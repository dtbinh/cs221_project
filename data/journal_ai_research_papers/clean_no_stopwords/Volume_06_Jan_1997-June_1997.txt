Journal Artificial Intelligence Research 6 (1997) 147-176

Submitted 6/96; published 5/97

Query DAGs: Practical Paradigm Implementing
Belief-Network Inference
Adnan Darwiche

darwiche@aub.edu.lb

Department Mathematics
American University Beirut
PO Box 11 - 236, Beirut, Lebanon

Gregory Provan

provan@risc.rockwell.com

Rockwell Science Center
1049 Camino Dos Rios
Thousand Oaks, CA 91360

Abstract

describe new paradigm implementing inference belief networks, consists two steps: (1) compiling belief network arithmetic expression called
Query DAG (Q-DAG); (2) answering queries using simple evaluation algorithm.
node Q-DAG represents numeric operation, number, symbol evidence. leaf node Q-DAG represents answer network query, is,
probability event interest. appears Q-DAGs generated using standard algorithms exact inference belief networks | show
generated using clustering conditioning algorithms. time space
complexity Q-DAG generation algorithm worse time complexity
inference algorithm based. complexity Q-DAG evaluation algorithm
linear size Q-DAG, inference amounts standard evaluation
arithmetic expression represents. intended value Q-DAGs reducing
software hardware resources required utilize belief networks on-line, real-world
applications. proposed framework also facilitates development on-line inference
different software hardware platforms due simplicity Q-DAG evaluation
algorithm. Interestingly enough, Q-DAGs found serve purposes: simple techniques reducing Q-DAGs tend subsume relatively complex optimization techniques
belief-network inference, network-pruning computation-caching.

1. Introduction
Consider designing car self-diagnostic system alert driver range
problems. Figure 1 shows simplistic belief network could provide ranked set
diagnoses car troubleshooting, given input sensors hooked battery,
alternator, fuel-tank oil-system.
standard approach building diagnostic system put belief network,
along inference code, onto car's computer; see Figure 2. encountered
number diculties using approach embody belief network technology industrial applications. First, asked provide technology multiple platforms.
applications, technology implemented ADA pass certain certification procedures. others, implemented domain-specific hardware
supports primitive programming languages. Second, memory limited keep

c 1997 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiDarwiche & Provan

fuel sensor
fuel
battery

oil-pressure
battery sensor

fault

oil-pressure
sensor
alternator
alternator
sensor

Figure 1: simple belief network car diagnosis.
cost unit certain threshold maintain product profitability. dilemma
following: belief network algorithms trivial implement, especially optimization crucial, porting algorithms multiple platforms languages would
prohibitively expensive, time-consuming demanding qualified manpower.
overcome diculties, devised exible approach implementing
belief network systems, based following observation. Almost work
performed standard algorithms belief networks independent specific evidence
gathered variables. example, run algorithm battery-sensor set
low run later variable set dead, find almost algorithmic
difference two runs. is, algorithm branch differently
key decisions makes, difference two runs specific
arguments invoked numeric operations. Therefore, one apply standard inference
algorithm network evidence parameter instead specific value.
result returned algorithm arithmetic expression parameters
depend specific evidence. parameterized expression call Query
DAG, example shown Figure 4.1
approach proposing consists two steps. First, given belief network, set
variables evidence may collected (evidence variables), set variables need compute probability distributions (query variables), Q-DAG
compiled off-line, shown Figure 3. compilation typically done sophisticated software/hardware platform, using traditional belief network inference algorithm
conjunction Q-DAG compilation method. part process far away
costly computationally. Second, on-line system composed generated
Q-DAG evaluator specific given platform used evaluate Q-DAG. Given
evidence, parameterized arithmetic expression evaluated straightforward manner
using simple arithmetic operations rather complicated belief network inference.
1. sharing subexpressions makes Directed Acyclic Graph instead tree.

148

fiA Practical Paradigm Implementing Belief-Network Inference

Traditional Approach

Compiled Approach

Fault
Variables
Causal
Network


N
L

N
E

Sensor
Values

Causal Network
Inference
Software

Sensor
Variables

Q-DAG
Compiler

Query
DAG

Q-DAG
Evaluator


F
F
L

N
E

0
N
L

N
E

Fault
Probabilities

Figure 2: figure compares traditional approach exact belief-network inference
(shown left) new compiled approach (shown right)
context diagnostic reasoning. traditional approach, belief network
sensor values used on-line compute probability distributions
fault variables; compiled approach, belief network, fault variables
sensor variables compiled off-line produce Q-DAG, evaluated
on-line using sensor values compute required distributions.
computational work needed perform on-line evaluation straightforward
lends easy implementations different software hardware platforms.
approach shares commonality methods symbolically manipulate probability expressions, like SPI (Li & D'Ambrosio, 1994; Shachter, D'Ambrosio, &
del Favero, 1990); differs SPI objective manipulations and, hence,
results obtained. SPI explicates notion arithmetic expression state
belief-network inference viewed expression-factoring operation. allows
results optimization theory utilized belief-network inference.
hand, define arithmetic expression explicate formalize boundaries
on-line off-line inference, goal identifying minimal piece software
required on-line. results therefore oriented towards purpose include:
(a) formal definition Q-DAG evaluator; (b) method generating Q-DAGs
using standard inference algorithms | algorithm need subscribe inference-as149

fiDarwiche & Provan

Query Variables

Evidence Variables

Causal Network

Q-DAG Compiler
Off-line

On-line
Query DAG

Evidence

Q-DAG Evaluator

Figure 3: proposed framework implementing belief-network inference.

(a)

(b)

Pr(A=ON) = .3

Pr(B=OFF, c)

Pr(B=ON, c)



+

+

.56

.075

+

Pr(B=ON|a)

.14

.225

B

C



*

*

*

*



*

Pr(C=ON|a)



.25



.9



.8



.5

.9

*
.1

(C,ON)

+
*

*
.5

(C,OFF)

Figure 4: belief network (a); corresponding Query-DAG (b). Here, C evidence
variable, interested probability variable B .
factoring view used Q-DAG generation; (c) computational guarantees
size Q-DAGs terms computational guarantees inference algorithm used
generate them. Although SPI framework positioned formulate related results,
pursued direction.
important stress following properties proposed approach. First, declaring evidence variable compilation process mean evidence must
collected variable on-line|this important evidence values, e.g.,
sensors, may lost practice|it means evidence may collected. Therefore, one declare variables evidence one wishes. Second, variable
declared evidence query. allows one perform value-of-information
150

fiA Practical Paradigm Implementing Belief-Network Inference

computations decide whether worth collecting evidence specific variable.
Third, space complexity Q-DAG terms number evidence variables
worse time complexity underlying inference algorithm; therefore,
simple enumerate-all-possible-cases approach. Finally, time space complexity
generating Q-DAG worse time complexity standard belief-network
algorithm used generation. Therefore, network solved using standard
inference algorithm, time complexity algorithm worse space
complexity,2 construct Q-DAG network.
following section explains concept Q-DAG concrete example
provides formal definitions. Section 3 dedicated generation Q-DAGs
computational complexity, showing standard belief-network inference algorithm
used compile Q-DAG long meets general conditions. Section 4
discusses reduction Q-DAG generated, showing reduction
subsumes key optimizations typically implemented belief network algorithms.
Section 5 contains detailed example application framework diagnostic
reasoning. Finally, Section 6 closes concluding remarks.

2. Query DAGs

section starts treatment Q-DAGs concrete example. consider
particular belief network, define set queries interest, show Q-DAG
used answer queries. discuss Q-DAG generated;
used. allow concrete introduction Q-DAGs help us
ground formal definitions follow.
belief network consider one Figure 4(a). class queries
interested Pr (B j C ), is, probability variable B takes value
given known (or unknown) value C . Figure 4(b) depicts Q-DAG answering
queries, essentially parameterized arithmetic expression values
parameters depend evidence obtained. Q-DAG actually answer queries
form Pr (B; C ), use normalization compute Pr (B j C ).
First, number observations Q-DAG Figure 4(b):
Q-DAG two leaf nodes labeled Pr (B=ON ; c) Pr (B=OFF ; c).
called query nodes values represent answers queries Pr (B=ON ; c)
Pr (B=OFF ; c).
Q-DAG two root nodes labeled (C; ) (C; ). called
Evidence Specific Nodes (ESNs) since values depend evidence collected
variable C on-line.
According semantics Q-DAGs, value node (V; v ) 1 variable V
observed v unknown, 0 otherwise. values ESNs determined,
evaluate remaining nodes Q-DAG using numeric multiplication addition.
numbers get assigned query nodes result evaluation answers
queries represented nodes.
2. Algorithms based join trees property.

151

fiDarwiche & Provan

.2725

.2875

.0925

Pr(B=OFF, c)

Pr(B=ON, c)

Pr(B=OFF, c)

.3475

Pr(B=ON, c)

+

+
.28

.2025

.07

*

*

*

*

.9

.0075

.28

*

*

.5

.1

+

+

.5

+

.9

0

.5

0

0

.1

*

*

*

*

*

*

(C,ON)

.5

.9

.1

0
(C,OFF)

0

(b)

.14

.225

+

.1

*

*

.56

.075

.07

.0225

.9

1

(a)

.14

.225

.56

.075

+

+

.0675

(C,ON)

0

.5

*

*
.5
1
(C,OFF)

Figure 5: Evaluating Q-DAG Figure 4 respect two pieces evidence: (a)
C=ON (b) C=OFF .
example, suppose evidence C = . ESN (C; )
evaluated 1 ESN (C; ) evaluated 0. Q-DAG Figure 4(b)
evaluated given Figure 5(a), thus leading
Pr (B=ON ; C=ON ) = :3475;



Pr (B=OFF ; C=ON ) = :2725;
conclude Pr (C = ) = :62. compute conditional
probabilities Pr (B=ON j C=ON ) Pr (B=OFF j C=ON ) using:
Pr (B=ON j C=ON ) = Pr (B=ON ; C=ON )=Pr (C=ON );
Pr (B=OFF j C=ON ) = Pr (B=OFF ; C=ON )=Pr (C=ON ):
evidence C=OFF , however, (C; ) evaluates 0 (C; )
evaluates 1. Q-DAG Figure 4(b) evaluated given Figure 5(b),
thus leading
Pr (B=ON ; C=OFF ) = :2875;

Pr (B=OFF ; C=OFF ) = :0925:
use following notation denoting variables values. Variables
denoted using uppercase letters, A; B; C , variable values denoted
lowercase letters, a; b; c. Sets variables denoted boldface uppercase letters,
A; B; C, instantiations denoted boldface lowercase letters,
a; b; c. use E denote set variables evidence. Therefore,
152

fiA Practical Paradigm Implementing Belief-Network Inference

use e denote instantiation variables represents evidence. Finally,
family variable set containing variable parents directed acyclic
graph.
Following formal definition Q-DAG.

Definition 1 Q-DAG tuple (V ; ; ; D; Z )
1. V distinguished set symbols (called evidence variables)
2. symbol (called unknown value)
3. maps variable V set symbols (called variable values) different
.
4. directed acyclic graph
- non-root node labeled either +
- root node labeled either
- number [0; 1]
- pair (V; v ) V evidence variable v value

5. Z distinguished set nodes (called query nodes)

Evidence variables V correspond network variables expect collect
evidence on-line. example, Figure 5, C evidence variable. one
variables set possible values captured function . example,
Figure 5, evidence variable C values . special value used
value variable known. example, may sensor variable
values \low," \medium," \high," lose sensor value on-line reasoning.
case, set sensor value .3 Query nodes representing answers
user queries. example, Figure 5, B query variable, leads query nodes
Pr(B=ON ; c) Pr(B=OFF ; c).
important notion evidence:

Definition 2 given Q-DAG (V ; ; ; D; Z ), evidence defined function E
maps variable V V set values (V ) [ fg.
variable V mapped v 2 (V ), evidence tells us V instantiated
value v . V mapped , evidence tell us anything value
V .
state formally evaluate Q-DAG given evidence. first
need notation:
1. Numeric-Node: n(p) denotes node labeled number p 2 [0; 1];
2. ESN: n(V; v ) denotes node labeled (V; v );
3. also useful cases variable measured value information justifies
that.

153

fiDarwiche & Provan

3. Operation-Node: n1
: : :
ni denotes node labeled parents
n1 ; : : :; ni ;
4. Operation-Node: n1 : : : ni denotes node labeled + parents
n1 ; : : :; ni .
following definition tells us evaluate Q-DAG evaluating nodes.
recursive definition according value assigned node function
values assigned parents. first two cases boundary conditions, assigning
values root nodes. last two cases recursive ones.
Definition 3 Q-DAG (V ; ; ; D; Z ) evidence E , node evaluator defined
function maps node number [0; 1] that:
1. [n(p)] = p
(The value node labeled number number itself.)
(
E (V ) = v E (V ) = ;
2. [n(V; v )] = 10;; ifotherwise
(The value evidence-specific node depends available evidence: 1 v
consistent evidence 0 otherwise.)
3. [n1
: : :
ni ] = (n1) : : : (ni )
(The value node labeled product values parent nodes.)
4. [n1 : : : ni ] = (n1) + : : : + (ni )
(The value node labeled + sum values parent nodes.)
One typically interested values nodes Q-DAG since
nodes represent intermediate results interest user. query nodes
Q-DAG represent answers user queries values nodes one
seeks constructing Q-DAG. values queries captured notion
Q-DAG output.
Definition 4 node evaluator extended Q-DAGs follows:
((V ; ; ; D; Z )) = f(n; (n)) j n 2 Zg:
set ((V ; ; ; D; Z )) called Q-DAG output.
output one seeks Q-DAG. element output represents
probabilistic query answer.
Let us consider evaluations Q-DAG shown Figure 4, shown
Figure 5. Given evidence E (C )= , assuming Qnode(B = ) Qnode(B =
) stand Q-DAG nodes labeled Pr (B=ON ; c) Pr (B=OFF ; c), respectively,

[n(C; )] = 1;
[n(C; )] = 0;
[Qnode(B=ON )] = :075 (:9 1 + :1 0) + :56 (1 :5 + :5 0) = :3475;
[Qnode(B=OFF )] = (:9 1 + :1 0) :225 + (1 :5 + :5 0) :14 = :2725;
154

fiA Practical Paradigm Implementing Belief-Network Inference

meaning Pr (B=ON ; C=ON ) = :3475 Pr (B=OFF ; C=ON ) = :2725. instead
evidence E (C )=OFF , set analogous computations done.
also possible evidence tells us nothing value variable C , is,
E (C ) = . case, would

[n(C; )] = 1;
[n(C; )] = 1;
[Qnode(B=ON )] = :075 (:9 1 + :1 1) + :56 (1 :5 + :5 1) = :635;
[Qnode(B=OFF )] = (:9 1 + :1 1) :225 + (1 :5 + :5 1) :14 = :365;
meaning Pr (B=ON ) = :635 Pr (B=OFF ) = :365.

2.1 Implementing Q-DAG Evaluator

Q-DAG evaluator implemented using event-driven, forward propagation scheme.
Whenever value Q-DAG node changes, one updates value children,
on, possible update values possible. Another way implement evaluator
using backward propagation scheme one starts query node updates
value updating values parent nodes. specifics application
typically determine method (or combination) appropriate.
important stress level refinement enjoyed Q-DAG propagation scheme implications eciency query updates. Propagation
Q-DAGs done arithmetic-operation level, contrasted propagation
message-operation level (used many standard algorithms). propagation schemes
typically optimized keeping validity ags messages invalid messages
recomputed new evidence arrives. clearly avoid unnecessary computations never avoid unnecessary computations message typically
coarse purpose. example, one entry message invalid,
whole message considered invalid. Recomputing message lead many unnecessary computations. problem avoided Q-DAG propagation since validity
ags attributed arithmetic operations, building blocks message operations. Therefore, necessary arithmetic operations recomputed Q-DAG
propagation scheme, leading detailed level optimization.
also stress process evaluating updating Q-DAG done outside
probability theory belief network inference. makes development ecient online inference software accessible larger group people may lack strong backgrounds
areas.4

2.2 Availability Evidence

construction Q-DAG requires identification query evidence variables.
may give incorrect impression must know front variables observed
not. could problematic (1) applications one may lose sensor
reading, thus changing status variable observed unobserved;
4. fact, appears background compiler theory may relevant generating ecient
evaluator background belief network theory.

155

fiDarwiche & Provan



.3

.3

Pr(B=true|a)
.1
.8

true
false

Pr(B=true,b)

+

*

Pr(a)



B

Pr(A=true,b)


true

Pr(B=false,b)

+

Pr(A=false,b)

+

+

*

.1

*

.9

(B,true)

(B,false)

.8

*

.7

.2

Figure 6: belief network corresponding Q-DAG variable B declared
query evidence.
(2) applications variable may expensive observe, leading on-line
decision whether observe (using value-of-information computation).
situations dealt Q-DAG framework. First, mentioned
earlier, Q-DAGs allow us handle missing evidence use notation
denotes unknown value variable. Therefore, Q-DAGs handle missing sensor
readings. Second, variable declared query evidence. means
incorporate evidence variable available, also compute
probability distribution variable case evidence available. Figure 6 depicts
Q-DAG variable declared query variable, variable B declared
evidence query variable (both variables true false values).
case, two ESNs variable B also two query nodes (see Figure 6).
Q-DAG used two ways:
1. compute probability distributions variables B evidence
available B . situation, values n(B; true ) n(B; false )
set 1,
Pr (A = true ) = :3 :1 + :3 :9 = :3
Pr (A = false ) = :8 :7 + :7 :2 = :7
Pr (B = true ) = :3 :1 + :8 :7 = :59
156

fiA Practical Paradigm Implementing Belief-Network Inference

Pr (B = false ) = :3 :9 + :7 :2 = :41

2. compute probability variable evidence available B .
example, suppose observe B false . value n(B; true )
set 0 value n(B; false ) set 1,
Pr (A = true ; B = false ) = :3 :9 = :27
Pr (A = false ; B = false ) = :7 :2 = :14

ability declare variable evidence query variable seems
essential applications (1) decision may need made whether collect
evidence variable B ; (2) making decision requires knowing probability
distribution variable B . example, suppose using following formula
(Pearl, 1988, Page 313) compute utility observing variable B :
X
Utility Observing (B ) = Pr(B = bje) U (B = b);
b

U (B = b) utility decision maker finding variable B value b.
Suppose U (B = true ) = $2:5 U (B = false ) = ,$3. use Q-DAG
compute probability distribution B use evaluate Utility Observing (B ):
Utility Observing (B ) = ($2:5 :59) + (,$3 :41) = $0:24;

leads us observe variable B . Observing B , find value false .
accommodate evidence Q-DAG continue analysis.

3. Generating Query DAGs

section shows Q-DAGs generated using traditional algorithms exact
belief-network inference. particular, show Q-DAGs generated using
clustering (join tree, Jensen, LS) algorithm (Jensen, Lauritzen, & Olesen, 1990; Shachter,
Andersen, & Szolovits, 1994; Shenoy & Shafer, 1986), polytree algorithm, cutset
conditioning (Pearl, 1988; Peot & Shachter, 1991). also outline properties must
satisfied belief network algorithms order adapt generating Q-DAGs
propose.

3.1 Clustering Algorithm

provide sketch clustering algorithm section. Readers interested
details referred (Shachter et al., 1994; Jensen et al., 1990; Shenoy & Shafer, 1986).
According clustering method, start by:
1. constructing join tree given belief network;5
5. join tree tree clusters satisfies following property: intersection two clusters
belongs clusters path connecting them.

157

fiDarwiche & Provan

2. assigning matrix variable belief network cluster contains
variable's family.
join tree secondary structure inference algorithm operates. need
following notation state algorithm:
- S1; : : :; Sn clusters, cluster corresponds set variables
original belief network.
- potential function cluster Si , mapping instantiations
variables Si real numbers.
- Pi posterior probability distribution cluster Si , mapping
instantiations variables Si real numbers.
- Mij message sent cluster Si cluster Sj , mapping instantiations variables Si \ Sj real numbers.
- e given evidence, is, instantiation evidence variables E.
also assume standard multiplication marginalization operations potentials.
goal compute potential Pr (X; e) maps instantiation x
variable X belief network probability Pr (x; e). Given notation,
state algorithm follows:
Potential functions initialized using

= Pr X X ;
X



{ X variable whose matrix assigned cluster Si;
{ Pr X matrix variable X : mapping instantiations family
X conditional probabilities;
{ X likelihood vector variable X : X (x) 1 x consistent given

evidence e 0 otherwise.
Posterior distributions computed using

Pi =


k

Mki ;

Sk clusters adjacent cluster Si .
Messages computed using
X
Mij =
Mki ;
Si nSj

k6=j

Sk clusters adjacent cluster Si .
158

fiA Practical Paradigm Implementing Belief-Network Inference

potential Pr (X; e) computed using
Pr (X; e) =

X
Si nfX g

Pi ;

Si cluster X belongs.
equations used follows. compute probability variable, must
compute posterior distribution cluster containing variable. compute
posterior distribution cluster, collect messages neighboring clusters. message
cluster Si Sj computed collecting messages clusters adjacent Si
except Sj .
statement join tree algorithm appropriate situations evidence
changing frequently since involves computing initial potentials time evidence
changes. necessary general one provide optimized versions
algorithm. issue, however, irrelevant context generating Q-DAGs
updating probabilities face evidence changes take place Q-DAG level,
includes optimization technique discuss later.

3.2 Generating Q-DAGs

generate Q-DAGs using clustering method, go two steps. First,
modify initialization potential functions join tree quantified
using Q-DAG nodes instead numeric probabilities. Second, replace numeric
addition multiplication algorithm analogous functions operate Q-DAG
nodes. particular:
1. Numeric multiplication replaced operation
takes Q-DAG nodes
n1; : : :; ni arguments, constructs returns new node n label parents
n1; : : :; ni .
2. Numeric addition + replaced operation takes Q-DAG nodes n1 ; : : :; ni
arguments, constructs returns new node n label + parents n1 ; : : :; ni.
Therefore, instead numeric operations, Q-DAG-node constructors. instead
returning number computation result, return Q-DAG node.
state Q-DAG clustering algorithm, realize evidence
e, instead set evidence variables E collect evidence.
Therefore, Q-DAG algorithm compute answer query Pr (x; e), instead
compute Q-DAG node evaluates Pr (x; e) instantiation e variables
E.
following equations, potentials mappings variable instantiations QDAG nodes (instead numbers). example, matrix variable X map
instantiation X 's family Q-DAG node n(p) instead mapping number
p. Q-DAG operations
extended operate new potentials
way + extended clustering algorithm.
new set equations is:
159

fiDarwiche & Provan

Potential functions initialized using


= n(Pr X )
n(E );
X

E



{ X variable whose matrix assigned cluster Si;
{ n(Pr X ) Q-DAG matrix X : mapping instantiations X 's family

Q-DAG nodes representing conditional probabilities;
{ E evidence variable whose matrix assigned cluster Si;
{ n(E ) Q-DAG likelihood vector variable E : n(E )(e) = n(E; e),
means node n(E )(e) evaluates 1 e consistent given evidence
0 otherwise.
Posterior distributions computed using

Pi = Mki ;
k

Sk clusters adjacent cluster Si .
Messages computed using

Mij =
Mki ;
Si nSj

k6=j

Sk clusters adjacent cluster Si .
Q-DAG nodes answering queries form Pr (x; e) computed using

Qnode(X ) =
Pi ;
Si nfX g

Si cluster X belongs.
Qnode(X ) potential maps instantiation x variable X Q-DAG
node Qnode(X )(x) evaluates Pr (x; e) given instantiation e variables E.
Hence, modifications made clustering algorithm (a) changing
initialization potential functions (b) replacing multiplication addition
Q-DAG constructors multiplication addition nodes.

3.3 Example

show proposed Q-DAG algorithm used generate Q-DAG
belief network Figure 4(a).
one evidence variable example, C . interested generating Q-DAG answering queries variable B , is, queries form Pr (b; e).
Figure 7(a) shows join tree belief network Figure 4(a), tables contain
potential functions needed probabilistic clustering algorithm. Figure 7(b) shows
160

fiA Practical Paradigm Implementing Belief-Network Inference

S1

AC




C=ON
.9
.5

2

(a)

AB


C=OFF
.1

S1

S2

AC


1

.5




B=ON
.25 * .3
.8 * .7

B=OFF
.75 * .3
.2 * .7

AB


C=OFF

C=ON



n(.9)

n(C,ON)

n(.1)

n(C,OFF)



n(.5)

n(C,ON)

n(.5)

n(C,OFF)


2

(b)

B=ON

S2

1

B=OFF



n(.075)

n(.225)



n(.56)

n(.14)

Figure 7: join tree quantified numbers (a), Q-DAG nodes (b).
join tree again, tables contain potential functions needed Q-DAG
clustering algorithm. Note tables filled Q-DAGs instead numbers.
apply Q-DAG algorithm. compute Q-DAG nodes evaluate
Pr (b; e), must compute posterior distribution P2 cluster S2 since
cluster variable B belongs. sum distribution variable
obtain want. compute distribution P2 must first compute message
M12 cluster S1 cluster S2 .
message M12 computed summing
potential function 1 cluster S1
possible values variable C , i.e., M12 = 1 ; leads to:
C

M12 (A=ON ) = [n(:9)
n(C; )] [n(:1)
n(C; )];
M12(A=OFF ) = [n(:5)
n(C; )] [n(:5)
n(C; )]:
posterior distribution cluster S2 , P2 , computed using P2 = 2
M12 ;

leads

P2 (A=ON ; B=ON ) = n(:075)
[[n(:9)
n(C; )] [n(:1)
n(C; )]]
P2(A=ON ; B=OFF ) = n(:225)
[[n(:9)
n(C; )] [n(:1)
n(C; )]]
P2(A=OFF ; B=ON ) = n(:56)
[[n(:5)
n(C; )] [n(:5)
n(C; )]]
P2(A=OFF ; B=OFF ) = n(:14)
[[n(:5)
n(C; )] [n(:5)
n(C; )]]:
Q-DAG node Qnode(b) answering queries
form Pr (b; e) computed
summing posterior P2 variable A, Qnode =
P2 ; leading
nfB g
Qnode(B=ON ) = [n(:075)
[[n(:9)
n(C; )] [n(:1)
n(C; )]]]
[n(:56)
[[n(:5)
n(C; )] [n(:5)
n(C; )]]]
Qnode(B=OFF ) = [n(:225)
[[n(:9)
n(C; )] [n(:1)
n(C; )]]]
[n(:14)
[[n(:5)
n(C; )] [n(:5)
n(C; )]]];
2

161

fiDarwiche & Provan

Q-DAG depicted Figure 4(b). Therefore, result applying algorithm
two Q-DAG nodes, one evaluate Pr (B = ; e) evaluate
Pr (B=OFF ; e) instantiation e evidence variables E.

3.4 Computational Complexity Q-DAG Generation

computational complexity algorithm generating Q-DAGs determined
computational complexity clustering algorithm. particular, proposed algorithm applies -operation precisely clustering algorithm applies additionoperation. Similarly, applies
-operation precisely clustering algorithm applies
multiplication-operation. Therefore, assume
take constant time,
algorithms time complexity.
application
ends adding new node Q-DAG.
way new node added Q-DAG. Moreover, number parents
added node equal number arguments corresponding arithmetic operation
invoked clustering algorithm. Therefore, space complexity Q-DAG
time complexity clustering algorithm.
particular, means space complexity Q-DAGs terms number
evidence variables time complexity clustering algorithm
terms. Moreover, evidence variable E add evidence-specific nodes
Q-DAG, number values variable E take. important
stress without complexity guarantee may hard distinguish
proposed approach brute-force approach builds big table containing possible
instantiations evidence variables together corresponding distributions query
variables.

3.5 Generation Algorithms

polytree algorithm special case clustering algorithm shown (Shachter
et al., 1994). Therefore, polytree algorithm also modified suggested
compute Q-DAGs. also means cutset conditioning easily modified
compute Q-DAGs: instantiation c cutset C, compute Q-DAG node
Pr (x; c; e) using polytree algorithm take -sum resulting nodes.
algorithms exact inference belief networks adapted generate QDAGs. general, algorithm must satisfy key condition adaptable computing
Q-DAGs suggested above. condition behavior algorithm
never depend specific evidence obtained, depend variables
evidence collected. is, whether variable E instantiated value v1
value v2 affect complexity algorithm. whether variable E
instantiated matter.
belief networks algorithms aware satisfy property. reason
seems notion probabilistic independence algorithms
based. Specifically, read topology belief network relation
(X; Z; Y), stating variables X independent given variables Z. is,
Pr (x; j z) = Pr (x j z)Pr (y j z)
162

fiA Practical Paradigm Implementing Belief-Network Inference

instantiations x; y; z variables. possible, however, hold
instantiations z specific ones. standard algorithms aware
take advantage instantiation{specific notion independence.6 Therefore,
cannot attach computational significance specific value variable
instantiated. property existing algorithms makes easily adaptable
generation Q-DAGs.

3.6 Soundness Q-DAG Clustering Algorithm

soundness proposed algorithm stated below. proof given Appendix A.

Theorem 1 Suppose Qnode(X ) Q-DAG potential generated Q-DAG clustering algorithm query variable X evidence variables E. Let e0 instantiation
variables E, let Q-DAG evidence E defined follows:
(
evidence e0 sets variable E value e;
E (E ) = e;; otherwise.


(Qnode(X )(x)) = Pr (x; e0):

is, theorem guarantees Q-DAG nodes generated algorithm
always evaluate corresponding probabilities partial full instantiation
evidence variables.

4. Reducing Query DAGs

section focused reducing Q-DAGs generated. main
motivation behind reduction twofold: faster evaluation Q-DAGs less space
store them. Interestingly enough, observed few, simple reduction techniques
tend certain cases subsume optimization techniques uential practical implementations belief-network inference. Therefore, reducing Q-DAGs
important practically.
section structured follows. First, start discussing four simple reduction
operations form rewrite rules. show examples reductions subsume two key optimization techniques known network-pruning computation-caching.

4.1 Reductions

goal Q-DAG reduction reduce size Q-DAG maintaining
arithmetic expression represents. describing equivalence arithmetic expressions,
define notion Q-DAG equivalence:
Definition 5 Two Q-DAGs equivalent iff set evidence-specific
nodes output possible Q-DAG evidence.
6. algorithms two{level binary networks (BN20 networks), versions SPI algorithm
take advantage independences.

163

fiDarwiche & Provan

Q



.

.

.
p

.

q
Q2

Q

p

.

+

Q1

*
Q1

Q3

*
Q2 Q 1

*

.

q

+

Q2

Q3

b) numeric
reduction

c) associative
merging

Q1

Q1
Q2

(a) Identity
elimination

Q3

Q3

d) commutative
merging

Figure 8: four main methods Q-DAG reduction.
Figure 8 shows four basic reduction operations experimented with:
1. Identity elimination: eliminates numeric node identity element child
operation node.
2. Numeric reduction: replaces operation node numeric node parents
numeric nodes.
3. Associative merging: eliminates operation node using operation associativity.
4. Commutative merging: eliminates operation node using operation commutativity.
rules applied successively different order applications
possible.
proven operations sound (Darwiche & Provan, 1995). Based
analysis network structure preliminary empirical results, observed
many factors govern effectives operations. degree reduction
operations, numeric reduction particular, reduce size Q-DAG depends
topology given belief network set evidence query variables.
example, root nodes evidence variables belief network, leaf nodes
query variables, numeric reduction lead little Q-DAG reduction.
focus numeric reduction, showing sometimes subsumes two optimization techniques uential belief network algorithms. optimizations, show examples unoptimized algorithm employs numeric reduction
yields Q-DAG optimized algorithm. major implication optimizations done uniformly Q-DAG level, freeing underlying belief network
algorithms implementational complications.
following examples assume applying polytree algorithm singlyconnected networks.
164

fiA Practical Paradigm Implementing Belief-Network Inference





P(a)



.6




B

.9
.5

.6



B



.8
.3

P(B=ON|a)
.9
.5




P(C=ON|b)

b

(a)

P(a)

P(B=ON|a)




C




(b)

Figure 9: simple belief network pruning (a) pruning (b). light-shaded
node, A, query node, dark-shaded node, B , evidence node.

P(A=ON,B=b)

P(A=ON,B=b)

*

*

+

(B,ON)

+

.8

.2

.1

+

(B,OFF)

.3

.6

*

*

*

*
.9

+

.6

.9

(B,ON)

(B,OFF)

.1

.7

(a) Original Q-DAG

(b) Reduced Q-DAG

Figure 10: Q-DAG (a) reduction (b).

4.2 Network Pruning
Pruning process deleting irrelevant parts belief network invoking inference. Consider network Figure 9(a) example, B evidence variable
query variable. One prune node C network, leading network
Figure 9(b). query form Pr (a j b) value respect either
network. clear working smaller network preferred. general,
pruning lead dramatic savings since reduce multiply-connected network
singly-connected one.
165

fiDarwiche & Provan

generate Q-DAG network Figure 9(a) using polytree algorithm,
obtain one Figure 10(a). Q-DAG corresponds following expression,
X
X
Pr (A=ON ; e) = Pr (A=ON ) B (b)Pr (b j A=ON ) Pr (c j b):
c

b

generate Q-DAG network Figure 9(b), however, obtain one
Figure 10(b) corresponds following expression,
X
Pr (A=ON ; e) = Pr (A=ON ) B (b)Pr (b j A=ON ):
b

expected, Q-DAG smaller Q-DAG Figure 10(a), contains subset
nodes Figure 10(a).
key observation, however, optimized Q-DAG Figure 10(b)
obtained unoptimized one Figure 10(a) using Q-DAG reduction. particular,
nodes enclosed dotted lines collapsed using numeric reduction single
node value 1. Identity elimination remove resulting node, leading
optimized Q-DAG Figure 10(b).
general observation, however, prunable nodes contribute identity elements computing answers queries. contributions appear Q-DAG nodes
evaluate identity elements instantiations evidence. nodes
easily detected collapsed identity elements using numeric reduction. Identity
elimination remove Q-DAG, leading effect network
pruning.7 Whether Q-DAG reduction replace possible pruning operations open
question outside scope paper.

4.3 Computation Caching

Caching computations another uential technique optimizing inference belief networks. consider example, suppose applying polytree algorithm
compute Pr (c; b) network Figure 11. Given evidence, say B =ON , algorithm
compute Pr (c; B = ) passing messages shown Figure 12. evidence
changes B=OFF , however, algorithm employing caching recompute message B (a) (which represents causal support B (Pearl, 1988)) since value
message depend evidence B .8 kind optimization typically
7. Note, however, Q-DAG reduction reduce computational complexity generating QDAG, although network pruning may. example, multiply{connected network may become singlyconnected pruning, thereby, reducing complexity generating Q-DAG. using Q-DAG
reduction, still generate Q-DAG working multiply-connected network.
8. seen considering following expression, evaluated incrementally polytree
algorithm message passes:
Pr (c; e) =

X
b

Pr (c j b) B (b)

|

X


Pr (b j a) Pr (a) :

{z

C (b)

| {z }
B
}
( )

clear subexpression corresponding message B (a) B independent
evidence B .

166

fiA Practical Paradigm Implementing Belief-Network Inference


B
C



Pr(a)



.6



Pr(B=ON|a)
.9
.5




Pr(C=ON|b)

b

.8
.3




Figure 11: simple belief network demonstrating relationship Q-DAG reduction computation caching. light-shaded node, C , query node,
dark-shaded node, B , evidence node.



(a)
B
B

(b)
C
C

Figure 12: Message passing C queried B observed.
implemented caching values messages keeping track messages
affected evidence.
Now, consider Q-DAG corresponding problem shown Figure 13(a).
nodes enclosed dotted lines correspond message B .9 nodes
evidence-specific nodes ancestor set and, therefore, never change values
due evidence changes. fact, numeric reduction replace one nodes
ancestors single node shown Figure 13(b).
general, numeric reduction applied Q-DAG, one guaranteed following:
(a) Q-DAG node represents message depend evidence, node
re-evaluated given evidence changes; (b) numeric reduction guarantee
P Pr (b a)Pr (a).
9. precisely, correspond expression


167

j

fiDarwiche & Provan

P(C=ON,B=b)

P(C=ON,B=b)

+

+

*

.8

*
+

*

*

(B,ON)

*

.3

*

.74
+

(B,OFF)

*

(B,OFF)

(B,ON)

.3

*

.8

.26

*

*

*

*

cached value
.9

.6

.5

.4
.1

.6 .5

.4

(a) Original Q-DAG

(b) Reduced Q-DAG

Figure 13: Q-DAG (a) reduction (b).
Q-DAG evaluation method since replace node ancestor set
single root node.10

4.4 Optimization Belief-Network Inference

Network pruning computation caching proven uential practical
implementations belief-network inference. fact, experience shown
optimizations typically make difference usable non-usable beliefnetwork system.
One problem optimizations, however, algorithm-specific implementations although based general principles (e.g., taking advantage network
topology). Another problem make elegant algorithms complicated hard
understand. Moreover, optimizations often hard define succinctly, hence
well documented within community.
contrast, belief{network inference optimized generating Q-DAGs using unoptimized inference algorithms, optimizing generated Q-DAG reduction techniques. shown examples earlier respect pruning
caching optimizations. However, whether alternate approach optimization always
feasible yet known. positive answer clearly provide algorithm{independent
10. Note Q-DAGs lead refined caching mechanism Q-DAG evaluator (1) caches value
Q-DAG node (2) updates cached values need (that is,
value parent node changes). refined mechanism allows caching values messages
depend evidence well.

168

fiA Practical Paradigm Implementing Belief-Network Inference

fuel sensor
fuel
battery

oil-pressure
battery sensor

fault

oil-pressure
sensor
alternator
alternator
sensor

Figure 14: simple belief network car diagnosis.
approach optimizing belief{network inference, practically important least
two reasons. First, Q-DAG reduction techniques seem much simpler understand
implement since deal graphically represented arithmetic expressions, without
invoke probability belief network theory. Second, reduction operations applicable Q-DAGs generated belief{network algorithm. Therefore, optimization
approach based Q-DAG reduction would systematic accessible bigger
class developers.

5. Diagnosis Example
section contains comprehensive example illustrating application Q-DAG
framework diagnostic reasoning.
Consider car troubleshooting example depicted Figure 14. simple case
want determine probability distribution fault node, given evidence four
sensors: battery-, alternator-, fuel- oil-sensors. sensor provides information
corresponding system. fault node defines five possible faults: normal, cloggedfuel-injector, dead-battery, short-circuit, broken-fuel-pump.
denote fault variable F , sensor variables E, want build
system compute probability Pr (f; e); fault f evidence e.
probabilities represent unnormalized probability distribution fault variable
given sensor readings. Q-DAG framework, realizing diagnostic system involves three
steps: Q-DAG generation, reduction, evaluation. first two steps accomplished
off-line, final step performed on-line. discuss one steps
detail.

5.1 Q-DAG Generation
first step generate Q-DAG. accomplished applying Q-DAG
clustering algorithm fault query variable sensors evidence vari169

fiDarwiche & Provan

P(F=normal,e)

P(F=normal)
.90

P(F=pump)
.05

fuel
(normal)

P(F=pump,e)

fuel
subtree

(pump)

battery
(normal)

battery
(pump)

alternator
(normal)

oil
alternator
(pump)

(normal)

oil
(pump)

structure-sharing

Figure 15: partial Q-DAG car example, displaying two five query nodes,
broken fuel pump normal. shaded regions portions Q-DAG
shared multiple query nodes; values nodes relevant
value one query node.
ables. resulting Q-DAG five query nodes, Qnode(F = normal ; e), Qnode(F =
clogged fuel injector ; e), Qnode(F = dead battery ; e), Qnode(F = short circuit ; e),
Qnode(F = broken fuel pump; e). node evaluates probability corresponding fault instantiation evidence. probabilities constitute differential
diagnosis tells us fault probable given certain sensor values.
Figure 15 shows stylized description Q-DAG restricted two five query
nodes, corresponding Pr (F = broken fuel pump ; e) Pr (F = normal ; e). Q-DAG
structure symmetric fault value sensor.
Given Q-DAG symmetric possible faults, clarity exposition
look subset needed evaluate node Pr (F = broken fuel pump ; e). Figure 16
shows stylized version Q-DAG produced node. Following observations Q-DAG. First, evidence-specific node every instantiation
sensor variables, corresponding forms sensor measurements possible. Second,
roots Q-DAG probabilities. Third, one five parents query node
Pr(F = broken fuel pump ; e) prior F = broken fuel pump , four
contributions four sensors. example, Figure 16 highlights (in dots)
part Q-DAG computing contribution battery sensor.

5.2 Q-DAG Reduction

generating Q-DAG, one proceeds reducing using graph rewrite rules. Figure 16
shows example reduction Q-DAG restricted one query node
simplicity. give idea kind reduction applied, consider
partial Q-DAG enclosed dots figure. Figure 17 compares reduced Q-DAG
unreduced one generated. Given goal generating Q-DAGs
(a) evaluated eciently possible (b) require minimal space store,
170

fiA Practical Paradigm Implementing Belief-Network Inference

KEY
F-S fuel-sensor
B-S battery-sensor
A-S alternator-sensor
O-S oil-sensor

P(F=pump,e)

*

+

P(F=pump)
.05

+

*

*

*

*

full)

+

*

*

*

*

.36 ESN(B-S, .64 ESN(A-S, .45 ESN(A-S, .55 ESN(O-S, .27 ESN(O-S,

.4 ESN(F-S, .6 ESN(B-S,

ESN(F-S,
empty)

+

dead)

charged)

not-OK)

OK)

low)

.73

normal)

Figure 16: partial Q-DAG car example.
+
*

*

(a) Reduced Q-DAG
ESN(B-S,

.36 ESN(B-S, .64

dead)

charged)

+

(b) Original Q-DAG

+

+

*
ESN(B-S,

ESN(B-S,

*

charged)

dead)

P(B-S=charged| P(B=charged|
F=pump,B=charged) F=pump)
.8

*

*

.6

ESN(B-S,

*

charged)

P(B-S=dead|
P(B-S=charged|
P(B=charged|
F=pump,B=dead)
F=pump,B=charged) F=pump)
.2

.6

.4

*
*
P(B=dead|
F=pump)
.4

ESN(B-S,
dead)
P(B-S=dead|
F=pump,B=dead)
.6

*
P(B=dead|
F=pump)
.4

Figure 17: Reduced unreduced Q-DAGs car diagnosis example.
important see, even simple example, Q-DAG reduction make big difference
size.
171

fiDarwiche & Provan

5.3 Q-DAG Evaluation

reduced Q-DAG, use compute answers diagnostic queries.
section presents examples evaluation respect generated Q-DAG.
Suppose obtain readings dead, normal, ok full battery, oil,
alternator fuel sensors, respectively. let us compute probability distribution
fault variable. obtained evidence formalized follows:
- E (battery sensor ) = dead ,
- E (oil sensor ) = normal ,
- E (alternator sensor ) = ok ,
- E (fuel sensor ) = full .
Evidence-specific nodes evaluated according Definition 3. example,

[n(battery sensor ; charged)] = 0;

[n(battery sensor ; dead )] = 1:
evaluation evidence-specific nodes shown pictorially Figure 18(a). Definition 3
used evaluate remaining nodes: values node's parents
known, value node determined. Figure 18(b) depicts results
evaluating nodes. result interest probability 0.00434 assigned
query node Pr (fault = broken fuel pump ; e).
Suppose evidence changed value fuel sensor empty instead
full. update probability assigned node Pr (fault = broken fuel pump ; e), brute
force method re-evaluate whole Q-DAG. However, forward propagation scheme
used implement node evaluator, four nodes need re-evaluated
Figure 18(b) (those enclosed circles) instead thirteen (the total number nodes).
stress point refined updating scheme, easy implement
framework, much harder achieve one attempts embed standard beliefnetwork algorithms based message passing.

6. Concluding Remarks

introduced new paradigm implementing belief-network inference oriented towards real-world, on-line applications. proposed framework utilizes knowledge
query evidence variables application compile belief network arithmetic expression called Query DAG (Q-DAG). node Q-DAG represents numeric
operation, number, symbol depends available evidence. leaf node
Q-DAG represents answer network query, is, probability event
interest. Inference Q-DAGs linear size amounts standard evaluation
arithmetic expressions represent.
important point stress work reported proposing
new algorithm belief-network inference. proposing paradigm
172

fiA Practical Paradigm Implementing Belief-Network Inference

Pr(F=pump,e)
(a) Evaluating ESNs

*

+

.05
Pr(F=pump)

+

*
0

*
1

.4

ESN(F-S,
empty)

+

*

*

1

.6

*

.36 0

ESN(B-S,
dead)

ESN(F-S,
full)

+

.64

ESN(B-S,
charged)

0

*

*

.45 1

ESN(A-S,
not-OK)

.55

ESN(A-S,
OK)

*
.27

0

ESN(O-S,
low)

1

ESN(O-S,
normal)

.73

ESN values

.0043362

Pr(F=pump,e)
(b) Propagating probabilities

*

0 *
0
ESN(F-S,
empty)

+ .36

+ .6

.05
Pr(F=pump)

* .36

.6 *
.4

1
ESN(F-S,
full)

.6

1
ESN(B-S,
dead)

+ .55

0*

.36 0
ESN(B-S,
charged)

*0
.64

0
ESN(A-S,
not-OK)

+ .73

.55*
.45 1
ESN(A-S,
OK)

* 0
.55

0

ESN(O-S,
low)

.73 *

.27

1

ESN(O-S,
normal)

.73

ESN values

Figure 18: Evaluating Q-DAG car diagnosis example given evidence sensors.
bar (a) indicates instantiation ESNs. shaded numbers
(b) indicate probability values computed node evaluator.
circled operations left-hand-side (b) ones need
updated evidence fuel-system sensor altered, denoted circled
ESNs.

173

fiDarwiche & Provan

implementing belief-network inference orthogonal standard inference algorithms
engineered meet demands real-world, on-line applications. class
applications typically demanding following reasons:
1. typically requires short response time, i.e., milliseconds.
2. requires software written specialized languages, ADA, C++,
assembly pass certification procedures.
3. imposes severe restrictions available software hardware resources order
keep cost \unit" (such electromechanical device) low possible.
address real-world constraints, proposing one compile belief network
Q-DAG shown Figure 3 use Q-DAG evaluator on-line reasoning.
brings required memory needed storing Q-DAG evaluator.
also brings required software needed implementing Q-DAG evaluator,
simple seen earlier.
proposed approach still requires belief-network algorithm generate Q-DAG,
makes eciency algorithm less critical factor.11 example,
show standard optimizations belief-network inference, pruning
caching, become less critical Q-DAG framework since optimizations tend
subsumed simple Q-DAG reduction techniques, numeric reduction.
work reported paper extended least two ways. First, QDAG reduction techniques could explored, oriented towards reducing evaluation
time Q-DAGs, others towards minimizing memory needed store them. Second,
shown optimization techniques dramatically improve belief-network
algorithms may become irrelevant size Q-DAGs Q-DAG reduction employed.
investigation needed prove formal results guarantees effectiveness
Q-DAG reduction.
close section noting framework proposed also applicable
order-of-magnitude (OMP) belief networks, multiplication addition get replaced
addition minimization, respectively (Goldszmidt, 1992; Darwiche & Goldszmidt,
1994). OMP Q-DAG evaluator, however, much ecient probabilistic
counterpart since one may evaluate minimization node without evaluate
parents many cases. make considerable difference performance Q-DAG
evaluator.

Acknowledgements
work paper carried first author Rockwell Science
Center. Special thanks Jack Breese, Bruce D'Ambrosio anonymous reviewers
useful comments earlier drafts paper.
11. shown clustering conditioning algorithms used Q-DAG generation,
algorithms SPI (Li & D'Ambrosio, 1994; Shachter et al., 1990) used well.

174

fiA Practical Paradigm Implementing Belief-Network Inference

Appendix A. Proof Theorem 1

Without loss generality, assume proof variables declared evidence
variables. prove soundness theorem, need show Q-DAG potential evaluate corresponding probabilistic potential possible evidence.
Formally, cluster variables X , matrices assigned ,
need show


( n(Pr X )
n(X )) = Pr X X
(1)
X

X

given evidence E . establish this, guaranteed Qnode(X )(x)
evaluate probability Pr (x; e) application
Q-DAG algorithm isomorphic application + probabilistic algorithm, respectively.
prove Equation 1, extend Q-DAG node evaluator mappings
standard way. is, f mapping instantiations Q-DAG nodes, (f )
defined follows:
(f )(x) =def (f (x)):
is, simply apply Q-DAG node evaluator range mapping f .
Note (f
g ) equal (f )ME (g ). Therefore,

( n(Pr X )
n(X ))
XY
=
(n(Pr X ))ME (n(X ))
X

=
Pr X (n(X )) definition n(Pr X ):
X

Note also definition n(X ), n(X )(x) equals n(X; x). Therefore,
(n(X ))(x) = (n(X )(x))
=
( E (n(X; x))
1; E (X ) = x E (X ) =
=
0; otherwise
= X (x):
Therefore,


( n(Pr X )
n(X )) = Pr X X :
X

X

References

Darwiche, A., & Goldszmidt, M. (1994). relation kappa calculus probabilistic reasoning. Proceedings Tenth Conference Uncertainty Artificial
Intelligence (UAI), pp. 145{153.
Darwiche, A., & Provan, G. (1995). Query DAGs: practical paradigm implementing
on-line causal-network inference. Tech. rep. 95-86, Rockwell Science Center, Thousand
Oaks, CA.
175

fiDarwiche & Provan

Goldszmidt, M. (1992). Qualitative probabilities: normative framework commonsense
reasoning. Tech. rep. R-190, University California Los Angeles, Ph.D. thesis.
Jensen, F. V., Lauritzen, S., & Olesen, K. (1990). Bayesian updating recursive graphical
models local computation. Computational Statistics Quarterly, 4, 269{282.
Li, Z., & D'Ambrosio, B. (1994). Ecient Inference Bayes Networks Combinatorial
Optimization Problem. International Journal Approximate Reasoning, 11, 55{81.
Pearl, J. (1988). Probabilistic Reasoning Intelligent Systems: Networks Plausible Inference. Morgan Kaufmann Publishers, Inc., San Mateo, California.
Peot, M. A., & Shachter, R. D. (1991). Fusion propagation multiple observations
belief networks. Artificial Intelligence, 48 (3), 299{318.
Shachter, R., Andersen, S., & Szolovits, P. (1994). Global Conditioning Probabilistic
Inference Belief Networks. Proc. Tenth Conference Uncertainty AI, pp.
514{522 Seattle WA.
Shachter, R., D'Ambrosio, B., & del Favero, B. (1990). Symbolic Probabilistic Inference
Belief Networks. Proc. Conf. Uncertainty AI, pp. 126{131.
Shenoy, P. P., & Shafer, G. (1986). Propagating belief functions local computations.
IEEE Expert, 1 (3), 43{52.

176

fiJournal Artificial Intelligence Research 6 (1997) 211-221

Submitted 12/96; published 6/97

Research Note

Complete Classification Tractability RCC-5

Peter Jonsson
Thomas Drakengren

Department Computer Information Science, Linkoping University
S-581 83 Linkoping, Sweden

petej@ida.liu.se
thodr@ida.liu.se

Abstract

investigate computational properties spatial algebra RCC-5 restricted
version RCC framework spatial reasoning. satisfiability problem RCC-5 known
NP-complete much known approximately four billion subclasses.
provide complete classification satisfiability subclasses polynomial NPcomplete respectively. process, identify maximal tractable subalgebras four
total.

1. Introduction

Qualitative spatial reasoning received constantly increasing amount interest literature.
main reason is, probably, spatial reasoning proved applicable realworld problems in, example, geographical database systems (Egenhofer, 1991; Grigni, Papadias,
& Papadimitriou, 1995) molecular biology (Cui, 1994). applications, size
problem instances huge, complexity problems algorithms highly relevant
area study. However, questions computational complexity received much attention
literature; two notable exceptions results reported Nebel (1995) Renz
Nebel (1997). article take small step towards better understanding complexity
issues qualitative spatial reasoning.
well-known framework qualitative spatial reasoning so-called RCC approach (Randell
& Cohn, 1989; Randell, Cui, & Cohn, 1992). approach based modelling qualitative spatial
relations regions using first-order logic. special interest, complexity-theoretic
standpoint, two subclasses RCC-5 RCC-8. well-known RCC-5
RCC-8 quite weak expressive power. Although used describe spatial situations,
general perhaps better described topological algebras. However,
denote algebras spatial algebras order avoid terminological confusion; term
topological algebra well-established completely different meaning mathematics (Mallios,
1986).
Bennett (1994) shown suciency using propositional logics reasoning RCC5 RCC-8. Hence, reasoning becomes ecient compared reasoning full
first-order logic. Bennett's approach uses classical propositional logic RCC-5 intuitionistic
propositional logic RCC-8. Unfortunately, logics known computationally hard.
satisfiability problem classical propositional logic intuitionistic propositional logic NPcomplete (Cook, 1971) Pspace-complete (Statman, 1979) respectively. However, complexity
underlying logic carry cases; Renz Nebel (1997) shown
satisfiability problem RCC-5 RCC-8 NP-complete. full proofs found
(Renz, 1996).
findings motivate search tractable subclasses RCC-5 RCC-8. Nebel (1995)
showed reasoning basic relations RCC-8 polynomial-time problem. Renz
Nebel (1997) improved result substantially showing following results:

c 1997 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiJonsson & Drakengren

exists large, maximal subclass RCC-8, denoted Hb8, contains basic relations
polynomial. Hb8 contains 148 elements 256 (58%).
exists large, maximal subclass RCC-5, denoted Hb5, contains basic relations
polynomial. Hb5 contains 28 elements 32 (87%). Furthermore, unique,
maximal subclass RCC-5 containing basic relations.

concentrate RCC-5 article. main result complete classification
subclasses RCC-5 respect tractability. classification makes possible determine
whether given subclass tractable simple test carried hand
automatically. thus gained clear picture tractability borderline RCC-5.
less necessary showing results kind, main proof relies case analysis
performed computer. number cases considered roughly 4 104 . analysis cannot,
course, reproduced research paper verified manually. Hence, include description
programs used. programs also available on-line appendix article.
structure article follows: Section 2 defines RCC-5 auxiliary concepts.
Section 3 contains tractability proofs three subclasses RCC-5. Section 4 show
subclasses together Hb5 maximal tractable subclasses RCC-5. article
concludes brief discussion results.

2. RCC-5 Algebra

follow Bennett (1994) definition RCC-5. RCC-5 based notions regions
binary relations them. region p variable interpreted non-empty subsets
fixed set. noted require sets open sets topological
space. limitation since impossible distinguish interior points boundary points
RCC-5. Thus take set X use discrete topology = hX ; 2X i, every
subset X open set .
assume fixed universe variable names regions. Then, R-interpretation
function maps region variables non-empty subsets set.
Given two interpreted regions, relation described exactly one elements
set B five basic RCC-5 relations. definition relations found Table 1.
Figure 1 shows 2-dimensional examples relations RCC-5. formula form XBY
X regions B 2 B, said satisfied R-interpretation iff interpretation
regions satisfies relations specified Table 1.
express indefinite information, unions basic relations used, written sets basic
relations, leading 25 binary RCC-5 relations. Naturally, set basic relations interpreted
disjunction basic relations. set RCC-5 relations 2B denoted R5. Relations
special interest null relation ? (also denoted ?) universal relation B (also
denoted >).
formula form X fB1 ; : : :; B gY called RCC-5 formula. formula satisfied
R-interpretation = iff XB satisfied = i, 1 n. finite set RCC-5
formulae said R-satisfiable iff exists R-interpretation = satisfies every formula
. satisfying R-interpretation called R-model . Given R-interpretation =
variable v, write =(v) denote value v interpretation =.
reasoning problem study following:
n



: finite set RCC-5 formulae.
: exist R-model ?

Instance
Question

212

fiA Complete Classification Tractability RCC-5

X fDRgY
X fPOgY
X fPPgY
X fPPIgY
X fEQgY

iff X \ = ?
iff 9a; b; c : 2 X; 62 Y; b 2 X; b 2 Y; c 62 X; c 2
iff X
iff X
iff X =
Table 1: five basic relations RCC-5.

X

X





(X; )

DR

(X; )

PO

X

PP

(X; )

X

PPI

(X; )

X
(X; )

EQ

Figure 1: Pictorial example relations RCC-5.
denote problem RSAT. following, often consider restricted versions RSAT
relations used formulae subset R5. case say
set formulae use parameter problem description denote subclass
consideration, e.g., RSAT(S ). Note RSAT problem instance represented
labelled directed graph, nodes region variables arcs labelled relations
variables. Given instance RSAT, say graph graph representation
.
continue defining algebra RCC-5 relations.

Definition 2.1 Let B = fDR; PO; PP; PPI; EQg. RCC-5 algebra consists set R5 = 2B
operations unary converse (denoted ), binary intersection (denoted \) binary
composition (denoted ). defined follows:
8X; :
XR iff RX
8X; : X (R \ )Y iff XRY ^ XSY
8X; : X (R )Y iff 9Z : (XRZ ^ ZSY )
subset R5 , said subalgebra RCC-5
iff closed converse, intersection
composition. easily verified R = fB B 0 jB 2 R; B 0 2 g, i.e., composition
^

^

union component-wise composition basic relations.
Next, introduce closure operation. closure operation transforms given subclass
R5 one polynomially equivalent original subclass respect satisfiability.
operation similar closure operation RCC-5 introduced Renz (1996)
pose restrictions given subclass. (Renz's operation requires fEQg member
subclass closed.)

Definition 2.2 Let R5. denote closure , defined least subalgebra
containing closed converse, intersection composition.
Observe subset R5 subalgebra iff = .

next lemma given without proof. proof analogous result Allen's algebra
found Nebel Burckert (1995).
213

fiJonsson & Drakengren

Lemma 2.3 Let R5. RSAT(S ) polynomially transformed RSAT(S ) vice
versa.

Corollary 2.4 Let R5. RSAT(S ) polynomial iff RSAT(S ) polynomial. RSAT(S )
NP-complete iff RSAT(S ) NP-complete.

3. Tractable Subclasses RCC-5

begin section defining four tractable subalgebras RCC-5, found Table 2.
Later on, show algebras maximal tractable subalgebras RCC-5.
28
tractability first algebra, R28
5 , established Renz Nebel (1997). name R5
ects fact algebra contains 28 elements.

Theorem 3.1 RSAT(R28
5 ) polynomial.
tractability second algebra, R20
5 , settled quite easily. algorithm found
Figure 2.
20
Lemma 3.2 Let instance RSAT(R20
5 ). algorithm accepts input iff

R-model.

Proof: if: show contrapositive, i.e., A20 rejects R-model. Clearly,
satisfiability preserved transformations made lines 7-10. Note XRX 2
EQ 2 R satisfiable. Thus satisfiable algorithm rejects line 5. Similarly,
satisfiable algorithm rejects line 6.

only-if: Consider set completion line 11. denote set 0 . Obviously, 0

satisfiable initial satisfiable. Also observe line 7 ensures 0 relate
variables EQ. Furthermore, line 8 guarantees one relation relates
two variables.
Now, construct R-model 0 follows: Let V set variables 0 . Let
assign non-empty sets pairwise disjoint members V . Let U = 2 (X ).
Introduce set values U 0 = fff j X; 2 V g satisfying following:
X

V

X;Y

1. ff = ff iff X = Z = W ;
2. arbitrary X; 2 V , ff 62 U .
X;Y

Z;W

X;Y

relation type X fPOgY X fPO; EQgY , extend sets (X ) (Y )
element ff .
Clearly, two sets X; disjoint (and thus related DR) unless X fPOgY
X fPO; EQgY . cases, X must disjoint. fact, introducing
ff , forced X fPOgY hold satisfies formulae type X fPOgY well
formulae type X fPO; EQgY . Hence, R-model 0 implies R-satisfiability
.
2
X;Y

X;Y

Theorem 3.3 RSAT(R20
5 ) polynomial.
Proof: Algorithm A20 correctly solves RSAT(R20
5 ) problem previous lemma. Further-

more, number iterations bounded number variables number
formulae given instance tests easily performed polynomial time.
2
Next show tractability RSAT(R17
5 ).
214

fiA Complete Classification Tractability RCC-5

20 R17 R14
R28
5 R5
5
5
?


fDRg

fPOg

fDR; POg

fPPg


fDR; PPg

fPO; PPg

fDR; PO; PPg

fPPIg


fDR; PPIg

fPO; PPIg

fDR; PO; PPIg

fPP; PPIg

fDR; PP; PPIg


fPO; PP; PPIg


fDR; PO; PP; PPIg

fEQg


fDR; EQg

fPO; EQg

fDR; PO; EQg

fPP; EQg



fDR; PP; EQg

fPO; PP; EQg


fDR; PO; PP; EQg
fPPI; EQg



fDR; PPI; EQg

fPO; PPI; EQg


fDR; PO; PPI; EQg
fPP; PPI; EQg


fDR; PP; PPI; EQg


fPO; PP; PPI; EQg


>


Table 2: maximal tractable subalgebras RCC-5.

Theorem 3.4 RSAT(R17
5 ) polynomial.
Proof: Consider algorithm A17 Figure 2. exist X; X ?Y 2

satisfiable. Otherwise, let variables value. Since EQ member
every relation occurs , interpretation R-model .
2

continue proving RSAT(R14
5 ) tractable problem. Let
9
R5 = ffPP; EQgg [ fR [ fPP; PPIg j R 2 R5g:
9
Using machine-assisted proof, shown R14
5 = R5 sucient prove
9
tractability RSAT(R5) Corollary 2.4. program used showing available
on-line appendix article.
on, let arbitrary instance RSAT(R95) G = hV; E graph representation. following proofs similar spirit proofs appearing Drakengren
215

fiJonsson & Drakengren

1
2
3
4
5
6
7
8
9
10
11
12

algorithm A20
Input: instance RSAT(R20
5 ).
repeat
0
9X; R : XRX 2 EQ 62 R reject
9X; : X ?Y 2 reject
9X; : X =6 X fEQgY 2 substitute X
9X; Y; R; : XRY 2 XSY 2
( , fXRY; XSY g) [ fX (R \ )Y g
9X; R : XRX 2 EQ 2 R , fXRX g
= 0
accept

1
2
3
4

algorithm A17
Input: instance RSAT(R17
5 ).
9X; X ?Y 2 reject
else accept

1
2
3
4
5
6
7

algorithm A9
Input: instance RSAT(R95) graph representation G.
Let G0 graph obtained G removing arcs labelled fPP; EQg.
Find strongly connected components C G0
every arc e G whose relation contain EQ
e connects two nodes C reject
accept
17
9
Figure 2: Algorithms RSAT(R20
5 ), RSAT(R5 ) RSAT(R5).

Jonsson (1996). algorithm reminiscent algorithm van Beek (1992) deciding
satisfiability point algebra.
Definition 3.5 RCC-5 relation R said acyclic relation iff cycle G R
every arc never satisfiable.
relation PP example acyclic relation fPP; EQg acyclic. continue
showing properties acyclic relations.
Proposition 3.6 Let R acyclic relation. every relation R0 R acyclic.
Proof: Since taking subsets R constrains satisfiability further, result follows.
2
Proposition 3.7 Let R acyclic relation, choose fR0 j R0 Rg. Then,
cycle G every arc labelled relation unsatisfiable.
Proof: argument previous proposition.
2
following definition needed following proofs.
Definition 3.8 Let instance R-satisfiability problem, model , r 2 R5
relation two region variables X . r said satisfied r0
relation r0 r, Xr0 satisfied .
216

fiA Complete Classification Tractability RCC-5

definition may seem bit cumbersome essence clear. example, let X
region variables related X fPO; PPgY , model X interpreted f1; 2g
f1; 2; 3g. , fPO; PPg satisfied fPPg, also fPO; PPg.
Lemma 3.9 Let R acyclic relation, A; A0 sets fR0 j R0 Rg A0
fa [ fEQg j 2 Ag. Then, every cycle C labelled relations [ A0 satisfiable iff contains
relations A0 . Furthermore, relations cycle satisfied EQ.
Proof: only-if: Suppose cycle C satisfiable contains relation
A. Apply induction number n arcs cycle. n = 1, get contradiction
Proposition 3.7. So, suppose induction C contains n + 1 arcs. Let R-model
relations C . cannot case every relation C satisfied
relation A, Proposition 3.7. Thus, relation R0 C satisfied EQ.
collapse two variables connected R0 one variable, cycle n nodes
containing relation A. contradicts induction hypothesis.
if: Suppose cycle C contains relations A0 . C satisfied choosing EQ
every arc. Notice only-if part implies C must satisfied choosing EQ every arc.

2

Hence, variables forced equal.

studied acyclic relations, turn attention DAG-satisfying relations.
formal definition follows.
Definition 3.10 basic relation B said DAG-satisfying iff DAG (directed acyclic
graph) labelled relations containing B satisfiable, i.e., corresponding RSAT problem
model.
typical example DAG-satisfying relation EQ. Given DAG labelled relations containing EQ, always satisfy relations assigning non-empty set variables.
show PP DAG-satisfying relation.
Definition 3.11 Let G arbitrary DAG. node v G said terminal node iff
arcs start v.
Lemma 3.12 basic relation PP DAG-satisfying.
Proof: Let G DAG labelled relations containing PP. show G satisfied
R-model . Induction n number nodes G. case n = 1
trivial. Suppose G n +1 nodes remove terminal node g. induction, remaining
graph G0 = hV 0 ; E 0i satisfiable model 0.SWe shall construct model G,
agrees 0 every variable G0. Let = fM 0(v) j v 2 V 0 g let ff element
. Let (g) = [ fffg. Obviously, model G.
2
state simple result Drakengren Jonsson (1996).
Lemma 3.13 Let G irre exive1 acyclic subgraph D. arcs G
reoriented resulting graph acyclic.
specializing result, get next lemma.
Lemma 3.14 Let G irre exive acyclic subgraph let arcs labelled
relations containing PP, arcs labelled relations containing PP PPI.
G R-satisfiable.
1. graph irre exive iff arcs node v node v.

217

fiJonsson & Drakengren

Proof: Reorient arcs G resulting graph acyclic. always possible
previous lemma. Furthermore, whenever arc reoriented, also invert relation
arc, G0 satisfiable iff G is. construction, arcs containing PP PPI
reoriented, every arc DAG G0 contains PP and, thus, since PP DAG-satisfying
Lemma 3.12, G0 satisfiable. Consequently, G also satisfiable.
2
Lemma 3.15 Algorithm A9 correctly solves RSAT(R95).
Proof: Assume algorithm finds strongly connected component G0 (which contains
relation fPP; EQg), containing two nodes G connected arc e labelled
relation R0 contain EQ. exists cycle C relation
every arc contains EQ, e connects two nodes C e part cycle.
Lemma 3.9, C satisfied choosing relation EQ every arc C , since R0

admit EQ, C unsatisfiable.
Otherwise, every strongly connected component collapsed single node, removing
arcs start end collapsed node. transformation retains satisfiability using
argument above. collapsing, subgraph obtained considering arcs labelled
fPP; EQg acyclic. Since remaining arcs labelled relations containing PP
PPI, graph R-satisfiable Lemma 3.14. (Note graph irre exive since every
node contained strongly connected component.)
2
Lemma 3.16 Given graph G = hV; Ei, algorithm A9 runs O(jV j + jEj) time.
Proof: Strongly connected components found O(jV j + jEj) time (Baase, 1988)
remaining test also made O(jV j + jE j) time.
2
Theorem 3.17 RSAT(R14
5 ) solved polynomial time.
14
9
Proof: RSAT(R95) polynomial previous two lemmata. Since R14
5 = R5, RSAT(R5 )
solved polynomial time Corollary 2.4.
2

4. Classification RCC-5

give classification RCC-5 need two NP-completeness results.
Theorem 4.1 RSAT(S ) NP-complete
1. (Renz & Nebel, 1997) C1 = ffPOg; fPP; PPIgg ,
2. C2 = ffDR; POg; fPP; PPIgg .
Proof: proof C2 polynomial-time reduction RSAT(C1). Let arbitrary
instance RSAT(C1). Construct following set:
0 = fX fPP; PPIgY j X fPP; PPIgY 2 g [ fX fDR; POgY j X fPOgY 2 g:
Clearly, 0 obtained polynomial time 0 instance RSAT(C2). show
satisfiable iff 0 satisfiable.
only-if: Assume exists R-model . hard see also R-model

0 since X fPOgY X fDR; POgY . Thus 0 R-satisfiable R-satisfiable.

if: Assume existence R-model 0 assigns subsets set U region variables

0 . Let ff element ff 62 U . construct new interpretation follows:
(x) = 0 (x) [ fffg every variable x 0 . easily seen following holds :
218

fiA Complete Classification Tractability RCC-5

1.
2.
3.
4.

xfDRgy 0 xfPOgy .
xfPOgy 0 xfPOgy .
xfPPgy 0 xfPPgy .
xfPPIgy 0 xfPPIgy .

easy see xfPP; PPIgy 0 xfPP; PPIgy . Similarly, xfDR; POgy
0 xfPOgy . follows model R-satisfiable 0 R-satisfiable.
2
main theorem stated proved.

Theorem 4.2 R5, RSAT(S ) polynomial iff subset member R =
20 17 14
fR28
5 ; R5 ; R5 ; R5 g, NP-complete otherwise.
Proof: if: R 2 R , RSAT(R) polynomial shown previous section.
only-if: Choose R5 subset algebra R . subalgebra
R 2 R , choose relation x x 2 x 62 R. always done since 6 R. Let
X set relations note X subset algebra R . set R
contains four algebras construction X , jX j 4. Observe RSAT(S ) NP-complete
RSAT(X ) NP-complete.
show RSAT(S ) NP-complete, machine-assisted case analysis following
P

P

P

P

P

P

form performed:


4
X
32
1. Generate subsets R5 size 4.
= 41449 subsets.
=0


2. Let set. Test: subset subalgebra R C
2 f1; 2g.
P

test succeeds . Hence, RSAT(S ) NP-complete Corollary 2.4.



2

program used showing previous theorem appears on-line appendix article.

5. Discussion

main problem reporting tractability results restricted classes problems diculty
isolating interesting relevant subclasses. systematic approach building complete classifications way partially overcoming problem. problem class consideration
regarded relevant, tractable subclasses regarded relevant computational
problem interest. especially true spatial reasoning size problem instances extremely large; one good example spatial reasoning connection Human
Genome project (Cui, 1994).
Another advantage complete classifications satisfactory scientific
point view; gain clear picture borderline tractability intractability
intrinsic scientific value. common critique complete classifications tend generate
certain classes totally useless. instance, subalgebra R17
5 certainly use.
must made clear critique unjustified since researcher makes complete
classification deliberately invent useless classes. Instead, useless classes appear
complete classification, unavoidable parts classification.
219

fiJonsson & Drakengren

work reported article extended many different ways. One obvious extension
study computational problems RSAT problem. Renz (1996) studied two
problems, RMIN RENT, certain subclasses RCC-5 RCC-8. RMIN problem
decide set spatial formulae minimal, i.e., whether basic relations every formula
satisfied not. RENT problem decide whether formula XRY entailed
set spatial formulae. Grigni et al. (1995) study stronger form satisfiability refer
realizability: finite set RCC-5 formulae said realizable iff exist regions
plane bounded Jordan curves satisfy relations . Grigni et al. (1995)
shown realizability problem much harder satisfiability problem. instance,
deciding realizability formulae constructed two relations DR PO NP-complete
satisfiability problem polynomial. Certainly, studies realizability problem would
worthwhile.
Another obvious research direction completely classify spatial algebras, RCC8. RCC-8 contains 2256 1077 relations question whether feasible remains
answered.

6. Conclusions

studied computational properties RCC-5. 232 possible subclasses classified respect whether corresponding satisfiability problem tractable not.
classification reveals four maximal tractable subclasses algebra.

References

Baase, S. (1988). Computer Algorithms: Introduction Analysis (2nd edition). Addison Wesley,
Reading, MA.
Bennett, B. (1994). Spatial reasoning propositional logics. Doyle, J., Sandewall, E., &
Torasso, P. (Eds.), Proceedings 4th International Conference Principles Knowledge
Representation Reasoning (KR-94), pp. 165{176 Bonn, Germany. Morgan Kaufmann.
Cook, S. A. (1971). complexity theorem-proving procedures. Proceedings 3rd ACM
Symposium Theory Computing, pp. 151{158.
Cui, Z. (1994). Using interval logic order assembly. Proceedings Second International
Conference Intelligent Systems Molecular Biology, pp. 103{111. AAAI Press.
Drakengren, T., & Jonsson, P. (1996). Maximal tractable subclasses Allen's interval algebra: Preliminary report. Proceedings 13th (US) National Conference Artificial Intelligence
(AAAI-96), pp. 389{394 Portland, OR, USA. American Association Artificial Intelligence.
Egenhofer, M. J. (1991). Reasoning binary topological relations. Gunther, O., & Schek,
H. J. (Eds.), Advances Spatial Databases, pp. 143{160. Springer-Verlag.
Grigni, M., Papadias, D., & Papadimitriou, C. (1995). Topological inference. Mellish, C. (Ed.),
Proceedings 14th International Joint Conference Artificial Intelligence (IJCAI-95),
pp. 901{906 Montreal, PQ, Canada. Morgan Kaufmann.
Mallios, A. (1986). Topological Algebras. Selected Topics. North-Holland, Amsterdam.
Nebel, B. (1995). Computational properties qualitative spatial reasoning: First results.
Wachsmuth, I., Rollinger, C.-R., & Brauer, W. (Eds.), KI-95: Advances Artificial Intelligence, pp. 233{244 Bielefeld, Germany. Springer-Verlag.
220

fiA Complete Classification Tractability RCC-5

Nebel, B., & Burckert, H.-J. (1995). Reasoning temporal relations: maximal tractable
subclass Allen's interval algebra. Journal ACM, 42 (1), 43{66.
Randell, D. A., & Cohn, A. G. (1989). Modelling topological metrical properties physical
processes. Brachman, R. J., Levesque, H. J., & Reiter, R. (Eds.), Proceedings 1st
International Conference Principles Knowledge Representation Reasoning (KR-89),
pp. 55{66 Toronto, ON, Canada. Morgan Kaufmann.
Randell, D. A., Cui, Z., & Cohn, A. G. (1992). spatial logic based regions connection.
Swartout, B., & Nebel, B. (Eds.), Proceedings 3rd International Conference Principles
Knowledge Representation Reasoning (KR-92), pp. 165{176 Cambridge, MA, USA.
Morgan Kaufmann.
Renz, J. (1996). Qualitatives raumliches Schlieen: Berechnungseigenschaften und eziente Algorithmen. Master thesis report, Fakultat fur Informatik, Universitat Ulm. Available
http://www.informatik.uni-freiburg.de/sppraum.
Renz, J., & Nebel, B. (1997). complexity qualitative spatial reasoning: maximal
tractable fragment region connected calculus. Proceedings 15th International
Joint Conference Artificial Intelligence (IJCAI-97) Nagoya, Japan. Morgan Kaufmann.
appear.
Statman, R. (1979). Intuitionistic logic polynomial-space complete. Theoretical Computer Science,
9 (1), 67{72.
van Beek, P. (1992). Reasoning qualitative temporal information. Artificial Intelligence, 58,
297{326.

221

fiJournal Artificial Intelligence Research 6 (1997) 1-34

Submitted 5/96; published 1/97

Improved Heterogeneous Distance Functions
D. Randall Wilson
Tony R. Martinez
Computer Science Department
Brigham Young University
Provo, UT 84602, USA

RANDY @AXON.CS.BYU.EDU
MARTINEZ @CS.BYU.EDU

Abstract
Instance-based learning techniques typically handle continuous linear input values well,
often handle nominal input attributes appropriately. Value Difference Metric
(VDM) designed find reasonable distance values nominal attribute values,
largely ignores continuous attributes, requiring discretization map continuous values
nominal values. paper proposes three new heterogeneous distance functions, called
Heterogeneous Value Difference Metric (HVDM), Interpolated Value Difference Metric
(IVDM), Windowed Value Difference Metric (WVDM). new distance functions
designed handle applications nominal attributes, continuous attributes, both.
experiments 48 applications new distance metrics achieve higher classification accuracy
average three previous distance functions datasets nominal
continuous attributes.

1. Introduction
Instance-Based Learning (IBL) (Aha, Kibler & Albert, 1991; Aha, 1992; Wilson & Martinez,
1993; Wettschereck, Aha & Mohri, 1995; Domingos, 1995) paradigm learning
algorithms typically store n available training examples (instances)
training set, T, learning. instance input vector x, output class c.
generalization, systems use distance function determine close new
input vector stored instance, use nearest instance instances predict
output class (i.e., classify y). instance-based learning algorithms referred
nearest neighbor techniques (Cover & Hart, 1967; Hart, 1968; Dasarathy, 1991), memorybased reasoning methods (Stanfill & Waltz, 1986; Cost & Salzberg, 1993; Rachlin et al., 1994)
overlap significantly instance-based paradigm well. algorithms much
success wide variety applications (real-world classification tasks).
Many neural network models also make use distance functions, including radial basis
function networks (Broomhead & Lowe, 1988; Renals & Rohwer, 1989; Wasserman, 1993),
counterpropagation networks (Hecht-Nielsen, 1987), ART (Carpenter & Grossberg, 1987), selforganizing maps (Kohonen, 1990) competitive learning (Rumelhart & McClelland, 1986).
Distance functions also used many fields besides machine learning neural networks,
including statistics (Atkeson, Moore & Schaal, 1996), pattern recognition (Diday, 1974;
Michalski, Stepp & Diday, 1981), cognitive psychology (Tversky, 1977; Nosofsky, 1986).
1997 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiWILSON & MARTINEZ

many distance functions proposed decide instance
closest given input vector (Michalski, Stepp & Diday, 1981; Diday, 1974). Many
metrics work well numerical attributes appropriately handle nominal (i.e.,
discrete, perhaps unordered) attributes.
Value Difference Metric (VDM) (Stanfill & Waltz, 1986) introduced define
appropriate distance function nominal (also called symbolic) attributes. Modified Value
Difference Metric (MVDM) uses different weighting scheme VDM used
PEBLS system (Cost & Salzberg, 1993; Rachlin et al., 1994). distance metrics work well
many nominal domains, handle continuous attributes directly. Instead,
rely upon discretization (Lebowitz, 1985; Schlimmer, 1987), degrade generalization
accuracy (Ventura & Martinez, 1995).
Many real-world applications nominal linear attributes, including,
example, half datasets UCI Machine Learning Database Repository (Merz &
Murphy, 1996). paper introduces three new distance functions appropriate
previous functions applications nominal continuous attributes.
new distance functions incorporated many learning systems areas
study, augmented weighting schemes (Wettschereck, Aha & Mohri, 1995;
Atkeson, Moore & Schaal, 1996) enhancements system provides.
choice distance function influences bias learning algorithm. bias rule
method causes algorithm choose one generalized output another (Mitchell,
1980). learning algorithm must bias order generalize, shown
learning algorithm generalize accurately summed
possible problems (Schaffer, 1994) (unless information problem
training data available). follows distance function strictly better
terms generalization ability, considering possible problems equal
probability.
However, higher probability one class problems occurring another,
learning algorithms generalize accurately others (Wolpert, 1993).
better summed problems, problems
perform well likely occur. sense, one algorithm distance function
improvement another higher probability good generalization
another, better matched kinds problems likely occur.
Many learning algorithms use bias simplicity (Mitchell, 1980; Wolpert, 1993)
generalize, bias appropriatemeaning leads good generalization
accuracyfor wide variety real-world applications, though meaning simplicity varies
depending upon representational language learning algorithm. biases,
decisions made basis additional domain knowledge particular problem (Mitchell,
1980), also improve generalization.
light, distance functions presented paper appropriate
used comparison average yield improved generalization accuracy
collection 48 applications. results theoretically limited set datasets,
hope datasets representative problems interest (and occur
frequently) real world, distance functions presented useful
cases, especially involving continuous nominal input attributes.
Section 2 provides background information distance functions used previously. Section 3
2

fiIMPROVED HETEROGENEOUS DISTANCE FUNCTIONS

introduces distance function combines Euclidean distance VDM handle
continuous nominal attributes. Sections 4 5 present two extensions Value
Difference Metric allow direct use continuous attributes. Section 4 introduces
Interpolated Value Difference Metric (IVDM), uses interpolation probabilities avoid
problems related discretization. Section 5 presents Windowed Value Difference Metric
(WVDM), uses detailed probability density function similar interpolation
process.
Section 6 presents empirical results comparing three commonly-used distance functions
three new functions presented paper. results obtained using
distance functions instance-based learning system 48 datasets. results indicate
new heterogeneous distance functions appropriate previously used functions
datasets nominal linear attributes, achieve higher average
generalization accuracy datasets. Section 7 discusses related work, Section 8
provides conclusions future research directions.

2. Previous Distance Functions
mentioned introduction, many learning systems depend upon good
distance function successful. variety distance functions available uses,
including Minkowsky (Batchelor, 1978), Mahalanobis (Nadler & Smith, 1993), Camberra,
Chebychev, Quadratic, Correlation, Chi-square distance metrics (Michalski, Stepp &
Diday, 1981; Diday, 1974); Context-Similarity measure (Biberman, 1994); Contrast
Model (Tversky, 1977); hyperrectangle distance functions (Salzberg, 1991; Domingos, 1995)
others. Several functions defined Figure 1.
Although many distance functions proposed, far commonly
used Euclidean Distance function, defined as:


E(x, y) =

(xa ya )2

(1)

a=1

x two input vectors (one typically stored instance,
input vector classified) number input variables (attributes)
application. square root often computed practice, closest instance(s)
still closest, regardless whether square root taken.
alternative function, city-block Manhattan distance function, requires less
computation defined as:
M(x, y) =



xa ya

(2)

a=1

Euclidean Manhattan distance functions equivalent Minkowskian rdistance function (Batchelor, 1978) r = 2 1, respectively.

3

fiWILSON & MARTINEZ

Minkowsky:

Euclidean:


r
D(x, y) = xi yi
i=1

Camberra:

1

r

Manhattan / city-block:



2
( xi yi )

D(x, y) =

i=1

x

D(x, y) =
x
+


i=1

Chebychev:



D(x, y) = xi yi
i=1



D(x, y) = max xi yi
i=1



D(x, y) = (x y)T Q(x y) = (xi yi )q ji (x j j )
Quadratic:

Q problem-specific positive
j=1 i=1
definite weight matrix
V covariance matrix 1..Am,
Mahalanobis:
Aj vector values
D(x, y) = [det V]1/ (x y)T V 1 (x y)
attribute j occuring training set
instances 1..n.

Correlation:
(xi xi )(yi yi )
xi = yi average value
i=1
D(x, y) =
attribute
occuring training set.


2
2
(xi xi ) (yi yi )
i=1

i=1


1 xi
Chi-square: D(x, y) =


sumi sizex size
i=1


Kendalls Rank Correlation:
sign(x)=-1, 0 1 x < 0,
x = 0, x > 0, respectively.

D(x, y) = 1

2

sumi sum values attribute
occuring training set, sizex
sum values vector x.

i1
2

sign(xi x j )sign(yi j )
n(n 1) i=1 j=1

Figure 1. Equations selected distance functions.
(x vectors attribute values).
2.1. Normalization
One weakness basic Euclidean distance function one input attributes
relatively large range, overpower attributes. example, application
two attributes, B, values 1 1000, B values
1 10, Bs influence distance function usually overpowered
influence. Therefore, distances often normalized dividing distance attribute
range (i.e., maximum-minimum) attribute, distance attribute
approximate range 0..1. order avoid outliers, also common divide
standard deviation instead range, trim range removing highest lowest
percent (e.g., 5%) data consideration defining range. also possible
map value outside range minimum maximum value avoid normalized
values outside range 0..1. Domain knowledge often used decide method
appropriate.
Related idea normalization using attribute weights weighting
4

fiIMPROVED HETEROGENEOUS DISTANCE FUNCTIONS

schemes. Many learning systems use distance functions incorporate various weighting
schemes distance calculations (Wettschereck, Aha & Mohri, 1995; Atkeson, Moore &
Schaal, 1996). improvements presented paper independent schemes,
various weighting schemes (as well enhancements instance pruning
techniques) used conjunction new distance functions presented here.
2.2. Attribute Types
None distance functions shown Figure 1, including Euclidean distance, appropriately
handle non-continuous input attributes.
attribute linear nominal, linear attribute continuous discrete.
continuous (or continuously-valued) attribute uses real values, mass planet
velocity object. linear discrete (or integer) attribute discrete set
linear values, number children.
argued value stored computer discrete level. reason
continuous attributes treated differently many different values
value may appear rarely (perhaps particular application). causes
problems algorithms VDM (described Section 2.4) depend testing two
values equality, two continuous values rarely equal, though may
quite close other.
nominal (or symbolic) attribute discrete attribute whose values necessarily
linear order. example, variable representing color might values red,
green, blue, brown, black white, could represented integers 1 6,
respectively. Using linear distance measurement (1) (2) values makes little
sense case.
2.3. Heterogeneous Euclidean-Overlap Metric (HEOM)
One way handle applications continuous nominal attributes use
heterogeneous distance function uses different attribute distance functions different
kinds attributes. One approach used use overlap metric nominal
attributes normalized Euclidean distance linear attributes.
purposes comparison testing, define heterogeneous distance function
similar used IB1, IB2 IB3 (Aha, Kibler & Albert, 1991; Aha, 1992) well
used Giraud-Carrier & Martinez (1995). function defines distance
two values x given attribute as:
x unknown, else
1,

da (x, y) = overlap(x, y), nominal, else
rn_ diff (x, y)



(3)

Unknown attribute values handled returning attribute distance 1 (i.e., maximal
distance) either attribute values unknown. function overlap rangenormalized difference rn_diff defined as:
0, x =
overlap(x, y) =
1, otherwise

5

(4)

fiWILSON & MARTINEZ

rn_ diff (x, y) =

| x y|
rangea

(5)

value rangea used normalize attributes, defined as:
rangea= maxa- mina

(6)

max mina maximum minimum values, respectively, observed
training set attribute a. means possible new input vector value
outside range produce difference value greater one. However, cases
rare, occur, large difference may acceptable anyway. normalization
serves scale attribute point differences almost always less one.
definition da returns value (typically) range 0..1, whether
attribute nominal linear. overall distance two (possibly heterogeneous) input
vectors x given Heterogeneous Euclidean-Overlap Metric function HEOM(x,y):


da (xa , ya )2

HEOM(x, y) =

(7)

a=1

distance function removes effects arbitrary ordering nominal values,
overly simplistic approach handling nominal attributes fails make use additional
information provided nominal attribute values aid generalization.
2.4. Value Difference Metric (VDM)
Value Difference Metric (VDM) introduced Stanfill Waltz (1986) provide
appropriate distance function nominal attributes. simplified version VDM (without
weighting schemes) defines distance two values x attribute as:
C Na,x,c

Na,y,c
vdma (x, y) =

N
Na,y
a,x
c=1

q

C

= Pa,x,c Pa,y,c

q

(8)

c=1


Na,x number instances training set value x attribute a;
Na,x,c number instances value x attribute output class c;
C number output classes problem domain;
q constant, usually 1 2;
P a,x,c conditional probability output class c given attribute
value x, i.e., P(c | xa). seen (8), Pa,x,c defined as:
Pa,x,c =

Na,x,c
Na,x

(9)

Na,x sum Na,x,c classes, i.e.,
C

Na,x = Na,x,c
c=1

6

(10)

fiIMPROVED HETEROGENEOUS DISTANCE FUNCTIONS

sum Pa,x,c C classes 1 fixed value x.
Using distance measure vdma(x,y), two values considered closer
similar classifications (i.e., similar correlations output classes), regardless
order values may given in. fact, linear discrete attributes values
remapped randomly without changing resultant distance measurements.
example, attribute color three values red, green blue, application
identify whether object apple, red green would considered closer
red blue former two similar correlations output class apple.
original VDM algorithm (Stanfill & Waltz, 1986) makes use feature weights
included equations, variants VDM (Cost & Salzberg, 1993;
Rachlin et al., 1994; Domingos, 1995) used alternate weighting schemes. discussed
earlier, new distance functions presented paper independent schemes
cases make use similar enhancements.
One problem formulas presented define
done value appears new input vector never appeared training set.
attribute never value x instance training set, Na,x,c c 0,
N a,x (which sum Na,x,c classes) also 0. cases P a,x,c = 0/0,
undefined. nominal attributes, way know probability
value, since inherent ordering values. paper assign
P a,x,c default value 0 cases (though also possible let Pa,x,c = 1/C, C
number output classes, since sum Pa,x,c c = 1..C always 1.0).
distance function used directly continuous attributes, values
potentially unique, case Na,x 1 every value x, Na,x,c 1 one value c
0 others given value x. addition, new vectors likely unique
values, resulting division zero problem above. Even value 0 substituted
0/0, resulting distance measurement nearly useless.
Even values unique, often enough different values continuous
attribute statistical sample unreliably small value, distance measure
still untrustworthy. problems, inappropriate use VDM directly
continuous attributes.
2.5. Discretization
One approach problem using VDM continuous attributes discretization
(Lebowitz, 1985; Schlimmer, 1987; Ventura, 1995). models used VDM
variants (Cost & Salzberg, 1993; Rachlin et al., 1994; Mohri & Tanaka, 1994)
discretized continuous attributes somewhat arbitrary number discrete ranges,
treated values nominal (discrete unordered) values. method advantage
generating large enough statistical sample nominal value P values
significance. However, discretization lose much important information available
continuous values. example, two values discretized range considered
equal even opposite ends range. effects reduce generalization
accuracy (Ventura & Martinez, 1995).
paper propose three new alternatives, presented following three
sections. Section 3 presents heterogeneous distance function uses Euclidean distance
linear attributes VDM nominal attributes. method requires careful attention
7

fiWILSON & MARTINEZ

problem normalization neither nominal linear attributes regularly given
much weight.
Sections 4 5 present two distance functions, Interpolated Value Difference
Metric (IVDM) Windowed Value Difference Metric (WVDM), use discretization
collect statistics determine values Pa,x,c continuous values occurring training
set instances, retain continuous values later use. generalization,
value Pa,y,c continuous value interpolated two values P, namely,
P a,x1,c Pa,x2,c, x 1 x2. IVDM WVDM essentially different techniques
nonparametric probability density estimation (Tapia & Thompson, 1978)
determine values P class. generic version VDM algorithm, called
discretized value difference metric (DVDM) used comparisons two new
algorithms.

3. Heterogeneous Value Difference Metric (HVDM)
discussed previous section, Euclidean distance function inappropriate
nominal attributes, VDM inappropriate continuous attributes, neither sufficient
use heterogeneous application, i.e., one nominal continuous
attributes.
section, define heterogeneous distance function HVDM returns distance
two input vectors x y. defined follows:
HVDM(x, y) =



da2 (xa , ya )

(11)

a=1

number attributes. function da(x,y) returns distance two
values x attribute defined as:
x unknown; otherwise...
1,

da (x, y) = normalized_ vdma (x, y), nominal
normalized_ diff (x, y), linear



(12)

function da(x,y) uses one two functions (defined Section 3.1), depending
whether attribute nominal linear. Note practice square root (11)
typically performed distance always positive, nearest neighbor(s) still
nearest whether distance squared. However, models (e.g.,
distance-weighted k-nearest neighbor, Dudani, 1976) require square root
evaluated.
Many applications contain unknown input values must handled appropriately
practical system (Quinlan, 1989). function da(x,y) therefore returns distance 1 either
x unknown, done Aha, Kibler & Albert (1991) Giraud-Carrier & Martinez
(1995). complicated methods tried (Wilson & Martinez, 1993),
little effect accuracy.
function HVDM similar function HOEM given Section 2.3, except
8

fiIMPROVED HETEROGENEOUS DISTANCE FUNCTIONS

uses VDM instead overlap metric nominal values also normalizes differently.
also similar distance function used RISE 2.0 (Domingos, 1995),
important differences noted Section 3.2.
Section 3.1 presents three alternatives normalizing nominal linear attributes.
Section 3.2 presents experimental results show one schemes provides better
normalization two set several datasets. Section 3.3 gives empirical results
comparing HVDM two commonly-used distance functions.
3.1. Normalization
discussed Section 2.1, distances often normalized dividing distance
variable range attribute, distance input variable range
0..1. policy used HEOM Section 2.3. However, dividing range allows
outliers (extreme values) profound effect contribution attribute.
example, variable values range 0..10 almost every case one
exceptional (and possibly erroneous) value 50, dividing range would almost
always result value less 0.2. robust alternative presence outliers
divide values standard deviation reduce effect extreme values typical
cases.
new heterogeneous distance metric HVDM, situation complicated
nominal numeric distance values come different types measurements:
numeric distances computed difference two linear values, normalized
standard deviation, nominal attributes computed sum C differences
probability values (where C number output classes). therefore necessary find
way scale two different kinds measurements approximately range
give variable similar influence overall distance measurement.
Since 95% values normal distribution fall within two standard deviations
mean, difference numeric values divided 4 standard deviations scale
value range usually width 1. function normalized_diff therefore defined
shown Equation 13:
normalized_ diff (x, y) =

xy
4

(13)

standard deviation numeric values attribute a.
Three alternatives function normalized_vdm considered use
heterogeneous distance function. labeled N1, N2 N3, definitions
given below:
N1: normalized_ vdm1a (x, y) =

C N
a,x,c



c=1

N2: normalized_ vdm2 (x, y) =

C N
a,x,c



c=1

9

Na,x

Na,x



Na,y,c



Na,y,c

(14)

Na,y

Na,y

2

(15)

fiWILSON & MARTINEZ

C N
a,x,c

N3: normalized_ vdm3a (x, y) = C *

c=1

Na,x



Na,y,c

2

(16)

Na,y

function N1 Equation (8) q=1. similar formula used PEBLS
(Rachlin et al., 1994) RISE (Domingos, 1995) nominal attributes.
N2 uses q=2, thus squaring individual differences. analogous using Euclidean
distance instead Manhattan distance. Though slightly expensive computationally,
formula hypothesized robust N1 favors class
correlations fairly similar rather close different. N1
would able distinguish two. practice square root taken,
individual attribute distances squared HVDM function.
N3 function used Heterogeneous Radial Basis Function Networks (Wilson &
Martinez, 1996), HVDM first introduced.
3.2. Normalization Experiments
order determine whether normalization scheme N1, N2 N3 gave unfair weight
either nominal linear attributes, experiments run 15 databases machine
learning database repository University California, Irvine (Merz & Murphy, 1996).
datasets experiment least nominal linear attributes,
thus require heterogeneous distance function.
experiment, five-fold cross validation used. five trials,
distance instance test set instance training set
computed. computing distance attribute, normalized_diff function
used linear attributes, normalized_vdm function N1, N2, N3 used (in
three respective experiments) nominal attributes.
average distance (i.e., sum distances divided number comparisons)
computed attribute. average linear attributes database
computed averages listed heading avgLin Table 1.

Database
Anneal
Australian
Bridges
Crx
Echocardiogram
Flag
Heart
Heart.Cleveland
Heart.Hungarian
Heart.Long-Beach-VA
Heart.More
Heart.Swiss
Hepatitis
Horse-Colic
Soybean-Large
Average

avgLin
0.427
0.215
0.328
0.141
0.113
0.188
0.268
0.271
0.382
0.507
0.360
0.263
0.271
0.444
0.309
0.299

N1
avgNom
0.849
0.266
0.579
0.268
0.487
0.372
0.323
0.345
0.417
0.386
0.440
0.390
0.205
0.407
0.601
0.422

N2
avgNom
0.841
0.188
0.324
0.193
0.344
0.195
0.228
0.195
0.347
0.324
0.340
0.329
0.158
0.386
0.301
0.313

N3
avgNom
0.859
0.266
0.808
0.268
0.487
0.552
0.323
0.434
0.557
0.417
0.503
0.421
0.205
0.407
0.872
0.492

#Nom.
29
8
7
9
2
18
6
6
6
6
6
6
13
16
29
11

#Lin.
9
6
4
6
7
10
7
7
7
7
7
7
6
7
6
7

Table 1. Average attribute distance linear nominal attributes.
10

#C
6
2
7
2
2
8
2
5
5
5
5
5
2
2
19
5

fiIMPROVED HETEROGENEOUS DISTANCE FUNCTIONS

Average distance

Average distance

Average distance

averages nominal attributes three normalization schemes
listed headings avgNom Table 1 well. average distance linear
variables exactly regardless whether N1, N2 N3 used, average
given once. Table 1 also lists number nominal (#Nom.) number linear
(#Lin.) attributes database, along number output classes (#C).
seen overall averages first four columns last row
Table 1, N2 closer N1 N3. However, important understand reasons behind
difference order know normalization scheme N2 robust general.
Figures 2-4 graphically display averages shown Table 1 headings N1, N2
N3, respectively, ordered left right number output classes.
hypothesized number output classes grows, normalization would get worse
N3 indeed appropriate add scaling factor C sum. length
line indicates much difference
average distance nominal attributes
Nominal
1
linear attributes. ideal normalization scheme
Linear
would difference zero, longer lines
.8
indicate worse normalization.
.6
number output classes grows,
.4
difference N3 linear distances
.2
nominal distances grows wider cases.
N2, hand, seems remain quite close
0
2 2 2 2 2 2 5 5 5 5 5 6 7 8 19 Avg
independent number output classes.
Number output classes
Interestingly, N1 almost poorly N3, even
Figure 2. Average distances N1.
though use scaling factor C.
Apparently squaring factor provides
Nominal
1
well-rounded distance metric nominal attributes
Linear
similar provided using Euclidean distance
.8
instead Manhattan distance linear attributes.
.6
underlying hypothesis behind performing
.4
normalization proper normalization
.2
typically improve generalization accuracy.
nearest neighbor classifier (with k =1)
0
2 2 2 2 2 2 5 5 5 5 5 6 7 8 19 Avg
implemented using HVDM distance metric.
Number output classes
system tested heterogeneous
Figure 3. Average distances N2.
datasets appearing Table 1 using three
different normalization schemes discussed above,
1
Nominal
using ten-fold cross-validation (Schaffer, 1993),
Linear
results summarized Table 2.
.8
normalization schemes used training sets
.6
test sets trial. Bold entries indicate
.4
scheme highest accuracy.
.2
asterisk indicates difference greater
1% next highest scheme.
0
2 2 2 2 2 2 5 5 5 5 5 6 7 8 19 Avg
seen table, normalization
Number output classes
scheme N2 highest accuracy, N1
Figure 4. Average distances N3.
11

fiWILSON & MARTINEZ

substantially lower two. N2
Database
N1
N2
N3
N3 highest accuracy
Anneal
93.98
94.61 94.99
8 domains. significantly, N2
Australian
71.30
81.45 81.59
Bridges
43.36
59.64 59.55
1% higher 5 times compared N1
Crx
70.29
80.87 81.01
1% higher one dataset.
Echocardiogram
70.36
94.82 94.82
N3 higher two
Flag
28.95
55.82* 51.50
Heart.Cleveland
73.88
76.56* 71.61
one dataset, lower average
Heart.Hungarian
70.75
76.85* 75.82
accuracy N2.
Heart.Long-Beach-Va
65.50
65.50 70.00*
results support hypothesis
Heart.More
60.03
72.09 72.48
Heart
88.46
89.49 89.49
normalization scheme N2
Heart.Swiss
74.81
78.52* 75.19
achieves higher generalization accuracy
Hepatitis
73.50
76.67 77.33
N1 N3 (on datasets) due
Horse-Colic
64.75* 60.53 60.53
Soybean-Large
41.45
90.88* 87.89
robust normalization though
Average
66.09
76.95 76.25
accuracy N3 almost good N2.
Note proper normalization
Table 2. Generalization accuracy
using N1, N2 N3.
always necessarily improve generalization
accuracy. one attribute
important others classification, giving higher weight may improve
classification. Therefore, important attribute given higher weight accidentally
poor normalization, may actually improve generalization accuracy. However,
random improvement typically case. Proper normalization improve
generalization cases used typical applications.
consequence results, N2 used normalization scheme HVDM,
function normalized_vdm defined (15).
3.3. Empirical Results HVDM vs. Euclidean HOEM
nearest neighbor classifier (with k=1) using three distance functions listed Table 3
tested 48 datasets UCI machine learning database repository. 48 datasets,
results obtained 35 datasets least nominal attributes shown
Table 3.
results approximately equivalent datasets linear attributes, results
remaining datasets shown here, found Section 6. 10-fold crossvalidation used, three distance metrics used training sets test sets
trial.
results experiments shown Table 3. first column lists name
database (.test means database originally meant used test set,
instead used entirety separate database). second column shows results
obtained using Euclidean distance function normalized standard deviation
attributes, including nominal attributes. next column shows generalization accuracy
obtained using HOEM metric, uses range-normalized Euclidean distance linear
attributes overlap metric nominal attributes. final column shows accuracy
obtained using HVDM distance function uses standard-deviation-normalized
Euclidean distance (i.e., normalized_diff defined Equation 13) linear attributes
normalized_vdm function N2 nominal attributes.
highest accuracy obtained database shown bold. Entries Euclid.
12

fiIMPROVED HETEROGENEOUS DISTANCE FUNCTIONS

HOEM columns significantly
higher HVDM (at 90% higher
confidence level, using two-tailed
paired test) marked
asterisk (*).
Entries
significantly lower HVDM
marked less-than sign (<).
seen Table 3,
HVDM distance functions overall
average accuracy higher
two metrics 3%.
HVDM achieved high higher
generalization accuracy
two distance functions 21 35
datasets. Euclidean distance
function highest 18 datasets,
HOEM highest 12
datasets.
HVDM significantly higher
Euclidean distance function
10 datasets, significantly lower
3. Similarly, HVDM higher
HOEM 6 datasets,
significantly lower 4.
results support hypothesis
HVDM handles nominal attributes
appropriately Euclidean
distance heterogeneous
Euclidean-overlap metric, thus
tends achieve higher generalization
accuracy typical applications.

Database
Euclid.
Anneal
94.99
Audiology
60.50 <
Audiology.Test
41.67 <
Australian
80.58
Bridges
58.64
Crx
78.99
Echocardiogram
94.82
Flag
48.95 <
Heart.Cleveland
73.94
Heart.Hungarian
73.45 <
Heart.Long-Beach-Va 71.50
Heart.More
72.09
Heart.Swiss
93.53 *
Hepatitis
77.50
Horse-Colic
65.77
House-Votes-84
93.12 <
Image.Segmentation
92.86
Led+17
42.90 <
Led-Creator
57.20 *
Monks-1.Test
77.08
Monks-2.Test
59.04 <
Monks-3.Test
87.26 <
Mushroom
100.00
Promoters
73.73 <
Soybean-Large
87.26 <
Soybean-Small
100.00
Thyroid.Allbp
94.89
Thyroid.Allhyper
97.00
Thyroid.Allhypo
90.39
Thyroid.Allrep
96.14
Thyroid.Dis
98.21
Thyroid.Hypothyroid 93.42
Thyroid.Sick-Euthyroid 68.23
Thyroid.Sick
86.93 *
Zoo
97.78
Average:
79.44

HOEM
94.61
72.00 <
75.00
81.16
53.73
81.01
94.82
48.84
74.96
74.47
71.00 *
71.90
91.86
77.50
60.82
93.12 <
93.57
42.90 <
57.20 *
69.43
54.65 <
78.49 <
100.00
82.09 <
89.20
100.00
94.89
97.00
90.39 *
96.14
98.21
93.42
68.23
86.89 *
94.44
80.11

HVDM
94.61
77.50
78.33
81.45
59.64
80.87
94.82
55.82
76.56
76.85
65.50
72.09
89.49
76.67
60.53
95.17
92.86
60.70
56.40
68.09
97.50
100.00
100.00
92.36
90.88
100.00
95.00
96.86
90.29
96.11
98.21
93.36
68.23
86.61
98.89
83.38

Table 3. Generalization accuracy
Euclidean, HOEM, HVDM distance functions.

4. Interpolated Value Difference Metric (IVDM)
section Section 5 introduce distance functions allow VDM applied
directly continuous attributes. alleviates need normalization attributes.
also cases provides better measure distance continuous attributes linear
distance.
example, consider application input attribute height output class
indicates whether person good candidate fighter pilot particular airplane.
individuals heights significantly preferred height might
considered poor candidates, thus could beneficial consider heights
similar preferred height, even though farther apart
linear sense.

13

fiWILSON & MARTINEZ

hand, linear attributes linearly distant values tend indicate different
classifications also handled appropriately. Interpolated Value Difference Metric
(IVDM) handles situations, handles heterogeneous applications robustly.
generic version VDM distance function, called discretized value difference
metric (DVDM) used comparisons extensions VDM presented paper.
4.1. IVDM Learning Algorithm
original value difference metric (VDM) uses statistics derived training set
instances determine probability Pa,x,c output class c given input value x
attribute a.
using IVDM, continuous values discretized equal-width intervals (though
continuous values also retained later use), integer supplied user.
Unfortunately, currently little guidance value use. value
large reduce statistical strength values P, value small allow
discrimination among classes. purposes paper, use heuristic
determine automatically: let 5 C, whichever greatest, C number
output classes problem domain. Current research examining sophisticated
techniques determining good values s, cross-validation, statistical
methods (e.g., Tapia & Thompson, 1978, p. 67). (Early experimental results indicate
value may critical long C n, n number instances
training set.)
width wa discretized interval attribute given by:
wa =

maxa mina


(17)

max mina maximum minimum value, respectively, occurring
training set attribute a.
example, consider Iris database UCI machine learning databases.
Iris database four continuous input attributes, first sepal length. Let
training set consisting 90% 150 available training instances, test set
consisting remaining 10%.
one division training set, values sepal length attribute ranged
4.3 7.9. three output classes database, let s=5, resulting
width |7.9 - 4.3| / 5 = 0.72. Note since discretization part learning process,
would unfair use instances test set help determine discretize
values. discretized value v continuous value x attribute integer 1 s,
given by:
x, discrete, else

v = discretizea (x) = s, x = max , else
(x min ) / w + 1




(18)

deciding upon finding w a, discretized values continuous attributes
14

fiIMPROVED HETEROGENEOUS DISTANCE FUNCTIONS

used like discrete values nominal attributes finding Pa,x,c. Figure 5 lists pseudo-code
done.
LearnP(training set T)
attribute
instance
Let x input value attribute instance i.
v = discretizea(x) [which x discrete]
Let c output class instance i.
Increment Na,v,c 1.
Increment Na,v 1.
discrete value v (of attribute a)
class c
Na,v=0
Pa,v,c=0
Else Pa,v,c = Na,v,c / Na,v
Return 3-D array Pa,v,c.

Figure 5. Pseudo code finding Pa,x,c.

Probability

first attribute Iris database, values Pa,x,c displayed Figure 6.
five discretized ranges x, probability three corresponding
output classes shown bar heights. Note heights three bars sum 1.0
discretized range. bold integers indicate discretized value range.
example, sepal length greater equal 5.74 less 6.46 would discretized
value 3.
1.0

1.0
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0

.867

Output Class:
1. Iris
Setosa

.609
.485
.455

.100
.033
4.3

1

5.02

.474 .500

3. Iris
Viginica

.061 .026

2

2. Iris
Versicolor

.391

0.0

3

5.74

6.46

4

Sepal Length (in cm)

0.0 0.0
7.18 5

7.9

Bold =
discretized
range number.

Figure 6. Pa,x,c a=1, x=1..5, c=1..3, first attribute Iris database.
4.2. IVDM DVDM Generalization
Thus far DVDM IVDM algorithms learn identically. However, point DVDM
algorithm need retain original continuous values use discretized
values generalization. hand, IVDM use continuous values.
generalization, algorithm nearest neighbor classifier use distance
function DVDM, defined follows:
DVDM(x, y) =



vdma (discretizea (xa ), discretizea (ya ))

a=1

15

2

(19)

fiWILSON & MARTINEZ

discretizea defined Equation (18) vdma defined Equation (8),
q=2. repeat convenience:
vdma (x, y) =

C

Pa,x,c Pa,y,c

2

(20)

c=1

Unknown input values (Quinlan, 1989) treated simply another discrete value, done
(Domingos, 1995).

A:
B:

1
5.0
5.7

y:

5.1

Input Attributes
2
3
3.6
1.4
2.8
4.5
3.8

1.9

4
0.2
1.3

->
->

Output Class
1 (Iris Setosa)
2 (Iris Versicolor)

0.4

Table 4. Example Iris database.
example, consider two training instances B shown Table 4, new
input vector classified. attribute a=1, discretized values A, B, 1, 2,
2, respectively. Using values Figure 6, distance attribute 1 is:
|.867-.485|2 + |.1-.455|2 + |.033-.061|2 = .273

Probability Class 2

distance B 0, since discretized value.
Note B values different ends range 2, actually nearly
close are. spite fact, discretized distance function says B
equal happen fall discretized range.
IVDM uses interpolation alleviate problems. IVDM assumes Pa,x,c values
hold true midpoint range, interpolates midpoints find P
attribute values.
Figure 7 shows P values second output class (Iris Versicolor) function
first attribute value (sepal length). dashed line indicates P value used DVDM,
solid line shows IVDM uses.
1.0
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0

Center
points
DVDM
IVDM

4

4.3

1

5.02 2

5.74 3 6.46 4
7.18 5
Sepal Length (in cm)

7.9

Bold =
discretized
range number.

Figure 7. P1,x,2 values DVDM IVDM attribute 1, class 2 Iris database.
16

fiIMPROVED HETEROGENEOUS DISTANCE FUNCTIONS

distance function Interpolated Value Difference Metric defined as:
IVDM(x, y) =



ivdma (xa , ya )2

(21)

a=1

ivdma defined as:
discrete
vdma (x, y),
C
2
ivdma (x, y) =
p (x) pa,c (y) , otherwise
a,c
c=1

(22)

formula determining interpolated probability value pa,c(x) continuous value x
attribute class c is:


x mida,u
pa,c (x) = Pa,u,c +
* (Pa,u+1,c Pa,u,c )
mida,u+1 mida,u

(23)

equation, mida,u mida,u+1 midpoints two consecutive discretized ranges
mida,u x < mida,u+1. Pa,u,c probability value discretized range u,
taken probability value midpoint range u (and similarly Pa,u+1,c).
value u found first setting u = discretizea(x), subtracting 1 u x < mida,u.
value mida,u found follows:
mida,u = mina + widtha * (u+.5)

(24)

Probability Class

Figure 8 shows values pa,c(x) attribute a=1 Iris database three output
classes (i.e. c=1, 2, 3). Since data points outside range mina..maxa,
probability value Pa,u,c taken 0 u < 1 u > s, seen visually
diagonal lines sloping toward zero outer edges graph. Note sum
probabilities three output classes sum 1.0 every point midpoint range 1
midpoint range 5.
1.0
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0

Output Class:
1. Iris Setosa
2. Iris Versicolor
3. Iris Viginica

4

4.3

1

5.02 2

5.74 3 6.46 4
7.18 5
Sepal Length (in cm)

7.9

Bold =
discretized
range number.

Figure 8. Interpolated probability values attribute 1 Iris database.
17

fiWILSON & MARTINEZ


B

value
5.0
5.7

p1,1 (v)
.687
.281

p1,2 (v)
.268
.463

p1,3 (v)
.046
.256



5.1

.634

.317

.050

ivdm1(v,y)
.005
.188

vdm1(v,y)
.273
0

Table 5. Example ivdm vs. vdm.
Using IVDM example instances Table 4, values first attribute
discretized DVDM, used find interpolated probability values.
example, value 5.1, p1,c(x) interpolates midpoints 1 2, returning
values shown Table 5 three classes. Instance value 5.0, also
falls midpoints 1 2, instance B value 5.7, falls
midpoints 2 3.
seen Table 5, IVDM (using single-attribute distance function ivdm)
returns distance indicates closer B (for first attribute),
certainly case here. DVDM (using
discretized vdm), hand, returns
Database
DVDM
IVDM
Annealing
94.99
96.11 *
distance indicates value
Australian
83.04 *
80.58
equal B, quite far A,
Bridges
56.73
60.55
illustrating problems involved
Credit Screening
80.14
80.14
Echocardiogram
100.00
100.00
using discretization.
Flag
58.76
57.66
IVDM DVDM algorithms
Glass
56.06
70.54 *
implemented tested 48 datasets
Heart Disease
80.37
81.85
Heart (Cleveland)
79.86
78.90
UCI machine learning databases.
Heart
(Hungarian)
81.30
80.98
results 34 datasets contain
Heart (Long-Beach-Va) 71.00
66.00
least continuous attributes
Heart (More)
72.29
73.33
shown Table 6. (Since IVDM
Heart (Swiss)
88.59
87.88
Hepatitis
80.58
82.58
DVDM equivalent domains
Horse-Colic
76.75
76.78
discrete attributes, results
Image Segmentation
92.38
92.86
remaining datasets deferred Section
Ionosphere
92.60
91.17
Iris
92.00
94.67
6.) 10-fold cross-validation
Liver Disorders
55.04
58.23
used, average accuracy
Pima Indians Diabetes
71.89
69.28
database 10 trials shown
Satellite Image
87.06
89.79 *
Shuttle
96.17
99.77 *
Table 6. Bold values indicate value
Sonar
78.45
84.17
highest dataset. Asterisks (*)
Thyroid (Allbp)
94.86
95.32
indicates difference statistically
Thyroid (Allhyper)
96.93
97.86 *
Thyroid (Allhypo)
89.36
96.07 *
significant 90% confidence level
Thyroid (Allrep)
96.86
98.43 *
higher, using two-tailed paired t-test.
Thyroid (Dis)
98.29
98.04
set datasets, IVDM
Thyroid (Hypothyroid)
93.01
98.07 *
higher average generalization accuracy
Thyroid (Sick)
88.24
95.07 *
Thyroid (Sick-Euthyroid) 88.82
96.86 *
overall discretized algorithm.
Vehicle
63.72
69.27 *
IVDM obtained higher generalization
Vowel
91.47
97.53 *
accuracy DVDM 23 34
Wine
94.38
97.78 *
Average:
83.08
85.22
cases, 13 significant
90% level above. DVDM higher
Table 6. Generalization DVDM vs. IVDM.
18

fiIMPROVED HETEROGENEOUS DISTANCE FUNCTIONS

accuracy 9 cases, one difference statistically significant.
results indicate interpolated distance function typically appropriate
discretized value difference metric applications one continuous
attributes. Section 6 contains comparisons IVDM distance functions.

5. Windowed Value Difference Metric (WVDM)
IVDM algorithm thought sampling value Pa,u,c midpoint mida,u
discretized range u. P sampled first finding instances value
attribute range mida,u w / 2. Na,u incremented instance,
N a,u,c also incremented instance whose output class c,
P a,u,c = Na,u,c / Na,u computed. IVDM interpolates sampled points
provide continuous rough approximation function pa,c(x). possible sample P
points thus provide closer approximation function pa,c(x), may
turn provide accurate distance measurements values.
Figure 9 shows pseudo-code Windowed Value Difference Metric (WVDM).
WVDM samples value P a,x,c value x occurring training set
Define:
instance[a][1..n] list n instances sorted ascending order attribute a.
instance[a][i].val[a] value attribute instance[a][i].
x
center value current window, i.e., x=instance[a][i].val[a].
p[a][i][c]
probability Pa,x,c output class c given input value x
attribute a. Note index, value itself.
N[c]
number Na,x,c instances current window output class c.
N
total number Na,x instances current window.
instance[a][in] first instance window.
instance[a][out] first instance outside window. (i.e., window contains
instances instance[a][in..out-1]).
w[a]
window width attribute a.
LearnWVDM(training set T)
continuous attribute
Sort instance[a][1..n] ascending order attribute a, using quicksort.
Initialize N N[c] 0, 1 (i.e., start empty window).
i=1..n
Let x=instance[a][i].val[a].
// Expand window include instances range
(out < n) (instance[a][out].val[a] < (x + w[a]/2))
Increment N[c], c=the class instance[a][out].
Increment N.
Increment out.
// Shrink window exclude instances longer range
(in < out) (instance[a][in].val[a] < (x - w[a]/2))
Decrement N[c], c=the class instance[a][in].
Decrement N.
Increment in.
// Compute probability value class current window
class c=1..C
p[a][i][c] = N[c] / N. (i.e., Pa,x,c = Na,x,c / Na,x).
Return 3-D array p[a][i][c].

Figure 9. Pseudo code WVDM learning algorithm.
19

fiWILSON & MARTINEZ

attribute a, instead midpoints range. fact, discretized ranges
even used WVDM continuous attributes, except determine appropriate window
width, wa, range width used DVDM IVDM. pseudo-code
learning algorithm used determine Pa,x,c attribute value x given Figure 9.
value x occurring training set attribute a, P sampled finding
instances value attribute range x w / 2, computing Na,x,
Na,x,c, Pa,x,c = Na,x,c / Na,x before. Thus, instead fixed number sampling
points, window instances, centered training instance, used determining
probability given point. technique similar concept shifted histogram estimators
(Rosenblatt, 1956) Parzen window techniques (Parzen, 1962).
attribute values sorted (using O(nlogn) sorting algorithm) allow
sliding window used thus collect needed statistics O(n) time attribute.
sorted order retained attribute binary search performed O(log
n) time generalization.
Values occurring sampled points interpolated IVDM, except
many points available, new value interpolated two
closer, precise values IVDM.
WVDM_Find_P(attribute a,continuous value x)
// Find Pa,x,c c=1..C, given value x attribute a.
Find instance[a][i].val[a] x instance[a][i+1].val[a] (binary search).
x1 = instance[a][i].val[a]
(unless i<1, case x1=min[a] - (w[a] / 2))
x2 = instance[a][i+1].val[a] (unless i>n, case x2=max[a] + (w[a] / 2))
class c=1..C
p1=p[a][i][c]
(unless i<1, case p1=0)
p2=p[a][i+1][c] (unless i>n, case p2=0)
Pa,x,c = p1 + ((x-x1)/(x2-x1)) * (p2 - p1)
Return array Pa,x,1..C.

Figure 10. Pseudo-code WVDM probability interpolation (see Figure 9 definitions).
pseudo-code interpolation algorithm given Figure 10. algorithm takes
value x attribute returns vector C probability values Pa,x,c c=1..C. first
binary search find two consecutive instances sorted list instances
attribute surround x. probability class interpolated
stored two surrounding instances. (The exceptions noted parenthesis handle
outlying values interpolating towards 0 done IVDM.)
probability values input vectors attribute values computed,
used vdm function discrete probability values are.
WVDM distance function defined as:
WVDM(x, y) =



wvdma (xa , ya )2

(25)

a=1

wvdma defined as:
discrete
vdma (x, y),
C
2
wvdma (x, y) =
P
Pa,y,c , otherwise
a,x,c
c=1

20

(26)

fiProbability Class

IMPROVED HETEROGENEOUS DISTANCE FUNCTIONS

1.0
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0

Output Class:
1. Iris Setosa
2. Iris Versicolor
3. Iris Viginica

4

5

6

7

8

Sepal Length (in cm)

Figure 11. Example WVDM probability landscape.
Pa,x,c interpolated probability value continuous value x computed
Figure 10. Note typically finding distance new input vector
instance training set. Since
instances training set used
Database
DVDM WVDM
define probability attribute
Annealing
94.99
95.87
Australian
83.04
82.46
values, binary search interpolation
Bridges
56.73
56.64
unnecessary training instances
Credit Screening
80.14
81.45
immediately recall stored
Echocardiogram
100.00
98.57
probability values, unless pruning techniques
Flag
58.76
58.74
Glass
56.06
71.49 *
used.
Heart Disease
80.37
82.96
One drawback approach
Heart (Cleveland)
79.86
80.23
increased storage needed retain C
Heart (Hungarian)
81.30
79.26
Heart (Long-Beach-Va) 71.00
68.00
probability values attribute value
Heart (More)
72.29
73.33
training set. Execution time
Heart (Swiss)
88.59
88.72
significantly increased IVDM
Hepatitis
80.58
79.88
Horse-Colic
76.75
74.77
DVDM. (See Section 6.2 discussion
Image
Segmentation
92.38
93.33
efficiency considerations).
Ionosphere
92.60
91.44
Figure 11 shows probability values
Iris
92.00
96.00
Liver Disorders
55.04
57.09
three classes first attribute
Pima Indians Diabetes
71.89
70.32
Iris database again, time using
Satellite Image
87.06
89.33 *
windowed sampling technique. Comparing
Shuttle
96.17
99.61 *
Figure 11 Figure 8 reveals
Sonar
78.45
84.19
Thyroid (Allbp)
94.86
95.29
attribute IVDM provides approximately
Thyroid (Allhyper)
96.93
97.50
overall shape, misses much
Thyroid (Allhypo)
89.36
90.18
detail. example, peak occurring
Thyroid (Allrep)
96.86
97.07
Thyroid (Dis)
98.29
98.00
output class 2 approximately sepal
Thyroid (Hypothyroid)
93.01
96.96 *
length=5.75. Figure 8 flat line
Thyroid (Sick)
88.24
97.11 *
misses peak entirely, due mostly
Thyroid (Sick-Euthyroid) 88.82
94.40 *
Vehicle
63.72
65.37 *
somewhat arbitrary position
Vowel
91.47
96.21 *
midpoints probability values
Wine
94.38
97.22 *
sampled.
Average:
83.08
84.68
Table 7 summarizes results testing
Table 7. Generalization WVDM vs. DVDM.
21

fiWILSON & MARTINEZ

WVDM algorithm datasets DVDM IVDM. bold entry indicates
highest two accuracy measurements, asterisk (*) indicates difference
statistically significant 90% confidence level, using two-tailed paired t-test.
set databases, WVDM average 1.6% accurate DVDM
overall. WVDM higher average accuracy DVDM 23 34 databases,
significantly higher 9, DVDM higher 11 databases, none
differences statistically significant.
Section 6 provides comparisons WVDM distance functions, including
IVDM.

6. Empirical Comparisons Analysis Distance Functions
section compares distance functions discussed paper. nearest neighbor
classifier implemented using six different distance functions: Euclidean
(normalized standard deviation) HOEM discussed Section 2; HVDM discussed
Section 3; DVDM IVDM discussed Section 4; WVDM discussed Section
5. Figure 12 summarizes definition distance function.
functions use
overall distance function:

D(x, y) =



da (xa , ya )2

a=1

Distance
Function
Euclidean

Definition da(xa,ya) attribute type:
Linear
Continuous
Discrete Nominal
xa ya
xa ya



HOEM

xa ya
rangea

0 xa = ya
1 xa ya

HVDM

xa ya
4

vdma (xa , ya )

DVDM

vdma(disca(xa),disca(ya))

vdma (xa , ya )

IVDM

ivdma(xa,ya)
Interpolate probabilities
range midpoints.

vdma (xa , ya )

WVDM

wvdma(xa,ya)
Interpolate probabilities
adjacent values.

vdma (xa , ya )

rangea = maxa mina , vdma (x, y) =

C

Pa,x,c Pa,y,c

2

c=1

Figure 12. Summary distance function definitions.
distance function tested 48 datasets UCI machine learning databases,
22

fiIMPROVED HETEROGENEOUS DISTANCE FUNCTIONS

using 10-fold cross-validation. average accuracy 10 trials reported
test Table 8. highest accuracy achieved dataset shown bold.
names three new distance functions presented paper (HVDM, IVDM WVDM)
also shown bold identify them.
Table 8 also lists number instances database (#Inst.), number
continuous (Con), integer (Int, i.e., linear discrete), nominal (Nom) input attributes.

Database
Euclid HOEM
Annealing
94.99
94.61
Audiology
60.50
72.00
Audiology (test)
41.67
75.00
Australian
80.58
81.16
Breast Cancer
94.99
95.28
Bridges
58.64
53.73
Credit Screening
78.99
81.01
Echocardiogram
94.82
94.82
Flag
48.95
48.84
Glass
72.36
70.52
Heart Disease
72.22
75.56
Heart (Cleveland)
73.94
74.96
Heart (Hungarian)
73.45
74.47
Heart (Long-Beach-Va)
71.50
71.00
Heart (More)
72.09
71.90
Heart (Swiss)
93.53
91.86
Hepatitis
77.50
77.50
Horse-Colic
65.77
60.82
House-Votes-84
93.12
93.12
Image Segmentation
92.86
93.57
Ionosphere
86.32
86.33
Iris
94.67
95.33
LED+17 noise
42.90
42.90
LED
57.20
57.20
Liver Disorders
62.92
63.47
Monks-1
77.08
69.43
Monks-2
59.04
54.65
Monks-3
87.26
78.49
Mushroom
100.00 100.00
Pima Indians Diabetes
71.09
70.31
Promoters
73.73
82.09
Satellite Image
90.21
90.24
Shuttle
99.78
99.78
Sonar
87.02
86.60
Soybean (Large)
87.26
89.20
Soybean (Small)
100.00 100.00
Thyroid (Allbp)
94.89
94.89
Thyroid (Allhyper)
97.00
97.00
Thyroid (Allhypo)
90.39
90.39
Thyroid (Allrep)
96.14
96.14
Thyroid (Dis)
98.21
98.21
Thyroid (Hypothyroid)
93.42
93.42
Thyroid (Sick-Euthyroid) 68.23
68.23
Thyroid (Sick)
86.93
86.89
Vehicle
70.93
70.22
Vowel
99.24
98.86
Wine
95.46
95.46
Zoo
97.78
94.44
Average:
80.78
81.29

n c e
HVDM
94.61
77.50
78.33
81.45
94.99
59.64
80.87
94.82
55.82
72.36
78.52
76.56
76.85
65.50
72.09
89.49
76.67
60.53
95.17
92.86
86.32
94.67
60.70
56.40
62.92
68.09
97.50
100.00
100.00
71.09
92.36
90.21
99.78
87.02
90.88
100.00
95.00
96.86
90.29
96.11
98.21
93.36
68.23
86.61
70.93
99.24
95.46
98.89
83.79

F u n
DVDM
94.99
77.50
78.33
83.04
95.57
56.73
80.14
100.00
58.76
56.06
80.37
79.86
81.30
71.00
72.29
88.59
80.58
76.75
95.17
92.38
92.60
92.00
60.70
56.40
55.04
68.09
97.50
100.00
100.00
71.89
92.36
87.06
96.17
78.45
92.18
100.00
94.86
96.93
89.36
96.86
98.29
93.01
88.24
88.82
63.72
91.47
94.38
98.89
84.06

c n
# inputs
IVDM WVDM #Inst. Con Int Nom
96.11
95.87
798
6 3
29
77.50
77.50
200
0 0
69
78.33
78.33
26
0 0
69
80.58
82.46
690
6 0
8
95.57
95.57
699
0 9
0
60.55
56.64
108
1 3
7
80.14
81.45
690
6 0
9
100.00
98.57
132
7 0
2
57.66
58.74
194
3 7
18
70.54
71.49
214
9 0
0
81.85
82.96
270
5 2
6
78.90
80.23
303
5 2
6
80.98
79.26
294
5 2
6
66.00
68.00
200
5 2
6
73.33
73.33 1541
5 2
6
87.88
88.72
123
5 2
6
82.58
79.88
155
6 0
13
76.78
74.77
301
7 0
16
95.17
95.17
435
0 0
16
92.86
93.33
420 18 0
1
91.17
91.44
351 34 0
0
94.67
96.00
150
4 0
0
60.70
60.70 10000
0 0
24
56.40
56.40 1000
0 0
7
58.23
57.09
345
6 0
0
68.09
68.09
432
0 0
6
97.50
97.50
432
0 0
6
100.00 100.00
432
0 0
6
100.00 100.00 8124
0 1
21
69.28
70.32
768
8 0
0
92.36
92.36
106
0 0
57
89.79
89.33 4435 36 0
0
99.77
99.61 9253
9 0
0
84.17
84.19
208 60 0
0
92.18
92.18
307
0 6
29
100.00 100.00
47
0 6
29
95.32
95.29 2800
6 0
22
97.86
97.50 2800
6 0
22
96.07
90.18 2800
6 0
22
98.43
97.07 2800
6 0
22
98.04
98.00 2800
6 0
22
98.07
96.96 3163
7 0
18
95.07
94.40 3163
7 0
18
96.86
97.11 2800
6 0
22
69.27
65.37
846 18 0
0
97.53
96.21
528 10 0
0
97.78
97.22
178 13 0
0
98.89
98.89
90
0 0
16
85.56
85.24

Table 8. Summary Generalization Accuracy

23

fiWILSON & MARTINEZ

set 48 datasets, three new distance functions (HVDM, IVDM WVDM)
substantially better Euclidean distance HOEM. IVDM highest average accuracy
(85.56%) almost 5% higher average Euclidean distance (80.78%), indicating
robust distance function datasets, especially nominal
attributes. WVDM slightly lower IVDM 85.24% accuracy. Somewhat
surprisingly, DVDM slightly higher HVDM datasets, even though uses
discretization instead linear distance continuous attributes. four VDM-based
distance functions outperformed Euclidean distance HOEM.
48 datasets, Euclidean distance highest accuracy 11 times; HOEM
highest 7 times; HVDM, 14; DVDM, 19; IVDM, 25 WVDM, 18.
datasets continuous attributes, four VDM-based distance functions
(HVDM, DVDM, IVDM WVDM) equivalent. datasets, VDM-based
distance functions achieve average accuracy 86.6% compared 78.8% HOEM
76.6% Euclidean, indicating substantial superiority problems.
datasets nominal attributes, Euclidean HVDM equivalent,
distance functions perform average except DVDM, averages
4% less others, indicating detrimental effects discretization. Euclidean
HOEM similar definitions applications without nominal attributes, except
Euclidean normalized standard deviation HOEM normalized range
attribute. interesting average accuracy datasets slightly higher
Euclidean HOEM, indicating standard deviation may provide better normalization
datasets. However, difference small (less 1%), datasets
contain many outliers, difference probably negligible case.
One disadvantage scaling attributes standard deviation attributes
almost always value (e.g., boolean attribute almost always 0)
given large weightnot due scale, relative frequencies attribute
values. related problem occur HVDM. skewed class distribution
(i.e., many instances classes others), P values quite
small classes quite large others, either case difference |Pa,x,c - Pa,y,c|
correspondingly small, thus nominal attributes get little weight
compared linear attributes. phenomenon noted Ting (1994, 1996),
recognized problems hypothyroid dataset. Future research address
normalization problems look automated solutions. Fortunately, DVDM, IVDM
WVDM suffer either problem, attributes scaled amount
cases, may part account success HVDM
experiments.
datasets nominal continuous attributes, HVDM slightly higher
Euclidean distance datasets, turn slightly higher HOEM, indicating
overlap metric may much improvement heterogeneous databases.
DVDM, IVDM WVDM higher Euclidean distance datasets,
IVDM lead.
6.1. Effects Sparse Data
Distance functions use VDM require statistics determine distance. therefore
hypothesized generalization accuracy might lower VDM-based distance functions
24

fiIMPROVED HETEROGENEOUS DISTANCE FUNCTIONS

Euclidean distance HOEM little data available, VDMbased functions would increase accuracy slowly others instances
made available, sufficient number instances allowed reasonable sample size
determine good probability values.

85.00

%Average Generalization Accuracy

80.00

75.00

Euclidean
70.00
HOEM
HVDM

65.00

DVDM
IVDM

60.00

WVDM
55.00
0

20

40
60
%Instances Used

80

100

Figure 13. Average accuracy amount data increases.
test hypothesis, experiments used obtain results shown Table 8
repeated using part available training data. Figure 13 shows generalization
accuracy test set improves percentage available training instances used
learning generalization increased 1% 100%. generalization accuracy values
shown averages 48 datasets Table 8.
Surprisingly, VDM-based distance functions increased accuracy fast faster
Euclidean HOEM even little data available. may
little data available, random positioning sample data input space
greater detrimental affect accuracy error statistical sampling VDM-based
functions.
interesting note Figure 13 six distance functions seem pair
three distinct pairs. interpolated VDM-based distance functions (IVDM WVDM)
maintain highest accuracy, two VDM-based functions next, functions
based linear overlap distance remain lowest early graph.
25

fiWILSON & MARTINEZ

6.2. Efficiency Considerations
section considers storage requirements, learning speed, generalization speed
algorithms presented paper.
6.2.1. STORAGE
distance functions must store entire training set, requiring O(nm) storage,
n number instances training set number input attributes
application, unless instance pruning technique used. Euclidean HOEM
functions, necessary, even amount storage restrictive n
grows large.
HVDM, DVDM, IVDM, probabilities Pa,x,c attributes (only discrete
attributes HVDM) must stored, requiring O(mvC) storage, v average number
attribute values discrete (or discretized) attributes C number output
classes application. possible instead store array Da,x,y = vdma(x,y) HVDM
DVDM, storage would O(mv2), savings C < v.
WVDM, C probability values must stored continuous attribute value,
resulting O(nmC) storage typically much larger O(mvC) n usually
much larger v (and cannot less). also necessary store list (pointers to)
instances attribute, requiring additional O(mn) storage. Thus total storage
WVDM O((C+2)nm) = O(Cnm).
Distance Function
Euclidean
HOEM
HVDM
DVDM
IVDM
WVDM

Storage
O(mn)
O(mn)
O(mn+mvC)
O(mn+mvC)
O(mn+mvC)
O(Cmn)

Learning Time
O(mn)
O(mn)
O(mn+mvC)
O(mn+mvC)
O(mn+mvC)
O(mnlogn+mvC)

Generalization Time
O(mn)
O(mn)
O(mnC) O(mn)
O(mnC) O(mn)
O(mnC) O(mn)
O(mnC)

Table 9. Summary efficiency six distance metrics.
Table 9 summarizes storage requirements system. WVDM one
distance functions requires significantly storage others.
applications, n critical factor, distance functions could used
conjunction instance pruning techniques reduce storage requirements. See Section 7
list several techniques reduce number instances retained training set
subsequent generalization.
6.2.2. L EARNING SPEED
takes nm time read training set. takes additional 2nm time find standard
deviation attributes Euclidean distance, nm time find ranges HOEM.
Computing VDM statistics HVDM, DVDM IVDM takes mn+mvC time,
approximately O(mn). Computing WVDM statistics takes mnlogn+mnC time,
approximately O(mnlogn).
general, learning time quite acceptable distance functions.
26

fiIMPROVED HETEROGENEOUS DISTANCE FUNCTIONS

6.2.3. GENERALIZATION SPEED
Assuming distance function must compare new input vector training instances,
Euclidean HOEM take O(mn) time. HVDM, IVDM DVDM take O(mnC) (unless
Da,x,y stored instead Pa,x,c HVDM, case search done O(mn)
time). WVDM takes O(logn+mnC) = O(mnC) time.
Though C typically fairly small, generalization process require
significant amount time and/or computational resources n grows large. Techniques
k-d trees (Deng & Moore, 1995; Wess, Althoff & Derwand, 1993; Sproull, 1991)
projection (Papadimitriou & Bentley, 1980) reduce time required locate nearest
neighbors training set, though algorithms may require modification handle
continuous nominal attributes. Pruning techniques used reduce storage (as Section
6.2.1) also reduce number instances must searched generalization.

7. Related Work
Distance functions used variety fields, including instance-based learning, neural
networks, statistics, pattern recognition, cognitive psychology (see Section 1
references). Section 2 lists several commonly-used distance functions involving numeric
attributes.
Normalization often desirable using linear distance function Euclidean
distance attributes arbitrarily get weight others. Dividing
range standard deviation normalize numerical attributes common practice. Turney
(1993; Turney & Halasz, 1993) investigated contextual normalization, standard
deviation mean used normalization continuous attributes depend context
input vector obtained. paper attempt use contextual
normalization, instead use simpler methods normalizing continuous attributes,
focus normalize appropriately continuous nominal attributes.
Value Distance Metric (VDM) introduced Stanfill & Waltz (1986). uses
attribute weights used functions presented paper. Modified Value
Difference Metric (MVDM) (Cost & Salzberg, 1993; Rachlin et al., 1994) use attribute
weights instead uses instance weights. assumed systems use discretization
(Lebowitz, 1985; Schlimmer, 1987) handle continuous attributes.
Ventura (1995; Ventura & Martinez, 1995) explored variety discretization methods
use systems use discrete input attributes. found using discretization
preprocess data often degraded accuracy, recommended machine learning algorithms
designed handle continuous attributes directly.
Ting (1994, 1996) used several different discretization techniques conjunction
MVDM IB1 (Aha, Kibler & Albert, 1991). results showed improved generalization
accuracy using discretization. Discretization allowed algorithm use MVDM
attributes instead using linear distance continuous attributes, thus avoided
normalization problems discussed Sections 3.1 3.2. paper, similar
results seen slightly higher results DVDM (which also discretizes continuous
attributes uses VDM) compared HVDM (which uses linear distance
continuous attributes). paper, DVDM uses equal-width intervals discretization,
27

fiWILSON & MARTINEZ

Tings algorithms make use advanced discretization techniques.
Domingos (1995) uses heterogeneous distance function similar HVDM RISE
system, hybrid rule instance-based learning system. However, RISE uses normalization
scheme similar N1 Sections 3.1 3.2, square individual attribute
distances.
Mohri & Tanaka (1994) use statistical technique called Quantification Method II (QM2)
derive attribute weights, present distance functions handle nominal
continuous attributes. transform nominal attributes values boolean
attributes, one time, weights attribute actually
correspond individual attribute values original data.
Turney (1994) addresses cross-validation error voting (i.e. using values k > 1)
instance-based learning systems, explores issues related selecting parameter k (i.e.,
number neighbors used decide classification). paper use k = 1 order
focus attention distance functions themselves, accuracy would improved
applications using k > 1.
IVDM WVDM use nonparametric density estimation techniques (Tapia & Thompson,
1978) determining values P use computing distances. Parzen windows (Parzen,
1962) shifting histograms (Rosenblatt, 1956) similar concept techniques,
especially WVDM. techniques often use gaussian kernels advanced
techniques instead fixed-sized sliding window. experimented gaussianweighted kernels well results slightly worse either WVDM IVDM, perhaps
increased overfitting.
paper applies distance function problem classification, input
vector mapped discrete output class. distance functions could also used
systems perform regression (Atkeson, Moore & Schaal, 1996; Atkeson, 1989; Cleveland &
Loader, 1994), output real value, often interpolated nearby points,
kernel regression (Deng & Moore, 1995).
mentioned Section 6.2 elsewhere, pruning techniques used reduce
storage requirements instance-based systems improve classification speed. Several
techniques introduced, including IB3 (Aha, Kibler & Albert, 1991; Aha, 1992),
condensed nearest neighbor rule (Hart, 1968), reduced nearest neighbor rule (Gates, 1972),
selective nearest neighbor rule (Rittler et al., 1975), typical instance based learning
algorithm (Zhang, 1992), prototype methods (Chang, 1974), hyperrectangle techniques
(Salzberg, 1991; Wettschereck & Dietterich, 1995), rule-based techniques (Domingos, 1995),
random mutation hill climbing (Skalak, 1994; Cameron-Jones, 1995) others (Kibler & Aha,
1987; Tomek, 1976; Wilson, 1972).

8. Conclusions & Future Research Areas
many learning systems depend reliable distance function achieve accurate
generalization. Euclidean distance function many distance functions
inappropriate nominal attributes, HOEM function throws away information
achieve much better accuracy Euclidean function itself.
Value Difference Metric (VDM) designed provide appropriate measure

28

fiIMPROVED HETEROGENEOUS DISTANCE FUNCTIONS

distance two nominal attribute values. However, current systems use VDM
often discretize continuous data discrete ranges, causes loss information
often corresponding loss generalization accuracy.
paper introduced three new distance functions. Heterogeneous Value Difference
Function (HVDM) uses Euclidean distance linear attributes VDM nominal attributes,
uses appropriate normalization. Interpolated Value Difference Metric (IVDM)
Windowed Value Difference Metric (WVDM) handle continuous attributes within
paradigm VDM. IVDM WVDM provide classification accuracy higher
average discretized version algorithm (DVDM) datasets continuous
attributes examined, equivalent DVDM applications without
continuous attributes.
experiments 48 datasets, IVDM WVDM achieved higher average accuracy
HVDM, also better DVDM, HOEM Euclidean distance. IVDM
slightly accurate WVDM requires less time storage, thus would seem
desirable distance function heterogeneous applications similar used
paper. Properly normalized Euclidean distance achieves comparable generalization
accuracy nominal attributes, situations still appropriate
distance function.
learning system used obtain generalization accuracy results paper nearest
neighbor classifier, HVDM, IVDM WVDM distance functions used knearest neighbor classifier k > 1 incorporated wide variety systems
allow handle continuous values including instance-based learning algorithms (such
PEBLS), radial basis function networks, distance-based neural networks. new
distance metrics also used areas statistics, cognitive psychology, pattern
recognition areas distance heterogeneous input vectors
interest. distance functions also used conjunction weighting schemes
improvements system provides.
new distance functions presented show improved average generalization 48
datasets used experimentation. hoped datasets representative kinds
applications face real world, new distance functions
continue provide improved generalization accuracy cases.
Future research look determining conditions distance function
appropriate particular application. also look closely problem selecting
window width, look possibility smoothing WVDMs probability landscape
avoid overfitting. new distance functions also used conjunction variety
weighting schemes provide robust generalization presence noise
irrelevant attributes, well increase generalization accuracy wide variety
applications.

References
Aha, David W., (1992). Tolerating noisy, irrelevant novel attributes instance-based
learning algorithms. International Journal Man-Machine Studies, Vol. 36, pp. 267-287.
Aha, David W., Dennis Kibler, Marc K. Albert, (1991). Instance-Based Learning
Algorithms. Machine Learning, Vol. 6, pp. 37-66.
29

fiWILSON & MARTINEZ

Atkeson, Chris, (1989). Using local models control movement. D. S. Touretzky (Ed.),
Advances Neural Information Processing Systems 2. San Mateo, CA: Morgan Kaufmann.
Atkeson, Chris, Andrew Moore, Stefan Schaal, (1996). Locally weighted learning.
appear Artificial Intelligence Review.
Batchelor, Bruce G., (1978). Pattern Recognition: Ideas Practice. New York: Plenum Press,
pp. 71-72.
Biberman, Yoram, (1994). Context Similarity Measure. Proceedings European
Conference Machine Learning (ECML-94). Catalina, Italy: Springer Verlag, pp. 49-63.
Broomhead, D. S., D. Lowe (1988). Multi-variable functional interpolation adaptive
networks. Complex Systems, Vol. 2, pp. 321-355.
Cameron-Jones, R. M., (1995). Instance Selection Encoding Length Heuristic Random
Mutation Hill Climbing. Proceedings Eighth Australian Joint Conference
Artificial Intelligence, pp. 99-106.
Carpenter, Gail A., Stephen Grossberg, (1987). Massively Parallel Architecture
Self-Organizing Neural Pattern Recognition Machine. Computer Vision, Graphics,
Image Processing, Vol. 37, pp. 54-115.
Chang, Chin-Liang, (1974). Finding Prototypes Nearest Neighbor Classifiers. IEEE
Transactions Computers, Vol. 23, No. 11, pp. 1179-1184.
Cleveland, W. S., C. Loader, (1994). Computational Methods Local Regression.
Technical Report 11, Murray Hill, NJ: AT&T Bell Laboratories, Statistics Department.
Cost, Scott, Steven Salzberg, (1993). Weighted Nearest Neighbor Algorithm
Learning Symbolic Features. Machine Learning, Vol. 10, pp. 57-78.
Cover, T. M., P. E. Hart, (1967). Nearest Neighbor Pattern Classification. Institute
Electrical Electronics Engineers Transactions Information Theory, Vol. 13, No. 1,
pp. 21-27.
Dasarathy, Belur V., (1991). Nearest Neighbor (NN) Norms: NN Pattern Classification
Techniques. Los Alamitos, CA: IEEE Computer Society Press.
Deng, Kan, Andrew W. Moore, (1995). Multiresolution Instance-Based Learning.
appear Proceedings International Joint Conference Artificial Intelligence
(IJCAI95).
Diday, Edwin, (1974). Recent Progress Distance Similarity Measures Pattern
Recognition. Second International Joint Conference Pattern Recognition, pp. 534-539.
Domingos, Pedro, (1995). Rule Induction Instance-Based Learning: Unified Approach.
appear 1995 International Joint Conference Artificial Intelligence (IJCAI-95).
Dudani, Sahibsingh A., (1976). Distance-Weighted k-Nearest-Neighbor Rule. IEEE
Transactions Systems, Man Cybernetics, Vol. 6, No. 4, April 1976, pp. 325-327.
30

fiIMPROVED HETEROGENEOUS DISTANCE FUNCTIONS

Gates, G. W., (1972). Reduced Nearest Neighbor Rule. IEEE Transactions Information
Theory, Vol. IT-18, No. 3, pp. 431-433.
Giraud-Carrier, Christophe, Tony Martinez, (1995). Efficient Metric Heterogeneous
Inductive Learning Applications Attribute-Value Language. Intelligent Systems, pp.
341-350.
Hart, P. E., (1968). Condensed Nearest Neighbor Rule. Institute Electrical
Electronics Engineers Transactions Information Theory, Vol. 14, pp. 515-516.
Hecht-Nielsen, R., (1987). Counterpropagation Networks. Applied Optics, Vol. 26, No. 23, pp.
4979-4984.
Kibler, D., David W. Aha, (1987). Learning representative exemplars concepts:
initial case study. Proceedings Fourth International Workshop Machine
Learning. Irvine, CA: Morgan Kaufmann, pp. 24-30.
Kohonen, Teuvo, (1990). Self-Organizing Map. Proceedings IEEE, Vol. 78, No.
9, pp. 1464-1480.
Lebowitz, Michael, (1985). Categorizing Numeric Information Generalization. Cognitive
Science, Vol. 9, pp. 285-308.
Merz, C. J., P. M. Murphy, (1996). UCI Repository Machine Learning Databases.
Irvine, CA: University California Irvine, Department Information Computer
Science. Internet: http://www.ics.uci.edu/~mlearn/MLRepository.html.
Michalski, Ryszard S., Robert E. Stepp, Edwin Diday, (1981). Recent Advance Data
Analysis: Clustering Objects Classes Characterized Conjunctive Concepts.
Progress Pattern Recognition, Vol. 1, Laveen N. Kanal Azriel Rosenfeld (Eds.).
New York: North-Holland, pp. 33-56.
Mitchell, Tom M., (1980). Need Biases Learning Generalizations. J. W. Shavlik
& T. G. Dietterich (Eds.), Readings Machine Learning. San Mateo, CA: Morgan
Kaufmann, 1990, pp. 184-191.
Mohri, Takao, Hidehiko Tanaka, (1994). Optimal Weighting Criterion Case
Indexing Numeric Symbolic Attributes. D. W. Aha (Ed.), Case-Based
Reasoning: Papers 1994 Workshop, Technical Report WS-94-01. Menlo Park,
CA: AIII Press, pp. 123-127.
Nadler, Morton, Eric P. Smith, (1993). Pattern Recognition Engineering. New York:
Wiley, pp. 293-294.
Nosofsky, Robert M., (1986). Attention, Similarity, Identification-Categorization
Relationship. Journal Experimental Psychology: General, Vol. 115, No. 1, pp. 39-57.
Papadimitriou, Christos H., Jon Louis Bentley, (1980). Worst-Case Analysis Nearest
Neighbor Searching Projection. Lecture Notes Computer Science, Vol. 85,
Automata Languages Programming, pp. 470-482.
31

fiWILSON & MARTINEZ

Parzen, Emanuel, (1962). estimation probability density function mode. Annals
Mathematical Statistics. Vol. 33, pp. 1065-1076.
Quinlan, J. R., (1989). Unknown Attribute Values Induction. Proceedings 6th
International Workshop Machine Learning. San Mateo, CA: Morgan Kaufmann, pp.
164-168.
Rachlin, John, Simon Kasif, Steven Salzberg, David W. Aha, (1994). Towards Better
Understanding Memory-Based Bayesian Classifiers. Proceedings
Eleventh International Machine Learning Conference. New Brunswick, NJ: Morgan
Kaufmann, pp. 242-250.
Renals, Steve, Richard Rohwer, (1989). Phoneme Classification Experiments Using Radial
Basis Functions. Proceedings IEEE International Joint Conference Neural
Networks (IJCNN89), Vol. 1, pp. 461-467.
Rittler, G. L., H. B. Woodruff, S. R. Lowry, T. L. Isenhour, (1975). Algorithm
Selective Nearest Neighbor Decision Rule. IEEE Transactions Information Theory,
Vol. 21, No. 6, pp. 665-669.
Rosenblatt, Murray, (1956). Remarks Nonparametric Estimates Density Function.
Annals Mathematical Statistics. Vol. 27, pp. 832-835.
Rumelhart, D. E., J. L. McClelland, (1986). Parallel Distributed Processing, MIT Press,
Ch. 8, pp. 318-362.
Salzberg, Steven, (1991). Nearest Hyperrectangle Learning Method. Machine Learning,
Vol. 6, pp. 277-309.
Schaffer, Cullen, (1993). Selecting Classification Method Cross-Validation. Machine
Learning, Vol. 13, No. 1.
Schaffer, Cullen, (1994). Conservation Law Generalization Performance. Proceedings
Eleventh International Conference Machine Learning (ML94), Morgan
Kaufmann, 1994.
Schlimmer, Jeffrey C., (1987). Learning Representation Change. Proceedings
Sixth National Conference Artificial Intelligence (AAAI87), Vol. 2, pp. 511-535.
Skalak, D. B., (1994). Prototype Feature Selection Sampling Random Mutation Hill
Climbing Algorithsm. Proceedings Eleventh International Conference
Machine Learning (ML94). Morgan Kaufman, pp. 293-301.
Sproull, Robert F., (1991). Refinements Nearest-Neighbor Searching k-Dimensional
Trees. Algorithmica, Vol. 6, pp. 579-589.
Stanfill, C., D. Waltz, (1986). Toward memory-based reasoning. Communications
ACM, Vol. 29, December 1986, pp. 1213-1228.

32

fiIMPROVED HETEROGENEOUS DISTANCE FUNCTIONS

Tapia, Richard A., James R. Thompson, (1978). Nonparametric Probability Density
Estimation. Baltimore, MD: Johns Hopkins University Press.
Ting, Kai Ming, (1994). Discretization Continuous-Valued Attributes Instance-Based
Learning. Technical Report No. 491, Basser Department Computer Science, University
Sydney, Australia.
Ting, Kai Ming, (1996). Discretisation Lazy Learning. appear special issue
Lazy Learning Artificial Intelligence Review.
Tomek, Ivan, (1976). Experiment Edited Nearest-Neighbor Rule. IEEE
Transactions Systems, Man, Cybernetics, Vol. 6, No. 6, June 1976, pp. 448-452.
Turney, Peter, (1994). Theoretical Analyses Cross-Validation Error Voting InstanceBased Learning. Journal Experimental Theoretical Artificial Intelligence (JETAI),
pp. 331-360.
Turney, Peter, (1993). Exploiting context learning classify. Proceedings
European Conference Machine Learning. Vienna, Austria: Springer-Verlag, pp. 402407.
Turney, Peter, Michael Halasz, (1993). Contextual Normalization Applied Aircraft Gas
Turbine Engine Diagnosis. Journal Applied Intelligence, Vol. 3, pp. 109-129.
Tversky, Amos, (1977). Features Similarity. Psychological Review, Vol. 84, No. 4, pp. 327352.
Ventura, Dan, (1995). Discretization Preprocessing Step Supervised Learning
Models, Masters Thesis, Department Computer Science, Brigham Young University.
Ventura, Dan, Tony R. Martinez (1995). Empirical Comparison Discretization
Methods. Proceedings Tenth International Symposium Computer
Information Sciences, pp. 443-450.
Wasserman, Philip D., (1993). Advanced Methods Neural Computing. New York, NY: Van
Nostrand Reinhold, pp. 147-176.
Wess, Stefan, Klaus-Dieter Althoff Guido Derwand, (1994). Using k-d Trees Improve
Retrieval Step Case-Based Reasoning. Stefan Wess, Klaus-Dieter Althoff, & M. M.
Richter (Eds.), Topics Case-Based Reasoning. Berlin: Springer-Verlag, pp. 167-181.
Wettschereck, Dietrich, Thomas G. Dietterich, (1995). Experimental Comparison
Nearest-Neighbor Nearest-Hyperrectangle Algorithms. Machine Learning, Vol. 19,
No. 1, pp. 5-28.
Wettschereck, Dietrich, David W. Aha, Takao Mohri, (1995). Review Comparative
Evaluation Feature Weighting Methods Lazy Learning Algorithms. Technical
Report AIC-95-012. Washington, D.C.: Naval Research Laboratory, Navy Center
Applied Research Artificial Intelligence.

33

fiWILSON & MARTINEZ

Wilson, D. Randall, Tony R. Martinez, (1993). Potential Prototype Styles
Generalization. Proceedings Sixth Australian Joint Conference Artifical
Intelligence (AI93), pp. 356-361.
Wilson, D. Randall, Tony R. Martinez, (1996). Heterogeneous Radial Basis Functions.
Proceedings International Conference Neural Networks (ICNN96), Vol. 2, pp.
1263-1267.
Wilson, Dennis L., (1972). Asymptotic Properties Nearest Neighbor Rules Using Edited
Data. IEEE Transactions Systems, Man, Cybernetics, Vol. 2, No. 3, pp. 408-421.
Wolpert, David H., (1993). Overfitting Avoidance Bias. Technical Report SFI TR 9203-5001. Santa Fe, NM: Santa Fe Institute.
Zhang, Jianping, (1992). Selecting Typical Instances Instance-Based Learning. Proceedings
Ninth International Conference Machine Learning.

34

fiJournal Artificial Intelligence Research 6 (1997) 87-110

Submitted 7/96; published 3/97

Uniform Framework Concept Definitions
Description Logics
Giuseppe De Giacomo

degiacomo@dis.uniroma1.it

Universita di Roma \La Sapienza"
Via Salaria 113, 00198 Roma, Italy

Maurizio Lenzerini

lenzerini@dis.uniroma1.it

Universita di Roma \La Sapienza"
Via Salaria 113, 00198 Roma, Italy

Abstract

modern formalisms used Databases Artificial Intelligence describing
application domain based notions class (or concept) relationship among
classes. One interesting feature formalisms possibility defining class,
i.e., providing set properties precisely characterize instances class.
Many recent articles point several ways assigning meaning
class definition containing sort recursion. paper, argue that, instead
choosing single style semantics, achieve better results adopting formalism
allows different semantics coexist. demonstrate feasibility argument,
presenting knowledge representation formalism, description logic ALCQ,
characteristics. addition constructs conjunction, disjunction, negation,
quantifiers, qualified number restrictions, ALCQ includes special fixpoint constructs
express (suitably interpreted) recursive definitions. constructs enable usual
frame-based descriptions combined definitions recursive data structures
directed acyclic graphs, lists, streams, etc. establish several properties ALCQ,
including decidability computational complexity reasoning, formulating
correspondence particular modal logic programs called modal mu-calculus.

1. Introduction
modern formalisms used Databases Artificial Intelligence representing
application domain based notions class (or concept) relationship among
classes. example, object-oriented semantics data models developed Databases
describe data terms classes (sometimes called entity types) incorporate several
features establishing various forms relationships classes. hand,
notion class (often called concept frame) link among classes provided
structured formalisms Knowledge Representation (frame-based languages, semantic
networks, description logics, etc.). Finally, notion also present several type systems
programming languages, specially based object-oriented paradigm.
basically two ways using describing classes (concepts). first one,
call prescriptive approach, description formalism allows expressing
number properties class, thus prescribing constraints instances class
must satisfy. second one, call definitional approach, formalism
allows providing definition class, i.e., set properties precisely character c 1997 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiDe Giacomo & Lenzerini

ize instances class. prescriptive approach quite well understood
established, definitional approach still subject interesting debate, regarding
nature semantic foundation. particular, well known
various ways assign meaning class definition contains sort recursion
(Baader, 1990, 1991; Nebel, 1991; Beneventano & Bergamaschi, 1992; Beeri, 1990).
paper, concerned semantic problems related definitional
approach, arguing that, instead choosing single style semantics knowledge
representation formalism, achieve better results allowing different semantics coexist.
discuss issue context Description Logics1 , logics originally
developed Knowledge Representation provide formal reconstruction frame-based
languages. Description logics describe domain interest terms concepts,
represent classes individuals, roles, binary relations used specify properties attributes individuals well links individuals (Nebel, 1990). Starting
atomic concepts, denoted simply name, complex concepts built using suitable set constructs. example, expression parent u male u 8child:male
denotes concept father (male parent) whose children male. symbol u
denotes construct concept conjunction, 8 denotes universal role quantification.
Typically, concepts structured hierarchies determined properties associated
them. hierarchical structure defined way specific concepts
inherit properties general ones.
introduce description logic, called ALCQ, extends well-known description logic ALC (Schmidt-Schau & Smolka, 1991) including called qualified
number restrictions, general form cardinality constraints roles,
special fixpoint constructs, enable us capture various semantics recursive
definitions within single formalism. Notably, availability constructs makes
possible combine usual frame-based descriptions definitions recursive data
structures directed acyclic graphs, lists, streams, etc.
establish several properties ALCQ, including decidability computational complexity reasoning, formulating correspondence particular modal
logic programs called modal mu-calculus.
Recent articles, (e.g., Bergamaschi & Sartori, 1992; Borgida, 1992), advocate use
description logics unifying framework several types database knowledge
representation formalisms. Indeed, possible show that, depending constructs semantics used, one capture several database models programming
language type systems using description logics. Therefore, study presented paper merely confined description logics, also applicable representation
formalisms.
paper organized follows. Section 2, present basic notions regarding
description logics fixpoints. Section 3, motivate approach
detailed discussion different semantics concept definitions
considered literature, argue formalism various semantics
coexist. Section 4, present one formalism, namely logic ALCQ,
1. Also called Concept Languages Terminological Languages.

88

fiConcept Definitions Description Logics

discuss several properties. Section 5 study reasoning techniques ALCQ
expose correspondence modal mu-calculus. Finally, Section 6, draw
conclusions discuss open problems.

2. Preliminaries
section, brie present basic notions regarding description logics,
fixpoints. interested reader referred (Nebel, 1990) (de Bakker, 1980)
complete introduction subjects.

2.1 Description Logics

Description logics allow one represent domain interest terms concepts
roles. Concepts model classes individuals, roles model relationships classes.
Starting atomic concepts (denoted A) atomic roles (denoted R),
concepts roles described simply name, complex concepts roles built
means suitable constructs.
section, concentrate description logic ALCQ, obtained wellknown description logic ALC (Schmidt-Schau & Smolka, 1991) including qualified number restrictions. cardinality constraints role fillers general form,
role fillers constraint applies selected means generic concept
expression, qualifier.
ALCQ concepts (denoted C D, possibly subscript) composed inductively
according following abstract syntax (n denotes natural number):

C ::= j > j ? j :C j C1 u C2 j C1 C2 j 9R:C j 8R:C j ( n R:C ) j ( n R:C ):
constructs independent. following equalities hold: > = :A,

? = :>, 8R:C = :9R::C , ( n R:C ) = :( n + 1 R:C ).

semantic point view, concepts interpreted subsets abstract domain,
roles interpreted binary relations domain. precisely,
interpretation = (I ; ) consists domain interpretation , interpretation
function mapping every atomic concept subset every atomic role R
subset .
interpretation function extended complex concepts ALCQ (note
ALCQ roles always atomic) follows:

>I
?I
(:C )I
(C1 u C2 )I
(C1 C2 )I
(9R:C )I
(8R:C )I
( n R:C )I
( n R:C )I

=
=
=
=
=
=
=
=
=



;

, C

C1I \ C2I
C1I [ C2I
fs 2 j 9s0: (s; s0 ) 2 RI s0 2 C g
fs 2 j 8s0: (s; s0 ) 2 RI implies s0 2 C g
fs 2 j #fs0 j (s; s0) 2 RI s0 2 C g ng
fs 2 j #fs0 j (s; s0) 2 RI s0 2 C g ng
89

fiDe Giacomo & Lenzerini

#S denotes cardinality set .
concept C satisfiable iff exists interpretation C 6= ;, otherwise
C unsatisfiable. concept C1 subsumed concept C2, written C1 v C1, iff
every interpretation , C1I C2I .
knowledge expressed terms concepts roles assembled special
knowledge base, traditionally called TBox, consists finite (possibly empty) set
assertions. order general possible, assume every assertion
form inclusion assertion (or simply inclusion):

C1 v C2

without restriction form concepts C1 C2 . pair inclusions
form fC1 v C2 ; C2 v C1 g often written C1 C2 called equivalence assertion.
interpretation satisfies inclusion C1 v C2 iff C1I C2I . interpretation
model TBox K iff satisfies inclusions K.
Let K TBox. say concept C satisfiable K, iff exists model
K C 6= ;, unsatisfiable otherwise. say concept C1 subsumed
concept C2 K, written K j= C1 v C2 , iff every model K, C1I C2I .

2.2 Fixpoints

brie recall notions fixpoints. Consider equation:
X = f (X )
f operator 2S 2S (2S denotes set subsets set ). Every
solution E equation called fixpoint operator f (while every set E
f (E ) E called pre-fixpoint, every set E E f (E ) called post-fixpoint).
general, equation one may either solution, finite number
solutions, infinite number them. Among various solutions, smallest
greatest solutions (with respect set-inclusion) prominent position, exist.
fundamental result due Tarski (Tarski, 1955) guarantees existence uniqueness
solutions case f monotonic wrt set-inclusion (), f monotonic
wrt whenever E1 E2 implies f (E1 ) f (E2 ).
Theorem 1 (Tarski) Let set, f operator 2S 2S monotonic
wrt . Then:
exists unique least fixpoint f , given TfE j f (E ) Eg.
exists unique greatest fixpoint f , given SfE j E f (E )g.

3. Concept Definitions Equations

analyze notion concept definition detail. Let us ignore moment
knowledge bases introduced previous section, let us consider
different kind assertion: definition statement. Let form definition statement
(or simply definition) be:
=def C
90

fiConcept Definitions Description Logics

atomic concept cannot appear left-hand side definition
statements, C concept expression ALCQ. principle, =def C intended
provide exact account concept terms C , i.e., define set
individuals satisfying C .
specifying semantics definitions, need distinguish two different
types atomic concepts, namely, primitive concepts defined concepts. Given set
definition statements, primitive concepts atomic concepts appear
left-hand side definition statement, whereas defined concepts
appear left-hand side definition statement.
Given interpretation = (I ; ), interpretation function directly assigns
subset primitive concepts, defined concepts. meaning
defined concept assigned definition statement =def C , extending
interpretation function following requirement satisfied:
AI = C :
(1)
Consider, example, definition statement:
parent =def 9child:>:
Note defined concept parent appear body definition statement.
(1), definition statement provides definition concept parent,
following sense: interpretation = (I ; ), parentI denotes single subset ,
exactly one denoted (9child:>)I , i.e., fs j 9t:(s; t) 2 childI g. general, concept
defined terms primitive already defined concepts, every interpretation
exists unique way extend interpretation function defined concepts,
hence doubt definition statement provides definition A.
Now, consider following definition statement:
=def 9child:A:
Given interpretation = (I ; ), (1) statement interpreted equation:
AI = fs 2 j 9t:(s; t) 2 childI 2 AI g:
However equation specify univocally extend interpretation function
defined concept A, since ; satisfies equation well set individuals
member infinite chain descendants also members.
general, call recursive definition statements2 (or simply recursive definitions),
definition statements form:
=def F (A)
F (A) stands concept subconcept3 . According (1), recursive
definition =def F (A) interpreted simply sort equation specifying that, given
2. Terminological cycles (Baader, 1990, 1991; Nebel, 1991). present discussion, sake simplicity, consider mutual recursive definitions, =def F (B ), B =def F (A). shall come
back point later on.
3. subconcept concept C substring C (including C itself) concept, according
syntax rules.
0

91

fiDe Giacomo & Lenzerini

interpretation , subset tied defined concept must satisfy
equation AI = F (A)I , i.e., must one solutions. Observe that, general, either
none, one, several subsets may exist solutions equation.
Another convenient way consider definition statement associate it, every
interpretation , operator subsets subsets instead equation,
fixpoints operator correspond solutions equation. example,
definition =def 9child:A associate operator:

S:fs 2 j 9t:(s; t) 2 childI 2 g
interpretation . general either none, one multiple solutions exist
equation associated recursive definition, either none, one multiple
fixpoints exist corresponding operator.
situation word \definition" seems misleading: body definition
give complete account defined concept. additional criterion needed
selecting solutions associated equation, equivalently, fixpoints associated
operator. words addition (1), criterion needed extend univocally
interpretations defined concepts. observation led various semantics,
interprets recursive definitions differently, choosing, priori
all, solutions, equivalently fixpoints, assigned defining
concept recursive definition4.

3.1 Different Semantics Recursive Definitions

literature description logics, three semantics recursive definitions
proposed (see Nebel, 1991):

Descriptive Semantics
Least Fixpoint Semantics
Greatest Fixpoint Semantics
semantics \right" one long standing matter debate.
describe three semantics interprets recursive definitions, present
examples showing choice semantics depends fact upon concept
defined. first, stressed descriptive semantics able
assign meaning general inclusion assertions C1 v C2 introduced previous section.
According Descriptive Semantics, recursive definition =def F (A) constraint stating that, , AI solution equation AI = F (A)I .
descriptive semantics, =def 9child:A simply states individuals class
child class A, individuals child class
class A, better specified. general descriptive semantics appropriate properly define recursive concepts, sense that, given
4. remark non-recursive definition interpreted various semantics way, since,
every , equation associated single solution.

92

fiConcept Definitions Description Logics

interpretation , unable assign unique subset defined concept
recursive definition.
fact descriptive semantics definition statements indistinguishable
equivalence assertions introduced previous section. words, meaning
assigned =def F (A) assigned equivalence assertion F (A).
Although equivalence assertions used specify if-and-only-if constraints,
provide proper definitions recursion involved. example, express
fact humans mammals parents humans, converse,
mammals parents humans humans themselves, terms
equivalence assertion:

human mammal u 9parent:> u 8parent:human:
Similarly may require horses satisfy analogous property:

horse mammal u 9parent:> u 8parent:horse:
However two equivalence assertions define human horse shown,

e.g., fact (correctly) imply humans horses vice-versa
(in contrast happen fixpoint semantics used, see below).
Least Fixpoint Semantics interprets recursive definition statement =def F (A)
assigning smallest possible extension interpretation , among
satisfy AI =def F (A)I { i.e., least fixpoint corresponding operator. fact
always assumed operator associated definition statement monotonic,
Theorem 1 applies least fixpoint exists unique, i.e., corresponding
equation unique smallest solution. Hence least fixpoint semantics
recursive definition statement =def F (A) defines concept A. easy verify
example =def 9child:A, least fixpoint semantics leads us identify ?.
Indeed empty set solution equation associated statement,
obviously smallest solution. Similarly interpret definition statement:
human =def mammal u 9parent:> u 8parent:human
least fixpoint semantics, humanI = ; interpretation .
Observe if, above, adopt similar definition horse, get horseI = ;,
trivially infer horse human.
least fixpoint semantics particularly suitable providing inductive definitions
concepts. example, consider class list (LIST) defined follows:
EMPTY-LIST LIST.
NODE exactly one successor LIST LIST.
Nothing else LIST.
first two conditions captured following recursive definition statement5 :
list =def emptylist (node u ( 1 succ:>) u 9succ:list)
5. Additionally specify two concepts emptylist node disjoint.

93

fiDe Giacomo & Lenzerini

( 1 succ:>) forces succ function. enforce third condition must
assign smallest possible extension list. Thus, class LISTs naturally
defined means definition statement, interpreted according least
fixpoint semantics.
Greatest Fixpoint Semantics interprets recursive definition statement =def F (A)
assigning largest possible extension interpretation , among
satisfy AI =def F (A)I { i.e., greatest fixpoint corresponding operator. Again,
assumed operator monotonic order guaranty existence unicity
greatest fixpoint (Theorem 1). least fixpoint semantics, greatest
fixpoint semantics recursive definition statement =def F (A) defines concept A.
example, considering definition statement =def 9child:A, greatest fixpoint
semantics leads us interpret class individuals child
turn member A.
least fixpoint semantics naturally captures classes defined induction,
greatest fixpoint semantics naturally captures classes individuals whose structure nonwell-founded co-inductive. example class STREAMs, modeling wellknown linear data structure NODE first element, rest
structure STREAM itself. Note streams similar lists except lists
considered finite sequences nodes, streams infinite sequences nodes.
class captured following recursive definition statement:

stream =def node u ( 1 succ:>) u 9succ:stream
proviso greatest possible extension assigned stream.
Finally, consider greatest fixpoint semantics recursive definition statements:
human =def mammal u 9parent:> u 8parent:human
horse =def mammal u 9parent:> u 8parent:horse:
Although assign empty extension human horse least
fixpoint semantics does, rather counter intuitive consequence
human horse, since humanI = horseI interpretation . general
types fixpoint semantics particular name used denote defined concept
impact interpretation it, since meaning defined concept
completely specified definition statement.

3.2 Least Greatest Fixpoints Concept Constructs

considerations show arguing \right" semantics recursive definitions really issue. captures essential use recursive
equations: descriptive semantics appropriate specify constraints concepts
one extends general inclusion assertions introduced Section 2;
least fixpoint semantics appropriate define structure inductively; greatest fixpoint
semantics appropriate define non-well-founded structures. Generally, may need
three knowledge base, order model various properties
different concepts.
94

fiConcept Definitions Description Logics

proposal paper exactly direction reconciling various semantics
knowledge base. pursued means logic incorporates two
constructs, X:F (X ) X:F (X ) (the symbols X; Y; : : : stand concept variables),
denoting, respectively, least fixpoint greatest fixpoint operator associated
definition X =def F (X ), is, every , smallest solution greatest
solution equation X = F (X )I .
approach, definition statements never appear TBox. Instead, knowledge
base simply set inclusion assertions (interpreted according descriptive semantics) involve fixpoint constructs. example, order specify properties
concepts list, stream, human horse use following assertions6 :
list
X:emptylist (node u ( 1 succ:>) u 9succ:X )
stream X:node u ( 1 succ:>) u 9succ:X

human mammal u 9parent:> u 8parent:human
horse mammal u 9parent:> u 8parent:horse:

Note that, add knowledge base equivalence assertion:

mgm X : mammal u 9parent:> u 8parent:X
defining concept mgm (mammal generated mammal), correctly turns
human horse subsumed mgm.

availability least greatest fixpoint constructs, allowing different semantics
used TBox, makes possible model abstract classes, also
inductively co-inductively defined data structures, lists streams.
particularly important objective integrate class-based representation formalisms
programming systems (declarative procedural), order make formalisms
useful practice. Furthermore, possibility nesting fixpoints, thus
going beyond simple equational format motivated introduction.
example, consider following one:
Among inhabitants planet \Plonk", disease called \foo" quite
common. disease manifests two forms: \visible" one
\latent" one, rather intricate hereditary pattern. Individuals
visible form transmit visible form least one (say first) direct
descendant (obviously, direct descendant), ill descendants
turn same, on, someone transmits latent form
disease. precisely, along chain descendants, visible form
disease sooner later interrupted, either individual direct
descendant individual transmits descendant latent form.
direct descendants (if any) individual latent form inherit
visible form. pattern goes like this, generation generation, forever.
hereditary pattern (foo hp) disease defined follows:
foo hp X:Y:((visible u (9child:Y 8child:?))t
(latent u 8child:(visible u X )))
6. also include assertion emptylist v :node, specifying concepts emptylist node
disjoint.

95

fiDe Giacomo & Lenzerini

visible latent denote visible latent form respectively disease,
assumed disjoint (latent v :visible).

4. Description Logic ALCQ
provide formal account meaning fixpoint constructs introducing
description logic, called ALCQ, obtained adding constructs ALCQ.
make use notions scope, bound free occurrences variables, closed
formulae, etc. definitions notions analogues first-order
logic, treating quantifiers. addition, use symbol abstraction
either .
primitive symbols ALCQ atomic concepts, (concept) variables (denoted
X; Y; : : :), atomic roles roles admitted logic.
Concepts ALCQ formed inductively according following abstract syntax:

C ::= j > j ? j :C j C1 u C2 j C1 C2 j 9R:C j 8R:C j ( n R:C ) j ( n R:C ) j
X:C j X:C j X
denotes atomic concept, R atomic role, n natural number, X variable,
restriction variable X occurring positively C bounded
fixpoint X:C . say variable X occurs positively concept C , every
free occurrence X scope even number negations, considering concepts
C 0 ( n R:C 0 ) scope one negation.
two fixpoint constructs mutually definable: X:C = :X::C [X=:X ] (where
C [X=:X ] concept obtained substituting free occurrences X concept
:X ).
before, interpretation = (I ; ) consists domain interpretation ,
interpretation function , maps every atomic concept subset , every
atomic role subset . presence free variables allow us
extend interpretation function directly every concept logic. reason
introduce valuations. valuation interpretation mapping variables
subsets .
Given valuation , denote [X=E ] valuation identical except
[X=E ](X ) = E . words, every variable :

(

X
[X=E ](Y ) = E(Y ) ifif YY =
6= X
Let interpretation valuation . assign meaning concepts
logic associating extension function , mapping concepts subsets
, follows:
96

fiConcept Definitions Description Logics

XI
AI

>I
?I
(:C )I
(C1 u C2 )I
(C1 C2 )I
(9R:C )I
(8R:C )I
( n R:C )I
( n R:C )I

(X:C )I
(X:C )I

=
=
=
=
=
=
=
=
=
=
=
=
=

(X )
AI


;

, CI
(C1 )I \ (C2 )I
(C1 )I [ (C2 )I
fs 2 j 9s0: (s; s0 ) 2 RI s0 2 CI g
fs 2 j 8s0: (s; s0 ) 2 RI implies s0 2 CI g
fs 2 j #fs0 j (s; s0) 2 RI s0 2 CI g ng
fs 2 j #fs0 j (s; s0) 2 RI s0 2 CI g ng

j CI[X=E ] E g
SfE
fE j E CI[X=E ] g

last two cases CI[X=E ] interpreted operator subsets E subsets
. syntactic restriction enforced variables, operator guaranteed
monotonic wrt . Notice free variables appearing concept interpreted
similarly atomic concepts.
concept C satisfiable, exists interpretation valuation
CI 6= ;, otherwise C unsatisfiable. concept C1 subsumed concept C2 ,
written C1 v C2 , every interpretation every valuation , (C1 )I (C2 )I .
ALCQ TBox finite (possibly empty) set inclusion assertions C1 v C2
C1 C2 closed concepts ALCQ. before, use equivalence assertions
form C1 C2 abbreviation fC1 v C2 ; C2 v C1 g.
interpretation satisfies inclusion assertion C1 v C2 , (C1 )I (C2 )I ,
valuation (being C1 C2 closed, hence independent valuations).
model TBox K, satisfies inclusion assertions K. say TBox
K satisfiable, model. Observe inclusion assertions K interpreted
according descriptive semantics.
say TBox K logically implies inclusion assertion C1 v C2 , written K j=
C1 v C2, every model K every valuation , (C1 )I (C2 )I .

4.1 Properties Fixpoint Constructs

following, use notation C (X ) indicate variable X occurs free
concept C (other variables could occur free C well), notation C (D),
concept, shorthand C (X )[X=D] (i.e., concept obtained substituting
free occurrences X C (X ) concept D).
Let us comment brie simple properties logic. First, concept
X:C (X ) equivalent concept Y:C (Y ), long free X C (X ). Second,
extension function assign closed concept value independent actual
valuation . Hence X:C , X occur C , equivalent C . Third, since
X:C (X ) fixpoint C (X:C (X )) equivalent X:C (X ). Furthermore,
concept X:C (X ) always subsumed concept X:C (X ).
97

fiDe Giacomo & Lenzerini

next property substantial. Consider class single source finite
directed acyclic graphs (DAGs) defined inductively follows7:
EMPTY-DAG DAG (base step).

NODE connections connections DAGs, DAG (inductive
step).

Nothing else DAG.
Consider ALCQ TBox K containing two equivalence assertions:
dag student X : emptydag (student u 9arc:> u 8arc:X )
dag person X : emptydag (person u 9arc:> u 8arc:X )

define concepts dag student dag person classes DAGs whose
nodes students persons respectively. Assuming students persons, want
able infer DAGs students DAGs persons well. is, want:

K j= student v person implies K j= dag student v dag person:
turns ALCQ property holds. prove this, introduce

following two theorems.

Theorem 2 Let K ALCQ TBox, C two ALCQ concepts
variable X occurs free positively. Then:
K j= C v implies K j= X:C v X:D:
Proof proceed contradiction8 . Assume CI DI holds models K
valuations . suppose exists model K valuation
(X:C )I 6 (X:D)I .

First prove result = . Let individual (X:C )I
(X:D)I . Now, have:

2 (X:C )I iff 8E : (CI[X=E ] E implies 2 E )

(2)

62 (X:D)I iff 9E 0 : (DI[X=E ] E 0 62 E 0 ):

(3)

0

set E 0 (3), following expression holds:

CI[X=E ] DI[X=E ] E 0
0

0

7. assume leaf DAG NODE arcs leading special DAG called EMPTY-DAG.
alternative, one assume leaf DAG NODE connection all.
latter case, definition dag would simplify dag =def node u 8arc:dag (in general form
inductive definitions { i.e., base case inductive case { less apparent).
8. uniformity, distinguish X occurs free not. Obviously X occur free,
result trivial.

98

fiConcept Definitions Description Logics

hence (2) 2 E 0 (3) 62 E 0 , impossible.
proof = similar. Let individual (X:C )I (X:D)I .
Now, have:

2 (X:C )I iff 9E 00 : (E 00 CI[X=E ] 2 E 00)

(4)

62 (X:D)I iff 8E : (E DI[X=E ] implies 62 E ):

(5)

00

set E 00 (4), following expression holds:

E 00 CI[X=E ] DI[X=E
00

00

]

hence (4) 2 E 00 (5) 62 E 00 , impossible. 2
defined means variable X occur positively concept C .
Similarly say variable X occurs negatively concept C , every free occurrence
X scope odd number negations, considering concepts C 0 ( n R:C 0 )
scope one negation.

Theorem 3 Let K ALCQ TBox, D(X ) ALCQ concept variable X
free variable. Then, ALCQ concepts C1 C2 :
K j= C1 v C2 implies

(

K j= D(C1) v D(C2) X occurs positively D(X )
K j= D(C2) v D(C1) X occurs negatively D(X )

Proof prove result induction formation D(X ).

Base case. D(X ) = X , result holds trivially.
Inductive cases. D(X ) form :D0 (X ) j ( n R:C 0 ) , X occurs positively
(negatively) D0 (X ) negatively (positively) D(X ). induction hypothesis K j=
D0 (Ci ) v D0(Cj ) (where i; j 2 f1; 2g 6= j ) hence semantics constructs
K j= D(Cj ) v D(Ci).
D(X ) form D10 (X ) u D20 (X ) j D10 (X ) D20 (X ) j 8R:D0(X ) j ( n R:D0 (X )),
X occurs positively (negatively) D0 (X ) D(X ). induction hypothesis
K j= D0(Ci) v D0(Cj ) hence semantics constructs K j= D(Ci) v D(Cj ).
remains prove result D(X ) = Y:D0 (X ) (Y 6= X ). case,
syntactic restriction enforced, occurs positively D0 (X ) hence Theorem 2
K j= D0(Ci) v D0(Cj ) implies K j= Y:D0(Ci ) v Y:D0 (Cj ), thus induction hypothesis
done. 2
Going back example, can, fact, infer DAGs students also DAGs
persons. Indeed, applying Theorem 3 Theorem 2, K j= student v
person implies K j= X:emptydag (studentu9arc:>u8arc:X ) v X:emptydag (person u
9arc:> u 8arc:X ).
99

fiDe Giacomo & Lenzerini

4.2 Internalizing Assertions

show logical implication ALCQ TBoxes (thus also satisfiability ALCQ
TBoxes) reducible unsatisfiability single ALCQ concept. prove result,
introduce notions generated sub-interpretation sub-valuation9.
Let = (I ; ) interpretation,
valuation , 2 individual.



define interpretation = ( ; ), valuation s, follows:
= fs0 2 j (s; s0) 2 (R1I [ : : : [ RmI )g.
atomic role Ri, RiI = RiI \ (I ).
atomic concept A, AI = AI \ .
variable X , s(X ) = (X ) \ .
call sub-interpretation generated s, sub-valuation generated
s.
generated sub-interpretations sub-valuations state following lemma.

Lemma 4 Let C ALCQ concept. interpretation , valuation
, individual 2 , have:
8t 2 : 2 CI iff 2 CIss :
Proof Without loss generality, consider concepts formed according following
simplified abstract syntax: C ::= j ? j :C j C1 u C2 j 9R:C j ( n R:C ) j X:C j X:

prove result induction number nested fixpoint constructs. Base
case. C fixpoint constructs, thesis proven induction
formation C .
Inductive case. assume thesis holds concepts C k nested fixpoint
constructs, prove concepts X:C k + 1. recall that, TarskiKnaster Theorem fixpoints (Tarski, 1955), 2 (X:C )I iff exists ordinal ff
2 (ff X:C )I , (ff X:C )I defined transfinite induction as:
(0 X:C )I = ;

(ff+1 X:C )I = CI[X=(ff X:C ) ]
( X:C )I = Sff< (ffX:C )I , limit ordinal.


Hence proceed transfinite induction ordinals ff.
Base case transfinite induction. 0 X:C defined ?, thus trivially
2 (0 X:C )I iff 2 (0 X:C )Iss .
Successor case transfinite induction. want show 2 (ff+1 X:C )I iff 2
(ff+1 X:C )Iss , reduces to:

2 CI[X=(ff X:C ) ] iff 2 CIss[X=(ff X:C )ss ]:




9. Together notions play role generated sub-model modal logics.

100

(6)

fiConcept Definitions Description Logics

prove this, start showing that:

2 CIss[X=(ff X:C )ss ] iff 2 C(Is[X=(ff X:C ) ])s :




(7)

Notice two valuations may differ value X . holds that:

2 XIss[X=(ff X:C )ss ] iff 2 X(Is[X=(ff X:C ) ])s ;




(8)

straightforward induction formation C (7) holds well.
Let us prove (8). write as:

2 s[X=(ff X:C )Iss ](X ) iff 2 ([X=(ff X:C )I ])s (X );
since 2 , reduces

2 (ff X:C )Iss iff 2 (ff X:C )I :
holds transfinite inductive hypothesis.
Now, since C contains k fixpoint constructs, inductive hypothesis k, have:

2 CI[X=(ff X:C ) ] iff 2 C(Is[X=(ff X:C ) ])s :




Hence, considering (6) (7), follows indeed 2 (ff+1 X:C )I iff 2 (ff+1 X:C )Iss .
Limit case transfinite induction. Let limit ordinal, 2 ( X:C )I iff
exists ordinal ff < 2 (ff X:C )I . transfinite induction hypothesis,
holds that: 2 (ff X:C )I iff 2 (ff X:C )Iss , thus:

2 ( X:C )I iff 2 ( X:C )Iss :
completes transfinite induction. ordinals ff holds that:

2 (ff X:C )I iff 2 (ff X:C )Iss :
induction nesting fixpoint constructs completed well, hence
proven lemma. 2
ready state result mentioned above.

Theorem 5 Let K = fC1 v D1 ; : : : ; Cq v Dq g ALCQ TBox, C two
ALCQ concepts. K j= C v ALCQ concept:
X:(8R1 :X u : : : u 8Rm :X u CK) u C u :D
(9)
unsatisfiable, R1 ; : : : ; Rm atomic roles appearing K, CK = (:C1
D1 ) u : : : u (:Cq Dq ).
101

fiDe Giacomo & Lenzerini

Proof part. contradiction. Assume (9) satisfiable, suppose
K 6j= C v D, i.e., exists interpretation , valuation ,
model K CI 6 DI . follows that, exists individual 2
2 CI 2 (:D)I . hand, fact model K implies
(CK )I = , thus (X:(8R1 :X u : : : u 8Rm :X u CK ))I = .
2 (X:(8R1 :X u : : : u 8Rm:X u CK ) u C u :D)I , i.e., (9) satisfiable, contradicting

hypotheses.
part. proceed contradiction. Assume K j= C v D. suppose
(9) satisfiable, i.e., exists interpretation , valuation ,
individual 2 , 2 (X:(8R1 :X u : : : u 8Rm :X u CK ) u C u :D)I .
consider sub-interpretation = (I ; Iss ) sub-valuation
generated s. one hand, clearly (CK )Iss = , hence model
K. hand Lemma 4 2 (X:(8R1 :X u : : : u8Rm :X u CK ) u C u:D)Iss ,
follows satisfy subsumption C v D, contradicting hypotheses.

2

result states satisfiability ALCQ concepts logical implication
ALCQ TBoxes (and thus satisfiability ALCQ TBoxes) distinct reasoning
tasks. Hence following limit attention concept satisfiability without
loss generality.

5. Reasoning Fixpoints

section concentrate developing reasoning methods check satisfiability
concepts involving fixpoints. particular, exhibit correspondence ALCQ
well-known logic programs, called modal mu-calculus (Kozen, 1983; Kozen &
Parikh, 1983; Streett & Emerson, 1984, 1989), recently investigated
expressing temporal properties reactive parallel processes (Stirling, 1992; Larsen,
1990; Cleaveland, 1990; Winsket, 1989; Dam, 1992).
get better insight correspondence two logics, first study
sublanguage ALC obtained ALCQ leaving qualified number restrictions10 .
Then, study full logic ALCQ.

5.1 Reasoning ALC

Let us introduce modal mu-calculus formally. Formulae ; ; : : : modal mu-calculus
formed inductively atomic formulae A; : : : variables X; : : : according
following abstract syntax:
; ::= j > j ? j : j ^ j _ j hai j [a] j X: j X: j X
generic element set labels L, every bounded occurrence every
variable X must scope even number negation signs.
10. Observe that, Theorem 5 qualified number restrictions play role. Hence exactly reduction
logical implication unsatisfiability holds ALC well. allows us restrict attention
satisfiability only.

102

fiConcept Definitions Description Logics

semantics modal mu-calculus based notions (Kripke) structure
valuation. Kripke structure triple (S ; fRi j 2 Lg; V ), set states,
Ri binary relation , V mapping atomic formulae subsets
. valuation mapping variables subsets . Kripke structure
valuation M, associated extension function
defined inductively
follows:
XM
= (X )

= V (A)


>
=
?M
= ;

(:)M
= ,




( ^ )M
= \


( _ ) = [

(hai)M
= fs 2 j 9s0 : (s; s0 ) 2 Ra s0 2

g
0 : (s; s0 ) 2 Ra implies s0 2 g
([a])M
=
f

2

j
8





(X:)M
= SfE j [X=E ] E g
(X:)M
= fE j E

[X=E ] g
formula satisfiable exists Kripke structure valuation

6= ;.
following theorem basis correspondence ALC modal
mu-calculus.

Theorem 6 exists one-to-one linear-time function q mapping concepts ALC
formulae modal mu-calculus that: ALC concept C , C satisfiable
q(C ) satisfiable.

Proof define q following way: q(A) = (atomic concepts mapped
atomic formulae), q(X ) = X , q(>) = >, q(?) = ?, q(:C ) = :q(C ), q(9R:C ) =
hRiq(C ) (atomic roles mapped labels), q(8R:C ) = [R]q(C ), q(X:C ) = X:q(C ),
q(X:C ) = X:q(C ).
interpretation = (I ; ) equivalent Kripke structure = (S ; fRi j 2
Lg; V ) that: = ; L equal set names atomic roles interpreted
; RR = RI atomic role R; V (A) = AI atomic concept A.
addition, valuation equivalent valuation 0 M. extension
function associated extension function associated 0
map, respectively, concept C corresponding formula q(C ) subset
= . Hence thesis follows. 2
follows may transfer decidability complexity results modal
mu-calculus (Kozen & Parikh, 1983; Emerson & Jutla, 1988; Safra, 1988) ALC . Thus,
immediately state complexity reasoning ALC concepts
ALC TBoxes.

Theorem 7 Satisfiability ALC concepts, satisfiability ALC TBoxes, logical
implication ALC TBoxes EXPTIME-complete problems.
103

fiDe Giacomo & Lenzerini

Proof satisfiability problem modal mu-calculus EXPTIME-complete (Emerson
& Jutla, 1988), hence Theorem 6 Theorem 5 thesis follows. 2

5.2 Reasoning ALCQ
Next exhibit mapping ALCQ concepts formulae variant modal mucalculus, called deterministic modal mu-calculus, syntax modal
mu-calculus, interpreted deterministic Kripke structures, Kripke structures = (S ; fRi j 2 Lg; V ) relations Ri partial functions (Streett &
Emerson, 1984).
Let us ignore moment qualified number restriction constructs. Formulae
ALCQ without qualified number restrictions are, fact, formulae modal mucalculus, shown previous section. using well-known technique developed
propositional dynamic logic (Parikh, 1981), (nondeterministic) modal mu-calculus formulae reduced deterministic modal mu-calculus formulae (Streett & Emerson,
1984), shown below.
use following notations usual operations binary relations: chaining,
exive transitive closure, + transitive closure, , converse. also use
following abbreviations:
[R ]
[R+ ]



hR
hR+i

X:( ^ [R]X )
[R][R ]
X:( _ hRiX )
hRihR i:

reduction follows: formula , recursively replace subformulae
form [R] [R][(Rnew ) ] subformulae form hRi hRih(Rnew ) i,
Rnew new symbol R Rnew resulting formula interpreted
partial functions. Let us call resulting formula 0 , satisfiable
0 satisfiable.
brie sketch reasoning behind proof statement. direction
easy: suces observe = (S ; fRDi j 2 LD g; V ) model 0 ,
transform model = (S ; fRi j 2 Lg; V ) defining = ,
L = LD , new, RR = RDR (RDnew ) , V = V . direction follows.
recall nondeterministic deterministic modal mu-calculus tree model
property (Streett & Emerson, 1989, 1984): formula model tree model,
i.e., model form tree11 . without loss generality restrict
attention tree models only. one-to-one transformation tree models
= (S ; fRTi j 2 LT g; V ) (tree) models B = (S B ; fRBi j 2 LB g; V B )
0 . Indeed, put B = , V B = V , LB = LT , given state x 2
11. Given model get tree model simply \unfolding" original one.

104

fiConcept Definitions Description Logics

RTR -successors z1; : : : ; zl ,12 put (x; z1 ) 2 RBR , (zi ; zi+1 ) 2 RBRnew , = 1; : : : ; l , 1.
way (x; zi ) 2 RTR (x; zi ) 2 RBR (RBRnew ) .13

remark required tree get B need recover
\original" RTR -predecessor x state zi , namely need (RBR (RBRnew ) ),
partial function, otherwise, given state zi , would know various
(RBR (RBRnew ) ), -successors original RTR -predecessor x, therefore would
able reconstruct B .
interpreting R Rnew partial functions, easy express qualified number
)-successors state. example:
restrictions constraints chain (R Rnew
( 3 R:) expressed
[R][(Rnew ) ](: _ [(Rnew )+ ](: _ [(Rnew )+ ](: _ [(Rnew )+ ]:)))
read \everywhere along chain R (Rnew ) three states
holds", corresponds exactly intended meaning. Similarly ( 3 R:)
expressed

hRih(Rnew ) i( ^ h(Rnew )+i( ^ h(Rnew )+ i))
read \somewhere along chain R (Rnew ) least three states
holds", corresponds exactly intended meaning.
discussion allows us state following result.

Theorem 8 exists polynomial function mapping concepts ALCQ formulae
deterministic modal mu-calculus that: ALCQ concept C , C satisfiable

u(C ) satisfiable.

Proof function defined inductively follows:
u(A)
u(X )
u(C1 u C1 )
u(C1 C2 )
u(:C )
u(X:C )
u(X:C )
u(9R:C )
u(8R:C )


X
u(C1 ) ^ u(C2 )
u(C1 ) _ u(C2 )
:u(C )
X:u(C )
X:u(C )
hRih(Rnew )iu(C )
[R][(Rnew ) ]u(C )
Rnew new role. Finally, ( n R:C ) ( n R:C ) mapped following
=
=
=
=
=
=
=
=
=

formulae:

12. implicitly assume finite branching tree model. done without loss
generality since modal mu-calculus finite model property, hence unfolding finite model
get finite branching tree model. Note however would suce assume countable
branching tree model.
13. Note construction similar one often used programming reduce n-ary trees
binary trees coding children node combination one child siblings.

105

fiDe Giacomo & Lenzerini

u(( n R:C )) =[R][(Rnew ) ](:u(C ) _ [(Rnew )+](:u(C )_
[(Rnew )+ ](: : : (:u(C ) _ [(Rnew )+ ]:u(C )) : : :)))
number nested formulae form :u(C ) _ [(Rnew )+ ] n,

u(( n R:C )) =hRih(Rnew ) i(u(C ) ^ h(Rnew )+i(u(C )^
h(Rnew )+i(: : : (u(C ) ^ h(Rnew )+iu(C )) : : :)))
number nested formulae form u(C ) ^ h(Rnew )+ n , 1.
u(C ) clearly polynomial size C (under usual assumption numbers
C coded unary). Moreover, following technique (Parikh, 1981; Streett & Emerson,
1984) exposed above, easy verify, induction formation
concept C , mapping preserves satisfiability. 2
follows may transfer decidability complexity results deterministic modal mu-calculus (Streett & Emerson, 1984; Emerson & Jutla, 1988; Safra,
1988) ALCQ. Thus, immediately state complexity reasoning
ALCQ concepts ALCQ TBoxes.

Theorem 9 Satisfiability ALCQ concepts, satisfiability ALCQ TBoxes, logical
implication ALCQ TBoxes EXPTIME-complete problems.
Proof Satisfiability deterministic modal mu-calculus EXPTIME-complete problem

(Streett & Emerson, 1984; Emerson & Jutla, 1988; Safra, 1988). Hence Theorem 8
Theorem 5 thesis follows. 2

6. Discussion Conclusion

work presented paper stems (De Giacomo, 1993), basic ideas
introducing explicit fixpoint first presented, (De Giacomo & Lenzerini, 1994b),
idea elaborated ALCQ first introduced.
One main contributions work devise tight correspondence
description logics fixpoints modal mu-calculus. respect remark
that, ALC corresponds directly modal mu-calculus, full ALCQ corresponds
variant modal mu-calculus whose decidability complexity studied.
precisely, notion essentially equivalent qualified number restrictions
independently emerged modal logics, namely graded modalities (Van der Hoek
& de Rijke, 1995; Van der Hoek, 1992; Fattorosi-Barnaba & De Caro, 1985; Fine, 1972).
However combination fixpoints graded modalities investigated
setting modal logics. Given tight correspondence ALC
modal mu-calculus, ALCQ considered modal mu-calculus augmented graded
modalities. Hence results paper apply logic well.
research reported paper bears several similarities one correspondence description logics propositional dynamic logics (Baader, 1991;
106

fiConcept Definitions Description Logics

Schild, 1991; De Giacomo & Lenzerini, 1994a, 1995; De Giacomo, 1995). fact characterize description logics based propositional dynamic logics role constructs
chaining, choice, test, exive transitive closure roles, limited
form fixpoint. role constructs easily expressed using explicit fixpoints
introduced here. suce resort following equivalences:
9R1 R2 :C = 9R1:9R2:C
9R1 R2:C = 9R1:C 9R2:C
9R:C = X:(C 9R:X )
9id(D):C = C u D:
Note 8R :C = X:(C u 8R:X ). (Calvanese, De Giacomo, & Lenzerini, 1995)
implicit form fixpoint advocated, called well-founded role
construct wf (R). explicit fixpoints, wf (R) expressed simply X:(8R:X ).
proposal allowing fixpoint constructs explicitly formalism shared
study independently carried Schild (Schild, 1994)14 . main goal
work study expressive power computational complexity
subsumption satisfiability TBoxes expressed ALC (no fixpoint constructs),
allow mutually recursive definitions. end, description logic defined
corresponds variant modal mu-calculus mutual fixpoints allowed
restrictions nested fixpoints enforced (Vardi & Wolper, 1984). well
known mutual fixpoints re-expressed means nested ones (see, example,
Park, 1976; de Bakker, 1980). consequence observation follows logic
introduced paper, expressive one analyzed (Schild, 1994) since,
one hand, allows nesting fixpoints without restriction, hand
makes possible state sophisticated forms cardinality constraints role fillers
means qualified number restrictions.
present work extended along several directions. conclude outlining
two them.
already noticed fixpoint constructs allow representing abstract
classes, also several data structures extensively used software development.
believe characteristic important step towards satisfactory integration
description logics traditional declarative programming systems. Indeed
description logic proposed paper provides powerful mechanisms data structure
modeling. particular, properties stated Section 4.1 base formulate
notion parametric concept15 . instance, expression (named dag [Z ])
X : emptydag (Z u 9arc:> u 8arc:X )
Z formal parameter, denotes class DAGs whose nodes left unspecified.
class used several ways TBox. example, instantiated
binding formal parameter actual parameters, thus getting, say, dag [student],
dag [person], etc., concepts inheriting properties dag [Z ].
14. (Schild, 1994) number restrictions considered.
15. Note parametric concepts introduced also simpler logics include fixpoint
constructs.

107

fiDe Giacomo & Lenzerini

Although ALCQ powerful logic, lacks construct inverse roles
needed example correctly capture notions (finite) TREE, BINARY-TREE, etc.
Indeed, define concept TREE (an EMPTY-TREE TREE; NODE
one parent, children, children TREEs, TREE; nothing else
TREE) write tree X : empty tree (node u ( 1 child, :>) u9child:>u8child:X
child, denotes inverse child. Notice introduction inverse roles
pose diculty semantical point view; however, impact
reasoning method needs investigated. generally, wide variety concept
constructs studied conjunction fixpoints. research description logics
related propositional dynamic logics (De Giacomo & Lenzerini, 1994a, 1995; Calvanese
et al., 1995; De Giacomo, 1995) may give us hints proceed along direction.

References

Baader, F. (1990). Terminological cycles KL-ONE-based knowledge representation languages. Proc. 8th Nat. Conf. Artificial Intelligence (AAAI-90), pp.
621{626 Boston, Ma.
Baader, F. (1991). Augmenting concept languages transitive closure roles: alternative terminological cycles. Proc. 12th Int. Joint Conf. Artificial
Intelligence (IJCAI-91) Sydney, Australia.
Beeri, C. (1990). formal approach object-oriented databases. Data Knowledge
Engineering, 5, 353{382.
Beneventano, D., & Bergamaschi, S. (1992). Subsumption complex object data models.
Proc. 4th Int. Conf. Database Theory (ICDT-92), No. 646 Lecture
Notes Computer Science, pp. 357{375. Springer-Verlag.
Bergamaschi, S., & Sartori, C. (1992). taxonomic reasoning conceptual design. ACM
Transaction Database Systems, 17 (3), 385{422.
Borgida, A. (1992). type systems knowledge representation: Natural semantics
specifications description logics. Journal Intelligent Cooperative Information
Systems, 1 (1), 93{126.
Calvanese, D., De Giacomo, G., & Lenzerini, M. (1995). Structured objects: modeling
reasoning. Proc. 4th Int. Conf. Deductive Object-Oriented Databases
(DOOD-95), Lecture Notes Computer Science. Springer-Verlag.
Cleaveland, R. (1990). Tableaux-based model checking propositional mu-calculus.
Acta Informatica, 27, 725{747.
Dam, M. (1992). CTL* ECTL* fragments modal mu-calculus. Proceeding
Col. Trees Algebra Programming, No. 581 Lecture Notes Computer
Science, pp. 145{164. Springer-Verlag.
de Bakker, J. (1980). Mathematical Theory Program Correctness. Prentice-Hall.
108

fiConcept Definitions Description Logics

De Giacomo, G. (1993). Reconciling different semantics concept definition (extended
abstract). Proc. 1st COMPULOG Net Meeting Knowledge Representation
Reasoning Systems (CNKRR-93).
De Giacomo, G. (1995). Decidability Class-Based Knowledge Representation Formalisms.
Ph.D. thesis, Dipartimento di Informatica e Sistemistica, Universita di Roma \La
Sapienza".
De Giacomo, G., & Lenzerini, M. (1994a). Boosting correspondence description
logics propositional dynamic logics. Proc. 12th Nat. Conf. Artificial
Intelligence (AAAI-94), pp. 205{212. AAAI-Press/the MIT-Press.
De Giacomo, G., & Lenzerini, M. (1994b). Concept language number restrictions
fixpoints, relationship mu-calculus. Proc. 11th Eur. Conf.
Artificial Intelligence (ECAI-94), pp. 411{415. John Wiley Sons.
De Giacomo, G., & Lenzerini, M. (1995). What's aggregate: foundation description
logics tuples set. Proc. 14th Int. Conf. Artificial Intelligence
(IJCAI-95).
Emerson, E. A., & Jutla, C. S. (1988). complexity tree automata logics
programs. Proc. 20th An. Symp. Foundations Computer Science
(FOCS-88), pp. 328{337.
Fattorosi-Barnaba, M., & De Caro, F. (1985). Graded modalities I. Studia Logica, 44,
197{221.
Fine, K. (1972). many possible worlds. Notre Dame Journal Formal Logic, 13 (4),
516{520.
Kozen, D. (1983). Results propositional mu-calculus. Theoretical Computer Science,
27, 333{355.
Kozen, D., & Parikh, R. (1983). decision procedure propositional mu-calculus.
Proc. 2nd Work. Logic Programs, No. 164 Lecture Notes Computer
Science, pp. 313{325. Springer-Verlag.
Larsen, K. J. (1990). Proof systems satisfiability Hennessy-Milner logic recursion.
Theoretical Computer Science, 72, 265{288.
Nebel, B. (1990). Reasoning Revision Hybrid Representation Systems. No. 422
Lecture Notes Artificial Intelligence. Springer-Verlag.
Nebel, B. (1991). Terminological cycles: Semantics computational properties. Sowa,
J. F. (Ed.), Principles Semantic Networks, pp. 331{361. Morgan Kaufmann, Los
Altos.
Parikh, R. (1981). Propositional dynamic logic programs: survey. Proc.
1st Work. Logic Programs, No. 125 Lecture Notes Computer Science, pp.
102{144. Springer-Verlag.
109

fiDe Giacomo & Lenzerini

Park, D. (1976). Finiteness mu-ineffable. Theoretical Computer Science, 3, 173{181.
Safra, S. (1988). complexity !-automata. Proc. 20th An. Symp.
Foundations Computer Science (FOCS-88), pp. 319{327.
Schild, K. (1991). correspondence theory terminological logics: Preliminary report.
Proc. 12th Int. Joint Conf. Artificial Intelligence (IJCAI-91), pp. 466{471
Sydney, Australia.
Schild, K. (1994). Terminological cycles propositional -calculus. Doyle, J.,
Sandewall, E., & Torasso, P. (Eds.), Proc. 4th Int. Conf. Principles
Knowledge Representation Reasoning (KR-94), pp. 509{520 Bonn. Morgan
Kaufmann, Los Altos.
Schmidt-Schau, M., & Smolka, G. (1991). Attributive concept descriptions complements. Artificial Intelligence, 48 (1), 1{26.
Stirling, C. (1992). Modal temporal logic. Abramsky, S., Gabbay, D. M., & Maibaum,
T. S. E. (Eds.), Handbook Logic Computer Science, pp. 477{563. Clarendon Press,
Oxford.
Streett, R. S., & Emerson, E. A. (1984). propositional mu-calculus elementary.
Proc. 6th Int. Col. Automata, Languages Programming, No. 172
Lecture Notes Computer Science, pp. 465{472. Springer-Verlag.
Streett, R. S., & Emerson, E. A. (1989). automata theoretic decision procedure
propositional mu-calculus. Information Control, 81, 249{264.
Tarski, A. (1955). lattice-theoretical fixpoint theorem applications. Pacific Journal
Mathematics, 5, 285{309.
Van der Hoek, W. (1992). semantics graded modalities. Journal Applied
Non-Classical Logics, 2 (1), 81{123.
Van der Hoek, W., & de Rijke, M. (1995). Counting objects. Journal Logic Computation, 5 (3), 325{345.
Vardi, M. Y., & Wolper, P. (1984). Automata theoretic techniques modal logics
programs. Proc. 16th An. Symp. Foundations Computer Science
(FOCS-84), pp. 446{456.
Winsket, G. (1989). note model checking modal -calculus. Proc. 11th
Int. Col. Automata, Languages Programming, No. 372 Lecture Notes
Computer Science, pp. 761{772. Springer-Verlag.

110

fiJournal Artificial Intelligence Research 6 (1997) 177-209

Submitted 10/96; published 5/97

Connectionist Theory Refinement:
Genetically Searching Space Network Topologies
David W. Opitz

opitz@cs.umt.edu

Jude W. Shavlik

shavlik@cs.wisc.edu

Department Computer Science
University Montana
Missoula, MT 59812 USA

Computer Sciences Department
University Wisconsin
1210 W. Dayton St.
Madison, WI 53706 USA

Abstract

algorithm learns set examples ideally able exploit
available resources (a) abundant computing power (b) domain-specific knowledge
improve ability generalize. Connectionist theory-refinement systems, use background knowledge select neural network's topology initial weights, proven
effective exploiting domain-specific knowledge; however, exploit available computing power. weakness occurs lack ability refine
topology neural networks produce, thereby limiting generalization, especially
given impoverished domain theories. present Regent algorithm uses
(a) domain-specific knowledge help create initial population knowledge-based neural networks (b) genetic operators crossover mutation (specifically designed
knowledge-based networks) continually search better network topologies. Experiments three real-world domains indicate new algorithm able significantly
increase generalization compared standard connectionist theory-refinement system,
well previous algorithm growing knowledge-based networks.

1. Introduction
Many scientific industrial problems better understood learning samples
task. reason, machine learning statistics communities devote considerable research effort inductive-learning algorithms. Often, however, learning
algorithms fail capitalize number potentially available resources, domainspecific knowledge computing power, improve ability generalize. Using
domain-specific knowledge desirable inductive learners start approximately correct theory achieve improved \generalization" (accuracy examples
seen training) significantly fewer training examples (Ginsberg, 1990; Ourston
& Mooney, 1994; Pazzani & Kibler, 1992; Towell & Shavlik, 1994). Making effective use
available computing power desirable because, many applications, important
obtain concepts generalize well induce concepts quickly. article, present algorithm, called Regent (REfining, Genetic Evolution, Network
Topologies), utilizes available computer time extensively search neural-network

c 1997 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiOpitz & Shavlik

topology best explains training data minimizing changes domain-specific
theory.
Inductive learning systems utilize set approximately correct, domain-specific
inference rules (called domain theory) describe currently known
domain, called theory-refinement systems. Making use knowledge
shown important since rules may contain insight easily obtainable
current set training examples (Ourston & Mooney, 1994; Pazzani & Kibler, 1992;
Towell & Shavlik, 1994). domains, expert created theory willing
wait weeks, even months, learning system produce improved theory.
Thus, given rapid growth computing power, believe important learning
techniques able trade expense large numbers computing cycles gains
predictive accuracy. Analogous anytime planning techniques (Dean & Boddy, 1988),
believe machine learning researchers create better anytime learning algorithms.
learning algorithms produce good concept quickly, continue search
concept space, reporting new \best" concept whenever one found.
concentrate connectionist theory-refinement systems, since shown
frequently generalize better many inductive-learning theory-refinement
systems (Fu, 1989; Lacher, Hruska, & Kuncicky, 1992; Towell, 1991). Kbann (Towell &
Shavlik, 1994) example connectionist system; translates provided
domain theory neural network, thereby determining network's topology,
refines reformulated rules using backpropagation (Rumelhart, Hinton, & Williams,
1986). However, Kbann, connectionist theory-refinement systems
alter network topologies, suffer given impoverished domain theories { ones
missing rules needed adequately learn true concept (Opitz & Shavlik, 1995;
Towell & Shavlik, 1994). TopGen (Opitz & Shavlik, 1995) improvement
systems; heuristically searches space possible network topologies adding
hidden nodes neural representation domain theory. TopGen showed statistically
significant improvements Kbann several real-world domains (Opitz & Shavlik, 1995);
however, paper empirically show TopGen nevertheless suffers
considers simple expansions Kbann network.
address limitation, broaden types topologies TopGen considers
using genetic algorithms (GAs). choose GAs two reasons. First, GAs
shown effective optimization techniques ecient use global
information (Goldberg, 1989; Holland, 1975; Mitchell, 1996). Second, GAs inherent
quality makes suitable anytime learning. \off-line" application mode
(DeJong, 1975), GAs simulate many alternatives output best alternative seen
far.
new algorithm, Regent, proceeds first trying generate, domain
theory, diversified initial population. produces new candidate networks via
genetic operators crossover mutation, networks trained using
backpropagation. Regent's crossover operator tries maintain rule structure
network, mutation operator adds nodes network using TopGen algorithm. Hence, genetic operators specialized connectionist theory refinement.
Experiments reported herein show Regent better able search network topologies TopGen.
178

fiConnectionist Theory Refinement

rest paper organized follows. next section, brie argue
importance effectively exploiting data, theory, available computer time
learning process. review Kbann TopGen algorithms. present
details Regent algorithm Section 4. followed empirical results
three Human Genome Project domains. Section 6, discuss results, well
future work. review related work concluding.

2. Using Data, Prior Knowledge, Available CPU Cycles
system learns set labeled examples called inductive learner (alternately, supervised, empirical, similarity-based learner). output example
provided teacher, set labeled examples given learner called
training set. task inductive learning generate training set concept
description correctly predicts output future examples,
training set. Many inductive-learning algorithms previously studied (e.g.,
Michalski, 1983; Quinlan, 1986; Rumelhart et al., 1986). algorithms differ
concept-representation language, method (or bias) constructing
concept within language. differences important since determine
concepts classifier induce.
alternative inductive learning paradigm build concept description
set examples, querying experts field directly assembling set
rules describe concept (i.e., build expert system; Waterman, 1986). problem
building expert systems theories derived interviewing experts tend
approximately correct. Thus, expert-provided domain theory usually
good first approximation concept learned, inaccuracies frequently exposed
empirical testing.
Theory-refinement systems (Ginsberg, 1990; Ourston & Mooney, 1994; Pazzani & Kibler,
1992; Towell & Shavlik, 1994) systems revise theory basis collection
examples. systems try improve theory making minimal repairs theory
make consistent training data. Changes initial domain theory
kept minimum theory presumably contains useful information, even
completely correct. hybrid learning systems designed learn
theory data, empirical tests shown achieve high generalization
significantly fewer examples purely inductive-learning techniques (Ourston & Mooney,
1994; Pazzani & Kibler, 1992; Towell & Shavlik, 1994). Thus, ideal inductive-learning
system able incorporate background knowledge available
form domain theory improve ability generalize.
indicated earlier, available computer time also important resource since (a) computing power rapidly increasing, (b) problems expert willing wait
lengthy period improved concept. reasons, one develop \anytime"
learning algorithms continually improve quality answer time. Dean
Boddy (1988) defined criteria anytime algorithm be: (a) algorithm
suspended resumed minimal overhead, (b) algorithm stopped
time return answer, (c) algorithm must return answers improve
179

fiOpitz & Shavlik

x
x

x

x

Output

x x

x

x

x

Input

Figure 1: classical regression example smooth function (the solid curve)
fit noisy data points (the x's) probably better predictor
high-degree polynomial (the dashed curve).

time. criteria created planning scheduling algorithms,
apply inductive learning algorithms well.1
standard inductive learners, backpropagation (Rumelhart et al., 1986)
ID3 (Quinlan, 1986), unable continually improve answers (at least
receive additional training examples). fact, run long, algorithms tend
\overfit" training set (Holder, 1991). Overfitting occurs learning algorithm
produces concept captures much information training examples,
enough general characteristics domain whole. concepts
great job classifying training instances, poor job generalizing
new examples { ultimate measure success. help illustrate point, consider
typical regression case shown Figure 1. Here, fitting noisy data high-degree
polynomial likely lead poor generalization.
general framework use encouraging algorithm improve answer
time quite simple. spend computer time considering many different possible
concept descriptions, scoring possibility, always keeping description scores
best. framework anytime respect scoring function. scoring
function approximate measure generalization obviously still prone
problems overfitting; thus guarantee generalization monotonically
decrease time. Nevertheless, assuming accurate scoring function, long
considering wide range good possibilities, quality best concept likely
improve longer period time.
1. use term anytime learning differs Grefenstette Ramsey (1992); use
mean continuous learning changing environment.

180

fiConnectionist Theory Refinement

3. Review KBANN TopGen
goal research exploit prior knowledge available computing cycles
search neural network likely generalize best. proceed
choosing, initial guess, network defined Kbann algorithm.
continually refine topology find best network concept. presenting
new algorithm (Regent), give overview Kbann algorithm well
initial approach refining Kbann-created network's topology (TopGen).

3.1 KBANN Algorithm
Kbann (Towell & Shavlik, 1994) works translating domain theory consisting set

propositional rules directly neural network (see Figure 2). Figure 2a shows Prologlike rule set defines membership category a. Figure 2b represents hierarchical
structure rules, solid lines representing necessary dependencies dotted lines
representing prohibitory dependencies. Figure 2c represents network Kbann creates
translation. sets biases nodes representing disjuncts output
near 1 least one high-weighted antecedents satisfied, nodes
representing conjuncts must high-weighted antecedents satisfied (i.e., near
1 positive links near 0 negative links). Otherwise activations near 0. Kbann
creates nodes b1 b2 Figure 2c handle two rules disjunctively defining b.
thin lines Figure 2c represent low-weighted links Kbann adds allow rules
add new antecedents backpropagation training. Following network initialization,
Kbann uses available training instances refine network links. Refer Towell
(1991) Towell Shavlik (1994) details.
Kbann successfully applied several real-world problems, control
chemical plant (Scott, Shavlik, & Ray, 1992), protein folding (Maclin & Shavlik, 1993),


: b, c.
b : d, f, g.

b



b1

b : d, f, i.
c : h, j, k.

(a)

b

c

e f g h j k
(b)

e

b2

f

g h
(c)

c

j k

Figure 2: KBANN's translation knowledge base neural network. Panel (a) shows
sample propositional rule set Prolog (Clocksin & Mellish, 1987) notation,
panel (b) illustrates rule set's corresponding and/or dependency tree,
panel (c) shows resulting network created Kbann's translation.
181

fiOpitz & Shavlik

finding genes sequence DNA (Opitz & Shavlik, 1995; Towell & Shavlik, 1994),
ECG patient monitoring (Watrous, Towell, & Glassman, 1993). case, Kbann
shown produce improvements generalization standard neural networks small
numbers training examples. fact, Towell (1991) favorably compared Kbann
wide variety algorithms, including purely symbolic theory-refinement systems,
version promoter splice-junction tasks include testbeds Section 5.
training Kbann-created network alters antecedents existing rules,
capability inducing new rules add additional
hidden nodes training. instance, Kbann unable add third rule
inferring b Figure 2's example. help illustrate point, consider following
example. Assume Figure 2's target concept consists Figure 2a's domain theory plus
rule:
b :- d, e, g.
Although trained Kbann network shown Figure 2c possible examples
target concept, unable completely learn conditions true.
topology Kbann network must modified order learn new rule.
Studies show (Opitz & Shavlik, 1995; Towell, 1991) Kbann effective
removing extraneous rules antecedents expert-provided domain theory, generalization ability suffers given \impoverished" domain theories { theories
missing rules antecedents needed adequately learn true concept. ideal connectionist theory-refinement algorithm, therefore, able dynamically expand
topology network training.

3.2 TopGen Algorithm

TopGen (Opitz & Shavlik, 1995) addresses Kbann's limitation heuristically searching
space possible expansions knowledge-based neural network { network
whose topology determined direct mapping dependencies domain theory
(e.g., Kbann network). TopGen proceeds first training Kbann network,
placing search queue. cycle, TopGen takes best network search
queue, estimates errors occur network, adds new nodes response
estimates, trains new networks, places back queue. TopGen judges
errors occur network using training examples increment two counters
node, one false negatives one false positives.
Figure 3 illustrates possible ways TopGen add nodes one networks.
symbolic rule base uses negation-by-failure, one decrease false negatives either
dropping antecedents existing rules adding new rules rule base. Kbann
effective removing antecedents existing rules, unable add new rules;
therefore, TopGen adds nodes, intended decreasing false negatives, fashion
analogous adding new rule rule base. existing node node, TopGen
adds new node child (see Figure 3a), fully connects new node input
nodes. existing node node, TopGen creates new node
parent original node another new node TopGen fully connects
inputs (see Figure 3c); TopGen moves outgoing links original node (A
Figure 3c) become outgoing links new node.
182

fiConnectionist Theory Refinement

Existing Node

Decrease False Negatives

Decrease False Positives
...

...

...

New
Node





New
Node


B

B

C

Node

C

New
Node

B

C

(a)

(b)
...



C

Node



New
Node


B

...

New
Node

...

B
B

C

C

(c)

New
Node

(d)

Figure 3: Possible ways add new nodes knowledge-based neural network (arcs indicate nodes). decrease false negatives, wish broaden applicability node. Conversely, decrease false positives, wish
constrain node.
symbolic rule base, one decrease false positives either adding antecedents
existing rules removing rules rule base. Kbann effectively remove
rules, less effective adding antecedents rules unable invent (i.e.,
constructively induce; Michalski, 1983) new terms antecedents. Thus TopGen adds new
nodes, intended decrease false positives, fashion analogous adding new
constructively induced antecedents network. Figures 3b 3d illustrates
done (analogous Figures 3a 3c explained above). Refer Opitz Shavlik (1993;
1995) details.
TopGen showed statistically significant improvements Kbann several real-world
domains, comparative experiments simpler approach adding nodes verified
new nodes must added intelligent manner (Opitz & Shavlik, 1995).
article, however, increase number networks TopGen considers search
show increase generalization primarily limited first networks
considered. Therefore, TopGen much \anytime" algorithm, rather first
step towards one. mostly due fact TopGen considers larger networks contain original Kbann network subgraphs; however, one increases
number networks considered, one also increase variety networks considered
183

fiOpitz & Shavlik

search. Broadening range networks considered search
topology space major focus paper.

4. REGENT Algorithm

new algorithm, Regent, tries broaden types networks TopGen considers
use GAs. view Regent two phases: (a) genetically searching
topology space, (b) training network using backpropagation's gradient
descent method. Regent uses domain theory aid phases. uses theory
help guide search topology space give good starting point weight
space.
Table 1 summarizes Regent algorithm. Regent first sets aside validation set
(from part training instances) use scoring different networks. perturbs Kbann-produced network create initial set candidate networks. Next,
Regent trains networks using backpropagation places population. cycle, Regent creates new networks crossing mutating networks
current population randomly picked proportional fitness (i.e.,
validation-set correctness). trains new networks places
population. searches, Regent keeps network lowest validation-set
error best concept seen far, breaking ties choosing smaller network
application Occam's Razor. parallel version Regent trains many candidate networks time using Condor system (Litzkow, Livny, & Mutka, 1988),
runs jobs idle workstations.
diverse initial population broaden types networks Regent considers
search; however, since domain theory may provide useful information may
present training set, still desirable use theory generating initial
population. Regent creates diversity around domain theory randomly perturbing
Kbann network various nodes. Regent perturbs node either deleting it,
adding new nodes manner analogous one TopGen's four methods adding

GOAL: Search best network topology describing domain theory data.

1. Set aside validation set training instances.
2. Perturb Kbann-produced network multiple ways create initial networks, train
networks using backpropagation place population.
3. Loop forever:
(a) Create new networks using crossover mutation operators.
(b) Train networks backpropagation, score validation set, place
population.
(c) new network network lowest validation-set error seen far (breaking
ties preferring smallest network), report current best concept.

Table 1: REGENT algorithm.
184

fiConnectionist Theory Refinement

Crossover Two Networks:

GOAL: Crossover two networks generate two new network topologies.
1. Divide network's hidden nodes sets B using DivideNodes.

2. Set forms one network, set B forms another. new network created follows:
(a) network inherits weight w parent nodes j either also inherited
input output nodes.
(b) Link unconnected nodes levels near-zero weights.
(c) Adjust node biases keep original function node (see text explanation).
ji

DivideNodes:
GOAL:

Divide hidden nodes sets B, probabilistically maintaining
network's rule structure.
hidden node assigned set B:
(i) Collect unassigned hidden nodes whose output linked either previouslyassigned nodes output nodes.
(ii) set set B empty:
node collected part (i), randomly assign set set B.

Else

Probabilistically add nodes collected part (i) set set B. Equation 1
shows probability assigned set A. probability assigned
set B one minus value.

Table 2: REGENT's method crossing networks.
nodes. (Should happen multiple theories domain,
used seed population.)

4.1 REGENT's Crossover Operator

Regent crosses two networks first dividing nodes parent network

two sets, B, combining nodes set form two new networks (i.e.,
nodes two sets form one network, nodes two B sets form another).
Table 2 summarizes Regent's method crossover Figure 4 illustrates
example. Regent divides nodes, one level2 time, starting level nearest
output nodes. considering level, either set set B empty, cycles
node level randomly assigns either set. neither set empty, nodes
probabilistically placed set. following equation calculates probability
2. Although one define level several different ways, define node's level longest path
output node.

185

fiOpitz & Shavlik

Original
Networks
Crossed


Output

Output

Input

Input

Output

Output

Input

Input

Resulting
Networks
Figure 4: REGENT's method crossing two networks. hidden nodes
original network divided sets B; nodes two sets
form one new network, nodes two B sets form another. Grey lines
represent low-weighted links added fully connect neighboring levels.
given node assigned set A:

Pj2A jwjij
Prob(node 2 setA) = P jw j + P jw j ;
j 2A ji
j 2B ji

(1)

j 2 means node j member set wji weight value node
node j . probability belonging set B one minus probability.
probabilities, Regent tends assign set nodes heavily linked
together. helps minimize destruction rule structure crossed-over
networks, since nodes belonging syntactic rule connected heavily linked
weights. Thus, Regent's crossover operator produces new networks crossing-over rules,
rather simply crossing-over nodes.
Regent must next decide connect nodes newly created networks.
First, new network inherits weight values parents links (a) connect
two nodes inherited new network, (b) connect inherited hidden
node input output node, (c) directly connect input node output node.
adds randomly set, low-weighted links unconnected nodes consecutive
levels.
Finally, adjusts bias nodes help maintain original function.
instance, Regent removes positively weighted incoming link node,
decrements node's bias subtracting product link's magnitude
186

fiConnectionist Theory Refinement

average activation (over set training examples) entering link.
bias node needs slightly less sum positive weights
incoming links (see Towell Shavlik, 1994 details). Regent increments
bias node analogous amount removes negatively weighted incoming
links (since bias node slightly greater sum negative
weights incoming links node inactive incoming negatively
weighted linked nodes active positively weighted linked nodes inactive).

4.2 REGENT's Mutation Operator

Regent mutates networks applying variant TopGen. Regent uses TopGen's
method incrementing false-negatives false-positives counters node. Regent adds nodes, based values counters, way TopGen does.

Since neural learning effective removing unwanted antecedents rules KNNs
(see Section 3.1), Regent considers adding nodes, deleting them, mutation. Thus, mutation operator adds diversity population, still maintaining
directed, heuristic-search technique choosing add nodes; directedness
necessary currently unable evaluate thousand possible
networks per day.

4.3 Additional Details
Regent adds newly trained networks population validation-set correctness better equal existing member population. Regent

replaces member, replaces member lowest correctness (ties broken
choosing oldest member). techniques (Goldberg, 1989), replacing
member nearest new candidate network, promote diverse populations; however,
want promote diversity expense decreased generalization. future
research topic, plan investigate incorporating diversity-promoting techniques
able consider tens thousands networks.
Regent considered Lamarckian3 , genetic-hillclimbing algorithm (Ackley, 1987),
since performs local optimizations individuals, passes successful optimizations
offspring. ability individuals learn smooth fitness landscape
facilitate subsequent learning. Thus, Lamarckian learning lead large increase
learning speed solution quality (Ackley & Littman, 1994; Farmer & Belin, 1992).

5. Experimental Results
section, test Regent three real-world Human Genome Project problems
aid locating genes DNA sequences (recognizing promoters, splice-junctions,
ribosome-binding sites). domains, input short segment DNA nucleotides
(about 100 elements long) task learn predict DNA subsequence contains
biologically important site. domain also accompanied domain theory generated
DNA expert (M. Noordewier).
3. Lamarckian evolution theory based inheritance characteristics acquired lifetime.

187

fiOpitz & Shavlik

promoter domain contains 234 positive examples, 702 negative examples, 31
rules. splice-junction domain contains 1,200 examples distributed equally among three
classes, 23 rules. Finally, ribosome binding sites (RBS) domain, contains 366
positive examples, 1,098 negative examples, 17 rules. (Note promoter data set
domain theory later version one appears Towell, 1994.) domains
available University Wisconsin Machine Learning (UW-ML) site via World
Wide Web (ftp://ftp.cs.wisc.edu/machine-learning/shavlik-group/datasets/)
anonymous ftp (ftp.cs.wisc.edu, machine-learning/shavlik-group/datasets).
first directly compare Regent TopGen Kbann. perform
lesion study4 Regent. particular, investigate value adding randomly
created networks Regent's initial population examine utility Regent's
genetic operators.

5.1 Experimental Methodology

results article ten-fold cross validation runs. ten-fold cross
validation data set first partitioned ten equal-sized sets, set turn
used test set classifier trains nine sets. fold, Regent
run population size 20. network trained using backpropagation. Parameter
settings neural networks include learning rate 0.10, momentum term 0.9,
number training epochs 20; first two standard settings 20
epochs may fewer typically found neural network literature, set 20
help avoid overfitting. set aside validation set consisting 10% training
examples Regent use scoring function.

5.2 Generalization Ability REGENT

section's experiments compare test-set accuracy (i.e., generalization) Regent
TopGen's. Figure 5 shows test-set error Kbann, TopGen, Regent
search space network topologies. horizontal line graph results
Kbann algorithm. drew horizontal line sake visual comparison;
recall Kbann considers single network. first point graph,
one network considered, nearly three algorithms, since start
Kbann network; however, TopGen Regent differ slightly Kbann since
must set aside part training set score candidate networks. Notice
TopGen stops improving considering 10 30 networks generalization
ability Regent better TopGen's point. reason occasional
upward movements Figure 5 due fact validation set (or scoring
function) inexact estimate true generalization error (as results
ten-fold cross validation).
Figure 6 presents test-set error TopGen Regent consider
500 candidate topologies. standard neural network results fully connected,
single-layer, feed-forward neural network; fold, trained 20 networks containing
100 hidden nodes used validation set choose best network. results
4. lesion study one components algorithm individually disabled ascertain
contribution full algorithm's performance (Kibler & Langley, 1988).

188

fiConnectionist Theory Refinement

10 %

8%
Ribosome Binding Sites

6%
KBANN
TopGen

4%

REGENT

TestSet Error

2%

6%

4%

Splice Junctions

2%

6%

4%
Promoters
2%

0

100

200

300

400

Networks Considered
Figure 5: Error rates three Human Genome problems.

189

500

fiOpitz & Shavlik

show Kbann generalizes much better best standard networks, thus
confirming Kbann's effectiveness generating good network topologies. TopGen
able improve Kbann network, Regent able significantly decrease error
rate Kbann TopGen. (For benchmark purposes, Regent error rate
3.9% ten-fold cross validation full Splice Junction dataset 3190 examples
commonly used machine learning researchers.)
Table 3 contains number hidden nodes final networks produced Kbann,
TopGen, Regent. results demonstrate Regent produces networks
larger Kbann's TopGen's networks (even though TopGen adds nodes
search). Regent's networks larger, necessarily mean
\complex." inspected sample networks found large
portions network either used (e.g., weights insignificantly small)
functional duplications groups hidden nodes.
One could prune weights nodes Regent's search; however, pruning
prematurely reduce variety structures available recombination crossover
(Koza, 1992). Real-life organisms, instance, super uous DNA believed
enhance rate evolution (Watson, Hopkins, Roberts, Argetsinger-Steitz, & Weiner,
1987). However, pruning network size genetic search may unwise, one
could prune Regent's final network using, say, Hassibi Stork's (1992) Optimal Brain
Surgeon algorithm. post-pruning process may increase future classification speed
network, well increase comprehensibility possibly accuracy.

5.3 Lesion Study REGENT
section, describe lesion study performed Regent. Since single run
Regent takes four CPU days consider 500 networks, single ten-fold cross
10.70
10 %

9.40

9.15

TestSet Error

8.23
8%

7.83
6.62

6%

5.25 4.92

Key

6.26

Standard NN

5.25

4.08

4.17

KBANN
TopGen

4%

REGENT
2%

RBS

Splice Junctions

Promoters

Figure 6: Test-set error rates TopGen REGENT consider 500 networks. Pairwise, one-tailed t-tests indicate Regent differs Standard NN, Kbann,
TopGen 95% confidence level three problems.
190

fiConnectionist Theory Refinement

Domain
Kbann TopGen
Regent
RBS
18
42.1 (9.3) 70.1 (25.1)
Splice Junction
21
28.4 (4.1) 32.4 (12.2)
Promoters
31
40.2 (3.3) 74.9 (38.9)
Table 3: Number hidden nodes networks produced KBANN, TopGen,
REGENT. columns show mean number hidden nodes found within
networks. Standard deviations contained within parentheses;
report standard deviations Kbann since uses one network.

validation takes (a minimum of) 40 CPU days. Therefore, given inherent similarity
investigating various aspects Regent multiple datasets, feasible
run experiments section 95% confidence level reached cases
(assuming level actually exists). Nonetheless, results convey important
information various components Regent, and, shown previous section,
complete Regent algorithm generate statistically significant improvements
existing algorithms.
5.3.1 Including Non-KNNs REGENT's Population

correct theory may quite different initial domain theory. Thus,
section investigate whether one include, initial population networks,
variety networks obtained directly domain theory. Currently, Regent
creates initial population always perturbing Kbann network. include networks
obtained domain theory, first randomly pick number hidden
nodes include network, randomly create hidden nodes network.
adding new nodes randomly selected output hidden node using one
TopGen's four methods adding new nodes (refer Figure 3). Adding nodes
manner creates random networks whose node structure analogous dependencies found
symbolic rule bases, thus creating networks suitable Regent's crossover mutation
operators.
Table 4 shows test-set error Regent various percentages knowledge-based
neural networks (KNNs) present initial population. first row contains results
initializing Regent purely random initial population (i.e., population contains
KNNs). second row lists results Regent creates half population
domain theory, half randomly. Finally, last row contains results
seeding entire population domain theory.
results suggest including, initial population, networks
created domain theory increases Regent's test-set error three domains.
occurs randomly generated networks correct KNNs,
191

fiOpitz & Shavlik

0% KNN
50% KNN
100% KNN

RBS
9.7%
8.6%
8.2%

Splice Junction
6.3%
4.3%
4.1%

Promoters
5.1%
4.6%
4.2%

Table 4: Test-set error considering 500 networks. row gives pergentage
KNNs present initial population. Pairwise, one-tailed t-tests indicate
initializing Regent 100% KNNs differs 0% KNNs 95% confidence
level three domains; however, difference runs 50%
100% KNNs significant level.

thus offspring original KNN quickly replace random networks. Hence, diversity population suffers compared methods start whole population
KNNs. Assuming domain theory \malicious," therefore better seed
entire population Kbann network. domain theory indeed malicious
contain information promotes spurious correlations data, would
reasonable randomly create \whole" population. Running Regent
without domain theory allows one investigate utility theory.
results also interesting GA point view. Forrest Mitchell (1993)
showed GAs perform poorly complex problems basic building blocks either
(a) non-trivial find (b) get split crossover. Seeding initial population
domain theory (as Regent does) help define basic building blocks
problems.
5.3.2 Value REGENT's Mutation

Typically GAs, mutation secondary operation sparingly used (Goldberg, 1989); however, Regent's mutation directed approach heuristically adds
nodes KNNs provenly effective manner (i.e., uses TopGen). therefore reasonable hypothesize one apply mutation operator frequently
traditionally done GAs. results section test hypothesis.
Figure 7 presents test-set error Regent varying percentages mutation
(versus crossover) creating new networks step 3a Table 1. graph plots four
curves: (a) 0% mutation (i.e., Regent uses crossover), (b) 10% mutation, (c) 50%
mutation, (d) 100% mutation. Performing mutations tests value solely using
crossover, 100% mutation tests ecacy mutation operator itself. Note
100% mutation TopGen different search strategy; instead keeping
OPEN list heuristic search, population KNNs generated members
population improved proportional fitness. two curves (10%
50% mutation) test synergy two operators. Performing 10% mutation
192

fiConnectionist Theory Refinement

10 %

8%

Ribosome Binding Sites
6%
0% Mutation
10% Mutation

4%

50% Mutation
100% Mutation

TestSet Error

2%

6%

4%

Splice Junctions
2%

6%

4%

Promoters
2%

0

100

200

300

400

500

Networks Considered
Figure 7: Error rates REGENT different fractions mutation versus crossover
considering 500 networks. Arguably due inherent similarity
algorithms, limited number runs due computational complexity,
results significant 95% confidence level.

193

fiOpitz & Shavlik

closer traditional GA viewpoint mutation secondary operation, 50%
mutation means operations equally valuable. (Previous experiments
section used 50% mutation 50% crossover.)
differences statistically significant, results nevertheless suggest
synergy exists two operations. Except middle portion
promoter domain, results show that, qualitatively, using operations
time better using either operation alone. fact, equally mixing mutation
crossover operator better three curves three domains Regent
considered 500 networks. result particularly pronounced splice-junction
domain.
5.3.3 Value REGENT's Crossover
Regent tries cross rules networks, rather blindly crossing

nodes. probabilistically dividing nodes network two sets
nodes belonging rule tend belong set. section,
test ecacy Regent's crossover comparing variant
randomly assigns nodes two sets (rather using DivideNodes Table 2).
Table 5 contains results test 250 networks considered.
first row, Regent-random-crossover, Regent randomly breaks hidden nodes
two sets, second row, Regent assigns nodes two sets according Table
2. cases, Regent creates half networks mutation operator,
half crossover operator. Although differences statistically significant,
results suggest keeping rule structure networks intact crossover
important; otherwise, basic building blocks networks (i.e., rules) get split
crossover, studies shown importance keeping intact basic building
blocks crossover (Forrest & Mitchell, 1993; Goldberg, 1989).

Regent-random-crossover
Regent

Promoters Splice Junction RBS
4.6%
4.7%
9.1%
4.4%
4.1%
8.8%

Table 5: Test-set error two runs REGENT: (a) randomly crossing \nodes"
networks, (b) one crossing \rules" network (defined
Equation 1). runs considered 250 networks used half crossover, half
mutation. results significant 95% confidence level;
slight difference learning algorithms long run-times limited
runs ten-fold cross validation.

6. Discussion Future Work

Towell (1991) showed Kbann generalized better many machine learning algorithms promoter splice-junction domains (the RBS dataset exist then).
194

fiConnectionist Theory Refinement

Despite success, Regent able effectively use available computer cycles significantly improve generalization Kbann previous improvement Kbann,
TopGen algorithm. Regent reduces Kbann's test-set error 12% RBS domain, 22% splice-junction domain, 33% promoter domain; reduces
TopGen's test-set error 10% RBS domain, 17% splice-junction domain,
21% promoter domain. Also, Regent's ability use available computing time
aided inherently parallel, since train many networks simultaneously.
results show Regent's two genetic operators complement other.
crossover operator considers large variety network topologies probabilistically combining rules contained within two \successful" KNNs. Mutation, hand, makes
smaller, directed improvements members population, time adding
diversity population adding new rules population. Equal use operators, therefore, allows wide variety topologies considered well allowing
incremental improvements members population.
Since Regent searches many candidate networks, important
able recognize networks likely generalize best. mind,
first planned extension Regent develop test different network-evaluation functions. currently use validation set; however, validation sets several drawbacks.
First, keeping aside validation set decreases number training instances available
network. Second, performance validation set noisy approximator
true error (MacKay, 1992; Weigend, Huberman, & Rumelhart, 1990). Finally,
increase number networks searched, Regent may start selecting networks
overfit validation set. fact, explains occasional upward trend test-set error,
TopGen Regent, Figure 5.
avoid problem overfitting data, common regression trick cost
function includes \smoothness" term along error term. best function,
then, smoothest function also fits data well. neural networks, one
add estimated error smoothness component measure complexity
network. complexity network cannot simply estimated counting
number possible parameters, since tends significant duplication
function weight network, especially early training process (Weigend,
1993). Two techniques try take account effective size network
Generalized Prediction Error (Moody, 1991) Bayesian methods (MacKay, 1992).
Quinlan Cameron-Jones (1995) propose adding additional term accuracy
smoothness term takes account length time spent searching. coin
term \oversearching" describe phenomenon extensive searching causes
lower predictive accuracy. claim oversearching orthogonal overfitting,
thus complexity-based methods alone cannot prevent oversearching. increase
number networks consider search, may start oversearching,
thus plan investigate adding oversearching penalty term well.
indicated earlier, Regent Lamarckian passes local optimizations individuals (i.e., trained weights network) offspring. viable alternative, called
Baldwin effect (Ackley & Littman, 1992; Baldwin, 1896; Belew & Mitchell, 1996; Hinton &
Nowlan, 1987), local search still change fitness individual (backpropagation learning case), pass changes offspring (this form
195

fiOpitz & Shavlik

evolution Darwinian nature). Even though learned explicitly coded
genetic material, individuals best able learn offspring;
thus learning still impacts evolution. fact form evolution sometimes outperform forms Lamarckian evolution employ local search strategy (Whitley,
Gordon, & Mathias, 1994). Future work investigate utility Baldwin effect
Regent. case would cross trained networks, instead cross
initial weight settings backpropagation learning took place.
Finally, often times multiple, even con icting, theories domain. Future work, then, investigate ways using domain theories seed
initial population. Although results Section 5.3.1 show including randomly generated networks degrades generalization performance, seeding population multiple
approximately correct theories degrade generalization, assuming networks
initial correctness. Thus Regent able naturally
combine good parts multiple theories. Also, given domain theory, many
different equivalent ways represent theory using set propositional rules.
representation leads different network topology, even though network
starts theory, topologies may conducive neural refinement.

7. Related Work

Regent mainly differs previous work an\anytime" theory-refinement sys-

tem continually searches, non-hillclimbing manner, improvements domain
theory. summary, work unique provides connectionist approach
attempts effectively utilize available background knowledge available computer cycles
generate best concept possible. broken rest section four parts:
(a) connectionist theory-refinement algorithms, (b) purely symbolic theory-refinement algorithms, (c) algorithms find appropriate domain-specific neural-network topology,
(d) optimization algorithms wrapped around induction algorithms.

7.1 Connectionist Theory-Refinement Techniques

begin discussion connectionist theory-refinement systems. systems
developed refine many types rule bases. instance, number systems
proposed revising certainty-factor rule bases (Fu, 1989; Lacher et al., 1992;
Mahoney & Mooney, 1993), finite-state automata (Maclin & Shavlik, 1993; Omlin & Giles,
1992), push-down automata (Das, Giles, & Sun, 1992), fuzzy-logic rules (Berenji, 1991;
Masuoka, Watanabe, Kawamura, Owada, & Asakawa, 1990), mathematical equations
(Roscheisen, Hofmann, & Tresp, 1991; Scott et al., 1992). systems work like
Kbann first translating domain knowledge neural network, modifying
weights resulting network. attempts (which describe next)
made dynamically adjust resulting network's topology training (as Regent
does).
Like TopGen Regent, Fletcher Obradovic (1993) present approach
adds nodes Kbann network. system constructs single layer nodes, fully
connected input output nodes, \off side" Kbann network.
generate new hidden nodes using variant Baum Lang's (1991) constructive
196

fiConnectionist Theory Refinement

algorithm. Baum Lang's algorithm first divides feature space hyperplanes.
find hyperplane randomly selecting two points different classes,
localizing suitable split points. Baum Lang repeat process
generate fixed number hyperplanes. Fletcher Obradovic map
Baum Lang's hyperplanes one new hidden node, thus defining weights
input layer hidden node. Fletcher Obradovic's algorithm change
weights Kbann portion network, modifications initial rule base
solely left constructed hidden nodes. Thus, system take advantage
Kbann's strength removing unwanted antecedents rules original rule
base. fact, TopGen compared favorably similar technique also added nodes
side Kbann (Opitz & Shavlik, 1993) Regent outperformed TopGen
article's experiments.
Rapture (Mahoney & Mooney, 1994) designed domain theories containing probabilistic rules. Like connectionist theory-refinement systems, Rapture first translates
domain theory neural network, refines weights network
modified backpropagation algorithm. Like Regent, Rapture able dynamically
refine topology network. using Upstart algorithm (Frean,
1990) add new nodes network. Aside designed probabilistic rules,
Rapture differs Regent adds nodes intention completely
learning training set, generalizing well. Thus, Rapture hillclimbs
training set learned, Regent continually searches topology space looking network
minimizes scoring function's error. Also, Rapture initially creates links
specified domain theory, explicitly adds links ID3's (Quinlan,
1986) information-gain metric. Regent, hand, fully connect consecutive layers
networks, allowing rule possibility adding antecedents training.
Daid algorithm (Towell & Shavlik, 1992) extension Kbann uses
domain theory help train Kbann network. Since Kbann effective dropping antecedents adding them, Daid tries find potentially useful inputs features
mentioned domain theory. backing-up errors lowest level
domain theory, computing correlations features. Daid increases
weight links potentially useful input features based correlations.
Daid mainly differs Regent refine topology Kbann network. Thus, Daid addresses Kbann's limitation effectively adding antecedents,
still unable introduce new rules constructively induce new antecedents. Daid
therefore suffer impoverished domain theories. Also notice since Daid improvement training KNNs, Regent use Daid train network considers
search (however, done so).
Opitz Shavlik (1996) used variant Regent learning algorithm
generating neural network \ensemble." neural-network ensemble successful
technique outputs set separately trained neural networks combined
form one unified prediction (Drucker, Cortes, Jackel, LeCun, & Vapnik, 1994; Hansen
& Salamon, 1990; Perrone, 1993). Since Regent considers many networks, select
subset final population networks ensemble minimal extra cost. Previous
work, though, shown ideal ensemble one networks accurate
make errors different parts input space (Hansen & Salamon, 1990;
197

fiOpitz & Shavlik

Krogh & Vedelsby, 1995). result, Opitz Shavlik (1996) changed scoring
function Regent \fit" network one accurate
disagreed members population much possible. addition,
algorithm (Addemup) actively tries generate good candidates emphasizing
current population's erroneous examples backpropagation training. result
alterations, Addemup able create enough diversity among population
networks able effectively exploit knowledge domain theory. Opitz
Shavlik (1996) show Addemup able generate significantly better ensemble
using domain theory either running Addemup without benefit theory
simply combining Regent's final population networks. Actively searching highly
diverse population, however, aid searching single best network. fact,
single best network produced Addemup significantly worse Regent's single
best network three domains.

7.2 Purely Symbolic Theory-Refinement Techniques
Additional work related Regent includes purely symbolic theory-refinement systems
modify domain theory directly initial form. Systems Focl (Pazzani
& Kibler, 1992) Forte (Richards & Mooney, 1995) first-order, theory-refinement
systems revise predicate-logic theories. One drawback systems
currently generalize well connectionist approaches many real-world problems,
DNA promoter task (Cohen, 1992).
several genetic-based, first-order logic, multimodal concept learners
(Greene & Smith, 1993; Janikow, 1993). Giordana Saitta (1993) showed integrate one system, Regal (Giordana, Saitta, & Zini, 1994; Neri & Saitta, 1996),
deductive engine ML-SMART (Bergadano, Giordana, & Ponsero, 1989) help
refine incomplete inconsistent domain theory. version works first using automated theorem prover recognize unresolved literals proof, uses GA-based
Regal induce corrections literals. Regent, hand, use genetic
algorithms (along neural learning) refine whole domain theory time.
Dogma (Hekanaho, 1996) recently proposed GA-based learner use background knowledge learn description language Regal. Current restrictions,
however, force representation language domain theory propositional rules.
Dogma converts \ at" set background rules (i.e., handle intermediate
conclusions) individual bitstrings used building blocks higher-level
concept. Dogma focus theory refinement, rather builds completely new
theory using substructures background knowledge. term approach
theory-suggested theory-guided (Hekanaho, 1996).
Several systems, including ours, proposed refining propositional rule bases.
Early approaches could handle improvements overly specific theories (Danyluk,
1989) specializations overly general theories (Flann & Dietterich, 1989). Later systems
Rtls (Ginsberg, 1990), Either (Ourston & Mooney, 1994), Ptr (Koppel, Feldman,
& Segre, 1994), Tgci (Donoho & Rendell, 1995) later able handle types
refinements. discuss Either system representative propositional
systems.
198

fiConnectionist Theory Refinement

Either four theory-revision operators: (a) removing antecedents rule, (b)
adding antecedents rule, (c) removing rules rule base, (d) inventing new
rules. Either uses operators make revisions domain theory correctly
classify previously misclassified training examples without undefining
correctly classified examples. Either uses inductive learning algorithms invent new
rules; currently uses ID3 (Quinlan, 1986) induction component.
Even though Regent's mutation operator add nodes manner analogous
symbolic system adds antecedents rules, underlying learning algorithm \connectionist." Towell (1991) showed Kbann outperformed Either promoter
task, Regent outperformed Kbann article. Kbann's power domain
largely attributed ability make \fine-grain" refinements domain theory
(Towell, 1991). Either's diculty domain, Baffes Mooney (1993)
presented extension called Neither-MofN able learn -of-N rules {
rules true N antecedents true. improvement generated
concept closely matches Kbann's generalization performance.
want minimize changes theory, want expense accuracy; however, Donoho Rendell (1995) demonstrate existing
theory-refinement systems, Either, suffer able make small,
local changes domain theory. Thus, accurate theory significantly far
structure initial theory, systems forced either become trapped
local maximum similar initial theory, forced drop entire rules replace
new rules inductively created purely scratch. Regent
suffer translates theory less restricting representation
neural networks (Donoho & Rendell, 1995). Also, Regent able reconfigure
structure domain genetic algorithms.
Many authors reported results using varying subsets splice junction domain
(e.g., Donoho Rendell 1995; Mahoney 1996; Neri Saitta 1996, Towell Shavlik 1994). authors used different training set sizes, nevertheless worthwhile
qualitatively discuss conclusions here. Towell Shavlik (1994) compared
Kbann numerous machine learning algorithms learning algorithm
given training set 1000 examples; Kbann's generalization ability compared favorably
algorithms splice domain Regent, turn, compared favorably
Kbann article. Donoho Rendell (1995) showed purely symbolic approach
converged performance Kbann around 200 examples. Mahoney (1996) showed,
using training set sizes 400 examples, Rapture algorithm generalized
better Kbann domain; results look similar Regent. Finally,
Neri Saitta (1996) showed generalization ability GA-based Regal compares favorably purely symbolic, non-GA based techniques; used slightly
different training set sizes article, Regent compares well results
reported paper.

7.3 Finding Appropriate Network Topologies
third area related work covers techniques attempt find good domaindependent topology dynamically refining network's topology training. Many
199

fiOpitz & Shavlik

studies shown generalization ability neural network depends topology network (Baum & Haussler, 1989; Tishby, Levin, & Solla, 1989). trying
find appropriate topology, one approach construct modify topology
incremental fashion. Network-shrinking algorithms start many parameters,
remove nodes weights training (Hassibi & Stork, 1992; Le Cun, Denker, &
Solla, 1989; Mozer & Smolensky, 1989). Network-growing algorithms, hand,
start parameters, add nodes weights training (Blanziere
& Katenkamp, 1996; Fahlman & Lebiere, 1989; Frean, 1990). obvious difference Regent algorithms Regent uses domain knowledge
symbolic rule-refinement techniques help determine network's topology. Also,
algorithms restructure network based solely training-set error, Regent
minimized validation-set error.
Instead incrementally finding appropriate topology, one mount \richer"
search hillclimbing space topologies. One common approach
combine genetic algorithms neural networks (as Regent does). Genetic algorithms
applied neural networks two different ways: (a) optimize connection
weights fixed topology, (b) optimize topology network. Techniques
solely use genetic algorithms optimize weights (Montana & Davis, 1989; Whitley
& Hanson, 1989) performed competitively gradient-based training algorithms;
however, one problem genetic algorithms ineciency fine-tuned local search,
thus scalability methods question (Yao, 1993). Kitano (1990b) presents
method combines genetic algorithms backpropagation. using
genetic algorithm determine starting weights network,
refined backpropagation. Regent differs Kitano's method use domain
theory help determine network's starting weights genetically search, instead,
appropriate network topologies.
methods use genetic algorithms optimize network topology similar
Regent also use backpropagation train network's weights.
methods, many directly encode link network (Miller, Todd, & Hegde,
1989; Oliker, Furst, & Maimon, 1992; Schiffmann, Joost, & Werner, 1992). methods
relatively straightforward implement, good fine tuning small networks
(Miller et al., 1989); however, scale well since require large matrices
represent links large networks (Yao, 1993). techniques (Dodd, 1990;
Harp, Samad, & Guha, 1989; Kitano, 1990a) encode important features
network, number hidden layers, number hidden nodes
layer, etc. indirect encoding schemes evolve different sets parameters along
network's topology shown good scalability (Yao, 1993).
techniques (Koza & Rice, 1991; Oliker et al., 1992) evolve architecture
connection weights time; however, combination two levels evolution
greatly increases search space.
Regent mainly differs genetic-algorithm-based training methods designed knowledge-based neural networks. Thus Regent uses domain-specific knowledge
symbolic rule-refinement techniques aid determining network's topology
initial weight setting. Regent also differs explicitly encode networks;
rather, spirit Lamarkian evolution, passes trained network weights off200

fiConnectionist Theory Refinement

spring. final difference algorithms restructure network
based solely training-set error, Regent minimizes validation-set error.

7.4 Wrapping Optimization Around Learning

end related work discussion brief overview methods combine global
local optimization strategies. Local search algorithms iteratively improve estimate
minimum searching local neighborhood current solution; local minima
guaranteed global minima. (Many inductive learning methods often
equated local optimization techniques; Rumelhart et al., 1986.) Global optimization
methods (such GAs), hand, perform sophisticated search across
multiple local minima good finding regions search space nearoptimal solutions found; however, usually good refining solution
(once close near-optimal solution) local optimization strategies (Hart, 1994).
Recent research shown desirable emply global local search
strategy (Hart, 1994).
Hybrid GAs (such Regent) combine local search traditional GA.
focus hybrid-GA algorithms section, two-tiered search strategy
employed researchers well (Kohavi & John, 1997; Provost & Buchanan, 1995;
Schaffer, 1993). GAs combined many local search methods (Bala, Huang,
Vafaie, DeJong, & Wechsler, 1995; Belew, 1990; Hinton & Nowlan, 1987; Turney, 1995).
Neural networks common choice local search strategy hybrid GA
systems discussed GA/neural-network hybrids Section 7.3. two
common forms hybrid GAs: Lamarckian-based evolution Darwinian-based evolution (the Baldwin effect). Lamarckian evolution encodes local improvements directly
genetic material, Darwinian evolution leaves genetic material unchanged
learning. discussed Section 6, authors use Lamarckian local search techniques many shown numerous cases Lamarckian evolution outperforms
non-Lamarckian local search (Belew, McInerney, & Schraudolph, 1992; Hart, 1994; Judson,
Colvin, Meza, Huffa, & Gutierrez, 1992).

8. Conclusion

ideal inductive-learning algorithm able exploit available resources
extensive computing power domain-specific knowledge improve ability generalize. Kbann (Towell & Shavlik, 1994) shown effective translating
domain theory neural network; however, Kbann suffers alter
topology. TopGen (Opitz & Shavlik, 1995) improved Kbann algorithm using
available computer power search effective places add nodes Kbann network;
however, show empirically TopGen suffers restricting search expansions
Kbann network, unable improve performance searching beyond
topologies. Therefore TopGen unable exploit available computing power
increase correctness induced concept.
present new algorithm, Regent, uses specialized genetic algorithm
broaden types topologies considered TopGen's search. Experiments indicate
Regent able significantly increase generalization TopGen; hence, new
201

fiOpitz & Shavlik

algorithm successful overcoming TopGen's limitation searching small portion
space possible network topologies. so, Regent able generate
good solution quickly, using Kbann, able continually improve solution
searches concept space. Therefore, Regent takes step toward true anytime theory
refinement system able make effective use problem-specific knowledge
available computing cycles.

Acknowledgements
work supported Oce Naval Research grant N00014-93-1-0998 National
Science Foundation grant IRI 95-02990. Thanks Richard Maclin, Richard Sutton,
three anonymous reviewers helpful comments. extended version
paper published Machine Learning: Proceedings Eleventh International Conference,
pp. 208-216, New Brunswick, NJ, Morgan Kaufmann. David Opitz completed portion
work graduate student University Wisconsin professor
University Minnesota, Duluth.

References
Ackley, D. (1987). Connectionist Machine Genetic Hillclimbing. Kluwer, Norwell,
MA.
Ackley, D., & Littman, M. (1992). Interactions learning evolution. Langton,
C., Taylor, C., Farmer, C., & Rasmussen, S. (Eds.), Artificial Life II, pp. 487{509,
Redwood City, CA. Addison-Wesley.
Ackley, D., & Littman, M. (1994). case Lamarckian evolution. Langton, C. (Ed.),
Artificial Life III, pp. 3{10, Redwood City, CA. Addison-Wesley.
Baffes, P., & Mooney, R. (1993). Symbolic revision theories M-of-N rules.
Proceedings Thirteenth International Joint Conference Artificial Intelligence,
pp. 1135{1140, Chambery, France. Morgan Kaufmann.
Bala, J., Huang, J., Vafaie, H., DeJong, K., & Wechsler, H. (1995). Hybrid learning using
genetic algorithms decision trees pattern classification. Proceedings
Fourteenth International Joint Conference Artificial Intelligence, pp. 719{724,
Montreal, Canada. Morgan Kaufmann.
Baldwin, J. (1896). Physical social heredity. American Naturalist, 30, 441{451.
Baum, E., & Haussler, D. (1989). size net gives valid generalization? Neural Computation, 1, 151{160.
Baum, E., & Lang, K. (1991). Constructing hidden units using examples queries.
Lippmann, R., Moody, J., & Touretzky, D. (Eds.), Advances Neural Information
Processing Systems, Vol. 3, pp. 904{910, San Mateo, CA. Morgan Kaufmann.
202

fiConnectionist Theory Refinement

Belew, R. (1990). Evolution, learning culture: Computational metaphors adaptive
search. Complex Systems, 4, 11{49.
Belew, R., McInerney, J., & Schraudolph, N. (1992). Evolving networks: Using genetic
algorithm connectionist learning. Langton, C., Taylor, C., Farmer, C., &
Rasmussen, S. (Eds.), Artificial Life II, pp. 511{547, Redwood City, CA. AddisonWesley.
Belew, R., & Mitchell, M. (1996). Adaptive Individuals Evolving Populations: Models
Algorithms. Addison-Wesley, Massachusetts.
Berenji, H. (1991). Refinement approximate reasoning-based controllers reinforcement
learning. Proceedings Eighth International Machine Learning Workshop, pp.
475{479, Evanston, IL. Morgan Kaufmann.
Bergadano, F., Giordana, A., & Ponsero, S. (1989). Deduction top-down inductive
learning. Proceedings Sixth International Workshop Machine Learning,
pp. 23{25, Ithaca, NY. Morgan Kaufmann.
Blanziere, E., & Katenkamp, P. (1996). Learning radial basis function networks on-line.
Proceedings Thirteenth International Conference Machine Learning, pp.
37{45, Bari, Italy. Morgan Kaufmann.
Clocksin, W., & Mellish, C. (1987). Programming Prolog. Springer-Verlag, New York.
Cohen, W. (1992). Compiling prior knowledge explicit bias. Proceedings
Ninth International Conference Machine Learning, pp. 102{110, Aberdeen,
Scotland. Morgan Kaufmann.
Danyluk, A. (1989). Finding new rules incomplete theories: Explicit biases induction
contextual information. Proceedings Sixth International Workshop
Machine Learning, pp. 34{36, Ithaca, NY. Morgan Kaufmann.
Das, A., Giles, C., & Sun, G. (1992). Using prior knowledge NNPDA learn
context-free languages. Hanson, S., Cowan, J., & Giles, C. (Eds.), Advances
Neural Information Processing Systems, Vol. 5, pp. 65{72, San Mateo, CA. Morgan
Kaufmann.
Dean, T., & Boddy, M. (1988). analysis time-dependent planning. Proceedings
Seventh National Conference Artificial Intelligence, pp. 49{54, St. Paul, MN.
Morgan Kaufmann.
DeJong, K. (1975). Analysis Behavior class Genetic Adaptive Systems.
Ph.D. thesis, University Michigan, Ann Arbor, MI.
Dodd, N. (1990). Optimization network structure using genetic techniques. Proceedings
IEEE International Joint Conference Neural Networks, Vol. III, pp. 965{970,
Paris. IEEE Press.
203

fiOpitz & Shavlik

Donoho, S., & Rendell, L. (1995). Rerepresenting restructuring domain theories:
constructive induction approach. Journal Artificial Intelligence Research, 2, 411{
446.
Drucker, H., Cortes, C., Jackel, L., LeCun, Y., & Vapnik, V. (1994). Boosting
machine learning algorithms. Proceedings Eleventh International Conference
Machine Learning, pp. 53{61, New Brunswick, NJ. Morgan Kaufmann.
Fahlman, S., & Lebiere, C. (1989). cascade-correlation learning architecture. Touretzky, D. (Ed.), Advances Neural Information Processing Systems, Vol. 2, pp. 524{
532, San Mateo, CA. Morgan Kaufmann.
Farmer, J., & Belin, A. (1992). Artificial life: coming evolution. Langton, C., Taylor,
C., Farmer, J. D., & Rasmussen, S. (Eds.), Artificial Life II, pp. 815{840, Redwood
City, CA. Addison-Wesley.
Flann, N., & Dietterich, T. (1989). study explanation-based methods inductive
learning. Machine Learning, 4, 187{226.
Fletcher, J., & Obradovic, Z. (1993). Combining prior symbolic knowledge constructive
neural network learning. Connection Science, 5, 365{375.
Forrest, S., & Mitchell, M. (1993). makes problem hard genetic algorithm?
anomalous results explanation. Machine Learning, 13, 285{319.
Frean, M. (1990). upstart algorithm: method constructing training feedforward neural networks. Neural Computation, 2, 198{209.
Fu, L. (1989). Integration neural heuristics knowledge-based inference. Connection
Science, 1, 325{340.
Ginsberg, A. (1990). Theory reduction, theory revision, retranslation. Proceedings
Eighth National Conference Artificial Intelligence, pp. 777{782, Boston, MA.
AAAI/MIT Press.
Giordana, A., & Saitta, L. (1993). REGAL: integrated system relations using genetic
algorithms. Proceedings Second International Workshop Multistrategy
Learning, pp. 234{249, Harpers Ferry, WV.
Giordana, A., Saitta, L., & Zini, F. (1994). Learning disjunctive concepts means genetic algorithms. Proceedings Eleventh International Conference Machine
Learning, pp. 96{104, New Brunswick, NJ. Morgan Kaufmann.
Goldberg, D. (1989). Genetic Algorithms Search, Optimization, Machine Learning.
Addison-Wesley, Reading, MA.
Greene, D., & Smith, S. (1993). Competition-based induction decision models
examples. Machine Learning, 13, 229{258.
204

fiConnectionist Theory Refinement

Grefenstette, J., & Ramsey, C. (1992). approach anytime learning. Proceedings
Ninth International Conference Machine Learning, pp. 189{195, Aberdeen,
Scotland. Morgan Kaufmann.
Hansen, L., & Salamon, P. (1990). Neural network ensembles. IEEE Transactions
Pattern Analysis Machine Intelligence, 12, 993{1001.
Harp, S., Samad, T., & Guha, A. (1989). Designing application-specific neural networks
using genetic algorithm. Touretzky, D. (Ed.), Advances Neural Information
Processing Systems, Vol. 2, pp. 447{454, San Mateo, CA. Morgan Kaufmann.
Hart, W. (1994). Adaptive Global Optimization Local Search. Ph.D. thesis, University
California, San Diego.
Hassibi, B., & Stork, D. (1992). Second order derivatives network pruning: Optimal brain
surgeon. Hanson, S., Cowan, J., & Giles, C. (Eds.), Advances Neural Information
Processing Systems, Vol. 5, pp. 164{171, San Mateo, CA. Morgan Kaufmann.
Hekanaho, J. (1996). Background knowledge GA-based concept learning. Proceedings
Thirteenth International Conference Machine Learning, pp. 234{242, Bari,
Italy. Morgan Kaufmann.
Hinton, G., & Nowlan, S. (1987). learning guide evolution. Complex Systems, 1,
495{502.
Holder, L. (1991). Maintaining Utility Learned Knowledge Using Model-Based Control. Ph.D. thesis, Computer Science Department, University Illinois UrbanaChampaign.
Holland, J. (1975). Adaptation Natural Artificial Systems. University Michigan
Press, Ann Arbor, MI.
Janikow, C. (1993). knowledge intensive GA supervised learning. Machine Learning,
13, 198{228.
Judson, R., Colvin, M., Meza, J., Huffa, A., & Gutierrez, D. (1992). intelligent configuration search techniques outperform random search large molecules? International
Journal Quantum Chemistry, 277{290.
Kibler, D., & Langley, P. (1988). Machine learning experimental science. Proceedings Third European Working Session Learning, pp. 1{12, Edinburgh,
UK.
Kitano, H. (1990a). Designing neural networks using genetic algorithms graph generation system. Complex Systems, 4, 461{476.
Kitano, H. (1990b). Empirical studies speed convergence neural network training using genetic algorithms. Proceedings Eighth National Conference
Artificial Intelligence, pp. 789{795, Boston, MA. AAAI/MIT Press.
205

fiOpitz & Shavlik

Kohavi, R., & John, G. (1997). Wrappers feature subset selection. Artificial Intelligence.
Koppel, M., Feldman, R., & Segre, A. (1994). Bias-driven revision logical domain theories.
Journal Artificial Intelligence Research, 1, 159{208.
Koza, J. (1992). Genetic Programming. MIT Press, Cambridge, MA.
Koza, J., & Rice, J. (1991). Genetic generation weights architectures
neural network. International Joint Conference Neural Networks, Vol. 2, pp.
397{404, Seattle, WA. IEEE Press.
Krogh, A., & Vedelsby, J. (1995). Neural network ensembles, cross validation, active
learning. Tesauro, G., Touretzky, D., & Leen, T. (Eds.), Advances Neural
Information Processing Systems, Vol. 7, pp. 231{238, Cambridge, MA. MIT Press.
Lacher, R., Hruska, S., & Kuncicky, D. (1992). Back-propagation learning expert networks. IEEE Transactions Neural Networks, 3, 62{72.
Le Cun, Y., Denker, J., & Solla, S. (1989). Optimal brain damage. Touretzky, D. (Ed.),
Advances Neural Information Processing Systems, Vol. 2, pp. 598{605, San Mateo,
CA. Morgan Kaufmann.
Litzkow, M., Livny, M., & Mutka, M. (1988). Condor | hunter idle workstations.
Proceedings Eighth International Conference Distributed Computing Systems,
pp. 104{111, San Jose, CA. Computer Society Press.
MacKay, D. (1992). practical Bayesian framework backpropagation networks. Neural
Computation, 4, 448{472.
Maclin, R., & Shavlik, J. (1993). Using knowledge-based neural networks improve algorithms: Refining Chou-Fasman algorithm protein folding. Machine Learning,
11, 195{215.
Mahoney, J. (1996). Combining Symbolic Connectionist Learning Methods Refine
Certainty-Factor Rule-Bases. Ph.D. thesis, University Texas, Austin, TX.
Mahoney, J., & Mooney, R. (1993). Combining connectionist symbolic learning refine
certainty-factor rule-bases. Connection Science, 5, 339{364.
Mahoney, J., & Mooney, R. (1994). Comparing methods refining certainty-factor rulebases. Proceedings Eleventh International Conference Machine Learning,
pp. 173{180, New Brunswick, NJ. Morgan Kaufmann.
Masuoka, R., Watanabe, N., Kawamura, A., Owada, Y., & Asakawa, K. (1990). Neurofuzzy
system | fuzzy inference using structured neural network. Proceedings
International Conference Fuzzy Logic & Neural Networks, pp. 173{177, Iizuka,
Japan.
Michalski, R. (1983). theory methodology inductive learning. Artificial Intelligence,
20, 111{161.
206

fiConnectionist Theory Refinement

Miller, G., Todd, P., & Hegde, S. (1989). Designing neural networks using genetic algorithms. Proceedings Third International Conference Genetic Algorithms,
pp. 379{384, Arlington, VA. Morgan Kaufmann.
Mitchell, M. (1996). Introduction Genetic Algorithms. MIT Press, Cambridge, MA.
Mitchell, T. (1982). Generalization search. Artificial Intelligence, 18, 203{226.
Montana, D., & Davis, L. (1989). Training feedforward networks using genetic algorithms.
Proceedings Eleventh International Joint Conference Artificial Intelligence,
pp. 762{767, Detroit, MI. Morgan Kaufmann.
Moody, J. (1991). effective number parameters: analysis generalization
regularization nonlinear learning systems. Moody, J., Hanson, S., & Lippmann,
R. (Eds.), Advances Neural Information Processing Systems, Vol. 4, pp. 847{854,
San Mateo, CA. Morgan Kaufmann.
Mozer, M. C., & Smolensky, P. (1989). Using relevance reduce network size automatically.
Connection Science, 1, 3{16.
Neri, F., & Saitta, L. (1996). Exploring power genetic search learning symbolic
classifiers. IEEE Transactions Pattern Analisys Machine Intelligence.
Oliker, S., Furst, M., & Maimon, O. (1992). distributed genetic algorithm neural
network design training. Complex Systems, 6, 459{477.
Omlin, C., & Giles, C. (1992). Training second-order recurrent neural networks using hints.
Proceedings Ninth International Conference Machine Learning, pp. 361{
366, Aberdeen, Scotland. Morgan Kaufmann.
Opitz, D., & Shavlik, J. (1993). Heuristically expanding knowledge-based neural networks.
Proceedings Thirteenth International Joint Conference Artificial Intelligence, pp. 1360{1365, Chambery, France. Morgan Kaufmann.
Opitz, D., & Shavlik, J. (1995). Dynamically adding symbolically meaningful nodes
knowledge-based neural networks. Knowledge-Based Systems, 8, 301{311.
Opitz, D., & Shavlik, J. (1996). Actively searching effective neural-network ensemble.
Connection Science, 8, 337{353.
Ourston, D., & Mooney, R. (1994). Theory refinement combining analytical empirical
methods. Artificial Intelligence, 66, 273{309.
Pazzani, M., & Kibler, D. (1992). utility knowledge inductive learning. Machine
Learning, 9, 57{94.
Perrone, M. (1993). Improving Regression Estimation: Averaging Methods Variance
Reduction Extension General Convex Measure Optimization. Ph.D. thesis,
Brown University, Providence, RI.
207

fiOpitz & Shavlik

Provost, F., & Buchanan, B. (1995). Inductive policy: pragmatics bias selection.
Machine Learning, 20, 35{61.
Quinlan, J. (1986). Induction decision trees. Machine Learning, 1, 81{106.
Quinlan, J., & Cameron-Jones, R. (1995). Lookahead pathology decision tree induction. Proceedings Fourteenth International Joint Conference Artificial
Intelligence, pp. 1019{1024, Montreal, Canada. Morgan Kaufmann.
Richards, B., & Mooney, R. (1995). Automated refinement first-order Horn-clause domain
theories. Machine Learning, 19, 95{131.
Roscheisen, M., Hofmann, R., & Tresp, V. (1991). Neural control rolling mills: Incorporating domain theories overcome data deficiency. Moody, J., Hanson, S., &
Lippmann, R. (Eds.), Advances Neural Information Processing Systems, Vol. 4, pp.
659{666, San Mateo, CA. Morgan Kaufmann.
Rumelhart, D., Hinton, G., & Williams, R. (1986). Learning internal representations
error propagation. Rumelhart, D., & McClelland, J. (Eds.), Parallel Distributed
Processing: Explorations microstructure cognition. Volume 1: Foundations,
pp. 318{363. MIT Press, Cambridge, MA.
Schaffer, C. (1993). Selecting classification method cross-validation. Machine Learning,
13, 135{143.
Schiffmann, W., Joost, M., & Werner, R. (1992). Synthesis performance analysis
multilayer neural network architectures. Tech. rep. 16, University Koblenz, Institute
Physics.
Scott, G., Shavlik, J., & Ray, W. (1992). Refining PID controllers using neural networks.
Neural Computation, 5, 746{757.
Tishby, N., Levin, E., & Solla, S. (1989). Consistent inference probabilities layered
networks, predictions generalization. International Joint Conference Neural
Networks, pp. 403{410, Washington, D.C. IEEE Press.
Towell, G. (1991). Symbolic Knowledge Neural Networks: Insertion, Refinement,
Extraction. Ph.D. thesis, Computer Sciences Department, University Wisconsin,
Madison, WI.
Towell, G., & Shavlik, J. (1992). Using symbolic learning improve knowledge-based neural
networks. Proceedings Tenth National Conference Artificial Intelligence,
pp. 177{182, San Jose, CA. AAAI/MIT Press.
Towell, G., & Shavlik, J. (1994). Knowledge-based artificial neural networks. Artificial
Intelligence, 70, 119{165.
Turney, P. (1995). Cost-sensitive classification: Empirical evaluation hybrid genetic
decision tree induction algorithm. Journal Artificial Intelligence Research, 2, 369{
409.
208

fiConnectionist Theory Refinement

Waterman, D. (1986). Guide Expert Systems. Addison Wesley, Reading, MA.
Watrous, R., Towell, G., & Glassman, M. (1993). Synthesize, optimize, analyze, repeat
(SOAR): Application neural network tools ECG patient monitoring. Proceedings Symposium Nonlinear Theory Applications, pp. 565{570,
Honolulu, Hawaii.
Watson, J. D., Hopkins, N. H., Roberts, J. W., Argetsinger-Steitz, J., & Weiner, A. M.
(1987). Molecular Biology Gene (Fourth edition). Benjamin/Cummings, Menlo
Park, CA.
Weigend, A. (1993). overfitting effective number hidden units. Proceedings 1993 Connectionist Models Summer School, pp. 335{342, Boulder, CO.
Lawrence Erlbaum Associates.
Weigend, A., Huberman, B., & Rumelhart, D. (1990). Predicting future: connectionist
approach. International Journal Neural Systems, I, 193{209.
Whitley, D., Gordon, S., & Mathias, K. (1994). Lamarckian evolution, Baldwin effect
function optimization. Davidor, Y., Schwefel, H., & Manner, R. (Eds.), Parallel
Problem Solving Nature - PPSN III, pp. 6{15. Springer-Verlag.
Whitley, D., & Hanson, T. (1989). Optimizing neural networks using faster, accurate genetic search. Proceedings Third International Conference Genetic
Algorithms, pp. 391{396, Arlington, VA. Morgan Kaufmann.
Yao, X. (1993). Evolutionary artificial neural networks. International Journal Neural
Systems, 4, 203{221.

209

fiJournal Artificial Intelligence Research 6 (1997) 223-262

Submitted 2/97; published 6/97

Flaw Selection Strategies Partial-Order Planning

Martha E. Pollack

Department Computer Science Intelligent Systems Program,
University Pittsburgh, Pittsburgh, PA 15260 USA

David Joslin

Computational Intelligence Research Laboratory,
University Oregon, Eugene, 97403 USA

pollack@cs.pitt.edu
joslin@cirl.uoregon.edu

Massimo Paolucci

Intelligent Systems Program,
University Pittsburgh, Pittsburgh, PA 15260 USA

paolucci@pitt.edu

Abstract

Several recent studies compared relative eciency alternative aw selection
strategies partial-order causal link (POCL) planning. review literature,
present new experimental results generalize earlier work explain
discrepancies it. particular, describe Least-Cost Flaw Repair (LCFR) strategy
developed analyzed Joslin Pollack (1994), compare strategies,
including Gerevini Schubert's (1996) ZLIFO strategy. LCFR ZLIFO make
different, apparently con icting claims effective way reduce searchspace size POCL planning. resolve con ict, arguing much benefit
Gerevini Schubert ascribe LIFO component ZLIFO strategy better
attributed causes. show many problems, strategy combines
least-cost aw selection delay separable threats effective reducing
search-space size, without excessive computational overhead. Although
strategy thus provides good default, also show certain domain characteristics
may reduce effectiveness.

1. Introduction
Much current research plan generation centers partial-order causal link (POCL)
algorithms, descend McAllester Rosenblitt's (1991) SNLP algorithm. POCL
planning involves searching space partial plans, successors node
representing partial plan P refinements P . search problem, POCL
planning requires effective search control strategies.
POCL planning, search control two components. first, node selection, involves choosing partial plan refine next. partial plan selected
refinement, planner must perform aw selection, involves choosing either
threat resolve open condition establish.
past years, several studies compared relative eciency alternative aw selection strategies POCL planning extensions (Peot & Smith, 1993;
Joslin & Pollack, 1994; Srinivasan & Howe, 1995; Gerevini & Schubert, 1996; Williamson &
Hanks, 1996). studies motivated least part tension
attractive formal properties POCL algorithms, limitations putting

c 1997 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiPollack, Joslin, & Paolucci
practical use result relatively poor performance. date, POCL
algorithms cannot match eciency so-called industrial-strength planners
SIPE (Wilkins, 1988; Wilkins & Desimone, 1994) O-Plan (Currie & Tate, 1991; Tate,
Drabble, & Dalton, 1994). Flaw selection strategy shown significant
effect eciency POCL planning algorithms, thus researchers viewed
design improved aw selection strategies one means making POCL planning
algorithms practical.
paper, review literature aw selection strategies, present new
experimental results generalize earlier work explain discrepancies
it. particular, describe Least-Cost Flaw Repair (LCFR) strategy developed
analyzed Joslin Pollack (1994), compare strategies, including
Gerevini Schubert's ZLIFO strategy (1996). LCFR ZLIFO make different,
apparently con icting claims effective way reduce search-space size
POCL planning. resolve con ict, arguing much benefit Gerevini
Schubert ascribe LIFO component ZLIFO strategy better attributed
causes. show many problems, strategy combines least-cost aw
selection delay separable threats effective reducing search-space size,
without excessive computational overhead. Although strategy thus
provides good default, also show certain domain characteristics may reduce
effectiveness.

2. Background
2.1 Node Flaw Selection

Although main ideas POCL planning literature
two decades, serious efforts comparing alternative plan generation algorithms
relatively recent. made comparisons possible development set
clear algorithms provable formal properties, notably TWEAK (Chapman, 1987),
SNLP (McAllester & Rosenblitt, 1991). algorithms intended add
functionality known planning methods, rather capture essential elements
known methods readily analyzable fashion.
analyzing POCL algorithms, researchers found useful decouple search
control strategy underlying plan refinement process. Figure 1 generic POCL
algorithm, highlight two search decisions.1 Following convention, use
CHOOSE indicate node selection backtracking point, SELECT indicate
aw selection not. given node may lead solution, may necessary
backtrack consider alternative nodes. hand, node lead
solution, solution found regardless order aws selected.
See Weld's (1994) tutorial paper discussion difference.
generic algorithm sketched figure must supplemented search strategies
implement CHOOSE SELECT operators. POCL algorithms perform
node selection using best-first ranking computes function number
1. Various versions well-known algorithm appeared literature (Weld, 1994; Russell &
Norvig, 1995; Kambhampati, Knoblock, & Yang, 1995). version give corresponds directly
given Williamson Hanks (1996).

224

fiFlaw Selection Strategies

POCL (init,goal)

dummy-plan make-skeletal-plan(init,goal).
nodes f dummy-plan g.
nodes empty do:

CHOOSE (and remove) partial plan P nodes. (Node Selection)
P aws
return P
else do:

SELECT aw P. (Flaw Selection)

Add refinements P nodes.
Return failure (because nodes become empty without aw-free plan found.)
Figure 1: Basic POCL Planning Algorithm
steps (denoted ), open conditions (OC ), unsafe conditions (UC , i.e., threats)
partial plan. Gerevini Schubert (1996) argued that, general, steps
open conditions included ranking function, adopt strategy
experiments, except otherwise indicated.
chosen node, POCL planning algorithm must select aw|open condition threat|within node repair. Open conditions repaired establishment,
consists either adding new step unifying condition effect (along
causal link new step condition), else simply adding new
causal link existing step unifying effect. use term repair cost
denote number possible ways repair aw.
open condition o, repair cost R(o) + + N ,

= number conditions initial state unify given
current binding constraints,
= number conditions effects existing plan steps unify
given current binding constraints, counting existing plan
steps constrained occur step associated o,
N = number conditions effects operators library
unify given current binding constraints.
Note time, repair cost open condition resolved may either
increase, new steps might achieve condition added plan, decrease,
steps already plan constrained temporal ordering variable binding
longer achieve condition.
considering cost threat repair, useful distinguish nonseparable
separable threats. Nonseparable threats consist step S1 effect E ,
causal link S2; F; S3 , E F complementary literals necessarily unify:
either complementary ground literals (E :F ), else complementary
literals E 's variables identical with, forced binding constraint
225

fiPollack, Joslin, & Paolucci
equivalent variable position F (e.g., E = p(x; ) F = :p(x; z ),
currently binding constraint = z ).2
Nonseparable threats repaired two ways: promoting S1, requiring
occur S3 , demoting it, requiring occur S2 . course, already
existing temporal ordering constraints may block one repair options,
two possible repairs.3 time, repair cost unresolved
nonseparable threat decrease.
separable threat consists step S1 effect E , causal link S2 ; F; S3 ,
E F complementary literals unified, unification
forced (e.g., E = p(x) F = p(y ) exist binding
constraint x = ). circumstances, threat may disappear subsequent variable
binding blocks unification. (A nonseparable threat may also disappear subsequent
ordering constraint effect imposing promotion demotion.) repair cost
separable threat may higher nonseparable threat:
promotion demotion used, separation, involves forcing variable
binding blocks unification. Separation introduce one repair unbound
variable threat. example, effect P (x; y; z ) threatens S2 ; :P (t; u; v ); S3 ,
three possible repairs: x 6= t, 6= u, z 6= v . nonseparable threats,
repair cost separable threat remains unresolved decrease time.

2.2 Notation

aw selection strategies discussed literature typically
given idiosyncratic names (e.g., DUnf, LCFR, ZLIFO). useful, comparing them,
precise unifying notation. therefore specify aw strategy sequence
preferences. strategy begins attempting find aw satisfies first preference;
unable so, looks aw satisfies second preference;
on. ensure POCL algorithm using strategy complete, sequence
preferences must exhaustive: every aw must satisfy preference. aw satisfies
one preference strategy, assume first match counts.
principle, preference could identify feature aw. practice, however, aw
selection strategies made use small number features: type aw
(open condition, nonseparable threat, separable threat), number ways
repaired, time introduced plan. Often, one aw
given feature, case tie-breaking strategy may specified choosing
among relevant aws.
therefore describe preference using following notation

f aw typesgrepair cost rangetie-breaking strategy
2. alternative approach also treats cases E F threats; required make planner
systematic, i.e., guaranteed never generate node (McAllester & Rosenblitt,
1991).
3. Conditional planners make use additional method threat resolution|confrontation|but
ignore within paper (Peot & Smith, 1992; Etzioni, Hanks, Weld, Draper, Lesh, & Williamson,
1992). Joslin (1996) provides detailed account generalizing treatment aws types
planning decisions.

226

fiFlaw Selection Strategies
indicates preference aw f specified type types, provided
repair cost f falls within range values specified. (If restrictions
repair cost, omit repair cost range.) one aw meets criteria,
tie-breaking strategy applied select among them.
abbreviate aw type \o" (for open condition), \n" (for nonseparable threat),
\s" (for separable threat). also use abbreviations common tie-breaking strategies,
e.g., \LC" (least (repair) cost), \LIFO" \R" (Random). case LC, choice
must made aws repair cost, LIFO selection used.
Thus, example
fng0-1R
specifies preference nonseparable threats repair cost zero one;
one aw meets conditions, random selection made among them. use
term forced describe aws repair cost one less.
example complete aw selection strategy then:
fng0-1R / fogLIFO / fn,sgR
strategy would begin looking forced nonseparable threat; one aw
meets criterion, strategy would select randomly among them. forced
nonseparable threats, would look open condition, repair cost, using
LIFO scheme select among them. Finally, neither forced nonseparable threats
open conditions, would randomly select either unforced nonseparable threat
separable threat.
distinguished aw type maximum repair cost, one
hand, tie-breaking strategy, other, easy describe strategies use
something aw type main criterion selection. example, pure
LIFO selection strategy would encoded follows. (Henceforth, give name
strategy boldface preceding specification.)
LIFO fo,n,sgLIFO

3. Flaw Selection Strategies

begin reviewing aw selection strategies proposed studied
literature date.

3.1 Threat Preference Delay

original SNLP algorithm (McAllester & Rosenblitt, 1991) adopted aw selection
strategy threats resolved open conditions, early versions
widely used UCPOP planning system (Penberthy & Weld, 1992) same.4 SNLP
specify principle selecting among multiple threats multiple opens; UCPOP
used LIFO purpose. Employing notation above, describe basic
UCPOP strategy as:
4. current version UCPOP (v.4), aw selection strategy run default DSep
strategy, discussed below. historical reasons, maintain name DSep strategy,
use UCPOP older default strategy.

227

fiPollack, Joslin, & Paolucci

UCPOP fn,sgLIFO / fogLIFO
first study alternative aw selection strategies done Peot Smith (1993),
relaxed requirement threats always resolved open conditions,
examined several strategies delaying resolution threats. analyzed five
different strategies delaying repair threats; these, two provably superior:
DSep DUnf.
DSep (Delay Separable Threats) motivated observation sometimes separable threats simply disappear planning process blocking variable bindings
introduced. pointed earlier, nonseparable threats may also \disappear",
typically less frequent. Moreover, resolution threats|separable
nonseparable|were delayed, nonseparable threats would disappear early side
effect step reuse, making disappearance even less frequent.
DSep strategy therefore defers repair separable threats end
planning process. However, like UCPOP, continues give preference nonseparable
threats:
DSep fngLIFO / fogLIFO / fsgLIFO
Actually, Peot Smith specify tie-breaking strategy choosing among multiple
threats; indicated LIFO. explored three different tie-breaking
strategies selecting open conditions (FIFO, LIFO, least-cost); list LIFO,
one also specify alternatives:
DSep-LC fngLIFO / fogLC / fsgLIFO
DSep-FIFO fngLIFO / fogFIFO / fsgLIFO
Peot Smith prove search space generated POCL planner using DSep
never larger search space generated using UCPOP strategy. result
holds tie-breaking strategy open conditions LIFO FIFO, LC,
point return later paper.
Peot Smith's second successful strategy DUnf (Delay Unforced Threats). makes
use notion forced aws. stated earlier, aw forced
one possible way repair it. DUnf strategy delays repair unforced threats:
DUnf fn,sg0LIFO / fn,sg1LIFO / fogLIFO / fn,sg2-1LIFO
define DUnf-LC DUnf-FIFO manner analogous used DSep-LC
DSep-FIFO:
DUnf-LC fn,sg0LIFO / fn,sg1LIFO / fogLC / fn,sg2-1LIFO
DUnf-FIFO fn,sg0LIFO / fn,sg1LIFO / fogFIFO / fn,sg2-1LIFO
Peot Smith proved DUnf strategy would never generate larger search
space either remaining two strategies examined. also proved
DSep DUnf incomparable: exist planning problems DSep
generates smaller search space DUnf, problems reverse
true.
228

fiFlaw Selection Strategies
Peot Smith support theoretical results DSep DUnf experiments
showing that, least domains examined, strategies result significant decrease search-space size. decrease search correlated diculty
problem, consequently, problems get dicult, strategies reduce
search time well space. is, large enough problems, \pay for"
overhead.
follow-on work, Peot Smith (1994) describe strategy called DMin, generates smaller search spaces DSep DUnf. DMin combines process pruning
dead-end nodes process aw selection. gives preference forced threats.
forced threats, checks see whether remaining nonseparable threats
could repaired simultaneously. so, leaves threats, selects open condition repair; open conditions, presumably selects remaining
unforced threat repair. hand, impossible repair unforced,
nonseparable threats, node dead end, pruned search
space. Note dead-end nodes recognized immediately, even without
complete consistency checking DMin. unrepairable aw cannot
subsequently become repairable, hence, node containing aw repair cost zero
dead end. Consequently, aw selection strategies give highest priority
aws (Joslin & Pollack, 1996; Joslin, 1996).

3.2 Least-Cost Flaw Repair

Peot Smith's work provided foundation subsequent exploration leastcost aw repair (LCFR) strategy (Joslin & Pollack, 1994). hypothesized power
DUnf strategy might come relative ordering threats open conditions, instead fact DUnf effect imposing partial preference
least-cost aw selection. DUnf always prefer forced threat, which, definition
repair cost one; thus, cases forced threat, DUnf
make low-cost selection. cases forced threats?
DUnf select among open conditions, assuming any. hypothesis correct, version DUnf makes selection using least-cost strategy (i.e.,
DUnf-LC) ought perform better version uses one strategies (i.e.,
bare DUnf DUnf-FIFO). fact, selection low-cost repairs causing
search-space reduction, idea treating threat resolution differently open
condition establishment ought abandoned. Instead, strategy always selects
aw minimal repair cost, regardless whether threat open condition,
ought show best performance. Least-Cost Flaw Repair (LCFR) strategy:5

LCFR fo,n,sgLC
strong similarities LCFR certain heuristics proposed studied literature constraint satisfaction problems (CSPs).
perhaps surprising, given aw selection POCL planning corresponds
5. LCFR strategy similar branch-1/branch-n search heuristics included O-Plan system
(Currie & Tate, 1991). contribution original work topic isolate strategy
examine detail.

229

fiPollack, Joslin, & Paolucci
fairly strong ways variable selection constraint programming. Flaws POCL planner represent decisions yet made, must made plan
complete; unbound variables play similar role constraint satisfaction problems
(CSPs).6 Although exist number heuristics selecting variable branch
solving CSP (Kumar, 1992), one well-known heuristic often quite effective
fail first principle, picks variable \most constrained" selecting
variable branch on. simple common implementation fail first principle
selects variable smallest domain (Tsang, 1993).
intuition behind fail first principle one prune dead-end regions
search early possible. unbound variables tightly constrained
likely points current partial solution \brittle" sense,
branching variables hope find contradiction (if one exists) quickly.
Similarly, LCFR thought selecting \most constrained" aws, resulting
better pruning.
similar heuristic also adopted recent work controlling search hierarchical task network (HTN) planning, Dynamic Variable Commitment Strategy (DVCS). DVCS, like LCFR, based minimal-branching heuristic. Experimental
analyses demonstrate DVCS generally produces well-focused search (Tsuneto, Erol,
Hendler, & Nau, 1996).
initial experimental results, presented Joslin Pollack (1994), similarly
supported hypothesis uniform least-cost aw repair strategy could highly
effective reducing size search space POCL planning. experiments,
compared LCFR four strategies: UCPOP, DUnf, DUnf-LC, defined
above, new strategy, UCPOP-LC previously called LCOS (Joslin & Pollack,
1994):
UCPOP-LC fn,sgLIFO / fogLC
included UCPOP-LC help verify search-space reduction results preference
aws minimal repair costs. true, UCPOP-LC ought generate
smaller search space DUnf, even though delay threats. results
expected. UCPOP DUnf, least-cost selection open conditions,
generated largest search spaces; UCPOP-LC generated significantly smaller spaces;
DUnf-LC LCFR generated smallest spaces.
time, observed LCFR incurred unwieldy overhead, often taking
longer solve problem UCPOP, despite fact searching far fewer
nodes. part due particularly inecient implementation LCFR
using, part resulted fact computing repair costs bound take
time simply popping stack (as LIFO strategy), finding aw particular
type (as strategy prefers threats). therefore explored approximation strategies,
reduce overhead aw selection accepting inaccuracy repair cost
calculation. example, developed \Quick LCFR" (or QLCFR) strategy,
calculates repair cost aw once, aw first encountered.
successor node aw remains unresolved, QLCFR assumes repair
6. planning problems cast CSPs planner Descartes (Joslin & Pollack, 1996; Joslin,
1996), correspondence even direct.

230

fiFlaw Selection Strategies
cost changed. experiments QLCFR showed promising means
making least-cost approach suciently fast pay overhead. Additional
approximation strategies studied Srinivasan Howe (1995), experimented
three variations LCFR, along fourth, novel strategy moves
control burden user.

3.3 Threat Delays Revisited

Recently, Gerevini Schubert (1996) revived idea aw selection strategy
treat open conditions threats differently, suggested LIFO
used tie-breaking strategy deciding among open conditions. combine
ideas ZLIFO strategy:
ZLIFO fngLIFO / fog0LIFO / fog1New / fog2-1LIFO / fsgLIFO
ZLIFO strategy gives highest priority nonseparable threats, forced open
conditions. neither nonseparable threats forced open conditions, ZLIFO
select open condition using LIFO. defers separable threats end
planning process. name ZLIFO intended summarize overall strategy. \Z"
stands \zero-commitment", indicating preference given forced open conditions:
repairing these, planner making commitment beyond must made
node ultimately refined complete plan. \LIFO" indicates
strategy used selecting among unforced open conditions.
open conditions repair cost exactly one, ZLIFO strategy uses tiebreaking strategy called \New". prefers repair open condition
established introducing new action repair open condition
established using element start state. Gerevini Schubert state
preference \gave improvements context Russell's tire changing domain . . .without
significant deterioration performance domains" (1996, p. 104). However
difference apparently dramatic, Gerevini believes implementation
detail, though open possibility study might show preference
significant (Gerevini, 1997).
Gerevini Schubert make three primary claims ZLIFO:
1. POCL planner using ZLIFO tend generate smaller search space one
using pure LIFO strategy.
2. reduction search space using ZLIFO, relative LIFO, correlated
complexity planning problem (where complexity measured number
nodes generated pure LIFO strategy).
3. ZLIFO performs comparably LCFR relatively easy problems, generates
smaller search space harder problems.
first two claims consistent found earlier LCFR studies.
LIFO strategy pays attention repair costs, ZLIFO does, least indirectly,
initial preference nonseparable threats, repair cost
two, secondary preference forced opens.
231

fiPollack, Joslin, & Paolucci
third claim harder square earlier LCFR study, LIFObased strategies, UCPOP DUnf, generated much larger search spaces
least-cost based strategies. explains ZLIFO's performance? Gerevini Schubert
answer question follows:
Based experience search processes AI general, [a LIFO] strategy
much recommend it, simple default. first place, overhead
cost low compared strategies use heuristic evaluation lookahead
prioritize goals. well, tend maintain focus achievement
particular higher level goal regression . . .rather attempting achieve
multiple goals breadth-first fashion. [p. 103]
point overhead important one. ZLIFO relatively inexpensive control
strategy, competing strategy better job pruning search space may
end paying excessive overhead. second point addresses question
asking here, namely, ZLIFO could produce smaller search spaces. Gerevini
Schubert go say that:
[m]aintaining focus single goal advantageous least
goals achieved independent. instance, suppose two
goals G1 G2 achieved various ways, choosing particular
method achieving G1 rule methods achieving G2.
maintain focus G1 solved, attempting G2,
total cost solving goals sum costs solving
independently. switch back forth, solutions
goals involve searches encounter many dead ends, combined cost
much larger. tend search unsolvable subtree
G1 search tree repeatedly, combination various alternatives
G2 search tree . . .. [p. 103]
certainly plausible explanation. key remaining question, course, extent explanation carries many planning problems involve
interacting goals.

4. Experimental Comparison Flaw Selection Strategies

discussed previous section, several different proposals made
literature best reduce size search space POCL planning.
include:
giving preference threats open conditions;
giving preference certain kinds threats (either separable forced threats),
delaying threats open conditions resolved;
giving preference aws minimal repair cost;
giving preference recently introduced aws.
232

fiFlaw Selection Strategies
Moreover, different strategies combined preference schemes different ways,
apparently con icting claims made effects preferences
search-space size.
resolve con icts, performed experimental comparisons POCL planners
using variety aw selection strategies. gave particular attention comparison
LCFR ZLIFO, apparently con icting claims. LCFR generates
search space treating aws uniformly, using least-cost approach choose among
them. ZLIFO distinguishes aw types (non-separable threats, open conditions,
separable threats), uses modified LIFO approach select among aws
class. original LCFR studies would led us predict ZLIFO would generate
larger search spaces LCFR, Gerevini Schubert found opposite
true. aimed, then, explain discrepancy.
principal focus search-space size, two reasons. First, puzzle raised
LCFR ZLIFO one space, time. mentioned earlier, easy see
ZLIFO would faster LCFR, even per node basis. least-cost strategy
must compute repair costs, ZLIFO need pop stack containing right type
aws. puzzle us ZLIFO faster, generated smaller
search spaces. Second, believe understanding effect search control strategies
search-space size lead development approximation techniques produce
speed-up well; QLCFR strategy (Joslin & Pollack, 1994) Srinivasan Howe's
strategies (1995) examples this.
However, secondary goal analyze time requirements strategies
compared, therefore collected timing data experiments. discuss
Section 4.6, strategy tends generate smallest search space achieves enough
reduction pay overhead, large.

4.1 Experimental Design

conduct comparison, implemented set aw selection strategies UCPOP
v.4.7 Table 1 lists strategies implemented. Except LCFR-DSep DUnfGen, discussed later, implemented strategies described Section
3.
tested strategies three problem sets, also used earlier work (Joslin
& Pollack, 1994) Gerevini Schubert's (1996):
1. Basic Problems, 33 problems taken test suite distributed
UCPOP system. include problems variety domains, including
7. Note experiments earlier LCFR paper (Joslin & Pollack, 1994) Gerevini
Schubert's (1996) ZLIFO paper run using earlier version (v.2) UCPOP. result,
number nodes produced experiments sometimes differs reported
two papers. appears largely due fact UCPOP v.4 puts elements new set
open conditions onto aw list reverse order way UCPOP v.2 (Gerevini,
1997). discussed Sections 4.3{4.5, studied uence ordering change also
collecting data using modified version UCPOP v.4 reversed order conditions
entered open list. resulting numbers similar previously published,
identical, leading us conclude additional subtle differences v.2
v.4. However, experiments report run using version
UCPOP, believe fair comparison strategies.

233

fiPollack, Joslin, & Paolucci
UCPOP
UCPOP-LC
DSep
DSep-LC
DUnf
DUnf-LC
DUnf-Gen
LCFR
LCFR-DSep
ZLIFO

fn,sgLIFO / fogLIFO
fn,sgLIFO / fogLC
fngLIFO / fogLIFO / fsgLIFO
fngLIFO / fogLC / fsgLIFO
fn,sg0LIFO / fn,sg1LIFO / fogLIFO / fn,sg2-1LIFO
fn,sg0LIFO / fn,sg1LIFO / fogLC / fn,sg2-1LIFO
fn,s,og0LIFO / fn,s,og1LIFO / fn,s,og2-1LIFO
fo,n,sgLC
fn,ogLC / fsgLC
fngLIFO / fog0LIFO / fog1New / fog2-1LIFO / fsgLIFO
Table 1: Implemented Flaw Selection Strategies

blocks world, Monkeys Bananas problem, Pednault's (1988) briefcase-andoce problem, Russell's (1992) tire changing world, etc.
2. Trains Problems, three problems taken TRAINS transportation domain
(Allen, Schubert, & et al., 1995).
3. Tileworld Problems, seven problems taken Tileworld domain (Pollack &
Ringuette, 1990).
ran strategy problem twice. first time, imposed node limit,
10,000 nodes basic problems, 100,000 nodes Trains Tileworld
problems. second time, imposed time limit, 100 seconds basic problems,
1000 seconds Trains Tileworld problems.
Gerevini Schubert experimented several different node selection strategies
Trains Tileworld domains, facilitate comparison also used node
selection strategies did. basic problems, used + OC .
reporting results, make use raw counts nodes generated
computation time seconds taken, also compute measure badly strategy
performed given problem set problems. call measure %-overrun,
compute follows. Let minimum node count given problem
strategies tested, let c node count particular strategy .
%-overrun(S ) = [(c , m)=m] 100
Thus, example, best strategy given problem generated 100 nodes,
strategy generated 200 nodes would 100 %-overrun problem.
strategy best given problem %-overrun 0 problem.
Section 4.6, make use similarly computed %-overruns computation time.
strategy hit node limit, set c relevant node limit (10,000 100,000)
compute node-count %-overrun.8 Similarly, strategy hit time limit, used
relevant time limit (100 1000) compute computation-time %-overrun.
8. way UCPOP completes basic iteration, sometimes go somewhat beyond
specified node limit terminating run. cases, used node limit value, rather
actual number nodes generated, computation %-overrun.

234

fiFlaw Selection Strategies
Online Appendix provides raw data|node counts computation-time taken|
experiments conducted; also includes computed %-overruns.
conducting experiments these, one set either node- time limit
cutoff strategy/problem pair. However, always danger cutoffs
unfairly bias data, limits set way certain strategies fail
would instead succeeded limits increased slightly. carefully analyzed
data help eliminate possibility bias; details given Appendix A.

4.2 Value Least-Cost Selection

described overall experimental design, turn analysis results. begin, sought re-establish claims originally made earlier
work. Specifically, wanted first reconfirm, using larger data set, least-cost
aw selection effective technique reducing size search space generated
POCL planner. therefore ran experiment compared node
counts five strategies earlier studied|LCFR, DUnf, DUnf-LC, UCPOP,
UCPOP-LC|plus one new one, DUnf-Gen, explained below.
results experiment shown Figures 2 3. former log-log
scatter plot, showing performance six strategies 33 problems
basic set. problems sorted minimal number nodes generated
six strategies. Thus, left-hand side graph includes problems
least one six strategies found relatively easy, right-hand side
problems hard six strategies. omitted problems none
six strategies able solve. actual number nodes generated
strategy plotted Y-axis, minimal number nodes problem,
X-axis. LCFR's performance highlighted line connecting data points.
graph shows that, general, LCFR generates small search spaces problem set,
relative strategies class. six problems LCFR
within 10% minimum. Three Get-Paid/Uget-Paid class
problems|including two \hardest" problems (UGet-Paid3 UGet-Paid4).
discuss class problems Section 4.5.
alternative view data given Figure 3, shows aggregate performance six strategies, i.e., average node-count %-overrun basic
problems. seen, LCFR smallest average %-overrun.
Figures 4 5 present similar views data Tileworld domain, Figure
6 gives data Trains problems. Trains domain, six strategies
able solve easiest problem (Trains1), simply show actual node counts
Figure 6. omitted two data points, extreme
inclusion graph made impossible see differences among strategies:
LCFR DUnf-Gen + OC + UC node selection took 28,218, 35,483 nodes,
respectively, solve problem.
Tileworld Trains problems, observed sorts interactions node aw selection strategies seen Gerevini Schubert. Specifically,
LCFR performs relatively poorly + OC Tileworld problems, performs
poorly + OC + UC Trains problems. However, paired
235

fiPollack, Joslin, & Paolucci
10000

Nodes Generated (Log)

1000
UCPOP
DUnf
UCPOP-LC
DUnf-LC
DUnf-Gen
LCFR
100

10
10

100

1000

10000

Minimum Number Nodes Generated (Log)

Figure 2: Basic Problems: Node Counts Strategies without Forced-Flaw Delay
node-selection strategies, LCFR produces smallest search spaces strategies
class.
sum, LCFR tend produce smaller search spaces strategies
class. question remains. LCFR uses least-cost strategy, side effect
prefer forced aws, since forced aws low-cost aws. therefore
conceivable LCFR's performance mostly even fully due preference forced
aws, (or greatly) uenced use least-cost strategy unforced
aws. hypothesis could explain DUnf-LC consistently outperforms DUnf,
UCPOP-LC consistently outperforms UCPOP.
address issue included DUnf-Gen experiment. DUnf-Gen
simple strategy prefers forced aws kind, otherwise uses LIFO regime.
would expect DUnf-Gen LCFR perform similarly, since frequently make
decision. Specifically, select aw node
forced aw; differ unforced aws, DUnf-Gen
selecting recently introduced aw LCFR selecting least-cost aw.
practice, DUnf-Gen's performance closely mimicked LCFR's. basic
problem set marginally worse LCFR. fact, marginally better
reverse order planner adds preconditions new step
open list (see Section 4.4). LCFR somewhat better DUnf-Gen
Trains Tileworld problems, true regardless order
preconditions added open list, extent better varies.
Thus, data inconclusive value using least-cost strategy unforced
aws. LCFR clearly benefits selecting forced aws early (as side effect preferring
236

fiFlaw Selection Strategies
3500

3000

Node-Count %-Overrun

2500

2000

1500

1000

500

0
LCFR

DUnf-Gen

UCPOP-LC

UCPOP

DUnf-LC

DUnf

Figure 3: Basic Problems: Aggregate Performance Strategies without Forced-Flaw Delay
100000

10000

Nodes Generated (Log)

UCPOP S+OC
UCPOP-LC S+OC
DUnf S+OC
DUnf-LC S+OC
DUnf-Gen S+OC

1000

DUnf-Gen S+OC+UC
DUnf-Gen S+OC+.1UC+F
LCFR S+OC
LCFR S+OC+UC
LCFR S+OC+.1UC+F
100

10
10

100

1000

Minimum Number Nodes Generated (Log)

Figure 4: Tileworld Problems: Node Counts Strategies without Forced-Flaw Delay
237

fiPollack, Joslin, & Paolucci

35000

30000

25000

20000

15000

10000

5000

UCPOP
S+OC

UCPOP-LC
S+OC

DUnf
S+OC

DUnf-LC
S+OC

LCFR
S+OC

DUnf-Gen
S+OC

DUnf-Gen
S+OC+.1UC+F

DUnf-Gen
S+OC+UC

LCFR
S+OC+.1UC+F

LCFR
S+OC+UC

0

Figure 5: Tileworld Problems: Aggregate Performance Strategies without Forced-Flaw
Delay
800

700

Nodes Generated

600

500

400

300

200

100

UCPOP
S+OC

DUnf
S+OC

DUnf-Gen
S+OC+.1UC+F

DUnf-Gen
S+OC

UCPOP-LC
S+OC

DUnf-LC
S+OC

LCFR
S+OC

LCFR
S+OC+.1UC+F

0

Figure 6: Trains 1: Node Counts Strategies without Forced-Flaw Delay
238

fiFlaw Selection Strategies
least-cost aws), may matter whether continues use least-cost strategy
unforced aws. indeed generally sucient use least-cost strategy
forced aws, ZLIFO's performance somewhat less puzzling, since ZLIFO also prefers
forced aws. However puzzle completely resolved. all, DUnf-Gen, like
ZLIFO, prefers forced aws makes LIFO-based decisions unforced aws,
performance clearly inferior LCFR's, neither clearly superior.
Even use LIFO unforced aws obviously increase search-space,
neither appear decrease it.

4.3 Comparing LCFR ZLIFO

next turn direct comparison LCFR ZLIFO. Gerevini Schubert compared
strategies problems. get complete picture performance
LCFR ZLIFO, ran problems three problem
sets.
data basic problem set shown Figure 7. sorted problems
difference node counts produced LCFR ZLIFO. Thus, problems
near left-hand side graph LCFR generated smaller search
space, problems near right-hand side ones ZLIFO space
advantage. omit problems neither strategy could solve.
seen, problems (notably R-Test2, Move-Boxes, Monkey-Test2),
LCFR generates much smaller search space ZLIFO, problems (notably
Get-Paid4, Hanoi, Uget-Paid4, Uget-Paid3), ZLIFO generates much smaller search
space. problems LCFR also worse strategies mentioned
Section 4.2.
noted earlier, one major changes UCPOP v.2 v.4
v.4 puts elements new set open conditions onto aw list reverse
order v.2. ordering may make difference, particularly LIFO-based
strategies. Indeed, researchers suggested one reason LIFO-based strategy
may perform well exploit decisions made system designers
writing domain operators, since sense natural list constraining
preconditions operator first (Williamson & Hanks, 1996). therefore also collected
data modified version UCPOP, preconditions step entered
onto open condition reverse order would normally entered.
discuss results modification detail next two sections,
now, simply present node counts LCFR ZLIFO reversed precondition
insertion, Figure 8. seen, problems reversing
precondition ordering significant effect (notably FIXB MonkeyTest2),
large LCFR ZLIFO showed relative performance.
problems basic set, dicult discern obvious pattern performance. contrast Gerevini Schubert suggest, seem clear
correlation diculty problem, measured terms nodes generated,
relative performance LCFR ZLIFO. (In fact, little dicult determine strategy's node-count serve measure diculty.)
hand, true aggregate, ZLIFO generates smaller search spaces LCFR
239

fiR-TEST2

240

UGET-PAID3

UGET-PAID4

MONKEY-TEST2

HANOI

GET-PAID4

GET-PAID3

GET-PAID2

UGET-PAID2

UGET-PAID

ROAD-TEST

FIX5

FIX4

GET-PAID

FIXA

R-TEST1

FIX2

TEST-FERRY

MONKEY-TEST1

FIX1

SUSS-ANOM

TWO-INV3

FIX3

RAT-INSULIN

PRODIGY-SUSS

TWO-INV4

FIXB

MOVE-BOXES

Nodes Generated (Log)

R-TEST2

UGET-PAID3

UGET-PAID4

HANOI

GET-PAID4

GET-PAID3

TEST-FERRY

GET-PAID2

UGET-PAID2

HO-DEMO

TOW-INV3

UGET-PAID

TOW-INV4

ROAD-TEST

FIX5

FIX4

GET-PAID

R-TEST1

SUSS-ANOM

FIX2

FIX1

FIX3

MONKEY-TEST1

PRODIGY-SUSS

RAT-INSULIN

FIXA

MONKEY-TEST2

MOVE-BOXES

Nodes Generated (Log)

Pollack, Joslin, & Paolucci

10000

1000

100
LCFR -Default

ZLIFO -Default

10

1

Figure 7: Basic Problems: Node Counts LCFR ZLIFO

10000

1000

100
ZLIFO-Reversed

LCFR-Reversed

10

1

Figure 8: Basic Problems: Node Counts LCFR ZLIFO Reversed Precondition
Insertion

fiFlaw Selection Strategies
basic problems. default precondition ordering, ZLIFO obtains average
%-overrun 212.62, LCFR obtains 647.57. reverse ordering, ZLIFO's average
%-overrun 244.24, LCFR's 914.87. fact LCFR's relative performance
worse preconditions entered reverse direction results primarily
failure MonkeyTest2 reverse direction.
Trains data scant. Neither LCFR ZLIFO solve hardest problem,
Trains3, regardless whether preconditions entered default reverse
order. (In fact, none strategies studied able solve Trains3.) But, least
preconditions entered default order, ZLIFO solve Trains2,
LCFR cannot. reverse precondition insertion, neither strategy solve Trains2.
data shown Figure 9. Note LCFR's performance essentially
node-selection strategies shown.
Finally, Tileworld data, default order precondition insertion, shown
Figure 10. place LCFR clearly generates smaller search spaces
ZLIFO. also plotted data reverse precondition insertion,
strategies affected change. however, one notable
exception: reversed insertion, ZLIFO (with + OC + :1UC + F ) much better|
indeed, well LCFR. return uence precondition ordering
Tileworld problems Section 4.5.
now, however, enough observe experiments show ZLIFO
tend generate smaller search spaces LCFR. basic problem set,
regardless order precondition insertion, Trains one ordering (and
worse LCFR ordering), well LCFR
Tileworld problems preconditions inserted reverse order.
exception Tileworld problem set preconditions inserted default order:
LCFR better.

4.4 Value Separable-Threat Delay

first two analyses essentially aimed replicating earlier results literature,
namely LCFR results ZLIFO results. next address question
square results one another.
Recall LCFR ZLIFO differ two key respects. First, LCFR treats aws
uniformly, ZLIFO distinguishes among aw types, giving highest preference nonseparable threats, medium preference open conditions, lowest preference separable
threats. Second, LCFR uniformly makes least-cost selections, ZLIFO uses LIFO
strategy secondary aw-type preferences (but giving preference forced open
conditions). comparisons made Section 4.2 suggest use LIFO strategy
unforced aws best make little difference search-space size, may possibly lead generation larger search spaces. hand, first difference
presents obvious place look relative advantage ZLIFO. all, ZLIFO
delaying separable threats, Peot Smith demonstrated effectiveness
approach DSep strategy.
Peot Smith's proof DSep never generate larger search space UCPOP
transfer LCFR. planning problems LCFR generate
241

fiPollack, Joslin, & Paolucci

100000

Nodes Generated (Log)

10000

1000
ZLIFO S+OC
ZLIFO S+OC+.1UC+F
LCFR S+OC
LCFR S+OC+.1UC+F
100

10

1
TRAINS1 (Default)

TRAINS1 (Reverse)

TRAINS2 (Default)

Figure 9: Trains Problems: Node Counts LCFR ZLIFO
100000

Nodes Generated (Log)

10000

ZLIFO S+OC

1000

ZLIFO S+OC+.1UC+F
LCFR S+OC
LCFR S+OC+UC
LCFR S+OC+.1UC+F
100

10

1
TW-EZ

TW-1

TW-2

TW-3

TW-4

TW-5

TW-6

Figure 10: Tileworld Problems: Node Counts LCFR ZLIFO
242

fiFlaw Selection Strategies
smaller search space DSep. proof relies fact that, DSep, open conditions
selected order, regardless threats selected. selection
threat LCFR uence repair cost open condition (e.g., promoting
action longer available potential establisher condition),
turn affect order remaining open conditions selected.
Nonetheless, despite fact one can't guarantee delaying separable threats
lead reduction search-space size, motivation behind DSep still appealing:
separable threats may often simply disappear subsequent planning, naturally lead reduction search-space size. reason, implemented slightly
modified version LCFR, called LCFR-DSep, separable threats
delayed. Note relatively easy UCPOP system, provides
switch, dsep switch, turned automatically delay repair
separable threats. defined earlier Table 1, definition LCFR-DSep is:
LCFR-DSep fn,ogLC / fsgLC
hypothesis ZLIFO's reduction search-space size largely due
incorporating DSep approach, LCFR-DSep ought \the best worlds",
combining advantages LCFR's least-cost approach advantages DSep
approach.
basic problems, LCFR-DSep proved smallest average node-count %overrun basic problems strategies tested. Moreover, true even
reversed order preconditions operator added open
list. Figure 11 gives average node-count %-overruns unmodified UCPOP v.4
(labeled \default") modified version reversed precondition ordering
(labeled \reverse"). Reversing ordering effect conclusion LCFR-DSep
generates smallest search spaces problems; fact, general little
affect relative performance strategies all. notable exception,
mentioned earlier, relative performance LCFR DUnf-Gen ips.
detailed comparison, plot node counts basic problems LCFR,
ZLIFO, Separable-Threat Delay strategies Figure 12. ease comparison,
show data sorted difference LCFR ZLIFO's node counts.
problems near left-hand side graph are, again, LCFR generated
smaller search space ZLIFO; problems near right
generated larger search space. seen, LCFR-DSep nearly always well
as, better LCFR. much better ZLIFO problems LCFR
good at. also much better LCFR problems ZLIFO good at.
However, ZLIFO still outperforms LCFR-DSep latter class problems.
Another view data given Figure 13, log-log scatter plot basic
problems, strategies studied. time highlighted LCFR-DSep's
performance. Although problems produce minimal
search space, performance individual problems actually quite good, consistent
good aggregate performance.
least basic problems, augmenting simple LCFR strategy delay
separable threats reduces search space expected. turn suggests
LCFR generates larger search space ZLIFO, due large part fact
243

fiPollack, Joslin, & Paolucci

4000

3500

Node-Count %-Overrun

3000

2500

Default

2000

Reverse

1500

1000

500

0
LCFRDSep

DSepLc

ZLIFO

DSep

LCFR

DUnfGen

UC
POP-LC

UCPOP

DUnfLC

DUnf

Figure 11: Basic Problems: Aggregate Performance Strategies

10000

Nodes Generated (Log)

1000

ZLIFO
100

LCFR
LCFR-DSep

10

UGET-PAID3

HANOI

UGET-PAID4

GET-PAID4

GET-PAID3

GET-PAID2

TEST-FERRY

HO-DEMO

UGET-PAID2

TOW-INV3

TOW-INV4

UGET-PAID

ROAD-TEST

FIX4

PRODIGY-P22

R-TEST1

FIX5

GET-PAID

FIX2

SUSS-ANOM

FIX1

FIX3

PRODIGY-SUSS

MONKEY-TEST1

FIXA

RAT-INSULIN

MOVE-BOXES

MONKEY-TEST2

R-TEST2

1

Figure 12: Basic Problems: Node Counts LCFR, ZLIFO, DSep Strategies
244

fiFlaw Selection Strategies
10000

1000
Nodes Generated (Log)

UCPOP
DSep
DUnf
UCPOP-LC
DUnf-LC
ZLIFO
DUnf-Gen
LCFR
DSep-Lc

100

LCFR-DSep

10
10

100

1000

10000

Minimum Number Nodes Generated (Log)

Figure 13: Basic Problems: Node Counts Strategies
delay separable threats. ZLIFO's primary advantage relative LCFR seems
use LIFO strategy unforced threats, rather separable-threat
delay component. Combining separable-threat delay least-cost approach yields
strategy tends generate smaller search spaces either strategy
basic problem set. However, analysis Trains Tileworld problem sets reveals
situation little complicated comparison basic problems would
suggest, discuss next section.

4.5 Need Domain Information

Tileworld Trains domains problems challenge overly simple conclusions might
draw basic problem sets. consider set problems turn.
4.5.1 Tileworld Problems

Tileworld domain involves grid tiles holes, goal fill hole
tile. goal achieved fill operator, two preconditions:
agent must hole, must holding tile. encoding, agent
hold four tiles time. go operator used achieve (sub)goal
hole, pickup operator used achieve (sub)goal holding tile.
normal way, go precondition location, namely whatever location
agent move from. Pickup precondition location tile.
problems Tileworld problem set differ one another number holes
agent must fill: problem adds another hole.
245

fiPollack, Joslin, & Paolucci
100000

LCFR S+OC+UC
10000

LCFR S+OC+.1UC+F
DUnf-Gen S+OC+UC

Nodes Generated (Log)

DUnf-Gen S+OC+.1UC+F
DUnf-Gen S+OC
LCFR S+OC
LCFR-DSep S+OC+UC
ZLIFO S+OC+.1UC+F

1000

ZLIFO S+OC
LCFR-DSep S+OC+.1UC+F
DSep-LC S+OC
LCFR-DSep S+OC
DUnf S+OC
DSep S+OC
100

UCPOP-LC S+OC
DUnf-LC S+OC
UCPOP S+OC

10
10

100

1000

Minimum Number Nodes Generated (Log)

Figure 14: Tileworld Problems: Node Counts Strategies
Figures 14 gives log-log plot various strategies Tileworld problems,
preconditions entered default order. Note LCFR (S + OC + UC )
strategy highlighted. Three strategies almost indistinguishable LCFR
(S + OC + UC ), namely, LCFR (S + OC + :1UC + F ), DUnf-Gen (S + OC + UC )
DUnf-Gen(S + OC + :1UC + F ). strategies performed worse.
easily seen Figure 15, gives aggregate performance leading strategies:
able solve seven Tileworld problems. fact, leading strategies
able solve seven Tileworld problems without generating 1800 nodes
problem. contrast, remaining strategies failed least one, four,
seven problems, given limit 100,000 nodes generated.
originally surprising us Tileworld problems, delaying separable threats actually seems hurt performance. strategies best like
LCFR DUnf-Gen delay separable threats. LCFR-DSep, ZLIFO, DSep-LC,
DSep generated larger search spaces, contrast would predicted
given experiments basic problem set.
understand result, looked detail planning trace problems.
revealed Tileworld domain, early resolution separable threats
important advantage: imposes turns correct temporal ordering
steps going tile (to pick up), carrying hole. Virtually
strategies create subplans like one shown Figure 16. goals involve filling
holes, planners insert steps go pick tile, go hole.
point, two separable threats: (1) effect going hole, :at(X ), threatens
link going tile picking (at(Z )), (2) effect going
246

fiFlaw Selection Strategies
100

90

80

Node-Count %-Overrun

70

60

50

40

30

20

10

0
LCFR
S+OC+UC

LCFR
S+OC+.1UC+F

DUnf-Gen
S+OC+UC

DUnf-Gen
S+OC+.1UC+F

DUnf-Gen
S+OC

Figure 15: Tileworld Problems: Aggregate Performance Leading Strategies

at(X)

GO(X,Y)

at(Y)
loc(H,Y)
holding(T)

~at(W)
at(W)

GO(W,Z)

at(Z)
tile(T)
loc(T,Z)

~at(X)

FILL(H)

filled(H)

PICKUP(T)

Figure 16: Typical Partial Plan Tileworld Domain
tile, :at(W ), threatens link going hole filling (at(Y )).
threats separable, X W unbound; planner yet know
traveling from. one valid temporal ordering
resolve threats: going tile must precede picking tile, turn must
precede going hole. temporal ordering determined, planning goes
smoothly.
contrast, ordering decision made, planner often \get lost",
attempting find plans goes location hole
hole tile. many ways attempt this, many different
247

fiPollack, Joslin, & Paolucci
100000

LCFR-DSep S+OC+.1UC+F
10000

ZLIFO S+OC+.1UC+F
LCFR S+OC+UC

Nodes Generated (Log)

LCFR S+OC+.1UC+F
DUnf-Gen S+OC+.1UC+F
LCFR-DSep S+OC+UC
DUnf-Gen S+OC
DUnf-Gen S+OC+UC

1000

DUnf-LC S+OC
LCFR-DSep S+OC
DSep-LC S+OC
LCFR S+OC
ZLIFO S+OC
UCPOP-LC S+OC
100

DUnf S+OC
DSep S+OC
UCPOP S+OC

10
10

100

1000

Minimum Number Nodes Generated (Log)

Figure 17: Tileworld Problems: Node Counts Reversed Precondition Insertion
tiles select, many different locations move among. planner may try many
alternatives determining fundamental inconsistency
plans, destined fail. larger number holes filled,
worse situation becomes.
Sometimes planner may make right decision temporal ordering even
deferred separable threats. faced partial plan Figure 16, planner
select threat, select among several open conditions. attempt
establish precondition going hole (at(X )) reusing effect going
tile (at(Z )), reverse, attempt establish precondition going
tile (at(W )) reusing effect going hole (at(X )). course, first
solution right one, includes critical temporal ordering constraint,
second eventually fail.
order open conditions selected determine two
choices planner makes. preconditions entered default order, planners
delay separable threats end making latter, problematic choice. contrast,
preconditions entered reverse order, planners make turns
correct choice. Thus, experiments reversed precondition
insertion, see different pattern performance, shown Figures 17{18.9
preconditions entered reverse order, larger number strategies
perform well, solving problems. particular, + OC + :1UC + F node9. preserve readability, Figure 18, used \(1)" denote + OC , \(2)" + OC + U C ,
\(3)" + OC + U C + :1F .

248

fi249
UCPOP (1)

DUnf (1)

DSep (1)

UCPOP-LC (1)

LCFR (1)

ZLIFO (1)

DSep-LC (1)

LCFR-DSep (1)

DUnf-LC(1)

DUnf-Gen (2)

DUnf-Gen (1)

LCFR-DSep (2)

DUnf-Gen (3)

LCFR (3)

LCFR (2)

ZLIFO (3)

LCFR-DSep (3)

Node-Count %-Overrun

Flaw Selection Strategies

50000

45000

40000

35000

30000

25000

20000

15000

10000

5000

0

Figure 18: Tileworld Problems: Aggregate Performance Strategies Reversed
Precondition Insertion

fiPollack, Joslin, & Paolucci
25000

20000

15000
TRAINS1
TRAINS2
10000

5000

DSep-LC
S+OC

LCFR-DSep
S+OC

LCFR-DSep
S+OC+.1UC+F

ZLIFO
S+OC+.1UC+F

DUnf
S+OC

LCFR-DSep
S+OC+UC

ZLIFO
S+OC

DSep
S+OC

0

Figure 19: Trains Problems: Node Counts
selection, performance LCFR, DUnf-Gen, ZLIFO, LCFR-DSep virtually indistinguishable. important note leading strategies delay separable
threats|LCFR DUnf-Gen|are affected much reversal precondition insertion Tileworld problems; fact, LCFR's performance identical cases.
contrast, strategies use separable-threat delay|LCFR-DSep, ZLIFO, DSepLC|all perform much better reverse precondition insertion. explained
analysis above.
sum, important Tileworld domain planner recognize,
early possible, certain required temporal orderings
steps successful plan. Every successful plan involve going tile going
hole, although exibility order multiple holes visited,
interleaving picking tiles dropping holes. strategies
studied, two different methods led temporal constraint added
plan. added planner selected separable threat resolve,
added selected one particular precondition resolve another.
4.5.2 Trains Get-Paid Problems

Trains domain present somewhat different variation original conclusions.
Trains domain involves set locations objects, goal transport various
objects specific starting locations specified destinations. Gerevini Schubert
studied three Trains problems. strategies failed successfully complete
hardest (Trains3) within either 100,000 node 1000 second limit. Moreover,
many also failed second hardest (Trains2). Caution must therefore taken
interpreting results, limited number data points.
250

fiFlaw Selection Strategies
Figure 19 gives node counts Trains domain, preconditions inserted
default order. show strategies able solve Trains1 Trains2.
results closer would predicted basic problem set
results Tileworld. particular, LCFR-DSep well, generating
much smaller search spaces LCFR. However, slightly worse ZLIFO.
Recall saw pattern performance subset basic problems,
specifically Get-Paid/Uget-Paid problems. There, LCFR-DSep improved
LCFR, generate small search spaces ZLIFO. turns
similar factors uencing sets problems, instructive consider
detail planning done ZLIFO LCFR-DSep Get-Paid/Uget-Paid problems
understand occurring.
Like Trains domain problems, Get-Paid/Uget-Paid problems involve moving
particular objects specified locations. Get-Paid/Uget-Paid domain three
objects: paycheck, dictionary, briefcase. generally formulated, initial
state three home, paycheck briefcase. goal deposit
paycheck bank, bring dictionary work, briefcase home.
dictionary paycheck moved briefcase. human,
solution problem obvious. dictionary must put briefcase,
must carried work, dictionary taken out. briefcase must
carried home. addition, stop must made bank, either way work
way home, point paycheck must taken briefcase
deposited.
ZLIFO LCFR-DSep take different paths solving problem. ZLIFO begins
forming plans get paycheck bank dictionary work. goals
selected first forced: one way get paycheck
bank (carry there), similarly one way get dictionary oce (carry
there). contrast, two possible ways get briefcase home: either
leaving (i.e., reusing initial state) carrying somewhere else
(i.e., adding new step). LIFO mechanism proceeds complete plans
achieving goals getting paycheck bank dictionary work,
beginning work remaining goal, getting briefcase home. point,
goal easy solve. needed plan route home wherever briefcase
end two errands.
LCFR-DSep, like ZLIFO, begins selecting forced goals getting dictionary
oce getting paycheck bank. However, instead next completing
plans goals, LCFR-DSep continues greedily select least-cost aws, thus
begins work achieving goal getting briefcase home. Unfortunately,
point clear briefcase needs moved home from, hence LCFRDSep begins engage lengthy process \guessing" briefcase
end tasks, planned tasks.10
10. diculty LCFR-DSep encounters greedily picking low-cost aws might reduced
lookahead several planning steps, determine accurate repair cost. approach
taken branch-n mechanism O-Plan (Currie & Tate, 1991). Significant overhead involved
strategy, however.

251

fiPollack, Joslin, & Paolucci
key decision Get-Paid/Uget-Paid domain|and, turns out, Trains
domain|is related to, subtly different key decision Tileworld domain.
Get-Paid/Uget-Paid Trains, key insight planner
important temporal ordering goals. goal getting briefcase home
going achieved goal taking dictionary work. However,
recognition constraint affected separable-threat delay,
Tileworld. Instead, happens domains higher-cost aw interacts
lower-cost one, causing latter become fully constrained.
tempting think finally case LIFO-based strategy
advantageous. all, example, completely determining
achieve one goal, make much easier know solve another goal. use
ZLIFO (or alternative LIFO-based strategy) guarantee interactions
high- lower-cost aws exploited. particular interactions
among two unforced aws, order goals agenda lead ZLIFO
make inecient choice. Thus, modified problem briefcase
work initial state, ZLIFO LCFR-DSep solved problem quickly
(178 nodes ZLIFO 157 LCFR-DSep). Note modification removes
problematic interaction low-cost high-cost aw.
Finally, note effectiveness LIFO strategies heavily dependent
order preconditions entered onto open list. Figure 20 gives
node counts Trains domain reverse precondition insertion.
plot strategies solve Trains 1 Trains2. case,
two strategies: LCFR-DSep DSep-LC. strategies rely LIFO
open-condition selection, ZLIFO, DSep, DUnf-Gen, UCPOP, significantly worse
preconditions correct order. extent LIFO
helps domains, appears ability exploit decisions made
system designers writing domain operators, suggested Williamson
Hanks (1996).

4.6 Computation Time
covered key questions set address: relative effects
alternative search-control strategies search-space size, and, particular,
reconcile apparently con icting approaches LCFR ZLIFO? concluded
LCFR-DSep combines main advantages reducing search-space size two
strategies, namely LCFR's use least-cost selection mechanism, least forced aws,
ZLIFO's use separable-threat delay. final question concerns price one
pay use LCFR-DSep|or matter, alternative strategies. achieve
reduction search-space size, necessary spend vastly time processing?
strategies pay themselves?
answer questions, collected timing data experiments. Figures 21
22 gives data basic problems, experiments run node
limit run time limit. (As detailed Appendix A, results
experiments node limit time limit similar.) saw
little uence precondition ordering basic problems, analyze data
252

fiFlaw Selection Strategies
30000

25000

20000

TRAINS1

15000

TRAINS2

10000

5000

0
LCFR-DSep
S+OC+UC

LCFR-DSep
S+OC+.1UC+F

LCFR-DSep
S+OC

DSep-LC
S+OC

Figure 20: Trains Problems: Node Counts Reversed Precondition Insertion
350

300

Computation-Time %-Overrun

250

200
Time Limit
Node Limit
150

100

50

0
DSep-Lc

ZLIFO

LCFR-DSep

DSep

Figure 21: Basic Problems: Aggregate Computation Time Performance Leading Strategies
default precondition ordering. show one graph strategies, another
includes \leading strategies", make possible see distinctions among
them.
253

fiPollack, Joslin, & Paolucci
30000

Computation-Time %-Overrun

25000

20000

Time Limit

15000

Node Limit

10000

5000

0
DSepLc

ZLIFO

LCFRDSep

DSep

UCPOP

UC
POP-LC

DUnfGen

LCFR

DUnfLC

DUnf

Figure 22: Basic Problems: Aggregate Computation Time Performance
timing data show LCFR-DSep does, large, pay overhead
basic problems generating smaller search spaces (and therefore process
fewer nodes). run time limit, LCFR-DSep's time performance almost
identical ZLIFO's, despite fact repair cost computations expensive
stack-popping LIFO strategy. run node limit, LCFR-DSep
show worse time performance ZLIFO aggregate, still performs markedly better
strategies. change relative performance results cases
strategies fail node limit: LCFR-DSep takes longer generate 10,000
nodes.
Another interesting observation DSep-LC best time performance
basic problem set. perhaps surprise, DSep-LC closely
approximates LCFR-DSep. differs primarily preference nonseparable threats,
case tend low repair costs. Whenever node includes nonseparable threat, DSep-LC quickly select threat, without compute repair
costs. speed advantage outweighs cost processing extra nodes sometimes
generates.
Figures 23{26 provide timing data Trains Tileworld domains.11
real surprises. computation times taken parallel quite closely size
search spaces generated. strategies generate smallest search spaces
also fastest. Trains problems, see DSep-LC serve
11. omitted strategies poorly, performing worse node- time-limit
experiments strategies graphed. Note ran reverse-order experiments
node limit.

254

fiFlaw Selection Strategies
7000

6000

Computation-Time %-Overrun

5000

4000
Default-Node Limit
Default-Time Limit
3000

2000

1000

0
LCFR
(2)

DUnfGen
(2)

LCFR
(3)

DUnfGen
(3)

DUnfGen
(1)

ZLIFO
(1)

LCFR
(1)

ZLIFO
(3)

LCFRDSep
(2)

LCFRDSep
(3)

DSep
(1)

Figure 23: Tileworld Problems: Aggregate Computation Time Performance Leading
Strategies
good approximation technique LCFR-DSep. Although generates nodes
LCFR-DSep, somewhat faster.12

5. Conclusion
paper, synthesized much previous work aw selection partialorder causal link planning, showing earlier studies relate one another,
developed concise notation describing alternative aw selection strategies.
also presented results series experiments aimed clarifying effects
alternative search-control preferences search-space size. particular, aimed
explaining comparative performance LCFR ZLIFO strategies. showed
neither aw selection strategies consistently generates smaller search spaces,
combining LCFR's least-cost approach delay separable threats
included ZLIFO strategy, obtain strategy|LCFR-DSep|whose space
performance nearly always good better LCFR ZLIFO given problem.
therefore concluded much ZLIFO's advantage relative LCFR due delay
separable threats rather use LIFO strategy. Although unable
resolve question whether least-cost selection required unforced, well
forced aws, found evidence LIFO strategy unforced aws better.
hand, separable-threat delay clearly advantageous. open question exactly
advantageous. conducted preliminary experiments suggest
12. interpreting Trains timing data, important note strategies shown|notably
UCPOP, UCPOP-LC, Dunf, failed solve Trains2 within either node time limit.

255

fiPollack, Joslin, & Paolucci
900

800

Computation-Time %-Overrun

700

600

500

400

300

200

100

S+OC+UC
DUnf-Gen

S+OC
DUnf-Gen

S+OC
LCFR-DSep

S+OC
DUnf-LC

S+OC
DSep-LC

S+OC+.1UC+F
DUnf-Gen

S+OC+.1UC+F
LCFR

S+OC+UC
LCFR

S+OC+.1UC+F
LCFR-DSep

S+OC+.1UC+F
ZLIFO

S+OC+UC
LCFR-DSep

0

Figure 24: Tileworld Problems: Aggregate Computation Time Performance Leading
Strategies Reversed Precondition Insertion
2500

Computation-Time %-Overrun

2000

1500
Default - Node Limit
Default-Time Limit
1000

500

S+OC
UCPOP

S+OC
LCFR-DSep

S+OC+UC
LCFR-DSep

S+OC+.1UC+F
LCFR-DSep

S+OC
DSep-LC

S+OC+.1UC+F
ZLIFO

S+OC
ZLIFO

S+OC
DUnf

S+OC
DSep

0

Figure 25: Trains Problems: Aggregate Computation Time Performance Leading Strategies
256

fiFlaw Selection Strategies

2000
1800

Computation-Time %-Overrun

1600
1400
1200
1000
800
600
400
200

S+OC
DSep

S+OC+.1UC+F
ZLIFO

S+OC
ZLIFO

S+OC+UC
LCFR-DSep

S+OC+.1UC+F
LCFR

S+OC
DUnf-LC

S+OC
LCFR

S+OC
UCPOP-LC

S+OC
LCFR-DSep

S+OC+.1UC+F
LCFR-DSep

S+OC
DSep-LC

0

Figure 26: Trains Problems: Aggregate Computation Time Performance Leading Strategies Reversed Precondition Insertion

257

fiPollack, Joslin, & Paolucci
much search-space reduction results delaying separable threats also
achieved making separation systematic, something UCPOP v.4 do.
also considered question computation time, showed often LCFR-DSep
requires computation time comparable ZLIFO. LCFR-DSep therefore
seen paying computational overhead search-space reduction. Moreover,
Peot Smith's DSep-LC provides good approximation LCFR-DSep: although
produces somewhat larger search spaces, quickly.
conclusions, however, tempered fact certain clusters problems, combined strategy, LCFR-DSep, generate minimal search spaces.
saw, Tileworld problems, important recognize need
particular temporal ordering among plan steps, recognition obtained
resolving separable threats early. Trains Get-Paid/Uget-Paid domains,
matters recognizing particular effect fact achieved one
way, recognized particular aw selected|a aw happens
generally least cost aw available. lesson learned sets
problems although understand reasons LCFR ZLIFO perform
way do, combine best features create good default strategies POCL planning, clear domain-dependent characteristics
identified Trains Tileworld domains must still taken account settling
aw selection strategy domain.

Acknowledgments
Martha Pollack's work project supported Air Force Oce Scientific
Research (F49620-96-1-0403) NSF Young Investigator's Award (IRI-9258392). David
Joslin supported Rome Labs (RL)ARPA (F30602-95-1-0023) NSF CISE
Postdoctoral Research award (CDA-9625755). Massimo Paolucci supported
Oce Naval Research, Cognitive Neural Sciences Division (N00014-91-J-1694).
grateful Alfonso Gerevini providing us code used
earlier study, allowing us use experiments. would also like thank
Arthur Nunes Yazmine DeLeon, assisted us carrying experiments done
preliminary stages work. Finally, thank Alfonso Gerevini, Len Schubert,
Michael Wellman, anonymous reviewers helpful comments work.

Appendix A: Ruling Ceiling Effects
data collected using node limit, examined problems least
one strategies hit node limit. Table 27 gives second worst node count
problems. shows that, basic problems least one strategy
failed, least one succeeded, second-worst strategy generally created fewer
7000 nodes.
Similarly, Trains Tileworld problems, cases except TW3,
second-worst strategy took fewer 50,000 nodes (and TW3 took 89,790). Recall
node limit basic problems 10,000 nodes, Trains
Tileworld problems 100,000 nodes. thus clear strategies hit
258

fiFlaw Selection Strategies
PROBLEM
HANOI
R-TEST2
MONKEY-TEST2
MONKEY-TEST3
GET-PAID2
GET-PAID3
GET-PAID4
FIXIT
HO-DEMO
FIXB
UGET-PAID2
UGET-PAID3
UGET-PAID4
PRODIGY-P22
MOVE-BOXES
MOVE-BOXES-1

Default

Reverse
2919
7567
3744
10000
129
6431
1625
10000

TRAINS2
TRAINS3
TW-2
TW-3
TW-4
TW-5
TW-6

10000
175
4725
2894
8265
4402
10000

2952
5227
5200
10000
129
6431
1625
10000
10000
3184
175
4725
2894
9264
2687
10000

22351
100000

29585
100000

89790
3844
49024
1722

11620
401
1266
20345
3040

Figure 27: Second-Worst Node Counts Problems Failing Strategies
node limit substantially worse strategies succeed. Even
succeed increasing node limit slightly, comparative performance would still
poor.
Thus, using node limits imposed, making strategies look worse
actually are. hand, computing %-overrun, may making
strategies look better actually are, use value 10,000 (or
100,000) nodes generated strategy hits limit, actual number nodes
might take, run completion, could significantly higher. why, analyses,
considered absolute performance strategies individual problems,
aggregate performance, measured average %-overrun.
also compared experiments run time limit
run node limit. basic problem set, time limit 100 seconds high
enough that, cases, strategies could compute significantly nodes
259

fiPollack, Joslin, & Paolucci
could node cutoff. Nonetheless, results almost identical. nearly
cases, strategy failed node cutoff, also failed time limit cutoff.
four exceptions this:
1. Hanoi: 10,000 nodes limit, DSep fails, 100 second time limit,
succeeds, taking 46,946 nodes.
2. Uget-Paid3: 10,000 node limit, UCPOP-LC fails, 100 second
time limit, succeeds, taking 37,951 nodes.
3. Uget-Paid4: 10,000 node limit, UCPOP-LC fails, 100 second
time limit, succeeds, taking 23,885 nodes.
4. Fixit: 10,000 nodes limit, DSep-LC, UCPOP-LC, ZLIFO fail,
100 second time limit, succeed 12,732, 13,510, 20,301 nodes
respectively. strategies fail solve problem either limit.
similarly strong correspondence results obtained
Trains Tileworld problems using node limit time limit. cases,
strategy able succeed within 100,000 node limit able succeed
within 1,000 second time limit. nature problems computation
time per node great. Specifically,
1. TW3, DUnf succeeded 56,296 nodes run node limit, failed
1,000 second time limit.
2. TW4, LCFR-DSep (with S+OC node-selection strategy) succeeded 69,843
nodes, failed time limit.
3. TW5, LCFR-DSep (with S+OC+UC node-selection strategy) succeeded
49,024, failed limit.
4. TW6, LCFR (with S+OC node-selection strategy) succeeded 4,506 nodes,
failed time limit.
one case strategy fail node limit succeed within time limit:
1. TW3, DSep (with S+OC node-selection strategy) failed 100,000 node
limit, succeeded 134,951 nodes using 100 second time limit. Note
significantly worse second worst strategy, solved problem
generating 89,790 nodes.
Given close correspondence experiments node time limits,
collected node-limit data experiments reversed precondition
insertion.

260

fiFlaw Selection Strategies

References

Allen, J. F., Schubert, L. K., Ferguson, G. M., Heeman, P. A., Hwant, C. H., Kato, T., Light,
M., Margin, N. G., Miller, B. W., Poesio, M., & Traum, B. R. (1995). TRAINS
project: case study building conversational planning agent. Experimental
Theoretical Artificial Intelligence, 7, 7{48.
Chapman, D. (1987). Planning conjunctive goals. Artificial Intelligence, 32 (3), 333{378.
Currie, K., & Tate, A. (1991). O-plan: open planning architecture. Artificial Intelligence, 52, 49{86.
Etzioni, O., Hanks, S., Weld, D., Draper, D., Lesh, N., & Williamson, M. (1992).
approach planning incomplete information. Proceedings Third International Conference Principles Knowledge Representation Reasoning, pp.
115{125.
Gerevini, A. (1997). Personal communication.
Gerevini, A., & Schubert, L. (1996). Accelerating partial-order planners: techniques
effective search control pruning. Journal Artificial Intelligence Research, 5,
95{137.
Joslin, D. (1996). Passive Active Decision Postponement Plan Generation. Ph.D.
thesis, Intelligent Systems Program, University Pittsburgh.
Joslin, D., & Pollack, M. E. (1994). Least-cost aw repair: plan refinement strategy
partial-order planning. Proceedings Twelfth National Conference Artificial
Intelligence (AAAI), pp. 1004{1009 Seattle, WA.
Joslin, D., & Pollack, M. E. (1996). \early commitment" plan generation ever good
idea?. Proceedings Thirteenth National Conference Artificial Intelligence
(AAAI), pp. 1188{1193 Portland, OR.
Kambhampati, S., Knoblock, C. A., & Yang, Q. (1995). Planning refinement search:
unified framework evaluating design tradeoffs partial-order planning. Artificial
Intelligence, 76 (1-2), 167{238.
Kumar, V. (1992). Algorithms constraint-satisfaction problems: survey. AI Magazine,
13 (1), 32{44.
McAllester, D., & Rosenblitt, D. (1991). Systematic nonlinear planning. Proceedings
Ninth National Conference Artificial Intelligence, pp. 634{639 Anaheim, CA.
Pednault, E. P. D. (1988). Synthesizing plans contain actions context-dependent
effects. Computational Intelligence, 4 (4), 356{372.
Penberthy, J. S., & Weld, D. (1992). UCPOP: sound, complete, partial order planner
ADL. Proceedings Third International Conference Knowledge Representation Reasoning, pp. 103{114 Cambridge, MA.
261

fiPollack, Joslin, & Paolucci
Peot, M., & Smith, D. E. (1992). Conditional nonlinear planning. Proceedings First
International Conference AI Planning Systems (AIPS-92), pp. 189{197 College
Park, MD.
Peot, M., & Smith, D. E. (1993). Threat-removal strategies partial-order planning.
Proceedings Eleventh National Conference Artificial Intelligence, pp. 492{499
Washington, D.C.
Pollack, M. E., & Ringuette, M. (1990). Introducing Tileworld: Experimentally evaluating agent architectures. Proceedings Eighth National Conference Artificial
Intelligence, pp. 183{189 Boston, MA.
Russell, S., & Norvig, P. (1995). Artificial Intelligence: Modern Approach. Prentice Hall,
Englewood Cliffs, NJ.
Russell, S. J. (1992). Ecient memory-bounded search algorithms. Proceedings
Tenth European Conference Artificial Intelligence, pp. 1{5.
Smith, D. E., & Peot, M. A. (1994). note DMIN strategy. Unpublished manuscript.
Srinivasan, R., & Howe, A. E. (1995). Comparison methods improving search eciency
partial-order planner. Proceedings 14th International Joint Conference
Artificial Intelligence, pp. 1620{1626.
Tate, A., Drabble, B., & Dalton, J. (1994). Reasoning constraints within O-plan2.
Tech. rep. ARPA-RL/O-Plan2/TP/6 V. 1, AIAI, Edinburgh.
Tsang, E. (1993). Foundations Constraint Satisfaction. Academic Press.
Tsuneto, R., Erol, K., Hendler, J., & Nau, D. (1996). Commitment strategies hierarchical task network planning. Proceedings Thirteenth National Conference
Artificial Intelligence (AAAI), pp. 526{542 Portland, OR.
Weld, D. S. (1994). introduction least commitment planning. AI Magazine, 15 (4),
27{61.
Wilkins, D. E. (1988). Practical Planning: Extending Classical AI Paradigm. Morgan
Kaufmann, San Mateo, CA.
Wilkins, D. E., & Desimone, R. V. (1994). Applying AI planner military operations
planning. Fox, M., & Zweben, M. (Eds.), Intelligent Scheduling, pp. 685{708.
Morgan Kaufmann Publishers, San Mateo, CA.
Williamson, M., & Hanks, S. (1996). Flaw selection strategies value-directed planning.
Proceedings Third International Conference Artificial Intelligence Planning
Systems, pp. 237{244.

262

fiJournal Artificial Intelligence Research 6 (1997) 111{145

Submitted 8/96; published 4/97

Lifeworld Analysis
Philip Agre

pagre@ucsd.edu

Ian Horswill

ian@ils.nwu.edu

Department Communication 0503
University California, San Diego
La Jolla, CA 92093, USA
Northwestern University Computer Science Department
1890 Maple Avenue
Evanston, IL 60201, USA

Abstract

argue analysis agent/environment interactions extended
include conventions invariants maintained agents throughout activity.
refer thicker notion environment lifeworld present partial set formal
tools describing structures lifeworlds ways computationally
simplify activity. one specific example, apply tools analysis Toast
system show versions system different control structures fact
implement common control structure together different conventions encoding
task state positions states objects environment.

1. Introduction
Biologists long sought concepts describe ways organisms adapted
environments. Social scientists likewise sought concepts describe ways
people become acculturated participants social worlds around them. Yet
dicult approach phenomena methods computational modeling.
see least two reasons diculty. first tradition modeling
artificial intelligence developed around concern cognition, is, mental processes
understood intervene stimuli responses human beings. Although minority
traditions ecological psychology reacted approach studying human
life, able translate concepts computational mechanisms
match expressive power symbolic programming. second reason subtle:
one conceives organisms environments spatially extended mechanisms
explained according principles boundary
(the surface body) particularly different from, interesting than,
rest total organism-environment system. challenge computational modeling,
then, conceptualize agents' adaptations environments ways neither
treat agents isolated black boxes dissolve one big machine.
purposes, find useful distinguish two aspects agent's
involvement familiar environment: embodiment embedding. \Embodiment"
pertains agent's life body: finiteness resources, limited perspective
world, indexicality perceptions, physical locality, motility,
on. \Embedding" pertains agent's structural relationship world: habitual
c 1997 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiAgre & Horswill
paths, customary practices fit shapes workings things,
connections agents, position set roles hierarchy, forth.
concept embedding, then, extends concrete kinds locatedness
world (places, things, actions) abstract kinds location (within social systems,
ecosystems, cultures, on). Embodiment embedding obviously interrelated,
powerful consequences agents' direct dealings agents
solitary activities physical world. principal focus article
embedding, particularly ways agents maintain relationships objects
functionally significant tasks.
paper develop thoughts embodiment embedding follows:

Section 2 reviews concept environment developed early work
Newell Simon.

Section 3 introduces adaptation traditional idea, call life








worlds, sketch involved lifeworld analysis.
Section 4 introduces informally concept factorization lifeworlds; refers
roughly structures lifeworld permit agents' decisions made
independently one another.
Section 5 defines basics formal theory lifeworld analysis, namely
concepts environments, actions, policies, factorization, reduction one
environment another. purpose formalism characterize kinds
interactions arise agents familiar lifeworlds.
Section 6 brie introduces computer program wrote illustrate
phenomena lifeworlds.
Section 7 applies formalism modeling world program
operates; proceeds modeling successively complicated versions world.
Section 8 explains program keeps track objects world
figure activities, discusses issues arise trying model
keeping-track formal terms.
Section 9 sums formal work explaining precise relationship
program formal model world.
Section 10 expands theory lifeworlds informally introducing
concept cognitive autopoiesis, collection means agents manipulate surroundings provide conditions cognitive processes;
provide taxonomy phenomena.
Section 11 concludes suggesting directions future work.

2. Concept Environment

Intuitively, notion \the environment" AI robotics refers relatively enduring stable set circumstances surround given individual. environment
probably yours, though may similar. hand, although
environment starts leave (at skin, perhaps), clear ending-point.
necessarily defined terms metric space; physically distant circumstances
consequences life (via telephone, say) properly regarded
112

fiLifeworld Analysis
part environment well. environment agents live, determines
effects actions. environment thus matter importance computational
modeling; know agent's environment like determine given
pattern behavior adaptive. particular need positive theory environment,
is, kind principled characterization structures dynamics
attributes environment virtue adaptive behavior adaptive.
Herbert Simon discussed issue pre-AI work. book Administrative Behavior (1947), example, presents uential theory later became known limited
rationality. contrast assumption rational choice classical economics, Simon
describes range cognitive limitations make fully rational decision-making organizations impracticable. Yet organizations thrive anyway, argues, provide
individual structured environment ensures decisions good
enough. division labor, example, compensates individual's limited ability
master range tasks. Structured ows information, likewise, compensate
individual's limited ability seek information judge relevance. Hierarchy
compensates individual's limited capacity choose goals. fixed procedures
compensate individuals' limited capacity construct procedures themselves.
comparison Simon's early theory Administrative Behavior, AI downplayed
distinction agent environment. Newell Simon's early work
problem solving (1963), environment reduced discrete series choices
presents course solving given problem. phrase \task environment" came
refer formal structure search space choices outcomes. clearly
good way modeling tasks logical theorem-proving chess, objects
manipulated purely formal. tasks involve activities physical world,
however, picture complex. cases, problem solving model analyzes
world distinctive way. theory treat world agent separate
constructs. Instead, world shows up, speak, phenomenologically: terms
differences make difference agent, given particular representations, actions,
goals. Agents different perceptual capabilities action repertoires, example,
inhabit different task environments, even though physical surroundings goals
might identical.
Newell Simon's theory task environment, then, tends blur difference
agent environment. framework analysis, find phenomenological
approach valuable, wish adapt purposes. Unfortunately, Newell
Simon carry blurring theory cognitive architecture. often unclear
whether problem solving activity takes place wholly within mind, whether
unfolds agent's potentially complicated interactions physical world.
distinction arise cases theorem-proving chess,
domain whose workings easily simulated mental reasoning. crucial
domain whose actions uncertain outcomes. Even though wish retain
Newell Simon's phenomenological approach task analysis, therefore, wish
presuppose agents reason conducting searches problem spaces. Instead,
wish develop analytical framework guide design wide range
agent architectures. particular, want analytical framework help us design
simplest possible architecture given task.
113

fiAgre & Horswill

3. Lifeworlds
use term lifeworld mean environment described terms customary
ways structuring activities take place within | conventional uses
tools materials, \loop invariants" maintained within conventional
activities, on. term originally comes phenomenological sociology (Schutz
& Luckmann, 1973), refers familiar world everyday life, specifically
world described terms make difference given way life. Cats
people, example, understood inhabiting physical environment
different lifeworlds. Kitchen cupboards, window sills, spaces underneath chairs
different significances cats people, balls yarn, upholstery, television
sets, cats. Similarly, kitchen affords different kind lifeworld chef
mechanic, though clearly two lifeworlds may overlap ways well.
lifeworld, then, physical environment, patterned ways
physical environment functionally meaningful within activity.
idea similar Gibson's theory perception (1986), two theories also
differ important ways. Whereas Gibson believes perception worldly affordances
direct, believe perceptual process explained causal terms. Also,
whereas Gibson treated categories perception essentially biological innate,
regard cultural emergent.
analyzing lifeworld, one attempts draw individual structures within
facilitate customary activities. example, lifeworlds typically contain artifacts
tools specifically evolved support activities. tools
also arranged world ways simplify life reduce cognitive burden
individuals: cups typically found cupboards, food refrigerators grocery
stores. one needs remember butter found specific grocery store
butter grocery stores found well-defined dairy section, usually along wall,
recognized distance; dairy section view, butter
visible definite area. Artifacts also designed make functional properties
perceptually obvious. Handles perceptibly suited picking up, knobs perceptibly
suited turning, forks perceptibly suited impaling things, (Brady,
Agre, Braunegg, & Connell, 1984; Winston, Binford, Katz, & Lowry, 1983). Contrarily,
generally assumed artifacts provide readily perceptible grounds
drawing functional distinctions fact interchangeable. Usually, functionally
significant property object obvious, lifeworld provides alternate way
marking it. see record player house, example, assume
mine unless specific reason to. aspects lifeworlds
tend make easy perform particular kinds activities within without
remember many facts reinvent screwdriver first principles.
Lifeworlds contain networks interacting conventions practices simplify specific aspects specific activities. practices relieve agents burden solving certain
problems spot diffuse solutions throughout activity agent
many agents. example, hospital might try get along without maintaining sterile
conditions. People always germs, technically always infected. problem
making sure infections never get control. direct solution would
114

fiLifeworld Analysis
constantly monitor patients, assess degree infection treat
becomes severe. Since undesirable number reasons, hospital instead tries
prevent infections patients maintaining sterile conditions. might this,
example, looking contaminated objects surfaces disinfecting them. Unfortunately, sterility visible surface characteristic. Instead, hospitals solve problem
structuring space activity. Different locations kept less sterile depending
conventional uses: operating rooms sterile hallway oors. Objects
generate germs (people) washed, masked, gloved. Critical instruments
come contact specially sterilized use. Tongue depressors
assumed dirty trash (or biohazard bag) clean
wrapped paper. objects surfaces periodically disinfected regardless
level contamination. practices maintained regardless immediate
need them. hospital (for reason) temporarily find without
patients, workers would stop washing hands disinfecting bathrooms.

4. Factorization Lifeworlds

Simon, Sciences Artificial (1970), argued complex systems \nearly
decomposable." model rooms building, whose walls tend minimize
effects activity one room upon activity another. Sussman (1975),
analysis block-stacking tasks, classified several types \subgoal interactions"
result attempts break tasks subtasks; one hopes tasks
decomposable, bugs arise decomposable enough. One assumes
task decomposable unless one reason believe otherwise. Sussman's research,
rich tradition planning research helped inaugurate, concerned dicult problem
constructing plans presence subgoal interactions. goal, complementary
theirs, analyze many ways tasks really decomposable, derive
broadest range conditions moment-to-moment activity proceed without
extensive analysis potential interactions.
non-pathological lifeworld structured ways limit prevent interactions
among subtasks. structures might taxonomized follows:

Activity partition. lifeworlds separate activities discrete headings: sewing

distinct activity bathing, gathering food separate activity giving
birth, on. distinctions provide basis reckoning \different activities" purposes rest partitions. boundaries among
various activities often marked type ritual.

Spatial partition. Different things often done different places. Tasks may

confined places associated tools materials stored,
suitable conditions lighting safety obtain. places may even close together, different recipes prepared different sections countertop space
different kinds food kept different parts one's plate, boundary
regions perhaps employed assemble forkfuls neighboring foods. general, activities arranged space, decisions made one place tend minimal
interaction decisions made places. course spatial distance brings
115

fiAgre & Horswill
absolute guarantees functional independence (using resources one
location prevent carted another location another use later
on), general tendencies.

Material partition. Different activities often involve different materials, decisions affect materials one activity interact decisions affect
materials activity.

Temporal partition. Different activities often take place different times, thus lim-

iting channels might constrain one another. times
might standardized points cycle day week, ordering
might constrained kind precondition first activity produces
successive ones depend upon.

Role partition. Simon pointed division labor eases cognitive burdens.
part supplying individuals separate spheres conduct
respective activities.

Background maintenance. Many activities background conditions main-

tained without reference specific goals. example, one maintains stocks supplies pantry, puts things back belong, forth. Hammond,
Converse, Grass (1995) call \stabilization." (See Section 5.)
practices stabilize relationships agent materials used
customary activities. tend ensure, example, one encounter
one's hammer currently opened box corn akes definite sorts recurring
situations. thus reduce complexity life, variety different hassles
arise, encouraging rise routine patterns cycles activity rather
constant stream unique puzzles.

Attributes tools. Numerous properties tools limit interactions among separate

decisions. Virtually tools resettable, meaning regardless one
them, restored normal state within
full range functionalities accessible. (This course assumes one
using tools customary ways breaking them.) Thus
properties tool place ordering constraints activities
use it. Likewise, tools committed tasks long periods.
turned screw screwdriver, example, screwdriver stay
\stuck" screw long period. Thus necessary schedule
use screwdriver unless several people wish use once. Exceptions
general rule include bowls (whose ingredients must often sit waiting future actions
conditions, cannot contain anything else meantime), stove burners
(which sometimes must remain committed heating particular dishes
reached certain states before), clamps (which must remain fastened
glue dried sawing operations completed).

Supplies tools. latter tools raise spectre generalized scheduling problems potential deadlock among multiple activities, problems
116

fiLifeworld Analysis
fact sometimes arise cooking people number
given kitchen adapted. time, though, one solves problems
scheduling simply enough tools must remain
committed particular purposes period time. Lansky Fogelsong (1987)
modeled effects search spaces limited interactions different cooks
using overlapping sets tools.

Warning signs. things go wrong, unpleasant subgoal interactions ensue.

avoid diculties, individual, community, species keeps track warning
signs cultivates capacity notice them; warning signs include supplies
running low funny smells. often done primitive associative level,
rats stay away smells associated stuff made sick
people develop phobias things present suffered traumas.
Communities often arrange certain warning signs become obtrusive,
kettles whistle natural gas mixed another gas distinctive smell.

Simple impossibility. Sometimes things impossible, obviously so,
necessary invest great effort deciding them.

Monotonicity. Many actions changes state irreversible. Irreversible changes
cause decisions interact certain things must done change takes
place. also provides structure decision process: lifeworld needs
make evident must done given irreversible change occurs.

Flow paths. Often lifeworld arranged particular materials (parts

assembly line, paperwork organization, food way refrigerator stove
table) follow definite paths. paths provide great deal structure
decision-making. inspecting various points along path, example, one see
needs done next. determining object is, one determine
must done must taken afterward. paths
consciously mapped others emergent properties set customs.

Cycles. Likewise, many lifeworlds involve stable cycles activities, perhaps

cycles nested inside others. resulting rhythms often expressed
recurring combinations materials, decisions, spatial arrangements, warning signs,
on.

Externalized state. computer people, \state" (used mass noun) means dis-

cernible differences things modified voluntarily, interpreted functionally significant way. Early AI treat internal state
(memory) external state (functionally significant mutable states world)
importantly different, often analytically convenient treat uniform
fashion. often advantageous record state world, whether relative
locations things persistent states (in count noun sense)
left (Beach, 1988). example, one need remember whether eggs
broken fact readily perceptible, one's attention drawn
suitable occasion, one understands significance task. Likewise, one
117

fiAgre & Horswill
save great deal memory retrieving ingredients evening's
recipes cupboards placing customary place shelf.
Lifeworlds, then, great deal structure permits decisions made independently one another. point real lifeworlds permit anyone live
100% \reactive" mode, without performing significant computation, even
would desirable. point, rather, nontrivial cognition people perform takes place considerable background familiar generally reliable
dynamic structure.
factorability lifeworlds helps particularly understanding activities
agent body. great deal focusing inherent embodiment. look
one place time, handle one tool time, activities necessarily
serial. attention certain degree hysteresis: gotten work
one countertop using one particular tool, example, natural step
carry task. crucial, therefore, different tasks relatively
separate consequences, lifeworld provide clues change task
necessary, functionally significant conditions generally detected using
general-purpose forms vigilance occasionally looking around. course, certain
kinds activities complex this, require special-purpose strategies
go beyond simple heuristic policies \find something needs
it." point complex activities many interacting components
rare, generally conducted specially designed adapted lifeworlds,
lifeworlds structured minimize diculty tasks rather increase it.
various phenomena together formed motivation concept indexicalfunctional deictic representation (Agre & Chapman, 1987; Agre, 1997). Embodied agents
focused one activity one set objects time; many objects specifically adapted activity; relevant states generally readily perceptible; objects
perceptibly different generally interchangeable; stabilization practices
help ensure objects encountered standardized ways. thus makes sense,
purposes, represent objects generic ways one's relationships them.
ashlight keep car the- ashlight-I-keep-in-the-car FLASHLIGHT-13.
maintain stable relationship ashlight keeping standard place, putting
back done it, using intended purposes, keeping
batteries fresh, on. presence environment ensures ready access
light car breaks night, therefore need separately plan
contingency time drive. conventional structures activity
maintain ashlight's presence \loop invariant." presence ashlight
activities ensure structures lifeworld.

5. Environments, Policies, Reducibility

section, introduce formalism. purpose formalism directly
specify workings agent's cognitive machinery. Instead, purpose construct \principled characterizations interactions agents environments
guide explanation design" (Agre, 1995). formalism, words, describes
agent's embodied activities particular environment. characterized dy118

fiLifeworld Analysis
namics activities, becomes possible design suitable machinery. matter
principle, want design simplest possible machinery consistent
given pattern interaction (Horswill, 1995). therefore make priori commitments
machinery. favor particular architecture particular activity
analyzed. make priori commitments matters analog
versus digital, \planning" versus \reaction," on. experience real
lifeworlds real activities incorporate great deal useful dynamic structure,
effort invest studying structure repaid parsimonious theories
machinery. intend methods equally useful investigating types
activity designing types machinery might able participate them.
concept lifeworld appear specific mathematical entity
formalism. intuition, however, this: objective material environment,
agent directly deal environment's complexity. Instead deals
functional environment projected material environment.
projection possible various conventions invariants stably present
environment actively maintained agent. lifeworld understood
functional world together projection conventions create it.
section summarizes formal model environmental specialization given Horswill
(1995); proofs theorems, see original paper. Subsequent sections apply
extend model.
model environments state machines behavior agents policies
mapping states actions.
environment E pair (S; A) state-space set possible
actions.
action a: ! mapping states states.
policy p: ! mapping states actions taken. paper,
states include facts physical environment, straightforward matter include agent's internal states well (Horswill, 1995).
combination policy environment creates dynamic system: environment's state mapped policy action maps environment new state
whole process repeated.
discrete control problem (DCP) pair (E; G) environment E goal G,
subset E 's state space.
policy solves problem dynamic system generates environment
eventually reaches goal state.
solves problem halts remains within G entering it.
example, consider robot moving along corridor n equally spaced oces
labeled 1, 2, 3, on. formalize environment Zn = (f0; 1; :::; n ,
1g; fincn ; dec; ig), identity function, incn dec map integer
+ 1 , 1, respectively, proviso dec(0) = 0 incn(n , 1) = n , 1
119

fiAgre & Horswill

(dec,i)
(i,inc)

dec

dec

inc5
3

dec

inc5

4

(i,dec)

inc5
2

(1,1)
(i,inc)

1

(dec,i)

(i,dec)

inc5

inc5
0

(i,inc)

(0,1)

dec

(inc,i)
(i,inc)

(inc,i)

(0,0) (dec,i) (1,0)

dec

(dec,i)
(i,dec)

(inc,i)

(inc,i)
(i,dec)

Figure 1: environment Z5 (left) serial product Z2 itself, expressed
graphs. Function products written pairs, i.e. inci written
(inc; i). Identity actions (i ii) left undrawn reduce clutter.
(see Figure 1). Note effect performing identity action stay
state.
emphasize policy model agent's behavior, causal/computational processes behavior exhibited. specifies agent
state, it. thus theoretical construct, data structure algorithm
agent's head. examine implementation issues surround policies
section 8.

5.1 Product Environments

majority formal sections paper explore phenomenon factoring.
particular, explore policies factorable environments composed
policies factors. state-machine models environments, factorization
factorization state-space; environment's state-space Cartesian product
state-spaces. environment, whole, \factorable" component
sub-environments. example, position king chess board row
column components. thought \product" components,
isomorphic Z8 (since eight rows eight columns). consider
environment car drives 88 grid city blocks, see
kind product Z8 itself. environments 88 grids state spaces,
car environment allows one component change time, whereas king
environment allows change.
must therefore distinguish different kinds factorization. call chessboard
case parallel product Z8 itself, car case serial product.
focus another kind factorization later. Let Cartesian product two functions f
g fg: (a; b) 7! (f (a); g(b)), let identity function. two environments
E1 = (S1; A1 ) E2 = (S2 ; A2 ), define parallel product

E1 k E2 = (S1S2; fa1a2 : a1 2 A1; a2 2 A2 g)
120

fiLifeworld Analysis
serial product
E1 *
) E2 = (S1S2; fa1i : a1 2 A1 g [ fia2 : a2 2 A2 g)
products DCPs defined obvious way:
(E1 ; G1 ) k (E2 ; G2 ) = (E1 k E2 ; G1G2)
(E1 ; G1 ) *
) (E2 ; G2) = (E1 *
) E2 ; G1G2)
state diagram Z2 *
) Z2 shown Figure 1.
say environment DCP parallel (or serial) separable isomorphic
product environments DCPs.
5.1.1 Solvability Separable DCPs

important property separable DCPs solutions constructed
solutions components:
Lemma 1 Let p1 policy solves D1 halts states set initial
states I1 , let p2 policy solves D2 halts states I2 .
policy
p(x; y) = p1(x)p2(y)
solves D1 k D2 halts states I1I2 . (Note using convention
treating p, function pairs, function two scalars.)
Lemma 2 Let p1 policy solves D1 states set initial states
I1, let p2 policy solves D2 states I2 . policy
p(x; y) = p1 (x)i ip2(y)

2 G2; x 62 G1 ) p(x; y) = p1(x)i
x 2 G1; 62 G2 ) p(x; y) = ip2(y)
solve D1 *
) D2 halt states I1I2.
Note parallel serial cases different. One would expect parallel case
easier solve policy perform actions state components
simultaneously. fact dicult one required perform actions
simultaneously leaves agent way preserving one solved subproblem
solving another. Consider \ ip- op" environment F = (f0; 1g; fflipg) flip(x) =
1 , x. F property every state accessible every state. F *
)F
also property. F k F , however, not. F k F one action, ips
state components once. Thus two states accessible given state
F k F : state ip. king, problem fixed add
identity action F . possible leave one component product intact,
changing other. identity action, sucient, necessary. weaker,
still unnecessary, condition F action always maps goal states goal
states.
121

fiAgre & Horswill

s'



= (s' )

a'
a' (s' )
unreduced environment




a(s) = (a' (s' ))
reduced environment

Figure 2: simple reduction environment E 0 E . s0 corresponding
states reduced unreduced environments respectively a0
corresponding actions. projection simple reduction \commutes"
actions, (a0 (s0 )) = a((s0 )), alternatively, a0 = . Thus
regardless whether take projection action,
achieve result.

5.2 Reduction

Another important kind structure one environment considered abstraction another (Newell, Shaw, & Simon, 1960; Sacerdoti, 1974; Knoblock, 1989).
abstract environment retains fundamental structure concrete environment
removes unimportant distinctions among states. abstract state corresponds set
concrete states abstract actions correspond complicated sequences concrete
actions.
say projection environment E 0 another environment E
mapping state space E 0 E . say simple reduction
E 0 E every action E , corresponding action a0 E 0
state s0
(a0 (s0)) = a((s0 ))
equivalently,
a0 =
function composition operator. say a0 -implementation
use denote function mapping E -actions implementations
E 0 .
possible define much powerful notion reduction implementations allowed arbitrary policies. requires fair amount additional machinery,
however, including addition state agent. Since simple reduction suce
purposes, simply assert following lemma, direct consequence
general reduction lemma (Horswill, 1995):
Lemma 3 Let simple reduction E 0 environment E let (E 0 ; G0)
DCP. policy p solves (E; (G0 )),
p = p
122

fiLifeworld Analysis
solves (E 0 ; G0 ).

5.3 Related Work

formal models environments use state-space descriptions environment, usually finite-state machines. Rosenschein Kaelbling used finite state machines represent
agent environment (1987, 1989, 1986). formalization allowed specialized
mechanisms directly synthesized descriptions desired behavior formalization behavior environment. formalization powerful enough form
basis programming language used program real robot. Later, Rosenschein developed method synthesizing automata whose internal states provable correlations
state environment given set temporal logic assertions dynamics
environment. Donald Jennings (1992) use geometric, similar, approach
constructing virtual sensors. Lyons Arbib (1989) model organisms robots
using process algebras, Beer (1995) employs formalisms dynamic systems theory.
Wilson (1991) specifically proposed classification simulated environments
based types mechanisms operate successfully within them. Wilson
also used finite state formalization environment. divided environments
three classes based properties determinacy. Todd Wilson (1993) Todd
et al. (1994) taxonomized grid worlds terms behaviors successful
them. Littman (1993) used FSM models classify environments reinforcement learning
algorithms. Littman parameterized complexity RL agents terms amount
local storage use far future RL algorithm looks.
empirically classified environments minimal parameters still allowed
optimal control policy learned.
also extensive literature discrete-event dynamic systems (Kosecka, 1992),
also model environment finite state machine, assume transition
information (rather state information) visible agents.
alternative state-machine formalism found work Dixon (1991).
Dixon derives semantics first order logic, world comes individuated
objects relations, rather state-space methods used here. Dixon's \open"
approach also avoids need define environment single mathematical structure.
Like work, Dixon's work attempts formally model assumptions system makes
environment. Dixon's interest, however, individual program means
rather comparing competing programs.

6. Toast

Toast (Agre & Horswill, 1992) program simulates short-order cook reasonably detailed simulation kitchen (see Figure 3). Toast, world consists

set objects ovens, pans, cutting boards, globs pancake batter, individual eggs,
customers restaurant. object type (e.g., EGG) objects
given type common set possible states common set possible operations
performed them. action involves set objects given types.
action require objects specified states may change states
objects, others. example, MIX operation would involve objects type
123

fiAgre & Horswill
Time
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
30
31
36
46
56
57
58
59
60
69
79
89
90
91
92
93
94
95
96
97
98
99
100
101
102

Event
(BREAK-EGG EGG-11 BOWL-4) [Making omelette]
(ADD-EGG EGG-10 OMELETTE-BATTER-0)
(ADD-EGG EGG-9 OMELETTE-BATTER-0)
(BEAT OMELETTE-BATTER-0 WHISK)
(MOVE PAN-4 BURNER-4)
(MOVE BUTTER-PAT-15 PAN-4)
(MELT BURNER-4 PAN-4 BUTTER-PAT-15)
(MOVE SLICE-23 TOASTER) [Waiting butter making toast]
(START TOASTER SLICE-23)
(MOVE KNIFE-4 PLATE-1) [Waiting toast setting table]
*** Done goal (KNIFE CLEAN PLATE-1) ***
(MOVE PLATE-1 KITCHEN-TABLE)
(MOVE FORK-4 PLATE-1)
*** Done goal (FORK CLEAN PLATE-1) ***
(MOVE SPOON-4 PLATE-1)
Toaster pops!
(MOVE BUTTER-PAT-14 KNIFE-3) [Back toast]
(BUTTER SLICE-23 KNIFE-3 BUTTER-PAT-14)
(POUR-OMELETTE-BATTER OMELETTE-BATTER-0 ...) [Butter melted back omelette]
(MOVE SLICE-23 PLATE-1) [Setting table]
*** Done goal (SLICE BUTTERED PLATE-1) ***
*** Done goal (SPOON CLEAN PLATE-1) ***
(POUR-FLOUR FLOUR BOWL-3) [Making pancake]
(ADD-SUGAR SUGAR PANCAKE-BATTER-0)
(ADD-BAKING-POWDER BAKING-POWDER PANCAKE-BATTER-0)
(FOLD OMELETTE-0 SPATULA-2) [Tending omelette]
(ADD-MILK MILK-DISPENSER PANCAKE-BATTER-0) [Back pancakes]
(ADD-EGG EGG-8 PANCAKE-BATTER-0)
(MIX PANCAKE-BATTER-0 SPOON-3)
(MOVE PAN-3 BURNER-3)
(FLIP OMELETTE-0 SPATULA-2) [Tending omelette]
(MOVE BUTTER-PAT-13 PAN-3) [Pancake]
(MELT BURNER-3 PAN-3 BUTTER-PAT-13)
(MOVE OMELETTE-0 PLATE-1) [Finishing omelette]
*** Done goal (OMELETTE COOKED PLATE-1) ***
(SPOON-BATTER PANCAKE-BATTER-0 PAN-3 BUTTER-PAT-13) [Pancake]
(FLIP PANCAKE-0 SPATULA-2)
(MOVE PANCAKE-0 PLATE-3)
*** Done goal (PANCAKE COOKED PLATE-3) ***
(MOVE PLATE-3 KITCHEN-TABLE)
(MOVE PAN-2 BURNER-2) [Pancake 2]
(MOVE BUTTER-PAT-12 PAN-2)
(MELT BURNER-2 PAN-2 BUTTER-PAT-12)
(SPOON-BATTER PANCAKE-BATTER-0 PAN-2 BUTTER-PAT-12)
(FLIP PANCAKE-1 SPATULA-2)
(MOVE PANCAKE-1 PLATE-2)
*** Done goal (PANCAKE COOKED PLATE-2) ***
(MOVE PLATE-2 KITCHEN-TABLE)
(CLEAN PAN-2) [Cleanup]
(CLEAN PAN-3)
(CLEAN SPOON-3)
(CLEAN SPATULA-2)
(CLEAN BOWL-3)
(CLEAN KNIFE-3)
(CLEAN PAN-4)
(CLEAN WHISK)
(CLEAN BOWL-4)
(TURN-OFF BURNER-2)
(TURN-OFF BURNER-3)
(TURN-OFF BURNER-4)

Figure 3: Sample run breakfast program. agent given goals making
omelette, two pancakes, slice toast, setting table, cleaning
up. comments appear square brackets.
MIXING-BOWL, BATTER,

SPOON. would require spoon CLEAN state
effects would put batter MIXED state spoon DIRTY
state. Objects perform actions, Toast agent, oven, customers
modeled objects perform actions cooking, transferring heat, making
orders, respectively.
Toast divides objects world two important classes (see Figure
4). Informally, tools objects (1) end products cooking (2) easily
124

fiLifeworld Analysis
Material. Eggs. Fresh ! broken ! beaten ! cooked.
Material. Butter pat. Fresh ! melted.
Material. Milk supply. Non-empty ! empty.
Material. Pancake batter. Has- ! has-sugar ! has-dry ! has-milk ! has-all ! mixed.
Material. Pancake. Cooking ! cooked-1-side ! ipped ! cooked ! burnt.
Material. Bread slice. Fresh ! toasted ! buttered.
Tools. Forks, spoons, knives, spatulas, whisks. Clean ! dirty, dirty ! clean.
Containers. Bowls, plates, pans, stove burners, countertop, toaster, bread bag.
Active objects. Agent, stove burners, toaster.

Figure 4: object types current system.
reset initial states. example, knives spoons used dirtied
process cooking, end products cooking easily reset
clean state washing. Materials objects end products cooking
state graphs form linear chains. words, state material,
exactly one state brought exactly one action
bring there. example, egg scrambled always goes series
states UNBROKEN, BROKEN, BEATEN, COOKED. UNBROKEN state, action available
egg BREAK, action available BEAT.
Toast given stock type object. runs, customers give goals
(orders) prepare specific dishes. goal specifies type material (e.g., \EGG").
satisfied putting object type finished state. egg object
cooked matter. Toast manages dynamic set goals opportunistically
overlaps preparation processes finish scarce resources, stove burners,
become free. Toast uses surprisingly simple algorithm:
clock cycle simulator:
Choose material already cooked
Look action needed advance next state
action requires additional tools,
choose objects proper types
objects reset states
perform action
else choose one unreset tool objects
look perform reset action

algorithm intentionally sketchy implemented many versions
find intuitively similar, different control structures
require different correctness proofs. task next section draw
similarities produce coherent theory them.
Toast algorithm two interesting features:

algorithm proceeds table-lookup.
algorithm stateless: internal plans models stored agent;
information used choose actions stored world.
125

fiAgre & Horswill
Table lookup implies algorithm fast simple. Statelessness makes algorithm simple well, relatively robust face unexpected perturbations.

7. Modeling Toast World

Toast work? specifically, properties environment rely
upon work? general, strategy identify series structures environment
permit Toast's tasks factored, define series reductions
permit complex versions Toast's problem defined terms simpler ones.
claim vast generality Toast architecture; simply observe
environmental regularities Toast relies upon common many environments,
suggest method arguing Toast's architecture seems likely extend
types structure environment. Although different versions Toast rely
different structures, show versions rely on:
1. factorability environment individual objects. Factoring allows us
construct solutions problems solutions subproblems individual
factors.
2. special properties tool material object classes.
3. maintenance invariants agent's activity introduce new structure
environment.
formalization properties tools materials simple. precise formalization factorability objects, however, surprisingly dicult environment directly factorable using methods developed far. solve
problem defining new factoring technique called uniform reduction,
environment viewed collection overlapping instances schematic environments,
containing minimal set objects necessary perform task. agent solves
task choosing one instances reducing goal true environment
solution schematic instance. this, agent must keep track
instance operating goes along. could accomplished internal memory, course, agent would need memory performs
tasks concurrently. show structuring activity, agent
make information manifest environment, thus \storing" information
world.

7.1 Single-Material Worlds

start defining schematic environment Toast. environment
exactly one material cooked one tool needed cook it. simplify
further, start ignoring even tools.
1. Solve no-tools case.
2. Reduce self-resetting tools case no-tools case.
3. Reduce general case self-resetting tools case.
126

fiLifeworld Analysis
7.1.1 Single-Material Worlds Tools

Since materials linear chains state spaces, action restricted, say
least. case egg, might chain:
fresh break
! broken beat
! beaten heat
! cooked heat
! burnt
(We assume identity, \nop," action always available every state.
trivial assumption.) given state, one non-trivial action executed,
action selection agent trivial. solving DCP involving single-material
world one following must always hold:
current state goal state, need execute identity action.
current state pregoal state: goal state later chain
current state, reach executing unique action brings us
next state chain.
current state postgoal state: goal states earlier chain,
problem unsolvable.
really matters single-material worlds, therefore, many states
direction goal lies relative current state. sense,
really one single-material world, rather one class them, namely chains Cn given
length:
Cn = (f1; :::; ng; fincn ; ig)
(Note environment Zn , without actions move
backward along chain.)
Proposition 1 single-material worlds n states reducible Cn
Proof: Let E = (S; A) single-material environment. Define : ! f1; :::; ng
letting (s) s's position E 's state chain, i.e. first state maps 1, second
2, etc. Let action(s) denote unique action performed state s.
pincn (s) = (action(s))(s)
-implementation incn E reduced. 2
one real class single-material worlds, one real class
policies single-material DCPs:
(
s2G
pCn ;G(s) = i;inc ; ifotherwise
n
clearly solves DCP (Cn ; G) n valid G.
Corollary 1 goal G solvable single-material environment E tools,
solved policy
(
s2G
pE;G(s) = i;(action(s))(s); ifotherwise
127

fiAgre & Horswill
7.1.2 Single-Material Worlds Single-State Tools

suppose world contains material set tools, tools always clean
otherwise reset use. Self-resetting tools one state,
trivial kind environment. define \singleton" environment environment
exactly one state:
= (freadyg; fig)
single-state environments isomorphic , model environment consisting
material = (S; A) self-resetting tool k . state space simply
freadyg actions set

fa0 : (sM ; ready) 7! (a(sM ); ready)ja 2 Ag
action performs action -component product's state
leaves component unchanged. induction, that:

Proposition 2 environment isomorphic kS n .
single-state-tool worlds trivially reducible tool-free worlds.
7.1.3 Single-Material Worlds General Tools

general tool environment identical single-state tool environment, except
actions change states tools addition states materials. solve
general tool case using solution single-state tool case resetting tools whenever
dirtied.
proof simple, requires formalize notion tool. Let E
environment state space form S1 S2 ::: Sn. Let action E
Si component state space. say

independent Si never changes Si result regardless
value Si .

focused component Si independent components.
Si tool privileged value readyi 2 Si that:
{ state (s1; :::; si ; :::; sn ) E , reach state (s1; :::; readyi ; :::; sn )

using actions focused Si .
{ action a, either independent Si, focused Si, else
defined states whose Si component readyi .

prove general tool case reducible single-state tool case:

Lemma 4 environment tool components reduced one tools
replaced singletons. Specifically, let = ((S; A); G) DCP let readyT 2
, A0 = fa0 : (s; readyT ) 7! (a(s); t)ja 2 A; 2 S; 2 g. D0 = ((S T; A0 [
); G freadyT g) reducible tool D0.
128

fiLifeworld Analysis
Proof: Let pD solution (policy) D. definition tool, must
policy pT bring D0 state (s; t) (s; readyt ) without changing
component. Let projection D0 given

(

= readyT
(s; t) = s;?; ifotherwise
2 A, define -implementation a, pa
( 0
= readyT
pa (s; t) = ap ; ; ifotherwise

D0 reducible D. general case multiple tools follows induction. 2

7.2 Multiple-Material Worlds Single-Material Goals

reprise: want factor environment individual objects describe
Toast composite techniques operating individual factors. cannot
properly define environments Cartesian products individual objects defined isolation
way expressing actions involving multiple objects. can, however,
define set objects context minimal, schematic environment containing one
copy object. done so, want recapture notion environment
kind product objects different types. showing
environment two eggs thought two overlapping copies environment
one egg; copies differ choice egg.
treat environments state spaces formed products state spaces
objects. state environment tuple states objects. binding
schematic environment real environment particular kind projection
complex environment schematic, one also reduction. reasonable
projections valid bindings, say environment uniformly reducible
schematic environment.
7.2.1 Bindings Uniform Reducibility
Let E 0 E environments state spaces built Cartesian products family

disjoint sets fSi g. Si might represent state spaces object types like egg fork.
E 0 E would state spaces make number copies egg
fork.
say projection E 0 E simple every component result
component argument.

(s1; s2 ; s3; :::; sn ) = (si1 ; si2 ; :::; sim )
i1 ; :::; im [1; n]. Thus takes E 0 -state, s0 , probably throws away
components, possibly rearranges rest form new tuple. example, might

single particular egg's state and/or particular fork's state throw state
components away. projection simple, define kind inverse it,
129

fiAgre & Horswill

schematic world

multiple-object world

the-egg

egg0

the-fork

egg1

the-spatula

egg2

the-pan

egg3
egg4
fork0
fork1
fork2
spatula0
spatula1
pan0
pan1

Figure 5: binding (solid vectors) alternate binding (dashed).
call back-projection. define back-projection, , (s; s0 ),
function whose result s0 components keeps replaced
corresponding components s. example, defined
(s01 ; s02; s03 ) = (s03 ; s02)
back-projection would given by:
, ((sa; sb ); (s01 ; s02; s03 )) = (s01; sb ; sa)
say simple projection binding E E 0 also simple reduction
E 0 E (see Figure 5).
Lemma 5 Let binding E E 0 . given
(a) = ; (s0) = ,(a((s0 )); s0 )
is, implementation E -action simply 's back-projection composed
action .
proof follows definitions simple projection back-projection.
say E 0 uniformly reducible E every simple projection E 0 E binding.
7.2.2 Existential Goals
Toast given goal putting instance given material finished state.

call existential goal satisfied exactly environment
states exists object specified type specified state. Let (E; G)
DCP let E 0 uniformly reducible E . define existential goal 9E;E G G
E 0 set states E 0 project binding goal state (E; G):
[
,1(G)
9E;E G =
0

0

binding E E

130

0

fiLifeworld Analysis
,1 (G) = fs0 : (s0 ) 2 Gg set states map goal states . Given
solution schematic goal schematic environment, easily construct
number solutions existential goal:

Lemma 6 policy p solution problem (E; G) initial states ,
binding E 0 E ,
p = p
solution (E 0 ; 9E;E G) initial states ,1 (I ), function mapping
actions E corresponding actions E 0 .
0

Toast algorithm implements policy composition schematic solution
binding maps onto real world. Consider problem cooking egg.
schematic solution might be:

break the-egg the-pan
beat the-egg the-pan using the-whisk
heat the-egg the-pan
boldface verbs break, beat, heat name actions. italicized expressions the-

egg the-pan name objects (state components) affect simplified world.
binding determines objects real world state components
correspond. Given binding, main control structure need remember sequence
break, beat, heat. may preconditions states tools (i.e.
whisk needs clean), handled reduction given policies resetting
tools.
7.2.3 Binding Maps

Given basic policy cooking single egg single pan whisk, construct
policy achieve goal composing basic policy binding. policy
solve goal state bound material non-postgoal state.
policy solve goal solvable state, must able change bindings run
time. call function states bindings binding map.
One simple policy choosing bindings impose priori ordering
objects always use first acceptable object ordering. ordering might
random, might correspond order imposed visual search mechanism.
formal standpoint, ordering matter, can, without loss generality, use
left-to-right order state components environment's state tuple. Let M0
binding map always chooses leftmost pregoal material uses fixed
mapping tools (we care what). mapping allows us construct true
solution, one requires internal state agent:

Proposition 3 policy
pM0 (s) = (AM0(s) p (M0 (s)))(s)
solution state M0 defined.
131

fiAgre & Horswill
Proof: assumption, M0 defined initial state. environment must map
solvable state M0 initial state. Since p is, assumption, solution
problem E , pM0 must solve problem E 0 unless M0 changes value
pM0 solve problem. Suppose does. environment must go state
s00, state component E 0 leftmost pregoal material, state s01,
component leftmost pregoal material. happen (a)
leftmost pregoal material s00 changed goal state s01 (b)
component pregoal s00 becomes pregoal s00 . Case (b) impossible
case (a) implies s01 goal state. Thus pM0 must solution. 2

7.3 Multiple Goals: Metabolism

Thus far, considered happens policy achieves goal. Since agents
rarely set achieve goal die, want consider account extended
activity involving many goals.
One important class extended activities agent transforms whole class
identical objects. call metabolizing class. Metabolism useful
make extra work: cooking 100 eggs useful, least feeding lot people;
dirtying 100 forks, however, probably means wash all.
Whether policy metabolizes object class depends large part binding map
uses. policy pM0 metabolizes materials material worked
ceases leftmost pregoal material soon arrives goal state.
happens, M0 changes bindings agent starts work different object. Policy p
never actually sees material goal state. course, property \leftmost"
artifact formalism. matters property metabolism simply
binding map implement ordering instances material always
choose minimum ordering objects pre-goal states.
ordering might implemented agent visually scanning work surface
uncooked egg, always scanning left-to-right top-to-bottom. return
issues section 8.
binding maps lead kinds behavior, pathological.
binding map always chooses binding, metabolism ceases. binding
map always chooses uncooked eggs doesn't impose ordering them, might start
cooking infinite number eggs without ever actually finishing one them.
Metabolism also issue tool use. metabolize materials, pM0 must repeatedly
reset tools. alternate policy metabolize tools too. Let us define M1
binding map uses leftmost pregoal material also leftmost reset
tools. clearly,
pM1 (s) = (AM1(s) p (M1 (s)))(s)
solution state M1 defined. policy treats tools disposable.
long infinite supply fresh tools, p see succession states
tools reset states. never need execute resetting action
environment effectively single-state-tool environment. Thus reduction section
7.1.3 unnecessary.
132

fiLifeworld Analysis

7.4 Multiple Goals: Interleaved Execution

Metabolism involves performing transformation uniformly instances
type object: cooking eggs, cleaning/dirtying forks. Often times,
however, agent work toward different kinds goals once. often
done interleaving actions solutions individual goals. say
interleaving function returns one first two arguments,
depending third state argument:

(s; p1 ; p2 ) 2 fp1 ; p2g;
last two arguments policies, result policy, define
notation:
Ip1;p2 (s) = (I (s; p1 ; p2 ))(s)
wanted simultaneously make toast cook egg, good interleaving
toast-making policy egg-cooking policy would one chose egg-making
policy whenever egg finished current cooking step (and ready
ipped removed pan) chose toast-making policy egg busy
cooking. bad interleaving would one always chose toast-making policy.
interleaving fair p1 p2 starting state, Ip1 ;p2
finite number steps executed p1 p2 least once. Finally, say
two bindings independent map disjoint sets components images.
Binding independence special case subgoal independence: two policies can't possibly
interfere alter distinct state components. Fairness binding independence
sucient conditions interleaving solve conjunctive goal:

Lemma 7 Let p1 = A1 p01 1 p2 = A2 p02 2 policies solve goals G1

G2, respectively, halt. 1 2 independent fair interleaving
p1 p2 Ip1;p2 solves G1 \ G2 halts.
Proof: Since fair interleaving, two policies executed finite time,
regardless starting state. induction, n, number steps
guaranteed executed least n steps policy.
policy p1 composition policy p01 state space S1 binding.
p1 solves G1 halts, must p01 solve (G1 ) halt finite
number steps n. execution, environment goes series states

s0; s1; :::; sn
project 1 series states

s00; s01; :::; s0n
claim execution interleaving Ip1 ;p2 must bring environment
sequence states project 1
(s00 )+ ; (s01 )+ ; :::; (s0n )+ ; :::
133

fiAgre & Horswill
is, string states s00 appears least once, s01 , appears least once,
on. state transitions appear s0i s0i+1 .
Suppose otherwise. must point series broken:
(s00 )+ ; (s01 )+ ; :::; (s0i )+ ;
neither s0i s0i+1 . two cases. Case 1: p1 executed transition.
p01 (s0i ) = 6= s0i+1 , contradiction. Case 2: p2 executed transition.
p2 changed one state components mapped 1 2 1
independent, contradiction. Thus interleaving solves G1 . reasoning,
must halt G1 , since p1 halts G1 . Also reasoning, must solve G2
halt, hence, must solve intersection halt. 2
useful corollary policy applied two independent
bindings, bindings safely interleaved, is, interleaving commutes binding:

Corollary 2 p1 = A1 p 1 p2 = A2 p 2 policies solve goals G1
G2, respectively, halt, fair interleaving p1 p2, AI1;2 p I1;2
solves G1 \ G2 halts.

8. Implementing Policies Bindings

modeled Toast's behavior composition various bindings interleavings
basic policy schematic environment. case Toast, basic policy
simple enough implemented table-lookup. hard part implementing
bindings interleavings given realistic limitations short-term memory perceptual
bandwidth.
One approach would assume relatively complete representation world.
egg would represented logical constant state would represented
set propositions involving constant. binding would implemented
frame structure set variables point logical constants. problem
approach presupposes underlying perceptual motor systems maintain
correspondence logical constants eggs world. one eggs
changes, visual system know looking update assertions
egg model.
assumption taken lightly. capacity human perceptual
system keep track objects world extremely limited. Ballard et al. (1995)found
experimental subjects adopt strategies minimized amount world state
needed track internally, preferring rescan environment information
needed rather memorize advance. environment could even modified
saccadic eye movements without subjects noticing.
alternative treat limitations body, locality space, limited
attentional motor resources resource implementing bindings directly. person
visually focus one object, stand one place, grasp objects
one time. orientation body's parts relative environment used
encode selection objects operated moment. words,
134

fiLifeworld Analysis
implement binding. Actions body, gaze shifts, movements new places
used shift binding.
Another alternative use states relationships objects world keep
track bindings. egg cooked frying pan. fork available
use drawer, sink waiting washed.
section, model use body conventions implement bindings interleavings. simplify presentation concrete, focus
materials, particularly eggs.

8.1 Binding, Deixis, Gaze

first approximation, people visually recognize objects
directly looking. People achieve illusion direct access arbitrary objects rapidly
changing gaze direction. Thus addition normal state environment,
lived world contains additional state component, gaze direction. Since
normally change gaze direction without changing world, vice versa, lived
world E 0 separated parallel product objective environment gaze
direction:
E0 = E k
access world gaze, allows us focus one particular
object time. gaze implements binding, precisely, binding map, since
depends direction gaze. model gaze direction number indicating
object presently foveated, that:
gaze(s1 ; s2; :::; sn ; d) = sd
person could implement single-object binding fixating object wish
bind. First would set component egg, use binding.
Since really binding map, however, rather true binding, agent must
pervasively structure activity ensure gaze need never redirected.

8.2 Binding Convention

general, agents must maintain bindings sort convention, whether
structuring internal memory, case problem solver, structuring
activity. case gaze above, agent maintains binding
convention spatial relation eye object binding.
versions Toast date maintained bindings using conventions (simulated)
spatial arrangement states objects.
One reason Toast cannot rely solely gaze binding technique breaks
binding multiple objects. agent must continually move gaze among objects
interest additional convention must introduced ensure
gaze leaves egg later returns, always returns egg. (This assumes,
course, Toast must return egg. tasks may suce Toast
return functionally equivalent egg. preparing three fried eggs
attention distracted preparing break second one, alright attention
returns third egg, long gets back second egg eventually.)
135

fiAgre & Horswill
State conventions

original version Toast used convention eggs bound cooking task
iff starting (unbroken) state. Eggs therefore bound using
binding map

Toast (s) = state unique egg unbroken state
agent implement first visually searching unbroken egg,
using gaze . corollary 2, interleaving cooking multiple eggs accomplished interleaving bindings eggs. example, might assume
visual system searched non-deterministically round-robin fashion eggs. fair
interleaving suce.
Spatial conventions

Later development Toast, found useful adopt convention
eggs bound cooking task iff located designated workspace. Cooking
eggs counter frying pan, idle eggs refrigerator.
convention lets agent use space external memory binding information. bind
egg, agent faces workspace performs visual search egg. egg
finds egg cooked, since idle eggs view.
still leaves open issue fairness. extreme elegant solution fairness
problem use multiple workspaces employ convention workspace
defines unique binding. cook two eggs, agent works cooking whatever egg
front it, spins place alternates workspaces.
Formally, environment consists two copies workspace objects
therein plus extra state component determines workspace agent faces.
agent's perceptual system implements binding map one
two workspaces bound depending agent's orientation. Given policy
cooking one egg one workspace, construct policy cooking two eggs two
interleaving policy \ ipping" operation switches workspaces:

Proposition 4 Let E = (S; A) environment, p policy solves goal G

E halts, let environment two states, 0 1, two actions,
(the identity) flip moves environment opposite state present
state. Consider product environment:

E0 = E *
)E *
)D
binding map E 0 E :

MD (s0 ; s1; d) = sd
fair interleaving policies:

pMD = AMD p MD
136

fiLifeworld Analysis

real world
idealization

functionally equivalent objects
least reset
binding map

binding maps
interleavings

general tools
resetting policies

self-cleaning tools
isomorphism

single object
isomorphism

canonical chain

Figure 6: Various alternative reductions used Toast.


pflip(s0; s1 ; d) = flip

solution problem (E 0 ; (G G f0; 1g)).
Proof: Consider bindings 0 : (s0 ; s1 ; d) ! s0 1 : (s0 ; s1 ; d) ! s1 , let p0 =
A0 p 0 p1 = A1 p 1. Since binding map MD alternates
bindings 0 1 , fair interleaving pMD pflip equivalent interleaving
p0 , p1 pflip . would like show interleaving also fair, is,
p0 p1 get run finite time. see fact
execution pflip switches MD one binding another. objection
leaves open possibility pflip always get run twice row, thus returning
environment original state preventing MD switching bindings.
cannot occur, however, since would introduce loop, causing interleaving run pflip
forever, never running pMD , violating assumption fairness interleaving
pMD pflip. Thus interleaving p0 , p1 pflip must fair. note
p0 solves goal G f0; 1g halts, p1 solves goal G f0; 1g halts,
pflip solves goal G G f0; 1g halts. Thus lemma 7, interleaving solves
intersection goals, G G f0; 1g. 2
137

fiAgre & Horswill

9. Reductions Structure Toast
shown cooking problem solved series reductions
conventions. Binding allows reduction problem schematic world
action greatly restricted action selection greatly simplified. world
reduced, given algorithms resetting tools, world tools always
reset. world, turn, equivalent world one object,
material cooked, one action taken given time. actions
found table lookup.
Multiple materials cooked interleaving execution processes cooking
individual materials. Interleaving processes equivalent, however, interleaving
bindings, schematic-world algorithm need even aware pursuing
multiple goals. tool bindings continuously changed tools dirtied tools
effectively disposable, tools effectively single state, separate reduction
general tools single-state tools unnecessary. Material bindings maintained
number conventions involving states and/or positions objects.
short, describe Toast algorithm path network possible
simplifications problem (see Figure 6) every path actual world
idealized single-object world defines possible (and correct) version Toast
algorithm.

10. Cognitive Autopoiesis
formalizing ideas binding gaze, moving toward theory
intentionality depends agent's embedding world, rather solely upon
internal models world. agent keep track particular objects terms
functional significance { roles play ongoing activity.
keep track tools materials associated different tasks keeping
different locations, example different regions countertop. far, however,
ideas subject limited simple cases, example agent switching
visual focus back forth two objects. model complex patterns
found everyday life, need much better theory world
embedded. theory partially matter biology physics, course,
also matter cultural practices organizing activities space. section,
would like sketch general theory matters using concept \cognitive
autopoiesis."
Maturana Varela (1988), autopoiesis refers processes organisms
act environments order provide conditions continued functioning. Cognitive autopoiesis refers active means agents structure
environments order provide conditions cognitive activities.
include basically means agents provide factorability environments: engaging customary activities, using customary tools materials them,
partitioning activities customary ways, on. also includes range
subtle phenomena. Kirsh (1995), example, drawn useful distinction
actions aim achieving functional goals (beating eggs, sweeping oors)
138

fiLifeworld Analysis
actions aim facilitating cognition (setting right number eggs beginning, opening curtains dust visible). Actions can, course,
serve purposes, example one chooses boil water kettle rather
saucepan: strategy achieves result, latter also provide sign
possible take next action, example preparing tea. Stabilization actions (Hammond et al., 1995) also provide cognitive conditions actions. One might,
example, develop habit leaving items door moment one realizes
need taken work.
phenomena help understanding inadequate concept \the
environment." one conceptualizes \the environment" monolithic whole, perhaps
way looks viewed airplane, else way looks understood
peephole momentary vector sense-perceptions, begins seem arbitrary, chaotic,
hostile. certain sense seems static, anatomy physiology.
fact phenomena cognitive autopoiesis reveal lifeworld great
deal living structure, structure actively maintained agents also
providing crucial preconditions cognition. Indeed hard draw clear line
around agent's cognition; trace sequence causal events led given agent
pour pitcher milk particular moment, sequence lead back forth
agent customary surroundings. almost surroundings
extension one's mind.
Cognitive autopoiesis complex multifaceted phenomenon single theory
suce explain it. One useful way think cognitive autopoiesis spatially,
terms series buffer zones embodied agent putative dangers
complexities \the environment." people whose lives similar own,
buffer zones conveniently sorted six headings:

body itself: posture, markings, things might attached hung

it, prostheses, artificial markings, things one holding one's hands,
on. things serve forms memory, example way
remember activity one middle momentary distraction.
body's motility also makes possible wide range voluntary reconfigurations
one's physical relationship things, example get better view better
leverage.

Clothing, including pockets, purses, money belts, hats, on. Everyone carries
around various objects ways draw customary practices artifacts (cash
wallets, keys pockets, watch wrist, etc) configuring things
evolving personal way (keys left pocket money right, tissues hip pocket
one's coat, spare change outer ap backpack, on).

Temporary workspaces one occupies perform particular activity bound-

ed period. repairing bicycle, example, one might spread tools bicycle
parts oor patterns cognitive significance relationship
one's body cognitive states (Chapman & Agre, 1986). One
claiming space permanent colony (it might located patio
139

fiAgre & Horswill
public park, example), one lay claim space long enough perform
customarily bounded task.

One's private spaces: home, desk, oce, car, trunks stuff kept someone else's

attic, forth. spaces serve numerous functions, course, among
cognitive functions providing stable locations long periods time
tools materials, storage places stuff needs kept adequate supply,
practices regulating people's access stuff, on. stable
conditions actively maintained provide background wide variety
transient activities.

Spaces shared people within stable, time-extended relationships.
spaces include living rooms, kitchens, shared oce spaces, forth.
line private shared spaces clearly depends particular culture
set relationships, distinction might clear. point
cognitive functions spaces maintained shared practices
letting someone know borrow stuff.

Public spaces whole range customary artifacts practices regu-

late activities them. Public spaces offer fewer guarantees private shared
spaces, include wide variety supports cognition, including signs
architectural conventions. also possible use one's body clothing
carry artifacts provide cognitive support dealing public spaces.

buffer zones always offer perfect protection harm complete support
pursuit goals. Shared public spaces sites con ict, example,
con icts include involuntary disruption destruction one's body
buffer zones customarily one's private control. serious theory
activity must include account phenomena well, usually
orderly way anything else.
event, nested buffer zones ordinary life participate large metabolism
continually interweaves cognitive functional purposes. Among purposes
learning. adaptation body parts tools customary activities helps channel action customary directions, existing background objects, spaces,
practices help channel actions children newcomers customary directions
larger scale. Caretakers regularly construct customized types buffer zones around
young, example, dicult impossible get anything
could cause harm. lifeworld child, example, differs adult
reach cookie jar locked cupboard roach spray
kept. growing literature investigated processes cognitive apprenticeship (Rogoff, 1990), situated learning (Lave & Wenger, 1991), distributed cognition (Hutchins, 1995;
Salomon, 1993), shared construction activities (Grin & Cole, 1989) go
systematically restrictive supportive lifeworlds.
140

fiLifeworld Analysis

11. Conclusion

paper explored ways structure lifeworld
supports agents' cognition, suggested analysis might expanded
cover wider range phenomena. Much work obviously remains done. Perhaps
significant part work concerns fundamental assumption lifeworld analysis:
people use objects customary ways. plausible enough first approximation,
always true. Faced diculty goes beyond capacities
usual practices artifacts readily available, people frequently improvise.
handle spoon might used pry open lid, pen might used fish acorns
exhaust duct, book might used provide backing sheet paper one
writing on, protruding section car's bumper might bent straight deliberately
driving car concrete wall. cases underlying physical affordances
object \show through" beyond ready-to-hand appropriation routine patterns
interaction. underlying affordances also show situations breakdown, example tool breaks proves inadequate job. cases, people
confer improvised meanings upon artifacts. phenomena particularly important
conversation, utterance interpreted context created previous
utterances, simultaneously helping create context interpretation successive utterances well (Edwards & Mercer, 1987; Atkinson & Heritage, 1984). point
lifeworld exist, rather something actively created
well something adapted socialization. One challenge future research
learn computational methods might help modeling phenomena|and
phenomena might help us rethink basic ideas computation.

Acknowledgements

appreciate detailed comments referees. work funded part
National Science Foundation grant number IRI{9625041. Institute
Learning Sciences established 1989 support Anderson Consulting, part
Arthur Anderson Worldwide Organization.

Glossary Terms

Binding. simple projection (mapping state-space components two environ-

ments) acts reduction one environment another (see section 7.2.1).
Binding map. mapping environment states bindings (see section 7.2.3).
Cartesian product. sets: B set pairs (a; b) 2 A, b 2 B .
environments: environment Cartesian product two environments iff
state space Cartesian product state spaces. Since set actions
left open definition, many possible ways forming products, e.g. serial
product, parallel product, uniform extension, etc.(see section 5.1).
Discrete control problem (DCP). environment set goal states within
(see section 5).
Environment. state machine, i.e. , set possible states set possible actions
mapping states states. sets states actions need finite (see section 5).
141

fiAgre & Horswill

Focus. action focused state component alters component (see

section 7.1.3).
Material. object (environment) whose state space chain (see section 7.1).
Policy. mapping states actions; formalization agent's control structure
(see section 5).
Projection. mapping state space one environment state space
another (see section 5.2).
Simple projection. mapping state spaces maps state space components
one environment state space components another (see section 5.2).
State component. (For environments whose state spaces Cartesian products)
element environment's state-tuple (see section 5.1).
Solution. policy solves DCP initial state if, run state,
eventually reaches goal state (see section 5).
Tool. (Roughly) state component brought ready state without altering
state components (see section 7.1.3).
Uniform reducibility. (Roughly) E 0 uniformly reducible E consists multiple
copies E 's objects (see section 7.2.1).

Glossary Notation

. Function composition operator: f g(x) = f (g(x)).

. projection (p. 122).
,1. inverse , i.e. set states map given state (p. 131).
,. (For simple projection : 0 ! ). generalized inverse. Since maps certain
components 0 , , (s; s0 ) s0 components replaced corresponding
components (p. 130).
. simple reduction environment E 0 E , function mapping action
E action implements E 0 (p. 122).
Cn. chain-environment n states (p. 127).
E . environment.
9E;E G. G goal E E 0 uniformly reducible E . existential goal G E 0 :
set E 0 -states map goal state binding (p. 130).
E1 *
) E2. serial product. Cartesian product E1 E2 actions
0

two environments must taken separately (p. 120).
E1 k E2 . parallel product. Cartesian product E1 E2 actions
two environments must taken simultaneously (p. 120).
LE;E . (E 0 environment uniformly reducible E ) leftmost-ready binding map
E 0 E (p. 131).
p. policy.
pE;G. standard policy single-material environment E goal G (p. 127).
. singleton environment (the environment exactly one state). Used represent
self-resetting tool (p. 128).
0

142

fiLifeworld Analysis

References

Agre, P., & Horswill, I. (1992). Cultural support improvisation. Tenth National Conference Artificial Intelligence Cambridge, MA. American Association Artificial
Intelligence, MIT Press.
Agre, P. E. (1995). Computational research interaction agency. Artificial Intelligence,
72 (1{2), 1{52.
Agre, P. E. (1997). Computation Human Experience. Cambridge University Press,
Cambridge, UK.
Agre, P. E., & Chapman, D. (1987). Pengi: implementation theory activity.
Proceedings Sixth National Conference Artificial Intelligence, pp. 268{272.
Atkinson, J. M., & Heritage, J. (1984). Structures Social Action. Cambridge University
Press, Cambridge, UK.
Ballard, D. H., Hayhoe, M. M., Pook, P. K., & Rao, R. P. N. (1995). Deictic codes
embodiment cognition. Technical report 95.1, University Rochester National
Resource Laboratory study Brain Behavior, Rochester, NY. Revised
July 1996.
Beach, K. D. (1988). role external mnemonic symbols acquiring occupation.
Gruneberg, M. M., Morris, P. E., & Sykes, R. N. (Eds.), Practical Aspects Memory:
Current Research Issues, volume 1: Memory Everyday Life. Wiley, Chichester,
UK.
Beer, R. D. (1995). dynamical systems perspective agent-environment interaction.
Artificial Intelligence, 72 (1{2), 173{215.
Brady, J. M., Agre, P. E., Braunegg, D. J., & Connell, J. H. (1984). mechanic's mate.
Proceedings 1984 European Conference Artificial Intelligence Pisa, Italy.
Chapman, D., & Agre, P. E. (1986). Abstract reasoning emergent concrete activity.
Georgeff, M. P., & Lansky, A. L. (Eds.), Reasoning Actions Plans, Proceedings 1986 Workshop, Timberline, Oregon. Morgan-Kaufmann Publishers,
Los Altos, CA.
Dixon, M. (1991). Embedded computation semantics programs. TR SSL-91-1,
Xerox Palo Alto Research Center, Palo Alto, CA.
Donald, B. R., & Jennings, J. (1992). Constructive recognizability task-directed robot
programming. Robotics Autonomous Systems, 9, 41{74.
Edwards, D., & Mercer, N. (1987). Common Knowledge: Development Understanding Classroom. Methuen, London.
Gibson, J. J. (1986). Ecological Approach Visual Perception. Erlbaum, Hilldale, NJ.
Originally published 1979.
143

fiAgre & Horswill
Grin, D. N. P., & Cole, M. (1989). Construction Zone: Working Cognitive Change
School. Cambridge University Press, Cambridge.
Hammond, K. J., Converse, T. M., & Grass, J. W. (1995). stabilization environments.
Artificial Intelligence, 72 (1{2), 305{327.
Horswill, I. (1995). Analysis adaptation environment. Artificial Intelligence, 73 (1{2),
1{30.
Hutchins, E. (1995). Cognition Wild. MIT Press, Cambridge, MA.
Kirsh, D. (1995). intelligent use space. Artificial Intelligence, 72 (1{2), 31{68.
Knoblock, C. A. (1989). theory abstraction hierarchical planning. Benjamin,
D. P. (Ed.), Change Representation Inductive Bias. Kluwer, Boston.
Kosecka, J. (1992). Control discrete event systems. GRASP LAB report 313, University
Pennsylvania Computer Information Science Department, Philadelphia, PA.
Lansky, A. L., & Fogelsong, D. S. (1987). Localized representations planning methods
parallel domains. Proceedings Sixth National Conference Artificial
Intelligence, pp. 240{245 Menlo Park, CA. AAAI Press.
Lave, J., & Wenger, E. (1991). Situated Learning: Legitimate Peripheral Participation.
Cambridge University Press, Cambridge, UK.
Littman, M. L. (1993). optimization-based categorization reinforcement learning
environments. Meyer, & Wilson (Meyer & Wilson, 1993), pp. 262{270.
Lyons, D. M., & Arbib, M. A. (1989). formal model computation sensory-based
robotics. IEEE Transactions Robotics Automation, 5 (3), 280{293.
Maturana, H. R., & Varela, F. J. (1988). Tree Knowledge: Biological Roots
Human Understanding. Shambhala, Boston.
Meyer, J.-A., & Wilson, S. W. (Eds.). (1993). Animals Animats: Second
International Conference Simulation Adaptive Behavior. MIT Press, Cambridge,
MA.
Newell, A., Shaw, J. C., & Simon, H. A. (1960). Report general problem-solving
program. Proceedings International Conference Information Processing,
pp. 256{264 Paris.
Newell, A., & Simon, H. A. (1963). GPS: program simulates human thought.
Feigenbaum, E. A., & Feldman, J. (Eds.), Computers Thought, pp. 279{296.
McGraw-Hill.
Rogoff, B. (1990). Apprenticeship Thinking: Cognitive Development Social Context.
Oxford University Press, New York.
144

fiLifeworld Analysis
Rosenschein, S. J. (1987). Formal theories knowledge AI robotics. report CSLI87-84, Center Study Language Information, Stanford, CA.
Rosenschein, S. J. (1989). Synthesizing information-tracking automata environment
descriptions. Brachman, R. J., Levesque, H. J., & Reiter, R. (Eds.), Proceedings
First International Conference Principles Knowledge Representation
Reasoning, pp. 386{393.
Rosenschein, S. J., & Kaelbling, L. P. (1986). synthesis machines provable
epistemic properties. Halpern, J. (Ed.), Proc. Conf. Theoretical Aspects
Reasoning Knowledge, pp. 83{98. Morgan Kaufmann.
Sacerdoti, E. D. (1974). Planning hierarchy abstraction spaces. Artificial Intelligence,
5 (2).
Salomon, G. (Ed.). (1993). Distributed Cognitions: Psychological Educational Considerations. Cambridge University Press.
Schutz, A., & Luckmann, T. (1973). Structures Life-World. Northwestern
University Press, Evanston, IL.
Simon, H. A. (1947). Administrative Behavior: Study Decision-Making Processes
Administrative Organization. Macmillan, New York.
Simon, H. A. (1970). Sciences Artificial. MIT Press, Cambridge, MA.
Sussman, G. J. (1975). Computer Model Skill Acquisition. Elsevier, New York.
Todd, P. M., Wilson, S. W., Somayaji, A. B., & Yanco, H. A. (1994). blind breeding
blind: Adaptive behavior without looking. Cliff, D., Husbands, P., Meyer,
J.-A., & Wilson, S. W. (Eds.), Animals Animats: Third International
Conference Simulation Adaptive Behavior, pp. 228{237. MIT Press.
Todd, P. M., & Wilson, S. W. (1993). Environment structure adaptive behavior
ground up. Meyer, & Wilson (Meyer & Wilson, 1993), pp. 11{20.
Wilson, S. W. (1991). animat path AI. Meyer, J.-A., & Wilson, S. W. (Eds.),
Animals Animats: Proceedings First International Conference Simulation
Adaptive Behavior, pp. 15{21. MIT Press, Cambridge, MA.
Winston, P. H., Binford, T. O., Katz, B., & Lowry, M. (1983). Learning physical descriptions
functional definitions, examples, precedents. Proceedings National
Conference Artificial Intelligence, pp. 433{439 Austin, TX.

145

fiJournal Artificial Intelligence Research 6 (1997) 35-85

Submitted 7/96; published 1/97

SCREEN: Learning Flat Syntactic Semantic Spoken
Language Analysis Using Artificial Neural Networks
Stefan Wermter
Volker Weber

wermter@informatik.uni-hamburg.de
weber@informatik.uni-hamburg.de

Department Computer Science
University Hamburg
22527 Hamburg, Germany

Abstract
Previous approaches analyzing spontaneously spoken language often based
encoding syntactic semantic knowledge manually symbolically.
progress using statistical connectionist language models, many current
spoken-language systems still use relatively brittle, hand-coded symbolic grammar
symbolic semantic component.
contrast, describe so-called screening approach learning robust processing
spontaneously spoken language. screening approach analysis uses shallow sequences category representations analyzing utterance various syntactic,
semantic dialog levels. Rather using deeply structured symbolic analysis,
use connectionist analysis. screening approach aims supporting speech
language processing using (1) data-driven learning (2) robustness connectionist
networks. order test approach, developed screen system
based new robust, learned analysis.
paper, focus detailed description screen's architecture,
syntactic semantic analysis, interaction speech recognizer, detailed
evaluation analysis robustness uence noisy incomplete input.
main result paper representations allow robust processing
spontaneous spoken language deeply structured representations. particular,
show fault-tolerance learning capability connectionist networks support
analysis providing robust spoken-language processing within overall
hybrid symbolic/connectionist framework.

1. Introduction
Recently fields speech processing well language processing seen
efforts examine possibility integrating speech language processing (von Hahn
& Pyka, 1992; Jurafsky et al., 1994b; Waibel et al., 1992; Ward, 1994; Menzel, 1994; Geutner
et al., 1996; Wermter et al., 1996). new large speech language corpora
developed rapidly, new techniques examined particularly support
properties speech language processing. Although quite
approaches spoken-language analysis (Mellish, 1989; Young et al., 1989; Hauenstein &
Weber, 1994; Ward, 1994), emphasized learning syntactic semantic
analysis spoken language using hybrid connectionist1 architecture topic
c 1997 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiWermter & Weber

paper goal screen2 . However, learning important reduction
knowledge acquisition, automatic system adaptation, increasing system
portability new domains. Different previous approaches, paper
demonstrate hybrid connectionist learning techniques used providing
robust analysis faulty spoken language.
Processing spoken language different processing written language, successful techniques text processing may useful spoken-language processing.
Processing spoken language less constrained, contains errors less strict regularities written language. Errors occur levels spoken-language processing.
instance, acoustic errors, repetitions, false starts repairs prominent spontaneously spoken language. Furthermore, incorrectly analyzed words, unforeseen grammatical semantic constructions occur often spoken language. order deal
important problems \real-world" language analysis, robust processing necessary.
Therefore cannot expect existing techniques like context-free tree representations
proven work written language simply transferred spoken
language.
instance, consider speech recognizer produced correct German sentence hypothesis \Ich meine naturlich Marz" (English translation: \I mean course
March"). Standard techniques text processing - like chart parsers context-free
grammars - may able produce deeply structured tree representations many correct
sentences shown Figure 1.
sentence
verb phrase

noun group

pronoun

verb group

verb

noun group

adverb

ich (I) meine (mean) natrlich (of_course)

noun

Mrz (March)

Figure 1: Tree representation correctly recognized sentence
However, currently speech recognizers still far perfect produce many word
errors possible rely perfect sentence hypothesis. Therefore, incorrect
1. Sometimes connectionist networks also called artificial neural networks. use
term \connectionist networks", term \hybrid connectionist architecture" refer
architecture emphasizes use connectionist networks rule use
symbolic representations higher levels might needed.
2. Symbolic Connectionist Robust EnterprisE Natural language

36

fiSCREEN: Flat Syntactic Semantic Spoken Language Analysis

variations like \Ich meine ich Marz" (\I mean March"), \Ich hatte ich Marz" (\I
March") \Ich Ich meine Marz" (\I mean March") analyzed. However,
context-free grammars single syntactic semantic category error may prevent
complete tree built, standard top-down chart parsers may fail completely. However, suboptimal sentence hypotheses analyzed since sometimes sentence
hypotheses best possible output produced speech recognizer. Furthermore,
lot content extracted even partially incorrect sentence hypotheses.
instance, \I March" plausible agent \I" said something
time \March". Therefore, robust analysis able analyze sentence
hypotheses ideally break input.

1.1 Screening Approach: Flat Representations Support Robustness
examples incorrect variations sentence hypotheses, in-depth structured
syntactic semantic representation advantageous since arbitrary word order spontaneous errors make often impossible determine desired deep highly
structured representation. Furthermore, deep highly structured representation may
many restrictions appropriate spontaneously spoken language. However,
maybe even important, certain tasks necessary perform in-depth
analysis. While, instance, inferences story understanding require in-depth
understanding (Dyer, 1983), tasks like information extraction spoken language
need much in-depth analysis. instance, output parser used
translating speech recognizer sentence hypothesis \Eh ich meine eh ich Marz" (\Eh
mean eh March"), may sucient extract agent (\I") uttered (\mean")
time (\March"). contrast deeply structured representation, screening approach
aims reaching robust representation spoken language. screening approach
shallow analysis based category sequences (called representations) various
syntactic semantic levels.
representation structures utterance U words w1 wn according
syntactic semantic properties words contexts, e.g., according sequence
basic abstract syntactic categories. instance, phrase \a meeting London"
described representation \determiner noun preposition noun" basic
syntactic level representation \noun-group noun-group prepositional-group
prepositional-group" abstract syntactic level. Similar representations used
semantic categories, dialog act categories, etc.
Kase
(Rubbish)
noun

noun group
negation

ich
(I)
pronoun
animate
noun group
agent

meine
(mean)
verb
utter
verb group
action

naturlich
(of course)
adverb
nil
special group
miscellaneous

Marz
(March)
noun
time
noun group
time

Figure 2: Utterance representation
37

fiWermter & Weber

Figure 2 gives example representation correct sentence hypothesis
\Kase ich meine naturlich Marz" (\Rubbish mean course March"). first line shows
sentence, second literal translation. third line describes basic syntactic
category word, fourth line shows basic semantic category. last two lines
illustrate syntactic semantic categories phrase level.
Kase
(Rubbish)
noun

noun group
negation

ich
(I)
pronoun
animate
noun group
agent

hatte
(had)
verb

verb group
action

ich
(I)
pronoun
animate
noun group
agent

Marz
(March)
noun
time
noun group
time

Figure 3: Utterance representation
Figure 3 gives example representation incorrect sentence hypothesis
\Kase ich hatte ich Marz" (\Rubbish March"). parser spoken language
able process sentence hypotheses far possible, use
representations support necessary robustness. example, analysis
least provide animate agent noun group (\I") made statement
specific time noun group (\March"). Flat representations potential support
robustness better since minimal sequential structure, even error
occurs whole representation still built. contrast, standard tree-structured
representations many decisions made construct deeply structured
representation, therefore possibilities make incorrect decisions,
particular noisy spontaneously spoken language. chose representations
rather highly structured representations desired robustness
mistakes speech/language systems.

1.2 Flat Representations Learned Hybrid Connectionist Framework

Robust spoken-language analysis using representations could pursued different
approaches. Therefore want motivate use hybrid connectionist approach,
uses connectionist networks far possible rule use symbolic
knowledge. use connectionist networks?
important, due distributed fault tolerance, connectionist networks support
robustness (Rumelhart et al., 1986; Sun, 1994) connectionist networks also number properties relevant spoken-language analysis. instance,
connectionist networks well known learning generalization capabilities.
Learning capabilities allow induce regularities directly examples. training
examples representative task, noisy robust processing supported
inductive connectionist learning.
Furthermore, hybrid connectionist architecture property different knowledge sources take advantage learning generalization capabilities connectionist networks. hand, knowledge - task control knowledge -
38

fiSCREEN: Flat Syntactic Semantic Spoken Language Analysis

rules known represented directly symbolic representations. Since humans apparently symbolic inferencing based real neural networks, abstract models
symbolic representations connectionist networks additional potential
shed light human language processing capabilities. respect, approach
also differs candidates robust processing, like statistical taggers statistical
n-grams. statistical techniques used robust analysis (Charniak, 1993)
statistical techniques like n-grams relate human cognitive language capabilities simple recurrent connectionist networks relationships human
cognitive language capabilities (Elman, 1990).
screen new hybrid connectionist system developed examination
syntactic semantic analysis spoken language. earlier work explored
scanning understanding written texts (Wermter, 1995; Wermter & Lochel, 1994;
Wermter & Peters, 1994). Based experience started completely new project
screen explore learned fault-tolerant analysis spontaneously spoken-language
processing. preliminary successful case studies transcripts developed
screen system using knowledge generated speech recognizer. previous work,
gave brief summary screen specific focus segmentation parsing dialog
act processing (Wermter & Weber, 1996a). paper, focus detailed description
screen's architecture, syntactic semantic analysis, interaction
speech recognizer, detailed evaluation analysis robustness uence
noisy incomplete input.

1.3 Organization Claim Paper
paper structured follows. Section 2 provide detailed description
examples noise spoken language. Noise introduced human speaker
also speech recognizer. Noise spoken-language analysis motivates representations whose categories described Section 3. basic abstract categories
syntactic semantic level explained section. Section 4 motivate
explain design screen architecture. brief functional overview, show
overall architecture explain details individual modules connectionist
network level. order demonstrate behavior analysis spoken language
provide various detailed examples Section 5. Using several representative sentences
walk reader detailed step-by-step analysis. behavior system explained, provide overall analysis screen system Section 6.
evaluate system's individual networks, compare performance simple recurrent networks statistical n-gram techniques, show simple recurrent networks
performed better 1-5 grams syntactic semantic prediction. Furthermore
provide overall system evaluation, examine overall performance uence
additional noise, supply results transfer different second domain. Finally
compare approach approaches conclude representations based
connectionist networks provide robust learned spoken-language analysis.
want point paper make argument deeply structured symbolic representations language processing general. Usually, deeply
structured representation built, course due additional knowledge con39

fiWermter & Weber

tains, potential powerful relationships interpretations greater
representation. instance, in-depth analysis required tasks like making
detailed planning inferences reading text stories. However, screening approach
motivated based noisy spoken-language analysis. noisy spoken-language analysis,
representations support robustness, connectionist networks effective providing robustness due learned fault-tolerance. main contribution
paper, demonstrate building evaluating computational hybrid
connectionist architecture screen based at, robust, learned processing.

2. Processing Spoken Language

goal learn process spontaneously spoken language syntactic semantic
level fault-tolerant manner. section give motivating examples spoken
language.

2.1 \Noise" Spoken Language

domain paper arrangement meetings business partners,
currently use 184 spoken dialog turns 314 utterances domain. One
turn consists one subsequent utterances speaker. 314
utterances, thousands utterance hypotheses generated processed
based underlying speech recognizer. German utterance examples domain
shown together literal English translation. important note
English translations word-for-word translations.
1. Kase ich meine naturlich Marz
(Rubbish mean course March)
2. Der vierzehnte ist ein Mittwoch richtig
(The fourteenth Wednesday right)
3. hm sechsten April bin ich leider auer Hause
(Eh sixth April unfortunately home)
4. Also ich dachte noch der nachsten Woche auf jeden Fall noch im April
(So thought still next week case still April)
5. Gut prima vielen Dank dann ist das ja kein Problem
(Good great many thanks yeah problem)
6. Oh das ist schlecht da habe ich um vierzehn Uhr dreiig einen Termin beim Zahnarzt
(Oh bad fourteen o'clock thirty date dentist)
7. Ja genau allerdings habe ich da von neun bis vier Uhr schon einen Arzttermin
(Yes exactly however nine four o'clock already doctorappointment)
see, spoken language contains many performance phenomena, among
exclamations (\rubbish", see Example 1), interjections (\eh", \so", \oh", see Examples 3,
40

fiSCREEN: Flat Syntactic Semantic Spoken Language Analysis

4 6), new starts (\there ...", see Example 6). Furthermore, syntactic
semantic constraints spoken language less strict written text. instance,
word order spontaneously spoken language often different written language.
Therefore, spoken language \noisier" written language even transcribed
sentences, well-known parsing strategies text processing - rely
wellformedness criteria - directly applicable analyzing spoken language.

2.2 \Noise" Speech Recognizer

want analyze spoken language computational model,
\noise" introduced humans speaking also \noise" introduced limitations speech recognizers. Typical speech recognizers produce many separated word
hypotheses different plausibilities time based given speech signal. word
hypotheses connected word hypothesis sequence evaluated
providing basis analysis. Typically, word hypothesis consists four parts: 1)
#PAUSE#
0.00-[0.01-0.33]

hm (eh)

ich (I)

0.02-[0.11-0.33]

5.36e-02

0.12-[0.33-0.33]

wie (how)
2.92e-03

htte (had)
1.06-[1.21-1.21]

0.13-[0.33-0.33]

(on)
2.78e-03

April (April)
3.66e-04

0.81-[1.05-1.22]

ich (I)
1.22-[1.37-1.37]

1.12-[1.22-1.22]

ich (I)

leider (unfortunately)
3.33e-04

0.34-[0.43-0.43]

6.84e-03

sechsten (sixth)

6.53e-05

0.44-[0.80-0.80]

3.54e-03

1.13-[1.22-1.22]

bin (am)
1.53e-03

1.23-[1.30-1.37]

1.38-[1.59-1.59]

3.01e-01

5.07e-08

wenn (if)
3.35e-04

ich (I)
1.18e-02

1.31-[1.38-1.38]

1.81e-02

leider (unfortunately)
1.39-[1.59-1.59]

6.37e-04

auer (out of)
1.60-[1.90-1.90]

Hause (home)

6.74e-05

1.91-[2.37-3.38]

7.18e-01

2.38-[3.38-3.38]

#PAUSE#
3.39-[3.39-3.39]

1.88e-07

#not recognized#
2.74e-07

Figure 4: Simple word graph spoken utterance: \ahm sechsten April bin ich
leider auer Hause" (\eh sixth April unfortunately home").
node represents word hypothesis; arrow represents possible
subsequent word hypotheses. word hypothesis shown word
string, start time, end time interval acoustic plausibility.
41

fiWermter & Weber

start time seconds, 2) end time seconds, 3) word string hypothesis,
4) plausibility hypothesis based confidence speech recognizer. show simple word graph3 . practice, word graphs spontaneous speech
much longer leading comprehensive word hypothesis sequences. However, illustrating
properties speech input focus relatively short simple word graph
(Figure 4).
word hypotheses overlap time constitute directed graph called word
graph. node word graph represents one word hypothesis. Two hypotheses
graph generated word hypotheses connected end time first word
hypothesis directly start time second word hypothesis. instance,
word hypothesis \am" (\on") ending 0.43 hypothesis \sechsten" (\sixth")
starting 0.44 connected word hypothesis sequence.
hm
(eh)
hm
(eh)
0sec

ich
(I)


(on)

sechsten
(sixth)

April
(April)

bin
(am)

leider
(unfort.)

auer
(out of)

Hause
(home)


(on)

sechsten
(sixth)

April
(April)

wenn ich ich leider
(if) (I) (I) (unfort.)

auer
(out of)

Hause
(home)

1sec

ich
(I)

3sec

Figure 5: Two examples word hypothesis sequences word graph
example word graph simple. However, shown Figure 5, possible
word hypothesis sequence desired \A hm sechsten April bin ich leider
auer Hause" (\Eh sixth April unfortunately home"), also sequence
\A hm ich sechsten April wenn ich ich leider auer Hause" (\Eh sixth April
unfortunately home"). Consequently, deal incorrectly recognized
words extraordinary order. Therefore syntactic semantic analysis
fault-tolerant order process noisy word hypothesis sequences.

3. Flat Category Representation: Intermediate Connecting
Representation
section describe category representations. First, show
categories syntactic analysis depict categories semantic
analysis.
3. speech input form test word graphs taken so-called Blaubeuren Meeting
Corpus. particular word graphs used provided project partners general test
purposes Verbmobil project. particularly generated testing parsing strategies.
Therefore speech recognizer fine-tuned produce relatively small word graphs relatively
high word accuracy 93%. vocabulary size HMM recognizer 628. average number
hypotheses per word 6.3 10 dialogs.

42

fiSCREEN: Flat Syntactic Semantic Spoken Language Analysis

3.1 Categories Flat Syntactic Analysis

Flat syntactic analysis assignment syntactic categories sequence words, e.g.,
word hypothesis sequence generated speech recognizer. Flat representations
phrase group level support local structural decisions. Local structural decisions deal
problem phrase group (abstract syntactic category) word belongs to.
case local, directly preceding words phrase group uence
current decision. instance, determiner \the" could part prepositional group
\in mine" part starting noun group \the old mine". is, local structural
decisions depending local context made based analysis.
syntactic analysis developed level basic syntactic categories
abstract syntactic categories. syntactic categories may vary depending language, degree detail intended structural representation. However,
general approach rather independent specifically used categories. fact,
used syntactic categories two different domains: railway counter interactions
business meeting arrangements. basic syntactic categories used noun,
verb, preposition, pronoun, numeral, past participle, pause, adjective, adverb, conjunction,
determiner, interjection other. shown abbreviations Table 1.
Category
noun (N)
verb (V)
preposition (R)
pronoun (U)
numeral (M)
participle (P)
pause (/)

Examples
date, April
meet, choose
at,
I,
fourteenth
taken
pause

Category
adjective (J)
adverb (A)
conjunction (C)
determiner (D)
interjection (I)
(O)

Examples
late
often
and,
the,
eh, oh
particles

Table 1: Basic syntactic categories
abstract syntactic categories used verb group, noun group, adverbial group,
prepositional group, conjunction group, modus group, special group interjection group.
abstract syntactic categories shown Table 2.
Category
verb group (VG)
noun group (NG)
adverbial group (AG)
prepositional group (PG)
conjunction group (CG)
modus group (MG)
special group (SG)
interjection group (IG)

Examples
mean, would propose
date, next possible slot
later, early possible
dining hall
and, either ...
interrogatives, confirmations: when, long, yes
additives like politeness: please,
interjections, pauses: eh, oh

Table 2: Abstract syntactic categories
43

fiWermter & Weber

categories express main syntactic properties phrases.
basic abstract syntactic categories widely used different parsers. However,
approach representations crucially rely specific set basic
abstract syntactic categories. goal train, learn generalize syntactic
analysis based abstract syntactic categories basic syntactic categories. Local syntactic decisions made far possible. Local syntactic ambiguities
phrase group level (abstract syntactic categories) dealt global ambiguities like prepositional phrase attachment dealt since need
additional knowledge, e.g., semantics module. complete syntax trees
certain preference (which might turn wrong based semantic knowledge),
syntactic representation goes far possible using local syntactic knowledge
disambiguation.

3.2 Categories Flat Semantic Analysis

Since semantic analysis domain-dependent, semantic categories differ different
domains. worked particularly two domains: railway counter interactions (called:
Regensburg train corpus) business meeting arrangements (called: Blaubeuren meeting
corpus). 3/4 overlap semantic categories train corpus
Category
select (SEL)
suggest (SUG)
meet (MEET)
utter (UTTER)
(IS)
(HAVE)
move (MOVE)
aux (AUX)
question (QUEST)
physical (PHYS)
animate (ANIM)
abstract (ABS)
(HERE)
source (SRC)
destination (DEST)
location (LOC)
time (TIME)
negative evaluation (NO)
positive evaluation (YES)
nil (NIL)

Examples
select, choose
propose, suggest
meet, join
say, think
is,
had,
come, go
would, could
question words: where,
physical objects: building, oce
animate objects: I,
abstract objects: date
time location state words, prepositions: at,
time location source words, prepositions:
time location destination words, prepositions:
Hamburg, Pittsburgh
tomorrow, 3 o' clock, April
no, bad
yes, good
words \without" specific semantics, e.g., determiner:

Table 3: Basic semantic categories
meeting corpus (Wermter & Weber, 1996b). Differences occurred mainly verbs,
e.g., NEED-events frequent railway counter interactions SUGGESTevents frequent business meeting interactions. semantic categories
44

fiSCREEN: Flat Syntactic Semantic Spoken Language Analysis

Category
action (ACT)
aux-action (AUX)
agent (AGENT)
object (OBJ)
recipient (RECIP)
instrument (INSTR)
manner (MANNER)
time-at (TM-AT)
time-from (TM-FRM)
time-to (TM-TO)
loc-at (LC-AT)
loc-from (LC-FRM)
loc-to (LC-TO)
confirmation (CONF)
negation (NEG)
question (QUEST)
misc (MISC)

Examples
action full verb events: meet, select
auxiliary action auxiliary events: would like
agent action:
object action: date
recipient action:
instrument action: using elevator
achieve action: without changing rooms
time: morning
start time: 6am
end time: 8pm
location: Frankfurt, New York
start location: Boston, Dortmund
end location: Hamburg
confirmation phrase: ok great, yes wonderful
negation phrase: stop,
question phrases: time
miscellaneous words, e.g., politeness: please, eh

Table 4: Abstract semantic categories
railway counter interactions described previous work (Weber & Wermter, 1995).
primarily focus semantic categories meeting corpus. basic
semantic categories word shown Table 3. higher level abstraction,
word belong abstract semantic category. possible abstract semantic categories
shown Table 4. summary, categories provide basis analysis.
word represented syntactically semantically context four categories two
basic two abstract levels.

4. Architecture SCREEN System

section want describe constraints principles important
system design. outlined motivated introduction, screening approach
at, robust, learned analysis spoken language based category sequences (called
representations) various syntactic semantic levels. order test screening
approach, designed implemented hybrid connectionist screen system
processes spontaneously spoken language using learned connectionist representations.
summarize main requirements order motivate specific system design
explained subsequent subsections.

4.1 General Motivation Architecture

consider learning extremely important spoken-language analysis several
reasons. Learning reduces knowledge acquisition increases portability, particularly
spoken-language analysis, underlying rules regularities dicult
formulate often reliable. Furthermore, cases, inductive learning may detect
45

fiWermter & Weber

unknown implicit regularities. want use connectionist learning simple recurrent
networks rather forms learning (e.g., decision trees) primarily
inherent fault-tolerance connectionist networks, also knowledge
sequence words categories learned simple recurrent networks.
Fault-tolerance often occurring language errors ected system
design. commonly occurring errors (interjections, pauses, word repairs,
phrase repairs). However, fault-tolerance cannot go far try model class
occurring errors. number potentially occurring errors unpredictable constructions far large. screen, want incorporate explicit fault-tolerance using
specific modules correction well implicit fault-tolerance using connectionist network techniques inherently fault-tolerant due support similarity-based
processing. fact, even word completely unknown, recurrent networks use
empty input may even assign correct category sucient previous context.
Flat representations, motivated Sections 1 3, may support robust spokenlanguage analysis. However, connectionist representations provide full recursive power arbitrary syntactic semantic symbolic knowledge structures. contrast
context-free parsers, representations provide better basis robust processing
automatic knowledge acquisition inductive learning. However, also argued use potentially unrestricted recursion well-known context-free grammar
parsers provides computational model recursive power humans
order understand language. order better support robustness, want use
representations spontaneous language analysis.
Incremental processing speech, syntax, semantics dialog processing parallel
allows us start language analysis parallel speech recognizer finished
analysis. incremental processing advantage providing analysis results
early stage. example, syntactic semantic processing occur parallel
slightly behind speech processing. analyzing spoken language based speech
recognizer output, want consider many competing paths word hypothesis sequences
parallel.
respect hybrid representations, examine hybrid connectionist architecture
using connectionist networks useful also want use symbolic processing wherever necessary. Symbolic processing useful complex control
large system. hand learning robust analysis, use feedforward
simple recurrent networks many modules try use rather homogeneous, supervised
networks.

4.2 Overview Architecture

screen parallel integrated hybrid architecture (Wermter, 1994) various

main properties:

1. Outside module, difference communication symbolic
connectionist module. previous hybrid architectures emphasized different
symbolic connectionist representations, different representations screen
benefit common module interface. Outside connectionist symbolic
46

fiSCREEN: Flat Syntactic Semantic Spoken Language Analysis

module communication identically realized symbolic lists contain values
connectionist units.
2. previous hybrid symbolic connectionist architectures usually within
either symbolic connectionist module (Hendler, 1989; Faisal & Kwasny, 1990;
Medsker, 1994), screen global state described collection individual
symbolic connectionist modules. Processing parallel long one module
need input second module.
3. communication among symbolic connectionist modules organized via
messages. hybrid architectures often used either activation
values symbolic structures, used messages consisting lists symbols
associated activation plausibility values provide communication medium
supports connectionist processing well symbolic processing.
give overview various parts screen (see Figure 6).
important output consists syntactic semantic category representations based
input incrementally recognized parallel word hypotheses. speech recognizer
generates many incorrect word hypotheses time, even correctly recognized speech
contain many errors introduced humans. representation used since
fault-tolerant robust than, instance, context-free tree representation since
tree representation requires many decisions representation.
module system, instance disambiguation abstract syntactic categories, contains connectionist network symbolic program. integration symbolic
connectionist representations occurs encapsulation symbolic connectionist
processes module level. Connectionist networks embedded symbolic modules
communicate via messages.
However, essential parts needed purposes learning spokenlanguage analysis why? Starting output individual word hypotheses
speech recognizer, first need component receives incremental stream
individual parallel word hypotheses produces incremental stream word hypothesis sequences (see Figure 6). call part speech sequence construction part.
needed transforming parallel overlapping individual word hypotheses word hypothesis sequences. word hypothesis sequences different quality goal
find work best word hypothesis sequences. Therefore need speech
evaluation part combine speech-related plausibilities syntactic semantic
plausibilities order restrict attention best found word hypothesis sequences.
Furthermore, need part analyzes best found word hypothesis sequences
according syntactic semantic representation. category part receives
stream current word hypothesis sequences. Two word hypothesis sequences
shown Figure 6. part provides interpretation word hypothesis sequence
basic syntactic categories, abstract syntactic categories, basic semantic categories,
abstract semantic categories. is, word hypothesis sequence assigned four
graded preferences four word categories.
Human speech analyzed speech recognizer may contain many errors. question
arises extent want consider errors. analysis several hundred
47

fiWermter & Weber

two word hypotheses sequences:
1.

output analysis
2.

Kse

ich

meine

natrlich

(rubbish)

(I)

(mean)

(of course) (March)

N

NG

U

NG



NEG

ANIM

AGENT UTTER ACT

V

VG



SG

N

NG

NILL

MISC

TIME

TMAT

Kse

ich

htte

ich

(rubbish)

(I)

(had)

(I)

N

NG

U

NG



NEG

ANIM

AGENT

V

Mrz

Mrz
(March)

VG

U

ACT

ANIM [AGENT] TIME

[NG]

N

NG
TMAT

....
syntactic/semantic hypotheses

case frame part

dialog part
learned
flat
syntactic
semantic
analysis

correction part
speech evaluation part

category part
constructed word hypotheses sequences:
Kse ich meine natrlich Mrz
1. Rubbish mean course March

speech sequence construction part

Kse ich htte ich Mrz
March

2. Rubbish

....

word hypotheses
word hypotheses generated speech recognizer:
0.00
0.11
0.45
0.45
0.57
0.57
0.58
0.76
0.95
1.12
1.13
0.76
1.15
1.35
3.00

input speech recognizer
current word hypothesis

0.10
0.44
0.56
0.57
0.75
0.75
0.94
1.14
1.11
2.99
1.34
1.11
2.99
2.99
3.00

#PAUSE#
Kse
ich
ich
meine
meine
htte
etliche
ich
Mrz
da
natrlich
Mrz
aus
#PAUSE#

Figure 6: Overview screen
48

(rubbish)
(I)
(I)
(mean)
(mean)
(had)
(several)
(I)
(March)
(there)
(of course)
(March)
(out)

7.022857e02
2.269389e06
3.697864e03
2.017291e03
1.245984e05
1.016475e04
2.831144e08
3.045548e08
1.749518e04
9.596145e16
1.257770e04
1.017243e07
4.249394e15
2.624843e12
7.497616e01

fiSCREEN: Flat Syntactic Semantic Spoken Language Analysis

transcripts speech recognizer outputs revealed errors occur
often regularly. interjections, pauses, word repairs, phrase repairs.
Therefore designed correction part receives hypotheses words deals
frequently occurring errors spoken language explicitly.
parts outlined far build center integration speech-related
language-related knowledge fault-tolerant learning architecture, therefore
focus parts paper. However, want process complete dialog turns
contain several individual utterances need know certain utterance
starts constituents belong utterance. task performed case
frame part fills frame incrementally segments speaker's turn utterances.
long-term perspective screen provide analysis tasks spoken
utterance translation information extraction. Besides syntactic semantic analysis
utterance, intended dialog acts convey important additional knowledge. Therefore,
dialog part needed assigning dialog acts utterances, instance utterance
request suggestion. fact, already fully implemented case frame part
dialog part utterances. However, describe details two
parts paper since described elsewhere (Wermter & Lochel, 1996).
Learning screen based concepts supervised learning instance feedforward networks (Rumelhart et al., 1986), simple recurrent networks (Elman, 1990)
general recurrent plausibility networks (Wermter, 1995). general, recurrent plausibility networks allow arbitrary number context hidden layers considering long
distance dependencies. However, many network modules screen attempted
keep individual networks simple homogeneous. Therefore, first version
described used variations feedforward networks (Rumelhart et al., 1986)
simple recurrent networks (Elman, 1990). Due greater potential sequential
context representations, recurrent plausibility networks might provide improvements
optimizations simple recurrent networks. However, primarily interested
overall real-world hybrid connectionist architecture screen rather optimization single networks. following description give detailed examples
individual networks.

4.3 Detailed View

motivated various parts screen, give detailed description
architecture screen respect modules syntactic semantic
analysis word hypothesis sequences. Therefore, focus speech related parts,
categorization part correction part. Figure 7 shows detailed overview
parts. basic data ow shown arrows. Many modules generate hypotheses
used subsequent modules higher level. hypotheses illustrated
rising arrows. modules, output contains local predictive hypotheses (sometimes
called local top-down hypotheses) used modules lower level.
hypotheses illustrated falling arrows. Local predictive hypotheses used
correction part eliminate4 repaired utterance parts speech evaluation part
eliminate syntactically semantically implausible word hypothesis sequences.
4. means repaired utterance parts actually marked deleted.

49

fiWermter & Weber

SEGMENT-PARSER

DIA-ACT

frame

slots
dialog act
type
verb-form

...

case frame part 1

2

8

reject
utter
meinen
(mean)

4

3

dialog part
PHRASE-ERROR

2

2

3

3

BAS-SYN-EQ

BAS-SEM-EQ

2

2

2*13

2*20

correction part

LEX-START-EQ

LEX-WORD-EQ

8

5

WORD-ERROR


pause, interjection,
hesitation, unresolved
phonetic material?

INTERJECTION

1

...

PAUSE-ERROR

PAUSE

Dialog Lexicon

2

ABS-SYN-EQ
2

2

2*8

2*17

3

4

SEM-SPEECH-ERROR

2

PHRASE-START?

3

BAS-SYN-PRE

5
4

separates
SYN-SPEECH-ERROR

ABS-SEM-EQ

5

ABS-SYN-CAT

ABS-SEM-CAT

2

8

17

13

13

20

BAS-SEM-PRE

13

20

13

20

BAS-SYN-DIS

2

2

BAS-SEM-DIS

13

20

13

20

3

3
verb, pronoun
UTTER, NIL

speech evaluation part

Syntactic Lexicon
Semantic Lexicon

category part

1
CON-SEQU-HYPS
Kse ich meine

(rubbish mean)
constructed word hypotheses sequences:
Kse ich
Kse ich meine

(rubbish I)
(rubbish mean)

speech sequence construction part

Figure 7: detailed overview screen. abbreviations functionality
modules described text.
50

fiSCREEN: Flat Syntactic Semantic Spoken Language Analysis

cases arrows would complex used numbers illustrate
data ow individual modules.
4.3.1 Speech sequence construction part

speech sequence construction part receives stream parallel word hypotheses
generates stream word hypothesis sequences within module con-sequ-hyps
bottom Figure 7. Based current word hypotheses many word hypothesis sequences
may possible. cases reduce number current word hypotheses, e.g.,
know time passed far specific word hypothesis sequence cannot
extended anymore time current word hypothesis. case
eliminate sequence since word hypothesis sequences could reach end
sentence candidates successful speech interpretation.
Furthermore, use speech plausibility values individual word hypothesis
determine speech plausibility word hypothesis sequence. using
best word hypothesis sequences reduce large space possible sequences.
generated stream word hypothesis sequences similar set partial N-best
representations generated pruned incrementally speech analysis rather
end speech analysis process.
4.3.2 Speech evaluation part

speech evaluation part computes plausibilities based syntactic semantic knowledge order evaluate word hypothesis sequences. part contains modules
detection speech-related errors. Currently, performance speech recognizers
spontaneously spoken speaker-independent speech general still far perfect.
Typically, many word hypotheses generated certain signal5 . Therefore, many hypothesized words produced speech recognizer incorrect speech confidence
value word hypothesis alone provide enough evidence finding desired
string signal. Therefore goal speech evaluation part provide preference
filtering unlikely word hypothesis sequences. syn-speech-error sem-speecherror two modules decide current word hypothesis syntactically
(semantically) plausible extension current word hypothesis sequence. syntactic
(semantic) plausibility based basic syntactic (semantic) category disambiguation
prediction.
summary, word hypothesis sequence acoustic confidence based
speech recognizer, syntactic confidence based syn-speech-error, semantic
confidence based sem-speech-error. three values integrated weighted
equally6 determine best word hypothesis sequences. way, two modules
5. HMM-speech recognizer used generating word hypotheses domain word accuracy
93% best match word graph desired transcript utterance.
recognizer particularly optimized task domain order able examine
robustness language level. unoptimized version task domain currently 72%
word accuracy.
6. integration speech, syntax, semantics confidence values provided better results
using one two three knowledge sources.

51

fiWermter & Weber

act evaluator speech recognizer well filter language processing
part.
statistical models speech recognition, bigram trigram models used language models filtering best possible hypotheses. used simple recurrent
networks since networks performed slightly better bigram trigram model
implemented comparison (Sauerland, 1996). Later Section 6.1
also show detailed comparison simple recurrent networks n-gram models (for n
= 1,...,5). reason better performance internal representation simple
recurrent network restrict covered context fixed number two
three words potential learn required context needed.
output-layer
13 units
N

J

V



R

C

U







P



/

14*13 connections

context-layer

hidden-layer
14*14
conn.

input-layer

2*14 units

14 copy

13*14 connections

13 units
N

J

V



R

C

U







P



/

disambiguated representation "ich" ("I") BAS-SYN-DIS

Figure 8: Network architecture syntactic prediction speech evaluation part
(bas-syn-pre). abbreviations explained Table 1.
knowledge syntactic semantic plausibility provided prediction
networks (bas-syn-pre bas-sem-pre) speech evaluation part disambiguation networks (bas-syn-dis bas-sem-dis) categorization part. example, show network bas-syn-pre Figure 8. previous basic syntactic
category currently considered word hypothesis sequence input network.
example \ich" (\I") word hypothesis sequence \Kase ich meine" (\Rubbish
mean") found pronoun (U). Therefore, syntactic category representation
\ich" (\I") contains \1" pronoun (U) category. categories receive \0".
input network consists 13 units 13 categories. output
network size. unit vector represents plausibility
predicted basic syntax category last word current word hypothesis sequence.
plausibility unit representing desired basic syntactic category (found
bas-syn-dis) taken syntactic plausibility currently considered word hypothesis
sequence syn-speech-error. example \meine" (\mean") found verb
52

fiSCREEN: Flat Syntactic Semantic Spoken Language Analysis

(V). Therefore plausibility verb (V) taken syntax plausibility (selection
marked box output-layer bas-syn-pre Figure 8).
summary, syntactic (semantic) plausibility word hypothesis sequence evaluated degree agreement disambiguated syntactic (semantic) category
current word predicted syntactic (semantic) category previous word.
Since decisions current state whole sequence made, preceding
context represented copying hidden layer current word context layer
next word based SRN network structure (Elman, 1990). connections
network n:m connections except connections hidden layer
context layer simply used copy store internal preceding state
context layer later processing next word comes in. general, speech
evaluation part provides ranking current word hypothesis sequences equally
weighted combination acoustic, syntactic, semantic plausibility.
4.3.3 Category part

module bas-syn-dis performs basic syntactic disambiguation (see Figure 9). Input
module sequence potentially ambiguous syntactic word representations, one
word utterance time. module disambiguates syntactic category
representation according syntactic possibilities previous context. output
preference disambiguated syntactic category. syntactic disambiguation task
learned simple recurrent network. Input output network ambiguous
disambiguated syntactic category representations. Figure 9 show example
input representation \meine" (\mean", \my") verb pronoun.
However, sequence \Ich meine" (\I mean"), \meine" verb therefore
network receives disambiguated verb category representation alone.
module bas-sem-dis similar module bas-syn-dis instead receiving
potentially ambiguous syntactic category input producing disambiguated syntactic
category output, module bas-sem-dis receives semantic category representation
lexicon provides disambiguated semantic category representation output.
semantic disambiguation learned simple recurrent network provides mapping ambiguous semantic word representation disambiguated semantic word
representation. modules bas-syn-dis bas-sem-dis provide disambiguation
subsequent tasks like association abstract categories test category
equality word error detection possible.
module abs-syn-cat supplies mapping disambiguated basic syntactic
category representations abstract syntactic category representations (see Figure 10).
module provides abstract syntactic categorization realized simple
recurrent network. module important providing abstract interpretation
utterance preparing input detection phrase errors. Figure 10 shows
disambiguated basic syntactic representation \meine" (\mean") verb -
small preference pronoun - mapped verb group category higher
abstract syntactic category representation. Based number basic abstract
syntactic categories 13 input units basic syntactic categories 8 output
units abstract syntactic categories.
53

fiWermter & Weber

output-layer
13 units
N

J

V



R

C

U







P



/

14*13 connections

hidden-layer

context-layer
14*14
conn.

input-layer

2*14 units

14 copy

13*14 connections

13 units
N

J

V



R

C

U





P



/

ambiguous representation
"meine" (verb/pronoun)

syntactic lexicon
meine

Kse
(rubbish)



verb
pronoun

ich meine
(I) (mean)

current word hypotheses sequence

Figure 9: Network architecture basic syntactic disambiguation (bas-syn-dis).
abbreviations explained Table 1.
module abs-sem-cat parallel module abs-syn-cat uses basic semantic
category representations input abstract semantic category representations output.
Similar previous modules, also used simple recurrent network learn
mapping represent sequential context. input network basic
semantic category representation word, output abstract category
preference.
described four networks provide basis fault-tolerant analysis
detection errors. Furthermore, module phrase-start distinguishing
abstract categories. task module indicate boundaries subsequent
abstract categories delimiter. use boundaries determine abstract
syntactic abstract semantic category phrase7 . Earlier experiments provided
support take abstract syntactic category first word phrase final
abstract syntactic category phrase, since phrase starts (e.g., prepositions) good
7. Figure 7 show uence phrase start delimiter abstract syntactic semantic
categorization dotted lines.

54

fiSCREEN: Flat Syntactic Semantic Spoken Language Analysis

output-layer
8 units
NG

VG

PG

CG

AG MG

SG

IG

14*13 connections

hidden-layer

context-layer
14*14
conn.

input-layer

13*14 connections

2*14 units

14 copy

13 units
N
J
V

R
C
U

disambiguated representation "meine" (mean)





P



/

Figure 10: Network architecture abstract syntactic categorization (abs-syn-cat).
abbreviations explained Table 2.
indicators abstract syntactic categories (Wermter & Lochel, 1994). hand,
earlier experiments supported take abstract semantic category last word
phrase final abstract semantic category phrase, since phrase ends (e.g., nouns)
good indicators abstract semantic categories (Wermter & Peters, 1994). Furthermore, phrase start gives us opportunity distinguish two equal subsequent abstract
categories two phrases. instance, phrase like \in Hamburg Monday"
know border exists first second prepositional
phrase.
4.3.4 Correction part

correction part contains modules detecting pauses, interjections, well repetitions repairs words phrases (see Figure 7). modules detecting pause
errors pause-error, pause interjection. modules pause interjection receive currently processed word detect potential occurrence pause
interjection, respectively. output modules input module pauseerror. soon pause interjection detected, word marked deleted
therefore virtually eliminated input stream8. elimination interjections
pauses desired - instance speech translation task - order provide inter8. Pauses interjections sometimes provide clues repairs (Nakatani & Hirschberg, 1993) although
currently use clues repair detection. Compared lexical, syntactic, semantic
equality constituents, interjections pauses provide relatively weak indicators repairs since
also occur relatively often places sentence. However, since mark interjections
pauses deleted could make use knowledge future necessary.

55

fiWermter & Weber

pretation errors possible. Since three modules basically occurrence
tests realized symbolic representations.
second main cluster modules correction part modules
responsible detection word-related errors. Then, word repairs \Am sechsten
April bin ich ich" (\on sixth April I") \Wir haben ein Termin Treffen" (\We
date meeting") dealt with. certain preferences finding repetitions
repairs word level. Among preferences lexical equality two
subsequent words (symbolic module lex-word-eq), equality two basic syntactic
category representations (connectionist module bas-syn-eq), equality basic
semantic categories two words (connectionist module bas-sem-eq). example
three modules, show test syntactic equality (BAS-SYN-EQ) Figure 11.
output-layer
2 units
equal equal
5*2 connections

hidden-layer
5 units
input-layer

(2*13)*5 connections

N J V R C U P /

N J V R C U P /

2*13
units

disambiguated representation second "ich" (I)

disambiguated repr. first "ich" (I)

output-layer
2 units
equal equal
5*2 connections

hidden-layer
5 units
input-layer

(2*13)*5 connections

N J V R C U P /
disambiguated repr. "Termin" (date)

N J V R C U P /

2*13
units

disambiguated representation "Treffen" (meeting)

Figure 11: Network architecture equality basic syntactic category representation (bas-syn-eq). abbreviations explained Table 1.
56

fiSCREEN: Flat Syntactic Semantic Spoken Language Analysis

Two output units plausible/implausible outcome used since network two output units gave consistently better results compared network
one output unit (with 1 plausible 0 implausible). reason network two output units performed better separation weights plausible
implausible hidden-output layer. order receive single value, two output values integrated according formula: unit1 (1:0 , unit2 ). Then, output
three equality modules value 0 1 1 represents equality 0
represents inequality. Although single preference may sucient, common
uence provides reasonable basis detecting word repairs word repetitions
module word-error. Then, word repairs repetitions eliminated original
utterance. Since modules word-related errors based two representations two
subsequent input words since context play minor role, use feedforward
networks modules. hand, simple test lexical equality
two words lex-word-eq represented effectively using symbolic representation.
third main cluster correction part consists modules detection
correction phrase errors. example phrase error is: \Wir brauchen
den fruheren Termin den spateren Termin" (\We need earlier date later date").
preferences phrase errors lexical start two subsequent phrases
equal, abstract syntactic categories equal abstract semantic categories
equal. three preferences modules lex-start-eq, abs-syn-eq
abs-sem-eq. modules receive two input representations two corresponding
words two phrases, lex-start-eq receives two lexical words, abs-syn-eq two abstract
syntactic category representations, abs-sem-eq two abstract semantic category representations. output three modules value toward 1 equality toward
0 otherwise. values input module phrase-error finally decides
whether phrase replaced another phrase. lexical equality two words
discrete test, implemented lex-start-eq symbolically, preferences
phrase error implemented feedforward networks.

5. Detailed Analysis Examples

section detailed look processing output speech recognizer
producing syntactic semantic interpretation concurrent word hypothesis
sequences (also called sentence hypothesis here).

5.1 Overall Environment

overall processing incremental left right, time multiple sentence
hypotheses processed parallel. Figure 12 shows snapshot screen 0.95s
utterance. time snapshot shows first three sentence hypotheses
German words together (literal) English translations (\Rubbish mean", \Rubbish I", \Rubbish had"). screen environment allows user view inspect
incremental generation word hypothesis sequences (partial sentence hypotheses)
preferred syntactic semantic categories basic abstract level.
sentence hypothesis illustrated horizontally. certain time many sentence hypotheses
active parallel. ranked according descending plausibility
57

fiWermter & Weber

SCREEN - Symbolic Connectionist Robust EnterprisE Natural language
Quit

line

Stop

Go

single step

1

3 Sentencehypotheses. Time: 0.95s (System)/0.95s (Display)

N



NG

SUG

NEG CONF

Kse (rubbish)

N



0

NG

SUG

NEG CONF

Kse (rubbish)

N



NG

SUG

NEG CONF

Kse (rubbish)

U

NG

SUG

ANIM AGENT CONF

ich (I)

V

NIL

SUG

UTTER NIL

CONF

meine (mean)

U

NIL

SUG

ANIM

NIL

CONF

NG

SUG

ich (I)

U

ANIM AGENT CONF

ich (I)

V

NIL

SUG



NIL

CONF

htte (had)

0

0.0000 0.0000 0.9799 0.0000 0.0038 0.0004 0.1653 0.0048 0.0001 0.0003 0.0001 0.0017 0.0001
N
J
V

R
C
U



P

/

Figure 12: First snapshot sentence \Kase ich meine naturlich Marz (\Rubbish mean
course March"). abbreviations explained Table 1 4. Below,
second pop-up window illustrates full preferences word \meine"
(\mean") basic syntactic categories.
sentence hypotheses. snapshot Figure 12 currently three sentence
hypotheses preferred current sentence hypothesis consists \Rubbish mean".
sentence hypotheses syntactically semantically plausible starts.
underlying variations introduced speech recognizer produced different word
hypotheses slightly overlapping signal parts sentence. Besides speech plausibility, syntax also semantics help choosing better sentence hypotheses. Currently
combine speech recognition plausibility, syntactic plausibility, semantic
plausibility compute plausibility sentence hypotheses multiplication
respective normalized plausibility values 0 1. Since speech recognizer
contain syntactic semantic knowledge, sequence hypothesis rated plausible based
speech knowledge alone may neglect potential syntactic semantic regularity.
58

fiSCREEN: Flat Syntactic Semantic Spoken Language Analysis

using corresponding syntactic semantic plausibility values sentence hypothesis
integrate acoustic, syntactic, semantic knowledge.
word hypothesis shown preferred basic syntactic hypothesis (upper left
square word hypothesis), preferred abstract syntactic hypothesis (upper middle
square), preferred basic semantic hypothesis (lower left square), preferred abstract
semantic hypothesis (lower middle square), preferred dialog act (upper right square)9,
integrated acoustic, syntactic semantic confidence partial sentence hypothesis point (lower right square). size square illustrates strength
hypothesis, full black square means preferred hypothesis close one.
instance, word hypothesis \ich" (\I") first sentence hypothesis
hypothesis pronoun (U) basic syntactic category, noun group (NG)
abstract syntactic category, animate object (ANIM) basic semantic category,
AGENT abstract semantic category, suggestion (SUG) dialog act. Furthermore, length vertical bar word hypotheses indicate plausibility
new phrase start.
another example, see representation example word \meine" (could
verb \mean" pronoun \my" German) used throughout
network descriptions (see Figure 9). network correct preference \meine"
verb (V). Figure 12 shows preference well zoomed illustration
less favored preferences second pop-up window below. see, ambiguous pronoun preference U received second strongest activation
preferences close 0. shown activation preferences output values
corresponding network basic syntactic categorization. shown activation value
snapshots shows preferred hypothesis hypotheses
shown request10.
Within display scroll descending ascending sentence
hypotheses. Furthermore scroll left right analyzing specific longer word
hypothesis sequences. also step mode allows screen system wait
interactive mouse click process next incoming word hypothesis
detailed analysis. step mode adapted different number steps (word
hypotheses) switched completely one decides analyze sentence
hypotheses later end word hypotheses. preferred possible
syntactic semantic hypotheses shown. Therefore many different hypotheses appear
size. However, clicking one squares less confident
hypotheses displayed well.
9. dialog acts use are: accept (ACC), query (QUERY), reject (REJ), request-suggest (RE-S),
request-state (RE-S), state (STATE), suggest (SUG), miscellaneous (MISC). Since paper focuses
syntactic semantic aspects screen elaborate implemented dialog
part here. details dialog act processing described previously (Wermter & Lochel,
1996).
10. snapshots Figure 12 abstract syntactic semantic categories yet computed
therefore represented NIL. next processing step computation performed
seen next Figure 13.

59

fiWermter & Weber

5.2 Analyzing Final Snapshot Short Sentence Hypotheses

Figure 13 illustrate final state 3.01s utterance. Eight possible sentence hypotheses remained see first four Figure 13. Starting
fourth sentence hypothesis \Kase ich hatte ich Marz" (\Rubbish march")
see lower rated sentence hypothesis desired sentence. lower ranked
hypotheses good examples current state-of-the-art speech recognizers alone
able produce reliable sentence hypotheses, since problem analyzing spontaneous
speaker-independent speech complex. Therefore syntactic semantic components spontaneous language take account highly irregular
sequences shown below. However, interesting observe underlying connectionist networks always produce preference syntactic semantic interpretation
abstract basic level. fact, although lower ranked sentence hypotheses
constitute desired sentence assigned syntactic semantic categories
correct individual word hypotheses. course may cases network
also could make wrong decision uncertain word hypotheses. However syntactic
semantic processing never break possible sentence hypothesis,
respect different well-known methods like symbolic context-free chart parsers.
look top-ranked sentence hypothesis \Kase ich meine naturlich Marz" (\Rubbish mean course March") also desired sentence. plausible
SCREEN - Symbolic Connectionist Robust EnterprisE Natural language
Quit

Go

line

Stop

single step

1

8 Sentencehypotheses. Time: 3.01s (System)/3.01s (Display)

N

NG DSUG



NEG CONF

KSE

0

NG DSUG

ANIM AGENT CONF

ICH

N

NG DSUG



NEG CONF

KSE

U

NG DSUG

NG DSUG

ANIM AGENT CONF



NEG CONF

KSE

U

NG DSUG

NG DSUG

ANIM AGENT CONF



NEG CONF

U

UTTER ACT

CONF

V

VG DSUG

UTTER ACT

V



NG DSUG

V



HTTE



SG DSUG

NILL

MISC CONF

NATRLICH

CONF



SG DSUG

NILL

MISC CONF

NATRLICH

VG DSUG

ACT

CONF

HTTE

ANIM AGENT CONF

ICH

VG DSUG

MEINE

ICH

N

V

MEINE

ICH

N

KSE

U

U

NG DSUG

ANIM AGENT CONF

ICH

VG DSUG

ACT

CONF

U

N

NG DSUG

TIME TMAT CONF

MRZ

N

NG DSUG

TIME TMAT CONF

MRZ

N

NG DSUG

TIME TMAT CONF

MRZ

NG DSUG

ANIM AGENT CONF

ICH

N

NG DSUG

TIME TMAT CONF

MRZ
0

Figure 13: Final snapshot sentence \Kase ich meine naturlich Marz (\Rubbish mean
course March").
60

fiSCREEN: Flat Syntactic Semantic Spoken Language Analysis

sentence based speech language plausibility. Furthermore, see assigned categories correct: German word \Kase" (\Rubbish") found noun
part noun group expresses negation. \Ich" (\I") starts new phrase,
pronoun noun group represents animate agent. following
German word \meine" particularly interesting since used verb sense
\mean" also pronoun sense \my". Therefore, connectionist network
basic syntactic classification disambiguate two possibilities based
preceding context. network learned take consideration preceding
context able choose correct basic syntactic category verb (V) rather
pronoun (U) word \meine" (\mean"). time new phrase start
found well. following word \naturlich" (\of course") highest preference
adverb special group. Finally, word \Marz" (\March") assigned highest
plausibility noun noun group well time something happens.

5.3 Phrase Starts Phrase Groups Longer Sentence Hypotheses

focus detailed analysis second example: \A hm ja genau allerdings
habe ich da von neun bis vier Uhr schon einen Arzttermin". literally translated
SCREEN - Symbolic Connectionist Robust EnterprisE Natural language
Quit

Go

line

Stop

single step

1

10 Sentencehypotheses. Time: 2.18s (System)/2.18s (Display)



YES

MG DACC

CONF CONF

JA

YES

MG DACC

CONF CONF

JA

DREJ

CONF CONF

J

YES

YES

MG DACC

CONF CONF

JA



NILL

MG

DREJ

CONF CONF

YES

MG DACC

CONF CONF



NILL



SG

DREJ

NEG CONF





SG

DREJ

NEG CONF

ALLERDINGS

MG DMISC

MISC CONF

DENNOCH





ALLERDINGS

GENAU



JA

YES

MG

GENAU



0

J

MG DMISC

MISC CONF

DENNOCH





SG DMISC

NEG CONF

ALLERDINGS





SG DMISC

NEG CONF

ALLERDINGS

V

VG

DREJ



ACT

CONF

HABE

VG

DREJ



ACT

CONF

HABE

U

NILL

ACT

CONF



NG

DREJ

MISC CONF

ACT

CONF

ANIM AGENT CONF

U

NILL

ES

DREJ

MISC CONF

NILL

SG

DREJ

MISC CONF

NILL

SG DMISC

MISC CONF

DA

MISC CONF

DREJ

TMAT CONF

R

PG

DREJ

TMAT CONF

R



NIL DMISC

NIL

CONF

VON



NILL

DA

PG

VON



NG DMISC

R

VON



NG DMISC

ICH

HABE

NILL

SG

DA

U

VG DMISC



DA

ES

HABE

V

DREJ

ANIM AGENT CONF

VG DMISC



NG

ICH

V

V

U

SG DMISC

MISC CONF

R



NIL DACC

NIL

CONF

VON

0

Figure 14: First part snapshot sentence \A hm ja genau allerdings habe ich
da von neun bis vier Uhr schon einen Arzttermin" (literal translation: \Yes
exactly however nine four o'clock already doctorappointment"; improved translation: \Eh yes exactly however
doctor appointment nine four o'clock").
61

fiWermter & Weber

SCREEN - Symbolic Connectionist Robust EnterprisE Natural language
Quit

line

Stop

Go

single step

1

10 Sentencehypotheses. Time: 4.45s (System)/4.45s (Display)



PG

MISC

TIME TMAT CONF

neun (nine)



PG

MISC

neun (nine)



PG

MISC

TIME TMAT CONF

PG

MISC CONF

R

NIL

R

NIL

ACC

R

NIL

bis (to)



PG

MISC

TIME TMAT CONF

vier (four)

PG

MISC

MISC CONF



PG

PG

MISC

MISC

TIME TMAT CONF

MISC CONF



PG

MISC

MISC

TIME TMAT CONF

MISC CONF



PG

MISC

TIME TMAT CONF

N

PG

MISC

TIME TMAT CONF

N

PG

MISC

TIME TMAT CONF

Uhr (oclock)

MISC

TIME TMAT CONF

zehn (ten)

PG

Uhr (oclock)

zehn (ten)

PG

N

Uhr (oclock)

vier (four)

bis (to)

TIME TMAT CONF

neun (nine)

MISC

bis (to)

neun (nine)



NIL

PG

bis (to)

TIME TMAT CONF

0

R

N

PG

ACC

TIME TMAT CONF

Uhr (oclock)



NIL

SG

MISC

MISC CONF

schon (already)



NIL

SG

MISC

MISC CONF

schon (already)



NIL

SG

MISC

MISC CONF

schon (already)



NIL

SG

ACC

MISC CONF

schon (already)



NIL

NG

RES

MISC CONF

einen (a)



NIL

NG

RES

MISC CONF

NIL

NG

RES

MISC CONF

NIL

NG

ABS

OBJ

CONF

N

NG

RES

ABS

OBJ

CONF

N

NG

RES

ABS

OBJ

CONF

Arzttermin(doc.app

RES

MISC CONF

einen (a)

RES

Arzttermin(doc.app

einen (a)



NG

Arzttermin(doc.app

einen (a)



N

N

NG

RES

ABS

OBJ

CONF

Arzttermin(doc.app

7

Figure 15: Second part snapshot sentence \A hm ja genau allerdings habe ich
da von neun bis vier Uhr schon einen Arzttermin" (\Yes exactly however
nine four o'clock already doctor-appointment").
sentence analyzed is: \Eh yes exactly however nine four o'clock
already doctor-appointment". better non-literal translation would be: \Eh yes
exactly however doctor appointment nine four o'clock".
analysis first sentence hypotheses, interjection \ahm" (\eh") detected
corresponding module correction part eliminated respective
sentence hypotheses.
Figure 14 Figure 15 show best found four sentence hypotheses.
categories sentence hypotheses look similar keep separate
hypotheses since differ time stamps speech confidence values.
two snapshots longer example also illustrate uence
phrase starts. sequences \von neun" (\from nine") \bis vier Uhr" (\to four
o'clock") constitute two phrase groups clearly separated black bar
prepositions \von" (\from") \bis" (\to"). words \neun" (\nine"),
\vier" (\four"), \Uhr" (\o'clock") start another phrase group. Since underlying connectionist network learning phrase boundaries simple recurrent network
example demonstrates network learned preceding context. Without
learned preposition \von" (\from") \bis" (\to") noun
62

fiSCREEN: Flat Syntactic Semantic Spoken Language Analysis

like \Uhr" (\o'clock") within prepositional phrase group could
also part noun phrase another context like \vier Uhr pat gut" (\four o'clock fits
well").

5.4 Dealing Noise Repairs
Finally focus example simple word graph shown beginning
paper page 41: \A hm sechsten April bin ich leider auer Hause". literal
translation \Eh 6th April unfortunately home". Using sentence
give example interjection simple word repair. Dealing hesitations
repairs large area spontaneous language processing main topic
paper (a detailed discussion repairs screen found previous work,
Weber & Wermter, 1996). Nevertheless, sake illustration completeness
show ability screen deal interjections word repairs. first snapshot
Figure 16 shows start example sentence 1.39s. leading interjection
\eh" eliminated already.
Furthermore, see second word hypothesis sequence shows two subsequent
word hypotheses \ich" (\I"). possible since two word hypotheses
SCREEN - Symbolic Connectionist Robust EnterprisE Natural language
Quit

Go

line

Stop

single step

1

18 Sentencehypotheses. Time: 1.39s (System)/1.39s (Display)

R

PG

SUG

TMAT CONF

(on)

R

PG

SUG

(on)

R

PG

SUG

TMAT CONF

TIME TMAT CONF



PG

SUG

TIME TMAT CONF



PG

SUG

TIME TMAT CONF

sechsten (6th)

PG

SUG

TMAT CONF

(on)

SUG

sechsten (6th)

(on)

R

PG

sechsten (6th)

TMAT CONF

0





PG

SUG

TIME TMAT CONF

sechsten (6th)

N

PG

SUG

TIME TMAT CONF

April (April)

N

PG

SUG

TIME TMAT CONF

PG

SUG

TIME TMAT CONF

PG



ACT

CONF

V

VG

SUG



ACT

CONF

U

PG

SUG

U

NG

STATE

ANIM AGENT CONF

ich (I)

U

NIL

STATE

ANIM

NIL

CONF

U

NIL

STATE

ANIM

NIL

CONF

ich (I)

U

NIL

SUG

ANIM

NIL

CONF

U

NIL

SUG

ANIM

NIL

CONF

NG

STATE

ich (I)

SUG

ANIM RECIP CONF

ich (I)

TIME TMAT CONF

April (April)

STATE

htte (had)

April (April)

N

VG

bin (am)

April (April)

N

V

ich (I)

V

VG

STATE



ACT

CONF

bin (am)

U

ANIM AGENT CONF

ich (I)

ich (I)

0

Figure 16: First snapshot sentence \A hm sechsten April bin ich leider auer
Hause" (\Eh 6th April unfortunately home").
63

fiWermter & Weber

generated speech recognizer could connected. case
four word hypotheses shown below:
start time
1.22s
1.23s
1.23s
1.31s

end time
1.37s
1.30s
1.37s
1.38s

word hypothesis
ich (I)
ich (I)
ich (I)
ich (I)

speech plausibility
1.527688e-03
1.178415e-02
2.463924e-03
1.813340e-02

using speech knowledge word hypotheses, possible connect
second hypothesis runs 1.23s 1.30s fourth hypothesis runs
1.31s 1.38s. example noise generated speech recognizer, since
desired sentence contains one word \ich" (\I") sentence hypothesis
point contains two. repetition treated eliminated way actual
word repairs language. reasons occurrence repairs different
effect repeated word same. Therefore, case repeated \ich" (\I")
eliminated sentence sequence. Figure 17 show final snapshot
sentence. see word repairs occur top-ranked sentence hypothesis
also desired sentence.
SCREEN - Symbolic Connectionist Robust EnterprisE Natural language
Quit

line

Stop

Go

single step

1

10 Sentencehypotheses. Time: 3.40s (System)/3.40s (Display)



PG

SUG

TIME TMAT CONF

sechsten (6th)



PG

SUG

TIME TMAT CONF

0

sechsten (6th)



PG

SUG

TIME TMAT CONF

sechsten (6th)



PG

SUG

TIME TMAT CONF

sechsten (6th)

N

PG

SUG

TIME TMAT CONF

April (April)

N

PG

SUG

TIME TMAT CONF

PG

SUG

TIME TMAT CONF

PG



ACT

CONF

U

PG

SUG

U

NG

STATE

ANIM AGENT CONF

ich (I)

SUG

ANIM RECIP CONF

U

V

VG

STATE

NG

SUG

ANIM RECIP CONF



ACT

CONF

VG

STATE

NG

STATE

ANIM AGENT CONF



ACT

CONF

U



SG

REJ

NEG CONF





SG

REJ

NEG CONF

leider (unfort.)

ich (I)

V

bin (am)

U



leider (unfort.)

ich (I)

bin (am)

TIME TMAT CONF

April (April)

STATE

ich (I)

April (April)

N

VG

bin (am)

April (April)

N

V





SG

REJ

NEG CONF

leider (unfort.)

NG

STATE

ANIM AGENT CONF

ich (I)





SG

REJ

NEG CONF

leider (unfort.)

R

PG

REJ

LCAT CONF

auer (out of)

R

PG

REJ

LCAT CONF

auer (out of)

R

PG

REJ

LCAT CONF

auer (out of)

R

PG

REJ

LCAT CONF

auer (out of)

N

PG

REJ

PHYS LCAT CONF

Hause (home)

N

PG

REJ

PHYS LCAT CONF

Hause (home)

N

PG

REJ

PHYS LCAT CONF

Hause (home)

N

PG

REJ

PHYS LCAT CONF

Hause (home)

1

Figure 17: Final snapshot sentence \A hm sechsten April bin ich leider auer
Hause" (\Eh 6th April unfortunately home").
64

fiSCREEN: Flat Syntactic Semantic Spoken Language Analysis

general, language repairs, screen deal elimination interjections
pauses, repair word repetitions, word corrections (where words may
different, categories same) well simple forms phrase repairs (where
phrase repeated replaced another phrase).

6. Design Analysis SCREEN
section describe design choices screen. particular focus
issues use connectionist networks, reach high accuracy little training,
screen compared systems design principles.

6.1 Use Connectionist Networks SCREEN?
past, n-gram based techniques used successfully tasks like syntactic
category prediction part speech tagging. Therefore, possible ask developed simple recurrent networks screen. subsection provide detailed
comparison simple recurrent networks n-gram techniques prediction basic
syntactic categories. chose task detailed comparison since currently
dicult task simple recurrent network screen. purposefully
choose subtask simple recurrent network high accuracy,
prediction task since dicult predict category compared disambiguating among categories, instance. chose dicult prediction relatively
low network performance order (extremely) fair comparison n-gram
techniques.
primarily interested generalization behavior new unknown input.
Therefore Figure 18 shows accuracy syntactic prediction unknown test
set. word several different syntactic categories follow syntactic
categories excluded. instance, determiner \the" adjective noun
follow: \the short ...", \the appointment", determiner \the" preposition
implausible occur probably excluded. Therefore important
know many categories ruled Figure 18 shows relationship
prediction accuracy number excluded categories n-grams simple
recurrent network (as described Figure 8).
expect, techniques, n-grams recurrent networks, prediction
accuracy higher categories excluded performance lower
many categories excluded. However, interestingly, see simple
recurrent networks performed better 1-grams, 2-grams, 3-grams, 4-grams 5-grams.
Furthermore, interesting note higher n-grams necessarily lead better
performance. instance, 4-grams 5-grams perform worse 2-grams since
would probably need much larger training sets.
comparison n-grams (1-5) simple recurrent networks also
semantic prediction received result simple recurrent networks performed
better n-grams. performance best n-gram often slightly worse
performance simple recurrent network, indicates n-grams
reasonably useful technique. However, comparisons simple recurrent networks per65

fiWermter & Weber

Testset
100

correct prediction %

80

60

40

SRN
1gram
2gram
3gram
4gram
5gram

20

0
0

2

4

6

8

10

12

number excluded categories

Figure 18: Comparison simple recurrent network n-grams
formed least slightly better best n-grams. Therefore, used simple recurrent
networks primary technique connectionist sequence learning screen.
explain result? N-grams like 2-grams still perform reasonably well
task simple recurrent networks closest performance. However,
simple recurrent networks perform slightly better since contain fixed
limited context. many sequences, simple recurrent network may primarily use
directly preceding word representation make prediction. However, exceptions
context required recurrent network memory internal reduced
representation preceding context. Therefore, potential exible
respect context size.
N-grams may perform optimally extremely fast. question arises
much time necessary compute new category using new input current
context network. general networks differ slightly size typically
contain several hundred weights. typical representative simple recurrent network
13 input units, 14 hidden units, 8 output units, 14 context units, 500 weights
takes 10,4 Sparc Ultra compute new category within whole forward sweep.
66

fiSCREEN: Flat Syntactic Semantic Spoken Language Analysis

Since techniques smoothed n-grams basically rely ecient table-look-up
precomputed values, course typical n-gram techniques still faster. However, due
fixed-size context may perform well simple recurrent networks. Furthermore, computing next possible categories 10,4s fast enough current version
screen. sake explanation one could argue screen contains 10
networks modules typical utterance contains 10 words, single utterance hypothesis could performed 10,2 s. However, different text tagging, single
sentences process word graphs. Depending specific utterance, 105 word
hypothesis sequences could generated processed. Furthermore
book-keeping required keeping best word hypotheses, loading appropriate networks appropriate word hypotheses, etc. potentially large number
word hypotheses, additional book-keeping performance, number individual
modules syntax, semantics dialog processing explain total analysis time
whole unoptimized screen system order seconds although single recurrent
network performs order 10,4 s.

6.2 Improvement Hypothesis Space
subsection analyze extent syntactic semantic prediction
knowledge used improve best found sentence hypotheses. illustrate
pruning performance hypothesis space integrating acoustic, syntactic, semantic knowledge. speech recognizer alone provides acoustic confidence
values, screen adds syntactic semantic knowledge. knowledge sources
weighted equally order compute single plausibility value current word hypothesis sequence. plausibility value used speech construction part prune
hypothesis space select currently best word hypothesis sequences. Several
word hypothesis sequences processed incremental parallel. given time
11
n best incremental word hypothesis sequences kept .
syntactic semantic plausibility values based basic syntactic semantic prediction (bas-syn-pre bas-sem-pre) next possible categories
word selection preference determined basic syntactic respectively semantic category (bas-syn-dis bas-sem-dis)12 . performance disambiguation
modules 86%-89% test set. prediction modules performance 72%
81% semantic syntactic test set, respectively want exclude least
8 12 possible categories. performance allows us computation syntactic
semantic plausibility syn-speech-error sem-speech-error. Based
combined acoustic, syntactic, semantic knowledge, first tests 184 turns show
accuracy constructed sentence hypotheses screen could increased
30% using acoustic syntactic plausibilities 50% using acoustic,
syntactic, semantic plausibilities (Wermter & Weber, 1996a).
11. experiments low values (n = 10) provided best overall performance.
12. explained detail Section 4.3.2

67

fiWermter & Weber

6.3 SCREEN's Network Performance Networks Yield High
Accuracy Little Training

evaluating performance screen's categorization part meeting corpus
first show percentages correctly classified words important networks
categorization: bas-syn-dis, bas-sem-dis, abs-syn-cat, abs-sem-cat, phrase-start.
184 turns corpus 314 utterances 2355 words. 1/3 2355
words 184 turns used training, 2/3 testing. Usually data used
training testing. preliminary earlier experiments used 2/3 training
1/3 testing. However, performance unknown test set similar 1/3
training set 2/3 test set. Therefore, used testing training data since
interested generalization performance unknown instances test
set compared training performance known instances.
first sight, might seem relatively little data training. statistical techniques
information retrieval techniques often work large texts individual lexical word
items, need much less material get reasonable performance since work
syntactic semantic representations rather words. would like stress
use syntactic semantic category representations 2355 words training
testing rather lexical words themselves. Therefore, category representation
requires much less training data lexical word representation would required.
side effect, also training time reduced 1/3 training set, keeping
performance 2/3 test set. is, training used category representations
64 dialog turns, testing generalization category representations remaining
120 dialog turns.
Table 5 shows test results individual networks unknown test set.
networks trained 3000 epochs learning rate 0.001 14 hidden units.
configuration provided best performance network architectures.
general tested network architectures 7 28 hidden units, learning parameters
0.1 0.0001. learning rule used generalized delta rule (Rumelhart et al.,
1986). assigned output category representation word counted correct
category maximum activation desired category.
Module

Accuracy test set
bas-syn-dis
89%
bas-sem-dis
86%
abs-syn-cat
84%
abs-sem-cat
83%
phrase-start
90%
word-error
94%
phrase-error
98%

Table 5: Performance individual networks test set meeting corpus
performance basic syntactic disambiguation 89% unknown test
set. Current syntactic (text-)taggers reach 95% accuracy texts. However,
68

fiSCREEN: Flat Syntactic Semantic Spoken Language Analysis

big difference text speech parsing due spontaneous noise
spoken language. interjections, pauses, repetitions, repairs, new starts
\ungrammatical" syntactic varieties spoken-language domain reasons
typical accuracy syntactic text taggers reached.
hand see 86% accuracy basic semantic disambiguation
relatively high semantics. evidence noisy \ungrammatical"
variety spoken language hurts syntax less semantics. Due domain dependence
semantic classifications dicult compare explain semantic performance.
However, different study within domain railway interactions could reach
similar performance (for details see Section 6.6). experiments syntactic results
better semantic results, indicating syntactic classification easier
learn generalize. Furthermore, syntactic results close 90% noisy
spoken language consider good comparison 95% regular
text language.
performance abstract categories somewhat lower basic categories since evaluation word introduces unavoidable errors. instance,
\in" network cannot yet know time location follow, make
early decision already. general, networks perform relatively well dicult
real-world corpus, given eliminate sentence reason took
spontaneous sentences spoken.
Furthermore, use transcripts spontaneous language training domain
meeting arrangements. utterances questions answers dates
locations. restricts potential syntactic semantic constructions, certainly
benefit restricted domain. Furthermore, mappings ambiguous
learning (e.g., noun part noun group prepositional group) mappings
relatively unambiguous (e.g., verb part verb group). would expect
performance mixed arbitrary domains like random spoken sentences
various topics passers-by city. However, performance somewhat
restricted domains learned promising manner (for transfer different
domain see Section 6.6). evidence simple recurrent networks
provide good performance using small training data restricted domain.

6.4 SCREEN's Overall Output Performance
described individual network performance, focus
performance running system. performance running screen system
different performance individual networks number reasons. First,
individual networks trained separately order support modular architecture.
running screen system, however, connectionist networks receive input
underlying networks. Therefore, actual input connectionist network
running screen system may also differ original training test sets. Second,
spoken sentences may contain errors like interjections word repairs. part
individual network training, running screen system able detect
correct certain interjections, word corrections phrase corrections. Therefore, system
network performance differ dis uencies. Third, want evaluate
69

fiWermter & Weber

performance abstract semantic categorization abstract syntactic categorization
particularly interested certain sentence parts. abstract syntactic categorization,
e.g., detection prepositional phrase, consider beginning
phrase significant function word, e.g., preposition, important
location syntactic categorization. contrast, abstract semantic categorization,
content word end phrase group, directly next phrase start,
important.
Correct syntactic output representation 74%
Correct semantic output representation 72%

Table 6: Overall syntactic semantic accuracy running screen system
unknown test set meeting corpus
expect based explanation previous paragraph, overall accuracy output complete running system lower performance
individual modules. fact, true Table 6 shows overall syntactic
semantic phrase accuracy running screen system. 74% assigned syntactic
phrase representations unknown test set correct 72% assigned semantic
phrase representations. slight performance drop partially explained
uncertain input underlying networks uenced
networks. hand, cases various decisions different modules (e.g.
three modules lexical, syntactic semantic category equality two words)
combined order clean errors (e.g. wrong decision one single module).
general, given 120 dialog turns test set completely unrestricted, unknown real-world spontaneous language turns, believe overall performance
quite promising.

6.5 SCREEN's Overall Performance Incomplete Lexicon

One important property screen robustness. Therefore, interesting question
screen would behave could receive incomplete input lexicon.
situations realistic since speakers could use new words speech recognizer
seen before. Furthermore, test robustness techniques. standard
context-free parsers usually cannot provide analysis words missing lexicon,
screen would break missing input representations, although course
expect overall classification performance must drop less reliable input provided.
order test situation controlled uence removing items
lexicon, first tested scenario randomly eliminated 5% syntactic
semantic lexicon representations. word unknown, screen used single syntactic
single semantic average default vector instead. average default vector contained
normalized frequency syntactic respectively semantic category across lexicon.
Even without 5% lexicon entries utterances could still analyzed. screen
break missing word representations attempts provide analysis good
70

fiSCREEN: Flat Syntactic Semantic Spoken Language Analysis

Correct syntactic output representation 72%
Correct semantic output representation 67%

Table 7: Overall syntactic semantic accuracy running screen system
meeting corpus unknown test set 5% lexicon entries eliminated
possible. expected, Table 7 shows performance drop overall syntactic
semantic accuracy. However, compared 74% 72% performance complete
lexicon (see Table 6) still find 72% syntactic output representations 67%
semantic output representations correct eliminating 5% lexicon entries.
Correct syntactic output representation 70%
Correct semantic output representation 67%

Table 8: Overall syntactic semantic accuracy running screen system
meeting corpus unknown test set 10% lexicon entries
eliminated
another experiment eliminated 10% syntactic semantic lexicon entries.
case, syntactic accuracy still 70% semantic accuracy 67%.
Eliminating 10% lexicon led syntactic accuracy reduction 4% (74%
versus 70%) semantic accuracy reduction 5% (72% versus 67%). general
see experiments percentage accuracy reduction much less
percentage eliminated lexicon entries demonstrating screen's robustness working
incomplete lexicon.

6.6 Comparison Results New Different Domain

order compare performance techniques, also show results
experiments different spoken Regensburg Train Corpus. intention cannot
describe experiments domain level detail done
Blaubeuren Meeting Corpus paper. However, provide summary order
provide point reference comparison experiments meeting corpus.
comparison serves another additional possibility judge results meeting
corpus.
different domain chose 176 dialog turns railway counter. People ask
questions receive answers train connections. typical utterance is: \Yes need
eh sleeping car PAUSE PAUSE Regensburg Hamburg". used exactly
screen communication architecture process spoken utterances domain:
architecture used, 1/3 dialog turns used training, 2/3
71

fiWermter & Weber

testing unseen unknown utterances. syntactic processing, even used exactly
network structure, since expect much syntactic differences
two domains. semantic processing retrained semantic networks. Different
categories used semantic classification, particular actions. actions
meetings (e.g., visit, meet) predominant meeting corpus, actions
selecting connections (e.g., choose, select) important train corpus (Wermter &
Weber, 1996b). give reader impression portability screen,
would estimate 90% original human effort (system architecture, networks) could
used new domain. remaining 10% needed necessary new
semantic tagging training new domain.
Module

Accuracy test set
bas-syn-dis
93%
bas-sem-dis
84%
abs-syn-cat
85%
abs-sem-cat
77%
phrase-start
89%
word-error
94%
phrase-error
98%

Table 9: Performance individual networks test set train corpus
Table 9 shows performance test set train corpus. compare
results meeting corpus (Table 5) results train corpus see
particular abstract syntactic processing almost meeting corpus
(84% Table 5 compared 85% Table 9) abstract semantic processing better
meeting corpus (83% Table 5 compared 77% Table 9). modules dealing
explicit robustness repairs (phrase start, word repair errors, phrase repair errors)
show almost performance (90% vs 89%, 94% vs 94%, 98% vs 98%).
Correct syntactic output representation 76%
Correct semantic output representation 64%

Table 10: Overall syntactic semantic accuracy running screen system
unknown test set different train corpus
comparison summarize overall performance different train
domain. Table 10 shows screen syntactic performance two
domains (compare Table 6). different domain essentially confirm
previous results syntactic processing performance (74% vs. 76%). However, semantic
processing appears harder train domain since performance 64% lower
72% meeting domain. However, semantic processing, semantic tagging
semantic classification often found much harder syntactic processing general,
72

fiSCREEN: Flat Syntactic Semantic Spoken Language Analysis

difference still within range usual performance differences syntax
semantics. Since semantic categories like agents, locations, time expressions
two domains dicult action categorization mainly responsible
difference semantic performance two domains.
general transfer one domain another requires limited amount
hand-modeling. course, syntactic semantic categories specified
lexicon transcripts. syntactically semantically tagged transcript sentences
direct basis generating training sets networks. Generating
trainings sets main manual effort transferring system new domain.
generation training sets performed training networks
proceed automatically. training typical single recurrent network takes
order hours. much less manual work required transferring standard
symbolic parser new domain generating new syntactic semantic grammar.

6.7 Illustrative Comparison Argument Based Symbolic Parser
made point screen's learned representations robust
hand-coded deeply structured representations. would like elaborate point
compelling illustrative argument. Consider different variations sentence hypotheses
speech recognizer Figure 19: 1. correct sentence hypothesis: \Am sechsten
April bin ich auer Hause" (\On 6th April home") 2. partially incorrect
1.Input: SECHSTEN APRIL BIN ICH AUER HAUSE
(ON 6th APRIL HOME)
1.Output:

PP

,!
VP

NP

NP

NG

NG

R

PP

V

NP

ADJG
N

U

ADJ
am(on)

sechsten(6th)April(April)

R

NG
N

bin(am)

2.Input: SECHSTEN APRIL ICH ICH AUER HAUS
(ON 6th APRIL HOME)
2.Output:NIL (NO ANALYSIS POSSIBLE)

ich(I)

auer(out_of) Hause(home)

,!

Figure 19: Two sentence hypotheses speech recognizer. first hypothesis
analyzed, second partially incorrect hypothesis cannot analyzed
anymore symbolic parser.
73

fiWermter & Weber

sentence hypothesis: \Am sechsten April ich ich auer Hause" (\On 6th April
home"). Focusing syntactic analysis, used existing chart parser existing
grammar used extensively real-world parsing sentence
level (Wermter, 1995). necessary significant adaptation addition rule
N G ! U pronouns, part original grammar. rule states
pronoun U (e.g., \I") noun group (NG).
run first sentence hypothesis symbolic context-free parser receive desired syntactic analysis shown Figure 19, run second slightly
incorrect sentence hypothesis parser receive analysis (The syntactic category abbreviations Figure 19 used manner throughout
paper (see Table 1-4); furthermore usual, \S" stands sentence, \ADJG" adjective group, \NP" complex nominal phrase, \VP" verb phrase. literal English
translations shown brackets).
reason second sentence hypothesis could parsed context-free
chart parser speech recognizer generated incorrect output. verb
second sentence hypothesis additional pronoun \I". mistakes
occur rather frequently based imperfectness current speech recognition technology.
course one could argue grammar relaxed made exible
deal mistakes. However, rules fault detection integrated
grammar parser complicated grammar parser. Even
important, impossible predict possible mistakes integrate symbolic
context-free grammar. Finally, relaxing grammar dealing mistakes using
explicit specific rules also might lead additional mistakes grammar
extremely underspecified.
shown, instance Figure 17, screen problems dealing
speech recognizer variations mistakes. main difference standard
context-free symbolic chart parser analysis screen's analysis screen learned
provide analysis noisy conditions context-free parser handcoded provide structural analysis. emphasized
make argument structural representations per se general.
structure provided better, particularly tasks require structured
world knowledge. However, robustness major concern, lower syntactic
semantic spoken-language analysis, learned analysis provides robustness.

6.8 Comparisons Related Hybrid Systems
Recently, connectionist networks received lot attention computational learning
mechanisms written language processing (Reilly & Sharkey, 1992; Miikkulainen, 1993;
Feldman, 1993; Barnden & Holyoak, 1994; Wermter, 1995). paper however,
focused examination hybrid connectionist techniques spoken language processing. previous approaches speech/language processing processing often
sequential. is, one module like speech recognizer syntactic analyzer completed work next module like semantic analyzer started work. contrast,
screen works incrementally allows system (1) modules running par74

fiSCREEN: Flat Syntactic Semantic Spoken Language Analysis

allel, (2) integrate knowledge sources early, (3) compute analysis
similar humans since humans start process sentences may completed.
compare approach related work systems. head-to-head comparison different system dicult based different computer environments
whether systems accessed adapted easily input. Furthermore,
different systems typically used different purposes different language corpora,
grammars, rules, etc. However, made extensive effort fair conceptual
comparison.
parsec (Jain, 1991) hybrid connectionist system embedded larger
speech translation effort janus (Waibel et al., 1992). input parsec sentences,
output case role representations. system consists several connectionist modules
associated symbolic transformation rules providing transformations suggested
connectionist networks. parsec's philosophy use connectionist networks
triggering symbolic transformations, screen uses connectionist networks transformations themselves. screen's philosophy use connectionist networks wherever
possible symbolic rules necessary.
found symbolic processing particularly useful simple known tests (like lexical
equality) complex control tasks whole system (when module communicate module). Much actual transformational work done
trained connectionist networks. contrast design philosophy parsec
connectionist modules provide control knowledge transformation
performed. selected transformation actually performed symbolic procedure. screen uses connectionist modules transformations symbolic control,
parsec uses connectionist modules control symbolic procedures transformations.
Different screen, parsec receives sentence hypotheses either sentence transcripts N-best hypotheses janus system. approach receives incremental
word hypotheses used speech construction part build sentence hypotheses. part also used prune hypothesis space determine best sentence
hypotheses. analysis screen semantic syntactic plausibilities
partial sentence hypothesis still uence partial sentence hypotheses
processed.
parsec screen modular architecture tested advantage
connectionist module learn relatively easy subtask. contrast
development parsec experience modularity requires less training time.
Furthermore, modules screen able work independently
parallel. addition syntactic semantic knowledge, parsec make use
prosodic knowledge screen currently use prosodic hints. hand,
screen also contains modules learning dialog act assignment modules
currently part parsec. Learning dialog act processing important determining
intended meaning utterance (Wermter & Lochel, 1996).
Recent extensions based parsec provide structure use annotated
linguistic features (Bu et al., 1994). authors state \implemented (based
parsec) connectionist system" approximate shift reduce parser.
connectionist shift-reduce parser substantially differs original parsec architecture.
75

fiWermter & Weber

refer \parsec extension". parsec extension labels complete
sentence first level categories. first level categories input
network order provide second level categories complete sentence
on, highest level sentence symbol added.
Using recursion step parsec extension provide deeper structural
interpretations screen currently does. However, recursion step construction structure also price. First, labels like NP noun phrase
defined lexical items lexicon. Second, important, complete utterance
labeled n-th level categories processing n+1-th level categories
starts. Therefore several parses (e.g., 7 utterance \his big brother loved himself")
utterance necessary. means recent parsec extension
powerful screen original parsec system Jain respect opportunity provide deeper structural interpretations. However, time
parsec extension looses possibility process utterances incremental manner.
However, incrementality important property spoken-language processing
screen. Besides fact humans process language incremental left-to-right
manner, also allows screen prune search space incoming word hypotheses
early.
Comparing parsec screen, parsec aims supporting symbolic rules using symbolic transformations (triggered connectionist networks) integrating linguistic features. Currently, linguistic features recent parsec extension (Bu et al.,
1994) provide structural morphological knowledge screen does. Therefore,
currently appears easier integrate parsec extension larger systems
high level linguistic processing. fact, parsec used context janus
framework. hand, screen aims robust incremental processing
using word hypothesis space, specific repair modules, representations.
particular, screen emphasizes robustness spoken-language processing, since
contains explicit repair mechanisms implicit robustness. Explicit robustness covers
often occurring errors (interjections, pauses, word phrase repairs) explicit modules,
less predictable types errors supported implicit similaritybased robustness connectionist networks themselves. general, representations generated extension parsec provide better support deeper structures
screen, screen provides better support incremental robust processing.
recent extension based parsec called feaspar, overall parsing performance
syntactic semantic feature accuracy 33.8%. Although additional improvements
shown using subsequent search techniques parsing results, consider
subsequent search techniques better parses since would violate incremental
processing (Bu, 1996). Without using subsequent search techniques screen reaches
overall semantic syntactic accuracy 72% 74% shown Table 6. However
pointed out, screen feaspar use different input sentences, features
architectures.
Besides parsec also berp trains systems focus hybrid spoken-language processing. berp (Berkeley Restaurant Project) current project employs multiple
different representations speech/language analysis (Wooters, 1993; Jurafsky et al., 1994,
1994b). task berp act knowledge consultant giving advice choos76

fiSCREEN: Flat Syntactic Semantic Spoken Language Analysis

ing restaurants. different components berp: feature extractor receives
digitized acoustic data extracts features. features used connectionist phonetic probability estimation. output connectionist feedforward network
used Viterbi decoder uses multiple pronunciation lexicon different language models (e.g. bigram, hand-coded grammar rules). output decoder word
strings transformed database queries stochastic chart parser. Finally,
dialog manager controls dialog user ask questions.
berp screen common ability deal errors humans
speech recognizer well relatively analysis. However, reaching robustness berp probabilistic chart parser used compute possible fragments first.
Then, additional fragment combination algorithm used combining fragments
cover greatest number input words. Different sequential process
first computing fragments utterance combining fragments, screen
uses incremental processing desirably provides best possible interpretation.
sense screen's language analysis weaker general. screen's analysis never
break produce best possible interpretation noisy utterances. strategy
may particularly useful incremental translation. hand, berp's language
analysis stronger restricted. berp's analysis may stop fragment level
contradictory fragments. strategy may particularly useful question
answering additional world knowledge necessary available.
trains related spoken-language project building planning assistant
reason time, actions, events (Allen, 1995; Allen et al., 1995).
goal building general framework natural language processing planning
train scheduling, trains needs lot commonsense knowledge. scenario, person
interacts system order find solutions train scheduling cooperative
manner. person assumed know goals scheduling
system supposed details domain. utterance person
parsed syntactic semantic parser. linguistic reasoning completed
modules scoping reference resolution. linguistic reasoning, conversation
acts determined system dialog manager responses generated based
template-driven natural language generator. Performance phenomena spoken language
like repairs false starts currently dealt already (Heeman & Allen, 1994b,
1994a). Compared screen, trains project focuses processing spoken
language in-depth planning level. screen uses primarily connectionist
language analysis, trains uses chart parser generalized phrase structure grammar.

7. Discussion
First focus learned processing spoken-language processing.
started screen project, predetermined whether deep analysis
screening analysis would particularly appropriate robust analysis spoken
sentences. deep analysis highly structured representations less appropriate since
unpredictable faulty variations spoken language limit usefulness deep structured knowledge representations much case written language. Deep
interpretations structured representations - instance possible HPSG
77

fiWermter & Weber

grammars text processing - make great deal assumptions predictions
hold faulty spoken language. Furthermore, learned generating
semantic syntactic representation even need use deep interpretation
certain tasks. instance, translating two languages necessary
disambiguate prepositional phrase attachment ambiguities since process
translation disambiguations may get ambiguous target language.
However, use structure level words phrases syntax semantics respectively. learned single semantics level rather four
syntax semantics levels sucient since syntax necessary detecting phrase
boundaries. One could argue one syntactic abstract phrase representation one
abstract semantic phrase representation may enough. However, found basic
syntactic semantic representations word level make task easier subsequent abstract analysis phrase level. Furthermore, basic syntactic semantic
representations necessary tasks well, instance judgment
plausibility sequence syntactic semantic categories. plausibility used
filter finding good word hypothesis sequences. Therefore, argue processing
faulty spoken language - task like sentence translation question answering -
need much less structured representations typically used well-known parsers
need structured representations single-level tagger.
previous work made early experiences related connectionist
networks analyzing text phrases. Moving analyzing text phrases analyzing unrestricted spoken utterances, tremendous differences two tasks. found
phrase-oriented analysis used scan (Wermter, 1995) advantageous principle
spoken-language analysis phrase-oriented analysis common learning text
speech processing. However, learned spoken-language analysis needs much
sophisticated architecture. particular, since spoken language contains many unpredictable errors variations, fault tolerance robustness much important.
Connectionist networks inherent implicit robustness based similarity-based
processing gradual numerical representations. addition, found classes
relatively often occurring mistakes, explicit robustness provided
machinery interjections, word phrase repairs. Furthermore, architecture
consider processing potentially large number competing word hypothesis
sequences rather single sentence phrase text processing.
Now, focus learned connectionist hybrid architectures. beginning predetermine whether connectionist methods would
particularly useful control individual modules both. However, development screen system became clear general task
spoken language understanding, individual subtasks like syntactic analysis
fault-tolerant \noise" spoken language, due humans speechrecognizers well. Especially unforeseeable variations often occur spontaneously spoken
language cannot predefined well advance symbolic rules general manner.
fault-tolerance task level could supported particularly well inherent
fault-tolerance connectionist networks individual tasks support inductive
learning algorithms. learned robust understanding spoken-language
connectionist networks particularly effective within individual subtasks.
78

fiSCREEN: Flat Syntactic Semantic Spoken Language Analysis

quite lot work control connectionist networks. However,
many cases approaches concentrated control single networks.
recently work control modular architectures (Sumida, 1991;
Jacobs et al., 1991b; Jain, 1991; Jordan & Jacobs, 1992; Miikkulainen, 1996). instance,
approach Jacobs Jordan (Jacobs et al., 1991b; Jordan & Jacobs, 1992), task
knowledge control knowledge learned both. Task knowledge learned individual
task networks, higher control networks responsible learning single task
network responsible producing output. Originally open question whether
connectionist control would possible processing spoken language. automatic
modular task decomposition (Jacobs et al., 1991a) done simple forms function
approximation, complex problems like understanding spoken language real-world
environments still need designer-based modular task decomposition necessary tasks.
learned connectionist control architecture lot modules
subtasks currently seems beyond capabilities current connectionist networks.
shown connectionist control possible limited number connectionist modules (Miikkulainen, 1996; Jain, 1991). instance Miikkulainen shows
connectionist segmenter connectionist stack control parser analyze embedded clauses. However, communication paths still restricted within
three modules. Especially real-world system spoken-language understanding speech, syntax, semantics dialog processing translation extremely
dicult learn coordinate different activities, especially large parallel stream
word hypothesis sequences. believe may possible future, however
currently connectionist control screen restricted detection certain hesitations
phenomena like corrections.
Considering screening analysis spoken language hybrid connectionist techniques together, developed followed general guideline (or design philosophy )
using little knowledge necessary getting far possible using connectionist
networks wherever possible symbolic representations necessary. guideline
led us (1) robust representation spoken-language analysis (2)
use hybrid connectionist techniques support task choice possibly
appropriate knowledge structure. Many hybrid systems contain small portion
connectionist representations addition many modules, e.g. berp (Wooters,
1993; Jurafsky et al., 1994, 1994b), janus (Waibel et al., 1992), trains (Allen, 1995; Allen
et al., 1995). contrast, important subtasks screen performed directly
many connectionist networks.
Furthermore, learned syntactic semantic representations could give
surprisingly good training test results trained tested medium corpus
2300 words 184 dialog turns. good results mostly due
learned internal weight representation local context adds sequentiality
category assignments. Without internal weight representation preceding context
syntactic semantic categorization perform equally well, choice
recurrent networks crucial many sequential category assignments. Therefore
networks techniques hold potential especially medium-size domains
restricted amount training material available. statistical techniques often
79

fiWermter & Weber

used large data sets, work well medium data sets, connectionist
techniques used work well medium-size domains.
used techniques ported different domains used different purposes. Even different sets categories would used learning networks
able extract syntactic regularities automatically. Besides domain arranging
business meetings also ported screen domain interactions railway
counter comparable syntactic semantic results. two domains differed primarily semantic categories, syntactic categories (and networks) screen
could used directly.
screen potential scaling up. fact, based imperfect output
speech recognizer, several thousand sentence hypotheses already processed.
new words processed, syntactic semantic basic categories simply
entered lexicon. structure individual networks change, new units
added therefore networks retrained.
amount hand-coding restricted primarily symbolic control module
interaction labeling training material individual networks.
changed domain railway counter interactions, could use identical control,
well syntactic networks. semantic networks retrained due
different domain.
far focused supervised learning simple recurrent networks feedforward networks. Supervised learning still requires training set manual labeling
work still done. Although especially medium size corpora labeling examples
easier instance designing complete rule bases would nice automate
knowledge acquisition even further. Currently plan build sophisticated lexicon component provide support automatic lexicon design (Riloff, 1993)
dynamic lexicon entry determination using local context (Miikkulainen, 1993).
Furthermore, screen could expanded speech construction evaluation
part. syntactic semantic hypotheses could used interaction
speech recognizer. Currently syntactic semantic hypotheses speech evaluation
part used exclude unlikely word hypothesis sequences language modules.
However, hypotheses connectionist networks syntax semantics -
particular modules basic syntactic semantic category prediction - could also
used directly process recognition future order provide
syntactic semantic feedback speech recognizer early stage. Besides syntax
semantics, cue phrases, stress intonation could provide additional knowledge
speech/language processing (Hirschberg, 1993; Gupta & Touretzky, 1994). issues
additional major efforts future.

8. Conclusions
described underlying principles, implemented architecture, evaluation new screening approach learning analysis spoken language. work
makes number original contributions fields artificial intelligence advances
state art several perspectives: perspective symbolic connectionist design argue hybrid solution, connectionist networks used
80

fiSCREEN: Flat Syntactic Semantic Spoken Language Analysis

wherever useful symbolic processing used control higher level analysis. Furthermore, shown recurrent networks provided better syntactic
semantic prediction results 1-5 grams. perspective connectionist networks
alone, demonstrated connectionist networks fact used real-world
spoken-language analysis. perspective natural language processing argue
hybrid system design advantageous integrating speech language since lower
speech-related processing supported fault-tolerant learning connectionist networks
higher processing control supported symbolic knowledge structures. general, properties support parallel rather sequential, learned rather coded,
fault-tolerant rather strict processing spoken language.
main result paper learned representations support robust processing spoken language better in-depth structured representations connectionist networks provide fault-tolerance reach robustness. Due noise
spontaneous language (interjections, pauses, repairs, repetitions, false starts, ungrammaticalities, also additional false word hypotheses speech recognizer) complex structured possibly recursive representations often cannot computed using standard symbolic
representations like context-free parsers. hand, tasks like information
extraction spoken language may need in-depth structured representation. believe hybrid connectionist techniques considerable potential
tasks, instance information extraction restricted noisy spoken-language domains. in-depth understanding like inferencing story interpretation needs
complex structured representations, shallow understanding instance information
extraction noisy speech language environments benefit at, robust learned
representations.

Acknowledgements
research funded German Federal Ministry Research Technology
(BMBF) Grant #01IV101A0 German Research Association (DFG)
Grant DFG Ha 1026/6-3, Grant DFG 1468/4-1. would like thank S. Haack,
M. Lochel, M. Meurer, U. Sauerland, M. Schrattenholzer work screen;
well David Bean, Alexandra Klein, Steven Minton, Johanna Moore, Ellen Riloff five
anonymous referees comments earlier versions paper.

References
Allen, J. F. (1995). TRAINS-95 parsing system: user's manual. Tech. rep. TRAINS
TN 95-1, University Rochester, Computer Science Department.
Allen, J. F., Schubert, L. K., Ferguson, G., Heeman, P., Hwang, C. H., Kato, T., Light,
M., Martin, N. G., Miller, B. W., Poesio, M., & Traum, D. R. (1995). TRAINS
project: case study building conversational planning agent. Journal Experimental Theoretical AI, 7, 7{48.
81

fiWermter & Weber

Barnden, J. A., & Holyoak, K. J. (Eds.). (1994). Advances Connectionist Neural
Computation Theory, Vol. 3., Ablex Publishing Corporation.
Bu, F. D. (1996). FeasPar - Feature Structure Parser Learning Parse Spontaneous
Speech. Ph.D. thesis, University Karlsruhe, Karlsruhe, FRG.
Bu, F. D., Polzin, T. S., & Waibel, A. (1994). Learning complex output representations
connectionist parsing spoken language. Proceedings International Conference Acoustics, Speech Signal Processing, Vol. 1, pp. 365{368, Adelaide,
Australia.
Charniak, E. (1993). Statistical Language Learning. MIT Press, Cambridge, MA.
Dyer, M. G. (1983). In-Depth Understanding: Computer Model Integrated Processing
Narrative Comprehension. MIT Press, Cambridge, MA.
Elman, J. L. (1990). Finding structure time. Cognitive Science, 14 (2), 179{211.
Faisal, K. A., & Kwasny, S. C. (1990). Design hybrid deterministic parser. Proceedings 13 th International Conference Computational Linguistics, pp. 11{16,
Helsinki, Finnland.
Feldman, J. A. (1993). Structured connectionist models language learning. Artificial
Intelligence Review, 7 (5), 301{312.
Geutner, P., Suhm, B., Bu, F.-D., Kemp, T., Mayfield, L., McNair, A. E., Rogina, I.,
Schultz, T., Sloboda, T., Ward, W., Woszczyna, M., & Waibel, A. (1996). Integrating
different learning approaches multilingual spoken language translation system.
Wermter, S., Riloff, E., & Scheler, G. (Eds.), Connectionist, Statistical Symbolic Approaches Learning Natural Language Processing, pp. 117{131, Springer,
Heidelberg.
Gupta, P., & Touretzky, D. S. (1994). Connectionist models linguistic theory: Investigations stress systems language. Cognitive Science, 18 (1), 1{50.
Hauenstein, A., & Weber, H. H. (1994). investigation tightly coupled time synchronous
speech language interfaces using unification grammar. Proceedings 12th
National Conference Artificial Intelligence Workshop Integration Natural
Language Speech Processing, pp. 42{49, Seattle, Washington.
Heeman, P. A., & Allen, J. (1994a). Detecting correcting speech repairs. Proceedings
32nd Annual Meeting Association Computational Linguistics, pp. 295{
302, Las Cruces, NM.
Heeman, P. A., & Allen, J. (1994b). Tagging speech repairs. Proceedings Human
Language Technology Workshop, pp. 187{192, Plainsboro, NJ.
Hendler, J. A. (1989). Marker-passing microfeatures: Towards hybrid symbolic/connectionist model. Cognitive Science, 13 (1), 79{106.
82

fiSCREEN: Flat Syntactic Semantic Spoken Language Analysis

Hirschberg, J. (1993). Pitch accent context: Predicting intonational prominence
text. Artificial Intelligence, 63, 305{340.
Jacobs, R. A., Jordan, M. I., & Barto, A. G. (1991a). Task decomposition competition modular connectionist architecture: vision tasks.
Cognitive Science, 15, 219{250.
Jacobs, R. A., Jordan, M. I., Nowlan, S. J., & Hinton, G. E. (1991b). Adaptive mixtures
local experts. Neural Computation, 3 (1), 79{87.
Jain, A. N. (1991). Parsing complex sentences structured connectionist networks.
Neural Computation, 3 (1), 110{120.
Jordan, M. I., & Jacobs, R. A. (1992). Hierarchies adaptive experts. Moody, J. E.,
Hanson, S. J., & Lippmann, R. R. (Eds.), Advances Neural Information Processing
Systems 4, pp. 985{992, Morgan Kaufmann, San Mateo, CA.
Jurafsky, D., Wooters, C., Tajchman, G., Segal, J., Stolcke, A., Fosler, E., & Morgan,
N. (1994a). Berkeley Restaurant Project. Proceedings International
Conference Speech Language Processing. pp. 2139-2142, Yokohama, Japan.
Jurafsky, D., Wooters, C., Tajchman, G., Segal, J., Stolcke, A., & Morgan, N. (1994b). Integrating experimental models syntax, phonology, accent/dialect speech recognizer. investigation tightly coupled time synchronous speech. Proceedings
12th National Conference Artificial Intelligence Workshop Integration
Natural Language Speech Processing, pp. 107{115, Seattle, Washington.
Medsker, L. R. (1994). Hybrid Neural Network Expert Systems. Kluwer Academic
Publishers, Boston.
Mellish, C. S. (1989). chart-based techniques parsing ill-formed input. Proceedings 27th Annual Meeting Association Computational Linguistics, pp.
102{109, Vancouver, Canada.
Menzel, W. (1994). Parsing spoken language time constraints. Cohn, A. G.
(Ed.), Proceedings 11th European Conference Artificial Intelligence, pp. 561{
564, Amsterdam.
Miikkulainen, R. (1993). Subsymbolic Natural Language Processing. integrated model
scripts, lexicon memory. MIT Press, Cambridge, MA.
Miikkulainen, R. (1996). Subsymbolic case-role analysis sentences embedded clauses.
Cognitive Science, 20, 47{73.
Nakatani, C., & Hirschberg, J. (1993). speech-first model repair detection correction. Proceedings 31st Annual Meeting Association Computational
Linguistics, pp. 46{53 Columbus, Ohio.
Reilly, R. G., & Sharkey, N. E. (Eds.). (1992). Connectionist Approaches Natural Language Processing. Lawrence Erlbaum Associates, Hillsdale, NJ.
83

fiWermter & Weber

Riloff, E. (1993). Automatically constructing dictionary information extraction tasks.
Proceedings 11th National Conference Artificial Intelligence, pp. 811{816,
Washington, DC.
Rumelhart, D. E., Hinton, G. E., & Williams, R. J. (1986). Learning internal representations error propagation. Rumelhart, D. E., McClelland, J. L., & PDP
research group (Eds.), Parallel Distributed Processing, Vol. 1., pp. 318{362. MIT Press,
Cambridge, MA.
Sauerland, U. (1996). Konzeption und Implementierung einer Speech/Language
Schnittstelle. Master's thesis, University Hamburg, Computer Science Department,
Hamburg, FRG.
Sumida, R. A. (1991). Dynamic inferencing parallel distributed semantic networks.
Proceedings 13th Annual Meeting Cognitive Science Society, pp. 913{917,
Boston, Chicago.
Sun, R. (1994). Integrating Rules Connectionism Robust Common Sense Reasoning.
Wiley Sons, New York.
von Hahn, W., & Pyka, C. (1992). System architectures speech understanding
language processing. Heyer, G., & Haugeneder, H. (Eds.), Applied Linguistics.
Wiesbaden.
Waibel, A., Jain, A. N., McNair, A., Tebelskis, J., Osterholtz, L., Saito, H., Schmidbauer,
O., Sloboda, T., & Woszczyna, M. (1992). JANUS: Speech-to-speech translation using
connectionist non-connectionist techniques. Moody, J. E., Hanson, S. J., &
Lippmann, R. R. (Eds.), Advances Neural Information Processing Systems 4, pp.
183{190, Morgan Kaufmann, San Mateo, CA.
Ward, N. (1994). approach tightly-coupled syntactic/semantic processing speech
understanding. Proceedings 12th National Conference Artificial Intelligence Workshop Integration Natural Language Speech Processing, pp.
50{57, Seattle, Washington.
Weber, V., & Wermter, S. (1995). Towards learning semantics spontaneous dialog utterances hybrid framework. Hallam, J. (Ed.), Hybrid Problems, Hybrid Solutions
| Proceedings 10th Biennial Conference AI Cognitive Science, pp.
229{238, Sheeld, UK.
Weber, V., & Wermter, S. (1996). Artificial neural networks repairing language.
Proceedings 8th International Conference Neural Networks Applications, pp. 117{123, Marseille, FRA.
Wermter, S., & Weber, V. (1996a). Interactive spoken-language processing hybrid
connectionist system. IEEE Computer { Theme Issue Interactive Natural Language
Processing, July, 65{74.
84

fiSCREEN: Flat Syntactic Semantic Spoken Language Analysis

Wermter, S. (1994). Hybride symbolische und subsymbolische Verarbeitung Beispiel
der Sprachverarbeitung. Duwe, I., Kurfe, F., Paa, G., & Vogel, S. (Eds.),
Herbstschule Konnektionismus und Neuronale Netze. Gesellschaft fur Mathematik und
Datenverarbeitung (GMD), Sankt Augustin, FRG.
Wermter, S. (1995). Hybrid Connectionist Natural Language Processing. Chapman
Hall, Thompson International, London, UK.
Wermter, S., & Lochel, M. (1994). Connectionist learning syntactic analysis
speech/language systems. Marinaro, M., & Morasso, P. G. (Eds.), Proceedings
International Conference Artificial Neural Networks, Vol. 2, pp. 941{944,
Sorrento, Italy.
Wermter, S., & Lochel, M. (1996). Learning dialog act processing. Proceedings
16th International Conference Computational Linguistics, pp. 740{745, Kopenhagen, Denmark.
Wermter, S., & Peters, U. (1994). Learning incremental case assignment based modular
connectionist knowledge sources. Werbos, P., Szu, H., & Widrow, B. (Eds.), Proceedings World Congress Neural Networks, Vol. 4, pp. 538{543, San Diego,
CA.
Wermter, S., Riloff, E., & Scheler, G. (Eds.). (1996). Connectionist, Statistical Symbolic
Approaches Learning Natural Language Processing. Springer, Berlin.
Wermter, S., & Weber, V. (1996b). Artificial neural networks automatic knowledge acquisition multiple real{world language domains. Proceedings 8th International Conference Neural Networks Applications, pp. 289{296, Marseille,
FRA.
Wooters, C. C. (1993). Lexical modeling speaker independent speech understanding
system. Tech. rep. TR-93-068, International Computer Science Institute, Berkeley.
Young, S. R., Hauptmann, A. G., Ward, W. H., Smith, E., & Werner, P. (1989). High
level knowledge sources usable speech recognition systems. Communications
ACM, 32, 183{194.

85

fi
