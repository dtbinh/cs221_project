Journal Artificial Intelligence Research 6 (1997) 147-176Submitted 6/96; published 5/97Query DAGs: Practical Paradigm ImplementingBelief-Network InferenceAdnan Darwichedarwiche@aub.edu.lbDepartment MathematicsAmerican University BeirutPO Box 11 - 236, Beirut, LebanonGregory Provanprovan@risc.rockwell.comRockwell Science Center1049 Camino Dos RiosThousand Oaks, CA 91360Abstractdescribe new paradigm implementing inference belief networks, consists two steps: (1) compiling belief network arithmetic expression calledQuery DAG (Q-DAG); (2) answering queries using simple evaluation algorithm.node Q-DAG represents numeric operation, number, symbol evidence. leaf node Q-DAG represents answer network query, is,probability event interest. appears Q-DAGs generated using standard algorithms exact inference belief networks | showgenerated using clustering conditioning algorithms. time spacecomplexity Q-DAG generation algorithm worse time complexityinference algorithm based. complexity Q-DAG evaluation algorithmlinear size Q-DAG, inference amounts standard evaluationarithmetic expression represents. intended value Q-DAGs reducingsoftware hardware resources required utilize belief networks on-line, real-worldapplications. proposed framework also facilitates development on-line inferencedifferent software hardware platforms due simplicity Q-DAG evaluationalgorithm. Interestingly enough, Q-DAGs found serve purposes: simple techniques reducing Q-DAGs tend subsume relatively complex optimization techniquesbelief-network inference, network-pruning computation-caching.1. IntroductionConsider designing car self-diagnostic system alert driver rangeproblems. Figure 1 shows simplistic belief network could provide ranked setdiagnoses car troubleshooting, given input sensors hooked battery,alternator, fuel-tank oil-system.standard approach building diagnostic system put belief network,along inference code, onto car's computer; see Figure 2. encounterednumber diculties using approach embody belief network technology industrial applications. First, asked provide technology multiple platforms.applications, technology implemented ADA pass certain certification procedures. others, implemented domain-specific hardwaresupports primitive programming languages. Second, memory limited keepc 1997 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.fiDarwiche & Provanfuel sensorfuelbatteryoil-pressurebattery sensorfaultoil-pressuresensoralternatoralternatorsensorFigure 1: simple belief network car diagnosis.cost unit certain threshold maintain product profitability. dilemmafollowing: belief network algorithms trivial implement, especially optimization crucial, porting algorithms multiple platforms languages wouldprohibitively expensive, time-consuming demanding qualified manpower.overcome diculties, devised exible approach implementingbelief network systems, based following observation. Almost workperformed standard algorithms belief networks independent specific evidencegathered variables. example, run algorithm battery-sensor setlow run later variable set dead, find almost algorithmicdifference two runs. is, algorithm branch differentlykey decisions makes, difference two runs specificarguments invoked numeric operations. Therefore, one apply standard inferencealgorithm network evidence parameter instead specific value.result returned algorithm arithmetic expression parametersdepend specific evidence. parameterized expression call QueryDAG, example shown Figure 4.1approach proposing consists two steps. First, given belief network, setvariables evidence may collected (evidence variables), set variables need compute probability distributions (query variables), Q-DAGcompiled off-line, shown Figure 3. compilation typically done sophisticated software/hardware platform, using traditional belief network inference algorithmconjunction Q-DAG compilation method. part process far awaycostly computationally. Second, on-line system composed generatedQ-DAG evaluator specific given platform used evaluate Q-DAG. Givenevidence, parameterized arithmetic expression evaluated straightforward mannerusing simple arithmetic operations rather complicated belief network inference.1. sharing subexpressions makes Directed Acyclic Graph instead tree.148fiA Practical Paradigm Implementing Belief-Network InferenceTraditional ApproachCompiled ApproachFaultVariablesCausalNetworkNLNESensorValuesCausal NetworkInferenceSoftwareSensorVariablesQ-DAGCompilerQueryDAGQ-DAGEvaluatorFFLNE0NLNEFaultProbabilitiesFigure 2: figure compares traditional approach exact belief-network inference(shown left) new compiled approach (shown right)context diagnostic reasoning. traditional approach, belief networksensor values used on-line compute probability distributionsfault variables; compiled approach, belief network, fault variablessensor variables compiled off-line produce Q-DAG, evaluatedon-line using sensor values compute required distributions.computational work needed perform on-line evaluation straightforwardlends easy implementations different software hardware platforms.approach shares commonality methods symbolically manipulate probability expressions, like SPI (Li & D'Ambrosio, 1994; Shachter, D'Ambrosio, &del Favero, 1990); differs SPI objective manipulations and, hence,results obtained. SPI explicates notion arithmetic expression statebelief-network inference viewed expression-factoring operation. allowsresults optimization theory utilized belief-network inference.hand, define arithmetic expression explicate formalize boundarieson-line off-line inference, goal identifying minimal piece softwarerequired on-line. results therefore oriented towards purpose include:(a) formal definition Q-DAG evaluator; (b) method generating Q-DAGsusing standard inference algorithms | algorithm need subscribe inference-as149fiDarwiche & ProvanQuery VariablesEvidence VariablesCausal NetworkQ-DAG CompilerOff-lineOn-lineQuery DAGEvidenceQ-DAG EvaluatorFigure 3: proposed framework implementing belief-network inference.(a)(b)Pr(A=ON) = .3Pr(B=OFF, c)Pr(B=ON, c)++.56.075+Pr(B=ON|a).14.225BC*****Pr(C=ON|a).25.9.8.5.9*.1(C,ON)+**.5(C,OFF)Figure 4: belief network (a); corresponding Query-DAG (b). Here, C evidencevariable, interested probability variable B .factoring view used Q-DAG generation; (c) computational guaranteessize Q-DAGs terms computational guarantees inference algorithm usedgenerate them. Although SPI framework positioned formulate related results,pursued direction.important stress following properties proposed approach. First, declaring evidence variable compilation process mean evidence mustcollected variable on-line|this important evidence values, e.g.,sensors, may lost practice|it means evidence may collected. Therefore, one declare variables evidence one wishes. Second, variabledeclared evidence query. allows one perform value-of-information150fiA Practical Paradigm Implementing Belief-Network Inferencecomputations decide whether worth collecting evidence specific variable.Third, space complexity Q-DAG terms number evidence variablesworse time complexity underlying inference algorithm; therefore,simple enumerate-all-possible-cases approach. Finally, time space complexitygenerating Q-DAG worse time complexity standard belief-networkalgorithm used generation. Therefore, network solved using standardinference algorithm, time complexity algorithm worse spacecomplexity,2 construct Q-DAG network.following section explains concept Q-DAG concrete exampleprovides formal definitions. Section 3 dedicated generation Q-DAGscomputational complexity, showing standard belief-network inference algorithmused compile Q-DAG long meets general conditions. Section 4discusses reduction Q-DAG generated, showing reductionsubsumes key optimizations typically implemented belief network algorithms.Section 5 contains detailed example application framework diagnosticreasoning. Finally, Section 6 closes concluding remarks.2. Query DAGssection starts treatment Q-DAGs concrete example. considerparticular belief network, define set queries interest, show Q-DAGused answer queries. discuss Q-DAG generated;used. allow concrete introduction Q-DAGs help usground formal definitions follow.belief network consider one Figure 4(a). class queriesinterested Pr (B j C ), is, probability variable B takes valuegiven known (or unknown) value C . Figure 4(b) depicts Q-DAG answeringqueries, essentially parameterized arithmetic expression valuesparameters depend evidence obtained. Q-DAG actually answer queriesform Pr (B; C ), use normalization compute Pr (B j C ).First, number observations Q-DAG Figure 4(b):Q-DAG two leaf nodes labeled Pr (B=ON ; c) Pr (B=OFF ; c).called query nodes values represent answers queries Pr (B=ON ; c)Pr (B=OFF ; c).Q-DAG two root nodes labeled (C; ) (C; ). calledEvidence Specific Nodes (ESNs) since values depend evidence collectedvariable C on-line.According semantics Q-DAGs, value node (V; v ) 1 variable Vobserved v unknown, 0 otherwise. values ESNs determined,evaluate remaining nodes Q-DAG using numeric multiplication addition.numbers get assigned query nodes result evaluation answersqueries represented nodes.2. Algorithms based join trees property.151fiDarwiche & Provan.2725.2875.0925Pr(B=OFF, c)Pr(B=ON, c)Pr(B=OFF, c).3475Pr(B=ON, c)++.28.2025.07****.9.0075.28**.5.1++.5+.90.500.1******(C,ON).5.9.10(C,OFF)0(b).14.225+.1**.56.075.07.0225.91(a).14.225.56.075++.0675(C,ON)0.5**.51(C,OFF)Figure 5: Evaluating Q-DAG Figure 4 respect two pieces evidence: (a)C=ON (b) C=OFF .example, suppose evidence C = . ESN (C; )evaluated 1 ESN (C; ) evaluated 0. Q-DAG Figure 4(b)evaluated given Figure 5(a), thus leadingPr (B=ON ; C=ON ) = :3475;Pr (B=OFF ; C=ON ) = :2725;conclude Pr (C = ) = :62. compute conditionalprobabilities Pr (B=ON j C=ON ) Pr (B=OFF j C=ON ) using:Pr (B=ON j C=ON ) = Pr (B=ON ; C=ON )=Pr (C=ON );Pr (B=OFF j C=ON ) = Pr (B=OFF ; C=ON )=Pr (C=ON ):evidence C=OFF , however, (C; ) evaluates 0 (C; )evaluates 1. Q-DAG Figure 4(b) evaluated given Figure 5(b),thus leadingPr (B=ON ; C=OFF ) = :2875;Pr (B=OFF ; C=OFF ) = :0925:use following notation denoting variables values. Variablesdenoted using uppercase letters, A; B; C , variable values denotedlowercase letters, a; b; c. Sets variables denoted boldface uppercase letters,A; B; C, instantiations denoted boldface lowercase letters,a; b; c. use E denote set variables evidence. Therefore,152fiA Practical Paradigm Implementing Belief-Network Inferenceuse e denote instantiation variables represents evidence. Finally,family variable set containing variable parents directed acyclicgraph.Following formal definition Q-DAG.Definition 1 Q-DAG tuple (V ; ; ; D; Z )1. V distinguished set symbols (called evidence variables)2. symbol (called unknown value)3. maps variable V set symbols (called variable values) different.4. directed acyclic graph- non-root node labeled either +- root node labeled either- number [0; 1]- pair (V; v ) V evidence variable v value5. Z distinguished set nodes (called query nodes)Evidence variables V correspond network variables expect collectevidence on-line. example, Figure 5, C evidence variable. onevariables set possible values captured function . example,Figure 5, evidence variable C values . special value usedvalue variable known. example, may sensor variablevalues \low," \medium," \high," lose sensor value on-line reasoning.case, set sensor value .3 Query nodes representing answersuser queries. example, Figure 5, B query variable, leads query nodesPr(B=ON ; c) Pr(B=OFF ; c).important notion evidence:Definition 2 given Q-DAG (V ; ; ; D; Z ), evidence defined function Emaps variable V V set values (V ) [ fg.variable V mapped v 2 (V ), evidence tells us V instantiatedvalue v . V mapped , evidence tell us anything valueV .state formally evaluate Q-DAG given evidence. firstneed notation:1. Numeric-Node: n(p) denotes node labeled number p 2 [0; 1];2. ESN: n(V; v ) denotes node labeled (V; v );3. also useful cases variable measured value information justifiesthat.153fiDarwiche & Provan3. Operation-Node: n1: : :ni denotes node labeled parentsn1 ; : : :; ni ;4. Operation-Node: n1 : : : ni denotes node labeled + parentsn1 ; : : :; ni .following definition tells us evaluate Q-DAG evaluating nodes.recursive definition according value assigned node functionvalues assigned parents. first two cases boundary conditions, assigningvalues root nodes. last two cases recursive ones.Definition 3 Q-DAG (V ; ; ; D; Z ) evidence E , node evaluator definedfunction maps node number [0; 1] that:1. [n(p)] = p(The value node labeled number number itself.)(E (V ) = v E (V ) = ;2. [n(V; v )] = 10;; ifotherwise(The value evidence-specific node depends available evidence: 1 vconsistent evidence 0 otherwise.)3. [n1: : :ni ] = (n1) : : : (ni )(The value node labeled product values parent nodes.)4. [n1 : : : ni ] = (n1) + : : : + (ni )(The value node labeled + sum values parent nodes.)One typically interested values nodes Q-DAG sincenodes represent intermediate results interest user. query nodesQ-DAG represent answers user queries values nodes oneseeks constructing Q-DAG. values queries captured notionQ-DAG output.Definition 4 node evaluator extended Q-DAGs follows:((V ; ; ; D; Z )) = f(n; (n)) j n 2 Zg:set ((V ; ; ; D; Z )) called Q-DAG output.output one seeks Q-DAG. element output representsprobabilistic query answer.Let us consider evaluations Q-DAG shown Figure 4, shownFigure 5. Given evidence E (C )= , assuming Qnode(B = ) Qnode(B =) stand Q-DAG nodes labeled Pr (B=ON ; c) Pr (B=OFF ; c), respectively,[n(C; )] = 1;[n(C; )] = 0;[Qnode(B=ON )] = :075 (:9 1 + :1 0) + :56 (1 :5 + :5 0) = :3475;[Qnode(B=OFF )] = (:9 1 + :1 0) :225 + (1 :5 + :5 0) :14 = :2725;154fiA Practical Paradigm Implementing Belief-Network Inferencemeaning Pr (B=ON ; C=ON ) = :3475 Pr (B=OFF ; C=ON ) = :2725. insteadevidence E (C )=OFF , set analogous computations done.also possible evidence tells us nothing value variable C , is,E (C ) = . case, would[n(C; )] = 1;[n(C; )] = 1;[Qnode(B=ON )] = :075 (:9 1 + :1 1) + :56 (1 :5 + :5 1) = :635;[Qnode(B=OFF )] = (:9 1 + :1 1) :225 + (1 :5 + :5 1) :14 = :365;meaning Pr (B=ON ) = :635 Pr (B=OFF ) = :365.2.1 Implementing Q-DAG EvaluatorQ-DAG evaluator implemented using event-driven, forward propagation scheme.Whenever value Q-DAG node changes, one updates value children,on, possible update values possible. Another way implement evaluatorusing backward propagation scheme one starts query node updatesvalue updating values parent nodes. specifics applicationtypically determine method (or combination) appropriate.important stress level refinement enjoyed Q-DAG propagation scheme implications eciency query updates. PropagationQ-DAGs done arithmetic-operation level, contrasted propagationmessage-operation level (used many standard algorithms). propagation schemestypically optimized keeping validity ags messages invalid messagesrecomputed new evidence arrives. clearly avoid unnecessary computations never avoid unnecessary computations message typicallycoarse purpose. example, one entry message invalid,whole message considered invalid. Recomputing message lead many unnecessary computations. problem avoided Q-DAG propagation since validityags attributed arithmetic operations, building blocks message operations. Therefore, necessary arithmetic operations recomputed Q-DAGpropagation scheme, leading detailed level optimization.also stress process evaluating updating Q-DAG done outsideprobability theory belief network inference. makes development ecient online inference software accessible larger group people may lack strong backgroundsareas.42.2 Availability Evidenceconstruction Q-DAG requires identification query evidence variables.may give incorrect impression must know front variables observednot. could problematic (1) applications one may lose sensorreading, thus changing status variable observed unobserved;4. fact, appears background compiler theory may relevant generating ecientevaluator background belief network theory.155fiDarwiche & Provan.3.3Pr(B=true|a).1.8truefalsePr(B=true,b)+*Pr(a)BPr(A=true,b)truePr(B=false,b)+Pr(A=false,b)++*.1*.9(B,true)(B,false).8*.7.2Figure 6: belief network corresponding Q-DAG variable B declaredquery evidence.(2) applications variable may expensive observe, leading on-linedecision whether observe (using value-of-information computation).situations dealt Q-DAG framework. First, mentionedearlier, Q-DAGs allow us handle missing evidence use notationdenotes unknown value variable. Therefore, Q-DAGs handle missing sensorreadings. Second, variable declared query evidence. meansincorporate evidence variable available, also computeprobability distribution variable case evidence available. Figure 6 depictsQ-DAG variable declared query variable, variable B declaredevidence query variable (both variables true false values).case, two ESNs variable B also two query nodes (see Figure 6).Q-DAG used two ways:1. compute probability distributions variables B evidenceavailable B . situation, values n(B; true ) n(B; false )set 1,Pr (A = true ) = :3 :1 + :3 :9 = :3Pr (A = false ) = :8 :7 + :7 :2 = :7Pr (B = true ) = :3 :1 + :8 :7 = :59156fiA Practical Paradigm Implementing Belief-Network InferencePr (B = false ) = :3 :9 + :7 :2 = :412. compute probability variable evidence available B .example, suppose observe B false . value n(B; true )set 0 value n(B; false ) set 1,Pr (A = true ; B = false ) = :3 :9 = :27Pr (A = false ; B = false ) = :7 :2 = :14ability declare variable evidence query variable seemsessential applications (1) decision may need made whether collectevidence variable B ; (2) making decision requires knowing probabilitydistribution variable B . example, suppose using following formula(Pearl, 1988, Page 313) compute utility observing variable B :XUtility Observing (B ) = Pr(B = bje) U (B = b);bU (B = b) utility decision maker finding variable B value b.Suppose U (B = true ) = $2:5 U (B = false ) = ,$3. use Q-DAGcompute probability distribution B use evaluate Utility Observing (B ):Utility Observing (B ) = ($2:5 :59) + (,$3 :41) = $0:24;leads us observe variable B . Observing B , find value false .accommodate evidence Q-DAG continue analysis.3. Generating Query DAGssection shows Q-DAGs generated using traditional algorithms exactbelief-network inference. particular, show Q-DAGs generated usingclustering (join tree, Jensen, LS) algorithm (Jensen, Lauritzen, & Olesen, 1990; Shachter,Andersen, & Szolovits, 1994; Shenoy & Shafer, 1986), polytree algorithm, cutsetconditioning (Pearl, 1988; Peot & Shachter, 1991). also outline properties mustsatisfied belief network algorithms order adapt generating Q-DAGspropose.3.1 Clustering Algorithmprovide sketch clustering algorithm section. Readers interesteddetails referred (Shachter et al., 1994; Jensen et al., 1990; Shenoy & Shafer, 1986).According clustering method, start by:1. constructing join tree given belief network;55. join tree tree clusters satisfies following property: intersection two clustersbelongs clusters path connecting them.157fiDarwiche & Provan2. assigning matrix variable belief network cluster containsvariable's family.join tree secondary structure inference algorithm operates. needfollowing notation state algorithm:- S1; : : :; Sn clusters, cluster corresponds set variablesoriginal belief network.- potential function cluster Si , mapping instantiationsvariables Si real numbers.- Pi posterior probability distribution cluster Si , mappinginstantiations variables Si real numbers.- Mij message sent cluster Si cluster Sj , mapping instantiations variables Si \ Sj real numbers.- e given evidence, is, instantiation evidence variables E.also assume standard multiplication marginalization operations potentials.goal compute potential Pr (X; e) maps instantiation xvariable X belief network probability Pr (x; e). Given notation,state algorithm follows:Potential functions initialized using= Pr X X ;X{ X variable whose matrix assigned cluster Si;{ Pr X matrix variable X : mapping instantiations familyX conditional probabilities;{ X likelihood vector variable X : X (x) 1 x consistent givenevidence e 0 otherwise.Posterior distributions computed usingPi =kMki ;Sk clusters adjacent cluster Si .Messages computed usingXMij =Mki ;Si nSjk6=jSk clusters adjacent cluster Si .158fiA Practical Paradigm Implementing Belief-Network Inferencepotential Pr (X; e) computed usingPr (X; e) =XSi nfX gPi ;Si cluster X belongs.equations used follows. compute probability variable, mustcompute posterior distribution cluster containing variable. computeposterior distribution cluster, collect messages neighboring clusters. messagecluster Si Sj computed collecting messages clusters adjacent Siexcept Sj .statement join tree algorithm appropriate situations evidencechanging frequently since involves computing initial potentials time evidencechanges. necessary general one provide optimized versionsalgorithm. issue, however, irrelevant context generating Q-DAGsupdating probabilities face evidence changes take place Q-DAG level,includes optimization technique discuss later.3.2 Generating Q-DAGsgenerate Q-DAGs using clustering method, go two steps. First,modify initialization potential functions join tree quantifiedusing Q-DAG nodes instead numeric probabilities. Second, replace numericaddition multiplication algorithm analogous functions operate Q-DAGnodes. particular:1. Numeric multiplication replaced operationtakes Q-DAG nodesn1; : : :; ni arguments, constructs returns new node n label parentsn1; : : :; ni .2. Numeric addition + replaced operation takes Q-DAG nodes n1 ; : : :; niarguments, constructs returns new node n label + parents n1 ; : : :; ni.Therefore, instead numeric operations, Q-DAG-node constructors. insteadreturning number computation result, return Q-DAG node.state Q-DAG clustering algorithm, realize evidencee, instead set evidence variables E collect evidence.Therefore, Q-DAG algorithm compute answer query Pr (x; e), insteadcompute Q-DAG node evaluates Pr (x; e) instantiation e variablesE.following equations, potentials mappings variable instantiations QDAG nodes (instead numbers). example, matrix variable X mapinstantiation X 's family Q-DAG node n(p) instead mapping numberp. Q-DAG operationsextended operate new potentialsway + extended clustering algorithm.new set equations is:159fiDarwiche & ProvanPotential functions initialized using= n(Pr X )n(E );XE{ X variable whose matrix assigned cluster Si;{ n(Pr X ) Q-DAG matrix X : mapping instantiations X 's familyQ-DAG nodes representing conditional probabilities;{ E evidence variable whose matrix assigned cluster Si;{ n(E ) Q-DAG likelihood vector variable E : n(E )(e) = n(E; e),means node n(E )(e) evaluates 1 e consistent given evidence0 otherwise.Posterior distributions computed usingPi = Mki ;kSk clusters adjacent cluster Si .Messages computed usingMij =Mki ;Si nSjk6=jSk clusters adjacent cluster Si .Q-DAG nodes answering queries form Pr (x; e) computed usingQnode(X ) =Pi ;Si nfX gSi cluster X belongs.Qnode(X ) potential maps instantiation x variable X Q-DAGnode Qnode(X )(x) evaluates Pr (x; e) given instantiation e variables E.Hence, modifications made clustering algorithm (a) changinginitialization potential functions (b) replacing multiplication additionQ-DAG constructors multiplication addition nodes.3.3 Exampleshow proposed Q-DAG algorithm used generate Q-DAGbelief network Figure 4(a).one evidence variable example, C . interested generating Q-DAG answering queries variable B , is, queries form Pr (b; e).Figure 7(a) shows join tree belief network Figure 4(a), tables containpotential functions needed probabilistic clustering algorithm. Figure 7(b) shows160fiA Practical Paradigm Implementing Belief-Network InferenceS1ACC=ON.9.52(a)ABC=OFF.1S1S2AC1.5B=ON.25 * .3.8 * .7B=OFF.75 * .3.2 * .7ABC=OFFC=ONn(.9)n(C,ON)n(.1)n(C,OFF)n(.5)n(C,ON)n(.5)n(C,OFF)2(b)B=ONS21B=OFFn(.075)n(.225)n(.56)n(.14)Figure 7: join tree quantified numbers (a), Q-DAG nodes (b).join tree again, tables contain potential functions needed Q-DAGclustering algorithm. Note tables filled Q-DAGs instead numbers.apply Q-DAG algorithm. compute Q-DAG nodes evaluatePr (b; e), must compute posterior distribution P2 cluster S2 sincecluster variable B belongs. sum distribution variableobtain want. compute distribution P2 must first compute messageM12 cluster S1 cluster S2 .message M12 computed summingpotential function 1 cluster S1possible values variable C , i.e., M12 = 1 ; leads to:CM12 (A=ON ) = [n(:9)n(C; )] [n(:1)n(C; )];M12(A=OFF ) = [n(:5)n(C; )] [n(:5)n(C; )]:posterior distribution cluster S2 , P2 , computed using P2 = 2M12 ;leadsP2 (A=ON ; B=ON ) = n(:075)[[n(:9)n(C; )] [n(:1)n(C; )]]P2(A=ON ; B=OFF ) = n(:225)[[n(:9)n(C; )] [n(:1)n(C; )]]P2(A=OFF ; B=ON ) = n(:56)[[n(:5)n(C; )] [n(:5)n(C; )]]P2(A=OFF ; B=OFF ) = n(:14)[[n(:5)n(C; )] [n(:5)n(C; )]]:Q-DAG node Qnode(b) answering queriesform Pr (b; e) computedsumming posterior P2 variable A, Qnode =P2 ; leadingnfB gQnode(B=ON ) = [n(:075)[[n(:9)n(C; )] [n(:1)n(C; )]]][n(:56)[[n(:5)n(C; )] [n(:5)n(C; )]]]Qnode(B=OFF ) = [n(:225)[[n(:9)n(C; )] [n(:1)n(C; )]]][n(:14)[[n(:5)n(C; )] [n(:5)n(C; )]]];2161fiDarwiche & ProvanQ-DAG depicted Figure 4(b). Therefore, result applying algorithmtwo Q-DAG nodes, one evaluate Pr (B = ; e) evaluatePr (B=OFF ; e) instantiation e evidence variables E.3.4 Computational Complexity Q-DAG Generationcomputational complexity algorithm generating Q-DAGs determinedcomputational complexity clustering algorithm. particular, proposed algorithm applies -operation precisely clustering algorithm applies additionoperation. Similarly, applies-operation precisely clustering algorithm appliesmultiplication-operation. Therefore, assumetake constant time,algorithms time complexity.applicationends adding new node Q-DAG.way new node added Q-DAG. Moreover, number parentsadded node equal number arguments corresponding arithmetic operationinvoked clustering algorithm. Therefore, space complexity Q-DAGtime complexity clustering algorithm.particular, means space complexity Q-DAGs terms numberevidence variables time complexity clustering algorithmterms. Moreover, evidence variable E add evidence-specific nodesQ-DAG, number values variable E take. importantstress without complexity guarantee may hard distinguishproposed approach brute-force approach builds big table containing possibleinstantiations evidence variables together corresponding distributions queryvariables.3.5 Generation Algorithmspolytree algorithm special case clustering algorithm shown (Shachteret al., 1994). Therefore, polytree algorithm also modified suggestedcompute Q-DAGs. also means cutset conditioning easily modifiedcompute Q-DAGs: instantiation c cutset C, compute Q-DAG nodePr (x; c; e) using polytree algorithm take -sum resulting nodes.algorithms exact inference belief networks adapted generate QDAGs. general, algorithm must satisfy key condition adaptable computingQ-DAGs suggested above. condition behavior algorithmnever depend specific evidence obtained, depend variablesevidence collected. is, whether variable E instantiated value v1value v2 affect complexity algorithm. whether variable Einstantiated matter.belief networks algorithms aware satisfy property. reasonseems notion probabilistic independence algorithmsbased. Specifically, read topology belief network relation(X; Z; Y), stating variables X independent given variables Z. is,Pr (x; j z) = Pr (x j z)Pr (y j z)162fiA Practical Paradigm Implementing Belief-Network Inferenceinstantiations x; y; z variables. possible, however, holdinstantiations z specific ones. standard algorithms awaretake advantage instantiation{specific notion independence.6 Therefore,cannot attach computational significance specific value variableinstantiated. property existing algorithms makes easily adaptablegeneration Q-DAGs.3.6 Soundness Q-DAG Clustering Algorithmsoundness proposed algorithm stated below. proof given Appendix A.Theorem 1 Suppose Qnode(X ) Q-DAG potential generated Q-DAG clustering algorithm query variable X evidence variables E. Let e0 instantiationvariables E, let Q-DAG evidence E defined follows:(evidence e0 sets variable E value e;E (E ) = e;; otherwise.(Qnode(X )(x)) = Pr (x; e0):is, theorem guarantees Q-DAG nodes generated algorithmalways evaluate corresponding probabilities partial full instantiationevidence variables.4. Reducing Query DAGssection focused reducing Q-DAGs generated. mainmotivation behind reduction twofold: faster evaluation Q-DAGs less spacestore them. Interestingly enough, observed few, simple reduction techniquestend certain cases subsume optimization techniques uential practical implementations belief-network inference. Therefore, reducing Q-DAGsimportant practically.section structured follows. First, start discussing four simple reductionoperations form rewrite rules. show examples reductions subsume two key optimization techniques known network-pruning computation-caching.4.1 Reductionsgoal Q-DAG reduction reduce size Q-DAG maintainingarithmetic expression represents. describing equivalence arithmetic expressions,define notion Q-DAG equivalence:Definition 5 Two Q-DAGs equivalent iff set evidence-specificnodes output possible Q-DAG evidence.6. algorithms two{level binary networks (BN20 networks), versions SPI algorithmtake advantage independences.163fiDarwiche & ProvanQ...p.qQ2Qp.+Q1*Q1Q3*Q2 Q 1*.q+Q2Q3b) numericreductionc) associativemergingQ1Q1Q2(a) IdentityeliminationQ3Q3d) commutativemergingFigure 8: four main methods Q-DAG reduction.Figure 8 shows four basic reduction operations experimented with:1. Identity elimination: eliminates numeric node identity element childoperation node.2. Numeric reduction: replaces operation node numeric node parentsnumeric nodes.3. Associative merging: eliminates operation node using operation associativity.4. Commutative merging: eliminates operation node using operation commutativity.rules applied successively different order applicationspossible.proven operations sound (Darwiche & Provan, 1995). Basedanalysis network structure preliminary empirical results, observedmany factors govern effectives operations. degree reductionoperations, numeric reduction particular, reduce size Q-DAG dependstopology given belief network set evidence query variables.example, root nodes evidence variables belief network, leaf nodesquery variables, numeric reduction lead little Q-DAG reduction.focus numeric reduction, showing sometimes subsumes two optimization techniques uential belief network algorithms. optimizations, show examples unoptimized algorithm employs numeric reductionyields Q-DAG optimized algorithm. major implication optimizations done uniformly Q-DAG level, freeing underlying belief networkalgorithms implementational complications.following examples assume applying polytree algorithm singlyconnected networks.164fiA Practical Paradigm Implementing Belief-Network InferenceP(a).6B.9.5.6B.8.3P(B=ON|a).9.5P(C=ON|b)b(a)P(a)P(B=ON|a)C(b)Figure 9: simple belief network pruning (a) pruning (b). light-shadednode, A, query node, dark-shaded node, B , evidence node.P(A=ON,B=b)P(A=ON,B=b)**+(B,ON)+.8.2.1+(B,OFF).3.6****.9+.6.9(B,ON)(B,OFF).1.7(a) Original Q-DAG(b) Reduced Q-DAGFigure 10: Q-DAG (a) reduction (b).4.2 Network PruningPruning process deleting irrelevant parts belief network invoking inference. Consider network Figure 9(a) example, B evidence variablequery variable. One prune node C network, leading networkFigure 9(b). query form Pr (a j b) value respect eithernetwork. clear working smaller network preferred. general,pruning lead dramatic savings since reduce multiply-connected networksingly-connected one.165fiDarwiche & Provangenerate Q-DAG network Figure 9(a) using polytree algorithm,obtain one Figure 10(a). Q-DAG corresponds following expression,XXPr (A=ON ; e) = Pr (A=ON ) B (b)Pr (b j A=ON ) Pr (c j b):cbgenerate Q-DAG network Figure 9(b), however, obtain oneFigure 10(b) corresponds following expression,XPr (A=ON ; e) = Pr (A=ON ) B (b)Pr (b j A=ON ):bexpected, Q-DAG smaller Q-DAG Figure 10(a), contains subsetnodes Figure 10(a).key observation, however, optimized Q-DAG Figure 10(b)obtained unoptimized one Figure 10(a) using Q-DAG reduction. particular,nodes enclosed dotted lines collapsed using numeric reduction singlenode value 1. Identity elimination remove resulting node, leadingoptimized Q-DAG Figure 10(b).general observation, however, prunable nodes contribute identity elements computing answers queries. contributions appear Q-DAG nodesevaluate identity elements instantiations evidence. nodeseasily detected collapsed identity elements using numeric reduction. Identityelimination remove Q-DAG, leading effect networkpruning.7 Whether Q-DAG reduction replace possible pruning operations openquestion outside scope paper.4.3 Computation CachingCaching computations another uential technique optimizing inference belief networks. consider example, suppose applying polytree algorithmcompute Pr (c; b) network Figure 11. Given evidence, say B =ON , algorithmcompute Pr (c; B = ) passing messages shown Figure 12. evidencechanges B=OFF , however, algorithm employing caching recompute message B (a) (which represents causal support B (Pearl, 1988)) since valuemessage depend evidence B .8 kind optimization typically7. Note, however, Q-DAG reduction reduce computational complexity generating QDAG, although network pruning may. example, multiply{connected network may become singlyconnected pruning, thereby, reducing complexity generating Q-DAG. using Q-DAGreduction, still generate Q-DAG working multiply-connected network.8. seen considering following expression, evaluated incrementally polytreealgorithm message passes:Pr (c; e) =XbPr (c j b) B (b)|XPr (b j a) Pr (a) :{zC (b)| {z }B}( )clear subexpression corresponding message B (a) B independentevidence B .166fiA Practical Paradigm Implementing Belief-Network InferenceBCPr(a).6Pr(B=ON|a).9.5Pr(C=ON|b)b.8.3Figure 11: simple belief network demonstrating relationship Q-DAG reduction computation caching. light-shaded node, C , query node,dark-shaded node, B , evidence node.(a)BB(b)CCFigure 12: Message passing C queried B observed.implemented caching values messages keeping track messagesaffected evidence.Now, consider Q-DAG corresponding problem shown Figure 13(a).nodes enclosed dotted lines correspond message B .9 nodesevidence-specific nodes ancestor set and, therefore, never change valuesdue evidence changes. fact, numeric reduction replace one nodesancestors single node shown Figure 13(b).general, numeric reduction applied Q-DAG, one guaranteed following:(a) Q-DAG node represents message depend evidence, nodere-evaluated given evidence changes; (b) numeric reduction guaranteeP Pr (b a)Pr (a).9. precisely, correspond expression167jfiDarwiche & ProvanP(C=ON,B=b)P(C=ON,B=b)++*.8*+**(B,ON)*.3*.74+(B,OFF)*(B,OFF)(B,ON).3*.8.26****cached value.9.6.5.4.1.6 .5.4(a) Original Q-DAG(b) Reduced Q-DAGFigure 13: Q-DAG (a) reduction (b).Q-DAG evaluation method since replace node ancestor setsingle root node.104.4 Optimization Belief-Network InferenceNetwork pruning computation caching proven uential practicalimplementations belief-network inference. fact, experience shownoptimizations typically make difference usable non-usable beliefnetwork system.One problem optimizations, however, algorithm-specific implementations although based general principles (e.g., taking advantage networktopology). Another problem make elegant algorithms complicated hardunderstand. Moreover, optimizations often hard define succinctly, hencewell documented within community.contrast, belief{network inference optimized generating Q-DAGs using unoptimized inference algorithms, optimizing generated Q-DAG reduction techniques. shown examples earlier respect pruningcaching optimizations. However, whether alternate approach optimization alwaysfeasible yet known. positive answer clearly provide algorithm{independent10. Note Q-DAGs lead refined caching mechanism Q-DAG evaluator (1) caches valueQ-DAG node (2) updates cached values need (that is,value parent node changes). refined mechanism allows caching values messagesdepend evidence well.168fiA Practical Paradigm Implementing Belief-Network Inferencefuel sensorfuelbatteryoil-pressurebattery sensorfaultoil-pressuresensoralternatoralternatorsensorFigure 14: simple belief network car diagnosis.approach optimizing belief{network inference, practically important leasttwo reasons. First, Q-DAG reduction techniques seem much simpler understandimplement since deal graphically represented arithmetic expressions, withoutinvoke probability belief network theory. Second, reduction operations applicable Q-DAGs generated belief{network algorithm. Therefore, optimizationapproach based Q-DAG reduction would systematic accessible biggerclass developers.5. Diagnosis Examplesection contains comprehensive example illustrating application Q-DAGframework diagnostic reasoning.Consider car troubleshooting example depicted Figure 14. simple casewant determine probability distribution fault node, given evidence foursensors: battery-, alternator-, fuel- oil-sensors. sensor provides informationcorresponding system. fault node defines five possible faults: normal, cloggedfuel-injector, dead-battery, short-circuit, broken-fuel-pump.denote fault variable F , sensor variables E, want buildsystem compute probability Pr (f; e); fault f evidence e.probabilities represent unnormalized probability distribution fault variablegiven sensor readings. Q-DAG framework, realizing diagnostic system involves threesteps: Q-DAG generation, reduction, evaluation. first two steps accomplishedoff-line, final step performed on-line. discuss one stepsdetail.5.1 Q-DAG Generationfirst step generate Q-DAG. accomplished applying Q-DAGclustering algorithm fault query variable sensors evidence vari169fiDarwiche & ProvanP(F=normal,e)P(F=normal).90P(F=pump).05fuel(normal)P(F=pump,e)fuelsubtree(pump)battery(normal)battery(pump)alternator(normal)oilalternator(pump)(normal)oil(pump)structure-sharingFigure 15: partial Q-DAG car example, displaying two five query nodes,broken fuel pump normal. shaded regions portions Q-DAGshared multiple query nodes; values nodes relevantvalue one query node.ables. resulting Q-DAG five query nodes, Qnode(F = normal ; e), Qnode(F =clogged fuel injector ; e), Qnode(F = dead battery ; e), Qnode(F = short circuit ; e),Qnode(F = broken fuel pump; e). node evaluates probability corresponding fault instantiation evidence. probabilities constitute differentialdiagnosis tells us fault probable given certain sensor values.Figure 15 shows stylized description Q-DAG restricted two five querynodes, corresponding Pr (F = broken fuel pump ; e) Pr (F = normal ; e). Q-DAGstructure symmetric fault value sensor.Given Q-DAG symmetric possible faults, clarity expositionlook subset needed evaluate node Pr (F = broken fuel pump ; e). Figure 16shows stylized version Q-DAG produced node. Following observations Q-DAG. First, evidence-specific node every instantiationsensor variables, corresponding forms sensor measurements possible. Second,roots Q-DAG probabilities. Third, one five parents query nodePr(F = broken fuel pump ; e) prior F = broken fuel pump , fourcontributions four sensors. example, Figure 16 highlights (in dots)part Q-DAG computing contribution battery sensor.5.2 Q-DAG Reductiongenerating Q-DAG, one proceeds reducing using graph rewrite rules. Figure 16shows example reduction Q-DAG restricted one query nodesimplicity. give idea kind reduction applied, considerpartial Q-DAG enclosed dots figure. Figure 17 compares reduced Q-DAGunreduced one generated. Given goal generating Q-DAGs(a) evaluated eciently possible (b) require minimal space store,170fiA Practical Paradigm Implementing Belief-Network InferenceKEYF-S fuel-sensorB-S battery-sensorA-S alternator-sensorO-S oil-sensorP(F=pump,e)*+P(F=pump).05+****full)+****.36 ESN(B-S, .64 ESN(A-S, .45 ESN(A-S, .55 ESN(O-S, .27 ESN(O-S,.4 ESN(F-S, .6 ESN(B-S,ESN(F-S,empty)+dead)charged)not-OK)OK)low).73normal)Figure 16: partial Q-DAG car example.+**(a) Reduced Q-DAGESN(B-S,.36 ESN(B-S, .64dead)charged)+(b) Original Q-DAG++*ESN(B-S,ESN(B-S,*charged)dead)P(B-S=charged| P(B=charged|F=pump,B=charged) F=pump).8**.6ESN(B-S,*charged)P(B-S=dead|P(B-S=charged|P(B=charged|F=pump,B=dead)F=pump,B=charged) F=pump).2.6.4**P(B=dead|F=pump).4ESN(B-S,dead)P(B-S=dead|F=pump,B=dead).6*P(B=dead|F=pump).4Figure 17: Reduced unreduced Q-DAGs car diagnosis example.important see, even simple example, Q-DAG reduction make big differencesize.171fiDarwiche & Provan5.3 Q-DAG Evaluationreduced Q-DAG, use compute answers diagnostic queries.section presents examples evaluation respect generated Q-DAG.Suppose obtain readings dead, normal, ok full battery, oil,alternator fuel sensors, respectively. let us compute probability distributionfault variable. obtained evidence formalized follows:- E (battery sensor ) = dead ,- E (oil sensor ) = normal ,- E (alternator sensor ) = ok ,- E (fuel sensor ) = full .Evidence-specific nodes evaluated according Definition 3. example,[n(battery sensor ; charged)] = 0;[n(battery sensor ; dead )] = 1:evaluation evidence-specific nodes shown pictorially Figure 18(a). Definition 3used evaluate remaining nodes: values node's parentsknown, value node determined. Figure 18(b) depicts resultsevaluating nodes. result interest probability 0.00434 assignedquery node Pr (fault = broken fuel pump ; e).Suppose evidence changed value fuel sensor empty insteadfull. update probability assigned node Pr (fault = broken fuel pump ; e), bruteforce method re-evaluate whole Q-DAG. However, forward propagation schemeused implement node evaluator, four nodes need re-evaluatedFigure 18(b) (those enclosed circles) instead thirteen (the total number nodes).stress point refined updating scheme, easy implementframework, much harder achieve one attempts embed standard beliefnetwork algorithms based message passing.6. Concluding Remarksintroduced new paradigm implementing belief-network inference oriented towards real-world, on-line applications. proposed framework utilizes knowledgequery evidence variables application compile belief network arithmetic expression called Query DAG (Q-DAG). node Q-DAG represents numericoperation, number, symbol depends available evidence. leaf nodeQ-DAG represents answer network query, is, probability eventinterest. Inference Q-DAGs linear size amounts standard evaluationarithmetic expressions represent.important point stress work reported proposingnew algorithm belief-network inference. proposing paradigm172fiA Practical Paradigm Implementing Belief-Network InferencePr(F=pump,e)(a) Evaluating ESNs*+.05Pr(F=pump)+*0*1.4ESN(F-S,empty)+**1.6*.36 0ESN(B-S,dead)ESN(F-S,full)+.64ESN(B-S,charged)0**.45 1ESN(A-S,not-OK).55ESN(A-S,OK)*.270ESN(O-S,low)1ESN(O-S,normal).73ESN values.0043362Pr(F=pump,e)(b) Propagating probabilities*0 *0ESN(F-S,empty)+ .36+ .6.05Pr(F=pump)* .36.6 *.41ESN(F-S,full).61ESN(B-S,dead)+ .550*.36 0ESN(B-S,charged)*0.640ESN(A-S,not-OK)+ .73.55*.45 1ESN(A-S,OK)* 0.550ESN(O-S,low).73 *.271ESN(O-S,normal).73ESN valuesFigure 18: Evaluating Q-DAG car diagnosis example given evidence sensors.bar (a) indicates instantiation ESNs. shaded numbers(b) indicate probability values computed node evaluator.circled operations left-hand-side (b) ones needupdated evidence fuel-system sensor altered, denoted circledESNs.173fiDarwiche & Provanimplementing belief-network inference orthogonal standard inference algorithmsengineered meet demands real-world, on-line applications. classapplications typically demanding following reasons:1. typically requires short response time, i.e., milliseconds.2. requires software written specialized languages, ADA, C++,assembly pass certification procedures.3. imposes severe restrictions available software hardware resources orderkeep cost \unit" (such electromechanical device) low possible.address real-world constraints, proposing one compile belief networkQ-DAG shown Figure 3 use Q-DAG evaluator on-line reasoning.brings required memory needed storing Q-DAG evaluator.also brings required software needed implementing Q-DAG evaluator,simple seen earlier.proposed approach still requires belief-network algorithm generate Q-DAG,makes eciency algorithm less critical factor.11 example,show standard optimizations belief-network inference, pruningcaching, become less critical Q-DAG framework since optimizations tendsubsumed simple Q-DAG reduction techniques, numeric reduction.work reported paper extended least two ways. First, QDAG reduction techniques could explored, oriented towards reducing evaluationtime Q-DAGs, others towards minimizing memory needed store them. Second,shown optimization techniques dramatically improve belief-networkalgorithms may become irrelevant size Q-DAGs Q-DAG reduction employed.investigation needed prove formal results guarantees effectivenessQ-DAG reduction.close section noting framework proposed also applicableorder-of-magnitude (OMP) belief networks, multiplication addition get replacedaddition minimization, respectively (Goldszmidt, 1992; Darwiche & Goldszmidt,1994). OMP Q-DAG evaluator, however, much ecient probabilisticcounterpart since one may evaluate minimization node without evaluateparents many cases. make considerable difference performance Q-DAGevaluator.Acknowledgementswork paper carried first author Rockwell ScienceCenter. Special thanks Jack Breese, Bruce D'Ambrosio anonymous reviewersuseful comments earlier drafts paper.11. shown clustering conditioning algorithms used Q-DAG generation,algorithms SPI (Li & D'Ambrosio, 1994; Shachter et al., 1990) used well.174fiA Practical Paradigm Implementing Belief-Network InferenceAppendix A. Proof Theorem 1Without loss generality, assume proof variables declared evidencevariables. prove soundness theorem, need show Q-DAG potential evaluate corresponding probabilistic potential possible evidence.Formally, cluster variables X , matrices assigned ,need show( n(Pr X )n(X )) = Pr X X(1)XXgiven evidence E . establish this, guaranteed Qnode(X )(x)evaluate probability Pr (x; e) applicationQ-DAG algorithm isomorphic application + probabilistic algorithm, respectively.prove Equation 1, extend Q-DAG node evaluator mappingsstandard way. is, f mapping instantiations Q-DAG nodes, (f )defined follows:(f )(x) =def (f (x)):is, simply apply Q-DAG node evaluator range mapping f .Note (fg ) equal (f )ME (g ). Therefore,( n(Pr X )n(X ))XY=(n(Pr X ))ME (n(X ))X=Pr X (n(X )) definition n(Pr X ):XNote also definition n(X ), n(X )(x) equals n(X; x). Therefore,(n(X ))(x) = (n(X )(x))=( E (n(X; x))1; E (X ) = x E (X ) ==0; otherwise= X (x):Therefore,( n(Pr X )n(X )) = Pr X X :XXReferencesDarwiche, A., & Goldszmidt, M. (1994). relation kappa calculus probabilistic reasoning. Proceedings Tenth Conference Uncertainty ArtificialIntelligence (UAI), pp. 145{153.Darwiche, A., & Provan, G. (1995). Query DAGs: practical paradigm implementingon-line causal-network inference. Tech. rep. 95-86, Rockwell Science Center, ThousandOaks, CA.175fiDarwiche & ProvanGoldszmidt, M. (1992). Qualitative probabilities: normative framework commonsensereasoning. Tech. rep. R-190, University California Los Angeles, Ph.D. thesis.Jensen, F. V., Lauritzen, S., & Olesen, K. (1990). Bayesian updating recursive graphicalmodels local computation. Computational Statistics Quarterly, 4, 269{282.Li, Z., & D'Ambrosio, B. (1994). Ecient Inference Bayes Networks CombinatorialOptimization Problem. International Journal Approximate Reasoning, 11, 55{81.Pearl, J. (1988). Probabilistic Reasoning Intelligent Systems: Networks Plausible Inference. Morgan Kaufmann Publishers, Inc., San Mateo, California.Peot, M. A., & Shachter, R. D. (1991). Fusion propagation multiple observationsbelief networks. Artificial Intelligence, 48 (3), 299{318.Shachter, R., Andersen, S., & Szolovits, P. (1994). Global Conditioning ProbabilisticInference Belief Networks. Proc. Tenth Conference Uncertainty AI, pp.514{522 Seattle WA.Shachter, R., D'Ambrosio, B., & del Favero, B. (1990). Symbolic Probabilistic InferenceBelief Networks. Proc. Conf. Uncertainty AI, pp. 126{131.Shenoy, P. P., & Shafer, G. (1986). Propagating belief functions local computations.IEEE Expert, 1 (3), 43{52.176fiJournal Artificial Intelligence Research 6 (1997) 211-221Submitted 12/96; published 6/97Research NoteComplete Classification Tractability RCC-5Peter JonssonThomas DrakengrenDepartment Computer Information Science, Linkoping UniversityS-581 83 Linkoping, Swedenpetej@ida.liu.sethodr@ida.liu.seAbstractinvestigate computational properties spatial algebra RCC-5 restrictedversion RCC framework spatial reasoning. satisfiability problem RCC-5 knownNP-complete much known approximately four billion subclasses.provide complete classification satisfiability subclasses polynomial NPcomplete respectively. process, identify maximal tractable subalgebras fourtotal.1. IntroductionQualitative spatial reasoning received constantly increasing amount interest literature.main reason is, probably, spatial reasoning proved applicable realworld problems in, example, geographical database systems (Egenhofer, 1991; Grigni, Papadias,& Papadimitriou, 1995) molecular biology (Cui, 1994). applications, sizeproblem instances huge, complexity problems algorithms highly relevantarea study. However, questions computational complexity received much attentionliterature; two notable exceptions results reported Nebel (1995) RenzNebel (1997). article take small step towards better understanding complexityissues qualitative spatial reasoning.well-known framework qualitative spatial reasoning so-called RCC approach (Randell& Cohn, 1989; Randell, Cui, & Cohn, 1992). approach based modelling qualitative spatialrelations regions using first-order logic. special interest, complexity-theoreticstandpoint, two subclasses RCC-5 RCC-8. well-known RCC-5RCC-8 quite weak expressive power. Although used describe spatial situations,general perhaps better described topological algebras. However,denote algebras spatial algebras order avoid terminological confusion; termtopological algebra well-established completely different meaning mathematics (Mallios,1986).Bennett (1994) shown suciency using propositional logics reasoning RCC5 RCC-8. Hence, reasoning becomes ecient compared reasoning fullfirst-order logic. Bennett's approach uses classical propositional logic RCC-5 intuitionisticpropositional logic RCC-8. Unfortunately, logics known computationally hard.satisfiability problem classical propositional logic intuitionistic propositional logic NPcomplete (Cook, 1971) Pspace-complete (Statman, 1979) respectively. However, complexityunderlying logic carry cases; Renz Nebel (1997) shownsatisfiability problem RCC-5 RCC-8 NP-complete. full proofs found(Renz, 1996).findings motivate search tractable subclasses RCC-5 RCC-8. Nebel (1995)showed reasoning basic relations RCC-8 polynomial-time problem. RenzNebel (1997) improved result substantially showing following results:c 1997 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.fiJonsson & Drakengrenexists large, maximal subclass RCC-8, denoted Hb8, contains basic relationspolynomial. Hb8 contains 148 elements 256 (58%).exists large, maximal subclass RCC-5, denoted Hb5, contains basic relationspolynomial. Hb5 contains 28 elements 32 (87%). Furthermore, unique,maximal subclass RCC-5 containing basic relations.concentrate RCC-5 article. main result complete classificationsubclasses RCC-5 respect tractability. classification makes possible determinewhether given subclass tractable simple test carried handautomatically. thus gained clear picture tractability borderline RCC-5.less necessary showing results kind, main proof relies case analysisperformed computer. number cases considered roughly 4 104 . analysis cannot,course, reproduced research paper verified manually. Hence, include descriptionprograms used. programs also available on-line appendix article.structure article follows: Section 2 defines RCC-5 auxiliary concepts.Section 3 contains tractability proofs three subclasses RCC-5. Section 4 showsubclasses together Hb5 maximal tractable subclasses RCC-5. articleconcludes brief discussion results.2. RCC-5 Algebrafollow Bennett (1994) definition RCC-5. RCC-5 based notions regionsbinary relations them. region p variable interpreted non-empty subsetsfixed set. noted require sets open sets topologicalspace. limitation since impossible distinguish interior points boundary pointsRCC-5. Thus take set X use discrete topology = hX ; 2X i, everysubset X open set .assume fixed universe variable names regions. Then, R-interpretationfunction maps region variables non-empty subsets set.Given two interpreted regions, relation described exactly one elementsset B five basic RCC-5 relations. definition relations found Table 1.Figure 1 shows 2-dimensional examples relations RCC-5. formula form XBYX regions B 2 B, said satisfied R-interpretation iff interpretationregions satisfies relations specified Table 1.express indefinite information, unions basic relations used, written sets basicrelations, leading 25 binary RCC-5 relations. Naturally, set basic relations interpreteddisjunction basic relations. set RCC-5 relations 2B denoted R5. Relationsspecial interest null relation ? (also denoted ?) universal relation B (alsodenoted >).formula form X fB1 ; : : :; B gY called RCC-5 formula. formula satisfiedR-interpretation = iff XB satisfied = i, 1 n. finite set RCC-5formulae said R-satisfiable iff exists R-interpretation = satisfies every formula. satisfying R-interpretation called R-model . Given R-interpretation =variable v, write =(v) denote value v interpretation =.reasoning problem study following:n: finite set RCC-5 formulae.: exist R-model ?InstanceQuestion212fiA Complete Classification Tractability RCC-5X fDRgYX fPOgYX fPPgYX fPPIgYX fEQgYiff X \ = ?iff 9a; b; c : 2 X; 62 Y; b 2 X; b 2 Y; c 62 X; c 2iff Xiff Xiff X =Table 1: five basic relations RCC-5.XX(X; )DR(X; )POXPP(X; )XPPI(X; )X(X; )EQFigure 1: Pictorial example relations RCC-5.denote problem RSAT. following, often consider restricted versions RSATrelations used formulae subset R5. case sayset formulae use parameter problem description denote subclassconsideration, e.g., RSAT(S ). Note RSAT problem instance representedlabelled directed graph, nodes region variables arcs labelled relationsvariables. Given instance RSAT, say graph graph representation.continue defining algebra RCC-5 relations.Definition 2.1 Let B = fDR; PO; PP; PPI; EQg. RCC-5 algebra consists set R5 = 2Boperations unary converse (denoted ), binary intersection (denoted \) binarycomposition (denoted ). defined follows:8X; :XR iff RX8X; : X (R \ )Y iff XRY ^ XSY8X; : X (R )Y iff 9Z : (XRZ ^ ZSY )subset R5 , said subalgebra RCC-5iff closed converse, intersectioncomposition. easily verified R = fB B 0 jB 2 R; B 0 2 g, i.e., composition^^union component-wise composition basic relations.Next, introduce closure operation. closure operation transforms given subclassR5 one polynomially equivalent original subclass respect satisfiability.operation similar closure operation RCC-5 introduced Renz (1996)pose restrictions given subclass. (Renz's operation requires fEQg membersubclass closed.)Definition 2.2 Let R5. denote closure , defined least subalgebracontaining closed converse, intersection composition.Observe subset R5 subalgebra iff = .next lemma given without proof. proof analogous result Allen's algebrafound Nebel Burckert (1995).213fiJonsson & DrakengrenLemma 2.3 Let R5. RSAT(S ) polynomially transformed RSAT(S ) viceversa.Corollary 2.4 Let R5. RSAT(S ) polynomial iff RSAT(S ) polynomial. RSAT(S )NP-complete iff RSAT(S ) NP-complete.3. Tractable Subclasses RCC-5begin section defining four tractable subalgebras RCC-5, found Table 2.Later on, show algebras maximal tractable subalgebras RCC-5.28tractability first algebra, R285 , established Renz Nebel (1997). name R5ects fact algebra contains 28 elements.Theorem 3.1 RSAT(R285 ) polynomial.tractability second algebra, R205 , settled quite easily. algorithm foundFigure 2.20Lemma 3.2 Let instance RSAT(R205 ). algorithm accepts input iffR-model.Proof: if: show contrapositive, i.e., A20 rejects R-model. Clearly,satisfiability preserved transformations made lines 7-10. Note XRX 2EQ 2 R satisfiable. Thus satisfiable algorithm rejects line 5. Similarly,satisfiable algorithm rejects line 6.only-if: Consider set completion line 11. denote set 0 . Obviously, 0satisfiable initial satisfiable. Also observe line 7 ensures 0 relatevariables EQ. Furthermore, line 8 guarantees one relation relatestwo variables.Now, construct R-model 0 follows: Let V set variables 0 . Letassign non-empty sets pairwise disjoint members V . Let U = 2 (X ).Introduce set values U 0 = fff j X; 2 V g satisfying following:XVX;Y1. ff = ff iff X = Z = W ;2. arbitrary X; 2 V , ff 62 U .X;YZ;WX;Yrelation type X fPOgY X fPO; EQgY , extend sets (X ) (Y )element ff .Clearly, two sets X; disjoint (and thus related DR) unless X fPOgYX fPO; EQgY . cases, X must disjoint. fact, introducingff , forced X fPOgY hold satisfies formulae type X fPOgY wellformulae type X fPO; EQgY . Hence, R-model 0 implies R-satisfiability.2X;YX;YTheorem 3.3 RSAT(R205 ) polynomial.Proof: Algorithm A20 correctly solves RSAT(R205 ) problem previous lemma. Further-more, number iterations bounded number variables numberformulae given instance tests easily performed polynomial time.2Next show tractability RSAT(R175 ).214fiA Complete Classification Tractability RCC-520 R17 R14R285 R555?fDRgfPOgfDR; POgfPPgfDR; PPgfPO; PPgfDR; PO; PPgfPPIgfDR; PPIgfPO; PPIgfDR; PO; PPIgfPP; PPIgfDR; PP; PPIgfPO; PP; PPIgfDR; PO; PP; PPIgfEQgfDR; EQgfPO; EQgfDR; PO; EQgfPP; EQgfDR; PP; EQgfPO; PP; EQgfDR; PO; PP; EQgfPPI; EQgfDR; PPI; EQgfPO; PPI; EQgfDR; PO; PPI; EQgfPP; PPI; EQgfDR; PP; PPI; EQgfPO; PP; PPI; EQg>Table 2: maximal tractable subalgebras RCC-5.Theorem 3.4 RSAT(R175 ) polynomial.Proof: Consider algorithm A17 Figure 2. exist X; X ?Y 2satisfiable. Otherwise, let variables value. Since EQ memberevery relation occurs , interpretation R-model .2continue proving RSAT(R145 ) tractable problem. Let9R5 = ffPP; EQgg [ fR [ fPP; PPIg j R 2 R5g:9Using machine-assisted proof, shown R145 = R5 sucient prove9tractability RSAT(R5) Corollary 2.4. program used showing availableon-line appendix article.on, let arbitrary instance RSAT(R95) G = hV; E graph representation. following proofs similar spirit proofs appearing Drakengren215fiJonsson & Drakengren123456789101112algorithm A20Input: instance RSAT(R205 ).repeat09X; R : XRX 2 EQ 62 R reject9X; : X ?Y 2 reject9X; : X =6 X fEQgY 2 substitute X9X; Y; R; : XRY 2 XSY 2( , fXRY; XSY g) [ fX (R \ )Y g9X; R : XRX 2 EQ 2 R , fXRX g= 0accept1234algorithm A17Input: instance RSAT(R175 ).9X; X ?Y 2 rejectelse accept1234567algorithm A9Input: instance RSAT(R95) graph representation G.Let G0 graph obtained G removing arcs labelled fPP; EQg.Find strongly connected components C G0every arc e G whose relation contain EQe connects two nodes C rejectaccept179Figure 2: Algorithms RSAT(R205 ), RSAT(R5 ) RSAT(R5).Jonsson (1996). algorithm reminiscent algorithm van Beek (1992) decidingsatisfiability point algebra.Definition 3.5 RCC-5 relation R said acyclic relation iff cycle G Revery arc never satisfiable.relation PP example acyclic relation fPP; EQg acyclic. continueshowing properties acyclic relations.Proposition 3.6 Let R acyclic relation. every relation R0 R acyclic.Proof: Since taking subsets R constrains satisfiability further, result follows.2Proposition 3.7 Let R acyclic relation, choose fR0 j R0 Rg. Then,cycle G every arc labelled relation unsatisfiable.Proof: argument previous proposition.2following definition needed following proofs.Definition 3.8 Let instance R-satisfiability problem, model , r 2 R5relation two region variables X . r said satisfied r0relation r0 r, Xr0 satisfied .216fiA Complete Classification Tractability RCC-5definition may seem bit cumbersome essence clear. example, let Xregion variables related X fPO; PPgY , model X interpreted f1; 2gf1; 2; 3g. , fPO; PPg satisfied fPPg, also fPO; PPg.Lemma 3.9 Let R acyclic relation, A; A0 sets fR0 j R0 Rg A0fa [ fEQg j 2 Ag. Then, every cycle C labelled relations [ A0 satisfiable iff containsrelations A0 . Furthermore, relations cycle satisfied EQ.Proof: only-if: Suppose cycle C satisfiable contains relationA. Apply induction number n arcs cycle. n = 1, get contradictionProposition 3.7. So, suppose induction C contains n + 1 arcs. Let R-modelrelations C . cannot case every relation C satisfiedrelation A, Proposition 3.7. Thus, relation R0 C satisfied EQ.collapse two variables connected R0 one variable, cycle n nodescontaining relation A. contradicts induction hypothesis.if: Suppose cycle C contains relations A0 . C satisfied choosing EQevery arc. Notice only-if part implies C must satisfied choosing EQ every arc.2Hence, variables forced equal.studied acyclic relations, turn attention DAG-satisfying relations.formal definition follows.Definition 3.10 basic relation B said DAG-satisfying iff DAG (directed acyclicgraph) labelled relations containing B satisfiable, i.e., corresponding RSAT problemmodel.typical example DAG-satisfying relation EQ. Given DAG labelled relations containing EQ, always satisfy relations assigning non-empty set variables.show PP DAG-satisfying relation.Definition 3.11 Let G arbitrary DAG. node v G said terminal node iffarcs start v.Lemma 3.12 basic relation PP DAG-satisfying.Proof: Let G DAG labelled relations containing PP. show G satisfiedR-model . Induction n number nodes G. case n = 1trivial. Suppose G n +1 nodes remove terminal node g. induction, remaininggraph G0 = hV 0 ; E 0i satisfiable model 0.SWe shall construct model G,agrees 0 every variable G0. Let = fM 0(v) j v 2 V 0 g let ff element. Let (g) = [ fffg. Obviously, model G.2state simple result Drakengren Jonsson (1996).Lemma 3.13 Let G irre exive1 acyclic subgraph D. arcs Greoriented resulting graph acyclic.specializing result, get next lemma.Lemma 3.14 Let G irre exive acyclic subgraph let arcs labelledrelations containing PP, arcs labelled relations containing PP PPI.G R-satisfiable.1. graph irre exive iff arcs node v node v.217fiJonsson & DrakengrenProof: Reorient arcs G resulting graph acyclic. always possibleprevious lemma. Furthermore, whenever arc reoriented, also invert relationarc, G0 satisfiable iff G is. construction, arcs containing PP PPIreoriented, every arc DAG G0 contains PP and, thus, since PP DAG-satisfyingLemma 3.12, G0 satisfiable. Consequently, G also satisfiable.2Lemma 3.15 Algorithm A9 correctly solves RSAT(R95).Proof: Assume algorithm finds strongly connected component G0 (which containsrelation fPP; EQg), containing two nodes G connected arc e labelledrelation R0 contain EQ. exists cycle C relationevery arc contains EQ, e connects two nodes C e part cycle.Lemma 3.9, C satisfied choosing relation EQ every arc C , since R0admit EQ, C unsatisfiable.Otherwise, every strongly connected component collapsed single node, removingarcs start end collapsed node. transformation retains satisfiability usingargument above. collapsing, subgraph obtained considering arcs labelledfPP; EQg acyclic. Since remaining arcs labelled relations containing PPPPI, graph R-satisfiable Lemma 3.14. (Note graph irre exive since everynode contained strongly connected component.)2Lemma 3.16 Given graph G = hV; Ei, algorithm A9 runs O(jV j + jEj) time.Proof: Strongly connected components found O(jV j + jEj) time (Baase, 1988)remaining test also made O(jV j + jE j) time.2Theorem 3.17 RSAT(R145 ) solved polynomial time.149Proof: RSAT(R95) polynomial previous two lemmata. Since R145 = R5, RSAT(R5 )solved polynomial time Corollary 2.4.24. Classification RCC-5give classification RCC-5 need two NP-completeness results.Theorem 4.1 RSAT(S ) NP-complete1. (Renz & Nebel, 1997) C1 = ffPOg; fPP; PPIgg ,2. C2 = ffDR; POg; fPP; PPIgg .Proof: proof C2 polynomial-time reduction RSAT(C1). Let arbitraryinstance RSAT(C1). Construct following set:0 = fX fPP; PPIgY j X fPP; PPIgY 2 g [ fX fDR; POgY j X fPOgY 2 g:Clearly, 0 obtained polynomial time 0 instance RSAT(C2). showsatisfiable iff 0 satisfiable.only-if: Assume exists R-model . hard see also R-model0 since X fPOgY X fDR; POgY . Thus 0 R-satisfiable R-satisfiable.if: Assume existence R-model 0 assigns subsets set U region variables0 . Let ff element ff 62 U . construct new interpretation follows:(x) = 0 (x) [ fffg every variable x 0 . easily seen following holds :218fiA Complete Classification Tractability RCC-51.2.3.4.xfDRgy 0 xfPOgy .xfPOgy 0 xfPOgy .xfPPgy 0 xfPPgy .xfPPIgy 0 xfPPIgy .easy see xfPP; PPIgy 0 xfPP; PPIgy . Similarly, xfDR; POgy0 xfPOgy . follows model R-satisfiable 0 R-satisfiable.2main theorem stated proved.Theorem 4.2 R5, RSAT(S ) polynomial iff subset member R =20 17 14fR285 ; R5 ; R5 ; R5 g, NP-complete otherwise.Proof: if: R 2 R , RSAT(R) polynomial shown previous section.only-if: Choose R5 subset algebra R . subalgebraR 2 R , choose relation x x 2 x 62 R. always done since 6 R. LetX set relations note X subset algebra R . set Rcontains four algebras construction X , jX j 4. Observe RSAT(S ) NP-completeRSAT(X ) NP-complete.show RSAT(S ) NP-complete, machine-assisted case analysis followingPPPPPPform performed:4X321. Generate subsets R5 size 4.= 41449 subsets.=02. Let set. Test: subset subalgebra R C2 f1; 2g.Ptest succeeds . Hence, RSAT(S ) NP-complete Corollary 2.4.2program used showing previous theorem appears on-line appendix article.5. Discussionmain problem reporting tractability results restricted classes problems dicultyisolating interesting relevant subclasses. systematic approach building complete classifications way partially overcoming problem. problem class considerationregarded relevant, tractable subclasses regarded relevant computationalproblem interest. especially true spatial reasoning size problem instances extremely large; one good example spatial reasoning connection HumanGenome project (Cui, 1994).Another advantage complete classifications satisfactory scientificpoint view; gain clear picture borderline tractability intractabilityintrinsic scientific value. common critique complete classifications tend generatecertain classes totally useless. instance, subalgebra R175 certainly use.must made clear critique unjustified since researcher makes completeclassification deliberately invent useless classes. Instead, useless classes appearcomplete classification, unavoidable parts classification.219fiJonsson & Drakengrenwork reported article extended many different ways. One obvious extensionstudy computational problems RSAT problem. Renz (1996) studied twoproblems, RMIN RENT, certain subclasses RCC-5 RCC-8. RMIN problemdecide set spatial formulae minimal, i.e., whether basic relations every formulasatisfied not. RENT problem decide whether formula XRY entailedset spatial formulae. Grigni et al. (1995) study stronger form satisfiability referrealizability: finite set RCC-5 formulae said realizable iff exist regionsplane bounded Jordan curves satisfy relations . Grigni et al. (1995)shown realizability problem much harder satisfiability problem. instance,deciding realizability formulae constructed two relations DR PO NP-completesatisfiability problem polynomial. Certainly, studies realizability problem wouldworthwhile.Another obvious research direction completely classify spatial algebras, RCC8. RCC-8 contains 2256 1077 relations question whether feasible remainsanswered.6. Conclusionsstudied computational properties RCC-5. 232 possible subclasses classified respect whether corresponding satisfiability problem tractable not.classification reveals four maximal tractable subclasses algebra.ReferencesBaase, S. (1988). Computer Algorithms: Introduction Analysis (2nd edition). Addison Wesley,Reading, MA.Bennett, B. (1994). Spatial reasoning propositional logics. Doyle, J., Sandewall, E., &Torasso, P. (Eds.), Proceedings 4th International Conference Principles KnowledgeRepresentation Reasoning (KR-94), pp. 165{176 Bonn, Germany. Morgan Kaufmann.Cook, S. A. (1971). complexity theorem-proving procedures. Proceedings 3rd ACMSymposium Theory Computing, pp. 151{158.Cui, Z. (1994). Using interval logic order assembly. Proceedings Second InternationalConference Intelligent Systems Molecular Biology, pp. 103{111. AAAI Press.Drakengren, T., & Jonsson, P. (1996). Maximal tractable subclasses Allen's interval algebra: Preliminary report. Proceedings 13th (US) National Conference Artificial Intelligence(AAAI-96), pp. 389{394 Portland, OR, USA. American Association Artificial Intelligence.Egenhofer, M. J. (1991). Reasoning binary topological relations. Gunther, O., & Schek,H. J. (Eds.), Advances Spatial Databases, pp. 143{160. Springer-Verlag.Grigni, M., Papadias, D., & Papadimitriou, C. (1995). Topological inference. Mellish, C. (Ed.),Proceedings 14th International Joint Conference Artificial Intelligence (IJCAI-95),pp. 901{906 Montreal, PQ, Canada. Morgan Kaufmann.Mallios, A. (1986). Topological Algebras. Selected Topics. North-Holland, Amsterdam.Nebel, B. (1995). Computational properties qualitative spatial reasoning: First results.Wachsmuth, I., Rollinger, C.-R., & Brauer, W. (Eds.), KI-95: Advances Artificial Intelligence, pp. 233{244 Bielefeld, Germany. Springer-Verlag.220fiA Complete Classification Tractability RCC-5Nebel, B., & Burckert, H.-J. (1995). Reasoning temporal relations: maximal tractablesubclass Allen's interval algebra. Journal ACM, 42 (1), 43{66.Randell, D. A., & Cohn, A. G. (1989). Modelling topological metrical properties physicalprocesses. Brachman, R. J., Levesque, H. J., & Reiter, R. (Eds.), Proceedings 1stInternational Conference Principles Knowledge Representation Reasoning (KR-89),pp. 55{66 Toronto, ON, Canada. Morgan Kaufmann.Randell, D. A., Cui, Z., & Cohn, A. G. (1992). spatial logic based regions connection.Swartout, B., & Nebel, B. (Eds.), Proceedings 3rd International Conference PrinciplesKnowledge Representation Reasoning (KR-92), pp. 165{176 Cambridge, MA, USA.Morgan Kaufmann.Renz, J. (1996). Qualitatives raumliches Schlieen: Berechnungseigenschaften und eziente Algorithmen. Master thesis report, Fakultat fur Informatik, Universitat Ulm. Availablehttp://www.informatik.uni-freiburg.de/sppraum.Renz, J., & Nebel, B. (1997). complexity qualitative spatial reasoning: maximaltractable fragment region connected calculus. Proceedings 15th InternationalJoint Conference Artificial Intelligence (IJCAI-97) Nagoya, Japan. Morgan Kaufmann.appear.Statman, R. (1979). Intuitionistic logic polynomial-space complete. Theoretical Computer Science,9 (1), 67{72.van Beek, P. (1992). Reasoning qualitative temporal information. Artificial Intelligence, 58,297{326.221fiJournal Artificial Intelligence Research 6 (1997) 1-34Submitted 5/96; published 1/97Improved Heterogeneous Distance FunctionsD. Randall WilsonTony R. MartinezComputer Science DepartmentBrigham Young UniversityProvo, UT 84602, USARANDY @AXON.CS.BYU.EDUMARTINEZ @CS.BYU.EDUAbstractInstance-based learning techniques typically handle continuous linear input values well,often handle nominal input attributes appropriately. Value Difference Metric(VDM) designed find reasonable distance values nominal attribute values,largely ignores continuous attributes, requiring discretization map continuous valuesnominal values. paper proposes three new heterogeneous distance functions, calledHeterogeneous Value Difference Metric (HVDM), Interpolated Value Difference Metric(IVDM), Windowed Value Difference Metric (WVDM). new distance functionsdesigned handle applications nominal attributes, continuous attributes, both.experiments 48 applications new distance metrics achieve higher classification accuracyaverage three previous distance functions datasets nominalcontinuous attributes.1. IntroductionInstance-Based Learning (IBL) (Aha, Kibler & Albert, 1991; Aha, 1992; Wilson & Martinez,1993; Wettschereck, Aha & Mohri, 1995; Domingos, 1995) paradigm learningalgorithms typically store n available training examples (instances)training set, T, learning. instance input vector x, output class c.generalization, systems use distance function determine close newinput vector stored instance, use nearest instance instances predictoutput class (i.e., classify y). instance-based learning algorithms referrednearest neighbor techniques (Cover & Hart, 1967; Hart, 1968; Dasarathy, 1991), memorybased reasoning methods (Stanfill & Waltz, 1986; Cost & Salzberg, 1993; Rachlin et al., 1994)overlap significantly instance-based paradigm well. algorithms muchsuccess wide variety applications (real-world classification tasks).Many neural network models also make use distance functions, including radial basisfunction networks (Broomhead & Lowe, 1988; Renals & Rohwer, 1989; Wasserman, 1993),counterpropagation networks (Hecht-Nielsen, 1987), ART (Carpenter & Grossberg, 1987), selforganizing maps (Kohonen, 1990) competitive learning (Rumelhart & McClelland, 1986).Distance functions also used many fields besides machine learning neural networks,including statistics (Atkeson, Moore & Schaal, 1996), pattern recognition (Diday, 1974;Michalski, Stepp & Diday, 1981), cognitive psychology (Tversky, 1977; Nosofsky, 1986).1997 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.fiWILSON & MARTINEZmany distance functions proposed decide instanceclosest given input vector (Michalski, Stepp & Diday, 1981; Diday, 1974). Manymetrics work well numerical attributes appropriately handle nominal (i.e.,discrete, perhaps unordered) attributes.Value Difference Metric (VDM) (Stanfill & Waltz, 1986) introduced defineappropriate distance function nominal (also called symbolic) attributes. Modified ValueDifference Metric (MVDM) uses different weighting scheme VDM usedPEBLS system (Cost & Salzberg, 1993; Rachlin et al., 1994). distance metrics work wellmany nominal domains, handle continuous attributes directly. Instead,rely upon discretization (Lebowitz, 1985; Schlimmer, 1987), degrade generalizationaccuracy (Ventura & Martinez, 1995).Many real-world applications nominal linear attributes, including,example, half datasets UCI Machine Learning Database Repository (Merz &Murphy, 1996). paper introduces three new distance functions appropriateprevious functions applications nominal continuous attributes.new distance functions incorporated many learning systems areasstudy, augmented weighting schemes (Wettschereck, Aha & Mohri, 1995;Atkeson, Moore & Schaal, 1996) enhancements system provides.choice distance function influences bias learning algorithm. bias rulemethod causes algorithm choose one generalized output another (Mitchell,1980). learning algorithm must bias order generalize, shownlearning algorithm generalize accurately summedpossible problems (Schaffer, 1994) (unless information problemtraining data available). follows distance function strictly betterterms generalization ability, considering possible problems equalprobability.However, higher probability one class problems occurring another,learning algorithms generalize accurately others (Wolpert, 1993).better summed problems, problemsperform well likely occur. sense, one algorithm distance functionimprovement another higher probability good generalizationanother, better matched kinds problems likely occur.Many learning algorithms use bias simplicity (Mitchell, 1980; Wolpert, 1993)generalize, bias appropriatemeaning leads good generalizationaccuracyfor wide variety real-world applications, though meaning simplicity variesdepending upon representational language learning algorithm. biases,decisions made basis additional domain knowledge particular problem (Mitchell,1980), also improve generalization.light, distance functions presented paper appropriateused comparison average yield improved generalization accuracycollection 48 applications. results theoretically limited set datasets,hope datasets representative problems interest (and occurfrequently) real world, distance functions presented usefulcases, especially involving continuous nominal input attributes.Section 2 provides background information distance functions used previously. Section 32fiIMPROVED HETEROGENEOUS DISTANCE FUNCTIONSintroduces distance function combines Euclidean distance VDM handlecontinuous nominal attributes. Sections 4 5 present two extensions ValueDifference Metric allow direct use continuous attributes. Section 4 introducesInterpolated Value Difference Metric (IVDM), uses interpolation probabilities avoidproblems related discretization. Section 5 presents Windowed Value Difference Metric(WVDM), uses detailed probability density function similar interpolationprocess.Section 6 presents empirical results comparing three commonly-used distance functionsthree new functions presented paper. results obtained usingdistance functions instance-based learning system 48 datasets. results indicatenew heterogeneous distance functions appropriate previously used functionsdatasets nominal linear attributes, achieve higher averagegeneralization accuracy datasets. Section 7 discusses related work, Section 8provides conclusions future research directions.2. Previous Distance Functionsmentioned introduction, many learning systems depend upon gooddistance function successful. variety distance functions available uses,including Minkowsky (Batchelor, 1978), Mahalanobis (Nadler & Smith, 1993), Camberra,Chebychev, Quadratic, Correlation, Chi-square distance metrics (Michalski, Stepp &Diday, 1981; Diday, 1974); Context-Similarity measure (Biberman, 1994); ContrastModel (Tversky, 1977); hyperrectangle distance functions (Salzberg, 1991; Domingos, 1995)others. Several functions defined Figure 1.Although many distance functions proposed, far commonlyused Euclidean Distance function, defined as:E(x, y) =(xa ya )2(1)a=1x two input vectors (one typically stored instance,input vector classified) number input variables (attributes)application. square root often computed practice, closest instance(s)still closest, regardless whether square root taken.alternative function, city-block Manhattan distance function, requires lesscomputation defined as:M(x, y) =xa ya(2)a=1Euclidean Manhattan distance functions equivalent Minkowskian rdistance function (Batchelor, 1978) r = 2 1, respectively.3fiWILSON & MARTINEZMinkowsky:Euclidean:rD(x, y) = xi yii=1Camberra:1rManhattan / city-block:2( xi yi )D(x, y) =i=1xD(x, y) =x+i=1Chebychev:D(x, y) = xi yii=1D(x, y) = max xi yii=1D(x, y) = (x y)T Q(x y) = (xi yi )q ji (x j j )Quadratic:Q problem-specific positivej=1 i=1definite weight matrixV covariance matrix 1..Am,Mahalanobis:Aj vector valuesD(x, y) = [det V]1/ (x y)T V 1 (x y)attribute j occuring training setinstances 1..n.Correlation:(xi xi )(yi yi )xi = yi average valuei=1D(x, y) =attributeoccuring training set.22(xi xi ) (yi yi )i=1i=11 xiChi-square: D(x, y) =sumi sizex sizei=1Kendalls Rank Correlation:sign(x)=-1, 0 1 x < 0,x = 0, x > 0, respectively.D(x, y) = 12sumi sum values attributeoccuring training set, sizexsum values vector x.i12sign(xi x j )sign(yi j )n(n 1) i=1 j=1Figure 1. Equations selected distance functions.(x vectors attribute values).2.1. NormalizationOne weakness basic Euclidean distance function one input attributesrelatively large range, overpower attributes. example, applicationtwo attributes, B, values 1 1000, B values1 10, Bs influence distance function usually overpoweredinfluence. Therefore, distances often normalized dividing distance attributerange (i.e., maximum-minimum) attribute, distance attributeapproximate range 0..1. order avoid outliers, also common dividestandard deviation instead range, trim range removing highest lowestpercent (e.g., 5%) data consideration defining range. also possiblemap value outside range minimum maximum value avoid normalizedvalues outside range 0..1. Domain knowledge often used decide methodappropriate.Related idea normalization using attribute weights weighting4fiIMPROVED HETEROGENEOUS DISTANCE FUNCTIONSschemes. Many learning systems use distance functions incorporate various weightingschemes distance calculations (Wettschereck, Aha & Mohri, 1995; Atkeson, Moore &Schaal, 1996). improvements presented paper independent schemes,various weighting schemes (as well enhancements instance pruningtechniques) used conjunction new distance functions presented here.2.2. Attribute TypesNone distance functions shown Figure 1, including Euclidean distance, appropriatelyhandle non-continuous input attributes.attribute linear nominal, linear attribute continuous discrete.continuous (or continuously-valued) attribute uses real values, mass planetvelocity object. linear discrete (or integer) attribute discrete setlinear values, number children.argued value stored computer discrete level. reasoncontinuous attributes treated differently many different valuesvalue may appear rarely (perhaps particular application). causesproblems algorithms VDM (described Section 2.4) depend testing twovalues equality, two continuous values rarely equal, though mayquite close other.nominal (or symbolic) attribute discrete attribute whose values necessarilylinear order. example, variable representing color might values red,green, blue, brown, black white, could represented integers 1 6,respectively. Using linear distance measurement (1) (2) values makes littlesense case.2.3. Heterogeneous Euclidean-Overlap Metric (HEOM)One way handle applications continuous nominal attributes useheterogeneous distance function uses different attribute distance functions differentkinds attributes. One approach used use overlap metric nominalattributes normalized Euclidean distance linear attributes.purposes comparison testing, define heterogeneous distance functionsimilar used IB1, IB2 IB3 (Aha, Kibler & Albert, 1991; Aha, 1992) wellused Giraud-Carrier & Martinez (1995). function defines distancetwo values x given attribute as:x unknown, else1,da (x, y) = overlap(x, y), nominal, elsern_ diff (x, y)(3)Unknown attribute values handled returning attribute distance 1 (i.e., maximaldistance) either attribute values unknown. function overlap rangenormalized difference rn_diff defined as:0, x =overlap(x, y) =1, otherwise5(4)fiWILSON & MARTINEZrn_ diff (x, y) =| x y|rangea(5)value rangea used normalize attributes, defined as:rangea= maxa- mina(6)max mina maximum minimum values, respectively, observedtraining set attribute a. means possible new input vector valueoutside range produce difference value greater one. However, casesrare, occur, large difference may acceptable anyway. normalizationserves scale attribute point differences almost always less one.definition da returns value (typically) range 0..1, whetherattribute nominal linear. overall distance two (possibly heterogeneous) inputvectors x given Heterogeneous Euclidean-Overlap Metric function HEOM(x,y):da (xa , ya )2HEOM(x, y) =(7)a=1distance function removes effects arbitrary ordering nominal values,overly simplistic approach handling nominal attributes fails make use additionalinformation provided nominal attribute values aid generalization.2.4. Value Difference Metric (VDM)Value Difference Metric (VDM) introduced Stanfill Waltz (1986) provideappropriate distance function nominal attributes. simplified version VDM (withoutweighting schemes) defines distance two values x attribute as:C Na,x,cNa,y,cvdma (x, y) =NNa,ya,xc=1qC= Pa,x,c Pa,y,cq(8)c=1Na,x number instances training set value x attribute a;Na,x,c number instances value x attribute output class c;C number output classes problem domain;q constant, usually 1 2;P a,x,c conditional probability output class c given attributevalue x, i.e., P(c | xa). seen (8), Pa,x,c defined as:Pa,x,c =Na,x,cNa,x(9)Na,x sum Na,x,c classes, i.e.,CNa,x = Na,x,cc=16(10)fiIMPROVED HETEROGENEOUS DISTANCE FUNCTIONSsum Pa,x,c C classes 1 fixed value x.Using distance measure vdma(x,y), two values considered closersimilar classifications (i.e., similar correlations output classes), regardlessorder values may given in. fact, linear discrete attributes valuesremapped randomly without changing resultant distance measurements.example, attribute color three values red, green blue, applicationidentify whether object apple, red green would considered closerred blue former two similar correlations output class apple.original VDM algorithm (Stanfill & Waltz, 1986) makes use feature weightsincluded equations, variants VDM (Cost & Salzberg, 1993;Rachlin et al., 1994; Domingos, 1995) used alternate weighting schemes. discussedearlier, new distance functions presented paper independent schemescases make use similar enhancements.One problem formulas presented definedone value appears new input vector never appeared training set.attribute never value x instance training set, Na,x,c c 0,N a,x (which sum Na,x,c classes) also 0. cases P a,x,c = 0/0,undefined. nominal attributes, way know probabilityvalue, since inherent ordering values. paper assignP a,x,c default value 0 cases (though also possible let Pa,x,c = 1/C, Cnumber output classes, since sum Pa,x,c c = 1..C always 1.0).distance function used directly continuous attributes, valuespotentially unique, case Na,x 1 every value x, Na,x,c 1 one value c0 others given value x. addition, new vectors likely uniquevalues, resulting division zero problem above. Even value 0 substituted0/0, resulting distance measurement nearly useless.Even values unique, often enough different values continuousattribute statistical sample unreliably small value, distance measurestill untrustworthy. problems, inappropriate use VDM directlycontinuous attributes.2.5. DiscretizationOne approach problem using VDM continuous attributes discretization(Lebowitz, 1985; Schlimmer, 1987; Ventura, 1995). models used VDMvariants (Cost & Salzberg, 1993; Rachlin et al., 1994; Mohri & Tanaka, 1994)discretized continuous attributes somewhat arbitrary number discrete ranges,treated values nominal (discrete unordered) values. method advantagegenerating large enough statistical sample nominal value P valuessignificance. However, discretization lose much important information availablecontinuous values. example, two values discretized range consideredequal even opposite ends range. effects reduce generalizationaccuracy (Ventura & Martinez, 1995).paper propose three new alternatives, presented following threesections. Section 3 presents heterogeneous distance function uses Euclidean distancelinear attributes VDM nominal attributes. method requires careful attention7fiWILSON & MARTINEZproblem normalization neither nominal linear attributes regularly givenmuch weight.Sections 4 5 present two distance functions, Interpolated Value DifferenceMetric (IVDM) Windowed Value Difference Metric (WVDM), use discretizationcollect statistics determine values Pa,x,c continuous values occurring trainingset instances, retain continuous values later use. generalization,value Pa,y,c continuous value interpolated two values P, namely,P a,x1,c Pa,x2,c, x 1 x2. IVDM WVDM essentially different techniquesnonparametric probability density estimation (Tapia & Thompson, 1978)determine values P class. generic version VDM algorithm, calleddiscretized value difference metric (DVDM) used comparisons two newalgorithms.3. Heterogeneous Value Difference Metric (HVDM)discussed previous section, Euclidean distance function inappropriatenominal attributes, VDM inappropriate continuous attributes, neither sufficientuse heterogeneous application, i.e., one nominal continuousattributes.section, define heterogeneous distance function HVDM returns distancetwo input vectors x y. defined follows:HVDM(x, y) =da2 (xa , ya )(11)a=1number attributes. function da(x,y) returns distance twovalues x attribute defined as:x unknown; otherwise...1,da (x, y) = normalized_ vdma (x, y), nominalnormalized_ diff (x, y), linear(12)function da(x,y) uses one two functions (defined Section 3.1), dependingwhether attribute nominal linear. Note practice square root (11)typically performed distance always positive, nearest neighbor(s) stillnearest whether distance squared. However, models (e.g.,distance-weighted k-nearest neighbor, Dudani, 1976) require square rootevaluated.Many applications contain unknown input values must handled appropriatelypractical system (Quinlan, 1989). function da(x,y) therefore returns distance 1 eitherx unknown, done Aha, Kibler & Albert (1991) Giraud-Carrier & Martinez(1995). complicated methods tried (Wilson & Martinez, 1993),little effect accuracy.function HVDM similar function HOEM given Section 2.3, except8fiIMPROVED HETEROGENEOUS DISTANCE FUNCTIONSuses VDM instead overlap metric nominal values also normalizes differently.also similar distance function used RISE 2.0 (Domingos, 1995),important differences noted Section 3.2.Section 3.1 presents three alternatives normalizing nominal linear attributes.Section 3.2 presents experimental results show one schemes provides betternormalization two set several datasets. Section 3.3 gives empirical resultscomparing HVDM two commonly-used distance functions.3.1. Normalizationdiscussed Section 2.1, distances often normalized dividing distancevariable range attribute, distance input variable range0..1. policy used HEOM Section 2.3. However, dividing range allowsoutliers (extreme values) profound effect contribution attribute.example, variable values range 0..10 almost every case oneexceptional (and possibly erroneous) value 50, dividing range would almostalways result value less 0.2. robust alternative presence outliersdivide values standard deviation reduce effect extreme values typicalcases.new heterogeneous distance metric HVDM, situation complicatednominal numeric distance values come different types measurements:numeric distances computed difference two linear values, normalizedstandard deviation, nominal attributes computed sum C differencesprobability values (where C number output classes). therefore necessary findway scale two different kinds measurements approximately rangegive variable similar influence overall distance measurement.Since 95% values normal distribution fall within two standard deviationsmean, difference numeric values divided 4 standard deviations scalevalue range usually width 1. function normalized_diff therefore definedshown Equation 13:normalized_ diff (x, y) =xy4(13)standard deviation numeric values attribute a.Three alternatives function normalized_vdm considered useheterogeneous distance function. labeled N1, N2 N3, definitionsgiven below:N1: normalized_ vdm1a (x, y) =C Na,x,cc=1N2: normalized_ vdm2 (x, y) =C Na,x,cc=19Na,xNa,xNa,y,cNa,y,c(14)Na,yNa,y2(15)fiWILSON & MARTINEZC Na,x,cN3: normalized_ vdm3a (x, y) = C *c=1Na,xNa,y,c2(16)Na,yfunction N1 Equation (8) q=1. similar formula used PEBLS(Rachlin et al., 1994) RISE (Domingos, 1995) nominal attributes.N2 uses q=2, thus squaring individual differences. analogous using Euclideandistance instead Manhattan distance. Though slightly expensive computationally,formula hypothesized robust N1 favors classcorrelations fairly similar rather close different. N1would able distinguish two. practice square root taken,individual attribute distances squared HVDM function.N3 function used Heterogeneous Radial Basis Function Networks (Wilson &Martinez, 1996), HVDM first introduced.3.2. Normalization Experimentsorder determine whether normalization scheme N1, N2 N3 gave unfair weighteither nominal linear attributes, experiments run 15 databases machinelearning database repository University California, Irvine (Merz & Murphy, 1996).datasets experiment least nominal linear attributes,thus require heterogeneous distance function.experiment, five-fold cross validation used. five trials,distance instance test set instance training setcomputed. computing distance attribute, normalized_diff functionused linear attributes, normalized_vdm function N1, N2, N3 used (inthree respective experiments) nominal attributes.average distance (i.e., sum distances divided number comparisons)computed attribute. average linear attributes databasecomputed averages listed heading avgLin Table 1.DatabaseAnnealAustralianBridgesCrxEchocardiogramFlagHeartHeart.ClevelandHeart.HungarianHeart.Long-Beach-VAHeart.MoreHeart.SwissHepatitisHorse-ColicSoybean-LargeAverageavgLin0.4270.2150.3280.1410.1130.1880.2680.2710.3820.5070.3600.2630.2710.4440.3090.299N1avgNom0.8490.2660.5790.2680.4870.3720.3230.3450.4170.3860.4400.3900.2050.4070.6010.422N2avgNom0.8410.1880.3240.1930.3440.1950.2280.1950.3470.3240.3400.3290.1580.3860.3010.313N3avgNom0.8590.2660.8080.2680.4870.5520.3230.4340.5570.4170.5030.4210.2050.4070.8720.492#Nom.2987921866666613162911#Lin.96467107777776767Table 1. Average attribute distance linear nominal attributes.10#C62722825555522195fiIMPROVED HETEROGENEOUS DISTANCE FUNCTIONSAverage distanceAverage distanceAverage distanceaverages nominal attributes three normalization schemeslisted headings avgNom Table 1 well. average distance linearvariables exactly regardless whether N1, N2 N3 used, averagegiven once. Table 1 also lists number nominal (#Nom.) number linear(#Lin.) attributes database, along number output classes (#C).seen overall averages first four columns last rowTable 1, N2 closer N1 N3. However, important understand reasons behinddifference order know normalization scheme N2 robust general.Figures 2-4 graphically display averages shown Table 1 headings N1, N2N3, respectively, ordered left right number output classes.hypothesized number output classes grows, normalization would get worseN3 indeed appropriate add scaling factor C sum. lengthline indicates much differenceaverage distance nominal attributesNominal1linear attributes. ideal normalization schemeLinearwould difference zero, longer lines.8indicate worse normalization..6number output classes grows,.4difference N3 linear distances.2nominal distances grows wider cases.N2, hand, seems remain quite close02 2 2 2 2 2 5 5 5 5 5 6 7 8 19 Avgindependent number output classes.Number output classesInterestingly, N1 almost poorly N3, evenFigure 2. Average distances N1.though use scaling factor C.Apparently squaring factor providesNominal1well-rounded distance metric nominal attributesLinearsimilar provided using Euclidean distance.8instead Manhattan distance linear attributes..6underlying hypothesis behind performing.4normalization proper normalization.2typically improve generalization accuracy.nearest neighbor classifier (with k =1)02 2 2 2 2 2 5 5 5 5 5 6 7 8 19 Avgimplemented using HVDM distance metric.Number output classessystem tested heterogeneousFigure 3. Average distances N2.datasets appearing Table 1 using threedifferent normalization schemes discussed above,1Nominalusing ten-fold cross-validation (Schaffer, 1993),Linearresults summarized Table 2..8normalization schemes used training sets.6test sets trial. Bold entries indicate.4scheme highest accuracy..2asterisk indicates difference greater1% next highest scheme.02 2 2 2 2 2 5 5 5 5 5 6 7 8 19 Avgseen table, normalizationNumber output classesscheme N2 highest accuracy, N1Figure 4. Average distances N3.11fiWILSON & MARTINEZsubstantially lower two. N2DatabaseN1N2N3N3 highest accuracyAnneal93.9894.61 94.998 domains. significantly, N2Australian71.3081.45 81.59Bridges43.3659.64 59.551% higher 5 times compared N1Crx70.2980.87 81.011% higher one dataset.Echocardiogram70.3694.82 94.82N3 higher twoFlag28.9555.82* 51.50Heart.Cleveland73.8876.56* 71.61one dataset, lower averageHeart.Hungarian70.7576.85* 75.82accuracy N2.Heart.Long-Beach-Va65.5065.50 70.00*results support hypothesisHeart.More60.0372.09 72.48Heart88.4689.49 89.49normalization scheme N2Heart.Swiss74.8178.52* 75.19achieves higher generalization accuracyHepatitis73.5076.67 77.33N1 N3 (on datasets) dueHorse-Colic64.75* 60.53 60.53Soybean-Large41.4590.88* 87.89robust normalization thoughAverage66.0976.95 76.25accuracy N3 almost good N2.Note proper normalizationTable 2. Generalization accuracyusing N1, N2 N3.always necessarily improve generalizationaccuracy. one attributeimportant others classification, giving higher weight may improveclassification. Therefore, important attribute given higher weight accidentallypoor normalization, may actually improve generalization accuracy. However,random improvement typically case. Proper normalization improvegeneralization cases used typical applications.consequence results, N2 used normalization scheme HVDM,function normalized_vdm defined (15).3.3. Empirical Results HVDM vs. Euclidean HOEMnearest neighbor classifier (with k=1) using three distance functions listed Table 3tested 48 datasets UCI machine learning database repository. 48 datasets,results obtained 35 datasets least nominal attributes shownTable 3.results approximately equivalent datasets linear attributes, resultsremaining datasets shown here, found Section 6. 10-fold crossvalidation used, three distance metrics used training sets test setstrial.results experiments shown Table 3. first column lists namedatabase (.test means database originally meant used test set,instead used entirety separate database). second column shows resultsobtained using Euclidean distance function normalized standard deviationattributes, including nominal attributes. next column shows generalization accuracyobtained using HOEM metric, uses range-normalized Euclidean distance linearattributes overlap metric nominal attributes. final column shows accuracyobtained using HVDM distance function uses standard-deviation-normalizedEuclidean distance (i.e., normalized_diff defined Equation 13) linear attributesnormalized_vdm function N2 nominal attributes.highest accuracy obtained database shown bold. Entries Euclid.12fiIMPROVED HETEROGENEOUS DISTANCE FUNCTIONSHOEM columns significantlyhigher HVDM (at 90% higherconfidence level, using two-tailedpaired test) markedasterisk (*).Entriessignificantly lower HVDMmarked less-than sign (<).seen Table 3,HVDM distance functions overallaverage accuracy highertwo metrics 3%.HVDM achieved high highergeneralization accuracytwo distance functions 21 35datasets. Euclidean distancefunction highest 18 datasets,HOEM highest 12datasets.HVDM significantly higherEuclidean distance function10 datasets, significantly lower3. Similarly, HVDM higherHOEM 6 datasets,significantly lower 4.results support hypothesisHVDM handles nominal attributesappropriately Euclideandistance heterogeneousEuclidean-overlap metric, thustends achieve higher generalizationaccuracy typical applications.DatabaseEuclid.Anneal94.99Audiology60.50 <Audiology.Test41.67 <Australian80.58Bridges58.64Crx78.99Echocardiogram94.82Flag48.95 <Heart.Cleveland73.94Heart.Hungarian73.45 <Heart.Long-Beach-Va 71.50Heart.More72.09Heart.Swiss93.53 *Hepatitis77.50Horse-Colic65.77House-Votes-8493.12 <Image.Segmentation92.86Led+1742.90 <Led-Creator57.20 *Monks-1.Test77.08Monks-2.Test59.04 <Monks-3.Test87.26 <Mushroom100.00Promoters73.73 <Soybean-Large87.26 <Soybean-Small100.00Thyroid.Allbp94.89Thyroid.Allhyper97.00Thyroid.Allhypo90.39Thyroid.Allrep96.14Thyroid.Dis98.21Thyroid.Hypothyroid 93.42Thyroid.Sick-Euthyroid 68.23Thyroid.Sick86.93 *Zoo97.78Average:79.44HOEM94.6172.00 <75.0081.1653.7381.0194.8248.8474.9674.4771.00 *71.9091.8677.5060.8293.12 <93.5742.90 <57.20 *69.4354.65 <78.49 <100.0082.09 <89.20100.0094.8997.0090.39 *96.1498.2193.4268.2386.89 *94.4480.11HVDM94.6177.5078.3381.4559.6480.8794.8255.8276.5676.8565.5072.0989.4976.6760.5395.1792.8660.7056.4068.0997.50100.00100.0092.3690.88100.0095.0096.8690.2996.1198.2193.3668.2386.6198.8983.38Table 3. Generalization accuracyEuclidean, HOEM, HVDM distance functions.4. Interpolated Value Difference Metric (IVDM)section Section 5 introduce distance functions allow VDM applieddirectly continuous attributes. alleviates need normalization attributes.also cases provides better measure distance continuous attributes lineardistance.example, consider application input attribute height output classindicates whether person good candidate fighter pilot particular airplane.individuals heights significantly preferred height mightconsidered poor candidates, thus could beneficial consider heightssimilar preferred height, even though farther apartlinear sense.13fiWILSON & MARTINEZhand, linear attributes linearly distant values tend indicate differentclassifications also handled appropriately. Interpolated Value Difference Metric(IVDM) handles situations, handles heterogeneous applications robustly.generic version VDM distance function, called discretized value differencemetric (DVDM) used comparisons extensions VDM presented paper.4.1. IVDM Learning Algorithmoriginal value difference metric (VDM) uses statistics derived training setinstances determine probability Pa,x,c output class c given input value xattribute a.using IVDM, continuous values discretized equal-width intervals (thoughcontinuous values also retained later use), integer supplied user.Unfortunately, currently little guidance value use. valuelarge reduce statistical strength values P, value small allowdiscrimination among classes. purposes paper, use heuristicdetermine automatically: let 5 C, whichever greatest, C numberoutput classes problem domain. Current research examining sophisticatedtechniques determining good values s, cross-validation, statisticalmethods (e.g., Tapia & Thompson, 1978, p. 67). (Early experimental results indicatevalue may critical long C n, n number instancestraining set.)width wa discretized interval attribute given by:wa =maxa mina(17)max mina maximum minimum value, respectively, occurringtraining set attribute a.example, consider Iris database UCI machine learning databases.Iris database four continuous input attributes, first sepal length. Lettraining set consisting 90% 150 available training instances, test setconsisting remaining 10%.one division training set, values sepal length attribute ranged4.3 7.9. three output classes database, let s=5, resultingwidth |7.9 - 4.3| / 5 = 0.72. Note since discretization part learning process,would unfair use instances test set help determine discretizevalues. discretized value v continuous value x attribute integer 1 s,given by:x, discrete, elsev = discretizea (x) = s, x = max , else(x min ) / w + 1(18)deciding upon finding w a, discretized values continuous attributes14fiIMPROVED HETEROGENEOUS DISTANCE FUNCTIONSused like discrete values nominal attributes finding Pa,x,c. Figure 5 lists pseudo-codedone.LearnP(training set T)attributeinstanceLet x input value attribute instance i.v = discretizea(x) [which x discrete]Let c output class instance i.Increment Na,v,c 1.Increment Na,v 1.discrete value v (of attribute a)class cNa,v=0Pa,v,c=0Else Pa,v,c = Na,v,c / Na,vReturn 3-D array Pa,v,c.Figure 5. Pseudo code finding Pa,x,c.Probabilityfirst attribute Iris database, values Pa,x,c displayed Figure 6.five discretized ranges x, probability three correspondingoutput classes shown bar heights. Note heights three bars sum 1.0discretized range. bold integers indicate discretized value range.example, sepal length greater equal 5.74 less 6.46 would discretizedvalue 3.1.01.00.90.80.70.60.50.40.30.20.10.867Output Class:1. IrisSetosa.609.485.455.100.0334.315.02.474 .5003. IrisViginica.061 .02622. IrisVersicolor.3910.035.746.464Sepal Length (in cm)0.0 0.07.18 57.9Bold =discretizedrange number.Figure 6. Pa,x,c a=1, x=1..5, c=1..3, first attribute Iris database.4.2. IVDM DVDM GeneralizationThus far DVDM IVDM algorithms learn identically. However, point DVDMalgorithm need retain original continuous values use discretizedvalues generalization. hand, IVDM use continuous values.generalization, algorithm nearest neighbor classifier use distancefunction DVDM, defined follows:DVDM(x, y) =vdma (discretizea (xa ), discretizea (ya ))a=1152(19)fiWILSON & MARTINEZdiscretizea defined Equation (18) vdma defined Equation (8),q=2. repeat convenience:vdma (x, y) =CPa,x,c Pa,y,c2(20)c=1Unknown input values (Quinlan, 1989) treated simply another discrete value, done(Domingos, 1995).A:B:15.05.7y:5.1Input Attributes233.61.42.84.53.81.940.21.3->->Output Class1 (Iris Setosa)2 (Iris Versicolor)0.4Table 4. Example Iris database.example, consider two training instances B shown Table 4, newinput vector classified. attribute a=1, discretized values A, B, 1, 2,2, respectively. Using values Figure 6, distance attribute 1 is:|.867-.485|2 + |.1-.455|2 + |.033-.061|2 = .273Probability Class 2distance B 0, since discretized value.Note B values different ends range 2, actually nearlyclose are. spite fact, discretized distance function says Bequal happen fall discretized range.IVDM uses interpolation alleviate problems. IVDM assumes Pa,x,c valueshold true midpoint range, interpolates midpoints find Pattribute values.Figure 7 shows P values second output class (Iris Versicolor) functionfirst attribute value (sepal length). dashed line indicates P value used DVDM,solid line shows IVDM uses.1.00.90.80.70.60.50.40.30.20.10CenterpointsDVDMIVDM44.315.02 25.74 3 6.46 47.18 5Sepal Length (in cm)7.9Bold =discretizedrange number.Figure 7. P1,x,2 values DVDM IVDM attribute 1, class 2 Iris database.16fiIMPROVED HETEROGENEOUS DISTANCE FUNCTIONSdistance function Interpolated Value Difference Metric defined as:IVDM(x, y) =ivdma (xa , ya )2(21)a=1ivdma defined as:discretevdma (x, y),C2ivdma (x, y) =p (x) pa,c (y) , otherwisea,cc=1(22)formula determining interpolated probability value pa,c(x) continuous value xattribute class c is:x mida,upa,c (x) = Pa,u,c +* (Pa,u+1,c Pa,u,c )mida,u+1 mida,u(23)equation, mida,u mida,u+1 midpoints two consecutive discretized rangesmida,u x < mida,u+1. Pa,u,c probability value discretized range u,taken probability value midpoint range u (and similarly Pa,u+1,c).value u found first setting u = discretizea(x), subtracting 1 u x < mida,u.value mida,u found follows:mida,u = mina + widtha * (u+.5)(24)Probability ClassFigure 8 shows values pa,c(x) attribute a=1 Iris database three outputclasses (i.e. c=1, 2, 3). Since data points outside range mina..maxa,probability value Pa,u,c taken 0 u < 1 u > s, seen visuallydiagonal lines sloping toward zero outer edges graph. Note sumprobabilities three output classes sum 1.0 every point midpoint range 1midpoint range 5.1.00.90.80.70.60.50.40.30.20.10Output Class:1. Iris Setosa2. Iris Versicolor3. Iris Viginica44.315.02 25.74 3 6.46 47.18 5Sepal Length (in cm)7.9Bold =discretizedrange number.Figure 8. Interpolated probability values attribute 1 Iris database.17fiWILSON & MARTINEZBvalue5.05.7p1,1 (v).687.281p1,2 (v).268.463p1,3 (v).046.2565.1.634.317.050ivdm1(v,y).005.188vdm1(v,y).2730Table 5. Example ivdm vs. vdm.Using IVDM example instances Table 4, values first attributediscretized DVDM, used find interpolated probability values.example, value 5.1, p1,c(x) interpolates midpoints 1 2, returningvalues shown Table 5 three classes. Instance value 5.0, alsofalls midpoints 1 2, instance B value 5.7, fallsmidpoints 2 3.seen Table 5, IVDM (using single-attribute distance function ivdm)returns distance indicates closer B (for first attribute),certainly case here. DVDM (usingdiscretized vdm), hand, returnsDatabaseDVDMIVDMAnnealing94.9996.11 *distance indicates valueAustralian83.04 *80.58equal B, quite far A,Bridges56.7360.55illustrating problems involvedCredit Screening80.1480.14Echocardiogram100.00100.00using discretization.Flag58.7657.66IVDM DVDM algorithmsGlass56.0670.54 *implemented tested 48 datasetsHeart Disease80.3781.85Heart (Cleveland)79.8678.90UCI machine learning databases.Heart(Hungarian)81.3080.98results 34 datasets containHeart (Long-Beach-Va) 71.0066.00least continuous attributesHeart (More)72.2973.33shown Table 6. (Since IVDMHeart (Swiss)88.5987.88Hepatitis80.5882.58DVDM equivalent domainsHorse-Colic76.7576.78discrete attributes, resultsImage Segmentation92.3892.86remaining datasets deferred SectionIonosphere92.6091.17Iris92.0094.676.) 10-fold cross-validationLiver Disorders55.0458.23used, average accuracyPima Indians Diabetes71.8969.28database 10 trials shownSatellite Image87.0689.79 *Shuttle96.1799.77 *Table 6. Bold values indicate valueSonar78.4584.17highest dataset. Asterisks (*)Thyroid (Allbp)94.8695.32indicates difference statisticallyThyroid (Allhyper)96.9397.86 *Thyroid (Allhypo)89.3696.07 *significant 90% confidence levelThyroid (Allrep)96.8698.43 *higher, using two-tailed paired t-test.Thyroid (Dis)98.2998.04set datasets, IVDMThyroid (Hypothyroid)93.0198.07 *higher average generalization accuracyThyroid (Sick)88.2495.07 *Thyroid (Sick-Euthyroid) 88.8296.86 *overall discretized algorithm.Vehicle63.7269.27 *IVDM obtained higher generalizationVowel91.4797.53 *accuracy DVDM 23 34Wine94.3897.78 *Average:83.0885.22cases, 13 significant90% level above. DVDM higherTable 6. Generalization DVDM vs. IVDM.18fiIMPROVED HETEROGENEOUS DISTANCE FUNCTIONSaccuracy 9 cases, one difference statistically significant.results indicate interpolated distance function typically appropriatediscretized value difference metric applications one continuousattributes. Section 6 contains comparisons IVDM distance functions.5. Windowed Value Difference Metric (WVDM)IVDM algorithm thought sampling value Pa,u,c midpoint mida,udiscretized range u. P sampled first finding instances valueattribute range mida,u w / 2. Na,u incremented instance,N a,u,c also incremented instance whose output class c,P a,u,c = Na,u,c / Na,u computed. IVDM interpolates sampled pointsprovide continuous rough approximation function pa,c(x). possible sample Ppoints thus provide closer approximation function pa,c(x), mayturn provide accurate distance measurements values.Figure 9 shows pseudo-code Windowed Value Difference Metric (WVDM).WVDM samples value P a,x,c value x occurring training setDefine:instance[a][1..n] list n instances sorted ascending order attribute a.instance[a][i].val[a] value attribute instance[a][i].xcenter value current window, i.e., x=instance[a][i].val[a].p[a][i][c]probability Pa,x,c output class c given input value xattribute a. Note index, value itself.N[c]number Na,x,c instances current window output class c.Ntotal number Na,x instances current window.instance[a][in] first instance window.instance[a][out] first instance outside window. (i.e., window containsinstances instance[a][in..out-1]).w[a]window width attribute a.LearnWVDM(training set T)continuous attributeSort instance[a][1..n] ascending order attribute a, using quicksort.Initialize N N[c] 0, 1 (i.e., start empty window).i=1..nLet x=instance[a][i].val[a].// Expand window include instances range(out < n) (instance[a][out].val[a] < (x + w[a]/2))Increment N[c], c=the class instance[a][out].Increment N.Increment out.// Shrink window exclude instances longer range(in < out) (instance[a][in].val[a] < (x - w[a]/2))Decrement N[c], c=the class instance[a][in].Decrement N.Increment in.// Compute probability value class current windowclass c=1..Cp[a][i][c] = N[c] / N. (i.e., Pa,x,c = Na,x,c / Na,x).Return 3-D array p[a][i][c].Figure 9. Pseudo code WVDM learning algorithm.19fiWILSON & MARTINEZattribute a, instead midpoints range. fact, discretized rangeseven used WVDM continuous attributes, except determine appropriate windowwidth, wa, range width used DVDM IVDM. pseudo-codelearning algorithm used determine Pa,x,c attribute value x given Figure 9.value x occurring training set attribute a, P sampled findinginstances value attribute range x w / 2, computing Na,x,Na,x,c, Pa,x,c = Na,x,c / Na,x before. Thus, instead fixed number samplingpoints, window instances, centered training instance, used determiningprobability given point. technique similar concept shifted histogram estimators(Rosenblatt, 1956) Parzen window techniques (Parzen, 1962).attribute values sorted (using O(nlogn) sorting algorithm) allowsliding window used thus collect needed statistics O(n) time attribute.sorted order retained attribute binary search performed O(logn) time generalization.Values occurring sampled points interpolated IVDM, exceptmany points available, new value interpolated twocloser, precise values IVDM.WVDM_Find_P(attribute a,continuous value x)// Find Pa,x,c c=1..C, given value x attribute a.Find instance[a][i].val[a] x instance[a][i+1].val[a] (binary search).x1 = instance[a][i].val[a](unless i<1, case x1=min[a] - (w[a] / 2))x2 = instance[a][i+1].val[a] (unless i>n, case x2=max[a] + (w[a] / 2))class c=1..Cp1=p[a][i][c](unless i<1, case p1=0)p2=p[a][i+1][c] (unless i>n, case p2=0)Pa,x,c = p1 + ((x-x1)/(x2-x1)) * (p2 - p1)Return array Pa,x,1..C.Figure 10. Pseudo-code WVDM probability interpolation (see Figure 9 definitions).pseudo-code interpolation algorithm given Figure 10. algorithm takesvalue x attribute returns vector C probability values Pa,x,c c=1..C. firstbinary search find two consecutive instances sorted list instancesattribute surround x. probability class interpolatedstored two surrounding instances. (The exceptions noted parenthesis handleoutlying values interpolating towards 0 done IVDM.)probability values input vectors attribute values computed,used vdm function discrete probability values are.WVDM distance function defined as:WVDM(x, y) =wvdma (xa , ya )2(25)a=1wvdma defined as:discretevdma (x, y),C2wvdma (x, y) =PPa,y,c , otherwisea,x,cc=120(26)fiProbability ClassIMPROVED HETEROGENEOUS DISTANCE FUNCTIONS1.00.90.80.70.60.50.40.30.20.10Output Class:1. Iris Setosa2. Iris Versicolor3. Iris Viginica45678Sepal Length (in cm)Figure 11. Example WVDM probability landscape.Pa,x,c interpolated probability value continuous value x computedFigure 10. Note typically finding distance new input vectorinstance training set. Sinceinstances training set usedDatabaseDVDM WVDMdefine probability attributeAnnealing94.9995.87Australian83.0482.46values, binary search interpolationBridges56.7356.64unnecessary training instancesCredit Screening80.1481.45immediately recall storedEchocardiogram100.0098.57probability values, unless pruning techniquesFlag58.7658.74Glass56.0671.49 *used.Heart Disease80.3782.96One drawback approachHeart (Cleveland)79.8680.23increased storage needed retain CHeart (Hungarian)81.3079.26Heart (Long-Beach-Va) 71.0068.00probability values attribute valueHeart (More)72.2973.33training set. Execution timeHeart (Swiss)88.5988.72significantly increased IVDMHepatitis80.5879.88Horse-Colic76.7574.77DVDM. (See Section 6.2 discussionImageSegmentation92.3893.33efficiency considerations).Ionosphere92.6091.44Figure 11 shows probability valuesIris92.0096.00Liver Disorders55.0457.09three classes first attributePima Indians Diabetes71.8970.32Iris database again, time usingSatellite Image87.0689.33 *windowed sampling technique. ComparingShuttle96.1799.61 *Figure 11 Figure 8 revealsSonar78.4584.19Thyroid (Allbp)94.8695.29attribute IVDM provides approximatelyThyroid (Allhyper)96.9397.50overall shape, misses muchThyroid (Allhypo)89.3690.18detail. example, peak occurringThyroid (Allrep)96.8697.07Thyroid (Dis)98.2998.00output class 2 approximately sepalThyroid (Hypothyroid)93.0196.96 *length=5.75. Figure 8 flat lineThyroid (Sick)88.2497.11 *misses peak entirely, due mostlyThyroid (Sick-Euthyroid) 88.8294.40 *Vehicle63.7265.37 *somewhat arbitrary positionVowel91.4796.21 *midpoints probability valuesWine94.3897.22 *sampled.Average:83.0884.68Table 7 summarizes results testingTable 7. Generalization WVDM vs. DVDM.21fiWILSON & MARTINEZWVDM algorithm datasets DVDM IVDM. bold entry indicateshighest two accuracy measurements, asterisk (*) indicates differencestatistically significant 90% confidence level, using two-tailed paired t-test.set databases, WVDM average 1.6% accurate DVDMoverall. WVDM higher average accuracy DVDM 23 34 databases,significantly higher 9, DVDM higher 11 databases, nonedifferences statistically significant.Section 6 provides comparisons WVDM distance functions, includingIVDM.6. Empirical Comparisons Analysis Distance Functionssection compares distance functions discussed paper. nearest neighborclassifier implemented using six different distance functions: Euclidean(normalized standard deviation) HOEM discussed Section 2; HVDM discussedSection 3; DVDM IVDM discussed Section 4; WVDM discussed Section5. Figure 12 summarizes definition distance function.functions useoverall distance function:D(x, y) =da (xa , ya )2a=1DistanceFunctionEuclideanDefinition da(xa,ya) attribute type:LinearContinuousDiscrete Nominalxa yaxa yaHOEMxa yarangea0 xa = ya1 xa yaHVDMxa ya4vdma (xa , ya )DVDMvdma(disca(xa),disca(ya))vdma (xa , ya )IVDMivdma(xa,ya)Interpolate probabilitiesrange midpoints.vdma (xa , ya )WVDMwvdma(xa,ya)Interpolate probabilitiesadjacent values.vdma (xa , ya )rangea = maxa mina , vdma (x, y) =CPa,x,c Pa,y,c2c=1Figure 12. Summary distance function definitions.distance function tested 48 datasets UCI machine learning databases,22fiIMPROVED HETEROGENEOUS DISTANCE FUNCTIONSusing 10-fold cross-validation. average accuracy 10 trials reportedtest Table 8. highest accuracy achieved dataset shown bold.names three new distance functions presented paper (HVDM, IVDM WVDM)also shown bold identify them.Table 8 also lists number instances database (#Inst.), numbercontinuous (Con), integer (Int, i.e., linear discrete), nominal (Nom) input attributes.DatabaseEuclid HOEMAnnealing94.9994.61Audiology60.5072.00Audiology (test)41.6775.00Australian80.5881.16Breast Cancer94.9995.28Bridges58.6453.73Credit Screening78.9981.01Echocardiogram94.8294.82Flag48.9548.84Glass72.3670.52Heart Disease72.2275.56Heart (Cleveland)73.9474.96Heart (Hungarian)73.4574.47Heart (Long-Beach-Va)71.5071.00Heart (More)72.0971.90Heart (Swiss)93.5391.86Hepatitis77.5077.50Horse-Colic65.7760.82House-Votes-8493.1293.12Image Segmentation92.8693.57Ionosphere86.3286.33Iris94.6795.33LED+17 noise42.9042.90LED57.2057.20Liver Disorders62.9263.47Monks-177.0869.43Monks-259.0454.65Monks-387.2678.49Mushroom100.00 100.00Pima Indians Diabetes71.0970.31Promoters73.7382.09Satellite Image90.2190.24Shuttle99.7899.78Sonar87.0286.60Soybean (Large)87.2689.20Soybean (Small)100.00 100.00Thyroid (Allbp)94.8994.89Thyroid (Allhyper)97.0097.00Thyroid (Allhypo)90.3990.39Thyroid (Allrep)96.1496.14Thyroid (Dis)98.2198.21Thyroid (Hypothyroid)93.4293.42Thyroid (Sick-Euthyroid) 68.2368.23Thyroid (Sick)86.9386.89Vehicle70.9370.22Vowel99.2498.86Wine95.4695.46Zoo97.7894.44Average:80.7881.29n c eHVDM94.6177.5078.3381.4594.9959.6480.8794.8255.8272.3678.5276.5676.8565.5072.0989.4976.6760.5395.1792.8686.3294.6760.7056.4062.9268.0997.50100.00100.0071.0992.3690.2199.7887.0290.88100.0095.0096.8690.2996.1198.2193.3668.2386.6170.9399.2495.4698.8983.79F u nDVDM94.9977.5078.3383.0495.5756.7380.14100.0058.7656.0680.3779.8681.3071.0072.2988.5980.5876.7595.1792.3892.6092.0060.7056.4055.0468.0997.50100.00100.0071.8992.3687.0696.1778.4592.18100.0094.8696.9389.3696.8698.2993.0188.2488.8263.7291.4794.3898.8984.06c n# inputsIVDM WVDM #Inst. Con Int Nom96.1195.877986 32977.5077.502000 06978.3378.33260 06980.5882.466906 0895.5795.576990 9060.5556.641081 3780.1481.456906 09100.0098.571327 0257.6658.741943 71870.5471.492149 0081.8582.962705 2678.9080.233035 2680.9879.262945 2666.0068.002005 2673.3373.33 15415 2687.8888.721235 2682.5879.881556 01376.7874.773017 01695.1795.174350 01692.8693.33420 18 0191.1791.44351 34 0094.6796.001504 0060.7060.70 100000 02456.4056.40 10000 0758.2357.093456 0068.0968.094320 0697.5097.504320 06100.00 100.004320 06100.00 100.00 81240 12169.2870.327688 0092.3692.361060 05789.7989.33 4435 36 0099.7799.61 92539 0084.1784.19208 60 0092.1892.183070 629100.00 100.00470 62995.3295.29 28006 02297.8697.50 28006 02296.0790.18 28006 02298.4397.07 28006 02298.0498.00 28006 02298.0796.96 31637 01895.0794.40 31637 01896.8697.11 28006 02269.2765.37846 18 0097.5396.21528 10 0097.7897.22178 13 0098.8998.89900 01685.5685.24Table 8. Summary Generalization Accuracy23fiWILSON & MARTINEZset 48 datasets, three new distance functions (HVDM, IVDM WVDM)substantially better Euclidean distance HOEM. IVDM highest average accuracy(85.56%) almost 5% higher average Euclidean distance (80.78%), indicatingrobust distance function datasets, especially nominalattributes. WVDM slightly lower IVDM 85.24% accuracy. Somewhatsurprisingly, DVDM slightly higher HVDM datasets, even though usesdiscretization instead linear distance continuous attributes. four VDM-baseddistance functions outperformed Euclidean distance HOEM.48 datasets, Euclidean distance highest accuracy 11 times; HOEMhighest 7 times; HVDM, 14; DVDM, 19; IVDM, 25 WVDM, 18.datasets continuous attributes, four VDM-based distance functions(HVDM, DVDM, IVDM WVDM) equivalent. datasets, VDM-baseddistance functions achieve average accuracy 86.6% compared 78.8% HOEM76.6% Euclidean, indicating substantial superiority problems.datasets nominal attributes, Euclidean HVDM equivalent,distance functions perform average except DVDM, averages4% less others, indicating detrimental effects discretization. EuclideanHOEM similar definitions applications without nominal attributes, exceptEuclidean normalized standard deviation HOEM normalized rangeattribute. interesting average accuracy datasets slightly higherEuclidean HOEM, indicating standard deviation may provide better normalizationdatasets. However, difference small (less 1%), datasetscontain many outliers, difference probably negligible case.One disadvantage scaling attributes standard deviation attributesalmost always value (e.g., boolean attribute almost always 0)given large weightnot due scale, relative frequencies attributevalues. related problem occur HVDM. skewed class distribution(i.e., many instances classes others), P values quitesmall classes quite large others, either case difference |Pa,x,c - Pa,y,c|correspondingly small, thus nominal attributes get little weightcompared linear attributes. phenomenon noted Ting (1994, 1996),recognized problems hypothyroid dataset. Future research addressnormalization problems look automated solutions. Fortunately, DVDM, IVDMWVDM suffer either problem, attributes scaled amountcases, may part account success HVDMexperiments.datasets nominal continuous attributes, HVDM slightly higherEuclidean distance datasets, turn slightly higher HOEM, indicatingoverlap metric may much improvement heterogeneous databases.DVDM, IVDM WVDM higher Euclidean distance datasets,IVDM lead.6.1. Effects Sparse DataDistance functions use VDM require statistics determine distance. thereforehypothesized generalization accuracy might lower VDM-based distance functions24fiIMPROVED HETEROGENEOUS DISTANCE FUNCTIONSEuclidean distance HOEM little data available, VDMbased functions would increase accuracy slowly others instancesmade available, sufficient number instances allowed reasonable sample sizedetermine good probability values.85.00%Average Generalization Accuracy80.0075.00Euclidean70.00HOEMHVDM65.00DVDMIVDM60.00WVDM55.000204060%Instances Used80100Figure 13. Average accuracy amount data increases.test hypothesis, experiments used obtain results shown Table 8repeated using part available training data. Figure 13 shows generalizationaccuracy test set improves percentage available training instances usedlearning generalization increased 1% 100%. generalization accuracy valuesshown averages 48 datasets Table 8.Surprisingly, VDM-based distance functions increased accuracy fast fasterEuclidean HOEM even little data available. maylittle data available, random positioning sample data input spacegreater detrimental affect accuracy error statistical sampling VDM-basedfunctions.interesting note Figure 13 six distance functions seem pairthree distinct pairs. interpolated VDM-based distance functions (IVDM WVDM)maintain highest accuracy, two VDM-based functions next, functionsbased linear overlap distance remain lowest early graph.25fiWILSON & MARTINEZ6.2. Efficiency Considerationssection considers storage requirements, learning speed, generalization speedalgorithms presented paper.6.2.1. STORAGEdistance functions must store entire training set, requiring O(nm) storage,n number instances training set number input attributesapplication, unless instance pruning technique used. Euclidean HOEMfunctions, necessary, even amount storage restrictive ngrows large.HVDM, DVDM, IVDM, probabilities Pa,x,c attributes (only discreteattributes HVDM) must stored, requiring O(mvC) storage, v average numberattribute values discrete (or discretized) attributes C number outputclasses application. possible instead store array Da,x,y = vdma(x,y) HVDMDVDM, storage would O(mv2), savings C < v.WVDM, C probability values must stored continuous attribute value,resulting O(nmC) storage typically much larger O(mvC) n usuallymuch larger v (and cannot less). also necessary store list (pointers to)instances attribute, requiring additional O(mn) storage. Thus total storageWVDM O((C+2)nm) = O(Cnm).Distance FunctionEuclideanHOEMHVDMDVDMIVDMWVDMStorageO(mn)O(mn)O(mn+mvC)O(mn+mvC)O(mn+mvC)O(Cmn)Learning TimeO(mn)O(mn)O(mn+mvC)O(mn+mvC)O(mn+mvC)O(mnlogn+mvC)Generalization TimeO(mn)O(mn)O(mnC) O(mn)O(mnC) O(mn)O(mnC) O(mn)O(mnC)Table 9. Summary efficiency six distance metrics.Table 9 summarizes storage requirements system. WVDM onedistance functions requires significantly storage others.applications, n critical factor, distance functions could usedconjunction instance pruning techniques reduce storage requirements. See Section 7list several techniques reduce number instances retained training setsubsequent generalization.6.2.2. L EARNING SPEEDtakes nm time read training set. takes additional 2nm time find standarddeviation attributes Euclidean distance, nm time find ranges HOEM.Computing VDM statistics HVDM, DVDM IVDM takes mn+mvC time,approximately O(mn). Computing WVDM statistics takes mnlogn+mnC time,approximately O(mnlogn).general, learning time quite acceptable distance functions.26fiIMPROVED HETEROGENEOUS DISTANCE FUNCTIONS6.2.3. GENERALIZATION SPEEDAssuming distance function must compare new input vector training instances,Euclidean HOEM take O(mn) time. HVDM, IVDM DVDM take O(mnC) (unlessDa,x,y stored instead Pa,x,c HVDM, case search done O(mn)time). WVDM takes O(logn+mnC) = O(mnC) time.Though C typically fairly small, generalization process requiresignificant amount time and/or computational resources n grows large. Techniquesk-d trees (Deng & Moore, 1995; Wess, Althoff & Derwand, 1993; Sproull, 1991)projection (Papadimitriou & Bentley, 1980) reduce time required locate nearestneighbors training set, though algorithms may require modification handlecontinuous nominal attributes. Pruning techniques used reduce storage (as Section6.2.1) also reduce number instances must searched generalization.7. Related WorkDistance functions used variety fields, including instance-based learning, neuralnetworks, statistics, pattern recognition, cognitive psychology (see Section 1references). Section 2 lists several commonly-used distance functions involving numericattributes.Normalization often desirable using linear distance function Euclideandistance attributes arbitrarily get weight others. Dividingrange standard deviation normalize numerical attributes common practice. Turney(1993; Turney & Halasz, 1993) investigated contextual normalization, standarddeviation mean used normalization continuous attributes depend contextinput vector obtained. paper attempt use contextualnormalization, instead use simpler methods normalizing continuous attributes,focus normalize appropriately continuous nominal attributes.Value Distance Metric (VDM) introduced Stanfill & Waltz (1986). usesattribute weights used functions presented paper. Modified ValueDifference Metric (MVDM) (Cost & Salzberg, 1993; Rachlin et al., 1994) use attributeweights instead uses instance weights. assumed systems use discretization(Lebowitz, 1985; Schlimmer, 1987) handle continuous attributes.Ventura (1995; Ventura & Martinez, 1995) explored variety discretization methodsuse systems use discrete input attributes. found using discretizationpreprocess data often degraded accuracy, recommended machine learning algorithmsdesigned handle continuous attributes directly.Ting (1994, 1996) used several different discretization techniques conjunctionMVDM IB1 (Aha, Kibler & Albert, 1991). results showed improved generalizationaccuracy using discretization. Discretization allowed algorithm use MVDMattributes instead using linear distance continuous attributes, thus avoidednormalization problems discussed Sections 3.1 3.2. paper, similarresults seen slightly higher results DVDM (which also discretizes continuousattributes uses VDM) compared HVDM (which uses linear distancecontinuous attributes). paper, DVDM uses equal-width intervals discretization,27fiWILSON & MARTINEZTings algorithms make use advanced discretization techniques.Domingos (1995) uses heterogeneous distance function similar HVDM RISEsystem, hybrid rule instance-based learning system. However, RISE uses normalizationscheme similar N1 Sections 3.1 3.2, square individual attributedistances.Mohri & Tanaka (1994) use statistical technique called Quantification Method II (QM2)derive attribute weights, present distance functions handle nominalcontinuous attributes. transform nominal attributes values booleanattributes, one time, weights attribute actuallycorrespond individual attribute values original data.Turney (1994) addresses cross-validation error voting (i.e. using values k > 1)instance-based learning systems, explores issues related selecting parameter k (i.e.,number neighbors used decide classification). paper use k = 1 orderfocus attention distance functions themselves, accuracy would improvedapplications using k > 1.IVDM WVDM use nonparametric density estimation techniques (Tapia & Thompson,1978) determining values P use computing distances. Parzen windows (Parzen,1962) shifting histograms (Rosenblatt, 1956) similar concept techniques,especially WVDM. techniques often use gaussian kernels advancedtechniques instead fixed-sized sliding window. experimented gaussianweighted kernels well results slightly worse either WVDM IVDM, perhapsincreased overfitting.paper applies distance function problem classification, inputvector mapped discrete output class. distance functions could also usedsystems perform regression (Atkeson, Moore & Schaal, 1996; Atkeson, 1989; Cleveland &Loader, 1994), output real value, often interpolated nearby points,kernel regression (Deng & Moore, 1995).mentioned Section 6.2 elsewhere, pruning techniques used reducestorage requirements instance-based systems improve classification speed. Severaltechniques introduced, including IB3 (Aha, Kibler & Albert, 1991; Aha, 1992),condensed nearest neighbor rule (Hart, 1968), reduced nearest neighbor rule (Gates, 1972),selective nearest neighbor rule (Rittler et al., 1975), typical instance based learningalgorithm (Zhang, 1992), prototype methods (Chang, 1974), hyperrectangle techniques(Salzberg, 1991; Wettschereck & Dietterich, 1995), rule-based techniques (Domingos, 1995),random mutation hill climbing (Skalak, 1994; Cameron-Jones, 1995) others (Kibler & Aha,1987; Tomek, 1976; Wilson, 1972).8. Conclusions & Future Research Areasmany learning systems depend reliable distance function achieve accurategeneralization. Euclidean distance function many distance functionsinappropriate nominal attributes, HOEM function throws away informationachieve much better accuracy Euclidean function itself.Value Difference Metric (VDM) designed provide appropriate measure28fiIMPROVED HETEROGENEOUS DISTANCE FUNCTIONSdistance two nominal attribute values. However, current systems use VDMoften discretize continuous data discrete ranges, causes loss informationoften corresponding loss generalization accuracy.paper introduced three new distance functions. Heterogeneous Value DifferenceFunction (HVDM) uses Euclidean distance linear attributes VDM nominal attributes,uses appropriate normalization. Interpolated Value Difference Metric (IVDM)Windowed Value Difference Metric (WVDM) handle continuous attributes withinparadigm VDM. IVDM WVDM provide classification accuracy higheraverage discretized version algorithm (DVDM) datasets continuousattributes examined, equivalent DVDM applications withoutcontinuous attributes.experiments 48 datasets, IVDM WVDM achieved higher average accuracyHVDM, also better DVDM, HOEM Euclidean distance. IVDMslightly accurate WVDM requires less time storage, thus would seemdesirable distance function heterogeneous applications similar usedpaper. Properly normalized Euclidean distance achieves comparable generalizationaccuracy nominal attributes, situations still appropriatedistance function.learning system used obtain generalization accuracy results paper nearestneighbor classifier, HVDM, IVDM WVDM distance functions used knearest neighbor classifier k > 1 incorporated wide variety systemsallow handle continuous values including instance-based learning algorithms (suchPEBLS), radial basis function networks, distance-based neural networks. newdistance metrics also used areas statistics, cognitive psychology, patternrecognition areas distance heterogeneous input vectorsinterest. distance functions also used conjunction weighting schemesimprovements system provides.new distance functions presented show improved average generalization 48datasets used experimentation. hoped datasets representative kindsapplications face real world, new distance functionscontinue provide improved generalization accuracy cases.Future research look determining conditions distance functionappropriate particular application. also look closely problem selectingwindow width, look possibility smoothing WVDMs probability landscapeavoid overfitting. new distance functions also used conjunction varietyweighting schemes provide robust generalization presence noiseirrelevant attributes, well increase generalization accuracy wide varietyapplications.ReferencesAha, David W., (1992). Tolerating noisy, irrelevant novel attributes instance-basedlearning algorithms. International Journal Man-Machine Studies, Vol. 36, pp. 267-287.Aha, David W., Dennis Kibler, Marc K. Albert, (1991). Instance-Based LearningAlgorithms. Machine Learning, Vol. 6, pp. 37-66.29fiWILSON & MARTINEZAtkeson, Chris, (1989). Using local models control movement. D. S. Touretzky (Ed.),Advances Neural Information Processing Systems 2. San Mateo, CA: Morgan Kaufmann.Atkeson, Chris, Andrew Moore, Stefan Schaal, (1996). Locally weighted learning.appear Artificial Intelligence Review.Batchelor, Bruce G., (1978). Pattern Recognition: Ideas Practice. New York: Plenum Press,pp. 71-72.Biberman, Yoram, (1994). Context Similarity Measure. Proceedings EuropeanConference Machine Learning (ECML-94). Catalina, Italy: Springer Verlag, pp. 49-63.Broomhead, D. S., D. Lowe (1988). Multi-variable functional interpolation adaptivenetworks. Complex Systems, Vol. 2, pp. 321-355.Cameron-Jones, R. M., (1995). Instance Selection Encoding Length Heuristic RandomMutation Hill Climbing. Proceedings Eighth Australian Joint ConferenceArtificial Intelligence, pp. 99-106.Carpenter, Gail A., Stephen Grossberg, (1987). Massively Parallel ArchitectureSelf-Organizing Neural Pattern Recognition Machine. Computer Vision, Graphics,Image Processing, Vol. 37, pp. 54-115.Chang, Chin-Liang, (1974). Finding Prototypes Nearest Neighbor Classifiers. IEEETransactions Computers, Vol. 23, No. 11, pp. 1179-1184.Cleveland, W. S., C. Loader, (1994). Computational Methods Local Regression.Technical Report 11, Murray Hill, NJ: AT&T Bell Laboratories, Statistics Department.Cost, Scott, Steven Salzberg, (1993). Weighted Nearest Neighbor AlgorithmLearning Symbolic Features. Machine Learning, Vol. 10, pp. 57-78.Cover, T. M., P. E. Hart, (1967). Nearest Neighbor Pattern Classification. InstituteElectrical Electronics Engineers Transactions Information Theory, Vol. 13, No. 1,pp. 21-27.Dasarathy, Belur V., (1991). Nearest Neighbor (NN) Norms: NN Pattern ClassificationTechniques. Los Alamitos, CA: IEEE Computer Society Press.Deng, Kan, Andrew W. Moore, (1995). Multiresolution Instance-Based Learning.appear Proceedings International Joint Conference Artificial Intelligence(IJCAI95).Diday, Edwin, (1974). Recent Progress Distance Similarity Measures PatternRecognition. Second International Joint Conference Pattern Recognition, pp. 534-539.Domingos, Pedro, (1995). Rule Induction Instance-Based Learning: Unified Approach.appear 1995 International Joint Conference Artificial Intelligence (IJCAI-95).Dudani, Sahibsingh A., (1976). Distance-Weighted k-Nearest-Neighbor Rule. IEEETransactions Systems, Man Cybernetics, Vol. 6, No. 4, April 1976, pp. 325-327.30fiIMPROVED HETEROGENEOUS DISTANCE FUNCTIONSGates, G. W., (1972). Reduced Nearest Neighbor Rule. IEEE Transactions InformationTheory, Vol. IT-18, No. 3, pp. 431-433.Giraud-Carrier, Christophe, Tony Martinez, (1995). Efficient Metric HeterogeneousInductive Learning Applications Attribute-Value Language. Intelligent Systems, pp.341-350.Hart, P. E., (1968). Condensed Nearest Neighbor Rule. Institute ElectricalElectronics Engineers Transactions Information Theory, Vol. 14, pp. 515-516.Hecht-Nielsen, R., (1987). Counterpropagation Networks. Applied Optics, Vol. 26, No. 23, pp.4979-4984.Kibler, D., David W. Aha, (1987). Learning representative exemplars concepts:initial case study. Proceedings Fourth International Workshop MachineLearning. Irvine, CA: Morgan Kaufmann, pp. 24-30.Kohonen, Teuvo, (1990). Self-Organizing Map. Proceedings IEEE, Vol. 78, No.9, pp. 1464-1480.Lebowitz, Michael, (1985). Categorizing Numeric Information Generalization. CognitiveScience, Vol. 9, pp. 285-308.Merz, C. J., P. M. Murphy, (1996). UCI Repository Machine Learning Databases.Irvine, CA: University California Irvine, Department Information ComputerScience. Internet: http://www.ics.uci.edu/~mlearn/MLRepository.html.Michalski, Ryszard S., Robert E. Stepp, Edwin Diday, (1981). Recent Advance DataAnalysis: Clustering Objects Classes Characterized Conjunctive Concepts.Progress Pattern Recognition, Vol. 1, Laveen N. Kanal Azriel Rosenfeld (Eds.).New York: North-Holland, pp. 33-56.Mitchell, Tom M., (1980). Need Biases Learning Generalizations. J. W. Shavlik& T. G. Dietterich (Eds.), Readings Machine Learning. San Mateo, CA: MorganKaufmann, 1990, pp. 184-191.Mohri, Takao, Hidehiko Tanaka, (1994). Optimal Weighting Criterion CaseIndexing Numeric Symbolic Attributes. D. W. Aha (Ed.), Case-BasedReasoning: Papers 1994 Workshop, Technical Report WS-94-01. Menlo Park,CA: AIII Press, pp. 123-127.Nadler, Morton, Eric P. Smith, (1993). Pattern Recognition Engineering. New York:Wiley, pp. 293-294.Nosofsky, Robert M., (1986). Attention, Similarity, Identification-CategorizationRelationship. Journal Experimental Psychology: General, Vol. 115, No. 1, pp. 39-57.Papadimitriou, Christos H., Jon Louis Bentley, (1980). Worst-Case Analysis NearestNeighbor Searching Projection. Lecture Notes Computer Science, Vol. 85,Automata Languages Programming, pp. 470-482.31fiWILSON & MARTINEZParzen, Emanuel, (1962). estimation probability density function mode. AnnalsMathematical Statistics. Vol. 33, pp. 1065-1076.Quinlan, J. R., (1989). Unknown Attribute Values Induction. Proceedings 6thInternational Workshop Machine Learning. San Mateo, CA: Morgan Kaufmann, pp.164-168.Rachlin, John, Simon Kasif, Steven Salzberg, David W. Aha, (1994). Towards BetterUnderstanding Memory-Based Bayesian Classifiers. ProceedingsEleventh International Machine Learning Conference. New Brunswick, NJ: MorganKaufmann, pp. 242-250.Renals, Steve, Richard Rohwer, (1989). Phoneme Classification Experiments Using RadialBasis Functions. Proceedings IEEE International Joint Conference NeuralNetworks (IJCNN89), Vol. 1, pp. 461-467.Rittler, G. L., H. B. Woodruff, S. R. Lowry, T. L. Isenhour, (1975). AlgorithmSelective Nearest Neighbor Decision Rule. IEEE Transactions Information Theory,Vol. 21, No. 6, pp. 665-669.Rosenblatt, Murray, (1956). Remarks Nonparametric Estimates Density Function.Annals Mathematical Statistics. Vol. 27, pp. 832-835.Rumelhart, D. E., J. L. McClelland, (1986). Parallel Distributed Processing, MIT Press,Ch. 8, pp. 318-362.Salzberg, Steven, (1991). Nearest Hyperrectangle Learning Method. Machine Learning,Vol. 6, pp. 277-309.Schaffer, Cullen, (1993). Selecting Classification Method Cross-Validation. MachineLearning, Vol. 13, No. 1.Schaffer, Cullen, (1994). Conservation Law Generalization Performance. ProceedingsEleventh International Conference Machine Learning (ML94), MorganKaufmann, 1994.Schlimmer, Jeffrey C., (1987). Learning Representation Change. ProceedingsSixth National Conference Artificial Intelligence (AAAI87), Vol. 2, pp. 511-535.Skalak, D. B., (1994). Prototype Feature Selection Sampling Random Mutation HillClimbing Algorithsm. Proceedings Eleventh International ConferenceMachine Learning (ML94). Morgan Kaufman, pp. 293-301.Sproull, Robert F., (1991). Refinements Nearest-Neighbor Searching k-DimensionalTrees. Algorithmica, Vol. 6, pp. 579-589.Stanfill, C., D. Waltz, (1986). Toward memory-based reasoning. CommunicationsACM, Vol. 29, December 1986, pp. 1213-1228.32fiIMPROVED HETEROGENEOUS DISTANCE FUNCTIONSTapia, Richard A., James R. Thompson, (1978). Nonparametric Probability DensityEstimation. Baltimore, MD: Johns Hopkins University Press.Ting, Kai Ming, (1994). Discretization Continuous-Valued Attributes Instance-BasedLearning. Technical Report No. 491, Basser Department Computer Science, UniversitySydney, Australia.Ting, Kai Ming, (1996). Discretisation Lazy Learning. appear special issueLazy Learning Artificial Intelligence Review.Tomek, Ivan, (1976). Experiment Edited Nearest-Neighbor Rule. IEEETransactions Systems, Man, Cybernetics, Vol. 6, No. 6, June 1976, pp. 448-452.Turney, Peter, (1994). Theoretical Analyses Cross-Validation Error Voting InstanceBased Learning. Journal Experimental Theoretical Artificial Intelligence (JETAI),pp. 331-360.Turney, Peter, (1993). Exploiting context learning classify. ProceedingsEuropean Conference Machine Learning. Vienna, Austria: Springer-Verlag, pp. 402407.Turney, Peter, Michael Halasz, (1993). Contextual Normalization Applied Aircraft GasTurbine Engine Diagnosis. Journal Applied Intelligence, Vol. 3, pp. 109-129.Tversky, Amos, (1977). Features Similarity. Psychological Review, Vol. 84, No. 4, pp. 327352.Ventura, Dan, (1995). Discretization Preprocessing Step Supervised LearningModels, Masters Thesis, Department Computer Science, Brigham Young University.Ventura, Dan, Tony R. Martinez (1995). Empirical Comparison DiscretizationMethods. Proceedings Tenth International Symposium ComputerInformation Sciences, pp. 443-450.Wasserman, Philip D., (1993). Advanced Methods Neural Computing. New York, NY: VanNostrand Reinhold, pp. 147-176.Wess, Stefan, Klaus-Dieter Althoff Guido Derwand, (1994). Using k-d Trees ImproveRetrieval Step Case-Based Reasoning. Stefan Wess, Klaus-Dieter Althoff, & M. M.Richter (Eds.), Topics Case-Based Reasoning. Berlin: Springer-Verlag, pp. 167-181.Wettschereck, Dietrich, Thomas G. Dietterich, (1995). Experimental ComparisonNearest-Neighbor Nearest-Hyperrectangle Algorithms. Machine Learning, Vol. 19,No. 1, pp. 5-28.Wettschereck, Dietrich, David W. Aha, Takao Mohri, (1995). Review ComparativeEvaluation Feature Weighting Methods Lazy Learning Algorithms. TechnicalReport AIC-95-012. Washington, D.C.: Naval Research Laboratory, Navy CenterApplied Research Artificial Intelligence.33fiWILSON & MARTINEZWilson, D. Randall, Tony R. Martinez, (1993). Potential Prototype StylesGeneralization. Proceedings Sixth Australian Joint Conference ArtificalIntelligence (AI93), pp. 356-361.Wilson, D. Randall, Tony R. Martinez, (1996). Heterogeneous Radial Basis Functions.Proceedings International Conference Neural Networks (ICNN96), Vol. 2, pp.1263-1267.Wilson, Dennis L., (1972). Asymptotic Properties Nearest Neighbor Rules Using EditedData. IEEE Transactions Systems, Man, Cybernetics, Vol. 2, No. 3, pp. 408-421.Wolpert, David H., (1993). Overfitting Avoidance Bias. Technical Report SFI TR 9203-5001. Santa Fe, NM: Santa Fe Institute.Zhang, Jianping, (1992). Selecting Typical Instances Instance-Based Learning. ProceedingsNinth International Conference Machine Learning.34fiJournal Artificial Intelligence Research 6 (1997) 87-110Submitted 7/96; published 3/97Uniform Framework Concept DefinitionsDescription LogicsGiuseppe De Giacomodegiacomo@dis.uniroma1.itUniversita di Roma \La Sapienza"Via Salaria 113, 00198 Roma, ItalyMaurizio Lenzerinilenzerini@dis.uniroma1.itUniversita di Roma \La Sapienza"Via Salaria 113, 00198 Roma, ItalyAbstractmodern formalisms used Databases Artificial Intelligence describingapplication domain based notions class (or concept) relationship amongclasses. One interesting feature formalisms possibility defining class,i.e., providing set properties precisely characterize instances class.Many recent articles point several ways assigning meaningclass definition containing sort recursion. paper, argue that, insteadchoosing single style semantics, achieve better results adopting formalismallows different semantics coexist. demonstrate feasibility argument,presenting knowledge representation formalism, description logic ALCQ,characteristics. addition constructs conjunction, disjunction, negation,quantifiers, qualified number restrictions, ALCQ includes special fixpoint constructsexpress (suitably interpreted) recursive definitions. constructs enable usualframe-based descriptions combined definitions recursive data structuresdirected acyclic graphs, lists, streams, etc. establish several properties ALCQ,including decidability computational complexity reasoning, formulatingcorrespondence particular modal logic programs called modal mu-calculus.1. Introductionmodern formalisms used Databases Artificial Intelligence representingapplication domain based notions class (or concept) relationship amongclasses. example, object-oriented semantics data models developed Databasesdescribe data terms classes (sometimes called entity types) incorporate severalfeatures establishing various forms relationships classes. hand,notion class (often called concept frame) link among classes providedstructured formalisms Knowledge Representation (frame-based languages, semanticnetworks, description logics, etc.). Finally, notion also present several type systemsprogramming languages, specially based object-oriented paradigm.basically two ways using describing classes (concepts). first one,call prescriptive approach, description formalism allows expressingnumber properties class, thus prescribing constraints instances classmust satisfy. second one, call definitional approach, formalismallows providing definition class, i.e., set properties precisely character c 1997 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.fiDe Giacomo & Lenzeriniize instances class. prescriptive approach quite well understoodestablished, definitional approach still subject interesting debate, regardingnature semantic foundation. particular, well knownvarious ways assign meaning class definition contains sort recursion(Baader, 1990, 1991; Nebel, 1991; Beneventano & Bergamaschi, 1992; Beeri, 1990).paper, concerned semantic problems related definitionalapproach, arguing that, instead choosing single style semantics knowledgerepresentation formalism, achieve better results allowing different semantics coexist.discuss issue context Description Logics1 , logics originallydeveloped Knowledge Representation provide formal reconstruction frame-basedlanguages. Description logics describe domain interest terms concepts,represent classes individuals, roles, binary relations used specify properties attributes individuals well links individuals (Nebel, 1990). Startingatomic concepts, denoted simply name, complex concepts built using suitable set constructs. example, expression parent u male u 8child:maledenotes concept father (male parent) whose children male. symbol udenotes construct concept conjunction, 8 denotes universal role quantification.Typically, concepts structured hierarchies determined properties associatedthem. hierarchical structure defined way specific conceptsinherit properties general ones.introduce description logic, called ALCQ, extends well-known description logic ALC (Schmidt-Schau & Smolka, 1991) including called qualifiednumber restrictions, general form cardinality constraints roles,special fixpoint constructs, enable us capture various semantics recursivedefinitions within single formalism. Notably, availability constructs makespossible combine usual frame-based descriptions definitions recursive datastructures directed acyclic graphs, lists, streams, etc.establish several properties ALCQ, including decidability computational complexity reasoning, formulating correspondence particular modallogic programs called modal mu-calculus.Recent articles, (e.g., Bergamaschi & Sartori, 1992; Borgida, 1992), advocate usedescription logics unifying framework several types database knowledgerepresentation formalisms. Indeed, possible show that, depending constructs semantics used, one capture several database models programminglanguage type systems using description logics. Therefore, study presented paper merely confined description logics, also applicable representationformalisms.paper organized follows. Section 2, present basic notions regardingdescription logics fixpoints. Section 3, motivate approachdetailed discussion different semantics concept definitionsconsidered literature, argue formalism various semanticscoexist. Section 4, present one formalism, namely logic ALCQ,1. Also called Concept Languages Terminological Languages.88fiConcept Definitions Description Logicsdiscuss several properties. Section 5 study reasoning techniques ALCQexpose correspondence modal mu-calculus. Finally, Section 6, drawconclusions discuss open problems.2. Preliminariessection, brie present basic notions regarding description logics,fixpoints. interested reader referred (Nebel, 1990) (de Bakker, 1980)complete introduction subjects.2.1 Description LogicsDescription logics allow one represent domain interest terms conceptsroles. Concepts model classes individuals, roles model relationships classes.Starting atomic concepts (denoted A) atomic roles (denoted R),concepts roles described simply name, complex concepts roles builtmeans suitable constructs.section, concentrate description logic ALCQ, obtained wellknown description logic ALC (Schmidt-Schau & Smolka, 1991) including qualified number restrictions. cardinality constraints role fillers general form,role fillers constraint applies selected means generic conceptexpression, qualifier.ALCQ concepts (denoted C D, possibly subscript) composed inductivelyaccording following abstract syntax (n denotes natural number):C ::= j > j ? j :C j C1 u C2 j C1 C2 j 9R:C j 8R:C j ( n R:C ) j ( n R:C ):constructs independent. following equalities hold: > = :A,? = :>, 8R:C = :9R::C , ( n R:C ) = :( n + 1 R:C ).semantic point view, concepts interpreted subsets abstract domain,roles interpreted binary relations domain. precisely,interpretation = (I ; ) consists domain interpretation , interpretationfunction mapping every atomic concept subset every atomic role Rsubset .interpretation function extended complex concepts ALCQ (noteALCQ roles always atomic) follows:>I?I(:C )I(C1 u C2 )I(C1 C2 )I(9R:C )I(8R:C )I( n R:C )I( n R:C )I=========;, CC1I \ C2IC1I [ C2Ifs 2 j 9s0: (s; s0 ) 2 RI s0 2 C gfs 2 j 8s0: (s; s0 ) 2 RI implies s0 2 C gfs 2 j #fs0 j (s; s0) 2 RI s0 2 C g ngfs 2 j #fs0 j (s; s0) 2 RI s0 2 C g ng89fiDe Giacomo & Lenzerini#S denotes cardinality set .concept C satisfiable iff exists interpretation C 6= ;, otherwiseC unsatisfiable. concept C1 subsumed concept C2, written C1 v C1, iffevery interpretation , C1I C2I .knowledge expressed terms concepts roles assembled specialknowledge base, traditionally called TBox, consists finite (possibly empty) setassertions. order general possible, assume every assertionform inclusion assertion (or simply inclusion):C1 v C2without restriction form concepts C1 C2 . pair inclusionsform fC1 v C2 ; C2 v C1 g often written C1 C2 called equivalence assertion.interpretation satisfies inclusion C1 v C2 iff C1I C2I . interpretationmodel TBox K iff satisfies inclusions K.Let K TBox. say concept C satisfiable K, iff exists modelK C 6= ;, unsatisfiable otherwise. say concept C1 subsumedconcept C2 K, written K j= C1 v C2 , iff every model K, C1I C2I .2.2 Fixpointsbrie recall notions fixpoints. Consider equation:X = f (X )f operator 2S 2S (2S denotes set subsets set ). Everysolution E equation called fixpoint operator f (while every set Ef (E ) E called pre-fixpoint, every set E E f (E ) called post-fixpoint).general, equation one may either solution, finite numbersolutions, infinite number them. Among various solutions, smallestgreatest solutions (with respect set-inclusion) prominent position, exist.fundamental result due Tarski (Tarski, 1955) guarantees existence uniquenesssolutions case f monotonic wrt set-inclusion (), f monotonicwrt whenever E1 E2 implies f (E1 ) f (E2 ).Theorem 1 (Tarski) Let set, f operator 2S 2S monotonicwrt . Then:exists unique least fixpoint f , given TfE j f (E ) Eg.exists unique greatest fixpoint f , given SfE j E f (E )g.3. Concept Definitions Equationsanalyze notion concept definition detail. Let us ignore momentknowledge bases introduced previous section, let us considerdifferent kind assertion: definition statement. Let form definition statement(or simply definition) be:=def C90fiConcept Definitions Description Logicsatomic concept cannot appear left-hand side definitionstatements, C concept expression ALCQ. principle, =def C intendedprovide exact account concept terms C , i.e., define setindividuals satisfying C .specifying semantics definitions, need distinguish two differenttypes atomic concepts, namely, primitive concepts defined concepts. Given setdefinition statements, primitive concepts atomic concepts appearleft-hand side definition statement, whereas defined conceptsappear left-hand side definition statement.Given interpretation = (I ; ), interpretation function directly assignssubset primitive concepts, defined concepts. meaningdefined concept assigned definition statement =def C , extendinginterpretation function following requirement satisfied:AI = C :(1)Consider, example, definition statement:parent =def 9child:>:Note defined concept parent appear body definition statement.(1), definition statement provides definition concept parent,following sense: interpretation = (I ; ), parentI denotes single subset ,exactly one denoted (9child:>)I , i.e., fs j 9t:(s; t) 2 childI g. general, conceptdefined terms primitive already defined concepts, every interpretationexists unique way extend interpretation function defined concepts,hence doubt definition statement provides definition A.Now, consider following definition statement:=def 9child:A:Given interpretation = (I ; ), (1) statement interpreted equation:AI = fs 2 j 9t:(s; t) 2 childI 2 AI g:However equation specify univocally extend interpretation functiondefined concept A, since ; satisfies equation well set individualsmember infinite chain descendants also members.general, call recursive definition statements2 (or simply recursive definitions),definition statements form:=def F (A)F (A) stands concept subconcept3 . According (1), recursivedefinition =def F (A) interpreted simply sort equation specifying that, given2. Terminological cycles (Baader, 1990, 1991; Nebel, 1991). present discussion, sake simplicity, consider mutual recursive definitions, =def F (B ), B =def F (A). shall comeback point later on.3. subconcept concept C substring C (including C itself) concept, accordingsyntax rules.091fiDe Giacomo & Lenzeriniinterpretation , subset tied defined concept must satisfyequation AI = F (A)I , i.e., must one solutions. Observe that, general, eithernone, one, several subsets may exist solutions equation.Another convenient way consider definition statement associate it, everyinterpretation , operator subsets subsets instead equation,fixpoints operator correspond solutions equation. example,definition =def 9child:A associate operator:S:fs 2 j 9t:(s; t) 2 childI 2 ginterpretation . general either none, one multiple solutions existequation associated recursive definition, either none, one multiplefixpoints exist corresponding operator.situation word \definition" seems misleading: body definitiongive complete account defined concept. additional criterion neededselecting solutions associated equation, equivalently, fixpoints associatedoperator. words addition (1), criterion needed extend univocallyinterpretations defined concepts. observation led various semantics,interprets recursive definitions differently, choosing, prioriall, solutions, equivalently fixpoints, assigned definingconcept recursive definition4.3.1 Different Semantics Recursive Definitionsliterature description logics, three semantics recursive definitionsproposed (see Nebel, 1991):Descriptive SemanticsLeast Fixpoint SemanticsGreatest Fixpoint Semanticssemantics \right" one long standing matter debate.describe three semantics interprets recursive definitions, presentexamples showing choice semantics depends fact upon conceptdefined. first, stressed descriptive semantics ableassign meaning general inclusion assertions C1 v C2 introduced previous section.According Descriptive Semantics, recursive definition =def F (A) constraint stating that, , AI solution equation AI = F (A)I .descriptive semantics, =def 9child:A simply states individuals classchild class A, individuals child classclass A, better specified. general descriptive semantics appropriate properly define recursive concepts, sense that, given4. remark non-recursive definition interpreted various semantics way, since,every , equation associated single solution.92fiConcept Definitions Description Logicsinterpretation , unable assign unique subset defined conceptrecursive definition.fact descriptive semantics definition statements indistinguishableequivalence assertions introduced previous section. words, meaningassigned =def F (A) assigned equivalence assertion F (A).Although equivalence assertions used specify if-and-only-if constraints,provide proper definitions recursion involved. example, expressfact humans mammals parents humans, converse,mammals parents humans humans themselves, termsequivalence assertion:human mammal u 9parent:> u 8parent:human:Similarly may require horses satisfy analogous property:horse mammal u 9parent:> u 8parent:horse:However two equivalence assertions define human horse shown,e.g., fact (correctly) imply humans horses vice-versa(in contrast happen fixpoint semantics used, see below).Least Fixpoint Semantics interprets recursive definition statement =def F (A)assigning smallest possible extension interpretation , amongsatisfy AI =def F (A)I { i.e., least fixpoint corresponding operator. factalways assumed operator associated definition statement monotonic,Theorem 1 applies least fixpoint exists unique, i.e., correspondingequation unique smallest solution. Hence least fixpoint semanticsrecursive definition statement =def F (A) defines concept A. easy verifyexample =def 9child:A, least fixpoint semantics leads us identify ?.Indeed empty set solution equation associated statement,obviously smallest solution. Similarly interpret definition statement:human =def mammal u 9parent:> u 8parent:humanleast fixpoint semantics, humanI = ; interpretation .Observe if, above, adopt similar definition horse, get horseI = ;,trivially infer horse human.least fixpoint semantics particularly suitable providing inductive definitionsconcepts. example, consider class list (LIST) defined follows:EMPTY-LIST LIST.NODE exactly one successor LIST LIST.Nothing else LIST.first two conditions captured following recursive definition statement5 :list =def emptylist (node u ( 1 succ:>) u 9succ:list)5. Additionally specify two concepts emptylist node disjoint.93fiDe Giacomo & Lenzerini( 1 succ:>) forces succ function. enforce third condition mustassign smallest possible extension list. Thus, class LISTs naturallydefined means definition statement, interpreted according leastfixpoint semantics.Greatest Fixpoint Semantics interprets recursive definition statement =def F (A)assigning largest possible extension interpretation , amongsatisfy AI =def F (A)I { i.e., greatest fixpoint corresponding operator. Again,assumed operator monotonic order guaranty existence unicitygreatest fixpoint (Theorem 1). least fixpoint semantics, greatestfixpoint semantics recursive definition statement =def F (A) defines concept A.example, considering definition statement =def 9child:A, greatest fixpointsemantics leads us interpret class individuals childturn member A.least fixpoint semantics naturally captures classes defined induction,greatest fixpoint semantics naturally captures classes individuals whose structure nonwell-founded co-inductive. example class STREAMs, modeling wellknown linear data structure NODE first element, reststructure STREAM itself. Note streams similar lists except listsconsidered finite sequences nodes, streams infinite sequences nodes.class captured following recursive definition statement:stream =def node u ( 1 succ:>) u 9succ:streamproviso greatest possible extension assigned stream.Finally, consider greatest fixpoint semantics recursive definition statements:human =def mammal u 9parent:> u 8parent:humanhorse =def mammal u 9parent:> u 8parent:horse:Although assign empty extension human horse leastfixpoint semantics does, rather counter intuitive consequencehuman horse, since humanI = horseI interpretation . generaltypes fixpoint semantics particular name used denote defined conceptimpact interpretation it, since meaning defined conceptcompletely specified definition statement.3.2 Least Greatest Fixpoints Concept Constructsconsiderations show arguing \right" semantics recursive definitions really issue. captures essential use recursiveequations: descriptive semantics appropriate specify constraints conceptsone extends general inclusion assertions introduced Section 2;least fixpoint semantics appropriate define structure inductively; greatest fixpointsemantics appropriate define non-well-founded structures. Generally, may needthree knowledge base, order model various propertiesdifferent concepts.94fiConcept Definitions Description Logicsproposal paper exactly direction reconciling various semanticsknowledge base. pursued means logic incorporates twoconstructs, X:F (X ) X:F (X ) (the symbols X; Y; : : : stand concept variables),denoting, respectively, least fixpoint greatest fixpoint operator associateddefinition X =def F (X ), is, every , smallest solution greatestsolution equation X = F (X )I .approach, definition statements never appear TBox. Instead, knowledgebase simply set inclusion assertions (interpreted according descriptive semantics) involve fixpoint constructs. example, order specify propertiesconcepts list, stream, human horse use following assertions6 :listX:emptylist (node u ( 1 succ:>) u 9succ:X )stream X:node u ( 1 succ:>) u 9succ:Xhuman mammal u 9parent:> u 8parent:humanhorse mammal u 9parent:> u 8parent:horse:Note that, add knowledge base equivalence assertion:mgm X : mammal u 9parent:> u 8parent:Xdefining concept mgm (mammal generated mammal), correctly turnshuman horse subsumed mgm.availability least greatest fixpoint constructs, allowing different semanticsused TBox, makes possible model abstract classes, alsoinductively co-inductively defined data structures, lists streams.particularly important objective integrate class-based representation formalismsprogramming systems (declarative procedural), order make formalismsuseful practice. Furthermore, possibility nesting fixpoints, thusgoing beyond simple equational format motivated introduction.example, consider following one:Among inhabitants planet \Plonk", disease called \foo" quitecommon. disease manifests two forms: \visible" one\latent" one, rather intricate hereditary pattern. Individualsvisible form transmit visible form least one (say first) directdescendant (obviously, direct descendant), ill descendantsturn same, on, someone transmits latent formdisease. precisely, along chain descendants, visible formdisease sooner later interrupted, either individual directdescendant individual transmits descendant latent form.direct descendants (if any) individual latent form inheritvisible form. pattern goes like this, generation generation, forever.hereditary pattern (foo hp) disease defined follows:foo hp X:Y:((visible u (9child:Y 8child:?))t(latent u 8child:(visible u X )))6. also include assertion emptylist v :node, specifying concepts emptylist nodedisjoint.95fiDe Giacomo & Lenzerinivisible latent denote visible latent form respectively disease,assumed disjoint (latent v :visible).4. Description Logic ALCQprovide formal account meaning fixpoint constructs introducingdescription logic, called ALCQ, obtained adding constructs ALCQ.make use notions scope, bound free occurrences variables, closedformulae, etc. definitions notions analogues first-orderlogic, treating quantifiers. addition, use symbol abstractioneither .primitive symbols ALCQ atomic concepts, (concept) variables (denotedX; Y; : : :), atomic roles roles admitted logic.Concepts ALCQ formed inductively according following abstract syntax:C ::= j > j ? j :C j C1 u C2 j C1 C2 j 9R:C j 8R:C j ( n R:C ) j ( n R:C ) jX:C j X:C j Xdenotes atomic concept, R atomic role, n natural number, X variable,restriction variable X occurring positively C boundedfixpoint X:C . say variable X occurs positively concept C , everyfree occurrence X scope even number negations, considering conceptsC 0 ( n R:C 0 ) scope one negation.two fixpoint constructs mutually definable: X:C = :X::C [X=:X ] (whereC [X=:X ] concept obtained substituting free occurrences X concept:X ).before, interpretation = (I ; ) consists domain interpretation ,interpretation function , maps every atomic concept subset , everyatomic role subset . presence free variables allow usextend interpretation function directly every concept logic. reasonintroduce valuations. valuation interpretation mapping variablessubsets .Given valuation , denote [X=E ] valuation identical except[X=E ](X ) = E . words, every variable :(X[X=E ](Y ) = E(Y ) ifif YY =6= XLet interpretation valuation . assign meaning conceptslogic associating extension function , mapping concepts subsets, follows:96fiConcept Definitions Description LogicsXIAI>I?I(:C )I(C1 u C2 )I(C1 C2 )I(9R:C )I(8R:C )I( n R:C )I( n R:C )I(X:C )I(X:C )I=============(X )AI;, CI(C1 )I \ (C2 )I(C1 )I [ (C2 )Ifs 2 j 9s0: (s; s0 ) 2 RI s0 2 CI gfs 2 j 8s0: (s; s0 ) 2 RI implies s0 2 CI gfs 2 j #fs0 j (s; s0) 2 RI s0 2 CI g ngfs 2 j #fs0 j (s; s0) 2 RI s0 2 CI g ngj CI[X=E ] E gSfEfE j E CI[X=E ] glast two cases CI[X=E ] interpreted operator subsets E subsets. syntactic restriction enforced variables, operator guaranteedmonotonic wrt . Notice free variables appearing concept interpretedsimilarly atomic concepts.concept C satisfiable, exists interpretation valuationCI 6= ;, otherwise C unsatisfiable. concept C1 subsumed concept C2 ,written C1 v C2 , every interpretation every valuation , (C1 )I (C2 )I .ALCQ TBox finite (possibly empty) set inclusion assertions C1 v C2C1 C2 closed concepts ALCQ. before, use equivalence assertionsform C1 C2 abbreviation fC1 v C2 ; C2 v C1 g.interpretation satisfies inclusion assertion C1 v C2 , (C1 )I (C2 )I ,valuation (being C1 C2 closed, hence independent valuations).model TBox K, satisfies inclusion assertions K. say TBoxK satisfiable, model. Observe inclusion assertions K interpretedaccording descriptive semantics.say TBox K logically implies inclusion assertion C1 v C2 , written K j=C1 v C2, every model K every valuation , (C1 )I (C2 )I .4.1 Properties Fixpoint Constructsfollowing, use notation C (X ) indicate variable X occurs freeconcept C (other variables could occur free C well), notation C (D),concept, shorthand C (X )[X=D] (i.e., concept obtained substitutingfree occurrences X C (X ) concept D).Let us comment brie simple properties logic. First, conceptX:C (X ) equivalent concept Y:C (Y ), long free X C (X ). Second,extension function assign closed concept value independent actualvaluation . Hence X:C , X occur C , equivalent C . Third, sinceX:C (X ) fixpoint C (X:C (X )) equivalent X:C (X ). Furthermore,concept X:C (X ) always subsumed concept X:C (X ).97fiDe Giacomo & Lenzerininext property substantial. Consider class single source finitedirected acyclic graphs (DAGs) defined inductively follows7:EMPTY-DAG DAG (base step).NODE connections connections DAGs, DAG (inductivestep).Nothing else DAG.Consider ALCQ TBox K containing two equivalence assertions:dag student X : emptydag (student u 9arc:> u 8arc:X )dag person X : emptydag (person u 9arc:> u 8arc:X )define concepts dag student dag person classes DAGs whosenodes students persons respectively. Assuming students persons, wantable infer DAGs students DAGs persons well. is, want:K j= student v person implies K j= dag student v dag person:turns ALCQ property holds. prove this, introducefollowing two theorems.Theorem 2 Let K ALCQ TBox, C two ALCQ conceptsvariable X occurs free positively. Then:K j= C v implies K j= X:C v X:D:Proof proceed contradiction8 . Assume CI DI holds models Kvaluations . suppose exists model K valuation(X:C )I 6 (X:D)I .First prove result = . Let individual (X:C )I(X:D)I . Now, have:2 (X:C )I iff 8E : (CI[X=E ] E implies 2 E )(2)62 (X:D)I iff 9E 0 : (DI[X=E ] E 0 62 E 0 ):(3)0set E 0 (3), following expression holds:CI[X=E ] DI[X=E ] E 0007. assume leaf DAG NODE arcs leading special DAG called EMPTY-DAG.alternative, one assume leaf DAG NODE connection all.latter case, definition dag would simplify dag =def node u 8arc:dag (in general forminductive definitions { i.e., base case inductive case { less apparent).8. uniformity, distinguish X occurs free not. Obviously X occur free,result trivial.98fiConcept Definitions Description Logicshence (2) 2 E 0 (3) 62 E 0 , impossible.proof = similar. Let individual (X:C )I (X:D)I .Now, have:2 (X:C )I iff 9E 00 : (E 00 CI[X=E ] 2 E 00)(4)62 (X:D)I iff 8E : (E DI[X=E ] implies 62 E ):(5)00set E 00 (4), following expression holds:E 00 CI[X=E ] DI[X=E0000]hence (4) 2 E 00 (5) 62 E 00 , impossible. 2defined means variable X occur positively concept C .Similarly say variable X occurs negatively concept C , every free occurrenceX scope odd number negations, considering concepts C 0 ( n R:C 0 )scope one negation.Theorem 3 Let K ALCQ TBox, D(X ) ALCQ concept variable Xfree variable. Then, ALCQ concepts C1 C2 :K j= C1 v C2 implies(K j= D(C1) v D(C2) X occurs positively D(X )K j= D(C2) v D(C1) X occurs negatively D(X )Proof prove result induction formation D(X ).Base case. D(X ) = X , result holds trivially.Inductive cases. D(X ) form :D0 (X ) j ( n R:C 0 ) , X occurs positively(negatively) D0 (X ) negatively (positively) D(X ). induction hypothesis K j=D0 (Ci ) v D0(Cj ) (where i; j 2 f1; 2g 6= j ) hence semantics constructsK j= D(Cj ) v D(Ci).D(X ) form D10 (X ) u D20 (X ) j D10 (X ) D20 (X ) j 8R:D0(X ) j ( n R:D0 (X )),X occurs positively (negatively) D0 (X ) D(X ). induction hypothesisK j= D0(Ci) v D0(Cj ) hence semantics constructs K j= D(Ci) v D(Cj ).remains prove result D(X ) = Y:D0 (X ) (Y 6= X ). case,syntactic restriction enforced, occurs positively D0 (X ) hence Theorem 2K j= D0(Ci) v D0(Cj ) implies K j= Y:D0(Ci ) v Y:D0 (Cj ), thus induction hypothesisdone. 2Going back example, can, fact, infer DAGs students also DAGspersons. Indeed, applying Theorem 3 Theorem 2, K j= student vperson implies K j= X:emptydag (studentu9arc:>u8arc:X ) v X:emptydag (person u9arc:> u 8arc:X ).99fiDe Giacomo & Lenzerini4.2 Internalizing Assertionsshow logical implication ALCQ TBoxes (thus also satisfiability ALCQTBoxes) reducible unsatisfiability single ALCQ concept. prove result,introduce notions generated sub-interpretation sub-valuation9.Let = (I ; ) interpretation,valuation , 2 individual.define interpretation = ( ; ), valuation s, follows:= fs0 2 j (s; s0) 2 (R1I [ : : : [ RmI )g.atomic role Ri, RiI = RiI \ (I ).atomic concept A, AI = AI \ .variable X , s(X ) = (X ) \ .call sub-interpretation generated s, sub-valuation generateds.generated sub-interpretations sub-valuations state following lemma.Lemma 4 Let C ALCQ concept. interpretation , valuation, individual 2 , have:8t 2 : 2 CI iff 2 CIss :Proof Without loss generality, consider concepts formed according followingsimplified abstract syntax: C ::= j ? j :C j C1 u C2 j 9R:C j ( n R:C ) j X:C j X:prove result induction number nested fixpoint constructs. Basecase. C fixpoint constructs, thesis proven inductionformation C .Inductive case. assume thesis holds concepts C k nested fixpointconstructs, prove concepts X:C k + 1. recall that, TarskiKnaster Theorem fixpoints (Tarski, 1955), 2 (X:C )I iff exists ordinal ff2 (ff X:C )I , (ff X:C )I defined transfinite induction as:(0 X:C )I = ;(ff+1 X:C )I = CI[X=(ff X:C ) ]( X:C )I = Sff< (ffX:C )I , limit ordinal.Hence proceed transfinite induction ordinals ff.Base case transfinite induction. 0 X:C defined ?, thus trivially2 (0 X:C )I iff 2 (0 X:C )Iss .Successor case transfinite induction. want show 2 (ff+1 X:C )I iff 2(ff+1 X:C )Iss , reduces to:2 CI[X=(ff X:C ) ] iff 2 CIss[X=(ff X:C )ss ]:9. Together notions play role generated sub-model modal logics.100(6)fiConcept Definitions Description Logicsprove this, start showing that:2 CIss[X=(ff X:C )ss ] iff 2 C(Is[X=(ff X:C ) ])s :(7)Notice two valuations may differ value X . holds that:2 XIss[X=(ff X:C )ss ] iff 2 X(Is[X=(ff X:C ) ])s ;(8)straightforward induction formation C (7) holds well.Let us prove (8). write as:2 s[X=(ff X:C )Iss ](X ) iff 2 ([X=(ff X:C )I ])s (X );since 2 , reduces2 (ff X:C )Iss iff 2 (ff X:C )I :holds transfinite inductive hypothesis.Now, since C contains k fixpoint constructs, inductive hypothesis k, have:2 CI[X=(ff X:C ) ] iff 2 C(Is[X=(ff X:C ) ])s :Hence, considering (6) (7), follows indeed 2 (ff+1 X:C )I iff 2 (ff+1 X:C )Iss .Limit case transfinite induction. Let limit ordinal, 2 ( X:C )I iffexists ordinal ff < 2 (ff X:C )I . transfinite induction hypothesis,holds that: 2 (ff X:C )I iff 2 (ff X:C )Iss , thus:2 ( X:C )I iff 2 ( X:C )Iss :completes transfinite induction. ordinals ff holds that:2 (ff X:C )I iff 2 (ff X:C )Iss :induction nesting fixpoint constructs completed well, henceproven lemma. 2ready state result mentioned above.Theorem 5 Let K = fC1 v D1 ; : : : ; Cq v Dq g ALCQ TBox, C twoALCQ concepts. K j= C v ALCQ concept:X:(8R1 :X u : : : u 8Rm :X u CK) u C u :D(9)unsatisfiable, R1 ; : : : ; Rm atomic roles appearing K, CK = (:C1D1 ) u : : : u (:Cq Dq ).101fiDe Giacomo & LenzeriniProof part. contradiction. Assume (9) satisfiable, supposeK 6j= C v D, i.e., exists interpretation , valuation ,model K CI 6 DI . follows that, exists individual 22 CI 2 (:D)I . hand, fact model K implies(CK )I = , thus (X:(8R1 :X u : : : u 8Rm :X u CK ))I = .2 (X:(8R1 :X u : : : u 8Rm:X u CK ) u C u :D)I , i.e., (9) satisfiable, contradictinghypotheses.part. proceed contradiction. Assume K j= C v D. suppose(9) satisfiable, i.e., exists interpretation , valuation ,individual 2 , 2 (X:(8R1 :X u : : : u 8Rm :X u CK ) u C u :D)I .consider sub-interpretation = (I ; Iss ) sub-valuationgenerated s. one hand, clearly (CK )Iss = , hence modelK. hand Lemma 4 2 (X:(8R1 :X u : : : u8Rm :X u CK ) u C u:D)Iss ,follows satisfy subsumption C v D, contradicting hypotheses.2result states satisfiability ALCQ concepts logical implicationALCQ TBoxes (and thus satisfiability ALCQ TBoxes) distinct reasoningtasks. Hence following limit attention concept satisfiability withoutloss generality.5. Reasoning Fixpointssection concentrate developing reasoning methods check satisfiabilityconcepts involving fixpoints. particular, exhibit correspondence ALCQwell-known logic programs, called modal mu-calculus (Kozen, 1983; Kozen &Parikh, 1983; Streett & Emerson, 1984, 1989), recently investigatedexpressing temporal properties reactive parallel processes (Stirling, 1992; Larsen,1990; Cleaveland, 1990; Winsket, 1989; Dam, 1992).get better insight correspondence two logics, first studysublanguage ALC obtained ALCQ leaving qualified number restrictions10 .Then, study full logic ALCQ.5.1 Reasoning ALCLet us introduce modal mu-calculus formally. Formulae ; ; : : : modal mu-calculusformed inductively atomic formulae A; : : : variables X; : : : accordingfollowing abstract syntax:; ::= j > j ? j : j ^ j _ j hai j [a] j X: j X: j Xgeneric element set labels L, every bounded occurrence everyvariable X must scope even number negation signs.10. Observe that, Theorem 5 qualified number restrictions play role. Hence exactly reductionlogical implication unsatisfiability holds ALC well. allows us restrict attentionsatisfiability only.102fiConcept Definitions Description Logicssemantics modal mu-calculus based notions (Kripke) structurevaluation. Kripke structure triple (S ; fRi j 2 Lg; V ), set states,Ri binary relation , V mapping atomic formulae subsets. valuation mapping variables subsets . Kripke structurevaluation M, associated extension functiondefined inductivelyfollows:XM= (X )= V (A)>=?M= ;(:)M= ,( ^ )M= \( _ ) = [(hai)M= fs 2 j 9s0 : (s; s0 ) 2 Ra s0 2g0 : (s; s0 ) 2 Ra implies s0 2 g([a])M=f2j8(X:)M= SfE j [X=E ] E g(X:)M= fE j E[X=E ] gformula satisfiable exists Kripke structure valuation6= ;.following theorem basis correspondence ALC modalmu-calculus.Theorem 6 exists one-to-one linear-time function q mapping concepts ALCformulae modal mu-calculus that: ALC concept C , C satisfiableq(C ) satisfiable.Proof define q following way: q(A) = (atomic concepts mappedatomic formulae), q(X ) = X , q(>) = >, q(?) = ?, q(:C ) = :q(C ), q(9R:C ) =hRiq(C ) (atomic roles mapped labels), q(8R:C ) = [R]q(C ), q(X:C ) = X:q(C ),q(X:C ) = X:q(C ).interpretation = (I ; ) equivalent Kripke structure = (S ; fRi j 2Lg; V ) that: = ; L equal set names atomic roles interpreted; RR = RI atomic role R; V (A) = AI atomic concept A.addition, valuation equivalent valuation 0 M. extensionfunction associated extension function associated 0map, respectively, concept C corresponding formula q(C ) subset= . Hence thesis follows. 2follows may transfer decidability complexity results modalmu-calculus (Kozen & Parikh, 1983; Emerson & Jutla, 1988; Safra, 1988) ALC . Thus,immediately state complexity reasoning ALC conceptsALC TBoxes.Theorem 7 Satisfiability ALC concepts, satisfiability ALC TBoxes, logicalimplication ALC TBoxes EXPTIME-complete problems.103fiDe Giacomo & LenzeriniProof satisfiability problem modal mu-calculus EXPTIME-complete (Emerson& Jutla, 1988), hence Theorem 6 Theorem 5 thesis follows. 25.2 Reasoning ALCQNext exhibit mapping ALCQ concepts formulae variant modal mucalculus, called deterministic modal mu-calculus, syntax modalmu-calculus, interpreted deterministic Kripke structures, Kripke structures = (S ; fRi j 2 Lg; V ) relations Ri partial functions (Streett &Emerson, 1984).Let us ignore moment qualified number restriction constructs. FormulaeALCQ without qualified number restrictions are, fact, formulae modal mucalculus, shown previous section. using well-known technique developedpropositional dynamic logic (Parikh, 1981), (nondeterministic) modal mu-calculus formulae reduced deterministic modal mu-calculus formulae (Streett & Emerson,1984), shown below.use following notations usual operations binary relations: chaining,exive transitive closure, + transitive closure, , converse. also usefollowing abbreviations:[R ][R+ ]hRhR+iX:( ^ [R]X )[R][R ]X:( _ hRiX )hRihR i:reduction follows: formula , recursively replace subformulaeform [R] [R][(Rnew ) ] subformulae form hRi hRih(Rnew ) i,Rnew new symbol R Rnew resulting formula interpretedpartial functions. Let us call resulting formula 0 , satisfiable0 satisfiable.brie sketch reasoning behind proof statement. directioneasy: suces observe = (S ; fRDi j 2 LD g; V ) model 0 ,transform model = (S ; fRi j 2 Lg; V ) defining = ,L = LD , new, RR = RDR (RDnew ) , V = V . direction follows.recall nondeterministic deterministic modal mu-calculus tree modelproperty (Streett & Emerson, 1989, 1984): formula model tree model,i.e., model form tree11 . without loss generality restrictattention tree models only. one-to-one transformation tree models= (S ; fRTi j 2 LT g; V ) (tree) models B = (S B ; fRBi j 2 LB g; V B )0 . Indeed, put B = , V B = V , LB = LT , given state x 211. Given model get tree model simply \unfolding" original one.104fiConcept Definitions Description LogicsRTR -successors z1; : : : ; zl ,12 put (x; z1 ) 2 RBR , (zi ; zi+1 ) 2 RBRnew , = 1; : : : ; l , 1.way (x; zi ) 2 RTR (x; zi ) 2 RBR (RBRnew ) .13remark required tree get B need recover\original" RTR -predecessor x state zi , namely need (RBR (RBRnew ) ),partial function, otherwise, given state zi , would know various(RBR (RBRnew ) ), -successors original RTR -predecessor x, therefore wouldable reconstruct B .interpreting R Rnew partial functions, easy express qualified number)-successors state. example:restrictions constraints chain (R Rnew( 3 R:) expressed[R][(Rnew ) ](: _ [(Rnew )+ ](: _ [(Rnew )+ ](: _ [(Rnew )+ ]:)))read \everywhere along chain R (Rnew ) three statesholds", corresponds exactly intended meaning. Similarly ( 3 R:)expressedhRih(Rnew ) i( ^ h(Rnew )+i( ^ h(Rnew )+ i))read \somewhere along chain R (Rnew ) least three statesholds", corresponds exactly intended meaning.discussion allows us state following result.Theorem 8 exists polynomial function mapping concepts ALCQ formulaedeterministic modal mu-calculus that: ALCQ concept C , C satisfiableu(C ) satisfiable.Proof function defined inductively follows:u(A)u(X )u(C1 u C1 )u(C1 C2 )u(:C )u(X:C )u(X:C )u(9R:C )u(8R:C )Xu(C1 ) ^ u(C2 )u(C1 ) _ u(C2 ):u(C )X:u(C )X:u(C )hRih(Rnew )iu(C )[R][(Rnew ) ]u(C )Rnew new role. Finally, ( n R:C ) ( n R:C ) mapped following=========formulae:12. implicitly assume finite branching tree model. done without lossgenerality since modal mu-calculus finite model property, hence unfolding finite modelget finite branching tree model. Note however would suce assume countablebranching tree model.13. Note construction similar one often used programming reduce n-ary treesbinary trees coding children node combination one child siblings.105fiDe Giacomo & Lenzeriniu(( n R:C )) =[R][(Rnew ) ](:u(C ) _ [(Rnew )+](:u(C )_[(Rnew )+ ](: : : (:u(C ) _ [(Rnew )+ ]:u(C )) : : :)))number nested formulae form :u(C ) _ [(Rnew )+ ] n,u(( n R:C )) =hRih(Rnew ) i(u(C ) ^ h(Rnew )+i(u(C )^h(Rnew )+i(: : : (u(C ) ^ h(Rnew )+iu(C )) : : :)))number nested formulae form u(C ) ^ h(Rnew )+ n , 1.u(C ) clearly polynomial size C (under usual assumption numbersC coded unary). Moreover, following technique (Parikh, 1981; Streett & Emerson,1984) exposed above, easy verify, induction formationconcept C , mapping preserves satisfiability. 2follows may transfer decidability complexity results deterministic modal mu-calculus (Streett & Emerson, 1984; Emerson & Jutla, 1988; Safra,1988) ALCQ. Thus, immediately state complexity reasoningALCQ concepts ALCQ TBoxes.Theorem 9 Satisfiability ALCQ concepts, satisfiability ALCQ TBoxes, logicalimplication ALCQ TBoxes EXPTIME-complete problems.Proof Satisfiability deterministic modal mu-calculus EXPTIME-complete problem(Streett & Emerson, 1984; Emerson & Jutla, 1988; Safra, 1988). Hence Theorem 8Theorem 5 thesis follows. 26. Discussion Conclusionwork presented paper stems (De Giacomo, 1993), basic ideasintroducing explicit fixpoint first presented, (De Giacomo & Lenzerini, 1994b),idea elaborated ALCQ first introduced.One main contributions work devise tight correspondencedescription logics fixpoints modal mu-calculus. respect remarkthat, ALC corresponds directly modal mu-calculus, full ALCQ correspondsvariant modal mu-calculus whose decidability complexity studied.precisely, notion essentially equivalent qualified number restrictionsindependently emerged modal logics, namely graded modalities (Van der Hoek& de Rijke, 1995; Van der Hoek, 1992; Fattorosi-Barnaba & De Caro, 1985; Fine, 1972).However combination fixpoints graded modalities investigatedsetting modal logics. Given tight correspondence ALCmodal mu-calculus, ALCQ considered modal mu-calculus augmented gradedmodalities. Hence results paper apply logic well.research reported paper bears several similarities one correspondence description logics propositional dynamic logics (Baader, 1991;106fiConcept Definitions Description LogicsSchild, 1991; De Giacomo & Lenzerini, 1994a, 1995; De Giacomo, 1995). fact characterize description logics based propositional dynamic logics role constructschaining, choice, test, exive transitive closure roles, limitedform fixpoint. role constructs easily expressed using explicit fixpointsintroduced here. suce resort following equivalences:9R1 R2 :C = 9R1:9R2:C9R1 R2:C = 9R1:C 9R2:C9R:C = X:(C 9R:X )9id(D):C = C u D:Note 8R :C = X:(C u 8R:X ). (Calvanese, De Giacomo, & Lenzerini, 1995)implicit form fixpoint advocated, called well-founded roleconstruct wf (R). explicit fixpoints, wf (R) expressed simply X:(8R:X ).proposal allowing fixpoint constructs explicitly formalism sharedstudy independently carried Schild (Schild, 1994)14 . main goalwork study expressive power computational complexitysubsumption satisfiability TBoxes expressed ALC (no fixpoint constructs),allow mutually recursive definitions. end, description logic definedcorresponds variant modal mu-calculus mutual fixpoints allowedrestrictions nested fixpoints enforced (Vardi & Wolper, 1984). wellknown mutual fixpoints re-expressed means nested ones (see, example,Park, 1976; de Bakker, 1980). consequence observation follows logicintroduced paper, expressive one analyzed (Schild, 1994) since,one hand, allows nesting fixpoints without restriction, handmakes possible state sophisticated forms cardinality constraints role fillersmeans qualified number restrictions.present work extended along several directions. conclude outliningtwo them.already noticed fixpoint constructs allow representing abstractclasses, also several data structures extensively used software development.believe characteristic important step towards satisfactory integrationdescription logics traditional declarative programming systems. Indeeddescription logic proposed paper provides powerful mechanisms data structuremodeling. particular, properties stated Section 4.1 base formulatenotion parametric concept15 . instance, expression (named dag [Z ])X : emptydag (Z u 9arc:> u 8arc:X )Z formal parameter, denotes class DAGs whose nodes left unspecified.class used several ways TBox. example, instantiatedbinding formal parameter actual parameters, thus getting, say, dag [student],dag [person], etc., concepts inheriting properties dag [Z ].14. (Schild, 1994) number restrictions considered.15. Note parametric concepts introduced also simpler logics include fixpointconstructs.107fiDe Giacomo & LenzeriniAlthough ALCQ powerful logic, lacks construct inverse rolesneeded example correctly capture notions (finite) TREE, BINARY-TREE, etc.Indeed, define concept TREE (an EMPTY-TREE TREE; NODEone parent, children, children TREEs, TREE; nothing elseTREE) write tree X : empty tree (node u ( 1 child, :>) u9child:>u8child:Xchild, denotes inverse child. Notice introduction inverse rolespose diculty semantical point view; however, impactreasoning method needs investigated. generally, wide variety conceptconstructs studied conjunction fixpoints. research description logicsrelated propositional dynamic logics (De Giacomo & Lenzerini, 1994a, 1995; Calvaneseet al., 1995; De Giacomo, 1995) may give us hints proceed along direction.ReferencesBaader, F. (1990). Terminological cycles KL-ONE-based knowledge representation languages. Proc. 8th Nat. Conf. Artificial Intelligence (AAAI-90), pp.621{626 Boston, Ma.Baader, F. (1991). Augmenting concept languages transitive closure roles: alternative terminological cycles. Proc. 12th Int. Joint Conf. ArtificialIntelligence (IJCAI-91) Sydney, Australia.Beeri, C. (1990). formal approach object-oriented databases. Data KnowledgeEngineering, 5, 353{382.Beneventano, D., & Bergamaschi, S. (1992). Subsumption complex object data models.Proc. 4th Int. Conf. Database Theory (ICDT-92), No. 646 LectureNotes Computer Science, pp. 357{375. Springer-Verlag.Bergamaschi, S., & Sartori, C. (1992). taxonomic reasoning conceptual design. ACMTransaction Database Systems, 17 (3), 385{422.Borgida, A. (1992). type systems knowledge representation: Natural semanticsspecifications description logics. Journal Intelligent Cooperative InformationSystems, 1 (1), 93{126.Calvanese, D., De Giacomo, G., & Lenzerini, M. (1995). Structured objects: modelingreasoning. Proc. 4th Int. Conf. Deductive Object-Oriented Databases(DOOD-95), Lecture Notes Computer Science. Springer-Verlag.Cleaveland, R. (1990). Tableaux-based model checking propositional mu-calculus.Acta Informatica, 27, 725{747.Dam, M. (1992). CTL* ECTL* fragments modal mu-calculus. ProceedingCol. Trees Algebra Programming, No. 581 Lecture Notes ComputerScience, pp. 145{164. Springer-Verlag.de Bakker, J. (1980). Mathematical Theory Program Correctness. Prentice-Hall.108fiConcept Definitions Description LogicsDe Giacomo, G. (1993). Reconciling different semantics concept definition (extendedabstract). Proc. 1st COMPULOG Net Meeting Knowledge RepresentationReasoning Systems (CNKRR-93).De Giacomo, G. (1995). Decidability Class-Based Knowledge Representation Formalisms.Ph.D. thesis, Dipartimento di Informatica e Sistemistica, Universita di Roma \LaSapienza".De Giacomo, G., & Lenzerini, M. (1994a). Boosting correspondence descriptionlogics propositional dynamic logics. Proc. 12th Nat. Conf. ArtificialIntelligence (AAAI-94), pp. 205{212. AAAI-Press/the MIT-Press.De Giacomo, G., & Lenzerini, M. (1994b). Concept language number restrictionsfixpoints, relationship mu-calculus. Proc. 11th Eur. Conf.Artificial Intelligence (ECAI-94), pp. 411{415. John Wiley Sons.De Giacomo, G., & Lenzerini, M. (1995). What's aggregate: foundation descriptionlogics tuples set. Proc. 14th Int. Conf. Artificial Intelligence(IJCAI-95).Emerson, E. A., & Jutla, C. S. (1988). complexity tree automata logicsprograms. Proc. 20th An. Symp. Foundations Computer Science(FOCS-88), pp. 328{337.Fattorosi-Barnaba, M., & De Caro, F. (1985). Graded modalities I. Studia Logica, 44,197{221.Fine, K. (1972). many possible worlds. Notre Dame Journal Formal Logic, 13 (4),516{520.Kozen, D. (1983). Results propositional mu-calculus. Theoretical Computer Science,27, 333{355.Kozen, D., & Parikh, R. (1983). decision procedure propositional mu-calculus.Proc. 2nd Work. Logic Programs, No. 164 Lecture Notes ComputerScience, pp. 313{325. Springer-Verlag.Larsen, K. J. (1990). Proof systems satisfiability Hennessy-Milner logic recursion.Theoretical Computer Science, 72, 265{288.Nebel, B. (1990). Reasoning Revision Hybrid Representation Systems. No. 422Lecture Notes Artificial Intelligence. Springer-Verlag.Nebel, B. (1991). Terminological cycles: Semantics computational properties. Sowa,J. F. (Ed.), Principles Semantic Networks, pp. 331{361. Morgan Kaufmann, LosAltos.Parikh, R. (1981). Propositional dynamic logic programs: survey. Proc.1st Work. Logic Programs, No. 125 Lecture Notes Computer Science, pp.102{144. Springer-Verlag.109fiDe Giacomo & LenzeriniPark, D. (1976). Finiteness mu-ineffable. Theoretical Computer Science, 3, 173{181.Safra, S. (1988). complexity !-automata. Proc. 20th An. Symp.Foundations Computer Science (FOCS-88), pp. 319{327.Schild, K. (1991). correspondence theory terminological logics: Preliminary report.Proc. 12th Int. Joint Conf. Artificial Intelligence (IJCAI-91), pp. 466{471Sydney, Australia.Schild, K. (1994). Terminological cycles propositional -calculus. Doyle, J.,Sandewall, E., & Torasso, P. (Eds.), Proc. 4th Int. Conf. PrinciplesKnowledge Representation Reasoning (KR-94), pp. 509{520 Bonn. MorganKaufmann, Los Altos.Schmidt-Schau, M., & Smolka, G. (1991). Attributive concept descriptions complements. Artificial Intelligence, 48 (1), 1{26.Stirling, C. (1992). Modal temporal logic. Abramsky, S., Gabbay, D. M., & Maibaum,T. S. E. (Eds.), Handbook Logic Computer Science, pp. 477{563. Clarendon Press,Oxford.Streett, R. S., & Emerson, E. A. (1984). propositional mu-calculus elementary.Proc. 6th Int. Col. Automata, Languages Programming, No. 172Lecture Notes Computer Science, pp. 465{472. Springer-Verlag.Streett, R. S., & Emerson, E. A. (1989). automata theoretic decision procedurepropositional mu-calculus. Information Control, 81, 249{264.Tarski, A. (1955). lattice-theoretical fixpoint theorem applications. Pacific JournalMathematics, 5, 285{309.Van der Hoek, W. (1992). semantics graded modalities. Journal AppliedNon-Classical Logics, 2 (1), 81{123.Van der Hoek, W., & de Rijke, M. (1995). Counting objects. Journal Logic Computation, 5 (3), 325{345.Vardi, M. Y., & Wolper, P. (1984). Automata theoretic techniques modal logicsprograms. Proc. 16th An. Symp. Foundations Computer Science(FOCS-84), pp. 446{456.Winsket, G. (1989). note model checking modal -calculus. Proc. 11thInt. Col. Automata, Languages Programming, No. 372 Lecture NotesComputer Science, pp. 761{772. Springer-Verlag.110fiJournal Artificial Intelligence Research 6 (1997) 177-209Submitted 10/96; published 5/97Connectionist Theory Refinement:Genetically Searching Space Network TopologiesDavid W. Opitzopitz@cs.umt.eduJude W. Shavlikshavlik@cs.wisc.eduDepartment Computer ScienceUniversity MontanaMissoula, MT 59812 USAComputer Sciences DepartmentUniversity Wisconsin1210 W. Dayton St.Madison, WI 53706 USAAbstractalgorithm learns set examples ideally able exploitavailable resources (a) abundant computing power (b) domain-specific knowledgeimprove ability generalize. Connectionist theory-refinement systems, use background knowledge select neural network's topology initial weights, proveneffective exploiting domain-specific knowledge; however, exploit available computing power. weakness occurs lack ability refinetopology neural networks produce, thereby limiting generalization, especiallygiven impoverished domain theories. present Regent algorithm uses(a) domain-specific knowledge help create initial population knowledge-based neural networks (b) genetic operators crossover mutation (specifically designedknowledge-based networks) continually search better network topologies. Experiments three real-world domains indicate new algorithm able significantlyincrease generalization compared standard connectionist theory-refinement system,well previous algorithm growing knowledge-based networks.1. IntroductionMany scientific industrial problems better understood learning samplestask. reason, machine learning statistics communities devote considerable research effort inductive-learning algorithms. Often, however, learningalgorithms fail capitalize number potentially available resources, domainspecific knowledge computing power, improve ability generalize. Usingdomain-specific knowledge desirable inductive learners start approximately correct theory achieve improved \generalization" (accuracy examplesseen training) significantly fewer training examples (Ginsberg, 1990; Ourston& Mooney, 1994; Pazzani & Kibler, 1992; Towell & Shavlik, 1994). Making effective useavailable computing power desirable because, many applications, importantobtain concepts generalize well induce concepts quickly. article, present algorithm, called Regent (REfining, Genetic Evolution, NetworkTopologies), utilizes available computer time extensively search neural-networkc 1997 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.fiOpitz & Shavliktopology best explains training data minimizing changes domain-specifictheory.Inductive learning systems utilize set approximately correct, domain-specificinference rules (called domain theory) describe currently knowndomain, called theory-refinement systems. Making use knowledgeshown important since rules may contain insight easily obtainablecurrent set training examples (Ourston & Mooney, 1994; Pazzani & Kibler, 1992;Towell & Shavlik, 1994). domains, expert created theory willingwait weeks, even months, learning system produce improved theory.Thus, given rapid growth computing power, believe important learningtechniques able trade expense large numbers computing cycles gainspredictive accuracy. Analogous anytime planning techniques (Dean & Boddy, 1988),believe machine learning researchers create better anytime learning algorithms.learning algorithms produce good concept quickly, continue searchconcept space, reporting new \best" concept whenever one found.concentrate connectionist theory-refinement systems, since shownfrequently generalize better many inductive-learning theory-refinementsystems (Fu, 1989; Lacher, Hruska, & Kuncicky, 1992; Towell, 1991). Kbann (Towell &Shavlik, 1994) example connectionist system; translates provideddomain theory neural network, thereby determining network's topology,refines reformulated rules using backpropagation (Rumelhart, Hinton, & Williams,1986). However, Kbann, connectionist theory-refinement systemsalter network topologies, suffer given impoverished domain theories { onesmissing rules needed adequately learn true concept (Opitz & Shavlik, 1995;Towell & Shavlik, 1994). TopGen (Opitz & Shavlik, 1995) improvementsystems; heuristically searches space possible network topologies addinghidden nodes neural representation domain theory. TopGen showed statisticallysignificant improvements Kbann several real-world domains (Opitz & Shavlik, 1995);however, paper empirically show TopGen nevertheless suffersconsiders simple expansions Kbann network.address limitation, broaden types topologies TopGen considersusing genetic algorithms (GAs). choose GAs two reasons. First, GAsshown effective optimization techniques ecient use globalinformation (Goldberg, 1989; Holland, 1975; Mitchell, 1996). Second, GAs inherentquality makes suitable anytime learning. \off-line" application mode(DeJong, 1975), GAs simulate many alternatives output best alternative seenfar.new algorithm, Regent, proceeds first trying generate, domaintheory, diversified initial population. produces new candidate networks viagenetic operators crossover mutation, networks trained usingbackpropagation. Regent's crossover operator tries maintain rule structurenetwork, mutation operator adds nodes network using TopGen algorithm. Hence, genetic operators specialized connectionist theory refinement.Experiments reported herein show Regent better able search network topologies TopGen.178fiConnectionist Theory Refinementrest paper organized follows. next section, brie argueimportance effectively exploiting data, theory, available computer timelearning process. review Kbann TopGen algorithms. presentdetails Regent algorithm Section 4. followed empirical resultsthree Human Genome Project domains. Section 6, discuss results, wellfuture work. review related work concluding.2. Using Data, Prior Knowledge, Available CPU Cyclessystem learns set labeled examples called inductive learner (alternately, supervised, empirical, similarity-based learner). output exampleprovided teacher, set labeled examples given learner calledtraining set. task inductive learning generate training set conceptdescription correctly predicts output future examples,training set. Many inductive-learning algorithms previously studied (e.g.,Michalski, 1983; Quinlan, 1986; Rumelhart et al., 1986). algorithms differconcept-representation language, method (or bias) constructingconcept within language. differences important since determineconcepts classifier induce.alternative inductive learning paradigm build concept descriptionset examples, querying experts field directly assembling setrules describe concept (i.e., build expert system; Waterman, 1986). problembuilding expert systems theories derived interviewing experts tendapproximately correct. Thus, expert-provided domain theory usuallygood first approximation concept learned, inaccuracies frequently exposedempirical testing.Theory-refinement systems (Ginsberg, 1990; Ourston & Mooney, 1994; Pazzani & Kibler,1992; Towell & Shavlik, 1994) systems revise theory basis collectionexamples. systems try improve theory making minimal repairs theorymake consistent training data. Changes initial domain theorykept minimum theory presumably contains useful information, evencompletely correct. hybrid learning systems designed learntheory data, empirical tests shown achieve high generalizationsignificantly fewer examples purely inductive-learning techniques (Ourston & Mooney,1994; Pazzani & Kibler, 1992; Towell & Shavlik, 1994). Thus, ideal inductive-learningsystem able incorporate background knowledge availableform domain theory improve ability generalize.indicated earlier, available computer time also important resource since (a) computing power rapidly increasing, (b) problems expert willing waitlengthy period improved concept. reasons, one develop \anytime"learning algorithms continually improve quality answer time. DeanBoddy (1988) defined criteria anytime algorithm be: (a) algorithmsuspended resumed minimal overhead, (b) algorithm stoppedtime return answer, (c) algorithm must return answers improve179fiOpitz & ShavlikxxxxOutputx xxxxInputFigure 1: classical regression example smooth function (the solid curve)fit noisy data points (the x's) probably better predictorhigh-degree polynomial (the dashed curve).time. criteria created planning scheduling algorithms,apply inductive learning algorithms well.1standard inductive learners, backpropagation (Rumelhart et al., 1986)ID3 (Quinlan, 1986), unable continually improve answers (at leastreceive additional training examples). fact, run long, algorithms tend\overfit" training set (Holder, 1991). Overfitting occurs learning algorithmproduces concept captures much information training examples,enough general characteristics domain whole. conceptsgreat job classifying training instances, poor job generalizingnew examples { ultimate measure success. help illustrate point, considertypical regression case shown Figure 1. Here, fitting noisy data high-degreepolynomial likely lead poor generalization.general framework use encouraging algorithm improve answertime quite simple. spend computer time considering many different possibleconcept descriptions, scoring possibility, always keeping description scoresbest. framework anytime respect scoring function. scoringfunction approximate measure generalization obviously still proneproblems overfitting; thus guarantee generalization monotonicallydecrease time. Nevertheless, assuming accurate scoring function, longconsidering wide range good possibilities, quality best concept likelyimprove longer period time.1. use term anytime learning differs Grefenstette Ramsey (1992); usemean continuous learning changing environment.180fiConnectionist Theory Refinement3. Review KBANN TopGengoal research exploit prior knowledge available computing cyclessearch neural network likely generalize best. proceedchoosing, initial guess, network defined Kbann algorithm.continually refine topology find best network concept. presentingnew algorithm (Regent), give overview Kbann algorithm wellinitial approach refining Kbann-created network's topology (TopGen).3.1 KBANN AlgorithmKbann (Towell & Shavlik, 1994) works translating domain theory consisting setpropositional rules directly neural network (see Figure 2). Figure 2a shows Prologlike rule set defines membership category a. Figure 2b represents hierarchicalstructure rules, solid lines representing necessary dependencies dotted linesrepresenting prohibitory dependencies. Figure 2c represents network Kbann createstranslation. sets biases nodes representing disjuncts outputnear 1 least one high-weighted antecedents satisfied, nodesrepresenting conjuncts must high-weighted antecedents satisfied (i.e., near1 positive links near 0 negative links). Otherwise activations near 0. Kbanncreates nodes b1 b2 Figure 2c handle two rules disjunctively defining b.thin lines Figure 2c represent low-weighted links Kbann adds allow rulesadd new antecedents backpropagation training. Following network initialization,Kbann uses available training instances refine network links. Refer Towell(1991) Towell Shavlik (1994) details.Kbann successfully applied several real-world problems, controlchemical plant (Scott, Shavlik, & Ray, 1992), protein folding (Maclin & Shavlik, 1993),: b, c.b : d, f, g.bb1b : d, f, i.c : h, j, k.(a)bce f g h j k(b)eb2fg h(c)cj kFigure 2: KBANN's translation knowledge base neural network. Panel (a) showssample propositional rule set Prolog (Clocksin & Mellish, 1987) notation,panel (b) illustrates rule set's corresponding and/or dependency tree,panel (c) shows resulting network created Kbann's translation.181fiOpitz & Shavlikfinding genes sequence DNA (Opitz & Shavlik, 1995; Towell & Shavlik, 1994),ECG patient monitoring (Watrous, Towell, & Glassman, 1993). case, Kbannshown produce improvements generalization standard neural networks smallnumbers training examples. fact, Towell (1991) favorably compared Kbannwide variety algorithms, including purely symbolic theory-refinement systems,version promoter splice-junction tasks include testbeds Section 5.training Kbann-created network alters antecedents existing rules,capability inducing new rules add additionalhidden nodes training. instance, Kbann unable add third ruleinferring b Figure 2's example. help illustrate point, consider followingexample. Assume Figure 2's target concept consists Figure 2a's domain theory plusrule:b :- d, e, g.Although trained Kbann network shown Figure 2c possible examplestarget concept, unable completely learn conditions true.topology Kbann network must modified order learn new rule.Studies show (Opitz & Shavlik, 1995; Towell, 1991) Kbann effectiveremoving extraneous rules antecedents expert-provided domain theory, generalization ability suffers given \impoverished" domain theories { theoriesmissing rules antecedents needed adequately learn true concept. ideal connectionist theory-refinement algorithm, therefore, able dynamically expandtopology network training.3.2 TopGen AlgorithmTopGen (Opitz & Shavlik, 1995) addresses Kbann's limitation heuristically searchingspace possible expansions knowledge-based neural network { networkwhose topology determined direct mapping dependencies domain theory(e.g., Kbann network). TopGen proceeds first training Kbann network,placing search queue. cycle, TopGen takes best network searchqueue, estimates errors occur network, adds new nodes responseestimates, trains new networks, places back queue. TopGen judgeserrors occur network using training examples increment two countersnode, one false negatives one false positives.Figure 3 illustrates possible ways TopGen add nodes one networks.symbolic rule base uses negation-by-failure, one decrease false negatives eitherdropping antecedents existing rules adding new rules rule base. Kbanneffective removing antecedents existing rules, unable add new rules;therefore, TopGen adds nodes, intended decreasing false negatives, fashionanalogous adding new rule rule base. existing node node, TopGenadds new node child (see Figure 3a), fully connects new node inputnodes. existing node node, TopGen creates new nodeparent original node another new node TopGen fully connectsinputs (see Figure 3c); TopGen moves outgoing links original node (AFigure 3c) become outgoing links new node.182fiConnectionist Theory RefinementExisting NodeDecrease False NegativesDecrease False Positives.........NewNodeNewNodeBBCNodeCNewNodeBC(a)(b)...CNodeNewNodeB...NewNode...BBCC(c)NewNode(d)Figure 3: Possible ways add new nodes knowledge-based neural network (arcs indicate nodes). decrease false negatives, wish broaden applicability node. Conversely, decrease false positives, wishconstrain node.symbolic rule base, one decrease false positives either adding antecedentsexisting rules removing rules rule base. Kbann effectively removerules, less effective adding antecedents rules unable invent (i.e.,constructively induce; Michalski, 1983) new terms antecedents. Thus TopGen adds newnodes, intended decrease false positives, fashion analogous adding newconstructively induced antecedents network. Figures 3b 3d illustratesdone (analogous Figures 3a 3c explained above). Refer Opitz Shavlik (1993;1995) details.TopGen showed statistically significant improvements Kbann several real-worlddomains, comparative experiments simpler approach adding nodes verifiednew nodes must added intelligent manner (Opitz & Shavlik, 1995).article, however, increase number networks TopGen considers searchshow increase generalization primarily limited first networksconsidered. Therefore, TopGen much \anytime" algorithm, rather firststep towards one. mostly due fact TopGen considers larger networks contain original Kbann network subgraphs; however, one increasesnumber networks considered, one also increase variety networks considered183fiOpitz & Shavliksearch. Broadening range networks considered searchtopology space major focus paper.4. REGENT Algorithmnew algorithm, Regent, tries broaden types networks TopGen considersuse GAs. view Regent two phases: (a) genetically searchingtopology space, (b) training network using backpropagation's gradientdescent method. Regent uses domain theory aid phases. uses theoryhelp guide search topology space give good starting point weightspace.Table 1 summarizes Regent algorithm. Regent first sets aside validation set(from part training instances) use scoring different networks. perturbs Kbann-produced network create initial set candidate networks. Next,Regent trains networks using backpropagation places population. cycle, Regent creates new networks crossing mutating networkscurrent population randomly picked proportional fitness (i.e.,validation-set correctness). trains new networks placespopulation. searches, Regent keeps network lowest validation-seterror best concept seen far, breaking ties choosing smaller networkapplication Occam's Razor. parallel version Regent trains many candidate networks time using Condor system (Litzkow, Livny, & Mutka, 1988),runs jobs idle workstations.diverse initial population broaden types networks Regent considerssearch; however, since domain theory may provide useful information maypresent training set, still desirable use theory generating initialpopulation. Regent creates diversity around domain theory randomly perturbingKbann network various nodes. Regent perturbs node either deleting it,adding new nodes manner analogous one TopGen's four methods addingGOAL: Search best network topology describing domain theory data.1. Set aside validation set training instances.2. Perturb Kbann-produced network multiple ways create initial networks, trainnetworks using backpropagation place population.3. Loop forever:(a) Create new networks using crossover mutation operators.(b) Train networks backpropagation, score validation set, placepopulation.(c) new network network lowest validation-set error seen far (breakingties preferring smallest network), report current best concept.Table 1: REGENT algorithm.184fiConnectionist Theory RefinementCrossover Two Networks:GOAL: Crossover two networks generate two new network topologies.1. Divide network's hidden nodes sets B using DivideNodes.2. Set forms one network, set B forms another. new network created follows:(a) network inherits weight w parent nodes j either also inheritedinput output nodes.(b) Link unconnected nodes levels near-zero weights.(c) Adjust node biases keep original function node (see text explanation).jiDivideNodes:GOAL:Divide hidden nodes sets B, probabilistically maintainingnetwork's rule structure.hidden node assigned set B:(i) Collect unassigned hidden nodes whose output linked either previouslyassigned nodes output nodes.(ii) set set B empty:node collected part (i), randomly assign set set B.ElseProbabilistically add nodes collected part (i) set set B. Equation 1shows probability assigned set A. probability assignedset B one minus value.Table 2: REGENT's method crossing networks.nodes. (Should happen multiple theories domain,used seed population.)4.1 REGENT's Crossover OperatorRegent crosses two networks first dividing nodes parent networktwo sets, B, combining nodes set form two new networks (i.e.,nodes two sets form one network, nodes two B sets form another).Table 2 summarizes Regent's method crossover Figure 4 illustratesexample. Regent divides nodes, one level2 time, starting level nearestoutput nodes. considering level, either set set B empty, cyclesnode level randomly assigns either set. neither set empty, nodesprobabilistically placed set. following equation calculates probability2. Although one define level several different ways, define node's level longest pathoutput node.185fiOpitz & ShavlikOriginalNetworksCrossedOutputOutputInputInputOutputOutputInputInputResultingNetworksFigure 4: REGENT's method crossing two networks. hidden nodesoriginal network divided sets B; nodes two setsform one new network, nodes two B sets form another. Grey linesrepresent low-weighted links added fully connect neighboring levels.given node assigned set A:Pj2A jwjijProb(node 2 setA) = P jw j + P jw j ;j 2A jij 2B ji(1)j 2 means node j member set wji weight value nodenode j . probability belonging set B one minus probability.probabilities, Regent tends assign set nodes heavily linkedtogether. helps minimize destruction rule structure crossed-overnetworks, since nodes belonging syntactic rule connected heavily linkedweights. Thus, Regent's crossover operator produces new networks crossing-over rules,rather simply crossing-over nodes.Regent must next decide connect nodes newly created networks.First, new network inherits weight values parents links (a) connecttwo nodes inherited new network, (b) connect inherited hiddennode input output node, (c) directly connect input node output node.adds randomly set, low-weighted links unconnected nodes consecutivelevels.Finally, adjusts bias nodes help maintain original function.instance, Regent removes positively weighted incoming link node,decrements node's bias subtracting product link's magnitude186fiConnectionist Theory Refinementaverage activation (over set training examples) entering link.bias node needs slightly less sum positive weightsincoming links (see Towell Shavlik, 1994 details). Regent incrementsbias node analogous amount removes negatively weighted incominglinks (since bias node slightly greater sum negativeweights incoming links node inactive incoming negativelyweighted linked nodes active positively weighted linked nodes inactive).4.2 REGENT's Mutation OperatorRegent mutates networks applying variant TopGen. Regent uses TopGen'smethod incrementing false-negatives false-positives counters node. Regent adds nodes, based values counters, way TopGen does.Since neural learning effective removing unwanted antecedents rules KNNs(see Section 3.1), Regent considers adding nodes, deleting them, mutation. Thus, mutation operator adds diversity population, still maintainingdirected, heuristic-search technique choosing add nodes; directednessnecessary currently unable evaluate thousand possiblenetworks per day.4.3 Additional DetailsRegent adds newly trained networks population validation-set correctness better equal existing member population. Regentreplaces member, replaces member lowest correctness (ties brokenchoosing oldest member). techniques (Goldberg, 1989), replacingmember nearest new candidate network, promote diverse populations; however,want promote diversity expense decreased generalization. futureresearch topic, plan investigate incorporating diversity-promoting techniquesable consider tens thousands networks.Regent considered Lamarckian3 , genetic-hillclimbing algorithm (Ackley, 1987),since performs local optimizations individuals, passes successful optimizationsoffspring. ability individuals learn smooth fitness landscapefacilitate subsequent learning. Thus, Lamarckian learning lead large increaselearning speed solution quality (Ackley & Littman, 1994; Farmer & Belin, 1992).5. Experimental Resultssection, test Regent three real-world Human Genome Project problemsaid locating genes DNA sequences (recognizing promoters, splice-junctions,ribosome-binding sites). domains, input short segment DNA nucleotides(about 100 elements long) task learn predict DNA subsequence containsbiologically important site. domain also accompanied domain theory generatedDNA expert (M. Noordewier).3. Lamarckian evolution theory based inheritance characteristics acquired lifetime.187fiOpitz & Shavlikpromoter domain contains 234 positive examples, 702 negative examples, 31rules. splice-junction domain contains 1,200 examples distributed equally among threeclasses, 23 rules. Finally, ribosome binding sites (RBS) domain, contains 366positive examples, 1,098 negative examples, 17 rules. (Note promoter data setdomain theory later version one appears Towell, 1994.) domainsavailable University Wisconsin Machine Learning (UW-ML) site via WorldWide Web (ftp://ftp.cs.wisc.edu/machine-learning/shavlik-group/datasets/)anonymous ftp (ftp.cs.wisc.edu, machine-learning/shavlik-group/datasets).first directly compare Regent TopGen Kbann. performlesion study4 Regent. particular, investigate value adding randomlycreated networks Regent's initial population examine utility Regent'sgenetic operators.5.1 Experimental Methodologyresults article ten-fold cross validation runs. ten-fold crossvalidation data set first partitioned ten equal-sized sets, set turnused test set classifier trains nine sets. fold, Regentrun population size 20. network trained using backpropagation. Parametersettings neural networks include learning rate 0.10, momentum term 0.9,number training epochs 20; first two standard settings 20epochs may fewer typically found neural network literature, set 20help avoid overfitting. set aside validation set consisting 10% trainingexamples Regent use scoring function.5.2 Generalization Ability REGENTsection's experiments compare test-set accuracy (i.e., generalization) RegentTopGen's. Figure 5 shows test-set error Kbann, TopGen, Regentsearch space network topologies. horizontal line graph resultsKbann algorithm. drew horizontal line sake visual comparison;recall Kbann considers single network. first point graph,one network considered, nearly three algorithms, since startKbann network; however, TopGen Regent differ slightly Kbann sincemust set aside part training set score candidate networks. NoticeTopGen stops improving considering 10 30 networks generalizationability Regent better TopGen's point. reason occasionalupward movements Figure 5 due fact validation set (or scoringfunction) inexact estimate true generalization error (as resultsten-fold cross validation).Figure 6 presents test-set error TopGen Regent consider500 candidate topologies. standard neural network results fully connected,single-layer, feed-forward neural network; fold, trained 20 networks containing100 hidden nodes used validation set choose best network. results4. lesion study one components algorithm individually disabled ascertaincontribution full algorithm's performance (Kibler & Langley, 1988).188fiConnectionist Theory Refinement10 %8%Ribosome Binding Sites6%KBANNTopGen4%REGENTTestSet Error2%6%4%Splice Junctions2%6%4%Promoters2%0100200300400Networks ConsideredFigure 5: Error rates three Human Genome problems.189500fiOpitz & Shavlikshow Kbann generalizes much better best standard networks, thusconfirming Kbann's effectiveness generating good network topologies. TopGenable improve Kbann network, Regent able significantly decrease errorrate Kbann TopGen. (For benchmark purposes, Regent error rate3.9% ten-fold cross validation full Splice Junction dataset 3190 examplescommonly used machine learning researchers.)Table 3 contains number hidden nodes final networks produced Kbann,TopGen, Regent. results demonstrate Regent produces networkslarger Kbann's TopGen's networks (even though TopGen adds nodessearch). Regent's networks larger, necessarily mean\complex." inspected sample networks found largeportions network either used (e.g., weights insignificantly small)functional duplications groups hidden nodes.One could prune weights nodes Regent's search; however, pruningprematurely reduce variety structures available recombination crossover(Koza, 1992). Real-life organisms, instance, super uous DNA believedenhance rate evolution (Watson, Hopkins, Roberts, Argetsinger-Steitz, & Weiner,1987). However, pruning network size genetic search may unwise, onecould prune Regent's final network using, say, Hassibi Stork's (1992) Optimal BrainSurgeon algorithm. post-pruning process may increase future classification speednetwork, well increase comprehensibility possibly accuracy.5.3 Lesion Study REGENTsection, describe lesion study performed Regent. Since single runRegent takes four CPU days consider 500 networks, single ten-fold cross10.7010 %9.409.15TestSet Error8.238%7.836.626%5.25 4.92Key6.26Standard NN5.254.084.17KBANNTopGen4%REGENT2%RBSSplice JunctionsPromotersFigure 6: Test-set error rates TopGen REGENT consider 500 networks. Pairwise, one-tailed t-tests indicate Regent differs Standard NN, Kbann,TopGen 95% confidence level three problems.190fiConnectionist Theory RefinementDomainKbann TopGenRegentRBS1842.1 (9.3) 70.1 (25.1)Splice Junction2128.4 (4.1) 32.4 (12.2)Promoters3140.2 (3.3) 74.9 (38.9)Table 3: Number hidden nodes networks produced KBANN, TopGen,REGENT. columns show mean number hidden nodes found withinnetworks. Standard deviations contained within parentheses;report standard deviations Kbann since uses one network.validation takes (a minimum of) 40 CPU days. Therefore, given inherent similarityinvestigating various aspects Regent multiple datasets, feasiblerun experiments section 95% confidence level reached cases(assuming level actually exists). Nonetheless, results convey importantinformation various components Regent, and, shown previous section,complete Regent algorithm generate statistically significant improvementsexisting algorithms.5.3.1 Including Non-KNNs REGENT's Populationcorrect theory may quite different initial domain theory. Thus,section investigate whether one include, initial population networks,variety networks obtained directly domain theory. Currently, Regentcreates initial population always perturbing Kbann network. include networksobtained domain theory, first randomly pick number hiddennodes include network, randomly create hidden nodes network.adding new nodes randomly selected output hidden node using oneTopGen's four methods adding new nodes (refer Figure 3). Adding nodesmanner creates random networks whose node structure analogous dependencies foundsymbolic rule bases, thus creating networks suitable Regent's crossover mutationoperators.Table 4 shows test-set error Regent various percentages knowledge-basedneural networks (KNNs) present initial population. first row contains resultsinitializing Regent purely random initial population (i.e., population containsKNNs). second row lists results Regent creates half populationdomain theory, half randomly. Finally, last row contains resultsseeding entire population domain theory.results suggest including, initial population, networkscreated domain theory increases Regent's test-set error three domains.occurs randomly generated networks correct KNNs,191fiOpitz & Shavlik0% KNN50% KNN100% KNNRBS9.7%8.6%8.2%Splice Junction6.3%4.3%4.1%Promoters5.1%4.6%4.2%Table 4: Test-set error considering 500 networks. row gives pergentageKNNs present initial population. Pairwise, one-tailed t-tests indicateinitializing Regent 100% KNNs differs 0% KNNs 95% confidencelevel three domains; however, difference runs 50%100% KNNs significant level.thus offspring original KNN quickly replace random networks. Hence, diversity population suffers compared methods start whole populationKNNs. Assuming domain theory \malicious," therefore better seedentire population Kbann network. domain theory indeed maliciouscontain information promotes spurious correlations data, wouldreasonable randomly create \whole" population. Running Regentwithout domain theory allows one investigate utility theory.results also interesting GA point view. Forrest Mitchell (1993)showed GAs perform poorly complex problems basic building blocks either(a) non-trivial find (b) get split crossover. Seeding initial populationdomain theory (as Regent does) help define basic building blocksproblems.5.3.2 Value REGENT's MutationTypically GAs, mutation secondary operation sparingly used (Goldberg, 1989); however, Regent's mutation directed approach heuristically addsnodes KNNs provenly effective manner (i.e., uses TopGen). therefore reasonable hypothesize one apply mutation operator frequentlytraditionally done GAs. results section test hypothesis.Figure 7 presents test-set error Regent varying percentages mutation(versus crossover) creating new networks step 3a Table 1. graph plots fourcurves: (a) 0% mutation (i.e., Regent uses crossover), (b) 10% mutation, (c) 50%mutation, (d) 100% mutation. Performing mutations tests value solely usingcrossover, 100% mutation tests ecacy mutation operator itself. Note100% mutation TopGen different search strategy; instead keepingOPEN list heuristic search, population KNNs generated memberspopulation improved proportional fitness. two curves (10%50% mutation) test synergy two operators. Performing 10% mutation192fiConnectionist Theory Refinement10 %8%Ribosome Binding Sites6%0% Mutation10% Mutation4%50% Mutation100% MutationTestSet Error2%6%4%Splice Junctions2%6%4%Promoters2%0100200300400500Networks ConsideredFigure 7: Error rates REGENT different fractions mutation versus crossoverconsidering 500 networks. Arguably due inherent similarityalgorithms, limited number runs due computational complexity,results significant 95% confidence level.193fiOpitz & Shavlikcloser traditional GA viewpoint mutation secondary operation, 50%mutation means operations equally valuable. (Previous experimentssection used 50% mutation 50% crossover.)differences statistically significant, results nevertheless suggestsynergy exists two operations. Except middle portionpromoter domain, results show that, qualitatively, using operationstime better using either operation alone. fact, equally mixing mutationcrossover operator better three curves three domains Regentconsidered 500 networks. result particularly pronounced splice-junctiondomain.5.3.3 Value REGENT's CrossoverRegent tries cross rules networks, rather blindly crossingnodes. probabilistically dividing nodes network two setsnodes belonging rule tend belong set. section,test ecacy Regent's crossover comparing variantrandomly assigns nodes two sets (rather using DivideNodes Table 2).Table 5 contains results test 250 networks considered.first row, Regent-random-crossover, Regent randomly breaks hidden nodestwo sets, second row, Regent assigns nodes two sets according Table2. cases, Regent creates half networks mutation operator,half crossover operator. Although differences statistically significant,results suggest keeping rule structure networks intact crossoverimportant; otherwise, basic building blocks networks (i.e., rules) get splitcrossover, studies shown importance keeping intact basic buildingblocks crossover (Forrest & Mitchell, 1993; Goldberg, 1989).Regent-random-crossoverRegentPromoters Splice Junction RBS4.6%4.7%9.1%4.4%4.1%8.8%Table 5: Test-set error two runs REGENT: (a) randomly crossing \nodes"networks, (b) one crossing \rules" network (definedEquation 1). runs considered 250 networks used half crossover, halfmutation. results significant 95% confidence level;slight difference learning algorithms long run-times limitedruns ten-fold cross validation.6. Discussion Future WorkTowell (1991) showed Kbann generalized better many machine learning algorithms promoter splice-junction domains (the RBS dataset exist then).194fiConnectionist Theory RefinementDespite success, Regent able effectively use available computer cycles significantly improve generalization Kbann previous improvement Kbann,TopGen algorithm. Regent reduces Kbann's test-set error 12% RBS domain, 22% splice-junction domain, 33% promoter domain; reducesTopGen's test-set error 10% RBS domain, 17% splice-junction domain,21% promoter domain. Also, Regent's ability use available computing timeaided inherently parallel, since train many networks simultaneously.results show Regent's two genetic operators complement other.crossover operator considers large variety network topologies probabilistically combining rules contained within two \successful" KNNs. Mutation, hand, makessmaller, directed improvements members population, time addingdiversity population adding new rules population. Equal use operators, therefore, allows wide variety topologies considered well allowingincremental improvements members population.Since Regent searches many candidate networks, importantable recognize networks likely generalize best. mind,first planned extension Regent develop test different network-evaluation functions. currently use validation set; however, validation sets several drawbacks.First, keeping aside validation set decreases number training instances availablenetwork. Second, performance validation set noisy approximatortrue error (MacKay, 1992; Weigend, Huberman, & Rumelhart, 1990). Finally,increase number networks searched, Regent may start selecting networksoverfit validation set. fact, explains occasional upward trend test-set error,TopGen Regent, Figure 5.avoid problem overfitting data, common regression trick costfunction includes \smoothness" term along error term. best function,then, smoothest function also fits data well. neural networks, oneadd estimated error smoothness component measure complexitynetwork. complexity network cannot simply estimated countingnumber possible parameters, since tends significant duplicationfunction weight network, especially early training process (Weigend,1993). Two techniques try take account effective size networkGeneralized Prediction Error (Moody, 1991) Bayesian methods (MacKay, 1992).Quinlan Cameron-Jones (1995) propose adding additional term accuracysmoothness term takes account length time spent searching. cointerm \oversearching" describe phenomenon extensive searching causeslower predictive accuracy. claim oversearching orthogonal overfitting,thus complexity-based methods alone cannot prevent oversearching. increasenumber networks consider search, may start oversearching,thus plan investigate adding oversearching penalty term well.indicated earlier, Regent Lamarckian passes local optimizations individuals (i.e., trained weights network) offspring. viable alternative, calledBaldwin effect (Ackley & Littman, 1992; Baldwin, 1896; Belew & Mitchell, 1996; Hinton &Nowlan, 1987), local search still change fitness individual (backpropagation learning case), pass changes offspring (this form195fiOpitz & Shavlikevolution Darwinian nature). Even though learned explicitly codedgenetic material, individuals best able learn offspring;thus learning still impacts evolution. fact form evolution sometimes outperform forms Lamarckian evolution employ local search strategy (Whitley,Gordon, & Mathias, 1994). Future work investigate utility Baldwin effectRegent. case would cross trained networks, instead crossinitial weight settings backpropagation learning took place.Finally, often times multiple, even con icting, theories domain. Future work, then, investigate ways using domain theories seedinitial population. Although results Section 5.3.1 show including randomly generated networks degrades generalization performance, seeding population multipleapproximately correct theories degrade generalization, assuming networksinitial correctness. Thus Regent able naturallycombine good parts multiple theories. Also, given domain theory, manydifferent equivalent ways represent theory using set propositional rules.representation leads different network topology, even though networkstarts theory, topologies may conducive neural refinement.7. Related WorkRegent mainly differs previous work an\anytime" theory-refinement sys-tem continually searches, non-hillclimbing manner, improvements domaintheory. summary, work unique provides connectionist approachattempts effectively utilize available background knowledge available computer cyclesgenerate best concept possible. broken rest section four parts:(a) connectionist theory-refinement algorithms, (b) purely symbolic theory-refinement algorithms, (c) algorithms find appropriate domain-specific neural-network topology,(d) optimization algorithms wrapped around induction algorithms.7.1 Connectionist Theory-Refinement Techniquesbegin discussion connectionist theory-refinement systems. systemsdeveloped refine many types rule bases. instance, number systemsproposed revising certainty-factor rule bases (Fu, 1989; Lacher et al., 1992;Mahoney & Mooney, 1993), finite-state automata (Maclin & Shavlik, 1993; Omlin & Giles,1992), push-down automata (Das, Giles, & Sun, 1992), fuzzy-logic rules (Berenji, 1991;Masuoka, Watanabe, Kawamura, Owada, & Asakawa, 1990), mathematical equations(Roscheisen, Hofmann, & Tresp, 1991; Scott et al., 1992). systems work likeKbann first translating domain knowledge neural network, modifyingweights resulting network. attempts (which describe next)made dynamically adjust resulting network's topology training (as Regentdoes).Like TopGen Regent, Fletcher Obradovic (1993) present approachadds nodes Kbann network. system constructs single layer nodes, fullyconnected input output nodes, \off side" Kbann network.generate new hidden nodes using variant Baum Lang's (1991) constructive196fiConnectionist Theory Refinementalgorithm. Baum Lang's algorithm first divides feature space hyperplanes.find hyperplane randomly selecting two points different classes,localizing suitable split points. Baum Lang repeat processgenerate fixed number hyperplanes. Fletcher Obradovic mapBaum Lang's hyperplanes one new hidden node, thus defining weightsinput layer hidden node. Fletcher Obradovic's algorithm changeweights Kbann portion network, modifications initial rule basesolely left constructed hidden nodes. Thus, system take advantageKbann's strength removing unwanted antecedents rules original rulebase. fact, TopGen compared favorably similar technique also added nodesside Kbann (Opitz & Shavlik, 1993) Regent outperformed TopGenarticle's experiments.Rapture (Mahoney & Mooney, 1994) designed domain theories containing probabilistic rules. Like connectionist theory-refinement systems, Rapture first translatesdomain theory neural network, refines weights networkmodified backpropagation algorithm. Like Regent, Rapture able dynamicallyrefine topology network. using Upstart algorithm (Frean,1990) add new nodes network. Aside designed probabilistic rules,Rapture differs Regent adds nodes intention completelylearning training set, generalizing well. Thus, Rapture hillclimbstraining set learned, Regent continually searches topology space looking networkminimizes scoring function's error. Also, Rapture initially creates linksspecified domain theory, explicitly adds links ID3's (Quinlan,1986) information-gain metric. Regent, hand, fully connect consecutive layersnetworks, allowing rule possibility adding antecedents training.Daid algorithm (Towell & Shavlik, 1992) extension Kbann usesdomain theory help train Kbann network. Since Kbann effective dropping antecedents adding them, Daid tries find potentially useful inputs featuresmentioned domain theory. backing-up errors lowest leveldomain theory, computing correlations features. Daid increasesweight links potentially useful input features based correlations.Daid mainly differs Regent refine topology Kbann network. Thus, Daid addresses Kbann's limitation effectively adding antecedents,still unable introduce new rules constructively induce new antecedents. Daidtherefore suffer impoverished domain theories. Also notice since Daid improvement training KNNs, Regent use Daid train network considerssearch (however, done so).Opitz Shavlik (1996) used variant Regent learning algorithmgenerating neural network \ensemble." neural-network ensemble successfultechnique outputs set separately trained neural networks combinedform one unified prediction (Drucker, Cortes, Jackel, LeCun, & Vapnik, 1994; Hansen& Salamon, 1990; Perrone, 1993). Since Regent considers many networks, selectsubset final population networks ensemble minimal extra cost. Previouswork, though, shown ideal ensemble one networks accuratemake errors different parts input space (Hansen & Salamon, 1990;197fiOpitz & ShavlikKrogh & Vedelsby, 1995). result, Opitz Shavlik (1996) changed scoringfunction Regent \fit" network one accuratedisagreed members population much possible. addition,algorithm (Addemup) actively tries generate good candidates emphasizingcurrent population's erroneous examples backpropagation training. resultalterations, Addemup able create enough diversity among populationnetworks able effectively exploit knowledge domain theory. OpitzShavlik (1996) show Addemup able generate significantly better ensembleusing domain theory either running Addemup without benefit theorysimply combining Regent's final population networks. Actively searching highlydiverse population, however, aid searching single best network. fact,single best network produced Addemup significantly worse Regent's singlebest network three domains.7.2 Purely Symbolic Theory-Refinement TechniquesAdditional work related Regent includes purely symbolic theory-refinement systemsmodify domain theory directly initial form. Systems Focl (Pazzani& Kibler, 1992) Forte (Richards & Mooney, 1995) first-order, theory-refinementsystems revise predicate-logic theories. One drawback systemscurrently generalize well connectionist approaches many real-world problems,DNA promoter task (Cohen, 1992).several genetic-based, first-order logic, multimodal concept learners(Greene & Smith, 1993; Janikow, 1993). Giordana Saitta (1993) showed integrate one system, Regal (Giordana, Saitta, & Zini, 1994; Neri & Saitta, 1996),deductive engine ML-SMART (Bergadano, Giordana, & Ponsero, 1989) helprefine incomplete inconsistent domain theory. version works first using automated theorem prover recognize unresolved literals proof, uses GA-basedRegal induce corrections literals. Regent, hand, use geneticalgorithms (along neural learning) refine whole domain theory time.Dogma (Hekanaho, 1996) recently proposed GA-based learner use background knowledge learn description language Regal. Current restrictions,however, force representation language domain theory propositional rules.Dogma converts \ at" set background rules (i.e., handle intermediateconclusions) individual bitstrings used building blocks higher-levelconcept. Dogma focus theory refinement, rather builds completely newtheory using substructures background knowledge. term approachtheory-suggested theory-guided (Hekanaho, 1996).Several systems, including ours, proposed refining propositional rule bases.Early approaches could handle improvements overly specific theories (Danyluk,1989) specializations overly general theories (Flann & Dietterich, 1989). Later systemsRtls (Ginsberg, 1990), Either (Ourston & Mooney, 1994), Ptr (Koppel, Feldman,& Segre, 1994), Tgci (Donoho & Rendell, 1995) later able handle typesrefinements. discuss Either system representative propositionalsystems.198fiConnectionist Theory RefinementEither four theory-revision operators: (a) removing antecedents rule, (b)adding antecedents rule, (c) removing rules rule base, (d) inventing newrules. Either uses operators make revisions domain theory correctlyclassify previously misclassified training examples without undefiningcorrectly classified examples. Either uses inductive learning algorithms invent newrules; currently uses ID3 (Quinlan, 1986) induction component.Even though Regent's mutation operator add nodes manner analogoussymbolic system adds antecedents rules, underlying learning algorithm \connectionist." Towell (1991) showed Kbann outperformed Either promotertask, Regent outperformed Kbann article. Kbann's power domainlargely attributed ability make \fine-grain" refinements domain theory(Towell, 1991). Either's diculty domain, Baffes Mooney (1993)presented extension called Neither-MofN able learn -of-N rules {rules true N antecedents true. improvement generatedconcept closely matches Kbann's generalization performance.want minimize changes theory, want expense accuracy; however, Donoho Rendell (1995) demonstrate existingtheory-refinement systems, Either, suffer able make small,local changes domain theory. Thus, accurate theory significantly farstructure initial theory, systems forced either become trappedlocal maximum similar initial theory, forced drop entire rules replacenew rules inductively created purely scratch. Regentsuffer translates theory less restricting representationneural networks (Donoho & Rendell, 1995). Also, Regent able reconfigurestructure domain genetic algorithms.Many authors reported results using varying subsets splice junction domain(e.g., Donoho Rendell 1995; Mahoney 1996; Neri Saitta 1996, Towell Shavlik 1994). authors used different training set sizes, nevertheless worthwhilequalitatively discuss conclusions here. Towell Shavlik (1994) comparedKbann numerous machine learning algorithms learning algorithmgiven training set 1000 examples; Kbann's generalization ability compared favorablyalgorithms splice domain Regent, turn, compared favorablyKbann article. Donoho Rendell (1995) showed purely symbolic approachconverged performance Kbann around 200 examples. Mahoney (1996) showed,using training set sizes 400 examples, Rapture algorithm generalizedbetter Kbann domain; results look similar Regent. Finally,Neri Saitta (1996) showed generalization ability GA-based Regal compares favorably purely symbolic, non-GA based techniques; used slightlydifferent training set sizes article, Regent compares well resultsreported paper.7.3 Finding Appropriate Network Topologiesthird area related work covers techniques attempt find good domaindependent topology dynamically refining network's topology training. Many199fiOpitz & Shavlikstudies shown generalization ability neural network depends topology network (Baum & Haussler, 1989; Tishby, Levin, & Solla, 1989). tryingfind appropriate topology, one approach construct modify topologyincremental fashion. Network-shrinking algorithms start many parameters,remove nodes weights training (Hassibi & Stork, 1992; Le Cun, Denker, &Solla, 1989; Mozer & Smolensky, 1989). Network-growing algorithms, hand,start parameters, add nodes weights training (Blanziere& Katenkamp, 1996; Fahlman & Lebiere, 1989; Frean, 1990). obvious difference Regent algorithms Regent uses domain knowledgesymbolic rule-refinement techniques help determine network's topology. Also,algorithms restructure network based solely training-set error, Regentminimized validation-set error.Instead incrementally finding appropriate topology, one mount \richer"search hillclimbing space topologies. One common approachcombine genetic algorithms neural networks (as Regent does). Genetic algorithmsapplied neural networks two different ways: (a) optimize connectionweights fixed topology, (b) optimize topology network. Techniquessolely use genetic algorithms optimize weights (Montana & Davis, 1989; Whitley& Hanson, 1989) performed competitively gradient-based training algorithms;however, one problem genetic algorithms ineciency fine-tuned local search,thus scalability methods question (Yao, 1993). Kitano (1990b) presentsmethod combines genetic algorithms backpropagation. usinggenetic algorithm determine starting weights network,refined backpropagation. Regent differs Kitano's method use domaintheory help determine network's starting weights genetically search, instead,appropriate network topologies.methods use genetic algorithms optimize network topology similarRegent also use backpropagation train network's weights.methods, many directly encode link network (Miller, Todd, & Hegde,1989; Oliker, Furst, & Maimon, 1992; Schiffmann, Joost, & Werner, 1992). methodsrelatively straightforward implement, good fine tuning small networks(Miller et al., 1989); however, scale well since require large matricesrepresent links large networks (Yao, 1993). techniques (Dodd, 1990;Harp, Samad, & Guha, 1989; Kitano, 1990a) encode important featuresnetwork, number hidden layers, number hidden nodeslayer, etc. indirect encoding schemes evolve different sets parameters alongnetwork's topology shown good scalability (Yao, 1993).techniques (Koza & Rice, 1991; Oliker et al., 1992) evolve architectureconnection weights time; however, combination two levels evolutiongreatly increases search space.Regent mainly differs genetic-algorithm-based training methods designed knowledge-based neural networks. Thus Regent uses domain-specific knowledgesymbolic rule-refinement techniques aid determining network's topologyinitial weight setting. Regent also differs explicitly encode networks;rather, spirit Lamarkian evolution, passes trained network weights off200fiConnectionist Theory Refinementspring. final difference algorithms restructure networkbased solely training-set error, Regent minimizes validation-set error.7.4 Wrapping Optimization Around Learningend related work discussion brief overview methods combine globallocal optimization strategies. Local search algorithms iteratively improve estimateminimum searching local neighborhood current solution; local minimaguaranteed global minima. (Many inductive learning methods oftenequated local optimization techniques; Rumelhart et al., 1986.) Global optimizationmethods (such GAs), hand, perform sophisticated search acrossmultiple local minima good finding regions search space nearoptimal solutions found; however, usually good refining solution(once close near-optimal solution) local optimization strategies (Hart, 1994).Recent research shown desirable emply global local searchstrategy (Hart, 1994).Hybrid GAs (such Regent) combine local search traditional GA.focus hybrid-GA algorithms section, two-tiered search strategyemployed researchers well (Kohavi & John, 1997; Provost & Buchanan, 1995;Schaffer, 1993). GAs combined many local search methods (Bala, Huang,Vafaie, DeJong, & Wechsler, 1995; Belew, 1990; Hinton & Nowlan, 1987; Turney, 1995).Neural networks common choice local search strategy hybrid GAsystems discussed GA/neural-network hybrids Section 7.3. twocommon forms hybrid GAs: Lamarckian-based evolution Darwinian-based evolution (the Baldwin effect). Lamarckian evolution encodes local improvements directlygenetic material, Darwinian evolution leaves genetic material unchangedlearning. discussed Section 6, authors use Lamarckian local search techniques many shown numerous cases Lamarckian evolution outperformsnon-Lamarckian local search (Belew, McInerney, & Schraudolph, 1992; Hart, 1994; Judson,Colvin, Meza, Huffa, & Gutierrez, 1992).8. Conclusionideal inductive-learning algorithm able exploit available resourcesextensive computing power domain-specific knowledge improve ability generalize. Kbann (Towell & Shavlik, 1994) shown effective translatingdomain theory neural network; however, Kbann suffers altertopology. TopGen (Opitz & Shavlik, 1995) improved Kbann algorithm usingavailable computer power search effective places add nodes Kbann network;however, show empirically TopGen suffers restricting search expansionsKbann network, unable improve performance searching beyondtopologies. Therefore TopGen unable exploit available computing powerincrease correctness induced concept.present new algorithm, Regent, uses specialized genetic algorithmbroaden types topologies considered TopGen's search. Experiments indicateRegent able significantly increase generalization TopGen; hence, new201fiOpitz & Shavlikalgorithm successful overcoming TopGen's limitation searching small portionspace possible network topologies. so, Regent able generategood solution quickly, using Kbann, able continually improve solutionsearches concept space. Therefore, Regent takes step toward true anytime theoryrefinement system able make effective use problem-specific knowledgeavailable computing cycles.Acknowledgementswork supported Oce Naval Research grant N00014-93-1-0998 NationalScience Foundation grant IRI 95-02990. Thanks Richard Maclin, Richard Sutton,three anonymous reviewers helpful comments. extended versionpaper published Machine Learning: Proceedings Eleventh International Conference,pp. 208-216, New Brunswick, NJ, Morgan Kaufmann. David Opitz completed portionwork graduate student University Wisconsin professorUniversity Minnesota, Duluth.ReferencesAckley, D. (1987). Connectionist Machine Genetic Hillclimbing. Kluwer, Norwell,MA.Ackley, D., & Littman, M. (1992). Interactions learning evolution. Langton,C., Taylor, C., Farmer, C., & Rasmussen, S. (Eds.), Artificial Life II, pp. 487{509,Redwood City, CA. Addison-Wesley.Ackley, D., & Littman, M. (1994). case Lamarckian evolution. Langton, C. (Ed.),Artificial Life III, pp. 3{10, Redwood City, CA. Addison-Wesley.Baffes, P., & Mooney, R. (1993). Symbolic revision theories M-of-N rules.Proceedings Thirteenth International Joint Conference Artificial Intelligence,pp. 1135{1140, Chambery, France. Morgan Kaufmann.Bala, J., Huang, J., Vafaie, H., DeJong, K., & Wechsler, H. (1995). Hybrid learning usinggenetic algorithms decision trees pattern classification. ProceedingsFourteenth International Joint Conference Artificial Intelligence, pp. 719{724,Montreal, Canada. Morgan Kaufmann.Baldwin, J. (1896). Physical social heredity. American Naturalist, 30, 441{451.Baum, E., & Haussler, D. (1989). size net gives valid generalization? Neural Computation, 1, 151{160.Baum, E., & Lang, K. (1991). Constructing hidden units using examples queries.Lippmann, R., Moody, J., & Touretzky, D. (Eds.), Advances Neural InformationProcessing Systems, Vol. 3, pp. 904{910, San Mateo, CA. Morgan Kaufmann.202fiConnectionist Theory RefinementBelew, R. (1990). Evolution, learning culture: Computational metaphors adaptivesearch. Complex Systems, 4, 11{49.Belew, R., McInerney, J., & Schraudolph, N. (1992). Evolving networks: Using geneticalgorithm connectionist learning. Langton, C., Taylor, C., Farmer, C., &Rasmussen, S. (Eds.), Artificial Life II, pp. 511{547, Redwood City, CA. AddisonWesley.Belew, R., & Mitchell, M. (1996). Adaptive Individuals Evolving Populations: ModelsAlgorithms. Addison-Wesley, Massachusetts.Berenji, H. (1991). Refinement approximate reasoning-based controllers reinforcementlearning. Proceedings Eighth International Machine Learning Workshop, pp.475{479, Evanston, IL. Morgan Kaufmann.Bergadano, F., Giordana, A., & Ponsero, S. (1989). Deduction top-down inductivelearning. Proceedings Sixth International Workshop Machine Learning,pp. 23{25, Ithaca, NY. Morgan Kaufmann.Blanziere, E., & Katenkamp, P. (1996). Learning radial basis function networks on-line.Proceedings Thirteenth International Conference Machine Learning, pp.37{45, Bari, Italy. Morgan Kaufmann.Clocksin, W., & Mellish, C. (1987). Programming Prolog. Springer-Verlag, New York.Cohen, W. (1992). Compiling prior knowledge explicit bias. ProceedingsNinth International Conference Machine Learning, pp. 102{110, Aberdeen,Scotland. Morgan Kaufmann.Danyluk, A. (1989). Finding new rules incomplete theories: Explicit biases inductioncontextual information. Proceedings Sixth International WorkshopMachine Learning, pp. 34{36, Ithaca, NY. Morgan Kaufmann.Das, A., Giles, C., & Sun, G. (1992). Using prior knowledge NNPDA learncontext-free languages. Hanson, S., Cowan, J., & Giles, C. (Eds.), AdvancesNeural Information Processing Systems, Vol. 5, pp. 65{72, San Mateo, CA. MorganKaufmann.Dean, T., & Boddy, M. (1988). analysis time-dependent planning. ProceedingsSeventh National Conference Artificial Intelligence, pp. 49{54, St. Paul, MN.Morgan Kaufmann.DeJong, K. (1975). Analysis Behavior class Genetic Adaptive Systems.Ph.D. thesis, University Michigan, Ann Arbor, MI.Dodd, N. (1990). Optimization network structure using genetic techniques. ProceedingsIEEE International Joint Conference Neural Networks, Vol. III, pp. 965{970,Paris. IEEE Press.203fiOpitz & ShavlikDonoho, S., & Rendell, L. (1995). Rerepresenting restructuring domain theories:constructive induction approach. Journal Artificial Intelligence Research, 2, 411{446.Drucker, H., Cortes, C., Jackel, L., LeCun, Y., & Vapnik, V. (1994). Boostingmachine learning algorithms. Proceedings Eleventh International ConferenceMachine Learning, pp. 53{61, New Brunswick, NJ. Morgan Kaufmann.Fahlman, S., & Lebiere, C. (1989). cascade-correlation learning architecture. Touretzky, D. (Ed.), Advances Neural Information Processing Systems, Vol. 2, pp. 524{532, San Mateo, CA. Morgan Kaufmann.Farmer, J., & Belin, A. (1992). Artificial life: coming evolution. Langton, C., Taylor,C., Farmer, J. D., & Rasmussen, S. (Eds.), Artificial Life II, pp. 815{840, RedwoodCity, CA. Addison-Wesley.Flann, N., & Dietterich, T. (1989). study explanation-based methods inductivelearning. Machine Learning, 4, 187{226.Fletcher, J., & Obradovic, Z. (1993). Combining prior symbolic knowledge constructiveneural network learning. Connection Science, 5, 365{375.Forrest, S., & Mitchell, M. (1993). makes problem hard genetic algorithm?anomalous results explanation. Machine Learning, 13, 285{319.Frean, M. (1990). upstart algorithm: method constructing training feedforward neural networks. Neural Computation, 2, 198{209.Fu, L. (1989). Integration neural heuristics knowledge-based inference. ConnectionScience, 1, 325{340.Ginsberg, A. (1990). Theory reduction, theory revision, retranslation. ProceedingsEighth National Conference Artificial Intelligence, pp. 777{782, Boston, MA.AAAI/MIT Press.Giordana, A., & Saitta, L. (1993). REGAL: integrated system relations using geneticalgorithms. Proceedings Second International Workshop MultistrategyLearning, pp. 234{249, Harpers Ferry, WV.Giordana, A., Saitta, L., & Zini, F. (1994). Learning disjunctive concepts means genetic algorithms. Proceedings Eleventh International Conference MachineLearning, pp. 96{104, New Brunswick, NJ. Morgan Kaufmann.Goldberg, D. (1989). Genetic Algorithms Search, Optimization, Machine Learning.Addison-Wesley, Reading, MA.Greene, D., & Smith, S. (1993). Competition-based induction decision modelsexamples. Machine Learning, 13, 229{258.204fiConnectionist Theory RefinementGrefenstette, J., & Ramsey, C. (1992). approach anytime learning. ProceedingsNinth International Conference Machine Learning, pp. 189{195, Aberdeen,Scotland. Morgan Kaufmann.Hansen, L., & Salamon, P. (1990). Neural network ensembles. IEEE TransactionsPattern Analysis Machine Intelligence, 12, 993{1001.Harp, S., Samad, T., & Guha, A. (1989). Designing application-specific neural networksusing genetic algorithm. Touretzky, D. (Ed.), Advances Neural InformationProcessing Systems, Vol. 2, pp. 447{454, San Mateo, CA. Morgan Kaufmann.Hart, W. (1994). Adaptive Global Optimization Local Search. Ph.D. thesis, UniversityCalifornia, San Diego.Hassibi, B., & Stork, D. (1992). Second order derivatives network pruning: Optimal brainsurgeon. Hanson, S., Cowan, J., & Giles, C. (Eds.), Advances Neural InformationProcessing Systems, Vol. 5, pp. 164{171, San Mateo, CA. Morgan Kaufmann.Hekanaho, J. (1996). Background knowledge GA-based concept learning. ProceedingsThirteenth International Conference Machine Learning, pp. 234{242, Bari,Italy. Morgan Kaufmann.Hinton, G., & Nowlan, S. (1987). learning guide evolution. Complex Systems, 1,495{502.Holder, L. (1991). Maintaining Utility Learned Knowledge Using Model-Based Control. Ph.D. thesis, Computer Science Department, University Illinois UrbanaChampaign.Holland, J. (1975). Adaptation Natural Artificial Systems. University MichiganPress, Ann Arbor, MI.Janikow, C. (1993). knowledge intensive GA supervised learning. Machine Learning,13, 198{228.Judson, R., Colvin, M., Meza, J., Huffa, A., & Gutierrez, D. (1992). intelligent configuration search techniques outperform random search large molecules? InternationalJournal Quantum Chemistry, 277{290.Kibler, D., & Langley, P. (1988). Machine learning experimental science. Proceedings Third European Working Session Learning, pp. 1{12, Edinburgh,UK.Kitano, H. (1990a). Designing neural networks using genetic algorithms graph generation system. Complex Systems, 4, 461{476.Kitano, H. (1990b). Empirical studies speed convergence neural network training using genetic algorithms. Proceedings Eighth National ConferenceArtificial Intelligence, pp. 789{795, Boston, MA. AAAI/MIT Press.205fiOpitz & ShavlikKohavi, R., & John, G. (1997). Wrappers feature subset selection. Artificial Intelligence.Koppel, M., Feldman, R., & Segre, A. (1994). Bias-driven revision logical domain theories.Journal Artificial Intelligence Research, 1, 159{208.Koza, J. (1992). Genetic Programming. MIT Press, Cambridge, MA.Koza, J., & Rice, J. (1991). Genetic generation weights architecturesneural network. International Joint Conference Neural Networks, Vol. 2, pp.397{404, Seattle, WA. IEEE Press.Krogh, A., & Vedelsby, J. (1995). Neural network ensembles, cross validation, activelearning. Tesauro, G., Touretzky, D., & Leen, T. (Eds.), Advances NeuralInformation Processing Systems, Vol. 7, pp. 231{238, Cambridge, MA. MIT Press.Lacher, R., Hruska, S., & Kuncicky, D. (1992). Back-propagation learning expert networks. IEEE Transactions Neural Networks, 3, 62{72.Le Cun, Y., Denker, J., & Solla, S. (1989). Optimal brain damage. Touretzky, D. (Ed.),Advances Neural Information Processing Systems, Vol. 2, pp. 598{605, San Mateo,CA. Morgan Kaufmann.Litzkow, M., Livny, M., & Mutka, M. (1988). Condor | hunter idle workstations.Proceedings Eighth International Conference Distributed Computing Systems,pp. 104{111, San Jose, CA. Computer Society Press.MacKay, D. (1992). practical Bayesian framework backpropagation networks. NeuralComputation, 4, 448{472.Maclin, R., & Shavlik, J. (1993). Using knowledge-based neural networks improve algorithms: Refining Chou-Fasman algorithm protein folding. Machine Learning,11, 195{215.Mahoney, J. (1996). Combining Symbolic Connectionist Learning Methods RefineCertainty-Factor Rule-Bases. Ph.D. thesis, University Texas, Austin, TX.Mahoney, J., & Mooney, R. (1993). Combining connectionist symbolic learning refinecertainty-factor rule-bases. Connection Science, 5, 339{364.Mahoney, J., & Mooney, R. (1994). Comparing methods refining certainty-factor rulebases. Proceedings Eleventh International Conference Machine Learning,pp. 173{180, New Brunswick, NJ. Morgan Kaufmann.Masuoka, R., Watanabe, N., Kawamura, A., Owada, Y., & Asakawa, K. (1990). Neurofuzzysystem | fuzzy inference using structured neural network. ProceedingsInternational Conference Fuzzy Logic & Neural Networks, pp. 173{177, Iizuka,Japan.Michalski, R. (1983). theory methodology inductive learning. Artificial Intelligence,20, 111{161.206fiConnectionist Theory RefinementMiller, G., Todd, P., & Hegde, S. (1989). Designing neural networks using genetic algorithms. Proceedings Third International Conference Genetic Algorithms,pp. 379{384, Arlington, VA. Morgan Kaufmann.Mitchell, M. (1996). Introduction Genetic Algorithms. MIT Press, Cambridge, MA.Mitchell, T. (1982). Generalization search. Artificial Intelligence, 18, 203{226.Montana, D., & Davis, L. (1989). Training feedforward networks using genetic algorithms.Proceedings Eleventh International Joint Conference Artificial Intelligence,pp. 762{767, Detroit, MI. Morgan Kaufmann.Moody, J. (1991). effective number parameters: analysis generalizationregularization nonlinear learning systems. Moody, J., Hanson, S., & Lippmann,R. (Eds.), Advances Neural Information Processing Systems, Vol. 4, pp. 847{854,San Mateo, CA. Morgan Kaufmann.Mozer, M. C., & Smolensky, P. (1989). Using relevance reduce network size automatically.Connection Science, 1, 3{16.Neri, F., & Saitta, L. (1996). Exploring power genetic search learning symbolicclassifiers. IEEE Transactions Pattern Analisys Machine Intelligence.Oliker, S., Furst, M., & Maimon, O. (1992). distributed genetic algorithm neuralnetwork design training. Complex Systems, 6, 459{477.Omlin, C., & Giles, C. (1992). Training second-order recurrent neural networks using hints.Proceedings Ninth International Conference Machine Learning, pp. 361{366, Aberdeen, Scotland. Morgan Kaufmann.Opitz, D., & Shavlik, J. (1993). Heuristically expanding knowledge-based neural networks.Proceedings Thirteenth International Joint Conference Artificial Intelligence, pp. 1360{1365, Chambery, France. Morgan Kaufmann.Opitz, D., & Shavlik, J. (1995). Dynamically adding symbolically meaningful nodesknowledge-based neural networks. Knowledge-Based Systems, 8, 301{311.Opitz, D., & Shavlik, J. (1996). Actively searching effective neural-network ensemble.Connection Science, 8, 337{353.Ourston, D., & Mooney, R. (1994). Theory refinement combining analytical empiricalmethods. Artificial Intelligence, 66, 273{309.Pazzani, M., & Kibler, D. (1992). utility knowledge inductive learning. MachineLearning, 9, 57{94.Perrone, M. (1993). Improving Regression Estimation: Averaging Methods VarianceReduction Extension General Convex Measure Optimization. Ph.D. thesis,Brown University, Providence, RI.207fiOpitz & ShavlikProvost, F., & Buchanan, B. (1995). Inductive policy: pragmatics bias selection.Machine Learning, 20, 35{61.Quinlan, J. (1986). Induction decision trees. Machine Learning, 1, 81{106.Quinlan, J., & Cameron-Jones, R. (1995). Lookahead pathology decision tree induction. Proceedings Fourteenth International Joint Conference ArtificialIntelligence, pp. 1019{1024, Montreal, Canada. Morgan Kaufmann.Richards, B., & Mooney, R. (1995). Automated refinement first-order Horn-clause domaintheories. Machine Learning, 19, 95{131.Roscheisen, M., Hofmann, R., & Tresp, V. (1991). Neural control rolling mills: Incorporating domain theories overcome data deficiency. Moody, J., Hanson, S., &Lippmann, R. (Eds.), Advances Neural Information Processing Systems, Vol. 4, pp.659{666, San Mateo, CA. Morgan Kaufmann.Rumelhart, D., Hinton, G., & Williams, R. (1986). Learning internal representationserror propagation. Rumelhart, D., & McClelland, J. (Eds.), Parallel DistributedProcessing: Explorations microstructure cognition. Volume 1: Foundations,pp. 318{363. MIT Press, Cambridge, MA.Schaffer, C. (1993). Selecting classification method cross-validation. Machine Learning,13, 135{143.Schiffmann, W., Joost, M., & Werner, R. (1992). Synthesis performance analysismultilayer neural network architectures. Tech. rep. 16, University Koblenz, InstitutePhysics.Scott, G., Shavlik, J., & Ray, W. (1992). Refining PID controllers using neural networks.Neural Computation, 5, 746{757.Tishby, N., Levin, E., & Solla, S. (1989). Consistent inference probabilities layerednetworks, predictions generalization. International Joint Conference NeuralNetworks, pp. 403{410, Washington, D.C. IEEE Press.Towell, G. (1991). Symbolic Knowledge Neural Networks: Insertion, Refinement,Extraction. Ph.D. thesis, Computer Sciences Department, University Wisconsin,Madison, WI.Towell, G., & Shavlik, J. (1992). Using symbolic learning improve knowledge-based neuralnetworks. Proceedings Tenth National Conference Artificial Intelligence,pp. 177{182, San Jose, CA. AAAI/MIT Press.Towell, G., & Shavlik, J. (1994). Knowledge-based artificial neural networks. ArtificialIntelligence, 70, 119{165.Turney, P. (1995). Cost-sensitive classification: Empirical evaluation hybrid geneticdecision tree induction algorithm. Journal Artificial Intelligence Research, 2, 369{409.208fiConnectionist Theory RefinementWaterman, D. (1986). Guide Expert Systems. Addison Wesley, Reading, MA.Watrous, R., Towell, G., & Glassman, M. (1993). Synthesize, optimize, analyze, repeat(SOAR): Application neural network tools ECG patient monitoring. Proceedings Symposium Nonlinear Theory Applications, pp. 565{570,Honolulu, Hawaii.Watson, J. D., Hopkins, N. H., Roberts, J. W., Argetsinger-Steitz, J., & Weiner, A. M.(1987). Molecular Biology Gene (Fourth edition). Benjamin/Cummings, MenloPark, CA.Weigend, A. (1993). overfitting effective number hidden units. Proceedings 1993 Connectionist Models Summer School, pp. 335{342, Boulder, CO.Lawrence Erlbaum Associates.Weigend, A., Huberman, B., & Rumelhart, D. (1990). Predicting future: connectionistapproach. International Journal Neural Systems, I, 193{209.Whitley, D., Gordon, S., & Mathias, K. (1994). Lamarckian evolution, Baldwin effectfunction optimization. Davidor, Y., Schwefel, H., & Manner, R. (Eds.), ParallelProblem Solving Nature - PPSN III, pp. 6{15. Springer-Verlag.Whitley, D., & Hanson, T. (1989). Optimizing neural networks using faster, accurate genetic search. Proceedings Third International Conference GeneticAlgorithms, pp. 391{396, Arlington, VA. Morgan Kaufmann.Yao, X. (1993). Evolutionary artificial neural networks. International Journal NeuralSystems, 4, 203{221.209fiJournal Artificial Intelligence Research 6 (1997) 223-262Submitted 2/97; published 6/97Flaw Selection Strategies Partial-Order PlanningMartha E. PollackDepartment Computer Science Intelligent Systems Program,University Pittsburgh, Pittsburgh, PA 15260 USADavid JoslinComputational Intelligence Research Laboratory,University Oregon, Eugene, 97403 USApollack@cs.pitt.edujoslin@cirl.uoregon.eduMassimo PaolucciIntelligent Systems Program,University Pittsburgh, Pittsburgh, PA 15260 USApaolucci@pitt.eduAbstractSeveral recent studies compared relative eciency alternative aw selectionstrategies partial-order causal link (POCL) planning. review literature,present new experimental results generalize earlier work explaindiscrepancies it. particular, describe Least-Cost Flaw Repair (LCFR) strategydeveloped analyzed Joslin Pollack (1994), compare strategies,including Gerevini Schubert's (1996) ZLIFO strategy. LCFR ZLIFO makedifferent, apparently con icting claims effective way reduce searchspace size POCL planning. resolve con ict, arguing much benefitGerevini Schubert ascribe LIFO component ZLIFO strategy betterattributed causes. show many problems, strategy combinesleast-cost aw selection delay separable threats effective reducingsearch-space size, without excessive computational overhead. Althoughstrategy thus provides good default, also show certain domain characteristicsmay reduce effectiveness.1. IntroductionMuch current research plan generation centers partial-order causal link (POCL)algorithms, descend McAllester Rosenblitt's (1991) SNLP algorithm. POCLplanning involves searching space partial plans, successors noderepresenting partial plan P refinements P . search problem, POCLplanning requires effective search control strategies.POCL planning, search control two components. first, node selection, involves choosing partial plan refine next. partial plan selectedrefinement, planner must perform aw selection, involves choosing eitherthreat resolve open condition establish.past years, several studies compared relative eciency alternative aw selection strategies POCL planning extensions (Peot & Smith, 1993;Joslin & Pollack, 1994; Srinivasan & Howe, 1995; Gerevini & Schubert, 1996; Williamson &Hanks, 1996). studies motivated least part tensionattractive formal properties POCL algorithms, limitations puttingc 1997 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.fiPollack, Joslin, & Paoluccipractical use result relatively poor performance. date, POCLalgorithms cannot match eciency so-called industrial-strength plannersSIPE (Wilkins, 1988; Wilkins & Desimone, 1994) O-Plan (Currie & Tate, 1991; Tate,Drabble, & Dalton, 1994). Flaw selection strategy shown significanteffect eciency POCL planning algorithms, thus researchers vieweddesign improved aw selection strategies one means making POCL planningalgorithms practical.paper, review literature aw selection strategies, present newexperimental results generalize earlier work explain discrepanciesit. particular, describe Least-Cost Flaw Repair (LCFR) strategy developedanalyzed Joslin Pollack (1994), compare strategies, includingGerevini Schubert's ZLIFO strategy (1996). LCFR ZLIFO make different,apparently con icting claims effective way reduce search-space sizePOCL planning. resolve con ict, arguing much benefit GereviniSchubert ascribe LIFO component ZLIFO strategy better attributedcauses. show many problems, strategy combines least-cost awselection delay separable threats effective reducing search-space size,without excessive computational overhead. Although strategy thusprovides good default, also show certain domain characteristics may reduceeffectiveness.2. Background2.1 Node Flaw SelectionAlthough main ideas POCL planning literaturetwo decades, serious efforts comparing alternative plan generation algorithmsrelatively recent. made comparisons possible development setclear algorithms provable formal properties, notably TWEAK (Chapman, 1987),SNLP (McAllester & Rosenblitt, 1991). algorithms intended addfunctionality known planning methods, rather capture essential elementsknown methods readily analyzable fashion.analyzing POCL algorithms, researchers found useful decouple searchcontrol strategy underlying plan refinement process. Figure 1 generic POCLalgorithm, highlight two search decisions.1 Following convention, useCHOOSE indicate node selection backtracking point, SELECT indicateaw selection not. given node may lead solution, may necessarybacktrack consider alternative nodes. hand, node leadsolution, solution found regardless order aws selected.See Weld's (1994) tutorial paper discussion difference.generic algorithm sketched figure must supplemented search strategiesimplement CHOOSE SELECT operators. POCL algorithms performnode selection using best-first ranking computes function number1. Various versions well-known algorithm appeared literature (Weld, 1994; Russell &Norvig, 1995; Kambhampati, Knoblock, & Yang, 1995). version give corresponds directlygiven Williamson Hanks (1996).224fiFlaw Selection StrategiesPOCL (init,goal)dummy-plan make-skeletal-plan(init,goal).nodes f dummy-plan g.nodes empty do:CHOOSE (and remove) partial plan P nodes. (Node Selection)P awsreturn Pelse do:SELECT aw P. (Flaw Selection)Add refinements P nodes.Return failure (because nodes become empty without aw-free plan found.)Figure 1: Basic POCL Planning Algorithmsteps (denoted ), open conditions (OC ), unsafe conditions (UC , i.e., threats)partial plan. Gerevini Schubert (1996) argued that, general, stepsopen conditions included ranking function, adopt strategyexperiments, except otherwise indicated.chosen node, POCL planning algorithm must select aw|open condition threat|within node repair. Open conditions repaired establishment,consists either adding new step unifying condition effect (alongcausal link new step condition), else simply adding newcausal link existing step unifying effect. use term repair costdenote number possible ways repair aw.open condition o, repair cost R(o) + + N ,= number conditions initial state unify givencurrent binding constraints,= number conditions effects existing plan steps unifygiven current binding constraints, counting existing plansteps constrained occur step associated o,N = number conditions effects operators libraryunify given current binding constraints.Note time, repair cost open condition resolved may eitherincrease, new steps might achieve condition added plan, decrease,steps already plan constrained temporal ordering variable bindinglonger achieve condition.considering cost threat repair, useful distinguish nonseparableseparable threats. Nonseparable threats consist step S1 effect E ,causal link S2; F; S3 , E F complementary literals necessarily unify:either complementary ground literals (E :F ), else complementaryliterals E 's variables identical with, forced binding constraint225fiPollack, Joslin, & Paolucciequivalent variable position F (e.g., E = p(x; ) F = :p(x; z ),currently binding constraint = z ).2Nonseparable threats repaired two ways: promoting S1, requiringoccur S3 , demoting it, requiring occur S2 . course, alreadyexisting temporal ordering constraints may block one repair options,two possible repairs.3 time, repair cost unresolvednonseparable threat decrease.separable threat consists step S1 effect E , causal link S2 ; F; S3 ,E F complementary literals unified, unificationforced (e.g., E = p(x) F = p(y ) exist bindingconstraint x = ). circumstances, threat may disappear subsequent variablebinding blocks unification. (A nonseparable threat may also disappear subsequentordering constraint effect imposing promotion demotion.) repair costseparable threat may higher nonseparable threat:promotion demotion used, separation, involves forcing variablebinding blocks unification. Separation introduce one repair unboundvariable threat. example, effect P (x; y; z ) threatens S2 ; :P (t; u; v ); S3 ,three possible repairs: x 6= t, 6= u, z 6= v . nonseparable threats,repair cost separable threat remains unresolved decrease time.2.2 Notationaw selection strategies discussed literature typicallygiven idiosyncratic names (e.g., DUnf, LCFR, ZLIFO). useful, comparing them,precise unifying notation. therefore specify aw strategy sequencepreferences. strategy begins attempting find aw satisfies first preference;unable so, looks aw satisfies second preference;on. ensure POCL algorithm using strategy complete, sequencepreferences must exhaustive: every aw must satisfy preference. aw satisfiesone preference strategy, assume first match counts.principle, preference could identify feature aw. practice, however, awselection strategies made use small number features: type aw(open condition, nonseparable threat, separable threat), number waysrepaired, time introduced plan. Often, one awgiven feature, case tie-breaking strategy may specified choosingamong relevant aws.therefore describe preference using following notationf aw typesgrepair cost rangetie-breaking strategy2. alternative approach also treats cases E F threats; required make plannersystematic, i.e., guaranteed never generate node (McAllester & Rosenblitt,1991).3. Conditional planners make use additional method threat resolution|confrontation|butignore within paper (Peot & Smith, 1992; Etzioni, Hanks, Weld, Draper, Lesh, & Williamson,1992). Joslin (1996) provides detailed account generalizing treatment aws typesplanning decisions.226fiFlaw Selection Strategiesindicates preference aw f specified type types, providedrepair cost f falls within range values specified. (If restrictionsrepair cost, omit repair cost range.) one aw meets criteria,tie-breaking strategy applied select among them.abbreviate aw type \o" (for open condition), \n" (for nonseparable threat),\s" (for separable threat). also use abbreviations common tie-breaking strategies,e.g., \LC" (least (repair) cost), \LIFO" \R" (Random). case LC, choicemust made aws repair cost, LIFO selection used.Thus, examplefng0-1Rspecifies preference nonseparable threats repair cost zero one;one aw meets conditions, random selection made among them. useterm forced describe aws repair cost one less.example complete aw selection strategy then:fng0-1R / fogLIFO / fn,sgRstrategy would begin looking forced nonseparable threat; one awmeets criterion, strategy would select randomly among them. forcednonseparable threats, would look open condition, repair cost, usingLIFO scheme select among them. Finally, neither forced nonseparable threatsopen conditions, would randomly select either unforced nonseparable threatseparable threat.distinguished aw type maximum repair cost, onehand, tie-breaking strategy, other, easy describe strategies usesomething aw type main criterion selection. example, pureLIFO selection strategy would encoded follows. (Henceforth, give namestrategy boldface preceding specification.)LIFO fo,n,sgLIFO3. Flaw Selection Strategiesbegin reviewing aw selection strategies proposed studiedliterature date.3.1 Threat Preference Delayoriginal SNLP algorithm (McAllester & Rosenblitt, 1991) adopted aw selectionstrategy threats resolved open conditions, early versionswidely used UCPOP planning system (Penberthy & Weld, 1992) same.4 SNLPspecify principle selecting among multiple threats multiple opens; UCPOPused LIFO purpose. Employing notation above, describe basicUCPOP strategy as:4. current version UCPOP (v.4), aw selection strategy run default DSepstrategy, discussed below. historical reasons, maintain name DSep strategy,use UCPOP older default strategy.227fiPollack, Joslin, & PaolucciUCPOP fn,sgLIFO / fogLIFOfirst study alternative aw selection strategies done Peot Smith (1993),relaxed requirement threats always resolved open conditions,examined several strategies delaying resolution threats. analyzed fivedifferent strategies delaying repair threats; these, two provably superior:DSep DUnf.DSep (Delay Separable Threats) motivated observation sometimes separable threats simply disappear planning process blocking variable bindingsintroduced. pointed earlier, nonseparable threats may also \disappear",typically less frequent. Moreover, resolution threats|separablenonseparable|were delayed, nonseparable threats would disappear early sideeffect step reuse, making disappearance even less frequent.DSep strategy therefore defers repair separable threats endplanning process. However, like UCPOP, continues give preference nonseparablethreats:DSep fngLIFO / fogLIFO / fsgLIFOActually, Peot Smith specify tie-breaking strategy choosing among multiplethreats; indicated LIFO. explored three different tie-breakingstrategies selecting open conditions (FIFO, LIFO, least-cost); list LIFO,one also specify alternatives:DSep-LC fngLIFO / fogLC / fsgLIFODSep-FIFO fngLIFO / fogFIFO / fsgLIFOPeot Smith prove search space generated POCL planner using DSepnever larger search space generated using UCPOP strategy. resultholds tie-breaking strategy open conditions LIFO FIFO, LC,point return later paper.Peot Smith's second successful strategy DUnf (Delay Unforced Threats). makesuse notion forced aws. stated earlier, aw forcedone possible way repair it. DUnf strategy delays repair unforced threats:DUnf fn,sg0LIFO / fn,sg1LIFO / fogLIFO / fn,sg2-1LIFOdefine DUnf-LC DUnf-FIFO manner analogous used DSep-LCDSep-FIFO:DUnf-LC fn,sg0LIFO / fn,sg1LIFO / fogLC / fn,sg2-1LIFODUnf-FIFO fn,sg0LIFO / fn,sg1LIFO / fogFIFO / fn,sg2-1LIFOPeot Smith proved DUnf strategy would never generate larger searchspace either remaining two strategies examined. also provedDSep DUnf incomparable: exist planning problems DSepgenerates smaller search space DUnf, problems reversetrue.228fiFlaw Selection StrategiesPeot Smith support theoretical results DSep DUnf experimentsshowing that, least domains examined, strategies result significant decrease search-space size. decrease search correlated dicultyproblem, consequently, problems get dicult, strategies reducesearch time well space. is, large enough problems, \pay for"overhead.follow-on work, Peot Smith (1994) describe strategy called DMin, generates smaller search spaces DSep DUnf. DMin combines process pruningdead-end nodes process aw selection. gives preference forced threats.forced threats, checks see whether remaining nonseparable threatscould repaired simultaneously. so, leaves threats, selects open condition repair; open conditions, presumably selects remainingunforced threat repair. hand, impossible repair unforced,nonseparable threats, node dead end, pruned searchspace. Note dead-end nodes recognized immediately, even withoutcomplete consistency checking DMin. unrepairable aw cannotsubsequently become repairable, hence, node containing aw repair cost zerodead end. Consequently, aw selection strategies give highest priorityaws (Joslin & Pollack, 1996; Joslin, 1996).3.2 Least-Cost Flaw RepairPeot Smith's work provided foundation subsequent exploration leastcost aw repair (LCFR) strategy (Joslin & Pollack, 1994). hypothesized powerDUnf strategy might come relative ordering threats open conditions, instead fact DUnf effect imposing partial preferenceleast-cost aw selection. DUnf always prefer forced threat, which, definitionrepair cost one; thus, cases forced threat, DUnfmake low-cost selection. cases forced threats?DUnf select among open conditions, assuming any. hypothesis correct, version DUnf makes selection using least-cost strategy (i.e.,DUnf-LC) ought perform better version uses one strategies (i.e.,bare DUnf DUnf-FIFO). fact, selection low-cost repairs causingsearch-space reduction, idea treating threat resolution differently opencondition establishment ought abandoned. Instead, strategy always selectsaw minimal repair cost, regardless whether threat open condition,ought show best performance. Least-Cost Flaw Repair (LCFR) strategy:5LCFR fo,n,sgLCstrong similarities LCFR certain heuristics proposed studied literature constraint satisfaction problems (CSPs).perhaps surprising, given aw selection POCL planning corresponds5. LCFR strategy similar branch-1/branch-n search heuristics included O-Plan system(Currie & Tate, 1991). contribution original work topic isolate strategyexamine detail.229fiPollack, Joslin, & Paoluccifairly strong ways variable selection constraint programming. Flaws POCL planner represent decisions yet made, must made plancomplete; unbound variables play similar role constraint satisfaction problems(CSPs).6 Although exist number heuristics selecting variable branchsolving CSP (Kumar, 1992), one well-known heuristic often quite effectivefail first principle, picks variable \most constrained" selectingvariable branch on. simple common implementation fail first principleselects variable smallest domain (Tsang, 1993).intuition behind fail first principle one prune dead-end regionssearch early possible. unbound variables tightly constrainedlikely points current partial solution \brittle" sense,branching variables hope find contradiction (if one exists) quickly.Similarly, LCFR thought selecting \most constrained" aws, resultingbetter pruning.similar heuristic also adopted recent work controlling search hierarchical task network (HTN) planning, Dynamic Variable Commitment Strategy (DVCS). DVCS, like LCFR, based minimal-branching heuristic. Experimentalanalyses demonstrate DVCS generally produces well-focused search (Tsuneto, Erol,Hendler, & Nau, 1996).initial experimental results, presented Joslin Pollack (1994), similarlysupported hypothesis uniform least-cost aw repair strategy could highlyeffective reducing size search space POCL planning. experiments,compared LCFR four strategies: UCPOP, DUnf, DUnf-LC, definedabove, new strategy, UCPOP-LC previously called LCOS (Joslin & Pollack,1994):UCPOP-LC fn,sgLIFO / fogLCincluded UCPOP-LC help verify search-space reduction results preferenceaws minimal repair costs. true, UCPOP-LC ought generatesmaller search space DUnf, even though delay threats. resultsexpected. UCPOP DUnf, least-cost selection open conditions,generated largest search spaces; UCPOP-LC generated significantly smaller spaces;DUnf-LC LCFR generated smallest spaces.time, observed LCFR incurred unwieldy overhead, often takinglonger solve problem UCPOP, despite fact searching far fewernodes. part due particularly inecient implementation LCFRusing, part resulted fact computing repair costs bound taketime simply popping stack (as LIFO strategy), finding aw particulartype (as strategy prefers threats). therefore explored approximation strategies,reduce overhead aw selection accepting inaccuracy repair costcalculation. example, developed \Quick LCFR" (or QLCFR) strategy,calculates repair cost aw once, aw first encountered.successor node aw remains unresolved, QLCFR assumes repair6. planning problems cast CSPs planner Descartes (Joslin & Pollack, 1996; Joslin,1996), correspondence even direct.230fiFlaw Selection Strategiescost changed. experiments QLCFR showed promising meansmaking least-cost approach suciently fast pay overhead. Additionalapproximation strategies studied Srinivasan Howe (1995), experimentedthree variations LCFR, along fourth, novel strategy movescontrol burden user.3.3 Threat Delays RevisitedRecently, Gerevini Schubert (1996) revived idea aw selection strategytreat open conditions threats differently, suggested LIFOused tie-breaking strategy deciding among open conditions. combineideas ZLIFO strategy:ZLIFO fngLIFO / fog0LIFO / fog1New / fog2-1LIFO / fsgLIFOZLIFO strategy gives highest priority nonseparable threats, forced openconditions. neither nonseparable threats forced open conditions, ZLIFOselect open condition using LIFO. defers separable threats endplanning process. name ZLIFO intended summarize overall strategy. \Z"stands \zero-commitment", indicating preference given forced open conditions:repairing these, planner making commitment beyond must madenode ultimately refined complete plan. \LIFO" indicatesstrategy used selecting among unforced open conditions.open conditions repair cost exactly one, ZLIFO strategy uses tiebreaking strategy called \New". prefers repair open conditionestablished introducing new action repair open conditionestablished using element start state. Gerevini Schubert statepreference \gave improvements context Russell's tire changing domain . . .withoutsignificant deterioration performance domains" (1996, p. 104). Howeverdifference apparently dramatic, Gerevini believes implementationdetail, though open possibility study might show preferencesignificant (Gerevini, 1997).Gerevini Schubert make three primary claims ZLIFO:1. POCL planner using ZLIFO tend generate smaller search space oneusing pure LIFO strategy.2. reduction search space using ZLIFO, relative LIFO, correlatedcomplexity planning problem (where complexity measured numbernodes generated pure LIFO strategy).3. ZLIFO performs comparably LCFR relatively easy problems, generatessmaller search space harder problems.first two claims consistent found earlier LCFR studies.LIFO strategy pays attention repair costs, ZLIFO does, least indirectly,initial preference nonseparable threats, repair costtwo, secondary preference forced opens.231fiPollack, Joslin, & Paoluccithird claim harder square earlier LCFR study, LIFObased strategies, UCPOP DUnf, generated much larger search spacesleast-cost based strategies. explains ZLIFO's performance? Gerevini Schubertanswer question follows:Based experience search processes AI general, [a LIFO] strategymuch recommend it, simple default. first place, overheadcost low compared strategies use heuristic evaluation lookaheadprioritize goals. well, tend maintain focus achievementparticular higher level goal regression . . .rather attempting achievemultiple goals breadth-first fashion. [p. 103]point overhead important one. ZLIFO relatively inexpensive controlstrategy, competing strategy better job pruning search space mayend paying excessive overhead. second point addresses questionasking here, namely, ZLIFO could produce smaller search spaces. GereviniSchubert go say that:[m]aintaining focus single goal advantageous leastgoals achieved independent. instance, suppose twogoals G1 G2 achieved various ways, choosing particularmethod achieving G1 rule methods achieving G2.maintain focus G1 solved, attempting G2,total cost solving goals sum costs solvingindependently. switch back forth, solutionsgoals involve searches encounter many dead ends, combined costmuch larger. tend search unsolvable subtreeG1 search tree repeatedly, combination various alternativesG2 search tree . . .. [p. 103]certainly plausible explanation. key remaining question, course, extent explanation carries many planning problems involveinteracting goals.4. Experimental Comparison Flaw Selection Strategiesdiscussed previous section, several different proposals madeliterature best reduce size search space POCL planning.include:giving preference threats open conditions;giving preference certain kinds threats (either separable forced threats),delaying threats open conditions resolved;giving preference aws minimal repair cost;giving preference recently introduced aws.232fiFlaw Selection StrategiesMoreover, different strategies combined preference schemes different ways,apparently con icting claims made effects preferencessearch-space size.resolve con icts, performed experimental comparisons POCL plannersusing variety aw selection strategies. gave particular attention comparisonLCFR ZLIFO, apparently con icting claims. LCFR generatessearch space treating aws uniformly, using least-cost approach choose amongthem. ZLIFO distinguishes aw types (non-separable threats, open conditions,separable threats), uses modified LIFO approach select among awsclass. original LCFR studies would led us predict ZLIFO would generatelarger search spaces LCFR, Gerevini Schubert found oppositetrue. aimed, then, explain discrepancy.principal focus search-space size, two reasons. First, puzzle raisedLCFR ZLIFO one space, time. mentioned earlier, easy seeZLIFO would faster LCFR, even per node basis. least-cost strategymust compute repair costs, ZLIFO need pop stack containing right typeaws. puzzle us ZLIFO faster, generated smallersearch spaces. Second, believe understanding effect search control strategiessearch-space size lead development approximation techniques producespeed-up well; QLCFR strategy (Joslin & Pollack, 1994) Srinivasan Howe'sstrategies (1995) examples this.However, secondary goal analyze time requirements strategiescompared, therefore collected timing data experiments. discussSection 4.6, strategy tends generate smallest search space achieves enoughreduction pay overhead, large.4.1 Experimental Designconduct comparison, implemented set aw selection strategies UCPOPv.4.7 Table 1 lists strategies implemented. Except LCFR-DSep DUnfGen, discussed later, implemented strategies described Section3.tested strategies three problem sets, also used earlier work (Joslin& Pollack, 1994) Gerevini Schubert's (1996):1. Basic Problems, 33 problems taken test suite distributedUCPOP system. include problems variety domains, including7. Note experiments earlier LCFR paper (Joslin & Pollack, 1994) GereviniSchubert's (1996) ZLIFO paper run using earlier version (v.2) UCPOP. result,number nodes produced experiments sometimes differs reportedtwo papers. appears largely due fact UCPOP v.4 puts elements new setopen conditions onto aw list reverse order way UCPOP v.2 (Gerevini,1997). discussed Sections 4.3{4.5, studied uence ordering change alsocollecting data using modified version UCPOP v.4 reversed order conditionsentered open list. resulting numbers similar previously published,identical, leading us conclude additional subtle differences v.2v.4. However, experiments report run using versionUCPOP, believe fair comparison strategies.233fiPollack, Joslin, & PaolucciUCPOPUCPOP-LCDSepDSep-LCDUnfDUnf-LCDUnf-GenLCFRLCFR-DSepZLIFOfn,sgLIFO / fogLIFOfn,sgLIFO / fogLCfngLIFO / fogLIFO / fsgLIFOfngLIFO / fogLC / fsgLIFOfn,sg0LIFO / fn,sg1LIFO / fogLIFO / fn,sg2-1LIFOfn,sg0LIFO / fn,sg1LIFO / fogLC / fn,sg2-1LIFOfn,s,og0LIFO / fn,s,og1LIFO / fn,s,og2-1LIFOfo,n,sgLCfn,ogLC / fsgLCfngLIFO / fog0LIFO / fog1New / fog2-1LIFO / fsgLIFOTable 1: Implemented Flaw Selection Strategiesblocks world, Monkeys Bananas problem, Pednault's (1988) briefcase-andoce problem, Russell's (1992) tire changing world, etc.2. Trains Problems, three problems taken TRAINS transportation domain(Allen, Schubert, & et al., 1995).3. Tileworld Problems, seven problems taken Tileworld domain (Pollack &Ringuette, 1990).ran strategy problem twice. first time, imposed node limit,10,000 nodes basic problems, 100,000 nodes Trains Tileworldproblems. second time, imposed time limit, 100 seconds basic problems,1000 seconds Trains Tileworld problems.Gerevini Schubert experimented several different node selection strategiesTrains Tileworld domains, facilitate comparison also used nodeselection strategies did. basic problems, used + OC .reporting results, make use raw counts nodes generatedcomputation time seconds taken, also compute measure badly strategyperformed given problem set problems. call measure %-overrun,compute follows. Let minimum node count given problemstrategies tested, let c node count particular strategy .%-overrun(S ) = [(c , m)=m] 100Thus, example, best strategy given problem generated 100 nodes,strategy generated 200 nodes would 100 %-overrun problem.strategy best given problem %-overrun 0 problem.Section 4.6, make use similarly computed %-overruns computation time.strategy hit node limit, set c relevant node limit (10,000 100,000)compute node-count %-overrun.8 Similarly, strategy hit time limit, usedrelevant time limit (100 1000) compute computation-time %-overrun.8. way UCPOP completes basic iteration, sometimes go somewhat beyondspecified node limit terminating run. cases, used node limit value, ratheractual number nodes generated, computation %-overrun.234fiFlaw Selection StrategiesOnline Appendix provides raw data|node counts computation-time taken|experiments conducted; also includes computed %-overruns.conducting experiments these, one set either node- time limitcutoff strategy/problem pair. However, always danger cutoffsunfairly bias data, limits set way certain strategies failwould instead succeeded limits increased slightly. carefully analyzeddata help eliminate possibility bias; details given Appendix A.4.2 Value Least-Cost Selectiondescribed overall experimental design, turn analysis results. begin, sought re-establish claims originally made earlierwork. Specifically, wanted first reconfirm, using larger data set, least-costaw selection effective technique reducing size search space generatedPOCL planner. therefore ran experiment compared nodecounts five strategies earlier studied|LCFR, DUnf, DUnf-LC, UCPOP,UCPOP-LC|plus one new one, DUnf-Gen, explained below.results experiment shown Figures 2 3. former log-logscatter plot, showing performance six strategies 33 problemsbasic set. problems sorted minimal number nodes generatedsix strategies. Thus, left-hand side graph includes problemsleast one six strategies found relatively easy, right-hand sideproblems hard six strategies. omitted problems nonesix strategies able solve. actual number nodes generatedstrategy plotted Y-axis, minimal number nodes problem,X-axis. LCFR's performance highlighted line connecting data points.graph shows that, general, LCFR generates small search spaces problem set,relative strategies class. six problems LCFRwithin 10% minimum. Three Get-Paid/Uget-Paid classproblems|including two \hardest" problems (UGet-Paid3 UGet-Paid4).discuss class problems Section 4.5.alternative view data given Figure 3, shows aggregate performance six strategies, i.e., average node-count %-overrun basicproblems. seen, LCFR smallest average %-overrun.Figures 4 5 present similar views data Tileworld domain, Figure6 gives data Trains problems. Trains domain, six strategiesable solve easiest problem (Trains1), simply show actual node countsFigure 6. omitted two data points, extremeinclusion graph made impossible see differences among strategies:LCFR DUnf-Gen + OC + UC node selection took 28,218, 35,483 nodes,respectively, solve problem.Tileworld Trains problems, observed sorts interactions node aw selection strategies seen Gerevini Schubert. Specifically,LCFR performs relatively poorly + OC Tileworld problems, performspoorly + OC + UC Trains problems. However, paired235fiPollack, Joslin, & Paolucci10000Nodes Generated (Log)1000UCPOPDUnfUCPOP-LCDUnf-LCDUnf-GenLCFR1001010100100010000Minimum Number Nodes Generated (Log)Figure 2: Basic Problems: Node Counts Strategies without Forced-Flaw Delaynode-selection strategies, LCFR produces smallest search spaces strategiesclass.sum, LCFR tend produce smaller search spaces strategiesclass. question remains. LCFR uses least-cost strategy, side effectprefer forced aws, since forced aws low-cost aws. thereforeconceivable LCFR's performance mostly even fully due preference forcedaws, (or greatly) uenced use least-cost strategy unforcedaws. hypothesis could explain DUnf-LC consistently outperforms DUnf,UCPOP-LC consistently outperforms UCPOP.address issue included DUnf-Gen experiment. DUnf-Gensimple strategy prefers forced aws kind, otherwise uses LIFO regime.would expect DUnf-Gen LCFR perform similarly, since frequently makedecision. Specifically, select aw nodeforced aw; differ unforced aws, DUnf-Genselecting recently introduced aw LCFR selecting least-cost aw.practice, DUnf-Gen's performance closely mimicked LCFR's. basicproblem set marginally worse LCFR. fact, marginally betterreverse order planner adds preconditions new stepopen list (see Section 4.4). LCFR somewhat better DUnf-GenTrains Tileworld problems, true regardless orderpreconditions added open list, extent better varies.Thus, data inconclusive value using least-cost strategy unforcedaws. LCFR clearly benefits selecting forced aws early (as side effect preferring236fiFlaw Selection Strategies35003000Node-Count %-Overrun25002000150010005000LCFRDUnf-GenUCPOP-LCUCPOPDUnf-LCDUnfFigure 3: Basic Problems: Aggregate Performance Strategies without Forced-Flaw Delay10000010000Nodes Generated (Log)UCPOP S+OCUCPOP-LC S+OCDUnf S+OCDUnf-LC S+OCDUnf-Gen S+OC1000DUnf-Gen S+OC+UCDUnf-Gen S+OC+.1UC+FLCFR S+OCLCFR S+OC+UCLCFR S+OC+.1UC+F10010101001000Minimum Number Nodes Generated (Log)Figure 4: Tileworld Problems: Node Counts Strategies without Forced-Flaw Delay237fiPollack, Joslin, & Paolucci3500030000250002000015000100005000UCPOPS+OCUCPOP-LCS+OCDUnfS+OCDUnf-LCS+OCLCFRS+OCDUnf-GenS+OCDUnf-GenS+OC+.1UC+FDUnf-GenS+OC+UCLCFRS+OC+.1UC+FLCFRS+OC+UC0Figure 5: Tileworld Problems: Aggregate Performance Strategies without Forced-FlawDelay800700Nodes Generated600500400300200100UCPOPS+OCDUnfS+OCDUnf-GenS+OC+.1UC+FDUnf-GenS+OCUCPOP-LCS+OCDUnf-LCS+OCLCFRS+OCLCFRS+OC+.1UC+F0Figure 6: Trains 1: Node Counts Strategies without Forced-Flaw Delay238fiFlaw Selection Strategiesleast-cost aws), may matter whether continues use least-cost strategyunforced aws. indeed generally sucient use least-cost strategyforced aws, ZLIFO's performance somewhat less puzzling, since ZLIFO also prefersforced aws. However puzzle completely resolved. all, DUnf-Gen, likeZLIFO, prefers forced aws makes LIFO-based decisions unforced aws,performance clearly inferior LCFR's, neither clearly superior.Even use LIFO unforced aws obviously increase search-space,neither appear decrease it.4.3 Comparing LCFR ZLIFOnext turn direct comparison LCFR ZLIFO. Gerevini Schubert comparedstrategies problems. get complete picture performanceLCFR ZLIFO, ran problems three problemsets.data basic problem set shown Figure 7. sorted problemsdifference node counts produced LCFR ZLIFO. Thus, problemsnear left-hand side graph LCFR generated smaller searchspace, problems near right-hand side ones ZLIFO spaceadvantage. omit problems neither strategy could solve.seen, problems (notably R-Test2, Move-Boxes, Monkey-Test2),LCFR generates much smaller search space ZLIFO, problems (notablyGet-Paid4, Hanoi, Uget-Paid4, Uget-Paid3), ZLIFO generates much smaller searchspace. problems LCFR also worse strategies mentionedSection 4.2.noted earlier, one major changes UCPOP v.2 v.4v.4 puts elements new set open conditions onto aw list reverseorder v.2. ordering may make difference, particularly LIFO-basedstrategies. Indeed, researchers suggested one reason LIFO-based strategymay perform well exploit decisions made system designerswriting domain operators, since sense natural list constrainingpreconditions operator first (Williamson & Hanks, 1996). therefore also collecteddata modified version UCPOP, preconditions step enteredonto open condition reverse order would normally entered.discuss results modification detail next two sections,now, simply present node counts LCFR ZLIFO reversed preconditioninsertion, Figure 8. seen, problems reversingprecondition ordering significant effect (notably FIXB MonkeyTest2),large LCFR ZLIFO showed relative performance.problems basic set, dicult discern obvious pattern performance. contrast Gerevini Schubert suggest, seem clearcorrelation diculty problem, measured terms nodes generated,relative performance LCFR ZLIFO. (In fact, little dicult determine strategy's node-count serve measure diculty.)hand, true aggregate, ZLIFO generates smaller search spaces LCFR239fiR-TEST2240UGET-PAID3UGET-PAID4MONKEY-TEST2HANOIGET-PAID4GET-PAID3GET-PAID2UGET-PAID2UGET-PAIDROAD-TESTFIX5FIX4GET-PAIDFIXAR-TEST1FIX2TEST-FERRYMONKEY-TEST1FIX1SUSS-ANOMTWO-INV3FIX3RAT-INSULINPRODIGY-SUSSTWO-INV4FIXBMOVE-BOXESNodes Generated (Log)R-TEST2UGET-PAID3UGET-PAID4HANOIGET-PAID4GET-PAID3TEST-FERRYGET-PAID2UGET-PAID2HO-DEMOTOW-INV3UGET-PAIDTOW-INV4ROAD-TESTFIX5FIX4GET-PAIDR-TEST1SUSS-ANOMFIX2FIX1FIX3MONKEY-TEST1PRODIGY-SUSSRAT-INSULINFIXAMONKEY-TEST2MOVE-BOXESNodes Generated (Log)Pollack, Joslin, & Paolucci100001000100LCFR -DefaultZLIFO -Default101Figure 7: Basic Problems: Node Counts LCFR ZLIFO100001000100ZLIFO-ReversedLCFR-Reversed101Figure 8: Basic Problems: Node Counts LCFR ZLIFO Reversed PreconditionInsertionfiFlaw Selection Strategiesbasic problems. default precondition ordering, ZLIFO obtains average%-overrun 212.62, LCFR obtains 647.57. reverse ordering, ZLIFO's average%-overrun 244.24, LCFR's 914.87. fact LCFR's relative performanceworse preconditions entered reverse direction results primarilyfailure MonkeyTest2 reverse direction.Trains data scant. Neither LCFR ZLIFO solve hardest problem,Trains3, regardless whether preconditions entered default reverseorder. (In fact, none strategies studied able solve Trains3.) But, leastpreconditions entered default order, ZLIFO solve Trains2,LCFR cannot. reverse precondition insertion, neither strategy solve Trains2.data shown Figure 9. Note LCFR's performance essentiallynode-selection strategies shown.Finally, Tileworld data, default order precondition insertion, shownFigure 10. place LCFR clearly generates smaller search spacesZLIFO. also plotted data reverse precondition insertion,strategies affected change. however, one notableexception: reversed insertion, ZLIFO (with + OC + :1UC + F ) much better|indeed, well LCFR. return uence precondition orderingTileworld problems Section 4.5.now, however, enough observe experiments show ZLIFOtend generate smaller search spaces LCFR. basic problem set,regardless order precondition insertion, Trains one ordering (andworse LCFR ordering), well LCFRTileworld problems preconditions inserted reverse order.exception Tileworld problem set preconditions inserted default order:LCFR better.4.4 Value Separable-Threat Delayfirst two analyses essentially aimed replicating earlier results literature,namely LCFR results ZLIFO results. next address questionsquare results one another.Recall LCFR ZLIFO differ two key respects. First, LCFR treats awsuniformly, ZLIFO distinguishes among aw types, giving highest preference nonseparable threats, medium preference open conditions, lowest preference separablethreats. Second, LCFR uniformly makes least-cost selections, ZLIFO uses LIFOstrategy secondary aw-type preferences (but giving preference forced openconditions). comparisons made Section 4.2 suggest use LIFO strategyunforced aws best make little difference search-space size, may possibly lead generation larger search spaces. hand, first differencepresents obvious place look relative advantage ZLIFO. all, ZLIFOdelaying separable threats, Peot Smith demonstrated effectivenessapproach DSep strategy.Peot Smith's proof DSep never generate larger search space UCPOPtransfer LCFR. planning problems LCFR generate241fiPollack, Joslin, & Paolucci100000Nodes Generated (Log)100001000ZLIFO S+OCZLIFO S+OC+.1UC+FLCFR S+OCLCFR S+OC+.1UC+F100101TRAINS1 (Default)TRAINS1 (Reverse)TRAINS2 (Default)Figure 9: Trains Problems: Node Counts LCFR ZLIFO100000Nodes Generated (Log)10000ZLIFO S+OC1000ZLIFO S+OC+.1UC+FLCFR S+OCLCFR S+OC+UCLCFR S+OC+.1UC+F100101TW-EZTW-1TW-2TW-3TW-4TW-5TW-6Figure 10: Tileworld Problems: Node Counts LCFR ZLIFO242fiFlaw Selection Strategiessmaller search space DSep. proof relies fact that, DSep, open conditionsselected order, regardless threats selected. selectionthreat LCFR uence repair cost open condition (e.g., promotingaction longer available potential establisher condition),turn affect order remaining open conditions selected.Nonetheless, despite fact one can't guarantee delaying separable threatslead reduction search-space size, motivation behind DSep still appealing:separable threats may often simply disappear subsequent planning, naturally lead reduction search-space size. reason, implemented slightlymodified version LCFR, called LCFR-DSep, separable threatsdelayed. Note relatively easy UCPOP system, providesswitch, dsep switch, turned automatically delay repairseparable threats. defined earlier Table 1, definition LCFR-DSep is:LCFR-DSep fn,ogLC / fsgLChypothesis ZLIFO's reduction search-space size largely dueincorporating DSep approach, LCFR-DSep ought \the best worlds",combining advantages LCFR's least-cost approach advantages DSepapproach.basic problems, LCFR-DSep proved smallest average node-count %overrun basic problems strategies tested. Moreover, true evenreversed order preconditions operator added openlist. Figure 11 gives average node-count %-overruns unmodified UCPOP v.4(labeled \default") modified version reversed precondition ordering(labeled \reverse"). Reversing ordering effect conclusion LCFR-DSepgenerates smallest search spaces problems; fact, general littleaffect relative performance strategies all. notable exception,mentioned earlier, relative performance LCFR DUnf-Gen ips.detailed comparison, plot node counts basic problems LCFR,ZLIFO, Separable-Threat Delay strategies Figure 12. ease comparison,show data sorted difference LCFR ZLIFO's node counts.problems near left-hand side graph are, again, LCFR generatedsmaller search space ZLIFO; problems near rightgenerated larger search space. seen, LCFR-DSep nearly always wellas, better LCFR. much better ZLIFO problems LCFRgood at. also much better LCFR problems ZLIFO good at.However, ZLIFO still outperforms LCFR-DSep latter class problems.Another view data given Figure 13, log-log scatter plot basicproblems, strategies studied. time highlighted LCFR-DSep'sperformance. Although problems produce minimalsearch space, performance individual problems actually quite good, consistentgood aggregate performance.least basic problems, augmenting simple LCFR strategy delayseparable threats reduces search space expected. turn suggestsLCFR generates larger search space ZLIFO, due large part fact243fiPollack, Joslin, & Paolucci40003500Node-Count %-Overrun30002500Default2000Reverse150010005000LCFRDSepDSepLcZLIFODSepLCFRDUnfGenUCPOP-LCUCPOPDUnfLCDUnfFigure 11: Basic Problems: Aggregate Performance Strategies10000Nodes Generated (Log)1000ZLIFO100LCFRLCFR-DSep10UGET-PAID3HANOIUGET-PAID4GET-PAID4GET-PAID3GET-PAID2TEST-FERRYHO-DEMOUGET-PAID2TOW-INV3TOW-INV4UGET-PAIDROAD-TESTFIX4PRODIGY-P22R-TEST1FIX5GET-PAIDFIX2SUSS-ANOMFIX1FIX3PRODIGY-SUSSMONKEY-TEST1FIXARAT-INSULINMOVE-BOXESMONKEY-TEST2R-TEST21Figure 12: Basic Problems: Node Counts LCFR, ZLIFO, DSep Strategies244fiFlaw Selection Strategies100001000Nodes Generated (Log)UCPOPDSepDUnfUCPOP-LCDUnf-LCZLIFODUnf-GenLCFRDSep-Lc100LCFR-DSep1010100100010000Minimum Number Nodes Generated (Log)Figure 13: Basic Problems: Node Counts Strategiesdelay separable threats. ZLIFO's primary advantage relative LCFR seemsuse LIFO strategy unforced threats, rather separable-threatdelay component. Combining separable-threat delay least-cost approach yieldsstrategy tends generate smaller search spaces either strategybasic problem set. However, analysis Trains Tileworld problem sets revealssituation little complicated comparison basic problems wouldsuggest, discuss next section.4.5 Need Domain InformationTileworld Trains domains problems challenge overly simple conclusions mightdraw basic problem sets. consider set problems turn.4.5.1 Tileworld ProblemsTileworld domain involves grid tiles holes, goal fill holetile. goal achieved fill operator, two preconditions:agent must hole, must holding tile. encoding, agenthold four tiles time. go operator used achieve (sub)goalhole, pickup operator used achieve (sub)goal holding tile.normal way, go precondition location, namely whatever locationagent move from. Pickup precondition location tile.problems Tileworld problem set differ one another number holesagent must fill: problem adds another hole.245fiPollack, Joslin, & Paolucci100000LCFR S+OC+UC10000LCFR S+OC+.1UC+FDUnf-Gen S+OC+UCNodes Generated (Log)DUnf-Gen S+OC+.1UC+FDUnf-Gen S+OCLCFR S+OCLCFR-DSep S+OC+UCZLIFO S+OC+.1UC+F1000ZLIFO S+OCLCFR-DSep S+OC+.1UC+FDSep-LC S+OCLCFR-DSep S+OCDUnf S+OCDSep S+OC100UCPOP-LC S+OCDUnf-LC S+OCUCPOP S+OC10101001000Minimum Number Nodes Generated (Log)Figure 14: Tileworld Problems: Node Counts StrategiesFigures 14 gives log-log plot various strategies Tileworld problems,preconditions entered default order. Note LCFR (S + OC + UC )strategy highlighted. Three strategies almost indistinguishable LCFR(S + OC + UC ), namely, LCFR (S + OC + :1UC + F ), DUnf-Gen (S + OC + UC )DUnf-Gen(S + OC + :1UC + F ). strategies performed worse.easily seen Figure 15, gives aggregate performance leading strategies:able solve seven Tileworld problems. fact, leading strategiesable solve seven Tileworld problems without generating 1800 nodesproblem. contrast, remaining strategies failed least one, four,seven problems, given limit 100,000 nodes generated.originally surprising us Tileworld problems, delaying separable threats actually seems hurt performance. strategies best likeLCFR DUnf-Gen delay separable threats. LCFR-DSep, ZLIFO, DSep-LC,DSep generated larger search spaces, contrast would predictedgiven experiments basic problem set.understand result, looked detail planning trace problems.revealed Tileworld domain, early resolution separable threatsimportant advantage: imposes turns correct temporal orderingsteps going tile (to pick up), carrying hole. Virtuallystrategies create subplans like one shown Figure 16. goals involve fillingholes, planners insert steps go pick tile, go hole.point, two separable threats: (1) effect going hole, :at(X ), threatenslink going tile picking (at(Z )), (2) effect going246fiFlaw Selection Strategies1009080Node-Count %-Overrun706050403020100LCFRS+OC+UCLCFRS+OC+.1UC+FDUnf-GenS+OC+UCDUnf-GenS+OC+.1UC+FDUnf-GenS+OCFigure 15: Tileworld Problems: Aggregate Performance Leading Strategiesat(X)GO(X,Y)at(Y)loc(H,Y)holding(T)~at(W)at(W)GO(W,Z)at(Z)tile(T)loc(T,Z)~at(X)FILL(H)filled(H)PICKUP(T)Figure 16: Typical Partial Plan Tileworld Domaintile, :at(W ), threatens link going hole filling (at(Y )).threats separable, X W unbound; planner yet knowtraveling from. one valid temporal orderingresolve threats: going tile must precede picking tile, turn mustprecede going hole. temporal ordering determined, planning goessmoothly.contrast, ordering decision made, planner often \get lost",attempting find plans goes location holehole tile. many ways attempt this, many different247fiPollack, Joslin, & Paolucci100000LCFR-DSep S+OC+.1UC+F10000ZLIFO S+OC+.1UC+FLCFR S+OC+UCNodes Generated (Log)LCFR S+OC+.1UC+FDUnf-Gen S+OC+.1UC+FLCFR-DSep S+OC+UCDUnf-Gen S+OCDUnf-Gen S+OC+UC1000DUnf-LC S+OCLCFR-DSep S+OCDSep-LC S+OCLCFR S+OCZLIFO S+OCUCPOP-LC S+OC100DUnf S+OCDSep S+OCUCPOP S+OC10101001000Minimum Number Nodes Generated (Log)Figure 17: Tileworld Problems: Node Counts Reversed Precondition Insertiontiles select, many different locations move among. planner may try manyalternatives determining fundamental inconsistencyplans, destined fail. larger number holes filled,worse situation becomes.Sometimes planner may make right decision temporal ordering evendeferred separable threats. faced partial plan Figure 16, plannerselect threat, select among several open conditions. attemptestablish precondition going hole (at(X )) reusing effect goingtile (at(Z )), reverse, attempt establish precondition goingtile (at(W )) reusing effect going hole (at(X )). course, firstsolution right one, includes critical temporal ordering constraint,second eventually fail.order open conditions selected determine twochoices planner makes. preconditions entered default order, plannersdelay separable threats end making latter, problematic choice. contrast,preconditions entered reverse order, planners make turnscorrect choice. Thus, experiments reversed preconditioninsertion, see different pattern performance, shown Figures 17{18.9preconditions entered reverse order, larger number strategiesperform well, solving problems. particular, + OC + :1UC + F node9. preserve readability, Figure 18, used \(1)" denote + OC , \(2)" + OC + U C ,\(3)" + OC + U C + :1F .248fi249UCPOP (1)DUnf (1)DSep (1)UCPOP-LC (1)LCFR (1)ZLIFO (1)DSep-LC (1)LCFR-DSep (1)DUnf-LC(1)DUnf-Gen (2)DUnf-Gen (1)LCFR-DSep (2)DUnf-Gen (3)LCFR (3)LCFR (2)ZLIFO (3)LCFR-DSep (3)Node-Count %-OverrunFlaw Selection Strategies50000450004000035000300002500020000150001000050000Figure 18: Tileworld Problems: Aggregate Performance Strategies ReversedPrecondition InsertionfiPollack, Joslin, & Paolucci250002000015000TRAINS1TRAINS2100005000DSep-LCS+OCLCFR-DSepS+OCLCFR-DSepS+OC+.1UC+FZLIFOS+OC+.1UC+FDUnfS+OCLCFR-DSepS+OC+UCZLIFOS+OCDSepS+OC0Figure 19: Trains Problems: Node Countsselection, performance LCFR, DUnf-Gen, ZLIFO, LCFR-DSep virtually indistinguishable. important note leading strategies delay separablethreats|LCFR DUnf-Gen|are affected much reversal precondition insertion Tileworld problems; fact, LCFR's performance identical cases.contrast, strategies use separable-threat delay|LCFR-DSep, ZLIFO, DSepLC|all perform much better reverse precondition insertion. explainedanalysis above.sum, important Tileworld domain planner recognize,early possible, certain required temporal orderingssteps successful plan. Every successful plan involve going tile goinghole, although exibility order multiple holes visited,interleaving picking tiles dropping holes. strategiesstudied, two different methods led temporal constraint addedplan. added planner selected separable threat resolve,added selected one particular precondition resolve another.4.5.2 Trains Get-Paid ProblemsTrains domain present somewhat different variation original conclusions.Trains domain involves set locations objects, goal transport variousobjects specific starting locations specified destinations. Gerevini Schubertstudied three Trains problems. strategies failed successfully completehardest (Trains3) within either 100,000 node 1000 second limit. Moreover,many also failed second hardest (Trains2). Caution must therefore takeninterpreting results, limited number data points.250fiFlaw Selection StrategiesFigure 19 gives node counts Trains domain, preconditions inserteddefault order. show strategies able solve Trains1 Trains2.results closer would predicted basic problem setresults Tileworld. particular, LCFR-DSep well, generatingmuch smaller search spaces LCFR. However, slightly worse ZLIFO.Recall saw pattern performance subset basic problems,specifically Get-Paid/Uget-Paid problems. There, LCFR-DSep improvedLCFR, generate small search spaces ZLIFO. turnssimilar factors uencing sets problems, instructive considerdetail planning done ZLIFO LCFR-DSep Get-Paid/Uget-Paid problemsunderstand occurring.Like Trains domain problems, Get-Paid/Uget-Paid problems involve movingparticular objects specified locations. Get-Paid/Uget-Paid domain threeobjects: paycheck, dictionary, briefcase. generally formulated, initialstate three home, paycheck briefcase. goal depositpaycheck bank, bring dictionary work, briefcase home.dictionary paycheck moved briefcase. human,solution problem obvious. dictionary must put briefcase,must carried work, dictionary taken out. briefcase mustcarried home. addition, stop must made bank, either way workway home, point paycheck must taken briefcasedeposited.ZLIFO LCFR-DSep take different paths solving problem. ZLIFO beginsforming plans get paycheck bank dictionary work. goalsselected first forced: one way get paycheckbank (carry there), similarly one way get dictionary oce (carrythere). contrast, two possible ways get briefcase home: eitherleaving (i.e., reusing initial state) carrying somewhere else(i.e., adding new step). LIFO mechanism proceeds complete plansachieving goals getting paycheck bank dictionary work,beginning work remaining goal, getting briefcase home. point,goal easy solve. needed plan route home wherever briefcaseend two errands.LCFR-DSep, like ZLIFO, begins selecting forced goals getting dictionaryoce getting paycheck bank. However, instead next completingplans goals, LCFR-DSep continues greedily select least-cost aws, thusbegins work achieving goal getting briefcase home. Unfortunately,point clear briefcase needs moved home from, hence LCFRDSep begins engage lengthy process \guessing" briefcaseend tasks, planned tasks.1010. diculty LCFR-DSep encounters greedily picking low-cost aws might reducedlookahead several planning steps, determine accurate repair cost. approachtaken branch-n mechanism O-Plan (Currie & Tate, 1991). Significant overhead involvedstrategy, however.251fiPollack, Joslin, & Paoluccikey decision Get-Paid/Uget-Paid domain|and, turns out, Trainsdomain|is related to, subtly different key decision Tileworld domain.Get-Paid/Uget-Paid Trains, key insight plannerimportant temporal ordering goals. goal getting briefcase homegoing achieved goal taking dictionary work. However,recognition constraint affected separable-threat delay,Tileworld. Instead, happens domains higher-cost aw interactslower-cost one, causing latter become fully constrained.tempting think finally case LIFO-based strategyadvantageous. all, example, completely determiningachieve one goal, make much easier know solve another goal. useZLIFO (or alternative LIFO-based strategy) guarantee interactionshigh- lower-cost aws exploited. particular interactionsamong two unforced aws, order goals agenda lead ZLIFOmake inecient choice. Thus, modified problem briefcasework initial state, ZLIFO LCFR-DSep solved problem quickly(178 nodes ZLIFO 157 LCFR-DSep). Note modification removesproblematic interaction low-cost high-cost aw.Finally, note effectiveness LIFO strategies heavily dependentorder preconditions entered onto open list. Figure 20 givesnode counts Trains domain reverse precondition insertion.plot strategies solve Trains 1 Trains2. case,two strategies: LCFR-DSep DSep-LC. strategies rely LIFOopen-condition selection, ZLIFO, DSep, DUnf-Gen, UCPOP, significantly worsepreconditions correct order. extent LIFOhelps domains, appears ability exploit decisions madesystem designers writing domain operators, suggested WilliamsonHanks (1996).4.6 Computation Timecovered key questions set address: relative effectsalternative search-control strategies search-space size, and, particular,reconcile apparently con icting approaches LCFR ZLIFO? concludedLCFR-DSep combines main advantages reducing search-space size twostrategies, namely LCFR's use least-cost selection mechanism, least forced aws,ZLIFO's use separable-threat delay. final question concerns price onepay use LCFR-DSep|or matter, alternative strategies. achievereduction search-space size, necessary spend vastly time processing?strategies pay themselves?answer questions, collected timing data experiments. Figures 2122 gives data basic problems, experiments run nodelimit run time limit. (As detailed Appendix A, resultsexperiments node limit time limit similar.) sawlittle uence precondition ordering basic problems, analyze data252fiFlaw Selection Strategies300002500020000TRAINS115000TRAINS21000050000LCFR-DSepS+OC+UCLCFR-DSepS+OC+.1UC+FLCFR-DSepS+OCDSep-LCS+OCFigure 20: Trains Problems: Node Counts Reversed Precondition Insertion350300Computation-Time %-Overrun250200Time LimitNode Limit150100500DSep-LcZLIFOLCFR-DSepDSepFigure 21: Basic Problems: Aggregate Computation Time Performance Leading Strategiesdefault precondition ordering. show one graph strategies, anotherincludes \leading strategies", make possible see distinctions amongthem.253fiPollack, Joslin, & Paolucci30000Computation-Time %-Overrun2500020000Time Limit15000Node Limit1000050000DSepLcZLIFOLCFRDSepDSepUCPOPUCPOP-LCDUnfGenLCFRDUnfLCDUnfFigure 22: Basic Problems: Aggregate Computation Time Performancetiming data show LCFR-DSep does, large, pay overheadbasic problems generating smaller search spaces (and therefore processfewer nodes). run time limit, LCFR-DSep's time performance almostidentical ZLIFO's, despite fact repair cost computations expensivestack-popping LIFO strategy. run node limit, LCFR-DSepshow worse time performance ZLIFO aggregate, still performs markedly betterstrategies. change relative performance results casesstrategies fail node limit: LCFR-DSep takes longer generate 10,000nodes.Another interesting observation DSep-LC best time performancebasic problem set. perhaps surprise, DSep-LC closelyapproximates LCFR-DSep. differs primarily preference nonseparable threats,case tend low repair costs. Whenever node includes nonseparable threat, DSep-LC quickly select threat, without compute repaircosts. speed advantage outweighs cost processing extra nodes sometimesgenerates.Figures 23{26 provide timing data Trains Tileworld domains.11real surprises. computation times taken parallel quite closely sizesearch spaces generated. strategies generate smallest search spacesalso fastest. Trains problems, see DSep-LC serve11. omitted strategies poorly, performing worse node- time-limitexperiments strategies graphed. Note ran reverse-order experimentsnode limit.254fiFlaw Selection Strategies70006000Computation-Time %-Overrun50004000Default-Node LimitDefault-Time Limit3000200010000LCFR(2)DUnfGen(2)LCFR(3)DUnfGen(3)DUnfGen(1)ZLIFO(1)LCFR(1)ZLIFO(3)LCFRDSep(2)LCFRDSep(3)DSep(1)Figure 23: Tileworld Problems: Aggregate Computation Time Performance LeadingStrategiesgood approximation technique LCFR-DSep. Although generates nodesLCFR-DSep, somewhat faster.125. Conclusionpaper, synthesized much previous work aw selection partialorder causal link planning, showing earlier studies relate one another,developed concise notation describing alternative aw selection strategies.also presented results series experiments aimed clarifying effectsalternative search-control preferences search-space size. particular, aimedexplaining comparative performance LCFR ZLIFO strategies. showedneither aw selection strategies consistently generates smaller search spaces,combining LCFR's least-cost approach delay separable threatsincluded ZLIFO strategy, obtain strategy|LCFR-DSep|whose spaceperformance nearly always good better LCFR ZLIFO given problem.therefore concluded much ZLIFO's advantage relative LCFR due delayseparable threats rather use LIFO strategy. Although unableresolve question whether least-cost selection required unforced, wellforced aws, found evidence LIFO strategy unforced aws better.hand, separable-threat delay clearly advantageous. open question exactlyadvantageous. conducted preliminary experiments suggest12. interpreting Trains timing data, important note strategies shown|notablyUCPOP, UCPOP-LC, Dunf, failed solve Trains2 within either node time limit.255fiPollack, Joslin, & Paolucci900800Computation-Time %-Overrun700600500400300200100S+OC+UCDUnf-GenS+OCDUnf-GenS+OCLCFR-DSepS+OCDUnf-LCS+OCDSep-LCS+OC+.1UC+FDUnf-GenS+OC+.1UC+FLCFRS+OC+UCLCFRS+OC+.1UC+FLCFR-DSepS+OC+.1UC+FZLIFOS+OC+UCLCFR-DSep0Figure 24: Tileworld Problems: Aggregate Computation Time Performance LeadingStrategies Reversed Precondition Insertion2500Computation-Time %-Overrun20001500Default - Node LimitDefault-Time Limit1000500S+OCUCPOPS+OCLCFR-DSepS+OC+UCLCFR-DSepS+OC+.1UC+FLCFR-DSepS+OCDSep-LCS+OC+.1UC+FZLIFOS+OCZLIFOS+OCDUnfS+OCDSep0Figure 25: Trains Problems: Aggregate Computation Time Performance Leading Strategies256fiFlaw Selection Strategies20001800Computation-Time %-Overrun1600140012001000800600400200S+OCDSepS+OC+.1UC+FZLIFOS+OCZLIFOS+OC+UCLCFR-DSepS+OC+.1UC+FLCFRS+OCDUnf-LCS+OCLCFRS+OCUCPOP-LCS+OCLCFR-DSepS+OC+.1UC+FLCFR-DSepS+OCDSep-LC0Figure 26: Trains Problems: Aggregate Computation Time Performance Leading Strategies Reversed Precondition Insertion257fiPollack, Joslin, & Paoluccimuch search-space reduction results delaying separable threats alsoachieved making separation systematic, something UCPOP v.4 do.also considered question computation time, showed often LCFR-DSeprequires computation time comparable ZLIFO. LCFR-DSep thereforeseen paying computational overhead search-space reduction. Moreover,Peot Smith's DSep-LC provides good approximation LCFR-DSep: althoughproduces somewhat larger search spaces, quickly.conclusions, however, tempered fact certain clusters problems, combined strategy, LCFR-DSep, generate minimal search spaces.saw, Tileworld problems, important recognize needparticular temporal ordering among plan steps, recognition obtainedresolving separable threats early. Trains Get-Paid/Uget-Paid domains,matters recognizing particular effect fact achieved oneway, recognized particular aw selected|a aw happensgenerally least cost aw available. lesson learned setsproblems although understand reasons LCFR ZLIFO performway do, combine best features create good default strategies POCL planning, clear domain-dependent characteristicsidentified Trains Tileworld domains must still taken account settlingaw selection strategy domain.AcknowledgmentsMartha Pollack's work project supported Air Force Oce ScientificResearch (F49620-96-1-0403) NSF Young Investigator's Award (IRI-9258392). DavidJoslin supported Rome Labs (RL)ARPA (F30602-95-1-0023) NSF CISEPostdoctoral Research award (CDA-9625755). Massimo Paolucci supportedOce Naval Research, Cognitive Neural Sciences Division (N00014-91-J-1694).grateful Alfonso Gerevini providing us code usedearlier study, allowing us use experiments. would also like thankArthur Nunes Yazmine DeLeon, assisted us carrying experiments donepreliminary stages work. Finally, thank Alfonso Gerevini, Len Schubert,Michael Wellman, anonymous reviewers helpful comments work.Appendix A: Ruling Ceiling Effectsdata collected using node limit, examined problems leastone strategies hit node limit. Table 27 gives second worst node countproblems. shows that, basic problems least one strategyfailed, least one succeeded, second-worst strategy generally created fewer7000 nodes.Similarly, Trains Tileworld problems, cases except TW3,second-worst strategy took fewer 50,000 nodes (and TW3 took 89,790). Recallnode limit basic problems 10,000 nodes, TrainsTileworld problems 100,000 nodes. thus clear strategies hit258fiFlaw Selection StrategiesPROBLEMHANOIR-TEST2MONKEY-TEST2MONKEY-TEST3GET-PAID2GET-PAID3GET-PAID4FIXITHO-DEMOFIXBUGET-PAID2UGET-PAID3UGET-PAID4PRODIGY-P22MOVE-BOXESMOVE-BOXES-1DefaultReverse291975673744100001296431162510000TRAINS2TRAINS3TW-2TW-3TW-4TW-5TW-6100001754725289482654402100002952522752001000012964311625100001000031841754725289492642687100002235110000029585100000897903844490241722116204011266203453040Figure 27: Second-Worst Node Counts Problems Failing Strategiesnode limit substantially worse strategies succeed. Evensucceed increasing node limit slightly, comparative performance would stillpoor.Thus, using node limits imposed, making strategies look worseactually are. hand, computing %-overrun, may makingstrategies look better actually are, use value 10,000 (or100,000) nodes generated strategy hits limit, actual number nodesmight take, run completion, could significantly higher. why, analyses,considered absolute performance strategies individual problems,aggregate performance, measured average %-overrun.also compared experiments run time limitrun node limit. basic problem set, time limit 100 seconds highenough that, cases, strategies could compute significantly nodes259fiPollack, Joslin, & Paoluccicould node cutoff. Nonetheless, results almost identical. nearlycases, strategy failed node cutoff, also failed time limit cutoff.four exceptions this:1. Hanoi: 10,000 nodes limit, DSep fails, 100 second time limit,succeeds, taking 46,946 nodes.2. Uget-Paid3: 10,000 node limit, UCPOP-LC fails, 100 secondtime limit, succeeds, taking 37,951 nodes.3. Uget-Paid4: 10,000 node limit, UCPOP-LC fails, 100 secondtime limit, succeeds, taking 23,885 nodes.4. Fixit: 10,000 nodes limit, DSep-LC, UCPOP-LC, ZLIFO fail,100 second time limit, succeed 12,732, 13,510, 20,301 nodesrespectively. strategies fail solve problem either limit.similarly strong correspondence results obtainedTrains Tileworld problems using node limit time limit. cases,strategy able succeed within 100,000 node limit able succeedwithin 1,000 second time limit. nature problems computationtime per node great. Specifically,1. TW3, DUnf succeeded 56,296 nodes run node limit, failed1,000 second time limit.2. TW4, LCFR-DSep (with S+OC node-selection strategy) succeeded 69,843nodes, failed time limit.3. TW5, LCFR-DSep (with S+OC+UC node-selection strategy) succeeded49,024, failed limit.4. TW6, LCFR (with S+OC node-selection strategy) succeeded 4,506 nodes,failed time limit.one case strategy fail node limit succeed within time limit:1. TW3, DSep (with S+OC node-selection strategy) failed 100,000 nodelimit, succeeded 134,951 nodes using 100 second time limit. Notesignificantly worse second worst strategy, solved problemgenerating 89,790 nodes.Given close correspondence experiments node time limits,collected node-limit data experiments reversed preconditioninsertion.260fiFlaw Selection StrategiesReferencesAllen, J. F., Schubert, L. K., Ferguson, G. M., Heeman, P. A., Hwant, C. H., Kato, T., Light,M., Margin, N. G., Miller, B. W., Poesio, M., & Traum, B. R. (1995). TRAINSproject: case study building conversational planning agent. ExperimentalTheoretical Artificial Intelligence, 7, 7{48.Chapman, D. (1987). Planning conjunctive goals. Artificial Intelligence, 32 (3), 333{378.Currie, K., & Tate, A. (1991). O-plan: open planning architecture. Artificial Intelligence, 52, 49{86.Etzioni, O., Hanks, S., Weld, D., Draper, D., Lesh, N., & Williamson, M. (1992).approach planning incomplete information. Proceedings Third International Conference Principles Knowledge Representation Reasoning, pp.115{125.Gerevini, A. (1997). Personal communication.Gerevini, A., & Schubert, L. (1996). Accelerating partial-order planners: techniqueseffective search control pruning. Journal Artificial Intelligence Research, 5,95{137.Joslin, D. (1996). Passive Active Decision Postponement Plan Generation. Ph.D.thesis, Intelligent Systems Program, University Pittsburgh.Joslin, D., & Pollack, M. E. (1994). Least-cost aw repair: plan refinement strategypartial-order planning. Proceedings Twelfth National Conference ArtificialIntelligence (AAAI), pp. 1004{1009 Seattle, WA.Joslin, D., & Pollack, M. E. (1996). \early commitment" plan generation ever goodidea?. Proceedings Thirteenth National Conference Artificial Intelligence(AAAI), pp. 1188{1193 Portland, OR.Kambhampati, S., Knoblock, C. A., & Yang, Q. (1995). Planning refinement search:unified framework evaluating design tradeoffs partial-order planning. ArtificialIntelligence, 76 (1-2), 167{238.Kumar, V. (1992). Algorithms constraint-satisfaction problems: survey. AI Magazine,13 (1), 32{44.McAllester, D., & Rosenblitt, D. (1991). Systematic nonlinear planning. ProceedingsNinth National Conference Artificial Intelligence, pp. 634{639 Anaheim, CA.Pednault, E. P. D. (1988). Synthesizing plans contain actions context-dependenteffects. Computational Intelligence, 4 (4), 356{372.Penberthy, J. S., & Weld, D. (1992). UCPOP: sound, complete, partial order plannerADL. Proceedings Third International Conference Knowledge Representation Reasoning, pp. 103{114 Cambridge, MA.261fiPollack, Joslin, & PaolucciPeot, M., & Smith, D. E. (1992). Conditional nonlinear planning. Proceedings FirstInternational Conference AI Planning Systems (AIPS-92), pp. 189{197 CollegePark, MD.Peot, M., & Smith, D. E. (1993). Threat-removal strategies partial-order planning.Proceedings Eleventh National Conference Artificial Intelligence, pp. 492{499Washington, D.C.Pollack, M. E., & Ringuette, M. (1990). Introducing Tileworld: Experimentally evaluating agent architectures. Proceedings Eighth National Conference ArtificialIntelligence, pp. 183{189 Boston, MA.Russell, S., & Norvig, P. (1995). Artificial Intelligence: Modern Approach. Prentice Hall,Englewood Cliffs, NJ.Russell, S. J. (1992). Ecient memory-bounded search algorithms. ProceedingsTenth European Conference Artificial Intelligence, pp. 1{5.Smith, D. E., & Peot, M. A. (1994). note DMIN strategy. Unpublished manuscript.Srinivasan, R., & Howe, A. E. (1995). Comparison methods improving search eciencypartial-order planner. Proceedings 14th International Joint ConferenceArtificial Intelligence, pp. 1620{1626.Tate, A., Drabble, B., & Dalton, J. (1994). Reasoning constraints within O-plan2.Tech. rep. ARPA-RL/O-Plan2/TP/6 V. 1, AIAI, Edinburgh.Tsang, E. (1993). Foundations Constraint Satisfaction. Academic Press.Tsuneto, R., Erol, K., Hendler, J., & Nau, D. (1996). Commitment strategies hierarchical task network planning. Proceedings Thirteenth National ConferenceArtificial Intelligence (AAAI), pp. 526{542 Portland, OR.Weld, D. S. (1994). introduction least commitment planning. AI Magazine, 15 (4),27{61.Wilkins, D. E. (1988). Practical Planning: Extending Classical AI Paradigm. MorganKaufmann, San Mateo, CA.Wilkins, D. E., & Desimone, R. V. (1994). Applying AI planner military operationsplanning. Fox, M., & Zweben, M. (Eds.), Intelligent Scheduling, pp. 685{708.Morgan Kaufmann Publishers, San Mateo, CA.Williamson, M., & Hanks, S. (1996). Flaw selection strategies value-directed planning.Proceedings Third International Conference Artificial Intelligence PlanningSystems, pp. 237{244.262fiJournal Artificial Intelligence Research 6 (1997) 111{145Submitted 8/96; published 4/97Lifeworld AnalysisPhilip Agrepagre@ucsd.eduIan Horswillian@ils.nwu.eduDepartment Communication 0503University California, San DiegoLa Jolla, CA 92093, USANorthwestern University Computer Science Department1890 Maple AvenueEvanston, IL 60201, USAAbstractargue analysis agent/environment interactions extendedinclude conventions invariants maintained agents throughout activity.refer thicker notion environment lifeworld present partial set formaltools describing structures lifeworlds ways computationallysimplify activity. one specific example, apply tools analysis Toastsystem show versions system different control structures factimplement common control structure together different conventions encodingtask state positions states objects environment.1. IntroductionBiologists long sought concepts describe ways organisms adaptedenvironments. Social scientists likewise sought concepts describe wayspeople become acculturated participants social worlds around them. Yetdicult approach phenomena methods computational modeling.see least two reasons diculty. first tradition modelingartificial intelligence developed around concern cognition, is, mental processesunderstood intervene stimuli responses human beings. Although minoritytraditions ecological psychology reacted approach studying humanlife, able translate concepts computational mechanismsmatch expressive power symbolic programming. second reason subtle:one conceives organisms environments spatially extended mechanismsexplained according principles boundary(the surface body) particularly different from, interesting than,rest total organism-environment system. challenge computational modeling,then, conceptualize agents' adaptations environments ways neithertreat agents isolated black boxes dissolve one big machine.purposes, find useful distinguish two aspects agent'sinvolvement familiar environment: embodiment embedding. \Embodiment"pertains agent's life body: finiteness resources, limited perspectiveworld, indexicality perceptions, physical locality, motility,on. \Embedding" pertains agent's structural relationship world: habitualc 1997 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.fiAgre & Horswillpaths, customary practices fit shapes workings things,connections agents, position set roles hierarchy, forth.concept embedding, then, extends concrete kinds locatednessworld (places, things, actions) abstract kinds location (within social systems,ecosystems, cultures, on). Embodiment embedding obviously interrelated,powerful consequences agents' direct dealings agentssolitary activities physical world. principal focus articleembedding, particularly ways agents maintain relationships objectsfunctionally significant tasks.paper develop thoughts embodiment embedding follows:Section 2 reviews concept environment developed early workNewell Simon.Section 3 introduces adaptation traditional idea, call lifeworlds, sketch involved lifeworld analysis.Section 4 introduces informally concept factorization lifeworlds; refersroughly structures lifeworld permit agents' decisions madeindependently one another.Section 5 defines basics formal theory lifeworld analysis, namelyconcepts environments, actions, policies, factorization, reduction oneenvironment another. purpose formalism characterize kindsinteractions arise agents familiar lifeworlds.Section 6 brie introduces computer program wrote illustratephenomena lifeworlds.Section 7 applies formalism modeling world programoperates; proceeds modeling successively complicated versions world.Section 8 explains program keeps track objects worldfigure activities, discusses issues arise trying modelkeeping-track formal terms.Section 9 sums formal work explaining precise relationshipprogram formal model world.Section 10 expands theory lifeworlds informally introducingconcept cognitive autopoiesis, collection means agents manipulate surroundings provide conditions cognitive processes;provide taxonomy phenomena.Section 11 concludes suggesting directions future work.2. Concept EnvironmentIntuitively, notion \the environment" AI robotics refers relatively enduring stable set circumstances surround given individual. environmentprobably yours, though may similar. hand, althoughenvironment starts leave (at skin, perhaps), clear ending-point.necessarily defined terms metric space; physically distant circumstancesconsequences life (via telephone, say) properly regarded112fiLifeworld Analysispart environment well. environment agents live, determineseffects actions. environment thus matter importance computationalmodeling; know agent's environment like determine givenpattern behavior adaptive. particular need positive theory environment,is, kind principled characterization structures dynamicsattributes environment virtue adaptive behavior adaptive.Herbert Simon discussed issue pre-AI work. book Administrative Behavior (1947), example, presents uential theory later became known limitedrationality. contrast assumption rational choice classical economics, Simondescribes range cognitive limitations make fully rational decision-making organizations impracticable. Yet organizations thrive anyway, argues, provideindividual structured environment ensures decisions goodenough. division labor, example, compensates individual's limited abilitymaster range tasks. Structured ows information, likewise, compensateindividual's limited ability seek information judge relevance. Hierarchycompensates individual's limited capacity choose goals. fixed procedurescompensate individuals' limited capacity construct procedures themselves.comparison Simon's early theory Administrative Behavior, AI downplayeddistinction agent environment. Newell Simon's early workproblem solving (1963), environment reduced discrete series choicespresents course solving given problem. phrase \task environment" camerefer formal structure search space choices outcomes. clearlygood way modeling tasks logical theorem-proving chess, objectsmanipulated purely formal. tasks involve activities physical world,however, picture complex. cases, problem solving model analyzesworld distinctive way. theory treat world agent separateconstructs. Instead, world shows up, speak, phenomenologically: termsdifferences make difference agent, given particular representations, actions,goals. Agents different perceptual capabilities action repertoires, example,inhabit different task environments, even though physical surroundings goalsmight identical.Newell Simon's theory task environment, then, tends blur differenceagent environment. framework analysis, find phenomenologicalapproach valuable, wish adapt purposes. Unfortunately, NewellSimon carry blurring theory cognitive architecture. often unclearwhether problem solving activity takes place wholly within mind, whetherunfolds agent's potentially complicated interactions physical world.distinction arise cases theorem-proving chess,domain whose workings easily simulated mental reasoning. crucialdomain whose actions uncertain outcomes. Even though wish retainNewell Simon's phenomenological approach task analysis, therefore, wishpresuppose agents reason conducting searches problem spaces. Instead,wish develop analytical framework guide design wide rangeagent architectures. particular, want analytical framework help us designsimplest possible architecture given task.113fiAgre & Horswill3. Lifeworldsuse term lifeworld mean environment described terms customaryways structuring activities take place within | conventional usestools materials, \loop invariants" maintained within conventionalactivities, on. term originally comes phenomenological sociology (Schutz& Luckmann, 1973), refers familiar world everyday life, specificallyworld described terms make difference given way life. Catspeople, example, understood inhabiting physical environmentdifferent lifeworlds. Kitchen cupboards, window sills, spaces underneath chairsdifferent significances cats people, balls yarn, upholstery, televisionsets, cats. Similarly, kitchen affords different kind lifeworld chefmechanic, though clearly two lifeworlds may overlap ways well.lifeworld, then, physical environment, patterned waysphysical environment functionally meaningful within activity.idea similar Gibson's theory perception (1986), two theories alsodiffer important ways. Whereas Gibson believes perception worldly affordancesdirect, believe perceptual process explained causal terms. Also,whereas Gibson treated categories perception essentially biological innate,regard cultural emergent.analyzing lifeworld, one attempts draw individual structures withinfacilitate customary activities. example, lifeworlds typically contain artifactstools specifically evolved support activities. toolsalso arranged world ways simplify life reduce cognitive burdenindividuals: cups typically found cupboards, food refrigerators grocerystores. one needs remember butter found specific grocery storebutter grocery stores found well-defined dairy section, usually along wall,recognized distance; dairy section view, buttervisible definite area. Artifacts also designed make functional propertiesperceptually obvious. Handles perceptibly suited picking up, knobs perceptiblysuited turning, forks perceptibly suited impaling things, (Brady,Agre, Braunegg, & Connell, 1984; Winston, Binford, Katz, & Lowry, 1983). Contrarily,generally assumed artifacts provide readily perceptible groundsdrawing functional distinctions fact interchangeable. Usually, functionallysignificant property object obvious, lifeworld provides alternate waymarking it. see record player house, example, assumemine unless specific reason to. aspects lifeworldstend make easy perform particular kinds activities within withoutremember many facts reinvent screwdriver first principles.Lifeworlds contain networks interacting conventions practices simplify specific aspects specific activities. practices relieve agents burden solving certainproblems spot diffuse solutions throughout activity agentmany agents. example, hospital might try get along without maintaining sterileconditions. People always germs, technically always infected. problemmaking sure infections never get control. direct solution would114fiLifeworld Analysisconstantly monitor patients, assess degree infection treatbecomes severe. Since undesirable number reasons, hospital instead triesprevent infections patients maintaining sterile conditions. might this,example, looking contaminated objects surfaces disinfecting them. Unfortunately, sterility visible surface characteristic. Instead, hospitals solve problemstructuring space activity. Different locations kept less sterile dependingconventional uses: operating rooms sterile hallway oors. Objectsgenerate germs (people) washed, masked, gloved. Critical instrumentscome contact specially sterilized use. Tongue depressorsassumed dirty trash (or biohazard bag) cleanwrapped paper. objects surfaces periodically disinfected regardlesslevel contamination. practices maintained regardless immediateneed them. hospital (for reason) temporarily find withoutpatients, workers would stop washing hands disinfecting bathrooms.4. Factorization LifeworldsSimon, Sciences Artificial (1970), argued complex systems \nearlydecomposable." model rooms building, whose walls tend minimizeeffects activity one room upon activity another. Sussman (1975),analysis block-stacking tasks, classified several types \subgoal interactions"result attempts break tasks subtasks; one hopes tasksdecomposable, bugs arise decomposable enough. One assumestask decomposable unless one reason believe otherwise. Sussman's research,rich tradition planning research helped inaugurate, concerned dicult problemconstructing plans presence subgoal interactions. goal, complementarytheirs, analyze many ways tasks really decomposable, derivebroadest range conditions moment-to-moment activity proceed withoutextensive analysis potential interactions.non-pathological lifeworld structured ways limit prevent interactionsamong subtasks. structures might taxonomized follows:Activity partition. lifeworlds separate activities discrete headings: sewingdistinct activity bathing, gathering food separate activity givingbirth, on. distinctions provide basis reckoning \different activities" purposes rest partitions. boundaries amongvarious activities often marked type ritual.Spatial partition. Different things often done different places. Tasks mayconfined places associated tools materials stored,suitable conditions lighting safety obtain. places may even close together, different recipes prepared different sections countertop spacedifferent kinds food kept different parts one's plate, boundaryregions perhaps employed assemble forkfuls neighboring foods. general, activities arranged space, decisions made one place tend minimalinteraction decisions made places. course spatial distance brings115fiAgre & Horswillabsolute guarantees functional independence (using resources onelocation prevent carted another location another use lateron), general tendencies.Material partition. Different activities often involve different materials, decisions affect materials one activity interact decisions affectmaterials activity.Temporal partition. Different activities often take place different times, thus lim-iting channels might constrain one another. timesmight standardized points cycle day week, orderingmight constrained kind precondition first activity producessuccessive ones depend upon.Role partition. Simon pointed division labor eases cognitive burdens.part supplying individuals separate spheres conductrespective activities.Background maintenance. Many activities background conditions main-tained without reference specific goals. example, one maintains stocks supplies pantry, puts things back belong, forth. Hammond,Converse, Grass (1995) call \stabilization." (See Section 5.)practices stabilize relationships agent materials usedcustomary activities. tend ensure, example, one encounterone's hammer currently opened box corn akes definite sorts recurringsituations. thus reduce complexity life, variety different hasslesarise, encouraging rise routine patterns cycles activity ratherconstant stream unique puzzles.Attributes tools. Numerous properties tools limit interactions among separatedecisions. Virtually tools resettable, meaning regardless onethem, restored normal state withinfull range functionalities accessible. (This course assumes oneusing tools customary ways breaking them.) Thusproperties tool place ordering constraints activitiesuse it. Likewise, tools committed tasks long periods.turned screw screwdriver, example, screwdriver stay\stuck" screw long period. Thus necessary scheduleuse screwdriver unless several people wish use once. Exceptionsgeneral rule include bowls (whose ingredients must often sit waiting future actionsconditions, cannot contain anything else meantime), stove burners(which sometimes must remain committed heating particular dishesreached certain states before), clamps (which must remain fastenedglue dried sawing operations completed).Supplies tools. latter tools raise spectre generalized scheduling problems potential deadlock among multiple activities, problems116fiLifeworld Analysisfact sometimes arise cooking people numbergiven kitchen adapted. time, though, one solves problemsscheduling simply enough tools must remaincommitted particular purposes period time. Lansky Fogelsong (1987)modeled effects search spaces limited interactions different cooksusing overlapping sets tools.Warning signs. things go wrong, unpleasant subgoal interactions ensue.avoid diculties, individual, community, species keeps track warningsigns cultivates capacity notice them; warning signs include suppliesrunning low funny smells. often done primitive associative level,rats stay away smells associated stuff made sickpeople develop phobias things present suffered traumas.Communities often arrange certain warning signs become obtrusive,kettles whistle natural gas mixed another gas distinctive smell.Simple impossibility. Sometimes things impossible, obviously so,necessary invest great effort deciding them.Monotonicity. Many actions changes state irreversible. Irreversible changescause decisions interact certain things must done change takesplace. also provides structure decision process: lifeworld needsmake evident must done given irreversible change occurs.Flow paths. Often lifeworld arranged particular materials (partsassembly line, paperwork organization, food way refrigerator stovetable) follow definite paths. paths provide great deal structuredecision-making. inspecting various points along path, example, one seeneeds done next. determining object is, one determinemust done must taken afterward. pathsconsciously mapped others emergent properties set customs.Cycles. Likewise, many lifeworlds involve stable cycles activities, perhapscycles nested inside others. resulting rhythms often expressedrecurring combinations materials, decisions, spatial arrangements, warning signs,on.Externalized state. computer people, \state" (used mass noun) means dis-cernible differences things modified voluntarily, interpreted functionally significant way. Early AI treat internal state(memory) external state (functionally significant mutable states world)importantly different, often analytically convenient treat uniformfashion. often advantageous record state world, whether relativelocations things persistent states (in count noun sense)left (Beach, 1988). example, one need remember whether eggsbroken fact readily perceptible, one's attention drawnsuitable occasion, one understands significance task. Likewise, one117fiAgre & Horswillsave great deal memory retrieving ingredients evening'srecipes cupboards placing customary place shelf.Lifeworlds, then, great deal structure permits decisions made independently one another. point real lifeworlds permit anyone live100% \reactive" mode, without performing significant computation, evenwould desirable. point, rather, nontrivial cognition people perform takes place considerable background familiar generally reliabledynamic structure.factorability lifeworlds helps particularly understanding activitiesagent body. great deal focusing inherent embodiment. lookone place time, handle one tool time, activities necessarilyserial. attention certain degree hysteresis: gotten workone countertop using one particular tool, example, natural stepcarry task. crucial, therefore, different tasks relativelyseparate consequences, lifeworld provide clues change tasknecessary, functionally significant conditions generally detected usinggeneral-purpose forms vigilance occasionally looking around. course, certainkinds activities complex this, require special-purpose strategiesgo beyond simple heuristic policies \find something needsit." point complex activities many interacting componentsrare, generally conducted specially designed adapted lifeworlds,lifeworlds structured minimize diculty tasks rather increase it.various phenomena together formed motivation concept indexicalfunctional deictic representation (Agre & Chapman, 1987; Agre, 1997). Embodied agentsfocused one activity one set objects time; many objects specifically adapted activity; relevant states generally readily perceptible; objectsperceptibly different generally interchangeable; stabilization practiceshelp ensure objects encountered standardized ways. thus makes sense,purposes, represent objects generic ways one's relationships them.ashlight keep car the- ashlight-I-keep-in-the-car FLASHLIGHT-13.maintain stable relationship ashlight keeping standard place, puttingback done it, using intended purposes, keepingbatteries fresh, on. presence environment ensures ready accesslight car breaks night, therefore need separately plancontingency time drive. conventional structures activitymaintain ashlight's presence \loop invariant." presence ashlightactivities ensure structures lifeworld.5. Environments, Policies, Reducibilitysection, introduce formalism. purpose formalism directlyspecify workings agent's cognitive machinery. Instead, purpose construct \principled characterizations interactions agents environmentsguide explanation design" (Agre, 1995). formalism, words, describesagent's embodied activities particular environment. characterized dy118fiLifeworld Analysisnamics activities, becomes possible design suitable machinery. matterprinciple, want design simplest possible machinery consistentgiven pattern interaction (Horswill, 1995). therefore make priori commitmentsmachinery. favor particular architecture particular activityanalyzed. make priori commitments matters analogversus digital, \planning" versus \reaction," on. experience reallifeworlds real activities incorporate great deal useful dynamic structure,effort invest studying structure repaid parsimonious theoriesmachinery. intend methods equally useful investigating typesactivity designing types machinery might able participate them.concept lifeworld appear specific mathematical entityformalism. intuition, however, this: objective material environment,agent directly deal environment's complexity. Instead dealsfunctional environment projected material environment.projection possible various conventions invariants stably presentenvironment actively maintained agent. lifeworld understoodfunctional world together projection conventions create it.section summarizes formal model environmental specialization given Horswill(1995); proofs theorems, see original paper. Subsequent sections applyextend model.model environments state machines behavior agents policiesmapping states actions.environment E pair (S; A) state-space set possibleactions.action a: ! mapping states states.policy p: ! mapping states actions taken. paper,states include facts physical environment, straightforward matter include agent's internal states well (Horswill, 1995).combination policy environment creates dynamic system: environment's state mapped policy action maps environment new statewhole process repeated.discrete control problem (DCP) pair (E; G) environment E goal G,subset E 's state space.policy solves problem dynamic system generates environmenteventually reaches goal state.solves problem halts remains within G entering it.example, consider robot moving along corridor n equally spaced oceslabeled 1, 2, 3, on. formalize environment Zn = (f0; 1; :::; n ,1g; fincn ; dec; ig), identity function, incn dec map integer+ 1 , 1, respectively, proviso dec(0) = 0 incn(n , 1) = n , 1119fiAgre & Horswill(dec,i)(i,inc)decdecinc53decinc54(i,dec)inc52(1,1)(i,inc)1(dec,i)(i,dec)inc5inc50(i,inc)(0,1)dec(inc,i)(i,inc)(inc,i)(0,0) (dec,i) (1,0)dec(dec,i)(i,dec)(inc,i)(inc,i)(i,dec)Figure 1: environment Z5 (left) serial product Z2 itself, expressedgraphs. Function products written pairs, i.e. inci written(inc; i). Identity actions (i ii) left undrawn reduce clutter.(see Figure 1). Note effect performing identity action staystate.emphasize policy model agent's behavior, causal/computational processes behavior exhibited. specifies agentstate, it. thus theoretical construct, data structure algorithmagent's head. examine implementation issues surround policiessection 8.5.1 Product Environmentsmajority formal sections paper explore phenomenon factoring.particular, explore policies factorable environments composedpolicies factors. state-machine models environments, factorizationfactorization state-space; environment's state-space Cartesian productstate-spaces. environment, whole, \factorable" componentsub-environments. example, position king chess board rowcolumn components. thought \product" components,isomorphic Z8 (since eight rows eight columns). considerenvironment car drives 88 grid city blocks, seekind product Z8 itself. environments 88 grids state spaces,car environment allows one component change time, whereas kingenvironment allows change.must therefore distinguish different kinds factorization. call chessboardcase parallel product Z8 itself, car case serial product.focus another kind factorization later. Let Cartesian product two functions fg fg: (a; b) 7! (f (a); g(b)), let identity function. two environmentsE1 = (S1; A1 ) E2 = (S2 ; A2 ), define parallel productE1 k E2 = (S1S2; fa1a2 : a1 2 A1; a2 2 A2 g)120fiLifeworld Analysisserial productE1 *) E2 = (S1S2; fa1i : a1 2 A1 g [ fia2 : a2 2 A2 g)products DCPs defined obvious way:(E1 ; G1 ) k (E2 ; G2 ) = (E1 k E2 ; G1G2)(E1 ; G1 ) *) (E2 ; G2) = (E1 *) E2 ; G1G2)state diagram Z2 *) Z2 shown Figure 1.say environment DCP parallel (or serial) separable isomorphicproduct environments DCPs.5.1.1 Solvability Separable DCPsimportant property separable DCPs solutions constructedsolutions components:Lemma 1 Let p1 policy solves D1 halts states set initialstates I1 , let p2 policy solves D2 halts states I2 .policyp(x; y) = p1(x)p2(y)solves D1 k D2 halts states I1I2 . (Note using conventiontreating p, function pairs, function two scalars.)Lemma 2 Let p1 policy solves D1 states set initial statesI1, let p2 policy solves D2 states I2 . policyp(x; y) = p1 (x)i ip2(y)2 G2; x 62 G1 ) p(x; y) = p1(x)ix 2 G1; 62 G2 ) p(x; y) = ip2(y)solve D1 *) D2 halt states I1I2.Note parallel serial cases different. One would expect parallel caseeasier solve policy perform actions state componentssimultaneously. fact dicult one required perform actionssimultaneously leaves agent way preserving one solved subproblemsolving another. Consider \ ip- op" environment F = (f0; 1g; fflipg) flip(x) =1 , x. F property every state accessible every state. F *)Falso property. F k F , however, not. F k F one action, ipsstate components once. Thus two states accessible given stateF k F : state ip. king, problem fixed addidentity action F . possible leave one component product intact,changing other. identity action, sucient, necessary. weaker,still unnecessary, condition F action always maps goal states goalstates.121fiAgre & Horswills'= (s' )a'a' (s' )unreduced environmenta(s) = (a' (s' ))reduced environmentFigure 2: simple reduction environment E 0 E . s0 correspondingstates reduced unreduced environments respectively a0corresponding actions. projection simple reduction \commutes"actions, (a0 (s0 )) = a((s0 )), alternatively, a0 = . Thusregardless whether take projection action,achieve result.5.2 ReductionAnother important kind structure one environment considered abstraction another (Newell, Shaw, & Simon, 1960; Sacerdoti, 1974; Knoblock, 1989).abstract environment retains fundamental structure concrete environmentremoves unimportant distinctions among states. abstract state corresponds setconcrete states abstract actions correspond complicated sequences concreteactions.say projection environment E 0 another environment Emapping state space E 0 E . say simple reductionE 0 E every action E , corresponding action a0 E 0state s0(a0 (s0)) = a((s0 ))equivalently,a0 =function composition operator. say a0 -implementationuse denote function mapping E -actions implementationsE 0 .possible define much powerful notion reduction implementations allowed arbitrary policies. requires fair amount additional machinery,however, including addition state agent. Since simple reduction sucepurposes, simply assert following lemma, direct consequencegeneral reduction lemma (Horswill, 1995):Lemma 3 Let simple reduction E 0 environment E let (E 0 ; G0)DCP. policy p solves (E; (G0 )),p = p122fiLifeworld Analysissolves (E 0 ; G0 ).5.3 Related Workformal models environments use state-space descriptions environment, usually finite-state machines. Rosenschein Kaelbling used finite state machines representagent environment (1987, 1989, 1986). formalization allowed specializedmechanisms directly synthesized descriptions desired behavior formalization behavior environment. formalization powerful enough formbasis programming language used program real robot. Later, Rosenschein developed method synthesizing automata whose internal states provable correlationsstate environment given set temporal logic assertions dynamicsenvironment. Donald Jennings (1992) use geometric, similar, approachconstructing virtual sensors. Lyons Arbib (1989) model organisms robotsusing process algebras, Beer (1995) employs formalisms dynamic systems theory.Wilson (1991) specifically proposed classification simulated environmentsbased types mechanisms operate successfully within them. Wilsonalso used finite state formalization environment. divided environmentsthree classes based properties determinacy. Todd Wilson (1993) Toddet al. (1994) taxonomized grid worlds terms behaviors successfulthem. Littman (1993) used FSM models classify environments reinforcement learningalgorithms. Littman parameterized complexity RL agents terms amountlocal storage use far future RL algorithm looks.empirically classified environments minimal parameters still allowedoptimal control policy learned.also extensive literature discrete-event dynamic systems (Kosecka, 1992),also model environment finite state machine, assume transitioninformation (rather state information) visible agents.alternative state-machine formalism found work Dixon (1991).Dixon derives semantics first order logic, world comes individuatedobjects relations, rather state-space methods used here. Dixon's \open"approach also avoids need define environment single mathematical structure.Like work, Dixon's work attempts formally model assumptions system makesenvironment. Dixon's interest, however, individual program meansrather comparing competing programs.6. ToastToast (Agre & Horswill, 1992) program simulates short-order cook reasonably detailed simulation kitchen (see Figure 3). Toast, world consistsset objects ovens, pans, cutting boards, globs pancake batter, individual eggs,customers restaurant. object type (e.g., EGG) objectsgiven type common set possible states common set possible operationsperformed them. action involves set objects given types.action require objects specified states may change statesobjects, others. example, MIX operation would involve objects type123fiAgre & HorswillTime012345678910111213141516171819202122232425262730313646565758596069798990919293949596979899100101102Event(BREAK-EGG EGG-11 BOWL-4) [Making omelette](ADD-EGG EGG-10 OMELETTE-BATTER-0)(ADD-EGG EGG-9 OMELETTE-BATTER-0)(BEAT OMELETTE-BATTER-0 WHISK)(MOVE PAN-4 BURNER-4)(MOVE BUTTER-PAT-15 PAN-4)(MELT BURNER-4 PAN-4 BUTTER-PAT-15)(MOVE SLICE-23 TOASTER) [Waiting butter making toast](START TOASTER SLICE-23)(MOVE KNIFE-4 PLATE-1) [Waiting toast setting table]*** Done goal (KNIFE CLEAN PLATE-1) ***(MOVE PLATE-1 KITCHEN-TABLE)(MOVE FORK-4 PLATE-1)*** Done goal (FORK CLEAN PLATE-1) ***(MOVE SPOON-4 PLATE-1)Toaster pops!(MOVE BUTTER-PAT-14 KNIFE-3) [Back toast](BUTTER SLICE-23 KNIFE-3 BUTTER-PAT-14)(POUR-OMELETTE-BATTER OMELETTE-BATTER-0 ...) [Butter melted back omelette](MOVE SLICE-23 PLATE-1) [Setting table]*** Done goal (SLICE BUTTERED PLATE-1) ****** Done goal (SPOON CLEAN PLATE-1) ***(POUR-FLOUR FLOUR BOWL-3) [Making pancake](ADD-SUGAR SUGAR PANCAKE-BATTER-0)(ADD-BAKING-POWDER BAKING-POWDER PANCAKE-BATTER-0)(FOLD OMELETTE-0 SPATULA-2) [Tending omelette](ADD-MILK MILK-DISPENSER PANCAKE-BATTER-0) [Back pancakes](ADD-EGG EGG-8 PANCAKE-BATTER-0)(MIX PANCAKE-BATTER-0 SPOON-3)(MOVE PAN-3 BURNER-3)(FLIP OMELETTE-0 SPATULA-2) [Tending omelette](MOVE BUTTER-PAT-13 PAN-3) [Pancake](MELT BURNER-3 PAN-3 BUTTER-PAT-13)(MOVE OMELETTE-0 PLATE-1) [Finishing omelette]*** Done goal (OMELETTE COOKED PLATE-1) ***(SPOON-BATTER PANCAKE-BATTER-0 PAN-3 BUTTER-PAT-13) [Pancake](FLIP PANCAKE-0 SPATULA-2)(MOVE PANCAKE-0 PLATE-3)*** Done goal (PANCAKE COOKED PLATE-3) ***(MOVE PLATE-3 KITCHEN-TABLE)(MOVE PAN-2 BURNER-2) [Pancake 2](MOVE BUTTER-PAT-12 PAN-2)(MELT BURNER-2 PAN-2 BUTTER-PAT-12)(SPOON-BATTER PANCAKE-BATTER-0 PAN-2 BUTTER-PAT-12)(FLIP PANCAKE-1 SPATULA-2)(MOVE PANCAKE-1 PLATE-2)*** Done goal (PANCAKE COOKED PLATE-2) ***(MOVE PLATE-2 KITCHEN-TABLE)(CLEAN PAN-2) [Cleanup](CLEAN PAN-3)(CLEAN SPOON-3)(CLEAN SPATULA-2)(CLEAN BOWL-3)(CLEAN KNIFE-3)(CLEAN PAN-4)(CLEAN WHISK)(CLEAN BOWL-4)(TURN-OFF BURNER-2)(TURN-OFF BURNER-3)(TURN-OFF BURNER-4)Figure 3: Sample run breakfast program. agent given goals makingomelette, two pancakes, slice toast, setting table, cleaningup. comments appear square brackets.MIXING-BOWL, BATTER,SPOON. would require spoon CLEAN stateeffects would put batter MIXED state spoon DIRTYstate. Objects perform actions, Toast agent, oven, customersmodeled objects perform actions cooking, transferring heat, makingorders, respectively.Toast divides objects world two important classes (see Figure4). Informally, tools objects (1) end products cooking (2) easily124fiLifeworld AnalysisMaterial. Eggs. Fresh ! broken ! beaten ! cooked.Material. Butter pat. Fresh ! melted.Material. Milk supply. Non-empty ! empty.Material. Pancake batter. Has- ! has-sugar ! has-dry ! has-milk ! has-all ! mixed.Material. Pancake. Cooking ! cooked-1-side ! ipped ! cooked ! burnt.Material. Bread slice. Fresh ! toasted ! buttered.Tools. Forks, spoons, knives, spatulas, whisks. Clean ! dirty, dirty ! clean.Containers. Bowls, plates, pans, stove burners, countertop, toaster, bread bag.Active objects. Agent, stove burners, toaster.Figure 4: object types current system.reset initial states. example, knives spoons used dirtiedprocess cooking, end products cooking easily resetclean state washing. Materials objects end products cookingstate graphs form linear chains. words, state material,exactly one state brought exactly one actionbring there. example, egg scrambled always goes seriesstates UNBROKEN, BROKEN, BEATEN, COOKED. UNBROKEN state, action availableegg BREAK, action available BEAT.Toast given stock type object. runs, customers give goals(orders) prepare specific dishes. goal specifies type material (e.g., \EGG").satisfied putting object type finished state. egg objectcooked matter. Toast manages dynamic set goals opportunisticallyoverlaps preparation processes finish scarce resources, stove burners,become free. Toast uses surprisingly simple algorithm:clock cycle simulator:Choose material already cookedLook action needed advance next stateaction requires additional tools,choose objects proper typesobjects reset statesperform actionelse choose one unreset tool objectslook perform reset actionalgorithm intentionally sketchy implemented many versionsfind intuitively similar, different control structuresrequire different correctness proofs. task next section drawsimilarities produce coherent theory them.Toast algorithm two interesting features:algorithm proceeds table-lookup.algorithm stateless: internal plans models stored agent;information used choose actions stored world.125fiAgre & HorswillTable lookup implies algorithm fast simple. Statelessness makes algorithm simple well, relatively robust face unexpected perturbations.7. Modeling Toast WorldToast work? specifically, properties environment relyupon work? general, strategy identify series structures environmentpermit Toast's tasks factored, define series reductionspermit complex versions Toast's problem defined terms simpler ones.claim vast generality Toast architecture; simply observeenvironmental regularities Toast relies upon common many environments,suggest method arguing Toast's architecture seems likely extendtypes structure environment. Although different versions Toast relydifferent structures, show versions rely on:1. factorability environment individual objects. Factoring allows usconstruct solutions problems solutions subproblems individualfactors.2. special properties tool material object classes.3. maintenance invariants agent's activity introduce new structureenvironment.formalization properties tools materials simple. precise formalization factorability objects, however, surprisingly dicult environment directly factorable using methods developed far. solveproblem defining new factoring technique called uniform reduction,environment viewed collection overlapping instances schematic environments,containing minimal set objects necessary perform task. agent solvestask choosing one instances reducing goal true environmentsolution schematic instance. this, agent must keep trackinstance operating goes along. could accomplished internal memory, course, agent would need memory performstasks concurrently. show structuring activity, agentmake information manifest environment, thus \storing" informationworld.7.1 Single-Material Worldsstart defining schematic environment Toast. environmentexactly one material cooked one tool needed cook it. simplifyfurther, start ignoring even tools.1. Solve no-tools case.2. Reduce self-resetting tools case no-tools case.3. Reduce general case self-resetting tools case.126fiLifeworld Analysis7.1.1 Single-Material Worlds ToolsSince materials linear chains state spaces, action restricted, sayleast. case egg, might chain:fresh break! broken beat! beaten heat! cooked heat! burnt(We assume identity, \nop," action always available every state.trivial assumption.) given state, one non-trivial action executed,action selection agent trivial. solving DCP involving single-materialworld one following must always hold:current state goal state, need execute identity action.current state pregoal state: goal state later chaincurrent state, reach executing unique action brings usnext state chain.current state postgoal state: goal states earlier chain,problem unsolvable.really matters single-material worlds, therefore, many statesdirection goal lies relative current state. sense,really one single-material world, rather one class them, namely chains Cn givenlength:Cn = (f1; :::; ng; fincn ; ig)(Note environment Zn , without actions movebackward along chain.)Proposition 1 single-material worlds n states reducible CnProof: Let E = (S; A) single-material environment. Define : ! f1; :::; ngletting (s) s's position E 's state chain, i.e. first state maps 1, second2, etc. Let action(s) denote unique action performed state s.pincn (s) = (action(s))(s)-implementation incn E reduced. 2one real class single-material worlds, one real classpolicies single-material DCPs:(s2GpCn ;G(s) = i;inc ; ifotherwisenclearly solves DCP (Cn ; G) n valid G.Corollary 1 goal G solvable single-material environment E tools,solved policy(s2GpE;G(s) = i;(action(s))(s); ifotherwise127fiAgre & Horswill7.1.2 Single-Material Worlds Single-State Toolssuppose world contains material set tools, tools always cleanotherwise reset use. Self-resetting tools one state,trivial kind environment. define \singleton" environment environmentexactly one state:= (freadyg; fig)single-state environments isomorphic , model environment consistingmaterial = (S; A) self-resetting tool k . state space simplyfreadyg actions setfa0 : (sM ; ready) 7! (a(sM ); ready)ja 2 Agaction performs action -component product's stateleaves component unchanged. induction, that:Proposition 2 environment isomorphic kS n .single-state-tool worlds trivially reducible tool-free worlds.7.1.3 Single-Material Worlds General Toolsgeneral tool environment identical single-state tool environment, exceptactions change states tools addition states materials. solvegeneral tool case using solution single-state tool case resetting tools wheneverdirtied.proof simple, requires formalize notion tool. Let Eenvironment state space form S1 S2 ::: Sn. Let action ESi component state space. sayindependent Si never changes Si result regardlessvalue Si .focused component Si independent components.Si tool privileged value readyi 2 Si that:{ state (s1; :::; si ; :::; sn ) E , reach state (s1; :::; readyi ; :::; sn )using actions focused Si .{ action a, either independent Si, focused Si, elsedefined states whose Si component readyi .prove general tool case reducible single-state tool case:Lemma 4 environment tool components reduced one toolsreplaced singletons. Specifically, let = ((S; A); G) DCP let readyT 2, A0 = fa0 : (s; readyT ) 7! (a(s); t)ja 2 A; 2 S; 2 g. D0 = ((S T; A0 [); G freadyT g) reducible tool D0.128fiLifeworld AnalysisProof: Let pD solution (policy) D. definition tool, mustpolicy pT bring D0 state (s; t) (s; readyt ) without changingcomponent. Let projection D0 given(= readyT(s; t) = s;?; ifotherwise2 A, define -implementation a, pa( 0= readyTpa (s; t) = ap ; ; ifotherwiseD0 reducible D. general case multiple tools follows induction. 27.2 Multiple-Material Worlds Single-Material Goalsreprise: want factor environment individual objects describeToast composite techniques operating individual factors. cannotproperly define environments Cartesian products individual objects defined isolationway expressing actions involving multiple objects. can, however,define set objects context minimal, schematic environment containing onecopy object. done so, want recapture notion environmentkind product objects different types. showingenvironment two eggs thought two overlapping copies environmentone egg; copies differ choice egg.treat environments state spaces formed products state spacesobjects. state environment tuple states objects. bindingschematic environment real environment particular kind projectioncomplex environment schematic, one also reduction. reasonableprojections valid bindings, say environment uniformly reducibleschematic environment.7.2.1 Bindings Uniform ReducibilityLet E 0 E environments state spaces built Cartesian products familydisjoint sets fSi g. Si might represent state spaces object types like egg fork.E 0 E would state spaces make number copies eggfork.say projection E 0 E simple every component resultcomponent argument.(s1; s2 ; s3; :::; sn ) = (si1 ; si2 ; :::; sim )i1 ; :::; im [1; n]. Thus takes E 0 -state, s0 , probably throws awaycomponents, possibly rearranges rest form new tuple. example, mightsingle particular egg's state and/or particular fork's state throw statecomponents away. projection simple, define kind inverse it,129fiAgre & Horswillschematic worldmultiple-object worldthe-eggegg0the-forkegg1the-spatulaegg2the-panegg3egg4fork0fork1fork2spatula0spatula1pan0pan1Figure 5: binding (solid vectors) alternate binding (dashed).call back-projection. define back-projection, , (s; s0 ),function whose result s0 components keeps replacedcorresponding components s. example, defined(s01 ; s02; s03 ) = (s03 ; s02)back-projection would given by:, ((sa; sb ); (s01 ; s02; s03 )) = (s01; sb ; sa)say simple projection binding E E 0 also simple reductionE 0 E (see Figure 5).Lemma 5 Let binding E E 0 . given(a) = ; (s0) = ,(a((s0 )); s0 )is, implementation E -action simply 's back-projection composedaction .proof follows definitions simple projection back-projection.say E 0 uniformly reducible E every simple projection E 0 E binding.7.2.2 Existential GoalsToast given goal putting instance given material finished state.call existential goal satisfied exactly environmentstates exists object specified type specified state. Let (E; G)DCP let E 0 uniformly reducible E . define existential goal 9E;E G GE 0 set states E 0 project binding goal state (E; G):[,1(G)9E;E G =00binding E E1300fiLifeworld Analysis,1 (G) = fs0 : (s0 ) 2 Gg set states map goal states . Givensolution schematic goal schematic environment, easily constructnumber solutions existential goal:Lemma 6 policy p solution problem (E; G) initial states ,binding E 0 E ,p = psolution (E 0 ; 9E;E G) initial states ,1 (I ), function mappingactions E corresponding actions E 0 .0Toast algorithm implements policy composition schematic solutionbinding maps onto real world. Consider problem cooking egg.schematic solution might be:break the-egg the-panbeat the-egg the-pan using the-whiskheat the-egg the-panboldface verbs break, beat, heat name actions. italicized expressions the-egg the-pan name objects (state components) affect simplified world.binding determines objects real world state componentscorrespond. Given binding, main control structure need remember sequencebreak, beat, heat. may preconditions states tools (i.e.whisk needs clean), handled reduction given policies resettingtools.7.2.3 Binding MapsGiven basic policy cooking single egg single pan whisk, constructpolicy achieve goal composing basic policy binding. policysolve goal state bound material non-postgoal state.policy solve goal solvable state, must able change bindings runtime. call function states bindings binding map.One simple policy choosing bindings impose priori orderingobjects always use first acceptable object ordering. ordering mightrandom, might correspond order imposed visual search mechanism.formal standpoint, ordering matter, can, without loss generality, useleft-to-right order state components environment's state tuple. Let M0binding map always chooses leftmost pregoal material uses fixedmapping tools (we care what). mapping allows us construct truesolution, one requires internal state agent:Proposition 3 policypM0 (s) = (AM0(s) p (M0 (s)))(s)solution state M0 defined.131fiAgre & HorswillProof: assumption, M0 defined initial state. environment must mapsolvable state M0 initial state. Since p is, assumption, solutionproblem E , pM0 must solve problem E 0 unless M0 changes valuepM0 solve problem. Suppose does. environment must go states00, state component E 0 leftmost pregoal material, state s01,component leftmost pregoal material. happen (a)leftmost pregoal material s00 changed goal state s01 (b)component pregoal s00 becomes pregoal s00 . Case (b) impossiblecase (a) implies s01 goal state. Thus pM0 must solution. 27.3 Multiple Goals: MetabolismThus far, considered happens policy achieves goal. Since agentsrarely set achieve goal die, want consider account extendedactivity involving many goals.One important class extended activities agent transforms whole classidentical objects. call metabolizing class. Metabolism usefulmake extra work: cooking 100 eggs useful, least feeding lot people;dirtying 100 forks, however, probably means wash all.Whether policy metabolizes object class depends large part binding mapuses. policy pM0 metabolizes materials material workedceases leftmost pregoal material soon arrives goal state.happens, M0 changes bindings agent starts work different object. Policy pnever actually sees material goal state. course, property \leftmost"artifact formalism. matters property metabolism simplybinding map implement ordering instances material alwayschoose minimum ordering objects pre-goal states.ordering might implemented agent visually scanning work surfaceuncooked egg, always scanning left-to-right top-to-bottom. returnissues section 8.binding maps lead kinds behavior, pathological.binding map always chooses binding, metabolism ceases. bindingmap always chooses uncooked eggs doesn't impose ordering them, might startcooking infinite number eggs without ever actually finishing one them.Metabolism also issue tool use. metabolize materials, pM0 must repeatedlyreset tools. alternate policy metabolize tools too. Let us define M1binding map uses leftmost pregoal material also leftmost resettools. clearly,pM1 (s) = (AM1(s) p (M1 (s)))(s)solution state M1 defined. policy treats tools disposable.long infinite supply fresh tools, p see succession statestools reset states. never need execute resetting actionenvironment effectively single-state-tool environment. Thus reduction section7.1.3 unnecessary.132fiLifeworld Analysis7.4 Multiple Goals: Interleaved ExecutionMetabolism involves performing transformation uniformly instancestype object: cooking eggs, cleaning/dirtying forks. Often times,however, agent work toward different kinds goals once. oftendone interleaving actions solutions individual goals. sayinterleaving function returns one first two arguments,depending third state argument:(s; p1 ; p2 ) 2 fp1 ; p2g;last two arguments policies, result policy, definenotation:Ip1;p2 (s) = (I (s; p1 ; p2 ))(s)wanted simultaneously make toast cook egg, good interleavingtoast-making policy egg-cooking policy would one chose egg-makingpolicy whenever egg finished current cooking step (and readyipped removed pan) chose toast-making policy egg busycooking. bad interleaving would one always chose toast-making policy.interleaving fair p1 p2 starting state, Ip1 ;p2finite number steps executed p1 p2 least once. Finally, saytwo bindings independent map disjoint sets components images.Binding independence special case subgoal independence: two policies can't possiblyinterfere alter distinct state components. Fairness binding independencesucient conditions interleaving solve conjunctive goal:Lemma 7 Let p1 = A1 p01 1 p2 = A2 p02 2 policies solve goals G1G2, respectively, halt. 1 2 independent fair interleavingp1 p2 Ip1;p2 solves G1 \ G2 halts.Proof: Since fair interleaving, two policies executed finite time,regardless starting state. induction, n, number stepsguaranteed executed least n steps policy.policy p1 composition policy p01 state space S1 binding.p1 solves G1 halts, must p01 solve (G1 ) halt finitenumber steps n. execution, environment goes series statess0; s1; :::; snproject 1 series statess00; s01; :::; s0nclaim execution interleaving Ip1 ;p2 must bring environmentsequence states project 1(s00 )+ ; (s01 )+ ; :::; (s0n )+ ; :::133fiAgre & Horswillis, string states s00 appears least once, s01 , appears least once,on. state transitions appear s0i s0i+1 .Suppose otherwise. must point series broken:(s00 )+ ; (s01 )+ ; :::; (s0i )+ ;neither s0i s0i+1 . two cases. Case 1: p1 executed transition.p01 (s0i ) = 6= s0i+1 , contradiction. Case 2: p2 executed transition.p2 changed one state components mapped 1 2 1independent, contradiction. Thus interleaving solves G1 . reasoning,must halt G1 , since p1 halts G1 . Also reasoning, must solve G2halt, hence, must solve intersection halt. 2useful corollary policy applied two independentbindings, bindings safely interleaved, is, interleaving commutes binding:Corollary 2 p1 = A1 p 1 p2 = A2 p 2 policies solve goals G1G2, respectively, halt, fair interleaving p1 p2, AI1;2 p I1;2solves G1 \ G2 halts.8. Implementing Policies Bindingsmodeled Toast's behavior composition various bindings interleavingsbasic policy schematic environment. case Toast, basic policysimple enough implemented table-lookup. hard part implementingbindings interleavings given realistic limitations short-term memory perceptualbandwidth.One approach would assume relatively complete representation world.egg would represented logical constant state would representedset propositions involving constant. binding would implementedframe structure set variables point logical constants. problemapproach presupposes underlying perceptual motor systems maintaincorrespondence logical constants eggs world. one eggschanges, visual system know looking update assertionsegg model.assumption taken lightly. capacity human perceptualsystem keep track objects world extremely limited. Ballard et al. (1995)foundexperimental subjects adopt strategies minimized amount world stateneeded track internally, preferring rescan environment informationneeded rather memorize advance. environment could even modifiedsaccadic eye movements without subjects noticing.alternative treat limitations body, locality space, limitedattentional motor resources resource implementing bindings directly. personvisually focus one object, stand one place, grasp objectsone time. orientation body's parts relative environment usedencode selection objects operated moment. words,134fiLifeworld Analysisimplement binding. Actions body, gaze shifts, movements new placesused shift binding.Another alternative use states relationships objects world keeptrack bindings. egg cooked frying pan. fork availableuse drawer, sink waiting washed.section, model use body conventions implement bindings interleavings. simplify presentation concrete, focusmaterials, particularly eggs.8.1 Binding, Deixis, Gazefirst approximation, people visually recognize objectsdirectly looking. People achieve illusion direct access arbitrary objects rapidlychanging gaze direction. Thus addition normal state environment,lived world contains additional state component, gaze direction. Sincenormally change gaze direction without changing world, vice versa, livedworld E 0 separated parallel product objective environment gazedirection:E0 = E kaccess world gaze, allows us focus one particularobject time. gaze implements binding, precisely, binding map, sincedepends direction gaze. model gaze direction number indicatingobject presently foveated, that:gaze(s1 ; s2; :::; sn ; d) = sdperson could implement single-object binding fixating object wishbind. First would set component egg, use binding.Since really binding map, however, rather true binding, agent mustpervasively structure activity ensure gaze need never redirected.8.2 Binding Conventiongeneral, agents must maintain bindings sort convention, whetherstructuring internal memory, case problem solver, structuringactivity. case gaze above, agent maintains bindingconvention spatial relation eye object binding.versions Toast date maintained bindings using conventions (simulated)spatial arrangement states objects.One reason Toast cannot rely solely gaze binding technique breaksbinding multiple objects. agent must continually move gaze among objectsinterest additional convention must introduced ensuregaze leaves egg later returns, always returns egg. (This assumes,course, Toast must return egg. tasks may suce Toastreturn functionally equivalent egg. preparing three fried eggsattention distracted preparing break second one, alright attentionreturns third egg, long gets back second egg eventually.)135fiAgre & HorswillState conventionsoriginal version Toast used convention eggs bound cooking taskiff starting (unbroken) state. Eggs therefore bound usingbinding mapToast (s) = state unique egg unbroken stateagent implement first visually searching unbroken egg,using gaze . corollary 2, interleaving cooking multiple eggs accomplished interleaving bindings eggs. example, might assumevisual system searched non-deterministically round-robin fashion eggs. fairinterleaving suce.Spatial conventionsLater development Toast, found useful adopt conventioneggs bound cooking task iff located designated workspace. Cookingeggs counter frying pan, idle eggs refrigerator.convention lets agent use space external memory binding information. bindegg, agent faces workspace performs visual search egg. eggfinds egg cooked, since idle eggs view.still leaves open issue fairness. extreme elegant solution fairnessproblem use multiple workspaces employ convention workspacedefines unique binding. cook two eggs, agent works cooking whatever eggfront it, spins place alternates workspaces.Formally, environment consists two copies workspace objectstherein plus extra state component determines workspace agent faces.agent's perceptual system implements binding map onetwo workspaces bound depending agent's orientation. Given policycooking one egg one workspace, construct policy cooking two eggs twointerleaving policy \ ipping" operation switches workspaces:Proposition 4 Let E = (S; A) environment, p policy solves goal GE halts, let environment two states, 0 1, two actions,(the identity) flip moves environment opposite state presentstate. Consider product environment:E0 = E *)E *)Dbinding map E 0 E :MD (s0 ; s1; d) = sdfair interleaving policies:pMD = AMD p MD136fiLifeworld Analysisreal worldidealizationfunctionally equivalent objectsleast resetbinding mapbinding mapsinterleavingsgeneral toolsresetting policiesself-cleaning toolsisomorphismsingle objectisomorphismcanonical chainFigure 6: Various alternative reductions used Toast.pflip(s0; s1 ; d) = flipsolution problem (E 0 ; (G G f0; 1g)).Proof: Consider bindings 0 : (s0 ; s1 ; d) ! s0 1 : (s0 ; s1 ; d) ! s1 , let p0 =A0 p 0 p1 = A1 p 1. Since binding map MD alternatesbindings 0 1 , fair interleaving pMD pflip equivalent interleavingp0 , p1 pflip . would like show interleaving also fair, is,p0 p1 get run finite time. see factexecution pflip switches MD one binding another. objectionleaves open possibility pflip always get run twice row, thus returningenvironment original state preventing MD switching bindings.cannot occur, however, since would introduce loop, causing interleaving run pflipforever, never running pMD , violating assumption fairness interleavingpMD pflip. Thus interleaving p0 , p1 pflip must fair. notep0 solves goal G f0; 1g halts, p1 solves goal G f0; 1g halts,pflip solves goal G G f0; 1g halts. Thus lemma 7, interleaving solvesintersection goals, G G f0; 1g. 2137fiAgre & Horswill9. Reductions Structure Toastshown cooking problem solved series reductionsconventions. Binding allows reduction problem schematic worldaction greatly restricted action selection greatly simplified. worldreduced, given algorithms resetting tools, world tools alwaysreset. world, turn, equivalent world one object,material cooked, one action taken given time. actionsfound table lookup.Multiple materials cooked interleaving execution processes cookingindividual materials. Interleaving processes equivalent, however, interleavingbindings, schematic-world algorithm need even aware pursuingmultiple goals. tool bindings continuously changed tools dirtied toolseffectively disposable, tools effectively single state, separate reductiongeneral tools single-state tools unnecessary. Material bindings maintainednumber conventions involving states and/or positions objects.short, describe Toast algorithm path network possiblesimplifications problem (see Figure 6) every path actual worldidealized single-object world defines possible (and correct) version Toastalgorithm.10. Cognitive Autopoiesisformalizing ideas binding gaze, moving toward theoryintentionality depends agent's embedding world, rather solely uponinternal models world. agent keep track particular objects termsfunctional significance { roles play ongoing activity.keep track tools materials associated different tasks keepingdifferent locations, example different regions countertop. far, however,ideas subject limited simple cases, example agent switchingvisual focus back forth two objects. model complex patternsfound everyday life, need much better theory worldembedded. theory partially matter biology physics, course,also matter cultural practices organizing activities space. section,would like sketch general theory matters using concept \cognitiveautopoiesis."Maturana Varela (1988), autopoiesis refers processes organismsact environments order provide conditions continued functioning. Cognitive autopoiesis refers active means agents structureenvironments order provide conditions cognitive activities.include basically means agents provide factorability environments: engaging customary activities, using customary tools materials them,partitioning activities customary ways, on. also includes rangesubtle phenomena. Kirsh (1995), example, drawn useful distinctionactions aim achieving functional goals (beating eggs, sweeping oors)138fiLifeworld Analysisactions aim facilitating cognition (setting right number eggs beginning, opening curtains dust visible). Actions can, course,serve purposes, example one chooses boil water kettle rathersaucepan: strategy achieves result, latter also provide signpossible take next action, example preparing tea. Stabilization actions (Hammond et al., 1995) also provide cognitive conditions actions. One might,example, develop habit leaving items door moment one realizesneed taken work.phenomena help understanding inadequate concept \theenvironment." one conceptualizes \the environment" monolithic whole, perhapsway looks viewed airplane, else way looks understoodpeephole momentary vector sense-perceptions, begins seem arbitrary, chaotic,hostile. certain sense seems static, anatomy physiology.fact phenomena cognitive autopoiesis reveal lifeworld greatdeal living structure, structure actively maintained agents alsoproviding crucial preconditions cognition. Indeed hard draw clear linearound agent's cognition; trace sequence causal events led given agentpour pitcher milk particular moment, sequence lead back forthagent customary surroundings. almost surroundingsextension one's mind.Cognitive autopoiesis complex multifaceted phenomenon single theorysuce explain it. One useful way think cognitive autopoiesis spatially,terms series buffer zones embodied agent putative dangerscomplexities \the environment." people whose lives similar own,buffer zones conveniently sorted six headings:body itself: posture, markings, things might attached hungit, prostheses, artificial markings, things one holding one's hands,on. things serve forms memory, example wayremember activity one middle momentary distraction.body's motility also makes possible wide range voluntary reconfigurationsone's physical relationship things, example get better view betterleverage.Clothing, including pockets, purses, money belts, hats, on. Everyone carriesaround various objects ways draw customary practices artifacts (cashwallets, keys pockets, watch wrist, etc) configuring thingsevolving personal way (keys left pocket money right, tissues hip pocketone's coat, spare change outer ap backpack, on).Temporary workspaces one occupies perform particular activity bound-ed period. repairing bicycle, example, one might spread tools bicycleparts oor patterns cognitive significance relationshipone's body cognitive states (Chapman & Agre, 1986). Oneclaiming space permanent colony (it might located patio139fiAgre & Horswillpublic park, example), one lay claim space long enough performcustomarily bounded task.One's private spaces: home, desk, oce, car, trunks stuff kept someone else'sattic, forth. spaces serve numerous functions, course, amongcognitive functions providing stable locations long periods timetools materials, storage places stuff needs kept adequate supply,practices regulating people's access stuff, on. stableconditions actively maintained provide background wide varietytransient activities.Spaces shared people within stable, time-extended relationships.spaces include living rooms, kitchens, shared oce spaces, forth.line private shared spaces clearly depends particular cultureset relationships, distinction might clear. pointcognitive functions spaces maintained shared practicesletting someone know borrow stuff.Public spaces whole range customary artifacts practices regu-late activities them. Public spaces offer fewer guarantees private sharedspaces, include wide variety supports cognition, including signsarchitectural conventions. also possible use one's body clothingcarry artifacts provide cognitive support dealing public spaces.buffer zones always offer perfect protection harm complete supportpursuit goals. Shared public spaces sites con ict, example,con icts include involuntary disruption destruction one's bodybuffer zones customarily one's private control. serious theoryactivity must include account phenomena well, usuallyorderly way anything else.event, nested buffer zones ordinary life participate large metabolismcontinually interweaves cognitive functional purposes. Among purposeslearning. adaptation body parts tools customary activities helps channel action customary directions, existing background objects, spaces,practices help channel actions children newcomers customary directionslarger scale. Caretakers regularly construct customized types buffer zones aroundyoung, example, dicult impossible get anythingcould cause harm. lifeworld child, example, differs adultreach cookie jar locked cupboard roach spraykept. growing literature investigated processes cognitive apprenticeship (Rogoff, 1990), situated learning (Lave & Wenger, 1991), distributed cognition (Hutchins, 1995;Salomon, 1993), shared construction activities (Grin & Cole, 1989) gosystematically restrictive supportive lifeworlds.140fiLifeworld Analysis11. Conclusionpaper explored ways structure lifeworldsupports agents' cognition, suggested analysis might expandedcover wider range phenomena. Much work obviously remains done. Perhapssignificant part work concerns fundamental assumption lifeworld analysis:people use objects customary ways. plausible enough first approximation,always true. Faced diculty goes beyond capacitiesusual practices artifacts readily available, people frequently improvise.handle spoon might used pry open lid, pen might used fish acornsexhaust duct, book might used provide backing sheet paper onewriting on, protruding section car's bumper might bent straight deliberatelydriving car concrete wall. cases underlying physical affordancesobject \show through" beyond ready-to-hand appropriation routine patternsinteraction. underlying affordances also show situations breakdown, example tool breaks proves inadequate job. cases, peopleconfer improvised meanings upon artifacts. phenomena particularly importantconversation, utterance interpreted context created previousutterances, simultaneously helping create context interpretation successive utterances well (Edwards & Mercer, 1987; Atkinson & Heritage, 1984). pointlifeworld exist, rather something actively createdwell something adapted socialization. One challenge future researchlearn computational methods might help modeling phenomena|andphenomena might help us rethink basic ideas computation.Acknowledgementsappreciate detailed comments referees. work funded partNational Science Foundation grant number IRI{9625041. InstituteLearning Sciences established 1989 support Anderson Consulting, partArthur Anderson Worldwide Organization.Glossary TermsBinding. simple projection (mapping state-space components two environ-ments) acts reduction one environment another (see section 7.2.1).Binding map. mapping environment states bindings (see section 7.2.3).Cartesian product. sets: B set pairs (a; b) 2 A, b 2 B .environments: environment Cartesian product two environments iffstate space Cartesian product state spaces. Since set actionsleft open definition, many possible ways forming products, e.g. serialproduct, parallel product, uniform extension, etc.(see section 5.1).Discrete control problem (DCP). environment set goal states within(see section 5).Environment. state machine, i.e. , set possible states set possible actionsmapping states states. sets states actions need finite (see section 5).141fiAgre & HorswillFocus. action focused state component alters component (seesection 7.1.3).Material. object (environment) whose state space chain (see section 7.1).Policy. mapping states actions; formalization agent's control structure(see section 5).Projection. mapping state space one environment state spaceanother (see section 5.2).Simple projection. mapping state spaces maps state space componentsone environment state space components another (see section 5.2).State component. (For environments whose state spaces Cartesian products)element environment's state-tuple (see section 5.1).Solution. policy solves DCP initial state if, run state,eventually reaches goal state (see section 5).Tool. (Roughly) state component brought ready state without alteringstate components (see section 7.1.3).Uniform reducibility. (Roughly) E 0 uniformly reducible E consists multiplecopies E 's objects (see section 7.2.1).Glossary Notation. Function composition operator: f g(x) = f (g(x)).. projection (p. 122).,1. inverse , i.e. set states map given state (p. 131).,. (For simple projection : 0 ! ). generalized inverse. Since maps certaincomponents 0 , , (s; s0 ) s0 components replaced correspondingcomponents (p. 130).. simple reduction environment E 0 E , function mapping actionE action implements E 0 (p. 122).Cn. chain-environment n states (p. 127).E . environment.9E;E G. G goal E E 0 uniformly reducible E . existential goal G E 0 :set E 0 -states map goal state binding (p. 130).E1 *) E2. serial product. Cartesian product E1 E2 actions0two environments must taken separately (p. 120).E1 k E2 . parallel product. Cartesian product E1 E2 actionstwo environments must taken simultaneously (p. 120).LE;E . (E 0 environment uniformly reducible E ) leftmost-ready binding mapE 0 E (p. 131).p. policy.pE;G. standard policy single-material environment E goal G (p. 127).. singleton environment (the environment exactly one state). Used representself-resetting tool (p. 128).0142fiLifeworld AnalysisReferencesAgre, P., & Horswill, I. (1992). Cultural support improvisation. Tenth National Conference Artificial Intelligence Cambridge, MA. American Association ArtificialIntelligence, MIT Press.Agre, P. E. (1995). Computational research interaction agency. Artificial Intelligence,72 (1{2), 1{52.Agre, P. E. (1997). Computation Human Experience. Cambridge University Press,Cambridge, UK.Agre, P. E., & Chapman, D. (1987). Pengi: implementation theory activity.Proceedings Sixth National Conference Artificial Intelligence, pp. 268{272.Atkinson, J. M., & Heritage, J. (1984). Structures Social Action. Cambridge UniversityPress, Cambridge, UK.Ballard, D. H., Hayhoe, M. M., Pook, P. K., & Rao, R. P. N. (1995). Deictic codesembodiment cognition. Technical report 95.1, University Rochester NationalResource Laboratory study Brain Behavior, Rochester, NY. RevisedJuly 1996.Beach, K. D. (1988). role external mnemonic symbols acquiring occupation.Gruneberg, M. M., Morris, P. E., & Sykes, R. N. (Eds.), Practical Aspects Memory:Current Research Issues, volume 1: Memory Everyday Life. Wiley, Chichester,UK.Beer, R. D. (1995). dynamical systems perspective agent-environment interaction.Artificial Intelligence, 72 (1{2), 173{215.Brady, J. M., Agre, P. E., Braunegg, D. J., & Connell, J. H. (1984). mechanic's mate.Proceedings 1984 European Conference Artificial Intelligence Pisa, Italy.Chapman, D., & Agre, P. E. (1986). Abstract reasoning emergent concrete activity.Georgeff, M. P., & Lansky, A. L. (Eds.), Reasoning Actions Plans, Proceedings 1986 Workshop, Timberline, Oregon. Morgan-Kaufmann Publishers,Los Altos, CA.Dixon, M. (1991). Embedded computation semantics programs. TR SSL-91-1,Xerox Palo Alto Research Center, Palo Alto, CA.Donald, B. R., & Jennings, J. (1992). Constructive recognizability task-directed robotprogramming. Robotics Autonomous Systems, 9, 41{74.Edwards, D., & Mercer, N. (1987). Common Knowledge: Development Understanding Classroom. Methuen, London.Gibson, J. J. (1986). Ecological Approach Visual Perception. Erlbaum, Hilldale, NJ.Originally published 1979.143fiAgre & HorswillGrin, D. N. P., & Cole, M. (1989). Construction Zone: Working Cognitive ChangeSchool. Cambridge University Press, Cambridge.Hammond, K. J., Converse, T. M., & Grass, J. W. (1995). stabilization environments.Artificial Intelligence, 72 (1{2), 305{327.Horswill, I. (1995). Analysis adaptation environment. Artificial Intelligence, 73 (1{2),1{30.Hutchins, E. (1995). Cognition Wild. MIT Press, Cambridge, MA.Kirsh, D. (1995). intelligent use space. Artificial Intelligence, 72 (1{2), 31{68.Knoblock, C. A. (1989). theory abstraction hierarchical planning. Benjamin,D. P. (Ed.), Change Representation Inductive Bias. Kluwer, Boston.Kosecka, J. (1992). Control discrete event systems. GRASP LAB report 313, UniversityPennsylvania Computer Information Science Department, Philadelphia, PA.Lansky, A. L., & Fogelsong, D. S. (1987). Localized representations planning methodsparallel domains. Proceedings Sixth National Conference ArtificialIntelligence, pp. 240{245 Menlo Park, CA. AAAI Press.Lave, J., & Wenger, E. (1991). Situated Learning: Legitimate Peripheral Participation.Cambridge University Press, Cambridge, UK.Littman, M. L. (1993). optimization-based categorization reinforcement learningenvironments. Meyer, & Wilson (Meyer & Wilson, 1993), pp. 262{270.Lyons, D. M., & Arbib, M. A. (1989). formal model computation sensory-basedrobotics. IEEE Transactions Robotics Automation, 5 (3), 280{293.Maturana, H. R., & Varela, F. J. (1988). Tree Knowledge: Biological RootsHuman Understanding. Shambhala, Boston.Meyer, J.-A., & Wilson, S. W. (Eds.). (1993). Animals Animats: SecondInternational Conference Simulation Adaptive Behavior. MIT Press, Cambridge,MA.Newell, A., Shaw, J. C., & Simon, H. A. (1960). Report general problem-solvingprogram. Proceedings International Conference Information Processing,pp. 256{264 Paris.Newell, A., & Simon, H. A. (1963). GPS: program simulates human thought.Feigenbaum, E. A., & Feldman, J. (Eds.), Computers Thought, pp. 279{296.McGraw-Hill.Rogoff, B. (1990). Apprenticeship Thinking: Cognitive Development Social Context.Oxford University Press, New York.144fiLifeworld AnalysisRosenschein, S. J. (1987). Formal theories knowledge AI robotics. report CSLI87-84, Center Study Language Information, Stanford, CA.Rosenschein, S. J. (1989). Synthesizing information-tracking automata environmentdescriptions. Brachman, R. J., Levesque, H. J., & Reiter, R. (Eds.), ProceedingsFirst International Conference Principles Knowledge RepresentationReasoning, pp. 386{393.Rosenschein, S. J., & Kaelbling, L. P. (1986). synthesis machines provableepistemic properties. Halpern, J. (Ed.), Proc. Conf. Theoretical AspectsReasoning Knowledge, pp. 83{98. Morgan Kaufmann.Sacerdoti, E. D. (1974). Planning hierarchy abstraction spaces. Artificial Intelligence,5 (2).Salomon, G. (Ed.). (1993). Distributed Cognitions: Psychological Educational Considerations. Cambridge University Press.Schutz, A., & Luckmann, T. (1973). Structures Life-World. NorthwesternUniversity Press, Evanston, IL.Simon, H. A. (1947). Administrative Behavior: Study Decision-Making ProcessesAdministrative Organization. Macmillan, New York.Simon, H. A. (1970). Sciences Artificial. MIT Press, Cambridge, MA.Sussman, G. J. (1975). Computer Model Skill Acquisition. Elsevier, New York.Todd, P. M., Wilson, S. W., Somayaji, A. B., & Yanco, H. A. (1994). blind breedingblind: Adaptive behavior without looking. Cliff, D., Husbands, P., Meyer,J.-A., & Wilson, S. W. (Eds.), Animals Animats: Third InternationalConference Simulation Adaptive Behavior, pp. 228{237. MIT Press.Todd, P. M., & Wilson, S. W. (1993). Environment structure adaptive behaviorground up. Meyer, & Wilson (Meyer & Wilson, 1993), pp. 11{20.Wilson, S. W. (1991). animat path AI. Meyer, J.-A., & Wilson, S. W. (Eds.),Animals Animats: Proceedings First International Conference SimulationAdaptive Behavior, pp. 15{21. MIT Press, Cambridge, MA.Winston, P. H., Binford, T. O., Katz, B., & Lowry, M. (1983). Learning physical descriptionsfunctional definitions, examples, precedents. Proceedings NationalConference Artificial Intelligence, pp. 433{439 Austin, TX.145fiJournal Artificial Intelligence Research 6 (1997) 35-85Submitted 7/96; published 1/97SCREEN: Learning Flat Syntactic Semantic SpokenLanguage Analysis Using Artificial Neural NetworksStefan WermterVolker Weberwermter@informatik.uni-hamburg.deweber@informatik.uni-hamburg.deDepartment Computer ScienceUniversity Hamburg22527 Hamburg, GermanyAbstractPrevious approaches analyzing spontaneously spoken language often basedencoding syntactic semantic knowledge manually symbolically.progress using statistical connectionist language models, many currentspoken-language systems still use relatively brittle, hand-coded symbolic grammarsymbolic semantic component.contrast, describe so-called screening approach learning robust processingspontaneously spoken language. screening approach analysis uses shallow sequences category representations analyzing utterance various syntactic,semantic dialog levels. Rather using deeply structured symbolic analysis,use connectionist analysis. screening approach aims supporting speechlanguage processing using (1) data-driven learning (2) robustness connectionistnetworks. order test approach, developed screen systembased new robust, learned analysis.paper, focus detailed description screen's architecture,syntactic semantic analysis, interaction speech recognizer, detailedevaluation analysis robustness uence noisy incomplete input.main result paper representations allow robust processingspontaneous spoken language deeply structured representations. particular,show fault-tolerance learning capability connectionist networks supportanalysis providing robust spoken-language processing within overallhybrid symbolic/connectionist framework.1. IntroductionRecently fields speech processing well language processing seenefforts examine possibility integrating speech language processing (von Hahn& Pyka, 1992; Jurafsky et al., 1994b; Waibel et al., 1992; Ward, 1994; Menzel, 1994; Geutneret al., 1996; Wermter et al., 1996). new large speech language corporadeveloped rapidly, new techniques examined particularly supportproperties speech language processing. Although quiteapproaches spoken-language analysis (Mellish, 1989; Young et al., 1989; Hauenstein &Weber, 1994; Ward, 1994), emphasized learning syntactic semanticanalysis spoken language using hybrid connectionist1 architecture topicc 1997 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.fiWermter & Weberpaper goal screen2 . However, learning important reductionknowledge acquisition, automatic system adaptation, increasing systemportability new domains. Different previous approaches, paperdemonstrate hybrid connectionist learning techniques used providingrobust analysis faulty spoken language.Processing spoken language different processing written language, successful techniques text processing may useful spoken-language processing.Processing spoken language less constrained, contains errors less strict regularities written language. Errors occur levels spoken-language processing.instance, acoustic errors, repetitions, false starts repairs prominent spontaneously spoken language. Furthermore, incorrectly analyzed words, unforeseen grammatical semantic constructions occur often spoken language. order dealimportant problems \real-world" language analysis, robust processing necessary.Therefore cannot expect existing techniques like context-free tree representationsproven work written language simply transferred spokenlanguage.instance, consider speech recognizer produced correct German sentence hypothesis \Ich meine naturlich Marz" (English translation: \I mean courseMarch"). Standard techniques text processing - like chart parsers context-freegrammars - may able produce deeply structured tree representations many correctsentences shown Figure 1.sentenceverb phrasenoun grouppronounverb groupverbnoun groupadverbich (I) meine (mean) natrlich (of_course)nounMrz (March)Figure 1: Tree representation correctly recognized sentenceHowever, currently speech recognizers still far perfect produce many worderrors possible rely perfect sentence hypothesis. Therefore, incorrect1. Sometimes connectionist networks also called artificial neural networks. useterm \connectionist networks", term \hybrid connectionist architecture" referarchitecture emphasizes use connectionist networks rule usesymbolic representations higher levels might needed.2. Symbolic Connectionist Robust EnterprisE Natural language36fiSCREEN: Flat Syntactic Semantic Spoken Language Analysisvariations like \Ich meine ich Marz" (\I mean March"), \Ich hatte ich Marz" (\IMarch") \Ich Ich meine Marz" (\I mean March") analyzed. However,context-free grammars single syntactic semantic category error may preventcomplete tree built, standard top-down chart parsers may fail completely. However, suboptimal sentence hypotheses analyzed since sometimes sentencehypotheses best possible output produced speech recognizer. Furthermore,lot content extracted even partially incorrect sentence hypotheses.instance, \I March" plausible agent \I" said somethingtime \March". Therefore, robust analysis able analyze sentencehypotheses ideally break input.1.1 Screening Approach: Flat Representations Support Robustnessexamples incorrect variations sentence hypotheses, in-depth structuredsyntactic semantic representation advantageous since arbitrary word order spontaneous errors make often impossible determine desired deep highlystructured representation. Furthermore, deep highly structured representation maymany restrictions appropriate spontaneously spoken language. However,maybe even important, certain tasks necessary perform in-depthanalysis. While, instance, inferences story understanding require in-depthunderstanding (Dyer, 1983), tasks like information extraction spoken languageneed much in-depth analysis. instance, output parser usedtranslating speech recognizer sentence hypothesis \Eh ich meine eh ich Marz" (\Ehmean eh March"), may sucient extract agent (\I") uttered (\mean")time (\March"). contrast deeply structured representation, screening approachaims reaching robust representation spoken language. screening approachshallow analysis based category sequences (called representations) varioussyntactic semantic levels.representation structures utterance U words w1 wn accordingsyntactic semantic properties words contexts, e.g., according sequencebasic abstract syntactic categories. instance, phrase \a meeting London"described representation \determiner noun preposition noun" basicsyntactic level representation \noun-group noun-group prepositional-groupprepositional-group" abstract syntactic level. Similar representations usedsemantic categories, dialog act categories, etc.Kase(Rubbish)nounnoun groupnegationich(I)pronounanimatenoun groupagentmeine(mean)verbutterverb groupactionnaturlich(of course)adverbnilspecial groupmiscellaneousMarz(March)nountimenoun grouptimeFigure 2: Utterance representation37fiWermter & WeberFigure 2 gives example representation correct sentence hypothesis\Kase ich meine naturlich Marz" (\Rubbish mean course March"). first line showssentence, second literal translation. third line describes basic syntacticcategory word, fourth line shows basic semantic category. last two linesillustrate syntactic semantic categories phrase level.Kase(Rubbish)nounnoun groupnegationich(I)pronounanimatenoun groupagenthatte(had)verbverb groupactionich(I)pronounanimatenoun groupagentMarz(March)nountimenoun grouptimeFigure 3: Utterance representationFigure 3 gives example representation incorrect sentence hypothesis\Kase ich hatte ich Marz" (\Rubbish March"). parser spoken languageable process sentence hypotheses far possible, userepresentations support necessary robustness. example, analysisleast provide animate agent noun group (\I") made statementspecific time noun group (\March"). Flat representations potential supportrobustness better since minimal sequential structure, even erroroccurs whole representation still built. contrast, standard tree-structuredrepresentations many decisions made construct deeply structuredrepresentation, therefore possibilities make incorrect decisions,particular noisy spontaneously spoken language. chose representationsrather highly structured representations desired robustnessmistakes speech/language systems.1.2 Flat Representations Learned Hybrid Connectionist FrameworkRobust spoken-language analysis using representations could pursued differentapproaches. Therefore want motivate use hybrid connectionist approach,uses connectionist networks far possible rule use symbolicknowledge. use connectionist networks?important, due distributed fault tolerance, connectionist networks supportrobustness (Rumelhart et al., 1986; Sun, 1994) connectionist networks also number properties relevant spoken-language analysis. instance,connectionist networks well known learning generalization capabilities.Learning capabilities allow induce regularities directly examples. trainingexamples representative task, noisy robust processing supportedinductive connectionist learning.Furthermore, hybrid connectionist architecture property different knowledge sources take advantage learning generalization capabilities connectionist networks. hand, knowledge - task control knowledge -38fiSCREEN: Flat Syntactic Semantic Spoken Language Analysisrules known represented directly symbolic representations. Since humans apparently symbolic inferencing based real neural networks, abstract modelssymbolic representations connectionist networks additional potentialshed light human language processing capabilities. respect, approachalso differs candidates robust processing, like statistical taggers statisticaln-grams. statistical techniques used robust analysis (Charniak, 1993)statistical techniques like n-grams relate human cognitive language capabilities simple recurrent connectionist networks relationships humancognitive language capabilities (Elman, 1990).screen new hybrid connectionist system developed examinationsyntactic semantic analysis spoken language. earlier work exploredscanning understanding written texts (Wermter, 1995; Wermter & Lochel, 1994;Wermter & Peters, 1994). Based experience started completely new projectscreen explore learned fault-tolerant analysis spontaneously spoken-languageprocessing. preliminary successful case studies transcripts developedscreen system using knowledge generated speech recognizer. previous work,gave brief summary screen specific focus segmentation parsing dialogact processing (Wermter & Weber, 1996a). paper, focus detailed descriptionscreen's architecture, syntactic semantic analysis, interactionspeech recognizer, detailed evaluation analysis robustness uencenoisy incomplete input.1.3 Organization Claim Paperpaper structured follows. Section 2 provide detailed descriptionexamples noise spoken language. Noise introduced human speakeralso speech recognizer. Noise spoken-language analysis motivates representations whose categories described Section 3. basic abstract categoriessyntactic semantic level explained section. Section 4 motivateexplain design screen architecture. brief functional overview, showoverall architecture explain details individual modules connectionistnetwork level. order demonstrate behavior analysis spoken languageprovide various detailed examples Section 5. Using several representative sentenceswalk reader detailed step-by-step analysis. behavior system explained, provide overall analysis screen system Section 6.evaluate system's individual networks, compare performance simple recurrent networks statistical n-gram techniques, show simple recurrent networksperformed better 1-5 grams syntactic semantic prediction. Furthermoreprovide overall system evaluation, examine overall performance uenceadditional noise, supply results transfer different second domain. Finallycompare approach approaches conclude representations basedconnectionist networks provide robust learned spoken-language analysis.want point paper make argument deeply structured symbolic representations language processing general. Usually, deeplystructured representation built, course due additional knowledge con39fiWermter & Webertains, potential powerful relationships interpretations greaterrepresentation. instance, in-depth analysis required tasks like makingdetailed planning inferences reading text stories. However, screening approachmotivated based noisy spoken-language analysis. noisy spoken-language analysis,representations support robustness, connectionist networks effective providing robustness due learned fault-tolerance. main contributionpaper, demonstrate building evaluating computational hybridconnectionist architecture screen based at, robust, learned processing.2. Processing Spoken Languagegoal learn process spontaneously spoken language syntactic semanticlevel fault-tolerant manner. section give motivating examples spokenlanguage.2.1 \Noise" Spoken Languagedomain paper arrangement meetings business partners,currently use 184 spoken dialog turns 314 utterances domain. Oneturn consists one subsequent utterances speaker. 314utterances, thousands utterance hypotheses generated processedbased underlying speech recognizer. German utterance examples domainshown together literal English translation. important noteEnglish translations word-for-word translations.1. Kase ich meine naturlich Marz(Rubbish mean course March)2. Der vierzehnte ist ein Mittwoch richtig(The fourteenth Wednesday right)3. hm sechsten April bin ich leider auer Hause(Eh sixth April unfortunately home)4. Also ich dachte noch der nachsten Woche auf jeden Fall noch im April(So thought still next week case still April)5. Gut prima vielen Dank dann ist das ja kein Problem(Good great many thanks yeah problem)6. Oh das ist schlecht da habe ich um vierzehn Uhr dreiig einen Termin beim Zahnarzt(Oh bad fourteen o'clock thirty date dentist)7. Ja genau allerdings habe ich da von neun bis vier Uhr schon einen Arzttermin(Yes exactly however nine four o'clock already doctorappointment)see, spoken language contains many performance phenomena, amongexclamations (\rubbish", see Example 1), interjections (\eh", \so", \oh", see Examples 3,40fiSCREEN: Flat Syntactic Semantic Spoken Language Analysis4 6), new starts (\there ...", see Example 6). Furthermore, syntacticsemantic constraints spoken language less strict written text. instance,word order spontaneously spoken language often different written language.Therefore, spoken language \noisier" written language even transcribedsentences, well-known parsing strategies text processing - relywellformedness criteria - directly applicable analyzing spoken language.2.2 \Noise" Speech Recognizerwant analyze spoken language computational model,\noise" introduced humans speaking also \noise" introduced limitations speech recognizers. Typical speech recognizers produce many separated wordhypotheses different plausibilities time based given speech signal. wordhypotheses connected word hypothesis sequence evaluatedproviding basis analysis. Typically, word hypothesis consists four parts: 1)#PAUSE#0.00-[0.01-0.33]hm (eh)ich (I)0.02-[0.11-0.33]5.36e-020.12-[0.33-0.33]wie (how)2.92e-03htte (had)1.06-[1.21-1.21]0.13-[0.33-0.33](on)2.78e-03April (April)3.66e-040.81-[1.05-1.22]ich (I)1.22-[1.37-1.37]1.12-[1.22-1.22]ich (I)leider (unfortunately)3.33e-040.34-[0.43-0.43]6.84e-03sechsten (sixth)6.53e-050.44-[0.80-0.80]3.54e-031.13-[1.22-1.22]bin (am)1.53e-031.23-[1.30-1.37]1.38-[1.59-1.59]3.01e-015.07e-08wenn (if)3.35e-04ich (I)1.18e-021.31-[1.38-1.38]1.81e-02leider (unfortunately)1.39-[1.59-1.59]6.37e-04auer (out of)1.60-[1.90-1.90]Hause (home)6.74e-051.91-[2.37-3.38]7.18e-012.38-[3.38-3.38]#PAUSE#3.39-[3.39-3.39]1.88e-07#not recognized#2.74e-07Figure 4: Simple word graph spoken utterance: \ahm sechsten April bin ichleider auer Hause" (\eh sixth April unfortunately home").node represents word hypothesis; arrow represents possiblesubsequent word hypotheses. word hypothesis shown wordstring, start time, end time interval acoustic plausibility.41fiWermter & Weberstart time seconds, 2) end time seconds, 3) word string hypothesis,4) plausibility hypothesis based confidence speech recognizer. show simple word graph3 . practice, word graphs spontaneous speechmuch longer leading comprehensive word hypothesis sequences. However, illustratingproperties speech input focus relatively short simple word graph(Figure 4).word hypotheses overlap time constitute directed graph called wordgraph. node word graph represents one word hypothesis. Two hypothesesgraph generated word hypotheses connected end time first wordhypothesis directly start time second word hypothesis. instance,word hypothesis \am" (\on") ending 0.43 hypothesis \sechsten" (\sixth")starting 0.44 connected word hypothesis sequence.hm(eh)hm(eh)0secich(I)(on)sechsten(sixth)April(April)bin(am)leider(unfort.)auer(out of)Hause(home)(on)sechsten(sixth)April(April)wenn ich ich leider(if) (I) (I) (unfort.)auer(out of)Hause(home)1secich(I)3secFigure 5: Two examples word hypothesis sequences word graphexample word graph simple. However, shown Figure 5, possibleword hypothesis sequence desired \A hm sechsten April bin ich leiderauer Hause" (\Eh sixth April unfortunately home"), also sequence\A hm ich sechsten April wenn ich ich leider auer Hause" (\Eh sixth Aprilunfortunately home"). Consequently, deal incorrectly recognizedwords extraordinary order. Therefore syntactic semantic analysisfault-tolerant order process noisy word hypothesis sequences.3. Flat Category Representation: Intermediate ConnectingRepresentationsection describe category representations. First, showcategories syntactic analysis depict categories semanticanalysis.3. speech input form test word graphs taken so-called Blaubeuren MeetingCorpus. particular word graphs used provided project partners general testpurposes Verbmobil project. particularly generated testing parsing strategies.Therefore speech recognizer fine-tuned produce relatively small word graphs relativelyhigh word accuracy 93%. vocabulary size HMM recognizer 628. average numberhypotheses per word 6.3 10 dialogs.42fiSCREEN: Flat Syntactic Semantic Spoken Language Analysis3.1 Categories Flat Syntactic AnalysisFlat syntactic analysis assignment syntactic categories sequence words, e.g.,word hypothesis sequence generated speech recognizer. Flat representationsphrase group level support local structural decisions. Local structural decisions dealproblem phrase group (abstract syntactic category) word belongs to.case local, directly preceding words phrase group uencecurrent decision. instance, determiner \the" could part prepositional group\in mine" part starting noun group \the old mine". is, local structuraldecisions depending local context made based analysis.syntactic analysis developed level basic syntactic categoriesabstract syntactic categories. syntactic categories may vary depending language, degree detail intended structural representation. However,general approach rather independent specifically used categories. fact,used syntactic categories two different domains: railway counter interactionsbusiness meeting arrangements. basic syntactic categories used noun,verb, preposition, pronoun, numeral, past participle, pause, adjective, adverb, conjunction,determiner, interjection other. shown abbreviations Table 1.Categorynoun (N)verb (V)preposition (R)pronoun (U)numeral (M)participle (P)pause (/)Examplesdate, Aprilmeet, chooseat,I,fourteenthtakenpauseCategoryadjective (J)adverb (A)conjunction (C)determiner (D)interjection (I)(O)Exampleslateoftenand,the,eh, ohparticlesTable 1: Basic syntactic categoriesabstract syntactic categories used verb group, noun group, adverbial group,prepositional group, conjunction group, modus group, special group interjection group.abstract syntactic categories shown Table 2.Categoryverb group (VG)noun group (NG)adverbial group (AG)prepositional group (PG)conjunction group (CG)modus group (MG)special group (SG)interjection group (IG)Examplesmean, would proposedate, next possible slotlater, early possibledining halland, either ...interrogatives, confirmations: when, long, yesadditives like politeness: please,interjections, pauses: eh, ohTable 2: Abstract syntactic categories43fiWermter & Webercategories express main syntactic properties phrases.basic abstract syntactic categories widely used different parsers. However,approach representations crucially rely specific set basicabstract syntactic categories. goal train, learn generalize syntacticanalysis based abstract syntactic categories basic syntactic categories. Local syntactic decisions made far possible. Local syntactic ambiguitiesphrase group level (abstract syntactic categories) dealt global ambiguities like prepositional phrase attachment dealt since needadditional knowledge, e.g., semantics module. complete syntax treescertain preference (which might turn wrong based semantic knowledge),syntactic representation goes far possible using local syntactic knowledgedisambiguation.3.2 Categories Flat Semantic AnalysisSince semantic analysis domain-dependent, semantic categories differ differentdomains. worked particularly two domains: railway counter interactions (called:Regensburg train corpus) business meeting arrangements (called: Blaubeuren meetingcorpus). 3/4 overlap semantic categories train corpusCategoryselect (SEL)suggest (SUG)meet (MEET)utter (UTTER)(IS)(HAVE)move (MOVE)aux (AUX)question (QUEST)physical (PHYS)animate (ANIM)abstract (ABS)(HERE)source (SRC)destination (DEST)location (LOC)time (TIME)negative evaluation (NO)positive evaluation (YES)nil (NIL)Examplesselect, choosepropose, suggestmeet, joinsay, thinkis,had,come, gowould, couldquestion words: where,physical objects: building, oceanimate objects: I,abstract objects: datetime location state words, prepositions: at,time location source words, prepositions:time location destination words, prepositions:Hamburg, Pittsburghtomorrow, 3 o' clock, Aprilno, badyes, goodwords \without" specific semantics, e.g., determiner:Table 3: Basic semantic categoriesmeeting corpus (Wermter & Weber, 1996b). Differences occurred mainly verbs,e.g., NEED-events frequent railway counter interactions SUGGESTevents frequent business meeting interactions. semantic categories44fiSCREEN: Flat Syntactic Semantic Spoken Language AnalysisCategoryaction (ACT)aux-action (AUX)agent (AGENT)object (OBJ)recipient (RECIP)instrument (INSTR)manner (MANNER)time-at (TM-AT)time-from (TM-FRM)time-to (TM-TO)loc-at (LC-AT)loc-from (LC-FRM)loc-to (LC-TO)confirmation (CONF)negation (NEG)question (QUEST)misc (MISC)Examplesaction full verb events: meet, selectauxiliary action auxiliary events: would likeagent action:object action: daterecipient action:instrument action: using elevatorachieve action: without changing roomstime: morningstart time: 6amend time: 8pmlocation: Frankfurt, New Yorkstart location: Boston, Dortmundend location: Hamburgconfirmation phrase: ok great, yes wonderfulnegation phrase: stop,question phrases: timemiscellaneous words, e.g., politeness: please, ehTable 4: Abstract semantic categoriesrailway counter interactions described previous work (Weber & Wermter, 1995).primarily focus semantic categories meeting corpus. basicsemantic categories word shown Table 3. higher level abstraction,word belong abstract semantic category. possible abstract semantic categoriesshown Table 4. summary, categories provide basis analysis.word represented syntactically semantically context four categories twobasic two abstract levels.4. Architecture SCREEN Systemsection want describe constraints principles importantsystem design. outlined motivated introduction, screening approachat, robust, learned analysis spoken language based category sequences (calledrepresentations) various syntactic semantic levels. order test screeningapproach, designed implemented hybrid connectionist screen systemprocesses spontaneously spoken language using learned connectionist representations.summarize main requirements order motivate specific system designexplained subsequent subsections.4.1 General Motivation Architectureconsider learning extremely important spoken-language analysis severalreasons. Learning reduces knowledge acquisition increases portability, particularlyspoken-language analysis, underlying rules regularities dicultformulate often reliable. Furthermore, cases, inductive learning may detect45fiWermter & Weberunknown implicit regularities. want use connectionist learning simple recurrentnetworks rather forms learning (e.g., decision trees) primarilyinherent fault-tolerance connectionist networks, also knowledgesequence words categories learned simple recurrent networks.Fault-tolerance often occurring language errors ected systemdesign. commonly occurring errors (interjections, pauses, word repairs,phrase repairs). However, fault-tolerance cannot go far try model classoccurring errors. number potentially occurring errors unpredictable constructions far large. screen, want incorporate explicit fault-tolerance usingspecific modules correction well implicit fault-tolerance using connectionist network techniques inherently fault-tolerant due support similarity-basedprocessing. fact, even word completely unknown, recurrent networks useempty input may even assign correct category sucient previous context.Flat representations, motivated Sections 1 3, may support robust spokenlanguage analysis. However, connectionist representations provide full recursive power arbitrary syntactic semantic symbolic knowledge structures. contrastcontext-free parsers, representations provide better basis robust processingautomatic knowledge acquisition inductive learning. However, also argued use potentially unrestricted recursion well-known context-free grammarparsers provides computational model recursive power humansorder understand language. order better support robustness, want userepresentations spontaneous language analysis.Incremental processing speech, syntax, semantics dialog processing parallelallows us start language analysis parallel speech recognizer finishedanalysis. incremental processing advantage providing analysis resultsearly stage. example, syntactic semantic processing occur parallelslightly behind speech processing. analyzing spoken language based speechrecognizer output, want consider many competing paths word hypothesis sequencesparallel.respect hybrid representations, examine hybrid connectionist architectureusing connectionist networks useful also want use symbolic processing wherever necessary. Symbolic processing useful complex controllarge system. hand learning robust analysis, use feedforwardsimple recurrent networks many modules try use rather homogeneous, supervisednetworks.4.2 Overview Architecturescreen parallel integrated hybrid architecture (Wermter, 1994) variousmain properties:1. Outside module, difference communication symbolicconnectionist module. previous hybrid architectures emphasized differentsymbolic connectionist representations, different representations screenbenefit common module interface. Outside connectionist symbolic46fiSCREEN: Flat Syntactic Semantic Spoken Language Analysismodule communication identically realized symbolic lists contain valuesconnectionist units.2. previous hybrid symbolic connectionist architectures usually withineither symbolic connectionist module (Hendler, 1989; Faisal & Kwasny, 1990;Medsker, 1994), screen global state described collection individualsymbolic connectionist modules. Processing parallel long one moduleneed input second module.3. communication among symbolic connectionist modules organized viamessages. hybrid architectures often used either activationvalues symbolic structures, used messages consisting lists symbolsassociated activation plausibility values provide communication mediumsupports connectionist processing well symbolic processing.give overview various parts screen (see Figure 6).important output consists syntactic semantic category representations basedinput incrementally recognized parallel word hypotheses. speech recognizergenerates many incorrect word hypotheses time, even correctly recognized speechcontain many errors introduced humans. representation used sincefault-tolerant robust than, instance, context-free tree representation sincetree representation requires many decisions representation.module system, instance disambiguation abstract syntactic categories, contains connectionist network symbolic program. integration symbolicconnectionist representations occurs encapsulation symbolic connectionistprocesses module level. Connectionist networks embedded symbolic modulescommunicate via messages.However, essential parts needed purposes learning spokenlanguage analysis why? Starting output individual word hypothesesspeech recognizer, first need component receives incremental streamindividual parallel word hypotheses produces incremental stream word hypothesis sequences (see Figure 6). call part speech sequence construction part.needed transforming parallel overlapping individual word hypotheses word hypothesis sequences. word hypothesis sequences different quality goalfind work best word hypothesis sequences. Therefore need speechevaluation part combine speech-related plausibilities syntactic semanticplausibilities order restrict attention best found word hypothesis sequences.Furthermore, need part analyzes best found word hypothesis sequencesaccording syntactic semantic representation. category part receivesstream current word hypothesis sequences. Two word hypothesis sequencesshown Figure 6. part provides interpretation word hypothesis sequencebasic syntactic categories, abstract syntactic categories, basic semantic categories,abstract semantic categories. is, word hypothesis sequence assigned fourgraded preferences four word categories.Human speech analyzed speech recognizer may contain many errors. questionarises extent want consider errors. analysis several hundred47fiWermter & Webertwo word hypotheses sequences:1.output analysis2.Kseichmeinenatrlich(rubbish)(I)(mean)(of course) (March)NNGUNGNEGANIMAGENT UTTER ACTVVGSGNNGNILLMISCTIMETMATKseichhtteich(rubbish)(I)(had)(I)NNGUNGNEGANIMAGENTVMrzMrz(March)VGUACTANIM [AGENT] TIME[NG]NNGTMAT....syntactic/semantic hypothesescase frame partdialog partlearnedflatsyntacticsemanticanalysiscorrection partspeech evaluation partcategory partconstructed word hypotheses sequences:Kse ich meine natrlich Mrz1. Rubbish mean course Marchspeech sequence construction partKse ich htte ich MrzMarch2. Rubbish....word hypothesesword hypotheses generated speech recognizer:0.000.110.450.450.570.570.580.760.951.121.130.761.151.353.00input speech recognizercurrent word hypothesis0.100.440.560.570.750.750.941.141.112.991.341.112.992.993.00#PAUSE#KseichichmeinemeinehtteetlicheichMrzdanatrlichMrzaus#PAUSE#Figure 6: Overview screen48(rubbish)(I)(I)(mean)(mean)(had)(several)(I)(March)(there)(of course)(March)(out)7.022857e022.269389e063.697864e032.017291e031.245984e051.016475e042.831144e083.045548e081.749518e049.596145e161.257770e041.017243e074.249394e152.624843e127.497616e01fiSCREEN: Flat Syntactic Semantic Spoken Language Analysistranscripts speech recognizer outputs revealed errors occuroften regularly. interjections, pauses, word repairs, phrase repairs.Therefore designed correction part receives hypotheses words dealsfrequently occurring errors spoken language explicitly.parts outlined far build center integration speech-relatedlanguage-related knowledge fault-tolerant learning architecture, thereforefocus parts paper. However, want process complete dialog turnscontain several individual utterances need know certain utterancestarts constituents belong utterance. task performed caseframe part fills frame incrementally segments speaker's turn utterances.long-term perspective screen provide analysis tasks spokenutterance translation information extraction. Besides syntactic semantic analysisutterance, intended dialog acts convey important additional knowledge. Therefore,dialog part needed assigning dialog acts utterances, instance utterancerequest suggestion. fact, already fully implemented case frame partdialog part utterances. However, describe details twoparts paper since described elsewhere (Wermter & Lochel, 1996).Learning screen based concepts supervised learning instance feedforward networks (Rumelhart et al., 1986), simple recurrent networks (Elman, 1990)general recurrent plausibility networks (Wermter, 1995). general, recurrent plausibility networks allow arbitrary number context hidden layers considering longdistance dependencies. However, many network modules screen attemptedkeep individual networks simple homogeneous. Therefore, first versiondescribed used variations feedforward networks (Rumelhart et al., 1986)simple recurrent networks (Elman, 1990). Due greater potential sequentialcontext representations, recurrent plausibility networks might provide improvementsoptimizations simple recurrent networks. However, primarily interestedoverall real-world hybrid connectionist architecture screen rather optimization single networks. following description give detailed examplesindividual networks.4.3 Detailed Viewmotivated various parts screen, give detailed descriptionarchitecture screen respect modules syntactic semanticanalysis word hypothesis sequences. Therefore, focus speech related parts,categorization part correction part. Figure 7 shows detailed overviewparts. basic data ow shown arrows. Many modules generate hypothesesused subsequent modules higher level. hypotheses illustratedrising arrows. modules, output contains local predictive hypotheses (sometimescalled local top-down hypotheses) used modules lower level.hypotheses illustrated falling arrows. Local predictive hypotheses usedcorrection part eliminate4 repaired utterance parts speech evaluation parteliminate syntactically semantically implausible word hypothesis sequences.4. means repaired utterance parts actually marked deleted.49fiWermter & WeberSEGMENT-PARSERDIA-ACTframeslotsdialog acttypeverb-form...case frame part 128rejectuttermeinen(mean)43dialog partPHRASE-ERROR2233BAS-SYN-EQBAS-SEM-EQ222*132*20correction partLEX-START-EQLEX-WORD-EQ85WORD-ERRORpause, interjection,hesitation, unresolvedphonetic material?INTERJECTION1...PAUSE-ERRORPAUSEDialog Lexicon2ABS-SYN-EQ222*82*1734SEM-SPEECH-ERROR2PHRASE-START?3BAS-SYN-PRE54separatesSYN-SPEECH-ERRORABS-SEM-EQ5ABS-SYN-CATABS-SEM-CAT2817131320BAS-SEM-PRE13201320BAS-SYN-DIS22BAS-SEM-DIS1320132033verb, pronounUTTER, NILspeech evaluation partSyntactic LexiconSemantic Lexiconcategory part1CON-SEQU-HYPSKse ich meine(rubbish mean)constructed word hypotheses sequences:Kse ichKse ich meine(rubbish I)(rubbish mean)speech sequence construction partFigure 7: detailed overview screen. abbreviations functionalitymodules described text.50fiSCREEN: Flat Syntactic Semantic Spoken Language Analysiscases arrows would complex used numbers illustratedata ow individual modules.4.3.1 Speech sequence construction partspeech sequence construction part receives stream parallel word hypothesesgenerates stream word hypothesis sequences within module con-sequ-hypsbottom Figure 7. Based current word hypotheses many word hypothesis sequencesmay possible. cases reduce number current word hypotheses, e.g.,know time passed far specific word hypothesis sequence cannotextended anymore time current word hypothesis. caseeliminate sequence since word hypothesis sequences could reach endsentence candidates successful speech interpretation.Furthermore, use speech plausibility values individual word hypothesisdetermine speech plausibility word hypothesis sequence. usingbest word hypothesis sequences reduce large space possible sequences.generated stream word hypothesis sequences similar set partial N-bestrepresentations generated pruned incrementally speech analysis ratherend speech analysis process.4.3.2 Speech evaluation partspeech evaluation part computes plausibilities based syntactic semantic knowledge order evaluate word hypothesis sequences. part contains modulesdetection speech-related errors. Currently, performance speech recognizersspontaneously spoken speaker-independent speech general still far perfect.Typically, many word hypotheses generated certain signal5 . Therefore, many hypothesized words produced speech recognizer incorrect speech confidencevalue word hypothesis alone provide enough evidence finding desiredstring signal. Therefore goal speech evaluation part provide preferencefiltering unlikely word hypothesis sequences. syn-speech-error sem-speecherror two modules decide current word hypothesis syntactically(semantically) plausible extension current word hypothesis sequence. syntactic(semantic) plausibility based basic syntactic (semantic) category disambiguationprediction.summary, word hypothesis sequence acoustic confidence basedspeech recognizer, syntactic confidence based syn-speech-error, semanticconfidence based sem-speech-error. three values integrated weightedequally6 determine best word hypothesis sequences. way, two modules5. HMM-speech recognizer used generating word hypotheses domain word accuracy93% best match word graph desired transcript utterance.recognizer particularly optimized task domain order able examinerobustness language level. unoptimized version task domain currently 72%word accuracy.6. integration speech, syntax, semantics confidence values provided better resultsusing one two three knowledge sources.51fiWermter & Weberact evaluator speech recognizer well filter language processingpart.statistical models speech recognition, bigram trigram models used language models filtering best possible hypotheses. used simple recurrentnetworks since networks performed slightly better bigram trigram modelimplemented comparison (Sauerland, 1996). Later Section 6.1also show detailed comparison simple recurrent networks n-gram models (for n= 1,...,5). reason better performance internal representation simplerecurrent network restrict covered context fixed number twothree words potential learn required context needed.output-layer13 unitsNJVRCUP/14*13 connectionscontext-layerhidden-layer14*14conn.input-layer2*14 units14 copy13*14 connections13 unitsNJVRCUP/disambiguated representation "ich" ("I") BAS-SYN-DISFigure 8: Network architecture syntactic prediction speech evaluation part(bas-syn-pre). abbreviations explained Table 1.knowledge syntactic semantic plausibility provided predictionnetworks (bas-syn-pre bas-sem-pre) speech evaluation part disambiguation networks (bas-syn-dis bas-sem-dis) categorization part. example, show network bas-syn-pre Figure 8. previous basic syntacticcategory currently considered word hypothesis sequence input network.example \ich" (\I") word hypothesis sequence \Kase ich meine" (\Rubbishmean") found pronoun (U). Therefore, syntactic category representation\ich" (\I") contains \1" pronoun (U) category. categories receive \0".input network consists 13 units 13 categories. outputnetwork size. unit vector represents plausibilitypredicted basic syntax category last word current word hypothesis sequence.plausibility unit representing desired basic syntactic category (foundbas-syn-dis) taken syntactic plausibility currently considered word hypothesissequence syn-speech-error. example \meine" (\mean") found verb52fiSCREEN: Flat Syntactic Semantic Spoken Language Analysis(V). Therefore plausibility verb (V) taken syntax plausibility (selectionmarked box output-layer bas-syn-pre Figure 8).summary, syntactic (semantic) plausibility word hypothesis sequence evaluated degree agreement disambiguated syntactic (semantic) categorycurrent word predicted syntactic (semantic) category previous word.Since decisions current state whole sequence made, precedingcontext represented copying hidden layer current word context layernext word based SRN network structure (Elman, 1990). connectionsnetwork n:m connections except connections hidden layercontext layer simply used copy store internal preceding statecontext layer later processing next word comes in. general, speechevaluation part provides ranking current word hypothesis sequences equallyweighted combination acoustic, syntactic, semantic plausibility.4.3.3 Category partmodule bas-syn-dis performs basic syntactic disambiguation (see Figure 9). Inputmodule sequence potentially ambiguous syntactic word representations, oneword utterance time. module disambiguates syntactic categoryrepresentation according syntactic possibilities previous context. outputpreference disambiguated syntactic category. syntactic disambiguation tasklearned simple recurrent network. Input output network ambiguousdisambiguated syntactic category representations. Figure 9 show exampleinput representation \meine" (\mean", \my") verb pronoun.However, sequence \Ich meine" (\I mean"), \meine" verb thereforenetwork receives disambiguated verb category representation alone.module bas-sem-dis similar module bas-syn-dis instead receivingpotentially ambiguous syntactic category input producing disambiguated syntacticcategory output, module bas-sem-dis receives semantic category representationlexicon provides disambiguated semantic category representation output.semantic disambiguation learned simple recurrent network provides mapping ambiguous semantic word representation disambiguated semantic wordrepresentation. modules bas-syn-dis bas-sem-dis provide disambiguationsubsequent tasks like association abstract categories test categoryequality word error detection possible.module abs-syn-cat supplies mapping disambiguated basic syntacticcategory representations abstract syntactic category representations (see Figure 10).module provides abstract syntactic categorization realized simplerecurrent network. module important providing abstract interpretationutterance preparing input detection phrase errors. Figure 10 showsdisambiguated basic syntactic representation \meine" (\mean") verb -small preference pronoun - mapped verb group category higherabstract syntactic category representation. Based number basic abstractsyntactic categories 13 input units basic syntactic categories 8 outputunits abstract syntactic categories.53fiWermter & Weberoutput-layer13 unitsNJVRCUP/14*13 connectionshidden-layercontext-layer14*14conn.input-layer2*14 units14 copy13*14 connections13 unitsNJVRCUP/ambiguous representation"meine" (verb/pronoun)syntactic lexiconmeineKse(rubbish)verbpronounich meine(I) (mean)current word hypotheses sequenceFigure 9: Network architecture basic syntactic disambiguation (bas-syn-dis).abbreviations explained Table 1.module abs-sem-cat parallel module abs-syn-cat uses basic semanticcategory representations input abstract semantic category representations output.Similar previous modules, also used simple recurrent network learnmapping represent sequential context. input network basicsemantic category representation word, output abstract categorypreference.described four networks provide basis fault-tolerant analysisdetection errors. Furthermore, module phrase-start distinguishingabstract categories. task module indicate boundaries subsequentabstract categories delimiter. use boundaries determine abstractsyntactic abstract semantic category phrase7 . Earlier experiments providedsupport take abstract syntactic category first word phrase finalabstract syntactic category phrase, since phrase starts (e.g., prepositions) good7. Figure 7 show uence phrase start delimiter abstract syntactic semanticcategorization dotted lines.54fiSCREEN: Flat Syntactic Semantic Spoken Language Analysisoutput-layer8 unitsNGVGPGCGAG MGSGIG14*13 connectionshidden-layercontext-layer14*14conn.input-layer13*14 connections2*14 units14 copy13 unitsNJVRCUdisambiguated representation "meine" (mean)P/Figure 10: Network architecture abstract syntactic categorization (abs-syn-cat).abbreviations explained Table 2.indicators abstract syntactic categories (Wermter & Lochel, 1994). hand,earlier experiments supported take abstract semantic category last wordphrase final abstract semantic category phrase, since phrase ends (e.g., nouns)good indicators abstract semantic categories (Wermter & Peters, 1994). Furthermore, phrase start gives us opportunity distinguish two equal subsequent abstractcategories two phrases. instance, phrase like \in Hamburg Monday"know border exists first second prepositionalphrase.4.3.4 Correction partcorrection part contains modules detecting pauses, interjections, well repetitions repairs words phrases (see Figure 7). modules detecting pauseerrors pause-error, pause interjection. modules pause interjection receive currently processed word detect potential occurrence pauseinterjection, respectively. output modules input module pauseerror. soon pause interjection detected, word marked deletedtherefore virtually eliminated input stream8. elimination interjectionspauses desired - instance speech translation task - order provide inter8. Pauses interjections sometimes provide clues repairs (Nakatani & Hirschberg, 1993) althoughcurrently use clues repair detection. Compared lexical, syntactic, semanticequality constituents, interjections pauses provide relatively weak indicators repairs sincealso occur relatively often places sentence. However, since mark interjectionspauses deleted could make use knowledge future necessary.55fiWermter & Weberpretation errors possible. Since three modules basically occurrencetests realized symbolic representations.second main cluster modules correction part modulesresponsible detection word-related errors. Then, word repairs \Am sechstenApril bin ich ich" (\on sixth April I") \Wir haben ein Termin Treffen" (\Wedate meeting") dealt with. certain preferences finding repetitionsrepairs word level. Among preferences lexical equality twosubsequent words (symbolic module lex-word-eq), equality two basic syntacticcategory representations (connectionist module bas-syn-eq), equality basicsemantic categories two words (connectionist module bas-sem-eq). examplethree modules, show test syntactic equality (BAS-SYN-EQ) Figure 11.output-layer2 unitsequal equal5*2 connectionshidden-layer5 unitsinput-layer(2*13)*5 connectionsN J V R C U P /N J V R C U P /2*13unitsdisambiguated representation second "ich" (I)disambiguated repr. first "ich" (I)output-layer2 unitsequal equal5*2 connectionshidden-layer5 unitsinput-layer(2*13)*5 connectionsN J V R C U P /disambiguated repr. "Termin" (date)N J V R C U P /2*13unitsdisambiguated representation "Treffen" (meeting)Figure 11: Network architecture equality basic syntactic category representation (bas-syn-eq). abbreviations explained Table 1.56fiSCREEN: Flat Syntactic Semantic Spoken Language AnalysisTwo output units plausible/implausible outcome used since network two output units gave consistently better results compared networkone output unit (with 1 plausible 0 implausible). reason network two output units performed better separation weights plausibleimplausible hidden-output layer. order receive single value, two output values integrated according formula: unit1 (1:0 , unit2 ). Then, outputthree equality modules value 0 1 1 represents equality 0represents inequality. Although single preference may sucient, commonuence provides reasonable basis detecting word repairs word repetitionsmodule word-error. Then, word repairs repetitions eliminated originalutterance. Since modules word-related errors based two representations twosubsequent input words since context play minor role, use feedforwardnetworks modules. hand, simple test lexical equalitytwo words lex-word-eq represented effectively using symbolic representation.third main cluster correction part consists modules detectioncorrection phrase errors. example phrase error is: \Wir brauchenden fruheren Termin den spateren Termin" (\We need earlier date later date").preferences phrase errors lexical start two subsequent phrasesequal, abstract syntactic categories equal abstract semantic categoriesequal. three preferences modules lex-start-eq, abs-syn-eqabs-sem-eq. modules receive two input representations two correspondingwords two phrases, lex-start-eq receives two lexical words, abs-syn-eq two abstractsyntactic category representations, abs-sem-eq two abstract semantic category representations. output three modules value toward 1 equality toward0 otherwise. values input module phrase-error finally decideswhether phrase replaced another phrase. lexical equality two wordsdiscrete test, implemented lex-start-eq symbolically, preferencesphrase error implemented feedforward networks.5. Detailed Analysis Examplessection detailed look processing output speech recognizerproducing syntactic semantic interpretation concurrent word hypothesissequences (also called sentence hypothesis here).5.1 Overall Environmentoverall processing incremental left right, time multiple sentencehypotheses processed parallel. Figure 12 shows snapshot screen 0.95sutterance. time snapshot shows first three sentence hypothesesGerman words together (literal) English translations (\Rubbish mean", \Rubbish I", \Rubbish had"). screen environment allows user view inspectincremental generation word hypothesis sequences (partial sentence hypotheses)preferred syntactic semantic categories basic abstract level.sentence hypothesis illustrated horizontally. certain time many sentence hypothesesactive parallel. ranked according descending plausibility57fiWermter & WeberSCREEN - Symbolic Connectionist Robust EnterprisE Natural languageQuitlineStopGosingle step13 Sentencehypotheses. Time: 0.95s (System)/0.95s (Display)NNGSUGNEG CONFKse (rubbish)N0NGSUGNEG CONFKse (rubbish)NNGSUGNEG CONFKse (rubbish)UNGSUGANIM AGENT CONFich (I)VNILSUGUTTER NILCONFmeine (mean)UNILSUGANIMNILCONFNGSUGich (I)UANIM AGENT CONFich (I)VNILSUGNILCONFhtte (had)00.0000 0.0000 0.9799 0.0000 0.0038 0.0004 0.1653 0.0048 0.0001 0.0003 0.0001 0.0017 0.0001NJVRCUP/Figure 12: First snapshot sentence \Kase ich meine naturlich Marz (\Rubbish meancourse March"). abbreviations explained Table 1 4. Below,second pop-up window illustrates full preferences word \meine"(\mean") basic syntactic categories.sentence hypotheses. snapshot Figure 12 currently three sentencehypotheses preferred current sentence hypothesis consists \Rubbish mean".sentence hypotheses syntactically semantically plausible starts.underlying variations introduced speech recognizer produced different wordhypotheses slightly overlapping signal parts sentence. Besides speech plausibility, syntax also semantics help choosing better sentence hypotheses. Currentlycombine speech recognition plausibility, syntactic plausibility, semanticplausibility compute plausibility sentence hypotheses multiplicationrespective normalized plausibility values 0 1. Since speech recognizercontain syntactic semantic knowledge, sequence hypothesis rated plausible basedspeech knowledge alone may neglect potential syntactic semantic regularity.58fiSCREEN: Flat Syntactic Semantic Spoken Language Analysisusing corresponding syntactic semantic plausibility values sentence hypothesisintegrate acoustic, syntactic, semantic knowledge.word hypothesis shown preferred basic syntactic hypothesis (upper leftsquare word hypothesis), preferred abstract syntactic hypothesis (upper middlesquare), preferred basic semantic hypothesis (lower left square), preferred abstractsemantic hypothesis (lower middle square), preferred dialog act (upper right square)9,integrated acoustic, syntactic semantic confidence partial sentence hypothesis point (lower right square). size square illustrates strengthhypothesis, full black square means preferred hypothesis close one.instance, word hypothesis \ich" (\I") first sentence hypothesishypothesis pronoun (U) basic syntactic category, noun group (NG)abstract syntactic category, animate object (ANIM) basic semantic category,AGENT abstract semantic category, suggestion (SUG) dialog act. Furthermore, length vertical bar word hypotheses indicate plausibilitynew phrase start.another example, see representation example word \meine" (couldverb \mean" pronoun \my" German) used throughoutnetwork descriptions (see Figure 9). network correct preference \meine"verb (V). Figure 12 shows preference well zoomed illustrationless favored preferences second pop-up window below. see, ambiguous pronoun preference U received second strongest activationpreferences close 0. shown activation preferences output valuescorresponding network basic syntactic categorization. shown activation valuesnapshots shows preferred hypothesis hypothesesshown request10.Within display scroll descending ascending sentencehypotheses. Furthermore scroll left right analyzing specific longer wordhypothesis sequences. also step mode allows screen system waitinteractive mouse click process next incoming word hypothesisdetailed analysis. step mode adapted different number steps (wordhypotheses) switched completely one decides analyze sentencehypotheses later end word hypotheses. preferred possiblesyntactic semantic hypotheses shown. Therefore many different hypotheses appearsize. However, clicking one squares less confidenthypotheses displayed well.9. dialog acts use are: accept (ACC), query (QUERY), reject (REJ), request-suggest (RE-S),request-state (RE-S), state (STATE), suggest (SUG), miscellaneous (MISC). Since paper focusessyntactic semantic aspects screen elaborate implemented dialogpart here. details dialog act processing described previously (Wermter & Lochel,1996).10. snapshots Figure 12 abstract syntactic semantic categories yet computedtherefore represented NIL. next processing step computation performedseen next Figure 13.59fiWermter & Weber5.2 Analyzing Final Snapshot Short Sentence HypothesesFigure 13 illustrate final state 3.01s utterance. Eight possible sentence hypotheses remained see first four Figure 13. Startingfourth sentence hypothesis \Kase ich hatte ich Marz" (\Rubbish march")see lower rated sentence hypothesis desired sentence. lower rankedhypotheses good examples current state-of-the-art speech recognizers aloneable produce reliable sentence hypotheses, since problem analyzing spontaneousspeaker-independent speech complex. Therefore syntactic semantic components spontaneous language take account highly irregularsequences shown below. However, interesting observe underlying connectionist networks always produce preference syntactic semantic interpretationabstract basic level. fact, although lower ranked sentence hypothesesconstitute desired sentence assigned syntactic semantic categoriescorrect individual word hypotheses. course may cases networkalso could make wrong decision uncertain word hypotheses. However syntacticsemantic processing never break possible sentence hypothesis,respect different well-known methods like symbolic context-free chart parsers.look top-ranked sentence hypothesis \Kase ich meine naturlich Marz" (\Rubbish mean course March") also desired sentence. plausibleSCREEN - Symbolic Connectionist Robust EnterprisE Natural languageQuitGolineStopsingle step18 Sentencehypotheses. Time: 3.01s (System)/3.01s (Display)NNG DSUGNEG CONFKSE0NG DSUGANIM AGENT CONFICHNNG DSUGNEG CONFKSEUNG DSUGNG DSUGANIM AGENT CONFNEG CONFKSEUNG DSUGNG DSUGANIM AGENT CONFNEG CONFUUTTER ACTCONFVVG DSUGUTTER ACTVNG DSUGVHTTESG DSUGNILLMISC CONFNATRLICHCONFSG DSUGNILLMISC CONFNATRLICHVG DSUGACTCONFHTTEANIM AGENT CONFICHVG DSUGMEINEICHNVMEINEICHNKSEUUNG DSUGANIM AGENT CONFICHVG DSUGACTCONFUNNG DSUGTIME TMAT CONFMRZNNG DSUGTIME TMAT CONFMRZNNG DSUGTIME TMAT CONFMRZNG DSUGANIM AGENT CONFICHNNG DSUGTIME TMAT CONFMRZ0Figure 13: Final snapshot sentence \Kase ich meine naturlich Marz (\Rubbish meancourse March").60fiSCREEN: Flat Syntactic Semantic Spoken Language Analysissentence based speech language plausibility. Furthermore, see assigned categories correct: German word \Kase" (\Rubbish") found nounpart noun group expresses negation. \Ich" (\I") starts new phrase,pronoun noun group represents animate agent. followingGerman word \meine" particularly interesting since used verb sense\mean" also pronoun sense \my". Therefore, connectionist networkbasic syntactic classification disambiguate two possibilities basedpreceding context. network learned take consideration precedingcontext able choose correct basic syntactic category verb (V) ratherpronoun (U) word \meine" (\mean"). time new phrase startfound well. following word \naturlich" (\of course") highest preferenceadverb special group. Finally, word \Marz" (\March") assigned highestplausibility noun noun group well time something happens.5.3 Phrase Starts Phrase Groups Longer Sentence Hypothesesfocus detailed analysis second example: \A hm ja genau allerdingshabe ich da von neun bis vier Uhr schon einen Arzttermin". literally translatedSCREEN - Symbolic Connectionist Robust EnterprisE Natural languageQuitGolineStopsingle step110 Sentencehypotheses. Time: 2.18s (System)/2.18s (Display)YESMG DACCCONF CONFJAYESMG DACCCONF CONFJADREJCONF CONFJYESYESMG DACCCONF CONFJANILLMGDREJCONF CONFYESMG DACCCONF CONFNILLSGDREJNEG CONFSGDREJNEG CONFALLERDINGSMG DMISCMISC CONFDENNOCHALLERDINGSGENAUJAYESMGGENAU0JMG DMISCMISC CONFDENNOCHSG DMISCNEG CONFALLERDINGSSG DMISCNEG CONFALLERDINGSVVGDREJACTCONFHABEVGDREJACTCONFHABEUNILLACTCONFNGDREJMISC CONFACTCONFANIM AGENT CONFUNILLESDREJMISC CONFNILLSGDREJMISC CONFNILLSG DMISCMISC CONFDAMISC CONFDREJTMAT CONFRPGDREJTMAT CONFRNIL DMISCNILCONFVONNILLDAPGVONNG DMISCRVONNG DMISCICHHABENILLSGDAUVG DMISCDAESHABEVDREJANIM AGENT CONFVG DMISCNGICHVVUSG DMISCMISC CONFRNIL DACCNILCONFVON0Figure 14: First part snapshot sentence \A hm ja genau allerdings habe ichda von neun bis vier Uhr schon einen Arzttermin" (literal translation: \Yesexactly however nine four o'clock already doctorappointment"; improved translation: \Eh yes exactly howeverdoctor appointment nine four o'clock").61fiWermter & WeberSCREEN - Symbolic Connectionist Robust EnterprisE Natural languageQuitlineStopGosingle step110 Sentencehypotheses. Time: 4.45s (System)/4.45s (Display)PGMISCTIME TMAT CONFneun (nine)PGMISCneun (nine)PGMISCTIME TMAT CONFPGMISC CONFRNILRNILACCRNILbis (to)PGMISCTIME TMAT CONFvier (four)PGMISCMISC CONFPGPGMISCMISCTIME TMAT CONFMISC CONFPGMISCMISCTIME TMAT CONFMISC CONFPGMISCTIME TMAT CONFNPGMISCTIME TMAT CONFNPGMISCTIME TMAT CONFUhr (oclock)MISCTIME TMAT CONFzehn (ten)PGUhr (oclock)zehn (ten)PGNUhr (oclock)vier (four)bis (to)TIME TMAT CONFneun (nine)MISCbis (to)neun (nine)NILPGbis (to)TIME TMAT CONF0RNPGACCTIME TMAT CONFUhr (oclock)NILSGMISCMISC CONFschon (already)NILSGMISCMISC CONFschon (already)NILSGMISCMISC CONFschon (already)NILSGACCMISC CONFschon (already)NILNGRESMISC CONFeinen (a)NILNGRESMISC CONFNILNGRESMISC CONFNILNGABSOBJCONFNNGRESABSOBJCONFNNGRESABSOBJCONFArzttermin(doc.appRESMISC CONFeinen (a)RESArzttermin(doc.appeinen (a)NGArzttermin(doc.appeinen (a)NNNGRESABSOBJCONFArzttermin(doc.app7Figure 15: Second part snapshot sentence \A hm ja genau allerdings habe ichda von neun bis vier Uhr schon einen Arzttermin" (\Yes exactly howevernine four o'clock already doctor-appointment").sentence analyzed is: \Eh yes exactly however nine four o'clockalready doctor-appointment". better non-literal translation would be: \Eh yesexactly however doctor appointment nine four o'clock".analysis first sentence hypotheses, interjection \ahm" (\eh") detectedcorresponding module correction part eliminated respectivesentence hypotheses.Figure 14 Figure 15 show best found four sentence hypotheses.categories sentence hypotheses look similar keep separatehypotheses since differ time stamps speech confidence values.two snapshots longer example also illustrate uencephrase starts. sequences \von neun" (\from nine") \bis vier Uhr" (\to fouro'clock") constitute two phrase groups clearly separated black barprepositions \von" (\from") \bis" (\to"). words \neun" (\nine"),\vier" (\four"), \Uhr" (\o'clock") start another phrase group. Since underlying connectionist network learning phrase boundaries simple recurrent networkexample demonstrates network learned preceding context. Withoutlearned preposition \von" (\from") \bis" (\to") noun62fiSCREEN: Flat Syntactic Semantic Spoken Language Analysislike \Uhr" (\o'clock") within prepositional phrase group couldalso part noun phrase another context like \vier Uhr pat gut" (\four o'clock fitswell").5.4 Dealing Noise RepairsFinally focus example simple word graph shown beginningpaper page 41: \A hm sechsten April bin ich leider auer Hause". literaltranslation \Eh 6th April unfortunately home". Using sentencegive example interjection simple word repair. Dealing hesitationsrepairs large area spontaneous language processing main topicpaper (a detailed discussion repairs screen found previous work,Weber & Wermter, 1996). Nevertheless, sake illustration completenessshow ability screen deal interjections word repairs. first snapshotFigure 16 shows start example sentence 1.39s. leading interjection\eh" eliminated already.Furthermore, see second word hypothesis sequence shows two subsequentword hypotheses \ich" (\I"). possible since two word hypothesesSCREEN - Symbolic Connectionist Robust EnterprisE Natural languageQuitGolineStopsingle step118 Sentencehypotheses. Time: 1.39s (System)/1.39s (Display)RPGSUGTMAT CONF(on)RPGSUG(on)RPGSUGTMAT CONFTIME TMAT CONFPGSUGTIME TMAT CONFPGSUGTIME TMAT CONFsechsten (6th)PGSUGTMAT CONF(on)SUGsechsten (6th)(on)RPGsechsten (6th)TMAT CONF0PGSUGTIME TMAT CONFsechsten (6th)NPGSUGTIME TMAT CONFApril (April)NPGSUGTIME TMAT CONFPGSUGTIME TMAT CONFPGACTCONFVVGSUGACTCONFUPGSUGUNGSTATEANIM AGENT CONFich (I)UNILSTATEANIMNILCONFUNILSTATEANIMNILCONFich (I)UNILSUGANIMNILCONFUNILSUGANIMNILCONFNGSTATEich (I)SUGANIM RECIP CONFich (I)TIME TMAT CONFApril (April)STATEhtte (had)April (April)NVGbin (am)April (April)NVich (I)VVGSTATEACTCONFbin (am)UANIM AGENT CONFich (I)ich (I)0Figure 16: First snapshot sentence \A hm sechsten April bin ich leider auerHause" (\Eh 6th April unfortunately home").63fiWermter & Webergenerated speech recognizer could connected. casefour word hypotheses shown below:start time1.22s1.23s1.23s1.31send time1.37s1.30s1.37s1.38sword hypothesisich (I)ich (I)ich (I)ich (I)speech plausibility1.527688e-031.178415e-022.463924e-031.813340e-02using speech knowledge word hypotheses, possible connectsecond hypothesis runs 1.23s 1.30s fourth hypothesis runs1.31s 1.38s. example noise generated speech recognizer, sincedesired sentence contains one word \ich" (\I") sentence hypothesispoint contains two. repetition treated eliminated way actualword repairs language. reasons occurrence repairs differenteffect repeated word same. Therefore, case repeated \ich" (\I")eliminated sentence sequence. Figure 17 show final snapshotsentence. see word repairs occur top-ranked sentence hypothesisalso desired sentence.SCREEN - Symbolic Connectionist Robust EnterprisE Natural languageQuitlineStopGosingle step110 Sentencehypotheses. Time: 3.40s (System)/3.40s (Display)PGSUGTIME TMAT CONFsechsten (6th)PGSUGTIME TMAT CONF0sechsten (6th)PGSUGTIME TMAT CONFsechsten (6th)PGSUGTIME TMAT CONFsechsten (6th)NPGSUGTIME TMAT CONFApril (April)NPGSUGTIME TMAT CONFPGSUGTIME TMAT CONFPGACTCONFUPGSUGUNGSTATEANIM AGENT CONFich (I)SUGANIM RECIP CONFUVVGSTATENGSUGANIM RECIP CONFACTCONFVGSTATENGSTATEANIM AGENT CONFACTCONFUSGREJNEG CONFSGREJNEG CONFleider (unfort.)ich (I)Vbin (am)Uleider (unfort.)ich (I)bin (am)TIME TMAT CONFApril (April)STATEich (I)April (April)NVGbin (am)April (April)NVSGREJNEG CONFleider (unfort.)NGSTATEANIM AGENT CONFich (I)SGREJNEG CONFleider (unfort.)RPGREJLCAT CONFauer (out of)RPGREJLCAT CONFauer (out of)RPGREJLCAT CONFauer (out of)RPGREJLCAT CONFauer (out of)NPGREJPHYS LCAT CONFHause (home)NPGREJPHYS LCAT CONFHause (home)NPGREJPHYS LCAT CONFHause (home)NPGREJPHYS LCAT CONFHause (home)1Figure 17: Final snapshot sentence \A hm sechsten April bin ich leider auerHause" (\Eh 6th April unfortunately home").64fiSCREEN: Flat Syntactic Semantic Spoken Language Analysisgeneral, language repairs, screen deal elimination interjectionspauses, repair word repetitions, word corrections (where words maydifferent, categories same) well simple forms phrase repairs (wherephrase repeated replaced another phrase).6. Design Analysis SCREENsection describe design choices screen. particular focusissues use connectionist networks, reach high accuracy little training,screen compared systems design principles.6.1 Use Connectionist Networks SCREEN?past, n-gram based techniques used successfully tasks like syntacticcategory prediction part speech tagging. Therefore, possible ask developed simple recurrent networks screen. subsection provide detailedcomparison simple recurrent networks n-gram techniques prediction basicsyntactic categories. chose task detailed comparison since currentlydicult task simple recurrent network screen. purposefullychoose subtask simple recurrent network high accuracy,prediction task since dicult predict category compared disambiguating among categories, instance. chose dicult prediction relativelylow network performance order (extremely) fair comparison n-gramtechniques.primarily interested generalization behavior new unknown input.Therefore Figure 18 shows accuracy syntactic prediction unknown testset. word several different syntactic categories follow syntacticcategories excluded. instance, determiner \the" adjective nounfollow: \the short ...", \the appointment", determiner \the" prepositionimplausible occur probably excluded. Therefore importantknow many categories ruled Figure 18 shows relationshipprediction accuracy number excluded categories n-grams simplerecurrent network (as described Figure 8).expect, techniques, n-grams recurrent networks, predictionaccuracy higher categories excluded performance lowermany categories excluded. However, interestingly, see simplerecurrent networks performed better 1-grams, 2-grams, 3-grams, 4-grams 5-grams.Furthermore, interesting note higher n-grams necessarily lead betterperformance. instance, 4-grams 5-grams perform worse 2-grams sincewould probably need much larger training sets.comparison n-grams (1-5) simple recurrent networks alsosemantic prediction received result simple recurrent networks performedbetter n-grams. performance best n-gram often slightly worseperformance simple recurrent network, indicates n-gramsreasonably useful technique. However, comparisons simple recurrent networks per65fiWermter & WeberTestset100correct prediction %806040SRN1gram2gram3gram4gram5gram200024681012number excluded categoriesFigure 18: Comparison simple recurrent network n-gramsformed least slightly better best n-grams. Therefore, used simple recurrentnetworks primary technique connectionist sequence learning screen.explain result? N-grams like 2-grams still perform reasonably welltask simple recurrent networks closest performance. However,simple recurrent networks perform slightly better since contain fixedlimited context. many sequences, simple recurrent network may primarily usedirectly preceding word representation make prediction. However, exceptionscontext required recurrent network memory internal reducedrepresentation preceding context. Therefore, potential exiblerespect context size.N-grams may perform optimally extremely fast. question arisesmuch time necessary compute new category using new input currentcontext network. general networks differ slightly size typicallycontain several hundred weights. typical representative simple recurrent network13 input units, 14 hidden units, 8 output units, 14 context units, 500 weightstakes 10,4 Sparc Ultra compute new category within whole forward sweep.66fiSCREEN: Flat Syntactic Semantic Spoken Language AnalysisSince techniques smoothed n-grams basically rely ecient table-look-upprecomputed values, course typical n-gram techniques still faster. However, duefixed-size context may perform well simple recurrent networks. Furthermore, computing next possible categories 10,4s fast enough current versionscreen. sake explanation one could argue screen contains 10networks modules typical utterance contains 10 words, single utterance hypothesis could performed 10,2 s. However, different text tagging, singlesentences process word graphs. Depending specific utterance, 105 wordhypothesis sequences could generated processed. Furthermorebook-keeping required keeping best word hypotheses, loading appropriate networks appropriate word hypotheses, etc. potentially large numberword hypotheses, additional book-keeping performance, number individualmodules syntax, semantics dialog processing explain total analysis timewhole unoptimized screen system order seconds although single recurrentnetwork performs order 10,4 s.6.2 Improvement Hypothesis Spacesubsection analyze extent syntactic semantic predictionknowledge used improve best found sentence hypotheses. illustratepruning performance hypothesis space integrating acoustic, syntactic, semantic knowledge. speech recognizer alone provides acoustic confidencevalues, screen adds syntactic semantic knowledge. knowledge sourcesweighted equally order compute single plausibility value current word hypothesis sequence. plausibility value used speech construction part prunehypothesis space select currently best word hypothesis sequences. Severalword hypothesis sequences processed incremental parallel. given time11n best incremental word hypothesis sequences kept .syntactic semantic plausibility values based basic syntactic semantic prediction (bas-syn-pre bas-sem-pre) next possible categoriesword selection preference determined basic syntactic respectively semantic category (bas-syn-dis bas-sem-dis)12 . performance disambiguationmodules 86%-89% test set. prediction modules performance 72%81% semantic syntactic test set, respectively want exclude least8 12 possible categories. performance allows us computation syntacticsemantic plausibility syn-speech-error sem-speech-error. Basedcombined acoustic, syntactic, semantic knowledge, first tests 184 turns showaccuracy constructed sentence hypotheses screen could increased30% using acoustic syntactic plausibilities 50% using acoustic,syntactic, semantic plausibilities (Wermter & Weber, 1996a).11. experiments low values (n = 10) provided best overall performance.12. explained detail Section 4.3.267fiWermter & Weber6.3 SCREEN's Network Performance Networks Yield HighAccuracy Little Trainingevaluating performance screen's categorization part meeting corpusfirst show percentages correctly classified words important networkscategorization: bas-syn-dis, bas-sem-dis, abs-syn-cat, abs-sem-cat, phrase-start.184 turns corpus 314 utterances 2355 words. 1/3 2355words 184 turns used training, 2/3 testing. Usually data usedtraining testing. preliminary earlier experiments used 2/3 training1/3 testing. However, performance unknown test set similar 1/3training set 2/3 test set. Therefore, used testing training data sinceinterested generalization performance unknown instances testset compared training performance known instances.first sight, might seem relatively little data training. statistical techniquesinformation retrieval techniques often work large texts individual lexical worditems, need much less material get reasonable performance since worksyntactic semantic representations rather words. would like stressuse syntactic semantic category representations 2355 words trainingtesting rather lexical words themselves. Therefore, category representationrequires much less training data lexical word representation would required.side effect, also training time reduced 1/3 training set, keepingperformance 2/3 test set. is, training used category representations64 dialog turns, testing generalization category representations remaining120 dialog turns.Table 5 shows test results individual networks unknown test set.networks trained 3000 epochs learning rate 0.001 14 hidden units.configuration provided best performance network architectures.general tested network architectures 7 28 hidden units, learning parameters0.1 0.0001. learning rule used generalized delta rule (Rumelhart et al.,1986). assigned output category representation word counted correctcategory maximum activation desired category.ModuleAccuracy test setbas-syn-dis89%bas-sem-dis86%abs-syn-cat84%abs-sem-cat83%phrase-start90%word-error94%phrase-error98%Table 5: Performance individual networks test set meeting corpusperformance basic syntactic disambiguation 89% unknown testset. Current syntactic (text-)taggers reach 95% accuracy texts. However,68fiSCREEN: Flat Syntactic Semantic Spoken Language Analysisbig difference text speech parsing due spontaneous noisespoken language. interjections, pauses, repetitions, repairs, new starts\ungrammatical" syntactic varieties spoken-language domain reasonstypical accuracy syntactic text taggers reached.hand see 86% accuracy basic semantic disambiguationrelatively high semantics. evidence noisy \ungrammatical"variety spoken language hurts syntax less semantics. Due domain dependencesemantic classifications dicult compare explain semantic performance.However, different study within domain railway interactions could reachsimilar performance (for details see Section 6.6). experiments syntactic resultsbetter semantic results, indicating syntactic classification easierlearn generalize. Furthermore, syntactic results close 90% noisyspoken language consider good comparison 95% regulartext language.performance abstract categories somewhat lower basic categories since evaluation word introduces unavoidable errors. instance,\in" network cannot yet know time location follow, makeearly decision already. general, networks perform relatively well dicultreal-world corpus, given eliminate sentence reason tookspontaneous sentences spoken.Furthermore, use transcripts spontaneous language training domainmeeting arrangements. utterances questions answers dateslocations. restricts potential syntactic semantic constructions, certainlybenefit restricted domain. Furthermore, mappings ambiguouslearning (e.g., noun part noun group prepositional group) mappingsrelatively unambiguous (e.g., verb part verb group). would expectperformance mixed arbitrary domains like random spoken sentencesvarious topics passers-by city. However, performance somewhatrestricted domains learned promising manner (for transfer differentdomain see Section 6.6). evidence simple recurrent networksprovide good performance using small training data restricted domain.6.4 SCREEN's Overall Output Performancedescribed individual network performance, focusperformance running system. performance running screen systemdifferent performance individual networks number reasons. First,individual networks trained separately order support modular architecture.running screen system, however, connectionist networks receive inputunderlying networks. Therefore, actual input connectionist networkrunning screen system may also differ original training test sets. Second,spoken sentences may contain errors like interjections word repairs. partindividual network training, running screen system able detectcorrect certain interjections, word corrections phrase corrections. Therefore, systemnetwork performance differ dis uencies. Third, want evaluate69fiWermter & Weberperformance abstract semantic categorization abstract syntactic categorizationparticularly interested certain sentence parts. abstract syntactic categorization,e.g., detection prepositional phrase, consider beginningphrase significant function word, e.g., preposition, importantlocation syntactic categorization. contrast, abstract semantic categorization,content word end phrase group, directly next phrase start,important.Correct syntactic output representation 74%Correct semantic output representation 72%Table 6: Overall syntactic semantic accuracy running screen systemunknown test set meeting corpusexpect based explanation previous paragraph, overall accuracy output complete running system lower performanceindividual modules. fact, true Table 6 shows overall syntacticsemantic phrase accuracy running screen system. 74% assigned syntacticphrase representations unknown test set correct 72% assigned semanticphrase representations. slight performance drop partially explaineduncertain input underlying networks uencednetworks. hand, cases various decisions different modules (e.g.three modules lexical, syntactic semantic category equality two words)combined order clean errors (e.g. wrong decision one single module).general, given 120 dialog turns test set completely unrestricted, unknown real-world spontaneous language turns, believe overall performancequite promising.6.5 SCREEN's Overall Performance Incomplete LexiconOne important property screen robustness. Therefore, interesting questionscreen would behave could receive incomplete input lexicon.situations realistic since speakers could use new words speech recognizerseen before. Furthermore, test robustness techniques. standardcontext-free parsers usually cannot provide analysis words missing lexicon,screen would break missing input representations, although courseexpect overall classification performance must drop less reliable input provided.order test situation controlled uence removing itemslexicon, first tested scenario randomly eliminated 5% syntacticsemantic lexicon representations. word unknown, screen used single syntacticsingle semantic average default vector instead. average default vector containednormalized frequency syntactic respectively semantic category across lexicon.Even without 5% lexicon entries utterances could still analyzed. screenbreak missing word representations attempts provide analysis good70fiSCREEN: Flat Syntactic Semantic Spoken Language AnalysisCorrect syntactic output representation 72%Correct semantic output representation 67%Table 7: Overall syntactic semantic accuracy running screen systemmeeting corpus unknown test set 5% lexicon entries eliminatedpossible. expected, Table 7 shows performance drop overall syntacticsemantic accuracy. However, compared 74% 72% performance completelexicon (see Table 6) still find 72% syntactic output representations 67%semantic output representations correct eliminating 5% lexicon entries.Correct syntactic output representation 70%Correct semantic output representation 67%Table 8: Overall syntactic semantic accuracy running screen systemmeeting corpus unknown test set 10% lexicon entrieseliminatedanother experiment eliminated 10% syntactic semantic lexicon entries.case, syntactic accuracy still 70% semantic accuracy 67%.Eliminating 10% lexicon led syntactic accuracy reduction 4% (74%versus 70%) semantic accuracy reduction 5% (72% versus 67%). generalsee experiments percentage accuracy reduction much lesspercentage eliminated lexicon entries demonstrating screen's robustness workingincomplete lexicon.6.6 Comparison Results New Different Domainorder compare performance techniques, also show resultsexperiments different spoken Regensburg Train Corpus. intention cannotdescribe experiments domain level detail doneBlaubeuren Meeting Corpus paper. However, provide summary orderprovide point reference comparison experiments meeting corpus.comparison serves another additional possibility judge results meetingcorpus.different domain chose 176 dialog turns railway counter. People askquestions receive answers train connections. typical utterance is: \Yes needeh sleeping car PAUSE PAUSE Regensburg Hamburg". used exactlyscreen communication architecture process spoken utterances domain:architecture used, 1/3 dialog turns used training, 2/371fiWermter & Webertesting unseen unknown utterances. syntactic processing, even used exactlynetwork structure, since expect much syntactic differencestwo domains. semantic processing retrained semantic networks. Differentcategories used semantic classification, particular actions. actionsmeetings (e.g., visit, meet) predominant meeting corpus, actionsselecting connections (e.g., choose, select) important train corpus (Wermter &Weber, 1996b). give reader impression portability screen,would estimate 90% original human effort (system architecture, networks) couldused new domain. remaining 10% needed necessary newsemantic tagging training new domain.ModuleAccuracy test setbas-syn-dis93%bas-sem-dis84%abs-syn-cat85%abs-sem-cat77%phrase-start89%word-error94%phrase-error98%Table 9: Performance individual networks test set train corpusTable 9 shows performance test set train corpus. compareresults meeting corpus (Table 5) results train corpus seeparticular abstract syntactic processing almost meeting corpus(84% Table 5 compared 85% Table 9) abstract semantic processing bettermeeting corpus (83% Table 5 compared 77% Table 9). modules dealingexplicit robustness repairs (phrase start, word repair errors, phrase repair errors)show almost performance (90% vs 89%, 94% vs 94%, 98% vs 98%).Correct syntactic output representation 76%Correct semantic output representation 64%Table 10: Overall syntactic semantic accuracy running screen systemunknown test set different train corpuscomparison summarize overall performance different traindomain. Table 10 shows screen syntactic performance twodomains (compare Table 6). different domain essentially confirmprevious results syntactic processing performance (74% vs. 76%). However, semanticprocessing appears harder train domain since performance 64% lower72% meeting domain. However, semantic processing, semantic taggingsemantic classification often found much harder syntactic processing general,72fiSCREEN: Flat Syntactic Semantic Spoken Language Analysisdifference still within range usual performance differences syntaxsemantics. Since semantic categories like agents, locations, time expressionstwo domains dicult action categorization mainly responsibledifference semantic performance two domains.general transfer one domain another requires limited amounthand-modeling. course, syntactic semantic categories specifiedlexicon transcripts. syntactically semantically tagged transcript sentencesdirect basis generating training sets networks. Generatingtrainings sets main manual effort transferring system new domain.generation training sets performed training networksproceed automatically. training typical single recurrent network takesorder hours. much less manual work required transferring standardsymbolic parser new domain generating new syntactic semantic grammar.6.7 Illustrative Comparison Argument Based Symbolic Parsermade point screen's learned representations robusthand-coded deeply structured representations. would like elaborate pointcompelling illustrative argument. Consider different variations sentence hypothesesspeech recognizer Figure 19: 1. correct sentence hypothesis: \Am sechstenApril bin ich auer Hause" (\On 6th April home") 2. partially incorrect1.Input: SECHSTEN APRIL BIN ICH AUER HAUSE(ON 6th APRIL HOME)1.Output:PP,!VPNPNPNGNGRPPVNPADJGNUADJam(on)sechsten(6th)April(April)RNGNbin(am)2.Input: SECHSTEN APRIL ICH ICH AUER HAUS(ON 6th APRIL HOME)2.Output:NIL (NO ANALYSIS POSSIBLE)ich(I)auer(out_of) Hause(home),!Figure 19: Two sentence hypotheses speech recognizer. first hypothesisanalyzed, second partially incorrect hypothesis cannot analyzedanymore symbolic parser.73fiWermter & Webersentence hypothesis: \Am sechsten April ich ich auer Hause" (\On 6th Aprilhome"). Focusing syntactic analysis, used existing chart parser existinggrammar used extensively real-world parsing sentencelevel (Wermter, 1995). necessary significant adaptation addition ruleN G ! U pronouns, part original grammar. rule statespronoun U (e.g., \I") noun group (NG).run first sentence hypothesis symbolic context-free parser receive desired syntactic analysis shown Figure 19, run second slightlyincorrect sentence hypothesis parser receive analysis (The syntactic category abbreviations Figure 19 used manner throughoutpaper (see Table 1-4); furthermore usual, \S" stands sentence, \ADJG" adjective group, \NP" complex nominal phrase, \VP" verb phrase. literal Englishtranslations shown brackets).reason second sentence hypothesis could parsed context-freechart parser speech recognizer generated incorrect output. verbsecond sentence hypothesis additional pronoun \I". mistakesoccur rather frequently based imperfectness current speech recognition technology.course one could argue grammar relaxed made exibledeal mistakes. However, rules fault detection integratedgrammar parser complicated grammar parser. Evenimportant, impossible predict possible mistakes integrate symboliccontext-free grammar. Finally, relaxing grammar dealing mistakes usingexplicit specific rules also might lead additional mistakes grammarextremely underspecified.shown, instance Figure 17, screen problems dealingspeech recognizer variations mistakes. main difference standardcontext-free symbolic chart parser analysis screen's analysis screen learnedprovide analysis noisy conditions context-free parser handcoded provide structural analysis. emphasizedmake argument structural representations per se general.structure provided better, particularly tasks require structuredworld knowledge. However, robustness major concern, lower syntacticsemantic spoken-language analysis, learned analysis provides robustness.6.8 Comparisons Related Hybrid SystemsRecently, connectionist networks received lot attention computational learningmechanisms written language processing (Reilly & Sharkey, 1992; Miikkulainen, 1993;Feldman, 1993; Barnden & Holyoak, 1994; Wermter, 1995). paper however,focused examination hybrid connectionist techniques spoken language processing. previous approaches speech/language processing processing oftensequential. is, one module like speech recognizer syntactic analyzer completed work next module like semantic analyzer started work. contrast,screen works incrementally allows system (1) modules running par74fiSCREEN: Flat Syntactic Semantic Spoken Language Analysisallel, (2) integrate knowledge sources early, (3) compute analysissimilar humans since humans start process sentences may completed.compare approach related work systems. head-to-head comparison different system dicult based different computer environmentswhether systems accessed adapted easily input. Furthermore,different systems typically used different purposes different language corpora,grammars, rules, etc. However, made extensive effort fair conceptualcomparison.parsec (Jain, 1991) hybrid connectionist system embedded largerspeech translation effort janus (Waibel et al., 1992). input parsec sentences,output case role representations. system consists several connectionist modulesassociated symbolic transformation rules providing transformations suggestedconnectionist networks. parsec's philosophy use connectionist networkstriggering symbolic transformations, screen uses connectionist networks transformations themselves. screen's philosophy use connectionist networks whereverpossible symbolic rules necessary.found symbolic processing particularly useful simple known tests (like lexicalequality) complex control tasks whole system (when module communicate module). Much actual transformational work donetrained connectionist networks. contrast design philosophy parsecconnectionist modules provide control knowledge transformationperformed. selected transformation actually performed symbolic procedure. screen uses connectionist modules transformations symbolic control,parsec uses connectionist modules control symbolic procedures transformations.Different screen, parsec receives sentence hypotheses either sentence transcripts N-best hypotheses janus system. approach receives incrementalword hypotheses used speech construction part build sentence hypotheses. part also used prune hypothesis space determine best sentencehypotheses. analysis screen semantic syntactic plausibilitiespartial sentence hypothesis still uence partial sentence hypothesesprocessed.parsec screen modular architecture tested advantageconnectionist module learn relatively easy subtask. contrastdevelopment parsec experience modularity requires less training time.Furthermore, modules screen able work independentlyparallel. addition syntactic semantic knowledge, parsec make useprosodic knowledge screen currently use prosodic hints. hand,screen also contains modules learning dialog act assignment modulescurrently part parsec. Learning dialog act processing important determiningintended meaning utterance (Wermter & Lochel, 1996).Recent extensions based parsec provide structure use annotatedlinguistic features (Bu et al., 1994). authors state \implemented (basedparsec) connectionist system" approximate shift reduce parser.connectionist shift-reduce parser substantially differs original parsec architecture.75fiWermter & Weberrefer \parsec extension". parsec extension labels completesentence first level categories. first level categories inputnetwork order provide second level categories complete sentenceon, highest level sentence symbol added.Using recursion step parsec extension provide deeper structuralinterpretations screen currently does. However, recursion step construction structure also price. First, labels like NP noun phrasedefined lexical items lexicon. Second, important, complete utterancelabeled n-th level categories processing n+1-th level categoriesstarts. Therefore several parses (e.g., 7 utterance \his big brother loved himself")utterance necessary. means recent parsec extensionpowerful screen original parsec system Jain respect opportunity provide deeper structural interpretations. However, timeparsec extension looses possibility process utterances incremental manner.However, incrementality important property spoken-language processingscreen. Besides fact humans process language incremental left-to-rightmanner, also allows screen prune search space incoming word hypothesesearly.Comparing parsec screen, parsec aims supporting symbolic rules using symbolic transformations (triggered connectionist networks) integrating linguistic features. Currently, linguistic features recent parsec extension (Bu et al.,1994) provide structural morphological knowledge screen does. Therefore,currently appears easier integrate parsec extension larger systemshigh level linguistic processing. fact, parsec used context janusframework. hand, screen aims robust incremental processingusing word hypothesis space, specific repair modules, representations.particular, screen emphasizes robustness spoken-language processing, sincecontains explicit repair mechanisms implicit robustness. Explicit robustness coversoften occurring errors (interjections, pauses, word phrase repairs) explicit modules,less predictable types errors supported implicit similaritybased robustness connectionist networks themselves. general, representations generated extension parsec provide better support deeper structuresscreen, screen provides better support incremental robust processing.recent extension based parsec called feaspar, overall parsing performancesyntactic semantic feature accuracy 33.8%. Although additional improvementsshown using subsequent search techniques parsing results, considersubsequent search techniques better parses since would violate incrementalprocessing (Bu, 1996). Without using subsequent search techniques screen reachesoverall semantic syntactic accuracy 72% 74% shown Table 6. Howeverpointed out, screen feaspar use different input sentences, featuresarchitectures.Besides parsec also berp trains systems focus hybrid spoken-language processing. berp (Berkeley Restaurant Project) current project employs multipledifferent representations speech/language analysis (Wooters, 1993; Jurafsky et al., 1994,1994b). task berp act knowledge consultant giving advice choos76fiSCREEN: Flat Syntactic Semantic Spoken Language Analysising restaurants. different components berp: feature extractor receivesdigitized acoustic data extracts features. features used connectionist phonetic probability estimation. output connectionist feedforward networkused Viterbi decoder uses multiple pronunciation lexicon different language models (e.g. bigram, hand-coded grammar rules). output decoder wordstrings transformed database queries stochastic chart parser. Finally,dialog manager controls dialog user ask questions.berp screen common ability deal errors humansspeech recognizer well relatively analysis. However, reaching robustness berp probabilistic chart parser used compute possible fragments first.Then, additional fragment combination algorithm used combining fragmentscover greatest number input words. Different sequential processfirst computing fragments utterance combining fragments, screenuses incremental processing desirably provides best possible interpretation.sense screen's language analysis weaker general. screen's analysis neverbreak produce best possible interpretation noisy utterances. strategymay particularly useful incremental translation. hand, berp's languageanalysis stronger restricted. berp's analysis may stop fragment levelcontradictory fragments. strategy may particularly useful questionanswering additional world knowledge necessary available.trains related spoken-language project building planning assistantreason time, actions, events (Allen, 1995; Allen et al., 1995).goal building general framework natural language processing planningtrain scheduling, trains needs lot commonsense knowledge. scenario, personinteracts system order find solutions train scheduling cooperativemanner. person assumed know goals schedulingsystem supposed details domain. utterance personparsed syntactic semantic parser. linguistic reasoning completedmodules scoping reference resolution. linguistic reasoning, conversationacts determined system dialog manager responses generated basedtemplate-driven natural language generator. Performance phenomena spoken languagelike repairs false starts currently dealt already (Heeman & Allen, 1994b,1994a). Compared screen, trains project focuses processing spokenlanguage in-depth planning level. screen uses primarily connectionistlanguage analysis, trains uses chart parser generalized phrase structure grammar.7. DiscussionFirst focus learned processing spoken-language processing.started screen project, predetermined whether deep analysisscreening analysis would particularly appropriate robust analysis spokensentences. deep analysis highly structured representations less appropriate sinceunpredictable faulty variations spoken language limit usefulness deep structured knowledge representations much case written language. Deepinterpretations structured representations - instance possible HPSG77fiWermter & Webergrammars text processing - make great deal assumptions predictionshold faulty spoken language. Furthermore, learned generatingsemantic syntactic representation even need use deep interpretationcertain tasks. instance, translating two languages necessarydisambiguate prepositional phrase attachment ambiguities since processtranslation disambiguations may get ambiguous target language.However, use structure level words phrases syntax semantics respectively. learned single semantics level rather foursyntax semantics levels sucient since syntax necessary detecting phraseboundaries. One could argue one syntactic abstract phrase representation oneabstract semantic phrase representation may enough. However, found basicsyntactic semantic representations word level make task easier subsequent abstract analysis phrase level. Furthermore, basic syntactic semanticrepresentations necessary tasks well, instance judgmentplausibility sequence syntactic semantic categories. plausibility usedfilter finding good word hypothesis sequences. Therefore, argue processingfaulty spoken language - task like sentence translation question answering -need much less structured representations typically used well-known parsersneed structured representations single-level tagger.previous work made early experiences related connectionistnetworks analyzing text phrases. Moving analyzing text phrases analyzing unrestricted spoken utterances, tremendous differences two tasks. foundphrase-oriented analysis used scan (Wermter, 1995) advantageous principlespoken-language analysis phrase-oriented analysis common learning textspeech processing. However, learned spoken-language analysis needs muchsophisticated architecture. particular, since spoken language contains many unpredictable errors variations, fault tolerance robustness much important.Connectionist networks inherent implicit robustness based similarity-basedprocessing gradual numerical representations. addition, found classesrelatively often occurring mistakes, explicit robustness providedmachinery interjections, word phrase repairs. Furthermore, architectureconsider processing potentially large number competing word hypothesissequences rather single sentence phrase text processing.Now, focus learned connectionist hybrid architectures. beginning predetermine whether connectionist methods wouldparticularly useful control individual modules both. However, development screen system became clear general taskspoken language understanding, individual subtasks like syntactic analysisfault-tolerant \noise" spoken language, due humans speechrecognizers well. Especially unforeseeable variations often occur spontaneously spokenlanguage cannot predefined well advance symbolic rules general manner.fault-tolerance task level could supported particularly well inherentfault-tolerance connectionist networks individual tasks support inductivelearning algorithms. learned robust understanding spoken-languageconnectionist networks particularly effective within individual subtasks.78fiSCREEN: Flat Syntactic Semantic Spoken Language Analysisquite lot work control connectionist networks. However,many cases approaches concentrated control single networks.recently work control modular architectures (Sumida, 1991;Jacobs et al., 1991b; Jain, 1991; Jordan & Jacobs, 1992; Miikkulainen, 1996). instance,approach Jacobs Jordan (Jacobs et al., 1991b; Jordan & Jacobs, 1992), taskknowledge control knowledge learned both. Task knowledge learned individualtask networks, higher control networks responsible learning single tasknetwork responsible producing output. Originally open question whetherconnectionist control would possible processing spoken language. automaticmodular task decomposition (Jacobs et al., 1991a) done simple forms functionapproximation, complex problems like understanding spoken language real-worldenvironments still need designer-based modular task decomposition necessary tasks.learned connectionist control architecture lot modulessubtasks currently seems beyond capabilities current connectionist networks.shown connectionist control possible limited number connectionist modules (Miikkulainen, 1996; Jain, 1991). instance Miikkulainen showsconnectionist segmenter connectionist stack control parser analyze embedded clauses. However, communication paths still restricted withinthree modules. Especially real-world system spoken-language understanding speech, syntax, semantics dialog processing translation extremelydicult learn coordinate different activities, especially large parallel streamword hypothesis sequences. believe may possible future, howevercurrently connectionist control screen restricted detection certain hesitationsphenomena like corrections.Considering screening analysis spoken language hybrid connectionist techniques together, developed followed general guideline (or design philosophy )using little knowledge necessary getting far possible using connectionistnetworks wherever possible symbolic representations necessary. guidelineled us (1) robust representation spoken-language analysis (2)use hybrid connectionist techniques support task choice possiblyappropriate knowledge structure. Many hybrid systems contain small portionconnectionist representations addition many modules, e.g. berp (Wooters,1993; Jurafsky et al., 1994, 1994b), janus (Waibel et al., 1992), trains (Allen, 1995; Allenet al., 1995). contrast, important subtasks screen performed directlymany connectionist networks.Furthermore, learned syntactic semantic representations could givesurprisingly good training test results trained tested medium corpus2300 words 184 dialog turns. good results mostly duelearned internal weight representation local context adds sequentialitycategory assignments. Without internal weight representation preceding contextsyntactic semantic categorization perform equally well, choicerecurrent networks crucial many sequential category assignments. Thereforenetworks techniques hold potential especially medium-size domainsrestricted amount training material available. statistical techniques often79fiWermter & Weberused large data sets, work well medium data sets, connectionisttechniques used work well medium-size domains.used techniques ported different domains used different purposes. Even different sets categories would used learning networksable extract syntactic regularities automatically. Besides domain arrangingbusiness meetings also ported screen domain interactions railwaycounter comparable syntactic semantic results. two domains differed primarily semantic categories, syntactic categories (and networks) screencould used directly.screen potential scaling up. fact, based imperfect outputspeech recognizer, several thousand sentence hypotheses already processed.new words processed, syntactic semantic basic categories simplyentered lexicon. structure individual networks change, new unitsadded therefore networks retrained.amount hand-coding restricted primarily symbolic control moduleinteraction labeling training material individual networks.changed domain railway counter interactions, could use identical control,well syntactic networks. semantic networks retrained duedifferent domain.far focused supervised learning simple recurrent networks feedforward networks. Supervised learning still requires training set manual labelingwork still done. Although especially medium size corpora labeling exampleseasier instance designing complete rule bases would nice automateknowledge acquisition even further. Currently plan build sophisticated lexicon component provide support automatic lexicon design (Riloff, 1993)dynamic lexicon entry determination using local context (Miikkulainen, 1993).Furthermore, screen could expanded speech construction evaluationpart. syntactic semantic hypotheses could used interactionspeech recognizer. Currently syntactic semantic hypotheses speech evaluationpart used exclude unlikely word hypothesis sequences language modules.However, hypotheses connectionist networks syntax semantics -particular modules basic syntactic semantic category prediction - could alsoused directly process recognition future order providesyntactic semantic feedback speech recognizer early stage. Besides syntaxsemantics, cue phrases, stress intonation could provide additional knowledgespeech/language processing (Hirschberg, 1993; Gupta & Touretzky, 1994). issuesadditional major efforts future.8. Conclusionsdescribed underlying principles, implemented architecture, evaluation new screening approach learning analysis spoken language. workmakes number original contributions fields artificial intelligence advancesstate art several perspectives: perspective symbolic connectionist design argue hybrid solution, connectionist networks used80fiSCREEN: Flat Syntactic Semantic Spoken Language Analysiswherever useful symbolic processing used control higher level analysis. Furthermore, shown recurrent networks provided better syntacticsemantic prediction results 1-5 grams. perspective connectionist networksalone, demonstrated connectionist networks fact used real-worldspoken-language analysis. perspective natural language processing arguehybrid system design advantageous integrating speech language since lowerspeech-related processing supported fault-tolerant learning connectionist networkshigher processing control supported symbolic knowledge structures. general, properties support parallel rather sequential, learned rather coded,fault-tolerant rather strict processing spoken language.main result paper learned representations support robust processing spoken language better in-depth structured representations connectionist networks provide fault-tolerance reach robustness. Due noisespontaneous language (interjections, pauses, repairs, repetitions, false starts, ungrammaticalities, also additional false word hypotheses speech recognizer) complex structured possibly recursive representations often cannot computed using standard symbolicrepresentations like context-free parsers. hand, tasks like informationextraction spoken language may need in-depth structured representation. believe hybrid connectionist techniques considerable potentialtasks, instance information extraction restricted noisy spoken-language domains. in-depth understanding like inferencing story interpretation needscomplex structured representations, shallow understanding instance informationextraction noisy speech language environments benefit at, robust learnedrepresentations.Acknowledgementsresearch funded German Federal Ministry Research Technology(BMBF) Grant #01IV101A0 German Research Association (DFG)Grant DFG Ha 1026/6-3, Grant DFG 1468/4-1. would like thank S. Haack,M. Lochel, M. Meurer, U. Sauerland, M. Schrattenholzer work screen;well David Bean, Alexandra Klein, Steven Minton, Johanna Moore, Ellen Riloff fiveanonymous referees comments earlier versions paper.ReferencesAllen, J. F. (1995). TRAINS-95 parsing system: user's manual. Tech. rep. TRAINSTN 95-1, University Rochester, Computer Science Department.Allen, J. F., Schubert, L. K., Ferguson, G., Heeman, P., Hwang, C. H., Kato, T., Light,M., Martin, N. G., Miller, B. W., Poesio, M., & Traum, D. R. (1995). TRAINSproject: case study building conversational planning agent. Journal Experimental Theoretical AI, 7, 7{48.81fiWermter & WeberBarnden, J. A., & Holyoak, K. J. (Eds.). (1994). Advances Connectionist NeuralComputation Theory, Vol. 3., Ablex Publishing Corporation.Bu, F. D. (1996). FeasPar - Feature Structure Parser Learning Parse SpontaneousSpeech. Ph.D. thesis, University Karlsruhe, Karlsruhe, FRG.Bu, F. D., Polzin, T. S., & Waibel, A. (1994). Learning complex output representationsconnectionist parsing spoken language. Proceedings International Conference Acoustics, Speech Signal Processing, Vol. 1, pp. 365{368, Adelaide,Australia.Charniak, E. (1993). Statistical Language Learning. MIT Press, Cambridge, MA.Dyer, M. G. (1983). In-Depth Understanding: Computer Model Integrated ProcessingNarrative Comprehension. MIT Press, Cambridge, MA.Elman, J. L. (1990). Finding structure time. Cognitive Science, 14 (2), 179{211.Faisal, K. A., & Kwasny, S. C. (1990). Design hybrid deterministic parser. Proceedings 13 th International Conference Computational Linguistics, pp. 11{16,Helsinki, Finnland.Feldman, J. A. (1993). Structured connectionist models language learning. ArtificialIntelligence Review, 7 (5), 301{312.Geutner, P., Suhm, B., Bu, F.-D., Kemp, T., Mayfield, L., McNair, A. E., Rogina, I.,Schultz, T., Sloboda, T., Ward, W., Woszczyna, M., & Waibel, A. (1996). Integratingdifferent learning approaches multilingual spoken language translation system.Wermter, S., Riloff, E., & Scheler, G. (Eds.), Connectionist, Statistical Symbolic Approaches Learning Natural Language Processing, pp. 117{131, Springer,Heidelberg.Gupta, P., & Touretzky, D. S. (1994). Connectionist models linguistic theory: Investigations stress systems language. Cognitive Science, 18 (1), 1{50.Hauenstein, A., & Weber, H. H. (1994). investigation tightly coupled time synchronousspeech language interfaces using unification grammar. Proceedings 12thNational Conference Artificial Intelligence Workshop Integration NaturalLanguage Speech Processing, pp. 42{49, Seattle, Washington.Heeman, P. A., & Allen, J. (1994a). Detecting correcting speech repairs. Proceedings32nd Annual Meeting Association Computational Linguistics, pp. 295{302, Las Cruces, NM.Heeman, P. A., & Allen, J. (1994b). Tagging speech repairs. Proceedings HumanLanguage Technology Workshop, pp. 187{192, Plainsboro, NJ.Hendler, J. A. (1989). Marker-passing microfeatures: Towards hybrid symbolic/connectionist model. Cognitive Science, 13 (1), 79{106.82fiSCREEN: Flat Syntactic Semantic Spoken Language AnalysisHirschberg, J. (1993). Pitch accent context: Predicting intonational prominencetext. Artificial Intelligence, 63, 305{340.Jacobs, R. A., Jordan, M. I., & Barto, A. G. (1991a). Task decomposition competition modular connectionist architecture: vision tasks.Cognitive Science, 15, 219{250.Jacobs, R. A., Jordan, M. I., Nowlan, S. J., & Hinton, G. E. (1991b). Adaptive mixtureslocal experts. Neural Computation, 3 (1), 79{87.Jain, A. N. (1991). Parsing complex sentences structured connectionist networks.Neural Computation, 3 (1), 110{120.Jordan, M. I., & Jacobs, R. A. (1992). Hierarchies adaptive experts. Moody, J. E.,Hanson, S. J., & Lippmann, R. R. (Eds.), Advances Neural Information ProcessingSystems 4, pp. 985{992, Morgan Kaufmann, San Mateo, CA.Jurafsky, D., Wooters, C., Tajchman, G., Segal, J., Stolcke, A., Fosler, E., & Morgan,N. (1994a). Berkeley Restaurant Project. Proceedings InternationalConference Speech Language Processing. pp. 2139-2142, Yokohama, Japan.Jurafsky, D., Wooters, C., Tajchman, G., Segal, J., Stolcke, A., & Morgan, N. (1994b). Integrating experimental models syntax, phonology, accent/dialect speech recognizer. investigation tightly coupled time synchronous speech. Proceedings12th National Conference Artificial Intelligence Workshop IntegrationNatural Language Speech Processing, pp. 107{115, Seattle, Washington.Medsker, L. R. (1994). Hybrid Neural Network Expert Systems. Kluwer AcademicPublishers, Boston.Mellish, C. S. (1989). chart-based techniques parsing ill-formed input. Proceedings 27th Annual Meeting Association Computational Linguistics, pp.102{109, Vancouver, Canada.Menzel, W. (1994). Parsing spoken language time constraints. Cohn, A. G.(Ed.), Proceedings 11th European Conference Artificial Intelligence, pp. 561{564, Amsterdam.Miikkulainen, R. (1993). Subsymbolic Natural Language Processing. integrated modelscripts, lexicon memory. MIT Press, Cambridge, MA.Miikkulainen, R. (1996). Subsymbolic case-role analysis sentences embedded clauses.Cognitive Science, 20, 47{73.Nakatani, C., & Hirschberg, J. (1993). speech-first model repair detection correction. Proceedings 31st Annual Meeting Association ComputationalLinguistics, pp. 46{53 Columbus, Ohio.Reilly, R. G., & Sharkey, N. E. (Eds.). (1992). Connectionist Approaches Natural Language Processing. Lawrence Erlbaum Associates, Hillsdale, NJ.83fiWermter & WeberRiloff, E. (1993). Automatically constructing dictionary information extraction tasks.Proceedings 11th National Conference Artificial Intelligence, pp. 811{816,Washington, DC.Rumelhart, D. E., Hinton, G. E., & Williams, R. J. (1986). Learning internal representations error propagation. Rumelhart, D. E., McClelland, J. L., & PDPresearch group (Eds.), Parallel Distributed Processing, Vol. 1., pp. 318{362. MIT Press,Cambridge, MA.Sauerland, U. (1996). Konzeption und Implementierung einer Speech/LanguageSchnittstelle. Master's thesis, University Hamburg, Computer Science Department,Hamburg, FRG.Sumida, R. A. (1991). Dynamic inferencing parallel distributed semantic networks.Proceedings 13th Annual Meeting Cognitive Science Society, pp. 913{917,Boston, Chicago.Sun, R. (1994). Integrating Rules Connectionism Robust Common Sense Reasoning.Wiley Sons, New York.von Hahn, W., & Pyka, C. (1992). System architectures speech understandinglanguage processing. Heyer, G., & Haugeneder, H. (Eds.), Applied Linguistics.Wiesbaden.Waibel, A., Jain, A. N., McNair, A., Tebelskis, J., Osterholtz, L., Saito, H., Schmidbauer,O., Sloboda, T., & Woszczyna, M. (1992). JANUS: Speech-to-speech translation usingconnectionist non-connectionist techniques. Moody, J. E., Hanson, S. J., &Lippmann, R. R. (Eds.), Advances Neural Information Processing Systems 4, pp.183{190, Morgan Kaufmann, San Mateo, CA.Ward, N. (1994). approach tightly-coupled syntactic/semantic processing speechunderstanding. Proceedings 12th National Conference Artificial Intelligence Workshop Integration Natural Language Speech Processing, pp.50{57, Seattle, Washington.Weber, V., & Wermter, S. (1995). Towards learning semantics spontaneous dialog utterances hybrid framework. Hallam, J. (Ed.), Hybrid Problems, Hybrid Solutions| Proceedings 10th Biennial Conference AI Cognitive Science, pp.229{238, Sheeld, UK.Weber, V., & Wermter, S. (1996). Artificial neural networks repairing language.Proceedings 8th International Conference Neural Networks Applications, pp. 117{123, Marseille, FRA.Wermter, S., & Weber, V. (1996a). Interactive spoken-language processing hybridconnectionist system. IEEE Computer { Theme Issue Interactive Natural LanguageProcessing, July, 65{74.84fiSCREEN: Flat Syntactic Semantic Spoken Language AnalysisWermter, S. (1994). Hybride symbolische und subsymbolische Verarbeitung Beispielder Sprachverarbeitung. Duwe, I., Kurfe, F., Paa, G., & Vogel, S. (Eds.),Herbstschule Konnektionismus und Neuronale Netze. Gesellschaft fur Mathematik undDatenverarbeitung (GMD), Sankt Augustin, FRG.Wermter, S. (1995). Hybrid Connectionist Natural Language Processing. ChapmanHall, Thompson International, London, UK.Wermter, S., & Lochel, M. (1994). Connectionist learning syntactic analysisspeech/language systems. Marinaro, M., & Morasso, P. G. (Eds.), ProceedingsInternational Conference Artificial Neural Networks, Vol. 2, pp. 941{944,Sorrento, Italy.Wermter, S., & Lochel, M. (1996). Learning dialog act processing. Proceedings16th International Conference Computational Linguistics, pp. 740{745, Kopenhagen, Denmark.Wermter, S., & Peters, U. (1994). Learning incremental case assignment based modularconnectionist knowledge sources. Werbos, P., Szu, H., & Widrow, B. (Eds.), Proceedings World Congress Neural Networks, Vol. 4, pp. 538{543, San Diego,CA.Wermter, S., Riloff, E., & Scheler, G. (Eds.). (1996). Connectionist, Statistical SymbolicApproaches Learning Natural Language Processing. Springer, Berlin.Wermter, S., & Weber, V. (1996b). Artificial neural networks automatic knowledge acquisition multiple real{world language domains. Proceedings 8th International Conference Neural Networks Applications, pp. 289{296, Marseille,FRA.Wooters, C. C. (1993). Lexical modeling speaker independent speech understandingsystem. Tech. rep. TR-93-068, International Computer Science Institute, Berkeley.Young, S. R., Hauptmann, A. G., Ward, W. H., Smith, E., & Werner, P. (1989). Highlevel knowledge sources usable speech recognition systems. CommunicationsACM, 32, 183{194.85fi