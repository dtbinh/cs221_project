Journal Artificial Intelligence Research 28 (2007) 517-557

Submitted 8/06; published 4/07

Consistency Random Constraint Satisfaction Models
Yong Gao

yong.gao@ubc.ca

Irving K. Barber School Arts Sciences
University British Columbia Okanagan, Kelowna, Canada V1V 1V7

Joseph Culberson

joe@cs.ualberta.ca

Department Computing Science, University Alberta
Edmonton, Alberta, Canada T6G 2E8

Abstract
paper, study possibility designing non-trivial random CSP models
exploiting intrinsic connection structures typical-case hardness. show
constraint consistency, notion developed improve efficiency
CSP algorithms, fact key design random CSP models
interesting phase transition behavior guaranteed exponential resolution complexity
without putting much restriction parameter constraint tightness domain size
problem. propose flexible framework constructing problem instances
interesting behavior develop variety concrete methods construct specific
random CSP models enforce different levels constraint consistency.
series experimental studies interesting observations carried illustrate effectiveness introducing structural elements random instances, verify
robustness proposal, investigate features specific models based
framework highly related behavior backtracking search algorithms.

1. Introduction
tale random models constraint satisfaction problems (CSP) gives us excellent
example dramatic impact structures typical-case hardness randomlygenerated problem instances (Achlioptas et al., 1997; Gent et al., 2001; MacIntyre et al.,
1998; Molloy, 2002; Prosser, 1996; Smith, 2001). also shows study phase
transitions random models NP-complete problems indeed viable approach
understanding interplay structures efficiency search algorithms.
Unlike random Boolean satisfiability problem (SAT) structures seem
exist randomly-generated instances, algorithmically-exploitable structures exist
general random constraint satisfaction problem. chief reason
random constraint satisfaction instances uncontrolled existence multiple
nogoods within constraint generates small scale structures make instance
unsatisfiable. small scale may mean variables involved,
variables involved highly constrained local way. first example
structures existence flawed variables flawed constraints random instances
generated four classical random CSP models parameter regions
(Achlioptas et al., 1997), assuming domain size fixed. appearance flawed
variables constraints makes models trivially unsatisfiable excludes phase

c
2007
AI Access Foundation. rights reserved.

fiGao & Culberson

transition behavior. yet another example, existence embedded easy subproblems
(Gao & Culberson, 2003), also called flowers (Molloy & Salavatipour, 2003), another
part parameter space models makes randomly-generated instances polynomially
sovable constraint consistency algorithms.
Several new models proposed overcome trivial unsatisfiability. Gent
et al. (2001) proposed flawless random binary CSP based notion flawless
conflict matrix. Instances flawless random CSP model guaranteed arcconsistent, thus suffer asymptotically problem flawed variables.
Achlioptas et al. (1997) proposed nogoods-based CSP model showed model
non-trivial asymptotic behaviors. Random CSP models (slowly) increasing
domain size also shown free problem flawed variables
interesting threshold behavior (Xu & Li, 2000; Smith, 2001; Frieze & Molloy, 2003).
proposed models guaranteed interesting phase transition
behavior (some also guaranteed generate hard instances phase transitions), fundamental relation structures typical-case hardness
randomly-generated CSP instances seriously addressed. consequence,
superficial conditions restrictions parameter constraint tightness
models frequently give (false) impression constraint tightness and/or
domain size determines behavior random CSP instances. classic binary
random CSP, constraint tightness less domain size order
phase transition. flawless random CSP true solubility phase transition
high constraint tightness, show later, still suffers embedded easy
unsatisfiable subproblems constraint tightness greater domain size.
CSP models increasing domain size, still obvious restriction possible
values constraint tightness. nogood-based CSP model, impossible
high constraint tightness without making constraint (hyper)graph dense.
paper, study possibility designing non-trivial random CSP models
exploiting intrinsic connection structures typical-case hardness.
purpose, show consistency, notion developed improve
efficiency CSP algorithms, fact key design random CSP models
interesting phase transition behaviors guaranteed exponential resolution complexity
without putting much restriction parameter constraint tightness domain
size.
Section 4 report series experimental studies. Algorithmic studies random
instances sometimes criticized model algorithms (Johnson, 2002). believe better study interaction models
algorithms. example, Section 4.2 observe double peak phenomenon
best guess suggests related (lack of) consistency enforcement algorithms
use interacting degree consistency enforced instances various
models. propose flexible framework constructing problem instances interesting behavior develop variety concrete methods construct specific random
CSP models enforce different levels constraint consistency. hope framework
useful helping researchers construct pseudo-random instances exhibiting various
kinds structure, avoiding trivialities sometimes tainted claimed results

518

fiConsistency Random CSPs

past, may cause algorithm design become focused particular
structure detriment general application.

2. Random Models CSPs
Throughout paper, consider binary CSPs defined domain |D| = d.
binary CSP C consists set variables x = {x1 , , xn } set binary constraints
{C1 , , Cm }. constraint Ci specified constraint scope, pair variables
x, constraint relation RCi defines set incompatible value-tuples
scope variables. incompatible value-tuple also called restriction, nogood.
Associated binary CSP constraint graph whose vertices correspond set
variables whose edges correspond set constraint scopes. Throughout
discussion, assume domain size fixed constant. rest paper,
using following notation:
1. n, number variables;
2. m, number constraints;
3. d, domain size;
4. t, constraint tightness, i.e., size restriction set.
Given two variables, constraint relation specified 0-1 matrix, called
conflict matrix, entry 0 (i, j) indicates tuple (i, j)
incompatible. Another way describe constraint relation use compatibility
graph, bipartite graph domain variable independent part,
edge signifies corresponding value-tuple compatible.
define generic model generating random binary CSPs. Recall
relation set ordered pairs.
d,t
Definition 2.1. (Bn,m
[L], Restricted Random Binary CSP) Let d, t, n, integers
specified above, variables share common domain = {1, . . . , d}, let L =
d,t
{L1 , L2 , . . . | Li D} set relations. Bn,m
[L] random CSP model

1. constraint graph standard random graph G(n, m) edges
graph selected uniformly random possible n2 edges;
2. edge G(n, m), constraint relation corresponding scope variables
specified follows:
(a) Choose random relation L L.
(b) Choose value-tuples \ L uniformly random nogood set.
definition, typically want add condition set L satisfies
\
(a, a)
/
Li , D.
i1

519

fiGao & Culberson

condition met, instances generated CSP model always
trivially satisfiable (and vacuously exponential resolution complexity).
d,t
mild, sufficient, condition make sure Bn,m
[L] linear solubility threshold.
particular, existing models models discussed present
paper satisfy condition. Appendix A.3, provide result showing
d,t
condition, constant c Bn,m
[L] m/n > c asymptotically
unsatisfiable probability one.
placing restrictions L subsume many previously existing
models well new models define shortly.
d,t
d,t
Definition 2.2. (Model B: Random Binary CSP Bn,m
) Bn,m
[L] L = {},
d,t
write Bn,m
, known literature Model B.

instance CSP said k-consistent (k 1) variables,
consistent (k 1)-tuple assignment (k 1) variables extended
consistent k-tuple assignment kth variable. CSP instance called strongly
k-consistent j-consistent j k. special interest
strong-k-consistencies k = 1, 2, 3, also known node-consistency, arc-consistency,
path-consistency (Mackworth, 1977).
d,t
restrictions construction constraint.
Note Bn,m
d,t
shown Bn,m asymptotically trivial unsatisfiable d, phase
transition satisfiability probability < (Achlioptas et al., 1997; Gent et al., 2001).
Basically, trivial cases arise asymptotically high probability
variable values forbidden due constraints containing
arc-consistent. motivates introduction flawless conflict matrix make
sure random model arc-consistent (Gent et al., 2001).
d,t
d,t
Definition 2.3. (Flawless Random Binary CSP Bn,m
[M]) Bn,m
[L] L L
d,t
bijection, L : D, write Bn,m
[M]. flawless random binary CSP
defined Gent et al. (2001).

notation reference matchings. use construction
generalized flawless random binary CSPs present Section 3.2, restrict
underlying graphs matchings, reduces flawless model.
specifying bijections create set tuples one D.
considered choosing incompatible value-tuples, resulting
model guaranteed arc-consistent consequently flawed variables.
d,t
However, even though flawless random binary CSP Bn,m
[M] suffer
d,t
problem trivial unsatisfiability, shown Bn,m
[M] may asymptotically
embedded easy subproblems 1.

Theorem 2.1. 1, constant c > 0
n > c , high
d,t
probability Bn,m
[M] asymptotically unsatisfiable solved polynomial time.

Proof. outline proof provide detailed proof Appendix A.1. idea
d,t
show sufficiently high
n , Bn,m [M] contains structures (sub-instances) (1)
cause unsatisfiability whole instance (2) detected polynomial time.
520

fiConsistency Random CSPs

One structure so-called flower consisting collection forbidden constraint
cycles explain below.
binary constraint two variables x1 x2 said contain (, )-forcer
assignment x1 = , compatible assignment x2 x2 = . Consider
CSP instance. Let {x0 , x1 , , xr1 } subset r variables domain value.
Suppose cycle constraints
C1 (x0 , x1 ), C2 (x1 , x2 ), . . . , Cr1 (xr2 , xr1 ), Cr (xr1 , x0 )
C1 (x0 , x1 ) contains (, 1 )-forcer, Ci (xi1 , xi ) contains (i1 , )-forcer,
Cr (xr1 , x0 ) contains (r1 , )-forcer 6= . Then, assignment x0 =
cannot used satisfying assignment. call cycle constraints forbidden
cycle (for variable x0 domain value ). Now, (the domain size)
forbidden cycles variable x0 , one domain value, CSP instance
satisfiable since none domain values satisfying assignment. call
variable together forbidden cycles flower.
Using second-moment method, shown constant c
d,t


n > c , probability Bn,m [M] contains flower asymptotically one.
d,t

So, high probability, Bn,m
[M] unsatisfiable
n > c . Furthermore, binary
CSP instance contains flower, path-consistency algorithm (e.g., Mackworth,
1977) produce new CSP instance variable flower empty
domain. Therefore, CSP instance embedded flower sub-instance solved
polynomial time.
d,t
noted Bn,m
[M] non-trivial phase transition since
1
satisfiable high probability
n < 2 . Theorem 2.1 exclude possibility
d,t

[M] able generate hard instances
Bn,m
n upper bound c ,
particular case large domain size. investigation required fully
d,t
understand complexity Bn,m
[M] regard.

3. Consistency, Resolution Complexity, Better Random CSP Models
Propositional resolution complexity deals minimum length resolution proofs
(unsatisfiable) CNF formula. many backtracking-style complete algorithms
simulated resolution proof, resolution complexity provides immediate lower
bound running time algorithms. Since work Chvatal Szemeredi
(1988), many studies resolution complexity randomly-generated
CNF formulas (Beame et al., 1998; Achlioptas et al., 2001).
Mitchell (2002b) developed framework notion resolution complexity
generalized CSPs resolution complexity randomly-generated random CSPs
studied. framework, resolution complexity CSP instance defined
resolution complexity natural CNF encoding give below. Given
instance CSP set variables {x1 , , xn } domain = {1, 2, , d},
CNF encoding constructed follows:
1. variable xi , Boolean variables xi : 1, xi : 2, . . . , xi :
indicates whether xi takes corresponding domain value.
521

fiGao & Culberson

clause xi : 1 xi : 2 . . . xi : Boolean variables making sure xi
takes least one domain values;
2. restriction (1 , , k ) Dk constraint C(xi1 , , xik ),
clause xi1 : 1 xik : k respect restriction.
CNF encoding equivalent original CSP problem sense CSP
instance satisfiable CNF encoding satisfiable. satisfying assignment CSP variables translates immediately satisfying assignment CNF
encoding. hand, satisfying assignment CNF encoding also
translated satisfying assignment original CSP instance. CNF assignment, one boolean variables xi : 1, xi : 2, . . . xi : assigned TRUE,
pick one assign corresponding domain value CSP
variable xi . possible add another set 2-clauses constraint variable xi
form {xi : j xi : h | 1 j < h d} ensure satisfying assignment
CNF encoding assigns unique domain value CSP variable. However,
general change complexity results, make analysis complicated.
Mitchell (2002b) well Molloy Salavatipour (2003) showed random CSPs
exponential resolution complexity constraint tightness less
d,t
certain value. random binary CSP Bn,m
, requirement (1) < 1; (2)
<

sufficiently
small.





1,
recent theoretical results (Gao & Culbern
son, 2003; Molloy & Salavatipour, 2003) indicate still possible classical
models asymptotic polynomial complexity due existence embedded easy
subproblems.
following, show necessary put restrictions constraint
tightness order guaranteed exponential resolution complexity. Based similar
arguments literature (Mitchell, 2002b; Molloy & Salavatipour, 2003; Beame,
d,t
Culberson, Mitchell, & Moore, 2005), shown Bn,m
[L], constraint
relation constraint chosen way resulting instances always
d,t
strongly 3-consistent, Bn,m
[L] exponential resolution complexity matter
large constraint tightness is.
d,t
Theorem 3.1. Let L Bn,m
[L] strongly 3-consistent. constant
d,t

n = c > 0, resolution complexity Bn,m [L] almost surely exponential.

Proof. See Appendix A.2.
Using tool developed Molloy Salavatipour (2003), requirement CSP
instances strongly 3-consistent exponential resolution complexity
relaxed. Recall constraint x1 , x2 contains (, )-forcer x1 =
consistent assignment allowed constraint x2 = .
Definition 3.1. call CSP instance weakly 4-consistent
1. arc-consistent,
2. contains forcer,

522

fiConsistency Random CSPs

3. 4 distinct variables x1 , x2 , x3 , x4 constraints C1 (x1 , x2 ), C2 (x2 , x3 ), C3 (x3 , x4 )
1 , 4 exist 2 , 3 assignment x1 = 1 , x2 =
2 , x3 = 3 , x4 = 4 consistent C1 , C2 C3 .
Note weak 4-consistency weaker strong 3-consistency since
require instance 3-consistent.
d,t
Theorem 3.2. Let L Bn,m
[L] weakly 4-consistent. constant
d,t

n = c > 0, resolution complexity Bn,m [L] almost surely exponential.

Proof. See Appendix A.2.
proofs theorems based structural properties underlying
constraint random graph CSP models relation size resolution
proof maximum size clause resolution proof. briefly discuss
key ideas proof Theorem 3.1 illustrate role constraint consistency.
First, order CSP instance exponential size proof, size minimum
unsatisfiable sub-instance (MUS) must constant. Otherwise, enumeration
partial assignments sub-instances size less MUS gives us
d,t
[L], minimum vertex degree MUS
proof polynomial size. case Bn,m
must larger 2 since 3-consistent. Due local sparseness random
graph forced assumption
n = c, minimum size MUS linear
problem size n.
Second, Ben-Sasson Wigderson (2001) shown establish exponential
lower bound resolution complexity, sufficient show resolution proof
must contain clause whose size linear problem size. Let minimum size
MUS. shown resolution proof must contain clause C
minimum size sub-instance J implies C least 2s . Since instance 3
consistent J minimal, clause C must contain one literal related
variables J whose vertex degree less 3. random graph argument shows
number variables sub-instance linear n. summary, due constraint
consistency local sparseness random constraint graph, resolution proof
must contain clause whose derivation involves linear number variables.
question remaining answered whether natural random
CSP models guaranteed strongly 3-consistent weakly 4-consistent. fact,
CSP-encoding random graph k-coloring strongly k-consistent. rest
section, discuss generate random CSPs high tightness strongly
3-consistent weakly 4-consistent.
3.1 Generalized Flawless Random Binary CSP
introduce generalized flawless model. call generalized flawless model
since requires even stronger conditions L flawless model Gent et al. (2001).
assume common domain = {1, . . . , d}, > 2.
Definition 3.2. say L SC-inducing
1. L L exist , (, ) L (, ) L
523

fiGao & Culberson

2. L1 , L2 L , exists (, ) L1 (, ) L2 .
first condition Definition 3.2 guarantees arc consistency constraint.
second condition ensures 3-consistency. Given > 2, two conditions strong
3-consistency.
Definition 3.3. say L WC-inducing
1. L L exist 1 , 2 , 1 , 2 (, 1 ), (, 2 ) L
(1 , ), (2 , ) L
2. L1 , L2 , L3 L , exist , (, ) L1 , (, ) L2
(, ) L3 .
first condition Definition 3.3 prevent forcers well enforce arc consistency, first two conditions required definition weak 4-consistency.
Definition 3.4. (Generalized Flawless Random Binary CSPs)
d,t
d,t
model Bn,m
[L] L SC-inducing write Bn,m
[SC]. L WC-inducing
d,t
write Bn,m [WC]. either case, say generate generalized flawless random
binary CSP.
d,t
[SC] strongly 3-consistent. CSP constructed
Lemma 3.3. CSP constructed Bn,m
d,t
Bn,m [WC] weakly 4-consistent.

note flawless method could generate every arc consistent
CSP (Gent et al., 2001) every SC (WC) CSP generated system.
example, constraint C variables x1 x2 respect third
variable x3 strong 3-consistency requires consistent assignment x3
pairs values compatible C. method ensures consistency every
pair values x1 , x2 independently whether constraint them.
see reasonable way produce relaxed version given constraints
generated independently G(n, m).
3.2 Constructing Consistent-Inducing Sets L
provide methods generate variety sets relations L SC-inducing
WC-inducing. Although CSP models require variables common domain,
start general construction varying domain sizes. enable
us significantly increase domain tightness larger domains. side benefit,
indicates models might adapted varying domains. However, build model
varying domain sizes would require least distinct sets L every ordered
pair distinct domains. would also complicate selection step, 2(a) Definition 2.1
well analysis. leave development models future research.
start constructing set bipartite graphs G, call core graphs.
pair domains D` Dr sizes d` = |D` |, dr = |Dr |, one
core graphs G G. graph G G form G = (V` Vr , E)
V` = {v1 , . . . , vd` } Vr = {w1 , . . . , wdr } sets vertices E V` Vr .
524

fiConsistency Random CSPs

graph G create set size kG triples form (G) = {(G, `i , ri ) | 1 kG },
`i : V` D` ri : Vr Dr bijections labeling vertices.
define = (G) = GG (G). , = (G, ` , r ), let L(T )
set pairs {(` (v), r (w)) | (v, w) E(G)}. define L = L(T ) = {L(T ) | },
set relations induced triples.
Given bipartite graph G = (V` Vr , E), define minimum degree vertex
vertex subset Vi {`, r}.
say G degree bound graph ` > d2r r > d2` .
Lemma 3.4. G degree bound T1 , T2 sharing domain = Dr1 =
D`2 , D`1 , Dr2 , exists (, ) L1 = L(T1 ), (, )
L2 = L(T2 ).
Proof. Let v = ` 1
1 () vertex G1 labeled . Since deg(v) `1 , number
pairs L1 first element must greater d2 . Similarly,
pairs L2 second element must also cover 1/2 D. Thus,
must exist (, ) L1 , (, ) L2 .
Corollary 3.5. G degree bound common domain L(T ) SC-inducing.
hard see without restricting bijections Lemma 3.4 provides best
possible result.
Lemma 3.6. degree bound arbitrary bijections ` r allowed, L(T )
may SC-inducing.
Proof. Consider two relations L1 L2 common domain graphs G1 , G2
`1 d2 r2 d2 . Let D1 D4 note neighbors vertices
labeled values cover 1/2 D. Since choose r1 `2
arbitrarily, ensure value x2 consistent x1 = , x3 = .
Consider graph domain = 9 shown Figure 1. allow arbitrary
bijections ` , r L SC-inducing, WC-inducing, reader may
readily verify. degree vertices graph = 4, less allowed
Lemma 3.4. remains WC-inducing structure graph distributes
edges uniform way.
generalize observation, assume common domain consider three constraints induced L1 , L2 , L3 built core graph set G. minimum
degree value left L1 values right L1 ,
allow arbitrary bijections, may match subset size left L2 .
Similarly, value right L3 match arbitrary set values right
L2 . ensure G generates L WC-inducing, need
arbitrary pair -sets induces least one edge G G. pair subsets fails
induce edge core graph, corresponding constraint set weakly
4-consistent.
Letting NG (v) neighbors vertex v graph G, argument generalizes
formal statement

525

fiGao & Culberson

Lemma 3.7. common domain D, G G minimum left right degree
` = r = , G generates WC-inducing
L using arbitrary bijections ` , r iff G G,
{`, r} Vi , |S| = , | vS NG (v)| > .
graph -regular every vertex degree . graph connected
path every pair vertices. Notice degree bound G G necessarily
connected. following special case G generate WC-inducing
SC-inducing L.
Corollary 3.8. Suppose common domain = 2 G
set -regular connected bipartite graphs. Let set triples generated random
pairs bijections graphs G. L(T ) WC-inducing.
Proof. Lemma 3.7, must show arbitrary subset V` |S| = ,
neighbors contain vertices. Suppose not. Note must 2
edges vertices S, distinct endpoints (there cannot fewer)
edges. follows edges neighbors,
G connected.
Lemma 3.7 used show 2 d. also follows easily G must
connected. bounds met = 4, = 2 using eight cycle illustrated
Figure 1. larger mostly leave problem optimizing research project
combinatorial design, although provide insight next section.
WC-inducing graphs shown Figure 1.
3.3 Recursive Construction
Lemmas 3.4 3.6 introduce additional restrictions bijections,
2
best tightness achieve maintaining strong 3-consistency < d2 .
require weak 4-consistency, Lemma 3.7 may allow significant improvement, although
unclear exactly much general. show increase tightness
reducing number edges graphs using recursive construction larger domains
simultaneously restricts set bijections.
Given domain partition set blocks = {1 , . . . , k } subject k 3
|j | 3, j. latter restrictions place SC-inducing graphs
pairs size two complete bipartite graphs. blocks j may vary size.
variable xi must exactly one partition domain used
construction constraints xi . problems common domain simplest
one partition common domain variables, construction
assume.
Let V = {v1 , . . . , vd }. bijection : V said respect partition
bijection : partition j, 1 j k j
(vi ) (j ). Note meet condition, must satisfy condition
|j | = | (j )| j. Thus, partitions varying sizes blocks restrict
set respectful bijections.
construct -bound graph G follows. Let V` = {v10 , . . . , vk0 } Vr =
{w10 , . . . , wk0 } sets vertices corresponding blocks partition. Let G =
(V` Vr , E ) SC-inducing graph.
526

fiConsistency Random CSPs

d=4
d=5
d=6

d=9

Figure 1: Graphs WC-inducing SC-inducing domains size 4,5,6
9. Notice = 5 minimal graph regular. boxes graph
= 9 indicate recursive construction described Section 3.3. See also
Figure 2.

assume general construction two sets vertices V` = {v1 , . . . , vd }
Vr = {w1 , . . . , wd }. edge (v, w) E construct degree bound graph Gvw =
(V` [v ] Vr [w ], Evw ), V` [v ] = {vi : v } Vr [w ] = {wi : w }. Recall
degree bound graphs work even domains differing sizes. construct
-bound graph G = (V` Vr , E) letting E = (v,w)E Evw .
Lemma 3.9. G consists -bound graphs bijections ` , r respect , L
SC-inducing.
Proof. Consider two relations L1 , L2 . Since block graphs G SC-inducing, follows
path block left graph block right
block permutations implied respectful bijections. focusing edges
bijections restricted blocks path, since induce degree bound
graphs, proof completed argument similar proof Lemma 3.4.
Figure 1 shows graph generated method = 9. (For = 3,
one minimal degree bound graph isomorphism.) Figure 2 shows construction
527

fiGao & Culberson

1

6

2

1

7

5 B C9

3

4

4

8
7 C

B 5

7

5

4

B6

5

4

6

1

7

2A 2

8

3

9

1

C 8
9

X

3

8

9

6

2

3





L1

B

C

Z
L2

Figure 2: illustration strongly 3-consistent pair constructed using 3 3 recursive
construction domain size 9. simplicity, use identity bijections
far left right. center, dashed lines represent bijection
shared domain induced r1 `2 . r1 `2 respect blocks,
rearrange values block vertex levels. highlight value 1
left vertices connected left side L2 ,
2 vertices two blocks. sufficient connect value
right.

two constraints using two copies graph. bijections respect block structure,
constraint SC-inducing.
large domains, notice may many blocks . Since G
SC-inducing, recursively use construction build G . call construction
recursive -bound construction. example, similar graph = 9 Figure 1,
see domains size = 3i recursive construction lets us use graphs
degree 2i . Thus, tightness high d2 d1+log3 2 SC-inducing graphs.

528

fiConsistency Random CSPs

note also possible recursively partition large blocks, resulting
possibly non-uniform depth recursive constructions, provided permutations block
respecting appropriate sense. leave exercise notation gets messy,
applications appear limited.
also claim without proof blocks size, make
G WC-inducing replace degree bound subgraphs WC-inducing graphs,
provided use -respecting bijections, G WC-inducing. call graphs weakly
-bound. before, recursively construct G get recursive weakly -bound
graphs. = 4i using recursion based = 4 case Figure 1, weak
4-consistency core graphs degree 2i ; is, tightness case
high d2 d3/2 .
Although increased tightness using recursive constructions,
side greatly reduce set allowed bijections. example, respect
block structure graph = 9 shown Figure 2, (3!)4 = 1296
distinct bijections either side, compared 9! = 362880 unrestricted bijections. also
note recursive constructions limited practical application since expensive
express tight constraints explicit way large domains.
3.4 Limits Tightness Complexity Tradeoffs
get even tighter constraints exponential resolution complexity? discussion
far indicates near limits using consistency inducing constructions,
need something else. following construction illustrates possible maintain
exponential complexity even higher tightness, trivial sense
really exponential linear sized embedded subproblem.
Let us embed 3-coloring domain size > 3. wish construct CSP version
k-coloring graphs, start coloring domain K = {1, . . . , k}. create one
graph G = (V` Vr , E) G, edge set E = V` Vr \ {(vi , wi ) | 1 k}. restrict
bijections ` (vi ) = i, r (wi ) = i, 1 k, refer identity bijections
identities, ` , r short. one relation L = {L(G, ` , r )}. complete
k-coloring implementation, set = k, maximum possible value t. embed
3-coloring domain size d, let G constructed 3-coloring construction
sub-domain {1, 2, 3} pad G independent vertices {vi , wi | 4 d}.
construct one triple (G, ` , r ) one relation L. set tightness
maximum possible value, = d2 6.
conjecture maximal possible tightness exponential complexity,
d,t
little relevance larger d. L, instance Bn,m
[L]
reasonable algorithm simply reduce 3-coloring, thus exhibit exponential
complexity 3-coloring threshold.
see maximizing tightness certainly consideration, probably
important. feel important consider kinds structure
one embed model, avoiding generating trivial instances. model expands
framework wherein done previous models.

529

fiGao & Culberson

3.5 Implementation Issues
experiments conducted Gao Culberson (2004) many paper
use domain size = 4 8 cycle WC-inducing graph shown Figure 1.
point experiments conducted Gao Culberson (2004) fixed
bijection ` = ` randomly assigned right hand set r . Although
adequate satisfy WC-inducing conditions, include possible L, since
example L generated way (1, ) (2, )
L. construction constraints variables ordered consistent
way, example smaller index always left side constraint,
may introduce overall asymmetry CSP.
following, report new series experiments used randomly
paired bijection approach.
best degree bound graphs, sense maximizing t,
vertices minimum possible degree, -regular graphs. purposes,
requirement graphs uniformly selected possible
graphs, hard find various techniques get variety graphs.
graphs conforming Corollary 3.8 example, one first generate cycle alternating
vertices V` , Vr choose set maximum matchings remaining
unused pairs reach required degree. found using variety
techniques, example finding 1-factorization regular bipartite graph (Bondy &
Murty, 1976, Chapter 5). one desire uniform sampling reason,
significant literature generating random regular graphs various types,
might serve starting point (Wormald, 1999).

4. Experiments
section, discuss series experiments conducted study impact
structural elements introduced generalized flawless model typical case
hardness problem instances practical size. Section 4.1, discuss experiment
Boolean 3-ary CSP model obtained widely-used random distribution CNF
formula. Section 4.2, report detailed experimental results comparison three
different random CSP models.
4.1 Randomly-generated 3-ary Boolean CSPs
observation set experiments Boolean CSPs different constraint
tightness partly motivated study interplay performance backtracking algorithms structural information seemingly structureless randomlygenerated instances. include results since provide nice illustration
effect increase constraint tightness (hence increase likelihood
existence forcer constraint) typical case hardness random CSP instances.
obtain instance distribution ternary boolean CSP, start random
3-CNF formula clause generated selecting three variables uniformly
random without replacement. clause CNF formula equivalent constraint
constraint tightness = 1 set variables. E.g., x z corresponds

530

fiConsistency Random CSPs

restriction {(0, 0, 1)}. therefore obtain random instances Boolean-valued
CSPs larger constraint tightness adding clauses defined set
variables.
Let F(n, m) random 3-CNF formula n variables clauses selected
uniformly random without replacement. construct new random 3-CNF formula
F(n, m, a) follows:
1. F(n, m, a) contains clauses F(n, m);
2. clause C F(n, m), generate random clause set variables
C, add new clause F(n, m, a) probability a.
fact, F(n, m, a) random Boolean CSP model average constraint tightness
1 + discussed Gao Culberson (2003). > 0, easy see
F(n, m, a) always strongly 2-consistent, 3-consistent asymptotically
probability 1.

Figure 3: Thresholds solution probability model F(n, m, a) n = 250.
z-axis solution probability. axis range 1.0 ... 2.0
parameter 1 + axis range 1.0 ... 6.0 clause density
m/n.
Figure 4 shows median number branches used SAT solver ZChaff
(Zhang et al., 2001) 100 instances F(n, m, a) n = 250. Figure 3 shows
solution probability model. expected, increase tightness results
shift location hardness peak toward smaller m/n. significant
magnitude decrease hardness result small increase constraint
tightness. instances hardness varies dramatically hard illustrate
difference constraint tightness values = 1.0 = 2.0 using either
original scale log scale. explains scale scheme used Figure 4.
reason dramatic change explained follows. randomly generate constraints tightness > 1 constraint, positive (fixed)
531

fiGao & Culberson

5000

3000

branches

4000

2000

1000

1
0

1.2
1.4
5.5

5

1.6
4.5

m/n

4

3.5

3

1+a

1.8
2.5

Figure 4: Effects increase constraint tightness instance hardness
F(n, m, a) n = 250. z-axis median number branches
first three highest peaks scaled 1/40, 1/10, 1/4 respectively. axis
range 1.0 ... 1.8 parameter 1 + a, 0 0.8 axis
range 2.5 ... 6 clause density m/n.

probability restriction set something {(1, 0, 0), (0, 0, 0)}.
constraint 3-consistent, partial assignment = 0, z = 0 consistent
extension x. effect, constraint induces binary constraint y, z restriction {(0, 0)}. enough constraints, induced binary constraints
create unsatisfiable subproblem, since domain also Boolean, subproblem detected polynomial time. Upper bounds m/n established
existence easy unsatisfiable subproblems F(n, m, a). example, know
upper bounds m/n F(n, m, a) exponential resolution complexity respectively 23.3 = 0.1 11.7 = 0.2 (Gao & Culberson, 2003). Since
ratio constraints variables m/n considered experiment well
bounds embedded 2SAT subproblems appear high probability, seems
impact forcers instance hardness goes beyond simply producing higlystructured 2-SAT-like embedded easy subproblems. see similar effect next
subsection non-Boolean valued CSP instances.
4.2 Random Binary CSP Models: Significance Structures
set experiments designed investigate whether introducing structural elements
enforce constraint consistency random CSPs leads significant increase
typical case hardness instances practical size. mentioned purpose
experiments compare rank relative merits solvers
used experiments. Neither intention exhaust available solvers
implementation techniques solve set problem instances.

532

fiConsistency Random CSPs

d,t
d,t
three random CSP models consider Bn,m
(the Model B), Bn,m
[M] (the
d,t
flawless model), generalized flawless model Bn,m [L] different domain size
different consistency-inducing core graphs. Randomly-generated instances models encoded CNF formulas solved SAT solver ZChaff 1 . Also included
experiments comparison ZChaff, SatZ (Li & Anbulagan, 1997) 2 ,
CSP solver based forward checking (FC) maintaining arc consistency (MAC)
static variable order3 .
looks unnatural primarily tested random CSP instances converting
SAT instances using SAT solver solve them. justified
following considerations. First, existing research resolution complexity
random CSPs carried studying resolution complexity SAT
encoding CSPs described Section 3. use encoding experiments.
Secondly, shown far complexity solving unsatisfiable CSP
instances concerned, many existing CSP algorithms efficiently simulated
resolution system corresponding SAT encodings CSPs (Mitchell, 2002a).
Experimental comparisons conducted three CSP models domain size
(d = 4, 5, 6, 9) different values constraint tightness. generalized flawless
CSP models constructed using WC-inducing core graphs described Figure 1.
next two subsections, focus results domain size = 4 9.
experiments carried machines AMD Athlon (tm) Processor (Model 3700,
Frequency 2.4GHz, Main Memory 1GB 1MB Cache) running Linux. following
setup used experiments: sample size parameter point 100;
cutoff time solvers 1800 seconds CPU time.

4.2.1 Case = 4
d,t
[WC] use experiment based WC-inducing
case = 4, Bn,m
core graph shown Figure 1, connected 2-regular bipartite graph (or 8-cycle). Note
core graph, maximum possible constraint tightness 8.
observe detailed behavior models, first fixed constraint tightness
= 6 number variables n = 500. Figure 5 plots solution probability
function ratio constraints variables three CSP models.
d,t
experimental data, observed phase transition Bn,m
[WC] much sharper
d,t
d,t 4
Bn,m
[M] Bn,m
.
d,t
importantly, instances Bn,m
[WC] phase transition clearly much harder
d,t
d,t
Bn,m Bn,m [M]. Figures 6, 7, 8 show 50th percentile, 20th
percentile, 10th percentile, 5th percentile number branches running time
seconds ZChaff solve randomly-generated CSP instances three models.
d,t
seen, instances drawn Bn,m
[WC] consistently much harder

1.
2.
3.
4.

Available http://www.princeton.edu/ chaff/zchaff.html
Available http://www.laria.u-picardie.fr/ cli/EnglishPage.html
Available http://ai.uwaterloo.ca/ vanbeek/software/software.html
reader aware model doesnt show phase transition limit (as problem size
approaches infinity).

533

fiGao & Culberson

1

0.9

0.8

Solution Probability

0.7

0.6

0.5

0.4

0.3
generalized flawless
flawless model
model B

0.2

0.1

0

0

0.5

1

1.5
2
2.5
ConstraintsVariables Ratio

3

3.5

4

Figure 5: Solution probability function ratio constraints variables
three random CSP models n = 500, = 6. generalized flawless
model, L set connected 2-regular bipartite graphs. y-axis
solution probability x-axis ratio constraints variables m/n.
Sample size data point 100.

d,t
d,t
Bn,m
Bn,m
[M] terms size search tree running time
satisfiable instances (Figure 8) well unsatisfiable instances.
d,t
Careful readers may noticed model Bn,m
[WC], number branches
obvious secondary peak phase transition (Figure 6 Figure 8),
anomaly reported previous paper (Gao & Culberson, 2004). detailed look experimental data reveals secondary peak, though persistent
statistical sense, appears number branches; noticed measure
running time secondary peak. tried several approaches understand secondary peak, finally conclude solver-dependent behavior
caused branching heuristics, CNF encoding, level local consistency
enforced CSP models. provide discussion phenomenon
next subsection.
case = 4, also studied behavior CSP models different
constraint tightness values. results reported Tables 1 2 show
maximum ratio constraints variables median number
branches three CSP models constraint tightness ranging = 5
= 8. results consistent observed experiments Boolean CSPs,
showing increase constraint tightness significant impact typical case
instance hardness. also clear constraint tightness values, instances
d,t
generalized flawless model Bn,m
[WC] significantly harder two

534

fiConsistency Random CSPs

5

6

10

median
Number Branches

Number Branches

10

4

10

3

10

2

1
2
3
ConstraintsVariables Ratio

6

Number Branches

4

10

3

10
10

4

0

1
2
3
ConstraintsVariables Ratio

4

generalized flawless
flawless model6
model B 10

10

90th percentile

5

10

4

10

3

10

2

10

5

10

2

0

Number Branches

10

95th percentile

80th percentile

5

10

4

10

3

10

2

0

1
2
3
ConstraintsVariables Ratio

10

4

0

1
2
3
ConstraintsVariables Ratio

4

Figure 6: Number branches used ZChaff solve instances three random CSP
d,t
[WC],
models n = 500, = 6, = 4. generalized flawless model Bn,m
core graph connected 2-regular bipartite graph described Figure 1.

d,t
classical models. case = 5, instances drawn Bn,m
[WC] cannot solved
within time limit 1800 seconds even solubility phase transition.
confirm enforcing constraint consistency increases typical case hardness, tested two backtracking solvers experiments: SatZ CSP solver
FC + MAC static variable ordering.
set experiments, problem size n = 300 run solvers
instances reduce variance. summarize results Tables 3 4.
problem size n = 300, ZChaff SatZ little difficulty solving randomlygenerated instances three models except rare cases, SatZ
get stuck instances generated ratio constraints variables well
threshold. Although CSP solver works directly CSP instances, perform
well SAT solvers working encoded instances. Given long history

535

fiGao & Culberson

2

4

10

10

95th percentile

median
1
2

Seconds

Seconds

10

0

10

1

10

2

10

10

0

10

2

1.5

2
2.5
3
3.5
ConstraintsVariables Ratio

10

4

0

10

90th percentile

80th percentile

2

2

10

Seconds

Seconds

4

generalized flawless
flawless model
4
model B 10

4

0

10

2

10

1
2
3
ConstraintsVariables Ratio

10

0

10

2

0

1
2
3
ConstraintsVariables Ratio

10

4

1

2
3
ConstraintsVariables Ratio

4

Figure 7: User CPU time seconds solve instances three random CSP models
d,t
n = 500, = 6, = 4. generalized flawless model Bn,m
[WC], core
graph connected 2-regular bipartite graph described Figure 1.

536

fiConsistency Random CSPs

6

6

10

10

95th percentile
Number Branches

Number Branches

median
5

10

4

10

3

10

2

0.5
1
1.5
2
ConstraintsVariables Ratio

6

Number Branches

4

10

3

10
10

2.5

0

0.5
1
1.5
2
ConstraintsVariables Ratio

2.5

generalized flawless
flawless model6
model B 10

10

90th percentile

5

10

4

10

3

10

2

10

10

2

0

Number Branches

10

5

80th percentile

5

10

4

10

3

10

2

0

0.5
1
1.5
2
ConstraintsVariables Ratio

10

2.5

0

0.5
1
1.5
2
ConstraintsVariables Ratio

2.5

Figure 8: Number branches used ZChaff solve satisfiable instances three
random CSP models n = 500, = 6, = 4. generalized flawless
d,t
model Bn,m
[WC], core graph connected 2-regular bipartite graph described Figure 1.

537

fiGao & Culberson

(n, t)
(500, 5)
(500, 6)
(500, 7)
(500, 8)

d,t
Bn,m
branches
10673
7243
4440
1853

m/n
2.30
1.80
1.40
0.90

d,t
Bn,m
[M]
branches m/n
20271
2.90
7446
1.90
5123
1.50
4113
1.20

d,t
Bn,m
[WC]
branches
m/n
?
> 3.10
94281
2.44
13813
2.00
9163
1.60

Table 1: maximum,
n , median number branches ZChaff
100 random instances three random CSP models , domain size
d,t
= 4, tightness = 5, 6, 7, 8. generalized flawless model Bn,m
[WC],
core graph connected 2-regular bipartite graph described Figure 1.

(n, t)
(500, 5)
(500, 6)
(500, 7)
(500, 8)

d,t
Bn,m
seconds m/n
0.08
2.80
0.02
2.00
0.01
1.40
0.00
0.90

d,t
Bn,m
[M]
seconds m/n
1.79
2.90
0.02
1.90
0.02
1.70
0.00
1.00

d,t
Bn,m
[WC]
seconds
m/n
> 1800 > 3.10
40.3
2.44
1.08
2.00
0.26
1.60

Table 2: maximum,
n , median running time seconds ZChaff
random instances three random CSP models , domain size = 4,
d,t
tightness = 5, 6, 7, 8. generalized flawless model Bn,m
[WC], core
graph connected 2-regular bipartite graph described Figure 1.

development SAT solvers, significant branch selection heuristics SatZ clauselearning (nogood recording) ZChaff, surprising. particular,
d,t
design Bn,m
[WC] seen rendering consistency checking CSP solver
less effective. Still, better performance SAT solvers indicates still
structure exploit.
4.2.2 Case = 9
study robustness method seek explanations double
peaks, consider case domain size = 9. turns = 9 able
construct variety random CSP models significantly different behavior.
consider collection 5 random CSP models:
d,t
1. Bn,m
(model B),
d,t
2. Bn,m
[M] (the flawless model),

538

fiConsistency Random CSPs

(n, t)
(300, 5)
(300, 6)
(300, 7)
(300, 8)

ZChaff
seconds m/n
4.16
3.10
0.33
2.50
0.11
2.00
0.03
1.70

SatZ
seconds m/n
2.50
3.10
0.31
2.50
0.11
2.00
0.03
1.70

CSP (FC + MAC)
seconds
m/n
90.21
3.10
12.11
2.50
3.10
2.00
0.60
1.70

Table 3: Maximum,
n , median number branches ZChaff, SatZ,
d,t
CSP solver FC + MAC random instances Bn,m
[WC] , n = 300,
d,t
= 4, = 5, 6, 7, 8, core graph Bn,m [WC] connected 2-regular
bipartite graph described Figure 1.

(n, t)
(300, 5)
(300, 6)
(300, 7)
(300, 8)

ZChaff
seconds m/n
0.08
2.90
0.01
2.20
0.01
1.70
0.00
1.30

SatZ
seconds m/n
0.15
2.90
0.02
2.20
0.01
1.70
0.01
1.30

CSP (FC + MAC)
seconds
m/n
2.68
3.00
0.29
2.20
0.09
1.80
0.06
1.30

Table 4: Maximum, overall
n , median running time seconds ZChaff, SatZ,
d,t
CSP solver FC + MAC random instances Bn,m
[M], n = 300,
= 4, = 5, 6, 7, 8.

d,t
3. Bn,m
[L1 ] L1 constructed using 18 cycle (i.e., connected 2-regular bipartite
graph) arbitrary bijections,
d,t
4. Bn,m
[L2 ] L2 constructed using core graph shown Figure 1 arbitrary
bijections,
d,t
5. Bn,m
[L3 ] L3 constructed using core graph Figure 1 blockrespecting bijections.
d,t
d,t
d,t
Recall model Bn,m
[L2 ] belongs class Bn,m
[WC], Bn,m
[L3 ] belongs
d,t
class Bn,m [SC]. five models, fix constraint tightness = 45,
maximum possible constraint tightness achieved generalized flawless
model WC-inducing core graph.
experiments show typical-case hardness randomly generated instances
increases level consistency enforced. Figure 9, plot median
number branches median running time seconds ZChaff solve instances
d,t
d,t
d,t
Bn,m
, Bn,m
[M], Bn,m
[L1 ]. Figure 10, show median number

539

fiGao & Culberson

6

3

10

10

18cycle
flawless model
model B

18cycle
flawless model
model B
2

10

5

Number Branches

10

1

Seconds

10

0

10
4

10

1

10

3

10

2

1

1.5
2
2.5
ConstraintsVariables Ratio

10

3

1

1.5
2
2.5
ConstraintsVariables Ratio

3

d,t
d,t
d,t
Figure 9: Results using ZChaff solve instances Bn,m
, Bn,m
[M], Bn,m
[L1 ]
L1 constructed 18 cycle (i.e., connected 2-regular bipartite graph)
arbitrary bijections. parameters used n = 300, = 9, =
d,t
45. Bn,m
[L1 ] parameter m/n = 2.3, ZChaff failed solve 45
100 instances. data (pointed solid triangles) m/n = 2.3 based
solved instances only.

branches median running time seconds ZChaff solve instances
d,t
d,t
Bn,m
[L2 ] Bn,m
[L3 ].
d,t
d,t
[M], ZChaff able solve instances within time limit
Bn,m
Bn,m
1800 seconds m/n. ZChaff starts frequent timeouts m/n 2.3.
d,t
[L1 ] m/n = 2.3, ZChaff solve 55 100 instances within 1800 seconds,
Bn,m
10 55 solved instances unsatisfiable. m/n = 2.4, 2.5, 2.6, ZChaff
solve 42 instances (respectively, 81 instances, 90 instances) unsatisfiable.
d,t
d,t
models Bn,m
[L2 ] andBn,m
[L3 ], observed 100 instances generated
d,t
parameter m/n = 2.3, ZChaff solve 90 instances Bn,m
[L2 ] 33 instances
d,t
d,t
Bn,m
[L3 ]. Bn,m
[L2 ] m/n = 2.4, ZChaff solved 5 instances.
d,t
d,t
solved instances Bn,m
[L2 ] Bn,m
[L3 ] satisfiable, expected since
d,t
region well threshold. didnt conduct experiments Bn,m
[L2 ]
d,t
m/n = 2.5 2.6 Bn,m
[L3 ] m/n = 2.4, 2.5 2.6, expect instances
models even harder.
assumed secondary peak observed CSP models = 4
algorithm-independent unique models, expected using larger
domain size variety CSP models would able help provide satisfactory
explanation phenomenon. designed experiments empirically investigate
relations appearance secondary peak three characteristics
540

fiConsistency Random CSPs

6

3

10

10
18cycle
WCinducing
SCinducing

18cycle
WCinducing
SCinducing
2

10
5

1

10

Seconds

Number Branches

10

4

10

0

10

3

10

1

10

2

10

1

2

1.5
2
2.5
ConstraintsVariables Ratio

10

3

1

1.5
2
2.5
ConstraintsVariables Ratio

3

d,t
Figure 10: Results using ZChaff solve instances Bn,m
[L1 ], weakly 4-consistent
d,t
d,t
model Bn,m [L2 ] strongly 3-consistent model Bn,m [L3 ]. parameters used = 9, n = 300, = 45. ZChaff starts frequent timeouts
m/n 2.3. Therefore m/n = 2.3, data (pointed solid trid,t
[L1 ], 45
angles) based solved instances only. model Bn,m
55 solved instances satisfiable remaining 10 solved instances
d,t
unsatisfiable. weakly 4-consistent model Bn,m
[L2 ] strongly 3d,t
consistent model Bn,m [L3 ], Zchaff solved 90 instances (respectively 33 instances)
d,t
satisfiable. weakly 4-consistentmodel Bn,m
[L2 ]
m/n = 2.4, ZChaff solve 5 100 instances 5 instances
satisfiable.

541

fiGao & Culberson

CSP models including (1) number derangements bijections constraint
construction, (2) level enforced local consistency models, (3) CNF
encoding scheme. Based series results, conclude secondary peak
algorithm-dependent artifact influenced selection branch heuristics,
level local consistency enforced models, CNF encoding scheme.
following, briefly summarize experimental investigations which, hope, also helps
illustrate flexibility framework constructing ensemble problem instances
study behavior different algorithms.
1. Number Derangements. number derangements bijection : V
number vertices vi V (vi ) 6= i. derangement
bijections constraint construction, generated instances always
satisfied assignments assign common domain value variables.
Contrary initial assumption, observe significant impact
number derangements behavior solvers except extreme cases
use bijections derangement probability close one.
2. Local Consistency Level. main difference among five models = 9
d,t
level enforced local constraint consistency. Bn,m
enforce
d,t
d,t
[L1 ] guarantees
[M] enforces arc-consistency; Bn,m
consistency; Bn,m
d,t
forcer; Bn,m
[L2 ] generates instances weakly 4-consistent; instances
d,t
Bn,m [L3 ] strongly 3-consistent. addition obvious impact instances
hardness, experiments indicate local consistency level models
contributes appearance secondary peak ZChaff. depicted Figures
9 10, problem size n = 300, secondary peak exists first four
d,t
models enforce strong 3-consistency, fifth model Bn,m
[L3 ]
peak. However, observed, additional trials reported
d,t
[L3 ] increase problem size.
here, secondary peak also exists Bn,m
3. CNF Encoding Scheme. experiments, CNF encoding CSP
instances include clauses enforce unique assignment CSP
variable. absence clauses affect theoretical exponential
lower bounds resolution complexity, observed experiments mixed
impacts clauses behavior solvers including appearance
secondary peak ZChaff. clauses included CNF encoding,
number branches running time SatZ increase, ZChaff
running time obvious decrease. also interesting adding
clauses CNF encoding also makes secondary peak ZChaff even sharper.
believe largely due greedy branching heuristics SatZ
tradeoff search inference achieved ZChaff.
empirical studies phase transitions AI literature
focused behavior solvers around solubility threshold random
model, would like point observations made
ratio constraints variables respective models threshold, parameter region
selection branch heuristics no-good recording technique make
big difference.
542

fiConsistency Random CSPs

5. Conclusions Future Directions
Random semi-random binary constraint instances used test various aspects
CSP solvers many researchers. illustrate robustness algorithms, desirable
instances generated model trivially unsolvable minimal
guarantee interest generators produce instances asymptotically
exponential resolution proofs. paper shown ensure
constraints instances strongly 3-consistent weakly 4-consistent
case. addition shown create instances,
allowing high constraint tightness, allowing considerable flexibility constraint
design. experimental sections showed significant increase difficulty instances
generated model models similar densities tightness. also noticed
double peak phenomenon experiments identified artifact
specific solver, influenced choice generation model characteristics
instances. exemplifies exactly kind algorithmic issue hope
generators would help researchers identify explore.
generation hard instances two foci, one restriction constraints
restricting constraint graph (or hyper-graph). specific problems,
example independent set (Brockington & Culberson, 1996) SAT (Bayardo Jr. & Schrag,
1996), observed techniques balancing degree constraint
graph reduce variance increases difficulty instances, whether camouflaging
hidden solution phase transition semi-random instances. expect modifying generation model also controlling graph structure might lead harder
instances, interesting properties would test mettle various algorithms.
example, suppose consider domain = {0, 1, 2, 3} let constraint
set allowed value pairs {(0, 1), (0, 3), (1, 0), (3, 0), (1, 2), (2, 1), (2, 3), (3, 2)}.
constraint could generated system using eight cycle enforces weak
4-consistency value set induces two four cycles pair domains. Thus,
constraint generate weakly 4-consistent CSPs. hand, arc
consistent contain forcer, since vertex induced constraint graph
degree two. consider constraint graph triangle, applying
constraint three edges mean satisfying assignment. Since random
graph m/n = c positive (bounded) expected number triangles,
positive expectation instance generated allowing constraint would
trivially unsatisfiable. Thus, appears weak 4-consistency minimal requirement
exponential complexity random constraint graphs. Notice weak 4-consistency
ensures every triangle satisfiable, also ensures (by induction basically)
larger cycle satisfiable. Thus, speaking general terms, way
sub-instance unsatisfiable subgraph contain edges vertices.
random graph analysis shows means asymptotically minimal unsatisfiable subinstance size O(n), course key ingredient complexity analysis.
Now, suppose ensure constraint graph girth g > 3. technique used specific problems, example graph coloring problems
(Culberson, Beacham, & Papp, 1995). wonder whether combining graph
restriction together weak g + 1-consistency (weaker weak 4-consistency) might

543

fiGao & Culberson

also produce instances exponentially long resolution proofs. Note one difficulty
analysis longer uniformly random graphs.
start considering larger picture, involving multiple variables, naturally
must consider k-ary constraints. part future research expect consider extending
model cases. course experiments effects increasing
tightness presented paper 3-ary constraints (SAT). fact, initial foray
tightness started variations SAT.
final cautionary note, point well known possible
CSP (i.e. SAT) instances exponential resolution proofs, resolvable
polynomial time techniques, Gaussian elimination. certain
system produce instances, see explicit reason prevents
so.

Acknowledgments
preliminary version paper appeared Proceedings Tenth International
Conference Principles Practice Constraint Programming (CP-2004). thank
referees helpful comments conference version journal version.
Thanks also given Dr. K. Xu comments conference version paper.
research supported Natural Sciences Engineering Research Council
Grant No. OGP8053. Yong Gao supported part UBCO startup grant
NSERC Discovery Grant RGPIN 327587-06.

Appendix A: Proofs Theorems
section, present concepts related resolution complexity results stated
paper prove Theorems 2.1, 3.1, 3.2.
A.1 Proof Theorem 2.1
providing proof Theorem 2.1, let us first formalize definitions
forcer, forbidding cycle, r-flower.
Definition A.1 (Forcers, Molloy & Salavatipour, 2003). constraint Cf var(Cf ) =
{x1 , x2 } called (, )-forcer nogood set
{(, ); 6= },
, , domain values involved variables. say constraint C
contains (, )-forcer Cf defined set variables C nogood set
Cf subset nogood set C.
Definition A.2 (Forbidding cycles r-flowers, Molloy & Salavatipour, 2003). forbidding cycle variable x0 set constraints
C1 (x0 , x1 ), C2 (x1 , x2 ), . . . , Cr1 (xr2 , xr1 ), Cr (xr1 , x0 )

544

fiConsistency Random CSPs

C1 (x0 , x1 ) (, 1 )-forcer, Cr (xr1 , x0 ) (r1 , r )-forcer (r 6= ),
Ci (xi1 , xi ) (i1 , )-forcer (2 r 1). call x0 center variable
-forbidding cycle.
r-flower R = {C1 , , Cd } consists (the domain size) forbidding cycles
length r
1. Ci , 1 d, center variable x;
2. Ci distinct -forbidding cycle common center variable x;
3. forbidding cycles share variables.
following facts straightforward establish:
1. r-flower consists = d(r 1) + 1 = dr + 1 variables dr constraints;
2. total number r-flowers

n
s!(d 1)d dd(r1) .

d,t
3. constraint Bn,m
[M] contains (, )-forcer pair (, ) one
tuples considered selecting set nogoods constraint.

following, assume r = o( n). probability constraint contains
forcer probability random instance flawless random CSP model
contains r-flower given following lemma.

Lemma A.1. Consider flawless random CSP

d,t
Bn,m
[M]

define fe =

(d

2 dd+1
td+1
d2


(

)

)

.

1. probability given constraint C(x1 , x2 ) contains (, )-forcer
1
fe .


(A.1)

2. Let R r-flower let c = m/n,
d,t
P {R appears Bn,m
[M]} = (1)(2cfe )dr

1 1
.
ndr ddr

(A.2)

Proof. Equation (A.1) follows following two observations:
1.

1


probability (, ) one tuples considered
d,t
selecting set nogoods constraint Bn,m
[M]

2. fe probability 1 tuples, (, ), 6= , set nogoods
selected uniformly random d2 tuples.

545

fiGao & Culberson

d,t
calculate probability given r-flower R appears Bn,m
[M], notice
probability selecting constraint edges R

N dr
cn(cn 1) (cn dr + 1)
cndr
=

N
N (N 1) (N dr + 1)
cn
dr
2c
= (1)
n

N = n2 . Since fixed choice dr constraint edges r-flower,
probability constraints contain r-flower ( d1 fe )dr , Equation (A.2) follows.

Proof Theorem 2.1. Let c =


2fe .

show c =


n

> c,

d,t
lim P {Bn,m
[M]} contains r-flower } = 1.

(A.3)

n

d,t
Let IR indicator function event r-flower R appears Bn,m
[M]
let
X
X=
IR
R
d,t
sum possible r-flowers. Then, Bn,m
[M] contains r-flower
X > 0.
Lemma A.1 fact = dr + 1,
X
E[X] =
E[IR ]
R


n
1 1
= (1)
s!(d 1)d dd(r1) (2cfe )dr dr dr

n
1 1
= (1)n(n 1) (n + 1)ddr (2cfe )dr dr dr
n
= (1)n1d (2cfe )dr .
Therefore, c > c r = log n sufficiently large, lim E[X] = .
n

show E[X 2 ] E 2 [X](1 + o(1)), application Chebyshev
inequality establish lim P {X = 0} = 0. get upper bound E[X 2 ],
n
need counting argument upper bound number r-flowers sharing given number
edges. done considering shared edges form connected components
(Franco & Gelder, 2003; Gao & Culberson, 2003; Molloy & Salavatipour, 2003). Here,

546

fiConsistency Random CSPs

follow method used Molloy Salavatipour (2003),


X

X
X X
X
X
2
E[X 2 ] =
E[IA
]+
E[IA IB ] +
IA
Nij (Pij )dri


=

X

B:BA=ff
2
E[IA
]+

X



X

E[IA ]E[IB ] +

X

B:BA=ff


2

i=1 j=1



E [X] +

X

IA

X

X



X

X
IA
Nij (Pij )dri



i=1 j=1


Nij (Pij )dri

(A.4)

i=1 j=1



(1) Nij number r-flowers share exactly constraint edges
constraints forms j connected components constraint graph A;
(2) (Pij )dri probability conditional IA , random CSP contains dr
constraints specific r-flower. work Molloy Salavatipour (2003), Nij
upper bounded
2

(2 + r2 )d (dr2 )j1 j!nsij dsij+d1 ,
((2 + r2 )d (dr2 )j1 )2 j! upper bounds number ways choose arrange j
shared connected components two r-flowers; nsij upper bounds number ways
choosing remaining non-shared variables since number variables
j shared connected components least one plus number edges shared
component; dsij+d1 upper bounds number ways choosing forcing values
non-sharing variables. shared variables take forcing values
due assumption < (Molloy & Salavatipour, 2003).
Since case d1 d2 d, possible shared variables take different
forcing values different r-flowers. Thus, upper bound Nij


(2 + r2 )d (dr2 )j1

2

j!nsij ds .

case, probability corresponding (Pij )dri
N dr(dri)
1
cni(dri)
( fe )dri

N dr

cni

= (1)(2cfe )dri

= (1)(

1

1

ndri

ddri

547

.

cn dri 1 dri
)
( fe )
N dr


fiGao & Culberson

Therefore, c =


2fe ,

X

X


Nij (2cfe )dri

i=1 j=1




X

1

1

ndri

ddri


(2 + r2 )2d r4 nsi ds (2cfe )dri

i=1




X

O(r4d4 )n1d (2cfe )dr

i=1

1

1

ndri

ddri



2
4
X
r j j
(
)
n
j=1

(2cfe )i r4
O( )
di
n



E[X]O(r

4d4

r4 X
)
)O( )
(
n
2cfe
i=1

E[X]O(

r4d
n

),

last inequality c >
completed.


2fe .

formula (A.4), proof

Remark A.1. relatively loose upper bound c = 2fde proof may improved
factor making distinction among r-flowers share forcing
values different number shared variables. purpose showing
flawless random CSP also potential embedded easy sub-problems, upper bound
constraint-variable ratio c sufficient since domain size constant.
A.2 Proof Theorems 3.1 3.2
Given CNF formula F, use Res(F) denote resolution complexity F, i.e.,
length shortest resolution refutation F. width deriving clause F,
denoted w(F ` A), defined minimum resolution refutations
maximum clause size resolution refutation. width w(F) formula F
size largest clause it. Ben-Sasson Wigderson (2001) established relationship
Res(F) w(F ` ):
Res(F) = e(

(w(F `)w(F ))2
)
n

.

relationship indicates give exponential lower bound resolution complexity, sufficient show every resolution refutation F contains clause whose
size linear n, number variables.
Let instance CSP let CNF(I) CNF encoding I. Mitchell
(2002b) provided framework within one investigate resolution complexity
I, i.e., resolution complexity CNF formula CNF(I) encodes I, working
directly structural properties I. Denote var(I) set CSP variables
var(CNF(I)) set encoding Boolean variables CNF(I). sub-instance J
CSP instance var(J ) var(I) J contains constraints
whose scope variables var(J ). following crucial concepts make possible work
548

fiConsistency Random CSPs

directly structural properties CSP instance investigating resolution
complexity encoding CNF formula.
Definition A.3 (Implies, Mitchell, 2002b). Let C clause encoding Boolean
variables var(CNF(I)). say sub-instance J implies C, denoted J |= C,
assignment CSP variables satisfying J , corresponding
assignment encoding Boolean variables satisfies C.
Definition A.4 (Clause Complexity, Mitchell, 2002b). Let CSP instance.
clause C defined Boolean variables var(CNF(I)), define
(C, I) = min{|var(J )|; J sub-instance implies C}.
following two concepts slightly generalize used Mitchell (2002b)
Molloy Salavatipour (2003) enable us uniform treatment establishing
resolution complexity lower bounds.
Definition A.5 (Boundary). boundary B(J ) sub-instance J defined
set CSP variables variable x B(J ) following true:
J minimally implies clause C defined Boolean variables var(CNF(I)),
C contains least one Boolean variables, x : , D, encode CSP variable
x.
Definition A.6 (Sub-critical Expansion, Mitchell, 2002b). Let CSP instance.
sub-critical expansion defined
e(I) =

max

min

|B(J )|

(A.5)

0s(,I) s/2|var(J )|s

minimum taken sub-instances s/2 |var(J )| s.
following theorem relates resolution complexity CNF encoding CSP
instance sub-critical expansion CSP instance.
Theorem A.2 (Mitchell, 2002b). CSP instance I,
w(CNF(I) ` ) e(I)

(A.6)

Proof. resolution refutation CNF(I) (, I), Lemma 1 Mitchell
(2002b) shows must contain clause C
s/2 (C, I) s.
Let J sub-instance |var(J )| = (C, I) J implies C. Since J minimally
implies C, according definition boundary, w(C) |B(J )|. Formula (A.6)
follows.
establish asymptotically exponential lower bound Res(C) random CSP C,
enough show constant > 0
lim P {e(C) n} = 1.

n

549

(A.7)

fiGao & Culberson

> 0, let () event {(, C) > n} (, ) event
)
(
min

n
|var(J )|n
2

B(J ) n .

Notice
P {e(C) n} P {Am () (, )}
1 P {Am ()} P {As (, )}.

(A.8)

need find appropriate
lim P {Am ( )} = 0

(A.9)

lim P {As ( , )} = 0.

(A.10)

n


n

Event ( ) size minimally unsatisfiable sub-instances. event
( , ), common practice identify special subset boundaries show
subset large. different random CSP models different assumptions
model parameters, different ways achieve this. Following Beame et al.
(2005), say graph G (r, q)-dense subset r vertices induces least
q edges G.
d,t
Proof Theorem 3.1. Recall constraint graph Bn,m
[SC] standard
random graph G(n, m).
d,t
Since instance Bn,m
[SC] strongly k-consistent, variables minimal unsatisfiable sub-instance J |var(J )| = r must vertex degree greater equal
k, consequently, constraint sub-graph H(J ) must contain least rk
2 edges. Thus,
d,t
[SC]) n}
P {Am ( )} = P {(, Bn,m
( n
)
[
P
{G(n, m) (r, rk/2)-dense } .
r=k+1

Let B k (J ) set variables var(J ) whose vertex degrees less k. Again,
d,t
since instances Bn,m
[SC] always strongly k-consistent, B k (J ) B(J )
k
thus, |B(J )| |B (J )|. Therefore, probability P {As ( , )} bounded
P {As ( , )} P {Aks ( , )}
Aks ( , ) event


k

min

n/2|var(J )| n

550





B (J ) n .

fiConsistency Random CSPs

Random graph arguments (see, e.g., Beame et al., 2005) show exist constants
P {Am ( } P {Aks ( , )} tend 0. Indeed, let

n(n1)
(12 )k > 1, c =
.
n , N =
2
(
P {Am ( )} P



[n

)
{G(n, m) (r, rk/2)-dense }

r=k+1



n
X

P {G(n, m) (r,

r=k+1

rk
)-dense}
2

n r(r1)
X
N
n
2

rk
r

2
r=k+1

rk 1
N
2
rk

2



n
X
en e(r 1) rk 2c rk
)2( )2

( )r (
r
k
n
r=k+1


n
X
en 2ec(r 1) k r
=
(
)2
r
kn
r=k+1


n
X
k k k+2 k r k2 r
=
( )2 e 2 c2 ( ) 2
2
n
r=k+1

blog nc



X

r=k+1

k k k+2 k log n k2
( )2 e 2 c2 (
) 2
2
n


n
X

+

r=blog nc

Similarly, =





k k k+2 k k2 log n
( ) 2 e 2 c 2 ( ) 2
2

2
,

P {Aks ( , )} = P


n

[

{ size-r sub-instance J s.t. |Bk (J )| n}


r= n

n

[





r(1 )k
{G(n, m) (r,
)-dense}


2
r= n

2

r

(1)k
n
X
2
(1)k+2
(1)k2
2c



e 2 ( ) 2
(1

)k
n
r=







2

P

(A.11)

(A.12)

2

second inequality fact sub-instance J size r

|Bk (J )| n, constraint graph contains least r n = r 2 n r r vertices
whose degree least k.

551

fiGao & Culberson





(1 )k
exist (1) 2
> 1; (3) right hand
< 1; (2)
2
side formula (A.11) right hand side formula (A.12) tend zero.
completes proof Theorem 3.1.
d,t
prove Theorem 3.2. First definition Bn,m
[W C], following
d,t
Lemma A.3. random CSP Bn,m
[W C],

1. Every sub-instance whose constraint graph cycle satisfiable;
2. path length 3, compatible assignments two variables
ends path extended assignments satisfy whole path.
effort establish exponential lower bounds resolution complexity
classical random CSP models tightness higher established Mitchell
(2002b), Molloy Salavatipour (2003) introduced collection sub-instances, denoted
BM (J ), used size give lower bound size boundary.
binary CSPs whose constraints arc-consistent contain forcer, BM (J ) consists
1 (J ) B 2 (J ), defined respectively follows:
two parts: BM

1 (J ) contains set single-edge sub-instances X , i.e., |var(X )| = 2,
1. BM
least one variables vertex degree 1 original constraint graph;
2 (J ) contains set sub-instances X whose induced constraint graph pen2. BM
dant path length 4, i.e., path length 4 vertex
endpoints vertex degree greater 2 original constraint graph.

shown
Lemma A.4. weakly path-consistent CSP sub-instance J ,
1
|B(J )| |BM
(J )| +

2 (J )|
|BM
.
4

1 (J ) B(J );
Proof. variable degree one sub-instance BM
2
least one internal variable pendant path BM (J ) B(J ). possible
several pendant paths length 4 share common internal variable B(J ),
e.g., long pendant path. variable appear three pendant
paths length 4.

preparations, proof provided Theorem 1 Molloy Salavatipour
(2003) readily applies case. make report self-contained, give proof
below.
Proof Theorem 3.2. Lemma A.3, minimally unsatisfiable sub-instance J
(1) constraint graph cannot single cycle; (2) BM (J ) empty since
1 (J )| = 0 |B 2 (J )| = 0 minimally unsatisfiable sub-instance. According
|BM

1
Lemma 11 Molloy Salavatipour, constraint graph J least (1+ 12
)var(J )

552

fiConsistency Random CSPs

edges. Therefore, due locally sparse property random graphs, constant
> 0 formula (A.9) holds, i.e.,
lim P {Am ( )} = 0.

n

establish formula (A.10), due Lemma A.4
P {As ( , )} P {As,M ( , )}
As,M ( , ) event

min

n/2|var(J )| n


|BM (J )| n .

suppose contrary > 0, sub-instance J n/2
1 (J )| + |B 2 (J )| n. Then, Lemmas 10 11 Molloy
|var(J )| |BM

Salavatipour, constraint graph J contains cycle components, Lemma
11 Molloy Salavatipour asserts edges-to-vertices ratio constraint graph
J bigger one. remove cycle components constraint
graph J , edges-to-vertices ratio remaining graph becomes even bigger.
impossible constraint graph J , hence remaining graph,
less n vertices.
well-known w.h.p. random graph fewer log n cycle components
length 4; random graph G(m, n) m/n = c constant,
number cycle components fixed length asymptotically Poisson distribution
(Bollobas, 2001). Thus, number variables cycle components length
4 4 log n. Since cycle component length l > 4 contains l pendant paths
length 4, total number variables cycle components length greater 4
2 (J )| < n. Therefore, var(J ) < n + 4 log n < n/2 var(J )
|BM
sufficiently small , contradiction.
We, therefore, conclude w.h.p, sub-instance J
n/2 |var(J )| , |BM (J )| n, i.e., formula (A.10) holds.
A.3 Upper Bound Threshold Random Restricted Binary CSP
d,t
Bn,m
[L]
subsection, show condition mentioned end Definition 2.1
d,t
guarantees existence constant c Bn,m
[L] m/n > c asymptotically
unsatisfiable probability one. state prove result case binary
constraints, similar results also hold general k-ary constraints.
Recall condition set relations L = {L1 , L2 , . . . | Li D}
\
(a, a)
/
Li , D.
(A.13)
i1

Since assume domain size fixed, probability constraint
d,t
Bn,m
[L] contains (a, a) one nogoods lower bounded constant p.
553

fiGao & Culberson

d,t
Theorem A.5. Bn,m
[L] set relations L satisfies condition A.13,
unsatisfiable w.h.p.
n = n

d(1

p c
) < 1.
d2

Proof. assignment A, must subset nd variables assigned
d,t
common domain value a. Then, satisfies Bn,m
[L] satisfies constraints
d,t
involve variables S. Let Hi event Bn,m
[L] constraints
involve variables S. Then,
d,t
P {A satisfies Bn,m
[L]}

cn
X

(1 p)i P {Hi }.

i=0

Let N = 21 n(n 1). Write
N1 =

1n n
1
( 1) = 2 n(n 1) + O(n)
2d
2d

number possible edges induced S,
1
1
N2 = N N1 = (1 2 )n(n 1) + O(n).
2

1 cn 1
N2
N1
P {Hi } =



cni

N
cn

N1 (N1 1) (N1 + 1) N2 (N2 1) (N2 cn + + 1) (cn)!
N (N 1) (N cn + 1)
i!(cn i)!

cni
N1
N2
cn

N
N


cni
N1
N2
cn


N
N cn
=

Similarly,
N2
cn

N
cn



P {H0 } =





N1
cn

N
cn

N2
N cn



P {Hcn } =

554




N1
N

cn

cn

fiConsistency Random CSPs

So,
d,t
P {A satisfies Bn,m
[L]}

cn
X

(1 p)i P {Hi }

i=0
cn
X

cni
N2
cn
N1

(1 p)
N
N cn

i=0




cn
cni
X
N1 N2 N
cn

(1 p)
N
N N cn

i=0
cn

N1 N2 N
= (1 p)
+
N
N N cn


1
1 cn
= (1 p) 2 + (1 2 )
O(1)



p cn
O(1)
= 1 2

Therefore,








p cn
p n
d,t
P {Bn,m
[L] satisfiable } dn 1 2
= d(1 2 )c



References
Achlioptas, D., Beame, P., & Molloy, M. (2001). sharp threshold proof complexity.
Proceedings 33rd Annual ACM Symposium Theory Computing, pp.
337346.
Achlioptas, D., L.M.Kirousis, E.Kranakis, D.Krizanc, M.Molloy, & Y.C.Stamation (1997).
Random constraint satisfaction: accurate picture. Proceedings Principles
Practice Constraint Programming (CP-1997), pp. 107120. Springer.
Bayardo Jr., R. J., & Schrag, R. (1996). Using CSP look-back techniques solve exceptionally hard SAT instances. Principles Practice Constraint Programming
(CP-1996), pp. 4660.
Beame, P., Culberson, J., Mitchell, D., & Moore, C. (2005). resolution complexity
random graph k-colorability. Discrete Applied Mathematics, 153 (1-3), 2547.
Beame, P., Karp, R. M., Pitassi, T., & Saks, M. E. (1998). complexity unsatisfiability proofs random k-CNF formulas. Proceedings 30th Annual ACM
Symposium Theory Computing, pp. 561571.
Ben-Sasson, E., & Wigderson, A. (2001). Short proofs narrow - resolution made simple.
Journal ACM, 49 (2), 149169.
Bollobas, B. (2001). Random Graphs. Cambridge University Press.
Bondy, J. A., & Murty, U. S. R. (1976). Graph Theory Applications. MacMillan
Press Ltd.

555

fiGao & Culberson

Brockington, M., & Culberson, J. C. (1996). Camouflaging independent sets quasirandom graphs. Johnson, D. S., & Trick, M. A. (Eds.), Cliques, Coloring,
Satisfiability: Second DIMACS Implementation Challenge, Vol. 26, pp. 7588. American Mathematical Society.
Chvatal, V., & Szemeredi, E. (1988). Many hard examples resolution. Journal
Association Computing Machinery, 35 (4), 759768.
Culberson, J., Beacham, A., & Papp, D. (1995). Hiding colors. CP95 Workshop
Studying Solving Really Hard Problems, pp. 3142, Cassis, France.
Franco, J., & Gelder, A. V. (2003). perspective certain polynomial-time solvable
classes satisfiability. Discrete Applied Mathematics, 125 (2-3), 177214.
Frieze, A., & Molloy, M. (2003). satisfiability threshold randomly generated binary
constraint satisfaction problems. 7th International Workshop Randomization
Approximation Techniques Computer Science, RANDOM 2003, pp. 275289.
Gao, Y., & Culberson, J. (2003). Resolution complexity random constraint satisfaction
problems: Another half story. LICS03 Workshop Typical Case Complexity
Phase Transitions.
Gao, Y., & Culberson, J. (2004). Consistency random constraint satisfaction models
high constraint tightness. Proceedings Tenth International Conference
Principles Practice Constraint Programming (CP-2004), pp. 1731.
Gent, I., MacIntyre, E., Prosser, P., Smith, B., & Walsh, T. (2001). Random constraint
satisfaction: Flaws structure. Constraints, 6 (4), 345372.
Johnson, D. S. (2002). theoreticians guide experimental analysis algorithms.
Data Structures, Near Neighbor Searches, Methodology: Fifth Sixth DIMACS
Implementation Challenges, pp. 215250. American Mathematical Society.
Li, C. M., & Anbulagan (1997). Heuristics based unit propagation satisfiability problems. Proceedings 15th International Joint Conference Artificial Interlligence
(IJCAI97), pp. 366371.
MacIntyre, E., Prosser, P., Smith, B., & Walsh, T. (1998). Random constraint satisfaction: theory meets practice. Proceedings Principles Practices Constraint
Programming(CP-1998), pp. 325339. Springer.
Mackworth, A. K. (1977). Consistency networks relations. Artificial Intelligence, 8,
99118.
Mitchell, D. (2002a). Resolution Complexity Constraint Satisfaction. Ph.D. thesis,
Department Computer Science, University Toronto, Canada.
Mitchell, D. (2002b). Resolution complexity random constraints. Proceedings Principles Practices Constraint Programming (CP-2002), pp. 295309. Springer.
Molloy, M. (2002). Models thresholds random constraint satisfaction problems.
Proceedings 34th ACM Symposium Theory Computing, pp. 209 217.
ACM Press.

556

fiConsistency Random CSPs

Molloy, M., & Salavatipour, M. (2003). resolution complexity random constraint
satisfaction problems. Proceedings 44th Annual IEEE Symposium Foundations Computer Science (FOCS-2003), pp. 330339. IEEE Press.
Prosser, P. (1996). empirical study phase transitions binary constraint satisfaction
problems. Artificial Intelligence, 81 (1-2), 81109.
Smith, B. M. (2001). Constructing asymptotic phase transition random binary constraint satisfaction problems. Theoretical Computer Science, 265 (1-2), 265283.
Wormald, N. C. (1999). Models random regular graphs. Surveys Combinatorics,
London Mathematical Society Lecture Note Series, vol. 276, pp. 239298. Cambridge
Univ. Press.
Xu, K., & Li, W. (2000). Exact phase transitions random constraint satisfaction problems.
Journal Artificial Intelligence Research, 12, 93103.
Zhang, L., Madigan, C., Moskewicz, M., & Malik, S. (2001). Efficient conflict driven learning boolean satisfiability solver. Proceedings International Conference
Computer Aided Design (ICCAD2001), pp. 530535.

557

fiJournal Artificial Intelligence Research 28 (2007) 157181

Submitted 08/06; published 02/07

Junta Distributions Average-Case Complexity
Manipulating Elections
Ariel D. Procaccia
Jeffrey S. Rosenschein

arielpro@cs.huji.ac.il
jeff@cs.huji.ac.il

School Engineering Computer Science,
Hebrew University Jerusalem,
Jerusalem 91904, Israel

Abstract
Encouraging voters truthfully reveal preferences election long
important issue. Recently, computational complexity suggested means
precluding strategic behavior. Previous studies shown voting protocols
hard manipulate, used N P-hardness complexity measure. worst-case
analysis may insufficient guarantee resistance manipulation.
Indeed, demonstrate N P-hard manipulations may tractable averagecase. purpose, augment existing theory average-case complexity
new concepts. particular, consider elections distributed respect junta
distributions, concentrate hard instances. use techniques prove
scoring protocols susceptible manipulation coalitions, number candidates constant.

1. Introduction
Multiagent environments often inhabited heterogeneous, selfish agents, continually
interacting sharing common goals. settings, agents may diverse
even conflicting preferences. Therefore, reaching consensus among agents long
important issue.
general, well-studied well-understood scheme preference aggregation voting:
agents reveal preferences ranking set candidates, winner determined
according voting protocol. candidates election beliefs, plans (Ephrati
& Rosenschein, 1997), schedules (Haynes, Sen, Arora, & Nadella, 1997), indeed many
less obvious entities, movies (Ghosh, Mundhe, Hernandez, & Sen, 1999).
Applications voting, place methods, motivated theoretical guarantees
provided various voting protocols. instance, Ghosh et al. (1999) present movie
recommender system relies voting, makes use voting properties generate
convincing explanations different recommendations.
is, however, obstacle always plagued voting theory, social choice
theory general: strategic behavior part voters. setting, self-interested
agent may reveal preferences untruthfully, believes would make final outcome
elections favorable it. Manipulation generally regarded problem, since
makes actual ballot complex game, voters react counter-react
strategies others. require larger investment (computational)
resources voters, may result socially undesirable alternative chosen.
c
2007
AI Access Foundation. rights reserved.

fiProcaccia & Rosenschein

celebrated Gibbard-Satterthwaite Theorem (Gibbard, 1973; Satterthwaite, 1975)
establishes deterministic voting protocol non-dictatorial,1
elections agent better voting untruthfully. Consequently, possible
design nonmanipulable voting system guarantee voters act honestly.
Fortunately, reasonable make assumption agents computationally bounded. Therefore, although principle agent may able manipulate
election, computation required may infeasible. motivated researchers
study computational complexity manipulating voting protocols. Indeed,
demonstrated several voting protocols N P-hard manipulate single
voter (Bartholdi, Tovey, & Trick, 1989a; Bartholdi & Orlin, 1991). Hereinafter mainly
focus attention setting multiple manipulators collude order achieve
certain outcome. setting, manipulation even harder: known
coalitional manipulation problem N P-hard numerous voting protocols, even
number candidates constant.
results suggest computational complexity may cure malady
called Manipulation. Computer Science, though, notion hardness usually
considered sense worst-case complexity. Indeed, results complexity
manipulation use N P-hardness complexity measure. Therefore, could still
case instances problem easy manipulate. put differently,
strategic voter may usually succeed finding beneficial manipulation, efficiently,
even problem hard worst-case. so, truly significant issue
average-case complexity manipulations.
Sadly, far attempts design voting protocol resistant manipulations
average-case failed. suggests manipulation problem inherently
easy average-case pushes us analytically support claim: must
characterize settings protocols easily manipulated average-case.
relatively little-known theory average case complexity exists (Trevisan, 2002);
theory introduces concept distributional problems, defines reduction
distributional problems is. also known average-case complete
problems. However, goal existing theory define problem hard
average-case; provide criteria deciding problem easy.
paper, engage novel average-case analysis, based criteria propose.
Coming interesting distribution problem instances respect
average-case complexity computed difficult task, solution may controversial. analyze problems whose instances distributed respect junta
distribution. distribution must satisfy several conditions, (arguably) guarantee focuses instances harder manipulate. consider protocol
susceptible manipulation polynomial time algorithm usually
manipulate it: probability failure (when instances distributed according
junta distribution) must inverse-polynomial. algorithm known heuristic
polynomial time algorithm.
use new methods analytically establish following result: important
family voting protocols, called scoring protocols, susceptible coalitional manipulation
1. dictatorial protocol, agent dictates outcome regardless others choices.

158

fiJunta Distributions

number candidates constant. Specifically, contemplate sensitive scoring
protocols, include well-known protocols Borda Veto. accomplish
task, define natural distribution instances well-defined coalitional
manipulation problem, show junta distribution. Furthermore, present
manipulation algorithm Greedy, prove usually succeeds respect
. significance result stems fact sensitive scoring protocols
N P-hard manipulate, even number candidates constant. support
claim junta distributions provide good benchmark proving Greedy also
usually succeeds respect uniform distribution.
also show protocols susceptible certain setting manipulation,
manipulator unsure others votes. result depends upon basic
conjecture regarding junta distributions.
paper proceeds follows: Section 2, outline important voting protocols,
define manipulation problems shall discuss. Section 3, formally introduce
tools average case analysis: junta distributions, heuristic polynomial time,
susceptibility manipulations. Section 4 prove main result: sensitive scoring
protocols susceptible coalitional manipulation candidates. Section 5,
discuss case single manipulator unsure voters votes.
Section 6 survey related work. Finally, Section 7, present conclusions
directions future research.

2. Preliminaries
first describe common voting protocols formally define manipulation
problems shall deal. Next, introduce two useful lemmas probability
theory.
2.1 Elections Manipulations
election consists set C = {c1 , c2 , . . .} candidates set V = {v1 , v2 , . . . , }
voters, provide total order candidates. election also includes winner
determination function set possible combinations votes C. note
throughout paper number candidates constant, complexity results
terms number voters.
Different voting protocols distinguished winner determination functions.
protocols shall discuss are:
Scoring protocols: scoring protocol defined vector
~ = h1 , 2 , . . . , |C| i,
1 2 . . . |C| N {0}. candidate receives points
voter ranks ith place. Examples scoring protocols are:
Plurality:
~ = h1, 0, . . . , 0, 0i.
Veto:
~ = h1, 1, . . . , 1, 0i.
Borda:
~ = h|C| 1, |C| 2, . . . , 1, 0i.
159

fiProcaccia & Rosenschein

Copeland: possible pair candidates, simulate election; candidate wins
pairwise election voters prefer opponent. candidate gets
1 point pairwise election wins, 1 pairwise election loses.
Maximin: candidates score pairwise election number voters
prefer opponent. winner candidate whose minimum score
pairwise elections highest.
Single Transferable Vote (STV): election proceeds rounds. round,
candidates score number voters rank highest among remaining
candidates; candidate lowest score eliminated.
Remark 1. assume tie-breaking always adversarial manipulator.2
case weighted votes, voter weight k N naturally regarded k voters
vote unanimously. paper, consider weights [0, 1]. equivalent, since
set integer weights exponential n scaled rational weights
segment [0, 1], represented using O(n) bits.
main results paper focus scoring protocols. shall require following
definition:


ff
Definition 1. Let P scoring protocol parameters
~ = 1 , 2 , . . . , |C| . say
P sensitive iff 1 2 . . . |C|1 > |C| = 0 (notice strict inequality
right).
particular, Borda Veto sensitive scoring protocols.
Remark 2. Generally, scoring protocol |C|1 > |C| , equivalent sensitive
scoring protocol obtained subtracting |C| coordinate-by-coordinate basis
vector
~ . Moreover, observe protocol scoring protocol
sensitive, |C| = 0, |C|1 = 0. case, three candidates equivalent
plurality protocol, interesting formulations manipulation problem
tractable even worst-case. Therefore, sufficient restrict results
sensitive scoring protocols.
next consider types manipulations, state appropriate complexity results,
introduce notations.
Remark 3. discuss constructive cases, goal trying make candidate
win, opposed destructive manipulation, goal make candidate lose.
Constructive manipulations always least hard (in worst-case sense)
destructive counterparts, cases strictly harder (if one able determine
whether p made win, one also ask whether 1 candidates
made win, thus making p lose).
Definition 2. Individual-Manipulation (IM) problem, given
votes, preferred candidate p. asked whether way manipulator
cast vote p wins.
2. standard assumption, also made, example, work Conitzer Sandholm (2002),
Conitzer, Lang, Sandholm (2003).

160

fiJunta Distributions

Bartholdi Orlin (1991) show IM N P-complete Single Transferable Vote,
provided number candidates unbounded. However, problem P
well-known voting schemes, hence studied here.
lions share paper, consider coalitional manipulation setting.
scenario, set V voters partitioned two subsets: set V1 = {v1 , . . . , vn }
manipulative, untruthful, voters; set V2 = {vn+1 , . . . , vn+N } nonmanipulative voters. set candidates C = {c1 , . . . , cm , p}. manipulators goal
make distinguished candidate p win election, coordinating rankings
candidates. CWM SCWM problems, manipulators full knowledge
nonmanipulators votes.
Definition 3. Coalitional-Weighted-Manipulation (CWM) problem,
given set voters V = V1 ] V2 , set candidates C, weights voters,
preferred candidate p C. addition, given votes voters V2 ,
assume manipulators aware votes. asked whether possible
manipulators V1 cast votes way makes preferred candidate p
win election.
know (Conitzer & Sandholm, 2002; Conitzer et al., 2003) CWM N P-complete
Borda, Veto, Single Transferable Vote, even 3 candidates, Maximin
Copeland least 4 candidates.
CWM version shall analyze, specifically tailored scoring protocols, slightly modified version whose analysis straightforward:
Definition 4. Scoring-Coalitional-Weighted-Manipulation (SCWM) problem, given initial score S[c] candidate c, weights manipulators
V1 , preferred candidate p. asked whether possible manipulators
V1 cast votes way makes preferred candidate p win election.
S[c] interpreted cs total score votes V2 . However,
require exist combination votes actually induces S[c] c.
Another setting shall shortly discuss (in Section 5) scenario
manipulators uncertain others votes.
Definition 5. Uncertain-Votes-Weighted-Evaluation (UVWE) problem,
given weight voter, distribution votes, candidate p,
number r [0, 1]. asked whether probability p winning greater r.
Definition 6. Uncertain-Votes-Weighted-Manipulation (UVWM) problem,
given single manipulative voter weight, weights voters,
distribution nonmanipulators votes, candidate p, number r,
r [0, 1]. asked whether manipulator cast vote p wins
probability greater r.
CWM N P-hard protocol, UVWE UVWM also N P-hard
protocol (Conitzer & Sandholm, 2002).
make assumption given distributions nonmanipulators votes
sampled polynomial time. words, given distribution nonmanipulators votes, possible obtain specific instance polynomial time.
161

fiProcaccia & Rosenschein

2.2 Probability Theory Tools
following lemma much use later on. Informally, states average
independent identically distributed (i.i.d.) random variables almost always close
expectation.
Lemma 1 (Chernoffs Bounds). (Alon & Spencer, 1992) Let X1 , . . . , Xt i.i.d. random
variables Xi b E[Xi ] = . > 0, holds that:
Pr[ 1t

Pt

2t

2
(ba)2

Pr[ 1t

Pt

2t

2
(ba)2

i=1 Xi + ] e
i=1 Xi ] e

Another tool shall require Central Limit Theorem. purposes,
implies probability sum random variables takes values small
segment small.
Lemma 2 (Central Limit Theorem). (Feller, 1968) Let Xt , . . . , Xt independent continuous random variables common density function, expected value variance
2 . < b:
"
#
Pt
Z b
x2
X
1

i=1

Pr <
< b
e 2 dx.

2

3. Approach
section lay mathematical foundations required average-case analysis
complexity manipulations. definitions general possible;
applied manipulation mechanism, merely manipulation
voting protocols.
describe distribution instances problem collection distributions
= {n }nN , n distribution instances x |x| = n. wish
analyze problems whose instances distributed respect distribution focuses
hard-to-manipulate instances. Ideally, would like ensure one manages
produce algorithm usually manipulate instances according distinguished
difficult distribution, algorithm would also usually succeed instances
distributed respect reasonable distributions.
Definition 7. Let = {n }nN distribution possible instances N Phard manipulation problem . junta distribution following
properties:
1. Hardness: restriction manipulation problem whose possible
instances only:
[
{x : |x| = n n (x) > 0}.
nN

Deciding restricted problem still N P-hard.
162

fiJunta Distributions

2. Balance: exist constant c > 1 N N n N :
1
1
Prxn [M (x) = yes] 1 .
c
c
3. Dichotomy: n instances x |x| = n:
n (x) 2polyn n (x) = 0.
voting manipulation problem, also require following property:
4. Symmetry: Let v nonmanipulative voter, let c1 , c2 6= p two candidates,
let {1, . . . , m}. probability v ranks c1 ith place
probability v ranks c2 ith place.
coalitional manipulation problem, also require following property:
5. Refinement: Let x instance |x| = n n (x) > 0; manipulators
voted identically, p would elected.
name junta distribution comes idea distribution, relatively powerful difficult instances represent problem instances.
Alternatively, intent problematic distributions (the family junta distributions) convincingly represent distributions respect average-case
analysis.
first three properties basic, relevant problems manipulating
mechanism. definition modular, additional properties may added top
basic three, case one wishes analyze mechanism voting protocol.
exact choice properties extreme importance (and, mentioned above,
may arguable). shall briefly explain choices. Hardness meant ensure
junta distribution contains hard instances. Balance guarantees trivial algorithm
always accepts (or always rejects) significant chance failure. dichotomy property helps preventing situations distribution gives (positive but) negligible
probability hard instances, high probability several easy instances.
examine properties specific manipulation problems. necessity symmetry best explained example. Consider CWM STV 3.
One could design distribution p wins distinguished candidate loses
first round. distribution could tailored satisfy conditions,
misses many hard instances. context SCWM, interpret symmetry
following way: every two candidates c1 , c2 6= p R,
Pr [S[c1 ] = y] = Pr [S[c2 ] = y].

xn

xn

Refinement less important four properties, seems help concentrating probability hard instances. Observe refinement relevant
coalitional manipulation; believe analysis individual voting manipulation
problems, first four properties sufficient.
163

fiProcaccia & Rosenschein

Definition 8. (Trevisan, 2002) distributional problem pair hL, L decision
problem distribution set {0, 1} possible inputs.
Informally, algorithm heuristic polynomial time algorithm distributional
problem runs polynomial time, fails small fraction inputs.
give formal definition; definition inspired Trevisan (2002) (there
name used somewhat different definition).
Definition 9. Let manipulation problem let hM, distributional problem.
1. algorithm deterministic heuristic polynomial time algorithm distributional manipulation problem hM, always runs polynomial time,
exists polynomial p degree least 1 N N n N :
Pr [A(x) 6= (x)]

xn

1
.
p(n)

(1)

2. Let probabilistic algorithm, uses random string s. probabilistic heuristic polynomial time algorithm distributional manipulation problem
hM, always runs polynomial time, exists polynomial p degree
least 1 N N n N :
Prn [A(x) 6= (x)]

x ,s

1
.
p(n)

(2)

Probabilistic algorithms two potential sources failure: unfortunate choice
input, unfortunate choice random string s. success failure deterministic
algorithms depends choice input.
combine definitions introduced section attempt establish
mechanism susceptible manipulation average case. following definition abuses notation bit: used refer manipulation itself,
corresponding decision problem.
Definition 10. say mechanism susceptible manipulation
exists junta distribution , exists deterministic/probabilistic heuristic
polynomial time algorithm hM, i.

4. Formulation, Proof, Justification Main Result
Recall (Conitzer & Sandholm, 2002; Conitzer et al., 2003) Borda Veto, CWM
N P-hard, even 3 candidates. Since Borda Veto examples sensitive scoring
protocols, would like know resistant family protocols really respect
coalitional manipulation. section use methods previous section
prove main result:
Theorem 1. Let P sensitive scoring protocol. = O(1) P , candidates
C = {p, c1 , . . . , cm }, susceptible SCWM.
164

fiJunta Distributions

Intuitively, instances CWM (or SCWM) hard require
specific partitioning voters V1 subsets, subset votes unanimously.
instances rare reasonable distribution; insight ultimately yield
theorem.
following proposition generalizes Theorem 1 Conitzer Sandholm (2002)
Theorem 2 Conitzer, Lang Sandholm (2003), justifies focus family
sensitive scoring protocols. stronger version Proposition 1 independently
proven Hemaspaandra Hemaspaandra (2005). Nevertheless, include proof,
since required proving hardness property junta distribution shall
design.
Proposition 1. Let P sensitive scoring protocol. CWM P N P-hard, even
3 candidates.
Definition 11. Partition problem, given set integers {ki }i[t] , summing
2K, asked whether subset integers sum K.
well-known Partition N P-complete.
Proof Proposition 1. reduce arbitrary instance Partition following
CWM instance. 3 candidates, a, b, p. V2 , K(41 22 ) 1
voters voting b p, K(41 22 ) 1 voters voting b p. V1 ,
every ki vote weight 2(1 + 2 )ki . Observe V2 , b get
(K(41 22 ) 1)(1 + 2 ) points.
Assume first partition exists. Let voters V1 one half partition
vote p b, let half vote p b a. vote, b
(K(41 22 ) 1)(1 + 2 ) + 2K(1 + 2 )2 = (1 + 2 )(4K1 1)
votes, p (1 + 2 )4K1 points; thus manipulation.
Conversely, assume manipulation exists. Clearly must exist manipulation
voters V1 vote either p b p b a, manipulators
gain anything placing p top scoring protocol. manipulation, p
(1 + 2 )4K1 points, b already (K(41 22 ) 1)(1 + 2 ) points
V2 . Therefore, b must gain less (22 K + 1)(1 + 2 ) points voters
V1 . voter corresponding ki contributes 2(1 + 2 )2 ki points; follows
sum ki corresponding voters voting p b less K + 21 2 ,
likewise voters voting p b a. Equivalently, sum K, since
ki integers 2 1. cases sum must K; hence,
partition.
Since instance CWM translated instance SCWM obvious
way, have:
Corollary 1. Let P sensitive scoring protocol. holds SCWM P N P-hard,
even 3 candidates.
165

fiProcaccia & Rosenschein

4.1 Junta Distribution
Let w(v) denote weight voter v, let W denote total weight votes
V1 ; P sensitive scoring protocol. denote |V1 | = n: size V1 size
instance.
Consider distribution = {n }nN instances SCWM P , + 1
candidates p, c1 , . . . , cm , n induced following sampling algorithm:
1. Fix polynomial q = q(n).
2. v : Randomly independently choose w(v) [0, 1] (up O(n) bits precision, i.e., intervals 1/2q(n) ).
3. {1, . . . , m}: Randomly independently choose S[ci ] [(1 2 )W, 1 W ] (up
O(n) bits precision).
Remark 4. Although distribution fact discrete weights, example,
uniformly distributed {0, 1/2q(n) , 2/2q(n) , 3/2q(n) , . . . , 1} treat continuous
sake clarity.
assume S[p] = 0, i.e., voters rank p last. assumption
restriction. holds candidate c S[c] S[p], candidate c surely lose,
since manipulators rank p first. Therefore, S[p] > 0, may simply normalize
scores subtracting S[p] scores candidates. equivalent
assumption.
Remark 5. believe natural distribution respect
coalitional manipulation scoring protocols studied. Even one disagrees
exact definition junta distribution, satisfy many reasonable conditions
one could produce.
shall, course, (presently) prove distribution possesses properties
junta distribution.
Proposition 2. Let P sensitive scoring protocol. junta distribution
SCWM P C = {p, c1 , . . . , cm }, = O(1).
Proof. first observe symmetry obviously satisfied, dichotomy holds Remark 4.
proof hardness property relies reduction Partition Proposition 1. reduction generates instances x CWM P 3 candidates,
W = 4(1 + 2 )K,
S[a] = S[b]
= (K(41 22 ) 1)(1 + 2 )
= (1 2 /2)W (1 + 2 ),
166

fiJunta Distributions

K originates Partition instance. instances satisfy (1 2 )W
S[a], S[b] 1 W . follows (x) > 0 (after scaling weights).3
prove balance property. i, S[ci ] > (1 2 /m)W ,
clearly manipulation, since least 2 W points given voters
V1 undesirable candidates c1 , . . . , cm . happens probability least m1m .
hand, consider situation i,
S[ci ] < (1

m2 1
2 )W ;
m2

(3)

occurs probability least (m12 )m . Intuitively, manipulators could distribute
votes way undesirable candidate ranked last exactly 1/mfraction votes, would successful manipulation: undesirable candidate
would gain additional m1
2 W points. Unfortunately, usually
case, following condition sufficient successful manipulation (assuming condition (3) holds). Partition manipulators disjoint subsets P1 , . . . , Pm (w.l.o.g.
size n/m), denote WPi total weight votes Pi . condition
{1, . . . , m}:
(1 1/m) 1/2 n/m WPi (1 + 1/m) 1/2 n/m.

(4)

condition sufficient, voters Pi rank ci last, fraction
votes V1 gives ci points most:
(m 1)(1 + 1/m)
m2 1
= 2
.
(m 1)(1 + 1/m) + 1 1/m
+m2
Hence number points ci gains manipulators most:
m2 1
m2 1

W

2 W < 1 W S[ci ].
2
m2 + 2
m2
Furthermore, Lemma 1 fact expected total weight n/m votes
2n
1/2 n/m, probability condition (4) holds least 1 2e m3 . Since
constant, probability larger 1/2 large enough n.
Finally, easily seen refinement property: manipulators
rank p first candidate c second, p gets 1 W points, c gets 2 W + S[c] points.
S[c] (1 2 )W , thus p surely loses.
4.2 Heuristic Polynomial Time Algorithm
present algorithm Greedy SCWM, given Algorithm 1. w
~ denotes
vector weights voters V1 = {v1 , . . . , vn }.
3. seems reduction generalized larger number candidates. hard instances
ones undesirable candidates two approximately (1 2 )W initial points,
two problematic candidates approximately (1 /2)W points. instances positive
probability .

167

fiProcaccia & Rosenschein

Algorithm 1 Decides SCWM
1: procedure Greedy(S, w,
~ p)
2:
c C
3:
S0 [c] S[c]
4:
end
5:
= 1 n
6:
Let j1 , j2 , . . . , jm s.t. l, Si1 [cjl1 ] Si1 [cjl ]
7:
Voter vi votes p cj1 cj2 . . . cjm
8:
l = 1
9:
Si [cjl ] Si1 [cjl ] + w(ti )l+1
10:
end
11:
Si [p] Si1 [p] + w(ti )1
12:
end
13:
argmaxcC Sn [c] = {p}
14:
return true
15:
else
16:
return false
17:
end
18: end procedure

. Initialization

. voters V1

. Update score

. p wins

voters V1 , according order, rank p first, rest candidates current score: candidate lowest current score ranked highest.
Greedy accepts p wins election.
algorithm, designed specifically scoring protocols, realization abstract
greedy algorithm: stage, voter vi ranks undesirable candidates order
minimizes highest score undesirable candidate obtains current vote.
tie among several permutations, voter chooses option
second highest score low possible, etc. case, every manipulator always ranks
p first.
Remark 6. abstract scheme might also appropriate protocols Maximin
Copeland. Similarly scoring protocols, two protocols manipulators
always better ranking p first. addition, abstract greedy algorithm
applied Maximin Copeland since result election based score
candidate (unlike STV, example).
Remark 7. Greedy considered generalization greedy algorithm given
Bartholdi et al. (1989a).
following lemmas, stage execution algorithm iteration
loop.
Lemma 3. exists stage i0 execution Greedy, two candidates
a, b 6= p,
|Si0 [a] Si0 [b]| 2 ,
(5)
i0 holds |Si [a] Si [b]| 2 .
168

fiJunta Distributions

Proof. proof induction i. base induction given equation (5).
Assume |Si [a] Si [b]| 2 , without loss generality: Si [a] Si [b].
algorithm, voter vi+1 ranks b higher a, therefore:
Si+1 [b] Si+1 [a] 2 .

(6)

Since p always ranked first, weight vote 1, b gains 2
points. Therefore:
Si+1 [b] Si+1 [a] 2 .
(7)
Combining equations (6) (7) completes proof.
Lemma 4. Let p 6= a, b C, suppose exists stage i0 Si0 [a]
Si0 [b], stage i1 i0 Si1 [b] Si1 [a]. i1 holds
|Si [a] Si [b]| 2 .
Proof. Assume exists stage i0 Si0 [a] Si0 [b], stage i1 i0
Si1 [b] Si1 [a]; w.l.o.g. i1 > i0 (otherwise stage i0 holds Si0 [b] = Si0 [a],
finish Lemma 3). must stage i2 i0 i2 < i1
Si2 [a] Si2 [b] Si2 +1 [b] Si2 +1 [a]. Since weight vote 1, b gains
2 points voter vi2 +1 . Hence conditions Lemma 3 hold stage i2 ,
implies i2 : |Si [a] Si [b]| 2 . particular, i1 i2 .
Lemma 5. Let P sensitive scoring protocol, assume Greedy errs instance
SCWM P successful manipulation. {2, 3, . . . , m},
subset candidates = {cj1 , . . . , cjd }, that:

X
i=1

(1 W S[cji ])

d1
X

(i 2 ) W

i=1


X
i=1

m+2i


X

(1 W S[cji ]).

(8)

i=1

Proof. right inequality, candidates, even ifP
voters V1 rank last
every vote, total points distributed among W di=1 m+2i . inequality
hold, must candidate ci gains least 1 W S[ci ] points
manipulators, implying candidate least 1 W points. However, p
also 1 W points, assumed successful manipulation
contradiction.
left inequality, assume algorithm erred. stage i0 ,
candidate cj0 total least 1 W points (w.l.o.g. one candidate passes
threshold simultaneously). Denote V10 = {v1 , v2 , . . . , vi0 }, let WV10 total weight
voters V10 . Voter vi0 rank cj0 last, since m+1 = 0, thus ranking
candidate last gives points. another candidate cj1 , that:
Si0 1 [cj1 ] Si0 1 [cj0 ]. Lemma 4, Si0 [cj0 ] Si0 [cj1 ] 2 , thus Si0 [cj1 ] 1 W 2 .
candidates always ranked last voters V10 , must another
candidate cj2 ranked strictly higher voter V10 , w.l.o.g. higher cj1 .
Therefore, Lemma 4 that: Si0 [cj1 ] Si0 [cj2 ] 2 , cj2 total
least 1 W 22 points. inductively continuing reasoning, obtain subset
candidates (possibly = m), always ranked last places voters
169

fiProcaccia & Rosenschein

V10 , lth candidate holds that: Si0 [cjl ] 1 W (l 1)2 . total points
gained lth candidate stage i0 must least 1 W (l 1)2 S[cjl ]. Since
P
total points distributed voters V10 last candidates WV10 di=1 m+2i ,
have:

X

(1 W S[cji ])

i=1

d1
X

(i 2 ) WV10


X

i=1

m+2i W

i=1


X

m+2i .

i=1

Lemma 6. Let SCWM sensitive scoring protocol P C = {p, c1 , . . . , cm },
m=O(1). Greedy deterministic heuristic polynomial time algorithm hM, i.
Proof. obvious given instance successful manipulation,
greedy algorithm would indeed answer manipulation, since algorithm
constructive (it actually selects specific votes manipulators).
wish bound probability manipulation algorithm erred.
Lemma 5, necessary condition occur specified equation (8),
equivalently:
W


X

1 W

i=1


X
i=1




X
X
X
d(d 1)
m+2i
2
S[cji ] W
1 W
m+2i .
2
i=1

i=1

(9)

i=1

case algorithm may err;
Pdwhat probability equation (9) holding? Fix
subset size {2, . . . , m}.
i=1 S[cji ] random variable takes values
[d(1 2 )W, d1 W ]. conditioning values S[cji ], = 1, . . . , 1,
P
probability di=1 S[cji ] taking values interval [a, b] chance
ba
S[cjd ] taking value interval size b a, 1 W (
, since S[cjd ]
1 2 )W
n

uniformly distributed. Lemma 1, W < n/4 probability (n) = e 8 .
hand, W n/4, (9) holds probability
d(d1)
2
2

1 W (1 2 )W

=

d(d 1)
2d(d 1)
1

=
,
2W
n
p (n)

polynomial pD . complete proof showing equation (1) holds:
Pr [Greedy(x) 6= (x)] Pr[W n/4 (D C s.t. |D| 2 (9) holds)]

xn



+ Pr[W < n/4]
X
1
DC:|D|2



pD (n)

+ (n)

1
poly n

last inequality follows assumption = O(1).
Clearly, Theorem 1 directly follows.
170

fiJunta Distributions

4.3 Algorithm 1 Uniform Distribution
previous subsection seen Algorithm 1 heuristic polynomial time
algorithm respect junta distribution . argued suggests
algorithm also well respect distributions. subsection
support claim showing Algorithm 1 also heuristic polynomial time
algorithm respect uniform distribution instances SCWM.
sake consistency previous results, shall consider uniform distribution
votes may produce unfeasible ballots. Nevertheless, equivalent results
obtained feasible (discrete) distributions votes. so, subsection assume
voter vi V2 , |V2 | = N , awards candidate c C, including p, score
independently uniformly distributed [0, 1 ]. Further, assume votes
unweighted; limit generality results, since use lower bounds
depend total weight manipulators V1 (where |V1 | = n)
individual weights consequence.
distinguish two cases results, depending ratio
number nonmanipulators N number manipulators n:

1. n/ N < 1/p(n) polynomial p degree least 1.

2. n/ N > p(log n) polynomial p degree least 1.
middle ground covered two cases remains open problem.
tackle first case, require lower bound sorts probability
instance SCWM easy decide. Since manipulators V1 award
candidate 1 n points, manipulators cannot make candidate c beat another
candidate c0 S[c0 ] S[c] > 1 n. particular, every two candidates c c0 holds
|S[c] S[c0 ]| > 1 n, manipulators cannot affect outcome election.
Moreover, Algorithm 1 always decides instance correctly: S[p] < S[c]
c, instance instance, case algorithm never errs;
S[p] > S[c] c, instance yes instance, vote manipulators
sufficient make p win. obtained following Lemma:
Lemma 7. Consider instance SCWM c, c0 C, |S[c] S[c0 ]| > 1 n.
instance yes instance iff S[p] > S[c] candidates c 6= p,
instance correctly decided Algorithm 1.
Lemma, together Central Limit Theorem, yields first result.
Proposition 3. Algorithm 1 heuristic polynomial time algorithm
respect

uniform distribution instances SCWM satisfy n/ N < 1/p(n)
polynomial p(n) degree least 1.
Proof. Lemma 7, sufficient bound probability c, c0 C,
|S[c] S[c0 ]| > 1 N .
Pr[c, c0 C, |S[c] S[c0 ]| > 1 N ] = 1 Pr[c, c0 C s.t. 0 S[c] S[c0 ] 1 N ].
171

fiProcaccia & Rosenschein

union bound:
Pr[c, c0 C s.t. 0 S[c] S[c0 ] 1 n]

X

Pr[0 S[c] S[c0 ] 1 n].

c,c0 C

Fix c, c0 C, let Xi si [c] si [c0 ], si score given candidate
voter vi V2 , = n + 1, . . . , n + N . Xi i.i.d. continuous random variables
expectation 0 constant variance 2 = 2 (1 )2 /12 = (1 )2 /6. Therefore, apply
Lemma 2:
"
#
n+N
X


Pr 0 S[c] S[c0 ] 1 n = Pr 0
Xi 1 n
"
= Pr 0

i=n+1
Pn+N

i=n+1 X



Z
1

2 0
Z 1 n
N

1 dx

N

N

n
1
N

e

x2
2

1 n

N

#

dx

0

1 n
=
N


n
=O
.
N
assumption regarding ratio manipulators nonmanipulators,
inverse-polynomial n. Rolling back, obtain probability algorithm
1
correct least 1 (m + 1)m p(n)
, result follows fact = O(1).
Moving second case, require following lemma:
2
Lemma 8. Let = 2(m+1)
, consider instance SCWM c, c0 C,
0
|S[c] S[c ]| < n. instance yes instance, correctly decided
Algorithm 1.

Proof. Obviously, sufficient prove algorithm constructively finds successful
vote makes p win. Let C 0 C \ {p} set undesirable candidates
maximal score among candidates C \ {p} stage execution
algorithm. algorithm, stage candidate C 0 ranked last
voter V1 , i.e., given 0 points; candidates C 0 receive stage
2 points. Therefore, total number points candidates C 0 receive
manipulators (d 1)2 n, |C 0 | = d. Consequently, [c] score
candidate c algorithm terminates,
X
X
[c]
S[c] + (d 1)2 n.
cC 0

cC 0

172

fiJunta Distributions

Let c0 = argmaxcC 0 S[c], c1 = argmaxcC 0 [c]. Lemma 4, algorithm
terminates holds scores candidates C 0 within 2 one another.
Therefore:
X
X
[c1 ]
S[c] + (d 1)2 n
[c] dS [c0 ] + (d 1)2 n (d 1)(S [c1 ] 2 ).
c1 6=cC 0

cC 0

algebraic manipulations, obtain:




d1

d1

[c1 ] S[c0 ] + n
2 +
2 S[c0 ] + n
2 +
2 .


m+1
m+1
Now, that:


[p]



[c1 ]





2 n +
2
(S[p] + 1 n)
+
m+1
m+1


2


1 n
n
2 n
2
2(m + 1)
m+1
m+1

2
n
2

2(m + 1)
m+1
> 0.


S[c0 ]



second transition follows assumption S[p] S[c0 ]n, third transition
fact 1 2 , last transition holds large enough n.
Proposition 4. Algorithm 1 heuristic polynomial time algorithm
respect

uniform distribution instances SCWM satisfy n/ N > p(log n)
polynomial p degree least 1.
Proof. Let =
least:

2
2(m+1) .

Lemma 8, probability algorithm err

Pr[c, c0 C, |S[c] S[c0 ]| < n] = 1 Pr[c, c0 C s.t. S[c] S[c0 ] > n].
union bound:
Pr[c, c0 C s.t. S[c] S[c0 ] > n]

X

Pr[S[c] S[c0 ] > n].

c,c0 C

before, fix c, c0 C, let Xi si [c] si [c0 ], si score given
candidate voter vi . Xi i.i.d. random variables expectation 0, take
values [1 , 1 ]. Applying Lemma 1 variables, obtain:
2

n+N
( n )
n
1 X
0 n2
2N N 2
0
(21 )
Xi E[Xi ] + ] e
= e N ,
Pr[S[c] S[c ] n] = Pr[
N
N
i=n+1

0 constant. result follows fact constant
assumption regarding relation n N .
173

fiProcaccia & Rosenschein

5. Case Uncertainty Votes
far dealt setting entire coalition manipulators trying
influence outcome election, using complete knowledge nonmanipulators
votes. section short aside, discuss setting single
manipulator uncertainty others votes. shall prove:
Theorem 2. Let P voting protocol exists junta distribution P
instances UVWM P , following property: r uniformly distributed
[0, 1]. P , candidates C = {p, c1 , . . . , cm }, = O(1), susceptible UVWM.
Recall UVWM, ask whether manipulator cast vote p
wins probability greater r. existence junta distribution r uniformly distributed weak requirement (it even quite natural r uniformly
distributed). fact, following claim likely true:
Conjecture 1. Let P voting protocol UVWM N P-hard. exists
junta distribution P instances UVWM P , r uniformly distributed
[0, 1].
conjecture indeed true, voting protocols susceptible
UVWM. reason conjecture true respect definition junta
distributions, perhaps definition restrictive modified accordingly. also remark similar results derived destructive manipulations
analogous proofs.
prove Theorem 2, first present helpful procedure, decides UVWE. w
~
denotes vector given weights, given distribution votes.
number voters |V | = n.
Sample(C = {p, c1 , . . . , cm }, w,
~ , r)
1: count = 0
2: = 1 n3
3:
Sample distribution votes
4:
Calculate result election using sampled votes
5:
p
6:
count = count + 1
7:
end
8: end
9: count/n3 > r
10:
return 1
11: else
12:
return 0
13: end
Sample samples given distribution votes n3 times, calculates winner
election time. p r-fraction elections procedure
accepts, otherwise rejects.
174

fiJunta Distributions

Lemma 9. Let P voting protocol, E UVWE P C = {p, c1 , . . . , cm }.
Furthermore, let distribution instances E, r uniformly distributed
[0, 1]. exists N n N :
Pr [Sample(x) 6= E(x)]

xn

1
.
polyn

3

Proof. Let {Xi }ni=1 random variables, Xi = 1 p ith iteration
loop, Xi = 0 otherwise. Let r0 probability p wins given
instance. Lemma 1 union bound:
fi
fi

3
fi X
fi
fi1 n
fi
3 1
1
Pr fifi 3
Xi r0 fifi 2e2n n2 = 2e2n .
fin
fi n
i=1

deduce |r r0 | > n1 , Sample fail exponentially small probability.
assumption r uniformly distributed, probability |r r0 | n1
2/n. Thus, union bound holds that:




1
1
0
0
Pr [Sample(x) 6= E(x)] Pr |r r |
+ Pr |r r | > Sample(x) 6= E(x)
xn
n
n
2/n + 2e2n
1
.

polyn

present algorithm decides UVWM. Here, w
~ denotes weights
voters including manipulator, given distribution nonmanipulators
votes.
Sample-and-manipulate(C = {p, c1 , . . . , cm }, w,
~ , r)
1: ans = 0
2: = 1 (m + 1)!
3:
= next permutation + 1 candidates
4:
= manipulator always votes , others votes distributed respect
5:
Sample(C, w,
~ , r) = 1
6:
ans = 1
7:
end
8: end
9: return ans
Given instance UVWM, Sample-and-Manipulate generates (m+1)! instances
UVWE problem, one manipulators possible votes, executes Sample
instance. Sample-and-Manipulate accepts Sample accepts one
instances.
175

fiProcaccia & Rosenschein

Lemma 10. Let P voting protocol, UVWM P C = {p, c1 , . . . , cm },
= O(1). Furthermore, let distribution instances UVWM, r
uniformly distributed [0, 1]. Sample-and-Manipulate probabilistic heuristic
polynomial time algorithm hM, i.
Proof. independent call Sample, chance failure inverse-polynomial.
applying union bound probability Sample failing
1
(m + 1)! invocations (m + 1)! polyn
, still inverse-polynomial since
constant. lemma follows fact manipulation
permutation candidates, manipulator votes according
permutation, chance p winning greater r.
Notice Sample-and-Manipulate indeed polynomial fact = O(1),
assumed given distribution votes sampled polynomial
time.

6. Related Work
Computational aspects voting long investigated. pivotal issue problem
winner-determination: voting protocols designed satisfy theoretical desiderata may
quite complex. Consequently, deciding election governed protocols may
computationally hard problem (Bartholdi, Tovey, & Trick, 1989b). Another concern
strategic behavior part officials conducting election, may add
remove voters candidates slate. computational complexity strategically
controlling election analyzed Bartholdi, Tovey Trick (1992).
said, main issue respect strategic behavior voting always
manipulation voters. growing body work deals worst-case
complexity manipulating elections. seminal paper Bartholdi, Tovey
Trick (1989a); authors suggested, first time, computational complexity
obstacle strategic voters must overcome. Indeed, although shown
many voting protocols efficiently manipulated, nevertheless proven
voting protocol, namely second-order Copeland, N P-hard manipulate.
Bartholdi Orlin (1991) demonstrated prominent Single Transferable Vote
(STV) protocol N P-hard manipulate.
Even voting protocols easy manipulate, difficulty artificially introduced adding preround (Conitzer & Sandholm, 2003); candidates paired,
pairing two candidates, candidate loses pairwise election
two eliminated. Plurality, Borda Maximin shown hard manipulate
augmented preround. detail, protocols N P-hard manipulate scheduling preround precedes voting, #P-hard voting precedes
scheduling, PSPACE-hard voting scheduling interleaved. Elkind
Lipmaa (2005a) induce hardness manipulation using general approach. Hybrid
voting protocols hard manipulate constructed composing several base
protocols; base protocols may individually easy manipulate.
Another case manipulation may hard, worst-case, election
multiple winners instead single winner, case elections parliament
176

fiJunta Distributions

assembly. Procaccia, Rosenschein, Zohar (2007) demonstrate manipulation
Cumulative voting, major protocol multi-winner elections, N P-hard.
coalitional manipulation problem, focus paper, first
investigated Conitzer Sandholm (2002, 2003). setting, computational
problem made difficult fact numerous manipulators must coordinate
strategy (and additionally, introduction weighted voting). hardness
results abovementioned papers relied number candidates unbounded,
Conitzer Sandholm present hardness results coalitional manipulation setting
constant number candidates, respect several central voting protocols.
Elkind Lipmaa (2005b) extend preround approach presented Conitzer
Sandholm (2003) coalitional manipulation setting. context, provide
early impossibility result regarding average-case complexity manipulations:
authors present family preference profiles manipulator always improve
outcome voting strategically, regardless preround schedule. result applies
seeking make manipulation hard adding preround. Further, one would
usually expect distributions instances coalitional manipulation problem
give family preference profiles significant probability, extremely restricted.
recent result regarding average-case complexity manipulation, complements
own, presented Conitzer Sandholm (2006). authors put forward two
properties instances coalitional manipulation problem, demonstrate
instance satisfies properties easy manipulate. first property
instance satisfy weaker form monotonicity property seems natural;
second property manipulators able make one exactly two candidates win
election property much harder accept. order justify second
property, authors show many voting protocols property usually holds,
respect specific family distributions.
result two main shortcomings compared ours. First, arguments favor
second property mentioned empirical rather analytical; second,
family distributions considered special sense case
here. words, family distributions question priori especially hard
manipulate. hand, result advantages: unlike ours,
depend number candidates constant (although experiments
number candidates manipulators extremely small compared number
voters), (arguably) require significant restrictions voting rule.

7. Conclusions
date, results complexity manipulation considered worst case. Although better nothing, results weak guarantee resistance manipulation.
truly worthy goal design voting protocol hard manipulate average
case plausible social choice point view, far attempts
failed.
Motivated this, presented specific manipulation setting worst-case
hard average-case tractable. first prepared ground average-case
analysis borrowing several concepts existing theory introducing several
177

fiProcaccia & Rosenschein

new ideas. key approach junta distributions, presumably concentrate
hard instances coalitional manipulation problem. considered voting
protocol susceptible coalitional manipulation algorithm almost
always correctly decides problem, instances distributed respect
junta distribution.
main result states sensitive scoring protocols susceptible coalitional manipulation number candidates constant, although hard manipulate
even number candidates constant.
7.1 Discussion
results, first foremost, suggest worst-case hardness indeed strong
enough barrier manipulation. motivates research regarding averagecase complexity manipulations, expense future investigations worst-case
complexity.
Moreover, view, main result provides evidence voting rule
average-case hard manipulate exist. least, suggests
scoring protocols cannot form basis protocol usually strategy resistant.
Nevertheless, negative result circumvented many ways.
First, circumvented via voting protocol. Scoring protocols among
easiest voting systems manipulate, structure quite simple
concisely represented. protocols, say STV, inherently harder deal with. fact,
recall STV worst-case hard manipulate one manipulator (but
unbounded number candidates) (Bartholdi & Orlin, 1991), whereas scoring protocols
certainly not.
Second, circumvented via setting. results hold one contemplates coalitional manipulation constant number candidates. constant number
candidates known guarantee worst-case hardness, may case allowing large number candidates would make difference respect average-case
analysis.
Third, circumvented via distribution. Traditional average-case complexity
theory deals hardness distributional problems; words, specific distribution
considered. Junta distributions chosen way one usually
manipulated algorithm, presumably algorithm would successful
distributions. view supported results Section 4.3, point
strong theoretical guarantees, may certainly true
specific distribution instances manipulation problem average-case
hard manipulate, even scoring protocol considered.
Section 4.3 deserves aside. lemmas established show that, respect
uniform distribution, even completely trivial algorithm usually decide
coalitional manipulation problem: number manipulators small (less
square root number voters), manipulators rarely influence outcome
election; therefore, p elected nonmanipulators well, usually
correct answer yes, not, usually correct answer no. number
manipulators large, usually correct answer yes manipulation.
178

fiJunta Distributions

Recent preliminary results direction imply true several families
voting rules, large variety distributions. important note
simple algorithm would work well respect junta distribution .
7.2 Future Research
view, central contribution paper establishes framework
used study average-case complexity manipulations protocols,
even generally, mechanisms. Indeed, voting general method
preference aggregation, issues also relevant one considers mechanisms
specific settings. One mechanism aware, whose manipulation
N P-hard, presented Bachrach Rosenschein (2006). definitions Section 3
sufficiently general deal different mechanisms preference aggregation.
still room debate exact definition junta distribution. may
also case unconvincing distributions satisfy (current)
conditions junta distribution. might prove especially fruitful show heuristic
polynomial time algorithm respect junta distribution guaranteed
property respect easy distributions, uniform distribution.
issue great importance coming natural criteria decide manipulation problem hard average-case. traditional definition average-case
completeness difficult work general; satisfying definition
applies specifically case manipulations? subject fully understood, understanding surely shed light great mystery: voting
protocols usually hard manipulate?

Acknowledgments
work partially supported grant #898/05 Israel Science Foundation.

References
Alon, N., & Spencer, J. H. (1992). Probabilistic Method. Wiley Sons.
Bachrach, Y., & Rosenschein, J. S. (2006). Achieving allocatively-efficient strongly
budget-balanced mechanisms network flow domain bounded-rational agents.
Seventh International Workshop Agent-Mediated Electronic Commerce:
Designing Mechanisms Systems, Utrecht, Netherlands (AMEC 2005), No.
3937 Lecture Notes Artificial Intelligence, pp. 7184. Springer-Verlag, Berlin.
Bartholdi, J., & Orlin, J. (1991). Single transferable vote resists strategic voting. Social
Choice Welfare, 8, 341354.
Bartholdi, J., Tovey, C. A., & Trick, M. A. (1989a). computational difficulty manipulating election. Social Choice Welfare, 6, 227241.
Bartholdi, J., Tovey, C. A., & Trick, M. A. (1989b). Voting schemes
difficult tell election. Social Choice Welfare, 6, 157165.
179

fiProcaccia & Rosenschein

Bartholdi, J., Tovey, C. A., & Trick, M. A. (1992). hard control election.
Mathematical Computer Modelling, 16, 2740.
Conitzer, V., Lang, J., & Sandholm, T. (2003). many candidates needed make
elections hard manipulate?. Proceedings International Conference
Theoretical Aspects Reasoning Knowledge, pp. 201214.
Conitzer, V., & Sandholm, T. (2002). Complexity manipulating elections candidates. Proceedings National Conference Artificial Intelligence, pp. 314
319.
Conitzer, V., & Sandholm, T. (2003). Universal voting protocol tweaks make manipulation hard. Proceedings International Joint Conference Artificial Intelligence, pp. 781788.
Conitzer, V., & Sandholm, T. (2006). Nonexistence voting rules usually hard
manipulate. Proceedings Twenty-First National Conference Artificial
Intelligence, pp. 627634.
Elkind, E., & Lipmaa, H. (2005a). Hybrid voting protocols hardness manipulation.
16th Annual International Symposium Algorithms Computation, Lecture
Notes Computer Science, pp. 206215. Springer-Verlag.
Elkind, E., & Lipmaa, H. (2005b). Small coalitions cannot manipulate voting. International Conference Financial Cryptography, Lecture Notes Computer Science.
Springer-Verlag.
Ephrati, E., & Rosenschein, J. S. (1997). heuristic technique multiagent planning.
Annals Mathematics Artificial Intelligence, 20, 1367.
Feller, W. (1968). Introduction Probability Theory Applications (3rd edition).,
Vol. 1, p. 254. John Wiley.
Ghosh, S., Mundhe, M., Hernandez, K., & Sen, S. (1999). Voting movies: anatomy
recommender system. Proceedings Third Annual Conference Autonomous Agents, pp. 434435.
Gibbard, A. (1973). Manipulation voting schemes. Econometrica, 41, 587602.
Haynes, T., Sen, S., Arora, N., & Nadella, R. (1997). automated meeting scheduling system utilizes user preferences. Proceedings First International Conference
Autonomous Agents, pp. 308315.
Hemaspaandra, E., & Hemaspaandra, L. A. (2005). Dichotomy voting systems. University Rochester Department Computer Science Technical Report 861.
Procaccia, A. D., Rosenschein, J. S., & Zohar, A. (2007). Multi-winner elections: Complexity
manipulation, control winner-determination. Twentieth International
Joint Conference Artificial Intelligence (IJCAI 2007), Hyderabad, India. appear.
Satterthwaite, M. (1975). Strategy-proofness Arrows conditions: Existence correspondence theorems voting procedures social welfare functions. Journal
Economic Theory, 10, 187217.
180

fiJunta Distributions

Trevisan, L. (2002). Lecture notes computational complexity. Available
http://www.cs.berkeley.edu/luca/notes/complexitynotes02.pdf. Lecture 12.

181

fiJournal Artificial Intelligence Research 28 (2007) 393-429

Submitted 6/06; published 3/07

Bin Completion Algorithms Multicontainer Packing,
Knapsack, Covering Problems
Alex S. Fukunaga

fukunaga@aig.jpl.nasa.gov

Jet Propulsion Laboratory
California Institute Technology
4800 Oak Grove Drive
Pasadena, CA 91108 USA

Richard E. Korf

korf@cs.ucla.edu

Computer Science Department
University California, Los Angeles
Los Angeles, CA 90095

Abstract
Many combinatorial optimization problems bin packing multiple knapsack problems involve assigning set discrete objects multiple containers. problems used model task resource allocation problems multi-agent systems
distributed systms, also found subproblems scheduling problems.
propose bin completion, branch-and-bound strategy one-dimensional, multicontainer
packing problems. Bin completion combines bin-oriented search space powerful
dominance criterion enables us prune much space. performance
basic bin completion framework enhanced using number extensions, including nogood-based pruning techniques allow exploitation dominance
criterion. Bin completion applied four problems: multiple knapsack, bin covering,
min-cost covering, bin packing. show bin completion algorithms yield
new, state-of-the-art results multiple knapsack, bin covering, min-cost covering problems, outperforming previous algorithms several orders magnitude
respect runtime classes hard, random problem instances. bin packing problem, demonstrate significant improvements compared previous results,
show bin completion competitive current state-of-the-art cutting-stock
based approaches.

1. Introduction
Many NP-hard problems involve assigning set discrete objects multiple containers. one class problems, objective pack items set containers
without exceeding containers capacities. related class problems, goal
cover set containers filling least minimal level (quota) using set
items. containers items modeled one-dimensional objects
(possibly associated cost/value function), refer collectively problems
one-dimensional, multicontainer packing covering problems, simply multicontainer
packing problems.
One example multicontainer packing problem bin packing problem: Given
set items (numbers), fixed bin capacity, assign item bin sum
items assigned bin exceed bin capacity, number bins
c
2007
AI Access Foundation. rights reserved.

fiFukunaga & Korf

used minimized. example, given set items 6, 12, 15, 40, 43, 82, bin
capacity 100, assign 6, 12, 82 one bin, 15, 40, 43, another,
total two bins. optimal solution instance, since sum
items, 198, greater 100, hence least two bins required.
Multicontainer packing problems ubiquitous. model many important operations research problems cargo loading transport, also model many artificial
intelligence applications, allocation rationing resources tasks among
group agents. Multicontainer packing problems often found embedded subproblems complex, real-world combinatorial optimization problems. example
many constraint programming problems contain bin packing knapsack constraints
subproblems (e.g., Shaw, 2004). constraints core many scheduling
resource allocation problems.
paper, propose bin completion, new algorithm optimally solving multicontainer packing problems. begin Section 1.1 overview four representative, strongly NP-complete, multicontainer problems: (1) bin packing problem, (2)
multiple knapsack problem, (3) bin covering problem, (4) min-cost covering
problem.
Section 2, begin describing standard, item-oriented branch-and-bound
framework problems. traditional approach, items considered one
time. node search corresponds decision regarding assignment
item non-full container. Then, describe bin completion, alternative, binoriented branch-and-bound strategy two key features: (1) nodes search tree
correspond complete assignments items single bin, (2) dominance criteria
assignments items bins used prune search. Section 3 describes
extensions basic bin completion framework improve search efficiency, well
runtime memory usage node.
Sections 4-7, explore application bin completion framework four
specific, one-dimensional multicontainer packing problems. problem, review
previous work algorithms optimally solve problem, detail bin completion
algorithm problem, provide empirical comparison previous state-ofthe-art algorithm. apply bin completion multiple knapsack problem Section
4, show bin completion solver significantly outperforms Mulknap (Pisinger,
1999), previous state-of-the-art algorithm. min-cost covering problem (also called
liquid loading problem) first problem Christofides, Mingozzi,
Toth (1979) proposed early variant bin completion approach. Section 5,
show new bin completion algorithm significantly outperforms earlier algorithm
Christofides et al. Section 6, apply bin completion bin covering problem
(also known dual bin packing problem). show bin completion algorithm
significantly outperforms previous state-of-the-art algorithm Labbe, Laporte,
Martello (1995). Section 7, apply extended bin completion algorithm
bin packing problem. Although initial results promising (Korf, 2002, 2003),
best bin completion solver competitive current state art,
recent branch-and-price approach based cutting-stock problem formulation. Section 8
concludes discussion directions future work.

394

fiBin Completion Algorithms Multicontainer Problems

1.1 One-Dimensional, Multicontainer Packing Problems
consider class multicontainer packing problems: Given set items, must
assigned one containers (bins), item assigned one
container. item j weight wj associated it. Depending problem,
item j may also profit cost pj associated it. assume item
weights containers one-dimensional. real-world applications,
continuous call double auctions (Kalagnanam, Davenport, & Lee, 2001), model
applied directly. applications, lot-to-order matching problem, onedimensional model approximation (Carlyle, Knutson, & Fowler, 2001). consider
two types containers: (1) Containers capacity, sum weights
items assigned container cannot exceed capacity, (2) containers quota,
sum weights items assigned container must least large
quota. single container, well-known 0-1 knapsack
problem. See recent text Kellerer, Pferschy, Pisinger (2004) overview
work 0-1 Knapsack problem variants. paper, focus four
one-dimensional, multicontainer packing problems (1) bin packing, (2) multiple knapsack,
(3) bin covering, (4) min-cost covering.
1.1.1 Bin Packing Problem
bin packing problem, goal pack n items weights w1 , ..., wn bins
capacity c items packed fewest number bins, sum
weights items bin greater capacity. Classical applications bin
packing include classic vehicle/container loading problem (Eilon & Christofides, 1971),
well memory/storage allocation data. minimal number agents required
carry set tasks multiagent planning problem modeled bin packing
problem.
formally, bin packing problem formulated integer program:

minimize

n
X

yi

subject to:

i=1
n
X

wj xij cyi ,

= 1, ..., n

(2)

j=1
n
X

xij 1,

j = 1, ..., n

(3)

xij {0, 1}

= 1, ..., n, j = 1, ..., n

(4)

yi {0, 1},

= 1, ..., n

(5)

(1)

i=1

yi represents whether ith bin used (yi = 1 items assigned
bin i, yi = 0 otherwise), xij = 1 item j assigned bin i, 0 otherwise.
Constraint 2 ensures capacity violated bin instantiated,
constraint 3 ensures items assigned one bin.

395

fiFukunaga & Korf

standard formulation, assume bins capacity. However,
assumption restrictive, since instances bins different capacities (nonuniform bins) modeled introducing additional items constraints.
1.1.2 0-1 Multiple Knapsack Problem
Consider containers capacities c1 , ..., cm , set n items, item
weight w1 , ..., wn profit p1 , ..., pn . Packing items containers maximize
total profit items, sum item weights container
exceed containers capacity, item assigned one container
0-1 Multiple Knapsack Problem, MKP.
MKP natural generalization 0-1 Knapsack Problem
containers capacities c1 , c2 , ...cm . Let binary decision variable xij 1 item j
placed container i, 0 otherwise. 0-1 Multiple Knapsack Problem
formulated as:
maximize

n
X
X

subject to:

i=1 j=1
n
X

wj xij ci ,

= 1, ...,

(7)

j=1

X

xij 1,

j = 1, ..., n

(8)

xij {0, 1}

i, j.

(9)

pj xij

(6)

i=1

Constraint 7 encodes capacity constraint container, constraint 8 ensures
item assigned one container.
MKP numerous applications, including task allocation among group autonomous agents order maximize total utility tasks executed (Fukunaga,
2005), continuous double-call auctions (Kalagnanam et al., 2001), multiprocessor scheduling (Labbe, Laporte, & Martello, 2003), vehicle/container loading (Eilon & Christofides,
1971), assignment files storage devices order maximize number
files stored fastest storage devices (Labbe et al., 2003). special case MKP
studied right Multiple Subset-Sum Problem (MSSP),
profits items equal weights, i.e., pj = wj j (e.g., Caprara,
Kellerer, & Pferschy, 2000b 2000a,2003). application MSSP marble cutting
problem, given marble slabs, problem decide cut slabs
sub-slabs (each sub-slab processed product) order minimize
total amount wasted marble.
1.1.3 Bin Covering
Suppose n items weights w1 , ..., wn , infinite supply identical containers quota q. bin covering problem, also known dual bin packing problem
pack items containers number containers contain sets
items whose sums least q maximized. is, goal distribute, ration
396

fiBin Completion Algorithms Multicontainer Problems

items among many containers possible, given containers specified
quota must satisfied. Note total weight items placed container
greater q (we assume infinite capacity, although assigning additional item
bin whose quota already satisfies clearly suboptimal).
formally, bin covering problem formulated integer program:

maximize

n
X

yi

subject to:

i=1
n
X

wj xij qyi ,

= 1, ..., n

(11)

j=1
n
X

xij 1,

j = 1, ..., n

(12)

xij {0, 1}

= 1, ..., n, j = 1, ..., n

(13)

yi {0, 1},

= 1, ..., n

(14)

(10)

i=1

yi represents whether quota ith bin satisfied (yi = 1) (yi = 0),
xij = 1 item j assigned bin i, 0 otherwise. Constraint 11 ensures
quota satisfied bin instantiated, constraint 12 ensures items
assigned one bin.
Bin covering natural model resource task allocation among multiple agents
goal maximize number agents achieve quota. also
models industrial problems as: (1) packing peach slices cans
contains least advertised net weight peaches, (2) breaking monopolies
smaller companies, large enough viable (Assmann, Johnson, Kleitman,
& Leung, 1984). Another application bin covering lot-to-order matching problem
semiconductor industry, problem assign fabrication wafer lots
customer orders various sizes (Carlyle et al., 2001).
1.1.4 Min-Cost Covering Problem (Liquid Loading Problem)
define Min-Cost Covering Problem (MCCP) follows. Given set bins
quotas {q1 , ..., qm }, set n items weights w1 , ..., wn costs p1 , ..., pn , assign
subset items bin (1) item assigned one
bin, (2) sum weights items assigned bin least bins quota
(i.e., bin covered, bin covering), (3) total cost items
assigned bin minimized. problem also called liquid loading problem
(Christofides et al., 1979), originally motivated following application:
Consider disposal transportation different liquids (e.g., chemicals) cannot
mixed. given n tanks various sizes, associated cost,
problem load liquids subset tanks minimize total
cost. Note here, liquids correspond containers, tanks correspond
items.
applications MCCP include: (1) storage different varieties grain
different silos, different types grains cannot mixed, (2) storage food types
397

fiFukunaga & Korf

freezer compartments, (3) trucking firm distributes trucks (of different sizes)
among customers mixing different customers orders truck, (4) storage
information storage devices (e.g., sensitive customer data must segregated
physical filing cabinets file servers). closely related problem segregated
storage problem (Neebe, 1987; Evans & Tsubakitani, 1993).
formally, MCCP formulated integer program:

minimize

n
X
X

subject to:

i=1 j=1
n
X

pj xij

(15)

wj xij qi ,

= 1, ...,

(16)

xij 1,

j = 1, ..., n

(17)

xij {0, 1}

i, j.

(18)

j=1

X
i=1

binary variable xij represents whether item j assigned container i. Constraint
16 ensures quotas bins satisfied, constraint 17 ensures
item assigned one bin.
1.1.5 taxonomy multicontainer problems
Table 1 summarizes two key, defining dimensions four multicontainer problems
study paper. One key dimension whether problem involves packing set
items containers container capacity exceeded (packing), whether
problem requires satisfying quota associated container (covering). Another
key dimension whether items must assigned bins, whether
subset items selected assigned bins. third dimension (not shown
table) set item attributes (e.g., weight, profit/cost). Bin packing bin covering
single-attribute problems (items weight only), multiple knapsack
min-cost covering problems two-attribute problems (items weight profit/cost).
focus bin packing, bin covering, MKP, MCCP problems
believe sense basic multicontainer problems. Many
combinatorial optimization problems viewed extensions problems
additional constraints. example, generalized assignment problem considered
generalization MKP complex profit function.

packing
covering

assign items bins
bin packing
bin covering

assign subset items bins
multiple knapsack
min-cost covering

Table 1: Characterizing multicontainer problems.

398

fiBin Completion Algorithms Multicontainer Problems

2. Bin Completion
multiple-knapsack problem, bin covering problem, min-cost covering problem, bin
packing problem strongly NP-complete (proofs reduction 3-PARTITION,
e.g. Martello & Toth, 1990; Fukunaga, 2005). Thus, problems cannot solved
polynomial pseudo-polynomial time algorithm unless P = N P , state-of-theart approach optimally solving problems branch-and-bound. contrast,
single-container 0-1 Knapsack problem subset sum problem weakly NPcomplete, solved pseudopolynomial time using dynamic programming algorithms (Kellerer et al., 2004).
section, begin describing standard item-oriented branch-and-bound approach solving multi-container problems. describe bin completion, alternate,
bin-oriented strategy. clarity simplicity exposition, detail algorithms
context bin packing problem.
2.1 Item-Oriented Branch-and-Bound
standard approach solving multi-container problems item-oriented branch-andbound strategy. Suppose bin packing problem instance bin capacity
100, 7 items weights 83, 42, 41, 40, 12, 11, 5. perform branchand-bound procedure search space assignments items bins, node
branch-and-bound search tree corresponds item, branches correspond
decisions bin place item. Assuming consider items
order non-increasing weight, first place 83 bin, resulting set
bins {(83)}. Next, consider 42. put bin 83, resulting
{(83, 42)}, exceed bin capacity. possibility put 42
new bin, resulting {(83), (42)}. feasible choice node. Next,
41 assigned bin. three possible places assign 41: (a)
bin 83, resulting {(83, 41), (42)}, (b) bin 42, resulting
{(83), (42, 41)}, (c) new bin own, resulting {(83), (42), (41)}. Option (a)
exceeds bin capacity first bin infeasible. Options (b) (c) feasible
choices, branch item assignment, resulting two subproblems,
search procedure recursively applied. Figure 1 illustrates portion search space
(we show feasible nodes).
branch-and-bound procedure item-oriented node, decide
upon placement particular item. Upper lower bounding techniques specific
problem applied make basic depth-first strategy efficient. Itemoriented branch-and-bound appears natural strategy multicontainer
problems. seminal paper Eilon Christofides (1971), first paper
address optimal solutions multi-container problems, proposed item-oriented branchand-bound strategy. work literature algorithms optimally solving
multi-container problems relied upon item-oriented strategy.

399

fiFukunaga & Korf

(83)
(83)(42)

(83)(42)(41)

(83) (42,41)

(83)
(42,41) (40)

(83 12) (42 41) (40)

(83)(42 41 12)
(40)

(83)(42 41)
(40 12)

(83)(42)
(41,40)

(83)(42)
(41)(40)

...

...

(83)(42 41)
(40)(12)

Figure 1: Partial, item-oriented search space bin packing instance capacity 100
items {83,42,41,40,12,11,5}. node corresponds decision
existing new bin item assigned to. Items considered nonincreasing
order weight.

2.2 Bin Completion, Bin-Oriented Branch-and-Bound Strategy
alternate problem space solving multi-container problems bin-oriented,
nodes correspond decisions remaining item(s) assign current bin.
bin assignment B = (item1 , ..., itemk ) set items assigned
given bin. Thus, valid solution bin packing problem instance consists set
bin assignments, item appears exactly one bin assignment. bin assignment
feasible respect given bin capacity c sum weights exceed
c. Otherwise, bin assignment infeasible. definition feasibility
MKP; however, bin covering MCCP, define bin assignment feasible
respect bin quota q sum weights least q. Given set k
remaining items, say bin assignment maximal respect capacity c
feasible, adding k remaining items would make infeasible. Similarly,
bin covering MCCP, feasible bin assignment minimal respect quota
q removing item would make infeasible. brevity, rest paper,
omit qualification respect given capacity/quota unnecessary
(for example, bin packing bin covering, bins capacity/quota
qualification necessary).
Bin completion (for bin packing) bin-oriented branch-and-bound algorithm
node represents maximal, feasible bin assignment. Rather assigning items one
time bins, bin completion branches different maximal, feasible bin assignments.
nodes given level bin completion search tree represent different maximal,
400

fiBin Completion Algorithms Multicontainer Problems

2
(83,12,5)
(42,41)

(42,40)

(83,11,5)
(42,11)

(40,11)
Figure 2: Bin-completion search space bin packing instance capacity 100
items {83,42,41,40,12,11,5}. node represents maximal, feasible bin assignment given bin. Bin assignments shown strikethrough, e.g., (83,11,5),
pruned due dominance criterion described Section 2.3.

feasible bin assignments include largest remaining item. nodes next
level represent different maximal, feasible bin assignments include largest remaining
item, etc. reason restrict sibling bin assignments bin packing search
tree largest remaining number common eliminate symmetries
introduced fact bins capacity bin packing fomulation.
Thus, depth branch bin completion search tree corresponds number
bins partial solution depth. Figure 2 shows example bin completion
search tree.
2.3 Dominance Criteria Bin Assignments
key making bin completion efficient use dominance criterion feasible
bin assignments requires us consider small subset them.
Bin comletion (for bin packing) considers maximal, feasible assignments,
clear non-maximal assignments dominated maximal assignments, i.e., assigning non-maximal assignment bin cannot lead solution fewer bins
assigning maximal assignment. example, current bin 20 units remaining
space remaining items {15, 30, 40, 60}, always better add 15
current bin, must eventually pack 15 somewhere. formalize
notion dominance describe powerful dominance criteria significantly prune
search space.
Definition 1 (Dominance) Given two feasible bin assignments F1 F2 , F1 dominates
F2 value optimal solution obtained assigning F1 bin
worse value optimal solution obtained assigning F2
bin.
show bin assignment B dominated another bin assignment A,
prune search tree B. Maximality trivial dominance criterion bin
completion. feasible bin assignment B maximal, definition, must

401

fiFukunaga & Korf

subset maximal, feasible subset A, B clearly dominated A. consider
powerful dominance criteria.
Suppose bin packing instance bin capacity 100 items {96,3,4,80,15,12}.
sets (96,3) (96,4) maximal, feasible bin assignments. choose
bin assignment (96,3), remaining subproblem unassigned items {80,15,12,4}.
hand, choose bin assignment (96,4), remaining subproblem
{80,15,12,3}. Clearly, optimal solution subproblem {80,15,12,4} must use least
many bins optimal solution subproblem {80,15,12,3}. words,
optimal solution subtree node (96,4) least good optimal
solution subtree (96,3), therefore need search (96,3)
bin assignment (96,4) dominates bin assignment (96,3).
Christofides, Mingozzi, Toth first proposed general form dominance
criterion context min-cost covering problem (Christofides et al., 1979).
reformulated criterion terms bin packing problem:
Proposition 1 (CMT Dominance Bin Packing) Given two feasible sets B,
dominates B if: (1) |A| |B| (2) exists one-to-one (but necessarily onto)
mapping B item b B, mapped element
weight greater equal weight b, i.e., w(b) w((b)).1
words, element b feasible bin assignment B, corresponding item feasible bin assignment b a, dominates B.
reason follows: consider bin packing solution S, single bin assigned
items B. items must assigned bin, items assigned
bin(s). item B, swap corresponding item A,
resulting solution feasible, bins S. example, consider
bin packing instance items {10,9,8,7,6} bin capacity 20. bin assignment
= (10, 8) dominates bin assignment B = (9, 7), map 9 10
map 7 8.
Martello Toth (1990) proposed powerful dominance criterion subsumes
CMT criterion. Consider bin packing instance items {6,4,2,1,...} capacity
10. assignment (6,4) dominates assignment (6,2,1) given solution
assignment (6,2,1), swap 2 1 4, resulting solution
assignment (6,4) number bins. CMT criterion account
this. generally, consider two feasible bin assignments B. elements
B packed bins whose capacities elements A, set dominates set
B. example, let = (20, 30, 40) let B = (5, 10, 10, 15, 15, 25). Partition B
subsets (5, 10),(25), (10, 15, 15). Since 5 + 10 20, 25 30, 10 + 15 + 15 40,
set dominates set B. formally:
Proposition 2 (Martello-Toth Bin Packing Dominance Criterion) Let B
two feasible bin assignments. dominates B B partitioned subsets B1 , ...Bi
subset Bk mapped one-to-one (but necessarily onto) item ak
sum weights items Bk less equal weight ak .
1. Recall function f : X one-to-one two distinct elements x, x X, f (x) 6= f (x ).
function f : X onto element image f element X.

402

fiBin Completion Algorithms Multicontainer Problems

Proof: Suppose candidate solution assigns B bin m, bin
assignments currently feasible. Let feasible bin assignment B
partitioned subsets B1 , ..., Bi , subset Bk mapped one-to-one
ak A, sum weights items Bk less equal weight
ak . Consider swapping B A. subset Bk swapped corresponding
element ak (where ak assigned bin dk original solution s). Since feasible,
bin remains feasible B swapped. consider bins d1 , ...di
subsets B1 , ..., Bi end swaps (in words, d1 , ...di bins
contain a1 , ..., ak , respectively, original solution s). target bin dk
remain feasible swap, since (1) bin assignment dk feasible prior
swap, (2) sum weights items Bk less equal weight
ak . Thus, resulting solution swap (a) feasible (all bin assignments
feasible) (b) worse initial solution s, (c) assigns bin m. Therefore,
dominates B. 2
Martello-Toth dominance criterion generalization CMT dominance criterion CMT dominance criterion special case Martello-Toth criterion
consider partitions B single-element subsets. Thus, node would
pruned CMT criterion also pruned Martello-Toth criterion, vice
versa.
Similarly, define dominance criterion bin covering follows:
bin covering (and MCCP), bin assignment feasible respect given
bin sum item weights greater equal bin quota q.
Proposition 3 (Bin Covering Dominance Criterion) Let B two feasible assignments. dominates B B partitioned subsets B1 , ..., Bi
item ak mapped one-to-one (but necessarily onto) subset Bk ,
weight ak less equal sum item weights corresponding
subset Bk (i.e., Bk covers ak ).
Proof: Suppose solution assigns B bin m, bin assignments
currently feasible. Let feasible bin assignment B partitioned
subsets B1 , ..., Bi , item ak mapped one-to-one subset Bk ,
weight ak less equal sum weights items Bk .
Consider swapping B A. subset Bk swapped corresponding element ak
(where ak assigned bin dk original solution s). Since feasible, bin remains
feasible B swapped. consider bins d1 , ..., d|A|
subsets Bk end swaps. words, d1 , ..., d|A| bins contain
a1 , ..., ak , respectively, original solution s. target bin dk remain feasible
swap, since (1) bin assignment dk feasible prior swap, (2)
sum weights items Bk greater equal weight ak (and thus
quota bin dk continue satisfied). Thus, resulting solution
swap (a) feasible (all bin assignments feasible) (b) worse initial solution
s, (c) assigns bin m. Therefore, dominates B. 2
dominance criteria MKP MCCP similar dominance criteria
bin packing bin covering, respectively, except must also take consideration
profits/costs. proofs similar proofs bin packing bin covering.
403

fiFukunaga & Korf

Proposition 4 (MKP Dominance Criterion) Let B two assignments
feasible respect capacity c. dominates B B partitioned subsets
B1 , ..., Bi subset Bk mapped one-to-one (but necessarily onto) ak ,
element A, k i, (1) weight ak greater equal sum
item weights items Bk , (2) profit item ak greater equal
sum profits items Bk .
Proposition 5 (MCCP Dominance Criterion) Let B two assignments
feasible respect quota q. dominates B B partitioned subsets
B1 , ..., Bi item ak mapped one-to-one (but necessarily onto)
subset Bk , ak corresponding subset Bk , (1) weight ak less
equal sum item weights items Bk , (2) cost item ak
less equal sum cost items Bk .
CMT dominance criterion MCCP originally proposed (Christofides et al.,
1979) special case Proposition 5, |Bk | = 1 k.
Note packing problems MKP bin packing, dominance
criteria require subsets dominated assignment packed items
dominating assignment. contrast, covering problems MCCP
bin covering, dominance criteria requires subsets dominated assignment
(B) cover items dominating assignment (A).
2.3.1 Bin-Oriented Branch-and-Bound + Dominance = Bin Completion
point, defined salient features bin completion approach solving
multicontainer packing knapsack problems:
bin-oriented branch-and-bound search nodes correspond maximal (or
minimal), feasible bin assignments;
exploitation dominance criterion among bin assignments prune search
space.
first instance bin completion algorithm aware Christofides,
Mingozzi, Toth algorithm min-cost covering problem 1979 (Christofides et al.,
1979), used CMT criterion described above. However, far know,
research done bin completion algorithms work bin completion
bin packing (Korf, 2002).
Martello-Toth dominance criterion proposed Martello Toth (1990),
component Martello-Toth Procedure (MTP), branch-and-bound algorithm bin
packing. However, MTP branch-and-bound algorithm item-oriented,
exploit dominance property limited way. particular, take remaining
element x, starting largest element, check single assignment
x one two elements dominates feasible sets containing x. so,
place x elements bin, apply reduction remaining
subproblem. also use dominance relations prune element placements well.
Another earlier instance bin completion algorithm BISON algorithm bin
packing Scholl, Klein, Jurgens (1997). BISON uses following, limited form
404

fiBin Completion Algorithms Multicontainer Problems

Martello-Toth dominance criterion: bin assignment one items
replaced single free item without decreasing sum, assignment
dominated. interesting despite fact basic idea bin-oriented search
dominance-based pruning demonstrated Christofides, Mingozzi, Toth,
MTP BISON use limited form Martello-Toth dominance criterion,
two ideas successfully integrated work.2 Presumably, reason
trivial generate undominated bin assignments efficiently.
2.4 Generating Undominated Bin Assignments
key component bin completion efficient generation undominated bin assignments. obvious approach generate feasible bin assignments, apply dominance tests eliminate dominated assignments. However, impractical,
number feasible assignments exponential number remaining items,
memory time required generate store assignments would prohibitive.
describe algorithm generates undominated bin assignments,
enables efficient implementation bin completion.
generate subsets n elements recursively traversing binary tree.
internal node corresponds item, left branch corresponds subsets
include item, right branch corresponds subsets include
item. Thus, leaf node represents individual subset. Note binary tree
search space subproblem (generating undominated bin assignments),
distinct search space higher level bin-completion algorithm (i.e.. space
undominated maximal assignments).
Given n elements container capacity c, feasible bin assignments subsets n elements, sum whose weights exceed c. recursive traversal
described generating subsets modified generate feasible assignments follows: node tree, keep track sum items
committed including subset (i.e., sum weights items
taken left branch). recursive traversal tree, pass parameter
representing remaining capacity bin. time left branch taken (thereby
including item), reduce remaining capacity item weight. remaining
capacity drops zero less, prune tree current node, since
equaled exceeded container capacity. Thus, algorithm generates feasible
bin assignments.
Now, extend algorithm generate undominated, feasible bin
assignments. Suppose feasible set whose sum weights t. excluded
items items A. Set dominated (with respect MartelloToth dominance criterion) contains subset whose sum less
equal excluded item x, replacing subset x exceed bin
capacity c. case exists excluded item x subset
weight sum + x c. Therefore, check undominated,
enumerate possible subset items, subset, compare
2. shown (Korf, 2002, 2003), bin-oriented search using full Martello-Toth dominance criterion
results dramatic speedups compared MTP.

405

fiFukunaga & Korf

excluded number x verify + x > c, sum item weights
subset. so, undominated, store list undominated assignments;
otherwise, dominated. optimizations found (Korf, 2003).
algorithm generates feasible bin assignments immediately tests dominance, never stores multiple dominated bin assignments. Furthermore, dominance
test done comparing included elements excluded elements, involve
comparison candidate bin assignment previously generated bin assignments. Therefore, memory required dominance testing linear number
items. contrast, method depends comparisons candidate sets,
earlier algorithm described (Korf, 2002), requires memory linear
number undominated bin assignments, potentially exponential number
items. ability incrementally generate undominated bin assignments using linear space without store undominated assignments enables hybrid
incremental branching strategy, described Section 3.4.

3. Extensions Bin Completion
describe extensions bin completion significantly improve search efficiency. Again, clarity, describe algorithms mostly context bin packing,
basic bin completion algorithm, extensions adapted straightforwardly multiple knapsack, bin covering, min-cost covering problems.
3.1 Nogood Pruning (NP)
Nogood pruning prunes redundant nodes bin completion search tree detecting
symmetries. Since need refer specific bins, extend notation bin assignment. Let (A)d denote bin depth assigned elements A. Thus, (10, 8, 2)1
(10, 7, 3)1 denote two possible bin assignments bin depth 1.
Suppose instance numbers {10,9,8,7,7,3,3,2,2}, bin capacity
c=20. exhausting subproblem assignment (10, 8, 2)1 , exploring
subproblem assignment (10, 7, 3)1 , assume find solution assigns
(9, 8, 2)2 . swap pair items (8,2) assignment (9, 8, 2)2 pair
items (7,3) assignment (10, 7, 3)1 , resulting solution (10, 8, 2)1
(9, 7, 3)2 number bins. However, already exhausted subtree
(10, 8, 2)1 would found solution number bins
best solution subtree (9, 7, 3)2 . Therefore, prune branch
(9, 8, 2)2 , redundant (in words, detected current partial
solution symmetric partial state already exhaustively searched).
formally, let {N1 , N2 , ..., Nm } set sibling nodes search tree,
let {S1 , S2 , ..., Sm } bin assignments sibling node, excluding first item
assigned bin, common sibling nodes. searching subtree
node Ni > 1, exclude bin assignment B (1) includes items
Sj , (2) swapping items Sj B items Si Ni results two feasible

406

fiBin Completion Algorithms Multicontainer Problems

bin assignments, > j. items Sj become nogood respect nodes deeper
tree.3
exists bin assignment B, could swap items Sj B
items Si Ni , resulting partial solution bin assignment Si bin Ni .
However, already exhausted subtree Ni , redundant node
pruned.
search progresses tree, list nogoods maintained, set
bin assignments candidate undominated bin assignment compared.
Given candidate bin assignment B, items sorted according weight,
current implementation test nogood pruning compares items
nogood. Since items nogood sets also sorted weight, comparison
takes time linear cardinality B. worst case, number nogoods
must compare candidate assignment level corresponds number
undominated bin assignments levels 1, ..., 1 currently stack (that is,
ancestors siblings ancestors current node). Note list
nogoods need grow monotonically go search tree. point,
nogood N longer subset set remaining items, N split,
removed nogood list passed search tree.
3.2 Nogood Dominance Pruning (NDP)
following nogood dominance pruning (NDP) technique allows even pruning: Suppose exhausting subproblem assignment (10, 8, 2)1 ,
exploring subproblem assignment (10, 7, 3)1 , consider assignment
(9, 7, 2)2 . swap pair items (7,2) bin 2 pair items (7,3)
bin 1 end solution (10, 7, 2)1 (9, 7, 3)2 . However, according
Martello-Toth dominance criterion, (10,7,2) dominated (10,8,2),
already exhausted search node (10, 8, 2)1 , prune search
(9, 7, 2)2 possible improve upon best solution (10, 8, 2)1 .
general, given node one child, searching subtree
child first, dont need consider assignments dominated bin
assignment previously explored child node. precisely, let {N1 , N2 , ..., Nm }
set sibling nodes search tree, let {S1 , S2 , ..., Sm } corresponding sets
items used bin assignment node. searching subtree node
Ni > 1, exclude bin assignment exists assignment Sj ,
j < i, (1) dominated items Sj (note assignment dominates
itself), (2) swapped Si , resulting bin assignments
feasible. exists bin assignment A, could swap items
items Si Ni , resulting partial solution bin assignment bin Ni ,
number bins. However, since dominated Sj , means
searching node symmetric one dominated Sj , therefore,
possible find solution better best solution Sj , pruned.
3. term nogood constraint programming literature often refers assignment value(s)
variable(s) cannot lead solution, use term mean assignment cannot lead
solution better previously discovered solution, similar usage (Focacci &
Shaw, 2002).

407

fiFukunaga & Korf

also describe nogood dominance pruning terms general constraint
programming formulation, variables correspond items values denote bins
assigned. Given partial, j-variable solution x, nogood dominance
pruning tries show, via swapping items dominance checks, x
equivalence class another partial solution x xi , subset x including
first variables, dominated another partial solution q. Thus, exhausted
subtree q search tree, need search subtree x .
Nogood dominance pruning strictly powerful nogood pruning. node
pruned nogood pruning pruned nogood dominance pruning, vice
versa. course, since NDP must detect dominance relationships opposed equivalence relationships, NDP incur overhead per node compared NP. current
implementation propagates list nogood sets along tree. generating undominated completions given bin, check one see dominated
current nogood. so, ignore bin assignment. current implementation uses
brute-force algorithm check dominance candidate bin assignment
nogood, worst case takes time exponential cardinality bin
assignment (for nogood).
Since nogood pruning much less expensive nogood dominance pruning, use
combined pruning strategy. Whenever apply NDP, actually apply NP
NDP node. First, candidate bin assignment checked nogood,
nogood pruning applied. apply nogood dominance pruning bin assignment
pruned nogood pruning. Thus, never pay full cost applying NDP
nodes pruned quickly NP. nogood pruning, NDP requires storing
set nogoods, number possible nogoods particular search depth
worst case number undominated bin assignments considered depths 1, ..., 1.
Note using NDP, apply optimization described Section
3.1 removing nogoods nogood list passed tree using
nogood pruning. reason even nogood split longer
prune bin assignment due nogood pruning, nogood may still able prune
bin assignment due nogood dominance pruning.
size nogood list increases depth, compare bin assignment
nogood. Therefore, per-node overhead NDP increases depth.
means pruning bottom tree (where pruning lowest utility)
expensive pruning top tree (where pruning highest utility).
simple strategy address issue depth-limited NDP, NDP applied
nodes NDP depth limit L. nodes depth limit, weaker
nogood pruning applied. experiments described paper, use
depth-limited strategy NDP consistently outperformed nogood pruning without
use depth limits.
3.3 Related Work Constraint Programming
Nogood pruning identifies prunes nodes detecting whether bin assignment
current node contains nogood. related symmetry-breaking techniques
proposed constraint programming literature. symmetry partitions set pos-

408

fiBin Completion Algorithms Multicontainer Problems

sible assignments values variables equivalence classes (Gent & Smith, 2000).
goal symmetry breaking prune nodes mapped previously explored
node via symmetry function. Symmetry-breaking approaches introduce constraints search prune symmetric variable assignments (e.g., Gent & Smith, 2000; Fahle,
Schamberger, & Sellmann, 2001; Focacci & Milano, 2001). Similarly, nogood nogood dominance pruning techniques dynamically introduce constraints prune variable
assignments cannot lead solution better best solution found far.
Nogood dominance pruning uses dynamic nogood recording mechanism nogood
pruning, goes step detecting dominance relationships based nogoods.
general notion dominance exploited NDP powerful symmetry, since
dominance asymmetric, i.e., symmetries dominance relationships,
vice versa.
NDP technique similar pruning technique proposed Focacci Shaw
(2002) constraint programming, applied technique symmetric
asymmetric traveling salesperson problem time windows. methods attempt
prune search proving current node depth j, represents partial jvariable (container) solution x, dominated previously explored i-variable partial
solution (nogood), q. main difference two methods approach used
test dominance. Focacci Shaws method extends q j-variable partial solution
q dominates x. apply local search procedure find extension q .
contrast, NDP method starts partial, j-variable solution x tries
transform partial solution x xi , subset x including first
variables, dominated q. swapping values ith jth variables
x derive x , testing whether xi dominated q.
efficiency, current implementations nogood dominance pruning methods
weak, sense x dominated q, procedures necessarily detect
dominance. Focacci Shaw rely incomplete, local search find extension
q . Due cost considering transformations, consider transformations
involving two variables (containers), fully exploit dominance criterion, would
need consider transformations involving variables i, + 1, ..., j.
3.4 Reducing Computation Required Per Node
issue enumerating undominated completions applying value ordering
computing undominated sets NP-complete. multicontainer problem
instance items weight wi andP
average container capacity c, average
number items fit container x = ni=0 wi /c. time generate undominated bin assignments increases x. issue bin packing, problems
large x tend easily solved using heuristics best-fit decreasing. solution found heuristic often equals lower bound. Therefore, instances require
search, hence need compute undominated bin assignments.
hand, multiple knapsack bin covering, observed experimentally
much less likely heuristics match optimistic bound allow termination
without search, found instances high x, algorithm would
terminate within reasonable time limit spending inordinate amount

409

fiFukunaga & Korf

2

b


e


h



f

g

c

k
l

j

Figure 3: Hybrid Incremental Branching Strategy
time computing set undominated completions node. addition, generating
undominated bin assignments may cause us run memory.
alternative approach start go search tree explore
children node without first enumerating sorting children. cases
(a) good optimistic bound available, (b) takes relatively little search find
optimal solution, approach leads dramatic speedups compared original scheme
generating undominated completions going search tree.
price pay strategy lose benefits ordering candidate bin
assignments according value-ordering heuristic.
solve problem, propose hybrid incremental branching strategy generates
h children node, applies value-ordering heuristic these, recursively calls
bin completion remaining subproblems. node, first generate h children,
sort according value-ordering heuristic. Then, explore subtrees
children. subtrees first h children fully explored,
next h children generated subtrees explored, on.
example, consider tree Figure 3, nodes correspond undominated
bin assignments. Assume complete search tree, assume simplicity
value ordering heuristic. standard bin completion algorithm first
generates children root: a, b, c. Then, bin completion selects one
children (say a), expands children (d,e,f ,g). generates children d,
on. Thus, order node generation is: a, b, c, d, e, f, g, h, i, j, k, l.
pre-order traversal tree. consider hybrid incremental branching width 1.
corresponds standard postorder traversal tree, order
nodes generated a, d, h, i, j, e, f, g, b, k, l, c. Hybrid incremental branching width
2 generates nodes order a, b, d, e, h, i, j, f, g, k, l, c.

4. Multiple Knapsack Problem (MKP)
Given set containers set items (characterized weight profit),
objective multiple knapsack problem (defined formally section 1.1.2) assign
items containers container capacities exceeded, sum
profits items assigned containers maximized.
compared bin completion two standard algorithms: state-of-the-art Mulknap
algorithm (Pisinger, 1999), well MTM algorithm (Martello & Toth, 1981).
410

fiBin Completion Algorithms Multicontainer Problems

4.1 MTM Algorithm
MTM algorithm Martello Toth (1981) item-oriented branch-and-bound
algorithm. items ordered according non-increasing efficiency (ratio profit
weight), next item selected variable-ordering heuristic itemoriented branch-and-bound item highest efficiency assigned least
one container greedy bound-and-bound procedure (see below). branches assign
selected item containers, order non-decreasing remaining capacity.
node, upper bound computed using relaxation MKP,
obtained combining remaining
containers MKP single conPm
tainer aggregate capacity C = i=1 ci , resulting single-container, 0-1 knapsack
problem:

maximize

n
X

pj xj

(19)

subject

j=1
n
X

wj xj C,

(20)

j=1
xj

{0, 1}, j = 1, ..., n.

(21)

variable xj represents whether item j assigned aggregated bin.
surrogate relaxed MKP (SMKP) solved applying algorithm optimally
solving 0-1 Knapsack problem, optimal value SMKP upper bound
original MKP. Thus, upper bound computation solving embedded,
weakly NP-complete (single-container) 0-1 Knapsack problem instance subproblem.
SMKP currently effective upper bound MKP (details
formulation derived initial surrogate relaxation Martello & Toth,
1981; Kellerer et al., 2004).
node, MTM algorithm applies extension branch-and-bound called
bound-and-bound. Consider branch-and-bound procedure maximization problem.
upper (optimistic) bound computed node less equal best known
lower bound problem, node pruned. standard branch-andbound approach, lower bound simply objective function value best solution
found far.
bound-and-bound, attempt validate upper bound applying fast, heuristic algorithm order find solution whose score equals upper bound. solution found, means found optimal solution current
node (i.e., upper bound validated), backtrack. hand,
solution found, must continue search node. MTM
algorithm applies greedy heuristic algorithm MKP, involves solving series
0-1 Knapsack problems. First, container = 1 filled optimally using
remaining items, items used fill container = 1 removed. Then, container
= 2 filled using remaining items. process iterated times, point
containers filled.

411

fiFukunaga & Korf

4.2 Mulknap Algorithm
previous state-of-the-art algorithm MKP Mulknap (Pisinger, 1999). Like
MTM, Mulknap item-oriented branch-and-bound algorithm using SMKP upper
bound bound-and-bound. Mulknap differs MTM (1) uses different
validation strategy bound-and-bound based splitting SMKP solution, (2)
applies item reduction node, (3) applies capacity tightening node.
Like MTM, Mulknap uses bound-and-bound strategy, uses different approach
validating upper bound: described above, upper bound MKP instance
computed solving surrogate relaxation MKP, SMKP, 0-1
Knapsack instance. Suppose computed optimal solution SMKP.
Now, suppose able partition items used SMKP containers
original MKP, item used SMKP solution assigned
container, capacity constraints violated. case, solution
original MKP achieves upper bound. Details capacity tightening
reduction procedures given Pisinger (1999).
4.3 Bin Completion Algorithm MKP
describe bin completion algorithm MKP. apply depth-first, bin
completion branch-and-bound algorithm. node search tree represents maximal, feasible bin assignment particular bin. Note MKP, bin capacities
vary, node, consider undominated bin assignments bin.
contrast bin packing 2.2, (assuming bins identical capacity),
restrict nodes level (largest) item.
node, upper bound remaining subproblem computed using
surrogate relaxed MKP (SMKP) bound. SMKP bound computed using straightforward branch-and-bound algorithm Martello-Toth U2 upper bound (Martello &
Toth, 1977). Pisingers R2 reduction procedure (Pisinger, 1999) applied node
order possibly reduce remaining problem. Then, select bin smallest
remaining capacity (i.e., use smallest-bin-first variable ordering heuristic, ties
broken randomly), undominated bin assignments computed explored using
dominance criterion (Proposition 4). Nogood pruning nogood dominance pruning
applied described Sections 3.1 3.2.
order branch undominated children current node
significant impact algorithms performance. node, undominated
children node generated ordered using value ordering heuristic. evaluated 11 different value ordering heuristics found best performing heuristic
overall min-cardinality-max-profit ordering, candidate bin assignments
sorted order non-decreasing cardinality ties broken according non-increasing
order profit. Fukunaga (2005) provides details experiments evaluating various
value variable ordering strategies. Figure 4 shows outline bin completion
algorithm MKP.

412

fiBin Completion Algorithms Multicontainer Problems

MKP bin completion(bins,items)
bestProfit =
search MKP(bins,items,0)
search MKP(bins, items,sumProfit)
bins== items ==
/*we candidate solution*/
sumProfit > bestProfit
bestProfit = sumProfit
return
/* Attempt reduce problem. reducedBinAssignments
maximal, feasible assignments items bins */
reducedBinAssignments = reduce(bins,items)
ri = get items(reducedBinAssignments) /* items eliminated reduction */
rb = get bins(reducedBinAssignments) /* bins eliminated reduction */
reducedItems 6=
P
search MKP(bins \ rb, items \ ri, sumProfit+ iri profit(i))
return
/* Attempt prune based upper bound */
(sumProfit + compute upper bound(items,bins)) < bestProfit
return
bin = choose bin(bins)
undominatedBinAssignments = generate undominated(items,capacity(bin))
foreach sort assignments(undominatedBinAssignments)
not(nogood(A)) not(nogood dominated(A))
assign undominated bin assignment bin
P
search MKP(bins \ bin, items \ items in(A),sumProfit+ iA profit(i))

Figure 4: Outline bin completion multiple knapsack problem.
compute lower bound returns SMKP upper bound profit
remaining subproblem, reduce applies Pisingers R2 reduction eliminate
items bins possible. choose bin selects bin least remaining
capacity, sort assignments sorts undominated bin assignments
order non-decreasing cardinality, ties broken order non-increasing
profit. generate undominated generates undominated bin assignments using
algorithm (Section 2.4). nogood nogood dominated apply nogood
pruning (Section 3.1) nogood dominance pruning (Section 3.2).

413

fiFukunaga & Korf

4.4 Experimental Results
evaluated MKP algorithm using four classes instances used Pisinger
(1999). considered:
uncorrelated instances, profits pj weights wj uniformly distributed
[min, max].
weakly correlated instances, wj uniformly distributed [min,max]
pj randomly distributed [wj (max min)/10, wj + (max min)/10]
pj 1,
strongly correlated instances, wj uniformly distributed [min,max]
pj = wj + (max min)/10,
multiple subset-sum instances, wj uniformly distributed [min, max]
pj = wj .
bin capacities
follows: first 1 capacities ci uniformly
Pn set asP
distributed [0.4 j=1 wj /m, 0.6 nj=1 wj /m] = 1, ..., 1. last capacity cm
P
Pm1
chosen cm = 0.5 nj=1 wj i=1
ci ensure sum capacities half
total weight sum. Degenerate instances discarded Pisingers experiments
(1999). is, used instances where: (a) items fits least one
containers, (b) smallest container large enough hold least smallest item,
(c) sum item weights least great size largest container.
experiments, used items weights range [10,1000].
4.4.1 Comparison Bin Completion Previous Algorithms
compare bin completion (BC) Mulknap MTM. experiments described involving Mulknap, used Pisingers Mulknap code, available web
site4 , compiled using gcc compiler -O3 optimization setting. Likewise,
experiments described involving MTM, used Martello Toths Fortran implementation MTM (Martello & Toth, 1990), converted C using f2c
could add instrumentation. bin completion code implemented
Common Lisp.5 shown experimentally choice programming language
added overhead approximately factor two runtimes (see Fukunaga, 2005,
Appendix A) compared GNU C 2.95 -O3 optimization.
four problem classes, generated test sets 30 instances each,
n = 20, varied 2 10. instance, ran Mulknap, bin
completion, bin completion nogood dominance pruning. purpose
experiment observe behavior algorithms ratio n/m varied.
results shown Table 2. algorithm given time limit 300 seconds solve
instance. fail column indicates number instances (out 30) could
solved algorithm within time limit. time nodes column show
4. http://www.diku.dk/pisinger/
5. bin completion solvers described paper MKP, MCCP, bin covering, bin
packing problems implemented Common Lisp.

414

fiBin Completion Algorithms Multicontainer Problems



n

fail

# bins

# items

2
3
4
5
6
7
8
9
10

20
20
20
20
20
20
20
20
20

0
0
0
0
0
1
1
1
3

2
3
4
5
6
7
8
9
10

20
20
20
20
20
20
20
20
20

0
0
0
0
0
0
0
0
2

2
3
4
5
6
7
8
9
10

20
20
20
20
20
20
20
20
20

0
0
0
0
0
0
2
2
4

2
3
4
5
6
7
8
9
10

20
20
20
20
20
20
20
20
20

0
0
0
0
0
0
2
2
4

MTM
time

nodes

fail

Mulknap
time
nodes

Uncorrelated Instances
201
0
0.0000
1
697
0
0.0000
23
1530
0
0.0030
306
34800
0
0.0387
2977
100387
0
0.4063
36057
851591
1
3.8207
369846
3539729
1 23.7996 2493203
11294580
4 33.2138 2868979
13536735
5 52.0812 4848676
Weakly Correlated Instances
0.0040
781
0
0.0000
26
0.0127
2693
0
0.0167
638
0.0327
6626
0
0.0390
1708
0.2363
53324
0
0.2917
12701
0.2763
65216
0
0.4220
20165
0.6237
168974
0
1.3180
60890
11.0927
2922499
2
6.5793
40339
27.5807 11263928
3 22.5878 1274756
25.1029 10697165
5 72.3472 4478185
Strongly Correlated Instances
0.0723
5747
0
0.0037
32
0.1243
6748
0
0.0053
65
0.1237
8125
0
0.0120
156
0.1777
14823
0
0.0360
563
0.1807
18012
0
0.0550
734
5.1393
882080
1
0.0928
1339
11.2361
2616615
3 12.2581
225236
20.0136
3150848
4 33.5415
693398
38.8554
8141902
9 34.3291
634358
Subset-Sum Instances
0.0820
2061
0
0.0033
9
0.2057
7033
0
0.0337
77
0.1760
8371
0
0.0503
137
0.2507
17514
0
0.1780
830
0.2393
17546
0
0.1953
738
5.7657
852615
1
0.3221
1752
14.9261
2546834
3 19.5930
270841
25.9393
3124421
4 41.8962
677467
51.5027
7907407
9 39.7500
627688
0.0003
0.0017
0.0063
0.0767
0.2343
1.5721
6.3352
18.3314
22.5185

Bin Completion+NDP
fail
time
nodes

0
0
0
0
0
0
0
0
0

0.0050
0.0063
0.0023
0.0033
0.0050
0.0043
0.0023
0.0017
0.0010

55
123
112
212
403
399
207
136
84

0
0
0
0
0
0
0
0
0

0.0340
0.0117
0.0133
0.0107
0.0080
0.0050
0.0027
0.0013
0.0013

87
240
379
521
405
245
144
66
43

0
0
0
0
0
0
0
0
0

0.0743
0.0417
0.0353
0.0350
0.0217
0.0137
0.0073
0.0060
0.0057

118
278
331
359
194
109
42
25
21

0
0
0
0
0
0
0
0
0

0.0447
0.0310
0.0260
0.0257
0.0173
0.0113
0.0073
0.0063
0.0057

64
248
294
315
176
102
39
25
20

Table 2: MTM, Mulknap, Bin Completion Nogood Dominance Pruning small
MKP instances varying n/m ratio.The fail column indicates number
instances (out 30) solved within time limit (300 seconds/instance). time (seconds 2.7GHz Pentium 4) nodes columns
show average time spent nodes generated successful runs, excluding
failed runs.

415

fiFukunaga & Korf

average time spent nodes generated successful runs, excluding failed runs.
experiments described section run 2.7GHz Pentium 4.
data confirms observations Pisinger (1999) Martello Toth (1981)
class uniform, random instances require search previous branchand-bound solvers appear generated n/m relatively low. words,
n/m ratio MKP appears critical parameter determines search
difficulty, similar clause-to-variable ratio satisfiability problems (Mitchell, Selman,
& Levesque, 1992). Table 2 shows Mulknap MTM great difficulty
relatively small problems small n/m ratios, bin completion could solve
problems quickly.
Next, investigated larger problem instances, n/m varied 2 4.
experiment, also included bin completion nogood pruning (BC+NP),
addition MTM, Mulknap, BC+NDP.
shown Table 3, problems n/m = 2 3, variants bin completion
(BC+NP BC+NDP) dramatically outperformed MTM Mulknap,
difference performance becoming pronounced problem size increased. runs truncated 300 seconds per instance per algorithm, possible
compare full runtimes sets. Note, example, subset-sum
instances n = 40 = 20, mean runtime BC+NDP 0.06 seconds,
neither MTM Mulknap solved instances within 300 seconds each,
least three orders magnitude slower BC+NDP instances. tried
running solvers longer order get actual runtimes (as opposed truncated, lower
bound runtimes), found even allocating hour per problem insufficient
allow MTM Mulknap solve problems. results suggest
bin completion asymptotically efficient MTM Mulknap class
problem instances. problems n/m = 4, results similar, notable
exception strongly-correlated instances, Mulknap outperformed bin completion
n = 40 = 10.
problems n/m = 2 3, observed BC+NDP consistently outperforms BC+NP significant margin respect number nodes searched,
significant improvements success rate execution times observed larger
problems sets. However, n/m = 4, BC+NDP still searches fewer nodes BC+NP,
difference much less significant, fact, reduced search enough
offset increased overhead per node NDP, runtimes BC+NP
BC+NDP end comparable (Table 3).
also ran experiments instances larger n/m ratios. n/m 5,
Mulknap clearly dominates current algorithms, solving instances little
search second, first demonstrated Pisinger (1999). high n/m ratios,
bound-and-bound approach Mulknap high probability finding upper
bound matches lower bound node, essentially eliminating need
search. fact, Pisinger (1999) showed instances n/m 10,
almost instances required searching one node.

416

fiMTM
time

n
# items

fail

15
20
25
10
15
5
10

30
40
50
30
45
20
40

30
30
30
12
30
0
7

47.77
0.08
99.13

15
20
25
10
15
5
10

30
40
50
30
45
20
40

30
30
30
16
30
0
29

68.80
0.10
205.99

15
20
25
10
15
5
10

30
40
50
30
45
20
40

30
30
30
1
30
0
13

23.48
0.06
115.38

15
20
25
10
15
5
10

30
40
50
30
45
20
40

30
30
30
0
18
0
5

25.58
0.0
0.05
35.20

nodes

fail

Mulknap
time
nodes

Bin Completion+NP
fail
time
nodes

Uncorrelated Instances
30
0
0.04
30
0
1.48
30
4
72.66
11
29.96
1649062
0
0.71
30
15
66.81
0
0.10
8487
0
0.01
4
51.66
1744911
0
11.58
Weakly Correlated Instances
30
0
0.07
30
0
0.79
30
0
34.39
8252155
15
69.65
1647576
0
0.94
30
19
52.42
21150
0
0.14
5758
0
0.01
12672965
27
131.41
2390152
0
21.10
Strongly Correlated Instances
30
0
0.04
30
0
3.46
30
9
52.26
2916858
0
7.02
88737
0
0.53
30
24
105.90
12490
0
0.02
486
0
0.01
5528847
0
44.55
361987
2
51.89
Subset-Sum Instances
30
0
0.01
30
0
0.13
30
0
4.37
1993648
0
4.74
43734
0
0.12
27.58
23
100.19
480014
2
45.07
5676
0
0.01
207
0
0.01
946934
0
10.48
58317
0
1.98
9240426
32602
15083247

Bin Completion + NDP
fail
time
nodes

1215
66681
2767939
48407
3369997
253
360567

0
0
3
0
15
0
0

0.02
0.72
32.43
0.61
60.54
0.01
13.47

887
26459
1060723
33141
2516681
237
297225

2123
22553
691645
34001
1126242
407
565036

0
0
0
0
18
0
0

0.05
0.35
15.80
0.79
67.17
0.01
20.63

1050
7473
231934
25764
1207099
396
490983

415
5407
58500
5662
964566
264
263462

0
0
4
0
23
0
2

0.03
2.29
58.72
0.50
118.72
0.01
50.51

194
2694
61900
5381
1150024
258
254094

171
1664
55334
1816
597581
140
26674

0
0
0
0
2
0
0

0.01
0.06
1.59
0.12
43.44
0.01
2.00

95
806
19491
1752
562129
137
26097

Table 3: Multiple knapsack problem results: Comparison MTM, Mulknap, Bin Completion Nogood Pruning (NP),
Bin Completion Nogood Dominance Pruning (NDP) hard MKP instances. fail column indicates number
instances (out 30) solved within time limit (300 seconds/instance). time (seconds 2.7GHz
Pentium 4) nodes show average time spent nodes generated successful runs, excluding failed runs.

Bin Completion Algorithms Multicontainer Problems

417


# bins

fiFukunaga & Korf

hand, n/m 5, bin completion tends generate large (more
10000) number undominated bin assignments decision node, runs
memory allocating set undominated bin assignments candidates
assigned current bin. hybrid incremental branching (Section 3.4) eliminates
problem allows algorithm run completion, still competitive
Mulknap (runs complete within 300-second time limit).
conclude uniform instances multiple knapsack problem exhibit bimodal characteristic, bin completion bound-and-bound complementary
approaches. n/m 4, uniform MKP instances require significant amount search
solve, bin completion approach clearly current state art, demonstrated Table 3. hand, n/m 5, bound-and-bound approach
exemplified Pisingers Mulknap algorithm state art, runtimes
dominated computation single lower bound single upper bound
root node. rather sharp phase transition around n/m = 4 dominant
approach changes bin completion bound-and-bound (see Fukunaga, 2005
details).
highly complementary nature Mulknap bin completion, MKP
natural candidate application algorithm portfolio approach (Huberman,
Lukose, & Hogg, 1997; Gomes & Selman, 2001) Mulknap bin completion
run parallel problem instance. Even trivial portfolio resource
allocation scheme processes received equal time, resulting total CPU usage
portfolio instance would worse twice faster algorithm.
Another way combine bin completion bound-and-bound add bound-and-bound
node bin completion search, avenue future work.

5. Min-Cost Covering Problem (MCCP)
Given set containers quotas set items (characterized weight
cost), objective MCCP assign items containers container
quotas satisfied, sum costs items assigned containers
minimized (see 1.1.4 formal definition).
5.1 Christofides, Mingozzi, Toth (CMT) Algorithm
previous state-of-the-art algorithm min-cost covering problem early version
bin completion Christofides, Mingozzi, Toth (1979). algorithm bin
completion algorithm uses CMT dominance criterion (see Section 2.3).
effective lower bound computed solving independent minimization
problems (similar standard 0-1 Knapsack, except objective satisfy
containers quota minimizing cost items assigned it), one
bins, summing results. L2 lower bound relaxation constraint
item used once.
Christofides et al. (1979) proposed several complex lower bounds, found
empirically among proposed lower bounds, L2 bound resulted best
performance far across wide range problem instances.

418

fiBin Completion Algorithms Multicontainer Problems

5.2 Bin Completion MCCP
new bin completion algorithm MCCP similar Christofides et al. algorithm. major difference use powerful dominance criterion (Proposition
5). node depth-first, search tree represents minimal, feasible bin assignment
particular bin. bin completion algorithm assigns bins order non-decreasing
size, i.e., smallest-bin-first variable ordering heuristic. evaluated eight different strategies ordering candidate undominated bin assignments, found min-weight
strategy sorts assignments non-decreasing order weight performed best. Fukunaga (2005) provides detailed comparison variable value orderings MCCP.
use L2 bound CMT algorithm.
5.3 Experimental Results
compared performance bin completion variants previous algorithms.
implemented following algorithms.
CMT - Christofides, Mingozzi Toth algorithm described above. implementation used smallest-bin-first variable ordering, min-weight value ordering,
L2 lower bound.
CMT+NP - CMT algorithm extended nogood pruning.
BC - Bin completion using min-weight value ordering smallest-bin-first variable
ordering.
BC+NP - Bin completion nogood pruning
BC+NDP - Bin completion nogood dominance pruning,
used smallest-bin-first variable ordering CMT BC variants observing led good performance compared random largest-bin-first variable
orderings.
experiment shown Table 4, compared CMT, CMT+NP, BC, BC+NP,
BC+NDP. purpose experiment evaluate relative impact
component bin completion, comparing various combinations of: (1) type
dominance criterion used, (2) whether nogood pruning used, (3) whether nogood
dominance pruning used.
used four classes test problems (uncorrelated, weakly correlated, strongly
correlated, subset-sum) multiple knapsack problem experiments (Section 4.4),
item weights costs range [10,1000]. four problem classes,
30 instances generated various values n. ran algorithm
instance. experiments run 2.7GHz Pentium 4. algorithm given
time limit 300 seconds solve instance. fail column indicates number
instances (out 30) could solved algorithm within time limit.
time nodes column show total time spent nodes generated, excluding failed
runs.

419

fin
# items

fail

5
10
5
10
15
20
5

15
30
10
20
30
40
20

0
30
0
1
30
30
0

5
10
5
10
15
20
5

15
30
10
20
30
40
20

5
10
5
10
15
20
5
5
10
5
10
15
20
5

CMT
time

nodes

fail

0.30
0.01
47.43
13.66

34094
256
5136873
1041966

0
30
0
0
11
30
0

0
30
0
0
28
30
1

0.21
0.01
3.22
227.63
54.11

10239
46
189874
16471570
975879

0
30
0
0
2
18
0

15
30
10
20
30
40
20

0
30
0
0
6
30
0

0.08
0.01
0.24
93.33
18.91

4226
30
19496
5178573
446419

0
30
0
0
0
18
0

15
30
10
20
30
40
20

0
30
0
0
10
30
0

0.08
0.01
0.17
74.57
18.11

4606
31
13286
3812510
384584

0
30
0
0
0
18
0

CMT+NP
time
nodes

fail

BC
time

nodes

Uncorrelated Instances
0.21
12641
0
0.02
678
20
184.79
12816074
0.01
48
0
0.01
127
0.17
10645
0
7.24
801863
80.04
3121178
30
30
0.10
4665
0
0.29
15979
Weakly Correlated Instances
0.13
4665
0
0.01
347
26
208
4242634
0.01
21
0
0.01
25
0.07
3979
0
0.13
11216
46.49
1803180
20
106.70
5367215
97.58
2874351
30
17.64
203251
0
0.65
15566
Strongly Correlated Instances
0.05
2518
0
0.01
68
0
54.65
1340276
0.01
16
0
0.01
10
0.02
1064
0
0.01
1064
5.18
241654
0
2.45
204069 0
97.19
2844301
17
52.50
2933474
20.78
253291
0
0.09
2474
Subset-Sum Instances
0.07
2899
0
0.01
65
0
32.71
810471
0.01
17
0
0.01
10
0.03
1573
0
0.01
986
17.48
789928
0
2.34
177683
97.90
2874340
17
55.18
2933474
17.66
203251
0
0.08
2270

fail

BC+NP
time

nodes

fail

BC+NDP
time
nodes

0
2
0
0
0
26
0

0.01
49.66
0.01
0.02
11.58
184.59
0.25

385
1952236
31
2149
705748
8356961
9339

0
0
0
0
0
10
0

0.01
23.82
0.01
0.01
2.81
97.67
0.15

238
635035
28
1149
136000
3145263
5193

0
16
0
0
0
12
0

0.01
168.21
0.01
0.01
3.19
112.08
0.54

197
2843080
12
428
182830
3871911
10032

0
5
0
0
0
2
0

0.01
97.16
0.01
0.01
0.56
44.84
0.45

150
1436142
12
236
30669
1704351
7698

0
0
0
0
0
1
0

0.01
17.60
0.01
0.01
0.12
27.17
0.07

53
333450
7
139
7532
1039810
1893

0
0
0
0
0
0
0

0.01
6.20
0.01
0.01
0.02
2.13
0.06

40
114786
7
79
1354
86685
1546

0
0
0
0
0
2
0

0.01
11.32
0.01
0.01
0.10
26.37
0.07

49
213975
8
146
6168
1160452
1605

0
0
0
0
0
0
0

0.01
3.97
0.01
0.01
0.02
2.47
0.06

42
70774
8
73
1272
125697
1242

Table 4: Min-cost covering problem results: Comparison (a) Christofides, Mingozzi, Toth (CMT) algorithm, (b) CMT algorihm Nogood
Pruning (NP), (c) Bin Completion, (d) Bin Completion Nogood Pruning (NP), (e) Bin Completion Nogood Dominance Pruning
(NDP). fail column indicates number instances (out 30) solved within time limit. time (seconds 2.7GHz
Pentium 4) nodes columns show average time spent nodes generated successful runs, excluding failed runs.

Fukunaga & Korf

420


# bins

fiBin Completion Algorithms Multicontainer Problems

shown Table 4, component bin completion significant impact. Although dominance criterion requires much computation per node simpler
CMT criterion, search efficiency dramatically improved. Thus, BC performed much
better CMT, BC+NP performed much better CMT+NP.
Furthermore, nogood pruning (NP) strategy significantly improves performance
algorithm based CMT dominance criterion, well dominance
criterion, evidenced improvement CMT+NP CMT improvement
BC+NP BC. fact, nogood pruning sufficiently powerful allows CMT+NP
sometimes outperform pure BC (without nogood pruning). Thus, data illustrates
power nogood pruning, confirming similar results bin packing reported (Korf,
2003), well preliminary experiments MKP MCCP.
Finally, BC+NDP results best performance, significantly outperforming BC+NP
larger instances respect number problems solved within time limit,
well runtimes nodes problems solved.
also implemented two baseline algorithms: straightforward integer programming
model using freely available GNU glpk integer programming solver, well itemoriented branch-and-bound algorithm uses L2 lower bound, baselines
performed poorly compared CMT bin completion algorithms (Fukunaga,
2005).

6. Bin Covering Problem
Given set identical containers quota q set n items, weight
wi , bin covering problem, sometimes called dual bin packing, assign items
containers number containers whose quotas satisfied (i.e., sum
item weights assigned container equal exceed quota) maximized (see 1.1.3
formal definition). Although considerable interest bin covering
problem algorithm operations research communities, previous work
bin covering theoretical, focusing approximation algorithms heuristic
algorithms (e.g., Assmann et al., 1984; Foster & Vohra, 1989; Csirik, Frenk, Galambos, &
Kan, 1991; Csirik, Johnson, & Kenyon, 2001), analysis properties classes
instances (e.g., Rhee & Talagrand, 1989).
6.1 Labbe, Laporte, Martello Algorithm
state-of-the-art algorithm opimally solving bin covering item-oriented branchand-bound algorithm Labbe, Laporte, Martello (1995). refer
LLM algorithm. items sorted non-increasing order size. node represents
decision bin put item into. node, upper bounds based
combinatorial arguments computed, remaining subproblem reduced using
two reduction criteria. root node, set heuristics applied order compute
initial solution lower bound. LLM upper lower bounds described
(Labbe et al., 1995).

421

fiFukunaga & Korf

6.2 Bin Completion Bin Covering
bin completion algorithm bin covering works follows. First, use LLM
upper bounding heuristics root node find initial solution lower bound.
Then, apply bin completion branch-and-bound algorithm, using new dominance
criterion (Proposition 3). node depth-first, search tree represents minimal,
feasible bin assignment particular bin include largest remaining item.
node, apply upper bounding procedures LLM algorithm compute
upper bound. addition, apply LLM reduction criteria node. evaluated
eight different strategies ordering undominated bin assignments, found mincardinality-min-sum strategy (sort bin assignments order non-decreasing cardinality,
breaking ties non-decreasing sum) performed best overall (Fukunaga, 2005).
6.3 Empirical Results
order evaluate bin covering algorithm, considered class uniform, random
problem instances previously studied Labbe, Laporte, Martello. simple
model n items chosen uniformly range [min, max], max less
bin quota q. experimental evaluations, Labbe, Laporte, Martello used
items weights range 1 100, bin quotas ranging 100 500.
However, many instances class solved without search. LLM
lower bound heuristics find solution number bins LLM upper
bound, found optimal solution terminate without search.
say instance trivial solved without search, nontrivial otherwise.
illustrate prepondrance trivial instances, generated 10000 uniform, random
instances bin quota 100000 120 items weights range [1, 99999].
these, 9084 solved root node. shows uniform random bin
covering instances are, fact, trivial given powerful upper lower bounds.
previously observed similar phenomenon bin packing uniform, random bin
packing instances solved root node combination best-first-decreasing
heuristic Martello-Toth L2 lower bound (Korf, 2002).
well-known number significant digits precision weights
items significantly affects difficulty one-dimensional packing problems
0-1 Knapsack problem (Kellerer et al., 2004). general, problem difficulty increases
precision. property extends multicontainer, one-dimensional packing problems
well (e.g., Pisinger, 1999). confirmed problem difficulty highly correlated
number significant digits item weights (Fukunaga, 2005).
Therefore, experiments described below, used nontrivial instances,
order highlight impact differences search strategy. is, generating
test instances, filtered trivial instances testing whether LLM upper bound
matched lower bound heuristics. Furthermore, use high precision problems
(quotas 10000 more) order focus difficult instances.
6.3.1 Hybrid Incremental Branching
Section 3.4, proposed hybrid incremental branching, strategy avoiding runtime memory overheads imposed completely enumerating undominated children
422

fiBin Completion Algorithms Multicontainer Problems

node. earlier experiments multiple knapsack min-cost covering
problems, (Sections 45), problem instances used experiments fewer 50
items, observed hundred assignments generated
node MKP MCCP experiments. Thus, number candidate undominated
bin assignments generated per node become bottleneck, hybrid incremental branching unnecessary. However, (1) average number items fit
container increases, (2) number items increases, number candidate undominated bin assignments per node increases. Therefore, benchmark comparisons
bin covering, hybrid incremental branching becomes much relevant.
illustrate this, performed following experiment. generated 20 nontrivial
instances bin quota q=20000 100 items range [1,9999]. applied bin
completion + NDP problem instances, using hybrid incremental branching
various values parameter h, limits number children generated
every node. h= 2000, 200, 20, 2, instances solved average
4.998 seconds, 0.150 seconds, 0.0139 seconds, 0.0079 seconds, respectively.
average number nodes expanded 20.2 h {2, 20, 200, 2000}. words,
instances easily solved relying leftmost children node
bin completion search tree generating additional children entirely unnecessary
expensive overhead. Thus, h increases, number nodes
explored, node requires much computation enumerate sort h
undominated children, resulting two orders magnitude difference runtime
h = 2 h = 2000. see large h would order able
enumerate undominated children node, experimented h
10000, found insufficient (the statically allocated array size h overflowed
runs).
experimented several values h several classes problems, found
optimal value h varied significantly depending problem instance.
experiments below, use hybrid incremental branching h=100, order set
balance minimizing number nodes expanded (exploiting value ordering
among children node) minimizing computational overhead per node (by
minimizing number children generated).
6.3.2 Comparing LLM Bin Completion
Next, compared LLM, bin completion+NP, bin completion+NDP using larger instances. also implemented straightforward integer linear programming model using
GNU glpk bin covering, found performed much worse LLM
bin completion algorithms (Fukunaga, 2005).
n {60, 80, 100}, generated 2000 non-trivial, uniform random instances
items chosen uniformly range [1,99999], bin quota 100000.
also generated 2000 non-trivial instances n = 100, q = 200000, items
range [1,99999]. ran implementations three algorithms instance,
time limit 180 seconds per instance. shown Table 5, bin completion
algorithms significantly outperformed LLM. harder problems, bin completion + NDP
significantly outperforms bin completion + NP. problems n = 100, q = 200000,

423

fiFukunaga & Korf

n (# items)

q (quota)

60
80
100

100000
100000
100000

100

200000

Labbe et al.
Bin Completion+NP
fail time
nodes fail time
nodes
2000 nontrivial instances per set
10 0.39
25196
6 0.08
33287
36 1.02
62093
15 0.18
39740
45 1.98 113110
15 0.42
152113
100 nontrivial instances per set
100
3 0.11
25

Bin Completion+NDP
fail time
nodes
2
12
8

0.11
0.09
0.31

13735
10517
31107

3

0.11

25

Table 5: Bin Covering results: Comparison Labbe, Laporte, Martello algorithm, Bin
Completion Nogood Pruning, Bin Completion Nogood Dominance
Pruning. fail column indicates number instances (out 30)
solved within time limit. time (seconds 2.7GHz Pentium 4)
nodes columns show average time spent nodes generated successful
runs, excluding failed runs.

results indicate instances extremely difficult LLM algorithm,
failed solve 100 instances within time limit, problems
actually relatively easy bin completion. Since little search performed
bin completion, bin completion+NDP improve upon bin completion+NP.

7. Bin Packing
bin completion approach originally developed bin packing problem,
shown significantly outperform Martello-Toth Procedure randomly generated
instances (Korf, 2002, 2003). implemented extended bin completion algorithm
bin packing problem, summarize results below. details, see (Fukunaga,
2005). bin completion based solver incorporated nogood dominance pruning
min-cardinality-max-weight value ordering strategy, (1) completions sorted
order non-decreasing cardinality, (2) ties broken according non-increasing
weight.
evaluated bin completion solver using set standard OR-LIB instances.6
test set consists 80 triplet instances (where elements generated three
time sum elements add exactly bin capacity) 80 uniform
instances (where items sizes chosen uniform random distribution). bin
completion solver (executed 1.3GHz Athlon) given time limit 15 minutes
instance benchmark set. solved 80 triplet instances ORLIB within 1500 seconds combined. solved 40 uniform instances 120
250 items 4 seconds combined. solved 18 (out 20) 500-item uniform
instances 11.13 seconds combined, failed solve 2 instances. Bin completion solved
19 (out 20) 1000-item uniform instances 44 seconds combined, failed
solve one instances.
6. available http://www.brunel.ac.uk/depts/ma/research/jeb/info.html

424

fiBin Completion Algorithms Multicontainer Problems

However, bin completion solver competitive state art,
recently developed branch-and-price integer linear programming solver Belov
Scheithauer (2006). Belov Scheithauer provide new benchmark set 28 hard
bin packing instances; solver solved within seconds, although took
hours. current bin completion code could solve 28 instances, given
15 minutes per instance. also report largest triplet instances OR-LIB
(Triplet-501) solved average 33 seconds per instance (660 seconds total)
1GHz AMD Athlon XP. Furthermore, Belov kind enough run solver set
one hundred, 80-item, uniform, random instances generated items
range [1,1000000] bin capacity 1000000. solver solved instances
less 1 second root node (i.e., without search), using rounding
heuristics based linear programming LP solution, whereas best bin completion
solver required 534 seconds searched 75,791,226 nodes.
7.1 Branch-and-Price vs. Bin Completion
Recent branch-and-price approaches bin packing solver Belov Scheithauer use bin-oriented branching strategy, decisions correspond instantiation one maximal bin assignments (see Valerio de Carvalho, 2002, survey
branch-and-price approaches). node, column generation procedure used
compute LP lower bound. derive much power accurate
LP lower bound based cutting-stock formulation bin packing (Gilmore & Gomory,
1961), observed almost always give optimal value lower bound,
never observed give value one greater optimal
value (e.g., Wascher & Gau, 1996). addition, rounding heuristics applied fractional
LP-solutions often yield optimal, integral solution. combination tight
LP lower bound good upper bounding procedure results little search
performed almost problem instances.
branch-and-price LP-based approach seem generalize straightforwardly
MKP MCCP, part due differences granularity objective
function. objective function bin packing counts number bins used.
hand, objective functions MKP MCCP sums profits items
assigned containers. Thus, number possible, distinct objective function values
MKP MCCP much larger number distinct objective function values
bin packing problem comparable size. Therefore, even assume existence
formulation analogous cutting-stock problem, likely rounding
LP solution MKP, MCCP, problems objective functions
fine-grained compared bin packing result optimistic bound accurate
bin packing. suggests may difficult develop branch-and-price
solver competitive problems. hand, since granularity
objective function bin covering bin packing, possible
branch-and-price approach could applied bin covering. However, unaware
approach literature.

425

fiFukunaga & Korf

8. Conclusions
studied bin completion, branch-and-bound approach multi-container packing,
knapsack, covering problems. previous work focused item-oriented, branchand-bound strategies assign one item time containers, bin completion
bin-oriented branch-and-bound algorithm uses dominance relationship bin
assignments prune search. presented general framework approach,
showed general utility applicability multicontainer problems. proposed
several extensions bin completion improve efficiency, including nogood pruning,
nogood dominance pruning, variable value ordering heuristics, hybrid incremental
undominated completion generation. demonstrated power bin completion
approach developing new, state-of-the-art algorithms three fundamental multicontainer problems. showed bin completion algorithms significantly outperform
Mulknap (Pisinger, 1999) MTM (Martello & Toth, 1981) algorithms hard MKP
instances. developed new, state-of-the-art algorithm MCCP based bin
completion. showed exploiting powerful dominance criterion, new
bin completion algorithms significantly outperform early bin completion algorithm
Christofides, Mingozzi, Toth (1979). developed new, state-of-the-art algorithm
bin covering based bin completion, showed bin completion algorithm significantly outperforms item-oriented branch bound algorithm Labbe, Laporte,
Martello (1995). However, results bin packing competitive stateof-the-art solver based cutting-stock approach. showed four
problems studied, nogood dominance pruning consistently improves upon performance
bin completion nogood pruning.7
focused four particular multicontainer problems paper,
many similar problems involving assignment objects multiple containers
similar dominance relationships candidate bin assignments exploited. Examples include generalized assignment problem, widely studied generalization
MKP many applications weight profit item function container assigned (e.g., Cattrysse & Wassenhove, 1992; Martello & Toth, 1990),
multiprocessor scheduling, equivalent k-way number partitioning, (DellAmico
& Martello, 1995), segregated storage problem (Neebe, 1987; Evans & Tsubakitani,
1993). addition, variants problems studied additional constraints,
class-constrained multiple knapsack problem (Shachnai & Tamir, 2001a, 2001b;
Kellerer et al., 2004) applications multimedia file storage. Exploiting powerful dominance criteria bin completion framework appears promising future
direction multicontainer problems.
One issue bin completion number unique items grows, number
undominated bin assignments grows rapidly. showed hybrid incremental
branching significantly alleviate problem (Section 6.3.1), drawback limits
utility value-ordering heuristics applied sort undominated bin assignments
generated. Thus, algorithm generates undominated assignments
7. previously showed nogood pruning significantly improves performance bin-completion without pruning (Korf, 2003). also confirmed MCCP (Table 4), MKP
bin covering preliminary experiments.

426

fiBin Completion Algorithms Multicontainer Problems

order conforms desired heuristic value ordering, rather relying sorting
assignments generated, area future work.

Acknowledgments
Thanks Gleb Belov running solver bin packing test instances.
anonymous reviewers provided many helpful comments suggestions improved
paper. research supported NSF grant No. EIA-0113313,
Jet Propulsion Laboratory, California Institute Technology, contract
National Aeronautics Space Administration.

References
Assmann, S., Johnson, D., Kleitman, D., & Leung, J. (1984). dual version
one-dimensional binpacking problem. Journal Algorithms, 5, 502525.
Belov, G., & Scheithauer, G. (2006). branch-and-cut-and-price algorithm onedimensional stock cutting two-dimensional two-stage cutting. European Journal
Operational Research, 171, 85106.
Caprara, A., Kellerer, H., & Pferchy, U. (2000a). PTAS multiple-subset sum
problem different knapsack capacities. Information Processing Letters, 73, 111
118.
Caprara, A., Kellerer, H., & Pferschy, U. (2000b). multiple subset sum problem. SIAM
Journal Optimization, 11, 308319.
Caprara, A., Kellerer, H., & Pferschy, U. (2003). 3/4-approximation algorithm multiple
subset sum. Journal Heuristics, 9, 99111.
Carlyle, M., Knutson, K., & Fowler, J. (2001). Bin covering algorithms second stage
lot order matching problem. Journal Operational Research Society,
52, 12321243.
Cattrysse, D., & Wassenhove, L. V. (1992). survey algorithms generalized
assignment problem. European Journal Operational Research, 60, 260272.
Christofides, N., Mingozzi, A., & Toth, P. (1979). Loading problems. Christofides, N.,
Mingozzi, A., Toth, P., & Sandi, C. (Eds.), Combinatorial Optimization. John Wiley
& Sons.
Csirik, J., Frenk, J., Galambos, G., & Kan, A. R. (1991). Probabilistic analysis algorithms
dual bin packing problems. Journal Algorithms, 12, 189203.
Csirik, J., Johnson, D., & Kenyon, C. (2001). Better approximation algorithms bin
covering. Proc. 12th ACM/SIAM Symposium Discrete Algorithms, pp.
557566.
DellAmico, M., & Martello, S. (1995). Optimal scheduling tasks identical parallel
processors. ORSA Journal Computing, 7 (2), 181200.
Eilon, S., & Christofides, N. (1971). loading problem. Management Science, 17 (5),
259268.
427

fiFukunaga & Korf

Evans, J., & Tsubakitani, S. (1993). Solving segregated storage problem Benders
partitioning. Journal Operational Research Society, 44 (2), 175184.
Fahle, T., Schamberger, S., & Sellmann, M. (2001). Symmetry breaking. Proceedings
International Conference Constraint Programming, pp. 93107.
Focacci, F., & Milano, M. (2001). Global cut framework removing symmetries.
Proceedings International Conference Constraint Programming, pp. 7792.
Focacci, F., & Shaw, P. (2002). Pruning sub-optimal search branch brances using local
search. Proc. Fourth International Workshop Integration AI Techniques Constraing Programming Combinatorial Optimisation Problems (CPAI-OR), pp. 181189.
Foster, D., & Vohra, R. (1989). Probabilistic analysis heuristic dual bin packing
problem. Information Processing Letters, 31, 287290.
Fukunaga, A. (2005). Bin-Completion Algorithms One Dimensional, Multicontainer
Packing Problems. Ph.D. thesis, UCLA.
Gent, I., & Smith, B. (2000). Symmetry breaking search constraint programming.
Proc. European Conference Artificial Intelligence, pp. 599603.
Gilmore, P., & Gomory, R. (1961). linear programming approach cutting stock
problem. Operations Research, 9, 849859.
Gomes, C., & Selman, B. (2001). Algorithm portfolios. Artificial Intelligence, 126, 4362.
Huberman, B., Lukose, R., & Hogg, T. (1997). economic approach hard computational
problems. Science, 265, 5154.
Kalagnanam, J., Davenport, A., & Lee, H. (2001). Computational aspects clearing continuous call double auctions assignment constraints indivisible demand. Electronic Commerce Research, 1, 221238.
Kellerer, H., Pferschy, U., & Pisinger, D. (2004). Knapsack Problems. Springer-Verlag.
Korf, R. (2002). new algorithm optimal bin packing. Proceedings AAAI, pp.
731736.
Korf, R. (2003). improved algorithm optimal bin packing. Proceedings
International Joint Conference Artificial Intelligence, pp. 12521258.
Labbe, M., Laporte, G., & Martello, S. (1995). exact algorithm dual bin packing
problem. Operations Research Letters, 17, 918.
Labbe, M., Laporte, G., & Martello, S. (2003). Upper bounds algorithms
maximum cardinality bin packing problem. European Journal Operational Research,
149, 490498.
Martello, S., & Toth, P. (1977). upper bound zero-one knapsack problem
branch bound algorithm. European Journal Operational Research, 1, 169175.
Martello, S., & Toth, P. (1981). bound bound algorithm zero-one multiple
knapsack problem. Discrete Applied Mathematics, 3, 275288.
Martello, S., & Toth, P. (1990). Knapsack problems: algorithms computer implementations. John Wiley & Sons.
428

fiBin Completion Algorithms Multicontainer Problems

Mitchell, D., Selman, B., & Levesque, H. (1992). Hard easy distributions SAT
problems. Proceedings AAAI, pp. 45965.
Neebe, A. (1987). improved, multiplier adjustment procedure segregated storage
problem. Journal Operational Research Society, 38 (9), 815825.
Pisinger, D. (1999). exact algorithm large multiple knapsack problems. European
Journal Operational Research, 114, 528541.
Rhee, W., & Talagrand, M. (1989). Optimal bin covering items random size. SIAM
Journal Computing, 18, 487498.
Scholl, A., Klein, R., & Jurgens, C. (1997). BISON: fast hybrid procedure exactly
solving one-dimensional bin packing problem. Computers Operations Research,
24 (7), 627645.
Shachnai, H., & Tamir, T. (2001a). two class-constrained versions multiple
knapsack problem. Algorithmica, 29, 442467.
Shachnai, H., & Tamir, T. (2001b). Polynomial time approximation schemes classconstrained packing problems. Journal Scheduling, 4, 313338.
Shaw, P. (2004). constraint bin packing. Proceedings 10th International Conference Principles Practice Constraint Programming 2004 (CP-2004),
Lecture Notes Computer Science Vol. 3258, pp. 648662. Springer.
Valerio de Carvalho, J. (2002). LP models bin packing cutting stock problems.
European Journal Operational Research, 141, 253273.
Wascher, G., & Gau, T. (1996). Heuristics integer one-dimensional cutting stock
problem: computational study. Spektrum, 18 (3), 131144.

429

fiJournal Artificial Intelligence Research 28 (2007) 349391

Submitted 06/06; published 03/07

Closed-Loop Learning Visual Control Policies
Sebastien Jodogne
Justus H. Piater

Jodogne@Montefiore.ULg.ac.be
Justus.Piater@ULg.ac.be

Montefiore Institute (B28)
University Liege, B-4000 Liege, Belgium

Abstract
paper present general, flexible framework learning mappings images actions interacting environment. basic idea introduce
feature-based image classifier front reinforcement learning algorithm. classifier
partitions visual space according presence absence highly informative local descriptors incrementally selected sequence attempts remove
perceptual aliasing. also address problem fighting overfitting greedy
algorithm. Finally, show high-level visual features generated
power local descriptors insufficient completely disambiguating aliased states.
done building hierarchy composite features consist recursive spatial
combinations visual features. demonstrate efficacy algorithms solving
three visual navigation tasks visual version classical Car Hill control
problem.

1. Introduction
Designing robotic controllers quickly becomes challenging problem. Indeed, controllers face huge number possible inputs noisy, must select actions among
continuous set, able automatically adapt evolving stochastic environmental conditions. Although real-world robotic task often solved
directly connecting perceptual space action space given computational
mechanism, mappings usually hard derive hand, especially perceptual space contains images. Evidently, automatic methods generating mappings
highly desirable, many robots nowadays equipped CCD sensors.
paper, interested reactive systems learn couple visual perceptions
actions inside dynamic world act reasonably. coupling known
visual (control) policy. wide category problems called vision-for-action tasks
(or simply visual tasks). Despite fifty years years active research artificial
intelligence, robotic agents still largely unable solve many real-world visuomotor
tasks easily performed humans even animals. vision-for-action
tasks notably include grasping, vision-guided navigation manipulation objects
achieve goal. article introduces general framework suitable building
image-to-action mappings using fully automatic flexible learning protocol.
1.1 Vision-for-Action Reinforcement Learning
Strong neuropsychological evidence suggests human beings learn extract useful information visual data interactive fashion, without external supervisor (Gibson
c
2007
AI Access Foundation. rights reserved.

fiJodogne & Piater

& Spelke, 1983). evaluating consequence actions environment,
learn pay attention visual cues behaviorally important solving task.
way, interact outside world, gain expertise
tasks (Tarr & Cheng, 2003). Obviously, process task driven, since different tasks
necessarily need make distinctions (Schyns & Rodet, 1997).
breakthrough modern artificial intelligence would design artificial system
would acquire object scene recognition skills based experience
surrounding environment. state general terms, important research
direction would design robotic agent could autonomously acquire visual skills
interactions uncommitted environment order achieve set
goals. Learning new visual skills dynamic, task-driven fashion complete
priori unknown visual task known purposive vision paradigm (Aloimonos, 1990).
One plausible framework learn image-to-action mappings according purposive vision Reinforcement Learning (RL) (Bertsekas & Tsitsiklis, 1996; Kaelbling, Littman,
& Moore, 1996; Sutton & Barto, 1998). Reinforcement learning biologically-inspired
computational framework generate nearly optimal control policies automatic
way, interacting environment. RL founded analysis so-called
reinforcement signal . Whenever agent takes decision, receives feedback real
number evaluates relevance decision. biological perspective,
signal becomes positive, agent experiences pleasure, talk reward .
Conversely, negative reinforcement implies sensation pain, corresponds
punishment. reinforcement signal arbitrarily delayed actions
responsible it. Now, RL algorithms able map every possible perception
action maximizes reinforcement signal time. framework, agent
never told optimal action facing given percept, whether one
decisions optimal. Rather, agent discover promising
actions constituting representative database interactions, understanding influence decisions future reinforcements. Schematically, RL lies
supervised learning (where external teacher gives correct action agent)
unsupervised learning (in clue goodness action given).
RL successful applications, example turning computer excellent
Backgammon player (Tesauro, 1995), solving Acrobot control problem (Yoshimoto,
Ishii, & Sato, 1999), making quadruped robot learn progressively walk without
human intervention (Huber & Grupen, 1998; Kimura, Yamashita, & Kobayashi, 2001; Kohl
& Stone, 2004), riding bicycle (Randlv & Alstrm, 1998; Lagoudakis & Parr, 2003)
controlling helicopter (Bagnell & Schneider, 2001; Ng, Coates, Diel, Ganapathi, Schulte,
Tse, Berger, & Liang, 2004). major advantages RL protocol fully
automatic, imposes weak constraints environment.
Unfortunately, standard RL algorithms highly sensitive number distinct
percepts well noise results sensing process. general problem
often referred Bellman curse dimensionality (Bellman, 1957). Thus, high
dimensionality noise inherent images forbid use basic RL algorithms
direct closed-loop learning image-to-action mappings according purposive vision.
350

fiClosed-Loop Learning Visual Control Policies

1.2 Achieving Purposive Vision Reinforcement Learning
exists variety work RL specific robotic problems involving perceptual
space contains images. instance, Schaal (1997) uses visual feedback solve
pole-balancing task. RL used control vision-guided underwater robotic vehicle (Wettergreen, Gaskett, & Zelinsky, 1999). recently, Kwok Fox (2004)
demonstrated applicability RL learning sensing strategies using Aibo robots.
Reinforcement learning also used learn strategies view selection (Paletta &
Pinz, 2000) sequential attention models (Paletta, Fritz, & Seifert, 2005). Let us also
mention use reinforcement learning vision-guided tasks ball kicking (Asada, Noda, Tawaratsumida, & Hosoda, 1994), ball acquisition (Takahashi, Takeda,
& Asada, 1999), visual servoing (Gaskett, Fletcher, & Zelinsky, 2000), robot docking (Weber, Wermter, & Zochios, 2004; Martnez-Marn & Duckett, 2005) obstacle avoidance (Michels, Saxena, & Ng, 2005). Interestingly, RL also used way tuning high-level parameters image-processing applications. example, Peng
Bhanu (1998) introduce RL algorithms image segmentation, whereas Yin (2002) proposes algorithms multilevel image thresholding, uses entropy reinforcement
signal.
applications preprocess images extract high-level information
observed scene directly relevant task solved feeds
RL algorithm. requires prior assumptions images perceived sensors
agent, physical structure task itself. preprocessing step
task specific coded hand. contrasts objectives, consist
introducing algorithms able learn directly connect visual space action
space, without using manually written code without relying prior knowledge
task solved. aim develop general algorithms applicable
visual task formulated RL framework.
noticeable exception work Iida et al. (2002) apply RL seek reach
targets, push boxes (Shibata & Iida, 2003) real robots. work, raw visual
signals directly feed neural network trained actor-critic architecture.
examples, visual signal downscaled averaged monochrome (i.e. two-color)
image 64 24 = 1536 pixels. output four infrared sensors also added
perceptual input. approach effective specific tasks, process
used highly controlled environment. Real-world images much richer
could undergo strong reduction size.
1.3 Local-Appearance Paradigm
paper, propose algorithms rely extraction visual features
way achieve compact state spaces used input traditional RL
algorithms. Indeed, buried noise confusion visual cues, images contain
hints regularity. regularities captured important notion visual features.
Loosely speaking, visual feature representation aspect local appearance,
e.g. corner formed two intensity edges, spatially localized texture signature,
color. Therefore, analyze images, often sufficient computer program extract
useful information visual signal, focusing attention robust highly
351

fiJodogne & Piater

percepts

Image Classifier

reinforcements

detected visual class
informative visual features

Reinforcement Learning

actions

Figure 1: structure Reinforcement Learning Visual Classes.

informative patterns percepts. program thereafter seek characteristic
appearance observed scenes objects.
actually basic postulate behind local-appearance methods
much success computer vision applications image matching, image retrieval
object recognition (Schmid & Mohr, 1997; Lowe, 2004). rely detection
discontinuities visual signal thanks interest point detectors (Schmid, Mohr, &
Bauckhage, 2000). Similarities images thereafter identified using local description
neighborhood around interest points (Mikolajczyk & Schmid, 2003): two images
share sufficient number matching local descriptors, considered belong
visual class.
Local-appearance techniques time powerful flexible,
robust partial occlusions, require segmentation 3D models scenes.
seems therefore promising introduce, front RL algorithm, feature-based
image classifier partitions visual space finite set distinct visual classes
according local-appearance paradigm, focusing attention agent
highly distinctive local descriptors located interest points visual stimuli.
symbol corresponding detected visual class could given input
classical, embedded RL algorithm, shown Figure 1.
preprocessing step intended reduce size input domain, thus enhancing rate convergence, generalization capabilities well robustness
RL noise visual domains. Importantly, family visual features
applied wide variety visual tasks, thus preprocessing step essentially general
task-independent. central difficulty dynamic selection discriminative
visual features. selection process group images share similar, task-specific
properties together visual class.
1.4 Contributions
key technical contribution paper consists introduction reinforcement
learning algorithms used perceptual space contains images.
developed algorithms rely task-specific pre-treatment. consequence,
used vision-for-action task formalized Markov Decision
Problem. review three major contributions discussed paper.
352

fiClosed-Loop Learning Visual Control Policies

1.4.1 Adaptive Discretization Visual Space
first contribution propose new algorithm called Reinforcement Learning Visual
Classes (RLVC) combines aforementioned ideas. RLVC iterative algorithm
suitable learning direct image-to-action mappings taking advantage
local-appearance paradigm. consists two simultaneous, interleaved learning processes:
Reinforcement learning mapping visual classes actions, incremental building
feature-based image classifier.
Initially, image classifier contains one single visual class, images
mapped class. course, introduces kind perceptual aliasing (or hidden
state) (Whitehead & Ballard, 1991): optimal decisions cannot always made, since
percepts requiring different reactions associated class. agent
isolates aliased classes. Since external supervisor, agent rely
statistical analysis earned reinforcements. detected aliased class, agent
dynamically selects new visual feature distinctive, i.e. best disambiguates
aliased percepts. extracted local descriptor used refine classifier. way,
stage algorithm, number visual classes classifier grows. New
visual features learned perceptual aliasing vanishes. resulting image classifier
finally used control system.
approach primarily motivated strong positive results McCallums U-Tree
algorithm (McCallum, 1996). essence, RLVC adaptation U-Tree visual spaces,
though internals algorithms different. originality RLVC lies
exploitation successful local-appearance features. RLVC selects subset highly
relevant features fully closed-loop, purposive learning process. show
algorithm practical interest, successfully applied several simulated
visual navigation tasks.
1.4.2 Compacting Visual Policies
greedy nature, RLVC prone overfitting. Splitting one visual class
potentially improve control policy visual classes. Therefore, splitting
strategy get stuck local minima: split made subsequently proves
useless, cannot undone original description RLVC. second contribution
provide RLVC possibility aggregating visual classes share similar
properties. least three potential benefits:
1. Useless features discarded, enhances generalization capabilities;
2. RLVC reset search good features;
3. number samples embedded RL algorithm disposal
visual class increased, results better visual control policies.
Experiments indeed show improvement generalization abilities, well reduction number visual classes selected features.
353

fiJodogne & Piater

1.4.3 Spatial Combinations Visual Features
Finally, efficacy RLVC clearly depends discriminative power visual
features. power insufficient, algorithm able completely remove
aliasing, produce sub-optimal control policies. Practical experiments
simulated visual navigation tasks exhibit deficiency, soon number detected
visual features reduced features made similar using less sensitive
metric. Now, objects encountered world composed number distinct
constituent parts (e.g. face contains nose two eyes, phone possesses keypad).
parts recursively composed sub-parts (e.g. eye contains
iris eyelashes, keypad composed buttons). hierarchical physical structure
certainly imposes strong constraints spatial disposition visual features.
third contribution show highly informative spatial combinations visual
features iteratively constructed framework RLVC. result promising
permits construction features increasingly higher levels discriminative
power, enabling us tackle visual tasks unsolvable using individual point features
alone. best knowledge, extension RLVC appears
first attempt build visual feature hierarchies closed-loop, interactive purposive
learning process.

2. Overview Reinforcement Learning
framework relies theory RL, introduced section. RL,
environment traditionally modeled Markov Decision Process (MDP). MDP
tuple hS, A, , Ri, finite set states, finite set actions,
probabilistic transition function S, R reinforcement function
R. MDP obeys following discrete-time dynamics: time t, agent
takes action environment lies state st , agent perceives numerical
reinforcement rt+1 = R(st , ), reaches state st+1 probability (st , , st+1 ).
Thus, point view agent, interaction environment defined
quadruple hst , , rt+1 , st+1 i. Note definition Markov decision processes
assumes full observability state space, means agent able
distinguish states environment using sensors. allows us
talk indifferently states percepts. visual tasks, set images.
percept-to-action mapping fixed probabilistic function : 7 states
actions. percept-to-action mapping tells agent probability
choose action faced percept. RL terminology, mapping called
stationary Markovian control policy. infinite sequence interactions starting
state st , discounted return
Rt =


X

rt+i+1 ,

(1)

i=0

[0, 1[ discount factor gives current value future reinforcements. Markov decision problem given MDP find optimal percept-to-action
mapping maximizes expected discounted return, whatever starting state is.
354

fiClosed-Loop Learning Visual Control Policies

possible prove problem well-defined, optimal percept-to-action
mapping always exists (Bellman, 1957).
Markov decision problems solved using Dynamic Programming (DP) algorithms
(Howard, 1960; Derman, 1970). Let percept-to-action mapping. Let us call
state-action value function Q (s, a) , function giving state
action expected discounted return obtained starting state s, taking action
a, thereafter following mapping :
Q (s, a) = E {Rt | st = s, = a} ,

(2)

E denotes expected value agent follows mapping . Let us also define
H transform Q functions Q functions
X
(HQ)(s, a) = R(s, a) +
(s, a, s0 ) max
Q(s0 , a0 ),
(3)
0
s0



A. Note H transform equally referred Bellman
backup operator state-action value functions. optimal mappings given MDP
share Q function, denoted Q called optimal state-action value function,
always exists satisfies Bellmans so-called optimality equation (Bellman, 1957)
HQ = Q .

(4)

optimal state-action value function Q known, optimal deterministic perceptto-action mapping easily derived choosing
(s) = argmax Q (s, a),

(5)

aA

S. Another useful concept DP theory optimal value
function V . state S, V (s) corresponds expected discounted return
agent always chooses optimal action encountered state, i.e.
V (s) = max Q (s, a).
aA

(6)

Dynamic Programming includes well-known Value Iteration (Bellman, 1957), Policy Iteration (Howard, 1960) Modified Policy Iteration (Puterman & Shin, 1978) algorithms. Value Iteration learns optimal state-action value function Q , whereas Policy
Iteration Modified Policy Iteration directly learn optimal percept-to-action mapping.
RL set algorithmic methods solving Markov decision problems
underlying MDP known (Bertsekas & Tsitsiklis, 1996; Kaelbling et al., 1996; Sutton
& Barto, 1998). Precisely, RL algorithms assume knowledge R.
input RL algorithms basically sequence interactions hst , , rt+1 , st+1 agent
environment. RL techniques often divided two categories:
1. Model-based methods first build estimate underlying MDP (e.g.
computing relative frequencies appear sequence interactions),
use classical DP algorithms Value Policy Iteration;
2. Model-free methods SARSA (Rummery & Niranjan, 1994), D() (Barto,
Sutton, & Anderson, 1983; Sutton, 1988), popular Q-learning (Watkins,
1989), compute estimate.
355

fiJodogne & Piater

3. Reinforcement Learning Visual Classes
discussed Introduction, propose insert image classifier RL
algorithm. classifier maps visual stimuli set visual classes according
local-appearance paradigm, focusing attention agent highly distinctive
local descriptors detected interest points images.
3.1 Incremental Discretization Visual Space
Formally, let us call D, infinite set local descriptors spanned
chosen local description method. elements equivalently referred visual
features. Usually, corresponds Rn n 1. assume existence visual
feature detector , Boolean function : 7 B testing whether given image
exhibits given local descriptor one interest points (Schmid et al., 2000).
suitable metric used test similarity two visual features, e.g. Mahalanobis
Euclidean distance.
image classifier iteratively refined. incremental process, natural
way implement image classifiers use binary decision trees. internal
nodes labeled visual feature, presence tested node.
leaves trees define set visual classes, hopefully much smaller
original visual space, upon possible apply directly usual RL
algorithm. classify image, system starts root node, progresses
tree according result feature detector visual feature found
descent, reaching leaf.
summarize, RLVC builds sequence C0 , C1 , C2 , . . . growing decision trees,
sequence attempts remove perceptual aliasing. initial classifier C0 maps
input images single visual class V0,1 . stage k, classifier Ck partitions
visual perceptual space finite number mk visual classes {Vk,1 , . . . , Vk,mk }.
3.2 Learning Architecture
resulting learning architecture called Reinforcement Learning Visual Classes
(RLVC) (Jodogne & Piater, 2005a). basic idea behind algorithms, namely
iterative learning decision tree, primarily motivated adaptive-resolution techniques
previously introduced reinforcement learning, notably McCallums
U-Tree algorithm (McCallum, 1996). section, idea showed extremely
fruitful suitably adapted visual spaces. links RLVC adaptiveresolution techniques thoroughly discussed Section 3.6.
components RLVC depicted Figure 2. in-depth discussion
components given next sections. time being, review
them:
RL algorithm: classifier sequence, arbitrary, standard RL algorithm
applied. provides information optimal state-action function,
optimal value function optimal policy induced current classifier
Ck . purpose computations, either new interactions acquired,
356

fiClosed-Loop Learning Visual Control Policies

Figure 2: different components RLVC algorithm.
database previously collected interactions exploited. component
covered Sections 3.3.1 3.3.2.
Aliasing detector: agent learned visual classes required complete
task, viewpoint embedded RL algorithm, input space
partially observable. aliasing detector extracts classes perceptual
aliasing occurs, analysis Bellman residuals. Indeed, explained
Section 3.3.3, exist tight relations perceptual aliasing Bellman
residuals. aliased class detected, RLVC stops.
Feature generator: applied RL algorithm, database interactions
hst , , rt+1 , st+1 available. feature generator component produces set F
candidate visual features aliased class Vk,i . features used
refine classifier chosen among set candidates. step
exposed Sections 3.4 5.
Feature selector: set candidate features F built aliased visual
class Vk,i , component selects visual feature f F best reduces
perceptual aliasing. candidate feature discriminant, component returns
conventional bottom symbol . feature selector RLVC described
Section 3.4.
Classifier refinement: leaves correspond aliased classes featurebased image classifier replaced internal node testing presence absence
selected visual features.
Post-processing: optional component invoked every refinement, corresponds techniques fighting overfitting. Details given Section 4.
general outline RLVC described Algorithm 1. Note experiments contained paper, model-based RL algorithms applied static
357

fiJodogne & Piater

Algorithm 1 General structure RLVC
1: k 0
2: mk 1
3: Ck binary decision tree one leaf
4: repeat
5:
Collect N interactions hst , , rt+1 , st+1
6:
Apply arbitrary RL algorithm sequence mapped Ck
7:
Ck+1 Ck
8:
{1, . . . , mk }
9:
aliased(Vk,i )
10:
F generator ({st | Ck (st ) = Vk,i })
11:
f selector (Vk,i , F )
12:
f 6=
13:
Ck+1 , refine Vk,i testing f
14:
mk+1 mk+1 + 1
15:
end
16:
end
17:
end
18:
k k+1
19:
post-process(Ck )
20: Ck = Ck1
databases interactions fifth step Algorithm 1. databases collected
using fully randomized exploration policy. choice guided ease
implementation presentation; way collecting experience could used
well, example re-sampling new database interactions iteration RLVC.
crucial point RLVC generates representation visual control policies
set collected visuomotor experience, makes RLVC interactive. following sections describe remaining algorithms, namely aliased, generator, selector
post-process.
3.3 Detection Aliased Visual Classes
discuss aliasing detected classifier Ck .
3.3.1 Projection MDP Image Classifier
Formally, image classifier Ck converts sequence N interactions
hst , , rt+1 , st+1 i,
mapped sequence N quadruples
hCk (st ), , rt+1 , Ck (st+1 )i,
upon embedded RL algorithm applied. Let us define mapped MDP Mk
MDP
hSk , A, Tk , Rk i,
358

fiClosed-Loop Learning Visual Control Policies

obtained mapped sequence, Sk set visual classes
known Ck , Tk Rk computed using relative frequencies
mapped sequence, follows.
Consider two visual classes V, V 0 {Vk,1 , . . . , Vk,mk } one action A. define
following functions:
(V, a) equals 1 Ck (st ) = V = a, 0 otherwise;
(V, a, V 0 ) equals 1 Ck (st ) = V , Ck (st+1 ) = V 0 = a, 0 otherwise;
(V, a) number ts (V, a) = 1.
Using notation, write:
Sk = {Vk,1 , . . . , Vk,mk };
P
0
Tk (V, a, V 0 ) = N
t=1 (V, a, V ) /(V, a);
P
Rk (V, a) = N
t=1 rt (V, a)/(V, a).
3.3.2 Optimal Q Function Mapped MDP
mapped MDP Mk induces optimal Q function domain Sk
0
denoted Q0
k . Computing Qk difficult: general, may exist MDP defined
state space Sk action space generate given mapped sequence,
since latter necessarily Markovian anymore. Thus, RL algorithm run
mapped sequence, might converge toward Q0
k , even converge all.
However, applied mapped sequence, model-based RL method (cf. Section 2)
used compute Q0
k Mk used underlying model. conditions,
Q-learning also converges optimal Q function mapped MDP (Singh, Jaakkola,
& Jordan, 1995).
turn, function Q0
k induces another Q function initial domain
relation:
Qk (s, a) = Q0
(7)
k (Ck (s), a) ,
absence aliasing, agent would perform optimally, Qk would correspond
Q , according Bellman theorem states uniqueness optimal Q function (cf.
Section 2). Equation 4, function
Bk (s, a) = (HQk )(s, a) Qk (s, a)

(8)

therefore measure aliasing induced image classifier Ck . RL terminology,
Bk Bellman residual function Qk (Sutton, 1988). basic idea behind RLVC
refine states non-zero Bellman residual.
3.3.3 Measuring Aliasing
Consider time stamp database interactions hst , , rt+1 , st+1 i. According
Equation 8, Bellman residual corresponds state-action pair (st , ) equals
X
Bk (st , ) = R(st , ) +
(st , , s0 ) max
Qk (s0 , a0 ) Qk (st , ).
(9)
0


s0

359

fiJodogne & Piater

Algorithm 2 Aliasing Criterion
1: aliased(Vk,i ) :
2:

3:
{t | Ck (st ) = Vk,i = a}
4:
2 () >
5:
return true
6:
end
7:
end
8:
return false
Unfortunately, RL agent access transition probabilities
reinforcement function R MDP modeling environment. Therefore, Equation 9 cannot directly evaluated. similar problem arises Q-learning (Watkins,
1989) Fitted Q Iteration (Ernst, Geurts, & Wehenkel, 2005) algorithms.
algorithms solve problem considering stochastic version time difference
described Equation 9: value
X
(st , , s0 ) max
Qk (s0 , a0 )
(10)
0


s0

indeed estimated
max
Qk (s0 , a0 ),
0


(11)

successor s0 chosen probability (st , , s0 ). following transitions
environment ensures making transition st st+1 probability (st , , st+1 ).
Thus
= rt+1 + max
Qk (st+1 , a0 ) Qk (st , )
a0

0
0
= rt+1 + max
Q0
k Ck (st+1 ) , Qk (Ck (st ), a)
0


(12)
(13)

unbiased estimate Bellman residual state-action pair (st , ) (Jaakkola,
Jordan, & Singh, 1994).1 importantly, system deterministic absence
perceptual aliasing, estimates equal zero. Therefore, nonzero potentially
indicates presence perceptual aliasing visual class Vt = Ck (st ) respect
action . criterion detecting aliased classes consists computing Q0
k
function, sweeping interactions hst , , rt+1 , st+1 identify nonzero
. practice, assert presence aliasing variance exceeds given
threshold . summarized Algorithm 2, 2 () denotes variance set
samples.
3.4 Generation Selection Distinctive Visual Features
aliasing detected visual class Vk,i Sk respect action a,
need select local descriptor best explains variations set values
1. worth noticing corresponds updates would applied Q-learning,
known learning rate time t.

360

fiClosed-Loop Learning Visual Control Policies

Algorithm 3 Canonical feature generator
1: generator({s1 , . . . , sn }) :
2:
F {}
3:
{1, . . . , n}
4:
(x, y) (x, y) interest point si
5:
F F {symbol(descriptor(si , x, y))}
6:
end
7:
end
8:
return F
corresponding Vk,i a. local descriptor chosen among set candidate
visual features F .
3.4.1 Extraction Candidate Features
Informally, canonical way building F visual class Vk,i consists in:
1. identifying collected visual percepts st Ck (st ) = Vk,i ,
2. locating interest points selected images st ,
3. adding F local descriptor interest points.
corresponding feature generator detailed Algorithm 3. latter algorithm,
descriptor(s, x, y) returns local description point location (x, y) image s,
symbol(d) returns symbol corresponds local descriptor F according
used metric. However, complex strategies generating visual features
used. strategy builds spatial combinations individual point features
presented Section 5.
3.4.2 Selection Candidate Features
problem choosing candidate feature reduces variations set
real-valued Bellman residuals regression problem, suggest adaptation
popular splitting rule used CART algorithm building regression trees (Breiman,
Friedman, & Stone, 1984).2
CART, variance used impurity indicator: split selected refine
particular node one leads greatest reduction sum squared
differences response values learning samples corresponding node
mean. formally, let = {hxi , yi i} set learning samples, xi Rn
input vectors real numbers, yi R real-valued outputs. CART selects
following candidate feature:


v
v
f = argmin pv 2
+ pv 2
,

(14)

vF

2. Note previous work, used splitting rule borrowed building classification
trees (Quinlan, 1993; Jodogne & Piater, 2005a).

361

fiJodogne & Piater

Algorithm 4 Feature Selection
1: selector(Vk,i , F ) :
2:
f
{Best feature found far}
3:
r +
{Variance reduction induced f }
4:

5:
{t | Ck (st ) = Vk,i = a}
6:
visual feature f F
7:
{t | st exhibits f }
8:
{t | st exhibit f }
9:
|S |/|T |
10:
|S |/|T |
11:
r 2 (S ) + 2 (S )
12:
r < r distributions (S , ) significantly different
13:
f f
14:
r
15:
end
16:
end
17:
end
18:
return f

pv (resp. pv ) proportion samples exhibit (resp. exhibit)
v (resp. v ) set samples exhibit (resp. exhibit)
feature v,

feature v. idea directly transferred framework, set xi
corresponds set interactions hst , , rt+1 , st+1 i, set yi corresponds
set . written explicitly Algorithm 4.
algorithms exploit stochastic version Bellman residuals. course, real environments general non-deterministic, generates variations Bellman residuals
consequence perceptual aliasing. RLVC made somewhat robust
variability introducing statistical hypothesis test: candidate feature,
Students ttest used decide whether two sub-distributions feature induces
significantly different. approach also used U-Tree (McCallum, 1996).
3.5 Illustration Simple Navigation Task
evaluated system abstract task closely parallels real-world scenario
avoiding unnecessary complexity. consequence, sensor model use may
seem unrealistic; better visual sensor model exploited Section 4.4.
RLVC succeeded solving continuous, noisy visual navigation task depicted
Figure 3. goal agent reach fast possible one two exits
maze. set possible locations continuous. location, agent four
possible actions: Go up, right, down, left. Every move altered Gaussian noise,
standard deviation 2% size maze. Glass walls present
maze. Whenever move would take agent wall outside maze, location
changed.
362

fiClosed-Loop Learning Visual Control Policies

Figure 3: continuous, noisy navigation task. exits maze indicated boxes
cross. Walls glass identified solid lines. agent depicted
center figure. one four possible moves represented
arrow, length corresponds resulting move. sensors return
picture corresponds dashed portion image.

agent earns reward 100 exit reached. move, including
forbidden ones, generates zero reinforcement. agent succeeds escaping
maze, arrives terminal state every move gives rise zero reinforcement.
task, set 0.9. Note agent faced delayed reward problem,
must take distance two exits consideration choosing
attractive one.
maze ground carpeted color image 1280 1280 pixels
montage pictures COIL-100 database (Nene, Nayar, & Murase, 1996).
agent direct access (x, y) position maze. Rather, sensors
take picture surrounding portion ground. portion larger
blank areas, makes input space fully observable. Importantly, glass walls
transparent, sensors also return portions tapestry behind
them. Therefore, way agent directly locate walls. obliged
identify regions maze action change location.
363

fiJodogne & Piater

Figure 4: deterministic image-to-action mapping results RLVC, sampled
regularly-spaced points. manages choose correct action location.

experiment, used color differential invariants visual features (Gouet
& Boujemaa, 2001). entire tapestry includes 2298 different visual features. RLVC
selected 200 features, corresponding ratio 9% entire set possible features.
computation stopped generation 84 image classifiers (i.e. k reached
84), took 35 minutes 2.4GHz Pentium IV using databases 10,000 interactions.
205 visual classes identified. small number, compared number
perceptual classes would generated discretization maze agent
knows (x, y) position. example, reasonably sized 2020 grid leads 400 perceptual
classes.
Figure 4 shows optimal, deterministic image-to-action mapping results
last obtained image classifier Ck :
(s) = argmax Qk (s, a) = Q0
k (Ck (s), a) .
aA

364

(15)

fiClosed-Loop Learning Visual Control Policies

(a)

(b)

Figure 5: (a) optimal value function, agent direct access (x, y)
position maze set possible locations discretized
50 50 grid. brighter location, greater value. (b) final value
function obtained RLVC.

Figure 5 compares optimal value function discretized problem one obtained RLVC. similarity two pictures indicates soundness
approach. Importantly, RLVC operates neither pretreatment, human intervention. agent initially aware visual features important task.
Moreover, interest selecting descriptors clear application: direct, tabular
representation Q function considering Boolean combinations features would
22298 4 cells.
behavior RLVC real-word images also investigated. navigation
rules kept identical, tapestry replaced panoramic photograph
3041 384 pixels subway station, depicted Figure 6. RLVC took 101 iterations
compute mapping right Figure 6. computation time 159 minutes
2.4GHz Pentium IV using databases 10,000 interactions. 144 distinct visual features
selected among set 3739 possible ones, generating set 149 visual classes. again,
resulting classifier fine enough obtain nearly optimal image-to-action mapping
task.

3.6 Related Work
RLVC thought performing adaptive discretization visual space
basis presence visual features. Previous reinforcement learning algorithms
exploit presence perceptual features various contexts discussed.
365

fiJodogne & Piater

(a)

(b)

Figure 6: (a) navigation task real-world image, using conventions
Figure 3. (b) deterministic image-to-action mapping computed RLVC.

366

fiClosed-Loop Learning Visual Control Policies

3.6.1 Perceptual Aliasing
explained above, incremental selection set informative visual features necessarily leads temporary perceptual aliasing, RLVC tries remove. generally,
perceptual aliasing occurs whenever agent cannot always take right basis
percepts.
Early work reinforcement learning tackled general problem two distinct
ways: Either agent identifies avoids states perceptual aliasing occurs
(as Lion algorithm, see Whitehead & Ballard, 1991), tries build short-term
memory allow remove ambiguities percepts (as predictive
distinctions approach, see Chrisman, 1992). sketchily, two algorithms detect
presence perceptual aliasing analysis sign Q-learning updates.
possibility managing short-term memory led development Partially
Observable Markov Decision Processes (POMDP) theory (Kaelbling, Littman, & Cassandra,
1998), current state random variable percepts.
Although approaches closely related perceptual aliasing RLVC temporarily introduces, consider exploitation perceptual features. Indeed,
tackle structural problem given control task, and, such, assume
perceptual aliasing cannot removed. consequence, approaches orthogonal
research interest, since ambiguities RLVC generates removed
refining image classifier. fact, techniques tackle lack information inherent used sensors, whereas goal handle surplus information related
high redundancy visual representations.
3.6.2 Adaptive Resolution Finite Perceptual Spaces
RLVC performs adaptive discretization perceptual space autonomous,
task-driven, purposive selection visual features. Work RL incrementally partitions
large (either discrete continuous) perceptual space piecewise constant value
function usually referred adaptive-resolution techniques. Ideally, regions
perceptual space high granularity present needed,
lower resolution used elsewhere. RLVC adaptive-resolution
algorithm. review several adaptive-resolution methods previously
proposed finite perceptual spaces.
idea adaptive-resolution techniques reinforcement learning goes back
G Algorithm (Chapman & Kaelbling, 1991), inspired approaches
discussed below. G Algorithm considers perceptual spaces made
fixed-length binary numbers. learns decision tree tests presence informative
bits percepts. algorithm uses Students t-test determine bit
b percepts mapped given leaf, state-action utilities states
b set significantly different state-action utilities states
b unset. bit found, corresponding leaf split. process repeated
leaf. method able learn compact representations, even though
large number irrelevant bits percepts. Unfortunately, region split,
information associated region lost, makes slow learning.
367

fiJodogne & Piater

Concretely, G Algorithm solve task whose perceptual space contains 2100 distinct
percepts, corresponds set binary numbers length 100 bits.
McCallums U-Tree algorithm builds upon idea combining selective attention
mechanism inspired G Algorithm short-term memory enables agent
deal partially observable environments (McCallum, 1996). Therefore, McCallums
algorithms keystone reinforcement learning, unify G Algorithm (Chapman & Kaelbling, 1991) Chrismans predictive distinctions (Chrisman, 1992).
U-Tree incrementally grows decision tree Kolmogorov-Smirnov tests.
succeeded learning behaviors driving simulator. simulator, percept consists
set 8 discrete variables whose variation domains contain 2 6 values,
leading perceptual space 2, 592 possible percepts. Thus, size perceptual
space much smaller visual space. However, task difficult
physical state space partially observable perceptual space: driving
task contains 21, 216 physical states, means several physical states requiring
different reactions mapped percept sensors agent.
U-Tree resolves ambiguities percepts testing presence perceptual
features percepts encountered previously history system.
end, U-Tree manages short-term memory. paper, partially observable
environments considered. challenge rather deal huge visual spaces,
without hand-tuned pre-processing, difficult, novel research direction.
3.6.3 Adaptive Resolution Continuous Perceptual Spaces
important notice methods adaptive resolution large-scale, finite
perceptual spaces use fixed set perceptual features hard-wired.
distinguished RLVC samples visual features possibly infinite visual feature
space (e.g. set visual features infinite), makes prior assumptions
maximum number useful features. point view, RLVC closer
adaptive-resolution techniques continuous perceptual spaces. Indeed, techniques
dynamically select new relevant features whole continuum.
first adaptive-resolution algorithm continuous perceptual spaces Darling algorithm (Salganicoff, 1993). algorithm, like current algorithms
continuous adaptive resolution, splits perceptual space using thresholds.
purpose, Darling builds hybrid decision tree assigns label point
perceptual space. Darling fully on-line incremental algorithm equipped
forgetting mechanism deletes outdated interactions. however limited
binary reinforcement signals, takes immediate reinforcements account,
Darling much closer supervised learning reinforcement learning.
Parti-Game algorithm (Moore & Atkeson, 1995) produces goal-directed behaviors
continuous perceptual spaces. Parti-Game also splits regions deems important,
using game-theoretic approach. Moore Atkeson show Parti-Game learn
competent behavior variety continuous domains. Unfortunately, approach
currently limited deterministic domains agent greedy controller
goal state known. Moreover, algorithm searches solution
given task, try find optimal one.
368

fiClosed-Loop Learning Visual Control Policies

Continuous U-Tree algorithm extension U-Tree adapted continuous perceptual spaces (Uther & Veloso, 1998). like Darling, Continuous U-Tree
incrementally builds decision tree splits perceptual space finite set hypercubes, testing thresholds. Kolmogorov-Smirnov sum-of-squared-errors used
determine split node decision tree. Pyeatt Howe (2001) analyze
performance several splitting criteria variation Continuous U-Tree.
conclude Students t-test leads best performance, motivates use
statistical test RLVC (cf. Section 3.4).
Munos Moore (2002) proposed Variable Resolution Grids. algorithm
assumes perceptual space compact subset Euclidean space, begins
coarse, grid-based discretization state space. contrast abstract
algorithms section, value function policy vary linearly within region.
Munos Moore use Kuhn triangulation efficient way interpolate value function within regions. algorithm refines approximation refining cells according
splitting criterion. Munos Moore explore several local heuristic measures importance splitting cell including average corner-value differences, variance
corner-value differences, policy disagreement. also explore global heuristic measures involving influence variance approximated system. Variable Resolution
Grids probably advanced adaptive-resolution algorithm available far.
3.6.4 Discussion
summarize, several algorithms similar spirit RLVC proposed
years. Nevertheless, work appears first learn direct image-toaction mappings reinforcement learning. Indeed, none reinforcement learning
methods combines following desirable properties RLVC: (1) set relevant perceptual features chosen priori hand, selection process fully
automatic require human intervention; (2) visual perceptual spaces explicitly considered appearance-based visual features; (3) highly informative
perceptual features drawn possibly infinite set.
advantages RLVC essentially due fact candidate visual
features selected informative: also ranked according
information-theoretic measure inspired decision tree induction (Breiman et al.,
1984). ranking required, vision-for-action tasks induce large number visual
features (a typical image contains thousand them). kind criterion
ranks features, though already considered Variable Resolution Grids (Munos & Moore,
2002), seems new discrete perceptual spaces.
RLVC defined independently fixed RL algorithm, similar spirit
Continuous U-Tree (Uther & Veloso, 1998), major exception RLVC deals
Boolean features, whereas Continuous U-Tree works continuous input space. Furthermore, version RLVC presented paper uses variance-reduction criterion
ranking visual features. criterion, though already considered Variable Resolution
Grids, seems new discrete perceptual spaces.
369

fiJodogne & Piater

4. Compacting Visual Policies
written Section 1.4.2, original version RLVC subject overfitting (Jodogne &
Piater, 2005b). simple heuristic avoid creation many visual classes simply
bound number visual classes refined stage algorithm,
since splitting one visual class potentially impact Bellman residuals
visual classes. practice, first try split classes samples
considering others, since evidence variance reduction first.
tests, systematically apply heuristics. However, often insufficient taken
alone.
4.1 Equivalence Relations Markov Decision Processes
Since apply embedded RL algorithm stage k RLVC, properties like
optimal value function Vk (), optimal state-action value function Qk (, ) optimal
control policy k () known mapped MDP Mk . Using properties, easy
define whole range equivalence relations visual classes. instance,
given threshold R+ , list hereunder three possible equivalence relations pair
visual classes (V, V 0 ):
Optimal Value Equivalence:
|Vk (V ) Vk (V 0 )| .
Optimal Policy Equivalence:
|Vk (V ) Qk (V 0 , k (V ))|
|Vk (V 0 ) Qk (V, k (V 0 ))| .
Optimal State-Action Value Equivalence:
(a A) |Qk (V, a) Qk (V 0 , a)| .
therefore propose modify RLVC that, periodically, visual classes
equivalent respect one criteria merged together. experimentally
observed conjunction first two criteria tends lead best performance.
way, RLVC alternatively splits merges visual classes. compaction phase
done often, order allow exploration. best knowledge,
possibility investigated yet framework adaptive-resolution methods
reinforcement learning.
original version RLVC, visual classes correspond leaves decision
tree. using decision trees, aggregation visual classes achieved
starting bottom tree recursively collapsing leaves, dissimilar leaves
found. operation close post-pruning framework decision trees
machine learning (Breiman et al., 1984). practice, means classes
similar properties, reached one another making number
hops upwards downwards, extremely unlikely matched. greatly reduces
interest exploiting equivalence relations.
drawback due rather limited expressiveness decision trees. decision
tree, visual class corresponds conjunction visual feature literals, defines
370

fiClosed-Loop Learning Visual Control Policies

path root decision tree one leaf. take full advantage equivalence
relations, necessary associate, visual class, arbitrary union conjunctions
visual features. Indeed, exploiting equivalence relations, visual classes
result sequence conjunctions (splitting) disjunctions (aggregation). Thus,
expressive data structure would able represent general, arbitrary Boolean
combinations visual features required. data structure introduced next
section.
4.2 Using Binary Decision Diagrams
problem representing general Boolean functions extensively studied
field computer-aided verification, since abstract behavior logical electronic
devices. fact, whole range methods representing state space richer
richer domains developed last years, Binary Decision Diagram
(BDD) (Bryant, 1992), Number Queue Decision Diagrams (Boigelot, 1999), Upward
Closed Sets (Delzanno & Raskin, 2000) Real Vector Automata (Boigelot, Jodogne, &
Wolper, 2005).
framework, BDD particularly well-suited tool. acyclic graph-based
symbolic representation encoding arbitrary Boolean functions, much success field computer-aided verification (Bryant, 1992). BDD unique
ordering variables fixed, different variable orderings lead different sizes
BDD, since variables discarded reordering process. Although
problem finding optimal variable ordering coNP-complete (Bryant, 1986), automatic heuristics practice find orderings close optimal. interesting
case, since reducing size BDD potentially discards irrelevant variables,
correspond removing useless visual features.
4.3 Modifications RLVC
summarize, extension RLVC use decision trees anymore, assigns
one BDD visual class. Two modifications applied Algorithm 1:
1. operation refining, visual feature f , visual class V labeled
BDD B(V ), consists replacing V two new visual classes V1 V2
B(V1 ) = B(V ) f B(V2 ) = B(V ) f .
2. Given equivalence relation, post-process(Ck ) operation consists merging
equivalent visual classes. merge pair visual classes (V1 , V2 ), V1 V2
deleted, new visual class V B(V ) = B(V1 ) B(V2 ) added. Every
time merging operation takes place, advised carry variable reordering,
minimize memory requirements.
4.4 Experiments
applied modified version RLVC another simulated navigation task.
task, agent moves 11 spots campus University Liege (cf.
Figure 7). Every time agent one 11 locations, body aim four possible
371

fiJodogne & Piater

N

(c) Google Map

Figure 7: Montefiore campus Liege. Red spots corresponds places
agent moves. agent follow links different
spots. goal enter Montefiore Institute, labeled red cross,
gets reward +100.

orientations: North, South, West, East. state space therefore size 11 4 = 44.
agent three possible actions: Turn left, turn right, go forward. goal enter
specific building, obtain reward +100. Turning left right induces
penalty 5, moving forward, penalty 10. discount factor set 0.8.
optimal control policy unique: One depicted Figure 8.
agent direct access position orientation. Rather,
perceives picture area front (cf. Figure 9). Thus, agent
connect input image appropriate reaction without explicitly knowing
geographical localization. possible location possible viewing direction,
database 24 images size 1024 768 significant viewpoint changes
collected. 44 databases randomly divided learning set 18 images
test set 6 images. experimental setup, versions RLVC learn
image-to-action mapping using interactions contain images learning set.
Images test set used assess accuracy learned visual control policies.
SIFT keypoints used visual features (Lowe, 2004). Thresholding
Mahalanobis distance gave rise set 13,367 distinct features. versions RLVC
applied static database 10,000 interactions collected using
fully randomized exploration policy. database used throughout entire
algorithm, database contains images belong learning set.
results basic version RLVC version extended BDDs
reported Figures 10 11. original version RLVC identified 281 visual
classes selecting 264 SIFT features. error rate computed visual policy (i.e.
proportion sub-optimal decisions agent presented possible stimuli)
372

fiClosed-Loop Learning Visual Control Policies

(c) Google Map

Figure 8: One optimal, deterministic control policies Montefiore navigation
task. state, indicated optimal action (the letter F stands
move forward, R turn right L turn left). policy
obtained applying standard RL algorithm scenario
agent direct access (p, d) information.

0.1% learning set 8% images test set used, respect
optimal policy agent direct access position viewing direction.
modified version RLVC applied, one compacting stage every 10 steps.
results clearly superior. error learning set anymore,
error rate test set 4.5%. number selected features reduced 171.
Furthermore, resulting number visual classes becomes 59, instead 281. Thus,
large improvement generalization abilities, well reduction number
visual classes selected features. Interestingly enough, number visual classes
(59) close number physical states (44), tends indicate
algorithm starts learn physical interpretation percepts.
summarize, compacting visual policies probably required step deal realistic visual tasks, iterative splitting process applied. price pay course
373

fiJodogne & Piater

(c) Google Map

Figure 9: percepts agent. Four possible different percepts shown, correspond location viewing direction marked yellow top image.

374

fiClosed-Loop Learning Visual Control Policies

60

60
RLVC
RLVC + BDD
50

40

40

30

0

20

40

60

80
Iterations (k)

100

120

140

Error rate (%)

50

30

20

20

10

10

0
160

0

20

40

60

80
Iterations (k)

100

120

140

Error rate (%)

RLVC
RLVC + BDD

0
160

Figure 10: Comparison error rates basic extended versions RLVC.
error computed policy function step counter k images
learning set (resp. test set) reported left figure (resp.
right).

higher computational cost. Future work focus theoretical justification used
equivalence relations. implies bridging gap theory MDP minimization (Givan, Dean, & Greig, 2003).

5. Learning Spatial Relationships
motivated Introduction (Section 1.4.3), propose extend RLVC constructing hierarchy spatial arrangements individual point features (Jodogne, Scalzo, &
Piater, 2005). idea learning models spatial combinations features takes
roots seminal paper Fischler Elschlager (1973) pictorial structures,
collections rigid parts arranged deformable configurations. idea
become increasingly popular computer vision community 90s, led
large literature modeling detection objects (Amit & Kong, 1996; Burl
& Perona, 1996; Forsyth, Haddon, & Ioffe, 1999). Crandall Huttenlocher (2006) provide pointers recent resources. Among recent techniques, Scalzo Piater (2006)
propose build probabilistic hierarchy visual features represented
acyclic graph. detect presence model Nonparametric Belief
Propagation (Sudderth, Ihler, Freeman, & Willsky, 2003). graphical models
proposed representing articulated structures, pictorial structures (Felzenszwalb & Huttenlocher, 2005; Kumar, Torr, & Zisserman, 2004). Similarly, constellation
model represents objects parts, modeled terms shape appearance
Gaussian probability density functions (Perona, Fergus, & Zisserman, 2003).
work contrasts approaches generation so-called composite
features driven task solved. distinguished techniques
unsupervised learning composite features, since additional information
375

fiJodogne & Piater

300

300
RLVC
RLVC + BDD
250

200

200

150

0

20

40

60

80
Iterations (k)

100

120

140

Number classes

250

150

100

100

50

50

0
160

0

20

40

60

80
Iterations (k)

100

120

140

Number selected features

RLVC
RLVC + BDD

0
160

Figure 11: Comparison number generated classes selected visual features basic extended versions RLVC. number visual classes
(resp. selected features) function step counter k plotted left
figure (resp. right).

embedded inside reinforcement signal drives generation composite features
focusing exploration task-relevant spatial arrangements.
extension RLVC, hierarchy visual features built simultaneously
image classifier. soon sufficiently informative visual feature extracted,
algorithm tries combine two visual features order construct higher level
abstraction, hopefully distinctive robust noise. extension
RLVC assumes co-existence two different kinds visual features:
Primitive Features: correspond individual point features, i.e. localappearance descriptors (cf. Section 1.3).
Composite Features: consist spatial combinations lower-level visual features.
priori bound maximal height hierarchy. Therefore,
composite feature potentially combined primitive feature,
composite feature.
5.1 Detection Visual Features
natural way represent hierarchy use directed acyclic graph G = (V, E),
vertex v V corresponds visual feature, edge (v, v 0 ) E
models fact v 0 part composite feature v. Thus, G must binary,
i.e. vertex either child, exactly two children. set VP leaves
G corresponds set primitive features, set VC internal vertexes
represents set composite features.
leaf vertex vP VP annotated local descriptor D(vP ). Similarly,
internal vertex vC VC annotated constraints relative position
parts. work, consider constraints distances constituent
376

fiClosed-Loop Learning Visual Control Policies

visual features composite features, assume distributed
according Gaussian law G(, ) mean standard deviation . Evidently, richer
constraints could used, taking relative orientation scaling factor constituent features consideration, would require use multivariate Gaussians.
precisely, let vC composite feature, parts v1 v2 . order
trigger detection vC image s, occurrence v1
occurrence v2 relative Euclidean distance sufficient likelihood
generated Gaussian mean (vC ) standard deviation (vC ). ensure
symmetry, location composite feature taken midpoint
locations v1 v2 .
occurrences visual feature v percept found using recursive
Algorithm 5. course, steps 6 7 Algorithm 4, test st exhibit v?
rewritten function Algorithm 5, checking occurrences(v, st ) 6= .
5.2 Generation Composite Features
cornerstone extension RLVC way generating composite features.
general idea behind algorithm accumulate statistical evidence relative
positions detected visual features order find conspicuous coincidences visual
features. done providing evolved implementation generator(s1 , . . . , sn )
one Algorithm 3.
5.2.1 Identifying Spatial Relations
first extract set F (primitive composite) features occur within
set provided images {s1 , . . . , sn }:
F = {v V | (i) si exhibits v} .

(16)

identify pairs visual features occurrences highly correlated within
set provided images {s1 , . . . , sn }. simply amounts counting number
co-occurrences pair features F , keeping pairs corresponding
count exceeds fixed threshold.
Let v1 v2 two features highly correlated. search meaningful
spatial relationship v1 v2 carried images {s1 , . . . , sn }
contain occurrences v1 v2 . co-occurrence, accumulate set
distances corresponding occurrences v1 v2 . Finally, clustering
algorithm applied distribution order detect typical distances v1
v2 . purpose experiments, used hierarchical clustering (Jain,
Murty, & Flynn, 1999). cluster, Gaussian fitted estimating mean value
standard deviation . Finally, new composite feature vC introduced
feature hierarchy, v1 v2 parts (vC ) = (vC ) = .
summary, Algorithm 1, replace call Algorithm 3 call Algorithm 6.
377

fiJodogne & Piater

Algorithm 5 Detecting Composite Features
1: occurrences(v, s) :
2:
v primitive
3:
return {(x, y) | (x, y) interest point s, local descriptor corresponds D(v)}
4:
else
5:
{}
6:
O1 occurrences(subfeature1 (v), s)
7:
O2 occurrences(subfeature2 (v), s)
8:
p
(x1 , y1 ) O1 (x2 , y2 ) O2
9:
(x2 x1 )2 + (y2 y1 )2
10:
G(d (v), (v))
11:
{((x1 + x2 )/2, (y1 + y2 )/2)}
12:
end
13:
end
14:
return
15:
end

Algorithm 6 Generation Composite Features
1: generator({s1 , . . . , sn }) :
2:
F = {v V | (i) si exhibits v}
3:
F 0 = {}
4:
(v1 , v2 ) F F
5:
enough co-occurrences v1 v2 {s1 , . . . , sn }
6:
{}
7:
{1, . . . , n}
8:
occurrences (x1 , y1 ) v1 si
9:
occurrences
(x2 , y2 ) v2 si
p
10:
{ (x2 x1 )2 + (y2 y1 )2 }
11:
end
12:
end
13:
end
14:
Apply clustering algorithm
15:
cluster C = {d1 , . . . dm }
16:
= mean(C)
17:
= stddev(C)
18:
Add F 0 composite feature vC composed v1 v2 , annotated
mean standard deviation
19:
end
20:
end
21:
end
22:
return F 0

378

fiClosed-Loop Learning Visual Control Policies

H(p)
0.4

N

u
0.2

mg
1

.5

.5

1

p

0.2

Figure 12: Car Hill control problem.

5.2.2 Feature Validation
Algorithm 6 generate several composite features given visual class Vk,i . However,
end Algorithm 4, one generated composite feature kept.
important notice performance clustering method critical
purpose. Indeed, irrelevant spatial combinations automatically discarded, thanks
variance-reduction criterion feature selection component. fact, reinforcement
signal helps direct search good feature, advantage unsupervised
methods building feature hierarchies.
5.3 Experiments
demonstrate efficacy algorithms version classical Car Hill
control problem (Moore & Atkeson, 1995), position velocity information
presented agent visually.
episodic task, car (modeled mass point) riding without friction
hill, shape defined function:

H(p) =

p2 p
+p
p < 0,
2
p/ 1 + 5p p 0.

goal agent reach fast possible top hill, i.e. location
p 1. top hill, agent obtains reward 100. car thrust left
right acceleration 4 Newtons. However, gravity, acceleration
insufficient agent reach top hill always thrusting toward right.
Rather, agent go left while, hence acquiring potential energy going
left side hill, thrusting rightward. two constraints: agent
allowed reach locations p < 1, velocity greater 3 absolute
value leads destruction car.
379

fiJodogne & Piater

5.3.1 Formal Definition Task
Formally, set possible actions = {4, 4}, state space = {(p, s) |
|p| 1 |s| 3}. system following continuous-time dynamics:
p =
=




p

1 + H 0 (p)2



gH 0 (p)
,
1 + H 0 (p)2

thrust acceleration, H 0 (p) first derivative H(p), = 1
mass car, g = 9.81 acceleration due gravity. continuous-time
dynamics approximated following discrete-time state update rule:
st+1 = st + hpt + h2 st /2
st+1 = pt + hst ,
h = 0.1 integration time step. reinforcement signal defined
expression:

100 st+1 1 |st+1 | 3,
R((st , st ), a) =
0
otherwise.
setup, discount factor set 0.75.
definition actually mix two coexistent formulations Car Hill
task (Ernst, Geurts, & Wehenkel, 2003; Moore & Atkeson, 1995). major differences
initial formulation problem (Moore & Atkeson, 1995) set
possible actions discrete, goal top hill (rather given
area hill), like definition Ernst et al. (2003). ensure existence
interesting solution, velocity required remain less 3 (instead 2),
integration time step set h = 0.1 (instead 0.01).
5.3.2 Inputs Agent
previous work (Moore & Atkeson, 1995; Ernst et al., 2003), agent always assumed
direct access numerical measure position velocity. exception
Gordons work visual, low-resolution representation global scene given
agent (Gordon, 1995). experimental setup, agent provided two
cameras, one looking ground underneath, second velocity gauge. way,
agent cannot directly know current position velocity, suitably interpret
visual inputs derive them.
examples pictures sensors return presented Figure 13.
ground carpeted color image 1280 128 pixels montage pictures
COIL-100 database (Nene et al., 1996). important notice using
individual point features insufficient solving task, since set features
pictures velocity gauge always same. know velocity, agent
generate composite features sensitive distance primitive features cursor
respect primitive features digits.
380

fiClosed-Loop Learning Visual Control Policies

(a)

(b)
Figure 13: (a) Visual percepts corresponding pictures velocity gauge = 3,
= 0.5 = 1.5. (b) Visual percepts returned position sensor.
region framed white rectangle corresponds portion ground
returned sensor p = 0.1. portion slides back forth
agent moves.

5.3.3 Results
experimental setup, used color differential invariants (Gouet & Boujemaa, 2001)
primitive features. Among possible visual inputs (both position
velocity sensors), 88 different primitive features. entire image ground
includes 142 interest points, whereas images velocity gauge include 20
interest points.
output RLVC decision tree defines 157 visual classes. internal
node tree tests presence one visual feature, taken set 91 distinct,
highly discriminant features selected RLVC. Among 91 selected visual features,
56 primitive 26 composite features. Two examples composites features
selected RLVC depicted Figure 15. computation stopped k = 38
refinement steps Algorithm 1.
show efficacy method, compare performance scenario
agent direct perception current (p, s) state. latter scenario,
state space discretized grid 13 13 cells. number 13 chosen since
approximately corresponds square root 157, number visual classes
produced RLVC. way, RL provided equivalent number perceptual classes
two scenarios. Figure 14 compares optimal value function direct-perception
381

fiJodogne & Piater

Velocity

3

0

3
1

0

Position

1

(a)

Velocity

3

0

3
1

0

Position

1

(b)

Figure 14: (a) optimal value function, agent direct access current
(p, s) state, input space discretized 13 13 grid.
brighter location, greater value. (b) value function obtained
RLVC.

382

fiClosed-Loop Learning Visual Control Policies

Figure 15: Two composite features generated, yellow. primitive features
composed marked yellow. first feature triggers
velocities around 0, whereas second triggers around 2.

problem one obtained RLVC. also, two pictures similar,
indicates soundness approach.
also evaluated performance optimal image-to-action mapping
= argmax Q ((p, s), a)

(17)

aA

obtained RLVC. purpose, agent placed randomly hill,
initial velocity 0. Then, used mapping choose action, reached
final state. set 10,000 trials carried step k Algorithm 1.
Figure 16 compares proportion trials missed goal (either leaving
hill left, acquiring high velocity) RLVC directperception problem. k became greater 27, proportion missed trials
always smaller RLVC direct-perception problem. advantage favor
RLVC due adaptive nature discretization. Figure 17 compares mean
lengths successful trials. mean length RLVC trials clearly converges
direct-perception trials, staying slightly larger.
conclude, RLVC achieves performance close direct-perception scenario. However, mapping built RLVC directly links visual percepts appropriate actions,
without considering explicitly physical variables.

6. Summary
paper introduces Reinforcement Learning Visual Classes (RLVC). RLVC designed
learn mappings directly connect visual stimuli output actions optimal
surrounding environment. framework RLVC general, sense
applied problem formulated Markov decision problem.
learning process behind algorithms closed-loop flexible. agent
takes lessons interactions environment, according purposive vision
paradigm. RLVC focuses attention embedded reinforcement learning algorithm
highly informative robust parts inputs testing presence absence
local descriptors interest points input images. relevant visual features
383

fiJodogne & Piater

25
RLVC
Direct perception (13x13 grid)

Missed goal (%)

20

15

10

5

0

0

5

10

15

20

25

30

35

40

Iterations (k)

Figure 16: Evolution number times goal missed iterations
RLVC.

19

RLVC
Direct perception (13x13 grid)

18

Mean length interaction

17

16

15

14

13

12

0

5

10

15

20

25

30

35

40

Iterations (k)

Figure 17: Evolution mean lengths successful trials iterations RLVC.

384

fiClosed-Loop Learning Visual Control Policies

incrementally selected sequence attempts remove perceptual aliasing:
discretization process targets zero Bellman residuals inspired supervised learning algorithms building decision trees. algorithms defined independently
interest point detector (Schmid et al., 2000) local description technique (Mikolajczyk & Schmid, 2003). user may choose two components sees fit.
Techniques fighting overfitting RLVC also proposed. idea
aggregate visual classes share similar properties respect theory Dynamic
Programming. Interestingly, process enhances generalization abilities learned
image-to-action mapping, reduces number visual classes built.
Finally, extension RLVC introduced allows closed-loop, interactive
purposive learning hierarchy geometrical combinations visual features.
contrast prior work topic, uses either supervised
unsupervised framework (Piater, 2001; Fergus, Perona, & Zisserman, 2003; Bouchard &
Triggs, 2005; Scalzo & Piater, 2006). Besides novelty approach, shown
practical value visual control tasks information provided individual
point features alone insufficient solving task. Indeed, spatial combinations visual
features informative robust noise.

7. Future Work
area applications RLVC wide, since nowadays robotic agents often equipped
CCD sensors. Future research includes demonstration applicability
algorithms reactive robotic application, grasping objects combining visual
haptic feedback (Coelho, Piater, & Grupen, 2001). necessitates extension
techniques continuous action spaces, fully satisfactory solutions exist
date. RLVC could also potentially applied Human-Computer Interaction,
actions need physical actions.
closed-loop learning hierarchy visual feature also raises interesting research
directions. example, combination RLVC techniques disambiguating
aliased percepts using short-term memory (McCallum, 1996) could solve visual
tasks percepts agent alone provide enough information solving
task. Likewise, unsupervised learning kinds geometrical models (Felzenszwalb & Huttenlocher, 2005) could potentially embedded RLVC. hand,
spatial relationships currently take consideration relative angles
parts composite feature. would increase discriminative power
composite features, requires non-trivial techniques clustering circular domains.

Acknowledgments
authors thank associate editor Thorsten Joachims three anonymous reviewers many suggestions improving quality manuscript. Sebastien
Jodogne gratefully acknowledge financial support Belgian National Fund
Scientific Research (FNRS).
385

fiJodogne & Piater

References
Aloimonos, Y. (1990). Purposive qualitative active vision. Proc. 10th International Conference Pattern Recognition, pp. 436460.
Amit, Y., & Kong, A. (1996). Graphical templates model registration. IEEE Transactions Pattern Analysis Machine Intelligence, 18 (3), 225236.
Asada, M., Noda, S., Tawaratsumida, S., & Hosoda, K. (1994). Vision-based behavior acquisition shooting robot using reinforcement learning. Proc. IAPR/IEEE
Workshop Visual Behaviors, pp. 112118.
Bagnell, J., & Schneider, J. (2001). Autonomous helicopter control using reinforcement
learning policy search methods. Proc. International Conference Robotics
Automation. IEEE.
Barto, A., Sutton, R., & Anderson, C. (1983). Neuronlike adaptive elements
solve difficult learning control problems. IEEE Transactions Systems, Man
Cybernetics, 13 (5), 835846.
Bellman, R. (1957). Dynamic Programming. Princeton University Press.
Bertsekas, D., & Tsitsiklis, J. (1996). Neuro-Dynamic Programming. Athena Scientific.
Boigelot, B. (1999). Symbolic Methods Exploring Infinite State Spaces. Ph.D. thesis,
University Liege, Liege (Belgium).
Boigelot, B., Jodogne, S., & Wolper, P. (2005). effective decision procedure linear
arithmetic integer real variables. ACM Transactions Computational Logic
(TOCL), 6 (3), 614633.
Bouchard, G., & Triggs, B. (2005). Hierarchical part-based visual object categorization.
IEEE Conference Computer Vision Pattern Recognition, Vol. 1, pp. 710715,
San Diego (CA, USA).
Breiman, L., Friedman, J., & Stone, C. (1984).
Wadsworth International Group.

Classification Regression Trees.

Bryant, R. (1986). Graph-based algorithms boolean function manipulation. IEEE Transactions Computers, 8 (35), 677691.
Bryant, R. (1992). Symbolic boolean manipulation ordered binary decision diagrams.
ACM Computing Surveys, 24 (3), 293318.
Burl, M., & Perona, P. (1996). Recognition planar object classes. Proc. IEEE
Conference Computer Vision Pattern Recognition, pp. 223230, San Francisco
(CA, USA).
Chapman, D., & Kaelbling, L. (1991). Input generalization delayed reinforcement learning: algorithm performance comparisons. Proc. 12th International
Joint Conference Artificial Intelligence (IJCAI), pp. 726731, Sydney.
Chrisman, L. (1992). Reinforcement learning perceptual aliasing: perceptual
distinctions approach. National Conference Artificial Intelligence, pp. 183188.
386

fiClosed-Loop Learning Visual Control Policies

Coelho, J., Piater, J., & Grupen, R. (2001). Developing haptic visual perceptual categories reaching grasping humanoid robot. Robotics Autonomous
Systems, special issue Humanoid Robots, 37 (23), 195218.
Crandall, D., & Huttenlocher, D. (2006). Weakly supervised learning part-based spatial
models visual object recognition. Proc. 9th European Conference
Computer Vision.
Delzanno, G., & Raskin, J.-F. (2000). Symbolic representation upward closed sets.
Tools Algorithms Construction Analysis Systems, Lecture Notes
Computer Science, pp. 426440, Berlin (Germany).
Derman, C. (1970). Finite State Markovian Decision Processes. Academic Press, New York.
Ernst, D., Geurts, P., & Wehenkel, L. (2003). Iteratively extending time horizon reinforcement learning. Proc. 14th European Conference Machine Learning, pp.
96107, Dubrovnik (Croatia).
Ernst, D., Geurts, P., & Wehenkel, L. (2005). Tree-based batch mode reinforcement learning.
Journal Machine Learning Research, 6, 503556.
Felzenszwalb, P., & Huttenlocher, D. (2005). Pictorial structures object recognition.
International Journal Computer Vision, 61 (1), 5579.
Fergus, R., Perona, P., & Zisserman, A. (2003). Object class recognition unsupervised
scale-invariant learning. IEEE Conference Computer Vision Pattern Recognition, Vol. 2, pp. 264271, Madison (WI, USA).
Fischler, M., & Elschlager, R. (1973). representation matching pictorial structures. IEEE Transactions Computers, 22 (1), 6792.
Forsyth, D., Haddon, J., & Ioffe, S. (1999). Finding objects grouping primitives. Shape,
Contour Grouping Computer Vision, pp. 302318, London (UK). SpringerVerlag.
Gaskett, C., Fletcher, L., & Zelinsky, A. (2000). Reinforcement learning visual servoing
mobile robot. Proc. Australian Conference Robotics Automation,
Melbourne (Australia).
Gibson, E., & Spelke, E. (1983). development perception. Flavell, J. H., & Markman, E. M. (Eds.), Handbook Child Psychology Vol. III: Cognitive Development
(4th edition)., chap. 1, pp. 276. Wiley.
Givan, R., Dean, T., & Greig, M. (2003). Equivalence notions model minimization
markov decision processes. Artificial Intelligence, 147 (12), 163223.
Gordon, G. (1995). Stable function approximation dynamic programming. Proc.
International Conference Machine Learning, pp. 261268.
Gouet, V., & Boujemaa, N. (2001). Object-based queries using color points interest.
IEEE Workshop Content-Based Access Image Video Libraries, pp. 3036,
Kauai (HI, USA).
Howard, R. (1960). Dynamic Programming Markov Processes. Technology Press
Wiley, Cambridge (MA) New York.
387

fiJodogne & Piater

Huber, M., & Grupen, R. (1998). control structure learning locomotion gaits. 7th
Int. Symposium Robotics Applications, Anchorage (AK, USA). TSI Press.
Iida, M., Sugisaka, M., & Shibata, K. (2002). Direct-vision-based reinforcement learning
real mobile robot. Proc. International Conference Neural Information
Processing Systems, Vol. 5, pp. 25562560.
Jaakkola, T., Jordan, M., & Singh, S. (1994). Convergence stochastic iterative dynamic
programming algorithms. Cowan, J. D., Tesauro, G., & Alspector, J. (Eds.), Advances Neural Information Processing Systems, Vol. 6, pp. 703710. Morgan Kaufmann Publishers.
Jain, A. K., Murty, M. N., & Flynn, P. J. (1999). Data clustering: review. ACM Computing
Surveys, 31 (3), 264323.
Jodogne, S., & Piater, J. (2005a). Interactive learning mappings visual percepts
actions. De Raedt, L., & Wrobel, S. (Eds.), Proc. 22nd International
Conference Machine Learning (ICML), pp. 393400, Bonn (Germany). ACM.
Jodogne, S., & Piater, J. (2005b). Learning, compacting visual policies (extended abstract). Proc. 7th European Workshop Reinforcement Learning (EWRL),
pp. 810, Napoli (Italy).
Jodogne, S., Scalzo, F., & Piater, J. (2005). Task-driven learning spatial combinations
visual features. Proc. IEEE Workshop Learning Computer Vision
Pattern Recognition, San Diego (CA, USA). IEEE.
Kaelbling, L., Littman, M., & Cassandra, A. (1998). Planning acting partially
observable stochastic domains. Artificial Intelligence, 101 (1-2), 99134.
Kaelbling, L., Littman, M., & Moore, A. (1996). Reinforcement learning: survey. Journal
Artificial Intelligence Research, 4, 237285.
Kimura, H., Yamashita, T., & Kobayashi, S. (2001). Reinforcement learning walking
behavior four-legged robot. Proc. 40th IEEE Conference Decision
Control, Orlando (FL, USA).
Kohl, N., & Stone, P. (2004). Policy gradient reinforcement learning fast quadrupedal
locomotion. Proc. IEEE International Conference Robotics Automation, pp. 26192624, New Orleans.
Kumar, M., Torr, P., & Zisserman, A. (2004). Extending pictorial structures object
recognition. Proc. British Machine Vision Conference.
Kwok, C., & Fox, D. (2004). Reinforcement learning sensing strategies. Proc.
IEEE International Conference Intelligent Robots Systems.
Lagoudakis, M., & Parr, R. (2003). Least-squares policy iteration. Journal Machine
Learning Research, 4, 11071149.
Lowe, D. (2004). Distinctive image features scale-invariant keypoints. International
Journal Computer Vision, 60 (2), 91110.
Martnez-Marn, T., & Duckett, T. (2005). Fast reinforcement learning vision-guided
mobile robots. Proc. IEEE International Conference Robotics Automation, pp. 1822, Barcelona (Spain).
388

fiClosed-Loop Learning Visual Control Policies

McCallum, R. (1996). Reinforcement Learning Selective Perception Hidden State.
Ph.D. thesis, University Rochester, New York.
Michels, J., Saxena, A., & Ng, A. (2005). High speed obstacle avoidance using monocular
vision reinforcement learning. Proc. 22nd International Conference
Machine Learning, pp. 593600, Bonn (Germany).
Mikolajczyk, K., & Schmid, C. (2003). performance evaluation local descriptors.
Proc. IEEE Conference Computer Vision Pattern Recognition, Vol. 2,
pp. 257263, Madison (WI, USA).
Moore, A., & Atkeson, C. (1995). parti-game algorithm variable resolution reinforcement learning multidimensional state-spaces. Machine Learning, 21.
Munos, R., & Moore, A. (2002). Variable resolution discretization optimal control. Machine Learning, 49, 291323.
Nene, S., Nayar, S., & Murase, H. (1996). Columbia object image library (COIL-100). Tech.
rep. CUCS-006-96, Columbia University, New York.
Ng, A., Coates, A., Diel, M., Ganapathi, V., Schulte, J., Tse, B., Berger, B., & Liang, E.
(2004). Inverted autonomous helicopter flight via reinforcement learning. Proc.
International Symposium Experimental Robotics.
Paletta, L., Fritz, G., & Seifert, C. (2005). Q-learning sequential attention visual object
recognition informative local descriptors.. Proc. 22nd International
Conference Machine Learning (ICML), pp. 649656, Bonn (Germany).
Paletta, L., & Pinz, A. (2000). Active object recognition view integration reinforcement learning. Robotics Autonomous Systems, 31 (12), 7186.
Peng, J., & Bhanu, B. (1998). Closed-loop object recognition using reinforcement learning.
IEEE Transactions Pattern Analysis Machine Intelligence, 20 (2), 139154.
Perona, P., Fergus, R., & Zisserman, A. (2003). Object class recognition unsupervised
scale-invariant learning. Conference Computer Vision Pattern Recognition,
Vol. 2, p. 264.
Piater, J. (2001). Visual Feature Learning. Ph.D. thesis, University Massachusetts,
Computer Science Department, Amherst (MA, USA).
Puterman, M., & Shin, M. (1978). Modified policy iteration algorithms discounted
Markov decision problems. Management Science, 24, 11271137.
Pyeatt, L., & Howe, A. (2001). Decision tree function approximation reinforcement
learning. Proc. Third International Symposium Adaptive Systems, pp.
7077, Havana, Cuba.
Quinlan, J. (1993). C4.5: Programs Machine Learning. Morgan Kaufmann Publishers
Inc., San Francisco (CA, USA).
Randlv, J., & Alstrm, P. (1998). Learning drive bicycle using reinforcement learning
shaping. Proc. 15th International Conference Machine Learning, pp.
463471, Madison (WI, USA). Morgan Kaufmann.
389

fiJodogne & Piater

Rummery, G., & Niranjan, M. (1994). On-line Q-learning using connectionist sytems. Tech.
rep. CUED/F-INFENG-TR 166, Cambridge University.
Salganicoff, M. (1993). Density-adaptive learning forgetting. Proc. 10th
International Conference Machine Learning, pp. 276283, Amherst (MA, USA).
Morgan Kaufmann Publishers.
Scalzo, F., & Piater, J. (2006). Unsupervised learning dense hierarchical appearance
representations. Proc. 18th International Conference Pattern Recognition,
Hong-Kong.
Schaal, S. (1997). Learning demonstration. Mozer, M. C., Jordan, M., & Petsche,
T. (Eds.), Advances Neural Information Processing Systems, Vol. 9, pp. 10401046.
Cambridge, MA, MIT Press.
Schmid, C., & Mohr, R. (1997). Local greyvalue invariants image retrieval. IEEE
Transactions Pattern Analysis Machine Intelligence, 19 (5), 530535.
Schmid, C., Mohr, R., & Bauckhage, C. (2000). Evaluation interest point detectors.
International Journal Computer Vision, 37 (2), 151172.
Schyns, P., & Rodet, L. (1997). Categorization creates functional features. Journal
Experimental Psychology: Learning, Memory Cognition, 23 (3), 681696.
Shibata, K., & Iida, M. (2003). Acquisition box pushing direct-vision-based reinforcement learning. Proc. Society Instrument Control Engineers Annual
Conference, p. 6.
Singh, S., Jaakkola, T., & Jordan, M. (1995). Reinforcement learning soft state aggregation. Advances Neural Information Processing Systems, Vol. 7, pp. 361368.
MIT Press.
Sudderth, E., Ihler, A., Freeman, W., & Willsky, A. (2003). Nonparametric belief propagation. Proc. IEEE Conference Computer Vision Pattern Recognition,
pp. 605612.
Sutton, R. (1988). Learning predict methods temporal differences. Machine
Learning, 3 (1), 944.
Sutton, R., & Barto, A. (1998). Reinforcement Learning, Introduction. MIT Press.
Takahashi, Y., Takeda, M., & Asada, M. (1999). Continuous valued Q-learning visionguided behavior acquisition. Proc. International Conference Multisensor
Fusion Integration Intelligent Systems, pp. 255260.
Tarr, M., & Cheng, Y. (2003). Learning see faces objects. Trends Cognitive
Sciences, 7 (1), 2330.
Tesauro, G. (1995). Temporal difference learning TD-Gammon. Communications
ACM, 38 (3), 5868.
Uther, W., & Veloso, M. (1998). Tree based discretization continuous state space reinforcement learning. Proc. 15th National Conference Artificial Intelligence
(AAAI), pp. 769774, Madison (WI, USA).
390

fiClosed-Loop Learning Visual Control Policies

Watkins, C. (1989). Learning Delayed Rewards. Ph.D. thesis, Kings College, Cambridge (UK).
Weber, C., Wermter, S., & Zochios, A. (2004). Robot docking neural vision
reinforcement. Knowledge-Based Systems, 17 (24), 165172.
Wettergreen, D., Gaskett, C., & Zelinsky, A. (1999). Autonomous guidance control
underwater robotic vehicle. Proc. International Conference Field
Service Robotics, Pittsburgh (USA).
Whitehead, S., & Ballard, D. (1991). Learning perceive act trial error.
Machine Learning, 7, 4583.
Yin, P.-Y. (2002). Maximum entropy-based optimal threshold selection using deterministic
reinforcement learning controlled randomization. Signal Processing, 82, 993
1006.
Yoshimoto, J., Ishii, S., & Sato, M. (1999). Application reinforcement learning balancing acrobot. Proc. 1999 IEEE International Conference Systems,
Man Cybernetics, pp. 516521.

391

fiJournal Artificial Intelligence Research 28 (2007) 233266

Submitted 05/06; published 3/07

Auctions Severely Bounded Communication
Liad Blumrosen

liadbl@microsoft.com

Microsoft Research
1065 La Avenida
Mountain View, CA 94043

Noam Nisan

noam.nisan@gmail.com

School Computer Science Engineering
Hebrew University
Jerusalem 91904, Israel

Ilya Segal

ilya.segal@stanford.edu

Department Economics
Stanford University
Stanford, CA 94305

Abstract
study auctions severe bounds communication allowed: bidder
may transmit bits information auctioneer. consider welfare-
profit-maximizing auctions communication restriction. measures,
determine optimal auction show loss incurred relative unconstrained
auctions mild. prove non-surprising properties kinds auctions, e.g.,
optimal mechanisms bidders simply report interval valuation lies
in, well surprising properties, e.g., asymmetric auctions better
symmetric ones multi-round auctions reduce communication complexity
linear factor.

1. Introduction
Recent years seen emergence Internet platform multifaceted economic
interaction, technical level computer communication, routing, storage, computing, level electronic commerce many forms. Studying interactions
raises new questions economics necessity taking computational considerations account. paper deals one question: design
auctions optimally restricted use small amount communication.
paper studies effect severely restricting amount communication allowed
single-item auction. bidder privately knows real-valued willingness pay
item, allowed send k possible messages auctioneer, must
allocate item determine price basis messages received. (For
example, bidder may able send bits information, case k = 2t ).
simplest case k = 2, i.e., bidder sends single bit information. contrast
usual auction design formulation, bidders communicate real numbers.
communicating real number may seem excessively burdensome,
several motivations studying auctions severe restrictions communication. First, auctions used allocating low-level computing resources,
c
2007
AI Access Foundation. rights reserved.

fiBlumrosen, Nisan & Segal

use small amount computational effort. example, auction
routing single packet Internet must require little communication overhead,
certainly whole real number. Ideally, one would like waste bit two
bidding information, perhaps piggy-backing unused bits packet header
existing networking protocols (such IP TCP). Second, amount communication
also measures extent information revelation bidders. Usually, bidders
reluctant reveal exact private data (e.g., Rothkopf, Teisberg, & Kahn, 1990).
work studies tradeoff amount revealed data optimality
auctions. show auctions close optimal even using single Yes/No question per bidder. results also applied various environments
need discretize bidding procedure; one example determining optimal bid
increment English auctions (Harstad & Rothkopf, 1994). Finally, restriction communication may sometimes viewed proxy simplicity considerations,
simple user interface small number possible payments facilitate electronic
handling. recent paper (Blumrosen & Feldman, 2006) shows ideas illustrated
work extend general mechanism-design frameworks requirement
small number actions per player natural intuitive.
examine effect severe communication bounds problem maximizing social welfare maximizing sellers expected profits (the latter
restrictions Bayesian incentive compatibility interim individual rationality
bidders, standard regularity condition distribution bidders valuations). study simultaneous mechanisms, bidders send bids
without observing actions bidders, sequential mechanisms messages may depend previous messages. find single-item auctions may
close fully optimal despite severe communication constraints. contrast
combinatorial auctions, exact even approximate efficiency known require
exponential amount communication number goods (Nisan & Segal, 2006).1
welfare maximization revenue maximization, show optimal
2-bidder auction takes simple form priority game player
highest bid wins, ties broken asymmetrically among players (i.e., players
pre-defined priority others send message). show
derive optimal values parameters priority game. optimal
mechanisms asymmetric definition, although players priori identical.
asymmetry contrast optimal mechanisms unconstrained communication,
symmetric mechanisms achieve optimal welfare (the second-price auction, Vickrey,
1961) optimal profit (the Myerson auction, Myerson, 1981, symmetric bidders).
Furthermore, show number players, allowed number messages
grows, loss due bounded communication order O( k12 ). bound tight
distributions valuations (e.g., uniform distribution). addition,
consider case number players grows player exactly two
1. several studies considering various computational considerations auction design: timing (e.g., Lavi & Nisan, 2004; Roth & Ockenfels, 2002), unbounded supply (e.g., Feigenbaum,
Papadimitriou, & Shenker, 2001; Goldberg, Hartline, & Wright, 2001; Bar-Yossef, Hildrum, & Wu, 2002),
computational complexity combinatorial auctions (see survey Cramton, Shoham, & Steinberg,
2006) more.

234

fiAuctions Severely Bounded Communication

possible messages. show priority games optimal case well,
also characterize parameters optimal mechanisms show
generated simple recursive formula. offer asymptotic bound welfare
profit losses due bounded communication number players grows (it O( n1 )
uniform distribution). optimal mechanisms paper deterministic,
optimal even auctioneer allowed randomize.2
analysis implies expected well unexpected results:
Low welfare profit loss: Even severe bounds communication result
mild loss efficiency. present mechanisms welfare loss
profit loss decrease exponentially number communication bits (and
quadratically number k allowed bids). example, two bidders
whose valuations uniformly distributed [0, 1], optimal 1-bit auction brings
expected welfare 0.648, compared first-best expected welfare 0.667.
Asymmetry helps: Asymmetric auctions better symmetric ones
communication bounds. example, two bidders whose valuations
uniformly distributed [0, 1], symmetric 1-bit auctions achieve expected welfare
0.625, compared 0.648 asymmetric ones. prove welfare-
profit-maximizing auctions must discriminatory allocation payments.
Dominant-strategy incentive compatibility achieved additional
cost: auctions design dominant-strategy equilibria ex-post individually rational3 , yet optimal even without incentive constraints (for welfare
maximization), among Bayesian-Nash incentive-compatible interim individually rational auctions (for profit maximization). generalizes well-known results
case without communication constraints.
Bidding using mutually-centered thresholds optimal: show
optimal auctions k messages, bidders simply partition range valuations
k interval ranges announce interval. 2-bidder mechanisms, threshold
interesting property average value bidder
respective interval. denote threshold vectors mutually centered.
Sequential mechanisms better, linear factor: Allowing players send messages sequentially rather simultaneously achieve
higher payoff simultaneous mechanisms. However, payoff
multi-round mechanism among n players achieved simultaneous mechanism players send messages longer factor n.
result surprising light fact general restriction simultaneous
communication increase communication complexity exponentially. results
2. mechanisms optimal even auctions run repeatedly, long bidders values
uncorrelated time.
3. mechanism ex-post individually rational player never pays value. Interim individual rationality weaker property, player pay value average.
Individual rationality constraints essential study revenue maximization (otherwise,
potential revenue unbounded).

235

fiBlumrosen, Nisan & Segal

sequential mechanisms robust several aspects. allow players
send messages various sizes order, allow auctioneer
adaptively determine order size messages based history
messages. auctioneer may also use randomized decisions.
Although welfare-maximizing mechanisms asymmetric, symmetric mechanisms
also close optimal: show number k possible messages grows,
number players fixed, loss optimal symmetric mechanisms converges
zero rate loss efficient priority games. optimal loss
symmetric asymmetric mechanisms, however, differs constant factor.
hand, fix number messages, show optimal loss asymmetric
mechanisms converges zero asymptotically faster optimal symmetric mechanisms
(O( n1 ) compared O( logn
n ), uniform distribution).
demonstrate properties example simplest case:
2-bidder mechanism player two possible bids (i.e., 1 bit) values
distributed uniformly.
Example 1. Consider two players, Alice Bob, values uniformly distributed
[0, 1]. 1-bit auction among players described 2x2 matrix, Alice
chooses row, Bob chooses column. entry matrix specifies allocation
payments given combination bids. mechanism allowed toss coins
determine allocations. Figure 1 describes example mechanism,
denote mechanism g1 .
strategy defines player determines bid according private value.
first note g1 , players dominant strategies, i.e., strategies optimal
regardless actions players. Consider following threshold strategy:
bid 1 valuation greater 13 , else bid 0. Clearly, strategy dominant
Alice g1 : valuation smaller 13 gain negative utility
bids 1; valuation greater 31 , bidding 0 gives utility zero,
get positive utility bidding 1. Similarly, threshold strategy threshold
2
3 dominant Bob.
social welfare mechanism measures total happiness players
outcome, case, value player receives item. expected
welfare g1 , given players follow dominant strategies, easily calculated
35
54
= 0.648: players bid 0 probability 13 23 , expected welfare
case equals expected value Bob, 21 23 . Similar computations show expected
welfare indeed:







1 2 23
1
2 1 + 23
1 2 1 + 13
1
2 1 + 23
35
+ (1 )
+ (1 )
+ (1 )(1 )
=
33 2
3
3
2
3 3
2
3
3
2
54
see despite restricting communication infinite number bits
1
single bit only, relatively small welfare loss 54
incurred. course, random
allocation implemented without communication result expected
welfare 12 , may regarded naive benchmark.
236

fiAuctions Severely Bounded Communication

turns mechanism described Figure 1 maximizes expected welfare:
1-bit mechanism achieves strictly higher expected welfare pair bidders
strategies (that is, regardless concept equilibrium use). note optimal
mechanism asymmetric (a priority game) ties always broken favor Bob,
mechanism optimal even randomized decisions allowed. Note
optimal symmetric 1-bit mechanism uses randomization, achieves expected
welfare 0.625 (the mechanism illustrated Appendix A.3 see also Footnote 20).
Finally, note optimal thresholds players mutually centered.
is, Alices value 13 average value Bob bids 0 Bobs value 32 average
value Alice bids 1. intuition simple: given Bob bids 0, average
value 12 23 = 13 . values Alice efficient mechanism give
item? Clearly value greater average value Bob. Therefore, Alice
use threshold 13 .

closely related work economic literature Harstad Rothkopf
(1994), considered similar questions cases restricting bid levels oral auctions
discrete levels, Wilson (1989) McAfee (2002) analyzed inefficiency
caused discrete priority classes buyers. particular, Wilson showed number k priority classes grows, efficiency loss asymptotically proportional k12 .
work Wilson buyers aggregate demand known supply uncertain,
model demand uncertain. Wilson Harstad Rothkopf restrict
attention symmetric mechanisms, show creating endogenous asymmetry
among ex ante identical buyers beneficial. Another related work Bergemann
Pesendorfer (2001), seller decide accuracy bidders know
private values. problem different ours, since bidders model know
valuations. work Parkes (2005) also related. compared efficiency
simultaneous sequential auctions uncertainties values players.
Recent work also studied similar discrete-bid model context ascending auctions
auctions use take-it-or-leave-it offers (Kress & Boutilier, 2004; Sandholm & Gilpin,
2006; David, Rogers, Schiff, Kraus, & Jennings, 2005).
organization paper follows: Section 2 presents model definition
introduces notations Section 3 presents characterization welfare- profitoptimal 2-bidder auctions. Section 4 characterizes optimal mechanisms arbitrary
number bidders, 2 possible bids player. Section 5 give asymptotic
analysis minimal welfare profit losses optimal mechanisms. Finally, Section
6 compares simultaneous sequential mechanisms bounded communication.

2. Model
section presents formal model notations use.
237

fiBlumrosen, Nisan & Segal

B

0
1

0

1

B wins pays 0
wins pays 13

B wins pays 0
B wins pays 23

Figure 1: (g1 ) 2-bidder 1-bit game achieves maximal expected welfare. example,
Alice (the rows bidder) bids 1 Bob bids 0, Alice wins pays 13 .

2.1 Bidders Mechanism
consider single item, sealed bid auctions among n risk-neutral players. Player
private valuation object vi [a, b].4 valuations independently drawn
cumulative probability functions Fi . parts analysis5 , assume existence
always-positive probability density function fi . sometime treat seller
one bidders, numbered 0. seller constant valuation v0 item.
consider normalized model, i.e., bidders valuations item a.
novelty model, compared standard mechanism-design settings,
bidder send message ti = lg(ki ) bits mechanism, i.e., player
choose one possible ki bids (or messages). Denote possible set bids bidder
= {0, 1, 2, ..., ki 1}. auction, bidder chooses bid bi . mechanism
determine allocation payments given vector bids b = (b1 , ..., bn ):
Definition 1. mechanism g composed pair functions (a, p) where:
: (1 ... n ) [0, 1]n+1 allocation scheme (not necessarily deterministic).
denote ith coordinate a(b) ai (b), bidder probability
winning
Pn
item bidders bid b. Clearly, b ai (b) 0 b


i=0 (b) = 1.
a0 (b) > 0, seller keep item positive probability.
p : (1 ... n ) <n payment scheme. pi (b) payment ith bidder
given vector bids b.6
Definition 2. mechanism k possible bids, every bidder i, |i | = ki = k.
denote set mechanisms k possible bids among n bidders Gn,k .
denote set n-bidder mechanisms |i | = ki bidder i,
Gn,(k1 ,...,kn ) .
strategy si bidder game g Gn,(k1 ,...,kn ) describes bidder determines
bid according valuation, i.e., function si : [a, b] {0, 1, ..., ki 1}. Let
4. simplicity, use range [0, 1] parts paper. Using general interval
required, though, characterization optimal mechanisms, mainly due reduction
use maximizing revenue translates original support virtual valuations
drawn another interval.
5. is, characterization optimal mechanisms Sections 3.2 4 using
concept virtual valuation Sections 3.3 5.2
6. Note allow non-deterministic allocations, ignore non-deterministic payments (since
interested expected values, using lottery payments effect results).

238

fiAuctions Severely Bounded Communication

si denote strategies bidders except i, i.e., si = (s1 , ..., si1 , si+1 , ..., sn ).
sometimes use notation = (si , si ).
Definition 3. real vector (t0 , t1 , ..., tk ) vector threshold values t0 t1 ... tk .
Definition 4. strategy si threshold strategy based vector threshold values
(t0 , t1 , ..., tk ), every bid j {0, ..., ki 1} every valuation vi [tj , tj+1 ), bidder
bids j valuation vi , i.e., si (vi ) = j (and every vi , vi [t0 , tk ]). say
si threshold strategy, exists vector threshold values si
threshold strategy based t.
2.2 Optimality Criteria
bidders aim maximize (quasi-linear) utilities. utility bidder
loses (and pay nothing), vi pi wins pay pi . Let ui (g, s) denote
expected utility bidder game g bidders use vector strategies
(implicit utility depends value vi ).
Definition 5. strategy si bidder dominant mechanism g Gn,(k1 ,...,kn )
regardless bidders strategies si , cannot increase expected utility
deviation another strategy, i.e.,
sei si ui (g, (si , si )) ui (g, (sei , si ))
Definition 6. profile strategies = (s1 , ..., sn ) forms Bayesian-Nash equilibrium
(BNE) mechanism g Gn,(k1 ,...,kn ) , every bidder i, si best response
strategies si bidders, i.e.,
sei ui (g, (si , si )) ui (g, (sei , si ))
use standard participation constraints definitions: say profile strategies
= (s1 , ..., sn ) ex-post individually rational mechanism g, every bidder never pays
actual valuation (for realization valuations); assume
strong version definition holds even randomized mechanisms. say
strategies profile = (s1 , ..., sn ) interim individually rational mechanism g every
bidder achieves non-negative expected utility, given valuation might have,
bidders play si .
goal find optimal, communication-bounded mechanisms. mechanism
designers, try optimize social criteria welfare (efficiency) sellers
profit.
expected welfare mechanism g, bidders use strategies s,
expected social surplus. item indivisible, social surplus actually
valuation bidder receives item. seller keeps item, social welfare
v0 .
Definition 7. Let w(g, s) denote expected welfare (or expected efficiency) n-bidder
game g bidders strategies s, i.e., expected value player (possibly
opt
seller) receives item g. Let wn,(k
denote maximal possible expected
1 ,...,kn )
239

fiBlumrosen, Nisan & Segal

welfare n-bidder game bidder ki possible bids, vector
strategies allowed, i.e.,
opt
wn,(k
=
max
w(g, s)
1 ,...,kn )
gGn,(k1 ,...,kn ) ,

opt
opt
bidders k possible bids use notation wn,k
= wn,(k,...,k)

Actually, optimal welfare defined maximum expected welfare
obtained equilibrium. Since later show optimal welfare without
strategic considerations dominant-strategy implementable, use definition
simplicity. Note even absence communication restrictions, optimizing
welfare objective obtained first-best solution (using VCG scheme); profit
maximization, hand, obtained second-best solution (incentive constraints
bind Myersons auction, Myerson, 1981).
Definition 8. sellers profit payment received winning bidder, v0
seller keeps item.7 Let r(g, s) denote expected profit n-bidder game
opt
g bidders strategies s. Let rn,k
denote maximal expected profit
n-bidder mechanism k possible bids vector interim individually-rational
strategies forms Bayesian-Nash equilibrium g:
opt
rn,k
=

max
r(g, s)
g Gn,k
interim IR BNE g

Note define optimal welfare maximal welfare among mechanisms
strategies, necessarily equilibria, define optimal profit maximal
profit achievable interim-IR Bayesian-Nash equilibria mechanism. Yet, optimal
mechanisms (for measures) present paper implement optimal
values dominant strategies ex-post IR.8
Definition 9. say mechanism g Gn,k achieves optimal welfare (resp.
profit), g interim-IR Bayesian-Nash equilibrium expected welfare
opt
opt
(resp. profit) w(g, s) = wn,k
(resp. r(g, s) = rn,k
).
say mechanism g Gn,k incurs welfare loss (resp. profit loss) L,
achieves expected welfare (resp. profit) additively smaller optimal welfare (resp. profit) unbounded communication L (the optimal results unbounded
communications best results achievable interim-IR Bayesian-Nash equilibria).

3. Optimal Mechanisms Two Bidders
section present 2-bidder mechanisms bounded communication achieve
optimal welfare profit. Section 4 present characterization welfareoptimal profit-optimal n-bidder mechanisms 2 possible bids bidder.
7. v0 = 0, expected profit equivalent sellers expected revenue.
8. Note ex-ante IR, i.e., bidders know type choosing strategies, noninteresting model, since auctioneer simply ask bidder pay expected
valuation.

240

fiAuctions Severely Bounded Communication

characterization optimal mechanisms general case (n bidders k possible bids) remains open question. Anyway, asymptotic analysis optimal welfare
loss profit loss (in Section 5) holds general case, shows asymptotically
optimal mechanisms.
first show allocation rules efficient mechanisms certain structure
call priority games. term priority game means allocation rule uses
asymmetric tie breaking rule: winning player player highest priority
among bidders bid highest. One consequence bidder lowest
priority win bid strictly higher bids. Note
term priority game refers asymmetry mechanisms allocation function,
additional asymmetry also appear payment scheme. modified priority game
similar allocation, except item allocated bidders bid
lowest bid.9 mostly interested mechanisms players
bid space .
Definition 10. game called priority game allocates item bidder
bids highest bid (i.e., bi > bj j 6= i, allocation ai (b) = 1 aj (b) = 0
j 6= i), ties consistently broken according pre-defined order bidders.
game called modified priority game allocation priority game,
except bidders bid 0, seller keeps item.
turns useful build payment scheme mechanisms according
given profile threshold strategies:
Definition 11. n-bidder priority game based profile threshold values vectors


= (t1 , ..., tn ) ni=1 <k+1 (where every i, ti0 ti1 ... tik ) mechanism
whose allocation priority game payment scheme follows: bidder j
wins item vector bids b pays smallest valuation might
still win item, given uses threshold strategy sj based tj , i.e, pj (b) =


min{vj |aj (sj (vj ), bj ) = 1}. denote mechanism P Gk ( ). modified priority
game similar payment rule called modified priority game based profile


threshold-value vectors, denoted P Gk ( ).
2-bidder games, may use notations P Gk (x, y), P Gk (x, y) (where x,
vectors threshold values). mechanisms P Gk (x, y) P Gk (x, y) presented Figure 2. Note P Gk (x, y) P Gk (x, y) differ bidder bids 0
(i.e., first line games matrix).
observe priority games modified priority games, payments
schemes described above, two desirable properties: admit dominantstrategy equilibrium, ex-post individually rational players follow
dominant strategies.
dominant strategies, well known result mechanism design (see Mookherjee
& Reichelstein, 1992 also Lemma 1 Segal, 2003) states monotone10
9. Modified priority games viewed priority games treat seller one bidders
lowest priority (then, seller always bids second-lowest bid).
10. mechanism monotone probability bidder wins increases raises bid, fixing
bids bidders. See Definition 12 model.

241

fiBlumrosen, Nisan & Segal

allocation rule transfer (i.e., payment) rule would implement desired
allocation dominant strategies. deterministic auctions, support equilibrium,
winning bidder pay smallest valuation still wins (fixing
behavior bidders). payments Definition 11 defined way,
therefore support dominant-strategy implementation. follows threshold




strategies based threshold values vector dominant P Gk ( )


P Gk ( ). clear definition priority games modified priority games
that, playing dominant threshold strategies, winning players never pay
value, losing players pay zero. Ex-post IR follows.
Actually, observation payments lead dominant strategies even
general. observe monotone mechanisms reveal enough information, despite
communication constraints, find transfer rules support dominant-strategy
implementation. Therefore, characterizing optimal mechanisms focus
defining monotone allocation schemes communication restrictions, transfers lead dominant-strategy equilibria concluded free. words,
use 2-stage approach widely used mechanism-design literature also
bounded-communication settings: first solve optimal allocation rule, construct transfers satisfy desired incentive-compatibility individual-rationality
constraints.
Remark 1. argument holds general environments: environments
player one-dimensional private value quasi-linear utility, non-monetary
allocation rule implemented dominant strategies transfers,
communication protocol11 realizing rule also reveals enough information construct
supporting transfers dominant strategies. see this, recall direct-revelation
mechanisms (i.e., unbounded communication), allocation rule proves
monotonic, transfers support dominant-strategy equilibrium. transfers
defined according allocation-dependent thresholds, e.g., deterministic
allocation rule every bidder pay smallest valuation still wins.
standard revelation-principle arguments, monotonic allocation rule bounded communication mechanisms, viewed monotonic direct-revelation mechanism
unbounded communication, therefore supporting transfers exist. supporting
transfers determined changes allocation rule valuation bidder
increases, transfers change allocation rule changes. Thus, communication protocol used determining allocation, reveal transfers
support dominant-strategy implementation.
3.1 Efficiency Priority Games
characterization welfare-maximizing mechanism done two steps: first
show allocation scheme 2-bidder priority games optimal12 . Afterwards,
characterize strategies players lead welfare maximization priority
11. deal simultaneous communication, i.e., bidders send messages simultaneously. observation true sequential mechanisms (see Section 6).
12. assume, w.l.o.g., throughout paper 2-bidder priority games B A, i.e., mechanism
allocates item bids higher B, otherwise B.

242

fiAuctions Severely Bounded Communication

0
1
2
...
k-2
k-1

0
B, y0
A, x1
A, x1
...
A, x1
A, x1

1
B, y0
B, y1
A, x2
...
A, x2
A, x2

...
...
...
...
...
...
...

k-2
B, y0
B, y1
B, y2
...
B, yk2
A, xk1

k-1
B, y0
B, y1
B, y2
...
B, yk2
B, yk1

0
1
2
...
k-2
k-1

0

A, x1
A, x1
...
A, x1
A, x1

1
B, y1
B, y1
A, x2
...
A, x2
A, x2

...
...
...
...
...
...
...

k-2
B, y1
B, y1
B, y2
...
B, yk2
A, xk1

k-1
B, y1
B, y1
B, y2
...
B, yk2
B, yk1

Figure 2: priority game (left) modified priority game (right) based threshold
values vectors x, y. entry, left argument denotes winning bidder,
right argument price pays. mechanisms differ allocation all-zero
bids, payments first row.

games; complete description outcome mechanism every profile
bidder valuations. two stages take strategic behavior bidders
account. Yet, observed before, since allocation scheme proved monotone,
exists payment scheme strategies dominant.
Definition 12. mechanism g Gn,k monotone vector bids b
bidder i, probability bidder wins item cannot decrease bid
increases, i.e.,
0
0
b bi > bi ai (bi , bi ) ai (bi , bi )
following theorem prove priority games welfare maximizing.
proof composed four steps: first show assume bidders
optimal mechanisms use threshold strategies. Then, show allocation optimal mechanisms is, w.l.o.g., monotone deterministic. show optimal
mechanisms waste communication, i.e., two rows two columns
allocation matrix optimal mechanism identical. Finally, use properties,
together several combinatorial arguments, derive optimality priority games.
Theorem 3.1. (Priority games efficiency) every pair distribution functions
opt
bidders valuations, every v0 , optimal welfare (i.e., w2,k
) achieved
either priority game modified priority game (with pair threshold strategies).
Proof. first prove theorem given seller low reservation value, i.e.,
v0 a. Recall point aim find welfare-maximizing allocation scheme,
without taking incentives bidders account. proof uses following
three claims. later use, Claims 3.2 3.3 proved n players.
Claim 3.2. (Optimality threshold strategies) Given mechanism g Gn,(k1 ,...,kn ) ,
exists vector threshold strategies achieve optimal welfare g among
possible strategies, i.e., w(g, s) = maxse w(g, se).
Proof. (sketch - formal proof given Appendix A.1)
Given profile welfare-maximizing strategies g, modify strategy
bidder (w.l.o.g., bidder 1) threshold strategy maintaining least expected
welfare. idea fixing strategies s1 bidders, expected welfare
243

fiBlumrosen, Nisan & Segal

achieved bidder 1 bids bid b1 linear function bidder value v1 .
maximum linear functions piecewise-linear function, specifies
optimal welfare function v1 . Bidder 1 use threshold strategy according
breaking points piecewise-linear function choose welfare-maximizing linear
function segment. Clearly, k 1 breaking points.
Claim 3.3. (Optimality deterministic, monotone mechanisms) every n
k1 , ..., kn , exists mechanism g Gn,(k1 ,...,kn ) optimal welfare (i.e., exists
opt
profile strategies w(g, s) = wn,(k
) monotone, deterministic
1 ,...,kn )
(i.e., winner fixed combination bids) seller never keeps
item.
Proof. Consider mechanism g Gn,(k1 ,...,kn ) profile strategies maximize
opt
expected welfare, is, w(g, s) = wn,(k
. social planner, aiming maximize
1 ,...,kn )
welfare, always allocate item bidder highest expected valuation.
is, combination bids b = (b1 , .., bn ) allocate item (i.e., ai (b) = 1)
bidder argmaxj (E(vj |sj (vj ) = bj )). expected welfare clearly
decrease. addition, always allocate item (we assume v0 a),
allocation deterministic. Finally, assume, w.l.o.g., bidder bids
names (i.e., 0,1 etc.) ordered according expected value bidder has.
Then, mechanism also monotone: winning bidder increases bid,
expected valuation also increase, expected welfare bidders
change. Thus, bidder still maximal expected valuation.
Claim 3.4. (Additional bids strictly help) Consider deterministic, monotone mechanism g G2,k seller never keeps item. g achieves optimal expected
welfare, matrix representation g two rows (or columns) identical
allocation scheme.
Proof. idea optimal protocol exploits communication resources intuitive, although hold settings (a trivial example calculating parity
two binary numbers, involved examples found Kushilevitz & Nisan, 1997).
simple proof statement model, proof based
Lemma A.1 appendix following way: Consider optimal mechanism
g G2,k two identical rows. mechanism achieves optimal welfare
players use profile strategies s. gs monotonicity implies two identical rows
adjacent. Thus, mechanism ge G2,(k1,k) k 1 possible bids
rows bidder achieves exactly expected welfare g (when identical
rows united one). welfare achieved strategies bidders,
rows player bids united row instead two identical rows. claim
follow Lemma A.1 appendix. According lemma, optimal welfare
game bidders k possible bids cannot achieved one
opt
opt
bidders k 1 possible bids (i.e., w2,k
> w2,(k1,k)
).
Now, due Claim 3.3, deterministic, monotone game item
opt
must sold achieves w2,k
. games, allocation scheme row looks
244

fiAuctions Severely Bounded Communication

like [A, ..., A, B...B]. Due Claim 3.4, matrix representation optimal game,
two rows allocation scheme. k+1 possible monotone
rows game matrix (with prefix 0 k As), mechanism k rows.
Similarly, k different columns (of possible k+1) mechanism. Assume
row [B, B, ..., B] g. Then, column [A, A, ..., A] clearly g. Therefore,
game matrix consists columns except [A, A, ..., A], compose priority
game B A. row [B, B, ..., B] g, g priority game
B.
Next, complete proof sellers valuation v0 . Consider mechanism h G2,k
pair threshold strategies based threshold-value vectors x
e, ye achieve
optimal welfare among mechanisms strategies (due Claim 3.2, strategies
exist). modify h, expected welfare (with x
e, ye) decrease. Let
smallest index E(vA |f
xa vA xg
)

v
.
Let
b smallest index
a+1
0
E(vB |yeb vB yg
b+1 ) v0 . = 0 b = 0, item never allocated
seller, efficient mechanism v0 a.
a, b > 0, consider vector bids (i, j). < j < b, expected
valuations B smaller v0 . Thus, seller keep item
optimal welfare. < j b, expected welfare bidder B v0 ,
expected welfare v0 , thus allocate item B welfare
decrease. Similarly, allocate item j < b. < a,
allocation done regardless i, thus assume xa first threshold (i.e.,
= 1), similarly b = 1.
Now, show optimal allocation combinations bids (i, j)
j b. Here, item allocated seller, actually perform auction
k 1 possible bids bidder, bidders valuation range [f
x1 , 1],
[ye1 , 1]. Note proof (above) case v0 holds ranges,
optimal welfare achieved priority game. Altogether, optimal mechanism turns
modified priority game.
3.2 Efficient 2-bidder Mechanisms k Possible Bids
Now, finally characterize efficient mechanisms model. turns
optimal threshold values priority games mutually centered, i.e., threshold
expected valuation bidder, given valuation bidder
lies two adjacent thresholds.
Definition 13. threshold values x = (x0 , x1 , ..., xk1 , xk ), = (y0 , y1 , ..., yk1 , yk )
bidders A, B respectively mutually centered, following constraints hold:
R yi
yi1 fB (vB ) vB dvB
1 k 1 xi = E(vB |yi1 vB yi ) =
F (y ) FB (yi1 )
R xBi+1
fA (vA ) vA dvA
xi
1 k 1 yi = E(vA |xi vA xi+1 ) =
FA (xi+1 ) FA (xi )


easy see given pair distribution functions, pair
x,
mutuallycentered vectors uniquely defined (when xk = yk and, w.l.o.g., y1 x1 ). basic
245

fiBlumrosen, Nisan & Segal

idea x1 known, clearly calculate y1 (the smallest value solves
x1 = EvB (vB |y0 vB y1 )). Similarly, easy see variables xi yi
considered continuous, monotone functions x1 . Now, let z solution
equation yk1 = E(vA |xk1 vA z). satisfying 2(k 1) equations, z must
equal xk . Since z also continuous monotone function x1 , single value
x1 equations hold.
following intuition shows optimal thresholds priority games must
mutually centered: Assume Alice bids i, is, value range [xi , xi+1 ].
monotone mechanism, mechanism designer decide minimal value
Bob wins Alice bids i. value Bob least average value Alice,
given bids i, Bob clearly receive item. Therefore, Bobs threshold
exactly expected value Alice. proof handle subtleties
intuition suffice (like characterization first thresholds
optimal modified priority games, see below), thus derive mutually-centered
condition solution optimization problem.
w
w
w
w = (a = w , w , ..., w , w = b)
Let xw = (a = xw
0 , x1 , ..., xk1 , xk = b)
0
1
k1 k
w
mutually-centered threshold values (w.l.o.g., y1 xw
1 ).
Let x = (a = x0 , x1 , ..., xk1 , xk = b) = (a = y0 , y1 , ..., yk1 , yk = b) two thresholdvalue vectors following constraints hold:
(x1 , ..., xk1 , b) (y1 , ..., yk1 , b) mutually-centered vectors13 .


Rx
x1 = v0 y1 = FA 1(x2 ) v0 FA (v0 ) + x12 vA fA (vA )dvA
following theorem says valuation seller item (v0 ) small
enough (e.g., a), efficient mechanism priority game based xw w (which
mutually centered). Otherwise, optimal welfare achieved modified priority
game based x y.
Theorem 3.5. pair distribution functions bidders valuations,
sellers valuation v0 item, mechanism P Gk (xw , w ) mechanism
opt
P Gk (x, y) achieves optimal welfare (i.e., w2,k
). particular, P Gk (xw , w ) achieves
optimal welfare v0 = a.
Proof. First, prove P Gk (xw , w ) optimal v0 = a. According Theorem
3.1 pair threshold values vectors x = (x0 , x1 , ..., xk ),y = (y0 , y1 , ..., yk )
P Gk (x, y) achieves optimal welfare. Note x0 = y0 = xk = yk = b,
2(k 1) variables optimize.
calculate total expected welfare summing first expected welfare
entries game matrix B wins item, summing entries
winner.
R yi
k
X
fB (vB )vB dvB

w(g, s) =
(FB (yi ) FB (yi1 )) (FA (xi ) FA (x0 )) i1
FB (yi ) FB (yi1 )
i=1

13. Again, unique solution exists when, w.l.o.g., y2 x2

246

fiAuctions Severely Bounded Communication

+

k
X

R xi
(FA (xi ) FA (xi1 )) (FB (yi1 ) FB (y0 ))

i=2

=

k
X

Z
FA (xi )

i=1

yi

yi1

fB (vB )vB dvB +

k
X

Z
FB (yi1 )

i=2

xi1

fA (vA )vA dvA

FA (xi ) FA (xi1 )

xi

xi1

fA (vA )vA dvA

assume probability density function exists bidder. Thus,
express partial derivatives respect variables:
Z
!
yi

0

(w(g, s))xi =

yi1

Z

0

(w(g, s))yi =

fB (vB )vB dvB

xi+1

xi

fA (xi ) + fA (xi ) xi FB (yi1 ) fA (xi ) xi FB (yi ) = 0


fA (vA )vA dvA fB (yi ) + fB (yi ) yi FA (xi ) fB (yi ) yi FA (xi+1 ) = 0

Rearranging terms derives yi = EvA (vA |xi vA xi+1 )
xi = EvB (vB |yi1 vB yi ) therefore, x, mutually centered optimal
efficiency.
Now, longer assume v0 = a: According Theorem 3.1, optimal welfare
achieved priority game above, achieved modified priority game.
threshold values vectors x, y, expected welfare P Gk (x, y) given
formula:
Z b
Z b
vB fB (vB )dvB + FB (y1 )
vA fA (vA )dvA
FA (x1 ) FB (y1 ) v0 + FA (x1 )
+
+

k
X
i=2
k
X
i=3

Z
(FA (xi ) FA (x1 ))

y1

yi

yi1

Z
(FB (yi1 ) FB (y1 ))

x1

vB fB (vB )dvB

xi

xi1

vA fA (vA )dvA

First-order condition similarly derive constraints x1 y1 given definition x, y, (x1 , ..., xk1 , xk ) (y1 , ..., yk1 , yk ) mutually-centered14 .
demonstrate characterization given showing explicit solution
case uniformly-distributed valuations [0, 1].
Corollary 3.6. bidders valuations distributed uniformly [0, 1] v0 = 0,
mechanism P Gk (x, y) achieves optimal welfare
x = (0,

1
3
2k 3
,
, ...,
, 1) ,
2k 1 2k 1
2k 1

= (0,

2
4
2k 2
,
, ...,
, 1)
2k 1 2k 1
2k 1

14. results surprising, since except case one bidders bids 0, priority
games allocation optimal threshold values must mutually centered (due first
part proof).

247

fiBlumrosen, Nisan & Segal

Proof. According Theorem 3.5 optimal welfare achieved P Gk (x, y), x,
mutually centered. uniform distributions, derives following constraints,
i+1
given vectors x, unique solution: 1ik1 xi = yi12+yi
yi = xi +x
2
see constraints implied, note conditional expectation
second players value, given value uniformly distributed yi1 yi ,
exactly yi12+yi .
1
y1 = x12+1 , implying
example, k = 2 constraints x1 = 0+y
2
x1 = 1/3 y1 = 2/3 optimal 1-bit mechanism Example 1.
optimal mutually-centered thresholds k = 4 are, instance, x = (0, 71 , 37 , 75 , 1)
= (0, 72 , 47 , 76 , 1).

3.3 Profit-Optimal 2-bidder Mechanisms k Possible Bids
Now, present profit-maximizing 2-bidder mechanisms. results literature
profit-maximizing auctions assume distribution functions bidders valuations
regular (as defined below). valuations bidders distributed
regular distribution function, well known Vickreys 2nd-price auction,
appropriately chosen reservation price, profit-optimal (Vickrey, 1961; Myerson, 1981;
Riley & Samuelson, 1981) unbounded communication.
Definition 14. (Myerson, 1981) Let f probability density function, let F
cumulative function. say f regular, function
ve(v) = v

1 F (v)
f (v)

monotone, strictly increasing function v. call function ve() virtual valuation
bidder.
example, bidders valuations distributed uniformly [0, 1], bidder
valuation v virtual valuation ve(v) = 2v 1.
Definition 15. virtual surplus game virtual valuation bidder (including seller15 ) receives item.
key observation work Myerson (1981), also use,
Bayesian-Nash equilibrium, expected profit equals expected virtual surplus (in interim individually-rational equilibria losing bidders getting surplus).
use property reduce profit-optimization problem welfare-optimization problem, already given full solution. Myersons observation originally
proved direct-revelation mechanisms. observe Myersons observation also
holds auctions bounded communication. is, given k-bid mechanism,
expected profit every Bayesian-Nash equilibrium equals expected virtual surplus.
Proposition 3.7. Let g Gn,k mechanism Bayesian Nash equilibrium =
(s1 , ..., sn ) interim individual rationality. Then, expected revenue achieved
g equal expected virtual surplus g.
15. sellers virtual valuation defined original valuation (v0 ).

248

fiAuctions Severely Bounded Communication

Proof. Consider following direct-revelation mechanism gd : player bids true
valuation vi . mechanism calculates si (vi ) every i, determines allocation
payments according g. easy observation gd incentive compatible (i.e.,
truthful bidding Bayesian-Nash equilibrium players) interim individually
rational. According Myerson observation direct revelation mechanisms, expected
revenue gd equal expected virtual surplus. However, every combination
bids, mechanism output identical allocations payments. Thus, expected
revenue expected virtual surplus equal mechanisms.
According Theorem 3.5, optimal welfare achieved either priority game
modified priority game. model bidders consider virtual valuations
valuations, let P G(e
x, ye) P G(x, y) mechanisms candidates
achieve optimal welfare (see Theorem 3.5 full characterization). Now, consider
mechanisms, except payment e
c replaced respective true valuation c = ve1 (e
c) (i.e., e
c = ve(c) ). Denote mechanisms P Gk (xR , R ), P Gk (xr , r ).
mechanisms achieve optimal profit (original) model. Note distribution functions must regular (but necessarily identical) reduction
work.
Theorem 3.8. bidders valuations distributed regular distribution functions, mechanism P Gk (xr , r ) mechanism P Gk (xR , R ) (see definitions above)
achieve optimal expected profit among profits achievable interim-IR Bayesianopt
Nash equilibrium mechanism G2,k (i.e., r2,k
).
x, ye) (x, y) defined above. mechanism
Proof. Consider threshold-value vectors (e
P G(e
x, ye) efficient model bidders consider virtual valuations
valuation (the proof holds P G(x, y) efficient mechanism). density
function f regular, therefore virtual valuation ve() strictly increasing. Thus,
P Gk (xr , r ) (when bidders use original valuations) exactly
allocation every combination bids P Gk (e
x, ye) (when bidders consider
virtual valuations valuations). conclude P Gk (xr , r ) achieves optimal
expected virtual surplus thus also optimal profit.
case welfare optimization, give explicit solution case
uniform distribution functions. direct corollary Theorem 3.8. Note
optimal profit achieved modified priority game. holds since uniform
distribution bidders expected virtual valuation negative bid 0,
efficient mechanism sell item bidders bid 0.
Corollary 3.9. bidders valuations distributed uniformly [0, 1] v0 = 0,
modified priority game P Gk (x, y) achieves optimal expected profit among
profits achievable interim-IR Bayesian-Nash equilibria mechanisms G2,k ,
1
1 (1 )
(2k 5) (1 )
x = (0, , +
, ..., +
, 1)
2
2k 3
2k 3
= (0, , +

2 (1 )
(2k 4) (1 )
, ..., +
, 1)
2k 3
2k 3
249

fiBlumrosen, Nisan & Segal

=


2+ 1+3
2(1)

=

1
(2k3)2

( =

5
8

k=2).

4. Optimal Mechanisms n Bidders Two Possible Bids
section consider games among n bidders bidder 2 possible bids
(i.e., send 1 bit mechanism). give characterization optimal
mechanisms general distribution functions. characterization optimal n-bidder
mechanism k possible bids seems harder, remains open question.
difficulty stems fact monotonicity allocation rule dictate
exact allocation rule general case. Rather, many possible allocation
schemes cannot rule know strategies bidders.16 Therefore,
seems one solve involved combinatorial problem finding optimal
allocation rule together finding optimal payments. Priority games 2 possible
bids per player interpreted sequence take-it-or-leave-it offers; player
highest priority interpretation first player offered, accepts
offer (i.e., bids 1) receive it. See work Sandholm Gilpin (2006)
analysis take-it-or-leave-it mechanisms. Moreover, 1-bit priority games actually
solution full-information version secretary problem (e.g., Gilbert & Mosteller,
1966; Ajtai, Megiddo, & Waarts, 2001). decision maker meets players (or potential
secretaries hired), one another, search player highest
value. decision maker knows underlying probability distributions. decision,
however, made online player receive item upon arrival
never receive item.
4.1 Characterization Optimal Mechanisms
first observe priority games also maximize welfare n-bidder games 2 possible bids. easier see k-possible-bids case. Claim 3.2 Theorem 3.1,
bidders use threshold strategies. efficient mechanism allocate item,


combination bids b , bidder highest
bids bi.


expected welfare
Given distributions i.i.d, xi xj E vi vi [xi , b] E vj vj [xj , b]
E (vi |vi [a, xi ] ) E (vj |vj [a, xj ] ). Therefore, ties broken according
order thresholds. sellers reservation price v0 high enough, efficient
mechanism modified priority game.17
show characterization optimal thresholds priority games.
show optimal mechanisms use fully discriminatory payments: bidder
highest priority priority game pays highest payment wins, forth.
optimal modified priority game given simple recursive formula. seller
allocates item bids zero, constraints become cyclic.
16. Consider, example, 3-bidder 3-bid priority game, item allocated player
second-highest priority players bid highest bid. mechanism also monotone
identical actions players.
17. see this, must note efficient mechanism seller never keep item one
bidder bids 1 (then, threshold higher v0 bidder gain higher welfare).

250

fiAuctions Severely Bounded Communication



Let
x = (x1 , ..., xn )
= (y1 , ..., yn ) profiles threshold values n
bidders following constraints hold:

1mn2

1mn2

x1 = E (v |a v xn )


xm+1 = (1 F (xm )) E v v [xm , b] + F (xm ) xm


Pn1 Qn1

i=1 ( j=i+1 F (xj )) (1 F (xi )) E v v [xi , b]
xn =
Q
1 n1
i=1 F (xi )
y1 = v 0


ym+1 = (1 F (ym )) E v v [ym , b] + F (ym ) ym

(1)
(2)
(3)
(4)
(5)



prove either mechanism P G2 (
x ) mechanism P G2 (
) achieve
optimal welfare. thresholds description shows, thresholds modified
priority game (i.e., seller keeps item bids zero) defined
simple, easy-to-compute recursive formula. optimality thresholds
shown following intuitive argument: Consider new bidder joins set 1
bidders. efficient auction allocate item bidder value
greater optimal welfare achievable first 1 bidders. Therefore,
threshold bidder equal optimal welfare gained preceding bidders;
indeed, probability 1 F (yi1 ), bidder valuation greater
expected
bidders (yi1 ) average contribution

welfare attained
E v v [ym , b] ); probability F (yi1 ) contribute optimal
welfare remains yi1 . intuition shows profit-maximizing thresholds
(Equations 4,5) independent number players, enables online
implementation profit-maximizing auctions.
Theorem 4.1. bidders valuations distributed distribution func

tion, mechanism P G2 (
x ) mechanism P G2 (
) achieves optimal expected

welfare. particular, v0 = a, P G2 (
x ) efficient mechanism.
Proof. already observed exists priority game achieves optimal
welfare threshold strategies. Consider priority game among n bidders, indexed
priorities (i.e., 1 2... n ). Every bidder wins item bids 1

Qthe bidderswith higher priorities bid 0. Thus, probability bidder wins
n
j=i+1 F (xj ) (1 F (xi )). bidders bid 0, either bidder n wins seller
keeps item herself. expected welfare game, bidders use
threshold strategies x1 , ..., xn is:


n
!
Rb
n
n


X
f (vi )vi dvi
x


F (xj ) (1 F (xi ))
+
F (xi ) E0
w(g, s) =
(1 F (xi ))
i=1

j=i+1

i=1

E0 = E(vn |vn [a, xn ]) priority game Eo = v0 modified priority
game (the second term relates case bidders bid 0). maximum,
partial derivatives respect x1 , ..., xn equal zero, resulting characterization
optimal solution.
251

fiBlumrosen, Nisan & Segal

bidders 1 n 1 get xm equals (both priority game
modified priority game):




m1
m1
X m1






F (xj ) (1 F (xi )) E vi vi [xi , b] +
F (xi ) E (vn |vn [a, xn ] )
i=1

j=i+1

i=1,i6=m

recursive formula reached calculating xm+1 xm , Equations 2
5 follow. bidder n priority game first order conditions yield constraint
Equation 3. = 1, x1 = E (vn |a vn xn ) (in priority game)
x1 = v0 (in modified priority game).
Section 3, characterize profit optimal mechanism reduction
welfare optimizing problem. Again, reduction performed regular distributions. Consider model bidders take virtual valuations valuations.
Let P G2 (e
u) P G2 (e
z ) mechanisms achieve optimal welfare model
(see Theorem 4.1 above). Let P G2 (u) P G2 (z) similar mechanisms respectively,
except payment e
c replaced respective original valuation c = ve1 (e
c).
Theorem 4.2. bidders valuations distributed regular distribution function, mechanism P G2 (u) mechanism P G2 (z) achieves optimal
expected profit among profits achievable Bayesian-Nash equilibrium interim IR.
Proof. corollary Theorem 4.1. reduction done Theorem 3.8,
possible due regularity distribution function.
Again, optimal thresholds modified priority game given simple
recursive formula intuitive meaning. recursion identical welfare optimizing formula (Equation 2), difference value first threshold
hold y1 = ve1 (v0 ). intuition given best revenue achievable
first 1 bidders yi1 , probability F (yi1 ) new player
able pay higher price (due individual-rationality restriction) therefore
optimal revenue remains yi1 . value greater yi1 , cannot charged
average value (E(v|yi1 v b)).
Now, give explicit solutions uniform distribution support [0, 1].
following recursive constraints characterize efficient profit-optimal mechanisms
constraints given Theorems 4.1 4.2 uniform distributions.
Let (x1 , ..., xn ) [0, 1]n threshold values following constraints hold:
x1 =
{1, ..., n 2}

xm+1 =
xn =

252

xn
2
1 x2m
+
2
2
Pn1 Qn1



x
1 x2i
j=i+1 j
i=1

Qn1
2 1 i=1
xi

(6)
(7)
(8)

fiAuctions Severely Bounded Communication

Let = (y1 , ..., yn ) [0, 1]n threshold values y1 =
{1, ..., n 2}

ym+1 =

1
2

and:

2
1 ym
+
2
2



Corollary 4.3. Consider threshold values
x = (x1 , ..., xn )
= (y1 , ..., yn ) defined

above. bidders valuations distributed uniformly [0, 1] v0 = 0, P G2 (
x)


achieves optimal welfare P G2 ( ) achieves optimal profit.
example, n = 5 = (0.5, 0.625, 0.695, 0.741, 0.775).
description simpler closed-form formulae could find.

5. Asymptotic Analysis Welfare Profit Losses
section, measure performance optimal mechanisms presented earlier
sections. Although present characterization optimal mechanisms
general model k possible bids n bidders, present mechanisms general
case asymptotically optimal. simplicity, assume valuations range
[0, 1] (all results apply general range [a, b] changes constants
analysis).
analyze welfare loss (Subsection 5.1), profit loss (Subsection 5.2), finally,
Subsection 5.3 measure profit loss welfare loss 1-bit mechanism
n bidders. result asymptotic respect amount communication,
except Section 5.3 respect number bidders.
5.1 Asymptotic Bounds Welfare Loss
next theorem shows matter bidders valuations distributed,
always construct mechanisms welfare loss incur diminishes quadratically
k. true number bidders fix (when k > 2n). particular, efficient
mechanism presented Theorem 3.5 incurs welfare loss O( k12 ). intuition behind
proof: given distribution functions bidders, construct certain threshold
strategy, dominant bidders. using strategy, bidder
bid bid probability smaller k1 . way, probability welfare loss
may occur O( k1 ) (for two players, instance, welfare loss possible
diagonal games matrix). average welfare loss also O( k1 ), resulting
total expected loss O( k12 ).
Theorem 5.1. (fixed) number bidders n, set distribution functions
bidders valuations, exist set mechanisms gk Gn,k (k = 2n + 1, 2n + 2, ...),
incur expected welfare loss O( k12 )). results implemented dominant
strategies ex-post individual rationality.
requirement k > 2n (here Proposition 5.3 below) due construction symmetric mechanism following proof. results hold even without
requirement, shown asymmetric construction general setting
work Blumrosen Feldman (2006).
253

fiBlumrosen, Nisan & Segal

Proof. proofs idea: construct priority game bidders
dominant threshold strategy, probability bidder bid bid smaller
nk . done dividing density functions bidders nk intervals
equal mass, combining thresholds vector k threshold values.
bidders use threshold strategy, welfare loss possible one
bidder bids highest bid. observation leads upper bound.

P
Let 1 , ..., n integers ni=1 = k 2, every i, nk 1
(clearly numbers exist). every bidder i, let = (y1i , ..., yi ) set threshold
values divide distribution function fi + 1 segments mass (when
y0i = 0, yi +1 = 1), i.e., every bid j, Fi (yj+1 ) Fi (yj ) = i1+1 .


Let X = { ni=1 } {v0 }, |X| = k 1, union threshold values (we add
arbitrary threshold values size X smaller k 1). Let x = (0, x1 , ..., xk1 , 1)
threshold-value vector created ordering threshold values X smallest
largest. Now, consider n-bidder mechanism P Gk (e
t) e
= (x, .., x). threshold
strategy based x dominant bidders, ex-post IR. construction
18
sets 1 , ..., n , every bidder bid particular bid w.p. 2n
k .
Next, bound welfare loss. divide possible cases according
number bidders bid highest bid. Since bidders use threshold
strategy, one bidder bids highest bid, welfare loss incurred (he definitely
highest valuation). 1 bidder bid highest bid i, expected welfare
loss exceed xi+1 xi . set bidders N , denote probability
bidders bid P r(T = i), probability bidders
bids smaller P r(N \ < i). Thus, expected welfare loss smaller (when
2n < k):
n
X

X

k
X

P r(T = i)P r(N \ < i) (xi+1 xi )

j=2 N, |T |=j i=1



n
X

X

k
X

P r(T = i) (xi+1 xi )

j=2 N, |T |=j i=1



(nj) k j
n X
X
X 2n
j=2

1

i=1

k

(xi+1 xi )

=


n
X
n
2n j
j=2

j

k

<

2n 4n2

1
k2

valuations bidders smaller v0 , welfare loss (it
easy see assume, w.l.o.g., x1 = v0 ). Note despite coefficient
1
exponential n, consider constant n fixed. Example,
k2
n = 2 similar proof shows welfare loss smaller k82 (when k > 3).
Asymptotic quadratic bounds also given Wilson (1989), studied similar
settings regarding effect discrete priority classes customers. work Wilson
uncertainty supply, paper demand uncertain well.
results illustrations idea deadweight loss second order
18. every bidder i, every bid j, Fi (xj+1 ) Fi (xj )

254

1
kc
bn



2n
k

fiAuctions Severely Bounded Communication

price distortion. (The price distortion model maximum difference
prices different bidders facing item given others bids,
bounded k1 .) Indeed, small price distortion ensures probability
inefficient allocation small inefficiency small occur.
Theorem 5.1 related proposition 4 paper Nisan Segal (2006). Nisan
Segal showed discretizing exactly efficient continuous protocol communicating
real numbers yields truly polynomial approximation scheme proportional
(i.e., > 0 realize approximation factor 1 using number
bits polynomial log(1 ) ). Here, discretize continuous efficient auction
(e.g., first-price auction), number bidders. Discretization achieves
approximation error exponential (minus) number bits sent per bidder, i.e.,
asymptotically proportional k1 . However, care average-case approximation
even closer, worst-case approximation within error ensures
average case approximation within 2 (the probability error made
order ).
show asymptotic upper bound tight, i.e., distribution
functions (and particular, uniform distribution) minimal welfare loss exactly
proportional k12 . show constant number bidders.
Theorem 5.2. Assume bidders valuations uniformly distributed v0 =
0. Then, efficient 2-bidder mechanism P Gk (x, y) described Corollary 3.6 incurs
1
welfare loss exactly 6(2k1)
2 . Moreover, (fixed) number bidders n
v0 , exists positive constant c mechanism g Gn,k incurs welfare
loss c k12 .
Proof. first prove first part theorem, regarding 2-bidder mechanisms. Note
given mechanism make non-optimal allocation combinations bids
diagonal lower secondary diagonal matrix representation
2-bidder game (i.e., bA = bB bA = bB + 1). bids (i, j),
1
overlapping segment [xi , xi+1 ] [yj , yj+1 ] size 2k1
. Given vector bids
(i, j), one valuations overlapping segment, allocation optimal
(note allocate item B main diagonal, secondary
1
diagonal). probability valuation overlapping range (2k1)
2.
expected valuation priority game (when valuation overlapping
segment) exactly middle segment. expected valuation optimal
auction (with unbounded communications), restricted overlapping interval,
1
23 point range. Thus, welfare loss 16 segment, i.e., 61 2k1
. Thus,
every vector bids main diagonal secondary-diagonal expected
1
welfare loss 61 (2k1)
3 . (2k 1) vector bids, thus total welfare loss
exactly

1
.
6(2k1)2

similar argument shows even sellers valuation v0 non zero, welfare
1
loss asymptotically greater (2k1)
2 : let z1 , ..., zm sizes overlapping
segments (only valuations bidders greater v0 ). Clearly, 2k1
255

fiBlumrosen, Nisan & Segal



Pm

i=1 zi

1. Then, welfare loss game least

(1 v0 )2


X
i=1

zi2

19 :


zi
(1 v0 )2 X 3 (1 v0 )2 2k 1
(1 v0 )2
1
=

zi

3
6
6
6
(2k 1)
6
(2k 1)2
i=1

proof second statement easily derived: Consider case bidders
1 2 valuations 12 , rest bidders valuations 12 .
occurs constant probability 21n . best mechanism always
allocate item one 1 2. due first part theorem, 2-bidder
mechanism welfare loss proportional k12 incurred (the fact valuation
range [ 12 , 1] [0, 1] changes constant c). hold opportunity
cost v0 seller. Thus, mechanism incur welfare loss ( k12 ).
Note asymptotic results hold even restrict attention symmetric
mechanisms. Actually, prove upper bound Theorem 5.1 constructing symmetric mechanism (we allocate item bidders bid highest bid
equal probabilities). However, asymmetric mechanisms incur strictly smaller welfare
loss symmetric mechanisms. example, valuations distributed uni1
formly, optimal welfare loss 6(2k1)
2 (by Theorem 5.2) compared optimal

welfare loss 6k12 attained symmetric mechanisms20 (i.e., welfare loss asymmetric
mechanisms 4 times better). observation interesting light results
Harstad Rothkopf (1994) Wilson (1989). Harstad Rothkopf studied symmetric
English auctions, analyzed optimal price-jumps auctions. results show
non-anonymous prices (i.e., different jumps bidder) achieve better results
symmetric (or anonymous) jumps. also characterize optimal price-jumps
auctions (mutually centered threshold values). Wilson also studied symmetric
priority classes model, also gives convergence rate n12 efficiency loss
(where n number priority classes). show asymmetric mechanisms
incur smaller efficiency loss, although asymptotic convergence rate same.
One obvious drawback characterization optimal mechanisms
design detail-free (as Wilsons doctrine) must know priors
bidders designing mechanisms. design mechanism regardless
distribution functions, always incur low welfare loss? answer
can, efficient commonly-known priors case. observe
simple, symmetric mechanism use equally spaced thresholds (i.e., P Gk (x, ..., x),
1
x = (0, k1 , k2 , ..., k1
k , 1) ), incurs welfare loss greater k possible distribution
functions. hard verify actually best done
detail-free mechanism: mechanism exist distribution functions
expected welfare loss least order k1 . severely low communication,
difference detail-free mechanisms prior-aware mechanisms (with loss
19.
use fact z = (z1 , ..., zm ) mth dimensional simplex,
Pmthe 3left inequality
1
i=1 zi m2 .
20. easy show efficient symmetric mechanisms similar priority games, except item
allocated equal probabilities cases ties. thresholds bidders simply divide
valuations range identical segments. Then, straightforward show welfare loss
exactly 6k12 .

256

fiAuctions Severely Bounded Communication

O( k12 ) ) may substantial. Note without communication constraints, socially-efficient
results achieved detail-free mechanisms second-price (Vickrey) auctions.
5.2 Asymptotic Bounds Profit Loss
done Theorem 3.8, profit optimization problem reduced welfareoptimization problem maximizing expected virtual surplus.
Proposition 5.3. Assume bidders valuations distributed regular distribution functions. Then, number bidders n, exist set mechanisms gk Gn,k
(k = 2n + 1, 2n + 2, ...) incur profit loss O( k12 ). profit loss compared
optimal, individually-rational mechanism unconstrained communication.
Proof. Consider model bidders consider virtual valuations vei (vi )
valuations. range valuations model, take union ranges
bidders virtual valuations. Denote range [, ]. Let ge Gn,k
mechanism achieves maximal welfare model. Due Theorem 5.1, ge incurs
welfare loss smaller c k12 , positive constant c (the constant takes
account size virtual valuations range ). Let g mechanism
allocation ge, payment qei bidder ge replaced qi = vei 1 (qei )
g, i.e., qei = vei (qi ). Since vei non-decreasing (by regularity), allocation
rules g ge identical every bids combination. Thus, g achieves maximal
expected virtual surplus, loss expected virtual surplus smaller c k12 .
proposition follows.
Again, upper bound asymptotically tight: uniform distribution,
mechanism incurs profit loss ( k12 ). result derived Theorem 5.2 using
similar arguments Proposition 5.3.
Proposition 5.4. Assume bidders valuations distributed uniformly. Then,
(fixed) number bidders n, exists positive constant c mechanism
g Gn,k incurs profit loss c k12 .
far, assumed bidders valuations drawn statistically independent distributions. point relaxation general joint distributions
non-interesting model. Specifically, show trivial priority game
bidders use threshold strategy based vector x = (0, k1 , k2 , ..., k1
k , 1)
always incurs expected welfare loss smaller k1 , mechanism asymptotically better. words, exists joint distribution function
mechanism incurs welfare loss proportional k1 .
5.3 Asymptotic Bounds Growing Number Bidders
subsection, fix size communication allowed (to two possible bids),
show asymptotic bounds function number bidders rather amount
communication. Unfortunately, able prove bounds
uniform distribution.
257

fiBlumrosen, Nisan & Segal

restrict attention symmetric mechanisms, solution simple. Using
1
threshold x = n n1 (for bidders) achieves maximal expected welfare,
21
exact formula showing optimal welfare loss O( logn
n ).
show optimal asymmetric mechanisms incur asymptotically smaller welfare
profit losses O( n1 ). mechanisms fully discriminate agents.


Theorem 5.5. Consider mechanisms P G2 (
x ) P G2 (
) described Corollary
4.3 (in Section 4.1). bidders valuations distributed uniformly, welfare


loss P G2 (
x ) profit loss P G2 (
) smaller n9 .
Proof. Let x revenue-optimizing thresholds Corollary 4.3. bound
welfare loss P G2 (x), efficient mechanism incur even smaller loss. assume,
w.l.o.g., g, bidders indexed according priorities (i.e., 1 2... n ).
bidder wins bidding 1, maximal welfare loss 1 xi . bidders
bid 0, use trivial upper bound 1 welfare loss . Therefore, bound
welfare loss with:


n
n
n
X




xj (1 xi ) (1 xi ) +
xi
(9)
i=1

j=i+1

i=1

following two claims easily verified induction:
Claim 5.6. n

1 xn

Claim 5.7. n15

xn

2
n
2n3
2n

Now, prove induction n first summand Equation 9 n8 . Denote
first term wln . Note wln+1 = (1 xn+1 )2 + xn+1 wln . Assuming wln n8 ,
8
using two claims above, easy prove wln+1 n+1
n > 14. (the
reader verify also holds n 14.)
Next, prove (again induction n) second expression smaller n1 .
Q
Q
1
assume ni=1 xi n1 prove n+1
i=1 xi n+1 (using Claim 5.7 ) :
n+1

i=1

xi = xn+1

n


xi xn+1

i=1

2n 1 1
2n 1 1
1
1
1

<
+
=
n
2n + 2 n
2n + 2 n 2n(n + 1)
n+1

Thus, expected welfare loss smaller n8 + n1 = n9
statement profit loss derived result welfare
loss (again, reducing profit optimization welfare optimization). Nevertheless, direct
proof easy given claims: thresholds x above, profit
21. expected welfare given by: xn

x
2

+ (1 xn )

1+x
.
2
n
12
n+1

maximum
achieved

(first order
1
n
1 n n1 ( n1 1) ( n+1

1

maximal welfare unbounded communication). easy see 1 n1 n converges logn n
1
log n
welfare loss also converges logn n . indeed, 1 n1 n = 1e n logn n (since 1ex x
small xs).
conditions) with: x = n

1
n1

. welfare loss thus:

258

fiAuctions Severely Bounded Communication

B


0
1

0

1

A, 0
A, 13

B, 14
B, 34

Figure 3: (h1 ) sequential game (when bids first) attains higher expected welfare
simultaneous mechanism communication requirement (2 bits).
outcome achieved Bayesian-Nash equilibrium.

loss bounded
smaller

Pn Qn
i=1


x
j=i+1 j (1 xi ) (1 xi ) proved

8 22
n.

6. Sequential Auctions
sequential mechanisms, bidders split bids smaller messages send
alternating order. section, show sequential mechanisms achieve
better results. However, additional gain (in amount communication)
linear factor number bidders.
sequential mechanism mechanism bidder may send several separate
messages, order (not necessarily round-robin fashion). stage,
bidder knows messages bidders sent far. messages
sent, mechanism determines allocation payments. study general
framework auctioneer adaptively determine order messages
sizes according message history. auctioneer also use randomization
decisions. measure communication volume mechanism number
bits actually transmitted.
Definition 16. communication requirement mechanism maximal amount
bits may transmitted bidders mechanism.
strategy bidder sequential mechanism threshold strategy stage
game bidder determines message sends comparing valuation
threshold values x1 , ...xi (where bidder + 1 possible bids stage i).
Example 2. following sequential mechanism communication requirement 2
(see Figure 3 ): Alice sends one bit mechanism first. Bob, knowing Alices bid, also
sends one bit. Alice bids 0: Bob wins bids 1 pays 14 ; bids zero Alice
wins pays zero. Alice bids 1: Bob also wins bids 1, pays 34 ;
bids zero, Alice wins again, pays 13 .
easy see mechanism Bayesian-Nash equilibrium23 achieves
expected welfare 0.653. saw efficient simultaneous mechanism

22. priority games based thresholds
, bidder wins item, pays yi . Thus, maximal
profit loss bidder wins 1 yi .
23. following strategies Bayesian-Nash equilibrium: Alice uses threshold 12 , Bob uses
threshold 41 Alice bids 0 34 Alice bids 1.

259

fiBlumrosen, Nisan & Segal

communication requirement 2 bits 0.648 (see Section 1). conclude sequential
mechanisms gain efficiency simultaneous mechanisms.
Note throughout paper searched optimal mechanisms among
mechanisms Bayesian-Nash equilibria, managed implement optimum
dominant strategy. sequential mechanisms less likely find dominant-strategy
implementations, thus example uses Bayesian-Nash implementation. result below, however, assume particular equilibrium concept sequential
mechanisms.
significant extra gain sequential mechanisms simultaneous mechanisms? following theorem states every sequential mechanism communication
requirement exists simultaneous mechanism achieves least
welfare communication requirement nm (where n number bidders)24 .
Note general (e.g., Kushilevitz & Nisan, 1997), multi-round protocols reduce
communication exponential factor. observe gain sequential
mechanism actually even smaller. many environments, messages sent centralized authority (auctioneer); therefore, extra bits communication required
inform bidders previous messages bidders. following theorem
holds order transmission size sub-messages, even values
adaptively determined according previous messages.
goal section show gain sequential auctions, compared
simultaneous auctions, mild. offer comprehensive analysis case,
present welfare-maximizing revenue-maximizing auctions. Several recent papers
studied different aspects sequential auctions similar constraints. Sandholm
Gilpin (2006) analyzed sequential auctions designed sequences take-it-or-leave-it offers.
paper Kress Boutilier (2004) studied sequential single-item auctions discrete
price increment, information used subsequent stages. work Parkes
(2006) studied information elicitation simultaneous sequential auctions
values uncertain.
First, observe assume welfare-maximizing strategies
bidders threshold strategies. Again, show message chosen bidder
i, welfare linear function vi . show use backward-induction
argument: last message, bidders clearly use thresholds. Therefore, previous
stages welfare (as function vi fixing strategies bidders) linear
combination linear functions linear function. maximum linear
function piecewise linear function thresholds crossing points.
Theorem 6.1. Let h n-bidder sequential mechanism communication requirement m. Then, exists simultaneous mechanism g achieves, dominant
strategies, least expected welfare h, communication requirement smaller
nm.
Proof. Consider n-bidder mechanism h Bayesian-Nash equilibrium,
communication requirement (for simplicity, assume n divides m, i.e., bidder sends
24. Note sequential mechanisms bidders must informed bits bidders sent
(we take account analysis), total gain communication mild.

260

fiAuctions Severely Bounded Communication


n

bits). exists profile = (s1 , ..., sn ) threshold strategies achieves
optimal welfare h. First, give upper bound total number thresholds
bidder uses game. bidder i, let 1i , ..., ki (positive) sizes ki
messages sends h. Let ji (1 j ki ) number bits sent
bidders (including i), bidder sends jth message. choosing message

size ji , bidder uses 2j 1 thresholds. stage, every bidder use
different set thresholds, every
history game. Thus, sending jth
possible

ji
j
message use 2
2 1 different thresholds. Summing up, bidder uses

Pki
(i) = j=1 2 j 2 j 1 thresholds. Now, assume, w.l.o.g., bidders
numbered according order send last messages (i.e., k11 > k22 > ... > knn ).
Recall total number
of1bits sent
bidders m. sending last message,
m1k
k
1
1
bidder 1 thus uses 2
2
1 < 2m different thresholds. Since messages
2

m12k

2
non-zero size, bidder 2 2
2 k2 1 < 2m1 different thresholds
last stage. Similarly, every bidder use 2mi+1 thresholds last
message. therefore, before-last message bidder uses 2mi1 different
thresholds (the worst case occurs one bidder sends one bit bidder 2 last
messages). follows maximal number different thresholds bidder is:
(i) =

ki
X




2j 2j 1

2mi+1 + 2mi1 +

<




2j 2j 1

j=1

j=1

< 2mi+1 + 2mi1 +

kX
2

mi2
X

2j

<

2mi+1 + 2mi1 + 2mi1

<

2mi+2

j=1

Now, let g simultaneous mechanisms bidder simply informs
mechanism thresholds uses h valuation lies. Clearly, every
set valuations bidders, allocation g h identical. Due inequality
above, + 2 bits suffice bidder express P
number. conclude
number bits sent bidders g smaller than: ni=1 (m + 2) = nm n(n3)
.
2
Finally, mention set allocation scheme payment scheme
g threshold-strategies based thresholds equilibrium
expected welfare decrease. shown Section 3, turn mechanism
monotone allocating item deterministically bidder highest expected
value, combination bids. dominant-strategy equilibrium follows.
analysis holds order sizes bidder messages, even
depend history messages, since counting number thresholds still
done way.

7. Future Work
paper concerns single-item auctions severely limited ability elicit
information bidders: possible bids available player although
player may continuum types. give comprehensive analysis
261

fiBlumrosen, Nisan & Segal

auctions, present welfare- revenue-maximizing mechanisms restrictions.
asymptotically analyze losses optimal mechanisms compared auctions
unrestricted communication, also compare auctions bidders
messages sent sequentially.
leave several questions open. obvious problem exact characterization
optimal mechanisms arbitrary number players arbitrary number
possible bids. paper fully characterized optimal 2-bidder k-bid auctions
optimal n-bidder 2-bid auctions, presented asymptotically optimal results
general case n players k bids. Also, future work may provide asymptotic analysis
welfare- revenue loss function k n (we provided separate
asymptotic analysis variables).
additional interesting question regarding gain allocating bits communication non-uniformly among agents. simple domains (like 2-bidder simultaneous auctions) uniform distribution communication seems best option,
would unclear, probably untrue, general settings. addition, seems
concepts methods presented work extend general frameworks,
like general single-parameter mechanism-design settings mechanism design interdependent values (some extensions given recent work Blumrosen & Feldman,
2006).
Finally, work presented partial study sequential auctions communication
restrictions. kind auctions captures many reasonable real-life settings, seems
analytically challenging. present characterization optimal sequential mechanisms paper, direct comparison simultaneous sequential
mechanisms communication requirement. Future work may also compare
prior-aware sequential mechanisms detail-free sequential mechanisms (a similar comparison simultaneous mechanisms showed detail-free mechanism achieve
trivial results). Another possible extension would take integrated approach
study settings partially-known priors.
Acknowledgment. thank Ron Lavi, Daniel Lehmann, Ahuva Mualem Motty
Perry helpful discussions. also thank several anonymous referees valuable remarks, suggestions insights. first two authors supported grants
Israeli Academy Sciences. third author supported National Science
Foundation.

Appendix A. Missing proofs
section present formal proofs results given body
paper.

262

fiAuctions Severely Bounded Communication

A.1 Optimality Threshold Strategies
Proof Claim 3.2 Theorem 3.1:
Proof. Given vector strategies achieve optimal welfare g (i.e.,
maxsek k w(g, se) ), show every player modify si threshold
i=1

strategy, welfare decrease.
Assume si threshold strategy. Therefore, must , , [a, b], < <
si () = si () = si () 6= (where bid player i).
show strategy vector identical , except every si () = m,
w(g, s) w(g, ).
Denote probability players except bids bi P r(bi ). Thus, expected
welfare game g given bidder valuation vi bids
players use strategies si is:


X
X

P r(bi ) ai (m, bi ) vi +
aj (m, bi ) E(vj sj (vj ) = bj )
bi

j6=i

Note expected welfare linear function vi , denote h(m) vi +
t(m) (the constants h(m) t(m) depend bid m).
know achieve optimal welfare g si () = m. Therefore,
bid l si () = l, expected welfare increase, i.e.:
l 6=

h(m) + t(m) h(l) + t(l)

(10)

h(m) + t(m) h(l) + t(l)

(11)

Similarly, si () = m:
l 6=

convex combination , due Equations 10 11:
l 6= h(m) + t(m) h(l) + t(l)
Thus, expected welfare player i, given vi = , maximal bids m. Therefore, modifying si si () = total expected welfare decrease.
repeat process si becomes threshold strategy.25
A.2 Optimal Mechanisms Use Possible Bids
opt
opt
Lemma A.1. w2,(k,k)
> w2,(k1,k)
every k > 1.

Proof. Let g G2,(k1,k) deterministic, monotone mechanism achieves optimal
welfare threshold strategies based vectors (x, y). row g form
[A, ..., A, B, ..., B], let li {0, ..., k} first index row B wins.
modify g ge G2,(k,k) adding missing row, change threshold strategy x
x
e <k+1 , welfare strictly improves. assume, w.l.o.g., thresholds
unique (i.e., 0 < x1 < ... < xk1 < 1, 0 < y1 < ... < 1).
25. See analysis similar problems, e.g., Athey (2001).

263

fiBlumrosen, Nisan & Segal

Case 1. row [B, ..., B] games matrix.
0

E

(v |0v )

0

Let x1 = vB B 2 B 1 , let x
e = (0, x1 , x1 , x2 , ..., xk2 , 1). create new
game ge adding line [B, ..., B] first line. easy see allocation
0
g ge identical rows except new one. vA [0, x1 ] vB [0, y1 ]
ge allocates item B g allocated item A. distribution functions
0
always positive, hence occur positive probability. Since E(vA |vA [0, x1 ]) <
0
x1 < EvB (vB |0 vB y1 ), expected welfare strictly increased. higher bids
bidder B, allocation first row clearly efficient now, therefore welfare
loss incurred.
Case 2. row [B, ..., B] appear gs game matrix.
Due monotonicity, g must two rows + 1 two columns j j + 1
allocate item B bids (i, j), (i, j + 1)
bids (i + 1, j), (i + 1, j + 1). create mechanism ge adding row i0 identical
row + 1 except B wins index j + 1. new threshold constructed follows:
E(vB |yj vB yj+1 ) < xi+1 :
0
0
Let xi+1 = E(vB |yj vB yj+1 ), let x
e = (0, x1 , ..., xi , xi , xi+1 , ..., 1). previous
cases, welfare entries hasnt changed, except strictly positive improvement
(i0 , j) entry.
E(vB |yj vB yj+1 ) xi+1 :
0
0
Let xi = E(vB |yj+1 vB yj+2 ) let x
e = (0, x1 , ..., xi , xi , xi+1 , ..., 1). show
0
since g efficient xi+1 < xi < xi+2 : First, E(vB |yj+1 vB yj+2 ) > E(vB |yj vB
yj+1 ) xi+1 ; Also, since wins bids (i + 1, j + 1), E(vB |yj+1 vB
yj+2 ) E(vA |xi+1 vA xi+2 ) < xi+2 . follows expected welfare strictly
increased entry (i0 , j + 1), decreased entries.
A.3 Optimal Symmetric 1-bit Mechanisms
Following optimal 1-bit 2-bidder mechanisms assuming independent uniform distribution values. socially-efficient symmetric 1-bit mechanism achieves expected
welfare 0.625 compared 0.648 achieved asymmetric 1-bit mechanism
2/3 achieved unrestricted communication. Similarly, revenue-maximizing
symmetric 1-bit mechanism achieves expected profit 0.385 compared 0.39
1-bit symmetric mechanisms 5/12 = 0.417 unrestricted communication (secondprice auction reserve price).
following mechanism achieves optimal welfare among symmetric 1-bit
mechanisms:
0
1

0
w.p. 12 wins, pays 0
w.p. 12 B wins, pays 0
wins pays 14

1
B wins pays
w.p.
w.p.

1
2
1
2

1
4

wins, pays 12
B wins, pays 12

Proving social efficiency mechanism done following idea: First
note symmetric, efficient mechanism clearly allocate item player
264

fiAuctions Severely Bounded Communication

bids 1 player bids 0, allocate equal probabilities 12
bids equal. threshold strategies (x, y) expected welfare is:


w(x,
y) = x 12 x2 + 12 y2 + x (1 y) (1+y)
+ (1 x) (1+x)
+ (1 x) (1 y)
2
2

1
2



(1+x)
2a

+

1
2



(1+y)
2

Maximum achieved (x, y) = ( 12 , 12 ).
mechanism revenue-maximizing mechanism:
0
1

0
allocation
wins, pays 13

1
B wins pays 13
w.p. 12 wins, pays 13
w.p. 12 B wins, pays 13

idea behind optimality mechanism 1-bit symmetric
mechanisms: profit-maximizing symmetric mechanism player bids 0
bids 1, latter wins pays x. players bid 1, pay x equal
probabilities. easy see ex-post IR assumption, x = x. expected
profit thus: r(x) = x(1 x)x + (1 x)xx + (1 x)(1 x)( 21 x + 12 x). Maximum achieved
(x [0, 1]) x = 13 .

References
Ajtai, M., Megiddo, N., & Waarts, O. (2001). Improved algorithms analysis secretary
problems generalizations. SIAM Journal Discrete Mathematics, 14 (1), 127.
Athey, S. (2001). Single crossing properties existence pure strategy equilibria
games incomplete information. Econometrica, 69 (4), 86189.
Bar-Yossef, Z., Hildrum, K., & Wu, F. (2002). Incentive-compatible online auctions digital goods. 13th Annual ACM-SIAM Symposium Discrete Algorithms (SODA),
pp. 964970.
Bergemann, D., & Pesendorfer, M. (2001). Information structures optimal auctions. Tech.
rep. 2991, C.E.P.R. Discussion Papers.
Blumrosen, L., & Feldman, M. (2006). Implementation bounded action space.
Proceedings 7th ACM conference Electronic commerce, pp. 6271.
Cramton, P., Shoham, Y., & Steinberg, R. (2006). Combinatorial Auctions. MIT Press.
David, E., Rogers, A., Schiff, J., Kraus, S., & Jennings, N. (2005). Optimal design
English auctions discrete bid levels. Sixth ACM Conference Electronic
Commerce, pp. 98107.
Feigenbaum, J., Papadimitriou, C. H., & Shenker, S. (2001). Sharing cost muliticast
transmissions. Journal Computer System Sciences., 63, 2141.
Gilbert, J. P., & Mosteller, F. (1966). Recognizing maximum sequence. Journal
American Statistical Association, 61, 3573.
Goldberg, A. V., Hartline, J. D., & Wright, A. (2001). Competitive auctions digital
goods. Symposium Discrete Algorithms, pp. 735744.
265

fiBlumrosen, Nisan & Segal

Harstad, R. M., & Rothkopf, M. H. (1994). role discrete bid levels oral auctions.
European Journal Operations Research, 4, 572581.
Kress, A., & Boutilier, C. (2004). study limited precision, incremental elicitation
auctions. 3rd international joint conference autonomous agents multiagent systems.
Kushilevitz, E., & Nisan, N. (1997). Communication Complexity. Cambridge University
Press.
Lavi, R., & Nisan, N. (2004). Competitive analysis incentive compatible on-line auctions.
Theoretical Computer Science., 310 (1), 159180.
McAfee, P. (2002). Coarse matching. Econometrica, 70 (5), 20252034.
Mookherjee, D., & Reichelstein, S. (1992). Dominant strategy implementation Bayesian
incentive compatible allocation rules. Journal Economic Theory, 56 (2), 378399.
Myerson, R. B. (1981). Optimal auction design. Mathematics Operations Research, 6 (1),
5873.
Nisan, N., & Segal, I. (2006). communication requirements efficient allocations
supporting prices. Journal Economic Theory, 129 (1), 192224.
Parkes, D. C. (2005). Auction design costly preference elicitation. Annals Mathematics Artificial Intelligence, 44 (3), 269302.
Parkes, D. C. (2006). Iterative combinatorial auctions. Cramton, P., Shoham, Y., &
Steinberg, R. (Eds.), Combinatorial Auctions, chap. 2. MIT Press.
Riley, J. G., & Samuelson, W. F. (1981). Optimal auctions. American Economic Review,
71 (3), 381392.
Roth, A. E., & Ockenfels, A. (2002). Late-minute bidding rules ending secondprice auctions: Evidence eBay Amazon Internet. American Economic
Review, 92 (4), 10931103.
Rothkopf, M. H., Teisberg, T. J., & Kahn, E. P. (1990). Vickrey auctions rare?.
Journal Political Economy, 98 (1), 94109.
Sandholm, T., & Gilpin, A. (2006). Sequences take-it-or-leave-it offers: Near-optimal
auctions without full valuation revelation. Fifth International Joint Conference
Autonomous Agents Multiagent Systems, pp. 11271134.
Segal, I. (2003). Optimal pricing mechanisms unknown demand. American Economic
Review, 93 (3), 509529.
Vickrey, W. (1961). Counterspeculation, auctions competitive sealed tenders. Journal
Finance, 16, 837.
Wilson, R. (1989). Efficient competitive rationing. Econometrica, 57, 140.

266

fiJournal Artificial Intelligence Research 28 (2007) 453-515

Submitted 08/06; published 4/07

Abstract Reasoning Planning Coordination
Bradley J. Clement

BRAD . CLEMENT @ JPL . NASA . GOV

Jet Propulsion Laboratory, Mail Stop: 126-347,
Pasadena, CA 91109 USA

Edmund H. Durfee

DURFEE @ UMICH . EDU

University Michigan, EECS Department,Ann Arbor, MI 48109 USA

Anthony C. Barrett

TONY. BARRETT @ JPL . NASA . GOV

Jet Propulsion Laboratory, Mail Stop: 126-347,
Pasadena, CA 91109 USA

Abstract
judicious use abstraction help planning agents identify key interactions
actions, resolve them, without getting bogged details. However, ignoring wrong
details lead agents building plans work, costly backtracking replanning overlooked interdependencies come light. claim associating systematicallygenerated summary information plans abstract operators ensure plan correctness, even
asynchronously-executed plans must coordinated across multiple agents, still achieving valuable efficiency gains. paper, formally characterize hierarchical plans whose
actions temporal extent, describe principled method deriving summarized state
metric resource information actions. provide sound complete algorithms, along
heuristics, exploit summary information hierarchical refinement planning plan
coordination. analyses experiments show that, clearcut reasonable conditions,
using summary information speed planning much doubly exponentially even plans
involving interacting subproblems.

1. Introduction
Abstraction powerful tool solving large-scale planning scheduling problems. abstracting away less critical details looking large problem, agent find overall solution problem easily. Then, skeleton overall solution place, agent
work additional details solution (Sacerdoti, 1974; Tsuneto, Hendler, & Nau, 1998).
Further, interdependencies fully resolved abstract levels, one agents
flesh sub-pieces abstract solution full details independently (even parallel)
divide-and-conquer approach (Korf, 1987; Lansky, 1990; Knoblock, 1991).
Unfortunately, always obvious best abstract large, complex problems achieve
efficiency improvements. agent solving complicated, many-step planning problem,
example, might able identify details earlier parts critical later
ones tried generate plans schedules seen interdependencies end
arising. Even worse, multiple agents trying plan schedule activities shared
environment, unless lot prior knowledge other, extremely
difficult one agent anticipate aspects planned activities likely affect,
affected by, agents.

c
2007
AI Access Foundation. rights reserved.

fiC LEMENT, URFEE , & BARRETT

paper, describe strategy balances benefits risks abstraction largescale single-agent multi-agent planning problems. approach avoids danger ignoring
important details lead incorrect plans (whose execution fail due overlooked interdependencies) substantial backtracking abstract decisions cannot consistently refined.
Meanwhile, approach still achieves many computational benefits abstraction long
one number reasonable conditions (listed later) holds.
key idea behind strategy annotate abstract operator plan hierarchy
summary information potential needs effects potential refinements. might sound contrary purpose abstraction reducing number
details, fact show strikes good balance. Specifically, possibly
relevant conditions effects modeled, agent agents reasoning abstract
operators absolutely sure important details cannot overlooked. However,
summary information abstracts away details refinement choices conditions
effects manifested, information relative timing conditions needed effects achieved, still often results exponential reduction information
compared flat representation.
Based concept summary information, paper extends prior work summarized
Section 8 make following contributions:
formal model hierarchical plans temporal extent, execution.
many planning systems sophisticated temporal models (e.g., Laborie & Ghallab, 1995; Muscettola, 1994) additionally use hierarchical representations alternative courses action
(Allen, Kautz, Pelavin, & Tenenberg, 1991; Currie & Tate, 1991; Chien, Knight, Stechert, Sherwood, & Rabideau, 2000a; Castillo, Fdez-Olivares, Garca-Perez, & Palao, 2006), know
work extends hierarchical task network (HTN) formalization (Erol, Hendler, & Nau,
1994a; Erol, Nau, & Hendler, 1994b) include temporal extent. need formalism order
clarify semantics summary information concurrently executing agents.
Algorithms deriving summary information propositional metric resource conditions effects, using information determine potential definite interactions abstract tasks. prove summarization techniques guaranteed
correctly capture conditions effects associated abstract operator appropriately, augmented modal information whether conditions must may hold whether
hold entire operation time. summary information
captures conditions effects, algorithms reason operators different levels
abstraction predict often resolve operator interactions without fully detailing task hierarchies,
even operators executing asynchronously different agents.
Sound complete algorithms hierarchical refinement planning centralized plan coordination actions temporal extent, supporting flexible plan execution systems.
agent reduce backtracking planning selectively interleaving refinement plan
predicting resolving potential interdependencies evolving plan plans
asynchronously executed agents. research also found benefit
guiding refinement conditions specified higher levels plan hierarchy guide refinement (Sacerdoti, 1974; Young, Pollack, & Moore, 1994; Tsuneto et al., 1998). show
algorithms improve capabilities exploiting hierarchical structure using summary

454

fiA BSTRACT R EASONING P LANNING C OORDINATION

information efficiently converge coordinated plans, refined
individually parallel participating agents.
ability coordinate abstract levels rather detailed plans allows
agents retain local flexibility refine operators best suits current expected
circumstances without jeopardizing coordination triggering new rounds renegotiation.
way, summary information supports robust execution systems PRS (Georgeff & Lansky,
1986), UMPRS (Lee, Huber, Durfee, & Kenny, 1994), RAPS (Firby, 1989), JAM (Huber, 1999), etc.
interleave refinement abstract plan operators execution.
approach also extends plan coordination (plan merging) techniques (Georgeff, 1983; Lansky, 1990; Ephrati & Rosenschein, 1994) utilizing plan hierarchies expressive temporal model. Prior techniques assume actions atomic, meaning action either executes
before, after, exactly time another. contrast, use interval point algebra (Vilain & Kautz, 1986) represent possibility several actions one agent executing
execution one action another agent. algorithms choose alternative
refinements HTN dynamically midst plan coordination, support interleaved local
planning, multiagent coordination, concurrent execution.
Search techniques heuristics, including choose-fewest-threats-first (CFTF) expandmost-threats-first (EMTF), take advantage summary information prune search
space. interdependencies run deeply agents plans, resolving abstract levels, possible all, lead unacceptable losses parallel activity. Fortunately, even
agents need delve details plans tease interdependencies, summary information still enable exponential speedups guiding decomposition pruning refinement
choices. search efficiency using summary information comes ignoring irrelevant information, distributed planning system also reduces communication overhead exponentially.
Complexity analyses experiments showing potential doubly-exponential speedups refinement local search planning/scheduling using summary information. algorithms
demonstrate exploiting summary information guide hierarchical planning scheduling
achieve exponential speedups, resolving interdependencies abstract levels improve
performance plan coordination algorithms doubly exponentially. others shown
abstraction exponentially reduce search space size (Korf, 1987; Knoblock, 1991) subproblem independence properties hold, show techniques lead exponential improvements
broader conditions hold problem:
solutions found abstract levels;
amount summary information less higher levels lower levels;
choices decompositions lead varying numbers plan threats.
none conditions hold, show generating using summary information
provides benefit increase computation communication overhead. Thus, care must
taken deciding use summary information, though proven extremely worthwhile
types problem domains examined, example next describe.

455

fiC LEMENT, URFEE , & BARRETT

M1

M2

E

transport1

transport2



B

C

tool

bin1

bin2

bin3

bin4

dock

Figure 1: simple example manufacturing domain
produce H
produce G

produce H G

produce G
M2

produce G
M1

move A&B
M2
move M2

move G
M2
build H

move H
bin1

build G

move B M2

Figure 2: production managers hierarchical plan
1.1 Manufacturing Example
running example motivate work, consider manufacturing plant production
manager, facilities manager, inventory manager goals separately
constructed hierarchical plans achieve them. However, still need coordinate use
equipment, availability parts used manufacturing parts, storage parts,
use transports moving parts around. state factory shown Figure 1.
domain, agents produce parts using machines M1 M2, service machines tool,
move parts shipping dock storage bins shop floor using transports.
Initially, machines M1 M2 free use, transports (transport1 transport2),
tool, parts (A E) shown storage locations available.
production manager responsible creating part H using machines M1 M2. Either M1 M2 consume parts B produce G, M2 produce H G.
production managers hierarchical plan manufacturing H involves using transports move
needed parts storage input trays machines, manufacturing G H, transporting H back storage. plan shown Figure 2. Arcs subplan branches mean
subplans must executed. Branches without arcs denote alternative choices achieving
parents goal. decomposition produce G M1 similar produce G M2.
facilities manager services machine equipping tool calibrating it.
machines unavailable production serviced. facilities managers hierarchical plan branches choices servicing machines different orders uses transports

456

fiA BSTRACT R EASONING P LANNING C OORDINATION

maintenance
service M1 M2

service M1

service M2

service M2 M1

move tool
dock

move tool equip M1 tool calibrate M1
M1

Figure 3: facilities managers hierarchical plan
move_parts
move C dock

move D&E

move bin3

move E bin4

Figure 4: inventory managers hierarchical plan
getting tool storage machines (Figure 3). decomposition service M2M1
similar service M1M2.
parts must available space-limited shop floor order agent use them.
Whenever agent moves uses part, becomes unavailable. inventory managers goal
move part C dock move E bins shop floor (shown Figure 4).
accelerate coordination plans, factory manager analyze hierarchical
plan derive summary information abstract plan operator affect world.
information includes summary pre-, post-, in-conditions intuitively correspond
externally required preconditions, externally effective postconditions, internally required
conditions, respectively, plan based potential refinements. Summary conditions augment state conditions modal information whether conditions must may hold
effect. Examples given end Section 3.2.
summary information computed, production inventory managers could
send information top-level plan facilities manager. facilities manager could
reason top-level summary information plans determine
facilities manager serviced machines production manager started producing
parts, production manager finished inventory manager began moving parts
dock, plans executed (refined) way, CanAnyWay.
facilities manager could instruct others add communication actions plans
synchronize actions appropriately.
top-level solution maximizes robustness choices production facilities managers plans preserved, solution inefficient concurrent
activityonly one manager executing plan time. production manager might
want wait facilities manager finish maintenance could negotiate solution
concurrency. case, facilities manager could determine could overlap

457

fiC LEMENT, URFEE , & BARRETT

plans way without risking conflict (CanAnyWay). However, summary information
could tell might way overlap plans (MightSomeWay), suggesting
search solution concurrency (at cost perhaps committing specific
refinement choices) hope success. case, facilities manager could request production manager summary information produce Hs subplans, reason
interactions lower level actions way, find way synchronize subplans
fine-grained solution plans executed concurrently. give algorithm
finding solutions Section 5.
1.2 Overview
first formally define model concurrent hierarchical plan, execution, interactions
(Section 2). Next, describe summary information propositional states metric resources,
mechanisms determining whether particular interactions must may hold based information, algorithms deriving information (Section 3). Built upon algorithms others
using summary information determine whether set CHiPs must might execute successfully set ordering constraints (Section 4). turn used within sound
complete multilevel planning/coordination algorithm employs search techniques heuristics
efficiently navigate prune search space refinement (Section 5). show
planning, scheduling, coordinating abstract levels exponentially improve performance
search execution (Section 6). provide experimental results demonstrating search
techniques also greatly reduce search optimal solutions (Section 7). Finally, Section 8
differentiate approach related work mention elsewhere conclude.

2. Model Hierarchical Plans Concurrent Execution
representation temporal extent HTN important modeling concurrently
executing agents also performing abstract reasoning summary information. agent
scheduling abstract actions sequentially order them, severely restricted
kinds solutions find. example, agent may prefer solutions shorter
makespans, seek plans subthreads carried concurrently.
section define concurrent hierarchical plans (CHiPs), state changes time
based executions, concepts success failure executions possible world,
history. later define summary information abstract plan interactions terms
definitions semantics given section, treatment fairly detailed (though
even comprehensive treatment, see Clement, 2002). However, begin summarizing
main concepts notation introduced, give reader basic gist.
2.1 Overview
CHiP (or plan p) mainly differentiated HTN including definition inconditions,
in(p), (sometimes called conditions) affect (or assert condition on) state
start time p (ts (p)) must hold throughout duration p. Preconditions (pre(p)) must
hold start, postconditions (post(p)) asserted finish time p (t f (p)). Metric
resource (res) consumption (usage(p, res)) instantaneous start time and, resource
defined non-consumable, instantaneously restored end. decompositions p (d(p))

458

fiA BSTRACT R EASONING P LANNING C OORDINATION

style and/or tree, either partial ordering (order(p)) choice child tasks
conditions.
execution e p instantiation start time, end time, decomposition. is,
execution nails exactly done when. order reason plan interactions,
quantify possible histories, history corresponds combination possible
executions concurrently-executing CHiPs partial ordering activities
context initial state. run (r(h,t)) specifies state time history h.
Achieve, clobber, undo interactions defined terms executions
plans assert positive literal ` negative literal ` relative ` required another plans
execution history. looking literals achieved, clobbered, undone set
executions history, identify conditions must hold prior executions
history external preconditions must hold executions history
external postconditions.
value metric resource time (r(res, h,t)) calculated subtracting prior
state value usage plans start executing (if non-consumable) adding back usages
end t. execution e p fails condition required asserted time
state r(h,t) t, value resource (r(res, h,t)) used plan
limits execution.
remainder section, give careful, detailed descriptions concepts
above, ground definitions firm semantics; casual reader skim
details desired. also important note that, rather starting scratch, formalization
weaves together, necessary augments, appropriate aspects theories, including
Allens temporal plans (1983), Georgeffs theory multiagent plans (1984), Fagin et al.s
theory multiagent reasoning knowledge (1995).
2.2

CH P

concurrent hierarchical plan p tuple hpre, in, post, usage, type, subplans, orderi. pre(p),
in(p), post(p) sets literals (v v propositional variable v) representing
preconditions, inconditions, postconditions defined plan p.1
borrow existing model metric resources (Chien, Rabideu, Knight, Sherwood, Engelhardt, Mutz, Estlin, Smith, Fisher, Barrett, Stebbins, & Tran, 2000b; Laborie & Ghallab, 1995).
plans usage function mapping resource variables amount used. write
usage(p, res) indicate amount p uses resource res sometimes treat usage(p) set
pairs (res, amount). metric resource res tuple hmin value, max value, typei. min
max values integer real values representing bounds capacity amount available. type resource either consumable non-consumable. example, fuel
battery energy consumable resources because, use, depleted amount.
non-consumable resource available use (e.g. vehicles, computers, power).
Domain modelers typically specify state conditions resource usage primitive actions hierarchy. Thus, conditions usage CHiP used derive summary conditions,
describe Section 3.4, algorithms reason action hierarchy.
order reason plan hierarchies and/or trees actions, type plan p, type(p),
1. Functions pre(p) used referential convenience throughout paper. Here, pre pre(p)
same, pre(p) read preconditions p.

459

fiC LEMENT, URFEE , & BARRETT

given value either primitive, and, or. plan non-primitive plan accomplished carrying subplans. plan non-primitive plan accomplished
carrying exactly one subplans. So, subplans set plans, primitive plans
subplans empty set. order(p) defined plan p consistent set
temporal relations (Allen, 1983) pairs subplans. Plans left unordered respect
interpreted potentially execute concurrently.
decomposition CHiP style HTN described Erol et al.
(1994a). plan task network, plan extra construct representing set
methods accomplish goal compound task. network tasks corresponds
subplans plan.
example Figure 2, production managers highest level plan produce H (Figure 2)
tuple
h{}, {}, {}, {}, and, {produce G, produce H f rom G}, {be f ore(0, 1)}i.
f ore(0,1), 0 1 indices subplans decomposition referring produce G
produce H f rom G respectively. conditions defined produce H rely
conditions defined primitive plans refinement. plan moving part
bin1 first input tray M1 using transport1 tuple
h{}, {}, {}, {}, and, {start move, f inish move}, {meets(0, 1)}i.
plan decomposes two half moves help capture important intermediate effects.
parent orders children meets relation bind together single move.
start move plan
h{at(A, bin1), available(A), f ree(transport1), f ull(M1 tray1)},
{at(A, bin1), available(A), f ull(bin1), f ull(M1 tray1), f ree(transport1)},
{at(A, bin1), available(A), f ree(transport1), f ull(bin1), f ull(M1 tray1)},
{}, primitive, {}, {}i.
f inish move plan
h{at(A, bin1), available(A), f ree(transport1), f ull(bin1), f ull(M1 tray1)},
{at(A, bin1), available(A), f ree(transport1), f ull(bin1), f ull(M1 tray1)},
{at(A, bin1), at(A, M1 tray1), available(A), f ree(transport1), f ull(bin1), f ull(M1 tray1)},
{}, primitive, {}, {}i.
split move plan two parts order ensure action executes
concurrently one use transport1, part A, input tray M1. would incorrect
instead specify f ree(transport1) incondition single plan another agent could,
instance, use transport1 time f ree(transport1) incondition would agree
f ree(transport1) incondition move action. However, specification still
insufficient since two pairs (start move, f inish move) actions could start end
time without conflict. get around allowing planner reason
move plan parent plans, effect, hiding transition start finish actions.
So, representing transition f ree f ree without knowing transition
460

fiA BSTRACT R EASONING P LANNING C OORDINATION

take place modeler ensures another move plan tries use transport1 concurrently
one cause conflict.2
postcondition required incondition specify whether incondition changes.
clarifies semantics inconditions conditions hold plan execution
whether caused action necessary conditions successful execution.
2.3 Executions
Informally, execution CHiP recursively defined instance decomposition
ordering subplans executions. Intuitively, executing plan, agent chooses plans
start time refined, determining points time conditions must hold,
witnesses finish time. formalism helps us reason outcomes different ways
execute group plans, describe state transitions, define summary information.
execution e CHiP p tuple hd,ts ,t f i. ts (e) f (e) positive, non-zero real numbers
representing start finish times execution e, ts < f . Thus, instantaneous actions
explicitly represented. d(e) set subplan executions representing decomposition plan p
execution e. Specifically, p plan, contains exactly one execution
subplans; plan, contains one execution one subplans;
empty primitive. addition, subplan executions, e0 d, ts (e0 ) f (e0 ) must
consistent relations specified order(p). Also, first subplan(s) start must start
time p, ts (e0 ) = ts (e), last subplan(s) finish must finish time
p, f (e0 ) = f (e). possible executions plan p set E (p) includes possible
instantiations execution p, meaning possible values tuple hd,ts ,t f i, obeying
rules stated.
example Section 1.1, execution production managers top-level plan
produce H would e E (produce H). e might h{e1 , e2 }, 2.0, 9.0 e1
E (produce G), e2 E (produce H f rom G). means execution produce H
begins time 2.0 ends time 9.0.
convenience, subexecutions execution e, subex(e), defined recursively
set subplan executions es decomposition unioned subexecutions.
2.4 Histories Runs
agent reasoning summary information make planning decisions abstract levels needs
first able reason CHiPs. section complete semantics CHiPs
describing affect state time. agent execute plan many different
ways different contexts, need able quantify possible worlds (or histories)
agents fulfill plans different ways. defining history, define run
transformation state time result history executions. formalization
histories runs follows closely Fagin et al. (1995) describing multiagent execution.
state world, s, truth assignment set propositions, representing aspect
environment. refer state set true propositional variables. history,
2. Using universal quantification (Weld, 1994) single plan could agent, agent 6= productionManager
using(transport1, agent) condition would exclude concurrent access transport. could also
simply specified transport1 non-consumable resource maximum capacity one.

461

fiC LEMENT, URFEE , & BARRETT

h, tuple hE, sI i. E set plan executions agents occurring h, sI
initial state h plan begins executing. So, history h hypothetical world begins
sI initial state executions E(h) occur. particular, history
manufacturing domain might initial state shown Figure 1 parts machines
available, transports free. set executions E would contain execution
produce H, maintenance, move parts, subexecutions.
run, r, function mapping history time point states. gives complete description
state world evolves time, time ranges positive real numbers.
Axiom 1
r(h, 0) = sI
Axiom 2
v r(h,t > 0) (v r(h,t )
p, e p E(h), (v in(p) ts (e p ) = ) (v post(p) f (e p ) = t))
(6 p0 , e p0 E(h), (v in(p0 ) ts (e p0 ) = ) (v post(p0 ) f (e p0 ) = t))
Axiom 1 states world initial state time zero. Axiom 2 states predicate
v true time already true beforehand, plan asserts v incondition
postcondition t, (in either case) plan asserts v t. plan starts t, inconditions
asserted right start, +, small positive real number. Axiom 2 also indicates
inconditions postconditions effects.
state resource level value (integer real). consumable resource usage, task
depletes resource modeled instantaneously deplete resource (subtract usage
current state) start task full amount. non-consumable resource usage, task
also depletes usage amount start task, usage restored (added back
resource state) end execution. task replenish resource negative usage.
refer level resource res time history h r(res, h,t). Axioms 3 4
describe calculations consumable non-consumable resources, respectively.
Axiom 3
r(consumable res, h,t) = r(consumable res, h,t ) e p E(h),ts (e p )=t usage(p, consumable res)
Axiom 4
r(nonconsumable res, h,t) =r(nonconsumable res, h,t )
e p E(h),ts (e p )=t usage(p, nonconsumable res)+
e p E(h),t f (e p )=t usage(p, nonconsumable res)
described CHiPs change state, specify conditions
execution succeeds fails. stated formally Definition 1, execution succeeds if:
plans preconditions met start; postconditions met end; inconditions
met throughout duration (not including start end); used resources stay within
value limits throughout duration; executions decomposition succeed. Otherwise,
execution fails.
462

fiA BSTRACT R EASONING P LANNING C OORDINATION

Definition 1
succeeds(e p , h) pre(p) r(h,ts (e p ))
post(p) r(h,t f (e p ))
t, res,ts (e p ) < < f (e p ) usage(p, res) 6= 0
in(p) r(h,t)
min value(res) <= r(res, h,t) <= max value(res)
e d(e p ), succeeds(e, h)
2.5 Asserting, Clobbering, Achieving, Undoing
Conventional planning literature often speaks clobbering achieving preconditions plans
(Weld, 1994). CHiPs, notions slightly different since inconditions clobber
clobbered, seen previous section. Formalizing concepts another, undoing
postconditions, helps us define summary conditions (in Section 3.2). However, convenient
define first means assert condition. Figure 5 gives examples executions involved
interactions, define terms follows:
Definition 2
asserts(e p , `,t, h) (e p E(h))
(` in(p) = ts (e p ) +
` post(p) = f (e p ))
(r(t, h) ` `)
Definition 2 states execution e p history h asserts literal time literal
effect p holds state t. Note point on, beginning Definition 3,
use brackets [ ] shorthand defining similar terms procedures. example, saying [a,
b] implies [c, d] means implies c, b implies d. shorthand help us avoid repetition,
cost slightly difficult parsing.
Definition 3
[achieves, clobbers] precondition(e p , `, e p0 ,t, h)
e p , e p0 E(h)
asserts(e p , [`, `],t, h) ` pre(p0 ) < ts (e p0 )
6 e p00 ,t 00 , (asserts(e p00 , `,t 00 , h) asserts(e p00 , `,t 00 , h)) < 00 ts (e p0 )
Definition 4
clobbers [in, post]condition(e p , `, e p0 ,t, h)
e p , e p0 E(h)
asserts(e p , `,t, h) ` [in(p0 ), post(p0 )] [ts (e p0 ) < < ts (e p0 ),t = f (e p0 )]
Definition 5
undoes(e p , `, e p0 ,t, h)
e p , e p0 E(h)
asserts(e p , `,t, h) ` post(p0 ) f (e p0 ) >
6 e p00 ,t 00 , (asserts(e p00 , `,t 00 , h) asserts(e p00 , `,t 00 , h)) f (e p0 ) 00 <
463

fiC LEMENT, URFEE , & BARRETT

Figure 5: Interval interactions plan steps
So, execution achieves clobbers precondition last (or one last) assert
condition negation (respectively) required. Likewise, execution undoes
postcondition first (or one first) assert negation condition
condition asserted. execution e clobbers incondition postcondition e0 e asserts
negation condition end (respectively) e0 . Achieving effects (inconditions
postconditions) make sense formalism, defined. Figure 5 shows
different ways execution e achieves, clobbers, undoes execution e0 . ` ` point
asserted required met.
2.6 External Conditions
recognized Tsuneto et al. (1998), external conditions important reasoning potential refinements abstract plans. Although basic idea same, define little
differently call external preconditions differentiate conditions
call external postconditions. Intuitively, external precondition group partially ordered
plans precondition one plans achieved another group must
met external group. External postconditions, similarly, undone
plans group net effects group. Definition 6 states ` external [pre,
post]condition execution e p ` [pre, post]condition subplan
[achieved, undone] subplan.
Definition 6
external [pre, post]condition(`, e p )
h, E(h) = {e p } subex(e p )
(e p0 E(h), ` [pre(p0 ), post(p0 )]
6 e p00 E(h),t,[achieves pre, undoes post]condition(e p00 , `, e p0 ,t, h))

464

fiA BSTRACT R EASONING P LANNING C OORDINATION

example Figure 2, available(G) external precondition because, although G
must exist produce H, G supplied execution produce G plan. Thus, available(G)
met internally, making available(G) internal condition. available(M1) external precondition, internal condition, external postcondition needed externally
internally; effect produce G M1 releases M1 finished;
plan decomposition undoes effect.

3. Plan Summary Information
Summary information used find abstract solutions guaranteed succeed matter
refined information describes potential conditions underlying
decomposition. Thus, commitments particular plan choices, whether single agent
agents, made based summary information without worrying deeper details
lurk beneath doom commitments. HTN planners used abstract conditions
guide search (e.g., Sacerdoti, 1974; Tsuneto et al., 1998), rely user-defined subset
constraints help detect potential conflicts. contrast, summary information
used identify potential conflicts.
formalisms previous section, define summary information
describe method computing non-primitive plans (in Section 3.4).
many detailed definitions algorithms section, follow structure
previous section, first give informal overview key concepts notation,
subsequently delve systematically.
3.1 Overview
summary information plan p consists summary pre-, in-, postconditions (presum (p),
insum (p), postsum (p)), summary resource usage (usagesum (p, res)) resource res, whether
plan executed way successfully (consistent).
summary condition (whether pre, post, in) specifies positive negated literal,
additional modal information. summary condition associated existence, whose
value either must may depending whether must hold possible decompositions
abstract operator may hold depending decomposition chosen. timing
summary condition either f irst, last, always, sometimes, specifying condition must
hold plans interval execution. plan p1 must [achieve, clobber] summary precondition
c2 p2 execution p1 (or plan summary information) would
[achieve, clobber] condition summarized c2 (or plan summary information
p2 ).
algorithm deriving summary conditions plan p takes input summary conditions immediate subplans p conditions defined CHiP p. pre-, in-,
postconditions p become must first, must always, must last summary conditions, respectively. algorithm retains existence timing subplan summary conditions parent
depending whether conditions achieved, clobbered, undone siblings, whether
decomposition or, whether subplan ordered first last, whether subplans
share condition. Subplan first, always, last conditions become sometimes conditions parent. parent computed consistent long subplans consistent,

465

fiC LEMENT, URFEE , & BARRETT

subplan may clobber summary condition another, summarized resources violate
limits.
represent summary resource usage three value ranges, hlocal min, local max, persisti,
resources local usage occurs within tasks execution, persistent usage represents usage lasts task terminates depletable resources. summarization
algorithm abstract task takes summary resource usages subtasks, considers legal orderings subtasks, possible usages subintervals within interval
abstract task, build multiple usage profiles. profiles combined algorithms
computing parallel, sequential, disjunctive usages give summary usage parent task.
3.2 Summary Conditions
summary information plan p, psum , tuple hpresum , insum , postsum , usagesum , consistenti,
whose members sets summary conditions, summarized resource usage, consistent flag
indicating whether plan execute consistently internally. presum (p) postsum (p) summary pre- postconditions, external pre- postconditions p, respectively.
summary inconditions p, insum (p), contain conditions must hold within execution
p successful. condition c one sets tuple h`, existence,timingi. `(c)
literal c. existence c must may. existence(c) = must, c called
must condition ` must hold every successful plan execution. convenience usually
write must(c). c may condition (may(c) true) `(c) must hold successful execution.
timing summary condition c either always, sometimes, f irst, last. timing(c)
always c insum `(c) incondition must hold throughout potential executions p
(` holds always); otherwise, timing(c) = sometimes meaning `(c) holds one point, least, within
execution p. So, always condition must, define may always inconditions
whether may existence timing, significantly different may
sometimes planner reasons it. Whether condition may always (however defined)
may sometimes, another plan may clobber relationship condition (as
defined Section 3.3). Note also incondition CHiP restricted meaning
must always summary incondition. timing f irst c presum `(c) holds beginning
execution p; otherwise, timing = sometimes. Similarly, timing last c postsum `(c)
asserted end successful execution p; otherwise, sometimes. Although existence
timing syntactically take one value, semantically must(c) may(c), always(c)
sometimes(c).
considered using modal logic operators describe concepts. mix existing
temporal logic dynamic logic (Pratt, 1976) notation could forced work, found
using terminology made definitions much simpler. discuss end
Section 8.
Definitions 7, 8, 9 give formal semantics existence timing representative
condition types. Summary conditions plan defined recursively depend
summary conditions plans immediate subplans instead complete decomposition. single description summary information could represent many different plan hierarchies,
quantify plans p0 , whose subplans summary information
plan p summarized. could defined existence timing properties conditions
based entire hierarchy, so, deriving summary conditions would expensive

466

fiA BSTRACT R EASONING P LANNING C OORDINATION

solving planning problem, one main purposes summary information reduce
computation planning problem. reason would expensive
worst case legal orderings plan steps must explored determine whether condition
must may. discuss example end subsection.
Definition 7
[must, may] f irst precondition(`, p)
p0 = hpre(p), in(p), post(p), {},type(p), subplans(p0 ), order(p)i
summary f ormation f subplans(p0 ) = summary f ormation f subplans(p)
h,e p0 , E(h) = {e p0 } subex(e p0 ) [true, external precondition(`, e p0 )]
e p00 E(h),ts (e p00 ) = ts (e p0 ) ` pre(p00 )

Definition 8
must always incondition(`, p)
p0 = hpre(p), in(p), post(p), {},type(p), subplans(p0 ), order(p)i
summary f ormation f subplans(p0 ) = summary f ormation f subplans(p)
h, e p0 ,E(h) = {e p0 } subex(e p0 ),t,ts (e p0 ) < < f (e p0 )
e p00 E(h),ts (e p00 ) < < f (e p00 ) ` in(p00 )

Definition 9
[must, may] sometimes incondition(`, p)
[, ]p0 = hpre(p), in(p), post(p), {},type(p), subplans(p0 ), order(p)i
summary f ormation f subplans(p0 ) = summary f ormation f subplans(p) [, ]
[, ]h, e p0 ,E(h) = {e p0 } subex(e p0 ), t,ts (e p0 ) < < f (e p0 )[, ]
e p00 E(h), = ts (e p00 ) ` pre(p00 )
ts (e p00 ) < < f (e p00 ) ` in(p00 )
= f (e p00 ) ` post(p00 )
Definition 7 states f irst precondition p external precondition always required beginning execution p0 conditions p
summary information ordering subplans p. last postcondition always asserted
end execution (substitute pre post ts f last two lines Definition 7). [must,may] sometimes precondition [must,may] external precondition
f irst precondition. sometimes postcondition defined similarly. Definition 8 states literal
` must, always incondition plan p time isolated execution p0
summary information p, executing plan p00 incondition `. Definition 9
states [must, may] sometimes incondition plan p condition required [any,
some] execution [any, some] plan p0 summary information ordering
subplans p.
consistent flag boolean indicating whether plan (or plan summary information ordering subplans) would execute successfully matter decomposed matter subplans executed. Definition 10 says possible
467

fiC LEMENT, URFEE , & BARRETT

executions succeed consistent plan. similar CanAnyWay relation
defined Section 4. include whether plan definitely succeed
summary information requires exponential computation see whether conflicts
subplans resolved. computation wait done planning summary
information fully derived.
Definition 10
consistent(p)
p0 = hpre(p), in(p), post(p), usage(p),type(p), subplans(p0 ), order(p)i
summary f ormation f subplans(p0 ) = summary f ormation f subplans(p)
h, e p0 E (p0 ), e p0 succeeds
show subset summary conditions production managers top-level plan (of
Figure 2) below. Following literal modal tags existence timing information. Mu
must; may; F f irst; L last; sometimes; always.
Production managers produce H plan:
Summary preconditions:
available(A)MuF, available(M1)MaS, available(M2)MaS
Summary inconditions:
available(A)MuS, available(M1)MaS, available(M2)MuS, available(G)MuS,
available(A)MuS, available(M1)MaS, available(M2)MuS, available(G)MuS,
available(H)MuS, available(H)MuS
Summary postconditions:
available(A)MuS, available(M1)MaS, available(M2)MuS, available(G)MuS,
available(H)MuL

available(M1) summary precondition may condition production manager
may end using M1 chooses use M2 instead produce G. available(A) f irst summary precondition part must used beginning execution transported
one machines. machines needed sometime parts transported,
sometimes (and first) conditions: needed point time beginning execution.
production manager may use M1 produce G, available(M1) summary
incondition produce H. available(M1) available(M1) inconditions
consistent sometimes conditions, implying hold different times
plans execution. contrast, conditions would conflict must always
(meaning must always hold throughout every possible execution plan).
summary condition available(A) must postcondition top-level plan
definitely consumed make G produced plan decomposition
produce H f rom G. Even though available(G) effect produce G, external
postcondition produce H undone produce H f rom G, consumes G
make H. available(H) last summary postcondition production manager releases
H end execution. available(M2) last manager finishes using M2
moving H storage.
Notice available(M2) may summary precondition. However, matter hierarchy decomposed, M2 must used produce H, available(M2) must established
468

fiA BSTRACT R EASONING P LANNING C OORDINATION

externally production managers plan. summary information defined terms
summary information immediate subplans, subplans produce H, see
produce G available(M2)MaS precondition available(M2)MaS postcondition
would achieve available(M2)MuF precondition produce H f rom G. summary
information tell us precondition produce G exists postcondition
exists, necessary condition determine derived precondition produce H must
condition. Thus, may. augmented summary information subsets conditions
existed together, hunting combinations temporal orderings condition subsets among
subplans derive summary conditions would basically adaptation HTN planning algorithm, summary information intended improve. Instead, derive summary information
polynomial time use improve HTN planning exponentially explain Section 6. tradeoff made beginning section defining summary conditions
terms immediate subplans instead entire hierarchy. Abstraction involves loss
information, loss enables computational gains.
3.3 Summary condition relationships algorithms
order derive summary conditions according definitions, need able recognize
achieve, clobber, undo relationships based summary conditions basic CHiP
conditions. give definitions algorithms these, build constructs algorithms
reasoning temporal relationships, described Appendix A.
Achieving clobbering similar, define together. Definition 11 states
plan p1 must [achieve, clobber] summary precondition c2 p2 executions
two plans, p01 p02 , summary information ordering constraints p1
p2 , execution p01 one subexecutions would [achieve, clobber] external precondition
`(c2 ) p02 .
Definition 11
must [achieve, clobber] precondition(p1 , c2 , p2 , Psum , order)
h H(Psum , order), p01 , p02 , e p01 , e p02 ,
(p01 p02 summary ordering f ormation p1 p2 )
t,e p001 subex(e p01 ), e p002 subex(e p02 ),
[achieve, clobber] precondition(e p001 , `(c2 ), e p002 ,t, h)
external precondition(`(c2 ), e p02 )
Achieving clobbering in- postconditions defined Definition 11 substituting post pre removing last line inconditions. Additionally substituting gives definitions may achieve clobber. Furthermore, definitions
must/may-undo obtained substituting post pre undo achieve Definition 11. Note that, mentioned Section 2.5, achieving inconditions postconditions
make sense formalism.
Algorithms interactions given Figure 6 Figure 7. algorithms build
others (detailed Appendix B) use interval point algebra determine whether plan must
may assert summary condition before, at, time another plan requires summary
condition hold. Similar Definition 3 must-achieve CHiP conditions, Figure 6 says p0
469

fiC LEMENT, URFEE , & BARRETT

Algorithm: Must-[achieve, clobber]
Input: plan p0 , summary condition c plan p, Psum , order
Output: true f alse, whether p0 must-[achieve, clobber] c
begin function
c0 in(p0 ) post(p0 )
`(c0 ) [`(c), `(c)] must(c0 )
c insum (p) p0 must-assert c0 c return [unde f ined, true]
c postsum (p) p0 must-assert c0 c return [unde f ined, true]
c presum (p) p0 must-assert c0 c
set assertion inbetween = f alse
c00 in(p00 ) post(p00 ), p00 Psum assertion inbetween = f alse
(p0 may-assert c0 c00
p00 may-assert c00 c
`(c00 ) [`(c), `(c)])
(p0 must-assert c0 c00
p00 must-assert c00 c
`(c00 ) [`(c), `(c)] must(c00 ))
set assertion inbetween = true
assertion inbetween return true
return f alse
end function

Figure 6: Algorithm whether plan must achieve clobber summary condition
achieves summary condition c must asserts condition must hold,
plans may assert condition negative between. algorithm may-achieve
(in Figure 7) mainly differs p0 may assert condition beforehand, plan
must assert between. undo algorithms achieve swapping c
c0 must/may-assert lines.
complexity determining must/may-clobber inconditions postconditions simply
O(c) check c conditions p0 . conditions hashed, algorithm constant time.
rest algorithm cases, complexity walking summary conditions
checking p00 c00 O(nc) maximum c summary conditions n plans
represented Psum . worst case, summary conditions summarize propositional
variable, O(nc) conditions must visited.
Lets look examples relationships. Figure 8a, p0 = equip M2 tool mayclobber c = available(M2)MaS summary preconditions p = produce G
history equip M2 tool ends produce G starts, calibrate M2 starts
produce G starts. Figure 8b, p0 = build H must-achieve c = available(H)MuF summary preconditions p = move H. Here, c0 available(H)MuL summary postconditions
build H. histories, build H attempts assert c0 move H requires c
met, plan execution attempts assert condition availability
H. equip M2 tool may-clobber c = available(M2)MuF summary preconditions
build H even though equip M2 tool asserts c0 = available(M2)MuL c required
met. calibrate M2 must assert available(M2)MuA time
equip M2 tool asserts c0 c required. Thus, calibrate M2 must-undo equip M2 tool

470

fiA BSTRACT R EASONING P LANNING C OORDINATION

Algorithm: May-[achieve, clobber]
Input: plan p0 , summary condition c plan p
Output: true f alse, whether p0 may-[achieve, clobber] c
begin function
c0 in(p0 ) post(p0 )
`(c0 ) [`(c), `(c)]
c insum (p) p0 may-assert c0 c return [unde f ined, true]
c postsum (p) p0 may-assert c0 c return [unde f ined, true]
c presum (p) p0 may-assert c0 c
set assertion inbetween = f alse
c00 in(p00 ) post(p00 ), p00 Psum assertion inbetween = f alse
p0 must-assert c0 c00
p00 must-assert c00 c
`(c00 ) `(c) `(c) must(c00 ))
set assertion inbetween = true
assertion inbetween return true
return f alse
end function

Figure 7: Algorithm whether plan may achieve clobber summary condition
a)

produce H
produce G

produce H G
move G

build H

move H

service M2
move

equip M2

tool

calibrate M2

tool

b)

produce H
produce H G

produce G

move G
=
move
tool

build H

move H

service M2

equip M2

calibrate M2

tool

Figure 8: production facilities managers plans partially expanded. a) managers plans
unordered respect other. b) equip M2 tool must clobber available(M2)MaL
produce G, calibrate M2 must clobber available(M2)MuF build H.

summary postcondition. calibrate M2 cannot assert postcondition available(M2)MuL
build H requires available(M2)MuF, calibrate M2 must-clobber summary precondition.

471

fiC LEMENT, URFEE , & BARRETT

3.4 Deriving Summary Conditions
algorithms determine interactions abstract plans based summary
conditions, create algorithm derives summary conditions according definitions Section 3.2. Figure 9 shows pseudocode algorithm. method deriving
summary conditions plan p recursive. First, summary information derived ps
subplans. conditions added based ps conditions. rest algorithm
derives summary conditions ps subplans. Whether p consistent depends
consistency subplans whether summary conditions resource usages
conflict. braces { } used slightly different semantics used
brackets. expression {x,y} interpreted simply (x y, respectively).
Definitions algorithms temporal relationships always- f irst covers
Appendix A. algorithm adds copies condition set, one condition exist
literal, conditions information may overwritten literal. cases,
must overwrites may; f irst, last, always overwrite sometimes; but, vice-versa. Further,
uses recursion, procedure assumed work plans whose expansion finite.
3.5 Summary Resource Usage
section, define representation capturing ranges usage local task interval depleted usage lasting end interval. Based introduce
summarization algorithm captures ranges uncertainty represented decomposition choices plans partial temporal orderings plan subtasks. representation
allows coordinator planner reason potential conflicts set tasks.
discuss reasoning later Section 4.2. Although referred resources, variables could
durations additive costs rewards.
3.5.1 R EPRESENTATION
start new example simplicity motivates choice representation. Consider
task coordinating collection rovers explore environment around lander
Mars. exploration takes form visiting different locations making observations.
traversal locations follows established paths minimize effort risk. paths combine form network like one mapped Figure 10, vertices denote distinguished
locations, edges denote allowed paths. Thinner edges harder traverse, labeled points
associated observation goals. paths hard ground, others loose
sand traversal harder since rover slip.
Figure 11 gives example abstract task. Imagine rover wants make early
morning trip point point B example map. trip sun slowly rises
horizon giving rover ability progressively use soak rays tasks provide
solar power (a non-consumable resource3 ) motors wheels. addition collecting photons,
morning traverse moves rover, resultant go tasks require path dependent amounts
power. rover traveling point point B take number paths, shortest
three involve following one, two, three steps.
3. important confuse power battery energy. power source (e.g. battery, solar panels) makes fixed
amount power Watts available point time. batterys energy (in Watt-hours) reduced integral
total use power time.

472

fiA BSTRACT R EASONING P LANNING C OORDINATION

Algorithm: Derive summary information
Input: plan p
Output: psum
begin function
derive summary information
p0 d(p)
V
set consistent(p) = p0 d(p) consistent(p0 )
` pre(p) add h`, must, f irsti presum (p)
` in(p) add h`, must, alwaysi insum (p)
` post(p) add h`, must, lasti postsum (p)
summary condition c0 p0 d(p)
set c = c0
c0 {presum (p0 ),postsum (p0 )}
c0 must-{achieved,undone} must-clobbered within d(p),
type(p) = (p0 always { f irst,last}
temporally ordered subplan according order(p)
sometimes- { f irst,last} subplan p0
{ f irst, last} `(c0 ) condition {presum (p0 ),postsum (p0 )}),
set timing(c) = sometimes
c0 may-{achieved,undone} may-clobbered P d(p)
p00 P must `(c0 ) condition {presum (p00 ),postsum (p00 )},
set existence(c) = may
copy c {presum (p),postsum (p)}
c0 insum (p0 ) p0 not-always { f irst,last} according order(p),
must(c0 ) c0 always-not- { f irst,last} according order(p),
set existence(c) = must
set P = 0/
set allAlways = true
p00 d(p), c00 insum (p00 )
`(c00 ) `(c)
always(c00 ) add p00 P
else set allAlways = f alse
else allAlways = f alse
always(c) ((type(p) = P covers p according order(p))
(type(p) = allAlways)),
set timing(c) = always
add c insum (p)
c0 may-clobbered, set consistent = f alse
usagesum (p) = SummarizeResourceUsage(p) (in Section 3.5.2)
consistent(usagesum (p)) = f alse, set consistent(p) = f alse
end function

Figure 9: Algorithm deriving summary information
summarized resource usage consists ranges potential resource usage amounts
performing abstract task, represent summary information plan p
resource res using structure
usagesum (p, res) = hlocal min(p, res), local max(p, res), persist(p, res)i,

473

fiC LEMENT, URFEE , & BARRETT




B
C
F
E

Figure 10: Example map established paths points rover domain
morning activities
move(A,B)
soak rays soak rays soak rays
use -4w use -5w use -6w
20 min
20 min
20 min
go(A,1)
use 3w
10 min

take low path

go(1,2)
use 3w
10 min

high path
middle path
go(A,B)
go(2,B) use 4w go(A,3) go(3,B)
use 6w 50 min use 4w use 6w
20 min
15 min 25 min

Figure 11: and/or tree defining rovers tasks resource usages
resources local usage occurs within ps execution, persistent usage represents
usage lasts execution terminates consumable resources.
Definition 12
usagesum (p, res)
h[minhH,e p E(h) (mints (e p )<t<t f (e p ) (r(res, h,t))), maxhH,e p E(h) (mints (e p )<t<t f (e p ) (r(res, h,t)))]
[minhH,e p E(h) (maxts (e p )<t<t f (e p ) (r(res, h,t))), maxhH,e p E(h) (maxts (e p )<t<t f (e p ) (r(res, h,t)))]
[minhH,e p E(h) (r(res, h,t f (e p ))),
maxhH,e p E(h) (r(res, h,t f (e p )))]

context Definition 12 set histories H value res 0 initial
state, E(h) contains execution p subexecutions. Thus, r(res, h,t) term
combined usage res time executions hierarchy defined Section 2.4. So,
maximum local min highest among histories lowest point usage
ps execution. usage ranges capture multiple possible usage profiles task multiple
decomposition choices timing choices among loosely constrained subtasks. example,
high path task h[4,4],[6,6],[0,0]i summary power use 40 minute interval. case
ranges single points due uncertainty task simply uses 4 watts 15 minutes
followed 6 watts 25 minutes. move(A,B) task provides slightly complex example
due decompositional uncertainty. task h[0,4],[4,6],[0,0]i summary power use
50 minute interval. cases persist [0,0] solar power non-consumable
resource.
example reasoning resource usage summaries, suppose 3 watts power
available move(A,B) task. Given [4,6] local max, know
enough power matter task decomposed. Raising available power 4 watts makes
task executable depending gets decomposed scheduled, raising 6
watts makes task executable possible decompositions.
474

fiA BSTRACT R EASONING P LANNING C OORDINATION

representation abstract (or uncertain) metric resource usage seen extension
tracking optimistic pessimistic resource levels (Drabble & Tate, 1994). Computing
upper lower bounds resource usage abstract plan gives information
whether lower upper bound constraints resource may, must, must violated,
complete. representing upper lower bounds ranges bounds
potential histories, certainly know whether bounds may, must, must violated
histories. example above, tracked one range local usage, [0,6],
would know definitely conflict 3 watts available. Knowing
extra information avoid exploration infeasible search space.
3.5.2 R ESOURCE UMMARIZATION LGORITHM
state summarization algorithm Section 3.4 recursively propagates summary conditions upwards and/or hierarchys leaves, algorithm resource summarization takes
approach. Starting leaves, algorithm finds primitive tasks use constant amounts
resource. resource summary task using x units resource h[x,x],[x,x],[0,0]i
h[x,x],[x,x],[x,x]i tasks duration non-consumable consumable resources respectively.
Moving and/or tree, summarization algorithm either comes branch.
branch combined summary usage comes computation
h [mincchildren (lb(local min(c))), maxcchildren (ub(local min(c)))],
[mincchildren (lb(local max(c))), maxcchildren (ub(local max(c)))],
[mincchildren (lb(persist(c))),
maxcchildren (ub(persist(c)))]
i,

lb() ub() extract lower bound upper bound range respectively. children
denote branchs children durations extended length longest child.
duration extension alters childs resource summary information childs usage profile
zero resource usage extension. instance, determining resource usage
move(A,B), algorithm combines two 40 minute tasks 50 minute task. resulting
summary information describes 50 minute abstract task whose profile might zero watt
power usage 10 minutes. extension move(A,B) [0,4] local min instead
[3,4]. Planners reason variable durations could use [3,4] duration ranging
40 50.
Computing branchs summary information bit complicated due timing
choices among loosely constrained subtasks. take x path examples illustrate simplest subcase, subtasks tightly constrained execute serially. profiles appended together,
resulting summary usage information comes SERIAL-AND computation
h [mincchildren (lb(local min(c)) + lb (c)), mincchildren (ub(local min(c)) + ub (c))],
pre
pre
[maxcchildren (lb(local max(c)) + lb (c)), maxcchildren (ub(local max(c)) + ub (c))],
[cchildren (lb(persist(c))),
cchildren (ub(persist(c)))]
i,
pre

pre

pre
pre
lb
(c) ub
(c) respective lower upper bounds cumulative persistent usages children execute c. computations form
computations final persist.
case subtasks execute parallel identical durations slightly simpler.
usage profiles add together, branchs resultant summary usage comes

475

fiC LEMENT, URFEE , & BARRETT

move(A,B)
soak rays
<[-4,-4],[-4,-4],[0,0]>

<[0,4],[4,6],[0,0]>

soak rays
<[-5,-5],[-5,-5],[0,0]>

soak rays
<[-6,-6],[-6,-6],[0,0]>

Figure 12: Possible task ordering rovers morning activities, resulting subintervals.
PARALLEL-AND computation
h [cchildren (lb(local min(c))),
maxcchildren (ub(local min(c)) + non
ub (c))],
non
[mincchildren (lb(local max(c)) + lb (c)), cchildren (ub(local max(c)))],
[cchildren (lb(persist(c))),
cchildren (ub(persist(c)))]
i,
non
non
ub (c) lb (c) respective sums local max upper bounds local min
lower bounds children except c.
handle tasks loose temporal constraints, consider legal orderings child
task endpoints. example, rovers early morning tasks, three serial solar energy collection subtasks running parallel subtask drive location B. Figure 12 shows
one possible ordering subtask endpoints, breaks move(A,B) three pieces,
two soak rays children half. Given ordering, summarization algorithm (1)
use endpoints children determine subintervals, (2) compute summary information
child task/subinterval combination, (3) combine parallel subinterval summaries using
PARALLEL-AND computation, (4) chain subintervals together using SERIALAND computation. Finally, tasks summary computed combining summaries
possible orderings using computation.
describe step (2) generates different summary resource usages subintervals
child task. child task summary resource usage h[a,b],[c,d],[e, f ]i contributes one two
summary resource usages intersecting subinterval4 :

h[a, b], [c, d], [0, 0]i, h[a, d], [a, d], [0, 0]i.

first usage tighter [a,b],[c,d] local ranges, second looser [a,d],[a,d] local
ranges. Since b c bounds apply subintervals containing subtasks minimum
maximum usages, tighter ranges apply one subtasks intersecting subintervals.
minimum maximum usages may occur subinterval, symmetry arguments
let us connect computation. Thus one subinterval tighter local ranges
intersecting subintervals get looser local ranges, extra complexity comes
investigate subtask/subinterval assignment options. instance, three subintervals
intersecting move(A,B) Figure 12, three different assignments summary resource usages
subintervals: placing [0,4],[4,6] one subinterval [0,6],[0,6] two.
placement options result subtask n subintervals n possible subinterval assignments.
child tasks n alternate assignments, nm combinations
potential subtask/subinterval summary resource usage assignments. Thus propagating summary
information branch exponential number subtasks multiple internal
4. summary resource usages last interval intersecting child task, replace [0, 0] [e, f ] persist.

476

fiA BSTRACT R EASONING P LANNING C OORDINATION

subintervals. However since number subtasks controlled domain modeler
usually bounded constant, computation tractable. addition, summary information
often derived offline domain. propagation algorithm takes form:
consistent ordering endpoints:
consistent subtask/subinterval summary usage assignment:
Use PARALLEL-AND computations combine subtask/subinterval summary
usages subinterval.
Use SERIAL-AND computation subintervals combined summary usages
get consistent summary usage.
Use computation combine consistent summary usages get tasks summary
usage.
described derive summary information, discuss use it.

4. Identifying Abstract Solutions
point, detailed algorithms deriving summary conditions reasoning
potential (may) definite (must) interactions tasks based summary information. addition, outlined algorithms deriving summarized resource usage
yet discussed identify solutions abstract levels. section, show
interactions summary conditions summarized metric resource usages identify potentially
resolvable threats unresolvable conflicts among plans group agents.
4.1 Threats Summary Conditions
Agents attempt resolve conflicts among plans considering commitments particular
decompositions ordering constraints. order this, agents must able identify
remaining conflicts (threats) among plans. present simple algorithms reasoning
threats abstract plans required conditions.
Formally, set CHiPs P ordering constraints order, threat abstract plan
p P summary condition c0 another plan p0 P exists iff p may-clobber c0 . say
threat unresolvable p must-clobber c0 must(c0 ) decomposition choices
ordering constraints could added resolve threat.
So, simple algorithm identifying threats check see O(nc) summary
conditions n plans Psum must- may-clobbered plan. Since complexity
checking see particular condition must- may-clobbered O(nc), algorithms
complexity O(n2 c2 ).
many coordination tasks, agents could determine certain temporal constraints
plans decomposed way (CanAnyWay) constraints
way successfully decomposed (MightSomeWay), make coordination
decisions abstract levels without entering potentially costly search valid plan merges lower
levels. formal definitions CanAnyWay MightSomeWay:

477

fiC LEMENT, URFEE , & BARRETT

a)

produce H

b)

maintenance

produce H
maintenance
move_parts

move_parts
c)

produce H
produce G

produce H G
maintenance
service M1 M2
service

service

M1

M2

move
tool

move_parts

Figure 13: top-level plans managers manufacturing domain
Definition 13
[CanAnyWay, MightSomeWay](order, Psum )
[, ]h, P summary f ormation = Psum h H(P, order)
[, ]e E(h), succeeds(e, h)
Definition 13 states plans summary information Psum ordering constraints
execute way sets plans P summary information Psum
execute successfully history. MightSomeWay true set plans
could possibly execute successfully. could also describe CanSomeWay(order,Psum )
MightAnyWay(rel,Psum ) fashion, obvious addition could
influence search. Exploring relations may interesting topic future research.
Figure 13a, three top-level plans managers unordered respect other.
leaf plans partially expanded hierarchies comprise Psum . Arrows represent constraints
order. CanAnyWay({},{produce G, maintenance, move parts}) false several conflicts use machines transports could occur certain executions
plans described Section 3.3 Figure 8. However, MightSomeWay({}, {produce G,
maintenance, move parts}) true plans might way execute successfully
shown Figure 13b. ordering constraints Figure 13b, CanAnyWay({before(1,0),
before(0,2)},{produce G, maintenance, move parts}) true plans execute
way consistent ordering constraints without conflict. Figure 8b example
MightSomeWay false calibrate M2 must-clobber available(M2)MuF summary precondition build H.
shown Figure 14, algorithm determining CanAnyWay summary conditions
simple needs check threats. MightSomeWay complicated
checking unresolvable threat enough. shown Figure 15, case
plan p must clobber p0 p00 could come achieve precondition ` p0 .
Thus, p may-clobbers ` p p00 . However, obviously p clobber one other,
478

fiA BSTRACT R EASONING P LANNING C OORDINATION

Algorithm: [CanAnyWay, MightSomeWay]
Input: order, Psum
Output: true f alse
begin function
psum Psum
[consistent(psum ), f alse] return f alse
p0sum Psum
summary condition c psum
p0 [may-clobber, must-clobber] c,
c [may must, must],
return f alse
resource res
[CanAnyWay, MightSomeWay](order, Psum , res) (see Section 4.2)
return false
return true
end function

Figure 14: Algorithm determining whether plans given summary information CanAnyWay
MightSomeWay execute successfully.
p
l

p
-l

l

l

p
l

l

l

Figure 15: MightSomeWay false even though must-clobber relationship.
MightSomeWay false. order determine MightSomeWay f alse, agent must exhaustively
search exponential number schedules see conflicts resolved. Instead
performing exponential search determine MightSomeWay, use simple algorithm
Figure 14 checks must-clobber relationships. Section 5.1 describe flexible
search find conflict-free abstract plans scheduling abstract level.
Thus, CanAnyWay algorithm sound complete, MightSomeWay algorithm
complete sound. also means determining MightSomeWay sound
complete. still make use algorithms sound complete planning/coordination algorithm Section 5.1. complexity algorithms O(n2 c2 ) since
O(nc) procedures determining must/may-clobber must run nc conditions (c
summary conditions n plans represented Psum ).
4.2 Summary Resource Usage Threats
Planners detect threats resource constraints different ways. planner reasons partially ordered actions, must consider combinations actions overlap together
exceed (or fall below) resources maximum value (or minimum value). polynomial algorithm

479

fiC LEMENT, URFEE , & BARRETT

IxTeT planner (Laborie & Ghallab, 1995). planners consider total order plans simply project levels resource initial state plan,
summing overlapping usages, see conflicts (e.g., Chien et al., 2000b).
Finding conflicts involving summarized resource usages work way.
partial order planner, resultant usage clusters actions tested using PARALLELAND algorithm Section 3.5. total order planner, level resource represented
summarized usage, initially h[x, x], [x, x], [x, x]i consumable resource initial level
x h[x, x], [x, x], [0, 0]i non-consumable resource. Then, subinterval
start end times schedule tasks, summary usage computed using
PARALLEL-AND algorithm. level resource computed subinterval
propagating persistent usages using SERIAL-AND algorithm.
decide CanAnyWay MightSomeWay defined Section 4.1, terms summary usage values resulting invocations PARALLEL-AND SERIAL-AND propagation algorithm end Section 3.5.2. CanAnyWay(order, Psum , res) true
potential threats. algorithms discover threat ever compute interval

lb(local min(i)) < min value(res) lb(persist(i)) < min value(res)
ub(local max(i)) > max value(res) ub(persist(i)) > max value(res).

MightSomeWay(order, Psum , res) true possible run potentially
threats. SERIAL-AND discovers run returns summary usage
ub(local min(i)) min value(res) lb(persist(i)) min value(res)
lb(local max(i)) max value(res) ub(persist(i)) max value(res).

mechanisms deriving summary information evaluating plans based
summarizations, discuss exploit planning/coordination algorithm.

5. Hierarchical Planning Coordination Algorithm
earlier defined algorithms reasoning group agents plans multiple levels
abstraction, describe agents efficiently plan coordinate based summary
information. describe coordination algorithm searches ways restrict decomposition ordering collective actions agent(s) order resolve conflicts
maximizing utilities individual agents global utility group.
approach starts making planning decisions abstract level and, needed,
decomposes agents plans top-down fashion. idea introduce information needed. Introducing irrelevant details complicates search increases communication.
describing top-down planning/coordination algorithm, describe search techniques
heuristics algorithm use exploit summary information.
5.1 Top-Down Hierarchical Planning Coordination
formalism summary conditions culminated Section 4 algorithms determine set
plans (abstract primitive) partial set ordering constraints definitely conflict-free
(CanAnyWay) unresolvable conflicts (MightSomeWay). integrate algorithms
one searches consistent plan one agents. particular algorithm
describe shown sound complete (Clement, 2002). search starts
top-level plans agent. solution one possible conflicts among
480

fiA BSTRACT R EASONING P LANNING C OORDINATION

agents plans. algorithm tries find solution top level expands hierarchies
deeper deeper optimal solution found search space exhausted.
pseudocode description algorithm given Figure 16.
state search partially elaborated plan represent set plans (one
agent), set temporal constraints, set blocked plans. subplans plans
leaves partially expanded hierarchies agents. set temporal constraints
includes synchronization constraints added search addition dictated
agents individual hierarchical plans. Blocked subplans keep track pruned subplans.
Decisions made search decentralized fashion. agents negotiate
ordering constraints adopt, choices subplans accomplish higher level plans,
decompositions explore first. algorithm described specify (or
commit to) negotiation technique, provide mechanisms identifying choices
agents negotiate. Although agents make search decisions decentralized fashion, describe algorithm given centralized process requests summary
information agents coordinated.
pseudocode Figure 16, coordinating agent collects summary information
agents plans decomposes them. queue keeps track expanded search states.
CanAnyWay relation holds search state, Dominates function determines current
solutions better every agent solution represented current search state
keeps solution dominated. MightSomeWay false, search space rooted
current search state pruned; otherwise, coordinator applies operators generate new
search states.
operators generating successor search states expanding non-primitive plans, blocking subplans, adding temporal constraints pairs plans. agent expands one
plans, plans summary conditions replaced original conditions
parent plan. subplans summary information ordering constraints added
search state. subplan plan added (or selected) subplans
blocked. ApplyOperator called select block operators, search states
generated selectable blockable subplan, respectively. Blocking subplan
effective resolving constraint subplans involved. example,
inventory manager plans use transport2, production manager could block subplans
using transport2, leaving subplans using transport1 conflict inventory managers
plan. lead least commitment abstract solutions leave agents flexibility selecting among multiple applicable remaining subplans. agents take another approach
selecting subplan (effectively blocking others) investigate preferred choice one
likely avoids conflicts.
operator add temporal constraint, new search state created alternative temporal constraint could added. successor states enqueued
backtracking needed, alternative tried. Adding temporal constraints generate new search states ordering consistent global local constraints.
implementation, add constraints help resolve threats determined
must/may achieves clobbers algorithms. plan expanded selected, ordering
constraints must updated subplans added.
soundness completeness coordination algorithm depends soundness
completeness identifying solutions complete exploration search space. Soundness
481

fiC LEMENT, URFEE , & BARRETT

Concurrent Hierarchical Coordination Algorithm
Input: set top-level plans, initial state
Output: set solutions, pair order constraints blocked plan choices
begin function
summarized plans = 0/
plan p plans
p0 = get summary information plan p
summarized plans = summarized plans { p0 }
end
threats = { (p, p0 ) | p, p0 summarized plans, MayClobber(p, p0 ) }
/ 0,
/ threats) }
queue = { (0,
solutions = 0/
loop
queue == 0/
return solutions
(order, blocked, threats) = Pop(queue)
CanAnyWay(initial state, summarized plans, order, blocked)
solution = (order, blocked)
solutions = solutions {solution}
sol1 sol2 solutions
Dominates(sol1 , sol2 )
solutions = solutions - { sol2 }
MightSomeWay(initial state, summarized plans, order, blocked)
operator = Choose({expand, select, block, constrain})
queue = queue ApplyOperator(operator, summarized plans, order, blocked)
return solutions
end function

Figure 16: concurrent hierarchical coordination algorithm.
completeness defined respect achieving particular goal predicates resolving
conflicts plan hierarchies. domain modeler may represent goals abstract CHiPs
decompose possible plans accomplish series actions agent execute
successfully.
Consider algorithm would find coordinated plans manufacturing agents.
beginning search, coordinating agent gathers summary information top-level
plans three agents plans. first, ordering constraints, order empty
first search state (shown Figure 13a) popped queue. CanAnyWay false,
MightSomeWay true state described earlier section, coordinator chooses
operator apply search state. could choose constrain order maintenance
plan produce H resolve conflicts two plans. order updated
new constraint, new search state inserted queue according ranking
function. next iteration loop, search state queue inserted
popped. coordinator finds CanAnyWay false, MightSomeWay true since
move parts may still conflict plans use transports. choose constrain
produce H move parts resolve remaining conflicts. detected next cycle
search loop CanAnyWay found true search state (shown Figure 13b).

482

fiA BSTRACT R EASONING P LANNING C OORDINATION

plans, two constraints order, empty set blocked plans added solution
since previously found solution Dominates it. Dominates function uses domain
specific criteria determining solution value alternative kept
inferior compared another dropped. manufacturing domain, one solution
dominates another finish time least one agent earlier finish times later
agents. search continues find alternative superior solutions, although agents
may decide terminate search interest time.
5.2 Search Techniques Heuristics
Although summary information valuable finding conflict free coordinated plans abstract
levels, information also valuable directing search avoid branches search
space lead inconsistent suboptimal coordinated plans. coordinator prune away
inconsistent coordinated plans abstract level quick check see MightSomeWay
false. example, search somehow reached state shown Figure 8b, coordinator
could backtrack expanding hierarchies avoid reasoning details
plans must fail.
Another strategy first expand plans involved threats. sake completeness, order plan expansions matter long expanded point
search trail cannot pruned. But, employing expand threats first (EMTF)
heuristic aims driving search hierarchy find subplan(s) causing conflicts others resolved quickly. similar most-constrained
variable heuristic often employed constraint satisfaction problems. example, facilities
inventory managers wished execute plans concurrently shown Figure 17a,
abstract level, coordinator would find conflicts use transports
moving parts. Instead decomposing produce H reasoning plan details
conflicts, EMTF heuristic would choose decompose either maintenance move parts
conflicts. decomposing maintenance agents resolve remaining
conflicts still execute concurrently.
Another heuristic coordinator use parallel EMTF choose fewest threats
first (CFTF). search orders states search queue ascending numbers threats
left resolve. effect, least-constraining value heuristic used constraint satisfaction
approaches. mentioned Section 4.1, threats identified CanAnyWay algorithm.
trying resolve threats coordinated plan search states fewer conflicts, hoped
solutions found quickly. So, EMTF heuristic ordering subplans expand,
CFTF, effect, orders subplan choices. example, production manager chooses
use machine M1 instead M2 produce G, coordinator likely closer solution
fewer conflicts resolve. heuristic applied selecting subplan
choices also choosing temporal constraints variable bindings search operator
entire set operators.
addition, trying find optimal solutions style branch-and-bound search,
coordinator use cost abstract solutions prune away branches search space whose
minimum cost greater maximum cost current best solution. role
Dominates function description coordination algorithm Section 5.1. usually

483

fiC LEMENT, URFEE , & BARRETT

a)

maintenance
produce H
move_parts

b)

maintenance
service M1 M2
service

service

M1

M2

move
tool

produce H

move_parts

Figure 17:

EMTF

heuristic resolving conflicts decomposing maintenance plan

assumes cost/utility information decomposable hierarchy actions, cost
abstract action function decompositions.

6. Complexity Analyses
Even though planner coordinator use search techniques described Section 5.2
prune search space, able find solutions multiple levels abstraction reduce
computation much doubly exponentially. section, give example
analyze complexity planning scheduling characterize cost reduction
conditions occurs.
agent interleaves execution planning/coordination often must limit total computation execution cost required achieve goals. planning algorithm described Section
5.1 able search solutions different levels abstraction. manufacturing example,
implementation centralized coordinator uses algorithm find 1.9 CPU seconds solution top level agents plans shown Figure 13b. define cost execution
makespan (completion time) coordinated plan, cost solution 210
makespan production managers plan 90, facilities managers 90, inventory
managers 30. solution Figure 13c, coordinator required 667 CPU seconds,
makespan coordinated plan 170. Another solution found intermediate level
abstraction, taking 69 CPU seconds makespan 180. So, little effort,
algorithm expanded hierarchy intermediate level cost solution
reduced 30. Thus, overall cost reduced coordinating intermediate levels.
problem, coordinating higher levels abstraction less costly
fewer plan steps. But, even though fewer plans higher levels, plans may
greater numbers summary conditions reason collected much
greater set plans below. argue even worst case number summary
conditions per plan increases exponentially hierarchy, finding solutions abstract levels
expected exponentially cheaper lower levels. first analyze complexity
484

fiA BSTRACT R EASONING P LANNING C OORDINATION

summarization algorithm help reader understand summary conditions collect
greater sets higher levels.
6.1 Complexity Summarization
Consider hierarchy n total plans, b subplans non-primitive plan, depth d, starting
zero root, shown Figure 18. procedure deriving summary conditions works
basically propagating conditions primitives hierarchy abstract
plans. conditions non-primitive plan depend immediate subplans, deriving summary conditions done quickly number subplans large.
derivation algorithm mainly involves checking achieve, clobber, undo interactions among
subplans possible total orderings subplans (as described Section 3.4). Checking
one relations one summary condition one subplan O(bs) b subplans,
summary conditions (as discussed Section 3.3). Since O(bs) conditions must
checked set subplans, deriving summary conditions one plan subplans
O(b2 s2 ).
However, maximum number summary conditions subplan grows exponentially
hierarchy since, worst case, summary conditions merge summarization.
happens conditions subplan completely different propositions/variables
sibling subplan. case, separate summary condition generated
summary condition subplan. children share conditions variable,
information collapsed single summary condition parent plan.
shown third column table Figure 18, plan lowest level = c
summary conditions derived c pre-, in-, postconditions. plan level 1 derives c
summary conditions conditions c b subplans giving c + bc summary conditions, = O(bc). So, worst case = O(bdi c) plan level hierarchy
plan c (non-summary) conditions. Thus, complexity summarizing plan
level (with subplans level + 1) O(b2 b2(d(i+1)) c2 ) = O(b2(di) c2 ). bi plans
level (second column figure), complexity summarizing set plans level
O(bi b2(di) c2 ) = O(b2di c2 ) shown fourth column figure. Thus, complexity
2(di) c2 ). summation = 0
summarizing entire hierarchy plans would O(d1
i=0 b b
2d
2
dominates, complexity simplified O(b c ). n = O(bd ) plans
hierarchy, write simply O(n2 c2 ), square size hierarchy.
best case conditions variable, plan c summary
2 2
conditions. Thus, complexity summarizing hierarchy O(d1
i=0 b b c ),
simplifies O(bd+1 c2 ) = O(nbc2 ). case, summarization conditions tractable,
discussed Section 3.5.2, summarization resources also tractable.
6.2 Complexity Finding Abstract Solutions
order resolve conflicts (and potentially arrive solution) particular level expansion
hierarchy, coordination algorithm checks threats plans particular
ordering constraints level. Checking threats involves finding clobber relations among
plans summary conditions. complexity finding threats among n plans
summary conditions O(n2 s2 ) shown Section 4.1 MightSomeWay algorithm.
hierarchy expanded level i, n = O(bi ) plans frontier expansion, plan
485

fiC LEMENT, URFEE , & BARRETT

level #plans #conds / #operations #test operations / solution
plan derive summ. info. solution candidate space

1

2

...

b

......
.................................
..........
............
1

2

...

b

1

2

...

b

.......

0

1

O(bdc)

O(b2(bd-1c)2)
= O(b2dc2)

O(1)

1

1

b

O(bd-1c)

O(bb2(bd-2c)2)
= O(b2d-1c2)

O(b2(b(d-1)c)2)
= O(b2dc2)

O(kb)

2

b2

O(bd-2c) O(b2b2(bd-3c)2)
= O(b2d-2c2)

O(b4(b(d-2)c)2)
= O(b2dc2)

O(kb )

d-2

bd-2

O(b2c)

O(bd-2b2(bc)2)
= O(bd+2c2)

O(b2(d-2)(b2c)2) O(kb )
= O(b2dc2)

d-1

bd-1

3c+b3c
= O(bc)

O(bd-1b2c2)
= O(bd+1c2)

O(b2(d-1)(bc)2) O(kb )
= O(b2dc2)



bd

3c

O(1)

O(b2dc2)

O(kb )



bi

O(bd-ic)

O(b2d-ic2)

O(b2dc2)

O(kbi)

2

d-2

d-1



Figure 18: Complexity threat identification resolution abstract levels
= O(bdi c) summary conditions. So, shown fifth column table Figure 18,
worst case complexity checking threats one synchronization set plans level
O(b2i (bdi c)2 ) = O(b2d c2 ). Notice drops formula, meaning complexity
checking candidate solution independent depth level. best case summary
conditions fully merge, plan = c summary conditions, complexity checking
candidate solution O(b2i c2 ), factor O(b2(di) )faster worst case.
However, algorithm may check many synchronizations particular level finding
solution exhausting search space. fact search complexity grows exponentially
number plans.5 Thus, shown last column table Figure 18, search space

O(kb ) bi plans level constant k.6 Thus, search space grows doubly exponentially
hierarchy based number plan steps.
refinement coordination planning algorithm, conflict detection basic operation
done resolving conflicts. So, also include effect size conditions (in
addition plan steps) complexity planning/coordination algorithm, must multiply

complexity check threats. Thus, complexity O(kb b2d c2 ) summary information

merge O(kb b2i c2 ) summary information fully merges. complexity

resolving conflicts primitive level O(kb b2d c2 ), resolving conflicts abstract


level speeds search doubly exponentially, factor O(kb b ) even summary information
merge summarization. Now, completely merges, speedup factor


O(kb b b2(di) ).
5. fact, NP-complete (Clement, 2002).
6. Georgeff chose cluster multiple operators critical regions synchronize (fewer) regions
since would many fewer interleavings check (1983). exploiting hierarchical structure plans,
use clusters predefined hierarchy kind advantage without needing cluster bottom
up.

486

fiA BSTRACT R EASONING P LANNING C OORDINATION

level
0
1


branching
factor b

...
1

2

n
c constraints
per hierarchy

v
variables

Figure 19: Schedule n task hierarchies c constraints v variables
plans analysis. case plans, able prune
branches higher levels based summary information also greatly improve search despite
overhead deriving using summary conditions. Pruning effectively reduces branching
factor since branch eliminated investigating details. Thus, complexity based

number plan steps becomes O(k(bp) ) fraction p/b branches pruned. Thus,
pruning also create exponential reduction search.
6.3 Scheduling Complexity
local search planner (e.g. ASPEN, Chien et al., 2000b) backtrack, problem
solved same, one might expect complexity advantages refinement planner. However, search operations local search planner different.
previous study technique called aggregation eliminates search inefficiencies lower levels
detail task hierarchies operating hierarchies single tasks (Knight, Rabideau, & Chien,
2000). Thus, immediately clear additional improvements scheduler could obtained
using summary information. show improvements significant, first must
provide background aggregation.
Moving tasks central scheduling operation iterative repair planners. planner
effectively schedule tasks moving related groups tasks preserve constraints among them.
Hierarchical task representations common way representing groups constraints. Aggregation involves moving fully detailed abstract task hierarchy preserving
temporal ordering constraints among subtasks. Moving individual tasks independently
parent, siblings, subtasks shown much less efficient (Knight et al., 2000). Valid placements task hierarchy schedule computed state resource usage profiles
hierarchy tasks context movement. hierarchys profile represents one instantiation decomposition temporal ordering abstract task
hierarchy.
Consider schedule n task hierarchies maximum branching factor b expanded
maximum depth shown Figure 19. Suppose hierarchy c constraints v
variables (states metric resources). move hierarchy tasks using aggregation, scheduler

487

fiC LEMENT, URFEE , & BARRETT

must compute valid intervals resource variable affected hierarchy.7 scheduler
intersects intervals get valid placements abstract tasks children.
complexity computing set valid intervals resource O(cC) c number
constraints (usages) abstract task children variable, C number
constraints tasks schedule variable (Knight et al., 2000). n similar
task hierarchies entire schedule, C = (n 1)c, complexity computing valid
intervals O(nc2 ). computation done v resource variables (often constant
domain), moving task complexity O(vnc2 ). intersection valid intervals
across variables increase complexity. complexity O(tnr)
nr valid intervals timeline; intersecting intervals pair timelines linear
number intervals; 1 pairs timelines need intersected get intersection
set.
summary information abstract task represents constraints children,
children share constraints resource, information collapsed single
summary resource usage abstract task. Therefore, moving abstract task, number
different constraints involved may far fewer depending domain. scheduler
trying place summarized abstract task among summarized tasks, computation valid
placement intervals greatly reduced c O(vnc2 ) smaller. consider
two extreme cases constraints fully collapsed cannot collapsed
all.
case tasks hierarchy constraints variable, number
constraints hierarchy O(bd ) hierarchy depth branching factor (number child
tasks per parent) b. aggregation, hierarchies fully detailed first, means
complexity moving task O(vnb2d ) c = O(bd ). consider using aggregation
moving partially expanded hierarchy leaves summarized abstract tasks.
hierarchies schedule decomposed level i, O(bi ) tasks hierarchy,
one summarized constraint representing yet undetailed subtasks beneath
constraint variable. c = O(bi ), complexity moving task O(vnb2i ). Thus,
moving abstract task using summary information factor O(b2(di) ) times faster
aggregation. worst case number conflicts increases number plan
steps (just refinement planner), worst case complexity resolving conflicts based

number plan steps level O(kb ). Thus (as refinement planning) using summary
di
information make speedups O(kb b2(di) ) summary information fully collapses.
extreme tasks place constraints different variables. case,
c = 1 hierarchy one constraint per variable. Fully detailed hierarchies
contain v = O(bd ) different variables, complexity moving task case O(nbd ).
moving summarized abstract task tasks schedule decomposed level i, v
abstract task summarizes constraints subtask hierarchy
beneath it, constraints different variables constraints combine
summarized. Thus, complexity moving partially expanded hierarchy
fully expanded one. case, number conflicts also change depth
hierarchy conflicts always pairs n hierarchies. So,
7. analysis also applies state constraints, restrict discussion resource usage constraints simplicity.

488

fiA BSTRACT R EASONING P LANNING C OORDINATION

extreme case, summary information reduce complexity scheduling would
incur unnecessary overhead.
complexity analyses shown different forms hierarchical problem solving,
need backtrack lower higher levels interacting subproblems, reduce size search space exponential factor (Korf, 1987; Knoblock, 1991).
planner scheduler using summary information witness exponential improvements without
assumption. Backtracking across abstraction levels occurs within planner/coordinator described Section 5.1 current search state MightSomeWay another subplan
higher level selected. demonstrated search space grows doubly
exponentially hierarchy number plans grows exponentially, resolving
conflicts grows exponentially number plans. Thus, long planner coordinator fully expand abstract plans primitive level summary information


merges higher levels, search complexity reduced least factor kb b
level search completed, depth hierarchy. Yang (1997) also suggests
ways exponential speedups obtained subplans interact based hierarchy structure.
speedups complementary summary information limits decomposition
task hierarchies compresses information manipulated planner scheduler.

7. Experiments
experimentally evaluate use summary information planning coordination
three different domains: evacuation domain, manufacturing domain described Section 1.1,
multi-rover domain. domains, define performance different ways show
range benefits abstract reasoning offers.
evaluate algorithm described Section 5.1. implementation orders search states
queue generated synchronization operators precede generated
expansion selection operators. Thus, going deeper part hierarchy, implementation algorithm explores orderings agents plans digging deeper
hierarchy. Investigating heuristics choosing synchronization decomposition
operators topic future research.
next section report experiments evacuation domain show abstract
reasoning using summary information find optimal coordination solutions quickly
conventional search strategies. Optimal solutions evacuation domain minimal global execution times evacuees must transported safety quickly possible. Section 7.2,
show summary information improves local search performance significantly tasks
within hierarchy constraints resource, solutions found
level abstraction. also evaluate benefits using CFTF EMTF heuristics
iterative repair show summary information slow search.
domains, computation time may insignificant communication costs. costs
could terms privacy self-interested agents, security sensitive information could
obtained malicious agents, simply communication delay. Section 7.3, show multilevel coordination fails reduce communication delay manufacturing domain example but,
domains, expected reduce communication overhead exponentially.

489

fiC LEMENT, URFEE , & BARRETT

1
s0

2

3

0

s3
t2

t1
4

5

Figure 20: Evacuation problem
7.1 Coordinated Planning Experiments
section, describe experiments evaluate use summary information coordinating group evacuation transports must together retrieve evacuees number locations
constraints routes. comparing EMTF CFTF search techniques described Section 5.2 conventional HTN approaches, experiments show reasoning summary
information finds optimally coordinated plans much quickly prior HTN techniques.
compare different techniques ordering expansion subplans
plans direct decomposition plan hierarchies search optimal solutions.
expansion techniques expand (for subplans) select (for subplans) operators
algorithm described Section 5.1.
compare EMTFs expansion plans ExCon heuristic random selection
heuristic. ExCon heuristic (Tsuneto et al., 1998) first selects plans achieve external
precondition, plans, selects one threatens external precondition.
case neither achieving threatening plans, chooses randomly. Note
EMTF additionally choose expand plans threatened external preconditions
preference whether plan achieves, threatens, threatened. expansion
plans, compare CFTF depth-first (DFS) random heuristic.
also compare combination CFTF EMTF FAF (fewest alternatives first)
heuristic combination DFS ExCon. FAF heuristic employ summary
information rather chooses expand select plans fewest subplans
(Currie & Tate, 1991; Tsuneto, Hendler, & Nau, 1997). Since summary information used,
threats resolved primitive levels. shown FAF heuristic
effectively used HTN planner (Tsuneto et al., 1997), combination DFS ExCon
shown make great improvements FAF domain task interactions
(Tsuneto et al., 1998). show one domain CFTF EMTF heuristics together
outperform combinations FAF, DFS, ExCon.
problems generated evacuation domain transports responsible
visiting certain locations along restricted routes pick evacuees bring back safety
points. Transports allowed location time, coordinator must
ensure transports avoid collisions along single lane routes. addition, order avoid
risk oncoming danger (from typhoon enemy attack), transports must accomplish
goals quickly possible.
Suppose two transports, t1 t2, located safety points s0 s3 respectively,
must visit locations 0, 1, 2 2, 3, 4 respectively bring evacuees back safe
490

fiA BSTRACT R EASONING P LANNING C OORDINATION

evacuate
move s0-0

make rounds

one switch

switch
clockwise

first route

cw0-1

second route

cw0-2

move 0-1

counterclockwise

ccw1-2

ccw2-0

go back

ccw2-0

goto safe loc

move

move 0-s0

move 3-s3

move 1-2

Figure 21: plan hierarchy transport t1
locations shown Figure 20. overlap locations must visit, coordinator
must synchronize actions order avoid collision. coordinators goal network includes
two unordered tasks, one transport evacuate locations responsible.
shown Figure 21, high-level task t1 (evacuate) decomposes primitive action
moving location 0 ring abstract plan traverse ring (make rounds). t1
travel one direction around ring without switching directions, switch directions once.
t1 either go clockwise counterclockwise and, switching, switch directions
location ( f irst route) travel farthest location needs visit switched
(second route). visited locations, continues around reaches first
safety point path (go back goto sa f e loc). move plan case t1
already location 0. task t2 refined similarly.
Suppose coordinator gathers summary information plan hierarchy attempts
resolve conflicts. Looking summary information one level top, coordinator
determine t1 finishes evacuating t2 even begins, conflicts
since external conditions t1s evacuate plan none routes traversed.
solution makespan (total completion time) 16 steps. optimal solution plan
duration seven t1 moves clockwise reaches location s3, t2 starts clockwise,
switches directions location 4, winds s0. solution t1 waits location 2
one time step avoid collision route location 2 location 3.
generated problems four, six, eight, twelve locations; two, three four
transports; no, some, complete overlap locations transports visit. Performance measured number search states expanded find optimal solution (if
compared heuristics find optimal solution) number states expanded
find solutions highest common quality within memory time bounds. chose instead CPU time measure performance order avoid fairness issues respect
implementation details various approaches.

491

fiC LEMENT, URFEE , & BARRETT

Search States Expanded
100000

CFTF-RAND

10000
1000
100
10
1
1

10

100

1000 10000 1E+05

CFTF-EMTF

Figure 22: Comparing EMTF random expansion searching optimal solutions

Figure 23: Comparing EMTF ExCon searching optimal solutions
scatter plot Figure 22 shows relative performance combination CFTF
combination CFTF random expansion (CFTF-Rand).
chose scatterplots compare results capture results simply trying
plot three dimensions problem size/complexity. Note scatter plots, axes
scaled logarithmically. Points diagonal line mean EMTF (x-axis) performing better
Rand (y-axis) fewer search states required find optimal solution.
performance similar problems, cases CFTF-EMTF outperformed
CFTF -Rand order magnitude more. Figure 23 exhibits similar effect CFTF - EMTF
CFTF-ExCon. Note runs terminated expansion 3,500 search states. Data
points 3,500 (the ones forming horizontal line top) indicate solution found
within memory time constraints. performance similar problems, four
points along top CFTF-ExCon finds solution. Thus, although EMTF greatly
EMTF ( CFTF - EMTF )

492

fiA BSTRACT R EASONING P LANNING C OORDINATION

Figure 24: Comparing CFTF DFS searching optimal solutions
improve performance many problems, rarely performs much worse, almost always avoids
getting stuck fruitless areas search space compared ExCon random heuristic.
expected since EMTF focuses resolving conflicts among problematic plans
first avoids spending lot time reasoning details less problematic plans.
combination CFTF EMTF, pruning inconsistent abstract plan spaces, branchand-bound pruning costly abstract plan spaces (all described Section 5.2) much
dramatically outperforms techniques reason abstract levels. Figure 24 shows DFSRand expanding one three orders magnitude states CFTF-Rand. Runs
terminated expansion 25,000 search states. Data points 25,000 (forming
horizontal line top) indicate solution found within memory time constraints.
avoiding search spaces greater numbers conflicts, CFTF finds optimal near-optimal solutions much quickly. Figures 25 26, CFTF-EMTF outperforms FAF-FAF (FAF
selecting plans) DFS-ExCon one two orders magnitude problems.
last two comparisons especially emphasize importance abstract reasoning finding
optimal solutions. Within maximum 3,500 expanded search states (the lowest cutoff point
experiments), CFTF-EMTF CFTF-Rand found optimal solutions 13 24 problems.
CFTF -ExCon FAF- FAF found 12; DFS -ExCon DFS -Rand found three.
surprising result FAF-FAF performs much better DFS-ExCon evacuation
problems contrary results given Tsuneto et al. (1998) show DFS-ExCon dominating
problems goal interactions. believe result reproduced
experiments involved hierarchies plans. experiments show
selection subplans greatly affects performance order subplans expand.
So, believe DFS-ExCon performed worse FAF-FAF FAF better choosing
subplans ExCon FAF stronger selecting subplans DFS.
However, main point section heuristic combinations use summary information find solutions prune search space abstract levels (CFTF-EMTF, CFTFExCon, CFTF-Rand) greatly outperform (FAF-FAF, DFS-ExCon,
DFS -Rand) searching optimal solutions.

493

fiC LEMENT, URFEE , & BARRETT

Figure 25: Comparing use summary information FAF heuristic

Figure 26: Comparing use summary information algorithm using external conditions
7.2 Scheduling Experiments
experiments describe show summary information improves performance significantly tasks within hierarchy constraints resource, solutions
found level abstraction. time, cases abstract reasoning
incurs significant overhead solutions found deeper levels. However, domains
decomposition choices critical, show overhead insignificant
CFTF heuristic chooses decompositions quickly lead solutions deeper levels.
experiments also show EMTF heuristic outperforms simpler heuristic depending
decomposition rate, raising new research questions. use ASPEN Planning System (Chien
et al., 2000b) coordinate rover team problem described next.

494

fiA BSTRACT R EASONING P LANNING C OORDINATION

Figure 27: Randomly generated rectangular field triangulated waypoints

Figure 28: Randomly generated waypoints along corridors
7.2.1 P ROBLEM OMAINS
domain involves team rovers must resolve conflicts shared resources. generate
two classes maps within rovers move. one, randomly generate map triangulated waypoints (Figure 27). other, generate corridor paths circle locations
three paths center points circle represent narrow paths around obstacles
(Figure 28). corridor map used evaluate CFTF heuristic. select subset
points science locations (where rovers study rocks/soil) use simple multiple traveling salesman algorithm assign routes rovers traverse perform experiments.
idea map area around lander constructed image taken upon landing
Mars.
Paths waypoints assigned random capacities either one, two, three
rovers traverse path simultaneously. one rover waypoint, rovers may
traverse paths opposite directions time. constraints modeled metric
resources. State variables also used ensure rovers locations
leave. addition, rovers must communicate lander telemetry using shared channel
fixed bandwidth (metric resource). Depending terrain waypoints, required
bandwidth varies. 80 problems generated two five rovers, three six science locations
per rover, 9 105 waypoints. general, problems contain fewer waypoints
science goals difficult interactions among rovers.
Schedules consist abstract task rover decomposition tasks
visiting assigned science location. tasks decomposition three shortest
paths waypoints target science location. paths decomposition
movements waypoints. Additional levels hierarchy introduced longer paths
order keep offline resource summarization tractable. Schedules ranged 180 1300
tasks.

495

fiC LEMENT, URFEE , & BARRETT

7.2.2 E MPIRICAL R ESULTS ARS ROVERS
compare ASPEN using aggregation without summarization three variations
rectangular field domain. using summary information, ASPEN also uses EMTF CFTF
decomposition heuristics. One domain excludes communications channel resource (no channel);
one excludes path capacity restrictions (channel only); excludes neither (mixed).
Since movement tasks reserve channel resource, greater improvement performance
expected using summary information according complexity analyses Section 6.3.
constraints channel resource collapse summary information derived
higher levels task hierarchy one constraint resource.
ASPEN use summary information, hierarchies must fully expanded, number
constraints channel resource equivalent number leaf movement tasks.
However, tasks within rovers hierarchy rarely place constraints path variables
once, channel domain corresponds worst case summarization
collapses constraints. complexity moving abstract task without summary information fully expanded hierarchy summary information partially
expanded hierarchy.
Figure 29 (top) exhibits two distributions problems channel domain.
cases (points x=y diagonal), ASPEN summary information finds solution quickly
level abstraction. However, many cases, summary information performs notably worse
(points x=y diagonal). discovered problems finding solution requires
planner dig deeply rovers hierarchies, decomposes hierarchies
level solution, difference additional time find solution two
approaches negligible (unless use summary information found solution slightly higher
level abstraction quickly). Thus, time spent reasoning summary information
higher levels incurred unnecessary overhead.
worst case analysis Section 6.3 showed summary information advantage even found abstract solutions. So, summary information perform
better abstract solutions found? CFTF heuristic since branch
choices result small differences numbers conflicts. actually results stochastic nature ASPENs iterative repair. Although moving abstract tasks using aggregation without
summary information would enabled ASPEN find solutions quickly fully expanded
hierarchies, ASPEN must sometimes move lower level tasks independently parents siblings order resolve conflicts lower levels. problem ASPEN heuristic tell
level needs move activities, sometimes chooses move activities detailed
levels unnecessarily. search lower levels search space explodes. Using summary
information search higher levels lower levels abstraction better protects ASPEN
unnecessary search.
Figure 29 (middle) shows significant improvement summary information mixed domain compared channel domain. Adding channel resource rarely affects use
summary information collapse summary constraints incurs insignificant additional
complexity. However, channel resource makes scheduling task noticeably difficult
ASPEN using summary information. channel domain (Figure 29 bottom), summary information finds solutions abstract level almost immediately, problems still
complicated ASPEN use summary information. results support complexity

496

fiA BSTRACT R EASONING P LANNING C OORDINATION

a)

b)

c)
Figure 29: Plots a) channel, b) mixed, c) channel domains
analysis Section 6.3 argues summary information exponentially improves performance
tasks within hierarchy constraints resource solutions
found level abstraction.
summary information generated offline, domain modeler knows front whether
constraints significantly collapsed. Thus, obvious approach avoiding cases
reasoning summary information causes unnecessary overhead fully expand start
scheduling hierarchies tasks summary information collapse.
complexity moving task hierarchy case whether fully expanded not, ASPEN
waste time duplicating efforts level expansion reaching level
finds solution. Evaluating approach subject future work.
Earlier mentioned CFTF heuristic effective rectangular field problems.
choice among different paths science location usually make

497

fiC LEMENT, URFEE , & BARRETT

Figure 30: Performance using CFTF heuristic

significant difference number conflicts encounteredif rovers cross paths, path
choices usually still lead conflict. set corridor problems, path choices always lead
different corridor get target location, usually path avoids conflict
path causes one depending path choices rovers. ASPEN uses
CFTF heuristic, performance dominates chooses decompositions randomly
two problems (Figure 30). reflects experiments coordination algorithm Section 7
show CFTF crucial reducing search time required find solutions.
order evaluate EMTF heuristic iterative repair planning, compared simple
alternative. alternative strategy (that refer level decomposition) interleave repair
decomposition separate steps. Step 1) planner repairs current schedule
number conflicts cannot reduced. Step 2) decomposes abstract tasks one level
returns Step 1. spending enough time particular level expansion appears
effective, planner attempts find highest decomposition level solutions exist without
wasting time level. time spent searching solution level expansion
controlled rate abstract tasks decomposed. EMTF heuristic implemented
repair method give priority detailing plans involved conflicts.
Figure 31 shows performance EMTF vs. level decomposition different rates decomposition three problems set varied performance. plotted points averages
ten runs problem. Depending choice rate decomposition (the probability
task decompose conflict encountered), performance varies significantly. However, best decomposition rate vary problem problem making potentially difficult
domain expert choose. example, problem figure, tested decomposition
rates EMTF outperformed use level decomposition. time, problem C using
either decomposition technique make significant difference problem B choosing
rate EMTF made big difference whether use EMTF level decomposition. Although
examples show varied performance, results problems showed decompo-

498

fiA BSTRACT R EASONING P LANNING C OORDINATION

1200


level-decomp
1000

B
B level decomp
C

CPU seconds

800

C level decomp
600

400

200

0
0

5

10

15

20

25

30

35

EMTF Decomposition Rate

Figure 31: Performance EMTF vs. level-decomposition heuristics
sition rate around 15% successful. suggests domain modeler may able
choose generally successful decomposition rate running performance experiments set
example problems.8
demonstrated many results complexity analyses Section 6. Scheduling
summary information gains speedups (over aggregation) resolving conflicts appropriate levels abstraction. summary information collapses, scheduler gains exponential
speedups. addition, CFTF heuristic enables exponential speedups decomposition
choices varying numbers conflicts.
7.3 Communication Overhead
show that, depending bandwidth, latency, summary information communicated among agents, delays due communication overhead vary. communication costs
concern, one extreme message delay dominates cost, sending plan hierarchy
without summary information makes sense. extreme bandwidth costs
dominate, makes sense send summary information task separate message
requested. Still, cases sending summary information tasks groups
makes sense. section explain system designer choose much
summary information send time order reduce communication overhead exponentially.
Consider simple protocol agents request coordination central coordinating agent.
search feasible solution, whenever decomposes task, coordinator requests
summary information subtasks yet received. manufacturing domain,
coordinator may already summary information task move part, encounters
different instantiation task schema, still must request parameters new task.
coordinator needs subplans plan, client agent sends required information
subplans, specifying preferences each. coordinator chooses preferred
8. experiments, used decomposition rate 20% since seemed work well.

499

fiC LEMENT, URFEE , & BARRETT

a)

b)

Figure 32: Delay communicating different granularities summary information varying a)
latency b) bandwidth

subplan, case must backtrack, chooses next preferred subplan.
coordinator finds feasible solution, sends modifications agent specifying subplans blocked agent must send wait synchronization messages. agent
choose send summary information number levels expansion requested
tasks hierarchy.
manufacturing problem described Section 1.1, communication data terms numbers messages size collected point coordinator found
solution Figure 13c. data collected cases agents sent summary information
tasks hierarchies, one time, two levels time, once. two levels
include requested task immediate subplans. following table summarizes
numbers total sizes messages sent granularity level information:

one task time
two levels time


number messages
9
4
3

total size (bytes)
8708
10525
16268

Assuming coordinator must wait requested information continuing search
request one task one agent time, coordination delayed amount
time depending bandwidth latency message passing. total delay calculated (n 2)` + s/b, n number messages sent; ` latency seconds;
total size messages; b bandwidth bytes per second. use n 2 instead n
assume agents transmit first top-level summary information message
time, three messages actually incur delay ` instead 3`.
Figure 32a shows communication delay varies three granularities information
fixed bandwidth 100 bytes/second. (We address lack realism example
shortly.) latency less 3 seconds, sending summary information task
separate messages results smallest communication overhead. latencies greater 58
seconds, sending entire hierarchy best; sending summary information two
levels time best. latency fixed 100 seconds, communication delay varies
500

fiA BSTRACT R EASONING P LANNING C OORDINATION

a)

b)

Figure 33: Delay varying a) latency b) bandwidth hypothetical example
bandwidth shown Figure 32b. bandwidth less 3 bytes/second, sending
one time best; sending best bandwidths greater 60 bytes/second;
sending two levels time best bandwidths between.
Admittedly, values unrealistic manufacturing domain. manufacturing problem simple provided mainly interesting domain coordination. realistic problems involving manufacturing domain could much larger hierarchies require
much larger scales data sent. case realistic bandwidth latency values would
exhibit similar tradeoffs.
see this, suppose manufacturing managers hierarchies common branching
factor b depth d. tasks generally reservations similar resources throughout hierarchies, amount total summary information particular level would grow exponentially
hierarchy would number tasks. agents agreed feasible solution
depth level hierarchy, table messages size would appear follows:

one task time
two levels time


number messages
O(bi )
3i/2
3

total size
O(bi )
O(bi )
O(bd )

suppose branching factor b 3; depth 10; solution found level
= 5; summary information task 1 Kbyte. table would look like this:

one task time
two levels time


number messages
363
9
3

total size (Kbytes)
1089
3276
246033

Now, fixed bandwidth 100 Kbyte/second varied latency, realistic
tradeoffs seen Figure 33a. Here, see unless latency small, sending summary
information two levels time best. shown Figure 33b, fix latency one second
vary bandwidth, realistic bandwidths sending summary information two levels
time best.

501

fiC LEMENT, URFEE , & BARRETT

simple protocol illustrates communication minimized sending summary
information particular granularity. agents chose send summary information
unsummarized hierarchies instead, would need send entire hierarchies.
experiment shows, hierarchies grow large, sending entire hierarchy (all once) would take
long time, even high bandwidth. Thus, using summary information (as opposed using
it) reduce communication exponentially solutions found abstract levels.
extreme, agents sent summary information one task time, latency
sending many messages grow large larger task hierarchies. solutions could
found primitive levels, sending summary information one task time would cause
exponential latency overhead compared sending entire hierarchy once. But, solutions
found intermediate levels, able send summary information intermediate
granularity minimize total delay.
However, argument assumes summary information collapses higher levels hierarchy. Otherwise, sending summary information intermediate level could almost
expensive sending entire hierarchy cause unnecessary overhead. actual manufacturing domain, tasks agents hierarchies mostly constraints different resources,
summarization able reduce summary information significantly constraints
collapse. result better, case, send entire hierarchy minimize
delay (unless unusual bandwidth latency constraints, shown experiment).
Even so, coordination agent still summarize hierarchies take advantage
computational advantages abstract reasoning.
section showed domain modeler minimize communication overhead communicating summary information proper level granularity. bandwidth, latency,
common depth coordination solutions known, domain modeler perform hypothetical
experiment like one varying granularities summary information determine
granularity optimal. summary information collapses hierarchy, solutions
found intermediate levels, communication exponentially reduced manner.

8. Related Work
approach taken abstract reasoning originally inspired earlier work involving
hierarchical behavior-space search agents represent planned behaviors multiple
levels abstraction (Durfee & Montgomery, 1991). Distributed protocols used decide
level abstraction coordination needed resolve conflicts there. approach capitalizes
domains resources abstracted naturally. earlier work viewed
limited, special case work presented here. justified intuitively limited
experiments analyses.
Corkill studied interleaved planning merging distributed version NOAH planner
(1979). recognized that, conditions affected abstract plan operator
might unknown refinement, deal overall effects preconditions
hold matter operator refined captured used identify resolve
conflicts. recognized choices refinement synchronization choices
abstract levels could lead unresolvable conflicts deeper levels, backtracking could
necessary. work directed toward avoiding backtracking using summary information
guide search.

502

fiA BSTRACT R EASONING P LANNING C OORDINATION

closer relation approach, Pappachan shows interleave hierarchical plan coordination plan execution cooperative agents using online iterative constraint relaxation
(OICR) algorithm (Pappachan, 2001). Like approach, coordination achieved higher
levels abstraction flexible execution, agents decompose tasks lower
levels tighter coordination improve plan quality. OICR approach tailored toward
interleaving coordination flexible execution price completeness coordination
algorithm presented aimed complete interleaved coordination planning price
potentially delaying execution due backtracking.
planning research, hierarchical plans often represented Hierarchical Task Networks (HTNs, Erol et al., 1994a), planners NOAH (Sacerdoti, 1977), NonLin (Tate,
1977), SIPE-2 (Wilkins, 1990), O-Plan (Currie & Tate, 1991), UMCP (Erol et al., 1994b), SHOP 2
(Nau, Au, Ilghami, Kuter, Murdock, Wu, & Yaman, 2003) use search combinations
alternative courses action achieve goals within particular context. actions may partially ordered, giving timing flexibility execution (Wilkins, 1990; Currie & Tate, 1991).
CH P representation extends HTN include temporal extent partial orderings expressed
constraints starting ending timepoints action.
Yang presented method (similar summarization) preprocessing plan hierarchy
order able detect unresolvable conflicts abstract level planner could backtrack inconsistent search spaces (Yang, 1990). corresponds use MightSomeWay
Section 5.2. However, approach requires decomposition hierarchy modeled
abstract operator unique main subaction preconditions effects
parent. avoid restriction analyzing subplans conditions ordering constraints
automatically compute parents summary conditions.
approach focused resolving conflicts among agents, Cox Durfee (2003)
used summary information exploit synergistic interactions. idea using summary information identify overlapping effects help agents skip actions whose effects
achieved others. Thangarajah, Padgham, Winikoff (2003) used summary information
rescheduling execution. representations actually subsumed ours,
work significantly postdates first reporting work paper (Clement & Durfee, 1999).
DSIPE (desJardins & Wolverton, 1999) distributed version SIPE -2 (Wilkins, 1990)
hierarchical planning system. way agents use summary information reduce
communication states common constraints, DSIPE filters conditions
communicated among planners using irrelevance reasoning (Wolverton & desJardins, 1998).
DPOCL (Decompositional Partial-Order Causal-Link) planner (Young et al., 1994) adds
action decomposition SNLP (McAllester & Rosenblitt, 1991). Like HTN planners, preconditions high level effects added abstract tasks order help planner resolve
conflicts decomposition. addition, causal links specified decomposition schemas
isolate external preconditions DPOCL must satisfy. However, conditions
causal links necessarily capture external conditions abstract tasks, planner
find solutions abstract levels requires tasks completely decomposed. addition, DPOCL cannot determine abstract plan unresolvable conflicts (MightSomeWay)
may effects hidden decompositions yet undetailed tasks could achieve
open preconditions. deriving summary conditions automatically using algorithms determining causal link information (e.g. must-achieve), planning/coordination algorithm find

503

fiC LEMENT, URFEE , & BARRETT

reject abstract plans search without adding burden domain expert specify redundant conditions causal links abstract tasks.
Like DPOCL, TMS (a framework Task Analysis, Environment Modeling, Simulation)
allows domain modeler specify wide range task relationships (Decker, 1995).
work offers quantitative methods analyzing simulating agents well interactions.
interactions represented discovered using summary conditions,
discover information analysis rather depending model developer
predefine interactions.
Groszs shared plans model collaboration (1996) presents theory modeling multiagent
belief intention. shared plans work directed toward cooperative agents, represents
action hierarchies provides mental models higher level represented article.
However, use analysis summary information complements Groszs work providing
way automatically represent efficiently reason intentions agents multiple levels
abstraction. Future work needed understand summary information bridged
mental states agents exploit techniques employed shared plans work based
BDI (belief-desire-intention) models agents (Rao & Georgeff, 1995).
analysis hierarchical planning (Yang, 1997) explains that, case interacting subgoals, certain structures hierarchy minimize interactions reduce worst case
planning complexity exponentially. However, complexity analyses Section 6 explain using summary information achieve exponential performance gains addition achieved
restructuring plan hierarchies according Yangs analysis limiting decomposition task
hierarchies compressing information manipulated coordinator, planner, scheduler.
SHOP 2 (Nau et al., 2003) HTN planner uses domain translation technique reason
durative action. however express temporal extent way planner
given here. model differs supports ordering relationships endpoints well
conditions effects actions execution. may domain translation
could achieve expression similar constraints solutions systems,
formal model expressions HTN planning.
SIADEX (Castillo et al., 2006) another HTN planner handles temporal extent use
expressive simple temporal networks (Dechter, Meiri, & Pearl, 1991). performance
improvement techniques reported SIADEX temporal reasoning specific HTNs.
Thus, work complementary ours. However, work needed understand
summary information exploited conjunction forward expansion approach
SHOP 2 SIADEX use perform competitively planning competition problems.
Another class hierarchical planners based ABSTRIPS (Sacerdoti, 1974) introduces conditions different levels abstraction critical conflicts handled higher levels
abstraction less important (or easier) conflicts resolved later lower levels.
approach similarly resolves conflicts abstract levels, planning decisions may consistent
conditions lower levels resulting backtracking. Summary information provides means
make sound complete decisions abstract levels without need decompose check
consistency lower levels. However, resolving conflicts based criticality still improve
performance complement approach.
Allens temporal planner (1991) uses hierarchical representations tasks could applied
reasoning concurrent actions multiple agents. However, exploit hierarchy
reasoning abstraction levels separately generates plan proving consistency
504

fiA BSTRACT R EASONING P LANNING C OORDINATION

collective constraints. Allens model temporal plans (1983) subsequent work interval
point algebra (Vilain & Kautz, 1986) strongly influenced hierarchical task representation
algorithms reason them.
also many, many models theories concurrency. older examples include
automata representations, Petri nets Hoares theory communicating sequential processes
(Glabbeek, 1997). also many temporal logics computational tree logic (CTL,
Emerson & Halpern, 1985) allow modal expressions proposition holding
possible worlds time, time, next state, eventually,
proposition holds. Another language specifying manufacturing processes process
standardized 10 years (Bock, 1996; Schlenoff, Knutilla, & Ray, 2006). Many
logics could used define summary conditions relations like MightSomeWay. However, found logics awkward representing inconditions defining summary
conditions terminology used article simplifies definitions.
Model checking uses temporal logics verify different properties system models, software,
hardware (such correctness, deadlock-free, convergence). fact, model checking
planning algorithms used interchangeably problems (e.g., Giunchiglia &
Traverso, 1999). context model checking, summary information set properties
(akin specifiable CTL) system model (as planning domain) summarize system
variable requirements (conditions) assignments (effects). Thus, model checking algorithm
could use summary information efficiently identify resolve potential requirement violations/bugs (condition conflicts) deadlock (resource conflicts) system model operation
(planning/scheduling problem instantiations).

9. Conclusion
article provides formalization Hierarchical Task Network planning that, unlike UMCP
formalism (Erol et al., 1994b), includes actions temporal extent. introduce sound
complete algorithm used generate plan, coordinate group agents hierarchical plans, interleave planning coordination.
algorithms summarizing propositional state metric resource conditions effects
abstract levels mechanisms reason summary information facilitate
construction planning coordination systems reason plans multiple levels
abstraction. mechanisms reasoning summary information determine whether
task (at level abstraction) must may achieve, clobber, undo condition another task
partial order constraints endpoints tasks. Built mechanisms, mechanisms
determine whether group agents decompose execute set partially ordered abstract
tasks way (CanAnyWay), might decompose execute way (MightSomeWay),
cannot execute consistently way (MightSomeWay).
algorithms enable planning system find solutions multiple levels abstraction
without needing fully detail task hierarchy. abstract solutions support flexible execution
remaining uncommitted alternative methods selected runtime, based
circumstances, achieve plan subgoals.
complexity analyses experiments different problem domains quantified benefits using summary information refinement planning local search scheduling algorithm.


potential doubly exponential speedup O(kb b b2(di) ) k ways resolve conflict,

505

fiC LEMENT, URFEE , & BARRETT

hierarchy branching factor b, depth hierarchy d, abstract solution depth i. exponential speedup obtained abstract solutions found, fewer summary conditions
abstract levels, alternative decomposition choices lead varying numbers threats.
conditions exponential improvement significant relaxation compared prior work,
performance improvement greater.
domain modeler run summarization algorithms offline library plan hierarchies
summary information available coordination planning set goal tasks
supported library. Using algorithms reasoning summary information, agents
discover coordinate states resources must coordinate/negotiate. Communicating summary information different levels abstraction reduces
communication costs exponentially conditions similar reducing computation time.
use summary information local search planner (like ASPEN, Section 6.3) another
contribution work. strength local search algorithms ability efficiently reason
large numbers tasks constraints metric resources, state variables, complex
resource classes. integrating algorithms reasoning summarized propositional state
metric resource constraints heuristic local search planner/scheduler, enable scalable
planning systems scale even larger problem domains. use summary information
different style planner demonstrates applicability abstract reasoning improving
performance different kinds planning (and plan coordination) systems.
Future work needed evaluate use summary information planning
scheduling systems wider classes problems requiring expressive representations
resources temporal constraints. Already, approach exploiting cooperative action
among agents based summary information developed (Cox & Durfee, 2003).
promising approaches include abstracting plan information, probabilistic conditions
effects classes resources states (e.g. location regions sub-regions). work
also needed understand communicate summary information distributed
planning system.

Acknowledgments
authors wish thank Pradeep Pappachan, Gregg Rabideau, Russell Knight help
implementation. also thank anonymous reviewers many valuable suggestions.
work performed Jet Propulsion Laboratory, California Institute Technology,
contract National Aeronautics Space Administration, University Michigan
supported part DARPA (F30602-98-2-0142).

Appendix A: Algorithms Computing Interval Relations
algorithms determining whether defined relations hold summary conditions
plans P use point algebra constraint table (Vilain & Kautz, 1986). point algebra
table constructed interval endpoints corresponding executions plans P;
row column p ts (e) (start endpoint execution e p) p+ f (e) (finish
endpoint) added plan p P. cell table gives time point constraint
row column <, , =, , >, 6=, <=>, empty. <=> means

506

fiA BSTRACT R EASONING P LANNING C OORDINATION

p
p+
p0
p0 +

p
=
>
>
>

p+
<
=
<
<

p0
<
>
=
>

p0 +
<
>
<
=

Table 1: Point algebra table p contains p0
p
p+
p0
p0 +

p
=
>

>

p+
<
=
<=>
<=>

p0

<=>
=
>

p0 +
<
<=>
<
=

Table 2: Point algebra table p p0
points unconstrained. cell empty, allowed temporal relations, indicating
inconsistency. Table 1 shows point algebra table plans p p0 constrained
ps execution contains p0 . Table 2 shows table start p constrained
earlier start p0 . transitive closures constraint relations. Table 1
computed Table 2 constraining p+ < p0 + (by putting < cell row p+
column p0 + ) computing transitive closure, O(n2 ) algorithm n points (Vilain &
Kautz, 1986). transitive closure computed, constraints point
point looked constant time.
Similarly, constraints order P added table, transitive closure
computed get constraints entailed order. needs done
P order determine achieve clobber relationships defined next section.
determine plan q ps subplans temporally ordered always-[ f irst,last]
[q , q+ ] constrained [before, after] equal points point algebra table
ps subplans. done looking entry row [q , q+ ] checking see
constraint [<, >], =, [, ]. case, q not-always-[ f irst,last].
q always-not-[ f irst,last] row [q , q+ ] entry [>, <]
constraint; otherwise, sometimes-[ f irst,last].
interval i0 covered set intervals = {i1 , i2 , . . . , ik } interval
found intersects i0 intersects nothing I. particular covering problem describes
intervals terms partial order endpoints, represent intervals point algebra
table. algorithm covering problem check see i0 covered looking
pairs intervals see overlap. i0 covered (1) either intervals meet either
+

0 i0 , (2) intervals endpoint contained i0
meet opposite endpoint another interval endpoint i0 , (3) intervals
overlapping i0 . Otherwise, i0 covered. Examples given Figure 34.

507

fiC LEMENT, URFEE , & BARRETT

a)
=

=

B

=
C

c)

E

b)



F
=
G



H



Figure 34: a) Interval covered B, C, D. b) E covered F, G, H. c)
covered.

Appendix B: Algorithms Must/May Asserting Summary Conditions
describe algorithms determining temporal plan relationships based summary information. used build algorithms determine whether plan must may achieve,
clobber, undo condition another particular ordering constraints.
definitions algorithms throughout section given within context set
plans P corresponding set summary information Psum , set ordering constraints order,
set histories H including histories E(h) includes execution e
plan P es subexecutions, E(h) satisfies constraints order. concerned
ordering plan execution intervals timing conditions. themselves,
anything whether conditions may need met must met plan
execution.
First, order determine whether abstract plan executions achieve, clobber, undo
conditions others, agent needs able reason summary conditions asserted
required met. Ultimately, agent needs able determine whether partial ordering
abstract plans succeed, may case agents action fails assert summary
condition required action another agent. Therefore, formalize means
action attempt assert summary condition require summary condition
met. definitions rely linking summary condition plan CHiP conditions
summarizes subplans plans decompositions. Thus, first define means
summary condition summarize conditions.
Definition 14
summary condition c summarizes condition ` condition set conds
plan p iff c added procedure deriving summary information
summary condition set p0 ; ` = `(c); either c added ` condition
set conds p = p0 , c added summary condition subplan p0
summarizes ` conds p.
example, at(bin1, A) precondition start move plan moving part bin1
machine M1 (as given Section 2.2). deriving summary conditions start move,

508

fiA BSTRACT R EASONING P LANNING C OORDINATION

at(bin1, A) added summary preconditions. Thus, summary precondition at(bin1,
A)MuF summarizes at(bin1, A) preconditions start move.
Definition 15
execution e p requires summary condition c met iff c
summary condition ps summary information; condition ` condition
set conds p0 summarized c; f irst(c), = ts (e); last(c), = f (e);
always(c), within (ts (e),t f (e)); sometimes(c), execution
subplan p d(e) requires summary condition c0 met t, c0
summarizes ` conds p0 .
So, basically, execution requires summary condition met whenever conditions
summarizes required. execution build G summary precondition at(A,M1 tray1).
execution requires summary condition met ts (build G) at(A, M1 tray1)
precondition build Gs first subplan summarized build Gs summary precondition.
Definition 16
execution e p attempts assert summary condition c iff c
summary condition ps summary information; condition ` condition
set conds p0 summarized c; f irst(c); always(c), smallest
interval ts (e) start end execution follows ts (e);
last(c), = f (e); sometimes(c), execution subplan p d(e)
attempts assert summary condition c0 t; c0 summarizes ` conds p0 .
say execution attempts assert summary condition asserting condition
fail due simultaneous assertion negation condition. Like example
requiring summary condition, executions build G, produce G M1, produce H
assert summary postconditions M1 becomes available f (build G).
order agents determine potential interactions among abstract plans (such clobbering achieving), need reason summary condition asserted one plan
relation asserted required another. Based interval point algebra constraints
set abstract plans, agent specifically would need able determine whether plan
would assert summary condition time another plan requires asserts summary
condition state variable. addition, reason clobbering inconditions, agent
would need determine summary condition would asserted time summary incondition c required (asserted c). Agents also need detect summary postcondition
would asserted time another summary postcondition c (asserted c).
consider cases executions attempt assert summary in- postcondition
time incondition asserted cases, clobber relations already
detected executions always require summary inconditions attempt assert.
example, equip M1 attempted assert incondition M1 unavailable
time build G attempted assert postcondition M1 available, incondition would
clobbered postcondition.
case ordering constraints allow alternative synchronizations abstract
plans, assertions summary conditions may come different orders. Therefore, formalize
must-assert may-assert determine relationships must may occur respectively.
mentioned beginning Section 9, use must may based disjunctive orderings existence summary conditions different decompositions.
509

fiC LEMENT, URFEE , & BARRETT

1
2
3
4

5
6
7

8
9

10
11

12
13
14
15

16
17
18
19

c0 post(p0 )
last


F
?
c0 in(p0 )
always


F
c0 post(p0 )
last

F
c0 in(p0 )
always

F
c0 post(p0 )
last


F
F
c0 in(p0 )
always


F
F

p0 must-assert c0 c
order must impose
constraints

p0 must-assert c0 c
order must impose
constraints

p0 + p
p0 + p
p0 + p
p0 + p

p0 + < p
p0 + < p
p0 + < p
p0 + < p


F
?
c in(p)
always
?
?

p0 < p
p0 p
f alse

p0 < p
p0 p
f alse

p0 + p
p0 + p

p0 + p
p0 + p

?
?
c post(p)
last

F

F

p0 p
f alse

p0 < p
f alse

p0 + p+
p0 + p
p0 + p+
p0 + p

p0 + < p+
p0 + p
p0 + p+
p0 + p


F

F

p0 < p+
p0 p
f alse
f alse

p0 < p+
p0 p
f alse
f alse

c pre(p)
f irst

F
?
?

Table 3: Table must-assert by/before algorithm
following definitions algorithms must- may-assert, assume c c0 summary
conditions plans P.
Definition 17
p0 P must-assert c0 [by, before] c iff histories h H
e top-level execution E(h) p P requires c met t,
e0 top-level execution p0 E(h), 0 e0 attempts assert c0
0 , [t 0 t, 0 < t].
must-assert algorithm described Table 3. p0 must-assert c0 c iff order entails
relationship given row corresponding type timing two conditions. Rows
table indicate timing summary conditions constraints order must dictate
must-assert true. F table indicate whether timing column true
false condition. ? means timing doesnt matter condition case.
example, row 9 says case c0 sometimes (last) postcondition p0 , c
incondition p timing, order must require end p0 start
p order p0 must-assert c0 time c asserted required.

510

fiA BSTRACT R EASONING P LANNING C OORDINATION

1
2
3
4

5
6

7
8
9
10

11
12

13
14
15
16

17
18

c0 post(p0 )
last


F
F
c0 in(p0 )
always
?
?
c0 post(p0 )
last


F
F
c0 in(p0 )
always
?
?
c0 post(p0 )
last


F
F
c0 in(p0 )
always
?
?

p0 may-assert c0 c
order cannot impose
constraints

p0 may-assert c0 c
order cannot impose
constraints

p0 + > p
p0 + p+
p0 p
p0 p+

p0 + p
p0 + p+
p0 p
p0 p+


F
c in(p)
always

F

F

p0 p
p0 p+

p0 p
p0 p+

p0 + > p
p0 + p+
p0 p
p0 p+

p0 + > p
p0 + p+
p0 p
p0 p+


F
c post(p)
last

F

F

p0 > p
p0 p+

p0 p
p0 p+

p0 + > p+
p0 + p+
p0 p+
p0 p+

p0 + p+
p0 + p+
p0 p+
p0 p+


F

p0 p+
p0 p+

p0 p+
p0 p+

c pre(p)
f irst

F

F

Table 4: Table may-assert by/before algorithm

1
2
3
4

5
6
7
8

c0 post(p0 )
last


F
F
c0 in(p0 )
always


F
F

p0 must-assert c0 c
order must impose
constraints

c in(p)
always

F

F

p0 + > p p0 + < p+
f alse
p0 p p0 + p+
f alse


F

F

p0 p p0 < p+
f alse
f alse
f alse

c0 post(p0 )
last


F
F
c0 in(p0 )
always


F
F

c in(p)
always

F

F

p0 + p
p0 + p
p0 + p
p0 + p






p0 + p+
p0 + p+
p0 p+
p0 p+


F

F

p0 + p
p0 + p
p0 + p
p0 + p






p0 p+
p0 p+
p0 p+
p0 p+

Table 5: Table must/may-assert algorithm

511

p0 may-assert c0 c
order cannot impose
constraints

fiC LEMENT, URFEE , & BARRETT

1
2
3
4

c0 post(p0 )
last


F
F

c post(p)
last

F

F

p0 must-assert c0 c
order must impose
constraints
p0 + = p+
f alse
f alse
f alse

c0 post(p0 )
last


F
F

c post(p)
last

F

F

p0 may-assert c0 c
order cannot impose
constraints
p0 + 6= p+
p p0 + p+
p0 + p+ p0 p+
p0 + p p0 p+
p0 +

Table 6: Table must/may-assert algorithm
definitions algorithms assert relationships similar. Tables 4-6 describe
logic algorithms. may relationships, algorithm returns true iff none
corresponding ordering constraints table imposed (can deduced from) order.
illustrate relationships example Figure 8. Figure 8a agents plans
unordered respect other. Part G produced either machine M1 M2 depending potential decompositions produce G plan. produce G must-assert c0 = must,
last available(G) c = must, f irst available(G) summary preconditions move G
matter plans decomposed (for executions histories plans
ordering constraints figure), execution produce G attempts assert c0 execution move G requires c met. algorithm verifies finding
end produce G ordered start move G (row 1 Table 3). also case
equip M2 tool may-assert c0 = must, last available(M2) c = may, sometimes available(M2)
summary preconditions produce G two plans unordered respect
other, history equip M2 tool precede produce G. algorithm finds
true since equip M2 constrained start start produce G (row 2 Table 4).
Figure 8b, move tool may-assert c0 = must, last f ree(transport1) c = may, sometimes
f ree(transport1) produce Gs summary inconditions history move tool attempts assert c0 time produce G using transport1 move part machine
M2. addition, equip M2 tool must-assert c0 = must, last available(M2) c = may, last
available(M2) produce Gs summary postconditions equip M2 tool attempts assert
c0 time produce G requires c met. end Section 3.3 gives examples.

References
Allen, J., Kautz, H., Pelavin, R., & Tenenberg, J. (1991). Reasoning plans. Morgan Kaufmann.
Allen, J. F. (1983). Maintaining knowledge temporal intervals. Communications ACM,
26(11), 832843.
Allen, J. F., & Koomen, J. A. (1983). Planning using temporal world model. Proceedings
International Joint Conference Artificial Intelligence, pp. 741747.
Bock, C. (1996). Unified process specification language: Requirements modeling process. Tech.
rep. NISTIR 5910, National Institute Standards Technology.
Castillo, L., Fdez-Olivares, J., Garca-Perez, O., & Palao, F. (2006). Efficiently handling temporal
knowledge HTN planner. 16th International Conference Automated Planning
512

fiA BSTRACT R EASONING P LANNING C OORDINATION

Scheduling (ICAPS-06), pp. 6372. AAAI.
Chien, S., Knight, R., Stechert, A., Sherwood, R., & Rabideau, G. (2000a). Using iterative repair
improve responsiveness planning scheduling. Proceedings International
Conference AI Planning Scheduling, pp. 300307.
Chien, S., Rabideu, G., Knight, R., Sherwood, R., Engelhardt, B., Mutz, D., Estlin, T., Smith, B.,
Fisher, F., Barrett, T., Stebbins, G., & Tran, D. (2000b). Automating space mission operations
using automated planning scheduling. Proc. SpaceOps.
Clement, B. (2002). Abstract Reasoning Multiagent Coordination Planning. Ph.D. thesis,
University Michigan, Ann Arbor.
Clement, B., & Durfee, E. (1999). Top-down search coordinating hierarchical plans
multiple agents. Proceedings International Conference Autonomous Agents.
Corkill, D. (1979). Hierarchical planning distributed environment. Proceedings
International Joint Conference Artificial Intelligence, pp. 168175.
Cox, J. S., & Durfee, E. H. (2003). Discovering exploiting synergy hierarchical planning agents. Proceedings International Joint Conference Autonomous Agents
MultiAgent Systems, pp. 281288.
Currie, K., & Tate, A. (1991). O-Plan: open planning architecture. Artificial Intelligence, 52,
4986.
Dechter, R., Meiri, I., & Pearl, J. (1991). Temporal constraint networks. Artificial Intelligence, 49,
6195.
Decker, K. (1995). Environment centered analysis design coordination mechanisms. Ph.D.
thesis, University Massachusetts.
desJardins, M., & Wolverton, M. (1999). Coordinating distributed planning system. AI Magazine,
20(4), 4553.
Drabble, B., & Tate, A. (1994). use optimistic pessimistic resource profiles inform
search activity based planner. Artificial Intelligence Planning Systems, pp. 243248.
Durfee, E. H., & Montgomery, T. A. (1991). Coordination distributed search hierarchical
behavior space. IEEE Transactions Systems, Man Cybernetics, 21(6), 13631378.
Emerson, E., & Halpern, J. Y. (1985). Decision procedures expressiveness temporal logic
branching time. Journal Computer System Sciences, 30(1), 124.
Ephrati, E., & Rosenschein, J. (1994). Divide conquer multi-agent planning. Proceedings
National Conference Artificial Intelligence, pp. 375380.
Erol, K., Hendler, J., & Nau, D. (1994a). Semantics hierarchical task-network planning. Tech.
rep. CS-TR-3239, University Maryland.
Erol, K., Nau, D., & Hendler, J. (1994b). UMCP: sound complete planning procedure
hierarchical task-network planning.. Proceedings International Conference AI
Planning Scheduling.
Fagin, R., Halpern, J., Moses, Y., & Vardi, M. (1995). Reasoning knowledge. MIT Press.
Firby, J. (1989). Adaptive Execution Complex Dynamic Domains. Ph.D. thesis, Yale University.
513

fiC LEMENT, URFEE , & BARRETT

Georgeff, M. P. (1983). Communication interaction multiagent planning. Proceedings
National Conference Artificial Intelligence, pp. 125129.
Georgeff, M. P. (1984). theory action multiagent planning. Proceedings National
Conference Artificial Intelligence, pp. 121125.
Georgeff, M. P., & Lansky, A. (1986). Procedural knowledge. Proceedings IEEE, 74(10), 1383
1398.
Giunchiglia, F., & Traverso, P. (1999). Planning model checking. Proceedings 5th
European Conference Planning, pp. 120, London, UK. Springer-Verlag.
Glabbeek, R. v. (1997). Notes methodology CCS CSP. Theoretical Computer Science,
177(2), 329349. Originally appeared Report CS-R8624, CWI, Amsterdam, 1986.
Grosz, B., & Kraus, S. (1996). Collaborative plans complex group action. Artificial Intelligence,
86, 269358.
Huber, M. (1999). JAM: BDI-theoretic mobile agent architecture. Proceedings International Conference Autonomous Agents, pp. 236243.
Knight, R., Rabideau, G., & Chien, S. (2000). Computing valid intervals collections activities shared states resources. Proceedings International Conference AI
Planning Scheduling, pp. 600610.
Knoblock, C. (1991). Search reduction hierarchical problem solving. Proceedings
National Conference Artificial Intelligence, pp. 686691.
Korf, R. (1987). Planning search: quantitative approach. Artificial Intelligence, 33, 6588.
Laborie, P., & Ghallab, M. (1995). Planning sharable resource constraints. Proceedings
International Joint Conference Artificial Intelligence, pp. 16431649.
Lansky, A. (1990). Localized search controlling automated reasoning. Proceedings
DARPA Workshop Innovative Approaches Planning, Scheduling Control, pp. 115
125.
Lee, J., Huber, M. J., Durfee, E. H., & Kenny, P. G. (1994). UMPRS: implementation
procedural reasoning system multirobot applications. Proceedings AIAA/NASA
Conference Intelligent Robotics Field, Factory, Service, Space, pp. 842849.
McAllester, D., & Rosenblitt, D. (1991). Systematic nonlinear planning. Proceedings
National Conference Artificial Intelligence, pp. 634639.
Muscettola, N. (1994). HSTS: Integrating planning scheduling. Intelligent Scheduling, 169212.
Nau, D., Au, T., Ilghami, O., Kuter, U., Murdock, J., Wu, D., & Yaman, F. (2003). SHOP2:
HTN planning system. Journal Artificial Intelligence Research, 20, 379404.
Pappachan, P. (2001). Coordinating Plan Execution Dynamic Multiagent Environments. Ph.D.
thesis, University Michigan, Ann Arbor.
Pratt, V. R. (1976). Semantical considerations floyd-hoare logic. 17th Annual IEEE Symposium Foundations Computer Science, pp. 109121.
Rao, A. S., & Georgeff, M. P. (1995). BDI-agents: theory practice. Proceedings
International Conference Multi-Agent Systems, San Francisco.
514

fiA BSTRACT R EASONING P LANNING C OORDINATION

Sacerdoti, E. (1974). Planning hierarchy abstraction spaces. Artificial Intelligence, 5(2),
115135.
Sacerdoti, E. D. (1977). Structure Plans Behavior. Elsevier-North Holland.
Schlenoff, C., Knutilla, A., & Ray, S. (2006). Interprocess communication process specification language. Tech. rep. NISTIR 7348, National Institute Standards Technology.
Tate, A. (1977). Generating project networks. Proceedings International Joint Conference
Artificial Intelligence, pp. 888893.
Thangarajah, J., Padgham, L., & Winikoff, M. (2003). Detecting & avoiding interference
goals intelligent agents. Proceedings International Joint Conference Artificial
Intelligence, pp. 721726.
Tsuneto, R., Hendler, J., & Nau, D. (1997). Space-size minimization refinement planning.
Proceedings European Conference Planning.
Tsuneto, R., Hendler, J., & Nau, D. (1998). Analyzing external conditions improve efficiency
HTN planning. Proceedings National Conference Artificial Intelligence, pp.
913920.
Vilain, & Kautz, H. (1986). Constraint propagation algorithms temporal reasoning. Proceedings National Conference Artificial Intelligence, pp. 377382.
Weld, D. (1994). introduction least commitment planning. AI Magazine, 15(4), 2761.
Wilkins, D. E. (1990). AI planners solve practical problems?. Computational Intelligence,
6(4), 232246.
Wolverton, M., & desJardins, M. (1998). Controlling communication distributed planning using
irrelevance reasoning. Proceedings National Conference Artificial Intelligence,
pp. 868874.
Yang, Q. (1990). Formalizing planning knowledge hierarchical planning. Computational Intelligence, 6(1), 1224.
Yang, Q. (Ed.). (1997). Intelligent Planning: Decomposition Abstraction Based Approach.
Springer.
Young, M., Pollack, M., & Moore, J. (1994). Decomposition causality partial-order planning.
Proceedings International Conference AI Planning Scheduling, pp. 188193.

515

fiJournal Artificial Intelligence Research 28 (2007) 1-48

Submitted 4/06; published 1/07

Cutset Sampling Bayesian Networks
Bozhena Bidyuk
Rina Dechter

bbidyuk@ics.uci.edu
dechter@ics.uci.edu

School Information Computer Science
University California Irvine
Irvine, CA 92697-3425

Abstract
paper presents new sampling methodology Bayesian networks samples
subset variables applies exact inference rest. Cutset sampling
network structure-exploiting application Rao-Blackwellisation principle sampling
Bayesian networks. improves convergence exploiting memory-based inference algorithms. also viewed anytime approximation exact cutset-conditioning
algorithm developed Pearl. Cutset sampling implemented efficiently
sampled variables constitute loop-cutset Bayesian network and, generally,
induced width networks graph conditioned observed sampled variables bounded constant w. demonstrate empirically benefit scheme
range benchmarks.

1. Introduction
Sampling common method approximate inference Bayesian networks.
exact algorithms impractical due prohibitive time memory demands, often
feasible approach offers performance guarantees. Given Bayesian network
variables X = {X1 , ..., Xn }, evidence e, set samples {x(t) } P (X|e),
estimate f(X) expected value function f (X) obtained generated
samples via ergodic average:
1X
f (x(t) ) ,
(1)
E[f (X)|e] f(X) =

number samples. f(X) shown converge exact value
increases. central query interest Bayesian networks computing posterior
marginals P (xi |e) value xi variable Xi , also called belief updating.
query, f (X) equals -function, equation reduces counting fraction
occurrences Xi = xi samples,
P (xi |e) =
(t)


1X
(xi |x(t) ) ,


(2)

t=1

(xi |x(t) )=1 iff xi = xi (xi |x(t) )=0 otherwise. Alternatively, mixture estimator used,

1X
(t)
P (xi |xi ) ,
(3)
P (xi |e)] =

t=1

c
2007
AI Access Foundation. rights reserved.

fiBidyuk & Dechter

(t)

xi = x(t) \xi .
significant limitation sampling, however, statistical variance increases
number variables network grows therefore number samples
necessary accurate estimation increases. paper, present sampling scheme
Bayesian networks discrete variables reduces sampling variance sampling
subset variables, technique also known collapsing Rao-Blackwellisation.
fundamentals Rao-Blackwellised sampling developed Casella Robert
(1996) Liu, Wong, Kong (1994) Gibbs sampling MacEachern, Clyde,
Liu (1998) Doucet, Gordon, Krishnamurthy (1999) importance sampling.
Doucet, de Freitas, Murphy, Russell (2000) extended Rao-Blackwellisation Particle
Filtering Dynamic Bayesian networks.
basic Rao-Blackwellisation scheme described follows. Suppose partition space variables X two subsets C Z. Subsequently, re-write
function f (X) f (C, Z). generate samples distribution P (C|e) compute E[f (C, Z)|c, e], perform sampling subset C only, generating samples
c(1) , c(2) , ..., c(T ) approximating quantity interest
E[f (C, Z)|e] = EC [EZ [f (C, Z)|c, e]] f(X) =


1X
EZ [f (C, Z)|c(t) , e] .


(4)

t=1

posterior marginals estimates cutset variables obtained using expression similar Eq.(2),
1X
(ci |c(t) ) ,
(5)
P (ci |e) =


using mixture estimator similar Eq.(3),
P (ci |e) =

1X
(t)
P (ci |ci , e) .


(6)

Xi X\C, E, E[P (Xi |e)] = EC [P (Xi |c, e)] Eq.(4) becomes
P (Xi |e) =

1X
P (Xi |c(t) , e) .


(7)

Since convergence rate Gibbs sampler tied maximum correlation
two samples (Liu, 2001), expect improvement convergence rate
sampling lower dimensional space since 1) highly-correlated variables may
marginalized 2) dependencies variables inside smaller set likely
weaker variables farther apart sampling distributions
smoothed out. Additionally, estimates obtained sampling lower dimensional
space expected lower sampling variance therefore require fewer samples
achieve accuracy estimates. hand, cost generating
sample may increase. Indeed, principles Rao-Blackwellised sampling
applied classes probabilistic models specialized structure (Kong, Liu,
& Wong, 1994; Escobar, 1994; MacEachern, 1994; Liu, 1996; Doucet & Andrieu, 2001;
Andrieu, de Freitas, & Doucet, 2002; Rosti & Gales, 2004).
2

fiCutset Sampling Bayesian Networks

contribution paper presenting general, structure-based scheme
applies Rao-Blackwellisation principle Bayesian networks. idea exploit
property conditioning subset variables simplifies networks structure, allowing efficient query processing exact algorithms. general, exact inference variable
elimination (Dechter, 1999a, 2003) join-tree algorithms (Lauritzen & Spiegelhalter, 1988;
Jensen, Lauritzen, & Olesen, 1990) time space exponential induced-width w
network. However, subset variables assigned (i.e., conditioned upon)
induced-width conditioned network may reduced.
idea cutset sampling choose subset variables C conditioning
C yields sparse enough Bayesian network small induced width allow exact
inference. Since sample assignment cutset variables, efficiently generate
new sample cutset variables conditioned network computation
P (c|e) P (Xi |c, e) bounded. particular, sampling set C cuts cycles
network (i.e., loop-cutset), inference conditioned network becomes
linear. general, C w-cutset, namely subset nodes assigned,
induced-width conditioned network w, time space complexity computing
next sample O(|C| N dw+2 ) maximum domain size N = |X|.

idea exploiting properties conditioning subset variables first proposed exact belief updating context cutset-conditioning (Pearl, 1988).
scheme requires enumerating instantiations cutset variables. Since number
instances exponential size cutset |C|, sampling cutset space may
right compromise size cutset big. Thus, sampling cutset
also viewed anytime approximation cutset-conditioning approach.
Although Rao-Blackwellisation general cutset sampling particular applied context sampling algorithm, introduce principle context Gibbs sampling (Geman & Geman, 1984; Gilks, Richardson, & Spiegelhalter, 1996;
MacKay, 1996), Markov Chain Monte Carlo sampling method Bayesian networks.
Extension sampling approach graphical models, Markov
networks, straight forward. recently demonstrated idea incorporated importance sampling (Bidyuk & Dechter, 2006).
paper defines analyzes cutset sampling scheme investigates empirically
trade-offs sampling exact computation variety randomly generated
networks grid structure networks well known real-life benchmarks CPCS
networks coding networks. show cutset sampling converges faster pure
sampling terms number samples, dictated theory, also almost always
time-wise cost effective benchmarks tried. also demonstrate applicability
scheme deterministic networks, Hailfinder network coding networks,
Markov Chain non-ergodic Gibbs sampling converge.
Section 2 provides background information. Specifically, section 2.1 introduces Bayesian
networks, section 2.2 reviews exact inference algorithms Bayesian networks, section 2.3 provides background Gibbs sampling. contribution paper presenting
cutset sampling starts section 3. Section 4 presents empirical evaluation cutset
sampling. also present empirical evaluation sampling variance resulting standard error based method batch means (for details, see Geyer, 1992).
3

fiBidyuk & Dechter

section 5, review previous application Rao-Blackwellisation section 6 provides
summary conclusions.

2. Background
section, define essential terminology provide background information
Bayesian networks.
2.1 Preliminaries
use upper case letters without subscripts, X, denote sets variables
lower case letters without subscripts denote instantiation group variables (e.g.,
x indicates variable set X assigned value). use upper case letter
subscript, Xi , denote single variable lower case letter
subscript, xi , denote instantiated variable (e.g., xi denotes arbitrary value
domain Xi means Xi = xi ). D(Xi ) denotes domain variable Xi .
superscript subscripted lower case letter would used distinguish different specific
values variable, i.e., D(Xi ) = {x1i , x2i , ...}. use x denote instantiation
set variables x = {x1 , ..., xi1 , xi , xi+1 , ..., xn } xi = x\xi denote x element
xi removed. Namely, xi = {x1 , x2 , ..., xi1 , xi+1 , ..., xn }.
Definition 2.1 (graph concepts) directed graph pair D=<V ,E>, V =
{X1 , ..., Xn } set nodes E = {(Xi , Xj )|Xi , Xj V } set edges. Given
(Xi , Xj ) E, Xi called parent Xj , Xj called child Xi . set
Xi parents denoted pa(Xi ), pai , set Xi children denoted ch(Xi ),
chi . family Xi includes Xi parents. moral graph directed graph
undirected graph obtained connecting parents nodes
removing arrows. cycle-cutset undirected graph subset nodes that,
removed, yields graph without cycles. loop directed graph subgraph
whose underlying graph cycle. directed graph acyclic directed loops.
directed graph singly-connected (also called poly-tree), underlying undirected
graph cycles. Otherwise, called multiply-connected.
Definition 2.2 (loop-cutset) vertex v sink respect loop L two
edges adjacent v L directed v. vertex sink respect
loop L called allowed vertex respect L. loop-cutset directed graph
set vertices contains least one allowed vertex respect loop D.
Definition 2.3 (Belief Networks) Let X = {X1 , ..., Xn } set random variables
multi-valued domains D(X1 ), ..., D(Xn ). belief network (BN) (Pearl, 1988)
pair <G, P > G directed acyclic graph whose nodes variables X
P = {P (Xi |pai )|i = 1, ..., n} set conditional probability tables (CPTs) associated
Xi . BN represents joint probability distribution product form:
P (x1 , ...., xn ) =

n

i=1

P (xi |pa(Xi ))

evidence e instantiated subset variables E X.
4

fiCutset Sampling Bayesian Networks

structure directed acyclic graph G reflects dependencies
variables using d-separation criterion. parents variable Xi together children
parents children form Markov blanket, denoted markovi , node Xi .
use xmarkovi denote x restricted variables markovi . know node
Xi independent rest variables conditioned Markov blanket. Namely,
P (xi |xi ) = P (xi |xmarkovi ).
common query belief networks belief updating task
computing posterior distribution P (Xi |e) given evidence e query variable Xi
X. Reasoning Bayesian networks NP-hard (Cooper, 1990). Finding approximate
posterior marginals fixed accuracy also NP-hard (Dagum & Luby, 1993; Abdelbar
& Hedetniemi, 1998). network poly-tree, belief updating inference
tasks accomplished time linear size input. general, exact inference
exponential induced width networks moral graph.
Definition 2.4 (induced-width) width node ordered undirected graph
number nodes neighbors precede ordering. width
ordering d, denoted w(d), maximum width nodes. induced width
ordered graph, w (d), width ordered graph obtained processing
nodes last first follows: node X processed, preceding neighbors
connected. resulting graph called induced graph triangulated graph.
task finding minimal induced width graph (over possible orderings)
NP-complete (Arnborg, 1985).
2.2 Reasoning Bayesian Networks
Belief propagation algorithm, introduce Section 2.2.2 below, performs belief
updating singly-connected Bayesian networks time linear size input
(Pearl, 1988). loopy networks, two main approaches belief updating cutset
conditioning tree clustering. algorithms often referred inference
algorithms. briefly describe idea clustering algorithms Section 2.2.1
conditioning method Section 2.2.3.
2.2.1 Variable Elimination Join-Tree Clustering (JTC)
join-tree clustering approach (JTC) refers family algorithms including jointree propagation (Lauritzen & Spiegelhalter, 1988; Jensen et al., 1990) bucket-tree
elimination (Dechter, 2003, 1999a). idea first obtain tree-decomposition
network clusters functions connected tree propagate messages
clusters tree. tree-decomposition singly-connected undirected
graph whose nodes, also called clusters, contain subsets variables input functions
defined variables. tree-decomposition must contain function
satisfy running intersection property (Maier, 1983). unifying perspective treedecomposition schemes see (Zhang & Poole, 1994; Dechter, 1999b; Kask, Dechter, Larrosa,
& Dechter, 2005).
Given tree-decomposition network, message propagation tree
synchronized. select one cluster root tree propagate messages
5

fiBidyuk & Dechter

tree. message cluster Vi neighbor Vj function
separator set Vi Vj marginalization product functions Vi
messages Vi received neighbors besides Vj . Assuming maximum
number variables cluster w + 1 maximum domain size d, time
space required process one cluster O(d(w+1) ). Since maximum number clusters
bounded |X| = N , complexity variable-elimination algorithms cluster-tree
propagation schemes O(N d(w+1) ). parameter w, maximum cluster size minus
1, called tree-width tree decomposition. minimal tree-width identical
minimal induced width graph.
2.2.2 Iterative Belief Propagation (IBP)
Belief propagation (BP) iterative message-passing algorithm performs exact inference singly-connected Bayesian networks (Pearl, 1988). iteration, every node Xi
sends j (Xi ) message child j receives j (Xi ) message child.
message-passing order organized converges two iterations. essence
algorithm join-tree clustering approach applied directly poly-tree.
Applied Bayesian networks loops, algorithm usually iterates longer (until may
converge) hence, known Iterative Belief Propagation (IBP) loopy belief propagation. IBP provides guarantees convergence quality approximate posterior
marginals shown perform well practice (Rish, Kask, & Dechter, 1998; Murphy,
Weiss, & Jordan, 1999). considered best algorithm inference coding networks
(Frey & MacKay, 1997; Kschischang & Frey, 1998) finding probable variable
values equals decoding process (McEliece, MacKay, & Cheng, 1997). Algorithm IBP
requires linear space usually converges fast converges. benchmarks, IBP
converged within 25 iterations less (see Section 4).
2.2.3 Cutset Conditioning
tree-width w Bayesian network large requirements inference
schemes bucket elimination join-tree clustering (JTC) exceed available memory,
switch alternative cutset conditioning schemes (Pearl, 1988; Peot & Shachter,
1992; Shachter, Andersen, & Solovitz, 1994). idea cutset conditioning select
subset variables C X\E, cutset, obtain posterior marginals node
Xi X\C, E using:
X
P (xi |e) =
P (xi |c, e)P (c|e)
(8)
cD(C)

Eq.(8) implies enumerate instantiations C, perform exact inference cutset instantiation c obtain P (xi |c, e) P (c|e) sum
results. total computation time exponential size cutset
enumerate instantiations cutset variables.
C loop-cutset, then, nodes C assigned, Bayesian network
transformed equivalent poly-tree P (xi |c, e) P (c|e) computed via
BP time space linear size network. example, subset {A, D}
loop-cutset belief network shown Figure 1, left, evidence E = e. right,
6

fiCutset Sampling Bayesian Networks


B

C



F

E

G







B

C



F

E

G



Figure 1: nodes loopy Bayesian network (left) instantiated,
network transformed equivalent singly-connected network (right).
transformation process, replica observed node created
child node.

Figure 1 shows equivalent singly-connected network resulting assigning values
D.
well-known minimum induced width w network always less
size smallest loop-cutset (Bertele & Brioschi, 1972; Dechter, 2003). Namely,
w + 1 |C| C. Thus, inference approaches (e.g., bucket elimination) never
worse often better cutset conditioning time-wise. However, w
large must resort cutset conditioning search order trade space time.
considerations yield hybrid search inference approach. Since observed variables
break dependencies network, network observed subset variables
C often transformed equivalent network smaller induced width, wC ,
term adjusted induced width. Hence, subset variables C X
observed, complexity bounded exponentially adjusted induced width
graph wC .
Definition 2.5 (adjusted induced width) Given graph G=<X,E>, adjusted
induced width G relative C, denoted wC , induced width C removed
moral graph.
Definition 2.6 (w-cutset) Given graph G=<X,E>, subset nodes C X
w-cutset G adjusted induced width equals w.
C w-cutset, quantities P (xi |c, e) P (c|e) computed time
space exponential w, much smaller tree-width unconditioned
network. resulting scheme requires memory exponential w time O(d|C| N d(w+1) )
N size network maximum domain size. Thus, performance
tuned available system memory resource via bounding parameter w.
Given constant w, finding minimal w-cutset (to minimize cutset conditioning
time) also hard problem. Several greedy heuristic approaches proposed
Geiger Fishelson (2003) Bidyuk Dechter (2003, 2004). elaborate
Section 3.5.
7

fiBidyuk & Dechter

2.3 Gibbs Sampling
Since complexity inference algorithms memory exponential networks induced
width (or tree-width) since resorting cutset-conditioning scheme may take
much time w-cutset size large, must often resort approximation
methods. Sampling methods Bayesian networks commonly used approximation
techniques. section provides background Gibbs sampling, Markov Chain Monte
Carlo method, one popular sampling schemes focus
paper. Although method may applied networks continuous distributions,
limit attention paper discrete random variables finite domains.
2.3.1 Gibbs Sampling Bayesian Networks
Ordered Gibbs Sampler
Input: belief network B X={X1 , ..., Xn } evidence e={(Xi = ei )|Xi E X}.
Output: set samples {x(t) }, = 1...T .
(0)
1. Initialize: Assign random value xi variable Xi X\E D(Xi ). Assign
evidence variables observed values.
2. Generate samples:
= 1 T, generate new sample x(t) :
(t)
= 1 N, compute new value xi variable Xi :
(t)
(t)
(t)
Compute distribution P (Xi |xmarkovi ) sample xi P (Xi |xmarkovi ).
(t)

Set Xi = xi .
End
End

Figure 2: Gibbs sampling Algorithm
Given Bayesian network variables X = {X1 , ..., Xn }, evidence e, Gibbs
sampling (Geman & Geman, 1984; Gilks et al., 1996; MacKay, 1996) generates set
(t)
(t)
samples {x(t) } sample x(t) = {x1 , ..., xn } instantiation variables.
(t)
superscript denotes sample index xi value Xi sample t. first
(t)
sample initialized random. generating new sample sample xi ,
(t)
new value variable Xi sampled probability distribution P (Xi |xi ) (recall
(t)

(t+1)

P (Xi |xi ) = P (Xi |x1

(t+1)

(t+1)

(t)

(t)

(t)

, ..., xi1 , xi+1 , ..., xn )) denote xi P (Xi |xi ).
(t)

next sample xi
generated previous sample xi following one two
schemes.
Random Scan Gibbs Sampling. Given sample x(t) iteration t, pick variable
(t)
Xi random sample new value xi conditional distribution xi P (Xi |xi )
leaving variables unchanged.
Systematic Scan (Ordered) Gibbs Sampling. Given sample x(t) , sample new
value variable order:
(t)

(t)

x1 P (X1 |x2 , x3 , ..., x(t)
n )
8

fiCutset Sampling Bayesian Networks

(t+1)

x2 P (X2 |x1

(t)

, x3 , ..., x(t)
n )

...

(t+1)

xi P (Xi |x1

(t+1)

(t)

, ..., xi1 , xi+1 , ..., x(t)
n )

...

(t+1)

xn P (Xn |x1

(t+1)

, x2

(t+1)

, ..., xn1 )
(t)

Bayesian networks, conditional distribution P (Xi |xi ) dependent
(t)

(t)

assignment Markov blanket variable Xi . Thus, P (Xi |xi )=P (Xi |xmarkovi )
(t)

xmarkovi restriction x(t) markovi . Given Markov blanket Xi , sampling
probability distribution given explicitly Pearl (1988):

(t)
(t)
P (xj |x(t)
(9)
P (xi |xmarkovi ) = P (xi |x(t)
)
paj )
pai
{j|Xj chj }

Thus, generating complete new sample done O(n r) multiplication steps
r maximum family size n number variables.
sequence samples x(1) , x(2) , ... viewed sequence states Markov
(t+1)
(t+1) (t) (t)
(t)
chain. transition probability state {x1
, ..., xi1 , xi , xi+1 , ..., xn } state
(t+1)

(t+1)

(t+1)

(t)

(t)

(t)

{x1
, ..., xi1 , xi
, xi+1 , ..., xn } defined sampling distribution P (Xi |xi ).
construction, Markov chain induced Gibbs sampling invariant distribution
P (X|e). However, since values assigned Gibbs sampler variables sample
x(t+1) depend assignment values previous sample x(t) , follows
sample x(n) depends initial state x(0) . convergence Markov chain
defined rate distance distribution P (x(n) |x(0) , e)
stationary distribution P (X|e) (i.e., variational distance, L1 -distance, 2 ) converges 0
function n. Intuitively, reflects quickly inital state x(0) forgotten.
convergence guaranteed Markov chain ergodic (Pearl, 1988; Gelfand
& Smith, 1990; MacKay, 1996). Markov chain finite number states ergodic
aperiodic irreducible (Liu, 2001). Markov chain aperiodic
regular loops. Markov chain irreducible get state Si state
Sj (including Si ) non-zero probability finite number steps. irreducibility
guarantees able visit (as number samples increases) statistically
important regions state space. Bayesian networks, conditions almost always
satisfied long conditional probabilities positive (Tierney, 1994).
ensure collected samples drawn distribution close P (X|e),
burn-in time may allocated. Namely, assuming takes K samples
Markov chain get close stationary distribution, first K samples may included computation posterior marginals. However, determining K hard (Jones
& Hobert, 2001). general, burn-in optional sense convergence
estimates correct posterior marginals depend it. completeness
sake, algorithm given Figure 2.
P
convergence conditions satisfied, ergodic average fT (X) = T1 f (xt )
function f (X) guaranteed converge expected value E[f (X)] increases.
9

fiBidyuk & Dechter

words, |fT (X) E[f (X)]| 0 . finite-state Markov chain
irreducible aperiodic, following result applies (see Liu, 2001, Theorem 12.7.2):

|fT (X) E[f (X)]| N (0, (f )2 )
(10)
initial assignment x(0) . variance term (f )2 defined follows:
(f )2 = 2 (f ) 2
2 = var[f (X)] (h) integrated autocorrelation time.
focus computing posterior marginals P (Xi |e) Xi X\E.
posterior marginals estimated using either histogram estimator:
P (Xi = xi |e) =


1X
(xi |x(t) )


P (Xi = xi |e) =


1X
(t)
P (xi |xi )


mixture estimator:

(11)

t=1

(12)

t=1

histogram estimator corresponds counting samples Xi = xi , namely (xi |x(t) ) =
(t)
1 xi = xi equals 0 otherwise. Gelfand Smith (1990) pointed since
mixture estimator based estimating conditional expectation, sampling variance
smaller due Rao-Blackwell theorem. Thus, mixture estimator preferred.
(t)
(t)
Since P (xi |xi ) = P (xi |xmarkovi ), mixture estimator simply average conditional
probabilities:

1X
(t)
P (xi |e) =
P (xi |xmarkovi )
(13)

t=1

mentioned above, Markov chain ergodic, P (Xi |e) converge exact
posterior marginal P (Xi |e) number samples increases. shown Roberts
Sahu (1997) random scan Gibbs sampler expected converge faster
systematic scan Gibbs sampler. Ultimately, convergence rate Gibbs sampler depends
correlation two consecutive samples (Liu, 1991; Schervish & Carlin, 1992;
Liu et al., 1994). review subject next section.
2.4 Variance Reduction Schemes
convergence rate Gibbs sampler depends strength correlations
samples (which also states Markov chain). term correlation
used mean samples dependent, mentioned earlier. case
finite-state irreducible aperiodic Markov chain, convergence rate expressed
maximal correlation states x(0) x(n) (see Liu, 2001, ch. 12). practice,
convergence rate analyzed covariance cov[f (x(t) ), f (x(t+1) )], f
function, also called auto-covariance.
convergence estimates exact values depends convergence
rate Markov chain stationary distribution variance estimator.
10

fiCutset Sampling Bayesian Networks

factors contribute value term (f )2 Eq.(10). two main
approaches allow reduce correlation samples reduce sampling variance
estimates blocking (grouping variables together sampling simultaneously)
collapsing (integrating random variables sampling subset), also
known Rao-Blackwellisation.
Given joint probability distribution three random variables X, , Z,
depict essence three sampling schemes follows:
1. Standard Gibbs:
x(t+1) P (X|y (t) , z (t) )


(t+1)

z

(t+1)

(t+1)

P (Y |x

(t+1)

P (Z|x

(14)

(t)

,z )

,y

(15)

(t+1)

)

(16)

2. Collapsed (variable Z integrated out):
x(t+1) P (X|y (t) )


(t+1)

(t+1)

P (Y |x

(17)
)

(18)

3. Blocking grouping X together:
(x(t+1) , (t+1) ) P (X, |z (t) )
z

(t+1)

(t+1)

P (Z|x

,y

(19)
(t+1)

)

(20)

blocking reduces correlation samples grouping highly correlated
variables blocks. collapsing, highly correlated variables marginalized out,
also results smoothing sampling distributions remaining variables
(P (Y |x) smoother P (Y |x, z)). approaches lead reduction sampling
variance estimates, speeding convergence exact values.
Generally, blocking Gibbs sampling expected converge faster standard Gibbs
sampler (Liu et al., 1994; Roberts & Sahu, 1997). Variations scheme
investigated Jensen et al. (1995) Kjaerulff (1995). Given number samples,
estimate resulting collapsed Gibbs sampler expected lower variance
(converge faster) estimate obtained blocking Gibbs sampler (Liu et al., 1994).
Thus, collapsing preferred blocking. analysis collapsed Gibbs sampler
found Escobar (1994), MacEachern (1994), Liu (1994, 1996).
caveat utilization collapsed Gibbs sampler computation
probabilities P (X|y) P (Y |x) must efficient time-wise. case Bayesian networks,
task integrating variables equivalent posterior belief updating
evidence variables sampling variables observed. time complexity therefore
exponential adjusted induced width, namely, effective width network
dependencies broken instantiated variables (evidence sampled).
11

fiBidyuk & Dechter

2.5 Importance Sampling
Since sampling target distribution hard, different sampling methods explore
different trade-offs generating samples obtaining estimates. already discussed,
Gibbs sampling generates dependent samples guarantees convergence sampling
distribution target distribution. Alternative approach, called importance sampling,
generate samples sampling distribution Q(X) different P (X|e)
include weight w(t) = P (x(t) |e)/Q(x(t) ) sample x(t) computation
estimates follows:

1X
f (xt )w(t)
fT (X) =


(21)

t=1

convergence fT (X) E[f (X)] guaranteed long condition P (x|e) 6=
0 Q(x) 6= 0 holds. convergence speed depends distance Q(X)
P (X|e).
One simplest forms importance sampling Bayesian networks likelihood
weighting (Fung & Chang, 1989; Shachter & Peot, 1989) processes variables topological order, sampling root variables priors remaining variables
conditional distribution P (Xi |pai ) defined conditional probability table (the evidence variables assigned observed values). sampling distribution close
prior and, result, usually converges slowly evidence concentrated around
leaf nodes (nodes without children) probability evidence small. Adaptive (also called dynamic) importance sampling method attempts speed
convergence updating sampling distribution based weight previously generated samples. Adaptive importance sampling methods include self-importance sampling,
heuristic importance sampling (Shachter & Peot, 1989), and, recently, AIS-BN (Cheng
& Druzdzel, 2000) EPIS-BN (Yuan & Druzdzel, 2003). empirical section,
compare performance proposed cutset sampling algorithm AIS-BN
considered state-of-the-art importance sampling algorithm date (although EPIS-BN
shown perform better networks) and, hence, describe AIS-BN
detail.
AIS-BN algorithm based observation could sample node
topological order distribution P (Xi |pai , e), resulting sample would drawn
target distribution P (X|e). Since distribution unknown variable
observed descendants, AIS-BN initializes sampling distributions P 0 (Xi |pai , e)
equal either P (Xi |pai ) uniform distribution updates distribution
P k (Xi |pai , e) every l samples next sampling distribution P k+1 (Xi |pai , e)
closer P (Xi |pai , e) P k (Xi |pai , e) follows:
P k+1 (xi |pai , e) = P k (xi |pai , e) + (k) (P (xi |pai , e) P k (xi |pai , e))
(k) positive function determines learning rate P (xi |pai , e)
estimate P (xi |pai , e) based last l samples.
12

fiCutset Sampling Bayesian Networks

3. Cutset Sampling
section presents cutset sampling scheme. discussed above, sampling
cutset guaranteed statistically efficient. Cutset sampling scheme computationally efficient way sampling collapsed variable subset C X, tying
complexity sample generation structure Bayesian network.
3.1 Cutset Sampling Algorithm
cutset sampling scheme partitions variable set X two subsets C X\C.
objective generate samples space C={C1 , C2 , ..., Cm } sample c(t)
instantiation variables C. Following Gibbs sampling principles,
(t)
wish generate new sample c(t) sampling value ci probability distribution
(t)
(t+1) (t+1)
(t+1) (t)
(t)
P (Ci |ci ) = P (Ci |c1
, c2
, ..., ci1 , ci+1 , ..., cm ). use left arrow denote
(t)

value ci drawn distribution P (Ci |ci ):

(t)

ci P (Ci |ci , e)

(22)
(t)

compute probability distribution P (Ci |ci , e) efficiently sampling
variable Ci C, generate samples efficiently. relevant conditional distributions computed exact inference whose complexity tied network structure. denote JT C(B, Xi , e) generic algorithm class variable-elimination
join-tree clustering algorithms which, given belief network B evidence e, outputs
posterior probabilities P (Xi |e) variable Xi X (Lauritzen & Spiegelhalter, 1988;
Jensen et al., 1990; Dechter, 1999a). networks identity clear, use
notation JT C(Xi , e).
Cutset Sampling
Input: belief network B, cutset C = {C1 , ..., Cm }, evidence e.
Output: set samples ct , = 1...T .
1. Initialize: Assign random value c0i Ci C assign e.
2. Generate samples:
= 0 T-1, generate new sample c(t+1) follows:
(t)
= 1 m, compute new value ci variable Ci follows:
(t)
a. Compute JT C(Ci , ci , e).
(t)

(t)

b. Compute P (Ci |ci , e) = P (Ci , ci , e).
c. Sample:
(t+1)
(t)
ci
P (Ci |ci , e)
End
End

(23)

Figure 3: w-Cutset sampling Algorithm
Therefore, sampling variable Ci value ci D(Ci ), compute
(t)
(t)
(t)
(t)
P (Ci , ci , e) via JT C(Ci , ci , e) obtain P (Ci |ci , e) via normalization: P (Ci |ci , e) =
(t)

P (Ci , ci , e).

13

fiBidyuk & Dechter

Cutset sampling algorithm uses systematic scan Gibbs sampler given Figure 3.
Clearly, adapted used random scan Gibbs sampler well. Steps
(a)-(c) generate sample (t + 1) sample (t). every variable Ci C sequence,
(t)
main computation step (a), distribution P (Ci , ci , e) Ci generated.
requires executing JT C every value ci D(Ci ), separately. step (b),
conditional distribution derived normalization. Finally, step (c) samples new value
(t)
obtained distribution. Note use P (Ci |ci , e) short-hand notation
(t+1)

(t+1)

(t)

(t)

P (Ci |c1
, ..., ci1 , ci+1 , ..., ck , e). Namely, sample new value variable
Ci , values variables C1 Ci1 already updated.
next demonstrate process using special case loop-cutset (see Definition 2.1).
Example 3.1 Consider belief network previously shown Figure 1 observed node
E = e loop-cutset {A, D}. begin sampling process initializing sampling variables
a(0) d(0) . Next, compute new sample values a(1) , d(1) follows:
P (A|d(0) , e)

=

PJT C (A, c(0) , e)
(0)

(24)

(1)


P (D|a(1) , e)


=

P (A|d , e)
PJT C (D, a(1) , e)

(25)
(26)

d(1)



P (D|a(1) , e)

(27)

process corresponds two iterations inner loop Figure 3. Eq. (24)-(25),
sample new value variable A, correspond steps (a)-(c) first iteration. second
iteration, Eq.(26)-(27), sample new value variable D. Since conditioned network
poly-tree (Figure 1, right), computing probabilities PJT C (A|d(t) , e) PJT C (D|a(t+1) , e) via JT C
reduces Pearls belief propagation algorithm distributions computed linear time.

3.2 Estimating Posterior Marginals
set samples subset variables C generated, estimate posterior
marginals variable network using mixture estimator. sampling variables,
estimator takes form similar Eq.(12):

1X
(t)
P (Ci |e) =
P (Ci |ci , e)


(28)

t=1

variables X\C, E, posterior marginal estimator is:

1X
P (Xi |e) =
P (Xi |c(t) , e)


(29)

t=1

use JT C(Xi , c(t) , e) obtain distribution P (Xi |c(t) , e) input Bayesian
network conditioned c(t) e shown before.
(t)
maintain running sum computed distributions P (Ci |ci , e) P (Xi |c(t) , e)
sample generation, sums right hand side Eq.(28)-(29) readily
available. noted before, estimators P (Ci |e) P (Xi |e) guaranteed converge corresponding exact posterior marginals increases long Markov
14

fiCutset Sampling Bayesian Networks

chain cutset C ergodic. cutset variables estimator simple
ergodic average, Xi X\C, E convergence also derived directly first
principles:
Theorem 3.2 Given Bayesian network B X, evidence variables E X, cutset
C X\E, given set samples c(1) , c(2) , ..., c(T ) obtained via Gibbs sampling
P (C|e), assuming Markov chain corresponding sampling C ergodic,
Xi X\C, E assuming P (Xi |E) defined Eq.(29), P (Xi |e) P (Xi |e)
.
Proof. definition:

1X
P (Xi |c(t) , e)
P (Xi |e) =


(30)

t=1

Instead summing samples, rewrite expression sum
possible tuples c D(C) group together samples corresponding tuple
instanceP
c. Let q(c) denote number times tuple C = c occurs set samples
cD(C) q(c) = . easy see that:
P (Xi |e) =

fraction

q(c)


X

cD(C)

P (Xi |c, e)

q(c)


(31)

histogram estimator posterior marginal P (c|e). Thus, get:
X
P (Xi |e) =
P (Xi |c, e)P (c|e)
(32)
cD(C)

Since Markov chain formed samples C ergodic, P (c|e) P (c|e)
therefore:
X
P (Xi |e)
P (Xi |c, e)P (c|e) = P (Xi |e)
cD(C)



3.3 Complexity
time space complexity generating samples estimating posterior marginals
via cutset sampling dominated complexity JT C line (a) algorithm
(Figure 3). linear amount additional memory required maintain running
(t)
sums P (Ci |ci , e) P (Xi |c(t) , e) used posterior marginal estimators.
3.3.1 Sample Generation Complexity
Clearly, JT C applied network B conditioned cutset variables C
evidence variables E, complexity time space exponential induced width
w conditioned network. O(N d(w+1) ) C w-cutset (see Definition 2.6).
15

fiBidyuk & Dechter

Using notion w-cutset, balance sampling exact inference. one end
spectrum plain Gibbs sampling sample generation fast, requiring
linear space, may high variance. end, exact algorithm
requiring time space exponential induced width moral graph.
two extremes, control time space complexity using w follows.
Theorem 3.3 (Complexity sample generation) Given network B X, evidence E, w-cutset C, complexity generating new sample time space
O(|C| N d(w+2) ) bounds variables domain size N = |X|.
Proof. C w-cutset maximum domain size, complexity
(t)
computing joint probability P (ci , ci , e) conditioned network O(N d(w+1) ).
Since operation must repeated ci D(Ci ), complexity processing one
(t)
variable (computing distribution P (Ci |ci , e)) O(N d(w+1) ) = O(N d(w+2) ). Finally,
since ordered Gibbs sampling requires sampling variable cutset, generating one
sample O(|C| N d(w+2) ).

3.3.2 Complexity Estimator Computation
posterior marginals cutset variable Ci C easily obtained end
sampling process without incurring additional computation overhead. mentioned earlier,
(t)
need maintain running sum probabilities P (ci |ci , e) ci D(Ci ).
Estimating P (Xi |e), Xi X\C, E, using Eq.(29) requires computing P (Xi |c(t) , e)
sample c(t) generated. summary:
Theorem 3.4 (Computing Marginals) Given w-cutset C, complexity computing posteriors variables Xi X\E using samples cutset variables
O(T [|C| + d] N d(w+1) ).
Proof. showed Theorem 3.3, complexity generating one sample O(|C|
N d(w+2) ). sample c(t) generated, computation posterior marginals
remaining variables requires computing P (Xi |c(t) , e) via JT C(Xi , c(t) , e)
O(N d(w+1) ). combined computation time one sample O(|C| N d(w+2) +
N d(w+1) ) = O([|C| + d] N d(w+1) ). Repeating computation samples, yields
O(T [|C| + d] N d(w+1) ).
Note space complexity w-cutset sampling bounded O(N d(w+1) ).

3.3.3 Complexity Loop-Cutset
cutset C loop-cutset, algorithm JT C reduces belief propagation (Pearl,
(t)
1988) computes joint distribution P (Ci , ci , e) linear time. refer
special case loop-cutset sampling general w-cutset sampling.
loop-cutset also w-cutset w equals maximum number unobserved
parents (upper bounded maximum indegree node). However, since processing
poly-trees linear even large w, induced width capture complexity
16

fiCutset Sampling Bayesian Networks

properly. notion loop-cutset could better captured via hyperwidth
network (Gottlob, Leone, & Scarello, 1999; Kask et al., 2005). hyperwidth polytree 1 therefore, loop-cutset defined 1-hypercutset. Alternatively,
express complexity via networks input size captures total size
conditional probability tables processed follows:
Theorem 3.5 (Complexity loop-cutset sample generation) C loop-cutset,
complexity generating sample O(|C| ) size input
network.
Proof. loop-cutset network instantiated, belief propagation (BP)
(t)
compute joint probability P (ci , ci , e) linear time O(M ) (Pearl, 1988) yielding total
time space O(|C| ) sample.

3.4 Optimizing Cutset Sampling Performance
analysis complexity generating samples (Theorem 3.3) overly pessimistic
assuming computation sampling distribution variable cutset
independent. variables may change value moving one sample
next, change occurs one variable time sequence much
computation retained moving one variable next .
show sampling cutset variables done efficiently
reducing factor N |C| Theorem 3.3 (N + |C| ) bounds number
clusters tree decomposition used JT C contains node Ci C. assume
control order cutset variables sampled.

X1
X1X2Y1

Y1

Y2

Yn-2

Yn-1

X2

X3

Xn-1

Xn

X2X3Y2

X3X4Y3

Xn-1XnYn-1

Figure 4: Bayesian network (top) corresponding cluster-tree (bottom).
Consider simple network variables X={X1 , ....Xn }, ={Y1 , ..., Yn1 } CPTs
P (Xi+1 |Xi , Yi ) P (Yi+1 |Xi ) defined every shown Figure 4, top. join-tree
network chain cliques size 3 given Figure 4, bottom. Since loopcutset, sample variables . Lets assume use ordering Y1 , Y2 , ...Yn1
generate sample. Given current sample, ready generate next sample
applying JT C (or bucket-elimination) network whose cutset variables assigned.
17

fiBidyuk & Dechter

makes network effectively singly-connected leaves 2 actual variables
cluster. algorithm sends message cluster containing Xn towards
cluster containing X1 . cluster (X1 , X2 , Y1 ) gets relevant message cluster
(X2 , X3 , Y2 ) sample Y1 . accomplished linear computations clique
(X1 , X2 , Y1 ) yi D(Yi ) yielding desired distribution P (Y1 |.) (we multiply
functions incoming messages cluster, sum X1 X2 normalize).
cutset w-cutset, computation single clique O(d(w+1) ).
P (Y1 |), Y1 sampled assigned new value, y1 . Cluster (X1 , X2 , Y1 =
y1 ) sends message cluster (X2 , X3 , Y2 ) information necessary
compute P (Y2 |.) O(d(w+2) ). P (Y2 |.) available, new value Y2 = y2 sampled.
cluster computes sends message cluster (X3 , X4 , Y3 ), on.
end, obtain full sample via two message passes conditioned network
computation complexity O(N d(w+2) ). example generalized follows.
Theorem 3.6 Given Bayesian network N variables, w-cutset C, tree-decomposition
Tr , given sample c1 , ..., c|C| , new sample generated O((N + |C| ) d(w+2) )
maximum number clusters containing variable Ci C.
Proof. Given w-cutset C, definition, exists tree-decomposition Tr network
(that includes cutset variables) cutset variables C removed,
number variables remaining cluster Tr bounded w + 1. Lets impose
directionality Tr starting arbitrary cluster call R shown Figure 5. Let
TCi denote connected subtree Tr whose clusters include Ci . Figure 5, clarity,
collapse subtree Ci single node. assume cutset nodes
sampled depth-first traversal order dictated cluster tree rooted R.

TC1 R
TC2
TCk
TC3

TC4

TC6

TC5
Figure 5: cluster-tree rooted cluster R subtree cutset node Ci
collapsed single node marked TCi .

18

fiCutset Sampling Bayesian Networks

Given sample c(t) , JT C send messages leaves Tr towards root cluster.
assume without loss generality R contains cutset node C1 first
sampled c(t+1) . JTC pass messages root clusters restricted
(t)
TC1 (note R TC1 ). Based messages P (C1 = c1 , c1 ) computed
O(d(w+1) ). repeat computation value C1 involving
clusters TC1 obtain distribution P (C1 |) O(d(w+2) ) sample new value
C1 . Thus, C1 appears clusters, number message passing computations
(after initial O(N ) pass) O() generate first distribution P (C1 |)
O( d(w+2) ).
next node depth-first traversal order TC2 thus, second variable
sampled C2 . distance variables C1 C2 , denoted dist1,2 , shortest
path along Tr cluster contains C1 cluster contains C2 . apply JTCs
mesage-passing along path take O(dist1,2 d(w+1) ). Then,
obtain conditional distribution P (C2 |), recompute messages subtree
TC2 value c2 D(C2 ) O( d(w+2) ). continue computation similar
manner cutset nodes.
JT C traverses tree depth-first order, needs pass messages along
P|C|
edge twice (see Figure 5). Thus, sum distances traveled i=2 disti,i1 =
O(N ). may repeated computation value sampled variable.
This, however, accomplished via message-passing restricted individual variables
subtrees bounded . conclude new full sample generated
O((N + |C| ) d(w+2) ).
worthwhile noting complexity generating sample reduced
factor d/(d1) (which amounts factor 2 = 2) noticing whenever
(t+1)
(t+1) (t)
(t)
move variable Ci Ci+1 , joint probability P (c1
, ..., ci
, ci+1 , ..., ck )
already available previous round recomputed. need
(t+1)
(t+1)
(t)
(t)
compute P (c1
, ..., ci
, ci+1 , ..., ck ) ci+1 6= ci+1 . Buffering last computed
joint probability, need apply JT C algorithm 1 times. Therefore, total
complexity generating new sample O((N + |C| ) (d 1) d(w+1) ).
Example 3.7 Figure 6 demonstrates application enhancements discussed.
depicts moral graph (a), already triangulated, corresponding join-tree (b)
Bayesian network Figure 1. evidence variable E removed, variables B form
1-cutset. join-tree network cutset evidence variables removed shown
Figure 6 (c). Since removing E cluster DF E leaves one variable, F ,
combine clusters BDF DF E one cluster, F G. Assuming cutset variables
domains size 2, initialize B = b0 = d0 .
Selecting cluster AC root tree, JT C first propagates messages leaves
root shown Figure 6 (c) computes P (b0 , d0 , e) cluster AC. Next,
set B = b1 ; updating functions containing variable B, propagating messages
subtree B consisting clusters AC CF (Figure 6 (d)), obtain P (b1 , d0 , e).
Normalizing two joint probabilities, obtain distribution P (B|d0 , e) sample new
value B. Assume sampled value b1 .
19

fiBidyuk & Dechter

ABC
P(B|A),P(C|A),
P(A)



AC
P(b0|A),P(C|A),
P(A)

AC
P(b1|A),P(C|A),
P(A)

AC
P(b1|A),P(C|A),
P(A)

AC
P(b1|A),P(C|A),
P(A)

CF
P(F|b0,C),P(d0|b0)

CF
P(F|b1,C),P(d0|b1)

CF
P(F|b1,C),P(d1|b1)

CF
P(F|b1,C),P(d0|b1)

FG
P(e|d0,F),P(G|d0,F)

FG
P(e|d0,F),P(G|d0,F)

FG
P(e|d1,F),P(G|d1,F)

FG
P(e|d0,F),P(G|d0,F)

B
C

BCF
P(F|B,C)

F
G

DFG
P(D|B), P(G|D,F)



E

DFE
P(E|D,F)

B=b0, D=d0, E=e
(a)

(b)

(c)

B=b1

D=d1

D=d0

(d)

(e)

(f)

Figure 6: join-tree width 2 (b) moral graph (a) transformed join-tree
width 1 (c) evidence variable E cutset variables B instantiated (in process, clusters BDF BCF merged cluster CF ).
clusters contain variables functions original network. cutset
nodes domains size 2, D(B) = {b0 , b1 }, D(D) = {d0 , d1 }. Starting
sample {b0 , d0 }, messages propagated (c)-(e) first, sample new value
variable B (d) variable (e). messages propagated
tree compute posterior marginals P (|b1 , d0 , e) rest variables (f).

Next, need compute P (D|b1 , e) sample new value variable D. joint
probability P (d0 , b1 , e) readily available since computed sampling new value
B. Thus, set = d1 compute second probability P (d1 , b1 , e) updating functions
clusters CF F G sending updated message CF F G (Figure 6 (e)).
obtain distribution P (D|b1 , e) normalizing joint probabilities sample new
value d0 D. Since value changed latest computation, update
functions clusters CF F G propagate updated messages subtree CD
(send message CF F G).
order obtain distributions P (|b1 , d0 , e) remaining variables A, C, F ,
G, need send updated messages join-tree, F G CF
CF AC shown Figure 6 (f ). last step also serves initialization
step next sample generation.
example performance cutset sampling significantly better worst
case. sent total 5 messages generate new sample worst case
suggests least N |C| = 3 2 2 = 12 messages (here, N equals number clusters).
20

fiCutset Sampling Bayesian Networks

3.5 finding w-Cutset
Clearly, w-cutset sampling effective w-cutset small. calls
task finding minimum size w-cutset. problem NP-hard; yet, several heuristic
algorithms proposed. next briefly survey proposals.
Larossa Dechter (2003) obtain w-cutset processing variables elimination
order. next node eliminated (selected using triangulation heuristics) added
cutset current induced width (or degree) greater w. Geiger Fishelson
(2003) agument idea various heuristics.
Bidyuk Dechter (2003) select variables included cutset using greedy
heuristics based nodes basic graph properties (such degree node). One
scheme starts empty w-cutset heuristically adds nodes cutset
tree-decomposition width w obtained. scheme starts set
C = X\E containing nodes network cutset removes nodes
set order. algorithm stops removing next node would result tree
decomposition width > w.
Alternatively, Bidyuk Dechter (2004) proposed first obtain tree-decomposition
network find minimal w-cutset tree-decomposition (also NPhard problem) via well-known greedy algorithm used set cover problem. approach
shown yield smaller cutset previously proposed heuristics used finding
w-cutset experiments (section 4.4) modification tree-decomposition
re-computed time node removed tree added w-cutset.

4. Experiments
section, present empirical studies cutset sampling algorithms several classes
problems. use mean square error posterior marginals estimates
measure accuracy. compare traditional Gibbs sampling, likelihood weighting
(Fung & Chang, 1989; Shachter & Peot, 1989), state art AIS-BN adaptive
importance sampling algorithm (Cheng & Druzdzel, 2000). implemented AIS-BN using
parameters specified Cheng Druzdzel (2000). using implementation,
made sure sampling algorithms used data access routines
error measures providing uniform framework comparing performance.
reference also report performance Iterative Belief Propagation (IBP) algorithm.
4.1 Methodology
section detail describe methodology used implementation decisions made
apply collection empirical results.
4.1.1 Sampling Methodology
sampling algorithms restarted Markov chain every samples. samples
chain (batch) averaged separately:
Pm (xi |e) =


1X
P (xi |c(t) , e)

t=1

21

fiBidyuk & Dechter

final estimate obtained sample average chains:

1 X
Pm (xi |e)
P (xi |e) =

m=1

Restarting Markov chain known improve sampling convergence rate. single
chain become stuck generating samples single high-probability region without
ever exploring large number high-probability tuples. restarting Markov chain
different random point, sampling algorithm achieve better coverage
sampling space. experiments, observe significant difference
estimates obtained single chain size chains size therefore,
choose report results multiple Markov chains. However, rely
independence random values Pm (xi |e) estimate 90% confidence interval P (xi |e).
implementation Gibbs sampling schemes, use zero burn-in time (see
section 2.3.1). mentioned earlier, idea burn-in time throw away
first K samples ensure remaining samples drawn distribution close
target distribution P (X|e). conservative methods estimating K drift
minorization conditions proposed Rosenthal (1995) Roberts Tweedie
(1999, 2001), required analysis beyond scope paper. consider
comparison Gibbs sampling cutset sampling, objective, fair
sense schemes use K=0. Further, experimental results showed positive
indication burn-in time would beneficial. practice, burn-in pre-processing
time used algorithm find high-probability regions distribution P (C|e)
case initially spends disproportionally large period time low probability regions.
Discarding large number low-probability tuples obtained initially, frequency
remaining high-probability tuples automatically adjusted better reflect weight.
cpcs360b, N=360, |E|=32, w*=21

cpcs360b, N=360, |E|=32, |LC|=26, w*=21

LCS
800

1.40E-04

700

# unique samples

1.60E-04

1.20E-04

MSE

1.00E-04
8.00E-05
6.00E-05
4.00E-05

LCS

600
500
400
300
200
100

2.00E-05

0

0.00E+00

0

2000

4000

6000

8000

10000

0

2000

4000

6000

8000

10000

# samples

# samples

Figure 7: Comparing loop-cutset sampling MSE vs. number samples (left) number unique samples vs. number samples (right) cpcs360b. Results
averaged 10 instances different observations.

benchmarks, observed full Gibbs sampling cutset sampling
able find high probability tuples fast relative number samples generated.
example, one benchmarks, cpcs360b, rate generating unique samples,
22

fiCutset Sampling Bayesian Networks

namely, ratio cutset instances seen number samples,
decreases time. Specifically, loop-cutset sampling generates 200 unique tuples
first 1000 samples, additional 100 unique tuples generating next 1000 samples,
rate generating unique tuples slows 50 per 1000 samples range
2000 10000 samples shown Figure 7, right. means first
hundred samples, algorithm spends time revisiting high-probability
tuples. benchmarks, number unique tuple instances generated increases
linearly (as cpcs54) and, thus, tuples appear distributed nearly uniformly.
case, need burn-in strongly-expressed heavy-weight
tuples. Instead using burn-in times, sample initial variable values posterior
marginal estimates generated IBP experiments. sampling time includes
pre-processing time IBP.
experiments performed 1.8 GHz CPU.
4.1.2 Measures Performance
problem instance defined Bayesian network B variables X = {X1 , ..., Xn }
evidence E X, derived exact posterior marginals P (Xi |e) using bucket-tree
elimination (Dechter, 2003, 1999a) computed mean square error (MSE)
approximate posterior marginals P (Xi |e) algorithm MSE defined by:
X X
1
[P (xi |e) P (xi |e)]2
SE = P
|D(X
)|

Xi X\E
Xi X\E D(Xi )

mean square error primary accuracy measure, results consistent
across well-known measures average absolute error, KL-distance, squared
Hellingers distance show loop-cutset sampling. absolute error
averaged values unobserved variables:
X X
1
= P
|P (xi |e) P (xi |e)|
Xi X\E |D(Xi )|
Xi X\E D(Xi )

KL-distance DK distribution P (Xi |e) estimator P (Xi |e) defined
follows:
X
P (xi |e)
DK (P (Xi |e), P (Xi |e)) =
P (xi |e) lg
P (xi |e)
D(X )


benchmark instance, compute KL-distance variable Xi X\E
average results:
X
1
DK (P (Xi |e), P (Xi |e))
DK (P, P ) =
|X\E|
Xi X\E

squared Hellingers distance DH distribution P (Xi |e) estimator
P (Xi |e) obtained as:
q
X p
DH (P (Xi |e), P (Xi |e)) =
[ P (xi |e) P (xi |e)]2
D(Xi )

23

fiBidyuk & Dechter

average squared Hellingers distance benchmark instance average
distances posterior distributions one variable:
DH (P, P ) =

1
|X\E|

X

Xi X\E

DH (P (Xi |e), P (Xi |e))

average errors different network instances averaged instances
given network (typically, 20 instances).
also report confidence interval estimate P (xi |e) using approach similar
well-known batch means method (Billingsley, 1968; Geyer, 1992; Steiger & Wilson,
2001). Since chains restarted independently, estimates Pm (xi |e) independent.
Thus, confidence interval obtained measuring variance estimators
P (Xi |e). report results Section 4.5.
4.2 Benchmarks
experimented four classes networks:
CPCS. considered four CPCS networks derived Computer-based Patient
Case Simulation system (Parker & Miller, 1987; Pradhan, Provan, Middleton, & Henrion,
1994). CPCS network representation based INTERNIST 1 (Miller, Pople, & Myers,
1982) Quick Medical Reference (QMR) (Miller, Masarie, & Myers, 1986) expert systems. nodes CPCS networks correspond diseases findings conditional
probabilities describe correlations. cpcs54 network consists N =54 nodes
relatively large loop-cutset size |LC|=16 (> 25% nodes). induced width
15. cpcs179 network consists N =179 nodes. induced width w =8.
small loop-cutset size |LC|=8 relatively large corresponding adjusted induced
width wLC =7. cpcs360b larger CPCS network 360 nodes, adjusted induced
width 21, loop-cutset |LC|=26. Exact inference cpcs360b averaged 30 minutes.
largest network, cpcs422b, consisted 422 nodes induced width w =22
loop-cutset size 47. exact inference time cpcs422b 50 minutes.
Hailfinder network. small network 56 nodes. exact inference
Hailfinder network easy since loop-cutset size 5. Yet, network
zero probabilities and, therefore, good benchmark demonstrating convergence
cutset sampling contrast Gibbs sampling.
Random networks. experimented several classes random networks: random networks, 2-layer networks, grid networks. random networks generated
N =200 binary nodes (domains size 2). first 100 nodes, {X1 , ..., X100 },
designated root nodes. non-root node Xi , > 100, assigned 3 parents selected
randomly list predecessors {X1 , ..., Xi1 }. refer class random
networks multi-partite random networks distinguish bi-partite (2-layer) random
networks. random 2-layer networks generated 50 root nodes (first layer)
150 leaf nodes (second layer), yielding total 200 nodes. sample 2-layer random
network shown Figure 8, left. non-root node (second layer) assigned 1-3
parents selected random among root nodes. nodes assigned domain size
2, D(Xi ) = {x0i , x1i }.
24

fiCutset Sampling Bayesian Networks

Figure 8: Sample random networks: 2-layer (left), grid (center), coding (right).

2-layer multi-partite random networks, root nodes assigned uniform priors conditional probabilities chosen randomly. Namely, value
P (x0i |pai ) drawn uniform distribution interval (0, 1) used compute
complementary probability value P (x1i |pai ) = 1 P (x0i |pai ).
directed grid networks (as opposed grid-shaped undirected Markov Random
Fields) size 15x30 450 nodes also constructed uniform priors (on single
root node) random conditional probability tables (as described above). sample grid
network shown Figure 8, center. networks average induced width
size 20 (exact inference using bucket elimination required 30 minutes).
regular structure largest loop-cutset containing nearly half
unobserved nodes.
Coding networks. experimented coding networks 50 code bits 50
parity check bits. parity check matrix randomized; parity check bit three
parents. sample coding network 4 code bits, 4 parity checking bits, total 8
transmitted bits shown Figure 8, center. total number variables network
experiments 200 (50 code bits, 50 parity check bits, 1 transmitted bit
code parity check bit). average loop-cutset size 26 induced width
21. Markov chain produced Gibbs sampling whole coding network
ergodic due deterministic parity check function. result, Gibbs sampling
converge. However, Markov chain corresponding sampling subspace coding
bits ergodic and, thus, cutset sampling schemes converged
show next two sections.
networks, except coding grid networks, evidence nodes selected random
among leaf nodes (nodes without children). Since grid network one leaf
node, evidence grid networks selected random among nodes.
benchmark, report chart title number nodes network N , average
number evidence nodes |E|, size loop-cutset |LC|, average induced width
input instance denoted w distinguish induced width w network adjusted
w-cutset.
25

fiBidyuk & Dechter

4.3 Results Loop-Cutset Sampling
section compare loop-cutset sampling pure Gibbs sampling, likelihood
weighting, AIS-BN, IBP. benchmarks, cutset selected evidence
sampling nodes together constitute loop-cutset network using algorithm
proposed Becker et al. (2000). show accuracy Gibbs loop-cutset sampling
function number samples time.
CPCS networks. results summarized Figures 9-12. loop-cutset curve
chart denoted LCS (for Loop Cutset Sampling). induced width network
wLC loop-cutset nodes observed specified caption. identical
largest family size poly-tree generated cutset variables removed. plot
time x-axis accuracy (MSE) y-axis. CPCS networks, IBP
always converged converged fast (within seconds). Consequently, IBP curve always
straight horizontal line results change convergence achieved.
curves corresponding Gibbs sampling, loop-cutset sampling, likelihood weighting,
AIS-BN demonstrate convergence sampling schemes time. three
CPCS networks loop-cutset sampling converges much faster Gibbs sampling.
exception cpcs422b (Figure 12, right) induced width conditioned singlyconnected network remains high (wLC = 14) due large family sizes thus, loop-cutset
sampling generates samples slowly (4 samples/second) compared Gibbs sampling
(300 samples/second). Since computing sampling distribution exponential w, sampling
single variable O(214 ) (all variables domains size 2). result, although loopcutset sampling shows significant reduction MSE function number samples
(Figure 12, left), enough compensate two orders magnitude difference
loop-cutset rate sample generation. cpcs54 (Figure 9), cpcs179 (Figure 10),
cpcs360b (Figure 11) loop-cutset sampling achieves greater accuracy IBP within
10 seconds less.
comparison importance sampling schemes, observe AIS-BN algorithm consistently outperforms likelihood weighting AIS-BN slightly better loopcutset sampling cpcs54, probability evidence P (e)=0.0928 relatively high.
cpcs179, probability evidence P (e)=4E-05 smaller, LCS outperforms AIS-BN
Gibbs sampling curves falls AIS-BN likelihood weighting. Gibbs
sampling loop-cutset sampling outperform AIS-BN cpcs360b cpcs422b
probability evidence small. cpcs360b average P (e)=5E-8 cpcs422b probability evidence varies 4E-17 8E-47. Note likelihood weighting AIS-BN
performed considerably worse either Gibbs sampling loop-cutset sampling
benchmarks function number samples. Consequently, left
charts showing convergence Gibbs loop-cutset sampling function
number samples order zoom two algorithms focus
empirical studies.
Coding Networks. results coding networks shown Figure 13.
computed error measures coding bits averaged 100 instances (10 instances,
different observed values, 10 networks different coding matrices).
noted earlier, Markov chains corresponding Gibbs sampling coding networks
ergodic and, result, Gibbs sampling converge. However, Markov
26

fiCutset Sampling Bayesian Networks

Gibbs

cpcs54, N=54, |LC|=16, w*=15, |E|=8

LW

cpcs54, N=54, |LC|=16, w*=15, |E|=8

LCS

4.0E-04

AIS-BN

3.0E-04

Gibbs

IBP

3.5E-04

2.5E-04

LCS

2.0E-04

IBP

3.0E-04

MSE

MSE

2.5E-04
2.0E-04
1.5E-04

1.5E-04
1.0E-04

1.0E-04

5.0E-05

5.0E-05

0.0E+00

0.0E+00
0

5000

10000

15000

20000

25000

0

30000

2

4

6

# samples
LW

cpcs54, N=54, |LC|=16, w*=15, |E|=8

10

12

14

Hellinger-distance

LCS

1.0E-05

AIS-BN

7.0E-06

Gibbs

1.2E-05

LW

cpcs54, N=54, |LC|=16, w*=15, |E|=8

AIS-BN

1.4E-05

KL-distance

8

Time (sec)

IBP

8.0E-06
6.0E-06
4.0E-06
2.0E-06

Gibbs

6.0E-06

LCS

5.0E-06

IBP

4.0E-06
3.0E-06
2.0E-06
1.0E-06
0.0E+00

0.0E+00
0

2

4

6

8

10

12

0

14

2

4

6

10

12

14

Time (sec)

Time (sec)
LW

cpcs54, N=54, |LC|=16, w*=15, |E|=8

AIS-BN

2.1E-03

Absolute Error

8

Gibbs

1.8E-03

LCS

1.5E-03

IBP

1.2E-03
9.0E-04
6.0E-04
3.0E-04
0.0E+00
0

2

4

6

8

10

12

14

Time (sec)

Figure 9: Comparing loop-cutset sampling (LCS), wLC =5, Gibbs sampling (hereby referred
Gibbs), likelihood weighting (LW), AIS-BN, IBP cpcs54 network,
averaged 20 instances, showing MSE function number samples
(top left) time (top right) KL-distance (middle left), squared Hellingers
distance (middle right), average error (bottom) function time.

27

fiBidyuk & Dechter

cpcs179, N=179, |LC|=8, w*=8, |E|=17

LW

cpcs179, N=179, |LC|=8, w*=8, |E|=17

LW

1.0E-02

AIS-BN

1.0E-01

AIS-BN

Gibbs

Gibbs
LCS

IBP

1.0E-02

IBP

1.0E-03

MSE

Absolute Error

LCS

1.0E-04

1.0E-03

1.0E-05

1.0E-04
0

2

4

6

8

10

12

0

14

2

4

6

8

10

12

cpcs179, N=179, |LC|=8, w*=8, |E|=17

LW

cpcs179, N=179, |LC|=8, w*=8, |E|=17

LW

1.0E+00

AIS-BN

AIS-BN

1.0E-01

Gibbs

1.0E-01

Hellinger-distance

Gibbs

KL-distance

14

Time (sec)

Time (sec)

LCS
IBP

1.0E-02
1.0E-03
1.0E-04
1.0E-05

LCS

1.0E-02

IBP

1.0E-03

1.0E-04

1.0E-05
0

2

4

6

8

10

12

14

0

2

4

6

Time (sec)

8

10

12

14

Time (sec)
LW

cpcs179, N=179, |LC|=8, w*=8, |E|=17

AIS-BN

1.0E-01

Gibbs
Absolute Error

LCS
IBP

1.0E-02

1.0E-03

1.0E-04
0

2

4

6

8

10

12

14

Time (sec)

Figure 10: Comparing loop-cutset sampling (LCS), wLC =7, Gibbs sampling, likelihood
weighting (LW), AIS-BN, IBP cpcs179 network, averaged 20 instances, showing MSE function number samples (top left) time
(top right) KL-distance (middle left), squared Hellingers distance (middle
right), average error (bottom) function time.

28

fiCutset Sampling Bayesian Networks

cpcs360b, N=360, |LC|=26, w*=21, |E|=15

cpcs360b, N=360, |LC|=26, w*=21, |E|=15
1.E-02

Gibbs

2.5E-04

LW
AIS-BN

LCS

2.0E-04

Gibbs

IBP

1.5E-04

LCS

MSE

MSE

1.E-03

1.0E-04

IBP

1.E-04

5.0E-05

1.E-05

0.0E+00
0

5000

10000

15000

20000

0

25000

2

4

6

# samples

cpcs360b, N=360, |LC|=26, w*=21, |E|=15

10

12

14

cpcs360b, N=360, |LC|=26, w*=21, |E|=15
LW

1.E-02

AIS-BN

Hellinger-distance

Gibbs

1.E-03

LCS
IBP

1.E-04

LW

1.E-02

AIS-BN

KL-distance

8

Time (sec)

1.E-05
1.E-06

Gibbs

1.E-03

LCS

1.E-04

IBP

1.E-05
1.E-06
1.E-07

0

2

4

6

8

10

12

14

0

2

4

6

Time (sec)

8

10

12

14

Time (sec)

cpcs360b, N=360, |LC|=26, w*=21, |E|=15
1.E-01

LW

Absolute Error

AIS-BN
Gibbs

1.E-02

LCS
IBP

1.E-03

1.E-04
0

5

10

15

20

25

30

Time (sec)

Figure 11: Comparing loop-cutset sampling (LCS), wLC =3, Gibbs sampling, likelihood
weighting (LW), AIS-BN, IBP cpcs360b network, averaged 20 instances, showing MSE function number samples (top left) time
(top right) KL-distance (middle left), squared Hellingers distance (middle
right), average error (bottom) function time.

29

fiBidyuk & Dechter

cpcs422b, N=422, |LC|=47, w*=22, |E|=28

Gibbs

cpcs422b, N=422, |LC|=47, w*=22, |E|=28

LCS

4.0E-04

LW
AIS-BN

1.0E-02

Gibbs

IBP

3.5E-04

LCS

3.0E-04

MSE

2.5E-04

MSE

IBP

1.0E-03

2.0E-04
1.5E-04

1.0E-04

1.0E-04
5.0E-05
1.0E-05

0.0E+00
0

1000

2000

3000

4000

5000

0

6000

10

20

LW

cpcs422b, N=422, |LC|=47, w*=22, |E|=28

40

50

60

LW

cpcs422b, N=422, |LC|=47, w*=22, |E|=28

AIS-BN

1.0E+00

AIS-BN

Gibbs

1.0E-01

LCS

1.0E-02

IBP

Gibbs

1.0E-01

Hellinger-distance

KL-distance

30

Time (sec)

# samples

1.0E-03
1.0E-04
1.0E-05
1.0E-06

LCS
1.0E-02

IBP

1.0E-03
1.0E-04
1.0E-05
1.0E-06

0

10

20

30

40

50

60

0

10

20

Time (sec)

30

40

50

60

Time (sec)
cpcs422b, N=422, |LC|=47, w*=22, |E|=28

LW
AIS-BN

1.0E-01

Gibbs

Absolute Error

LCS
IBP

1.0E-02

1.0E-03

1.0E-04
0

10

20

30

40

50

60

Time (sec)

Figure 12: Comparing loop-cutset sampling (LCS), wLC =14, Gibbs sampling, likelihood
weighting (LW), AIS-BN sampling, IBP cpcs422b network, averaged
10 instances, showing MSE function number samples (top
left) time (top right) KL-distance (middle left), squared Hellingers
distance (middle right), average error (bottom) function time.

30

fiCutset Sampling Bayesian Networks

1.0E-01

1.0E-02

1.0E-02

1.0E-03
1.0E-04

1.0E-03

1.0E-05

1.0E-04
0

2

4

6

8

0

10

2

4

Time (sec)

6

8

10

Time (sec)
LW
AIS-BN
Gibbs
LCS
IBP

1.0E+00

coding, N=200, P=3, |LC|=26, w*=21

LW
AIS-BN
Gibbs
LCS
IBP

1.0E+00

Hellinger-distance

coding, N=200, P=3, |LC|=26, w*=21
1.0E+01

KL-distance

LW
AIS-BN
Gibbs
LCS
IBP

1.0E-01

MSE

Absolute Error

coding, N=200, P=3, |LC|=26, w*=21

LW
AIS-BN
Gibbs
LCS
IBP

coding, N=200, P=3, |LC|=26, w*=21
1.0E+00

1.0E-01
1.0E-02
1.0E-03
1.0E-04
1.0E-05

1.0E-01
1.0E-02
1.0E-03
1.0E-04
1.0E-05

0

2

4

6

8

0

10

Time (sec)

2

4

6

8

10

Time (sec)

Figure 13: Comparing loop-cutset sampling (LCS), wLC =3, Gibbs sampling, likelihood
weighting (LW), AIS-BN, IBP coding networks, =0.4, averaged
10 instances 10 coding networks (100 instances total). graphs show average absolute error ( top left), MSE (top right), KL-distance (bottom left),
squared Hellingers distance (bottom right) function time.

chain corresponding sampling subspace code bits ergodic therefore,
loop-cutset sampling, samples subset coding bits, converges even achieves
higher accuracy IBP time. reality, IBP certainly preferable coding
networks since size loop-cutset grows linearly number code bits.
Random networks. random multi-part networks (Figure 14, top) random
2-layer networks (Figure 14, middle), loop-cutset sampling always converged faster
Gibbs sampling. results averaged 10 instances network type.
cases, loop-cutset sampling achieved accuracy IBP 2 seconds less. 2-layer
networks, Iterative Belief Propagation performed particularly poorly. Gibbs sampling
loop-cutset sampling obtained accurate results less second.
Hailfinder network. used network (in addition coding networks) compare behavior cutset sampling Gibbs sampling deterministic networks. Since
Hailfinder network contains many deterministic probabilities, Markov chain corresponding Gibbs sampling variables non-ergodic. expected, Gibbs sampling fails
loop-cutset sampling computes accurate marginals (Figure 15).
31

fiBidyuk & Dechter

random, N=200, |E|=20, |C|=30, w*=22

2-layer, R=50, P=3, N=200, |E|=16, |LC|=17, w*=16

Gibbs

1.8E-04

LCS

1.5E-04

IBP

1.0E-01

Gibbs
LCS

1.0E-02

IBP

MSE

MSE

1.2E-04
9.0E-05
6.0E-05

1.0E-03
1.0E-04

3.0E-05
1.0E-05

0.0E+00
0

5

10

15

20

25

0

30

2

4

Time (sec)

6

8

10

12

Time (sec)

Figure 14: Comparing loop-cutset sampling (LCS), Gibbs sampling, IBP random
networks (left) 2-layer random networks (right), wLC =3 classes
networks, averaged 10 instances each. MSE function time.

Hailfinder, N=56, |LC|=5, w*=5, |E|=4

Gibbs

1.0E-01

LCS
IBP

MSE

1.0E-02

1.0E-03

1.0E-04
0

1

2

3

4

5

6

7

Time (sec)

Figure 15: Comparing loop-cutset sampling (LCS), wLC =7, Gibbs sampling, IBP
Hailfinder network, 10 instances. MSE function time.

summary, empirical results demonstrate loop-cutset sampling cost-effective

time-wise superior Gibbs sampling. measured ratio R = Mgc number
samples Mg generated Gibbs number samples Mc generated loop-cutset
sampling time period (it relatively constant given network
changes slightly problem instances differ observations). cpcs54,
cpcs179, cpcs360b, cpcs422b ratios correspondingly 2.5, 3.75, 0.7, 75
(see Table 2 section 4.4). also obtained R=2.0 random networks R=0.3
random 2-layer networks. ratio values > 1 indicate Gibbs sampler generates
32

fiCutset Sampling Bayesian Networks

samples faster loop-cutset sampling usually case. instances,
variance reduction compensated increased computation time fewer samples
needed converge resulting overall better performance loop-cutset sampling
compared Gibbs sampling. cases, however, reduction sample size
also compensates overhead computation sampling one variable value.
cases, loop-cutset sampling generated samples faster Gibbs yielding ratio R < 1.
Then, improvement accuracy due larger number samples
faster convergence.
4.4 w-Cutset Sampling
section, compare general w-cutset scheme different values w
Gibbs sampling. main goal study performance w-cutset sampling
varies w. completeness sake, include results loop-cutset sampling shown
section 4.3.
empirical study, used greedy algorithm set cover problem, mentioned
section 3.5, finding minimal w-cutset. apply algorithm manner
(w + 1)-cutset proper subset w-cutset and, thus, expected
lower variance converge faster sampling w-cutset terms number samples
required (following Rao-Blackwellisation theory). focus empirical study
trade-offs cutset size reduction associated increase sample generation
time gradually increase bound w.
used benchmarks included also grid networks. sampling
algorithms given fixed time bound. sampling small networks, cpcs54
(w =15) cpcs179 (w =8), exact inference easy, sampling algorithms
allocated 10 seconds 20 seconds respectively. larger networks allocated 100-200
seconds depending complexity network fraction exact
computation time.
Table 1 reports size sampling set used algorithm column
reports size corresponding w-cutset. example, cpcs360b, average
size Gibbs sample (all nodes except evidence) 345, loop-cutset size 26, size
2-cutset 22, on. Table 2 shows rate sample generation different
algorithms per second. observed previously case loop-cutset sampling,
special cases cutset sampling generated samples faster Gibbs sampler.
example, cpcs360b, loop-cutset sampling 2-cutset sampling generated 600 samples
per second Gibbs sampler able generate 400 samples. attribute
size cutset sample (26 nodes less reported Table 1) compared
size Gibbs sample (over 300 nodes).
CPCS networks. present two charts. One chart demonstrates convergence
time several values w. second chart depicts change quality
approximation (MSE) function w two time points, half total
sampling time end total sampling time. performance Gibbs sampling
cutset sampling cpcs54 shown Figure 16. results averaged 20
instances 5-10 evidence variables. graph left Figure 16 shows mean
square error estimated posterior marginals function time Gibbs sampling,
33

fiBidyuk & Dechter

cpcs54
cpcs179
cpcs360b
cpcs422b
grid15x30
random
2layer
coding

Gibbs
51
162
345
392
410
190
185
100

LC
16
8
26
47
169
30
17
26

w=2
17
11
22
65
163
61
22
38

Sampling Set Size
w=3 w=4 w=5 w=6
15
11
9
8
9
7
5
19
16
15
14
57
50
45
40
119
95
75
60
26
25
24
18
15
13
13
11
23
18
18
-

w=7
13
35
50
17
-

w=8
13
-

Table 1: Markov chain sampling set size function w.

cpcs54
cpcs179
cpcs360b
cpcs422b
grid15x30
random
2layer
coding

Gibbs
5000
1500
400
300
2000
2000
200
2400

LC
2000, w= 5
400, w= 7
600, w= 3
4, w=14
500, w= 2
1000, w= 3
700, w= 3
1000, w= 3

No. Samples
w=2 w=3 w=4 w=5
3000 2400
800
500
400
150
40
10
600
400
160
100
200
150
90
50
300
260
150
105
1400
700
450
300
900
320
150
75
1000
400
200
120

w=6
300
40
30
60
140
40
100

w=7
20
15
35
75
-

w=8
20
-

Table 2: Average number samples generated per second function w.
loop-cutset sampling, w-cutset sampling w=2, 3, 4, 5. second chart shows
accuracy function w. first point corresponds Gibbs sampling; points
correspond loop-cutset sampling w-cutset sampling w ranging 2 6.
loop-cutset result embedded w-cutset values w=5. explained section 3.3,
loop-cutset corresponds w-cutset w maximum number parents
network. Initially, best results obtained 2- 3-cutset sampling followed
loop-cutset sampling. time, 2- 5-cutset sampling become best.
results cpcs179 reported Figure 17. charts show loop-cutset
sampling w-cutset sampling w range 2 5 superior Gibbs sampling.
chart left shows best cutset sampling schemes, lowest
MSE curves, 2- 3-cutset sampling. loop-cutset curve falls 2-
3-cutset first outperformed 2- 3-cutset 12 seconds. Loop-cutset
sampling 2- 3-cutset sampling outperform Gibbs sampling nearly two orders
magnitude MSE falls 1E-04 Gibbs MSE remains order 1E02. 4- 5-cutset sampling results fall between, achieving MSE 1E-03.
curves corresponding loop-cutset sampling 2-, 3- 4-cutset sampling fall
IBP line means four algorithms outperform IBP first seconds
execution (IBP converges less second). 5-cutset outperforms IBP 8
seconds. Figure 17 right, see accuracy results sampling algorithms
34

fiCutset Sampling Bayesian Networks

Gibbs

2.5E-04

MSE

2.0E-04
1.5E-04

IBP

cpcs54, N=54, |LC|=16, w*=15, |E|=8

IBP
LCS,w=5

2.5E-04

|C|=16,w=2
|C|=15,w=3

2.0E-04

|C|=11,w=4
|C|=9,w=5

1.5E-04

1.0E-04

MSE

cpcs54, N=54, |LC|=16, w*=15, |E|=8
3.0E-04

5.0E-05

Cutset, 5 sec
Cutset, 10 sec

1.0E-04
5.0E-05

0.0E+00

0.0E+00
0

2

4

6

8

10

12

14

Gibbs

w=2

w=3

w=4

Time (sec)

LCS,
w=5

w=5

w=6

Figure 16: MSE function time (left) w (right) cpcs54, 20 instances, time
bound=12 seconds.

MSE

1.0E-03

1.0E-04

IBP

cpcs179, N=179, |LC|=8, w*=8, |E|=17

Cutset, 10 sec

1.0E-01

Cutset, 20 sec
1.0E-02

MSE

Gibbs
IBP
LCS,w=7
|C|=11,w=2
|C|=9,w=3
|C|=7,w=4
|C|=5,w=5

cpcs179, N=179, |LC|=8, w*=8, |E|=17
1.0E-02

1.0E-03
1.0E-04
1.0E-05

12

14

Time (sec)

LC
S,
w=
7

10

w=
5

8

w=
4

6

w=
3

4

w=
2

2

G

0

ib
bs

1.0E-05

Figure 17: MSE function time (left) w (right) cpcs179, 20 instances, time
bound=12 seconds. Y-scale exponential due large variation performance
Gibbs cutset sampling.

10 seconds 20 seconds. agreement convergence curves
left.
cpcs360b (Figure 18), loop-cutset sampling 2- 3-cutset sampling similar
performance. accuracy estimates slowly degrades w increases. Loop-cutset
sampling w-cutset sampling substantially outperform Gibbs sampling values w
exceed accuracy IBP within 1 minute.
example cpcs422b, demonstrate significance adjusted induced
width conditioned network performance cutset sampling. reported
section 4.3, loop-cutset relatively small |LC|=47 wLC =14 thus, sampling
one new loop-cutset variable value exponential big adjusted induced width.
result, loop-cutset sampling computes 4 samples per second 2-, 3and 4-cutset, slightly larger 65, 57, 50 nodes respectively (see
Table 1), compute samples rates 200, 150, 90 samples per second (see Table 2).
35

fiBidyuk & Dechter

cpcs360b, N=360, |LC|=26, w*=21, |E|=15

cpcs360b, N=360, |E|=18, |LC|=26, w*=15

Gibbs

1.E-03

1.E-04

|C|=23,w=2
|C|=19,w=3

8.E-05

|C|=16,w=4
|C|=15,w=5

6.E-05

IBP
cutset,t=30sec
cutset,t=60sec

MSE

MSE

1.E-04

IBP
LCS,w=3

4.E-05

1.E-05

2.E-05

G

=7
w

w=
6

=5
w

Time (sec)

=4

70

w

60

=3

50

w

40

=3

30

LC
,w

20



10

ib
b

0

w=
2

0.E+00

1.E-06

Figure 18: MSE function time (left) w (right) cpcs360b, 20 instances, time
bound=60 seconds. Y-scale exponential due large variation performance
Gibbs cutset sampling.

Gibbs
IBP
LCS,w=2
|C|=65,w=2
|C|=57,w=3
|C|=50,w=4
|C|=45,w=5

1.8E-04

MSE

1.5E-04
1.2E-04

cpcs422b, N=422, |LC|=47, w*=22, |E|=28
1.0E-01

IBP
Cutset, 100 sec
Cutset, 200 sec

1.0E-02

MSE

cpcs422b, N=422, |LC|=47, w*=22, |E|=28
2.1E-04

9.0E-05

1.0E-03

6.0E-05

1.0E-04

3.0E-05
0.0E+00
0

20

40

60

80

100

120

140

1.0E-05

Gibbs

Time (sec)

w=2

w=3

w=4

w=5

w=6

w=7

Figure 19: MSE function time (left) w (right) cpcs422b, 10 instances, time
bound=200 seconds. Y-scale exponential due large variation performance
Gibbs cutset sampling.

5-cutset closest loop-cutset size, |C5 | = 45, computes 50 samples per
second order magnitude loop-cutset sampling. results
cpcs422b shown Figure 19. loop-cutset sampling results excluded due
poor performance. chart right Figure 19 shows w-cutset performed well
range w = 2 7 far superior Gibbs sampling. allowed enough time,
w-cutset sampling outperformed IBP well. IBP converged 5 seconds. 2-, 3-,
4-cutset improved IBP within 30 seconds, 5-cutset 50 seconds.
Random networks. Results 10 instances random multi-partite 10 instances 2-layer networks shown Figure 20. see, w-cutset sampling
substantially improves Gibbs sampling IBP reaching optimal performance
w = 2 3 classes networks. range, performance similar
loop-cutset sampling. case 2-layer networks, accuracy Gibbs sampling
36

fiCutset Sampling Bayesian Networks

random, R=50, N=200, P=3, |LC|=30, w*=22

random, R=50, N=200, P=3, |LC|=30, w*=22

1.5E-04
1.0E-04

IBP
cutset,t=30sec
cutset,t=60sec

1.5E-04

1.0E-04

5.0E-05

5.0E-05
0.0E+00

G

2layer, R=50, N=200, P=3, |LC|=17, w*=16

1.0E-04

w=
7

IBP

1.0E-01

cutset,t=10sec
cutset,t=20sec
1.0E-02

MSE

MSE

1.0E-03

w=
6

2layer, R=50, N=200, P=3, |LC|=17, w*=16

Gibbs
IBP
|LC|=17,w*=3
|C|=22,w*=2
|C|=15,w*=3
|C|=13,w*=4
|C|=12,w*=5

1.0E-02

w=
5

Time (sec)

w
=4

50

=3

40

,w

30

LC

20

ib
bs

10

w=
3

0.0E+00
0

w=
2

MSE

2.0E-04

2.0E-04

MSE

Gibbs
IBP
|LC|=30,w*=3
|C|=61,w*=2
|C|=26,w*=3
|C|=25,w*=4
|C|=24,w*=5

2.5E-04

1.0E-03

1.0E-04

1.0E-05
0

5

10

15

20

25

Time (sec)

1.0E-05
Gibbs

w =2

LC,w =3

w =3

w =4

w =5

w =6

Figure 20: Random multi-partite networks (top) 2-layer networks (bottom), 200 nodes,
10 instances. MSE function number samples (left) w (right).

37

fiBidyuk & Dechter

IBP order-of-magnitude less compared cutset sampling (Figure 20, bottom right).
poor convergence accuracy IBP 2-layer networks observed previously
(Murphy et al., 1999).
grid, 15x30, |E|=60, |LC|=169, w*=15, MSE
2.5E-04

1.5E-04

IBP
|LC|=169,w*=2

2.0E-04

1.2E-04

|C|=163,w*=2

100

120

cutset,t=100sec

Time (sec)

w*
=8

80

w*
=7

60

w*
=6

40

ibb


20

cutset,t=50sec

0.0E+00
G

0

IBP

3.0E-05

w*
=5

5.0E-05

6.0E-05

w*
=4

|C|=75,w*=5

w*
=3

|C|=95,w*=4

1.0E-04

9.0E-05

w*
=2
LC
,w
*=
2

|C|=119,w*=3

1.5E-04

MSE

MSE

grid, 15x30, |E|=40, |LC|=169, w*=20

Gibbs

Figure 21: Random networks, 450 nodes, 10 instances. MSE function number
samples (left) w (right).

Grid networks. Grid networks 450 nodes (15x30) class benchmarks full Gibbs sampling able produce estimates comparable cutsetsampling (Figure 21). respect accuracy, Gibbs sampler, loop-cutset sampling,
3-cutset sampling best performers achieved similar results. Loop-cutset
sampling fastest accurate among cutset sampling schemes. Still, generated samples 4 times slowly compared Gibbs sampling (Table 2) since
loop-cutset relatively large. accuracy loop-cutset sampling closely followed
2-, 3- 4-cutset sampling slowly degrading w increased. Grid networks
example benchmarks regular graph structure (that cutset sampling cannot exploit
advantage) small CPTs (in two-dimensional grid network node
2 parents) Gibbs sampling strong.
coding 50x50, N=200, P=3, |LC|=26, w*=19

coding, 50x50, N=200, P=3, |LC|=26, w*=19

IBP
2.5E-04

cutset,t=5sec

|C|=38,w*=2

2.5E-04

cutset,t=10sec
2.0E-04

|C|=21,w*=3

2.0E-04

|C|=18,w*=4

MSE

MSE

IBP

|LC|=26,w*=3

3.0E-04

1.5E-04
1.0E-04

1.5E-04
1.0E-04

5.0E-05

5.0E-05
0.0E+00
0

2

4

6

8

10

0.0E+00
w=2

Time (sec)

w=3

LC,w=3

w=4

Figure 22: Coding networks, 50 code bits, 50 parity check bits, =0.4, 100 instances, time
bound=6 minutes.

38

fiCutset Sampling Bayesian Networks

cpcs54
cpcs179
cpcs360b
cpcs422b
grid15x30
random
2layer
coding

Time
20 sec
40 sec
100 sec
200 sec
100 sec
50 sec
20 sec
20 sec

Gibbs
4500
1500
2000
3000
2000
2000
200
650

Markov Chain Length
LC w=2 w=3 w=4
2200 4000 2400
800
400
400
150
40
3000 3000 2000
800
20 2000 1500
900
500
300
260
150
1000 1400
700
450
700
900
320
150
450
800
600
250


w=5
500
10
500
500
105
300
75
150

w=6
200
250
60
140
40
100

Table 3: Individual Markov chain length function w. length chain
adjusted sampling scheme benchmark total processing
time across sampling algorithms same.

Coding Networks. cutset sampling results coding networks shown
Figure 22. Here, induced width varied 18 22 allowing exact inference.
However, additionally tested observed complexity network grows
exponentially number coding bits (even small increase number
coding bits 60 yielding total 240 nodes corresponding adjustments number
parity-checking bits transmitted code size, induced width exceeds 24)
time sample generation scales linearly. collected results 10 networks
(10 different parity check matrices) 10 different evidence instantiations (total 100
instances). decoding, Bit Error Rate (BER) standard error measure. However,
computed MSE unobserved nodes evaluate quality approximate results
precisely. expected, Gibbs sampling converge (because Markov chain
non-ergodic) left charts. charts Figure 22 show loop-cutset
optimal choice coding networks whose performance closely followed 2-cutset
sampling. saw earlier, cutset sampling outperforms IBP.
4.5 Computing Error Bound
Second issue convergence sampling scheme always problem predicting
quality estimates deciding stop sampling. section, compare
empirically error intervals Gibbs cutset sampling estimates.
Gibbs sampling cutset sampling guaranteed converge correct posterior
distribution ergodic networks. However, hard estimate many samples
needed achieve certain degree convergence. possible derive bounds
absolute error based sample variance sampling method samples independent. Gibbs MCMC methods, samples dependent cannot apply
confidence interval estimate directly. case Gibbs sampling, apply batch
means method special case standardized time series method used
BUGS software package (Billingsley, 1968; Geyer, 1992; Steiger & Wilson, 2001).
39

fiBidyuk & Dechter

main idea split Markov chain length chains length
. Let Pm (xi |e) estimate derived single chain [1, ..., ] length
(meaning, containing samples) defined equations (28)-(29). estimates Pm (x|e)
assumed approximately independent large enough . Assuming convergence
conditions satisfied central limit theorem holds, Pm (x|e) distributed
according N (E[P (xi |e)], 2 ) posterior marginal P (Xi |e) obtained
average results obtained chain, namely:
P (x|e) =


1 X
Pm (x|e)


(33)

m=1

sampling variance computed usually:
2 =


X
1
(Pm (x|e) P (x|e))2
1
m=1

equivalent expression sampling variance is:
PM
P 2 (x|e) P 2 (x|e)
2
= m=1
1

(34)

2 easy compute incrementally storing running sums Pm (x|e)
2 (x|e). Therefore, compute confidence interval 100(1 ) percentile
Pm
used random variables normal distribution small sampling set sizes. Namely:
"
r #
2
=1
(35)
P P (x|e) [P (x|e) 2 ,(M 1)

2 ,(M 1) table value distribution (M 1) degrees freedom.
used batch means approach estimate confidence interval posterior
marginals one modification. Since working relatively small sample sets
(a thousand samples) notion large enough well defined,
restarted chain every samples guarantee estimates Pm (x|e)
truly independent. method batch means provides meaningful error estimates
assuming samples drawn stationary distribution. assume
problems chains mix fast enough samples drawn target
distribution.
applied approach estimate error bound Gibbs sampler
cutset sampler. computed 90% confidence interval estimated posterior
marginal P (xi |e) based sampling variance Pm (xi |e) 20 Markov chains
described above. computed sampling variance 2 Eq.(34) 90% confidence
interval 0.9 (xi ) Eq.(35) averaged nodes:
X X
1
0.9 = P
0.9 (xi )
N |D(Xi )|


xi D(Xi )

estimated confidence interval large practical. Thus, compared 0.9
empirical average absolute error :
40

fiCutset Sampling Bayesian Networks

cpcs54
cpcs179
cpcs360b
cpcs422b
random
2layer
coding
grid15x30


0.9

0.9

0.9

0.9

0.9

0.9

0.9

0.9

Average Error
LC
w=2
0.00036 0.00030
0.00076 0.00064
0.00086 0.00074
0.00148 0.00111
0.00011 0.00010
0.00022 0.00023
- 0.00018
- 0.00033
0.00039 0.00119
0.00080 0.00247
0.00066 0.00063
0.00145 0.00144
0.00014 0.00019
0.00030 0.00035
0.00099 0.00119
0.00214 0.00247

Gibbs
0.00056
0.00119
0.01577
0.02138
0.00051
0.00113
0.00055
0.00119
0.00091
0.00199
0.00436
0.00944
0.00108
0.00248

Confidence Interval
w=3
w=4
w=5
0.00030
0.00040 0.00036
0.00063
0.00098 0.00112
0.00066
0.00113 0.00178
0.00164
0.00235 0.00392
0.00008
0.00014 0.00012
0.00021
0.00030 0.00028
0.00020
0.00018 0.00027
0.00035
0.00043 0.00060
0.00091
0.00099 0.00109
0.00205
0.00225 0.00222
0.00082
0.00117 0.00134
0.00185
0.00235 0.00302
0.00019 0.000174
0.00034 0.000356
0.00091
0.00099 0.00109
0.00205
0.00225 0.00222

w=6
0.00067
0.00116
0.00022
0.00046
0.00037
0.00074
0.00113
0.00239
0.00197
0.00341
0.00113
0.00239

Table 4: Average absolute error (measured) estimated confidence interval 0.9
function w 20 Markov Chains.

=

N

X
1
|D(Xi )|

P



X

xi D(Xi )

|P (xi |e) P (xi |e))

objective study observe whether computed confidence interval 0.9
(estimated absolute error) accurately reflects true absolute error , namely, verify
< 0.9 , so, investigate empirically whether confidence interval cutsetsampling estimates smaller compared Gibbs sampling would expect due
variance reduction.
Table 4 presents average confidence interval average absolute error
benchmarks. benchmark, first row results (row ) reports average
absolute error second row results (row 0.9 ) reports 90% confidence interval.
column Table 4 corresponds sampling scheme. first column reports results
Gibbs sampling. second column reports results loop-cutset sampling.
remaining columns report results w-cutset sampling w range 26. loop-cutset
sampling results cpcs422b included due statistically insignificant number
samples generated loop-cutset sampling. Gibbs sampling results coding networks
left network ergodic (as mentioned earlier) Gibbs sampling
converge.
see networks < 0.9 validates method measuring
confidence interval. cases estimated confidence interval 0.9
2-3 times size average error relatively small. case cutset sampling,
largest confidence interval max 0.9 = 0.00247 reported grid networks loop-cutset
41

fiBidyuk & Dechter

sampling. Thus, confidence interval estimate could used criteria reflecting
quality posterior marginal estimate sampling algorithm practice. Subsequently, comparing results Gibbs sampling cutset sampling, observe
significant reduction average absolute error, also similar reduction
estimated confidence interval. Across benchmarks, estimated confidence interval
Gibbs sampler remains 0.9 > 1E-3. time, cutset sampling obtain
0.9 < 1E-3 5 8 classes networks (excluded cpcs179, grid, 2-layer
networks).
4.6 Discussion
empirical evaluation performance cutset sampling demonstrates that, except
grid networks, sampling cutset usually outperforms Gibbs sampling. show
convergence cutset sampling terms number samples dramatically improves
predicted theoretically.
experiments clearly show exists range w-values w-cutset
sampling outperforms Gibbs sampler. performance w-cutset sampling deteriorates
increase w yields small reduction cutset size. example cpcs360b
network starting w=4, increasing w 1 results reducing sampling
set 1 node (shown Table 1).
observe loop-cutset good choice cutset sampling long
induced width network wLC conditioned loop-cutset reasonably small. wLC
large (as cpcs422b), loop-cutset sampling computationally less efficient w-cutset
sampling w < wLC .
also showed Section 4.3 Gibbs sampling loop-cutset sampling
outperform state-of-the-art AIS-BN adaptive importance sampling method
probability evidence small. Consequently, w-cutset sampling schemes Section 4.4 outperformed Gibbs sampler cpcs360b cpcs422b would also outperfrom
AIS-BN.

5. Related Work
mention related work. idea marginalising variables improve
efficiency Gibbs sampling first proposed Liu et al. (1994). successfully
applied several special classes Bayesian models. Kong et al. (1994) applied collapsing
bivariate Gaussian problem missing data. Liu (1994) defined collapsed Gibbs
sampling algorithm finding repetitive motifs biological sequences applies integrating
two parameters model. Similarly, Gibbs sampling set collapsed Escobar
(1994), MacEachern (1994), Liu (1996) learning nonparametric Bayes problem.
instances above, special relationships problem variables
exploited integrate several variables resulting collapsed Gibbs sampling approach.
Compared previous research work, contribution defining generic scheme
collapsing Gibbs sampling Bayesian networks takes advantage networks
graph properties depend specific form relationships
variables.
42

fiCutset Sampling Bayesian Networks

Jensen et al. (1995) combined sampling exact inference blocking Gibbs sampling
scheme. Groups variables sampled simultaneously using exact inference compute
needed conditional distributions. empirical results demonstrate significant improvement convergence Gibbs sampler time. Yet, proposed blocking
Gibbs sampling, sample contains variables network. contrast, cutset sampling reduces set variables sampled. noted previously, collapsing produces
lower variance estimates blocking and, therefore, cutset sampling require fewer
samples converge.
different combination sampling exact inference join-trees described
Koller et al. (1998) Kjaerulff (1995). oller et al. Kjaerulff proposed sample
probability distribution cluster computing outgoing messages. Kjaerulff
used Gibbs sampling large clusters estimate joint probability distribution
P (Vi ), Vi X cluster i. estimated P (Vi ) recorded instead true joint
distribution conserve memory. motivation high-probability tuples
recorded remaining low-probability tuples assumed probability 0.
small clusters, exact joint distribution P (Vi ) computed recorded. However,
paper analyze introduced errors compare performance scheme
standard Gibbs sampler exact algorithm. analysis error given
comparison approaches.
Koller et al. (1998) used sampling used compute messages sent cluster
cluster j posterior joint distributions cluster-tree contains discrete
continuous variables. approach subsumes cluster-based sampling proposed
Kjaerulff (1995) includes rigorous analysis error estimated posterior
distributions. method difficulties propagation evidence. empirical
evaluation limited two hybrid network instances compares quality
estimates likelihood weighting, instance importance sampling
perform well presence low-probability evidence.
effectiveness collapsing sampling set demonstrated previously
context Particle Filtering method Dynamic Bayesian networks (Doucet, Andrieu, &
Godsill, 2000a; Doucet, deFreitas, & Gordon, 2001; Doucet, de Freitas, Murphy, & Russell,
2000b). shown sampling subspace combined exact inference (RaoBlackwellised Particle Filtering) yields better approximation Particle Filtering
full set variables. However, objective study limited observation
effect special cases variables integrated easily.
cutset sampling scheme offers generic approach collapsing Gibbs sampler
Bayesian network.

6. Conclusion
paper presents w-cutset sampling scheme, general scheme collapsing Gibbs
sampler Bayesian networks. showed theoretically empirically cutset sampling improves convergence rate allows sampling non-ergodic network
ergodic subspace. collapsing sampling set, reduce dependence
samples marginalising highly correlated variables smoothing
sampling distributions remaining variables. estimators obtained sampling
43

fiBidyuk & Dechter

lower-dimensional space also lower sampling variance. Using induced
width w controlling parameter, w-cutset sampling provides mechanism balancing
sampling exact inference.
studied power cutset sampling sampling set loop-cutset and,
generally, sampling set w-cutset network (defined subset
variables that, instantiated, induced width network w). Based
Rao-Blackwell theorem, cutset sampling requires fewer samples regular sampling
convergence. experiments showed reduction number samples
time-wise cost-effective. confirmed range randomly generated real
benchmarks. also demonstrated cutset sampling superior state art
AIS-BN importance sampling algorithm probability evidence small.
Since size cutset correlations variables two main
factors contributing speed convergence, w-cutset sampling may optimized advancement methods finding minimal w-cutset. Another promising
direction future research incorporate heuristics avoiding selecting stronglycorrelated variables cutset since correlations driving factors speed
convergence Gibbs sampling. Alternatively, could combine sample collapsing
blocking.
summary, w-cutset sampling scheme simple yet powerful extension sampling
Bayesian networks likely dominate regular sampling sampling method.
focused Gibbs sampling better convergence characteristics, sampling
schemes implemented cutset sampling principle. particular,
adapted use likelihood weighting (Bidyuk & Dechter, 2006).

References
Abdelbar, A. M., & Hedetniemi, S. M. (1998). Approximating maps belief networks
NP-hard theorems. Artificial Intelligence, 102, 2138.
Andrieu, C., de Freitas, N., & Doucet, A. (2002). Rao-Blackwellised particle filtering via
data augmentation. Advances Neural Information Processing Systems. MIT
Press.
Arnborg, S. A. (1985). Efficient algorithms combinatorial problems graphs
bounded decomposability - survey. BIT, 25, 223.
Becker, A., Bar-Yehuda, R., & Geiger, D. (2000). Random algorithms loop cutset
problem. Journal Artificial Intelligence Research, 12, 219234.
Bertele, U., & Brioschi, F. (1972). Nonserial Dynamic Programming. Academic Press.
Bidyuk, B., & Dechter, R. (2003). Empirical study w-cutset sampling Bayesian networks. Proceedings 19th Conference Uncertainty Artificial Intelligence
(UAI), pp. 3746. Morgan Kaufmann.
Bidyuk, B., & Dechter, R. (2004). finding minimal w-cutset problem. Proceedings
20th Conference Uncertainty Artificial Intelligence (UAI), pp. 4350.
Morgan Kaufmann.
44

fiCutset Sampling Bayesian Networks

Bidyuk, B., & Dechter, R. (2006). Cutset Sampling Likelihood Weighting. Proceedings 22nd Conference Uncertainty Artificial Intelligence (UAI), pp.
3946. Morgan Kaufmann.
Billingsley, P. (1968). Convergence Probability Measures. John Wiley & Sons, New York.
Casella, G., & Robert, C. P. (1996). Rao-Blackwellisation sampling schemes. Biometrika,
83 (1), 8194.
Cheng, J., & Druzdzel, M. J. (2000). AIS-BN: adaptive importance sampling algorithm
evidenctial reasoning large baysian networks. Journal Aritificial Intelligence
Research, 13, 155188.
Cooper, G. (1990). computational complexity probabilistic inferences. Artificial
Intelligence, 42, 393405.
Dagum, P., & Luby, M. (1993). Approximating probabilistic inference Bayesian belief
networks NP-hard. Artificial Intelligence, 60 (1), 141153.
Dechter, R. (1999a). Bucket elimination: unifying framework reasoning. Artificial
Intelligence, 113, 4185.
Dechter, R. (1999b). Bucket elimination: unifying framework reasoning. Artificial
Intelligence, 113 (12), 4185.
Dechter, R. (2003). Constraint Processing. Morgan Kaufmann.
Doucet, A., & Andrieu, C. (2001). Iterative algorithms state estimation jump Markov
linear systems. IEEE Trans. Signal Processing, 49 (6), 12161227.
Doucet, A., Andrieu, C., & Godsill, S. (2000a). sequential Monte Carlo sampling methods Bayesian filtering. Statistics Computing, 10 (3), 197208.
Doucet, A., de Freitas, N., Murphy, K., & Russell, S. (2000b). Rao-Blackwellised particle
filtering dynamic Bayesian networks. Proceedings 16th Conference
Uncertainty Artificial Intelligence (UAI), pp. 176183.
Doucet, A., deFreitas, N., & Gordon, N. (2001). Sequential Monte Carlo Methods Practice.
Springer-Verlag, New York, Inc.
Doucet, A., Gordon, N., & Krishnamurthy, V. (1999). Particle filters state estimation jump markov linear systems. Tech. rep., Cambridge University Engineering
Department.
Escobar, M. D. (1994). Estimating normal means iwth dirichlet process prior. Journal
American Statistical Aasociation, 89, 268277.
Frey, B. J., & MacKay, D. J. C. (1997). revolution: Belief propagation graphs
cycles. Neural Information Processing Systems, Vol. 10.
Fung, R., & Chang, K.-C. (1989). Weighing integrating evidence stochastic simulation Bayesian networks. Proceedings 5th Conference Uncertainty
Artificial Intelligence (UAI), pp. 209219. Morgan Kaufmann.
Geiger, D., & Fishelson, M. (2003). Optimizing exact genetic linkage computations. Proceedings 7th Annual International Conf. Computational Molecular Biology,
pp. 114121. Morgan Kaufmann.
45

fiBidyuk & Dechter

Gelfand, A., & Smith, A. (1990). Sampling-based approaches calculating marginal densities. Journal American Statistical Association, 85, 398409.
Geman, S., & Geman, D. (1984). Stochastic relaxations, Gibbs distributions
Bayesian restoration images. IEEE Transaction Pattern analysis Machine
Intelligence, 6, 721742.
Geyer, C. J. (1992). Practical Markov Chain Monte Carlo. Statistical Science, 7, 473483.
Gilks, W., Richardson, S., & Spiegelhalter, D. (1996). Markov chain Monte Carlo practice.
Chapman Hall.
Gottlob, G., Leone, N., & Scarello, F. (1999). comparison structural CSP decomposition
methods. Proceedings 16th International Joint Conference Artificial
Intelligence (IJCAI), pp. 394399. Morgan Kaufmann.
Jensen, C., Kong, A., & Kjrulff, U. (1995). Blocking Gibbs sampling large probabilistic expert systems. Int. J. Human Computer Studies. Special Issue RealWorld Applications Uncertain Reasoning, 42 (6), 647666.
Jensen, F. V., Lauritzen, S. L., & Olesen, K. G. (1990). Bayesian updating causal
probabilistic networks local computation. Computational Statistics Quarterly, 4,
269282.
Jones, G., & Hobert, J. P. (2001). Honest exploration intractable probability distributions
via Markov Chain Monte Carlo. Statist. Sci., 16 (4), 312334.
Kask, K., Dechter, R., Larrosa, J., & Dechter, A. (2005). Unifying cluster-tree decompositions reasoning graphical models. Artificial Intelligence, 166, 165193.
Kjrulff, U. (1995). HUGS: Combining exact inference Gibbs sampling junction
trees. Proceedings 11th Conference Uncertainty Artificial Intelligence
(UAI), pp. 368375. Morgan Kaufmann.
Koller, D., Lerner, U., & Angelov, D. (1998). general algorithm approximate inference
application hybrid Bayes nets. Proceedings 14th Conference
Uncertainty Artificial Intelligence (UAI), pp. 324333.
Kong, A., Liu, J. S., & Wong, W. (1994). Sequential imputations Bayesian missing
data problems. J. American Statistical Association, 89 (425), 278288.
Kschischang, F. R., & Frey, B. J. (1998). Iterative decoding compound codes probability propagation graphical models. IEEE Journal Selected Areas Communications, 16, 219230.
Larrosa, J., & Dechter, R. (2003). Boosting search variable elimination constraint
optimization constraint satisfaction problems. Constraints, 8 (3), 303326.
Lauritzen, S., & Spiegelhalter, D. (1988). Local computation probabilities graphical
structures application expert systems. Journal Royal Statistical
Society, Series B, 50(2), 157224.
Liu, J. (1991). Correlation Structure Convergence Rate Gibbs Sampler, Ph.D.
Thesis. University Chicago.
46

fiCutset Sampling Bayesian Networks

Liu, J. (1994). collapsed Gibbs sampler Bayesian computations applications
gene regulation problem. Journal American Statistical Association, 89 (427),
958966.
Liu, J., Wong, W., & Kong, A. (1994). Covariance structure Gibbs sampler
applications comparison estimators augmentation schemes. Biometrika,
81 (1), 2740.
Liu, J. S. (1996). Nonparametric hierarchical bayes via sequential imputations. Annals
Statistics, 24 (3), 911930.
Liu, J. S. (2001). Monte Carlo Strategies Scientific Computing. Springer-Verlag, New
York, Inc.
MacEachern, S., Clyde, M., & Liu, J. (1998). Sequential importance sampling nonparametric bayes models: next generation. Canadian Journal Statistics, 27,
251267.
MacEachern, S. N. (1994). Estimating normal means conjugate style dirichlet process
prior. Communications Statistics-Simulation Computation, 23 (3), 727741.
MacKay, D. (1996). Introduction Monte Carlo methods. Proceedings NATO Advanced Study Institute Learning Graphical Models. Sept 27-Oct 7, pp. 175204.
Maier, D. (1983). theory relational databases. Computer Science Press, Rockville,
MD.
McEliece, R., MacKay, D., & Cheng, J.-F. (1997). Turbo decoding instance Pearls
belief propagation algorithm. IEEE J. Selected Areas Communication, 16, 140152.
Miller, R., Masarie, F., & Myers, J. (1986). Quick medical reference (QMR) diagnostic
assistance. Medical Computing, 3 (5), 3438.
Miller, R., Pople, H., & Myers, J. (1982). Internist-1: experimental computerbased
diagnostic consultant general internal medicine. New English Journal Medicine,
307 (8), 468476.
Murphy, K. P., Weiss, Y., & Jordan, M. I. (1999). Loopy belief propagation approximate
inference: empirical study. Proceedings 15th Conference Uncertainty
Artificial Intelligence (UAI), pp. 467475. Morgan Kaufmann.
Parker, R., & Miller, R. (1987). Using causal knowledge create simulated patient cases:
CPCS project extension INTERNIST-1. Proceedings 11th Symp.
Comp. Appl. Medical Care, pp. 473480.
Pearl, J. (1988). Probabilistic Reasoning Intelligent Systems. Morgan Kaufmann.
Peot, M. A., & Shachter, R. D. (1992). Fusion propagation multiple observations
belief networks. Artificial Intelligence, 48, 299318.
Pradhan, M., Provan, G., Middleton, B., & Henrion, M. (1994). Knowledge engineering
large belief networks. Proceedings 10th Conference Uncertainty Artificial
Intelligence, Seattle, WA, pp. 484490.
Rish, I., Kask, K., & Dechter, R. (1998). Empirical evaluation approximation algorithms
probabilistic decoding. Proceedings 14th Conference Uncertainty
Artificial Intelligence (UAI), pp. 455463. Morgan Kaufmann.
47

fiBidyuk & Dechter

Roberts, G. O., & Sahu, S. K. (1997). Updating schemes; correlation structure; blocking
parameterization Gibbs sampler. Journal Royal Statistical Society,
Series B, 59 (2), 291317.
Roberts, G. O., & Tweedie, R. L. (1999). Bounds regeneration times convergence
rates Markov chains. Stochastic Processes Applications, 80, 211229.
Roberts, G. O., & Tweedie, R. L. (2001). Corregendum bounds regeneration times
convergence rates Markov chains. Stochastic Processes Applications, 91,
337338.
Rosenthal, J. S. (1995). Convergence rates Markov Chains. SIAM Review, 37 (3), 387
405.
Rosti, A.-V., & Gales, M. (2004). Rao-Blackwellised Gibbs sampling switching linear
dynamical systems. IEEE International Conference Acoustics, Speech,
Signal Processing (ICASSP 2004), pp. 809812.
Schervish, M., & Carlin, B. (1992). convergence successive substitution sampling.
Journal Computational Graphical Statistics, 1, 111127.
Shachter, R. D., Andersen, S. K., & Solovitz, P. (1994). Global conditioning probabilistic
inference belief networks. Proceedings 10th Conference Uncertainty
Artificial Intelligence (UAI), pp. 514522.
Shachter, R. D., & Peot, M. A. (1989). Simulation approaches general probabilistic
inference belief networks. Proceedings 5th Conference Uncertainty
Artificial Intelligence (UAI), pp. 221231.
Steiger, N. M., & Wilson, J. R. (2001). Convergence properties batch means method
simulation output analysis. INFORMS Journal Computing, 13 (4), 277293.
Tierney, L. (1994). Markov chains exploring posterior distributions. Annals Statistics,
22 (4), 17011728.
Yuan, C., & Druzdzel, M. (2003). importance sampling algorithm based evidence
pre-propagation. Proceedings 19th Conference Uncertainty Artificial
Intelligence (UAI), pp. 624631.
Zhang, N., & Poole, D. (1994). simple algorithm Bayesian network computations.
Proceedings 10th Canadian Conference Artificial Intelligence, pp. 171178.

48

fiJournal Artificial Intelligence Research 28 (2007) 299-348

Submitted 07/06; published 03/07

Supporting Temporal Reasoning Mapping
Calendar Expressions Minimal Periodic Sets
Claudio Bettini
Sergio Mascetti

bettini@dico.unimi.it
mascetti@dico.unimi.it

Dipartimento di Informatica e Comunicazione, Universita di Milano
Via Comelico, 39, 20135, Milan, Italy

X. Sean Wang

Sean.Wang@uvm.edu

Department Computer Science, University Vermont
33 Colchester Avenue, Burlington, VT, 05405 USA

Abstract
recent years several research efforts focused concept time granularity applications. first stream research investigated mathematical models
behind notion granularity algorithms manage temporal data based
models. second stream research investigated symbolic formalisms providing set
algebraic operators define granularities compact compositional way. However, limited manipulation algorithms proposed operate directly
algebraic representation making unsuitable use symbolic formalisms
applications need manipulation granularities.
paper aims filling gap results two streams research,
providing efficient conversion algebraic representation equivalent
low-level representation based mathematical models. addition, conversion
returns minimal representation terms period length. results major
practical impact: users easily define arbitrary granularities terms algebraic
operators, access granularity reasoning services operating efficiently
equivalent, minimal low-level representation. example, illustrate
application temporal constraint reasoning multiple granularities.
technical point view, propose hybrid algorithm interleaves
conversion calendar subexpressions periodical sets minimization period length. algorithm returns set-based granularity representations minimal
period length, relevant parameter performance considered reasoning services. Extensive experimental work supports techniques used
algorithm, shows efficiency effectiveness algorithm.

1. Introduction
According 2006 research Oxford University Press, word time found
common noun English language, considering diverse sources
Internet including newspapers, journals, fictions weblogs. somehow surprising
among 25 common nouns find time granularities like day, week, month
year. pretty sure many time granularities like business day, quarter,
semester, etc. would found quite frequently used natural languages. However,
way computer applications deal concepts still naive mostly hidden program code and/or based limited sometimes imprecise calendar support.

c
2007
AI Access Foundation. rights reserved.

fiBettini, Mascetti & Wang

Temporal representation reasoning long time AI research topic aimed
providing formal framework common sense reasoning, natural language understanding, planning, diagnosis many complex tasks involving time data management.
Despite many relevant contributions, time granularity representation reasoning
support often ignored over-simplified. active area temporal
constraint satisfaction, proposals implicitly assumed adding support granularity trivial extension. quite recently recognized
case specific techniques proposed (Bettini, Wang, & Jajodia, 2002a). Even
intuitively simple task deciding whether specific instant part time granularity
tricky arbitrary user-defined granularities like e.g., banking days, academic
semesters considered.
Granularities periodic patterns terms granularities playing role even
emerging application areas like inter-organizational workflows personal information
management (PIM). example, inter-organizational workflows need model monitor
constraints like: Event2 occur later two business days occurrence
Event1. context PIM, current calendar applications, even mobile devices,
allow user specify quite involved periodical patterns recurrence events.
example, possible schedule event every last Saturday every two months.
complexity supported patterns increasing last years, current
simple interfaces showing limits. essentially based combination
recurrences based one two granularities taken fixed set (days, weeks, months,
years). foresee possibility significant extensions applications
specifying recurrences user-defined granularities. example, user may define (or
upload granularity library) granularity corresponding academic semester
school teaching at, set date finals last Monday
semester. bank may want define banking days granularity bank
policies may formalized recurrences terms granularity. Automatically
generated appointments policies may appear devices bank employees
involved specific procedures. also foresee need show user preferred view
calendar. current standard applications user choice businessday limited view complete view, enabling view based userss
consulting-days, example? new perspective use mobile devices may also result
considering time span activities supposed executed (expressed
arbitrary granularities), software agents board alert constraints
may violated, even based contextual information like user location traffic
conditions. scenario highlights three main requirements: a) sufficiently expressive
formal model time granularity, b) convenient way define new time granularities,
c) efficient reasoning tools time granularities.
Consider a). last decade significant efforts made provide formal
models notion time granularity devise algorithms manage temporal
data based models. addition logical approaches (Montanari, 1996; Combi,
Franceschet, & Peron, 2004), framework based periodic-set representations
extensively studied (Bettini, Wang, & Jajodia, 2000), recently approach based
strings automata introduced (Wijsen, 2000; Bresolin, Montanari, & Puppis,
2004). mostly interested last two approaches support effective
300

fiMapping Calendar Expressions Minimal Periodic Sets

computation basic operations time granularities. cases representation
granularities considered low-level one, rather involved specification
terms instants time domain.
Consider requirement b) above. Users may hard time defining granularities
formalisms based low-level representations, interpret output operations.
clearly unreasonable ask users specify granularities linear equations
mathematical formalisms operate directly terms instants granules fixed
time granularity. Hence, second stream research investigated high-level symbolic
formalisms providing set algebraic operators define granularities compact
compositional way. efforts task started even research formal
models granularity (Leban, McDonald, & Forster, 1986; Niezette & Stevenne, 1992)
continued parallel stream research (Bettini & Sibi, 2000; Ning, Wang, & Jajodia,
2002; Terenziani, 2003; Urgun, Dyreson, Snodgrass, Miller, Soo, Kline, & Jensen, 2007).
Finally, let us consider requirement c) above. Several inferencing operations
defined low-level representations, including equivalence, inclusion granules
different granularities, even complex inferencing services like constraint propagation
(Bettini et al., 2002a). Even simple operations general method available operating
directly high level representation. Indeed, cases, proposed methods
cannot exploit structure expression require enumeration granules,
may inefficient. case, example, granule conversion
methods presented Ning e at. (2002). Moreover, aware method
perform operations, equivalence intersection sets granules, directly
terms high level representation.
major goal paper provide unique framework satisfy requirements
a), b), c) identified above, adding existing results smart efficient
technique convert granularity specifications high-level algebraic formalism
low-level one, many reasoning tools available. particular, paper
focus conversion high-level formalism called Calendar Algebra (Ning
et al., 2002) low-level formalism based periodical sets (Bettini et al., 2000, 2002a).
Among several proposals high-level (algebraic) specification granularities,
choice Calendar Algebra two main motivations: first, allows user express
large class granularities; comparison expressiveness Calendar Algebra
formalisms see (Bettini et al., 2000). Second, provides richest set
algebraic operations designed reflect intuitive ways users define
new granularities. discussion actual usability tool could
enhanced graphical user interface found Section 6.2. choice
low-level formalism based periodic-sets also two main motivations: first,
efficient implementation basic operations already exists extensively
experimented (Bettini, Mascetti, & Pupillo, 2005); second, one currently
supporting complex operations granularities needed constraint satisfaction,
illustrated detail Section 6.1.
technical contribution paper hybrid algorithm interleaves conversion calendar subexpressions periodical sets step period minimization.
central phase conversion procedure derive, algebraic subexpression,
periodicity output set. periodicity used build periodical represen301

fiBettini, Mascetti & Wang

tation subexpression recursively used operand expressions.
Given calendar algebra expression, algorithm returns set-based granularity representations minimal period length. period length relevant parameter
performance basic operations granularities specialized ones
like operations used constraint satisfaction service. Extensive experimental work
reported paper validates techniques used algorithm, showing, among
things, (1) even large calendar expressions efficiently converted, (2)
less precise conversion formulas may lead unacceptable computation time. latter
property shows importance carefully accurately designed conversion formulas.
Indeed, conversion formulas may seem trivial length periodicity concern.
designing conversion formulas, made effort reduce period length
resulting granularity representation, thus render whole conversion process computationally efficient.
next section define granularities; several interesting relationships among
highlighted periodical set representation formalized. Section 3 define
Calendar Algebra present operations. Section 4 describe conversion
process: definition three steps necessary conversion, algebraic
operation present formulas perform step. Section 5 discuss period
minimality issue, report experimental results based full implementation
conversion algorithm extension ensuring minimality. Section 6
motivate work presenting complete application scenario. Section 7 reports
related work, Section 8 concludes paper.

2. Formal Notions Time Granularities
Time granularities include common ones like hours, days, weeks, months years,
well evolution specialization granularities specific contexts
applications. Trading days, banking days, academic semesters examples
specialization granularities become quite common describing policies
constraints.
2.1 Time Granularities
comprehensive formal study time granularities relationships found
(Bettini et al., 2000). paper, introduce notions essential
show results. particular, report notion labeled granularity
proposed specification calendar algebra (Bettini et al., 2000; Ning et al., 2002);
show later labeled granularity reduced standard notion
granularity, like one used Bettini et al. (2002a).
Granularities defined grouping sets instants granules. example,
granule granularity day specifies set instants included particular day.
label used refer particular granule. whole set time instants called time
domain, purpose paper domain arbitrary infinite set
total order relationship, .

302

fiMapping Calendar Expressions Minimal Periodic Sets

Definition 1 labeled granularity G pair (LG , ), LG subset
integers, mapping LG subsets time domain
pair integers j LG < j, (i) 6= (j) 6= , (1) element
(i) less every element (j), (2) integer k LG < k < j,
(k) 6= .
former condition guarantees monotonicity granularity; latter
used introduce bounds (see Section 2.2).
call LG label set LG call G(i) granule; G(i) 6= call
non-empty granule. LG exactly integers, granularity called fullinteger labeled. LG = Z+ notion granularity used several
applications, e.g., (Bettini et al., 2002a). example, following labeling schema,
assume map day(1) subset time domain corresponding January 1,
2001, day(32) would mapped February 1, 2001, b-day(6) January 8, 2001 (the
sixth business day), month(15) March 2002. generalization arbitrary label
sets introduced mainly facilitate conversion operations algebra, however
final goal conversion labeled granularity denoted calendar expression
positive-integer labeled one denoted periodic formula.
2.2 Granularity Relationships
interesting relationships granularities follows. definitions extended
ones presented Bettini et al. (2000) cover notion labeled granularity.
Definition 2 G H labeled granularities, G said group H, denoted
G / H, non-empty
granule H(j), exists (possibly infinite) set labels

G H(j) = G(i).
Intuitively, G / H means granule H union granules G.
example, day / week since week composed 7 days day / b-day since business
day day.
Definition 3 G H labeled granularities, G said finer H,
denoted G H, granule G(i), exists granule H(j) G(i) H(j).
example business-day finer day, also finer week.
also say G partitions H G / H G H. Intuitively G partitions H
G / H granules G included granules H.
example, day b-day group b-week (business week, i.e., business day
week), day partition b-week, b-day does.
Definition 4 labeled granularity G1 label-aligned subgranularity labeled granularity G2 label set LG1 G1 subset label set LG2 G2
LG1 G1 (i) 6= , G1 (i) = G2 (i).
Intuitively, G1 subset granules G2 granules label
two granularities.
303

fiBettini, Mascetti & Wang

Granularities said bounded LG first last element G(i) =
LG . assume existence unbounded bottom granularity, denoted
full-integer labeled groups every granularity system.
time domains that, given set granularities, always possible
find bottom one; example, easily proved property holds
time domain cardinality integers. hand,
property hold time domains (e.g. reals). However, assumption
existence bottom granularity still reasonable since address problems
granularities defined starting bottom one. definition calendar
set granularities bottom granularity (Bettini et al., 2000) captures
idea.
2.3 Granularity Conversions
dealing granularities, often need determine granule (if any)
granularity H covers given granule z another granularity G. example,
may wish find month (an interval absolute time) includes given week
(another interval absolute time).
transformation obtained operation. Formally, label z LG ,
H
0
0
dzeG undefined @z 0 LH s.t. G(z) H(z 0 ) ; otherwise, dzeH
G = z , z
0
0
unique index value G(z) H(z ). uniqueness z guaranteed
monotonicity 1 granularities. example, dzemonth
second gives month includes
month
second z. Note dzesecond always defined, dzemonth
week undefined week
z falls two months. Note G H, function dzeH
G defined
week
index value z. example, since day week, dzeday always defined, i.e.,
day find week contains it. notation dzeH used source
granularity left implicit (e.g., dealing fixed set granularities
distinguished bottom granularity).
Another direction transformation operation: Let G H
H
granularities
G / H, z an2 integer. Define bzcG set labels
granules G jS G(j) = H(z). function useful finding, e.g.,
days month.
2.4 Periodical Granules Representation
central issue temporal reasoning possibility finitely representing infinite granularities. definition granularity provided general expressive may
impossible provide finite representation granularities. Even labels
(i.e., subset integers) necessarily finite representation.
solution first proposed Bettini et al. (2000). idea
commonly used granularities present periodical behavior; means certain
pattern repeats periodically. feature exploited provide method
1. Condition (1) Definition 1.
2. definition different one given Bettini et al (2000) since also considers non contiguous
granules G.

304

fiMapping Calendar Expressions Minimal Periodic Sets

finitely describing granularities. formal definition based periodically groups
relationship.
Definition 5 labeled granularity G groups periodically labeled granularity H
(G / H) G / H exist positive integers N P
(1) label H, + N label H unless + N greater greatest
label H,

(2) label H, H(i) = kr=0 G(jr ) H(i + N ) non-empty granule

H H(i + N ) = kr=0 G(jr + P ),
(3) H(s) first non-empty granule H (if exists), H(s + N ) non-empty.
groups periodically relationship special case group characterized
periodic repetition grouping pattern granules G granules H.
definition may appear complicated actually quite simple. Since G groups H,
granule H(i) union granules G; instance assume union
granules G(a1 ), G(a2 ), . . . , G(ak ). Condition (1) ensures label + N exists (if
greater greatest label H) condition (2) ensures that, H(i + N )
empty, union G(a1 + P ), G(a2 + P ), . . . , G(ak + P ). assume
r = 0 . . . k, (jr + P ) LG ; not, conditions considered satisfied. Condition
(3) simply says least one repetitions.
call pair P N Definition 5, period length associated period
label distance. also indicate R number granules H corresponding
groups P consecutive granules . formally R equal number labels
H greater equal smaller + N arbitrary label H. Note
R affected value i.
period length period label distance unique; precisely,
G period label
indicate PHG period length H terms G NH
distance H terms G; form PH NH used G = . Note
period length integer value. simplicity also indicate one period
granularity H set R consecutive granules H.
general, periodically groups relationship guarantees granularity H
finitely described (in terms granules G).
Definition 6 G / H, H finitely described providing: (i) value P
P
N ; (ii) set LP labels H
one period H; (iii) L , finite set
Sa labels G, H(a) = iSa G(i); (iv) labels first last non-empty
granules H, values infinite.
representation, granules labels LP ones need
explicitly represented; call granules explicit granules.
granularity H represented periodic set granules granularity G,
G ) periodically groups
exists infinite number pairs (PHG , NH
relation satisfied. relation satisfied pair (P, N ), proved
also satisfied pair (P, N ) N+ .

305

fiBettini, Mascetti & Wang

Definition 7 periodic representation granularity H terms G called minimal
period length P used representation smallest value among period
G ) H periodically groups G.
lengths appearing pairs (PHG , NH
H fully characterized terms G, possible derive composition,
terms G, granule H. Indeed, LP set labels H values
G 1}, assume H unbounded, description arbitrary
{b, . . . , b + NH
G] + 1
granule H(j) obtained following formula. Given j 0 = [(j 1) mod NH

k
k
j
j
b1
b1
G + j0
G + j0 b


N
NH


G
G
H

NH
NH
k=
k

j


b1

+ 1 N G + j 0 otherwise
G
NH

H


H(j) =

[


G

PHG

iSk




k1
j1
G
+ PH
.

G
G
NH
NH


Example 1 Figure 1 shows granularities day week parts i.e., granularity that,
week, contains granule working days granule weekend.
sake simplicity, denote day week parts W respectively. Since
/ W , W fully characterized terms D. Among different possible representations,
= 7, N = 2, LP = {3, 4},
example decide represent W terms PW
W
W
S3 = {8, 9, 10, 11, 12} S4 = {13, 14}. composition granule W
easily computed; example composition W (6) given formula presented
j 0 = 2 k = 4. Hence W (6) = D(7 2 + 13 7 1) D(7 2 + 14 7 1) =
D(20) D(21).

-1 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30
j

b

k

2

3

4

j

W
1

5

6

7

8

Figure 1: Periodically groups example

3. Calendar Algebra
Several high-level symbolic formalisms proposed represent granularities (Leban
et al., 1986; Niezette & Stevenne, 1992).
work consider formalism proposed Ning et al. (2002) called Calendar
Algebra. approach set algebraic operations defined; operation generates
new granularity manipulating granularities already generated.
relationships operands resulting granularities thus encoded
operations. granularities generated directly indirectly bottom
granularity form calendar, granularities related
306

fiMapping Calendar Expressions Minimal Periodic Sets

operations define them. practice, choices bottom granularity include day,
hour, second, microsecond granularities, depending accuracy required
application context.
following illustrate calendar algebra operations presented Ning et al.
(2002) together restrictions introduced Bettini et al. (2004).
3.1 Grouping-Oriented Operations
calendar algebra consists following two kinds operations: grouping-oriented
operations granule-oriented operations. grouping-oriented operations group
certain granules granularity together form new granules new granularity.
3.1.1 Grouping Operation
Let G full-integer labeled granularity, positive integer. grouping operation
Groupm (G) generates new granularity G0 partitioning granules G m-granule
groups making group granule resulting granularity. precisely, G0 =
Groupm (G) granularity integer i,
im
[

G0 (i) =

G(j).

j=(i1)m+1

example, given granularity day, granularity week generated calendar
algebra expression week = Group7 (day) assume day(1) corresponds Monday,
i.e., first day week.
3.1.2 Altering-tick Operation
Let G1 , G2 full-integer labeled granularities, l, k, integers, G2 partitions
(G , G ) generates new granularity
G1 , 1 l m. altering-tick operation Alterl,k
2
1
periodically expanding shrinking granules G1 terms granules G2 . Since G2
partitions G1 , granule G1 consists contiguous granules G2 . granules
G1 partitioned m-granule groups G1 (1) G1 (m) one group,
G1 (m + 1) G1 (2m) following group, on. goal altering-tick
operation modify granules G1 l-th granule every m-granule group
|k| additional (or fewer k < 0) granules G2 . example, G1 represents
30-day groups (i.e., G1 = Group30 (day)) want add day every 3-rd month
(i.e., make March 31 days), may perform Alter12
3,1 (day, G1 ).
altering-tick operation formally described follows. integer

G1 (i) 6= , let bi ti integers G1 (i) = tj=b
G2 (j) (the integers bi


0
ti exist G2 partitions G1 ). G = Alterl,k (G2 , G1 ) granularity
integer i, let G0 (i) = G1 (i) = , otherwise let
0

0

G (i) =

ti
[
j=b0i

307

G2 (j),

fiBettini, Mascetti & Wang


b0i


=

bi + (h 1) k, = (h 1) + l,
bi + h k,
otherwise,
t0i = ti + h k,




il
+ 1.
h=



Example 2 Figure 2 shows example Alter operation. Granularity G1 defined
G1 = Group5 (G2 ) granularity G0 defined G0 = Alter22,1 (G2 , G1 ), means
shrinking second one every two granules G1 one granule G2 .
G2
-9 -8 -7 -6 -5 -4 -3 -2 -1 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21

G1
-1

0

1

2

3

4

G
-

1

0

1

2

3

4

Figure 2: Altering-tick operation example
original definition altering-tick given Ning et al. (2002) reported above,
following problems arbitrary negative value k used: (1) allows
definition G0 full-integer labeled granularity (2) allows
definition G0 even satisfy definition granularity. order avoid
undesired behavior, impose following restriction:
k > (mindist(G1, 2, G2) 1)
mindist() formally defined Bettini et al. (2000).
Intuitively, mindist(G1, 2, G2) represents minimum distance (in terms granules
G2) two consecutive granules G1.
3.1.3 Shift Operation
Let G full-integer labeled granularity, integer. shifting operation
Shiftm (G) generates new granularity G0 shifting labels G positions.
formally, G0 = Shiftm (G) granularity integer i, G0 (i) = G(i m).
Note G0 also full-integer labeled.
3.1.4 Combining Operation
Let G1 G2 granularities label sets LG1 LG2 respectively. combining
operation Combine(G1 , G2 ) generates new granularity G0 combining granules
G2 included one granule G1 one granule G0 . formally,
L1 , let s(i) = G1 (i) = , otherwise let s(i) = {j LG2 | =
6 G2 (j) G1 (i)}.

308

fiMapping Calendar Expressions Minimal Periodic Sets

G0 = Combine(G1 , G2 ) granularity
label set LG0 = {i LG1 |s(i) 6= }

LG0 , G0 (i) = js(i) G2 (j).
example, given granularities b-day month, granularity business months
generated b-month = Combine(month, b-day).
3.1.5 Anchored Grouping Operation
Let G1 G2 granularities label sets LG1 LG2 respectively, G2
label-aligned subgranularity G1 , G1 full-integer labeled granularity. anchored
grouping operation Anchored-group(G1 , G2 ) generates new granularity G0 combining
granules G1 two granules G2 one granule G0 .
formally, G0 = Anchored-group(G1 , G2 ) granularity label set LG0 = LG2
0 1
G1 (j) i0 next label G2 i.
LG0 , G0 (i) = ij=i
example, academic year certain university begins last Monday
August, ends day beginning next academic year. Then,
granularity corresponding academic years generated AcademicY ear =
Anchored-group(day, lastMondayOfAugust).
3.2 Granule-Oriented Operations
Differently grouping-oriented operations, granule-oriented operations
modify granules granularity, rather enable selection granules
remain new granularity.
3.2.1 Subset Operation
Let G granularity label set LG , m, n integers n. subset
operation G0 = Subsetnm (G) generates new granularity G0 taking granules
G whose labels n. formally, G0 = Subsetnm (G) granularity
label set LG0 = {i LG | n}, LG0 , G0 (i) = G(i).
example, given granularity year, years 20th century generated
0
20CenturyYear = Subset1999
1900 (year). Note G label-aligned subgranularity G,
G0 full-integer labeled granularity even G is. also allow extensions
setting = n = semantics properly extended.
3.2.2 Selecting Operations
selecting operations binary operations. generate new granularities
selecting granules first operand terms relationship granules
second operand. result always label-aligned subgranularity first operand
granularity.
three selecting operations: select-down, select-up select-by-intersect.
facilitate description operations, lk (S) notation used. Intuitively,
set integers, lk (S) selects l elements starting k-th one (for formal
description operator see (Ning et al., 2002)).
Select-down operation. granule G2 (i), exits set granules G1
contained G2 (i). operation Select-downlk (G1 , G2 ), k 6= 0 l > 0
309

fiBettini, Mascetti & Wang

integers, selects granules G1 using lk () set granules (actually labels)
G1 contained one granule G2 . formally, G0 = Select-downlk (G1 , G2 )
granularity label set
LG0 = iLG2 lk ({j LG1 | 6= G1 (j) G2 (i)}),
LG0 , G0 (i) = G1 (i). example, Thanksgiving days fourth
Thursdays Novembers; Thursday November given, generated
Thanksgiving = Select-down14 (Thursday, November).
Select-up operation. select-up operation Select-up(G1 , G2 ) generates new granularity
G0 selecting granules G1 contain one granules G2 . formally,
G0 = Select-up(G1 , G2 ) granularity label set
6 G2 (j) G1 (i)), }
LG0 = {i LG1 |j LG2 ( =
LG0 , G0 (i) = G1 (i). example, given granularities Thanksgiving
week, weeks contain Thanksgiving days defined ThanxWeek =
Select-up(week, Thanksgiving).
Select-by-intersect operation. granule G2 (i), may exist set granules G1 ,
intersecting G2 (i). Select-by-intersectlk (G1 , G2 ) operation, k 6= 0 l > 0
integers, selects granules G1 applying lk () operator sets, generating
new granularity G0 . formally, G0 = Select-by-intersectlk (G1 , G2 ) granularity
label set
LG0 = iLG2 lk ({j LG1 | G1 (j) G2 (i) 6= }),
LG0 , G0 (i) = G1 (i). example, given granularities week month,
granularity consisting first week month (among weeks intersecting
month) generated FirstWeekOfMonth = Select-by-intersect11 (week, month).
3.2.3 Set Operations
order set operations part calendar algebra make certain
computations easier, restrict operand granularities participating set operations
result operation always valid granularity: set operations
defined G1 G2 exists granularity H G1 G2
label-aligned subgranularities H. following, describe union, intersection,
difference operations G1 G2 , assuming satisfy requirement.
Union. union operation G1 G2 generates new granularity G0 collecting
granules G1 G2 . formally, G0 = G1 G2 granularity
label set LG0 = LG1 LG2 , LG0 ,

G1 (i), L1 ,
0
G (i) =
G2 (i), L2 L1 .
example, given granularities Sunday Saturday, granularity weekend days
generated WeekendDay = Sunday Saturday.
310

fiMapping Calendar Expressions Minimal Periodic Sets

Intersection. intersection operation G1 G2 generates new granularity G0 taking
common granules G1 G2 . formally, G0 = G1 G2 granularity
label set LG0 = LG1 LG2 , LG0 , G0 (i) = G1 (i) (or equivalently
G2 (i)).
Difference. difference operation G1 \ G2 generates new granularity G0 excluding
granules G2 G1 . formally, G0 = G1 \ G2 granularity
label set LG0 = LG1 \ LG2 , LG0 , G0 (i) = G1 (i).

4. Calendar Algebra Periodical Set
section first describe overall conversion process report
formulas specific conversion calendar algebra operation. Finally, present
procedure relabeling resulting granularity, sketch complexity analysis
considerations period length minimality.
4.1 Conversion Process
final goal provide correct effective way convert calendar expressions
periodical representations. appropriate limitations, calendar algebra
operation, periodical descriptions operand granularities known, possible
compute periodical characterization resulting granularity.
result allows us calculate, calendar, periodical description
granularity terms bottom granularity. fact, definition, bottom granularity fully characterized; hence possible compute periodical representation
granularities obtained operations applied bottom granularity.
Recursively, periodical description granularities obtained.
calendar algebra presented previous section represent granularities
periodical finite exceptions (i.e., granularity G bottom groups
periodically finite exceptions G). Since periodical representations defined
Section 2 possible express finite exceptions, need restrict calendar
algebra cannot represent them. implies allowing Subset operation
used last step deriving granularity. Note calendar algebra
presented Ning et al. (2002) extension altering-tick operation allow
usage parameter (i.e., G0 = Alter
l,k (G2 , G1 )); resulting granularity
single exception hence periodic. extension disallowed order
generate periodical granularities (without finite exceptions).
conversion process divided three steps: first one period length
period label distance computed; second derive set LP labels one
period, last one composition explicit granules computed.
operation identify correct formulas algorithms three steps.
first step consists computing period length period label distance
resulting granularity. values calculated function parameters (e.g.
grouping factor m, Group operation) operand granularities (actually
period lengths period label distances).

311

fiBettini, Mascetti & Wang

second step conversion process identification label set
resulting granularity. Section 2.4 pointed order fully characterize
granularity sufficient identify labels period granularity. spite
theoretical result, perform computations required operation need
explicit granules operand granularities aligned. two possible
approaches: first one consist computing explicit granules period
recalculate needed granules correct position order eventually align
them. second one consists aligning periods containing explicit granules
fixed granule bottom granularity. considering possibilities,
performance reasons, decided adopt second approach. decided use (1)
alignment point granularities. formal definition used formalism
follows.
Let G granularity smallest positive integer dieG defined.
call lG = dieG LG set labels G contained lG . . . lG +NG 1. Note
definition LG instance definition LP given Section 2.4. definition
LG provided useful representing G actually final goal step
compute LG ; however LG suitable performing computations. problem
G(lG ) starts (1) (i.e., min(blG cG ) < 1) granule G(lG + NG ) begins
PG PG , hence G(lG + NG ) necessary computations; however
lG + NG
/ LG .
solve problem introduce symbol LG represent set labels
granules G cover one (1) . . . (PG ). easily seen G(lG ) cover
(0), LG = LG , otherwise LG = LG {lG + NG }. Therefore conversion
L L vice versa immediate.
notion L still enough perform computations. problem
granularity G used operand operation, period length
resulting granularity G0 generally bigger period length G. Therefore
necessary extend notion LG period length PG0 G0 using PG0 spite
P 0
PG definition L. symbol used notion LGG .
P 0
idea G used operand operation generates G0 , LGG
computed LG . set used formula provide compute
LG0 .
computation LG0 performed follows: G0 defined operation
0 .
returns full-integer labeled granularity, sufficient compute value lG
0
0
0
Indeed easily seen LG0 = {i Z|lG lG + NG0 1}. G defined
algebraic operation, provide formulas compute LG0 ; LG0 easily
derive LG0 .
Example 3 Figure 3 shows granularities , G H; clear PG = PH = 4
NG = NH = 3. Moreover, lG = lH = 6 therefore LG = LH = {6, 7}. Since 0
/ b6cG
H
LG = LG . hand, since 0 b6c , LH = LH {6 + 3}.
P0
Suppose granularity G0 period length PG0 = 8; LGG = {6, 7, 9, 10}
P 0
LHG = {6, 7, 9, 10, 12}.

312

fiMapping Calendar Expressions Minimal Periodic Sets

^

-6 -5 -4 -3 -2 -1 0 1 2 3 4 5 6 7 8 9 10

G
1

3

4

6

7

9

10

12

H
1

3

4

6

7

9

10

12 13

Figure 3: L, l, L LPG0 examples
third (and last) step conversion process computation composition explicit granules. LG0 computed, sufficient apply,
label LG0 formulas presented Chapter 3.
Sections 4.3 4.10 show, calendar algebra operation, compute
first second conversion steps.
4.2 Computability Issues
formulas presented necessary compute set labels
granularity G G(i) H(j) H granularity j specific label
H. Since LG contains infinite number labels, possible check, LG
G(i) H(j). However easily seen k s.t. G(dkeG ) H(j). Therefore
k s.t. G(dkeG ) defined k bjcH .
Therefore compute set considering labels LG s.t. n bjcH s.t.
dneG = G(i) H(j). Since set bjcH finite3 , computation performed
finite time. consideration analogous set G(i) H(j)
(G(i) H(j) 6= ).
4.3 Group Operation
Proposition 1 G0 = Groupm (G), then:
PG
1. PG0 = GCD(m,N
NG0 =
G)
j
k

lG 1
+
1
;
2. lG0 =


3. LG0 G0 (i) =

NG
GCD(m,NG ) ;

Sim

j=(i1)m+1 G(j).

Example 4 Figure 4 shows example group operation: G0 = Group3 (G). Since
PG = 1 NG = 1, PG0 = 3 NG = 1. Moreover, since LG = {7}, lG = 7
therefore lG0 = 2 LG0 = {2}. Finally G0 (2) = G(8) G(7) G(6) i.e.,
G0 (2) = (0) (1) (2).
3. calendar algebra possible define granularities granules maps
infinite set time instants.

313

fiBettini, Mascetti & Wang

^

-6 -5 -4 -3 -2 -1 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20

G
-14-13-12-11-10 -9 -8 -7 -6 -5 -4 -3 -2 -1 0 1 2 3 4 5 6 7 8 9 10 11 12

G
-4

-3

-2

-1

0

1

2

3

4

Figure 4: Group operation example
4.4 Altering-tick Operation
Proposition 2 G0 = Alterm
l,k (G2 , G1 ) then:
1.


N

G0

PG2 NG1
NG2
= lcm NG1 , m,
,
GCD(PG2 NG1 , PG1 ) GCD(NG2 m, |k|)




PG0 =

NG0 k
NG0 PG1 NG2
+
NG1 PG2







PG2
NG2

0

2. lG0 = dlG2 eG
G2 ;
3. LG0 G0 (i) =

St0i

j=b0i

G(j) b0i t0i defined Section 3.1.2.

Referring step 2., note computing lG0 explicit characterization
0
granules G0 still unknown. perform operation dlG2 eG
G2 need know least
explicit granules one periods. choose compute granules labeled
1 . . . NG0 . lG0 derived, granules labeled lG0 . . . lG0 + NG0 1 computed
explicit granules aligned (1) required.
Example 5 Figure 5 shows example altering-tick operation: G0 = Alter32,1 (G2 , G1 ).
Since PG1 = 4, NG1 = 1, PG2 = 4 NG2 = 2, NG0 = 6 PG0 = 28.
G0 = 4
Moreover, since LG2 = {10, 9}, lG2 = 10 therefore lG0 = d10eG
2
hence LG2 = {4, 3, . . . , 0, 1}. Finally G0 (4) = G1 (11) G1 (10) G1 (9) =
(1) (0) (1) (3) (4); analogously derive G0 (3), G0 (2), G0 (1), G0 (0)
G0 (1).

4.5 Shift Operation
Proposition 3 G0 = Shiftm (G), then:
1. PG0 = PG1 NG0 = NG1 ;
2. lG0 = lG + m;
3. LG0 G0 (i) = G(i m).
314

fiMapping Calendar Expressions Minimal Periodic Sets

^

-3 -2 -1 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41

G1
-5

-4

-3

-2

-1

0

1

2

3

4

5

G2
-11 -10

-9

-8

-7

-6

-5

-4

-3

-2

-1

0

1

2

3

4

5

6

7

8

9

10

G
-4

-3

-2

-1

0

1

2

3

4

Figure 5: Alter operation example
Example 6 shifting operation easily model time differences. Suppose granularity
USEast-Hour stands hours US Eastern Time. Since hours US Pacific
Time 3 hours later US Eastern Time, hours US Pacific Time
generated USPacific-Hour= Shift3 (USEast-Hour).
USEast-Hour
-6 -5 -4 -3 -2 -1 0 1 2 3 4 5 6 7 8

USPacific-Hour
-9 -8 -7 -6 -5 -4 -3 -2 -1 0 1 2 3 4 5

Figure 6: Shift operation example

4.6 Combining Operation
Proposition 4 Given G0 = Combining(G1 , G2 ), then:
1. PG0 = lcm(PG1 , PG2 ) NG0 =
P

0

P

lcm(PG1 ,PG2 )NG1
;
PG1
P

0

0

2. LGG1 let se(i) = {j LGG2 | =
6 G2 (j) G1 (i)}; LG0 = {i LGG1 |e
s(i) 6= };

3. LG0 G0 (i) = js(i) G2 (j).
Example 7 Figure 7 shows example combining operation: G0 = Combine(G1 , G2 ).
Since PG1 = 6, NG1 = 2, PG2 = 4 NG2 = 2, PG0 = 12 NG0 = 4. Moreover,
P 0
since LG1 = {1} 0 b1cG1 , LG1 = {1, 3} hence LGG1 = {1, 3, 5}. Since
0
s(i) 6= {1, 3, 5}, LG0 = {1, 3, 5}; moreover, since 0 b1cG , LG0 = {1, 3}.
Finally s(1) = {1, 0} s(3) = {2, 3}; consequently, G0 (1) = G2 (1) G2 (0) i.e.,
G0 (1) = (1) (0) (1) G0 (3) = G2 (2) G2 (3) i.e., G0 (3) = (4) (5) (7).

4.7 Anchored Grouping Operation
Proposition 5 Given G0 = Anchored-group(G1 , G2 ), then:
1. PG0 = lcm(PG1 , PG2 ) NG0 =

lcm(PG1 ,PG2 )NG2
;
PG2

315

fiBettini, Mascetti & Wang

^

-6 -5 -4 -3 -2 -1 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20

G1
1

3

5

7

G2
-3

-2

-1

0

1

2

3

4

5

6

7

8

9

G
1

3

5

7

Figure 7: Combine operation example
2.
(
LG0 =

P

0

LGG2 ,
lG2 = lG1 ,
PG0
0
{lG2 } LG2 , otherwise,

0
lG
greatest among labels LG2 smaller lG2 .
2

3. LG0 G0 (i) =

Si0 1
j=i

G1 (j) i0 next label G2 i.

Example 8 Figure 8 shows example anchored grouping operation: USweek
(i.e., week starting Sunday) defined operation Anchored-group(day,
Sunday). Since Pday = 1 PSunday = 7, period length USweek 7. MorePUSweek
since lday = 11, lSunday = 14 LSunday
= {14}, LUSweek = {7} {14}.

Clearly, since 0 b7cUSweek LUSweek = {7}. Finally, USweek(7) = 13
j=7 day(j) =
S3
k=3 (k).

^

-18-17-16-15-14-13-12-11-10 -9 -8 -7 -6 -5 -4 -3 -2 -1 0 1 2 3 4 5 6 7 8 9 10 11 12

day
-8 -7 -6 -5 -4 -3 -2 -1 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22

Sunday
-7

0

7

14

21

USweek
-7

0

7

14

Figure 8: Anchored Grouping operation example

4.8 Subset Operation
Subset operation modifies operand granularity introducing bounds.
period length, period label distance, L composition explicit granules
affected.

316

fiMapping Calendar Expressions Minimal Periodic Sets

4.9 Selecting Operations
4.9.1 Select-down Operation
Proposition 6 Given G0 = Select-downlk (G1 , G2 ), then:
1. PG0 = lcm(PG1 , PG2 ) NG0 =
2. LG2 let

lcm(PG1 ,PG2 )NG1
;
PG1

6 G1 (j) G2 (i)}) .
A(i) = lk ({j LG1 | =




[ n
P 0
A(i)|a LGG1 ;

LG0 =

P 0

iLGG
2

3. LG0 G0 (i) = G1 (i).
Example 9 Figure 9 shows example Select-down operation granularity
G0 defined as: G0 = Select-down12 (G1 , G2 ). Since PG1 = 4, NG1 = 2 PG2 = 6
PG0 = 12 NG0 = 6. Moreover, since LG2 = {3} 0 b3cG2 , LG2 =
P 0
{3, 2} LGG2 = {3, 2, 1}. Intuitively, A(3) = {5}, A(2) = {2}
0
A(1) = {1}. Hence LG0 = {5, 2, 1} therefore, since 0 b5cG , LG0 = {5, 2}.
Finally G0 (5) = G1 (5) = (0) (1) G0 (2) = G1 (2) = (6).
^

-9 -8 -7 -6 -5 -4 -3 -2 -1 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25

G1
-9

-8

-7

-6

-5

-4

-3

-2

-1

0

1

2

3

4

5

6

7

G2
-4

-3

-2

-1

0

1

G
-8

-5

-2

1

4

Figure 9: Select-down operation example

4.9.2 Select-up Operation
Proposition 7 Given G0 = Select-up(G1 , G2 ), then:
1. PG0 = lcm(PG1 , PG2 ) NG0 =

lcm(PG1 ,PG2 )NG1
;
PG1

2.
P

0

LG0 = {i LGG1 |j LG2 s.t. =
6 G2 (j) G1 (i)};
3. LG0 G0 (i) = G1 (i).

317

7

fiBettini, Mascetti & Wang

Example 10 Figure 10 shows example Select-up operation: G0 = Select-up(G1 , G2 ).
Since PG1 = 6, NG1 = 3 PG2 = 4 PG0 = 12 NG0 = 6. Moreover, since LG1 =
P0

{3, 2, 1} 0 b3cG2 , LG1 = {3, 2, 1, 0} LGG1 = {3, 2, 1, 0, 1, 2, 3}.
Since G1 (3) G2 (6), G1 (1) G2 (4) G1 (3) G2 (0) LG0 = {3, 1, 3}
0
and, since 0 b3cG , LG0 = {3, 1} Finally G0 (3) = G1 (3) = (0) (1)
G0 (1) = G1 (1) = (4).
^

-9 -8 -7 -6 -5 -4 -3 -2 -1 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16

G1
-8 -7

-6

-5 -4

-3

-2 -1

0

1 2

3

4 5

G2
-10

-8

-6

-4

-2

0

2

G
-7

-3

-1

3

5

Figure 10: Select-up operation example

4.9.3 Select-by-intersect Operation
Proposition 8 Given G0 = Select-by-intersectlk (G1 , G2 ), then:
1. PG0 = lcm(PG1 , PG2 ) NG0 =

lcm(PG1 ,PG2 )NG1
;
PG1

2. LG2 let
A(i) = lk ({j LG1 |G1 (j) G2 (i) 6= }) .

LG0 =


[ n
P 0
A(i)|a LGG1 .
P 0

iLGG
2

3. LG0 G0 (i) = G1 (i).
Example 11 Figure 11 shows example Select-by-intersect operation
G0 = Select-by-intersect12 (G1 , G2 ). Since PG1 = 4, NG1 = 2 PG2 = 6 PG0 = 12
NG0 = 6. Moreover, since LG2 = {3} 0 b3cG2 , LG2 = {3, 2}
P 0
LGG2 = {3, 2, 1}. Intuitively, A(3) = {6}, A(2) = {2} A(1) = {0}. Hence
0
LG0 = {2, 0} therefore, since 0
/ b5cG , LG0 = {2, 0}. Finally G0 (2) =
G1 (2) = (6) G0 (0) = G1 (0) = (10).

318

fiMapping Calendar Expressions Minimal Periodic Sets

^

-9 -8 -7 -6 -5 -4 -3 -2 -1 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25

G1
-9

-8

-7

-6

-5

-4

-3

-2

-1

0

1

2

3

4

5

6

7

G2
-4

-3

-2

-1

0

1

G
-8

-6

-2

0

4

6

Figure 11: Select-by-intersect operation example
4.10 Set Operations
Since set operation valid granularities used argument labeled aligned
granularity another granularity, following property used.
Proposition 9 G labeled aligned subgranularity H,

NG
PG

=

NH
PH .

Proposition 10 Given G0 = G1 G2 , G00 = G1 G2 G000 = G1 \ G2 , then:
1. PG0 = PG00 = PG000 = lcm(PG1 , PG2 )
lcm(PG1 ,PG2 )NG1
=
NG0 = NG00 = NG000 =
PG
1

P

0

P

0

P

00

P

lcm(PG1 ,PG2 )NG2
;
PG2

00

P

000

P

000

2. LG0 = LGG1 LGG2 ; LG00 = LGG1 LGG2 ; LG000 = LGG1 \ LGG2 ;

G1 (i), LG1
0
3. LG0 G (i) =
G2 (i), otherwise,
LG00 G00 (i) = G1 (i) LG000 G000 (i) = G1 (i)
Example 12 Figure 12 shows example set operations. Note G1
G2 labeled aligned subgranularities H. G0 = G1 G2 , G00 = G1 G2
G000 = G1 \ G2 . Since PG1 = PG2 = 6 NG1 = NG2 = 6 PG0 = PG00 = PG000 = 6
NG0 = NG00 = NG000 = 2. Moreover, since LG1 = {1, 2} LG2 = {2, 3},
LG0 = {1, 2, 3}, LG00 = {2} LG000 = {1}. Finally G0 (1) = G1 (1), G0 (2) = G1 (2)
G0 (3) = G2 (3); G00 (2) = G1 (2) G000 (1) = G1 (1).

4.11 Relabeling
Granularity processing algorithms much simpler restricted operate full-integer
labeled granularities. Moreover, simplification obtained using positive integers set labels (i.e., L = Z+ ).
section show relabel granularity G obtain full-integer labeled
granularity G0 . granularity G00 LG00 = Z+ obtained using G00 =
0
Subset
1 (G )
Note relabeling process information lost: example, G
labeled aligned subgranularity H G 6= H, then, relabeling, G
319

fiBettini, Mascetti & Wang

^

-9 -8 -7 -6 -5 -4 -3 -2 -1 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25

H
-3

-2

-1

-2

-1

0

1

2

1

2

3

4

5

4

5

6

7

8

7

8

9

10

G1
10

G2
-3

-1

0

-1

0

2

3

2

3

5

6

5

6

8

9

8

9

G
-3

-2

1

4

7

10

G
-1

2

5

8

G
-2

1

4

7

10

Figure 12: Set operations example
labeled aligned subgranularity H. lost information semantically meaningful
calendar algebra, therefore relabeling must performed granularity
used operator algebraic operation.
Let G labeled granularity, j integers LG s.t. G(i) 6= .
relabeling operation Relabelji (G) generates full-integer labeled granularity G0 relabeling
G(i) G0 (j) relabel next (and previous) granule G next (and previous,
respectively) integer. formally, integer k, k = j, let G0 (k) = G(i),
otherwise let G0 (k) = G(i0 ) G(i0 ) |j k|-th granule G (before,
respectively) G(i). required |j k|-th granule G exist, let G0 (k) = .
Note G0 always full-integer labeled granularity.
relabeling procedure implemented periodic representation adopted
computing value lG0 . easily seen lG0 known, full characterization G0 obtained with: PG0 = PG ; NG0 = RG0 = RG LG0 =
{lG0 , lG0 + 1, . . . , lG0 + NG0 2, lG0 + NG0 1}. clear explicit representation
granules modified.
j
k
ilG
0
0
compute lG consider label = NG NG ; i0 represents label LG
i0 multiple NG . jTherefore
clear label j 0 LG0 s.t. G0 (j 0 ) = G(i0 )
k
G
computed j 0 = j il
NG0 . Finally lG0 obtained lG0 = j 0 ||
NG
distance, terms number granules G, G(lG ) G(i0 ).
4
Example 13 Figure 13 shows example Relabel operation: G0 = Relabel
33 (G).
336
0
Since PG = 4and R
= 33
5 = 8
5
G = 2 PG0 = 4 NG0 0 = 2. Moreover,
0 ) next granule G
j 0 = 4 336

2
=
6.
Since
l
=
6


=
8

G(i
G
5
G(lG ). = 1 hence lG0 = 6 1 = 7. follows LG0 = {7, 6}.
Finally G0 (7) = G(6) G0 (6) = G(8).

GSTP constraint solver imposes first non-empty granule granularity
( included) labeled 1. Therefore, using relabeling operation producing
320

fiMapping Calendar Expressions Minimal Periodic Sets

Figure 13: Relabeling example
granularities GSTP, parameter j must set 1. parameter equal
smallest label among identify granules G covering granules
labeled positive values. definition lG , = lG min(blG cG ) > 0; otherwise
next label G lG .
4.12 Complexity Issues
operation time necessary perform three conversion steps, depends
operation parameters (e.g. grouping factor m, Group operation)
operand granularities (in particular period length, period label distance
number granules one period).
central issue operand granularity bottom granularity,
period function periods granularities operands operation
defines it. algebraic operations, worst case period
resulting granularity product periods operands granularity.
operations, first step conversion process performed
constant logarithmic time. Indeed formulas necessary derive period length
period label distance involve (i) standard arithmetic operations, (ii) computation
Greatest Common Divisor (iii) computation least common multiple. Part
(i) computed constant time (ii) (iii) computed logarithmic
time using Euclids algorithm.
operations, second step performed constant time (e.g. Group,
Shift Anchored-group) linear time (e.g. set operations). operations
necessary compute set labels granularity G G(i) H(j)
H granularity j LH (analogously set G(i)
H(j) (G(i) H(j) 6= )). computation needs performed
P 0
granule PHG . idea algorithm solving problem presented
Section 4.2. Several optimizations applied algorithm, worst
case (when H covers entire time domain) necessary perform number deG
operations linear period length resulting granularity. optimized data
structure used represent granularities, deG operation performed
constant time 4 , time necessary perform second step linear period
length resulting granularity (O(PG0 )).
last step conversion process performed linear time respect
number granules period G0 .
4. non-optimized data structure used, deG requires logarithmic time.

321

fiBettini, Mascetti & Wang

complexity analysis conversion general algebraic expression needs
consider composition operations hence complexity. Finally, relabeling,
done linear time.
detailed complexity analysis scope work.

5. Minimal Representation Experimental Results
section address problem guaranteeing converted representation
minimal terms period length. show Example 14 conversion
formulas proposed paper guarantee minimal representation result
clear conversion formulas ensuring minimality exist. approach apply
minimization step conversion.
practical applicability minimization step depends period length
representation minimized. Indeed, tests noted minimization
step efficient conversion formulas proposed Section 4 adopted,
impractical conversion procedure returns period orders magnitude
higher minimal one would case conversion formulas constructed
naive way.
5.1 Period Length Minimization
stated Section 2, granularity different periodical representations and,
given granularity, possible identify set representations minimal
i.e. adopting smallest period length.
Unfortunately, conversions always return minimal representation, shown
Example 14.
Example 14 Consider calendar day bottom granularity. define
week week = Group7 (day); applying formulas Group operation obtain
Pweek = 7 Nweek = 1.
apply Altering-tick operation add one day every first week every
two weeks. Let granularity G1 = Alter21,1 (day, week); applying formulas
Altering-tick operation obtain PG1 = 15 NG1 = 2.
apply Altering-tick operation create granularity G2 removing
one day every first granule G1 every two granules G1 : G2 = Alter21,1 (day, G1 ).
Intuitively, applying operation get back granularity week, however
using formulas Altering-tick operation obtain PG2 = 14 NG2 = 2; Hence
G2 minimal.
order qualitatively evaluate close minimal representations results
conversions are, performed set tests using algorithm (Bettini & Mascetti,
2005) minimality checking. experimental results conversions algebraic
expressions defining granularities real-world calendars, including many user-defined nonstandard ones, always returned exactly minimal representations. Non-minimal ones could
obtained artificial examples like one presented Example 14.
Although non-minimal result unlikely practical calendars, minimality
granularity representation known greatly affect performance algorithms
322

fiMapping Calendar Expressions Minimal Periodic Sets

granularity processing, e.g., granularity constraint processing (Bettini et al., 2002a), calendar calculations (Urgun et al., 2007), workflow temporal support (Combi & Pozzi, 2003).
Hence, considered extension conversion algorithm adding minimization
step exploiting technique illustrated Bettini et al. (2005) derive minimal representation.
choice using conversion algorithm extended one minimizations, probably driven performance considerations. Section 5.3 report
results experiments showing generally advantageous apply minimization step. implementation, presented Section 5.2, possible specify
minimization step performed.
5.2 Implementation CalendarConverter Web Service
conversion formulas presented Section 4 implemented CalendarConverter web service converts Calendar Algebra representations equivalent
periodical ones. precisely, given calendar granularities expressed Calendar Algebra operations, service converts operation equivalent periodical
representation.
service first rewrites calendar algebra expression order express
terms bottom granularity. example, bottom granularity hour,
expression Monday = Select-down11 (day, week) changed
Monday = Select-down11 (Group24 (hour), Group7 (Group24 (hour)))
Then, Procedure 1 run granularitys expression. idea periodical
representation subexpression recursively computed starting expressions
bottom granularity operand. operand given operation
converted periodical representation, corresponding formula presented Section 4
applied. call step ConvertOperation procedure.
trivial optimization Procedure 1 consists caching results conversions
subexpression computed once, even subexpression appears
several times (like Group24 (hour) Monday definition).
5.3 Experimental Results
experiments address two main issues: first, evaluate conversion formulas
impact practical applicability conversion procedure and, second, evaluate
useful minimization step.
first issue, execute conversion procedure two different sets conversion formulas compare results. first set laid Section 4. other,
less optimized, taken preliminary version paper (Bettini et al.,
2004).
Table 1 shows converting calendars granularities small minimal
period length (first two rows), using formulas Section 4 improves performance
one order magnitude; However, conversions minimizations almost instantaneous approaches. contrary, minimal period length higher,
323

fiBettini, Mascetti & Wang

Procedure 1 ConvertExpression
Input: calendar algebra expression ex; boolean value minimize set
true minimization step executed;
Output: periodical representation ex;
Method:
1:
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:

(ex bottom granularity)
return periodical representation bottom granularity
end
operands :=
(each operand op ex)
add ConvertExpression(op, minimize) operands;
end
result :=ConvertOperation(ex.getOperator(), operands)
(minimize)
minimize periodical representation result
end
return result;

Table 1: Impact conversion formulas performance conversion minimization procedures (time milliseconds).

Calendar
Period
Bot
1 year
day
4 years
day
1 year
hour
4 years
hour
100 years day

Section 4 formulas
Conv. Min. Tot.
4
2
6
7
2
9
9
2
11
16
4
20
127
9 136

Less optimized formulas
Conv.
Min.
Tot.
62
32
94
76
55
131
2,244
126,904
129,148
4,362
908,504
912,866
3,764 1,434,524 1,438,288

(last three rows) time required minimize periodical representation five
orders magnitude larger formulas proposed Bettini et al. (2004) used;
consequence, entire conversion may require several minutes while, using formulas
presented Section 4, still requires fraction second. period length
even larger, conversion procedure impractical formulas presented Bettini et
al. (2004) used, indeed experiments obtain result less
thirteen hours.
second issue, perform set three experiments. first one compare
performance conversion procedure performance minimization step.

324

fiMapping Calendar Expressions Minimal Periodic Sets

experiment consider case conversion procedure produces minimal
representations. case minimization step always overhead since cannot
improve performance conversion procedure.
Figure 14 shows result experiment. Four calendars considered, one
containing set granularities Gregorian calendar. four calendars differs
values two parameters: bottom granularity (it second cal-1 cal-3
minute cal-2 cal-4) period leap years leap years exceptions
represented (it 1, 4, 100 400 years cal-1, cal-3, cal-2 cal-4 respectively);
consequence, minimal period length granularities month year
3 107 cal-1, 5 107 cal-2, 108 cal-3 2 108 cal-4.

Figure 14: Impact minimization conversion; minimal conversions case.
observed Figure 14, ratio time required perform
conversions time required minimization step varies significantly
minimum 3% cal-4 maximum 23% cal-3. reason complexity
conversion procedure mainly affected period length granularity
largest period length. hand, complexity minimization step
affected also features granularities internal structure
number integers divide time period label distance, period
length number granules one period; details see (Bettini & Mascetti,
2005).
second experiment consider case conversion procedure produces non-minimal representation granularity input calendar; case
possible benefit minimization step. example, suppose granularity G
converted used argument another Calendar Algebra operation
defines granularity H. time required compute periodical representation
H strongly depends period length G; period length G reduced
execution minimization step, conversion H executed faster.
produced situation using technique similar one Example 14;
created Calendar Algebra definitions Gregorian calendar granularity
day converted granularity non-minimal representation. Figure 15 shows
performance obtained converting granularities used Figure 14.
325

fiBettini, Mascetti & Wang

difference case definition granularity day that,
conversion procedure, period twice large minimal one (i.e., 48 hours
2880 minutes 172800 seconds depending bottom granularity used).
easily seen case use minimization step improve performance
entire algorithm. Indeed, minimization step performed, conversion
procedure requires one half time required minimization
performed.

Figure 15: Impact minimization conversion; non-minimal case.
third experiment evaluate impact minimal representation
performance applications involving intensive manipulations granularities. test
use GSTP solver application; computes solutions temporal constraints
granularities. description architecture GSTP system provided
Section 6.1.
Figure 16 shows experiments performed four temporal constraint networks
granularities. four networks differs number variables, number constraints granularities used express constraints. networks labeled
non-minimal use granularities definitions obtained technique similar
one used Example 14, period twice large minimal one.
Figure 16 shows use minimal representations greatly improves performance GSTP solver. Indeed experiments ratio time required
solve network using non-minimal representation minimal one
three five. Moreover, time required solve network, greater
improvement obtained using minimal representation; means complex
temporal networks expect improvement even higher.
Considering results experiments, conclude that, general, advisable
perform minimization step. particular, advantageous specific case
GSTP, based following considerations: i) time required perform minimization step fraction time required perform conversion procedure, ii)
conversions performed off-line cases, respect granularity processing,
conversion results cached future use, iii) period length strongly influ-

326

fiMapping Calendar Expressions Minimal Periodic Sets

Figure 16: Impact minimal representations performance GSTP solver.
ences GSTP processing time cases much longer time needed
conversion.

6. Applications
section complement motivations work sketch applications
enabled proposed conversion. Firstly describe GSTP system, example
applications involving intensive manipulation time granularities. GSTP used
check consistency find solutions temporal constraint satisfaction problems
granularities5 ; also applied check consistency inter-organizational
workflow models (Bettini, Wang, & Jajodia, 2002b). Then, discuss use Calendar
Algebra define new granularities may later part input reasoning services,
GSTP.
6.1 GSTP System
GSTP system developed University Milan objective
providing universal access implementation set algorithms multi-granularity
temporal constraint satisfaction (Bettini et al., 2002a). allows user specify binary
constraints form X [m, n]G n minimum maximum
values distance X terms granularity G. Variables take values
positive integers, unary constraints applied domains. example,
constraint: Event2 occur 2 4 business days occurrence Event1
modeled OccE2 OccE1 [2, 4]BDay. problem considered extension STP
(Dechter, Meiri, & Pearl, 1991) multiple arbitrary granularities. knowledge,
GSTP available system solve class temporal constraint satisfaction
problems.
Figure 17 shows general architecture GSTP system. three main
modules: constraint solver; web service, enables external access solver;
5. detailed description system, see (Bettini et al., 2005).

327

fiBettini, Mascetti & Wang

user interface used locally remotely design analyze constraint
networks.

Figure 17: GSTP Architecture
constraint solver C implementation ACG algorithm
proposed Bettini et al. (2002a), runs server machine. Following approach Bettini et al. (2002a), solver uses representation granularities based
periodical sets. representation makes possible efficiently compute core operations granularities required solve constraint satisfaction problem.
operations involve, example, union intersection periodical sets.
cannot exclude operations may computed terms alternative low level
representations, seems much harder obtain similar results high level representation,
Calendar Algebra, used.
second module system Web Service defines, WSDL
specification, parameters passed constraint solver, including
XML schema constraint network specification.
third module remote Java-based user interface, allows user easily
edit constraint networks, submit constraint solver, analyze results.
particular, possible views terms specific granularities, visualize implicit
constraints, browse descriptions domains, obtain network solution. Fig. 18
shows screenshot interface.
6.2 Defining New Granularities
GSTP solver handle arbitrary granularities, new granularities must added
editing explicit periodical representation. true general multi328

fiMapping Calendar Expressions Minimal Periodic Sets

Figure 18: GSTP User Interface
granularity reasoning service based low-level representation granularities,
painful task granularities large period. example, experimental
results illustrated Figure 16, used representation granularity month
considers leap years leap years exceptions period 400 years. case,
users specify representation 4800 granules i.e., number months 400
years.
period length real world granularities generally high, graphical interface help supports user individually select explicit granules.
effective solution requires use implicit explicit operations granules. Among
various proposals, Calendar Algebra provides richest set operators. question
arises: definition granularities terms Calendar Algebra really simpler
specification periodical representation? Calendar Algebra seem user
friendly: exact semantics operator may immediate inexperienced
user time required order learn use operator.
practice, think reasonable ask unexperienced user
define granularities writing Calendar Algebra expressions. Nevertheless, think
Calendar Algebra used specialized user interfaces guide user
specifying granularities. sense, believe Calendar Algebra plays
role SQL definition databases queries. Similarly Calendar Algebra,
SQL abstraction tool directly exploited expressive power
advanced user, also used less experienced user graphical user
interface, possibly reduced expressiveness.
mentioned above, case periodical representations, graphical user interfaces
sufficient making specification new granularities practical. contrary, case Calendar Algebra, user interfaces strongly enhance usability
Calendar Algebra, making practical use possible also definition involved
granularities. least two reasons difference. Firstly, main difficulty
Calendar Algebra understanding semantics operators choice
appropriate one given task. effective user interface hide existence algebraic operators user showing operators modify existing

329

fiBettini, Mascetti & Wang

(a) Step 1.

(b) Step 2.

(c) Step 3.

Figure 19: 3-steps wizard visually defining granularity using Calendar Algebra
granularities (i.e., semantics operators). Secondarily, Calendar Algebra allows
compact definition granularities. due fact Calendar Algebra
operations specifically designed reflect intuitive ways users define new
granularities.
Example 15 shows graphical user interface effectively used define new
granularity terms Calendar Algebra expression.
Example 15 example shows graphical user interface used support
user definition granularity final set days, one corresponding
330

fiMapping Calendar Expressions Minimal Periodic Sets

last Monday every academic semester. assume granularities Monday
academicSemester already defined. graphical user interface use
example wizard guides user step step. first step (Figure 19(a))
user chooses kind operation wants perform. second step (Figure 19(b))
user provide details wants modify operand granularity
(Monday, example). results choice Calendar Algebra expression
shown third step (Figure 19(c)); last window user also give name
granularity defined.
6.3 Global Architecture

Figure 20: Integration GSTP CalendarConverter web services
Figure 20 shows possible architecture integration GSTP, interface
new granularity definitions CalendarConverter web service. granularity repository
collects Calendar Algebra definitions. Upon request GSTP system definitions
converted low-level representation CalendarConverter web service efficiently
processed. Clearly, caching techniques used optimize process.

7. Related Work
Several formalisms proposed symbolic representation granularities
periodicity. Periodicity application AI DB area extensively
investigated (Tuzhilin & Clifford, 1995; Morris, Shoaff, & Khatib, 1996; Kabanza, Stevenne,
& Wolper, 1990; Ladkin, 1986). Regarding symbolic representation, well known
formalism proposed Leban et al. (1986), based notion collection,
intended represent temporal expressions occurring natural language. collection
structured set time intervals order collection gives measure
structure depth: order 1 collection ordered list intervals, order n
(n > 1) collection ordered list collections order n 1. Two operators,
331

fiBettini, Mascetti & Wang

called slicing dicing used operate collections selecting specific intervals
sub-collections, dividing interval collection, respectively.
example, Weeks:during:January2006 divides interval corresponding January2006
intervals corresponding weeks fully contained month.
formalism adopted extensions many researchers AI (Koomen,
1991; Cukierman & Delgrande, 1998) Database area (Chandra, Segev, & Stonebraker,
1994; Terenziani, 2003). particular, control statements if-then-else
introduced Chandra et al. (1994) facilitate representation certain
sets intervals. example, possible specify: fourth Saturday April
holiday, previous business day otherwise.
deductive database community, second influential proposal slice
formalism introduced Niezette et al. (1992). slice denotes (finite infinite) set
necessarily consecutive time intervals. example, slice all.Years + {2,4}.Months
+ {1}.Days . 2.Days denotes set intervals corresponding first 2 days February
April year.
totally different approach calendar algebra described Ning et al. (2002),
considered paper. representation based rich set algebraic operators
periodic sets opposed slicing dicing nonconvex intervals.
None cited papers provide mapping identify operator changes
mathematical characterization periodicity argument expressions.
problem finding mappings trivial operators.
(Bettini & Sibi, 2000) expressive power algebras proposed Leban et
al. (1986) Niezette et al. (1992) compared extension first proposed
order capture larger set granularities. Since periodical representation
used compare expressiveness, mapping calendar expressions formalisms
periodical representations found proofs paper. However, since
minimality issue purpose comparing expressiveness, many cases
mapping returns non-minimal representations.
Regarding alternative approaches low-level representation, already mentioned
ones based strings (Wijsen, 2000) automata (Dal Lago, Montanari, &
Puppis, 2003; Bresolin et al., 2004) may considered alternative target
conversion. matter fact, example conversion Calendar Algebra
expression string based representation found (Dal Lago & Montanari,
2001). complete conversion procedure appeared revision process paper
PhD Dissertation Puppis (2006). aim conversion prove
granspecs formalism, used represent granularities terms automata, least
expressiveness Calendar Algebra. Hence, obtaining minimal representations
goal. Moreover, case minimization terms period length,
terms automaton size automaton complexity. complexity reasoning,
given automaton , worst case time complexity operations analogous
depends linearly ||M ||, value computed called complexity
. sense ||M || role period length (P ), even precise
relationship two values hard obtain. approach compute
logarithmic time respect P linear time respect dimension
result (that bounded P ). operations, like checking equivalence, seem
332

fiMapping Calendar Expressions Minimal Periodic Sets

complex using automata (Bresolin et al., 2004). Techniques minimization
terms automaton complexity presented Dal Lago et al. (2003), time
complexity proved polynomial, even exact bound explicitly given.
3
approach, worst case time complexity minimization O(P 2 ) (Bettini &
Mascetti, 2005). Overall, automata approach elegant well-founded, but,
one side still misses implementation order experimental data
compare with, side basic operations currently defined;
would interesting investigate definition formalism complex
operations like ones required GSTP.

8. Conclusion Future Work
presented hybrid algorithm interleaves conversion Calendar Algebra
subexpressions periodical sets minimization period length.
proved algorithm returns set-based granularity representations minimal
period length, extremely important efficiency operations granularities. Based technical contribution paper, software system developed
allowing users access multi-granularity reasoning services defining arbitrary time granularities high-level formalism. current efforts mainly devoted completing
refining development different modules architecture shown Section 6.3.
future work, intend develop effective graphical user interfaces support
definition Calendar Algebra expressions user friendly way. Example 15 described one
possible interfaces. Another open issue convert periodical representation
granularity user friendly Calendar Algebra expression. conversion could
useful, example, present result computation performed using periodical
representation. However, naive conversion may effective since resulting calendar
algebra expression could involved periodical representation
derived. example, conversion procedure presented Bettini et al. (2000) prove
Calendar Algebra least expressive periodical representation; however,
resulting Calendar Algebra expression composed number Calendar Algebra
operations linear number granules one period original
granularity. contrary, effective conversion generate Calendar Algebra
expressions compact easily readable user. problem somehow
related discovery calendar-based association rules (Li, Ning, Wang, & Jajodia,
2001). Finally, intend investigate usage automaton-based representation
low-level granularity formalism. would interesting know whether, using
representation, possible compute operations computed
periodical representation performance gain could achieved.

Acknowledgments
thank anonymous referees useful comments suggestions. work
Bettini Mascetti partially supported Italian MIUR InterLink project N.II04C0EC1D.
work Wang partially supported US NSF grant IIS-0415023.

333

fiBettini, Mascetti & Wang

Appendix A. Proofs
A.1 Transitivity Periodically Groups Relationship
order prove correctness conversions algebraic expressions periodical
sets, useful formal result transitivity periodically groups
relation. addition transitivity / , Theorem 1 also says something period
length values.
Theorem 1 Let G H two unbounded granularities G periodic terms
bottom granularity (i.e., / G) H periodic terms G (i.e., G / H). Let
G period length period label distance H terms granules
PHG NH
G, NG period label distance G terms . Then, PHG = NG
positive integer , H periodic terms bottom granularity (i.e., / H)
PH = PG .
G

Proof. Since
Sni hypothesis G / H PH = NG , H(i) =
G
NH ) = r=0 G(ir + NG ). also written follows:


Sni

r=0 G(ir ),

H(i +

H(i) = G(i0 ) ... G(ini )

(1)

G
H(i + NH
) = G(i0 + NG ) ... G(ini + NG )

(2)

Ns.t.:

Since / G,


G(ij ) =

ij
[

(ij,k )

(3)

(ij,k + PG )

(4)

k=0




G(ij + NG ) =

ij
[

k=0

clearly extended using NG instead NG .


G(ij + NG ) =

ij
[

(ij,k + PG )

(5)

k=0

Rewriting (1) substituting G(ij ) according (3) rewriting (2) substituting G(ij +
NG ) according (5), obtain:
H(i) = (i0,0 ) . . . (i0,i0 ) . . . (ini ,0 ) ... (ini ,in )

|
{z
}
|
{z
}
G(i0 )

G(ini )

334

fiMapping Calendar Expressions Minimal Periodic Sets

G ) = (i
H(i + NH
0,0 + PG ) . . . (i0,i0 + PG ) . . .
{z
}
|
G(i0 +NG )

(ini ,0 + PG ) . . . (ini ,in + PG )

|
{z
}
G(ini +NG )

Hence second condition Definition 5 satisfied. third one always satisfied
unbounded granularities. first one satisfied too; fact since G / H period
G , label H, + N G label H. Hence, definition
label distance NH
H
G.
periodically-groups-into / H PH = PG NH = NH

A.2 Proof Proposition 1
A.2.1 Part 1
definition Group operation, N:
0

G (i) =

im
[

G(j) = G(im + 1) . . . G(im) = G() . . . G( + 1)

j=(i1)m+1

= im + 1. Furthermore, k N:
(i+k)m

[

0

G (i + k) =

G(j) = G(im + km + 1) . . . G(im + km) =

j=(i+k1)m+1

= G( + km) . . . G( + km + 1)
Hence,
0

0

G (i ) =

m1
[

0

m1
[

0

G( + r) G (i + k) =

r=0

G( + r + km).

(6)

r=0

G
holds k. use k = GCMN(m,N
(note k N), hypotheses
G)
Theorem 1 satisfied: (i) / G (by hypothesis); (ii) G / G0 (since G / G0 , LG0 = Z,
mNG
NG
(6) holds); (iii) PGG0 = GCM
(m,NG ) (since use k = GCM (m,NG ) and, (6)

know PGG0 = km). Therefore, Theorem 1, / G0 PG0 =
NG0 =

mPG
GCM (m,NG )

NG
GCM (mNG ) .

A.2.2 Part 2
definition Group

j

k

j

G0





lG 1
+1

0
operation, G (i) =

definition l, need show G0



lG 1
+1




lG 1


k
+1

[

=
j=

335


= tj=b G(j) b lG t.
Sim
j=(i1)m+1 G(i) ; hence:

j

lG 1


k
m+1

G(j)



fiBettini, Mascetti & Wang

prove thesis showing (1)
lG .
(1) Since

j

lG 1


k



lG 1
,

j

lG 1


lG 1
G
lm

lG 1[(lG 1)mod m]
G
lm
1;


(2) First prove
prove

hence
k
j

j

lG 1


k

m+1 lG (2)

j

lG 1


k


+ 1

k

+ 1 lG
j
k
1. Since lGm1 =

lG 1[(lG 1)mod m]




equivalent thej inequality
[(lG 1)mod m]
k

+ 1 true since (lG 1)mod 1. Since
k

j
lG 1
+
1
lG .


lG 1




lG


1 trivial

A.3 Proof Proposition 2
A.3.1 Part 1
Proof sketch
show G2 / G0 PGG02 = NG2 apply Theorem 1 obtain thesis.
particular use


PG2 NG1
NG2
= lcm NG1 , m,
,
GCD(PG2 NG1 , PG1 ) GCD(NG2 m, |k|)



PG2
PG1 NG2
k

=
+
NG1 PG2

NG2


that, i, j, k : G0 (i) = kr=0 G2 (j + r), G0 (i + ) = kr=0 G2 (j + r +
NG2 ).
Given arbitrary granule G0 (i), show G0 (i + ) union granules
obtained adding NG2 index granule G2 contained G0 (i). Note
+ LG0 since G0 full-integer labeled. order show correct
consider way granules G0 constructed definition altering-tick. precisely,
compute difference label b0i+ first granule G2 included
G0 (i + ) label b0i first granule G2 included G0 (i); show
difference equal difference label t0i+ last granule G2 included
G0 (i + ) label t0i last granule G2 included G0 (i). fact together
consideration G2 full-integer labeled granularity, leads conclusion
G0 (i) G0 (i + ) number granules. clear
computed label differences also equal difference label arbitrary
n-th granule G2 included G0 (i + ) label n-th granule
G2 included

G0 (i). difference b0i+ b0i , have: j, k : G0 (i) = kr=0 G2 (j + r),


G0 (i + ) = kr=0 G2 j + r + b0i+ b0i . showing b0i+ b0i multiple NG2
thesis follows.
Proof details


336

fiMapping Calendar Expressions Minimal Periodic Sets

Si
Sti+
Assume G1 (i) = tj=b
G2 (j) G1 (i + ) = j=b
G2 (j). need compute

i+
0
0
bi+ bi . definition altering-tick operation:
b0i

=



k
bi + il



bi +

il


=

il


+ l,
(7)


+ 1 k otherwise.


b0i+

=




k
bi+ + i+l



bi+ +

i+l


+ =

i+l


+ l,
(8)


+ 1 k otherwise.






Note = il
+ l, + = i+l
Indeed, i+l
+l =

+ l.

il

il

il
+
m+l
and,
since



multiple

m,

+
m+l
=
+
m+







il
l = + + l.
Hence, compute b0i+ b0i consider two cases:
b0i+ b0i =






k bi il
k = il
m+l
bi+ + i+l





bi+ +

i+l


(9)




+ 1 k bi il
+ 1 k otherwise.

cases (again considering fact multiple m):
b0i+ b0i = (bi+ bi ) +

k


(10)

left compute bi+ bi , i.e., distance terms granules G2 , G2 (bi )
Sti+
Si
G2 (j),
G2 (j) G1 (i + ) = j=b
G2 (bi+ ). Since, hypothesis, G1 (i) = tj=b

i+
first granule making G2 (bi ) first granule making G1 (i)
granule. observed first granule making G2 (bi+ )
first granule making G1 (i + ). formally:
min bbi cG2 = min bicG1

min bbi+ cG2 = min bi + cG1
Hence, have:
min bbi+ cG2 min bbi cG2 = min bi + cG1 min bicG1

(11)

shown difference index first granule making
G2 (bi+ ) index first granule making G2 (bi ) equal difference
index first granule making G1 (i + ) index first
granule making G1 (i). Then, need compute difference index
first granule making G1 (i + ) index first granuleSof making
G1 (i). Since / G1 multiple NG1 , i, j, : G1 (i) = r=0 (j + r),
337

fiBettini, Mascetti & Wang


P
P
G1 (i + ) = r=0 (j + NGG1 ). Hence, difference value NGG1 ,
1
1
shown also value difference index first granule
making G2 (bi+ ) index first granule making G2 (bi ). Then, since
P
/ G2 period length PG2 since NGG1 multiple PG2 , that, if:
1

(j) G2 (i)
then:
(j +
Thus, bi+ bi =
Reconsidering 10:

PG1
PG1 NG2
)
) G2 (i +
NG1
NG1 PG2

PG1 NG2
NG1 PG2 .

b0i+ b0i =

PG1 NG2
k
+
.
NG1 PG2

P

N

Analogously compute t0i+ t0i = NGG1PGG2 + k
.
1
2
0
0
0
0
Thus, bi+ bi = ti+ ti ; hence ti+ bi+ = ti bi . Since G2 full integer labeled
granularity, G0 (i) G0 (i + ) formed number granules.
St0i+
St0i
0
0
0
0
Since know G0 (i+) = j=b
G2 (j) = j=b
0 G2 (j +(bi+ bi )) (bi+ bi )
0


i+

/ G0 ,

PGG02

PG1 NG2
NG1 PG2

multiple NG2 , G2
=
/ G2 . Hence,
hypothesis Theorem 1 hold, application leads thesis proposition.
A.3.2 Part 2
0

Since G2 partitions G0 (see table 2.2 (Bettini et al., 2000)), (1) dlG2 eG
G2 al+
ways defined (2) min({n N |i LG2 s.t. (n) G2 (i)}) = min({m N+ |j
LG0 s.t. (m) G0 (j)}). Therefore lG0 label granule G0 covers
0
granule G2 labeled lG2 ; definition de operation, lG0 = dlG2 eG
G2 .
A.4 Proof Proposition 3
A.4.1 Part 2
definition Shift operation, G0 (i) = G(im). Hence G0 (lG +m) = G(lG +mm) =
G(lG ).
A.5 Proof Proposition 4
A.5.1 Part 1
thesis follow application Theorem 1. Indeed, know / G2
show G2 / G0 PGG02 multiple
s.t.,
NG2 . we0 need identify

0
i, exists s(i) s.t. G (i) = js(i) G2 (j), G (i + ) = js(i) G2 (j + NG2 ).
lcm(P

,P

)N

G1 G2
G1
Consider arbitrary N =
. definition combining
PG1


0
0
operation, G (i) = js(i) G2 (j) G (i + ) = js(i+) G2 (j)

s(i) = {j LG2 | =
6 G2 (j) G1 (i)}
338

fiMapping Calendar Expressions Minimal Periodic Sets


s(i + ) = {j LG2 | =
6 G2 (j) G1 (i + )} .
show s(i + ) composed elements s(i)
lcm(PG1 ,PG2 )NG2
quantity 0 =
added. purpose need:
PG
2

j s(i) (j + 0 ) s(i + )

(12)


j + 0 s(i + ) j s(i)

(13)



12, note j s(i), G2 (j) G1 (i). Since / G2 ,
G2 (j) =

k
[

(jr )

r=0


0



G2 j + =

k
[

(jr + lcm(PG1 , PG2 ))

(14)

r=0

Since G1 (i) G2 (j) =

Sk

r=0 (jr ),

since / G1 ,

G1 (j + )

k
[

(jr + lcm(PG1 , PG2 ))

(15)

r=0

14 15 derive G1 (i + ) G2 (j + 0 ), hence (j + 0 ) s(i + ).
Analogously
validitySof 13; Hence, i, exists s(i) s.t.
proved
0
0
G (i) = js(i) G2 (j), G (i + ) = js(i) G2 (j + 0 ). Hence, considering fact
G2 / G0 , conclude G2 / G0 . Finally, since PGG02 multiple NG2 , Theorem 1
obtain thesis.
A.5.2 Part 2
Let

P 0
s(i) 6= }
LeG0 = {i LGG1 |e
P

0

P

0

LGG1 se(i) = {j LGG2 | =
6 G2 (j) G1 (i)};
show LeG0 = LG0 proving that: (1) LeG0 LG0 (2) LeG0 LG0 .
(1) Suppose contradiction exists k LG0 \ LeG0 . Since k LG0 since G0
derived Combine operation,
q LG2 |G2 (q) G1 (k). definition

0
Combine operation G (k) = js(k) G2 (j); since q s(k), G2 (q) G0 (k). Hence (a)
q LG2 |G2 (q) G0 (k).
P 0
Moreover, since k 6 LeG0 , se(k) = ; therefore @j LGG2 |G2 (j) G1 (k).
definition Combine operation easily seen G0 G1 . Using
P 0
previous formula, derive (b) @j LGG2 |G2 (j) G0 (k).
339

fiBettini, Mascetti & Wang

P

0

(a) (b) follows q LG2 \ LGG2 |G2 (q) G0 (k). show
leads contradiction.
P 0
P 0
P 0
P 0
Since q 6 LGG2 labels LGG2 contiguous (i.e., @i LG2 \ LGG2 s.t. min(LGG2 ) <
P

P

0

P

0

0

< max(LGG2 )), q < min(LGG2 ) q > max(LGG2 ). consider first case,
proof second analogous.
P 0
P 0
q < min(LGG2 ) max(bqcG2 ) < 1 (otherwise q LGG2 ).
0
0
Let = min(bmin(LG0 )cG ). Since k LG0 , bkcG .
1, G0 (k) G2 (q) = contradicting G0 (k) G2 (q).
< 1, G0 (lG0 ) (0) show lG0 LeG0 . Indeed, definition
P 0
P 0
Combine, j LGG2 |G2 (j) G0 (LG0 ). Since G0 G1 also j LGG2 |G2 (j)
G1 (LG0 ); hence j se(lG0 ) lG0 LeG0 .
Since 0 G0 (lG0 ) max(bqcG2 ) 0, max(bqcG2 ) < (otherwise G2 (q)
0
0
G0 (lG0 )). Therefore, since min(bkcG ) , bqcG2 blG0 cG = , contradiction
G2 (q) G0 (k).
e
(2) Suppose contradiction k LeG0 \ LG0 . Since k LeG0 , definition L,
P

P

0

0

k LGG1 se(k) 6= ; Therefore, definition se, j LGG2 |G2 (j) G1 (k).
P

0

Since j LGG2 , definition L, h 0 < h PG0 s.t. dheG2 = j. Since
0
G2 (j) G1 (k), dheG1 = k. definition combine operation, dheG = k.
0
Moreover, since 0 < h PG0 , definition L, dheG = k LG0 , contradicting
hypothesis.
A.6 Proof Proposition 5
A.6.1 Part 1
thesis follow application Theorem 1. Indeed, show G1 / G0
PGG01 multiple NG1 . need identify s.t., i, exists s(i)


lcm(PG1 ,PG2 )NG2
s.t. G0 (i) = js(i) G1 (j), G0 (i+) = js(i) G1 (j +NG1 ). Let =
.
PG2
0


0
(i+) 1
1
G1 (j) G0 (i + ) = j=i+ G1 (j)
definition anchored grouping, G0 (i) = ij=i
i0 first label G2 (i + )0 first label G2 + .
periodicity G2 , (and since multiple NG2 ) difference label
granule following G2 (i + ) label granule following G2 (i)
Sk.
0
0
0
0
0
formally, (i + ) = , hence (i + ) = + . Then, i, G (i) = j=i G1 (j),
0 +1
0 1
G0 (i + ) = ij=i+
G1 (j) = ij=i
G1 (j + ). result considering G1 / G0 ,
conclude G1 / G0 PGG01 = . Note Proposition 9, NG1 =
PGG01

multiple . Then, Theorem 1, thesis.

A.6.2 Part 2
Let

(
LeG0 =

P

0

lG2 = lG1 ,
LGG2 ,
PG0
0
{lG2 } LG2 , otherwise,

340

PG1 NG2
PG2 ,

hence

fiMapping Calendar Expressions Minimal Periodic Sets

0
lG
greatest among labels LG2 smaller lG2 . show
2
e
LG0 = LG0 proving (1) LeG0 LG0 (2) LG0 LeG0 .
P 0
(1) Suppose contradiction k LeG0 \ LG0 . Then, since k LeG0 , k LGG2
0 .
k = lG
2
P

P

0

0

k LGG2 , then, definition LGG2 , h 0 < h PG0 s.t. dheG2 = k.
0 1
definition Anchored-group, G0 (k) = kj=k
G1 (j) k 0 first label G2
0
k. Therefore G (k) G1 (k). Since G2 labeled aligned subgranularity G1 since
0
k LG2 , k LG1 G1 (k) = G2 (k). Hence G0 (k) G2 (k). follows dheG = k
therefore, definition L, k LG0 contrast hypothesis.
0 , then, definition L
eG0 , lG 6= lG . Therefore, since G2 labeled aligned
k = lG
2
1
2
0 <l
;

h

0 < h < min(blG2 cG2 ) s.t. dheG1 = lG1 .
<
l
subgranularity G1 lG
G
G
2
1
2

lG2 1
0 ) =
0
Since, definition Anchored-group, G0 (lG
G1 (j) since lG
< lG1 < lG2 ,
j=l0
2
2
G2

0

0 ) G (l ). Hence dheG = l0
0
G0 (lG
1 G1
G2 therefore, definition L, lG2 = k LG0
2
contrast hypothesis.
P 0
(2) Suppose contradiction k LG0 \ LeG0 . k LGG2 then, definition
LeG0 , k LeG0 , contrast hypothesis.
P 0
P 0
P 0
P 0
P 0
k
/ LGG2 , since @q LG2 \LGG2 s.t. min(LGG2 ) q max(LGG2 ), k > max(LGG2 )
P

0

k < min(LGG2 ).

P

0

k > max(LGG2 ) then, definition L, min(bkcG2 ) > PG0 . Since G2 labeled
aligned subgranularity G1 G2 (k) = G1 (k) hence min(bkcG1 ) > PG0 . Since
0 1
0
G0 (k) = kj=k
G1 (j) min(bkcG ) > PG0 contrast hypothesis k LG0 .
P

0

0 , k < l0
0
k < min(LGG2 ) then, definition lG
G2 k = lG2 .
2
0
0
k < lG
then, let k 0 next label G2 k. Since k < lG
then, definition
2
2
0
0
0
0
0
G
lG2 , k lG2 . definition lG2 max(blG2 c 2 ) 0. Since G2 labeled aligned
0 ) = G (l0 ); therefore max(bl0 cG1 ) 0. Since G0 (k) =
subgranularity G1 G1 (lG
2 G2
G2
2
Sk0 1
0
0
G0 ) 0 contrast hypothesis
G
(j)

k

l
,
follows

max(bkc
1
j=k
G2
k LG0 .
SlG2 1
0
0 ) =
0
Finally k = lG
G0 (lG
G1 (j). Since k = lG
LG0 h
j=l0
2
2
2
0

G2

0 . Since G0 composition granules G , dheG1
0 < h PG0 s.t. dheG = lG
1
2
P

0

defined. Let q = dheG1 . definition L, q LGG1 therefore q lG1 . Since,
0
0
definition Anchored-group, G0 composition granules G1 since dheG = lG
2

lG2 1
0 ). Therefore since G0 (l0 ) =
dheG1 = q, G1 (q) G0 (lG
G
(j)

q
<
l
1
G2 .
G2
j=l0
2
G2

0
follows lG1 q < lG2 hence lG1 6= lG2 . definition LeG0 , lG
= k LeG0
2
contrast hypothesis.

A.7 Selecting operations
selecting operations common part proof computation period
length period label distance.

341

fiBettini, Mascetti & Wang

lcm(P

,P

)N

G1 G2
G1
Let =
. proof divided two steps: first show
PG1
select operation LG0 + LG0 (details Select-down, Select-up
Select-by-intersect operations found below). second step application
Theorem 1. Indeed, Select operation, following holds: LG0 G0 (i) = G1 (i);
implies G1 / G0 . step 1 follows + LG0 , hence G0 (i + ) = G1 (i + ).
result considering G1 / G0 , conclude G1 / G0 PGG01 =
multiple NG1 definition. Then, Theorem 1 thesis.

A.8 Proof Proposition 6
A.8.1 Part 1
See Section A.7.
prove LG0 0 = + LG0 .
definition select-down operation, LG0 LG2 s.t. lk (S(i))
S(i) ordered set defined follows: S(i) = {j LG1 | =
6 G1 (j) G2 (i)}.
order prove thesis need show i0 LG2 |0 lk (S(i0 )). Consider
i0 = i+

lcm(PG1 PG2 )NG2
PG2

note i0 LG2 (this trivially derived periodicity

G2 ). prove 0 lk (S(i0 )) show S(i0 ) obtained S(i) adding
elements.
Indeed note periodicity G1 , j S(i) if:
j
[

(jr )

(16)

(jr + lcm(PG1 PG2 ))

(17)

G1 (j) =

r=0

then:
G1 j

0



=

j
[
r=0

Since j S(i), G1 (j) G2 (i) then, (16), G2 (i)
periodicity G2 :

0



G2

j
[

(jr + lcm(PG1 PG2 ))

Sj

r=0 (jr ).

Moreover,

(18)

r=0

Since (17) (18), G2 (i0 ) G1 (j 0 ); hence j S(i), j 0 = (j + ) S(i0 ). Analogously
prove j 0 S(i0 ), j = (j 0 ) S(i).
Thus S(i0 ) obtained S(i) adding elements; therefore j S(i)
position n S(i), j 0 S(i0 ) position n S(i0 ). Hence trivial
position k k + l 1 S(i), 0 position k k + l 1
S(i0 ). Hence LG0 , 0 LG0 .

342

fiMapping Calendar Expressions Minimal Periodic Sets

A.8.2 Part 2
Let
LeG0 =


[ n
P 0
A(i)|a LGG1 ;
P 0

iLGG
2

LG2 :

6 G1 (j) G2 (i)}) .
A(i) = lk ({j LG1 | =

show LeG0 = LG0 proving (1) LeG0 LG0 (2) LeG0 LG0 .
P 0
(1)Suppose contradiction q LeG0 \ LG0 . definition LeG0 , q LGG1 ;
therefore h 0 < h PG0 s.t. dheG1 = q. Moreover, definition LeG0
definition Select-down, LeG0 LG0 hence q LG0 . Since, definition Select-down
0
G0 (q) = G1 (q), dheG = q; hence, definition L, q LG0 contradiction
hypothesis.
(2)Suppose contradiction q LG0 \ LeG0 . Since q LG0 then, definition
Select-down
6 G1 (j) G2 (i)})
LG2 s.t. q lk ({j LG1 | =
therefore, definition A(i), q A(i).
0
Since q LG0 h 0 < h PG0 s.t. dheG = q. definition Select-down,
P 0
G0 (q) = G1 (q), dheG1 = q therefore q LGG1 . Moreover, since G1 (q) G2 (i),
P

P

0

0

P

0

dheG2 = therefore LGG2 . Since q A(i), q LGG1 LGG2 then,
definition LeG0 , q LeG0 , contrast hypothesis.
A.9 Proof Proposition 7
A.9.1 Part 1
See Section A.7. prove LG0 + LG0 . periodicity G1 ,
i+ LG1 (this trivially derived periodicity G1 ). Hence need show
j 0 LG2 | =
6 G2 (j) G1 (i + ). Since LG0 j LG2 | =
6 G2 (j) G1 (i).
periodicity G2 , if:
G2 (j) =

j
[

(jr )

(19)

r=0

then:

[
j
lcm(PG1 PG2 )NG2
G2 j +
=
(jr + lcm(PG1 PG2 ))
PG2
r=0

Moreover, (19) since G1 (i) G2 (j):
G1 (i)

j
[
r=0

periodicity G1 :
343

(jr )

(20)

fiBettini, Mascetti & Wang

G1 (i + )

j
[

(jr + lcm(PG1 PG2 ))

(21)

r=0


(20) (21) follows G1 (i + ) G2 j +

lcm(PG1 PG2 )NG2
PG2



, thesis.

A.9.2 Part 2
Let

P 0
6 G2 (j) G1 (i)};
LeG0 = {i LGG1 |j LG2 s.t. =

show LeG0 = LG0 proving (1) LeG0 LG0 (2) LeG0 LG0 .
P 0
(1) Suppose contradiction k LeG0 \ LG2 . Since k LeG0 , k LGG1 ;
therefore h 0 < h PG0 s. t. dheG1 = k. Moreover, definition LeG0
definition Select-down, LeG0 LG0 hence q LG0 . Since, definition Select-up,
0
G0 (k) = G1 (k), dheG = k. Hence, definition L, k LG0 , contrast
hypothesis.
(2) Suppose contradiction k LG0 \ LeG0 . Since k LG0 , h 0 <
0
h PG0 s.t. dheG = k. Since, definition Select-up, G0 (k) = G1 (k), dheG1 = k;
P 0
Therefore, definition L, k LGG1 . Moreover, since k LG0 LG0 LG0 ,
definition Select-up operation, j LG2 s.t. 6= G2 (j) G1 (k). Hence
definition LeG0 , k LeG0 , contradiction hypothesis.
A.10 Proof Proposition 8
A.10.1 Part 1
See Section A.7. prove LG0 , 0 = + LG0 .
definition select-by-intersect operation, LG0 , LG2 :
lk (S(i)) S(i) ordered set defined follows: S(i) = {j LG1 |G1 (j)G2 (i) 6= }.
order prove thesis need show i0 LG2 : 0 lk (S(i0 )). Consider
i0 = +

lcm(PG1 PG2 )NG2
note i0 LG2 (this
PG2
prove 0 lk (S(i0 )) show

trivially derived periodicity

G2 ).
S(i0 ) obtained S(i) adding
elements.
Indeed note j j S(i), G1 (j) G2 (i) 6= . Hence l Z : (l) G1 (j)
(l) G2 (i). periodicity G1 , G1 (j + ) (l + lcm(PG1 PG2 )).
periodicity G2 , G2 (i0 ) (l + lcm(PG1 PG2 )). G1 (j + ) G2 (i0 ) 6= , therefore
j S(i), (j + ) S(i0 ).
Analogously prove j 0 S(i0 ), (j 0 ) S(i). Hence S(i0 ) obtained
S(i) adding elements. Therefore, j S(i) position n S(i),
j + S(i0 ) position n S(i0 ); hence j position k k + l 1 S(i),
also j + position k k + l 1 S(i0 ) j + LG0 .
A.10.2 Part 2
proof analogous ones Proposition 6.
344

fiMapping Calendar Expressions Minimal Periodic Sets

A.11 Set Operations
A.11.1 Proof Proposition 9
Given periodical granularities H G G label aligned subgranularity H,
NH
G
prove N
PG = PH . thesis proved considering common period length H
G i.e. Pc = lcm(PG , PH ).
Let NG0 difference label ith granule one period G
label ith granule next period, considering Pc period length G.
0 defined.
Analogously NH


periodicity G, G(i) = kr=0 (ir ) G(i + NG0 ) = kr=0 (ir + Pc ); since G

aligned subranularity H, LH H(i) = G(i) = kr=0 (ij ) and, since H periodic,
Sk
0 )=
0
0
H(i + NH
r=0 (ij + Pc ); easily derive + NG = + NH , hence
0
0
NG = NH .
0 = N 0 ,
definition Pc , , N s. t. PH = PG . Moreover, since NH
G
PG
PH
=
.
NH = NG . Therefore N
NG
H
A.11.2 Property used proofs set operations
lcm(P

,P

)N

lcm(P

,P

)N

G1 G2
G1
G1 G2
G2
Let 1
2
. Since G1 G2 aligned subgranPG1
PG2
ularity certain granularity H, Proposition 9 easily derive 1 = 2 .

A.12 Proof Proposition 10
A.12.1 Part 1
Union. Let 1

lcm(PG1 ,PG2 )NG2
lcm(PG1 ,PG2 )NG1
2
. thesis
PG1
PG2

Sk
0
0
LG0 if, G (i) = r=0 (ir ), G (i + ) = kr=0 (ir

proved

+ lcm(PG1 , PG2 ))
showing
0
= 1 = 2 . Since LG = LG1 LG2 , two cases considered:

LG1 G0 (i) = G1 (i) = kr=0 (ir ). periodicity G1 , G1 (i + 1 ) =
Sk
Sk
0
r=0 (ir + lcm(PG1 , PG2 )); hence G (i + 1 ) =
r=0 (ir + lcm(PG1 , PG2 )).

LG2 LG1 G0 (i) = G2 (i) = kr=0 (ir ). periodicity G2 , G2 (i + 2 ) =
Sk
Sk
0
r=0 (ir + lcm(PG1 , PG2 )); hence G (i + 2 ) =
r=0 (ir + lcm(PG1 , PG2 )).

Since 1 = 2 , LG0 G0 (i) = kr=0 (ir ), G0 (i + 1 ) = G0 (i + 2 ) =
Sk
r=0 (ir + lcm(PG1 , PG2 )). Hence, definition / , thesis.

Intersect. LG0 = LG1 LG2 G0 (i) = G1 (i) = kr=0 (ir ). periodicity
G1 G2 , + 1 LG1 eSi + 2 LG2 ; since 1 = 2 , + 1 LG0 . Moreover
G0 (i + 1 ) = G1 (i + 1 ) = kr=0 (ir + lcm(PG1 , PG2 )); hence, definition / ,
thesis.

Difference. LG0 = LG1 LG2 G0 (i) = G1 (i) = kr=0 (ir ). Since LG1
periodicity G1 + 1 LG1 . Since
/ LG2 , periodicity G2 , + 2
/ LG2
(if would exists + 2 LG2 , periodicity G2 would exists LG2
0
0

Sk possible hypothesis). Hence + 1 LG . Moreover G (i + 1 ) = G1 (i + 1 ) =
r=0 (ir + lcm(PG1 , PG2 )); hence, definition / , thesis.
345

fiBettini, Mascetti & Wang

A.12.2 Part 2
P 0
P 0
Let LeG0 = LGG1 LGG2 .
show LeG0 = LG0 proving (1) LeG0 LG0 (2) LeG0 LG0 .
P 0
(1) Suppose contradiction k LeG0 \ LG0 . Since k LeG0 k LGG1
P

0

P

P

0

0

P

0

k LGG2 . Suppose k LGG1 (the proof analogous k LGG2 ). Since k LGG1 ,
0
0 < h < PG0 s.t. dheG = k. Since, definition Union operation G0 (k) = G1 (k),
0
dheG = k. Hence, definition L, k LG0 contrast hypothesis.
(2) Suppose contradiction k LG0 \ LeG0 . Since k LG0 , then, definition
0
L, 0 < h < PG0 s.t. dheG = k. Moreover, definition Union operation, k LG1
P 0
P 0
k LG2 . Suppose k LGG1 (the proof analogous k LGG2 ). definition
P

0

Union operation, G0 (k) = G1 (k) therefore dheG1 = k so, definition L, k LGG1 .
e k LeG0 contradiction hypothesis.
Hence, definition L,

References
Bettini, C., & Mascetti, S. (2005). efficient algorithm minimizing time granularity
periodical representations. Proc. 12th International Symposium Temporal
Representation Reasoning (TIME), pp. 2025. IEEE Computer Society.
Bettini, C., Mascetti, S., & Pupillo, V. (2005). system prototype solving multigranularity temporal csp. Recent Advances Constraints, Revised selected papers Workshop Constraint Solving Constraint Logic Programming
(CSCLP), volume 3419 Lecture Notes Computer Science, pp. 142156. Springer.
Bettini, C., Mascetti, S., & Wang., X. S. (2004). Mapping calendar expressions periodical granularities. Proc. 11th International Symposium Temporal
Representation Reasoning (TIME), pp. 96102. IEEE Computer Society.
Bettini, C., & Sibi, R. D. (2000). Symbolic representation user-defined time granularities.
Annals Mathematics Artificial Intelligence, 30 (1-4), 5392.
Bettini, C., Wang, X. S., & Jajodia, S. (2000). Time Granularities Databases, Data
Mining, Temporal Reasoning. Springer.
Bettini, C., Wang, X. S., & Jajodia, S. (2002a). Solving multi-granularity temporal constraint networks. Artificial Intelligence, 140 (1/2), 107152.
Bettini, C., Wang, X. S., & Jajodia, S. (2002b). Temporal reasoning workflow systems.
Distributed Parallel Databases, 11 (3), 269306.
Bresolin, D., Montanari, A., & Puppis, G. (2004). Time granularities ultimately periodic
automata. Proc. 9th European Conference Logics Artificial Intelligence
(JELIA) volume 3229 Lecture Notes Computer Science, pp. 513525. Springer.
Chandra, R., Segev, A., & Stonebraker, M. (1994). Implementing calendars temporal
rules next generation databases. Proc. 10th International Conference
Data Engineering (ICDE), pp. 264273. IEEE Computer Society.
Combi, C., Franceschet, M., & Peron, A. (2004). Representing reasoning temporal
granularities. Journal Logic Computation, 14 (1), 5177.
346

fiMapping Calendar Expressions Minimal Periodic Sets

Combi, C., & Pozzi, G. (2003). Temporal conceptual modelling workflows. Proc.
22nd International Conference Conceptual Modeling (ER) volume 2813 Lecture
Notes Computer Science, pp. 5976. Springer.
Cukierman, D., & Delgrande, J. P. (1998). Expressing time intervals repetition within
formalization calendars. Computational Intelligence, 14, 563597.
Dal Lago, U., & Montanari, A. (2001). Calendars, time granularities, automata. Proc.
7th International Symposium Spatial Temporal Databases (SSTD),
volume 2121 Lecture Notes Computer Science, pp. 279298. Springer.
Dal Lago, U., Montanari, A., & Puppis, G. (2003). Towards compact tractable
automaton-based representations time granularities. Proc. 8th Italian
Conference Theoretical Computer Science (ICTCS), volume 2841 Lecture Notes
Computer Science, pp. 7285. Springer.
Dechter, R., Meiri, I., & Pearl, J. (1991). Temporal constraint networks. Artificial Intelligence, 49 (1-3), 6195.
Kabanza, F., Stevenne, J. M., & Wolper, P. (1990). Handling infinite temporal data. Proc.
9th ACM SIGACT-SIGMOD-SIGART Symposium Principles Database
Systems (PODS), pp. 392403. ACM Press.
Koomen, J. (1991). Reasoning recurrence. International Journal Intelligent Systems, 6, 461496.
Ladkin, P. B. (1986). Primitives units time specification. Proc. 5th National
Conference Artificial Intelligence (AAAI), pp. 353359. Morgan Kaufmann.
Leban, B., McDonald, D., & Forster, D. (1986). representation collections temporal
intervals. Proc. 5th National Conference Artificial Intelligence (AAAI),
pp. 367371. Morgan Kaufmann.
Li, Y., Ning, P., Wang, X. S., & Jajodia, S. (2001). Discovering calendar-based temporal
association rules. Proc. 8th International Symposium Temporal Representation Reasoning (TIME), pp. 111118. IEEE Computer Society.
Montanari, A. (1996). Metric Layered Temporal Logic Time Granularity. Ph.D.
thesis, ILLC Dissertation Series 1996-02, University Amsterdam.
Morris, R., Shoaff, W., & Khatib, L. (1996). Domain-independent temporal reasoning
recurring events. Computational Intelligence, 12, 450477.
Niezette, M., & Stevenne, J. M. (1992). efficient symbolic representation periodic
time. Proc. first International Conference Information Knowledge
Management (CIKM) volume 725 Lecture Notes Computer Science, pp. 161168.
Springer.
Ning, P., Wang, X. S., & Jajodia, S. (2002). algebraic representation calendars.
Annals Mathematics Artificial Intelligence, 36 (1-2), 538.
Puppis, G. (2006). Automata Branching Layered Temporal Structures. Ph.D. thesis,
Universita degli Studi di Udine.
Terenziani, P. (2003). Symbolic user-defined periodicity temporal relational databases.
IEEE Transactions Knowledge Data Engineering, 15 (2), 489509.
347

fiBettini, Mascetti & Wang

Tuzhilin, A., & Clifford, J. (1995). periodicity temporal databases. Information
Systems, 20 (8), 619639.
Urgun, B., Dyreson, C. E., Snodgrass, R. T., Miller, J. K., Soo, M. D., Kline, N., & Jensen,
C. S. (2007). Integrating multiple calendars using TauZaman. Software-Practice
Experience, appear.
Wijsen, J. (2000). string-based model infinite granularities. Spatial Temporal
Granularity: Papers AAAI Workshop. Technical Report WS-00-08, pp. 916.
AAAI Press.

348

fiJournal Artificial Intelligence Research 28 (2007) 107-118

Submitted 9/05; published 2/07

Generating Hard Satisfiable Formulas Hiding
Solutions Deceptively
Haixia Jia

hjia@cs.unm.edu

Computer Science Department
University New Mexico

Cristopher Moore

moore@santafe.edu

Computer Science Department
University New Mexico

Doug Strain

doug.strain@gmail.com

Computer Science Department
University New Mexico

Abstract
test incomplete search algorithms constraint satisfaction problems 3SAT, need source hard, satisfiable, benchmark instances. simple way
choose random truth assignment A, choose clauses randomly
among satisfied A. However, method tends produce easy problems, since
majority literals point toward hidden assignment A. Last year, Achlioptas,
Jia Moore proposed problem generator cancels effect hiding
complement (Achlioptas, Jia, & Moore, 2004). resulting formulas
appear hard DPLL algorithms random 3-SAT formulas hidden
assignment, solved WalkSAT polynomial time.
propose new method cancel attraction A, choosing clause
> 0 literals satisfied probability proportional q q < 1. varying
q, generate formulas whose variables bias, i.e., equally likely
true false; even cause formula deceptively point away A. present
theoretical experimental results suggesting formulas exponentially hard
DPLL algorithms incomplete algorithms WalkSAT.

1. Introduction
evaluate search algorithms constraint satisfaction problems, need good sources
benchmark instances. Real-world problems best benchmarks definition,
problem structures specific application domain; addition,
wish study running times search algorithms scale, need entire families
benchmarks varying size density.
One way fill need generate random instances. instance, 3-SAT
generate instances
n variables clauses choosing clause uniformly
among 8 n3 possibilities. vary formulas according
size density r = m/n. formulas lack much structure realworld instances, instrumental development study new search
methods simulated annealing (Johnson, Aragon, McGeoch, & Shevon, 1989),
c
2007
AI Access Foundation. rights reserved.

fiJia, Moore, & Strain

breakout procedure (Morris, 1993), WalkSAT (Selman, Kautz, & Cohen, 1996), Survey
Propagation (Mezard & Zecchina, 2002).
However, wish test incomplete algorithms WalkSAT Survey Propagation (SP), need source problems hard satisfiable. contrast, critical density r 4.27, random formulas defined almost certainly unsatisfiable.
Random formulas threshold appear quite hard complete solvers (Cheeseman, Kanefsky, & Taylor, 1991; Mitchell, Selman, & Levesque, 1992; Hogg, Huberman, &
Williams, 1996); precisely reason, feasible generate large problems
threshold filter unsatisfiable ones. classes satisfiable
CSPs proposed, quasigroup completion problem (Shaw, Stergiou, &
Walsh, 1998; Kautz, Ruan, Achlioptas, Gomes, Selman, & Stickel, 2001; Achlioptas, Gomes,
Kautz, & Selman, 2000), would like problems generators native
3-SAT.
natural way generate random satisfiable 3-SAT formulas choose random
truth assignment
{0, 1}n , choose clauses uniformly independently
n
among 7 3 clauses satisfied A. problem simply rejecting clauses
conflict causes unbalanced distribution literals; particular, average
literal agree value hidden assignment 4/7 time. Thus, especially
many clauses, simple majority heuristic local search quickly find
A. sophisticated versions hidden assignment scheme (Asahiro, Iwama, &
Miyano, 1996; Van Gelder, 1993) improve matters somewhat still lead biased samples.
Thus question avoid attraction hidden assignment,
One approach (Achlioptas et al., 2004) choose clauses uniformly among
satisfied complement A. inspired recent work
random k-SAT Not-All-Equal SAT (Achlioptas & Moore, 2002b), symmetry
respect complementation reduces variance number solutions; idea
cancel others attractions out, making either one hard find. Indeed,
resulting formulas appear take DPLL solvers exponential time and, general,
hard random 3-SAT formulas hidden assignment.
hand, WalkSAT solves formulas polynomial time, since variables set
way agrees one hidden assignments, neighboring variables develop
correlations consistent (Barthel, Hartmann, Leone, Ricci-Tersenghi, Weigt, &
Zecchina, 2002).
paper, pursue alternate approach, inspired Achlioptas Preres,
reweighted satisfying assignments natural way (Achlioptas & Peres, 2003). hide
one assignment, bias distribution clauses follows:
1. Predefine constant q < 1 generate random truth assignment {0, 1}n
2. rn times: choose random k-tuple variables, choose among clauses
> 0 literals satisfied probability proportional q .
penalizes clauses satisfied A, reduces extent
variable occurrences likely agree A. (Note naive formulas discussed
amount case q = 1.) see below, choosing q appropriately
rebalance distribution literals, variable likely appear positively
108

fiGenerating Hard Satisfiable Formulas Hiding Solutions Deceptively

often negatively longer points toward value A. reducing q further,
even make likely variable occurrence disagrees A,
formula becomes deceptive points away hidden assignment.
call formulas q-hidden, distinguish naive 1-hidden formulas discussed above, 2-hidden formulas studied Achlioptas, Jia Moore (Achlioptas et al., 2004), 0-hidden formulas consisting random 3-SAT formulas
hidden assignment. Like families, q-hidden formulas readily amenable
mathematical tools developed studying random k-SAT formulas,
including moment calculations method differential equations. calculate
expected density satisfying assignments function distance A,
analyze behavior Unit Clause (UC) algorithm q-hidden formulas.
present experiments several complete incomplete solvers. certain values q,
find q-hidden formulas hard harder DPLL algorithms 0-hidden
formulas 2-hidden formulas, much harder naive 1-hidden formulas. addition, find local search algorithms like WalkSAT find formulas much harder
families, taking exponential opposed polynomial time. Moreover,
running time WalkSAT increases sharply formulas become deceptive.

2. Expected Density Solutions Bias Local Search
[0, 1], let X number satisfying truth assignments random q-hidden
k-SAT formula agree fraction variables hidden assignment A;
is, Hamming distance (1 )n. wish calculate expectation
E[X ].
symmetry, take all-true assignment. case, clause
> 0 positive literals chosen probability q /((1 + q)k 1) (here normalize
probabilities summing kt clauses > 0). Let B truth assignment
n variables true (1)n false. Then, analogous calculation
Achlioptas, Jia Moore (Achlioptas et al., 2004), use linearity expectation, independence clauses, selection literals clause replacement,
Stirlings approximation factorial obtain (where suppresses terms polynomial
n):

n
Pr[B satisfies random clause]m
n
!m

k
X
k q (1 )t kt
n
1
=
(1 + q)k 1
n
t=1

E[X ] =



fk,r,q ()n


f () =

1
(1 )1



1

(q(1 ) + )k k
(1 + q)k 1

r

.

Looking Figure 1, see behavior f near = 1/2 changes dramatically
vary q. q = 1 (i.e., naive 1-hidden formulas), f 0 (1/2) positive.
109

fiJia, Moore, & Strain

Density solutions q=0.5

Density solutions r=6
1.1

1.4
r=3

1

1.3

q=0.5

0.9

1.2

r=4

q=0.618
0.8

1.1

0.7

1

r=5

0.6

r=5.6

q=1

0.9
r=6

0.5

0.8

0.4

0.7

r=7

0.3
0

0.2

0.4



0.6

0.8

0.6
0

1

0.2

0.4



0.6

0.8

1

Figure 1: nth root f () expected number solutions agree
hidden assignment fraction variables. k = 3. left part
figure shows f () q = 1, q = 0.618 q = 0.5 r = 6. right part
shows f () q = 0.5 varying r. Note r = 5.6, f () < 1
1/2.
hand, q positive root q
1 (1 q)(1 + q)k1 = 0

(1)



f 0 (1/2) =
0. call resulting q -hidden formulas balanced; k = 3, q
golden ratio ( 5 1)/2 = 0.618...
choice q affects local search algorithms WalkSAT following way.
start random assignment B, step WalkSAT chooses random unsatisfied
clause, satisfies literal ` chosen randomly clause. expected change
Hamming distance d(A, B) probability ` agrees A, minus
probability doesnt. Since clauses equally likely unsatisfied
random assignment, expectation 2t/k 1 random clause, namely

E[d(A, B)] =

k
X
k q (2t/k 1)
t=1

(1 + q)k 1

=

1 (1 q)(1 + q)k1
.
(1 + q)k 1

Thus zero (1) holds, case WalkSAT equally likely move toward away
A. Thus, analogous calculation Achlioptas Peres (Achlioptas & Peres,
2003), q = q given literal equally likely agree disagree A, WalkSAT
information direction hidden assignment lies. (This argument
applies first o(n1/2 ) steps WalkSAT, since unlikely seen
variable twice).
110

fiGenerating Hard Satisfiable Formulas Hiding Solutions Deceptively

smaller values q q = 0.5 shown Figure 1, f 0 (1/2) becomes negative,
expect local search algorithm starting random assignment move away
A. Indeed, f () local maximum < 1/2, small r solutions
< 1/2. r sufficiently large, however, f () < 1 < 1/2,
n probability alternate solutions exist exponentially small.
conjecture q q threshold rc (q) high probability
solutions close A. Setting max{f () | 1/2} = 1 yields upper
bound rc (q), show Figure 4 below. instance, dotted line Figure 1
shows rc (0.5) 5.6.
call formulas deceptive, since local search algorithms WalkSAT, DPLL
algorithms zChaff use majority heuristic splitting rule, messagepassing algorithms SP presumably search wrong direction, take exponential time cross local minimum f () find hidden assignment.
experiments appear confirm intuition. addition, three types algorithms appear encounter difficulty roughly density rc (q),
conjecture alternate solutions disappear.

3. Unit Clause Heuristic DPLL Algorithms
Unit Clause (UC) linear-time heuristic permanently sets one variable
step follows: unit clauses, satisfy them; otherwise, pick random literal
satisfy it. random 3-SAT formulas, UC succeeds constant probability
r < 8/3, fails high probability r > 8/3 (Chao & Franco, 1986). UC
thought first branch simple DPLL algorithm S, whose splitting rule takes
random unset variable tries truth values random order; thus UC succeeds
succeeds without backtracking. hand, showed Ss expected running
time exponential n r > 8/3 (Cocco & Monasson, 2004; Cocco, Monasson,
Montanari, & Semerjian, 2005); also Achlioptas, Beame Molloy used lower bounds
resolution complexity show takes exponential time high probability
r > 3.81 (Achlioptas, Beame, & Molloy, 2001). general, appears simple DPLL
algorithms begin take exponential time exactly density corresponding
linear-time heuristic fails.
section, analyze performance UC q-hidden formulas. Specifically,
show balanced case q = q , UC fails r > 8/3
0-hidden formulas. Based this, conjecture running time S,
simple DPLL algorithms, exponentially large formulas density
0-hidden ones.
analyze behavior UC arbitrary initial distributions 3-SAT clauses using
method differential equations. simplicity assume all-true assignment. round UC consists free step, satisfy random literal,
ensuing chain unit-clause propagations. 0 3 0 j i, let Si,j = si,j n
number
clauses length j positive literals j negative ones, let
P
si = j si,j . Let X = xn number variables set far, let mT mF
expected number variables set true false round. model discrete
111

fiJia, Moore, & Strain

stochastic process Si,j following differential equations si,j :
ds3,j
dx
ds2,j
dx

3s3,j
1x
2s2,j
mF (j + 1)s3,j+1 + mT (3 j)s3,j
=
+
1x
(mT + mF )(1 x)
=

(2)

unit clauses governed two-type branching process, transition matrix


1
s2,1 2s2,0
M=
.
1 x 2s2,2 s2,1
calculation Achlioptas Moore (Achlioptas & Moore, 2002a), long
largest eigenvalue less 1, branching process subcritical, summing
round gives




1/2
mF
1
= (I )
.
1/2
mT
solve equation (2) initial conditions s3,0 = 0

qj
3
s3,j =
j (1 + q)3 1
0 < j 3. balanced case q = q , find UC succeeds q-hidden formulas
constant probability r < 8/3, 0-hidden formulas. reason
that, 2-hidden formulas, expected number positive negative literals
throughout process. symmetry causes UC behave would
random 3-SAT formulas without hidden assignment.
note q < q , UC succeeds slightly higher densities, find
one alternate solutions < 1/2. higher densities alternate
solutions disappear, experimental results show deceptive formulas
take DPLL algorithms exponential time, r > rc (q) harder 0-hidden
formulas density.

4. Experimental Results
4.1 DPLL
section discuss behavior DPLL solvers q-hidden formulas. focus
zChaff (Zhang, 2002); behavior OKsolver (Kullmann, 2002) similar. Figure 2
shows zChaffs running time 0-hidden, 1-hidden, 2-hidden, q-hidden formulas
various values q.
Balanced formulas, i.e. q = q = 0.618..., appear hard 0-hidden
ones, including satisfiability threshold r 4.27 0-hidden formulas become
unsatisfiable. Like 0-hidden formulas, q -hidden formulas appear peak complexity near satisfiability threshold. consistent picture given previous
two sections: namely, balanced formulas make impossible algorithms
feel attraction hidden assignment. contrast, naive 1-hidden formulas far
easier, since attraction hidden assignment strong.
112

fiGenerating Hard Satisfiable Formulas Hiding Solutions Deceptively

zChaff performance n=200

zChaff performance r=5.5

5

10

4

10

Median number Decisions 49 trials

Median number Decisions 49 trials

6

10

q=0.2
q=0.3
q=0.4
q=0.5
q=0.618
1hidden
2hidden
0hidden

3

10

2

10

1

10

4

5

10

q=0.3
0hidden
q=0.618
2hidden
1hidden

4

10

3

10

2

10

1

4.5

5

5.5

6
r

6.5

7

7.5

10
50

8

100

150

200

250

300

N

Figure 2: left part figure shows zChaffs median running time 49 trials
0-hidden, 1-hidden, 2-hidden q-hidden formulas n = 200 r ranging
4.0 8.0. right part shows median running time r = 5.5
n ranging 50 300. Note 0-hidden formulas almost always
unsatisfiable r > 4.27.

Deceptive formulas, i.e. q < q , appear two phases. low density
relatively easy, hardness peaks density rc (q). rc (q) take
exponential time; 0-hidden formulas, r increases coefficient
exponential decreases clauses generate contradictions quickly.
believe peak rc (q) threshold density defined earlier (see Figure 4
below) solutions close hidden assignment.
situation seems following: rc (q), alternate solutions <
1/2, zChaff led splitting rule. rc (q), alternate solutions
disappear, zChaff takes exponential time find vicinity hidden assignment,
since formula deceptively points direction. Moreover, fixed r
rc (q) formulas become harder q decreases become deceptive.
illustrate further, right part Figure 2 shows zChaffs median running
time 0-hidden formulas, 1-hidden formulas, 2-hidden formulas, q-hidden formulas
q = q (balanced) q = 0.3 (deceptive). fix r = 5.5, appears
rc (q) values q. density, 0-hidden, 2-hidden, balanced
q-hidden formulas comparable difficulty, 1-hidden formulas much easier
deceptive formulas appear somewhat harder.
4.2 SP
Survey Propagation SP (Mezard & Zecchina, 2002) recently introduced incomplete
solver based insights replica method statistical physics generalization
belief propagation. tested SP 0-hidden formulas q-hidden formulas different
values q, using n = 104 varying r. 0-hidden formulas, SP succeeds r = 4.25,
113

fiJia, Moore, & Strain

quite close satisfiability threshold. q-hidden formulas q = q , SP fails
4.25 0-hidden formulas, suggesting finds formulas exactly
hard 0-hidden ones even though guaranteed satisfiable. naive 1-hidden
formulas, SP succeeds significantly higher density, r = 5.6.
Presumably naive 1-hidden formulas easier SP since messages
clauses variables, like majority heuristic, tend push algorithm towards
hidden assignment. balanced case q = q , attraction successfully suppressed,
causing SP fail essentially density 0-hidden formulas, close satisfiability threshold, even though q-hidden formulas continue satisfiable densities. contrast, 2-hidden formulas proposed Achlioptas, Jia Moore (Achlioptas
et al., 2004) solved SP somewhat higher density r 4.8. Thus seems
reweighting approach q-hidden formulas better job confusing SP hiding
two complementary assignments does.
q < q , SP succeeds somewhat higher densities, matches quite
closely value rc (q) zChaffs running time peaks (see Figure 4 below). Building
conjecture density solutions close
hidden assignment, guess SP succeeds r < rc (q) precisely
local gradient density solutions pushes towards alternate solutions
< 1/2. rc (q), solutions longer exist, SP fails clauses send
deceptive messages, demanding variables set opposite hidden assignment.
4.3 WalkSAT
conclude local search algorithm, WalkSAT. formula, 104
restarts, 104 steps per attempt, step random greedy flip
equal probability. left part Figure 3 measure WalkSATs performance 1hidden, 2-hidden, q-hidden formulas various values q. use n = 200 r
range 4 8. Even relatively small formulas, see three
deceptive values q, density median running time jumps 108
flips. instance, q-hidden formulas q = 0.4 appear unfeasible WalkSAT for,
say, r > 5.
believe that, consistent discussion above, local search algorithms like
WalkSAT greedily follow gradient density solutions f (). q < q ,
gradient deceptive, lures WalkSAT away hidden assignment. densities
rc (q), many alternate solutions < 1/2 WalkSAT finds one
easily; densities rc (q), solutions near hidden
assignment, WalkSATs greed causes wander exponentially long time
wrong region. picture supported fact that, Figure 4 shows below, density WalkSATs running time jumps upward closely matches thresholds rc (q)
observed zChaff SP.
right part Figure 3 looks WalkSATs median running time fixed density
function n. compare 1-hidden 2-hidden formulas q-hidden ones
q = q two deceptive values, 0.5 0.3. choose r = 5.5, rc (q)
three values q. running time 1-hidden 2-hidden formulas
polynomial (Achlioptas et al., 2004; Barthel et al., 2002). contrast, even balanced
114

fiGenerating Hard Satisfiable Formulas Hiding Solutions Deceptively

case q = q , running time exponential, slope exponential increases
dramatically decrease q make formulas deceptive. note
might possible develop heuristic analysis WalkSATs running time deceptive
case (Semerjian & Monasson, 2003; Cocco et al., 2005).

WalkSAT performance n=200

8

8

7

10

6

10

5

10

q=0.2
q=0.3
q=0.4
q=0.5
q=0.618
1hidden
2hidden

4

10

3

10

2

10

WalkSAT performance r=5.5

10
Median number flips 49 trials

Median number flips 49 trials

10

4

7

10

q=0.3
q=0.5
q=0.618
2hidden
1hidden

6

10

5

10

4

10

3

10

2

4.5

5

5.5

6
r

6.5

7

7.5

10
50

8

100 150 200 250 300 350 400 450 500 550 600
N

Figure 3: left part figure shows WalkSATs median running time 49 trials
n = 200 r ranging 4 8; right part shows median running
time r = 5.5 n ranging 50 600.

5. Threshold Density
seen, appears characteristic density rc (q) value q q
running time DPLL algorithms like zChaff peaks, WalkSATs running
time becomes exponential, SP ceases work. conjecture three
cases, key phenomenon density solutions < 1/2 disappear,
leaving close hidden assignment. Figure 4 shows measured values
rc (q), indeed quite close three algorithms. also show analytic
upper bound rc (q) resulting setting max{f () | 1/2} = 1,
expected number solutions 1/2 exponentially small.

6. Conclusions
introduced simple new way hide solutions 3-SAT problems produces
instances hard satisfiable. Unlike 2-hidden formulas proposed
Achlioptas, Jia Moore (Achlioptas et al., 2004) attraction hidden
assignment cancelled also hiding complement, eliminate attraction
reweighting distribution clauses proposed Achlioptas Peres (Achlioptas
& Peres, 2003). Indeed, going beyond value parameter q makes
q-hidden formulas balanced, create deceptive formulas lead algorithms
wrong direction. Experimentally, formulas hard harder DPLL algorithms
115

fiJia, Moore, & Strain

12
Upper bound
zChaff
SP
WalkSAT

11
10

rc(q)

9
8
7
6
5
4
0.2

0.3

0.4
q

0.5

0.6

Figure 4: density rc (q) running time zChaff peaks, WalkSAT peaks
exceeds 108 flips, SP stops working. conjecture events occur
density alternate solutions < 1/2 disappear, leaving
close hidden assignment. Shown also analytic upper
bound described text.

0-hidden formulas, i.e., random 3-SAT formulas without hidden assignment; local
search algorithms like WalkSAT, much harder 0-hidden 2-hidden formulas,
taking exponential rather polynomial time. formulas also amenable
mathematical tools developed study random 3-SAT; calculated
expected density solutions function distance hidden assignment,
used method differential equations show UC fails density
0-hidden formulas.
close several exciting directions future work:
1. Confirm single threshold density rc (q) a) alternate solutions
far hidden assignment disappear, b) running time DPLL algorithms
maximized, c) SP stops working, d) running time WalkSAT becomes
exponential;
2. Prove simple DPLL algorithms take exponential time r > rc (q), expectation
high probability;
3. Calculate variance number solutions function , giving
improved upper lower bounds distribution solutions rc (q).

Acknowledgments
H.J. supported NSF Graduate Fellowship. C.M. D.S. supported NSF
grants CCR-0220070, EIA-0218563, PHY-0200909. C.M. thanks Tracy Conrad
Rosemary Moore support.
116

fiGenerating Hard Satisfiable Formulas Hiding Solutions Deceptively

References
Achlioptas, D., Beame, P., & Molloy, M. (2001). sharp threshold proof complexity.
Proc. STOC, pp. 337346.
Achlioptas, D., Gomes, C., Kautz, H., & Selman, B. (2000). Generating satisfiable problem
instances. Proc. AAAI, pp. 256261.
Achlioptas, D., Jia, H., & Moore, C. (2004). Hiding satisfying assignments: two better
one. Proc. AAAI, pp. 131136.
Achlioptas, D., & Moore, C. (2002a). Almost graphs average degree 4 3colorable. Proc. STOC, pp. 199208.
Achlioptas, D., & Moore, C. (2002b). asymptotic order random k-SAT threshold.
Proc. FOCS, pp. 779788.
Achlioptas, D., & Peres, Y. (2003). threshold random k-SAT 2k (ln 2 o(k)).
Proc. STOC, pp. 223231.
Asahiro, Y., Iwama, K., & Miyano, E. (1996). Random generation test instances
controlled attributes. DIMACS Series Disc. Math. Theor. Comp. Sci., 26.
Barthel, W., Hartmann, A., Leone, M., Ricci-Tersenghi, F., Weigt, M., & Zecchina, R.
(2002). Hiding solutions random satisfiability problems: statistical mechanics
approach. Phys. Rev. Lett., 88 (188701).
Chao, M., & Franco, J. (1986). Probabilistic analysis two heuristics 3-satisfiability
problem. SIAM J. Comput., 15 (4), 11061118.
Cheeseman, P., Kanefsky, R., & Taylor, W. (1991). really hard problems are.
Proc. IJCAI, pp. 163169.
Cocco, S., & Monasson, R. (2004). Heuristic average-case analysis backtrack resolution random 3-satisfiability instances. Theor. Comp. Sci., 320, 345372.
Cocco, S., Monasson, R., Montanari, A., & Semerjian, G. (2005). Approximate analysis
search algorithms physical methods. Percus, A., Istrate, G., & Moore, C.
(Eds.), Computational Complexity Statistical Physics. Oxford University Press.
Hogg, T., Huberman, B., & Williams, C. (1996). Phase transitions complexity. Artificial
Intelligence, 81.
Johnson, D., Aragon, C., McGeoch, L., & Shevon, C. (1989). Optimization simulated
annealing: experimental evaluation. Operations Research, 37 (6), 865892.
Kautz, H., Ruan, Y., Achlioptas, D., Gomes, C., Selman, B., & Stickel, . (2001). Balance
filtering structured satisfiable problems. Proc. IJCAI, pp. 351358.
Kullmann, O. (2002). Investigating behaviour SAT solver random formulas.
Tech. rep. CSR 23-2002, University Wales Swansea.
Mezard, M., & Zecchina, R. (2002). Random k-satisfiability: analytic solution
new efficient algorithm. Phys. Rev. E, 66, 056126.
Mitchell, D., Selman, B., & Levesque, H. (1992). Hard easy distributions SAT
problems. Proc. AAAI, pp. 459465.
117

fiJia, Moore, & Strain

Morris, P. (1993). breakout method escaping local minima. Proc. AAAI,
pp. 4045.
Selman, B., Kautz, H., & Cohen, B. (1996). Local search strategies satisfiability testing.
Proc. 2nd DIMACS Challange Cliques, Coloring, Satisfiability.
Semerjian, G., & Monasson, R. (2003). study pure random walk random satisfiability
problems physical methods. LNCS, 2919, 120134.
Shaw, P., Stergiou, K., & Walsh, T. (1998). Arc consistency quasigroup completion.
Proc. ECAI, workshop binary constraints.
Van Gelder, A. (1993). Problem generator mkcnf.c. Proc. DIMACS. Challenge archive.
Zhang, L. (2002). zChaff.. ee.princeton.edu/chaff/zchaff.php.

118

fiJournal Artificial Intelligence Research 28 (2007) 183232

Submitted 5/06; published 3/07

Proactive Algorithms Job Shop Scheduling
Probabilistic Durations
J. Christopher Beck

jcb@mie.utoronto.ca

Department Mechanical & Industrial Engineering
University Toronto, Canada

Nic Wilson

n.wilson@4c.ucc.ie

Cork Constraint Computation Centre
University College Cork, Ireland

Abstract
classical scheduling formulations assume fixed known duration activity. paper, weaken assumption, requiring instead duration
represented independent random variable known mean variance.
best solutions ones high probability achieving good makespan.
first create theoretical framework, formally showing Monte Carlo simulation
combined deterministic scheduling algorithms solve problem. propose
associated deterministic scheduling problem whose solution proved, certain conditions, lower bound probabilistic problem. propose investigate
number techniques solving problems based combinations Monte Carlo
simulation, solutions associated deterministic problem, either constraint programming tabu search. empirical results demonstrate combination use
associated deterministic problem Monte Carlo simulation results algorithms
scale best terms problem size uncertainty. experiments point
correlation quality deterministic solution quality
probabilistic solution major factor responsible success.

1. Introduction
Proactive scheduling techniques seek produce off-line schedule robust execution time events. paper, assume perfect knowledge
duration activity: durations determined execution time
observed activity finished. However, partial knowledge form
known probability distribution duration. execution time, activities
dispatched according sequences defined off-line schedule measure
robustness probability given quality achieved. specifically,
paper, address problem job shop scheduling (and related generalizations)
durations activities random variables objective find
solution high probability good (ideally, minimal) makespan.
challenging problem even evaluating solution hard problem.
address problem, develop theoretical framework within formally
define problem (a) construct approach, based Monte Carlo simulation,
evaluating solutions partial solutions, (b) show solving carefully defined
deterministic job shop scheduling problem results lower bound probabilistic
c
2007
AI Access Foundation. rights reserved.

fiBeck & Wilson

minimum makespan probabilistic job shop scheduling problem. use framework
define number algorithms embodying three solution approaches:
1. Branch-and-bound search Monte Carlo simulation: search node,
search pruned almost certain (based Monte Carlo simulation)
partial solution cannot extended solution better current best
solution.
2. Iterative deterministic search descending lower bound: deterministic job
shop problem whose solution lower bound probabilistic job shop problem
defined using parameter, q. lower bound proof depends q less
equal q (I), problem-instance-dependent threshold value problem instance
difficult compute. Starting high q value, use tree search
Monte Carlo simulation solve sequence deterministic problems decreasing
q values. q large, problems highly constrained easy solve (if
solutions exist). q descends, best probabilistic makespan previous
iterations used restrict search. able reach value q
q q (I) within CPU time limit, search approximately complete
subject sampling error.
3. Deterministic filtering search: deterministic scheduling algorithms based constraint
programming tabu search used define number filter-based algorithms.
algorithms operate generating series solution candidates
evaluated Monte Carlo simulation.
empirical results indicate Monte Carlo based branch-and-bound
practical small problems. iterative search based descending q values
good as, better than, branch-and-bound algorithm small problems, performs
significantly better larger problems. However, even medium-sized problems,
techniques inferior heuristic approaches based deterministic filtering.
Contributions.

main contributions paper are:

introduction problem finding proactive schedules probabilistic execution guarantees class problems underlying deterministic scheduling
problem NP-hard;
development method generating lower bound probabilistic minimum makespan;
development particular Monte Carlo approach evaluating solutions;
design empirical analysis number approximately complete heuristic solution techniques based either constraint-based constructive search tabu
search;
identification correlation deterministic probabilistic solution
quality key factor performance filter-based algorithms.
184

fiProactive Algorithms JSP

Plan Paper. next section define probabilistic job shop scheduling problem, illustrating example. Section 3 discusses related work. Section 4,
present theoretical framework: formally define problem, derive approach
generating lower bound based associated deterministic job shop problem,
show Monte Carlo simulation used evaluate solutions partial solutions.
Six search algorithms defined Section 5 empirical investigations results
appear Section 6. Section 7, shown results paper apply much
general classes scheduling problems. Directions future work based theoretical
algorithmic extensions also discussed.

2. Probabilistic Job Shop Scheduling Problems
job shop scheduling problem probabilistic durations natural extension
standard (deterministic) job shop scheduling problem (JSP).
2.1 Job Shop Scheduling Problems
JSP involves set activities, Ai positive duration di .
instance JSP, assumed either durations positive integers,
positive real numbers.1 partitioned jobs, job associated
total ordering set activities. activity must execute specified
unary capacity resource. activities require resource overlap
execution, activity started must executed entire duration.
represent formally another partition resource sets: two activities
resource set require resource.
solution consists total ordering resource set, conflict
jobs ordering, i.e., union resource orderings job orderings acyclic
relation A. Thus, Ai Aj resource set, solution either orders Ai
Aj (meaning Aj starts sooner end Ai ), Aj Ai . set
solutions job shop problem labeled S. partial solution consists partial
ordering resource set extended solution.
Let (partial) solution. path (or s-path) sequence activities
Ai immediately precedes Aj sequence, either (i) Ai Aj
job, Ai precedes Aj job, (ii) Ai Aj resource set
orders Ai Aj . length, len(), path
P (of solution) equal
sum durations activities path, i.e., Ai di . makespan, make(s),
solution defined length longest s-path. s-path, , said
critical s-path length equal makespan solution s, i.e., one
longest s-paths. minimum makespan job shop scheduling problem defined
minimum value make(s) solutions s.
definitions focus solutions rather schedules. Here, briefly indicate definitions relate to, perhaps immediately intuitive, definitions focusing
schedules. schedule assigns start time activity, considered
1. empirical investigations examine integer case. shown below, theoretical results hold also
case positive real number durations.

185

fiBeck & Wilson

function set activities set time-points, defining activity
starts. set time-points assumed either set non-negative integers
set non-negative real numbers. Let starti start time activity Ai
respect particular schedule, let endi , end time, starti + di . Ai , Aj A,
write Ai Aj constraint endi startj . schedule defined valid
following two conditions hold two different activities Ai , Aj A: (a) Ai precedes
Aj job, Ai Aj ; (b) Ai Aj resource set,
either Ai Aj Aj Ai (since Ai Aj allowed overlap).
Let Z valid schedule. Define make(Z), makespan Z, maxAi endi ,
time last activity completed. minimum makespan defined
minimum value make(Z) valid schedules.
solution defines valid schedule sched(s), activity started soon
immediate predecessors (if any) finished, activities without predecessors
started time-point 0 (so sched(s) non-delay schedule given precedence constraints
expressed s). immediate predecessor activity Aj respect particular
solution defined activity immediate predecessor Aj either
respect ordering job containing Aj , respect ordering (associated
solution) resource set containing Aj . shown makespan
sched(s) equal make(s) defined earlier, hence justifying definition.
Conversely, given valid schedule Z, define solution, call sol(Z),
ordering resource set relation defined above. Z schedule,
makespan sched(sol(Z)), equal make(sol(Z)), less equal
makespan Z. implies minimum makespan solutions equal
minimum makespan valid schedules. Therefore, interested schedules
best makespans, need consider solutions associated schedules.
summarize, aiming find minimum makespan JSP, focus
searching solutions, rather schedules, (i) schedule Z,
exists solution = sol(Z) Z consistent (i.e., satisfies precedence constraints expressed s); (ii) solution s, efficiently construct
schedule sched(s) optimal among schedules consistent (and furthermore,
makespan sched(s) equal make(s)).
JSP Example. Consider job shop scheduling problem involving two jobs five activities shown Figure 1. first job consists sequence (A1 , A2 , A3 ) activities;
second job consists sequence (A4 , A5 ). three resources involved. A1
A4 require first resource; hence activities A1 A4 cannot overlap, either (i)
A1 precedes A4 , (ii) A4 precedes A1 . Activities A3 A5 require second resource;
A2 requires third resource. Hence, resource sets {A1 , A4 }, {A2 } {A3 , A5 }.
four solutions:
sa involves orderings A1 A4 A3 A5 ;
sb defined A1 A4 A5 A3 ;
sc A4 A1 A3 A5 ;
sd A4 A1 A5 A3 .
186

fiProactive Algorithms JSP

A1

A2

A3

A4

A1

A2

A5

A3

A4

A1

A5

A2

A4

A5

Solution Sa
A1

A2

Solution Sb
A3

A4

A3

A1

A5

A2

A3

A4

Solution Sc

A5
Solution Sd

Figure 1: example JSP four solutions.
duration activity Ai di . sequence (A1 , A4 , A5 ) sa -path, whose length
d1 +d4 +d5 . Also, sa -path (A1 , A2 , A3 , A5 ), len() = d1 +d2 +d3 +d5 .
sa -paths subsequences one two. Hence, make(sa ), makespan
solution sa , equal max(d1 + d4 + d5 , d1 + d2 + d3 + d5 ) = d1 + d5 + max(d4 , d2 + d3 ).
particular, d1 = 1, d2 = 2, d3 = 3, d4 = 4 d5 = 5, make(sa ) = 11 time units.
also make(sb ) = 13, make(sc ) = 15 make(sd ) = 12. Hence, minimum
makespan make(sa ) = 11.
Let Z = sched(sa ) schedule associated solution sa . generated
follows. A1 predecessors, start A1 beginning, setting Z(A1 ) = 0; hence
activity A1 starts time-point 0 ends time-point d1 . predecessor A4
A1 , set Z(A4 ) = d1 . Similarly, set Z(A2 ) = d1 , activity A2 ends
time-point d1 + d2 . Continuing, set Z(A3 ) = d1 + d2 . Activity A5 two immediate
predecessors (for solution, sa ), A3 A4 , A5 set start soon
activities completed, time-point max(d1 + d2 + d3 , d1 + d4 ).
activities completed A5 completed, time-point
max(d1 +d2 +d3 , d1 +d4 )+d5 = d1 +d5 +max(d4 , d2 +d3 ). confirms makespan
make(sa ) solution sa equal makespan associated schedule sched(sa ).
2.2 Independent General Probabilistic Job Shop Scheduling Problems
independent probabilistic job shop scheduling problem defined way
JSP, except duration di associated activity Ai random variable;
assume instance probabilistic JSP, either durations positive
integer-valued random variables, positive real-valued random variables.
(known) distribution Pi , expected value = E[di ] variance i2 = Var[di ].
187

fiBeck & Wilson

random variables fully independent. length path solution
random variable, write len(). makespan make(s) solution (the
length longest path s) therefore also random variable, sometimes
refer random makespan s.
generalize non-independent case. probabilistic job shop scheduling problem joint probability measure P durations vectors. (The intention
efficiently sample joint density function. example, Bayesian
network might used represent P .) Here, activity Ai , distribution Pi defined
appropriate marginal distribution, expected value variance i2 .
Loosely speaking, probabilistic job shop scheduling problem, want find
small value possible solution whose random makespan is,
high probability, less (the deadline activities finish). time value
called probabilistic minimum makespan.
Evaluating solution deterministic JSP, i.e., finding associated makespan given
duration activity, achieved low degree polynomial time using longest
path algorithm. Without ordering resource set, disjunctions resource
constraints must satisfied find solution turn easy problem
NP-complete JSP (Garey & Johnson, 1979). PERT networks, hand, generalize
simple longest-path problem allowing durations independent random variables,
leading #P-complete problem (Hagstrom, 1988). probabilistic JSP makes
generalizations. Consequently, finding optimal solutions probabilistic JSP
appears hard, focus methods finding good solutions instead.
Evaluating (approximately) solution probabilistic JSP done relatively
efficiently using Monte Carlo simulation: large number trials randomly
sample duration every activity generate makespan associated
trial. Roughly speaking, approximately evaluate solution evaluating sampled
distribution makespans. approach described detail Section 4.3.
Almost solution techniques involve associating deterministic job shop problem
given probabilistic job shop problem, replacing, number q, random
duration mean distribution plus q times standard deviation. Hence, set
duration di activity Ai associated deterministic problem +q
case continuous time. case time-points integers, set = bi +qi c.
certain values q, leads minimum makespan deterministic problem
lower bound probabilistic minimum makespan, shown Section 4.2.
lower bound useful pruning branch-and-bound algorithm. generally,
show solving associated deterministic problem used help solve
probabilistic problem.
assumptions joint probability somewhat restrictive. example,
model allow activitys duration depend start time; however,
extended certain situations kind.2 Despite restrictions (which common
related literaturesee Section 3), model apply interesting class problems
2. could allow duration activity probabilistically dependent start time, given
additional (very natural) coherence condition time-point t0 , conditional probability
endi t0 , given starti = t, monotonically increasing t, i.e., Pr(endi t0 |starti = t1 )
Pr(endi t0 |starti = t2 ) t1 t2 . condition ensures that, given solution,

188

fiProactive Algorithms JSP

previously addressed. Extending model richer representations
relaxing assumptions remains future work.
Probabilistic JSP Example. consider independent probabilistic job shop scheduling problem structure JSP example Figure 1. durations
activities A2 , A3 A4 independent real-valued random variables (referred
d2 , d3 d4 , respectively) approximately normally distributed standard deviation 0.5 (2 = 3 = 4 = 0.5) means 2 = 2, 3 = 3 4 = 4.
durations activities A1 A5 deterministic, equal 1 5, respectively.
Let sa -path (A1 , A2 , A3 , A5 ). length len() approximately
normally distributed random variablewith mean 1+2+3+5 = 11 variance 0.5 2 +0.52 =
0.5 hence standard deviation 1/ 2.
length sa -path 0 = (A1 , A4 , A5 ) approximately normal random variable
mean 10 standard deviation 0.5. (random) makespan make(sa ) solution
sa random variable equaling maximum random variables len() len( 0 ).
general, maximum two independent normally distributed random variables
normally distributed; however, is, high probability, longer 0 , distribution
make(sa ) approximately equal distribution len().

3. Previous Work
considerable work scheduling uncertainty variety fields
including artificial intelligence (AI), operations research (OR), fault-tolerant computing,
systems. surveys literature, mostly focusing AI OR, see work
Davenport Beck (2000), Herroelen Leus (2005), Bidot (2005).
highest level, two approaches problems: proactive scheduling,
knowledge uncertainty taken account generating off-line
schedule; reactive scheduling decisions made on-line deal unexpected
changes. significant work reactive scheduling and, indeed, techniques
combine reactive proactive scheduling least commitment approaches (see
surveys noted above), interest pure proactive scheduling. Three categories
proactive approaches identified: redundancy-based techniques, probabilistic
techniques, contingent/policy-based techniques (Herroelen & Leus, 2005). briefly
look turn.
3.1 Redundancy-based Techniques
Redundancy-based techniques generate schedule includes allocation extra
resources and/or time schedule. intuition redundant allocations
help cushion impact unexpected events execution. example, extra time
consumed activity takes longer expected execute.
clear conflict insertion redundancy common measures schedule quality
(e.g., makespan), focus work tends intelligent insertion redundancy
order achieve satisfactory trade-off schedule quality robustness.
advantage delaying starting activity predecessors finished. Allowing delay
would break assumptions underlying formulation.

189

fiBeck & Wilson

common fault-tolerant scheduling real-time guarantees reserve redundant
resources (i.e., processors) time. former case, multiple instantiations given
process executed parallel error detection done comparing results
different instantiations. contrast, time redundancy, time reserved
re-execution process fails. Given fault model, either technique used
provide real-time guarantees (Ghosh, Melhem, & Mosse, 1995; Ghosh, 1996).
similar approach used work Gao (1995) Davenport, Gefflot Beck
(2001) context job shop scheduling. Statistical information mean time
failure mean repair time machines used either extend duration
critical activities former work require solution produced must respect
constraints slack activity. Given solution, slack room
activity move without breaking constraint increasing cost. Typically,
formalized difference activitys possible time window solution (i.e.,
latest possible end time less earliest possible start time) duration activity.
advantage Gaos approach purely modeling approach: problem
changed incorporate extended durations scheduling techniques used
solve problem. However, Davenport et al. show reasoning slack shared
amongst set activities lead better solutions cost specialized solving
approaches.
Leon, Wu Storer (1994) present approach job shop scheduling
objective function modified linear combination expected makespan
expected delay assuming machines break that, execution time, disruptions dealt shifting activities later time maintaining sequence
original schedule. basic technique properly seen probabilistic
approach, authors show exact calculation measure intractable unless
single disruption assumed. likely multiple disruptions, authors
present number surrogate measures. Empirically, best surrogate measure
deterministic makespan minus mean activity slack. Unlike, Gao Davenport et al.,
Leon et al. provide formal probabilistic foundation, temporal redundancy plays
central role practical application approach.
3.2 Probabilistic Techniques
Probabilistic techniques use representations uncertainty reason likely outcomes
schedule executed.3 Rather explicitly inserting redundancy attempt
create robust schedule, probabilistic techniques build schedule optimizes
measure probabilistic performance. Performance measures typically come two forms:
expected value expected makespan expected weighted tardiness, probabilistic guarantee respect threshold value deterministic optimization measure.
example latter measure, discussed below, probability flow time
schedule less particular value.
Optimal expected value scheduling problems widely studied (Pinedo,
2003). many cases, approach takes form dispatch rules slightly
complicated polynomial time algorithms find optimal schedule tractable
3. Alternative representations uncertainty fuzzy sets also used (Herroelen & Leus, 2005).

190

fiProactive Algorithms JSP

problems (e.g., 1 2 machine problems) serve heuristics difficult
problems. One example work AI literature Wurman Wellman
(1996) extends decision theoretic planning concepts scheduling. problem
studied assumes single machine, stochastic processing time stochastic set-up time,
objective minimization expected weighted number tardy jobs.
authors propose state-space search solve problem multi-objective stochastic
dominance A*. Critical aspects work use number sophisticated path
pruning rules relaxation-based heuristics evaluation promising nodes.
threshold measure used Burns, Punnekkat, Littlewood Wright (1997)
fault-tolerant, single processor, pre-emptive scheduling application. objective find
minimum fault arrival rate tasks scheduled meet deadlines.
Based fault-model, probability observing fault arrival rate calculated
used measure schedule quality. optimization problem, then, find
schedule maximizes probability tasks meeting deadlines fault
arrival process.
one-machine manufacturing context independent activities, Daniels Carrillo (1997) define -robust schedule sequence maximizes probability
execution achieve flow time greater given threshold. underlying deterministic scheduling problem solvable polynomial time and, indeed,
minimum expected flow time schedule found polynomial time, shown
finding -robust schedule NP-hard. Daniels Carrillo present branch-and-bound
heuristic techniques solve problem.
3.3 Contingent Policy-based Approaches
Unlike approaches described above, contingent policy-based approaches
generate single off-line schedule. Rather, produced branching contingent
schedule or, extreme, policy, specifies actions taken particular
set circumstances arises. Given importance off-line schedule terms
coordination entities context surrounding scheduling problem,
difference significant practical implications (see Herroelen & Leus, 2005,
discussion).
elegant example contingent scheduling approach just-in-case work
Drummond, Bresina Swanson (1994). Given initial, deterministic schedule
single telescope observation problem, approach identifies activity likely fail
based available uncertainty information. point, new schedule produced
assuming activity does, indeed, fail. Repeated application identification
most-likely-to-fail activity generation new schedule results branching schedule
number likely contingencies accounted alternative schedules.
execution time, activity fails, execution switches alternative schedule
one exists. alternative exist, on-line rescheduling done. Empirical results
demonstrate significantly larger portion existing (branching) schedule
executed without revert rescheduling compared original deterministic
schedule.
191

fiBeck & Wilson

One weaknesses just-in-case scheduling surrounds combinatorics
multiple resources. multiple inter-dependent telescopes, problem quickly becomes
intractable. Policy-based approaches Markov Decision Processes (MDPs) (Boutilier,
Dean, & Hanks, 1999) applied problems. Here, objective
produce policy mapping states actions direct on-line execution
schedule: given state encountered, corresponding action taken. Meuleau et
al. (1998) apply MDPs stochastic military resource allocation problem weapons
must allocated targets. Given limited number weapons uncertainty
effectiveness given allocation, MDP used derive optimal policy
states represented number remaining weapons targets, actions
weapon allocation decisions. goal minimize expected number surviving
targets. Empirical results demonstrated computational challenges approach
6 target, 60 weapon problem required approximately 6 hours CPU time (albeit
now-outdated hardware).
literature, substantial work (cited Brucker, Drexl, Mohring,
Neumann Pesch, 1999, Herroelen Leus, 2005) stochastic resource-constraint
project scheduling, generalization job shop scheduling. general form
approaches multi-stage stochastic programming problem, objective finding
scheduling policy minimize expected makespan. context, scheduling
policy makes decisions on-line activities execute. Decisions need made
beginning schedule end time activity, information used
decisions must become known time decision
making. number different classes policy investigated. example,
minimal forbidden subset activities, F , set activities F cannot
executed simultaneously due resource constraints, subset F
executed. pre-selective policy identifies set F waiting activity, j F ,
j cannot started least one activity F {j} executed.
execution, j started least one activity F finished.
proactive problem, then, identify waiting activity minimal forbidden
subset expected makespan minimized. computational challenges
pre-selective policies (in particular, due number minimal forbidden subsets)
led work different classes policy well heuristic approaches.
3.4 Discussion
work paper falls within probabilistic scheduling approaches
closely inspired -robustness work Daniels Carrillo (1997). However, unlike
Daniels Carrillo, address scheduling model deterministic problem
underlies probabilistic job shop scheduling problem is, itself, NP-hard.
first work aware seeks provide probabilistic guarantees
underlying deterministic problem computationally difficult.

4. Theoretical Framework
section, develop theoretical framework probabilistic job shop problems.
Section 4.1, define compare solutions, using call -makespans.
192

fiProactive Algorithms JSP

-makespan solution less time value D, least chance 1
(random) makespan less D. useful idea far
solutions -makespan optimum -makespan (i.e., minimum -makespan
solutions), Section 4.2, describe approach finding lower bound
optimum -makespan. Section 4.3 considers problem evaluating given solution, s,
using Monte Carlo simulation estimate -makespan s.
order separate theoretical contributions empirical analysis, summarize notation introduced section Section 5.1. Readers interested primarily
algorithms empirical results therefore move directly Section 5.
section makes use notation introduced Section 2: definitions Section
2.1 JSP, solution, paths solution, makespan solution, minimum
makespan; definitions Section 2.2 probabilistic JSP random makespan
solution.
4.1 Comparing Solutions Probabilistic Makespan
standard job shop problem, solutions compared considering associated
makespans. probabilistic case, makespan solution random variable,
comparing solutions less straight-forward. map random makespan scalar
quantity, called -makespan, sums good is; solutions compared
comparing associated -makespans. simple idea prefer solutions smaller
expected makespan. However, may substantial probability makespan
solution much higher expected value. Instead, take following
approach: confident random makespan solution D,
cannot confident makespan solution s0 D, prefer
solution solution s0 .
fix value , used bound probabilities. Although imagine
natural applications work, would quite small (e.g., less 0.1)
assume range (0, 0.5]. probability event least 1 ,
say event sufficiently certain. experiments described Section 6
use value = 0.05, sufficiently certain means occurs least 95%
chance.
Let time value, let solution. said -achievable using
sufficiently certain jobs finish use solution s; is,
Pr(make(s) D) 1 , make(s) random makespan s.
said -achievable solution -achievable using
s, i.e., exists solution making sufficiently certain jobs finish D.
Time value -achievable maxsS Pr(make(s) D)) 1 ,
max solutions s.
Define Ach (s) set -achievable using s. define (s),
-makespan s, infimum4 Ach (s). , -minimum makespan,
defined infimum Ach , set -achievable,
4. is, greatest lower bound Ach (s); fact, shown Proposition 1(i), (s) smallest
element Ach (s). Hence, Ach (s) equal closed interval [D (s), ), i.e., set time-points
(s).

193

fiBeck & Wilson

= inf {D : (maxsS Pr(make(s) D)) 1 }. also sometimes refer (s)
probabilistic makespan s, refer probabilistic minimum makespan.5
prefer solutions better (i.e., smaller) -makespans. Equivalently, solution
considered better s0 time value -achievable using
-achievable using s0 . Optimal solutions ones whose -makespan equal
-minimum makespan.
prove technical properties -makespans -achievability relevant
mathematical results later sections. particular, Proposition 1(ii) states minimum makespan -achievable: i.e., exists solution makes
sufficiently certain jobs finish . smallest value satisfying
property.
Lemma 1 notation:
(i) Ach =



sS

Ach (s);

(ii) exists solution Ach = Ach (s) = (s);
(iii) = minsS (s), minimum (s) solutions s.
Proof:
(i) -achievable
solution s, Ach (s), true

sS Ach (s).
(ii) Consider following property () set time values A: 0 time
value greater (i.e., 0 > D), 0 A; is, interval upper
bound. Let B two sets property (); either B B A. (To show
this, suppose otherwise, neither B B A; exists x B
B A; x must different, assume, without loss
generality, x < y; property (), contradiction required.)
Hence, B either equal equal B. using induction, follows
union finite number sets
property () one sets. set Ach (s)
satisfies property (); therefore, sS Ach (s) = Achs0 solution s0 , so, (i),
Ach = Achs0 . implies also = (s0 ).
(iii) Let solution let time value. Clearly, -achievable using
s, -achievable. implies (s). Hence, minsS (s).
(ii), = (s) solution s, = minsS (s), required.
2

Proposition 1
(i) Let solution. (s) -achievable using s, i.e., Pr(make(s) (s))
1 .
(ii) -achievable, i.e., exists solution Pr(make(s) ) 1.
5. Note probabilistic makespan number (a time value), opposed random makespan
solution, random variable.

194

fiProactive Algorithms JSP

Proof:
discrete case, set time values set non-negative integers,
infimum definitions (s) minimum. (i) (ii)
follow immediately definitions.
consider case set time values set non-negative real
numbers.
1
1
(i): m, n {1, 2, . . . , }, let Gm = Pr(0 < make(s)D (s)
), let gn = Pr( n+1
<
1
make(s) (s) n ). countable additivity axiom probability measures, Gm =
P
P
gn . means l1
n=m
n=m gn tends Gm l tends infinity, hence Gl =
Pl1
P
n=m gn tends 0. So, limm Gm = 0. > 0,
l gn = G
1
) 1 , definition (s). Also Pr(make(s)
Pr(make(s) (s) +
1
). So, = 1, 2, . . ., Pr(make(s)
(s)) + Gm = Pr(make(s) (s) +
(s)) 1 Gm , implies Pr(make(s) (s)) 1 , Gm tends
0 tends infinity.

(ii): part (ii) Lemma 1, solution s, = (s). Part (i) implies
Pr(make(s) ) 1 .
2
Probabilistic JSP Example continued. continue example Section 2.1
Section 2.2. Set 0.05, corresponding 95% confidence. value = 12.5
-achievable using solution sa , since 95% chance paths
0 (simultaneously) shorter length 12.5, probability random
makespan make(sa ) less 12.5 0.95.
consider value ofD = 12.0. Since len() (the random length ) mean 11
standard deviation 1/ 2, chance
len() 12.0 approximately chance
normal distribution 2 standard deviations mean;
probability 0.92. Therefore, = 12.0 -achievable using solution , since
less 0.95 chance random makespan make(sa ) D.
-makespan (also referred probabilistic makespan) solution
therefore 12.0 12.5. fact, -makespan (sa ) approximately equal
12.16, since approximately 95% chance (random) makespan make(s )
12.16. easy show = 12.16 -achievable using
solution, , -minimum makespan, equal (sa ), hence 12.16.
4.2 Lower Bound -Minimum Makespan
section show lower bound -minimum makespan found
solving particular deterministic JSP.
common approach generate deterministic problem replacing random
duration mean distribution. show, certain conditions, minimum makespan deterministic JSP lower bound probabilistic minimum
makespan. instance, example, minimum makespan deterministic
JSP 11, probabilistic minimum makespan 12.16. However, obvious
weakness approach take account spreads distributions. especially important since typically considering small value ,
195

fiBeck & Wilson

0.05. generate stronger lower bound taking account variances
distributions generating associated deterministic job shop problem.
Generating Deterministic JSP Probabilistic JSP Value q.
probabilistic job shop problem, generate particular deterministic job shop problem, depending parameter q 0. use transformation almost
algorithms Section 5. deterministic JSP probabilistic JSP except
random duration replaced particular time value. Solving corresponding
deterministic problem give us information probabilistic problem. deterministic JSP consists set activities, partitioned resource sets
jobs, total order job. duration activity
deterministic problem defined + qi , respectively mean
standard deviation duration activity Ai probabilistic job shop problem.
Hence, q = 0, associated deterministic problem corresponds replacing random
duration mean. Let makeq (s) deterministic makespan solution s, i.e.,
makespan associated deterministic problem (which defined length
longest s-pathsee Section 2.1). Let makeq minimum deterministic makespan
solutions.
Let solution. say probabilistically optimal (s) = . Let
s-path. ( path probabilistic deterministic problems.) said
(deterministically) critical path critical path deterministic problem.
length deterministic
problem, lenq (), P
equal sum
P
P durations
activities path:
Ai (i + qi ), equals
Ai + q
Ai .
introduce following rather technical definition whose significance made clear
Proposition 2: q -sufficient exists (deterministically) critical path
probabilistically optimal solution Pr(len() > lenq ()) > , i.e.,
chance random path length greater deterministic length.
following result shows -sufficient value q leads deterministic
minimum makespan makeq lower bound probabilistic minimum makespan
. Therefore, lower bound deterministic minimum makespan also lower
bound probabilistic minimum makespan.
Proposition 2 probabilistic JSP, suppose q -sufficient. Then, solution
s, Pr(make(s) makeq ) < 1 . Therefore, makeq -achievable, strict
lower bound -minimum makespan , i.e., > makeq .
Proof: Since q -sufficient, exists (deterministically) critical path (probabilistically) optimal solution Pr(len() > lenq ()) > . lenq () =
makeq (so ), critical path, and, definition makeq , makeq (so )
makeq . So, Pr(len() > makeq ) > . definition makespan, sample
random durations vector, make(so ) least large len(). So,
Pr(make(so ) > makeq ) > . Hence, Pr(make(so ) makeq ) = 1 Pr(make(so ) >
makeq ) < 1 . implies (so ) > makeq since Pr(make(so ) (so )) 1 ,
Proposition 1(i). Since probabilistically optimal solution, = (so ),
> makeq . Also, solution s, (s) > makeq , (s) > makeq ,
implies makeq -achievable using s, i.e., Pr(make(s) makeq ) < 1 . 2
196

fiProactive Algorithms JSP

4.2.1 Finding -Sufficient q-Values
Proposition 2 shows find lower bound probabilistic minimum makespan
find -sufficient value q, solve (or find lower bound for)
associated deterministic problem. section looks problem finding -sufficient
values q, breaking condition simpler conditions.
remainder Section 4.2, assume independent probabilistic JSP.
Let path solution. Define E[len()],
P expected value
length (in probabilistic JSP), equal PAi . Define 2
Var[len()], variance length , equal Ai i2 , since
assuming durations independent.
P
Defining -adequate B. B 0, write B () + B , equals Ai +
qP
2
B
Ai . say B -adequate (deterministically) critical path
(probabilistically) optimal solution, Pr(len() > B ()) > , i.e.,
chance B standard deviations longer expected length.
duration normally distributed, len() normally distributed, since
sum independent normal distributions. Even durations normally
distributed, len() often close normally distributed (cf. central limit
theorem extensions). So, Pr(len() > B ()) approximately 1 (B),
unit normal distribution. B value slightly less 1 (1 )
-adequate, given approximate normality.
Defining B-adequate Values q. say q B-adequate exists
(deterministically) critical path (probabilistically) optimal solution
lenq () B ().
following proposition shows task finding -sufficient values q
broken down. follows almost immediately definitions.
Proposition 3 q B-adequate B -adequate, q -sufficient.
Proof: Since q B-adequate, exists (deterministically) critical path
(probabilistically) optimal solution lenq () B (). Since B -adequate,
Pr(len() > B ()) > , hence Pr(len() > lenq ()) > , required.
2
Establishing B-adequate Values q. value q B-adequate
exists (deterministically) critical path (probabilistically) optimal solution
qP
P
P
P
2
lenq () B (), equivalently:
Ai ,
Ai + q
Ai
Ai + B
qP

q

Mean{i2 : Ai }
,
MeanP
{i : Ai }
Ai
number activities path , Mean{i : Ai } = M1 Ai .
activity Ai uncertain (i.e., standard deviation equals 0),
omitted summations means. becomes number uncertain
activities path .
is, q B

P

Ai

i2



. written as: q

197

B


fiBeck & Wilson

well known (and quite easily shown), root qmean square collection
Mean{ 2 : Ai }
numbers always least large mean. Hence, Mean{ i: } greater


equal 1. Therefore, crude sufficient condition q B-adequate is: q BM ,
upper bound number uncertain activities path
probabilistically optimal solution (or could take upper bound number
uncertain activities path solution). particular, could generate Badequate q choosing q = BM .
-sufficient Value q. Putting two conditions together using Proposition
1
3, q-value little less (1)
-sufficient, given

lengths paths approximately normally distributed, upper bound
number uncertain activities path optimal solution. Hence,
Proposition 2, minimum makespan makeq associated deterministic problem
strict lower bound -minimum makespan . example, = 0.05,
1 (1 ) 1.645 (since 0.05 chance normal distribution
1.645 standard deviations mean), set q little less
.
1.645

One sometimes generate larger -sufficient value q, hence stronger lower
bound makeq , focusing significantly uncertain activities. Choose value

P 0 1. path , say
P activity Aj -uncertain (with respect
)
{i : Ai , j } > {i : Ai }; sum durations
activities -uncertain fraction sum durations
path. Hence, activities -uncertain relatively small standard
deviations. define upper bound number -uncertain activities
involved path (probabilistically) optimal solution, shown,

B-adequate,
slight modification earlier argument, q-value (1)B

hence q-value little less

(1)1 (1)





-sufficient.

experiments described Section 6 use, varying n, problems n jobs n
activities per job). Solutions paths involving large numbers activities
unlikely good solutions. particular, one might assume that, problems,
optimal solution (deterministically) critical s-path involving
2n activities. Given assumption, following value q -sufficient,
1
, e.g.,
making makeq lower bound probabilistic minimum makespan: q = (1)
2n
q=

1.645

2n

= 0.05. motivates choice q1 Table 2 Section 6.1.

Probabilistic JSP Example continued. number uncertain activities
running example (see Section 2.2, Figure 1 Section 4.1) 3, one
set = 3.
Using = 0.05, leads choice q slightly less 1.645/ 3 0.950.
Proposition 3 discussion, value q -sufficient. durations
associated deterministic problem given setting di = + qi , d1 = 1,
d2 = 2 + q/2, d3 = 3 + q/2, d4 = 4 + q/2 d5 = 5. Solution sa best solution
makespan makeq (sa ) = 1 + 5 + (2 + q/2) + (3 + q/2) = 11 + q. Hence, minimum
198

fiProactive Algorithms JSP

deterministic makespan makeq equals approximately 11.95, lower bound
probabilistic minimum makespan 12.16, illustrating Proposition 2.
However, sc clearly poor solution, could consider solutions:
{sa , sb , sd }. (deterministically) critical path solutions involves two
uncertain activities (within
range interest q-values), set = 2,
q = 1.16 1.645/ 2. leads stronger lower bound 11 + 1.16 = 12.16,
tight lower bound -minimum makespan .
4.2.2 Discussion lower bound
example, able use approach construct tight lower bound
probabilistic minimum makespan. However, situation rather exceptional.
Two features example enable tight lower bound (a) best
solution path almost always longest path; (b) standard deviations
uncertain durations equal. analysis, root mean square
approximated (from below) mean. good approximation standard
deviations fairly similar, extreme case (non-zero) standard deviations
durations (as example), root mean square actually equal
mean.
generally, number ways lower bound tend
conservative. particular,
choice often conservative us confident
genuine upper bound number uncertain activities path
optimal solution;
approximating root mean square standard deviations average
standard deviations: crude approximation standard deviations
durations vary considerably activities;
approximating random variable make(s) random length particular path.
strength lower bound method, however, computationally feasible
reasonably large problems uses existing well-developed JSP methods.
4.3 Evaluating Solution Using Monte Carlo Simulation
given time value, D, want assess exists solution
chance random makespan greater D. methods
involve generating solutions (or partial solutions), testing condition.
noted earlier, evaluating solution amounts solving PERT problem uncertain durations, #P-complete problem (Hagstrom, 1988). #P-complete
problems computation Dempster-Shafer Belief (Wilson, 2000), natural approach take Monte Carlo simulation (Burt & Garman, 1970); try perform
exact computation instead choose accuracy level require high
chance random estimate within true value. evaluation algorithm
199

fiBeck & Wilson

optimal complexity (low-degree polynomial) potentially high constant factor
corresponding number trials required given accuracy.
evaluate solution (or partial solution) using Monte Carlo simulation perform
(large) number, N , independent trials assigning values random variable.
trial generates deterministic problem, check efficiently corresponding
makespan greater D; so, say trial succeeds. proportion trials
succeed estimate Pr(make(s) > D), chance random makespan
D. case independent probabilistic JSPs, generate
random durations vector picking, using distribution Pi , value random duration
di activity Ai . general case, picking random durations vector still
efficient many situations; example, distribution represented Bayesian
network.
4.3.1 Estimating Chance Random Makespan Greater
Perform N trials: l = 1, . . . , N .
(trial) l:
Pick random durations vector using joint density function.
Let Tl = 1 (the trial succeeds) corresponding (deterministic) makespan greater
D. Otherwise, set Tl = 0.
P
Let = N1 N
l=1 Tl proportion trials succeed. estimate p,
p = Pr(make(s) > D), chance randomly generated durations vector leads
makespan (for solution s) greater D. expected value equal
q p, since
1 PN
E[Tl ] = p E[T ] = N l=1 E[Tl ] = p. standard deviation p(1p)
N ,
shown follows: V ar[Tl ] = E[(Tl )2 ] (E[Tl ])2 = p p2 = p(1 p). variables
P
p(1p)
1
Tl independent V ar[T ] = N12 N
4N
. random variable N
i=1 V ar[Tl ] =
N
binomially distributed, (because deMoivre-Laplace limit theorem (Feller,
1968)) use normal distribution approximate .
means that, large N , generating value algorithm will,
high probability, give value close Pr(make(s) > D). choose accuracy level
> 0 confidence level r (e.g., r = 0.95), choose N Pr(|T p| < ) > r;
particular, r = 0.95 using normal approximation, choosing number N trials
12 sufficient. fixed accuracy level confidence level r, number
trials N constant: depend size problem. algorithm
therefore excellent complexity: complexity (low-order polynomial)
single deterministic propagation, must optimal clearly cannot hope beat
complexity deterministic propagation. However, constant factor 12 large
require high accuracy.
4.3.2 Solution Good Enough?
Let time value let solution. Suppose, based Monte-Carlo
algorithm using N trials, want confident -achievable using (i.e.,
200

fiProactive Algorithms JSP

Pr(make(s) > D) ). therefore need observed least little smaller
, since (only) estimate Pr(make(s) > D).
formalize this, shall use confidence interval-style approach. Let K 0. Recall
p = Pr(make(s) > D) unknown quantity want find information
about. say p K-implausible given result following condition
holds: p p
implies least K standard deviations expected value, i.e.,
p KN p(1 p).
case p , p K-implausible given , unlikely
event would happened. example, K = 2, (given normal approximation),
event happen every 45 experiments; K = 4 event
happen every 32,000 experiments.
Pr(make(s) > D) K-implausible given result , confident
Pr(make(s) > D) < : -achievable using s, upper bound
(s) hence -minimum makespan . confidence level, based
normal approximation binomial distribution, (K), unit normal
distribution. example, K = 2 gives confidence around 97.7%.
Similarly, 0 0.5, say p K-implausible given
result following condition holds: p implies
least K standard
p
deviations expected value, i.e., p + KN p(1 p).
definitions K-implausibility slightly informal. formal definitions
follows. Suppose (0, 0.5], K 0, [0, 1] N {1, 2, . . . , }. define:
p K-implausible given p
p p 1, following
condition holds: p KN p(1 p). Similarly, p K-implausible given
p
p 0 p , following condition holds: p + KN p(1 p).
K-implausibility conditions cannot tested directly using definition since
p unknown. Fortunately, following result, gives equivalent conditions
easily checked.
Proposition 4 definitions:
K
N

p
(1 ).
p
(ii) p K-implausible given + KN (1 ).
(i) p K-implausible given

p
Proof: (i): p K-implausible given , setting p gives KN (1 )
p
required. Conversely, suppose KN (1 ). result follows K = 0,
2

assume K > 0. Write f (x) = (x )2 K x(1x)
. Now, since
N
p
K 2 (1)
K
2
N (1 ), > ( )
so, f () 0. Also, f (T ) 0.
N
Since f (x) quadratic polynomial positive coefficient x2 , implies
either solution equation f (x) = 0, two solutions. Since f () 0
> , follows must either solution f (x) = 0, greater
2
. Since p > ,
solution(s). implies, p > , f (p) > 0, (p )2 > K p(1p)
N
q
p(1p)
p p K
N , is, p K-implausible given ,
proving (i).
201

fiBeck & Wilson

q

. Con(ii) p K-implausible given , setting p gives + K (1)
q N
q
, (since 0.5) p implies p + K p(1p)
since
versely, + K (1)
N
N
right-hand-side strictly increasing function p, p K-implausible given ,
required.
2
Part (i) result shows us evaluate solution respect
p bound
K

D: generate (using Monte Carlo simulation) least N (1 ) less
, confidence p < , i.e., Pr(make(s) > D) < ,
confidence -achievable using solution s, i.e., upper bound
probabilistic makespan (s). Part (ii) used branch-and-bound algorithm
described Section 5.2.1, determining backtrack node.
4.3.3 Generating upper approximation probabilistic makespan
solution
Suppose that, given solution s, wish find time value large enough
confident probabilistic makespan D, i.e.,
upper bound -makespan (s). Monte Carlo simulation
adapted purpose. simulate values random makespan make(s)
record distribution these. decide value K, corresponding desired
degree confidence (e.g., K = 2 corresponds 97.7% confidence) choose
minimal suchpthat associated value (generated simulation results) satisfies
KN (1 ). Proposition 4(i), Pr(make(s) > D) K-implausible
given . therefore confident Pr(make(s) > D) < ,
confidence upper bound -makespan (s) s. balance
paper, use notation D(s) represent (upper) estimate (s) found
way.

5. Searching Solutions
theoretical framework provides two key tools use building search algorithms.
First, use Monte Carlo simulation evaluate solution partial solution (see
Section 4.3). Second, appropriate choice q value, solve associated
deterministic problem find lower bound -minimum makespan problem
instance (see Section 4.2). section, make use tools (and
variations) define number constructive local search algorithms. describing
algorithms, recall important concepts notation introduced
earlier sections.
algorithms, explicitly deal case independent probabilistic JSPs durations positive integer random variables. Given approach,
however, algorithms valid:
generalized probabilistic case, assumptions noted Section 4, provided efficient way sample activity durations;
202

fiProactive Algorithms JSP

continuous random variables, provided deterministic solver
handle continuous time values.
5.1 Summary Notation
remainder paper makes use notation concepts earlier sections,
briefly summarize below.
JSP probabilistic JSP: solution totally orders activities requiring
resource (i.e., activities resource set), activity Ai Aj require
resource, either determines Ai must completed time
Aj starts, vice versa (see Section 2.1). partial solution partially orders set
activities resource set. Associated solution non-delay schedule (relative
solution), activities without predecessors started time 0,
activities started soon predecessors completed. makespan
solution time jobs completed associated non-delay
schedule. probabilistic JSP (see Section 2.2), makespan make(s) solution
random variable, since depends random durations.
quantity use evaluate solution (s), -makespan (also known
probabilistic makespan s), defined Section 4.1. probability (random)
makespan (s) , approximately equal . (More
precisely, (s) smallest time value Pr(make(s) > D) .)
Value therefore represents degree confidence required. -minimum makespan
(also known probabilistic minimum makespan) minimum (s)
solutions s.
time value -achievable using solution chance
random makespan D. -achievable using
(s) (see Section 4.1).
Solutions probabilistic JSPs evaluated Monte Carlo simulation (see Section
4.3). method derived generating upper approximation . use
notation D(s) represent upper approximation, constructed D(s)
approximately equal (s), high chance (s) less
D(s)see Section 4.3.3. D(s) thus represents probable upper bound probabilistic
minimum makespan.
probabilistic job shop problem often associate deterministic JSP (see Section
4.2). mapping parameterized (non-negative real) number q. associated
deterministic JSP structure probabilistic JSP; difference
duration activity Ai equal + qi , mean
standard deviation (respectively) duration Ai probabilistic problem.
write makeq (s) makespan solution respect associated deterministic
JSP, makeq minimum makespan: minimum makeq (s) solutions s.
Section 4.2, shown, using Propositions 2 3 analysis Section
4.2.1, certain values q, time value makeq lower bound .
203

fiBeck & Wilson

5.2 Constructive Search Algorithms
Four constructive-search based algorithms introduced here. uses constraintbased tree search core search technique, incorporating simulation q values different ways. section, define constructive algorithm detail provide
description heuristics constraint propagation building blocks used
them.
5.2.1 B&B-N: Approximately Complete Branch-and-Bound Algorithm
Given ability estimate probabilistic makespan solution, ability
test condition implies partial solution cannot extended solution
better probabilistic makespan, obviously applicable search technique branch-andbound (B&B) use Monte Carlo simulation derive upper- lower-bounds
solution quality. able cover entire search space, approach
approximately complete (only approximately always small probability
miss optimal solution due sampling error).
B&B tree (rooted) binary tree. Associated node e tree
partial solution se , solution node leaf node. empty partial solution
associated root node. Also associated non-leaf node e pair
activities, Ai , Aj , j 6= i, resource set, whose sequence determined
partial solution se . two nodes e extend se : one sequences Ai Aj ,
adds opposite sequence. heuristic used choose sequence try first
described Section 5.2.5.
value global variable always confidence (corresponding
choice Ksee Section 4.3.2) exists solution whose -makespan, (s),
. Whenever reach leaf node, e, find upper estimate 0 = D(se )
probabilistic makespan (s), Monte Carlo simulation based method
Section 4.3.3. set := min(D , D0 ). Variable initialized high value.
non-leaf nodes, e, check see worth exploring subtree e.
perform Monte Carlo simulation partial solution, se , using current value ;
generates result . use Proposition 4(ii) determine Pr(make(s e ) > )
K-implausible given ; is, backtrack, since confident
exists solution extending partial solution se improves current best solution.
K chosen sufficiently large, confident miss good solution. 6
refer algorithm B&B-N performs B ranch-and-B ound simulation
N ode.
5.2.2 B&B-DQ-L: Approximately Complete Iterative Tree Search
internal node, e, tree, previous algorithm used Monte Carlo simulation
(but without strong propagation within trial) find lower bound probabilistic
makespans solutions extending partial solution se . alternative idea generating
6. large number tests, need much higher confidence usual
confidence interval; fortunately, confidence associated K (based normal approximation
2
1
binomial, approximation tail normal distribution) approximately 1 K 1 2 e 2 K ,
tends 1 extremely fast K increases.

204

fiProactive Algorithms JSP

B&B-DQ-L():
Returns solution lowest probabilistic makespan
1
2
3
4
5
6

7
8

(s , ) findFirstB&BSimLeaves(, 0)
q qinit
q 0 timed-out
(s, D) findOptB&BSimLeaves(D , q)
6= N IL
s;
end
q q qdec
end
return
Algorithm 1: B&B-DQ-L: Approximately Complete Iterative Tree Search

lower bound use approach Section 4.2: find minimum makespan,
solutions extending se , associated deterministic problem based q value
-sufficient. minimum makespan (see Proposition 2) lower bound
probabilistic makespan. Standard constraint propagation deterministic durations
enables lower bound computed much faster simulation previous
algorithm. leaf node, simulation used B&B-N find estimate
probabilistic makespan solution.
basic idea requires selection q value. However, rather parameterize
algorithm (as others below), choose perform repeated tree
searches descending q value.
algorithm finds initial solution (line 1 Algorithm 1) therefore initial
upper bound, , probabilistic makespan q = 0. Subsequently, starting
high q value (one result deterministic lower bound), perform
tree search. leaf, e, reached, simulation used find D(se ).
high q value, likely deterministic makespan makeq (se ) much greater
D(se ). Since enforce constraint makeq (se ) D(se ), finding D(se )
simulation causes search return interior node, i, high tree
makeq (Si ) D(se ) Si represents set solutions subtree node i,
makeq (Si ) deterministic lower bound makespan solutions. high
q values, commonly observed experiments nodes
meet criterion and, therefore, search able quickly exhaust search
space. happens, reduce q value small amount, qdec (e.g., 0.05),
restart tree search. Eventually, often quickly, reach q value
exists full solution, se , makeq (se ) D(se ). solution stored
current best set = D(se ). B&B-N, used upper bound
subsequent search.
Algorithm 1 presents pseudocode basic algorithm. make use two functions
defined using pseudocode:
findFirstB&BSimLeaves(c, q): creates JSP activity durations defined based
q value passed conducts branch-and-bound search Monte Carlo
205

fiBeck & Wilson

simulation used leaf node standard constraint propagation used
interior nodes. first solution found whose probabilistic makespan less
c returned value probabilistic makespan. c set
high line 1, backtracking needed find solution therefore one
leaf node visited one simulation performed.
findOptB&BSimLeaves(c, q): findFirstB&BSimLeaves(c, q) except
solution lowest probabilistic makespan returned rather first one found.
solution found, NIL value returned. Unless q value low enough
deterministic makespan lower bound probabilistic makespan,
function necessarily return globally optimal solution.
find starting solution q = 0 serve initial upper bound optimal
probabilistic makespan. practice, B&B-DQ-L run limit CPU time.
q = 0 reached within time limit, algorithm approximately complete.
noted above, possible, especially high q value, solution, se ,
makeq (se ) much larger D(se ), therefore search backtrack deepest
interior node makeq (Si ) D(se ). fact, assignment D(se ) value
global cut upper bound probabilistic makespan. technical reasons
beyond scope paper, standard constraint-based tree search implementations
automatically handle global cuts. therefore modified standard behavior
repeatedly post upper bound constraint makeq (Si ) causing series backtracks
correct interior node.
refer algorithm B&B-DQ-L series B ranch-and-B ound
searches Descending q values simulation used Leaves tree.
B&B-DQ-L example novel constraint-based search technique might
useful wider context. problem cost function expensive evaluate
inexpensive, parameterizable lower bound calculation, search based overconstraining problem (i.e., choosing parameter value lead lower
bound) iteratively relaxing bounding function, may worth investigating.
discuss approach Section 7.
5.2.3 B&B-TBS: Heuristic Tree Search Algorithm
Previous results algorithm similar B&B-N (Beck & Wilson, 2004) indicated
simulation responsible large percentage (e.g., 95%) run-time.
reduce number times require simulation simulating solutions
good deterministic makespan. deterministic filtering search central idea
rest algorithms investigated paper.
simple method filtering solutions first spend fixed amount CPU time
find solution, s0 , low deterministic makespan, makeq (s0 ), using fixed q value
standard constructive tree search. Then, search restarted using q value
whenever solution, si , found makeq (si ) makeq (s0 ), simulation run
evaluate D(si ), estimate probabilistic makespan, (si ). probabilistic
makespan found better lowest probabilistic makespan far, solution
stored. Search continued entire tree explored maximum allowed
CPU time expired. Algorithm 2 contains pseudocode.
206

fiProactive Algorithms JSP

B&B-TBS(q):
Returns solution lowest probabilistic makespan found
1
2
3
4
5
6
7

8

(s , Dinitial ) findOptB&B(, q, tinitial )

solutions exist timed-out
(s, D) findNextB&B(Dinitial + 1, q, time-remaining)
D0 simulate(s)
D0 <
s; D0
end
end
return
Algorithm 2: B&B-TBS: Heuristic Tree Search Algorithm
Algorithm 1, make use number functions defined pseudocode:
findOptB&B(c, q, t): creates JSP activity durations defined based q
value passed conducts deterministic branch-and-bound search CPU
seconds using c upper bound deterministic makespan. search
tree exhausted time-limit reached, best deterministic solution found
(i.e., one minimum makespan), together deterministic makespan
returned. Monte Carlo simulation done.
findNextB&B(c, q, t): function produces sequence solutions (one solution
time called) whose deterministic makespan less c. problem
defined using q value CPU time limit. solutions produced
leaves B&B search tree order encountered algorithm. Note
Algorithm 2, c value change. Given enough CPU time, algorithm
evaluate probabilistic makespan solutions whose deterministic makespan
less equal Dinitial .
simulate(s): standard Monte Carlo simulation run solution D(s),
estimate probabilistic makespan, (s), returned.

algorithm complete, even choice q value results deterministic
makespans lower bounds probabilistic makespan.
guarantee optimal probabilistic solution deterministic makespan less
Dinitial therefore, even infinite CPU time, may evaluated.
algorithm called B&B-TBS B ranch-and-B ound-T imed B etter olution:
fixed CPU time spent find good deterministic solution, deterministic
solution found good better initial solution simulated.
5.2.4 B&B-I-BS: Iterative Heuristic Tree Search Algorithm
extreme filtering algorithm first finds optimal deterministic solution uses
deterministic makespan filter choosing solutions simulate. Using fixed
207

fiBeck & Wilson

B&B-I-BS(q):
Returns solution smallest probabilistic makespan found
1
2
3
4
5
6
7
8
9

10
11

(s , Dinitial ) findOptB&B(, q, t0 1)
simulate(s )
i0
timed-out
search complete
(s, makeq ) findNextB&B(Dinitial (1 + i/100) + 1, q, time-remaining)
simulate(s)
<
s;
end
end
ii+1
end
return
Algorithm 3: B&B-I-BS: Iterative Heuristic Tree Search Algorithm

q value, optimal solution found simulated. CPU time remaining,
search series iterations starting using optimal deterministic makespan
bound. solutions deterministic makespan good (or, general, better
than) current bound found simulated. subsequent iterations, bound
deterministic makespan increased, resulting larger set solutions
simulated. solution lowest estimated probabilistic makespan returned.
larger problems, optimal deterministic makespan may found within CPU
limit. case, best deterministic solution found simulated returned
(i.e., one simulation done).
formally, finding optimal deterministic solution makespan, make q ,
series iterations beginning = 0 executed. iteration, bound
deterministic makespans set makeq (1+i/100). solutions, se , whose deterministic
makespans, makeq (se ) makeq (1 + i/100), simulated one lowest
probabilistic makespan returned. Algorithm 3 presents pseudocode depends
functions defined above.
algorithm complete. large enough cost bound greater
deterministic makespan activity permutations, simulated.
However, may grow unreasonably large therefore treat algorithm as,
practically, incomplete.
refer algorithm B&B-I-BS B ranch-and-B ound-I terative-B est olution.
5.2.5 Heuristic Constraint Propagation Details
algorithms described use texture-based heuristics decide pair activities sequence sequence try first. heuristic builds resource profiles
combine probabilistic estimates contention activity resource
time-point. maximum point resource profiles selected activity
208

fiProactive Algorithms JSP

pair contends resource selected time-point heuristically chosen.
sequence chosen one maximizes remaining slack. intuition
pair activities contending highly contended-for resource time-point
critical pair activities sequenced early search. Otherwise, via
constraint propagation decisions, time windows activities may
pruned point neither sequence possible. texture-based heuristics
complexity search node O(mn2 ) number resources n
number activities resource.
detailed description analysis texture-based heuristic see work
Beck Fox (2000) Beck (1999).
constraint propagation used (i.e., algorithms except B&B-N),
use strong constraint propagation techniques constraint-based scheduling: temporal
propagation, timetables (Le Pape, Couronne, Vergamini, & Gosselin, 1994), edge-finder
(Nuijten, 1994), balance constraint (Laborie, 2003).
5.3 Local Search Algorithms
reason deterministic filtering search algorithm needs based
branch-and-bound. Indeed, given approach finding simulating solutions
low deterministic makespans, algorithms based local search may perform better
constructive search algorithms.
section, present two deterministic filtering algorithms based tabu search. 7
define algorithm discuss details tabu search procedure itself.
5.3.1 Tabu-TBS: Tabu Search Analog B&B-TBS
central idea behind using tabu search deterministic filtering search generate
sequence promising deterministic solutions simulated. seems reasonable
create analog B&B-TBS using tabu search. fixed q fixed amount
tinitial CPU time, beginning run, solution lowest possible deterministic makespan, Dinitial , sought. Search restarted whenever solution, s,
found deterministic makespan makeq (s) Dinitial , Monte Carlo simulation
used approximate probabilistic makespan. solution lowest estimated
probabilistic makespan returned.
Algorithm 4 presents pseudocode simple approach. use following
functions (pseudo-code given):
findBestTabu(c, q, t): function analogous findOptB&B(c, q, t). Tabu search
run CPU seconds solution lowest deterministic makespan
(based q value) less c returned.
findNextTabu(c, q, t): function analogous findNextB&B(c, q, t). sequence
solutions (one solution time called) whose deterministic makespan less
7. Early experiments explored even simpler way using tabu search solve probabilistic JSP
incorporating simulation neighborhood evaluation. Given search state, move operator (see
Section 5.3.3 details) defines set neighboring states. neighbor, run Monte
Carlo simulation choose neighbor lowest probabilistic makespan. technique,
surprisingly, proved impractical considerable CPU time spent determine single move.

209

fiBeck & Wilson

Tabu-TBS(q):
Returns solution lowest probabilistic makespan found
1
2
3
4
5
6
7

8

(s , Dinitial ) findBestTabu(, q, tinitial )

termination criteria unmet
(s, D) findNextTabu(Dinitial + 1, q, time-remaining)
D0 simulate(s)
D0 <
s; D0
end
end
return
Algorithm 4: Tabu-TBS: Local Search Filtering Algorithm
c returned. problem defined using q value CPU time
limit. solution produced next solution found tabu search meets
makespan requirement.

call algorithm Tabu-TBS Tabu-T imed B etter olution.
B&B-TBS, c value updated iteration. initial search (line
1) used find good deterministic solution simulation done solutions whose
deterministic makespan better solution found initial search.
5.3.2 Tabu-I-BS: Iterative Tabu Search Algorithm
core tabu search implementation fixed durations necessarily use entire
CPU time (see Section 5.3.3) and, fact, especially small instances often terminates
quickly. therefore create iterative tabu-based solver probabilistic
JSP similar B&B-I-BS.
first phase, using time limit one second less overall time limit,
tabu search used find good deterministic solution, based fixed q value.
solution simulated. tabu search may terminate time
limit expired, remaining time spent generating solutions deterministic
makespan within fixed percentage initial solutions deterministic makespan.
B&B-I-BS, iterations run increasing value starting = 0.
iteration, simulate solutions found tabu search whose deterministic makespan
(1 + i/100)Dinitial , Dinitial value deterministic makespan found
phase 1. solution lowest probabilistic makespan returned.8
algorithm termed Tabu-I-BS Tabu-I terative-B est earch. pseudocode
algorithm presented Algorithm 5.
5.3.3 Tabu Search Details
tabu search used find solutions problems deterministic durations TSAB
algorithm due Nowicki Smutnicki (1996). restricted move operator (termed
8. Tabuf algorithm proposed Beck Wilson (2004) corresponds first iteration Tabu-I-BS.

210

fiProactive Algorithms JSP

Tabu-I-BS(q):
Returns solution smallest probabilistic makespan found
1
2
3
4
5
6
7
8
9

10
11

(s , Dinitial ) findBestTabu(, q, t0 1)
simulate(s )
i0
timed-out
termination criteria unmet
(s, makeq ) findNextTabu(Dinitial (1 + i/100) + 1, q, time-remaining)
simulate(s)
<
s;
end
end
ii+1
end
return
Algorithm 5: Tabu-I-BS: Iterative Tabu-based Filtering Algorithm

N 5 Blazewicz, Domschke Pesch, 1996) produces neighborhood swapping
subset pairs adjacent activities resource given solution. standard
tabu list ten moves done immediate past kept escape local minima.
use standard aspiration criteria accepting move tabu list resulting
solution better solution found far.
One important additions basic tabu search mechanism TSAB
maintenance elite pool solutions. small set (i.e., 8) best solutions encountered far updated whenever new best solution
encountered. standard tabu search stagnates (i.e., made large number
moves without finding new best solution), search returns one elite solutions
continues search it. solution removed set elite solutions. Search
terminated either maximum CPU time reached elite solution pool
empty.
5.4 Summary Algorithms
Table 1 summarizes algorithms introduced above.

6. Empirical Investigations
empirical investigations address two main issues: scaling behavior
approximately complete heuristic methods problem size uncertainty increase
whether using deterministic methods, represent uncertainty duration
extensions, useful approach. respect scaling, two interesting subquestions: first, approximately complete techniques compare
and, second, cross-over point terms problem size heuristic
techniques out-perform approximately complete techniques.
211

fiBeck & Wilson

Deterministic
Algorithm
B&B

Complete
Yes

B&B-DQ-L

B&B

Yes

B&B-TBS

B&B



B&B-I-BS

B&B

Yes

Tabu-TBS

Tabu



Tabu-I-BS

Tabu



Name
B&B-N

Description
B&B simulation node find upper
lower bounds
B&B deterministic durations used lower
bounds simulation done leaf node.
durations decrease iteration.
Find good deterministic solution, s,
restart search, simulating whenever
deterministic solution good found.
Find optimal deterministic solution, s.
Restart search simulating whenever
deterministic solution within i% found
Repeat increasing i.
Find good deterministic solution, s,
restart search simulating whenever
deterministic solution good found.
Find good deterministic solution, s,
possible. Restart search simulating whenever
deterministic solution within i%
found. Repeat increasing i.

Table 1: summary algorithms introduced find probabilistic makespan
instance job shop scheduling problem probabilistic durations.

heuristic techniques necessary assign fixed durations activity.
standard approach use mean duration. However, cases
representation uncertainty surrounding duration, take
account want high probability (1 ) execution. general approach
heuristically use formulation lower bound -minimum makespans presented
Section 4.2: duration activity Ai defined + qi , q fixed
non-negative value, (respectively) mean standard deviation
duration Ai . Since longer limited producing lower bound,
flexibility selecting q. Intuitively, want q-value leads situation
good deterministic solutions also low values probabilistic makespan (s).
experiment number q-values based analysis Section 4.2 shown Table
2. cases, set B = 1.645 (see Section 4.2) corresponding = 0.05. Value q 3
generated problem instance Monte Carlo simulation: simulating 100000 paths
n activities.
6.1 Experimental Details
empirical investigations examine four sets probabilistic JSPs size {4 4, 6 6, 10
10, 20 20} (where 10 10 problem 10 jobs consisting 10 activities),
set, three uncertainty levels uj {0.1, 0.5, 1} considered. deterministic problem
generated using existing generator (Watson, Barbulescu, Whitley, & Howe, 2002)
212

fiProactive Algorithms JSP

q0
0

q1
1.645

2n

q2
q1 +q3
2

1.645

n

q3
MeanAi i2
MeanAi

q

Table 2: q-values used experiments. choices q1 q3 motivated
analysis Section 4.2.1.

integer durations drawn uniformly interval [1, 99]. Three probabilistic instances
different levels uncertainty produced setting mean duration
deterministic duration activity Ai , randomly drawing (using uniform
distribution) standard deviation duration activity Ai interval [0,
uj ]. distribution duration approximately normal. problem size,
generate 10 deterministic problems transformed 30 probabilistic instances.
problem sizes chosen elicit range behavior, small problems,
approximately complete algorithms expected able find prove
(approximate) optimality, larger problems, even underlying deterministic
problems could solved optimality within time limit used. chose use
existing generator rather than, example, modifying existing benchmark problems,
allowed us full control problem structure. three levels
uncertainty simply chosen low, medium, high uncertainty conditions
compare algorithms.
Given stochastic nature simulation tabu search algorithm, algorithm run 10 times problem instance different random seeds. run
time limit 600 CPU seconds. Monte Carlo simulation uses N = 1000 independent
trials.
hardware used experiments 1.8GHz Pentium 4 512 MB main
memory running Linux RedHat 9. algorithms implemented using ILOG Scheduler
5.3.
Recall B&B-DQ-L algorithm, employ descending sequence q values.
problems except 20 20 problems, initial q value, qinit , set 1.25,
decrement, qdec , 0.05. 20 20 problems, qinit value 0.9 used.
change made observing qinit = 1.25, initial tree search 2020
problems would often fail find solution prove none existed within reasonable
amount time. believe due problem instances size
solution q = 1.25 satisfied constraint simulated makespan must
less equal deterministic approximation (i.e., makeq (se ) D(se )see
Section 5.2.2), yet search space sufficiently large require significant
amount search prove it. Reducing qinit 0.9 results initial solution found
quickly instances.
primary evaluation criterion mean normalized probabilistic makespan (MNPM )
algorithm achieved relevant subset problem instances (we display
data different subsets examine algorithm performance different problem sizes
uncertainty levels). mean normalized probabilistic makespan defined follows:
213

fiBeck & Wilson

MNPM (a, L) =

1 X D(a, l)
|L|
Dlb (l)

(1)



L set problem instances, D(a, l) mean estimate probabilistic
makespan found algorithm l 10 runs, Dlb (l) lower bound probabilistic makespan l. problems except 20 20, Dlb found solving
deterministic problems using q1 , simple, plausibly -sufficient q-value (see Section
4.2 Table 2). instance solved using constraint-based tree search incorporating
texture-based heuristics global constraint propagation used above. maximum
time 600 CPU seconds given. (deterministic) problems smaller 20 20
easily solved optimality. However, none 2020 problems solved optimality.
this, Dlb values chosen represent best solutions found,
true lower bounds.
6.2 Results Analysis
Table 3 presents overview results experiments problem size
uncertainty level. results q = q2 shown heuristic algorithm.
large performance difference among non-zero q-values (q 1 , q2 q3 ). return
issue Section 6.2.2. cell Table 3 mean value 10 independent
runs 10 problems. Aside 4 4 instances, runs reached 600 CPU
second time limit. Therefore, report CPU times.

Problem
Size
44
66
10 10
20 20

Unc.
Level
0.1
0.5
1
0.1
0.5
1
0.1
0.5
1
0.1
0.5
1

B&B Complete
N
DQ-L
1.027* 1.023*
1.060* 1.049*
1.151*
1.129
1.034
1.021
1.113
1.073
1.226
1.170
1.185
1.028
1.241
1.115
1.346
1.234
1.256
1.142
1.326
1.233
1.482
1.388

Algorithms
B&B Heuristic
TBS
I-BS
1.026
1.026
1.064
1.059
1.154
1.149
1.022
1.022
1.083
1.077
1.178
1.174
1.024 1.024
1.101 1.101
1.215 1.215
1.077
1.071
1.177
1.181
1.334
1.338

Tabu
TBS
I-BS
1.027 1.023
1.063 1.046
1.153 1.128
1.027
1.023
1.074
1.074
1.185 1.168
1.035
1.028
1.121
1.112
1.244
1.223
1.029 1.027
1.136 1.137
1.297 1.307

Table 3: mean normalized probabilistic makespans algorithm. * indicates
set runs have, high confidence, found approximately optimal
makespans. indicates problem sets normalization done
approximate lower bounds. lowest MNPM found problem set
shown bold.

214

fiProactive Algorithms JSP

impression results gained looking bold entries indicate
lowest mean normalized probabilistic makespan (MNPM) found problem
set. B&B-N B&B-DQ-L find approximately optimal solutions smallest
problem set, B&B-DQ-L Tabu-I-BS find lowest probabilistic makespans
4 4 6 6 problems. Performance complete B&B techniques,
especially B&B-N, degrade 10 10 problems heuristic B&B algorithms
find lowest probabilistic makespans. Finally, largest problems, tabu-based
techniques clearly superior.
One anomaly overall results Table 3 seen B&B-N B&B-DQ-L
entries 4 4 problems. two three uncertainty levels algorithms terminate limit CPU time resulting approximately optimal solutions. However,
mean normalized probabilistic makespans lower B&B-DQ-L algorithm.
conjecture artifact B&B-DQ-L algorithm biases simulation
toward lower probabilistic makespan values. B&B-N, particular solution, s,
simulated find D(s). B&B-DQ-L, solution may simulated multiple
times leading bias. illustration, assume B&B-DQ-L finds approximately
optimal solution searching tree corresponding q = q 0 > 0. subsequent
iteration q = q 00 < q 0 , provided deterministic makespan less previously identified probabilistic makespan (i.e., makeq (s ) < D(s )), solution found
simulated again. actual identity current best solution used
determine solutions simulate. subsequent simulation, lower value
D(s ) generated, replace previous lowest probabilistic makespan value.
leads situation may re-simulate solution multiple times, keeping
lowest probabilistic makespan found simulations. Similar re-simulation
possible Tabu-I-BS algorithm.
test statistical significance results Table 3, ran series randomized
paired-t tests (Cohen, 1995) p 0.005. results statistical tests
displayed Table 4 different problem sizes. different uncertainty levels
collapsed that, example, 4 4 statistics based 4 4
instances. informal impression discussed reflected tests B&BDQ-L Tabu-I-BS dominating two smallest problem sizes, branch-and-bound
heuristic approaches performing best 1010 problems, tabu-based techniques
delivering best results 20 20 problems.
Overview. primary interpretation performance algorithms
experiments follows. smaller problems (44 66), complete techniques
able cover entire search space least significant portion it. Though
case B&B-DQ-L, solutions chosen simulation heuristically driven
deterministic makespan values, lower bound results Section 4.2 ensure
good solutions found provided iterations small q values run within
CPU time limit. 10 10 problems, complete techniques able
simulate sufficient variety solutions as, especially B&B-N, heuristic guidance
poor. Note, however, B&B-DQ-L competitive with, and, many problems
sets, better tabu-based algorithms 10 10 problems. believe
10 10 results stem ability B&B heuristic algorithms quickly find
215

fiBeck & Wilson

Problem
Size
44
66
10 10
20 20

Statistical Significance
(p 0.005)
{B&B-DQ-L, Tabu-I-BS} < {B&B-TBS, B&B-I-BS, Tabu-TBS, B&B-N}
{B&B-DQ-L, Tabu-I-BS} < {B&B-I-BS} < {B&B-TBS} < {Tabu-TBS} < {B&B-N}
{B&B-TBS, B&B-I-BS} < {Tabu-I-BS, B&B-DQ-L, Tabu-TBS} < {B&B-N}
{Tabu-TBS, Tabu-I-BS} < {B&B-TBS, B&B-I-BS} < {B&B-DQ-L} < {B&B-N}

Table 4: statistically significant relationships among algorithms results
shown Table 3. Algorithms within set show significant difference.
< relation indicates algorithms left-hand set significantly
lower MNPM algorithms right-hand set. set indicated
represents complicated relationship amongst algorithms: Tabu-I-BS <
Tabu-TBS pairs set show significant performance differences.

optimal deterministic solution systematically simulate solutions
deterministic makespans close optimal. contrast, tabu-based algorithms
systematically enumerate solutions. Finally, largest problems,
hypothesize tabu search techniques result best performance able
find better deterministic solutions simulate.
Problem Size. size problems increase, see not-unexpected decrease
quality probabilistic makespans found. simple reasonable explanation
trend less search space explored within given CPU time
larger problems. likely factors contribute trend (e.g.,
quality lower bound may well systematically decrease problem size increases).
Uncertainty Level. normalized makespan values also increase within problem size
uncertainty level rises. results calculated normalization
lower bound, possible observed decrease solution quality actually due
decrease quality lower bound rather reduction quality
solutions found algorithms uncertainty increases. test idea, Table 5
normalized 4 4 results using optimal probabilistic makespans found B&B-N
rather deterministic lower bound. table shows algorithms apart
B&B-DQ-L Tabu-I-BS, trend increasing mean normalized probabilistic
makespan still evident. algorithms, least, putative decreasing quality
lower bound cannot entire explanation trend worse performance
results higher levels uncertainty. Section 6.2.2, revisit question provide
evidence could explain algorithms perform worse uncertainty increased.
results also lend credibility conjecture observed super-optimal
performance B&B-DQ-L Tabu-I-BS small problems due repeatedly
simulating solution. low levels uncertainty, repeated simulations truly
best solution vary greatly, resulting MNPM value 1. higher levels
uncertainty, distribution simulated makespans wider and, therefore, repeated
simulation solution biases results toward smaller probabilistic makespan values.
observe results B&B-DQ-L Tabu-I-BS Table 5.
216

fiProactive Algorithms JSP

Unc.
Level
0.1
0.5
1

B&B Complete
N
DQ-L
1.004
1.000
1.008
0.998
1.015
0.996

Algorithms
B&B Heuristic
TBS
I-BS
1.003
1.002
1.012
1.008
1.018
1.013

Tabu
TBS
I-BS
1.003 0.999
1.011 0.995
1.017 0.996

Table 5: mean normalized probabilistic makespans algorithm 4 4
problem set normalized optimal probabilistic makespans found B&B-N.

balance section, turn detailed analysis algorithms.
6.2.1 Analysis: B&B Complete Algorithms
performance B&B-N poor unable exhaustively search branchand-bound tree. high computational cost running simulation every node
relatively weak lower bound partial solutions provide9 conspire result technique
scale beyond small problems.
Problem
Size
44
66
10 10
20 20

Uncertainty
0.1
0.5
0
0
0
0.5
0.95 0.85
0.9
0.9

Level
1
0
0.75
0.9
0.9

Table 6: lowest q value used problem size uncertainty level B&BDQ-L. problems except 20 20, initial q value 1.25. 20 20
problems, initial q value 0.9

B&B-DQ-L able perform somewhat better B&B-N larger problems even
able exhaustively search tree q = 0. Table 6 shows
minimum q values attained problem size uncertainty level. deterministic
durations defined q value serve guide prune search iteration and,
therefore, heuristic algorithms (see below), search heuristically guided
extent solutions low deterministic makespans also low probabilistic
makespans. However, characteristics solutions found search unclear.
Recall B&B-DQ-L starts high q value that, combination constraint
deterministic makespan must less equal best simulated probabilis9. One idea improving lower bound investigate incorporate resourcebased propagators (e.g., edge-finding) evaluation partial solution. single trial
internal node, deterministic makespan found sampling distributions finding
longest path temporal network. sampling, however, possible apply
standard propagation techniques might insert additional edges precedence graph
thereby increase makespan, improving lower bound.

217

fiBeck & Wilson

tic makespan found far, significantly prunes search space. Ideally, would like
search high q find solutions good probabilistic makespans
wish find good solutions quickly simulated probabilistic makespan
values used prune subsequent search lower q values. Therefore, effort
better understand B&B-DQ-L search, examine characteristics initial
solutions finds.
idea quality solutions produced high q values seen
comparing probabilistic makespan found high q (the first solution found)
best solution found run. Table 7 presents comparison form f ,
mean normalized makespans initial solutions found B&B-N B&B-DQL. data indicate first solution found B&B-DQ-L much better
found B&B-N. B&B-N searches initial solution, upper bound
deterministic makespan constrain problem: solution therefore
easy find (i.e., backtracking) little constraint propagation
heuristic information available guide search solution small makespan.
contrast, B&B-DQ-L searches initial solution, high q value means
searching highly constrained search space deterministic makespan must
less probabilistic makespan. Therefore, tight upper bound
deterministic makespan (relative durations incorporate q values).
many cases, initial iterations fail find feasible solutions, quickly.
Eventually, q value low enough allow feasible solution, however search
solution strongly guided propagation problem constraints. summary,
initial search B&B-N guidance constraint propagation toward good
solution B&-DQ-L guided constraint propagation overly constrained
problem. Table 7 shows that, experiments, guidance tends result better
initial solutions. believe observation may useful generally constraint
solving (see Section 7).
provide fuller indication performance differences, Table 7 also presents
improvement first solution achieved: difference first solution
last solution (Dl ) found algorithm (Dl value reported Table 3).
larger problem sets, improvement made first solution B&B-DQ-L
greater. smaller problem sets, improvement B&B-N greater
B&B-DQ-L, however, suspect ceiling effect reduces amount B&B-DQ-L
improve (i.e., initial solutions already quite close optimal).
6.2.2 Analysis: Heuristic Algorithms
turn performance heuristic algorithms. first examine hypothesis
performance dependent two factors: ability algorithms find
solutions low deterministic makespans correlation good deterministic
probabilistic makespans. turn analysis effect differing q
values heuristic algorithm performance.
Finding Good Deterministic Makespans. argued performance
heuristic techniques (and B&B-DQ-L) dependent upon ability find solutions
good deterministic makespans. provide evidence argument, looked
218

fiProactive Algorithms JSP

Problem
Size
44
66
10 10
20 20

Unc.
Level
0.1
0.5
1
0.1
0.5
1
0.1
0.5
1
0.1
0.5
1

B&B-N
Df
Df l
1.089
0.062
1.119
0.059
1.227
0.076
1.106
0.072
1.163
0.050
1.301
0.075
1.191
0.006
1.258
0.017
1.369
0.005
1.259
0.003
1.332
0.004
1.494
0.008

B&B-DQ-L
Df
Df l
1.028
0.005
1.078
0.029
1.165
0.036
1.067
0.046
1.108
0.035
1.221
0.051
1.069
0.045
1.151
0.050
1.269
0.054
1.168
0.026
1.242
0.009
1.404
0.016

Table 7: mean normalized makespan first solutions found algorithm
(Df ) difference mean normalized makespans first
last solutions (Df Dl ).

quality best deterministic solutions found B&B-I-BS Tabu-I-BS.
hypothesize better performing algorithm also found better deterministic
solutions worse performer.
Table 8 presents results algorithm two largest problem sets. 10 mean
normalized deterministic makespan (MNDM ) calculated follows:
MNDM (a, L) =

makeq (a, l)
1 X
|L|
makeq,min (l, B&B BS)

(2)



L set problem instances, makeq (a, l) mean deterministic makespan found
algorithm l 10 runs, makeq,min (l, B&B BS) lowest deterministic
makespan found B&B-I-BS algorithm runs problem l. MNDM, therefore,
provides relative measure quality average deterministic makespans
two algorithms: higher value, worse average makespan found relative
B&B-I-BS.
Table 8 consistent hypothesis. 10 10 problems, B&B-I-BS
outperforms Tabu-I-BS, former able find solutions lower mean deterministic
makespan. 20 20 problems results reversed Tabu-I-BS finding
better mean deterministic makespans better probabilistic makespans.
result lends support original motivation deterministic filtering algorithms: performance algorithms terms probabilistic solution quality
positively related quality deterministic solutions able find.
next section addresses question performance relationship observed.
10. show 10 10 20 20 problems sets influenced conjectured
repeated simulation behavior Tabu-I-BS.

219

fiBeck & Wilson

Problem
Size
10 10
20 20

Uncertainty
Level
0.1
0.5
1
0.1
0.5
1

MNDM
B&B-I-BS Tabu-I-BS
1.000
1.002
1.000
1.004
1.000
1.004
1.045
1.002
1.041
0.998
1.037
1.002

Table 8: mean normalized deterministic makespan (MNDM) B&B-I-BS TabuI-BS.

Correlation Deterministic Probabilistic Makespan. ability algorithms find good deterministic makespans would irrelevant
ability find good probabilistic makespans without correlation two.
reasonable expect level uncertainty problem instance impact
correlation: low uncertainty variations duration small, meaning
expect probabilistic makespan relatively close deterministic makespan.
uncertainty level high, distribution probabilistic makespans single
solution wider, resulting less correlation. hypothesize impact
uncertainty level contributes observed performance degradation (see Tables 3 5)
heuristic techniques higher uncertainty levels problem size held constant.
examine hypothesis generated 100 new 10 10 deterministic JSP problem
instances generator parameters used above. standard deviations
duration activity 100 instances generated independently
five uncertainty levels uj {0.1, 0.5, 1, 2, 3} resulting total 500 problem
instances (100 uncertainty level). instance four q
values (as Table 2), randomly generated 100 deterministic solutions
simulated. Using R statistical package (R Development Core Team, 2004),
measured correlation coefficient problem set. cell Table 9 result
10000 pairs data points: deterministic probabilistic makespans 100 random
deterministic solutions 100 problem instances.
Uncertainty Level
0.1
0.5
1
2
3

q0
0.9990
0.9767
0.9176
0.8240
0.7381

q1
0.9996
0.9912
0.9740
0.9451
0.9362

q2
0.9996
0.9917
0.9751
0.9507
0.9418

q3
0.9995
0.9909
0.9736
0.9517
0.9423

Table 9: correlation coefficient (r) comparing pairs deterministic probabilistic makespans set 10 10 probabilistic JSPs. cell represents
correlation coefficient 10000 deterministic, probabilistic pairs.

220

fiProactive Algorithms JSP

Table 9 supports explanation performance heuristic techniques.
uncertainty level increases, correlation deterministic makespan
corresponding probabilistic makespan lessens. strength correlation somewhat
surprising: even highest uncertainty level standard deviation duration activity uniformly drawn 0 3 times mean duration,
correlation 0.94 q2 q3 . positive indication heuristic
algorithms suggests may scale well higher uncertainty levels provided
reasonable q value used. examine impact q values original experiments implications deterministic/probabilistic makespan correlation
next section.
emphasized results based correlations deterministic probabilistic makespans randomly generated solutions. addressed
correlations might change high-quality solutions, might considered
appropriate population sample. One technical difficulty
design experiment examine this, ensure sufficiently randomized sample
population good solutions; also, result could depend strongly (rather
arbitrary) particular choice quality cutoff solutions.
Effect q Values. heuristic algorithms requires fixed q value.11
experimented four different values (see Table 2). Table 10 displays significant pairwise differences among q values heuristic measured randomized
paired-t tests (Cohen, 1995) p 0.005. observed, almost
significant differences low levels uncertainty (0.1 0.5) smallest problem
set. higher levels uncertainty larger problems, using q0 never better
using one higher q values many cases, q0 results worst mean makespan.
Among q-values, majority problem sets algorithms
significant differences. given algorithm, never case lower q value leads
significantly better results higher q value.
correlation results Table 9 provide explanation differences.
10 10 problems, performance q0 algorithms competitive
large difference correlations deterministic probabilistic solutions (i.e.,
uncertainty levels 0.1 0.5). uncertainty level 1, significant
reduction correlation coefficient q0 corresponding reduction mean
normalized probabilistic makespans found algorithms using q0 .
6.3 Summary
results experiments summarized follows:
principled use simulation (B&B-N) useful small problems.
simulation time major component run-time resulting little
exploration search space.
Algorithm B&B-DQ-L, based idea iteratively reducing parameter determines validity lower bound, results equal performance small prob11. addressing behavior B&B-DQ-L, q descends run algorithm.
examining algorithms fixed q values.

221

fiBeck & Wilson

Problem
Size
44

66

10 10

20 20

Unc.
Level
0.1
0.5
1

0.1
0.5
1

0.1
0.5
1

0.1
0.5
1


B&B
TBS
I-BS
q2 < {q1 , q3 } < q0
q2 < {q0 , q1 }
{q1 , q2 , q3 } < q0
{q1 , q2 , q3 } < q0
{q1 , q2 , q3 } < q0
{q1 , q2 , q3 } < q0
{q1 , q2 } < q0
{q2 , q3 } < q0
q2 < q 1
q2 < q1 < q0
{q2 , q3 } < q0
q3 < q 0

Tabu
TBS
I-BS
q 2 < q1
{q1 , q2 , q3 } < q0
{q1 , q2 , q3 } < q0
q1 < q 0
{q1 , q3 } < q0
{q2 , q3 } < q0
q1 < q 0
{q1 , q2 , q3 } < q0
q 2 < q0
{q1 , q2 , q3 } < q0 {q1 , q2 , q3 } < q0
{q1 , q2 , q3 } < q0

{q1 , q2 , q3 } < q0

Table 10: results pair-wise statistical tests algorithm problem set.
notation < b indicates algorithm using q = achieved significantly
better solution (i.e., lower probabilistic makespan) used q = b. -
indicates significant differences. statistical tests randomized paired-t
tests (Cohen, 1995) p 0.005.

lems much better performance larger problems compared B&B-N.
work needed understand behavior algorithm, however preliminary evidence indicates able find good solutions quickly current
application domain.
series heuristic algorithms proposed based using deterministic makespan
filter solutions would simulated. demonstrated performance algorithms depends ability find good deterministic
makespans correlation quality deterministic probabilistic solutions. shown even problems quite high uncertainty
level, deterministic problems constructed lead strong deterministic/probabilistic makespan correlation.
Central success heuristic algorithms use q value governed
extent duration uncertainty represented durations activities
deterministic problems. shown incorporation uncertainty
data leads stronger correlation deterministic probabilistic makespans
corresponding ability find better probabilistic makespans.
222

fiProactive Algorithms JSP

7. Extensions Future Work
section, look three kinds extensions work. First, show
theoretical framework fact applies far general probabilistic scheduling problems
job shop scheduling. Section 7.2, discuss ways algorithms
probabilistic JSP presented paper might improved. Finally, discuss
possibility developing central idea B&B-DQ-L algorithm solving approach
general constraint optimization problems.
7.1 Generalization Scheduling Problems
results paper derived important case job shop scheduling
problems. fact, valid much broader class scheduling problems, including
resource-constrained project scheduling problems common form (e.g., probabilistic
version deterministic problems studied work Laborie, 2005). section,
describe extend framework approaches.
approach relies fact job shop scheduling problem, one focus
orderings activities, rather directly assignments start times activities;
specifically, definition minimum makespan based orderings equivalent
one based start time assignments; equivalence holds much generally.
First, 7.1.1, give basic definitions properties immediate extensions defined Section 2. Then, 7.1.2, characterize class scheduling
problems properties require, use logical expression represent
constraints problem. 7.1.3 give key result relating schedule-based
minimum makespan ordering-based minimum makespan. Section 7.1.4 discusses
extended class probabilistic scheduling problems, Section 7.1.5 considers different
optimization functions.
7.1.1 Schedules, Orderings Makespans
Section 2, given set activities, activity Ai associated positive duration di (for deterministic case). schedule (for A) defined
function set activities set time-points (which non-negative
numbers), defining activity starts. Let Z schedule. makespan make(Z)
schedule Z defined time last activity completed, i.e.,
maxAi (Z(Ai ) + di ). say Z orders Ai Aj Aj starts earlier
Ai ends, i.e., Z(Ai ) + di Z(Aj ).
essential aspect job shop problems approach one focus
orderings activities rather schedules; Section 2 use term solution
ordering satisfies constraints given JSP. Define ordering (on A)
strict partial order A, i.e., irreflexive transitive relation set activities.
Hence, ordering s, Ai A, (Ai , Ai )
/ s, (Ai , Aj ) (Aj , Ak ) s,
(Ai , Ak ) s. (Ai , Aj ) s, say orders Ai Aj ; also say
Ai predecessor Aj . path (or s-path) sequence activities
Ai precedes Aj sequence, orders Ai Aj . length len() path
(in ordering) defined sum durations activities path,
223

fiBeck & Wilson

P
i.e., Ai di . makespan, make(s), ordering defined length
longest s-path. s-path said critical s-path length equal
makespan ordering s, i.e., one longest s-paths.
schedule associated ordering. schedule Z define ordering sol(Z)
follows: sol(Z) orders activity Ai Aj Z orders Ai Aj .
Conversely, ordering one define non-delay schedule, optimal
among schedules compatible ordering, starting activity soon
predecessors finish. Let ordering. inductively define schedule Z = sched(s)
follows: Ai predecessor, start Ai time 0, i.e., Z(Ai ) = 0. Otherwise,
set Z(Ai ) = maxAj pred(Ai ) (Z(Aj ) + dj ), pred(Ai ) set predecessors Ai .
fact acyclic guarantees defines schedule. Section 2.1,
following two important properties. first states makespan ordering
equal makespan associated schedule. second states makespan
schedule better makespan associated ordering.
Proposition 5
(i) ordering s, make(sched(s)) = make(s).
(ii) schedule Z, make(sol(Z)) make(Z).
proof straight-forward. follows easily induction schedule Z
respects precedence constraints expressed ordering s, last activity
s-path end earlier Z length path; applying critical path
implies (ii) make(sol(Z)) make(Z), implies half (i): make(sched(s)) make(s).
working backwards activity finishes last sched(s), choosing immediate
predecessor stage, one generates (in reverse order) path whose length equal
make(sched(s)), hence showing make(sched(s)) make(s), proving (i).
7.1.2 Positive Precedence Expressions
define class scheduling problems, using call positive precedence expressions (PPEs) represent constraints. scheduling problems assumes
preemption (so activities cannot interrupted started) use
makespan cost function.
activities Ai Aj , expression before(i, j) interpreted constraint (on
possible schedules) activity Aj starts earlier end activity Ai .
expressions called primitive precedence expressions. positive precedence expression
defined logical formula built primitive precedence expressions, conjunctions
disjunctions. (The term positive used since involve negations.) Formally,
set E positive precedence expressions (over A) defined smallest set
(a) E contains before(i, j) Ai Aj A, (b) E,
( ) ( ) E.
Positive precedence expressions interpreted constraining schedules A.
Let E PPE let Z schedule. define Z satisfies recursively
follows:
224

fiProactive Algorithms JSP

Z satisfies primitive precedence expression before(i, j) Z orders
Aj , i.e., Z(Ai ) + di Z(Aj );
Z satisfies conjunction two constraint expressions satisfies
them;
Z satisfies disjunction two constraint expressions satisfies
least one them.
Similarly, ordering positive precedence expression recursively define
satisfies obvious way: satisfies before(i, j) orders
Aj . Ordering satisfies ( ) satisfies . Ordering satisfies
( ) satisfies either .
Positive precedence expressions powerful enough represent constraints
job shop scheduling problem, resource-constrained project scheduling problem.
JSPs Positive Precedence Expressions. Resource constraints job shop scheduling problem give rise disjunctions primitive precedence expressions: pair
activities Ai Aj require resource, expression before(i, j) before(j, i)
expresses Ai Aj overlap (one precedes other).
ordering activities job expressed terms primitive expressions: before(i, j)
Ai precedes Aj within job. Hence, constraints job shop problem
expressed positive precedence expression conjunctive normal form, i.e., conjunction
disjunctions primitive precedence expressions.
RCPSPs PPEs. constraints resource-constrained project scheduling problem
(RCPSP) (Pinedo, 2003; Brucker et al., 1999; Laborie & Ghallab, 1995; Laborie, 2005)
also expressed positive precedence expression conjunctive normal form.
RCPSP, precedence constraints activities, expressed
primitive precedence expression; let conjunction these. RCPSP,
set resources, positive capacity. Associated activity
resource r rate usage Ai (r) resource r activity Ai . following
resource constraints schedule: resource r, time-point t, sum
Ai (r) activities Ai progress (i.e., started
yet ended) must exceed capacity resource r.
Define forbidden set (or conflict set) set activities whose total usage
resource exceeds capacity resource. Let F set forbidden sets. (If
wished, could delete F set superset set F;
could also delete set H contains elements Ai Aj Ai precedes Aj
according .) resource constraints expressed equivalently as: H F,
exists time every activity H progress. holds
H F, exist two activities H overlap (since pairs
activities H overlap activities H progress latest start time
activities H), i.e., exists Ai , Aj H before(i, j). Hence, schedule satisfies
resource constraints satisfies positive precedence expression defined
225

fiBeck & Wilson


^

HF

_

before(i, j).

Ai ,Aj H
i6=j

Therefore, expression ( ) represents RCPSP, i.e., schedule satisfies constraints
RCPSP satisfies ( ).
Another class scheduling problems, represented positive
precedence expression, class based AND/OR precedence constraints (Gillies &
Liu, 1995; Mohring, Skutella, & Stork, 2004).
7.1.3 Solutions Minimum Makespan
fixed positive precedence expression A, say schedule Z valid
satisfies . say ordering solution satisfies . ordering satisfies
before(i, j), then, construction, sched(s) satisfies before(i, j). also follows immediately
schedule Z satisfies before(i, j) sol(Z) satisfies before(i, j). following
result proved easily induction number connectives .
Lemma 2 PPE A, solution, sched(s) valid schedule.
Z valid schedule, sol(Z) solution.
minimum makespan (for ) defined infimum makespan valid
schedules, i.e., infimum make(Z) valid schedules Z. minimum solution
makespan defined minimum makespan solutions, i.e., minimum
make(s) solutions s. following key result links schedulebased definition minimum makespan solution-based definition. follows
Proposition 5 Lemma 2, since solution valid schedule (i.e., sched(s))
value makespan, valid schedule Z solution (i.e.,
sol(Z)) least good value makespan.
Proposition 6 Let positive precedence expression A. minimum
makespan equal minimum solution makespan.
7.1.4 Probabilistic Scheduling Problems based PPEs
probabilistic versions scheduling problems defined way
JSPs. duration activity Ai random variable. positive precedence
expression used represent constraints.
definitions Sections 2 4 immediately extended much
general setting. results paper still hold, exactly proofs.
particular, probabilistic problem one associates corresponding deterministic
problem way; lower bound results Section 4.2 based longest
path characterization makespan; Monte Carlo approach (or least usefulness)
relies fact makespan solution equal makespan associated
schedule. Furthermore, algorithms Section 5 extend, given one method
solving corresponding deterministic problem.
226

fiProactive Algorithms JSP

ordering-based policies use (based fixing partial ordering activities,
irrespective sampled values durations) known Earliest Start policies
(Radermacher, 1985). policies studied RCPSPs (see e.g.,
Stork, 2000, however aim work minimize expected makespan, whereas
attempting minimize -makespan).
7.1.5 Different Optimization Functions
approach evaluating comparing solutions based use Monte
Carlo simulation generate sample distribution, techniques quite general.
Much work paper also generalizes immediately regular cost functions, regular means function monotonic sense increasing
end activity schedule decrease cost. regular function based
efficiently computable measurement sample distributions accommodated.
example, could easily adapt situations probability extreme solutions
important basing optimization function maximum sampled makespan. Conversely, could use measures tightness makespan distribution situations
minimizing variance measure accuracy schedule important. Furthermore, weighted combinations functions (e.g., -makespan plus measure
distribution tightness) could easily incorporated.
also modify approach account ways comparing solutions
based sample distributions. example, could perform t-tests using sample
distributions determine one solution significantly lower expected makespan.
7.2 Toward Better Algorithms Probabilistic JSPs
two directions future work algorithms presented paper. First,
B&B-N could improved make use deterministic techniques and/or incorporate probabilistic reasoning existing deterministic techniques. example, number
deterministic lower bound formulations PERT networks exist operations research literature (Ludwig, Mohring, & Stork, 2001) may used evaluate partial
solutions. Similarly, perhaps dominance rules presented Daniels Carrillo (1997)
one-machine -robustness problem generalized multiple resources. Another
approach improving B&B-N performance incorporate explicit reasoning
probability distributions standard constraint propagation techniques. Techniques
longest path calculations edge-finding make inferences based propagation
minimum maximum values temporal variables. believe many
techniques adapted reason probabilistic intervals; related work
done, example, simple temporal networks uncertainty (Morris, Muscettola, &
Vidal, 2001; Tsamardinos, 2002).
second direction future work improvement heuristic algorithms.
key advantage algorithms make use deterministic techniques
scheduling: transforming probabilistic problems deterministic problems, bring
significant set existing tools bear problem. developments approach include adaptively changing q-values search order find lead
solutions better values probabilistic makespan (D (s)). deeper understanding
227

fiBeck & Wilson

relationship good deterministic solutions good probabilistic solutions,
building work here, necessary pursue work principled fashion.
course, proactive techniques sufficient. practice, schedules dynamic
need adapted new jobs arrive existing jobs canceled. execution time,
reactive component necessary deal unexpected (or sufficiently unlikely) disruptions
that, nonetheless, occur. complete solution scheduling uncertainty needs
incorporate elements reason uncertainty different levels granularity
different time pressures. See work Bidot, Vidal, Laborie Beck (2007)
recent work direction.
7.3 Exploiting Unsound Lower Bounds Constraint Programming
B&B-DQ-L algorithm may represent problem-solving approach applied
beyond current application area. abstract away probabilistic JSP application,
central idea B&B-DQ-L exploit unsound lower bound (over)constrain
search run subsequent searches gradually relaxed unsound lower bound.
approach may play strengths constraint programming: searching within
highly constrained spaces.
example, assignment problem (AP) well-known lower bound traveling
salesman problem (TSP) used cost-based constraint literature
(Focacci, Lodi, & Milano, 2002; Rousseau, Gendreau, Pesant, & Focacci, 2004). Given
TSP, P , let AP (P, q) corresponding assignment problem travel distances
multiplied q. is, let dij distance cities j P let d0ij
distance cities j AP (P, q). d0ij = dij q q 1. approach
similar B&B-DQ-L algorithm applied solve TSP.
would interesting investigate approach compares traditional
optimization approach constraint programming. may particularly useful applications evaluation partial solutions expensive exists
parameterizable, inexpensive lower bound.

8. Conclusion
paper, addressed job shop scheduling durations activities
independent random variables. theoretical framework created formally define
problem prove soundness two algorithm components: Monte Carlo simulation
find upper bounds probabilistic makespan solution partial solution;
carefully defined deterministic JSP whose optimal makespan lower bound
probabilistic makespan corresponding probabilistic JSP.
used two components together either constraint programming
tabu search define number algorithms solve probabilistic JSPs. introduced
three solution approaches: branch-and-bound technique using Monte Carlo simulation
evaluate partial solutions; iterative deterministic search using Monte Carlo simulation
evaluate solutions series increasingly less constrained problems based
parameterizable lower bound; number deterministic filtering algorithms
generate sequence solutions deterministic JSP, simulated
using Monte Carlo simulation.
228

fiProactive Algorithms JSP

empirical evaluation demonstrated branch-and-bound technique
able find approximately optimal solutions small problem instances. iterative
deterministic search performs well as, better than, branch-and-bound approach
problem sizes. However, medium large instances, deterministic filtering
techniques perform much strongly providing optimality guarantees.
experimentation demonstrated techniques using deterministic methods,
correlation deterministic makespan probabilistic makespan key factor
algorithm performance: taking account variance duration deterministic
problem led strong correlations good algorithmic performance.
Proactive scheduling techniques seek incorporate models uncertainty offline, predictive schedule. goal techniques increase robustness
schedules produced. important schedule typically generated
executed isolation. decisions deliver raw materials
schedule up- down-stream factories affected individual schedule. Indeed,
schedule seen locus competing constraints across company supply
chain (Fox, 1983). Differences predictive schedule execution
significant source disruption leading cascading delays across widely separated entities.
ability, therefore, develop schedules robust uncertainty important.
paper represents step direction.

Acknowledgments
work received support Science Foundation Ireland grants 00/PI.1/C075
05/IN/I886, Natural Sciences Engineering Research Council Canada,
ILOG, SA. authors would like thank Daria Terekhov Radoslaw Szymanek
comments previous versions paper. Preliminary versions work reported
paper published Beck Wilson (2004, 2005).

References
Beck, J. C. (1999). Texture measurements basis heuristic commitment techniques
constraint-directed scheduling. Ph.D. thesis, University Toronto.
Beck, J. C., & Fox, M. S. (2000). Dynamic problem structure analysis basis
constraint-directed scheduling heuristics. Artificial Intelligence, 117 (1), 3181.
Beck, J. C., & Wilson, N. (2004). Job shop scheduling probabilistic durations.
Proceedings Sixteenth European Conference Artificial Intelligence (ECAI04),
pp. 652656.
Beck, J. C., & Wilson, N. (2005). Proactive algorithms scheduling probabilistic durations. Proceedings Nineteenth International Joint Conference Artificial
Intelligence (IJCAI05), pp. 12011206.
Bidot, J. (2005). General Framework Integrating Techniques Scheduling Uncertainty. Ph.D. thesis, Ecole Nationale dIngeieurs de Tarbes.
229

fiBeck & Wilson

Bidot, J., Vidal, T., Laborie, P., & Beck, J. C. (2007). general framework scheduling
stochastic environment. Proceedings Twentieth International Joint
Conference Artificial Intelligence (IJCAI07), pp. 5661.
Blazewicz, J., Domschke, W., & Pesch, E. (1996). job shop scheduling problem: Conventional new solution techniques. European Journal Operational Research,
93 (1), 133.
Boutilier, C., Dean, T., & Hanks, S. (1999). Decision-theoretic planning: Structural assumptions computational leverage. Journal Artificial Intelligence Research,
11, 194.
Brucker, P., Drexl, A., Mohring, R., Neumann, K., & Pesch, E. (1999). Resource-constrained
project scheduling: Notation, classification, models methods. European Journal
Operational Research, 112, 341.
Burns, A., Punnekkat, S., Littlewood, B., & Wright, D. (1997). Probabilistic guarantees fault-tolerant real-time systems. Tech. rep. DeVa TR No. 44, Design Validation, Esprit Long Term Research Project No. 20072. Available
http://www.fcul.research.ec.org/deva.
Burt, J. M., & Garman, M. B. (1970). Monte Carlo techniques stochastic network analysis. Proceedings Fourth Annual Conference Applications Simulation,
pp. 146153.
Cohen, P. R. (1995). Empirical Methods Artificial Intelligence. MIT Press, Cambridge, Mass.
Daniels, R., & Carrillo, J. (1997). -robust scheduling single-machine systems
uncertain processing times. IIE Transactions, 29, 977985.
Davenport, A. J., Gefflot, C., & Beck, J. C. (2001). Slack-based techniques robust
schedules. Proceedings Sixth European Conference Planning (ECP-2001).
Davenport, A., & Beck, J. C. (2000). survey techniques scheduling uncertainty.
Tech. rep.. Available at: http://www.tidel.mie.utoronto.ca/publications.php.
Drummond, M., Bresina, J., & Swanson, K. (1994). Just-in-case scheduling. Proceedings
Twelfth National Conference Artificial Intelligence (AAAI-94), pp. 1098
1104, Menlo Park, CA. AAAI Press/MIT Press.
Feller, W. (1968). Introduction Probability Theory Applications (Third edition). John Wiley Sons, New York, London.
Focacci, F., Lodi, A., & Milano, M. (2002). hybrid exact algorithm TSPTW.
INFORMS Journal Computing, 14 (4), 403417.
Fox, M. S. (1983). Constraint-Directed Search: Case Study Job-Shop Scheduling. Ph.D.
thesis, Carnegie Mellon University, Intelligent Systems Laboratory, Robotics Institute, Pittsburgh, PA. CMU-RI-TR-85-7.
Gao, H. (1995). Building robust schedules using temporal protectionan empirical study
constraint based scheduling machine failure uncertainty. Masters thesis,
Department Industrial Engineering, University Toronto.
230

fiProactive Algorithms JSP

Garey, M. R., & Johnson, D. S. (1979). Computers Intractability: Guide Theory
NP-Completeness. W.H. Freeman Company, New York.
Ghosh, S. (1996). Guaranteeing fault tolerance scheduling real-time systems.
Ph.D. thesis, University Pittsburgh.
Ghosh, S., Melhem, R., & Mosse, D. (1995). Enhancing real-time schedules tolerate
transient faults. Real-Time Systems Symposium.
Gillies, D. W., & Liu, J. W.-S. (1995). Scheduling tasks AND/OR precedence constraints. SIAM J. Comput., 24, 797810.
Hagstrom, J. N. (1988). Computational complexity PERT problems. Networks, 18,
139147.
Herroelen, W., & Leus, R. (2005). Project scheduling uncertainty: Survey research
potentials. European Journal Operational Research, 165 (2), 289306.
Laborie, P. (2003). Algorithms propagating resource constraints AI planning
scheduling: Existing approaches new results. Artificial Intelligence, 143, 151188.
Laborie, P. (2005). Complete MCS-Based Search: Application Resource-Constrained
Project Scheduling. Proceedings Nineteenth International Joint Conference
Artificial Intelligence (IJCAI05), pp. 181186.
Laborie, P., & Ghallab, M. (1995). Planning sharable resource constraints. Proceedings Fourteenth International Joint Conference Artificial Intelligence
(IJCAI95).
Le Pape, C., Couronne, P., Vergamini, D., & Gosselin, V. (1994). Time-versus-capacity
compromises project scheduling. Proceedings Thirteenth Workshop
UK Planning Special Interest Group.
Leon, V. J., Wu, S. D., & Storer, R. H. (1994). Robustness measures robust scheduling
job shop. IIE Transactions, 26 (5), 3243.
Ludwig, A., Mohring, R., & Stork, F. (2001). computational study bounding
makespan distribution stochastic project networks. Annals Operations Research,
102, 4964.
Meuleau, N., Hauskrecht, M., Kim, K., Peshkin, L., Kaelbling, L., Dean, T., & Boutilier, C.
(1998). Solving large weakly coupled markov decision processes. Proceedings
Fifteenth National Conference Artificial Intelligence (AAAI-98).
Mohring, R., Skutella, M., & Stork, F. (2004). Scheduling AND/OR precedence constraints. SIAM J. Comput, 33 (2), 393415.
Morris, P., Muscettola, N., & Vidal, T. (2001). Dynamic control plans temporal
uncertainty. Proceedings Seventeenth International Joint Conference
Artificial Intelligence (IJCAI-01).
Nowicki, E., & Smutnicki, C. (1996). fast taboo search algorithm job shop problem.
Management Science, 42 (6), 797813.
Nuijten, W. P. M. (1994). Time resource constrained scheduling: constraint satisfaction approach. Ph.D. thesis, Department Mathematics Computing Science,
Eindhoven University Technology.
231

fiBeck & Wilson

Pinedo, M. (2003). Scheduling: Theory, Algorithms, Systems (2nd edition). PrenticeHall.
R Development Core Team (2004). R: language environment statistical computing.
R Foundation Statistical Computing, Vienna, Austria. ISBN 3-900051-07-0.
Radermacher, F. J. (1985). Scheduling project networks. Annals Operations Research,
4, 227252.
Rousseau, L., Gendreau, M., Pesant, G., & Focacci, F. (2004). Solving VRPTWs
constraint programming based column generation. Annals Operations Research,
130, 190216.
Stork, F. (2000). Branch-and-bound algorithms stochastic resource-constrained project
scheduling. Tech. rep. 702/2000, Technische Universitat Berlin, Department Mathematics.
Tsamardinos, I. (2002). probabilistic approach robust execution temporal plans
uncertainty. Methods Applications Artificial Intelligence: Proceedings
Second Hellenic Conference Artificial Intelligence, Vol. 2308 Lecture Notes
Artificial Intelligence, pp. 97108.
Watson, J.-P., Barbulescu, L., Whitley, L., & Howe, A. (2002). Contrasting structured
random permutation flow-shop scheduling problems: search-space topology
algorithm performance. INFORMS Journal Computing, 14 (1).
Wilson, N. (2000). Algorithms Dempster-Shafer Theory. In: Kohlas, J., Moral, S.,
(eds.) Algorithms Uncertainty Defeasible Reasoning, Volume 5, Handbook
Defeasible Reasoning. Kluwer Academic Publishers.
Wurman, P., & Wellman, M. (1996). Optimal factory scheduling using stochastic dominance
A*. Proceedings Twelfth Conference Uncertainty Artificial Intelligence
(UAI-96).

232

fiJournal Artificial Intelligence Research 28 (2007) 431-451

Submitted 07/06; published 04/07

Discovering Classes Strongly Equivalent Logic Programs
Fangzhen Lin

flin@cs.ust.hk

Department Computer Science Engineering
Hong Kong University Science Technology
Clear Water Bay, Kowloon, Hong Kong

Yin Chen

gzchenyin@gmail.com

Department Computer Science
South China Normal University
Guangzhou, P.R. China

Abstract
paper apply computer-aided theorem discovery technique discover theorems strongly equivalent logic programs answer set semantics. discovered theorems capture new classes strongly equivalent logic programs lead
new program simplification rules preserve strong equivalence. Specifically,
help computers, discovered exact conditions capture strong equivalence
rule empty set, two rules, two rules one two
rules, two rules another rule, three rules two three
rules.

1. Introduction
paper apply computer-aided theorem discovery technique discover theorems
strongly equivalent logic programs answer set semantics. discovered
theorems capture new classes strongly equivalent logic programs lead new
program simplification rules preserve strong equivalence.
Theorem discovery highly creative human process. Generally speaking,
divide two steps: (i) conjecture formulation, (ii) conjecture verification,
computers help two steps. instance, machine learning tools
used first step, i.e. coming reasonable conjectures, automated
deduction tools used second step, i.e. verifying correctness
conjectures.
theorem discovery may make use learning, two tasks fundamentally different. Theorem discovery starts theory, aims finding interesting
consequences theory, learning mostly induction, i.e. starts
examples/consequences, aims finding theory would explain given examples/consequences.
Using computers discover theorems old aspiration.
success stories. instance, (Lenat, 1979) reported able come
interesting concepts theorems number theory, remarkable systems
described Petkovsek, Wilf, Zeilberger (1996) discover many identities, especially
hypergeometric identities involving sums binomial coefficients important
analyses algorithms. Yet another example interesting theorems discovered
c
2007
AI Access Foundation. rights reserved.

fiLin & Chen

almost fully automatically recent work Lin (2004) discovering state invariants
planning domains. Lin showed ways classify many state constraints
useful planning according syntactic properties, enumerate easily
many domains. Furthermore, many constraints whether invariants
checked automatically. result, system described Lin (2004) discover
many common constraints planning domains, logistics domain, could even
discover set complete state invariants.
Following line research, paper, consider problem discovering
classes strongly equivalent sets logic program rules answer set semantics.
noted Lifschitz, Pearce, Valverde (2001), two sets rules strongly equivalent,
replace one logic program without changing semantics
program. Thus identifying strongly equivalent sets logic program rules useful
exercise may applications program simplification.
paper organized follows. next section, briefly review basic
concepts logic programming answer set semantics. section 3 state
precise terms type theorems want discover. section 4 prove
general theorems help us prove theorems, section 5, describe
theorems discovered. discuss application logic program
simplification section 6, finally conclude paper section 7.

2. Answer Set Programming
Traditional logic programming systems like Prolog solve problems query answering.
user encodes knowledge domain set rules, solves problem issuing
queries set rules. contrast, Answer Set Programming (ASP) (Niemela, 1999;
Lifschitz, 1999; Marek & Truszczynski, 1999) constraint-based programming paradigm.
based logic programming answer set semantics (Gelfond & Lifschitz, 1988,
1991). solve problem, user encodes domain knowledge logic program
way answer sets program correspond solutions original
problem. Compared constraint-based programming paradigms, ASP allows natural
encodings recursive relations, built-in facilities default reasoning. Several ASP
solvers developed (Niemela, Simons, & Syrjanen, 2000; Leone, Pfeifer, Faber,
Eiter, Gottlob, Perri, & Scarcello, 2006; Lin & Zhao, 2004; Lierler & Maratea, 2004).
date, ASP used space shuttle planning (Nogueira, Balduccini, Gelfond, Watson,
& Barry, 2001), evolutional linguistics (Erdem, Lifschitz, Nakhleh, & Ringe, 2003),
others. following, briefly review basic notions ASP.
Let L propositional language, i.e. set atoms. paper shall consider
logic programs rules following form:
h1 ; ; hk p1 , , pm , pm+1 , , pn

(1)

hi pi atoms L. logic program default negation (not ),
constraints (when k = 0), disjunctions head rules. following, r
rule form, write Hdr denote set {h1 , ..., hk }, Psr set {p1 , ..., pm },
Ngr set {pm+1 , ..., pn }. Thus rule r also written Hdr Psr , Ngr .
semantics programs given answer sets (Gelfond & Lifschitz, 1991),
432

fiDiscovering Classes Strongly Equivalent Logic Programs

defined fixed-point operator known Gelfond-Lifschitz
transformation. Let X subset L, P logic program. Gelfond-Lifschitz
transformation P X, written P X , set rules obtained P according
following two rules:
1. rule form (1) P , pi X + 1 n, delete
rule.
2. Delete literals form pi bodies remaining rules.
instance, P set following rules:
a; b
c
P {a} {a; b }, P {b} {(a; b ), (c )}.
Clearly, X P , P X set rules operator.
set X answer set P X minimal set atoms satisfies every rule
P X , X satisfies rule form
h 1 ; ; h k p1 , , p
1 k, hi X whenever {p1 , ..., pm } X. instance,
program, {a} {b, c} answer sets, answer sets
program.
Two logic programs P1 P2 said equivalent answer sets,
strongly equivalent (Lifschitz et al., 2001) (under language L), written P1 'se P2 ,
logic program P L, P P1 P P2 equivalent (thus write P1 6'se P2
P1 P2 strongly equivalent). example, {a b} {a c}
equivalent, strongly equivalent. shown {a a} 'se { a}.
abstract, also say rule r strongly equivalent another rule r0 , written
r 'se r0 , {r} 'se {r0 }, two rules r1 r2 strongly equivalent rule r, written
{r1 , r2 } 'se r, {r1 , r2 } 'se {r}, on.
notion strong equivalence important ASP several reasons. First all,
helps us understand answer set semantics. instance, Turner (2003) showed
disjunctive rule (a; b ) strongly equivalent set normal rules. implies
cannot modular translation disjunctive logic programs normal logic
programs. However,
{(a; b ), ( a, b)}
strongly equivalent
{(a b), (b a), ( a, b)}.
means constraint ( a, b), disjunctive rule (a; b ) replaced
two rules without disjunction. Secondly, mentioned introduction, P1
P2 strongly equivalent, interchangeable regardless occur.
Thus large repertoire pairs strongly equivalent logic programs, could
433

fiLin & Chen

use transform given program one suitable need hand.
particular, could help us simplify program purpose computing answer
sets. shall see, discovered theorems contribute significantly repertoire.
Lifschitz et al. (2001) showed checking strong equivalence two logic
programs done logic here-and-there, three-valued non-classical logic
somewhere classical logic intuitionistic logic. Lin (2002) provided mapping
logic programs propositional theories showed two logic programs
strongly equivalent iff corresponding theories propositional logic equivalent.
result used generating example pairs strongly equivalent logic
programs, verifying conjecture. repeat here.
Let P1 P2 two finite logic programs, L set atoms them.
Theorem 1 (Lin, 2002) P1 'se P2 iff propositional logic, following sentence valid:
^
^
^
p p0 ) [
(
(r)
(r)],
(2)
pL

rP1

rP2

p L, p0 new atom, rule r form (1), (r)
conjunction following two sentences:
p1 pm p0m+1 p0n h1 hk ,

(3)

p01

(4)



p0m



p0m+1



p0n



h01



h0k .

Notice = n = 0, left sides implications (3) (4) considered
true, k = 0, right sides implications (3) (4) considered
f alse.
general checking two sets rules strongly equivalent coNP-complete (c.f.
Turner, 2001; Pearce, Tompits, & Woltran, 2001; Lin, 2002).

3. Problem
mentioned above, one possible use notion strongly equivalent logic programs
program simplification. instance, given logic program, rule r it,
may ask whether deleted without knowing rules P , i.e.
whether {r} strongly equivalent empty set. may ask whether rule r
P deleted one knows another rule r0 already P , i.e. whether {r, r0 }
strongly equivalent {r0 }. general, may ask following k-m-n question:
{r1 , ..., rk , u1 , ..., um } 'se {r1 , ..., rk , v1 , ..., vn }? Thus theorem discovery task come
up, given k-m-n problem, computationally effective condition holds
answer k-m-n question positive.
suppose condition C, suppose
{r1 , ..., rk , u1 , ..., um } 'se {r1 , ..., rk , v1 , ..., vn },
better replace {u1 , ..., um } {v1 , ..., vn } presence r1 , ..., rk purpose
of, say computing answer sets program. One way use result simplify
given program P first choose k rules P , rules it, try find
434

fiDiscovering Classes Strongly Equivalent Logic Programs

n rules condition C holds, replace rules P simpler n
rules.
However, even checking whether C holds would take negligible constant time, using
procedure simplify given logic program practical k, m, n
small k almost number rules given
program, n small. Thus seems us worthwhile solve
k-m-n problem k, m, n small. particular, paper, shall
concentrate 0-1-0 problem (whether rule always deleted), 0-1-1 problem
(whether rule always replaced another one), 1-1-0 problem (in presence
rule, whether another rule deleted), 2-1-0 problem (in presence two
rules, whether rule always deleted), 0-2-1 problem (if pair rules
replaced single rule).
example theorems want discover problems follows:
rule r, r 'se iff (Hdr Ngr ) Psr 6= .

(5)

4. General Theorems
section, prove general theorems help us verify whether assertion
like (5) true.
Let L propositional language, i.e. set atoms. L, construct first-order
language FL equality, two unary predicates H1 H2 , three unary predicates Hdr ,
Psr , Ngr logic program rule r L (we assume rule L unique
name), three unary predicates Xi , Yi , Zi positive number i.
Notice used Hdr , Psr , Ngr denote sets atoms previously,
overload unary predicates. Naturally, intended interpretations
unary predicates respective sets.
Definition 1 Given set L atoms, intended model FL one whose domain L,
rule r L, unary predicates Psr , Hdr , Ngr interpreted
corresponding sets atoms, Psr , Hdr , Ngr , respectively.
Conditions rules L, Psr Ngr 6= , expressed special sentences
called properties FL .
Definition 2 sentence FL property n rules constructed equality
predicates Xi , Yi , Zi , 1 n. property n rules true (holds)
sequence P = [r1 , ..., rn ] n rules [P ] true intended model FL , [P ]
obtained replacing Xi Hdri , Yi Psri , Zi Ngri .
Notice since [P ] mention predicates Xi , Yi , Zi , H1 , H2 , true
one intended model, true intended models.
mentioned above, interested capturing strong equivalence
two programs computationally effective condition. specifically,
small k, m, n, interested finding property k + + n rules
sequence k + + n rules, P = [r1 , ..., rk , u1 , ..., um , v1 , ..., vn ],
{r1 , ..., rk , u1 , ..., um } 'se {r1 , ..., rk , v1 , ..., vn } iff true P .
435

(6)

fiLin & Chen

shall prove general theorems help us verify assertion
class formulas .
First all, Theorem 1 reformulated FL follows reading H1 (p) p
holds, H2 (p) p0 holds:
Theorem 2 P1 'se P2 L iff following sentence
^
^
x(H1 (x) H2 (x)) [
(r)
(r)]
rP1

(7)

rP2

true intended models FL , (r) conjunction following two
sentences:
[x(Psr (x) H1 (x)) x(Ngr (x) H2 (x))] x(Hdr (x) H1 (x)),

(8)

[x(Psr (x) H2 (x)) x(Ngr (x) H2 (x))] x(Hdr (x) H2 (x)).

(9)

first order logic, prenex formula form ~x~y B satisfiable,
satisfiable structure n elements, B formula contains quantifiers,
constants, function symbols, n length ~x non-empty, 1 ~x
empty. prove similar result first-order languages intended
models here.
Definition 3 sentence FL extended property n rules constructed
equality predicates Xi , Yi , Zi , 1 n, H1 H2 . extended
property n rules true (holds) sequence P = [r1 , ..., rn ] n rules model
[P ] true , [P ] obtained replacing Xi Hdri , Yi
Psri , Zi Ngri .
Definition 4 following, P = [r1 , ..., rn ] tuple rules L, L0 subset
L, define restriction P L0 [r10 , ..., rn0 ], ri0
Hdri L0 Psri L0 , (Ngri L0 ).
Lemma 1 Let extended property FL n rules, form ~x~y Q,
~x tuple w variables, Q formula quantifiers.
holds sequence P n rules intended model FL , subset
L0 L L0 w atoms (or one atom w = 0), holds
restriction P L0 intended model FL0 .
Proof: Suppose intended model FL |= [P ]. Thus tuple
p~ w (or one w = 0) atoms L |= ~y Q[P ](~x/~
p). let L0 set
0
atoms p~, defined follows:
predicates H1 , H2 , Xi , Yi , Zi , 1, interpreted restriction
interpretation L0 .
rule r L0 , predicates Hdr , Psr , Ngr interpreted
. well-defined r also rule L,
436

fiDiscovering Classes Strongly Equivalent Logic Programs

0 intended model FL0 . Let P 0 restriction P L0 . P 0
tuple rules L0 . Since Q quantifiers (and language function symbols),
instantiation ~u ~y L0 , |= Q[P ](~x/~
p)(~y /~u) iff 0 |= Q[P 0 ](~x/~
p)(~y /~u). Since
0
0
|= ~y Q[P ](~x/~
p), |= ~y Q[P ](~x/~
p), Thus 0 |= ~x~y Q[P 0 ].
Using Theorem 2 lemma, show following theorem enable
us automate verification part (6) property prenex
format.
Theorem 3 Without loss generality, suppose n. property k+m+n
rules form ~x~y Q, ~x tuple w variables, Q formula
quantifiers, following two assertions equivalent:
(a) sequence k + + n rules, P = [r1 , ..., rk , u1 , ..., um , v1 , ..., vn ], true
P , {r1 , ..., rk , u1 , ..., um } 'se {r1 , ..., rk , v1 , ..., vn }.
(b) (b.1) n > 0, sequence P = [r1 , ..., rk , u1 , ..., um , v1 , ..., vn ] rules
w + 2(k + m) atoms, true P ,
{r1 , ..., rk , u1 , ..., um } 'se {r1 , ..., rk , v1 , ..., vn }.
(b.2) n = 0, sequence P = [r1 , ..., rk , u1 , ..., um ] rules
K atoms, true P ,
{r1 , ..., rk , u1 , ..., um } 'se {r1 , ..., rk },
K w + 2k w + 2k > 0, K = 1 otherwise.
Proof: (a) (b) obvious. assume (b) true, show (a) holds
well. Suppose first n > 0. Suppose P = [r1 , ..., rk , u1 , ..., um , v1 , ..., vn ] sequence
k + + n rules language L true P ,
{r1 , ..., rk , u1 , ..., um } 6'se {r1 , ..., rk , v1 , ..., vn }.
Thus intended model FL satisfies [P ], intended model FL
satisfies following sentence:
^
^
(x)H1 (x) H2 (x) [
(r)
(r)],
rP1

rP2

P1 = {r1 , ..., rk , u1 , ..., um }, P2 = {r1 , ..., rk , v1 , ..., vn }. noted Definition 2, also satisfy [P ]. Thus satisfies following sentence
^
^
^
^
[P ] (x)H1 (x) H2 (x) {[
(r)
(r)] [
(r)
(r)]}, (10)
rP1

rP3

rP2

rP4

P3 = {v1 , ..., vn }, P4 = {u1 , ..., um }.
rule r, extended property (x, y) one rule
mention quantifiers (r) equivalent x, y.[r]. Thus tuple Q
rules,Vthere extended property rules mention quantifiers
rQ (r) equivalent ~y .[Q], ~y tuple 2t variables.
Thus
437

fiLin & Chen

tuple z~1 2(k + m) variables, tuple z~2 variables, extended property 1
k + + n rules quantifiers, whose free variables z~1
z~2 ;
tuple z~3 2(k + n) variables, tuple v~4 variables, extended property 2
k + + n rules quantifiers, whose free variables
z~3 z~4
v~1 , v~2 , v~3 , v~4 common variables them, (10) equivalent
following sentence:
{ x(H1 (x) H2 (x)) (z~1 z~2 1 z~3 z~4 2 )}[P ].
Since assumed n, thus extended property 3 k + + n
rules mention quantifiers function symbols, whose free variables
among z~1 , z~2 , z~4 sentence equivalent following sentence:
( x(H1 (x) H2 (x)) z~1 (z~2 , z~4 )3 )[P ].
given form assumed theorem, tuple z~5 w + 2(k + m)
variables, tuple z~6 variables, extended property k + + n rules
mention quantifiers, whose free variables among z~5 , z~6
sentence equivalent (z~5 )(z~6 )[P ].
Lemma 1, subset L0 L w + 2(k + m) atoms
(z~5 )(z~6 ) holds P 0 , P 0 restriction P L0 .
P 0 = [r10 , ..., rk0 , u01 , ..., u0m , v10 , ..., vn0 ],
mean true P 0 , {r10 , ..., rk0 , u01 , ..., u0m } 6'se {r10 , ..., rk0 , v10 , ..., vn0 }.
shows (b.1), (a).
proof (b.2) (a) exactly except
^
^
[
(r)
(r)]
rP1

rP2

equivalent
[

^

rP2

^

(r)

(r)].

rP1


part (6) often proved help following theorem.
Theorem 4 Let L1 L2 two languages, f function L1 L2 . P1 P2
two programs L1 strongly equivalent, f (P1 ) f (P2 ) two programs
L2 also strongly equivalent. f (P ) obtained P replacing
atom p f (p).
Proof: Theorem 1 fact propositional logic, tautology, f
function L1 L2 , f () also tautology, f () formula obtained
replacing atom p f (p).
example using theorems section proving assertions form
(6), see Section 5.1.
438

fiDiscovering Classes Strongly Equivalent Logic Programs

5. Computer-Aided Theorem Discovery
Given k-m-n problem, strategy discovering theorems follows:
1. Choose small language L;
2. Generate possible triples
({r1 , ..., rk }, {u1 , ..., um }, {v1 , ..., vn })

(11)

sets rules L {r1 , ..., rk , u1 , ..., um } 'se {r1 , ..., rk , v1 , ..., vn } L;
3. Formulate conjecture k-m-n problem holds language L, i.e.
condition true triple form (11) iff generated Step 2;
4. Verify correctness conjecture general case.
process may iterated. instance, conjecture formulated Step 3 may
fail generalize Step 4, either need formulate new conjecture start
step 1 using larger language.
Ideally, would like process automatic. However, difficult automate
Steps 3 4 - number possible patterns need examine order come
good conjecture Step 3 huge, general theorem
enables us automate verification part Step 4. Theorem 3 enables us
automate proof sufficient part assertion (6) class formulas ,
similar result necessary part - shall see below, Theorem 4 helps
lot here, provide automated procedure. Nonetheless, computers play
crucial role steps, following report theorems discovered
using procedure.
5.1 0-1-0 Problem
problem asks given rule strongly equivalent empty set, thus always
deleted program. following experimental result:
Lemma 2 rule r mentions three distinct atoms, r 'se iff
(Hdr Ngr ) Psr 6= .
Using Theorem 4, show following result:
Lemma 3 rule r form (1) r 'se (Hdr Ngr ) Psr 6=
true, rule mentions three atoms.
Proof: Suppose r 'se , Hdr Psr = , Psr Ngr = . Suppose L set atoms
r, a, b, c three new atoms. Let

p Hdr

b
p Psr
f (p) =

c
otherwise
439

fiLin & Chen

Theorem 4, also f (r) 'se . construction f , also
Hdf (r) Psf (r) = , Psf (r) Ngf (r) = , f (r) mentions three distinct
atoms.
Theorem 5 (The 0-1-0 problem) Lemma 2 holds general case, i.e. without
restriction number atoms r.
Proof: notice condition Lemma 2, (Hdr Ngr ) Psr 6= , equivalent
following property
x.(X1 (x) Z1 (x)) Y1 (x)
true [r]. Thus part follows Theorem 3 Lemma 2.
part follows Lemma 2 Lemma 3.
part theorem already well-known, first proved Osorio et. al. (2001).
part also proved recently Inoue Sakama (2004).
discover anything new case, reassuring methodology works.
notice need consider 0-n-0 problem n > 1,
n, {r1 , ..., rn } strongly equivalent iff 1 n, {ri } strongly
equivalent .
5.2 1-1-0 0-1-1 Problems
1-1-0 problem asks rule always deleted presence another rule,
0-1-1 problem asks rule always replaced another one. first solve
1-1-0 problem, solution 0-1-1 problem come corollary.
following experimental result 1-1-0 problem:
Lemma 4 two rules r1 r2 mentions three atoms, {r1 , r2 }
{r1 } strongly equivalent iff one following two conditions true:
1. r2 'se .
2. Psr1 Psr2 , Ngr1 Ngr2 , Hdr1 Hdr2 Ngr2 .
Lemma 5 two rules r1 r2 {r1 , r2 } 'se {r2 }, none
two conditions Lemma 4 hold, two rules mention three
atoms.
Proof: Suppose two rules r1 , r2 {r1 , r2 } 'se {r2 }, none two
conditions Lemma 4 hold. Let L set atoms r1 , r2 .
Without loss generality, suppose a1 atom makes condition (2)
Lemma 4 false. Psr2 \ {a1 } empty, let a2 atom it. Let L0 = {a1 , a2 , a3 },
a3 new atom, f function L L0 following:

= a1
a1
a2
Psr2 \ {a1 }
f (a) =

a3
otherwise
440

fiDiscovering Classes Strongly Equivalent Logic Programs

clearly, f (r1 ) f (r2 ) mention three distinct atoms, Theorem 4,
{f (r1 ), f (r2 )} 'se f (r1 ).
show none two conditions Lemma 4 hold f (r1 ) f (r2 ) either.
show first f (r2 ) 6'se . Theorem 5, need show
= Psf (r2 ) (Hdf (r2 ) Ngf (r2 ) )
empty. a1 S, construction f , a1 Psr2 (Hdr2 Ngr2 ), contradiction
assumption r2 strongly equivalent . Similarly, a2 S,
construction f , a2 Psr2 (Hdr2 Ngr2 ), contradiction assumption
r2 strongly equivalent . a3 cannot a3 cannot Psf (r2 ) .
Thus must empty.
show case Psf (r1 ) Psf (r2 ) , Ngf (r1 ) Ngf (r2 ) ,
Hdf (r1 ) Hdf (r2 ) Ngf (r2 ) . assumption, a1 atom makes either Psr1 Psr2 ,
Ngr1 Ngr2 , Hdr1 Hdr2 Ngr2 false. three cases here. Suppose a1 makes
Psr1 Psr2 false, i.e. a1 Psr1 a1 6 Psr2 . construction f , also
a1 Psf (r1 ) a1 6 Psf (r2 ) . two cases similar.
Theorem 6 (The 1-1-0 problem) Lemma 4 holds general case, without restriction number atoms r1 r2 .
Proof: condition Lemma 4 equivalent following property
[x.(X2 (x) Z2 (x)) Y2 (x)]
{[x.Y1 (x) Y2 (x)] [x.Z1 (x) Z2 (x)] [x.X1 (x) (X2 (x) Z2 (x))]}
true [r1 , r2 ]. Thus part follows Theorem 3 Lemma 4, noticing
property written x~y .Q required Theorem 3.
part follows Lemma 4 Lemma 5.
Thus rule r2 cannot deleted deleted presence
another rule r1 , must case r2 redundant given r1 : body r2
satisfied, body r1 satisfied well; furthermore, r2 entail
entailed r1 (Hdr1 Hdr2 Ngr2 ).
Osorio et al. (2001) proved {r1 , r2 } 'se r1 either Psr1 Ngr1 = Hdr1 Ngr2
Psr1 Psr2 , Ngr1 Ngr2 , Hdr1 Hdr2 . recently, Eiter et al. (2004) showed
{r1 , r2 } 'se r1 r1 s-implies r2 (Wang & Zhou, 2005), i.e. exists set
Ngr2 Hdr1 Hdr2 A, Ngr1 Ngr2 \ A, Psr1 Psr2 .
one see, special cases part Theorem 6. result
actually general. instance, special cases apply
{(c b, c), ( b, c)}

{c b, c},
one easily show two sets strongly equivalent using theorem.
solution 1-1-0 problem, derive solution 0-1-1 problem.
441

fiLin & Chen

Theorem 7 (The 0-1-1 problem) two rules r1 r2 , r1 'se r2 iff one
following two conditions true:
1. r1 'se r2 'se .
2. Psr1 = Psr2 , Ngr1 = Ngr2 , Hdr1 Ngr1 = Hdr2 Ngr2 .
Proof: Theorem 1, easy see r1 'se r2 iff {r1 , r2 } 'se r1 {r1 , r2 } 'se r2 .

Thus two rules r1 r2 always interchanged either
deleted (strongly equivalent empty set) body,
consequences body true. instance, {a B, a} 'se { B, a}
matter B is, two rules body, body true,
consequence - contradiction. another example,
{a; b a} 'se {b a},
two rules body, and, body true, consequence,
b.
5.3 2-1-0, 0-2-1, 0-2-2 Problems
2-1-0 problem asks rule deleted presence another two rules,
0-2-1 problem asks two rules replaced single rule, 0-2-2 problem asks
two rules replaced another two rules. Similar previous subsection,
solution 0-2-1 0-2-2 problems follow solution 2-1-0 problem.
experiment 2-1-0 problem difficult turned out,
consider language six atoms case. principle, given language L,
every subset L Hd, Ps, Ng rule. Thus size L six,
principle (26 )3 1 = 262, 143 possible rules, 262, 1433 triples them. However,
cut numbers significantly results already proved.
First, consider rules common elements
two sets {Hd, Ps, Ng}: either Hd Ps Ps Ng common element,
Theorem 5, rule deleted; Hd Ng common elements, according
Theorem 7, obtain strongly equivalent rule deleting common elements Hd.
following, call rules canonical, is, rule r canonical
Hdr Psr = Hdr Ngr = Psr Ngr = .
Secondly, consider isomorphic rules: one-to-one onto
function L L maps {r1 , r2 , r3 } {r10 , r20 , r30 }, two sets rules
essentially except names atoms them.
Thus considering canonical rules using certain normal form triples
rules avoids isomorphic rules, ended roughly 120 million triples rules
consider verifying following result, took 10 hours Solaris server
consisting 8 Sun Ultra-SPARC III 900Mhz CPUs 8GB RAM.
details experiment 2-1-0 problem, please refer (Chen, Lin, & Li,
2005).
442

fiDiscovering Classes Strongly Equivalent Logic Programs

Lemma 6 three canonical rules r1 , r2 r3 mention six atoms,
{r1 , r2 , r3 } 'se {r1 , r2 } iff one following three conditions true:
1. {r1 , r3 } 'se r1 .
2. {r2 , r3 } 'se r2 .
3. atom p that:
3.1 p (Psr1 Psr2 ) (Hdr1 Hdr2 Ngr1 Ngr2 )
3.2 Hdri \ {p} Hdr3 Ngr3 Psri \ {p} Psr3 Ngri \ {p} Ngr3 ,
= 1, 2
3.3 p Psr1 Ngr2 , Hdr1 Hdr3 =
3.4 p Psr2 Ngr1 , Hdr2 Hdr3 =
following lemma reason need consider language six atoms
problem.
Lemma 7 three canonical rules r1 ,r2 r3 {r1 , r2 , r3 } 'se {r1 , r2 },
none three conditions Lemma 6 hold, three rules
mention six atoms.
Proof: proof lemma tedious consider several cases. Consider
following statements three canonical rules r1 , r2 , r3 :
(I) {r1 , r2 , r3 } 'se {r1 , r2 }.
(II) {r1 , r3 } 6'se {r1 }, i.e. Psr1 6 Psr3 Ngr1 6 Ngr3 Hdr1 Ngr1 6 Hdr3 Ngr3
(III) {r2 , r3 } 6'se {r2 }, i.e. Psr2 6 Psr3 Ngr2 6 Ngr3 Hdr2 Ngr2 6 Hdr3 Ngr3
(IV) (Psr1 Psr2 ) (Hdr1 Hdr2 Ngr1 Ngr2 ) =
(V) atom p set (Psr1 Psr2 ) (Hdr1 Hdr2 Ngr1 Ngr2 ), another
different atom q one following three conditions true:
1. q Hdr1 Ngr1 q 6 Hdr3 Ngr3 .
2. q Psr1 q 6 Psr3 .
3. q Ngr1 q 6 Ngr3 .
Notice negation condition (3.2) Lemma 6.
(VI) Hdr1 Hdr3 6 Ngr3 , atom p Psr1 Ngr2 = 1, 2,
Hdri \ {p} Hdr3 Ngr3 , Psri \ {p} Psr3 , Ngri \ {p} Ngr3 .
Since r1 r2 symmetric conditions Lemma 6, prove lemma, need
prove following three assertions:
(a) three canonical rules r1 , r2 , r3 satisfy (I)-(IV), three
canonical rules r10 , r20 , r30 mention six atoms, satisfy (I)-(IV) well.
443

fiLin & Chen

(b) three canonical rules r1 , r2 , r3 satisfy (I)-(III)(V),
three canonical rules r10 , r20 , r30 mention six atoms, satisfy (I)-(III)(V)
well.
(c) three canonical rules r1 , r2 , r3 satisfy (I)-(III)(VI),
three canonical rules r10 , r20 , r30 mention six atoms, satisfy (I)(III)(VI) well.
prove three assertions one one.
(a) Let a1 , a2 two atoms make (II) (III) true. (Psr3 (Psr1 Psr2 ))\{a1 , a2 }
empty, let a3 atom it. Psr3 \(Psr1 Psr2 {a1 , a2 }) empty, let a4
atom it. (Psr1 Psr2 )\(Psr3 {a1 , a2 }) empty, let a5 atom it.
Finally let a6 new atom different a1 a5 , L0 = {a1 , a2 , a3 , a4 , a5 , a6 }.
Let f function L L0 defined following:

a1
= a1





= a2

2


a3
(Psr3 (Psr1 Psr2 )) \ {a1 , a2 }
f (a) =

Psr3 \ (Psr1 Psr2 {a1 , a2 })


4



(Psr1 Psr2 ) \ (Psr3 {a1 , a2 })

5
a6
otherwise
1 3, let ri0 follows:
Psri0 = Psf (ri ) , Ngri0 = Ngf (ri ) , Hdri0 = Hdf (ri ) \ Ngf (ri ) .

(12)


1 3, ri0 canonical rule, ri0 'se f (ri ). this,
need show f (ri ) 6'se 1 3. see this, notice
definition f , atoms a1 a2 Psr3 mapped {a3 , a4 },
atoms a1 a2 Hdr3 Ngr3 mapped {a5 , a6 }. Thus
Psf (r3 ) (Hdf (r3 ) Ngf (r3 ) ) = . Theorem 5, f (r3 ) 6'se . f (r1 ) 6'se
f (r2 ) 6'se , (II) (III) hold f (r1 ), f (r2 ), f (r3 ) definition
f .
(I) holds r10 , r20 , r30 . Theorem 4,
{f (r1 ), f (r2 ), f (r3 )} 6'se {f (r1 ), f (r2 )},
1 3, ri0 'se f (ri ).
(II) (III) hold r10 , r20 , r30 . mentioned, definition f , (II)
(III) hold f (r1 ), f (r2 ), f (r3 ).
(IV) holds r10 , r20 , r30 . Again, need show (IV) holds
f (r1 ), f (r2 ), f (r3 ). see this, notice atoms a1 a2
Psr1 Psr2 mapped {a3 , a5 }, atoms a1 a2
Hdr1 Hdr2 Ngr1 Ngr2 mapped {a4 , a6 }.
444

fiDiscovering Classes Strongly Equivalent Logic Programs

(b) let a1 , a2 two atoms make (II) (III) true. Let p, q two witness
atoms (V). P os(r3 ) \ {a1 , a2 , p, q} empty, let a3 atom it. Let a4
new atom, L0 = {a1 , a2 , a3 , a4 , p, q}. Define f follows:

= a1

a1


a2
= a2



p
a=p
f (a) =
q
a=q






Psr3 \ {a1 , a2 , p, q}
3


a4
otherwise
Define ri0 (12) well 1 3.
1 3, ri0 canonical rule, ri0 'se f (ri ). seen
way (a) above.
Theorem 4, {f (r1 ), f (r2 ), f (r3 )} 'se {f (r1 ), f (r2 )}, thus
{r10 , r20 , r30 } 'se {r10 , r20 }.
(I) holds r10 , r20 , r30 .
definition f , (II) (III) hold f (r1 ), f (r2 ), f (r3 ), thus hold
r10 , r20 , r30 well.
definition f , (V) holds f (r1 ), f (r2 ), f (r3 ): atom
p set (Psf (r1 ) Psf (r2 ) ) (Hdf (r1 ) Hdf (r2 ) Ngf (r1 ) Ngf (r2 ) ), another
different atom q one following three conditions true:
1. q Hdf (r1 ) Ngf (r1 ) q 6 Hdf (r3 ) Ngf (r3 ) .
2. q Psf (r1 ) q 6 Psf (r3 ) .
3. q Ngf (r1 ) q 6 Ngf (r3 ) .
(V) holds r10 , r20 , r30 well 1 3,
Psri0 = Psf (ri ) , Ngri0 = Ngf (ri ) , Hdri0 Ngri0 = Hdf (ri ) Ngf (ri ) .
(c) Let a1 , a2 two atoms make (II) (III) true. Let p witness atom
(VI), let q Hdr1 Hdr3 q 6 Ngr3 . P os(r3 ) \ {a1 , a2 , p, q} empty, let
a3 atom it. Let a4 new atom, Let L0 = {a1 , a2 , a3 , a4 , p, q}, Define f
follows:

a1
= a1





= a2

2


p
a=p
f (a) =
q
a=q






Psr3 \ {a1 , a2 , p, q}

3
a4
otherwise
define ri0 (12) well 1 3.
1 3, ri0 canonical rule, ri0 'se f (ri ). seen
way (a) above.
445

fiLin & Chen

Theorem 4, {f (r1 ), f (r2 ), f (r3 )} 'se {f (r1 ), f (r2 )}, thus
{r10 , r20 , r30 } 'se {r10 , r20 }.
(I) holds r10 , r20 , r30 .
definition f , (II) (III) hold f (r1 ), f (r2 ), f (r3 ), thus
hold r10 , r20 , r30 well.
definition f , (VI) holds f (r1 ), f (r2 ), f (r3 ): Hdf (r1 ) Hdf (r3 ) 6
Ngf (r3 ) , atom p Psf (r1 ) Ngf (r2 ) = 1, 2, Hdf (ri ) \
{p} Hdf (r3 ) Ngf (r3 ) , Psf (ri ) \ {p} Psf (r3 ) , Ngf (ri ) \ {p} Ngf (r3 ) . (VI)
holds r10 , r20 , r30 well
Psri0 = Psf (ri ) , Ngri0 = Ngf (ri ) , Hdri0 Hdf (ri ) .

Theorem 8 (The 2-1-0 problem) Lemma 6 holds general case, without restriction number atoms r1 , r2 , r3 .
Proof: assertion r1 , r2 , r3 canonical rules satisfy one three
conditions Lemma 6 equivalent following property
[x.(((X1 (x) Y1 (x))) ((X1 (x) Z1 (x))) ((Y1 (x) Z1 (x))))]
[x.(((X2 (x) Y2 (x))) ((X2 (x) Z2 (x))) ((Y2 (x) Z2 (x))))]
[x.(((X3 (x) Y3 (x))) ((X3 (x) Z3 (x))) ((Y3 (x) Z3 (x))))]
{[(x.Y1 (x) Y3 (x)) (x.Z1 (x) Z3 (x)) (x.X1 (x) (X3 (x) Z3 (x)))]
[(x.Y2 (x) Y3 (x)) (x.Z2 (x) Z3 (x)) (x.X2 (x) (X3 (x) Z3 (x)))]
[x.CON 1(x) CON 2(x) CON 3(x) CON 4(x)]}
true [r1 , r2 , r3 ], CON 1(x) stands
(Y1 (x) Y2 (x)) (X1 (x) X2 (x) Z1 (x) Z2 (x))
CON 2(x)
y.(x 6= y) [(X1 (y) (X3 (y) Z3 (y))) (Y1 (y) Y3 (y)) (Z1 (y) Z3 (y))
(X2 (y) (X3 (y) Z3 (y))) (Y2 (y) Y3 (y)) (Z2 (y) Z3 (y))]
CON 3(x)
Y1 (x) Z2 (x) y.((X1 (y) X3 (y))),
CON 4(x)
Y2 (x) Z1 (x) y.((X2 (y) X3 (y))).
Thus part follows Theorem 3 Lemma 6, noticing
property written x~y .Q required Theorem 3. part follows
Lemma 6 Lemma 7.
446

fiDiscovering Classes Strongly Equivalent Logic Programs

conditions Lemma 6 (Theorem 8) rather complex, reason
difficult automate Step 3 procedure beginning section.
conditions capture possible cases r3 subsumed r1 r2 , difficult
describe concisely words. give examples.
Consider following three rules:
r1 : (a2 a1 )
r2 : (a3 a1 )
r3 : (a3 a2 ).
{r1 , r2 , r3 } 'se {r1 , r2 } condition (4) Lemma 6 holds.
However, change r3 r30 : a2 a3 , P1 = {r1 , r2 , r30 } P2 = {r1 , r2 }
strongly equivalent: one could check condition (4.3) Lemma 6 hold,
indeed, P2 {a1 a2 } unique answer set {a3 }, P1 {a1 a2 } two
answer sets {a3 } {a1 , a2 }.
also easy show Theorem 8 a3 a2 subsumed
{(a1 ; a2 ; a3 ), (a2 ; a3 a1 )},
a2 ; a3 subsumed
{(a2 a1 ), (a3 a1 )}.
results have, following theorem yield solution 0-2-1
problem.
Theorem 9 (the 0-2-1 problem) three rules r1 , r2 r3 , {r1 , r2 } {r3 }
strongly equivalent iff following three conditions true:
1. {r1 , r2 , r3 } 'se {r1 , r2 }.
2. {r1 , r3 } 'se {r3 }.
3. {r2 , r3 } 'se {r3 }.
example,
{(a2 a1 , a3 ), (a1 ; a2 a3 )} 'se {a2 a3 }.

{( a2 , a3 ), ( a3 , a2 )} 'se { a3 },

{(a1 a2 , a3 ), (a1 a3 , a2 )} 6'se {a1 a3 }.
Similarly, following theorem
Theorem 10 (the 0-2-2 problem) four rules r1 , r2 , r3 , r4 , {r1 , r2 } {r3 , r4 }
strongly equivalent iff following four conditions true:
447

fiLin & Chen

1. {r1 , r2 , r3 } 'se {r1 , r2 }.
2. {r1 , r2 , r4 } 'se {r1 , r2 }.
3. {r3 , r4 , r1 } 'se {r3 , r4 }.
4. {r3 , r4 , r2 } 'se {r3 , r4 }.

6. Program Simplification
mentioned one possible use notion strongly equivalent logic programs
simplifying logic programs: P 'se Q, Q simpler P ,
replace P program contains Q.
answer set programming systems perform program simplifications. However,
Smodels (Niemela et al., 2000) stand-alone front-end called lparse
used ground simplify given logic program. seems lparse simplifies grounded
logic program computing first well-founded model. not, however, perform
program simplification using notion strong equivalence. instance, lparse-1.0.13,
current version lparse, nothing following set rules:
{(a b), (b a), (a a)}. replace first rule following
program {(a a), (a b), (b a)} constraint a.
unlikely anyone would intentionally writing rules like b a, a.
type rules arise result grounding rules variables.
instance, following typical recursive rule used logic programming encoding
Hamiltonian Circuit problem (Niemela, 1999; Marek & Truszczynski, 1999):
reached(X) arc(Y, X), hc(Y, X), reached(Y ).
instantiated graph cyclic arcs like arc(a, a), rule generates cyclic rules
form reached(X) hc(X, X), reached(X). Unless deleted explicitly, rules
slow many systems, especially based SAT. instance, none graphs
tested using ASSAT self-cycles consisting arc node (Lin & Zhao,
2004). cycles included, ASSAT would run significantly longer.
thus useful consider using results program simplification.
Indeed, transformation rules deleting contain common elements
heads positive bodies proposed (Brass & Dix, 1999), studied
perspective strong equivalence (Osorio et al., 2001; Eiter et al., 2004). results
add new transformation rules. instance, Theorem 7, delete
elements head rule also appear negation-as-failure part rule.
Theorems 6, 8, 9 also used define new transformation rules.

7. Concluding Remarks Future Work
Donald Knuth, Forward (Petkovsek et al., 1996), said
Science understand well enough explain computer. Art
everything else do. ...Science advances whenever Art becomes Science.
448

fiDiscovering Classes Strongly Equivalent Logic Programs

state Art advances too, people always leap new
territory understood old.
hope work, one step closer making discovering classes strongly
equivalent logic programs Science.
mentioned methodology used paper similar (Lin,
2004). cases, plausible conjectures generated testing domains
small sizes, general theorems proved aid verification conjectures
general case. However, plausible conjectures generated automatically
(Lin, 2004), done manually here. verifications conjectures
(Lin, 2004) done automatically well, done semi-automatically here.
Overcoming two weaknesses focus future work. Specifically, would
like make Step 3 procedure Section 5 automatic, prove theorem similar
Theorem 3 automate proofs parts theorems like Theorems 5 8, way Theorem 3 makes proofs parts theorems
automatic. way, would able discover interesting theorems area,
easily!

Acknowledgments
extended abstract paper appeared Proceedings IJCAI2005. thank Yan
Zhang comments earlier version paper. also thank anonymous
reviewers useful comments, especially one pointing error
Lemma 4 earlier version paper. work supported part
Research Grants Council Hong Kong Competitive Earmarked Research Grant
HKUST6170/04E. Part second authors work done student Sun
Yat-Sen University, Guangzhou, China, visiting scholar Department Computer
Science Engineering, Hong Kong University Science Technology, Hong Kong.

References
Brass, S., & Dix, J. (1999). Semantics (disjunctive) logic programs based partial
evaluation. Journal Logic Programming, 40 (1), 146.
Chen, Y., Lin, F., & Li, L. (2005). SELP - system studying strong equivalence
logic programs. Proceedings 8th International Conference Logic
Programming Nonmonotonic Reasoning(LPNMR 2005), pp. 442446.
Eiter, T., Fink, M., Tompits, H., & Woltran, S. (2004). Simplifying logic programs
uniform strong equivalence. Proceedings 7th International Conference
Logic Programming Nonmonotonic Reasoning(LPNMR 2004), pp. 8799.
Erdem, E., Lifschitz, V., Nakhleh, L., & Ringe, D. (2003). Reconstructing evolutionary
history indo-european languages using answer set programming. Proceedings
5th International Symposium Practical Aspects Declarative Languages(PADL
2003), pp. 160176.
449

fiLin & Chen

Gelfond, M., & Lifschitz, V. (1988). stable model semantics logic programming.
Proceedings 5th International Conference Symposium Logic Programming(ICLP/SLP), pp. 10701080.
Gelfond, M., & Lifschitz, V. (1991). Classical negation logic programs disjunctive
databases. New Generation Computing, 9 (3/4), 365386.
Inoue, K., & Sakama, C. (2004). Equivalence logic programs updates. Proceedings 9th European Conference Logics Artificial Intelligence(JELIA), pp.
174186.
Lenat, D. B. (1979). automated scientific theory formation: case study using
program. Machine Intelligence 9, pp. 251283. Jean Hayes, Donald Michie, L.
I. Mikulich, eds. Ellis Horwood.
Leone, N., Pfeifer, G., Faber, W., Eiter, T., Gottlob, G., Perri, S., & Scarcello, F. (2006).
DLV system knowledge representation reasoning. ACM Transactions
Computational Logic, 7 (3).
Lierler, Y., & Maratea, M. (2004). Cmodels-2: SAT-based answer set solver enhanced
non-tight programs. Proceedings 7th International Conference Logic
Programming Nonmonotonic Reasoning(LPNMR 2004), pp. 346350.
Lifschitz, V. (1999). Action languages, answer sets planning. Logic Programming
Paradigm: 25-Year Perspective. K.R. Apt, V.W. Marek, M. Truszczynski, D.S.
Warren, eds, Springer-Verlag.
Lifschitz, V., Pearce, D., & Valverde, A. (2001). Strongly equivalent logic programs. ACM
Transactions Computational Logic, 2 (4), 526541.
Lin, F. (2002). Reducing strong equivalence logic programs entailment classical
propositional logic. Proceedings 8th International Conference Principles
Knowledge Representation Reasoning(KR2002), pp. 170176.
Lin, F. (2004). Discovering state invariants. Proceedings 9th International Conference Principles Knowledge Representation Reasoning(KR2004), pp. 536
544.
Lin, F., & Zhao, Y. (2004). ASSAT: computing answer sets logic program sat solvers.
Artificial Intelligence, 157 (1-2), 115137.
Marek, V. W., & Truszczynski, M. (1999). Stable logic programming - alternative logic
programming paradigm. Logic Programming Paradigm: 25-Year Perspective.
K.R. Apt, V.W. Marek, M. Truszczynski, D.S. Warren, eds, Springer-Verlag.
Niemela, I., Simons, P., & Syrjanen, T. (2000).
Smodels: system answer
set programming. Proceedings 8th International Workshop NonMonotonic Reasoning. Breckenridge, Colorado, USA. (CoRR: arXiv:cs.AI/0003033)
http://www.tcs.hut.fi/Software/smodels/.
Niemela, I. (1999). Logic programs stable model semantics constraint programming
paradigm. Annals Mathematics Artificial Intelligence, 25 (3-4), 241273.
450

fiDiscovering Classes Strongly Equivalent Logic Programs

Nogueira, M., Balduccini, M., Gelfond, M., Watson, R., & Barry, M. (2001). A-Prolog
decision support system space shuttle. Proceedings 3rd International
Symposium Practical Aspects Declarative Languages(PADL 2001), pp. 169183.
Osorio, M., Navarro, J. A., & Arrazola, J. (2001). Equivalence answer set programming.
Selected Papers 11th International Workshop Logic Based Program Synthesis
Transformation(LOPSTR 2001), pp. 5775.
Pearce, D., Tompits, H., & Woltran, S. (2001). Encodings equilibrium logic logic
programs nested expressions. Proceedings 10th Portuguese Conference
Artificial Intelligence(EPIA 2001), pp. 306320.
Petkovsek, M., Wilf, H. S., & Zeilberger, D. (1996). = B. Wellesley, Mass. : K Peters.
Turner, H. (2001). Strong equivalence logic programs default theories (made easy).
Proceedings 6th International Conference Logic Programming Nonmonotonic Reasoning(LPNMR 2001), pp. 8192.
Turner, H. (2003). Strong equivalence made easy: nested expressions weight constraints.
Theory Practice Logic Programming, 3 (4-5), 609622.
Wang, K., & Zhou, L. (2005). Comparisons computation well-founded semantics
disjunctive logic programs. ACM Transactions Computational Logic, 6 (2),
295327.

451

fiJournal Artificial Intelligence Research 28 (2007) 267-297

Submitted 05/06; published 03/07

Anytime Heuristic Search
Eric A. Hansen

hansen@cse.msstate.edu

Department Computer Science Engineering
Mississippi State University
Mississippi State, MS 39762 USA

Rong Zhou

rzhou@parc.com

Palo Alto Research Center
3333 Coyote Hill Road
Palo Alto, CA 94304 USA

Abstract
describe convert heuristic search algorithm A* anytime algorithm
finds sequence improved solutions eventually converges optimal solution.
approach adopt uses weighted heuristic search find approximate solution
quickly, continues weighted search find improved solutions well
improve bound suboptimality current solution. time available
solve search problem limited uncertain, creates anytime heuristic search
algorithm allows flexible tradeoff search time solution quality.
analyze properties resulting Anytime A* algorithm, consider performance
three domains; sliding-tile puzzles, STRIPS planning, multiple sequence alignment.
illustrate generality approach, also describe transform memoryefficient search algorithm Recursive Best-First Search (RBFS) anytime algorithm.

1. Introduction
widely-used framework problem-solving artificial intelligence heuristic search
minimum-cost solution path graph. large complex problems, finding optimal
solution path take long time suboptimal solution found quickly
may useful. Various techniques modifying heuristic search algorithm
A* allow tradeoff solution quality search time studied. One
approach weight admissible evaluation function make non-admissible (Pohl,
1970a, 1970b; Pearl, 1984). substantial literature weighted heuristic search,
assumption search stops soon first solution found. Analysis
focused characterizing tradeoff time takes find first solution
quality. example, shown cost first solution found
exceed optimal cost factor greater 1+, depends weight (Pearl,
1984; Davis, Bramanti-Gregor, & Wang, 1988). also empirical studies
tradeoff search time quality first solution found (Gasching, 1979;
Korf, 1993).
starting point paper simple observation reason
stop non-admissible search first solution found. continuing search,
sequence improved solutions found eventually converges optimal
solution. possibility continuing non-admissible A* search first solution
c
2007
AI Access Foundation. rights reserved.

fiHansen & Zhou

found suggested Harris (1974), although consider weighted heuristic
search somewhat related approach called bandwidth heuristic search.
aware mention idea proposed strategy creating
Anytime A* algorithm (Hansen, Zilberstein, & Danilchenko, 1997; Zhou & Hansen, 2002).
paper, discuss strategy length evaluate analytically empirically.
refer strategy anytime heuristic search. Anytime algorithms useful
problem-solving varying uncertain time constraints solution
ready whenever stopped (with possible exception initial time period
first solution found) quality solution improves additional
computation time (Zilberstein, 1996). heuristic search many applications,
general method transforming heuristic search algorithm A* anytime
algorithm could prove useful many domains good anytime algorithms
otherwise available.
paper organized follows. Section 2 presents approach transforming
weighted heuristic search algorithm anytime algorithm, shows transform
Weighted A* Anytime A* algorithm. illustrate generality approach,
Section 3 considers Recursive Best-First Search (RBFS), memory-efficient version
A*, shows transform Weighted RBFS Anytime RBFS algorithm.
Section 4 discusses related work, including related approach creating Anytime A*
algorithm recently proposed.

2. Anytime A*
begin section brief review standard A* Weighted A* algorithms.
describe transform Weighted A* Anytime A* algorithm. analyze
theoretical properties resulting algorithm evaluate performance three
test domains; sliding-tile puzzles, STRIPS planning, multiple sequence alignment.
2.1 A*
A* algorithm (Hart, Nilsson, & Raphael, 1968) uses two lists, Open list Closed
list, manage systematic search minimum-cost path start node goal
node graph. Initially, Open list contains start node Closed list empty.
cycle algorithm, promising open node expanded, moved
Closed list, successor nodes inserted Open list. Thus, Closed list
contains nodes expanded, generating successor nodes,
Open list contains nodes generated, yet expanded. search
terminates goal node selected expansion. solution path extracted
tracing node pointers backwards goal node start node.
order nodes expanded determined node evaluation function
f (n) = g(n) + h(n), g(n) cost best path currently known start
node node n, h(n) heuristic estimate h (n), cost best path n
goal node. behavior A* depends large part heuristic h(n) guides
search. h(n) admissible, is, never overestimates h (n), nodes
expanded order f (n), first goal node selected expansion guaranteed
optimal. heuristic said consistent h(n) c(n, n0 ) + h(n0 ) n n0 ,
268

fiAnytime Heuristic Search

c(n, n0 ) cost edge node n node n0 . h(n) consistent nodes
expanded order f (n), g-cost node guaranteed optimal
node selected expansion, node never expanded once. Note
consistency implies admissibility, non-admissibility implies inconsistency.
h(n) consistent, possible A* find better path node
node expanded. case, improved g-cost node needs propagated
descendants. way A* usually reopening nodes, is,
moving node Closed list Open list g-cost improved.
node eventually reexpanded, improved g-cost propagated successor nodes,
may need reopened also. result, node expanded multiple
times. Although rarely used practice, various techniques introduced bound
worst-case number node reexpansions (Bagchi & Mahanti, 1983; Bagchi & Srimani,
1985).
2.2 Weighted A*
difficult search problems, A* may take long find optimal solution,
approximate solution found relatively quickly useful. Beginning
Pohl (1970a, 1970b), many researchers explored effect weighting terms g(n)
h(n) node evaluation function differently, order allow A* find boundedoptimal solution less computational effort. approach, called Weighted A*
(WA*), node evaluation function defined f 0 (n) = g(n) + w h(n),
weight w 1.0 parameter set user. Sometimes node evaluation function
defined f 0 (n) = (1w0 )g(n)+w0 h(n), equivalent f 0 (n) = g(n)+wh(n)
w
. use notation f 0 (n) distinguish weighted evaluation function
w0 = 1+w
unweighted f (n). w > 1.0, search admissible (first) solution
found may optimal, although usually found much faster. h(n) admissible,
suboptimality solution found weighted heuristic search bounded: solution
cost cannot greater optimal cost factor w (Davis et al., 1988).
solution said -admissible = w 1.0. weighted heuristic accelerates
search solution makes nodes closer goal seem attractive, giving
search depth-first aspect implicitly adjusting tradeoff search effort
solution quality. Weighted heuristic search effective search problems
close-to-optimal solutions, often find close-to-optimal solution small fraction
time takes find optimal solution.
variations weighted heuristic search studied. approach called
dynamic weighting adjusts weight depth search (Pohl, 1973; Koll &
Kaindl, 1992). Another approach uses weighted heuristic identify subset open nodes
expanded without loss -admissibility; subset, selects node
expand next based criteria (Pearl & Kim, 1982; Davis et al., 1988). Weighted
heuristic search used search algorithms besides A*, including memoryefficient versions A* IDA* RBFS (Korf, 1993), well Learning RealTime A* (LRTA*) (Shimbo & Ishida, 2003), heuristic search algorithms AND/OR
graphs (Chakrabarti, Ghosh, & DeSarkar, 1988; Hansen & Zilberstein, 2001).
269

fiHansen & Zhou

2.3 Anytime Weighted A*
consider Weighted A* transformed anytime algorithm
finds sequence improved solutions eventually converges optimal solution.
transformation example general approach transforming search
algorithm explores nodes best-first order, A*, anytime algorithm.
approach consists following three changes.
1. non-admissible evaluation function, f 0 (n) = g(n) + h0 (n), heuristic h0 (n)
admissible, used select nodes expansion order allows good,
possibly suboptimal, solutions found quickly.
2. search continues solution found, order find improved solutions.
3. admissible evaluation function (i.e., lower-bound function), f (n) = g(n) + h(n),
h(n) admissible, used together upper bound optimal solution
cost (given cost best solution found far), order prune search
space detect convergence optimal solution.
paper, use weighted heuristic create non-admissible evaluation function guides search. is, assume admissible heuristic h(n),
use create weighted heuristic h0 (n) = w h(n). three-step approach
creating anytime heuristic search algorithm use non-admissible heuristic
helps A* find approximate solution quickly; limited weighted heuristic
search. general approach used transform A* anytime algorithm,
call resulting algorithm Anytime A*. special case non-admissible
evaluation function weighted heuristic, call algorithm Anytime Weighted A*
Anytime WA*.
Algorithm 1 shows high-level pseudocode Anytime WA*. (Some details
unaffected transformation WA* anytime algorithm, extracting
solution path, omitted.) Note implementation Anytime A* tests whether
node goal node soon node generated selected
expansion, A*, since improve currently available solution quickly.
Besides continuing search first solution found, Anytime WA* uses bounds
prune search space. sequence improved solutions found Anytime WA*
provides sequence improved upper bounds optimal solution cost. Anytime WA*
tests whether f -cost newly-generated node less current upper bound.
not, node inserted Open list since cannot lead improved solution.
inserting suboptimal nodes Open list, memory requirements
algorithm reduced.1 time improved solution found upper bound
decreases, possible nodes already Open list may f -cost equal
greater new upper bound. Although nodes could immediately
1. possibility using bounds optimal solution cost reduce number nodes stored
Open list suggested least twice literature. Harris (1974, p. 219) points
done bandwidth heuristic used guide search, heuristic
error bounded additive constant. heuristics may easy obtain, however. Ikeda
Imai (1994) describe Enhanced A* algorithm uses previously-computed upper bound limit
number nodes stored Open list. compare Enhanced A* Anytime WA* Section 2.4.3.

270

fiAnytime Heuristic Search

Algorithm 1: Anytime-WA*
Input: start node start
Output: Best solution found error bound
begin
g(start) 0, f (start) h(start), f 0 (start) w h(start)
OP EN {start}, CLOSED , incumbent nil
OP EN 6= interrupted
n arg minxOP EN f 0 (x)
OP EN OP EN \ {n}
incumbent = nil f (n) < f (incumbent)
CLOSED CLOSED {n}
foreach ni Successors(n) g(n) + c(n, ni ) + h(ni ) < f (incumbent)
ni goal node
f (ni ) g(ni ) g(n) + c(n, ni ), incumbent ni
else ni OP EN CLOSED g(ni ) > g(n) + c(n, ni )
g(ni ) g(n) + c(n, ni ), f (ni ) g(ni ) + h(ni ), f 0 (ni ) g(ni ) + w h(ni )
ni CLOSED
OP EN OP EN {ni }
CLOSED CLOSED \ {ni }
else
g(ni ) g(n) + c(n, ni ), f (ni ) g(ni ) + h(ni ), f 0 (ni ) g(ni ) + w h(ni )
OP EN OP EN {ni }
OP EN = error 0
else error f (incumbent) minxOP EN f (x)
output incumbent solution error bound
end

removed Open list, incurs overhead searching Open list every time
upper bound decreases, step included pseudocode. (Of course,
Anytime WA* close running memory, overhead searching
Open list sub-optimal nodes deleted might justified need
recover memory.) algorithm shown pseudocode simply tests f -cost
node expanding it. f -cost equal greater current upper bound,
node expanded. implies related test convergence optimal solution:
Open list empty, currently available solution must optimal.
Anytime WA* requires node expansions A* converge optimal solution, two reasons. First, use weighted heuristic allows expand distinct
nodes A*. Second, weighted heuristic inconsistent means possible
node higher-than-optimal g-cost expanded. better path
node later found, node reinserted Open list improved
g-cost propagated descendants node reexpanded. means
Anytime WA* expand node multiple times.
considering empirical performance Anytime WA*, discuss two important
theoretical properties algorithm: convergence optimal solution, bound
suboptimality currently available solution.
271

fiHansen & Zhou

2.3.1 Convergence
admissible evaluation function, f (n), gives lower bound cost solution
path extension current best path node n. Let incumbent denote
goal node corresponding best solution found far. f (incumbent) upper
bound cost optimal solution. Clearly, reason expand node
f -cost (i.e., lower bound) greater equal current upper bound,
f (incumbent), since cannot lead improved solution. Thus following
convergence test Anytime WA*, and, generally, anytime version A*:
best solution found far optimal unexpanded nodes search frontier
(i.e., Open list) f -cost less f (incumbent).
prove following theorem standard assumptions search graph
finite branching factor minimal edge cost c > 0. also assume solution
exists h(n) 0 nodes n.
Theorem 1 Anytime WA* always terminates last solution finds optimal.
Proof: First show algorithm cannot terminate optimal solution
found. Suppose algorithm terminates finding optimal solution
cost f . sequence upper bounds used execution algorithm
b0 , b1 , ...., bk , b0 = (the upper bound solution found), b1 cost
first solution found, bk cost last solution found. know that,
b0 > b1 > ... > bk > f ,
last inequality holds assumption algorithm terminates
finding optimal solution, is, suboptimal solution.
consider optimal path leading initial state goal state.
assumption optimal solution path found, must node n along
path generated expanded. possible g(n) + h(n) bk .
admissibility h, know
g(n) + h(n) f ,
therefore
: g(n) + h(n) f < bi .
contradiction, follows algorithm cannot terminate optimal
solution found.
Next show algorithm always terminates. already proved
optimal solution found, Open list must include node n
g(n) + h(n) f . Hence,
f 0 (n) = g(n) + w h(n) w (g(n) + h(n)) w f .
establishes upper bound f -cost node expanded Anytime
WA* optimal solution found. finite number nodes
f (n) w f , algorithm must run bounded number steps optimal
solution found. optimal solution found, algorithm expand
node f -cost greater equal f . number nodes
f (n) f also finite, algorithm must eventually terminate.
272

fiAnytime Heuristic Search

2.3.2 Error bound
important property approach creating Anytime A* algorithm
refines upper lower bound optimal cost solution. upper bound
f -cost best solution found far, decreased improved solution
found. lower bound least f -cost currently open node, increased
nodes smallest f -cost expanded.
Although obvious cost best solution found far upper bound,
claim least f -cost currently open node lower bound optimal
solution cost requires justification. First note currently available solution
optimal, optimal solution path must pass currently open node.
Although f -cost open node necessarily lower bound best solution
path passes node, since g-cost open node may suboptimal,
lower bound cost solution path extension current path
node. Since improved path open node (resulting improved g-cost)
must extension already-found path another currently open node lower
f -cost, least f -cost currently open node must lower bound cost
optimal solution path. words, least f -cost currently open node
lower bound optimal solution cost reason lower bound
optimal solution cost branch-and-bound tree search.
upper lower bounds approach search progresses
meet upon convergence optimal solution. (Figure 3 shows example
bounds approach other.) optimal solution found, bound difference
cost currently available solution optimal solution cost given
difference upper lower bounds. error bound expressed
f (incumbent)
approximation ratio, f (incumbent)
, f L denotes lower
f
fL
bound optimal solution cost, f (incumbent) denotes upper bound, f denotes
optimal solution cost. Thus, Anytime A* viewed anytime algorithm two
respects. improves solution time, also improves bound suboptimality
currently available solution.
2.4 Performance evaluation
next consider empirical performance Anytime WA* solving range search
problems. effectiveness depends weight used, weight affects search
performance depends characteristics problem heuristic. set
weight based combination knowledge search problem trial error.
use weight start end search, advantage simplicity.
also shows technique simplest form leads good performance.
possible change weight search, weight adjustment together
methods search control potential improve performance further. postpone
discussion Section 4.1 discuss variant Anytime A* recently
proposed.
search problems unit edge costs, many nodes f -cost tiebreaking rule used systematic search algorithm A* significant effect
number nodes actually expanded. well-known A* achieves best performance
273

fiHansen & Zhou

Figure 1: (a) Performance profiles Anytime WA* using three different weights, averaged
instances Eight Puzzle. (b) Average number nodes stored
expanded Anytime WA* instances Eight Puzzle.

breaks ties favor nodes least h-cost. experimental
comparisons reported paper, A* uses tie-breaking rule. note Anytime
WA* achieve similar tie-breaking behavior without applying rule
using even small weight effect breaking ties favor nodes
least h-cost. Moreover, Anytime WA* usually finds optimal solution prove
optimal (that is, expands nodes f -cost less optimal
f -cost). result, usually expand non-goal nodes f -cost equal
optimal solution cost. consistency experimental comparison, implementation
Anytime WA* uses rule A* uses breaking ties favor nodes
least h-cost. practice, tie-breaking rule omitted implementing Anytime
WA* order reduce run-time overhead.
2.4.1 Sliding-tile puzzle
first test domain consider traditional benchmark lets us illustrate
technique simple well-understood example. Figure 1(a) shows performance profiles
Anytime WA* using three different weights, averaged instances Eight
Puzzle.2 (Performance profiles commonly used model performance anytime
algorithms, show expected solution quality improves function computation

time. problems, define quality solution 1 f f
f .) weight 1.3
seems result best overall performance among three weights, although
dominate performance profiles running times.
2. instances, mean possible starting states fixed goal state. goal state blank
upper left corner tiles arranged numerical order, left-to-right top-down.
use Manhattan distance heuristic.

274

fiAnytime Heuristic Search

A*
Instance
Blocks-8
Logistics-6
Satellite-6
Freecell-3
Psr-46
Depots-7
Driverlog-11
Elevator-12

Len
14
25
20
18
34
21
19
40

Stored
426,130
364,846
3,270,195
5,992,688
7,464,850
21,027,257
22,344,515
12,748,119

Exp
40,638
254,125
2,423,373
2,693,235
7,141,461
7,761,661
6,693,096
12,734,334

Secs
5.2
4.0
151.5
170.0
343.2
367.8
407.0
560.6

Stored
41,166
254,412
2,423,547
2,695,321
7,148,048
7,773,830
6,702,570
12,734,636

AWA* (weight
Exp
41,099
254,748
2,423,566
2,705,421
7,175,275
7,772,091
6,699,143
12,829,775

= 2)
Opt %
0.2%
6.2%
14.3%
1.7%
69.0%
0.5%
1.4%
98.6%

Secs
3.8
3.7
138.8
146.2
348.0
249.1
281.6
569.7

Table 1: Comparison A* AWA* eight benchmark problems biennial
Planning Competitions.

Figure 1(b) shows many nodes Anytime WA* stores expands converges optimal solution, using different weights. (Again, converges optimal
solution, mean lower upper bounds meet algorithm proved
solution optimal.) Using weight 1.3, average increase number
nodes expanded Anytime WA* slight compared number nodes expanded
unweighted A*. Figure 1(b) also shows Anytime WA* using weight 1.3 1.5
stores fewer nodes unweighted A*. weights, reduction memory requirements due using upper bound prune Open list greater increase
memory requirements due expanding distinct nodes.
2.4.2 STRIPS planning
recent years, considerable interest using heuristic search domainindependent STRIPS planning. Influential examples approach HSP
HSPr planners Bonet Geffner (2001), performed well biennial
planning competitions sponsored International Conference Automated Planning
Scheduling (Long & Fox, 2003). HSP solves STRIPS planning problems using A*
search forward start state goal, HSPr uses A* search backwards
goal start state, advantage allows heuristic
computed efficiently. many benchmark planning problems used
planning competition difficult solve optimally, WA* often used find suboptimal
solutions reasonable amount time.
Using Bonets publicly-available implementation HSPr, compared performance
A* Anytime WA* benchmark problems previous planning competitions
could solved optimally A*, using domain-independent admissible max-pair
heuristic described Haslum Geffner (2000). used weight 2.0 experiments. instances, Anytime WA* converged optimal solution using less
memory A*. (but all) instances, also took less time. Table 1 compares performance A* Anytime WA* (AWA*) hardest solvable instances
275

fiHansen & Zhou

Instance
Blocks-8
Logistics-6
Satellite-6
Freecell-3
Psr-46
Depots-7
Driverlog-11
Elevator-12

AWA* (weight = 5)
Exp Opt %
Secs
42,293
0.2%
3.9
274,047
4.6%
3.8
2,458,452
8.9%
138.7
> 35,639,419
N/A > 2,207.6
7,310,349 10.0%
350.6
7,902,183
0.4%
250.7
6,814,696
1.2%
281.1
12,851,075 76.0%
557.5

AWA* (weight = 10)
Exp Opt %
Secs
42,293
0.2%
3.9
312,726 11.0%
4.3
2,585,074 13.2%
144.8
> 73,712,127
N/A > 4,550.5
7,623,007
4.8%
365.1
8,115,603
1.9%
254.7
7,674,956 18.0%
322.4
13,145,547 21.4%
568.0

Table 2: Performance AWA* weights 5 10 eight benchmark problems
biennial Planning Competitions.

eight planning problems.3 CPU time relatively long number
nodes generated stored due significant overhead generating node computing heuristic domain-independent way. Blocks Driverlog domains
largest branching factors, thus space savings using upper bound prevent
insertion suboptimal nodes Open list greatest domains. domain
Anytime WA* expand many 1% nodes A*, usually increased
percentage node expansions fraction this.
column labeled Opt % shows soon Anytime WA* finds turns
optimal solution. percentage number node expansions finding
optimal solution total number node expansions convergence. provides
rough measure anytime performance algorithm. shows
domains, Anytime WA* finds turns optimal solution quickly
spends search time proving solution optimal. However two domains
(Psr-46 Elevator-12), Anytime WA* find solution relatively late.
domains, solutions found sooner weight increased. Table 2
shows performance Anytime WA* using weights 5 10. Using higher
weights, anytime performance better last two problems, especially Elevator-12,
although worse others. Even weights 5 10, Anytime WA*
tends outperform A* solving first five problems. sixth problem, Freecell-3,
different. weight 5, Anytime WA* cannot find solution running
memory. weight 10, number stored nodes (since exhausts
amount memory) number expanded nodes (and CPU time)
doubles node reexpansions weight increases. results
clearly show effect weight search performance vary domain.
Given variability, trial error selecting weight appears inevitable.
appropriate weight used, Anytime Weighted A* consistently beneficial.

3. experiments performed Intel Xeon 3.0GHz processor 2MB L2 cache 2GB
RAM

276

fiAnytime Heuristic Search

2.4.3 Multiple sequence alignment
Alignment multiple DNA protein sequences plays important role computational
molecular biology. well-known problem formalized shortest-path
problem n-dimensional lattice, n number sequences aligned (Carillo & Lipman, 1988; Yoshizumi, Miura, & Ishida, 2000). A* outperform dynamic programming solving problem using admissible heuristic limit number
nodes lattice need examined find optimal alignment (Ikeda & Imai,
1999). However, challenging feature search problem large branching factor,
equal 2n 1. A* applied problem, large branching factor
means Open list much larger Closed list, memory required
store Open list becomes bottleneck algorithm.
Two solutions problem proposed literature. Yoshizumi et
al. (2000) describe extension A* called A* Partial Expansion (PEA*). Instead
generating successors node expanded, PEA* inserts
promising successors Open list. partially expanded node reinserted
Open list revised f -cost equal least f -cost successors
yet generated, node reexpanded later. Use technique
significantly reduces size Open list, PEA* solve larger multiple sequence
alignment problems A*. Unfortunately, reduced space complexity PEA*
achieved cost node reexpansion overhead. tradeoff space time
complexity adjusted setting cutoff value C, implicitly determines many
successor nodes add Open list time.
Another way reduce size Open list insert nodes Open list
f -cost equal greater previously established upper bound cost
optimal solution, since nodes never expanded A*. approach
proposed Ikeda Imai (1999), call Enhanced A* (EA*). suggest one
way obtain upper bound use solution found Weighted A* search
weight w > 1, although report experimental results using technique.
anytime algorithm provides third approach reducing size Open list.
also use Weighted A* quickly find solution provides upper bound pruning
Open list. first solution found may optimal, weighted search
continued order find sequence improved solutions eventually converges
optimal solution. provides sequence improved upper bounds
reduce size Open list.
Figure 2 compares performance Anytime WA* (AWA*) performance A*
Partial Expansion Enhanced A* aligning five sequences set dissimilar
(and thus difficult align) sequences used earlier experiments (Kobayashi & Imai, 1998).
cost function Dayhoffs PAM-250 matrix linear gap cost 8. admissible
heuristic standard pairwise alignment heuristic, (almost negligible) time
needed compute heuristic included running time search.
three algorithms require much less memory standard A* solving problem.
found good weight Anytime WA* solving test problem 100
99 , is,
g-cost weighted 99 h-cost weighted 100. (Because cost function
multiple sequence alignment integer-valued, use weighting scheme preserves
277

fiHansen & Zhou

Figure 2: Average performance search algorithms aligning sets 5 sequences
Kobayashi Imai (1998).

integer f -costs allow efficient integer-valued arithmetic.) create upper bound
Enhanced A*, ran Weighted A* weight 100
99 used cost
first solution found upper bound.
Figure 2 shows Anytime WA* runs seven times faster stores
number nodes PEA* cutoff C = 0. PEA* uses cutoff
C = 50, stores 44% nodes Anytime WA* still runs 65% slower
average. Although Enhanced A* runs fast Anytime WA*, stores 36%
nodes. Anytime WA* stores fewer nodes continuation weighted search results
discovery improved solutions provide tighter upper bounds pruning Open list.
summary, Anytime WA* outperforms standard A* solving problem,
performs better two state-of-the-art enhancements A* specifically designed
problem.
Figure 3 illustrates behavior Anytime WA* showing upper lower
bounds gradually converge. Notice Anytime WA* finds optimal solution
10% total search time, spends remaining 90% time proving
solution optimal, point converges. Compared Partial Expansion A*
Enhanced A*, important advantage Anytime WA* finds suboptimal
alignment quickly continues improve alignment additional computation
time. Thus, offers tradeoff solution quality computation time
prove useful finding optimal alignment infeasible.
weight found worked well problem may seem surprisingly small,
one might suspect weight small little effect order
nodes different f -costs expanded, serves primarily tie-breaking rule
nodes f -cost different h-costs. implementations A*
Anytime WA* break ties favor nodes least h-cost, however, weight
effect tie breaking experiments.
couple reasons small weight effective search problem.
First, search graph multiple sequence alignment non-uniform edge costs.
278

fiAnytime Heuristic Search

Figure 3: Convergence bounds Anytime WA* aligning sets 5 sequences
Kobayashi Imai (1998).

result, range f -costs much greater test problems,
unit edge costs. Second, f -costs h-costs much larger problem
test problems part, edge costs larger (given cost
function used), and, part, search space deeper. (The protein sequences
aligned average length 150, means search least
deep.) search problem, optimal f -costs around 50, 000.
pairwise alignment heuristic used solving problem accurate, largest h-costs
also around 50, 000. Given h-costs large wide range f -costs, weight 100
99
significant effect order node expansions. serves illustrate
appropriate weight Anytime WA* depends characteristics search problem.
2.4.4 Discussion
results show Anytime WA* effective wide range search problems.
general, effective search problem whenever Weighted A* effective. others
observed, Weighted A* usually find solution much faster A* A* spends
time discriminating close-to optimal solutions order determine
optimal (Pearl, 1984, p. 86). Indeed, test results show Anytime WA*
often finds turns optimal solution relatively quickly, spends
search time proving solution optimal.
One surprising results experiments Anytime WA* using appropriate weight sometimes converge optimal solution using less memory even
less time A*. surprising well-known A* using consistent
heuristic optimally efficient terms number nodes expanded (Dechter &
Pearl, 1985). However necessarily optimally efficient measures search
complexity, including memory requirements running time. Anytime WA* sometimes
efficient measures search performance, even though requires
node expansions find provably optimal solution. reason improved solutions found anytime approach provide upper bounds used
279

fiHansen & Zhou

reduce number nodes stored Open list. resulting savings, memory
time overhead managing Open list, sometimes greater additional
overhead increased node expansions.
experiments, used relatively low weights result fast convergence
well good anytime performance. shows A* transformed anytime
algorithm exchange little delay convergence optimal solution.
mean recommend weight used Anytime WA* always
set low enough minimize memory use time takes find provably optimal
solution. search problems, could advantage use higher weights
attempt find approximate solutions quickly. cases, increasing weight
used Anytime WA* allows approximate solution found sooner, increases
number node expansions convergence optimal solution. end,
best weight depends preferences time-quality tradeoffs.
focused use weighted heuristic search create anytime heuristic
search algorithm. fact, non-admissible heuristic could used guide
Anytime A* algorithm, pointed beginning Section 2.3. possible (and
even seems likely) informative, inadmissible, heuristic could sometimes lead
better anytime search performance weighted admissible heuristic. case,
Anytime A* would use two heuristics non-admissible heuristic select order
node expansions, another, admissible heuristic, prune search space detect
convergence optimal solution. interesting direction exploration.
contribution paper show approach simple weighting
admissible heuristic creates effective anytime algorithm many search problems.

3. Anytime RBFS
well-known scalability A* limited memory required store
Open Closed lists. also limits scalability Anytime A*. Several variants
A* developed use less memory, including algorithms require linear
space depth search. show transform one them, Recursive
Best-First Search, RBFS (Korf, 1993), anytime algorithm. Besides showing
create linear-space anytime heuristic search algorithm, helps illustrate
generality approach showing another weighted heuristic search algorithm
transformed anytime heuristic search algorithm similar way, continuing
weighted search first solution found.
begin section brief review RBFS algorithm. consider
two approaches using weighted evaluation function RBFS, one
studied alternative show advantages. Finally, discuss
transform Weighted RBFS Anytime Weighted RBFS algorithm. use
Fifteen Puzzle test domain, larger version sliding-tile puzzle
A* cannot solve optimally memory limitations. RBFS saves memory
storing generated nodes, slowed excessive node regenerations solving
graph-search problems many duplicate paths. result, RBFS effective (in
terms time efficiency) either STRIPS planning multiple sequence alignment.
280

fiAnytime Heuristic Search

3.1 Recursive Best-First Search (RBFS)
Recursive best-first search, RBFS (Korf, 1993), general heuristic search algorithm
expands frontier nodes best-first order, saves memory determining next
node expand using stack-based backtracking instead selecting nodes Open
list. stack contains nodes along path start node node currently
visited, plus siblings node path. Thus memory complexity
RBFS O(db), depth search b branching factor.
RBFS similar recursive implementation depth-first search, difference
uses special condition backtracking ensures nodes expanded
(for first time) best-first order. Instead continuing current path far
possible, ordinary depth-first search, RBFS keeps track f -cost best
alternative path available ancestor current node, passed
argument recursive function. f -cost current path exceeds threshold,
called local cost threshold, recursion unwinds back alternative path.
recursion unwinds, RBFS keeps track f -cost best unexpanded node
frontier forgotten subtree saving stored value F (n). stored values,
one node n stack, used RBFS decide path expand next
point search. F (n) least f -cost unexpanded node
frontier subtree rooted node n, stored values propagated successor
nodes successor generation. node previously expanded, (propagated)
stored value greater static evaluation, RBFS uses fact detect
previously expanded nodes regenerate subtrees efficiently.
Among advantages RBFS, Korf points expands nodes best-first
order even evaluation function nonmonotonic. illustrate nonmonotonic
evaluation function, considers RBFS using weighted evaluation function.
3.2 Weighted RBFS
Like A*, RBFS use weighted heuristic trade solution quality search time.
Algorithm 2 gives pseudocode recursive function RBFS using weighted
evaluation function. RBFS algorithm described Korf, although
notation slightly adjusted show weighted values F 0 stored stack
instead unweighted values F , local cost threshold B 0 weighted value.
RBFS initially invoked, three arguments start node, (weighted)
evaluation start node, cost threshold infinity. Using weighted evaluation
function, RBFS expands nodes (for first time) order weighted evaluation
function, f 0 , instead order unweighted evaluation function, f . Korf (1993)
considers approach Weighted RBFS presents empirical study tradeoff
offers search time solution quality.
motivate another approach weighted heuristic search using RBFS, introduce
distinction two search frontiers maintained RBFS. stored values, denoted
F (n) F 0 (n), keep track best unexpanded node frontier subtree rooted
node n stack. call virtual frontier RBFS actually
store frontier memory, uses stored values represent regenerate
frontier. introduce term stack frontier refer frontier RBFS actually
281

fiHansen & Zhou

Algorithm 2: RBFS (using weighted evaluation function)
Input: node n, F 0 (n), threshold B 0
begin
n goal node output solution path exit algorithm
Successors(n) = return
foreach ni Successors(n), = 1, 2, , |Successors(n)|
g(ni ) g(n) + c(n, ni ), f 0 (ni ) g(ni ) + w h(ni )
f 0 (n) < F 0 (n) F 0 (ni ) max{F 0 (n), f 0 (ni )}
else F 0 (ni ) f 0 (ni )
sort ni increasing order F 0 (ni )
|Successors(n)| = 1 F 0 (n2 )
F 0 (n1 ) < F 0 (n1 ) B 0

F 0 (n1 ) RBFS n1 , F 0 (n1 ), min{B 0 , F 0 (n2 )}
insert n1 sorted order F 0 (ni )
return F 0 (n1 )
end

stores memory. stack frontier consists nodes stack
successor nodes stack.
weighted heuristic search, weighted evaluation function used determine
order expand nodes frontier search. approach Weighted
RBFS shown Algorithm 2, approach adopted Korf (1993), weighted
evaluation function used select order expand nodes virtual
frontier. virtual frontier frontier maintained memory
Weighted A*, using Open list, approach Weighted RBFS expands nodes
order Weighted A* (disregarding tie breaking node regenerations).
Algorithm 3 shows pseudocode alternative approach weighted heuristic
search using RBFS. Like approach shown Algorithm 2, uses weighted evaluation
function continues expand solution path long weighted evaluation
currently-expanding node greater weighted evaluation sibling one
nodes along path. difference instead backing least weighted
evaluation f 0 unexpanded node subtree rooted node n storing
F 0 (n), Algorithm 3 backs least unweighted evaluation f unexpanded node,
stores F (n). f (n) admissible evaluation function, F (n) lower
bound cost best solution found subtree rooted n.
follows H(n) = F (n) g(n) improved admissible heuristic node n. Therefore,
Algorithm 3 use weighted evaluation g(n) + w H(n) = g(n) + w (F (n) g(n))
determine order expand nodes. approach Weighted RBFS, nodes
expanded best-first order weighted evaluation nodes stack frontier,
instead order weighted evaluation nodes virtual frontier.
RBFS general algorithmic scheme use different evaluation functions. Thus,
even uses weighted evaluation function, Korf refers RBFS. make
easier distinguish algorithms, introduce name WRBFS refer
alternative approach weighted heuristic search based RBFS propose.
WRBFS expands nodes stack frontier best-first order evaluation function
282

fiAnytime Heuristic Search

Algorithm 3: WRBFS
Input: node n, F (n), threshold B 0
begin
n goal node output solution path exit algorithm
Successors(n) = return
foreach ni Successors(n), = 1, 2, , |Successors(n)|
g(ni ) g(n) + c(n, ni ), f (ni ) g(ni ) + h(ni )
f (n) < F (n) F (ni ) max{F (n), f (ni )}
else F (ni ) f (ni )
sort ni increasing order F (ni )
|Successors(n)| = 1 F (n2 )
g(n2 )
F (n1 ) <
g(n
)
+
w

F (n1 ) g(n1 ) B 0
1


F (n1 ) WRBFS n1 , F (n1 ), min{B 0 , g(n2 ) + w F (n2 ) g(n2 ) }
insert n1 sorted order F (ni )
return F (n1 )
end

F 0 (n) = g(n) + w H(n), instead expanding nodes virtual frontier order
evaluation function f 0 (n) = g(n) + w h(n). Since F 0 (n) = g(n) + w H(n) improves
search, static evaluation function, another reason using
name WRBFS. Note w = 1, unweighted RBFS, difference
behavior two algorithms; expanding nodes best-first order evaluation
stack frontier equivalent expanding nodes best-first order evaluation
virtual frontier. difference one considers whether apply
weight greater 1 heuristic stack frontier virtual frontier.
Figure 4 compares performance two approaches Weighted RBFS solving
Korfs (1985) 100 random instances Fifteen Puzzle. Figure 4(a) shows average
length solutions found algorithm, using weights ranging 1.0 5.0
increments 0.1. WRBFS finds better-quality solutions RBFS using weighted
evaluation function weight, difference increases weight.
since WRBFS also take longer find solution, consider time-quality tradeoff
offered algorithm. Figure 4(b), similar Figure 10 article
Korf (1993), plots solution length versus time (measured number recursive calls)
solving Fifteen Puzzle examples, using solution lengths ranging 53 85
algorithms. time-quality tradeoff offered two algorithms similar,
modest advantage WRBFS. striking WRBFS offers smooth timequality tradeoff, whereas tradeoff offered RBFS using weighted evaluation function
irregular. Sometimes, increasing weight used RBFS causes take longer find
solution, instead less time. dramatic example increasing weight 1.0
1.1 causes RBFS weighted evaluation function take three times longer find
(potentially suboptimal) solution unweighted RBFS takes find optimal solution.
Korf (1993) gives reason irregular time-quality tradeoff. node regeneration overhead RBFS grows number iterations algorithm,
number times local cost threshold increases, since iteration requires regeneration
subtrees. one iteration distinct f -cost, or, case RBFS using
283

fiHansen & Zhou

Figure 4: Comparison RBFS using weighted evaluation function WRBFS solving
Korfs 100 random instances Fifteen Puzzle. Panel (a) shows solution
quality function heuristic weight. Panel (b) shows time-quality tradeoff
algorithm plotting number recursive calls solution quality.

weighted evaluation function, distinct f 0 -cost. irregular time-quality tradeoff
caused fluctuation number distinct f 0 -costs weight increases, leads
fluctuation number iterations. number distinct f 0 -costs many
number distinct pairs g-cost h-cost, actual number depends
weight, since different pairs g-cost h-cost may sum f 0 -cost, depending
weight. Increasing weight 1.0 1.1, example, significantly increases
number distinct f 0 -costs, explains RBFS using weighted evaluation
function takes longer find solution case. advantage using WRBFS
stored value node stack minimum f -cost frontier
subtree rooted node, instead minimum f 0 -cost, thus number
iterations affected variation number distinct f 0 -costs weight
increased. result, adjusting weight creates smoother time-quality tradeoff.
approaches Weighted RBFS well-motivated offer useful tradeoff
search time solution quality. original approach expands frontier nodes
best-first order weighted evaluation function f 0 (n) = g(n) + w h(n), and,
respect, closer Weighted A*. seen, alternate approach
advantage allows smoother time-quality tradeoff. consider transform
two approaches Weighted RBFS anytime heuristic search algorithm,
see alternate approach advantages well.
3.3 Anytime Weighted RBFS
straightforward transform either approach Weighted RBFS anytime
algorithm. Algorithm 4 shows pseudocode recursive function Anytime WRBFS.
couple differences Weighted RBFS algorithm WRBFS
284

fiAnytime Heuristic Search

Algorithm 4: Anytime WRBFS
Input: node n, F (n), threshold B 0
begin
n goal node return f (n)
Successors(n) = return
foreach ni Successors(n), = 1, 2, , |Successors(n)|
g(ni ) g(n) + c(n, ni ), f (ni ) g(ni ) + h(ni )
ni goal node f (ni ) < f (incumbent)
incumbent ni
save (or output) incumbent solution path
f (ni ) f (incumbent) F (ni )
else f (n) < F (n) F (ni ) max{F (n), f (ni )}
else F (ni ) f (ni )
sort ni increasing order F (ni )
|Successors(n)| = 1 F (n2 ) g(n2 )


F (n1 ) < f (incumbent)and g(n1 ) + w F (n1 ) g(n1) B 0

F (n1 ) Anytime-WRBFS n1 , F (n1 ), min{B 0 , g(n2 ) + w F (n2 ) g(n2 ) }
insert n1 sorted order F (ni )
return F (n1 )
end

Anytime Weighted RBFS algorithm. importantly, condition termination different. anytime algorithm finds solution, time finds
improved solution, saves (or outputs) solution continues search.
Anytime Weighted A*, algorithm checks whether node goal node generated, instead waiting expanded. also checks whether f -cost node
greater equal upper bound given f -cost incumbent solution.
so, part search space pruned. (Note first solution found,
f (incumbent) set equal infinity, since yet finite upper bound
optimal solution cost.) Convergence optimal solution detected stack
empty. point, backtracking determined branches tree
searched pruned. Proof termination optimal solution follows similar logic
Theorem 1. suboptimality currently available solution bounded using
f (incumbent) upper bound optimal solution cost least F -cost node
stack frontier lower bound. (Again, stack frontier consists node
end current best path, plus every sibling node along path.)
Figure 5(a) shows performance profiles Anytime WRBFS, averaged Korfs 100
random instances Fifteen Puzzle. Although weights 2.0 1.5 offer better timequality tradeoff short amounts search time, weight 1.3 provides better long-term
performance. Figure 5(b) shows time (measured average number recursive
calls) taken Anytime WRBFS find optimal solutions Fifteen puzzle, using
weights 1.0 2.0 increments 0.1. Using weights 1.2 1.4, converges
optimal solution quickly unweighted RBFS. fact, using weight 1.3,
Anytime WRBFS converges optimal solution average 25% fewer recursive
calls unweighted RBFS. Although always expands many distinct nodes
unweighted RBFS, reliance stack-based backtracking reduce memory use means
285

fiHansen & Zhou

Figure 5: Performance Anytime WRBFS. Panel (a) shows performance profiles using
three different weights, averaged Korfs 100 random instances Fifteen
Puzzle. Panel (b) shows average number recursive calls required converge
optimal solution, using weights 1.0 2.0 increments 0.1,
averaged 100 random instances Fifteen Puzzle.

algorithms revisit nodes multiple times. Figure 5(b) shows
weighted heuristic used Anytime WRBFS reduce number recursive calls;
intuitively, occurs greedier search strategy weighted heuristic search
tends delay reduce backtracking. course, weight increased enough,
number distinct node expansions increases eventually number recursive calls
also increases, Figure 5(b) shows. Nevertheless, demonstration small weight
sometimes improve efficiency finding optimal solutions interesting.
comparison, Figure 6(a) shows performance profiles version Anytime Weighted
RBFS based RBFS using weighted evaluation function, original
approach Weighted RBFS. case, performance profile Anytime Weighted
RBFS using weight 1.3 dominated performance profiles using weights 1.5
2.0. Figure 6(b) shows average number recursive calls taken version
Anytime Weighted RBFS find optimal solutions Fifteen puzzle, using
range weights 1.0 2.0. ensure fair comparison, implemented version
Anytime Weighted RBFS saves admissible F (n) values addition
non-admissible F 0 (n) values, uses F (n) values prune branches search tree
detect convergence optimal solution, instead using static evaluation f (n).
Nevertheless, version Anytime Weighted RBFS converges much slowly.
scale y-axis Figure 6(b) order magnitude greater Figure 5(b),
reflects fact Anytime Weighted RBFS based version Weighted
RBFS takes order magnitude longer converge optimal solution Anytime
WRBFS, using weight.
Fluctuations length time convergence Figure 6(b) caused differences number distinct f 0 -costs weight increases, causing differences
286

fiAnytime Heuristic Search

Figure 6: Performance Anytime Weighted RBFS based RBFS using weighted evaluation function. Panel (a) shows performance profiles using three different weights,
averaged Korfs 100 random instances Fifteen Puzzle. Panel (b) shows
average number recursive calls converge optimal solution, using
weights 1.0 2.0 increments 0.1, averaged instances.
scale y-axis order magnitude greater Figure 5(b).

number iterations resulting fluctuations node regeneration overhead.
similar observed earlier performance approach Weighted RBFS.
explain large difference time takes algorithm converge. least two reasons Anytime WRBFS converges much faster. One
efficient backtracking behavior. Anytime WRBFS expands nodes order
weighted evaluation function stack frontier, instead order weighted
evaluation function virtual frontier, searches greedily deeper levels
stack backtracking shallower levels. Since computationally expensive
regenerate large subtrees rooted shallower nodes stack
smaller subtrees rooted deeper nodes, bias towards backtracking deeper
levels backtracking shallower levels contributes improved convergence time.
Another reason Anytime WRBFS converges much faster effective
improving lower bound optimal solution cost. pointed earlier, anytime
heuristic search often finds turns optimal solution relatively quickly,
spends time proving solution optimal, corresponds
improving lower bound. versions Anytime Weighted RBFS, lower bound
minimum F (n) values stored stack frontier. Although anytime search
algorithm based original version Weighted RBFS guaranteed improve
F 0 (n) value subtree rooted node n iteration, may may improve F (n)
value (which assume also stores). contrast, anytime search algorithm based
WRBFS guaranteed improve F (n) value iteration. improves
admissible F (n) values, instead weighted F 0 (n) values, Anytime WRBFS effective
improving lower bound optimal solution cost, leading faster convergence.
287

fiHansen & Zhou

4. Related Work
section, consider closely-related work. begin considering variant
Anytime A* recently proposed. discuss relationship
Anytime A* variants A* that, directly indirectly, also allow tradeoff
search time solution quality.
4.1 Anytime Repairing A*
Likhachev, Gordon, Thrun (2004) recently introduced interesting variant
Anytime A*, called Anytime Repairing A* (or ARA*), shown
effective real-time robot path planning. approach follows approach creating
Anytime A* algorithm many respects. uses Weighted A* find approximate
solution relatively quickly, continues weighted search find sequence improved
solutions convergence optimal solution. However, introduces two extensions
improve performance. First, solution found, decreases weight
continuing search. Second, uses technique limit node reexpansions. first
extensions, decreasing weight new solutions found, easy consider
independently other, also easily combined Anytime Weighted A*
(AWA*), consider first.
Decreasing weight experiments, used weighted heuristic weight
change search. chose approach simplicity.
Likhachev et al. (2004) argue better performance possible gradually decreasing
weight search. new solution found, ARA* decreases weight
small, fixed amount, continues search. Experimental results show
approach leads improved performance robot path-planning domains.
course, relative performance depend initial weight simply
whether weight remains fixed decreases. Likhachev et al. report three experimental
comparisons AWA* ARA*. one, set initial weight 3; another,
set initial weight 10; third, set initial weight 30. weights
higher found worked well test problems. experiments,
AWA* never changes initial weight whereas ARA* decreases new solutions
found. initial weight set high, might explain decreasing improves
performance. could also setting initial weight high gradually decreasing
effective approach robot path-planning problems consider,
similar problems. Even so, follow best approach problems.
compared Anytime Weighted A* Anytime Repairing A* solving STRIPS
planning problems used testbed Section 2.4.2. Although Likhachev et al.
use upper bounds reduce size Open list implementation ARA*,
easy included enhancement implementation ARA*
order ensure fair comparison. addition decreasing weight, ARA* uses special
repairing technique limit node reexpansions. Since independent idea,
implemented version AWA* decreases weight search use
special technique limiting node reexpansions. itself, decreasing weight
search requires recalculating f 0 -costs reordering Open list whenever weight
288

fiAnytime Heuristic Search

Instances
Blocks-8
Logistics-6
Satellite-6
Freecell-3
Psr-46
Depots-7
Driverlog-11
Elevator-12

AWA* (weight = 2, step = 0.1)
Stored
Exp Opt %
Secs
41,166
40,727
0.2%
3.9
254,412
254,390
6.2%
3.6
2,423,547
2,423,489 14.3% 138.6
2,695,321
2,698,596
1.7% 155.3
7,148,048
7,171,557 69.0% 345.7
7,773,830
7,762,783
0.5% 247.4
6,763,379
6,693,441
4.7% 283.3
12,734,636 12,825,980 98.7% 561.3

ARA* (weight = 2, step = 0.1)
Stored
Exp Opt %
Secs
41,166
42,141
0.2%
3.9
312,438
364,840 87.1%
5.0
2,423,547
2,428,325 14.2% 138.4
4,115,032
5,911,849 68.7% 317.2
7,143,912 11,888,700 35.3% 567.7
7,771,780
7,823,005
0.5% 247.1
6,698,404
6,771,651
1.3% 281.3
12,736,328 12,843,441 97.8% 559.7

Table 3: Comparison AWA* (with decreasing weight) ARA* eight benchmark
problems biennial Planning Competitions.

changed. Table 3 compares performance AWA* ARA* use initial
weight 2.0 decrease weight 0.1 new solution found. planning
instances except Logistics-6, Freecell-3 Psr-46, significant difference
performance significant difference performance performance
AWA* fixed weight 2.0 solving instances. (See Table 1.)
STRIPS planning problems using initial weight, gradually decreasing
weight improve performance. course, could improve performance
problems. case, note easy decrease weight used AWA* without
implementing full ARA* algorithm.
Another potential advantage decreasing weight, Likhachev et al. point out,
provides different way bounding suboptimality solution. solution
found Weighted A* using weight w, one error bound, f (incumbent)
w. Note
f
decreasing bound requires decreasing weight search.
Section 2.3.2, defined different error bound, f (incumbent)
f (incumbent)
,
f
fL
L
f denotes least f -cost currently open node frontier. advantage
error bound decreases even weight remains fixed search.
additional advantage tighter bound. Let nL denote open node
f (nL ) = f L . h(incumbent) = 0 incumbent expanded nL , know

f (incumbent) = f 0 (incumbent) g(nL ) + w h(nL ).
Therefore,
f (incumbent)
g(nL ) + w h(nL )
w (g(nL ) + h(nL ))

<
= w,
fL
g(nL ) + h(nL )
g(nL ) + h(nL )
strict inequality follows assumptions w > 1 g(nL ) > 0.
Although ARA* performs AWA* solving five eight planning
problems, performs worse solving three: Logistics-6, Freecell-3, Psr-46.
Comparing ARA* AWA* initial weight decrease weight
way shows deterioration performance caused decreasing
weight. consider next technique used ARA* limiting node reexpansions.
289

fiHansen & Zhou

Figure 7: Comparison AWA* ARA* solving instances Eight Puzzle.
Panel (a) shows average number nodes stored panel (b) shows
average number node expansions, function initial weight.

Limiting node reexpansions discussed before, complication Anytime Weighted
A* inherits Weighted A* weighted heuristic typically inconsistent.
means possible node higher-than-optimal g-cost expanded.
better path node later found, node reinserted Open list
improved g-cost propagated descendants node reexpanded.
result, Weighted A* Anytime WA* expand node multiple times.
Likhachev et al. note error bound Weighted A* remains valid even node
reexpansions allowed. Since ARA* algorithm performs series Weighted A*
searches decreasing weights, reason ARA* postpones node reexpansions
current iteration Weighted A* finishes weight decreased,
create efficient Anytime A* algorithm. ARA* finds better path
already-expanded node, inserts node list called INCONS order delay node
reexpansion. solution found weight decreased, ARA* moves nodes
INCONS list Open list resumes search.
technique limiting node reexpansions may improve search performance robot
path planning similar search problems, especially using large weights.
relative performance AWA* ARA* solving Logistics-6, Freecell-3, Psr-46
planning instances raises question whether always improves performance.
comparison, Table 7 shows average performance AWA* ARA* solving
instances Eight Puzzle. algorithm initial weight. AWA* never
changes initial weight ARA* reduces increments 0.1 new solutions
found. larger weight makes heuristic inconsistent increases likelihood
AWA* reexpand nodes. Yet results show larger initial weight,
nodes ARA* expands relative AWA*, difference dramatic.
initial weight set 3.0, ARA* expands four times nodes AWA*.
290

fiAnytime Heuristic Search

many cases, takes longer ARA* find initial suboptimal solution takes
unweighted A* find optimal solution.
One reason result limiting node reexpansions cause ARA* expand
distinct nodes. (The fact ARA* stores well expands nodes, shown
Figure 7, indicates expands generates distinct nodes.) Limiting node
reexpansions lead expansion distinct nodes blocks improvement
paths pass node stored INCONS list. blocking improvement
paths, prevent better solutions found. One possibility
solution found Weighted A* passes node stored INCONS
list, means reexpansion propagation improved g-cost postponed.
case, f 0 -cost solution greater would reexpansion node
allowed. Another possibility potentially better solution one found
Weighted A* passes node INCONS list, therefore discovered
improvement blocked. Either way, solution found Weighted A*
allow node reexpansions greater f 0 -cost node reexpansions
allowed. Weighted A* must expand nodes f 0 -cost less
f 0 -cost solution finds, distinct nodes expanded whenever limiting node
reexpansions prevents Weighted A* finding better solution. Figure 7 shows,
effect becomes pronounced increasing weight increases likelihood
first time ARA* expands node, g-cost suboptimal.
results show effect occur search problems, least
degree. seems occur primarily search problems relatively sparse
solutions, sliding-tile puzzle Logistics Freecell planning domains.
solutions sparse, easier nodes lead good solution
expanded higher-than-optimal g-cost, thus likely Weighted A* find
solution worse would found allowed node reexpansions. search
problems huge number solutions equal almost equal cost, limiting node
reexpansions way less likely cause problem. robot path-planning
problems considered Likhachev et al. examples kind search problem,
thus impressive results report inconsistent observations.
yet another way limiting node reexpansions sometimes makes search
performance worse. far, considered search problems ARA* expands
distinct nodes AWA*. Psr-46 planning instance, ARA* expands many
nodes AWA*, store nodes. indicates ARA*
expand distinct nodes AWA*. Instead, performs node reexpansions.
possible ARA* explicitly limits node reexpansions? turns
limiting node reexpansions way ARA* sometimes lead node
reexpansions. time ARA* decreases weight reexpands node propagate
improved path information, reexpanded node many descendants
explicit search graph improved path node originally found.
result, many nodes may need reexpanded propagate improved path
information. Again, always happen. behavior ARA* solving
Psr-46 illustrates possibility.
Figure 7(b) compares average number nodes expanded ARA* AWA*
solving instances Eight Puzzle, show CPU time. initial
291

fiHansen & Zhou

weight 3, ARA* expands 4.5 times nodes AWA*. difference
CPU time actually greater. ARA* takes 7 times longer solve problems
AWA*, average. One reason extra time overhead recalculating f 0 -costs
reordering Open list every time weight decreased. time overhead
negligible STRIPS planning problems compared much greater overhead
domain-independent node generation heuristic calculation. sliding-tile
puzzle, node generation heuristic calculation fast time overhead
recalculating f 0 -costs reordering Open list noticeable effect slowing
search. another example relative performance ARA* AWA*
vary search problem.
summary, idea decreasing weight search used independently
technique limiting node reexpansions. Although gradually decreasing weight
improve performance test problems, could improve performance
problems. However, additional overhead recalculating f 0 -costs reordering
Open list considered. technique limiting node reexpansions also help,
used caution. problems, shown actually
cause significantly node reexpansions expansion distinct nodes.
problems, negative effect. Although show clear benefit
test domains, could improve performance robot path planning similar problems
many close-to-optimal solutions, especially using large weight.
4.2 Real-time A*
anytime approach heuristic search effective real-time search problems
enough time available search optimal solution. Previous work time-limited
heuristic search adopts model Korfs Real-time A* algorithm (RTA*) assumes
search interleaved execution (Korf, 1990). searching bounded amount
time, best next action chosen search-act cycle repeats goal state
reached. Similar examples real-time search strategy include DTA* (Russell &
Wefald, 1991), BPS (Hansson & Mayer, 1990) k-best (Pemberton, 1995). realtime search algorithms commit actions finding complete solution, cannot
find optimal solutions. contrast, assume search phase precedes execution
phase output search complete solution. words, real-time
search algorithms try find best next decision time constraint, whereas
anytime approach tries find best complete solution time constraint.
4.3 Depth-first branch bound Iterative-Deepening A*
Depth-first branch-and-bound (DFBnB) search algorithms effective tree-search
problems, especially many solutions depth, traveling
salesman problem. problems, DFBnB behavior anytime algorithm.
quickly finds solution suboptimal, continues search improved
solutions optimal solution found. even uses cost best solution found
far upper bound prune search space.
search technique combines elements DFBnB A* Iterative-deepening
A* IDA* (Korf, 1985). well-known IDA* performs poorly problems
292

fiAnytime Heuristic Search

real-valued edge costs traveling salesman almost nodes distinct
f -costs. problems, may expand one new node iteration. prevent
excessive iterations node regenerations, several variants IDA* developed
set successive thresholds higher minimum f -cost exceeded previous
threshold (Sarkar, Chakrabarti, Ghose, & DeSarkar, 1991; Rao, Kumar, & Korf, 1991; Wah
& Shang, 1994). result, first solution found guaranteed optimal,
although bounded error. finding initial solution, algorithms revert
DFBnB search ensure eventual convergence optimal solution. approach
reducing node regenerations IDA* side-effect creating anytime algorithm,
although one effective problems IDA* DFBnB effective,
typically tree-search problems.
4.4 Bidirectional A*
Another search technique side-effect creating anytime algorithm Bidirectional A* (Kaindl & Kainz, 1997). approach, two simultaneous A* searches
performed, one start state goal, goal start
state. two search frontiers meet node, two partial solutions combined
create complete solution. Typically, first solution found suboptimal
search must continued find optimal solution. Thus, bidirectional search strategy
side-effect finding succession improved solutions convergence
optimal solution. fact, convergence test used Bidirectional A* detect optimal
solution similar convergence test used Anytime WA*: incumbent solution
cost f (incumbent) optimal unexpanded node f -cost less
f (incumbent) one two directions search, is, one two Open lists
empty. interesting possibility improving bidirectional search use Anytime A*
(instead standard A*) search directions.
4.5 Local-search variants A*
important class anytime search algorithms relies local search form iteratively improve solution. Although local-search algorithms cannot guarantee convergence
optimal solution, scale much better systematic search algorithms.
couple attempts improve scalability A* integrating
form local search. Ratner Pohl (1986) propose two local-search variants A*
improve suboptimal solution path making local searches around segments path.
example, Joint A* divides initial suboptimal solution path segments, and,
segment, uses A* search better path start end states
segment, reduce overall solution cost. Ikeda et al. (1999) propose K-group A* algorithm multiple sequence alignment performs A* groups sequences, instead
individual sequences, order reduce search complexity number sequences
large find optimal alignments. varying groupings, local-search algorithm
created gradually improves alignment computationally feasible way (Zhou &
Hansen, 2004). But, like local-search algorithms, local-search variants A*
guarantee convergence optimal solution.
293

fiHansen & Zhou

5. Conclusion
presented simple approach converting heuristic search algorithm A*
anytime algorithm offers tradeoff search time solution quality.
approach uses weighted heuristic search find initial, possibly suboptimal solution,
continues search improved solutions convergence provably optimal
solution. also bounds suboptimality currently available solution.
simplicity approach makes easy use. also widely applicable.
used search algorithms explore nodes best-first order,
RBFS, shown effective solving wide range search problems.
rule, effective whenever suboptimal solution found relatively quickly
using weighted heuristic, finding provably optimal solution takes much longer.
is, effective whenever weighted heuristic search effective. weight
chosen appropriately, shown approach create search algorithm
attractive anytime properties without significantly delaying convergence provably
optimal solution. conclude anytime heuristic search provides attractive approach
challenging search problems, especially time available find solution
limited uncertain.
Acknowledgments
grateful Shlomo Zilberstein encouragement work, especially
early stages. appreciate helpful comments suggestions anonymous
reviewers, led several improvements paper. also thank Rich Korf
helpful feedback RBFS algorithm. research supported part NSF
grant IIS-9984952 NASA grant NAG-2-1463.

References
Bagchi, A., & Mahanti, A. (1983). Search algorithms different kinds heuristics
comparative study. Journal ACM, 30 (1), 121.
Bagchi, A., & Srimani, P. (1985). Weighted heuristic search networks. Journal Algorithms, 6, 550576.
Bonet, B., & Geffner, H. (2001). Planning heuristic search. Artificial Intelligence, 129 (1),
533.
Carillo, H., & Lipman, D. (1988). multiple sequence alignment problem biology.
SIAM Journal Applied Mathematics, 48 (5), 10731082.
Chakrabarti, P., Ghosh, S., & DeSarkar, S. (1988). Admissibility AO* heuristics
overestimate. Artificial Intelligence, 34 (1), 97113.
Davis, H., Bramanti-Gregor, A., & Wang, J. (1988). advantages using depth
breadth components heuristic search. Ras, Z., & Saitta, L. (Eds.), Methodologies
Intelligent Systems 3, pp. 1928.
294

fiAnytime Heuristic Search

Dechter, R., & Pearl, J. (1985). Generalized best-first search strategies optimality
A*. Journal ACM, 32 (3), 505536.
Gasching, J. (1979). Performance measurement analysis certain search algorithms.
Ph.D. thesis, Carnegie-Mellon University. Department Computer Science.
Hansen, E., Zilberstein, S., & Danilchenko, V. (1997). Anytime heuristic search: First
results. Tech. rep. 97-50, Univ. Massachusetts/Amherst, Dept. Computer Science.
Hansen, E., & Zilberstein, S. (2001). LAO*: heuristic search algorithm finds solutions
loops. Artificial Intelligence, 129 (12), 3562.
Hansson, O., & Mayer, A. (1990). Probabilistic heuristic estimates. Annals Mathematics
Artificial Intelligence, 2, 209220.
Harris, L. (1974). heuristic search conditions error. Artificial Intelligence,
5 (3), 217234.
Hart, P., Nilsson, N., & Raphael, B. (1968). formal basis heuristic determination
minimum cost paths. IEEE Transactions Systems Science Cybernetics (SSC),
4 (2), 100107.
Haslum, P., & Geffner, H. (2000). Admissible heuristics optimal planning. Proceedings
5th International Conference Artifial Intelligence Planning Scheduling
(AIPS-00), pp. 140149. AAAI Press.
Ikeda, T., & Imai, T. (1994). Fast A* algorithms multiple sequence alignment.
Genome Informatics Workshop 94, pp. 9099.
Ikeda, T., & Imai, H. (1999). Enhanced A* algorithms multiple alignments: Optimal
alignments several sequences k-opt approximate alignments large cases.
Theoretical Computer Science, 210 (2), 341374.
Kaindl, H., & Kainz, G. (1997). Bidirectional heuristic search reconsidered. Journal
Artificial Intelligence Research, 7, 283317.
Kobayashi, H., & Imai, H. (1998). Improvement A* algorithm multiple sequence
alignment. Proceedings 9th Workshop Genome Informatics (GIW98),
pp. 120130. Universal Academy Press, Inc.
Koll, A., & Kaindl, H. (1992). new approach dynamic weighting. Proceedings
10th European Conference Artificial Intelligence (ECAI-92), pp. 1617. John
Wiley Sons.
Korf, R. (1985). Depth-first iterative deepening: optimal admissible tree search. Artificial Intelligence, 27 (1), 97109.
Korf, R. (1990). Real-time heuristic search. Artificial Intelligence, 42 (23), 197221.
Korf, R. (1993). Linear-space best-first search. Artificial Intelligence, 62 (1), 4178.
295

fiHansen & Zhou

Likhachev, M., Gordon, G., & Thrun, S. (2004). ARA*: Anytime A* provable bounds
sub-optimality. Advances Neural Information Processing Systems 16: Proceedings 2003 Conference (NIPS-03). MIT Press.
Long, D., & Fox, M. (2003). 3rd international planning competition: Results
analysis. Journal Artificial Intelligence Research, 20, 159.
Pearl, J. (1984). Heuristics: Intelligent search strategies computer problem solving.
Addison-Wesley.
Pearl, J., & Kim, J. (1982). Studies semi-admissible heuristics. IEEE Transactions
Pattern Analysis Machine Intelligence, PAMI-4 (4), 392399.
Pemberton, J. (1995). k-best: new method real-time decision making. Proceedings
14th International Joint Conference Artificial Intelligence (IJCAI-95), pp.
227233. Morgan Kaufmann.
Pohl, I. (1970a). First results effect error heuristic search. Machine Intelligence,
5, 219236.
Pohl, I. (1970b). Heuristic search viewed path finding graph. Artificial Intelligence,
1 (3), 193204.
Pohl, I. (1973). avoidance (relative) catastrophe, heuristic competence, genuine dynamic weighting computational issues heuristic problem-solving. Proceedings
3rd International Joint Conference Artificial Intelligence (IJCAI-73), pp.
1217. Morgan Kaufmann.
Rao, V., Kumar, V., & Korf, R. (1991). Depth-first vs. best-first search. Proceedings
9th National Conference Artificial Intelligence (AAAI-91), pp. 434440.
AAAI/MIT Press.
Ratner, D., & Pohl, I. (1986). Joint LPA*: Combination approximation search.
Proceedings 5th National Conference Artificial Intelligence (AAAI-86),
pp. 173177. AAAI/MIT Press.
Russell, S., & Wefald, E. (1991). Right Thing: Studies Limited Rationality. MIT
Press.
Sarkar, U., Chakrabarti, P., Ghose, S., & DeSarkar, S. (1991). Reducing reexpansions
iterative-deepening search controlling cutoff bounds. Artificial Intelligence, 50 (2),
207221.
Shimbo, M., & Ishida, T. (2003). Controlling learning process real-time heuristic
search. Artificial Intelligence, 146 (1), 141.
Wah, B., & Shang, Y. (1994). comparative study IDA*-style searches. Proceedings
6th International Conference Tools Artificial Intelligence (ICTAI-94),
pp. 290296. IEEE Computer Society.
296

fiAnytime Heuristic Search

Yoshizumi, T., Miura, T., & Ishida, T. (2000). A* partial expansion large branching factor problems. Proceedings 17th National Conference Artificial
Intelligence (AAAI-2000), pp. 923929. AAAI/MIT Press.
Zhou, R., & Hansen, E. (2002). Multiple sequence alignment using Anytime A*. Proceedings 18th National Conference Artificial Intelligence (AAAI-02), pp. 9756.
AAAI/MIT Press.
Zhou, R., & Hansen, E. (2004). K-group A* multiple sequence alignment quasinatural gap costs. Proceedings 16th IEEE International Conference Tools
Artificial Intelligence (ICTAI-04), pp. 688695. IEEE Computer Society.
Zilberstein, S. (1996). Using anytime algorithms intelligent systems. AI Magazine, 17 (3),
7383.

297

fiJournal Artificial Intelligence Research 28 (2007) 119156

Submitted 04/06; published 02/07

Marvin: Heuristic Search Planner
Online Macro-Action Learning
Andrew Coles
Amanda Smith

ANDREW. COLES @ CIS . STRATH . AC . UK
AMANDA . SMITH @ CIS . STRATH . AC . UK

Department Computer Information Sciences,
University Strathclyde,
26 Richmond Street, Glasgow, G1 1XH, UK

Abstract
paper describes Marvin, planner competed Fourth International Planning
Competition (IPC 4). Marvin uses action-sequence-memoisation techniques generate macroactions, used search solution plan. provide overview
architecture search behaviour, detailing algorithms used. also empirically demonstrate
effectiveness features various planning domains; particular, effects performance due use macro-actions, novel features search behaviour, native
support ADL Derived Predicates.

1. Introduction
One currently successful approaches domain-independent planning forwardchaining heuristic search problem state space. Search guided heuristic function
based appropriate relaxation planning problem. Different relaxations explored (Bonet & Geffner, 2000; McDermott, 1996; Hoffmann & Nebel, 2001; Helmert, 2004)
shown result less informative heuristic functions. common relaxation
ignore delete lists actions problem domain, resulting abstracted problem
domain comprised relaxed actions. given state evaluated counting number
relaxed actions needed reach goal state given state. Hoffmann Nebel (2001)
present search strategy called Enforced Hill-Climbing (EHC) which, coupled relaxation
kind, proven empirically effective strategy many planning domains.
planner, FF, performed great success Second Third International Planning Competitions (Bacchus, 2001; Long & Fox, 2003). paper present planner, Marvin,
builds upon search approach.
EHC search strategy performs gradient-descent local search, using breadth-first search
find action sequences leading strictly-better states single-action step able reach
one. embedded exhaustive-search step one bottlenecks planning approach.
present approach that, memoising plateau-escaping action sequences discovered
search, form macro-actions applied later plateaux once-again
encountered. so, planner escape similar plateaux encountered later, without
expensive exhaustive search. resulting planner called Marvin.
begin paper brief review FFs search behaviour provide background
approach. introduce main features Marvin, explaining search behaviour
differs FF. describe three main contributions made Marvin, detailing
c
2007
AI Access Foundation. rights reserved.

fiC OLES & MITH

key algorithms effects performance. Marvin plan STRIPS ADL domains,
also handle derived predicates PDDL2.2. describe way domains
containing derived predicates ADL handled without first reduced STRIPS domains.
Finally, discuss results obtained Marvin Fourth International Planning Competition
(IPC 4) (Hoffmann & Edelkamp, 2005), provide additional ablation studies assess impact
various features planning performance across selection domains.

2. Background
section, give overview background work. First, forward-chaining heuristic planning defined, existing work area described; particular attention paid
planner FF. followed introduction macro-actions.
2.1 Forward-Chaining Planning
Formally, forward-chaining planning described search landscape
node defined tuple < S, P >. world state comprised predicate facts P
plan (a series ordered actions) used reach initial state. Search begins initial
problem state, corresponding tuple < S0 , {} >.
Edges pairs nodes search landscape correspond applying actions lead
one state another. action applied search space node < S, P > node
< 0 , P 0 > reached, 0 result applying action state P 0
determined appending action P . Forward-chaining search landscape
restricted considering moves forwards direction: transitions ever made
node plan P nodes plan P 0 P 0 determined adding (or chaining)
actions end P .
unguided search manner prohibitively expensive smallest problems,
heuristics used guide search. Commonly, heuristic value used provide goal distance
estimate node < S, P > node < 0 , P 0 > 0 goal state.
2.2 Heuristics Forward-Chaining Planning
Many heuristics used guide forward-chaining planners based around solving abstraction original, hard, planning problem planner presented. widely
used abstraction involves planning using relaxed actions, delete effects original
actions ignored. FF, HSP (Bonet & Geffner, 2000) UnPOP (McDermott, 1996) use relaxed
actions basis heuristic estimates, although FF first count number
relaxed actions relaxed plan connecting goal initial state. Although ignoring delete
lists turns powerful relaxation, least class planning domains, relaxations
possible. recently, work done using abstraction based causal graph analysis
(Helmert, 2004).
initial approaches calculating goal distance estimates, taken planners HSP,
calculated cost reaching goal state state evaluated forwards
reachability analysis state given goal appears. Two heuristics derived
information: either maximum steps-to-goal valuesan admissible heuristic;
sum steps-to-goal valuesan inadmissible heuristic, practice informative.
120

fiM ARVIN : H EURISTIC EARCH P LANNER NLINE ACRO -ACTION L EARNING

1:
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
17:
18:
19:
20:

Procedure: EHCSearch
open list = [initial state];
best heuristic = heuristic value initial state;
open list empty
current state = pop state head open list;
successors = list states visible current state;
successors empty
next state = remove state successors;
h = heuristic value next state;
next state goal state
return next state;
end
h better best heuristic
clear successors;
clear open list;
best heuristic = h;
end
place next state back open list;
end
end

Figure 1: Enforced Hill-Climbing Search

disadvantage latter approaches ignores positive interactions (shared
actions) action sequences goal: problem addressed
heuristic used FF. FF, planning graph (Blum & Furst, 1995) built forward current
state using relaxed actionsthis known relaxed planning-graph (RPG). relaxed plan (one
using relaxed actions) achieve goal state extracted RPG polynomial time;
number actions plan used provide heuristic value. Graphplan
provide guarantee plan found contain optimum number sequentialised actions
(only optimum makespan) heuristic returned inadmissible, practice
heuristic informative used previously.
2.3 Enforced Hill Climbing Search
Along heuristic based relaxed planning graphs, FF introduced Enforced Hill Climbing
(EHC) algorithm, illustrated Figure 1. EHC based commonly used hill-climbing algorithm local search, differs breadth-first search forwards global optimum
used find sequence actions leading heuristically better successor none present
immediate neighbourhood.
key bottleneck using EHC search heuristic cannot provide sufficient guidance escape plateau1 single action step, breadth-first search used suitable
action sequence found. Characteristically, EHC search consists prolonged periods exhaustive search, bridged relatively quick periods heuristic descent.
1. work, plateau defined region search space heuristic values successors
greater equal best seen far.

121

fiC OLES & MITH

practice, EHC guided RPG heuristic effective search strategy number
domains. Work done (Hoffmann, 2005) analysing topology local-search
landscape investigate effective heuristic, well identifying situations
weak.
2.4 Exploiting Structure Relaxed Plan
actions relaxed plan goal given state used provide search
advice. YAHSP (Vidal, 2004), planner produced interesting results Fourth International
Planning Competition (IPC 4), makes use actions relaxed plan suggest actions add
current plan reach goal. FF, notion helpful actions definedthose add
fact added action chosen first time unit relaxed plan. state encountered
search, number actions applicable, irrelevant; i.e. make
progress towards goal. considering helpful actions determining successors
state, performing EHC, number successor states evaluated reduced.
Restricting choice actions apply helpful reduces
completeness EHC, beyond would case applicable actions considered.
practice observed, however, cases EHC using helpful actions unable
find plan correlate cases EHC applicable actions would unable
find plan.
2.5 Guaranteeing Completeness FF
FF first attempts search solution plan performing Enforced Hill-Climbing (EHC) search
initial state towards goal state. discussed earlier, EHC uses hill-climbing local
search guided RPG heuristic strictly-better successor found. soon
strictly better successor found, FF entered plateau, breadth-first search used
improving state found. directed search spaces, EHC lead search process
wrong direction dead-ends; i.e. open list empty, goal state found.
cases FF resorts best-first search initial state, thereby preserving completeness.
2.6 Macro-Actions Planning
macro-action, used planning, meta-action built sequence action steps.
forward-chaining planning, applying macro-action state produces successor corresponding application series actions. way, use macro-actions thought
extending neighbourhood successors visible state selectively introduce
states hitherto would visible application several steps. additional states introduced chosen effectively, increase planner performance realised;
whereas additional states chosen poorly, performance planner decreases due
increased branching factor.
use macro-actions planning widely explored. techniques use off-line
learning approach generate filter macro-actions using search. Early work
macro-actions began version STRIPS plannerknown ABSTRIPS (Fikes & Nilsson, 1971)which used previous solution plans (and segments thereof) macro-actions solving
subsequent problems. MORRIS (Minton, 1985) later extended approach adding filter122

fiM ARVIN : H EURISTIC EARCH P LANNER NLINE ACRO -ACTION L EARNING

ing heuristics prune generated set macro-actions. Two distinct types macro-actions
identified approach: S-macrosthose occur frequently searchand T-macros
occur less often model weakness heuristic. Minton observed
T-macros, although used less frequently, offered greater improvement search performance.
REFLECT system (Dawson & Siklossy, 1977) took alternative approach forming macroactions based preprocessing domain. sound pairwise combinations actions
considered macro-actions filtered basic pruning rules. Due small size
domains planner reasoning, number macro-actions remaining following process sufficiently small use planning.
recent work macro-actions includes Macro-FF (Botea, Enzenberger, Muller,
& Schaeffer, 2005). Macro-actions extracted two ways: solution plans;
identification statically connected abstract components. offline filtering technique used
prune list macro-actions. Another recent approach macro-action generation (Newton,
Levine, & Fox, 2005) uses genetic algorithm generate collection macro-actions,
filters collection offline filtering technique similar used Macro-FF.

3. Marvins Search Behaviour
Marvins underlying search algorithm based used FF: forward-chaining heuristic search
using RPG heuristic. However, Marvin includes important modifications basic FF
algorithm. are: least-bad-first search strategy exploring plateaux, greedy best-first
strategy searching EHC fails development use plateau-escaping macroactions.
FF first approach finding solution plan perform EHC search using helpful
actions. first successor heuristic strictly better best far taken, one
found. one found, plateau encountered, form best-first search using
helpful actions used (instead breadth-first search FF) try find action sequence
escape it. states plateau never improve heuristic value node
root plateau, call least-bad-first search.
EHC approach unable find plan, Marvin resorts modified form best-first
search using actions applicable state. expands first strictly better successor
whilst keeping current state expansion later necessary. call strategy greedy
best-first search. seen graphs Section 6.2, IPC 4 domains
modifications enable solution problems unsolvable best-first search.
EHC search strategy, Marvin uses plateau-escaping macro-actions learned
previous searches similar plateaux. applied way atomic actions
traverse plateaux single step. Plateau-escaping macro-actions learned online planner
must decide ones likely applicable points search. Section 6.5
show plateau-escaping actions yield performance benefits. power depends
structure search space ability planner learn re-usable macro-actions.
Least-bad-first search plateaux, greedy best-first search plateau-escaping macro-actions
three main features Marvin distinguishing basic search strategy
forward heuristic search-based planners. discuss three features detail going describe exploited context ADL domains domains
involving derived predicates.
123

fiC OLES & MITH

5
6

5
5

5
6
5
5

6

4
4

4
4

3

4

Figure 2: Least-bad-first search versus breadth-first search plateau. Black nodes
expanded breadth-first search. Dotted blue/grey nodes expanded
breadth-first least-bad-first search. Solid blue/grey nodes expanded
least-bad-first search. seen least-bad-first search leads better exit node
breadth-first search.

3.1 Least-Bad-First Search Plateaux
plateau encountered successor nodes given current node heuristic
value as, worse than, current node. notion best context
relates successor heuristic value closest parent state. called
least-bad-first search chosen successor make heuristic progress, choices
less negative others. successor chosen least-bad-first search least negative
impact current state therefore likely best path goal.
breadth-first search used, exit state reached might goal exit
state reached state least negative impact always expanded next.
Figure 2 show order states explored using least-bad-first search relative
breadth-first search. observed that, using least-bad-first search, exit state reached
better heuristic value reached using breadth-first search FF. expected
sometimes leads better quality plans found. results Section 6.3 show that,
indeed, using least-bad-first search sometimes find shorter plans FF finds using standard
breadth-first strategy plateaux.
3.2 Greedy Best-First Search EHC Fails
FF, Marvin resorts best-first search EHC proves unable find solution. approach
maintains completeness planner cases use EHC helpful actions
would otherwise render search incomplete. Two planners IPC 4 used variations
best-first search algorithm, YAHSP (Vidal, 2004) Fast-Downward (Helmert, 2006). Unlike
Marvin, however, two planners incomplete search step (such EHC)
using modified best-first search algorithm. YAHSP, conventional WA* search used within
search queue, states reached applying helpful action parent state ordered
not. Fast-Downward, deferred heuristic evaluation strategy used,
124

fiM ARVIN : H EURISTIC EARCH P LANNER NLINE ACRO -ACTION L EARNING

states inserted search queue heuristic value parent state; actual
heuristic cost state calculated state expanded.
Marvin best-first strategy modified greedily expanding first successor found
better heuristic parent state, retaining parent remaining children
evaluated later necessary. effect similar approach taken Fast-Downward,
would lead nodes search space visited order. approach taken
Marvin, however, allows smaller search queue maintained, nodes necessarily
inserted search queue successor node reachable state.
Whenever successor state generated evaluated (by calculating heuristic value), one
two things happens:
successor heuristic better parent, successor placed front
search queue, parent state behind (along counter variable, noting
many successors already evaluated); search loop restarted
successor state.
successor heuristic better parent, successor inserted
search queue appropriate place (stable priority-queue insertion, ordered heuristic
value). process carries evaluating successors parent state.
pseudo-code seen Figure 3. approach inspired idea taking
first strictly-better successor performing EHC search, benefit number
heuristic evaluations performed potentially reduced considering fewer successors
state. differs EHC that, maintain completeness, parent state discardedit
placed back queue successors evaluated later necessary. Theoretically,
EHC search given problem encounter plateaux, pruning selecting
helpful actions ignored, using greedy best-first search problem would visit
number nodes evaluate number successors. plateau encountered, however, search behaviour would differ EHC would consider states reachable
state start plateau.
Another effect greedy best-first search search focusses exploring given
direction. described, soon successor node found heuristic value better
parent, expansion parent node postponed successor
node expanded. practical consequence search queue contain
equally good successors, search forward successor state sidetracked
also search forward sibling states. parent node re-visited,
sibling nodes added, proves heuristically wise sothat is, searching
forward successor node making heuristic progress.
3.3 Plateau-Escaping Macro-Actions
Due nature relaxed problem used generate RPG heuristic aspects
original problem captured. Thus, RPG heuristic used perform EHC,
plateaux often encountered. plateaux, RPG heuristic value successor states
as, worse than, heuristic value current state. nature plateaux
encountered, whether EHC able find path escape them, influenced
properties planning domain (Hoffmann, 2001).
125

fiC OLES & MITH

1:
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
17:
18:
19:
20:
21:
22:
23:
24:
25:
26:
27:
28:
29:
30:

Procedure: GreedyBFS
insert (state=initial state, h=initial heuristic, counter=0) search queue;
search queue empty
current queue entry = pop item front search queue;
current state = state current queue entry;
current heuristic = heuristic current queue entry;
starting counter = counter current queue entry;
applicable actions = array actions applicable current state;
index ?i applicable actions starting counter
current action = applicable actions[?i];
successor state = current state.apply(current action);
successor state goal
return plan exit;
end
successor heuristic = heuristic value successor state;
successor heuristic < current heuristic
insert (current state, current heuristic, ?i + 1) front search queue;
insert (successor state, successor heuristic, 0) front search queue;
break for;
else
insert (successor state, successor heuristic, 0) search queue;
end
end
end
exit - plan found;

Figure 3: Pseudo-code greedy best-first search

126

fiM ARVIN : H EURISTIC EARCH P LANNER NLINE ACRO -ACTION L EARNING

Ignoring delete effects pickup action Gripper domain creates problem
which, given state, possible pick many balls using one gripper, long gripper
initially available: delete effect action, marking gripper longer available,
removed. relaxed plan initial problem state pickup balls one gripper,
move next room, drop all. length plan, heuristic value
initial state, n + 1 + n, 2n + 1 (where n number balls). If, initial state, ball
picked using one grippers, relaxed plan resulting state pickup
remaining balls gripper, move second room drop all;
length (n 1) + 1 + n, 2n, less heuristic value initial state
action chosen one apply.
next state, however, start plateau. actions applicable (those
preconditions satisfied) either drop ball picked up, pickup
another ball move next room. correct action would pickup another ball:
relaxed plan goal state resulting state would drop one balls, pickup
remaining balls newly-freed gripper, move next room, drop balls.
However, heuristic value state would 1 + (n 2) + 1 + n, 2n, value
state action applied. Moving next room would produce state
heuristic value 2n (move initial room, pickup remaining (n 1) balls, drop
balls final roomno move action required move back room robot already
visited). Dropping one balls would also produce state heuristic value 2n (pickup
remaining (n 1) balls newly-freed gripper, move next room, drop balls).
successor states RPG heuristic value parent state, heuristic unable
provide useful guidance action apply.
exhaustive search forward point, improvement heuristic value
made two ways: either move next room drop ball, pickup ball
move next roomboth lead heuristic values (2n 1). plateau will,
however, encountered time robot first room, holding one ball, action
choices either pickup another ball move next room (or drop ball). time
plateau encountered, action sequence escape plateau identicalmove-drop
pickup-move (in EHC actual sequence chosen depend order actions
considered planner). discover one action sequences exhaustive
search time plateau encountered considerable bottleneck search process:
true general many domains.
order address overhead caused recurrent plateaux search space, Marvin memoises action sequences used escape previously encountered plateaux; action sequences used form called Plateau-Escaping Macro-Actions. macro-action
generated action sequence using code presented Figure 4. step action
sequence considered turn, abstract action step made replacing entities
given parameters action placeholder identifiersone distinct entity.
placeholder identifiers form parameter list macro-action; recorded abstract
action steps dictate component actions macro-action built.
Returning pickup-move action sequence, action sequence:
0: pickup robot1 ball2 room1
1: move robot1 room1 room2
127

fiC OLES & MITH

would form macro-action:
pickup-move (?a - robot) (?b - ball) (?c - room) (?d - room)
0: pickup ?a ?b ?c
1: move ?a ?c ?d
macro-action instantiated specifying parameters ?a ?d, resulting
sequence actions. example, (pickup-move robot1 ball3 room1 room2) would give
action sequence:
0: pickup robot1 ball3 room1
1: move robot1 room1 room2
Marvin, preconditions steps within macro-action collected give
single precondition formula macro-action. Instead, instantiated macro-action said
applicable given state first component action macro-action applicable,
subsequent actions applicable relevant resulting states.
built macro-actions plateau-escaping action sequences, search
later attempting escape plateau, macro-actions available application. plateau
arose due weakness heuristic led earlier plateau, macro-actions
able lead search strictly better state skipping intermediate states.
plateau-escaping macro-actions used search attempting escape plateaux
avoids slowing search RPG heuristic able provide effective guidance using
single-step actions.
reduce number macro-actions considered, blow-up size explored
search space would otherwise occur, macro-actions considered containing
actions first time step helpful actions current state.
3.4 Macro-Actions Use
structure reusability macro-actions depends underlying topology problem
space given heuristic function. problem space contains many similar occurrences
plateaux (which happens problem contains much repeating structure) effort
involved learning macro-actions escape plateaux efficiently richly rewarded.
principle, benefit obtained problem space features large, frequently recurring
plateaux, since large plateaux time-consuming explore effort would need
repeated every similar occurrence. Short macro-actions (of two three actions) indicate
problem space contains small plateaux (although might arise frequently enough
learned macro-actions still beneficial).
Problems repeating structure include: transportation problems, basic sequences actions repeated move groups objects sources destinations; construction problems, many similar components need built combined
finished artifact; configuration problems, multiple components architecture
need go similar processes complete functions, etc. Dining Philosophers
Towers Hanoi problems good examples problems repeating structure.
Although using macro-actions search advantagesthey offer search guidance
allow many actions planned one stepconsidering expansion
128

fiM ARVIN : H EURISTIC EARCH P LANNER NLINE ACRO -ACTION L EARNING

1:
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
17:
18:
19:
20:
21:
22:
23:
24:
25:

Procedure: BuildMacro
parameters = [];
parameter types = [];
abstract steps = [];
parameter count = 0;
action ?a action sequence used escape plateau
abstract parameters = [];
parameter ?p ?a
?p parameters
index = parameter index ?p parameters;
append (index) abstract parameters;
else
parameters[parameter count] = ?p;
parameter types[parameter count] = type ?p;
append (parameter count) abstract parameters;
increment parameter count;
end
end
append (action type ?a, abstract parameters) abstract steps;
end
return parameter types abstract steps macro-action

Figure 4: Pseudo-code building macro-actions plan segments

129

fiC OLES & MITH

state increases branching factor. Thus, large number unproductive macro-actions
generated search space become larger, making problem harder, easier, solve.
Whilst many plateau-escaping sequences helpful planning, specific
situation derived, situation might occur plan. macroactions learnt planning processand human intuition, large test suite,
allow reusable macro-actions identifiedcare must taken deciding points
consider use planning process.
Plateau-escaping macro-actions generated situations heuristic broken
down; therefore, heuristic used indicator likely useful
planning. areas repeating structure within solution plan involve application
similar (or identical) sequences actions, likely similar heuristic profiles.
case plateau-escaping action sequences, heuristic profile search landscape
application initial increase (or no-change) heuristic value, eventually followed fall
initial levelthe profile occurring local minimum. plateau-escaping macroactions reusable, likely re-use occur planning process
similar situation. such, considered application exhaustive search step
used escape plateaux (both start point plateau).
Situations may arise use macro-actions increases makespan resulting
plan due redundant action sequences. example, simple game domainwith actions
move up, down, left right macro-action formed left, left, left, left optimal
action sequence escape given plateau left, left, left {left, left, left, left}, right may
chosen state reached moving left four times heuristically better one reached
applying single-step left action. Thus, macro-actions adverse effect plan quality.
Within problem domains presented IPC 4 (Hoffmann & Edelkamp, 2005) encoding Dining Philosophers problem, translated Promela PDDL encoding.
solving problem, two important macro-actions formed: eleven-step macro-action upon
completion first period exhaustive search; three-step macro-action upon completion
second. solution plan requires macro-actions repeated many times, something nowas result macro-actionsinvolves simply applying single action
results strictly better state. Without macro-actions, planning process consists repeated
episodes exhaustive search find two sequences actions time.
behaviour seen Figure 5 depicting heuristic values states generated
without macro-actions, across solution plan IPC 4 Dining Philosophers problem
involving 14 philosophers. Initially, macro-actions learnt search done
approaches identical. first 14 action choices value heuristic, shown line
graph, moves monotonically downwards planner able find actions apply
lead strictly better states.
time step 14, heuristic value begins oscillate, point planner reached
plateau: state strictly better heuristic value reached application
one action. first plateau reached, macro-actions generated
heuristic profiles identical configurations. time step 25 state reached
better heuristic value time step 14. time plateau-escaping
macro-action generated, memoising lifted version sequence actions used
escape plateau. brief period search strictly better state found
choice point follows planner hits plateau.
130

fiM ARVIN : H EURISTIC EARCH P LANNER NLINE ACRO -ACTION L EARNING

40

35

30

Heuristic

25

20

15

10

5
Without Macro-Actions
Macro-Actions
0
0

20

40

60

80

100

120

Plan Time Step

Figure 5: Heuristic landscape makespan, without macro-actions.
subsequent six plateaux consist applying sequence actions six
pairs philosophers; seen heuristic fingerprints plateaux identical.
version Marvin macro-actions disabled repeats expensive exhaustive
search plateau: heuristic value goes process increasing
decreasing reaching strictly-better state. version using plateau-escaping
macro-actions, however, single action apply achieves strictly better state
search continues, stepping subsequent plateaux selection macro-actions
yield strictly-better states.
larger plateaux overcome, series smaller plateaux encountered. Again, seen first these, versions must complete stage
exhaustive search; however, first smaller plateaux completed, macroaction formed allows subsequent plateaux bypassed. Finally, plan finishes short
previously unseen sequence actions, versions must exhaustive search.

4. Handling ADL
PDDL (McDermott, 2000) (the Planning Domain Definition Language) first defined use
First International Planning Competition (IPC 1) AIPS-98. subsequent competitions,
modifications made language planning technology evolved.
first three competitions, domains available STRIPS (Fikes & Nilsson,
1971) actions used. STRIPS actions conjunctive predicate preconditions, add effects,
delete effects defined terms action schema parameters constant entities. determine
preconditions effects given ground action instance (an action whose parameters
bound specific entities) actions parameters substituted schema. action
applicable given state, precondition predicates must hold state; action
applied, new state generated previous state removing predicates present
delete effect list adding add effect list..
131

fiC OLES & MITH

ADL action schemata (Pednault, 1989) extend syntax STRIPS action schemata. ADL
domains language used describe preconditions action extended allow disjunctive, quantified negative preconditions well conjunctive preconditions used
STRIPS domains. syntax describing effects actions also extended allow
conditional effectseffects applied whenever given condition holds.
extended syntax provided ADL increases convenience domain
encoded, also reduce size domain descriptions needed. example,
action schema has, precondition (or B C) then, without ADL, three copies action
schema would need made: one precondition (A), one precondition (B) one
precondition (C). one willing tolerate increases domain-description size,
number objects domain finite, possible compile given ADL domain
problem-instance pair domain-problem pair containing STRIPS actions: general,
compilation must done problem instance, ADL domain.
ability compile ADL domains STRIPS domains first demonstrated compilation
procedure devised Gazen Knoblock (1997). Using techniques preprocessing stage,
FF able handle domains containing ADL actions whilst reasoning STRIPS actions
internally. output FFs preprocessor stage made available IPC 4 allow planners
could handle ADL directly solve compiled STRIPS formulations problems
loading compiled domain-problem pair original problem instances given
domain.
Whereas previous competitions ADL domains simplified manually reformulated
produce STRIPS domains, STRIPS domains IPC 4 compiled automatically
ADL. compilation used, based preprocessor FF, results compiled domain-problem
pair original problem instance. compilation explicitly grounds many original
actions, producing one compiled action schema (with preconditions effects whose parameters
refer PDDL constants) per ground action could arise original ADL problem. Whilst
compilations produce STRIPS domains allow planning performed, replace
general action schemata sets specific action instances.
allow new features Marvin used competition, Marvin extended
include native support ADL. reasoning original ADL domain able effectively
abstract macro-actions action sequences.
4.1 Preconditions ADL Actions
preconditions STRIPS actions consist one structural feature - clause, allowing
conjunctive preconditions predicates constant parameterised bindings. ADL actions
far greater range structural features preconditions. allow or, imply,
not, forall exists, combined well-formed manner. Marvin, ADL
preconditions processed using two steps. First, quantified preconditions fully enumerated.
Second, resulting precondition formula translated Negation Normal Form (NNF) using
standard procedure: replacing (a b) (a b), using De Morgans laws
eliminate negations clauses. reductions applied eliminate redundancy,
replacing (and (and B C)) (and B C), (or (or B C)) (or B C).
Internally, within Marvin, NNF precondition formula forms basis satisfaction tree,
nodes elements formula literals (negated non132

fiM ARVIN : H EURISTIC EARCH P LANNER NLINE ACRO -ACTION L EARNING

negated) form leaves. structure satisfaction tree given action schema fixed,
although propositions leaves vary groundings.
determine ground ADL action instances applicable given state based
preconditions, algorithm shown pseudo-code fragment Figure 6 used. Initially,
satisfaction counters associated ground actions satisfaction tree nodes reset using
following rules:
nodes counter set denote number children has.
node counter set 1.
Negative preconditions assumed true, satisfaction counters parents
decremented accordingly.
values state-independent, reasons efficiency values used reset satisfaction counters computed cached later use.
reset satisfaction counters, proposition current state considered,
satisfaction trees updated accordingly:
satisfaction counters parent nodes current proposition negative precondition incremented.
satisfaction counters parent nodes current proposition positive precondition decremented.
Then, propagating effects truth value changes upwards tree, action
whose root node sufficiently many children satisfied applicable.
4.2 Effects ADL Actions
ADL extends action definitions STRIPS actions allowing quantified conditional effects. preconditions, former dealt enumeration; latter dealt depending conditions.
conditional effect dependent static predicates possible determine
grounding action whether applies instance: static information
change state state. effect depends dynamic predicates, necessary consider,
state, whether effect applies. achieve this, effect conditions used
form sub-action. sub-action conditional effects condition preconditions,
conditional effect effects. conditional effects nested original
operator schemata, sub-actions may also conditional effects; case
sub-action-creation step applied recursively, creating nested sub-actions necessary.
applicability ground sub-actions given state performed manner
normal actions. action applied, sub-actions also applicable applied
alongside it, thereby preserving conditional effects original operator.
4.3 Modifying Relaxed Planning Graph
necessary modify Relaxed Planning Graph expansion plan-extraction phases make
possible apply heuristic domain contains ADL actions. Work done
133

fiC OLES & MITH

1:
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
17:
18:
19:
20:
21:
22:
23:
24:
25:
26:
27:
28:
29:
30:
31:
32:
33:
34:
35:
36:
37:
38:
39:
40:
41:
42:
43:
44:
45:

Procedure: test-action-applicability
reset satisfaction counters();
predicate ?p state
(ground action ?a, tree node ?c) pair ?p negative precondition child node
tree node update = ?c;
tree node update still valid
old value = value tree node update;
value tree node update = old value + 1;
value tree node update > 0 && old value = 0
tree node update = parent tree node update;
else
tree node update = invalid;
end
end
end
(ground action ?a, tree node ?c) pair ?p positive precondition child node
tree node update = ?c;
tree node update still valid
old value = value tree node update;
value tree node update = old value -1;
value tree node update = 0 && old value > 0
tree node update = parent tree node update;
else
tree node update = invalid;
end
end
end
end
applicable actions = ;
ground action ?a
root tree node satisfied
add ?a applicable actions;
end
end

Figure 6: Pseudo-code action applicability testing

134

fiM ARVIN : H EURISTIC EARCH P LANNER NLINE ACRO -ACTION L EARNING

extending full graphplan planning graphs reason subset ADL actions (Koehler, Nebel,
Hoffmann, & Dimopoulos, 1997); approach taken Marvin extends relaxed planning graph
structure handle available ADL constructs. effect modifications
heuristic estimate obtained precompiled STRIPS domain formulation used.
building conventional relaxed planning graph assumption made that, first
fact layer, facts present state evaluated true facts are, implicitly,
false. Facts gradually accumulated application actions, add effects adding facts
spike (Long & Fox, 1999). Actions become applicable preconditions present;
i.e. accumulated. STRIPS actions used build conventional relaxed
planning graph necessarily negative preconditions, sufficient consider facts
positive truth value determine action applicability this. ADL actions, however,
also negative preconditions, corresponding facts must false. Within conventional
relaxed planning graph, record made whether possible given fact negative
truth value.
handle negative facts within relaxed planning graph used Marvin, second spike
added. positive-fact spike, facts present state evaluated true
facts are, implicitly, false. However, unlike positive-fact spike, facts gradually
eroded applications actions; delete effects marking fact negativefact spike deleted. inherent relaxation relaxed planning graph
founded still preserved, though: delete effects effect positive-fact spike; and,
similarly, add effects effect negative-fact spike.
precompiled STRIPS domain formulation used, additional complimentary propositions
added denote proposition true. accumulate alongside original
domain propositions, way able satisfy negative preconditions. negative fact
spike, discussed, effect, although rather recording propositions
available negated form layer, records propositions available negated
form.
discussed, ADL action preconditions preprocessed negation applied
leaves satisfaction tree; i.e. applied unit facts forming part actions
precondition structures. Within relaxed planning graph given fact leaf marked
satisfied either one following holds:
positive fact leaf, fact contained therein added positive-fact
spike.
negative fact leaf, fact contained therein either never negativefact spike since marked deleted.
Plan graph construction proceeds manner similar used build conventional relaxed
planning graph. newly present newly deleted facts considered turn,
effects applicability available actions noted. updating satisfaction tree
action lead becoming applicable:
action added action spike, available next fact layer.
Previously unseen add effects added positive-fact spike, available next fact
layer.
135

fiC OLES & MITH

Delete effects deleting fact still present negative-fact spike mark fact
deleted available satisfy negative preconditions next fact layer.
efficiency, first action achieve fact stored added positive-fact
spike, along earliest layer action applicable. Similarly, first action
deletes fact ever negative-fact spike noted. Relaxed plan extraction
consists regressing layers relaxed planning graph, selecting actions achieve
goals achieved layer. Initially, proposition goal state added
layer goals layer first appears (or disappears, case negative goals).
extract plan, next goal repeatedly taken deepest action layer outstanding
goals. first achieving action added plan preconditions, taken satisfaction
tree, added goals first layer appear. process finishes
outstanding goals layer. sub-action (that is, action created represent
conditional effect ADL action, see Section 4.2) chosen achieve given proposition,
preconditions parent action(s) also added goals first layer
appear.
considering adding preconditions achieving action layer
appear, collection disjunctive preconditions may arise. situation, first satisfied precondition negative precondition disjunction added subgoal earlier layer.
avoids adding many redundant actions satisfy disjunctive preconditions,
one needs satisfied. precondition chosen satisfied collection disjunctive preconditions first achiever found building relaxed planning
graph, thus providing heuristic estimate compiled STRIPS domain formulation
used. compiled STRIPS domain formulation, disjunctive precondition would give
rise several action instantiations; first applicable would chosen achiever
desired fact.
start planning process, relaxed planning graph constructed forward
initial state. However, rather stopping goal literals appear, graph construction stops
ground actions become applicable. actions propositions appearing
relaxed planning graph superset actions propositions appearing later relaxed
planning graphs: actions propositions discovered used form cache detailing
propositionaction dependencies. Using cached information, code shown Figure 6
used determine actions applicable given state, relaxed planning graphs
used calculate heuristic values extracted efficiently.

5. Handling Derived Predicates
IPC 4, PDDL extended addition Derived Predicates (Hoffmann &
Edelkamp, 2005). Derived Predicates, used three competition domains, allow higherlevel concepts recursively derived propositions. derived predicates
present preconditions actions, allow higher-level concepts domain reasoned with. example, BlocksWorld domain, derivation rule predicate
follows:
(:derived (above ?x ?y)
(or (on ?x ?y) (exists (?z) (and (on ?x ?z) (above ?z ?y)))))
136

fiM ARVIN : H EURISTIC EARCH P LANNER NLINE ACRO -ACTION L EARNING

planner include native support derived predicates, possible compile
domains containing derived predicates flattened domains not. However, possible without super-polynomial increase size domain solution plan
(Nebel, Hoffmann, & Thiebaux, 2003). IPC 4, compiled versions domains contained
derived predicates made available competitors could support derived predicates.
However, sizes problems could compiled restricted concomitant sizes
PDDL files produced compilation process computational effort necessary
solve compiled problems.
IPC 4 first planning competition make use derived predicates domains.
shown derived predicates cannot reasoned efficiently compilation
(Nebel et al., 2003) steps taken provide native support Marvin.
also possible compile derived predicates appearing domains adding actions
instantiate derived predicates as-needed basis (Gazen & Knoblock, 1997). Using
compilation, derivation rule blocksworld problem described would
compiled following action:
confirm ?x ?y
pre: (or (on ?x ?y) (exists (?z) (and (on ?x ?z) (above ?y ?z))))
add: (above ?x ?y)
used domain compilation, original actions domain must
extended delete propositions, forcing confirm actions used
re-achieve preconditions action requires them. case, action
given additional effect:
(forall (?x ?y) (not (above ?x ?y)))
Although effective STRIPS domains, possible use compilation domains
making use negative preconditions re-derivation derived predicates occurring negative
preconditions actions enforced. example, action could applied modifies
propositions, leading state number additional properties could
derived. Deleting propositions necessary step, confirm actions
re-assert derived predicate action needs it. However, (above ?x ?y) deleted,
(not (above ?x ?y)) true, used action precondition. deal issue
necessary prevent non-confirm actions applied possible derived predicates
re-asserted; prevents actions applied given
temporarily true, i.e. whilst yet re-derived. force re-derivation derived
predicates, dummy predicates actions must added domain. necessary
compilation results large increase size search space explored, additional
dummy actions affect usefulness relaxed-planning-graph heuristic.
problems using Gazen & Knoblock compilation arise solely because, original
form, force applicable confirm actions applied original action
applied. such, planner generates confirm actions internally deals
appropriately, compilation still form basis effective means handling derived
predicates.
137

fiC OLES & MITH

end, presented domain containing derived predicates, Marvin machinegenerates confirm actions extends (original) action delete derived predicates,
described. action applied, propositions directly recursively derived
resulting state instantiated applying applicable confirm actions. Along
avoiding unwieldy compilation domains negative preconditions, handling confirm
actions internally manner provides performance improvements two reasons:
confirm actions automatically applied appropriate, Marvin
search perform heuristic evaluation discover next action required
confirm action.
Confirm actions included alongside normal actions relaxed planning graph built
state, used relaxed plan contribute towards heuristic value
taken length, eliminating noise would otherwise add.

6. Results
planning competition offers great opportunity assessing relative performance various
techniques used planning wide range problems. Inevitably will, however,
features tested set domains used competition. also
domains many features planner collaborate produce good results, rather
results directly attributable one individual feature. discuss results
competition present results clarify features Marvin contribute
performance particular case.
important note refer macro-actions generated used Marvin
generated planning process specific problem. additional learning time
knowledge gained solving problems used Marvin competition,
producing additional results presented paper. Although planners use additional
learning time solving series problems, satisfactory way incorporate extra time
time taken solve problem, measured planning competition, yet
found. planning competition planners compared based performance
isolated problem instances, still interesting comparison make.
results presented produced two machines: machine University Strathclyde (with 3.4GHz Pentium 4 processor) IPC 4 competition machine (with 3GHz Xeon
processor). cases, planner subjected 30 minute time limit 1Gb memory
usage limit. results directly compared (i.e. appear graph)
produced machine. domains used evaluation taken IPC 3 IPC
4, described detail papers giving overview two competitions (Long
& Fox, 2003; Hoffmann & Edelkamp, 2005).
6.1 Plateau-Escaping Macro-Actions
assess effect plateau-escaping macro-actions planner performance, tests run across
range planning domains macro-actions enabled disabled. results tests
shown Figures 7 8, illustrating time taken find solution plan makespan
plan found respectively.
138

fiM ARVIN : H EURISTIC EARCH P LANNER NLINE ACRO -ACTION L EARNING
Airport

Philosophers

1000

1000
Macro-Actions
Macro-Actions

100

100

10

10

Time (sec.)

Time (sec.)

Macro-Actions
Macro-Actions

1

1

0.1

0.1

0.01

0.01
5

10

15

20

25
30
Problem Instance

35

40

45

50

5

10

15

20
25
30
Problem Instance

Depots

35

40

45

Driverlog

10000

1000
Macro-Actions
Macro-Actions

Macro-Actions
Macro-Actions

1000
100

Time (sec.)

Time (sec.)

100

10

10

1
1

0.1
0.1

0.01

0.01
5

10
Problem Instance

15

20

2

4

6

8

10
12
Problem Instance

Pipes Tankage Non-Temporal

14

16

18

20

Satellite

10000

1000
Macro-Actions
Macro-Actions

Macro-Actions
Macro-Actions

1000
100

Time (sec.)

Time (sec.)

100

10

10

1
1

0.1
0.1

0.01

0.01
5

10

15

20

25
30
Problem Instance

35

40

45

50

5

10

FreeCell

15
20
Problem Instance

30

35

Pipes No-Tankage Non-Temporal

10000

10000
Macro-Actions
Macro-Actions

Macro-Actions
Macro-Actions

1000

1000

100

100
Time (sec.)

Time (sec.)

25

10

10

1

1

0.1

0.1

0.01

0.01
2

4

6

8

10
12
Problem Instance

14

16

18

20

5

10

15

20

25
30
Problem Instance

35

40

45

50

Figure 7: CPU time showing results planning without plateau-escaping macroactions range domains (from left right: Airport, Philosophers, Depots, Driverlog, Pipestankage-nontemporal, Satellite, FreeCell, Pipesnotankage-nontemporal).

139

fiC OLES & MITH
Airport

Philosophers

500

450
Macro-Actions
Macro-Actions

Macro-Actions
Macro-Actions

450

400

400

350

350
300
Makespan

Makespan

300
250

250
200

200
150
150
100

100

50

50
0

0
5

10

15

20

25
30
Problem Instance

35

40

45

50

5

10

15

20
25
30
Problem Instance

Depots

35

40

45

Driverlog

250

200
Macro-Actions
Macro-Actions

Macro-Actions
Macro-Actions
180

200

160
140

Makespan

120

Makespan

150

100

100
80
60

50

40
20

0

0
5

10
Problem Instance

15

20

2

4

6

8

10
12
Problem Instance

Pipes Tankage Non-Temporal

14

16

18

20

Satellite

250

450
Macro-Actions
Macro-Actions

Macro-Actions
Macro-Actions
400

200

350
300
Makespan

Makespan

150
250
200

100
150
100

50

50
0

0
5

10

15

20

25
30
Problem Instance

35

40

45

50

5

10

FreeCell

15
20
Problem Instance

25

30

35

Pipes No-Tankage Non-Temporal

250

250
Macro-Actions
Macro-Actions

Macro-Actions
Macro-Actions

150

150
Makespan

200

Makespan

200

100

100

50

50

0

0
2

4

6

8

10
12
Problem Instance

14

16

18

20

5

10

15

20

25
30
Problem Instance

35

40

45

50

Figure 8: Makespan solution plans found planning without plateau-escaping
macro-actions range domains (from left right: Airport, Philosophers, Depots,
Driverlog, Pipestankage-nontemporal, Satellite, FreeCell, Pipesnotankage-nontemporal).

140

fiM ARVIN : H EURISTIC EARCH P LANNER NLINE ACRO -ACTION L EARNING

Airport domain time taken find plans makespans plans found
almost identical. strictly better successor usually found state using EHC,
clear domain addition macro-actions occasional plateau
degraded performance planner. performance two configurations deviates
problem 47, planning macro-actions able find solution plan planning
without macro-actions not. Closer inspection output planner reveals
case, way EHC search, plateau encountered escaped; configuration using
macro-actions, leads formation macro-action. Later search, another plateau
encountered. point, earlier macro-action used lead strictly better state,
solution plan ultimately found using EHC. macro-action available,
however, sequence actions found escape plateau leads different exit point,
solution plan cannot found using EHC.
Philosophers domain neither makespans plans found coverage differs two configurations tested. Using macro-actions, however, leads consistently improved
performance plateaux encountered search require application action
sequence. Consistently, across problems, searching macro-actions faster factor
two; furthermore, factor increasing problem size, suggesting better scalability.
Depots domain, using macro-actions improves coverage, allowing 18 problems
solved within time limit rather 15. Further, many cases, time taken find plan
reduced. one case, problem file 6, planning without macro-actions able find plan
planning macro-actions cannot. Here, planning without macro-actions unable find exit
point one plateaux encountered later search, resorts best-first search. Planning
macro-actions, however, able reach greater number successor states nodes
plateau unable exhaust reachable possibilities terminate EHC search within
30-minute time limit.
Driverlog domain, using macro-actions generally increases time taken find plans
adverse effect makespan. domain, macro-actions containing varying-length
action sequences consisting repeated walk drive actions inferred. practice,
detrimental two ways: large number instantiations dramatically increase
branching factor, reducing performance; usefully reusable situations
prescribed number walk drive actions needed. Despite this, planning macroactions able find solution plans 18 problems, whereas planning without macroactions able solve 17 problems. problem question, problem 17,
increased number successor states visible nodes plateaux due presence
macro-actions allows EHC find solution plan rather resorting best-first search,
would ultimately fail within time limit set.
Pipestankage-nontemporal domain, clear first whether macro-actions beneficial not. number problems solved configurations same, 34, impact
makespan appears insignificant, improving cases making worse others.
However, looking harder problems problem 25 upwards, planning macro-actions
able solve 13 rather 11 problems, suggesting able scale better larger problems
compared searching without macro-actions.
Satellite domain configurations exhibit similar performance, terms
time taken find solution plan makespan plan found, relaxed planning graph
heuristic generally able provide good search guidance. exception problem 36: here,
141

fiC OLES & MITH

inference macro-action allows search completed using EHC rather resorting
best-first search, reducing time taken find plan.
FreeCell domain, macro-actions appear lead improved makespans negligible impact time taken find solution plans. Intuitively, however, strongly directed
search space (such FreeCell, possible move card one location
another often move back) using non-backtracking search strategy EHC
reduce effectiveness macro-actions, introduction redundant action steps part
macro-action instantiations lead search towards unpredicted dead-ends. illustrated results,
contradicting intuition, ascribed nature FreeCell problems used IPC 3.
problem files four suits cards, problem file 7 upwards four free
cells. number cards suit number columns gradually increased 2
13 4 8 respectively. effect this, however, hardest problems
favourable free cells cards ratio. macro-actions used, impact needlessly moving
card free cell significant generous allocation free cells compared
number cards might need stored there.
provide reasonable test whether macro-actions beneficial FreeCell domain, twenty full-sized problem instances generated tests run compare performance
Marvin without macro-actions problems. results tests seen
Figure 9 - clearly, number problems solvable within 30 minute time limit and, generally,
time taken find solution plan improved macro-actions used.
Pipesnotankage-nontemporal domain results obtained show significant advantage disadvantage using macro-actions: planner faster problems
using macro-actions, slower others; similarly, planner produces plans shorter
makespans problems using macro-actions, longer makespans others. Two
results obtained macro-actions used close 30-minute cut-off.
first solved around 10 seconds macro-actions used; second
solved using macro-actions extra 5 minutes CPU time allowed, slightly faster
computer used.
Overall, seen effect plateau-escaping macro-actions execution time
planner varies depending domain question:
Philosophers, Depots, Driverlog Pipestankage-nontemporal domains, use
macro-actions improves performance planner, either terms coverage
general reduction time taken find solution plans.
FreeCell domain, worse performance observed macro-actions used.
Airport, Pipesnotankage-nontemporal Satellite domains difference performance minimal.
Furthermore, exception Driverlog FreeCell domains (where makespan
solution plans generally increased using macro-actions) use macro-actions
significantly affect makespan.
6.2 Greedy Best-First Search versus Best-First Search
assess performance greedy best-first search compares conventional best-first search,
ran tests across range planning domains EHC macro-actions disabled isolate
142

fiM ARVIN : H EURISTIC EARCH P LANNER NLINE ACRO -ACTION L EARNING

FreeCell
10000
Macro-Actions
Macro-Actions
1000

Time (sec.)

100

10

1

0.1

0.01
5

10
Problem Instance

15

20

Figure 9: Time taken solve twenty full-sized problems FreeCell domain, without
plateau-escaping macro-actions.

effect greedy best-first search approach. Overall, analysing results, observed
choice best-first search algorithm little impact performance planner.
6.3 Least-Bad-First Search versus Breadth-First Search
assess effect using least-bad-first search rather breadth-first search escape plateaux
EHC search, ran tests across range planning domains using two search
algorithms. results tests shown Figures 10 11, illustrating time taken
find solution plan, makespan plan found.
Airport domain, plateaux arise one two cases:
unforeseen deadend reached; backtracking made action choices
exhaustively searching plateau inexpensive, EHC terminates rapidly.
short plateau reached, requiring two actions applied reach state
strictly better heuristic valuehere, two actions found least-bad-first breadthfirst search identical.
seen planning time makespan graphs, using least-bad-first search rather
breadth-first search impact planning time solution plan quality Airport
domain: time spent searching plateaux negligible, escape paths found identical
two plateau-search approaches.
143

fiC OLES & MITH
Airport

Philosophers

1000

10000
Least-Bad-First Search
Breadth-First Search

Least-Bad-First Search
Breadth-First Search
1000

100

Time (sec.)

Time (sec.)

100
10

10

1
1

0.1
0.1

0.01

0.01
5

10

15

20

25
30
Problem Instance

35

40

45

50

5

10

15

20
25
30
Problem Instance

Depots

35

40

45

Driverlog

10000

1000
Least-Bad-First Search
Breadth-First Search

Least-Bad-First Search
Breadth-First Search

1000
100

Time (sec.)

Time (sec.)

100

10

10

1
1

0.1
0.1

0.01

0.01
5

10
Problem Instance

15

20

2

4

6

8

10
12
Problem Instance

Pipes Tankage Non-Temporal

18

20

10000
Least-Bad-First Search
Breadth-First Search

Least-Bad-First Search
Breadth-First Search
1000

1000

100

100
Time (sec.)

Time (sec.)

16

Satellite

10000

10

10

1

1

0.1

0.1

0.01

0.01
5

10

15

20

25
30
Problem Instance

35

40

45

50

5

10

FreeCell

15
20
Problem Instance

25

30

35

Pipes No-Tankage Non-Temporal

10000

10000
Least-Bad-First Search
Breadth-First Search

Least-Bad-First Search
Breadth-First Search

1000

1000

100

100
Time (sec.)

Time (sec.)

14

10

10

1

1

0.1

0.1

0.01

0.01
2

4

6

8

10
12
Problem Instance

14

16

18

20

5

10

15

20

25
30
Problem Instance

35

40

45

50

Figure 10: CPU time showing comparison using breadth-first least-bad-first search
plateau search range domains (from left right: Airport, Philosophers,
Depots, Driverlog, Pipestankage-nontemporal, Satellite, FreeCell, Pipesnotankagenontemporal). results generated without using macro-actions.

144

fiM ARVIN : H EURISTIC EARCH P LANNER NLINE ACRO -ACTION L EARNING
Airport

Philosophers

350

450
Least-Bad-First Search
Breadth-First Search

Least-Bad-First Search
Breadth-First Search
400

300
350
250

Makespan

Makespan

300
200

150

250
200
150

100
100
50
50
0

0
5

10

15

20

25
30
Problem Instance

35

40

45

50

5

10

15

20
25
30
Problem Instance

Depots

35

40

45

Driverlog

250

180
Least-Bad-First Search
Breadth-First Search

Least-Bad-First Search
Breadth-First Search
160

200

140
120
Makespan

Makespan

150
100
80

100
60
40

50

20
0

0
5

10
Problem Instance

15

20

2

4

6

8

10
12
Problem Instance

Pipes Tankage Non-Temporal

14

16

18

20

Satellite

250

300
Least-Bad-First Search
Breadth-First Search

Least-Bad-First Search
Breadth-First Search
250
200

200
Makespan

Makespan

150
150

100
100

50
50

0

0
5

10

15

20

25
30
Problem Instance

35

40

45

50

5

10

FreeCell

15
20
Problem Instance

25

30

35

Pipes No-Tankage Non-Temporal

250

140
Least-Bad-First Search
Breadth-First Search

Least-Bad-First Search
Breadth-First Search
120

200
100

Makespan

Makespan

150

100

80

60

40
50
20

0

0
2

4

6

8

10
12
Problem Instance

14

16

18

20

5

10

15

20

25
30
Problem Instance

35

40

45

50

Figure 11: Makespan plans produced using breadth-first least-bad-first search
plateau search range domains (from left right: Airport, Philosophers,
Depots, Driverlog, Pipestankage-nontemporal, Satellite, FreeCell, Pipesnotankagenontemporal). results generated without using macro-actions.

145

fiC OLES & MITH

Philosophers domain, search time dramatically reduced using least-bad-first search
rather breadth-first search plateaux. Using least-bad-first search, 48 problems solved;
using breadth-first search, first 14 solved. plans found first 14 identical
makespans, although actions occur differing orders two plans.
search landscape provides insights least-bad-first search suited
problem domain. start largest plateaux encountered, action leads state
strictly worse heuristic value; corresponds applying action queue-write
philosopher. these, state less-bad heuristic visible. using least-badfirst search, less-bad state considered others queue, avoiding redundant
search would otherwise performed breadth-first search. Adding philosophers
problem causes dramatic increase amount redundant search performed breadth-first
search used, leading observed performance improvement least-bad-first approach
taken.
Depots domain, observe effect differing exit points plateaux using
least-bad-first breadth-first search. solving problem 18, least-bad-first search able
solve problem substantially less time: EHC search able escape plateau encountered, find solution plan. Breadth-first search, however, leads termination EHC,
exhaustive best-first search used. problem 15, however, breadth-first search able find
solution plan least-bad-first search cannot; also, problem 5 solved much less time.
two cases, success breadth-first search plateaux leads improved
performance, failure; EHC search terminates resorts best-first search less time
breadth-first search used least-bad-first search used.
Driverlog domain, one additional problem, number 18, solved least-badfirst search used instead breadth-first search. EHC using breadth-first search leads plateau
cannot escaped, EHC aborts without solution plan; resulting exhaustive best-first
search cannot completed within allowed 30 minutes. makespans plans found
two approaches differ significantly.
Pipestankage-nontemporal domain, seen use least-bad-first search
generally reduces time taken find solution plans. 34 problems solved using leastbad-first search compared 30 using breadth-first search and, majority cases,
time taken find solution plan reduced. makespans resulting solution plans
generally increased least-bad-first search used, though, suboptimal exit paths found
domain often longer (optimal-length) paths found breadth-first search
used.
Satellite domain using least-bad-first search leads reduction planning time and,
many cases, reduction makespan. particular, performance problems 19 20
substantially improved. makespans problems 28 30 inclusive also improved.
twenty standard benchmark FreeCell problems using least-bad-first search allows one
additional problem solved within 30 minute time limit. results obtained
assessing impact macro-actions planner performance, obtained interesting
useful set data. Figure 12 shows results experiments: seen although
least-bad-first search often improves time taken solve problems, coverage overall reduced, additional problems solved previously not.
Pipesnotankage-nontemporal domain, one additional problem solved using
breadth-first search rather least-bad-first search. Also, many cases, use least-bad146

fiM ARVIN : H EURISTIC EARCH P LANNER NLINE ACRO -ACTION L EARNING

FreeCell
10000
Least-Bad-First Search
Breadth-First Search
1000

Time (sec.)

100

10

1

0.1

0.01
5

10
Problem Instance

15

20

Figure 12: Time taken solve twenty full-sized problems FreeCell domain, least-badfirst breadth-first search plateaux (without macro-actions).

first search increases makespan solution plan found. Overall, although time reductions
occur solving problems using least-bad-first search, use breadth-first
search provides better overall performance terms planning time makespan.
Overall, seen across evaluation domains performance planner
using least-bad- breadth-first search varies, terms planner execution time plan quality:
Philosophers domain, use least-bad-first search provides substantial improvement planner performance.
Satellite, Driverlog Pipestankage-nontemporal domains, execution time
planner generally improved use least-bad-first search (with reduction plan
quality latter these).
Airport Depots domain, impact performance minimal, either terms
execution time solution plan quality.
FreeCell Pipesnotankage-nontemporal domains, performance planner degraded, terms execution time plan quality.
6.4 Handling Derived Predicates
possible reason domains involving derived predicates precompiling domain,
adding additional actions support derived predicates, planning usual manner
147

fiC OLES & MITH

PSR
10000
Original Domain: ADL Derived Predicates
Compiled Domain: ADL
1000

Time (sec.)

100

10

1

0.1

0.01
10

20

30
Problem Instance

40

50

Figure 13: Time taken solve problems PSR domain without Derived Predicates.

(see Section 5). necessary compilation, however, causes large increase size
domain. planner performs compilation itself, generating confirm actions segregating normal actions internally, avoid search overhead compiled domain
would incur.
Three IPC 4 domains make use derived predicates: PSR (Power Supply Restoration), Philosophers Optical Telegraph. assess impact native support derived predicates
planner performance, tests run domains using original domains containing derived predicates, using compiled domains. results tests shown
Figures 13, 14 15.
PSR domain, support derived predicates substantially reduces time taken
find solution plans. improvement efficiency allows 23 rather 12 problems solved
within 30 minute time limit.
Marvin able solve problems promela/optical-telegraph domain.
smaller problems, performance better without derived predicates; nonetheless, two
larger problems (problems 8 9) solved working original domain
previously could not, overall one additional problem solved derived predicates.
Philosophers domain, supporting derived predicates natively yields substantial reductions
planning time. Using compiled ADL domain formulation, first nine problems
solved. native derived predicate support, 48 problems solved.
148

fiM ARVIN : H EURISTIC EARCH P LANNER NLINE ACRO -ACTION L EARNING

Optical Telegraph
10000
Original Domain: ADL Derived Predicates
Compiled Domain: ADL
1000

Time (sec.)

100

10

1

0.1

0.01
2

4

6
Problem Instance

8

10

Figure 14: Time taken solve problems Optical Telegraph domain without Derived
Predicates.

6.5 Native ADL Support
native support ADL Marvin provides two benefits, arising ability use noncompiled domain formulations:
Potentially improved efficiency, due more-efficient representation.
ability infer reusable, parameterised macro-action sequences original ADL
actions, whose parameters lost side-effect process used compile ADL
STRIPS domains.
6.5.1 E FFECTS U SING



N -C OMPILED OMAIN

assess effect native support ADL constructs performance Marvin, ran
series tests comparing planners performance given STRIPS ADL domain encodings. Macro-actions disabled cases isolate effect encoding
performance. IPC 4, ADL used encode four domains: Airport,
Philosophers, Optical Telegraph PSR. STRIPS compilations made available
domains, ground action could arise using original ADL domain
made fixed-parameter STRIPS action. Philosophers, Optical Telegraph PSR
domains, domain formulations making use Derived Predicates used.
149

fiC OLES & MITH

Philosophers
10000
Original Domain: ADL Derived Predicates
Compiled Domain: ADL
1000

Time (sec.)

100

10

1

0.1

0.01
5

10

15

20
25
30
Problem Instance

35

40

45

Figure 15: Time taken solve problems Philosophers Domain without Derived
Predicates.

Airport, Optical Telegraph PSR domains, performance Marvin (with macroactions disabled) unaffected use either ADL STRIPS domain encoding.
ADL domain encodings give rise inefficient compiled STRIPS encodings.
Philosophers domain, use ADL domain encoding resulted reduction
planning time compared use compiled STRIPS encoding. seen
Figure 17, problems solved within 30 minute time-limit ADL encoding rather
STRIPS encoding used, even disregarding improvements performance provided
use macro-actions.
6.5.2 E FFECTS NFERRING ACRO -ACTIONS
Supporting ADL natively Marvin allows lifted macro-action schemata inferred
search: compiled STRIPS domain formulations presented IPC 4, actions plateauescaping action sequences parameters, removing opportunity infer parameterised action sequences use basis macro-actions. Reusable macro-actions
inferred STRIPS domains, many domains discussed Section 6.1; compilation ADL STRIPS produces domain macro-actions cannot, practice, ever
reused.
assess effects plateau-escaping macro-actions using ADL domain formulation, tests run Philosophers, Optical Telegraph PSR domains using ADL domain
formulation macro-actions enabled disabled. Results Airport domain presented
Section 6.1, results domains discussed.
150

fiM ARVIN : H EURISTIC EARCH P LANNER NLINE ACRO -ACTION L EARNING

0:
1:
2:
3:
4:

(activate-trans philosopher-1 philosopher forkspid-wfork state-1 state-6) [1]
(activate-trans philosopher-2 philosopher forkspid-wfork state-1 state-6) [1]
(activate-trans philosopher-3 philosopher forkspid-wfork state-1 state-6) [1]
(activate-trans philosopher-4 philosopher forkspid-wfork state-1 state-6) [1]
(activate-trans philosopher-0 philosopher forkspid-wfork state-1 state-6) [1]

5: Macro-Action Derived Here, using philosopher-4, philosopher-3, forks-4 forks-3
16: (activate-trans philosopher-3 philosopher forkspid-rfork state-6 state-3) [1]
17: Macro-Action A, using philosopher-2, philosopher-1, forks-2- forks-1
28: (activate-trans philosopher-1 philosopher forkspid-rfork state-6 state-3) [1]
29: Macro-Action B Derived Here, using philosopher-3 -forks-332: (activate-trans philosopher-3 philosopher forks- -pidp1 11 -rfork state-3 state-4) [1]
33: Macro-Action B, using philosopher-1 -forks-136: (activate-trans philosopher-1 philosopher forks- -pidp1 11 -rfork state-3 state-4) [1]
37:
38:
39:
40:

(queue-write philosopher-0 forkspid-wfork forks-0- fork) [1]
(advance-empty-queue-tail forks-0- queue-1 qs-0 qs-0 fork empty zero one) [1]
(perform-trans philosopher-0 philosopher forkspid-wfork state-1 state-6) [1]
(activate-trans philosopher-0 philosopher forkspid-rfork state-6 state-3) [1]

41: Macro-Action B, using philosopher-0 -forks-044: (activate-trans philosopher-0 philosopher forks- -pidp1 5 -rfork state-3 state-4) [1]

Figure 16: Plan Philosophers problem macro-action expansion.
plan shown Figure 16 produced Marvin problem four Philosophers
domain (before translation macro-actions back sequences single-step actions).
first five steps found easily guidance heuristic; following eleven
found period exhaustive search are, upon exiting plateau, used form
macro-action, macro-action A. Macro-action B formed similar manner later planning
process, subsequently used avoid exhaustive search. solution plans problems
involving philosophers, two macro-actions used several times: macro-action used
consecutive pair philosophers, macro-action B odd-numbered
philosopher (and philosopher-0). graph Figure 17 shows performance Marvin
macro-actions inferred search compared macro-actions
inferred; configurations produce identical solution plans. seen performance
consistently improved macro-actions used, exhaustive plateau search avoided.
seen Figure 18, using macro-actions provides improved performance PSR
domain: 23 rather 15 problems solved, majority cases solved
two configurations, solution found less time macro-actions used.
151

fiC OLES & MITH

Philosophers
10000
ADL Domain, Macro-Actions Enabled
ADL Domain, Macro-Actions Disabled
STRIPS Domain
1000

Time (sec.)

100

10

1

0.1

0.01
5

10

15

20
25
30
Problem Instance

35

40

45

Figure 17: Time taken find solution plan Philosophers domain STRIPS domain
encoding ADL domain encoding, without macro-actions.

PSR
10000
ADL Domain, Macro-Actions Enabled
ADL Domain, Macro-Actions Disabled
1000

Time (sec.)

100

10

1

0.1

0.01
10

20

30
Problem Instance

40

50

Figure 18: Time taken solve problems PSR domain without macro-actions.

152

fiM ARVIN : H EURISTIC EARCH P LANNER NLINE ACRO -ACTION L EARNING

Optical Telegraph
10000
ADL Domain, Macro-Actions Enabled
ADL Domain, Macro-Actions Disabled
1000

Time (sec.)

100

10

1

0.1

0.01
2

4

6
Problem Instance

8

10

Figure 19: Time taken solve problems Optical Telegraph domain without macroactions.

shown Figure 19, Marvin able solve first 10 problems
promela/optical-telegraph domain. Nonetheless, macro-actions enabled, net two additional problems solved.

7. Future Work
macro-action strategy adopted Marvin IPC 4 generate macro-actions perproblem basis. possible, however, build libraries macro-actions per-domain basis;
approach taken Macro-FF (Botea et al., 2005). Marvins macro-actions could also
cached use solving problem instances given domain. done,
knowledge encapsulated plateau-escaping macro-actions allows heuristic imperfections
search landscape bypassed could made available across problems given
domain without needing exhaustive search re-discover knowledge problem instance.
contrast existing systems use off-line learning generate test macro-actions, caching
Marvins plateau-escaping macro-actions across solving problem suite manner would allow
online learning take place. work undertaken area, investigate
effective caching strategies manage large number macro-actions found.
idea using plateau-escaping macro-actions restricted search relaxed
planning graph heuristic. Currently, effect using macro-actions search
heuristics investigated, including causal-graph heuristic (Helmert, 2004) used FastDownward .
153

fiC OLES & MITH

present, macro-actions used Marvin restricted used escape plateaux.
Work currently progress exploring ways extending macro-learning capabilities Marvin
include general macro-action structures kind explored Botea Schaeffer
(Botea et al., 2005).

8. Conclusions
presented forward search heuristic planner called Marvin, introduces several modifications search strategy FF. are:
use learned macro-actions escaping plateaux.
least-bad-first search strategy search plateaux.
greedy best-first search strategy EHC fails.
addition native support ADL derived predicates, without relying
domain preprocessor.
Results presented indicate effects modifications varies depending domain
planner presented, summarised as:
inference use plateau-escaping macro-actions:
Provides improved performance Philosophers, Depots, Driverlog
Pipestankage-nontemporal domains, terms planner execution time.
Although performance improve domains, significantly
degrade, exception FreeCell.
makespan plans found majority domains degraded
use macro-actions.
use least-bad-first search:
Provides substantial improvements planner performance Philosophers domain.
Reduces planner execution time Satellite, Driverlog Pipestankagenontemporal domains, sometimes expense increased solution plan makespans.
Provides worse performance FreeCell Pipesnotankage-nontemporal domains.
Greedy best-first search perform significantly differently best-first search
evaluation domains considered.
Airport domain, difference performance observed, native
support derived predicates ADL improves performance planner; either
allowing more-compact higher-level domain formulation used, improving
effectiveness macro-actions inferred.
154

fiM ARVIN : H EURISTIC EARCH P LANNER NLINE ACRO -ACTION L EARNING

Acknowledgments
would like thank anonymous referees comments, Maria Fox help
revising manuscript. also thank Derek Long supporting us entering Marvin IPC
4 Jorg Hoffmann Stefan Edelkamp hard work organising competition.

References
Bacchus, F. (2001). aips 00 planning competition.. AI Magazine, 22(3), 4756.
Blum, A., & Furst, M. (1995). Fast planning planning graph analysis. Proceedings
Fourteenth International Joint Conference Artificial Inteligence (IJCAI-95), pp. 1636
1642.
Bonet, B., & Geffner, H. (2000). HSP: Heuristic search planner. AI Magazine, 21(2).
Botea, A., Enzenberger, M., Muller, M., & Schaeffer, J. (2005). Macro-FF: Improving AI planning
automatically learned macro-operators. Journal Artificial Intelligence Research, 24,
581621.
Dawson, C., & Siklossy, L. (1977). role preprocessing problem solving systems.
Proceedings Fifth International Joint Conference Artificial Intelligence, (IJCAI-77),
pp. 465471.
Fikes, R., & Nilsson, N. (1971). STRIPS: new approach application theorem proving
problem solving. Proceedings 2nd International Joint Conference Artificial
Intelligence (IJCAI-71), pp. 608620.
Gazen, B., & Knoblock, C. (1997). Combining expressivity UCPOP efficiency
Graphplan. Proceedings Fourth European Conference Planning (ECP-97), pp.
221233.
Helmert, M. (2004). planning heuristic based causal graph analysis. Proceedings
Fourteenth International Conference Automated Planning Scheduling (ICAPS-04),
pp. 161170.
Helmert, M. (2006). fast downward planning system. Journal Artificial Intelligence Research, 26, 191246.
Hoffmann, J., & Edelkamp, S. (2005). deterministic part IPC-4: overview. Journal
Artificial Intelligence Research, 24, 519579.
Hoffmann, J., & Nebel, B. (2001). FF planning system: Fast plan generation heuristic
search. Journal Artificial Intelligence Research, 14, 253302.
Hoffmann, J. (2001). Local search topology planning benchmarks: empirical analysis. Proceedings Seventeenth International Joint Conference Artificial Intelligence (IJCAI01), pp. 453458.
Hoffmann, J. (2005). ignoring delete lists works: Local search topology planning benchmarks. Journal Artificial Intelligence Research, 24, 685758.
Koehler, J., Nebel, B., Hoffmann, J., & Dimopoulos, Y. (1997). Extending planning graphs
ADL sub-set. Proceedings Fourth European Conference Planning (ECP-97), pp.
275287.
155

fiC OLES & MITH

Long, D., & Fox, M. (2003). 3rd International Planning Competition: Results Analysis.
Journal Artificial Intelligence Research, 20, 159.
Long, D., & Fox, M. (1999). Efficient implementation plan graph STAN. Journal
Artificial Intelligence Research, 10, 87115.
Long, D., & Fox, M. (2003). third international planning competition: Results analysis.
Journal Artificial Intelligence Research, 20, 159.
McDermott, D. (1996). heuristic estimator means ends analysis planning. Drabble, B.
(Ed.), Proceedings Third International Conference Artificial Intelligence Planning
Systems (AIPS-96), pp. 142149. AAAI Press.
McDermott, D. (2000). 1998 AI planning systems competition. AI Magazine, 21(2), 3555.
Minton, S. (1985). Selectively generalizing plans problem-solving. Proceedings Ninth
International Joint Conference Artificial Intelligence (IJCAI-85).
Nebel, B., Hoffmann, J., & Thiebaux, S. (2003). defense PDDL axioms. Proceedings
Eighteenth International Joint Conference Artificial Intelligence (IJCAI-03), pp. 961966.
Newton, M., Levine, J., & Fox, M. (2005). Genetically evolved macro-actions A.I. planning
problems. Tuson, A. (Ed.), Proceedings 24th UK Planning Scheduling SIG, pp.
163172.
Pednault, E. (1989). ADL: Exploring middle ground STRIPS situation calculus.
Proceedings First International Conference Principles Knowledge Representation Reasoning, pp. 324332.
Vidal, V. (2004). lookahead strategy heuristic search planning. Proceedings Fourteenth International Conference Automated Planning Scheduling (ICAPS-04), pp.
150160.

156

fiJournal Artificial Intelligence Research 28 (2007) 49-105

Submitted 2/06; published 02/07

Strategy-Proofness Landscape Merging
Patricia Everaere
Sebastien Konieczny
Pierre Marquis

everaere@cril.fr
konieczny@cril.fr
marquis@cril.fr

CRIL CNRS
Faculte des Sciences, Universite dArtois
62300 Lens, France

Abstract
Merging operators aim defining beliefs/goals group agents
beliefs/goals member group. Whenever agent group preferences
possible results merging process (i.e., possible merged bases),
try rig merging process lying true beliefs/goals leads better
merged base according point view. Obviously, strategy-proof operators highly
desirable order guarantee equity among agents even
sincere. paper, draw strategy-proof landscape many merging operators
literature, including model-based ones formula-based ones. general
case several restrictions merging process considered.

1. Introduction
Merging operators aim defining beliefs/goals group agents beliefs/goals member group. Though beliefs goals distinct notions,
merging operators typically used merging either beliefs goals. Thus,
logical properties literature (Revesz, 1993, 1997; Konieczny & Pino Perez, 1998,
2002) characterizing rational belief merging operators used characterizing
well rational goal merging operators.
Whatever beliefs goals merged, numerous situations agents
preferences possible results merging process (i.e., merged bases).
far goals concerned, agent surely satisfied individual goals chosen
goals group. case belief merging, agent interested
imposing beliefs group (i.e., convincing agents), especially
result decision stage group level may depend beliefs
group.
So, soon agent participates merging process, strategy-proofness problem
considered. question is: possible given agent improve result
merging process respect point view lying true beliefs/goals,
given knows (or least assumes) beliefs/goals agent group
way beliefs/goals merged?
illustration, let us consider following scenario goal merging (that
used running example rest paper):

c
2007
AI Access Foundation. rights reserved.

fiEveraere, Konieczny & Marquis

Example 1 Three friends, Marie, Alain Pierre want spend summer holidays
together. determine whether go seaside and/or mountains, stay home, also determine whether take long period
vacations not. goals Marie go seaside mountains
long period; otherwise wants go mountains, only, stay home.
goals Alain go seaside long period; go mountains
short period. Finally, Pierre interested going seaside
long period, otherwise prefers stay home. one uses common merging operator
defining choice group,1 goals group either go
seaside long period, go mountains stay home short period.
Accordingly, group may choose go seaside, only, long period,
among goals Marie. However, Marie lies claims that, short period,
wants go mountains only, stay home, result merging process
different. Indeed, case, goals group go mountains
short period, stay home, corresponds goals Marie.
Similarly, strategy-proofness issue considered many belief merging scenarios, rational decision making typically takes account true state
world. agents conflicting beliefs it, belief merging used
determine true state world group; manipulating belief
merging process way agent change resulting beliefs group level
make close beliefs. consequence, decisions made group
may also change become closer agent would made alone. instance,
assume three friends agree mountains must avoided weather
bad. beliefs group weather bad, decision go
mountains given up. Pierre believes weather bad, may
tempted make weather bad accepted group level. Therefore, collective
decision go mountains.
several multi-agent settings agents exchange information
must make individual decisions based beliefs. many scenarios, agents tempted
get informational advantage agents, achieved gathering
much information possible hiding ones. Indeed, better informed
may help agent making better decisions agents group. instance,
Shoham Tennenholtz (2005) investigate non-cooperative computation: agent delivers piece information (truthfully not), pieces used compute
value (commonly-known) function, value given back agents;
aim agent get true value function, possible
one get it. work Shoham Tennenholtz (2005), information considered
abstract level; assuming information represent beliefs function belief
merging operator, agent wants get true merged base possibly
one get it. Contrastingly, scenarios, decisions made collectively
based beliefs group, agents satisfied beliefs group
1. Formally, model-based operator 4dH , , using Hamming distance sum aggregation function, defined Section 3.1.

50

fiThe Strategy-Proofness Landscape Merging

close beliefs. paper, focus issue,
addressed many everyday life situations. Let us illustrate example:
Example 2 position available university. committee charge
recruitment determine right profile position. Four criteria
considered: research skills, teaching skills, relationship skills, past positions
candidate. Suppose member committee believes important criteria
job research skills relationship skills, better recruit candidate
got good position past. pleased recruitment group shares
beliefs right profile. tempted manipulate merging process
order achieve situation.
Determining whether belief/goal merging operator strategy-proof, negative case, identifying restrictions strategy-proofness ensured thus
important issue. Indeed, merging operators intended characterize beliefs/goals
group agents, beliefs/goals agent group; obviously,
objective cannot reached agents report true beliefs/goals,
easily case manipulable merging operators used (since agents
tempted manipulate process case).
Since merging operators typically used artificial systems, one wonder whether
strategy-proofness really relevant issue context. answer actually depends
sophistication agents consideration. Thus, distributed database
setting, (low-level) agents (i.e., databases) typically evaluation/preference
merged base, strategy-proofness issue make sense.
story agents goals reasoning capacities. case, cannot
discarded agents able foresee weakenesses aggregation process
exploit benefits. high-level artificial agents involved,
strategy-proofness problem even stricking case human agents
superior computational abilities artificial systems.
strategy-proofness issue studied years domain Social Choice
Theory (Arrow, Sen, & Suzumura, 2002). important objective design preference
aggregation procedures (and, particular, voting procedures) strategy-proof.
famous result, known Gibbard-Sattherwaite theorem, objective cannot
reached absolute manner: number sensible requirements, strategyproof voting procedure may exist (Gibbard, 1973; Satterthwaite, 1975). Strategy-proofness
achieved relaxing requirements, enough escape
Gibbard-Sattherwaite theorem. shall return topic Section 7
connections belief merging preference aggregation considered
depth.
objective paper draw strategy-proofness landscape many
merging operators literature, including model-based ones formula-based ones.
focused operators merging bases sets propositional formulas,
priorities bases available. (classical) propositional logic framework
argued representation setting expressive enough many AI scenarios; furthermore,
natural investigate first key problems raised aggregation manipulation
simple setting, considering sophisticated logics. operator
51

fiEveraere, Konieczny & Marquis

consideration, aim determining whether strategy-proof general case,
restrictions merging process (including number agents
presence integrity constraints) set available strategies agents.
rest paper organized follows. Section 2, formal preliminaries
provided. Section 3, definitions main propositional merging operators
literature recalled. Several definitions strategy-proofness based general notion
satisfaction index given Section 4 strategy-proofness results reported
Section 5. discussed Section 6. Then, connections Social Choice Theory
related works pointed Section 7, conclusion. Proofs
reported end paper.

2. Formal Preliminaries
consider propositional language L defined finite (and non-empty) set propositional variables P standard connectives, including >, Boolean constant always
true, , Boolean constant always false.
interpretation (or world) total function P {0, 1}, denoted bit
vector whenever strict total order P specified. set interpretations noted
W. interpretation model formula L makes true
usual truth functional way.
[] denotes set models formula , i.e., [] = { W | |= }. order
avoid heavy notations, identify interpretation canonical term P
unique model. instance, P = {a, b} (a) = 1, (b) = 0,
identified term b.
formula L consistent [] 6= . logical consequence
formula , noted |= [] []. Two formulas logically equivalent ()
share models.
belief/goal base K denotes set beliefs/goals agent. finite
consistent set propositional formulas, interpreted conjunctively.VWhen K belief/goal
b denotes singleton base containing conjunction K formulas
base, K
K. base said complete exactly one model. belief/goal
base K characterizes bipartition set interpretations: models K
interpretations acceptable agent, countermodels not.
K belief base, interpretation acceptable enough evidence
true state world; K goal base, acceptable sufficiently
desired. bipartition considered approximation full belief/goal
preference structure corresponding agent: belief case, least preferred
0 means fact true state world least plausible
fact 0 true state world; goal case, least preferred
0 means fact would true state world least desired
fact 0 would true state world.
belief/goal profile E associated group n agents involved merging
process. non-empty multi-set (bag) belief/goal bases E = {K1 , . . . , Kn } (hence
different agents allowed exhibit identical bases). Note profiles non-ordered
(multi-)sets; thus, profile representation groups agents induces anonymity prop52

fiThe Strategy-Proofness Landscape Merging

erty: agent importance agents group result
merging process depends bases (i.e., exchanging bases
two agents gives profile, hence merged base).
V
V
V
WeVdenote E conjunction

bases

E
=
{K
,
.
.
.
,
K
},
i.e.,
E
=
(
1
n
W
W
V K1 )
. . . (V Kn ), denote E disjunction bases E, i.e., E = ( K1 )
. . . ( Kn ).
V
profile E said consistent E consistent. multi-set union
noted multi-set containment relation noted v. cardinal finite set
(or finite multi-set) noted #(A). denote set containment strict set
containment, i.e., B B 6= B.
E denotes pre-order W (i.e., reflexive transitive relation), <E denotes
associated strict ordering defined , 0 W, <E 0 E 0
0 6E .
result merging (the bases from) profile E merging operator 4,
integrity constraints base, noted 4 (E), called merged base.
integrity constraints consist consistent formula (or, equivalently, (finite) consistent
conjunction formulas) merged base satisfy (it may represent physical laws,
norms, etc.); words, models merged base models integrity
constraints.

3. Merging Operators
recall section two main families merging operators literature.
first family defined selection interpretations (model-based operators).
second family defined selection formulas union bases (formulabased operators). details two families, see example (Konieczny, Lang,
& Marquis, 2004).
3.1 Model-Based Operators
first family based selection models integrity constraints,
closest ones profile. Closeness usually defined notion distance
aggregation function (Revesz, 1997; Konieczny & Pino Perez, 1998, 1999; Lin & Mendelzon,
1999; Liberatore & Schaerf, 1998).
Definition 1 (pseudo-distances)
pseudo-distance interpretations total function : W W 7 R+ s.t.
, 0 , 00 W: d(, 0 ) = d( 0 , ), d(, 0 ) = 0 = 0 .
distance interpretations pseudo-distance satisfies triangular
inequality: , 0 , 00 W, d(, 0 ) d(, 00 ) + d( 00 , 0 ).
Two widely used distances interpretations Dalal distance (Dalal, 1988),
denoted dH , Hamming distance interpretations (the number propositional atoms two interpretations differ); drastic distance, denoted
53

fiEveraere, Konieczny & Marquis

dD , one simplest pseudo-distances one define: gives 0 two interpretations one, 1 otherwise.
Definition 2 (aggregation functions) aggregation function f total function associating nonnegative real number every finite tuple nonnegative real numbers s.t.
x1 , . . . , xn , x, R+ :
x y, f (x1 , . . . , x, . . . , xn ) f (x1 , . . . , y, . . . , xn ).

(non-decreasingness)

f (x1 , . . . , xn ) = 0 x1 = . . . = xn = 0.
f (x) = x.

(minimality)
(identity)

Widely used functions max (Revesz, 1997; Konieczny & Pino Perez, 2002),
sum (Revesz, 1997; Lin & Mendelzon, 1999; Konieczny & Pino Perez, 1999),
leximax GM ax (Konieczny & Pino Perez, 1999, 2002).
chosen distance interpretations induces distance2 interpretation base, turn gives distance interpretation profile,
using aggregation function. latter distance gives needed notion closeness represented pre-order W induced E, noted E . pre-order interpreted
plausibility ordering associated merged base.
Definition 3 (distance-based merging operators) Let pseudo-distance
interpretations f aggregation function. result 4d,f
(E) merging E
given integrity constraints defined by:
0
0
[4d,f
(E)] = min([], E ) = { [] | @ [], <E }

pre-order E W induced E defined by:
E 0 d(, E) d( 0 , E),
d(, E) = fKE (d(, K)),
d(, K) = min0 |=K d(, 0 ).
Observe dd,f (, E) would correct notation d(, E); however, since
ambiguity choice function f distance interpretations
following, prefer lighter notation d(, E).
Let us step back example given introduction order illustrate modelbased merging operators:
Example 3 Consider set P three propositional variables l(long period), s(easide)
m(ountains), taken order. goals three agents given
following bases: [K1 ] = {000, 001, 111} (Maries wishes), [K2 ] = {001, 110} (Alains wishes)
[K3 ] = {000, 110} (Pierres wishes). integrity constraint ( >).
2. Abusing words since distance mathematical standpoint.

54

fiThe Strategy-Proofness Landscape Merging

[dH , ({K1 , K2 , K3 })] = {000, 001, 110}. Table 1 gives details
computation. first column gives possible words. Ki (i = 1 . . . 3) columns give
interpretation value dH (, Ki ). Finally, rightmost column gives
interpretation value dH (, {K1 , K2 , K3 }). interpretations
dH (, {K1 , K2 , K3 }) minimal (in bold) models merged base dH , ({K1 , K2 ,
K3 }).

000
001
010
011
100
101
110
111

K1
0
0
1
1
1
1
1
0

K2
1
0
1
1
1
1
0
1



>H

K3
0
1
1
2
1
2
0
1

,

({K1 , K2 , K3 })
1
1
3
4
3
4
1
2

Table 1: Merging dH , .

3.2 Formula-Based Operators
main family merging operators gather so-called formula-based operators
syntax-based operators. Formula-based operators based selection consistent subsets formulas union bases profile E. Several operators
obtained letting vary selection criterion. result merging process
set consequences inferred selected subsets (Baral, Kraus, Minker, &
Subrahmanian, 1992; Rescher & Manor, 1970; Konieczny, 2000). operators,
syntactic form bases may easily influence result merging process: replacb = {1 . . . n } may
ing base K = {1 , . . . , n } (logically equivalent) base K
lead change corresponding merged base (while case model-based
operators).
Definition 4 (maximal consistent subsets) Let K base integrity constraint. maxcons(K, ) set maximal (w.r.t. set inclusion) consistent
subsets (maxcons short) K {} contains , i.e., maxcons(K, ) set
consistent satisfy:
K {},
,
0 K {}, 0 consistent.
maximality must taken respect cardinality (instead set inclusion),
shall use notation maxconscard (K, ).
Now, profile E integrity constraint , set
[
maxcons(E, ) = maxcons(
Ki , )
Ki E

55

fiEveraere, Konieczny & Marquis

Observe set-theoretic union (and multi-set union) used here.
following operators defined far (Baral, Kraus, & Minker, 1991; Baral
et al., 1992; Konieczny, 2000):
Definition 5 (formula-based merging operators) Let E profile let
integrity constraint:
W
V
4C1
(E)
maxcons(E,) ( ).
V
W
4C3
(E)
|M maxcons(E,>) {} consistent ( ).
W
V
4C4
(E)
maxconscard (E,) ( ).
V
W
maxcons(E,>) {} consistent ( {M {}})
4C5
consistent,
(E)

otherwise.
operators clearly select much formulas union bases,
consistency requirement. differences lie meaning
much. operators defined Baral et al. (1992), except 4C5
modification 4C3 ensures consistency. Indeed, unlike operators listed here,
C2 operator
4C3
may generate inconsistent merged bases (as empty disjunction). 4
also introduced Baral et al. (1992), shown equivalent 4C1 (this
listed above). important drawback operators take
account sources formulas issued.3 Nevertheless,
appealing, simple definition.
illustrate behaviour formula-based operators, let us step back example
given introduction. Since absence constraints makes operators 4C1 , 4C3
4C5 coincide, shall add following constraint: = l s, i.e., turns
group take holidays long period cannot go seaside.
Example 4 Suppose Marie, Alain Pierres goals encoded following
bases: K1 = {l s, l m}, K2 = {l s, m}, K3 = {l s, m}.
integrity constraints = l s, maxcons(E, ) contains two sets: {l m, m}
C3
C4
C5
{m}. get 4C1
(E) , 4 (E) , 4 (E) l m, 4 (E) .
syntax sensitivity operators due fact comma symbol
, appears expression bases, specific, yet truth-functional,
connective (Konieczny, Lang, & Marquis, 2005) usually equivalent standard
conjunction formula-based framework. operators may easily lead merged
bases differ counterparts commas replaced conjunctions
input bases. example, = >, K1 = {a b}, K2 = {(a b)} K10 =
C1
0
{a, b}, fact K10 K1 imply 4C1
({K1 , K2 }) 4 ({K1 , K2 }), since
C1
C1
0
4 ({K1 , K2 }) > 4 ({K1 , K2 }) b. See (Konieczny et al., 2005)
3. possible avoid taking advantage selection function (Konieczny, 2000).

56

fiThe Strategy-Proofness Landscape Merging

detailed discussion meaning comma connective frameworks reasoning
inconsistency.
b singleton base containing
Clearly enough, one replaces base K K,
b
conjunction elements making union, resulting operators, noted 4C
,
longer sensitive syntactic presentation bases (replacing every base
logically equivalent one leads merged base). Formally, have:
Definition 6 (other formula-based merging operators) Let E = {K1 , . . . , Kn }
profile let integrity constraint:
c
Ci c
c
4Ci
(E) = 4 ({K1 , . . . , Kn }).

Remark 1 Observe 4C4 equivalent model-based operator dD , = dD ,GM ax .
c
Indeed, 4C4 returns disjunction maximal (for cardinality) consistent subsets
profile constraints. exactly operator dD , = dD ,GM ax
achieves since amounts define set models merged base set interpretations satisfy constraints maximal number bases profile, i.e.,
interpretations models maximal (for cardinality) consistent subset
profile constraints.
c

4. Strategy-Proofness
strategy-proofness issue merging operator stated follows: possible
given agent improve result merging process respect
point view lying true beliefs/goals, given knows beliefs/goals
agent group way beliefs/goals merged? question
answered positively, operator strategy-proof (the agent may benefit
untruthful). Thus, merging operator strategy-proof one find profile
E = {K1 , . . . , Kn } represents bases agents, integrity constraint ,
two bases K K 0 s.t. result merging E K 0 better agent
result merging E true base K (called initial base).
Definition 7 (strategy-proofness) Let satisfaction index, i.e., total function
L L IR.
profile E said manipulable base K given merging operator
integrity constraint exists base K 0 i(K, (E
{K 0 })) > i(K, (E {K})).
merging operator strategy-proof integrity
constraint profile E = {K1 , . . . , Kn } E manipulable i.
Given two bases (interpreted conjunctively) K, K , value i(K, K ) intended
indicate much base K close merged base K . need satisfaction
indexes comes fact information given agent base
K: full preference structure sets interpretations available agent
57

fiEveraere, Konieczny & Marquis

additional input (e.g., form utility function), one could use
define strategy-proofness directly given agent (as done Social Choice Theory,
Arrow et al., 2002) uniform way agents. explains call
satisfaction index utility function.
Clearly, many different ways define satisfaction agent given
merged base. many ad hoc definitions considered, consider following
three indexes are, according us, meaningful ones additional
information agents available. far know, first time
indexes considered context pure propositional merging.
first two indexes drastic ones: range {0, 1}, agent either fully
satisfied satisfied all.
Definition 8 (weak drastic index)

1
idw (K, K ) =
0

K K consistent,
otherwise.

index takes value 1 result merging process (noted K definition) consistent agents base (K), 0 otherwise. means agent
considered fully satisfied soon beliefs/goals consistent merged base.
Definition 9 (strong drastic index)

ids (K, K ) =

1
0

K |= K,
otherwise.

index takes value 1 agents base logical consequence result
merging process, 0 otherwise. order fully satisfied, agent must impose
beliefs/goals whole group.
last index Boolean one, leading gradual notion satisfaction.
compatible merged base agents base satisfied agent.
compatibility degree K K (normalized) number models K
models K well:
Definition 10 (probabilistic index) #([K ]) = 0, ip (K, K ) = 0, otherwise:
ip (K, K ) =

#([K] [K ])
.
#([K ])

ip (K, K ) probability get model K uniform sampling models
K . index takes minimal value model K models
merged base K , maximal value model merged base model
K.
Strategy-proofness three indexes independent notions:
Theorem 1
1. merging operator strategy-proof ip , strategy-proof idw .
58

fiThe Strategy-Proofness Landscape Merging

2. Consider merging operator generates consistent bases.4 strategyproof ip , strategy-proof ids .
hand, easy prove strategy-proofness idw strategyproofness ids logically independent general case (an operator strategyproof one without strategy-proof other, strategy-proof
neither).
Let us conclude section running example, give formal arguments
explaining Marie manipulate merging process:
Example 5 consider three bases [K1 ] = {000, 001, 111} (Maries wishes), [K2 ] =
{110, 001} (Alains wishes) [K3 ] = {110, 000} (Pierres wishes). constraint
( >).
dH ,
({K1 , K2 , K3 })] = {000, 001, 110} ids (K1 , d>H , ({K1 , K2 , K3 })) = 0.
[>
Marie reports [K10 ] = {000, 001} instead K1 , [d>H , ({K10 , K2 , K3 })] = {000,
001} ids (K1 , d>H , ({K10 , K2 , K3 })) = 1.
See Table 2 details computations.

000
001
010
011
100
101
110
111

K1
0
0
1
1
1
1
1
0

K10
0
0
1
1
1
1
2
2

K2
1
0
1
1
1
1
0
1

K3
0
1
1
2
1
2
0
1



>H

,

({K1 , K2 , K3 })
1
1
3
4
3
4
1
2



>H

,

({K10 , K2 , K3 })
1
1
3
4
3
4
2
4

Table 2: dH , strategy-proof ids .
rest paper, shall focus three indexes, idw , ids ip . Note
investigating indexes interesting. particular, probabilistic index
viewed rough measure similarity bases. Could complex
similarity measures sets (see e.g., Tversky, 2003) also prove useful define
sensible indexes interesting question let research.

5. Strategy-Proofness Results
general case, family model-based operators family formulabased operators strategy-proof three indexes consider. means
operators families strategy-proof. However, imposing
restrictions may lead strategy-proofness results. Considering
systematic way allows us draw strategy-proofness landscape families.
following, consider four natural restrictions merging process, listed
below:
4. I.e., (E) always consistent.

59

fiEveraere, Konieczny & Marquis

first restriction concerns number bases merged. question
following: number bases involved merging process influence
strategy-proofness operator? general, answer positively
question. precisely, distinction cases #(E) = 2
#(E) > 2. situations, manipulation possible two bases,
bases, becomes possible. Since base {>} typically plays role
neutral element operators consider (i.e., 4 (E) 4 (E t{>})),
operator strategy-proof profiles n bases, strategy-proof
profiles > n bases.
second parameter completeness beliefs/goals agent aims
manipulating. cases, strong beliefs/goals renders manipulation impossible. Working complete bases (i.e., singleton sets models) makes
merging process close uninominal vote, i.e., vote unique interpretation.
third significant parameter presence integrity constraints. one hand,
nontrivial integrity constraints ( 6 >) make manipulation possible,
case integrity constraints considered, converse
also holds.
Another restriction bears available manipulations. general case untruthful agent free reporting base, even quite far true base.
However, numerous situations agents participating
merging process information true base. cases, agents
report bases close real ones. Two particular manipulations
studied: erosion manipulation agent pretends believe/desire
(the agent gives parts models); dilatation manipulation
agent pretends believe/desire less (the agent gives
parts countermodels).
5.1 Model-Based Operators
first result general strategy-proofness result (i.e., aggregation
function distance) model-based operators. surprising
one reminds existence Gibbard-Satterthwaite theorem, states
good strategy-proof preference aggregation method (see Section 7).
However, quite general strategy-proofness results obtained. following
theorem gives them, organized general one (for aggregation
function drastic distance dD considered), specific ones (for distance
aggregation function ):
Theorem 2
Let f aggregation function. dD ,f strategy-proof ip , idw ids .
Let distance. Provided two bases merged, d,
> strategyproof indexes idw ids .
60

fiThe Strategy-Proofness Landscape Merging

distance d, d,
strategy-proof indexes ip , idw ids

initial base K complete.
interesting note dD , (which coincides dD ,GM ax ) close voting
procedure called approval voting (Brams & Fishburn, 1983), agent vote
(approve) many candidates wants, elected candidates ones
get greatest number votes.
shown running example, family merging operators dH ,f obtained
considering Hamming distance letting aggregation function f vary
strategy-proof. Let us focus family, consider successively two operators
obtained considering GM ax aggregation functions.
dH , , number bases, presence integrity constraints completness bases significant. operator, next theorem makes precise
boundaries strategy-proofness manipulation (in following properties, K
represents initial base #(E) number bases profile E):
Theorem 3
dH , strategy-proof idw ids ( > #(E) = 2) K
complete.
dH , strategy-proof ip K complete.
contrast dH , , dH ,GM ax strategy-proof even restricted situations:
Theorem 4
dH ,GM ax strategy-proof satisfaction indexes idw ip (even >,
K complete #(E) = 2).
dH ,GM ax strategy-proof satisfaction index ids >, K
complete #(E) = 2.
5.2 Formula-Based Operators
C3
C4
probabilistic index, none formula-based operators 4C1
, 4 , 4 ,
C5
4 strategy-proof. But, two drastic indexes, situations
strategy-proofness ensured:

Theorem 5
C3
C4
C5
4C1
, 4 , 4 , 4 strategy-proof ip (even >, K complete
#(E) = 2).

4C1
strategy-proof idw ids .
4C3
strategy-proof idw ids >.
4C4
strategy-proof idw ids (even >, K complete #(E) = 2).
61

fiEveraere, Konieczny & Marquis

4C5
strategy-proof idw > K complete, strategyproof ids >.
C3
C4
C5
formula-based merging operators 4C1
, 4 , 4 , 4 , results
balanced, strategy-proofness results:
c

c

c

c

Theorem 6
4C1
strategy-proof idw ids , strategy-proof ip
#(E) = 2.
c

4C3
strategy-proof idw ids >, strategy-proof ip
#(E) = 2 >.
c

4C4
strategy-proof ip , idw ids .
c

4C5
strategy-proof idw #(E) = 2 > K complete.
c

C5
4C5
strategy-proof ids #(E) = 2 >. Finally, 4
strategy-proof ip #(E) = 2.
c

c

5.3 Ensuring Strategy-Proofness: Case Complete Bases
Let us focus specific case: situation every base complete.
situation rather infrequent dealing usual belief bases, imposed
goal merging setting, especially guarantees strategy-proofness. explains
consider case paper. said above, also interesting
relationship uninominal voting systems one interprets complete base vote
corresponding interpretation.
Theorem 7 strategy-proofness results reported Table 3 hold, restriction
base complete (f stands aggregation function, distance).
sp means strategy-proof , sp means non strategy-proof even #(E) = 2 >,
sp means non strategy-proof even either #(E) = 2 >, strategy-proof
#(E) = 2 >. Finally, sp> means non strategy-proof even #(E) = 2,
strategy-proof whenever >.
Theorem 7 shows, operator among dH ,GM ax 4C
ones ensures
full strategy-proofness restricted case two complete bases merged
integrity constraint considered. Contrastingly, operators offer strategyproofness three indexes whenever every base complete.
5.4 Dalal Index
explained before, fact ip based model counting allows form
graduality corresponding notion satisfaction, contrasts drastic
indexes. Actually, non drastic indexes defined. particular, cases
agent knows result could fit beliefs/goals (e.g., beliefs/goals
62

fiThe Strategy-Proofness Landscape Merging



ip

idw

ids

dD ,f
d,

dH ,GM ax

4C1

4C3

4C4

4C5

c
4C1

c
4C3

c
4C4

c
4C5


sp
sp
sp
sp
sp
sp
sp

sp
sp
sp
sp
sp>
sp
sp

sp
sp
sp
sp
sp>
sp
sp>

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

Table 3: Strategy-proofness: complete bases
.
consistent integrity constraints), still interested achieving result
close beliefs/goals. Closeness captured notion distance,
possible satisfaction index following Dalal index:
Definition 11 (Dalal index) iDalal (K, K ) = 1

min({dH (,K ) | |=K})
.
#(P)

far know, index never carried out. sake homogeneity
previous indexes, greater iDalal (K, K ) satisfied agent associated
K. iDalal grows antimonotonically Hamming distance two bases
consideration, i.e., minimal distance model first base
model second one. Thus, index takes minimal value every variable must
flipped obtain model K model K, takes maximal value
whenever K consistent K (no flip required).
direct observation iDalal (K, K ) idw (K, K ), whatever bases K
K . Investigating strategy-proofness profile E Dalal index given merging
operator integrity constraint makes sense situation K (E)
inconsistent. Indeed, remaining case, iDalal (K, (E)) takes maximal value 1
manipulation possible.
contrast three previous indexes considered, merging operators
strategy-proof iDalal , even restricted situations.
Theorem 8 None dD , , dD ,GM ax , dH , dH ,GM ax strategy-proof iDalal ,
even restricted case E consists two complete bases.
C
Theorem 9 None 4C
operators (hence, none 4 operators) strategy-proof
iDalal , even restricted case E consists two complete bases.
b

63

fiEveraere, Konieczny & Marquis

5.5 Restricted Strategies
situations agents participating merging process
information bases agents. instance, cooperative problem
solving, decided whenever agent able answer query within
limited amount time, communicate agents. Contrastingly,
communication protocol may force agent inform agents definitely
able answer query. information exchanges allow agents get
partial view models countermodels true beliefs/goals agent,
conflicts reported beliefs/goals, untruthful agent unmasked.
clearly wrong thing untruthful agent since opinion could ignored;
even punished guilty behaviour.
consider two restrictions available manipulations (and corresponding
notions strategy-proofness): erosion manipulation agent pretends believe/desire (the agent gives parts models); dilatation manipulation agent pretends believe/desire less (the agent
gives parts countermodels).
Definition 12 (erosion dilation)
Erosion manipulation holds reported base K 0 logically stronger
true one K: K 0 |= K
Dilation manipulation holds reported base K 0 logically weaker
true one K: K |= K 0 .
Erosion (resp. dilation) manipulation safe untruthful agent
agents may access subset countermodels (resp. models) true
beliefs/goals, unsafe general agents may access subset
models (resp. countermodels).
next theorem gives dilation strategy-proofness model-based operators:
Theorem 10 Let pseudo-distance let f aggregation function. d,f


dilation strategy-proof indexes ip , idw ids .
result compared ones unrestricted case (previous sections),
operators strategy-proof.
story erosion. One easily find profiles manipulated
using erosion manipulation (see running example). Interestingly, focusing erosion
strategy-proofness proves sufficient situations. Indeed, distance,
aggregation function drastic index id considered, d,
strategy-proof

id erosion strategy-proof id :
Theorem 11 Let distance. d,
strategy-proof index idw (resp.

ids ), erosion strategy-proof idw (resp. ids ).
result corollary, showing enough focus complete base
implies K determine whether profile E manipulable base K idw :
64

fiThe Strategy-Proofness Landscape Merging

Corollary 12 profile E manipulable K idw (resp. ids ) given d,

manipulation possible using complete base K |= K, i.e., exists K |= K
d,
d,
s.t. idw (K, d,
(E {K })) > idw (K, (E {K})) (resp. ids (K, (E {K })) >
d,
ids (K, (E {K}))).

6. Discussion
paper, drawn strategy-proofness landscape many merging operators,
including model-based ones formula-based ones. families strategyproof general case, shown several restrictions merging framework
available strategies may lead strategy-proofness.
model-based operators, choice right distance appears crucial. Thus,
model-based operators strategy-proof based drastic distance,
typically strategy-proof based Dalal distance.
Among formula-based merging operators 4C1
achieves highest degree strategyproofness sense strategy-proof drastic indexes.
results summed Table 4 (sp means strategy-proof sp means
strategy-proof). space reasons, results restricted strategies reported
(see Section 5.5), well ones concerning complete bases (see Table 3).
derived results, appears strategy-proofness easier achieve
formula-based operators model-based ones, especially bases singlec
tons (i.e., 4Ci operators). could explained fact latter
operators obey all-or-nothing principle base either selected whole (and included maxcons) selected may forbid subtle
manipulations.
also exhibited restricted strategies constrain agent wants
manipulate. example, model-based operators strategy-proof dilation.
results paper based three satisfaction indexes, are,
according us, natural ones additional information merging
process available. three indexes share property two bases jointly
inconsistent, satisfaction minimal. call consistency property.
order handle scenarios consistency property discriminant enough,
introduced Dalal index. turns none operators considered paper
strategy-proof index.
choice satisfaction index (by definition) major impact existence
manipulation. explained before, full preferences agents sets
interpretations available, strategy-proofness could easily defined Social Choice
Theory: manipulation occurs merged base obtained agent lies
strictly preferred (w.r.t. preference) merged base obtained
reports true base. information available, several choices
index possible, capturing different intuitions.
beliefs merged, indexes satisfying consistency property seem
suited remaining ones; indeed, latter indexes, even merged base close
agents beliefs, still compatible them. Drawing conclusion
easy goals merged, since instance, case
65

fiEveraere, Konieczny & Marquis



#(E)

K







,f



H

,



H

,Gmax

4C1


4C3


4C4


4C5


4C1


4C3


4C4


4C5


c

c

c

c

>

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

6 >

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

>

complete
6 >

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

>

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

6 >

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

>

complete
6 >

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

>

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

6 >

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

>

complete
6 >

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

>

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

6 >

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

>

complete
6 >

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

>

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

6 >

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

>

complete
6 >

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

>

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

6 >

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

>

complete
6 >

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

complete
=2

ip
complete
>2

complete
=2

idw
complete
>2

complete
=2

ids
complete
>2

Table 4: Synthesis results.

66

fiThe Strategy-Proofness Landscape Merging

agents, goals satisfied, better. Nevertheless, three satisfaction indexes idw ,
ids ip still meaningful scenarios, since agent typically satisfied
goals group compatible ones case.
light study, strategy-proofness appears property independent computational complexity query answering merged base (see Konieczny et al., 2004).
means low/high complexity prevent/imply strategy-proofness.
Strategy-proofness appears also independent fact operator satisfies
rationality postulates given Konieczny Pino Perez (1999, 2002). Indeed, direct
consequence Theorems 2 3, majority (resp. arbitration) merging
operators (Konieczny & Pino Perez, 2002) strategy-proof, others not. Thus,
satisfying rationality postulates merging proves sufficient ensure strategyproofness manipulability. Nevertheless, note arbitration operators, like
d,GM ax , sensitive manipulation majority operators, like d, .
easily explained fact arbitration operators egalitarist ones: aim
giving result close base profile. Intuitively, small change
base heavily change whole result. Contrastingly, majority operators, listen
majority wishes defining merged base, often take account bases
far majority. So, using majority operators, likely small change
base impact merged base.
Thus, strategy-proofness viewed dimension used
compare merging operators, besides computational complexity rationality criteria.
independence latter criteria may also explain strategy-proofness results
wide families operators seem exist.

7. Related Work
explained paper, manipulation problem studied extensively
Social Choice Theory years. next subsection relate work
stream research. second subsection mention related work concerning
strategy-proofness issue weighted bases.
7.1 Social Choice Theory
propositional merging framework considered paper, beliefs/goals K
agent induce two-strata partition interpretations: models K equally
preferred, strictly preferred countermodels, equally disliked.
agents report full preference relations (that encoded various ways, e.g., explicitly,
prioritized base, ordinal conditional function, etc.), aggregation problem
consists defining global preference relation individual preference relations.
problem addressed centuries Social Choice Theory. traced back
least Condorcet (1785) Borda (1781).
Social Choice Theory (Arrow et al., 2002), strategy-proofness problem received great attention. framework, agent untruthful reports
preference relation (a complete pre-order set alternatives) true
one. social choice function (associating alternative profile preference
relations) strategy-proof alternative chosen function lies
67

fiEveraere, Konieczny & Marquis

ranked higher alternative chosen reports true preferences.
One famous result Social Choice Theory good strategyproof preference aggregation procedure. result known Gibbard-Satterthwaite
impossibility theorem (Gibbard, 1973; Satterthwaite, 1975; Moulin, 1988).
Formally, consider set agents (individuals) N = {1, . . . , n}, set alternatives
= {a, b, . . .}. agent preference relation alternatives, supposed
complete, reflexive transitive binary relation, noted . preference profile
P = (1 , . . . , n ) assigns preference relation agent. Let us note P set
possible preference profiles. given preference profile noted P = (Pi , ),
N , Pi denotes profile P without (the preferences of) individual i. social
choice function f mapping P A. social choice function manipulable
individual N , preference relation 0 , preference profile P
f (Pi , 0i ) >i f (P ), i.e., agent best satisfied result
claims preferences 0i instead true preference . social choice function
manipulable, said strategy-proof. social choice function dictatorial
individual N (the dictator), f (P )
P P. social choice function onto alternative preference
profile P P f (P ) = a. Gibbard-Satterthwaite theorem (Gibbard, 1973;
Satterthwaite, 1975) stated as:
Theorem 13 (Gibbard, 1973; Satterthwaite, 1975) contains least three alternatives, social choice function f onto, strategy-proof non-dictatorial.
Since result stated, lot work deriving strategyproofness results restrictions (see Kelly, 1988; Arrow et al., 2002).
sense, work relevant approaches. Nonetheless, work original - far
know - two points view: one hand, preference relations considered
two-strata total pre-orders, arbitrary pre-orders; hand,
result merging process usually single interpretation still two-strata total
pre-order (and number models merged base constrained priori).
leads complex notions strategy-proofness different definitions possible,
depending index formalizes one various intuitive notions satisfied
agent result merging process.
social choice theory, also works social choice correspondences,
mapping P 2A , closer framework social choice functions. data coming individuals preference relations A, problem
shift preference relations 2A . standard way achieve consider
even set chosen correspondence, ultimately one alternative
realized, suppose individual subjective probability measure
realization. social choice correspondance strategy-proof possible
individual increase expected utility result. case, results similar Gibbard-Satterthwaite theorems derived (see e.g., Barbera, Dutta, & Sen,
2001; Chin & Zhou, 2002; Duggan & Schwartz, 2000). works related one
conducted paper, suppose agent makes available
full preference relation alternatives form utility function typically
reducible two-strata complete pre-order also subjective probability measure
68

fiThe Strategy-Proofness Landscape Merging

alternatives. Contrastingly, work, information coming agent
corresponding base, typically approximates full preference relation,
pure ordinal nature.
7.2 Strategy-Proofness Weighted-Bases Merging
study strategy-proofness merging operators carried Meyer,
Ghose, Chopra (2001). framework consider distinct one used
work. one hand, agents may report full preference relations (encoded
ordinal conditional functions, also called -functions, see Spohn, 1987). hand,
merging operators consideration escape Gibbard-Satterthwaite theorem since
Meyer et al. (2001) make commensurability assumption agents preference
relations (the remark applies also possibilistic base merging defined Benferhat,
Dubois, Kaci, & Prade, 2002). Roughly, commensurability assumption amounts
consider weights (or levels) associated formulas meaning
agents, i.e., weight 3 agent 1 weight 3 agent
2. commensurability assumption sensible many situations, dealing
agents preferences, commensurability must used carefully. human agents,
commonly accepted Social Choice Theory assumption strong. Arrow
(1963) illustrates idea quoting Bentham:
vain talk adding quantities addition continue
distinct before, one mans happiness never another mans
happiness: gain one man gain another; might well pretend
add 20 apples 20 pears...
notion strategy-proofness merging operators Meyer et al. (2001)
Chopra, Ghose, Meyer (2006) defined framework ordinal conditional functions. section, study corresponding operators pure propositional
framework, i.e., profile contains flat belief/goal bases, order compare
approach.
ordinal conditional function (OCF) total function set interpretations W set non-negative integers (originally, OCF maps interpretation
class ordinals, least one interpretation mapped zero,
considering integers sufficient here). Intuitively, greater number, less
credible interpretation. OCF one associate base Bel() defined
[Bel()] = { W | () = min0 W (( 0 ))}. aim OCF merging operators is,
profile OCFs E = {1 , . . . , n } define OCF (E) best represents
profile. operators studied Meyer et al. (2001) following ones:
max (E)() = maxi E (),

21 () () = j () , j E
min1 (E)() =
2 mini E () + 1 otherwise,

1 () () = j () , j E
min2 (E)() =
mini E () + 1 otherwise,
69

fiEveraere, Konieczny & Marquis

(E)() =

P

E

().

straightforward way translate framework propositional merging ordinal conditional functions consider propositional base special case OCF:
propositional base two-strata OCF, models bases rank 0
countermodels rank 1. consider two-strata OCFs note Ki = Bel(i )
= Bel( ), previous definitions merging operators give:
V
max (E) min2 (E) E consistent max (E) min2 (E) > otherwise.
V
W
min1 (E) E consistent min1 (E) E otherwise.
(E) dD , (E).
resulting propositional merging operators max , min1 , min2 , quite
simple well-known. max (or equivalently min2 ) so-called basic merging operator (in absence integrity constraints) (Konieczny & Pino Perez, 1999). min1
1-quota operator defined Everaere, Konieczny, Marquis (2005) (without integrity
constraints). corresponds intersection operator defined Konieczny (2000).
operators strategy-proof indexes:
Theorem 14 max , min1 , min2 , strategy-proof idw , ids ip .
Besides operators, Meyer, Chopra Ghose also proposed general definitions
strategy-proofness OCF merging. precisely, studied two properties.
first one (IP) property (Meyer et al., 2001):
Definition 13 (IP) OCF merging operator satisfies (IP) property
every OCF profile E, every agent i, whatever OCF
W, | (E)() ()| | (rep(E, {i}, )() ()|
rep(E, {i}, ) profile identical E except OCF replaced .
Focusing two-strata OCFs, say merging operator (= Bel( )) strategyproof (IP) satisfies (IP) property every agent given profile.
obtained following characterization:
Theorem 15 strategy-proof (IP) every profile E every pair
bases K K 0 :
K (E {K}) |= (E {K 0 }),
K (E {K}) |= (E {K 0 }).
second strategy-proofness property Meyer, Chopra Ghose investigated (WIP):
70

fiThe Strategy-Proofness Landscape Merging

Definition 14 (WIP) OCF merging operator satisfies (WIP) property
every profile E, every agent i, whatever OCF :
W | (E)() ()| W | (rep(E, {i}, )() ()|.
(WIP) weaker (IP) sense OCF merging operator satisfies
(IP) agent i, satisfies (WIP) (but converse always hold).
Again, focusing two-strata OCFs, say merging operator (= Bel( ))
strategy-proof (WIP) satisfies (WIP) property every agent
given profile.
V
V
V
V
Let us note exclusive operator, i.e., K K 0 = ( K K 0 ) ( K K 0 ).
(WIP) characterized framework :
Theorem 16 Let iwip (K, K ) =
strategy-proof iwip .

1
#([KK ])+1 .

satisfies (WIP) property

Note wip index iwip close probabilistic index ip . probabilistic index measures closeness merged base agent base, whereas wip
index measures difference merged base agent base.
However, corresponding notion strategy-proofness (and fortiori one induced
(IP)) appears strong pure propositional setting. Consider following belief
merging scenario:
Example 6 Consider K = K1 = b.We dH , ({K, K1 }) b.
agent gives K 0 = {a b} instead K, merged base dH , ({K 0 , K1 }) a.
Accordingly, example manipulation (WIP) (iwip (dH , ({K, K1 })) = 12 <
iwip (dH , ({K 0 , K1 })) = 1).
example, untruthful agent actually manages change merged base
one similar initial base (with respect iwip ).
fully satisfied merged base equivalent b still strictly prefers initial
base {a}, despite fact b refines beliefs. Accordingly, agent
wants preserve beliefs ignorance. many scenarios agent
participates merging process order get new information, counter-intuitive.
Chopra et al. (2006) give general definitions strategy-proofness, considering
similarity relations. propositional case, suffer above-mentioned
drawback. explains investigate strategy-proofness purely
propositional model-based operators formula-based operators criteria like (WIP)
(IP).

8. Conclusion
Investigating strategy-proofness merging operators important multi-agent
perspective whenever agents get information conveyed agents
participating merging process. strategy-proofness guaranteed, may
questioned whether result merging process actually represents beliefs/goals
group.
71

fiEveraere, Konieczny & Marquis

paper, drawn strategy-proofness landscape many existing merging
operators, including model-based ones formula-based ones, general case
several natural restrictions. Strategy-proofness appears independent complexity
rationality aspects, used such, criterion evaluate merging
operators. results discussed Section 6.
work calls number perspectives. first perspective identify complexity determining whether profile manipulated base given operator.
Indeed, using merging operator strategy-proof necessarily harmful finding strategy computationally hard. complexity issue investigated
voting schemes (Conitzer & Sandholm, 2003; Conitzer, Lang, & Sandholm, 2003; Conitzer
& Sandholm, 2002a, 2002b) individual preferences given explicitly (which
case framework). first result follows easily Theorem 11: distance
interpretations computed polynomial time input size (which
strong assumption), determining whether given profile manipulated base
p
drastic index given d,
2 .
Social Choice Theory, Gibbard-Sattertwhaite theorem states every sensible
social choice function manipulable. Taking account fact agents
tempted manipulate transforms aggregation process game agents.
ensuring strategy-proofness, prove sufficient build game telling
truth optimal strategy agent. achieve aim implementation
theory (also called mechanism design), see e.g., Maskin & Sjostrom, 2002. perspective
determine whether building mechanisms possible belief merging setting
order force agents tell truth. work mechanism design assume
transferable utility, use payments part process. Importing ideas
fully qualitative framework surely hard task.
Another interesting perspective study strategy-proofness problem coalitions allowed. Instead considering manipulation single agents, one interested manipulation coalition agents coordinate improve result
coalition. See (Meyer et al., 2001; Chopra et al., 2006) definition different
framework. Since manipulation single agent particular case manipulation
coalition, since seen many operators strategy-proof single
agent, clear strategy-proofness results coalitions hard achieve.

Acknowledgements
authors would like thank anonymous referees thoughful comments
helped us lot improve paper. authors supported Universite
dArtois, Region Nord/Pas-de-Calais, IRCICA Consortium, European
Community FEDER Program.

72

fiThe Strategy-Proofness Landscape Merging

Appendix A. Proofs
Theorem 1
1. merging operator strategy-proof ip , strategy-proof idw .
2. Consider merging operator generates consistent bases.5 strategyproof ip , strategy-proof ids .
Proof:
1. Assume strategy-proof idw . exists profile E, base
K, base K 0 integrity constraint s.t. (1) (E {K}) K inconsistent,
#([K][ (Et{K})])
= 0. (2)
(2) (E {K 0 }) K consistent. (1) implies #([ (Et{K})])
implies

#([K][ (Et{K 0 })])
#([ (Et{K 0 })])

> 0. Hence, strategy-proof ip .

2. Assume strategy-proof ids . exists profile E, base
K, base K 0 integrity constraint s.t. (1) (E {K}) 6|= K, (2)
#([K][ (Et{K})])
(E {K 0 }) |= K. (1) implies #([ (Et{K})])
6= 1. (2) implies
#([K][ (Et{K 0 })])
#([ (Et{K 0 })])

= 1 (E {K 0 }) consistent. Hence, strategy-

proof ip .


Theorem 2
Let f aggregation function. dD ,f strategy-proof ip , idw ids .
Let distance. Provided two bases merged, d,
> strategyproof indexes idw ids .
distance d, d,
strategy-proof indexes ip , idw ids

initial base K complete.
Proof:
Let f aggregation function. dD ,f strategy-proof ip , idw ids .
proof organized three steps: reduction ad absurdum, show
minimal drastic distance model E {K} equal minimal
drastic distance model E {K 0 }. Then, easy show
number Ks models greater E {K} E {K 0 }. Finally, prove
number countermodels K greater E {K 0 } E {K},
entails contradiction.
5. I.e., (E) always consistent.

73

fiEveraere, Konieczny & Marquis

Theorem 1, know operator dD ,f strategy-proof ip , also
strategy-proof idw ids (indeed, dD ,f (E) always consistent).
sufficient prove strategy-proofness dD ,f ip prove strategy-proofness
three indexes.
Let us prove reductio ad absurdum: assume operator dD ,f ,
dD drastic distance f aggregation function, strategy-proof
ip . exist integrity constraint , profile E, two bases K
K 0 s.t. ip (K, dD ,f ({K} E)) < ip (K, dD ,f ({K 0 } E)), equivalent
#([K] [E 4dD ,f K])
#([E 4dD ,f K])

<

#([K] [E 4dD ,f K 0 ])
#([E 4dD ,f K 0 ])

E 4dD ,f K light notation dD ,f ({K} E)). Let us note dmin (E tdD ,f
{K}) = min({dD (, E {K}) | |= }, ). show dmin (E tdD ,f {K}) =
dmin (E tdD ,f {K 0 }):
Let us first notice ip (K, E 4dD ,f K) 6= 1: ip (K, E 4dD ,f K) = 1,
probabilistic satisfaction index takes maximal value, impossible increase it.
Since ip (K, E 4dD ,f K) < 1, #([K][E 4dD ,f K]) < #([E 4dD ,f K]),
least one model E 4dD ,f K belong K:
1 |= (K) , dD (1 , E {K}) = dmin (E tdD ,f {K}).
Since 1 |= (K) , dD (1 , K) = 1 distance maximal
(because use drastic distance). get immediately dD (1 , K)
dD (1 , K 0 ). Hence dD (1 , E t{K}) dD (1 , E t{K 0 }) (because aggregation
function f satisfy non-decreasingness). Since dD (1 , E {K}) = dmin (E tdD ,f
{K}), get dmin (E tdD ,f {K}) dD (1 , E {K 0 }). Since dD (1 , E {K 0 })
dmin (E tdD ,f {K 0 }) definition min since 1 |= ,
dmin (E tdD ,f {K}) dmin (E tdD ,f {K 0 }) ().
also conclude ip (K, E 4dD ,f K 0 ) 6= 0: ip (K, E 4dD ,f K 0 ) = 0,
ip (K, E 4dD ,f K 0 ) minimal, value taken ip increased,
contradicts assumption (manipulation).
ip (K, E 4dD ,f K 0 ) 6= 0, find least one model K
E 4dD ,f K 0 : 1 |= K , dD (1 , E t{K 0 }) = dmin (E tdD ,f {K 0 }). Since 1 |= K,
dD (1 , K) = 0 since distance minimal, get dD (1 , E
{K}) dD (1 , E {K 0 }), dD (1 , E {K}) dmin (E tdD ,f {K 0 }),
dD (1 , E {K 0 }) = dmin (E tdD ,f {K 0 }). Furthermore, since dD (1 , E
{K}) dmin (E tdD ,f {K}) definition min 1 |= , have:
dmin (E tdD ,f {K}) dmin (E tdD ,f {K 0 }) ().
74

fiThe Strategy-Proofness Landscape Merging

inequations (*) (**), get:
dmin (E tdD ,f {K}) = dmin (E tdD ,f {K 0 }).

(1)

Let us show increase number countermodels K
E 4dD ,f K 0 , decrease number models K E 4dD ,f K 0 .
Let countermodel K model E 4dD ,f K: |= (K)
(E 4dD ,f K).
Since |= K, dD (, K) = 1 distance maximal. Hence
dD (, K) dD (, K 0 ). So:
dD (, E {K}) dD (, E {K 0 })

(2)

aggregation function f satisfies non-decreasingness.
Since |= E 4dD ,f K, dD (, E {K}) = dmin (E tdD ,f {K}). (2),
get dmin (E tdD ,f {K}) dD (, E {K 0 }).
Since dmin (E tdD ,f {K}) = dmin (E tdD ,f {K 0 }) (1), obtain: dmin (E tdD ,f
{K 0 }) dD (, E {K 0 }). definition min since |= (because |=
E 4dD ,f K), deduce model E 4dD ,f K 0 . conclude
every model E 4dD ,f K model K model E 4dD ,f K 0 .
Hence: [K] [E 4dD ,f K] [K] [E 4dD ,f K 0 ].
Finally, let model K model E 4dD ,f K 0 : |= K (E 4dD ,f
K 0 ). Since |= K, dD (, K) = 0 distance minimal. Hence
dD (, K) dD (, K 0 ). So:
dD (, E {K}) dD (, E {K 0 })

(3)

aggregation function non-decreasing.
Since |= E 4dD ,f K 0 , dD (, E {K 0 }) = dmin (E tdD ,f {K 0 }).
(3), get dD (, E {K} dmin (E tdD ,f {K 0 }). Since dmin (E tdD ,f {K}) =
dmin (E tdD ,f {K 0 }) (1), obtain dD (, E {K} dmin (E tdD ,f {K}).
definition min since |= (because |= E 4dD ,f K 0 ), deduce
model E 4dD ,f K. conclude every model E 4dD ,f K 0
model K model E 4dD ,f K. follows [K] [E 4dD ,f K 0 ]
[K] [E 4dD ,f K].
Since increase number countermodels K E 4dD ,f K 0
decrease number models K E 4dD ,f K 0 , proportion models K
E 4dD ,f K 0 smaller E 4dD ,f K. contradicts assumption shows
dD ,f strategy-proof ip .
Let distance. Provided two bases merged, d,

>
strategy-proof indexes idw ids .
75

fiEveraere, Konieczny & Marquis

proof, first show merging two bases consistent base.
Then, property follows directly.
Strategy-proofness two drastic indexes direct consequence following
property:
d,
Lemma 1 E = {K1 , K2 }, d,
> (E) K1 > (E) K2 consistent.

Proof:
show d,
> (E) K1 consistent (the remaining case similar
symmetry). Reductio ad absurdum. Let us suppose two bases K1 K2 ,
d,
> ({K1 , K2 }) inconsistent K1 . deduce that:
0 |= K1 , |= K1 , d(, K1 4d, K2 ) > d( 0 , K1 4d, K2 ),
K1 4d, K2 light notation d,
> ({K1 , K2 }).
Since |= K1 , d(, K1 ) = 0, get 0 |= K1 , |= K1 , d(, K2 ) >
d( 0 , K1 ) + d( 0 , K2 ). particular, consider 1 |= K1 s.t. d( 0 , 1 ) = d( 0 , K1 )
(such 1 exists definition d( 0 , K1 )), have: d(1 , K2 ) > d( 0 , 1 ) +
d( 0 , K2 ). Similarly, consider 2 |= K2 s.t. d( 0 , 2 ) = d( 0 , K2 ), get:
d(1 , K2 ) > d( 0 , 1 ) + d( 0 , 2 ) ().
definition d, |= K2 , d(1 , K2 ) d(1 , ); particular, d(1 , K2 )
d(1 , 2 ). transitivity , (*), get d(1 , 2 ) > d( 0 , 1 ) + d( 0 , 2 ).
contradicts triangular inequality.

Let us prove main theorem:
Weak drastic index. two bases K1 K2 , always idw (K1 , K1 4 K2 ) = 1,
d,
> ({K1 , K2 }) K1 consistent (Lemma 1), manipulation possible
(idw maximal).
0
Strong drastic index. d,
> strategy-proof, find K1 s.t.:
d,
0
ids (K1 , d,
> ({K1 , K2 }) < ids (K1 , > ({K1 , K2 }).

strong drastic index, means exactly that:
d,
> ({K1 , K2 }) 6|= K1

(4)

0
d,
> ({K1 , K2 }) |= K1 .

(5)

and:
0
Since d,
> ({K1 , K2 }) K2 consistent (Lemma 1), find 2 |= K2 s.t. 2 |=
0
d,
> ({K1 , K2 }). (5), conclude 2 |= K1 well.

Since 2 |= K1 K2 , conclude every model d,
> ({K1 , K2 }),
d,
d(, {K1 , K2 }) = 0. |= > ({K1 , K2 }), d(, K1 ) = d(, K2 ) = 0.
Hence |= d,
> ({K1 , K2 }), |= K1 K2 . contradicts (4), manipulation
possible.
76

fiThe Strategy-Proofness Landscape Merging

distance d, d,
strategy-proof indexes ip , idw ids

initial base K complete.
drastic indexes, result consequence Theorem 11, showing
manipulation occurs initial base K, manipulation complete base
K |= K possible. K complete, manipulation possible.
probabilistic index, result consequence triangular inequality.
Drastic indexes. property direct consequence Theorem 11, showing
d,
manipulable idw ids base K, manipulable erosion.
manipulation erosion impossible whenever K complete.
Probabilistic index. reductio ad absurdum: let us suppose operator
d,
, distance, manipulable ip given complete base K =
{1 }. So, exists integrity constraint , profile E, base K 0 s.t.:
d,
0
ip ({1 }, d,
({1 } E)) < ip ({1 }, ({K } E)).
d,
ip ({1 }, d,
({1 } E)) = 0, idw ({1 }, ({1 } E)) = 0 too. case,
manipulation ip implies manipulation idw seen manipulation possible idw . consequence, suppose ip ({1 }, d,
({1 }
E)) 6= 0. Equivalently:
#({1 } [E 4
{1 }])
6= 0

#([E 4 {1 }])
d,
(where E 4
{1 } light notation ({1 } E)).
statement allows us infer 1 model E 4
{1 }. order
d,
0
0
increase ip ({1 }, (K E)), reduce number models E 4
K


0
compared E 4 {1 }, without removing 1 [E 4 K ]. find

0
2 6= 1 s.t. 2 |= E 4
{1 } 2 6|= E 4 K . So, 2 |= d(2 , E
0
{1 }) = d(1 , E {1 }) and: d(2 , E {K }) > d(1 , E {K 0 }) (because 1

0
model E 4
{1 } E 4 K ). aggregation function , get:
d(2 , 1 ) + d(2 , E) = d(1 , E) d(2 , K 0 ) + d(2 , E) > d(1 , K 0 ) + d(1 , E).

Replacing d(1 , E) d(2 , 1 )+d(2 , E), obtain d(2 , K 0 )+d(2 , E) > d(1 , K 0 )+
d(2 , 1 ) + d(2 , E), d(2 , K 0 ) > d(1 , K 0 ) + d(2 , 1 ). 10 model K 0 s.t.
d(1 , K 0 ) = d(1 , 10 ), d(2 , K 0 ) > d(1 , 10 ) + d(2 , 1 ). Furthermore
definition min, d(2 , 10 ) d(2 , K 0 ), d(2 , 10 ) > d(1 , 10 ) + d(2 , 1 )
contradicts triangular inequality.

Theorem 3
dH , strategy-proof idw ids ( > #(E) = 2) K
complete.
dH , strategy-proof ip K complete.
77

fiEveraere, Konieczny & Marquis

Proof:
Theorem 2 entails straightforwardly part proof, taking
Hamming distance dH d.
part proof, shall show examples manipulation dH ,
strategy-proof cases.
first examples show dH , strategy-proof idw ids ( 6 >
#(E) 6= 2), K complete.
Weak drastic index.
idw 6 > (K complete)
consider constraint = ab two bases K1 K2 defined
set models: [K1 ] = {00, 01} [K2 ] = {10}. [dH , ({K1 , K2 })] =
{10} idw (K1 , dH , ({K1 , K2 })) = 0. hand, agent whose
base K1 gives K10 , [K10 ] = {01} instead K1 , obtain [dH , ({K10 ,
K2 })] = {01, 10, 11} idw (K1 , dH , ({K10 , K2 }) = 1. example shows
manipulability dH , 6 >, even two bases profile.
Computations detailed Table 5. Interpretations satisfy
constraint shaded.

00
01
10
11

dH (, K1 )
0
0
1
1

dH (, K10 )
1
0
2
1

dH (, K2 )
1
2
0
1



H

,



H

({K1 , K2 })
1
2
1
2

,

({K10 , K2 })
2
2
2
2

Table 5: Manipulability dH , idw 6 >.
idw #(E) 6= 2 (K complete)
Let us consider three bases [K1 ] = {00, 10}, [K2 ] = {01, 10, 11} [K3 ] =
{01}. d>H , ({K1 , K2 , K3 }) unique model 01 idw (K1 , d>H , ({K1 ,
K2 , K3 }) = 0. consider [K10 ] = {10} instead K1 , [d>H , ({K10 ,
K2 , K3 })] = {01, 10, 11} idw (K1 , dH , ({K10 , K2 , K3 }) = 1. See Table 6.

00
01
10
11

K1
0
1
0
1

K10
1
2
0
1

K2
1
0
0
0

K3
1
0
2
1



>H

,

({K1 , K2 , K3 })
2
1
2
2



>H

,

({K10 , K2 , K3 })
3
2
2
2

Table 6: Manipulability d>H , idw #(E) 6= 2.
Strong drastic index.
78

fiThe Strategy-Proofness Landscape Merging

ids 6 > (K complete)
consider constraint = (a b) (a b c) two bases K1
K2 defined sets models: [K1 ] = {000, 111} [K2 ] = {000, 001}.
[dH , ({K1 , K2 })] = {111, 100} ids (K1 , dH , ({K1 , K2 })) = 0.
hand, agent whose base K1 gives K10 , [K10 ] = {111} instead
K1 , obtain [dH , ({K10 , K2 })) = {111} ids (K1 , dH , ({K10 , K2 }) = 1.
example shows manipulability dH , ids 6 >, even
two bases profile. Details computation reported
Table 7.

000
001
010
011
100
101
110
111

K1
0
1
1
1
1
1
1
0

K10
3
2
2
1
2
1
1
0

K2
0
0
1
1
1
1
2
2



H

,

({K1 , K2 })
0
1
2
2
2
2
3
2



H

,

({K10 , K2 })
3
2
3
2
3
2
3
2

Table 7: Manipulability dH , ids 6 >.
ids #(E) 6= 2 (K complete)
Let us consider three bases [K1 ] = {000, 001, 111}, [K2 ] = {110, 001}
[K3 ] = {110, 000}. [d>H , ({K1 , K2 , K3 })] = {000, 001, 110}
ids (K1 , d>H , ({K1 , K2 , K3 }) = 0.
consider [K10 ] = {000, 001} instead K1 , [d>H , ({K1 , K2 , K3 })] =
{000, 001} ids (K1 , d>H , ({K10 , K2 , K3 }) = 1. See Table 8.

000
001
010
011
100
101
110
111

K1
0
0
1
1
1
1
1
0

K10
0
0
1
1
1
1
2
2

K2
1
0
1
1
1
1
0
1

K3
0
1
1
2
1
2
0
1



>H

,

({K1 , K2 , K3 })
1
1
3
4
3
4
1
2



>H

,

({K10 , K2 , K3 })
1
1
3
4
3
4
2
4

Table 8: Manipulability dH , ids #(E) 6= 2.
following example shows dH , strategy-proof ip K complete. Table 9 shows manipulability d>H , ip (even two bases
profile >). Let us consider two bases K1 K2 defined
sets models: [K1 ] = {000, 001, 010, 100} [K2 ] = {110, 011, 101, 111}.
79

fiEveraere, Konieczny & Marquis

[d>H , ({K1 , K2 })] = {001, 010, 100, 110, 011, 101} ip (K1 , d>H , ({K1 , K2 })) = 21 .
hand, agent whose base K1 gives K10 , [K10 ] = {000} instead K1 , obtain [d>H , ({K10 , K2 })] = {000, 001, 010, 100, 110, 011, 101}
ip (K1 , d>H , ({K10 , K2 }) = 47 .

000
001
010
011
100
101
110
111

K1
0
0
0
1
0
1
1
2

K10
0
1
1
2
1
2
2
3



>H

K2
2
1
1
0
1
0
0
0

,

({K1 , K2 })
2
1
1
1
1
1
1
2



>H

,

({K10 , K2 })
2
2
2
2
2
2
2
3

Table 9: Manipulability d>H , ip K complete.


Theorem 4
dH ,GM ax strategy-proof satisfaction indexes idw ip (even >,
K complete #(E) = 2).
dH ,GM ax strategy-proof satisfaction index ids >, K
complete #(E) = 2.
Proof:
Table 10 shows manipulability dH ,GM ax weak satisfaction index idw
even >, K complete #(E) = 2. consider K1 s.t. [K1 ] = {001}, K2
[K2 ] = {111}, >. [dH ,GM ax ({K1 , K2 })] = {011, 101},
model K1 belongs [dH ,GM ax ({K1 , K2 })] idw (K1 , dH ,GM ax ({K1 , K2 }) = 0.
agent 1 gives K10 [K10 ] = {000} instead K1 , [dH ,GM ax {K10 , K2 })] =
{001, 010, 011, 100, 101, 110} idw (K1 , dH ,GM ax ({K10 , K2 }) = 1.

000
001
010
011
100
101
110
111

K1
1
0
2
1
2
1
3
2

K10
0
1
1
2
1
2
2
3

K2
3
2
2
1
2
1
1
0



H

,GM ax

({K1 , K2 })
(3, 1)
(2, 0)
(2, 2)
(1, 1)
(2, 1)
(1, 1)
(3, 1)
(2, 0)



H

,GM ax

({K10 , K2 })
(3, 0)
(2, 1)
(2, 1)
(2, 1)
(2, 1)
(2, 1)
(2, 1)
(3, 0)

Table 10: Manipulability dH ,GM ax idw .
80

fiThe Strategy-Proofness Landscape Merging

Since manipulability idw holds, manipulability ip holds well (cf. Theorem 1).
ids , first show dH ,GM ax strategy-proof index >,
#(E) = 2 K complete. Then, give examples manipulation 6 >,
#(E) 6= 2, K complete.
d>H ,GM ax strategy-proof E = {K1 , K2 } >, K1 complete.
consider E 0 = {K10 , K2 } K10 = K0 1 complete (thanks forthcoming
Lemma 2, know operator manipulable, manipulable
complete base), >. Let #(P) = n let d(K10 , K2 ) = n.
exists model 2 K2 s.t. dH (K0 1 , 2 ) = m. definition
Hamming distance, 2 generated 1 flipping variables (since
K0 1 2 differ truth values variables x1 , . . . , xm ).
= 2k + 1 (m odd), d(>, E 0 ) = (k + 1, k); otherwise = 2k (m
even) d(>, E 0 ) = (k, k). first case (m odd), exist least two
interpretations 0 s.t. d(, E 0 ) = d( 0 , E 0 ) = d(>, E 0 ) (for instance,
generated 1 flipping x1 , . . . , xk 0 generated 2 flipping
xk+1 , . . . , xm ).
similar conclusion derived second case (m even) soon k 1.
two cases, d>H ,GM ax (E 0 ) least two models, hence cannot
d>H ,GM ax (E 0 ) K1 K1 complete: E cannot manipulated K1 ids .
remaining case d(>, E 0 ) = (0, 0). imposes K0 1 K2 consistent.
Since K0 1 complete, d>H ,GM ax (E 0 ) K0 1 , hence manipulation
dH ,GM ax
possible ids (since >
(E 0 ) K1 K1 K0 1
dH ,GM ax
>
({K1 , K2 }) K1 ).
showing manipulability ids , consider following scenarios:
6 >, even #(E) = 2 K complete.
Let us consider [K1 ] = {01}, [K2 ] = {11}, = b. [dH ,GM ax ({K1 ,
K2 }] = {01, 11}, ids (K1 , dH ,GM ax ({K1 , K2 }) = 0. agent 1 gives K10
[K10 ] = {00} instead K1 , result [dH ,GM ax ({K10 , K2 })] =
{01} ids (K1 , dH ,GM ax ({K10 , K2 }) = 1. (see Table 11).

00
01
10
11

K1
1
0
2
1

K10
0
1
1
2

K2
2
1
1
0



H

,GM ax

({K1 , K2 })
(2, 1)
(1, 0)
(2, 1)
(1, 0)



H

,GM ax

({K10 , K2 })
(2, 0)
(1, 1)
(1, 1)
(2, 0)

Table 11: Manipulability dH ,GM ax ids 6 >
#(E) 6= 2, even > K complete.
Let us consider [K1 ] = {01}, [K2 ] = {11}, [K3 ] = {00, 01, 11}.
[d>H ,GM ax ({K1 , K2 , K3 }] = {01, 11}, ids (K1 , d>H ,GM ax ({K1 , K2 , K3 }) =
81

fiEveraere, Konieczny & Marquis

0. agent 1 gives K10 [K10 ] = {00} instead K1 , [d>H ,GM ax ({K10 ,
K2 , K3 })] = {01} ids (K1 , d>H ,GM ax ({K10 , K2 , K3 }) = 1. (see Table 12).

00
01
10
11

K1
1
0
2
1

K10
0
1
1
2

K2
2
1
1
0

K3
0
0
1
0



H

,GM ax



H

({K1 , K2 , K3 })
(2, 1, 0)
(1, 0, 0)
(2, 1, 1)
(1, 0, 0)

,GM ax

({K10 , K2 , K3 })
(2, 0, 0)
(1, 1, 0)
(1, 1, 1)
(2, 0, 0)

Table 12: Manipulability d>H ,GM ax ids #(E) 6= 2.
K complete, even > #(E) = 2.
example given Table 13 shows manipulation possible initial base complete. Consider [K1 ] = {01, 10}, [K2 ] = {11},
>. [dH ,GM ax ({K1 , K2 }] = {01, 10, 11}, ids (K1 , dH ,GM ax ({K1 ,
K2 }) = 0. agent 1 gives K10 [K10 ] = {00} instead K1 ,
[dH ,GM ax ({K10 , K2 })] = {01, 10} ids (K1 , dH ,GM ax ({K10 , K2 }) = 1.

00
01
10
11

K1
1
0
0
1

K10
0
1
1
2

K2
2
1
1
0



H

,GM ax

({K1 , K2 })
(2, 1)
(1, 0)
(1, 0)
(1, 0)



H

,GM ax

({K10 , K2 })
(2, 0)
(1, 1)
(1, 1)
(2, 0)

Table 13: Manipulability dH ,GM ax ids K complete.



Theorem 5
C3
C4
C5
4C1
, 4 , 4 , 4 strategy-proof ip (even >, K complete
#(E) = 2).

4C1
strategy-proof idw ids .
4C3
strategy-proof idw ids >.
4C4
strategy-proof idw ids (even >, K complete #(E) = 2).
4C5
strategy-proof idw > K complete, strategyproof ids >.
Proof:
82

fiThe Strategy-Proofness Landscape Merging

first give example manipulation 4C1
ip , #(E) = 2, complete
base K1 , >.
Consider E = {K1 , K2 }, K1 = {a b} K2 = {(a b)}. 4C1
> (E) >,
1
0 = {a, b} instead K ,
ip (K1 , 4C1
(E))
=
.


agent
1
gives
K
1
1
>
4
1
0
C1
0
4C1
> ({K1 , K2 }) b, ip (K1 , 4> ({K1 , K2 })) = 3 . E manipulable K1
C1
C3
ip . example holds 4C4
. remains note 4> = 4> =
4C5
> conclude first point proof.
4C1
strategy-proof idw ids .
Weak drastic index.
K E two cases:
K
subset
consistent. least one maximal consistent
C1
Ki E Ki contains formulas K. 4 (E t{K}) R
(where R denotes disjunction maxcons) consistent K .
idw (K, 4C1
(E {K})) = 1 manipulation possible.
0
K consistent. Since K 0 , 4C1
(E {K })) |= , also
C1
0
idw (K, 4 (E {K })) = 0 manipulation possible.

Strong drastic index.
reductio ad absurdum. Assume 4C1
strategy-proof ids . means

K s.t. 4C1
(6)
(E {K}) 6|= K,
0
K 0 s.t. 4C1
(E {K }) |= K.

(7)

statement (7) get maxcons(E {K 0 }, ), |= K.
0
0
0
consider 4C1
(E {K } {K}), every maxcons(E {K } {K}, )
0
C1
0
form {K}, |= K 4 (E {K } {K}) |= K ().
statement (6) get maxcons(E {K}, ), 6|= K. Since
maximal subset, means K consistent. consider 4C1
(E
{K 0 } {K}), 0 , 0 maxcons(E {K 0 } {K}, ). 0 K
0
consistent. Hence 0 6|= K 4C1
(E {K} {K }) 6|= K, contradicts
().
4C3
strategy-proof idw ids >.
Weak drastic index.
C3
C1
C3
Since 4C1
> = 4> , follows immediately proof 4 4>
strategy-proof idw .

showing manipulation possible 4C3
6 >, even two bases
complete initial base K1 , consider following example: let K1 = {ab}, K2 = {a},
= b K10 = {a}. C3
({K1 , K2 }) a, inconsistent K1 .
0 , K }) >, consistent K .
also C3
({K
2
1

1
83

fiEveraere, Konieczny & Marquis

Strong drastic index.
C3
C3
Since 4C1
> = 4> , follows immediately point 4> strategyproof ids .

showing manipulation possible 4C3
ids 6 >, even two
bases complete initial base K1 , consider following example: let K1 = {a
b}, K2 = {a}, = b K10 = {a b}. C3
({K1 , K2 }) a, hence
C3
C3
0
0
({K1 , K2 }) 6|= K1 . also ({K1 , K2 }) , hence C3
({K1 , K2 }) |=
K1 .
4C4
strategy-proof idw ids (even >, K complete #(E) = 2).
Weak drastic index.
showing manipulation possible 4C4
two bases, complete initial base K1 >, consider following example: let K1 = {a}, K2 =
{a, >}, = > K10 = {a, >}. C4
({K1 , K2 }) a, hence
C4
0
({K1 , K2 }) K1 consistent. also C4
({K1 , K2 }) >, hence
C4
0
({K1 , K2 }) K1 consistent.
Strong drastic index.
showing 4C4
strategy-proof ids two bases, complete initial
base K1 >, consider following example: let K1 = {a}, K2 = {a},
C4
K10 = {a, >}. C4
({K1 , K2 }) >, hence ({K1 , K2 }) 6|= K1 . also
0
C4
0
C4
({K1 , K2 }) a, hence ({K1 , K2 }) |= K1 .
4C5
strategy-proof idw > K complete, strategyproof ids >.
Weak drastic index.
C5
C1
C5
Since 4C1
> = 4> , follows proof 4 4 strategy-proof
idw >.

initial base K1 complete, 4C5
also strategy-proof. two cases:

K1 |= . Let
= { KE K | K1 |= }. construction, element
maxcons( KE K, >). Since K1 |= , consistent (K1 model
them). Since K1 |= |= C5
(E) (by definition
C5 (E) K consistent,
operator), also K1 |= C5
(E).
Hence

1


prevents E manipulable K1 idw given C5
.
K1 |= . definition operator, base K10 profile E 0
0
0
(especially profile obtained removing K1 E), C5
({K1 }tE )
0
0
C5
0
0
consistent C5
({K1 } E ) |= . implies ({K1 } E ) K1
inconsistent, manipulation possible idw .
showing manipulation possible 4C5
6 > initial base K1
complete, consider following example:
84

fiThe Strategy-Proofness Landscape Merging

let K1 = {a}, K2 = {b, a}, = ab K10 = {ab}. C5
({K1 , K2 })
C5
C5
b a, hence ({K1 , K2 }) K1 consistent. also ({K10 , K2 })
0
(a b) (b a), hence C4
({K1 , K2 }) K1 consistent.
Strong drastic index.
C5
C1
C5
Since 4C1
> = 4> , follows immediately proof 4 4
strategy-proof ids >.

showing manipulation possible 4C5
6 >, even two bases
complete initial base K1 , consider following example: let K1 = {a b},
K2 = {b}, = K10 = {a b, b a}. C5
({K1 , K2 }) a, hence
C5
C5
0
0
({K1 , K2 }) 6|= K1 . also ({K1 , K2 }) ab. Hence C5
({K1 , K2 }) |=
K1 .

Theorem 6
4C1
strategy-proof idw ids , strategy-proof ip #(E) =
2.
c

4C3
strategy-proof idw ids >, strategy-proof ip
#(E) = 2 >.
c

4C4
strategy-proof ip , idw ids .
c

4C5
strategy-proof idw #(E) = 2 > K complete.
c

C5
4C5
strategy-proof ids #(E) = 2 >. Finally, 4
strategy-proof ip #(E) = 2.
c

c

Proof:
4C1
strategy-proof idw ids , strategy-proof ip #(E) =
2.
c

Drastic indexes. strategy-proofness 4C1
comes strategy-proofness
c

C1
C1
4C1
reported Theorem 5, 4 specialization 4 . Furthermore,
C1
examples given proof Theorem 5 concerning 4 , every base
c

singleton, examples hold 4C1
too.
c

Probabilistic index.
proof probabilistic index profile E s.t. #(E) = 2 based fact
c
merging two bases 4C1
either conjunction two bases,
disjunction. cases, shall show manipulation occur.
part proof, suppose #(E) = 2. shall show 4C1

c

4C5
(we group two cases, proofs similar) strategy-proof
ip . case analysis:
c

85

fiEveraere, Konieczny & Marquis

K1 consistent , two cases:
C5
4C1
({K1 , K2 }) 4 ({K1 , K2 }) K1 K2 consistent.
c

c

C5
4C1
({K1 , K2 }) 4 ({K1 , K2 }) (K1 K2 ) otherwise.
c

c

C5
first case, 4C1
({K1 , K2 }) |= K1 4 ({K1 , K2 }) |= K1 ip takes
maximal value, manipulation possible.
c

c

C5
Let us consider second case 4C1
(the case 4 similar): assume
c

c

4C1
({K1 , K2 }) (K1 K2 ) .
c

C1
0
Since every base K10 , definition 4C1
requires 4 ({K1 ,
c

c

K2 }) |= since K1 |= 4C1
({K1 , K2 }), following inequation
0
holds every base K1 :
c

0
C1
#([K1 ] [4C1
({K1 , K2 })]) #([K1 ] [4 ({K1 , K2 })]).
c

c

0
0
K10 K2 consistent, 4C1
({K1 , K2 }) K1 K2 , hence
c

0
#([K1 ][4C1
({K1 , K2 })]) = 0 minimal since assumed K1 K2
inconsistent.
K10 K2 inconsistent, two cases:
c

0
K10 inconsistent K2 inconsistent. 4C1
({K1 , K2 })
c

. Since assumed K1 consistent, also 4C1
({K1 , K2 })
K1 . Hence:
c

c

#([K1 ] []
,
#([])

ip (K1 , 4C1
({K1 , K2 })) =

#([K1 ] [K1 ]
.
#([K1 ])

0
ip (K1 , 4C1
({K1 , K2 })) =


c

Since numerators two fractions coincide #([K1 ]) #([]),
manipulation possible case.
0
K10 consistent K2 consistent. 4C1
({K1 , K2 })
0
(K1 K2 ) . Since K1 K2 inconsistent,
c

0
ip (K1 , 4C1
({K1 , K2 })) =

#([K1 K10 ])
.
#([(K10 K2 ) ])

ip (K1 , 4C1
({K1 , K2 })) =

#([K1 ])
.
#([(K1 K2 ) ])

c

also have:
c

Now, since K10 K2 inconsistent, #([(K10 K2 ) ]) =
#([K10 ]) + #([K2 ]). Similarly, since K1 K2 inconsistent,
#([(K1 K2 ) ]) = #([K1 ]) + #([K2 ]). Subsequently, suppose
86

fiThe Strategy-Proofness Landscape Merging

0
C1
ip (K1 , 4C1
({K1 , K2 })) > ip (K1 , 4 ({K1 , K2 })).
case #([K1 K10 ])(#([K1 ]) + #([K2 ])) > #([K1
])(#([K10 ]) + #([K2 ])).
note = #([K1 K10 ]) b = #([K2 ]), exist two
natural integers a0 a00 #([K1 ]) = + a0 #([K10 ]) =
+ a00 . Replacing previous inequation, comes:
c

c

a(a + a0 + b) > (a + a0 )(a + a00 + b)
simplifies 0 > aa00 + a0 a00 + a0 c, impossible. Hence
manipulation possible case well.
0
C5
0
K1 consistent , then, since E 0 , 4C1
(E ) |= 4 (E ) |= ,
c

c

0
C5
0
have: E 0 , ip (K1 , 4C1
(E )) = 0 ip (K1 , 4 (E )) = 0, manipulation
possible.
c

c

part proof, following example shows strategy-proofness
c
c
C5
ip hold longer 4C1
4 #(E) 6= 2, even initial base complete >. consider K1 = {a b}, K2 = {a b}
K3 = {a}, integrity constraint = >. two maximal consistent sets maxcons({K1 , K2 , K3 }, ): M1 = {a b, >} M2 = {a, >}. Hence
c
c
1
C1
4C1
({K1 , K2 , K3 }) (a b) (a). get ip (K1 , 4 ({K1 , K2 , K3 })) = 3 .
agent 1 gives K10 = {a b} instead K1 , two maximal consistent sets M10 = {a b, >}, M20 = {a b, a, >} maxcons({K10 , K2 , K3 }, ),
c
c
1
0
C1
0
4C1
({K1 , K2 , K3 }) (a b) (a b). get ip (K1 , 4 ({K1 , K2 , K3 })) = 2 ,
example manipulation 4C1
> ip .
c

C5
C5
Since 4C1
> = 4> , example shows manipulability 4 well.
c

c

c

4C3
strategy-proof idw ids >, strategy-proof ip
#(E) = 2 >.
c

Drastic indexes.
C3
Since 4C3
> strategy-proof idw ids , specialization 4 also strategy-proof
idw ids .
c

example showing manipulation 4C3
two bases complete
initial base K1 , every base singleton, example holds 4C3
too.
c

Probabilistic index.
C3
C1
C3
Since 4C1
> = 4> , follows immediately proof 4 4>
strategy-proof ip two bases considered, case three
agents taken account.
c

c

showing manipulation possible 4C3
two bases complete initial base K1 , integrity constraint true, consider following examc
ple: let K1 = {a b}, K2 = {a}, = b K10 = {a}. 4C3
({K1 , K2 })
c

87

fiEveraere, Konieczny & Marquis

a, inconsistent K1 , ip (K1 , 4C3
({K1 , K2 })) = 0. also
c

0
C3
0
4C3
({K1 , K2 }) >, consistent K1 , ip (K1 , 4 ({K1 , K2 })) > 0.
c

c

4C4
strategy-proof ip , idw ids . direct consequence Remark 1
Theorem 2.
c

4C5
strategy-proof idw #(E) = 2 > K complete.
c

C5
4C5
strategy-proof ids #(E) = 2 >. Finally, 4
strategy-proof ip #(E) = 2.
c

c

Weak drastic index.
4C5
strategy-proof ip two bases, also strategy-proof idw
case.
c

C5
Since 4C5
> strategy-proof idw , 4 > also strategy-proof idw .
c

Finally, manipulation possible 4C5
initial base K1 complete
(Theorem 5), manipulation exists 4C5
cas.
c

Contrastingly, manipulation example exists 4C5
#(E) 6= 2 6 >
initial base K1 complete. consider three (singleton) bases:
c
K1 = {b}, K2 = {a}, K3 = {a b}, = a. 4C5
({K1 , K2 , K3 })
c

0
b, idw (K1 , 4C5
({K1 , K2 , K3 })) = 0. K1 = {b a},
c

0
C5
0
4C5
({K1 , K2 , K3 }) a, idw (K1 , 4 ({K1 , K2 , K3 })) = 1.
c

c

Strong drastic index.
C5
4C5
> strategy-proof ids , 4> also strategy-proof ids .
c

C5
4C5
strategy-proof ip two bases E, 4 also strategyc

c

proof ids case, since profile E, 4C5
(E) consistent.
c

manipulation example exists 4C5
#(E) 6= 2 6 >, even initial
base K1 complete: K1 = {a b}, K2 = {a b}, K3 = {a b}, = a.
two maximal consistent sets maxcons({K1 , K2 , K3 }, >): M1 = {a b}
c
M2 = {a b}. Hence 4C5
({K1 , K2 , K3 }) (a b) (a b). get
c

0
ids (K1 , 4C5
({K1 , K2 , K3 })) = 0. K1 = {a b}, two maximal
consistent sets maxcons({K1 , K2 , K3 }, >): M10 = {a b} M20 = {a b}.
c
c
0
C5
0
Hence 4C5
({K1 , K2 , K3 }) (a b), ids (K1 , 4 ({K1 , K2 , K3 })) = 1.
c

Probabilistic index.
C1
proof 4C5
similar proof 4 .
c

c


Theorem 7 strategy-proofness results reported Table 14 hold, restriction
base complete (f stands aggregation function, distance).
88

fiThe Strategy-Proofness Landscape Merging

f aggregation function, distance, sp means strategy-proof , sp means non
strategy-proof even #(E) = 2 >, sp means non strategy-proof even either
#(E) = 2 >, strategy-proof #(E) = 2 >. Finally, sp> means
non strategy-proof even #(E) = 2, strategy-proof whenever >.



ip

idw

ids

dD ,f
d,

dH ,GM ax

4C1

4C3

4C4

4C5

c
4C1

c
4C3

c
4C4

c
4C5


sp
sp
sp
sp
sp
sp
sp

sp
sp
sp
sp
sp>
sp
sp

sp
sp
sp
sp
sp>
sp
sp>

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

sp

Table 14: Strategy-proofness: complete bases.
Proof:

first line table (dD ,f ) direct consequence Theorem 2.

second line table (d,
) direct consequence Theorem 2.
third line table (dH ,GM ax ) comes proof Theorem 4.
first column fourth line (4C1
ip ) comes following example. Let
K1 = {a, b}, K2 = {a, b}, K10 = {a b} = >. 4C1
({K1 , K2 }) >, hence
1
C1
0
C1
ip (K1 , 4 ({K1 , K2 })) = 4 , 4 ({K1 , K2 }) (a b) (a b), showing
1
0
C1
ip (K1 , 4C1
({K1 , K2 })) = 2 . rightmost columns fourth line (4 idw ,
ids ) come directly Theorem 5.
first column fifth line (4C3
ip ) comes first column fourth
line given example s.t. > (in case operators coincide). Similarly
C3
second third columns (4C3
idw , ids ) case > (4> coincides
C3
4C1
> ). remaining case, 4 strategy-proof idw even #(E) = 2
following example shows: take E = {K1 , K2 } K1 = {a b c}, K2 = {a b, c}
= b; 4C3
(E) b c, inconsistent K1 ; agent
0
gives K10 = {a, b c} instead K1 , obtain 4C3
({K1 , K2 }) (a c) (a b c),
consistent K1 . Finally, 4C3
strategy-proof ids even #(E) = 2
6= >; let K1 = {a, b}, K2 = {a, b}, K10 = {a b} = b.
C3
4C3
({K1 , K2 }) (a b) (a b), hence ids (K1 , 4 ({K1 , K2 })) = 0,
0
C3
0
4C3
({K1 , K2 }) b, showing ids (K1 , 4 ({K1 , K2 })) = 1.
sixth line (4C4
) comes proof Theorem 5.
89

fiEveraere, Konieczny & Marquis

first column seventh line (4C5
ip ) comes first column fourth
line given example s.t. > (in case operators coincide). second
C5
column (4C5
idw ) comes directly Theorem 5. third column (4 ids )
C5
case > comes third column fourth line (4> coincides 4C1
> ).
C5
Finally, 4 strategy-proof ids even #(E) = 2 6 >; let K1 = {a, b},
K2 = {a, b}, K10 = {a b} = b. 4C5
({K1 , K2 }) (a b) (a b),
C5
C5
hence ids (K1 , 4 ({K1 , K2 })) = 0, 4 ({K10 , K2 }) b, showing
0
ids (K1 , 4C5
({K1 , K2 })) = 1.
C4
Finally, remains consider 4C
operators. 4 , know Theorem 6
strategy-proof ip (hence idw ids ) since 4C4
strategy-proof ip
c

b

C3
C5
bases singletons. Let us focus 4C1
, 4 4 . Since base complete
assumed singleton without loss generality,
c

c
4C1
({K1 , . . . , Kn })



c

c

c
4C5
({K1 , . . . , Kn })

(

n
_

Ki ) consistent,

i=1
C5
4C1
({K1 , . . . , Kn }) 4 ({K1 , . . . , Kn }) otherwise.
c

c

also have:
4C3
({K1 , . . . , Kn }) (
c

n
_

Ki ) consistent,

i=1
c
4C3
({K1 , . . . , Kn })

otherwise.

C1
C3
C5
Let 4C
operator among 4 , 4 4 . two cases:
b

c

c

c

4C
consistent. two cases:
b

0
C5
0
K1 |= . Since every profile E 0 4C1
(E ) |= 4 (E ) |= ,
c

c

0
C5
0
also 4C1
(E ) K1 inconsistent 4 (E ) K1 inconsistent, showing
manipulation possible ip , hence idw ids . specific case
consider (all bases singletons complete), also every
c
0
0
profile E 0 , 4C3
(E ) |= since base E kept element
c

c

0
maxcons(E 0 , >) must satisfy base kept, 4C3
(E ) inconsistent,
c

0
hence 4C3
(E ) |= trivially holds. previous argument used show
c

manipulation possible 4C3
ip , hence idw (and ids
c

assumption 4C3
(E) consistent).
c

K1 |= . necessarily #([K1 ] [4C
({K1 , . . . , Kn })]) = 1. reductio
ad absurdum. manipulation ip possible find complete
b
b
0
C
0
base K10 s.t. (1) K1 |= 4C
({K1 , . . . , Kn }) (2) #([4 ({K1 , . . . , Kn })]) <
b

0
#([4C
({K1 , . . . , Kn })]). (2) requires K1 |= . (1) imposes K1 |=
K10 K2 . . . Kn . Since K1 |= K10 |= , K1 6 K10 . Subsequently, exists Kj (j 2, . . . , n) s.t. K1 Kj . Since Kj model
b

90

fiThe Strategy-Proofness Landscape Merging

0
C
4C
({K1 , . . . , Kn }), inequation (2) cannot satisfied. Hence, 4 strategyb

b

proof ip , hence idw . Since 4C
(E) assumed consistent, manipulation
possible ids .
b

C
C3
4C
(E) inconsistent. possible 4 = 4 requires Ki
b

b

c

C3
(i 1, . . . , n) s.t. Ki |= . Since 4C3
(E) inconsistent, ip (K1 , 4 (E)) =
c

c

0
0. Since every K10 complete, K1 model 4C3
({K1 , . . . , Kn }),
c

C3
0
C3
ip (K1 , 4C3
(4 ({K1 , . . . , Kn }))) = 0 well. shows 4 strategy-proof
c

c

C3
ip , hence idw . Finally, 4C3
(E) inconsistent, 4 (E) |= K1 ,
showing manipulation possible ids well.
c

c


Theorem 8 None dD , , dD ,GM ax , dH , dH ,GM ax strategy-proof iDalal ,
even restricted case E consists two complete bases.
Proof:
dD , = dD ,GM ax . Let us consider [K1 ] = {000}, [K2 ] = {110} = b c
P = {a, b, c}. [dD , ({K1 , K2 })] = {110} iDalal (K1 , dD , ({K1 ,
K2 })) = 1 23 . [K10 ] = {001}, get [dD , ({K10 , K2 })] = {110, 001}
iDalal (K1 , dD , ({K10 , K2 })) = 1 13 , showing manipulation (details reported
Table 15).

000
001
010
011
100
101
110
111

K1
0
1
1
1
1
1
1
1

K10
1
0
1
1
1
1
1
1

K2
1
1
1
1
1
1
0
1





,

({K1 , K2 })
1
2
2
2
2
2
1
2





,

({K10 , K2 })
2
1
2
2
2
2
1
2

Table 15: Manipulation dD , iDalal two complete bases.
dH , . Let us consider [K1 ] = {000}, [K2 ] = {110} = ((a b c) (a
b c) (a b c)) P = {a, b, c}. [dH , ({K1 , K2 })] = {110}
iDalal (K1 , dH , ({K1 , K2 })) = 1 23 . [K10 ] = {001}, get [dH , ({K10 , K2 })] =
{110, 001, 011, 111} iDalal (K1 , dH , ({K10 , K2 })) = 1 13 , showing manipulation (details reported Table 16).
dH ,GM ax . Let us consider [K1 ] = {0001}, [K2 ] = {0111} = (a b
c d) (a b c) (a b c) (a b c d) (a b c d)
(a b c d) P = {a, b, c, d}. [dH ,GM ax ({K1 , K2 })] = {0111}
91

fiEveraere, Konieczny & Marquis


000
001
010
011
100
101
110
111

K10
1
0
2
1
2
1
3
2

K1
0
1
1
2
1
2
2
3



H

K2
2
3
1
2
1
2
0
1

,

({K1 , K2 })
2
4
2
4
2
4
2
4



H

,

({K10 , K2 })
3
3
3
3
3
3
3
3

Table 16: Manipulation dH , iDalal two complete bases.
iDalal (K1 , dH ,GM ax ({K1 , K2 })) = 1 42 . [K10 ] = {1000}, get [dH ,GM ax ({K10 ,
K2 })] = {0000, 0110, 1001, 1010, 1100, 1111} iDalal (K1 , dH ,GM ax ({K10 , K2 })) =
1 41 , showing manipulation (details reported Table 17).

0000
0001
0010
0011
0100
0101
0110
0111
1000
1001
1010
1011
1100
1101
1110
1111

K1
1
0
2
1
2
1
3
2
2
1
3
2
3
2
4
3

K10
1
2
2
3
2
3
3
4
0
1
1
2
1
2
2
3

K2
3
2
2
1
2
1
1
0
4
3
3
2
3
2
2
1



H

,GM ax

({K1 , K2 })
(3, 1)
(2, 0)
(2, 2)
(1, 1)
(2, 2)
(1, 1)
(3, 1)
(2, 0)
(4, 2)
(3, 1)
(3, 3)
(2, 2)
(3, 3)
(2, 2)
(4, 2)
(3, 1)



H

,GM ax

({K10 , K2 })
(3, 1)
(2, 2)
(2, 2)
(3, 1)
(2, 2)
(3, 1)
(3, 1)
(4, 0)
(4, 0)
(3, 1)
(3, 1)
(2, 2)
(3, 1)
(2, 2)
(2, 2)
(3, 1)

Table 17: Manipulation dH ,GM ax iDalal two complete bases.

C
Theorem 9 None 4C
operators (hence, none 4 operators) strategy-proof
iDalal , even restricted case E consists two complete bases.
b

Proof:
Let us consider complete bases K1 = {a b} K2 = {a b}, =
(ab). maxcons({K1 , K2 }, ) = {{ab, (ab)}} = maxconscard ({K1 , K2 },
c
) maxcons({K1 , K2 }, >) = {{a b, >}, {a b, >}}, hence 4C1
({K1 , K2 })
C4
C5
4C3
({K1 , K2 }) 4 ({K1 , K2 }) 4 ({K1 , K2 }) b.
c

c

c

2
get iDalal (K1 , 4C
({K1 , K2 })) = 1 2 = 0.
K10 = {a b}, maxcons({K10 , K2 }, ) = {{a b, (a b)}, {a b, (a
b)}} = maxconscard ({K10 , K2 }, ) maxcons({K10 , K2 }, >) = {{a b, >}, {a
b

92

fiThe Strategy-Proofness Landscape Merging

0
C3
0
C4
0
C5
0
b, >}}, hence 4C1
({K1 , K2 }) 4 ({K1 , K2 }) 4 ({K1 , K2 }) 4 ({K1 , K2 })
(a b) (a b) a.
b
1
0
Thus iDalal (K1 , 4C

({K1 , K2 })) = 1 2 , showing manipulation.
c

c

c

c

Theorem 10 Let pseudo-distance let f aggregation function. d,f


dilation strategy-proof indexes ip , idw ids .
Proof:
idea untruthful base K 0 contains models true
base K, merged base K 0 provided contains models K
appearing merged base K reported, countermodels K.
manipulation possible.
Theorem 1, sufficient show d,f
strategy-proof ip . reductio ad
absurdum. Let us suppose operator d,f
, f respectively
pseudo-distance aggregation function, manipulable dilation ip .
assumption, find integrity constraint , profile E, two bases K K 0
d,f
0
K |= K 0 , s.t. ip (K, d,f
({K} E)) < ip (K, ({K } E)). Using light notation
E 4 K instead d,f
({K} E), have:
#([K] [E 4 K 0 ])
#([K] [E 4 K])
<
.
#([E 4 K])
#([E 4 K 0 ])
Since K |= K 0 , pseudo-distance d, W, d(, K) d(, K 0 ). So,
aggregation function f (that satisfies non-decreasingness):
W, d(, E {K}) d(, E {K 0 }).

(8)

Let us note dmin (E {K}) = min({d(, E {K}) | |= }, ). (8),
immediately infer: dmin (E {K}) dmin (E {K 0 }). Two cases considered:
dmin (E {K}) > dmin (E {K 0 }) (*).
1 model K then, since K |= K 0 , d(1 , K) = d(1 , K 0 ) = 0, d(1 , E
{K}) = d(1 , E {K 0 }) . furthermore 1 model E 4 K 0 , d(1 , E
{K 0 }) = dmin (E {K 0 }), d(1 , E {K}) = dmin (E {K 0 }). definition
min, d(1 , E {K}) dmin (E {K}), 1 |= . conclude
dmin (E {K}) dmin (E {K 0 }), contradicts (*). So, model
K model E 4 K 0 . Consequently, ip (K, E 4 K 0 ) = 0 minimal,
prevents manipulation d,f
. So, exclude case (*).
dmin (E {K}) = dmin (E {K 0 }) (**).
model E 4 K, |= d(, E {K}) = dmin (E
{K}). So, d(, E {K}) = dmin (E {K 0 }) equation (**). Furthermore,
inequation (8), infer d(, E {K}) d(, E {K 0 }). Hence,
d(, E {K 0 }) dmin (E {K 0 }). Since model , finally infer
93

fiEveraere, Konieczny & Marquis

model E 4 K 0 well. model E 4 K model
E 4 K 0 , then:
#([E 4 K]) #([E 4 K 0 ]).
(9)
deduce well model E 4 K model K model
E 4 K 0 (and K), so:
#([K] [E 4 K]) #([K] [E 4 K 0 ]).
Furthermore, 1 |= K model E 4 K 0 , both:
d(1 , E {K 0 }) = dmin (E {K 0 }) = dmin (E {K}) (**),
d(1 , E {K}) = d(1 , E {K 0 }) K |= K 0 : since d(1 , K) = 0,
d(1 , K 0 ) = 0 too.
obtain: d(1 , E t{K}) = dmin (E {K}) 1 |= , 1 model E 4 K.
state #([K] [E 4 K]) #([K] [E 4 K 0 ]). get:
#([K] [E 4 K]) = #([K] [E 4 K 0 ]).

(10)

(9) (10), get immediately that:
#([K] #([E 4 K 0 ])
#([K] [E 4 K])

.
#([E 4 K])
#([E 4 K 0 ])

(11)

d,f
0
consequence, ip (K, d,f
({K} E) ip (K, ({K } E)). inequation
d,f
shows manipulable ip , contradicts assumption. case
(**) excluded well, concludes proof.


Theorem 11 Let distance. d,
strategy-proof index idw (resp.

ids ), erosion strategy-proof idw (resp. ids ).
Proof:

first need following lemma:

Lemma 2 Let pseudo-distance let f aggregation function. profile E
manipulable K idw (resp. ids ) given d,f
, one find complete base
K 0 base agent gives instead true base K s.t. idw (K, (E {K 0 })) >
idw (K, (E {K})) (resp. ids (K, (E {K 0 })) > ids (K, (E {K}))).
Proof:
lemma mainly consequence definition distance
interpretation base K 0 , minimal distance interpretation model
00 base; complete base whose unique model 00 allows well manipulation
Weak drastic index.
94

fiThe Strategy-Proofness Landscape Merging

suppose d,f
manipulable idw , i.e., find integrity constraint ,
profile E = {K1 , . . . , Kn }, two bases K K 0 s.t.:
d,f
0
idw (K, d,f
({K} E)) < idw (K, ({K } E)).

(12)

equivalent to: idw (K, E 4 K) = 0 idw (K, E 4 K 0 ) = 1, d,f
({K} E)
noted E 4 K simplifying notations.
Statement (13) states idw (K, E 4 K) = 0: model K model E 4 K;
statement (14) states idw (K, E 4 K 0 ) = 1: least one model K
E 4 K 0 :
|= K , 0 |= (K) , d( 0 , E {K}) < d(, E {K}).

(13)

1 |= K , |= , d(1 , E {K 0 }) d(, E {K 0 }).

(14)

Since (13) choice 0 made apart , (13) equivalent to:
0 |= (K) , |= K , d( 0 , E {K}) < d(, E {K}).

(15)

Let 00 |= K 0 s.t. d(1 , K 0 ) = d(1 , 00 ). consider complete base K 00 s.t. [K 00 ] = { 00 }.
shall show rest proof d,f
manipulable base. agent
whose beliefs/goals K gives K 00 base instead K, then, since d(1 , K 00 ) = d(1 , K 0 ),
have:
d(1 , E {K 00 }) = d(1 , E {K 0 }),
(16)
then:
|= , d(1 , E {K 00 }) d(, E {K 0 }),

(17)

(14) (16).
Furthermore, since aggregation function f non-decreasing (by definition) since
K 00 |= K 0 , |= , d(, E {K 0 }) d(, E {K 00 }), get immediately
(17):
|= : d(1 , E {K 00 }) d(, E {K 00 }).
(18)
d,f
00
00
1 model d,f
(E {K }), idw (K, ({K } E)) = 1
d,f
d,f
00
idw (K, d,f
({K} E)) < idw (K, ({K } E)). shows manipulable
00
complete base K .

Strong drastic index. Let us assume operator d,f
, pseudo-distance
f aggregation function, manipulable strong drastic index ids .Then
find integrity constraint , profile E bases K K 0 s.t. ids (K, d,f
(E
0 }). implies (K, d,f (E {K}) = 0, (K,
{K}) < ids (K, d,f
(E

{K


ds
ds
d,f
0
d,f
(E {K }) = 1. means, definition index, (E {K}) 6|= K,
0
d,f
(E {K }) |= K.
0
0
0
Given model 1 d,f
(E {K }) model 2 K s.t. d(1 , K ) = d(1 , 2 ),
define K 00 = {2 }. d(1 , K 00 ) = d(1 , K 0 ), and: d(1 , E {K 00 }) =
d(1 , E {K 0 }).

95

fiEveraere, Konieczny & Marquis

0
0
Let us note dmin (E td,f
{K }) = min({d(, E {K }) | |= }, ). Since 1 model
d,f
0
(E {K 0 }), d(1 , E {K 0 }) = dmin (E td,f
{K }). Hence:
0
d(1 , E {K 00 }) = dmin (E td,f
{K }).

(19)

00
definition min since 1 |= , also have: d(1 , E {K 00 }) dmin (E td,f
{K }).
get:
0
d,f
00
dmin (E td,f
(20)
{K }) dmin (E {K }).

hand, since K 00 |= K 0 , have: W, d(, K 0 ) d(, K 00 ). Since
aggregation function f non-decreasing, get:
W, d(, E {K 0 }) d(, E {K 00 }),

(21)

d,f
d,f
0
00
0
dmin (E td,f
{K }) dmin (E {K }). (20) get dmin (E {K }) =
d,f
d,f
00
00
00
dmin (E {K }). Then, (19), obtain d(1 , E {K }) = dmin (E {K }). Since
00
1 |= , 1 model d,f
(E {K }) too.
d,f
00
00
00
Let model d,f
(E t{K }). Then, |= d(, E t{K }) = dmin (E {K }).
d,f
d,f
0
00
00
Then, since dmin (E td,f
{K }) = dmin (E {K }), d(, E {K }) = dmin (E
0
{K 0 }). (21), get d(, E {K 0 }) dmin (E td,f
{K }).
0
Then, definition min d(, E {K 0 }) = dmin (E td,f
{K }).
0
implies model d,f
(E {K }) (because |= ), write:
d,f
d,f
00
0
0
d,f
(E {K }) |= (E {K }). Since (E {K }) |= K, infer
d,f
00
00
d,f
(E {K }) |= K, ids (K, (E {K }) = 1.

get manipulation ids complete base K 00 , completes proof
lemma.

Let us give proof main theorem:
Weak drastic index. reductio ad absurdum. assume d,
manipulable

operator manipulable erosion. find integrity constraint
, profile E, two bases K K 0 K 0 6|= K s.t.:
d,
0
idw (K, d,
(E {K})) < idw (K, (E {K })).

Lemma 2 shows assume [K 0 ] = {10 } complete; comes:
d,
0
idw (K, d,
(E {K})) < idw (K, (E {1 })).

implies that:
idw (K, d,
(E {K}) = 0
0
idw (K, d,
(E {1 }) = 1.

96

(22)

fiThe Strategy-Proofness Landscape Merging

means model K model d,
(E {K}),
d,
least one model 1 K model (E {10 }). express
facts two statements:
|= K , 0 |= K , d( 0 , E {K}) < d(, E {K})
and:
1 |= K , |= , d(1 , E {10 }) d(, E {10 }).
Hence:
1 |= K , |= , d(1 , 10 ) + d(1 , E) d(, 10 ) + d(, E)

(23)

Let us define new base K 00 = {1 }. Since supposed operator
manipulable erosion since K 00 |= K, state strategy-proof
d,
00
idw K 00 : idw (K, d,
(E {K})) idw (K, (E {K })). implies that:
either idw (K, d,
(E {K})) = 1,
d,
00
idw (K, d,
(E {K})) = idw (K, (E {K })) = 0.
00
equation (22), infer idw (K, d,
(E {K })) = 0, |=
0
0
00
00
K , |= K , d( , E {K }) < d(, E {K }).

Since K 00 = {1 } choice 0 made independently 1 , 2 |=
(K) , |= K , d(2 , E {1 }) < d(, E {1 }), is:
2 |= K , |= K , d(2 , 1 ) + d(2 , E) < d(, 1 ) + d(, E).
particular, statement holds = 1 , 1 |= K . Hence:
d(2 , 1 ) + d(2 , E) < d(1 , 1 ) + d(1 , E).
Since d(1 , 1 ) = 0, obtain finally:
d(2 , 1 ) + d(2 , E) < d(1 , E).

(24)

hand, since 2 |= , (23), get:
d(1 , 10 ) + d(1 , E) d(2 , 10 ) + d(2 , E).
Summing (24) (25) side side, get:
d(2 , 1 ) + d(2 , E) + d(1 , 10 ) + d(1 , E) < d(1 , E) + d(2 , 10 ) + d(2 , E).
Simplifying d(1 , E) d(2 , E), obtain:
d(2 , 1 ) + d(1 , 10 ) < d(2 , 10 ).
97

(25)

fiEveraere, Konieczny & Marquis

contradicts triangular inequality. So, manipulation possible, possible
erosion complete base K 00 = {1 }.
Strong drastic index. Let us assume d,
manipulable ids . find

profile E, integrity constraint two bases K K 0 s.t.:
d,
0
ids (K, d,
(E {K})) < ids (K, (E {K })).

implies that:
ids (K, d,
(E {K}) = 0

(26)


0
ids (K, d,
(E {K }) = 1.

means least one model d,
(E {K}) model K,
0 }) model K . Let us consider model
(E

{K
every model d,

1
0
d,
(E {K }). write 1 |= K and:
|= , d(1 , E {K 0 }) d(, E {K 0 }).
have:
|= , d(1 , K 0 ) + d(1 , E) d(, K 0 ) + d(, E).
Let us define K 00 = {1 } show manipulation base. Let us assume
d,
00
00
00
find 00 |= d,
(E {K }) s.t. 6|= K. Since |= (E {1 }),
00 |=
d(, E {1 }) d(1 , E {1 }),
then:
d(, 1 ) + d(, E) d(1 , E)
(as d(1 , 1 ) = 0).
0
know 00 6|= K 00 |= , infer 00 6|= d,
(E {K }) (else
d,
00
0
|= K). Since 1 model (E {K }), have:
d(, E {K 0 }) > d(1 , E {K 0 }).
Equivalently:
d(, K 0 ) + d(, E) > d(1 , K 0 ) + d(1 , E).
Since d(1 , E) d(, 1 ) + d(, E), obtain:
d(, K 0 ) + d(, E) > d(1 , K 0 ) + d(, 1 ) + d( 00 , E).
Simplifying equation d(, E), get:
d(, K 0 ) > d(1 , K 0 ) + d(, 1 ).
2 model K 0 s.t. d(1 , K 0 ) = d(1 , 2 ), have:
d(, K 0 ) > d(1 , 2 ) + d(, 1 ),
98

fiThe Strategy-Proofness Landscape Merging

finally, since d(, 2 ) d(, K 0 ) definition min, get:
d(, 2 ) > d(1 , 2 ) + d(, 1 ).
contradicts triangular inequality.
d,
00
shown every model d,
(E t{K }) model K. Hence, ids (K, (E
{K 00 }) = 1. Since ids (K, d,
(E {K}) = 0 (26), have:
d,
00
ids (K, d,
(E {K})) < ids (K, (E {K })),

manipulation erosion complete base possible.

Corollary 12 profile E manipulable K idw (resp. ids ) given d,

manipulation possible using complete base K |= K, i.e., exists K |= K
d,
d,
s.t. idw (K, d,
(E {K })) > idw (K, (E {K})) (resp. ids (K, (E {K })) >
ids (K, d,
(E {K}))).
Proof:
(): consequence Theorem 11 Lemma 2, enable
state K manipulable = idw = ids given d,
E, one find
d,f
0
0
0
base K = { } |= K complete i(K, (E { })) > i(K, d,f
(E {K})).
(): K strategy-proof = idw = ids given d,
E, [K 0 ]

d,
d,
0
W, i(K, (E {K }) i(K, (E {K})). particular true K 0
reduced singleton.

Theorem 14 max , min1 , min2 , strategy-proof idw , ids ip .
V
Proof:
max (or equivalently min2 ) strategy-proof ip . Indeed, E
consistent, models
V merged base models K1 E, thus satisfaction
K1 maximal ip . E consistent,
V merged base valid. Assume
agent 1 reports K10 instead K1 . K10 {K2 , . . . , Kn } isVconsistent, model
resulting merged base model K1 . case K10 {K2 , . . . , Kn } inconsistent,
resulting merged base still valid. Theorem 1, max (or equivalently min2 )
also strategy-proof two drastic indexes.
V
V
E

consistent


above.

E
min1 also strategy-proof ip . case
W
consistent, result merging E models K1 models
merged base. So, order increase value ip index, possible
increase number models K1 result merging. Hence one needs
decrease number countermodels K1 merged base. shall
show
V
possible: assume agent 1 reports K10 instead K1 . K10 {KV
2 , . . . , Kn }
consistent, model resulting merged base model K1 (as E
consistent).
99

fiEveraere, Konieczny & Marquis

K10

V

{K2 , . . . , Kn } consistent, have:
ip (K1 , min1 (K1 {K2 , . . . , Kn })) =


ip (K1 , min1 (K10

#([K1

#([K1 ])
W
{K2 , . . . , Kn }])

W
#([K1 (K10 {K2 , . . . , Kn })])
W
.
{K2 , . . . , Kn })) =
#([K10 {K2 , . . . , Kn }])

numerator ip (K1 , min1 (K1 {K2 , . . . , Kn })) maximal, order increase
ip (K1 , min1 (K10 t{K2 , . . . ,W
Kn })), decrease denominator ip (K1 , min1 (K10
0
t{K2 , . . . , Kn })), #([K1 {K2 , . . . , Kn }]).
write following equality:
#([K10

_

_
{K2 , . . . , Kn }]) = #([K10 K1 ( {K2 , . . . , Kn })])+
_
_
#([K10 K1 ( {K2 , . . . , Kn })]) + #([ {K2 , . . . , Kn }]).

W
sum, #([ {K2 , . . . , Kn }]) cannot
changed. decrease two
W
0 K ( {K , . . . , K })]) minimal K 0 #([K 0
terms
sum:
#([K
1
2
n
1
1
1
W
KW1 ( {K2 , . . . , Kn })]) = 0. following, suppose #([K10 K1
( {K2 , . . . , Kn })]) = 0.
W
first term sum, #([K10 K1 ( {K2 , . . . , Kn })]), write:
_
#([K10 K1 ( {K2 , . . . , Kn })]) =
_
_
#([K1 ( {K2 , . . . , Kn })]) #([K1 K10 ( {K2 , . . . , Kn })])
obtain probabilistic index:
ip (K1 , min1 (K10 {K2 , . . . , Kn })) =
W
#([K1 ]) #([K1 K10 ( {K2 , . . . , Kn })])
W
W
W
.
#([K1 ( {K2 , . . . , Kn })]) #([K1 K10 ( {K2 , . . . , Kn })]) + #([ {K2 , . . . , Kn }])

remark k integer b, ak
bk b . subtract
W
0
integer #([K1 K1 ( {K2 , . . . , Kn })]) numerator denominator,
get following inequation:

W
#([K1 ]) #([K1 K10 ( {K2 , . . . , Kn })])
W
W
W

#([K1 ( {K2 , . . . , Kn })]) #([K1 K10 ( {K2 , . . . , Kn })]) + #([ {K2 , . . . , Kn }])
#([K1 ])
W
W
.
#([K1 ( {K2 , . . . , Kn })]) + #([ {K2 , . . . , Kn }])

So:
ip (K1 , min1 (K10 {K2 , . . . , Kn }))

#([K1 ])
W
W
#([K1 ( {K2 , . . . , Kn })]) + #([ {K2 , . . . , Kn }])
100

fiThe Strategy-Proofness Landscape Merging


ip (K1 , min1 (K10 {K2 , . . . , Kn })) ip (K1 , min1 (K1 {K2 , . . . , Kn })).
manipulation possible, min1 strategy-proof ip . Theorem 1, min1
also strategy-proof two drastic indexes.
Finally, strategy-proof three indexes (see Theorem 2).



Theorem 15 satisfies (IP) property every profile E every pair
bases K K 0 :
K (E {K}) |= (E {K 0 }),
K (E {K}) |= (E {K 0 }).
Proof:
Suppose merging operator = Bel( )) satisfy (IP)
property. profile E, agent i, OCF , interpretation W s.t.
| (E)() ()| > | (rep(E, {i}, )() ()|
rep(E, {i}, ) profile identical E except OCF replaced .
following note (E {K}) Bel( (E)): initial merged base agent
reports true base K Bel(i ), note (E {K 0 }) Bel( (rep(E, {i}, )):
merged base obtained replacing base K agent another K 0 Bel().
Focusing two-strata OCFs, inequation entails | (E)() ()| = 1
| (rep(E, {i}, )() ()| = 0. Since | (rep(E, {i}, )() ()| = 0, model
(E {K 0 }) K (*), countermodel (E {K 0 }) K
(**).
get | (E)() ()| = 1, also two cases:
either (E)() = 1 () = 0: model K countermodel
(E {K}). Since model K, (*), know model
(E {K 0 }). model K, ((E {K})) (E {K 0 }):
entails
K (E {K}) 6|= (E {K 0 }).
(E)() = 0 () = 1: countermodel K model (E
{K}). Since countermodel K, (**), know countermodel
(E {K 0 }). model K, (E {K}) (E {K 0 }):
entails
K (E {K}) 6|= (E {K 0 }).
Hence case
K (E {K}) |= (E {K 0 }),
101

fiEveraere, Konieczny & Marquis

K (E {K}) |= (E {K 0 }).
satisfied.
converse, suppose profile E, agent base K, another
base K 0 s.t.:
K (E {K}) 6|= (E {K 0 })

K (E {K}) 6|= (E {K 0 }).
first case, model K (E {K}) countermodel
(E {K 0 }) :
(E)() = 1, () = 0, (rep(E, {i}, )() = 0.

| (E)() ()| > | (rep(E, {i}, )() ()|.
second case, model K (E {K}) countermodel
(E {K 0 }):
(E)() = 0, () = 1, (rep(E, {i}, )() = 1.

| (E)() ()| > | (rep(E, {i}, )() ()|.
cases, satisfy (IP) property.
1
#([KK ]))+1 .

Theorem 16 Let iwip (K, K ) =
strategy-proof iwip .
Proof:



satisfies (WIP) property

definition K K (K K ) (K K ) write:
iwip (K, K ) =

1
#([(K K ) (K K )]) + 1


iwip (K, K ) =

1
.
#([K K ]) + #([K K ]) + 1

Suppose merging operator = Bel( )) satisfy (WIP) property.
profile E, agent i, OCF s.t.
W | (E)() ()| > W | (rep(E, {i}, )() ()|

()

following note (E {K}) Bel( (E)), initial merged base
agent reports true base K Bel(i ), note (E {K 0 }) Bel( (rep(E, {i},
)), i.e., merged base obtained replacing base K agent another
K 0 Bel().
two-strata case, | (E)() ()| equal 0 1. fact, | (E)() ()| = 1
if:
102

fiThe Strategy-Proofness Landscape Merging

either (E)() = 1 () = 0: equivalent |= K (E {K}).
(E)() = 0 () = 1: equivalent |= K (E {K}).
deduce following equation:
W | (E)() ()| = #([K (E {K})]) + #([K (E {K})]).
Similarly, get:
W | (rep(E, {i}, )() ()| = #([K (E {K 0 })]) + #([K (E {K 0 })])
inequation (*) equivalent to:
#([K (E {K})]) + #([K (E {K})]) > #([K (E {K 0 })]) + #[K (E {K 0 })])

equivalent
1
<
#([K (E {K})]) + #([K (E {K})]) + 1
1
#([K (E {K 0 })]) + #([K (E {K 0 })]) + 1
equivalent
iwip (K, (E {K})) < iwip (K, (E {K 0 }))
equivalent fact strategy-proof iwip .


References
Arrow, K. J. (1963). Social choice individual values (second edition). Wiley, New York.
Arrow, K., Sen, A. K., & Suzumura, K. (Eds.). (2002). Handbook Social Choice
Welfare, Vol. 1. North-Holland.
Baral, C., Kraus, S., & Minker, J. (1991). Combining multiple knowledge bases. IEEE
Transactions Knowledge Data Engineering, 3 (2), 208220.
Baral, C., Kraus, S., Minker, J., & Subrahmanian, V. S. (1992). Combining knowledge
bases consisting first-order theories. Computational Intelligence, 8 (1), 4571.
Barbera, S., Dutta, B., & Sen, A. (2001). Strategy-proof social choice correspondences.
Journal Economic Theory, 101 (2), 374394.
Benferhat, S., Dubois, D., Kaci, S., & Prade, H. (2002). Possibilistic merging distancebased fusion propositional information. Annals Mathematics Artificial Intelligence, 34 (13), 217252.
Borda, J. (1781). Memoire sur les elections au srutin. Histoire de lAcademie Royale des
Sciences.
103

fiEveraere, Konieczny & Marquis

Brams, S. J., & Fishburn, P. C. (1983). Approval voting. Springer Verlag.
Chin, S., & Zhou, L. (2002). Multi-valued strategy-proof social choice rules. Social Choice
Welfare, 19 (3), 569580.
Chopra, S., Ghose, A., & Meyer, T. (2006). Social choice theory, belief merging strategyproofness. Information Fusion, 7 (1), 6179.
Condorcet, M. (1785). Essai sur lapplication de lanalyse la probabilite des decisions
rendues la pluralite des voix. Paris.
Conitzer, V., Lang, J., & Sandholm, T. (2003). many candidates needed make
elections hard manipulate?. Proceedings Ninth Conference Theoretical
Aspects Rationality Knowledge (TARK03), pp. 201214.
Conitzer, V., & Sandholm, T. (2002a). Complexity manipulating elections candidates. Proceedings Eighteenth National Conference Artificial Intelligence
(AAAI02), pp. 314319.
Conitzer, V., & Sandholm, T. (2002b). Vote elicitation: complexity strategyproofness. Proceedings Eighteenth National Conference Artificial Intelligence (AAAI02), pp. 392397.
Conitzer, V., & Sandholm, T. (2003). Universal voting protocol tweaks make manipulation hard. Proceedings Eighteenth International Joint Conference
Artificial Intelligence (IJCAI03), pp. 781788.
Dalal, M. (1988). Investigations theory knowledge base revision: preliminary report.
Proceedings Seventh American National Conference Artificial Intelligence
(AAAI88), pp. 475479.
Duggan, J., & Schwartz, T. (2000). Strategic manipulability without resoluteness shared
beliefs: Gibbard-satterthwaite generalized. Social Choice Welfare, 17, 8593.
Everaere, P., Konieczny, S., & Marquis, P. (2005). Quota gmin merging operators.
Proceedings Nineteenth International Joint Conference Artificial Intelligence
(IJCAI05), pp. 424429.
Gibbard, A. (1973). Manipulation voting schemes. Econometrica, 41, 587602.
Kelly, J. S. (1988). Social Choice Theory : Introduction. Springer-Verlag.
Konieczny, S. (2000). difference merging knowledge bases combining them. Proceedings Seventh International Conference Principles
Knowledge Representation Reasoning (KR00), pp. 135144.
Konieczny, S., Lang, J., & Marquis, P. (2004). DA2 merging operators. Artificial Intelligence,
157 (1-2), 4979.
Konieczny, S., Lang, J., & Marquis, P. (2005). Reasoning inconsistency: forgotten connective. Proceedings Nineteenth International Joint Conference
Artificial Intelligence (IJCAI05), pp. 484489.
Konieczny, S., & Pino Perez, R. (1998). logic merging. Proceedings Sixth
International Conference Principles Knowledge Representation Reasoning
(KR98), pp. 488498.
104

fiThe Strategy-Proofness Landscape Merging

Konieczny, S., & Pino Perez, R. (1999). Merging integrity constraints. Proceedings
Fifth European Conference Symbolic Quantitative Approaches Reasoning
Uncertainty (ECSQARU99), LNAI 1638, pp. 233244.
Konieczny, S., & Pino Perez, R. (2002). Merging information constraints: logical
framework. Journal Logic Computation, 12 (5), 773808.
Liberatore, P., & Schaerf, M. (1998). Arbitration (or merge knowledge bases). IEEE
Transactions Knowledge Data Engineering, 10 (1), 7690.
Lin, J., & Mendelzon, A. O. (1999). Knowledge base merging majority. Dynamic
Worlds: Frame Problem Knowledge Management. Kluwer.
Maskin, E., & Sjostrom, T. (2002). Handbook Social Choice Welfare, Vol. 1, chap.
Implementation Theory, pp. 237288. North-Holland.
Meyer, T., Ghose, A., & Chopra, S. (2001). Social choice, merging elections. Proceedings Sixth European Conference Symbolic Quantitative Approaches
Reasoning Uncertainty (ECSQARU01), pp. 466477.
Moulin, H. (1988). Axioms cooperative decision making, chap. 9. Econometric society
monographs. Cambridge University Press.
Rescher, N., & Manor, R. (1970). inference inconsistent premises. Theory
Decision, 1, 179219.
Revesz, P. Z. (1993). semantics theory change: arbitration old
new information. Proceedings Twelfth ACM SIGACT-SIGMOD-SIGART
Symposium Principles Databases, pp. 7192.
Revesz, P. Z. (1997). semantics arbitration. International Journal Algebra
Computation, 7 (2), 133160.
Satterthwaite, M. (1975). Strategy-proofness Arrows conditions. Journal Economic
Theory, 10, 187217.
Shoham, Y., & Tennenholtz, M. (2005). Non-cooperative computation: Boolean functions
correctness exclusivity. Theoretical Computer Science, 343 (1-2), 97113.
Spohn, W. (1987). Ordinal conditional functions: dynamic theory epistemic states.
Harper, W. L., & Skyrms, B. (Eds.), Causation Decision, Belief Change,
Statistics, Vol. 2, pp. 105134.
Tversky, A. (2003). Preference, Belief, Similarity. MIT Press.

105

fi
