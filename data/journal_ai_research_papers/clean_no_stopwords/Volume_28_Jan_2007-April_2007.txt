Journal Artificial Intelligence Research 28 (2007) 517-557Submitted 8/06; published 4/07Consistency Random Constraint Satisfaction ModelsYong Gaoyong.gao@ubc.caIrving K. Barber School Arts SciencesUniversity British Columbia Okanagan, Kelowna, Canada V1V 1V7Joseph Culbersonjoe@cs.ualberta.caDepartment Computing Science, University AlbertaEdmonton, Alberta, Canada T6G 2E8Abstractpaper, study possibility designing non-trivial random CSP modelsexploiting intrinsic connection structures typical-case hardness. showconstraint consistency, notion developed improve efficiencyCSP algorithms, fact key design random CSP modelsinteresting phase transition behavior guaranteed exponential resolution complexitywithout putting much restriction parameter constraint tightness domain sizeproblem. propose flexible framework constructing problem instancesinteresting behavior develop variety concrete methods construct specificrandom CSP models enforce different levels constraint consistency.series experimental studies interesting observations carried illustrate effectiveness introducing structural elements random instances, verifyrobustness proposal, investigate features specific models basedframework highly related behavior backtracking search algorithms.1. Introductiontale random models constraint satisfaction problems (CSP) gives us excellentexample dramatic impact structures typical-case hardness randomlygenerated problem instances (Achlioptas et al., 1997; Gent et al., 2001; MacIntyre et al.,1998; Molloy, 2002; Prosser, 1996; Smith, 2001). also shows study phasetransitions random models NP-complete problems indeed viable approachunderstanding interplay structures efficiency search algorithms.Unlike random Boolean satisfiability problem (SAT) structures seemexist randomly-generated instances, algorithmically-exploitable structures existgeneral random constraint satisfaction problem. chief reasonrandom constraint satisfaction instances uncontrolled existence multiplenogoods within constraint generates small scale structures make instanceunsatisfiable. small scale may mean variables involved,variables involved highly constrained local way. first examplestructures existence flawed variables flawed constraints random instancesgenerated four classical random CSP models parameter regions(Achlioptas et al., 1997), assuming domain size fixed. appearance flawedvariables constraints makes models trivially unsatisfiable excludes phasec2007AI Access Foundation. rights reserved.fiGao & Culbersontransition behavior. yet another example, existence embedded easy subproblems(Gao & Culberson, 2003), also called flowers (Molloy & Salavatipour, 2003), anotherpart parameter space models makes randomly-generated instances polynomiallysovable constraint consistency algorithms.Several new models proposed overcome trivial unsatisfiability. Gentet al. (2001) proposed flawless random binary CSP based notion flawlessconflict matrix. Instances flawless random CSP model guaranteed arcconsistent, thus suffer asymptotically problem flawed variables.Achlioptas et al. (1997) proposed nogoods-based CSP model showed modelnon-trivial asymptotic behaviors. Random CSP models (slowly) increasingdomain size also shown free problem flawed variablesinteresting threshold behavior (Xu & Li, 2000; Smith, 2001; Frieze & Molloy, 2003).proposed models guaranteed interesting phase transitionbehavior (some also guaranteed generate hard instances phase transitions), fundamental relation structures typical-case hardnessrandomly-generated CSP instances seriously addressed. consequence,superficial conditions restrictions parameter constraint tightnessmodels frequently give (false) impression constraint tightness and/ordomain size determines behavior random CSP instances. classic binaryrandom CSP, constraint tightness less domain size orderphase transition. flawless random CSP true solubility phase transitionhigh constraint tightness, show later, still suffers embedded easyunsatisfiable subproblems constraint tightness greater domain size.CSP models increasing domain size, still obvious restriction possiblevalues constraint tightness. nogood-based CSP model, impossiblehigh constraint tightness without making constraint (hyper)graph dense.paper, study possibility designing non-trivial random CSP modelsexploiting intrinsic connection structures typical-case hardness.purpose, show consistency, notion developed improveefficiency CSP algorithms, fact key design random CSP modelsinteresting phase transition behaviors guaranteed exponential resolution complexitywithout putting much restriction parameter constraint tightness domainsize.Section 4 report series experimental studies. Algorithmic studies randominstances sometimes criticized model algorithms (Johnson, 2002). believe better study interaction modelsalgorithms. example, Section 4.2 observe double peak phenomenonbest guess suggests related (lack of) consistency enforcement algorithmsuse interacting degree consistency enforced instances variousmodels. propose flexible framework constructing problem instances interesting behavior develop variety concrete methods construct specific randomCSP models enforce different levels constraint consistency. hope frameworkuseful helping researchers construct pseudo-random instances exhibiting variouskinds structure, avoiding trivialities sometimes tainted claimed results518fiConsistency Random CSPspast, may cause algorithm design become focused particularstructure detriment general application.2. Random Models CSPsThroughout paper, consider binary CSPs defined domain |D| = d.binary CSP C consists set variables x = {x1 , , xn } set binary constraints{C1 , , Cm }. constraint Ci specified constraint scope, pair variablesx, constraint relation RCi defines set incompatible value-tuplesscope variables. incompatible value-tuple also called restriction, nogood.Associated binary CSP constraint graph whose vertices correspond setvariables whose edges correspond set constraint scopes. Throughoutdiscussion, assume domain size fixed constant. rest paper,using following notation:1. n, number variables;2. m, number constraints;3. d, domain size;4. t, constraint tightness, i.e., size restriction set.Given two variables, constraint relation specified 0-1 matrix, calledconflict matrix, entry 0 (i, j) indicates tuple (i, j)incompatible. Another way describe constraint relation use compatibilitygraph, bipartite graph domain variable independent part,edge signifies corresponding value-tuple compatible.define generic model generating random binary CSPs. Recallrelation set ordered pairs.d,tDefinition 2.1. (Bn,m[L], Restricted Random Binary CSP) Let d, t, n, integersspecified above, variables share common domain = {1, . . . , d}, let L =d,t{L1 , L2 , . . . | Li D} set relations. Bn,m[L] random CSP model1. constraint graph standard random graph G(n, m) edgesgraph selected uniformly random possible n2 edges;2. edge G(n, m), constraint relation corresponding scope variablesspecified follows:(a) Choose random relation L L.(b) Choose value-tuples \ L uniformly random nogood set.definition, typically want add condition set L satisfies\(a, a)/Li , D.i1519fiGao & Culbersoncondition met, instances generated CSP model alwaystrivially satisfiable (and vacuously exponential resolution complexity).d,tmild, sufficient, condition make sure Bn,m[L] linear solubility threshold.particular, existing models models discussed presentpaper satisfy condition. Appendix A.3, provide result showingd,tcondition, constant c Bn,m[L] m/n > c asymptoticallyunsatisfiable probability one.placing restrictions L subsume many previously existingmodels well new models define shortly.d,td,tDefinition 2.2. (Model B: Random Binary CSP Bn,m) Bn,m[L] L = {},d,twrite Bn,m, known literature Model B.instance CSP said k-consistent (k 1) variables,consistent (k 1)-tuple assignment (k 1) variables extendedconsistent k-tuple assignment kth variable. CSP instance called stronglyk-consistent j-consistent j k. special intereststrong-k-consistencies k = 1, 2, 3, also known node-consistency, arc-consistency,path-consistency (Mackworth, 1977).d,trestrictions construction constraint.Note Bn,md,tshown Bn,m asymptotically trivial unsatisfiable d, phasetransition satisfiability probability < (Achlioptas et al., 1997; Gent et al., 2001).Basically, trivial cases arise asymptotically high probabilityvariable values forbidden due constraints containingarc-consistent. motivates introduction flawless conflict matrix makesure random model arc-consistent (Gent et al., 2001).d,td,tDefinition 2.3. (Flawless Random Binary CSP Bn,m[M]) Bn,m[L] L Ld,tbijection, L : D, write Bn,m[M]. flawless random binary CSPdefined Gent et al. (2001).notation reference matchings. use constructiongeneralized flawless random binary CSPs present Section 3.2, restrictunderlying graphs matchings, reduces flawless model.specifying bijections create set tuples one D.considered choosing incompatible value-tuples, resultingmodel guaranteed arc-consistent consequently flawed variables.d,tHowever, even though flawless random binary CSP Bn,m[M] sufferd,tproblem trivial unsatisfiability, shown Bn,m[M] may asymptoticallyembedded easy subproblems 1.Theorem 2.1. 1, constant c > 0n > c , highd,tprobability Bn,m[M] asymptotically unsatisfiable solved polynomial time.Proof. outline proof provide detailed proof Appendix A.1. idead,tshow sufficiently highn , Bn,m [M] contains structures (sub-instances) (1)cause unsatisfiability whole instance (2) detected polynomial time.520fiConsistency Random CSPsOne structure so-called flower consisting collection forbidden constraintcycles explain below.binary constraint two variables x1 x2 said contain (, )-forcerassignment x1 = , compatible assignment x2 x2 = . ConsiderCSP instance. Let {x0 , x1 , , xr1 } subset r variables domain value.Suppose cycle constraintsC1 (x0 , x1 ), C2 (x1 , x2 ), . . . , Cr1 (xr2 , xr1 ), Cr (xr1 , x0 )C1 (x0 , x1 ) contains (, 1 )-forcer, Ci (xi1 , xi ) contains (i1 , )-forcer,Cr (xr1 , x0 ) contains (r1 , )-forcer 6= . Then, assignment x0 =cannot used satisfying assignment. call cycle constraints forbiddencycle (for variable x0 domain value ). Now, (the domain size)forbidden cycles variable x0 , one domain value, CSP instancesatisfiable since none domain values satisfying assignment. callvariable together forbidden cycles flower.Using second-moment method, shown constant cd,tn > c , probability Bn,m [M] contains flower asymptotically one.d,tSo, high probability, Bn,m[M] unsatisfiablen > c . Furthermore, binaryCSP instance contains flower, path-consistency algorithm (e.g., Mackworth,1977) produce new CSP instance variable flower emptydomain. Therefore, CSP instance embedded flower sub-instance solvedpolynomial time.d,tnoted Bn,m[M] non-trivial phase transition since1satisfiable high probabilityn < 2 . Theorem 2.1 exclude possibilityd,t[M] able generate hard instancesBn,mn upper bound c ,particular case large domain size. investigation required fullyd,tunderstand complexity Bn,m[M] regard.3. Consistency, Resolution Complexity, Better Random CSP ModelsPropositional resolution complexity deals minimum length resolution proofs(unsatisfiable) CNF formula. many backtracking-style complete algorithmssimulated resolution proof, resolution complexity provides immediate lowerbound running time algorithms. Since work Chvatal Szemeredi(1988), many studies resolution complexity randomly-generatedCNF formulas (Beame et al., 1998; Achlioptas et al., 2001).Mitchell (2002b) developed framework notion resolution complexitygeneralized CSPs resolution complexity randomly-generated random CSPsstudied. framework, resolution complexity CSP instance definedresolution complexity natural CNF encoding give below. Giveninstance CSP set variables {x1 , , xn } domain = {1, 2, , d},CNF encoding constructed follows:1. variable xi , Boolean variables xi : 1, xi : 2, . . . , xi :indicates whether xi takes corresponding domain value.521fiGao & Culbersonclause xi : 1 xi : 2 . . . xi : Boolean variables making sure xitakes least one domain values;2. restriction (1 , , k ) Dk constraint C(xi1 , , xik ),clause xi1 : 1 xik : k respect restriction.CNF encoding equivalent original CSP problem sense CSPinstance satisfiable CNF encoding satisfiable. satisfying assignment CSP variables translates immediately satisfying assignment CNFencoding. hand, satisfying assignment CNF encoding alsotranslated satisfying assignment original CSP instance. CNF assignment, one boolean variables xi : 1, xi : 2, . . . xi : assigned TRUE,pick one assign corresponding domain value CSPvariable xi . possible add another set 2-clauses constraint variable xiform {xi : j xi : h | 1 j < h d} ensure satisfying assignmentCNF encoding assigns unique domain value CSP variable. However,general change complexity results, make analysis complicated.Mitchell (2002b) well Molloy Salavatipour (2003) showed random CSPsexponential resolution complexity constraint tightness lessd,tcertain value. random binary CSP Bn,m, requirement (1) < 1; (2)<sufficientlysmall.1,recent theoretical results (Gao & Culbernson, 2003; Molloy & Salavatipour, 2003) indicate still possible classicalmodels asymptotic polynomial complexity due existence embedded easysubproblems.following, show necessary put restrictions constrainttightness order guaranteed exponential resolution complexity. Based similararguments literature (Mitchell, 2002b; Molloy & Salavatipour, 2003; Beame,d,tCulberson, Mitchell, & Moore, 2005), shown Bn,m[L], constraintrelation constraint chosen way resulting instances alwaysd,tstrongly 3-consistent, Bn,m[L] exponential resolution complexity matterlarge constraint tightness is.d,tTheorem 3.1. Let L Bn,m[L] strongly 3-consistent. constantd,tn = c > 0, resolution complexity Bn,m [L] almost surely exponential.Proof. See Appendix A.2.Using tool developed Molloy Salavatipour (2003), requirement CSPinstances strongly 3-consistent exponential resolution complexityrelaxed. Recall constraint x1 , x2 contains (, )-forcer x1 =consistent assignment allowed constraint x2 = .Definition 3.1. call CSP instance weakly 4-consistent1. arc-consistent,2. contains forcer,522fiConsistency Random CSPs3. 4 distinct variables x1 , x2 , x3 , x4 constraints C1 (x1 , x2 ), C2 (x2 , x3 ), C3 (x3 , x4 )1 , 4 exist 2 , 3 assignment x1 = 1 , x2 =2 , x3 = 3 , x4 = 4 consistent C1 , C2 C3 .Note weak 4-consistency weaker strong 3-consistency sincerequire instance 3-consistent.d,tTheorem 3.2. Let L Bn,m[L] weakly 4-consistent. constantd,tn = c > 0, resolution complexity Bn,m [L] almost surely exponential.Proof. See Appendix A.2.proofs theorems based structural properties underlyingconstraint random graph CSP models relation size resolutionproof maximum size clause resolution proof. briefly discusskey ideas proof Theorem 3.1 illustrate role constraint consistency.First, order CSP instance exponential size proof, size minimumunsatisfiable sub-instance (MUS) must constant. Otherwise, enumerationpartial assignments sub-instances size less MUS gives usd,t[L], minimum vertex degree MUSproof polynomial size. case Bn,mmust larger 2 since 3-consistent. Due local sparseness randomgraph forced assumptionn = c, minimum size MUS linearproblem size n.Second, Ben-Sasson Wigderson (2001) shown establish exponentiallower bound resolution complexity, sufficient show resolution proofmust contain clause whose size linear problem size. Let minimum sizeMUS. shown resolution proof must contain clause Cminimum size sub-instance J implies C least 2s . Since instance 3consistent J minimal, clause C must contain one literal relatedvariables J whose vertex degree less 3. random graph argument showsnumber variables sub-instance linear n. summary, due constraintconsistency local sparseness random constraint graph, resolution proofmust contain clause whose derivation involves linear number variables.question remaining answered whether natural randomCSP models guaranteed strongly 3-consistent weakly 4-consistent. fact,CSP-encoding random graph k-coloring strongly k-consistent. restsection, discuss generate random CSPs high tightness strongly3-consistent weakly 4-consistent.3.1 Generalized Flawless Random Binary CSPintroduce generalized flawless model. call generalized flawless modelsince requires even stronger conditions L flawless model Gent et al. (2001).assume common domain = {1, . . . , d}, > 2.Definition 3.2. say L SC-inducing1. L L exist , (, ) L (, ) L523fiGao & Culberson2. L1 , L2 L , exists (, ) L1 (, ) L2 .first condition Definition 3.2 guarantees arc consistency constraint.second condition ensures 3-consistency. Given > 2, two conditions strong3-consistency.Definition 3.3. say L WC-inducing1. L L exist 1 , 2 , 1 , 2 (, 1 ), (, 2 ) L(1 , ), (2 , ) L2. L1 , L2 , L3 L , exist , (, ) L1 , (, ) L2(, ) L3 .first condition Definition 3.3 prevent forcers well enforce arc consistency, first two conditions required definition weak 4-consistency.Definition 3.4. (Generalized Flawless Random Binary CSPs)d,td,tmodel Bn,m[L] L SC-inducing write Bn,m[SC]. L WC-inducingd,twrite Bn,m [WC]. either case, say generate generalized flawless randombinary CSP.d,t[SC] strongly 3-consistent. CSP constructedLemma 3.3. CSP constructed Bn,md,tBn,m [WC] weakly 4-consistent.note flawless method could generate every arc consistentCSP (Gent et al., 2001) every SC (WC) CSP generated system.example, constraint C variables x1 x2 respect thirdvariable x3 strong 3-consistency requires consistent assignment x3pairs values compatible C. method ensures consistency everypair values x1 , x2 independently whether constraint them.see reasonable way produce relaxed version given constraintsgenerated independently G(n, m).3.2 Constructing Consistent-Inducing Sets Lprovide methods generate variety sets relations L SC-inducingWC-inducing. Although CSP models require variables common domain,start general construction varying domain sizes. enableus significantly increase domain tightness larger domains. side benefit,indicates models might adapted varying domains. However, build modelvarying domain sizes would require least distinct sets L every orderedpair distinct domains. would also complicate selection step, 2(a) Definition 2.1well analysis. leave development models future research.start constructing set bipartite graphs G, call core graphs.pair domains D` Dr sizes d` = |D` |, dr = |Dr |, onecore graphs G G. graph G G form G = (V` Vr , E)V` = {v1 , . . . , vd` } Vr = {w1 , . . . , wdr } sets vertices E V` Vr .524fiConsistency Random CSPsgraph G create set size kG triples form (G) = {(G, `i , ri ) | 1 kG },`i : V` D` ri : Vr Dr bijections labeling vertices.define = (G) = GG (G). , = (G, ` , r ), let L(T )set pairs {(` (v), r (w)) | (v, w) E(G)}. define L = L(T ) = {L(T ) | },set relations induced triples.Given bipartite graph G = (V` Vr , E), define minimum degree vertexvertex subset Vi {`, r}.say G degree bound graph ` > d2r r > d2` .Lemma 3.4. G degree bound T1 , T2 sharing domain = Dr1 =D`2 , D`1 , Dr2 , exists (, ) L1 = L(T1 ), (, )L2 = L(T2 ).Proof. Let v = ` 11 () vertex G1 labeled . Since deg(v) `1 , numberpairs L1 first element must greater d2 . Similarly,pairs L2 second element must also cover 1/2 D. Thus,must exist (, ) L1 , (, ) L2 .Corollary 3.5. G degree bound common domain L(T ) SC-inducing.hard see without restricting bijections Lemma 3.4 provides bestpossible result.Lemma 3.6. degree bound arbitrary bijections ` r allowed, L(T )may SC-inducing.Proof. Consider two relations L1 L2 common domain graphs G1 , G2`1 d2 r2 d2 . Let D1 D4 note neighbors verticeslabeled values cover 1/2 D. Since choose r1 `2arbitrarily, ensure value x2 consistent x1 = , x3 = .Consider graph domain = 9 shown Figure 1. allow arbitrarybijections ` , r L SC-inducing, WC-inducing, reader mayreadily verify. degree vertices graph = 4, less allowedLemma 3.4. remains WC-inducing structure graph distributesedges uniform way.generalize observation, assume common domain consider three constraints induced L1 , L2 , L3 built core graph set G. minimumdegree value left L1 values right L1 ,allow arbitrary bijections, may match subset size left L2 .Similarly, value right L3 match arbitrary set values rightL2 . ensure G generates L WC-inducing, needarbitrary pair -sets induces least one edge G G. pair subsets failsinduce edge core graph, corresponding constraint set weakly4-consistent.Letting NG (v) neighbors vertex v graph G, argument generalizesformal statement525fiGao & CulbersonLemma 3.7. common domain D, G G minimum left right degree` = r = , G generates WC-inducingL using arbitrary bijections ` , r iff G G,{`, r} Vi , |S| = , | vS NG (v)| > .graph -regular every vertex degree . graph connectedpath every pair vertices. Notice degree bound G G necessarilyconnected. following special case G generate WC-inducingSC-inducing L.Corollary 3.8. Suppose common domain = 2 Gset -regular connected bipartite graphs. Let set triples generated randompairs bijections graphs G. L(T ) WC-inducing.Proof. Lemma 3.7, must show arbitrary subset V` |S| = ,neighbors contain vertices. Suppose not. Note must 2edges vertices S, distinct endpoints (there cannot fewer)edges. follows edges neighbors,G connected.Lemma 3.7 used show 2 d. also follows easily G mustconnected. bounds met = 4, = 2 using eight cycle illustratedFigure 1. larger mostly leave problem optimizing research projectcombinatorial design, although provide insight next section.WC-inducing graphs shown Figure 1.3.3 Recursive ConstructionLemmas 3.4 3.6 introduce additional restrictions bijections,2best tightness achieve maintaining strong 3-consistency < d2 .require weak 4-consistency, Lemma 3.7 may allow significant improvement, althoughunclear exactly much general. show increase tightnessreducing number edges graphs using recursive construction larger domainssimultaneously restricts set bijections.Given domain partition set blocks = {1 , . . . , k } subject k 3|j | 3, j. latter restrictions place SC-inducing graphspairs size two complete bipartite graphs. blocks j may vary size.variable xi must exactly one partition domain usedconstruction constraints xi . problems common domain simplestone partition common domain variables, constructionassume.Let V = {v1 , . . . , vd }. bijection : V said respect partitionbijection : partition j, 1 j k j(vi ) (j ). Note meet condition, must satisfy condition|j | = | (j )| j. Thus, partitions varying sizes blocks restrictset respectful bijections.construct -bound graph G follows. Let V` = {v10 , . . . , vk0 } Vr ={w10 , . . . , wk0 } sets vertices corresponding blocks partition. Let G =(V` Vr , E ) SC-inducing graph.526fiConsistency Random CSPsd=4d=5d=6d=9Figure 1: Graphs WC-inducing SC-inducing domains size 4,5,69. Notice = 5 minimal graph regular. boxes graph= 9 indicate recursive construction described Section 3.3. See alsoFigure 2.assume general construction two sets vertices V` = {v1 , . . . , vd }Vr = {w1 , . . . , wd }. edge (v, w) E construct degree bound graph Gvw =(V` [v ] Vr [w ], Evw ), V` [v ] = {vi : v } Vr [w ] = {wi : w }. Recalldegree bound graphs work even domains differing sizes. construct-bound graph G = (V` Vr , E) letting E = (v,w)E Evw .Lemma 3.9. G consists -bound graphs bijections ` , r respect , LSC-inducing.Proof. Consider two relations L1 , L2 . Since block graphs G SC-inducing, followspath block left graph block rightblock permutations implied respectful bijections. focusing edgesbijections restricted blocks path, since induce degree boundgraphs, proof completed argument similar proof Lemma 3.4.Figure 1 shows graph generated method = 9. (For = 3,one minimal degree bound graph isomorphism.) Figure 2 shows construction527fiGao & Culberson162175 B C934487 CB 5754B6546172A 28391C 89X389623L1BCZL2Figure 2: illustration strongly 3-consistent pair constructed using 3 3 recursiveconstruction domain size 9. simplicity, use identity bijectionsfar left right. center, dashed lines represent bijectionshared domain induced r1 `2 . r1 `2 respect blocks,rearrange values block vertex levels. highlight value 1left vertices connected left side L2 ,2 vertices two blocks. sufficient connect valueright.two constraints using two copies graph. bijections respect block structure,constraint SC-inducing.large domains, notice may many blocks . Since GSC-inducing, recursively use construction build G . call constructionrecursive -bound construction. example, similar graph = 9 Figure 1,see domains size = 3i recursive construction lets us use graphsdegree 2i . Thus, tightness high d2 d1+log3 2 SC-inducing graphs.528fiConsistency Random CSPsnote also possible recursively partition large blocks, resultingpossibly non-uniform depth recursive constructions, provided permutations blockrespecting appropriate sense. leave exercise notation gets messy,applications appear limited.also claim without proof blocks size, makeG WC-inducing replace degree bound subgraphs WC-inducing graphs,provided use -respecting bijections, G WC-inducing. call graphs weakly-bound. before, recursively construct G get recursive weakly -boundgraphs. = 4i using recursion based = 4 case Figure 1, weak4-consistency core graphs degree 2i ; is, tightness casehigh d2 d3/2 .Although increased tightness using recursive constructions,side greatly reduce set allowed bijections. example, respectblock structure graph = 9 shown Figure 2, (3!)4 = 1296distinct bijections either side, compared 9! = 362880 unrestricted bijections. alsonote recursive constructions limited practical application since expensiveexpress tight constraints explicit way large domains.3.4 Limits Tightness Complexity Tradeoffsget even tighter constraints exponential resolution complexity? discussionfar indicates near limits using consistency inducing constructions,need something else. following construction illustrates possible maintainexponential complexity even higher tightness, trivial sensereally exponential linear sized embedded subproblem.Let us embed 3-coloring domain size > 3. wish construct CSP versionk-coloring graphs, start coloring domain K = {1, . . . , k}. create onegraph G = (V` Vr , E) G, edge set E = V` Vr \ {(vi , wi ) | 1 k}. restrictbijections ` (vi ) = i, r (wi ) = i, 1 k, refer identity bijectionsidentities, ` , r short. one relation L = {L(G, ` , r )}. completek-coloring implementation, set = k, maximum possible value t. embed3-coloring domain size d, let G constructed 3-coloring constructionsub-domain {1, 2, 3} pad G independent vertices {vi , wi | 4 d}.construct one triple (G, ` , r ) one relation L. set tightnessmaximum possible value, = d2 6.conjecture maximal possible tightness exponential complexity,d,tlittle relevance larger d. L, instance Bn,m[L]reasonable algorithm simply reduce 3-coloring, thus exhibit exponentialcomplexity 3-coloring threshold.see maximizing tightness certainly consideration, probablyimportant. feel important consider kinds structureone embed model, avoiding generating trivial instances. model expandsframework wherein done previous models.529fiGao & Culberson3.5 Implementation Issuesexperiments conducted Gao Culberson (2004) many paperuse domain size = 4 8 cycle WC-inducing graph shown Figure 1.point experiments conducted Gao Culberson (2004) fixedbijection ` = ` randomly assigned right hand set r . Althoughadequate satisfy WC-inducing conditions, include possible L, sinceexample L generated way (1, ) (2, )L. construction constraints variables ordered consistentway, example smaller index always left side constraint,may introduce overall asymmetry CSP.following, report new series experiments used randomlypaired bijection approach.best degree bound graphs, sense maximizing t,vertices minimum possible degree, -regular graphs. purposes,requirement graphs uniformly selected possiblegraphs, hard find various techniques get variety graphs.graphs conforming Corollary 3.8 example, one first generate cycle alternatingvertices V` , Vr choose set maximum matchings remainingunused pairs reach required degree. found using varietytechniques, example finding 1-factorization regular bipartite graph (Bondy &Murty, 1976, Chapter 5). one desire uniform sampling reason,significant literature generating random regular graphs various types,might serve starting point (Wormald, 1999).4. Experimentssection, discuss series experiments conducted study impactstructural elements introduced generalized flawless model typical casehardness problem instances practical size. Section 4.1, discuss experimentBoolean 3-ary CSP model obtained widely-used random distribution CNFformula. Section 4.2, report detailed experimental results comparison threedifferent random CSP models.4.1 Randomly-generated 3-ary Boolean CSPsobservation set experiments Boolean CSPs different constrainttightness partly motivated study interplay performance backtracking algorithms structural information seemingly structureless randomlygenerated instances. include results since provide nice illustrationeffect increase constraint tightness (hence increase likelihoodexistence forcer constraint) typical case hardness random CSP instances.obtain instance distribution ternary boolean CSP, start random3-CNF formula clause generated selecting three variables uniformlyrandom without replacement. clause CNF formula equivalent constraintconstraint tightness = 1 set variables. E.g., x z corresponds530fiConsistency Random CSPsrestriction {(0, 0, 1)}. therefore obtain random instances Boolean-valuedCSPs larger constraint tightness adding clauses defined setvariables.Let F(n, m) random 3-CNF formula n variables clauses selecteduniformly random without replacement. construct new random 3-CNF formulaF(n, m, a) follows:1. F(n, m, a) contains clauses F(n, m);2. clause C F(n, m), generate random clause set variablesC, add new clause F(n, m, a) probability a.fact, F(n, m, a) random Boolean CSP model average constraint tightness1 + discussed Gao Culberson (2003). > 0, easy seeF(n, m, a) always strongly 2-consistent, 3-consistent asymptoticallyprobability 1.Figure 3: Thresholds solution probability model F(n, m, a) n = 250.z-axis solution probability. axis range 1.0 ... 2.0parameter 1 + axis range 1.0 ... 6.0 clause densitym/n.Figure 4 shows median number branches used SAT solver ZChaff(Zhang et al., 2001) 100 instances F(n, m, a) n = 250. Figure 3 showssolution probability model. expected, increase tightness resultsshift location hardness peak toward smaller m/n. significantmagnitude decrease hardness result small increase constrainttightness. instances hardness varies dramatically hard illustratedifference constraint tightness values = 1.0 = 2.0 using eitheroriginal scale log scale. explains scale scheme used Figure 4.reason dramatic change explained follows. randomly generate constraints tightness > 1 constraint, positive (fixed)531fiGao & Culberson50003000branches400020001000101.21.45.551.64.5m/n43.531+a1.82.5Figure 4: Effects increase constraint tightness instance hardnessF(n, m, a) n = 250. z-axis median number branchesfirst three highest peaks scaled 1/40, 1/10, 1/4 respectively. axisrange 1.0 ... 1.8 parameter 1 + a, 0 0.8 axisrange 2.5 ... 6 clause density m/n.probability restriction set something {(1, 0, 0), (0, 0, 0)}.constraint 3-consistent, partial assignment = 0, z = 0 consistentextension x. effect, constraint induces binary constraint y, z restriction {(0, 0)}. enough constraints, induced binary constraintscreate unsatisfiable subproblem, since domain also Boolean, subproblem detected polynomial time. Upper bounds m/n establishedexistence easy unsatisfiable subproblems F(n, m, a). example, knowupper bounds m/n F(n, m, a) exponential resolution complexity respectively 23.3 = 0.1 11.7 = 0.2 (Gao & Culberson, 2003). Sinceratio constraints variables m/n considered experiment wellbounds embedded 2SAT subproblems appear high probability, seemsimpact forcers instance hardness goes beyond simply producing higlystructured 2-SAT-like embedded easy subproblems. see similar effect nextsubsection non-Boolean valued CSP instances.4.2 Random Binary CSP Models: Significance Structuresset experiments designed investigate whether introducing structural elementsenforce constraint consistency random CSPs leads significant increasetypical case hardness instances practical size. mentioned purposeexperiments compare rank relative merits solversused experiments. Neither intention exhaust available solversimplementation techniques solve set problem instances.532fiConsistency Random CSPsd,td,tthree random CSP models consider Bn,m(the Model B), Bn,m[M] (thed,tflawless model), generalized flawless model Bn,m [L] different domain sizedifferent consistency-inducing core graphs. Randomly-generated instances models encoded CNF formulas solved SAT solver ZChaff 1 . Also includedexperiments comparison ZChaff, SatZ (Li & Anbulagan, 1997) 2 ,CSP solver based forward checking (FC) maintaining arc consistency (MAC)static variable order3 .looks unnatural primarily tested random CSP instances convertingSAT instances using SAT solver solve them. justifiedfollowing considerations. First, existing research resolution complexityrandom CSPs carried studying resolution complexity SATencoding CSPs described Section 3. use encoding experiments.Secondly, shown far complexity solving unsatisfiable CSPinstances concerned, many existing CSP algorithms efficiently simulatedresolution system corresponding SAT encodings CSPs (Mitchell, 2002a).Experimental comparisons conducted three CSP models domain size(d = 4, 5, 6, 9) different values constraint tightness. generalized flawlessCSP models constructed using WC-inducing core graphs described Figure 1.next two subsections, focus results domain size = 4 9.experiments carried machines AMD Athlon (tm) Processor (Model 3700,Frequency 2.4GHz, Main Memory 1GB 1MB Cache) running Linux. followingsetup used experiments: sample size parameter point 100;cutoff time solvers 1800 seconds CPU time.4.2.1 Case = 4d,t[WC] use experiment based WC-inducingcase = 4, Bn,mcore graph shown Figure 1, connected 2-regular bipartite graph (or 8-cycle). Notecore graph, maximum possible constraint tightness 8.observe detailed behavior models, first fixed constraint tightness= 6 number variables n = 500. Figure 5 plots solution probabilityfunction ratio constraints variables three CSP models.d,texperimental data, observed phase transition Bn,m[WC] much sharperd,td,t 4Bn,m[M] Bn,m.d,timportantly, instances Bn,m[WC] phase transition clearly much harderd,td,tBn,m Bn,m [M]. Figures 6, 7, 8 show 50th percentile, 20thpercentile, 10th percentile, 5th percentile number branches running timeseconds ZChaff solve randomly-generated CSP instances three models.d,tseen, instances drawn Bn,m[WC] consistently much harder1.2.3.4.Available http://www.princeton.edu/ chaff/zchaff.htmlAvailable http://www.laria.u-picardie.fr/ cli/EnglishPage.htmlAvailable http://ai.uwaterloo.ca/ vanbeek/software/software.htmlreader aware model doesnt show phase transition limit (as problem sizeapproaches infinity).533fiGao & Culberson10.90.8Solution Probability0.70.60.50.40.3generalized flawlessflawless modelmodel B0.20.1000.511.522.5ConstraintsVariables Ratio33.54Figure 5: Solution probability function ratio constraints variablesthree random CSP models n = 500, = 6. generalized flawlessmodel, L set connected 2-regular bipartite graphs. y-axissolution probability x-axis ratio constraints variables m/n.Sample size data point 100.d,td,tBn,mBn,m[M] terms size search tree running timesatisfiable instances (Figure 8) well unsatisfiable instances.d,tCareful readers may noticed model Bn,m[WC], number branchesobvious secondary peak phase transition (Figure 6 Figure 8),anomaly reported previous paper (Gao & Culberson, 2004). detailed look experimental data reveals secondary peak, though persistentstatistical sense, appears number branches; noticed measurerunning time secondary peak. tried several approaches understand secondary peak, finally conclude solver-dependent behaviorcaused branching heuristics, CNF encoding, level local consistencyenforced CSP models. provide discussion phenomenonnext subsection.case = 4, also studied behavior CSP models differentconstraint tightness values. results reported Tables 1 2 showmaximum ratio constraints variables median numberbranches three CSP models constraint tightness ranging = 5= 8. results consistent observed experiments Boolean CSPs,showing increase constraint tightness significant impact typical caseinstance hardness. also clear constraint tightness values, instancesd,tgeneralized flawless model Bn,m[WC] significantly harder two534fiConsistency Random CSPs5610medianNumber BranchesNumber Branches104103102123ConstraintsVariables Ratio6Number Branches4103101040123ConstraintsVariables Ratio4generalized flawlessflawless model6model B 101090th percentile51041031021051020Number Branches1095th percentile80th percentile51041031020123ConstraintsVariables Ratio1040123ConstraintsVariables Ratio4Figure 6: Number branches used ZChaff solve instances three random CSPd,t[WC],models n = 500, = 6, = 4. generalized flawless model Bn,mcore graph connected 2-regular bipartite graph described Figure 1.d,tclassical models. case = 5, instances drawn Bn,m[WC] cannot solvedwithin time limit 1800 seconds even solubility phase transition.confirm enforcing constraint consistency increases typical case hardness, tested two backtracking solvers experiments: SatZ CSP solverFC + MAC static variable ordering.set experiments, problem size n = 300 run solversinstances reduce variance. summarize results Tables 3 4.problem size n = 300, ZChaff SatZ little difficulty solving randomlygenerated instances three models except rare cases, SatZget stuck instances generated ratio constraints variables wellthreshold. Although CSP solver works directly CSP instances, performwell SAT solvers working encoded instances. Given long history535fiGao & Culberson24101095th percentilemedian12SecondsSeconds100101102101001021.522.533.5ConstraintsVariables Ratio10401090th percentile80th percentile2210SecondsSeconds4generalized flawlessflawless model4model B 104010210123ConstraintsVariables Ratio1001020123ConstraintsVariables Ratio104123ConstraintsVariables Ratio4Figure 7: User CPU time seconds solve instances three random CSP modelsd,tn = 500, = 6, = 4. generalized flawless model Bn,m[WC], coregraph connected 2-regular bipartite graph described Figure 1.536fiConsistency Random CSPs66101095th percentileNumber BranchesNumber Branchesmedian51041031020.511.52ConstraintsVariables Ratio6Number Branches410310102.500.511.52ConstraintsVariables Ratio2.5generalized flawlessflawless model6model B 101090th percentile5104103102101020Number Branches10580th percentile510410310200.511.52ConstraintsVariables Ratio102.500.511.52ConstraintsVariables Ratio2.5Figure 8: Number branches used ZChaff solve satisfiable instances threerandom CSP models n = 500, = 6, = 4. generalized flawlessd,tmodel Bn,m[WC], core graph connected 2-regular bipartite graph described Figure 1.537fiGao & Culberson(n, t)(500, 5)(500, 6)(500, 7)(500, 8)d,tBn,mbranches10673724344401853m/n2.301.801.400.90d,tBn,m[M]branches m/n202712.9074461.9051231.5041131.20d,tBn,m[WC]branchesm/n?> 3.10942812.44138132.0091631.60Table 1: maximum,n , median number branches ZChaff100 random instances three random CSP models , domain sized,t= 4, tightness = 5, 6, 7, 8. generalized flawless model Bn,m[WC],core graph connected 2-regular bipartite graph described Figure 1.(n, t)(500, 5)(500, 6)(500, 7)(500, 8)d,tBn,mseconds m/n0.082.800.022.000.011.400.000.90d,tBn,m[M]seconds m/n1.792.900.021.900.021.700.001.00d,tBn,m[WC]secondsm/n> 1800 > 3.1040.32.441.082.000.261.60Table 2: maximum,n , median running time seconds ZChaffrandom instances three random CSP models , domain size = 4,d,ttightness = 5, 6, 7, 8. generalized flawless model Bn,m[WC], coregraph connected 2-regular bipartite graph described Figure 1.development SAT solvers, significant branch selection heuristics SatZ clauselearning (nogood recording) ZChaff, surprising. particular,d,tdesign Bn,m[WC] seen rendering consistency checking CSP solverless effective. Still, better performance SAT solvers indicates stillstructure exploit.4.2.2 Case = 9study robustness method seek explanations doublepeaks, consider case domain size = 9. turns = 9 ableconstruct variety random CSP models significantly different behavior.consider collection 5 random CSP models:d,t1. Bn,m(model B),d,t2. Bn,m[M] (the flawless model),538fiConsistency Random CSPs(n, t)(300, 5)(300, 6)(300, 7)(300, 8)ZChaffseconds m/n4.163.100.332.500.112.000.031.70SatZseconds m/n2.503.100.312.500.112.000.031.70CSP (FC + MAC)secondsm/n90.213.1012.112.503.102.000.601.70Table 3: Maximum,n , median number branches ZChaff, SatZ,d,tCSP solver FC + MAC random instances Bn,m[WC] , n = 300,d,t= 4, = 5, 6, 7, 8, core graph Bn,m [WC] connected 2-regularbipartite graph described Figure 1.(n, t)(300, 5)(300, 6)(300, 7)(300, 8)ZChaffseconds m/n0.082.900.012.200.011.700.001.30SatZseconds m/n0.152.900.022.200.011.700.011.30CSP (FC + MAC)secondsm/n2.683.000.292.200.091.800.061.30Table 4: Maximum, overalln , median running time seconds ZChaff, SatZ,d,tCSP solver FC + MAC random instances Bn,m[M], n = 300,= 4, = 5, 6, 7, 8.d,t3. Bn,m[L1 ] L1 constructed using 18 cycle (i.e., connected 2-regular bipartitegraph) arbitrary bijections,d,t4. Bn,m[L2 ] L2 constructed using core graph shown Figure 1 arbitrarybijections,d,t5. Bn,m[L3 ] L3 constructed using core graph Figure 1 blockrespecting bijections.d,td,td,tRecall model Bn,m[L2 ] belongs class Bn,m[WC], Bn,m[L3 ] belongsd,tclass Bn,m [SC]. five models, fix constraint tightness = 45,maximum possible constraint tightness achieved generalized flawlessmodel WC-inducing core graph.experiments show typical-case hardness randomly generated instancesincreases level consistency enforced. Figure 9, plot mediannumber branches median running time seconds ZChaff solve instancesd,td,td,tBn,m, Bn,m[M], Bn,m[L1 ]. Figure 10, show median number539fiGao & Culberson63101018cycleflawless modelmodel B18cycleflawless modelmodel B2105Number Branches101Seconds10010410110310211.522.5ConstraintsVariables Ratio10311.522.5ConstraintsVariables Ratio3d,td,td,tFigure 9: Results using ZChaff solve instances Bn,m, Bn,m[M], Bn,m[L1 ]L1 constructed 18 cycle (i.e., connected 2-regular bipartite graph)arbitrary bijections. parameters used n = 300, = 9, =d,t45. Bn,m[L1 ] parameter m/n = 2.3, ZChaff failed solve 45100 instances. data (pointed solid triangles) m/n = 2.3 basedsolved instances only.branches median running time seconds ZChaff solve instancesd,td,tBn,m[L2 ] Bn,m[L3 ].d,td,t[M], ZChaff able solve instances within time limitBn,mBn,m1800 seconds m/n. ZChaff starts frequent timeouts m/n 2.3.d,t[L1 ] m/n = 2.3, ZChaff solve 55 100 instances within 1800 seconds,Bn,m10 55 solved instances unsatisfiable. m/n = 2.4, 2.5, 2.6, ZChaffsolve 42 instances (respectively, 81 instances, 90 instances) unsatisfiable.d,td,tmodels Bn,m[L2 ] andBn,m[L3 ], observed 100 instances generatedd,tparameter m/n = 2.3, ZChaff solve 90 instances Bn,m[L2 ] 33 instancesd,td,tBn,m[L3 ]. Bn,m[L2 ] m/n = 2.4, ZChaff solved 5 instances.d,td,tsolved instances Bn,m[L2 ] Bn,m[L3 ] satisfiable, expected sinced,tregion well threshold. didnt conduct experiments Bn,m[L2 ]d,tm/n = 2.5 2.6 Bn,m[L3 ] m/n = 2.4, 2.5 2.6, expect instancesmodels even harder.assumed secondary peak observed CSP models = 4algorithm-independent unique models, expected using largerdomain size variety CSP models would able help provide satisfactoryexplanation phenomenon. designed experiments empirically investigaterelations appearance secondary peak three characteristics540fiConsistency Random CSPs63101018cycleWCinducingSCinducing18cycleWCinducingSCinducing2105110SecondsNumber Branches10410010310110210121.522.5ConstraintsVariables Ratio10311.522.5ConstraintsVariables Ratio3d,tFigure 10: Results using ZChaff solve instances Bn,m[L1 ], weakly 4-consistentd,td,tmodel Bn,m [L2 ] strongly 3-consistent model Bn,m [L3 ]. parameters used = 9, n = 300, = 45. ZChaff starts frequent timeoutsm/n 2.3. Therefore m/n = 2.3, data (pointed solid trid,t[L1 ], 45angles) based solved instances only. model Bn,m55 solved instances satisfiable remaining 10 solved instancesd,tunsatisfiable. weakly 4-consistent model Bn,m[L2 ] strongly 3d,tconsistent model Bn,m [L3 ], Zchaff solved 90 instances (respectively 33 instances)d,tsatisfiable. weakly 4-consistentmodel Bn,m[L2 ]m/n = 2.4, ZChaff solve 5 100 instances 5 instancessatisfiable.541fiGao & CulbersonCSP models including (1) number derangements bijections constraintconstruction, (2) level enforced local consistency models, (3) CNFencoding scheme. Based series results, conclude secondary peakalgorithm-dependent artifact influenced selection branch heuristics,level local consistency enforced models, CNF encoding scheme.following, briefly summarize experimental investigations which, hope, also helpsillustrate flexibility framework constructing ensemble problem instancesstudy behavior different algorithms.1. Number Derangements. number derangements bijection : Vnumber vertices vi V (vi ) 6= i. derangementbijections constraint construction, generated instances alwayssatisfied assignments assign common domain value variables.Contrary initial assumption, observe significant impactnumber derangements behavior solvers except extreme casesuse bijections derangement probability close one.2. Local Consistency Level. main difference among five models = 9d,tlevel enforced local constraint consistency. Bn,menforced,td,t[L1 ] guarantees[M] enforces arc-consistency; Bn,mconsistency; Bn,md,tforcer; Bn,m[L2 ] generates instances weakly 4-consistent; instancesd,tBn,m [L3 ] strongly 3-consistent. addition obvious impact instanceshardness, experiments indicate local consistency level modelscontributes appearance secondary peak ZChaff. depicted Figures9 10, problem size n = 300, secondary peak exists first fourd,tmodels enforce strong 3-consistency, fifth model Bn,m[L3 ]peak. However, observed, additional trials reportedd,t[L3 ] increase problem size.here, secondary peak also exists Bn,m3. CNF Encoding Scheme. experiments, CNF encoding CSPinstances include clauses enforce unique assignment CSPvariable. absence clauses affect theoretical exponentiallower bounds resolution complexity, observed experiments mixedimpacts clauses behavior solvers including appearancesecondary peak ZChaff. clauses included CNF encoding,number branches running time SatZ increase, ZChaffrunning time obvious decrease. also interesting addingclauses CNF encoding also makes secondary peak ZChaff even sharper.believe largely due greedy branching heuristics SatZtradeoff search inference achieved ZChaff.empirical studies phase transitions AI literaturefocused behavior solvers around solubility threshold randommodel, would like point observations maderatio constraints variables respective models threshold, parameter regionselection branch heuristics no-good recording technique makebig difference.542fiConsistency Random CSPs5. Conclusions Future DirectionsRandom semi-random binary constraint instances used test various aspectsCSP solvers many researchers. illustrate robustness algorithms, desirableinstances generated model trivially unsolvable minimalguarantee interest generators produce instances asymptoticallyexponential resolution proofs. paper shown ensureconstraints instances strongly 3-consistent weakly 4-consistentcase. addition shown create instances,allowing high constraint tightness, allowing considerable flexibility constraintdesign. experimental sections showed significant increase difficulty instancesgenerated model models similar densities tightness. also noticeddouble peak phenomenon experiments identified artifactspecific solver, influenced choice generation model characteristicsinstances. exemplifies exactly kind algorithmic issue hopegenerators would help researchers identify explore.generation hard instances two foci, one restriction constraintsrestricting constraint graph (or hyper-graph). specific problems,example independent set (Brockington & Culberson, 1996) SAT (Bayardo Jr. & Schrag,1996), observed techniques balancing degree constraintgraph reduce variance increases difficulty instances, whether camouflaginghidden solution phase transition semi-random instances. expect modifying generation model also controlling graph structure might lead harderinstances, interesting properties would test mettle various algorithms.example, suppose consider domain = {0, 1, 2, 3} let constraintset allowed value pairs {(0, 1), (0, 3), (1, 0), (3, 0), (1, 2), (2, 1), (2, 3), (3, 2)}.constraint could generated system using eight cycle enforces weak4-consistency value set induces two four cycles pair domains. Thus,constraint generate weakly 4-consistent CSPs. hand, arcconsistent contain forcer, since vertex induced constraint graphdegree two. consider constraint graph triangle, applyingconstraint three edges mean satisfying assignment. Since randomgraph m/n = c positive (bounded) expected number triangles,positive expectation instance generated allowing constraint wouldtrivially unsatisfiable. Thus, appears weak 4-consistency minimal requirementexponential complexity random constraint graphs. Notice weak 4-consistencyensures every triangle satisfiable, also ensures (by induction basically)larger cycle satisfiable. Thus, speaking general terms, waysub-instance unsatisfiable subgraph contain edges vertices.random graph analysis shows means asymptotically minimal unsatisfiable subinstance size O(n), course key ingredient complexity analysis.Now, suppose ensure constraint graph girth g > 3. technique used specific problems, example graph coloring problems(Culberson, Beacham, & Papp, 1995). wonder whether combining graphrestriction together weak g + 1-consistency (weaker weak 4-consistency) might543fiGao & Culbersonalso produce instances exponentially long resolution proofs. Note one difficultyanalysis longer uniformly random graphs.start considering larger picture, involving multiple variables, naturallymust consider k-ary constraints. part future research expect consider extendingmodel cases. course experiments effects increasingtightness presented paper 3-ary constraints (SAT). fact, initial foraytightness started variations SAT.final cautionary note, point well known possibleCSP (i.e. SAT) instances exponential resolution proofs, resolvablepolynomial time techniques, Gaussian elimination. certainsystem produce instances, see explicit reason preventsso.Acknowledgmentspreliminary version paper appeared Proceedings Tenth InternationalConference Principles Practice Constraint Programming (CP-2004). thankreferees helpful comments conference version journal version.Thanks also given Dr. K. Xu comments conference version paper.research supported Natural Sciences Engineering Research CouncilGrant No. OGP8053. Yong Gao supported part UBCO startup grantNSERC Discovery Grant RGPIN 327587-06.Appendix A: Proofs Theoremssection, present concepts related resolution complexity results statedpaper prove Theorems 2.1, 3.1, 3.2.A.1 Proof Theorem 2.1providing proof Theorem 2.1, let us first formalize definitionsforcer, forbidding cycle, r-flower.Definition A.1 (Forcers, Molloy & Salavatipour, 2003). constraint Cf var(Cf ) ={x1 , x2 } called (, )-forcer nogood set{(, ); 6= },, , domain values involved variables. say constraint Ccontains (, )-forcer Cf defined set variables C nogood setCf subset nogood set C.Definition A.2 (Forbidding cycles r-flowers, Molloy & Salavatipour, 2003). forbidding cycle variable x0 set constraintsC1 (x0 , x1 ), C2 (x1 , x2 ), . . . , Cr1 (xr2 , xr1 ), Cr (xr1 , x0 )544fiConsistency Random CSPsC1 (x0 , x1 ) (, 1 )-forcer, Cr (xr1 , x0 ) (r1 , r )-forcer (r 6= ),Ci (xi1 , xi ) (i1 , )-forcer (2 r 1). call x0 center variable-forbidding cycle.r-flower R = {C1 , , Cd } consists (the domain size) forbidding cycleslength r1. Ci , 1 d, center variable x;2. Ci distinct -forbidding cycle common center variable x;3. forbidding cycles share variables.following facts straightforward establish:1. r-flower consists = d(r 1) + 1 = dr + 1 variables dr constraints;2. total number r-flowersns!(d 1)d dd(r1) .d,t3. constraint Bn,m[M] contains (, )-forcer pair (, ) onetuples considered selecting set nogoods constraint.following, assume r = o( n). probability constraint containsforcer probability random instance flawless random CSP modelcontains r-flower given following lemma.Lemma A.1. Consider flawless random CSPd,tBn,m[M]define fe =(d2 dd+1td+1d2()).1. probability given constraint C(x1 , x2 ) contains (, )-forcer1fe .(A.1)2. Let R r-flower let c = m/n,d,tP {R appears Bn,m[M]} = (1)(2cfe )dr1 1.ndr ddr(A.2)Proof. Equation (A.1) follows following two observations:1.1probability (, ) one tuples consideredd,tselecting set nogoods constraint Bn,m[M]2. fe probability 1 tuples, (, ), 6= , set nogoodsselected uniformly random d2 tuples.545fiGao & Culbersond,tcalculate probability given r-flower R appears Bn,m[M], noticeprobability selecting constraint edges RN drcn(cn 1) (cn dr + 1)cndr=NN (N 1) (N dr + 1)cndr2c= (1)nN = n2 . Since fixed choice dr constraint edges r-flower,probability constraints contain r-flower ( d1 fe )dr , Equation (A.2) follows.Proof Theorem 2.1. Let c =2fe .show c =n> c,d,tlim P {Bn,m[M]} contains r-flower } = 1.(A.3)nd,tLet IR indicator function event r-flower R appears Bn,m[M]letXX=IRRd,tsum possible r-flowers. Then, Bn,m[M] contains r-flowerX > 0.Lemma A.1 fact = dr + 1,XE[X] =E[IR ]Rn1 1= (1)s!(d 1)d dd(r1) (2cfe )dr dr drn1 1= (1)n(n 1) (n + 1)ddr (2cfe )dr dr drn= (1)n1d (2cfe )dr .Therefore, c > c r = log n sufficiently large, lim E[X] = .nshow E[X 2 ] E 2 [X](1 + o(1)), application Chebyshevinequality establish lim P {X = 0} = 0. get upper bound E[X 2 ],nneed counting argument upper bound number r-flowers sharing given numberedges. done considering shared edges form connected components(Franco & Gelder, 2003; Gao & Culberson, 2003; Molloy & Salavatipour, 2003). Here,546fiConsistency Random CSPsfollow method used Molloy Salavatipour (2003),XXX XXX2E[X 2 ] =E[IA]+E[IA IB ] +IANij (Pij )dri=XB:BA=ff2E[IA]+XXE[IA ]E[IB ] +XB:BA=ff2i=1 j=1E [X] +XIAXXXXIANij (Pij )drii=1 j=1Nij (Pij )dri(A.4)i=1 j=1(1) Nij number r-flowers share exactly constraint edgesconstraints forms j connected components constraint graph A;(2) (Pij )dri probability conditional IA , random CSP contains drconstraints specific r-flower. work Molloy Salavatipour (2003), Nijupper bounded2(2 + r2 )d (dr2 )j1 j!nsij dsij+d1 ,((2 + r2 )d (dr2 )j1 )2 j! upper bounds number ways choose arrange jshared connected components two r-flowers; nsij upper bounds number wayschoosing remaining non-shared variables since number variablesj shared connected components least one plus number edges sharedcomponent; dsij+d1 upper bounds number ways choosing forcing valuesnon-sharing variables. shared variables take forcing valuesdue assumption < (Molloy & Salavatipour, 2003).Since case d1 d2 d, possible shared variables take differentforcing values different r-flowers. Thus, upper bound Nij(2 + r2 )d (dr2 )j12j!nsij ds .case, probability corresponding (Pij )driN dr(dri)1cni(dri)( fe )driN drcni= (1)(2cfe )dri= (1)(11ndriddri547.cn dri 1 dri)( fe )N drfiGao & CulbersonTherefore, c =2fe ,XXNij (2cfe )drii=1 j=1X11ndriddri(2 + r2 )2d r4 nsi ds (2cfe )drii=1XO(r4d4 )n1d (2cfe )dri=111ndriddri24Xr j j()nj=1(2cfe )i r4O( )dinE[X]O(r4d4r4 X))O( )(n2cfei=1E[X]O(r4dn),last inequality c >completed.2fe .formula (A.4), proofRemark A.1. relatively loose upper bound c = 2fde proof may improvedfactor making distinction among r-flowers share forcingvalues different number shared variables. purpose showingflawless random CSP also potential embedded easy sub-problems, upper boundconstraint-variable ratio c sufficient since domain size constant.A.2 Proof Theorems 3.1 3.2Given CNF formula F, use Res(F) denote resolution complexity F, i.e.,length shortest resolution refutation F. width deriving clause F,denoted w(F ` A), defined minimum resolution refutationsmaximum clause size resolution refutation. width w(F) formula Fsize largest clause it. Ben-Sasson Wigderson (2001) established relationshipRes(F) w(F ` ):Res(F) = e((w(F `)w(F ))2)n.relationship indicates give exponential lower bound resolution complexity, sufficient show every resolution refutation F contains clause whosesize linear n, number variables.Let instance CSP let CNF(I) CNF encoding I. Mitchell(2002b) provided framework within one investigate resolution complexityI, i.e., resolution complexity CNF formula CNF(I) encodes I, workingdirectly structural properties I. Denote var(I) set CSP variablesvar(CNF(I)) set encoding Boolean variables CNF(I). sub-instance JCSP instance var(J ) var(I) J contains constraintswhose scope variables var(J ). following crucial concepts make possible work548fiConsistency Random CSPsdirectly structural properties CSP instance investigating resolutioncomplexity encoding CNF formula.Definition A.3 (Implies, Mitchell, 2002b). Let C clause encoding Booleanvariables var(CNF(I)). say sub-instance J implies C, denoted J |= C,assignment CSP variables satisfying J , correspondingassignment encoding Boolean variables satisfies C.Definition A.4 (Clause Complexity, Mitchell, 2002b). Let CSP instance.clause C defined Boolean variables var(CNF(I)), define(C, I) = min{|var(J )|; J sub-instance implies C}.following two concepts slightly generalize used Mitchell (2002b)Molloy Salavatipour (2003) enable us uniform treatment establishingresolution complexity lower bounds.Definition A.5 (Boundary). boundary B(J ) sub-instance J definedset CSP variables variable x B(J ) following true:J minimally implies clause C defined Boolean variables var(CNF(I)),C contains least one Boolean variables, x : , D, encode CSP variablex.Definition A.6 (Sub-critical Expansion, Mitchell, 2002b). Let CSP instance.sub-critical expansion definede(I) =maxmin|B(J )|(A.5)0s(,I) s/2|var(J )|sminimum taken sub-instances s/2 |var(J )| s.following theorem relates resolution complexity CNF encoding CSPinstance sub-critical expansion CSP instance.Theorem A.2 (Mitchell, 2002b). CSP instance I,w(CNF(I) ` ) e(I)(A.6)Proof. resolution refutation CNF(I) (, I), Lemma 1 Mitchell(2002b) shows must contain clause Cs/2 (C, I) s.Let J sub-instance |var(J )| = (C, I) J implies C. Since J minimallyimplies C, according definition boundary, w(C) |B(J )|. Formula (A.6)follows.establish asymptotically exponential lower bound Res(C) random CSP C,enough show constant > 0lim P {e(C) n} = 1.n549(A.7)fiGao & Culberson> 0, let () event {(, C) > n} (, ) event)(minn|var(J )|n2B(J ) n .NoticeP {e(C) n} P {Am () (, )}1 P {Am ()} P {As (, )}.(A.8)need find appropriatelim P {Am ( )} = 0(A.9)lim P {As ( , )} = 0.(A.10)nnEvent ( ) size minimally unsatisfiable sub-instances. event( , ), common practice identify special subset boundaries showsubset large. different random CSP models different assumptionsmodel parameters, different ways achieve this. Following Beame et al.(2005), say graph G (r, q)-dense subset r vertices induces leastq edges G.d,tProof Theorem 3.1. Recall constraint graph Bn,m[SC] standardrandom graph G(n, m).d,tSince instance Bn,m[SC] strongly k-consistent, variables minimal unsatisfiable sub-instance J |var(J )| = r must vertex degree greater equalk, consequently, constraint sub-graph H(J ) must contain least rk2 edges. Thus,d,t[SC]) n}P {Am ( )} = P {(, Bn,m( n)[P{G(n, m) (r, rk/2)-dense } .r=k+1Let B k (J ) set variables var(J ) whose vertex degrees less k. Again,d,tsince instances Bn,m[SC] always strongly k-consistent, B k (J ) B(J )kthus, |B(J )| |B (J )|. Therefore, probability P {As ( , )} boundedP {As ( , )} P {Aks ( , )}Aks ( , ) eventkminn/2|var(J )| n550B (J ) n .fiConsistency Random CSPsRandom graph arguments (see, e.g., Beame et al., 2005) show exist constantsP {Am ( } P {Aks ( , )} tend 0. Indeed, letn(n1)(12 )k > 1, c =.n , N =2(P {Am ( )} P[n){G(n, m) (r, rk/2)-dense }r=k+1nXP {G(n, m) (r,r=k+1rk)-dense}2n r(r1)XNn2rkr2r=k+1rk 1N2rk2nXen e(r 1) rk 2c rk)2( )2( )r (rknr=k+1nXen 2ec(r 1) k r=()2rknr=k+1nXk k k+2 k r k2 r=( )2 e 2 c2 ( ) 22nr=k+1blog ncXr=k+1k k k+2 k log n k2( )2 e 2 c2 () 22nnX+r=blog ncSimilarly, =k k k+2 k k2 log n( ) 2 e 2 c 2 ( ) 222,P {Aks ( , )} = Pn[{ size-r sub-instance J s.t. |Bk (J )| n}r= nn[r(1 )k{G(n, m) (r,)-dense}2r= n2r(1)knX2(1)k+2(1)k22ce 2 ( ) 2(1)knr=2P(A.11)(A.12)2second inequality fact sub-instance J size r|Bk (J )| n, constraint graph contains least r n = r 2 n r r verticeswhose degree least k.551fiGao & Culberson(1 )kexist (1) 2> 1; (3) right hand< 1; (2)2side formula (A.11) right hand side formula (A.12) tend zero.completes proof Theorem 3.1.d,tprove Theorem 3.2. First definition Bn,m[W C], followingd,tLemma A.3. random CSP Bn,m[W C],1. Every sub-instance whose constraint graph cycle satisfiable;2. path length 3, compatible assignments two variablesends path extended assignments satisfy whole path.effort establish exponential lower bounds resolution complexityclassical random CSP models tightness higher established Mitchell(2002b), Molloy Salavatipour (2003) introduced collection sub-instances, denotedBM (J ), used size give lower bound size boundary.binary CSPs whose constraints arc-consistent contain forcer, BM (J ) consists1 (J ) B 2 (J ), defined respectively follows:two parts: BM1 (J ) contains set single-edge sub-instances X , i.e., |var(X )| = 2,1. BMleast one variables vertex degree 1 original constraint graph;2 (J ) contains set sub-instances X whose induced constraint graph pen2. BMdant path length 4, i.e., path length 4 vertexendpoints vertex degree greater 2 original constraint graph.shownLemma A.4. weakly path-consistent CSP sub-instance J ,1|B(J )| |BM(J )| +2 (J )||BM.41 (J ) B(J );Proof. variable degree one sub-instance BM2least one internal variable pendant path BM (J ) B(J ). possibleseveral pendant paths length 4 share common internal variable B(J ),e.g., long pendant path. variable appear three pendantpaths length 4.preparations, proof provided Theorem 1 Molloy Salavatipour(2003) readily applies case. make report self-contained, give proofbelow.Proof Theorem 3.2. Lemma A.3, minimally unsatisfiable sub-instance J(1) constraint graph cannot single cycle; (2) BM (J ) empty since1 (J )| = 0 |B 2 (J )| = 0 minimally unsatisfiable sub-instance. According|BM1Lemma 11 Molloy Salavatipour, constraint graph J least (1+ 12)var(J )552fiConsistency Random CSPsedges. Therefore, due locally sparse property random graphs, constant> 0 formula (A.9) holds, i.e.,lim P {Am ( )} = 0.nestablish formula (A.10), due Lemma A.4P {As ( , )} P {As,M ( , )}As,M ( , ) eventminn/2|var(J )| n|BM (J )| n .suppose contrary > 0, sub-instance J n/21 (J )| + |B 2 (J )| n. Then, Lemmas 10 11 Molloy|var(J )| |BMSalavatipour, constraint graph J contains cycle components, Lemma11 Molloy Salavatipour asserts edges-to-vertices ratio constraint graphJ bigger one. remove cycle components constraintgraph J , edges-to-vertices ratio remaining graph becomes even bigger.impossible constraint graph J , hence remaining graph,less n vertices.well-known w.h.p. random graph fewer log n cycle componentslength 4; random graph G(m, n) m/n = c constant,number cycle components fixed length asymptotically Poisson distribution(Bollobas, 2001). Thus, number variables cycle components length4 4 log n. Since cycle component length l > 4 contains l pendant pathslength 4, total number variables cycle components length greater 42 (J )| < n. Therefore, var(J ) < n + 4 log n < n/2 var(J )|BMsufficiently small , contradiction.We, therefore, conclude w.h.p, sub-instance Jn/2 |var(J )| , |BM (J )| n, i.e., formula (A.10) holds.A.3 Upper Bound Threshold Random Restricted Binary CSPd,tBn,m[L]subsection, show condition mentioned end Definition 2.1d,tguarantees existence constant c Bn,m[L] m/n > c asymptoticallyunsatisfiable probability one. state prove result case binaryconstraints, similar results also hold general k-ary constraints.Recall condition set relations L = {L1 , L2 , . . . | Li D}\(a, a)/Li , D.(A.13)i1Since assume domain size fixed, probability constraintd,tBn,m[L] contains (a, a) one nogoods lower bounded constant p.553fiGao & Culbersond,tTheorem A.5. Bn,m[L] set relations L satisfies condition A.13,unsatisfiable w.h.p.n = nd(1p c) < 1.d2Proof. assignment A, must subset nd variables assignedd,tcommon domain value a. Then, satisfies Bn,m[L] satisfies constraintsd,tinvolve variables S. Let Hi event Bn,m[L] constraintsinvolve variables S. Then,d,tP {A satisfies Bn,m[L]}cnX(1 p)i P {Hi }.i=0Let N = 21 n(n 1). WriteN1 =1n n1( 1) = 2 n(n 1) + O(n)2d2dnumber possible edges induced S,11N2 = N N1 = (1 2 )n(n 1) + O(n).21 cn 1N2N1P {Hi } =cniNcnN1 (N1 1) (N1 + 1) N2 (N2 1) (N2 cn + + 1) (cn)!N (N 1) (N cn + 1)i!(cn i)!cniN1N2cnNNcniN1N2cnNN cn=Similarly,N2cnNcnP {H0 } =N1cnNcnN2N cnP {Hcn } =554N1NcncnfiConsistency Random CSPsSo,d,tP {A satisfies Bn,m[L]}cnX(1 p)i P {Hi }i=0cnXcniN2cnN1(1 p)NN cni=0cncniXN1 N2 Ncn(1 p)NN N cni=0cnN1 N2 N= (1 p)+NN N cn11 cn= (1 p) 2 + (1 2 )O(1)p cnO(1)= 1 2Therefore,p cnp nd,tP {Bn,m[L] satisfiable } dn 1 2= d(1 2 )cReferencesAchlioptas, D., Beame, P., & Molloy, M. (2001). sharp threshold proof complexity.Proceedings 33rd Annual ACM Symposium Theory Computing, pp.337346.Achlioptas, D., L.M.Kirousis, E.Kranakis, D.Krizanc, M.Molloy, & Y.C.Stamation (1997).Random constraint satisfaction: accurate picture. Proceedings PrinciplesPractice Constraint Programming (CP-1997), pp. 107120. Springer.Bayardo Jr., R. J., & Schrag, R. (1996). Using CSP look-back techniques solve exceptionally hard SAT instances. Principles Practice Constraint Programming(CP-1996), pp. 4660.Beame, P., Culberson, J., Mitchell, D., & Moore, C. (2005). resolution complexityrandom graph k-colorability. Discrete Applied Mathematics, 153 (1-3), 2547.Beame, P., Karp, R. M., Pitassi, T., & Saks, M. E. (1998). complexity unsatisfiability proofs random k-CNF formulas. Proceedings 30th Annual ACMSymposium Theory Computing, pp. 561571.Ben-Sasson, E., & Wigderson, A. (2001). Short proofs narrow - resolution made simple.Journal ACM, 49 (2), 149169.Bollobas, B. (2001). Random Graphs. Cambridge University Press.Bondy, J. A., & Murty, U. S. R. (1976). Graph Theory Applications. MacMillanPress Ltd.555fiGao & CulbersonBrockington, M., & Culberson, J. C. (1996). Camouflaging independent sets quasirandom graphs. Johnson, D. S., & Trick, M. A. (Eds.), Cliques, Coloring,Satisfiability: Second DIMACS Implementation Challenge, Vol. 26, pp. 7588. American Mathematical Society.Chvatal, V., & Szemeredi, E. (1988). Many hard examples resolution. JournalAssociation Computing Machinery, 35 (4), 759768.Culberson, J., Beacham, A., & Papp, D. (1995). Hiding colors. CP95 WorkshopStudying Solving Really Hard Problems, pp. 3142, Cassis, France.Franco, J., & Gelder, A. V. (2003). perspective certain polynomial-time solvableclasses satisfiability. Discrete Applied Mathematics, 125 (2-3), 177214.Frieze, A., & Molloy, M. (2003). satisfiability threshold randomly generated binaryconstraint satisfaction problems. 7th International Workshop RandomizationApproximation Techniques Computer Science, RANDOM 2003, pp. 275289.Gao, Y., & Culberson, J. (2003). Resolution complexity random constraint satisfactionproblems: Another half story. LICS03 Workshop Typical Case ComplexityPhase Transitions.Gao, Y., & Culberson, J. (2004). Consistency random constraint satisfaction modelshigh constraint tightness. Proceedings Tenth International ConferencePrinciples Practice Constraint Programming (CP-2004), pp. 1731.Gent, I., MacIntyre, E., Prosser, P., Smith, B., & Walsh, T. (2001). Random constraintsatisfaction: Flaws structure. Constraints, 6 (4), 345372.Johnson, D. S. (2002). theoreticians guide experimental analysis algorithms.Data Structures, Near Neighbor Searches, Methodology: Fifth Sixth DIMACSImplementation Challenges, pp. 215250. American Mathematical Society.Li, C. M., & Anbulagan (1997). Heuristics based unit propagation satisfiability problems. Proceedings 15th International Joint Conference Artificial Interlligence(IJCAI97), pp. 366371.MacIntyre, E., Prosser, P., Smith, B., & Walsh, T. (1998). Random constraint satisfaction: theory meets practice. Proceedings Principles Practices ConstraintProgramming(CP-1998), pp. 325339. Springer.Mackworth, A. K. (1977). Consistency networks relations. Artificial Intelligence, 8,99118.Mitchell, D. (2002a). Resolution Complexity Constraint Satisfaction. Ph.D. thesis,Department Computer Science, University Toronto, Canada.Mitchell, D. (2002b). Resolution complexity random constraints. Proceedings Principles Practices Constraint Programming (CP-2002), pp. 295309. Springer.Molloy, M. (2002). Models thresholds random constraint satisfaction problems.Proceedings 34th ACM Symposium Theory Computing, pp. 209 217.ACM Press.556fiConsistency Random CSPsMolloy, M., & Salavatipour, M. (2003). resolution complexity random constraintsatisfaction problems. Proceedings 44th Annual IEEE Symposium Foundations Computer Science (FOCS-2003), pp. 330339. IEEE Press.Prosser, P. (1996). empirical study phase transitions binary constraint satisfactionproblems. Artificial Intelligence, 81 (1-2), 81109.Smith, B. M. (2001). Constructing asymptotic phase transition random binary constraint satisfaction problems. Theoretical Computer Science, 265 (1-2), 265283.Wormald, N. C. (1999). Models random regular graphs. Surveys Combinatorics,London Mathematical Society Lecture Note Series, vol. 276, pp. 239298. CambridgeUniv. Press.Xu, K., & Li, W. (2000). Exact phase transitions random constraint satisfaction problems.Journal Artificial Intelligence Research, 12, 93103.Zhang, L., Madigan, C., Moskewicz, M., & Malik, S. (2001). Efficient conflict driven learning boolean satisfiability solver. Proceedings International ConferenceComputer Aided Design (ICCAD2001), pp. 530535.557fiJournal Artificial Intelligence Research 28 (2007) 157181Submitted 08/06; published 02/07Junta Distributions Average-Case ComplexityManipulating ElectionsAriel D. ProcacciaJeffrey S. Rosenscheinarielpro@cs.huji.ac.iljeff@cs.huji.ac.ilSchool Engineering Computer Science,Hebrew University Jerusalem,Jerusalem 91904, IsraelAbstractEncouraging voters truthfully reveal preferences election longimportant issue. Recently, computational complexity suggested meansprecluding strategic behavior. Previous studies shown voting protocolshard manipulate, used N P-hardness complexity measure. worst-caseanalysis may insufficient guarantee resistance manipulation.Indeed, demonstrate N P-hard manipulations may tractable averagecase. purpose, augment existing theory average-case complexitynew concepts. particular, consider elections distributed respect juntadistributions, concentrate hard instances. use techniques provescoring protocols susceptible manipulation coalitions, number candidates constant.1. IntroductionMultiagent environments often inhabited heterogeneous, selfish agents, continuallyinteracting sharing common goals. settings, agents may diverseeven conflicting preferences. Therefore, reaching consensus among agents longimportant issue.general, well-studied well-understood scheme preference aggregation voting:agents reveal preferences ranking set candidates, winner determinedaccording voting protocol. candidates election beliefs, plans (Ephrati& Rosenschein, 1997), schedules (Haynes, Sen, Arora, & Nadella, 1997), indeed manyless obvious entities, movies (Ghosh, Mundhe, Hernandez, & Sen, 1999).Applications voting, place methods, motivated theoretical guaranteesprovided various voting protocols. instance, Ghosh et al. (1999) present movierecommender system relies voting, makes use voting properties generateconvincing explanations different recommendations.is, however, obstacle always plagued voting theory, social choicetheory general: strategic behavior part voters. setting, self-interestedagent may reveal preferences untruthfully, believes would make final outcomeelections favorable it. Manipulation generally regarded problem, sincemakes actual ballot complex game, voters react counter-reactstrategies others. require larger investment (computational)resources voters, may result socially undesirable alternative chosen.c2007AI Access Foundation. rights reserved.fiProcaccia & Rosenscheincelebrated Gibbard-Satterthwaite Theorem (Gibbard, 1973; Satterthwaite, 1975)establishes deterministic voting protocol non-dictatorial,1elections agent better voting untruthfully. Consequently, possibledesign nonmanipulable voting system guarantee voters act honestly.Fortunately, reasonable make assumption agents computationally bounded. Therefore, although principle agent may able manipulateelection, computation required may infeasible. motivated researchersstudy computational complexity manipulating voting protocols. Indeed,demonstrated several voting protocols N P-hard manipulate singlevoter (Bartholdi, Tovey, & Trick, 1989a; Bartholdi & Orlin, 1991). Hereinafter mainlyfocus attention setting multiple manipulators collude order achievecertain outcome. setting, manipulation even harder: knowncoalitional manipulation problem N P-hard numerous voting protocols, evennumber candidates constant.results suggest computational complexity may cure maladycalled Manipulation. Computer Science, though, notion hardness usuallyconsidered sense worst-case complexity. Indeed, results complexitymanipulation use N P-hardness complexity measure. Therefore, could stillcase instances problem easy manipulate. put differently,strategic voter may usually succeed finding beneficial manipulation, efficiently,even problem hard worst-case. so, truly significant issueaverage-case complexity manipulations.Sadly, far attempts design voting protocol resistant manipulationsaverage-case failed. suggests manipulation problem inherentlyeasy average-case pushes us analytically support claim: mustcharacterize settings protocols easily manipulated average-case.relatively little-known theory average case complexity exists (Trevisan, 2002);theory introduces concept distributional problems, defines reductiondistributional problems is. also known average-case completeproblems. However, goal existing theory define problem hardaverage-case; provide criteria deciding problem easy.paper, engage novel average-case analysis, based criteria propose.Coming interesting distribution problem instances respectaverage-case complexity computed difficult task, solution may controversial. analyze problems whose instances distributed respect juntadistribution. distribution must satisfy several conditions, (arguably) guarantee focuses instances harder manipulate. consider protocolsusceptible manipulation polynomial time algorithm usuallymanipulate it: probability failure (when instances distributed accordingjunta distribution) must inverse-polynomial. algorithm known heuristicpolynomial time algorithm.use new methods analytically establish following result: importantfamily voting protocols, called scoring protocols, susceptible coalitional manipulation1. dictatorial protocol, agent dictates outcome regardless others choices.158fiJunta Distributionsnumber candidates constant. Specifically, contemplate sensitive scoringprotocols, include well-known protocols Borda Veto. accomplishtask, define natural distribution instances well-defined coalitionalmanipulation problem, show junta distribution. Furthermore, presentmanipulation algorithm Greedy, prove usually succeeds respect. significance result stems fact sensitive scoring protocolsN P-hard manipulate, even number candidates constant. supportclaim junta distributions provide good benchmark proving Greedy alsousually succeeds respect uniform distribution.also show protocols susceptible certain setting manipulation,manipulator unsure others votes. result depends upon basicconjecture regarding junta distributions.paper proceeds follows: Section 2, outline important voting protocols,define manipulation problems shall discuss. Section 3, formally introducetools average case analysis: junta distributions, heuristic polynomial time,susceptibility manipulations. Section 4 prove main result: sensitive scoringprotocols susceptible coalitional manipulation candidates. Section 5,discuss case single manipulator unsure voters votes.Section 6 survey related work. Finally, Section 7, present conclusionsdirections future research.2. Preliminariesfirst describe common voting protocols formally define manipulationproblems shall deal. Next, introduce two useful lemmas probabilitytheory.2.1 Elections Manipulationselection consists set C = {c1 , c2 , . . .} candidates set V = {v1 , v2 , . . . , }voters, provide total order candidates. election also includes winnerdetermination function set possible combinations votes C. notethroughout paper number candidates constant, complexity resultsterms number voters.Different voting protocols distinguished winner determination functions.protocols shall discuss are:Scoring protocols: scoring protocol defined vector~ = h1 , 2 , . . . , |C| i,1 2 . . . |C| N {0}. candidate receives pointsvoter ranks ith place. Examples scoring protocols are:Plurality:~ = h1, 0, . . . , 0, 0i.Veto:~ = h1, 1, . . . , 1, 0i.Borda:~ = h|C| 1, |C| 2, . . . , 1, 0i.159fiProcaccia & RosenscheinCopeland: possible pair candidates, simulate election; candidate winspairwise election voters prefer opponent. candidate gets1 point pairwise election wins, 1 pairwise election loses.Maximin: candidates score pairwise election number votersprefer opponent. winner candidate whose minimum scorepairwise elections highest.Single Transferable Vote (STV): election proceeds rounds. round,candidates score number voters rank highest among remainingcandidates; candidate lowest score eliminated.Remark 1. assume tie-breaking always adversarial manipulator.2case weighted votes, voter weight k N naturally regarded k votersvote unanimously. paper, consider weights [0, 1]. equivalent, sinceset integer weights exponential n scaled rational weightssegment [0, 1], represented using O(n) bits.main results paper focus scoring protocols. shall require followingdefinition:ffDefinition 1. Let P scoring protocol parameters~ = 1 , 2 , . . . , |C| . sayP sensitive iff 1 2 . . . |C|1 > |C| = 0 (notice strict inequalityright).particular, Borda Veto sensitive scoring protocols.Remark 2. Generally, scoring protocol |C|1 > |C| , equivalent sensitivescoring protocol obtained subtracting |C| coordinate-by-coordinate basisvector~ . Moreover, observe protocol scoring protocolsensitive, |C| = 0, |C|1 = 0. case, three candidates equivalentplurality protocol, interesting formulations manipulation problemtractable even worst-case. Therefore, sufficient restrict resultssensitive scoring protocols.next consider types manipulations, state appropriate complexity results,introduce notations.Remark 3. discuss constructive cases, goal trying make candidatewin, opposed destructive manipulation, goal make candidate lose.Constructive manipulations always least hard (in worst-case sense)destructive counterparts, cases strictly harder (if one able determinewhether p made win, one also ask whether 1 candidatesmade win, thus making p lose).Definition 2. Individual-Manipulation (IM) problem, givenvotes, preferred candidate p. asked whether way manipulatorcast vote p wins.2. standard assumption, also made, example, work Conitzer Sandholm (2002),Conitzer, Lang, Sandholm (2003).160fiJunta DistributionsBartholdi Orlin (1991) show IM N P-complete Single Transferable Vote,provided number candidates unbounded. However, problem Pwell-known voting schemes, hence studied here.lions share paper, consider coalitional manipulation setting.scenario, set V voters partitioned two subsets: set V1 = {v1 , . . . , vn }manipulative, untruthful, voters; set V2 = {vn+1 , . . . , vn+N } nonmanipulative voters. set candidates C = {c1 , . . . , cm , p}. manipulators goalmake distinguished candidate p win election, coordinating rankingscandidates. CWM SCWM problems, manipulators full knowledgenonmanipulators votes.Definition 3. Coalitional-Weighted-Manipulation (CWM) problem,given set voters V = V1 ] V2 , set candidates C, weights voters,preferred candidate p C. addition, given votes voters V2 ,assume manipulators aware votes. asked whether possiblemanipulators V1 cast votes way makes preferred candidate pwin election.know (Conitzer & Sandholm, 2002; Conitzer et al., 2003) CWM N P-completeBorda, Veto, Single Transferable Vote, even 3 candidates, MaximinCopeland least 4 candidates.CWM version shall analyze, specifically tailored scoring protocols, slightly modified version whose analysis straightforward:Definition 4. Scoring-Coalitional-Weighted-Manipulation (SCWM) problem, given initial score S[c] candidate c, weights manipulatorsV1 , preferred candidate p. asked whether possible manipulatorsV1 cast votes way makes preferred candidate p win election.S[c] interpreted cs total score votes V2 . However,require exist combination votes actually induces S[c] c.Another setting shall shortly discuss (in Section 5) scenariomanipulators uncertain others votes.Definition 5. Uncertain-Votes-Weighted-Evaluation (UVWE) problem,given weight voter, distribution votes, candidate p,number r [0, 1]. asked whether probability p winning greater r.Definition 6. Uncertain-Votes-Weighted-Manipulation (UVWM) problem,given single manipulative voter weight, weights voters,distribution nonmanipulators votes, candidate p, number r,r [0, 1]. asked whether manipulator cast vote p winsprobability greater r.CWM N P-hard protocol, UVWE UVWM also N P-hardprotocol (Conitzer & Sandholm, 2002).make assumption given distributions nonmanipulators votessampled polynomial time. words, given distribution nonmanipulators votes, possible obtain specific instance polynomial time.161fiProcaccia & Rosenschein2.2 Probability Theory Toolsfollowing lemma much use later on. Informally, states averageindependent identically distributed (i.i.d.) random variables almost always closeexpectation.Lemma 1 (Chernoffs Bounds). (Alon & Spencer, 1992) Let X1 , . . . , Xt i.i.d. randomvariables Xi b E[Xi ] = . > 0, holds that:Pr[ 1tPt2t2(ba)2Pr[ 1tPt2t2(ba)2i=1 Xi + ] ei=1 Xi ] eAnother tool shall require Central Limit Theorem. purposes,implies probability sum random variables takes values smallsegment small.Lemma 2 (Central Limit Theorem). (Feller, 1968) Let Xt , . . . , Xt independent continuous random variables common density function, expected value variance2 . < b:"#PtZ bx2X1i=1Pr << be 2 dx.23. Approachsection lay mathematical foundations required average-case analysiscomplexity manipulations. definitions general possible;applied manipulation mechanism, merely manipulationvoting protocols.describe distribution instances problem collection distributions= {n }nN , n distribution instances x |x| = n. wishanalyze problems whose instances distributed respect distribution focuseshard-to-manipulate instances. Ideally, would like ensure one managesproduce algorithm usually manipulate instances according distinguisheddifficult distribution, algorithm would also usually succeed instancesdistributed respect reasonable distributions.Definition 7. Let = {n }nN distribution possible instances N Phard manipulation problem . junta distribution followingproperties:1. Hardness: restriction manipulation problem whose possibleinstances only:[{x : |x| = n n (x) > 0}.nNDeciding restricted problem still N P-hard.162fiJunta Distributions2. Balance: exist constant c > 1 N N n N :11Prxn [M (x) = yes] 1 .cc3. Dichotomy: n instances x |x| = n:n (x) 2polyn n (x) = 0.voting manipulation problem, also require following property:4. Symmetry: Let v nonmanipulative voter, let c1 , c2 6= p two candidates,let {1, . . . , m}. probability v ranks c1 ith placeprobability v ranks c2 ith place.coalitional manipulation problem, also require following property:5. Refinement: Let x instance |x| = n n (x) > 0; manipulatorsvoted identically, p would elected.name junta distribution comes idea distribution, relatively powerful difficult instances represent problem instances.Alternatively, intent problematic distributions (the family junta distributions) convincingly represent distributions respect average-caseanalysis.first three properties basic, relevant problems manipulatingmechanism. definition modular, additional properties may added topbasic three, case one wishes analyze mechanism voting protocol.exact choice properties extreme importance (and, mentioned above,may arguable). shall briefly explain choices. Hardness meant ensurejunta distribution contains hard instances. Balance guarantees trivial algorithmalways accepts (or always rejects) significant chance failure. dichotomy property helps preventing situations distribution gives (positive but) negligibleprobability hard instances, high probability several easy instances.examine properties specific manipulation problems. necessity symmetry best explained example. Consider CWM STV 3.One could design distribution p wins distinguished candidate losesfirst round. distribution could tailored satisfy conditions,misses many hard instances. context SCWM, interpret symmetryfollowing way: every two candidates c1 , c2 6= p R,Pr [S[c1 ] = y] = Pr [S[c2 ] = y].xnxnRefinement less important four properties, seems help concentrating probability hard instances. Observe refinement relevantcoalitional manipulation; believe analysis individual voting manipulationproblems, first four properties sufficient.163fiProcaccia & RosenscheinDefinition 8. (Trevisan, 2002) distributional problem pair hL, L decisionproblem distribution set {0, 1} possible inputs.Informally, algorithm heuristic polynomial time algorithm distributionalproblem runs polynomial time, fails small fraction inputs.give formal definition; definition inspired Trevisan (2002) (therename used somewhat different definition).Definition 9. Let manipulation problem let hM, distributional problem.1. algorithm deterministic heuristic polynomial time algorithm distributional manipulation problem hM, always runs polynomial time,exists polynomial p degree least 1 N N n N :Pr [A(x) 6= (x)]xn1.p(n)(1)2. Let probabilistic algorithm, uses random string s. probabilistic heuristic polynomial time algorithm distributional manipulation problemhM, always runs polynomial time, exists polynomial p degreeleast 1 N N n N :Prn [A(x) 6= (x)]x ,s1.p(n)(2)Probabilistic algorithms two potential sources failure: unfortunate choiceinput, unfortunate choice random string s. success failure deterministicalgorithms depends choice input.combine definitions introduced section attempt establishmechanism susceptible manipulation average case. following definition abuses notation bit: used refer manipulation itself,corresponding decision problem.Definition 10. say mechanism susceptible manipulationexists junta distribution , exists deterministic/probabilistic heuristicpolynomial time algorithm hM, i.4. Formulation, Proof, Justification Main ResultRecall (Conitzer & Sandholm, 2002; Conitzer et al., 2003) Borda Veto, CWMN P-hard, even 3 candidates. Since Borda Veto examples sensitive scoringprotocols, would like know resistant family protocols really respectcoalitional manipulation. section use methods previous sectionprove main result:Theorem 1. Let P sensitive scoring protocol. = O(1) P , candidatesC = {p, c1 , . . . , cm }, susceptible SCWM.164fiJunta DistributionsIntuitively, instances CWM (or SCWM) hard requirespecific partitioning voters V1 subsets, subset votes unanimously.instances rare reasonable distribution; insight ultimately yieldtheorem.following proposition generalizes Theorem 1 Conitzer Sandholm (2002)Theorem 2 Conitzer, Lang Sandholm (2003), justifies focus familysensitive scoring protocols. stronger version Proposition 1 independentlyproven Hemaspaandra Hemaspaandra (2005). Nevertheless, include proof,since required proving hardness property junta distribution shalldesign.Proposition 1. Let P sensitive scoring protocol. CWM P N P-hard, even3 candidates.Definition 11. Partition problem, given set integers {ki }i[t] , summing2K, asked whether subset integers sum K.well-known Partition N P-complete.Proof Proposition 1. reduce arbitrary instance Partition followingCWM instance. 3 candidates, a, b, p. V2 , K(41 22 ) 1voters voting b p, K(41 22 ) 1 voters voting b p. V1 ,every ki vote weight 2(1 + 2 )ki . Observe V2 , b get(K(41 22 ) 1)(1 + 2 ) points.Assume first partition exists. Let voters V1 one half partitionvote p b, let half vote p b a. vote, b(K(41 22 ) 1)(1 + 2 ) + 2K(1 + 2 )2 = (1 + 2 )(4K1 1)votes, p (1 + 2 )4K1 points; thus manipulation.Conversely, assume manipulation exists. Clearly must exist manipulationvoters V1 vote either p b p b a, manipulatorsgain anything placing p top scoring protocol. manipulation, p(1 + 2 )4K1 points, b already (K(41 22 ) 1)(1 + 2 ) pointsV2 . Therefore, b must gain less (22 K + 1)(1 + 2 ) points votersV1 . voter corresponding ki contributes 2(1 + 2 )2 ki points; followssum ki corresponding voters voting p b less K + 21 2 ,likewise voters voting p b a. Equivalently, sum K, sinceki integers 2 1. cases sum must K; hence,partition.Since instance CWM translated instance SCWM obviousway, have:Corollary 1. Let P sensitive scoring protocol. holds SCWM P N P-hard,even 3 candidates.165fiProcaccia & Rosenschein4.1 Junta DistributionLet w(v) denote weight voter v, let W denote total weight votesV1 ; P sensitive scoring protocol. denote |V1 | = n: size V1 sizeinstance.Consider distribution = {n }nN instances SCWM P , + 1candidates p, c1 , . . . , cm , n induced following sampling algorithm:1. Fix polynomial q = q(n).2. v : Randomly independently choose w(v) [0, 1] (up O(n) bits precision, i.e., intervals 1/2q(n) ).3. {1, . . . , m}: Randomly independently choose S[ci ] [(1 2 )W, 1 W ] (upO(n) bits precision).Remark 4. Although distribution fact discrete weights, example,uniformly distributed {0, 1/2q(n) , 2/2q(n) , 3/2q(n) , . . . , 1} treat continuoussake clarity.assume S[p] = 0, i.e., voters rank p last. assumptionrestriction. holds candidate c S[c] S[p], candidate c surely lose,since manipulators rank p first. Therefore, S[p] > 0, may simply normalizescores subtracting S[p] scores candidates. equivalentassumption.Remark 5. believe natural distribution respectcoalitional manipulation scoring protocols studied. Even one disagreesexact definition junta distribution, satisfy many reasonable conditionsone could produce.shall, course, (presently) prove distribution possesses propertiesjunta distribution.Proposition 2. Let P sensitive scoring protocol. junta distributionSCWM P C = {p, c1 , . . . , cm }, = O(1).Proof. first observe symmetry obviously satisfied, dichotomy holds Remark 4.proof hardness property relies reduction Partition Proposition 1. reduction generates instances x CWM P 3 candidates,W = 4(1 + 2 )K,S[a] = S[b]= (K(41 22 ) 1)(1 + 2 )= (1 2 /2)W (1 + 2 ),166fiJunta DistributionsK originates Partition instance. instances satisfy (1 2 )WS[a], S[b] 1 W . follows (x) > 0 (after scaling weights).3prove balance property. i, S[ci ] > (1 2 /m)W ,clearly manipulation, since least 2 W points given votersV1 undesirable candidates c1 , . . . , cm . happens probability least m1m .hand, consider situation i,S[ci ] < (1m2 12 )W ;m2(3)occurs probability least (m12 )m . Intuitively, manipulators could distributevotes way undesirable candidate ranked last exactly 1/mfraction votes, would successful manipulation: undesirable candidatewould gain additional m12 W points. Unfortunately, usuallycase, following condition sufficient successful manipulation (assuming condition (3) holds). Partition manipulators disjoint subsets P1 , . . . , Pm (w.l.o.g.size n/m), denote WPi total weight votes Pi . condition{1, . . . , m}:(1 1/m) 1/2 n/m WPi (1 + 1/m) 1/2 n/m.(4)condition sufficient, voters Pi rank ci last, fractionvotes V1 gives ci points most:(m 1)(1 + 1/m)m2 1= 2.(m 1)(1 + 1/m) + 1 1/m+m2Hence number points ci gains manipulators most:m2 1m2 1W2 W < 1 W S[ci ].2m2 + 2m2Furthermore, Lemma 1 fact expected total weight n/m votes2n1/2 n/m, probability condition (4) holds least 1 2e m3 . Sinceconstant, probability larger 1/2 large enough n.Finally, easily seen refinement property: manipulatorsrank p first candidate c second, p gets 1 W points, c gets 2 W + S[c] points.S[c] (1 2 )W , thus p surely loses.4.2 Heuristic Polynomial Time Algorithmpresent algorithm Greedy SCWM, given Algorithm 1. w~ denotesvector weights voters V1 = {v1 , . . . , vn }.3. seems reduction generalized larger number candidates. hard instancesones undesirable candidates two approximately (1 2 )W initial points,two problematic candidates approximately (1 /2)W points. instances positiveprobability .167fiProcaccia & RosenscheinAlgorithm 1 Decides SCWM1: procedure Greedy(S, w,~ p)2:c C3:S0 [c] S[c]4:end5:= 1 n6:Let j1 , j2 , . . . , jm s.t. l, Si1 [cjl1 ] Si1 [cjl ]7:Voter vi votes p cj1 cj2 . . . cjm8:l = 19:Si [cjl ] Si1 [cjl ] + w(ti )l+110:end11:Si [p] Si1 [p] + w(ti )112:end13:argmaxcC Sn [c] = {p}14:return true15:else16:return false17:end18: end procedure. Initialization. voters V1. Update score. p winsvoters V1 , according order, rank p first, rest candidates current score: candidate lowest current score ranked highest.Greedy accepts p wins election.algorithm, designed specifically scoring protocols, realization abstractgreedy algorithm: stage, voter vi ranks undesirable candidates orderminimizes highest score undesirable candidate obtains current vote.tie among several permutations, voter chooses optionsecond highest score low possible, etc. case, every manipulator always ranksp first.Remark 6. abstract scheme might also appropriate protocols MaximinCopeland. Similarly scoring protocols, two protocols manipulatorsalways better ranking p first. addition, abstract greedy algorithmapplied Maximin Copeland since result election based scorecandidate (unlike STV, example).Remark 7. Greedy considered generalization greedy algorithm givenBartholdi et al. (1989a).following lemmas, stage execution algorithm iterationloop.Lemma 3. exists stage i0 execution Greedy, two candidatesa, b 6= p,|Si0 [a] Si0 [b]| 2 ,(5)i0 holds |Si [a] Si [b]| 2 .168fiJunta DistributionsProof. proof induction i. base induction given equation (5).Assume |Si [a] Si [b]| 2 , without loss generality: Si [a] Si [b].algorithm, voter vi+1 ranks b higher a, therefore:Si+1 [b] Si+1 [a] 2 .(6)Since p always ranked first, weight vote 1, b gains 2points. Therefore:Si+1 [b] Si+1 [a] 2 .(7)Combining equations (6) (7) completes proof.Lemma 4. Let p 6= a, b C, suppose exists stage i0 Si0 [a]Si0 [b], stage i1 i0 Si1 [b] Si1 [a]. i1 holds|Si [a] Si [b]| 2 .Proof. Assume exists stage i0 Si0 [a] Si0 [b], stage i1 i0Si1 [b] Si1 [a]; w.l.o.g. i1 > i0 (otherwise stage i0 holds Si0 [b] = Si0 [a],finish Lemma 3). must stage i2 i0 i2 < i1Si2 [a] Si2 [b] Si2 +1 [b] Si2 +1 [a]. Since weight vote 1, b gains2 points voter vi2 +1 . Hence conditions Lemma 3 hold stage i2 ,implies i2 : |Si [a] Si [b]| 2 . particular, i1 i2 .Lemma 5. Let P sensitive scoring protocol, assume Greedy errs instanceSCWM P successful manipulation. {2, 3, . . . , m},subset candidates = {cj1 , . . . , cjd }, that:Xi=1(1 W S[cji ])d1X(i 2 ) Wi=1Xi=1m+2iX(1 W S[cji ]).(8)i=1Proof. right inequality, candidates, even ifPvoters V1 rank lastevery vote, total points distributed among W di=1 m+2i . inequalityhold, must candidate ci gains least 1 W S[ci ] pointsmanipulators, implying candidate least 1 W points. However, palso 1 W points, assumed successful manipulationcontradiction.left inequality, assume algorithm erred. stage i0 ,candidate cj0 total least 1 W points (w.l.o.g. one candidate passesthreshold simultaneously). Denote V10 = {v1 , v2 , . . . , vi0 }, let WV10 total weightvoters V10 . Voter vi0 rank cj0 last, since m+1 = 0, thus rankingcandidate last gives points. another candidate cj1 , that:Si0 1 [cj1 ] Si0 1 [cj0 ]. Lemma 4, Si0 [cj0 ] Si0 [cj1 ] 2 , thus Si0 [cj1 ] 1 W 2 .candidates always ranked last voters V10 , must anothercandidate cj2 ranked strictly higher voter V10 , w.l.o.g. higher cj1 .Therefore, Lemma 4 that: Si0 [cj1 ] Si0 [cj2 ] 2 , cj2 totalleast 1 W 22 points. inductively continuing reasoning, obtain subsetcandidates (possibly = m), always ranked last places voters169fiProcaccia & RosenscheinV10 , lth candidate holds that: Si0 [cjl ] 1 W (l 1)2 . total pointsgained lth candidate stage i0 must least 1 W (l 1)2 S[cjl ]. SincePtotal points distributed voters V10 last candidates WV10 di=1 m+2i ,have:X(1 W S[cji ])i=1d1X(i 2 ) WV10Xi=1m+2i Wi=1Xm+2i .i=1Lemma 6. Let SCWM sensitive scoring protocol P C = {p, c1 , . . . , cm },m=O(1). Greedy deterministic heuristic polynomial time algorithm hM, i.Proof. obvious given instance successful manipulation,greedy algorithm would indeed answer manipulation, since algorithmconstructive (it actually selects specific votes manipulators).wish bound probability manipulation algorithm erred.Lemma 5, necessary condition occur specified equation (8),equivalently:WX1 Wi=1Xi=1XXXd(d 1)m+2i2S[cji ] W1 Wm+2i .2i=1i=1(9)i=1case algorithm may err;Pdwhat probability equation (9) holding? Fixsubset size {2, . . . , m}.i=1 S[cji ] random variable takes values[d(1 2 )W, d1 W ]. conditioning values S[cji ], = 1, . . . , 1,Pprobability di=1 S[cji ] taking values interval [a, b] chancebaS[cjd ] taking value interval size b a, 1 W (, since S[cjd ]1 2 )Wnuniformly distributed. Lemma 1, W < n/4 probability (n) = e 8 .hand, W n/4, (9) holds probabilityd(d1)221 W (1 2 )W=d(d 1)2d(d 1)1=,2Wnp (n)polynomial pD . complete proof showing equation (1) holds:Pr [Greedy(x) 6= (x)] Pr[W n/4 (D C s.t. |D| 2 (9) holds)]xn+ Pr[W < n/4]X1DC:|D|2pD (n)+ (n)1poly nlast inequality follows assumption = O(1).Clearly, Theorem 1 directly follows.170fiJunta Distributions4.3 Algorithm 1 Uniform Distributionprevious subsection seen Algorithm 1 heuristic polynomial timealgorithm respect junta distribution . argued suggestsalgorithm also well respect distributions. subsectionsupport claim showing Algorithm 1 also heuristic polynomial timealgorithm respect uniform distribution instances SCWM.sake consistency previous results, shall consider uniform distributionvotes may produce unfeasible ballots. Nevertheless, equivalent resultsobtained feasible (discrete) distributions votes. so, subsection assumevoter vi V2 , |V2 | = N , awards candidate c C, including p, scoreindependently uniformly distributed [0, 1 ]. Further, assume votesunweighted; limit generality results, since use lower boundsdepend total weight manipulators V1 (where |V1 | = n)individual weights consequence.distinguish two cases results, depending rationumber nonmanipulators N number manipulators n:1. n/ N < 1/p(n) polynomial p degree least 1.2. n/ N > p(log n) polynomial p degree least 1.middle ground covered two cases remains open problem.tackle first case, require lower bound sorts probabilityinstance SCWM easy decide. Since manipulators V1 awardcandidate 1 n points, manipulators cannot make candidate c beat anothercandidate c0 S[c0 ] S[c] > 1 n. particular, every two candidates c c0 holds|S[c] S[c0 ]| > 1 n, manipulators cannot affect outcome election.Moreover, Algorithm 1 always decides instance correctly: S[p] < S[c]c, instance instance, case algorithm never errs;S[p] > S[c] c, instance yes instance, vote manipulatorssufficient make p win. obtained following Lemma:Lemma 7. Consider instance SCWM c, c0 C, |S[c] S[c0 ]| > 1 n.instance yes instance iff S[p] > S[c] candidates c 6= p,instance correctly decided Algorithm 1.Lemma, together Central Limit Theorem, yields first result.Proposition 3. Algorithm 1 heuristic polynomial time algorithmrespectuniform distribution instances SCWM satisfy n/ N < 1/p(n)polynomial p(n) degree least 1.Proof. Lemma 7, sufficient bound probability c, c0 C,|S[c] S[c0 ]| > 1 N .Pr[c, c0 C, |S[c] S[c0 ]| > 1 N ] = 1 Pr[c, c0 C s.t. 0 S[c] S[c0 ] 1 N ].171fiProcaccia & Rosenscheinunion bound:Pr[c, c0 C s.t. 0 S[c] S[c0 ] 1 n]XPr[0 S[c] S[c0 ] 1 n].c,c0 CFix c, c0 C, let Xi si [c] si [c0 ], si score given candidatevoter vi V2 , = n + 1, . . . , n + N . Xi i.i.d. continuous random variablesexpectation 0 constant variance 2 = 2 (1 )2 /12 = (1 )2 /6. Therefore, applyLemma 2:"#n+NXPr 0 S[c] S[c0 ] 1 n = Pr 0Xi 1 n"= Pr 0i=n+1Pn+Ni=n+1 XZ12 0Z 1 nN1 dxNNn1Nex221 nN#dx01 n=Nn=O.Nassumption regarding ratio manipulators nonmanipulators,inverse-polynomial n. Rolling back, obtain probability algorithm1correct least 1 (m + 1)m p(n), result follows fact = O(1).Moving second case, require following lemma:2Lemma 8. Let = 2(m+1), consider instance SCWM c, c0 C,0|S[c] S[c ]| < n. instance yes instance, correctly decidedAlgorithm 1.Proof. Obviously, sufficient prove algorithm constructively finds successfulvote makes p win. Let C 0 C \ {p} set undesirable candidatesmaximal score among candidates C \ {p} stage executionalgorithm. algorithm, stage candidate C 0 ranked lastvoter V1 , i.e., given 0 points; candidates C 0 receive stage2 points. Therefore, total number points candidates C 0 receivemanipulators (d 1)2 n, |C 0 | = d. Consequently, [c] scorecandidate c algorithm terminates,XX[c]S[c] + (d 1)2 n.cC 0cC 0172fiJunta DistributionsLet c0 = argmaxcC 0 S[c], c1 = argmaxcC 0 [c]. Lemma 4, algorithmterminates holds scores candidates C 0 within 2 one another.Therefore:XX[c1 ]S[c] + (d 1)2 n[c] dS [c0 ] + (d 1)2 n (d 1)(S [c1 ] 2 ).c1 6=cC 0cC 0algebraic manipulations, obtain:d1d1[c1 ] S[c0 ] + n2 +2 S[c0 ] + n2 +2 .m+1m+1Now, that:[p][c1 ]2 n +2(S[p] + 1 n)+m+1m+121 nn2 n22(m + 1)m+1m+12n22(m + 1)m+1> 0.S[c0 ]second transition follows assumption S[p] S[c0 ]n, third transitionfact 1 2 , last transition holds large enough n.Proposition 4. Algorithm 1 heuristic polynomial time algorithmrespectuniform distribution instances SCWM satisfy n/ N > p(log n)polynomial p degree least 1.Proof. Let =least:22(m+1) .Lemma 8, probability algorithm errPr[c, c0 C, |S[c] S[c0 ]| < n] = 1 Pr[c, c0 C s.t. S[c] S[c0 ] > n].union bound:Pr[c, c0 C s.t. S[c] S[c0 ] > n]XPr[S[c] S[c0 ] > n].c,c0 Cbefore, fix c, c0 C, let Xi si [c] si [c0 ], si score givencandidate voter vi . Xi i.i.d. random variables expectation 0, takevalues [1 , 1 ]. Applying Lemma 1 variables, obtain:2n+N( n )n1 X0 n22N N 20(21 )Xi E[Xi ] + ] e= e N ,Pr[S[c] S[c ] n] = Pr[NNi=n+10 constant. result follows fact constantassumption regarding relation n N .173fiProcaccia & Rosenschein5. Case Uncertainty Votesfar dealt setting entire coalition manipulators tryinginfluence outcome election, using complete knowledge nonmanipulatorsvotes. section short aside, discuss setting singlemanipulator uncertainty others votes. shall prove:Theorem 2. Let P voting protocol exists junta distribution Pinstances UVWM P , following property: r uniformly distributed[0, 1]. P , candidates C = {p, c1 , . . . , cm }, = O(1), susceptible UVWM.Recall UVWM, ask whether manipulator cast vote pwins probability greater r. existence junta distribution r uniformly distributed weak requirement (it even quite natural r uniformlydistributed). fact, following claim likely true:Conjecture 1. Let P voting protocol UVWM N P-hard. existsjunta distribution P instances UVWM P , r uniformly distributed[0, 1].conjecture indeed true, voting protocols susceptibleUVWM. reason conjecture true respect definition juntadistributions, perhaps definition restrictive modified accordingly. also remark similar results derived destructive manipulationsanalogous proofs.prove Theorem 2, first present helpful procedure, decides UVWE. w~denotes vector given weights, given distribution votes.number voters |V | = n.Sample(C = {p, c1 , . . . , cm }, w,~ , r)1: count = 02: = 1 n33:Sample distribution votes4:Calculate result election using sampled votes5:p6:count = count + 17:end8: end9: count/n3 > r10:return 111: else12:return 013: endSample samples given distribution votes n3 times, calculates winnerelection time. p r-fraction elections procedureaccepts, otherwise rejects.174fiJunta DistributionsLemma 9. Let P voting protocol, E UVWE P C = {p, c1 , . . . , cm }.Furthermore, let distribution instances E, r uniformly distributed[0, 1]. exists N n N :Pr [Sample(x) 6= E(x)]xn1.polyn3Proof. Let {Xi }ni=1 random variables, Xi = 1 p ith iterationloop, Xi = 0 otherwise. Let r0 probability p wins giveninstance. Lemma 1 union bound:fifi3fi Xfifi1 nfi3 11Pr fifi 3Xi r0 fifi 2e2n n2 = 2e2n .finfi ni=1deduce |r r0 | > n1 , Sample fail exponentially small probability.assumption r uniformly distributed, probability |r r0 | n12/n. Thus, union bound holds that:1100Pr [Sample(x) 6= E(x)] Pr |r r |+ Pr |r r | > Sample(x) 6= E(x)xnnn2/n + 2e2n1.polynpresent algorithm decides UVWM. Here, w~ denotes weightsvoters including manipulator, given distribution nonmanipulatorsvotes.Sample-and-manipulate(C = {p, c1 , . . . , cm }, w,~ , r)1: ans = 02: = 1 (m + 1)!3:= next permutation + 1 candidates4:= manipulator always votes , others votes distributed respect5:Sample(C, w,~ , r) = 16:ans = 17:end8: end9: return ansGiven instance UVWM, Sample-and-Manipulate generates (m+1)! instancesUVWE problem, one manipulators possible votes, executes Sampleinstance. Sample-and-Manipulate accepts Sample accepts oneinstances.175fiProcaccia & RosenscheinLemma 10. Let P voting protocol, UVWM P C = {p, c1 , . . . , cm },= O(1). Furthermore, let distribution instances UVWM, runiformly distributed [0, 1]. Sample-and-Manipulate probabilistic heuristicpolynomial time algorithm hM, i.Proof. independent call Sample, chance failure inverse-polynomial.applying union bound probability Sample failing1(m + 1)! invocations (m + 1)! polyn, still inverse-polynomial sinceconstant. lemma follows fact manipulationpermutation candidates, manipulator votes accordingpermutation, chance p winning greater r.Notice Sample-and-Manipulate indeed polynomial fact = O(1),assumed given distribution votes sampled polynomialtime.6. Related WorkComputational aspects voting long investigated. pivotal issue problemwinner-determination: voting protocols designed satisfy theoretical desiderata mayquite complex. Consequently, deciding election governed protocols maycomputationally hard problem (Bartholdi, Tovey, & Trick, 1989b). Another concernstrategic behavior part officials conducting election, may addremove voters candidates slate. computational complexity strategicallycontrolling election analyzed Bartholdi, Tovey Trick (1992).said, main issue respect strategic behavior voting alwaysmanipulation voters. growing body work deals worst-casecomplexity manipulating elections. seminal paper Bartholdi, ToveyTrick (1989a); authors suggested, first time, computational complexityobstacle strategic voters must overcome. Indeed, although shownmany voting protocols efficiently manipulated, nevertheless provenvoting protocol, namely second-order Copeland, N P-hard manipulate.Bartholdi Orlin (1991) demonstrated prominent Single Transferable Vote(STV) protocol N P-hard manipulate.Even voting protocols easy manipulate, difficulty artificially introduced adding preround (Conitzer & Sandholm, 2003); candidates paired,pairing two candidates, candidate loses pairwise electiontwo eliminated. Plurality, Borda Maximin shown hard manipulateaugmented preround. detail, protocols N P-hard manipulate scheduling preround precedes voting, #P-hard voting precedesscheduling, PSPACE-hard voting scheduling interleaved. ElkindLipmaa (2005a) induce hardness manipulation using general approach. Hybridvoting protocols hard manipulate constructed composing several baseprotocols; base protocols may individually easy manipulate.Another case manipulation may hard, worst-case, electionmultiple winners instead single winner, case elections parliament176fiJunta Distributionsassembly. Procaccia, Rosenschein, Zohar (2007) demonstrate manipulationCumulative voting, major protocol multi-winner elections, N P-hard.coalitional manipulation problem, focus paper, firstinvestigated Conitzer Sandholm (2002, 2003). setting, computationalproblem made difficult fact numerous manipulators must coordinatestrategy (and additionally, introduction weighted voting). hardnessresults abovementioned papers relied number candidates unbounded,Conitzer Sandholm present hardness results coalitional manipulation settingconstant number candidates, respect several central voting protocols.Elkind Lipmaa (2005b) extend preround approach presented ConitzerSandholm (2003) coalitional manipulation setting. context, provideearly impossibility result regarding average-case complexity manipulations:authors present family preference profiles manipulator always improveoutcome voting strategically, regardless preround schedule. result appliesseeking make manipulation hard adding preround. Further, one wouldusually expect distributions instances coalitional manipulation problemgive family preference profiles significant probability, extremely restricted.recent result regarding average-case complexity manipulation, complementsown, presented Conitzer Sandholm (2006). authors put forward twoproperties instances coalitional manipulation problem, demonstrateinstance satisfies properties easy manipulate. first propertyinstance satisfy weaker form monotonicity property seems natural;second property manipulators able make one exactly two candidates winelection property much harder accept. order justify secondproperty, authors show many voting protocols property usually holds,respect specific family distributions.result two main shortcomings compared ours. First, arguments favorsecond property mentioned empirical rather analytical; second,family distributions considered special sense casehere. words, family distributions question priori especially hardmanipulate. hand, result advantages: unlike ours,depend number candidates constant (although experimentsnumber candidates manipulators extremely small compared numbervoters), (arguably) require significant restrictions voting rule.7. Conclusionsdate, results complexity manipulation considered worst case. Although better nothing, results weak guarantee resistance manipulation.truly worthy goal design voting protocol hard manipulate averagecase plausible social choice point view, far attemptsfailed.Motivated this, presented specific manipulation setting worst-casehard average-case tractable. first prepared ground average-caseanalysis borrowing several concepts existing theory introducing several177fiProcaccia & Rosenscheinnew ideas. key approach junta distributions, presumably concentratehard instances coalitional manipulation problem. considered votingprotocol susceptible coalitional manipulation algorithm almostalways correctly decides problem, instances distributed respectjunta distribution.main result states sensitive scoring protocols susceptible coalitional manipulation number candidates constant, although hard manipulateeven number candidates constant.7.1 Discussionresults, first foremost, suggest worst-case hardness indeed strongenough barrier manipulation. motivates research regarding averagecase complexity manipulations, expense future investigations worst-casecomplexity.Moreover, view, main result provides evidence voting ruleaverage-case hard manipulate exist. least, suggestsscoring protocols cannot form basis protocol usually strategy resistant.Nevertheless, negative result circumvented many ways.First, circumvented via voting protocol. Scoring protocols amongeasiest voting systems manipulate, structure quite simpleconcisely represented. protocols, say STV, inherently harder deal with. fact,recall STV worst-case hard manipulate one manipulator (butunbounded number candidates) (Bartholdi & Orlin, 1991), whereas scoring protocolscertainly not.Second, circumvented via setting. results hold one contemplates coalitional manipulation constant number candidates. constant numbercandidates known guarantee worst-case hardness, may case allowing large number candidates would make difference respect average-caseanalysis.Third, circumvented via distribution. Traditional average-case complexitytheory deals hardness distributional problems; words, specific distributionconsidered. Junta distributions chosen way one usuallymanipulated algorithm, presumably algorithm would successfuldistributions. view supported results Section 4.3, pointstrong theoretical guarantees, may certainly truespecific distribution instances manipulation problem average-casehard manipulate, even scoring protocol considered.Section 4.3 deserves aside. lemmas established show that, respectuniform distribution, even completely trivial algorithm usually decidecoalitional manipulation problem: number manipulators small (lesssquare root number voters), manipulators rarely influence outcomeelection; therefore, p elected nonmanipulators well, usuallycorrect answer yes, not, usually correct answer no. numbermanipulators large, usually correct answer yes manipulation.178fiJunta DistributionsRecent preliminary results direction imply true several familiesvoting rules, large variety distributions. important notesimple algorithm would work well respect junta distribution .7.2 Future Researchview, central contribution paper establishes frameworkused study average-case complexity manipulations protocols,even generally, mechanisms. Indeed, voting general methodpreference aggregation, issues also relevant one considers mechanismsspecific settings. One mechanism aware, whose manipulationN P-hard, presented Bachrach Rosenschein (2006). definitions Section 3sufficiently general deal different mechanisms preference aggregation.still room debate exact definition junta distribution. mayalso case unconvincing distributions satisfy (current)conditions junta distribution. might prove especially fruitful show heuristicpolynomial time algorithm respect junta distribution guaranteedproperty respect easy distributions, uniform distribution.issue great importance coming natural criteria decide manipulation problem hard average-case. traditional definition average-casecompleteness difficult work general; satisfying definitionapplies specifically case manipulations? subject fully understood, understanding surely shed light great mystery: votingprotocols usually hard manipulate?Acknowledgmentswork partially supported grant #898/05 Israel Science Foundation.ReferencesAlon, N., & Spencer, J. H. (1992). Probabilistic Method. Wiley Sons.Bachrach, Y., & Rosenschein, J. S. (2006). Achieving allocatively-efficient stronglybudget-balanced mechanisms network flow domain bounded-rational agents.Seventh International Workshop Agent-Mediated Electronic Commerce:Designing Mechanisms Systems, Utrecht, Netherlands (AMEC 2005), No.3937 Lecture Notes Artificial Intelligence, pp. 7184. Springer-Verlag, Berlin.Bartholdi, J., & Orlin, J. (1991). Single transferable vote resists strategic voting. SocialChoice Welfare, 8, 341354.Bartholdi, J., Tovey, C. A., & Trick, M. A. (1989a). computational difficulty manipulating election. Social Choice Welfare, 6, 227241.Bartholdi, J., Tovey, C. A., & Trick, M. A. (1989b). Voting schemesdifficult tell election. Social Choice Welfare, 6, 157165.179fiProcaccia & RosenscheinBartholdi, J., Tovey, C. A., & Trick, M. A. (1992). hard control election.Mathematical Computer Modelling, 16, 2740.Conitzer, V., Lang, J., & Sandholm, T. (2003). many candidates needed makeelections hard manipulate?. Proceedings International ConferenceTheoretical Aspects Reasoning Knowledge, pp. 201214.Conitzer, V., & Sandholm, T. (2002). Complexity manipulating elections candidates. Proceedings National Conference Artificial Intelligence, pp. 314319.Conitzer, V., & Sandholm, T. (2003). Universal voting protocol tweaks make manipulation hard. Proceedings International Joint Conference Artificial Intelligence, pp. 781788.Conitzer, V., & Sandholm, T. (2006). Nonexistence voting rules usually hardmanipulate. Proceedings Twenty-First National Conference ArtificialIntelligence, pp. 627634.Elkind, E., & Lipmaa, H. (2005a). Hybrid voting protocols hardness manipulation.16th Annual International Symposium Algorithms Computation, LectureNotes Computer Science, pp. 206215. Springer-Verlag.Elkind, E., & Lipmaa, H. (2005b). Small coalitions cannot manipulate voting. International Conference Financial Cryptography, Lecture Notes Computer Science.Springer-Verlag.Ephrati, E., & Rosenschein, J. S. (1997). heuristic technique multiagent planning.Annals Mathematics Artificial Intelligence, 20, 1367.Feller, W. (1968). Introduction Probability Theory Applications (3rd edition).,Vol. 1, p. 254. John Wiley.Ghosh, S., Mundhe, M., Hernandez, K., & Sen, S. (1999). Voting movies: anatomyrecommender system. Proceedings Third Annual Conference Autonomous Agents, pp. 434435.Gibbard, A. (1973). Manipulation voting schemes. Econometrica, 41, 587602.Haynes, T., Sen, S., Arora, N., & Nadella, R. (1997). automated meeting scheduling system utilizes user preferences. Proceedings First International ConferenceAutonomous Agents, pp. 308315.Hemaspaandra, E., & Hemaspaandra, L. A. (2005). Dichotomy voting systems. University Rochester Department Computer Science Technical Report 861.Procaccia, A. D., Rosenschein, J. S., & Zohar, A. (2007). Multi-winner elections: Complexitymanipulation, control winner-determination. Twentieth InternationalJoint Conference Artificial Intelligence (IJCAI 2007), Hyderabad, India. appear.Satterthwaite, M. (1975). Strategy-proofness Arrows conditions: Existence correspondence theorems voting procedures social welfare functions. JournalEconomic Theory, 10, 187217.180fiJunta DistributionsTrevisan, L. (2002). Lecture notes computational complexity. Availablehttp://www.cs.berkeley.edu/luca/notes/complexitynotes02.pdf. Lecture 12.181fiJournal Artificial Intelligence Research 28 (2007) 393-429Submitted 6/06; published 3/07Bin Completion Algorithms Multicontainer Packing,Knapsack, Covering ProblemsAlex S. Fukunagafukunaga@aig.jpl.nasa.govJet Propulsion LaboratoryCalifornia Institute Technology4800 Oak Grove DrivePasadena, CA 91108 USARichard E. Korfkorf@cs.ucla.eduComputer Science DepartmentUniversity California, Los AngelesLos Angeles, CA 90095AbstractMany combinatorial optimization problems bin packing multiple knapsack problems involve assigning set discrete objects multiple containers. problems used model task resource allocation problems multi-agent systemsdistributed systms, also found subproblems scheduling problems.propose bin completion, branch-and-bound strategy one-dimensional, multicontainerpacking problems. Bin completion combines bin-oriented search space powerfuldominance criterion enables us prune much space. performancebasic bin completion framework enhanced using number extensions, including nogood-based pruning techniques allow exploitation dominancecriterion. Bin completion applied four problems: multiple knapsack, bin covering,min-cost covering, bin packing. show bin completion algorithms yieldnew, state-of-the-art results multiple knapsack, bin covering, min-cost covering problems, outperforming previous algorithms several orders magnituderespect runtime classes hard, random problem instances. bin packing problem, demonstrate significant improvements compared previous results,show bin completion competitive current state-of-the-art cutting-stockbased approaches.1. IntroductionMany NP-hard problems involve assigning set discrete objects multiple containers. one class problems, objective pack items set containerswithout exceeding containers capacities. related class problems, goalcover set containers filling least minimal level (quota) using setitems. containers items modeled one-dimensional objects(possibly associated cost/value function), refer collectively problemsone-dimensional, multicontainer packing covering problems, simply multicontainerpacking problems.One example multicontainer packing problem bin packing problem: Givenset items (numbers), fixed bin capacity, assign item bin sumitems assigned bin exceed bin capacity, number binsc2007AI Access Foundation. rights reserved.fiFukunaga & Korfused minimized. example, given set items 6, 12, 15, 40, 43, 82, bincapacity 100, assign 6, 12, 82 one bin, 15, 40, 43, another,total two bins. optimal solution instance, since sumitems, 198, greater 100, hence least two bins required.Multicontainer packing problems ubiquitous. model many important operations research problems cargo loading transport, also model many artificialintelligence applications, allocation rationing resources tasks amonggroup agents. Multicontainer packing problems often found embedded subproblems complex, real-world combinatorial optimization problems. examplemany constraint programming problems contain bin packing knapsack constraintssubproblems (e.g., Shaw, 2004). constraints core many schedulingresource allocation problems.paper, propose bin completion, new algorithm optimally solving multicontainer packing problems. begin Section 1.1 overview four representative, strongly NP-complete, multicontainer problems: (1) bin packing problem, (2)multiple knapsack problem, (3) bin covering problem, (4) min-cost coveringproblem.Section 2, begin describing standard, item-oriented branch-and-boundframework problems. traditional approach, items considered onetime. node search corresponds decision regarding assignmentitem non-full container. Then, describe bin completion, alternative, binoriented branch-and-bound strategy two key features: (1) nodes search treecorrespond complete assignments items single bin, (2) dominance criteriaassignments items bins used prune search. Section 3 describesextensions basic bin completion framework improve search efficiency, wellruntime memory usage node.Sections 4-7, explore application bin completion framework fourspecific, one-dimensional multicontainer packing problems. problem, reviewprevious work algorithms optimally solve problem, detail bin completionalgorithm problem, provide empirical comparison previous state-ofthe-art algorithm. apply bin completion multiple knapsack problem Section4, show bin completion solver significantly outperforms Mulknap (Pisinger,1999), previous state-of-the-art algorithm. min-cost covering problem (also calledliquid loading problem) first problem Christofides, Mingozzi,Toth (1979) proposed early variant bin completion approach. Section 5,show new bin completion algorithm significantly outperforms earlier algorithmChristofides et al. Section 6, apply bin completion bin covering problem(also known dual bin packing problem). show bin completion algorithmsignificantly outperforms previous state-of-the-art algorithm Labbe, Laporte,Martello (1995). Section 7, apply extended bin completion algorithmbin packing problem. Although initial results promising (Korf, 2002, 2003),best bin completion solver competitive current state art,recent branch-and-price approach based cutting-stock problem formulation. Section 8concludes discussion directions future work.394fiBin Completion Algorithms Multicontainer Problems1.1 One-Dimensional, Multicontainer Packing Problemsconsider class multicontainer packing problems: Given set items, mustassigned one containers (bins), item assigned onecontainer. item j weight wj associated it. Depending problem,item j may also profit cost pj associated it. assume itemweights containers one-dimensional. real-world applications,continuous call double auctions (Kalagnanam, Davenport, & Lee, 2001), modelapplied directly. applications, lot-to-order matching problem, onedimensional model approximation (Carlyle, Knutson, & Fowler, 2001). considertwo types containers: (1) Containers capacity, sum weightsitems assigned container cannot exceed capacity, (2) containers quota,sum weights items assigned container must least largequota. single container, well-known 0-1 knapsackproblem. See recent text Kellerer, Pferschy, Pisinger (2004) overviewwork 0-1 Knapsack problem variants. paper, focus fourone-dimensional, multicontainer packing problems (1) bin packing, (2) multiple knapsack,(3) bin covering, (4) min-cost covering.1.1.1 Bin Packing Problembin packing problem, goal pack n items weights w1 , ..., wn binscapacity c items packed fewest number bins, sumweights items bin greater capacity. Classical applications binpacking include classic vehicle/container loading problem (Eilon & Christofides, 1971),well memory/storage allocation data. minimal number agents requiredcarry set tasks multiagent planning problem modeled bin packingproblem.formally, bin packing problem formulated integer program:minimizenXyisubject to:i=1nXwj xij cyi ,= 1, ..., n(2)j=1nXxij 1,j = 1, ..., n(3)xij {0, 1}= 1, ..., n, j = 1, ..., n(4)yi {0, 1},= 1, ..., n(5)(1)i=1yi represents whether ith bin used (yi = 1 items assignedbin i, yi = 0 otherwise), xij = 1 item j assigned bin i, 0 otherwise.Constraint 2 ensures capacity violated bin instantiated,constraint 3 ensures items assigned one bin.395fiFukunaga & Korfstandard formulation, assume bins capacity. However,assumption restrictive, since instances bins different capacities (nonuniform bins) modeled introducing additional items constraints.1.1.2 0-1 Multiple Knapsack ProblemConsider containers capacities c1 , ..., cm , set n items, itemweight w1 , ..., wn profit p1 , ..., pn . Packing items containers maximizetotal profit items, sum item weights containerexceed containers capacity, item assigned one container0-1 Multiple Knapsack Problem, MKP.MKP natural generalization 0-1 Knapsack Problemcontainers capacities c1 , c2 , ...cm . Let binary decision variable xij 1 item jplaced container i, 0 otherwise. 0-1 Multiple Knapsack Problemformulated as:maximizenXXsubject to:i=1 j=1nXwj xij ci ,= 1, ...,(7)j=1Xxij 1,j = 1, ..., n(8)xij {0, 1}i, j.(9)pj xij(6)i=1Constraint 7 encodes capacity constraint container, constraint 8 ensuresitem assigned one container.MKP numerous applications, including task allocation among group autonomous agents order maximize total utility tasks executed (Fukunaga,2005), continuous double-call auctions (Kalagnanam et al., 2001), multiprocessor scheduling (Labbe, Laporte, & Martello, 2003), vehicle/container loading (Eilon & Christofides,1971), assignment files storage devices order maximize numberfiles stored fastest storage devices (Labbe et al., 2003). special case MKPstudied right Multiple Subset-Sum Problem (MSSP),profits items equal weights, i.e., pj = wj j (e.g., Caprara,Kellerer, & Pferschy, 2000b 2000a,2003). application MSSP marble cuttingproblem, given marble slabs, problem decide cut slabssub-slabs (each sub-slab processed product) order minimizetotal amount wasted marble.1.1.3 Bin CoveringSuppose n items weights w1 , ..., wn , infinite supply identical containers quota q. bin covering problem, also known dual bin packing problempack items containers number containers contain setsitems whose sums least q maximized. is, goal distribute, ration396fiBin Completion Algorithms Multicontainer Problemsitems among many containers possible, given containers specifiedquota must satisfied. Note total weight items placed containergreater q (we assume infinite capacity, although assigning additional itembin whose quota already satisfies clearly suboptimal).formally, bin covering problem formulated integer program:maximizenXyisubject to:i=1nXwj xij qyi ,= 1, ..., n(11)j=1nXxij 1,j = 1, ..., n(12)xij {0, 1}= 1, ..., n, j = 1, ..., n(13)yi {0, 1},= 1, ..., n(14)(10)i=1yi represents whether quota ith bin satisfied (yi = 1) (yi = 0),xij = 1 item j assigned bin i, 0 otherwise. Constraint 11 ensuresquota satisfied bin instantiated, constraint 12 ensures itemsassigned one bin.Bin covering natural model resource task allocation among multiple agentsgoal maximize number agents achieve quota. alsomodels industrial problems as: (1) packing peach slices canscontains least advertised net weight peaches, (2) breaking monopoliessmaller companies, large enough viable (Assmann, Johnson, Kleitman,& Leung, 1984). Another application bin covering lot-to-order matching problemsemiconductor industry, problem assign fabrication wafer lotscustomer orders various sizes (Carlyle et al., 2001).1.1.4 Min-Cost Covering Problem (Liquid Loading Problem)define Min-Cost Covering Problem (MCCP) follows. Given set binsquotas {q1 , ..., qm }, set n items weights w1 , ..., wn costs p1 , ..., pn , assignsubset items bin (1) item assigned onebin, (2) sum weights items assigned bin least bins quota(i.e., bin covered, bin covering), (3) total cost itemsassigned bin minimized. problem also called liquid loading problem(Christofides et al., 1979), originally motivated following application:Consider disposal transportation different liquids (e.g., chemicals) cannotmixed. given n tanks various sizes, associated cost,problem load liquids subset tanks minimize totalcost. Note here, liquids correspond containers, tanks corresponditems.applications MCCP include: (1) storage different varieties graindifferent silos, different types grains cannot mixed, (2) storage food types397fiFukunaga & Korffreezer compartments, (3) trucking firm distributes trucks (of different sizes)among customers mixing different customers orders truck, (4) storageinformation storage devices (e.g., sensitive customer data must segregatedphysical filing cabinets file servers). closely related problem segregatedstorage problem (Neebe, 1987; Evans & Tsubakitani, 1993).formally, MCCP formulated integer program:minimizenXXsubject to:i=1 j=1nXpj xij(15)wj xij qi ,= 1, ...,(16)xij 1,j = 1, ..., n(17)xij {0, 1}i, j.(18)j=1Xi=1binary variable xij represents whether item j assigned container i. Constraint16 ensures quotas bins satisfied, constraint 17 ensuresitem assigned one bin.1.1.5 taxonomy multicontainer problemsTable 1 summarizes two key, defining dimensions four multicontainer problemsstudy paper. One key dimension whether problem involves packing setitems containers container capacity exceeded (packing), whetherproblem requires satisfying quota associated container (covering). Anotherkey dimension whether items must assigned bins, whethersubset items selected assigned bins. third dimension (not showntable) set item attributes (e.g., weight, profit/cost). Bin packing bin coveringsingle-attribute problems (items weight only), multiple knapsackmin-cost covering problems two-attribute problems (items weight profit/cost).focus bin packing, bin covering, MKP, MCCP problemsbelieve sense basic multicontainer problems. Manycombinatorial optimization problems viewed extensions problemsadditional constraints. example, generalized assignment problem consideredgeneralization MKP complex profit function.packingcoveringassign items binsbin packingbin coveringassign subset items binsmultiple knapsackmin-cost coveringTable 1: Characterizing multicontainer problems.398fiBin Completion Algorithms Multicontainer Problems2. Bin Completionmultiple-knapsack problem, bin covering problem, min-cost covering problem, binpacking problem strongly NP-complete (proofs reduction 3-PARTITION,e.g. Martello & Toth, 1990; Fukunaga, 2005). Thus, problems cannot solvedpolynomial pseudo-polynomial time algorithm unless P = N P , state-of-theart approach optimally solving problems branch-and-bound. contrast,single-container 0-1 Knapsack problem subset sum problem weakly NPcomplete, solved pseudopolynomial time using dynamic programming algorithms (Kellerer et al., 2004).section, begin describing standard item-oriented branch-and-bound approach solving multi-container problems. describe bin completion, alternate,bin-oriented strategy. clarity simplicity exposition, detail algorithmscontext bin packing problem.2.1 Item-Oriented Branch-and-Boundstandard approach solving multi-container problems item-oriented branch-andbound strategy. Suppose bin packing problem instance bin capacity100, 7 items weights 83, 42, 41, 40, 12, 11, 5. perform branchand-bound procedure search space assignments items bins, nodebranch-and-bound search tree corresponds item, branches corresponddecisions bin place item. Assuming consider itemsorder non-increasing weight, first place 83 bin, resulting setbins {(83)}. Next, consider 42. put bin 83, resulting{(83, 42)}, exceed bin capacity. possibility put 42new bin, resulting {(83), (42)}. feasible choice node. Next,41 assigned bin. three possible places assign 41: (a)bin 83, resulting {(83, 41), (42)}, (b) bin 42, resulting{(83), (42, 41)}, (c) new bin own, resulting {(83), (42), (41)}. Option (a)exceeds bin capacity first bin infeasible. Options (b) (c) feasiblechoices, branch item assignment, resulting two subproblems,search procedure recursively applied. Figure 1 illustrates portion search space(we show feasible nodes).branch-and-bound procedure item-oriented node, decideupon placement particular item. Upper lower bounding techniques specificproblem applied make basic depth-first strategy efficient. Itemoriented branch-and-bound appears natural strategy multicontainerproblems. seminal paper Eilon Christofides (1971), first paperaddress optimal solutions multi-container problems, proposed item-oriented branchand-bound strategy. work literature algorithms optimally solvingmulti-container problems relied upon item-oriented strategy.399fiFukunaga & Korf(83)(83)(42)(83)(42)(41)(83) (42,41)(83)(42,41) (40)(83 12) (42 41) (40)(83)(42 41 12)(40)(83)(42 41)(40 12)(83)(42)(41,40)(83)(42)(41)(40)......(83)(42 41)(40)(12)Figure 1: Partial, item-oriented search space bin packing instance capacity 100items {83,42,41,40,12,11,5}. node corresponds decisionexisting new bin item assigned to. Items considered nonincreasingorder weight.2.2 Bin Completion, Bin-Oriented Branch-and-Bound Strategyalternate problem space solving multi-container problems bin-oriented,nodes correspond decisions remaining item(s) assign current bin.bin assignment B = (item1 , ..., itemk ) set items assignedgiven bin. Thus, valid solution bin packing problem instance consists setbin assignments, item appears exactly one bin assignment. bin assignmentfeasible respect given bin capacity c sum weights exceedc. Otherwise, bin assignment infeasible. definition feasibilityMKP; however, bin covering MCCP, define bin assignment feasiblerespect bin quota q sum weights least q. Given set kremaining items, say bin assignment maximal respect capacity cfeasible, adding k remaining items would make infeasible. Similarly,bin covering MCCP, feasible bin assignment minimal respect quotaq removing item would make infeasible. brevity, rest paper,omit qualification respect given capacity/quota unnecessary(for example, bin packing bin covering, bins capacity/quotaqualification necessary).Bin completion (for bin packing) bin-oriented branch-and-bound algorithmnode represents maximal, feasible bin assignment. Rather assigning items onetime bins, bin completion branches different maximal, feasible bin assignments.nodes given level bin completion search tree represent different maximal,400fiBin Completion Algorithms Multicontainer Problems2(83,12,5)(42,41)(42,40)(83,11,5)(42,11)(40,11)Figure 2: Bin-completion search space bin packing instance capacity 100items {83,42,41,40,12,11,5}. node represents maximal, feasible bin assignment given bin. Bin assignments shown strikethrough, e.g., (83,11,5),pruned due dominance criterion described Section 2.3.feasible bin assignments include largest remaining item. nodes nextlevel represent different maximal, feasible bin assignments include largest remainingitem, etc. reason restrict sibling bin assignments bin packing searchtree largest remaining number common eliminate symmetriesintroduced fact bins capacity bin packing fomulation.Thus, depth branch bin completion search tree corresponds numberbins partial solution depth. Figure 2 shows example bin completionsearch tree.2.3 Dominance Criteria Bin Assignmentskey making bin completion efficient use dominance criterion feasiblebin assignments requires us consider small subset them.Bin comletion (for bin packing) considers maximal, feasible assignments,clear non-maximal assignments dominated maximal assignments, i.e., assigning non-maximal assignment bin cannot lead solution fewer binsassigning maximal assignment. example, current bin 20 units remainingspace remaining items {15, 30, 40, 60}, always better add 15current bin, must eventually pack 15 somewhere. formalizenotion dominance describe powerful dominance criteria significantly prunesearch space.Definition 1 (Dominance) Given two feasible bin assignments F1 F2 , F1 dominatesF2 value optimal solution obtained assigning F1 binworse value optimal solution obtained assigning F2bin.show bin assignment B dominated another bin assignment A,prune search tree B. Maximality trivial dominance criterion bincompletion. feasible bin assignment B maximal, definition, must401fiFukunaga & Korfsubset maximal, feasible subset A, B clearly dominated A. considerpowerful dominance criteria.Suppose bin packing instance bin capacity 100 items {96,3,4,80,15,12}.sets (96,3) (96,4) maximal, feasible bin assignments. choosebin assignment (96,3), remaining subproblem unassigned items {80,15,12,4}.hand, choose bin assignment (96,4), remaining subproblem{80,15,12,3}. Clearly, optimal solution subproblem {80,15,12,4} must use leastmany bins optimal solution subproblem {80,15,12,3}. words,optimal solution subtree node (96,4) least good optimalsolution subtree (96,3), therefore need search (96,3)bin assignment (96,4) dominates bin assignment (96,3).Christofides, Mingozzi, Toth first proposed general form dominancecriterion context min-cost covering problem (Christofides et al., 1979).reformulated criterion terms bin packing problem:Proposition 1 (CMT Dominance Bin Packing) Given two feasible sets B,dominates B if: (1) |A| |B| (2) exists one-to-one (but necessarily onto)mapping B item b B, mapped elementweight greater equal weight b, i.e., w(b) w((b)).1words, element b feasible bin assignment B, corresponding item feasible bin assignment b a, dominates B.reason follows: consider bin packing solution S, single bin assigneditems B. items must assigned bin, items assignedbin(s). item B, swap corresponding item A,resulting solution feasible, bins S. example, considerbin packing instance items {10,9,8,7,6} bin capacity 20. bin assignment= (10, 8) dominates bin assignment B = (9, 7), map 9 10map 7 8.Martello Toth (1990) proposed powerful dominance criterion subsumesCMT criterion. Consider bin packing instance items {6,4,2,1,...} capacity10. assignment (6,4) dominates assignment (6,2,1) given solutionassignment (6,2,1), swap 2 1 4, resulting solutionassignment (6,4) number bins. CMT criterion accountthis. generally, consider two feasible bin assignments B. elementsB packed bins whose capacities elements A, set dominates setB. example, let = (20, 30, 40) let B = (5, 10, 10, 15, 15, 25). Partition Bsubsets (5, 10),(25), (10, 15, 15). Since 5 + 10 20, 25 30, 10 + 15 + 15 40,set dominates set B. formally:Proposition 2 (Martello-Toth Bin Packing Dominance Criterion) Let Btwo feasible bin assignments. dominates B B partitioned subsets B1 , ...Bisubset Bk mapped one-to-one (but necessarily onto) item aksum weights items Bk less equal weight ak .1. Recall function f : X one-to-one two distinct elements x, x X, f (x) 6= f (x ).function f : X onto element image f element X.402fiBin Completion Algorithms Multicontainer ProblemsProof: Suppose candidate solution assigns B bin m, binassignments currently feasible. Let feasible bin assignment Bpartitioned subsets B1 , ..., Bi , subset Bk mapped one-to-oneak A, sum weights items Bk less equal weightak . Consider swapping B A. subset Bk swapped correspondingelement ak (where ak assigned bin dk original solution s). Since feasible,bin remains feasible B swapped. consider bins d1 , ...disubsets B1 , ..., Bi end swaps (in words, d1 , ...di binscontain a1 , ..., ak , respectively, original solution s). target bin dkremain feasible swap, since (1) bin assignment dk feasible priorswap, (2) sum weights items Bk less equal weightak . Thus, resulting solution swap (a) feasible (all bin assignmentsfeasible) (b) worse initial solution s, (c) assigns bin m. Therefore,dominates B. 2Martello-Toth dominance criterion generalization CMT dominance criterion CMT dominance criterion special case Martello-Toth criterionconsider partitions B single-element subsets. Thus, node wouldpruned CMT criterion also pruned Martello-Toth criterion, viceversa.Similarly, define dominance criterion bin covering follows:bin covering (and MCCP), bin assignment feasible respect givenbin sum item weights greater equal bin quota q.Proposition 3 (Bin Covering Dominance Criterion) Let B two feasible assignments. dominates B B partitioned subsets B1 , ..., Biitem ak mapped one-to-one (but necessarily onto) subset Bk ,weight ak less equal sum item weights correspondingsubset Bk (i.e., Bk covers ak ).Proof: Suppose solution assigns B bin m, bin assignmentscurrently feasible. Let feasible bin assignment B partitionedsubsets B1 , ..., Bi , item ak mapped one-to-one subset Bk ,weight ak less equal sum weights items Bk .Consider swapping B A. subset Bk swapped corresponding element ak(where ak assigned bin dk original solution s). Since feasible, bin remainsfeasible B swapped. consider bins d1 , ..., d|A|subsets Bk end swaps. words, d1 , ..., d|A| bins containa1 , ..., ak , respectively, original solution s. target bin dk remain feasibleswap, since (1) bin assignment dk feasible prior swap, (2)sum weights items Bk greater equal weight ak (and thusquota bin dk continue satisfied). Thus, resulting solutionswap (a) feasible (all bin assignments feasible) (b) worse initial solutions, (c) assigns bin m. Therefore, dominates B. 2dominance criteria MKP MCCP similar dominance criteriabin packing bin covering, respectively, except must also take considerationprofits/costs. proofs similar proofs bin packing bin covering.403fiFukunaga & KorfProposition 4 (MKP Dominance Criterion) Let B two assignmentsfeasible respect capacity c. dominates B B partitioned subsetsB1 , ..., Bi subset Bk mapped one-to-one (but necessarily onto) ak ,element A, k i, (1) weight ak greater equal sumitem weights items Bk , (2) profit item ak greater equalsum profits items Bk .Proposition 5 (MCCP Dominance Criterion) Let B two assignmentsfeasible respect quota q. dominates B B partitioned subsetsB1 , ..., Bi item ak mapped one-to-one (but necessarily onto)subset Bk , ak corresponding subset Bk , (1) weight ak lessequal sum item weights items Bk , (2) cost item akless equal sum cost items Bk .CMT dominance criterion MCCP originally proposed (Christofides et al.,1979) special case Proposition 5, |Bk | = 1 k.Note packing problems MKP bin packing, dominancecriteria require subsets dominated assignment packed itemsdominating assignment. contrast, covering problems MCCPbin covering, dominance criteria requires subsets dominated assignment(B) cover items dominating assignment (A).2.3.1 Bin-Oriented Branch-and-Bound + Dominance = Bin Completionpoint, defined salient features bin completion approach solvingmulticontainer packing knapsack problems:bin-oriented branch-and-bound search nodes correspond maximal (orminimal), feasible bin assignments;exploitation dominance criterion among bin assignments prune searchspace.first instance bin completion algorithm aware Christofides,Mingozzi, Toth algorithm min-cost covering problem 1979 (Christofides et al.,1979), used CMT criterion described above. However, far know,research done bin completion algorithms work bin completionbin packing (Korf, 2002).Martello-Toth dominance criterion proposed Martello Toth (1990),component Martello-Toth Procedure (MTP), branch-and-bound algorithm binpacking. However, MTP branch-and-bound algorithm item-oriented,exploit dominance property limited way. particular, take remainingelement x, starting largest element, check single assignmentx one two elements dominates feasible sets containing x. so,place x elements bin, apply reduction remainingsubproblem. also use dominance relations prune element placements well.Another earlier instance bin completion algorithm BISON algorithm binpacking Scholl, Klein, Jurgens (1997). BISON uses following, limited form404fiBin Completion Algorithms Multicontainer ProblemsMartello-Toth dominance criterion: bin assignment one itemsreplaced single free item without decreasing sum, assignmentdominated. interesting despite fact basic idea bin-oriented searchdominance-based pruning demonstrated Christofides, Mingozzi, Toth,MTP BISON use limited form Martello-Toth dominance criterion,two ideas successfully integrated work.2 Presumably, reasontrivial generate undominated bin assignments efficiently.2.4 Generating Undominated Bin Assignmentskey component bin completion efficient generation undominated bin assignments. obvious approach generate feasible bin assignments, apply dominance tests eliminate dominated assignments. However, impractical,number feasible assignments exponential number remaining items,memory time required generate store assignments would prohibitive.describe algorithm generates undominated bin assignments,enables efficient implementation bin completion.generate subsets n elements recursively traversing binary tree.internal node corresponds item, left branch corresponds subsetsinclude item, right branch corresponds subsets includeitem. Thus, leaf node represents individual subset. Note binary treesearch space subproblem (generating undominated bin assignments),distinct search space higher level bin-completion algorithm (i.e.. spaceundominated maximal assignments).Given n elements container capacity c, feasible bin assignments subsets n elements, sum whose weights exceed c. recursive traversaldescribed generating subsets modified generate feasible assignments follows: node tree, keep track sum itemscommitted including subset (i.e., sum weights itemstaken left branch). recursive traversal tree, pass parameterrepresenting remaining capacity bin. time left branch taken (therebyincluding item), reduce remaining capacity item weight. remainingcapacity drops zero less, prune tree current node, sinceequaled exceeded container capacity. Thus, algorithm generates feasiblebin assignments.Now, extend algorithm generate undominated, feasible binassignments. Suppose feasible set whose sum weights t. excludeditems items A. Set dominated (with respect MartelloToth dominance criterion) contains subset whose sum lessequal excluded item x, replacing subset x exceed bincapacity c. case exists excluded item x subsetweight sum + x c. Therefore, check undominated,enumerate possible subset items, subset, compare2. shown (Korf, 2002, 2003), bin-oriented search using full Martello-Toth dominance criterionresults dramatic speedups compared MTP.405fiFukunaga & Korfexcluded number x verify + x > c, sum item weightssubset. so, undominated, store list undominated assignments;otherwise, dominated. optimizations found (Korf, 2003).algorithm generates feasible bin assignments immediately tests dominance, never stores multiple dominated bin assignments. Furthermore, dominancetest done comparing included elements excluded elements, involvecomparison candidate bin assignment previously generated bin assignments. Therefore, memory required dominance testing linear numberitems. contrast, method depends comparisons candidate sets,earlier algorithm described (Korf, 2002), requires memory linearnumber undominated bin assignments, potentially exponential numberitems. ability incrementally generate undominated bin assignments using linear space without store undominated assignments enables hybridincremental branching strategy, described Section 3.4.3. Extensions Bin Completiondescribe extensions bin completion significantly improve search efficiency. Again, clarity, describe algorithms mostly context bin packing,basic bin completion algorithm, extensions adapted straightforwardly multiple knapsack, bin covering, min-cost covering problems.3.1 Nogood Pruning (NP)Nogood pruning prunes redundant nodes bin completion search tree detectingsymmetries. Since need refer specific bins, extend notation bin assignment. Let (A)d denote bin depth assigned elements A. Thus, (10, 8, 2)1(10, 7, 3)1 denote two possible bin assignments bin depth 1.Suppose instance numbers {10,9,8,7,7,3,3,2,2}, bin capacityc=20. exhausting subproblem assignment (10, 8, 2)1 , exploringsubproblem assignment (10, 7, 3)1 , assume find solution assigns(9, 8, 2)2 . swap pair items (8,2) assignment (9, 8, 2)2 pairitems (7,3) assignment (10, 7, 3)1 , resulting solution (10, 8, 2)1(9, 7, 3)2 number bins. However, already exhausted subtree(10, 8, 2)1 would found solution number binsbest solution subtree (9, 7, 3)2 . Therefore, prune branch(9, 8, 2)2 , redundant (in words, detected current partialsolution symmetric partial state already exhaustively searched).formally, let {N1 , N2 , ..., Nm } set sibling nodes search tree,let {S1 , S2 , ..., Sm } bin assignments sibling node, excluding first itemassigned bin, common sibling nodes. searching subtreenode Ni > 1, exclude bin assignment B (1) includes itemsSj , (2) swapping items Sj B items Si Ni results two feasible406fiBin Completion Algorithms Multicontainer Problemsbin assignments, > j. items Sj become nogood respect nodes deepertree.3exists bin assignment B, could swap items Sj Bitems Si Ni , resulting partial solution bin assignment Si bin Ni .However, already exhausted subtree Ni , redundant nodepruned.search progresses tree, list nogoods maintained, setbin assignments candidate undominated bin assignment compared.Given candidate bin assignment B, items sorted according weight,current implementation test nogood pruning compares itemsnogood. Since items nogood sets also sorted weight, comparisontakes time linear cardinality B. worst case, number nogoodsmust compare candidate assignment level corresponds numberundominated bin assignments levels 1, ..., 1 currently stack (that is,ancestors siblings ancestors current node). Note listnogoods need grow monotonically go search tree. point,nogood N longer subset set remaining items, N split,removed nogood list passed search tree.3.2 Nogood Dominance Pruning (NDP)following nogood dominance pruning (NDP) technique allows even pruning: Suppose exhausting subproblem assignment (10, 8, 2)1 ,exploring subproblem assignment (10, 7, 3)1 , consider assignment(9, 7, 2)2 . swap pair items (7,2) bin 2 pair items (7,3)bin 1 end solution (10, 7, 2)1 (9, 7, 3)2 . However, accordingMartello-Toth dominance criterion, (10,7,2) dominated (10,8,2),already exhausted search node (10, 8, 2)1 , prune search(9, 7, 2)2 possible improve upon best solution (10, 8, 2)1 .general, given node one child, searching subtreechild first, dont need consider assignments dominated binassignment previously explored child node. precisely, let {N1 , N2 , ..., Nm }set sibling nodes search tree, let {S1 , S2 , ..., Sm } corresponding setsitems used bin assignment node. searching subtree nodeNi > 1, exclude bin assignment exists assignment Sj ,j < i, (1) dominated items Sj (note assignment dominatesitself), (2) swapped Si , resulting bin assignmentsfeasible. exists bin assignment A, could swap itemsitems Si Ni , resulting partial solution bin assignment bin Ni ,number bins. However, since dominated Sj , meanssearching node symmetric one dominated Sj , therefore,possible find solution better best solution Sj , pruned.3. term nogood constraint programming literature often refers assignment value(s)variable(s) cannot lead solution, use term mean assignment cannot leadsolution better previously discovered solution, similar usage (Focacci &Shaw, 2002).407fiFukunaga & Korfalso describe nogood dominance pruning terms general constraintprogramming formulation, variables correspond items values denote binsassigned. Given partial, j-variable solution x, nogood dominancepruning tries show, via swapping items dominance checks, xequivalence class another partial solution x xi , subset x includingfirst variables, dominated another partial solution q. Thus, exhaustedsubtree q search tree, need search subtree x .Nogood dominance pruning strictly powerful nogood pruning. nodepruned nogood pruning pruned nogood dominance pruning, viceversa. course, since NDP must detect dominance relationships opposed equivalence relationships, NDP incur overhead per node compared NP. currentimplementation propagates list nogood sets along tree. generating undominated completions given bin, check one see dominatedcurrent nogood. so, ignore bin assignment. current implementation usesbrute-force algorithm check dominance candidate bin assignmentnogood, worst case takes time exponential cardinality binassignment (for nogood).Since nogood pruning much less expensive nogood dominance pruning, usecombined pruning strategy. Whenever apply NDP, actually apply NPNDP node. First, candidate bin assignment checked nogood,nogood pruning applied. apply nogood dominance pruning bin assignmentpruned nogood pruning. Thus, never pay full cost applying NDPnodes pruned quickly NP. nogood pruning, NDP requires storingset nogoods, number possible nogoods particular search depthworst case number undominated bin assignments considered depths 1, ..., 1.Note using NDP, apply optimization described Section3.1 removing nogoods nogood list passed tree usingnogood pruning. reason even nogood split longerprune bin assignment due nogood pruning, nogood may still able prunebin assignment due nogood dominance pruning.size nogood list increases depth, compare bin assignmentnogood. Therefore, per-node overhead NDP increases depth.means pruning bottom tree (where pruning lowest utility)expensive pruning top tree (where pruning highest utility).simple strategy address issue depth-limited NDP, NDP appliednodes NDP depth limit L. nodes depth limit, weakernogood pruning applied. experiments described paper, usedepth-limited strategy NDP consistently outperformed nogood pruning withoutuse depth limits.3.3 Related Work Constraint ProgrammingNogood pruning identifies prunes nodes detecting whether bin assignmentcurrent node contains nogood. related symmetry-breaking techniquesproposed constraint programming literature. symmetry partitions set pos-408fiBin Completion Algorithms Multicontainer Problemssible assignments values variables equivalence classes (Gent & Smith, 2000).goal symmetry breaking prune nodes mapped previously explorednode via symmetry function. Symmetry-breaking approaches introduce constraints search prune symmetric variable assignments (e.g., Gent & Smith, 2000; Fahle,Schamberger, & Sellmann, 2001; Focacci & Milano, 2001). Similarly, nogood nogood dominance pruning techniques dynamically introduce constraints prune variableassignments cannot lead solution better best solution found far.Nogood dominance pruning uses dynamic nogood recording mechanism nogoodpruning, goes step detecting dominance relationships based nogoods.general notion dominance exploited NDP powerful symmetry, sincedominance asymmetric, i.e., symmetries dominance relationships,vice versa.NDP technique similar pruning technique proposed Focacci Shaw(2002) constraint programming, applied technique symmetricasymmetric traveling salesperson problem time windows. methods attemptprune search proving current node depth j, represents partial jvariable (container) solution x, dominated previously explored i-variable partialsolution (nogood), q. main difference two methods approach usedtest dominance. Focacci Shaws method extends q j-variable partial solutionq dominates x. apply local search procedure find extension q .contrast, NDP method starts partial, j-variable solution x triestransform partial solution x xi , subset x including firstvariables, dominated q. swapping values ith jth variablesx derive x , testing whether xi dominated q.efficiency, current implementations nogood dominance pruning methodsweak, sense x dominated q, procedures necessarily detectdominance. Focacci Shaw rely incomplete, local search find extensionq . Due cost considering transformations, consider transformationsinvolving two variables (containers), fully exploit dominance criterion, wouldneed consider transformations involving variables i, + 1, ..., j.3.4 Reducing Computation Required Per Nodeissue enumerating undominated completions applying value orderingcomputing undominated sets NP-complete. multicontainer probleminstance items weight wi andPaverage container capacity c, averagenumber items fit container x = ni=0 wi /c. time generate undominated bin assignments increases x. issue bin packing, problemslarge x tend easily solved using heuristics best-fit decreasing. solution found heuristic often equals lower bound. Therefore, instances requiresearch, hence need compute undominated bin assignments.hand, multiple knapsack bin covering, observed experimentallymuch less likely heuristics match optimistic bound allow terminationwithout search, found instances high x, algorithm wouldterminate within reasonable time limit spending inordinate amount409fiFukunaga & Korf2behfgckljFigure 3: Hybrid Incremental Branching Strategytime computing set undominated completions node. addition, generatingundominated bin assignments may cause us run memory.alternative approach start go search tree explorechildren node without first enumerating sorting children. cases(a) good optimistic bound available, (b) takes relatively little search findoptimal solution, approach leads dramatic speedups compared original schemegenerating undominated completions going search tree.price pay strategy lose benefits ordering candidate binassignments according value-ordering heuristic.solve problem, propose hybrid incremental branching strategy generatesh children node, applies value-ordering heuristic these, recursively callsbin completion remaining subproblems. node, first generate h children,sort according value-ordering heuristic. Then, explore subtreeschildren. subtrees first h children fully explored,next h children generated subtrees explored, on.example, consider tree Figure 3, nodes correspond undominatedbin assignments. Assume complete search tree, assume simplicityvalue ordering heuristic. standard bin completion algorithm firstgenerates children root: a, b, c. Then, bin completion selects onechildren (say a), expands children (d,e,f ,g). generates children d,on. Thus, order node generation is: a, b, c, d, e, f, g, h, i, j, k, l.pre-order traversal tree. consider hybrid incremental branching width 1.corresponds standard postorder traversal tree, ordernodes generated a, d, h, i, j, e, f, g, b, k, l, c. Hybrid incremental branching width2 generates nodes order a, b, d, e, h, i, j, f, g, k, l, c.4. Multiple Knapsack Problem (MKP)Given set containers set items (characterized weight profit),objective multiple knapsack problem (defined formally section 1.1.2) assignitems containers container capacities exceeded, sumprofits items assigned containers maximized.compared bin completion two standard algorithms: state-of-the-art Mulknapalgorithm (Pisinger, 1999), well MTM algorithm (Martello & Toth, 1981).410fiBin Completion Algorithms Multicontainer Problems4.1 MTM AlgorithmMTM algorithm Martello Toth (1981) item-oriented branch-and-boundalgorithm. items ordered according non-increasing efficiency (ratio profitweight), next item selected variable-ordering heuristic itemoriented branch-and-bound item highest efficiency assigned leastone container greedy bound-and-bound procedure (see below). branches assignselected item containers, order non-decreasing remaining capacity.node, upper bound computed using relaxation MKP,obtained combining remainingcontainers MKP single conPmtainer aggregate capacity C = i=1 ci , resulting single-container, 0-1 knapsackproblem:maximizenXpj xj(19)subjectj=1nXwj xj C,(20)j=1xj{0, 1}, j = 1, ..., n.(21)variable xj represents whether item j assigned aggregated bin.surrogate relaxed MKP (SMKP) solved applying algorithm optimallysolving 0-1 Knapsack problem, optimal value SMKP upper boundoriginal MKP. Thus, upper bound computation solving embedded,weakly NP-complete (single-container) 0-1 Knapsack problem instance subproblem.SMKP currently effective upper bound MKP (detailsformulation derived initial surrogate relaxation Martello & Toth,1981; Kellerer et al., 2004).node, MTM algorithm applies extension branch-and-bound calledbound-and-bound. Consider branch-and-bound procedure maximization problem.upper (optimistic) bound computed node less equal best knownlower bound problem, node pruned. standard branch-andbound approach, lower bound simply objective function value best solutionfound far.bound-and-bound, attempt validate upper bound applying fast, heuristic algorithm order find solution whose score equals upper bound. solution found, means found optimal solution currentnode (i.e., upper bound validated), backtrack. hand,solution found, must continue search node. MTMalgorithm applies greedy heuristic algorithm MKP, involves solving series0-1 Knapsack problems. First, container = 1 filled optimally usingremaining items, items used fill container = 1 removed. Then, container= 2 filled using remaining items. process iterated times, pointcontainers filled.411fiFukunaga & Korf4.2 Mulknap Algorithmprevious state-of-the-art algorithm MKP Mulknap (Pisinger, 1999). LikeMTM, Mulknap item-oriented branch-and-bound algorithm using SMKP upperbound bound-and-bound. Mulknap differs MTM (1) uses differentvalidation strategy bound-and-bound based splitting SMKP solution, (2)applies item reduction node, (3) applies capacity tightening node.Like MTM, Mulknap uses bound-and-bound strategy, uses different approachvalidating upper bound: described above, upper bound MKP instancecomputed solving surrogate relaxation MKP, SMKP, 0-1Knapsack instance. Suppose computed optimal solution SMKP.Now, suppose able partition items used SMKP containersoriginal MKP, item used SMKP solution assignedcontainer, capacity constraints violated. case, solutionoriginal MKP achieves upper bound. Details capacity tighteningreduction procedures given Pisinger (1999).4.3 Bin Completion Algorithm MKPdescribe bin completion algorithm MKP. apply depth-first, bincompletion branch-and-bound algorithm. node search tree represents maximal, feasible bin assignment particular bin. Note MKP, bin capacitiesvary, node, consider undominated bin assignments bin.contrast bin packing 2.2, (assuming bins identical capacity),restrict nodes level (largest) item.node, upper bound remaining subproblem computed usingsurrogate relaxed MKP (SMKP) bound. SMKP bound computed using straightforward branch-and-bound algorithm Martello-Toth U2 upper bound (Martello &Toth, 1977). Pisingers R2 reduction procedure (Pisinger, 1999) applied nodeorder possibly reduce remaining problem. Then, select bin smallestremaining capacity (i.e., use smallest-bin-first variable ordering heuristic, tiesbroken randomly), undominated bin assignments computed explored usingdominance criterion (Proposition 4). Nogood pruning nogood dominance pruningapplied described Sections 3.1 3.2.order branch undominated children current nodesignificant impact algorithms performance. node, undominatedchildren node generated ordered using value ordering heuristic. evaluated 11 different value ordering heuristics found best performing heuristicoverall min-cardinality-max-profit ordering, candidate bin assignmentssorted order non-decreasing cardinality ties broken according non-increasingorder profit. Fukunaga (2005) provides details experiments evaluating variousvalue variable ordering strategies. Figure 4 shows outline bin completionalgorithm MKP.412fiBin Completion Algorithms Multicontainer ProblemsMKP bin completion(bins,items)bestProfit =search MKP(bins,items,0)search MKP(bins, items,sumProfit)bins== items ==/*we candidate solution*/sumProfit > bestProfitbestProfit = sumProfitreturn/* Attempt reduce problem. reducedBinAssignmentsmaximal, feasible assignments items bins */reducedBinAssignments = reduce(bins,items)ri = get items(reducedBinAssignments) /* items eliminated reduction */rb = get bins(reducedBinAssignments) /* bins eliminated reduction */reducedItems 6=Psearch MKP(bins \ rb, items \ ri, sumProfit+ iri profit(i))return/* Attempt prune based upper bound */(sumProfit + compute upper bound(items,bins)) < bestProfitreturnbin = choose bin(bins)undominatedBinAssignments = generate undominated(items,capacity(bin))foreach sort assignments(undominatedBinAssignments)not(nogood(A)) not(nogood dominated(A))assign undominated bin assignment binPsearch MKP(bins \ bin, items \ items in(A),sumProfit+ iA profit(i))Figure 4: Outline bin completion multiple knapsack problem.compute lower bound returns SMKP upper bound profitremaining subproblem, reduce applies Pisingers R2 reduction eliminateitems bins possible. choose bin selects bin least remainingcapacity, sort assignments sorts undominated bin assignmentsorder non-decreasing cardinality, ties broken order non-increasingprofit. generate undominated generates undominated bin assignments usingalgorithm (Section 2.4). nogood nogood dominated apply nogoodpruning (Section 3.1) nogood dominance pruning (Section 3.2).413fiFukunaga & Korf4.4 Experimental Resultsevaluated MKP algorithm using four classes instances used Pisinger(1999). considered:uncorrelated instances, profits pj weights wj uniformly distributed[min, max].weakly correlated instances, wj uniformly distributed [min,max]pj randomly distributed [wj (max min)/10, wj + (max min)/10]pj 1,strongly correlated instances, wj uniformly distributed [min,max]pj = wj + (max min)/10,multiple subset-sum instances, wj uniformly distributed [min, max]pj = wj .bin capacitiesfollows: first 1 capacities ci uniformlyPn set asPdistributed [0.4 j=1 wj /m, 0.6 nj=1 wj /m] = 1, ..., 1. last capacity cmPPm1chosen cm = 0.5 nj=1 wj i=1ci ensure sum capacities halftotal weight sum. Degenerate instances discarded Pisingers experiments(1999). is, used instances where: (a) items fits least onecontainers, (b) smallest container large enough hold least smallest item,(c) sum item weights least great size largest container.experiments, used items weights range [10,1000].4.4.1 Comparison Bin Completion Previous Algorithmscompare bin completion (BC) Mulknap MTM. experiments described involving Mulknap, used Pisingers Mulknap code, available website4 , compiled using gcc compiler -O3 optimization setting. Likewise,experiments described involving MTM, used Martello Toths Fortran implementation MTM (Martello & Toth, 1990), converted C using f2ccould add instrumentation. bin completion code implementedCommon Lisp.5 shown experimentally choice programming languageadded overhead approximately factor two runtimes (see Fukunaga, 2005,Appendix A) compared GNU C 2.95 -O3 optimization.four problem classes, generated test sets 30 instances each,n = 20, varied 2 10. instance, ran Mulknap, bincompletion, bin completion nogood dominance pruning. purposeexperiment observe behavior algorithms ratio n/m varied.results shown Table 2. algorithm given time limit 300 seconds solveinstance. fail column indicates number instances (out 30) couldsolved algorithm within time limit. time nodes column show4. http://www.diku.dk/pisinger/5. bin completion solvers described paper MKP, MCCP, bin covering, binpacking problems implemented Common Lisp.414fiBin Completion Algorithms Multicontainer Problemsnfail# bins# items2345678910202020202020202020000001113234567891020202020202020202000000000223456789102020202020202020200000002242345678910202020202020202020000000224MTMtimenodesfailMulknaptimenodesUncorrelated Instances20100.0000169700.000023153000.00303063480000.0387297710038700.40633605785159113.820736984635397291 23.7996 2493203112945804 33.2138 2868979135367355 52.0812 4848676Weakly Correlated Instances0.004078100.0000260.0127269300.01676380.0327662600.039017080.23635332400.2917127010.27636521600.4220201650.623716897401.31806089011.0927292249926.57934033927.5807 112639283 22.5878 127475625.1029 106971655 72.3472 4478185Strongly Correlated Instances0.0723574700.0037320.1243674800.0053650.1237812500.01201560.17771482300.03605630.18071801200.05507345.139388208010.0928133911.236126166153 12.258122523620.013631508484 33.541569339838.855481419029 34.3291634358Subset-Sum Instances0.0820206100.003390.2057703300.0337770.1760837100.05031370.25071751400.17808300.23931754600.19537385.765785261510.3221175214.926125468343 19.593027084125.939331244214 41.896267746751.502779074079 39.75006276880.00030.00170.00630.07670.23431.57216.335218.331422.5185Bin Completion+NDPfailtimenodes0000000000.00500.00630.00230.00330.00500.00430.00230.00170.001055123112212403399207136840000000000.03400.01170.01330.01070.00800.00500.00270.00130.00138724037952140524514466430000000000.07430.04170.03530.03500.02170.01370.00730.00600.00571182783313591941094225210000000000.04470.03100.02600.02570.01730.01130.00730.00630.005764248294315176102392520Table 2: MTM, Mulknap, Bin Completion Nogood Dominance Pruning smallMKP instances varying n/m ratio.The fail column indicates numberinstances (out 30) solved within time limit (300 seconds/instance). time (seconds 2.7GHz Pentium 4) nodes columnsshow average time spent nodes generated successful runs, excludingfailed runs.415fiFukunaga & Korfaverage time spent nodes generated successful runs, excluding failed runs.experiments described section run 2.7GHz Pentium 4.data confirms observations Pisinger (1999) Martello Toth (1981)class uniform, random instances require search previous branchand-bound solvers appear generated n/m relatively low. words,n/m ratio MKP appears critical parameter determines searchdifficulty, similar clause-to-variable ratio satisfiability problems (Mitchell, Selman,& Levesque, 1992). Table 2 shows Mulknap MTM great difficultyrelatively small problems small n/m ratios, bin completion could solveproblems quickly.Next, investigated larger problem instances, n/m varied 2 4.experiment, also included bin completion nogood pruning (BC+NP),addition MTM, Mulknap, BC+NDP.shown Table 3, problems n/m = 2 3, variants bin completion(BC+NP BC+NDP) dramatically outperformed MTM Mulknap,difference performance becoming pronounced problem size increased. runs truncated 300 seconds per instance per algorithm, possiblecompare full runtimes sets. Note, example, subset-suminstances n = 40 = 20, mean runtime BC+NDP 0.06 seconds,neither MTM Mulknap solved instances within 300 seconds each,least three orders magnitude slower BC+NDP instances. triedrunning solvers longer order get actual runtimes (as opposed truncated, lowerbound runtimes), found even allocating hour per problem insufficientallow MTM Mulknap solve problems. results suggestbin completion asymptotically efficient MTM Mulknap classproblem instances. problems n/m = 4, results similar, notableexception strongly-correlated instances, Mulknap outperformed bin completionn = 40 = 10.problems n/m = 2 3, observed BC+NDP consistently outperforms BC+NP significant margin respect number nodes searched,significant improvements success rate execution times observed largerproblems sets. However, n/m = 4, BC+NDP still searches fewer nodes BC+NP,difference much less significant, fact, reduced search enoughoffset increased overhead per node NDP, runtimes BC+NPBC+NDP end comparable (Table 3).also ran experiments instances larger n/m ratios. n/m 5,Mulknap clearly dominates current algorithms, solving instances littlesearch second, first demonstrated Pisinger (1999). high n/m ratios,bound-and-bound approach Mulknap high probability finding upperbound matches lower bound node, essentially eliminating needsearch. fact, Pisinger (1999) showed instances n/m 10,almost instances required searching one node.416fiMTMtimen# itemsfail15202510155103040503045204030303012300747.770.0899.13152025101551030405030452040303030163002968.800.10205.9915202510155103040503045204030303013001323.480.06115.381520251015510304050304520403030300180525.580.00.0535.20nodesfailMulknaptimenodesBin Completion+NPfailtimenodesUncorrelated Instances3000.043001.4830472.661129.96164906200.71301566.8100.10848700.01451.661744911011.58Weakly Correlated Instances3000.073000.7930034.3982521551569.65164757600.94301952.422115000.14575800.011267296527131.412390152021.10Strongly Correlated Instances3000.043003.4630952.26291685807.028873700.533024105.901249000.0248600.015528847044.55361987251.89Subset-Sum Instances3000.013000.133004.37199364804.744373400.1227.5823100.19480014245.07567600.0120700.01946934010.485831701.9892404263260215083247Bin Completion + NDPfailtimenodes1215666812767939484073369997253360567003015000.020.7232.430.6160.540.0113.47887264591060723331412516681237297225212322553691645340011126242407565036000018000.050.3515.800.7967.170.0120.63105074732319342576412070993964909834155407585005662964566264263462004023020.032.2958.720.50118.720.0150.511942694619005381115002425825409417116645533418165975811402667400002000.010.061.590.1243.440.012.009580619491175256212913726097Table 3: Multiple knapsack problem results: Comparison MTM, Mulknap, Bin Completion Nogood Pruning (NP),Bin Completion Nogood Dominance Pruning (NDP) hard MKP instances. fail column indicates numberinstances (out 30) solved within time limit (300 seconds/instance). time (seconds 2.7GHzPentium 4) nodes show average time spent nodes generated successful runs, excluding failed runs.Bin Completion Algorithms Multicontainer Problems417# binsfiFukunaga & Korfhand, n/m 5, bin completion tends generate large (more10000) number undominated bin assignments decision node, runsmemory allocating set undominated bin assignments candidatesassigned current bin. hybrid incremental branching (Section 3.4) eliminatesproblem allows algorithm run completion, still competitiveMulknap (runs complete within 300-second time limit).conclude uniform instances multiple knapsack problem exhibit bimodal characteristic, bin completion bound-and-bound complementaryapproaches. n/m 4, uniform MKP instances require significant amount searchsolve, bin completion approach clearly current state art, demonstrated Table 3. hand, n/m 5, bound-and-bound approachexemplified Pisingers Mulknap algorithm state art, runtimesdominated computation single lower bound single upper boundroot node. rather sharp phase transition around n/m = 4 dominantapproach changes bin completion bound-and-bound (see Fukunaga, 2005details).highly complementary nature Mulknap bin completion, MKPnatural candidate application algorithm portfolio approach (Huberman,Lukose, & Hogg, 1997; Gomes & Selman, 2001) Mulknap bin completionrun parallel problem instance. Even trivial portfolio resourceallocation scheme processes received equal time, resulting total CPU usageportfolio instance would worse twice faster algorithm.Another way combine bin completion bound-and-bound add bound-and-boundnode bin completion search, avenue future work.5. Min-Cost Covering Problem (MCCP)Given set containers quotas set items (characterized weightcost), objective MCCP assign items containers containerquotas satisfied, sum costs items assigned containersminimized (see 1.1.4 formal definition).5.1 Christofides, Mingozzi, Toth (CMT) Algorithmprevious state-of-the-art algorithm min-cost covering problem early versionbin completion Christofides, Mingozzi, Toth (1979). algorithm bincompletion algorithm uses CMT dominance criterion (see Section 2.3).effective lower bound computed solving independent minimizationproblems (similar standard 0-1 Knapsack, except objective satisfycontainers quota minimizing cost items assigned it), onebins, summing results. L2 lower bound relaxation constraintitem used once.Christofides et al. (1979) proposed several complex lower bounds, foundempirically among proposed lower bounds, L2 bound resulted bestperformance far across wide range problem instances.418fiBin Completion Algorithms Multicontainer Problems5.2 Bin Completion MCCPnew bin completion algorithm MCCP similar Christofides et al. algorithm. major difference use powerful dominance criterion (Proposition5). node depth-first, search tree represents minimal, feasible bin assignmentparticular bin. bin completion algorithm assigns bins order non-decreasingsize, i.e., smallest-bin-first variable ordering heuristic. evaluated eight different strategies ordering candidate undominated bin assignments, found min-weightstrategy sorts assignments non-decreasing order weight performed best. Fukunaga (2005) provides detailed comparison variable value orderings MCCP.use L2 bound CMT algorithm.5.3 Experimental Resultscompared performance bin completion variants previous algorithms.implemented following algorithms.CMT - Christofides, Mingozzi Toth algorithm described above. implementation used smallest-bin-first variable ordering, min-weight value ordering,L2 lower bound.CMT+NP - CMT algorithm extended nogood pruning.BC - Bin completion using min-weight value ordering smallest-bin-first variableordering.BC+NP - Bin completion nogood pruningBC+NDP - Bin completion nogood dominance pruning,used smallest-bin-first variable ordering CMT BC variants observing led good performance compared random largest-bin-first variableorderings.experiment shown Table 4, compared CMT, CMT+NP, BC, BC+NP,BC+NDP. purpose experiment evaluate relative impactcomponent bin completion, comparing various combinations of: (1) typedominance criterion used, (2) whether nogood pruning used, (3) whether nogooddominance pruning used.used four classes test problems (uncorrelated, weakly correlated, stronglycorrelated, subset-sum) multiple knapsack problem experiments (Section 4.4),item weights costs range [10,1000]. four problem classes,30 instances generated various values n. ran algorithminstance. experiments run 2.7GHz Pentium 4. algorithm giventime limit 300 seconds solve instance. fail column indicates numberinstances (out 30) could solved algorithm within time limit.time nodes column show total time spent nodes generated, excluding failedruns.419fin# itemsfail5105101520515301020304020030013030051051015205153010203040205105101520551051015205CMTtimenodesfail0.300.0147.4313.663409425651368731041966030001130003000283010.210.013.22227.6354.11102394618987416471570975879030002180153010203040200300063000.080.010.2493.3318.914226301949651785734464190300001801530102030402003000103000.080.010.1774.5718.11460631132863812510384584030000180CMT+NPtimenodesfailBCtimenodesUncorrelated Instances0.211264100.0267820184.79128160740.014800.011270.171064507.2480186380.04312117830300.10466500.2915979Weakly Correlated Instances0.13466500.013472620842426340.012100.01250.07397900.131121646.49180318020106.70536721597.5828743513017.6420325100.6515566Strongly Correlated Instances0.05251800.0168054.6513402760.011600.01100.02106400.0110645.1824165402.45204069 097.1928443011752.50293347420.7825329100.092474Subset-Sum Instances0.07289900.0165032.718104710.011700.01100.03157300.0198617.4878992802.3417768397.9028743401755.18293347417.6620325100.082270failBC+NPtimenodesfailBC+NDPtimenodes020002600.0149.660.010.0211.58184.590.25385195223631214970574883569619339000001000.0123.820.010.012.8197.670.15238635035281149136000314526351930160001200.01168.210.010.013.19112.080.5419728430801242818283038719111003205000200.0197.160.010.010.5644.840.45150143614212236306691704351769800000100.0117.600.010.010.1227.170.0753333450713975321039810189300000000.016.200.010.010.022.130.0640114786779135486685154600000200.0111.320.010.010.1026.370.0749213975814661681160452160500000000.013.970.010.010.022.470.06427077487312721256971242Table 4: Min-cost covering problem results: Comparison (a) Christofides, Mingozzi, Toth (CMT) algorithm, (b) CMT algorihm NogoodPruning (NP), (c) Bin Completion, (d) Bin Completion Nogood Pruning (NP), (e) Bin Completion Nogood Dominance Pruning(NDP). fail column indicates number instances (out 30) solved within time limit. time (seconds 2.7GHzPentium 4) nodes columns show average time spent nodes generated successful runs, excluding failed runs.Fukunaga & Korf420# binsfiBin Completion Algorithms Multicontainer Problemsshown Table 4, component bin completion significant impact. Although dominance criterion requires much computation per node simplerCMT criterion, search efficiency dramatically improved. Thus, BC performed muchbetter CMT, BC+NP performed much better CMT+NP.Furthermore, nogood pruning (NP) strategy significantly improves performancealgorithm based CMT dominance criterion, well dominancecriterion, evidenced improvement CMT+NP CMT improvementBC+NP BC. fact, nogood pruning sufficiently powerful allows CMT+NPsometimes outperform pure BC (without nogood pruning). Thus, data illustratespower nogood pruning, confirming similar results bin packing reported (Korf,2003), well preliminary experiments MKP MCCP.Finally, BC+NDP results best performance, significantly outperforming BC+NPlarger instances respect number problems solved within time limit,well runtimes nodes problems solved.also implemented two baseline algorithms: straightforward integer programmingmodel using freely available GNU glpk integer programming solver, well itemoriented branch-and-bound algorithm uses L2 lower bound, baselinesperformed poorly compared CMT bin completion algorithms (Fukunaga,2005).6. Bin Covering ProblemGiven set identical containers quota q set n items, weightwi , bin covering problem, sometimes called dual bin packing, assign itemscontainers number containers whose quotas satisfied (i.e., sumitem weights assigned container equal exceed quota) maximized (see 1.1.3formal definition). Although considerable interest bin coveringproblem algorithm operations research communities, previous workbin covering theoretical, focusing approximation algorithms heuristicalgorithms (e.g., Assmann et al., 1984; Foster & Vohra, 1989; Csirik, Frenk, Galambos, &Kan, 1991; Csirik, Johnson, & Kenyon, 2001), analysis properties classesinstances (e.g., Rhee & Talagrand, 1989).6.1 Labbe, Laporte, Martello Algorithmstate-of-the-art algorithm opimally solving bin covering item-oriented branchand-bound algorithm Labbe, Laporte, Martello (1995). referLLM algorithm. items sorted non-increasing order size. node representsdecision bin put item into. node, upper bounds basedcombinatorial arguments computed, remaining subproblem reduced usingtwo reduction criteria. root node, set heuristics applied order computeinitial solution lower bound. LLM upper lower bounds described(Labbe et al., 1995).421fiFukunaga & Korf6.2 Bin Completion Bin Coveringbin completion algorithm bin covering works follows. First, use LLMupper bounding heuristics root node find initial solution lower bound.Then, apply bin completion branch-and-bound algorithm, using new dominancecriterion (Proposition 3). node depth-first, search tree represents minimal,feasible bin assignment particular bin include largest remaining item.node, apply upper bounding procedures LLM algorithm computeupper bound. addition, apply LLM reduction criteria node. evaluatedeight different strategies ordering undominated bin assignments, found mincardinality-min-sum strategy (sort bin assignments order non-decreasing cardinality,breaking ties non-decreasing sum) performed best overall (Fukunaga, 2005).6.3 Empirical Resultsorder evaluate bin covering algorithm, considered class uniform, randomproblem instances previously studied Labbe, Laporte, Martello. simplemodel n items chosen uniformly range [min, max], max lessbin quota q. experimental evaluations, Labbe, Laporte, Martello useditems weights range 1 100, bin quotas ranging 100 500.However, many instances class solved without search. LLMlower bound heuristics find solution number bins LLM upperbound, found optimal solution terminate without search.say instance trivial solved without search, nontrivial otherwise.illustrate prepondrance trivial instances, generated 10000 uniform, randominstances bin quota 100000 120 items weights range [1, 99999].these, 9084 solved root node. shows uniform random bincovering instances are, fact, trivial given powerful upper lower bounds.previously observed similar phenomenon bin packing uniform, random binpacking instances solved root node combination best-first-decreasingheuristic Martello-Toth L2 lower bound (Korf, 2002).well-known number significant digits precision weightsitems significantly affects difficulty one-dimensional packing problems0-1 Knapsack problem (Kellerer et al., 2004). general, problem difficulty increasesprecision. property extends multicontainer, one-dimensional packing problemswell (e.g., Pisinger, 1999). confirmed problem difficulty highly correlatednumber significant digits item weights (Fukunaga, 2005).Therefore, experiments described below, used nontrivial instances,order highlight impact differences search strategy. is, generatingtest instances, filtered trivial instances testing whether LLM upper boundmatched lower bound heuristics. Furthermore, use high precision problems(quotas 10000 more) order focus difficult instances.6.3.1 Hybrid Incremental BranchingSection 3.4, proposed hybrid incremental branching, strategy avoiding runtime memory overheads imposed completely enumerating undominated children422fiBin Completion Algorithms Multicontainer Problemsnode. earlier experiments multiple knapsack min-cost coveringproblems, (Sections 45), problem instances used experiments fewer 50items, observed hundred assignments generatednode MKP MCCP experiments. Thus, number candidate undominatedbin assignments generated per node become bottleneck, hybrid incremental branching unnecessary. However, (1) average number items fitcontainer increases, (2) number items increases, number candidate undominated bin assignments per node increases. Therefore, benchmark comparisonsbin covering, hybrid incremental branching becomes much relevant.illustrate this, performed following experiment. generated 20 nontrivialinstances bin quota q=20000 100 items range [1,9999]. applied bincompletion + NDP problem instances, using hybrid incremental branchingvarious values parameter h, limits number children generatedevery node. h= 2000, 200, 20, 2, instances solved average4.998 seconds, 0.150 seconds, 0.0139 seconds, 0.0079 seconds, respectively.average number nodes expanded 20.2 h {2, 20, 200, 2000}. words,instances easily solved relying leftmost children nodebin completion search tree generating additional children entirely unnecessaryexpensive overhead. Thus, h increases, number nodesexplored, node requires much computation enumerate sort hundominated children, resulting two orders magnitude difference runtimeh = 2 h = 2000. see large h would order ableenumerate undominated children node, experimented h10000, found insufficient (the statically allocated array size h overflowedruns).experimented several values h several classes problems, foundoptimal value h varied significantly depending problem instance.experiments below, use hybrid incremental branching h=100, order setbalance minimizing number nodes expanded (exploiting value orderingamong children node) minimizing computational overhead per node (byminimizing number children generated).6.3.2 Comparing LLM Bin CompletionNext, compared LLM, bin completion+NP, bin completion+NDP using larger instances. also implemented straightforward integer linear programming model usingGNU glpk bin covering, found performed much worse LLMbin completion algorithms (Fukunaga, 2005).n {60, 80, 100}, generated 2000 non-trivial, uniform random instancesitems chosen uniformly range [1,99999], bin quota 100000.also generated 2000 non-trivial instances n = 100, q = 200000, itemsrange [1,99999]. ran implementations three algorithms instance,time limit 180 seconds per instance. shown Table 5, bin completionalgorithms significantly outperformed LLM. harder problems, bin completion + NDPsignificantly outperforms bin completion + NP. problems n = 100, q = 200000,423fiFukunaga & Korfn (# items)q (quota)6080100100000100000100000100200000Labbe et al.Bin Completion+NPfail timenodes fail timenodes2000 nontrivial instances per set10 0.39251966 0.083328736 1.026209315 0.183974045 1.98 11311015 0.42152113100 nontrivial instances per set1003 0.1125Bin Completion+NDPfail timenodes21280.110.090.3113735105173110730.1125Table 5: Bin Covering results: Comparison Labbe, Laporte, Martello algorithm, BinCompletion Nogood Pruning, Bin Completion Nogood DominancePruning. fail column indicates number instances (out 30)solved within time limit. time (seconds 2.7GHz Pentium 4)nodes columns show average time spent nodes generated successfulruns, excluding failed runs.results indicate instances extremely difficult LLM algorithm,failed solve 100 instances within time limit, problemsactually relatively easy bin completion. Since little search performedbin completion, bin completion+NDP improve upon bin completion+NP.7. Bin Packingbin completion approach originally developed bin packing problem,shown significantly outperform Martello-Toth Procedure randomly generatedinstances (Korf, 2002, 2003). implemented extended bin completion algorithmbin packing problem, summarize results below. details, see (Fukunaga,2005). bin completion based solver incorporated nogood dominance pruningmin-cardinality-max-weight value ordering strategy, (1) completions sortedorder non-decreasing cardinality, (2) ties broken according non-increasingweight.evaluated bin completion solver using set standard OR-LIB instances.6test set consists 80 triplet instances (where elements generated threetime sum elements add exactly bin capacity) 80 uniforminstances (where items sizes chosen uniform random distribution). bincompletion solver (executed 1.3GHz Athlon) given time limit 15 minutesinstance benchmark set. solved 80 triplet instances ORLIB within 1500 seconds combined. solved 40 uniform instances 120250 items 4 seconds combined. solved 18 (out 20) 500-item uniforminstances 11.13 seconds combined, failed solve 2 instances. Bin completion solved19 (out 20) 1000-item uniform instances 44 seconds combined, failedsolve one instances.6. available http://www.brunel.ac.uk/depts/ma/research/jeb/info.html424fiBin Completion Algorithms Multicontainer ProblemsHowever, bin completion solver competitive state art,recently developed branch-and-price integer linear programming solver BelovScheithauer (2006). Belov Scheithauer provide new benchmark set 28 hardbin packing instances; solver solved within seconds, although tookhours. current bin completion code could solve 28 instances, given15 minutes per instance. also report largest triplet instances OR-LIB(Triplet-501) solved average 33 seconds per instance (660 seconds total)1GHz AMD Athlon XP. Furthermore, Belov kind enough run solver setone hundred, 80-item, uniform, random instances generated itemsrange [1,1000000] bin capacity 1000000. solver solved instancesless 1 second root node (i.e., without search), using roundingheuristics based linear programming LP solution, whereas best bin completionsolver required 534 seconds searched 75,791,226 nodes.7.1 Branch-and-Price vs. Bin CompletionRecent branch-and-price approaches bin packing solver Belov Scheithauer use bin-oriented branching strategy, decisions correspond instantiation one maximal bin assignments (see Valerio de Carvalho, 2002, surveybranch-and-price approaches). node, column generation procedure usedcompute LP lower bound. derive much power accurateLP lower bound based cutting-stock formulation bin packing (Gilmore & Gomory,1961), observed almost always give optimal value lower bound,never observed give value one greater optimalvalue (e.g., Wascher & Gau, 1996). addition, rounding heuristics applied fractionalLP-solutions often yield optimal, integral solution. combination tightLP lower bound good upper bounding procedure results little searchperformed almost problem instances.branch-and-price LP-based approach seem generalize straightforwardlyMKP MCCP, part due differences granularity objectivefunction. objective function bin packing counts number bins used.hand, objective functions MKP MCCP sums profits itemsassigned containers. Thus, number possible, distinct objective function valuesMKP MCCP much larger number distinct objective function valuesbin packing problem comparable size. Therefore, even assume existenceformulation analogous cutting-stock problem, likely roundingLP solution MKP, MCCP, problems objective functionsfine-grained compared bin packing result optimistic bound accuratebin packing. suggests may difficult develop branch-and-pricesolver competitive problems. hand, since granularityobjective function bin covering bin packing, possiblebranch-and-price approach could applied bin covering. However, unawareapproach literature.425fiFukunaga & Korf8. Conclusionsstudied bin completion, branch-and-bound approach multi-container packing,knapsack, covering problems. previous work focused item-oriented, branchand-bound strategies assign one item time containers, bin completionbin-oriented branch-and-bound algorithm uses dominance relationship binassignments prune search. presented general framework approach,showed general utility applicability multicontainer problems. proposedseveral extensions bin completion improve efficiency, including nogood pruning,nogood dominance pruning, variable value ordering heuristics, hybrid incrementalundominated completion generation. demonstrated power bin completionapproach developing new, state-of-the-art algorithms three fundamental multicontainer problems. showed bin completion algorithms significantly outperformMulknap (Pisinger, 1999) MTM (Martello & Toth, 1981) algorithms hard MKPinstances. developed new, state-of-the-art algorithm MCCP based bincompletion. showed exploiting powerful dominance criterion, newbin completion algorithms significantly outperform early bin completion algorithmChristofides, Mingozzi, Toth (1979). developed new, state-of-the-art algorithmbin covering based bin completion, showed bin completion algorithm significantly outperforms item-oriented branch bound algorithm Labbe, Laporte,Martello (1995). However, results bin packing competitive stateof-the-art solver based cutting-stock approach. showed fourproblems studied, nogood dominance pruning consistently improves upon performancebin completion nogood pruning.7focused four particular multicontainer problems paper,many similar problems involving assignment objects multiple containerssimilar dominance relationships candidate bin assignments exploited. Examples include generalized assignment problem, widely studied generalizationMKP many applications weight profit item function container assigned (e.g., Cattrysse & Wassenhove, 1992; Martello & Toth, 1990),multiprocessor scheduling, equivalent k-way number partitioning, (DellAmico& Martello, 1995), segregated storage problem (Neebe, 1987; Evans & Tsubakitani,1993). addition, variants problems studied additional constraints,class-constrained multiple knapsack problem (Shachnai & Tamir, 2001a, 2001b;Kellerer et al., 2004) applications multimedia file storage. Exploiting powerful dominance criteria bin completion framework appears promising futuredirection multicontainer problems.One issue bin completion number unique items grows, numberundominated bin assignments grows rapidly. showed hybrid incrementalbranching significantly alleviate problem (Section 6.3.1), drawback limitsutility value-ordering heuristics applied sort undominated bin assignmentsgenerated. Thus, algorithm generates undominated assignments7. previously showed nogood pruning significantly improves performance bin-completion without pruning (Korf, 2003). also confirmed MCCP (Table 4), MKPbin covering preliminary experiments.426fiBin Completion Algorithms Multicontainer Problemsorder conforms desired heuristic value ordering, rather relying sortingassignments generated, area future work.AcknowledgmentsThanks Gleb Belov running solver bin packing test instances.anonymous reviewers provided many helpful comments suggestions improvedpaper. research supported NSF grant No. EIA-0113313,Jet Propulsion Laboratory, California Institute Technology, contractNational Aeronautics Space Administration.ReferencesAssmann, S., Johnson, D., Kleitman, D., & Leung, J. (1984). dual versionone-dimensional binpacking problem. Journal Algorithms, 5, 502525.Belov, G., & Scheithauer, G. (2006). branch-and-cut-and-price algorithm onedimensional stock cutting two-dimensional two-stage cutting. European JournalOperational Research, 171, 85106.Caprara, A., Kellerer, H., & Pferchy, U. (2000a). PTAS multiple-subset sumproblem different knapsack capacities. Information Processing Letters, 73, 111118.Caprara, A., Kellerer, H., & Pferschy, U. (2000b). multiple subset sum problem. SIAMJournal Optimization, 11, 308319.Caprara, A., Kellerer, H., & Pferschy, U. (2003). 3/4-approximation algorithm multiplesubset sum. Journal Heuristics, 9, 99111.Carlyle, M., Knutson, K., & Fowler, J. (2001). Bin covering algorithms second stagelot order matching problem. Journal Operational Research Society,52, 12321243.Cattrysse, D., & Wassenhove, L. V. (1992). survey algorithms generalizedassignment problem. European Journal Operational Research, 60, 260272.Christofides, N., Mingozzi, A., & Toth, P. (1979). Loading problems. Christofides, N.,Mingozzi, A., Toth, P., & Sandi, C. (Eds.), Combinatorial Optimization. John Wiley& Sons.Csirik, J., Frenk, J., Galambos, G., & Kan, A. R. (1991). Probabilistic analysis algorithmsdual bin packing problems. Journal Algorithms, 12, 189203.Csirik, J., Johnson, D., & Kenyon, C. (2001). Better approximation algorithms bincovering. Proc. 12th ACM/SIAM Symposium Discrete Algorithms, pp.557566.DellAmico, M., & Martello, S. (1995). Optimal scheduling tasks identical parallelprocessors. ORSA Journal Computing, 7 (2), 181200.Eilon, S., & Christofides, N. (1971). loading problem. Management Science, 17 (5),259268.427fiFukunaga & KorfEvans, J., & Tsubakitani, S. (1993). Solving segregated storage problem Benderspartitioning. Journal Operational Research Society, 44 (2), 175184.Fahle, T., Schamberger, S., & Sellmann, M. (2001). Symmetry breaking. ProceedingsInternational Conference Constraint Programming, pp. 93107.Focacci, F., & Milano, M. (2001). Global cut framework removing symmetries.Proceedings International Conference Constraint Programming, pp. 7792.Focacci, F., & Shaw, P. (2002). Pruning sub-optimal search branch brances using localsearch. Proc. Fourth International Workshop Integration AI Techniques Constraing Programming Combinatorial Optimisation Problems (CPAI-OR), pp. 181189.Foster, D., & Vohra, R. (1989). Probabilistic analysis heuristic dual bin packingproblem. Information Processing Letters, 31, 287290.Fukunaga, A. (2005). Bin-Completion Algorithms One Dimensional, MulticontainerPacking Problems. Ph.D. thesis, UCLA.Gent, I., & Smith, B. (2000). Symmetry breaking search constraint programming.Proc. European Conference Artificial Intelligence, pp. 599603.Gilmore, P., & Gomory, R. (1961). linear programming approach cutting stockproblem. Operations Research, 9, 849859.Gomes, C., & Selman, B. (2001). Algorithm portfolios. Artificial Intelligence, 126, 4362.Huberman, B., Lukose, R., & Hogg, T. (1997). economic approach hard computationalproblems. Science, 265, 5154.Kalagnanam, J., Davenport, A., & Lee, H. (2001). Computational aspects clearing continuous call double auctions assignment constraints indivisible demand. Electronic Commerce Research, 1, 221238.Kellerer, H., Pferschy, U., & Pisinger, D. (2004). Knapsack Problems. Springer-Verlag.Korf, R. (2002). new algorithm optimal bin packing. Proceedings AAAI, pp.731736.Korf, R. (2003). improved algorithm optimal bin packing. ProceedingsInternational Joint Conference Artificial Intelligence, pp. 12521258.Labbe, M., Laporte, G., & Martello, S. (1995). exact algorithm dual bin packingproblem. Operations Research Letters, 17, 918.Labbe, M., Laporte, G., & Martello, S. (2003). Upper bounds algorithmsmaximum cardinality bin packing problem. European Journal Operational Research,149, 490498.Martello, S., & Toth, P. (1977). upper bound zero-one knapsack problembranch bound algorithm. European Journal Operational Research, 1, 169175.Martello, S., & Toth, P. (1981). bound bound algorithm zero-one multipleknapsack problem. Discrete Applied Mathematics, 3, 275288.Martello, S., & Toth, P. (1990). Knapsack problems: algorithms computer implementations. John Wiley & Sons.428fiBin Completion Algorithms Multicontainer ProblemsMitchell, D., Selman, B., & Levesque, H. (1992). Hard easy distributions SATproblems. Proceedings AAAI, pp. 45965.Neebe, A. (1987). improved, multiplier adjustment procedure segregated storageproblem. Journal Operational Research Society, 38 (9), 815825.Pisinger, D. (1999). exact algorithm large multiple knapsack problems. EuropeanJournal Operational Research, 114, 528541.Rhee, W., & Talagrand, M. (1989). Optimal bin covering items random size. SIAMJournal Computing, 18, 487498.Scholl, A., Klein, R., & Jurgens, C. (1997). BISON: fast hybrid procedure exactlysolving one-dimensional bin packing problem. Computers Operations Research,24 (7), 627645.Shachnai, H., & Tamir, T. (2001a). two class-constrained versions multipleknapsack problem. Algorithmica, 29, 442467.Shachnai, H., & Tamir, T. (2001b). Polynomial time approximation schemes classconstrained packing problems. Journal Scheduling, 4, 313338.Shaw, P. (2004). constraint bin packing. Proceedings 10th International Conference Principles Practice Constraint Programming 2004 (CP-2004),Lecture Notes Computer Science Vol. 3258, pp. 648662. Springer.Valerio de Carvalho, J. (2002). LP models bin packing cutting stock problems.European Journal Operational Research, 141, 253273.Wascher, G., & Gau, T. (1996). Heuristics integer one-dimensional cutting stockproblem: computational study. Spektrum, 18 (3), 131144.429fiJournal Artificial Intelligence Research 28 (2007) 349391Submitted 06/06; published 03/07Closed-Loop Learning Visual Control PoliciesSebastien JodogneJustus H. PiaterJodogne@Montefiore.ULg.ac.beJustus.Piater@ULg.ac.beMontefiore Institute (B28)University Liege, B-4000 Liege, BelgiumAbstractpaper present general, flexible framework learning mappings images actions interacting environment. basic idea introducefeature-based image classifier front reinforcement learning algorithm. classifierpartitions visual space according presence absence highly informative local descriptors incrementally selected sequence attempts removeperceptual aliasing. also address problem fighting overfitting greedyalgorithm. Finally, show high-level visual features generatedpower local descriptors insufficient completely disambiguating aliased states.done building hierarchy composite features consist recursive spatialcombinations visual features. demonstrate efficacy algorithms solvingthree visual navigation tasks visual version classical Car Hill controlproblem.1. IntroductionDesigning robotic controllers quickly becomes challenging problem. Indeed, controllers face huge number possible inputs noisy, must select actions amongcontinuous set, able automatically adapt evolving stochastic environmental conditions. Although real-world robotic task often solveddirectly connecting perceptual space action space given computationalmechanism, mappings usually hard derive hand, especially perceptual space contains images. Evidently, automatic methods generating mappingshighly desirable, many robots nowadays equipped CCD sensors.paper, interested reactive systems learn couple visual perceptionsactions inside dynamic world act reasonably. coupling knownvisual (control) policy. wide category problems called vision-for-action tasks(or simply visual tasks). Despite fifty years years active research artificialintelligence, robotic agents still largely unable solve many real-world visuomotortasks easily performed humans even animals. vision-for-actiontasks notably include grasping, vision-guided navigation manipulation objectsachieve goal. article introduces general framework suitable buildingimage-to-action mappings using fully automatic flexible learning protocol.1.1 Vision-for-Action Reinforcement LearningStrong neuropsychological evidence suggests human beings learn extract useful information visual data interactive fashion, without external supervisor (Gibsonc2007AI Access Foundation. rights reserved.fiJodogne & Piater& Spelke, 1983). evaluating consequence actions environment,learn pay attention visual cues behaviorally important solving task.way, interact outside world, gain expertisetasks (Tarr & Cheng, 2003). Obviously, process task driven, since different tasksnecessarily need make distinctions (Schyns & Rodet, 1997).breakthrough modern artificial intelligence would design artificial systemwould acquire object scene recognition skills based experiencesurrounding environment. state general terms, important researchdirection would design robotic agent could autonomously acquire visual skillsinteractions uncommitted environment order achieve setgoals. Learning new visual skills dynamic, task-driven fashion completepriori unknown visual task known purposive vision paradigm (Aloimonos, 1990).One plausible framework learn image-to-action mappings according purposive vision Reinforcement Learning (RL) (Bertsekas & Tsitsiklis, 1996; Kaelbling, Littman,& Moore, 1996; Sutton & Barto, 1998). Reinforcement learning biologically-inspiredcomputational framework generate nearly optimal control policies automaticway, interacting environment. RL founded analysis so-calledreinforcement signal . Whenever agent takes decision, receives feedback realnumber evaluates relevance decision. biological perspective,signal becomes positive, agent experiences pleasure, talk reward .Conversely, negative reinforcement implies sensation pain, correspondspunishment. reinforcement signal arbitrarily delayed actionsresponsible it. Now, RL algorithms able map every possible perceptionaction maximizes reinforcement signal time. framework, agentnever told optimal action facing given percept, whether onedecisions optimal. Rather, agent discover promisingactions constituting representative database interactions, understanding influence decisions future reinforcements. Schematically, RL liessupervised learning (where external teacher gives correct action agent)unsupervised learning (in clue goodness action given).RL successful applications, example turning computer excellentBackgammon player (Tesauro, 1995), solving Acrobot control problem (Yoshimoto,Ishii, & Sato, 1999), making quadruped robot learn progressively walk withouthuman intervention (Huber & Grupen, 1998; Kimura, Yamashita, & Kobayashi, 2001; Kohl& Stone, 2004), riding bicycle (Randlv & Alstrm, 1998; Lagoudakis & Parr, 2003)controlling helicopter (Bagnell & Schneider, 2001; Ng, Coates, Diel, Ganapathi, Schulte,Tse, Berger, & Liang, 2004). major advantages RL protocol fullyautomatic, imposes weak constraints environment.Unfortunately, standard RL algorithms highly sensitive number distinctpercepts well noise results sensing process. general problemoften referred Bellman curse dimensionality (Bellman, 1957). Thus, highdimensionality noise inherent images forbid use basic RL algorithmsdirect closed-loop learning image-to-action mappings according purposive vision.350fiClosed-Loop Learning Visual Control Policies1.2 Achieving Purposive Vision Reinforcement Learningexists variety work RL specific robotic problems involving perceptualspace contains images. instance, Schaal (1997) uses visual feedback solvepole-balancing task. RL used control vision-guided underwater robotic vehicle (Wettergreen, Gaskett, & Zelinsky, 1999). recently, Kwok Fox (2004)demonstrated applicability RL learning sensing strategies using Aibo robots.Reinforcement learning also used learn strategies view selection (Paletta &Pinz, 2000) sequential attention models (Paletta, Fritz, & Seifert, 2005). Let us alsomention use reinforcement learning vision-guided tasks ball kicking (Asada, Noda, Tawaratsumida, & Hosoda, 1994), ball acquisition (Takahashi, Takeda,& Asada, 1999), visual servoing (Gaskett, Fletcher, & Zelinsky, 2000), robot docking (Weber, Wermter, & Zochios, 2004; Martnez-Marn & Duckett, 2005) obstacle avoidance (Michels, Saxena, & Ng, 2005). Interestingly, RL also used way tuning high-level parameters image-processing applications. example, PengBhanu (1998) introduce RL algorithms image segmentation, whereas Yin (2002) proposes algorithms multilevel image thresholding, uses entropy reinforcementsignal.applications preprocess images extract high-level informationobserved scene directly relevant task solved feedsRL algorithm. requires prior assumptions images perceived sensorsagent, physical structure task itself. preprocessing steptask specific coded hand. contrasts objectives, consistintroducing algorithms able learn directly connect visual space actionspace, without using manually written code without relying prior knowledgetask solved. aim develop general algorithms applicablevisual task formulated RL framework.noticeable exception work Iida et al. (2002) apply RL seek reachtargets, push boxes (Shibata & Iida, 2003) real robots. work, raw visualsignals directly feed neural network trained actor-critic architecture.examples, visual signal downscaled averaged monochrome (i.e. two-color)image 64 24 = 1536 pixels. output four infrared sensors also addedperceptual input. approach effective specific tasks, processused highly controlled environment. Real-world images much richercould undergo strong reduction size.1.3 Local-Appearance Paradigmpaper, propose algorithms rely extraction visual featuresway achieve compact state spaces used input traditional RLalgorithms. Indeed, buried noise confusion visual cues, images containhints regularity. regularities captured important notion visual features.Loosely speaking, visual feature representation aspect local appearance,e.g. corner formed two intensity edges, spatially localized texture signature,color. Therefore, analyze images, often sufficient computer program extractuseful information visual signal, focusing attention robust highly351fiJodogne & PiaterperceptsImage Classifierreinforcementsdetected visual classinformative visual featuresReinforcement LearningactionsFigure 1: structure Reinforcement Learning Visual Classes.informative patterns percepts. program thereafter seek characteristicappearance observed scenes objects.actually basic postulate behind local-appearance methodsmuch success computer vision applications image matching, image retrievalobject recognition (Schmid & Mohr, 1997; Lowe, 2004). rely detectiondiscontinuities visual signal thanks interest point detectors (Schmid, Mohr, &Bauckhage, 2000). Similarities images thereafter identified using local descriptionneighborhood around interest points (Mikolajczyk & Schmid, 2003): two imagesshare sufficient number matching local descriptors, considered belongvisual class.Local-appearance techniques time powerful flexible,robust partial occlusions, require segmentation 3D models scenes.seems therefore promising introduce, front RL algorithm, feature-basedimage classifier partitions visual space finite set distinct visual classesaccording local-appearance paradigm, focusing attention agenthighly distinctive local descriptors located interest points visual stimuli.symbol corresponding detected visual class could given inputclassical, embedded RL algorithm, shown Figure 1.preprocessing step intended reduce size input domain, thus enhancing rate convergence, generalization capabilities well robustnessRL noise visual domains. Importantly, family visual featuresapplied wide variety visual tasks, thus preprocessing step essentially generaltask-independent. central difficulty dynamic selection discriminativevisual features. selection process group images share similar, task-specificproperties together visual class.1.4 Contributionskey technical contribution paper consists introduction reinforcementlearning algorithms used perceptual space contains images.developed algorithms rely task-specific pre-treatment. consequence,used vision-for-action task formalized Markov DecisionProblem. review three major contributions discussed paper.352fiClosed-Loop Learning Visual Control Policies1.4.1 Adaptive Discretization Visual Spacefirst contribution propose new algorithm called Reinforcement Learning VisualClasses (RLVC) combines aforementioned ideas. RLVC iterative algorithmsuitable learning direct image-to-action mappings taking advantagelocal-appearance paradigm. consists two simultaneous, interleaved learning processes:Reinforcement learning mapping visual classes actions, incremental buildingfeature-based image classifier.Initially, image classifier contains one single visual class, imagesmapped class. course, introduces kind perceptual aliasing (or hiddenstate) (Whitehead & Ballard, 1991): optimal decisions cannot always made, sincepercepts requiring different reactions associated class. agentisolates aliased classes. Since external supervisor, agent relystatistical analysis earned reinforcements. detected aliased class, agentdynamically selects new visual feature distinctive, i.e. best disambiguatesaliased percepts. extracted local descriptor used refine classifier. way,stage algorithm, number visual classes classifier grows. Newvisual features learned perceptual aliasing vanishes. resulting image classifierfinally used control system.approach primarily motivated strong positive results McCallums U-Treealgorithm (McCallum, 1996). essence, RLVC adaptation U-Tree visual spaces,though internals algorithms different. originality RLVC liesexploitation successful local-appearance features. RLVC selects subset highlyrelevant features fully closed-loop, purposive learning process. showalgorithm practical interest, successfully applied several simulatedvisual navigation tasks.1.4.2 Compacting Visual Policiesgreedy nature, RLVC prone overfitting. Splitting one visual classpotentially improve control policy visual classes. Therefore, splittingstrategy get stuck local minima: split made subsequently provesuseless, cannot undone original description RLVC. second contributionprovide RLVC possibility aggregating visual classes share similarproperties. least three potential benefits:1. Useless features discarded, enhances generalization capabilities;2. RLVC reset search good features;3. number samples embedded RL algorithm disposalvisual class increased, results better visual control policies.Experiments indeed show improvement generalization abilities, well reduction number visual classes selected features.353fiJodogne & Piater1.4.3 Spatial Combinations Visual FeaturesFinally, efficacy RLVC clearly depends discriminative power visualfeatures. power insufficient, algorithm able completely removealiasing, produce sub-optimal control policies. Practical experimentssimulated visual navigation tasks exhibit deficiency, soon number detectedvisual features reduced features made similar using less sensitivemetric. Now, objects encountered world composed number distinctconstituent parts (e.g. face contains nose two eyes, phone possesses keypad).parts recursively composed sub-parts (e.g. eye containsiris eyelashes, keypad composed buttons). hierarchical physical structurecertainly imposes strong constraints spatial disposition visual features.third contribution show highly informative spatial combinations visualfeatures iteratively constructed framework RLVC. result promisingpermits construction features increasingly higher levels discriminativepower, enabling us tackle visual tasks unsolvable using individual point featuresalone. best knowledge, extension RLVC appearsfirst attempt build visual feature hierarchies closed-loop, interactive purposivelearning process.2. Overview Reinforcement Learningframework relies theory RL, introduced section. RL,environment traditionally modeled Markov Decision Process (MDP). MDPtuple hS, A, , Ri, finite set states, finite set actions,probabilistic transition function S, R reinforcement functionR. MDP obeys following discrete-time dynamics: time t, agenttakes action environment lies state st , agent perceives numericalreinforcement rt+1 = R(st , ), reaches state st+1 probability (st , , st+1 ).Thus, point view agent, interaction environment definedquadruple hst , , rt+1 , st+1 i. Note definition Markov decision processesassumes full observability state space, means agent abledistinguish states environment using sensors. allows ustalk indifferently states percepts. visual tasks, set images.percept-to-action mapping fixed probabilistic function : 7 statesactions. percept-to-action mapping tells agent probabilitychoose action faced percept. RL terminology, mapping calledstationary Markovian control policy. infinite sequence interactions startingstate st , discounted returnRt =Xrt+i+1 ,(1)i=0[0, 1[ discount factor gives current value future reinforcements. Markov decision problem given MDP find optimal percept-to-actionmapping maximizes expected discounted return, whatever starting state is.354fiClosed-Loop Learning Visual Control Policiespossible prove problem well-defined, optimal percept-to-actionmapping always exists (Bellman, 1957).Markov decision problems solved using Dynamic Programming (DP) algorithms(Howard, 1960; Derman, 1970). Let percept-to-action mapping. Let us callstate-action value function Q (s, a) , function giving stateaction expected discounted return obtained starting state s, taking actiona, thereafter following mapping :Q (s, a) = E {Rt | st = s, = a} ,(2)E denotes expected value agent follows mapping . Let us also defineH transform Q functions Q functionsX(HQ)(s, a) = R(s, a) +(s, a, s0 ) maxQ(s0 , a0 ),(3)0s0A. Note H transform equally referred Bellmanbackup operator state-action value functions. optimal mappings given MDPshare Q function, denoted Q called optimal state-action value function,always exists satisfies Bellmans so-called optimality equation (Bellman, 1957)HQ = Q .(4)optimal state-action value function Q known, optimal deterministic perceptto-action mapping easily derived choosing(s) = argmax Q (s, a),(5)aAS. Another useful concept DP theory optimal valuefunction V . state S, V (s) corresponds expected discounted returnagent always chooses optimal action encountered state, i.e.V (s) = max Q (s, a).aA(6)Dynamic Programming includes well-known Value Iteration (Bellman, 1957), Policy Iteration (Howard, 1960) Modified Policy Iteration (Puterman & Shin, 1978) algorithms. Value Iteration learns optimal state-action value function Q , whereas PolicyIteration Modified Policy Iteration directly learn optimal percept-to-action mapping.RL set algorithmic methods solving Markov decision problemsunderlying MDP known (Bertsekas & Tsitsiklis, 1996; Kaelbling et al., 1996; Sutton& Barto, 1998). Precisely, RL algorithms assume knowledge R.input RL algorithms basically sequence interactions hst , , rt+1 , st+1 agentenvironment. RL techniques often divided two categories:1. Model-based methods first build estimate underlying MDP (e.g.computing relative frequencies appear sequence interactions),use classical DP algorithms Value Policy Iteration;2. Model-free methods SARSA (Rummery & Niranjan, 1994), D() (Barto,Sutton, & Anderson, 1983; Sutton, 1988), popular Q-learning (Watkins,1989), compute estimate.355fiJodogne & Piater3. Reinforcement Learning Visual Classesdiscussed Introduction, propose insert image classifier RLalgorithm. classifier maps visual stimuli set visual classes accordinglocal-appearance paradigm, focusing attention agent highly distinctivelocal descriptors detected interest points images.3.1 Incremental Discretization Visual SpaceFormally, let us call D, infinite set local descriptors spannedchosen local description method. elements equivalently referred visualfeatures. Usually, corresponds Rn n 1. assume existence visualfeature detector , Boolean function : 7 B testing whether given imageexhibits given local descriptor one interest points (Schmid et al., 2000).suitable metric used test similarity two visual features, e.g. MahalanobisEuclidean distance.image classifier iteratively refined. incremental process, naturalway implement image classifiers use binary decision trees. internalnodes labeled visual feature, presence tested node.leaves trees define set visual classes, hopefully much smalleroriginal visual space, upon possible apply directly usual RLalgorithm. classify image, system starts root node, progressestree according result feature detector visual feature founddescent, reaching leaf.summarize, RLVC builds sequence C0 , C1 , C2 , . . . growing decision trees,sequence attempts remove perceptual aliasing. initial classifier C0 mapsinput images single visual class V0,1 . stage k, classifier Ck partitionsvisual perceptual space finite number mk visual classes {Vk,1 , . . . , Vk,mk }.3.2 Learning Architectureresulting learning architecture called Reinforcement Learning Visual Classes(RLVC) (Jodogne & Piater, 2005a). basic idea behind algorithms, namelyiterative learning decision tree, primarily motivated adaptive-resolution techniquespreviously introduced reinforcement learning, notably McCallumsU-Tree algorithm (McCallum, 1996). section, idea showed extremelyfruitful suitably adapted visual spaces. links RLVC adaptiveresolution techniques thoroughly discussed Section 3.6.components RLVC depicted Figure 2. in-depth discussioncomponents given next sections. time being, reviewthem:RL algorithm: classifier sequence, arbitrary, standard RL algorithmapplied. provides information optimal state-action function,optimal value function optimal policy induced current classifierCk . purpose computations, either new interactions acquired,356fiClosed-Loop Learning Visual Control PoliciesFigure 2: different components RLVC algorithm.database previously collected interactions exploited. componentcovered Sections 3.3.1 3.3.2.Aliasing detector: agent learned visual classes required completetask, viewpoint embedded RL algorithm, input spacepartially observable. aliasing detector extracts classes perceptualaliasing occurs, analysis Bellman residuals. Indeed, explainedSection 3.3.3, exist tight relations perceptual aliasing Bellmanresiduals. aliased class detected, RLVC stops.Feature generator: applied RL algorithm, database interactionshst , , rt+1 , st+1 available. feature generator component produces set Fcandidate visual features aliased class Vk,i . features usedrefine classifier chosen among set candidates. stepexposed Sections 3.4 5.Feature selector: set candidate features F built aliased visualclass Vk,i , component selects visual feature f F best reducesperceptual aliasing. candidate feature discriminant, component returnsconventional bottom symbol . feature selector RLVC describedSection 3.4.Classifier refinement: leaves correspond aliased classes featurebased image classifier replaced internal node testing presence absenceselected visual features.Post-processing: optional component invoked every refinement, corresponds techniques fighting overfitting. Details given Section 4.general outline RLVC described Algorithm 1. Note experiments contained paper, model-based RL algorithms applied static357fiJodogne & PiaterAlgorithm 1 General structure RLVC1: k 02: mk 13: Ck binary decision tree one leaf4: repeat5:Collect N interactions hst , , rt+1 , st+16:Apply arbitrary RL algorithm sequence mapped Ck7:Ck+1 Ck8:{1, . . . , mk }9:aliased(Vk,i )10:F generator ({st | Ck (st ) = Vk,i })11:f selector (Vk,i , F )12:f 6=13:Ck+1 , refine Vk,i testing f14:mk+1 mk+1 + 115:end16:end17:end18:k k+119:post-process(Ck )20: Ck = Ck1databases interactions fifth step Algorithm 1. databases collectedusing fully randomized exploration policy. choice guided easeimplementation presentation; way collecting experience could usedwell, example re-sampling new database interactions iteration RLVC.crucial point RLVC generates representation visual control policiesset collected visuomotor experience, makes RLVC interactive. following sections describe remaining algorithms, namely aliased, generator, selectorpost-process.3.3 Detection Aliased Visual Classesdiscuss aliasing detected classifier Ck .3.3.1 Projection MDP Image ClassifierFormally, image classifier Ck converts sequence N interactionshst , , rt+1 , st+1 i,mapped sequence N quadrupleshCk (st ), , rt+1 , Ck (st+1 )i,upon embedded RL algorithm applied. Let us define mapped MDP MkMDPhSk , A, Tk , Rk i,358fiClosed-Loop Learning Visual Control Policiesobtained mapped sequence, Sk set visual classesknown Ck , Tk Rk computed using relative frequenciesmapped sequence, follows.Consider two visual classes V, V 0 {Vk,1 , . . . , Vk,mk } one action A. definefollowing functions:(V, a) equals 1 Ck (st ) = V = a, 0 otherwise;(V, a, V 0 ) equals 1 Ck (st ) = V , Ck (st+1 ) = V 0 = a, 0 otherwise;(V, a) number ts (V, a) = 1.Using notation, write:Sk = {Vk,1 , . . . , Vk,mk };P0Tk (V, a, V 0 ) = Nt=1 (V, a, V ) /(V, a);PRk (V, a) = Nt=1 rt (V, a)/(V, a).3.3.2 Optimal Q Function Mapped MDPmapped MDP Mk induces optimal Q function domain Sk0denoted Q0k . Computing Qk difficult: general, may exist MDP definedstate space Sk action space generate given mapped sequence,since latter necessarily Markovian anymore. Thus, RL algorithm runmapped sequence, might converge toward Q0k , even converge all.However, applied mapped sequence, model-based RL method (cf. Section 2)used compute Q0k Mk used underlying model. conditions,Q-learning also converges optimal Q function mapped MDP (Singh, Jaakkola,& Jordan, 1995).turn, function Q0k induces another Q function initial domainrelation:Qk (s, a) = Q0(7)k (Ck (s), a) ,absence aliasing, agent would perform optimally, Qk would correspondQ , according Bellman theorem states uniqueness optimal Q function (cf.Section 2). Equation 4, functionBk (s, a) = (HQk )(s, a) Qk (s, a)(8)therefore measure aliasing induced image classifier Ck . RL terminology,Bk Bellman residual function Qk (Sutton, 1988). basic idea behind RLVCrefine states non-zero Bellman residual.3.3.3 Measuring AliasingConsider time stamp database interactions hst , , rt+1 , st+1 i. AccordingEquation 8, Bellman residual corresponds state-action pair (st , ) equalsXBk (st , ) = R(st , ) +(st , , s0 ) maxQk (s0 , a0 ) Qk (st , ).(9)0s0359fiJodogne & PiaterAlgorithm 2 Aliasing Criterion1: aliased(Vk,i ) :2:3:{t | Ck (st ) = Vk,i = a}4:2 () >5:return true6:end7:end8:return falseUnfortunately, RL agent access transition probabilitiesreinforcement function R MDP modeling environment. Therefore, Equation 9 cannot directly evaluated. similar problem arises Q-learning (Watkins,1989) Fitted Q Iteration (Ernst, Geurts, & Wehenkel, 2005) algorithms.algorithms solve problem considering stochastic version time differencedescribed Equation 9: valueX(st , , s0 ) maxQk (s0 , a0 )(10)0s0indeed estimatedmaxQk (s0 , a0 ),0(11)successor s0 chosen probability (st , , s0 ). following transitionsenvironment ensures making transition st st+1 probability (st , , st+1 ).Thus= rt+1 + maxQk (st+1 , a0 ) Qk (st , )a000= rt+1 + maxQ0k Ck (st+1 ) , Qk (Ck (st ), a)0(12)(13)unbiased estimate Bellman residual state-action pair (st , ) (Jaakkola,Jordan, & Singh, 1994).1 importantly, system deterministic absenceperceptual aliasing, estimates equal zero. Therefore, nonzero potentiallyindicates presence perceptual aliasing visual class Vt = Ck (st ) respectaction . criterion detecting aliased classes consists computing Q0kfunction, sweeping interactions hst , , rt+1 , st+1 identify nonzero. practice, assert presence aliasing variance exceeds giventhreshold . summarized Algorithm 2, 2 () denotes variance setsamples.3.4 Generation Selection Distinctive Visual Featuresaliasing detected visual class Vk,i Sk respect action a,need select local descriptor best explains variations set values1. worth noticing corresponds updates would applied Q-learning,known learning rate time t.360fiClosed-Loop Learning Visual Control PoliciesAlgorithm 3 Canonical feature generator1: generator({s1 , . . . , sn }) :2:F {}3:{1, . . . , n}4:(x, y) (x, y) interest point si5:F F {symbol(descriptor(si , x, y))}6:end7:end8:return Fcorresponding Vk,i a. local descriptor chosen among set candidatevisual features F .3.4.1 Extraction Candidate FeaturesInformally, canonical way building F visual class Vk,i consists in:1. identifying collected visual percepts st Ck (st ) = Vk,i ,2. locating interest points selected images st ,3. adding F local descriptor interest points.corresponding feature generator detailed Algorithm 3. latter algorithm,descriptor(s, x, y) returns local description point location (x, y) image s,symbol(d) returns symbol corresponds local descriptor F accordingused metric. However, complex strategies generating visual featuresused. strategy builds spatial combinations individual point featurespresented Section 5.3.4.2 Selection Candidate Featuresproblem choosing candidate feature reduces variations setreal-valued Bellman residuals regression problem, suggest adaptationpopular splitting rule used CART algorithm building regression trees (Breiman,Friedman, & Stone, 1984).2CART, variance used impurity indicator: split selected refineparticular node one leads greatest reduction sum squareddifferences response values learning samples corresponding nodemean. formally, let = {hxi , yi i} set learning samples, xi Rninput vectors real numbers, yi R real-valued outputs. CART selectsfollowing candidate feature:vvf = argmin pv 2+ pv 2,(14)vF2. Note previous work, used splitting rule borrowed building classificationtrees (Quinlan, 1993; Jodogne & Piater, 2005a).361fiJodogne & PiaterAlgorithm 4 Feature Selection1: selector(Vk,i , F ) :2:f{Best feature found far}3:r +{Variance reduction induced f }4:5:{t | Ck (st ) = Vk,i = a}6:visual feature f F7:{t | st exhibits f }8:{t | st exhibit f }9:|S |/|T |10:|S |/|T |11:r 2 (S ) + 2 (S )12:r < r distributions (S , ) significantly different13:f f14:r15:end16:end17:end18:return fpv (resp. pv ) proportion samples exhibit (resp. exhibit)v (resp. v ) set samples exhibit (resp. exhibit)feature v,feature v. idea directly transferred framework, set xicorresponds set interactions hst , , rt+1 , st+1 i, set yi correspondsset . written explicitly Algorithm 4.algorithms exploit stochastic version Bellman residuals. course, real environments general non-deterministic, generates variations Bellman residualsconsequence perceptual aliasing. RLVC made somewhat robustvariability introducing statistical hypothesis test: candidate feature,Students ttest used decide whether two sub-distributions feature inducessignificantly different. approach also used U-Tree (McCallum, 1996).3.5 Illustration Simple Navigation Taskevaluated system abstract task closely parallels real-world scenarioavoiding unnecessary complexity. consequence, sensor model use mayseem unrealistic; better visual sensor model exploited Section 4.4.RLVC succeeded solving continuous, noisy visual navigation task depictedFigure 3. goal agent reach fast possible one two exitsmaze. set possible locations continuous. location, agent fourpossible actions: Go up, right, down, left. Every move altered Gaussian noise,standard deviation 2% size maze. Glass walls presentmaze. Whenever move would take agent wall outside maze, locationchanged.362fiClosed-Loop Learning Visual Control PoliciesFigure 3: continuous, noisy navigation task. exits maze indicated boxescross. Walls glass identified solid lines. agent depictedcenter figure. one four possible moves representedarrow, length corresponds resulting move. sensors returnpicture corresponds dashed portion image.agent earns reward 100 exit reached. move, includingforbidden ones, generates zero reinforcement. agent succeeds escapingmaze, arrives terminal state every move gives rise zero reinforcement.task, set 0.9. Note agent faced delayed reward problem,must take distance two exits consideration choosingattractive one.maze ground carpeted color image 1280 1280 pixelsmontage pictures COIL-100 database (Nene, Nayar, & Murase, 1996).agent direct access (x, y) position maze. Rather, sensorstake picture surrounding portion ground. portion largerblank areas, makes input space fully observable. Importantly, glass wallstransparent, sensors also return portions tapestry behindthem. Therefore, way agent directly locate walls. obligedidentify regions maze action change location.363fiJodogne & PiaterFigure 4: deterministic image-to-action mapping results RLVC, sampledregularly-spaced points. manages choose correct action location.experiment, used color differential invariants visual features (Gouet& Boujemaa, 2001). entire tapestry includes 2298 different visual features. RLVCselected 200 features, corresponding ratio 9% entire set possible features.computation stopped generation 84 image classifiers (i.e. k reached84), took 35 minutes 2.4GHz Pentium IV using databases 10,000 interactions.205 visual classes identified. small number, compared numberperceptual classes would generated discretization maze agentknows (x, y) position. example, reasonably sized 2020 grid leads 400 perceptualclasses.Figure 4 shows optimal, deterministic image-to-action mapping resultslast obtained image classifier Ck :(s) = argmax Qk (s, a) = Q0k (Ck (s), a) .aA364(15)fiClosed-Loop Learning Visual Control Policies(a)(b)Figure 5: (a) optimal value function, agent direct access (x, y)position maze set possible locations discretized50 50 grid. brighter location, greater value. (b) final valuefunction obtained RLVC.Figure 5 compares optimal value function discretized problem one obtained RLVC. similarity two pictures indicates soundnessapproach. Importantly, RLVC operates neither pretreatment, human intervention. agent initially aware visual features important task.Moreover, interest selecting descriptors clear application: direct, tabularrepresentation Q function considering Boolean combinations features would22298 4 cells.behavior RLVC real-word images also investigated. navigationrules kept identical, tapestry replaced panoramic photograph3041 384 pixels subway station, depicted Figure 6. RLVC took 101 iterationscompute mapping right Figure 6. computation time 159 minutes2.4GHz Pentium IV using databases 10,000 interactions. 144 distinct visual featuresselected among set 3739 possible ones, generating set 149 visual classes. again,resulting classifier fine enough obtain nearly optimal image-to-action mappingtask.3.6 Related WorkRLVC thought performing adaptive discretization visual spacebasis presence visual features. Previous reinforcement learning algorithmsexploit presence perceptual features various contexts discussed.365fiJodogne & Piater(a)(b)Figure 6: (a) navigation task real-world image, using conventionsFigure 3. (b) deterministic image-to-action mapping computed RLVC.366fiClosed-Loop Learning Visual Control Policies3.6.1 Perceptual Aliasingexplained above, incremental selection set informative visual features necessarily leads temporary perceptual aliasing, RLVC tries remove. generally,perceptual aliasing occurs whenever agent cannot always take right basispercepts.Early work reinforcement learning tackled general problem two distinctways: Either agent identifies avoids states perceptual aliasing occurs(as Lion algorithm, see Whitehead & Ballard, 1991), tries build short-termmemory allow remove ambiguities percepts (as predictivedistinctions approach, see Chrisman, 1992). sketchily, two algorithms detectpresence perceptual aliasing analysis sign Q-learning updates.possibility managing short-term memory led development PartiallyObservable Markov Decision Processes (POMDP) theory (Kaelbling, Littman, & Cassandra,1998), current state random variable percepts.Although approaches closely related perceptual aliasing RLVC temporarily introduces, consider exploitation perceptual features. Indeed,tackle structural problem given control task, and, such, assumeperceptual aliasing cannot removed. consequence, approaches orthogonalresearch interest, since ambiguities RLVC generates removedrefining image classifier. fact, techniques tackle lack information inherent used sensors, whereas goal handle surplus information relatedhigh redundancy visual representations.3.6.2 Adaptive Resolution Finite Perceptual SpacesRLVC performs adaptive discretization perceptual space autonomous,task-driven, purposive selection visual features. Work RL incrementally partitionslarge (either discrete continuous) perceptual space piecewise constant valuefunction usually referred adaptive-resolution techniques. Ideally, regionsperceptual space high granularity present needed,lower resolution used elsewhere. RLVC adaptive-resolutionalgorithm. review several adaptive-resolution methods previouslyproposed finite perceptual spaces.idea adaptive-resolution techniques reinforcement learning goes backG Algorithm (Chapman & Kaelbling, 1991), inspired approachesdiscussed below. G Algorithm considers perceptual spaces madefixed-length binary numbers. learns decision tree tests presence informativebits percepts. algorithm uses Students t-test determine bitb percepts mapped given leaf, state-action utilities statesb set significantly different state-action utilities statesb unset. bit found, corresponding leaf split. process repeatedleaf. method able learn compact representations, even thoughlarge number irrelevant bits percepts. Unfortunately, region split,information associated region lost, makes slow learning.367fiJodogne & PiaterConcretely, G Algorithm solve task whose perceptual space contains 2100 distinctpercepts, corresponds set binary numbers length 100 bits.McCallums U-Tree algorithm builds upon idea combining selective attentionmechanism inspired G Algorithm short-term memory enables agentdeal partially observable environments (McCallum, 1996). Therefore, McCallumsalgorithms keystone reinforcement learning, unify G Algorithm (Chapman & Kaelbling, 1991) Chrismans predictive distinctions (Chrisman, 1992).U-Tree incrementally grows decision tree Kolmogorov-Smirnov tests.succeeded learning behaviors driving simulator. simulator, percept consistsset 8 discrete variables whose variation domains contain 2 6 values,leading perceptual space 2, 592 possible percepts. Thus, size perceptualspace much smaller visual space. However, task difficultphysical state space partially observable perceptual space: drivingtask contains 21, 216 physical states, means several physical states requiringdifferent reactions mapped percept sensors agent.U-Tree resolves ambiguities percepts testing presence perceptualfeatures percepts encountered previously history system.end, U-Tree manages short-term memory. paper, partially observableenvironments considered. challenge rather deal huge visual spaces,without hand-tuned pre-processing, difficult, novel research direction.3.6.3 Adaptive Resolution Continuous Perceptual Spacesimportant notice methods adaptive resolution large-scale, finiteperceptual spaces use fixed set perceptual features hard-wired.distinguished RLVC samples visual features possibly infinite visual featurespace (e.g. set visual features infinite), makes prior assumptionsmaximum number useful features. point view, RLVC closeradaptive-resolution techniques continuous perceptual spaces. Indeed, techniquesdynamically select new relevant features whole continuum.first adaptive-resolution algorithm continuous perceptual spaces Darling algorithm (Salganicoff, 1993). algorithm, like current algorithmscontinuous adaptive resolution, splits perceptual space using thresholds.purpose, Darling builds hybrid decision tree assigns label pointperceptual space. Darling fully on-line incremental algorithm equippedforgetting mechanism deletes outdated interactions. however limitedbinary reinforcement signals, takes immediate reinforcements account,Darling much closer supervised learning reinforcement learning.Parti-Game algorithm (Moore & Atkeson, 1995) produces goal-directed behaviorscontinuous perceptual spaces. Parti-Game also splits regions deems important,using game-theoretic approach. Moore Atkeson show Parti-Game learncompetent behavior variety continuous domains. Unfortunately, approachcurrently limited deterministic domains agent greedy controllergoal state known. Moreover, algorithm searches solutiongiven task, try find optimal one.368fiClosed-Loop Learning Visual Control PoliciesContinuous U-Tree algorithm extension U-Tree adapted continuous perceptual spaces (Uther & Veloso, 1998). like Darling, Continuous U-Treeincrementally builds decision tree splits perceptual space finite set hypercubes, testing thresholds. Kolmogorov-Smirnov sum-of-squared-errors useddetermine split node decision tree. Pyeatt Howe (2001) analyzeperformance several splitting criteria variation Continuous U-Tree.conclude Students t-test leads best performance, motivates usestatistical test RLVC (cf. Section 3.4).Munos Moore (2002) proposed Variable Resolution Grids. algorithmassumes perceptual space compact subset Euclidean space, beginscoarse, grid-based discretization state space. contrast abstractalgorithms section, value function policy vary linearly within region.Munos Moore use Kuhn triangulation efficient way interpolate value function within regions. algorithm refines approximation refining cells accordingsplitting criterion. Munos Moore explore several local heuristic measures importance splitting cell including average corner-value differences, variancecorner-value differences, policy disagreement. also explore global heuristic measures involving influence variance approximated system. Variable ResolutionGrids probably advanced adaptive-resolution algorithm available far.3.6.4 Discussionsummarize, several algorithms similar spirit RLVC proposedyears. Nevertheless, work appears first learn direct image-toaction mappings reinforcement learning. Indeed, none reinforcement learningmethods combines following desirable properties RLVC: (1) set relevant perceptual features chosen priori hand, selection process fullyautomatic require human intervention; (2) visual perceptual spaces explicitly considered appearance-based visual features; (3) highly informativeperceptual features drawn possibly infinite set.advantages RLVC essentially due fact candidate visualfeatures selected informative: also ranked accordinginformation-theoretic measure inspired decision tree induction (Breiman et al.,1984). ranking required, vision-for-action tasks induce large number visualfeatures (a typical image contains thousand them). kind criterionranks features, though already considered Variable Resolution Grids (Munos & Moore,2002), seems new discrete perceptual spaces.RLVC defined independently fixed RL algorithm, similar spiritContinuous U-Tree (Uther & Veloso, 1998), major exception RLVC dealsBoolean features, whereas Continuous U-Tree works continuous input space. Furthermore, version RLVC presented paper uses variance-reduction criterionranking visual features. criterion, though already considered Variable ResolutionGrids, seems new discrete perceptual spaces.369fiJodogne & Piater4. Compacting Visual Policieswritten Section 1.4.2, original version RLVC subject overfitting (Jodogne &Piater, 2005b). simple heuristic avoid creation many visual classes simplybound number visual classes refined stage algorithm,since splitting one visual class potentially impact Bellman residualsvisual classes. practice, first try split classes samplesconsidering others, since evidence variance reduction first.tests, systematically apply heuristics. However, often insufficient takenalone.4.1 Equivalence Relations Markov Decision ProcessesSince apply embedded RL algorithm stage k RLVC, properties likeoptimal value function Vk (), optimal state-action value function Qk (, ) optimalcontrol policy k () known mapped MDP Mk . Using properties, easydefine whole range equivalence relations visual classes. instance,given threshold R+ , list hereunder three possible equivalence relations pairvisual classes (V, V 0 ):Optimal Value Equivalence:|Vk (V ) Vk (V 0 )| .Optimal Policy Equivalence:|Vk (V ) Qk (V 0 , k (V ))||Vk (V 0 ) Qk (V, k (V 0 ))| .Optimal State-Action Value Equivalence:(a A) |Qk (V, a) Qk (V 0 , a)| .therefore propose modify RLVC that, periodically, visual classesequivalent respect one criteria merged together. experimentallyobserved conjunction first two criteria tends lead best performance.way, RLVC alternatively splits merges visual classes. compaction phasedone often, order allow exploration. best knowledge,possibility investigated yet framework adaptive-resolution methodsreinforcement learning.original version RLVC, visual classes correspond leaves decisiontree. using decision trees, aggregation visual classes achievedstarting bottom tree recursively collapsing leaves, dissimilar leavesfound. operation close post-pruning framework decision treesmachine learning (Breiman et al., 1984). practice, means classessimilar properties, reached one another making numberhops upwards downwards, extremely unlikely matched. greatly reducesinterest exploiting equivalence relations.drawback due rather limited expressiveness decision trees. decisiontree, visual class corresponds conjunction visual feature literals, defines370fiClosed-Loop Learning Visual Control Policiespath root decision tree one leaf. take full advantage equivalencerelations, necessary associate, visual class, arbitrary union conjunctionsvisual features. Indeed, exploiting equivalence relations, visual classesresult sequence conjunctions (splitting) disjunctions (aggregation). Thus,expressive data structure would able represent general, arbitrary Booleancombinations visual features required. data structure introduced nextsection.4.2 Using Binary Decision Diagramsproblem representing general Boolean functions extensively studiedfield computer-aided verification, since abstract behavior logical electronicdevices. fact, whole range methods representing state space richerricher domains developed last years, Binary Decision Diagram(BDD) (Bryant, 1992), Number Queue Decision Diagrams (Boigelot, 1999), UpwardClosed Sets (Delzanno & Raskin, 2000) Real Vector Automata (Boigelot, Jodogne, &Wolper, 2005).framework, BDD particularly well-suited tool. acyclic graph-basedsymbolic representation encoding arbitrary Boolean functions, much success field computer-aided verification (Bryant, 1992). BDD uniqueordering variables fixed, different variable orderings lead different sizesBDD, since variables discarded reordering process. Althoughproblem finding optimal variable ordering coNP-complete (Bryant, 1986), automatic heuristics practice find orderings close optimal. interestingcase, since reducing size BDD potentially discards irrelevant variables,correspond removing useless visual features.4.3 Modifications RLVCsummarize, extension RLVC use decision trees anymore, assignsone BDD visual class. Two modifications applied Algorithm 1:1. operation refining, visual feature f , visual class V labeledBDD B(V ), consists replacing V two new visual classes V1 V2B(V1 ) = B(V ) f B(V2 ) = B(V ) f .2. Given equivalence relation, post-process(Ck ) operation consists mergingequivalent visual classes. merge pair visual classes (V1 , V2 ), V1 V2deleted, new visual class V B(V ) = B(V1 ) B(V2 ) added. Everytime merging operation takes place, advised carry variable reordering,minimize memory requirements.4.4 Experimentsapplied modified version RLVC another simulated navigation task.task, agent moves 11 spots campus University Liege (cf.Figure 7). Every time agent one 11 locations, body aim four possible371fiJodogne & PiaterN(c) Google MapFigure 7: Montefiore campus Liege. Red spots corresponds placesagent moves. agent follow links differentspots. goal enter Montefiore Institute, labeled red cross,gets reward +100.orientations: North, South, West, East. state space therefore size 11 4 = 44.agent three possible actions: Turn left, turn right, go forward. goal enterspecific building, obtain reward +100. Turning left right inducespenalty 5, moving forward, penalty 10. discount factor set 0.8.optimal control policy unique: One depicted Figure 8.agent direct access position orientation. Rather,perceives picture area front (cf. Figure 9). Thus, agentconnect input image appropriate reaction without explicitly knowinggeographical localization. possible location possible viewing direction,database 24 images size 1024 768 significant viewpoint changescollected. 44 databases randomly divided learning set 18 imagestest set 6 images. experimental setup, versions RLVC learnimage-to-action mapping using interactions contain images learning set.Images test set used assess accuracy learned visual control policies.SIFT keypoints used visual features (Lowe, 2004). ThresholdingMahalanobis distance gave rise set 13,367 distinct features. versions RLVCapplied static database 10,000 interactions collected usingfully randomized exploration policy. database used throughout entirealgorithm, database contains images belong learning set.results basic version RLVC version extended BDDsreported Figures 10 11. original version RLVC identified 281 visualclasses selecting 264 SIFT features. error rate computed visual policy (i.e.proportion sub-optimal decisions agent presented possible stimuli)372fiClosed-Loop Learning Visual Control Policies(c) Google MapFigure 8: One optimal, deterministic control policies Montefiore navigationtask. state, indicated optimal action (the letter F standsmove forward, R turn right L turn left). policyobtained applying standard RL algorithm scenarioagent direct access (p, d) information.0.1% learning set 8% images test set used, respectoptimal policy agent direct access position viewing direction.modified version RLVC applied, one compacting stage every 10 steps.results clearly superior. error learning set anymore,error rate test set 4.5%. number selected features reduced 171.Furthermore, resulting number visual classes becomes 59, instead 281. Thus,large improvement generalization abilities, well reduction numbervisual classes selected features. Interestingly enough, number visual classes(59) close number physical states (44), tends indicatealgorithm starts learn physical interpretation percepts.summarize, compacting visual policies probably required step deal realistic visual tasks, iterative splitting process applied. price pay course373fiJodogne & Piater(c) Google MapFigure 9: percepts agent. Four possible different percepts shown, correspond location viewing direction marked yellow top image.374fiClosed-Loop Learning Visual Control Policies6060RLVCRLVC + BDD50404030020406080Iterations (k)100120140Error rate (%)5030202010100160020406080Iterations (k)100120140Error rate (%)RLVCRLVC + BDD0160Figure 10: Comparison error rates basic extended versions RLVC.error computed policy function step counter k imageslearning set (resp. test set) reported left figure (resp.right).higher computational cost. Future work focus theoretical justification usedequivalence relations. implies bridging gap theory MDP minimization (Givan, Dean, & Greig, 2003).5. Learning Spatial Relationshipsmotivated Introduction (Section 1.4.3), propose extend RLVC constructing hierarchy spatial arrangements individual point features (Jodogne, Scalzo, &Piater, 2005). idea learning models spatial combinations features takesroots seminal paper Fischler Elschlager (1973) pictorial structures,collections rigid parts arranged deformable configurations. ideabecome increasingly popular computer vision community 90s, ledlarge literature modeling detection objects (Amit & Kong, 1996; Burl& Perona, 1996; Forsyth, Haddon, & Ioffe, 1999). Crandall Huttenlocher (2006) provide pointers recent resources. Among recent techniques, Scalzo Piater (2006)propose build probabilistic hierarchy visual features representedacyclic graph. detect presence model Nonparametric BeliefPropagation (Sudderth, Ihler, Freeman, & Willsky, 2003). graphical modelsproposed representing articulated structures, pictorial structures (Felzenszwalb & Huttenlocher, 2005; Kumar, Torr, & Zisserman, 2004). Similarly, constellationmodel represents objects parts, modeled terms shape appearanceGaussian probability density functions (Perona, Fergus, & Zisserman, 2003).work contrasts approaches generation so-called compositefeatures driven task solved. distinguished techniquesunsupervised learning composite features, since additional information375fiJodogne & Piater300300RLVCRLVC + BDD250200200150020406080Iterations (k)100120140Number classes25015010010050500160020406080Iterations (k)100120140Number selected featuresRLVCRLVC + BDD0160Figure 11: Comparison number generated classes selected visual features basic extended versions RLVC. number visual classes(resp. selected features) function step counter k plotted leftfigure (resp. right).embedded inside reinforcement signal drives generation composite featuresfocusing exploration task-relevant spatial arrangements.extension RLVC, hierarchy visual features built simultaneouslyimage classifier. soon sufficiently informative visual feature extracted,algorithm tries combine two visual features order construct higher levelabstraction, hopefully distinctive robust noise. extensionRLVC assumes co-existence two different kinds visual features:Primitive Features: correspond individual point features, i.e. localappearance descriptors (cf. Section 1.3).Composite Features: consist spatial combinations lower-level visual features.priori bound maximal height hierarchy. Therefore,composite feature potentially combined primitive feature,composite feature.5.1 Detection Visual Featuresnatural way represent hierarchy use directed acyclic graph G = (V, E),vertex v V corresponds visual feature, edge (v, v 0 ) Emodels fact v 0 part composite feature v. Thus, G must binary,i.e. vertex either child, exactly two children. set VP leavesG corresponds set primitive features, set VC internal vertexesrepresents set composite features.leaf vertex vP VP annotated local descriptor D(vP ). Similarly,internal vertex vC VC annotated constraints relative positionparts. work, consider constraints distances constituent376fiClosed-Loop Learning Visual Control Policiesvisual features composite features, assume distributedaccording Gaussian law G(, ) mean standard deviation . Evidently, richerconstraints could used, taking relative orientation scaling factor constituent features consideration, would require use multivariate Gaussians.precisely, let vC composite feature, parts v1 v2 . ordertrigger detection vC image s, occurrence v1occurrence v2 relative Euclidean distance sufficient likelihoodgenerated Gaussian mean (vC ) standard deviation (vC ). ensuresymmetry, location composite feature taken midpointlocations v1 v2 .occurrences visual feature v percept found using recursiveAlgorithm 5. course, steps 6 7 Algorithm 4, test st exhibit v?rewritten function Algorithm 5, checking occurrences(v, st ) 6= .5.2 Generation Composite Featurescornerstone extension RLVC way generating composite features.general idea behind algorithm accumulate statistical evidence relativepositions detected visual features order find conspicuous coincidences visualfeatures. done providing evolved implementation generator(s1 , . . . , sn )one Algorithm 3.5.2.1 Identifying Spatial Relationsfirst extract set F (primitive composite) features occur withinset provided images {s1 , . . . , sn }:F = {v V | (i) si exhibits v} .(16)identify pairs visual features occurrences highly correlated withinset provided images {s1 , . . . , sn }. simply amounts counting numberco-occurrences pair features F , keeping pairs correspondingcount exceeds fixed threshold.Let v1 v2 two features highly correlated. search meaningfulspatial relationship v1 v2 carried images {s1 , . . . , sn }contain occurrences v1 v2 . co-occurrence, accumulate setdistances corresponding occurrences v1 v2 . Finally, clusteringalgorithm applied distribution order detect typical distances v1v2 . purpose experiments, used hierarchical clustering (Jain,Murty, & Flynn, 1999). cluster, Gaussian fitted estimating mean valuestandard deviation . Finally, new composite feature vC introducedfeature hierarchy, v1 v2 parts (vC ) = (vC ) = .summary, Algorithm 1, replace call Algorithm 3 call Algorithm 6.377fiJodogne & PiaterAlgorithm 5 Detecting Composite Features1: occurrences(v, s) :2:v primitive3:return {(x, y) | (x, y) interest point s, local descriptor corresponds D(v)}4:else5:{}6:O1 occurrences(subfeature1 (v), s)7:O2 occurrences(subfeature2 (v), s)8:p(x1 , y1 ) O1 (x2 , y2 ) O29:(x2 x1 )2 + (y2 y1 )210:G(d (v), (v))11:{((x1 + x2 )/2, (y1 + y2 )/2)}12:end13:end14:return15:endAlgorithm 6 Generation Composite Features1: generator({s1 , . . . , sn }) :2:F = {v V | (i) si exhibits v}3:F 0 = {}4:(v1 , v2 ) F F5:enough co-occurrences v1 v2 {s1 , . . . , sn }6:{}7:{1, . . . , n}8:occurrences (x1 , y1 ) v1 si9:occurrences(x2 , y2 ) v2 sip10:{ (x2 x1 )2 + (y2 y1 )2 }11:end12:end13:end14:Apply clustering algorithm15:cluster C = {d1 , . . . dm }16:= mean(C)17:= stddev(C)18:Add F 0 composite feature vC composed v1 v2 , annotatedmean standard deviation19:end20:end21:end22:return F 0378fiClosed-Loop Learning Visual Control PoliciesH(p)0.4Nu0.2mg1.5.51p0.2Figure 12: Car Hill control problem.5.2.2 Feature ValidationAlgorithm 6 generate several composite features given visual class Vk,i . However,end Algorithm 4, one generated composite feature kept.important notice performance clustering method criticalpurpose. Indeed, irrelevant spatial combinations automatically discarded, thanksvariance-reduction criterion feature selection component. fact, reinforcementsignal helps direct search good feature, advantage unsupervisedmethods building feature hierarchies.5.3 Experimentsdemonstrate efficacy algorithms version classical Car Hillcontrol problem (Moore & Atkeson, 1995), position velocity informationpresented agent visually.episodic task, car (modeled mass point) riding without frictionhill, shape defined function:H(p) =p2 p+pp < 0,2p/ 1 + 5p p 0.goal agent reach fast possible top hill, i.e. locationp 1. top hill, agent obtains reward 100. car thrust leftright acceleration 4 Newtons. However, gravity, accelerationinsufficient agent reach top hill always thrusting toward right.Rather, agent go left while, hence acquiring potential energy goingleft side hill, thrusting rightward. two constraints: agentallowed reach locations p < 1, velocity greater 3 absolutevalue leads destruction car.379fiJodogne & Piater5.3.1 Formal Definition TaskFormally, set possible actions = {4, 4}, state space = {(p, s) ||p| 1 |s| 3}. system following continuous-time dynamics:p ==p1 + H 0 (p)2gH 0 (p),1 + H 0 (p)2thrust acceleration, H 0 (p) first derivative H(p), = 1mass car, g = 9.81 acceleration due gravity. continuous-timedynamics approximated following discrete-time state update rule:st+1 = st + hpt + h2 st /2st+1 = pt + hst ,h = 0.1 integration time step. reinforcement signal definedexpression:100 st+1 1 |st+1 | 3,R((st , st ), a) =0otherwise.setup, discount factor set 0.75.definition actually mix two coexistent formulations Car Hilltask (Ernst, Geurts, & Wehenkel, 2003; Moore & Atkeson, 1995). major differencesinitial formulation problem (Moore & Atkeson, 1995) setpossible actions discrete, goal top hill (rather givenarea hill), like definition Ernst et al. (2003). ensure existenceinteresting solution, velocity required remain less 3 (instead 2),integration time step set h = 0.1 (instead 0.01).5.3.2 Inputs Agentprevious work (Moore & Atkeson, 1995; Ernst et al., 2003), agent always assumeddirect access numerical measure position velocity. exceptionGordons work visual, low-resolution representation global scene givenagent (Gordon, 1995). experimental setup, agent provided twocameras, one looking ground underneath, second velocity gauge. way,agent cannot directly know current position velocity, suitably interpretvisual inputs derive them.examples pictures sensors return presented Figure 13.ground carpeted color image 1280 128 pixels montage picturesCOIL-100 database (Nene et al., 1996). important notice usingindividual point features insufficient solving task, since set featurespictures velocity gauge always same. know velocity, agentgenerate composite features sensitive distance primitive features cursorrespect primitive features digits.380fiClosed-Loop Learning Visual Control Policies(a)(b)Figure 13: (a) Visual percepts corresponding pictures velocity gauge = 3,= 0.5 = 1.5. (b) Visual percepts returned position sensor.region framed white rectangle corresponds portion groundreturned sensor p = 0.1. portion slides back forthagent moves.5.3.3 Resultsexperimental setup, used color differential invariants (Gouet & Boujemaa, 2001)primitive features. Among possible visual inputs (both positionvelocity sensors), 88 different primitive features. entire image groundincludes 142 interest points, whereas images velocity gauge include 20interest points.output RLVC decision tree defines 157 visual classes. internalnode tree tests presence one visual feature, taken set 91 distinct,highly discriminant features selected RLVC. Among 91 selected visual features,56 primitive 26 composite features. Two examples composites featuresselected RLVC depicted Figure 15. computation stopped k = 38refinement steps Algorithm 1.show efficacy method, compare performance scenarioagent direct perception current (p, s) state. latter scenario,state space discretized grid 13 13 cells. number 13 chosen sinceapproximately corresponds square root 157, number visual classesproduced RLVC. way, RL provided equivalent number perceptual classestwo scenarios. Figure 14 compares optimal value function direct-perception381fiJodogne & PiaterVelocity30310Position1(a)Velocity30310Position1(b)Figure 14: (a) optimal value function, agent direct access current(p, s) state, input space discretized 13 13 grid.brighter location, greater value. (b) value function obtainedRLVC.382fiClosed-Loop Learning Visual Control PoliciesFigure 15: Two composite features generated, yellow. primitive featurescomposed marked yellow. first feature triggersvelocities around 0, whereas second triggers around 2.problem one obtained RLVC. also, two pictures similar,indicates soundness approach.also evaluated performance optimal image-to-action mapping= argmax Q ((p, s), a)(17)aAobtained RLVC. purpose, agent placed randomly hill,initial velocity 0. Then, used mapping choose action, reachedfinal state. set 10,000 trials carried step k Algorithm 1.Figure 16 compares proportion trials missed goal (either leavinghill left, acquiring high velocity) RLVC directperception problem. k became greater 27, proportion missed trialsalways smaller RLVC direct-perception problem. advantage favorRLVC due adaptive nature discretization. Figure 17 compares meanlengths successful trials. mean length RLVC trials clearly convergesdirect-perception trials, staying slightly larger.conclude, RLVC achieves performance close direct-perception scenario. However, mapping built RLVC directly links visual percepts appropriate actions,without considering explicitly physical variables.6. Summarypaper introduces Reinforcement Learning Visual Classes (RLVC). RLVC designedlearn mappings directly connect visual stimuli output actions optimalsurrounding environment. framework RLVC general, senseapplied problem formulated Markov decision problem.learning process behind algorithms closed-loop flexible. agenttakes lessons interactions environment, according purposive visionparadigm. RLVC focuses attention embedded reinforcement learning algorithmhighly informative robust parts inputs testing presence absencelocal descriptors interest points input images. relevant visual features383fiJodogne & Piater25RLVCDirect perception (13x13 grid)Missed goal (%)201510500510152025303540Iterations (k)Figure 16: Evolution number times goal missed iterationsRLVC.19RLVCDirect perception (13x13 grid)18Mean length interaction1716151413120510152025303540Iterations (k)Figure 17: Evolution mean lengths successful trials iterations RLVC.384fiClosed-Loop Learning Visual Control Policiesincrementally selected sequence attempts remove perceptual aliasing:discretization process targets zero Bellman residuals inspired supervised learning algorithms building decision trees. algorithms defined independentlyinterest point detector (Schmid et al., 2000) local description technique (Mikolajczyk & Schmid, 2003). user may choose two components sees fit.Techniques fighting overfitting RLVC also proposed. ideaaggregate visual classes share similar properties respect theory DynamicProgramming. Interestingly, process enhances generalization abilities learnedimage-to-action mapping, reduces number visual classes built.Finally, extension RLVC introduced allows closed-loop, interactivepurposive learning hierarchy geometrical combinations visual features.contrast prior work topic, uses either supervisedunsupervised framework (Piater, 2001; Fergus, Perona, & Zisserman, 2003; Bouchard &Triggs, 2005; Scalzo & Piater, 2006). Besides novelty approach, shownpractical value visual control tasks information provided individualpoint features alone insufficient solving task. Indeed, spatial combinations visualfeatures informative robust noise.7. Future Workarea applications RLVC wide, since nowadays robotic agents often equippedCCD sensors. Future research includes demonstration applicabilityalgorithms reactive robotic application, grasping objects combining visualhaptic feedback (Coelho, Piater, & Grupen, 2001). necessitates extensiontechniques continuous action spaces, fully satisfactory solutions existdate. RLVC could also potentially applied Human-Computer Interaction,actions need physical actions.closed-loop learning hierarchy visual feature also raises interesting researchdirections. example, combination RLVC techniques disambiguatingaliased percepts using short-term memory (McCallum, 1996) could solve visualtasks percepts agent alone provide enough information solvingtask. Likewise, unsupervised learning kinds geometrical models (Felzenszwalb & Huttenlocher, 2005) could potentially embedded RLVC. hand,spatial relationships currently take consideration relative anglesparts composite feature. would increase discriminative powercomposite features, requires non-trivial techniques clustering circular domains.Acknowledgmentsauthors thank associate editor Thorsten Joachims three anonymous reviewers many suggestions improving quality manuscript. SebastienJodogne gratefully acknowledge financial support Belgian National FundScientific Research (FNRS).385fiJodogne & PiaterReferencesAloimonos, Y. (1990). Purposive qualitative active vision. Proc. 10th International Conference Pattern Recognition, pp. 436460.Amit, Y., & Kong, A. (1996). Graphical templates model registration. IEEE Transactions Pattern Analysis Machine Intelligence, 18 (3), 225236.Asada, M., Noda, S., Tawaratsumida, S., & Hosoda, K. (1994). Vision-based behavior acquisition shooting robot using reinforcement learning. Proc. IAPR/IEEEWorkshop Visual Behaviors, pp. 112118.Bagnell, J., & Schneider, J. (2001). Autonomous helicopter control using reinforcementlearning policy search methods. Proc. International Conference RoboticsAutomation. IEEE.Barto, A., Sutton, R., & Anderson, C. (1983). Neuronlike adaptive elementssolve difficult learning control problems. IEEE Transactions Systems, ManCybernetics, 13 (5), 835846.Bellman, R. (1957). Dynamic Programming. Princeton University Press.Bertsekas, D., & Tsitsiklis, J. (1996). Neuro-Dynamic Programming. Athena Scientific.Boigelot, B. (1999). Symbolic Methods Exploring Infinite State Spaces. Ph.D. thesis,University Liege, Liege (Belgium).Boigelot, B., Jodogne, S., & Wolper, P. (2005). effective decision procedure lineararithmetic integer real variables. ACM Transactions Computational Logic(TOCL), 6 (3), 614633.Bouchard, G., & Triggs, B. (2005). Hierarchical part-based visual object categorization.IEEE Conference Computer Vision Pattern Recognition, Vol. 1, pp. 710715,San Diego (CA, USA).Breiman, L., Friedman, J., & Stone, C. (1984).Wadsworth International Group.Classification Regression Trees.Bryant, R. (1986). Graph-based algorithms boolean function manipulation. IEEE Transactions Computers, 8 (35), 677691.Bryant, R. (1992). Symbolic boolean manipulation ordered binary decision diagrams.ACM Computing Surveys, 24 (3), 293318.Burl, M., & Perona, P. (1996). Recognition planar object classes. Proc. IEEEConference Computer Vision Pattern Recognition, pp. 223230, San Francisco(CA, USA).Chapman, D., & Kaelbling, L. (1991). Input generalization delayed reinforcement learning: algorithm performance comparisons. Proc. 12th InternationalJoint Conference Artificial Intelligence (IJCAI), pp. 726731, Sydney.Chrisman, L. (1992). Reinforcement learning perceptual aliasing: perceptualdistinctions approach. National Conference Artificial Intelligence, pp. 183188.386fiClosed-Loop Learning Visual Control PoliciesCoelho, J., Piater, J., & Grupen, R. (2001). Developing haptic visual perceptual categories reaching grasping humanoid robot. Robotics AutonomousSystems, special issue Humanoid Robots, 37 (23), 195218.Crandall, D., & Huttenlocher, D. (2006). Weakly supervised learning part-based spatialmodels visual object recognition. Proc. 9th European ConferenceComputer Vision.Delzanno, G., & Raskin, J.-F. (2000). Symbolic representation upward closed sets.Tools Algorithms Construction Analysis Systems, Lecture NotesComputer Science, pp. 426440, Berlin (Germany).Derman, C. (1970). Finite State Markovian Decision Processes. Academic Press, New York.Ernst, D., Geurts, P., & Wehenkel, L. (2003). Iteratively extending time horizon reinforcement learning. Proc. 14th European Conference Machine Learning, pp.96107, Dubrovnik (Croatia).Ernst, D., Geurts, P., & Wehenkel, L. (2005). Tree-based batch mode reinforcement learning.Journal Machine Learning Research, 6, 503556.Felzenszwalb, P., & Huttenlocher, D. (2005). Pictorial structures object recognition.International Journal Computer Vision, 61 (1), 5579.Fergus, R., Perona, P., & Zisserman, A. (2003). Object class recognition unsupervisedscale-invariant learning. IEEE Conference Computer Vision Pattern Recognition, Vol. 2, pp. 264271, Madison (WI, USA).Fischler, M., & Elschlager, R. (1973). representation matching pictorial structures. IEEE Transactions Computers, 22 (1), 6792.Forsyth, D., Haddon, J., & Ioffe, S. (1999). Finding objects grouping primitives. Shape,Contour Grouping Computer Vision, pp. 302318, London (UK). SpringerVerlag.Gaskett, C., Fletcher, L., & Zelinsky, A. (2000). Reinforcement learning visual servoingmobile robot. Proc. Australian Conference Robotics Automation,Melbourne (Australia).Gibson, E., & Spelke, E. (1983). development perception. Flavell, J. H., & Markman, E. M. (Eds.), Handbook Child Psychology Vol. III: Cognitive Development(4th edition)., chap. 1, pp. 276. Wiley.Givan, R., Dean, T., & Greig, M. (2003). Equivalence notions model minimizationmarkov decision processes. Artificial Intelligence, 147 (12), 163223.Gordon, G. (1995). Stable function approximation dynamic programming. Proc.International Conference Machine Learning, pp. 261268.Gouet, V., & Boujemaa, N. (2001). Object-based queries using color points interest.IEEE Workshop Content-Based Access Image Video Libraries, pp. 3036,Kauai (HI, USA).Howard, R. (1960). Dynamic Programming Markov Processes. Technology PressWiley, Cambridge (MA) New York.387fiJodogne & PiaterHuber, M., & Grupen, R. (1998). control structure learning locomotion gaits. 7thInt. Symposium Robotics Applications, Anchorage (AK, USA). TSI Press.Iida, M., Sugisaka, M., & Shibata, K. (2002). Direct-vision-based reinforcement learningreal mobile robot. Proc. International Conference Neural InformationProcessing Systems, Vol. 5, pp. 25562560.Jaakkola, T., Jordan, M., & Singh, S. (1994). Convergence stochastic iterative dynamicprogramming algorithms. Cowan, J. D., Tesauro, G., & Alspector, J. (Eds.), Advances Neural Information Processing Systems, Vol. 6, pp. 703710. Morgan Kaufmann Publishers.Jain, A. K., Murty, M. N., & Flynn, P. J. (1999). Data clustering: review. ACM ComputingSurveys, 31 (3), 264323.Jodogne, S., & Piater, J. (2005a). Interactive learning mappings visual perceptsactions. De Raedt, L., & Wrobel, S. (Eds.), Proc. 22nd InternationalConference Machine Learning (ICML), pp. 393400, Bonn (Germany). ACM.Jodogne, S., & Piater, J. (2005b). Learning, compacting visual policies (extended abstract). Proc. 7th European Workshop Reinforcement Learning (EWRL),pp. 810, Napoli (Italy).Jodogne, S., Scalzo, F., & Piater, J. (2005). Task-driven learning spatial combinationsvisual features. Proc. IEEE Workshop Learning Computer VisionPattern Recognition, San Diego (CA, USA). IEEE.Kaelbling, L., Littman, M., & Cassandra, A. (1998). Planning acting partiallyobservable stochastic domains. Artificial Intelligence, 101 (1-2), 99134.Kaelbling, L., Littman, M., & Moore, A. (1996). Reinforcement learning: survey. JournalArtificial Intelligence Research, 4, 237285.Kimura, H., Yamashita, T., & Kobayashi, S. (2001). Reinforcement learning walkingbehavior four-legged robot. Proc. 40th IEEE Conference DecisionControl, Orlando (FL, USA).Kohl, N., & Stone, P. (2004). Policy gradient reinforcement learning fast quadrupedallocomotion. Proc. IEEE International Conference Robotics Automation, pp. 26192624, New Orleans.Kumar, M., Torr, P., & Zisserman, A. (2004). Extending pictorial structures objectrecognition. Proc. British Machine Vision Conference.Kwok, C., & Fox, D. (2004). Reinforcement learning sensing strategies. Proc.IEEE International Conference Intelligent Robots Systems.Lagoudakis, M., & Parr, R. (2003). Least-squares policy iteration. Journal MachineLearning Research, 4, 11071149.Lowe, D. (2004). Distinctive image features scale-invariant keypoints. InternationalJournal Computer Vision, 60 (2), 91110.Martnez-Marn, T., & Duckett, T. (2005). Fast reinforcement learning vision-guidedmobile robots. Proc. IEEE International Conference Robotics Automation, pp. 1822, Barcelona (Spain).388fiClosed-Loop Learning Visual Control PoliciesMcCallum, R. (1996). Reinforcement Learning Selective Perception Hidden State.Ph.D. thesis, University Rochester, New York.Michels, J., Saxena, A., & Ng, A. (2005). High speed obstacle avoidance using monocularvision reinforcement learning. Proc. 22nd International ConferenceMachine Learning, pp. 593600, Bonn (Germany).Mikolajczyk, K., & Schmid, C. (2003). performance evaluation local descriptors.Proc. IEEE Conference Computer Vision Pattern Recognition, Vol. 2,pp. 257263, Madison (WI, USA).Moore, A., & Atkeson, C. (1995). parti-game algorithm variable resolution reinforcement learning multidimensional state-spaces. Machine Learning, 21.Munos, R., & Moore, A. (2002). Variable resolution discretization optimal control. Machine Learning, 49, 291323.Nene, S., Nayar, S., & Murase, H. (1996). Columbia object image library (COIL-100). Tech.rep. CUCS-006-96, Columbia University, New York.Ng, A., Coates, A., Diel, M., Ganapathi, V., Schulte, J., Tse, B., Berger, B., & Liang, E.(2004). Inverted autonomous helicopter flight via reinforcement learning. Proc.International Symposium Experimental Robotics.Paletta, L., Fritz, G., & Seifert, C. (2005). Q-learning sequential attention visual objectrecognition informative local descriptors.. Proc. 22nd InternationalConference Machine Learning (ICML), pp. 649656, Bonn (Germany).Paletta, L., & Pinz, A. (2000). Active object recognition view integration reinforcement learning. Robotics Autonomous Systems, 31 (12), 7186.Peng, J., & Bhanu, B. (1998). Closed-loop object recognition using reinforcement learning.IEEE Transactions Pattern Analysis Machine Intelligence, 20 (2), 139154.Perona, P., Fergus, R., & Zisserman, A. (2003). Object class recognition unsupervisedscale-invariant learning. Conference Computer Vision Pattern Recognition,Vol. 2, p. 264.Piater, J. (2001). Visual Feature Learning. Ph.D. thesis, University Massachusetts,Computer Science Department, Amherst (MA, USA).Puterman, M., & Shin, M. (1978). Modified policy iteration algorithms discountedMarkov decision problems. Management Science, 24, 11271137.Pyeatt, L., & Howe, A. (2001). Decision tree function approximation reinforcementlearning. Proc. Third International Symposium Adaptive Systems, pp.7077, Havana, Cuba.Quinlan, J. (1993). C4.5: Programs Machine Learning. Morgan Kaufmann PublishersInc., San Francisco (CA, USA).Randlv, J., & Alstrm, P. (1998). Learning drive bicycle using reinforcement learningshaping. Proc. 15th International Conference Machine Learning, pp.463471, Madison (WI, USA). Morgan Kaufmann.389fiJodogne & PiaterRummery, G., & Niranjan, M. (1994). On-line Q-learning using connectionist sytems. Tech.rep. CUED/F-INFENG-TR 166, Cambridge University.Salganicoff, M. (1993). Density-adaptive learning forgetting. Proc. 10thInternational Conference Machine Learning, pp. 276283, Amherst (MA, USA).Morgan Kaufmann Publishers.Scalzo, F., & Piater, J. (2006). Unsupervised learning dense hierarchical appearancerepresentations. Proc. 18th International Conference Pattern Recognition,Hong-Kong.Schaal, S. (1997). Learning demonstration. Mozer, M. C., Jordan, M., & Petsche,T. (Eds.), Advances Neural Information Processing Systems, Vol. 9, pp. 10401046.Cambridge, MA, MIT Press.Schmid, C., & Mohr, R. (1997). Local greyvalue invariants image retrieval. IEEETransactions Pattern Analysis Machine Intelligence, 19 (5), 530535.Schmid, C., Mohr, R., & Bauckhage, C. (2000). Evaluation interest point detectors.International Journal Computer Vision, 37 (2), 151172.Schyns, P., & Rodet, L. (1997). Categorization creates functional features. JournalExperimental Psychology: Learning, Memory Cognition, 23 (3), 681696.Shibata, K., & Iida, M. (2003). Acquisition box pushing direct-vision-based reinforcement learning. Proc. Society Instrument Control Engineers AnnualConference, p. 6.Singh, S., Jaakkola, T., & Jordan, M. (1995). Reinforcement learning soft state aggregation. Advances Neural Information Processing Systems, Vol. 7, pp. 361368.MIT Press.Sudderth, E., Ihler, A., Freeman, W., & Willsky, A. (2003). Nonparametric belief propagation. Proc. IEEE Conference Computer Vision Pattern Recognition,pp. 605612.Sutton, R. (1988). Learning predict methods temporal differences. MachineLearning, 3 (1), 944.Sutton, R., & Barto, A. (1998). Reinforcement Learning, Introduction. MIT Press.Takahashi, Y., Takeda, M., & Asada, M. (1999). Continuous valued Q-learning visionguided behavior acquisition. Proc. International Conference MultisensorFusion Integration Intelligent Systems, pp. 255260.Tarr, M., & Cheng, Y. (2003). Learning see faces objects. Trends CognitiveSciences, 7 (1), 2330.Tesauro, G. (1995). Temporal difference learning TD-Gammon. CommunicationsACM, 38 (3), 5868.Uther, W., & Veloso, M. (1998). Tree based discretization continuous state space reinforcement learning. Proc. 15th National Conference Artificial Intelligence(AAAI), pp. 769774, Madison (WI, USA).390fiClosed-Loop Learning Visual Control PoliciesWatkins, C. (1989). Learning Delayed Rewards. Ph.D. thesis, Kings College, Cambridge (UK).Weber, C., Wermter, S., & Zochios, A. (2004). Robot docking neural visionreinforcement. Knowledge-Based Systems, 17 (24), 165172.Wettergreen, D., Gaskett, C., & Zelinsky, A. (1999). Autonomous guidance controlunderwater robotic vehicle. Proc. International Conference FieldService Robotics, Pittsburgh (USA).Whitehead, S., & Ballard, D. (1991). Learning perceive act trial error.Machine Learning, 7, 4583.Yin, P.-Y. (2002). Maximum entropy-based optimal threshold selection using deterministicreinforcement learning controlled randomization. Signal Processing, 82, 9931006.Yoshimoto, J., Ishii, S., & Sato, M. (1999). Application reinforcement learning balancing acrobot. Proc. 1999 IEEE International Conference Systems,Man Cybernetics, pp. 516521.391fiJournal Artificial Intelligence Research 28 (2007) 233266Submitted 05/06; published 3/07Auctions Severely Bounded CommunicationLiad Blumrosenliadbl@microsoft.comMicrosoft Research1065 La AvenidaMountain View, CA 94043Noam Nisannoam.nisan@gmail.comSchool Computer Science EngineeringHebrew UniversityJerusalem 91904, IsraelIlya Segalilya.segal@stanford.eduDepartment EconomicsStanford UniversityStanford, CA 94305Abstractstudy auctions severe bounds communication allowed: biddermay transmit bits information auctioneer. consider welfare-profit-maximizing auctions communication restriction. measures,determine optimal auction show loss incurred relative unconstrainedauctions mild. prove non-surprising properties kinds auctions, e.g.,optimal mechanisms bidders simply report interval valuation liesin, well surprising properties, e.g., asymmetric auctions bettersymmetric ones multi-round auctions reduce communication complexitylinear factor.1. IntroductionRecent years seen emergence Internet platform multifaceted economicinteraction, technical level computer communication, routing, storage, computing, level electronic commerce many forms. Studying interactionsraises new questions economics necessity taking computational considerations account. paper deals one question: designauctions optimally restricted use small amount communication.paper studies effect severely restricting amount communication allowedsingle-item auction. bidder privately knows real-valued willingness payitem, allowed send k possible messages auctioneer, mustallocate item determine price basis messages received. (Forexample, bidder may able send bits information, case k = 2t ).simplest case k = 2, i.e., bidder sends single bit information. contrastusual auction design formulation, bidders communicate real numbers.communicating real number may seem excessively burdensome,several motivations studying auctions severe restrictions communication. First, auctions used allocating low-level computing resources,c2007AI Access Foundation. rights reserved.fiBlumrosen, Nisan & Segaluse small amount computational effort. example, auctionrouting single packet Internet must require little communication overhead,certainly whole real number. Ideally, one would like waste bit twobidding information, perhaps piggy-backing unused bits packet headerexisting networking protocols (such IP TCP). Second, amount communicationalso measures extent information revelation bidders. Usually, biddersreluctant reveal exact private data (e.g., Rothkopf, Teisberg, & Kahn, 1990).work studies tradeoff amount revealed data optimalityauctions. show auctions close optimal even using single Yes/No question per bidder. results also applied various environmentsneed discretize bidding procedure; one example determining optimal bidincrement English auctions (Harstad & Rothkopf, 1994). Finally, restriction communication may sometimes viewed proxy simplicity considerations,simple user interface small number possible payments facilitate electronichandling. recent paper (Blumrosen & Feldman, 2006) shows ideas illustratedwork extend general mechanism-design frameworks requirementsmall number actions per player natural intuitive.examine effect severe communication bounds problem maximizing social welfare maximizing sellers expected profits (the latterrestrictions Bayesian incentive compatibility interim individual rationalitybidders, standard regularity condition distribution bidders valuations). study simultaneous mechanisms, bidders send bidswithout observing actions bidders, sequential mechanisms messages may depend previous messages. find single-item auctions mayclose fully optimal despite severe communication constraints. contrastcombinatorial auctions, exact even approximate efficiency known requireexponential amount communication number goods (Nisan & Segal, 2006).1welfare maximization revenue maximization, show optimal2-bidder auction takes simple form priority game playerhighest bid wins, ties broken asymmetrically among players (i.e., playerspre-defined priority others send message). showderive optimal values parameters priority game. optimalmechanisms asymmetric definition, although players priori identical.asymmetry contrast optimal mechanisms unconstrained communication,symmetric mechanisms achieve optimal welfare (the second-price auction, Vickrey,1961) optimal profit (the Myerson auction, Myerson, 1981, symmetric bidders).Furthermore, show number players, allowed number messagesgrows, loss due bounded communication order O( k12 ). bound tightdistributions valuations (e.g., uniform distribution). addition,consider case number players grows player exactly two1. several studies considering various computational considerations auction design: timing (e.g., Lavi & Nisan, 2004; Roth & Ockenfels, 2002), unbounded supply (e.g., Feigenbaum,Papadimitriou, & Shenker, 2001; Goldberg, Hartline, & Wright, 2001; Bar-Yossef, Hildrum, & Wu, 2002),computational complexity combinatorial auctions (see survey Cramton, Shoham, & Steinberg,2006) more.234fiAuctions Severely Bounded Communicationpossible messages. show priority games optimal case well,also characterize parameters optimal mechanisms showgenerated simple recursive formula. offer asymptotic bound welfareprofit losses due bounded communication number players grows (it O( n1 )uniform distribution). optimal mechanisms paper deterministic,optimal even auctioneer allowed randomize.2analysis implies expected well unexpected results:Low welfare profit loss: Even severe bounds communication resultmild loss efficiency. present mechanisms welfare lossprofit loss decrease exponentially number communication bits (andquadratically number k allowed bids). example, two bidderswhose valuations uniformly distributed [0, 1], optimal 1-bit auction bringsexpected welfare 0.648, compared first-best expected welfare 0.667.Asymmetry helps: Asymmetric auctions better symmetric onescommunication bounds. example, two bidders whose valuationsuniformly distributed [0, 1], symmetric 1-bit auctions achieve expected welfare0.625, compared 0.648 asymmetric ones. prove welfare-profit-maximizing auctions must discriminatory allocation payments.Dominant-strategy incentive compatibility achieved additionalcost: auctions design dominant-strategy equilibria ex-post individually rational3 , yet optimal even without incentive constraints (for welfaremaximization), among Bayesian-Nash incentive-compatible interim individually rational auctions (for profit maximization). generalizes well-known resultscase without communication constraints.Bidding using mutually-centered thresholds optimal: showoptimal auctions k messages, bidders simply partition range valuationsk interval ranges announce interval. 2-bidder mechanisms, thresholdinteresting property average value bidderrespective interval. denote threshold vectors mutually centered.Sequential mechanisms better, linear factor: Allowing players send messages sequentially rather simultaneously achievehigher payoff simultaneous mechanisms. However, payoffmulti-round mechanism among n players achieved simultaneous mechanism players send messages longer factor n.result surprising light fact general restriction simultaneouscommunication increase communication complexity exponentially. results2. mechanisms optimal even auctions run repeatedly, long bidders valuesuncorrelated time.3. mechanism ex-post individually rational player never pays value. Interim individual rationality weaker property, player pay value average.Individual rationality constraints essential study revenue maximization (otherwise,potential revenue unbounded).235fiBlumrosen, Nisan & Segalsequential mechanisms robust several aspects. allow playerssend messages various sizes order, allow auctioneeradaptively determine order size messages based historymessages. auctioneer may also use randomized decisions.Although welfare-maximizing mechanisms asymmetric, symmetric mechanismsalso close optimal: show number k possible messages grows,number players fixed, loss optimal symmetric mechanisms convergeszero rate loss efficient priority games. optimal losssymmetric asymmetric mechanisms, however, differs constant factor.hand, fix number messages, show optimal loss asymmetricmechanisms converges zero asymptotically faster optimal symmetric mechanisms(O( n1 ) compared O( lognn ), uniform distribution).demonstrate properties example simplest case:2-bidder mechanism player two possible bids (i.e., 1 bit) valuesdistributed uniformly.Example 1. Consider two players, Alice Bob, values uniformly distributed[0, 1]. 1-bit auction among players described 2x2 matrix, Alicechooses row, Bob chooses column. entry matrix specifies allocationpayments given combination bids. mechanism allowed toss coinsdetermine allocations. Figure 1 describes example mechanism,denote mechanism g1 .strategy defines player determines bid according private value.first note g1 , players dominant strategies, i.e., strategies optimalregardless actions players. Consider following threshold strategy:bid 1 valuation greater 13 , else bid 0. Clearly, strategy dominantAlice g1 : valuation smaller 13 gain negative utilitybids 1; valuation greater 31 , bidding 0 gives utility zero,get positive utility bidding 1. Similarly, threshold strategy threshold23 dominant Bob.social welfare mechanism measures total happiness playersoutcome, case, value player receives item. expectedwelfare g1 , given players follow dominant strategies, easily calculated3554= 0.648: players bid 0 probability 13 23 , expected welfarecase equals expected value Bob, 21 23 . Similar computations show expectedwelfare indeed:1 2 2312 1 + 231 2 1 + 1312 1 + 2335+ (1 )+ (1 )+ (1 )(1 )=33 23323 3233254see despite restricting communication infinite number bits1single bit only, relatively small welfare loss 54incurred. course, randomallocation implemented without communication result expectedwelfare 12 , may regarded naive benchmark.236fiAuctions Severely Bounded Communicationturns mechanism described Figure 1 maximizes expected welfare:1-bit mechanism achieves strictly higher expected welfare pair biddersstrategies (that is, regardless concept equilibrium use). note optimalmechanism asymmetric (a priority game) ties always broken favor Bob,mechanism optimal even randomized decisions allowed. Noteoptimal symmetric 1-bit mechanism uses randomization, achieves expectedwelfare 0.625 (the mechanism illustrated Appendix A.3 see also Footnote 20).Finally, note optimal thresholds players mutually centered.is, Alices value 13 average value Bob bids 0 Bobs value 32 averagevalue Alice bids 1. intuition simple: given Bob bids 0, averagevalue 12 23 = 13 . values Alice efficient mechanism giveitem? Clearly value greater average value Bob. Therefore, Aliceuse threshold 13 .closely related work economic literature Harstad Rothkopf(1994), considered similar questions cases restricting bid levels oral auctionsdiscrete levels, Wilson (1989) McAfee (2002) analyzed inefficiencycaused discrete priority classes buyers. particular, Wilson showed number k priority classes grows, efficiency loss asymptotically proportional k12 .work Wilson buyers aggregate demand known supply uncertain,model demand uncertain. Wilson Harstad Rothkopf restrictattention symmetric mechanisms, show creating endogenous asymmetryamong ex ante identical buyers beneficial. Another related work BergemannPesendorfer (2001), seller decide accuracy bidders knowprivate values. problem different ours, since bidders model knowvaluations. work Parkes (2005) also related. compared efficiencysimultaneous sequential auctions uncertainties values players.Recent work also studied similar discrete-bid model context ascending auctionsauctions use take-it-or-leave-it offers (Kress & Boutilier, 2004; Sandholm & Gilpin,2006; David, Rogers, Schiff, Kraus, & Jennings, 2005).organization paper follows: Section 2 presents model definitionintroduces notations Section 3 presents characterization welfare- profitoptimal 2-bidder auctions. Section 4 characterizes optimal mechanisms arbitrarynumber bidders, 2 possible bids player. Section 5 give asymptoticanalysis minimal welfare profit losses optimal mechanisms. Finally, Section6 compares simultaneous sequential mechanisms bounded communication.2. Modelsection presents formal model notations use.237fiBlumrosen, Nisan & SegalB0101B wins pays 0wins pays 13B wins pays 0B wins pays 23Figure 1: (g1 ) 2-bidder 1-bit game achieves maximal expected welfare. example,Alice (the rows bidder) bids 1 Bob bids 0, Alice wins pays 13 .2.1 Bidders Mechanismconsider single item, sealed bid auctions among n risk-neutral players. Playerprivate valuation object vi [a, b].4 valuations independently drawncumulative probability functions Fi . parts analysis5 , assume existencealways-positive probability density function fi . sometime treat sellerone bidders, numbered 0. seller constant valuation v0 item.consider normalized model, i.e., bidders valuations item a.novelty model, compared standard mechanism-design settings,bidder send message ti = lg(ki ) bits mechanism, i.e., playerchoose one possible ki bids (or messages). Denote possible set bids bidder= {0, 1, 2, ..., ki 1}. auction, bidder chooses bid bi . mechanismdetermine allocation payments given vector bids b = (b1 , ..., bn ):Definition 1. mechanism g composed pair functions (a, p) where:: (1 ... n ) [0, 1]n+1 allocation scheme (not necessarily deterministic).denote ith coordinate a(b) ai (b), bidder probabilitywinningPnitem bidders bid b. Clearly, b ai (b) 0 bi=0 (b) = 1.a0 (b) > 0, seller keep item positive probability.p : (1 ... n ) <n payment scheme. pi (b) payment ith biddergiven vector bids b.6Definition 2. mechanism k possible bids, every bidder i, |i | = ki = k.denote set mechanisms k possible bids among n bidders Gn,k .denote set n-bidder mechanisms |i | = ki bidder i,Gn,(k1 ,...,kn ) .strategy si bidder game g Gn,(k1 ,...,kn ) describes bidder determinesbid according valuation, i.e., function si : [a, b] {0, 1, ..., ki 1}. Let4. simplicity, use range [0, 1] parts paper. Using general intervalrequired, though, characterization optimal mechanisms, mainly due reductionuse maximizing revenue translates original support virtual valuationsdrawn another interval.5. is, characterization optimal mechanisms Sections 3.2 4 usingconcept virtual valuation Sections 3.3 5.26. Note allow non-deterministic allocations, ignore non-deterministic payments (sinceinterested expected values, using lottery payments effect results).238fiAuctions Severely Bounded Communicationsi denote strategies bidders except i, i.e., si = (s1 , ..., si1 , si+1 , ..., sn ).sometimes use notation = (si , si ).Definition 3. real vector (t0 , t1 , ..., tk ) vector threshold values t0 t1 ... tk .Definition 4. strategy si threshold strategy based vector threshold values(t0 , t1 , ..., tk ), every bid j {0, ..., ki 1} every valuation vi [tj , tj+1 ), bidderbids j valuation vi , i.e., si (vi ) = j (and every vi , vi [t0 , tk ]). saysi threshold strategy, exists vector threshold values sithreshold strategy based t.2.2 Optimality Criteriabidders aim maximize (quasi-linear) utilities. utility bidderloses (and pay nothing), vi pi wins pay pi . Let ui (g, s) denoteexpected utility bidder game g bidders use vector strategies(implicit utility depends value vi ).Definition 5. strategy si bidder dominant mechanism g Gn,(k1 ,...,kn )regardless bidders strategies si , cannot increase expected utilitydeviation another strategy, i.e.,sei si ui (g, (si , si )) ui (g, (sei , si ))Definition 6. profile strategies = (s1 , ..., sn ) forms Bayesian-Nash equilibrium(BNE) mechanism g Gn,(k1 ,...,kn ) , every bidder i, si best responsestrategies si bidders, i.e.,sei ui (g, (si , si )) ui (g, (sei , si ))use standard participation constraints definitions: say profile strategies= (s1 , ..., sn ) ex-post individually rational mechanism g, every bidder never paysactual valuation (for realization valuations); assumestrong version definition holds even randomized mechanisms. saystrategies profile = (s1 , ..., sn ) interim individually rational mechanism g everybidder achieves non-negative expected utility, given valuation might have,bidders play si .goal find optimal, communication-bounded mechanisms. mechanismdesigners, try optimize social criteria welfare (efficiency) sellersprofit.expected welfare mechanism g, bidders use strategies s,expected social surplus. item indivisible, social surplus actuallyvaluation bidder receives item. seller keeps item, social welfarev0 .Definition 7. Let w(g, s) denote expected welfare (or expected efficiency) n-biddergame g bidders strategies s, i.e., expected value player (possiblyoptseller) receives item g. Let wn,(kdenote maximal possible expected1 ,...,kn )239fiBlumrosen, Nisan & Segalwelfare n-bidder game bidder ki possible bids, vectorstrategies allowed, i.e.,optwn,(k=maxw(g, s)1 ,...,kn )gGn,(k1 ,...,kn ) ,optoptbidders k possible bids use notation wn,k= wn,(k,...,k)Actually, optimal welfare defined maximum expected welfareobtained equilibrium. Since later show optimal welfare withoutstrategic considerations dominant-strategy implementable, use definitionsimplicity. Note even absence communication restrictions, optimizingwelfare objective obtained first-best solution (using VCG scheme); profitmaximization, hand, obtained second-best solution (incentive constraintsbind Myersons auction, Myerson, 1981).Definition 8. sellers profit payment received winning bidder, v0seller keeps item.7 Let r(g, s) denote expected profit n-bidder gameoptg bidders strategies s. Let rn,kdenote maximal expected profitn-bidder mechanism k possible bids vector interim individually-rationalstrategies forms Bayesian-Nash equilibrium g:optrn,k=maxr(g, s)g Gn,kinterim IR BNE gNote define optimal welfare maximal welfare among mechanismsstrategies, necessarily equilibria, define optimal profit maximalprofit achievable interim-IR Bayesian-Nash equilibria mechanism. Yet, optimalmechanisms (for measures) present paper implement optimalvalues dominant strategies ex-post IR.8Definition 9. say mechanism g Gn,k achieves optimal welfare (resp.profit), g interim-IR Bayesian-Nash equilibrium expected welfareoptopt(resp. profit) w(g, s) = wn,k(resp. r(g, s) = rn,k).say mechanism g Gn,k incurs welfare loss (resp. profit loss) L,achieves expected welfare (resp. profit) additively smaller optimal welfare (resp. profit) unbounded communication L (the optimal results unboundedcommunications best results achievable interim-IR Bayesian-Nash equilibria).3. Optimal Mechanisms Two Bidderssection present 2-bidder mechanisms bounded communication achieveoptimal welfare profit. Section 4 present characterization welfareoptimal profit-optimal n-bidder mechanisms 2 possible bids bidder.7. v0 = 0, expected profit equivalent sellers expected revenue.8. Note ex-ante IR, i.e., bidders know type choosing strategies, noninteresting model, since auctioneer simply ask bidder pay expectedvaluation.240fiAuctions Severely Bounded Communicationcharacterization optimal mechanisms general case (n bidders k possible bids) remains open question. Anyway, asymptotic analysis optimal welfareloss profit loss (in Section 5) holds general case, shows asymptoticallyoptimal mechanisms.first show allocation rules efficient mechanisms certain structurecall priority games. term priority game means allocation rule usesasymmetric tie breaking rule: winning player player highest priorityamong bidders bid highest. One consequence bidder lowestpriority win bid strictly higher bids. Noteterm priority game refers asymmetry mechanisms allocation function,additional asymmetry also appear payment scheme. modified priority gamesimilar allocation, except item allocated bidders bidlowest bid.9 mostly interested mechanisms playersbid space .Definition 10. game called priority game allocates item bidderbids highest bid (i.e., bi > bj j 6= i, allocation ai (b) = 1 aj (b) = 0j 6= i), ties consistently broken according pre-defined order bidders.game called modified priority game allocation priority game,except bidders bid 0, seller keeps item.turns useful build payment scheme mechanisms accordinggiven profile threshold strategies:Definition 11. n-bidder priority game based profile threshold values vectors= (t1 , ..., tn ) ni=1 <k+1 (where every i, ti0 ti1 ... tik ) mechanismwhose allocation priority game payment scheme follows: bidder jwins item vector bids b pays smallest valuation mightstill win item, given uses threshold strategy sj based tj , i.e, pj (b) =min{vj |aj (sj (vj ), bj ) = 1}. denote mechanism P Gk ( ). modified prioritygame similar payment rule called modified priority game based profilethreshold-value vectors, denoted P Gk ( ).2-bidder games, may use notations P Gk (x, y), P Gk (x, y) (where x,vectors threshold values). mechanisms P Gk (x, y) P Gk (x, y) presented Figure 2. Note P Gk (x, y) P Gk (x, y) differ bidder bids 0(i.e., first line games matrix).observe priority games modified priority games, paymentsschemes described above, two desirable properties: admit dominantstrategy equilibrium, ex-post individually rational players followdominant strategies.dominant strategies, well known result mechanism design (see Mookherjee& Reichelstein, 1992 also Lemma 1 Segal, 2003) states monotone109. Modified priority games viewed priority games treat seller one bidderslowest priority (then, seller always bids second-lowest bid).10. mechanism monotone probability bidder wins increases raises bid, fixingbids bidders. See Definition 12 model.241fiBlumrosen, Nisan & Segalallocation rule transfer (i.e., payment) rule would implement desiredallocation dominant strategies. deterministic auctions, support equilibrium,winning bidder pay smallest valuation still wins (fixingbehavior bidders). payments Definition 11 defined way,therefore support dominant-strategy implementation. follows thresholdstrategies based threshold values vector dominant P Gk ( )P Gk ( ). clear definition priority games modified priority gamesthat, playing dominant threshold strategies, winning players never payvalue, losing players pay zero. Ex-post IR follows.Actually, observation payments lead dominant strategies evengeneral. observe monotone mechanisms reveal enough information, despitecommunication constraints, find transfer rules support dominant-strategyimplementation. Therefore, characterizing optimal mechanisms focusdefining monotone allocation schemes communication restrictions, transfers lead dominant-strategy equilibria concluded free. words,use 2-stage approach widely used mechanism-design literature alsobounded-communication settings: first solve optimal allocation rule, construct transfers satisfy desired incentive-compatibility individual-rationalityconstraints.Remark 1. argument holds general environments: environmentsplayer one-dimensional private value quasi-linear utility, non-monetaryallocation rule implemented dominant strategies transfers,communication protocol11 realizing rule also reveals enough information constructsupporting transfers dominant strategies. see this, recall direct-revelationmechanisms (i.e., unbounded communication), allocation rule provesmonotonic, transfers support dominant-strategy equilibrium. transfersdefined according allocation-dependent thresholds, e.g., deterministicallocation rule every bidder pay smallest valuation still wins.standard revelation-principle arguments, monotonic allocation rule bounded communication mechanisms, viewed monotonic direct-revelation mechanismunbounded communication, therefore supporting transfers exist. supportingtransfers determined changes allocation rule valuation bidderincreases, transfers change allocation rule changes. Thus, communication protocol used determining allocation, reveal transferssupport dominant-strategy implementation.3.1 Efficiency Priority Gamescharacterization welfare-maximizing mechanism done two steps: firstshow allocation scheme 2-bidder priority games optimal12 . Afterwards,characterize strategies players lead welfare maximization priority11. deal simultaneous communication, i.e., bidders send messages simultaneously. observation true sequential mechanisms (see Section 6).12. assume, w.l.o.g., throughout paper 2-bidder priority games B A, i.e., mechanismallocates item bids higher B, otherwise B.242fiAuctions Severely Bounded Communication012...k-2k-10B, y0A, x1A, x1...A, x1A, x11B, y0B, y1A, x2...A, x2A, x2.....................k-2B, y0B, y1B, y2...B, yk2A, xk1k-1B, y0B, y1B, y2...B, yk2B, yk1012...k-2k-10A, x1A, x1...A, x1A, x11B, y1B, y1A, x2...A, x2A, x2.....................k-2B, y1B, y1B, y2...B, yk2A, xk1k-1B, y1B, y1B, y2...B, yk2B, yk1Figure 2: priority game (left) modified priority game (right) based thresholdvalues vectors x, y. entry, left argument denotes winning bidder,right argument price pays. mechanisms differ allocation all-zerobids, payments first row.games; complete description outcome mechanism every profilebidder valuations. two stages take strategic behavior biddersaccount. Yet, observed before, since allocation scheme proved monotone,exists payment scheme strategies dominant.Definition 12. mechanism g Gn,k monotone vector bids bbidder i, probability bidder wins item cannot decrease bidincreases, i.e.,00b bi > bi ai (bi , bi ) ai (bi , bi )following theorem prove priority games welfare maximizing.proof composed four steps: first show assume biddersoptimal mechanisms use threshold strategies. Then, show allocation optimal mechanisms is, w.l.o.g., monotone deterministic. show optimalmechanisms waste communication, i.e., two rows two columnsallocation matrix optimal mechanism identical. Finally, use properties,together several combinatorial arguments, derive optimality priority games.Theorem 3.1. (Priority games efficiency) every pair distribution functionsoptbidders valuations, every v0 , optimal welfare (i.e., w2,k) achievedeither priority game modified priority game (with pair threshold strategies).Proof. first prove theorem given seller low reservation value, i.e.,v0 a. Recall point aim find welfare-maximizing allocation scheme,without taking incentives bidders account. proof uses followingthree claims. later use, Claims 3.2 3.3 proved n players.Claim 3.2. (Optimality threshold strategies) Given mechanism g Gn,(k1 ,...,kn ) ,exists vector threshold strategies achieve optimal welfare g amongpossible strategies, i.e., w(g, s) = maxse w(g, se).Proof. (sketch - formal proof given Appendix A.1)Given profile welfare-maximizing strategies g, modify strategybidder (w.l.o.g., bidder 1) threshold strategy maintaining least expectedwelfare. idea fixing strategies s1 bidders, expected welfare243fiBlumrosen, Nisan & Segalachieved bidder 1 bids bid b1 linear function bidder value v1 .maximum linear functions piecewise-linear function, specifiesoptimal welfare function v1 . Bidder 1 use threshold strategy accordingbreaking points piecewise-linear function choose welfare-maximizing linearfunction segment. Clearly, k 1 breaking points.Claim 3.3. (Optimality deterministic, monotone mechanisms) every nk1 , ..., kn , exists mechanism g Gn,(k1 ,...,kn ) optimal welfare (i.e., existsoptprofile strategies w(g, s) = wn,(k) monotone, deterministic1 ,...,kn )(i.e., winner fixed combination bids) seller never keepsitem.Proof. Consider mechanism g Gn,(k1 ,...,kn ) profile strategies maximizeoptexpected welfare, is, w(g, s) = wn,(k. social planner, aiming maximize1 ,...,kn )welfare, always allocate item bidder highest expected valuation.is, combination bids b = (b1 , .., bn ) allocate item (i.e., ai (b) = 1)bidder argmaxj (E(vj |sj (vj ) = bj )). expected welfare clearlydecrease. addition, always allocate item (we assume v0 a),allocation deterministic. Finally, assume, w.l.o.g., bidder bidsnames (i.e., 0,1 etc.) ordered according expected value bidder has.Then, mechanism also monotone: winning bidder increases bid,expected valuation also increase, expected welfare bidderschange. Thus, bidder still maximal expected valuation.Claim 3.4. (Additional bids strictly help) Consider deterministic, monotone mechanism g G2,k seller never keeps item. g achieves optimal expectedwelfare, matrix representation g two rows (or columns) identicalallocation scheme.Proof. idea optimal protocol exploits communication resources intuitive, although hold settings (a trivial example calculating paritytwo binary numbers, involved examples found Kushilevitz & Nisan, 1997).simple proof statement model, proof basedLemma A.1 appendix following way: Consider optimal mechanismg G2,k two identical rows. mechanism achieves optimal welfareplayers use profile strategies s. gs monotonicity implies two identical rowsadjacent. Thus, mechanism ge G2,(k1,k) k 1 possible bidsrows bidder achieves exactly expected welfare g (when identicalrows united one). welfare achieved strategies bidders,rows player bids united row instead two identical rows. claimfollow Lemma A.1 appendix. According lemma, optimal welfaregame bidders k possible bids cannot achieved oneoptoptbidders k 1 possible bids (i.e., w2,k> w2,(k1,k)).Now, due Claim 3.3, deterministic, monotone game itemoptmust sold achieves w2,k. games, allocation scheme row looks244fiAuctions Severely Bounded Communicationlike [A, ..., A, B...B]. Due Claim 3.4, matrix representation optimal game,two rows allocation scheme. k+1 possible monotonerows game matrix (with prefix 0 k As), mechanism k rows.Similarly, k different columns (of possible k+1) mechanism. Assumerow [B, B, ..., B] g. Then, column [A, A, ..., A] clearly g. Therefore,game matrix consists columns except [A, A, ..., A], compose prioritygame B A. row [B, B, ..., B] g, g priority gameB.Next, complete proof sellers valuation v0 . Consider mechanism h G2,kpair threshold strategies based threshold-value vectors xe, ye achieveoptimal welfare among mechanisms strategies (due Claim 3.2, strategiesexist). modify h, expected welfare (with xe, ye) decrease. Letsmallest index E(vA |fxa vA xg)v.Letb smallest indexa+10E(vB |yeb vB ygb+1 ) v0 . = 0 b = 0, item never allocatedseller, efficient mechanism v0 a.a, b > 0, consider vector bids (i, j). < j < b, expectedvaluations B smaller v0 . Thus, seller keep itemoptimal welfare. < j b, expected welfare bidder B v0 ,expected welfare v0 , thus allocate item B welfaredecrease. Similarly, allocate item j < b. < a,allocation done regardless i, thus assume xa first threshold (i.e.,= 1), similarly b = 1.Now, show optimal allocation combinations bids (i, j)j b. Here, item allocated seller, actually perform auctionk 1 possible bids bidder, bidders valuation range [fx1 , 1],[ye1 , 1]. Note proof (above) case v0 holds ranges,optimal welfare achieved priority game. Altogether, optimal mechanism turnsmodified priority game.3.2 Efficient 2-bidder Mechanisms k Possible BidsNow, finally characterize efficient mechanisms model. turnsoptimal threshold values priority games mutually centered, i.e., thresholdexpected valuation bidder, given valuation bidderlies two adjacent thresholds.Definition 13. threshold values x = (x0 , x1 , ..., xk1 , xk ), = (y0 , y1 , ..., yk1 , yk )bidders A, B respectively mutually centered, following constraints hold:R yiyi1 fB (vB ) vB dvB1 k 1 xi = E(vB |yi1 vB yi ) =F (y ) FB (yi1 )R xBi+1fA (vA ) vA dvAxi1 k 1 yi = E(vA |xi vA xi+1 ) =FA (xi+1 ) FA (xi )easy see given pair distribution functions, pairx,mutuallycentered vectors uniquely defined (when xk = yk and, w.l.o.g., y1 x1 ). basic245fiBlumrosen, Nisan & Segalidea x1 known, clearly calculate y1 (the smallest value solvesx1 = EvB (vB |y0 vB y1 )). Similarly, easy see variables xi yiconsidered continuous, monotone functions x1 . Now, let z solutionequation yk1 = E(vA |xk1 vA z). satisfying 2(k 1) equations, z mustequal xk . Since z also continuous monotone function x1 , single valuex1 equations hold.following intuition shows optimal thresholds priority games mustmutually centered: Assume Alice bids i, is, value range [xi , xi+1 ].monotone mechanism, mechanism designer decide minimal valueBob wins Alice bids i. value Bob least average value Alice,given bids i, Bob clearly receive item. Therefore, Bobs thresholdexactly expected value Alice. proof handle subtletiesintuition suffice (like characterization first thresholdsoptimal modified priority games, see below), thus derive mutually-centeredcondition solution optimization problem.wwww = (a = w , w , ..., w , w = b)Let xw = (a = xw0 , x1 , ..., xk1 , xk = b)01k1 kwmutually-centered threshold values (w.l.o.g., y1 xw1 ).Let x = (a = x0 , x1 , ..., xk1 , xk = b) = (a = y0 , y1 , ..., yk1 , yk = b) two thresholdvalue vectors following constraints hold:(x1 , ..., xk1 , b) (y1 , ..., yk1 , b) mutually-centered vectors13 .Rxx1 = v0 y1 = FA 1(x2 ) v0 FA (v0 ) + x12 vA fA (vA )dvAfollowing theorem says valuation seller item (v0 ) smallenough (e.g., a), efficient mechanism priority game based xw w (whichmutually centered). Otherwise, optimal welfare achieved modified prioritygame based x y.Theorem 3.5. pair distribution functions bidders valuations,sellers valuation v0 item, mechanism P Gk (xw , w ) mechanismoptP Gk (x, y) achieves optimal welfare (i.e., w2,k). particular, P Gk (xw , w ) achievesoptimal welfare v0 = a.Proof. First, prove P Gk (xw , w ) optimal v0 = a. According Theorem3.1 pair threshold values vectors x = (x0 , x1 , ..., xk ),y = (y0 , y1 , ..., yk )P Gk (x, y) achieves optimal welfare. Note x0 = y0 = xk = yk = b,2(k 1) variables optimize.calculate total expected welfare summing first expected welfareentries game matrix B wins item, summing entrieswinner.R yikXfB (vB )vB dvBw(g, s) =(FB (yi ) FB (yi1 )) (FA (xi ) FA (x0 )) i1FB (yi ) FB (yi1 )i=113. Again, unique solution exists when, w.l.o.g., y2 x2246fiAuctions Severely Bounded Communication+kXR xi(FA (xi ) FA (xi1 )) (FB (yi1 ) FB (y0 ))i=2=kXZFA (xi )i=1yiyi1fB (vB )vB dvB +kXZFB (yi1 )i=2xi1fA (vA )vA dvAFA (xi ) FA (xi1 )xixi1fA (vA )vA dvAassume probability density function exists bidder. Thus,express partial derivatives respect variables:Z!yi0(w(g, s))xi =yi1Z0(w(g, s))yi =fB (vB )vB dvBxi+1xifA (xi ) + fA (xi ) xi FB (yi1 ) fA (xi ) xi FB (yi ) = 0fA (vA )vA dvA fB (yi ) + fB (yi ) yi FA (xi ) fB (yi ) yi FA (xi+1 ) = 0Rearranging terms derives yi = EvA (vA |xi vA xi+1 )xi = EvB (vB |yi1 vB yi ) therefore, x, mutually centered optimalefficiency.Now, longer assume v0 = a: According Theorem 3.1, optimal welfareachieved priority game above, achieved modified priority game.threshold values vectors x, y, expected welfare P Gk (x, y) givenformula:Z bZ bvB fB (vB )dvB + FB (y1 )vA fA (vA )dvAFA (x1 ) FB (y1 ) v0 + FA (x1 )++kXi=2kXi=3Z(FA (xi ) FA (x1 ))y1yiyi1Z(FB (yi1 ) FB (y1 ))x1vB fB (vB )dvBxixi1vA fA (vA )dvAFirst-order condition similarly derive constraints x1 y1 given definition x, y, (x1 , ..., xk1 , xk ) (y1 , ..., yk1 , yk ) mutually-centered14 .demonstrate characterization given showing explicit solutioncase uniformly-distributed valuations [0, 1].Corollary 3.6. bidders valuations distributed uniformly [0, 1] v0 = 0,mechanism P Gk (x, y) achieves optimal welfarex = (0,132k 3,, ...,, 1) ,2k 1 2k 12k 1= (0,242k 2,, ...,, 1)2k 1 2k 12k 114. results surprising, since except case one bidders bids 0, prioritygames allocation optimal threshold values must mutually centered (due firstpart proof).247fiBlumrosen, Nisan & SegalProof. According Theorem 3.5 optimal welfare achieved P Gk (x, y), x,mutually centered. uniform distributions, derives following constraints,i+1given vectors x, unique solution: 1ik1 xi = yi12+yiyi = xi +x2see constraints implied, note conditional expectationsecond players value, given value uniformly distributed yi1 yi ,exactly yi12+yi .1y1 = x12+1 , implyingexample, k = 2 constraints x1 = 0+y2x1 = 1/3 y1 = 2/3 optimal 1-bit mechanism Example 1.optimal mutually-centered thresholds k = 4 are, instance, x = (0, 71 , 37 , 75 , 1)= (0, 72 , 47 , 76 , 1).3.3 Profit-Optimal 2-bidder Mechanisms k Possible BidsNow, present profit-maximizing 2-bidder mechanisms. results literatureprofit-maximizing auctions assume distribution functions bidders valuationsregular (as defined below). valuations bidders distributedregular distribution function, well known Vickreys 2nd-price auction,appropriately chosen reservation price, profit-optimal (Vickrey, 1961; Myerson, 1981;Riley & Samuelson, 1981) unbounded communication.Definition 14. (Myerson, 1981) Let f probability density function, let Fcumulative function. say f regular, functionve(v) = v1 F (v)f (v)monotone, strictly increasing function v. call function ve() virtual valuationbidder.example, bidders valuations distributed uniformly [0, 1], biddervaluation v virtual valuation ve(v) = 2v 1.Definition 15. virtual surplus game virtual valuation bidder (including seller15 ) receives item.key observation work Myerson (1981), also use,Bayesian-Nash equilibrium, expected profit equals expected virtual surplus (in interim individually-rational equilibria losing bidders getting surplus).use property reduce profit-optimization problem welfare-optimization problem, already given full solution. Myersons observation originallyproved direct-revelation mechanisms. observe Myersons observation alsoholds auctions bounded communication. is, given k-bid mechanism,expected profit every Bayesian-Nash equilibrium equals expected virtual surplus.Proposition 3.7. Let g Gn,k mechanism Bayesian Nash equilibrium =(s1 , ..., sn ) interim individual rationality. Then, expected revenue achievedg equal expected virtual surplus g.15. sellers virtual valuation defined original valuation (v0 ).248fiAuctions Severely Bounded CommunicationProof. Consider following direct-revelation mechanism gd : player bids truevaluation vi . mechanism calculates si (vi ) every i, determines allocationpayments according g. easy observation gd incentive compatible (i.e.,truthful bidding Bayesian-Nash equilibrium players) interim individuallyrational. According Myerson observation direct revelation mechanisms, expectedrevenue gd equal expected virtual surplus. However, every combinationbids, mechanism output identical allocations payments. Thus, expectedrevenue expected virtual surplus equal mechanisms.According Theorem 3.5, optimal welfare achieved either priority gamemodified priority game. model bidders consider virtual valuationsvaluations, let P G(ex, ye) P G(x, y) mechanisms candidatesachieve optimal welfare (see Theorem 3.5 full characterization). Now, considermechanisms, except payment ec replaced respective true valuation c = ve1 (ec) (i.e., ec = ve(c) ). Denote mechanisms P Gk (xR , R ), P Gk (xr , r ).mechanisms achieve optimal profit (original) model. Note distribution functions must regular (but necessarily identical) reductionwork.Theorem 3.8. bidders valuations distributed regular distribution functions, mechanism P Gk (xr , r ) mechanism P Gk (xR , R ) (see definitions above)achieve optimal expected profit among profits achievable interim-IR BayesianoptNash equilibrium mechanism G2,k (i.e., r2,k).x, ye) (x, y) defined above. mechanismProof. Consider threshold-value vectors (eP G(ex, ye) efficient model bidders consider virtual valuationsvaluation (the proof holds P G(x, y) efficient mechanism). densityfunction f regular, therefore virtual valuation ve() strictly increasing. Thus,P Gk (xr , r ) (when bidders use original valuations) exactlyallocation every combination bids P Gk (ex, ye) (when bidders considervirtual valuations valuations). conclude P Gk (xr , r ) achieves optimalexpected virtual surplus thus also optimal profit.case welfare optimization, give explicit solution caseuniform distribution functions. direct corollary Theorem 3.8. Noteoptimal profit achieved modified priority game. holds since uniformdistribution bidders expected virtual valuation negative bid 0,efficient mechanism sell item bidders bid 0.Corollary 3.9. bidders valuations distributed uniformly [0, 1] v0 = 0,modified priority game P Gk (x, y) achieves optimal expected profit amongprofits achievable interim-IR Bayesian-Nash equilibria mechanisms G2,k ,11 (1 )(2k 5) (1 )x = (0, , +, ..., +, 1)22k 32k 3= (0, , +2 (1 )(2k 4) (1 ), ..., +, 1)2k 32k 3249fiBlumrosen, Nisan & Segal=2+ 1+32(1)=1(2k3)2( =58k=2).4. Optimal Mechanisms n Bidders Two Possible Bidssection consider games among n bidders bidder 2 possible bids(i.e., send 1 bit mechanism). give characterization optimalmechanisms general distribution functions. characterization optimal n-biddermechanism k possible bids seems harder, remains open question.difficulty stems fact monotonicity allocation rule dictateexact allocation rule general case. Rather, many possible allocationschemes cannot rule know strategies bidders.16 Therefore,seems one solve involved combinatorial problem finding optimalallocation rule together finding optimal payments. Priority games 2 possiblebids per player interpreted sequence take-it-or-leave-it offers; playerhighest priority interpretation first player offered, acceptsoffer (i.e., bids 1) receive it. See work Sandholm Gilpin (2006)analysis take-it-or-leave-it mechanisms. Moreover, 1-bit priority games actuallysolution full-information version secretary problem (e.g., Gilbert & Mosteller,1966; Ajtai, Megiddo, & Waarts, 2001). decision maker meets players (or potentialsecretaries hired), one another, search player highestvalue. decision maker knows underlying probability distributions. decision,however, made online player receive item upon arrivalnever receive item.4.1 Characterization Optimal Mechanismsfirst observe priority games also maximize welfare n-bidder games 2 possible bids. easier see k-possible-bids case. Claim 3.2 Theorem 3.1,bidders use threshold strategies. efficient mechanism allocate item,combination bids b , bidder highestbids bi.expected welfareGiven distributions i.i.d, xi xj E vi vi [xi , b] E vj vj [xj , b]E (vi |vi [a, xi ] ) E (vj |vj [a, xj ] ). Therefore, ties broken accordingorder thresholds. sellers reservation price v0 high enough, efficientmechanism modified priority game.17show characterization optimal thresholds priority games.show optimal mechanisms use fully discriminatory payments: bidderhighest priority priority game pays highest payment wins, forth.optimal modified priority game given simple recursive formula. sellerallocates item bids zero, constraints become cyclic.16. Consider, example, 3-bidder 3-bid priority game, item allocated playersecond-highest priority players bid highest bid. mechanism also monotoneidentical actions players.17. see this, must note efficient mechanism seller never keep item onebidder bids 1 (then, threshold higher v0 bidder gain higher welfare).250fiAuctions Severely Bounded CommunicationLetx = (x1 , ..., xn )= (y1 , ..., yn ) profiles threshold values nbidders following constraints hold:1mn21mn2x1 = E (v |a v xn )xm+1 = (1 F (xm )) E v v [xm , b] + F (xm ) xmPn1 Qn1i=1 ( j=i+1 F (xj )) (1 F (xi )) E v v [xi , b]xn =Q1 n1i=1 F (xi )y1 = v 0ym+1 = (1 F (ym )) E v v [ym , b] + F (ym ) ym(1)(2)(3)(4)(5)prove either mechanism P G2 (x ) mechanism P G2 () achieveoptimal welfare. thresholds description shows, thresholds modifiedpriority game (i.e., seller keeps item bids zero) definedsimple, easy-to-compute recursive formula. optimality thresholdsshown following intuitive argument: Consider new bidder joins set 1bidders. efficient auction allocate item bidder valuegreater optimal welfare achievable first 1 bidders. Therefore,threshold bidder equal optimal welfare gained preceding bidders;indeed, probability 1 F (yi1 ), bidder valuation greaterexpectedbidders (yi1 ) average contributionwelfare attainedE v v [ym , b] ); probability F (yi1 ) contribute optimalwelfare remains yi1 . intuition shows profit-maximizing thresholds(Equations 4,5) independent number players, enables onlineimplementation profit-maximizing auctions.Theorem 4.1. bidders valuations distributed distribution function, mechanism P G2 (x ) mechanism P G2 () achieves optimal expectedwelfare. particular, v0 = a, P G2 (x ) efficient mechanism.Proof. already observed exists priority game achieves optimalwelfare threshold strategies. Consider priority game among n bidders, indexedpriorities (i.e., 1 2... n ). Every bidder wins item bids 1Qthe bidderswith higher priorities bid 0. Thus, probability bidder winsnj=i+1 F (xj ) (1 F (xi )). bidders bid 0, either bidder n wins sellerkeeps item herself. expected welfare game, bidders usethreshold strategies x1 , ..., xn is:n!RbnnXf (vi )vi dvixF (xj ) (1 F (xi ))+F (xi ) E0w(g, s) =(1 F (xi ))i=1j=i+1i=1E0 = E(vn |vn [a, xn ]) priority game Eo = v0 modified prioritygame (the second term relates case bidders bid 0). maximum,partial derivatives respect x1 , ..., xn equal zero, resulting characterizationoptimal solution.251fiBlumrosen, Nisan & Segalbidders 1 n 1 get xm equals (both priority gamemodified priority game):m1m1X m1F (xj ) (1 F (xi )) E vi vi [xi , b] +F (xi ) E (vn |vn [a, xn ] )i=1j=i+1i=1,i6=mrecursive formula reached calculating xm+1 xm , Equations 25 follow. bidder n priority game first order conditions yield constraintEquation 3. = 1, x1 = E (vn |a vn xn ) (in priority game)x1 = v0 (in modified priority game).Section 3, characterize profit optimal mechanism reductionwelfare optimizing problem. Again, reduction performed regular distributions. Consider model bidders take virtual valuations valuations.Let P G2 (eu) P G2 (ez ) mechanisms achieve optimal welfare model(see Theorem 4.1 above). Let P G2 (u) P G2 (z) similar mechanisms respectively,except payment ec replaced respective original valuation c = ve1 (ec).Theorem 4.2. bidders valuations distributed regular distribution function, mechanism P G2 (u) mechanism P G2 (z) achieves optimalexpected profit among profits achievable Bayesian-Nash equilibrium interim IR.Proof. corollary Theorem 4.1. reduction done Theorem 3.8,possible due regularity distribution function.Again, optimal thresholds modified priority game given simplerecursive formula intuitive meaning. recursion identical welfare optimizing formula (Equation 2), difference value first thresholdhold y1 = ve1 (v0 ). intuition given best revenue achievablefirst 1 bidders yi1 , probability F (yi1 ) new playerable pay higher price (due individual-rationality restriction) thereforeoptimal revenue remains yi1 . value greater yi1 , cannot chargedaverage value (E(v|yi1 v b)).Now, give explicit solutions uniform distribution support [0, 1].following recursive constraints characterize efficient profit-optimal mechanismsconstraints given Theorems 4.1 4.2 uniform distributions.Let (x1 , ..., xn ) [0, 1]n threshold values following constraints hold:x1 ={1, ..., n 2}xm+1 =xn =252xn21 x2m+22Pn1 Qn1x1 x2ij=i+1 ji=1Qn12 1 i=1xi(6)(7)(8)fiAuctions Severely Bounded CommunicationLet = (y1 , ..., yn ) [0, 1]n threshold values y1 ={1, ..., n 2}ym+1 =12and:21 ym+22Corollary 4.3. Consider threshold valuesx = (x1 , ..., xn )= (y1 , ..., yn ) definedabove. bidders valuations distributed uniformly [0, 1] v0 = 0, P G2 (x)achieves optimal welfare P G2 ( ) achieves optimal profit.example, n = 5 = (0.5, 0.625, 0.695, 0.741, 0.775).description simpler closed-form formulae could find.5. Asymptotic Analysis Welfare Profit Lossessection, measure performance optimal mechanisms presented earliersections. Although present characterization optimal mechanismsgeneral model k possible bids n bidders, present mechanisms generalcase asymptotically optimal. simplicity, assume valuations range[0, 1] (all results apply general range [a, b] changes constantsanalysis).analyze welfare loss (Subsection 5.1), profit loss (Subsection 5.2), finally,Subsection 5.3 measure profit loss welfare loss 1-bit mechanismn bidders. result asymptotic respect amount communication,except Section 5.3 respect number bidders.5.1 Asymptotic Bounds Welfare Lossnext theorem shows matter bidders valuations distributed,always construct mechanisms welfare loss incur diminishes quadraticallyk. true number bidders fix (when k > 2n). particular, efficientmechanism presented Theorem 3.5 incurs welfare loss O( k12 ). intuition behindproof: given distribution functions bidders, construct certain thresholdstrategy, dominant bidders. using strategy, bidderbid bid probability smaller k1 . way, probability welfare lossmay occur O( k1 ) (for two players, instance, welfare loss possiblediagonal games matrix). average welfare loss also O( k1 ), resultingtotal expected loss O( k12 ).Theorem 5.1. (fixed) number bidders n, set distribution functionsbidders valuations, exist set mechanisms gk Gn,k (k = 2n + 1, 2n + 2, ...),incur expected welfare loss O( k12 )). results implemented dominantstrategies ex-post individual rationality.requirement k > 2n (here Proposition 5.3 below) due construction symmetric mechanism following proof. results hold even withoutrequirement, shown asymmetric construction general settingwork Blumrosen Feldman (2006).253fiBlumrosen, Nisan & SegalProof. proofs idea: construct priority game biddersdominant threshold strategy, probability bidder bid bid smallernk . done dividing density functions bidders nk intervalsequal mass, combining thresholds vector k threshold values.bidders use threshold strategy, welfare loss possible onebidder bids highest bid. observation leads upper bound.PLet 1 , ..., n integers ni=1 = k 2, every i, nk 1(clearly numbers exist). every bidder i, let = (y1i , ..., yi ) set thresholdvalues divide distribution function fi + 1 segments mass (wheny0i = 0, yi +1 = 1), i.e., every bid j, Fi (yj+1 ) Fi (yj ) = i1+1 .Let X = { ni=1 } {v0 }, |X| = k 1, union threshold values (we addarbitrary threshold values size X smaller k 1). Let x = (0, x1 , ..., xk1 , 1)threshold-value vector created ordering threshold values X smallestlargest. Now, consider n-bidder mechanism P Gk (et) e= (x, .., x). thresholdstrategy based x dominant bidders, ex-post IR. construction18sets 1 , ..., n , every bidder bid particular bid w.p. 2nk .Next, bound welfare loss. divide possible cases accordingnumber bidders bid highest bid. Since bidders use thresholdstrategy, one bidder bids highest bid, welfare loss incurred (he definitelyhighest valuation). 1 bidder bid highest bid i, expected welfareloss exceed xi+1 xi . set bidders N , denote probabilitybidders bid P r(T = i), probability biddersbids smaller P r(N \ < i). Thus, expected welfare loss smaller (when2n < k):nXXkXP r(T = i)P r(N \ < i) (xi+1 xi )j=2 N, |T |=j i=1nXXkXP r(T = i) (xi+1 xi )j=2 N, |T |=j i=1(nj) k jn XXX 2nj=21i=1k(xi+1 xi )=nXn2n jj=2jk<2n 4n21k2valuations bidders smaller v0 , welfare loss (iteasy see assume, w.l.o.g., x1 = v0 ). Note despite coefficient1exponential n, consider constant n fixed. Example,k2n = 2 similar proof shows welfare loss smaller k82 (when k > 3).Asymptotic quadratic bounds also given Wilson (1989), studied similarsettings regarding effect discrete priority classes customers. work Wilsonuncertainty supply, paper demand uncertain well.results illustrations idea deadweight loss second order18. every bidder i, every bid j, Fi (xj+1 ) Fi (xj )2541kcbn2nkfiAuctions Severely Bounded Communicationprice distortion. (The price distortion model maximum differenceprices different bidders facing item given others bids,bounded k1 .) Indeed, small price distortion ensures probabilityinefficient allocation small inefficiency small occur.Theorem 5.1 related proposition 4 paper Nisan Segal (2006). NisanSegal showed discretizing exactly efficient continuous protocol communicatingreal numbers yields truly polynomial approximation scheme proportional(i.e., > 0 realize approximation factor 1 using numberbits polynomial log(1 ) ). Here, discretize continuous efficient auction(e.g., first-price auction), number bidders. Discretization achievesapproximation error exponential (minus) number bits sent per bidder, i.e.,asymptotically proportional k1 . However, care average-case approximationeven closer, worst-case approximation within error ensuresaverage case approximation within 2 (the probability error madeorder ).show asymptotic upper bound tight, i.e., distributionfunctions (and particular, uniform distribution) minimal welfare loss exactlyproportional k12 . show constant number bidders.Theorem 5.2. Assume bidders valuations uniformly distributed v0 =0. Then, efficient 2-bidder mechanism P Gk (x, y) described Corollary 3.6 incurs1welfare loss exactly 6(2k1)2 . Moreover, (fixed) number bidders nv0 , exists positive constant c mechanism g Gn,k incurs welfareloss c k12 .Proof. first prove first part theorem, regarding 2-bidder mechanisms. Notegiven mechanism make non-optimal allocation combinations bidsdiagonal lower secondary diagonal matrix representation2-bidder game (i.e., bA = bB bA = bB + 1). bids (i, j),1overlapping segment [xi , xi+1 ] [yj , yj+1 ] size 2k1. Given vector bids(i, j), one valuations overlapping segment, allocation optimal(note allocate item B main diagonal, secondary1diagonal). probability valuation overlapping range (2k1)2.expected valuation priority game (when valuation overlappingsegment) exactly middle segment. expected valuation optimalauction (with unbounded communications), restricted overlapping interval,123 point range. Thus, welfare loss 16 segment, i.e., 61 2k1. Thus,every vector bids main diagonal secondary-diagonal expected1welfare loss 61 (2k1)3 . (2k 1) vector bids, thus total welfare lossexactly1.6(2k1)2similar argument shows even sellers valuation v0 non zero, welfare1loss asymptotically greater (2k1)2 : let z1 , ..., zm sizes overlappingsegments (only valuations bidders greater v0 ). Clearly, 2k1255fiBlumrosen, Nisan & SegalPmi=1 zi1. Then, welfare loss game least(1 v0 )2Xi=1zi219 :zi(1 v0 )2 X 3 (1 v0 )2 2k 1(1 v0 )21=zi3666(2k 1)6(2k 1)2i=1proof second statement easily derived: Consider case bidders1 2 valuations 12 , rest bidders valuations 12 .occurs constant probability 21n . best mechanism alwaysallocate item one 1 2. due first part theorem, 2-biddermechanism welfare loss proportional k12 incurred (the fact valuationrange [ 12 , 1] [0, 1] changes constant c). hold opportunitycost v0 seller. Thus, mechanism incur welfare loss ( k12 ).Note asymptotic results hold even restrict attention symmetricmechanisms. Actually, prove upper bound Theorem 5.1 constructing symmetric mechanism (we allocate item bidders bid highest bidequal probabilities). However, asymmetric mechanisms incur strictly smaller welfareloss symmetric mechanisms. example, valuations distributed uni1formly, optimal welfare loss 6(2k1)2 (by Theorem 5.2) compared optimalwelfare loss 6k12 attained symmetric mechanisms20 (i.e., welfare loss asymmetricmechanisms 4 times better). observation interesting light resultsHarstad Rothkopf (1994) Wilson (1989). Harstad Rothkopf studied symmetricEnglish auctions, analyzed optimal price-jumps auctions. results shownon-anonymous prices (i.e., different jumps bidder) achieve better resultssymmetric (or anonymous) jumps. also characterize optimal price-jumpsauctions (mutually centered threshold values). Wilson also studied symmetricpriority classes model, also gives convergence rate n12 efficiency loss(where n number priority classes). show asymmetric mechanismsincur smaller efficiency loss, although asymptotic convergence rate same.One obvious drawback characterization optimal mechanismsdesign detail-free (as Wilsons doctrine) must know priorsbidders designing mechanisms. design mechanism regardlessdistribution functions, always incur low welfare loss? answercan, efficient commonly-known priors case. observesimple, symmetric mechanism use equally spaced thresholds (i.e., P Gk (x, ..., x),1x = (0, k1 , k2 , ..., k1k , 1) ), incurs welfare loss greater k possible distributionfunctions. hard verify actually best donedetail-free mechanism: mechanism exist distribution functionsexpected welfare loss least order k1 . severely low communication,difference detail-free mechanisms prior-aware mechanisms (with loss19.use fact z = (z1 , ..., zm ) mth dimensional simplex,Pmthe 3left inequality1i=1 zi m2 .20. easy show efficient symmetric mechanisms similar priority games, except itemallocated equal probabilities cases ties. thresholds bidders simply dividevaluations range identical segments. Then, straightforward show welfare lossexactly 6k12 .256fiAuctions Severely Bounded CommunicationO( k12 ) ) may substantial. Note without communication constraints, socially-efficientresults achieved detail-free mechanisms second-price (Vickrey) auctions.5.2 Asymptotic Bounds Profit Lossdone Theorem 3.8, profit optimization problem reduced welfareoptimization problem maximizing expected virtual surplus.Proposition 5.3. Assume bidders valuations distributed regular distribution functions. Then, number bidders n, exist set mechanisms gk Gn,k(k = 2n + 1, 2n + 2, ...) incur profit loss O( k12 ). profit loss comparedoptimal, individually-rational mechanism unconstrained communication.Proof. Consider model bidders consider virtual valuations vei (vi )valuations. range valuations model, take union rangesbidders virtual valuations. Denote range [, ]. Let ge Gn,kmechanism achieves maximal welfare model. Due Theorem 5.1, ge incurswelfare loss smaller c k12 , positive constant c (the constant takesaccount size virtual valuations range ). Let g mechanismallocation ge, payment qei bidder ge replaced qi = vei 1 (qei )g, i.e., qei = vei (qi ). Since vei non-decreasing (by regularity), allocationrules g ge identical every bids combination. Thus, g achieves maximalexpected virtual surplus, loss expected virtual surplus smaller c k12 .proposition follows.Again, upper bound asymptotically tight: uniform distribution,mechanism incurs profit loss ( k12 ). result derived Theorem 5.2 usingsimilar arguments Proposition 5.3.Proposition 5.4. Assume bidders valuations distributed uniformly. Then,(fixed) number bidders n, exists positive constant c mechanismg Gn,k incurs profit loss c k12 .far, assumed bidders valuations drawn statistically independent distributions. point relaxation general joint distributionsnon-interesting model. Specifically, show trivial priority gamebidders use threshold strategy based vector x = (0, k1 , k2 , ..., k1k , 1)always incurs expected welfare loss smaller k1 , mechanism asymptotically better. words, exists joint distribution functionmechanism incurs welfare loss proportional k1 .5.3 Asymptotic Bounds Growing Number Bidderssubsection, fix size communication allowed (to two possible bids),show asymptotic bounds function number bidders rather amountcommunication. Unfortunately, able prove boundsuniform distribution.257fiBlumrosen, Nisan & Segalrestrict attention symmetric mechanisms, solution simple. Using1threshold x = n n1 (for bidders) achieves maximal expected welfare,21exact formula showing optimal welfare loss O( lognn ).show optimal asymmetric mechanisms incur asymptotically smaller welfareprofit losses O( n1 ). mechanisms fully discriminate agents.Theorem 5.5. Consider mechanisms P G2 (x ) P G2 () described Corollary4.3 (in Section 4.1). bidders valuations distributed uniformly, welfareloss P G2 (x ) profit loss P G2 () smaller n9 .Proof. Let x revenue-optimizing thresholds Corollary 4.3. boundwelfare loss P G2 (x), efficient mechanism incur even smaller loss. assume,w.l.o.g., g, bidders indexed according priorities (i.e., 1 2... n ).bidder wins bidding 1, maximal welfare loss 1 xi . biddersbid 0, use trivial upper bound 1 welfare loss . Therefore, boundwelfare loss with:nnnXxj (1 xi ) (1 xi ) +xi(9)i=1j=i+1i=1following two claims easily verified induction:Claim 5.6. n1 xnClaim 5.7. n15xn2n2n32nNow, prove induction n first summand Equation 9 n8 . Denotefirst term wln . Note wln+1 = (1 xn+1 )2 + xn+1 wln . Assuming wln n8 ,8using two claims above, easy prove wln+1 n+1n > 14. (thereader verify also holds n 14.)Next, prove (again induction n) second expression smaller n1 .QQ1assume ni=1 xi n1 prove n+1i=1 xi n+1 (using Claim 5.7 ) :n+1i=1xi = xn+1nxi xn+1i=12n 1 12n 1 1111<+=n2n + 2 n2n + 2 n 2n(n + 1)n+1Thus, expected welfare loss smaller n8 + n1 = n9statement profit loss derived result welfareloss (again, reducing profit optimization welfare optimization). Nevertheless, directproof easy given claims: thresholds x above, profit21. expected welfare given by: xnx2+ (1 xn )1+x.2n12n+1maximumachieved(first order1n1 n n1 ( n1 1) ( n+11maximal welfare unbounded communication). easy see 1 n1 n converges logn n1log nwelfare loss also converges logn n . indeed, 1 n1 n = 1e n logn n (since 1ex xsmall xs).conditions) with: x = n1n1. welfare loss thus:258fiAuctions Severely Bounded CommunicationB0101A, 0A, 13B, 14B, 34Figure 3: (h1 ) sequential game (when bids first) attains higher expected welfaresimultaneous mechanism communication requirement (2 bits).outcome achieved Bayesian-Nash equilibrium.loss boundedsmallerPn Qni=1xj=i+1 j (1 xi ) (1 xi ) proved8 22n.6. Sequential Auctionssequential mechanisms, bidders split bids smaller messages sendalternating order. section, show sequential mechanisms achievebetter results. However, additional gain (in amount communication)linear factor number bidders.sequential mechanism mechanism bidder may send several separatemessages, order (not necessarily round-robin fashion). stage,bidder knows messages bidders sent far. messagessent, mechanism determines allocation payments. study generalframework auctioneer adaptively determine order messagessizes according message history. auctioneer also use randomizationdecisions. measure communication volume mechanism numberbits actually transmitted.Definition 16. communication requirement mechanism maximal amountbits may transmitted bidders mechanism.strategy bidder sequential mechanism threshold strategy stagegame bidder determines message sends comparing valuationthreshold values x1 , ...xi (where bidder + 1 possible bids stage i).Example 2. following sequential mechanism communication requirement 2(see Figure 3 ): Alice sends one bit mechanism first. Bob, knowing Alices bid, alsosends one bit. Alice bids 0: Bob wins bids 1 pays 14 ; bids zero Alicewins pays zero. Alice bids 1: Bob also wins bids 1, pays 34 ;bids zero, Alice wins again, pays 13 .easy see mechanism Bayesian-Nash equilibrium23 achievesexpected welfare 0.653. saw efficient simultaneous mechanism22. priority games based thresholds, bidder wins item, pays yi . Thus, maximalprofit loss bidder wins 1 yi .23. following strategies Bayesian-Nash equilibrium: Alice uses threshold 12 , Bob usesthreshold 41 Alice bids 0 34 Alice bids 1.259fiBlumrosen, Nisan & Segalcommunication requirement 2 bits 0.648 (see Section 1). conclude sequentialmechanisms gain efficiency simultaneous mechanisms.Note throughout paper searched optimal mechanisms amongmechanisms Bayesian-Nash equilibria, managed implement optimumdominant strategy. sequential mechanisms less likely find dominant-strategyimplementations, thus example uses Bayesian-Nash implementation. result below, however, assume particular equilibrium concept sequentialmechanisms.significant extra gain sequential mechanisms simultaneous mechanisms? following theorem states every sequential mechanism communicationrequirement exists simultaneous mechanism achieves leastwelfare communication requirement nm (where n number bidders)24 .Note general (e.g., Kushilevitz & Nisan, 1997), multi-round protocols reducecommunication exponential factor. observe gain sequentialmechanism actually even smaller. many environments, messages sent centralized authority (auctioneer); therefore, extra bits communication requiredinform bidders previous messages bidders. following theoremholds order transmission size sub-messages, even valuesadaptively determined according previous messages.goal section show gain sequential auctions, comparedsimultaneous auctions, mild. offer comprehensive analysis case,present welfare-maximizing revenue-maximizing auctions. Several recent papersstudied different aspects sequential auctions similar constraints. SandholmGilpin (2006) analyzed sequential auctions designed sequences take-it-or-leave-it offers.paper Kress Boutilier (2004) studied sequential single-item auctions discreteprice increment, information used subsequent stages. work Parkes(2006) studied information elicitation simultaneous sequential auctionsvalues uncertain.First, observe assume welfare-maximizing strategiesbidders threshold strategies. Again, show message chosen bidderi, welfare linear function vi . show use backward-inductionargument: last message, bidders clearly use thresholds. Therefore, previousstages welfare (as function vi fixing strategies bidders) linearcombination linear functions linear function. maximum linearfunction piecewise linear function thresholds crossing points.Theorem 6.1. Let h n-bidder sequential mechanism communication requirement m. Then, exists simultaneous mechanism g achieves, dominantstrategies, least expected welfare h, communication requirement smallernm.Proof. Consider n-bidder mechanism h Bayesian-Nash equilibrium,communication requirement (for simplicity, assume n divides m, i.e., bidder sends24. Note sequential mechanisms bidders must informed bits bidders sent(we take account analysis), total gain communication mild.260fiAuctions Severely Bounded Communicationnbits). exists profile = (s1 , ..., sn ) threshold strategies achievesoptimal welfare h. First, give upper bound total number thresholdsbidder uses game. bidder i, let 1i , ..., ki (positive) sizes kimessages sends h. Let ji (1 j ki ) number bits sentbidders (including i), bidder sends jth message. choosing messagesize ji , bidder uses 2j 1 thresholds. stage, every bidder usedifferent set thresholds, everyhistory game. Thus, sending jthpossiblejijmessage use 22 1 different thresholds. Summing up, bidder usesPki(i) = j=1 2 j 2 j 1 thresholds. Now, assume, w.l.o.g., biddersnumbered according order send last messages (i.e., k11 > k22 > ... > knn ).Recall total numberof1bits sentbidders m. sending last message,m1kk11bidder 1 thus uses 221 < 2m different thresholds. Since messages2m12k2non-zero size, bidder 2 22 k2 1 < 2m1 different thresholdslast stage. Similarly, every bidder use 2mi+1 thresholds lastmessage. therefore, before-last message bidder uses 2mi1 differentthresholds (the worst case occurs one bidder sends one bit bidder 2 lastmessages). follows maximal number different thresholds bidder is:(i) =kiX2j 2j 12mi+1 + 2mi1 +<2j 2j 1j=1j=1< 2mi+1 + 2mi1 +kX2mi2X2j<2mi+1 + 2mi1 + 2mi1<2mi+2j=1Now, let g simultaneous mechanisms bidder simply informsmechanism thresholds uses h valuation lies. Clearly, everyset valuations bidders, allocation g h identical. Due inequalityabove, + 2 bits suffice bidder express Pnumber. concludenumber bits sent bidders g smaller than: ni=1 (m + 2) = nm n(n3).2Finally, mention set allocation scheme payment schemeg threshold-strategies based thresholds equilibriumexpected welfare decrease. shown Section 3, turn mechanismmonotone allocating item deterministically bidder highest expectedvalue, combination bids. dominant-strategy equilibrium follows.analysis holds order sizes bidder messages, evendepend history messages, since counting number thresholds stilldone way.7. Future Workpaper concerns single-item auctions severely limited ability elicitinformation bidders: possible bids available player althoughplayer may continuum types. give comprehensive analysis261fiBlumrosen, Nisan & Segalauctions, present welfare- revenue-maximizing mechanisms restrictions.asymptotically analyze losses optimal mechanisms compared auctionsunrestricted communication, also compare auctions biddersmessages sent sequentially.leave several questions open. obvious problem exact characterizationoptimal mechanisms arbitrary number players arbitrary numberpossible bids. paper fully characterized optimal 2-bidder k-bid auctionsoptimal n-bidder 2-bid auctions, presented asymptotically optimal resultsgeneral case n players k bids. Also, future work may provide asymptotic analysiswelfare- revenue loss function k n (we provided separateasymptotic analysis variables).additional interesting question regarding gain allocating bits communication non-uniformly among agents. simple domains (like 2-bidder simultaneous auctions) uniform distribution communication seems best option,would unclear, probably untrue, general settings. addition, seemsconcepts methods presented work extend general frameworks,like general single-parameter mechanism-design settings mechanism design interdependent values (some extensions given recent work Blumrosen & Feldman,2006).Finally, work presented partial study sequential auctions communicationrestrictions. kind auctions captures many reasonable real-life settings, seemsanalytically challenging. present characterization optimal sequential mechanisms paper, direct comparison simultaneous sequentialmechanisms communication requirement. Future work may also compareprior-aware sequential mechanisms detail-free sequential mechanisms (a similar comparison simultaneous mechanisms showed detail-free mechanism achievetrivial results). Another possible extension would take integrated approachstudy settings partially-known priors.Acknowledgment. thank Ron Lavi, Daniel Lehmann, Ahuva Mualem MottyPerry helpful discussions. also thank several anonymous referees valuable remarks, suggestions insights. first two authors supported grantsIsraeli Academy Sciences. third author supported National ScienceFoundation.Appendix A. Missing proofssection present formal proofs results given bodypaper.262fiAuctions Severely Bounded CommunicationA.1 Optimality Threshold StrategiesProof Claim 3.2 Theorem 3.1:Proof. Given vector strategies achieve optimal welfare g (i.e.,maxsek k w(g, se) ), show every player modify si thresholdi=1strategy, welfare decrease.Assume si threshold strategy. Therefore, must , , [a, b], < <si () = si () = si () 6= (where bid player i).show strategy vector identical , except every si () = m,w(g, s) w(g, ).Denote probability players except bids bi P r(bi ). Thus, expectedwelfare game g given bidder valuation vi bidsplayers use strategies si is:XXP r(bi ) ai (m, bi ) vi +aj (m, bi ) E(vj sj (vj ) = bj )bij6=iNote expected welfare linear function vi , denote h(m) vi +t(m) (the constants h(m) t(m) depend bid m).know achieve optimal welfare g si () = m. Therefore,bid l si () = l, expected welfare increase, i.e.:l 6=h(m) + t(m) h(l) + t(l)(10)h(m) + t(m) h(l) + t(l)(11)Similarly, si () = m:l 6=convex combination , due Equations 10 11:l 6= h(m) + t(m) h(l) + t(l)Thus, expected welfare player i, given vi = , maximal bids m. Therefore, modifying si si () = total expected welfare decrease.repeat process si becomes threshold strategy.25A.2 Optimal Mechanisms Use Possible BidsoptoptLemma A.1. w2,(k,k)> w2,(k1,k)every k > 1.Proof. Let g G2,(k1,k) deterministic, monotone mechanism achieves optimalwelfare threshold strategies based vectors (x, y). row g form[A, ..., A, B, ..., B], let li {0, ..., k} first index row B wins.modify g ge G2,(k,k) adding missing row, change threshold strategy xxe <k+1 , welfare strictly improves. assume, w.l.o.g., thresholdsunique (i.e., 0 < x1 < ... < xk1 < 1, 0 < y1 < ... < 1).25. See analysis similar problems, e.g., Athey (2001).263fiBlumrosen, Nisan & SegalCase 1. row [B, ..., B] games matrix.0E(v |0v )0Let x1 = vB B 2 B 1 , let xe = (0, x1 , x1 , x2 , ..., xk2 , 1). create newgame ge adding line [B, ..., B] first line. easy see allocation0g ge identical rows except new one. vA [0, x1 ] vB [0, y1 ]ge allocates item B g allocated item A. distribution functions0always positive, hence occur positive probability. Since E(vA |vA [0, x1 ]) <0x1 < EvB (vB |0 vB y1 ), expected welfare strictly increased. higher bidsbidder B, allocation first row clearly efficient now, therefore welfareloss incurred.Case 2. row [B, ..., B] appear gs game matrix.Due monotonicity, g must two rows + 1 two columns j j + 1allocate item B bids (i, j), (i, j + 1)bids (i + 1, j), (i + 1, j + 1). create mechanism ge adding row i0 identicalrow + 1 except B wins index j + 1. new threshold constructed follows:E(vB |yj vB yj+1 ) < xi+1 :00Let xi+1 = E(vB |yj vB yj+1 ), let xe = (0, x1 , ..., xi , xi , xi+1 , ..., 1). previouscases, welfare entries hasnt changed, except strictly positive improvement(i0 , j) entry.E(vB |yj vB yj+1 ) xi+1 :00Let xi = E(vB |yj+1 vB yj+2 ) let xe = (0, x1 , ..., xi , xi , xi+1 , ..., 1). show0since g efficient xi+1 < xi < xi+2 : First, E(vB |yj+1 vB yj+2 ) > E(vB |yj vByj+1 ) xi+1 ; Also, since wins bids (i + 1, j + 1), E(vB |yj+1 vByj+2 ) E(vA |xi+1 vA xi+2 ) < xi+2 . follows expected welfare strictlyincreased entry (i0 , j + 1), decreased entries.A.3 Optimal Symmetric 1-bit MechanismsFollowing optimal 1-bit 2-bidder mechanisms assuming independent uniform distribution values. socially-efficient symmetric 1-bit mechanism achieves expectedwelfare 0.625 compared 0.648 achieved asymmetric 1-bit mechanism2/3 achieved unrestricted communication. Similarly, revenue-maximizingsymmetric 1-bit mechanism achieves expected profit 0.385 compared 0.391-bit symmetric mechanisms 5/12 = 0.417 unrestricted communication (secondprice auction reserve price).following mechanism achieves optimal welfare among symmetric 1-bitmechanisms:010w.p. 12 wins, pays 0w.p. 12 B wins, pays 0wins pays 141B wins paysw.p.w.p.121214wins, pays 12B wins, pays 12Proving social efficiency mechanism done following idea: Firstnote symmetric, efficient mechanism clearly allocate item player264fiAuctions Severely Bounded Communicationbids 1 player bids 0, allocate equal probabilities 12bids equal. threshold strategies (x, y) expected welfare is:w(x,y) = x 12 x2 + 12 y2 + x (1 y) (1+y)+ (1 x) (1+x)+ (1 x) (1 y)2212(1+x)2a+12(1+y)2Maximum achieved (x, y) = ( 12 , 12 ).mechanism revenue-maximizing mechanism:010allocationwins, pays 131B wins pays 13w.p. 12 wins, pays 13w.p. 12 B wins, pays 13idea behind optimality mechanism 1-bit symmetricmechanisms: profit-maximizing symmetric mechanism player bids 0bids 1, latter wins pays x. players bid 1, pay x equalprobabilities. easy see ex-post IR assumption, x = x. expectedprofit thus: r(x) = x(1 x)x + (1 x)xx + (1 x)(1 x)( 21 x + 12 x). Maximum achieved(x [0, 1]) x = 13 .ReferencesAjtai, M., Megiddo, N., & Waarts, O. (2001). Improved algorithms analysis secretaryproblems generalizations. SIAM Journal Discrete Mathematics, 14 (1), 127.Athey, S. (2001). Single crossing properties existence pure strategy equilibriagames incomplete information. Econometrica, 69 (4), 86189.Bar-Yossef, Z., Hildrum, K., & Wu, F. (2002). Incentive-compatible online auctions digital goods. 13th Annual ACM-SIAM Symposium Discrete Algorithms (SODA),pp. 964970.Bergemann, D., & Pesendorfer, M. (2001). Information structures optimal auctions. Tech.rep. 2991, C.E.P.R. Discussion Papers.Blumrosen, L., & Feldman, M. (2006). Implementation bounded action space.Proceedings 7th ACM conference Electronic commerce, pp. 6271.Cramton, P., Shoham, Y., & Steinberg, R. (2006). Combinatorial Auctions. MIT Press.David, E., Rogers, A., Schiff, J., Kraus, S., & Jennings, N. (2005). Optimal designEnglish auctions discrete bid levels. Sixth ACM Conference ElectronicCommerce, pp. 98107.Feigenbaum, J., Papadimitriou, C. H., & Shenker, S. (2001). Sharing cost muliticasttransmissions. Journal Computer System Sciences., 63, 2141.Gilbert, J. P., & Mosteller, F. (1966). Recognizing maximum sequence. JournalAmerican Statistical Association, 61, 3573.Goldberg, A. V., Hartline, J. D., & Wright, A. (2001). Competitive auctions digitalgoods. Symposium Discrete Algorithms, pp. 735744.265fiBlumrosen, Nisan & SegalHarstad, R. M., & Rothkopf, M. H. (1994). role discrete bid levels oral auctions.European Journal Operations Research, 4, 572581.Kress, A., & Boutilier, C. (2004). study limited precision, incremental elicitationauctions. 3rd international joint conference autonomous agents multiagent systems.Kushilevitz, E., & Nisan, N. (1997). Communication Complexity. Cambridge UniversityPress.Lavi, R., & Nisan, N. (2004). Competitive analysis incentive compatible on-line auctions.Theoretical Computer Science., 310 (1), 159180.McAfee, P. (2002). Coarse matching. Econometrica, 70 (5), 20252034.Mookherjee, D., & Reichelstein, S. (1992). Dominant strategy implementation Bayesianincentive compatible allocation rules. Journal Economic Theory, 56 (2), 378399.Myerson, R. B. (1981). Optimal auction design. Mathematics Operations Research, 6 (1),5873.Nisan, N., & Segal, I. (2006). communication requirements efficient allocationssupporting prices. Journal Economic Theory, 129 (1), 192224.Parkes, D. C. (2005). Auction design costly preference elicitation. Annals Mathematics Artificial Intelligence, 44 (3), 269302.Parkes, D. C. (2006). Iterative combinatorial auctions. Cramton, P., Shoham, Y., &Steinberg, R. (Eds.), Combinatorial Auctions, chap. 2. MIT Press.Riley, J. G., & Samuelson, W. F. (1981). Optimal auctions. American Economic Review,71 (3), 381392.Roth, A. E., & Ockenfels, A. (2002). Late-minute bidding rules ending secondprice auctions: Evidence eBay Amazon Internet. American EconomicReview, 92 (4), 10931103.Rothkopf, M. H., Teisberg, T. J., & Kahn, E. P. (1990). Vickrey auctions rare?.Journal Political Economy, 98 (1), 94109.Sandholm, T., & Gilpin, A. (2006). Sequences take-it-or-leave-it offers: Near-optimalauctions without full valuation revelation. Fifth International Joint ConferenceAutonomous Agents Multiagent Systems, pp. 11271134.Segal, I. (2003). Optimal pricing mechanisms unknown demand. American EconomicReview, 93 (3), 509529.Vickrey, W. (1961). Counterspeculation, auctions competitive sealed tenders. JournalFinance, 16, 837.Wilson, R. (1989). Efficient competitive rationing. Econometrica, 57, 140.266fiJournal Artificial Intelligence Research 28 (2007) 453-515Submitted 08/06; published 4/07Abstract Reasoning Planning CoordinationBradley J. ClementBRAD . CLEMENT @ JPL . NASA . GOVJet Propulsion Laboratory, Mail Stop: 126-347,Pasadena, CA 91109 USAEdmund H. DurfeeDURFEE @ UMICH . EDUUniversity Michigan, EECS Department,Ann Arbor, MI 48109 USAAnthony C. BarrettTONY. BARRETT @ JPL . NASA . GOVJet Propulsion Laboratory, Mail Stop: 126-347,Pasadena, CA 91109 USAAbstractjudicious use abstraction help planning agents identify key interactionsactions, resolve them, without getting bogged details. However, ignoring wrongdetails lead agents building plans work, costly backtracking replanning overlooked interdependencies come light. claim associating systematicallygenerated summary information plans abstract operators ensure plan correctness, evenasynchronously-executed plans must coordinated across multiple agents, still achieving valuable efficiency gains. paper, formally characterize hierarchical plans whoseactions temporal extent, describe principled method deriving summarized statemetric resource information actions. provide sound complete algorithms, alongheuristics, exploit summary information hierarchical refinement planning plancoordination. analyses experiments show that, clearcut reasonable conditions,using summary information speed planning much doubly exponentially even plansinvolving interacting subproblems.1. IntroductionAbstraction powerful tool solving large-scale planning scheduling problems. abstracting away less critical details looking large problem, agent find overall solution problem easily. Then, skeleton overall solution place, agentwork additional details solution (Sacerdoti, 1974; Tsuneto, Hendler, & Nau, 1998).Further, interdependencies fully resolved abstract levels, one agentsflesh sub-pieces abstract solution full details independently (even parallel)divide-and-conquer approach (Korf, 1987; Lansky, 1990; Knoblock, 1991).Unfortunately, always obvious best abstract large, complex problems achieveefficiency improvements. agent solving complicated, many-step planning problem,example, might able identify details earlier parts critical laterones tried generate plans schedules seen interdependencies endarising. Even worse, multiple agents trying plan schedule activities sharedenvironment, unless lot prior knowledge other, extremelydifficult one agent anticipate aspects planned activities likely affect,affected by, agents.c2007AI Access Foundation. rights reserved.fiC LEMENT, URFEE , & BARRETTpaper, describe strategy balances benefits risks abstraction largescale single-agent multi-agent planning problems. approach avoids danger ignoringimportant details lead incorrect plans (whose execution fail due overlooked interdependencies) substantial backtracking abstract decisions cannot consistently refined.Meanwhile, approach still achieves many computational benefits abstraction longone number reasonable conditions (listed later) holds.key idea behind strategy annotate abstract operator plan hierarchysummary information potential needs effects potential refinements. might sound contrary purpose abstraction reducing numberdetails, fact show strikes good balance. Specifically, possiblyrelevant conditions effects modeled, agent agents reasoning abstractoperators absolutely sure important details cannot overlooked. However,summary information abstracts away details refinement choices conditionseffects manifested, information relative timing conditions needed effects achieved, still often results exponential reduction informationcompared flat representation.Based concept summary information, paper extends prior work summarizedSection 8 make following contributions:formal model hierarchical plans temporal extent, execution.many planning systems sophisticated temporal models (e.g., Laborie & Ghallab, 1995; Muscettola, 1994) additionally use hierarchical representations alternative courses action(Allen, Kautz, Pelavin, & Tenenberg, 1991; Currie & Tate, 1991; Chien, Knight, Stechert, Sherwood, & Rabideau, 2000a; Castillo, Fdez-Olivares, Garca-Perez, & Palao, 2006), knowwork extends hierarchical task network (HTN) formalization (Erol, Hendler, & Nau,1994a; Erol, Nau, & Hendler, 1994b) include temporal extent. need formalism orderclarify semantics summary information concurrently executing agents.Algorithms deriving summary information propositional metric resource conditions effects, using information determine potential definite interactions abstract tasks. prove summarization techniques guaranteedcorrectly capture conditions effects associated abstract operator appropriately, augmented modal information whether conditions must may hold whetherhold entire operation time. summary informationcaptures conditions effects, algorithms reason operators different levelsabstraction predict often resolve operator interactions without fully detailing task hierarchies,even operators executing asynchronously different agents.Sound complete algorithms hierarchical refinement planning centralized plan coordination actions temporal extent, supporting flexible plan execution systems.agent reduce backtracking planning selectively interleaving refinement planpredicting resolving potential interdependencies evolving plan plansasynchronously executed agents. research also found benefitguiding refinement conditions specified higher levels plan hierarchy guide refinement (Sacerdoti, 1974; Young, Pollack, & Moore, 1994; Tsuneto et al., 1998). showalgorithms improve capabilities exploiting hierarchical structure using summary454fiA BSTRACT R EASONING P LANNING C OORDINATIONinformation efficiently converge coordinated plans, refinedindividually parallel participating agents.ability coordinate abstract levels rather detailed plans allowsagents retain local flexibility refine operators best suits current expectedcircumstances without jeopardizing coordination triggering new rounds renegotiation.way, summary information supports robust execution systems PRS (Georgeff & Lansky,1986), UMPRS (Lee, Huber, Durfee, & Kenny, 1994), RAPS (Firby, 1989), JAM (Huber, 1999), etc.interleave refinement abstract plan operators execution.approach also extends plan coordination (plan merging) techniques (Georgeff, 1983; Lansky, 1990; Ephrati & Rosenschein, 1994) utilizing plan hierarchies expressive temporal model. Prior techniques assume actions atomic, meaning action either executesbefore, after, exactly time another. contrast, use interval point algebra (Vilain & Kautz, 1986) represent possibility several actions one agent executingexecution one action another agent. algorithms choose alternativerefinements HTN dynamically midst plan coordination, support interleaved localplanning, multiagent coordination, concurrent execution.Search techniques heuristics, including choose-fewest-threats-first (CFTF) expandmost-threats-first (EMTF), take advantage summary information prune searchspace. interdependencies run deeply agents plans, resolving abstract levels, possible all, lead unacceptable losses parallel activity. Fortunately, evenagents need delve details plans tease interdependencies, summary information still enable exponential speedups guiding decomposition pruning refinementchoices. search efficiency using summary information comes ignoring irrelevant information, distributed planning system also reduces communication overhead exponentially.Complexity analyses experiments showing potential doubly-exponential speedups refinement local search planning/scheduling using summary information. algorithmsdemonstrate exploiting summary information guide hierarchical planning schedulingachieve exponential speedups, resolving interdependencies abstract levels improveperformance plan coordination algorithms doubly exponentially. others shownabstraction exponentially reduce search space size (Korf, 1987; Knoblock, 1991) subproblem independence properties hold, show techniques lead exponential improvementsbroader conditions hold problem:solutions found abstract levels;amount summary information less higher levels lower levels;choices decompositions lead varying numbers plan threats.none conditions hold, show generating using summary informationprovides benefit increase computation communication overhead. Thus, care musttaken deciding use summary information, though proven extremely worthwhiletypes problem domains examined, example next describe.455fiC LEMENT, URFEE , & BARRETTM1M2Etransport1transport2BCtoolbin1bin2bin3bin4dockFigure 1: simple example manufacturing domainproduce Hproduce Gproduce H Gproduce GM2produce GM1move A&BM2move M2move GM2build Hmove Hbin1build Gmove B M2Figure 2: production managers hierarchical plan1.1 Manufacturing Examplerunning example motivate work, consider manufacturing plant productionmanager, facilities manager, inventory manager goals separatelyconstructed hierarchical plans achieve them. However, still need coordinate useequipment, availability parts used manufacturing parts, storage parts,use transports moving parts around. state factory shown Figure 1.domain, agents produce parts using machines M1 M2, service machines tool,move parts shipping dock storage bins shop floor using transports.Initially, machines M1 M2 free use, transports (transport1 transport2),tool, parts (A E) shown storage locations available.production manager responsible creating part H using machines M1 M2. Either M1 M2 consume parts B produce G, M2 produce H G.production managers hierarchical plan manufacturing H involves using transports moveneeded parts storage input trays machines, manufacturing G H, transporting H back storage. plan shown Figure 2. Arcs subplan branches meansubplans must executed. Branches without arcs denote alternative choices achievingparents goal. decomposition produce G M1 similar produce G M2.facilities manager services machine equipping tool calibrating it.machines unavailable production serviced. facilities managers hierarchical plan branches choices servicing machines different orders uses transports456fiA BSTRACT R EASONING P LANNING C OORDINATIONmaintenanceservice M1 M2service M1service M2service M2 M1move tooldockmove tool equip M1 tool calibrate M1M1Figure 3: facilities managers hierarchical planmove_partsmove C dockmove D&Emove bin3move E bin4Figure 4: inventory managers hierarchical plangetting tool storage machines (Figure 3). decomposition service M2M1similar service M1M2.parts must available space-limited shop floor order agent use them.Whenever agent moves uses part, becomes unavailable. inventory managers goalmove part C dock move E bins shop floor (shown Figure 4).accelerate coordination plans, factory manager analyze hierarchicalplan derive summary information abstract plan operator affect world.information includes summary pre-, post-, in-conditions intuitively correspondexternally required preconditions, externally effective postconditions, internally requiredconditions, respectively, plan based potential refinements. Summary conditions augment state conditions modal information whether conditions must may holdeffect. Examples given end Section 3.2.summary information computed, production inventory managers couldsend information top-level plan facilities manager. facilities manager couldreason top-level summary information plans determinefacilities manager serviced machines production manager started producingparts, production manager finished inventory manager began moving partsdock, plans executed (refined) way, CanAnyWay.facilities manager could instruct others add communication actions planssynchronize actions appropriately.top-level solution maximizes robustness choices production facilities managers plans preserved, solution inefficient concurrentactivityonly one manager executing plan time. production manager mightwant wait facilities manager finish maintenance could negotiate solutionconcurrency. case, facilities manager could determine could overlap457fiC LEMENT, URFEE , & BARRETTplans way without risking conflict (CanAnyWay). However, summary informationcould tell might way overlap plans (MightSomeWay), suggestingsearch solution concurrency (at cost perhaps committing specificrefinement choices) hope success. case, facilities manager could request production manager summary information produce Hs subplans, reasoninteractions lower level actions way, find way synchronize subplansfine-grained solution plans executed concurrently. give algorithmfinding solutions Section 5.1.2 Overviewfirst formally define model concurrent hierarchical plan, execution, interactions(Section 2). Next, describe summary information propositional states metric resources,mechanisms determining whether particular interactions must may hold based information, algorithms deriving information (Section 3). Built upon algorithms othersusing summary information determine whether set CHiPs must might execute successfully set ordering constraints (Section 4). turn used within soundcomplete multilevel planning/coordination algorithm employs search techniques heuristicsefficiently navigate prune search space refinement (Section 5). showplanning, scheduling, coordinating abstract levels exponentially improve performancesearch execution (Section 6). provide experimental results demonstrating searchtechniques also greatly reduce search optimal solutions (Section 7). Finally, Section 8differentiate approach related work mention elsewhere conclude.2. Model Hierarchical Plans Concurrent Executionrepresentation temporal extent HTN important modeling concurrentlyexecuting agents also performing abstract reasoning summary information. agentscheduling abstract actions sequentially order them, severely restrictedkinds solutions find. example, agent may prefer solutions shortermakespans, seek plans subthreads carried concurrently.section define concurrent hierarchical plans (CHiPs), state changes timebased executions, concepts success failure executions possible world,history. later define summary information abstract plan interactions termsdefinitions semantics given section, treatment fairly detailed (thougheven comprehensive treatment, see Clement, 2002). However, begin summarizingmain concepts notation introduced, give reader basic gist.2.1 OverviewCHiP (or plan p) mainly differentiated HTN including definition inconditions,in(p), (sometimes called conditions) affect (or assert condition on) statestart time p (ts (p)) must hold throughout duration p. Preconditions (pre(p)) musthold start, postconditions (post(p)) asserted finish time p (t f (p)). Metricresource (res) consumption (usage(p, res)) instantaneous start time and, resourcedefined non-consumable, instantaneously restored end. decompositions p (d(p))458fiA BSTRACT R EASONING P LANNING C OORDINATIONstyle and/or tree, either partial ordering (order(p)) choice child tasksconditions.execution e p instantiation start time, end time, decomposition. is,execution nails exactly done when. order reason plan interactions,quantify possible histories, history corresponds combination possibleexecutions concurrently-executing CHiPs partial ordering activitiescontext initial state. run (r(h,t)) specifies state time history h.Achieve, clobber, undo interactions defined terms executionsplans assert positive literal ` negative literal ` relative ` required another plansexecution history. looking literals achieved, clobbered, undone setexecutions history, identify conditions must hold prior executionshistory external preconditions must hold executions historyexternal postconditions.value metric resource time (r(res, h,t)) calculated subtracting priorstate value usage plans start executing (if non-consumable) adding back usagesend t. execution e p fails condition required asserted timestate r(h,t) t, value resource (r(res, h,t)) used planlimits execution.remainder section, give careful, detailed descriptions conceptsabove, ground definitions firm semantics; casual reader skimdetails desired. also important note that, rather starting scratch, formalizationweaves together, necessary augments, appropriate aspects theories, includingAllens temporal plans (1983), Georgeffs theory multiagent plans (1984), Fagin et al.stheory multiagent reasoning knowledge (1995).2.2CH Pconcurrent hierarchical plan p tuple hpre, in, post, usage, type, subplans, orderi. pre(p),in(p), post(p) sets literals (v v propositional variable v) representingpreconditions, inconditions, postconditions defined plan p.1borrow existing model metric resources (Chien, Rabideu, Knight, Sherwood, Engelhardt, Mutz, Estlin, Smith, Fisher, Barrett, Stebbins, & Tran, 2000b; Laborie & Ghallab, 1995).plans usage function mapping resource variables amount used. writeusage(p, res) indicate amount p uses resource res sometimes treat usage(p) setpairs (res, amount). metric resource res tuple hmin value, max value, typei. minmax values integer real values representing bounds capacity amount available. type resource either consumable non-consumable. example, fuelbattery energy consumable resources because, use, depleted amount.non-consumable resource available use (e.g. vehicles, computers, power).Domain modelers typically specify state conditions resource usage primitive actions hierarchy. Thus, conditions usage CHiP used derive summary conditions,describe Section 3.4, algorithms reason action hierarchy.order reason plan hierarchies and/or trees actions, type plan p, type(p),1. Functions pre(p) used referential convenience throughout paper. Here, pre pre(p)same, pre(p) read preconditions p.459fiC LEMENT, URFEE , & BARRETTgiven value either primitive, and, or. plan non-primitive plan accomplished carrying subplans. plan non-primitive plan accomplishedcarrying exactly one subplans. So, subplans set plans, primitive planssubplans empty set. order(p) defined plan p consistent settemporal relations (Allen, 1983) pairs subplans. Plans left unordered respectinterpreted potentially execute concurrently.decomposition CHiP style HTN described Erol et al.(1994a). plan task network, plan extra construct representing setmethods accomplish goal compound task. network tasks correspondssubplans plan.example Figure 2, production managers highest level plan produce H (Figure 2)tupleh{}, {}, {}, {}, and, {produce G, produce H f rom G}, {be f ore(0, 1)}i.f ore(0,1), 0 1 indices subplans decomposition referring produce Gproduce H f rom G respectively. conditions defined produce H relyconditions defined primitive plans refinement. plan moving partbin1 first input tray M1 using transport1 tupleh{}, {}, {}, {}, and, {start move, f inish move}, {meets(0, 1)}i.plan decomposes two half moves help capture important intermediate effects.parent orders children meets relation bind together single move.start move planh{at(A, bin1), available(A), f ree(transport1), f ull(M1 tray1)},{at(A, bin1), available(A), f ull(bin1), f ull(M1 tray1), f ree(transport1)},{at(A, bin1), available(A), f ree(transport1), f ull(bin1), f ull(M1 tray1)},{}, primitive, {}, {}i.f inish move planh{at(A, bin1), available(A), f ree(transport1), f ull(bin1), f ull(M1 tray1)},{at(A, bin1), available(A), f ree(transport1), f ull(bin1), f ull(M1 tray1)},{at(A, bin1), at(A, M1 tray1), available(A), f ree(transport1), f ull(bin1), f ull(M1 tray1)},{}, primitive, {}, {}i.split move plan two parts order ensure action executesconcurrently one use transport1, part A, input tray M1. would incorrectinstead specify f ree(transport1) incondition single plan another agent could,instance, use transport1 time f ree(transport1) incondition would agreef ree(transport1) incondition move action. However, specification stillinsufficient since two pairs (start move, f inish move) actions could start endtime without conflict. get around allowing planner reasonmove plan parent plans, effect, hiding transition start finish actions.So, representing transition f ree f ree without knowing transition460fiA BSTRACT R EASONING P LANNING C OORDINATIONtake place modeler ensures another move plan tries use transport1 concurrentlyone cause conflict.2postcondition required incondition specify whether incondition changes.clarifies semantics inconditions conditions hold plan executionwhether caused action necessary conditions successful execution.2.3 ExecutionsInformally, execution CHiP recursively defined instance decompositionordering subplans executions. Intuitively, executing plan, agent chooses plansstart time refined, determining points time conditions must hold,witnesses finish time. formalism helps us reason outcomes different waysexecute group plans, describe state transitions, define summary information.execution e CHiP p tuple hd,ts ,t f i. ts (e) f (e) positive, non-zero real numbersrepresenting start finish times execution e, ts < f . Thus, instantaneous actionsexplicitly represented. d(e) set subplan executions representing decomposition plan pexecution e. Specifically, p plan, contains exactly one executionsubplans; plan, contains one execution one subplans;empty primitive. addition, subplan executions, e0 d, ts (e0 ) f (e0 ) mustconsistent relations specified order(p). Also, first subplan(s) start must starttime p, ts (e0 ) = ts (e), last subplan(s) finish must finish timep, f (e0 ) = f (e). possible executions plan p set E (p) includes possibleinstantiations execution p, meaning possible values tuple hd,ts ,t f i, obeyingrules stated.example Section 1.1, execution production managers top-level planproduce H would e E (produce H). e might h{e1 , e2 }, 2.0, 9.0 e1E (produce G), e2 E (produce H f rom G). means execution produce Hbegins time 2.0 ends time 9.0.convenience, subexecutions execution e, subex(e), defined recursivelyset subplan executions es decomposition unioned subexecutions.2.4 Histories Runsagent reasoning summary information make planning decisions abstract levels needsfirst able reason CHiPs. section complete semantics CHiPsdescribing affect state time. agent execute plan many differentways different contexts, need able quantify possible worlds (or histories)agents fulfill plans different ways. defining history, define runtransformation state time result history executions. formalizationhistories runs follows closely Fagin et al. (1995) describing multiagent execution.state world, s, truth assignment set propositions, representing aspectenvironment. refer state set true propositional variables. history,2. Using universal quantification (Weld, 1994) single plan could agent, agent 6= productionManagerusing(transport1, agent) condition would exclude concurrent access transport. could alsosimply specified transport1 non-consumable resource maximum capacity one.461fiC LEMENT, URFEE , & BARRETTh, tuple hE, sI i. E set plan executions agents occurring h, sIinitial state h plan begins executing. So, history h hypothetical world beginssI initial state executions E(h) occur. particular, historymanufacturing domain might initial state shown Figure 1 parts machinesavailable, transports free. set executions E would contain executionproduce H, maintenance, move parts, subexecutions.run, r, function mapping history time point states. gives complete descriptionstate world evolves time, time ranges positive real numbers.Axiom 1r(h, 0) = sIAxiom 2v r(h,t > 0) (v r(h,t )p, e p E(h), (v in(p) ts (e p ) = ) (v post(p) f (e p ) = t))(6 p0 , e p0 E(h), (v in(p0 ) ts (e p0 ) = ) (v post(p0 ) f (e p0 ) = t))Axiom 1 states world initial state time zero. Axiom 2 states predicatev true time already true beforehand, plan asserts v inconditionpostcondition t, (in either case) plan asserts v t. plan starts t, inconditionsasserted right start, +, small positive real number. Axiom 2 also indicatesinconditions postconditions effects.state resource level value (integer real). consumable resource usage, taskdepletes resource modeled instantaneously deplete resource (subtract usagecurrent state) start task full amount. non-consumable resource usage, taskalso depletes usage amount start task, usage restored (added backresource state) end execution. task replenish resource negative usage.refer level resource res time history h r(res, h,t). Axioms 3 4describe calculations consumable non-consumable resources, respectively.Axiom 3r(consumable res, h,t) = r(consumable res, h,t ) e p E(h),ts (e p )=t usage(p, consumable res)Axiom 4r(nonconsumable res, h,t) =r(nonconsumable res, h,t )e p E(h),ts (e p )=t usage(p, nonconsumable res)+e p E(h),t f (e p )=t usage(p, nonconsumable res)described CHiPs change state, specify conditionsexecution succeeds fails. stated formally Definition 1, execution succeeds if:plans preconditions met start; postconditions met end; inconditionsmet throughout duration (not including start end); used resources stay withinvalue limits throughout duration; executions decomposition succeed. Otherwise,execution fails.462fiA BSTRACT R EASONING P LANNING C OORDINATIONDefinition 1succeeds(e p , h) pre(p) r(h,ts (e p ))post(p) r(h,t f (e p ))t, res,ts (e p ) < < f (e p ) usage(p, res) 6= 0in(p) r(h,t)min value(res) <= r(res, h,t) <= max value(res)e d(e p ), succeeds(e, h)2.5 Asserting, Clobbering, Achieving, UndoingConventional planning literature often speaks clobbering achieving preconditions plans(Weld, 1994). CHiPs, notions slightly different since inconditions clobberclobbered, seen previous section. Formalizing concepts another, undoingpostconditions, helps us define summary conditions (in Section 3.2). However, convenientdefine first means assert condition. Figure 5 gives examples executions involvedinteractions, define terms follows:Definition 2asserts(e p , `,t, h) (e p E(h))(` in(p) = ts (e p ) +` post(p) = f (e p ))(r(t, h) ` `)Definition 2 states execution e p history h asserts literal time literaleffect p holds state t. Note point on, beginning Definition 3,use brackets [ ] shorthand defining similar terms procedures. example, saying [a,b] implies [c, d] means implies c, b implies d. shorthand help us avoid repetition,cost slightly difficult parsing.Definition 3[achieves, clobbers] precondition(e p , `, e p0 ,t, h)e p , e p0 E(h)asserts(e p , [`, `],t, h) ` pre(p0 ) < ts (e p0 )6 e p00 ,t 00 , (asserts(e p00 , `,t 00 , h) asserts(e p00 , `,t 00 , h)) < 00 ts (e p0 )Definition 4clobbers [in, post]condition(e p , `, e p0 ,t, h)e p , e p0 E(h)asserts(e p , `,t, h) ` [in(p0 ), post(p0 )] [ts (e p0 ) < < ts (e p0 ),t = f (e p0 )]Definition 5undoes(e p , `, e p0 ,t, h)e p , e p0 E(h)asserts(e p , `,t, h) ` post(p0 ) f (e p0 ) >6 e p00 ,t 00 , (asserts(e p00 , `,t 00 , h) asserts(e p00 , `,t 00 , h)) f (e p0 ) 00 <463fiC LEMENT, URFEE , & BARRETTFigure 5: Interval interactions plan stepsSo, execution achieves clobbers precondition last (or one last) assertcondition negation (respectively) required. Likewise, execution undoespostcondition first (or one first) assert negation conditioncondition asserted. execution e clobbers incondition postcondition e0 e assertsnegation condition end (respectively) e0 . Achieving effects (inconditionspostconditions) make sense formalism, defined. Figure 5 showsdifferent ways execution e achieves, clobbers, undoes execution e0 . ` ` pointasserted required met.2.6 External Conditionsrecognized Tsuneto et al. (1998), external conditions important reasoning potential refinements abstract plans. Although basic idea same, define littledifferently call external preconditions differentiate conditionscall external postconditions. Intuitively, external precondition group partially orderedplans precondition one plans achieved another group mustmet external group. External postconditions, similarly, undoneplans group net effects group. Definition 6 states ` external [pre,post]condition execution e p ` [pre, post]condition subplan[achieved, undone] subplan.Definition 6external [pre, post]condition(`, e p )h, E(h) = {e p } subex(e p )(e p0 E(h), ` [pre(p0 ), post(p0 )]6 e p00 E(h),t,[achieves pre, undoes post]condition(e p00 , `, e p0 ,t, h))464fiA BSTRACT R EASONING P LANNING C OORDINATIONexample Figure 2, available(G) external precondition because, although Gmust exist produce H, G supplied execution produce G plan. Thus, available(G)met internally, making available(G) internal condition. available(M1) external precondition, internal condition, external postcondition needed externallyinternally; effect produce G M1 releases M1 finished;plan decomposition undoes effect.3. Plan Summary InformationSummary information used find abstract solutions guaranteed succeed matterrefined information describes potential conditions underlyingdecomposition. Thus, commitments particular plan choices, whether single agentagents, made based summary information without worrying deeper detailslurk beneath doom commitments. HTN planners used abstract conditionsguide search (e.g., Sacerdoti, 1974; Tsuneto et al., 1998), rely user-defined subsetconstraints help detect potential conflicts. contrast, summary informationused identify potential conflicts.formalisms previous section, define summary informationdescribe method computing non-primitive plans (in Section 3.4).many detailed definitions algorithms section, follow structureprevious section, first give informal overview key concepts notation,subsequently delve systematically.3.1 Overviewsummary information plan p consists summary pre-, in-, postconditions (presum (p),insum (p), postsum (p)), summary resource usage (usagesum (p, res)) resource res, whetherplan executed way successfully (consistent).summary condition (whether pre, post, in) specifies positive negated literal,additional modal information. summary condition associated existence, whosevalue either must may depending whether must hold possible decompositionsabstract operator may hold depending decomposition chosen. timingsummary condition either f irst, last, always, sometimes, specifying condition musthold plans interval execution. plan p1 must [achieve, clobber] summary preconditionc2 p2 execution p1 (or plan summary information) would[achieve, clobber] condition summarized c2 (or plan summary informationp2 ).algorithm deriving summary conditions plan p takes input summary conditions immediate subplans p conditions defined CHiP p. pre-, in-,postconditions p become must first, must always, must last summary conditions, respectively. algorithm retains existence timing subplan summary conditions parentdepending whether conditions achieved, clobbered, undone siblings, whetherdecomposition or, whether subplan ordered first last, whether subplansshare condition. Subplan first, always, last conditions become sometimes conditions parent. parent computed consistent long subplans consistent,465fiC LEMENT, URFEE , & BARRETTsubplan may clobber summary condition another, summarized resources violatelimits.represent summary resource usage three value ranges, hlocal min, local max, persisti,resources local usage occurs within tasks execution, persistent usage represents usage lasts task terminates depletable resources. summarizationalgorithm abstract task takes summary resource usages subtasks, considers legal orderings subtasks, possible usages subintervals within intervalabstract task, build multiple usage profiles. profiles combined algorithmscomputing parallel, sequential, disjunctive usages give summary usage parent task.3.2 Summary Conditionssummary information plan p, psum , tuple hpresum , insum , postsum , usagesum , consistenti,whose members sets summary conditions, summarized resource usage, consistent flagindicating whether plan execute consistently internally. presum (p) postsum (p) summary pre- postconditions, external pre- postconditions p, respectively.summary inconditions p, insum (p), contain conditions must hold within executionp successful. condition c one sets tuple h`, existence,timingi. `(c)literal c. existence c must may. existence(c) = must, c calledmust condition ` must hold every successful plan execution. convenience usuallywrite must(c). c may condition (may(c) true) `(c) must hold successful execution.timing summary condition c either always, sometimes, f irst, last. timing(c)always c insum `(c) incondition must hold throughout potential executions p(` holds always); otherwise, timing(c) = sometimes meaning `(c) holds one point, least, withinexecution p. So, always condition must, define may always inconditionswhether may existence timing, significantly different maysometimes planner reasons it. Whether condition may always (however defined)may sometimes, another plan may clobber relationship condition (asdefined Section 3.3). Note also incondition CHiP restricted meaningmust always summary incondition. timing f irst c presum `(c) holds beginningexecution p; otherwise, timing = sometimes. Similarly, timing last c postsum `(c)asserted end successful execution p; otherwise, sometimes. Although existencetiming syntactically take one value, semantically must(c) may(c), always(c)sometimes(c).considered using modal logic operators describe concepts. mix existingtemporal logic dynamic logic (Pratt, 1976) notation could forced work, foundusing terminology made definitions much simpler. discuss endSection 8.Definitions 7, 8, 9 give formal semantics existence timing representativecondition types. Summary conditions plan defined recursively dependsummary conditions plans immediate subplans instead complete decomposition. single description summary information could represent many different plan hierarchies,quantify plans p0 , whose subplans summary informationplan p summarized. could defined existence timing properties conditionsbased entire hierarchy, so, deriving summary conditions would expensive466fiA BSTRACT R EASONING P LANNING C OORDINATIONsolving planning problem, one main purposes summary information reducecomputation planning problem. reason would expensiveworst case legal orderings plan steps must explored determine whether conditionmust may. discuss example end subsection.Definition 7[must, may] f irst precondition(`, p)p0 = hpre(p), in(p), post(p), {},type(p), subplans(p0 ), order(p)isummary f ormation f subplans(p0 ) = summary f ormation f subplans(p)h,e p0 , E(h) = {e p0 } subex(e p0 ) [true, external precondition(`, e p0 )]e p00 E(h),ts (e p00 ) = ts (e p0 ) ` pre(p00 )Definition 8must always incondition(`, p)p0 = hpre(p), in(p), post(p), {},type(p), subplans(p0 ), order(p)isummary f ormation f subplans(p0 ) = summary f ormation f subplans(p)h, e p0 ,E(h) = {e p0 } subex(e p0 ),t,ts (e p0 ) < < f (e p0 )e p00 E(h),ts (e p00 ) < < f (e p00 ) ` in(p00 )Definition 9[must, may] sometimes incondition(`, p)[, ]p0 = hpre(p), in(p), post(p), {},type(p), subplans(p0 ), order(p)isummary f ormation f subplans(p0 ) = summary f ormation f subplans(p) [, ][, ]h, e p0 ,E(h) = {e p0 } subex(e p0 ), t,ts (e p0 ) < < f (e p0 )[, ]e p00 E(h), = ts (e p00 ) ` pre(p00 )ts (e p00 ) < < f (e p00 ) ` in(p00 )= f (e p00 ) ` post(p00 )Definition 7 states f irst precondition p external precondition always required beginning execution p0 conditions psummary information ordering subplans p. last postcondition always assertedend execution (substitute pre post ts f last two lines Definition 7). [must,may] sometimes precondition [must,may] external preconditionf irst precondition. sometimes postcondition defined similarly. Definition 8 states literal` must, always incondition plan p time isolated execution p0summary information p, executing plan p00 incondition `. Definition 9states [must, may] sometimes incondition plan p condition required [any,some] execution [any, some] plan p0 summary information orderingsubplans p.consistent flag boolean indicating whether plan (or plan summary information ordering subplans) would execute successfully matter decomposed matter subplans executed. Definition 10 says possible467fiC LEMENT, URFEE , & BARRETTexecutions succeed consistent plan. similar CanAnyWay relationdefined Section 4. include whether plan definitely succeedsummary information requires exponential computation see whether conflictssubplans resolved. computation wait done planning summaryinformation fully derived.Definition 10consistent(p)p0 = hpre(p), in(p), post(p), usage(p),type(p), subplans(p0 ), order(p)isummary f ormation f subplans(p0 ) = summary f ormation f subplans(p)h, e p0 E (p0 ), e p0 succeedsshow subset summary conditions production managers top-level plan (ofFigure 2) below. Following literal modal tags existence timing information. Mumust; may; F f irst; L last; sometimes; always.Production managers produce H plan:Summary preconditions:available(A)MuF, available(M1)MaS, available(M2)MaSSummary inconditions:available(A)MuS, available(M1)MaS, available(M2)MuS, available(G)MuS,available(A)MuS, available(M1)MaS, available(M2)MuS, available(G)MuS,available(H)MuS, available(H)MuSSummary postconditions:available(A)MuS, available(M1)MaS, available(M2)MuS, available(G)MuS,available(H)MuLavailable(M1) summary precondition may condition production managermay end using M1 chooses use M2 instead produce G. available(A) f irst summary precondition part must used beginning execution transportedone machines. machines needed sometime parts transported,sometimes (and first) conditions: needed point time beginning execution.production manager may use M1 produce G, available(M1) summaryincondition produce H. available(M1) available(M1) inconditionsconsistent sometimes conditions, implying hold different timesplans execution. contrast, conditions would conflict must always(meaning must always hold throughout every possible execution plan).summary condition available(A) must postcondition top-level plandefinitely consumed make G produced plan decompositionproduce H f rom G. Even though available(G) effect produce G, externalpostcondition produce H undone produce H f rom G, consumes Gmake H. available(H) last summary postcondition production manager releasesH end execution. available(M2) last manager finishes using M2moving H storage.Notice available(M2) may summary precondition. However, matter hierarchy decomposed, M2 must used produce H, available(M2) must established468fiA BSTRACT R EASONING P LANNING C OORDINATIONexternally production managers plan. summary information defined termssummary information immediate subplans, subplans produce H, seeproduce G available(M2)MaS precondition available(M2)MaS postconditionwould achieve available(M2)MuF precondition produce H f rom G. summaryinformation tell us precondition produce G exists postconditionexists, necessary condition determine derived precondition produce H mustcondition. Thus, may. augmented summary information subsets conditionsexisted together, hunting combinations temporal orderings condition subsets amongsubplans derive summary conditions would basically adaptation HTN planning algorithm, summary information intended improve. Instead, derive summary informationpolynomial time use improve HTN planning exponentially explain Section 6. tradeoff made beginning section defining summary conditionsterms immediate subplans instead entire hierarchy. Abstraction involves lossinformation, loss enables computational gains.3.3 Summary condition relationships algorithmsorder derive summary conditions according definitions, need able recognizeachieve, clobber, undo relationships based summary conditions basic CHiPconditions. give definitions algorithms these, build constructs algorithmsreasoning temporal relationships, described Appendix A.Achieving clobbering similar, define together. Definition 11 statesplan p1 must [achieve, clobber] summary precondition c2 p2 executionstwo plans, p01 p02 , summary information ordering constraints p1p2 , execution p01 one subexecutions would [achieve, clobber] external precondition`(c2 ) p02 .Definition 11must [achieve, clobber] precondition(p1 , c2 , p2 , Psum , order)h H(Psum , order), p01 , p02 , e p01 , e p02 ,(p01 p02 summary ordering f ormation p1 p2 )t,e p001 subex(e p01 ), e p002 subex(e p02 ),[achieve, clobber] precondition(e p001 , `(c2 ), e p002 ,t, h)external precondition(`(c2 ), e p02 )Achieving clobbering in- postconditions defined Definition 11 substituting post pre removing last line inconditions. Additionally substituting gives definitions may achieve clobber. Furthermore, definitionsmust/may-undo obtained substituting post pre undo achieve Definition 11. Note that, mentioned Section 2.5, achieving inconditions postconditionsmake sense formalism.Algorithms interactions given Figure 6 Figure 7. algorithms buildothers (detailed Appendix B) use interval point algebra determine whether plan mustmay assert summary condition before, at, time another plan requires summarycondition hold. Similar Definition 3 must-achieve CHiP conditions, Figure 6 says p0469fiC LEMENT, URFEE , & BARRETTAlgorithm: Must-[achieve, clobber]Input: plan p0 , summary condition c plan p, Psum , orderOutput: true f alse, whether p0 must-[achieve, clobber] cbegin functionc0 in(p0 ) post(p0 )`(c0 ) [`(c), `(c)] must(c0 )c insum (p) p0 must-assert c0 c return [unde f ined, true]c postsum (p) p0 must-assert c0 c return [unde f ined, true]c presum (p) p0 must-assert c0 cset assertion inbetween = f alsec00 in(p00 ) post(p00 ), p00 Psum assertion inbetween = f alse(p0 may-assert c0 c00p00 may-assert c00 c`(c00 ) [`(c), `(c)])(p0 must-assert c0 c00p00 must-assert c00 c`(c00 ) [`(c), `(c)] must(c00 ))set assertion inbetween = trueassertion inbetween return truereturn f alseend functionFigure 6: Algorithm whether plan must achieve clobber summary conditionachieves summary condition c must asserts condition must hold,plans may assert condition negative between. algorithm may-achieve(in Figure 7) mainly differs p0 may assert condition beforehand, planmust assert between. undo algorithms achieve swapping cc0 must/may-assert lines.complexity determining must/may-clobber inconditions postconditions simplyO(c) check c conditions p0 . conditions hashed, algorithm constant time.rest algorithm cases, complexity walking summary conditionschecking p00 c00 O(nc) maximum c summary conditions n plansrepresented Psum . worst case, summary conditions summarize propositionalvariable, O(nc) conditions must visited.Lets look examples relationships. Figure 8a, p0 = equip M2 tool mayclobber c = available(M2)MaS summary preconditions p = produce Ghistory equip M2 tool ends produce G starts, calibrate M2 startsproduce G starts. Figure 8b, p0 = build H must-achieve c = available(H)MuF summary preconditions p = move H. Here, c0 available(H)MuL summary postconditionsbuild H. histories, build H attempts assert c0 move H requires cmet, plan execution attempts assert condition availabilityH. equip M2 tool may-clobber c = available(M2)MuF summary preconditionsbuild H even though equip M2 tool asserts c0 = available(M2)MuL c requiredmet. calibrate M2 must assert available(M2)MuA timeequip M2 tool asserts c0 c required. Thus, calibrate M2 must-undo equip M2 tool470fiA BSTRACT R EASONING P LANNING C OORDINATIONAlgorithm: May-[achieve, clobber]Input: plan p0 , summary condition c plan pOutput: true f alse, whether p0 may-[achieve, clobber] cbegin functionc0 in(p0 ) post(p0 )`(c0 ) [`(c), `(c)]c insum (p) p0 may-assert c0 c return [unde f ined, true]c postsum (p) p0 may-assert c0 c return [unde f ined, true]c presum (p) p0 may-assert c0 cset assertion inbetween = f alsec00 in(p00 ) post(p00 ), p00 Psum assertion inbetween = f alsep0 must-assert c0 c00p00 must-assert c00 c`(c00 ) `(c) `(c) must(c00 ))set assertion inbetween = trueassertion inbetween return truereturn f alseend functionFigure 7: Algorithm whether plan may achieve clobber summary conditiona)produce Hproduce Gproduce H Gmove Gbuild Hmove Hservice M2moveequip M2toolcalibrate M2toolb)produce Hproduce H Gproduce Gmove G=movetoolbuild Hmove Hservice M2equip M2calibrate M2toolFigure 8: production facilities managers plans partially expanded. a) managers plansunordered respect other. b) equip M2 tool must clobber available(M2)MaLproduce G, calibrate M2 must clobber available(M2)MuF build H.summary postcondition. calibrate M2 cannot assert postcondition available(M2)MuLbuild H requires available(M2)MuF, calibrate M2 must-clobber summary precondition.471fiC LEMENT, URFEE , & BARRETT3.4 Deriving Summary Conditionsalgorithms determine interactions abstract plans based summaryconditions, create algorithm derives summary conditions according definitions Section 3.2. Figure 9 shows pseudocode algorithm. method derivingsummary conditions plan p recursive. First, summary information derived pssubplans. conditions added based ps conditions. rest algorithmderives summary conditions ps subplans. Whether p consistent dependsconsistency subplans whether summary conditions resource usagesconflict. braces { } used slightly different semantics usedbrackets. expression {x,y} interpreted simply (x y, respectively).Definitions algorithms temporal relationships always- f irst coversAppendix A. algorithm adds copies condition set, one condition existliteral, conditions information may overwritten literal. cases,must overwrites may; f irst, last, always overwrite sometimes; but, vice-versa. Further,uses recursion, procedure assumed work plans whose expansion finite.3.5 Summary Resource Usagesection, define representation capturing ranges usage local task interval depleted usage lasting end interval. Based introducesummarization algorithm captures ranges uncertainty represented decomposition choices plans partial temporal orderings plan subtasks. representationallows coordinator planner reason potential conflicts set tasks.discuss reasoning later Section 4.2. Although referred resources, variables coulddurations additive costs rewards.3.5.1 R EPRESENTATIONstart new example simplicity motivates choice representation. Considertask coordinating collection rovers explore environment around landerMars. exploration takes form visiting different locations making observations.traversal locations follows established paths minimize effort risk. paths combine form network like one mapped Figure 10, vertices denote distinguishedlocations, edges denote allowed paths. Thinner edges harder traverse, labeled pointsassociated observation goals. paths hard ground, others loosesand traversal harder since rover slip.Figure 11 gives example abstract task. Imagine rover wants make earlymorning trip point point B example map. trip sun slowly riseshorizon giving rover ability progressively use soak rays tasks providesolar power (a non-consumable resource3 ) motors wheels. addition collecting photons,morning traverse moves rover, resultant go tasks require path dependent amountspower. rover traveling point point B take number paths, shortestthree involve following one, two, three steps.3. important confuse power battery energy. power source (e.g. battery, solar panels) makes fixedamount power Watts available point time. batterys energy (in Watt-hours) reduced integraltotal use power time.472fiA BSTRACT R EASONING P LANNING C OORDINATIONAlgorithm: Derive summary informationInput: plan pOutput: psumbegin functionderive summary informationp0 d(p)Vset consistent(p) = p0 d(p) consistent(p0 )` pre(p) add h`, must, f irsti presum (p)` in(p) add h`, must, alwaysi insum (p)` post(p) add h`, must, lasti postsum (p)summary condition c0 p0 d(p)set c = c0c0 {presum (p0 ),postsum (p0 )}c0 must-{achieved,undone} must-clobbered within d(p),type(p) = (p0 always { f irst,last}temporally ordered subplan according order(p)sometimes- { f irst,last} subplan p0{ f irst, last} `(c0 ) condition {presum (p0 ),postsum (p0 )}),set timing(c) = sometimesc0 may-{achieved,undone} may-clobbered P d(p)p00 P must `(c0 ) condition {presum (p00 ),postsum (p00 )},set existence(c) = maycopy c {presum (p),postsum (p)}c0 insum (p0 ) p0 not-always { f irst,last} according order(p),must(c0 ) c0 always-not- { f irst,last} according order(p),set existence(c) = mustset P = 0/set allAlways = truep00 d(p), c00 insum (p00 )`(c00 ) `(c)always(c00 ) add p00 Pelse set allAlways = f alseelse allAlways = f alsealways(c) ((type(p) = P covers p according order(p))(type(p) = allAlways)),set timing(c) = alwaysadd c insum (p)c0 may-clobbered, set consistent = f alseusagesum (p) = SummarizeResourceUsage(p) (in Section 3.5.2)consistent(usagesum (p)) = f alse, set consistent(p) = f alseend functionFigure 9: Algorithm deriving summary informationsummarized resource usage consists ranges potential resource usage amountsperforming abstract task, represent summary information plan presource res using structureusagesum (p, res) = hlocal min(p, res), local max(p, res), persist(p, res)i,473fiC LEMENT, URFEE , & BARRETTBCFEFigure 10: Example map established paths points rover domainmorning activitiesmove(A,B)soak rays soak rays soak raysuse -4w use -5w use -6w20 min20 min20 mingo(A,1)use 3w10 mintake low pathgo(1,2)use 3w10 minhigh pathmiddle pathgo(A,B)go(2,B) use 4w go(A,3) go(3,B)use 6w 50 min use 4w use 6w20 min15 min 25 minFigure 11: and/or tree defining rovers tasks resource usagesresources local usage occurs within ps execution, persistent usage representsusage lasts execution terminates consumable resources.Definition 12usagesum (p, res)h[minhH,e p E(h) (mints (e p )<t<t f (e p ) (r(res, h,t))), maxhH,e p E(h) (mints (e p )<t<t f (e p ) (r(res, h,t)))][minhH,e p E(h) (maxts (e p )<t<t f (e p ) (r(res, h,t))), maxhH,e p E(h) (maxts (e p )<t<t f (e p ) (r(res, h,t)))][minhH,e p E(h) (r(res, h,t f (e p ))),maxhH,e p E(h) (r(res, h,t f (e p )))]context Definition 12 set histories H value res 0 initialstate, E(h) contains execution p subexecutions. Thus, r(res, h,t) termcombined usage res time executions hierarchy defined Section 2.4. So,maximum local min highest among histories lowest point usageps execution. usage ranges capture multiple possible usage profiles task multipledecomposition choices timing choices among loosely constrained subtasks. example,high path task h[4,4],[6,6],[0,0]i summary power use 40 minute interval. caseranges single points due uncertainty task simply uses 4 watts 15 minutesfollowed 6 watts 25 minutes. move(A,B) task provides slightly complex exampledue decompositional uncertainty. task h[0,4],[4,6],[0,0]i summary power use50 minute interval. cases persist [0,0] solar power non-consumableresource.example reasoning resource usage summaries, suppose 3 watts poweravailable move(A,B) task. Given [4,6] local max, knowenough power matter task decomposed. Raising available power 4 watts makestask executable depending gets decomposed scheduled, raising 6watts makes task executable possible decompositions.474fiA BSTRACT R EASONING P LANNING C OORDINATIONrepresentation abstract (or uncertain) metric resource usage seen extensiontracking optimistic pessimistic resource levels (Drabble & Tate, 1994). Computingupper lower bounds resource usage abstract plan gives informationwhether lower upper bound constraints resource may, must, must violated,complete. representing upper lower bounds ranges boundspotential histories, certainly know whether bounds may, must, must violatedhistories. example above, tracked one range local usage, [0,6],would know definitely conflict 3 watts available. Knowingextra information avoid exploration infeasible search space.3.5.2 R ESOURCE UMMARIZATION LGORITHMstate summarization algorithm Section 3.4 recursively propagates summary conditions upwards and/or hierarchys leaves, algorithm resource summarization takesapproach. Starting leaves, algorithm finds primitive tasks use constant amountsresource. resource summary task using x units resource h[x,x],[x,x],[0,0]ih[x,x],[x,x],[x,x]i tasks duration non-consumable consumable resources respectively.Moving and/or tree, summarization algorithm either comes branch.branch combined summary usage comes computationh [mincchildren (lb(local min(c))), maxcchildren (ub(local min(c)))],[mincchildren (lb(local max(c))), maxcchildren (ub(local max(c)))],[mincchildren (lb(persist(c))),maxcchildren (ub(persist(c)))]i,lb() ub() extract lower bound upper bound range respectively. childrendenote branchs children durations extended length longest child.duration extension alters childs resource summary information childs usage profilezero resource usage extension. instance, determining resource usagemove(A,B), algorithm combines two 40 minute tasks 50 minute task. resultingsummary information describes 50 minute abstract task whose profile might zero wattpower usage 10 minutes. extension move(A,B) [0,4] local min instead[3,4]. Planners reason variable durations could use [3,4] duration ranging40 50.Computing branchs summary information bit complicated due timingchoices among loosely constrained subtasks. take x path examples illustrate simplest subcase, subtasks tightly constrained execute serially. profiles appended together,resulting summary usage information comes SERIAL-AND computationh [mincchildren (lb(local min(c)) + lb (c)), mincchildren (ub(local min(c)) + ub (c))],prepre[maxcchildren (lb(local max(c)) + lb (c)), maxcchildren (ub(local max(c)) + ub (c))],[cchildren (lb(persist(c))),cchildren (ub(persist(c)))]i,preprepreprelb(c) ub(c) respective lower upper bounds cumulative persistent usages children execute c. computations formcomputations final persist.case subtasks execute parallel identical durations slightly simpler.usage profiles add together, branchs resultant summary usage comes475fiC LEMENT, URFEE , & BARRETTmove(A,B)soak rays<[-4,-4],[-4,-4],[0,0]><[0,4],[4,6],[0,0]>soak rays<[-5,-5],[-5,-5],[0,0]>soak rays<[-6,-6],[-6,-6],[0,0]>Figure 12: Possible task ordering rovers morning activities, resulting subintervals.PARALLEL-AND computationh [cchildren (lb(local min(c))),maxcchildren (ub(local min(c)) + nonub (c))],non[mincchildren (lb(local max(c)) + lb (c)), cchildren (ub(local max(c)))],[cchildren (lb(persist(c))),cchildren (ub(persist(c)))]i,nonnonub (c) lb (c) respective sums local max upper bounds local minlower bounds children except c.handle tasks loose temporal constraints, consider legal orderings childtask endpoints. example, rovers early morning tasks, three serial solar energy collection subtasks running parallel subtask drive location B. Figure 12 showsone possible ordering subtask endpoints, breaks move(A,B) three pieces,two soak rays children half. Given ordering, summarization algorithm (1)use endpoints children determine subintervals, (2) compute summary informationchild task/subinterval combination, (3) combine parallel subinterval summaries usingPARALLEL-AND computation, (4) chain subintervals together using SERIALAND computation. Finally, tasks summary computed combining summariespossible orderings using computation.describe step (2) generates different summary resource usages subintervalschild task. child task summary resource usage h[a,b],[c,d],[e, f ]i contributes one twosummary resource usages intersecting subinterval4 :h[a, b], [c, d], [0, 0]i, h[a, d], [a, d], [0, 0]i.first usage tighter [a,b],[c,d] local ranges, second looser [a,d],[a,d] localranges. Since b c bounds apply subintervals containing subtasks minimummaximum usages, tighter ranges apply one subtasks intersecting subintervals.minimum maximum usages may occur subinterval, symmetry argumentslet us connect computation. Thus one subinterval tighter local rangesintersecting subintervals get looser local ranges, extra complexity comesinvestigate subtask/subinterval assignment options. instance, three subintervalsintersecting move(A,B) Figure 12, three different assignments summary resource usagessubintervals: placing [0,4],[4,6] one subinterval [0,6],[0,6] two.placement options result subtask n subintervals n possible subinterval assignments.child tasks n alternate assignments, nm combinationspotential subtask/subinterval summary resource usage assignments. Thus propagating summaryinformation branch exponential number subtasks multiple internal4. summary resource usages last interval intersecting child task, replace [0, 0] [e, f ] persist.476fiA BSTRACT R EASONING P LANNING C OORDINATIONsubintervals. However since number subtasks controlled domain modelerusually bounded constant, computation tractable. addition, summary informationoften derived offline domain. propagation algorithm takes form:consistent ordering endpoints:consistent subtask/subinterval summary usage assignment:Use PARALLEL-AND computations combine subtask/subinterval summaryusages subinterval.Use SERIAL-AND computation subintervals combined summary usagesget consistent summary usage.Use computation combine consistent summary usages get tasks summaryusage.described derive summary information, discuss use it.4. Identifying Abstract Solutionspoint, detailed algorithms deriving summary conditions reasoningpotential (may) definite (must) interactions tasks based summary information. addition, outlined algorithms deriving summarized resource usageyet discussed identify solutions abstract levels. section, showinteractions summary conditions summarized metric resource usages identify potentiallyresolvable threats unresolvable conflicts among plans group agents.4.1 Threats Summary ConditionsAgents attempt resolve conflicts among plans considering commitments particulardecompositions ordering constraints. order this, agents must able identifyremaining conflicts (threats) among plans. present simple algorithms reasoningthreats abstract plans required conditions.Formally, set CHiPs P ordering constraints order, threat abstract planp P summary condition c0 another plan p0 P exists iff p may-clobber c0 . saythreat unresolvable p must-clobber c0 must(c0 ) decomposition choicesordering constraints could added resolve threat.So, simple algorithm identifying threats check see O(nc) summaryconditions n plans Psum must- may-clobbered plan. Since complexitychecking see particular condition must- may-clobbered O(nc), algorithmscomplexity O(n2 c2 ).many coordination tasks, agents could determine certain temporal constraintsplans decomposed way (CanAnyWay) constraintsway successfully decomposed (MightSomeWay), make coordinationdecisions abstract levels without entering potentially costly search valid plan merges lowerlevels. formal definitions CanAnyWay MightSomeWay:477fiC LEMENT, URFEE , & BARRETTa)produce Hb)maintenanceproduce Hmaintenancemove_partsmove_partsc)produce Hproduce Gproduce H Gmaintenanceservice M1 M2serviceserviceM1M2movetoolmove_partsFigure 13: top-level plans managers manufacturing domainDefinition 13[CanAnyWay, MightSomeWay](order, Psum )[, ]h, P summary f ormation = Psum h H(P, order)[, ]e E(h), succeeds(e, h)Definition 13 states plans summary information Psum ordering constraintsexecute way sets plans P summary information Psumexecute successfully history. MightSomeWay true set planscould possibly execute successfully. could also describe CanSomeWay(order,Psum )MightAnyWay(rel,Psum ) fashion, obvious addition couldinfluence search. Exploring relations may interesting topic future research.Figure 13a, three top-level plans managers unordered respect other.leaf plans partially expanded hierarchies comprise Psum . Arrows represent constraintsorder. CanAnyWay({},{produce G, maintenance, move parts}) false several conflicts use machines transports could occur certain executionsplans described Section 3.3 Figure 8. However, MightSomeWay({}, {produce G,maintenance, move parts}) true plans might way execute successfullyshown Figure 13b. ordering constraints Figure 13b, CanAnyWay({before(1,0),before(0,2)},{produce G, maintenance, move parts}) true plans executeway consistent ordering constraints without conflict. Figure 8b exampleMightSomeWay false calibrate M2 must-clobber available(M2)MuF summary precondition build H.shown Figure 14, algorithm determining CanAnyWay summary conditionssimple needs check threats. MightSomeWay complicatedchecking unresolvable threat enough. shown Figure 15, caseplan p must clobber p0 p00 could come achieve precondition ` p0 .Thus, p may-clobbers ` p p00 . However, obviously p clobber one other,478fiA BSTRACT R EASONING P LANNING C OORDINATIONAlgorithm: [CanAnyWay, MightSomeWay]Input: order, PsumOutput: true f alsebegin functionpsum Psum[consistent(psum ), f alse] return f alsep0sum Psumsummary condition c psump0 [may-clobber, must-clobber] c,c [may must, must],return f alseresource res[CanAnyWay, MightSomeWay](order, Psum , res) (see Section 4.2)return falsereturn trueend functionFigure 14: Algorithm determining whether plans given summary information CanAnyWayMightSomeWay execute successfully.plp-lllplllFigure 15: MightSomeWay false even though must-clobber relationship.MightSomeWay false. order determine MightSomeWay f alse, agent must exhaustivelysearch exponential number schedules see conflicts resolved. Insteadperforming exponential search determine MightSomeWay, use simple algorithmFigure 14 checks must-clobber relationships. Section 5.1 describe flexiblesearch find conflict-free abstract plans scheduling abstract level.Thus, CanAnyWay algorithm sound complete, MightSomeWay algorithmcomplete sound. also means determining MightSomeWay soundcomplete. still make use algorithms sound complete planning/coordination algorithm Section 5.1. complexity algorithms O(n2 c2 ) sinceO(nc) procedures determining must/may-clobber must run nc conditions (csummary conditions n plans represented Psum ).4.2 Summary Resource Usage ThreatsPlanners detect threats resource constraints different ways. planner reasons partially ordered actions, must consider combinations actions overlap togetherexceed (or fall below) resources maximum value (or minimum value). polynomial algorithm479fiC LEMENT, URFEE , & BARRETTIxTeT planner (Laborie & Ghallab, 1995). planners consider total order plans simply project levels resource initial state plan,summing overlapping usages, see conflicts (e.g., Chien et al., 2000b).Finding conflicts involving summarized resource usages work way.partial order planner, resultant usage clusters actions tested using PARALLELAND algorithm Section 3.5. total order planner, level resource representedsummarized usage, initially h[x, x], [x, x], [x, x]i consumable resource initial levelx h[x, x], [x, x], [0, 0]i non-consumable resource. Then, subintervalstart end times schedule tasks, summary usage computed usingPARALLEL-AND algorithm. level resource computed subintervalpropagating persistent usages using SERIAL-AND algorithm.decide CanAnyWay MightSomeWay defined Section 4.1, terms summary usage values resulting invocations PARALLEL-AND SERIAL-AND propagation algorithm end Section 3.5.2. CanAnyWay(order, Psum , res) truepotential threats. algorithms discover threat ever compute intervallb(local min(i)) < min value(res) lb(persist(i)) < min value(res)ub(local max(i)) > max value(res) ub(persist(i)) > max value(res).MightSomeWay(order, Psum , res) true possible run potentiallythreats. SERIAL-AND discovers run returns summary usageub(local min(i)) min value(res) lb(persist(i)) min value(res)lb(local max(i)) max value(res) ub(persist(i)) max value(res).mechanisms deriving summary information evaluating plans basedsummarizations, discuss exploit planning/coordination algorithm.5. Hierarchical Planning Coordination Algorithmearlier defined algorithms reasoning group agents plans multiple levelsabstraction, describe agents efficiently plan coordinate based summaryinformation. describe coordination algorithm searches ways restrict decomposition ordering collective actions agent(s) order resolve conflictsmaximizing utilities individual agents global utility group.approach starts making planning decisions abstract level and, needed,decomposes agents plans top-down fashion. idea introduce information needed. Introducing irrelevant details complicates search increases communication.describing top-down planning/coordination algorithm, describe search techniquesheuristics algorithm use exploit summary information.5.1 Top-Down Hierarchical Planning Coordinationformalism summary conditions culminated Section 4 algorithms determine setplans (abstract primitive) partial set ordering constraints definitely conflict-free(CanAnyWay) unresolvable conflicts (MightSomeWay). integrate algorithmsone searches consistent plan one agents. particular algorithmdescribe shown sound complete (Clement, 2002). search startstop-level plans agent. solution one possible conflicts among480fiA BSTRACT R EASONING P LANNING C OORDINATIONagents plans. algorithm tries find solution top level expands hierarchiesdeeper deeper optimal solution found search space exhausted.pseudocode description algorithm given Figure 16.state search partially elaborated plan represent set plans (oneagent), set temporal constraints, set blocked plans. subplans plansleaves partially expanded hierarchies agents. set temporal constraintsincludes synchronization constraints added search addition dictatedagents individual hierarchical plans. Blocked subplans keep track pruned subplans.Decisions made search decentralized fashion. agents negotiateordering constraints adopt, choices subplans accomplish higher level plans,decompositions explore first. algorithm described specify (orcommit to) negotiation technique, provide mechanisms identifying choicesagents negotiate. Although agents make search decisions decentralized fashion, describe algorithm given centralized process requests summaryinformation agents coordinated.pseudocode Figure 16, coordinating agent collects summary informationagents plans decomposes them. queue keeps track expanded search states.CanAnyWay relation holds search state, Dominates function determines currentsolutions better every agent solution represented current search statekeeps solution dominated. MightSomeWay false, search space rootedcurrent search state pruned; otherwise, coordinator applies operators generate newsearch states.operators generating successor search states expanding non-primitive plans, blocking subplans, adding temporal constraints pairs plans. agent expands oneplans, plans summary conditions replaced original conditionsparent plan. subplans summary information ordering constraints addedsearch state. subplan plan added (or selected) subplansblocked. ApplyOperator called select block operators, search statesgenerated selectable blockable subplan, respectively. Blocking subplaneffective resolving constraint subplans involved. example,inventory manager plans use transport2, production manager could block subplansusing transport2, leaving subplans using transport1 conflict inventory managersplan. lead least commitment abstract solutions leave agents flexibility selecting among multiple applicable remaining subplans. agents take another approachselecting subplan (effectively blocking others) investigate preferred choice onelikely avoids conflicts.operator add temporal constraint, new search state created alternative temporal constraint could added. successor states enqueuedbacktracking needed, alternative tried. Adding temporal constraints generate new search states ordering consistent global local constraints.implementation, add constraints help resolve threats determinedmust/may achieves clobbers algorithms. plan expanded selected, orderingconstraints must updated subplans added.soundness completeness coordination algorithm depends soundnesscompleteness identifying solutions complete exploration search space. Soundness481fiC LEMENT, URFEE , & BARRETTConcurrent Hierarchical Coordination AlgorithmInput: set top-level plans, initial stateOutput: set solutions, pair order constraints blocked plan choicesbegin functionsummarized plans = 0/plan p plansp0 = get summary information plan psummarized plans = summarized plans { p0 }endthreats = { (p, p0 ) | p, p0 summarized plans, MayClobber(p, p0 ) }/ 0,/ threats) }queue = { (0,solutions = 0/loopqueue == 0/return solutions(order, blocked, threats) = Pop(queue)CanAnyWay(initial state, summarized plans, order, blocked)solution = (order, blocked)solutions = solutions {solution}sol1 sol2 solutionsDominates(sol1 , sol2 )solutions = solutions - { sol2 }MightSomeWay(initial state, summarized plans, order, blocked)operator = Choose({expand, select, block, constrain})queue = queue ApplyOperator(operator, summarized plans, order, blocked)return solutionsend functionFigure 16: concurrent hierarchical coordination algorithm.completeness defined respect achieving particular goal predicates resolvingconflicts plan hierarchies. domain modeler may represent goals abstract CHiPsdecompose possible plans accomplish series actions agent executesuccessfully.Consider algorithm would find coordinated plans manufacturing agents.beginning search, coordinating agent gathers summary information top-levelplans three agents plans. first, ordering constraints, order emptyfirst search state (shown Figure 13a) popped queue. CanAnyWay false,MightSomeWay true state described earlier section, coordinator choosesoperator apply search state. could choose constrain order maintenanceplan produce H resolve conflicts two plans. order updatednew constraint, new search state inserted queue according rankingfunction. next iteration loop, search state queue insertedpopped. coordinator finds CanAnyWay false, MightSomeWay true sincemove parts may still conflict plans use transports. choose constrainproduce H move parts resolve remaining conflicts. detected next cyclesearch loop CanAnyWay found true search state (shown Figure 13b).482fiA BSTRACT R EASONING P LANNING C OORDINATIONplans, two constraints order, empty set blocked plans added solutionsince previously found solution Dominates it. Dominates function uses domainspecific criteria determining solution value alternative keptinferior compared another dropped. manufacturing domain, one solutiondominates another finish time least one agent earlier finish times lateragents. search continues find alternative superior solutions, although agentsmay decide terminate search interest time.5.2 Search Techniques HeuristicsAlthough summary information valuable finding conflict free coordinated plans abstractlevels, information also valuable directing search avoid branches searchspace lead inconsistent suboptimal coordinated plans. coordinator prune awayinconsistent coordinated plans abstract level quick check see MightSomeWayfalse. example, search somehow reached state shown Figure 8b, coordinatorcould backtrack expanding hierarchies avoid reasoning detailsplans must fail.Another strategy first expand plans involved threats. sake completeness, order plan expansions matter long expanded pointsearch trail cannot pruned. But, employing expand threats first (EMTF)heuristic aims driving search hierarchy find subplan(s) causing conflicts others resolved quickly. similar most-constrainedvariable heuristic often employed constraint satisfaction problems. example, facilitiesinventory managers wished execute plans concurrently shown Figure 17a,abstract level, coordinator would find conflicts use transportsmoving parts. Instead decomposing produce H reasoning plan detailsconflicts, EMTF heuristic would choose decompose either maintenance move partsconflicts. decomposing maintenance agents resolve remainingconflicts still execute concurrently.Another heuristic coordinator use parallel EMTF choose fewest threatsfirst (CFTF). search orders states search queue ascending numbers threatsleft resolve. effect, least-constraining value heuristic used constraint satisfactionapproaches. mentioned Section 4.1, threats identified CanAnyWay algorithm.trying resolve threats coordinated plan search states fewer conflicts, hopedsolutions found quickly. So, EMTF heuristic ordering subplans expand,CFTF, effect, orders subplan choices. example, production manager choosesuse machine M1 instead M2 produce G, coordinator likely closer solutionfewer conflicts resolve. heuristic applied selecting subplanchoices also choosing temporal constraints variable bindings search operatorentire set operators.addition, trying find optimal solutions style branch-and-bound search,coordinator use cost abstract solutions prune away branches search space whoseminimum cost greater maximum cost current best solution. roleDominates function description coordination algorithm Section 5.1. usually483fiC LEMENT, URFEE , & BARRETTa)maintenanceproduce Hmove_partsb)maintenanceservice M1 M2serviceserviceM1M2movetoolproduce Hmove_partsFigure 17:EMTFheuristic resolving conflicts decomposing maintenance planassumes cost/utility information decomposable hierarchy actions, costabstract action function decompositions.6. Complexity AnalysesEven though planner coordinator use search techniques described Section 5.2prune search space, able find solutions multiple levels abstraction reducecomputation much doubly exponentially. section, give exampleanalyze complexity planning scheduling characterize cost reductionconditions occurs.agent interleaves execution planning/coordination often must limit total computation execution cost required achieve goals. planning algorithm described Section5.1 able search solutions different levels abstraction. manufacturing example,implementation centralized coordinator uses algorithm find 1.9 CPU seconds solution top level agents plans shown Figure 13b. define cost executionmakespan (completion time) coordinated plan, cost solution 210makespan production managers plan 90, facilities managers 90, inventorymanagers 30. solution Figure 13c, coordinator required 667 CPU seconds,makespan coordinated plan 170. Another solution found intermediate levelabstraction, taking 69 CPU seconds makespan 180. So, little effort,algorithm expanded hierarchy intermediate level cost solutionreduced 30. Thus, overall cost reduced coordinating intermediate levels.problem, coordinating higher levels abstraction less costlyfewer plan steps. But, even though fewer plans higher levels, plans maygreater numbers summary conditions reason collected muchgreater set plans below. argue even worst case number summaryconditions per plan increases exponentially hierarchy, finding solutions abstract levelsexpected exponentially cheaper lower levels. first analyze complexity484fiA BSTRACT R EASONING P LANNING C OORDINATIONsummarization algorithm help reader understand summary conditions collectgreater sets higher levels.6.1 Complexity SummarizationConsider hierarchy n total plans, b subplans non-primitive plan, depth d, startingzero root, shown Figure 18. procedure deriving summary conditions worksbasically propagating conditions primitives hierarchy abstractplans. conditions non-primitive plan depend immediate subplans, deriving summary conditions done quickly number subplans large.derivation algorithm mainly involves checking achieve, clobber, undo interactions amongsubplans possible total orderings subplans (as described Section 3.4). Checkingone relations one summary condition one subplan O(bs) b subplans,summary conditions (as discussed Section 3.3). Since O(bs) conditions mustchecked set subplans, deriving summary conditions one plan subplansO(b2 s2 ).However, maximum number summary conditions subplan grows exponentiallyhierarchy since, worst case, summary conditions merge summarization.happens conditions subplan completely different propositions/variablessibling subplan. case, separate summary condition generatedsummary condition subplan. children share conditions variable,information collapsed single summary condition parent plan.shown third column table Figure 18, plan lowest level = csummary conditions derived c pre-, in-, postconditions. plan level 1 derives csummary conditions conditions c b subplans giving c + bc summary conditions, = O(bc). So, worst case = O(bdi c) plan level hierarchyplan c (non-summary) conditions. Thus, complexity summarizing planlevel (with subplans level + 1) O(b2 b2(d(i+1)) c2 ) = O(b2(di) c2 ). bi planslevel (second column figure), complexity summarizing set plans levelO(bi b2(di) c2 ) = O(b2di c2 ) shown fourth column figure. Thus, complexity2(di) c2 ). summation = 0summarizing entire hierarchy plans would O(d1i=0 b b2d2dominates, complexity simplified O(b c ). n = O(bd ) planshierarchy, write simply O(n2 c2 ), square size hierarchy.best case conditions variable, plan c summary2 2conditions. Thus, complexity summarizing hierarchy O(d1i=0 b b c ),simplifies O(bd+1 c2 ) = O(nbc2 ). case, summarization conditions tractable,discussed Section 3.5.2, summarization resources also tractable.6.2 Complexity Finding Abstract Solutionsorder resolve conflicts (and potentially arrive solution) particular level expansionhierarchy, coordination algorithm checks threats plans particularordering constraints level. Checking threats involves finding clobber relations amongplans summary conditions. complexity finding threats among n planssummary conditions O(n2 s2 ) shown Section 4.1 MightSomeWay algorithm.hierarchy expanded level i, n = O(bi ) plans frontier expansion, plan485fiC LEMENT, URFEE , & BARRETTlevel #plans #conds / #operations #test operations / solutionplan derive summ. info. solution candidate space12...b.............................................................12...b12...b.......01O(bdc)O(b2(bd-1c)2)= O(b2dc2)O(1)11bO(bd-1c)O(bb2(bd-2c)2)= O(b2d-1c2)O(b2(b(d-1)c)2)= O(b2dc2)O(kb)2b2O(bd-2c) O(b2b2(bd-3c)2)= O(b2d-2c2)O(b4(b(d-2)c)2)= O(b2dc2)O(kb )d-2bd-2O(b2c)O(bd-2b2(bc)2)= O(bd+2c2)O(b2(d-2)(b2c)2) O(kb )= O(b2dc2)d-1bd-13c+b3c= O(bc)O(bd-1b2c2)= O(bd+1c2)O(b2(d-1)(bc)2) O(kb )= O(b2dc2)bd3cO(1)O(b2dc2)O(kb )biO(bd-ic)O(b2d-ic2)O(b2dc2)O(kbi)2d-2d-1Figure 18: Complexity threat identification resolution abstract levels= O(bdi c) summary conditions. So, shown fifth column table Figure 18,worst case complexity checking threats one synchronization set plans levelO(b2i (bdi c)2 ) = O(b2d c2 ). Notice drops formula, meaning complexitychecking candidate solution independent depth level. best case summaryconditions fully merge, plan = c summary conditions, complexity checkingcandidate solution O(b2i c2 ), factor O(b2(di) )faster worst case.However, algorithm may check many synchronizations particular level findingsolution exhausting search space. fact search complexity grows exponentiallynumber plans.5 Thus, shown last column table Figure 18, search spaceO(kb ) bi plans level constant k.6 Thus, search space grows doubly exponentiallyhierarchy based number plan steps.refinement coordination planning algorithm, conflict detection basic operationdone resolving conflicts. So, also include effect size conditions (inaddition plan steps) complexity planning/coordination algorithm, must multiplycomplexity check threats. Thus, complexity O(kb b2d c2 ) summary informationmerge O(kb b2i c2 ) summary information fully merges. complexityresolving conflicts primitive level O(kb b2d c2 ), resolving conflicts abstractlevel speeds search doubly exponentially, factor O(kb b ) even summary informationmerge summarization. Now, completely merges, speedup factorO(kb b b2(di) ).5. fact, NP-complete (Clement, 2002).6. Georgeff chose cluster multiple operators critical regions synchronize (fewer) regionssince would many fewer interleavings check (1983). exploiting hierarchical structure plans,use clusters predefined hierarchy kind advantage without needing cluster bottomup.486fiA BSTRACT R EASONING P LANNING C OORDINATIONlevel01branchingfactor b...12nc constraintsper hierarchyvvariablesFigure 19: Schedule n task hierarchies c constraints v variablesplans analysis. case plans, able prunebranches higher levels based summary information also greatly improve search despiteoverhead deriving using summary conditions. Pruning effectively reduces branchingfactor since branch eliminated investigating details. Thus, complexity basednumber plan steps becomes O(k(bp) ) fraction p/b branches pruned. Thus,pruning also create exponential reduction search.6.3 Scheduling Complexitylocal search planner (e.g. ASPEN, Chien et al., 2000b) backtrack, problemsolved same, one might expect complexity advantages refinement planner. However, search operations local search planner different.previous study technique called aggregation eliminates search inefficiencies lower levelsdetail task hierarchies operating hierarchies single tasks (Knight, Rabideau, & Chien,2000). Thus, immediately clear additional improvements scheduler could obtainedusing summary information. show improvements significant, first mustprovide background aggregation.Moving tasks central scheduling operation iterative repair planners. plannereffectively schedule tasks moving related groups tasks preserve constraints among them.Hierarchical task representations common way representing groups constraints. Aggregation involves moving fully detailed abstract task hierarchy preservingtemporal ordering constraints among subtasks. Moving individual tasks independentlyparent, siblings, subtasks shown much less efficient (Knight et al., 2000). Valid placements task hierarchy schedule computed state resource usage profileshierarchy tasks context movement. hierarchys profile represents one instantiation decomposition temporal ordering abstract taskhierarchy.Consider schedule n task hierarchies maximum branching factor b expandedmaximum depth shown Figure 19. Suppose hierarchy c constraints vvariables (states metric resources). move hierarchy tasks using aggregation, scheduler487fiC LEMENT, URFEE , & BARRETTmust compute valid intervals resource variable affected hierarchy.7 schedulerintersects intervals get valid placements abstract tasks children.complexity computing set valid intervals resource O(cC) c numberconstraints (usages) abstract task children variable, C numberconstraints tasks schedule variable (Knight et al., 2000). n similartask hierarchies entire schedule, C = (n 1)c, complexity computing validintervals O(nc2 ). computation done v resource variables (often constantdomain), moving task complexity O(vnc2 ). intersection valid intervalsacross variables increase complexity. complexity O(tnr)nr valid intervals timeline; intersecting intervals pair timelines linearnumber intervals; 1 pairs timelines need intersected get intersectionset.summary information abstract task represents constraints children,children share constraints resource, information collapsed singlesummary resource usage abstract task. Therefore, moving abstract task, numberdifferent constraints involved may far fewer depending domain. schedulertrying place summarized abstract task among summarized tasks, computation validplacement intervals greatly reduced c O(vnc2 ) smaller. considertwo extreme cases constraints fully collapsed cannot collapsedall.case tasks hierarchy constraints variable, numberconstraints hierarchy O(bd ) hierarchy depth branching factor (number childtasks per parent) b. aggregation, hierarchies fully detailed first, meanscomplexity moving task O(vnb2d ) c = O(bd ). consider using aggregationmoving partially expanded hierarchy leaves summarized abstract tasks.hierarchies schedule decomposed level i, O(bi ) tasks hierarchy,one summarized constraint representing yet undetailed subtasks beneathconstraint variable. c = O(bi ), complexity moving task O(vnb2i ). Thus,moving abstract task using summary information factor O(b2(di) ) times fasteraggregation. worst case number conflicts increases number plansteps (just refinement planner), worst case complexity resolving conflicts basednumber plan steps level O(kb ). Thus (as refinement planning) using summarydiinformation make speedups O(kb b2(di) ) summary information fully collapses.extreme tasks place constraints different variables. case,c = 1 hierarchy one constraint per variable. Fully detailed hierarchiescontain v = O(bd ) different variables, complexity moving task case O(nbd ).moving summarized abstract task tasks schedule decomposed level i, vabstract task summarizes constraints subtask hierarchybeneath it, constraints different variables constraints combinesummarized. Thus, complexity moving partially expanded hierarchyfully expanded one. case, number conflicts also change depthhierarchy conflicts always pairs n hierarchies. So,7. analysis also applies state constraints, restrict discussion resource usage constraints simplicity.488fiA BSTRACT R EASONING P LANNING C OORDINATIONextreme case, summary information reduce complexity scheduling wouldincur unnecessary overhead.complexity analyses shown different forms hierarchical problem solving,need backtrack lower higher levels interacting subproblems, reduce size search space exponential factor (Korf, 1987; Knoblock, 1991).planner scheduler using summary information witness exponential improvements withoutassumption. Backtracking across abstraction levels occurs within planner/coordinator described Section 5.1 current search state MightSomeWay another subplanhigher level selected. demonstrated search space grows doublyexponentially hierarchy number plans grows exponentially, resolvingconflicts grows exponentially number plans. Thus, long planner coordinator fully expand abstract plans primitive level summary informationmerges higher levels, search complexity reduced least factor kb blevel search completed, depth hierarchy. Yang (1997) also suggestsways exponential speedups obtained subplans interact based hierarchy structure.speedups complementary summary information limits decompositiontask hierarchies compresses information manipulated planner scheduler.7. Experimentsexperimentally evaluate use summary information planning coordinationthree different domains: evacuation domain, manufacturing domain described Section 1.1,multi-rover domain. domains, define performance different ways showrange benefits abstract reasoning offers.evaluate algorithm described Section 5.1. implementation orders search statesqueue generated synchronization operators precede generatedexpansion selection operators. Thus, going deeper part hierarchy, implementation algorithm explores orderings agents plans digging deeperhierarchy. Investigating heuristics choosing synchronization decompositionoperators topic future research.next section report experiments evacuation domain show abstractreasoning using summary information find optimal coordination solutions quicklyconventional search strategies. Optimal solutions evacuation domain minimal global execution times evacuees must transported safety quickly possible. Section 7.2,show summary information improves local search performance significantly taskswithin hierarchy constraints resource, solutions foundlevel abstraction. also evaluate benefits using CFTF EMTF heuristicsiterative repair show summary information slow search.domains, computation time may insignificant communication costs. costscould terms privacy self-interested agents, security sensitive information couldobtained malicious agents, simply communication delay. Section 7.3, show multilevel coordination fails reduce communication delay manufacturing domain example but,domains, expected reduce communication overhead exponentially.489fiC LEMENT, URFEE , & BARRETT1s0230s3t2t145Figure 20: Evacuation problem7.1 Coordinated Planning Experimentssection, describe experiments evaluate use summary information coordinating group evacuation transports must together retrieve evacuees number locationsconstraints routes. comparing EMTF CFTF search techniques described Section 5.2 conventional HTN approaches, experiments show reasoning summaryinformation finds optimally coordinated plans much quickly prior HTN techniques.compare different techniques ordering expansion subplansplans direct decomposition plan hierarchies search optimal solutions.expansion techniques expand (for subplans) select (for subplans) operatorsalgorithm described Section 5.1.compare EMTFs expansion plans ExCon heuristic random selectionheuristic. ExCon heuristic (Tsuneto et al., 1998) first selects plans achieve externalprecondition, plans, selects one threatens external precondition.case neither achieving threatening plans, chooses randomly. NoteEMTF additionally choose expand plans threatened external preconditionspreference whether plan achieves, threatens, threatened. expansionplans, compare CFTF depth-first (DFS) random heuristic.also compare combination CFTF EMTF FAF (fewest alternatives first)heuristic combination DFS ExCon. FAF heuristic employ summaryinformation rather chooses expand select plans fewest subplans(Currie & Tate, 1991; Tsuneto, Hendler, & Nau, 1997). Since summary information used,threats resolved primitive levels. shown FAF heuristiceffectively used HTN planner (Tsuneto et al., 1997), combination DFS ExConshown make great improvements FAF domain task interactions(Tsuneto et al., 1998). show one domain CFTF EMTF heuristics togetheroutperform combinations FAF, DFS, ExCon.problems generated evacuation domain transports responsiblevisiting certain locations along restricted routes pick evacuees bring back safetypoints. Transports allowed location time, coordinator mustensure transports avoid collisions along single lane routes. addition, order avoidrisk oncoming danger (from typhoon enemy attack), transports must accomplishgoals quickly possible.Suppose two transports, t1 t2, located safety points s0 s3 respectively,must visit locations 0, 1, 2 2, 3, 4 respectively bring evacuees back safe490fiA BSTRACT R EASONING P LANNING C OORDINATIONevacuatemove s0-0make roundsone switchswitchclockwisefirst routecw0-1second routecw0-2move 0-1counterclockwiseccw1-2ccw2-0go backccw2-0goto safe locmovemove 0-s0move 3-s3move 1-2Figure 21: plan hierarchy transport t1locations shown Figure 20. overlap locations must visit, coordinatormust synchronize actions order avoid collision. coordinators goal network includestwo unordered tasks, one transport evacuate locations responsible.shown Figure 21, high-level task t1 (evacuate) decomposes primitive actionmoving location 0 ring abstract plan traverse ring (make rounds). t1travel one direction around ring without switching directions, switch directions once.t1 either go clockwise counterclockwise and, switching, switch directionslocation ( f irst route) travel farthest location needs visit switched(second route). visited locations, continues around reaches firstsafety point path (go back goto sa f e loc). move plan case t1already location 0. task t2 refined similarly.Suppose coordinator gathers summary information plan hierarchy attemptsresolve conflicts. Looking summary information one level top, coordinatordetermine t1 finishes evacuating t2 even begins, conflictssince external conditions t1s evacuate plan none routes traversed.solution makespan (total completion time) 16 steps. optimal solution planduration seven t1 moves clockwise reaches location s3, t2 starts clockwise,switches directions location 4, winds s0. solution t1 waits location 2one time step avoid collision route location 2 location 3.generated problems four, six, eight, twelve locations; two, three fourtransports; no, some, complete overlap locations transports visit. Performance measured number search states expanded find optimal solution (ifcompared heuristics find optimal solution) number states expandedfind solutions highest common quality within memory time bounds. chose instead CPU time measure performance order avoid fairness issues respectimplementation details various approaches.491fiC LEMENT, URFEE , & BARRETTSearch States Expanded100000CFTF-RAND1000010001001011101001000 10000 1E+05CFTF-EMTFFigure 22: Comparing EMTF random expansion searching optimal solutionsFigure 23: Comparing EMTF ExCon searching optimal solutionsscatter plot Figure 22 shows relative performance combination CFTFcombination CFTF random expansion (CFTF-Rand).chose scatterplots compare results capture results simply tryingplot three dimensions problem size/complexity. Note scatter plots, axesscaled logarithmically. Points diagonal line mean EMTF (x-axis) performing betterRand (y-axis) fewer search states required find optimal solution.performance similar problems, cases CFTF-EMTF outperformedCFTF -Rand order magnitude more. Figure 23 exhibits similar effect CFTF - EMTFCFTF-ExCon. Note runs terminated expansion 3,500 search states. Datapoints 3,500 (the ones forming horizontal line top) indicate solution foundwithin memory time constraints. performance similar problems, fourpoints along top CFTF-ExCon finds solution. Thus, although EMTF greatlyEMTF ( CFTF - EMTF )492fiA BSTRACT R EASONING P LANNING C OORDINATIONFigure 24: Comparing CFTF DFS searching optimal solutionsimprove performance many problems, rarely performs much worse, almost always avoidsgetting stuck fruitless areas search space compared ExCon random heuristic.expected since EMTF focuses resolving conflicts among problematic plansfirst avoids spending lot time reasoning details less problematic plans.combination CFTF EMTF, pruning inconsistent abstract plan spaces, branchand-bound pruning costly abstract plan spaces (all described Section 5.2) muchdramatically outperforms techniques reason abstract levels. Figure 24 shows DFSRand expanding one three orders magnitude states CFTF-Rand. Runsterminated expansion 25,000 search states. Data points 25,000 (forminghorizontal line top) indicate solution found within memory time constraints.avoiding search spaces greater numbers conflicts, CFTF finds optimal near-optimal solutions much quickly. Figures 25 26, CFTF-EMTF outperforms FAF-FAF (FAFselecting plans) DFS-ExCon one two orders magnitude problems.last two comparisons especially emphasize importance abstract reasoning findingoptimal solutions. Within maximum 3,500 expanded search states (the lowest cutoff pointexperiments), CFTF-EMTF CFTF-Rand found optimal solutions 13 24 problems.CFTF -ExCon FAF- FAF found 12; DFS -ExCon DFS -Rand found three.surprising result FAF-FAF performs much better DFS-ExCon evacuationproblems contrary results given Tsuneto et al. (1998) show DFS-ExCon dominatingproblems goal interactions. believe result reproducedexperiments involved hierarchies plans. experiments showselection subplans greatly affects performance order subplans expand.So, believe DFS-ExCon performed worse FAF-FAF FAF better choosingsubplans ExCon FAF stronger selecting subplans DFS.However, main point section heuristic combinations use summary information find solutions prune search space abstract levels (CFTF-EMTF, CFTFExCon, CFTF-Rand) greatly outperform (FAF-FAF, DFS-ExCon,DFS -Rand) searching optimal solutions.493fiC LEMENT, URFEE , & BARRETTFigure 25: Comparing use summary information FAF heuristicFigure 26: Comparing use summary information algorithm using external conditions7.2 Scheduling Experimentsexperiments describe show summary information improves performance significantly tasks within hierarchy constraints resource, solutionsfound level abstraction. time, cases abstract reasoningincurs significant overhead solutions found deeper levels. However, domainsdecomposition choices critical, show overhead insignificantCFTF heuristic chooses decompositions quickly lead solutions deeper levels.experiments also show EMTF heuristic outperforms simpler heuristic dependingdecomposition rate, raising new research questions. use ASPEN Planning System (Chienet al., 2000b) coordinate rover team problem described next.494fiA BSTRACT R EASONING P LANNING C OORDINATIONFigure 27: Randomly generated rectangular field triangulated waypointsFigure 28: Randomly generated waypoints along corridors7.2.1 P ROBLEM OMAINSdomain involves team rovers must resolve conflicts shared resources. generatetwo classes maps within rovers move. one, randomly generate map triangulated waypoints (Figure 27). other, generate corridor paths circle locationsthree paths center points circle represent narrow paths around obstacles(Figure 28). corridor map used evaluate CFTF heuristic. select subsetpoints science locations (where rovers study rocks/soil) use simple multiple traveling salesman algorithm assign routes rovers traverse perform experiments.idea map area around lander constructed image taken upon landingMars.Paths waypoints assigned random capacities either one, two, threerovers traverse path simultaneously. one rover waypoint, rovers maytraverse paths opposite directions time. constraints modeled metricresources. State variables also used ensure rovers locationsleave. addition, rovers must communicate lander telemetry using shared channelfixed bandwidth (metric resource). Depending terrain waypoints, requiredbandwidth varies. 80 problems generated two five rovers, three six science locationsper rover, 9 105 waypoints. general, problems contain fewer waypointsscience goals difficult interactions among rovers.Schedules consist abstract task rover decomposition tasksvisiting assigned science location. tasks decomposition three shortestpaths waypoints target science location. paths decompositionmovements waypoints. Additional levels hierarchy introduced longer pathsorder keep offline resource summarization tractable. Schedules ranged 180 1300tasks.495fiC LEMENT, URFEE , & BARRETT7.2.2 E MPIRICAL R ESULTS ARS ROVERScompare ASPEN using aggregation without summarization three variationsrectangular field domain. using summary information, ASPEN also uses EMTF CFTFdecomposition heuristics. One domain excludes communications channel resource (no channel);one excludes path capacity restrictions (channel only); excludes neither (mixed).Since movement tasks reserve channel resource, greater improvement performanceexpected using summary information according complexity analyses Section 6.3.constraints channel resource collapse summary information derivedhigher levels task hierarchy one constraint resource.ASPEN use summary information, hierarchies must fully expanded, numberconstraints channel resource equivalent number leaf movement tasks.However, tasks within rovers hierarchy rarely place constraints path variablesonce, channel domain corresponds worst case summarizationcollapses constraints. complexity moving abstract task without summary information fully expanded hierarchy summary information partiallyexpanded hierarchy.Figure 29 (top) exhibits two distributions problems channel domain.cases (points x=y diagonal), ASPEN summary information finds solution quicklylevel abstraction. However, many cases, summary information performs notably worse(points x=y diagonal). discovered problems finding solution requiresplanner dig deeply rovers hierarchies, decomposes hierarchieslevel solution, difference additional time find solution twoapproaches negligible (unless use summary information found solution slightly higherlevel abstraction quickly). Thus, time spent reasoning summary informationhigher levels incurred unnecessary overhead.worst case analysis Section 6.3 showed summary information advantage even found abstract solutions. So, summary information performbetter abstract solutions found? CFTF heuristic since branchchoices result small differences numbers conflicts. actually results stochastic nature ASPENs iterative repair. Although moving abstract tasks using aggregation withoutsummary information would enabled ASPEN find solutions quickly fully expandedhierarchies, ASPEN must sometimes move lower level tasks independently parents siblings order resolve conflicts lower levels. problem ASPEN heuristic telllevel needs move activities, sometimes chooses move activities detailedlevels unnecessarily. search lower levels search space explodes. Using summaryinformation search higher levels lower levels abstraction better protects ASPENunnecessary search.Figure 29 (middle) shows significant improvement summary information mixed domain compared channel domain. Adding channel resource rarely affects usesummary information collapse summary constraints incurs insignificant additionalcomplexity. However, channel resource makes scheduling task noticeably difficultASPEN using summary information. channel domain (Figure 29 bottom), summary information finds solutions abstract level almost immediately, problems stillcomplicated ASPEN use summary information. results support complexity496fiA BSTRACT R EASONING P LANNING C OORDINATIONa)b)c)Figure 29: Plots a) channel, b) mixed, c) channel domainsanalysis Section 6.3 argues summary information exponentially improves performancetasks within hierarchy constraints resource solutionsfound level abstraction.summary information generated offline, domain modeler knows front whetherconstraints significantly collapsed. Thus, obvious approach avoiding casesreasoning summary information causes unnecessary overhead fully expand startscheduling hierarchies tasks summary information collapse.complexity moving task hierarchy case whether fully expanded not, ASPENwaste time duplicating efforts level expansion reaching levelfinds solution. Evaluating approach subject future work.Earlier mentioned CFTF heuristic effective rectangular field problems.choice among different paths science location usually make497fiC LEMENT, URFEE , & BARRETTFigure 30: Performance using CFTF heuristicsignificant difference number conflicts encounteredif rovers cross paths, pathchoices usually still lead conflict. set corridor problems, path choices always leaddifferent corridor get target location, usually path avoids conflictpath causes one depending path choices rovers. ASPEN usesCFTF heuristic, performance dominates chooses decompositions randomlytwo problems (Figure 30). reflects experiments coordination algorithm Section 7show CFTF crucial reducing search time required find solutions.order evaluate EMTF heuristic iterative repair planning, compared simplealternative. alternative strategy (that refer level decomposition) interleave repairdecomposition separate steps. Step 1) planner repairs current schedulenumber conflicts cannot reduced. Step 2) decomposes abstract tasks one levelreturns Step 1. spending enough time particular level expansion appearseffective, planner attempts find highest decomposition level solutions exist withoutwasting time level. time spent searching solution level expansioncontrolled rate abstract tasks decomposed. EMTF heuristic implementedrepair method give priority detailing plans involved conflicts.Figure 31 shows performance EMTF vs. level decomposition different rates decomposition three problems set varied performance. plotted points averagesten runs problem. Depending choice rate decomposition (the probabilitytask decompose conflict encountered), performance varies significantly. However, best decomposition rate vary problem problem making potentially difficultdomain expert choose. example, problem figure, tested decompositionrates EMTF outperformed use level decomposition. time, problem C usingeither decomposition technique make significant difference problem B choosingrate EMTF made big difference whether use EMTF level decomposition. Althoughexamples show varied performance, results problems showed decompo-498fiA BSTRACT R EASONING P LANNING C OORDINATION1200level-decomp1000BB level decompCCPU seconds800C level decomp600400200005101520253035EMTF Decomposition RateFigure 31: Performance EMTF vs. level-decomposition heuristicssition rate around 15% successful. suggests domain modeler may ablechoose generally successful decomposition rate running performance experiments setexample problems.8demonstrated many results complexity analyses Section 6. Schedulingsummary information gains speedups (over aggregation) resolving conflicts appropriate levels abstraction. summary information collapses, scheduler gains exponentialspeedups. addition, CFTF heuristic enables exponential speedups decompositionchoices varying numbers conflicts.7.3 Communication Overheadshow that, depending bandwidth, latency, summary information communicated among agents, delays due communication overhead vary. communication costsconcern, one extreme message delay dominates cost, sending plan hierarchywithout summary information makes sense. extreme bandwidth costsdominate, makes sense send summary information task separate messagerequested. Still, cases sending summary information tasks groupsmakes sense. section explain system designer choose muchsummary information send time order reduce communication overhead exponentially.Consider simple protocol agents request coordination central coordinating agent.search feasible solution, whenever decomposes task, coordinator requestssummary information subtasks yet received. manufacturing domain,coordinator may already summary information task move part, encountersdifferent instantiation task schema, still must request parameters new task.coordinator needs subplans plan, client agent sends required informationsubplans, specifying preferences each. coordinator chooses preferred8. experiments, used decomposition rate 20% since seemed work well.499fiC LEMENT, URFEE , & BARRETTa)b)Figure 32: Delay communicating different granularities summary information varying a)latency b) bandwidthsubplan, case must backtrack, chooses next preferred subplan.coordinator finds feasible solution, sends modifications agent specifying subplans blocked agent must send wait synchronization messages. agentchoose send summary information number levels expansion requestedtasks hierarchy.manufacturing problem described Section 1.1, communication data terms numbers messages size collected point coordinator foundsolution Figure 13c. data collected cases agents sent summary informationtasks hierarchies, one time, two levels time, once. two levelsinclude requested task immediate subplans. following table summarizesnumbers total sizes messages sent granularity level information:one task timetwo levels timenumber messages943total size (bytes)87081052516268Assuming coordinator must wait requested information continuing searchrequest one task one agent time, coordination delayed amounttime depending bandwidth latency message passing. total delay calculated (n 2)` + s/b, n number messages sent; ` latency seconds;total size messages; b bandwidth bytes per second. use n 2 instead nassume agents transmit first top-level summary information messagetime, three messages actually incur delay ` instead 3`.Figure 32a shows communication delay varies three granularities informationfixed bandwidth 100 bytes/second. (We address lack realism exampleshortly.) latency less 3 seconds, sending summary information taskseparate messages results smallest communication overhead. latencies greater 58seconds, sending entire hierarchy best; sending summary information twolevels time best. latency fixed 100 seconds, communication delay varies500fiA BSTRACT R EASONING P LANNING C OORDINATIONa)b)Figure 33: Delay varying a) latency b) bandwidth hypothetical examplebandwidth shown Figure 32b. bandwidth less 3 bytes/second, sendingone time best; sending best bandwidths greater 60 bytes/second;sending two levels time best bandwidths between.Admittedly, values unrealistic manufacturing domain. manufacturing problem simple provided mainly interesting domain coordination. realistic problems involving manufacturing domain could much larger hierarchies requiremuch larger scales data sent. case realistic bandwidth latency values wouldexhibit similar tradeoffs.see this, suppose manufacturing managers hierarchies common branchingfactor b depth d. tasks generally reservations similar resources throughout hierarchies, amount total summary information particular level would grow exponentiallyhierarchy would number tasks. agents agreed feasible solutiondepth level hierarchy, table messages size would appear follows:one task timetwo levels timenumber messagesO(bi )3i/23total sizeO(bi )O(bi )O(bd )suppose branching factor b 3; depth 10; solution found level= 5; summary information task 1 Kbyte. table would look like this:one task timetwo levels timenumber messages36393total size (Kbytes)10893276246033Now, fixed bandwidth 100 Kbyte/second varied latency, realistictradeoffs seen Figure 33a. Here, see unless latency small, sending summaryinformation two levels time best. shown Figure 33b, fix latency one secondvary bandwidth, realistic bandwidths sending summary information two levelstime best.501fiC LEMENT, URFEE , & BARRETTsimple protocol illustrates communication minimized sending summaryinformation particular granularity. agents chose send summary informationunsummarized hierarchies instead, would need send entire hierarchies.experiment shows, hierarchies grow large, sending entire hierarchy (all once) would takelong time, even high bandwidth. Thus, using summary information (as opposed usingit) reduce communication exponentially solutions found abstract levels.extreme, agents sent summary information one task time, latencysending many messages grow large larger task hierarchies. solutions couldfound primitive levels, sending summary information one task time would causeexponential latency overhead compared sending entire hierarchy once. But, solutionsfound intermediate levels, able send summary information intermediategranularity minimize total delay.However, argument assumes summary information collapses higher levels hierarchy. Otherwise, sending summary information intermediate level could almostexpensive sending entire hierarchy cause unnecessary overhead. actual manufacturing domain, tasks agents hierarchies mostly constraints different resources,summarization able reduce summary information significantly constraintscollapse. result better, case, send entire hierarchy minimizedelay (unless unusual bandwidth latency constraints, shown experiment).Even so, coordination agent still summarize hierarchies take advantagecomputational advantages abstract reasoning.section showed domain modeler minimize communication overhead communicating summary information proper level granularity. bandwidth, latency,common depth coordination solutions known, domain modeler perform hypotheticalexperiment like one varying granularities summary information determinegranularity optimal. summary information collapses hierarchy, solutionsfound intermediate levels, communication exponentially reduced manner.8. Related Workapproach taken abstract reasoning originally inspired earlier work involvinghierarchical behavior-space search agents represent planned behaviors multiplelevels abstraction (Durfee & Montgomery, 1991). Distributed protocols used decidelevel abstraction coordination needed resolve conflicts there. approach capitalizesdomains resources abstracted naturally. earlier work viewedlimited, special case work presented here. justified intuitively limitedexperiments analyses.Corkill studied interleaved planning merging distributed version NOAH planner(1979). recognized that, conditions affected abstract plan operatormight unknown refinement, deal overall effects preconditionshold matter operator refined captured used identify resolveconflicts. recognized choices refinement synchronization choicesabstract levels could lead unresolvable conflicts deeper levels, backtracking couldnecessary. work directed toward avoiding backtracking using summary informationguide search.502fiA BSTRACT R EASONING P LANNING C OORDINATIONcloser relation approach, Pappachan shows interleave hierarchical plan coordination plan execution cooperative agents using online iterative constraint relaxation(OICR) algorithm (Pappachan, 2001). Like approach, coordination achieved higherlevels abstraction flexible execution, agents decompose tasks lowerlevels tighter coordination improve plan quality. OICR approach tailored towardinterleaving coordination flexible execution price completeness coordinationalgorithm presented aimed complete interleaved coordination planning pricepotentially delaying execution due backtracking.planning research, hierarchical plans often represented Hierarchical Task Networks (HTNs, Erol et al., 1994a), planners NOAH (Sacerdoti, 1977), NonLin (Tate,1977), SIPE-2 (Wilkins, 1990), O-Plan (Currie & Tate, 1991), UMCP (Erol et al., 1994b), SHOP 2(Nau, Au, Ilghami, Kuter, Murdock, Wu, & Yaman, 2003) use search combinationsalternative courses action achieve goals within particular context. actions may partially ordered, giving timing flexibility execution (Wilkins, 1990; Currie & Tate, 1991).CH P representation extends HTN include temporal extent partial orderings expressedconstraints starting ending timepoints action.Yang presented method (similar summarization) preprocessing plan hierarchyorder able detect unresolvable conflicts abstract level planner could backtrack inconsistent search spaces (Yang, 1990). corresponds use MightSomeWaySection 5.2. However, approach requires decomposition hierarchy modeledabstract operator unique main subaction preconditions effectsparent. avoid restriction analyzing subplans conditions ordering constraintsautomatically compute parents summary conditions.approach focused resolving conflicts among agents, Cox Durfee (2003)used summary information exploit synergistic interactions. idea using summary information identify overlapping effects help agents skip actions whose effectsachieved others. Thangarajah, Padgham, Winikoff (2003) used summary informationrescheduling execution. representations actually subsumed ours,work significantly postdates first reporting work paper (Clement & Durfee, 1999).DSIPE (desJardins & Wolverton, 1999) distributed version SIPE -2 (Wilkins, 1990)hierarchical planning system. way agents use summary information reducecommunication states common constraints, DSIPE filters conditionscommunicated among planners using irrelevance reasoning (Wolverton & desJardins, 1998).DPOCL (Decompositional Partial-Order Causal-Link) planner (Young et al., 1994) addsaction decomposition SNLP (McAllester & Rosenblitt, 1991). Like HTN planners, preconditions high level effects added abstract tasks order help planner resolveconflicts decomposition. addition, causal links specified decomposition schemasisolate external preconditions DPOCL must satisfy. However, conditionscausal links necessarily capture external conditions abstract tasks, plannerfind solutions abstract levels requires tasks completely decomposed. addition, DPOCL cannot determine abstract plan unresolvable conflicts (MightSomeWay)may effects hidden decompositions yet undetailed tasks could achieveopen preconditions. deriving summary conditions automatically using algorithms determining causal link information (e.g. must-achieve), planning/coordination algorithm find503fiC LEMENT, URFEE , & BARRETTreject abstract plans search without adding burden domain expert specify redundant conditions causal links abstract tasks.Like DPOCL, TMS (a framework Task Analysis, Environment Modeling, Simulation)allows domain modeler specify wide range task relationships (Decker, 1995).work offers quantitative methods analyzing simulating agents well interactions.interactions represented discovered using summary conditions,discover information analysis rather depending model developerpredefine interactions.Groszs shared plans model collaboration (1996) presents theory modeling multiagentbelief intention. shared plans work directed toward cooperative agents, representsaction hierarchies provides mental models higher level represented article.However, use analysis summary information complements Groszs work providingway automatically represent efficiently reason intentions agents multiple levelsabstraction. Future work needed understand summary information bridgedmental states agents exploit techniques employed shared plans work basedBDI (belief-desire-intention) models agents (Rao & Georgeff, 1995).analysis hierarchical planning (Yang, 1997) explains that, case interacting subgoals, certain structures hierarchy minimize interactions reduce worst caseplanning complexity exponentially. However, complexity analyses Section 6 explain using summary information achieve exponential performance gains addition achievedrestructuring plan hierarchies according Yangs analysis limiting decomposition taskhierarchies compressing information manipulated coordinator, planner, scheduler.SHOP 2 (Nau et al., 2003) HTN planner uses domain translation technique reasondurative action. however express temporal extent way plannergiven here. model differs supports ordering relationships endpoints wellconditions effects actions execution. may domain translationcould achieve expression similar constraints solutions systems,formal model expressions HTN planning.SIADEX (Castillo et al., 2006) another HTN planner handles temporal extent useexpressive simple temporal networks (Dechter, Meiri, & Pearl, 1991). performanceimprovement techniques reported SIADEX temporal reasoning specific HTNs.Thus, work complementary ours. However, work needed understandsummary information exploited conjunction forward expansion approachSHOP 2 SIADEX use perform competitively planning competition problems.Another class hierarchical planners based ABSTRIPS (Sacerdoti, 1974) introduces conditions different levels abstraction critical conflicts handled higher levelsabstraction less important (or easier) conflicts resolved later lower levels.approach similarly resolves conflicts abstract levels, planning decisions may consistentconditions lower levels resulting backtracking. Summary information provides meansmake sound complete decisions abstract levels without need decompose checkconsistency lower levels. However, resolving conflicts based criticality still improveperformance complement approach.Allens temporal planner (1991) uses hierarchical representations tasks could appliedreasoning concurrent actions multiple agents. However, exploit hierarchyreasoning abstraction levels separately generates plan proving consistency504fiA BSTRACT R EASONING P LANNING C OORDINATIONcollective constraints. Allens model temporal plans (1983) subsequent work intervalpoint algebra (Vilain & Kautz, 1986) strongly influenced hierarchical task representationalgorithms reason them.also many, many models theories concurrency. older examples includeautomata representations, Petri nets Hoares theory communicating sequential processes(Glabbeek, 1997). also many temporal logics computational tree logic (CTL,Emerson & Halpern, 1985) allow modal expressions proposition holdingpossible worlds time, time, next state, eventually,proposition holds. Another language specifying manufacturing processes processstandardized 10 years (Bock, 1996; Schlenoff, Knutilla, & Ray, 2006). Manylogics could used define summary conditions relations like MightSomeWay. However, found logics awkward representing inconditions defining summaryconditions terminology used article simplifies definitions.Model checking uses temporal logics verify different properties system models, software,hardware (such correctness, deadlock-free, convergence). fact, model checkingplanning algorithms used interchangeably problems (e.g., Giunchiglia &Traverso, 1999). context model checking, summary information set properties(akin specifiable CTL) system model (as planning domain) summarize systemvariable requirements (conditions) assignments (effects). Thus, model checking algorithmcould use summary information efficiently identify resolve potential requirement violations/bugs (condition conflicts) deadlock (resource conflicts) system model operation(planning/scheduling problem instantiations).9. Conclusionarticle provides formalization Hierarchical Task Network planning that, unlike UMCPformalism (Erol et al., 1994b), includes actions temporal extent. introduce soundcomplete algorithm used generate plan, coordinate group agents hierarchical plans, interleave planning coordination.algorithms summarizing propositional state metric resource conditions effectsabstract levels mechanisms reason summary information facilitateconstruction planning coordination systems reason plans multiple levelsabstraction. mechanisms reasoning summary information determine whethertask (at level abstraction) must may achieve, clobber, undo condition another taskpartial order constraints endpoints tasks. Built mechanisms, mechanismsdetermine whether group agents decompose execute set partially ordered abstracttasks way (CanAnyWay), might decompose execute way (MightSomeWay),cannot execute consistently way (MightSomeWay).algorithms enable planning system find solutions multiple levels abstractionwithout needing fully detail task hierarchy. abstract solutions support flexible executionremaining uncommitted alternative methods selected runtime, basedcircumstances, achieve plan subgoals.complexity analyses experiments different problem domains quantified benefits using summary information refinement planning local search scheduling algorithm.potential doubly exponential speedup O(kb b b2(di) ) k ways resolve conflict,505fiC LEMENT, URFEE , & BARRETThierarchy branching factor b, depth hierarchy d, abstract solution depth i. exponential speedup obtained abstract solutions found, fewer summary conditionsabstract levels, alternative decomposition choices lead varying numbers threats.conditions exponential improvement significant relaxation compared prior work,performance improvement greater.domain modeler run summarization algorithms offline library plan hierarchiessummary information available coordination planning set goal taskssupported library. Using algorithms reasoning summary information, agentsdiscover coordinate states resources must coordinate/negotiate. Communicating summary information different levels abstraction reducescommunication costs exponentially conditions similar reducing computation time.use summary information local search planner (like ASPEN, Section 6.3) anothercontribution work. strength local search algorithms ability efficiently reasonlarge numbers tasks constraints metric resources, state variables, complexresource classes. integrating algorithms reasoning summarized propositional statemetric resource constraints heuristic local search planner/scheduler, enable scalableplanning systems scale even larger problem domains. use summary informationdifferent style planner demonstrates applicability abstract reasoning improvingperformance different kinds planning (and plan coordination) systems.Future work needed evaluate use summary information planningscheduling systems wider classes problems requiring expressive representationsresources temporal constraints. Already, approach exploiting cooperative actionamong agents based summary information developed (Cox & Durfee, 2003).promising approaches include abstracting plan information, probabilistic conditionseffects classes resources states (e.g. location regions sub-regions). workalso needed understand communicate summary information distributedplanning system.Acknowledgmentsauthors wish thank Pradeep Pappachan, Gregg Rabideau, Russell Knight helpimplementation. also thank anonymous reviewers many valuable suggestions.work performed Jet Propulsion Laboratory, California Institute Technology,contract National Aeronautics Space Administration, University Michigansupported part DARPA (F30602-98-2-0142).Appendix A: Algorithms Computing Interval Relationsalgorithms determining whether defined relations hold summary conditionsplans P use point algebra constraint table (Vilain & Kautz, 1986). point algebratable constructed interval endpoints corresponding executions plans P;row column p ts (e) (start endpoint execution e p) p+ f (e) (finishendpoint) added plan p P. cell table gives time point constraintrow column <, , =, , >, 6=, <=>, empty. <=> means506fiA BSTRACT R EASONING P LANNING C OORDINATIONpp+p0p0 +p=>>>p+<=<<p0<>=>p0 +<><=Table 1: Point algebra table p contains p0pp+p0p0 +p=>>p+<=<=><=>p0<=>=>p0 +<<=><=Table 2: Point algebra table p p0points unconstrained. cell empty, allowed temporal relations, indicatinginconsistency. Table 1 shows point algebra table plans p p0 constrainedps execution contains p0 . Table 2 shows table start p constrainedearlier start p0 . transitive closures constraint relations. Table 1computed Table 2 constraining p+ < p0 + (by putting < cell row p+column p0 + ) computing transitive closure, O(n2 ) algorithm n points (Vilain &Kautz, 1986). transitive closure computed, constraints pointpoint looked constant time.Similarly, constraints order P added table, transitive closurecomputed get constraints entailed order. needs doneP order determine achieve clobber relationships defined next section.determine plan q ps subplans temporally ordered always-[ f irst,last][q , q+ ] constrained [before, after] equal points point algebra tableps subplans. done looking entry row [q , q+ ] checking seeconstraint [<, >], =, [, ]. case, q not-always-[ f irst,last].q always-not-[ f irst,last] row [q , q+ ] entry [>, <]constraint; otherwise, sometimes-[ f irst,last].interval i0 covered set intervals = {i1 , i2 , . . . , ik } intervalfound intersects i0 intersects nothing I. particular covering problem describesintervals terms partial order endpoints, represent intervals point algebratable. algorithm covering problem check see i0 covered lookingpairs intervals see overlap. i0 covered (1) either intervals meet either+0 i0 , (2) intervals endpoint contained i0meet opposite endpoint another interval endpoint i0 , (3) intervalsoverlapping i0 . Otherwise, i0 covered. Examples given Figure 34.507fiC LEMENT, URFEE , & BARRETTa)==B=Cc)Eb)F=GHFigure 34: a) Interval covered B, C, D. b) E covered F, G, H. c)covered.Appendix B: Algorithms Must/May Asserting Summary Conditionsdescribe algorithms determining temporal plan relationships based summary information. used build algorithms determine whether plan must may achieve,clobber, undo condition another particular ordering constraints.definitions algorithms throughout section given within context setplans P corresponding set summary information Psum , set ordering constraints order,set histories H including histories E(h) includes execution eplan P es subexecutions, E(h) satisfies constraints order. concernedordering plan execution intervals timing conditions. themselves,anything whether conditions may need met must met planexecution.First, order determine whether abstract plan executions achieve, clobber, undoconditions others, agent needs able reason summary conditions assertedrequired met. Ultimately, agent needs able determine whether partial orderingabstract plans succeed, may case agents action fails assert summarycondition required action another agent. Therefore, formalize meansaction attempt assert summary condition require summary conditionmet. definitions rely linking summary condition plan CHiP conditionssummarizes subplans plans decompositions. Thus, first define meanssummary condition summarize conditions.Definition 14summary condition c summarizes condition ` condition set condsplan p iff c added procedure deriving summary informationsummary condition set p0 ; ` = `(c); either c added ` conditionset conds p = p0 , c added summary condition subplan p0summarizes ` conds p.example, at(bin1, A) precondition start move plan moving part bin1machine M1 (as given Section 2.2). deriving summary conditions start move,508fiA BSTRACT R EASONING P LANNING C OORDINATIONat(bin1, A) added summary preconditions. Thus, summary precondition at(bin1,A)MuF summarizes at(bin1, A) preconditions start move.Definition 15execution e p requires summary condition c met iff csummary condition ps summary information; condition ` conditionset conds p0 summarized c; f irst(c), = ts (e); last(c), = f (e);always(c), within (ts (e),t f (e)); sometimes(c), executionsubplan p d(e) requires summary condition c0 met t, c0summarizes ` conds p0 .So, basically, execution requires summary condition met whenever conditionssummarizes required. execution build G summary precondition at(A,M1 tray1).execution requires summary condition met ts (build G) at(A, M1 tray1)precondition build Gs first subplan summarized build Gs summary precondition.Definition 16execution e p attempts assert summary condition c iff csummary condition ps summary information; condition ` conditionset conds p0 summarized c; f irst(c); always(c), smallestinterval ts (e) start end execution follows ts (e);last(c), = f (e); sometimes(c), execution subplan p d(e)attempts assert summary condition c0 t; c0 summarizes ` conds p0 .say execution attempts assert summary condition asserting conditionfail due simultaneous assertion negation condition. Like examplerequiring summary condition, executions build G, produce G M1, produce Hassert summary postconditions M1 becomes available f (build G).order agents determine potential interactions among abstract plans (such clobbering achieving), need reason summary condition asserted one planrelation asserted required another. Based interval point algebra constraintsset abstract plans, agent specifically would need able determine whether planwould assert summary condition time another plan requires asserts summarycondition state variable. addition, reason clobbering inconditions, agentwould need determine summary condition would asserted time summary incondition c required (asserted c). Agents also need detect summary postconditionwould asserted time another summary postcondition c (asserted c).consider cases executions attempt assert summary in- postconditiontime incondition asserted cases, clobber relations alreadydetected executions always require summary inconditions attempt assert.example, equip M1 attempted assert incondition M1 unavailabletime build G attempted assert postcondition M1 available, incondition wouldclobbered postcondition.case ordering constraints allow alternative synchronizations abstractplans, assertions summary conditions may come different orders. Therefore, formalizemust-assert may-assert determine relationships must may occur respectively.mentioned beginning Section 9, use must may based disjunctive orderings existence summary conditions different decompositions.509fiC LEMENT, URFEE , & BARRETT12345678910111213141516171819c0 post(p0 )lastF?c0 in(p0 )alwaysFc0 post(p0 )lastFc0 in(p0 )alwaysFc0 post(p0 )lastFFc0 in(p0 )alwaysFFp0 must-assert c0 corder must imposeconstraintsp0 must-assert c0 corder must imposeconstraintsp0 + pp0 + pp0 + pp0 + pp0 + < pp0 + < pp0 + < pp0 + < pF?c in(p)always??p0 < pp0 pf alsep0 < pp0 pf alsep0 + pp0 + pp0 + pp0 + p??c post(p)lastFFp0 pf alsep0 < pf alsep0 + p+p0 + pp0 + p+p0 + pp0 + < p+p0 + pp0 + p+p0 + pFFp0 < p+p0 pf alsef alsep0 < p+p0 pf alsef alsec pre(p)f irstF??Table 3: Table must-assert by/before algorithmfollowing definitions algorithms must- may-assert, assume c c0 summaryconditions plans P.Definition 17p0 P must-assert c0 [by, before] c iff histories h He top-level execution E(h) p P requires c met t,e0 top-level execution p0 E(h), 0 e0 attempts assert c00 , [t 0 t, 0 < t].must-assert algorithm described Table 3. p0 must-assert c0 c iff order entailsrelationship given row corresponding type timing two conditions. Rowstable indicate timing summary conditions constraints order must dictatemust-assert true. F table indicate whether timing column truefalse condition. ? means timing doesnt matter condition case.example, row 9 says case c0 sometimes (last) postcondition p0 , cincondition p timing, order must require end p0 startp order p0 must-assert c0 time c asserted required.510fiA BSTRACT R EASONING P LANNING C OORDINATION123456789101112131415161718c0 post(p0 )lastFFc0 in(p0 )always??c0 post(p0 )lastFFc0 in(p0 )always??c0 post(p0 )lastFFc0 in(p0 )always??p0 may-assert c0 corder cannot imposeconstraintsp0 may-assert c0 corder cannot imposeconstraintsp0 + > pp0 + p+p0 pp0 p+p0 + pp0 + p+p0 pp0 p+Fc in(p)alwaysFFp0 pp0 p+p0 pp0 p+p0 + > pp0 + p+p0 pp0 p+p0 + > pp0 + p+p0 pp0 p+Fc post(p)lastFFp0 > pp0 p+p0 pp0 p+p0 + > p+p0 + p+p0 p+p0 p+p0 + p+p0 + p+p0 p+p0 p+Fp0 p+p0 p+p0 p+p0 p+c pre(p)f irstFFTable 4: Table may-assert by/before algorithm12345678c0 post(p0 )lastFFc0 in(p0 )alwaysFFp0 must-assert c0 corder must imposeconstraintsc in(p)alwaysFFp0 + > p p0 + < p+f alsep0 p p0 + p+f alseFFp0 p p0 < p+f alsef alsef alsec0 post(p0 )lastFFc0 in(p0 )alwaysFFc in(p)alwaysFFp0 + pp0 + pp0 + pp0 + pp0 + p+p0 + p+p0 p+p0 p+FFp0 + pp0 + pp0 + pp0 + pp0 p+p0 p+p0 p+p0 p+Table 5: Table must/may-assert algorithm511p0 may-assert c0 corder cannot imposeconstraintsfiC LEMENT, URFEE , & BARRETT1234c0 post(p0 )lastFFc post(p)lastFFp0 must-assert c0 corder must imposeconstraintsp0 + = p+f alsef alsef alsec0 post(p0 )lastFFc post(p)lastFFp0 may-assert c0 corder cannot imposeconstraintsp0 + 6= p+p p0 + p+p0 + p+ p0 p+p0 + p p0 p+p0 +Table 6: Table must/may-assert algorithmdefinitions algorithms assert relationships similar. Tables 4-6 describelogic algorithms. may relationships, algorithm returns true iff nonecorresponding ordering constraints table imposed (can deduced from) order.illustrate relationships example Figure 8. Figure 8a agents plansunordered respect other. Part G produced either machine M1 M2 depending potential decompositions produce G plan. produce G must-assert c0 = must,last available(G) c = must, f irst available(G) summary preconditions move Gmatter plans decomposed (for executions histories plansordering constraints figure), execution produce G attempts assert c0 execution move G requires c met. algorithm verifies findingend produce G ordered start move G (row 1 Table 3). also caseequip M2 tool may-assert c0 = must, last available(M2) c = may, sometimes available(M2)summary preconditions produce G two plans unordered respectother, history equip M2 tool precede produce G. algorithm findstrue since equip M2 constrained start start produce G (row 2 Table 4).Figure 8b, move tool may-assert c0 = must, last f ree(transport1) c = may, sometimesf ree(transport1) produce Gs summary inconditions history move tool attempts assert c0 time produce G using transport1 move part machineM2. addition, equip M2 tool must-assert c0 = must, last available(M2) c = may, lastavailable(M2) produce Gs summary postconditions equip M2 tool attempts assertc0 time produce G requires c met. end Section 3.3 gives examples.ReferencesAllen, J., Kautz, H., Pelavin, R., & Tenenberg, J. (1991). Reasoning plans. Morgan Kaufmann.Allen, J. F. (1983). Maintaining knowledge temporal intervals. Communications ACM,26(11), 832843.Allen, J. F., & Koomen, J. A. (1983). Planning using temporal world model. ProceedingsInternational Joint Conference Artificial Intelligence, pp. 741747.Bock, C. (1996). Unified process specification language: Requirements modeling process. Tech.rep. NISTIR 5910, National Institute Standards Technology.Castillo, L., Fdez-Olivares, J., Garca-Perez, O., & Palao, F. (2006). Efficiently handling temporalknowledge HTN planner. 16th International Conference Automated Planning512fiA BSTRACT R EASONING P LANNING C OORDINATIONScheduling (ICAPS-06), pp. 6372. AAAI.Chien, S., Knight, R., Stechert, A., Sherwood, R., & Rabideau, G. (2000a). Using iterative repairimprove responsiveness planning scheduling. Proceedings InternationalConference AI Planning Scheduling, pp. 300307.Chien, S., Rabideu, G., Knight, R., Sherwood, R., Engelhardt, B., Mutz, D., Estlin, T., Smith, B.,Fisher, F., Barrett, T., Stebbins, G., & Tran, D. (2000b). Automating space mission operationsusing automated planning scheduling. Proc. SpaceOps.Clement, B. (2002). Abstract Reasoning Multiagent Coordination Planning. Ph.D. thesis,University Michigan, Ann Arbor.Clement, B., & Durfee, E. (1999). Top-down search coordinating hierarchical plansmultiple agents. Proceedings International Conference Autonomous Agents.Corkill, D. (1979). Hierarchical planning distributed environment. ProceedingsInternational Joint Conference Artificial Intelligence, pp. 168175.Cox, J. S., & Durfee, E. H. (2003). Discovering exploiting synergy hierarchical planning agents. Proceedings International Joint Conference Autonomous AgentsMultiAgent Systems, pp. 281288.Currie, K., & Tate, A. (1991). O-Plan: open planning architecture. Artificial Intelligence, 52,4986.Dechter, R., Meiri, I., & Pearl, J. (1991). Temporal constraint networks. Artificial Intelligence, 49,6195.Decker, K. (1995). Environment centered analysis design coordination mechanisms. Ph.D.thesis, University Massachusetts.desJardins, M., & Wolverton, M. (1999). Coordinating distributed planning system. AI Magazine,20(4), 4553.Drabble, B., & Tate, A. (1994). use optimistic pessimistic resource profiles informsearch activity based planner. Artificial Intelligence Planning Systems, pp. 243248.Durfee, E. H., & Montgomery, T. A. (1991). Coordination distributed search hierarchicalbehavior space. IEEE Transactions Systems, Man Cybernetics, 21(6), 13631378.Emerson, E., & Halpern, J. Y. (1985). Decision procedures expressiveness temporal logicbranching time. Journal Computer System Sciences, 30(1), 124.Ephrati, E., & Rosenschein, J. (1994). Divide conquer multi-agent planning. ProceedingsNational Conference Artificial Intelligence, pp. 375380.Erol, K., Hendler, J., & Nau, D. (1994a). Semantics hierarchical task-network planning. Tech.rep. CS-TR-3239, University Maryland.Erol, K., Nau, D., & Hendler, J. (1994b). UMCP: sound complete planning procedurehierarchical task-network planning.. Proceedings International Conference AIPlanning Scheduling.Fagin, R., Halpern, J., Moses, Y., & Vardi, M. (1995). Reasoning knowledge. MIT Press.Firby, J. (1989). Adaptive Execution Complex Dynamic Domains. Ph.D. thesis, Yale University.513fiC LEMENT, URFEE , & BARRETTGeorgeff, M. P. (1983). Communication interaction multiagent planning. ProceedingsNational Conference Artificial Intelligence, pp. 125129.Georgeff, M. P. (1984). theory action multiagent planning. Proceedings NationalConference Artificial Intelligence, pp. 121125.Georgeff, M. P., & Lansky, A. (1986). Procedural knowledge. Proceedings IEEE, 74(10), 13831398.Giunchiglia, F., & Traverso, P. (1999). Planning model checking. Proceedings 5thEuropean Conference Planning, pp. 120, London, UK. Springer-Verlag.Glabbeek, R. v. (1997). Notes methodology CCS CSP. Theoretical Computer Science,177(2), 329349. Originally appeared Report CS-R8624, CWI, Amsterdam, 1986.Grosz, B., & Kraus, S. (1996). Collaborative plans complex group action. Artificial Intelligence,86, 269358.Huber, M. (1999). JAM: BDI-theoretic mobile agent architecture. Proceedings International Conference Autonomous Agents, pp. 236243.Knight, R., Rabideau, G., & Chien, S. (2000). Computing valid intervals collections activities shared states resources. Proceedings International Conference AIPlanning Scheduling, pp. 600610.Knoblock, C. (1991). Search reduction hierarchical problem solving. ProceedingsNational Conference Artificial Intelligence, pp. 686691.Korf, R. (1987). Planning search: quantitative approach. Artificial Intelligence, 33, 6588.Laborie, P., & Ghallab, M. (1995). Planning sharable resource constraints. ProceedingsInternational Joint Conference Artificial Intelligence, pp. 16431649.Lansky, A. (1990). Localized search controlling automated reasoning. ProceedingsDARPA Workshop Innovative Approaches Planning, Scheduling Control, pp. 115125.Lee, J., Huber, M. J., Durfee, E. H., & Kenny, P. G. (1994). UMPRS: implementationprocedural reasoning system multirobot applications. Proceedings AIAA/NASAConference Intelligent Robotics Field, Factory, Service, Space, pp. 842849.McAllester, D., & Rosenblitt, D. (1991). Systematic nonlinear planning. ProceedingsNational Conference Artificial Intelligence, pp. 634639.Muscettola, N. (1994). HSTS: Integrating planning scheduling. Intelligent Scheduling, 169212.Nau, D., Au, T., Ilghami, O., Kuter, U., Murdock, J., Wu, D., & Yaman, F. (2003). SHOP2:HTN planning system. Journal Artificial Intelligence Research, 20, 379404.Pappachan, P. (2001). Coordinating Plan Execution Dynamic Multiagent Environments. Ph.D.thesis, University Michigan, Ann Arbor.Pratt, V. R. (1976). Semantical considerations floyd-hoare logic. 17th Annual IEEE Symposium Foundations Computer Science, pp. 109121.Rao, A. S., & Georgeff, M. P. (1995). BDI-agents: theory practice. ProceedingsInternational Conference Multi-Agent Systems, San Francisco.514fiA BSTRACT R EASONING P LANNING C OORDINATIONSacerdoti, E. (1974). Planning hierarchy abstraction spaces. Artificial Intelligence, 5(2),115135.Sacerdoti, E. D. (1977). Structure Plans Behavior. Elsevier-North Holland.Schlenoff, C., Knutilla, A., & Ray, S. (2006). Interprocess communication process specification language. Tech. rep. NISTIR 7348, National Institute Standards Technology.Tate, A. (1977). Generating project networks. Proceedings International Joint ConferenceArtificial Intelligence, pp. 888893.Thangarajah, J., Padgham, L., & Winikoff, M. (2003). Detecting & avoiding interferencegoals intelligent agents. Proceedings International Joint Conference ArtificialIntelligence, pp. 721726.Tsuneto, R., Hendler, J., & Nau, D. (1997). Space-size minimization refinement planning.Proceedings European Conference Planning.Tsuneto, R., Hendler, J., & Nau, D. (1998). Analyzing external conditions improve efficiencyHTN planning. Proceedings National Conference Artificial Intelligence, pp.913920.Vilain, & Kautz, H. (1986). Constraint propagation algorithms temporal reasoning. Proceedings National Conference Artificial Intelligence, pp. 377382.Weld, D. (1994). introduction least commitment planning. AI Magazine, 15(4), 2761.Wilkins, D. E. (1990). AI planners solve practical problems?. Computational Intelligence,6(4), 232246.Wolverton, M., & desJardins, M. (1998). Controlling communication distributed planning usingirrelevance reasoning. Proceedings National Conference Artificial Intelligence,pp. 868874.Yang, Q. (1990). Formalizing planning knowledge hierarchical planning. Computational Intelligence, 6(1), 1224.Yang, Q. (Ed.). (1997). Intelligent Planning: Decomposition Abstraction Based Approach.Springer.Young, M., Pollack, M., & Moore, J. (1994). Decomposition causality partial-order planning.Proceedings International Conference AI Planning Scheduling, pp. 188193.515fiJournal Artificial Intelligence Research 28 (2007) 1-48Submitted 4/06; published 1/07Cutset Sampling Bayesian NetworksBozhena BidyukRina Dechterbbidyuk@ics.uci.edudechter@ics.uci.eduSchool Information Computer ScienceUniversity California IrvineIrvine, CA 92697-3425Abstractpaper presents new sampling methodology Bayesian networks samplessubset variables applies exact inference rest. Cutset samplingnetwork structure-exploiting application Rao-Blackwellisation principle samplingBayesian networks. improves convergence exploiting memory-based inference algorithms. also viewed anytime approximation exact cutset-conditioningalgorithm developed Pearl. Cutset sampling implemented efficientlysampled variables constitute loop-cutset Bayesian network and, generally,induced width networks graph conditioned observed sampled variables bounded constant w. demonstrate empirically benefit schemerange benchmarks.1. IntroductionSampling common method approximate inference Bayesian networks.exact algorithms impractical due prohibitive time memory demands, oftenfeasible approach offers performance guarantees. Given Bayesian networkvariables X = {X1 , ..., Xn }, evidence e, set samples {x(t) } P (X|e),estimate f(X) expected value function f (X) obtained generatedsamples via ergodic average:1Xf (x(t) ) ,(1)E[f (X)|e] f(X) =number samples. f(X) shown converge exact valueincreases. central query interest Bayesian networks computing posteriormarginals P (xi |e) value xi variable Xi , also called belief updating.query, f (X) equals -function, equation reduces counting fractionoccurrences Xi = xi samples,P (xi |e) =(t)1X(xi |x(t) ) ,(2)t=1(xi |x(t) )=1 iff xi = xi (xi |x(t) )=0 otherwise. Alternatively, mixture estimator used,1X(t)P (xi |xi ) ,(3)P (xi |e)] =t=1c2007AI Access Foundation. rights reserved.fiBidyuk & Dechter(t)xi = x(t) \xi .significant limitation sampling, however, statistical variance increasesnumber variables network grows therefore number samplesnecessary accurate estimation increases. paper, present sampling schemeBayesian networks discrete variables reduces sampling variance samplingsubset variables, technique also known collapsing Rao-Blackwellisation.fundamentals Rao-Blackwellised sampling developed Casella Robert(1996) Liu, Wong, Kong (1994) Gibbs sampling MacEachern, Clyde,Liu (1998) Doucet, Gordon, Krishnamurthy (1999) importance sampling.Doucet, de Freitas, Murphy, Russell (2000) extended Rao-Blackwellisation ParticleFiltering Dynamic Bayesian networks.basic Rao-Blackwellisation scheme described follows. Suppose partition space variables X two subsets C Z. Subsequently, re-writefunction f (X) f (C, Z). generate samples distribution P (C|e) compute E[f (C, Z)|c, e], perform sampling subset C only, generating samplesc(1) , c(2) , ..., c(T ) approximating quantity interestE[f (C, Z)|e] = EC [EZ [f (C, Z)|c, e]] f(X) =1XEZ [f (C, Z)|c(t) , e] .(4)t=1posterior marginals estimates cutset variables obtained using expression similar Eq.(2),1X(ci |c(t) ) ,(5)P (ci |e) =using mixture estimator similar Eq.(3),P (ci |e) =1X(t)P (ci |ci , e) .(6)Xi X\C, E, E[P (Xi |e)] = EC [P (Xi |c, e)] Eq.(4) becomesP (Xi |e) =1XP (Xi |c(t) , e) .(7)Since convergence rate Gibbs sampler tied maximum correlationtwo samples (Liu, 2001), expect improvement convergence ratesampling lower dimensional space since 1) highly-correlated variables maymarginalized 2) dependencies variables inside smaller set likelyweaker variables farther apart sampling distributionssmoothed out. Additionally, estimates obtained sampling lower dimensionalspace expected lower sampling variance therefore require fewer samplesachieve accuracy estimates. hand, cost generatingsample may increase. Indeed, principles Rao-Blackwellised samplingapplied classes probabilistic models specialized structure (Kong, Liu,& Wong, 1994; Escobar, 1994; MacEachern, 1994; Liu, 1996; Doucet & Andrieu, 2001;Andrieu, de Freitas, & Doucet, 2002; Rosti & Gales, 2004).2fiCutset Sampling Bayesian Networkscontribution paper presenting general, structure-based schemeapplies Rao-Blackwellisation principle Bayesian networks. idea exploitproperty conditioning subset variables simplifies networks structure, allowing efficient query processing exact algorithms. general, exact inference variableelimination (Dechter, 1999a, 2003) join-tree algorithms (Lauritzen & Spiegelhalter, 1988;Jensen, Lauritzen, & Olesen, 1990) time space exponential induced-width wnetwork. However, subset variables assigned (i.e., conditioned upon)induced-width conditioned network may reduced.idea cutset sampling choose subset variables C conditioningC yields sparse enough Bayesian network small induced width allow exactinference. Since sample assignment cutset variables, efficiently generatenew sample cutset variables conditioned network computationP (c|e) P (Xi |c, e) bounded. particular, sampling set C cuts cyclesnetwork (i.e., loop-cutset), inference conditioned network becomeslinear. general, C w-cutset, namely subset nodes assigned,induced-width conditioned network w, time space complexity computingnext sample O(|C| N dw+2 ) maximum domain size N = |X|.idea exploiting properties conditioning subset variables first proposed exact belief updating context cutset-conditioning (Pearl, 1988).scheme requires enumerating instantiations cutset variables. Since numberinstances exponential size cutset |C|, sampling cutset space mayright compromise size cutset big. Thus, sampling cutsetalso viewed anytime approximation cutset-conditioning approach.Although Rao-Blackwellisation general cutset sampling particular applied context sampling algorithm, introduce principle context Gibbs sampling (Geman & Geman, 1984; Gilks, Richardson, & Spiegelhalter, 1996;MacKay, 1996), Markov Chain Monte Carlo sampling method Bayesian networks.Extension sampling approach graphical models, Markovnetworks, straight forward. recently demonstrated idea incorporated importance sampling (Bidyuk & Dechter, 2006).paper defines analyzes cutset sampling scheme investigates empiricallytrade-offs sampling exact computation variety randomly generatednetworks grid structure networks well known real-life benchmarks CPCSnetworks coding networks. show cutset sampling converges faster puresampling terms number samples, dictated theory, also almost alwaystime-wise cost effective benchmarks tried. also demonstrate applicabilityscheme deterministic networks, Hailfinder network coding networks,Markov Chain non-ergodic Gibbs sampling converge.Section 2 provides background information. Specifically, section 2.1 introduces Bayesiannetworks, section 2.2 reviews exact inference algorithms Bayesian networks, section 2.3 provides background Gibbs sampling. contribution paper presentingcutset sampling starts section 3. Section 4 presents empirical evaluation cutsetsampling. also present empirical evaluation sampling variance resulting standard error based method batch means (for details, see Geyer, 1992).3fiBidyuk & Dechtersection 5, review previous application Rao-Blackwellisation section 6 providessummary conclusions.2. Backgroundsection, define essential terminology provide background informationBayesian networks.2.1 Preliminariesuse upper case letters without subscripts, X, denote sets variableslower case letters without subscripts denote instantiation group variables (e.g.,x indicates variable set X assigned value). use upper case lettersubscript, Xi , denote single variable lower case lettersubscript, xi , denote instantiated variable (e.g., xi denotes arbitrary valuedomain Xi means Xi = xi ). D(Xi ) denotes domain variable Xi .superscript subscripted lower case letter would used distinguish different specificvalues variable, i.e., D(Xi ) = {x1i , x2i , ...}. use x denote instantiationset variables x = {x1 , ..., xi1 , xi , xi+1 , ..., xn } xi = x\xi denote x elementxi removed. Namely, xi = {x1 , x2 , ..., xi1 , xi+1 , ..., xn }.Definition 2.1 (graph concepts) directed graph pair D=<V ,E>, V ={X1 , ..., Xn } set nodes E = {(Xi , Xj )|Xi , Xj V } set edges. Given(Xi , Xj ) E, Xi called parent Xj , Xj called child Xi . setXi parents denoted pa(Xi ), pai , set Xi children denoted ch(Xi ),chi . family Xi includes Xi parents. moral graph directed graphundirected graph obtained connecting parents nodesremoving arrows. cycle-cutset undirected graph subset nodes that,removed, yields graph without cycles. loop directed graph subgraphwhose underlying graph cycle. directed graph acyclic directed loops.directed graph singly-connected (also called poly-tree), underlying undirectedgraph cycles. Otherwise, called multiply-connected.Definition 2.2 (loop-cutset) vertex v sink respect loop L twoedges adjacent v L directed v. vertex sink respectloop L called allowed vertex respect L. loop-cutset directed graphset vertices contains least one allowed vertex respect loop D.Definition 2.3 (Belief Networks) Let X = {X1 , ..., Xn } set random variablesmulti-valued domains D(X1 ), ..., D(Xn ). belief network (BN) (Pearl, 1988)pair <G, P > G directed acyclic graph whose nodes variables XP = {P (Xi |pai )|i = 1, ..., n} set conditional probability tables (CPTs) associatedXi . BN represents joint probability distribution product form:P (x1 , ...., xn ) =ni=1P (xi |pa(Xi ))evidence e instantiated subset variables E X.4fiCutset Sampling Bayesian Networksstructure directed acyclic graph G reflects dependenciesvariables using d-separation criterion. parents variable Xi together childrenparents children form Markov blanket, denoted markovi , node Xi .use xmarkovi denote x restricted variables markovi . know nodeXi independent rest variables conditioned Markov blanket. Namely,P (xi |xi ) = P (xi |xmarkovi ).common query belief networks belief updating taskcomputing posterior distribution P (Xi |e) given evidence e query variable XiX. Reasoning Bayesian networks NP-hard (Cooper, 1990). Finding approximateposterior marginals fixed accuracy also NP-hard (Dagum & Luby, 1993; Abdelbar& Hedetniemi, 1998). network poly-tree, belief updating inferencetasks accomplished time linear size input. general, exact inferenceexponential induced width networks moral graph.Definition 2.4 (induced-width) width node ordered undirected graphnumber nodes neighbors precede ordering. widthordering d, denoted w(d), maximum width nodes. induced widthordered graph, w (d), width ordered graph obtained processingnodes last first follows: node X processed, preceding neighborsconnected. resulting graph called induced graph triangulated graph.task finding minimal induced width graph (over possible orderings)NP-complete (Arnborg, 1985).2.2 Reasoning Bayesian NetworksBelief propagation algorithm, introduce Section 2.2.2 below, performs beliefupdating singly-connected Bayesian networks time linear size input(Pearl, 1988). loopy networks, two main approaches belief updating cutsetconditioning tree clustering. algorithms often referred inferencealgorithms. briefly describe idea clustering algorithms Section 2.2.1conditioning method Section 2.2.3.2.2.1 Variable Elimination Join-Tree Clustering (JTC)join-tree clustering approach (JTC) refers family algorithms including jointree propagation (Lauritzen & Spiegelhalter, 1988; Jensen et al., 1990) bucket-treeelimination (Dechter, 2003, 1999a). idea first obtain tree-decompositionnetwork clusters functions connected tree propagate messagesclusters tree. tree-decomposition singly-connected undirectedgraph whose nodes, also called clusters, contain subsets variables input functionsdefined variables. tree-decomposition must contain functionsatisfy running intersection property (Maier, 1983). unifying perspective treedecomposition schemes see (Zhang & Poole, 1994; Dechter, 1999b; Kask, Dechter, Larrosa,& Dechter, 2005).Given tree-decomposition network, message propagation treesynchronized. select one cluster root tree propagate messages5fiBidyuk & Dechtertree. message cluster Vi neighbor Vj functionseparator set Vi Vj marginalization product functions Vimessages Vi received neighbors besides Vj . Assuming maximumnumber variables cluster w + 1 maximum domain size d, timespace required process one cluster O(d(w+1) ). Since maximum number clustersbounded |X| = N , complexity variable-elimination algorithms cluster-treepropagation schemes O(N d(w+1) ). parameter w, maximum cluster size minus1, called tree-width tree decomposition. minimal tree-width identicalminimal induced width graph.2.2.2 Iterative Belief Propagation (IBP)Belief propagation (BP) iterative message-passing algorithm performs exact inference singly-connected Bayesian networks (Pearl, 1988). iteration, every node Xisends j (Xi ) message child j receives j (Xi ) message child.message-passing order organized converges two iterations. essencealgorithm join-tree clustering approach applied directly poly-tree.Applied Bayesian networks loops, algorithm usually iterates longer (until mayconverge) hence, known Iterative Belief Propagation (IBP) loopy belief propagation. IBP provides guarantees convergence quality approximate posteriormarginals shown perform well practice (Rish, Kask, & Dechter, 1998; Murphy,Weiss, & Jordan, 1999). considered best algorithm inference coding networks(Frey & MacKay, 1997; Kschischang & Frey, 1998) finding probable variablevalues equals decoding process (McEliece, MacKay, & Cheng, 1997). Algorithm IBPrequires linear space usually converges fast converges. benchmarks, IBPconverged within 25 iterations less (see Section 4).2.2.3 Cutset Conditioningtree-width w Bayesian network large requirements inferenceschemes bucket elimination join-tree clustering (JTC) exceed available memory,switch alternative cutset conditioning schemes (Pearl, 1988; Peot & Shachter,1992; Shachter, Andersen, & Solovitz, 1994). idea cutset conditioning selectsubset variables C X\E, cutset, obtain posterior marginals nodeXi X\C, E using:XP (xi |e) =P (xi |c, e)P (c|e)(8)cD(C)Eq.(8) implies enumerate instantiations C, perform exact inference cutset instantiation c obtain P (xi |c, e) P (c|e) sumresults. total computation time exponential size cutsetenumerate instantiations cutset variables.C loop-cutset, then, nodes C assigned, Bayesian networktransformed equivalent poly-tree P (xi |c, e) P (c|e) computed viaBP time space linear size network. example, subset {A, D}loop-cutset belief network shown Figure 1, left, evidence E = e. right,6fiCutset Sampling Bayesian NetworksBCFEGBCFEGFigure 1: nodes loopy Bayesian network (left) instantiated,network transformed equivalent singly-connected network (right).transformation process, replica observed node createdchild node.Figure 1 shows equivalent singly-connected network resulting assigning valuesD.well-known minimum induced width w network always lesssize smallest loop-cutset (Bertele & Brioschi, 1972; Dechter, 2003). Namely,w + 1 |C| C. Thus, inference approaches (e.g., bucket elimination) neverworse often better cutset conditioning time-wise. However, wlarge must resort cutset conditioning search order trade space time.considerations yield hybrid search inference approach. Since observed variablesbreak dependencies network, network observed subset variablesC often transformed equivalent network smaller induced width, wC ,term adjusted induced width. Hence, subset variables C Xobserved, complexity bounded exponentially adjusted induced widthgraph wC .Definition 2.5 (adjusted induced width) Given graph G=<X,E>, adjustedinduced width G relative C, denoted wC , induced width C removedmoral graph.Definition 2.6 (w-cutset) Given graph G=<X,E>, subset nodes C Xw-cutset G adjusted induced width equals w.C w-cutset, quantities P (xi |c, e) P (c|e) computed timespace exponential w, much smaller tree-width unconditionednetwork. resulting scheme requires memory exponential w time O(d|C| N d(w+1) )N size network maximum domain size. Thus, performancetuned available system memory resource via bounding parameter w.Given constant w, finding minimal w-cutset (to minimize cutset conditioningtime) also hard problem. Several greedy heuristic approaches proposedGeiger Fishelson (2003) Bidyuk Dechter (2003, 2004). elaborateSection 3.5.7fiBidyuk & Dechter2.3 Gibbs SamplingSince complexity inference algorithms memory exponential networks inducedwidth (or tree-width) since resorting cutset-conditioning scheme may takemuch time w-cutset size large, must often resort approximationmethods. Sampling methods Bayesian networks commonly used approximationtechniques. section provides background Gibbs sampling, Markov Chain MonteCarlo method, one popular sampling schemes focuspaper. Although method may applied networks continuous distributions,limit attention paper discrete random variables finite domains.2.3.1 Gibbs Sampling Bayesian NetworksOrdered Gibbs SamplerInput: belief network B X={X1 , ..., Xn } evidence e={(Xi = ei )|Xi E X}.Output: set samples {x(t) }, = 1...T .(0)1. Initialize: Assign random value xi variable Xi X\E D(Xi ). Assignevidence variables observed values.2. Generate samples:= 1 T, generate new sample x(t) :(t)= 1 N, compute new value xi variable Xi :(t)(t)(t)Compute distribution P (Xi |xmarkovi ) sample xi P (Xi |xmarkovi ).(t)Set Xi = xi .EndEndFigure 2: Gibbs sampling AlgorithmGiven Bayesian network variables X = {X1 , ..., Xn }, evidence e, Gibbssampling (Geman & Geman, 1984; Gilks et al., 1996; MacKay, 1996) generates set(t)(t)samples {x(t) } sample x(t) = {x1 , ..., xn } instantiation variables.(t)superscript denotes sample index xi value Xi sample t. first(t)sample initialized random. generating new sample sample xi ,(t)new value variable Xi sampled probability distribution P (Xi |xi ) (recall(t)(t+1)P (Xi |xi ) = P (Xi |x1(t+1)(t+1)(t)(t)(t), ..., xi1 , xi+1 , ..., xn )) denote xi P (Xi |xi ).(t)next sample xigenerated previous sample xi following one twoschemes.Random Scan Gibbs Sampling. Given sample x(t) iteration t, pick variable(t)Xi random sample new value xi conditional distribution xi P (Xi |xi )leaving variables unchanged.Systematic Scan (Ordered) Gibbs Sampling. Given sample x(t) , sample newvalue variable order:(t)(t)x1 P (X1 |x2 , x3 , ..., x(t)n )8fiCutset Sampling Bayesian Networks(t+1)x2 P (X2 |x1(t), x3 , ..., x(t)n )...(t+1)xi P (Xi |x1(t+1)(t), ..., xi1 , xi+1 , ..., x(t)n )...(t+1)xn P (Xn |x1(t+1), x2(t+1), ..., xn1 )(t)Bayesian networks, conditional distribution P (Xi |xi ) dependent(t)(t)assignment Markov blanket variable Xi . Thus, P (Xi |xi )=P (Xi |xmarkovi )(t)xmarkovi restriction x(t) markovi . Given Markov blanket Xi , samplingprobability distribution given explicitly Pearl (1988):(t)(t)P (xj |x(t)(9)P (xi |xmarkovi ) = P (xi |x(t))paj )pai{j|Xj chj }Thus, generating complete new sample done O(n r) multiplication stepsr maximum family size n number variables.sequence samples x(1) , x(2) , ... viewed sequence states Markov(t+1)(t+1) (t) (t)(t)chain. transition probability state {x1, ..., xi1 , xi , xi+1 , ..., xn } state(t+1)(t+1)(t+1)(t)(t)(t){x1, ..., xi1 , xi, xi+1 , ..., xn } defined sampling distribution P (Xi |xi ).construction, Markov chain induced Gibbs sampling invariant distributionP (X|e). However, since values assigned Gibbs sampler variables samplex(t+1) depend assignment values previous sample x(t) , followssample x(n) depends initial state x(0) . convergence Markov chaindefined rate distance distribution P (x(n) |x(0) , e)stationary distribution P (X|e) (i.e., variational distance, L1 -distance, 2 ) converges 0function n. Intuitively, reflects quickly inital state x(0) forgotten.convergence guaranteed Markov chain ergodic (Pearl, 1988; Gelfand& Smith, 1990; MacKay, 1996). Markov chain finite number states ergodicaperiodic irreducible (Liu, 2001). Markov chain aperiodicregular loops. Markov chain irreducible get state Si stateSj (including Si ) non-zero probability finite number steps. irreducibilityguarantees able visit (as number samples increases) statisticallyimportant regions state space. Bayesian networks, conditions almost alwayssatisfied long conditional probabilities positive (Tierney, 1994).ensure collected samples drawn distribution close P (X|e),burn-in time may allocated. Namely, assuming takes K samplesMarkov chain get close stationary distribution, first K samples may included computation posterior marginals. However, determining K hard (Jones& Hobert, 2001). general, burn-in optional sense convergenceestimates correct posterior marginals depend it. completenesssake, algorithm given Figure 2.Pconvergence conditions satisfied, ergodic average fT (X) = T1 f (xt )function f (X) guaranteed converge expected value E[f (X)] increases.9fiBidyuk & Dechterwords, |fT (X) E[f (X)]| 0 . finite-state Markov chainirreducible aperiodic, following result applies (see Liu, 2001, Theorem 12.7.2):|fT (X) E[f (X)]| N (0, (f )2 )(10)initial assignment x(0) . variance term (f )2 defined follows:(f )2 = 2 (f ) 22 = var[f (X)] (h) integrated autocorrelation time.focus computing posterior marginals P (Xi |e) Xi X\E.posterior marginals estimated using either histogram estimator:P (Xi = xi |e) =1X(xi |x(t) )P (Xi = xi |e) =1X(t)P (xi |xi )mixture estimator:(11)t=1(12)t=1histogram estimator corresponds counting samples Xi = xi , namely (xi |x(t) ) =(t)1 xi = xi equals 0 otherwise. Gelfand Smith (1990) pointed sincemixture estimator based estimating conditional expectation, sampling variancesmaller due Rao-Blackwell theorem. Thus, mixture estimator preferred.(t)(t)Since P (xi |xi ) = P (xi |xmarkovi ), mixture estimator simply average conditionalprobabilities:1X(t)P (xi |e) =P (xi |xmarkovi )(13)t=1mentioned above, Markov chain ergodic, P (Xi |e) converge exactposterior marginal P (Xi |e) number samples increases. shown RobertsSahu (1997) random scan Gibbs sampler expected converge fastersystematic scan Gibbs sampler. Ultimately, convergence rate Gibbs sampler dependscorrelation two consecutive samples (Liu, 1991; Schervish & Carlin, 1992;Liu et al., 1994). review subject next section.2.4 Variance Reduction Schemesconvergence rate Gibbs sampler depends strength correlationssamples (which also states Markov chain). term correlationused mean samples dependent, mentioned earlier. casefinite-state irreducible aperiodic Markov chain, convergence rate expressedmaximal correlation states x(0) x(n) (see Liu, 2001, ch. 12). practice,convergence rate analyzed covariance cov[f (x(t) ), f (x(t+1) )], ffunction, also called auto-covariance.convergence estimates exact values depends convergencerate Markov chain stationary distribution variance estimator.10fiCutset Sampling Bayesian Networksfactors contribute value term (f )2 Eq.(10). two mainapproaches allow reduce correlation samples reduce sampling varianceestimates blocking (grouping variables together sampling simultaneously)collapsing (integrating random variables sampling subset), alsoknown Rao-Blackwellisation.Given joint probability distribution three random variables X, , Z,depict essence three sampling schemes follows:1. Standard Gibbs:x(t+1) P (X|y (t) , z (t) )(t+1)z(t+1)(t+1)P (Y |x(t+1)P (Z|x(14)(t),z ),y(15)(t+1))(16)2. Collapsed (variable Z integrated out):x(t+1) P (X|y (t) )(t+1)(t+1)P (Y |x(17))(18)3. Blocking grouping X together:(x(t+1) , (t+1) ) P (X, |z (t) )z(t+1)(t+1)P (Z|x,y(19)(t+1))(20)blocking reduces correlation samples grouping highly correlatedvariables blocks. collapsing, highly correlated variables marginalized out,also results smoothing sampling distributions remaining variables(P (Y |x) smoother P (Y |x, z)). approaches lead reduction samplingvariance estimates, speeding convergence exact values.Generally, blocking Gibbs sampling expected converge faster standard Gibbssampler (Liu et al., 1994; Roberts & Sahu, 1997). Variations schemeinvestigated Jensen et al. (1995) Kjaerulff (1995). Given number samples,estimate resulting collapsed Gibbs sampler expected lower variance(converge faster) estimate obtained blocking Gibbs sampler (Liu et al., 1994).Thus, collapsing preferred blocking. analysis collapsed Gibbs samplerfound Escobar (1994), MacEachern (1994), Liu (1994, 1996).caveat utilization collapsed Gibbs sampler computationprobabilities P (X|y) P (Y |x) must efficient time-wise. case Bayesian networks,task integrating variables equivalent posterior belief updatingevidence variables sampling variables observed. time complexity thereforeexponential adjusted induced width, namely, effective width networkdependencies broken instantiated variables (evidence sampled).11fiBidyuk & Dechter2.5 Importance SamplingSince sampling target distribution hard, different sampling methods exploredifferent trade-offs generating samples obtaining estimates. already discussed,Gibbs sampling generates dependent samples guarantees convergence samplingdistribution target distribution. Alternative approach, called importance sampling,generate samples sampling distribution Q(X) different P (X|e)include weight w(t) = P (x(t) |e)/Q(x(t) ) sample x(t) computationestimates follows:1Xf (xt )w(t)fT (X) =(21)t=1convergence fT (X) E[f (X)] guaranteed long condition P (x|e) 6=0 Q(x) 6= 0 holds. convergence speed depends distance Q(X)P (X|e).One simplest forms importance sampling Bayesian networks likelihoodweighting (Fung & Chang, 1989; Shachter & Peot, 1989) processes variables topological order, sampling root variables priors remaining variablesconditional distribution P (Xi |pai ) defined conditional probability table (the evidence variables assigned observed values). sampling distribution closeprior and, result, usually converges slowly evidence concentrated aroundleaf nodes (nodes without children) probability evidence small. Adaptive (also called dynamic) importance sampling method attempts speedconvergence updating sampling distribution based weight previously generated samples. Adaptive importance sampling methods include self-importance sampling,heuristic importance sampling (Shachter & Peot, 1989), and, recently, AIS-BN (Cheng& Druzdzel, 2000) EPIS-BN (Yuan & Druzdzel, 2003). empirical section,compare performance proposed cutset sampling algorithm AIS-BNconsidered state-of-the-art importance sampling algorithm date (although EPIS-BNshown perform better networks) and, hence, describe AIS-BNdetail.AIS-BN algorithm based observation could sample nodetopological order distribution P (Xi |pai , e), resulting sample would drawntarget distribution P (X|e). Since distribution unknown variableobserved descendants, AIS-BN initializes sampling distributions P 0 (Xi |pai , e)equal either P (Xi |pai ) uniform distribution updates distributionP k (Xi |pai , e) every l samples next sampling distribution P k+1 (Xi |pai , e)closer P (Xi |pai , e) P k (Xi |pai , e) follows:P k+1 (xi |pai , e) = P k (xi |pai , e) + (k) (P (xi |pai , e) P k (xi |pai , e))(k) positive function determines learning rate P (xi |pai , e)estimate P (xi |pai , e) based last l samples.12fiCutset Sampling Bayesian Networks3. Cutset Samplingsection presents cutset sampling scheme. discussed above, samplingcutset guaranteed statistically efficient. Cutset sampling scheme computationally efficient way sampling collapsed variable subset C X, tyingcomplexity sample generation structure Bayesian network.3.1 Cutset Sampling Algorithmcutset sampling scheme partitions variable set X two subsets C X\C.objective generate samples space C={C1 , C2 , ..., Cm } sample c(t)instantiation variables C. Following Gibbs sampling principles,(t)wish generate new sample c(t) sampling value ci probability distribution(t)(t+1) (t+1)(t+1) (t)(t)P (Ci |ci ) = P (Ci |c1, c2, ..., ci1 , ci+1 , ..., cm ). use left arrow denote(t)value ci drawn distribution P (Ci |ci ):(t)ci P (Ci |ci , e)(22)(t)compute probability distribution P (Ci |ci , e) efficiently samplingvariable Ci C, generate samples efficiently. relevant conditional distributions computed exact inference whose complexity tied network structure. denote JT C(B, Xi , e) generic algorithm class variable-eliminationjoin-tree clustering algorithms which, given belief network B evidence e, outputsposterior probabilities P (Xi |e) variable Xi X (Lauritzen & Spiegelhalter, 1988;Jensen et al., 1990; Dechter, 1999a). networks identity clear, usenotation JT C(Xi , e).Cutset SamplingInput: belief network B, cutset C = {C1 , ..., Cm }, evidence e.Output: set samples ct , = 1...T .1. Initialize: Assign random value c0i Ci C assign e.2. Generate samples:= 0 T-1, generate new sample c(t+1) follows:(t)= 1 m, compute new value ci variable Ci follows:(t)a. Compute JT C(Ci , ci , e).(t)(t)b. Compute P (Ci |ci , e) = P (Ci , ci , e).c. Sample:(t+1)(t)ciP (Ci |ci , e)EndEnd(23)Figure 3: w-Cutset sampling AlgorithmTherefore, sampling variable Ci value ci D(Ci ), compute(t)(t)(t)(t)P (Ci , ci , e) via JT C(Ci , ci , e) obtain P (Ci |ci , e) via normalization: P (Ci |ci , e) =(t)P (Ci , ci , e).13fiBidyuk & DechterCutset sampling algorithm uses systematic scan Gibbs sampler given Figure 3.Clearly, adapted used random scan Gibbs sampler well. Steps(a)-(c) generate sample (t + 1) sample (t). every variable Ci C sequence,(t)main computation step (a), distribution P (Ci , ci , e) Ci generated.requires executing JT C every value ci D(Ci ), separately. step (b),conditional distribution derived normalization. Finally, step (c) samples new value(t)obtained distribution. Note use P (Ci |ci , e) short-hand notation(t+1)(t+1)(t)(t)P (Ci |c1, ..., ci1 , ci+1 , ..., ck , e). Namely, sample new value variableCi , values variables C1 Ci1 already updated.next demonstrate process using special case loop-cutset (see Definition 2.1).Example 3.1 Consider belief network previously shown Figure 1 observed nodeE = e loop-cutset {A, D}. begin sampling process initializing sampling variablesa(0) d(0) . Next, compute new sample values a(1) , d(1) follows:P (A|d(0) , e)=PJT C (A, c(0) , e)(0)(24)(1)P (D|a(1) , e)=P (A|d , e)PJT C (D, a(1) , e)(25)(26)d(1)P (D|a(1) , e)(27)process corresponds two iterations inner loop Figure 3. Eq. (24)-(25),sample new value variable A, correspond steps (a)-(c) first iteration. seconditeration, Eq.(26)-(27), sample new value variable D. Since conditioned networkpoly-tree (Figure 1, right), computing probabilities PJT C (A|d(t) , e) PJT C (D|a(t+1) , e) via JT Creduces Pearls belief propagation algorithm distributions computed linear time.3.2 Estimating Posterior Marginalsset samples subset variables C generated, estimate posteriormarginals variable network using mixture estimator. sampling variables,estimator takes form similar Eq.(12):1X(t)P (Ci |e) =P (Ci |ci , e)(28)t=1variables X\C, E, posterior marginal estimator is:1XP (Xi |e) =P (Xi |c(t) , e)(29)t=1use JT C(Xi , c(t) , e) obtain distribution P (Xi |c(t) , e) input Bayesiannetwork conditioned c(t) e shown before.(t)maintain running sum computed distributions P (Ci |ci , e) P (Xi |c(t) , e)sample generation, sums right hand side Eq.(28)-(29) readilyavailable. noted before, estimators P (Ci |e) P (Xi |e) guaranteed converge corresponding exact posterior marginals increases long Markov14fiCutset Sampling Bayesian Networkschain cutset C ergodic. cutset variables estimator simpleergodic average, Xi X\C, E convergence also derived directly firstprinciples:Theorem 3.2 Given Bayesian network B X, evidence variables E X, cutsetC X\E, given set samples c(1) , c(2) , ..., c(T ) obtained via Gibbs samplingP (C|e), assuming Markov chain corresponding sampling C ergodic,Xi X\C, E assuming P (Xi |E) defined Eq.(29), P (Xi |e) P (Xi |e).Proof. definition:1XP (Xi |c(t) , e)P (Xi |e) =(30)t=1Instead summing samples, rewrite expression sumpossible tuples c D(C) group together samples corresponding tupleinstancePc. Let q(c) denote number times tuple C = c occurs set samplescD(C) q(c) = . easy see that:P (Xi |e) =fractionq(c)XcD(C)P (Xi |c, e)q(c)(31)histogram estimator posterior marginal P (c|e). Thus, get:XP (Xi |e) =P (Xi |c, e)P (c|e)(32)cD(C)Since Markov chain formed samples C ergodic, P (c|e) P (c|e)therefore:XP (Xi |e)P (Xi |c, e)P (c|e) = P (Xi |e)cD(C)3.3 Complexitytime space complexity generating samples estimating posterior marginalsvia cutset sampling dominated complexity JT C line (a) algorithm(Figure 3). linear amount additional memory required maintain running(t)sums P (Ci |ci , e) P (Xi |c(t) , e) used posterior marginal estimators.3.3.1 Sample Generation ComplexityClearly, JT C applied network B conditioned cutset variables Cevidence variables E, complexity time space exponential induced widthw conditioned network. O(N d(w+1) ) C w-cutset (see Definition 2.6).15fiBidyuk & DechterUsing notion w-cutset, balance sampling exact inference. one endspectrum plain Gibbs sampling sample generation fast, requiringlinear space, may high variance. end, exact algorithmrequiring time space exponential induced width moral graph.two extremes, control time space complexity using w follows.Theorem 3.3 (Complexity sample generation) Given network B X, evidence E, w-cutset C, complexity generating new sample time spaceO(|C| N d(w+2) ) bounds variables domain size N = |X|.Proof. C w-cutset maximum domain size, complexity(t)computing joint probability P (ci , ci , e) conditioned network O(N d(w+1) ).Since operation must repeated ci D(Ci ), complexity processing one(t)variable (computing distribution P (Ci |ci , e)) O(N d(w+1) ) = O(N d(w+2) ). Finally,since ordered Gibbs sampling requires sampling variable cutset, generating onesample O(|C| N d(w+2) ).3.3.2 Complexity Estimator Computationposterior marginals cutset variable Ci C easily obtained endsampling process without incurring additional computation overhead. mentioned earlier,(t)need maintain running sum probabilities P (ci |ci , e) ci D(Ci ).Estimating P (Xi |e), Xi X\C, E, using Eq.(29) requires computing P (Xi |c(t) , e)sample c(t) generated. summary:Theorem 3.4 (Computing Marginals) Given w-cutset C, complexity computing posteriors variables Xi X\E using samples cutset variablesO(T [|C| + d] N d(w+1) ).Proof. showed Theorem 3.3, complexity generating one sample O(|C|N d(w+2) ). sample c(t) generated, computation posterior marginalsremaining variables requires computing P (Xi |c(t) , e) via JT C(Xi , c(t) , e)O(N d(w+1) ). combined computation time one sample O(|C| N d(w+2) +N d(w+1) ) = O([|C| + d] N d(w+1) ). Repeating computation samples, yieldsO(T [|C| + d] N d(w+1) ).Note space complexity w-cutset sampling bounded O(N d(w+1) ).3.3.3 Complexity Loop-Cutsetcutset C loop-cutset, algorithm JT C reduces belief propagation (Pearl,(t)1988) computes joint distribution P (Ci , ci , e) linear time. referspecial case loop-cutset sampling general w-cutset sampling.loop-cutset also w-cutset w equals maximum number unobservedparents (upper bounded maximum indegree node). However, since processingpoly-trees linear even large w, induced width capture complexity16fiCutset Sampling Bayesian Networksproperly. notion loop-cutset could better captured via hyperwidthnetwork (Gottlob, Leone, & Scarello, 1999; Kask et al., 2005). hyperwidth polytree 1 therefore, loop-cutset defined 1-hypercutset. Alternatively,express complexity via networks input size captures total sizeconditional probability tables processed follows:Theorem 3.5 (Complexity loop-cutset sample generation) C loop-cutset,complexity generating sample O(|C| ) size inputnetwork.Proof. loop-cutset network instantiated, belief propagation (BP)(t)compute joint probability P (ci , ci , e) linear time O(M ) (Pearl, 1988) yielding totaltime space O(|C| ) sample.3.4 Optimizing Cutset Sampling Performanceanalysis complexity generating samples (Theorem 3.3) overly pessimisticassuming computation sampling distribution variable cutsetindependent. variables may change value moving one samplenext, change occurs one variable time sequence muchcomputation retained moving one variable next .show sampling cutset variables done efficientlyreducing factor N |C| Theorem 3.3 (N + |C| ) bounds numberclusters tree decomposition used JT C contains node Ci C. assumecontrol order cutset variables sampled.X1X1X2Y1Y1Y2Yn-2Yn-1X2X3Xn-1XnX2X3Y2X3X4Y3Xn-1XnYn-1Figure 4: Bayesian network (top) corresponding cluster-tree (bottom).Consider simple network variables X={X1 , ....Xn }, ={Y1 , ..., Yn1 } CPTsP (Xi+1 |Xi , Yi ) P (Yi+1 |Xi ) defined every shown Figure 4, top. join-treenetwork chain cliques size 3 given Figure 4, bottom. Since loopcutset, sample variables . Lets assume use ordering Y1 , Y2 , ...Yn1generate sample. Given current sample, ready generate next sampleapplying JT C (or bucket-elimination) network whose cutset variables assigned.17fiBidyuk & Dechtermakes network effectively singly-connected leaves 2 actual variablescluster. algorithm sends message cluster containing Xn towardscluster containing X1 . cluster (X1 , X2 , Y1 ) gets relevant message cluster(X2 , X3 , Y2 ) sample Y1 . accomplished linear computations clique(X1 , X2 , Y1 ) yi D(Yi ) yielding desired distribution P (Y1 |.) (we multiplyfunctions incoming messages cluster, sum X1 X2 normalize).cutset w-cutset, computation single clique O(d(w+1) ).P (Y1 |), Y1 sampled assigned new value, y1 . Cluster (X1 , X2 , Y1 =y1 ) sends message cluster (X2 , X3 , Y2 ) information necessarycompute P (Y2 |.) O(d(w+2) ). P (Y2 |.) available, new value Y2 = y2 sampled.cluster computes sends message cluster (X3 , X4 , Y3 ), on.end, obtain full sample via two message passes conditioned networkcomputation complexity O(N d(w+2) ). example generalized follows.Theorem 3.6 Given Bayesian network N variables, w-cutset C, tree-decompositionTr , given sample c1 , ..., c|C| , new sample generated O((N + |C| ) d(w+2) )maximum number clusters containing variable Ci C.Proof. Given w-cutset C, definition, exists tree-decomposition Tr network(that includes cutset variables) cutset variables C removed,number variables remaining cluster Tr bounded w + 1. Lets imposedirectionality Tr starting arbitrary cluster call R shown Figure 5. LetTCi denote connected subtree Tr whose clusters include Ci . Figure 5, clarity,collapse subtree Ci single node. assume cutset nodessampled depth-first traversal order dictated cluster tree rooted R.TC1 RTC2TCkTC3TC4TC6TC5Figure 5: cluster-tree rooted cluster R subtree cutset node Cicollapsed single node marked TCi .18fiCutset Sampling Bayesian NetworksGiven sample c(t) , JT C send messages leaves Tr towards root cluster.assume without loss generality R contains cutset node C1 firstsampled c(t+1) . JTC pass messages root clusters restricted(t)TC1 (note R TC1 ). Based messages P (C1 = c1 , c1 ) computedO(d(w+1) ). repeat computation value C1 involvingclusters TC1 obtain distribution P (C1 |) O(d(w+2) ) sample new valueC1 . Thus, C1 appears clusters, number message passing computations(after initial O(N ) pass) O() generate first distribution P (C1 |)O( d(w+2) ).next node depth-first traversal order TC2 thus, second variablesampled C2 . distance variables C1 C2 , denoted dist1,2 , shortestpath along Tr cluster contains C1 cluster contains C2 . apply JTCsmesage-passing along path take O(dist1,2 d(w+1) ). Then,obtain conditional distribution P (C2 |), recompute messages subtreeTC2 value c2 D(C2 ) O( d(w+2) ). continue computation similarmanner cutset nodes.JT C traverses tree depth-first order, needs pass messages alongP|C|edge twice (see Figure 5). Thus, sum distances traveled i=2 disti,i1 =O(N ). may repeated computation value sampled variable.This, however, accomplished via message-passing restricted individual variablessubtrees bounded . conclude new full sample generatedO((N + |C| ) d(w+2) ).worthwhile noting complexity generating sample reducedfactor d/(d1) (which amounts factor 2 = 2) noticing whenever(t+1)(t+1) (t)(t)move variable Ci Ci+1 , joint probability P (c1, ..., ci, ci+1 , ..., ck )already available previous round recomputed. need(t+1)(t+1)(t)(t)compute P (c1, ..., ci, ci+1 , ..., ck ) ci+1 6= ci+1 . Buffering last computedjoint probability, need apply JT C algorithm 1 times. Therefore, totalcomplexity generating new sample O((N + |C| ) (d 1) d(w+1) ).Example 3.7 Figure 6 demonstrates application enhancements discussed.depicts moral graph (a), already triangulated, corresponding join-tree (b)Bayesian network Figure 1. evidence variable E removed, variables B form1-cutset. join-tree network cutset evidence variables removed shownFigure 6 (c). Since removing E cluster DF E leaves one variable, F ,combine clusters BDF DF E one cluster, F G. Assuming cutset variablesdomains size 2, initialize B = b0 = d0 .Selecting cluster AC root tree, JT C first propagates messages leavesroot shown Figure 6 (c) computes P (b0 , d0 , e) cluster AC. Next,set B = b1 ; updating functions containing variable B, propagating messagessubtree B consisting clusters AC CF (Figure 6 (d)), obtain P (b1 , d0 , e).Normalizing two joint probabilities, obtain distribution P (B|d0 , e) sample newvalue B. Assume sampled value b1 .19fiBidyuk & DechterABCP(B|A),P(C|A),P(A)ACP(b0|A),P(C|A),P(A)ACP(b1|A),P(C|A),P(A)ACP(b1|A),P(C|A),P(A)ACP(b1|A),P(C|A),P(A)CFP(F|b0,C),P(d0|b0)CFP(F|b1,C),P(d0|b1)CFP(F|b1,C),P(d1|b1)CFP(F|b1,C),P(d0|b1)FGP(e|d0,F),P(G|d0,F)FGP(e|d0,F),P(G|d0,F)FGP(e|d1,F),P(G|d1,F)FGP(e|d0,F),P(G|d0,F)BCBCFP(F|B,C)FGDFGP(D|B), P(G|D,F)EDFEP(E|D,F)B=b0, D=d0, E=e(a)(b)(c)B=b1D=d1D=d0(d)(e)(f)Figure 6: join-tree width 2 (b) moral graph (a) transformed join-treewidth 1 (c) evidence variable E cutset variables B instantiated (in process, clusters BDF BCF merged cluster CF ).clusters contain variables functions original network. cutsetnodes domains size 2, D(B) = {b0 , b1 }, D(D) = {d0 , d1 }. Startingsample {b0 , d0 }, messages propagated (c)-(e) first, sample new valuevariable B (d) variable (e). messages propagatedtree compute posterior marginals P (|b1 , d0 , e) rest variables (f).Next, need compute P (D|b1 , e) sample new value variable D. jointprobability P (d0 , b1 , e) readily available since computed sampling new valueB. Thus, set = d1 compute second probability P (d1 , b1 , e) updating functionsclusters CF F G sending updated message CF F G (Figure 6 (e)).obtain distribution P (D|b1 , e) normalizing joint probabilities sample newvalue d0 D. Since value changed latest computation, updatefunctions clusters CF F G propagate updated messages subtree CD(send message CF F G).order obtain distributions P (|b1 , d0 , e) remaining variables A, C, F ,G, need send updated messages join-tree, F G CFCF AC shown Figure 6 (f ). last step also serves initializationstep next sample generation.example performance cutset sampling significantly better worstcase. sent total 5 messages generate new sample worst casesuggests least N |C| = 3 2 2 = 12 messages (here, N equals number clusters).20fiCutset Sampling Bayesian Networks3.5 finding w-CutsetClearly, w-cutset sampling effective w-cutset small. callstask finding minimum size w-cutset. problem NP-hard; yet, several heuristicalgorithms proposed. next briefly survey proposals.Larossa Dechter (2003) obtain w-cutset processing variables eliminationorder. next node eliminated (selected using triangulation heuristics) addedcutset current induced width (or degree) greater w. Geiger Fishelson(2003) agument idea various heuristics.Bidyuk Dechter (2003) select variables included cutset using greedyheuristics based nodes basic graph properties (such degree node). Onescheme starts empty w-cutset heuristically adds nodes cutsettree-decomposition width w obtained. scheme starts setC = X\E containing nodes network cutset removes nodesset order. algorithm stops removing next node would result treedecomposition width > w.Alternatively, Bidyuk Dechter (2004) proposed first obtain tree-decompositionnetwork find minimal w-cutset tree-decomposition (also NPhard problem) via well-known greedy algorithm used set cover problem. approachshown yield smaller cutset previously proposed heuristics used findingw-cutset experiments (section 4.4) modification tree-decompositionre-computed time node removed tree added w-cutset.4. Experimentssection, present empirical studies cutset sampling algorithms several classesproblems. use mean square error posterior marginals estimatesmeasure accuracy. compare traditional Gibbs sampling, likelihood weighting(Fung & Chang, 1989; Shachter & Peot, 1989), state art AIS-BN adaptiveimportance sampling algorithm (Cheng & Druzdzel, 2000). implemented AIS-BN usingparameters specified Cheng Druzdzel (2000). using implementation,made sure sampling algorithms used data access routineserror measures providing uniform framework comparing performance.reference also report performance Iterative Belief Propagation (IBP) algorithm.4.1 Methodologysection detail describe methodology used implementation decisions madeapply collection empirical results.4.1.1 Sampling Methodologysampling algorithms restarted Markov chain every samples. sampleschain (batch) averaged separately:Pm (xi |e) =1XP (xi |c(t) , e)t=121fiBidyuk & Dechterfinal estimate obtained sample average chains:1 XPm (xi |e)P (xi |e) =m=1Restarting Markov chain known improve sampling convergence rate. singlechain become stuck generating samples single high-probability region withoutever exploring large number high-probability tuples. restarting Markov chaindifferent random point, sampling algorithm achieve better coveragesampling space. experiments, observe significant differenceestimates obtained single chain size chains size therefore,choose report results multiple Markov chains. However, relyindependence random values Pm (xi |e) estimate 90% confidence interval P (xi |e).implementation Gibbs sampling schemes, use zero burn-in time (seesection 2.3.1). mentioned earlier, idea burn-in time throw awayfirst K samples ensure remaining samples drawn distribution closetarget distribution P (X|e). conservative methods estimating K driftminorization conditions proposed Rosenthal (1995) Roberts Tweedie(1999, 2001), required analysis beyond scope paper. considercomparison Gibbs sampling cutset sampling, objective, fairsense schemes use K=0. Further, experimental results showed positiveindication burn-in time would beneficial. practice, burn-in pre-processingtime used algorithm find high-probability regions distribution P (C|e)case initially spends disproportionally large period time low probability regions.Discarding large number low-probability tuples obtained initially, frequencyremaining high-probability tuples automatically adjusted better reflect weight.cpcs360b, N=360, |E|=32, w*=21cpcs360b, N=360, |E|=32, |LC|=26, w*=21LCS8001.40E-04700# unique samples1.60E-041.20E-04MSE1.00E-048.00E-056.00E-054.00E-05LCS6005004003002001002.00E-0500.00E+0002000400060008000100000200040006000800010000# samples# samplesFigure 7: Comparing loop-cutset sampling MSE vs. number samples (left) number unique samples vs. number samples (right) cpcs360b. Resultsaveraged 10 instances different observations.benchmarks, observed full Gibbs sampling cutset samplingable find high probability tuples fast relative number samples generated.example, one benchmarks, cpcs360b, rate generating unique samples,22fiCutset Sampling Bayesian Networksnamely, ratio cutset instances seen number samples,decreases time. Specifically, loop-cutset sampling generates 200 unique tuplesfirst 1000 samples, additional 100 unique tuples generating next 1000 samples,rate generating unique tuples slows 50 per 1000 samples range2000 10000 samples shown Figure 7, right. means firsthundred samples, algorithm spends time revisiting high-probabilitytuples. benchmarks, number unique tuple instances generated increaseslinearly (as cpcs54) and, thus, tuples appear distributed nearly uniformly.case, need burn-in strongly-expressed heavy-weighttuples. Instead using burn-in times, sample initial variable values posteriormarginal estimates generated IBP experiments. sampling time includespre-processing time IBP.experiments performed 1.8 GHz CPU.4.1.2 Measures Performanceproblem instance defined Bayesian network B variables X = {X1 , ..., Xn }evidence E X, derived exact posterior marginals P (Xi |e) using bucket-treeelimination (Dechter, 2003, 1999a) computed mean square error (MSE)approximate posterior marginals P (Xi |e) algorithm MSE defined by:X X1[P (xi |e) P (xi |e)]2SE = P|D(X)|Xi X\EXi X\E D(Xi )mean square error primary accuracy measure, results consistentacross well-known measures average absolute error, KL-distance, squaredHellingers distance show loop-cutset sampling. absolute erroraveraged values unobserved variables:X X1= P|P (xi |e) P (xi |e)|Xi X\E |D(Xi )|Xi X\E D(Xi )KL-distance DK distribution P (Xi |e) estimator P (Xi |e) definedfollows:XP (xi |e)DK (P (Xi |e), P (Xi |e)) =P (xi |e) lgP (xi |e)D(X )benchmark instance, compute KL-distance variable Xi X\Eaverage results:X1DK (P (Xi |e), P (Xi |e))DK (P, P ) =|X\E|Xi X\Esquared Hellingers distance DH distribution P (Xi |e) estimatorP (Xi |e) obtained as:qX pDH (P (Xi |e), P (Xi |e)) =[ P (xi |e) P (xi |e)]2D(Xi )23fiBidyuk & Dechteraverage squared Hellingers distance benchmark instance averagedistances posterior distributions one variable:DH (P, P ) =1|X\E|XXi X\EDH (P (Xi |e), P (Xi |e))average errors different network instances averaged instancesgiven network (typically, 20 instances).also report confidence interval estimate P (xi |e) using approach similarwell-known batch means method (Billingsley, 1968; Geyer, 1992; Steiger & Wilson,2001). Since chains restarted independently, estimates Pm (xi |e) independent.Thus, confidence interval obtained measuring variance estimatorsP (Xi |e). report results Section 4.5.4.2 Benchmarksexperimented four classes networks:CPCS. considered four CPCS networks derived Computer-based PatientCase Simulation system (Parker & Miller, 1987; Pradhan, Provan, Middleton, & Henrion,1994). CPCS network representation based INTERNIST 1 (Miller, Pople, & Myers,1982) Quick Medical Reference (QMR) (Miller, Masarie, & Myers, 1986) expert systems. nodes CPCS networks correspond diseases findings conditionalprobabilities describe correlations. cpcs54 network consists N =54 nodesrelatively large loop-cutset size |LC|=16 (> 25% nodes). induced width15. cpcs179 network consists N =179 nodes. induced width w =8.small loop-cutset size |LC|=8 relatively large corresponding adjusted inducedwidth wLC =7. cpcs360b larger CPCS network 360 nodes, adjusted inducedwidth 21, loop-cutset |LC|=26. Exact inference cpcs360b averaged 30 minutes.largest network, cpcs422b, consisted 422 nodes induced width w =22loop-cutset size 47. exact inference time cpcs422b 50 minutes.Hailfinder network. small network 56 nodes. exact inferenceHailfinder network easy since loop-cutset size 5. Yet, networkzero probabilities and, therefore, good benchmark demonstrating convergencecutset sampling contrast Gibbs sampling.Random networks. experimented several classes random networks: random networks, 2-layer networks, grid networks. random networks generatedN =200 binary nodes (domains size 2). first 100 nodes, {X1 , ..., X100 },designated root nodes. non-root node Xi , > 100, assigned 3 parents selectedrandomly list predecessors {X1 , ..., Xi1 }. refer class randomnetworks multi-partite random networks distinguish bi-partite (2-layer) randomnetworks. random 2-layer networks generated 50 root nodes (first layer)150 leaf nodes (second layer), yielding total 200 nodes. sample 2-layer randomnetwork shown Figure 8, left. non-root node (second layer) assigned 1-3parents selected random among root nodes. nodes assigned domain size2, D(Xi ) = {x0i , x1i }.24fiCutset Sampling Bayesian NetworksFigure 8: Sample random networks: 2-layer (left), grid (center), coding (right).2-layer multi-partite random networks, root nodes assigned uniform priors conditional probabilities chosen randomly. Namely, valueP (x0i |pai ) drawn uniform distribution interval (0, 1) used computecomplementary probability value P (x1i |pai ) = 1 P (x0i |pai ).directed grid networks (as opposed grid-shaped undirected Markov RandomFields) size 15x30 450 nodes also constructed uniform priors (on singleroot node) random conditional probability tables (as described above). sample gridnetwork shown Figure 8, center. networks average induced widthsize 20 (exact inference using bucket elimination required 30 minutes).regular structure largest loop-cutset containing nearly halfunobserved nodes.Coding networks. experimented coding networks 50 code bits 50parity check bits. parity check matrix randomized; parity check bit threeparents. sample coding network 4 code bits, 4 parity checking bits, total 8transmitted bits shown Figure 8, center. total number variables networkexperiments 200 (50 code bits, 50 parity check bits, 1 transmitted bitcode parity check bit). average loop-cutset size 26 induced width21. Markov chain produced Gibbs sampling whole coding networkergodic due deterministic parity check function. result, Gibbs samplingconverge. However, Markov chain corresponding sampling subspace codingbits ergodic and, thus, cutset sampling schemes convergedshow next two sections.networks, except coding grid networks, evidence nodes selected randomamong leaf nodes (nodes without children). Since grid network one leafnode, evidence grid networks selected random among nodes.benchmark, report chart title number nodes network N , averagenumber evidence nodes |E|, size loop-cutset |LC|, average induced widthinput instance denoted w distinguish induced width w network adjustedw-cutset.25fiBidyuk & Dechter4.3 Results Loop-Cutset Samplingsection compare loop-cutset sampling pure Gibbs sampling, likelihoodweighting, AIS-BN, IBP. benchmarks, cutset selected evidencesampling nodes together constitute loop-cutset network using algorithmproposed Becker et al. (2000). show accuracy Gibbs loop-cutset samplingfunction number samples time.CPCS networks. results summarized Figures 9-12. loop-cutset curvechart denoted LCS (for Loop Cutset Sampling). induced width networkwLC loop-cutset nodes observed specified caption. identicallargest family size poly-tree generated cutset variables removed. plottime x-axis accuracy (MSE) y-axis. CPCS networks, IBPalways converged converged fast (within seconds). Consequently, IBP curve alwaysstraight horizontal line results change convergence achieved.curves corresponding Gibbs sampling, loop-cutset sampling, likelihood weighting,AIS-BN demonstrate convergence sampling schemes time. threeCPCS networks loop-cutset sampling converges much faster Gibbs sampling.exception cpcs422b (Figure 12, right) induced width conditioned singlyconnected network remains high (wLC = 14) due large family sizes thus, loop-cutsetsampling generates samples slowly (4 samples/second) compared Gibbs sampling(300 samples/second). Since computing sampling distribution exponential w, samplingsingle variable O(214 ) (all variables domains size 2). result, although loopcutset sampling shows significant reduction MSE function number samples(Figure 12, left), enough compensate two orders magnitude differenceloop-cutset rate sample generation. cpcs54 (Figure 9), cpcs179 (Figure 10),cpcs360b (Figure 11) loop-cutset sampling achieves greater accuracy IBP within10 seconds less.comparison importance sampling schemes, observe AIS-BN algorithm consistently outperforms likelihood weighting AIS-BN slightly better loopcutset sampling cpcs54, probability evidence P (e)=0.0928 relatively high.cpcs179, probability evidence P (e)=4E-05 smaller, LCS outperforms AIS-BNGibbs sampling curves falls AIS-BN likelihood weighting. Gibbssampling loop-cutset sampling outperform AIS-BN cpcs360b cpcs422bprobability evidence small. cpcs360b average P (e)=5E-8 cpcs422b probability evidence varies 4E-17 8E-47. Note likelihood weighting AIS-BNperformed considerably worse either Gibbs sampling loop-cutset samplingbenchmarks function number samples. Consequently, leftcharts showing convergence Gibbs loop-cutset sampling functionnumber samples order zoom two algorithms focusempirical studies.Coding Networks. results coding networks shown Figure 13.computed error measures coding bits averaged 100 instances (10 instances,different observed values, 10 networks different coding matrices).noted earlier, Markov chains corresponding Gibbs sampling coding networksergodic and, result, Gibbs sampling converge. However, Markov26fiCutset Sampling Bayesian NetworksGibbscpcs54, N=54, |LC|=16, w*=15, |E|=8LWcpcs54, N=54, |LC|=16, w*=15, |E|=8LCS4.0E-04AIS-BN3.0E-04GibbsIBP3.5E-042.5E-04LCS2.0E-04IBP3.0E-04MSEMSE2.5E-042.0E-041.5E-041.5E-041.0E-041.0E-045.0E-055.0E-050.0E+000.0E+000500010000150002000025000030000246# samplesLWcpcs54, N=54, |LC|=16, w*=15, |E|=8101214Hellinger-distanceLCS1.0E-05AIS-BN7.0E-06Gibbs1.2E-05LWcpcs54, N=54, |LC|=16, w*=15, |E|=8AIS-BN1.4E-05KL-distance8Time (sec)IBP8.0E-066.0E-064.0E-062.0E-06Gibbs6.0E-06LCS5.0E-06IBP4.0E-063.0E-062.0E-061.0E-060.0E+000.0E+00024681012014246101214Time (sec)Time (sec)LWcpcs54, N=54, |LC|=16, w*=15, |E|=8AIS-BN2.1E-03Absolute Error8Gibbs1.8E-03LCS1.5E-03IBP1.2E-039.0E-046.0E-043.0E-040.0E+0002468101214Time (sec)Figure 9: Comparing loop-cutset sampling (LCS), wLC =5, Gibbs sampling (hereby referredGibbs), likelihood weighting (LW), AIS-BN, IBP cpcs54 network,averaged 20 instances, showing MSE function number samples(top left) time (top right) KL-distance (middle left), squared Hellingersdistance (middle right), average error (bottom) function time.27fiBidyuk & Dechtercpcs179, N=179, |LC|=8, w*=8, |E|=17LWcpcs179, N=179, |LC|=8, w*=8, |E|=17LW1.0E-02AIS-BN1.0E-01AIS-BNGibbsGibbsLCSIBP1.0E-02IBP1.0E-03MSEAbsolute ErrorLCS1.0E-041.0E-031.0E-051.0E-0402468101201424681012cpcs179, N=179, |LC|=8, w*=8, |E|=17LWcpcs179, N=179, |LC|=8, w*=8, |E|=17LW1.0E+00AIS-BNAIS-BN1.0E-01Gibbs1.0E-01Hellinger-distanceGibbsKL-distance14Time (sec)Time (sec)LCSIBP1.0E-021.0E-031.0E-041.0E-05LCS1.0E-02IBP1.0E-031.0E-041.0E-05024681012140246Time (sec)8101214Time (sec)LWcpcs179, N=179, |LC|=8, w*=8, |E|=17AIS-BN1.0E-01GibbsAbsolute ErrorLCSIBP1.0E-021.0E-031.0E-0402468101214Time (sec)Figure 10: Comparing loop-cutset sampling (LCS), wLC =7, Gibbs sampling, likelihoodweighting (LW), AIS-BN, IBP cpcs179 network, averaged 20 instances, showing MSE function number samples (top left) time(top right) KL-distance (middle left), squared Hellingers distance (middleright), average error (bottom) function time.28fiCutset Sampling Bayesian Networkscpcs360b, N=360, |LC|=26, w*=21, |E|=15cpcs360b, N=360, |LC|=26, w*=21, |E|=151.E-02Gibbs2.5E-04LWAIS-BNLCS2.0E-04GibbsIBP1.5E-04LCSMSEMSE1.E-031.0E-04IBP1.E-045.0E-051.E-050.0E+0005000100001500020000025000246# samplescpcs360b, N=360, |LC|=26, w*=21, |E|=15101214cpcs360b, N=360, |LC|=26, w*=21, |E|=15LW1.E-02AIS-BNHellinger-distanceGibbs1.E-03LCSIBP1.E-04LW1.E-02AIS-BNKL-distance8Time (sec)1.E-051.E-06Gibbs1.E-03LCS1.E-04IBP1.E-051.E-061.E-07024681012140246Time (sec)8101214Time (sec)cpcs360b, N=360, |LC|=26, w*=21, |E|=151.E-01LWAbsolute ErrorAIS-BNGibbs1.E-02LCSIBP1.E-031.E-04051015202530Time (sec)Figure 11: Comparing loop-cutset sampling (LCS), wLC =3, Gibbs sampling, likelihoodweighting (LW), AIS-BN, IBP cpcs360b network, averaged 20 instances, showing MSE function number samples (top left) time(top right) KL-distance (middle left), squared Hellingers distance (middleright), average error (bottom) function time.29fiBidyuk & Dechtercpcs422b, N=422, |LC|=47, w*=22, |E|=28Gibbscpcs422b, N=422, |LC|=47, w*=22, |E|=28LCS4.0E-04LWAIS-BN1.0E-02GibbsIBP3.5E-04LCS3.0E-04MSE2.5E-04MSEIBP1.0E-032.0E-041.5E-041.0E-041.0E-045.0E-051.0E-050.0E+00010002000300040005000060001020LWcpcs422b, N=422, |LC|=47, w*=22, |E|=28405060LWcpcs422b, N=422, |LC|=47, w*=22, |E|=28AIS-BN1.0E+00AIS-BNGibbs1.0E-01LCS1.0E-02IBPGibbs1.0E-01Hellinger-distanceKL-distance30Time (sec)# samples1.0E-031.0E-041.0E-051.0E-06LCS1.0E-02IBP1.0E-031.0E-041.0E-051.0E-06010203040506001020Time (sec)30405060Time (sec)cpcs422b, N=422, |LC|=47, w*=22, |E|=28LWAIS-BN1.0E-01GibbsAbsolute ErrorLCSIBP1.0E-021.0E-031.0E-040102030405060Time (sec)Figure 12: Comparing loop-cutset sampling (LCS), wLC =14, Gibbs sampling, likelihoodweighting (LW), AIS-BN sampling, IBP cpcs422b network, averaged10 instances, showing MSE function number samples (topleft) time (top right) KL-distance (middle left), squared Hellingersdistance (middle right), average error (bottom) function time.30fiCutset Sampling Bayesian Networks1.0E-011.0E-021.0E-021.0E-031.0E-041.0E-031.0E-051.0E-040246801024Time (sec)6810Time (sec)LWAIS-BNGibbsLCSIBP1.0E+00coding, N=200, P=3, |LC|=26, w*=21LWAIS-BNGibbsLCSIBP1.0E+00Hellinger-distancecoding, N=200, P=3, |LC|=26, w*=211.0E+01KL-distanceLWAIS-BNGibbsLCSIBP1.0E-01MSEAbsolute Errorcoding, N=200, P=3, |LC|=26, w*=21LWAIS-BNGibbsLCSIBPcoding, N=200, P=3, |LC|=26, w*=211.0E+001.0E-011.0E-021.0E-031.0E-041.0E-051.0E-011.0E-021.0E-031.0E-041.0E-0502468010Time (sec)246810Time (sec)Figure 13: Comparing loop-cutset sampling (LCS), wLC =3, Gibbs sampling, likelihoodweighting (LW), AIS-BN, IBP coding networks, =0.4, averaged10 instances 10 coding networks (100 instances total). graphs show average absolute error ( top left), MSE (top right), KL-distance (bottom left),squared Hellingers distance (bottom right) function time.chain corresponding sampling subspace code bits ergodic therefore,loop-cutset sampling, samples subset coding bits, converges even achieveshigher accuracy IBP time. reality, IBP certainly preferable codingnetworks since size loop-cutset grows linearly number code bits.Random networks. random multi-part networks (Figure 14, top) random2-layer networks (Figure 14, middle), loop-cutset sampling always converged fasterGibbs sampling. results averaged 10 instances network type.cases, loop-cutset sampling achieved accuracy IBP 2 seconds less. 2-layernetworks, Iterative Belief Propagation performed particularly poorly. Gibbs samplingloop-cutset sampling obtained accurate results less second.Hailfinder network. used network (in addition coding networks) compare behavior cutset sampling Gibbs sampling deterministic networks. SinceHailfinder network contains many deterministic probabilities, Markov chain corresponding Gibbs sampling variables non-ergodic. expected, Gibbs sampling failsloop-cutset sampling computes accurate marginals (Figure 15).31fiBidyuk & Dechterrandom, N=200, |E|=20, |C|=30, w*=222-layer, R=50, P=3, N=200, |E|=16, |LC|=17, w*=16Gibbs1.8E-04LCS1.5E-04IBP1.0E-01GibbsLCS1.0E-02IBPMSEMSE1.2E-049.0E-056.0E-051.0E-031.0E-043.0E-051.0E-050.0E+00051015202503024Time (sec)681012Time (sec)Figure 14: Comparing loop-cutset sampling (LCS), Gibbs sampling, IBP randomnetworks (left) 2-layer random networks (right), wLC =3 classesnetworks, averaged 10 instances each. MSE function time.Hailfinder, N=56, |LC|=5, w*=5, |E|=4Gibbs1.0E-01LCSIBPMSE1.0E-021.0E-031.0E-0401234567Time (sec)Figure 15: Comparing loop-cutset sampling (LCS), wLC =7, Gibbs sampling, IBPHailfinder network, 10 instances. MSE function time.summary, empirical results demonstrate loop-cutset sampling cost-effectivetime-wise superior Gibbs sampling. measured ratio R = Mgc numbersamples Mg generated Gibbs number samples Mc generated loop-cutsetsampling time period (it relatively constant given networkchanges slightly problem instances differ observations). cpcs54,cpcs179, cpcs360b, cpcs422b ratios correspondingly 2.5, 3.75, 0.7, 75(see Table 2 section 4.4). also obtained R=2.0 random networks R=0.3random 2-layer networks. ratio values > 1 indicate Gibbs sampler generates32fiCutset Sampling Bayesian Networkssamples faster loop-cutset sampling usually case. instances,variance reduction compensated increased computation time fewer samplesneeded converge resulting overall better performance loop-cutset samplingcompared Gibbs sampling. cases, however, reduction sample sizealso compensates overhead computation sampling one variable value.cases, loop-cutset sampling generated samples faster Gibbs yielding ratio R < 1.Then, improvement accuracy due larger number samplesfaster convergence.4.4 w-Cutset Samplingsection, compare general w-cutset scheme different values wGibbs sampling. main goal study performance w-cutset samplingvaries w. completeness sake, include results loop-cutset sampling shownsection 4.3.empirical study, used greedy algorithm set cover problem, mentionedsection 3.5, finding minimal w-cutset. apply algorithm manner(w + 1)-cutset proper subset w-cutset and, thus, expectedlower variance converge faster sampling w-cutset terms number samplesrequired (following Rao-Blackwellisation theory). focus empirical studytrade-offs cutset size reduction associated increase sample generationtime gradually increase bound w.used benchmarks included also grid networks. samplingalgorithms given fixed time bound. sampling small networks, cpcs54(w =15) cpcs179 (w =8), exact inference easy, sampling algorithmsallocated 10 seconds 20 seconds respectively. larger networks allocated 100-200seconds depending complexity network fraction exactcomputation time.Table 1 reports size sampling set used algorithm columnreports size corresponding w-cutset. example, cpcs360b, averagesize Gibbs sample (all nodes except evidence) 345, loop-cutset size 26, size2-cutset 22, on. Table 2 shows rate sample generation differentalgorithms per second. observed previously case loop-cutset sampling,special cases cutset sampling generated samples faster Gibbs sampler.example, cpcs360b, loop-cutset sampling 2-cutset sampling generated 600 samplesper second Gibbs sampler able generate 400 samples. attributesize cutset sample (26 nodes less reported Table 1) comparedsize Gibbs sample (over 300 nodes).CPCS networks. present two charts. One chart demonstrates convergencetime several values w. second chart depicts change qualityapproximation (MSE) function w two time points, half totalsampling time end total sampling time. performance Gibbs samplingcutset sampling cpcs54 shown Figure 16. results averaged 20instances 5-10 evidence variables. graph left Figure 16 shows meansquare error estimated posterior marginals function time Gibbs sampling,33fiBidyuk & Dechtercpcs54cpcs179cpcs360bcpcs422bgrid15x30random2layercodingGibbs51162345392410190185100LC1682647169301726w=217112265163612238Sampling Set Sizew=3 w=4 w=5 w=615119897519161514575045401199575602625241815131311231818-w=713355017-w=813-Table 1: Markov chain sampling set size function w.cpcs54cpcs179cpcs360bcpcs422bgrid15x30random2layercodingGibbs50001500400300200020002002400LC2000, w= 5400, w= 7600, w= 34, w=14500, w= 21000, w= 3700, w= 31000, w= 3No. Samplesw=2 w=3 w=4 w=53000 2400800500400150401060040016010020015090503002601501051400700450300900320150751000400200120w=630040306014040100w=720153575-w=820-Table 2: Average number samples generated per second function w.loop-cutset sampling, w-cutset sampling w=2, 3, 4, 5. second chart showsaccuracy function w. first point corresponds Gibbs sampling; pointscorrespond loop-cutset sampling w-cutset sampling w ranging 2 6.loop-cutset result embedded w-cutset values w=5. explained section 3.3,loop-cutset corresponds w-cutset w maximum number parentsnetwork. Initially, best results obtained 2- 3-cutset sampling followedloop-cutset sampling. time, 2- 5-cutset sampling become best.results cpcs179 reported Figure 17. charts show loop-cutsetsampling w-cutset sampling w range 2 5 superior Gibbs sampling.chart left shows best cutset sampling schemes, lowestMSE curves, 2- 3-cutset sampling. loop-cutset curve falls 2-3-cutset first outperformed 2- 3-cutset 12 seconds. Loop-cutsetsampling 2- 3-cutset sampling outperform Gibbs sampling nearly two ordersmagnitude MSE falls 1E-04 Gibbs MSE remains order 1E02. 4- 5-cutset sampling results fall between, achieving MSE 1E-03.curves corresponding loop-cutset sampling 2-, 3- 4-cutset sampling fallIBP line means four algorithms outperform IBP first secondsexecution (IBP converges less second). 5-cutset outperforms IBP 8seconds. Figure 17 right, see accuracy results sampling algorithms34fiCutset Sampling Bayesian NetworksGibbs2.5E-04MSE2.0E-041.5E-04IBPcpcs54, N=54, |LC|=16, w*=15, |E|=8IBPLCS,w=52.5E-04|C|=16,w=2|C|=15,w=32.0E-04|C|=11,w=4|C|=9,w=51.5E-041.0E-04MSEcpcs54, N=54, |LC|=16, w*=15, |E|=83.0E-045.0E-05Cutset, 5 secCutset, 10 sec1.0E-045.0E-050.0E+000.0E+0002468101214Gibbsw=2w=3w=4Time (sec)LCS,w=5w=5w=6Figure 16: MSE function time (left) w (right) cpcs54, 20 instances, timebound=12 seconds.MSE1.0E-031.0E-04IBPcpcs179, N=179, |LC|=8, w*=8, |E|=17Cutset, 10 sec1.0E-01Cutset, 20 sec1.0E-02MSEGibbsIBPLCS,w=7|C|=11,w=2|C|=9,w=3|C|=7,w=4|C|=5,w=5cpcs179, N=179, |LC|=8, w*=8, |E|=171.0E-021.0E-031.0E-041.0E-051214Time (sec)LCS,w=710w=58w=46w=34w=22G0ibbs1.0E-05Figure 17: MSE function time (left) w (right) cpcs179, 20 instances, timebound=12 seconds. Y-scale exponential due large variation performanceGibbs cutset sampling.10 seconds 20 seconds. agreement convergence curvesleft.cpcs360b (Figure 18), loop-cutset sampling 2- 3-cutset sampling similarperformance. accuracy estimates slowly degrades w increases. Loop-cutsetsampling w-cutset sampling substantially outperform Gibbs sampling values wexceed accuracy IBP within 1 minute.example cpcs422b, demonstrate significance adjusted inducedwidth conditioned network performance cutset sampling. reportedsection 4.3, loop-cutset relatively small |LC|=47 wLC =14 thus, samplingone new loop-cutset variable value exponential big adjusted induced width.result, loop-cutset sampling computes 4 samples per second 2-, 3and 4-cutset, slightly larger 65, 57, 50 nodes respectively (seeTable 1), compute samples rates 200, 150, 90 samples per second (see Table 2).35fiBidyuk & Dechtercpcs360b, N=360, |LC|=26, w*=21, |E|=15cpcs360b, N=360, |E|=18, |LC|=26, w*=15Gibbs1.E-031.E-04|C|=23,w=2|C|=19,w=38.E-05|C|=16,w=4|C|=15,w=56.E-05IBPcutset,t=30seccutset,t=60secMSEMSE1.E-04IBPLCS,w=34.E-051.E-052.E-05G=7ww=6=5wTime (sec)=470w60=350w40=330LC,w2010ibb0w=20.E+001.E-06Figure 18: MSE function time (left) w (right) cpcs360b, 20 instances, timebound=60 seconds. Y-scale exponential due large variation performanceGibbs cutset sampling.GibbsIBPLCS,w=2|C|=65,w=2|C|=57,w=3|C|=50,w=4|C|=45,w=51.8E-04MSE1.5E-041.2E-04cpcs422b, N=422, |LC|=47, w*=22, |E|=281.0E-01IBPCutset, 100 secCutset, 200 sec1.0E-02MSEcpcs422b, N=422, |LC|=47, w*=22, |E|=282.1E-049.0E-051.0E-036.0E-051.0E-043.0E-050.0E+000204060801001201401.0E-05GibbsTime (sec)w=2w=3w=4w=5w=6w=7Figure 19: MSE function time (left) w (right) cpcs422b, 10 instances, timebound=200 seconds. Y-scale exponential due large variation performanceGibbs cutset sampling.5-cutset closest loop-cutset size, |C5 | = 45, computes 50 samples persecond order magnitude loop-cutset sampling. resultscpcs422b shown Figure 19. loop-cutset sampling results excluded duepoor performance. chart right Figure 19 shows w-cutset performed wellrange w = 2 7 far superior Gibbs sampling. allowed enough time,w-cutset sampling outperformed IBP well. IBP converged 5 seconds. 2-, 3-,4-cutset improved IBP within 30 seconds, 5-cutset 50 seconds.Random networks. Results 10 instances random multi-partite 10 instances 2-layer networks shown Figure 20. see, w-cutset samplingsubstantially improves Gibbs sampling IBP reaching optimal performancew = 2 3 classes networks. range, performance similarloop-cutset sampling. case 2-layer networks, accuracy Gibbs sampling36fiCutset Sampling Bayesian Networksrandom, R=50, N=200, P=3, |LC|=30, w*=22random, R=50, N=200, P=3, |LC|=30, w*=221.5E-041.0E-04IBPcutset,t=30seccutset,t=60sec1.5E-041.0E-045.0E-055.0E-050.0E+00G2layer, R=50, N=200, P=3, |LC|=17, w*=161.0E-04w=7IBP1.0E-01cutset,t=10seccutset,t=20sec1.0E-02MSEMSE1.0E-03w=62layer, R=50, N=200, P=3, |LC|=17, w*=16GibbsIBP|LC|=17,w*=3|C|=22,w*=2|C|=15,w*=3|C|=13,w*=4|C|=12,w*=51.0E-02w=5Time (sec)w=450=340,w30LC20ibbs10w=30.0E+000w=2MSE2.0E-042.0E-04MSEGibbsIBP|LC|=30,w*=3|C|=61,w*=2|C|=26,w*=3|C|=25,w*=4|C|=24,w*=52.5E-041.0E-031.0E-041.0E-050510152025Time (sec)1.0E-05Gibbsw =2LC,w =3w =3w =4w =5w =6Figure 20: Random multi-partite networks (top) 2-layer networks (bottom), 200 nodes,10 instances. MSE function number samples (left) w (right).37fiBidyuk & DechterIBP order-of-magnitude less compared cutset sampling (Figure 20, bottom right).poor convergence accuracy IBP 2-layer networks observed previously(Murphy et al., 1999).grid, 15x30, |E|=60, |LC|=169, w*=15, MSE2.5E-041.5E-04IBP|LC|=169,w*=22.0E-041.2E-04|C|=163,w*=2100120cutset,t=100secTime (sec)w*=880w*=760w*=640ibb20cutset,t=50sec0.0E+00G0IBP3.0E-05w*=55.0E-056.0E-05w*=4|C|=75,w*=5w*=3|C|=95,w*=41.0E-049.0E-05w*=2LC,w*=2|C|=119,w*=31.5E-04MSEMSEgrid, 15x30, |E|=40, |LC|=169, w*=20GibbsFigure 21: Random networks, 450 nodes, 10 instances. MSE function numbersamples (left) w (right).Grid networks. Grid networks 450 nodes (15x30) class benchmarks full Gibbs sampling able produce estimates comparable cutsetsampling (Figure 21). respect accuracy, Gibbs sampler, loop-cutset sampling,3-cutset sampling best performers achieved similar results. Loop-cutsetsampling fastest accurate among cutset sampling schemes. Still, generated samples 4 times slowly compared Gibbs sampling (Table 2) sinceloop-cutset relatively large. accuracy loop-cutset sampling closely followed2-, 3- 4-cutset sampling slowly degrading w increased. Grid networksexample benchmarks regular graph structure (that cutset sampling cannot exploitadvantage) small CPTs (in two-dimensional grid network node2 parents) Gibbs sampling strong.coding 50x50, N=200, P=3, |LC|=26, w*=19coding, 50x50, N=200, P=3, |LC|=26, w*=19IBP2.5E-04cutset,t=5sec|C|=38,w*=22.5E-04cutset,t=10sec2.0E-04|C|=21,w*=32.0E-04|C|=18,w*=4MSEMSEIBP|LC|=26,w*=33.0E-041.5E-041.0E-041.5E-041.0E-045.0E-055.0E-050.0E+0002468100.0E+00w=2Time (sec)w=3LC,w=3w=4Figure 22: Coding networks, 50 code bits, 50 parity check bits, =0.4, 100 instances, timebound=6 minutes.38fiCutset Sampling Bayesian Networkscpcs54cpcs179cpcs360bcpcs422bgrid15x30random2layercodingTime20 sec40 sec100 sec200 sec100 sec50 sec20 sec20 secGibbs450015002000300020002000200650Markov Chain LengthLC w=2 w=3 w=42200 4000 2400800400400150403000 3000 200080020 2000 15009005003002601501000 1400700450700900320150450800600250w=55001050050010530075150w=62002506014040100Table 3: Individual Markov chain length function w. length chainadjusted sampling scheme benchmark total processingtime across sampling algorithms same.Coding Networks. cutset sampling results coding networks shownFigure 22. Here, induced width varied 18 22 allowing exact inference.However, additionally tested observed complexity network growsexponentially number coding bits (even small increase numbercoding bits 60 yielding total 240 nodes corresponding adjustments numberparity-checking bits transmitted code size, induced width exceeds 24)time sample generation scales linearly. collected results 10 networks(10 different parity check matrices) 10 different evidence instantiations (total 100instances). decoding, Bit Error Rate (BER) standard error measure. However,computed MSE unobserved nodes evaluate quality approximate resultsprecisely. expected, Gibbs sampling converge (because Markov chainnon-ergodic) left charts. charts Figure 22 show loop-cutsetoptimal choice coding networks whose performance closely followed 2-cutsetsampling. saw earlier, cutset sampling outperforms IBP.4.5 Computing Error BoundSecond issue convergence sampling scheme always problem predictingquality estimates deciding stop sampling. section, compareempirically error intervals Gibbs cutset sampling estimates.Gibbs sampling cutset sampling guaranteed converge correct posteriordistribution ergodic networks. However, hard estimate many samplesneeded achieve certain degree convergence. possible derive boundsabsolute error based sample variance sampling method samples independent. Gibbs MCMC methods, samples dependent cannot applyconfidence interval estimate directly. case Gibbs sampling, apply batchmeans method special case standardized time series method usedBUGS software package (Billingsley, 1968; Geyer, 1992; Steiger & Wilson, 2001).39fiBidyuk & Dechtermain idea split Markov chain length chains length. Let Pm (xi |e) estimate derived single chain [1, ..., ] length(meaning, containing samples) defined equations (28)-(29). estimates Pm (x|e)assumed approximately independent large enough . Assuming convergenceconditions satisfied central limit theorem holds, Pm (x|e) distributedaccording N (E[P (xi |e)], 2 ) posterior marginal P (Xi |e) obtainedaverage results obtained chain, namely:P (x|e) =1 XPm (x|e)(33)m=1sampling variance computed usually:2 =X1(Pm (x|e) P (x|e))21m=1equivalent expression sampling variance is:PMP 2 (x|e) P 2 (x|e)2= m=11(34)2 easy compute incrementally storing running sums Pm (x|e)2 (x|e). Therefore, compute confidence interval 100(1 ) percentilePmused random variables normal distribution small sampling set sizes. Namely:"r #2=1(35)P P (x|e) [P (x|e) 2 ,(M 1)2 ,(M 1) table value distribution (M 1) degrees freedom.used batch means approach estimate confidence interval posteriormarginals one modification. Since working relatively small sample sets(a thousand samples) notion large enough well defined,restarted chain every samples guarantee estimates Pm (x|e)truly independent. method batch means provides meaningful error estimatesassuming samples drawn stationary distribution. assumeproblems chains mix fast enough samples drawn targetdistribution.applied approach estimate error bound Gibbs samplercutset sampler. computed 90% confidence interval estimated posteriormarginal P (xi |e) based sampling variance Pm (xi |e) 20 Markov chainsdescribed above. computed sampling variance 2 Eq.(34) 90% confidenceinterval 0.9 (xi ) Eq.(35) averaged nodes:X X10.9 = P0.9 (xi )N |D(Xi )|xi D(Xi )estimated confidence interval large practical. Thus, compared 0.9empirical average absolute error :40fiCutset Sampling Bayesian Networkscpcs54cpcs179cpcs360bcpcs422brandom2layercodinggrid15x300.90.90.90.90.90.90.90.9Average ErrorLCw=20.00036 0.000300.00076 0.000640.00086 0.000740.00148 0.001110.00011 0.000100.00022 0.00023- 0.00018- 0.000330.00039 0.001190.00080 0.002470.00066 0.000630.00145 0.001440.00014 0.000190.00030 0.000350.00099 0.001190.00214 0.00247Gibbs0.000560.001190.015770.021380.000510.001130.000550.001190.000910.001990.004360.009440.001080.00248Confidence Intervalw=3w=4w=50.000300.00040 0.000360.000630.00098 0.001120.000660.00113 0.001780.001640.00235 0.003920.000080.00014 0.000120.000210.00030 0.000280.000200.00018 0.000270.000350.00043 0.000600.000910.00099 0.001090.002050.00225 0.002220.000820.00117 0.001340.001850.00235 0.003020.00019 0.0001740.00034 0.0003560.000910.00099 0.001090.002050.00225 0.00222w=60.000670.001160.000220.000460.000370.000740.001130.002390.001970.003410.001130.00239Table 4: Average absolute error (measured) estimated confidence interval 0.9function w 20 Markov Chains.=NX1|D(Xi )|PXxi D(Xi )|P (xi |e) P (xi |e))objective study observe whether computed confidence interval 0.9(estimated absolute error) accurately reflects true absolute error , namely, verify< 0.9 , so, investigate empirically whether confidence interval cutsetsampling estimates smaller compared Gibbs sampling would expect duevariance reduction.Table 4 presents average confidence interval average absolute errorbenchmarks. benchmark, first row results (row ) reports averageabsolute error second row results (row 0.9 ) reports 90% confidence interval.column Table 4 corresponds sampling scheme. first column reports resultsGibbs sampling. second column reports results loop-cutset sampling.remaining columns report results w-cutset sampling w range 26. loop-cutsetsampling results cpcs422b included due statistically insignificant numbersamples generated loop-cutset sampling. Gibbs sampling results coding networksleft network ergodic (as mentioned earlier) Gibbs samplingconverge.see networks < 0.9 validates method measuringconfidence interval. cases estimated confidence interval 0.92-3 times size average error relatively small. case cutset sampling,largest confidence interval max 0.9 = 0.00247 reported grid networks loop-cutset41fiBidyuk & Dechtersampling. Thus, confidence interval estimate could used criteria reflectingquality posterior marginal estimate sampling algorithm practice. Subsequently, comparing results Gibbs sampling cutset sampling, observesignificant reduction average absolute error, also similar reductionestimated confidence interval. Across benchmarks, estimated confidence intervalGibbs sampler remains 0.9 > 1E-3. time, cutset sampling obtain0.9 < 1E-3 5 8 classes networks (excluded cpcs179, grid, 2-layernetworks).4.6 Discussionempirical evaluation performance cutset sampling demonstrates that, exceptgrid networks, sampling cutset usually outperforms Gibbs sampling. showconvergence cutset sampling terms number samples dramatically improvespredicted theoretically.experiments clearly show exists range w-values w-cutsetsampling outperforms Gibbs sampler. performance w-cutset sampling deterioratesincrease w yields small reduction cutset size. example cpcs360bnetwork starting w=4, increasing w 1 results reducing samplingset 1 node (shown Table 1).observe loop-cutset good choice cutset sampling longinduced width network wLC conditioned loop-cutset reasonably small. wLClarge (as cpcs422b), loop-cutset sampling computationally less efficient w-cutsetsampling w < wLC .also showed Section 4.3 Gibbs sampling loop-cutset samplingoutperform state-of-the-art AIS-BN adaptive importance sampling methodprobability evidence small. Consequently, w-cutset sampling schemes Section 4.4 outperformed Gibbs sampler cpcs360b cpcs422b would also outperfromAIS-BN.5. Related Workmention related work. idea marginalising variables improveefficiency Gibbs sampling first proposed Liu et al. (1994). successfullyapplied several special classes Bayesian models. Kong et al. (1994) applied collapsingbivariate Gaussian problem missing data. Liu (1994) defined collapsed Gibbssampling algorithm finding repetitive motifs biological sequences applies integratingtwo parameters model. Similarly, Gibbs sampling set collapsed Escobar(1994), MacEachern (1994), Liu (1996) learning nonparametric Bayes problem.instances above, special relationships problem variablesexploited integrate several variables resulting collapsed Gibbs sampling approach.Compared previous research work, contribution defining generic schemecollapsing Gibbs sampling Bayesian networks takes advantage networksgraph properties depend specific form relationshipsvariables.42fiCutset Sampling Bayesian NetworksJensen et al. (1995) combined sampling exact inference blocking Gibbs samplingscheme. Groups variables sampled simultaneously using exact inference computeneeded conditional distributions. empirical results demonstrate significant improvement convergence Gibbs sampler time. Yet, proposed blockingGibbs sampling, sample contains variables network. contrast, cutset sampling reduces set variables sampled. noted previously, collapsing produceslower variance estimates blocking and, therefore, cutset sampling require fewersamples converge.different combination sampling exact inference join-trees describedKoller et al. (1998) Kjaerulff (1995). oller et al. Kjaerulff proposed sampleprobability distribution cluster computing outgoing messages. Kjaerulffused Gibbs sampling large clusters estimate joint probability distributionP (Vi ), Vi X cluster i. estimated P (Vi ) recorded instead true jointdistribution conserve memory. motivation high-probability tuplesrecorded remaining low-probability tuples assumed probability 0.small clusters, exact joint distribution P (Vi ) computed recorded. However,paper analyze introduced errors compare performance schemestandard Gibbs sampler exact algorithm. analysis error givencomparison approaches.Koller et al. (1998) used sampling used compute messages sent clustercluster j posterior joint distributions cluster-tree contains discretecontinuous variables. approach subsumes cluster-based sampling proposedKjaerulff (1995) includes rigorous analysis error estimated posteriordistributions. method difficulties propagation evidence. empiricalevaluation limited two hybrid network instances compares qualityestimates likelihood weighting, instance importance samplingperform well presence low-probability evidence.effectiveness collapsing sampling set demonstrated previouslycontext Particle Filtering method Dynamic Bayesian networks (Doucet, Andrieu, &Godsill, 2000a; Doucet, deFreitas, & Gordon, 2001; Doucet, de Freitas, Murphy, & Russell,2000b). shown sampling subspace combined exact inference (RaoBlackwellised Particle Filtering) yields better approximation Particle Filteringfull set variables. However, objective study limited observationeffect special cases variables integrated easily.cutset sampling scheme offers generic approach collapsing Gibbs samplerBayesian network.6. Conclusionpaper presents w-cutset sampling scheme, general scheme collapsing Gibbssampler Bayesian networks. showed theoretically empirically cutset sampling improves convergence rate allows sampling non-ergodic networkergodic subspace. collapsing sampling set, reduce dependencesamples marginalising highly correlated variables smoothingsampling distributions remaining variables. estimators obtained sampling43fiBidyuk & Dechterlower-dimensional space also lower sampling variance. Using inducedwidth w controlling parameter, w-cutset sampling provides mechanism balancingsampling exact inference.studied power cutset sampling sampling set loop-cutset and,generally, sampling set w-cutset network (defined subsetvariables that, instantiated, induced width network w). BasedRao-Blackwell theorem, cutset sampling requires fewer samples regular samplingconvergence. experiments showed reduction number samplestime-wise cost-effective. confirmed range randomly generated realbenchmarks. also demonstrated cutset sampling superior state artAIS-BN importance sampling algorithm probability evidence small.Since size cutset correlations variables two mainfactors contributing speed convergence, w-cutset sampling may optimized advancement methods finding minimal w-cutset. Another promisingdirection future research incorporate heuristics avoiding selecting stronglycorrelated variables cutset since correlations driving factors speedconvergence Gibbs sampling. Alternatively, could combine sample collapsingblocking.summary, w-cutset sampling scheme simple yet powerful extension samplingBayesian networks likely dominate regular sampling sampling method.focused Gibbs sampling better convergence characteristics, samplingschemes implemented cutset sampling principle. particular,adapted use likelihood weighting (Bidyuk & Dechter, 2006).ReferencesAbdelbar, A. M., & Hedetniemi, S. M. (1998). Approximating maps belief networksNP-hard theorems. Artificial Intelligence, 102, 2138.Andrieu, C., de Freitas, N., & Doucet, A. (2002). Rao-Blackwellised particle filtering viadata augmentation. Advances Neural Information Processing Systems. MITPress.Arnborg, S. A. (1985). Efficient algorithms combinatorial problems graphsbounded decomposability - survey. BIT, 25, 223.Becker, A., Bar-Yehuda, R., & Geiger, D. (2000). Random algorithms loop cutsetproblem. Journal Artificial Intelligence Research, 12, 219234.Bertele, U., & Brioschi, F. (1972). Nonserial Dynamic Programming. Academic Press.Bidyuk, B., & Dechter, R. (2003). Empirical study w-cutset sampling Bayesian networks. Proceedings 19th Conference Uncertainty Artificial Intelligence(UAI), pp. 3746. Morgan Kaufmann.Bidyuk, B., & Dechter, R. (2004). finding minimal w-cutset problem. Proceedings20th Conference Uncertainty Artificial Intelligence (UAI), pp. 4350.Morgan Kaufmann.44fiCutset Sampling Bayesian NetworksBidyuk, B., & Dechter, R. (2006). Cutset Sampling Likelihood Weighting. Proceedings 22nd Conference Uncertainty Artificial Intelligence (UAI), pp.3946. Morgan Kaufmann.Billingsley, P. (1968). Convergence Probability Measures. John Wiley & Sons, New York.Casella, G., & Robert, C. P. (1996). Rao-Blackwellisation sampling schemes. Biometrika,83 (1), 8194.Cheng, J., & Druzdzel, M. J. (2000). AIS-BN: adaptive importance sampling algorithmevidenctial reasoning large baysian networks. Journal Aritificial IntelligenceResearch, 13, 155188.Cooper, G. (1990). computational complexity probabilistic inferences. ArtificialIntelligence, 42, 393405.Dagum, P., & Luby, M. (1993). Approximating probabilistic inference Bayesian beliefnetworks NP-hard. Artificial Intelligence, 60 (1), 141153.Dechter, R. (1999a). Bucket elimination: unifying framework reasoning. ArtificialIntelligence, 113, 4185.Dechter, R. (1999b). Bucket elimination: unifying framework reasoning. ArtificialIntelligence, 113 (12), 4185.Dechter, R. (2003). Constraint Processing. Morgan Kaufmann.Doucet, A., & Andrieu, C. (2001). Iterative algorithms state estimation jump Markovlinear systems. IEEE Trans. Signal Processing, 49 (6), 12161227.Doucet, A., Andrieu, C., & Godsill, S. (2000a). sequential Monte Carlo sampling methods Bayesian filtering. Statistics Computing, 10 (3), 197208.Doucet, A., de Freitas, N., Murphy, K., & Russell, S. (2000b). Rao-Blackwellised particlefiltering dynamic Bayesian networks. Proceedings 16th ConferenceUncertainty Artificial Intelligence (UAI), pp. 176183.Doucet, A., deFreitas, N., & Gordon, N. (2001). Sequential Monte Carlo Methods Practice.Springer-Verlag, New York, Inc.Doucet, A., Gordon, N., & Krishnamurthy, V. (1999). Particle filters state estimation jump markov linear systems. Tech. rep., Cambridge University EngineeringDepartment.Escobar, M. D. (1994). Estimating normal means iwth dirichlet process prior. JournalAmerican Statistical Aasociation, 89, 268277.Frey, B. J., & MacKay, D. J. C. (1997). revolution: Belief propagation graphscycles. Neural Information Processing Systems, Vol. 10.Fung, R., & Chang, K.-C. (1989). Weighing integrating evidence stochastic simulation Bayesian networks. Proceedings 5th Conference UncertaintyArtificial Intelligence (UAI), pp. 209219. Morgan Kaufmann.Geiger, D., & Fishelson, M. (2003). Optimizing exact genetic linkage computations. Proceedings 7th Annual International Conf. Computational Molecular Biology,pp. 114121. Morgan Kaufmann.45fiBidyuk & DechterGelfand, A., & Smith, A. (1990). Sampling-based approaches calculating marginal densities. Journal American Statistical Association, 85, 398409.Geman, S., & Geman, D. (1984). Stochastic relaxations, Gibbs distributionsBayesian restoration images. IEEE Transaction Pattern analysis MachineIntelligence, 6, 721742.Geyer, C. J. (1992). Practical Markov Chain Monte Carlo. Statistical Science, 7, 473483.Gilks, W., Richardson, S., & Spiegelhalter, D. (1996). Markov chain Monte Carlo practice.Chapman Hall.Gottlob, G., Leone, N., & Scarello, F. (1999). comparison structural CSP decompositionmethods. Proceedings 16th International Joint Conference ArtificialIntelligence (IJCAI), pp. 394399. Morgan Kaufmann.Jensen, C., Kong, A., & Kjrulff, U. (1995). Blocking Gibbs sampling large probabilistic expert systems. Int. J. Human Computer Studies. Special Issue RealWorld Applications Uncertain Reasoning, 42 (6), 647666.Jensen, F. V., Lauritzen, S. L., & Olesen, K. G. (1990). Bayesian updating causalprobabilistic networks local computation. Computational Statistics Quarterly, 4,269282.Jones, G., & Hobert, J. P. (2001). Honest exploration intractable probability distributionsvia Markov Chain Monte Carlo. Statist. Sci., 16 (4), 312334.Kask, K., Dechter, R., Larrosa, J., & Dechter, A. (2005). Unifying cluster-tree decompositions reasoning graphical models. Artificial Intelligence, 166, 165193.Kjrulff, U. (1995). HUGS: Combining exact inference Gibbs sampling junctiontrees. Proceedings 11th Conference Uncertainty Artificial Intelligence(UAI), pp. 368375. Morgan Kaufmann.Koller, D., Lerner, U., & Angelov, D. (1998). general algorithm approximate inferenceapplication hybrid Bayes nets. Proceedings 14th ConferenceUncertainty Artificial Intelligence (UAI), pp. 324333.Kong, A., Liu, J. S., & Wong, W. (1994). Sequential imputations Bayesian missingdata problems. J. American Statistical Association, 89 (425), 278288.Kschischang, F. R., & Frey, B. J. (1998). Iterative decoding compound codes probability propagation graphical models. IEEE Journal Selected Areas Communications, 16, 219230.Larrosa, J., & Dechter, R. (2003). Boosting search variable elimination constraintoptimization constraint satisfaction problems. Constraints, 8 (3), 303326.Lauritzen, S., & Spiegelhalter, D. (1988). Local computation probabilities graphicalstructures application expert systems. Journal Royal StatisticalSociety, Series B, 50(2), 157224.Liu, J. (1991). Correlation Structure Convergence Rate Gibbs Sampler, Ph.D.Thesis. University Chicago.46fiCutset Sampling Bayesian NetworksLiu, J. (1994). collapsed Gibbs sampler Bayesian computations applicationsgene regulation problem. Journal American Statistical Association, 89 (427),958966.Liu, J., Wong, W., & Kong, A. (1994). Covariance structure Gibbs samplerapplications comparison estimators augmentation schemes. Biometrika,81 (1), 2740.Liu, J. S. (1996). Nonparametric hierarchical bayes via sequential imputations. AnnalsStatistics, 24 (3), 911930.Liu, J. S. (2001). Monte Carlo Strategies Scientific Computing. Springer-Verlag, NewYork, Inc.MacEachern, S., Clyde, M., & Liu, J. (1998). Sequential importance sampling nonparametric bayes models: next generation. Canadian Journal Statistics, 27,251267.MacEachern, S. N. (1994). Estimating normal means conjugate style dirichlet processprior. Communications Statistics-Simulation Computation, 23 (3), 727741.MacKay, D. (1996). Introduction Monte Carlo methods. Proceedings NATO Advanced Study Institute Learning Graphical Models. Sept 27-Oct 7, pp. 175204.Maier, D. (1983). theory relational databases. Computer Science Press, Rockville,MD.McEliece, R., MacKay, D., & Cheng, J.-F. (1997). Turbo decoding instance Pearlsbelief propagation algorithm. IEEE J. Selected Areas Communication, 16, 140152.Miller, R., Masarie, F., & Myers, J. (1986). Quick medical reference (QMR) diagnosticassistance. Medical Computing, 3 (5), 3438.Miller, R., Pople, H., & Myers, J. (1982). Internist-1: experimental computerbaseddiagnostic consultant general internal medicine. New English Journal Medicine,307 (8), 468476.Murphy, K. P., Weiss, Y., & Jordan, M. I. (1999). Loopy belief propagation approximateinference: empirical study. Proceedings 15th Conference UncertaintyArtificial Intelligence (UAI), pp. 467475. Morgan Kaufmann.Parker, R., & Miller, R. (1987). Using causal knowledge create simulated patient cases:CPCS project extension INTERNIST-1. Proceedings 11th Symp.Comp. Appl. Medical Care, pp. 473480.Pearl, J. (1988). Probabilistic Reasoning Intelligent Systems. Morgan Kaufmann.Peot, M. A., & Shachter, R. D. (1992). Fusion propagation multiple observationsbelief networks. Artificial Intelligence, 48, 299318.Pradhan, M., Provan, G., Middleton, B., & Henrion, M. (1994). Knowledge engineeringlarge belief networks. Proceedings 10th Conference Uncertainty ArtificialIntelligence, Seattle, WA, pp. 484490.Rish, I., Kask, K., & Dechter, R. (1998). Empirical evaluation approximation algorithmsprobabilistic decoding. Proceedings 14th Conference UncertaintyArtificial Intelligence (UAI), pp. 455463. Morgan Kaufmann.47fiBidyuk & DechterRoberts, G. O., & Sahu, S. K. (1997). Updating schemes; correlation structure; blockingparameterization Gibbs sampler. Journal Royal Statistical Society,Series B, 59 (2), 291317.Roberts, G. O., & Tweedie, R. L. (1999). Bounds regeneration times convergencerates Markov chains. Stochastic Processes Applications, 80, 211229.Roberts, G. O., & Tweedie, R. L. (2001). Corregendum bounds regeneration timesconvergence rates Markov chains. Stochastic Processes Applications, 91,337338.Rosenthal, J. S. (1995). Convergence rates Markov Chains. SIAM Review, 37 (3), 387405.Rosti, A.-V., & Gales, M. (2004). Rao-Blackwellised Gibbs sampling switching lineardynamical systems. IEEE International Conference Acoustics, Speech,Signal Processing (ICASSP 2004), pp. 809812.Schervish, M., & Carlin, B. (1992). convergence successive substitution sampling.Journal Computational Graphical Statistics, 1, 111127.Shachter, R. D., Andersen, S. K., & Solovitz, P. (1994). Global conditioning probabilisticinference belief networks. Proceedings 10th Conference UncertaintyArtificial Intelligence (UAI), pp. 514522.Shachter, R. D., & Peot, M. A. (1989). Simulation approaches general probabilisticinference belief networks. Proceedings 5th Conference UncertaintyArtificial Intelligence (UAI), pp. 221231.Steiger, N. M., & Wilson, J. R. (2001). Convergence properties batch means methodsimulation output analysis. INFORMS Journal Computing, 13 (4), 277293.Tierney, L. (1994). Markov chains exploring posterior distributions. Annals Statistics,22 (4), 17011728.Yuan, C., & Druzdzel, M. (2003). importance sampling algorithm based evidencepre-propagation. Proceedings 19th Conference Uncertainty ArtificialIntelligence (UAI), pp. 624631.Zhang, N., & Poole, D. (1994). simple algorithm Bayesian network computations.Proceedings 10th Canadian Conference Artificial Intelligence, pp. 171178.48fiJournal Artificial Intelligence Research 28 (2007) 299-348Submitted 07/06; published 03/07Supporting Temporal Reasoning MappingCalendar Expressions Minimal Periodic SetsClaudio BettiniSergio Mascettibettini@dico.unimi.itmascetti@dico.unimi.itDipartimento di Informatica e Comunicazione, Universita di MilanoVia Comelico, 39, 20135, Milan, ItalyX. Sean WangSean.Wang@uvm.eduDepartment Computer Science, University Vermont33 Colchester Avenue, Burlington, VT, 05405 USAAbstractrecent years several research efforts focused concept time granularity applications. first stream research investigated mathematical modelsbehind notion granularity algorithms manage temporal data basedmodels. second stream research investigated symbolic formalisms providing setalgebraic operators define granularities compact compositional way. However, limited manipulation algorithms proposed operate directlyalgebraic representation making unsuitable use symbolic formalismsapplications need manipulation granularities.paper aims filling gap results two streams research,providing efficient conversion algebraic representation equivalentlow-level representation based mathematical models. addition, conversionreturns minimal representation terms period length. results majorpractical impact: users easily define arbitrary granularities terms algebraicoperators, access granularity reasoning services operating efficientlyequivalent, minimal low-level representation. example, illustrateapplication temporal constraint reasoning multiple granularities.technical point view, propose hybrid algorithm interleavesconversion calendar subexpressions periodical sets minimization period length. algorithm returns set-based granularity representations minimalperiod length, relevant parameter performance considered reasoning services. Extensive experimental work supports techniques usedalgorithm, shows efficiency effectiveness algorithm.1. IntroductionAccording 2006 research Oxford University Press, word time foundcommon noun English language, considering diverse sourcesInternet including newspapers, journals, fictions weblogs. somehow surprisingamong 25 common nouns find time granularities like day, week, monthyear. pretty sure many time granularities like business day, quarter,semester, etc. would found quite frequently used natural languages. However,way computer applications deal concepts still naive mostly hidden program code and/or based limited sometimes imprecise calendar support.c2007AI Access Foundation. rights reserved.fiBettini, Mascetti & WangTemporal representation reasoning long time AI research topic aimedproviding formal framework common sense reasoning, natural language understanding, planning, diagnosis many complex tasks involving time data management.Despite many relevant contributions, time granularity representation reasoningsupport often ignored over-simplified. active area temporalconstraint satisfaction, proposals implicitly assumed adding support granularity trivial extension. quite recently recognizedcase specific techniques proposed (Bettini, Wang, & Jajodia, 2002a). Evenintuitively simple task deciding whether specific instant part time granularitytricky arbitrary user-defined granularities like e.g., banking days, academicsemesters considered.Granularities periodic patterns terms granularities playing role evenemerging application areas like inter-organizational workflows personal informationmanagement (PIM). example, inter-organizational workflows need model monitorconstraints like: Event2 occur later two business days occurrenceEvent1. context PIM, current calendar applications, even mobile devices,allow user specify quite involved periodical patterns recurrence events.example, possible schedule event every last Saturday every two months.complexity supported patterns increasing last years, currentsimple interfaces showing limits. essentially based combinationrecurrences based one two granularities taken fixed set (days, weeks, months,years). foresee possibility significant extensions applicationsspecifying recurrences user-defined granularities. example, user may define (orupload granularity library) granularity corresponding academic semesterschool teaching at, set date finals last Mondaysemester. bank may want define banking days granularity bankpolicies may formalized recurrences terms granularity. Automaticallygenerated appointments policies may appear devices bank employeesinvolved specific procedures. also foresee need show user preferred viewcalendar. current standard applications user choice businessday limited view complete view, enabling view based userssconsulting-days, example? new perspective use mobile devices may also resultconsidering time span activities supposed executed (expressedarbitrary granularities), software agents board alert constraintsmay violated, even based contextual information like user location trafficconditions. scenario highlights three main requirements: a) sufficiently expressiveformal model time granularity, b) convenient way define new time granularities,c) efficient reasoning tools time granularities.Consider a). last decade significant efforts made provide formalmodels notion time granularity devise algorithms manage temporaldata based models. addition logical approaches (Montanari, 1996; Combi,Franceschet, & Peron, 2004), framework based periodic-set representationsextensively studied (Bettini, Wang, & Jajodia, 2000), recently approach basedstrings automata introduced (Wijsen, 2000; Bresolin, Montanari, & Puppis,2004). mostly interested last two approaches support effective300fiMapping Calendar Expressions Minimal Periodic Setscomputation basic operations time granularities. cases representationgranularities considered low-level one, rather involved specificationterms instants time domain.Consider requirement b) above. Users may hard time defining granularitiesformalisms based low-level representations, interpret output operations.clearly unreasonable ask users specify granularities linear equationsmathematical formalisms operate directly terms instants granules fixedtime granularity. Hence, second stream research investigated high-level symbolicformalisms providing set algebraic operators define granularities compactcompositional way. efforts task started even research formalmodels granularity (Leban, McDonald, & Forster, 1986; Niezette & Stevenne, 1992)continued parallel stream research (Bettini & Sibi, 2000; Ning, Wang, & Jajodia,2002; Terenziani, 2003; Urgun, Dyreson, Snodgrass, Miller, Soo, Kline, & Jensen, 2007).Finally, let us consider requirement c) above. Several inferencing operationsdefined low-level representations, including equivalence, inclusion granulesdifferent granularities, even complex inferencing services like constraint propagation(Bettini et al., 2002a). Even simple operations general method available operatingdirectly high level representation. Indeed, cases, proposed methodscannot exploit structure expression require enumeration granules,may inefficient. case, example, granule conversionmethods presented Ning e at. (2002). Moreover, aware methodperform operations, equivalence intersection sets granules, directlyterms high level representation.major goal paper provide unique framework satisfy requirementsa), b), c) identified above, adding existing results smart efficienttechnique convert granularity specifications high-level algebraic formalismlow-level one, many reasoning tools available. particular, paperfocus conversion high-level formalism called Calendar Algebra (Ninget al., 2002) low-level formalism based periodical sets (Bettini et al., 2000, 2002a).Among several proposals high-level (algebraic) specification granularities,choice Calendar Algebra two main motivations: first, allows user expresslarge class granularities; comparison expressiveness Calendar Algebraformalisms see (Bettini et al., 2000). Second, provides richest setalgebraic operations designed reflect intuitive ways users definenew granularities. discussion actual usability tool couldenhanced graphical user interface found Section 6.2. choicelow-level formalism based periodic-sets also two main motivations: first,efficient implementation basic operations already exists extensivelyexperimented (Bettini, Mascetti, & Pupillo, 2005); second, one currentlysupporting complex operations granularities needed constraint satisfaction,illustrated detail Section 6.1.technical contribution paper hybrid algorithm interleaves conversion calendar subexpressions periodical sets step period minimization.central phase conversion procedure derive, algebraic subexpression,periodicity output set. periodicity used build periodical represen301fiBettini, Mascetti & Wangtation subexpression recursively used operand expressions.Given calendar algebra expression, algorithm returns set-based granularity representations minimal period length. period length relevant parameterperformance basic operations granularities specialized oneslike operations used constraint satisfaction service. Extensive experimental workreported paper validates techniques used algorithm, showing, amongthings, (1) even large calendar expressions efficiently converted, (2)less precise conversion formulas may lead unacceptable computation time. latterproperty shows importance carefully accurately designed conversion formulas.Indeed, conversion formulas may seem trivial length periodicity concern.designing conversion formulas, made effort reduce period lengthresulting granularity representation, thus render whole conversion process computationally efficient.next section define granularities; several interesting relationships amonghighlighted periodical set representation formalized. Section 3 defineCalendar Algebra present operations. Section 4 describe conversionprocess: definition three steps necessary conversion, algebraicoperation present formulas perform step. Section 5 discuss periodminimality issue, report experimental results based full implementationconversion algorithm extension ensuring minimality. Section 6motivate work presenting complete application scenario. Section 7 reportsrelated work, Section 8 concludes paper.2. Formal Notions Time GranularitiesTime granularities include common ones like hours, days, weeks, months years,well evolution specialization granularities specific contextsapplications. Trading days, banking days, academic semesters examplesspecialization granularities become quite common describing policiesconstraints.2.1 Time Granularitiescomprehensive formal study time granularities relationships found(Bettini et al., 2000). paper, introduce notions essentialshow results. particular, report notion labeled granularityproposed specification calendar algebra (Bettini et al., 2000; Ning et al., 2002);show later labeled granularity reduced standard notiongranularity, like one used Bettini et al. (2002a).Granularities defined grouping sets instants granules. example,granule granularity day specifies set instants included particular day.label used refer particular granule. whole set time instants called timedomain, purpose paper domain arbitrary infinite settotal order relationship, .302fiMapping Calendar Expressions Minimal Periodic SetsDefinition 1 labeled granularity G pair (LG , ), LG subsetintegers, mapping LG subsets time domainpair integers j LG < j, (i) 6= (j) 6= , (1) element(i) less every element (j), (2) integer k LG < k < j,(k) 6= .former condition guarantees monotonicity granularity; latterused introduce bounds (see Section 2.2).call LG label set LG call G(i) granule; G(i) 6= callnon-empty granule. LG exactly integers, granularity called fullinteger labeled. LG = Z+ notion granularity used severalapplications, e.g., (Bettini et al., 2002a). example, following labeling schema,assume map day(1) subset time domain corresponding January 1,2001, day(32) would mapped February 1, 2001, b-day(6) January 8, 2001 (thesixth business day), month(15) March 2002. generalization arbitrary labelsets introduced mainly facilitate conversion operations algebra, howeverfinal goal conversion labeled granularity denoted calendar expressionpositive-integer labeled one denoted periodic formula.2.2 Granularity Relationshipsinteresting relationships granularities follows. definitions extendedones presented Bettini et al. (2000) cover notion labeled granularity.Definition 2 G H labeled granularities, G said group H, denotedG / H, non-emptygranule H(j), exists (possibly infinite) set labelsG H(j) = G(i).Intuitively, G / H means granule H union granules G.example, day / week since week composed 7 days day / b-day since businessday day.Definition 3 G H labeled granularities, G said finer H,denoted G H, granule G(i), exists granule H(j) G(i) H(j).example business-day finer day, also finer week.also say G partitions H G / H G H. Intuitively G partitions HG / H granules G included granules H.example, day b-day group b-week (business week, i.e., business dayweek), day partition b-week, b-day does.Definition 4 labeled granularity G1 label-aligned subgranularity labeled granularity G2 label set LG1 G1 subset label set LG2 G2LG1 G1 (i) 6= , G1 (i) = G2 (i).Intuitively, G1 subset granules G2 granules labeltwo granularities.303fiBettini, Mascetti & WangGranularities said bounded LG first last element G(i) =LG . assume existence unbounded bottom granularity, denotedfull-integer labeled groups every granularity system.time domains that, given set granularities, always possiblefind bottom one; example, easily proved property holdstime domain cardinality integers. hand,property hold time domains (e.g. reals). However, assumptionexistence bottom granularity still reasonable since address problemsgranularities defined starting bottom one. definition calendarset granularities bottom granularity (Bettini et al., 2000) capturesidea.2.3 Granularity Conversionsdealing granularities, often need determine granule (if any)granularity H covers given granule z another granularity G. example,may wish find month (an interval absolute time) includes given week(another interval absolute time).transformation obtained operation. Formally, label z LG ,H00dzeG undefined @z 0 LH s.t. G(z) H(z 0 ) ; otherwise, dzeHG = z , z00unique index value G(z) H(z ). uniqueness z guaranteedmonotonicity 1 granularities. example, dzemonthsecond gives month includesmonthsecond z. Note dzesecond always defined, dzemonthweek undefined weekz falls two months. Note G H, function dzeHG definedweekindex value z. example, since day week, dzeday always defined, i.e.,day find week contains it. notation dzeH used sourcegranularity left implicit (e.g., dealing fixed set granularitiesdistinguished bottom granularity).Another direction transformation operation: Let G HHgranularitiesG / H, z an2 integer. Define bzcG set labelsgranules G jS G(j) = H(z). function useful finding, e.g.,days month.2.4 Periodical Granules Representationcentral issue temporal reasoning possibility finitely representing infinite granularities. definition granularity provided general expressive mayimpossible provide finite representation granularities. Even labels(i.e., subset integers) necessarily finite representation.solution first proposed Bettini et al. (2000). ideacommonly used granularities present periodical behavior; means certainpattern repeats periodically. feature exploited provide method1. Condition (1) Definition 1.2. definition different one given Bettini et al (2000) since also considers non contiguousgranules G.304fiMapping Calendar Expressions Minimal Periodic Setsfinitely describing granularities. formal definition based periodically groupsrelationship.Definition 5 labeled granularity G groups periodically labeled granularity H(G / H) G / H exist positive integers N P(1) label H, + N label H unless + N greater greatestlabel H,(2) label H, H(i) = kr=0 G(jr ) H(i + N ) non-empty granuleH H(i + N ) = kr=0 G(jr + P ),(3) H(s) first non-empty granule H (if exists), H(s + N ) non-empty.groups periodically relationship special case group characterizedperiodic repetition grouping pattern granules G granules H.definition may appear complicated actually quite simple. Since G groups H,granule H(i) union granules G; instance assume uniongranules G(a1 ), G(a2 ), . . . , G(ak ). Condition (1) ensures label + N exists (ifgreater greatest label H) condition (2) ensures that, H(i + N )empty, union G(a1 + P ), G(a2 + P ), . . . , G(ak + P ). assumer = 0 . . . k, (jr + P ) LG ; not, conditions considered satisfied. Condition(3) simply says least one repetitions.call pair P N Definition 5, period length associated periodlabel distance. also indicate R number granules H correspondinggroups P consecutive granules . formally R equal number labelsH greater equal smaller + N arbitrary label H. NoteR affected value i.period length period label distance unique; precisely,G period labelindicate PHG period length H terms G NHdistance H terms G; form PH NH used G = . Noteperiod length integer value. simplicity also indicate one periodgranularity H set R consecutive granules H.general, periodically groups relationship guarantees granularity Hfinitely described (in terms granules G).Definition 6 G / H, H finitely described providing: (i) value PPN ; (ii) set LP labels Hone period H; (iii) L , finite setSa labels G, H(a) = iSa G(i); (iv) labels first last non-emptygranules H, values infinite.representation, granules labels LP ones needexplicitly represented; call granules explicit granules.granularity H represented periodic set granules granularity G,G ) periodically groupsexists infinite number pairs (PHG , NHrelation satisfied. relation satisfied pair (P, N ), provedalso satisfied pair (P, N ) N+ .305fiBettini, Mascetti & WangDefinition 7 periodic representation granularity H terms G called minimalperiod length P used representation smallest value among periodG ) H periodically groups G.lengths appearing pairs (PHG , NHH fully characterized terms G, possible derive composition,terms G, granule H. Indeed, LP set labels H valuesG 1}, assume H unbounded, description arbitrary{b, . . . , b + NHG] + 1granule H(j) obtained following formula. Given j 0 = [(j 1) mod NHkkjjb1b1G + j0G + j0 bNNHGGHNHNHk=kjb1+ 1 N G + j 0 otherwiseGNHHH(j) =[GPHGiSkk1j1G+ PH.GGNHNHExample 1 Figure 1 shows granularities day week parts i.e., granularity that,week, contains granule working days granule weekend.sake simplicity, denote day week parts W respectively. Since/ W , W fully characterized terms D. Among different possible representations,= 7, N = 2, LP = {3, 4},example decide represent W terms PWWWS3 = {8, 9, 10, 11, 12} S4 = {13, 14}. composition granule Weasily computed; example composition W (6) given formula presentedj 0 = 2 k = 4. Hence W (6) = D(7 2 + 13 7 1) D(7 2 + 14 7 1) =D(20) D(21).-1 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30jbk234jW15678Figure 1: Periodically groups example3. Calendar AlgebraSeveral high-level symbolic formalisms proposed represent granularities (Lebanet al., 1986; Niezette & Stevenne, 1992).work consider formalism proposed Ning et al. (2002) called CalendarAlgebra. approach set algebraic operations defined; operation generatesnew granularity manipulating granularities already generated.relationships operands resulting granularities thus encodedoperations. granularities generated directly indirectly bottomgranularity form calendar, granularities related306fiMapping Calendar Expressions Minimal Periodic Setsoperations define them. practice, choices bottom granularity include day,hour, second, microsecond granularities, depending accuracy requiredapplication context.following illustrate calendar algebra operations presented Ning et al.(2002) together restrictions introduced Bettini et al. (2004).3.1 Grouping-Oriented Operationscalendar algebra consists following two kinds operations: grouping-orientedoperations granule-oriented operations. grouping-oriented operations groupcertain granules granularity together form new granules new granularity.3.1.1 Grouping OperationLet G full-integer labeled granularity, positive integer. grouping operationGroupm (G) generates new granularity G0 partitioning granules G m-granulegroups making group granule resulting granularity. precisely, G0 =Groupm (G) granularity integer i,im[G0 (i) =G(j).j=(i1)m+1example, given granularity day, granularity week generated calendaralgebra expression week = Group7 (day) assume day(1) corresponds Monday,i.e., first day week.3.1.2 Altering-tick OperationLet G1 , G2 full-integer labeled granularities, l, k, integers, G2 partitions(G , G ) generates new granularityG1 , 1 l m. altering-tick operation Alterl,k21periodically expanding shrinking granules G1 terms granules G2 . Since G2partitions G1 , granule G1 consists contiguous granules G2 . granulesG1 partitioned m-granule groups G1 (1) G1 (m) one group,G1 (m + 1) G1 (2m) following group, on. goal altering-tickoperation modify granules G1 l-th granule every m-granule group|k| additional (or fewer k < 0) granules G2 . example, G1 represents30-day groups (i.e., G1 = Group30 (day)) want add day every 3-rd month(i.e., make March 31 days), may perform Alter123,1 (day, G1 ).altering-tick operation formally described follows. integerG1 (i) 6= , let bi ti integers G1 (i) = tj=bG2 (j) (the integers bi0ti exist G2 partitions G1 ). G = Alterl,k (G2 , G1 ) granularityinteger i, let G0 (i) = G1 (i) = , otherwise let00G (i) =ti[j=b0i307G2 (j),fiBettini, Mascetti & Wangb0i=bi + (h 1) k, = (h 1) + l,bi + h k,otherwise,t0i = ti + h k,il+ 1.h=Example 2 Figure 2 shows example Alter operation. Granularity G1 definedG1 = Group5 (G2 ) granularity G0 defined G0 = Alter22,1 (G2 , G1 ), meansshrinking second one every two granules G1 one granule G2 .G2-9 -8 -7 -6 -5 -4 -3 -2 -1 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21G1-101234G-101234Figure 2: Altering-tick operation exampleoriginal definition altering-tick given Ning et al. (2002) reported above,following problems arbitrary negative value k used: (1) allowsdefinition G0 full-integer labeled granularity (2) allowsdefinition G0 even satisfy definition granularity. order avoidundesired behavior, impose following restriction:k > (mindist(G1, 2, G2) 1)mindist() formally defined Bettini et al. (2000).Intuitively, mindist(G1, 2, G2) represents minimum distance (in terms granulesG2) two consecutive granules G1.3.1.3 Shift OperationLet G full-integer labeled granularity, integer. shifting operationShiftm (G) generates new granularity G0 shifting labels G positions.formally, G0 = Shiftm (G) granularity integer i, G0 (i) = G(i m).Note G0 also full-integer labeled.3.1.4 Combining OperationLet G1 G2 granularities label sets LG1 LG2 respectively. combiningoperation Combine(G1 , G2 ) generates new granularity G0 combining granulesG2 included one granule G1 one granule G0 . formally,L1 , let s(i) = G1 (i) = , otherwise let s(i) = {j LG2 | =6 G2 (j) G1 (i)}.308fiMapping Calendar Expressions Minimal Periodic SetsG0 = Combine(G1 , G2 ) granularitylabel set LG0 = {i LG1 |s(i) 6= }LG0 , G0 (i) = js(i) G2 (j).example, given granularities b-day month, granularity business monthsgenerated b-month = Combine(month, b-day).3.1.5 Anchored Grouping OperationLet G1 G2 granularities label sets LG1 LG2 respectively, G2label-aligned subgranularity G1 , G1 full-integer labeled granularity. anchoredgrouping operation Anchored-group(G1 , G2 ) generates new granularity G0 combininggranules G1 two granules G2 one granule G0 .formally, G0 = Anchored-group(G1 , G2 ) granularity label set LG0 = LG20 1G1 (j) i0 next label G2 i.LG0 , G0 (i) = ij=iexample, academic year certain university begins last MondayAugust, ends day beginning next academic year. Then,granularity corresponding academic years generated AcademicY ear =Anchored-group(day, lastMondayOfAugust).3.2 Granule-Oriented OperationsDifferently grouping-oriented operations, granule-oriented operationsmodify granules granularity, rather enable selection granulesremain new granularity.3.2.1 Subset OperationLet G granularity label set LG , m, n integers n. subsetoperation G0 = Subsetnm (G) generates new granularity G0 taking granulesG whose labels n. formally, G0 = Subsetnm (G) granularitylabel set LG0 = {i LG | n}, LG0 , G0 (i) = G(i).example, given granularity year, years 20th century generated020CenturyYear = Subset19991900 (year). Note G label-aligned subgranularity G,G0 full-integer labeled granularity even G is. also allow extensionssetting = n = semantics properly extended.3.2.2 Selecting Operationsselecting operations binary operations. generate new granularitiesselecting granules first operand terms relationship granulessecond operand. result always label-aligned subgranularity first operandgranularity.three selecting operations: select-down, select-up select-by-intersect.facilitate description operations, lk (S) notation used. Intuitively,set integers, lk (S) selects l elements starting k-th one (for formaldescription operator see (Ning et al., 2002)).Select-down operation. granule G2 (i), exits set granules G1contained G2 (i). operation Select-downlk (G1 , G2 ), k 6= 0 l > 0309fiBettini, Mascetti & Wangintegers, selects granules G1 using lk () set granules (actually labels)G1 contained one granule G2 . formally, G0 = Select-downlk (G1 , G2 )granularity label setLG0 = iLG2 lk ({j LG1 | 6= G1 (j) G2 (i)}),LG0 , G0 (i) = G1 (i). example, Thanksgiving days fourthThursdays Novembers; Thursday November given, generatedThanksgiving = Select-down14 (Thursday, November).Select-up operation. select-up operation Select-up(G1 , G2 ) generates new granularityG0 selecting granules G1 contain one granules G2 . formally,G0 = Select-up(G1 , G2 ) granularity label set6 G2 (j) G1 (i)), }LG0 = {i LG1 |j LG2 ( =LG0 , G0 (i) = G1 (i). example, given granularities Thanksgivingweek, weeks contain Thanksgiving days defined ThanxWeek =Select-up(week, Thanksgiving).Select-by-intersect operation. granule G2 (i), may exist set granules G1 ,intersecting G2 (i). Select-by-intersectlk (G1 , G2 ) operation, k 6= 0 l > 0integers, selects granules G1 applying lk () operator sets, generatingnew granularity G0 . formally, G0 = Select-by-intersectlk (G1 , G2 ) granularitylabel setLG0 = iLG2 lk ({j LG1 | G1 (j) G2 (i) 6= }),LG0 , G0 (i) = G1 (i). example, given granularities week month,granularity consisting first week month (among weeks intersectingmonth) generated FirstWeekOfMonth = Select-by-intersect11 (week, month).3.2.3 Set Operationsorder set operations part calendar algebra make certaincomputations easier, restrict operand granularities participating set operationsresult operation always valid granularity: set operationsdefined G1 G2 exists granularity H G1 G2label-aligned subgranularities H. following, describe union, intersection,difference operations G1 G2 , assuming satisfy requirement.Union. union operation G1 G2 generates new granularity G0 collectinggranules G1 G2 . formally, G0 = G1 G2 granularitylabel set LG0 = LG1 LG2 , LG0 ,G1 (i), L1 ,0G (i) =G2 (i), L2 L1 .example, given granularities Sunday Saturday, granularity weekend daysgenerated WeekendDay = Sunday Saturday.310fiMapping Calendar Expressions Minimal Periodic SetsIntersection. intersection operation G1 G2 generates new granularity G0 takingcommon granules G1 G2 . formally, G0 = G1 G2 granularitylabel set LG0 = LG1 LG2 , LG0 , G0 (i) = G1 (i) (or equivalentlyG2 (i)).Difference. difference operation G1 \ G2 generates new granularity G0 excludinggranules G2 G1 . formally, G0 = G1 \ G2 granularitylabel set LG0 = LG1 \ LG2 , LG0 , G0 (i) = G1 (i).4. Calendar Algebra Periodical Setsection first describe overall conversion process reportformulas specific conversion calendar algebra operation. Finally, presentprocedure relabeling resulting granularity, sketch complexity analysisconsiderations period length minimality.4.1 Conversion Processfinal goal provide correct effective way convert calendar expressionsperiodical representations. appropriate limitations, calendar algebraoperation, periodical descriptions operand granularities known, possiblecompute periodical characterization resulting granularity.result allows us calculate, calendar, periodical descriptiongranularity terms bottom granularity. fact, definition, bottom granularity fully characterized; hence possible compute periodical representationgranularities obtained operations applied bottom granularity.Recursively, periodical description granularities obtained.calendar algebra presented previous section represent granularitiesperiodical finite exceptions (i.e., granularity G bottom groupsperiodically finite exceptions G). Since periodical representations definedSection 2 possible express finite exceptions, need restrict calendaralgebra cannot represent them. implies allowing Subset operationused last step deriving granularity. Note calendar algebrapresented Ning et al. (2002) extension altering-tick operation allowusage parameter (i.e., G0 = Alterl,k (G2 , G1 )); resulting granularitysingle exception hence periodic. extension disallowed ordergenerate periodical granularities (without finite exceptions).conversion process divided three steps: first one period lengthperiod label distance computed; second derive set LP labels oneperiod, last one composition explicit granules computed.operation identify correct formulas algorithms three steps.first step consists computing period length period label distanceresulting granularity. values calculated function parameters (e.g.grouping factor m, Group operation) operand granularities (actuallyperiod lengths period label distances).311fiBettini, Mascetti & Wangsecond step conversion process identification label setresulting granularity. Section 2.4 pointed order fully characterizegranularity sufficient identify labels period granularity. spitetheoretical result, perform computations required operation needexplicit granules operand granularities aligned. two possibleapproaches: first one consist computing explicit granules periodrecalculate needed granules correct position order eventually alignthem. second one consists aligning periods containing explicit granulesfixed granule bottom granularity. considering possibilities,performance reasons, decided adopt second approach. decided use (1)alignment point granularities. formal definition used formalismfollows.Let G granularity smallest positive integer dieG defined.call lG = dieG LG set labels G contained lG . . . lG +NG 1. Notedefinition LG instance definition LP given Section 2.4. definitionLG provided useful representing G actually final goal stepcompute LG ; however LG suitable performing computations. problemG(lG ) starts (1) (i.e., min(blG cG ) < 1) granule G(lG + NG ) beginsPG PG , hence G(lG + NG ) necessary computations; howeverlG + NG/ LG .solve problem introduce symbol LG represent set labelsgranules G cover one (1) . . . (PG ). easily seen G(lG ) cover(0), LG = LG , otherwise LG = LG {lG + NG }. Therefore conversionL L vice versa immediate.notion L still enough perform computations. problemgranularity G used operand operation, period lengthresulting granularity G0 generally bigger period length G. Thereforenecessary extend notion LG period length PG0 G0 using PG0 spiteP 0PG definition L. symbol used notion LGG .P 0idea G used operand operation generates G0 , LGGcomputed LG . set used formula provide computeLG0 .computation LG0 performed follows: G0 defined operation0 .returns full-integer labeled granularity, sufficient compute value lG000Indeed easily seen LG0 = {i Z|lG lG + NG0 1}. G definedalgebraic operation, provide formulas compute LG0 ; LG0 easilyderive LG0 .Example 3 Figure 3 shows granularities , G H; clear PG = PH = 4NG = NH = 3. Moreover, lG = lH = 6 therefore LG = LH = {6, 7}. Since 0/ b6cGHLG = LG . hand, since 0 b6c , LH = LH {6 + 3}.P0Suppose granularity G0 period length PG0 = 8; LGG = {6, 7, 9, 10}P 0LHG = {6, 7, 9, 10, 12}.312fiMapping Calendar Expressions Minimal Periodic Sets^-6 -5 -4 -3 -2 -1 0 1 2 3 4 5 6 7 8 9 10G1346791012H1346791012 13Figure 3: L, l, L LPG0 examplesthird (and last) step conversion process computation composition explicit granules. LG0 computed, sufficient apply,label LG0 formulas presented Chapter 3.Sections 4.3 4.10 show, calendar algebra operation, computefirst second conversion steps.4.2 Computability Issuesformulas presented necessary compute set labelsgranularity G G(i) H(j) H granularity j specific labelH. Since LG contains infinite number labels, possible check, LGG(i) H(j). However easily seen k s.t. G(dkeG ) H(j). Thereforek s.t. G(dkeG ) defined k bjcH .Therefore compute set considering labels LG s.t. n bjcH s.t.dneG = G(i) H(j). Since set bjcH finite3 , computation performedfinite time. consideration analogous set G(i) H(j)(G(i) H(j) 6= ).4.3 Group OperationProposition 1 G0 = Groupm (G), then:PG1. PG0 = GCD(m,NNG0 =G)jklG 1+1;2. lG0 =3. LG0 G0 (i) =NGGCD(m,NG ) ;Simj=(i1)m+1 G(j).Example 4 Figure 4 shows example group operation: G0 = Group3 (G). SincePG = 1 NG = 1, PG0 = 3 NG = 1. Moreover, since LG = {7}, lG = 7therefore lG0 = 2 LG0 = {2}. Finally G0 (2) = G(8) G(7) G(6) i.e.,G0 (2) = (0) (1) (2).3. calendar algebra possible define granularities granules mapsinfinite set time instants.313fiBettini, Mascetti & Wang^-6 -5 -4 -3 -2 -1 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20G-14-13-12-11-10 -9 -8 -7 -6 -5 -4 -3 -2 -1 0 1 2 3 4 5 6 7 8 9 10 11 12G-4-3-2-101234Figure 4: Group operation example4.4 Altering-tick OperationProposition 2 G0 = Alterml,k (G2 , G1 ) then:1.NG0PG2 NG1NG2= lcm NG1 , m,,GCD(PG2 NG1 , PG1 ) GCD(NG2 m, |k|)PG0 =NG0 kNG0 PG1 NG2+NG1 PG2PG2NG202. lG0 = dlG2 eGG2 ;3. LG0 G0 (i) =St0ij=b0iG(j) b0i t0i defined Section 3.1.2.Referring step 2., note computing lG0 explicit characterization0granules G0 still unknown. perform operation dlG2 eGG2 need know leastexplicit granules one periods. choose compute granules labeled1 . . . NG0 . lG0 derived, granules labeled lG0 . . . lG0 + NG0 1 computedexplicit granules aligned (1) required.Example 5 Figure 5 shows example altering-tick operation: G0 = Alter32,1 (G2 , G1 ).Since PG1 = 4, NG1 = 1, PG2 = 4 NG2 = 2, NG0 = 6 PG0 = 28.G0 = 4Moreover, since LG2 = {10, 9}, lG2 = 10 therefore lG0 = d10eG2hence LG2 = {4, 3, . . . , 0, 1}. Finally G0 (4) = G1 (11) G1 (10) G1 (9) =(1) (0) (1) (3) (4); analogously derive G0 (3), G0 (2), G0 (1), G0 (0)G0 (1).4.5 Shift OperationProposition 3 G0 = Shiftm (G), then:1. PG0 = PG1 NG0 = NG1 ;2. lG0 = lG + m;3. LG0 G0 (i) = G(i m).314fiMapping Calendar Expressions Minimal Periodic Sets^-3 -2 -1 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41G1-5-4-3-2-1012345G2-11 -10-9-8-7-6-5-4-3-2-1012345678910G-4-3-2-101234Figure 5: Alter operation exampleExample 6 shifting operation easily model time differences. Suppose granularityUSEast-Hour stands hours US Eastern Time. Since hours US PacificTime 3 hours later US Eastern Time, hours US Pacific Timegenerated USPacific-Hour= Shift3 (USEast-Hour).USEast-Hour-6 -5 -4 -3 -2 -1 0 1 2 3 4 5 6 7 8USPacific-Hour-9 -8 -7 -6 -5 -4 -3 -2 -1 0 1 2 3 4 5Figure 6: Shift operation example4.6 Combining OperationProposition 4 Given G0 = Combining(G1 , G2 ), then:1. PG0 = lcm(PG1 , PG2 ) NG0 =P0Plcm(PG1 ,PG2 )NG1;PG1P002. LGG1 let se(i) = {j LGG2 | =6 G2 (j) G1 (i)}; LG0 = {i LGG1 |es(i) 6= };3. LG0 G0 (i) = js(i) G2 (j).Example 7 Figure 7 shows example combining operation: G0 = Combine(G1 , G2 ).Since PG1 = 6, NG1 = 2, PG2 = 4 NG2 = 2, PG0 = 12 NG0 = 4. Moreover,P 0since LG1 = {1} 0 b1cG1 , LG1 = {1, 3} hence LGG1 = {1, 3, 5}. Since0s(i) 6= {1, 3, 5}, LG0 = {1, 3, 5}; moreover, since 0 b1cG , LG0 = {1, 3}.Finally s(1) = {1, 0} s(3) = {2, 3}; consequently, G0 (1) = G2 (1) G2 (0) i.e.,G0 (1) = (1) (0) (1) G0 (3) = G2 (2) G2 (3) i.e., G0 (3) = (4) (5) (7).4.7 Anchored Grouping OperationProposition 5 Given G0 = Anchored-group(G1 , G2 ), then:1. PG0 = lcm(PG1 , PG2 ) NG0 =lcm(PG1 ,PG2 )NG2;PG2315fiBettini, Mascetti & Wang^-6 -5 -4 -3 -2 -1 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20G11357G2-3-2-10123456789G1357Figure 7: Combine operation example2.(LG0 =P0LGG2 ,lG2 = lG1 ,PG00{lG2 } LG2 , otherwise,0lGgreatest among labels LG2 smaller lG2 .23. LG0 G0 (i) =Si0 1j=iG1 (j) i0 next label G2 i.Example 8 Figure 8 shows example anchored grouping operation: USweek(i.e., week starting Sunday) defined operation Anchored-group(day,Sunday). Since Pday = 1 PSunday = 7, period length USweek 7. MorePUSweeksince lday = 11, lSunday = 14 LSunday= {14}, LUSweek = {7} {14}.Clearly, since 0 b7cUSweek LUSweek = {7}. Finally, USweek(7) = 13j=7 day(j) =S3k=3 (k).^-18-17-16-15-14-13-12-11-10 -9 -8 -7 -6 -5 -4 -3 -2 -1 0 1 2 3 4 5 6 7 8 9 10 11 12day-8 -7 -6 -5 -4 -3 -2 -1 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22Sunday-7071421USweek-70714Figure 8: Anchored Grouping operation example4.8 Subset OperationSubset operation modifies operand granularity introducing bounds.period length, period label distance, L composition explicit granulesaffected.316fiMapping Calendar Expressions Minimal Periodic Sets4.9 Selecting Operations4.9.1 Select-down OperationProposition 6 Given G0 = Select-downlk (G1 , G2 ), then:1. PG0 = lcm(PG1 , PG2 ) NG0 =2. LG2 letlcm(PG1 ,PG2 )NG1;PG16 G1 (j) G2 (i)}) .A(i) = lk ({j LG1 | =[ nP 0A(i)|a LGG1 ;LG0 =P 0iLGG23. LG0 G0 (i) = G1 (i).Example 9 Figure 9 shows example Select-down operation granularityG0 defined as: G0 = Select-down12 (G1 , G2 ). Since PG1 = 4, NG1 = 2 PG2 = 6PG0 = 12 NG0 = 6. Moreover, since LG2 = {3} 0 b3cG2 , LG2 =P 0{3, 2} LGG2 = {3, 2, 1}. Intuitively, A(3) = {5}, A(2) = {2}0A(1) = {1}. Hence LG0 = {5, 2, 1} therefore, since 0 b5cG , LG0 = {5, 2}.Finally G0 (5) = G1 (5) = (0) (1) G0 (2) = G1 (2) = (6).^-9 -8 -7 -6 -5 -4 -3 -2 -1 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25G1-9-8-7-6-5-4-3-2-101234567G2-4-3-2-101G-8-5-214Figure 9: Select-down operation example4.9.2 Select-up OperationProposition 7 Given G0 = Select-up(G1 , G2 ), then:1. PG0 = lcm(PG1 , PG2 ) NG0 =lcm(PG1 ,PG2 )NG1;PG12.P0LG0 = {i LGG1 |j LG2 s.t. =6 G2 (j) G1 (i)};3. LG0 G0 (i) = G1 (i).3177fiBettini, Mascetti & WangExample 10 Figure 10 shows example Select-up operation: G0 = Select-up(G1 , G2 ).Since PG1 = 6, NG1 = 3 PG2 = 4 PG0 = 12 NG0 = 6. Moreover, since LG1 =P0{3, 2, 1} 0 b3cG2 , LG1 = {3, 2, 1, 0} LGG1 = {3, 2, 1, 0, 1, 2, 3}.Since G1 (3) G2 (6), G1 (1) G2 (4) G1 (3) G2 (0) LG0 = {3, 1, 3}0and, since 0 b3cG , LG0 = {3, 1} Finally G0 (3) = G1 (3) = (0) (1)G0 (1) = G1 (1) = (4).^-9 -8 -7 -6 -5 -4 -3 -2 -1 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16G1-8 -7-6-5 -4-3-2 -101 234 5G2-10-8-6-4-202G-7-3-135Figure 10: Select-up operation example4.9.3 Select-by-intersect OperationProposition 8 Given G0 = Select-by-intersectlk (G1 , G2 ), then:1. PG0 = lcm(PG1 , PG2 ) NG0 =lcm(PG1 ,PG2 )NG1;PG12. LG2 letA(i) = lk ({j LG1 |G1 (j) G2 (i) 6= }) .LG0 =[ nP 0A(i)|a LGG1 .P 0iLGG23. LG0 G0 (i) = G1 (i).Example 11 Figure 11 shows example Select-by-intersect operationG0 = Select-by-intersect12 (G1 , G2 ). Since PG1 = 4, NG1 = 2 PG2 = 6 PG0 = 12NG0 = 6. Moreover, since LG2 = {3} 0 b3cG2 , LG2 = {3, 2}P 0LGG2 = {3, 2, 1}. Intuitively, A(3) = {6}, A(2) = {2} A(1) = {0}. Hence0LG0 = {2, 0} therefore, since 0/ b5cG , LG0 = {2, 0}. Finally G0 (2) =G1 (2) = (6) G0 (0) = G1 (0) = (10).318fiMapping Calendar Expressions Minimal Periodic Sets^-9 -8 -7 -6 -5 -4 -3 -2 -1 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25G1-9-8-7-6-5-4-3-2-101234567G2-4-3-2-101G-8-6-2046Figure 11: Select-by-intersect operation example4.10 Set OperationsSince set operation valid granularities used argument labeled alignedgranularity another granularity, following property used.Proposition 9 G labeled aligned subgranularity H,NGPG=NHPH .Proposition 10 Given G0 = G1 G2 , G00 = G1 G2 G000 = G1 \ G2 , then:1. PG0 = PG00 = PG000 = lcm(PG1 , PG2 )lcm(PG1 ,PG2 )NG1=NG0 = NG00 = NG000 =PG1P0P0P00Plcm(PG1 ,PG2 )NG2;PG200P000P0002. LG0 = LGG1 LGG2 ; LG00 = LGG1 LGG2 ; LG000 = LGG1 \ LGG2 ;G1 (i), LG103. LG0 G (i) =G2 (i), otherwise,LG00 G00 (i) = G1 (i) LG000 G000 (i) = G1 (i)Example 12 Figure 12 shows example set operations. Note G1G2 labeled aligned subgranularities H. G0 = G1 G2 , G00 = G1 G2G000 = G1 \ G2 . Since PG1 = PG2 = 6 NG1 = NG2 = 6 PG0 = PG00 = PG000 = 6NG0 = NG00 = NG000 = 2. Moreover, since LG1 = {1, 2} LG2 = {2, 3},LG0 = {1, 2, 3}, LG00 = {2} LG000 = {1}. Finally G0 (1) = G1 (1), G0 (2) = G1 (2)G0 (3) = G2 (3); G00 (2) = G1 (2) G000 (1) = G1 (1).4.11 RelabelingGranularity processing algorithms much simpler restricted operate full-integerlabeled granularities. Moreover, simplification obtained using positive integers set labels (i.e., L = Z+ ).section show relabel granularity G obtain full-integer labeledgranularity G0 . granularity G00 LG00 = Z+ obtained using G00 =0Subset1 (G )Note relabeling process information lost: example, Glabeled aligned subgranularity H G 6= H, then, relabeling, G319fiBettini, Mascetti & Wang^-9 -8 -7 -6 -5 -4 -3 -2 -1 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25H-3-2-1-2-1012123454567878910G110G2-3-10-10232356568989G-3-214710G-1258G-214710Figure 12: Set operations examplelabeled aligned subgranularity H. lost information semantically meaningfulcalendar algebra, therefore relabeling must performed granularityused operator algebraic operation.Let G labeled granularity, j integers LG s.t. G(i) 6= .relabeling operation Relabelji (G) generates full-integer labeled granularity G0 relabelingG(i) G0 (j) relabel next (and previous) granule G next (and previous,respectively) integer. formally, integer k, k = j, let G0 (k) = G(i),otherwise let G0 (k) = G(i0 ) G(i0 ) |j k|-th granule G (before,respectively) G(i). required |j k|-th granule G exist, let G0 (k) = .Note G0 always full-integer labeled granularity.relabeling procedure implemented periodic representation adoptedcomputing value lG0 . easily seen lG0 known, full characterization G0 obtained with: PG0 = PG ; NG0 = RG0 = RG LG0 ={lG0 , lG0 + 1, . . . , lG0 + NG0 2, lG0 + NG0 1}. clear explicit representationgranules modified.jkilG00compute lG consider label = NG NG ; i0 represents label LGi0 multiple NG . jThereforeclear label j 0 LG0 s.t. G0 (j 0 ) = G(i0 )kGcomputed j 0 = j ilNG0 . Finally lG0 obtained lG0 = j 0 ||NGdistance, terms number granules G, G(lG ) G(i0 ).4Example 13 Figure 13 shows example Relabel operation: G0 = Relabel33 (G).3360Since PG = 4and R= 335 = 85G = 2 PG0 = 4 NG0 0 = 2. Moreover,0 ) next granule Gj 0 = 4 3362=6.Sincel=6=8G(iG5G(lG ). = 1 hence lG0 = 6 1 = 7. follows LG0 = {7, 6}.Finally G0 (7) = G(6) G0 (6) = G(8).GSTP constraint solver imposes first non-empty granule granularity( included) labeled 1. Therefore, using relabeling operation producing320fiMapping Calendar Expressions Minimal Periodic SetsFigure 13: Relabeling examplegranularities GSTP, parameter j must set 1. parameter equalsmallest label among identify granules G covering granuleslabeled positive values. definition lG , = lG min(blG cG ) > 0; otherwisenext label G lG .4.12 Complexity Issuesoperation time necessary perform three conversion steps, dependsoperation parameters (e.g. grouping factor m, Group operation)operand granularities (in particular period length, period label distancenumber granules one period).central issue operand granularity bottom granularity,period function periods granularities operands operationdefines it. algebraic operations, worst case periodresulting granularity product periods operands granularity.operations, first step conversion process performedconstant logarithmic time. Indeed formulas necessary derive period lengthperiod label distance involve (i) standard arithmetic operations, (ii) computationGreatest Common Divisor (iii) computation least common multiple. Part(i) computed constant time (ii) (iii) computed logarithmictime using Euclids algorithm.operations, second step performed constant time (e.g. Group,Shift Anchored-group) linear time (e.g. set operations). operationsnecessary compute set labels granularity G G(i) H(j)H granularity j LH (analogously set G(i)H(j) (G(i) H(j) 6= )). computation needs performedP 0granule PHG . idea algorithm solving problem presentedSection 4.2. Several optimizations applied algorithm, worstcase (when H covers entire time domain) necessary perform number deGoperations linear period length resulting granularity. optimized datastructure used represent granularities, deG operation performedconstant time 4 , time necessary perform second step linear periodlength resulting granularity (O(PG0 )).last step conversion process performed linear time respectnumber granules period G0 .4. non-optimized data structure used, deG requires logarithmic time.321fiBettini, Mascetti & Wangcomplexity analysis conversion general algebraic expression needsconsider composition operations hence complexity. Finally, relabeling,done linear time.detailed complexity analysis scope work.5. Minimal Representation Experimental Resultssection address problem guaranteeing converted representationminimal terms period length. show Example 14 conversionformulas proposed paper guarantee minimal representation resultclear conversion formulas ensuring minimality exist. approach applyminimization step conversion.practical applicability minimization step depends period lengthrepresentation minimized. Indeed, tests noted minimizationstep efficient conversion formulas proposed Section 4 adopted,impractical conversion procedure returns period orders magnitudehigher minimal one would case conversion formulas constructednaive way.5.1 Period Length Minimizationstated Section 2, granularity different periodical representations and,given granularity, possible identify set representations minimali.e. adopting smallest period length.Unfortunately, conversions always return minimal representation, shownExample 14.Example 14 Consider calendar day bottom granularity. defineweek week = Group7 (day); applying formulas Group operation obtainPweek = 7 Nweek = 1.apply Altering-tick operation add one day every first week everytwo weeks. Let granularity G1 = Alter21,1 (day, week); applying formulasAltering-tick operation obtain PG1 = 15 NG1 = 2.apply Altering-tick operation create granularity G2 removingone day every first granule G1 every two granules G1 : G2 = Alter21,1 (day, G1 ).Intuitively, applying operation get back granularity week, howeverusing formulas Altering-tick operation obtain PG2 = 14 NG2 = 2; HenceG2 minimal.order qualitatively evaluate close minimal representations resultsconversions are, performed set tests using algorithm (Bettini & Mascetti,2005) minimality checking. experimental results conversions algebraicexpressions defining granularities real-world calendars, including many user-defined nonstandard ones, always returned exactly minimal representations. Non-minimal ones couldobtained artificial examples like one presented Example 14.Although non-minimal result unlikely practical calendars, minimalitygranularity representation known greatly affect performance algorithms322fiMapping Calendar Expressions Minimal Periodic Setsgranularity processing, e.g., granularity constraint processing (Bettini et al., 2002a), calendar calculations (Urgun et al., 2007), workflow temporal support (Combi & Pozzi, 2003).Hence, considered extension conversion algorithm adding minimizationstep exploiting technique illustrated Bettini et al. (2005) derive minimal representation.choice using conversion algorithm extended one minimizations, probably driven performance considerations. Section 5.3 reportresults experiments showing generally advantageous apply minimization step. implementation, presented Section 5.2, possible specifyminimization step performed.5.2 Implementation CalendarConverter Web Serviceconversion formulas presented Section 4 implemented CalendarConverter web service converts Calendar Algebra representations equivalentperiodical ones. precisely, given calendar granularities expressed Calendar Algebra operations, service converts operation equivalent periodicalrepresentation.service first rewrites calendar algebra expression order expressterms bottom granularity. example, bottom granularity hour,expression Monday = Select-down11 (day, week) changedMonday = Select-down11 (Group24 (hour), Group7 (Group24 (hour)))Then, Procedure 1 run granularitys expression. idea periodicalrepresentation subexpression recursively computed starting expressionsbottom granularity operand. operand given operationconverted periodical representation, corresponding formula presented Section 4applied. call step ConvertOperation procedure.trivial optimization Procedure 1 consists caching results conversionssubexpression computed once, even subexpression appearsseveral times (like Group24 (hour) Monday definition).5.3 Experimental Resultsexperiments address two main issues: first, evaluate conversion formulasimpact practical applicability conversion procedure and, second, evaluateuseful minimization step.first issue, execute conversion procedure two different sets conversion formulas compare results. first set laid Section 4. other,less optimized, taken preliminary version paper (Bettini et al.,2004).Table 1 shows converting calendars granularities small minimalperiod length (first two rows), using formulas Section 4 improves performanceone order magnitude; However, conversions minimizations almost instantaneous approaches. contrary, minimal period length higher,323fiBettini, Mascetti & WangProcedure 1 ConvertExpressionInput: calendar algebra expression ex; boolean value minimize settrue minimization step executed;Output: periodical representation ex;Method:1:2:3:4:5:6:7:8:9:10:11:12:(ex bottom granularity)return periodical representation bottom granularityendoperands :=(each operand op ex)add ConvertExpression(op, minimize) operands;endresult :=ConvertOperation(ex.getOperator(), operands)(minimize)minimize periodical representation resultendreturn result;Table 1: Impact conversion formulas performance conversion minimization procedures (time milliseconds).CalendarPeriodBot1 yearday4 yearsday1 yearhour4 yearshour100 years daySection 4 formulasConv. Min. Tot.4267299211164201279 136Less optimized formulasConv.Min.Tot.62329476551312,244126,904129,1484,362908,504912,8663,764 1,434,524 1,438,288(last three rows) time required minimize periodical representation fiveorders magnitude larger formulas proposed Bettini et al. (2004) used;consequence, entire conversion may require several minutes while, using formulaspresented Section 4, still requires fraction second. period lengtheven larger, conversion procedure impractical formulas presented Bettini etal. (2004) used, indeed experiments obtain result lessthirteen hours.second issue, perform set three experiments. first one compareperformance conversion procedure performance minimization step.324fiMapping Calendar Expressions Minimal Periodic Setsexperiment consider case conversion procedure produces minimalrepresentations. case minimization step always overhead since cannotimprove performance conversion procedure.Figure 14 shows result experiment. Four calendars considered, onecontaining set granularities Gregorian calendar. four calendars differsvalues two parameters: bottom granularity (it second cal-1 cal-3minute cal-2 cal-4) period leap years leap years exceptionsrepresented (it 1, 4, 100 400 years cal-1, cal-3, cal-2 cal-4 respectively);consequence, minimal period length granularities month year3 107 cal-1, 5 107 cal-2, 108 cal-3 2 108 cal-4.Figure 14: Impact minimization conversion; minimal conversions case.observed Figure 14, ratio time required performconversions time required minimization step varies significantlyminimum 3% cal-4 maximum 23% cal-3. reason complexityconversion procedure mainly affected period length granularitylargest period length. hand, complexity minimization stepaffected also features granularities internal structurenumber integers divide time period label distance, periodlength number granules one period; details see (Bettini & Mascetti,2005).second experiment consider case conversion procedure produces non-minimal representation granularity input calendar; casepossible benefit minimization step. example, suppose granularity Gconverted used argument another Calendar Algebra operationdefines granularity H. time required compute periodical representationH strongly depends period length G; period length G reducedexecution minimization step, conversion H executed faster.produced situation using technique similar one Example 14;created Calendar Algebra definitions Gregorian calendar granularityday converted granularity non-minimal representation. Figure 15 showsperformance obtained converting granularities used Figure 14.325fiBettini, Mascetti & Wangdifference case definition granularity day that,conversion procedure, period twice large minimal one (i.e., 48 hours2880 minutes 172800 seconds depending bottom granularity used).easily seen case use minimization step improve performanceentire algorithm. Indeed, minimization step performed, conversionprocedure requires one half time required minimizationperformed.Figure 15: Impact minimization conversion; non-minimal case.third experiment evaluate impact minimal representationperformance applications involving intensive manipulations granularities. testuse GSTP solver application; computes solutions temporal constraintsgranularities. description architecture GSTP system providedSection 6.1.Figure 16 shows experiments performed four temporal constraint networksgranularities. four networks differs number variables, number constraints granularities used express constraints. networks labelednon-minimal use granularities definitions obtained technique similarone used Example 14, period twice large minimal one.Figure 16 shows use minimal representations greatly improves performance GSTP solver. Indeed experiments ratio time requiredsolve network using non-minimal representation minimal onethree five. Moreover, time required solve network, greaterimprovement obtained using minimal representation; means complextemporal networks expect improvement even higher.Considering results experiments, conclude that, general, advisableperform minimization step. particular, advantageous specific caseGSTP, based following considerations: i) time required perform minimization step fraction time required perform conversion procedure, ii)conversions performed off-line cases, respect granularity processing,conversion results cached future use, iii) period length strongly influ-326fiMapping Calendar Expressions Minimal Periodic SetsFigure 16: Impact minimal representations performance GSTP solver.ences GSTP processing time cases much longer time neededconversion.6. Applicationssection complement motivations work sketch applicationsenabled proposed conversion. Firstly describe GSTP system, exampleapplications involving intensive manipulation time granularities. GSTP usedcheck consistency find solutions temporal constraint satisfaction problemsgranularities5 ; also applied check consistency inter-organizationalworkflow models (Bettini, Wang, & Jajodia, 2002b). Then, discuss use CalendarAlgebra define new granularities may later part input reasoning services,GSTP.6.1 GSTP SystemGSTP system developed University Milan objectiveproviding universal access implementation set algorithms multi-granularitytemporal constraint satisfaction (Bettini et al., 2002a). allows user specify binaryconstraints form X [m, n]G n minimum maximumvalues distance X terms granularity G. Variables take valuespositive integers, unary constraints applied domains. example,constraint: Event2 occur 2 4 business days occurrence Event1modeled OccE2 OccE1 [2, 4]BDay. problem considered extension STP(Dechter, Meiri, & Pearl, 1991) multiple arbitrary granularities. knowledge,GSTP available system solve class temporal constraint satisfactionproblems.Figure 17 shows general architecture GSTP system. three mainmodules: constraint solver; web service, enables external access solver;5. detailed description system, see (Bettini et al., 2005).327fiBettini, Mascetti & Wanguser interface used locally remotely design analyze constraintnetworks.Figure 17: GSTP Architectureconstraint solver C implementation ACG algorithmproposed Bettini et al. (2002a), runs server machine. Following approach Bettini et al. (2002a), solver uses representation granularities basedperiodical sets. representation makes possible efficiently compute core operations granularities required solve constraint satisfaction problem.operations involve, example, union intersection periodical sets.cannot exclude operations may computed terms alternative low levelrepresentations, seems much harder obtain similar results high level representation,Calendar Algebra, used.second module system Web Service defines, WSDLspecification, parameters passed constraint solver, includingXML schema constraint network specification.third module remote Java-based user interface, allows user easilyedit constraint networks, submit constraint solver, analyze results.particular, possible views terms specific granularities, visualize implicitconstraints, browse descriptions domains, obtain network solution. Fig. 18shows screenshot interface.6.2 Defining New GranularitiesGSTP solver handle arbitrary granularities, new granularities must addedediting explicit periodical representation. true general multi328fiMapping Calendar Expressions Minimal Periodic SetsFigure 18: GSTP User Interfacegranularity reasoning service based low-level representation granularities,painful task granularities large period. example, experimentalresults illustrated Figure 16, used representation granularity monthconsiders leap years leap years exceptions period 400 years. case,users specify representation 4800 granules i.e., number months 400years.period length real world granularities generally high, graphical interface help supports user individually select explicit granules.effective solution requires use implicit explicit operations granules. Amongvarious proposals, Calendar Algebra provides richest set operators. questionarises: definition granularities terms Calendar Algebra really simplerspecification periodical representation? Calendar Algebra seem userfriendly: exact semantics operator may immediate inexperienceduser time required order learn use operator.practice, think reasonable ask unexperienced userdefine granularities writing Calendar Algebra expressions. Nevertheless, thinkCalendar Algebra used specialized user interfaces guide userspecifying granularities. sense, believe Calendar Algebra playsrole SQL definition databases queries. Similarly Calendar Algebra,SQL abstraction tool directly exploited expressive poweradvanced user, also used less experienced user graphical userinterface, possibly reduced expressiveness.mentioned above, case periodical representations, graphical user interfacessufficient making specification new granularities practical. contrary, case Calendar Algebra, user interfaces strongly enhance usabilityCalendar Algebra, making practical use possible also definition involvedgranularities. least two reasons difference. Firstly, main difficultyCalendar Algebra understanding semantics operators choiceappropriate one given task. effective user interface hide existence algebraic operators user showing operators modify existing329fiBettini, Mascetti & Wang(a) Step 1.(b) Step 2.(c) Step 3.Figure 19: 3-steps wizard visually defining granularity using Calendar Algebragranularities (i.e., semantics operators). Secondarily, Calendar Algebra allowscompact definition granularities. due fact Calendar Algebraoperations specifically designed reflect intuitive ways users define newgranularities.Example 15 shows graphical user interface effectively used define newgranularity terms Calendar Algebra expression.Example 15 example shows graphical user interface used supportuser definition granularity final set days, one corresponding330fiMapping Calendar Expressions Minimal Periodic Setslast Monday every academic semester. assume granularities MondayacademicSemester already defined. graphical user interface useexample wizard guides user step step. first step (Figure 19(a))user chooses kind operation wants perform. second step (Figure 19(b))user provide details wants modify operand granularity(Monday, example). results choice Calendar Algebra expressionshown third step (Figure 19(c)); last window user also give namegranularity defined.6.3 Global ArchitectureFigure 20: Integration GSTP CalendarConverter web servicesFigure 20 shows possible architecture integration GSTP, interfacenew granularity definitions CalendarConverter web service. granularity repositorycollects Calendar Algebra definitions. Upon request GSTP system definitionsconverted low-level representation CalendarConverter web service efficientlyprocessed. Clearly, caching techniques used optimize process.7. Related WorkSeveral formalisms proposed symbolic representation granularitiesperiodicity. Periodicity application AI DB area extensivelyinvestigated (Tuzhilin & Clifford, 1995; Morris, Shoaff, & Khatib, 1996; Kabanza, Stevenne,& Wolper, 1990; Ladkin, 1986). Regarding symbolic representation, well knownformalism proposed Leban et al. (1986), based notion collection,intended represent temporal expressions occurring natural language. collectionstructured set time intervals order collection gives measurestructure depth: order 1 collection ordered list intervals, order n(n > 1) collection ordered list collections order n 1. Two operators,331fiBettini, Mascetti & Wangcalled slicing dicing used operate collections selecting specific intervalssub-collections, dividing interval collection, respectively.example, Weeks:during:January2006 divides interval corresponding January2006intervals corresponding weeks fully contained month.formalism adopted extensions many researchers AI (Koomen,1991; Cukierman & Delgrande, 1998) Database area (Chandra, Segev, & Stonebraker,1994; Terenziani, 2003). particular, control statements if-then-elseintroduced Chandra et al. (1994) facilitate representation certainsets intervals. example, possible specify: fourth Saturday Aprilholiday, previous business day otherwise.deductive database community, second influential proposal sliceformalism introduced Niezette et al. (1992). slice denotes (finite infinite) setnecessarily consecutive time intervals. example, slice all.Years + {2,4}.Months+ {1}.Days . 2.Days denotes set intervals corresponding first 2 days FebruaryApril year.totally different approach calendar algebra described Ning et al. (2002),considered paper. representation based rich set algebraic operatorsperiodic sets opposed slicing dicing nonconvex intervals.None cited papers provide mapping identify operator changesmathematical characterization periodicity argument expressions.problem finding mappings trivial operators.(Bettini & Sibi, 2000) expressive power algebras proposed Leban etal. (1986) Niezette et al. (1992) compared extension first proposedorder capture larger set granularities. Since periodical representationused compare expressiveness, mapping calendar expressions formalismsperiodical representations found proofs paper. However, sinceminimality issue purpose comparing expressiveness, many casesmapping returns non-minimal representations.Regarding alternative approaches low-level representation, already mentionedones based strings (Wijsen, 2000) automata (Dal Lago, Montanari, &Puppis, 2003; Bresolin et al., 2004) may considered alternative targetconversion. matter fact, example conversion Calendar Algebraexpression string based representation found (Dal Lago & Montanari,2001). complete conversion procedure appeared revision process paperPhD Dissertation Puppis (2006). aim conversion provegranspecs formalism, used represent granularities terms automata, leastexpressiveness Calendar Algebra. Hence, obtaining minimal representationsgoal. Moreover, case minimization terms period length,terms automaton size automaton complexity. complexity reasoning,given automaton , worst case time complexity operations analogousdepends linearly ||M ||, value computed called complexity. sense ||M || role period length (P ), even preciserelationship two values hard obtain. approach computelogarithmic time respect P linear time respect dimensionresult (that bounded P ). operations, like checking equivalence, seem332fiMapping Calendar Expressions Minimal Periodic Setscomplex using automata (Bresolin et al., 2004). Techniques minimizationterms automaton complexity presented Dal Lago et al. (2003), timecomplexity proved polynomial, even exact bound explicitly given.3approach, worst case time complexity minimization O(P 2 ) (Bettini &Mascetti, 2005). Overall, automata approach elegant well-founded, but,one side still misses implementation order experimental datacompare with, side basic operations currently defined;would interesting investigate definition formalism complexoperations like ones required GSTP.8. Conclusion Future Workpresented hybrid algorithm interleaves conversion Calendar Algebrasubexpressions periodical sets minimization period length.proved algorithm returns set-based granularity representations minimalperiod length, extremely important efficiency operations granularities. Based technical contribution paper, software system developedallowing users access multi-granularity reasoning services defining arbitrary time granularities high-level formalism. current efforts mainly devoted completingrefining development different modules architecture shown Section 6.3.future work, intend develop effective graphical user interfaces supportdefinition Calendar Algebra expressions user friendly way. Example 15 described onepossible interfaces. Another open issue convert periodical representationgranularity user friendly Calendar Algebra expression. conversion coulduseful, example, present result computation performed using periodicalrepresentation. However, naive conversion may effective since resulting calendaralgebra expression could involved periodical representationderived. example, conversion procedure presented Bettini et al. (2000) proveCalendar Algebra least expressive periodical representation; however,resulting Calendar Algebra expression composed number Calendar Algebraoperations linear number granules one period originalgranularity. contrary, effective conversion generate Calendar Algebraexpressions compact easily readable user. problem somehowrelated discovery calendar-based association rules (Li, Ning, Wang, & Jajodia,2001). Finally, intend investigate usage automaton-based representationlow-level granularity formalism. would interesting know whether, usingrepresentation, possible compute operations computedperiodical representation performance gain could achieved.Acknowledgmentsthank anonymous referees useful comments suggestions. workBettini Mascetti partially supported Italian MIUR InterLink project N.II04C0EC1D.work Wang partially supported US NSF grant IIS-0415023.333fiBettini, Mascetti & WangAppendix A. ProofsA.1 Transitivity Periodically Groups Relationshiporder prove correctness conversions algebraic expressions periodicalsets, useful formal result transitivity periodically groupsrelation. addition transitivity / , Theorem 1 also says something periodlength values.Theorem 1 Let G H two unbounded granularities G periodic termsbottom granularity (i.e., / G) H periodic terms G (i.e., G / H). LetG period length period label distance H terms granulesPHG NHG, NG period label distance G terms . Then, PHG = NGpositive integer , H periodic terms bottom granularity (i.e., / H)PH = PG .GProof. SinceSni hypothesis G / H PH = NG , H(i) =GNH ) = r=0 G(ir + NG ). also written follows:Snir=0 G(ir ),H(i +H(i) = G(i0 ) ... G(ini )(1)GH(i + NH) = G(i0 + NG ) ... G(ini + NG )(2)Ns.t.:Since / G,G(ij ) =ij[(ij,k )(3)(ij,k + PG )(4)k=0G(ij + NG ) =ij[k=0clearly extended using NG instead NG .G(ij + NG ) =ij[(ij,k + PG )(5)k=0Rewriting (1) substituting G(ij ) according (3) rewriting (2) substituting G(ij +NG ) according (5), obtain:H(i) = (i0,0 ) . . . (i0,i0 ) . . . (ini ,0 ) ... (ini ,in )|{z}|{z}G(i0 )G(ini )334fiMapping Calendar Expressions Minimal Periodic SetsG ) = (iH(i + NH0,0 + PG ) . . . (i0,i0 + PG ) . . .{z}|G(i0 +NG )(ini ,0 + PG ) . . . (ini ,in + PG )|{z}G(ini +NG )Hence second condition Definition 5 satisfied. third one always satisfiedunbounded granularities. first one satisfied too; fact since G / H periodG , label H, + N G label H. Hence, definitionlabel distance NHHG.periodically-groups-into / H PH = PG NH = NHA.2 Proof Proposition 1A.2.1 Part 1definition Group operation, N:0G (i) =im[G(j) = G(im + 1) . . . G(im) = G() . . . G( + 1)j=(i1)m+1= im + 1. Furthermore, k N:(i+k)m[0G (i + k) =G(j) = G(im + km + 1) . . . G(im + km) =j=(i+k1)m+1= G( + km) . . . G( + km + 1)Hence,00G (i ) =m1[0m1[0G( + r) G (i + k) =r=0G( + r + km).(6)r=0Gholds k. use k = GCMN(m,N(note k N), hypothesesG)Theorem 1 satisfied: (i) / G (by hypothesis); (ii) G / G0 (since G / G0 , LG0 = Z,mNGNG(6) holds); (iii) PGG0 = GCM(m,NG ) (since use k = GCM (m,NG ) and, (6)know PGG0 = km). Therefore, Theorem 1, / G0 PG0 =NG0 =mPGGCM (m,NG )NGGCM (mNG ) .A.2.2 Part 2definition GroupjkjG0lG 1+10operation, G (i) =definition l, need show G0lG 1+1lG 1k+1[=j=335= tj=b G(j) b lG t.Simj=(i1)m+1 G(i) ; hence:jlG 1km+1G(j)fiBettini, Mascetti & Wangprove thesis showing (1)lG .(1) SincejlG 1klG 1,jlG 1lG 1GlmlG 1[(lG 1)mod m]Glm1;(2) First proveprovehencekjjlG 1km+1 lG (2)jlG 1k+ 1k+ 1 lGjk1. Since lGm1 =lG 1[(lG 1)mod m]equivalent thej inequality[(lG 1)mod m]k+ 1 true since (lG 1)mod 1. SincekjlG 1+1lG .lG 1lG1 trivialA.3 Proof Proposition 2A.3.1 Part 1Proof sketchshow G2 / G0 PGG02 = NG2 apply Theorem 1 obtain thesis.particular usePG2 NG1NG2= lcm NG1 , m,,GCD(PG2 NG1 , PG1 ) GCD(NG2 m, |k|)PG2PG1 NG2k=+NG1 PG2NG2that, i, j, k : G0 (i) = kr=0 G2 (j + r), G0 (i + ) = kr=0 G2 (j + r +NG2 ).Given arbitrary granule G0 (i), show G0 (i + ) union granulesobtained adding NG2 index granule G2 contained G0 (i). Note+ LG0 since G0 full-integer labeled. order show correctconsider way granules G0 constructed definition altering-tick. precisely,compute difference label b0i+ first granule G2 includedG0 (i + ) label b0i first granule G2 included G0 (i); showdifference equal difference label t0i+ last granule G2 includedG0 (i + ) label t0i last granule G2 included G0 (i). fact togetherconsideration G2 full-integer labeled granularity, leads conclusionG0 (i) G0 (i + ) number granules. clearcomputed label differences also equal difference label arbitraryn-th granule G2 included G0 (i + ) label n-th granuleG2 includedG0 (i). difference b0i+ b0i , have: j, k : G0 (i) = kr=0 G2 (j + r),G0 (i + ) = kr=0 G2 j + r + b0i+ b0i . showing b0i+ b0i multiple NG2thesis follows.Proof details336fiMapping Calendar Expressions Minimal Periodic SetsSiSti+Assume G1 (i) = tj=bG2 (j) G1 (i + ) = j=bG2 (j). need computei+00bi+ bi . definition altering-tick operation:b0i=kbi + ilbi +il=il+ l,(7)+ 1 k otherwise.b0i+=kbi+ + i+lbi+ +i+l+ =i+l+ l,(8)+ 1 k otherwise.Note = il+ l, + = i+lIndeed, i+l+l =+ l.ililil+m+land,sincemultiplem,+m+l=+m+ill = + + l.Hence, compute b0i+ b0i consider two cases:b0i+ b0i =k bi ilk = ilm+lbi+ + i+lbi+ +i+l(9)+ 1 k bi il+ 1 k otherwise.cases (again considering fact multiple m):b0i+ b0i = (bi+ bi ) +k(10)left compute bi+ bi , i.e., distance terms granules G2 , G2 (bi )Sti+SiG2 (j),G2 (j) G1 (i + ) = j=bG2 (bi+ ). Since, hypothesis, G1 (i) = tj=bi+first granule making G2 (bi ) first granule making G1 (i)granule. observed first granule making G2 (bi+ )first granule making G1 (i + ). formally:min bbi cG2 = min bicG1min bbi+ cG2 = min bi + cG1Hence, have:min bbi+ cG2 min bbi cG2 = min bi + cG1 min bicG1(11)shown difference index first granule makingG2 (bi+ ) index first granule making G2 (bi ) equal differenceindex first granule making G1 (i + ) index firstgranule making G1 (i). Then, need compute difference indexfirst granule making G1 (i + ) index first granuleSof makingG1 (i). Since / G1 multiple NG1 , i, j, : G1 (i) = r=0 (j + r),337fiBettini, Mascetti & WangPPG1 (i + ) = r=0 (j + NGG1 ). Hence, difference value NGG1 ,11shown also value difference index first granulemaking G2 (bi+ ) index first granule making G2 (bi ). Then, sinceP/ G2 period length PG2 since NGG1 multiple PG2 , that, if:1(j) G2 (i)then:(j +Thus, bi+ bi =Reconsidering 10:PG1PG1 NG2)) G2 (i +NG1NG1 PG2PG1 NG2NG1 PG2 .b0i+ b0i =PG1 NG2k+.NG1 PG2PNAnalogously compute t0i+ t0i = NGG1PGG2 + k.120000Thus, bi+ bi = ti+ ti ; hence ti+ bi+ = ti bi . Since G2 full integer labeledgranularity, G0 (i) G0 (i + ) formed number granules.St0i+St0i0000Since know G0 (i+) = j=bG2 (j) = j=b0 G2 (j +(bi+ bi )) (bi+ bi )0i+/ G0 ,PGG02PG1 NG2NG1 PG2multiple NG2 , G2=/ G2 . Hence,hypothesis Theorem 1 hold, application leads thesis proposition.A.3.2 Part 20Since G2 partitions G0 (see table 2.2 (Bettini et al., 2000)), (1) dlG2 eGG2 al+ways defined (2) min({n N |i LG2 s.t. (n) G2 (i)}) = min({m N+ |jLG0 s.t. (m) G0 (j)}). Therefore lG0 label granule G0 covers0granule G2 labeled lG2 ; definition de operation, lG0 = dlG2 eGG2 .A.4 Proof Proposition 3A.4.1 Part 2definition Shift operation, G0 (i) = G(im). Hence G0 (lG +m) = G(lG +mm) =G(lG ).A.5 Proof Proposition 4A.5.1 Part 1thesis follow application Theorem 1. Indeed, know / G2show G2 / G0 PGG02 multiples.t.,NG2 . we0 need identify0i, exists s(i) s.t. G (i) = js(i) G2 (j), G (i + ) = js(i) G2 (j + NG2 ).lcm(P,P)NG1 G2G1Consider arbitrary N =. definition combiningPG100operation, G (i) = js(i) G2 (j) G (i + ) = js(i+) G2 (j)s(i) = {j LG2 | =6 G2 (j) G1 (i)}338fiMapping Calendar Expressions Minimal Periodic Setss(i + ) = {j LG2 | =6 G2 (j) G1 (i + )} .show s(i + ) composed elements s(i)lcm(PG1 ,PG2 )NG2quantity 0 =added. purpose need:PG2j s(i) (j + 0 ) s(i + )(12)j + 0 s(i + ) j s(i)(13)12, note j s(i), G2 (j) G1 (i). Since / G2 ,G2 (j) =k[(jr )r=00G2 j + =k[(jr + lcm(PG1 , PG2 ))(14)r=0Since G1 (i) G2 (j) =Skr=0 (jr ),since / G1 ,G1 (j + )k[(jr + lcm(PG1 , PG2 ))(15)r=014 15 derive G1 (i + ) G2 (j + 0 ), hence (j + 0 ) s(i + ).AnalogouslyvaliditySof 13; Hence, i, exists s(i) s.t.proved00G (i) = js(i) G2 (j), G (i + ) = js(i) G2 (j + 0 ). Hence, considering factG2 / G0 , conclude G2 / G0 . Finally, since PGG02 multiple NG2 , Theorem 1obtain thesis.A.5.2 Part 2LetP 0s(i) 6= }LeG0 = {i LGG1 |eP0P0LGG1 se(i) = {j LGG2 | =6 G2 (j) G1 (i)};show LeG0 = LG0 proving that: (1) LeG0 LG0 (2) LeG0 LG0 .(1) Suppose contradiction exists k LG0 \ LeG0 . Since k LG0 since G0derived Combine operation,q LG2 |G2 (q) G1 (k). definition0Combine operation G (k) = js(k) G2 (j); since q s(k), G2 (q) G0 (k). Hence (a)q LG2 |G2 (q) G0 (k).P 0Moreover, since k 6 LeG0 , se(k) = ; therefore @j LGG2 |G2 (j) G1 (k).definition Combine operation easily seen G0 G1 . UsingP 0previous formula, derive (b) @j LGG2 |G2 (j) G0 (k).339fiBettini, Mascetti & WangP0(a) (b) follows q LG2 \ LGG2 |G2 (q) G0 (k). showleads contradiction.P 0P 0P 0P 0Since q 6 LGG2 labels LGG2 contiguous (i.e., @i LG2 \ LGG2 s.t. min(LGG2 ) <PP0P00< max(LGG2 )), q < min(LGG2 ) q > max(LGG2 ). consider first case,proof second analogous.P 0P 0q < min(LGG2 ) max(bqcG2 ) < 1 (otherwise q LGG2 ).00Let = min(bmin(LG0 )cG ). Since k LG0 , bkcG .1, G0 (k) G2 (q) = contradicting G0 (k) G2 (q).< 1, G0 (lG0 ) (0) show lG0 LeG0 . Indeed, definitionP 0P 0Combine, j LGG2 |G2 (j) G0 (LG0 ). Since G0 G1 also j LGG2 |G2 (j)G1 (LG0 ); hence j se(lG0 ) lG0 LeG0 .Since 0 G0 (lG0 ) max(bqcG2 ) 0, max(bqcG2 ) < (otherwise G2 (q)00G0 (lG0 )). Therefore, since min(bkcG ) , bqcG2 blG0 cG = , contradictionG2 (q) G0 (k).e(2) Suppose contradiction k LeG0 \ LG0 . Since k LeG0 , definition L,PP00k LGG1 se(k) 6= ; Therefore, definition se, j LGG2 |G2 (j) G1 (k).P0Since j LGG2 , definition L, h 0 < h PG0 s.t. dheG2 = j. Since0G2 (j) G1 (k), dheG1 = k. definition combine operation, dheG = k.0Moreover, since 0 < h PG0 , definition L, dheG = k LG0 , contradictinghypothesis.A.6 Proof Proposition 5A.6.1 Part 1thesis follow application Theorem 1. Indeed, show G1 / G0PGG01 multiple NG1 . need identify s.t., i, exists s(i)lcm(PG1 ,PG2 )NG2s.t. G0 (i) = js(i) G1 (j), G0 (i+) = js(i) G1 (j +NG1 ). Let =.PG200(i+) 11G1 (j) G0 (i + ) = j=i+ G1 (j)definition anchored grouping, G0 (i) = ij=ii0 first label G2 (i + )0 first label G2 + .periodicity G2 , (and since multiple NG2 ) difference labelgranule following G2 (i + ) label granule following G2 (i)Sk.00000formally, (i + ) = , hence (i + ) = + . Then, i, G (i) = j=i G1 (j),0 +10 1G0 (i + ) = ij=i+G1 (j) = ij=iG1 (j + ). result considering G1 / G0 ,conclude G1 / G0 PGG01 = . Note Proposition 9, NG1 =PGG01multiple . Then, Theorem 1, thesis.A.6.2 Part 2Let(LeG0 =P0lG2 = lG1 ,LGG2 ,PG00{lG2 } LG2 , otherwise,340PG1 NG2PG2 ,hencefiMapping Calendar Expressions Minimal Periodic Sets0lGgreatest among labels LG2 smaller lG2 . show2eLG0 = LG0 proving (1) LeG0 LG0 (2) LG0 LeG0 .P 0(1) Suppose contradiction k LeG0 \ LG0 . Then, since k LeG0 , k LGG20 .k = lG2PP00k LGG2 , then, definition LGG2 , h 0 < h PG0 s.t. dheG2 = k.0 1definition Anchored-group, G0 (k) = kj=kG1 (j) k 0 first label G20k. Therefore G (k) G1 (k). Since G2 labeled aligned subgranularity G1 since0k LG2 , k LG1 G1 (k) = G2 (k). Hence G0 (k) G2 (k). follows dheG = ktherefore, definition L, k LG0 contrast hypothesis.0 , then, definition LeG0 , lG 6= lG . Therefore, since G2 labeled alignedk = lG2120 <l;h0 < h < min(blG2 cG2 ) s.t. dheG1 = lG1 .<lsubgranularity G1 lGGG212lG2 10 ) =0Since, definition Anchored-group, G0 (lGG1 (j) since lG< lG1 < lG2 ,j=l022G200 ) G (l ). Hence dheG = l00G0 (lG1 G1G2 therefore, definition L, lG2 = k LG02contrast hypothesis.P 0(2) Suppose contradiction k LG0 \ LeG0 . k LGG2 then, definitionLeG0 , k LeG0 , contrast hypothesis.P 0P 0P 0P 0P 0k/ LGG2 , since @q LG2 \LGG2 s.t. min(LGG2 ) q max(LGG2 ), k > max(LGG2 )P0k < min(LGG2 ).P0k > max(LGG2 ) then, definition L, min(bkcG2 ) > PG0 . Since G2 labeledaligned subgranularity G1 G2 (k) = G1 (k) hence min(bkcG1 ) > PG0 . Since0 10G0 (k) = kj=kG1 (j) min(bkcG ) > PG0 contrast hypothesis k LG0 .P00 , k < l00k < min(LGG2 ) then, definition lGG2 k = lG2 .200k < lGthen, let k 0 next label G2 k. Since k < lGthen, definition2200000GlG2 , k lG2 . definition lG2 max(blG2 c 2 ) 0. Since G2 labeled aligned0 ) = G (l0 ); therefore max(bl0 cG1 ) 0. Since G0 (k) =subgranularity G1 G1 (lG2 G2G22Sk0 100G0 ) 0 contrast hypothesisG(j)kl,followsmax(bkc1j=kG2k LG0 .SlG2 100 ) =0Finally k = lGG0 (lGG1 (j). Since k = lGLG0 hj=l02220G20 . Since G0 composition granules G , dheG10 < h PG0 s.t. dheG = lG12P0defined. Let q = dheG1 . definition L, q LGG1 therefore q lG1 . Since,00definition Anchored-group, G0 composition granules G1 since dheG = lG2lG2 10 ). Therefore since G0 (l0 ) =dheG1 = q, G1 (q) G0 (lGG(j)q<l1G2 .G2j=l02G20follows lG1 q < lG2 hence lG1 6= lG2 . definition LeG0 , lG= k LeG02contrast hypothesis.A.7 Selecting operationsselecting operations common part proof computation periodlength period label distance.341fiBettini, Mascetti & Wanglcm(P,P)NG1 G2G1Let =. proof divided two steps: first showPG1select operation LG0 + LG0 (details Select-down, Select-upSelect-by-intersect operations found below). second step applicationTheorem 1. Indeed, Select operation, following holds: LG0 G0 (i) = G1 (i);implies G1 / G0 . step 1 follows + LG0 , hence G0 (i + ) = G1 (i + ).result considering G1 / G0 , conclude G1 / G0 PGG01 =multiple NG1 definition. Then, Theorem 1 thesis.A.8 Proof Proposition 6A.8.1 Part 1See Section A.7.prove LG0 0 = + LG0 .definition select-down operation, LG0 LG2 s.t. lk (S(i))S(i) ordered set defined follows: S(i) = {j LG1 | =6 G1 (j) G2 (i)}.order prove thesis need show i0 LG2 |0 lk (S(i0 )). Consideri0 = i+lcm(PG1 PG2 )NG2PG2note i0 LG2 (this trivially derived periodicityG2 ). prove 0 lk (S(i0 )) show S(i0 ) obtained S(i) addingelements.Indeed note periodicity G1 , j S(i) if:j[(jr )(16)(jr + lcm(PG1 PG2 ))(17)G1 (j) =r=0then:G1 j0=j[r=0Since j S(i), G1 (j) G2 (i) then, (16), G2 (i)periodicity G2 :0G2j[(jr + lcm(PG1 PG2 ))Sjr=0 (jr ).Moreover,(18)r=0Since (17) (18), G2 (i0 ) G1 (j 0 ); hence j S(i), j 0 = (j + ) S(i0 ). Analogouslyprove j 0 S(i0 ), j = (j 0 ) S(i).Thus S(i0 ) obtained S(i) adding elements; therefore j S(i)position n S(i), j 0 S(i0 ) position n S(i0 ). Hence trivialposition k k + l 1 S(i), 0 position k k + l 1S(i0 ). Hence LG0 , 0 LG0 .342fiMapping Calendar Expressions Minimal Periodic SetsA.8.2 Part 2LetLeG0 =[ nP 0A(i)|a LGG1 ;P 0iLGG2LG2 :6 G1 (j) G2 (i)}) .A(i) = lk ({j LG1 | =show LeG0 = LG0 proving (1) LeG0 LG0 (2) LeG0 LG0 .P 0(1)Suppose contradiction q LeG0 \ LG0 . definition LeG0 , q LGG1 ;therefore h 0 < h PG0 s.t. dheG1 = q. Moreover, definition LeG0definition Select-down, LeG0 LG0 hence q LG0 . Since, definition Select-down0G0 (q) = G1 (q), dheG = q; hence, definition L, q LG0 contradictionhypothesis.(2)Suppose contradiction q LG0 \ LeG0 . Since q LG0 then, definitionSelect-down6 G1 (j) G2 (i)})LG2 s.t. q lk ({j LG1 | =therefore, definition A(i), q A(i).0Since q LG0 h 0 < h PG0 s.t. dheG = q. definition Select-down,P 0G0 (q) = G1 (q), dheG1 = q therefore q LGG1 . Moreover, since G1 (q) G2 (i),PP00P0dheG2 = therefore LGG2 . Since q A(i), q LGG1 LGG2 then,definition LeG0 , q LeG0 , contrast hypothesis.A.9 Proof Proposition 7A.9.1 Part 1See Section A.7. prove LG0 + LG0 . periodicity G1 ,i+ LG1 (this trivially derived periodicity G1 ). Hence need showj 0 LG2 | =6 G2 (j) G1 (i + ). Since LG0 j LG2 | =6 G2 (j) G1 (i).periodicity G2 , if:G2 (j) =j[(jr )(19)r=0then:[jlcm(PG1 PG2 )NG2G2 j +=(jr + lcm(PG1 PG2 ))PG2r=0Moreover, (19) since G1 (i) G2 (j):G1 (i)j[r=0periodicity G1 :343(jr )(20)fiBettini, Mascetti & WangG1 (i + )j[(jr + lcm(PG1 PG2 ))(21)r=0(20) (21) follows G1 (i + ) G2 j +lcm(PG1 PG2 )NG2PG2, thesis.A.9.2 Part 2LetP 06 G2 (j) G1 (i)};LeG0 = {i LGG1 |j LG2 s.t. =show LeG0 = LG0 proving (1) LeG0 LG0 (2) LeG0 LG0 .P 0(1) Suppose contradiction k LeG0 \ LG2 . Since k LeG0 , k LGG1 ;therefore h 0 < h PG0 s. t. dheG1 = k. Moreover, definition LeG0definition Select-down, LeG0 LG0 hence q LG0 . Since, definition Select-up,0G0 (k) = G1 (k), dheG = k. Hence, definition L, k LG0 , contrasthypothesis.(2) Suppose contradiction k LG0 \ LeG0 . Since k LG0 , h 0 <0h PG0 s.t. dheG = k. Since, definition Select-up, G0 (k) = G1 (k), dheG1 = k;P 0Therefore, definition L, k LGG1 . Moreover, since k LG0 LG0 LG0 ,definition Select-up operation, j LG2 s.t. 6= G2 (j) G1 (k). Hencedefinition LeG0 , k LeG0 , contradiction hypothesis.A.10 Proof Proposition 8A.10.1 Part 1See Section A.7. prove LG0 , 0 = + LG0 .definition select-by-intersect operation, LG0 , LG2 :lk (S(i)) S(i) ordered set defined follows: S(i) = {j LG1 |G1 (j)G2 (i) 6= }.order prove thesis need show i0 LG2 : 0 lk (S(i0 )). Consideri0 = +lcm(PG1 PG2 )NG2note i0 LG2 (thisPG2prove 0 lk (S(i0 )) showtrivially derived periodicityG2 ).S(i0 ) obtained S(i) addingelements.Indeed note j j S(i), G1 (j) G2 (i) 6= . Hence l Z : (l) G1 (j)(l) G2 (i). periodicity G1 , G1 (j + ) (l + lcm(PG1 PG2 )).periodicity G2 , G2 (i0 ) (l + lcm(PG1 PG2 )). G1 (j + ) G2 (i0 ) 6= , thereforej S(i), (j + ) S(i0 ).Analogously prove j 0 S(i0 ), (j 0 ) S(i). Hence S(i0 ) obtainedS(i) adding elements. Therefore, j S(i) position n S(i),j + S(i0 ) position n S(i0 ); hence j position k k + l 1 S(i),also j + position k k + l 1 S(i0 ) j + LG0 .A.10.2 Part 2proof analogous ones Proposition 6.344fiMapping Calendar Expressions Minimal Periodic SetsA.11 Set OperationsA.11.1 Proof Proposition 9Given periodical granularities H G G label aligned subgranularity H,NHGprove NPG = PH . thesis proved considering common period length HG i.e. Pc = lcm(PG , PH ).Let NG0 difference label ith granule one period Glabel ith granule next period, considering Pc period length G.0 defined.Analogously NHperiodicity G, G(i) = kr=0 (ir ) G(i + NG0 ) = kr=0 (ir + Pc ); since Galigned subranularity H, LH H(i) = G(i) = kr=0 (ij ) and, since H periodic,Sk0 )=00H(i + NHr=0 (ij + Pc ); easily derive + NG = + NH , hence00NG = NH .0 = N 0 ,definition Pc , , N s. t. PH = PG . Moreover, since NHGPGPH=.NH = NG . Therefore NNGHA.11.2 Property used proofs set operationslcm(P,P)Nlcm(P,P)NG1 G2G1G1 G2G2Let 12. Since G1 G2 aligned subgranPG1PG2ularity certain granularity H, Proposition 9 easily derive 1 = 2 .A.12 Proof Proposition 10A.12.1 Part 1Union. Let 1lcm(PG1 ,PG2 )NG2lcm(PG1 ,PG2 )NG12. thesisPG1PG2Sk00LG0 if, G (i) = r=0 (ir ), G (i + ) = kr=0 (irproved+ lcm(PG1 , PG2 ))showing0= 1 = 2 . Since LG = LG1 LG2 , two cases considered:LG1 G0 (i) = G1 (i) = kr=0 (ir ). periodicity G1 , G1 (i + 1 ) =SkSk0r=0 (ir + lcm(PG1 , PG2 )); hence G (i + 1 ) =r=0 (ir + lcm(PG1 , PG2 )).LG2 LG1 G0 (i) = G2 (i) = kr=0 (ir ). periodicity G2 , G2 (i + 2 ) =SkSk0r=0 (ir + lcm(PG1 , PG2 )); hence G (i + 2 ) =r=0 (ir + lcm(PG1 , PG2 )).Since 1 = 2 , LG0 G0 (i) = kr=0 (ir ), G0 (i + 1 ) = G0 (i + 2 ) =Skr=0 (ir + lcm(PG1 , PG2 )). Hence, definition / , thesis.Intersect. LG0 = LG1 LG2 G0 (i) = G1 (i) = kr=0 (ir ). periodicityG1 G2 , + 1 LG1 eSi + 2 LG2 ; since 1 = 2 , + 1 LG0 . MoreoverG0 (i + 1 ) = G1 (i + 1 ) = kr=0 (ir + lcm(PG1 , PG2 )); hence, definition / ,thesis.Difference. LG0 = LG1 LG2 G0 (i) = G1 (i) = kr=0 (ir ). Since LG1periodicity G1 + 1 LG1 . Since/ LG2 , periodicity G2 , + 2/ LG2(if would exists + 2 LG2 , periodicity G2 would exists LG200Sk possible hypothesis). Hence + 1 LG . Moreover G (i + 1 ) = G1 (i + 1 ) =r=0 (ir + lcm(PG1 , PG2 )); hence, definition / , thesis.345fiBettini, Mascetti & WangA.12.2 Part 2P 0P 0Let LeG0 = LGG1 LGG2 .show LeG0 = LG0 proving (1) LeG0 LG0 (2) LeG0 LG0 .P 0(1) Suppose contradiction k LeG0 \ LG0 . Since k LeG0 k LGG1P0PP00P0k LGG2 . Suppose k LGG1 (the proof analogous k LGG2 ). Since k LGG1 ,00 < h < PG0 s.t. dheG = k. Since, definition Union operation G0 (k) = G1 (k),0dheG = k. Hence, definition L, k LG0 contrast hypothesis.(2) Suppose contradiction k LG0 \ LeG0 . Since k LG0 , then, definition0L, 0 < h < PG0 s.t. dheG = k. Moreover, definition Union operation, k LG1P 0P 0k LG2 . Suppose k LGG1 (the proof analogous k LGG2 ). definitionP0Union operation, G0 (k) = G1 (k) therefore dheG1 = k so, definition L, k LGG1 .e k LeG0 contradiction hypothesis.Hence, definition L,ReferencesBettini, C., & Mascetti, S. (2005). efficient algorithm minimizing time granularityperiodical representations. Proc. 12th International Symposium TemporalRepresentation Reasoning (TIME), pp. 2025. IEEE Computer Society.Bettini, C., Mascetti, S., & Pupillo, V. (2005). system prototype solving multigranularity temporal csp. Recent Advances Constraints, Revised selected papers Workshop Constraint Solving Constraint Logic Programming(CSCLP), volume 3419 Lecture Notes Computer Science, pp. 142156. Springer.Bettini, C., Mascetti, S., & Wang., X. S. (2004). Mapping calendar expressions periodical granularities. Proc. 11th International Symposium TemporalRepresentation Reasoning (TIME), pp. 96102. IEEE Computer Society.Bettini, C., & Sibi, R. D. (2000). Symbolic representation user-defined time granularities.Annals Mathematics Artificial Intelligence, 30 (1-4), 5392.Bettini, C., Wang, X. S., & Jajodia, S. (2000). Time Granularities Databases, DataMining, Temporal Reasoning. Springer.Bettini, C., Wang, X. S., & Jajodia, S. (2002a). Solving multi-granularity temporal constraint networks. Artificial Intelligence, 140 (1/2), 107152.Bettini, C., Wang, X. S., & Jajodia, S. (2002b). Temporal reasoning workflow systems.Distributed Parallel Databases, 11 (3), 269306.Bresolin, D., Montanari, A., & Puppis, G. (2004). Time granularities ultimately periodicautomata. Proc. 9th European Conference Logics Artificial Intelligence(JELIA) volume 3229 Lecture Notes Computer Science, pp. 513525. Springer.Chandra, R., Segev, A., & Stonebraker, M. (1994). Implementing calendars temporalrules next generation databases. Proc. 10th International ConferenceData Engineering (ICDE), pp. 264273. IEEE Computer Society.Combi, C., Franceschet, M., & Peron, A. (2004). Representing reasoning temporalgranularities. Journal Logic Computation, 14 (1), 5177.346fiMapping Calendar Expressions Minimal Periodic SetsCombi, C., & Pozzi, G. (2003). Temporal conceptual modelling workflows. Proc.22nd International Conference Conceptual Modeling (ER) volume 2813 LectureNotes Computer Science, pp. 5976. Springer.Cukierman, D., & Delgrande, J. P. (1998). Expressing time intervals repetition withinformalization calendars. Computational Intelligence, 14, 563597.Dal Lago, U., & Montanari, A. (2001). Calendars, time granularities, automata. Proc.7th International Symposium Spatial Temporal Databases (SSTD),volume 2121 Lecture Notes Computer Science, pp. 279298. Springer.Dal Lago, U., Montanari, A., & Puppis, G. (2003). Towards compact tractableautomaton-based representations time granularities. Proc. 8th ItalianConference Theoretical Computer Science (ICTCS), volume 2841 Lecture NotesComputer Science, pp. 7285. Springer.Dechter, R., Meiri, I., & Pearl, J. (1991). Temporal constraint networks. Artificial Intelligence, 49 (1-3), 6195.Kabanza, F., Stevenne, J. M., & Wolper, P. (1990). Handling infinite temporal data. Proc.9th ACM SIGACT-SIGMOD-SIGART Symposium Principles DatabaseSystems (PODS), pp. 392403. ACM Press.Koomen, J. (1991). Reasoning recurrence. International Journal Intelligent Systems, 6, 461496.Ladkin, P. B. (1986). Primitives units time specification. Proc. 5th NationalConference Artificial Intelligence (AAAI), pp. 353359. Morgan Kaufmann.Leban, B., McDonald, D., & Forster, D. (1986). representation collections temporalintervals. Proc. 5th National Conference Artificial Intelligence (AAAI),pp. 367371. Morgan Kaufmann.Li, Y., Ning, P., Wang, X. S., & Jajodia, S. (2001). Discovering calendar-based temporalassociation rules. Proc. 8th International Symposium Temporal Representation Reasoning (TIME), pp. 111118. IEEE Computer Society.Montanari, A. (1996). Metric Layered Temporal Logic Time Granularity. Ph.D.thesis, ILLC Dissertation Series 1996-02, University Amsterdam.Morris, R., Shoaff, W., & Khatib, L. (1996). Domain-independent temporal reasoningrecurring events. Computational Intelligence, 12, 450477.Niezette, M., & Stevenne, J. M. (1992). efficient symbolic representation periodictime. Proc. first International Conference Information KnowledgeManagement (CIKM) volume 725 Lecture Notes Computer Science, pp. 161168.Springer.Ning, P., Wang, X. S., & Jajodia, S. (2002). algebraic representation calendars.Annals Mathematics Artificial Intelligence, 36 (1-2), 538.Puppis, G. (2006). Automata Branching Layered Temporal Structures. Ph.D. thesis,Universita degli Studi di Udine.Terenziani, P. (2003). Symbolic user-defined periodicity temporal relational databases.IEEE Transactions Knowledge Data Engineering, 15 (2), 489509.347fiBettini, Mascetti & WangTuzhilin, A., & Clifford, J. (1995). periodicity temporal databases. InformationSystems, 20 (8), 619639.Urgun, B., Dyreson, C. E., Snodgrass, R. T., Miller, J. K., Soo, M. D., Kline, N., & Jensen,C. S. (2007). Integrating multiple calendars using TauZaman. Software-PracticeExperience, appear.Wijsen, J. (2000). string-based model infinite granularities. Spatial TemporalGranularity: Papers AAAI Workshop. Technical Report WS-00-08, pp. 916.AAAI Press.348fiJournal Artificial Intelligence Research 28 (2007) 107-118Submitted 9/05; published 2/07Generating Hard Satisfiable Formulas HidingSolutions DeceptivelyHaixia Jiahjia@cs.unm.eduComputer Science DepartmentUniversity New MexicoCristopher Mooremoore@santafe.eduComputer Science DepartmentUniversity New MexicoDoug Straindoug.strain@gmail.comComputer Science DepartmentUniversity New MexicoAbstracttest incomplete search algorithms constraint satisfaction problems 3SAT, need source hard, satisfiable, benchmark instances. simple waychoose random truth assignment A, choose clauses randomlyamong satisfied A. However, method tends produce easy problems, sincemajority literals point toward hidden assignment A. Last year, Achlioptas,Jia Moore proposed problem generator cancels effect hidingcomplement (Achlioptas, Jia, & Moore, 2004). resulting formulasappear hard DPLL algorithms random 3-SAT formulas hiddenassignment, solved WalkSAT polynomial time.propose new method cancel attraction A, choosing clause> 0 literals satisfied probability proportional q q < 1. varyingq, generate formulas whose variables bias, i.e., equally likelytrue false; even cause formula deceptively point away A. presenttheoretical experimental results suggesting formulas exponentially hardDPLL algorithms incomplete algorithms WalkSAT.1. Introductionevaluate search algorithms constraint satisfaction problems, need good sourcesbenchmark instances. Real-world problems best benchmarks definition,problem structures specific application domain; addition,wish study running times search algorithms scale, need entire familiesbenchmarks varying size density.One way fill need generate random instances. instance, 3-SATgenerate instancesn variables clauses choosing clause uniformlyamong 8 n3 possibilities. vary formulas accordingsize density r = m/n. formulas lack much structure realworld instances, instrumental development study new searchmethods simulated annealing (Johnson, Aragon, McGeoch, & Shevon, 1989),c2007AI Access Foundation. rights reserved.fiJia, Moore, & Strainbreakout procedure (Morris, 1993), WalkSAT (Selman, Kautz, & Cohen, 1996), SurveyPropagation (Mezard & Zecchina, 2002).However, wish test incomplete algorithms WalkSAT Survey Propagation (SP), need source problems hard satisfiable. contrast, critical density r 4.27, random formulas defined almost certainly unsatisfiable.Random formulas threshold appear quite hard complete solvers (Cheeseman, Kanefsky, & Taylor, 1991; Mitchell, Selman, & Levesque, 1992; Hogg, Huberman, &Williams, 1996); precisely reason, feasible generate large problemsthreshold filter unsatisfiable ones. classes satisfiableCSPs proposed, quasigroup completion problem (Shaw, Stergiou, &Walsh, 1998; Kautz, Ruan, Achlioptas, Gomes, Selman, & Stickel, 2001; Achlioptas, Gomes,Kautz, & Selman, 2000), would like problems generators native3-SAT.natural way generate random satisfiable 3-SAT formulas choose randomtruth assignment{0, 1}n , choose clauses uniformly independentlynamong 7 3 clauses satisfied A. problem simply rejecting clausesconflict causes unbalanced distribution literals; particular, averageliteral agree value hidden assignment 4/7 time. Thus, especiallymany clauses, simple majority heuristic local search quickly findA. sophisticated versions hidden assignment scheme (Asahiro, Iwama, &Miyano, 1996; Van Gelder, 1993) improve matters somewhat still lead biased samples.Thus question avoid attraction hidden assignment,One approach (Achlioptas et al., 2004) choose clauses uniformly amongsatisfied complement A. inspired recent workrandom k-SAT Not-All-Equal SAT (Achlioptas & Moore, 2002b), symmetryrespect complementation reduces variance number solutions; ideacancel others attractions out, making either one hard find. Indeed,resulting formulas appear take DPLL solvers exponential time and, general,hard random 3-SAT formulas hidden assignment.hand, WalkSAT solves formulas polynomial time, since variables setway agrees one hidden assignments, neighboring variables developcorrelations consistent (Barthel, Hartmann, Leone, Ricci-Tersenghi, Weigt, &Zecchina, 2002).paper, pursue alternate approach, inspired Achlioptas Preres,reweighted satisfying assignments natural way (Achlioptas & Peres, 2003). hideone assignment, bias distribution clauses follows:1. Predefine constant q < 1 generate random truth assignment {0, 1}n2. rn times: choose random k-tuple variables, choose among clauses> 0 literals satisfied probability proportional q .penalizes clauses satisfied A, reduces extentvariable occurrences likely agree A. (Note naive formulas discussedamount case q = 1.) see below, choosing q appropriatelyrebalance distribution literals, variable likely appear positively108fiGenerating Hard Satisfiable Formulas Hiding Solutions Deceptivelyoften negatively longer points toward value A. reducing q further,even make likely variable occurrence disagrees A,formula becomes deceptive points away hidden assignment.call formulas q-hidden, distinguish naive 1-hidden formulas discussed above, 2-hidden formulas studied Achlioptas, Jia Moore (Achlioptas et al., 2004), 0-hidden formulas consisting random 3-SAT formulashidden assignment. Like families, q-hidden formulas readily amenablemathematical tools developed studying random k-SAT formulas,including moment calculations method differential equations. calculateexpected density satisfying assignments function distance A,analyze behavior Unit Clause (UC) algorithm q-hidden formulas.present experiments several complete incomplete solvers. certain values q,find q-hidden formulas hard harder DPLL algorithms 0-hiddenformulas 2-hidden formulas, much harder naive 1-hidden formulas. addition, find local search algorithms like WalkSAT find formulas much harderfamilies, taking exponential opposed polynomial time. Moreover,running time WalkSAT increases sharply formulas become deceptive.2. Expected Density Solutions Bias Local Search[0, 1], let X number satisfying truth assignments random q-hiddenk-SAT formula agree fraction variables hidden assignment A;is, Hamming distance (1 )n. wish calculate expectationE[X ].symmetry, take all-true assignment. case, clause> 0 positive literals chosen probability q /((1 + q)k 1) (here normalizeprobabilities summing kt clauses > 0). Let B truth assignmentn variables true (1)n false. Then, analogous calculationAchlioptas, Jia Moore (Achlioptas et al., 2004), use linearity expectation, independence clauses, selection literals clause replacement,Stirlings approximation factorial obtain (where suppresses terms polynomialn):nPr[B satisfies random clause]mn!mkXk q (1 )t ktn1=(1 + q)k 1nt=1E[X ] =fk,r,q ()nf () =1(1 )11(q(1 ) + )k k(1 + q)k 1r.Looking Figure 1, see behavior f near = 1/2 changes dramaticallyvary q. q = 1 (i.e., naive 1-hidden formulas), f 0 (1/2) positive.109fiJia, Moore, & StrainDensity solutions q=0.5Density solutions r=61.11.4r=311.3q=0.50.91.2r=4q=0.6180.81.10.71r=50.6r=5.6q=10.9r=60.50.80.40.7r=70.300.20.40.60.80.6010.20.40.60.81Figure 1: nth root f () expected number solutions agreehidden assignment fraction variables. k = 3. left partfigure shows f () q = 1, q = 0.618 q = 0.5 r = 6. right partshows f () q = 0.5 varying r. Note r = 5.6, f () < 11/2.hand, q positive root q1 (1 q)(1 + q)k1 = 0(1)f 0 (1/2) =0. call resulting q -hidden formulas balanced; k = 3, qgolden ratio ( 5 1)/2 = 0.618...choice q affects local search algorithms WalkSAT following way.start random assignment B, step WalkSAT chooses random unsatisfiedclause, satisfies literal ` chosen randomly clause. expected changeHamming distance d(A, B) probability ` agrees A, minusprobability doesnt. Since clauses equally likely unsatisfiedrandom assignment, expectation 2t/k 1 random clause, namelyE[d(A, B)] =kXk q (2t/k 1)t=1(1 + q)k 1=1 (1 q)(1 + q)k1.(1 + q)k 1Thus zero (1) holds, case WalkSAT equally likely move toward awayA. Thus, analogous calculation Achlioptas Peres (Achlioptas & Peres,2003), q = q given literal equally likely agree disagree A, WalkSATinformation direction hidden assignment lies. (This argumentapplies first o(n1/2 ) steps WalkSAT, since unlikely seenvariable twice).110fiGenerating Hard Satisfiable Formulas Hiding Solutions Deceptivelysmaller values q q = 0.5 shown Figure 1, f 0 (1/2) becomes negative,expect local search algorithm starting random assignment move awayA. Indeed, f () local maximum < 1/2, small r solutions< 1/2. r sufficiently large, however, f () < 1 < 1/2,n probability alternate solutions exist exponentially small.conjecture q q threshold rc (q) high probabilitysolutions close A. Setting max{f () | 1/2} = 1 yields upperbound rc (q), show Figure 4 below. instance, dotted line Figure 1shows rc (0.5) 5.6.call formulas deceptive, since local search algorithms WalkSAT, DPLLalgorithms zChaff use majority heuristic splitting rule, messagepassing algorithms SP presumably search wrong direction, take exponential time cross local minimum f () find hidden assignment.experiments appear confirm intuition. addition, three types algorithms appear encounter difficulty roughly density rc (q),conjecture alternate solutions disappear.3. Unit Clause Heuristic DPLL AlgorithmsUnit Clause (UC) linear-time heuristic permanently sets one variablestep follows: unit clauses, satisfy them; otherwise, pick random literalsatisfy it. random 3-SAT formulas, UC succeeds constant probabilityr < 8/3, fails high probability r > 8/3 (Chao & Franco, 1986). UCthought first branch simple DPLL algorithm S, whose splitting rule takesrandom unset variable tries truth values random order; thus UC succeedssucceeds without backtracking. hand, showed Ss expected runningtime exponential n r > 8/3 (Cocco & Monasson, 2004; Cocco, Monasson,Montanari, & Semerjian, 2005); also Achlioptas, Beame Molloy used lower boundsresolution complexity show takes exponential time high probabilityr > 3.81 (Achlioptas, Beame, & Molloy, 2001). general, appears simple DPLLalgorithms begin take exponential time exactly density correspondinglinear-time heuristic fails.section, analyze performance UC q-hidden formulas. Specifically,show balanced case q = q , UC fails r > 8/30-hidden formulas. Based this, conjecture running time S,simple DPLL algorithms, exponentially large formulas density0-hidden ones.analyze behavior UC arbitrary initial distributions 3-SAT clauses usingmethod differential equations. simplicity assume all-true assignment. round UC consists free step, satisfy random literal,ensuing chain unit-clause propagations. 0 3 0 j i, let Si,j = si,j nnumberclauses length j positive literals j negative ones, letPsi = j si,j . Let X = xn number variables set far, let mT mFexpected number variables set true false round. model discrete111fiJia, Moore, & Strainstochastic process Si,j following differential equations si,j :ds3,jdxds2,jdx3s3,j1x2s2,jmF (j + 1)s3,j+1 + mT (3 j)s3,j=+1x(mT + mF )(1 x)=(2)unit clauses governed two-type branching process, transition matrix1s2,1 2s2,0M=.1 x 2s2,2 s2,1calculation Achlioptas Moore (Achlioptas & Moore, 2002a), longlargest eigenvalue less 1, branching process subcritical, summinground gives1/2mF1= (I ).1/2mTsolve equation (2) initial conditions s3,0 = 0qj3s3,j =j (1 + q)3 10 < j 3. balanced case q = q , find UC succeeds q-hidden formulasconstant probability r < 8/3, 0-hidden formulas. reasonthat, 2-hidden formulas, expected number positive negative literalsthroughout process. symmetry causes UC behave wouldrandom 3-SAT formulas without hidden assignment.note q < q , UC succeeds slightly higher densities, findone alternate solutions < 1/2. higher densities alternatesolutions disappear, experimental results show deceptive formulastake DPLL algorithms exponential time, r > rc (q) harder 0-hiddenformulas density.4. Experimental Results4.1 DPLLsection discuss behavior DPLL solvers q-hidden formulas. focuszChaff (Zhang, 2002); behavior OKsolver (Kullmann, 2002) similar. Figure 2shows zChaffs running time 0-hidden, 1-hidden, 2-hidden, q-hidden formulasvarious values q.Balanced formulas, i.e. q = q = 0.618..., appear hard 0-hiddenones, including satisfiability threshold r 4.27 0-hidden formulas becomeunsatisfiable. Like 0-hidden formulas, q -hidden formulas appear peak complexity near satisfiability threshold. consistent picture given previoustwo sections: namely, balanced formulas make impossible algorithmsfeel attraction hidden assignment. contrast, naive 1-hidden formulas fareasier, since attraction hidden assignment strong.112fiGenerating Hard Satisfiable Formulas Hiding Solutions DeceptivelyzChaff performance n=200zChaff performance r=5.5510410Median number Decisions 49 trialsMedian number Decisions 49 trials610q=0.2q=0.3q=0.4q=0.5q=0.6181hidden2hidden0hidden3102101104510q=0.30hiddenq=0.6182hidden1hidden41031021014.555.56r6.577.510508100150200250300NFigure 2: left part figure shows zChaffs median running time 49 trials0-hidden, 1-hidden, 2-hidden q-hidden formulas n = 200 r ranging4.0 8.0. right part shows median running time r = 5.5n ranging 50 300. Note 0-hidden formulas almost alwaysunsatisfiable r > 4.27.Deceptive formulas, i.e. q < q , appear two phases. low densityrelatively easy, hardness peaks density rc (q). rc (q) takeexponential time; 0-hidden formulas, r increases coefficientexponential decreases clauses generate contradictions quickly.believe peak rc (q) threshold density defined earlier (see Figure 4below) solutions close hidden assignment.situation seems following: rc (q), alternate solutions <1/2, zChaff led splitting rule. rc (q), alternate solutionsdisappear, zChaff takes exponential time find vicinity hidden assignment,since formula deceptively points direction. Moreover, fixed rrc (q) formulas become harder q decreases become deceptive.illustrate further, right part Figure 2 shows zChaffs median runningtime 0-hidden formulas, 1-hidden formulas, 2-hidden formulas, q-hidden formulasq = q (balanced) q = 0.3 (deceptive). fix r = 5.5, appearsrc (q) values q. density, 0-hidden, 2-hidden, balancedq-hidden formulas comparable difficulty, 1-hidden formulas much easierdeceptive formulas appear somewhat harder.4.2 SPSurvey Propagation SP (Mezard & Zecchina, 2002) recently introduced incompletesolver based insights replica method statistical physics generalizationbelief propagation. tested SP 0-hidden formulas q-hidden formulas differentvalues q, using n = 104 varying r. 0-hidden formulas, SP succeeds r = 4.25,113fiJia, Moore, & Strainquite close satisfiability threshold. q-hidden formulas q = q , SP fails4.25 0-hidden formulas, suggesting finds formulas exactlyhard 0-hidden ones even though guaranteed satisfiable. naive 1-hiddenformulas, SP succeeds significantly higher density, r = 5.6.Presumably naive 1-hidden formulas easier SP since messagesclauses variables, like majority heuristic, tend push algorithm towardshidden assignment. balanced case q = q , attraction successfully suppressed,causing SP fail essentially density 0-hidden formulas, close satisfiability threshold, even though q-hidden formulas continue satisfiable densities. contrast, 2-hidden formulas proposed Achlioptas, Jia Moore (Achlioptaset al., 2004) solved SP somewhat higher density r 4.8. Thus seemsreweighting approach q-hidden formulas better job confusing SP hidingtwo complementary assignments does.q < q , SP succeeds somewhat higher densities, matches quiteclosely value rc (q) zChaffs running time peaks (see Figure 4 below). Buildingconjecture density solutions closehidden assignment, guess SP succeeds r < rc (q) preciselylocal gradient density solutions pushes towards alternate solutions< 1/2. rc (q), solutions longer exist, SP fails clauses senddeceptive messages, demanding variables set opposite hidden assignment.4.3 WalkSATconclude local search algorithm, WalkSAT. formula, 104restarts, 104 steps per attempt, step random greedy flipequal probability. left part Figure 3 measure WalkSATs performance 1hidden, 2-hidden, q-hidden formulas various values q. use n = 200 rrange 4 8. Even relatively small formulas, see threedeceptive values q, density median running time jumps 108flips. instance, q-hidden formulas q = 0.4 appear unfeasible WalkSAT for,say, r > 5.believe that, consistent discussion above, local search algorithms likeWalkSAT greedily follow gradient density solutions f (). q < q ,gradient deceptive, lures WalkSAT away hidden assignment. densitiesrc (q), many alternate solutions < 1/2 WalkSAT finds oneeasily; densities rc (q), solutions near hiddenassignment, WalkSATs greed causes wander exponentially long timewrong region. picture supported fact that, Figure 4 shows below, density WalkSATs running time jumps upward closely matches thresholds rc (q)observed zChaff SP.right part Figure 3 looks WalkSATs median running time fixed densityfunction n. compare 1-hidden 2-hidden formulas q-hidden onesq = q two deceptive values, 0.5 0.3. choose r = 5.5, rc (q)three values q. running time 1-hidden 2-hidden formulaspolynomial (Achlioptas et al., 2004; Barthel et al., 2002). contrast, even balanced114fiGenerating Hard Satisfiable Formulas Hiding Solutions Deceptivelycase q = q , running time exponential, slope exponential increasesdramatically decrease q make formulas deceptive. notemight possible develop heuristic analysis WalkSATs running time deceptivecase (Semerjian & Monasson, 2003; Cocco et al., 2005).WalkSAT performance n=20088710610510q=0.2q=0.3q=0.4q=0.5q=0.6181hidden2hidden410310210WalkSAT performance r=5.510Median number flips 49 trialsMedian number flips 49 trials104710q=0.3q=0.5q=0.6182hidden1hidden61051041031024.555.56r6.577.510508100 150 200 250 300 350 400 450 500 550 600NFigure 3: left part figure shows WalkSATs median running time 49 trialsn = 200 r ranging 4 8; right part shows median runningtime r = 5.5 n ranging 50 600.5. Threshold Densityseen, appears characteristic density rc (q) value q qrunning time DPLL algorithms like zChaff peaks, WalkSATs runningtime becomes exponential, SP ceases work. conjecture threecases, key phenomenon density solutions < 1/2 disappear,leaving close hidden assignment. Figure 4 shows measured valuesrc (q), indeed quite close three algorithms. also show analyticupper bound rc (q) resulting setting max{f () | 1/2} = 1,expected number solutions 1/2 exponentially small.6. Conclusionsintroduced simple new way hide solutions 3-SAT problems producesinstances hard satisfiable. Unlike 2-hidden formulas proposedAchlioptas, Jia Moore (Achlioptas et al., 2004) attraction hiddenassignment cancelled also hiding complement, eliminate attractionreweighting distribution clauses proposed Achlioptas Peres (Achlioptas& Peres, 2003). Indeed, going beyond value parameter q makesq-hidden formulas balanced, create deceptive formulas lead algorithmswrong direction. Experimentally, formulas hard harder DPLL algorithms115fiJia, Moore, & Strain12Upper boundzChaffSPWalkSAT1110rc(q)9876540.20.30.4q0.50.6Figure 4: density rc (q) running time zChaff peaks, WalkSAT peaksexceeds 108 flips, SP stops working. conjecture events occurdensity alternate solutions < 1/2 disappear, leavingclose hidden assignment. Shown also analytic upperbound described text.0-hidden formulas, i.e., random 3-SAT formulas without hidden assignment; localsearch algorithms like WalkSAT, much harder 0-hidden 2-hidden formulas,taking exponential rather polynomial time. formulas also amenablemathematical tools developed study random 3-SAT; calculatedexpected density solutions function distance hidden assignment,used method differential equations show UC fails density0-hidden formulas.close several exciting directions future work:1. Confirm single threshold density rc (q) a) alternate solutionsfar hidden assignment disappear, b) running time DPLL algorithmsmaximized, c) SP stops working, d) running time WalkSAT becomesexponential;2. Prove simple DPLL algorithms take exponential time r > rc (q), expectationhigh probability;3. Calculate variance number solutions function , givingimproved upper lower bounds distribution solutions rc (q).AcknowledgmentsH.J. supported NSF Graduate Fellowship. C.M. D.S. supported NSFgrants CCR-0220070, EIA-0218563, PHY-0200909. C.M. thanks Tracy ConradRosemary Moore support.116fiGenerating Hard Satisfiable Formulas Hiding Solutions DeceptivelyReferencesAchlioptas, D., Beame, P., & Molloy, M. (2001). sharp threshold proof complexity.Proc. STOC, pp. 337346.Achlioptas, D., Gomes, C., Kautz, H., & Selman, B. (2000). Generating satisfiable probleminstances. Proc. AAAI, pp. 256261.Achlioptas, D., Jia, H., & Moore, C. (2004). Hiding satisfying assignments: two betterone. Proc. AAAI, pp. 131136.Achlioptas, D., & Moore, C. (2002a). Almost graphs average degree 4 3colorable. Proc. STOC, pp. 199208.Achlioptas, D., & Moore, C. (2002b). asymptotic order random k-SAT threshold.Proc. FOCS, pp. 779788.Achlioptas, D., & Peres, Y. (2003). threshold random k-SAT 2k (ln 2 o(k)).Proc. STOC, pp. 223231.Asahiro, Y., Iwama, K., & Miyano, E. (1996). Random generation test instancescontrolled attributes. DIMACS Series Disc. Math. Theor. Comp. Sci., 26.Barthel, W., Hartmann, A., Leone, M., Ricci-Tersenghi, F., Weigt, M., & Zecchina, R.(2002). Hiding solutions random satisfiability problems: statistical mechanicsapproach. Phys. Rev. Lett., 88 (188701).Chao, M., & Franco, J. (1986). Probabilistic analysis two heuristics 3-satisfiabilityproblem. SIAM J. Comput., 15 (4), 11061118.Cheeseman, P., Kanefsky, R., & Taylor, W. (1991). really hard problems are.Proc. IJCAI, pp. 163169.Cocco, S., & Monasson, R. (2004). Heuristic average-case analysis backtrack resolution random 3-satisfiability instances. Theor. Comp. Sci., 320, 345372.Cocco, S., Monasson, R., Montanari, A., & Semerjian, G. (2005). Approximate analysissearch algorithms physical methods. Percus, A., Istrate, G., & Moore, C.(Eds.), Computational Complexity Statistical Physics. Oxford University Press.Hogg, T., Huberman, B., & Williams, C. (1996). Phase transitions complexity. ArtificialIntelligence, 81.Johnson, D., Aragon, C., McGeoch, L., & Shevon, C. (1989). Optimization simulatedannealing: experimental evaluation. Operations Research, 37 (6), 865892.Kautz, H., Ruan, Y., Achlioptas, D., Gomes, C., Selman, B., & Stickel, . (2001). Balancefiltering structured satisfiable problems. Proc. IJCAI, pp. 351358.Kullmann, O. (2002). Investigating behaviour SAT solver random formulas.Tech. rep. CSR 23-2002, University Wales Swansea.Mezard, M., & Zecchina, R. (2002). Random k-satisfiability: analytic solutionnew efficient algorithm. Phys. Rev. E, 66, 056126.Mitchell, D., Selman, B., & Levesque, H. (1992). Hard easy distributions SATproblems. Proc. AAAI, pp. 459465.117fiJia, Moore, & StrainMorris, P. (1993). breakout method escaping local minima. Proc. AAAI,pp. 4045.Selman, B., Kautz, H., & Cohen, B. (1996). Local search strategies satisfiability testing.Proc. 2nd DIMACS Challange Cliques, Coloring, Satisfiability.Semerjian, G., & Monasson, R. (2003). study pure random walk random satisfiabilityproblems physical methods. LNCS, 2919, 120134.Shaw, P., Stergiou, K., & Walsh, T. (1998). Arc consistency quasigroup completion.Proc. ECAI, workshop binary constraints.Van Gelder, A. (1993). Problem generator mkcnf.c. Proc. DIMACS. Challenge archive.Zhang, L. (2002). zChaff.. ee.princeton.edu/chaff/zchaff.php.118fiJournal Artificial Intelligence Research 28 (2007) 183232Submitted 5/06; published 3/07Proactive Algorithms Job Shop SchedulingProbabilistic DurationsJ. Christopher Beckjcb@mie.utoronto.caDepartment Mechanical & Industrial EngineeringUniversity Toronto, CanadaNic Wilsonn.wilson@4c.ucc.ieCork Constraint Computation CentreUniversity College Cork, IrelandAbstractclassical scheduling formulations assume fixed known duration activity. paper, weaken assumption, requiring instead durationrepresented independent random variable known mean variance.best solutions ones high probability achieving good makespan.first create theoretical framework, formally showing Monte Carlo simulationcombined deterministic scheduling algorithms solve problem. proposeassociated deterministic scheduling problem whose solution proved, certain conditions, lower bound probabilistic problem. propose investigatenumber techniques solving problems based combinations Monte Carlosimulation, solutions associated deterministic problem, either constraint programming tabu search. empirical results demonstrate combination useassociated deterministic problem Monte Carlo simulation results algorithmsscale best terms problem size uncertainty. experiments pointcorrelation quality deterministic solution qualityprobabilistic solution major factor responsible success.1. IntroductionProactive scheduling techniques seek produce off-line schedule robust execution time events. paper, assume perfect knowledgeduration activity: durations determined execution timeobserved activity finished. However, partial knowledge formknown probability distribution duration. execution time, activitiesdispatched according sequences defined off-line schedule measurerobustness probability given quality achieved. specifically,paper, address problem job shop scheduling (and related generalizations)durations activities random variables objective findsolution high probability good (ideally, minimal) makespan.challenging problem even evaluating solution hard problem.address problem, develop theoretical framework within formallydefine problem (a) construct approach, based Monte Carlo simulation,evaluating solutions partial solutions, (b) show solving carefully defineddeterministic job shop scheduling problem results lower bound probabilisticc2007AI Access Foundation. rights reserved.fiBeck & Wilsonminimum makespan probabilistic job shop scheduling problem. use frameworkdefine number algorithms embodying three solution approaches:1. Branch-and-bound search Monte Carlo simulation: search node,search pruned almost certain (based Monte Carlo simulation)partial solution cannot extended solution better current bestsolution.2. Iterative deterministic search descending lower bound: deterministic jobshop problem whose solution lower bound probabilistic job shop problemdefined using parameter, q. lower bound proof depends q lessequal q (I), problem-instance-dependent threshold value problem instancedifficult compute. Starting high q value, use tree searchMonte Carlo simulation solve sequence deterministic problems decreasingq values. q large, problems highly constrained easy solve (ifsolutions exist). q descends, best probabilistic makespan previousiterations used restrict search. able reach value qq q (I) within CPU time limit, search approximately completesubject sampling error.3. Deterministic filtering search: deterministic scheduling algorithms based constraintprogramming tabu search used define number filter-based algorithms.algorithms operate generating series solution candidatesevaluated Monte Carlo simulation.empirical results indicate Monte Carlo based branch-and-boundpractical small problems. iterative search based descending q valuesgood as, better than, branch-and-bound algorithm small problems, performssignificantly better larger problems. However, even medium-sized problems,techniques inferior heuristic approaches based deterministic filtering.Contributions.main contributions paper are:introduction problem finding proactive schedules probabilistic execution guarantees class problems underlying deterministic schedulingproblem NP-hard;development method generating lower bound probabilistic minimum makespan;development particular Monte Carlo approach evaluating solutions;design empirical analysis number approximately complete heuristic solution techniques based either constraint-based constructive search tabusearch;identification correlation deterministic probabilistic solutionquality key factor performance filter-based algorithms.184fiProactive Algorithms JSPPlan Paper. next section define probabilistic job shop scheduling problem, illustrating example. Section 3 discusses related work. Section 4,present theoretical framework: formally define problem, derive approachgenerating lower bound based associated deterministic job shop problem,show Monte Carlo simulation used evaluate solutions partial solutions.Six search algorithms defined Section 5 empirical investigations resultsappear Section 6. Section 7, shown results paper apply muchgeneral classes scheduling problems. Directions future work based theoreticalalgorithmic extensions also discussed.2. Probabilistic Job Shop Scheduling Problemsjob shop scheduling problem probabilistic durations natural extensionstandard (deterministic) job shop scheduling problem (JSP).2.1 Job Shop Scheduling ProblemsJSP involves set activities, Ai positive duration di .instance JSP, assumed either durations positive integers,positive real numbers.1 partitioned jobs, job associatedtotal ordering set activities. activity must execute specifiedunary capacity resource. activities require resource overlapexecution, activity started must executed entire duration.represent formally another partition resource sets: two activitiesresource set require resource.solution consists total ordering resource set, conflictjobs ordering, i.e., union resource orderings job orderings acyclicrelation A. Thus, Ai Aj resource set, solution either orders AiAj (meaning Aj starts sooner end Ai ), Aj Ai . setsolutions job shop problem labeled S. partial solution consists partialordering resource set extended solution.Let (partial) solution. path (or s-path) sequence activitiesAi immediately precedes Aj sequence, either (i) Ai Ajjob, Ai precedes Aj job, (ii) Ai Aj resource setorders Ai Aj . length, len(), pathP (of solution) equalsum durations activities path, i.e., Ai di . makespan, make(s),solution defined length longest s-path. s-path, , saidcritical s-path length equal makespan solution s, i.e., onelongest s-paths. minimum makespan job shop scheduling problem definedminimum value make(s) solutions s.definitions focus solutions rather schedules. Here, briefly indicate definitions relate to, perhaps immediately intuitive, definitions focusingschedules. schedule assigns start time activity, considered1. empirical investigations examine integer case. shown below, theoretical results hold alsocase positive real number durations.185fiBeck & Wilsonfunction set activities set time-points, defining activitystarts. set time-points assumed either set non-negative integersset non-negative real numbers. Let starti start time activity Airespect particular schedule, let endi , end time, starti + di . Ai , Aj A,write Ai Aj constraint endi startj . schedule defined validfollowing two conditions hold two different activities Ai , Aj A: (a) Ai precedesAj job, Ai Aj ; (b) Ai Aj resource set,either Ai Aj Aj Ai (since Ai Aj allowed overlap).Let Z valid schedule. Define make(Z), makespan Z, maxAi endi ,time last activity completed. minimum makespan definedminimum value make(Z) valid schedules.solution defines valid schedule sched(s), activity started soonimmediate predecessors (if any) finished, activities without predecessorsstarted time-point 0 (so sched(s) non-delay schedule given precedence constraintsexpressed s). immediate predecessor activity Aj respect particularsolution defined activity immediate predecessor Aj eitherrespect ordering job containing Aj , respect ordering (associatedsolution) resource set containing Aj . shown makespansched(s) equal make(s) defined earlier, hence justifying definition.Conversely, given valid schedule Z, define solution, call sol(Z),ordering resource set relation defined above. Z schedule,makespan sched(sol(Z)), equal make(sol(Z)), less equalmakespan Z. implies minimum makespan solutions equalminimum makespan valid schedules. Therefore, interested schedulesbest makespans, need consider solutions associated schedules.summarize, aiming find minimum makespan JSP, focussearching solutions, rather schedules, (i) schedule Z,exists solution = sol(Z) Z consistent (i.e., satisfies precedence constraints expressed s); (ii) solution s, efficiently constructschedule sched(s) optimal among schedules consistent (and furthermore,makespan sched(s) equal make(s)).JSP Example. Consider job shop scheduling problem involving two jobs five activities shown Figure 1. first job consists sequence (A1 , A2 , A3 ) activities;second job consists sequence (A4 , A5 ). three resources involved. A1A4 require first resource; hence activities A1 A4 cannot overlap, either (i)A1 precedes A4 , (ii) A4 precedes A1 . Activities A3 A5 require second resource;A2 requires third resource. Hence, resource sets {A1 , A4 }, {A2 } {A3 , A5 }.four solutions:sa involves orderings A1 A4 A3 A5 ;sb defined A1 A4 A5 A3 ;sc A4 A1 A3 A5 ;sd A4 A1 A5 A3 .186fiProactive Algorithms JSPA1A2A3A4A1A2A5A3A4A1A5A2A4A5Solution SaA1A2Solution SbA3A4A3A1A5A2A3A4Solution ScA5Solution SdFigure 1: example JSP four solutions.duration activity Ai di . sequence (A1 , A4 , A5 ) sa -path, whose lengthd1 +d4 +d5 . Also, sa -path (A1 , A2 , A3 , A5 ), len() = d1 +d2 +d3 +d5 .sa -paths subsequences one two. Hence, make(sa ), makespansolution sa , equal max(d1 + d4 + d5 , d1 + d2 + d3 + d5 ) = d1 + d5 + max(d4 , d2 + d3 ).particular, d1 = 1, d2 = 2, d3 = 3, d4 = 4 d5 = 5, make(sa ) = 11 time units.also make(sb ) = 13, make(sc ) = 15 make(sd ) = 12. Hence, minimummakespan make(sa ) = 11.Let Z = sched(sa ) schedule associated solution sa . generatedfollows. A1 predecessors, start A1 beginning, setting Z(A1 ) = 0; henceactivity A1 starts time-point 0 ends time-point d1 . predecessor A4A1 , set Z(A4 ) = d1 . Similarly, set Z(A2 ) = d1 , activity A2 endstime-point d1 + d2 . Continuing, set Z(A3 ) = d1 + d2 . Activity A5 two immediatepredecessors (for solution, sa ), A3 A4 , A5 set start soonactivities completed, time-point max(d1 + d2 + d3 , d1 + d4 ).activities completed A5 completed, time-pointmax(d1 +d2 +d3 , d1 +d4 )+d5 = d1 +d5 +max(d4 , d2 +d3 ). confirms makespanmake(sa ) solution sa equal makespan associated schedule sched(sa ).2.2 Independent General Probabilistic Job Shop Scheduling Problemsindependent probabilistic job shop scheduling problem defined wayJSP, except duration di associated activity Ai random variable;assume instance probabilistic JSP, either durations positiveinteger-valued random variables, positive real-valued random variables.(known) distribution Pi , expected value = E[di ] variance i2 = Var[di ].187fiBeck & Wilsonrandom variables fully independent. length path solutionrandom variable, write len(). makespan make(s) solution (thelength longest path s) therefore also random variable, sometimesrefer random makespan s.generalize non-independent case. probabilistic job shop scheduling problem joint probability measure P durations vectors. (The intentionefficiently sample joint density function. example, Bayesiannetwork might used represent P .) Here, activity Ai , distribution Pi definedappropriate marginal distribution, expected value variance i2 .Loosely speaking, probabilistic job shop scheduling problem, want findsmall value possible solution whose random makespan is,high probability, less (the deadline activities finish). time valuecalled probabilistic minimum makespan.Evaluating solution deterministic JSP, i.e., finding associated makespan givenduration activity, achieved low degree polynomial time using longestpath algorithm. Without ordering resource set, disjunctions resourceconstraints must satisfied find solution turn easy problemNP-complete JSP (Garey & Johnson, 1979). PERT networks, hand, generalizesimple longest-path problem allowing durations independent random variables,leading #P-complete problem (Hagstrom, 1988). probabilistic JSP makesgeneralizations. Consequently, finding optimal solutions probabilistic JSPappears hard, focus methods finding good solutions instead.Evaluating (approximately) solution probabilistic JSP done relativelyefficiently using Monte Carlo simulation: large number trials randomlysample duration every activity generate makespan associatedtrial. Roughly speaking, approximately evaluate solution evaluating sampleddistribution makespans. approach described detail Section 4.3.Almost solution techniques involve associating deterministic job shop problemgiven probabilistic job shop problem, replacing, number q, randomduration mean distribution plus q times standard deviation. Hence, setduration di activity Ai associated deterministic problem +qcase continuous time. case time-points integers, set = bi +qi c.certain values q, leads minimum makespan deterministic problemlower bound probabilistic minimum makespan, shown Section 4.2.lower bound useful pruning branch-and-bound algorithm. generally,show solving associated deterministic problem used help solveprobabilistic problem.assumptions joint probability somewhat restrictive. example,model allow activitys duration depend start time; however,extended certain situations kind.2 Despite restrictions (which commonrelated literaturesee Section 3), model apply interesting class problems2. could allow duration activity probabilistically dependent start time, givenadditional (very natural) coherence condition time-point t0 , conditional probabilityendi t0 , given starti = t, monotonically increasing t, i.e., Pr(endi t0 |starti = t1 )Pr(endi t0 |starti = t2 ) t1 t2 . condition ensures that, given solution,188fiProactive Algorithms JSPpreviously addressed. Extending model richer representationsrelaxing assumptions remains future work.Probabilistic JSP Example. consider independent probabilistic job shop scheduling problem structure JSP example Figure 1. durationsactivities A2 , A3 A4 independent real-valued random variables (referredd2 , d3 d4 , respectively) approximately normally distributed standard deviation 0.5 (2 = 3 = 4 = 0.5) means 2 = 2, 3 = 3 4 = 4.durations activities A1 A5 deterministic, equal 1 5, respectively.Let sa -path (A1 , A2 , A3 , A5 ). length len() approximatelynormally distributed random variablewith mean 1+2+3+5 = 11 variance 0.5 2 +0.52 =0.5 hence standard deviation 1/ 2.length sa -path 0 = (A1 , A4 , A5 ) approximately normal random variablemean 10 standard deviation 0.5. (random) makespan make(sa ) solutionsa random variable equaling maximum random variables len() len( 0 ).general, maximum two independent normally distributed random variablesnormally distributed; however, is, high probability, longer 0 , distributionmake(sa ) approximately equal distribution len().3. Previous Workconsiderable work scheduling uncertainty variety fieldsincluding artificial intelligence (AI), operations research (OR), fault-tolerant computing,systems. surveys literature, mostly focusing AI OR, see workDavenport Beck (2000), Herroelen Leus (2005), Bidot (2005).highest level, two approaches problems: proactive scheduling,knowledge uncertainty taken account generating off-lineschedule; reactive scheduling decisions made on-line deal unexpectedchanges. significant work reactive scheduling and, indeed, techniquescombine reactive proactive scheduling least commitment approaches (seesurveys noted above), interest pure proactive scheduling. Three categoriesproactive approaches identified: redundancy-based techniques, probabilistictechniques, contingent/policy-based techniques (Herroelen & Leus, 2005). brieflylook turn.3.1 Redundancy-based TechniquesRedundancy-based techniques generate schedule includes allocation extraresources and/or time schedule. intuition redundant allocationshelp cushion impact unexpected events execution. example, extra timeconsumed activity takes longer expected execute.clear conflict insertion redundancy common measures schedule quality(e.g., makespan), focus work tends intelligent insertion redundancyorder achieve satisfactory trade-off schedule quality robustness.advantage delaying starting activity predecessors finished. Allowing delaywould break assumptions underlying formulation.189fiBeck & Wilsoncommon fault-tolerant scheduling real-time guarantees reserve redundantresources (i.e., processors) time. former case, multiple instantiations givenprocess executed parallel error detection done comparing resultsdifferent instantiations. contrast, time redundancy, time reservedre-execution process fails. Given fault model, either technique usedprovide real-time guarantees (Ghosh, Melhem, & Mosse, 1995; Ghosh, 1996).similar approach used work Gao (1995) Davenport, Gefflot Beck(2001) context job shop scheduling. Statistical information mean timefailure mean repair time machines used either extend durationcritical activities former work require solution produced must respectconstraints slack activity. Given solution, slack roomactivity move without breaking constraint increasing cost. Typically,formalized difference activitys possible time window solution (i.e.,latest possible end time less earliest possible start time) duration activity.advantage Gaos approach purely modeling approach: problemchanged incorporate extended durations scheduling techniques usedsolve problem. However, Davenport et al. show reasoning slack sharedamongst set activities lead better solutions cost specialized solvingapproaches.Leon, Wu Storer (1994) present approach job shop schedulingobjective function modified linear combination expected makespanexpected delay assuming machines break that, execution time, disruptions dealt shifting activities later time maintaining sequenceoriginal schedule. basic technique properly seen probabilisticapproach, authors show exact calculation measure intractable unlesssingle disruption assumed. likely multiple disruptions, authorspresent number surrogate measures. Empirically, best surrogate measuredeterministic makespan minus mean activity slack. Unlike, Gao Davenport et al.,Leon et al. provide formal probabilistic foundation, temporal redundancy playscentral role practical application approach.3.2 Probabilistic TechniquesProbabilistic techniques use representations uncertainty reason likely outcomesschedule executed.3 Rather explicitly inserting redundancy attemptcreate robust schedule, probabilistic techniques build schedule optimizesmeasure probabilistic performance. Performance measures typically come two forms:expected value expected makespan expected weighted tardiness, probabilistic guarantee respect threshold value deterministic optimization measure.example latter measure, discussed below, probability flow timeschedule less particular value.Optimal expected value scheduling problems widely studied (Pinedo,2003). many cases, approach takes form dispatch rules slightlycomplicated polynomial time algorithms find optimal schedule tractable3. Alternative representations uncertainty fuzzy sets also used (Herroelen & Leus, 2005).190fiProactive Algorithms JSPproblems (e.g., 1 2 machine problems) serve heuristics difficultproblems. One example work AI literature Wurman Wellman(1996) extends decision theoretic planning concepts scheduling. problemstudied assumes single machine, stochastic processing time stochastic set-up time,objective minimization expected weighted number tardy jobs.authors propose state-space search solve problem multi-objective stochasticdominance A*. Critical aspects work use number sophisticated pathpruning rules relaxation-based heuristics evaluation promising nodes.threshold measure used Burns, Punnekkat, Littlewood Wright (1997)fault-tolerant, single processor, pre-emptive scheduling application. objective findminimum fault arrival rate tasks scheduled meet deadlines.Based fault-model, probability observing fault arrival rate calculatedused measure schedule quality. optimization problem, then, findschedule maximizes probability tasks meeting deadlines faultarrival process.one-machine manufacturing context independent activities, Daniels Carrillo (1997) define -robust schedule sequence maximizes probabilityexecution achieve flow time greater given threshold. underlying deterministic scheduling problem solvable polynomial time and, indeed,minimum expected flow time schedule found polynomial time, shownfinding -robust schedule NP-hard. Daniels Carrillo present branch-and-boundheuristic techniques solve problem.3.3 Contingent Policy-based ApproachesUnlike approaches described above, contingent policy-based approachesgenerate single off-line schedule. Rather, produced branching contingentschedule or, extreme, policy, specifies actions taken particularset circumstances arises. Given importance off-line schedule termscoordination entities context surrounding scheduling problem,difference significant practical implications (see Herroelen & Leus, 2005,discussion).elegant example contingent scheduling approach just-in-case workDrummond, Bresina Swanson (1994). Given initial, deterministic schedulesingle telescope observation problem, approach identifies activity likely failbased available uncertainty information. point, new schedule producedassuming activity does, indeed, fail. Repeated application identificationmost-likely-to-fail activity generation new schedule results branching schedulenumber likely contingencies accounted alternative schedules.execution time, activity fails, execution switches alternative scheduleone exists. alternative exist, on-line rescheduling done. Empirical resultsdemonstrate significantly larger portion existing (branching) scheduleexecuted without revert rescheduling compared original deterministicschedule.191fiBeck & WilsonOne weaknesses just-in-case scheduling surrounds combinatoricsmultiple resources. multiple inter-dependent telescopes, problem quickly becomesintractable. Policy-based approaches Markov Decision Processes (MDPs) (Boutilier,Dean, & Hanks, 1999) applied problems. Here, objectiveproduce policy mapping states actions direct on-line executionschedule: given state encountered, corresponding action taken. Meuleau etal. (1998) apply MDPs stochastic military resource allocation problem weaponsmust allocated targets. Given limited number weapons uncertaintyeffectiveness given allocation, MDP used derive optimal policystates represented number remaining weapons targets, actionsweapon allocation decisions. goal minimize expected number survivingtargets. Empirical results demonstrated computational challenges approach6 target, 60 weapon problem required approximately 6 hours CPU time (albeitnow-outdated hardware).literature, substantial work (cited Brucker, Drexl, Mohring,Neumann Pesch, 1999, Herroelen Leus, 2005) stochastic resource-constraintproject scheduling, generalization job shop scheduling. general formapproaches multi-stage stochastic programming problem, objective findingscheduling policy minimize expected makespan. context, schedulingpolicy makes decisions on-line activities execute. Decisions need madebeginning schedule end time activity, information useddecisions must become known time decisionmaking. number different classes policy investigated. example,minimal forbidden subset activities, F , set activities F cannotexecuted simultaneously due resource constraints, subset Fexecuted. pre-selective policy identifies set F waiting activity, j F ,j cannot started least one activity F {j} executed.execution, j started least one activity F finished.proactive problem, then, identify waiting activity minimal forbiddensubset expected makespan minimized. computational challengespre-selective policies (in particular, due number minimal forbidden subsets)led work different classes policy well heuristic approaches.3.4 Discussionwork paper falls within probabilistic scheduling approachesclosely inspired -robustness work Daniels Carrillo (1997). However, unlikeDaniels Carrillo, address scheduling model deterministic problemunderlies probabilistic job shop scheduling problem is, itself, NP-hard.first work aware seeks provide probabilistic guaranteesunderlying deterministic problem computationally difficult.4. Theoretical Frameworksection, develop theoretical framework probabilistic job shop problems.Section 4.1, define compare solutions, using call -makespans.192fiProactive Algorithms JSP-makespan solution less time value D, least chance 1(random) makespan less D. useful idea farsolutions -makespan optimum -makespan (i.e., minimum -makespansolutions), Section 4.2, describe approach finding lower boundoptimum -makespan. Section 4.3 considers problem evaluating given solution, s,using Monte Carlo simulation estimate -makespan s.order separate theoretical contributions empirical analysis, summarize notation introduced section Section 5.1. Readers interested primarilyalgorithms empirical results therefore move directly Section 5.section makes use notation introduced Section 2: definitions Section2.1 JSP, solution, paths solution, makespan solution, minimummakespan; definitions Section 2.2 probabilistic JSP random makespansolution.4.1 Comparing Solutions Probabilistic Makespanstandard job shop problem, solutions compared considering associatedmakespans. probabilistic case, makespan solution random variable,comparing solutions less straight-forward. map random makespan scalarquantity, called -makespan, sums good is; solutions comparedcomparing associated -makespans. simple idea prefer solutions smallerexpected makespan. However, may substantial probability makespansolution much higher expected value. Instead, take followingapproach: confident random makespan solution D,cannot confident makespan solution s0 D, prefersolution solution s0 .fix value , used bound probabilities. Although imaginenatural applications work, would quite small (e.g., less 0.1)assume range (0, 0.5]. probability event least 1 ,say event sufficiently certain. experiments described Section 6use value = 0.05, sufficiently certain means occurs least 95%chance.Let time value, let solution. said -achievable usingsufficiently certain jobs finish use solution s; is,Pr(make(s) D) 1 , make(s) random makespan s.said -achievable solution -achievable usings, i.e., exists solution making sufficiently certain jobs finish D.Time value -achievable maxsS Pr(make(s) D)) 1 ,max solutions s.Define Ach (s) set -achievable using s. define (s),-makespan s, infimum4 Ach (s). , -minimum makespan,defined infimum Ach , set -achievable,4. is, greatest lower bound Ach (s); fact, shown Proposition 1(i), (s) smallestelement Ach (s). Hence, Ach (s) equal closed interval [D (s), ), i.e., set time-points(s).193fiBeck & Wilson= inf {D : (maxsS Pr(make(s) D)) 1 }. also sometimes refer (s)probabilistic makespan s, refer probabilistic minimum makespan.5prefer solutions better (i.e., smaller) -makespans. Equivalently, solutionconsidered better s0 time value -achievable using-achievable using s0 . Optimal solutions ones whose -makespan equal-minimum makespan.prove technical properties -makespans -achievability relevantmathematical results later sections. particular, Proposition 1(ii) states minimum makespan -achievable: i.e., exists solution makessufficiently certain jobs finish . smallest value satisfyingproperty.Lemma 1 notation:(i) Ach =sSAch (s);(ii) exists solution Ach = Ach (s) = (s);(iii) = minsS (s), minimum (s) solutions s.Proof:(i) -achievablesolution s, Ach (s), truesS Ach (s).(ii) Consider following property () set time values A: 0 timevalue greater (i.e., 0 > D), 0 A; is, interval upperbound. Let B two sets property (); either B B A. (To showthis, suppose otherwise, neither B B A; exists x BB A; x must different, assume, without lossgenerality, x < y; property (), contradiction required.)Hence, B either equal equal B. using induction, followsunion finite number setsproperty () one sets. set Ach (s)satisfies property (); therefore, sS Ach (s) = Achs0 solution s0 , so, (i),Ach = Achs0 . implies also = (s0 ).(iii) Let solution let time value. Clearly, -achievable usings, -achievable. implies (s). Hence, minsS (s).(ii), = (s) solution s, = minsS (s), required.2Proposition 1(i) Let solution. (s) -achievable using s, i.e., Pr(make(s) (s))1 .(ii) -achievable, i.e., exists solution Pr(make(s) ) 1.5. Note probabilistic makespan number (a time value), opposed random makespansolution, random variable.194fiProactive Algorithms JSPProof:discrete case, set time values set non-negative integers,infimum definitions (s) minimum. (i) (ii)follow immediately definitions.consider case set time values set non-negative realnumbers.11(i): m, n {1, 2, . . . , }, let Gm = Pr(0 < make(s)D (s)), let gn = Pr( n+1<1make(s) (s) n ). countable additivity axiom probability measures, Gm =PPgn . means l1n=mn=m gn tends Gm l tends infinity, hence Gl =Pl1Pn=m gn tends 0. So, limm Gm = 0. > 0,l gn = G1) 1 , definition (s). Also Pr(make(s)Pr(make(s) (s) +1). So, = 1, 2, . . ., Pr(make(s)(s)) + Gm = Pr(make(s) (s) +(s)) 1 Gm , implies Pr(make(s) (s)) 1 , Gm tends0 tends infinity.(ii): part (ii) Lemma 1, solution s, = (s). Part (i) impliesPr(make(s) ) 1 .2Probabilistic JSP Example continued. continue example Section 2.1Section 2.2. Set 0.05, corresponding 95% confidence. value = 12.5-achievable using solution sa , since 95% chance paths0 (simultaneously) shorter length 12.5, probability randommakespan make(sa ) less 12.5 0.95.consider value ofD = 12.0. Since len() (the random length ) mean 11standard deviation 1/ 2, chancelen() 12.0 approximately chancenormal distribution 2 standard deviations mean;probability 0.92. Therefore, = 12.0 -achievable using solution , sinceless 0.95 chance random makespan make(sa ) D.-makespan (also referred probabilistic makespan) solutiontherefore 12.0 12.5. fact, -makespan (sa ) approximately equal12.16, since approximately 95% chance (random) makespan make(s )12.16. easy show = 12.16 -achievable usingsolution, , -minimum makespan, equal (sa ), hence 12.16.4.2 Lower Bound -Minimum Makespansection show lower bound -minimum makespan foundsolving particular deterministic JSP.common approach generate deterministic problem replacing randomduration mean distribution. show, certain conditions, minimum makespan deterministic JSP lower bound probabilistic minimummakespan. instance, example, minimum makespan deterministicJSP 11, probabilistic minimum makespan 12.16. However, obviousweakness approach take account spreads distributions. especially important since typically considering small value ,195fiBeck & Wilson0.05. generate stronger lower bound taking account variancesdistributions generating associated deterministic job shop problem.Generating Deterministic JSP Probabilistic JSP Value q.probabilistic job shop problem, generate particular deterministic job shop problem, depending parameter q 0. use transformation almostalgorithms Section 5. deterministic JSP probabilistic JSP exceptrandom duration replaced particular time value. Solving correspondingdeterministic problem give us information probabilistic problem. deterministic JSP consists set activities, partitioned resource setsjobs, total order job. duration activitydeterministic problem defined + qi , respectively meanstandard deviation duration activity Ai probabilistic job shop problem.Hence, q = 0, associated deterministic problem corresponds replacing randomduration mean. Let makeq (s) deterministic makespan solution s, i.e.,makespan associated deterministic problem (which defined lengthlongest s-pathsee Section 2.1). Let makeq minimum deterministic makespansolutions.Let solution. say probabilistically optimal (s) = . Lets-path. ( path probabilistic deterministic problems.) said(deterministically) critical path critical path deterministic problem.length deterministicproblem, lenq (), Pequal sumPP durationsactivities path:Ai (i + qi ), equalsAi + qAi .introduce following rather technical definition whose significance made clearProposition 2: q -sufficient exists (deterministically) critical pathprobabilistically optimal solution Pr(len() > lenq ()) > , i.e.,chance random path length greater deterministic length.following result shows -sufficient value q leads deterministicminimum makespan makeq lower bound probabilistic minimum makespan. Therefore, lower bound deterministic minimum makespan also lowerbound probabilistic minimum makespan.Proposition 2 probabilistic JSP, suppose q -sufficient. Then, solutions, Pr(make(s) makeq ) < 1 . Therefore, makeq -achievable, strictlower bound -minimum makespan , i.e., > makeq .Proof: Since q -sufficient, exists (deterministically) critical path (probabilistically) optimal solution Pr(len() > lenq ()) > . lenq () =makeq (so ), critical path, and, definition makeq , makeq (so )makeq . So, Pr(len() > makeq ) > . definition makespan, samplerandom durations vector, make(so ) least large len(). So,Pr(make(so ) > makeq ) > . Hence, Pr(make(so ) makeq ) = 1 Pr(make(so ) >makeq ) < 1 . implies (so ) > makeq since Pr(make(so ) (so )) 1 ,Proposition 1(i). Since probabilistically optimal solution, = (so ),> makeq . Also, solution s, (s) > makeq , (s) > makeq ,implies makeq -achievable using s, i.e., Pr(make(s) makeq ) < 1 . 2196fiProactive Algorithms JSP4.2.1 Finding -Sufficient q-ValuesProposition 2 shows find lower bound probabilistic minimum makespanfind -sufficient value q, solve (or find lower bound for)associated deterministic problem. section looks problem finding -sufficientvalues q, breaking condition simpler conditions.remainder Section 4.2, assume independent probabilistic JSP.Let path solution. Define E[len()],P expected valuelength (in probabilistic JSP), equal PAi . Define 2Var[len()], variance length , equal Ai i2 , sinceassuming durations independent.PDefining -adequate B. B 0, write B () + B , equals Ai +qP2BAi . say B -adequate (deterministically) critical path(probabilistically) optimal solution, Pr(len() > B ()) > , i.e.,chance B standard deviations longer expected length.duration normally distributed, len() normally distributed, sincesum independent normal distributions. Even durations normallydistributed, len() often close normally distributed (cf. central limittheorem extensions). So, Pr(len() > B ()) approximately 1 (B),unit normal distribution. B value slightly less 1 (1 )-adequate, given approximate normality.Defining B-adequate Values q. say q B-adequate exists(deterministically) critical path (probabilistically) optimal solutionlenq () B ().following proposition shows task finding -sufficient values qbroken down. follows almost immediately definitions.Proposition 3 q B-adequate B -adequate, q -sufficient.Proof: Since q B-adequate, exists (deterministically) critical path(probabilistically) optimal solution lenq () B (). Since B -adequate,Pr(len() > B ()) > , hence Pr(len() > lenq ()) > , required.2Establishing B-adequate Values q. value q B-adequateexists (deterministically) critical path (probabilistically) optimal solutionqPPPP2lenq () B (), equivalently:Ai ,Ai + qAiAi + BqPqMean{i2 : Ai },MeanP{i : Ai }Ainumber activities path , Mean{i : Ai } = M1 Ai .activity Ai uncertain (i.e., standard deviation equals 0),omitted summations means. becomes number uncertainactivities path .is, q BPAii2. written as: q197BfiBeck & Wilsonwell known (and quite easily shown), root qmean square collectionMean{ 2 : Ai }numbers always least large mean. Hence, Mean{ i: } greaterequal 1. Therefore, crude sufficient condition q B-adequate is: q BM ,upper bound number uncertain activities pathprobabilistically optimal solution (or could take upper bound numberuncertain activities path solution). particular, could generate Badequate q choosing q = BM .-sufficient Value q. Putting two conditions together using Proposition13, q-value little less (1)-sufficient, givenlengths paths approximately normally distributed, upper boundnumber uncertain activities path optimal solution. Hence,Proposition 2, minimum makespan makeq associated deterministic problemstrict lower bound -minimum makespan . example, = 0.05,1 (1 ) 1.645 (since 0.05 chance normal distribution1.645 standard deviations mean), set q little less.1.645One sometimes generate larger -sufficient value q, hence stronger lowerbound makeq , focusing significantly uncertain activities. Choose valueP 0 1. path , sayP activity Aj -uncertain (with respect){i : Ai , j } > {i : Ai }; sum durationsactivities -uncertain fraction sum durationspath. Hence, activities -uncertain relatively small standarddeviations. define upper bound number -uncertain activitiesinvolved path (probabilistically) optimal solution, shown,B-adequate,slight modification earlier argument, q-value (1)Bhence q-value little less(1)1 (1)-sufficient.experiments described Section 6 use, varying n, problems n jobs nactivities per job). Solutions paths involving large numbers activitiesunlikely good solutions. particular, one might assume that, problems,optimal solution (deterministically) critical s-path involving2n activities. Given assumption, following value q -sufficient,1, e.g.,making makeq lower bound probabilistic minimum makespan: q = (1)2nq=1.6452n= 0.05. motivates choice q1 Table 2 Section 6.1.Probabilistic JSP Example continued. number uncertain activitiesrunning example (see Section 2.2, Figure 1 Section 4.1) 3, oneset = 3.Using = 0.05, leads choice q slightly less 1.645/ 3 0.950.Proposition 3 discussion, value q -sufficient. durationsassociated deterministic problem given setting di = + qi , d1 = 1,d2 = 2 + q/2, d3 = 3 + q/2, d4 = 4 + q/2 d5 = 5. Solution sa best solutionmakespan makeq (sa ) = 1 + 5 + (2 + q/2) + (3 + q/2) = 11 + q. Hence, minimum198fiProactive Algorithms JSPdeterministic makespan makeq equals approximately 11.95, lower boundprobabilistic minimum makespan 12.16, illustrating Proposition 2.However, sc clearly poor solution, could consider solutions:{sa , sb , sd }. (deterministically) critical path solutions involves twouncertain activities (withinrange interest q-values), set = 2,q = 1.16 1.645/ 2. leads stronger lower bound 11 + 1.16 = 12.16,tight lower bound -minimum makespan .4.2.2 Discussion lower boundexample, able use approach construct tight lower boundprobabilistic minimum makespan. However, situation rather exceptional.Two features example enable tight lower bound (a) bestsolution path almost always longest path; (b) standard deviationsuncertain durations equal. analysis, root mean squareapproximated (from below) mean. good approximation standarddeviations fairly similar, extreme case (non-zero) standard deviationsdurations (as example), root mean square actually equalmean.generally, number ways lower bound tendconservative. particular,choice often conservative us confidentgenuine upper bound number uncertain activities pathoptimal solution;approximating root mean square standard deviations averagestandard deviations: crude approximation standard deviationsdurations vary considerably activities;approximating random variable make(s) random length particular path.strength lower bound method, however, computationally feasiblereasonably large problems uses existing well-developed JSP methods.4.3 Evaluating Solution Using Monte Carlo Simulationgiven time value, D, want assess exists solutionchance random makespan greater D. methodsinvolve generating solutions (or partial solutions), testing condition.noted earlier, evaluating solution amounts solving PERT problem uncertain durations, #P-complete problem (Hagstrom, 1988). #P-completeproblems computation Dempster-Shafer Belief (Wilson, 2000), natural approach take Monte Carlo simulation (Burt & Garman, 1970); try performexact computation instead choose accuracy level require highchance random estimate within true value. evaluation algorithm199fiBeck & Wilsonoptimal complexity (low-degree polynomial) potentially high constant factorcorresponding number trials required given accuracy.evaluate solution (or partial solution) using Monte Carlo simulation perform(large) number, N , independent trials assigning values random variable.trial generates deterministic problem, check efficiently correspondingmakespan greater D; so, say trial succeeds. proportion trialssucceed estimate Pr(make(s) > D), chance random makespanD. case independent probabilistic JSPs, generaterandom durations vector picking, using distribution Pi , value random durationdi activity Ai . general case, picking random durations vector stillefficient many situations; example, distribution represented Bayesiannetwork.4.3.1 Estimating Chance Random Makespan GreaterPerform N trials: l = 1, . . . , N .(trial) l:Pick random durations vector using joint density function.Let Tl = 1 (the trial succeeds) corresponding (deterministic) makespan greaterD. Otherwise, set Tl = 0.PLet = N1 Nl=1 Tl proportion trials succeed. estimate p,p = Pr(make(s) > D), chance randomly generated durations vector leadsmakespan (for solution s) greater D. expected value equalq p, since1 PNE[Tl ] = p E[T ] = N l=1 E[Tl ] = p. standard deviation p(1p)N ,shown follows: V ar[Tl ] = E[(Tl )2 ] (E[Tl ])2 = p p2 = p(1 p). variablesPp(1p)1Tl independent V ar[T ] = N12 N4N. random variable Ni=1 V ar[Tl ] =Nbinomially distributed, (because deMoivre-Laplace limit theorem (Feller,1968)) use normal distribution approximate .means that, large N , generating value algorithm will,high probability, give value close Pr(make(s) > D). choose accuracy level> 0 confidence level r (e.g., r = 0.95), choose N Pr(|T p| < ) > r;particular, r = 0.95 using normal approximation, choosing number N trials12 sufficient. fixed accuracy level confidence level r, numbertrials N constant: depend size problem. algorithmtherefore excellent complexity: complexity (low-order polynomial)single deterministic propagation, must optimal clearly cannot hope beatcomplexity deterministic propagation. However, constant factor 12 largerequire high accuracy.4.3.2 Solution Good Enough?Let time value let solution. Suppose, based Monte-Carloalgorithm using N trials, want confident -achievable using (i.e.,200fiProactive Algorithms JSPPr(make(s) > D) ). therefore need observed least little smaller, since (only) estimate Pr(make(s) > D).formalize this, shall use confidence interval-style approach. Let K 0. Recallp = Pr(make(s) > D) unknown quantity want find informationabout. say p K-implausible given result following conditionholds: p pimplies least K standard deviations expected value, i.e.,p KN p(1 p).case p , p K-implausible given , unlikelyevent would happened. example, K = 2, (given normal approximation),event happen every 45 experiments; K = 4 eventhappen every 32,000 experiments.Pr(make(s) > D) K-implausible given result , confidentPr(make(s) > D) < : -achievable using s, upper bound(s) hence -minimum makespan . confidence level, basednormal approximation binomial distribution, (K), unit normaldistribution. example, K = 2 gives confidence around 97.7%.Similarly, 0 0.5, say p K-implausible givenresult following condition holds: p impliesleast K standardpdeviations expected value, i.e., p + KN p(1 p).definitions K-implausibility slightly informal. formal definitionsfollows. Suppose (0, 0.5], K 0, [0, 1] N {1, 2, . . . , }. define:p K-implausible given pp p 1, followingcondition holds: p KN p(1 p). Similarly, p K-implausible givenpp 0 p , following condition holds: p + KN p(1 p).K-implausibility conditions cannot tested directly using definition sincep unknown. Fortunately, following result, gives equivalent conditionseasily checked.Proposition 4 definitions:KNp(1 ).p(ii) p K-implausible given + KN (1 ).(i) p K-implausible givenpProof: (i): p K-implausible given , setting p gives KN (1 )prequired. Conversely, suppose KN (1 ). result follows K = 0,2assume K > 0. Write f (x) = (x )2 K x(1x). Now, sinceNpK 2 (1)K2N (1 ), > ( )so, f () 0. Also, f (T ) 0.NSince f (x) quadratic polynomial positive coefficient x2 , implieseither solution equation f (x) = 0, two solutions. Since f () 0> , follows must either solution f (x) = 0, greater2. Since p > ,solution(s). implies, p > , f (p) > 0, (p )2 > K p(1p)Nqp(1p)p p KN , is, p K-implausible given ,proving (i).201fiBeck & Wilsonq. Con(ii) p K-implausible given , setting p gives + K (1)q Nq, (since 0.5) p implies p + K p(1p)sinceversely, + K (1)NNright-hand-side strictly increasing function p, p K-implausible given ,required.2Part (i) result shows us evaluate solution respectp boundKD: generate (using Monte Carlo simulation) least N (1 ) less, confidence p < , i.e., Pr(make(s) > D) < ,confidence -achievable using solution s, i.e., upper boundprobabilistic makespan (s). Part (ii) used branch-and-bound algorithmdescribed Section 5.2.1, determining backtrack node.4.3.3 Generating upper approximation probabilistic makespansolutionSuppose that, given solution s, wish find time value large enoughconfident probabilistic makespan D, i.e.,upper bound -makespan (s). Monte Carlo simulationadapted purpose. simulate values random makespan make(s)record distribution these. decide value K, corresponding desireddegree confidence (e.g., K = 2 corresponds 97.7% confidence) chooseminimal suchpthat associated value (generated simulation results) satisfiesKN (1 ). Proposition 4(i), Pr(make(s) > D) K-implausiblegiven . therefore confident Pr(make(s) > D) < ,confidence upper bound -makespan (s) s. balancepaper, use notation D(s) represent (upper) estimate (s) foundway.5. Searching Solutionstheoretical framework provides two key tools use building search algorithms.First, use Monte Carlo simulation evaluate solution partial solution (seeSection 4.3). Second, appropriate choice q value, solve associateddeterministic problem find lower bound -minimum makespan probleminstance (see Section 4.2). section, make use tools (andvariations) define number constructive local search algorithms. describingalgorithms, recall important concepts notation introducedearlier sections.algorithms, explicitly deal case independent probabilistic JSPs durations positive integer random variables. Given approach,however, algorithms valid:generalized probabilistic case, assumptions noted Section 4, provided efficient way sample activity durations;202fiProactive Algorithms JSPcontinuous random variables, provided deterministic solverhandle continuous time values.5.1 Summary Notationremainder paper makes use notation concepts earlier sections,briefly summarize below.JSP probabilistic JSP: solution totally orders activities requiringresource (i.e., activities resource set), activity Ai Aj requireresource, either determines Ai must completed timeAj starts, vice versa (see Section 2.1). partial solution partially orders setactivities resource set. Associated solution non-delay schedule (relativesolution), activities without predecessors started time 0,activities started soon predecessors completed. makespansolution time jobs completed associated non-delayschedule. probabilistic JSP (see Section 2.2), makespan make(s) solutionrandom variable, since depends random durations.quantity use evaluate solution (s), -makespan (also knownprobabilistic makespan s), defined Section 4.1. probability (random)makespan (s) , approximately equal . (Moreprecisely, (s) smallest time value Pr(make(s) > D) .)Value therefore represents degree confidence required. -minimum makespan(also known probabilistic minimum makespan) minimum (s)solutions s.time value -achievable using solution chancerandom makespan D. -achievable using(s) (see Section 4.1).Solutions probabilistic JSPs evaluated Monte Carlo simulation (see Section4.3). method derived generating upper approximation . usenotation D(s) represent upper approximation, constructed D(s)approximately equal (s), high chance (s) lessD(s)see Section 4.3.3. D(s) thus represents probable upper bound probabilisticminimum makespan.probabilistic job shop problem often associate deterministic JSP (see Section4.2). mapping parameterized (non-negative real) number q. associateddeterministic JSP structure probabilistic JSP; differenceduration activity Ai equal + qi , meanstandard deviation (respectively) duration Ai probabilistic problem.write makeq (s) makespan solution respect associated deterministicJSP, makeq minimum makespan: minimum makeq (s) solutions s.Section 4.2, shown, using Propositions 2 3 analysis Section4.2.1, certain values q, time value makeq lower bound .203fiBeck & Wilson5.2 Constructive Search AlgorithmsFour constructive-search based algorithms introduced here. uses constraintbased tree search core search technique, incorporating simulation q values different ways. section, define constructive algorithm detail providedescription heuristics constraint propagation building blocks usedthem.5.2.1 B&B-N: Approximately Complete Branch-and-Bound AlgorithmGiven ability estimate probabilistic makespan solution, abilitytest condition implies partial solution cannot extended solutionbetter probabilistic makespan, obviously applicable search technique branch-andbound (B&B) use Monte Carlo simulation derive upper- lower-boundssolution quality. able cover entire search space, approachapproximately complete (only approximately always small probabilitymiss optimal solution due sampling error).B&B tree (rooted) binary tree. Associated node e treepartial solution se , solution node leaf node. empty partial solutionassociated root node. Also associated non-leaf node e pairactivities, Ai , Aj , j 6= i, resource set, whose sequence determinedpartial solution se . two nodes e extend se : one sequences Ai Aj ,adds opposite sequence. heuristic used choose sequence try firstdescribed Section 5.2.5.value global variable always confidence (correspondingchoice Ksee Section 4.3.2) exists solution whose -makespan, (s),. Whenever reach leaf node, e, find upper estimate 0 = D(se )probabilistic makespan (s), Monte Carlo simulation based methodSection 4.3.3. set := min(D , D0 ). Variable initialized high value.non-leaf nodes, e, check see worth exploring subtree e.perform Monte Carlo simulation partial solution, se , using current value ;generates result . use Proposition 4(ii) determine Pr(make(s e ) > )K-implausible given ; is, backtrack, since confidentexists solution extending partial solution se improves current best solution.K chosen sufficiently large, confident miss good solution. 6refer algorithm B&B-N performs B ranch-and-B ound simulationN ode.5.2.2 B&B-DQ-L: Approximately Complete Iterative Tree Searchinternal node, e, tree, previous algorithm used Monte Carlo simulation(but without strong propagation within trial) find lower bound probabilisticmakespans solutions extending partial solution se . alternative idea generating6. large number tests, need much higher confidence usualconfidence interval; fortunately, confidence associated K (based normal approximation21binomial, approximation tail normal distribution) approximately 1 K 1 2 e 2 K ,tends 1 extremely fast K increases.204fiProactive Algorithms JSPB&B-DQ-L():Returns solution lowest probabilistic makespan12345678(s , ) findFirstB&BSimLeaves(, 0)q qinitq 0 timed-out(s, D) findOptB&BSimLeaves(D , q)6= N ILs;endq q qdecendreturnAlgorithm 1: B&B-DQ-L: Approximately Complete Iterative Tree Searchlower bound use approach Section 4.2: find minimum makespan,solutions extending se , associated deterministic problem based q value-sufficient. minimum makespan (see Proposition 2) lower boundprobabilistic makespan. Standard constraint propagation deterministic durationsenables lower bound computed much faster simulation previousalgorithm. leaf node, simulation used B&B-N find estimateprobabilistic makespan solution.basic idea requires selection q value. However, rather parameterizealgorithm (as others below), choose perform repeated treesearches descending q value.algorithm finds initial solution (line 1 Algorithm 1) therefore initialupper bound, , probabilistic makespan q = 0. Subsequently, startinghigh q value (one result deterministic lower bound), performtree search. leaf, e, reached, simulation used find D(se ).high q value, likely deterministic makespan makeq (se ) much greaterD(se ). Since enforce constraint makeq (se ) D(se ), finding D(se )simulation causes search return interior node, i, high treemakeq (Si ) D(se ) Si represents set solutions subtree node i,makeq (Si ) deterministic lower bound makespan solutions. highq values, commonly observed experiments nodesmeet criterion and, therefore, search able quickly exhaust searchspace. happens, reduce q value small amount, qdec (e.g., 0.05),restart tree search. Eventually, often quickly, reach q valueexists full solution, se , makeq (se ) D(se ). solution storedcurrent best set = D(se ). B&B-N, used upper boundsubsequent search.Algorithm 1 presents pseudocode basic algorithm. make use two functionsdefined using pseudocode:findFirstB&BSimLeaves(c, q): creates JSP activity durations defined basedq value passed conducts branch-and-bound search Monte Carlo205fiBeck & Wilsonsimulation used leaf node standard constraint propagation usedinterior nodes. first solution found whose probabilistic makespan lessc returned value probabilistic makespan. c sethigh line 1, backtracking needed find solution therefore oneleaf node visited one simulation performed.findOptB&BSimLeaves(c, q): findFirstB&BSimLeaves(c, q) exceptsolution lowest probabilistic makespan returned rather first one found.solution found, NIL value returned. Unless q value low enoughdeterministic makespan lower bound probabilistic makespan,function necessarily return globally optimal solution.find starting solution q = 0 serve initial upper bound optimalprobabilistic makespan. practice, B&B-DQ-L run limit CPU time.q = 0 reached within time limit, algorithm approximately complete.noted above, possible, especially high q value, solution, se ,makeq (se ) much larger D(se ), therefore search backtrack deepestinterior node makeq (Si ) D(se ). fact, assignment D(se ) valueglobal cut upper bound probabilistic makespan. technical reasonsbeyond scope paper, standard constraint-based tree search implementationsautomatically handle global cuts. therefore modified standard behaviorrepeatedly post upper bound constraint makeq (Si ) causing series backtrackscorrect interior node.refer algorithm B&B-DQ-L series B ranch-and-B oundsearches Descending q values simulation used Leaves tree.B&B-DQ-L example novel constraint-based search technique mightuseful wider context. problem cost function expensive evaluateinexpensive, parameterizable lower bound calculation, search based overconstraining problem (i.e., choosing parameter value lead lowerbound) iteratively relaxing bounding function, may worth investigating.discuss approach Section 7.5.2.3 B&B-TBS: Heuristic Tree Search AlgorithmPrevious results algorithm similar B&B-N (Beck & Wilson, 2004) indicatedsimulation responsible large percentage (e.g., 95%) run-time.reduce number times require simulation simulating solutionsgood deterministic makespan. deterministic filtering search central idearest algorithms investigated paper.simple method filtering solutions first spend fixed amount CPU timefind solution, s0 , low deterministic makespan, makeq (s0 ), using fixed q valuestandard constructive tree search. Then, search restarted using q valuewhenever solution, si , found makeq (si ) makeq (s0 ), simulation runevaluate D(si ), estimate probabilistic makespan, (si ). probabilisticmakespan found better lowest probabilistic makespan far, solutionstored. Search continued entire tree explored maximum allowedCPU time expired. Algorithm 2 contains pseudocode.206fiProactive Algorithms JSPB&B-TBS(q):Returns solution lowest probabilistic makespan found12345678(s , Dinitial ) findOptB&B(, q, tinitial )solutions exist timed-out(s, D) findNextB&B(Dinitial + 1, q, time-remaining)D0 simulate(s)D0 <s; D0endendreturnAlgorithm 2: B&B-TBS: Heuristic Tree Search AlgorithmAlgorithm 1, make use number functions defined pseudocode:findOptB&B(c, q, t): creates JSP activity durations defined based qvalue passed conducts deterministic branch-and-bound search CPUseconds using c upper bound deterministic makespan. searchtree exhausted time-limit reached, best deterministic solution found(i.e., one minimum makespan), together deterministic makespanreturned. Monte Carlo simulation done.findNextB&B(c, q, t): function produces sequence solutions (one solutiontime called) whose deterministic makespan less c. problemdefined using q value CPU time limit. solutions producedleaves B&B search tree order encountered algorithm. NoteAlgorithm 2, c value change. Given enough CPU time, algorithmevaluate probabilistic makespan solutions whose deterministic makespanless equal Dinitial .simulate(s): standard Monte Carlo simulation run solution D(s),estimate probabilistic makespan, (s), returned.algorithm complete, even choice q value results deterministicmakespans lower bounds probabilistic makespan.guarantee optimal probabilistic solution deterministic makespan lessDinitial therefore, even infinite CPU time, may evaluated.algorithm called B&B-TBS B ranch-and-B ound-T imed B etter olution:fixed CPU time spent find good deterministic solution, deterministicsolution found good better initial solution simulated.5.2.4 B&B-I-BS: Iterative Heuristic Tree Search Algorithmextreme filtering algorithm first finds optimal deterministic solution usesdeterministic makespan filter choosing solutions simulate. Using fixed207fiBeck & WilsonB&B-I-BS(q):Returns solution smallest probabilistic makespan found1234567891011(s , Dinitial ) findOptB&B(, q, t0 1)simulate(s )i0timed-outsearch complete(s, makeq ) findNextB&B(Dinitial (1 + i/100) + 1, q, time-remaining)simulate(s)<s;endendii+1endreturnAlgorithm 3: B&B-I-BS: Iterative Heuristic Tree Search Algorithmq value, optimal solution found simulated. CPU time remaining,search series iterations starting using optimal deterministic makespanbound. solutions deterministic makespan good (or, general, betterthan) current bound found simulated. subsequent iterations, bounddeterministic makespan increased, resulting larger set solutionssimulated. solution lowest estimated probabilistic makespan returned.larger problems, optimal deterministic makespan may found within CPUlimit. case, best deterministic solution found simulated returned(i.e., one simulation done).formally, finding optimal deterministic solution makespan, make q ,series iterations beginning = 0 executed. iteration, bounddeterministic makespans set makeq (1+i/100). solutions, se , whose deterministicmakespans, makeq (se ) makeq (1 + i/100), simulated one lowestprobabilistic makespan returned. Algorithm 3 presents pseudocode dependsfunctions defined above.algorithm complete. large enough cost bound greaterdeterministic makespan activity permutations, simulated.However, may grow unreasonably large therefore treat algorithm as,practically, incomplete.refer algorithm B&B-I-BS B ranch-and-B ound-I terative-B est olution.5.2.5 Heuristic Constraint Propagation Detailsalgorithms described use texture-based heuristics decide pair activities sequence sequence try first. heuristic builds resource profilescombine probabilistic estimates contention activity resourcetime-point. maximum point resource profiles selected activity208fiProactive Algorithms JSPpair contends resource selected time-point heuristically chosen.sequence chosen one maximizes remaining slack. intuitionpair activities contending highly contended-for resource time-pointcritical pair activities sequenced early search. Otherwise, viaconstraint propagation decisions, time windows activities maypruned point neither sequence possible. texture-based heuristicscomplexity search node O(mn2 ) number resources nnumber activities resource.detailed description analysis texture-based heuristic see workBeck Fox (2000) Beck (1999).constraint propagation used (i.e., algorithms except B&B-N),use strong constraint propagation techniques constraint-based scheduling: temporalpropagation, timetables (Le Pape, Couronne, Vergamini, & Gosselin, 1994), edge-finder(Nuijten, 1994), balance constraint (Laborie, 2003).5.3 Local Search Algorithmsreason deterministic filtering search algorithm needs basedbranch-and-bound. Indeed, given approach finding simulating solutionslow deterministic makespans, algorithms based local search may perform betterconstructive search algorithms.section, present two deterministic filtering algorithms based tabu search. 7define algorithm discuss details tabu search procedure itself.5.3.1 Tabu-TBS: Tabu Search Analog B&B-TBScentral idea behind using tabu search deterministic filtering search generatesequence promising deterministic solutions simulated. seems reasonablecreate analog B&B-TBS using tabu search. fixed q fixed amounttinitial CPU time, beginning run, solution lowest possible deterministic makespan, Dinitial , sought. Search restarted whenever solution, s,found deterministic makespan makeq (s) Dinitial , Monte Carlo simulationused approximate probabilistic makespan. solution lowest estimatedprobabilistic makespan returned.Algorithm 4 presents pseudocode simple approach. use followingfunctions (pseudo-code given):findBestTabu(c, q, t): function analogous findOptB&B(c, q, t). Tabu searchrun CPU seconds solution lowest deterministic makespan(based q value) less c returned.findNextTabu(c, q, t): function analogous findNextB&B(c, q, t). sequencesolutions (one solution time called) whose deterministic makespan less7. Early experiments explored even simpler way using tabu search solve probabilistic JSPincorporating simulation neighborhood evaluation. Given search state, move operator (seeSection 5.3.3 details) defines set neighboring states. neighbor, run MonteCarlo simulation choose neighbor lowest probabilistic makespan. technique,surprisingly, proved impractical considerable CPU time spent determine single move.209fiBeck & WilsonTabu-TBS(q):Returns solution lowest probabilistic makespan found12345678(s , Dinitial ) findBestTabu(, q, tinitial )termination criteria unmet(s, D) findNextTabu(Dinitial + 1, q, time-remaining)D0 simulate(s)D0 <s; D0endendreturnAlgorithm 4: Tabu-TBS: Local Search Filtering Algorithmc returned. problem defined using q value CPU timelimit. solution produced next solution found tabu search meetsmakespan requirement.call algorithm Tabu-TBS Tabu-T imed B etter olution.B&B-TBS, c value updated iteration. initial search (line1) used find good deterministic solution simulation done solutions whosedeterministic makespan better solution found initial search.5.3.2 Tabu-I-BS: Iterative Tabu Search Algorithmcore tabu search implementation fixed durations necessarily use entireCPU time (see Section 5.3.3) and, fact, especially small instances often terminatesquickly. therefore create iterative tabu-based solver probabilisticJSP similar B&B-I-BS.first phase, using time limit one second less overall time limit,tabu search used find good deterministic solution, based fixed q value.solution simulated. tabu search may terminate timelimit expired, remaining time spent generating solutions deterministicmakespan within fixed percentage initial solutions deterministic makespan.B&B-I-BS, iterations run increasing value starting = 0.iteration, simulate solutions found tabu search whose deterministic makespan(1 + i/100)Dinitial , Dinitial value deterministic makespan foundphase 1. solution lowest probabilistic makespan returned.8algorithm termed Tabu-I-BS Tabu-I terative-B est earch. pseudocodealgorithm presented Algorithm 5.5.3.3 Tabu Search Detailstabu search used find solutions problems deterministic durations TSABalgorithm due Nowicki Smutnicki (1996). restricted move operator (termed8. Tabuf algorithm proposed Beck Wilson (2004) corresponds first iteration Tabu-I-BS.210fiProactive Algorithms JSPTabu-I-BS(q):Returns solution smallest probabilistic makespan found1234567891011(s , Dinitial ) findBestTabu(, q, t0 1)simulate(s )i0timed-outtermination criteria unmet(s, makeq ) findNextTabu(Dinitial (1 + i/100) + 1, q, time-remaining)simulate(s)<s;endendii+1endreturnAlgorithm 5: Tabu-I-BS: Iterative Tabu-based Filtering AlgorithmN 5 Blazewicz, Domschke Pesch, 1996) produces neighborhood swappingsubset pairs adjacent activities resource given solution. standardtabu list ten moves done immediate past kept escape local minima.use standard aspiration criteria accepting move tabu list resultingsolution better solution found far.One important additions basic tabu search mechanism TSABmaintenance elite pool solutions. small set (i.e., 8) best solutions encountered far updated whenever new best solutionencountered. standard tabu search stagnates (i.e., made large numbermoves without finding new best solution), search returns one elite solutionscontinues search it. solution removed set elite solutions. Searchterminated either maximum CPU time reached elite solution poolempty.5.4 Summary AlgorithmsTable 1 summarizes algorithms introduced above.6. Empirical Investigationsempirical investigations address two main issues: scaling behaviorapproximately complete heuristic methods problem size uncertainty increasewhether using deterministic methods, represent uncertainty durationextensions, useful approach. respect scaling, two interesting subquestions: first, approximately complete techniques compareand, second, cross-over point terms problem size heuristictechniques out-perform approximately complete techniques.211fiBeck & WilsonDeterministicAlgorithmB&BCompleteYesB&B-DQ-LB&BYesB&B-TBSB&BB&B-I-BSB&BYesTabu-TBSTabuTabu-I-BSTabuNameB&B-NDescriptionB&B simulation node find upperlower boundsB&B deterministic durations used lowerbounds simulation done leaf node.durations decrease iteration.Find good deterministic solution, s,restart search, simulating wheneverdeterministic solution good found.Find optimal deterministic solution, s.Restart search simulating wheneverdeterministic solution within i% foundRepeat increasing i.Find good deterministic solution, s,restart search simulating wheneverdeterministic solution good found.Find good deterministic solution, s,possible. Restart search simulating wheneverdeterministic solution within i%found. Repeat increasing i.Table 1: summary algorithms introduced find probabilistic makespaninstance job shop scheduling problem probabilistic durations.heuristic techniques necessary assign fixed durations activity.standard approach use mean duration. However, casesrepresentation uncertainty surrounding duration, takeaccount want high probability (1 ) execution. general approachheuristically use formulation lower bound -minimum makespans presentedSection 4.2: duration activity Ai defined + qi , q fixednon-negative value, (respectively) mean standard deviationduration Ai . Since longer limited producing lower bound,flexibility selecting q. Intuitively, want q-value leads situationgood deterministic solutions also low values probabilistic makespan (s).experiment number q-values based analysis Section 4.2 shown Table2. cases, set B = 1.645 (see Section 4.2) corresponding = 0.05. Value q 3generated problem instance Monte Carlo simulation: simulating 100000 pathsn activities.6.1 Experimental Detailsempirical investigations examine four sets probabilistic JSPs size {4 4, 6 6, 1010, 20 20} (where 10 10 problem 10 jobs consisting 10 activities),set, three uncertainty levels uj {0.1, 0.5, 1} considered. deterministic problemgenerated using existing generator (Watson, Barbulescu, Whitley, & Howe, 2002)212fiProactive Algorithms JSPq00q11.6452nq2q1 +q321.645nq3MeanAi i2MeanAiqTable 2: q-values used experiments. choices q1 q3 motivatedanalysis Section 4.2.1.integer durations drawn uniformly interval [1, 99]. Three probabilistic instancesdifferent levels uncertainty produced setting mean durationdeterministic duration activity Ai , randomly drawing (using uniformdistribution) standard deviation duration activity Ai interval [0,uj ]. distribution duration approximately normal. problem size,generate 10 deterministic problems transformed 30 probabilistic instances.problem sizes chosen elicit range behavior, small problems,approximately complete algorithms expected able find prove(approximate) optimality, larger problems, even underlying deterministicproblems could solved optimality within time limit used. chose useexisting generator rather than, example, modifying existing benchmark problems,allowed us full control problem structure. three levelsuncertainty simply chosen low, medium, high uncertainty conditionscompare algorithms.Given stochastic nature simulation tabu search algorithm, algorithm run 10 times problem instance different random seeds. runtime limit 600 CPU seconds. Monte Carlo simulation uses N = 1000 independenttrials.hardware used experiments 1.8GHz Pentium 4 512 MB mainmemory running Linux RedHat 9. algorithms implemented using ILOG Scheduler5.3.Recall B&B-DQ-L algorithm, employ descending sequence q values.problems except 20 20 problems, initial q value, qinit , set 1.25,decrement, qdec , 0.05. 20 20 problems, qinit value 0.9 used.change made observing qinit = 1.25, initial tree search 2020problems would often fail find solution prove none existed within reasonableamount time. believe due problem instances sizesolution q = 1.25 satisfied constraint simulated makespan mustless equal deterministic approximation (i.e., makeq (se ) D(se )seeSection 5.2.2), yet search space sufficiently large require significantamount search prove it. Reducing qinit 0.9 results initial solution foundquickly instances.primary evaluation criterion mean normalized probabilistic makespan (MNPM )algorithm achieved relevant subset problem instances (we displaydata different subsets examine algorithm performance different problem sizesuncertainty levels). mean normalized probabilistic makespan defined follows:213fiBeck & WilsonMNPM (a, L) =1 X D(a, l)|L|Dlb (l)(1)L set problem instances, D(a, l) mean estimate probabilisticmakespan found algorithm l 10 runs, Dlb (l) lower bound probabilistic makespan l. problems except 20 20, Dlb found solvingdeterministic problems using q1 , simple, plausibly -sufficient q-value (see Section4.2 Table 2). instance solved using constraint-based tree search incorporatingtexture-based heuristics global constraint propagation used above. maximumtime 600 CPU seconds given. (deterministic) problems smaller 20 20easily solved optimality. However, none 2020 problems solved optimality.this, Dlb values chosen represent best solutions found,true lower bounds.6.2 Results AnalysisTable 3 presents overview results experiments problem sizeuncertainty level. results q = q2 shown heuristic algorithm.large performance difference among non-zero q-values (q 1 , q2 q3 ). returnissue Section 6.2.2. cell Table 3 mean value 10 independentruns 10 problems. Aside 4 4 instances, runs reached 600 CPUsecond time limit. Therefore, report CPU times.ProblemSize446610 1020 20Unc.Level0.10.510.10.510.10.510.10.51B&B CompleteNDQ-L1.027* 1.023*1.060* 1.049*1.151*1.1291.0341.0211.1131.0731.2261.1701.1851.0281.2411.1151.3461.2341.2561.1421.3261.2331.4821.388AlgorithmsB&B HeuristicTBSI-BS1.0261.0261.0641.0591.1541.1491.0221.0221.0831.0771.1781.1741.024 1.0241.101 1.1011.215 1.2151.0771.0711.1771.1811.3341.338TabuTBSI-BS1.027 1.0231.063 1.0461.153 1.1281.0271.0231.0741.0741.185 1.1681.0351.0281.1211.1121.2441.2231.029 1.0271.136 1.1371.297 1.307Table 3: mean normalized probabilistic makespans algorithm. * indicatesset runs have, high confidence, found approximately optimalmakespans. indicates problem sets normalization doneapproximate lower bounds. lowest MNPM found problem setshown bold.214fiProactive Algorithms JSPimpression results gained looking bold entries indicatelowest mean normalized probabilistic makespan (MNPM) found problemset. B&B-N B&B-DQ-L find approximately optimal solutions smallestproblem set, B&B-DQ-L Tabu-I-BS find lowest probabilistic makespans4 4 6 6 problems. Performance complete B&B techniques,especially B&B-N, degrade 10 10 problems heuristic B&B algorithmsfind lowest probabilistic makespans. Finally, largest problems, tabu-basedtechniques clearly superior.One anomaly overall results Table 3 seen B&B-N B&B-DQ-Lentries 4 4 problems. two three uncertainty levels algorithms terminate limit CPU time resulting approximately optimal solutions. However,mean normalized probabilistic makespans lower B&B-DQ-L algorithm.conjecture artifact B&B-DQ-L algorithm biases simulationtoward lower probabilistic makespan values. B&B-N, particular solution, s,simulated find D(s). B&B-DQ-L, solution may simulated multipletimes leading bias. illustration, assume B&B-DQ-L finds approximatelyoptimal solution searching tree corresponding q = q 0 > 0. subsequentiteration q = q 00 < q 0 , provided deterministic makespan less previously identified probabilistic makespan (i.e., makeq (s ) < D(s )), solution foundsimulated again. actual identity current best solution useddetermine solutions simulate. subsequent simulation, lower valueD(s ) generated, replace previous lowest probabilistic makespan value.leads situation may re-simulate solution multiple times, keepinglowest probabilistic makespan found simulations. Similar re-simulationpossible Tabu-I-BS algorithm.test statistical significance results Table 3, ran series randomizedpaired-t tests (Cohen, 1995) p 0.005. results statistical testsdisplayed Table 4 different problem sizes. different uncertainty levelscollapsed that, example, 4 4 statistics based 4 4instances. informal impression discussed reflected tests B&BDQ-L Tabu-I-BS dominating two smallest problem sizes, branch-and-boundheuristic approaches performing best 1010 problems, tabu-based techniquesdelivering best results 20 20 problems.Overview. primary interpretation performance algorithmsexperiments follows. smaller problems (44 66), complete techniquesable cover entire search space least significant portion it. Thoughcase B&B-DQ-L, solutions chosen simulation heuristically drivendeterministic makespan values, lower bound results Section 4.2 ensuregood solutions found provided iterations small q values run withinCPU time limit. 10 10 problems, complete techniques ablesimulate sufficient variety solutions as, especially B&B-N, heuristic guidancepoor. Note, however, B&B-DQ-L competitive with, and, many problemssets, better tabu-based algorithms 10 10 problems. believe10 10 results stem ability B&B heuristic algorithms quickly find215fiBeck & WilsonProblemSize446610 1020 20Statistical Significance(p 0.005){B&B-DQ-L, Tabu-I-BS} < {B&B-TBS, B&B-I-BS, Tabu-TBS, B&B-N}{B&B-DQ-L, Tabu-I-BS} < {B&B-I-BS} < {B&B-TBS} < {Tabu-TBS} < {B&B-N}{B&B-TBS, B&B-I-BS} < {Tabu-I-BS, B&B-DQ-L, Tabu-TBS} < {B&B-N}{Tabu-TBS, Tabu-I-BS} < {B&B-TBS, B&B-I-BS} < {B&B-DQ-L} < {B&B-N}Table 4: statistically significant relationships among algorithms resultsshown Table 3. Algorithms within set show significant difference.< relation indicates algorithms left-hand set significantlylower MNPM algorithms right-hand set. set indicatedrepresents complicated relationship amongst algorithms: Tabu-I-BS <Tabu-TBS pairs set show significant performance differences.optimal deterministic solution systematically simulate solutionsdeterministic makespans close optimal. contrast, tabu-based algorithmssystematically enumerate solutions. Finally, largest problems,hypothesize tabu search techniques result best performance ablefind better deterministic solutions simulate.Problem Size. size problems increase, see not-unexpected decreasequality probabilistic makespans found. simple reasonable explanationtrend less search space explored within given CPU timelarger problems. likely factors contribute trend (e.g.,quality lower bound may well systematically decrease problem size increases).Uncertainty Level. normalized makespan values also increase within problem sizeuncertainty level rises. results calculated normalizationlower bound, possible observed decrease solution quality actually duedecrease quality lower bound rather reduction qualitysolutions found algorithms uncertainty increases. test idea, Table 5normalized 4 4 results using optimal probabilistic makespans found B&B-Nrather deterministic lower bound. table shows algorithms apartB&B-DQ-L Tabu-I-BS, trend increasing mean normalized probabilisticmakespan still evident. algorithms, least, putative decreasing qualitylower bound cannot entire explanation trend worse performanceresults higher levels uncertainty. Section 6.2.2, revisit question provideevidence could explain algorithms perform worse uncertainty increased.results also lend credibility conjecture observed super-optimalperformance B&B-DQ-L Tabu-I-BS small problems due repeatedlysimulating solution. low levels uncertainty, repeated simulations trulybest solution vary greatly, resulting MNPM value 1. higher levelsuncertainty, distribution simulated makespans wider and, therefore, repeatedsimulation solution biases results toward smaller probabilistic makespan values.observe results B&B-DQ-L Tabu-I-BS Table 5.216fiProactive Algorithms JSPUnc.Level0.10.51B&B CompleteNDQ-L1.0041.0001.0080.9981.0150.996AlgorithmsB&B HeuristicTBSI-BS1.0031.0021.0121.0081.0181.013TabuTBSI-BS1.003 0.9991.011 0.9951.017 0.996Table 5: mean normalized probabilistic makespans algorithm 4 4problem set normalized optimal probabilistic makespans found B&B-N.balance section, turn detailed analysis algorithms.6.2.1 Analysis: B&B Complete Algorithmsperformance B&B-N poor unable exhaustively search branchand-bound tree. high computational cost running simulation every noderelatively weak lower bound partial solutions provide9 conspire result techniquescale beyond small problems.ProblemSize446610 1020 20Uncertainty0.10.50000.50.95 0.850.90.9Level100.750.90.9Table 6: lowest q value used problem size uncertainty level B&BDQ-L. problems except 20 20, initial q value 1.25. 20 20problems, initial q value 0.9B&B-DQ-L able perform somewhat better B&B-N larger problems evenable exhaustively search tree q = 0. Table 6 showsminimum q values attained problem size uncertainty level. deterministicdurations defined q value serve guide prune search iteration and,therefore, heuristic algorithms (see below), search heuristically guidedextent solutions low deterministic makespans also low probabilisticmakespans. However, characteristics solutions found search unclear.Recall B&B-DQ-L starts high q value that, combination constraintdeterministic makespan must less equal best simulated probabilis9. One idea improving lower bound investigate incorporate resourcebased propagators (e.g., edge-finding) evaluation partial solution. single trialinternal node, deterministic makespan found sampling distributions findinglongest path temporal network. sampling, however, possible applystandard propagation techniques might insert additional edges precedence graphthereby increase makespan, improving lower bound.217fiBeck & Wilsontic makespan found far, significantly prunes search space. Ideally, would likesearch high q find solutions good probabilistic makespanswish find good solutions quickly simulated probabilistic makespanvalues used prune subsequent search lower q values. Therefore, effortbetter understand B&B-DQ-L search, examine characteristics initialsolutions finds.idea quality solutions produced high q values seencomparing probabilistic makespan found high q (the first solution found)best solution found run. Table 7 presents comparison form f ,mean normalized makespans initial solutions found B&B-N B&B-DQL. data indicate first solution found B&B-DQ-L much betterfound B&B-N. B&B-N searches initial solution, upper bounddeterministic makespan constrain problem: solution thereforeeasy find (i.e., backtracking) little constraint propagationheuristic information available guide search solution small makespan.contrast, B&B-DQ-L searches initial solution, high q value meanssearching highly constrained search space deterministic makespan mustless probabilistic makespan. Therefore, tight upper bounddeterministic makespan (relative durations incorporate q values).many cases, initial iterations fail find feasible solutions, quickly.Eventually, q value low enough allow feasible solution, however searchsolution strongly guided propagation problem constraints. summary,initial search B&B-N guidance constraint propagation toward goodsolution B&-DQ-L guided constraint propagation overly constrainedproblem. Table 7 shows that, experiments, guidance tends result betterinitial solutions. believe observation may useful generally constraintsolving (see Section 7).provide fuller indication performance differences, Table 7 also presentsimprovement first solution achieved: difference first solutionlast solution (Dl ) found algorithm (Dl value reported Table 3).larger problem sets, improvement made first solution B&B-DQ-Lgreater. smaller problem sets, improvement B&B-N greaterB&B-DQ-L, however, suspect ceiling effect reduces amount B&B-DQ-Limprove (i.e., initial solutions already quite close optimal).6.2.2 Analysis: Heuristic Algorithmsturn performance heuristic algorithms. first examine hypothesisperformance dependent two factors: ability algorithms findsolutions low deterministic makespans correlation good deterministicprobabilistic makespans. turn analysis effect differing qvalues heuristic algorithm performance.Finding Good Deterministic Makespans. argued performanceheuristic techniques (and B&B-DQ-L) dependent upon ability find solutionsgood deterministic makespans. provide evidence argument, looked218fiProactive Algorithms JSPProblemSize446610 1020 20Unc.Level0.10.510.10.510.10.510.10.51B&B-NDfDf l1.0890.0621.1190.0591.2270.0761.1060.0721.1630.0501.3010.0751.1910.0061.2580.0171.3690.0051.2590.0031.3320.0041.4940.008B&B-DQ-LDfDf l1.0280.0051.0780.0291.1650.0361.0670.0461.1080.0351.2210.0511.0690.0451.1510.0501.2690.0541.1680.0261.2420.0091.4040.016Table 7: mean normalized makespan first solutions found algorithm(Df ) difference mean normalized makespans firstlast solutions (Df Dl ).quality best deterministic solutions found B&B-I-BS Tabu-I-BS.hypothesize better performing algorithm also found better deterministicsolutions worse performer.Table 8 presents results algorithm two largest problem sets. 10 meannormalized deterministic makespan (MNDM ) calculated follows:MNDM (a, L) =makeq (a, l)1 X|L|makeq,min (l, B&B BS)(2)L set problem instances, makeq (a, l) mean deterministic makespan foundalgorithm l 10 runs, makeq,min (l, B&B BS) lowest deterministicmakespan found B&B-I-BS algorithm runs problem l. MNDM, therefore,provides relative measure quality average deterministic makespanstwo algorithms: higher value, worse average makespan found relativeB&B-I-BS.Table 8 consistent hypothesis. 10 10 problems, B&B-I-BSoutperforms Tabu-I-BS, former able find solutions lower mean deterministicmakespan. 20 20 problems results reversed Tabu-I-BS findingbetter mean deterministic makespans better probabilistic makespans.result lends support original motivation deterministic filtering algorithms: performance algorithms terms probabilistic solution qualitypositively related quality deterministic solutions able find.next section addresses question performance relationship observed.10. show 10 10 20 20 problems sets influenced conjecturedrepeated simulation behavior Tabu-I-BS.219fiBeck & WilsonProblemSize10 1020 20UncertaintyLevel0.10.510.10.51MNDMB&B-I-BS Tabu-I-BS1.0001.0021.0001.0041.0001.0041.0451.0021.0410.9981.0371.002Table 8: mean normalized deterministic makespan (MNDM) B&B-I-BS TabuI-BS.Correlation Deterministic Probabilistic Makespan. ability algorithms find good deterministic makespans would irrelevantability find good probabilistic makespans without correlation two.reasonable expect level uncertainty problem instance impactcorrelation: low uncertainty variations duration small, meaningexpect probabilistic makespan relatively close deterministic makespan.uncertainty level high, distribution probabilistic makespans singlesolution wider, resulting less correlation. hypothesize impactuncertainty level contributes observed performance degradation (see Tables 3 5)heuristic techniques higher uncertainty levels problem size held constant.examine hypothesis generated 100 new 10 10 deterministic JSP probleminstances generator parameters used above. standard deviationsduration activity 100 instances generated independentlyfive uncertainty levels uj {0.1, 0.5, 1, 2, 3} resulting total 500 probleminstances (100 uncertainty level). instance four qvalues (as Table 2), randomly generated 100 deterministic solutionssimulated. Using R statistical package (R Development Core Team, 2004),measured correlation coefficient problem set. cell Table 9 result10000 pairs data points: deterministic probabilistic makespans 100 randomdeterministic solutions 100 problem instances.Uncertainty Level0.10.5123q00.99900.97670.91760.82400.7381q10.99960.99120.97400.94510.9362q20.99960.99170.97510.95070.9418q30.99950.99090.97360.95170.9423Table 9: correlation coefficient (r) comparing pairs deterministic probabilistic makespans set 10 10 probabilistic JSPs. cell representscorrelation coefficient 10000 deterministic, probabilistic pairs.220fiProactive Algorithms JSPTable 9 supports explanation performance heuristic techniques.uncertainty level increases, correlation deterministic makespancorresponding probabilistic makespan lessens. strength correlation somewhatsurprising: even highest uncertainty level standard deviation duration activity uniformly drawn 0 3 times mean duration,correlation 0.94 q2 q3 . positive indication heuristicalgorithms suggests may scale well higher uncertainty levels providedreasonable q value used. examine impact q values original experiments implications deterministic/probabilistic makespan correlationnext section.emphasized results based correlations deterministic probabilistic makespans randomly generated solutions. addressedcorrelations might change high-quality solutions, might consideredappropriate population sample. One technical difficultydesign experiment examine this, ensure sufficiently randomized samplepopulation good solutions; also, result could depend strongly (ratherarbitrary) particular choice quality cutoff solutions.Effect q Values. heuristic algorithms requires fixed q value.11experimented four different values (see Table 2). Table 10 displays significant pairwise differences among q values heuristic measured randomizedpaired-t tests (Cohen, 1995) p 0.005. observed, almostsignificant differences low levels uncertainty (0.1 0.5) smallest problemset. higher levels uncertainty larger problems, using q0 never betterusing one higher q values many cases, q0 results worst mean makespan.Among q-values, majority problem sets algorithmssignificant differences. given algorithm, never case lower q value leadssignificantly better results higher q value.correlation results Table 9 provide explanation differences.10 10 problems, performance q0 algorithms competitivelarge difference correlations deterministic probabilistic solutions (i.e.,uncertainty levels 0.1 0.5). uncertainty level 1, significantreduction correlation coefficient q0 corresponding reduction meannormalized probabilistic makespans found algorithms using q0 .6.3 Summaryresults experiments summarized follows:principled use simulation (B&B-N) useful small problems.simulation time major component run-time resulting littleexploration search space.Algorithm B&B-DQ-L, based idea iteratively reducing parameter determines validity lower bound, results equal performance small prob11. addressing behavior B&B-DQ-L, q descends run algorithm.examining algorithms fixed q values.221fiBeck & WilsonProblemSize446610 1020 20Unc.Level0.10.510.10.510.10.510.10.51B&BTBSI-BSq2 < {q1 , q3 } < q0q2 < {q0 , q1 }{q1 , q2 , q3 } < q0{q1 , q2 , q3 } < q0{q1 , q2 , q3 } < q0{q1 , q2 , q3 } < q0{q1 , q2 } < q0{q2 , q3 } < q0q2 < q 1q2 < q1 < q0{q2 , q3 } < q0q3 < q 0TabuTBSI-BSq 2 < q1{q1 , q2 , q3 } < q0{q1 , q2 , q3 } < q0q1 < q 0{q1 , q3 } < q0{q2 , q3 } < q0q1 < q 0{q1 , q2 , q3 } < q0q 2 < q0{q1 , q2 , q3 } < q0 {q1 , q2 , q3 } < q0{q1 , q2 , q3 } < q0{q1 , q2 , q3 } < q0Table 10: results pair-wise statistical tests algorithm problem set.notation < b indicates algorithm using q = achieved significantlybetter solution (i.e., lower probabilistic makespan) used q = b. -indicates significant differences. statistical tests randomized paired-ttests (Cohen, 1995) p 0.005.lems much better performance larger problems compared B&B-N.work needed understand behavior algorithm, however preliminary evidence indicates able find good solutions quickly currentapplication domain.series heuristic algorithms proposed based using deterministic makespanfilter solutions would simulated. demonstrated performance algorithms depends ability find good deterministicmakespans correlation quality deterministic probabilistic solutions. shown even problems quite high uncertaintylevel, deterministic problems constructed lead strong deterministic/probabilistic makespan correlation.Central success heuristic algorithms use q value governedextent duration uncertainty represented durations activitiesdeterministic problems. shown incorporation uncertaintydata leads stronger correlation deterministic probabilistic makespanscorresponding ability find better probabilistic makespans.222fiProactive Algorithms JSP7. Extensions Future Worksection, look three kinds extensions work. First, showtheoretical framework fact applies far general probabilistic scheduling problemsjob shop scheduling. Section 7.2, discuss ways algorithmsprobabilistic JSP presented paper might improved. Finally, discusspossibility developing central idea B&B-DQ-L algorithm solving approachgeneral constraint optimization problems.7.1 Generalization Scheduling Problemsresults paper derived important case job shop schedulingproblems. fact, valid much broader class scheduling problems, includingresource-constrained project scheduling problems common form (e.g., probabilisticversion deterministic problems studied work Laborie, 2005). section,describe extend framework approaches.approach relies fact job shop scheduling problem, one focusorderings activities, rather directly assignments start times activities;specifically, definition minimum makespan based orderings equivalentone based start time assignments; equivalence holds much generally.First, 7.1.1, give basic definitions properties immediate extensions defined Section 2. Then, 7.1.2, characterize class schedulingproblems properties require, use logical expression representconstraints problem. 7.1.3 give key result relating schedule-basedminimum makespan ordering-based minimum makespan. Section 7.1.4 discussesextended class probabilistic scheduling problems, Section 7.1.5 considers differentoptimization functions.7.1.1 Schedules, Orderings MakespansSection 2, given set activities, activity Ai associated positive duration di (for deterministic case). schedule (for A) definedfunction set activities set time-points (which non-negativenumbers), defining activity starts. Let Z schedule. makespan make(Z)schedule Z defined time last activity completed, i.e.,maxAi (Z(Ai ) + di ). say Z orders Ai Aj Aj starts earlierAi ends, i.e., Z(Ai ) + di Z(Aj ).essential aspect job shop problems approach one focusorderings activities rather schedules; Section 2 use term solutionordering satisfies constraints given JSP. Define ordering (on A)strict partial order A, i.e., irreflexive transitive relation set activities.Hence, ordering s, Ai A, (Ai , Ai )/ s, (Ai , Aj ) (Aj , Ak ) s,(Ai , Ak ) s. (Ai , Aj ) s, say orders Ai Aj ; also sayAi predecessor Aj . path (or s-path) sequence activitiesAi precedes Aj sequence, orders Ai Aj . length len() path(in ordering) defined sum durations activities path,223fiBeck & WilsonPi.e., Ai di . makespan, make(s), ordering defined lengthlongest s-path. s-path said critical s-path length equalmakespan ordering s, i.e., one longest s-paths.schedule associated ordering. schedule Z define ordering sol(Z)follows: sol(Z) orders activity Ai Aj Z orders Ai Aj .Conversely, ordering one define non-delay schedule, optimalamong schedules compatible ordering, starting activity soonpredecessors finish. Let ordering. inductively define schedule Z = sched(s)follows: Ai predecessor, start Ai time 0, i.e., Z(Ai ) = 0. Otherwise,set Z(Ai ) = maxAj pred(Ai ) (Z(Aj ) + dj ), pred(Ai ) set predecessors Ai .fact acyclic guarantees defines schedule. Section 2.1,following two important properties. first states makespan orderingequal makespan associated schedule. second states makespanschedule better makespan associated ordering.Proposition 5(i) ordering s, make(sched(s)) = make(s).(ii) schedule Z, make(sol(Z)) make(Z).proof straight-forward. follows easily induction schedule Zrespects precedence constraints expressed ordering s, last activitys-path end earlier Z length path; applying critical pathimplies (ii) make(sol(Z)) make(Z), implies half (i): make(sched(s)) make(s).working backwards activity finishes last sched(s), choosing immediatepredecessor stage, one generates (in reverse order) path whose length equalmake(sched(s)), hence showing make(sched(s)) make(s), proving (i).7.1.2 Positive Precedence Expressionsdefine class scheduling problems, using call positive precedence expressions (PPEs) represent constraints. scheduling problems assumespreemption (so activities cannot interrupted started) usemakespan cost function.activities Ai Aj , expression before(i, j) interpreted constraint (onpossible schedules) activity Aj starts earlier end activity Ai .expressions called primitive precedence expressions. positive precedence expressiondefined logical formula built primitive precedence expressions, conjunctionsdisjunctions. (The term positive used since involve negations.) Formally,set E positive precedence expressions (over A) defined smallest set(a) E contains before(i, j) Ai Aj A, (b) E,( ) ( ) E.Positive precedence expressions interpreted constraining schedules A.Let E PPE let Z schedule. define Z satisfies recursivelyfollows:224fiProactive Algorithms JSPZ satisfies primitive precedence expression before(i, j) Z ordersAj , i.e., Z(Ai ) + di Z(Aj );Z satisfies conjunction two constraint expressions satisfiesthem;Z satisfies disjunction two constraint expressions satisfiesleast one them.Similarly, ordering positive precedence expression recursively definesatisfies obvious way: satisfies before(i, j) ordersAj . Ordering satisfies ( ) satisfies . Ordering satisfies( ) satisfies either .Positive precedence expressions powerful enough represent constraintsjob shop scheduling problem, resource-constrained project scheduling problem.JSPs Positive Precedence Expressions. Resource constraints job shop scheduling problem give rise disjunctions primitive precedence expressions: pairactivities Ai Aj require resource, expression before(i, j) before(j, i)expresses Ai Aj overlap (one precedes other).ordering activities job expressed terms primitive expressions: before(i, j)Ai precedes Aj within job. Hence, constraints job shop problemexpressed positive precedence expression conjunctive normal form, i.e., conjunctiondisjunctions primitive precedence expressions.RCPSPs PPEs. constraints resource-constrained project scheduling problem(RCPSP) (Pinedo, 2003; Brucker et al., 1999; Laborie & Ghallab, 1995; Laborie, 2005)also expressed positive precedence expression conjunctive normal form.RCPSP, precedence constraints activities, expressedprimitive precedence expression; let conjunction these. RCPSP,set resources, positive capacity. Associated activityresource r rate usage Ai (r) resource r activity Ai . followingresource constraints schedule: resource r, time-point t, sumAi (r) activities Ai progress (i.e., startedyet ended) must exceed capacity resource r.Define forbidden set (or conflict set) set activities whose total usageresource exceeds capacity resource. Let F set forbidden sets. (Ifwished, could delete F set superset set F;could also delete set H contains elements Ai Aj Ai precedes Ajaccording .) resource constraints expressed equivalently as: H F,exists time every activity H progress. holdsH F, exist two activities H overlap (since pairsactivities H overlap activities H progress latest start timeactivities H), i.e., exists Ai , Aj H before(i, j). Hence, schedule satisfiesresource constraints satisfies positive precedence expression defined225fiBeck & Wilson^HF_before(i, j).Ai ,Aj Hi6=jTherefore, expression ( ) represents RCPSP, i.e., schedule satisfies constraintsRCPSP satisfies ( ).Another class scheduling problems, represented positiveprecedence expression, class based AND/OR precedence constraints (Gillies &Liu, 1995; Mohring, Skutella, & Stork, 2004).7.1.3 Solutions Minimum Makespanfixed positive precedence expression A, say schedule Z validsatisfies . say ordering solution satisfies . ordering satisfiesbefore(i, j), then, construction, sched(s) satisfies before(i, j). also follows immediatelyschedule Z satisfies before(i, j) sol(Z) satisfies before(i, j). followingresult proved easily induction number connectives .Lemma 2 PPE A, solution, sched(s) valid schedule.Z valid schedule, sol(Z) solution.minimum makespan (for ) defined infimum makespan validschedules, i.e., infimum make(Z) valid schedules Z. minimum solutionmakespan defined minimum makespan solutions, i.e., minimummake(s) solutions s. following key result links schedulebased definition minimum makespan solution-based definition. followsProposition 5 Lemma 2, since solution valid schedule (i.e., sched(s))value makespan, valid schedule Z solution (i.e.,sol(Z)) least good value makespan.Proposition 6 Let positive precedence expression A. minimummakespan equal minimum solution makespan.7.1.4 Probabilistic Scheduling Problems based PPEsprobabilistic versions scheduling problems defined wayJSPs. duration activity Ai random variable. positive precedenceexpression used represent constraints.definitions Sections 2 4 immediately extended muchgeneral setting. results paper still hold, exactly proofs.particular, probabilistic problem one associates corresponding deterministicproblem way; lower bound results Section 4.2 based longestpath characterization makespan; Monte Carlo approach (or least usefulness)relies fact makespan solution equal makespan associatedschedule. Furthermore, algorithms Section 5 extend, given one methodsolving corresponding deterministic problem.226fiProactive Algorithms JSPordering-based policies use (based fixing partial ordering activities,irrespective sampled values durations) known Earliest Start policies(Radermacher, 1985). policies studied RCPSPs (see e.g.,Stork, 2000, however aim work minimize expected makespan, whereasattempting minimize -makespan).7.1.5 Different Optimization Functionsapproach evaluating comparing solutions based use MonteCarlo simulation generate sample distribution, techniques quite general.Much work paper also generalizes immediately regular cost functions, regular means function monotonic sense increasingend activity schedule decrease cost. regular function basedefficiently computable measurement sample distributions accommodated.example, could easily adapt situations probability extreme solutionsimportant basing optimization function maximum sampled makespan. Conversely, could use measures tightness makespan distribution situationsminimizing variance measure accuracy schedule important. Furthermore, weighted combinations functions (e.g., -makespan plus measuredistribution tightness) could easily incorporated.also modify approach account ways comparing solutionsbased sample distributions. example, could perform t-tests using sampledistributions determine one solution significantly lower expected makespan.7.2 Toward Better Algorithms Probabilistic JSPstwo directions future work algorithms presented paper. First,B&B-N could improved make use deterministic techniques and/or incorporate probabilistic reasoning existing deterministic techniques. example, numberdeterministic lower bound formulations PERT networks exist operations research literature (Ludwig, Mohring, & Stork, 2001) may used evaluate partialsolutions. Similarly, perhaps dominance rules presented Daniels Carrillo (1997)one-machine -robustness problem generalized multiple resources. Anotherapproach improving B&B-N performance incorporate explicit reasoningprobability distributions standard constraint propagation techniques. Techniqueslongest path calculations edge-finding make inferences based propagationminimum maximum values temporal variables. believe manytechniques adapted reason probabilistic intervals; related workdone, example, simple temporal networks uncertainty (Morris, Muscettola, &Vidal, 2001; Tsamardinos, 2002).second direction future work improvement heuristic algorithms.key advantage algorithms make use deterministic techniquesscheduling: transforming probabilistic problems deterministic problems, bringsignificant set existing tools bear problem. developments approach include adaptively changing q-values search order find leadsolutions better values probabilistic makespan (D (s)). deeper understanding227fiBeck & Wilsonrelationship good deterministic solutions good probabilistic solutions,building work here, necessary pursue work principled fashion.course, proactive techniques sufficient. practice, schedules dynamicneed adapted new jobs arrive existing jobs canceled. execution time,reactive component necessary deal unexpected (or sufficiently unlikely) disruptionsthat, nonetheless, occur. complete solution scheduling uncertainty needsincorporate elements reason uncertainty different levels granularitydifferent time pressures. See work Bidot, Vidal, Laborie Beck (2007)recent work direction.7.3 Exploiting Unsound Lower Bounds Constraint ProgrammingB&B-DQ-L algorithm may represent problem-solving approach appliedbeyond current application area. abstract away probabilistic JSP application,central idea B&B-DQ-L exploit unsound lower bound (over)constrainsearch run subsequent searches gradually relaxed unsound lower bound.approach may play strengths constraint programming: searching withinhighly constrained spaces.example, assignment problem (AP) well-known lower bound travelingsalesman problem (TSP) used cost-based constraint literature(Focacci, Lodi, & Milano, 2002; Rousseau, Gendreau, Pesant, & Focacci, 2004). GivenTSP, P , let AP (P, q) corresponding assignment problem travel distancesmultiplied q. is, let dij distance cities j P let d0ijdistance cities j AP (P, q). d0ij = dij q q 1. approachsimilar B&B-DQ-L algorithm applied solve TSP.would interesting investigate approach compares traditionaloptimization approach constraint programming. may particularly useful applications evaluation partial solutions expensive existsparameterizable, inexpensive lower bound.8. Conclusionpaper, addressed job shop scheduling durations activitiesindependent random variables. theoretical framework created formally defineproblem prove soundness two algorithm components: Monte Carlo simulationfind upper bounds probabilistic makespan solution partial solution;carefully defined deterministic JSP whose optimal makespan lower boundprobabilistic makespan corresponding probabilistic JSP.used two components together either constraint programmingtabu search define number algorithms solve probabilistic JSPs. introducedthree solution approaches: branch-and-bound technique using Monte Carlo simulationevaluate partial solutions; iterative deterministic search using Monte Carlo simulationevaluate solutions series increasingly less constrained problems basedparameterizable lower bound; number deterministic filtering algorithmsgenerate sequence solutions deterministic JSP, simulatedusing Monte Carlo simulation.228fiProactive Algorithms JSPempirical evaluation demonstrated branch-and-bound techniqueable find approximately optimal solutions small problem instances. iterativedeterministic search performs well as, better than, branch-and-bound approachproblem sizes. However, medium large instances, deterministic filteringtechniques perform much strongly providing optimality guarantees.experimentation demonstrated techniques using deterministic methods,correlation deterministic makespan probabilistic makespan key factoralgorithm performance: taking account variance duration deterministicproblem led strong correlations good algorithmic performance.Proactive scheduling techniques seek incorporate models uncertainty offline, predictive schedule. goal techniques increase robustnessschedules produced. important schedule typically generatedexecuted isolation. decisions deliver raw materialsschedule up- down-stream factories affected individual schedule. Indeed,schedule seen locus competing constraints across company supplychain (Fox, 1983). Differences predictive schedule executionsignificant source disruption leading cascading delays across widely separated entities.ability, therefore, develop schedules robust uncertainty important.paper represents step direction.Acknowledgmentswork received support Science Foundation Ireland grants 00/PI.1/C07505/IN/I886, Natural Sciences Engineering Research Council Canada,ILOG, SA. authors would like thank Daria Terekhov Radoslaw Szymanekcomments previous versions paper. Preliminary versions work reportedpaper published Beck Wilson (2004, 2005).ReferencesBeck, J. C. (1999). Texture measurements basis heuristic commitment techniquesconstraint-directed scheduling. Ph.D. thesis, University Toronto.Beck, J. C., & Fox, M. S. (2000). Dynamic problem structure analysis basisconstraint-directed scheduling heuristics. Artificial Intelligence, 117 (1), 3181.Beck, J. C., & Wilson, N. (2004). Job shop scheduling probabilistic durations.Proceedings Sixteenth European Conference Artificial Intelligence (ECAI04),pp. 652656.Beck, J. C., & Wilson, N. (2005). Proactive algorithms scheduling probabilistic durations. Proceedings Nineteenth International Joint Conference ArtificialIntelligence (IJCAI05), pp. 12011206.Bidot, J. (2005). General Framework Integrating Techniques Scheduling Uncertainty. Ph.D. thesis, Ecole Nationale dIngeieurs de Tarbes.229fiBeck & WilsonBidot, J., Vidal, T., Laborie, P., & Beck, J. C. (2007). general framework schedulingstochastic environment. Proceedings Twentieth International JointConference Artificial Intelligence (IJCAI07), pp. 5661.Blazewicz, J., Domschke, W., & Pesch, E. (1996). job shop scheduling problem: Conventional new solution techniques. European Journal Operational Research,93 (1), 133.Boutilier, C., Dean, T., & Hanks, S. (1999). Decision-theoretic planning: Structural assumptions computational leverage. Journal Artificial Intelligence Research,11, 194.Brucker, P., Drexl, A., Mohring, R., Neumann, K., & Pesch, E. (1999). Resource-constrainedproject scheduling: Notation, classification, models methods. European JournalOperational Research, 112, 341.Burns, A., Punnekkat, S., Littlewood, B., & Wright, D. (1997). Probabilistic guarantees fault-tolerant real-time systems. Tech. rep. DeVa TR No. 44, Design Validation, Esprit Long Term Research Project No. 20072. Availablehttp://www.fcul.research.ec.org/deva.Burt, J. M., & Garman, M. B. (1970). Monte Carlo techniques stochastic network analysis. Proceedings Fourth Annual Conference Applications Simulation,pp. 146153.Cohen, P. R. (1995). Empirical Methods Artificial Intelligence. MIT Press, Cambridge, Mass.Daniels, R., & Carrillo, J. (1997). -robust scheduling single-machine systemsuncertain processing times. IIE Transactions, 29, 977985.Davenport, A. J., Gefflot, C., & Beck, J. C. (2001). Slack-based techniques robustschedules. Proceedings Sixth European Conference Planning (ECP-2001).Davenport, A., & Beck, J. C. (2000). survey techniques scheduling uncertainty.Tech. rep.. Available at: http://www.tidel.mie.utoronto.ca/publications.php.Drummond, M., Bresina, J., & Swanson, K. (1994). Just-in-case scheduling. ProceedingsTwelfth National Conference Artificial Intelligence (AAAI-94), pp. 10981104, Menlo Park, CA. AAAI Press/MIT Press.Feller, W. (1968). Introduction Probability Theory Applications (Third edition). John Wiley Sons, New York, London.Focacci, F., Lodi, A., & Milano, M. (2002). hybrid exact algorithm TSPTW.INFORMS Journal Computing, 14 (4), 403417.Fox, M. S. (1983). Constraint-Directed Search: Case Study Job-Shop Scheduling. Ph.D.thesis, Carnegie Mellon University, Intelligent Systems Laboratory, Robotics Institute, Pittsburgh, PA. CMU-RI-TR-85-7.Gao, H. (1995). Building robust schedules using temporal protectionan empirical studyconstraint based scheduling machine failure uncertainty. Masters thesis,Department Industrial Engineering, University Toronto.230fiProactive Algorithms JSPGarey, M. R., & Johnson, D. S. (1979). Computers Intractability: Guide TheoryNP-Completeness. W.H. Freeman Company, New York.Ghosh, S. (1996). Guaranteeing fault tolerance scheduling real-time systems.Ph.D. thesis, University Pittsburgh.Ghosh, S., Melhem, R., & Mosse, D. (1995). Enhancing real-time schedules toleratetransient faults. Real-Time Systems Symposium.Gillies, D. W., & Liu, J. W.-S. (1995). Scheduling tasks AND/OR precedence constraints. SIAM J. Comput., 24, 797810.Hagstrom, J. N. (1988). Computational complexity PERT problems. Networks, 18,139147.Herroelen, W., & Leus, R. (2005). Project scheduling uncertainty: Survey researchpotentials. European Journal Operational Research, 165 (2), 289306.Laborie, P. (2003). Algorithms propagating resource constraints AI planningscheduling: Existing approaches new results. Artificial Intelligence, 143, 151188.Laborie, P. (2005). Complete MCS-Based Search: Application Resource-ConstrainedProject Scheduling. Proceedings Nineteenth International Joint ConferenceArtificial Intelligence (IJCAI05), pp. 181186.Laborie, P., & Ghallab, M. (1995). Planning sharable resource constraints. Proceedings Fourteenth International Joint Conference Artificial Intelligence(IJCAI95).Le Pape, C., Couronne, P., Vergamini, D., & Gosselin, V. (1994). Time-versus-capacitycompromises project scheduling. Proceedings Thirteenth WorkshopUK Planning Special Interest Group.Leon, V. J., Wu, S. D., & Storer, R. H. (1994). Robustness measures robust schedulingjob shop. IIE Transactions, 26 (5), 3243.Ludwig, A., Mohring, R., & Stork, F. (2001). computational study boundingmakespan distribution stochastic project networks. Annals Operations Research,102, 4964.Meuleau, N., Hauskrecht, M., Kim, K., Peshkin, L., Kaelbling, L., Dean, T., & Boutilier, C.(1998). Solving large weakly coupled markov decision processes. ProceedingsFifteenth National Conference Artificial Intelligence (AAAI-98).Mohring, R., Skutella, M., & Stork, F. (2004). Scheduling AND/OR precedence constraints. SIAM J. Comput, 33 (2), 393415.Morris, P., Muscettola, N., & Vidal, T. (2001). Dynamic control plans temporaluncertainty. Proceedings Seventeenth International Joint ConferenceArtificial Intelligence (IJCAI-01).Nowicki, E., & Smutnicki, C. (1996). fast taboo search algorithm job shop problem.Management Science, 42 (6), 797813.Nuijten, W. P. M. (1994). Time resource constrained scheduling: constraint satisfaction approach. Ph.D. thesis, Department Mathematics Computing Science,Eindhoven University Technology.231fiBeck & WilsonPinedo, M. (2003). Scheduling: Theory, Algorithms, Systems (2nd edition). PrenticeHall.R Development Core Team (2004). R: language environment statistical computing.R Foundation Statistical Computing, Vienna, Austria. ISBN 3-900051-07-0.Radermacher, F. J. (1985). Scheduling project networks. Annals Operations Research,4, 227252.Rousseau, L., Gendreau, M., Pesant, G., & Focacci, F. (2004). Solving VRPTWsconstraint programming based column generation. Annals Operations Research,130, 190216.Stork, F. (2000). Branch-and-bound algorithms stochastic resource-constrained projectscheduling. Tech. rep. 702/2000, Technische Universitat Berlin, Department Mathematics.Tsamardinos, I. (2002). probabilistic approach robust execution temporal plansuncertainty. Methods Applications Artificial Intelligence: ProceedingsSecond Hellenic Conference Artificial Intelligence, Vol. 2308 Lecture NotesArtificial Intelligence, pp. 97108.Watson, J.-P., Barbulescu, L., Whitley, L., & Howe, A. (2002). Contrasting structuredrandom permutation flow-shop scheduling problems: search-space topologyalgorithm performance. INFORMS Journal Computing, 14 (1).Wilson, N. (2000). Algorithms Dempster-Shafer Theory. In: Kohlas, J., Moral, S.,(eds.) Algorithms Uncertainty Defeasible Reasoning, Volume 5, HandbookDefeasible Reasoning. Kluwer Academic Publishers.Wurman, P., & Wellman, M. (1996). Optimal factory scheduling using stochastic dominanceA*. Proceedings Twelfth Conference Uncertainty Artificial Intelligence(UAI-96).232fiJournal Artificial Intelligence Research 28 (2007) 431-451Submitted 07/06; published 04/07Discovering Classes Strongly Equivalent Logic ProgramsFangzhen Linflin@cs.ust.hkDepartment Computer Science EngineeringHong Kong University Science TechnologyClear Water Bay, Kowloon, Hong KongYin Chengzchenyin@gmail.comDepartment Computer ScienceSouth China Normal UniversityGuangzhou, P.R. ChinaAbstractpaper apply computer-aided theorem discovery technique discover theorems strongly equivalent logic programs answer set semantics. discovered theorems capture new classes strongly equivalent logic programs leadnew program simplification rules preserve strong equivalence. Specifically,help computers, discovered exact conditions capture strong equivalencerule empty set, two rules, two rules one tworules, two rules another rule, three rules two threerules.1. Introductionpaper apply computer-aided theorem discovery technique discover theoremsstrongly equivalent logic programs answer set semantics. discoveredtheorems capture new classes strongly equivalent logic programs lead newprogram simplification rules preserve strong equivalence.Theorem discovery highly creative human process. Generally speaking,divide two steps: (i) conjecture formulation, (ii) conjecture verification,computers help two steps. instance, machine learning toolsused first step, i.e. coming reasonable conjectures, automateddeduction tools used second step, i.e. verifying correctnessconjectures.theorem discovery may make use learning, two tasks fundamentally different. Theorem discovery starts theory, aims finding interestingconsequences theory, learning mostly induction, i.e. startsexamples/consequences, aims finding theory would explain given examples/consequences.Using computers discover theorems old aspiration.success stories. instance, (Lenat, 1979) reported able comeinteresting concepts theorems number theory, remarkable systemsdescribed Petkovsek, Wilf, Zeilberger (1996) discover many identities, especiallyhypergeometric identities involving sums binomial coefficients importantanalyses algorithms. Yet another example interesting theorems discoveredc2007AI Access Foundation. rights reserved.fiLin & Chenalmost fully automatically recent work Lin (2004) discovering state invariantsplanning domains. Lin showed ways classify many state constraintsuseful planning according syntactic properties, enumerate easilymany domains. Furthermore, many constraints whether invariantschecked automatically. result, system described Lin (2004) discovermany common constraints planning domains, logistics domain, could evendiscover set complete state invariants.Following line research, paper, consider problem discoveringclasses strongly equivalent sets logic program rules answer set semantics.noted Lifschitz, Pearce, Valverde (2001), two sets rules strongly equivalent,replace one logic program without changing semanticsprogram. Thus identifying strongly equivalent sets logic program rules usefulexercise may applications program simplification.paper organized follows. next section, briefly review basicconcepts logic programming answer set semantics. section 3 stateprecise terms type theorems want discover. section 4 provegeneral theorems help us prove theorems, section 5, describetheorems discovered. discuss application logic programsimplification section 6, finally conclude paper section 7.2. Answer Set ProgrammingTraditional logic programming systems like Prolog solve problems query answering.user encodes knowledge domain set rules, solves problem issuingqueries set rules. contrast, Answer Set Programming (ASP) (Niemela, 1999;Lifschitz, 1999; Marek & Truszczynski, 1999) constraint-based programming paradigm.based logic programming answer set semantics (Gelfond & Lifschitz, 1988,1991). solve problem, user encodes domain knowledge logic programway answer sets program correspond solutions originalproblem. Compared constraint-based programming paradigms, ASP allows naturalencodings recursive relations, built-in facilities default reasoning. Several ASPsolvers developed (Niemela, Simons, & Syrjanen, 2000; Leone, Pfeifer, Faber,Eiter, Gottlob, Perri, & Scarcello, 2006; Lin & Zhao, 2004; Lierler & Maratea, 2004).date, ASP used space shuttle planning (Nogueira, Balduccini, Gelfond, Watson,& Barry, 2001), evolutional linguistics (Erdem, Lifschitz, Nakhleh, & Ringe, 2003),others. following, briefly review basic notions ASP.Let L propositional language, i.e. set atoms. paper shall considerlogic programs rules following form:h1 ; ; hk p1 , , pm , pm+1 , , pn(1)hi pi atoms L. logic program default negation (not ),constraints (when k = 0), disjunctions head rules. following, rrule form, write Hdr denote set {h1 , ..., hk }, Psr set {p1 , ..., pm },Ngr set {pm+1 , ..., pn }. Thus rule r also written Hdr Psr , Ngr .semantics programs given answer sets (Gelfond & Lifschitz, 1991),432fiDiscovering Classes Strongly Equivalent Logic Programsdefined fixed-point operator known Gelfond-Lifschitztransformation. Let X subset L, P logic program. Gelfond-Lifschitztransformation P X, written P X , set rules obtained P accordingfollowing two rules:1. rule form (1) P , pi X + 1 n, deleterule.2. Delete literals form pi bodies remaining rules.instance, P set following rules:a; bcP {a} {a; b }, P {b} {(a; b ), (c )}.Clearly, X P , P X set rules operator.set X answer set P X minimal set atoms satisfies every ruleP X , X satisfies rule formh 1 ; ; h k p1 , , p1 k, hi X whenever {p1 , ..., pm } X. instance,program, {a} {b, c} answer sets, answer setsprogram.Two logic programs P1 P2 said equivalent answer sets,strongly equivalent (Lifschitz et al., 2001) (under language L), written P1 'se P2 ,logic program P L, P P1 P P2 equivalent (thus write P1 6'se P2P1 P2 strongly equivalent). example, {a b} {a c}equivalent, strongly equivalent. shown {a a} 'se { a}.abstract, also say rule r strongly equivalent another rule r0 , writtenr 'se r0 , {r} 'se {r0 }, two rules r1 r2 strongly equivalent rule r, written{r1 , r2 } 'se r, {r1 , r2 } 'se {r}, on.notion strong equivalence important ASP several reasons. First all,helps us understand answer set semantics. instance, Turner (2003) showeddisjunctive rule (a; b ) strongly equivalent set normal rules. impliescannot modular translation disjunctive logic programs normal logicprograms. However,{(a; b ), ( a, b)}strongly equivalent{(a b), (b a), ( a, b)}.means constraint ( a, b), disjunctive rule (a; b ) replacedtwo rules without disjunction. Secondly, mentioned introduction, P1P2 strongly equivalent, interchangeable regardless occur.Thus large repertoire pairs strongly equivalent logic programs, could433fiLin & Chenuse transform given program one suitable need hand.particular, could help us simplify program purpose computing answersets. shall see, discovered theorems contribute significantly repertoire.Lifschitz et al. (2001) showed checking strong equivalence two logicprograms done logic here-and-there, three-valued non-classical logicsomewhere classical logic intuitionistic logic. Lin (2002) provided mappinglogic programs propositional theories showed two logic programsstrongly equivalent iff corresponding theories propositional logic equivalent.result used generating example pairs strongly equivalent logicprograms, verifying conjecture. repeat here.Let P1 P2 two finite logic programs, L set atoms them.Theorem 1 (Lin, 2002) P1 'se P2 iff propositional logic, following sentence valid:^^^p p0 ) [((r)(r)],(2)pLrP1rP2p L, p0 new atom, rule r form (1), (r)conjunction following two sentences:p1 pm p0m+1 p0n h1 hk ,(3)p01(4)p0mp0m+1p0nh01h0k .Notice = n = 0, left sides implications (3) (4) consideredtrue, k = 0, right sides implications (3) (4) consideredf alse.general checking two sets rules strongly equivalent coNP-complete (c.f.Turner, 2001; Pearce, Tompits, & Woltran, 2001; Lin, 2002).3. Problemmentioned above, one possible use notion strongly equivalent logic programsprogram simplification. instance, given logic program, rule r it,may ask whether deleted without knowing rules P , i.e.whether {r} strongly equivalent empty set. may ask whether rule rP deleted one knows another rule r0 already P , i.e. whether {r, r0 }strongly equivalent {r0 }. general, may ask following k-m-n question:{r1 , ..., rk , u1 , ..., um } 'se {r1 , ..., rk , v1 , ..., vn }? Thus theorem discovery task comeup, given k-m-n problem, computationally effective condition holdsanswer k-m-n question positive.suppose condition C, suppose{r1 , ..., rk , u1 , ..., um } 'se {r1 , ..., rk , v1 , ..., vn },better replace {u1 , ..., um } {v1 , ..., vn } presence r1 , ..., rk purposeof, say computing answer sets program. One way use result simplifygiven program P first choose k rules P , rules it, try find434fiDiscovering Classes Strongly Equivalent Logic Programsn rules condition C holds, replace rules P simpler nrules.However, even checking whether C holds would take negligible constant time, usingprocedure simplify given logic program practical k, m, nsmall k almost number rules givenprogram, n small. Thus seems us worthwhile solvek-m-n problem k, m, n small. particular, paper, shallconcentrate 0-1-0 problem (whether rule always deleted), 0-1-1 problem(whether rule always replaced another one), 1-1-0 problem (in presencerule, whether another rule deleted), 2-1-0 problem (in presence tworules, whether rule always deleted), 0-2-1 problem (if pair rulesreplaced single rule).example theorems want discover problems follows:rule r, r 'se iff (Hdr Ngr ) Psr 6= .(5)4. General Theoremssection, prove general theorems help us verify whether assertionlike (5) true.Let L propositional language, i.e. set atoms. L, construct first-orderlanguage FL equality, two unary predicates H1 H2 , three unary predicates Hdr ,Psr , Ngr logic program rule r L (we assume rule L uniquename), three unary predicates Xi , Yi , Zi positive number i.Notice used Hdr , Psr , Ngr denote sets atoms previously,overload unary predicates. Naturally, intended interpretationsunary predicates respective sets.Definition 1 Given set L atoms, intended model FL one whose domain L,rule r L, unary predicates Psr , Hdr , Ngr interpretedcorresponding sets atoms, Psr , Hdr , Ngr , respectively.Conditions rules L, Psr Ngr 6= , expressed special sentencescalled properties FL .Definition 2 sentence FL property n rules constructed equalitypredicates Xi , Yi , Zi , 1 n. property n rules true (holds)sequence P = [r1 , ..., rn ] n rules [P ] true intended model FL , [P ]obtained replacing Xi Hdri , Yi Psri , Zi Ngri .Notice since [P ] mention predicates Xi , Yi , Zi , H1 , H2 , trueone intended model, true intended models.mentioned above, interested capturing strong equivalencetwo programs computationally effective condition. specifically,small k, m, n, interested finding property k + + n rulessequence k + + n rules, P = [r1 , ..., rk , u1 , ..., um , v1 , ..., vn ],{r1 , ..., rk , u1 , ..., um } 'se {r1 , ..., rk , v1 , ..., vn } iff true P .435(6)fiLin & Chenshall prove general theorems help us verify assertionclass formulas .First all, Theorem 1 reformulated FL follows reading H1 (p) pholds, H2 (p) p0 holds:Theorem 2 P1 'se P2 L iff following sentence^^x(H1 (x) H2 (x)) [(r)(r)]rP1(7)rP2true intended models FL , (r) conjunction following twosentences:[x(Psr (x) H1 (x)) x(Ngr (x) H2 (x))] x(Hdr (x) H1 (x)),(8)[x(Psr (x) H2 (x)) x(Ngr (x) H2 (x))] x(Hdr (x) H2 (x)).(9)first order logic, prenex formula form ~x~y B satisfiable,satisfiable structure n elements, B formula contains quantifiers,constants, function symbols, n length ~x non-empty, 1 ~xempty. prove similar result first-order languages intendedmodels here.Definition 3 sentence FL extended property n rules constructedequality predicates Xi , Yi , Zi , 1 n, H1 H2 . extendedproperty n rules true (holds) sequence P = [r1 , ..., rn ] n rules model[P ] true , [P ] obtained replacing Xi Hdri , YiPsri , Zi Ngri .Definition 4 following, P = [r1 , ..., rn ] tuple rules L, L0 subsetL, define restriction P L0 [r10 , ..., rn0 ], ri0Hdri L0 Psri L0 , (Ngri L0 ).Lemma 1 Let extended property FL n rules, form ~x~y Q,~x tuple w variables, Q formula quantifiers.holds sequence P n rules intended model FL , subsetL0 L L0 w atoms (or one atom w = 0), holdsrestriction P L0 intended model FL0 .Proof: Suppose intended model FL |= [P ]. Thus tuplep~ w (or one w = 0) atoms L |= ~y Q[P ](~x/~p). let L0 set0atoms p~, defined follows:predicates H1 , H2 , Xi , Yi , Zi , 1, interpreted restrictioninterpretation L0 .rule r L0 , predicates Hdr , Psr , Ngr interpreted. well-defined r also rule L,436fiDiscovering Classes Strongly Equivalent Logic Programs0 intended model FL0 . Let P 0 restriction P L0 . P 0tuple rules L0 . Since Q quantifiers (and language function symbols),instantiation ~u ~y L0 , |= Q[P ](~x/~p)(~y /~u) iff 0 |= Q[P 0 ](~x/~p)(~y /~u). Since00|= ~y Q[P ](~x/~p), |= ~y Q[P ](~x/~p), Thus 0 |= ~x~y Q[P 0 ].Using Theorem 2 lemma, show following theorem enableus automate verification part (6) property prenexformat.Theorem 3 Without loss generality, suppose n. property k+m+nrules form ~x~y Q, ~x tuple w variables, Q formulaquantifiers, following two assertions equivalent:(a) sequence k + + n rules, P = [r1 , ..., rk , u1 , ..., um , v1 , ..., vn ], trueP , {r1 , ..., rk , u1 , ..., um } 'se {r1 , ..., rk , v1 , ..., vn }.(b) (b.1) n > 0, sequence P = [r1 , ..., rk , u1 , ..., um , v1 , ..., vn ] rulesw + 2(k + m) atoms, true P ,{r1 , ..., rk , u1 , ..., um } 'se {r1 , ..., rk , v1 , ..., vn }.(b.2) n = 0, sequence P = [r1 , ..., rk , u1 , ..., um ] rulesK atoms, true P ,{r1 , ..., rk , u1 , ..., um } 'se {r1 , ..., rk },K w + 2k w + 2k > 0, K = 1 otherwise.Proof: (a) (b) obvious. assume (b) true, show (a) holdswell. Suppose first n > 0. Suppose P = [r1 , ..., rk , u1 , ..., um , v1 , ..., vn ] sequencek + + n rules language L true P ,{r1 , ..., rk , u1 , ..., um } 6'se {r1 , ..., rk , v1 , ..., vn }.Thus intended model FL satisfies [P ], intended model FLsatisfies following sentence:^^(x)H1 (x) H2 (x) [(r)(r)],rP1rP2P1 = {r1 , ..., rk , u1 , ..., um }, P2 = {r1 , ..., rk , v1 , ..., vn }. noted Definition 2, also satisfy [P ]. Thus satisfies following sentence^^^^[P ] (x)H1 (x) H2 (x) {[(r)(r)] [(r)(r)]}, (10)rP1rP3rP2rP4P3 = {v1 , ..., vn }, P4 = {u1 , ..., um }.rule r, extended property (x, y) one rulemention quantifiers (r) equivalent x, y.[r]. Thus tuple Qrules,Vthere extended property rules mention quantifiersrQ (r) equivalent ~y .[Q], ~y tuple 2t variables.Thus437fiLin & Chentuple z~1 2(k + m) variables, tuple z~2 variables, extended property 1k + + n rules quantifiers, whose free variables z~1z~2 ;tuple z~3 2(k + n) variables, tuple v~4 variables, extended property 2k + + n rules quantifiers, whose free variablesz~3 z~4v~1 , v~2 , v~3 , v~4 common variables them, (10) equivalentfollowing sentence:{ x(H1 (x) H2 (x)) (z~1 z~2 1 z~3 z~4 2 )}[P ].Since assumed n, thus extended property 3 k + + nrules mention quantifiers function symbols, whose free variablesamong z~1 , z~2 , z~4 sentence equivalent following sentence:( x(H1 (x) H2 (x)) z~1 (z~2 , z~4 )3 )[P ].given form assumed theorem, tuple z~5 w + 2(k + m)variables, tuple z~6 variables, extended property k + + n rulesmention quantifiers, whose free variables among z~5 , z~6sentence equivalent (z~5 )(z~6 )[P ].Lemma 1, subset L0 L w + 2(k + m) atoms(z~5 )(z~6 ) holds P 0 , P 0 restriction P L0 .P 0 = [r10 , ..., rk0 , u01 , ..., u0m , v10 , ..., vn0 ],mean true P 0 , {r10 , ..., rk0 , u01 , ..., u0m } 6'se {r10 , ..., rk0 , v10 , ..., vn0 }.shows (b.1), (a).proof (b.2) (a) exactly except^^[(r)(r)]rP1rP2equivalent[^rP2^(r)(r)].rP1part (6) often proved help following theorem.Theorem 4 Let L1 L2 two languages, f function L1 L2 . P1 P2two programs L1 strongly equivalent, f (P1 ) f (P2 ) two programsL2 also strongly equivalent. f (P ) obtained P replacingatom p f (p).Proof: Theorem 1 fact propositional logic, tautology, ffunction L1 L2 , f () also tautology, f () formula obtainedreplacing atom p f (p).example using theorems section proving assertions form(6), see Section 5.1.438fiDiscovering Classes Strongly Equivalent Logic Programs5. Computer-Aided Theorem DiscoveryGiven k-m-n problem, strategy discovering theorems follows:1. Choose small language L;2. Generate possible triples({r1 , ..., rk }, {u1 , ..., um }, {v1 , ..., vn })(11)sets rules L {r1 , ..., rk , u1 , ..., um } 'se {r1 , ..., rk , v1 , ..., vn } L;3. Formulate conjecture k-m-n problem holds language L, i.e.condition true triple form (11) iff generated Step 2;4. Verify correctness conjecture general case.process may iterated. instance, conjecture formulated Step 3 mayfail generalize Step 4, either need formulate new conjecture startstep 1 using larger language.Ideally, would like process automatic. However, difficult automateSteps 3 4 - number possible patterns need examine order comegood conjecture Step 3 huge, general theoremenables us automate verification part Step 4. Theorem 3 enables usautomate proof sufficient part assertion (6) class formulas ,similar result necessary part - shall see below, Theorem 4 helpslot here, provide automated procedure. Nonetheless, computers playcrucial role steps, following report theorems discoveredusing procedure.5.1 0-1-0 Problemproblem asks given rule strongly equivalent empty set, thus alwaysdeleted program. following experimental result:Lemma 2 rule r mentions three distinct atoms, r 'se iff(Hdr Ngr ) Psr 6= .Using Theorem 4, show following result:Lemma 3 rule r form (1) r 'se (Hdr Ngr ) Psr 6=true, rule mentions three atoms.Proof: Suppose r 'se , Hdr Psr = , Psr Ngr = . Suppose L set atomsr, a, b, c three new atoms. Letp Hdrbp Psrf (p) =cotherwise439fiLin & ChenTheorem 4, also f (r) 'se . construction f , alsoHdf (r) Psf (r) = , Psf (r) Ngf (r) = , f (r) mentions three distinctatoms.Theorem 5 (The 0-1-0 problem) Lemma 2 holds general case, i.e. withoutrestriction number atoms r.Proof: notice condition Lemma 2, (Hdr Ngr ) Psr 6= , equivalentfollowing propertyx.(X1 (x) Z1 (x)) Y1 (x)true [r]. Thus part follows Theorem 3 Lemma 2.part follows Lemma 2 Lemma 3.part theorem already well-known, first proved Osorio et. al. (2001).part also proved recently Inoue Sakama (2004).discover anything new case, reassuring methodology works.notice need consider 0-n-0 problem n > 1,n, {r1 , ..., rn } strongly equivalent iff 1 n, {ri } stronglyequivalent .5.2 1-1-0 0-1-1 Problems1-1-0 problem asks rule always deleted presence another rule,0-1-1 problem asks rule always replaced another one. first solve1-1-0 problem, solution 0-1-1 problem come corollary.following experimental result 1-1-0 problem:Lemma 4 two rules r1 r2 mentions three atoms, {r1 , r2 }{r1 } strongly equivalent iff one following two conditions true:1. r2 'se .2. Psr1 Psr2 , Ngr1 Ngr2 , Hdr1 Hdr2 Ngr2 .Lemma 5 two rules r1 r2 {r1 , r2 } 'se {r2 }, nonetwo conditions Lemma 4 hold, two rules mention threeatoms.Proof: Suppose two rules r1 , r2 {r1 , r2 } 'se {r2 }, none twoconditions Lemma 4 hold. Let L set atoms r1 , r2 .Without loss generality, suppose a1 atom makes condition (2)Lemma 4 false. Psr2 \ {a1 } empty, let a2 atom it. Let L0 = {a1 , a2 , a3 },a3 new atom, f function L L0 following:= a1a1a2Psr2 \ {a1 }f (a) =a3otherwise440fiDiscovering Classes Strongly Equivalent Logic Programsclearly, f (r1 ) f (r2 ) mention three distinct atoms, Theorem 4,{f (r1 ), f (r2 )} 'se f (r1 ).show none two conditions Lemma 4 hold f (r1 ) f (r2 ) either.show first f (r2 ) 6'se . Theorem 5, need show= Psf (r2 ) (Hdf (r2 ) Ngf (r2 ) )empty. a1 S, construction f , a1 Psr2 (Hdr2 Ngr2 ), contradictionassumption r2 strongly equivalent . Similarly, a2 S,construction f , a2 Psr2 (Hdr2 Ngr2 ), contradiction assumptionr2 strongly equivalent . a3 cannot a3 cannot Psf (r2 ) .Thus must empty.show case Psf (r1 ) Psf (r2 ) , Ngf (r1 ) Ngf (r2 ) ,Hdf (r1 ) Hdf (r2 ) Ngf (r2 ) . assumption, a1 atom makes either Psr1 Psr2 ,Ngr1 Ngr2 , Hdr1 Hdr2 Ngr2 false. three cases here. Suppose a1 makesPsr1 Psr2 false, i.e. a1 Psr1 a1 6 Psr2 . construction f , alsoa1 Psf (r1 ) a1 6 Psf (r2 ) . two cases similar.Theorem 6 (The 1-1-0 problem) Lemma 4 holds general case, without restriction number atoms r1 r2 .Proof: condition Lemma 4 equivalent following property[x.(X2 (x) Z2 (x)) Y2 (x)]{[x.Y1 (x) Y2 (x)] [x.Z1 (x) Z2 (x)] [x.X1 (x) (X2 (x) Z2 (x))]}true [r1 , r2 ]. Thus part follows Theorem 3 Lemma 4, noticingproperty written x~y .Q required Theorem 3.part follows Lemma 4 Lemma 5.Thus rule r2 cannot deleted deleted presenceanother rule r1 , must case r2 redundant given r1 : body r2satisfied, body r1 satisfied well; furthermore, r2 entailentailed r1 (Hdr1 Hdr2 Ngr2 ).Osorio et al. (2001) proved {r1 , r2 } 'se r1 either Psr1 Ngr1 = Hdr1 Ngr2Psr1 Psr2 , Ngr1 Ngr2 , Hdr1 Hdr2 . recently, Eiter et al. (2004) showed{r1 , r2 } 'se r1 r1 s-implies r2 (Wang & Zhou, 2005), i.e. exists setNgr2 Hdr1 Hdr2 A, Ngr1 Ngr2 \ A, Psr1 Psr2 .one see, special cases part Theorem 6. resultactually general. instance, special cases apply{(c b, c), ( b, c)}{c b, c},one easily show two sets strongly equivalent using theorem.solution 1-1-0 problem, derive solution 0-1-1 problem.441fiLin & ChenTheorem 7 (The 0-1-1 problem) two rules r1 r2 , r1 'se r2 iff onefollowing two conditions true:1. r1 'se r2 'se .2. Psr1 = Psr2 , Ngr1 = Ngr2 , Hdr1 Ngr1 = Hdr2 Ngr2 .Proof: Theorem 1, easy see r1 'se r2 iff {r1 , r2 } 'se r1 {r1 , r2 } 'se r2 .Thus two rules r1 r2 always interchanged eitherdeleted (strongly equivalent empty set) body,consequences body true. instance, {a B, a} 'se { B, a}matter B is, two rules body, body true,consequence - contradiction. another example,{a; b a} 'se {b a},two rules body, and, body true, consequence,b.5.3 2-1-0, 0-2-1, 0-2-2 Problems2-1-0 problem asks rule deleted presence another two rules,0-2-1 problem asks two rules replaced single rule, 0-2-2 problem askstwo rules replaced another two rules. Similar previous subsection,solution 0-2-1 0-2-2 problems follow solution 2-1-0 problem.experiment 2-1-0 problem difficult turned out,consider language six atoms case. principle, given language L,every subset L Hd, Ps, Ng rule. Thus size L six,principle (26 )3 1 = 262, 143 possible rules, 262, 1433 triples them. However,cut numbers significantly results already proved.First, consider rules common elementstwo sets {Hd, Ps, Ng}: either Hd Ps Ps Ng common element,Theorem 5, rule deleted; Hd Ng common elements, accordingTheorem 7, obtain strongly equivalent rule deleting common elements Hd.following, call rules canonical, is, rule r canonicalHdr Psr = Hdr Ngr = Psr Ngr = .Secondly, consider isomorphic rules: one-to-one ontofunction L L maps {r1 , r2 , r3 } {r10 , r20 , r30 }, two sets rulesessentially except names atoms them.Thus considering canonical rules using certain normal form triplesrules avoids isomorphic rules, ended roughly 120 million triples rulesconsider verifying following result, took 10 hours Solaris serverconsisting 8 Sun Ultra-SPARC III 900Mhz CPUs 8GB RAM.details experiment 2-1-0 problem, please refer (Chen, Lin, & Li,2005).442fiDiscovering Classes Strongly Equivalent Logic ProgramsLemma 6 three canonical rules r1 , r2 r3 mention six atoms,{r1 , r2 , r3 } 'se {r1 , r2 } iff one following three conditions true:1. {r1 , r3 } 'se r1 .2. {r2 , r3 } 'se r2 .3. atom p that:3.1 p (Psr1 Psr2 ) (Hdr1 Hdr2 Ngr1 Ngr2 )3.2 Hdri \ {p} Hdr3 Ngr3 Psri \ {p} Psr3 Ngri \ {p} Ngr3 ,= 1, 23.3 p Psr1 Ngr2 , Hdr1 Hdr3 =3.4 p Psr2 Ngr1 , Hdr2 Hdr3 =following lemma reason need consider language six atomsproblem.Lemma 7 three canonical rules r1 ,r2 r3 {r1 , r2 , r3 } 'se {r1 , r2 },none three conditions Lemma 6 hold, three rulesmention six atoms.Proof: proof lemma tedious consider several cases. Considerfollowing statements three canonical rules r1 , r2 , r3 :(I) {r1 , r2 , r3 } 'se {r1 , r2 }.(II) {r1 , r3 } 6'se {r1 }, i.e. Psr1 6 Psr3 Ngr1 6 Ngr3 Hdr1 Ngr1 6 Hdr3 Ngr3(III) {r2 , r3 } 6'se {r2 }, i.e. Psr2 6 Psr3 Ngr2 6 Ngr3 Hdr2 Ngr2 6 Hdr3 Ngr3(IV) (Psr1 Psr2 ) (Hdr1 Hdr2 Ngr1 Ngr2 ) =(V) atom p set (Psr1 Psr2 ) (Hdr1 Hdr2 Ngr1 Ngr2 ), anotherdifferent atom q one following three conditions true:1. q Hdr1 Ngr1 q 6 Hdr3 Ngr3 .2. q Psr1 q 6 Psr3 .3. q Ngr1 q 6 Ngr3 .Notice negation condition (3.2) Lemma 6.(VI) Hdr1 Hdr3 6 Ngr3 , atom p Psr1 Ngr2 = 1, 2,Hdri \ {p} Hdr3 Ngr3 , Psri \ {p} Psr3 , Ngri \ {p} Ngr3 .Since r1 r2 symmetric conditions Lemma 6, prove lemma, needprove following three assertions:(a) three canonical rules r1 , r2 , r3 satisfy (I)-(IV), threecanonical rules r10 , r20 , r30 mention six atoms, satisfy (I)-(IV) well.443fiLin & Chen(b) three canonical rules r1 , r2 , r3 satisfy (I)-(III)(V),three canonical rules r10 , r20 , r30 mention six atoms, satisfy (I)-(III)(V)well.(c) three canonical rules r1 , r2 , r3 satisfy (I)-(III)(VI),three canonical rules r10 , r20 , r30 mention six atoms, satisfy (I)(III)(VI) well.prove three assertions one one.(a) Let a1 , a2 two atoms make (II) (III) true. (Psr3 (Psr1 Psr2 ))\{a1 , a2 }empty, let a3 atom it. Psr3 \(Psr1 Psr2 {a1 , a2 }) empty, let a4atom it. (Psr1 Psr2 )\(Psr3 {a1 , a2 }) empty, let a5 atom it.Finally let a6 new atom different a1 a5 , L0 = {a1 , a2 , a3 , a4 , a5 , a6 }.Let f function L L0 defined following:a1= a1= a22a3(Psr3 (Psr1 Psr2 )) \ {a1 , a2 }f (a) =Psr3 \ (Psr1 Psr2 {a1 , a2 })4(Psr1 Psr2 ) \ (Psr3 {a1 , a2 })5a6otherwise1 3, let ri0 follows:Psri0 = Psf (ri ) , Ngri0 = Ngf (ri ) , Hdri0 = Hdf (ri ) \ Ngf (ri ) .(12)1 3, ri0 canonical rule, ri0 'se f (ri ). this,need show f (ri ) 6'se 1 3. see this, noticedefinition f , atoms a1 a2 Psr3 mapped {a3 , a4 },atoms a1 a2 Hdr3 Ngr3 mapped {a5 , a6 }. ThusPsf (r3 ) (Hdf (r3 ) Ngf (r3 ) ) = . Theorem 5, f (r3 ) 6'se . f (r1 ) 6'sef (r2 ) 6'se , (II) (III) hold f (r1 ), f (r2 ), f (r3 ) definitionf .(I) holds r10 , r20 , r30 . Theorem 4,{f (r1 ), f (r2 ), f (r3 )} 6'se {f (r1 ), f (r2 )},1 3, ri0 'se f (ri ).(II) (III) hold r10 , r20 , r30 . mentioned, definition f , (II)(III) hold f (r1 ), f (r2 ), f (r3 ).(IV) holds r10 , r20 , r30 . Again, need show (IV) holdsf (r1 ), f (r2 ), f (r3 ). see this, notice atoms a1 a2Psr1 Psr2 mapped {a3 , a5 }, atoms a1 a2Hdr1 Hdr2 Ngr1 Ngr2 mapped {a4 , a6 }.444fiDiscovering Classes Strongly Equivalent Logic Programs(b) let a1 , a2 two atoms make (II) (III) true. Let p, q two witnessatoms (V). P os(r3 ) \ {a1 , a2 , p, q} empty, let a3 atom it. Let a4new atom, L0 = {a1 , a2 , a3 , a4 , p, q}. Define f follows:= a1a1a2= a2pa=pf (a) =qa=qPsr3 \ {a1 , a2 , p, q}3a4otherwiseDefine ri0 (12) well 1 3.1 3, ri0 canonical rule, ri0 'se f (ri ). seenway (a) above.Theorem 4, {f (r1 ), f (r2 ), f (r3 )} 'se {f (r1 ), f (r2 )}, thus{r10 , r20 , r30 } 'se {r10 , r20 }.(I) holds r10 , r20 , r30 .definition f , (II) (III) hold f (r1 ), f (r2 ), f (r3 ), thus holdr10 , r20 , r30 well.definition f , (V) holds f (r1 ), f (r2 ), f (r3 ): atomp set (Psf (r1 ) Psf (r2 ) ) (Hdf (r1 ) Hdf (r2 ) Ngf (r1 ) Ngf (r2 ) ), anotherdifferent atom q one following three conditions true:1. q Hdf (r1 ) Ngf (r1 ) q 6 Hdf (r3 ) Ngf (r3 ) .2. q Psf (r1 ) q 6 Psf (r3 ) .3. q Ngf (r1 ) q 6 Ngf (r3 ) .(V) holds r10 , r20 , r30 well 1 3,Psri0 = Psf (ri ) , Ngri0 = Ngf (ri ) , Hdri0 Ngri0 = Hdf (ri ) Ngf (ri ) .(c) Let a1 , a2 two atoms make (II) (III) true. Let p witness atom(VI), let q Hdr1 Hdr3 q 6 Ngr3 . P os(r3 ) \ {a1 , a2 , p, q} empty, leta3 atom it. Let a4 new atom, Let L0 = {a1 , a2 , a3 , a4 , p, q}, Define ffollows:a1= a1= a22pa=pf (a) =qa=qPsr3 \ {a1 , a2 , p, q}3a4otherwisedefine ri0 (12) well 1 3.1 3, ri0 canonical rule, ri0 'se f (ri ). seenway (a) above.445fiLin & ChenTheorem 4, {f (r1 ), f (r2 ), f (r3 )} 'se {f (r1 ), f (r2 )}, thus{r10 , r20 , r30 } 'se {r10 , r20 }.(I) holds r10 , r20 , r30 .definition f , (II) (III) hold f (r1 ), f (r2 ), f (r3 ), thushold r10 , r20 , r30 well.definition f , (VI) holds f (r1 ), f (r2 ), f (r3 ): Hdf (r1 ) Hdf (r3 ) 6Ngf (r3 ) , atom p Psf (r1 ) Ngf (r2 ) = 1, 2, Hdf (ri ) \{p} Hdf (r3 ) Ngf (r3 ) , Psf (ri ) \ {p} Psf (r3 ) , Ngf (ri ) \ {p} Ngf (r3 ) . (VI)holds r10 , r20 , r30 wellPsri0 = Psf (ri ) , Ngri0 = Ngf (ri ) , Hdri0 Hdf (ri ) .Theorem 8 (The 2-1-0 problem) Lemma 6 holds general case, without restriction number atoms r1 , r2 , r3 .Proof: assertion r1 , r2 , r3 canonical rules satisfy one threeconditions Lemma 6 equivalent following property[x.(((X1 (x) Y1 (x))) ((X1 (x) Z1 (x))) ((Y1 (x) Z1 (x))))][x.(((X2 (x) Y2 (x))) ((X2 (x) Z2 (x))) ((Y2 (x) Z2 (x))))][x.(((X3 (x) Y3 (x))) ((X3 (x) Z3 (x))) ((Y3 (x) Z3 (x))))]{[(x.Y1 (x) Y3 (x)) (x.Z1 (x) Z3 (x)) (x.X1 (x) (X3 (x) Z3 (x)))][(x.Y2 (x) Y3 (x)) (x.Z2 (x) Z3 (x)) (x.X2 (x) (X3 (x) Z3 (x)))][x.CON 1(x) CON 2(x) CON 3(x) CON 4(x)]}true [r1 , r2 , r3 ], CON 1(x) stands(Y1 (x) Y2 (x)) (X1 (x) X2 (x) Z1 (x) Z2 (x))CON 2(x)y.(x 6= y) [(X1 (y) (X3 (y) Z3 (y))) (Y1 (y) Y3 (y)) (Z1 (y) Z3 (y))(X2 (y) (X3 (y) Z3 (y))) (Y2 (y) Y3 (y)) (Z2 (y) Z3 (y))]CON 3(x)Y1 (x) Z2 (x) y.((X1 (y) X3 (y))),CON 4(x)Y2 (x) Z1 (x) y.((X2 (y) X3 (y))).Thus part follows Theorem 3 Lemma 6, noticingproperty written x~y .Q required Theorem 3. part followsLemma 6 Lemma 7.446fiDiscovering Classes Strongly Equivalent Logic Programsconditions Lemma 6 (Theorem 8) rather complex, reasondifficult automate Step 3 procedure beginning section.conditions capture possible cases r3 subsumed r1 r2 , difficultdescribe concisely words. give examples.Consider following three rules:r1 : (a2 a1 )r2 : (a3 a1 )r3 : (a3 a2 ).{r1 , r2 , r3 } 'se {r1 , r2 } condition (4) Lemma 6 holds.However, change r3 r30 : a2 a3 , P1 = {r1 , r2 , r30 } P2 = {r1 , r2 }strongly equivalent: one could check condition (4.3) Lemma 6 hold,indeed, P2 {a1 a2 } unique answer set {a3 }, P1 {a1 a2 } twoanswer sets {a3 } {a1 , a2 }.also easy show Theorem 8 a3 a2 subsumed{(a1 ; a2 ; a3 ), (a2 ; a3 a1 )},a2 ; a3 subsumed{(a2 a1 ), (a3 a1 )}.results have, following theorem yield solution 0-2-1problem.Theorem 9 (the 0-2-1 problem) three rules r1 , r2 r3 , {r1 , r2 } {r3 }strongly equivalent iff following three conditions true:1. {r1 , r2 , r3 } 'se {r1 , r2 }.2. {r1 , r3 } 'se {r3 }.3. {r2 , r3 } 'se {r3 }.example,{(a2 a1 , a3 ), (a1 ; a2 a3 )} 'se {a2 a3 }.{( a2 , a3 ), ( a3 , a2 )} 'se { a3 },{(a1 a2 , a3 ), (a1 a3 , a2 )} 6'se {a1 a3 }.Similarly, following theoremTheorem 10 (the 0-2-2 problem) four rules r1 , r2 , r3 , r4 , {r1 , r2 } {r3 , r4 }strongly equivalent iff following four conditions true:447fiLin & Chen1. {r1 , r2 , r3 } 'se {r1 , r2 }.2. {r1 , r2 , r4 } 'se {r1 , r2 }.3. {r3 , r4 , r1 } 'se {r3 , r4 }.4. {r3 , r4 , r2 } 'se {r3 , r4 }.6. Program Simplificationmentioned one possible use notion strongly equivalent logic programssimplifying logic programs: P 'se Q, Q simpler P ,replace P program contains Q.answer set programming systems perform program simplifications. However,Smodels (Niemela et al., 2000) stand-alone front-end called lparseused ground simplify given logic program. seems lparse simplifies groundedlogic program computing first well-founded model. not, however, performprogram simplification using notion strong equivalence. instance, lparse-1.0.13,current version lparse, nothing following set rules:{(a b), (b a), (a a)}. replace first rule followingprogram {(a a), (a b), (b a)} constraint a.unlikely anyone would intentionally writing rules like b a, a.type rules arise result grounding rules variables.instance, following typical recursive rule used logic programming encodingHamiltonian Circuit problem (Niemela, 1999; Marek & Truszczynski, 1999):reached(X) arc(Y, X), hc(Y, X), reached(Y ).instantiated graph cyclic arcs like arc(a, a), rule generates cyclic rulesform reached(X) hc(X, X), reached(X). Unless deleted explicitly, rulesslow many systems, especially based SAT. instance, none graphstested using ASSAT self-cycles consisting arc node (Lin & Zhao,2004). cycles included, ASSAT would run significantly longer.thus useful consider using results program simplification.Indeed, transformation rules deleting contain common elementsheads positive bodies proposed (Brass & Dix, 1999), studiedperspective strong equivalence (Osorio et al., 2001; Eiter et al., 2004). resultsadd new transformation rules. instance, Theorem 7, deleteelements head rule also appear negation-as-failure part rule.Theorems 6, 8, 9 also used define new transformation rules.7. Concluding Remarks Future WorkDonald Knuth, Forward (Petkovsek et al., 1996), saidScience understand well enough explain computer. Arteverything else do. ...Science advances whenever Art becomes Science.448fiDiscovering Classes Strongly Equivalent Logic Programsstate Art advances too, people always leap newterritory understood old.hope work, one step closer making discovering classes stronglyequivalent logic programs Science.mentioned methodology used paper similar (Lin,2004). cases, plausible conjectures generated testing domainssmall sizes, general theorems proved aid verification conjecturesgeneral case. However, plausible conjectures generated automatically(Lin, 2004), done manually here. verifications conjectures(Lin, 2004) done automatically well, done semi-automatically here.Overcoming two weaknesses focus future work. Specifically, wouldlike make Step 3 procedure Section 5 automatic, prove theorem similarTheorem 3 automate proofs parts theorems like Theorems 5 8, way Theorem 3 makes proofs parts theoremsautomatic. way, would able discover interesting theorems area,easily!Acknowledgmentsextended abstract paper appeared Proceedings IJCAI2005. thank YanZhang comments earlier version paper. also thank anonymousreviewers useful comments, especially one pointing errorLemma 4 earlier version paper. work supported partResearch Grants Council Hong Kong Competitive Earmarked Research GrantHKUST6170/04E. Part second authors work done student SunYat-Sen University, Guangzhou, China, visiting scholar Department ComputerScience Engineering, Hong Kong University Science Technology, Hong Kong.ReferencesBrass, S., & Dix, J. (1999). Semantics (disjunctive) logic programs based partialevaluation. Journal Logic Programming, 40 (1), 146.Chen, Y., Lin, F., & Li, L. (2005). SELP - system studying strong equivalencelogic programs. Proceedings 8th International Conference LogicProgramming Nonmonotonic Reasoning(LPNMR 2005), pp. 442446.Eiter, T., Fink, M., Tompits, H., & Woltran, S. (2004). Simplifying logic programsuniform strong equivalence. Proceedings 7th International ConferenceLogic Programming Nonmonotonic Reasoning(LPNMR 2004), pp. 8799.Erdem, E., Lifschitz, V., Nakhleh, L., & Ringe, D. (2003). Reconstructing evolutionaryhistory indo-european languages using answer set programming. Proceedings5th International Symposium Practical Aspects Declarative Languages(PADL2003), pp. 160176.449fiLin & ChenGelfond, M., & Lifschitz, V. (1988). stable model semantics logic programming.Proceedings 5th International Conference Symposium Logic Programming(ICLP/SLP), pp. 10701080.Gelfond, M., & Lifschitz, V. (1991). Classical negation logic programs disjunctivedatabases. New Generation Computing, 9 (3/4), 365386.Inoue, K., & Sakama, C. (2004). Equivalence logic programs updates. Proceedings 9th European Conference Logics Artificial Intelligence(JELIA), pp.174186.Lenat, D. B. (1979). automated scientific theory formation: case study usingprogram. Machine Intelligence 9, pp. 251283. Jean Hayes, Donald Michie, L.I. Mikulich, eds. Ellis Horwood.Leone, N., Pfeifer, G., Faber, W., Eiter, T., Gottlob, G., Perri, S., & Scarcello, F. (2006).DLV system knowledge representation reasoning. ACM TransactionsComputational Logic, 7 (3).Lierler, Y., & Maratea, M. (2004). Cmodels-2: SAT-based answer set solver enhancednon-tight programs. Proceedings 7th International Conference LogicProgramming Nonmonotonic Reasoning(LPNMR 2004), pp. 346350.Lifschitz, V. (1999). Action languages, answer sets planning. Logic ProgrammingParadigm: 25-Year Perspective. K.R. Apt, V.W. Marek, M. Truszczynski, D.S.Warren, eds, Springer-Verlag.Lifschitz, V., Pearce, D., & Valverde, A. (2001). Strongly equivalent logic programs. ACMTransactions Computational Logic, 2 (4), 526541.Lin, F. (2002). Reducing strong equivalence logic programs entailment classicalpropositional logic. Proceedings 8th International Conference PrinciplesKnowledge Representation Reasoning(KR2002), pp. 170176.Lin, F. (2004). Discovering state invariants. Proceedings 9th International Conference Principles Knowledge Representation Reasoning(KR2004), pp. 536544.Lin, F., & Zhao, Y. (2004). ASSAT: computing answer sets logic program sat solvers.Artificial Intelligence, 157 (1-2), 115137.Marek, V. W., & Truszczynski, M. (1999). Stable logic programming - alternative logicprogramming paradigm. Logic Programming Paradigm: 25-Year Perspective.K.R. Apt, V.W. Marek, M. Truszczynski, D.S. Warren, eds, Springer-Verlag.Niemela, I., Simons, P., & Syrjanen, T. (2000).Smodels: system answerset programming. Proceedings 8th International Workshop NonMonotonic Reasoning. Breckenridge, Colorado, USA. (CoRR: arXiv:cs.AI/0003033)http://www.tcs.hut.fi/Software/smodels/.Niemela, I. (1999). Logic programs stable model semantics constraint programmingparadigm. Annals Mathematics Artificial Intelligence, 25 (3-4), 241273.450fiDiscovering Classes Strongly Equivalent Logic ProgramsNogueira, M., Balduccini, M., Gelfond, M., Watson, R., & Barry, M. (2001). A-Prologdecision support system space shuttle. Proceedings 3rd InternationalSymposium Practical Aspects Declarative Languages(PADL 2001), pp. 169183.Osorio, M., Navarro, J. A., & Arrazola, J. (2001). Equivalence answer set programming.Selected Papers 11th International Workshop Logic Based Program SynthesisTransformation(LOPSTR 2001), pp. 5775.Pearce, D., Tompits, H., & Woltran, S. (2001). Encodings equilibrium logic logicprograms nested expressions. Proceedings 10th Portuguese ConferenceArtificial Intelligence(EPIA 2001), pp. 306320.Petkovsek, M., Wilf, H. S., & Zeilberger, D. (1996). = B. Wellesley, Mass. : K Peters.Turner, H. (2001). Strong equivalence logic programs default theories (made easy).Proceedings 6th International Conference Logic Programming Nonmonotonic Reasoning(LPNMR 2001), pp. 8192.Turner, H. (2003). Strong equivalence made easy: nested expressions weight constraints.Theory Practice Logic Programming, 3 (4-5), 609622.Wang, K., & Zhou, L. (2005). Comparisons computation well-founded semanticsdisjunctive logic programs. ACM Transactions Computational Logic, 6 (2),295327.451fiJournal Artificial Intelligence Research 28 (2007) 267-297Submitted 05/06; published 03/07Anytime Heuristic SearchEric A. Hansenhansen@cse.msstate.eduDepartment Computer Science EngineeringMississippi State UniversityMississippi State, MS 39762 USARong Zhourzhou@parc.comPalo Alto Research Center3333 Coyote Hill RoadPalo Alto, CA 94304 USAAbstractdescribe convert heuristic search algorithm A* anytime algorithmfinds sequence improved solutions eventually converges optimal solution.approach adopt uses weighted heuristic search find approximate solutionquickly, continues weighted search find improved solutions wellimprove bound suboptimality current solution. time availablesolve search problem limited uncertain, creates anytime heuristic searchalgorithm allows flexible tradeoff search time solution quality.analyze properties resulting Anytime A* algorithm, consider performancethree domains; sliding-tile puzzles, STRIPS planning, multiple sequence alignment.illustrate generality approach, also describe transform memoryefficient search algorithm Recursive Best-First Search (RBFS) anytime algorithm.1. Introductionwidely-used framework problem-solving artificial intelligence heuristic searchminimum-cost solution path graph. large complex problems, finding optimalsolution path take long time suboptimal solution found quicklymay useful. Various techniques modifying heuristic search algorithmA* allow tradeoff solution quality search time studied. Oneapproach weight admissible evaluation function make non-admissible (Pohl,1970a, 1970b; Pearl, 1984). substantial literature weighted heuristic search,assumption search stops soon first solution found. Analysisfocused characterizing tradeoff time takes find first solutionquality. example, shown cost first solution foundexceed optimal cost factor greater 1+, depends weight (Pearl,1984; Davis, Bramanti-Gregor, & Wang, 1988). also empirical studiestradeoff search time quality first solution found (Gasching, 1979;Korf, 1993).starting point paper simple observation reasonstop non-admissible search first solution found. continuing search,sequence improved solutions found eventually converges optimalsolution. possibility continuing non-admissible A* search first solutionc2007AI Access Foundation. rights reserved.fiHansen & Zhoufound suggested Harris (1974), although consider weighted heuristicsearch somewhat related approach called bandwidth heuristic search.aware mention idea proposed strategy creatingAnytime A* algorithm (Hansen, Zilberstein, & Danilchenko, 1997; Zhou & Hansen, 2002).paper, discuss strategy length evaluate analytically empirically.refer strategy anytime heuristic search. Anytime algorithms usefulproblem-solving varying uncertain time constraints solutionready whenever stopped (with possible exception initial time periodfirst solution found) quality solution improves additionalcomputation time (Zilberstein, 1996). heuristic search many applications,general method transforming heuristic search algorithm A* anytimealgorithm could prove useful many domains good anytime algorithmsotherwise available.paper organized follows. Section 2 presents approach transformingweighted heuristic search algorithm anytime algorithm, shows transformWeighted A* Anytime A* algorithm. illustrate generality approach,Section 3 considers Recursive Best-First Search (RBFS), memory-efficient versionA*, shows transform Weighted RBFS Anytime RBFS algorithm.Section 4 discusses related work, including related approach creating Anytime A*algorithm recently proposed.2. Anytime A*begin section brief review standard A* Weighted A* algorithms.describe transform Weighted A* Anytime A* algorithm. analyzetheoretical properties resulting algorithm evaluate performance threetest domains; sliding-tile puzzles, STRIPS planning, multiple sequence alignment.2.1 A*A* algorithm (Hart, Nilsson, & Raphael, 1968) uses two lists, Open list Closedlist, manage systematic search minimum-cost path start node goalnode graph. Initially, Open list contains start node Closed list empty.cycle algorithm, promising open node expanded, movedClosed list, successor nodes inserted Open list. Thus, Closed listcontains nodes expanded, generating successor nodes,Open list contains nodes generated, yet expanded. searchterminates goal node selected expansion. solution path extractedtracing node pointers backwards goal node start node.order nodes expanded determined node evaluation functionf (n) = g(n) + h(n), g(n) cost best path currently known startnode node n, h(n) heuristic estimate h (n), cost best path ngoal node. behavior A* depends large part heuristic h(n) guidessearch. h(n) admissible, is, never overestimates h (n), nodesexpanded order f (n), first goal node selected expansion guaranteedoptimal. heuristic said consistent h(n) c(n, n0 ) + h(n0 ) n n0 ,268fiAnytime Heuristic Searchc(n, n0 ) cost edge node n node n0 . h(n) consistent nodesexpanded order f (n), g-cost node guaranteed optimalnode selected expansion, node never expanded once. Noteconsistency implies admissibility, non-admissibility implies inconsistency.h(n) consistent, possible A* find better path nodenode expanded. case, improved g-cost node needs propagateddescendants. way A* usually reopening nodes, is,moving node Closed list Open list g-cost improved.node eventually reexpanded, improved g-cost propagated successor nodes,may need reopened also. result, node expanded multipletimes. Although rarely used practice, various techniques introduced boundworst-case number node reexpansions (Bagchi & Mahanti, 1983; Bagchi & Srimani,1985).2.2 Weighted A*difficult search problems, A* may take long find optimal solution,approximate solution found relatively quickly useful. BeginningPohl (1970a, 1970b), many researchers explored effect weighting terms g(n)h(n) node evaluation function differently, order allow A* find boundedoptimal solution less computational effort. approach, called Weighted A*(WA*), node evaluation function defined f 0 (n) = g(n) + w h(n),weight w 1.0 parameter set user. Sometimes node evaluation functiondefined f 0 (n) = (1w0 )g(n)+w0 h(n), equivalent f 0 (n) = g(n)+wh(n)w. use notation f 0 (n) distinguish weighted evaluation functionw0 = 1+wunweighted f (n). w > 1.0, search admissible (first) solutionfound may optimal, although usually found much faster. h(n) admissible,suboptimality solution found weighted heuristic search bounded: solutioncost cannot greater optimal cost factor w (Davis et al., 1988).solution said -admissible = w 1.0. weighted heuristic acceleratessearch solution makes nodes closer goal seem attractive, givingsearch depth-first aspect implicitly adjusting tradeoff search effortsolution quality. Weighted heuristic search effective search problemsclose-to-optimal solutions, often find close-to-optimal solution small fractiontime takes find optimal solution.variations weighted heuristic search studied. approach calleddynamic weighting adjusts weight depth search (Pohl, 1973; Koll &Kaindl, 1992). Another approach uses weighted heuristic identify subset open nodesexpanded without loss -admissibility; subset, selects nodeexpand next based criteria (Pearl & Kim, 1982; Davis et al., 1988). Weightedheuristic search used search algorithms besides A*, including memoryefficient versions A* IDA* RBFS (Korf, 1993), well Learning RealTime A* (LRTA*) (Shimbo & Ishida, 2003), heuristic search algorithms AND/ORgraphs (Chakrabarti, Ghosh, & DeSarkar, 1988; Hansen & Zilberstein, 2001).269fiHansen & Zhou2.3 Anytime Weighted A*consider Weighted A* transformed anytime algorithmfinds sequence improved solutions eventually converges optimal solution.transformation example general approach transforming searchalgorithm explores nodes best-first order, A*, anytime algorithm.approach consists following three changes.1. non-admissible evaluation function, f 0 (n) = g(n) + h0 (n), heuristic h0 (n)admissible, used select nodes expansion order allows good,possibly suboptimal, solutions found quickly.2. search continues solution found, order find improved solutions.3. admissible evaluation function (i.e., lower-bound function), f (n) = g(n) + h(n),h(n) admissible, used together upper bound optimal solutioncost (given cost best solution found far), order prune searchspace detect convergence optimal solution.paper, use weighted heuristic create non-admissible evaluation function guides search. is, assume admissible heuristic h(n),use create weighted heuristic h0 (n) = w h(n). three-step approachcreating anytime heuristic search algorithm use non-admissible heuristichelps A* find approximate solution quickly; limited weighted heuristicsearch. general approach used transform A* anytime algorithm,call resulting algorithm Anytime A*. special case non-admissibleevaluation function weighted heuristic, call algorithm Anytime Weighted A*Anytime WA*.Algorithm 1 shows high-level pseudocode Anytime WA*. (Some detailsunaffected transformation WA* anytime algorithm, extractingsolution path, omitted.) Note implementation Anytime A* tests whethernode goal node soon node generated selectedexpansion, A*, since improve currently available solution quickly.Besides continuing search first solution found, Anytime WA* uses boundsprune search space. sequence improved solutions found Anytime WA*provides sequence improved upper bounds optimal solution cost. Anytime WA*tests whether f -cost newly-generated node less current upper bound.not, node inserted Open list since cannot lead improved solution.inserting suboptimal nodes Open list, memory requirementsalgorithm reduced.1 time improved solution found upper bounddecreases, possible nodes already Open list may f -cost equalgreater new upper bound. Although nodes could immediately1. possibility using bounds optimal solution cost reduce number nodes storedOpen list suggested least twice literature. Harris (1974, p. 219) pointsdone bandwidth heuristic used guide search, heuristicerror bounded additive constant. heuristics may easy obtain, however. IkedaImai (1994) describe Enhanced A* algorithm uses previously-computed upper bound limitnumber nodes stored Open list. compare Enhanced A* Anytime WA* Section 2.4.3.270fiAnytime Heuristic SearchAlgorithm 1: Anytime-WA*Input: start node startOutput: Best solution found error boundbeging(start) 0, f (start) h(start), f 0 (start) w h(start)OP EN {start}, CLOSED , incumbent nilOP EN 6= interruptedn arg minxOP EN f 0 (x)OP EN OP EN \ {n}incumbent = nil f (n) < f (incumbent)CLOSED CLOSED {n}foreach ni Successors(n) g(n) + c(n, ni ) + h(ni ) < f (incumbent)ni goal nodef (ni ) g(ni ) g(n) + c(n, ni ), incumbent nielse ni OP EN CLOSED g(ni ) > g(n) + c(n, ni )g(ni ) g(n) + c(n, ni ), f (ni ) g(ni ) + h(ni ), f 0 (ni ) g(ni ) + w h(ni )ni CLOSEDOP EN OP EN {ni }CLOSED CLOSED \ {ni }elseg(ni ) g(n) + c(n, ni ), f (ni ) g(ni ) + h(ni ), f 0 (ni ) g(ni ) + w h(ni )OP EN OP EN {ni }OP EN = error 0else error f (incumbent) minxOP EN f (x)output incumbent solution error boundendremoved Open list, incurs overhead searching Open list every timeupper bound decreases, step included pseudocode. (Of course,Anytime WA* close running memory, overhead searchingOpen list sub-optimal nodes deleted might justified needrecover memory.) algorithm shown pseudocode simply tests f -costnode expanding it. f -cost equal greater current upper bound,node expanded. implies related test convergence optimal solution:Open list empty, currently available solution must optimal.Anytime WA* requires node expansions A* converge optimal solution, two reasons. First, use weighted heuristic allows expand distinctnodes A*. Second, weighted heuristic inconsistent means possiblenode higher-than-optimal g-cost expanded. better pathnode later found, node reinserted Open list improvedg-cost propagated descendants node reexpanded. meansAnytime WA* expand node multiple times.considering empirical performance Anytime WA*, discuss two importanttheoretical properties algorithm: convergence optimal solution, boundsuboptimality currently available solution.271fiHansen & Zhou2.3.1 Convergenceadmissible evaluation function, f (n), gives lower bound cost solutionpath extension current best path node n. Let incumbent denotegoal node corresponding best solution found far. f (incumbent) upperbound cost optimal solution. Clearly, reason expand nodef -cost (i.e., lower bound) greater equal current upper bound,f (incumbent), since cannot lead improved solution. Thus followingconvergence test Anytime WA*, and, generally, anytime version A*:best solution found far optimal unexpanded nodes search frontier(i.e., Open list) f -cost less f (incumbent).prove following theorem standard assumptions search graphfinite branching factor minimal edge cost c > 0. also assume solutionexists h(n) 0 nodes n.Theorem 1 Anytime WA* always terminates last solution finds optimal.Proof: First show algorithm cannot terminate optimal solutionfound. Suppose algorithm terminates finding optimal solutioncost f . sequence upper bounds used execution algorithmb0 , b1 , ...., bk , b0 = (the upper bound solution found), b1 costfirst solution found, bk cost last solution found. know that,b0 > b1 > ... > bk > f ,last inequality holds assumption algorithm terminatesfinding optimal solution, is, suboptimal solution.consider optimal path leading initial state goal state.assumption optimal solution path found, must node n alongpath generated expanded. possible g(n) + h(n) bk .admissibility h, knowg(n) + h(n) f ,therefore: g(n) + h(n) f < bi .contradiction, follows algorithm cannot terminate optimalsolution found.Next show algorithm always terminates. already provedoptimal solution found, Open list must include node ng(n) + h(n) f . Hence,f 0 (n) = g(n) + w h(n) w (g(n) + h(n)) w f .establishes upper bound f -cost node expanded AnytimeWA* optimal solution found. finite number nodesf (n) w f , algorithm must run bounded number steps optimalsolution found. optimal solution found, algorithm expandnode f -cost greater equal f . number nodesf (n) f also finite, algorithm must eventually terminate.272fiAnytime Heuristic Search2.3.2 Error boundimportant property approach creating Anytime A* algorithmrefines upper lower bound optimal cost solution. upper boundf -cost best solution found far, decreased improved solutionfound. lower bound least f -cost currently open node, increasednodes smallest f -cost expanded.Although obvious cost best solution found far upper bound,claim least f -cost currently open node lower bound optimalsolution cost requires justification. First note currently available solutionoptimal, optimal solution path must pass currently open node.Although f -cost open node necessarily lower bound best solutionpath passes node, since g-cost open node may suboptimal,lower bound cost solution path extension current pathnode. Since improved path open node (resulting improved g-cost)must extension already-found path another currently open node lowerf -cost, least f -cost currently open node must lower bound costoptimal solution path. words, least f -cost currently open nodelower bound optimal solution cost reason lower boundoptimal solution cost branch-and-bound tree search.upper lower bounds approach search progressesmeet upon convergence optimal solution. (Figure 3 shows examplebounds approach other.) optimal solution found, bound differencecost currently available solution optimal solution cost givendifference upper lower bounds. error bound expressedf (incumbent)approximation ratio, f (incumbent), f L denotes lowerffLbound optimal solution cost, f (incumbent) denotes upper bound, f denotesoptimal solution cost. Thus, Anytime A* viewed anytime algorithm tworespects. improves solution time, also improves bound suboptimalitycurrently available solution.2.4 Performance evaluationnext consider empirical performance Anytime WA* solving range searchproblems. effectiveness depends weight used, weight affects searchperformance depends characteristics problem heuristic. setweight based combination knowledge search problem trial error.use weight start end search, advantage simplicity.also shows technique simplest form leads good performance.possible change weight search, weight adjustment togethermethods search control potential improve performance further. postponediscussion Section 4.1 discuss variant Anytime A* recentlyproposed.search problems unit edge costs, many nodes f -cost tiebreaking rule used systematic search algorithm A* significant effectnumber nodes actually expanded. well-known A* achieves best performance273fiHansen & ZhouFigure 1: (a) Performance profiles Anytime WA* using three different weights, averagedinstances Eight Puzzle. (b) Average number nodes storedexpanded Anytime WA* instances Eight Puzzle.breaks ties favor nodes least h-cost. experimentalcomparisons reported paper, A* uses tie-breaking rule. note AnytimeWA* achieve similar tie-breaking behavior without applying ruleusing even small weight effect breaking ties favor nodesleast h-cost. Moreover, Anytime WA* usually finds optimal solution proveoptimal (that is, expands nodes f -cost less optimalf -cost). result, usually expand non-goal nodes f -cost equaloptimal solution cost. consistency experimental comparison, implementationAnytime WA* uses rule A* uses breaking ties favor nodesleast h-cost. practice, tie-breaking rule omitted implementing AnytimeWA* order reduce run-time overhead.2.4.1 Sliding-tile puzzlefirst test domain consider traditional benchmark lets us illustratetechnique simple well-understood example. Figure 1(a) shows performance profilesAnytime WA* using three different weights, averaged instances EightPuzzle.2 (Performance profiles commonly used model performance anytimealgorithms, show expected solution quality improves function computationtime. problems, define quality solution 1 f ff .) weight 1.3seems result best overall performance among three weights, althoughdominate performance profiles running times.2. instances, mean possible starting states fixed goal state. goal state blankupper left corner tiles arranged numerical order, left-to-right top-down.use Manhattan distance heuristic.274fiAnytime Heuristic SearchA*InstanceBlocks-8Logistics-6Satellite-6Freecell-3Psr-46Depots-7Driverlog-11Elevator-12Len1425201834211940Stored426,130364,8463,270,1955,992,6887,464,85021,027,25722,344,51512,748,119Exp40,638254,1252,423,3732,693,2357,141,4617,761,6616,693,09612,734,334Secs5.24.0151.5170.0343.2367.8407.0560.6Stored41,166254,4122,423,5472,695,3217,148,0487,773,8306,702,57012,734,636AWA* (weightExp41,099254,7482,423,5662,705,4217,175,2757,772,0916,699,14312,829,775= 2)Opt %0.2%6.2%14.3%1.7%69.0%0.5%1.4%98.6%Secs3.83.7138.8146.2348.0249.1281.6569.7Table 1: Comparison A* AWA* eight benchmark problems biennialPlanning Competitions.Figure 1(b) shows many nodes Anytime WA* stores expands converges optimal solution, using different weights. (Again, converges optimalsolution, mean lower upper bounds meet algorithm provedsolution optimal.) Using weight 1.3, average increase numbernodes expanded Anytime WA* slight compared number nodes expandedunweighted A*. Figure 1(b) also shows Anytime WA* using weight 1.3 1.5stores fewer nodes unweighted A*. weights, reduction memory requirements due using upper bound prune Open list greater increasememory requirements due expanding distinct nodes.2.4.2 STRIPS planningrecent years, considerable interest using heuristic search domainindependent STRIPS planning. Influential examples approach HSPHSPr planners Bonet Geffner (2001), performed well biennialplanning competitions sponsored International Conference Automated PlanningScheduling (Long & Fox, 2003). HSP solves STRIPS planning problems using A*search forward start state goal, HSPr uses A* search backwardsgoal start state, advantage allows heuristiccomputed efficiently. many benchmark planning problems usedplanning competition difficult solve optimally, WA* often used find suboptimalsolutions reasonable amount time.Using Bonets publicly-available implementation HSPr, compared performanceA* Anytime WA* benchmark problems previous planning competitionscould solved optimally A*, using domain-independent admissible max-pairheuristic described Haslum Geffner (2000). used weight 2.0 experiments. instances, Anytime WA* converged optimal solution using lessmemory A*. (but all) instances, also took less time. Table 1 compares performance A* Anytime WA* (AWA*) hardest solvable instances275fiHansen & ZhouInstanceBlocks-8Logistics-6Satellite-6Freecell-3Psr-46Depots-7Driverlog-11Elevator-12AWA* (weight = 5)Exp Opt %Secs42,2930.2%3.9274,0474.6%3.82,458,4528.9%138.7> 35,639,419N/A > 2,207.67,310,349 10.0%350.67,902,1830.4%250.76,814,6961.2%281.112,851,075 76.0%557.5AWA* (weight = 10)Exp Opt %Secs42,2930.2%3.9312,726 11.0%4.32,585,074 13.2%144.8> 73,712,127N/A > 4,550.57,623,0074.8%365.18,115,6031.9%254.77,674,956 18.0%322.413,145,547 21.4%568.0Table 2: Performance AWA* weights 5 10 eight benchmark problemsbiennial Planning Competitions.eight planning problems.3 CPU time relatively long numbernodes generated stored due significant overhead generating node computing heuristic domain-independent way. Blocks Driverlog domainslargest branching factors, thus space savings using upper bound preventinsertion suboptimal nodes Open list greatest domains. domainAnytime WA* expand many 1% nodes A*, usually increasedpercentage node expansions fraction this.column labeled Opt % shows soon Anytime WA* finds turnsoptimal solution. percentage number node expansions findingoptimal solution total number node expansions convergence. providesrough measure anytime performance algorithm. showsdomains, Anytime WA* finds turns optimal solution quicklyspends search time proving solution optimal. However two domains(Psr-46 Elevator-12), Anytime WA* find solution relatively late.domains, solutions found sooner weight increased. Table 2shows performance Anytime WA* using weights 5 10. Using higherweights, anytime performance better last two problems, especially Elevator-12,although worse others. Even weights 5 10, Anytime WA*tends outperform A* solving first five problems. sixth problem, Freecell-3,different. weight 5, Anytime WA* cannot find solution runningmemory. weight 10, number stored nodes (since exhaustsamount memory) number expanded nodes (and CPU time)doubles node reexpansions weight increases. resultsclearly show effect weight search performance vary domain.Given variability, trial error selecting weight appears inevitable.appropriate weight used, Anytime Weighted A* consistently beneficial.3. experiments performed Intel Xeon 3.0GHz processor 2MB L2 cache 2GBRAM276fiAnytime Heuristic Search2.4.3 Multiple sequence alignmentAlignment multiple DNA protein sequences plays important role computationalmolecular biology. well-known problem formalized shortest-pathproblem n-dimensional lattice, n number sequences aligned (Carillo & Lipman, 1988; Yoshizumi, Miura, & Ishida, 2000). A* outperform dynamic programming solving problem using admissible heuristic limit numbernodes lattice need examined find optimal alignment (Ikeda & Imai,1999). However, challenging feature search problem large branching factor,equal 2n 1. A* applied problem, large branching factormeans Open list much larger Closed list, memory requiredstore Open list becomes bottleneck algorithm.Two solutions problem proposed literature. Yoshizumi etal. (2000) describe extension A* called A* Partial Expansion (PEA*). Insteadgenerating successors node expanded, PEA* insertspromising successors Open list. partially expanded node reinsertedOpen list revised f -cost equal least f -cost successorsyet generated, node reexpanded later. Use techniquesignificantly reduces size Open list, PEA* solve larger multiple sequencealignment problems A*. Unfortunately, reduced space complexity PEA*achieved cost node reexpansion overhead. tradeoff space timecomplexity adjusted setting cutoff value C, implicitly determines manysuccessor nodes add Open list time.Another way reduce size Open list insert nodes Open listf -cost equal greater previously established upper bound costoptimal solution, since nodes never expanded A*. approachproposed Ikeda Imai (1999), call Enhanced A* (EA*). suggest oneway obtain upper bound use solution found Weighted A* searchweight w > 1, although report experimental results using technique.anytime algorithm provides third approach reducing size Open list.also use Weighted A* quickly find solution provides upper bound pruningOpen list. first solution found may optimal, weighted searchcontinued order find sequence improved solutions eventually convergesoptimal solution. provides sequence improved upper boundsreduce size Open list.Figure 2 compares performance Anytime WA* (AWA*) performance A*Partial Expansion Enhanced A* aligning five sequences set dissimilar(and thus difficult align) sequences used earlier experiments (Kobayashi & Imai, 1998).cost function Dayhoffs PAM-250 matrix linear gap cost 8. admissibleheuristic standard pairwise alignment heuristic, (almost negligible) timeneeded compute heuristic included running time search.three algorithms require much less memory standard A* solving problem.found good weight Anytime WA* solving test problem 10099 , is,g-cost weighted 99 h-cost weighted 100. (Because cost functionmultiple sequence alignment integer-valued, use weighting scheme preserves277fiHansen & ZhouFigure 2: Average performance search algorithms aligning sets 5 sequencesKobayashi Imai (1998).integer f -costs allow efficient integer-valued arithmetic.) create upper boundEnhanced A*, ran Weighted A* weight 10099 used costfirst solution found upper bound.Figure 2 shows Anytime WA* runs seven times faster storesnumber nodes PEA* cutoff C = 0. PEA* uses cutoffC = 50, stores 44% nodes Anytime WA* still runs 65% sloweraverage. Although Enhanced A* runs fast Anytime WA*, stores 36%nodes. Anytime WA* stores fewer nodes continuation weighted search resultsdiscovery improved solutions provide tighter upper bounds pruning Open list.summary, Anytime WA* outperforms standard A* solving problem,performs better two state-of-the-art enhancements A* specifically designedproblem.Figure 3 illustrates behavior Anytime WA* showing upper lowerbounds gradually converge. Notice Anytime WA* finds optimal solution10% total search time, spends remaining 90% time provingsolution optimal, point converges. Compared Partial Expansion A*Enhanced A*, important advantage Anytime WA* finds suboptimalalignment quickly continues improve alignment additional computationtime. Thus, offers tradeoff solution quality computation timeprove useful finding optimal alignment infeasible.weight found worked well problem may seem surprisingly small,one might suspect weight small little effect ordernodes different f -costs expanded, serves primarily tie-breaking rulenodes f -cost different h-costs. implementations A*Anytime WA* break ties favor nodes least h-cost, however, weighteffect tie breaking experiments.couple reasons small weight effective search problem.First, search graph multiple sequence alignment non-uniform edge costs.278fiAnytime Heuristic SearchFigure 3: Convergence bounds Anytime WA* aligning sets 5 sequencesKobayashi Imai (1998).result, range f -costs much greater test problems,unit edge costs. Second, f -costs h-costs much larger problemtest problems part, edge costs larger (given costfunction used), and, part, search space deeper. (The protein sequencesaligned average length 150, means search leastdeep.) search problem, optimal f -costs around 50, 000.pairwise alignment heuristic used solving problem accurate, largest h-costsalso around 50, 000. Given h-costs large wide range f -costs, weight 10099significant effect order node expansions. serves illustrateappropriate weight Anytime WA* depends characteristics search problem.2.4.4 Discussionresults show Anytime WA* effective wide range search problems.general, effective search problem whenever Weighted A* effective. othersobserved, Weighted A* usually find solution much faster A* A* spendstime discriminating close-to optimal solutions order determineoptimal (Pearl, 1984, p. 86). Indeed, test results show Anytime WA*often finds turns optimal solution relatively quickly, spendssearch time proving solution optimal.One surprising results experiments Anytime WA* using appropriate weight sometimes converge optimal solution using less memory evenless time A*. surprising well-known A* using consistentheuristic optimally efficient terms number nodes expanded (Dechter &Pearl, 1985). However necessarily optimally efficient measures searchcomplexity, including memory requirements running time. Anytime WA* sometimesefficient measures search performance, even though requiresnode expansions find provably optimal solution. reason improved solutions found anytime approach provide upper bounds used279fiHansen & Zhoureduce number nodes stored Open list. resulting savings, memorytime overhead managing Open list, sometimes greater additionaloverhead increased node expansions.experiments, used relatively low weights result fast convergencewell good anytime performance. shows A* transformed anytimealgorithm exchange little delay convergence optimal solution.mean recommend weight used Anytime WA* alwaysset low enough minimize memory use time takes find provably optimalsolution. search problems, could advantage use higher weightsattempt find approximate solutions quickly. cases, increasing weightused Anytime WA* allows approximate solution found sooner, increasesnumber node expansions convergence optimal solution. end,best weight depends preferences time-quality tradeoffs.focused use weighted heuristic search create anytime heuristicsearch algorithm. fact, non-admissible heuristic could used guideAnytime A* algorithm, pointed beginning Section 2.3. possible (andeven seems likely) informative, inadmissible, heuristic could sometimes leadbetter anytime search performance weighted admissible heuristic. case,Anytime A* would use two heuristics non-admissible heuristic select ordernode expansions, another, admissible heuristic, prune search space detectconvergence optimal solution. interesting direction exploration.contribution paper show approach simple weightingadmissible heuristic creates effective anytime algorithm many search problems.3. Anytime RBFSwell-known scalability A* limited memory required storeOpen Closed lists. also limits scalability Anytime A*. Several variantsA* developed use less memory, including algorithms require linearspace depth search. show transform one them, RecursiveBest-First Search, RBFS (Korf, 1993), anytime algorithm. Besides showingcreate linear-space anytime heuristic search algorithm, helps illustrategenerality approach showing another weighted heuristic search algorithmtransformed anytime heuristic search algorithm similar way, continuingweighted search first solution found.begin section brief review RBFS algorithm. considertwo approaches using weighted evaluation function RBFS, onestudied alternative show advantages. Finally, discusstransform Weighted RBFS Anytime Weighted RBFS algorithm. useFifteen Puzzle test domain, larger version sliding-tile puzzleA* cannot solve optimally memory limitations. RBFS saves memorystoring generated nodes, slowed excessive node regenerations solvinggraph-search problems many duplicate paths. result, RBFS effective (interms time efficiency) either STRIPS planning multiple sequence alignment.280fiAnytime Heuristic Search3.1 Recursive Best-First Search (RBFS)Recursive best-first search, RBFS (Korf, 1993), general heuristic search algorithmexpands frontier nodes best-first order, saves memory determining nextnode expand using stack-based backtracking instead selecting nodes Openlist. stack contains nodes along path start node node currentlyvisited, plus siblings node path. Thus memory complexityRBFS O(db), depth search b branching factor.RBFS similar recursive implementation depth-first search, differenceuses special condition backtracking ensures nodes expanded(for first time) best-first order. Instead continuing current path farpossible, ordinary depth-first search, RBFS keeps track f -cost bestalternative path available ancestor current node, passedargument recursive function. f -cost current path exceeds threshold,called local cost threshold, recursion unwinds back alternative path.recursion unwinds, RBFS keeps track f -cost best unexpanded nodefrontier forgotten subtree saving stored value F (n). stored values,one node n stack, used RBFS decide path expand nextpoint search. F (n) least f -cost unexpanded nodefrontier subtree rooted node n, stored values propagated successornodes successor generation. node previously expanded, (propagated)stored value greater static evaluation, RBFS uses fact detectpreviously expanded nodes regenerate subtrees efficiently.Among advantages RBFS, Korf points expands nodes best-firstorder even evaluation function nonmonotonic. illustrate nonmonotonicevaluation function, considers RBFS using weighted evaluation function.3.2 Weighted RBFSLike A*, RBFS use weighted heuristic trade solution quality search time.Algorithm 2 gives pseudocode recursive function RBFS using weightedevaluation function. RBFS algorithm described Korf, althoughnotation slightly adjusted show weighted values F 0 stored stackinstead unweighted values F , local cost threshold B 0 weighted value.RBFS initially invoked, three arguments start node, (weighted)evaluation start node, cost threshold infinity. Using weighted evaluationfunction, RBFS expands nodes (for first time) order weighted evaluationfunction, f 0 , instead order unweighted evaluation function, f . Korf (1993)considers approach Weighted RBFS presents empirical study tradeoffoffers search time solution quality.motivate another approach weighted heuristic search using RBFS, introducedistinction two search frontiers maintained RBFS. stored values, denotedF (n) F 0 (n), keep track best unexpanded node frontier subtree rootednode n stack. call virtual frontier RBFS actuallystore frontier memory, uses stored values represent regeneratefrontier. introduce term stack frontier refer frontier RBFS actually281fiHansen & ZhouAlgorithm 2: RBFS (using weighted evaluation function)Input: node n, F 0 (n), threshold B 0beginn goal node output solution path exit algorithmSuccessors(n) = returnforeach ni Successors(n), = 1, 2, , |Successors(n)|g(ni ) g(n) + c(n, ni ), f 0 (ni ) g(ni ) + w h(ni )f 0 (n) < F 0 (n) F 0 (ni ) max{F 0 (n), f 0 (ni )}else F 0 (ni ) f 0 (ni )sort ni increasing order F 0 (ni )|Successors(n)| = 1 F 0 (n2 )F 0 (n1 ) < F 0 (n1 ) B 0F 0 (n1 ) RBFS n1 , F 0 (n1 ), min{B 0 , F 0 (n2 )}insert n1 sorted order F 0 (ni )return F 0 (n1 )endstores memory. stack frontier consists nodes stacksuccessor nodes stack.weighted heuristic search, weighted evaluation function used determineorder expand nodes frontier search. approach WeightedRBFS shown Algorithm 2, approach adopted Korf (1993), weightedevaluation function used select order expand nodes virtualfrontier. virtual frontier frontier maintained memoryWeighted A*, using Open list, approach Weighted RBFS expands nodesorder Weighted A* (disregarding tie breaking node regenerations).Algorithm 3 shows pseudocode alternative approach weighted heuristicsearch using RBFS. Like approach shown Algorithm 2, uses weighted evaluationfunction continues expand solution path long weighted evaluationcurrently-expanding node greater weighted evaluation sibling onenodes along path. difference instead backing least weightedevaluation f 0 unexpanded node subtree rooted node n storingF 0 (n), Algorithm 3 backs least unweighted evaluation f unexpanded node,stores F (n). f (n) admissible evaluation function, F (n) lowerbound cost best solution found subtree rooted n.follows H(n) = F (n) g(n) improved admissible heuristic node n. Therefore,Algorithm 3 use weighted evaluation g(n) + w H(n) = g(n) + w (F (n) g(n))determine order expand nodes. approach Weighted RBFS, nodesexpanded best-first order weighted evaluation nodes stack frontier,instead order weighted evaluation nodes virtual frontier.RBFS general algorithmic scheme use different evaluation functions. Thus,even uses weighted evaluation function, Korf refers RBFS. makeeasier distinguish algorithms, introduce name WRBFS referalternative approach weighted heuristic search based RBFS propose.WRBFS expands nodes stack frontier best-first order evaluation function282fiAnytime Heuristic SearchAlgorithm 3: WRBFSInput: node n, F (n), threshold B 0beginn goal node output solution path exit algorithmSuccessors(n) = returnforeach ni Successors(n), = 1, 2, , |Successors(n)|g(ni ) g(n) + c(n, ni ), f (ni ) g(ni ) + h(ni )f (n) < F (n) F (ni ) max{F (n), f (ni )}else F (ni ) f (ni )sort ni increasing order F (ni )|Successors(n)| = 1 F (n2 )g(n2 )F (n1 ) <g(n)+wF (n1 ) g(n1 ) B 01F (n1 ) WRBFS n1 , F (n1 ), min{B 0 , g(n2 ) + w F (n2 ) g(n2 ) }insert n1 sorted order F (ni )return F (n1 )endF 0 (n) = g(n) + w H(n), instead expanding nodes virtual frontier orderevaluation function f 0 (n) = g(n) + w h(n). Since F 0 (n) = g(n) + w H(n) improvessearch, static evaluation function, another reason usingname WRBFS. Note w = 1, unweighted RBFS, differencebehavior two algorithms; expanding nodes best-first order evaluationstack frontier equivalent expanding nodes best-first order evaluationvirtual frontier. difference one considers whether applyweight greater 1 heuristic stack frontier virtual frontier.Figure 4 compares performance two approaches Weighted RBFS solvingKorfs (1985) 100 random instances Fifteen Puzzle. Figure 4(a) shows averagelength solutions found algorithm, using weights ranging 1.0 5.0increments 0.1. WRBFS finds better-quality solutions RBFS using weightedevaluation function weight, difference increases weight.since WRBFS also take longer find solution, consider time-quality tradeoffoffered algorithm. Figure 4(b), similar Figure 10 articleKorf (1993), plots solution length versus time (measured number recursive calls)solving Fifteen Puzzle examples, using solution lengths ranging 53 85algorithms. time-quality tradeoff offered two algorithms similar,modest advantage WRBFS. striking WRBFS offers smooth timequality tradeoff, whereas tradeoff offered RBFS using weighted evaluation functionirregular. Sometimes, increasing weight used RBFS causes take longer findsolution, instead less time. dramatic example increasing weight 1.01.1 causes RBFS weighted evaluation function take three times longer find(potentially suboptimal) solution unweighted RBFS takes find optimal solution.Korf (1993) gives reason irregular time-quality tradeoff. node regeneration overhead RBFS grows number iterations algorithm,number times local cost threshold increases, since iteration requires regenerationsubtrees. one iteration distinct f -cost, or, case RBFS using283fiHansen & ZhouFigure 4: Comparison RBFS using weighted evaluation function WRBFS solvingKorfs 100 random instances Fifteen Puzzle. Panel (a) shows solutionquality function heuristic weight. Panel (b) shows time-quality tradeoffalgorithm plotting number recursive calls solution quality.weighted evaluation function, distinct f 0 -cost. irregular time-quality tradeoffcaused fluctuation number distinct f 0 -costs weight increases, leadsfluctuation number iterations. number distinct f 0 -costs manynumber distinct pairs g-cost h-cost, actual number dependsweight, since different pairs g-cost h-cost may sum f 0 -cost, dependingweight. Increasing weight 1.0 1.1, example, significantly increasesnumber distinct f 0 -costs, explains RBFS using weighted evaluationfunction takes longer find solution case. advantage using WRBFSstored value node stack minimum f -cost frontiersubtree rooted node, instead minimum f 0 -cost, thus numberiterations affected variation number distinct f 0 -costs weightincreased. result, adjusting weight creates smoother time-quality tradeoff.approaches Weighted RBFS well-motivated offer useful tradeoffsearch time solution quality. original approach expands frontier nodesbest-first order weighted evaluation function f 0 (n) = g(n) + w h(n), and,respect, closer Weighted A*. seen, alternate approachadvantage allows smoother time-quality tradeoff. consider transformtwo approaches Weighted RBFS anytime heuristic search algorithm,see alternate approach advantages well.3.3 Anytime Weighted RBFSstraightforward transform either approach Weighted RBFS anytimealgorithm. Algorithm 4 shows pseudocode recursive function Anytime WRBFS.couple differences Weighted RBFS algorithm WRBFS284fiAnytime Heuristic SearchAlgorithm 4: Anytime WRBFSInput: node n, F (n), threshold B 0beginn goal node return f (n)Successors(n) = returnforeach ni Successors(n), = 1, 2, , |Successors(n)|g(ni ) g(n) + c(n, ni ), f (ni ) g(ni ) + h(ni )ni goal node f (ni ) < f (incumbent)incumbent nisave (or output) incumbent solution pathf (ni ) f (incumbent) F (ni )else f (n) < F (n) F (ni ) max{F (n), f (ni )}else F (ni ) f (ni )sort ni increasing order F (ni )|Successors(n)| = 1 F (n2 ) g(n2 )F (n1 ) < f (incumbent)and g(n1 ) + w F (n1 ) g(n1) B 0F (n1 ) Anytime-WRBFS n1 , F (n1 ), min{B 0 , g(n2 ) + w F (n2 ) g(n2 ) }insert n1 sorted order F (ni )return F (n1 )endAnytime Weighted RBFS algorithm. importantly, condition termination different. anytime algorithm finds solution, time findsimproved solution, saves (or outputs) solution continues search.Anytime Weighted A*, algorithm checks whether node goal node generated, instead waiting expanded. also checks whether f -cost nodegreater equal upper bound given f -cost incumbent solution.so, part search space pruned. (Note first solution found,f (incumbent) set equal infinity, since yet finite upper boundoptimal solution cost.) Convergence optimal solution detected stackempty. point, backtracking determined branches treesearched pruned. Proof termination optimal solution follows similar logicTheorem 1. suboptimality currently available solution bounded usingf (incumbent) upper bound optimal solution cost least F -cost nodestack frontier lower bound. (Again, stack frontier consists nodeend current best path, plus every sibling node along path.)Figure 5(a) shows performance profiles Anytime WRBFS, averaged Korfs 100random instances Fifteen Puzzle. Although weights 2.0 1.5 offer better timequality tradeoff short amounts search time, weight 1.3 provides better long-termperformance. Figure 5(b) shows time (measured average number recursivecalls) taken Anytime WRBFS find optimal solutions Fifteen puzzle, usingweights 1.0 2.0 increments 0.1. Using weights 1.2 1.4, convergesoptimal solution quickly unweighted RBFS. fact, using weight 1.3,Anytime WRBFS converges optimal solution average 25% fewer recursivecalls unweighted RBFS. Although always expands many distinct nodesunweighted RBFS, reliance stack-based backtracking reduce memory use means285fiHansen & ZhouFigure 5: Performance Anytime WRBFS. Panel (a) shows performance profiles usingthree different weights, averaged Korfs 100 random instances FifteenPuzzle. Panel (b) shows average number recursive calls required convergeoptimal solution, using weights 1.0 2.0 increments 0.1,averaged 100 random instances Fifteen Puzzle.algorithms revisit nodes multiple times. Figure 5(b) showsweighted heuristic used Anytime WRBFS reduce number recursive calls;intuitively, occurs greedier search strategy weighted heuristic searchtends delay reduce backtracking. course, weight increased enough,number distinct node expansions increases eventually number recursive callsalso increases, Figure 5(b) shows. Nevertheless, demonstration small weightsometimes improve efficiency finding optimal solutions interesting.comparison, Figure 6(a) shows performance profiles version Anytime WeightedRBFS based RBFS using weighted evaluation function, originalapproach Weighted RBFS. case, performance profile Anytime WeightedRBFS using weight 1.3 dominated performance profiles using weights 1.52.0. Figure 6(b) shows average number recursive calls taken versionAnytime Weighted RBFS find optimal solutions Fifteen puzzle, usingrange weights 1.0 2.0. ensure fair comparison, implemented versionAnytime Weighted RBFS saves admissible F (n) values additionnon-admissible F 0 (n) values, uses F (n) values prune branches search treedetect convergence optimal solution, instead using static evaluation f (n).Nevertheless, version Anytime Weighted RBFS converges much slowly.scale y-axis Figure 6(b) order magnitude greater Figure 5(b),reflects fact Anytime Weighted RBFS based version WeightedRBFS takes order magnitude longer converge optimal solution AnytimeWRBFS, using weight.Fluctuations length time convergence Figure 6(b) caused differences number distinct f 0 -costs weight increases, causing differences286fiAnytime Heuristic SearchFigure 6: Performance Anytime Weighted RBFS based RBFS using weighted evaluation function. Panel (a) shows performance profiles using three different weights,averaged Korfs 100 random instances Fifteen Puzzle. Panel (b) showsaverage number recursive calls converge optimal solution, usingweights 1.0 2.0 increments 0.1, averaged instances.scale y-axis order magnitude greater Figure 5(b).number iterations resulting fluctuations node regeneration overhead.similar observed earlier performance approach Weighted RBFS.explain large difference time takes algorithm converge. least two reasons Anytime WRBFS converges much faster. Oneefficient backtracking behavior. Anytime WRBFS expands nodes orderweighted evaluation function stack frontier, instead order weightedevaluation function virtual frontier, searches greedily deeper levelsstack backtracking shallower levels. Since computationally expensiveregenerate large subtrees rooted shallower nodes stacksmaller subtrees rooted deeper nodes, bias towards backtracking deeperlevels backtracking shallower levels contributes improved convergence time.Another reason Anytime WRBFS converges much faster effectiveimproving lower bound optimal solution cost. pointed earlier, anytimeheuristic search often finds turns optimal solution relatively quickly,spends time proving solution optimal, correspondsimproving lower bound. versions Anytime Weighted RBFS, lower boundminimum F (n) values stored stack frontier. Although anytime searchalgorithm based original version Weighted RBFS guaranteed improveF 0 (n) value subtree rooted node n iteration, may may improve F (n)value (which assume also stores). contrast, anytime search algorithm basedWRBFS guaranteed improve F (n) value iteration. improvesadmissible F (n) values, instead weighted F 0 (n) values, Anytime WRBFS effectiveimproving lower bound optimal solution cost, leading faster convergence.287fiHansen & Zhou4. Related Worksection, consider closely-related work. begin considering variantAnytime A* recently proposed. discuss relationshipAnytime A* variants A* that, directly indirectly, also allow tradeoffsearch time solution quality.4.1 Anytime Repairing A*Likhachev, Gordon, Thrun (2004) recently introduced interesting variantAnytime A*, called Anytime Repairing A* (or ARA*), showneffective real-time robot path planning. approach follows approach creatingAnytime A* algorithm many respects. uses Weighted A* find approximatesolution relatively quickly, continues weighted search find sequence improvedsolutions convergence optimal solution. However, introduces two extensionsimprove performance. First, solution found, decreases weightcontinuing search. Second, uses technique limit node reexpansions. firstextensions, decreasing weight new solutions found, easy considerindependently other, also easily combined Anytime Weighted A*(AWA*), consider first.Decreasing weight experiments, used weighted heuristic weightchange search. chose approach simplicity.Likhachev et al. (2004) argue better performance possible gradually decreasingweight search. new solution found, ARA* decreases weightsmall, fixed amount, continues search. Experimental results showapproach leads improved performance robot path-planning domains.course, relative performance depend initial weight simplywhether weight remains fixed decreases. Likhachev et al. report three experimentalcomparisons AWA* ARA*. one, set initial weight 3; another,set initial weight 10; third, set initial weight 30. weightshigher found worked well test problems. experiments,AWA* never changes initial weight whereas ARA* decreases new solutionsfound. initial weight set high, might explain decreasing improvesperformance. could also setting initial weight high gradually decreasingeffective approach robot path-planning problems consider,similar problems. Even so, follow best approach problems.compared Anytime Weighted A* Anytime Repairing A* solving STRIPSplanning problems used testbed Section 2.4.2. Although Likhachev et al.use upper bounds reduce size Open list implementation ARA*,easy included enhancement implementation ARA*order ensure fair comparison. addition decreasing weight, ARA* uses specialrepairing technique limit node reexpansions. Since independent idea,implemented version AWA* decreases weight search usespecial technique limiting node reexpansions. itself, decreasing weightsearch requires recalculating f 0 -costs reordering Open list whenever weight288fiAnytime Heuristic SearchInstancesBlocks-8Logistics-6Satellite-6Freecell-3Psr-46Depots-7Driverlog-11Elevator-12AWA* (weight = 2, step = 0.1)StoredExp Opt %Secs41,16640,7270.2%3.9254,412254,3906.2%3.62,423,5472,423,489 14.3% 138.62,695,3212,698,5961.7% 155.37,148,0487,171,557 69.0% 345.77,773,8307,762,7830.5% 247.46,763,3796,693,4414.7% 283.312,734,636 12,825,980 98.7% 561.3ARA* (weight = 2, step = 0.1)StoredExp Opt %Secs41,16642,1410.2%3.9312,438364,840 87.1%5.02,423,5472,428,325 14.2% 138.44,115,0325,911,849 68.7% 317.27,143,912 11,888,700 35.3% 567.77,771,7807,823,0050.5% 247.16,698,4046,771,6511.3% 281.312,736,328 12,843,441 97.8% 559.7Table 3: Comparison AWA* (with decreasing weight) ARA* eight benchmarkproblems biennial Planning Competitions.changed. Table 3 compares performance AWA* ARA* use initialweight 2.0 decrease weight 0.1 new solution found. planninginstances except Logistics-6, Freecell-3 Psr-46, significant differenceperformance significant difference performance performanceAWA* fixed weight 2.0 solving instances. (See Table 1.)STRIPS planning problems using initial weight, gradually decreasingweight improve performance. course, could improve performanceproblems. case, note easy decrease weight used AWA* withoutimplementing full ARA* algorithm.Another potential advantage decreasing weight, Likhachev et al. point out,provides different way bounding suboptimality solution. solutionfound Weighted A* using weight w, one error bound, f (incumbent)w. Notefdecreasing bound requires decreasing weight search.Section 2.3.2, defined different error bound, f (incumbent)f (incumbent),ffLLf denotes least f -cost currently open node frontier. advantageerror bound decreases even weight remains fixed search.additional advantage tighter bound. Let nL denote open nodef (nL ) = f L . h(incumbent) = 0 incumbent expanded nL , knowf (incumbent) = f 0 (incumbent) g(nL ) + w h(nL ).Therefore,f (incumbent)g(nL ) + w h(nL )w (g(nL ) + h(nL ))<= w,fLg(nL ) + h(nL )g(nL ) + h(nL )strict inequality follows assumptions w > 1 g(nL ) > 0.Although ARA* performs AWA* solving five eight planningproblems, performs worse solving three: Logistics-6, Freecell-3, Psr-46.Comparing ARA* AWA* initial weight decrease weightway shows deterioration performance caused decreasingweight. consider next technique used ARA* limiting node reexpansions.289fiHansen & ZhouFigure 7: Comparison AWA* ARA* solving instances Eight Puzzle.Panel (a) shows average number nodes stored panel (b) showsaverage number node expansions, function initial weight.Limiting node reexpansions discussed before, complication Anytime WeightedA* inherits Weighted A* weighted heuristic typically inconsistent.means possible node higher-than-optimal g-cost expanded.better path node later found, node reinserted Open listimproved g-cost propagated descendants node reexpanded.result, Weighted A* Anytime WA* expand node multiple times.Likhachev et al. note error bound Weighted A* remains valid even nodereexpansions allowed. Since ARA* algorithm performs series Weighted A*searches decreasing weights, reason ARA* postpones node reexpansionscurrent iteration Weighted A* finishes weight decreased,create efficient Anytime A* algorithm. ARA* finds better pathalready-expanded node, inserts node list called INCONS order delay nodereexpansion. solution found weight decreased, ARA* moves nodesINCONS list Open list resumes search.technique limiting node reexpansions may improve search performance robotpath planning similar search problems, especially using large weights.relative performance AWA* ARA* solving Logistics-6, Freecell-3, Psr-46planning instances raises question whether always improves performance.comparison, Table 7 shows average performance AWA* ARA* solvinginstances Eight Puzzle. algorithm initial weight. AWA* neverchanges initial weight ARA* reduces increments 0.1 new solutionsfound. larger weight makes heuristic inconsistent increases likelihoodAWA* reexpand nodes. Yet results show larger initial weight,nodes ARA* expands relative AWA*, difference dramatic.initial weight set 3.0, ARA* expands four times nodes AWA*.290fiAnytime Heuristic Searchmany cases, takes longer ARA* find initial suboptimal solution takesunweighted A* find optimal solution.One reason result limiting node reexpansions cause ARA* expanddistinct nodes. (The fact ARA* stores well expands nodes, shownFigure 7, indicates expands generates distinct nodes.) Limiting nodereexpansions lead expansion distinct nodes blocks improvementpaths pass node stored INCONS list. blocking improvementpaths, prevent better solutions found. One possibilitysolution found Weighted A* passes node stored INCONSlist, means reexpansion propagation improved g-cost postponed.case, f 0 -cost solution greater would reexpansion nodeallowed. Another possibility potentially better solution one foundWeighted A* passes node INCONS list, therefore discoveredimprovement blocked. Either way, solution found Weighted A*allow node reexpansions greater f 0 -cost node reexpansionsallowed. Weighted A* must expand nodes f 0 -cost lessf 0 -cost solution finds, distinct nodes expanded whenever limiting nodereexpansions prevents Weighted A* finding better solution. Figure 7 shows,effect becomes pronounced increasing weight increases likelihoodfirst time ARA* expands node, g-cost suboptimal.results show effect occur search problems, leastdegree. seems occur primarily search problems relatively sparsesolutions, sliding-tile puzzle Logistics Freecell planning domains.solutions sparse, easier nodes lead good solutionexpanded higher-than-optimal g-cost, thus likely Weighted A* findsolution worse would found allowed node reexpansions. searchproblems huge number solutions equal almost equal cost, limiting nodereexpansions way less likely cause problem. robot path-planningproblems considered Likhachev et al. examples kind search problem,thus impressive results report inconsistent observations.yet another way limiting node reexpansions sometimes makes searchperformance worse. far, considered search problems ARA* expandsdistinct nodes AWA*. Psr-46 planning instance, ARA* expands manynodes AWA*, store nodes. indicates ARA*expand distinct nodes AWA*. Instead, performs node reexpansions.possible ARA* explicitly limits node reexpansions? turnslimiting node reexpansions way ARA* sometimes lead nodereexpansions. time ARA* decreases weight reexpands node propagateimproved path information, reexpanded node many descendantsexplicit search graph improved path node originally found.result, many nodes may need reexpanded propagate improved pathinformation. Again, always happen. behavior ARA* solvingPsr-46 illustrates possibility.Figure 7(b) compares average number nodes expanded ARA* AWA*solving instances Eight Puzzle, show CPU time. initial291fiHansen & Zhouweight 3, ARA* expands 4.5 times nodes AWA*. differenceCPU time actually greater. ARA* takes 7 times longer solve problemsAWA*, average. One reason extra time overhead recalculating f 0 -costsreordering Open list every time weight decreased. time overheadnegligible STRIPS planning problems compared much greater overheaddomain-independent node generation heuristic calculation. sliding-tilepuzzle, node generation heuristic calculation fast time overheadrecalculating f 0 -costs reordering Open list noticeable effect slowingsearch. another example relative performance ARA* AWA*vary search problem.summary, idea decreasing weight search used independentlytechnique limiting node reexpansions. Although gradually decreasing weightimprove performance test problems, could improve performanceproblems. However, additional overhead recalculating f 0 -costs reorderingOpen list considered. technique limiting node reexpansions also help,used caution. problems, shown actuallycause significantly node reexpansions expansion distinct nodes.problems, negative effect. Although show clear benefittest domains, could improve performance robot path planning similar problemsmany close-to-optimal solutions, especially using large weight.4.2 Real-time A*anytime approach heuristic search effective real-time search problemsenough time available search optimal solution. Previous work time-limitedheuristic search adopts model Korfs Real-time A* algorithm (RTA*) assumessearch interleaved execution (Korf, 1990). searching bounded amounttime, best next action chosen search-act cycle repeats goal statereached. Similar examples real-time search strategy include DTA* (Russell &Wefald, 1991), BPS (Hansson & Mayer, 1990) k-best (Pemberton, 1995). realtime search algorithms commit actions finding complete solution, cannotfind optimal solutions. contrast, assume search phase precedes executionphase output search complete solution. words, real-timesearch algorithms try find best next decision time constraint, whereasanytime approach tries find best complete solution time constraint.4.3 Depth-first branch bound Iterative-Deepening A*Depth-first branch-and-bound (DFBnB) search algorithms effective tree-searchproblems, especially many solutions depth, travelingsalesman problem. problems, DFBnB behavior anytime algorithm.quickly finds solution suboptimal, continues search improvedsolutions optimal solution found. even uses cost best solution foundfar upper bound prune search space.search technique combines elements DFBnB A* Iterative-deepeningA* IDA* (Korf, 1985). well-known IDA* performs poorly problems292fiAnytime Heuristic Searchreal-valued edge costs traveling salesman almost nodes distinctf -costs. problems, may expand one new node iteration. preventexcessive iterations node regenerations, several variants IDA* developedset successive thresholds higher minimum f -cost exceeded previousthreshold (Sarkar, Chakrabarti, Ghose, & DeSarkar, 1991; Rao, Kumar, & Korf, 1991; Wah& Shang, 1994). result, first solution found guaranteed optimal,although bounded error. finding initial solution, algorithms revertDFBnB search ensure eventual convergence optimal solution. approachreducing node regenerations IDA* side-effect creating anytime algorithm,although one effective problems IDA* DFBnB effective,typically tree-search problems.4.4 Bidirectional A*Another search technique side-effect creating anytime algorithm Bidirectional A* (Kaindl & Kainz, 1997). approach, two simultaneous A* searchesperformed, one start state goal, goal startstate. two search frontiers meet node, two partial solutions combinedcreate complete solution. Typically, first solution found suboptimalsearch must continued find optimal solution. Thus, bidirectional search strategyside-effect finding succession improved solutions convergenceoptimal solution. fact, convergence test used Bidirectional A* detect optimalsolution similar convergence test used Anytime WA*: incumbent solutioncost f (incumbent) optimal unexpanded node f -cost lessf (incumbent) one two directions search, is, one two Open listsempty. interesting possibility improving bidirectional search use Anytime A*(instead standard A*) search directions.4.5 Local-search variants A*important class anytime search algorithms relies local search form iteratively improve solution. Although local-search algorithms cannot guarantee convergenceoptimal solution, scale much better systematic search algorithms.couple attempts improve scalability A* integratingform local search. Ratner Pohl (1986) propose two local-search variants A*improve suboptimal solution path making local searches around segments path.example, Joint A* divides initial suboptimal solution path segments, and,segment, uses A* search better path start end statessegment, reduce overall solution cost. Ikeda et al. (1999) propose K-group A* algorithm multiple sequence alignment performs A* groups sequences, insteadindividual sequences, order reduce search complexity number sequenceslarge find optimal alignments. varying groupings, local-search algorithmcreated gradually improves alignment computationally feasible way (Zhou &Hansen, 2004). But, like local-search algorithms, local-search variants A*guarantee convergence optimal solution.293fiHansen & Zhou5. Conclusionpresented simple approach converting heuristic search algorithm A*anytime algorithm offers tradeoff search time solution quality.approach uses weighted heuristic search find initial, possibly suboptimal solution,continues search improved solutions convergence provably optimalsolution. also bounds suboptimality currently available solution.simplicity approach makes easy use. also widely applicable.used search algorithms explore nodes best-first order,RBFS, shown effective solving wide range search problems.rule, effective whenever suboptimal solution found relatively quicklyusing weighted heuristic, finding provably optimal solution takes much longer.is, effective whenever weighted heuristic search effective. weightchosen appropriately, shown approach create search algorithmattractive anytime properties without significantly delaying convergence provablyoptimal solution. conclude anytime heuristic search provides attractive approachchallenging search problems, especially time available find solutionlimited uncertain.Acknowledgmentsgrateful Shlomo Zilberstein encouragement work, especiallyearly stages. appreciate helpful comments suggestions anonymousreviewers, led several improvements paper. also thank Rich Korfhelpful feedback RBFS algorithm. research supported part NSFgrant IIS-9984952 NASA grant NAG-2-1463.ReferencesBagchi, A., & Mahanti, A. (1983). Search algorithms different kinds heuristicscomparative study. Journal ACM, 30 (1), 121.Bagchi, A., & Srimani, P. (1985). Weighted heuristic search networks. Journal Algorithms, 6, 550576.Bonet, B., & Geffner, H. (2001). Planning heuristic search. Artificial Intelligence, 129 (1),533.Carillo, H., & Lipman, D. (1988). multiple sequence alignment problem biology.SIAM Journal Applied Mathematics, 48 (5), 10731082.Chakrabarti, P., Ghosh, S., & DeSarkar, S. (1988). Admissibility AO* heuristicsoverestimate. Artificial Intelligence, 34 (1), 97113.Davis, H., Bramanti-Gregor, A., & Wang, J. (1988). advantages using depthbreadth components heuristic search. Ras, Z., & Saitta, L. (Eds.), MethodologiesIntelligent Systems 3, pp. 1928.294fiAnytime Heuristic SearchDechter, R., & Pearl, J. (1985). Generalized best-first search strategies optimalityA*. Journal ACM, 32 (3), 505536.Gasching, J. (1979). Performance measurement analysis certain search algorithms.Ph.D. thesis, Carnegie-Mellon University. Department Computer Science.Hansen, E., Zilberstein, S., & Danilchenko, V. (1997). Anytime heuristic search: Firstresults. Tech. rep. 97-50, Univ. Massachusetts/Amherst, Dept. Computer Science.Hansen, E., & Zilberstein, S. (2001). LAO*: heuristic search algorithm finds solutionsloops. Artificial Intelligence, 129 (12), 3562.Hansson, O., & Mayer, A. (1990). Probabilistic heuristic estimates. Annals MathematicsArtificial Intelligence, 2, 209220.Harris, L. (1974). heuristic search conditions error. Artificial Intelligence,5 (3), 217234.Hart, P., Nilsson, N., & Raphael, B. (1968). formal basis heuristic determinationminimum cost paths. IEEE Transactions Systems Science Cybernetics (SSC),4 (2), 100107.Haslum, P., & Geffner, H. (2000). Admissible heuristics optimal planning. Proceedings5th International Conference Artifial Intelligence Planning Scheduling(AIPS-00), pp. 140149. AAAI Press.Ikeda, T., & Imai, T. (1994). Fast A* algorithms multiple sequence alignment.Genome Informatics Workshop 94, pp. 9099.Ikeda, T., & Imai, H. (1999). Enhanced A* algorithms multiple alignments: Optimalalignments several sequences k-opt approximate alignments large cases.Theoretical Computer Science, 210 (2), 341374.Kaindl, H., & Kainz, G. (1997). Bidirectional heuristic search reconsidered. JournalArtificial Intelligence Research, 7, 283317.Kobayashi, H., & Imai, H. (1998). Improvement A* algorithm multiple sequencealignment. Proceedings 9th Workshop Genome Informatics (GIW98),pp. 120130. Universal Academy Press, Inc.Koll, A., & Kaindl, H. (1992). new approach dynamic weighting. Proceedings10th European Conference Artificial Intelligence (ECAI-92), pp. 1617. JohnWiley Sons.Korf, R. (1985). Depth-first iterative deepening: optimal admissible tree search. Artificial Intelligence, 27 (1), 97109.Korf, R. (1990). Real-time heuristic search. Artificial Intelligence, 42 (23), 197221.Korf, R. (1993). Linear-space best-first search. Artificial Intelligence, 62 (1), 4178.295fiHansen & ZhouLikhachev, M., Gordon, G., & Thrun, S. (2004). ARA*: Anytime A* provable boundssub-optimality. Advances Neural Information Processing Systems 16: Proceedings 2003 Conference (NIPS-03). MIT Press.Long, D., & Fox, M. (2003). 3rd international planning competition: Resultsanalysis. Journal Artificial Intelligence Research, 20, 159.Pearl, J. (1984). Heuristics: Intelligent search strategies computer problem solving.Addison-Wesley.Pearl, J., & Kim, J. (1982). Studies semi-admissible heuristics. IEEE TransactionsPattern Analysis Machine Intelligence, PAMI-4 (4), 392399.Pemberton, J. (1995). k-best: new method real-time decision making. Proceedings14th International Joint Conference Artificial Intelligence (IJCAI-95), pp.227233. Morgan Kaufmann.Pohl, I. (1970a). First results effect error heuristic search. Machine Intelligence,5, 219236.Pohl, I. (1970b). Heuristic search viewed path finding graph. Artificial Intelligence,1 (3), 193204.Pohl, I. (1973). avoidance (relative) catastrophe, heuristic competence, genuine dynamic weighting computational issues heuristic problem-solving. Proceedings3rd International Joint Conference Artificial Intelligence (IJCAI-73), pp.1217. Morgan Kaufmann.Rao, V., Kumar, V., & Korf, R. (1991). Depth-first vs. best-first search. Proceedings9th National Conference Artificial Intelligence (AAAI-91), pp. 434440.AAAI/MIT Press.Ratner, D., & Pohl, I. (1986). Joint LPA*: Combination approximation search.Proceedings 5th National Conference Artificial Intelligence (AAAI-86),pp. 173177. AAAI/MIT Press.Russell, S., & Wefald, E. (1991). Right Thing: Studies Limited Rationality. MITPress.Sarkar, U., Chakrabarti, P., Ghose, S., & DeSarkar, S. (1991). Reducing reexpansionsiterative-deepening search controlling cutoff bounds. Artificial Intelligence, 50 (2),207221.Shimbo, M., & Ishida, T. (2003). Controlling learning process real-time heuristicsearch. Artificial Intelligence, 146 (1), 141.Wah, B., & Shang, Y. (1994). comparative study IDA*-style searches. Proceedings6th International Conference Tools Artificial Intelligence (ICTAI-94),pp. 290296. IEEE Computer Society.296fiAnytime Heuristic SearchYoshizumi, T., Miura, T., & Ishida, T. (2000). A* partial expansion large branching factor problems. Proceedings 17th National Conference ArtificialIntelligence (AAAI-2000), pp. 923929. AAAI/MIT Press.Zhou, R., & Hansen, E. (2002). Multiple sequence alignment using Anytime A*. Proceedings 18th National Conference Artificial Intelligence (AAAI-02), pp. 9756.AAAI/MIT Press.Zhou, R., & Hansen, E. (2004). K-group A* multiple sequence alignment quasinatural gap costs. Proceedings 16th IEEE International Conference ToolsArtificial Intelligence (ICTAI-04), pp. 688695. IEEE Computer Society.Zilberstein, S. (1996). Using anytime algorithms intelligent systems. AI Magazine, 17 (3),7383.297fiJournal Artificial Intelligence Research 28 (2007) 119156Submitted 04/06; published 02/07Marvin: Heuristic Search PlannerOnline Macro-Action LearningAndrew ColesAmanda SmithANDREW. COLES @ CIS . STRATH . AC . UKAMANDA . SMITH @ CIS . STRATH . AC . UKDepartment Computer Information Sciences,University Strathclyde,26 Richmond Street, Glasgow, G1 1XH, UKAbstractpaper describes Marvin, planner competed Fourth International PlanningCompetition (IPC 4). Marvin uses action-sequence-memoisation techniques generate macroactions, used search solution plan. provide overviewarchitecture search behaviour, detailing algorithms used. also empirically demonstrateeffectiveness features various planning domains; particular, effects performance due use macro-actions, novel features search behaviour, nativesupport ADL Derived Predicates.1. IntroductionOne currently successful approaches domain-independent planning forwardchaining heuristic search problem state space. Search guided heuristic functionbased appropriate relaxation planning problem. Different relaxations explored (Bonet & Geffner, 2000; McDermott, 1996; Hoffmann & Nebel, 2001; Helmert, 2004)shown result less informative heuristic functions. common relaxationignore delete lists actions problem domain, resulting abstracted problemdomain comprised relaxed actions. given state evaluated counting numberrelaxed actions needed reach goal state given state. Hoffmann Nebel (2001)present search strategy called Enforced Hill-Climbing (EHC) which, coupled relaxationkind, proven empirically effective strategy many planning domains.planner, FF, performed great success Second Third International Planning Competitions (Bacchus, 2001; Long & Fox, 2003). paper present planner, Marvin,builds upon search approach.EHC search strategy performs gradient-descent local search, using breadth-first searchfind action sequences leading strictly-better states single-action step able reachone. embedded exhaustive-search step one bottlenecks planning approach.present approach that, memoising plateau-escaping action sequences discoveredsearch, form macro-actions applied later plateaux once-againencountered. so, planner escape similar plateaux encountered later, withoutexpensive exhaustive search. resulting planner called Marvin.begin paper brief review FFs search behaviour provide backgroundapproach. introduce main features Marvin, explaining search behaviourdiffers FF. describe three main contributions made Marvin, detailingc2007AI Access Foundation. rights reserved.fiC OLES & MITHkey algorithms effects performance. Marvin plan STRIPS ADL domains,also handle derived predicates PDDL2.2. describe way domainscontaining derived predicates ADL handled without first reduced STRIPS domains.Finally, discuss results obtained Marvin Fourth International Planning Competition(IPC 4) (Hoffmann & Edelkamp, 2005), provide additional ablation studies assess impactvarious features planning performance across selection domains.2. Backgroundsection, give overview background work. First, forward-chaining heuristic planning defined, existing work area described; particular attention paidplanner FF. followed introduction macro-actions.2.1 Forward-Chaining PlanningFormally, forward-chaining planning described search landscapenode defined tuple < S, P >. world state comprised predicate facts Pplan (a series ordered actions) used reach initial state. Search begins initialproblem state, corresponding tuple < S0 , {} >.Edges pairs nodes search landscape correspond applying actions leadone state another. action applied search space node < S, P > node< 0 , P 0 > reached, 0 result applying action state P 0determined appending action P . Forward-chaining search landscaperestricted considering moves forwards direction: transitions ever madenode plan P nodes plan P 0 P 0 determined adding (or chaining)actions end P .unguided search manner prohibitively expensive smallest problems,heuristics used guide search. Commonly, heuristic value used provide goal distanceestimate node < S, P > node < 0 , P 0 > 0 goal state.2.2 Heuristics Forward-Chaining PlanningMany heuristics used guide forward-chaining planners based around solving abstraction original, hard, planning problem planner presented. widelyused abstraction involves planning using relaxed actions, delete effects originalactions ignored. FF, HSP (Bonet & Geffner, 2000) UnPOP (McDermott, 1996) use relaxedactions basis heuristic estimates, although FF first count numberrelaxed actions relaxed plan connecting goal initial state. Although ignoring deletelists turns powerful relaxation, least class planning domains, relaxationspossible. recently, work done using abstraction based causal graph analysis(Helmert, 2004).initial approaches calculating goal distance estimates, taken planners HSP,calculated cost reaching goal state state evaluated forwardsreachability analysis state given goal appears. Two heuristics derivedinformation: either maximum steps-to-goal valuesan admissible heuristic;sum steps-to-goal valuesan inadmissible heuristic, practice informative.120fiM ARVIN : H EURISTIC EARCH P LANNER NLINE ACRO -ACTION L EARNING1:2:3:4:5:6:7:8:9:10:11:12:13:14:15:16:17:18:19:20:Procedure: EHCSearchopen list = [initial state];best heuristic = heuristic value initial state;open list emptycurrent state = pop state head open list;successors = list states visible current state;successors emptynext state = remove state successors;h = heuristic value next state;next state goal statereturn next state;endh better best heuristicclear successors;clear open list;best heuristic = h;endplace next state back open list;endendFigure 1: Enforced Hill-Climbing Searchdisadvantage latter approaches ignores positive interactions (sharedactions) action sequences goal: problem addressedheuristic used FF. FF, planning graph (Blum & Furst, 1995) built forward currentstate using relaxed actionsthis known relaxed planning-graph (RPG). relaxed plan (oneusing relaxed actions) achieve goal state extracted RPG polynomial time;number actions plan used provide heuristic value. Graphplanprovide guarantee plan found contain optimum number sequentialised actions(only optimum makespan) heuristic returned inadmissible, practiceheuristic informative used previously.2.3 Enforced Hill Climbing SearchAlong heuristic based relaxed planning graphs, FF introduced Enforced Hill Climbing(EHC) algorithm, illustrated Figure 1. EHC based commonly used hill-climbing algorithm local search, differs breadth-first search forwards global optimumused find sequence actions leading heuristically better successor none presentimmediate neighbourhood.key bottleneck using EHC search heuristic cannot provide sufficient guidance escape plateau1 single action step, breadth-first search used suitableaction sequence found. Characteristically, EHC search consists prolonged periods exhaustive search, bridged relatively quick periods heuristic descent.1. work, plateau defined region search space heuristic values successorsgreater equal best seen far.121fiC OLES & MITHpractice, EHC guided RPG heuristic effective search strategy numberdomains. Work done (Hoffmann, 2005) analysing topology local-searchlandscape investigate effective heuristic, well identifying situationsweak.2.4 Exploiting Structure Relaxed Planactions relaxed plan goal given state used provide searchadvice. YAHSP (Vidal, 2004), planner produced interesting results Fourth InternationalPlanning Competition (IPC 4), makes use actions relaxed plan suggest actions addcurrent plan reach goal. FF, notion helpful actions definedthose addfact added action chosen first time unit relaxed plan. state encounteredsearch, number actions applicable, irrelevant; i.e. makeprogress towards goal. considering helpful actions determining successorsstate, performing EHC, number successor states evaluated reduced.Restricting choice actions apply helpful reducescompleteness EHC, beyond would case applicable actions considered.practice observed, however, cases EHC using helpful actions unablefind plan correlate cases EHC applicable actions would unablefind plan.2.5 Guaranteeing Completeness FFFF first attempts search solution plan performing Enforced Hill-Climbing (EHC) searchinitial state towards goal state. discussed earlier, EHC uses hill-climbing localsearch guided RPG heuristic strictly-better successor found. soonstrictly better successor found, FF entered plateau, breadth-first search usedimproving state found. directed search spaces, EHC lead search processwrong direction dead-ends; i.e. open list empty, goal state found.cases FF resorts best-first search initial state, thereby preserving completeness.2.6 Macro-Actions Planningmacro-action, used planning, meta-action built sequence action steps.forward-chaining planning, applying macro-action state produces successor corresponding application series actions. way, use macro-actions thoughtextending neighbourhood successors visible state selectively introducestates hitherto would visible application several steps. additional states introduced chosen effectively, increase planner performance realised;whereas additional states chosen poorly, performance planner decreases dueincreased branching factor.use macro-actions planning widely explored. techniques use off-linelearning approach generate filter macro-actions using search. Early workmacro-actions began version STRIPS plannerknown ABSTRIPS (Fikes & Nilsson, 1971)which used previous solution plans (and segments thereof) macro-actions solvingsubsequent problems. MORRIS (Minton, 1985) later extended approach adding filter122fiM ARVIN : H EURISTIC EARCH P LANNER NLINE ACRO -ACTION L EARNINGing heuristics prune generated set macro-actions. Two distinct types macro-actionsidentified approach: S-macrosthose occur frequently searchand T-macrosoccur less often model weakness heuristic. Minton observedT-macros, although used less frequently, offered greater improvement search performance.REFLECT system (Dawson & Siklossy, 1977) took alternative approach forming macroactions based preprocessing domain. sound pairwise combinations actionsconsidered macro-actions filtered basic pruning rules. Due small sizedomains planner reasoning, number macro-actions remaining following process sufficiently small use planning.recent work macro-actions includes Macro-FF (Botea, Enzenberger, Muller,& Schaeffer, 2005). Macro-actions extracted two ways: solution plans;identification statically connected abstract components. offline filtering technique usedprune list macro-actions. Another recent approach macro-action generation (Newton,Levine, & Fox, 2005) uses genetic algorithm generate collection macro-actions,filters collection offline filtering technique similar used Macro-FF.3. Marvins Search BehaviourMarvins underlying search algorithm based used FF: forward-chaining heuristic searchusing RPG heuristic. However, Marvin includes important modifications basic FFalgorithm. are: least-bad-first search strategy exploring plateaux, greedy best-firststrategy searching EHC fails development use plateau-escaping macroactions.FF first approach finding solution plan perform EHC search using helpfulactions. first successor heuristic strictly better best far taken, onefound. one found, plateau encountered, form best-first search usinghelpful actions used (instead breadth-first search FF) try find action sequenceescape it. states plateau never improve heuristic value noderoot plateau, call least-bad-first search.EHC approach unable find plan, Marvin resorts modified form best-firstsearch using actions applicable state. expands first strictly better successorwhilst keeping current state expansion later necessary. call strategy greedybest-first search. seen graphs Section 6.2, IPC 4 domainsmodifications enable solution problems unsolvable best-first search.EHC search strategy, Marvin uses plateau-escaping macro-actions learnedprevious searches similar plateaux. applied way atomic actionstraverse plateaux single step. Plateau-escaping macro-actions learned online plannermust decide ones likely applicable points search. Section 6.5show plateau-escaping actions yield performance benefits. power dependsstructure search space ability planner learn re-usable macro-actions.Least-bad-first search plateaux, greedy best-first search plateau-escaping macro-actionsthree main features Marvin distinguishing basic search strategyforward heuristic search-based planners. discuss three features detail going describe exploited context ADL domains domainsinvolving derived predicates.123fiC OLES & MITH565556556444434Figure 2: Least-bad-first search versus breadth-first search plateau. Black nodesexpanded breadth-first search. Dotted blue/grey nodes expandedbreadth-first least-bad-first search. Solid blue/grey nodes expandedleast-bad-first search. seen least-bad-first search leads better exit nodebreadth-first search.3.1 Least-Bad-First Search Plateauxplateau encountered successor nodes given current node heuristicvalue as, worse than, current node. notion best contextrelates successor heuristic value closest parent state. calledleast-bad-first search chosen successor make heuristic progress, choicesless negative others. successor chosen least-bad-first search least negativeimpact current state therefore likely best path goal.breadth-first search used, exit state reached might goal exitstate reached state least negative impact always expanded next.Figure 2 show order states explored using least-bad-first search relativebreadth-first search. observed that, using least-bad-first search, exit state reachedbetter heuristic value reached using breadth-first search FF. expectedsometimes leads better quality plans found. results Section 6.3 show that,indeed, using least-bad-first search sometimes find shorter plans FF finds using standardbreadth-first strategy plateaux.3.2 Greedy Best-First Search EHC FailsFF, Marvin resorts best-first search EHC proves unable find solution. approachmaintains completeness planner cases use EHC helpful actionswould otherwise render search incomplete. Two planners IPC 4 used variationsbest-first search algorithm, YAHSP (Vidal, 2004) Fast-Downward (Helmert, 2006). UnlikeMarvin, however, two planners incomplete search step (such EHC)using modified best-first search algorithm. YAHSP, conventional WA* search used withinsearch queue, states reached applying helpful action parent state orderednot. Fast-Downward, deferred heuristic evaluation strategy used,124fiM ARVIN : H EURISTIC EARCH P LANNER NLINE ACRO -ACTION L EARNINGstates inserted search queue heuristic value parent state; actualheuristic cost state calculated state expanded.Marvin best-first strategy modified greedily expanding first successor foundbetter heuristic parent state, retaining parent remaining childrenevaluated later necessary. effect similar approach taken Fast-Downward,would lead nodes search space visited order. approach takenMarvin, however, allows smaller search queue maintained, nodes necessarilyinserted search queue successor node reachable state.Whenever successor state generated evaluated (by calculating heuristic value), onetwo things happens:successor heuristic better parent, successor placed frontsearch queue, parent state behind (along counter variable, notingmany successors already evaluated); search loop restartedsuccessor state.successor heuristic better parent, successor insertedsearch queue appropriate place (stable priority-queue insertion, ordered heuristicvalue). process carries evaluating successors parent state.pseudo-code seen Figure 3. approach inspired idea takingfirst strictly-better successor performing EHC search, benefit numberheuristic evaluations performed potentially reduced considering fewer successorsstate. differs EHC that, maintain completeness, parent state discardeditplaced back queue successors evaluated later necessary. Theoretically,EHC search given problem encounter plateaux, pruning selectinghelpful actions ignored, using greedy best-first search problem would visitnumber nodes evaluate number successors. plateau encountered, however, search behaviour would differ EHC would consider states reachablestate start plateau.Another effect greedy best-first search search focusses exploring givendirection. described, soon successor node found heuristic value betterparent, expansion parent node postponed successornode expanded. practical consequence search queue containequally good successors, search forward successor state sidetrackedalso search forward sibling states. parent node re-visited,sibling nodes added, proves heuristically wise sothat is, searchingforward successor node making heuristic progress.3.3 Plateau-Escaping Macro-ActionsDue nature relaxed problem used generate RPG heuristic aspectsoriginal problem captured. Thus, RPG heuristic used perform EHC,plateaux often encountered. plateaux, RPG heuristic value successor statesas, worse than, heuristic value current state. nature plateauxencountered, whether EHC able find path escape them, influencedproperties planning domain (Hoffmann, 2001).125fiC OLES & MITH1:2:3:4:5:6:7:8:9:10:11:12:13:14:15:16:17:18:19:20:21:22:23:24:25:26:27:28:29:30:Procedure: GreedyBFSinsert (state=initial state, h=initial heuristic, counter=0) search queue;search queue emptycurrent queue entry = pop item front search queue;current state = state current queue entry;current heuristic = heuristic current queue entry;starting counter = counter current queue entry;applicable actions = array actions applicable current state;index ?i applicable actions starting countercurrent action = applicable actions[?i];successor state = current state.apply(current action);successor state goalreturn plan exit;endsuccessor heuristic = heuristic value successor state;successor heuristic < current heuristicinsert (current state, current heuristic, ?i + 1) front search queue;insert (successor state, successor heuristic, 0) front search queue;break for;elseinsert (successor state, successor heuristic, 0) search queue;endendendexit - plan found;Figure 3: Pseudo-code greedy best-first search126fiM ARVIN : H EURISTIC EARCH P LANNER NLINE ACRO -ACTION L EARNINGIgnoring delete effects pickup action Gripper domain creates problemwhich, given state, possible pick many balls using one gripper, long gripperinitially available: delete effect action, marking gripper longer available,removed. relaxed plan initial problem state pickup balls one gripper,move next room, drop all. length plan, heuristic valueinitial state, n + 1 + n, 2n + 1 (where n number balls). If, initial state, ballpicked using one grippers, relaxed plan resulting state pickupremaining balls gripper, move second room drop all;length (n 1) + 1 + n, 2n, less heuristic value initial stateaction chosen one apply.next state, however, start plateau. actions applicable (thosepreconditions satisfied) either drop ball picked up, pickupanother ball move next room. correct action would pickup another ball:relaxed plan goal state resulting state would drop one balls, pickupremaining balls newly-freed gripper, move next room, drop balls.However, heuristic value state would 1 + (n 2) + 1 + n, 2n, valuestate action applied. Moving next room would produce stateheuristic value 2n (move initial room, pickup remaining (n 1) balls, dropballs final roomno move action required move back room robot alreadyvisited). Dropping one balls would also produce state heuristic value 2n (pickupremaining (n 1) balls newly-freed gripper, move next room, drop balls).successor states RPG heuristic value parent state, heuristic unableprovide useful guidance action apply.exhaustive search forward point, improvement heuristic valuemade two ways: either move next room drop ball, pickup ballmove next roomboth lead heuristic values (2n 1). plateau will,however, encountered time robot first room, holding one ball, actionchoices either pickup another ball move next room (or drop ball). timeplateau encountered, action sequence escape plateau identicalmove-droppickup-move (in EHC actual sequence chosen depend order actionsconsidered planner). discover one action sequences exhaustivesearch time plateau encountered considerable bottleneck search process:true general many domains.order address overhead caused recurrent plateaux search space, Marvin memoises action sequences used escape previously encountered plateaux; action sequences used form called Plateau-Escaping Macro-Actions. macro-actiongenerated action sequence using code presented Figure 4. step actionsequence considered turn, abstract action step made replacing entitiesgiven parameters action placeholder identifiersone distinct entity.placeholder identifiers form parameter list macro-action; recorded abstractaction steps dictate component actions macro-action built.Returning pickup-move action sequence, action sequence:0: pickup robot1 ball2 room11: move robot1 room1 room2127fiC OLES & MITHwould form macro-action:pickup-move (?a - robot) (?b - ball) (?c - room) (?d - room)0: pickup ?a ?b ?c1: move ?a ?c ?dmacro-action instantiated specifying parameters ?a ?d, resultingsequence actions. example, (pickup-move robot1 ball3 room1 room2) would giveaction sequence:0: pickup robot1 ball3 room11: move robot1 room1 room2Marvin, preconditions steps within macro-action collected givesingle precondition formula macro-action. Instead, instantiated macro-action saidapplicable given state first component action macro-action applicable,subsequent actions applicable relevant resulting states.built macro-actions plateau-escaping action sequences, searchlater attempting escape plateau, macro-actions available application. plateauarose due weakness heuristic led earlier plateau, macro-actionsable lead search strictly better state skipping intermediate states.plateau-escaping macro-actions used search attempting escape plateauxavoids slowing search RPG heuristic able provide effective guidance usingsingle-step actions.reduce number macro-actions considered, blow-up size exploredsearch space would otherwise occur, macro-actions considered containingactions first time step helpful actions current state.3.4 Macro-Actions Usestructure reusability macro-actions depends underlying topology problemspace given heuristic function. problem space contains many similar occurrencesplateaux (which happens problem contains much repeating structure) effortinvolved learning macro-actions escape plateaux efficiently richly rewarded.principle, benefit obtained problem space features large, frequently recurringplateaux, since large plateaux time-consuming explore effort would needrepeated every similar occurrence. Short macro-actions (of two three actions) indicateproblem space contains small plateaux (although might arise frequently enoughlearned macro-actions still beneficial).Problems repeating structure include: transportation problems, basic sequences actions repeated move groups objects sources destinations; construction problems, many similar components need built combinedfinished artifact; configuration problems, multiple components architectureneed go similar processes complete functions, etc. Dining PhilosophersTowers Hanoi problems good examples problems repeating structure.Although using macro-actions search advantagesthey offer search guidanceallow many actions planned one stepconsidering expansion128fiM ARVIN : H EURISTIC EARCH P LANNER NLINE ACRO -ACTION L EARNING1:2:3:4:5:6:7:8:9:10:11:12:13:14:15:16:17:18:19:20:21:22:23:24:25:Procedure: BuildMacroparameters = [];parameter types = [];abstract steps = [];parameter count = 0;action ?a action sequence used escape plateauabstract parameters = [];parameter ?p ?a?p parametersindex = parameter index ?p parameters;append (index) abstract parameters;elseparameters[parameter count] = ?p;parameter types[parameter count] = type ?p;append (parameter count) abstract parameters;increment parameter count;endendappend (action type ?a, abstract parameters) abstract steps;endreturn parameter types abstract steps macro-actionFigure 4: Pseudo-code building macro-actions plan segments129fiC OLES & MITHstate increases branching factor. Thus, large number unproductive macro-actionsgenerated search space become larger, making problem harder, easier, solve.Whilst many plateau-escaping sequences helpful planning, specificsituation derived, situation might occur plan. macroactions learnt planning processand human intuition, large test suite,allow reusable macro-actions identifiedcare must taken deciding pointsconsider use planning process.Plateau-escaping macro-actions generated situations heuristic brokendown; therefore, heuristic used indicator likely usefulplanning. areas repeating structure within solution plan involve applicationsimilar (or identical) sequences actions, likely similar heuristic profiles.case plateau-escaping action sequences, heuristic profile search landscapeapplication initial increase (or no-change) heuristic value, eventually followed fallinitial levelthe profile occurring local minimum. plateau-escaping macroactions reusable, likely re-use occur planning processsimilar situation. such, considered application exhaustive search stepused escape plateaux (both start point plateau).Situations may arise use macro-actions increases makespan resultingplan due redundant action sequences. example, simple game domainwith actionsmove up, down, left right macro-action formed left, left, left, left optimalaction sequence escape given plateau left, left, left {left, left, left, left}, right maychosen state reached moving left four times heuristically better one reachedapplying single-step left action. Thus, macro-actions adverse effect plan quality.Within problem domains presented IPC 4 (Hoffmann & Edelkamp, 2005) encoding Dining Philosophers problem, translated Promela PDDL encoding.solving problem, two important macro-actions formed: eleven-step macro-action uponcompletion first period exhaustive search; three-step macro-action upon completionsecond. solution plan requires macro-actions repeated many times, something nowas result macro-actionsinvolves simply applying single actionresults strictly better state. Without macro-actions, planning process consists repeatedepisodes exhaustive search find two sequences actions time.behaviour seen Figure 5 depicting heuristic values states generatedwithout macro-actions, across solution plan IPC 4 Dining Philosophers probleminvolving 14 philosophers. Initially, macro-actions learnt search doneapproaches identical. first 14 action choices value heuristic, shown linegraph, moves monotonically downwards planner able find actions applylead strictly better states.time step 14, heuristic value begins oscillate, point planner reachedplateau: state strictly better heuristic value reached applicationone action. first plateau reached, macro-actions generatedheuristic profiles identical configurations. time step 25 state reachedbetter heuristic value time step 14. time plateau-escapingmacro-action generated, memoising lifted version sequence actions usedescape plateau. brief period search strictly better state foundchoice point follows planner hits plateau.130fiM ARVIN : H EURISTIC EARCH P LANNER NLINE ACRO -ACTION L EARNING403530Heuristic252015105Without Macro-ActionsMacro-Actions0020406080100120Plan Time StepFigure 5: Heuristic landscape makespan, without macro-actions.subsequent six plateaux consist applying sequence actions sixpairs philosophers; seen heuristic fingerprints plateaux identical.version Marvin macro-actions disabled repeats expensive exhaustivesearch plateau: heuristic value goes process increasingdecreasing reaching strictly-better state. version using plateau-escapingmacro-actions, however, single action apply achieves strictly better statesearch continues, stepping subsequent plateaux selection macro-actionsyield strictly-better states.larger plateaux overcome, series smaller plateaux encountered. Again, seen first these, versions must complete stageexhaustive search; however, first smaller plateaux completed, macroaction formed allows subsequent plateaux bypassed. Finally, plan finishes shortpreviously unseen sequence actions, versions must exhaustive search.4. Handling ADLPDDL (McDermott, 2000) (the Planning Domain Definition Language) first defined useFirst International Planning Competition (IPC 1) AIPS-98. subsequent competitions,modifications made language planning technology evolved.first three competitions, domains available STRIPS (Fikes & Nilsson,1971) actions used. STRIPS actions conjunctive predicate preconditions, add effects,delete effects defined terms action schema parameters constant entities. determinepreconditions effects given ground action instance (an action whose parametersbound specific entities) actions parameters substituted schema. actionapplicable given state, precondition predicates must hold state; actionapplied, new state generated previous state removing predicates presentdelete effect list adding add effect list..131fiC OLES & MITHADL action schemata (Pednault, 1989) extend syntax STRIPS action schemata. ADLdomains language used describe preconditions action extended allow disjunctive, quantified negative preconditions well conjunctive preconditions usedSTRIPS domains. syntax describing effects actions also extended allowconditional effectseffects applied whenever given condition holds.extended syntax provided ADL increases convenience domainencoded, also reduce size domain descriptions needed. example,action schema has, precondition (or B C) then, without ADL, three copies actionschema would need made: one precondition (A), one precondition (B) oneprecondition (C). one willing tolerate increases domain-description size,number objects domain finite, possible compile given ADL domainproblem-instance pair domain-problem pair containing STRIPS actions: general,compilation must done problem instance, ADL domain.ability compile ADL domains STRIPS domains first demonstrated compilationprocedure devised Gazen Knoblock (1997). Using techniques preprocessing stage,FF able handle domains containing ADL actions whilst reasoning STRIPS actionsinternally. output FFs preprocessor stage made available IPC 4 allow plannerscould handle ADL directly solve compiled STRIPS formulations problemsloading compiled domain-problem pair original problem instances givendomain.Whereas previous competitions ADL domains simplified manually reformulatedproduce STRIPS domains, STRIPS domains IPC 4 compiled automaticallyADL. compilation used, based preprocessor FF, results compiled domain-problempair original problem instance. compilation explicitly grounds many originalactions, producing one compiled action schema (with preconditions effects whose parametersrefer PDDL constants) per ground action could arise original ADL problem. Whilstcompilations produce STRIPS domains allow planning performed, replacegeneral action schemata sets specific action instances.allow new features Marvin used competition, Marvin extendedinclude native support ADL. reasoning original ADL domain able effectivelyabstract macro-actions action sequences.4.1 Preconditions ADL Actionspreconditions STRIPS actions consist one structural feature - clause, allowingconjunctive preconditions predicates constant parameterised bindings. ADL actionsfar greater range structural features preconditions. allow or, imply,not, forall exists, combined well-formed manner. Marvin, ADLpreconditions processed using two steps. First, quantified preconditions fully enumerated.Second, resulting precondition formula translated Negation Normal Form (NNF) usingstandard procedure: replacing (a b) (a b), using De Morgans lawseliminate negations clauses. reductions applied eliminate redundancy,replacing (and (and B C)) (and B C), (or (or B C)) (or B C).Internally, within Marvin, NNF precondition formula forms basis satisfaction tree,nodes elements formula literals (negated non132fiM ARVIN : H EURISTIC EARCH P LANNER NLINE ACRO -ACTION L EARNINGnegated) form leaves. structure satisfaction tree given action schema fixed,although propositions leaves vary groundings.determine ground ADL action instances applicable given state basedpreconditions, algorithm shown pseudo-code fragment Figure 6 used. Initially,satisfaction counters associated ground actions satisfaction tree nodes reset usingfollowing rules:nodes counter set denote number children has.node counter set 1.Negative preconditions assumed true, satisfaction counters parentsdecremented accordingly.values state-independent, reasons efficiency values used reset satisfaction counters computed cached later use.reset satisfaction counters, proposition current state considered,satisfaction trees updated accordingly:satisfaction counters parent nodes current proposition negative precondition incremented.satisfaction counters parent nodes current proposition positive precondition decremented.Then, propagating effects truth value changes upwards tree, actionwhose root node sufficiently many children satisfied applicable.4.2 Effects ADL ActionsADL extends action definitions STRIPS actions allowing quantified conditional effects. preconditions, former dealt enumeration; latter dealt depending conditions.conditional effect dependent static predicates possible determinegrounding action whether applies instance: static informationchange state state. effect depends dynamic predicates, necessary consider,state, whether effect applies. achieve this, effect conditions usedform sub-action. sub-action conditional effects condition preconditions,conditional effect effects. conditional effects nested originaloperator schemata, sub-actions may also conditional effects; casesub-action-creation step applied recursively, creating nested sub-actions necessary.applicability ground sub-actions given state performed mannernormal actions. action applied, sub-actions also applicable appliedalongside it, thereby preserving conditional effects original operator.4.3 Modifying Relaxed Planning Graphnecessary modify Relaxed Planning Graph expansion plan-extraction phases makepossible apply heuristic domain contains ADL actions. Work done133fiC OLES & MITH1:2:3:4:5:6:7:8:9:10:11:12:13:14:15:16:17:18:19:20:21:22:23:24:25:26:27:28:29:30:31:32:33:34:35:36:37:38:39:40:41:42:43:44:45:Procedure: test-action-applicabilityreset satisfaction counters();predicate ?p state(ground action ?a, tree node ?c) pair ?p negative precondition child nodetree node update = ?c;tree node update still validold value = value tree node update;value tree node update = old value + 1;value tree node update > 0 && old value = 0tree node update = parent tree node update;elsetree node update = invalid;endendend(ground action ?a, tree node ?c) pair ?p positive precondition child nodetree node update = ?c;tree node update still validold value = value tree node update;value tree node update = old value -1;value tree node update = 0 && old value > 0tree node update = parent tree node update;elsetree node update = invalid;endendendendapplicable actions = ;ground action ?aroot tree node satisfiedadd ?a applicable actions;endendFigure 6: Pseudo-code action applicability testing134fiM ARVIN : H EURISTIC EARCH P LANNER NLINE ACRO -ACTION L EARNINGextending full graphplan planning graphs reason subset ADL actions (Koehler, Nebel,Hoffmann, & Dimopoulos, 1997); approach taken Marvin extends relaxed planning graphstructure handle available ADL constructs. effect modificationsheuristic estimate obtained precompiled STRIPS domain formulation used.building conventional relaxed planning graph assumption made that, firstfact layer, facts present state evaluated true facts are, implicitly,false. Facts gradually accumulated application actions, add effects adding factsspike (Long & Fox, 1999). Actions become applicable preconditions present;i.e. accumulated. STRIPS actions used build conventional relaxedplanning graph necessarily negative preconditions, sufficient consider factspositive truth value determine action applicability this. ADL actions, however,also negative preconditions, corresponding facts must false. Within conventionalrelaxed planning graph, record made whether possible given fact negativetruth value.handle negative facts within relaxed planning graph used Marvin, second spikeadded. positive-fact spike, facts present state evaluated truefacts are, implicitly, false. However, unlike positive-fact spike, facts graduallyeroded applications actions; delete effects marking fact negativefact spike deleted. inherent relaxation relaxed planning graphfounded still preserved, though: delete effects effect positive-fact spike; and,similarly, add effects effect negative-fact spike.precompiled STRIPS domain formulation used, additional complimentary propositionsadded denote proposition true. accumulate alongside originaldomain propositions, way able satisfy negative preconditions. negative factspike, discussed, effect, although rather recording propositionsavailable negated form layer, records propositions available negatedform.discussed, ADL action preconditions preprocessed negation appliedleaves satisfaction tree; i.e. applied unit facts forming part actionsprecondition structures. Within relaxed planning graph given fact leaf markedsatisfied either one following holds:positive fact leaf, fact contained therein added positive-factspike.negative fact leaf, fact contained therein either never negativefact spike since marked deleted.Plan graph construction proceeds manner similar used build conventional relaxedplanning graph. newly present newly deleted facts considered turn,effects applicability available actions noted. updating satisfaction treeaction lead becoming applicable:action added action spike, available next fact layer.Previously unseen add effects added positive-fact spike, available next factlayer.135fiC OLES & MITHDelete effects deleting fact still present negative-fact spike mark factdeleted available satisfy negative preconditions next fact layer.efficiency, first action achieve fact stored added positive-factspike, along earliest layer action applicable. Similarly, first actiondeletes fact ever negative-fact spike noted. Relaxed plan extractionconsists regressing layers relaxed planning graph, selecting actions achievegoals achieved layer. Initially, proposition goal state addedlayer goals layer first appears (or disappears, case negative goals).extract plan, next goal repeatedly taken deepest action layer outstandinggoals. first achieving action added plan preconditions, taken satisfactiontree, added goals first layer appear. process finishesoutstanding goals layer. sub-action (that is, action created representconditional effect ADL action, see Section 4.2) chosen achieve given proposition,preconditions parent action(s) also added goals first layerappear.considering adding preconditions achieving action layerappear, collection disjunctive preconditions may arise. situation, first satisfied precondition negative precondition disjunction added subgoal earlier layer.avoids adding many redundant actions satisfy disjunctive preconditions,one needs satisfied. precondition chosen satisfied collection disjunctive preconditions first achiever found building relaxed planninggraph, thus providing heuristic estimate compiled STRIPS domain formulationused. compiled STRIPS domain formulation, disjunctive precondition would giverise several action instantiations; first applicable would chosen achieverdesired fact.start planning process, relaxed planning graph constructed forwardinitial state. However, rather stopping goal literals appear, graph construction stopsground actions become applicable. actions propositions appearingrelaxed planning graph superset actions propositions appearing later relaxedplanning graphs: actions propositions discovered used form cache detailingpropositionaction dependencies. Using cached information, code shown Figure 6used determine actions applicable given state, relaxed planning graphsused calculate heuristic values extracted efficiently.5. Handling Derived PredicatesIPC 4, PDDL extended addition Derived Predicates (Hoffmann &Edelkamp, 2005). Derived Predicates, used three competition domains, allow higherlevel concepts recursively derived propositions. derived predicatespresent preconditions actions, allow higher-level concepts domain reasoned with. example, BlocksWorld domain, derivation rule predicatefollows:(:derived (above ?x ?y)(or (on ?x ?y) (exists (?z) (and (on ?x ?z) (above ?z ?y)))))136fiM ARVIN : H EURISTIC EARCH P LANNER NLINE ACRO -ACTION L EARNINGplanner include native support derived predicates, possible compiledomains containing derived predicates flattened domains not. However, possible without super-polynomial increase size domain solution plan(Nebel, Hoffmann, & Thiebaux, 2003). IPC 4, compiled versions domains containedderived predicates made available competitors could support derived predicates.However, sizes problems could compiled restricted concomitant sizesPDDL files produced compilation process computational effort necessarysolve compiled problems.IPC 4 first planning competition make use derived predicates domains.shown derived predicates cannot reasoned efficiently compilation(Nebel et al., 2003) steps taken provide native support Marvin.also possible compile derived predicates appearing domains adding actionsinstantiate derived predicates as-needed basis (Gazen & Knoblock, 1997). Usingcompilation, derivation rule blocksworld problem described wouldcompiled following action:confirm ?x ?ypre: (or (on ?x ?y) (exists (?z) (and (on ?x ?z) (above ?y ?z))))add: (above ?x ?y)used domain compilation, original actions domain mustextended delete propositions, forcing confirm actions usedre-achieve preconditions action requires them. case, actiongiven additional effect:(forall (?x ?y) (not (above ?x ?y)))Although effective STRIPS domains, possible use compilation domainsmaking use negative preconditions re-derivation derived predicates occurring negativepreconditions actions enforced. example, action could applied modifiespropositions, leading state number additional properties couldderived. Deleting propositions necessary step, confirm actionsre-assert derived predicate action needs it. However, (above ?x ?y) deleted,(not (above ?x ?y)) true, used action precondition. deal issuenecessary prevent non-confirm actions applied possible derived predicatesre-asserted; prevents actions applied giventemporarily true, i.e. whilst yet re-derived. force re-derivation derivedpredicates, dummy predicates actions must added domain. necessarycompilation results large increase size search space explored, additionaldummy actions affect usefulness relaxed-planning-graph heuristic.problems using Gazen & Knoblock compilation arise solely because, originalform, force applicable confirm actions applied original actionapplied. such, planner generates confirm actions internally dealsappropriately, compilation still form basis effective means handling derivedpredicates.137fiC OLES & MITHend, presented domain containing derived predicates, Marvin machinegenerates confirm actions extends (original) action delete derived predicates,described. action applied, propositions directly recursively derivedresulting state instantiated applying applicable confirm actions. Alongavoiding unwieldy compilation domains negative preconditions, handling confirmactions internally manner provides performance improvements two reasons:confirm actions automatically applied appropriate, Marvinsearch perform heuristic evaluation discover next action requiredconfirm action.Confirm actions included alongside normal actions relaxed planning graph builtstate, used relaxed plan contribute towards heuristic valuetaken length, eliminating noise would otherwise add.6. Resultsplanning competition offers great opportunity assessing relative performance varioustechniques used planning wide range problems. Inevitably will, however,features tested set domains used competition. alsodomains many features planner collaborate produce good results, ratherresults directly attributable one individual feature. discuss resultscompetition present results clarify features Marvin contributeperformance particular case.important note refer macro-actions generated used Marvingenerated planning process specific problem. additional learning timeknowledge gained solving problems used Marvin competition,producing additional results presented paper. Although planners use additionallearning time solving series problems, satisfactory way incorporate extra timetime taken solve problem, measured planning competition, yetfound. planning competition planners compared based performanceisolated problem instances, still interesting comparison make.results presented produced two machines: machine University Strathclyde (with 3.4GHz Pentium 4 processor) IPC 4 competition machine (with 3GHz Xeonprocessor). cases, planner subjected 30 minute time limit 1Gb memoryusage limit. results directly compared (i.e. appear graph)produced machine. domains used evaluation taken IPC 3 IPC4, described detail papers giving overview two competitions (Long& Fox, 2003; Hoffmann & Edelkamp, 2005).6.1 Plateau-Escaping Macro-Actionsassess effect plateau-escaping macro-actions planner performance, tests run acrossrange planning domains macro-actions enabled disabled. results testsshown Figures 7 8, illustrating time taken find solution plan makespanplan found respectively.138fiM ARVIN : H EURISTIC EARCH P LANNER NLINE ACRO -ACTION L EARNINGAirportPhilosophers10001000Macro-ActionsMacro-Actions1001001010Time (sec.)Time (sec.)Macro-ActionsMacro-Actions110.10.10.010.0151015202530Problem Instance3540455051015202530Problem InstanceDepots354045Driverlog100001000Macro-ActionsMacro-ActionsMacro-ActionsMacro-Actions1000100Time (sec.)Time (sec.)1001010110.10.10.010.01510Problem Instance152024681012Problem InstancePipes Tankage Non-Temporal14161820Satellite100001000Macro-ActionsMacro-ActionsMacro-ActionsMacro-Actions1000100Time (sec.)Time (sec.)1001010110.10.10.010.0151015202530Problem Instance35404550510FreeCell1520Problem Instance3035Pipes No-Tankage Non-Temporal1000010000Macro-ActionsMacro-ActionsMacro-ActionsMacro-Actions10001000100100Time (sec.)Time (sec.)251010110.10.10.010.0124681012Problem Instance1416182051015202530Problem Instance35404550Figure 7: CPU time showing results planning without plateau-escaping macroactions range domains (from left right: Airport, Philosophers, Depots, Driverlog, Pipestankage-nontemporal, Satellite, FreeCell, Pipesnotankage-nontemporal).139fiC OLES & MITHAirportPhilosophers500450Macro-ActionsMacro-ActionsMacro-ActionsMacro-Actions450400400350350300MakespanMakespan30025025020020015015010010050500051015202530Problem Instance3540455051015202530Problem InstanceDepots354045Driverlog250200Macro-ActionsMacro-ActionsMacro-ActionsMacro-Actions180200160140Makespan120Makespan150100100806050402000510Problem Instance152024681012Problem InstancePipes Tankage Non-Temporal14161820Satellite250450Macro-ActionsMacro-ActionsMacro-ActionsMacro-Actions400200350300MakespanMakespan15025020010015010050500051015202530Problem Instance35404550510FreeCell1520Problem Instance253035Pipes No-Tankage Non-Temporal250250Macro-ActionsMacro-ActionsMacro-ActionsMacro-Actions150150Makespan200Makespan20010010050500024681012Problem Instance1416182051015202530Problem Instance35404550Figure 8: Makespan solution plans found planning without plateau-escapingmacro-actions range domains (from left right: Airport, Philosophers, Depots,Driverlog, Pipestankage-nontemporal, Satellite, FreeCell, Pipesnotankage-nontemporal).140fiM ARVIN : H EURISTIC EARCH P LANNER NLINE ACRO -ACTION L EARNINGAirport domain time taken find plans makespans plans foundalmost identical. strictly better successor usually found state using EHC,clear domain addition macro-actions occasional plateaudegraded performance planner. performance two configurations deviatesproblem 47, planning macro-actions able find solution plan planningwithout macro-actions not. Closer inspection output planner revealscase, way EHC search, plateau encountered escaped; configuration usingmacro-actions, leads formation macro-action. Later search, another plateauencountered. point, earlier macro-action used lead strictly better state,solution plan ultimately found using EHC. macro-action available,however, sequence actions found escape plateau leads different exit point,solution plan cannot found using EHC.Philosophers domain neither makespans plans found coverage differs two configurations tested. Using macro-actions, however, leads consistently improvedperformance plateaux encountered search require application actionsequence. Consistently, across problems, searching macro-actions faster factortwo; furthermore, factor increasing problem size, suggesting better scalability.Depots domain, using macro-actions improves coverage, allowing 18 problemssolved within time limit rather 15. Further, many cases, time taken find planreduced. one case, problem file 6, planning without macro-actions able find planplanning macro-actions cannot. Here, planning without macro-actions unable find exitpoint one plateaux encountered later search, resorts best-first search. Planningmacro-actions, however, able reach greater number successor states nodesplateau unable exhaust reachable possibilities terminate EHC search within30-minute time limit.Driverlog domain, using macro-actions generally increases time taken find plansadverse effect makespan. domain, macro-actions containing varying-lengthaction sequences consisting repeated walk drive actions inferred. practice,detrimental two ways: large number instantiations dramatically increasebranching factor, reducing performance; usefully reusable situationsprescribed number walk drive actions needed. Despite this, planning macroactions able find solution plans 18 problems, whereas planning without macroactions able solve 17 problems. problem question, problem 17,increased number successor states visible nodes plateaux due presencemacro-actions allows EHC find solution plan rather resorting best-first search,would ultimately fail within time limit set.Pipestankage-nontemporal domain, clear first whether macro-actions beneficial not. number problems solved configurations same, 34, impactmakespan appears insignificant, improving cases making worse others.However, looking harder problems problem 25 upwards, planning macro-actionsable solve 13 rather 11 problems, suggesting able scale better larger problemscompared searching without macro-actions.Satellite domain configurations exhibit similar performance, termstime taken find solution plan makespan plan found, relaxed planning graphheuristic generally able provide good search guidance. exception problem 36: here,141fiC OLES & MITHinference macro-action allows search completed using EHC rather resortingbest-first search, reducing time taken find plan.FreeCell domain, macro-actions appear lead improved makespans negligible impact time taken find solution plans. Intuitively, however, strongly directedsearch space (such FreeCell, possible move card one locationanother often move back) using non-backtracking search strategy EHCreduce effectiveness macro-actions, introduction redundant action steps partmacro-action instantiations lead search towards unpredicted dead-ends. illustrated results,contradicting intuition, ascribed nature FreeCell problems used IPC 3.problem files four suits cards, problem file 7 upwards four freecells. number cards suit number columns gradually increased 213 4 8 respectively. effect this, however, hardest problemsfavourable free cells cards ratio. macro-actions used, impact needlessly movingcard free cell significant generous allocation free cells comparednumber cards might need stored there.provide reasonable test whether macro-actions beneficial FreeCell domain, twenty full-sized problem instances generated tests run compare performanceMarvin without macro-actions problems. results tests seenFigure 9 - clearly, number problems solvable within 30 minute time limit and, generally,time taken find solution plan improved macro-actions used.Pipesnotankage-nontemporal domain results obtained show significant advantage disadvantage using macro-actions: planner faster problemsusing macro-actions, slower others; similarly, planner produces plans shortermakespans problems using macro-actions, longer makespans others. Tworesults obtained macro-actions used close 30-minute cut-off.first solved around 10 seconds macro-actions used; secondsolved using macro-actions extra 5 minutes CPU time allowed, slightly fastercomputer used.Overall, seen effect plateau-escaping macro-actions execution timeplanner varies depending domain question:Philosophers, Depots, Driverlog Pipestankage-nontemporal domains, usemacro-actions improves performance planner, either terms coveragegeneral reduction time taken find solution plans.FreeCell domain, worse performance observed macro-actions used.Airport, Pipesnotankage-nontemporal Satellite domains difference performance minimal.Furthermore, exception Driverlog FreeCell domains (where makespansolution plans generally increased using macro-actions) use macro-actionssignificantly affect makespan.6.2 Greedy Best-First Search versus Best-First Searchassess performance greedy best-first search compares conventional best-first search,ran tests across range planning domains EHC macro-actions disabled isolate142fiM ARVIN : H EURISTIC EARCH P LANNER NLINE ACRO -ACTION L EARNINGFreeCell10000Macro-ActionsMacro-Actions1000Time (sec.)1001010.10.01510Problem Instance1520Figure 9: Time taken solve twenty full-sized problems FreeCell domain, withoutplateau-escaping macro-actions.effect greedy best-first search approach. Overall, analysing results, observedchoice best-first search algorithm little impact performance planner.6.3 Least-Bad-First Search versus Breadth-First Searchassess effect using least-bad-first search rather breadth-first search escape plateauxEHC search, ran tests across range planning domains using two searchalgorithms. results tests shown Figures 10 11, illustrating time takenfind solution plan, makespan plan found.Airport domain, plateaux arise one two cases:unforeseen deadend reached; backtracking made action choicesexhaustively searching plateau inexpensive, EHC terminates rapidly.short plateau reached, requiring two actions applied reach statestrictly better heuristic valuehere, two actions found least-bad-first breadthfirst search identical.seen planning time makespan graphs, using least-bad-first search ratherbreadth-first search impact planning time solution plan quality Airportdomain: time spent searching plateaux negligible, escape paths found identicaltwo plateau-search approaches.143fiC OLES & MITHAirportPhilosophers100010000Least-Bad-First SearchBreadth-First SearchLeast-Bad-First SearchBreadth-First Search1000100Time (sec.)Time (sec.)1001010110.10.10.010.0151015202530Problem Instance3540455051015202530Problem InstanceDepots354045Driverlog100001000Least-Bad-First SearchBreadth-First SearchLeast-Bad-First SearchBreadth-First Search1000100Time (sec.)Time (sec.)1001010110.10.10.010.01510Problem Instance152024681012Problem InstancePipes Tankage Non-Temporal182010000Least-Bad-First SearchBreadth-First SearchLeast-Bad-First SearchBreadth-First Search10001000100100Time (sec.)Time (sec.)16Satellite100001010110.10.10.010.0151015202530Problem Instance35404550510FreeCell1520Problem Instance253035Pipes No-Tankage Non-Temporal1000010000Least-Bad-First SearchBreadth-First SearchLeast-Bad-First SearchBreadth-First Search10001000100100Time (sec.)Time (sec.)141010110.10.10.010.0124681012Problem Instance1416182051015202530Problem Instance35404550Figure 10: CPU time showing comparison using breadth-first least-bad-first searchplateau search range domains (from left right: Airport, Philosophers,Depots, Driverlog, Pipestankage-nontemporal, Satellite, FreeCell, Pipesnotankagenontemporal). results generated without using macro-actions.144fiM ARVIN : H EURISTIC EARCH P LANNER NLINE ACRO -ACTION L EARNINGAirportPhilosophers350450Least-Bad-First SearchBreadth-First SearchLeast-Bad-First SearchBreadth-First Search400300350250MakespanMakespan30020015025020015010010050500051015202530Problem Instance3540455051015202530Problem InstanceDepots354045Driverlog250180Least-Bad-First SearchBreadth-First SearchLeast-Bad-First SearchBreadth-First Search160200140120MakespanMakespan150100801006040502000510Problem Instance152024681012Problem InstancePipes Tankage Non-Temporal14161820Satellite250300Least-Bad-First SearchBreadth-First SearchLeast-Bad-First SearchBreadth-First Search250200200MakespanMakespan15015010010050500051015202530Problem Instance35404550510FreeCell1520Problem Instance253035Pipes No-Tankage Non-Temporal250140Least-Bad-First SearchBreadth-First SearchLeast-Bad-First SearchBreadth-First Search120200100MakespanMakespan15010080604050200024681012Problem Instance1416182051015202530Problem Instance35404550Figure 11: Makespan plans produced using breadth-first least-bad-first searchplateau search range domains (from left right: Airport, Philosophers,Depots, Driverlog, Pipestankage-nontemporal, Satellite, FreeCell, Pipesnotankagenontemporal). results generated without using macro-actions.145fiC OLES & MITHPhilosophers domain, search time dramatically reduced using least-bad-first searchrather breadth-first search plateaux. Using least-bad-first search, 48 problems solved;using breadth-first search, first 14 solved. plans found first 14 identicalmakespans, although actions occur differing orders two plans.search landscape provides insights least-bad-first search suitedproblem domain. start largest plateaux encountered, action leads statestrictly worse heuristic value; corresponds applying action queue-writephilosopher. these, state less-bad heuristic visible. using least-badfirst search, less-bad state considered others queue, avoiding redundantsearch would otherwise performed breadth-first search. Adding philosophersproblem causes dramatic increase amount redundant search performed breadth-firstsearch used, leading observed performance improvement least-bad-first approachtaken.Depots domain, observe effect differing exit points plateaux usingleast-bad-first breadth-first search. solving problem 18, least-bad-first search ablesolve problem substantially less time: EHC search able escape plateau encountered, find solution plan. Breadth-first search, however, leads termination EHC,exhaustive best-first search used. problem 15, however, breadth-first search able findsolution plan least-bad-first search cannot; also, problem 5 solved much less time.two cases, success breadth-first search plateaux leads improvedperformance, failure; EHC search terminates resorts best-first search less timebreadth-first search used least-bad-first search used.Driverlog domain, one additional problem, number 18, solved least-badfirst search used instead breadth-first search. EHC using breadth-first search leads plateaucannot escaped, EHC aborts without solution plan; resulting exhaustive best-firstsearch cannot completed within allowed 30 minutes. makespans plans foundtwo approaches differ significantly.Pipestankage-nontemporal domain, seen use least-bad-first searchgenerally reduces time taken find solution plans. 34 problems solved using leastbad-first search compared 30 using breadth-first search and, majority cases,time taken find solution plan reduced. makespans resulting solution plansgenerally increased least-bad-first search used, though, suboptimal exit paths founddomain often longer (optimal-length) paths found breadth-first searchused.Satellite domain using least-bad-first search leads reduction planning time and,many cases, reduction makespan. particular, performance problems 19 20substantially improved. makespans problems 28 30 inclusive also improved.twenty standard benchmark FreeCell problems using least-bad-first search allows oneadditional problem solved within 30 minute time limit. results obtainedassessing impact macro-actions planner performance, obtained interestinguseful set data. Figure 12 shows results experiments: seen althoughleast-bad-first search often improves time taken solve problems, coverage overall reduced, additional problems solved previously not.Pipesnotankage-nontemporal domain, one additional problem solved usingbreadth-first search rather least-bad-first search. Also, many cases, use least-bad146fiM ARVIN : H EURISTIC EARCH P LANNER NLINE ACRO -ACTION L EARNINGFreeCell10000Least-Bad-First SearchBreadth-First Search1000Time (sec.)1001010.10.01510Problem Instance1520Figure 12: Time taken solve twenty full-sized problems FreeCell domain, least-badfirst breadth-first search plateaux (without macro-actions).first search increases makespan solution plan found. Overall, although time reductionsoccur solving problems using least-bad-first search, use breadth-firstsearch provides better overall performance terms planning time makespan.Overall, seen across evaluation domains performance plannerusing least-bad- breadth-first search varies, terms planner execution time plan quality:Philosophers domain, use least-bad-first search provides substantial improvement planner performance.Satellite, Driverlog Pipestankage-nontemporal domains, execution timeplanner generally improved use least-bad-first search (with reduction planquality latter these).Airport Depots domain, impact performance minimal, either termsexecution time solution plan quality.FreeCell Pipesnotankage-nontemporal domains, performance planner degraded, terms execution time plan quality.6.4 Handling Derived Predicatespossible reason domains involving derived predicates precompiling domain,adding additional actions support derived predicates, planning usual manner147fiC OLES & MITHPSR10000Original Domain: ADL Derived PredicatesCompiled Domain: ADL1000Time (sec.)1001010.10.01102030Problem Instance4050Figure 13: Time taken solve problems PSR domain without Derived Predicates.(see Section 5). necessary compilation, however, causes large increase sizedomain. planner performs compilation itself, generating confirm actions segregating normal actions internally, avoid search overhead compiled domainwould incur.Three IPC 4 domains make use derived predicates: PSR (Power Supply Restoration), Philosophers Optical Telegraph. assess impact native support derived predicatesplanner performance, tests run domains using original domains containing derived predicates, using compiled domains. results tests shownFigures 13, 14 15.PSR domain, support derived predicates substantially reduces time takenfind solution plans. improvement efficiency allows 23 rather 12 problems solvedwithin 30 minute time limit.Marvin able solve problems promela/optical-telegraph domain.smaller problems, performance better without derived predicates; nonetheless, twolarger problems (problems 8 9) solved working original domainpreviously could not, overall one additional problem solved derived predicates.Philosophers domain, supporting derived predicates natively yields substantial reductionsplanning time. Using compiled ADL domain formulation, first nine problemssolved. native derived predicate support, 48 problems solved.148fiM ARVIN : H EURISTIC EARCH P LANNER NLINE ACRO -ACTION L EARNINGOptical Telegraph10000Original Domain: ADL Derived PredicatesCompiled Domain: ADL1000Time (sec.)1001010.10.01246Problem Instance810Figure 14: Time taken solve problems Optical Telegraph domain without DerivedPredicates.6.5 Native ADL Supportnative support ADL Marvin provides two benefits, arising ability use noncompiled domain formulations:Potentially improved efficiency, due more-efficient representation.ability infer reusable, parameterised macro-action sequences original ADLactions, whose parameters lost side-effect process used compile ADLSTRIPS domains.6.5.1 E FFECTS U SINGN -C OMPILED OMAINassess effect native support ADL constructs performance Marvin, ranseries tests comparing planners performance given STRIPS ADL domain encodings. Macro-actions disabled cases isolate effect encodingperformance. IPC 4, ADL used encode four domains: Airport,Philosophers, Optical Telegraph PSR. STRIPS compilations made availabledomains, ground action could arise using original ADL domainmade fixed-parameter STRIPS action. Philosophers, Optical Telegraph PSRdomains, domain formulations making use Derived Predicates used.149fiC OLES & MITHPhilosophers10000Original Domain: ADL Derived PredicatesCompiled Domain: ADL1000Time (sec.)1001010.10.0151015202530Problem Instance354045Figure 15: Time taken solve problems Philosophers Domain without DerivedPredicates.Airport, Optical Telegraph PSR domains, performance Marvin (with macroactions disabled) unaffected use either ADL STRIPS domain encoding.ADL domain encodings give rise inefficient compiled STRIPS encodings.Philosophers domain, use ADL domain encoding resulted reductionplanning time compared use compiled STRIPS encoding. seenFigure 17, problems solved within 30 minute time-limit ADL encoding ratherSTRIPS encoding used, even disregarding improvements performance provideduse macro-actions.6.5.2 E FFECTS NFERRING ACRO -ACTIONSSupporting ADL natively Marvin allows lifted macro-action schemata inferredsearch: compiled STRIPS domain formulations presented IPC 4, actions plateauescaping action sequences parameters, removing opportunity infer parameterised action sequences use basis macro-actions. Reusable macro-actionsinferred STRIPS domains, many domains discussed Section 6.1; compilation ADL STRIPS produces domain macro-actions cannot, practice, everreused.assess effects plateau-escaping macro-actions using ADL domain formulation, tests run Philosophers, Optical Telegraph PSR domains using ADL domainformulation macro-actions enabled disabled. Results Airport domain presentedSection 6.1, results domains discussed.150fiM ARVIN : H EURISTIC EARCH P LANNER NLINE ACRO -ACTION L EARNING0:1:2:3:4:(activate-trans philosopher-1 philosopher forkspid-wfork state-1 state-6) [1](activate-trans philosopher-2 philosopher forkspid-wfork state-1 state-6) [1](activate-trans philosopher-3 philosopher forkspid-wfork state-1 state-6) [1](activate-trans philosopher-4 philosopher forkspid-wfork state-1 state-6) [1](activate-trans philosopher-0 philosopher forkspid-wfork state-1 state-6) [1]5: Macro-Action Derived Here, using philosopher-4, philosopher-3, forks-4 forks-316: (activate-trans philosopher-3 philosopher forkspid-rfork state-6 state-3) [1]17: Macro-Action A, using philosopher-2, philosopher-1, forks-2- forks-128: (activate-trans philosopher-1 philosopher forkspid-rfork state-6 state-3) [1]29: Macro-Action B Derived Here, using philosopher-3 -forks-332: (activate-trans philosopher-3 philosopher forks- -pidp1 11 -rfork state-3 state-4) [1]33: Macro-Action B, using philosopher-1 -forks-136: (activate-trans philosopher-1 philosopher forks- -pidp1 11 -rfork state-3 state-4) [1]37:38:39:40:(queue-write philosopher-0 forkspid-wfork forks-0- fork) [1](advance-empty-queue-tail forks-0- queue-1 qs-0 qs-0 fork empty zero one) [1](perform-trans philosopher-0 philosopher forkspid-wfork state-1 state-6) [1](activate-trans philosopher-0 philosopher forkspid-rfork state-6 state-3) [1]41: Macro-Action B, using philosopher-0 -forks-044: (activate-trans philosopher-0 philosopher forks- -pidp1 5 -rfork state-3 state-4) [1]Figure 16: Plan Philosophers problem macro-action expansion.plan shown Figure 16 produced Marvin problem four Philosophersdomain (before translation macro-actions back sequences single-step actions).first five steps found easily guidance heuristic; following elevenfound period exhaustive search are, upon exiting plateau, used formmacro-action, macro-action A. Macro-action B formed similar manner later planningprocess, subsequently used avoid exhaustive search. solution plans problemsinvolving philosophers, two macro-actions used several times: macro-action usedconsecutive pair philosophers, macro-action B odd-numberedphilosopher (and philosopher-0). graph Figure 17 shows performance Marvinmacro-actions inferred search compared macro-actionsinferred; configurations produce identical solution plans. seen performanceconsistently improved macro-actions used, exhaustive plateau search avoided.seen Figure 18, using macro-actions provides improved performance PSRdomain: 23 rather 15 problems solved, majority cases solvedtwo configurations, solution found less time macro-actions used.151fiC OLES & MITHPhilosophers10000ADL Domain, Macro-Actions EnabledADL Domain, Macro-Actions DisabledSTRIPS Domain1000Time (sec.)1001010.10.0151015202530Problem Instance354045Figure 17: Time taken find solution plan Philosophers domain STRIPS domainencoding ADL domain encoding, without macro-actions.PSR10000ADL Domain, Macro-Actions EnabledADL Domain, Macro-Actions Disabled1000Time (sec.)1001010.10.01102030Problem Instance4050Figure 18: Time taken solve problems PSR domain without macro-actions.152fiM ARVIN : H EURISTIC EARCH P LANNER NLINE ACRO -ACTION L EARNINGOptical Telegraph10000ADL Domain, Macro-Actions EnabledADL Domain, Macro-Actions Disabled1000Time (sec.)1001010.10.01246Problem Instance810Figure 19: Time taken solve problems Optical Telegraph domain without macroactions.shown Figure 19, Marvin able solve first 10 problemspromela/optical-telegraph domain. Nonetheless, macro-actions enabled, net two additional problems solved.7. Future Workmacro-action strategy adopted Marvin IPC 4 generate macro-actions perproblem basis. possible, however, build libraries macro-actions per-domain basis;approach taken Macro-FF (Botea et al., 2005). Marvins macro-actions could alsocached use solving problem instances given domain. done,knowledge encapsulated plateau-escaping macro-actions allows heuristic imperfectionssearch landscape bypassed could made available across problems givendomain without needing exhaustive search re-discover knowledge problem instance.contrast existing systems use off-line learning generate test macro-actions, cachingMarvins plateau-escaping macro-actions across solving problem suite manner would allowonline learning take place. work undertaken area, investigateeffective caching strategies manage large number macro-actions found.idea using plateau-escaping macro-actions restricted search relaxedplanning graph heuristic. Currently, effect using macro-actions searchheuristics investigated, including causal-graph heuristic (Helmert, 2004) used FastDownward .153fiC OLES & MITHpresent, macro-actions used Marvin restricted used escape plateaux.Work currently progress exploring ways extending macro-learning capabilities Marvininclude general macro-action structures kind explored Botea Schaeffer(Botea et al., 2005).8. Conclusionspresented forward search heuristic planner called Marvin, introduces several modifications search strategy FF. are:use learned macro-actions escaping plateaux.least-bad-first search strategy search plateaux.greedy best-first search strategy EHC fails.addition native support ADL derived predicates, without relyingdomain preprocessor.Results presented indicate effects modifications varies depending domainplanner presented, summarised as:inference use plateau-escaping macro-actions:Provides improved performance Philosophers, Depots, DriverlogPipestankage-nontemporal domains, terms planner execution time.Although performance improve domains, significantlydegrade, exception FreeCell.makespan plans found majority domains degradeduse macro-actions.use least-bad-first search:Provides substantial improvements planner performance Philosophers domain.Reduces planner execution time Satellite, Driverlog Pipestankagenontemporal domains, sometimes expense increased solution plan makespans.Provides worse performance FreeCell Pipesnotankage-nontemporal domains.Greedy best-first search perform significantly differently best-first searchevaluation domains considered.Airport domain, difference performance observed, nativesupport derived predicates ADL improves performance planner; eitherallowing more-compact higher-level domain formulation used, improvingeffectiveness macro-actions inferred.154fiM ARVIN : H EURISTIC EARCH P LANNER NLINE ACRO -ACTION L EARNINGAcknowledgmentswould like thank anonymous referees comments, Maria Fox helprevising manuscript. also thank Derek Long supporting us entering Marvin IPC4 Jorg Hoffmann Stefan Edelkamp hard work organising competition.ReferencesBacchus, F. (2001). aips 00 planning competition.. AI Magazine, 22(3), 4756.Blum, A., & Furst, M. (1995). Fast planning planning graph analysis. ProceedingsFourteenth International Joint Conference Artificial Inteligence (IJCAI-95), pp. 16361642.Bonet, B., & Geffner, H. (2000). HSP: Heuristic search planner. AI Magazine, 21(2).Botea, A., Enzenberger, M., Muller, M., & Schaeffer, J. (2005). Macro-FF: Improving AI planningautomatically learned macro-operators. Journal Artificial Intelligence Research, 24,581621.Dawson, C., & Siklossy, L. (1977). role preprocessing problem solving systems.Proceedings Fifth International Joint Conference Artificial Intelligence, (IJCAI-77),pp. 465471.Fikes, R., & Nilsson, N. (1971). STRIPS: new approach application theorem provingproblem solving. Proceedings 2nd International Joint Conference ArtificialIntelligence (IJCAI-71), pp. 608620.Gazen, B., & Knoblock, C. (1997). Combining expressivity UCPOP efficiencyGraphplan. Proceedings Fourth European Conference Planning (ECP-97), pp.221233.Helmert, M. (2004). planning heuristic based causal graph analysis. ProceedingsFourteenth International Conference Automated Planning Scheduling (ICAPS-04),pp. 161170.Helmert, M. (2006). fast downward planning system. Journal Artificial Intelligence Research, 26, 191246.Hoffmann, J., & Edelkamp, S. (2005). deterministic part IPC-4: overview. JournalArtificial Intelligence Research, 24, 519579.Hoffmann, J., & Nebel, B. (2001). FF planning system: Fast plan generation heuristicsearch. Journal Artificial Intelligence Research, 14, 253302.Hoffmann, J. (2001). Local search topology planning benchmarks: empirical analysis. Proceedings Seventeenth International Joint Conference Artificial Intelligence (IJCAI01), pp. 453458.Hoffmann, J. (2005). ignoring delete lists works: Local search topology planning benchmarks. Journal Artificial Intelligence Research, 24, 685758.Koehler, J., Nebel, B., Hoffmann, J., & Dimopoulos, Y. (1997). Extending planning graphsADL sub-set. Proceedings Fourth European Conference Planning (ECP-97), pp.275287.155fiC OLES & MITHLong, D., & Fox, M. (2003). 3rd International Planning Competition: Results Analysis.Journal Artificial Intelligence Research, 20, 159.Long, D., & Fox, M. (1999). Efficient implementation plan graph STAN. JournalArtificial Intelligence Research, 10, 87115.Long, D., & Fox, M. (2003). third international planning competition: Results analysis.Journal Artificial Intelligence Research, 20, 159.McDermott, D. (1996). heuristic estimator means ends analysis planning. Drabble, B.(Ed.), Proceedings Third International Conference Artificial Intelligence PlanningSystems (AIPS-96), pp. 142149. AAAI Press.McDermott, D. (2000). 1998 AI planning systems competition. AI Magazine, 21(2), 3555.Minton, S. (1985). Selectively generalizing plans problem-solving. Proceedings NinthInternational Joint Conference Artificial Intelligence (IJCAI-85).Nebel, B., Hoffmann, J., & Thiebaux, S. (2003). defense PDDL axioms. ProceedingsEighteenth International Joint Conference Artificial Intelligence (IJCAI-03), pp. 961966.Newton, M., Levine, J., & Fox, M. (2005). Genetically evolved macro-actions A.I. planningproblems. Tuson, A. (Ed.), Proceedings 24th UK Planning Scheduling SIG, pp.163172.Pednault, E. (1989). ADL: Exploring middle ground STRIPS situation calculus.Proceedings First International Conference Principles Knowledge Representation Reasoning, pp. 324332.Vidal, V. (2004). lookahead strategy heuristic search planning. Proceedings Fourteenth International Conference Automated Planning Scheduling (ICAPS-04), pp.150160.156fiJournal Artificial Intelligence Research 28 (2007) 49-105Submitted 2/06; published 02/07Strategy-Proofness Landscape MergingPatricia EveraereSebastien KoniecznyPierre Marquiseveraere@cril.frkonieczny@cril.frmarquis@cril.frCRIL CNRSFaculte des Sciences, Universite dArtois62300 Lens, FranceAbstractMerging operators aim defining beliefs/goals group agentsbeliefs/goals member group. Whenever agent group preferencespossible results merging process (i.e., possible merged bases),try rig merging process lying true beliefs/goals leads bettermerged base according point view. Obviously, strategy-proof operators highlydesirable order guarantee equity among agents evensincere. paper, draw strategy-proof landscape many merging operatorsliterature, including model-based ones formula-based ones. generalcase several restrictions merging process considered.1. IntroductionMerging operators aim defining beliefs/goals group agents beliefs/goals member group. Though beliefs goals distinct notions,merging operators typically used merging either beliefs goals. Thus,logical properties literature (Revesz, 1993, 1997; Konieczny & Pino Perez, 1998,2002) characterizing rational belief merging operators used characterizingwell rational goal merging operators.Whatever beliefs goals merged, numerous situations agentspreferences possible results merging process (i.e., merged bases).far goals concerned, agent surely satisfied individual goals chosengoals group. case belief merging, agent interestedimposing beliefs group (i.e., convincing agents), especiallyresult decision stage group level may depend beliefsgroup.So, soon agent participates merging process, strategy-proofness problemconsidered. question is: possible given agent improve resultmerging process respect point view lying true beliefs/goals,given knows (or least assumes) beliefs/goals agent groupway beliefs/goals merged?illustration, let us consider following scenario goal merging (thatused running example rest paper):c2007AI Access Foundation. rights reserved.fiEveraere, Konieczny & MarquisExample 1 Three friends, Marie, Alain Pierre want spend summer holidaystogether. determine whether go seaside and/or mountains, stay home, also determine whether take long periodvacations not. goals Marie go seaside mountainslong period; otherwise wants go mountains, only, stay home.goals Alain go seaside long period; go mountainsshort period. Finally, Pierre interested going seasidelong period, otherwise prefers stay home. one uses common merging operatordefining choice group,1 goals group either goseaside long period, go mountains stay home short period.Accordingly, group may choose go seaside, only, long period,among goals Marie. However, Marie lies claims that, short period,wants go mountains only, stay home, result merging processdifferent. Indeed, case, goals group go mountainsshort period, stay home, corresponds goals Marie.Similarly, strategy-proofness issue considered many belief merging scenarios, rational decision making typically takes account true stateworld. agents conflicting beliefs it, belief merging useddetermine true state world group; manipulating beliefmerging process way agent change resulting beliefs group levelmake close beliefs. consequence, decisions made groupmay also change become closer agent would made alone. instance,assume three friends agree mountains must avoided weatherbad. beliefs group weather bad, decision gomountains given up. Pierre believes weather bad, maytempted make weather bad accepted group level. Therefore, collectivedecision go mountains.several multi-agent settings agents exchange informationmust make individual decisions based beliefs. many scenarios, agents temptedget informational advantage agents, achieved gatheringmuch information possible hiding ones. Indeed, better informedmay help agent making better decisions agents group. instance,Shoham Tennenholtz (2005) investigate non-cooperative computation: agent delivers piece information (truthfully not), pieces used computevalue (commonly-known) function, value given back agents;aim agent get true value function, possibleone get it. work Shoham Tennenholtz (2005), information consideredabstract level; assuming information represent beliefs function beliefmerging operator, agent wants get true merged base possiblyone get it. Contrastingly, scenarios, decisions made collectivelybased beliefs group, agents satisfied beliefs group1. Formally, model-based operator 4dH , , using Hamming distance sum aggregation function, defined Section 3.1.50fiThe Strategy-Proofness Landscape Mergingclose beliefs. paper, focus issue,addressed many everyday life situations. Let us illustrate example:Example 2 position available university. committee chargerecruitment determine right profile position. Four criteriaconsidered: research skills, teaching skills, relationship skills, past positionscandidate. Suppose member committee believes important criteriajob research skills relationship skills, better recruit candidategot good position past. pleased recruitment group sharesbeliefs right profile. tempted manipulate merging processorder achieve situation.Determining whether belief/goal merging operator strategy-proof, negative case, identifying restrictions strategy-proofness ensured thusimportant issue. Indeed, merging operators intended characterize beliefs/goalsgroup agents, beliefs/goals agent group; obviously,objective cannot reached agents report true beliefs/goals,easily case manipulable merging operators used (since agentstempted manipulate process case).Since merging operators typically used artificial systems, one wonder whetherstrategy-proofness really relevant issue context. answer actually dependssophistication agents consideration. Thus, distributed databasesetting, (low-level) agents (i.e., databases) typically evaluation/preferencemerged base, strategy-proofness issue make sense.story agents goals reasoning capacities. case, cannotdiscarded agents able foresee weakenesses aggregation processexploit benefits. high-level artificial agents involved,strategy-proofness problem even stricking case human agentssuperior computational abilities artificial systems.strategy-proofness issue studied years domain Social ChoiceTheory (Arrow, Sen, & Suzumura, 2002). important objective design preferenceaggregation procedures (and, particular, voting procedures) strategy-proof.famous result, known Gibbard-Sattherwaite theorem, objective cannotreached absolute manner: number sensible requirements, strategyproof voting procedure may exist (Gibbard, 1973; Satterthwaite, 1975). Strategy-proofnessachieved relaxing requirements, enough escapeGibbard-Sattherwaite theorem. shall return topic Section 7connections belief merging preference aggregation considereddepth.objective paper draw strategy-proofness landscape manymerging operators literature, including model-based ones formula-based ones.focused operators merging bases sets propositional formulas,priorities bases available. (classical) propositional logic frameworkargued representation setting expressive enough many AI scenarios; furthermore,natural investigate first key problems raised aggregation manipulationsimple setting, considering sophisticated logics. operator51fiEveraere, Konieczny & Marquisconsideration, aim determining whether strategy-proof general case,restrictions merging process (including number agentspresence integrity constraints) set available strategies agents.rest paper organized follows. Section 2, formal preliminariesprovided. Section 3, definitions main propositional merging operatorsliterature recalled. Several definitions strategy-proofness based general notionsatisfaction index given Section 4 strategy-proofness results reportedSection 5. discussed Section 6. Then, connections Social Choice Theoryrelated works pointed Section 7, conclusion. Proofsreported end paper.2. Formal Preliminariesconsider propositional language L defined finite (and non-empty) set propositional variables P standard connectives, including >, Boolean constant alwaystrue, , Boolean constant always false.interpretation (or world) total function P {0, 1}, denoted bitvector whenever strict total order P specified. set interpretations notedW. interpretation model formula L makes trueusual truth functional way.[] denotes set models formula , i.e., [] = { W | |= }. orderavoid heavy notations, identify interpretation canonical term Punique model. instance, P = {a, b} (a) = 1, (b) = 0,identified term b.formula L consistent [] 6= . logical consequenceformula , noted |= [] []. Two formulas logically equivalent ()share models.belief/goal base K denotes set beliefs/goals agent. finiteconsistent set propositional formulas, interpreted conjunctively.VWhen K belief/goalb denotes singleton base containing conjunction K formulasbase, KK. base said complete exactly one model. belief/goalbase K characterizes bipartition set interpretations: models Kinterpretations acceptable agent, countermodels not.K belief base, interpretation acceptable enough evidencetrue state world; K goal base, acceptable sufficientlydesired. bipartition considered approximation full belief/goalpreference structure corresponding agent: belief case, least preferred0 means fact true state world least plausiblefact 0 true state world; goal case, least preferred0 means fact would true state world least desiredfact 0 would true state world.belief/goal profile E associated group n agents involved mergingprocess. non-empty multi-set (bag) belief/goal bases E = {K1 , . . . , Kn } (hencedifferent agents allowed exhibit identical bases). Note profiles non-ordered(multi-)sets; thus, profile representation groups agents induces anonymity prop52fiThe Strategy-Proofness Landscape Mergingerty: agent importance agents group resultmerging process depends bases (i.e., exchanging basestwo agents gives profile, hence merged base).VVVWeVdenote E conjunctionbasesE={K,...,K},i.e.,E=(1nWWV K1 ). . . (V Kn ), denote E disjunction bases E, i.e., E = ( K1 ). . . ( Kn ).Vprofile E said consistent E consistent. multi-set unionnoted multi-set containment relation noted v. cardinal finite set(or finite multi-set) noted #(A). denote set containment strict setcontainment, i.e., B B 6= B.E denotes pre-order W (i.e., reflexive transitive relation), <E denotesassociated strict ordering defined , 0 W, <E 0 E 00 6E .result merging (the bases from) profile E merging operator 4,integrity constraints base, noted 4 (E), called merged base.integrity constraints consist consistent formula (or, equivalently, (finite) consistentconjunction formulas) merged base satisfy (it may represent physical laws,norms, etc.); words, models merged base models integrityconstraints.3. Merging Operatorsrecall section two main families merging operators literature.first family defined selection interpretations (model-based operators).second family defined selection formulas union bases (formulabased operators). details two families, see example (Konieczny, Lang,& Marquis, 2004).3.1 Model-Based Operatorsfirst family based selection models integrity constraints,closest ones profile. Closeness usually defined notion distanceaggregation function (Revesz, 1997; Konieczny & Pino Perez, 1998, 1999; Lin & Mendelzon,1999; Liberatore & Schaerf, 1998).Definition 1 (pseudo-distances)pseudo-distance interpretations total function : W W 7 R+ s.t., 0 , 00 W: d(, 0 ) = d( 0 , ), d(, 0 ) = 0 = 0 .distance interpretations pseudo-distance satisfies triangularinequality: , 0 , 00 W, d(, 0 ) d(, 00 ) + d( 00 , 0 ).Two widely used distances interpretations Dalal distance (Dalal, 1988),denoted dH , Hamming distance interpretations (the number propositional atoms two interpretations differ); drastic distance, denoted53fiEveraere, Konieczny & MarquisdD , one simplest pseudo-distances one define: gives 0 two interpretations one, 1 otherwise.Definition 2 (aggregation functions) aggregation function f total function associating nonnegative real number every finite tuple nonnegative real numbers s.t.x1 , . . . , xn , x, R+ :x y, f (x1 , . . . , x, . . . , xn ) f (x1 , . . . , y, . . . , xn ).(non-decreasingness)f (x1 , . . . , xn ) = 0 x1 = . . . = xn = 0.f (x) = x.(minimality)(identity)Widely used functions max (Revesz, 1997; Konieczny & Pino Perez, 2002),sum (Revesz, 1997; Lin & Mendelzon, 1999; Konieczny & Pino Perez, 1999),leximax GM ax (Konieczny & Pino Perez, 1999, 2002).chosen distance interpretations induces distance2 interpretation base, turn gives distance interpretation profile,using aggregation function. latter distance gives needed notion closeness represented pre-order W induced E, noted E . pre-order interpretedplausibility ordering associated merged base.Definition 3 (distance-based merging operators) Let pseudo-distanceinterpretations f aggregation function. result 4d,f(E) merging Egiven integrity constraints defined by:00[4d,f(E)] = min([], E ) = { [] | @ [], <E }pre-order E W induced E defined by:E 0 d(, E) d( 0 , E),d(, E) = fKE (d(, K)),d(, K) = min0 |=K d(, 0 ).Observe dd,f (, E) would correct notation d(, E); however, sinceambiguity choice function f distance interpretationsfollowing, prefer lighter notation d(, E).Let us step back example given introduction order illustrate modelbased merging operators:Example 3 Consider set P three propositional variables l(long period), s(easide)m(ountains), taken order. goals three agents givenfollowing bases: [K1 ] = {000, 001, 111} (Maries wishes), [K2 ] = {001, 110} (Alains wishes)[K3 ] = {000, 110} (Pierres wishes). integrity constraint ( >).2. Abusing words since distance mathematical standpoint.54fiThe Strategy-Proofness Landscape Merging[dH , ({K1 , K2 , K3 })] = {000, 001, 110}. Table 1 gives detailscomputation. first column gives possible words. Ki (i = 1 . . . 3) columns giveinterpretation value dH (, Ki ). Finally, rightmost column givesinterpretation value dH (, {K1 , K2 , K3 }). interpretationsdH (, {K1 , K2 , K3 }) minimal (in bold) models merged base dH , ({K1 , K2 ,K3 }).000001010011100101110111K100111110K210111101>HK301121201,({K1 , K2 , K3 })11343412Table 1: Merging dH , .3.2 Formula-Based Operatorsmain family merging operators gather so-called formula-based operatorssyntax-based operators. Formula-based operators based selection consistent subsets formulas union bases profile E. Several operatorsobtained letting vary selection criterion. result merging processset consequences inferred selected subsets (Baral, Kraus, Minker, &Subrahmanian, 1992; Rescher & Manor, 1970; Konieczny, 2000). operators,syntactic form bases may easily influence result merging process: replacb = {1 . . . n } maying base K = {1 , . . . , n } (logically equivalent) base Klead change corresponding merged base (while case model-basedoperators).Definition 4 (maximal consistent subsets) Let K base integrity constraint. maxcons(K, ) set maximal (w.r.t. set inclusion) consistentsubsets (maxcons short) K {} contains , i.e., maxcons(K, ) setconsistent satisfy:K {},,0 K {}, 0 consistent.maximality must taken respect cardinality (instead set inclusion),shall use notation maxconscard (K, ).Now, profile E integrity constraint , set[maxcons(E, ) = maxcons(Ki , )Ki E55fiEveraere, Konieczny & MarquisObserve set-theoretic union (and multi-set union) used here.following operators defined far (Baral, Kraus, & Minker, 1991; Baralet al., 1992; Konieczny, 2000):Definition 5 (formula-based merging operators) Let E profile letintegrity constraint:WV4C1(E)maxcons(E,) ( ).VW4C3(E)|M maxcons(E,>) {} consistent ( ).WV4C4(E)maxconscard (E,) ( ).VWmaxcons(E,>) {} consistent ( {M {}})4C5consistent,(E)otherwise.operators clearly select much formulas union bases,consistency requirement. differences lie meaningmuch. operators defined Baral et al. (1992), except 4C5modification 4C3 ensures consistency. Indeed, unlike operators listed here,C2 operator4C3may generate inconsistent merged bases (as empty disjunction). 4also introduced Baral et al. (1992), shown equivalent 4C1 (thislisted above). important drawback operators takeaccount sources formulas issued.3 Nevertheless,appealing, simple definition.illustrate behaviour formula-based operators, let us step back examplegiven introduction. Since absence constraints makes operators 4C1 , 4C34C5 coincide, shall add following constraint: = l s, i.e., turnsgroup take holidays long period cannot go seaside.Example 4 Suppose Marie, Alain Pierres goals encoded followingbases: K1 = {l s, l m}, K2 = {l s, m}, K3 = {l s, m}.integrity constraints = l s, maxcons(E, ) contains two sets: {l m, m}C3C4C5{m}. get 4C1(E) , 4 (E) , 4 (E) l m, 4 (E) .syntax sensitivity operators due fact comma symbol, appears expression bases, specific, yet truth-functional,connective (Konieczny, Lang, & Marquis, 2005) usually equivalent standardconjunction formula-based framework. operators may easily lead mergedbases differ counterparts commas replaced conjunctionsinput bases. example, = >, K1 = {a b}, K2 = {(a b)} K10 =C10{a, b}, fact K10 K1 imply 4C1({K1 , K2 }) 4 ({K1 , K2 }), sinceC1C104 ({K1 , K2 }) > 4 ({K1 , K2 }) b. See (Konieczny et al., 2005)3. possible avoid taking advantage selection function (Konieczny, 2000).56fiThe Strategy-Proofness Landscape Mergingdetailed discussion meaning comma connective frameworks reasoninginconsistency.b singleton base containingClearly enough, one replaces base K K,bconjunction elements making union, resulting operators, noted 4C,longer sensitive syntactic presentation bases (replacing every baselogically equivalent one leads merged base). Formally, have:Definition 6 (other formula-based merging operators) Let E = {K1 , . . . , Kn }profile let integrity constraint:cCi cc4Ci(E) = 4 ({K1 , . . . , Kn }).Remark 1 Observe 4C4 equivalent model-based operator dD , = dD ,GM ax .cIndeed, 4C4 returns disjunction maximal (for cardinality) consistent subsetsprofile constraints. exactly operator dD , = dD ,GM axachieves since amounts define set models merged base set interpretations satisfy constraints maximal number bases profile, i.e.,interpretations models maximal (for cardinality) consistent subsetprofile constraints.c4. Strategy-Proofnessstrategy-proofness issue merging operator stated follows: possiblegiven agent improve result merging process respectpoint view lying true beliefs/goals, given knows beliefs/goalsagent group way beliefs/goals merged? questionanswered positively, operator strategy-proof (the agent may benefituntruthful). Thus, merging operator strategy-proof one find profileE = {K1 , . . . , Kn } represents bases agents, integrity constraint ,two bases K K 0 s.t. result merging E K 0 better agentresult merging E true base K (called initial base).Definition 7 (strategy-proofness) Let satisfaction index, i.e., total functionL L IR.profile E said manipulable base K given merging operatorintegrity constraint exists base K 0 i(K, (E{K 0 })) > i(K, (E {K})).merging operator strategy-proof integrityconstraint profile E = {K1 , . . . , Kn } E manipulable i.Given two bases (interpreted conjunctively) K, K , value i(K, K ) intendedindicate much base K close merged base K . need satisfactionindexes comes fact information given agent baseK: full preference structure sets interpretations available agent57fiEveraere, Konieczny & Marquisadditional input (e.g., form utility function), one could usedefine strategy-proofness directly given agent (as done Social Choice Theory,Arrow et al., 2002) uniform way agents. explains callsatisfaction index utility function.Clearly, many different ways define satisfaction agent givenmerged base. many ad hoc definitions considered, consider followingthree indexes are, according us, meaningful ones additionalinformation agents available. far know, first timeindexes considered context pure propositional merging.first two indexes drastic ones: range {0, 1}, agent either fullysatisfied satisfied all.Definition 8 (weak drastic index)1idw (K, K ) =0K K consistent,otherwise.index takes value 1 result merging process (noted K definition) consistent agents base (K), 0 otherwise. means agentconsidered fully satisfied soon beliefs/goals consistent merged base.Definition 9 (strong drastic index)ids (K, K ) =10K |= K,otherwise.index takes value 1 agents base logical consequence resultmerging process, 0 otherwise. order fully satisfied, agent must imposebeliefs/goals whole group.last index Boolean one, leading gradual notion satisfaction.compatible merged base agents base satisfied agent.compatibility degree K K (normalized) number models Kmodels K well:Definition 10 (probabilistic index) #([K ]) = 0, ip (K, K ) = 0, otherwise:ip (K, K ) =#([K] [K ]).#([K ])ip (K, K ) probability get model K uniform sampling modelsK . index takes minimal value model K modelsmerged base K , maximal value model merged base modelK.Strategy-proofness three indexes independent notions:Theorem 11. merging operator strategy-proof ip , strategy-proof idw .58fiThe Strategy-Proofness Landscape Merging2. Consider merging operator generates consistent bases.4 strategyproof ip , strategy-proof ids .hand, easy prove strategy-proofness idw strategyproofness ids logically independent general case (an operator strategyproof one without strategy-proof other, strategy-proofneither).Let us conclude section running example, give formal argumentsexplaining Marie manipulate merging process:Example 5 consider three bases [K1 ] = {000, 001, 111} (Maries wishes), [K2 ] ={110, 001} (Alains wishes) [K3 ] = {110, 000} (Pierres wishes). constraint( >).dH ,({K1 , K2 , K3 })] = {000, 001, 110} ids (K1 , d>H , ({K1 , K2 , K3 })) = 0.[>Marie reports [K10 ] = {000, 001} instead K1 , [d>H , ({K10 , K2 , K3 })] = {000,001} ids (K1 , d>H , ({K10 , K2 , K3 })) = 1.See Table 2 details computations.000001010011100101110111K100111110K1000111122K210111101K301121201>H,({K1 , K2 , K3 })11343412>H,({K10 , K2 , K3 })11343424Table 2: dH , strategy-proof ids .rest paper, shall focus three indexes, idw , ids ip . Noteinvestigating indexes interesting. particular, probabilistic indexviewed rough measure similarity bases. Could complexsimilarity measures sets (see e.g., Tversky, 2003) also prove useful definesensible indexes interesting question let research.5. Strategy-Proofness Resultsgeneral case, family model-based operators family formulabased operators strategy-proof three indexes consider. meansoperators families strategy-proof. However, imposingrestrictions may lead strategy-proofness results. Consideringsystematic way allows us draw strategy-proofness landscape families.following, consider four natural restrictions merging process, listedbelow:4. I.e., (E) always consistent.59fiEveraere, Konieczny & Marquisfirst restriction concerns number bases merged. questionfollowing: number bases involved merging process influencestrategy-proofness operator? general, answer positivelyquestion. precisely, distinction cases #(E) = 2#(E) > 2. situations, manipulation possible two bases,bases, becomes possible. Since base {>} typically plays roleneutral element operators consider (i.e., 4 (E) 4 (E t{>})),operator strategy-proof profiles n bases, strategy-proofprofiles > n bases.second parameter completeness beliefs/goals agent aimsmanipulating. cases, strong beliefs/goals renders manipulation impossible. Working complete bases (i.e., singleton sets models) makesmerging process close uninominal vote, i.e., vote unique interpretation.third significant parameter presence integrity constraints. one hand,nontrivial integrity constraints ( 6 >) make manipulation possible,case integrity constraints considered, conversealso holds.Another restriction bears available manipulations. general case untruthful agent free reporting base, even quite far true base.However, numerous situations agents participatingmerging process information true base. cases, agentsreport bases close real ones. Two particular manipulationsstudied: erosion manipulation agent pretends believe/desire(the agent gives parts models); dilatation manipulationagent pretends believe/desire less (the agent givesparts countermodels).5.1 Model-Based Operatorsfirst result general strategy-proofness result (i.e., aggregationfunction distance) model-based operators. surprisingone reminds existence Gibbard-Satterthwaite theorem, statesgood strategy-proof preference aggregation method (see Section 7).However, quite general strategy-proofness results obtained. followingtheorem gives them, organized general one (for aggregationfunction drastic distance dD considered), specific ones (for distanceaggregation function ):Theorem 2Let f aggregation function. dD ,f strategy-proof ip , idw ids .Let distance. Provided two bases merged, d,> strategyproof indexes idw ids .60fiThe Strategy-Proofness Landscape Mergingdistance d, d,strategy-proof indexes ip , idw idsinitial base K complete.interesting note dD , (which coincides dD ,GM ax ) close votingprocedure called approval voting (Brams & Fishburn, 1983), agent vote(approve) many candidates wants, elected candidates onesget greatest number votes.shown running example, family merging operators dH ,f obtainedconsidering Hamming distance letting aggregation function f varystrategy-proof. Let us focus family, consider successively two operatorsobtained considering GM ax aggregation functions.dH , , number bases, presence integrity constraints completness bases significant. operator, next theorem makes preciseboundaries strategy-proofness manipulation (in following properties, Krepresents initial base #(E) number bases profile E):Theorem 3dH , strategy-proof idw ids ( > #(E) = 2) Kcomplete.dH , strategy-proof ip K complete.contrast dH , , dH ,GM ax strategy-proof even restricted situations:Theorem 4dH ,GM ax strategy-proof satisfaction indexes idw ip (even >,K complete #(E) = 2).dH ,GM ax strategy-proof satisfaction index ids >, Kcomplete #(E) = 2.5.2 Formula-Based OperatorsC3C4probabilistic index, none formula-based operators 4C1, 4 , 4 ,C54 strategy-proof. But, two drastic indexes, situationsstrategy-proofness ensured:Theorem 5C3C4C54C1, 4 , 4 , 4 strategy-proof ip (even >, K complete#(E) = 2).4C1strategy-proof idw ids .4C3strategy-proof idw ids >.4C4strategy-proof idw ids (even >, K complete #(E) = 2).61fiEveraere, Konieczny & Marquis4C5strategy-proof idw > K complete, strategyproof ids >.C3C4C5formula-based merging operators 4C1, 4 , 4 , 4 , resultsbalanced, strategy-proofness results:ccccTheorem 64C1strategy-proof idw ids , strategy-proof ip#(E) = 2.c4C3strategy-proof idw ids >, strategy-proof ip#(E) = 2 >.c4C4strategy-proof ip , idw ids .c4C5strategy-proof idw #(E) = 2 > K complete.cC54C5strategy-proof ids #(E) = 2 >. Finally, 4strategy-proof ip #(E) = 2.cc5.3 Ensuring Strategy-Proofness: Case Complete BasesLet us focus specific case: situation every base complete.situation rather infrequent dealing usual belief bases, imposedgoal merging setting, especially guarantees strategy-proofness. explainsconsider case paper. said above, also interestingrelationship uninominal voting systems one interprets complete base votecorresponding interpretation.Theorem 7 strategy-proofness results reported Table 3 hold, restrictionbase complete (f stands aggregation function, distance).sp means strategy-proof , sp means non strategy-proof even #(E) = 2 >,sp means non strategy-proof even either #(E) = 2 >, strategy-proof#(E) = 2 >. Finally, sp> means non strategy-proof even #(E) = 2,strategy-proof whenever >.Theorem 7 shows, operator among dH ,GM ax 4Cones ensuresfull strategy-proofness restricted case two complete bases mergedintegrity constraint considered. Contrastingly, operators offer strategyproofness three indexes whenever every base complete.5.4 Dalal Indexexplained before, fact ip based model counting allows formgraduality corresponding notion satisfaction, contrasts drasticindexes. Actually, non drastic indexes defined. particular, casesagent knows result could fit beliefs/goals (e.g., beliefs/goals62fiThe Strategy-Proofness Landscape MergingipidwidsdD ,fd,dH ,GM ax4C14C34C44C5c4C1c4C3c4C4c4C5spspspspspspspspspspspsp>spspspspspspsp>spsp>spspspspspspspspspspspspTable 3: Strategy-proofness: complete bases.consistent integrity constraints), still interested achieving resultclose beliefs/goals. Closeness captured notion distance,possible satisfaction index following Dalal index:Definition 11 (Dalal index) iDalal (K, K ) = 1min({dH (,K ) | |=K}).#(P)far know, index never carried out. sake homogeneityprevious indexes, greater iDalal (K, K ) satisfied agent associatedK. iDalal grows antimonotonically Hamming distance two basesconsideration, i.e., minimal distance model first basemodel second one. Thus, index takes minimal value every variable mustflipped obtain model K model K, takes maximal valuewhenever K consistent K (no flip required).direct observation iDalal (K, K ) idw (K, K ), whatever bases KK . Investigating strategy-proofness profile E Dalal index given mergingoperator integrity constraint makes sense situation K (E)inconsistent. Indeed, remaining case, iDalal (K, (E)) takes maximal value 1manipulation possible.contrast three previous indexes considered, merging operatorsstrategy-proof iDalal , even restricted situations.Theorem 8 None dD , , dD ,GM ax , dH , dH ,GM ax strategy-proof iDalal ,even restricted case E consists two complete bases.CTheorem 9 None 4Coperators (hence, none 4 operators) strategy-proofiDalal , even restricted case E consists two complete bases.b63fiEveraere, Konieczny & Marquis5.5 Restricted Strategiessituations agents participating merging processinformation bases agents. instance, cooperative problemsolving, decided whenever agent able answer query withinlimited amount time, communicate agents. Contrastingly,communication protocol may force agent inform agents definitelyable answer query. information exchanges allow agents getpartial view models countermodels true beliefs/goals agent,conflicts reported beliefs/goals, untruthful agent unmasked.clearly wrong thing untruthful agent since opinion could ignored;even punished guilty behaviour.consider two restrictions available manipulations (and correspondingnotions strategy-proofness): erosion manipulation agent pretends believe/desire (the agent gives parts models); dilatation manipulation agent pretends believe/desire less (the agentgives parts countermodels).Definition 12 (erosion dilation)Erosion manipulation holds reported base K 0 logically strongertrue one K: K 0 |= KDilation manipulation holds reported base K 0 logically weakertrue one K: K |= K 0 .Erosion (resp. dilation) manipulation safe untruthful agentagents may access subset countermodels (resp. models) truebeliefs/goals, unsafe general agents may access subsetmodels (resp. countermodels).next theorem gives dilation strategy-proofness model-based operators:Theorem 10 Let pseudo-distance let f aggregation function. d,fdilation strategy-proof indexes ip , idw ids .result compared ones unrestricted case (previous sections),operators strategy-proof.story erosion. One easily find profiles manipulatedusing erosion manipulation (see running example). Interestingly, focusing erosionstrategy-proofness proves sufficient situations. Indeed, distance,aggregation function drastic index id considered, d,strategy-proofid erosion strategy-proof id :Theorem 11 Let distance. d,strategy-proof index idw (resp.ids ), erosion strategy-proof idw (resp. ids ).result corollary, showing enough focus complete baseimplies K determine whether profile E manipulable base K idw :64fiThe Strategy-Proofness Landscape MergingCorollary 12 profile E manipulable K idw (resp. ids ) given d,manipulation possible using complete base K |= K, i.e., exists K |= Kd,d,s.t. idw (K, d,(E {K })) > idw (K, (E {K})) (resp. ids (K, (E {K })) >d,ids (K, (E {K}))).6. Discussionpaper, drawn strategy-proofness landscape many merging operators,including model-based ones formula-based ones. families strategyproof general case, shown several restrictions merging frameworkavailable strategies may lead strategy-proofness.model-based operators, choice right distance appears crucial. Thus,model-based operators strategy-proof based drastic distance,typically strategy-proof based Dalal distance.Among formula-based merging operators 4C1achieves highest degree strategyproofness sense strategy-proof drastic indexes.results summed Table 4 (sp means strategy-proof sp meansstrategy-proof). space reasons, results restricted strategies reported(see Section 5.5), well ones concerning complete bases (see Table 3).derived results, appears strategy-proofness easier achieveformula-based operators model-based ones, especially bases singlectons (i.e., 4Ci operators). could explained fact latteroperators obey all-or-nothing principle base either selected whole (and included maxcons) selected may forbid subtlemanipulations.also exhibited restricted strategies constrain agent wantsmanipulate. example, model-based operators strategy-proof dilation.results paper based three satisfaction indexes, are,according us, natural ones additional information mergingprocess available. three indexes share property two bases jointlyinconsistent, satisfaction minimal. call consistency property.order handle scenarios consistency property discriminant enough,introduced Dalal index. turns none operators considered paperstrategy-proof index.choice satisfaction index (by definition) major impact existencemanipulation. explained before, full preferences agents setsinterpretations available, strategy-proofness could easily defined Social ChoiceTheory: manipulation occurs merged base obtained agent liesstrictly preferred (w.r.t. preference) merged base obtainedreports true base. information available, several choicesindex possible, capturing different intuitions.beliefs merged, indexes satisfying consistency property seemsuited remaining ones; indeed, latter indexes, even merged base closeagents beliefs, still compatible them. Drawing conclusioneasy goals merged, since instance, case65fiEveraere, Konieczny & Marquis#(E)K,fH,H,Gmax4C14C34C44C54C14C34C44C5cccc>spspspspspspspspspspsp6 >spspspspspspspspspspsp>complete6 >spspspspspspspspspspspspspspspspspspspspspsp>spspspspspspspspspspsp6 >spspspspspspspspspspsp>complete6 >spspspspspspspspspspspspspspspspspspspspspsp>spspspspspspspspspspsp6 >spspspspspspspspspspsp>complete6 >spspspspspspspspspspspspspspspspspspspspspsp>spspspspspspspspspspsp6 >spspspspspspspspspspsp>complete6 >spspspspspspspspspspspspspspspspspspspspspsp>spspspspspspspspspspsp6 >spspspspspspspspspspsp>complete6 >spspspspspspspspspspspspspspspspspspspspspsp>spspspspspspspspspspsp6 >spspspspspspspspspspsp>complete6 >spspspspspspspspspspspspspspspspspspspspspspcomplete=2ipcomplete>2complete=2idwcomplete>2complete=2idscomplete>2Table 4: Synthesis results.66fiThe Strategy-Proofness Landscape Mergingagents, goals satisfied, better. Nevertheless, three satisfaction indexes idw ,ids ip still meaningful scenarios, since agent typically satisfiedgoals group compatible ones case.light study, strategy-proofness appears property independent computational complexity query answering merged base (see Konieczny et al., 2004).means low/high complexity prevent/imply strategy-proofness.Strategy-proofness appears also independent fact operator satisfiesrationality postulates given Konieczny Pino Perez (1999, 2002). Indeed, directconsequence Theorems 2 3, majority (resp. arbitration) mergingoperators (Konieczny & Pino Perez, 2002) strategy-proof, others not. Thus,satisfying rationality postulates merging proves sufficient ensure strategyproofness manipulability. Nevertheless, note arbitration operators, liked,GM ax , sensitive manipulation majority operators, like d, .easily explained fact arbitration operators egalitarist ones: aimgiving result close base profile. Intuitively, small changebase heavily change whole result. Contrastingly, majority operators, listenmajority wishes defining merged base, often take account basesfar majority. So, using majority operators, likely small changebase impact merged base.Thus, strategy-proofness viewed dimension usedcompare merging operators, besides computational complexity rationality criteria.independence latter criteria may also explain strategy-proofness resultswide families operators seem exist.7. Related Workexplained paper, manipulation problem studied extensivelySocial Choice Theory years. next subsection relate workstream research. second subsection mention related work concerningstrategy-proofness issue weighted bases.7.1 Social Choice Theorypropositional merging framework considered paper, beliefs/goals Kagent induce two-strata partition interpretations: models K equallypreferred, strictly preferred countermodels, equally disliked.agents report full preference relations (that encoded various ways, e.g., explicitly,prioritized base, ordinal conditional function, etc.), aggregation problemconsists defining global preference relation individual preference relations.problem addressed centuries Social Choice Theory. traced backleast Condorcet (1785) Borda (1781).Social Choice Theory (Arrow et al., 2002), strategy-proofness problem received great attention. framework, agent untruthful reportspreference relation (a complete pre-order set alternatives) trueone. social choice function (associating alternative profile preferencerelations) strategy-proof alternative chosen function lies67fiEveraere, Konieczny & Marquisranked higher alternative chosen reports true preferences.One famous result Social Choice Theory good strategyproof preference aggregation procedure. result known Gibbard-Satterthwaiteimpossibility theorem (Gibbard, 1973; Satterthwaite, 1975; Moulin, 1988).Formally, consider set agents (individuals) N = {1, . . . , n}, set alternatives= {a, b, . . .}. agent preference relation alternatives, supposedcomplete, reflexive transitive binary relation, noted . preference profileP = (1 , . . . , n ) assigns preference relation agent. Let us note P setpossible preference profiles. given preference profile noted P = (Pi , ),N , Pi denotes profile P without (the preferences of) individual i. socialchoice function f mapping P A. social choice function manipulableindividual N , preference relation 0 , preference profile Pf (Pi , 0i ) >i f (P ), i.e., agent best satisfied resultclaims preferences 0i instead true preference . social choice functionmanipulable, said strategy-proof. social choice function dictatorialindividual N (the dictator), f (P )P P. social choice function onto alternative preferenceprofile P P f (P ) = a. Gibbard-Satterthwaite theorem (Gibbard, 1973;Satterthwaite, 1975) stated as:Theorem 13 (Gibbard, 1973; Satterthwaite, 1975) contains least three alternatives, social choice function f onto, strategy-proof non-dictatorial.Since result stated, lot work deriving strategyproofness results restrictions (see Kelly, 1988; Arrow et al., 2002).sense, work relevant approaches. Nonetheless, work original - farknow - two points view: one hand, preference relations consideredtwo-strata total pre-orders, arbitrary pre-orders; hand,result merging process usually single interpretation still two-strata totalpre-order (and number models merged base constrained priori).leads complex notions strategy-proofness different definitions possible,depending index formalizes one various intuitive notions satisfiedagent result merging process.social choice theory, also works social choice correspondences,mapping P 2A , closer framework social choice functions. data coming individuals preference relations A, problemshift preference relations 2A . standard way achieve considereven set chosen correspondence, ultimately one alternativerealized, suppose individual subjective probability measurerealization. social choice correspondance strategy-proof possibleindividual increase expected utility result. case, results similar Gibbard-Satterthwaite theorems derived (see e.g., Barbera, Dutta, & Sen,2001; Chin & Zhou, 2002; Duggan & Schwartz, 2000). works related oneconducted paper, suppose agent makes availablefull preference relation alternatives form utility function typicallyreducible two-strata complete pre-order also subjective probability measure68fiThe Strategy-Proofness Landscape Mergingalternatives. Contrastingly, work, information coming agentcorresponding base, typically approximates full preference relation,pure ordinal nature.7.2 Strategy-Proofness Weighted-Bases Mergingstudy strategy-proofness merging operators carried Meyer,Ghose, Chopra (2001). framework consider distinct one usedwork. one hand, agents may report full preference relations (encodedordinal conditional functions, also called -functions, see Spohn, 1987). hand,merging operators consideration escape Gibbard-Satterthwaite theorem sinceMeyer et al. (2001) make commensurability assumption agents preferencerelations (the remark applies also possibilistic base merging defined Benferhat,Dubois, Kaci, & Prade, 2002). Roughly, commensurability assumption amountsconsider weights (or levels) associated formulas meaningagents, i.e., weight 3 agent 1 weight 3 agent2. commensurability assumption sensible many situations, dealingagents preferences, commensurability must used carefully. human agents,commonly accepted Social Choice Theory assumption strong. Arrow(1963) illustrates idea quoting Bentham:vain talk adding quantities addition continuedistinct before, one mans happiness never another manshappiness: gain one man gain another; might well pretendadd 20 apples 20 pears...notion strategy-proofness merging operators Meyer et al. (2001)Chopra, Ghose, Meyer (2006) defined framework ordinal conditional functions. section, study corresponding operators pure propositionalframework, i.e., profile contains flat belief/goal bases, order compareapproach.ordinal conditional function (OCF) total function set interpretations W set non-negative integers (originally, OCF maps interpretationclass ordinals, least one interpretation mapped zero,considering integers sufficient here). Intuitively, greater number, lesscredible interpretation. OCF one associate base Bel() defined[Bel()] = { W | () = min0 W (( 0 ))}. aim OCF merging operators is,profile OCFs E = {1 , . . . , n } define OCF (E) best representsprofile. operators studied Meyer et al. (2001) following ones:max (E)() = maxi E (),21 () () = j () , j Emin1 (E)() =2 mini E () + 1 otherwise,1 () () = j () , j Emin2 (E)() =mini E () + 1 otherwise,69fiEveraere, Konieczny & Marquis(E)() =PE().straightforward way translate framework propositional merging ordinal conditional functions consider propositional base special case OCF:propositional base two-strata OCF, models bases rank 0countermodels rank 1. consider two-strata OCFs note Ki = Bel(i )= Bel( ), previous definitions merging operators give:Vmax (E) min2 (E) E consistent max (E) min2 (E) > otherwise.VWmin1 (E) E consistent min1 (E) E otherwise.(E) dD , (E).resulting propositional merging operators max , min1 , min2 , quitesimple well-known. max (or equivalently min2 ) so-called basic merging operator (in absence integrity constraints) (Konieczny & Pino Perez, 1999). min11-quota operator defined Everaere, Konieczny, Marquis (2005) (without integrityconstraints). corresponds intersection operator defined Konieczny (2000).operators strategy-proof indexes:Theorem 14 max , min1 , min2 , strategy-proof idw , ids ip .Besides operators, Meyer, Chopra Ghose also proposed general definitionsstrategy-proofness OCF merging. precisely, studied two properties.first one (IP) property (Meyer et al., 2001):Definition 13 (IP) OCF merging operator satisfies (IP) propertyevery OCF profile E, every agent i, whatever OCFW, | (E)() ()| | (rep(E, {i}, )() ()|rep(E, {i}, ) profile identical E except OCF replaced .Focusing two-strata OCFs, say merging operator (= Bel( )) strategyproof (IP) satisfies (IP) property every agent given profile.obtained following characterization:Theorem 15 strategy-proof (IP) every profile E every pairbases K K 0 :K (E {K}) |= (E {K 0 }),K (E {K}) |= (E {K 0 }).second strategy-proofness property Meyer, Chopra Ghose investigated (WIP):70fiThe Strategy-Proofness Landscape MergingDefinition 14 (WIP) OCF merging operator satisfies (WIP) propertyevery profile E, every agent i, whatever OCF :W | (E)() ()| W | (rep(E, {i}, )() ()|.(WIP) weaker (IP) sense OCF merging operator satisfies(IP) agent i, satisfies (WIP) (but converse always hold).Again, focusing two-strata OCFs, say merging operator (= Bel( ))strategy-proof (WIP) satisfies (WIP) property every agentgiven profile.VVVVLet us note exclusive operator, i.e., K K 0 = ( K K 0 ) ( K K 0 ).(WIP) characterized framework :Theorem 16 Let iwip (K, K ) =strategy-proof iwip .1#([KK ])+1 .satisfies (WIP) propertyNote wip index iwip close probabilistic index ip . probabilistic index measures closeness merged base agent base, whereas wipindex measures difference merged base agent base.However, corresponding notion strategy-proofness (and fortiori one induced(IP)) appears strong pure propositional setting. Consider following beliefmerging scenario:Example 6 Consider K = K1 = b.We dH , ({K, K1 }) b.agent gives K 0 = {a b} instead K, merged base dH , ({K 0 , K1 }) a.Accordingly, example manipulation (WIP) (iwip (dH , ({K, K1 })) = 12 <iwip (dH , ({K 0 , K1 })) = 1).example, untruthful agent actually manages change merged baseone similar initial base (with respect iwip ).fully satisfied merged base equivalent b still strictly prefers initialbase {a}, despite fact b refines beliefs. Accordingly, agentwants preserve beliefs ignorance. many scenarios agentparticipates merging process order get new information, counter-intuitive.Chopra et al. (2006) give general definitions strategy-proofness, consideringsimilarity relations. propositional case, suffer above-mentioneddrawback. explains investigate strategy-proofness purelypropositional model-based operators formula-based operators criteria like (WIP)(IP).8. ConclusionInvestigating strategy-proofness merging operators important multi-agentperspective whenever agents get information conveyed agentsparticipating merging process. strategy-proofness guaranteed, mayquestioned whether result merging process actually represents beliefs/goalsgroup.71fiEveraere, Konieczny & Marquispaper, drawn strategy-proofness landscape many existing mergingoperators, including model-based ones formula-based ones, general caseseveral natural restrictions. Strategy-proofness appears independent complexityrationality aspects, used such, criterion evaluate mergingoperators. results discussed Section 6.work calls number perspectives. first perspective identify complexity determining whether profile manipulated base given operator.Indeed, using merging operator strategy-proof necessarily harmful finding strategy computationally hard. complexity issue investigatedvoting schemes (Conitzer & Sandholm, 2003; Conitzer, Lang, & Sandholm, 2003; Conitzer& Sandholm, 2002a, 2002b) individual preferences given explicitly (whichcase framework). first result follows easily Theorem 11: distanceinterpretations computed polynomial time input size (whichstrong assumption), determining whether given profile manipulated basepdrastic index given d,2 .Social Choice Theory, Gibbard-Sattertwhaite theorem states every sensiblesocial choice function manipulable. Taking account fact agentstempted manipulate transforms aggregation process game agents.ensuring strategy-proofness, prove sufficient build game tellingtruth optimal strategy agent. achieve aim implementationtheory (also called mechanism design), see e.g., Maskin & Sjostrom, 2002. perspectivedetermine whether building mechanisms possible belief merging settingorder force agents tell truth. work mechanism design assumetransferable utility, use payments part process. Importing ideasfully qualitative framework surely hard task.Another interesting perspective study strategy-proofness problem coalitions allowed. Instead considering manipulation single agents, one interested manipulation coalition agents coordinate improve resultcoalition. See (Meyer et al., 2001; Chopra et al., 2006) definition differentframework. Since manipulation single agent particular case manipulationcoalition, since seen many operators strategy-proof singleagent, clear strategy-proofness results coalitions hard achieve.Acknowledgementsauthors would like thank anonymous referees thoughful commentshelped us lot improve paper. authors supported UniversitedArtois, Region Nord/Pas-de-Calais, IRCICA Consortium, EuropeanCommunity FEDER Program.72fiThe Strategy-Proofness Landscape MergingAppendix A. ProofsTheorem 11. merging operator strategy-proof ip , strategy-proof idw .2. Consider merging operator generates consistent bases.5 strategyproof ip , strategy-proof ids .Proof:1. Assume strategy-proof idw . exists profile E, baseK, base K 0 integrity constraint s.t. (1) (E {K}) K inconsistent,#([K][ (Et{K})])= 0. (2)(2) (E {K 0 }) K consistent. (1) implies #([ (Et{K})])implies#([K][ (Et{K 0 })])#([ (Et{K 0 })])> 0. Hence, strategy-proof ip .2. Assume strategy-proof ids . exists profile E, baseK, base K 0 integrity constraint s.t. (1) (E {K}) 6|= K, (2)#([K][ (Et{K})])(E {K 0 }) |= K. (1) implies #([ (Et{K})])6= 1. (2) implies#([K][ (Et{K 0 })])#([ (Et{K 0 })])= 1 (E {K 0 }) consistent. Hence, strategy-proof ip .Theorem 2Let f aggregation function. dD ,f strategy-proof ip , idw ids .Let distance. Provided two bases merged, d,> strategyproof indexes idw ids .distance d, d,strategy-proof indexes ip , idw idsinitial base K complete.Proof:Let f aggregation function. dD ,f strategy-proof ip , idw ids .proof organized three steps: reduction ad absurdum, showminimal drastic distance model E {K} equal minimaldrastic distance model E {K 0 }. Then, easy shownumber Ks models greater E {K} E {K 0 }. Finally, provenumber countermodels K greater E {K 0 } E {K},entails contradiction.5. I.e., (E) always consistent.73fiEveraere, Konieczny & MarquisTheorem 1, know operator dD ,f strategy-proof ip , alsostrategy-proof idw ids (indeed, dD ,f (E) always consistent).sufficient prove strategy-proofness dD ,f ip prove strategy-proofnessthree indexes.Let us prove reductio ad absurdum: assume operator dD ,f ,dD drastic distance f aggregation function, strategy-proofip . exist integrity constraint , profile E, two bases KK 0 s.t. ip (K, dD ,f ({K} E)) < ip (K, dD ,f ({K 0 } E)), equivalent#([K] [E 4dD ,f K])#([E 4dD ,f K])<#([K] [E 4dD ,f K 0 ])#([E 4dD ,f K 0 ])E 4dD ,f K light notation dD ,f ({K} E)). Let us note dmin (E tdD ,f{K}) = min({dD (, E {K}) | |= }, ). show dmin (E tdD ,f {K}) =dmin (E tdD ,f {K 0 }):Let us first notice ip (K, E 4dD ,f K) 6= 1: ip (K, E 4dD ,f K) = 1,probabilistic satisfaction index takes maximal value, impossible increase it.Since ip (K, E 4dD ,f K) < 1, #([K][E 4dD ,f K]) < #([E 4dD ,f K]),least one model E 4dD ,f K belong K:1 |= (K) , dD (1 , E {K}) = dmin (E tdD ,f {K}).Since 1 |= (K) , dD (1 , K) = 1 distance maximal(because use drastic distance). get immediately dD (1 , K)dD (1 , K 0 ). Hence dD (1 , E t{K}) dD (1 , E t{K 0 }) (because aggregationfunction f satisfy non-decreasingness). Since dD (1 , E {K}) = dmin (E tdD ,f{K}), get dmin (E tdD ,f {K}) dD (1 , E {K 0 }). Since dD (1 , E {K 0 })dmin (E tdD ,f {K 0 }) definition min since 1 |= ,dmin (E tdD ,f {K}) dmin (E tdD ,f {K 0 }) ().also conclude ip (K, E 4dD ,f K 0 ) 6= 0: ip (K, E 4dD ,f K 0 ) = 0,ip (K, E 4dD ,f K 0 ) minimal, value taken ip increased,contradicts assumption (manipulation).ip (K, E 4dD ,f K 0 ) 6= 0, find least one model KE 4dD ,f K 0 : 1 |= K , dD (1 , E t{K 0 }) = dmin (E tdD ,f {K 0 }). Since 1 |= K,dD (1 , K) = 0 since distance minimal, get dD (1 , E{K}) dD (1 , E {K 0 }), dD (1 , E {K}) dmin (E tdD ,f {K 0 }),dD (1 , E {K 0 }) = dmin (E tdD ,f {K 0 }). Furthermore, since dD (1 , E{K}) dmin (E tdD ,f {K}) definition min 1 |= , have:dmin (E tdD ,f {K}) dmin (E tdD ,f {K 0 }) ().74fiThe Strategy-Proofness Landscape Merginginequations (*) (**), get:dmin (E tdD ,f {K}) = dmin (E tdD ,f {K 0 }).(1)Let us show increase number countermodels KE 4dD ,f K 0 , decrease number models K E 4dD ,f K 0 .Let countermodel K model E 4dD ,f K: |= (K)(E 4dD ,f K).Since |= K, dD (, K) = 1 distance maximal. HencedD (, K) dD (, K 0 ). So:dD (, E {K}) dD (, E {K 0 })(2)aggregation function f satisfies non-decreasingness.Since |= E 4dD ,f K, dD (, E {K}) = dmin (E tdD ,f {K}). (2),get dmin (E tdD ,f {K}) dD (, E {K 0 }).Since dmin (E tdD ,f {K}) = dmin (E tdD ,f {K 0 }) (1), obtain: dmin (E tdD ,f{K 0 }) dD (, E {K 0 }). definition min since |= (because |=E 4dD ,f K), deduce model E 4dD ,f K 0 . concludeevery model E 4dD ,f K model K model E 4dD ,f K 0 .Hence: [K] [E 4dD ,f K] [K] [E 4dD ,f K 0 ].Finally, let model K model E 4dD ,f K 0 : |= K (E 4dD ,fK 0 ). Since |= K, dD (, K) = 0 distance minimal. HencedD (, K) dD (, K 0 ). So:dD (, E {K}) dD (, E {K 0 })(3)aggregation function non-decreasing.Since |= E 4dD ,f K 0 , dD (, E {K 0 }) = dmin (E tdD ,f {K 0 }).(3), get dD (, E {K} dmin (E tdD ,f {K 0 }). Since dmin (E tdD ,f {K}) =dmin (E tdD ,f {K 0 }) (1), obtain dD (, E {K} dmin (E tdD ,f {K}).definition min since |= (because |= E 4dD ,f K 0 ), deducemodel E 4dD ,f K. conclude every model E 4dD ,f K 0model K model E 4dD ,f K. follows [K] [E 4dD ,f K 0 ][K] [E 4dD ,f K].Since increase number countermodels K E 4dD ,f K 0decrease number models K E 4dD ,f K 0 , proportion models KE 4dD ,f K 0 smaller E 4dD ,f K. contradicts assumption showsdD ,f strategy-proof ip .Let distance. Provided two bases merged, d,>strategy-proof indexes idw ids .75fiEveraere, Konieczny & Marquisproof, first show merging two bases consistent base.Then, property follows directly.Strategy-proofness two drastic indexes direct consequence followingproperty:d,Lemma 1 E = {K1 , K2 }, d,> (E) K1 > (E) K2 consistent.Proof:show d,> (E) K1 consistent (the remaining case similarsymmetry). Reductio ad absurdum. Let us suppose two bases K1 K2 ,d,> ({K1 , K2 }) inconsistent K1 . deduce that:0 |= K1 , |= K1 , d(, K1 4d, K2 ) > d( 0 , K1 4d, K2 ),K1 4d, K2 light notation d,> ({K1 , K2 }).Since |= K1 , d(, K1 ) = 0, get 0 |= K1 , |= K1 , d(, K2 ) >d( 0 , K1 ) + d( 0 , K2 ). particular, consider 1 |= K1 s.t. d( 0 , 1 ) = d( 0 , K1 )(such 1 exists definition d( 0 , K1 )), have: d(1 , K2 ) > d( 0 , 1 ) +d( 0 , K2 ). Similarly, consider 2 |= K2 s.t. d( 0 , 2 ) = d( 0 , K2 ), get:d(1 , K2 ) > d( 0 , 1 ) + d( 0 , 2 ) ().definition d, |= K2 , d(1 , K2 ) d(1 , ); particular, d(1 , K2 )d(1 , 2 ). transitivity , (*), get d(1 , 2 ) > d( 0 , 1 ) + d( 0 , 2 ).contradicts triangular inequality.Let us prove main theorem:Weak drastic index. two bases K1 K2 , always idw (K1 , K1 4 K2 ) = 1,d,> ({K1 , K2 }) K1 consistent (Lemma 1), manipulation possible(idw maximal).0Strong drastic index. d,> strategy-proof, find K1 s.t.:d,0ids (K1 , d,> ({K1 , K2 }) < ids (K1 , > ({K1 , K2 }).strong drastic index, means exactly that:d,> ({K1 , K2 }) 6|= K1(4)0d,> ({K1 , K2 }) |= K1 .(5)and:0Since d,> ({K1 , K2 }) K2 consistent (Lemma 1), find 2 |= K2 s.t. 2 |=0d,> ({K1 , K2 }). (5), conclude 2 |= K1 well.Since 2 |= K1 K2 , conclude every model d,> ({K1 , K2 }),d,d(, {K1 , K2 }) = 0. |= > ({K1 , K2 }), d(, K1 ) = d(, K2 ) = 0.Hence |= d,> ({K1 , K2 }), |= K1 K2 . contradicts (4), manipulationpossible.76fiThe Strategy-Proofness Landscape Mergingdistance d, d,strategy-proof indexes ip , idw idsinitial base K complete.drastic indexes, result consequence Theorem 11, showingmanipulation occurs initial base K, manipulation complete baseK |= K possible. K complete, manipulation possible.probabilistic index, result consequence triangular inequality.Drastic indexes. property direct consequence Theorem 11, showingd,manipulable idw ids base K, manipulable erosion.manipulation erosion impossible whenever K complete.Probabilistic index. reductio ad absurdum: let us suppose operatord,, distance, manipulable ip given complete base K ={1 }. So, exists integrity constraint , profile E, base K 0 s.t.:d,0ip ({1 }, d,({1 } E)) < ip ({1 }, ({K } E)).d,ip ({1 }, d,({1 } E)) = 0, idw ({1 }, ({1 } E)) = 0 too. case,manipulation ip implies manipulation idw seen manipulation possible idw . consequence, suppose ip ({1 }, d,({1 }E)) 6= 0. Equivalently:#({1 } [E 4{1 }])6= 0#([E 4 {1 }])d,(where E 4{1 } light notation ({1 } E)).statement allows us infer 1 model E 4{1 }. orderd,00increase ip ({1 }, (K E)), reduce number models E 4K0compared E 4 {1 }, without removing 1 [E 4 K ]. find02 6= 1 s.t. 2 |= E 4{1 } 2 6|= E 4 K . So, 2 |= d(2 , E0{1 }) = d(1 , E {1 }) and: d(2 , E {K }) > d(1 , E {K 0 }) (because 10model E 4{1 } E 4 K ). aggregation function , get:d(2 , 1 ) + d(2 , E) = d(1 , E) d(2 , K 0 ) + d(2 , E) > d(1 , K 0 ) + d(1 , E).Replacing d(1 , E) d(2 , 1 )+d(2 , E), obtain d(2 , K 0 )+d(2 , E) > d(1 , K 0 )+d(2 , 1 ) + d(2 , E), d(2 , K 0 ) > d(1 , K 0 ) + d(2 , 1 ). 10 model K 0 s.t.d(1 , K 0 ) = d(1 , 10 ), d(2 , K 0 ) > d(1 , 10 ) + d(2 , 1 ). Furthermoredefinition min, d(2 , 10 ) d(2 , K 0 ), d(2 , 10 ) > d(1 , 10 ) + d(2 , 1 )contradicts triangular inequality.Theorem 3dH , strategy-proof idw ids ( > #(E) = 2) Kcomplete.dH , strategy-proof ip K complete.77fiEveraere, Konieczny & MarquisProof:Theorem 2 entails straightforwardly part proof, takingHamming distance dH d.part proof, shall show examples manipulation dH ,strategy-proof cases.first examples show dH , strategy-proof idw ids ( 6 >#(E) 6= 2), K complete.Weak drastic index.idw 6 > (K complete)consider constraint = ab two bases K1 K2 definedset models: [K1 ] = {00, 01} [K2 ] = {10}. [dH , ({K1 , K2 })] ={10} idw (K1 , dH , ({K1 , K2 })) = 0. hand, agent whosebase K1 gives K10 , [K10 ] = {01} instead K1 , obtain [dH , ({K10 ,K2 })] = {01, 10, 11} idw (K1 , dH , ({K10 , K2 }) = 1. example showsmanipulability dH , 6 >, even two bases profile.Computations detailed Table 5. Interpretations satisfyconstraint shaded.00011011dH (, K1 )0011dH (, K10 )1021dH (, K2 )1201H,H({K1 , K2 })1212,({K10 , K2 })2222Table 5: Manipulability dH , idw 6 >.idw #(E) 6= 2 (K complete)Let us consider three bases [K1 ] = {00, 10}, [K2 ] = {01, 10, 11} [K3 ] ={01}. d>H , ({K1 , K2 , K3 }) unique model 01 idw (K1 , d>H , ({K1 ,K2 , K3 }) = 0. consider [K10 ] = {10} instead K1 , [d>H , ({K10 ,K2 , K3 })] = {01, 10, 11} idw (K1 , dH , ({K10 , K2 , K3 }) = 1. See Table 6.00011011K10101K101201K21000K31021>H,({K1 , K2 , K3 })2122>H,({K10 , K2 , K3 })3222Table 6: Manipulability d>H , idw #(E) 6= 2.Strong drastic index.78fiThe Strategy-Proofness Landscape Mergingids 6 > (K complete)consider constraint = (a b) (a b c) two bases K1K2 defined sets models: [K1 ] = {000, 111} [K2 ] = {000, 001}.[dH , ({K1 , K2 })] = {111, 100} ids (K1 , dH , ({K1 , K2 })) = 0.hand, agent whose base K1 gives K10 , [K10 ] = {111} insteadK1 , obtain [dH , ({K10 , K2 })) = {111} ids (K1 , dH , ({K10 , K2 }) = 1.example shows manipulability dH , ids 6 >, eventwo bases profile. Details computation reportedTable 7.000001010011100101110111K101111110K1032212110K200111122H,({K1 , K2 })01222232H,({K10 , K2 })32323232Table 7: Manipulability dH , ids 6 >.ids #(E) 6= 2 (K complete)Let us consider three bases [K1 ] = {000, 001, 111}, [K2 ] = {110, 001}[K3 ] = {110, 000}. [d>H , ({K1 , K2 , K3 })] = {000, 001, 110}ids (K1 , d>H , ({K1 , K2 , K3 }) = 0.consider [K10 ] = {000, 001} instead K1 , [d>H , ({K1 , K2 , K3 })] ={000, 001} ids (K1 , d>H , ({K10 , K2 , K3 }) = 1. See Table 8.000001010011100101110111K100111110K1000111122K210111101K301121201>H,({K1 , K2 , K3 })11343412>H,({K10 , K2 , K3 })11343424Table 8: Manipulability dH , ids #(E) 6= 2.following example shows dH , strategy-proof ip K complete. Table 9 shows manipulability d>H , ip (even two basesprofile >). Let us consider two bases K1 K2 definedsets models: [K1 ] = {000, 001, 010, 100} [K2 ] = {110, 011, 101, 111}.79fiEveraere, Konieczny & Marquis[d>H , ({K1 , K2 })] = {001, 010, 100, 110, 011, 101} ip (K1 , d>H , ({K1 , K2 })) = 21 .hand, agent whose base K1 gives K10 , [K10 ] = {000} instead K1 , obtain [d>H , ({K10 , K2 })] = {000, 001, 010, 100, 110, 011, 101}ip (K1 , d>H , ({K10 , K2 }) = 47 .000001010011100101110111K100010112K1001121223>HK221101000,({K1 , K2 })21111112>H,({K10 , K2 })22222223Table 9: Manipulability d>H , ip K complete.Theorem 4dH ,GM ax strategy-proof satisfaction indexes idw ip (even >,K complete #(E) = 2).dH ,GM ax strategy-proof satisfaction index ids >, Kcomplete #(E) = 2.Proof:Table 10 shows manipulability dH ,GM ax weak satisfaction index idweven >, K complete #(E) = 2. consider K1 s.t. [K1 ] = {001}, K2[K2 ] = {111}, >. [dH ,GM ax ({K1 , K2 })] = {011, 101},model K1 belongs [dH ,GM ax ({K1 , K2 })] idw (K1 , dH ,GM ax ({K1 , K2 }) = 0.agent 1 gives K10 [K10 ] = {000} instead K1 , [dH ,GM ax {K10 , K2 })] ={001, 010, 011, 100, 101, 110} idw (K1 , dH ,GM ax ({K10 , K2 }) = 1.000001010011100101110111K110212132K1001121223K232212110H,GM ax({K1 , K2 })(3, 1)(2, 0)(2, 2)(1, 1)(2, 1)(1, 1)(3, 1)(2, 0)H,GM ax({K10 , K2 })(3, 0)(2, 1)(2, 1)(2, 1)(2, 1)(2, 1)(2, 1)(3, 0)Table 10: Manipulability dH ,GM ax idw .80fiThe Strategy-Proofness Landscape MergingSince manipulability idw holds, manipulability ip holds well (cf. Theorem 1).ids , first show dH ,GM ax strategy-proof index >,#(E) = 2 K complete. Then, give examples manipulation 6 >,#(E) 6= 2, K complete.d>H ,GM ax strategy-proof E = {K1 , K2 } >, K1 complete.consider E 0 = {K10 , K2 } K10 = K0 1 complete (thanks forthcomingLemma 2, know operator manipulable, manipulablecomplete base), >. Let #(P) = n let d(K10 , K2 ) = n.exists model 2 K2 s.t. dH (K0 1 , 2 ) = m. definitionHamming distance, 2 generated 1 flipping variables (sinceK0 1 2 differ truth values variables x1 , . . . , xm ).= 2k + 1 (m odd), d(>, E 0 ) = (k + 1, k); otherwise = 2k (meven) d(>, E 0 ) = (k, k). first case (m odd), exist least twointerpretations 0 s.t. d(, E 0 ) = d( 0 , E 0 ) = d(>, E 0 ) (for instance,generated 1 flipping x1 , . . . , xk 0 generated 2 flippingxk+1 , . . . , xm ).similar conclusion derived second case (m even) soon k 1.two cases, d>H ,GM ax (E 0 ) least two models, hence cannotd>H ,GM ax (E 0 ) K1 K1 complete: E cannot manipulated K1 ids .remaining case d(>, E 0 ) = (0, 0). imposes K0 1 K2 consistent.Since K0 1 complete, d>H ,GM ax (E 0 ) K0 1 , hence manipulationdH ,GM axpossible ids (since >(E 0 ) K1 K1 K0 1dH ,GM ax>({K1 , K2 }) K1 ).showing manipulability ids , consider following scenarios:6 >, even #(E) = 2 K complete.Let us consider [K1 ] = {01}, [K2 ] = {11}, = b. [dH ,GM ax ({K1 ,K2 }] = {01, 11}, ids (K1 , dH ,GM ax ({K1 , K2 }) = 0. agent 1 gives K10[K10 ] = {00} instead K1 , result [dH ,GM ax ({K10 , K2 })] ={01} ids (K1 , dH ,GM ax ({K10 , K2 }) = 1. (see Table 11).00011011K11021K100112K22110H,GM ax({K1 , K2 })(2, 1)(1, 0)(2, 1)(1, 0)H,GM ax({K10 , K2 })(2, 0)(1, 1)(1, 1)(2, 0)Table 11: Manipulability dH ,GM ax ids 6 >#(E) 6= 2, even > K complete.Let us consider [K1 ] = {01}, [K2 ] = {11}, [K3 ] = {00, 01, 11}.[d>H ,GM ax ({K1 , K2 , K3 }] = {01, 11}, ids (K1 , d>H ,GM ax ({K1 , K2 , K3 }) =81fiEveraere, Konieczny & Marquis0. agent 1 gives K10 [K10 ] = {00} instead K1 , [d>H ,GM ax ({K10 ,K2 , K3 })] = {01} ids (K1 , d>H ,GM ax ({K10 , K2 , K3 }) = 1. (see Table 12).00011011K11021K100112K22110K30010H,GM axH({K1 , K2 , K3 })(2, 1, 0)(1, 0, 0)(2, 1, 1)(1, 0, 0),GM ax({K10 , K2 , K3 })(2, 0, 0)(1, 1, 0)(1, 1, 1)(2, 0, 0)Table 12: Manipulability d>H ,GM ax ids #(E) 6= 2.K complete, even > #(E) = 2.example given Table 13 shows manipulation possible initial base complete. Consider [K1 ] = {01, 10}, [K2 ] = {11},>. [dH ,GM ax ({K1 , K2 }] = {01, 10, 11}, ids (K1 , dH ,GM ax ({K1 ,K2 }) = 0. agent 1 gives K10 [K10 ] = {00} instead K1 ,[dH ,GM ax ({K10 , K2 })] = {01, 10} ids (K1 , dH ,GM ax ({K10 , K2 }) = 1.00011011K11001K100112K22110H,GM ax({K1 , K2 })(2, 1)(1, 0)(1, 0)(1, 0)H,GM ax({K10 , K2 })(2, 0)(1, 1)(1, 1)(2, 0)Table 13: Manipulability dH ,GM ax ids K complete.Theorem 5C3C4C54C1, 4 , 4 , 4 strategy-proof ip (even >, K complete#(E) = 2).4C1strategy-proof idw ids .4C3strategy-proof idw ids >.4C4strategy-proof idw ids (even >, K complete #(E) = 2).4C5strategy-proof idw > K complete, strategyproof ids >.Proof:82fiThe Strategy-Proofness Landscape Mergingfirst give example manipulation 4C1ip , #(E) = 2, completebase K1 , >.Consider E = {K1 , K2 }, K1 = {a b} K2 = {(a b)}. 4C1> (E) >,10 = {a, b} instead K ,ip (K1 , 4C1(E))=.agent1givesK11>410C104C1> ({K1 , K2 }) b, ip (K1 , 4> ({K1 , K2 })) = 3 . E manipulable K1C1C3ip . example holds 4C4. remains note 4> = 4> =4C5> conclude first point proof.4C1strategy-proof idw ids .Weak drastic index.K E two cases:Ksubsetconsistent. least one maximal consistentC1Ki E Ki contains formulas K. 4 (E t{K}) R(where R denotes disjunction maxcons) consistent K .idw (K, 4C1(E {K})) = 1 manipulation possible.0K consistent. Since K 0 , 4C1(E {K })) |= , alsoC10idw (K, 4 (E {K })) = 0 manipulation possible.Strong drastic index.reductio ad absurdum. Assume 4C1strategy-proof ids . meansK s.t. 4C1(6)(E {K}) 6|= K,0K 0 s.t. 4C1(E {K }) |= K.(7)statement (7) get maxcons(E {K 0 }, ), |= K.000consider 4C1(E {K } {K}), every maxcons(E {K } {K}, )0C10form {K}, |= K 4 (E {K } {K}) |= K ().statement (6) get maxcons(E {K}, ), 6|= K. Sincemaximal subset, means K consistent. consider 4C1(E{K 0 } {K}), 0 , 0 maxcons(E {K 0 } {K}, ). 0 K0consistent. Hence 0 6|= K 4C1(E {K} {K }) 6|= K, contradicts().4C3strategy-proof idw ids >.Weak drastic index.C3C1C3Since 4C1> = 4> , follows immediately proof 4 4>strategy-proof idw .showing manipulation possible 4C36 >, even two basescomplete initial base K1 , consider following example: let K1 = {ab}, K2 = {a},= b K10 = {a}. C3({K1 , K2 }) a, inconsistent K1 .0 , K }) >, consistent K .also C3({K21183fiEveraere, Konieczny & MarquisStrong drastic index.C3C3Since 4C1> = 4> , follows immediately point 4> strategyproof ids .showing manipulation possible 4C3ids 6 >, even twobases complete initial base K1 , consider following example: let K1 = {ab}, K2 = {a}, = b K10 = {a b}. C3({K1 , K2 }) a, henceC3C300({K1 , K2 }) 6|= K1 . also ({K1 , K2 }) , hence C3({K1 , K2 }) |=K1 .4C4strategy-proof idw ids (even >, K complete #(E) = 2).Weak drastic index.showing manipulation possible 4C4two bases, complete initial base K1 >, consider following example: let K1 = {a}, K2 ={a, >}, = > K10 = {a, >}. C4({K1 , K2 }) a, henceC40({K1 , K2 }) K1 consistent. also C4({K1 , K2 }) >, henceC40({K1 , K2 }) K1 consistent.Strong drastic index.showing 4C4strategy-proof ids two bases, complete initialbase K1 >, consider following example: let K1 = {a}, K2 = {a},C4K10 = {a, >}. C4({K1 , K2 }) >, hence ({K1 , K2 }) 6|= K1 . also0C40C4({K1 , K2 }) a, hence ({K1 , K2 }) |= K1 .4C5strategy-proof idw > K complete, strategyproof ids >.Weak drastic index.C5C1C5Since 4C1> = 4> , follows proof 4 4 strategy-proofidw >.initial base K1 complete, 4C5also strategy-proof. two cases:K1 |= . Let= { KE K | K1 |= }. construction, elementmaxcons( KE K, >). Since K1 |= , consistent (K1 modelthem). Since K1 |= |= C5(E) (by definitionC5 (E) K consistent,operator), also K1 |= C5(E).Hence1prevents E manipulable K1 idw given C5.K1 |= . definition operator, base K10 profile E 000(especially profile obtained removing K1 E), C5({K1 }tE )00C500consistent C5({K1 } E ) |= . implies ({K1 } E ) K1inconsistent, manipulation possible idw .showing manipulation possible 4C56 > initial base K1complete, consider following example:84fiThe Strategy-Proofness Landscape Merginglet K1 = {a}, K2 = {b, a}, = ab K10 = {ab}. C5({K1 , K2 })C5C5b a, hence ({K1 , K2 }) K1 consistent. also ({K10 , K2 })0(a b) (b a), hence C4({K1 , K2 }) K1 consistent.Strong drastic index.C5C1C5Since 4C1> = 4> , follows immediately proof 4 4strategy-proof ids >.showing manipulation possible 4C56 >, even two basescomplete initial base K1 , consider following example: let K1 = {a b},K2 = {b}, = K10 = {a b, b a}. C5({K1 , K2 }) a, henceC5C500({K1 , K2 }) 6|= K1 . also ({K1 , K2 }) ab. Hence C5({K1 , K2 }) |=K1 .Theorem 64C1strategy-proof idw ids , strategy-proof ip #(E) =2.c4C3strategy-proof idw ids >, strategy-proof ip#(E) = 2 >.c4C4strategy-proof ip , idw ids .c4C5strategy-proof idw #(E) = 2 > K complete.cC54C5strategy-proof ids #(E) = 2 >. Finally, 4strategy-proof ip #(E) = 2.ccProof:4C1strategy-proof idw ids , strategy-proof ip #(E) =2.cDrastic indexes. strategy-proofness 4C1comes strategy-proofnesscC1C14C1reported Theorem 5, 4 specialization 4 . Furthermore,C1examples given proof Theorem 5 concerning 4 , every basecsingleton, examples hold 4C1too.cProbabilistic index.proof probabilistic index profile E s.t. #(E) = 2 based factcmerging two bases 4C1either conjunction two bases,disjunction. cases, shall show manipulation occur.part proof, suppose #(E) = 2. shall show 4C1c4C5(we group two cases, proofs similar) strategy-proofip . case analysis:c85fiEveraere, Konieczny & MarquisK1 consistent , two cases:C54C1({K1 , K2 }) 4 ({K1 , K2 }) K1 K2 consistent.ccC54C1({K1 , K2 }) 4 ({K1 , K2 }) (K1 K2 ) otherwise.ccC5first case, 4C1({K1 , K2 }) |= K1 4 ({K1 , K2 }) |= K1 ip takesmaximal value, manipulation possible.ccC5Let us consider second case 4C1(the case 4 similar): assumecc4C1({K1 , K2 }) (K1 K2 ) .cC10Since every base K10 , definition 4C1requires 4 ({K1 ,ccK2 }) |= since K1 |= 4C1({K1 , K2 }), following inequation0holds every base K1 :c0C1#([K1 ] [4C1({K1 , K2 })]) #([K1 ] [4 ({K1 , K2 })]).cc00K10 K2 consistent, 4C1({K1 , K2 }) K1 K2 , hencec0#([K1 ][4C1({K1 , K2 })]) = 0 minimal since assumed K1 K2inconsistent.K10 K2 inconsistent, two cases:c0K10 inconsistent K2 inconsistent. 4C1({K1 , K2 })c. Since assumed K1 consistent, also 4C1({K1 , K2 })K1 . Hence:cc#([K1 ] [],#([])ip (K1 , 4C1({K1 , K2 })) =#([K1 ] [K1 ].#([K1 ])0ip (K1 , 4C1({K1 , K2 })) =cSince numerators two fractions coincide #([K1 ]) #([]),manipulation possible case.0K10 consistent K2 consistent. 4C1({K1 , K2 })0(K1 K2 ) . Since K1 K2 inconsistent,c0ip (K1 , 4C1({K1 , K2 })) =#([K1 K10 ]).#([(K10 K2 ) ])ip (K1 , 4C1({K1 , K2 })) =#([K1 ]).#([(K1 K2 ) ])calso have:cNow, since K10 K2 inconsistent, #([(K10 K2 ) ]) =#([K10 ]) + #([K2 ]). Similarly, since K1 K2 inconsistent,#([(K1 K2 ) ]) = #([K1 ]) + #([K2 ]). Subsequently, suppose86fiThe Strategy-Proofness Landscape Merging0C1ip (K1 , 4C1({K1 , K2 })) > ip (K1 , 4 ({K1 , K2 })).case #([K1 K10 ])(#([K1 ]) + #([K2 ])) > #([K1])(#([K10 ]) + #([K2 ])).note = #([K1 K10 ]) b = #([K2 ]), exist twonatural integers a0 a00 #([K1 ]) = + a0 #([K10 ]) =+ a00 . Replacing previous inequation, comes:cca(a + a0 + b) > (a + a0 )(a + a00 + b)simplifies 0 > aa00 + a0 a00 + a0 c, impossible. Hencemanipulation possible case well.0C50K1 consistent , then, since E 0 , 4C1(E ) |= 4 (E ) |= ,cc0C50have: E 0 , ip (K1 , 4C1(E )) = 0 ip (K1 , 4 (E )) = 0, manipulationpossible.ccpart proof, following example shows strategy-proofnessccC5ip hold longer 4C14 #(E) 6= 2, even initial base complete >. consider K1 = {a b}, K2 = {a b}K3 = {a}, integrity constraint = >. two maximal consistent sets maxcons({K1 , K2 , K3 }, ): M1 = {a b, >} M2 = {a, >}. Hencecc1C14C1({K1 , K2 , K3 }) (a b) (a). get ip (K1 , 4 ({K1 , K2 , K3 })) = 3 .agent 1 gives K10 = {a b} instead K1 , two maximal consistent sets M10 = {a b, >}, M20 = {a b, a, >} maxcons({K10 , K2 , K3 }, ),cc10C104C1({K1 , K2 , K3 }) (a b) (a b). get ip (K1 , 4 ({K1 , K2 , K3 })) = 2 ,example manipulation 4C1> ip .cC5C5Since 4C1> = 4> , example shows manipulability 4 well.ccc4C3strategy-proof idw ids >, strategy-proof ip#(E) = 2 >.cDrastic indexes.C3Since 4C3> strategy-proof idw ids , specialization 4 also strategy-proofidw ids .cexample showing manipulation 4C3two bases completeinitial base K1 , every base singleton, example holds 4C3too.cProbabilistic index.C3C1C3Since 4C1> = 4> , follows immediately proof 4 4>strategy-proof ip two bases considered, case threeagents taken account.ccshowing manipulation possible 4C3two bases complete initial base K1 , integrity constraint true, consider following examcple: let K1 = {a b}, K2 = {a}, = b K10 = {a}. 4C3({K1 , K2 })c87fiEveraere, Konieczny & Marquisa, inconsistent K1 , ip (K1 , 4C3({K1 , K2 })) = 0. alsoc0C304C3({K1 , K2 }) >, consistent K1 , ip (K1 , 4 ({K1 , K2 })) > 0.cc4C4strategy-proof ip , idw ids . direct consequence Remark 1Theorem 2.c4C5strategy-proof idw #(E) = 2 > K complete.cC54C5strategy-proof ids #(E) = 2 >. Finally, 4strategy-proof ip #(E) = 2.ccWeak drastic index.4C5strategy-proof ip two bases, also strategy-proof idwcase.cC5Since 4C5> strategy-proof idw , 4 > also strategy-proof idw .cFinally, manipulation possible 4C5initial base K1 complete(Theorem 5), manipulation exists 4C5cas.cContrastingly, manipulation example exists 4C5#(E) 6= 2 6 >initial base K1 complete. consider three (singleton) bases:cK1 = {b}, K2 = {a}, K3 = {a b}, = a. 4C5({K1 , K2 , K3 })c0b, idw (K1 , 4C5({K1 , K2 , K3 })) = 0. K1 = {b a},c0C504C5({K1 , K2 , K3 }) a, idw (K1 , 4 ({K1 , K2 , K3 })) = 1.ccStrong drastic index.C54C5> strategy-proof ids , 4> also strategy-proof ids .cC54C5strategy-proof ip two bases E, 4 also strategyccproof ids case, since profile E, 4C5(E) consistent.cmanipulation example exists 4C5#(E) 6= 2 6 >, even initialbase K1 complete: K1 = {a b}, K2 = {a b}, K3 = {a b}, = a.two maximal consistent sets maxcons({K1 , K2 , K3 }, >): M1 = {a b}cM2 = {a b}. Hence 4C5({K1 , K2 , K3 }) (a b) (a b). getc0ids (K1 , 4C5({K1 , K2 , K3 })) = 0. K1 = {a b}, two maximalconsistent sets maxcons({K1 , K2 , K3 }, >): M10 = {a b} M20 = {a b}.cc0C50Hence 4C5({K1 , K2 , K3 }) (a b), ids (K1 , 4 ({K1 , K2 , K3 })) = 1.cProbabilistic index.C1proof 4C5similar proof 4 .ccTheorem 7 strategy-proofness results reported Table 14 hold, restrictionbase complete (f stands aggregation function, distance).88fiThe Strategy-Proofness Landscape Mergingf aggregation function, distance, sp means strategy-proof , sp means nonstrategy-proof even #(E) = 2 >, sp means non strategy-proof even either#(E) = 2 >, strategy-proof #(E) = 2 >. Finally, sp> meansnon strategy-proof even #(E) = 2, strategy-proof whenever >.ipidwidsdD ,fd,dH ,GM ax4C14C34C44C5c4C1c4C3c4C4c4C5spspspspspspspspspspspsp>spspspspspspsp>spsp>spspspspspspspspspspspspTable 14: Strategy-proofness: complete bases.Proof:first line table (dD ,f ) direct consequence Theorem 2.second line table (d,) direct consequence Theorem 2.third line table (dH ,GM ax ) comes proof Theorem 4.first column fourth line (4C1ip ) comes following example. LetK1 = {a, b}, K2 = {a, b}, K10 = {a b} = >. 4C1({K1 , K2 }) >, hence1C10C1ip (K1 , 4 ({K1 , K2 })) = 4 , 4 ({K1 , K2 }) (a b) (a b), showing10C1ip (K1 , 4C1({K1 , K2 })) = 2 . rightmost columns fourth line (4 idw ,ids ) come directly Theorem 5.first column fifth line (4C3ip ) comes first column fourthline given example s.t. > (in case operators coincide). SimilarlyC3second third columns (4C3idw , ids ) case > (4> coincidesC34C1> ). remaining case, 4 strategy-proof idw even #(E) = 2following example shows: take E = {K1 , K2 } K1 = {a b c}, K2 = {a b, c}= b; 4C3(E) b c, inconsistent K1 ; agent0gives K10 = {a, b c} instead K1 , obtain 4C3({K1 , K2 }) (a c) (a b c),consistent K1 . Finally, 4C3strategy-proof ids even #(E) = 26= >; let K1 = {a, b}, K2 = {a, b}, K10 = {a b} = b.C34C3({K1 , K2 }) (a b) (a b), hence ids (K1 , 4 ({K1 , K2 })) = 0,0C304C3({K1 , K2 }) b, showing ids (K1 , 4 ({K1 , K2 })) = 1.sixth line (4C4) comes proof Theorem 5.89fiEveraere, Konieczny & Marquisfirst column seventh line (4C5ip ) comes first column fourthline given example s.t. > (in case operators coincide). secondC5column (4C5idw ) comes directly Theorem 5. third column (4 ids )C5case > comes third column fourth line (4> coincides 4C1> ).C5Finally, 4 strategy-proof ids even #(E) = 2 6 >; let K1 = {a, b},K2 = {a, b}, K10 = {a b} = b. 4C5({K1 , K2 }) (a b) (a b),C5C5hence ids (K1 , 4 ({K1 , K2 })) = 0, 4 ({K10 , K2 }) b, showing0ids (K1 , 4C5({K1 , K2 })) = 1.C4Finally, remains consider 4Coperators. 4 , know Theorem 6strategy-proof ip (hence idw ids ) since 4C4strategy-proof ipcbC3C5bases singletons. Let us focus 4C1, 4 4 . Since base completeassumed singleton without loss generality,cc4C1({K1 , . . . , Kn })ccc4C5({K1 , . . . , Kn })(n_Ki ) consistent,i=1C54C1({K1 , . . . , Kn }) 4 ({K1 , . . . , Kn }) otherwise.ccalso have:4C3({K1 , . . . , Kn }) (cn_Ki ) consistent,i=1c4C3({K1 , . . . , Kn })otherwise.C1C3C5Let 4Coperator among 4 , 4 4 . two cases:bccc4Cconsistent. two cases:b0C50K1 |= . Since every profile E 0 4C1(E ) |= 4 (E ) |= ,cc0C50also 4C1(E ) K1 inconsistent 4 (E ) K1 inconsistent, showingmanipulation possible ip , hence idw ids . specific caseconsider (all bases singletons complete), also everyc00profile E 0 , 4C3(E ) |= since base E kept elementcc0maxcons(E 0 , >) must satisfy base kept, 4C3(E ) inconsistent,c0hence 4C3(E ) |= trivially holds. previous argument used showcmanipulation possible 4C3ip , hence idw (and idscassumption 4C3(E) consistent).cK1 |= . necessarily #([K1 ] [4C({K1 , . . . , Kn })]) = 1. reductioad absurdum. manipulation ip possible find completebb0C0base K10 s.t. (1) K1 |= 4C({K1 , . . . , Kn }) (2) #([4 ({K1 , . . . , Kn })]) <b0#([4C({K1 , . . . , Kn })]). (2) requires K1 |= . (1) imposes K1 |=K10 K2 . . . Kn . Since K1 |= K10 |= , K1 6 K10 . Subsequently, exists Kj (j 2, . . . , n) s.t. K1 Kj . Since Kj modelb90fiThe Strategy-Proofness Landscape Merging0C4C({K1 , . . . , Kn }), inequation (2) cannot satisfied. Hence, 4 strategybbproof ip , hence idw . Since 4C(E) assumed consistent, manipulationpossible ids .bCC34C(E) inconsistent. possible 4 = 4 requires KibbcC3(i 1, . . . , n) s.t. Ki |= . Since 4C3(E) inconsistent, ip (K1 , 4 (E)) =cc00. Since every K10 complete, K1 model 4C3({K1 , . . . , Kn }),cC30C3ip (K1 , 4C3(4 ({K1 , . . . , Kn }))) = 0 well. shows 4 strategy-proofccC3ip , hence idw . Finally, 4C3(E) inconsistent, 4 (E) |= K1 ,showing manipulation possible ids well.ccTheorem 8 None dD , , dD ,GM ax , dH , dH ,GM ax strategy-proof iDalal ,even restricted case E consists two complete bases.Proof:dD , = dD ,GM ax . Let us consider [K1 ] = {000}, [K2 ] = {110} = b cP = {a, b, c}. [dD , ({K1 , K2 })] = {110} iDalal (K1 , dD , ({K1 ,K2 })) = 1 23 . [K10 ] = {001}, get [dD , ({K10 , K2 })] = {110, 001}iDalal (K1 , dD , ({K10 , K2 })) = 1 13 , showing manipulation (details reportedTable 15).000001010011100101110111K101111111K1010111111K211111101,({K1 , K2 })12222212,({K10 , K2 })21222212Table 15: Manipulation dD , iDalal two complete bases.dH , . Let us consider [K1 ] = {000}, [K2 ] = {110} = ((a b c) (ab c) (a b c)) P = {a, b, c}. [dH , ({K1 , K2 })] = {110}iDalal (K1 , dH , ({K1 , K2 })) = 1 23 . [K10 ] = {001}, get [dH , ({K10 , K2 })] ={110, 001, 011, 111} iDalal (K1 , dH , ({K10 , K2 })) = 1 13 , showing manipulation (details reported Table 16).dH ,GM ax . Let us consider [K1 ] = {0001}, [K2 ] = {0111} = (a bc d) (a b c) (a b c) (a b c d) (a b c d)(a b c d) P = {a, b, c, d}. [dH ,GM ax ({K1 , K2 })] = {0111}91fiEveraere, Konieczny & Marquis000001010011100101110111K1010212132K101121223HK223121201,({K1 , K2 })24242424H,({K10 , K2 })33333333Table 16: Manipulation dH , iDalal two complete bases.iDalal (K1 , dH ,GM ax ({K1 , K2 })) = 1 42 . [K10 ] = {1000}, get [dH ,GM ax ({K10 ,K2 })] = {0000, 0110, 1001, 1010, 1100, 1111} iDalal (K1 , dH ,GM ax ({K10 , K2 })) =1 41 , showing manipulation (details reported Table 17).0000000100100011010001010110011110001001101010111100110111101111K11021213221323243K101223233401121223K23221211043323221H,GM ax({K1 , K2 })(3, 1)(2, 0)(2, 2)(1, 1)(2, 2)(1, 1)(3, 1)(2, 0)(4, 2)(3, 1)(3, 3)(2, 2)(3, 3)(2, 2)(4, 2)(3, 1)H,GM ax({K10 , K2 })(3, 1)(2, 2)(2, 2)(3, 1)(2, 2)(3, 1)(3, 1)(4, 0)(4, 0)(3, 1)(3, 1)(2, 2)(3, 1)(2, 2)(2, 2)(3, 1)Table 17: Manipulation dH ,GM ax iDalal two complete bases.CTheorem 9 None 4Coperators (hence, none 4 operators) strategy-proofiDalal , even restricted case E consists two complete bases.bProof:Let us consider complete bases K1 = {a b} K2 = {a b}, =(ab). maxcons({K1 , K2 }, ) = {{ab, (ab)}} = maxconscard ({K1 , K2 },c) maxcons({K1 , K2 }, >) = {{a b, >}, {a b, >}}, hence 4C1({K1 , K2 })C4C54C3({K1 , K2 }) 4 ({K1 , K2 }) 4 ({K1 , K2 }) b.ccc2get iDalal (K1 , 4C({K1 , K2 })) = 1 2 = 0.K10 = {a b}, maxcons({K10 , K2 }, ) = {{a b, (a b)}, {a b, (ab)}} = maxconscard ({K10 , K2 }, ) maxcons({K10 , K2 }, >) = {{a b, >}, {ab92fiThe Strategy-Proofness Landscape Merging0C30C40C50b, >}}, hence 4C1({K1 , K2 }) 4 ({K1 , K2 }) 4 ({K1 , K2 }) 4 ({K1 , K2 })(a b) (a b) a.b10Thus iDalal (K1 , 4C({K1 , K2 })) = 1 2 , showing manipulation.ccccTheorem 10 Let pseudo-distance let f aggregation function. d,fdilation strategy-proof indexes ip , idw ids .Proof:idea untruthful base K 0 contains models truebase K, merged base K 0 provided contains models Kappearing merged base K reported, countermodels K.manipulation possible.Theorem 1, sufficient show d,fstrategy-proof ip . reductio adabsurdum. Let us suppose operator d,f, f respectivelypseudo-distance aggregation function, manipulable dilation ip .assumption, find integrity constraint , profile E, two bases K K 0d,f0K |= K 0 , s.t. ip (K, d,f({K} E)) < ip (K, ({K } E)). Using light notationE 4 K instead d,f({K} E), have:#([K] [E 4 K 0 ])#([K] [E 4 K])<.#([E 4 K])#([E 4 K 0 ])Since K |= K 0 , pseudo-distance d, W, d(, K) d(, K 0 ). So,aggregation function f (that satisfies non-decreasingness):W, d(, E {K}) d(, E {K 0 }).(8)Let us note dmin (E {K}) = min({d(, E {K}) | |= }, ). (8),immediately infer: dmin (E {K}) dmin (E {K 0 }). Two cases considered:dmin (E {K}) > dmin (E {K 0 }) (*).1 model K then, since K |= K 0 , d(1 , K) = d(1 , K 0 ) = 0, d(1 , E{K}) = d(1 , E {K 0 }) . furthermore 1 model E 4 K 0 , d(1 , E{K 0 }) = dmin (E {K 0 }), d(1 , E {K}) = dmin (E {K 0 }). definitionmin, d(1 , E {K}) dmin (E {K}), 1 |= . concludedmin (E {K}) dmin (E {K 0 }), contradicts (*). So, modelK model E 4 K 0 . Consequently, ip (K, E 4 K 0 ) = 0 minimal,prevents manipulation d,f. So, exclude case (*).dmin (E {K}) = dmin (E {K 0 }) (**).model E 4 K, |= d(, E {K}) = dmin (E{K}). So, d(, E {K}) = dmin (E {K 0 }) equation (**). Furthermore,inequation (8), infer d(, E {K}) d(, E {K 0 }). Hence,d(, E {K 0 }) dmin (E {K 0 }). Since model , finally infer93fiEveraere, Konieczny & Marquismodel E 4 K 0 well. model E 4 K modelE 4 K 0 , then:#([E 4 K]) #([E 4 K 0 ]).(9)deduce well model E 4 K model K modelE 4 K 0 (and K), so:#([K] [E 4 K]) #([K] [E 4 K 0 ]).Furthermore, 1 |= K model E 4 K 0 , both:d(1 , E {K 0 }) = dmin (E {K 0 }) = dmin (E {K}) (**),d(1 , E {K}) = d(1 , E {K 0 }) K |= K 0 : since d(1 , K) = 0,d(1 , K 0 ) = 0 too.obtain: d(1 , E t{K}) = dmin (E {K}) 1 |= , 1 model E 4 K.state #([K] [E 4 K]) #([K] [E 4 K 0 ]). get:#([K] [E 4 K]) = #([K] [E 4 K 0 ]).(10)(9) (10), get immediately that:#([K] #([E 4 K 0 ])#([K] [E 4 K]).#([E 4 K])#([E 4 K 0 ])(11)d,f0consequence, ip (K, d,f({K} E) ip (K, ({K } E)). inequationd,fshows manipulable ip , contradicts assumption. case(**) excluded well, concludes proof.Theorem 11 Let distance. d,strategy-proof index idw (resp.ids ), erosion strategy-proof idw (resp. ids ).Proof:first need following lemma:Lemma 2 Let pseudo-distance let f aggregation function. profile Emanipulable K idw (resp. ids ) given d,f, one find complete baseK 0 base agent gives instead true base K s.t. idw (K, (E {K 0 })) >idw (K, (E {K})) (resp. ids (K, (E {K 0 })) > ids (K, (E {K}))).Proof:lemma mainly consequence definition distanceinterpretation base K 0 , minimal distance interpretation model00 base; complete base whose unique model 00 allows well manipulationWeak drastic index.94fiThe Strategy-Proofness Landscape Mergingsuppose d,fmanipulable idw , i.e., find integrity constraint ,profile E = {K1 , . . . , Kn }, two bases K K 0 s.t.:d,f0idw (K, d,f({K} E)) < idw (K, ({K } E)).(12)equivalent to: idw (K, E 4 K) = 0 idw (K, E 4 K 0 ) = 1, d,f({K} E)noted E 4 K simplifying notations.Statement (13) states idw (K, E 4 K) = 0: model K model E 4 K;statement (14) states idw (K, E 4 K 0 ) = 1: least one model KE 4 K 0 :|= K , 0 |= (K) , d( 0 , E {K}) < d(, E {K}).(13)1 |= K , |= , d(1 , E {K 0 }) d(, E {K 0 }).(14)Since (13) choice 0 made apart , (13) equivalent to:0 |= (K) , |= K , d( 0 , E {K}) < d(, E {K}).(15)Let 00 |= K 0 s.t. d(1 , K 0 ) = d(1 , 00 ). consider complete base K 00 s.t. [K 00 ] = { 00 }.shall show rest proof d,fmanipulable base. agentwhose beliefs/goals K gives K 00 base instead K, then, since d(1 , K 00 ) = d(1 , K 0 ),have:d(1 , E {K 00 }) = d(1 , E {K 0 }),(16)then:|= , d(1 , E {K 00 }) d(, E {K 0 }),(17)(14) (16).Furthermore, since aggregation function f non-decreasing (by definition) sinceK 00 |= K 0 , |= , d(, E {K 0 }) d(, E {K 00 }), get immediately(17):|= : d(1 , E {K 00 }) d(, E {K 00 }).(18)d,f00001 model d,f(E {K }), idw (K, ({K } E)) = 1d,fd,f00idw (K, d,f({K} E)) < idw (K, ({K } E)). shows manipulable00complete base K .Strong drastic index. Let us assume operator d,f, pseudo-distancef aggregation function, manipulable strong drastic index ids .Thenfind integrity constraint , profile E bases K K 0 s.t. ids (K, d,f(E0 }). implies (K, d,f (E {K}) = 0, (K,{K}) < ids (K, d,f(E{Kdsdsd,f0d,f(E {K }) = 1. means, definition index, (E {K}) 6|= K,0d,f(E {K }) |= K.000Given model 1 d,f(E {K }) model 2 K s.t. d(1 , K ) = d(1 , 2 ),define K 00 = {2 }. d(1 , K 00 ) = d(1 , K 0 ), and: d(1 , E {K 00 }) =d(1 , E {K 0 }).95fiEveraere, Konieczny & Marquis00Let us note dmin (E td,f{K }) = min({d(, E {K }) | |= }, ). Since 1 modeld,f0(E {K 0 }), d(1 , E {K 0 }) = dmin (E td,f{K }). Hence:0d(1 , E {K 00 }) = dmin (E td,f{K }).(19)00definition min since 1 |= , also have: d(1 , E {K 00 }) dmin (E td,f{K }).get:0d,f00dmin (E td,f(20){K }) dmin (E {K }).hand, since K 00 |= K 0 , have: W, d(, K 0 ) d(, K 00 ). Sinceaggregation function f non-decreasing, get:W, d(, E {K 0 }) d(, E {K 00 }),(21)d,fd,f0000dmin (E td,f{K }) dmin (E {K }). (20) get dmin (E {K }) =d,fd,f000000dmin (E {K }). Then, (19), obtain d(1 , E {K }) = dmin (E {K }). Since001 |= , 1 model d,f(E {K }) too.d,f000000Let model d,f(E t{K }). Then, |= d(, E t{K }) = dmin (E {K }).d,fd,f00000Then, since dmin (E td,f{K }) = dmin (E {K }), d(, E {K }) = dmin (E0{K 0 }). (21), get d(, E {K 0 }) dmin (E td,f{K }).0Then, definition min d(, E {K 0 }) = dmin (E td,f{K }).0implies model d,f(E {K }) (because |= ), write:d,fd,f0000d,f(E {K }) |= (E {K }). Since (E {K }) |= K, inferd,f0000d,f(E {K }) |= K, ids (K, (E {K }) = 1.get manipulation ids complete base K 00 , completes prooflemma.Let us give proof main theorem:Weak drastic index. reductio ad absurdum. assume d,manipulableoperator manipulable erosion. find integrity constraint, profile E, two bases K K 0 K 0 6|= K s.t.:d,0idw (K, d,(E {K})) < idw (K, (E {K })).Lemma 2 shows assume [K 0 ] = {10 } complete; comes:d,0idw (K, d,(E {K})) < idw (K, (E {1 })).implies that:idw (K, d,(E {K}) = 00idw (K, d,(E {1 }) = 1.96(22)fiThe Strategy-Proofness Landscape Mergingmeans model K model d,(E {K}),d,least one model 1 K model (E {10 }). expressfacts two statements:|= K , 0 |= K , d( 0 , E {K}) < d(, E {K})and:1 |= K , |= , d(1 , E {10 }) d(, E {10 }).Hence:1 |= K , |= , d(1 , 10 ) + d(1 , E) d(, 10 ) + d(, E)(23)Let us define new base K 00 = {1 }. Since supposed operatormanipulable erosion since K 00 |= K, state strategy-proofd,00idw K 00 : idw (K, d,(E {K})) idw (K, (E {K })). implies that:either idw (K, d,(E {K})) = 1,d,00idw (K, d,(E {K})) = idw (K, (E {K })) = 0.00equation (22), infer idw (K, d,(E {K })) = 0, |=000000K , |= K , d( , E {K }) < d(, E {K }).Since K 00 = {1 } choice 0 made independently 1 , 2 |=(K) , |= K , d(2 , E {1 }) < d(, E {1 }), is:2 |= K , |= K , d(2 , 1 ) + d(2 , E) < d(, 1 ) + d(, E).particular, statement holds = 1 , 1 |= K . Hence:d(2 , 1 ) + d(2 , E) < d(1 , 1 ) + d(1 , E).Since d(1 , 1 ) = 0, obtain finally:d(2 , 1 ) + d(2 , E) < d(1 , E).(24)hand, since 2 |= , (23), get:d(1 , 10 ) + d(1 , E) d(2 , 10 ) + d(2 , E).Summing (24) (25) side side, get:d(2 , 1 ) + d(2 , E) + d(1 , 10 ) + d(1 , E) < d(1 , E) + d(2 , 10 ) + d(2 , E).Simplifying d(1 , E) d(2 , E), obtain:d(2 , 1 ) + d(1 , 10 ) < d(2 , 10 ).97(25)fiEveraere, Konieczny & Marquiscontradicts triangular inequality. So, manipulation possible, possibleerosion complete base K 00 = {1 }.Strong drastic index. Let us assume d,manipulable ids . findprofile E, integrity constraint two bases K K 0 s.t.:d,0ids (K, d,(E {K})) < ids (K, (E {K })).implies that:ids (K, d,(E {K}) = 0(26)0ids (K, d,(E {K }) = 1.means least one model d,(E {K}) model K,0 }) model K . Let us consider model(E{Kevery model d,10d,(E {K }). write 1 |= K and:|= , d(1 , E {K 0 }) d(, E {K 0 }).have:|= , d(1 , K 0 ) + d(1 , E) d(, K 0 ) + d(, E).Let us define K 00 = {1 } show manipulation base. Let us assumed,000000find 00 |= d,(E {K }) s.t. 6|= K. Since |= (E {1 }),00 |=d(, E {1 }) d(1 , E {1 }),then:d(, 1 ) + d(, E) d(1 , E)(as d(1 , 1 ) = 0).0know 00 6|= K 00 |= , infer 00 6|= d,(E {K }) (elsed,000|= K). Since 1 model (E {K }), have:d(, E {K 0 }) > d(1 , E {K 0 }).Equivalently:d(, K 0 ) + d(, E) > d(1 , K 0 ) + d(1 , E).Since d(1 , E) d(, 1 ) + d(, E), obtain:d(, K 0 ) + d(, E) > d(1 , K 0 ) + d(, 1 ) + d( 00 , E).Simplifying equation d(, E), get:d(, K 0 ) > d(1 , K 0 ) + d(, 1 ).2 model K 0 s.t. d(1 , K 0 ) = d(1 , 2 ), have:d(, K 0 ) > d(1 , 2 ) + d(, 1 ),98fiThe Strategy-Proofness Landscape Mergingfinally, since d(, 2 ) d(, K 0 ) definition min, get:d(, 2 ) > d(1 , 2 ) + d(, 1 ).contradicts triangular inequality.d,00shown every model d,(E t{K }) model K. Hence, ids (K, (E{K 00 }) = 1. Since ids (K, d,(E {K}) = 0 (26), have:d,00ids (K, d,(E {K})) < ids (K, (E {K })),manipulation erosion complete base possible.Corollary 12 profile E manipulable K idw (resp. ids ) given d,manipulation possible using complete base K |= K, i.e., exists K |= Kd,d,s.t. idw (K, d,(E {K })) > idw (K, (E {K})) (resp. ids (K, (E {K })) >ids (K, d,(E {K}))).Proof:(): consequence Theorem 11 Lemma 2, enablestate K manipulable = idw = ids given d,E, one findd,f000base K = { } |= K complete i(K, (E { })) > i(K, d,f(E {K})).(): K strategy-proof = idw = ids given d,E, [K 0 ]d,d,0W, i(K, (E {K }) i(K, (E {K})). particular true K 0reduced singleton.Theorem 14 max , min1 , min2 , strategy-proof idw , ids ip .VProof:max (or equivalently min2 ) strategy-proof ip . Indeed, Econsistent, modelsV merged base models K1 E, thus satisfactionK1 maximal ip . E consistent,V merged base valid. Assumeagent 1 reports K10 instead K1 . K10 {K2 , . . . , Kn } isVconsistent, modelresulting merged base model K1 . case K10 {K2 , . . . , Kn } inconsistent,resulting merged base still valid. Theorem 1, max (or equivalently min2 )also strategy-proof two drastic indexes.VVEconsistentabove.Emin1 also strategy-proof ip . caseWconsistent, result merging E models K1 modelsmerged base. So, order increase value ip index, possibleincrease number models K1 result merging. Hence one needsdecrease number countermodels K1 merged base. shallshowVpossible: assume agent 1 reports K10 instead K1 . K10 {KV2 , . . . , Kn }consistent, model resulting merged base model K1 (as Econsistent).99fiEveraere, Konieczny & MarquisK10V{K2 , . . . , Kn } consistent, have:ip (K1 , min1 (K1 {K2 , . . . , Kn })) =ip (K1 , min1 (K10#([K1#([K1 ])W{K2 , . . . , Kn }])W#([K1 (K10 {K2 , . . . , Kn })])W.{K2 , . . . , Kn })) =#([K10 {K2 , . . . , Kn }])numerator ip (K1 , min1 (K1 {K2 , . . . , Kn })) maximal, order increaseip (K1 , min1 (K10 t{K2 , . . . ,WKn })), decrease denominator ip (K1 , min1 (K100t{K2 , . . . , Kn })), #([K1 {K2 , . . . , Kn }]).write following equality:#([K10__{K2 , . . . , Kn }]) = #([K10 K1 ( {K2 , . . . , Kn })])+__#([K10 K1 ( {K2 , . . . , Kn })]) + #([ {K2 , . . . , Kn }]).Wsum, #([ {K2 , . . . , Kn }]) cannotchanged. decrease twoW0 K ( {K , . . . , K })]) minimal K 0 #([K 0termssum:#([K12n111WKW1 ( {K2 , . . . , Kn })]) = 0. following, suppose #([K10 K1( {K2 , . . . , Kn })]) = 0.Wfirst term sum, #([K10 K1 ( {K2 , . . . , Kn })]), write:_#([K10 K1 ( {K2 , . . . , Kn })]) =__#([K1 ( {K2 , . . . , Kn })]) #([K1 K10 ( {K2 , . . . , Kn })])obtain probabilistic index:ip (K1 , min1 (K10 {K2 , . . . , Kn })) =W#([K1 ]) #([K1 K10 ( {K2 , . . . , Kn })])WWW.#([K1 ( {K2 , . . . , Kn })]) #([K1 K10 ( {K2 , . . . , Kn })]) + #([ {K2 , . . . , Kn }])remark k integer b, akbk b . subtractW0integer #([K1 K1 ( {K2 , . . . , Kn })]) numerator denominator,get following inequation:W#([K1 ]) #([K1 K10 ( {K2 , . . . , Kn })])WWW#([K1 ( {K2 , . . . , Kn })]) #([K1 K10 ( {K2 , . . . , Kn })]) + #([ {K2 , . . . , Kn }])#([K1 ])WW.#([K1 ( {K2 , . . . , Kn })]) + #([ {K2 , . . . , Kn }])So:ip (K1 , min1 (K10 {K2 , . . . , Kn }))#([K1 ])WW#([K1 ( {K2 , . . . , Kn })]) + #([ {K2 , . . . , Kn }])100fiThe Strategy-Proofness Landscape Mergingip (K1 , min1 (K10 {K2 , . . . , Kn })) ip (K1 , min1 (K1 {K2 , . . . , Kn })).manipulation possible, min1 strategy-proof ip . Theorem 1, min1also strategy-proof two drastic indexes.Finally, strategy-proof three indexes (see Theorem 2).Theorem 15 satisfies (IP) property every profile E every pairbases K K 0 :K (E {K}) |= (E {K 0 }),K (E {K}) |= (E {K 0 }).Proof:Suppose merging operator = Bel( )) satisfy (IP)property. profile E, agent i, OCF , interpretation W s.t.| (E)() ()| > | (rep(E, {i}, )() ()|rep(E, {i}, ) profile identical E except OCF replaced .following note (E {K}) Bel( (E)): initial merged base agentreports true base K Bel(i ), note (E {K 0 }) Bel( (rep(E, {i}, )):merged base obtained replacing base K agent another K 0 Bel().Focusing two-strata OCFs, inequation entails | (E)() ()| = 1| (rep(E, {i}, )() ()| = 0. Since | (rep(E, {i}, )() ()| = 0, model(E {K 0 }) K (*), countermodel (E {K 0 }) K(**).get | (E)() ()| = 1, also two cases:either (E)() = 1 () = 0: model K countermodel(E {K}). Since model K, (*), know model(E {K 0 }). model K, ((E {K})) (E {K 0 }):entailsK (E {K}) 6|= (E {K 0 }).(E)() = 0 () = 1: countermodel K model (E{K}). Since countermodel K, (**), know countermodel(E {K 0 }). model K, (E {K}) (E {K 0 }):entailsK (E {K}) 6|= (E {K 0 }).Hence caseK (E {K}) |= (E {K 0 }),101fiEveraere, Konieczny & MarquisK (E {K}) |= (E {K 0 }).satisfied.converse, suppose profile E, agent base K, anotherbase K 0 s.t.:K (E {K}) 6|= (E {K 0 })K (E {K}) 6|= (E {K 0 }).first case, model K (E {K}) countermodel(E {K 0 }) :(E)() = 1, () = 0, (rep(E, {i}, )() = 0.| (E)() ()| > | (rep(E, {i}, )() ()|.second case, model K (E {K}) countermodel(E {K 0 }):(E)() = 0, () = 1, (rep(E, {i}, )() = 1.| (E)() ()| > | (rep(E, {i}, )() ()|.cases, satisfy (IP) property.1#([KK ]))+1 .Theorem 16 Let iwip (K, K ) =strategy-proof iwip .Proof:satisfies (WIP) propertydefinition K K (K K ) (K K ) write:iwip (K, K ) =1#([(K K ) (K K )]) + 1iwip (K, K ) =1.#([K K ]) + #([K K ]) + 1Suppose merging operator = Bel( )) satisfy (WIP) property.profile E, agent i, OCF s.t.W | (E)() ()| > W | (rep(E, {i}, )() ()|()following note (E {K}) Bel( (E)), initial merged baseagent reports true base K Bel(i ), note (E {K 0 }) Bel( (rep(E, {i},)), i.e., merged base obtained replacing base K agent anotherK 0 Bel().two-strata case, | (E)() ()| equal 0 1. fact, | (E)() ()| = 1if:102fiThe Strategy-Proofness Landscape Mergingeither (E)() = 1 () = 0: equivalent |= K (E {K}).(E)() = 0 () = 1: equivalent |= K (E {K}).deduce following equation:W | (E)() ()| = #([K (E {K})]) + #([K (E {K})]).Similarly, get:W | (rep(E, {i}, )() ()| = #([K (E {K 0 })]) + #([K (E {K 0 })])inequation (*) equivalent to:#([K (E {K})]) + #([K (E {K})]) > #([K (E {K 0 })]) + #[K (E {K 0 })])equivalent1<#([K (E {K})]) + #([K (E {K})]) + 11#([K (E {K 0 })]) + #([K (E {K 0 })]) + 1equivalentiwip (K, (E {K})) < iwip (K, (E {K 0 }))equivalent fact strategy-proof iwip .ReferencesArrow, K. J. (1963). Social choice individual values (second edition). Wiley, New York.Arrow, K., Sen, A. K., & Suzumura, K. (Eds.). (2002). Handbook Social ChoiceWelfare, Vol. 1. North-Holland.Baral, C., Kraus, S., & Minker, J. (1991). Combining multiple knowledge bases. IEEETransactions Knowledge Data Engineering, 3 (2), 208220.Baral, C., Kraus, S., Minker, J., & Subrahmanian, V. S. (1992). Combining knowledgebases consisting first-order theories. Computational Intelligence, 8 (1), 4571.Barbera, S., Dutta, B., & Sen, A. (2001). Strategy-proof social choice correspondences.Journal Economic Theory, 101 (2), 374394.Benferhat, S., Dubois, D., Kaci, S., & Prade, H. (2002). Possibilistic merging distancebased fusion propositional information. Annals Mathematics Artificial Intelligence, 34 (13), 217252.Borda, J. (1781). Memoire sur les elections au srutin. Histoire de lAcademie Royale desSciences.103fiEveraere, Konieczny & MarquisBrams, S. J., & Fishburn, P. C. (1983). Approval voting. Springer Verlag.Chin, S., & Zhou, L. (2002). Multi-valued strategy-proof social choice rules. Social ChoiceWelfare, 19 (3), 569580.Chopra, S., Ghose, A., & Meyer, T. (2006). Social choice theory, belief merging strategyproofness. Information Fusion, 7 (1), 6179.Condorcet, M. (1785). Essai sur lapplication de lanalyse la probabilite des decisionsrendues la pluralite des voix. Paris.Conitzer, V., Lang, J., & Sandholm, T. (2003). many candidates needed makeelections hard manipulate?. Proceedings Ninth Conference TheoreticalAspects Rationality Knowledge (TARK03), pp. 201214.Conitzer, V., & Sandholm, T. (2002a). Complexity manipulating elections candidates. Proceedings Eighteenth National Conference Artificial Intelligence(AAAI02), pp. 314319.Conitzer, V., & Sandholm, T. (2002b). Vote elicitation: complexity strategyproofness. Proceedings Eighteenth National Conference Artificial Intelligence (AAAI02), pp. 392397.Conitzer, V., & Sandholm, T. (2003). Universal voting protocol tweaks make manipulation hard. Proceedings Eighteenth International Joint ConferenceArtificial Intelligence (IJCAI03), pp. 781788.Dalal, M. (1988). Investigations theory knowledge base revision: preliminary report.Proceedings Seventh American National Conference Artificial Intelligence(AAAI88), pp. 475479.Duggan, J., & Schwartz, T. (2000). Strategic manipulability without resoluteness sharedbeliefs: Gibbard-satterthwaite generalized. Social Choice Welfare, 17, 8593.Everaere, P., Konieczny, S., & Marquis, P. (2005). Quota gmin merging operators.Proceedings Nineteenth International Joint Conference Artificial Intelligence(IJCAI05), pp. 424429.Gibbard, A. (1973). Manipulation voting schemes. Econometrica, 41, 587602.Kelly, J. S. (1988). Social Choice Theory : Introduction. Springer-Verlag.Konieczny, S. (2000). difference merging knowledge bases combining them. Proceedings Seventh International Conference PrinciplesKnowledge Representation Reasoning (KR00), pp. 135144.Konieczny, S., Lang, J., & Marquis, P. (2004). DA2 merging operators. Artificial Intelligence,157 (1-2), 4979.Konieczny, S., Lang, J., & Marquis, P. (2005). Reasoning inconsistency: forgotten connective. Proceedings Nineteenth International Joint ConferenceArtificial Intelligence (IJCAI05), pp. 484489.Konieczny, S., & Pino Perez, R. (1998). logic merging. Proceedings SixthInternational Conference Principles Knowledge Representation Reasoning(KR98), pp. 488498.104fiThe Strategy-Proofness Landscape MergingKonieczny, S., & Pino Perez, R. (1999). Merging integrity constraints. ProceedingsFifth European Conference Symbolic Quantitative Approaches ReasoningUncertainty (ECSQARU99), LNAI 1638, pp. 233244.Konieczny, S., & Pino Perez, R. (2002). Merging information constraints: logicalframework. Journal Logic Computation, 12 (5), 773808.Liberatore, P., & Schaerf, M. (1998). Arbitration (or merge knowledge bases). IEEETransactions Knowledge Data Engineering, 10 (1), 7690.Lin, J., & Mendelzon, A. O. (1999). Knowledge base merging majority. DynamicWorlds: Frame Problem Knowledge Management. Kluwer.Maskin, E., & Sjostrom, T. (2002). Handbook Social Choice Welfare, Vol. 1, chap.Implementation Theory, pp. 237288. North-Holland.Meyer, T., Ghose, A., & Chopra, S. (2001). Social choice, merging elections. Proceedings Sixth European Conference Symbolic Quantitative ApproachesReasoning Uncertainty (ECSQARU01), pp. 466477.Moulin, H. (1988). Axioms cooperative decision making, chap. 9. Econometric societymonographs. Cambridge University Press.Rescher, N., & Manor, R. (1970). inference inconsistent premises. TheoryDecision, 1, 179219.Revesz, P. Z. (1993). semantics theory change: arbitration oldnew information. Proceedings Twelfth ACM SIGACT-SIGMOD-SIGARTSymposium Principles Databases, pp. 7192.Revesz, P. Z. (1997). semantics arbitration. International Journal AlgebraComputation, 7 (2), 133160.Satterthwaite, M. (1975). Strategy-proofness Arrows conditions. Journal EconomicTheory, 10, 187217.Shoham, Y., & Tennenholtz, M. (2005). Non-cooperative computation: Boolean functionscorrectness exclusivity. Theoretical Computer Science, 343 (1-2), 97113.Spohn, W. (1987). Ordinal conditional functions: dynamic theory epistemic states.Harper, W. L., & Skyrms, B. (Eds.), Causation Decision, Belief Change,Statistics, Vol. 2, pp. 105134.Tversky, A. (2003). Preference, Belief, Similarity. MIT Press.105fi