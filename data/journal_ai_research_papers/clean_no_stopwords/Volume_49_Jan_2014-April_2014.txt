Journal Artificial Intelligence Research 49 (2014) 501-525

Submitted 09/13; published 03/14

Information-Theoretic Multi-view Domain Adaptation: Theoretical
Empirical Study
Pei Yang

YANGPEI @ SCUT. EDU . CN

South China University Technology
Guangzhou, China

Wei Gao

WGAO @ QF. ORG . QA

Qatar Computing Research Institute
Qatar Foundation, Doha, Qatar

Abstract
Multi-view learning aims improve classification performance leveraging consistency
among different views data. incorporation multiple views paid little attention
studies domain adaptation, view consistency based source data largely violated
target domain due distribution gap different domain data. paper, leverage multiple views cross-domain document classification. central idea strengthen
views consistency target data identifying associations domain-specific features
different domains. present Information-theoretic Multi-view Adaptation Model (IMAM)
using multi-way clustering scheme, word link clusters draw together seemingly unrelated features across domains, boosts consistency document clusterings
based respective word link views. Moreover, demonstrate IMAM
always find document clustering minimal disagreement rate overlap viewbased clusterings. provide theoretical empirical justifications proposed method.
experiments show IMAM significantly outperforms traditional multi-view algorithm cotraining, co-training-based adaptation algorithm CODA, single-view transfer model CoCC
large-margin-based multi-view transfer model MVTL-LM.

1. Introduction
many mission-critical applications data mining, natural language processing information
retrieval, typically expensive time-consuming obtain appropriate training data learn
needed models. example, sentiment classifiers online reviews need work properly
data different types products; search engines must provide consistent quality service
Web data markets different languages verticals. However, training data commonly
exist limited number domains. Collecting annotating data different domains
would become practically prohibitive.
Domain adaptation task utilizes training data domain (i.e., out-of-domain
source domain) effectively transform relevant knowledge domain task
performed (i.e., in-domain target domain). Abundant labeled data may exist source domain
webpage data training general Web search ranker, readily available
target domains ranking systems image search music search. out-of-domain
data commonly drawn form feature distribution different
in-domain counterpart. Bridging domain gap challenging issue model learned
source domain generalized well target domain. practical reasons, domain adaptation
c
2014
AI Access Foundation. rights reserved.

fiYANG & G AO

great importance many real-world applications, entity mention detection (Daume
III & Marcu, 2006), document classification (Sarinnapakorn & Kubat, 2007), sentiment classification (Blitzer, Dredze, & Pereira, 2007), part-of-speech tagging (Jiang & Zhai, 2007),
recently Web search ranking (Gao, Cai, Wong, & Zhou, 2010; Cai, Gao, Zhou, & Wong, 2011a,
2011b; Gao & Yang, 2014).
Many types data represented multiple independent sets features, reflecting
different views data. example, document classification, Web document features consist
word-based features also features based link structures among documents (Blum & Mitchell, 1998); Web search, document rankers accept query-dependent
features (e.g., tfidf, BM25, language-modeling IR scores, etc.) well query-independent features (e.g., page rank, inlink/outlink numbers, url click count, etc.) (Gao, Blitzer, Zhou, & Wong,
2009). Traditionally, learning scheme called multi-view learning aims improve classifiers
leveraging redundancy consistency among distinct views (Blum & Mitchell, 1998;
Ruping & Scheffer, 2005; Abney, 2002). Existing methods multi-view learning designed
data single domain, assumes either view alone predict in-domain
class consistently accurately. However, view-consistency assumption largely violated
setting domain adaptation training test data drawn different distributions
(which empirically justified experiment section). case, domain adaptation
multiple views data needs investigated carefully.
Little research done multi-view domain adaptation literature. Zhang, He,
Liu, Si, Lawrence (2011) proposed instance-based multi-view transfer learning approach
integrates loss cross-domain classification multi-view consistency large margin
framework. However, instance-level approach assumes useful source training examples identified reused train target model. cannot mine relationships feature
level correlation source-specific target-specific features, may perform
poorly since target-specific features key good adaptation performance (Blitzer, Kakade,
& Foster, 2011).
work, present Information-theoretical Multi-view Adaptation Model (IMAM)
combines paradigms multi-view learning domain adaptation based co-clustering
framework (Dhillon, Mallela, & Modha, 2003) aims transfer knowledge across domains
multiple subspaces features complementarily. IMAM exploits multi-way-clustering-based classification scheme simultaneously cluster documents, words links respective clusters.
word link clusterings automatically associate specific features different domains seemingly may directly correlated. correlations bridge domain gap
enhance consistency distinct views clustering (i.e., classifying) target data.
consistent views, better document clustering, better word
link clustering, creates cycle positive feedback gradually improves adaptation
performance. essence, enhanced consistency views helps bridge domain gap (i.e.,
finding cross-domain feature correlations), vice versa. also provide theoretical justifications proposed approach regarding objective, convergence property optimal
solution. experimental results demonstrate IMAM significantly outperforms state-ofthe-art baselines including traditional single-domain multi-view algorithm co-training (Blum &
Mitchell, 1998), co-training-based domain adaptation algorithm CODA (Chen, Weinberger, &
Blitzer, 2011), single-view transfer learning algorithm CoCC (Dai, Xue, Yang, & Yu, 2007a)
instance-level multi-view transfer learning algorithm MVTL-LM (Zhang et al., 2011).
502

fiI NFORMATION -T HEORETIC ULTI - VIEW OMAIN DAPTATION

rest paper organized follows: Section 2 reviews related work; Section 3
describes background concepts build model; Section 4 presents proposed
IMAM model corresponding algorithm; Section 5 analyses realization consistency
distinct views model; Section 6 discusses experiments results; Finally,
conclude Section 7 prospects future work.

2. Literature Review
Domain adaptation assumes multiple tasks benefit certain structures data shared different distributions. Existing methods divided instance-based approach (Jiang
& Zhai, 2007; Dai, Yang, Xue, & Yu, 2007b), feature-based approach (Blitzer et al., 2007; Dai et
al., 2007a) parameter-based approach (Dayanik, Lewis, Madigan, Menkov, & Genkin, 2006).
Pan Yang (2010) presented comprehensive survey transfer learning described domain adaptation sub-category transfer learning. would give comprehensive review
domain adaptation reason. Interested readers may refer survey paper (Pan & Yang,
2010) details.
work closely related done Dai et al. (2007a), proposed coclustering-based classification (CoCC) algorithm learn out-of-domain data apply
learned classifier in-domain task. CoCC extended information-theoretic co-clustering
method proposed Dhillon et al. (2003), in-domain constraints added word clusters
provide class structure partial categorization knowledge. However, CoCC single-view
algorithm cannot leverage complementary nature multiple views. framework
extension single-view CoCC, algorithm focused strengthening consistency
predictions distinct views across two domains, considered key success
multi-view domain adaptation.
Multi-view learning studied extensively single-domain setting. Co-training
first multi-view algorithm, trained learner view labeled examples
let learner label unlabeled examples receive highest confidence (Blum & Mitchell,
1998). proved two independent yet consistent views used learn concept PAC framework based labeled many unlabeled examples. Many extensions
proposed following idea co-training. Collins Singer (1999) introduced explicit
objective function measures compatibility learned hypotheses used boosting optimize function. Dasgupta, Littman, McAllester (2001) provided PAC-like guarantees
co-training providing upper bound error classifiers learned two views. Abney
(2002) relaxed view independence assumption suggested may underlying
principle gives rise family new methods: disagreement rate two independent
hypotheses upper bounds error rate either hypothesis. Sridharan Kakade (2008) proposed
information-theoretic framework multi-view learning. showed derive incompatibility functions certain loss functions interest minimizing incompatibility
unlabeled data helps reduce expected loss test data. Nevertheless, multi-view learning generally effective domain adaptation since treat domain divergence indiscriminately,
empirically justified experiments (see Experiments Results section).
Multi-view adaptation well studied literature. Daume III, Kumar, Saha (2010)
proposed co-regularization based approach (EA++) semi-supervised domain adaptation. EA++
builds feature augmentation harnesses unlabeled data target domain assist trans503

fiYANG & G AO

fer information source target. Different EA++ aims make different
hypotheses learned different distributions agree unlabeled data, consider true multiview setting try make hypotheses learned different views consistent other.
Furthermore, EA++ builds classifier transformed feature space via feature augmentation,
proposed method learns hypotheses mapped feature space via multi-way clustering. Chen et al. (2011) proposed CODA adaptation based co-training (Blum & Mitchell,
1998), however pseudo multi-view algorithm original data one
view. order apply CODA real multi-view data, views first concatenated split multiple pseudo-views. Therefore, suitable natural true
multi-view case ours. Lawrence (2011) proposed graph-based learning framework
tackle problems feature heterogeneity task heterogeneity. algorithm
transductive learning approach. Zhang Huan (2012) proposed inductive multi-view learning
algorithm multiple related tasks. used co-regularization obtain view-based classifiers agree unlabeled data ensure learned functions similar
view across different tasks. two algorithms designed multi-task
learning rather transfer learning. Zhang et al. (2011) proposed instance-level multi-view
transfer algorithm integrates classification loss view consistency terms based large margin framework. instance-level approach assumes similar source training examples
identified reused train target model. However, performance instance-based
approach generally poor new target features lack support source data (Blitzer et al.,
2011). focus feature-level multi-view adaptation, adaptation takes place multiple transformed feature spaces simultaneously complementarily. best knowledge,
existing work focused feature-level multi-view domain adaptation except
preliminary study recently published (Yang, Gao, Tan, & Wong, 2012). paper extends
work Yang et al. (2012) substantially providing detailed algorithm, theoretical justification
comprehensive empirical evaluation, specifically presented preliminary
version.

3. Background Concepts
multi-view approach based co-clustering (Dhillon et al., 2003) co-clustering-based
classification (CoCC) model (Dai et al., 2007a) building underlying clusters view.
going details model, briefly describe background concepts
lemmas related co-clustering techniques section.
Mutual information fundamental measure quantify mutual dependence two random variables. Let I(X, ) mutual information variables X , defined
P P
p(x,y)
I(X, ) = x p(x, y)log p(x)p(y)
(Cover & Thomas, 1991). Mutual information also
expressed form Kullback-Leibler (KL) divergence, i.e., I(X, ) = (p(x, y)||p(x)p(y)).
Given two discrete random variables X joint probability distribution p(x, y), co-clustering
approach (Dhillon et al., 2003) aims simultaneously cluster X disjoint clusters X,
disjoint clusters . quality co-clustering measured resulting loss based mutual
information:
I(X, ) I(X, )
given X , since I(X, ) fixed, minimizing equation equivalent
maximizing I(X, ).
504

fiI NFORMATION -T HEORETIC ULTI - VIEW OMAIN DAPTATION

p(x) p(y)
simplicity expression, joint distribution q(x, y) = p(x, y) p(x)
p(y) defined

approximate probability p(x, y) co-clustering (X, ). Note distribution q(x, y)
preserves marginals p(x, y). is, x x, y, q(x) = p(x)
q(x) =

X

q(x, y) =



XX


p(x, y)

yy

p(x) p(y) X
p(x)
=
p(x, y)
= p(x).
p(x) p(y)
p(x)


Likewise q(y) = p(y).
Dhillon et al. (2003) proved loss mutual information pre- post-clustering
reformulated KL-divergence p(x, y) approximation q(x, y),
given following lemma:
Lemma 3.1. fixed co-clustering (X, ), loss mutual information expressed
I(X, ) I(X, ) = (p(x, y)||q(x, y)) ,
D(||) KL-divergence, q(x, y) distribution form
q(x, y) = p(x, y)

p(x) p(y)
,
p(x) p(y)

x x y.
completeness clarity, reproduce illustrative example given Dhillon et al.
(2003) interpreting Lemma 3.1. Consider joint distribution (X, ) represented 6*6
matrix below:


.05 .05 .05 0
0
0
.05 .05 .05 0
0
0



0
0
0
.05
.05
.05


0
0
0 .05 .05 .05


.04 .04 0 .04 .04 .04
.04 .04 .04

0

.04 .04

follows naturally rows divided three clusters: x1 = {x1 , x2 }, x2 = {x3 , x4 }
x3 = {x5 , x6 }, columns clustering is: y1 = {y1 , y2 , y3 }, y2 = {y4 , y5 , y6 }. resulting
joint distribution (X, ) given by:



.3 0
0 .3
.2 .2
verified mutual information loss co-clustering .0957, minimum among possible co-clusterings.

4. Information-Theoretic Multi-view Adaptation Model (IMAM)
first introduce motivation, describe model algorithm.
505

fiYANG & G AO

4.1 Motivation
Traditional multi-view learning co-training framework (Blum & Mitchell, 1998) employs
two basic assumptions: (1) target functions view agree labels examples
(consistency assumption); (2) views independent given class label (independence
assumption). first assumption reduces complex learning problem search compatible
functions; second assumption allows model achieve high-confidence predictions since
becomes unlikely consistent classifiers trained independent views agree incorrect
label.
Considering training test data drawn different distributions, nonetheless, consistency assumption mostly violated distinct views agreeing labels source
data unnecessarily compatible labels target examples due domain gap. Therefore, expected traditional multi-view learning framework work effectively
across different domains, empirically justified comparison experiments. Hence,
enhance consistency among multiple views bridge gap among different domains
simultaneously key issue multi-view domain adaptation approach succeed.
Without loss generality, focus cross-domain document classification paper
document representation consists two views word link. Given text documents two domains, would set common word features available domains,
considered domain-independent features, remaining words would regarded either
source-specific target-specific features. taxonomy regarding domain-independent
domain-specific features also apply inter-document links, e.g., hyperlinks citations
features.
single views perspective, source-specific target-specific features drawn together mining co-occurrence domain-independent features. IMAM exploits multiway clustering correlate seemingly unrelated domain-specific features via domainindependent features act bridge. correlations help bridge domain gap facilitate adaptation (Dai et al., 2007a). multiple views perspective, word link clusters
constructed two domains high quality, corresponding target document clustering
resulted either view subsequently improved due effect co-clustering (Dhillon
et al., 2003). expected predictive power distinct views target data tends
become concordant approaches optimal solution. model leverages complementary cooperation different views yield better adaptation performance.
Next, present representational preliminaries objective function
multi-view adaptation model, iterative two-phase algorithm presented optimize
objective.
4.2 Graphical Representation
Let DS training documents source domain DT unlabeled documents
target domain. source target data assumed draw different feature spaces
i.i.d. assumption longer holds. features defined source target domain
others defined domains. simply expand feature space include
features domains missing features either domain replenished 0. Let W
vocabulary entire document collection = DS DT . represented
bag-of-words set {w|w w W }. Let L set links (hyperlinks citations)
506

fiI NFORMATION -T HEORETIC ULTI - VIEW OMAIN DAPTATION

collection. also represented bag-of-links set {l|l dl L}. L naturally
form independent sets features respectively corresponding word view link view. Let C
denote set class labels shared two domains. source document ds DS
labeled unique class label c C. objective assign appropriate class label
target document dt DT accurately possible. Note assume labeled data
available target domain, follows transductive learning scheme. Transductive approach
typical domain adaptation setting, general widely applicable different
scenarios including inductive setting small number labeled target data exist.
Figure 1 shows graphical multi-view adaption model representation, D, W L
respective clusterings documents, words links. Additionally, multi-way clusterings
mutually constrain subject various explicit implicit association relationships. Explicit association includes two types constraints: (1) Document clustering constrained
word clustering link clustering; (2) Word link clustering constrained document clustering class labels. Implicit association means class label knowledge transferred
source documents target documents word link clusters.

Figure 1: graphical representation proposed multi-view adaptation model.
model incorporates multi-way clustering scheme simultaneously clusters documents, words links. clustering functions defined CD (d) = documents,
w l represent corresponding
CW (w) = w words CL (l) = l links, d,
clusters.
4.3 Preliminaries Co-clustering-Based Classification
Dai et al. (2007a) proposed co-clustering-based classification framework, namely CoCC, learn
classifier source-domain documents use classify target-domain documents.
approach, co-clustering leveraged bridge transfer knowledge source
target.
Co-clustering aims simultaneously cluster target documents DT clusters DT words
W clusters W . Since problem classify target-domain documents, key make use
knowledge classes data source domain co-clustering process. kind
correlation source document class knowledge target document clustering
established considering respective relationship word clusters intermediary.
good word clustering minimize loss mutual information class labels
words clustering source data, meanwhile minimize
507

fiYANG & G AO

loss documents words target data. Therefore, loss function CoCC (Dai et
al., 2007a) formulated follows:
h

I(DT , W ) I(DT , W ) + I(C, W ) I(C, W )
trade-off parameter balances effect word clusters co-clustering
word clustering.
4.4 Objective Function
extend information-theoretic framework co-clustering (Dhillon et al., 2003) coclustering-based classification (Dai et al., 2007a) incorporating loss terms multiple
views. Co-clustering aims minimize loss mutual information pre- postclustering respect pair clustering variables, documents words. objective Information-theoretic Multi-view Adaptation Model (IMAM) minimize loss
trading different views:
= W + (1 )L
(1)

h

W = I(DT , W ) I(DT , W ) + I(C, W ) I(C, W )
h

L = I(DT , L) I(DT , L) + I(C, L) I(C, L) .

(2)
(3)

W L loss terms based word view link view, respectively, trade-off
coefficient. Eq. 2, I(DT , W ) I(DT , W ) measures loss word-document co-clustering,
I(C, W ) I(C, W ) measures loss vocabulary class labels, weight
loss word clustering. Class labels act indirect constraints added vocabulary via source
documents propagated target documents co-clustering. Eq. 3,
similar loss term link view. = 1, function relies text information only,
reduces CoCC (Dai et al., 2007a). unlike CoCC (Dai et al., 2007a), aim learn
cross-domain classifiers multi-view data.
worth noting substituting Eq. 2 3 Eq. 1 ignoring constant terms,
reformulate problem following maximization, kind easier interpret:
h

I(DT , W ) + (1 )I(DT , L) + I(C, W ) + (1 )I(C, L)
first two terms enforce view consistency DT , means document
clusters DT preserve mutual information words links much possible,
last two terms enforce transfer information source target via agreement labels
C, indicates source label knowledge maximally preserved word
link clusters.
Given multi-view data data different domains, central problem would different views could cooperate form consistent target class output scenario
different domain data follow different distributions. challenging view consistency based source data largely violated target domain due domain gap. tackle
problem, aim simultaneously enhance consistency among multiple views bridge
508

fiI NFORMATION -T HEORETIC ULTI - VIEW OMAIN DAPTATION

gap among different domains unified objective. IMAM exploits multi-way clustering enrich common words (and links) drawing together seemingly unrelated source-specific
target-specific words (and links). correlations bridge domain gap facilitate adaptation process. hand, IMAM takes weighted combination view-based loss
mutual information. pointed Section 5 (Consistency Multiple Views), optimal document clustering optimize weighted sum word-view link-view document clustering
functions, try minimize disagreement different views. Moreover, multi-way
clustering scheme imposes constraints document word/link clustering,
make mutually benefit other. summary, IMAM uses boosting procedure
enhance view consistency bridge domain gap simultaneously, expected
improve adaptation performance multi-view data.
4.5 IMAM Algorithm
Based q(x, y) defined Section 3, also define corresponding conditional distribution q(x|y) = q(x,y)
p(y) co-clustering. x x, easily prove q(x|y) =
p(x|x)p(x|y). Therefore, w w, l l, c C, calculate set
q(d|w), q(l|d),
q(d|l), q(c|w), q(c|l).
conditional distributions including q(w|d),
objective Eq. 1 hard optimize directly contains mutual information
two clusterings, combinatorial optimization problem. Therefore, transform
form KL-divergence two conditional distributions Lemma 4.1 order facilitate
search optimal value. Let D(p(x|y)||q(x|y)) denote KL-divergence p(x|y)
q(x|y), defined
D(p(x|y)||q(x|y)) =

X

p(x|y)log

x

p(x|y)
.
q(x|y)

following lemma, using similar technique Dhillon et al. (2003), provide
proof Appendix A.
Lemma 4.1 (Objective functions). Equation 1 turned form alternate minimization
two objectives:
(i) document clustering keeping word link clustering fixed, minimize
X
+ C (W , L)
=
p(d)D (d, d)


C (W , L) constant1
= D(p(w|d)||q(w|d))
+ (1 )D(p(l|d)||q(l|d)).

(d, d)
(ii) word link clustering keeping document clustering fixed, minimize
X
X
=
p(w)W (w, w) + (1 )
p(l)L (l, l)
w

l

h

1. prove C (W , L) = (I(C, W ) I(C, W )) + (1 )(I(C, L) I(C, L)) , MI
class label variables constant.

509

fiYANG & G AO

Algorithm 1 Algorithm IMAM
Input:
Document-term matrices DS W DT W ;
Document-link matrices DS L DT L;
Class label c C assigned doc DS ;
# document clusters (i.e., # classes);
Output:
Class label assigned document DT ;
(0)
(0)
1: Set = 0. Initialize document clustering CD using NBC. Initialize word clustering CW link clus(0)
tering CL randomly;
q (0) (l|d),
q (0) (d|w), q (0) (d|l), q (0) (c|w), q (0) (c|l);
2: Initialize distributions q (0) (w|d),
3: repeat
4:
Document clustering: d, find new cluster index using Eq. 4;
5:
Keep q (t+1) (c|w) = q (t) (c|w) q (t+1) (c|l) = q (t) (c|l);
q (t+1) (l|d),
q (t+1) (d|w), q (t+1) (d|l);
Update q (t+1) (w|d),
6:
Word clustering: word w, find new cluster index using Eq. 5;
Link clustering: link l, find new cluster index using Eq. 6;
q (t+2) (l|d),
q (t+2) (d|w), q (t+2) (d|l), q (t+2) (c|w) q (t+2) (c|l);
7:
Update q (t+2) (w|d),
8:
= + 2;
9: documents cluster index needs adjust
10: unlabeled DT
11:
Assign class label based Eq. 7;
12: end

feature v (e.g., w l) feature set V (e.g., W L)
V (v, v) = D(p(d|v)||q(d|v)) + D(p(c|v)||q(c|v)).
intuition optimization given document-word document-link matrices,
let us simultaneously re-order documents two matrices documents mapping
first document cluster arranged first, followed documents mapping second cluster,
on. good document clustering tries ensure consistency different views.
Next, let us simultaneously re-order words links document-word document-link matrices
similar way. good word (or link) clustering draws indirectly related domain-specific words
(or links) together since may co-occur domain-independent words (or links)
documents. document-word-link interaction helps finding optimal multi-way clustering.
Lemma 4.1 allows us alternately reorder either documents words links,
shown Algorithm 1, way mutual information loss decreases monotonically (see
Lemma 4.2).
4.5.1 LGORITHM
(0)

(0)

(0)

algorithm starts initial multi-clustering (CD , CW , CL ) iteratively refines
algorithm converges. algorithm uses two-phase iterative procedure minimize
loss, first searches best document clustering keeping word link
clustering unchanged, clusters words links document clustering remains fixed.
step 1, Naive Bayes classifier (NBC) trained source data DS used predict
class target data DT , produces initial document clustering entire D. Note
510

fiI NFORMATION -T HEORETIC ULTI - VIEW OMAIN DAPTATION

cluster index source documents fixed class labels. Thus, allocation target
document certain cluster also means document assigned corresponding class
label. worth noting since objective Eq. 1 non-convex, somewhat sensitive
initialization. Hence, instead random initialization, use NBC generate initial document
clusterings keep start good points.
Step 4 updates cluster index d:
h

(t+1)
+ (1 )D(p(l|d)||q (t) (l|d))

CD (d) = arg min D(p(w|d)||q (t) (w|d))
(4)


Step 6 updates cluster index w:
h

(t+2)
CW (w) = arg min D(p(d|w)||q (t+1) (d|w)) + D(p(c|w)||q (t+1) (c|w))

(5)

w

updates cluster index l:
h

(t+2)
CL (l) = arg min D(p(d|l)||q (t+1) (d|l)) + D(p(c|l)||q (t+1) (c|l))

(6)

l

Note Algorithm 1 separately update membership word link since
implicit association relationships word clustering link clustering via document clustering. document clustering acts bridge make word clustering link
clustering mutually affect other.
finishing multi-way clustering procedure, assign target document DT
class label predicted
h

+ (1 )D(p(l|c)||q(l|d))

c = arg min D(p(w|c)||q(w|d))
(7)
cC

Lemma 4.2 guarantees convergence algorithm, proof given
Appendix B borrowing similar technique Dhillon et al. (2003). Note finding
global minimum multi-way clustering NP-hard, IMAM uses greedy approach find
local minimum, guarantee global optimum. usually run experiments
multiple times average performance different runs.
Lemma 4.2 (Convergence). IMAM monotonically reduces objective given Equation 1.
is,
(t) (t+1)
(t+1) (t+2)
= 0, 2, 4, . . .

5. Consistency Multiple Views
section, present consistency document clustering target data could enhanced among multiple views, key issue multi-view adaptation method.
511

fiYANG & G AO

particularly discuss relationship disagreement rate views optimal document clustering function.
(t+1)
iteration Algorithm 1, optimal document clustering function CD
(see Eq. 4)
minimize weighted sum KL-divergences used optimal word-view link-view document clustering functions shown above. optimal word-view clustering functions
denoted follows:
(t+1)

CDW (d) = arg min D(p(w|d)||q (t) (w|d))
(8)


similarly link-view function
(t+1)


CDL (d) = arg min D(p(l|d)||q (t) (l|d))

(9)



(t+1)

(t+1)

central idea document clusterings CDW CDL based two views
drawn closer iteration due word link clusterings (Eq. 5 6) bring together
(t+1)
seemingly unrelated source-specific target-specific features. Meanwhile, CD
combines
two views reallocates documents maintains consistency view-based
clusterings much possible.
5.1 Disagreement Rate Views
D} set document clustering functions
Suppose = {Fi |Fi (d) = d,
number clusters fixed. document, consistency indicator function respect
two clustering functions defined follows (Round indicator omitted simplicity):
Definition 1 (Indicator function) D, Fi , Fj

1, Fi (d) = Fj (d);
Fi ,Fj (d) =
0, otherwise
define disagreement rate two view-based clustering functions:
Definition 2 (View disagreement rate) Fi Fj
P
F ,F (d)
(Fi , Fj ) = 1 dD j
|D|

(10)

Obviously, (CDW , CDL ) denotes disagreement rate word-view link-view
clustering functions. Abney (2002) suggests disagreement rate two independent hypotheses upper-bounds error rate either hypothesis. minimizing disagreement rate
unlabeled data, error rate view minimized (so overall error). However,
disagreement rate function continuous convex, difficult optimize directly2 .
Alternatively, minimize mutual information loss Eq. 1 surrogate disagreement
rate function. believe mutual information loss good surrogate because, discussed
Section 4.4, Eq. 1 aims enhance view consistency, equivalent minimizing
disagreement rate views. Moreover, show empirically optimizing Eq. 1 disagreement rate (CDW , CDL ) indeed monotonically decreased iterations experiments
(see Section 6).
2. Abney (2002) used greedy approach.

512

fiI NFORMATION -T HEORETIC ULTI - VIEW OMAIN DAPTATION

5.2 View Combination
Note practice view-based document clusterings Eq. 8 Eq. 9 computed
explicitly. Instead, Eq. 4 directly optimizes view combination produces document clustering. Therefore, necessary disclose consistent combined view-based clustering
could individual view-based clusterings.
Fi , obtain disagreement rate (Fi , CDW CDL ), CDW CDL denotes clustering resulting overlap individual view-based clusterings. Note
co-training style algorithms usually assume multiple views redundant. Thus,
intersection would empty. obtain Lemma 5.1 below, proof given
Appendix C.
Lemma 5.1. optimal document clustering function CD IMAM model always minimizes
disagreement rate Fi
(CD , CDW CDL ) = min (Fi , CDW CDL )
Fi

meanwhile, (CD , CDW CDL ) = (CDW , CDL ).
Lemma 5.1 suggests IMAM always finds document clustering minimal disagreement rate overlap individual view-based clusterings, minimal value
disagreement rate equals disagreement rate individual view-based clusterings.

6. Experiments Results
section, empirically evaluate IMAM algorithm cross-domain document classification tasks comparison state-of-the-art baselines.
6.1 Data Setup
Cora (McCallum, Nigam, Rennie, & Seymore, 2000) online archive contains approximately 37,000 computer science research papers 1 million links among documents.
documents categorized hierarchical structure. selected subset Cora, contains 5 top categories 10 sub-categories (the numbers parenthesis):
- DA 1: /data structures algorithms theory/computational complexity/ (711)
- DA 2: /data structures algorithms theory/computational geometry/ (459)
- EC 1: /encryption compression/encryption/ (534)
- EC 2: /encryption compression/compression/ (530)
- NT 1: /networking/protocols/ (743)
- NT 2: /networking/routing/ (477)
- OS 1: /operating systems/realtime/ (595)
- OS 2: /operating systems/memory management/ (1,102)
- ML 1: /machine learning/probabilistic methods/ (687)
- ML 2: /machine learning/genetic algorithms/ (670)

Based dataset, used similar way Dai et al. (2007a) construct training
test sets. set, chose two top categories, one positive class
negative. Different sub-categories deemed different domains. task defined
top category classification. example, subset denoted DA-EC consists source domain:
513

fiYANG & G AO

DA 1(+), EC 1(-); target domain: DA 2(+), EC 2(-). method ensures domains
labeled unlabeled data related due top categories, domains different
drawn different sub-categories. preprocessing common practice data
preparation adaptation purpose. previous work (Ling, Dai, Xue, Yang, & Yu, 2008; Dai
et al., 2007a) found baseline SVM well transductive SVM classifiers trained sourcedomain data performed much worse target domain, implying large domain gap them.
finding dataset using transductive SVM.
preprocessed data text link information. texts, removed stop
words low-frequency words count less 5. links, removed links less
5 citation counts. standard TF-IDF (Salton & Buckley, 1988) technique applied
text link datasets. Moreover, generated merged dataset concatenating
word link features together.
Reuters-21578 (Lewis, 2004) widely used evaluation automatic text categorization
algorithms. Reuters-21578 corpus also hierarchical structure, contains 5 top categories.
used pre-processed version corpus public accessible3 . statistics
dataset seen Table 1. Based data, generated separate information representing
two views: first view corresponds features using TF-IDF scores terms; second
view corresponds topic-based features (i.e. document-topic distributions) obtained applying probabilistic Latent Semantic Analysis (pLSA)4 term counts information, topic
number set 200.
Subset
Orgs-People
Orgs-Places
People-Places

Source
OrgsPeople.src (1,237)
OrgsPlaces.src (1,016)
PeoplePlaces.src (1,077)

Target
OrgsPeople.tar (1,208)
OrgsPlaces.tar (1,043)
PeoplePlaces.tar (1,077)

Table 1: statistics Reuters-21578 dataset.
Using Cora dataset, conducted experiments IMAM studying influence different parameters manifestation view disagreement rate. Also, compared IMAM
various state-of-the-art domain adaptation algorithms Cora Reuters datasets. order
avoid infinity values, applied Laplacian smoothing computing KL-divergence.
6.2 Parameter Sensitivity
first studied influence important parameters, i.e., number word/link clusters,
, .
6.2.1 NFLUENCE C LUSTER N UMBER
Figure 2 shows error rate curves varying different number word (and link) clusters
4 subsets: DA-EC, DA-NT, DA-OS EC-NT. X-axis represents number word (and
link) clusters tuned 32 512. According performance shown figure,
empirically set number word (and link) clusters 128.
3. http://www.cse.ust.hk/TL/dataset/Reuters.zip.
4. http://lear.inrialpes.fr/people/verbeek/code/plsa.tar.gz.

514

fiI NFORMATION -T HEORETIC ULTI - VIEW OMAIN DAPTATION

Figure 2: Error rate curves varying different number word/link clusters.
6.2.2 NFLUENCE
Figure 3 shows performance curves vary different values . error rate generally
decreases first increases augmented. always, algorithm performs worst
model heavily relies either text information (0.9 1.0) link structure
(0 0.1). setting 0.5 0.8 achieved best results subsets. implies two views document complementary. Therefore, remaining
experiments, set value 0.7.

Figure 3: Error rate curves varying different settings .
6.2.3 NFLUENCE
used propagating class labels source document class target document clustering
word link clusters. Surprisingly, observe significant influence
subsets. used NBC initialize document clusterings good starting
point, class information, though accurately, could largely propagated words
link clusters next iteration. observation similar Dai et al. (2007a)
number word clusters appropriately provided. empirically set 0.5
trying 0, 0.25, 0.5, 1, 2 4.
515

fiYANG & G AO

source
target

DA-EC
0.179
0.251

DA-NT
0.157
0.224

DA-OS
0.188
0.275

DA-ML
0.184
0.211

EC-NT
0.210
0.234

Average
0.184
0.239

Table 2: view disagreement rates different domains using co-training.
Iteration
DA-EC
DA-NT
DA-OS
DA-ML
EC-NT












1
0.194
0.340
0.147
0.295
0.129
0.252
0.166
0.306
0.311
0.321

2
0.153
0.132
0.083
0.100
0.064
0.092
0.102
0.107
0.250
0.137

3
0.149
0.111
0.071
0.076
0.052
0.068
0.071
0.076
0.228
0.112

4
0.144
0.101
0.065
0.069
0.047
0.060
0.065
0.062
0.219
0.096

5
0.144
0.095
0.064
0.064
0.041
0.052
0.064
0.054
0.217
0.089


0.998
0.996
0.998
0.984
0.988

Table 3: View disagreement rate () error rate () decrease iterations. correlation denoted .

6.3 View Disagreement Rate
section, studied view disagreement rate two different purposes: (1) experimentally verified view consistency assumption violated due distinct domains
traditional multi-view learning using co-training, justified motivation reduce view
disagreement rate; (2) examined property view disagreement rate based method
revealed relationship cross-domain classification performance.
6.3.1 C -T RAINING
experiment, subset, source data splitted two portions, one portion
training testing. traditional multi-view algorithm co-training (Blum &
Mitchell, 1998) trained source training set, model evaluated
source test set target test set separately. first result corresponds single-domain
performance second corresponds cross-domain performance.
shown Table 2, clear view disagreement rate target domain considerably higher source domain. implies domain gap likely deteriorate
view consistency. Abney (2002) pointed out, view consistency directly related classification
error rate, upper bounded view disagreement rate. finding experiment
seems consistent claim, furthermore, implies would helpful overcome
domain gap enhancing view consistency target data.
6.3.2 IMAM
examined variance disagreement rate (CDW , CDL ) view-based clusterings
correlation error rate .
516

fiI NFORMATION -T HEORETIC ULTI - VIEW OMAIN DAPTATION

used Pearsons correlation measure dependence disagreement rate error
rate, takes value -1 (perfect negative correlation) 1 (perfect positive correlation). Table 3 shows monotonic decrease disagreement rate error rate
iterations, correlation nearly perfectly positive. indicates IMAM may gradually improves adaptation performance strengthening consistency different views,
alternatively, IMAM increases classification performance, causes different views
consistent. procedures therefore reciprocal causation. achieved
mutual reinforcement word link clustering draws together target-specific
source-specific features, originally unrelated could co-occur common features across two domains.
6.4 Convergence
convergence property IMAM shown Figure 4. IMAM uses two-phase iterative procedure find local optimal point. convergence guaranteed Lemma 4.2. see
number documents needed reassigned different clusters decreases fast
first 5 iterations reaches 0 10 iterations. Thus, terminate algorithm
maximum 15 iterations.

Figure 4: Number documents needed reassigned different clusters varies iterations.
6.5 Algorithms Comparison
compared IMAM variety state-of-the-art algorithms including Transductive SVM5
(TSVM) (Joachims, 1999) semi-supervised classifier, co-training (Co-Train) (Blum &
Mitchell, 1998), co-clustering-based single-view transfer learning CoCC (Dai et al., 2007a),
large-margin-based multi-view transfer learning MVTL-LM (Zhang et al., 2011) cotraining-based adaptation algorithm CODA6 (Chen et al., 2011). used Cora Reuters
datasets comparative study.
datasets, ease presentation, used postfix -C, -L -CL denote
classifier fed data different views. Cora dataset, -C, -L -CL represent text
5. http://svmlight.joachims.org/.
6. http://www1.cse.wustl.edu/mchen/code/coda.tar.

517

fiYANG & G AO

Subset
DA-EC
DA-NT
DA-OS
DA-ML
EC-NT
EC-OS
EC-ML
NT-OS
NT-ML
OS-ML
Average

TSVM-C
0.293
0.175
0.276
0.217
0.305
0.355
0.333
0.364
0.205
0.202
0.272

TSVM-L
0.157
0.137
0.261
0.114
0.220
0.201
0.205
0.501
0.106
0.170
0.207

TSVM-CL
0.214
0.114
0.262
0.107
0.177
0.245
0.168
0.396
0.101
0.179
0.196

Co-Train
0.230
0.163
0.175
0.171
0.296
0.175
0.206
0.220
0.132
0.128
0.190

MVTL-LM
0.192
0.108
0.068
0.183
0.261
0.176
0.264
0.288
0.071
0.126
0.174

CODA
0.234
0.076
0.109
0.150
0.178
0.187
0.322
0.240
0.025
0.087
0.161

CoCC-C
0.149
0.106
0.075
0.109
0.225
0.137
0.203
0.107
0.054
0.051
0.122

CoCC-L
0.227
0.132
0.086
0.098
0.296
0.116
0.269
0.142
0.094
0.051
0.151

CoCC-CL
0.187
0.115
0.067
0.095
0.239
0.125
0.237
0.115
0.047
0.062
0.129

IMAM
0.138
0.069
0.039
0.047
0.191
0.074
0.173
0.070
0.031
0.021
0.085

Table 4: Error rate classification adaptation Cora dataset.
Subset
OrgsPeople
OrgsPlaces
PeoplePlaces
Average

TSVM-C
0.246
0.278
0.294
0.273

TSVM-L
0.263
0.304
0.335
0.301

TSVM-CL
0.227
0.263
0.286
0.259

Co-Train
0.251
0.270
0.318
0.280

MVTL-LM
0.230
0.249
0.260
0.246

CODA
0.177
0.226
0.275
0.226

CoCC-C
0.185
0.214
0.245
0.215

CoCC-L
0.219
0.235
0.262
0.239

CoCC-CL
0.191
0.221
0.248
0.220

IMAM
0.153
0.192
0.218
0.188

Table 5: Error rate classification adaptation Reuters-21578 dataset.
view, link view two views, respectively; Reuters dataset, correspond term view, topic
view two views. examined classifier inherently multi-view, viewss data
fed it. algorithm include TSVM-CL, co-training, MVTL-LM, CoCC-CL, IMAM.
Since CODA pseudo multi-view adaptation algorithm, fit scenario, CODA fed
merged view could automatically split sub-views. algorithm,
parameters tuned using five-fold cross-validation training data. cancel local
optimal results, repeated algorithms five times subset reported average error
rate.
algorithms trained source data tested target data.
classification error rate target data used evaluation metric, defined ratio
number misclassified documents total documents.
6.6 Performance Comparison
Table 4 shows results comparison Cora dataset, Table 5 shows Reuters21578. consistent findings two datasets.
datasets, TSVM performed poorly adaptation using either content link features alone. Simply merging two sets features makes improvements, implying text
link Cora data (or, term topic Reuters data) complementary, may degrade
confidence classifier instances whose features become conflicting
merging. Co-training avoid problem boosting confidence classifiers built
distinct views complementary way, performance comparable TSVM though
uses weaker base classifier. Since TSVM co-training consider distribution
gap, performed clearly worse CoCC even though CoCC single-view approach.
datasets, CODA outperformed co-training MVTL-LM splitting feature space
multiple pseudo views iteratively adding shared source target features based
compatibility across domains. However, could comparably effective IMAM.
seems pseudo views automatically generated CODA complementary
original view partition two datasets. performed even worse COCC singleview setting, indicating sometimes pseudo views might detrimental. relatively lower
performance CODA may explained follows. might happen original formation
two views data reasonably good, combined one view,
likely CODA could stuck poor locally optimal decomposition features due
518

fiI NFORMATION -T HEORETIC ULTI - VIEW OMAIN DAPTATION

non-smooth, non-convex nature objective function. Since model parameters
initialized randomly, repeating algorithm guarantee better solution. contrast,
objective function IMAM, although non-convex, smooth, also, instead using random
initialization used NBC initialize document clusters ensure good starting point.
IMAM significantly outperformed CoCC-C CoCC-L subsets. average,
error rate IMAM 30.3% lower CoCC-C (or 43.7% lower CoCCL). IMAM effectively leverages distinct complementary views. Compared
CoCC, using source training data improve view consistency target data key competency IMAM. Moreover, IMAM performed much better CoCC-CL. Unlike CoCC-CL
simply concatenates two-view data, technique strengthen view consistency
bootstrapping two CoCC models iteratively complementarily. model two CoCC
models communicate complementarily iteration, consequently boosts consistency
two views.
result shows multi-view adaptation using MVTL-LM performs worse IMAM
subsets. general explanation suggests instance-based approach relying instance
weighting effective data different domains drawn different feature
spaces. Although MVTL-LM regulates view consistency domains instances, cannot
identify useful correlation target-specific source-specific features,
key success adaptation especially domain gap large little commonality
could found. contrast, CoCC IMAM use co-clustering multi-way clustering find
correlation.
Note use different ways generate multi-view data two datasets. Different
Cora dataset natural multiple views, i.e., text link, generate term
topic views Reuters-21578 dataset based text information only. Nevertheless, results
datasets show IMAM works well different types multi-view data using
multi-way clustering enhance view consistency.

7. Conclusion Future Work
presented novel feature-level multi-view adaptation approach called IMAM cross-domain
document classification. thrust technique incorporate distinct views document
features multi-way clustering framework gradually strengthen view consistency
classifying target documents. improvements state-of-the-art baselines substantial.
provided theoretical empirical justifications regarding properties proposed
algorithm. Experiments show considerably outperforms state-of-the-art baselines including multi-view single-domain algorithm co-training, co-training-based adaptation CODA,
single-view adaptation CoCC well instance-level multi-view adaptation MVLT-LM.
Multi-view domain adaptation promising direction since underlying principle practice still open questions. part ongoing work, explore foundations
limitations multi-view domain adaptation. example, multiple views might hurt adaptation performance domains views dissimilar. Although observed
experiments, needs analyzed deeply. addition, due practical reasons,
directly optimize consistency measure, i.e., view disagreement rate. Instead, adopted
information-theoretical framework optimize mutual information loss, worked well
may ideal solution. future, study techniques directly optimize
consistency measure views.
519

fiYANG & G AO

Appendix A. Proof Lemma 4.1
Proof. proof Lemma 4.1 divided two parts.
(i) document clustering:
Note word link clusterings keep fixed phase. Thus mutual information
class label word (or link) clusters remains unchanged document clustering
phase, is,
h

C (W , L) = (I(C, W ) I(C, W )) + (1 )(I(C, L) I(C, L))
constant. using Eq. 1, obtain
C (W , L)
= W + (1 )L C (W , L)
h

h

= I(DT ; W ) I(DT ; W ) + (1 ) I(DT ; L) I(DT ; L)




XXX X
XX X X
w)
p(d,
w)
p(
d,


p(d, w) log
=
p(d, w) log

w)
p(d)p(w)
p(
d)p(
w dd ww
w
dd ww




X
X
XXXX
X
X


p(d, l)
p(d, l)

p(d, l) log
+ (1 )
p(d, l) log

l)
p(d)p(l)
p(d)p(


l

=

XXX X

=

XXX X

=

XXX X

=

XX









p(d, w) log

w dd ww

w dd ww

p(d)

XX

dd

l

XXXX
w)
l)
p(d, w)p(d)p(
p(d, l)p(d)p(
+ (1 )
p(d, l) log
w)p(d)p(w)
l)p(d)p(l)
p(d,
p(d,




l

dd

XXXX
p(d, w)
p(d, l)
p(d, w) log
+ (1 )
p(d, l) log
q(d, w)
q(d, l)


p(d)p(w|d) log

w dd ww

dd

=

dd

XX

p(w|d) log

w ww

p(w|d)
+ (1 )

q(w|d)

l

dd

XXXX

p(w|d)
+ (1 )

q(w|d)



p(d)p(l|d) log

dd

l

XX

p(d)

dd

XX
l

h

+ (1 )D(p(l|d)||q(l|d))

p(d) D(p(w|d)||q(w|d))

p(l|d)

q(l|d)

p(l|d) log



p(l|d)

q(l|d)



dd

=

X


p(d)D (d, d)



(ii) word link clustering:
Note document clusterings remains unchanged phase. Using similar technique
above, obtain
=

X

p(w)W (w, w) + (1 )

w

X
l

combining steps (i) (ii), Lemma 4.1 proved.
520

p(l)L (l, l)

fiI NFORMATION -T HEORETIC ULTI - VIEW OMAIN DAPTATION

Appendix B. Proof Lemma 4.2
Proof. proof Lemma 4.2 divided two parts.
(i) document clustering: Note word link clusterings keep fixed phase.
(t)



(a)

(t)

X

C (W , L) =

h

(t)
+ (1 )D(p(l|d)||q (t) (l|d))

p(d) D(p(w|d)||q (w|d))

X

d:C (t) (d)=d



=

X

X

p(d)

X

p(w|d) log

w

d:C (t) (d)=d



X
p(l|d)
p(w|d)

+ (1 )
p(l|d) log


q (t) (w|d)
q (t) (l|d)
l



(b)

X



X

p(d)

X

p(w|d)

p(w|d) log

w

d:C (t) (d)=d



(c)

X

=

X

p(d)

X

p(w|d) log

w

d:C (t+1) (d)=d


+ (1 )

(t+1)
q (t) (w|CD
(d))

X



p(l|d)

p(l|d) log

(t+1)
q (t) (l|CD
(d))

l




X
p(w|d)
p(l|d)

+ (1 )
p(l|d) log


q (t) (w|d)
q (t) (l|d)
l


(d)

X

=

X

d:C (t+1) (d)=d




X

p(d)

w

X

p(w|d)

p(w|d) log


q (t) (w|w)q (t) (w|d)

(t+1)
w:C
(w)=w
W

+ (1 )

X

X

p(l|d) log

l l:C (t+1) (l)=l
L

=

X

d:C (t+1) (d)=d






q (t) (l|l)q (t) (l|d)




X

p(l|d)

X

p(d)

w

X

p(w|d)

p(w|d) log

q (t) (w|w)

(t+1)
w:C
(w)=w
W

+ (1 )

X

X

l l:C (t+1) (l)=l
L

p(l|d)

p(l|d) log

q (t) (l|l)

{z

|

}






+

X

X

d:C (t+1) (d)=d


X

p(d)

w

X

p(w|d) log

(t+1)
w:C
(w)=w
W


"
=I+

X



X



w



X
d:C

X

(t+1)
(t+1)
(d)=d w:C
(w)=w

W

X

d:C

X

(t+1)
(t+1)
(d)=d l:C
(l)=l

L


X



X (t+1)
w) log
q
(d,
w


(e)

I+

1

q (t) (w|d)


X (t+1)
X (t+1)

log
q
(d)
q
(w|d)
w



X

X

p(d)

d:C (t+1) (d)=d


+ (1 )


1

p(d)p(l|d) log


q (t) (l|d)

+ (1 )

=

X

1

q (t+1) (w|d)

X

w

(t+1)
w:C
(w)=w
W

X

p(l|d) log

X

p(d)

d:C (t+1) (d)=d


(1 )

X





q (t) (l|d)

X

+ (1 )

p(w|d) log


q (t) (l|d)




X (t+1)
log
q
(l|d)
l

1

q (t+1) (l|d)




p(w|d)

q (t) (w|w)q (t+1) (w|d)
#

p(l|d)

X

w

(t+1)
w:C
(w)=w
W

l l:C (t+1) (l)=l
L

1


q (t) (l|l)q (t+1) (l|d)

X

p(l|d) log

#

X (t+1)
l) log
q
(d,

"
X

l l:C (t+1) (l)=l
L

l

X

l l:C (t+1) (l)=l
L
(f )

p(l|d) log

p(w|d)
+

q (t+1) (w|w)q (t+1) (w|d)

p(w|d) log

#

p(l|d)

q (t+1) (l|l)q (t+1) (l|d)


=

X

=

X

X

d:C (t+1) (d)=d




X

p(d)

w

X
w:C

(t+1)
(w)=w
W

p(w|d) log

p(w|d)

q (t+1) (w|d)

(t+1)

=

+ (1 )

X

(t+1)

C

(W , L)

521

X

l l:C (t+1) (l)=l
L

h

(t+1)
+ (1 )D(p(l|d)||q (t+1) (l|d))

p(d) D(p(w|d)||q
(w|d))

X

d:C (t+1) (d)=d

(g)

1


1

p(d)p(w|d) log


q (t) (w|d)

"
=

+ (1 )

X



X

+ (1 )



=I+


q (t) (w|d)

X





l

1

p(l|d) log


p(l|d)



q (t+1) (l|d)

fiYANG & G AO

(a) follows Lemma 4.1, (b) follows Step 4 IMAM algorithm, (c) follows rearranging summation, (d) (f) follow since hold word link clusters
fixed Step 4, (e) follows non-negativity KL-divergence, (g) follows Lemma 4.1. Since word link clusters remain unchanged document clustering, i.e.,
(t)
(t+1)
C (W , L) = C (W , L), prove (t) (t+1) .
(ii) word link clustering: Note document clusterings remains unchanged
phase. using properties Step 6 similar technique above, prove
(t+1) =

X

X

(t+1)

p(w)W

(w, w) + (1 )

X

X

l

(t+1)
l:CL
(l)=l

w w:C (t+1) (w)=w
W



X

=

(t+2)

X

(t+2)
p(w)W (w, w)

+ (1 )

X

w w:C (t+2) (w)=w
W

l

X
(t+2)

l:CL

(t+1)

p(l)L
(t+2)

p(l)L

(l,
l)

(l,
l)

(l)=l

combining steps (i) (ii), follows every iteration algorithm IMAM monotonically decreases objective function.

Appendix C. Proof Lemma 5.1
Proof. document document cluster D,
(i) CDW (d) = CDL (d)
brevity, denote cluster , i.e., CDW (d) = CDL (d) = . using Eq. 4, Eq. 8
Eq. 9, obtain

D(p(w|d)||q(w|d )) D(p(w|d)||q(w|d))



D(p(l|d)||q(l|d ))
D(p(l|d)||q(l|d))


+ (1 )D(p(l|d)||q(l|d))

D(p(w|d)||q(w|d )) + (1 )D(p(l|d)||q(l|d )) D(p(w|d)||q(w|d))



CD (d) = CDW (d) = CDL (d) =
CD ,CDW CDL (d) = 1

(ii) CDW (d) 6= CDL (d)
Obviously, CD ,CDW CDL (d) = 0. combining (i) (ii), obtain

1, CDW (d) = CDL (d);
CD ,CDW CDL (d) = CDW ,CDL (d) =
0, otherwise
Fi , indicator function Fi ,CDW CDL (d) rewritten

1, CDW (d) = CDL (d) = Fi (d);
0, CDW (d) = CDL (d) 6= Fi (d);
Fi ,CDW CDL (d) =

0, otherwise
Thus, CD ,CDW CDL (d) Fi ,CDW CDL (d). inequation holds true Fi .
Therefore, based definition disagreement rate obtain
P
(Fi , CDW CDL ) = 1

dD

Fi ,CDW CDL (d)
|D|

P
1

dD

CD ,CDW CDL (d)
|D|

Meanwhile, obtain (CD , CDW CDL ) = (CDW , CDL ).
522

= (CD , CDW CDL )

fiI NFORMATION -T HEORETIC ULTI - VIEW OMAIN DAPTATION

References
Abney, S. (2002). Bootstrapping. Proceedings 40th Annual Meeting Association
Computational Linguistics, July 6-12, 2002, Philadelphia, PA, USA, pp. 360367.
Blitzer, J., Dredze, M., & Pereira, F. (2007). Biographies, bollywood, boom-boxes blenders:
Domain adaptation sentiment classification. Proceedings 45th Annual Meeting
Association Computational Linguistics, June 23-30, 2007, Prague, Czech Republic,
pp. 440447.
Blitzer, J., Kakade, S., & Foster, D. P. (2011). Domain adaptation coupled subspaces. Proceedings 14th International Conference Artificial Intelligence Statistics, April
11-13, 2011, Ft. Lauderdale, FL, USA, pp. 173181.
Blum, A., & Mitchell, T. (1998). Combining labeled unlabeled data co-training. Proceedings 11th Annual Conference Computational Learning Theory, Madison, Wisconsin, USA, July 24-26, 1998, pp. 92100.
Cai, P., Gao, W., Zhou, A. Y., & Wong, K. F. (2011a). Relevant knowledge helps choosing right
teacher: Active query selection ranking adaptation. Proceedings 34th International ACM SIGIR Conference Research Development Information Retrieval, July
24-28, 2011, Beijing, China, pp. 115124.
Cai, P., Gao, W., Zhou, A. Y., & Wong, K. F. (2011b). Query weighting ranking model adaptation. Proceedings 49th Annual Meeting Association Computational Linguistics: Human Language Technologies, June 19-24, Portland, Oregon, USA, pp. 112122.
Chen, M.M., Weinberger, K. Q., & Blitzer, J. (2011). Co-training domain adaptation. Proceedings Advances Neural Information Processing Systems 24, December 12-14, 2011,
Granada, Spain, pp. 19.
Collins, M., & Singer, Y. (1999). Unsupervised models named entity classification. Proceedings 1999 Joint SIGDAT Conference Empirical Methods Natural Language Processing Large Corpora, pp. 100110.
Cover, T. M., & Thomas, J. A. (1991). Elements information theory. Wiley-Interscience.
Dai, W. Y., Xue, G. R., Yang, Q., & Yu, Y. (2007a). Co-clustering based classification outof-domain documents. Proceedings 13th ACM SIGKDD International Conference
Knowledge Discovery Data Mining, San Jose, California, USA, August 12-15, 2007,
pp. 210219.
Dai, W. Y., Yang, Q., Xue, G. R., & Yu, Y. (2007b). Boosting transfer learning. Proceedings
24th International Conference Machine Learning, Corvallis, Oregon, USA, June
20-24, 2007, pp. 193200.
Dasgupta, S., Littman, M. L., & McAllester, D. (2001). PAC generalization bounds co-training.
Proceedings Advances Neural Information Processing Systems 14, December 9-14,
2002, Vancouver, British Columbia, Canada, pp. 375382.
Daume III, H., & Marcu, D. (2006). Domain adaptation statistical classifiers. Journal Artificial
Intelligence Research, 26(2006):101126.
523

fiYANG & G AO

Daume III, H., Kumar, A., & Saha, A. (2010). Co-regularization based semi-supervised domain
adaptation. Proceedings Advances Neural Information Processing Systems 23, December 6-9, 2010, Vancouver, Canada, pp. 478496.
Dayanik, A. A., Lewis, D. D., Madigan, D., Menkov, V., & Genkin, A. (2006). Constructing informative prior distributions domain knowledge text classification. Proceedings
29th Annual International ACM SIGIR Conference Research Development
Information Retrieval, Seattle, Washington, USA, August 6-11, 2006, pp. 493500.
Dhillon, I. S., Mallela, S., & Modha, D. S. (2003). Information-theoretic co-clustering. Proceedings Ninth ACM SIGKDD International Conference Knowledge Discovery Data
Mining, Washington, DC, USA, August 24 - 27, 2003, pp. 210219.
Gao, W., Blitzer, J., Zhou, M., & Wong, K. F. (2009). Exploiting bilingual information improve
web search. Proceedings 47th Annual Meeting Association Computational
Linguistics 4th International Joint Conference Natural Language Processing
AFNLP, August 2-7, 2009, Singapore, pp. 10751083.
Gao, W., Cai, P., Wong, K. F., & Zhou, A. Y. (2010). Learning rank using training data
related domain. Proceedings 33rd Annual International ACM SIGIR Conference
Research Development Information Retrieval, July 19-23, 2010, Geneva, Switzerland,
pp. 162169.
Gao, W., & Yang, P. (2014). Democracy good ranking: Towards multi-view rank learning
adaptation web search. Proceedings 7th International ACM Conference Web
Search Data Mining, Feburary 25-27, 2014, New York City, USA, pp. 6372.
He, J. R., & Lawrence, R. (2011) graph-based framework multi-task multi-view learning.
Proceedings 28th International Conference Machine Learning, Washington, Jun
28-Jul 2, 2011, pp. 2532.
Lewis, D. D. (2004). Reuters-21578 test collection. http://www.daviddlewis.com/.
Joachims, T. (1999). Transductive inference text classification using support vector machines.
Proceedings 16th International Conference Machine Learning, Bled, Slovenia,
June 27-30, 1999, pp. 200209.
Jiang, J., & Zhai, C. X. (2007). Instance weighting domain Adaptation NLP. Proceedings
45th Annual Meeting Association Computational Linguistics, June 23-30, 2007,
Prague, Czech Republic, pp. 264271.
Ling, X., Dai, W. Y., Xue, G. R., Yang, Q., & Yu, Y. (2008). Spectral domain-transfer learning.
Proceedings 14th ACM SIGKDD International Conference Knowledge Discovery
Data Mining, Las Vegas, Nevada, USA, August 24-27, 2008, pp. 488496.
McCallum, A. K., Nigam, K., Rennie, J., & Seymore, K. (2000). Automating construction
Internet portals machine learning. Information Retrieval, 3(2):127163.
Pan, S. J., & Yang, Q. (2010). survey transfer learning. IEEE Transactions Knowledge
Data Engineering, 22(10):13451359.
Ruping, S., & Scheffer, T. (2005). Learning multiple views. Proceedings 2005 ICML
Workshop Learning Multiple Views.
524

fiI NFORMATION -T HEORETIC ULTI - VIEW OMAIN DAPTATION

Salton, G., & Buckley, C. (1988). Term-weighting approaches automatic text retrieval. Information Processing & Management, 24(5):513523.
Sarinnapakorn, K., & Kubat, M. (2007). Combining sub-classifiers text categorization: DSTbased solution case study. IEEE Transactions Knowledge Data Engineering,
19(12):16381651.
Sridharan, K., & Kakade, S. M. (2008). information theoretic framework multi-view learning. Proceedings 21st Annual Conference Learning Theory, Helsinki, Finland,
July 9-12, 2008, pp. 403414.
Yang, P., Gao, W., Tan, Q., & Wong, K. F. (2012). Information-theoretic multi-view domain adaptation. Proceedings 50th Annual Meeting Association Computational Linguistics, July 8-11, 2012, Jeju Island, Korea, pp. 270274.
Zhang, D., He, J. R., Liu, Y., Si, L., & Lawrence, R. D. (2011). Multi-view transfer learning
large margin approach. Proceedings 17th ACM SIGKDD International Conference Knowledge Discovery Data Mining, San Diego, CA, USA, August 21-24, 2011,
pp. 12081216.
Zhang, J. T., & Huan, J. (2012). Inductive multi-task learning multiple view data. Proceedings 18th ACM SIGKDD International Conference Knowledge Discovery Data
Mining, Beijing, China, August 12-16, 2012, pp. 543551.

525

fiJournal Artificial Intelligence Research 49 (2014) 601-633

Submitted 10/13; published 04/14

Algorithms Applications
Same-Decision Probability
Suming Chen
Arthur Choi
Adnan Darwiche

suming@cs.ucla.edu
aychoi@cs.ucla.edu
darwiche@cs.ucla.edu

Computer Science Department
University California, Los Angeles
Los Angeles, CA 90095

Abstract
making decisions uncertainty, optimal choices often difficult
discern, especially enough information gathered. Two key questions
regard relate whether one stop information gathering process commit
decision (stopping criterion), not, information gather next (selection
criterion). paper, show recently introduced notion, Same-Decision
Probability (SDP), useful stopping selection criterion, provide additional insight allow robust decision making variety scenarios.
query shown highly intractable, PPPP -complete, exemplary
class queries correspond computation certain expectations. propose first exact algorithm computing SDP, demonstrate effectiveness
several real synthetic networks. Finally, present new complexity results,
complexity computing SDP models Naive Bayes structure. Additionally,
prove computing non-myopic value information complete
complexity class computing SDP.

1. Introduction
Probabilistic graphical models often used model variety decision problems,
e.g., medical diagnosis (Pauker & Kassirer, 1980; Kahn, Roberts, Shaffer, & Haddawy,
1997; van der Gaag & Coupe, 1999), fault diagnosis (Lu & Przytula, 2006), classification
(Friedman, Geiger, & Goldszmidt, 1997; Ramoni & Sebastiani, 2001; Jordan, 2002), troubleshooting (Heckerman, Breese, & Rommelse, 1995), educational diagnosis (Butz, Hua, &
Maguire, 2004; Arroyo & Woolf, 2005; Millan, Descalco, Castillo, Oliveira, & Diogo, 2013),
intrusion detection (Kruegel, Mutz, Robertson, & Valeur, 2003; Modelo-Howard,
Bagchi, & Lebanon, 2008). similar applications, decision maker typically
position must decide tests perform observations make
order make better informed decision. Perhaps critically, decision maker must
also decide stop making observations commit particular decision.
Same-Decision Probability (SDP) recently proposed Darwiche Choi
(2010), order help quantify robustness decision, context decisionmaking Bayesian networks. short, SDP probability would make
decision, perform observations yet made.
such, SDP treated measure decisions robustness respect
c
2014
AI Access Foundation. rights reserved.

fiChen, Choi & Darwiche

unknown variables, quantifying confidence would make decision, even
made observations.
paper, show apply SDP tool information gathering,
particular, way determine stop information gathering (as stopping criterion), not, pieces information gather next (as selection criterion).
compare SDP classical stopping selection criteria illustrative examples.
instance, demonstrate SDP distinguish stable unstable
decisions indistinguishable classical criteria. Additionally, also show
scenarios classical criteria may call performing observations,
SDP indicates decision unlikely change.
Notably, SDP shown highly intractable, Choi, Xue, Darwiche
(2012), exact computation SDP limited toy examples,
variables, brute-force enumeration. paper, propose first exact
algorithm computing SDP. algorithm applied real-world networks
scope brute-force enumeration previously proposed approximation
algorithms, applied synthetic networks many 100 variables.
provide new complexity results SDP, highlight relative
intractability (even Naive Bayes networks), also relationship broader class
expectation computation problems, emphasizing broader importance developing
effective algorithms SDP related problems.
paper thus structured follows. first introduce notation discuss
common stopping selection criteria Section 2. review previously introduced work SDP Section 3. Section 4, discuss SDP applied
stopping criterion selection criterion. Section 5, present novel
exact algorithm computing SDP discuss experimental results Section 6.
Section 7, present recent complexity results SDP. conclude
paper Section 8.

2. Related Work
making decisions uncertainty, may difficult finalize decision
presence unobserved variables. Given unobserved variables, two fundamental questions. first question whether, given current observations, decision
maker ready commit decision. refer stopping criterion
making decision. Assuming stopping criterion met, second question
additional observations made decision maker ready make decision. typically requires selection criterion based measure quantifying
observations value information (VOI). section, first introduce necessary
notation, review commonly used stopping selection criteria.
2.1 Notation
Throughout paper, use standard notation variables instantiations,
variables denoted upper case letters X instantiations lower case
letters x. Additionally, sets variables denoted bold upper case letters X
instantiations bold lower case letters x. assume state world
602

fiAlgorithms Applications Same-Decision Probability

described random variables X, evidence E X includes known variables,
hidden variables U X include unknown variables. definition, E U =
EU = X. often discuss ramifications observing subset hidden variables
H U decision making. Furthermore, use U denote main hypothesis
variable forms basis decision.1
2.2 Stopping Criterion
Given hidden variables model choice whether
observe subset, stopping criterion determines stop process
information gathering commit decision. Note concerned making
decision based hypothesis variable, state patients health.
stopping criterion, basic approach used variety domains commit
decision belief certain event crosses threshold, done
Pauker Kassirer (1980), Kruegel et al. (2003), Lu Przytula (2006). However,
approach may robust, observations may cause belief
event fall threshold. Van der Gaag Bodlaender (2011) note possibility
pose STOP problem, asks whether present evidence gathered
sufficient diagnosis, exists relevant evidence
gathered.
approaches involve ensuring uncertainty surrounding decision variable
sufficiently reduced. instance, Gao Koller (2011) stop information gathering
1) conditional entropy interest variable reduced beyond threshold 2)
margin first second likely states interest variable
threshold. case, clear threshold-based stopping criteria ubiquitous
decision making uncertainty.
Alternatively, also several stopping criteria involve existence
budget, abstract quantity represent available resources
used information gathering. budget may representative number
observations allowed (Modelo-Howard et al., 2008; Munie & Shoham, 2008; Yu,
Krishnapuram, Rosales, & Rao, 2009; Chen, Low, Tan, Oran, Jaillet, Dolan, & Sukhatme,
2012a), terms monetary amount may spent observations varying
cost (Greiner, Grove, & Roth, 2002; Krause & Guestrin, 2009; Bilgic & Getoor, 2011).
context budget, general stopping criterion continue make observations
budget completely expended, done Modelo-Howard et al. (2008)
Munie Shoham (2008). Krause Guestrin (2009) Bilgic Getoor (2011) note
budget expended caveat value information
observation least cost observation.
2.3 Selection Criterion: Value Information
stopping criterion determine observations necessary, selection
criterion used determine variables selected observation.
Ideally, want observe variables give us additional information regards
1. work presented paper extended case multiple hypothesis variables,
focus case one hypothesis variable simplicity.

603

fiChen, Choi & Darwiche

decision variable. However, due resource constraints (such limited budget)
often possible. basic approach, common selection criterion select
observations minimize conditional entropy decision variable (Vomlel,
2004; Lu & Przytula, 2006; Krause & Guestrin, 2009; Yu et al., 2009; Zhang & Ji, 2010;
Gao & Koller, 2011; Ognibene & Demiris, 2013; Shann & Seuken, 2013). entropy
variable X defined as:
H(X) =

X

Pr (x) log Pr (x)

(1)

x

measure uncertainty variables state entropy variable
high, means much uncertainty value variable takes.2
uncertainty decision variables true state makes difficult make decision. Thus,
natural selection criterion observe variables minimize conditional entropy
decision variable, conditional entropy variable given variable X defined
as:
H(D | X) =

X

H(D | x)Pr (x)

(2)

x

conditional entropy thus expectation entropy would
observing X. similar selection criterion observe variables greatly
increase margin posterior probabilities first second most-likely
states decision variable (Krause & Guestrin, 2009).
selection criteria involve utilizing notion value information (VOI) order
quantify value various observations (Lindley, 1956; Stratonovich, 1965; Howard,
1966; Raiffa, 1968). VOI set variables depend various measures.
two example selection criteria discussed, measures would entropy
margins confidence. instance, observing variable X would reduce conditional
entropy H(D | X) observing variable X would (H(D | X) < H(D | X )),
value observing X would higher.
Krause Guestrin (2009) define general notion VOI based different
reward functions. particular, given arbitrary reward function R,3 hypothesis variable
D, evidence e, VOI observing hidden variables H is:
V(R, D, H, e) = ER(R, D, H, e) R(Pr (D | e))

(3)


ER(R, D, H, e) =

X

R(Pr (D | h, e))Pr (h | e)

(4)

h

expected reward observing variables H R(Pr (D | e)) reward
observed variables H. definition, reward function used Lu
2. information theory, logarithm typically assumed base-2 (Cover & Thomas, 1991),
also assume throughout paper convenience.
3. reward function assumed take input probability distribution hypothesis variable,
Pr (D), return numeric value. discuss reward functions Section 7.2.

604

fiAlgorithms Applications Same-Decision Probability




+


Pr (D | E1 = +, E2 = +)
0.880952
0.119048

X1

X2

E1

E2

H1

H2

Figure 1: simple Bayesian network, sensor readings {E1 = +, E2 = +}. Variables H1
H2 represent health sensors E1 E2 . left posterior
decision variable D. Network CPTs found Appendix C Figure 13.

Przytula (2006) Krause Guestrin (2009) select variables order minimize
conditional entropy R(Pr (D | e)) = H(D | e), maximizing expected
reward observing variables H equivalent minimizing conditional entropy
H(D | H). possible reward functions involve utility-based reward functions
threshold-based reward functions (Munie & Shoham, 2008).4
Note vast majority selection criteria use myopic approach,
possible observations, one observation considered time, observation
highest VOI selected time. approach greedy short-sighted
optimal VOI computed computing non-myopically (Bilgic & Getoor,
2011). discuss usage non-myopic VOI Appendix A.1.

3. Same-Decision Probability
Same-Decision Probability (SDP) initially introduced Darwiche Choi (2010)
confidence measure threshold-based decisions Bayesian networks noisy
sensor readings. Prior formally defining SDP, first show example provide
intuition. Consider Bayesian network Figure 1, models scenario involving
hypothesis variable D, two noisy sensors E1 E2 influence belief
hypothesis d. Networks typically used compute belief hypothesis
given sensor readings, Pr (d | e). basis whether make decision often
depends whether posterior probability hypothesis surpasses
threshold (Hamscher, Console, & de Kleer, 1992; Heckerman et al., 1995; Kruegel
et al., 2003; Lu & Przytula, 2006).
Figure 1 shows particular reading two sensors resulting belief Pr (D = + |
E1 = +, E2 = +). Suppose threshold = 0.6, Pr (d | e) , would make
certain decision. Notice Figure 1 health sensors modeled variables
H1 H2 . sensor either truthful, stuck positive (readings always display +),
lying (readings show opposite value actual value) (Darwiche & Choi, 2010).
variables observed, could informed us trustworthiness
4. reward functions, see list provided Krause Guestrin (2009).

605

fiChen, Choi & Darwiche

H1

p
l

p
l

p
l

H2



p
p
p
l
l
l

Pr (h | e)
0.781071
0.096429
0.001071
0.096429
0.021429
0.001190
0.001071
0.001190
0.000119

Pr (d | h, e)
0.90
0.82
0.10
0.90
0.50
0.10
0.90
0.18
0.10

Table 1: Scenarios h sensor readings e = {E1 = +, E2 = +} network Figure 1,
H = {H1 , H2 }. Cases threshold = 0.6 bold. Note t, p, l
respectively represent truthful, stuck positive, lying sensor.

sensors E1 E2 thus allow us make better decision. want make
more-informed decision based probability Pr (d | h, e) instead making decision
based Pr (d | e).
Consider Table 1, enumerates possible health states sensors.
four cases probability hypothesis pass threshold (in bold),
leading decision. five scenarios, different decision would
made. SDP thus probability four scenarios decision
would made. example, SDP is:
0.781071 + 0.096429 + 0.096429 + 0.001071 = 0.975
indicating relatively robust decision.
Choi et al. (2012) define SDP formally as:
Definition 1 (Same-Decision Probability). Let N Bayesian network conditioned
evidence e, given hypothesis d, threshold , set
unobserved variables H. Suppose making decision confirmed threshold
Pr (d | e) . Same-Decision Probability scenario
X
[Pr (d | e, h) ]Pr (h | e),
(5)
SDP (d, H, e, ) =
h

[Pr (d | h, e) ] indicator function

1 Pr (d | e, h)
[Pr (d | h, e) ] =
0 otherwise.
SDP notably hard compute. Choi et al. (2012) prove computing SDP
general PPPP -complete.5 previous work SDP (Darwiche & Choi, 2010;
Choi et al., 2012), two options computing SDP
5. class PPPP thought counting variant NPPP class, contains polynomial
time hierarchy PH MAP problem complete (Park & Darwiche, 2004).

606

fiAlgorithms Applications Same-Decision Probability


+


Pr (D)
0.5
0.5



S1

S2

S3

S4

Figure 2: Bayesian network intrusion detection, CPTs given Table 2
1. approximate algorithm developed Choi et al. (2012). algorithm uses
augmented variable elimination algorithm produces potentially weak bound
based one-sided Chebyshev inequality.
2. naive brute-force method enumerates possible instantiations.

4. Applying Same-Decision Probability
investigate use SDP stopping criterion selection criterion.
contrast usage SDP traditional methods discussed Section 2, find
using SDP provide insight decision maker scenarios.
4.1 SDP Stopping Criterion
definition SDP, see calculating high SDP, contrast calculating
low SDP, would indicate higher degree readiness make decision, chances
decision changing given evidence gathering lower. section show
computing SDP provide additional insight thus distinguish scenarios
otherwise indistinguishable based standard stopping criteria.
threshold-based decision classical notion decision making uncertainty,
commonly used requires utilities elicited. Examples thresholdbased decisions prevalent educational diagnosis (Gertner, Conati, & VanLehn,
1998; Conati, Gertner, & VanLehn, 2002; Butz et al., 2004; Xenos, 2004; Arroyo & Woolf,
2005; Munie & Shoham, 2008), intrusion detection (Kruegel et al., 2003; Modelo-Howard
et al., 2008), fault diagnosis (Heckerman et al., 1995; Lu & Przytula, 2006), medical
diagnosis (Pauker & Kassirer, 1980; Kahn et al., 1997; van der Gaag & Coupe, 1999).
Consider sensor network Figure 2, may correspond intrusion detection
application discussed Kruegel et al. (2003). Here, hypothesis variable =
{+, } = + implying intrusion. Suppose commit decision, stop
performing observations, belief event = + surpasses threshold ,
say = 0.55. four sensors model, S1 , S2 , S3 S4 , whose readings may
affect decision.
Consider two following scenarios:
1. S1 = + S2 = +.
2. S3 = + S4 = +.
607

fiChen, Choi & Darwiche

S1 Pr (S1 | D)
+ +
0.55
+
0.45
+
0.45
0.55


S3 Pr (S3 | D)
+ +
0.60
+
0.40
+
0.40
0.60


S2 Pr (S2 | D)
+ +
0.55
0.45
+
+
0.45

0.55

S4 Pr (S4 | D)
+ +
0.65
0.35
+
+
0.35

0.65

Table 2: CPTs network Figure 2. Parameterization 1.
Since Pr (D = + | S1 = +, S2 = +) = 0.60 > 0.55 Pr (D = + | S3 = +, S4 = +) =
0.74 > 0.55, clear cases threshold crossed. deem
observations necessary based beliefs surpassing threshold.
Hence, using thresholds stopping criterion (as commonly done, see Kruegel
et al., 2003; Lu & Przytula, 2006; Gao & Koller, 2011), two scenarios identical
information gathered decision made.
viewpoint SDP, however, two scenarios different. particular, first scenario leads SDP 52.97%. means 47.03% chance
different decision would made observe two unobserved
sensors S3 S4 . second scenario, however, leads SDP 100%. is,
would certainty know would make decision also observe
two unobserved sensors S1 S2 : matter readings S1 S2 could be,
beliefs event = + would always surpass threshold 0.55. Indeed,
see Table 2, sensors S1 S2 strong sensors S3 S4 ,
example, strong enough reverse decision.
example provides clear illustration utility SDP stopping criterion.
However, may argue clear second case, stop gathering
information Pr (D = + | S3 = +, S4 = +) = 0.74 larger margin threshold
Pr (D = + | S1 = +, S2 = +) = 0.60.6 However, show following example
deciding stop based solely margin robust. Consider
sensor network Figure 2 parameterizations sensor network shown Table 5
Table 6 (found Appendix C), respectively refer Case 1 Case 2.7
Note example, use threshold = 0.5.
cases, S3 = + S4 = + observed, Pr (D = + | S3 = +, S4 = +) .
particular,
1. Case 1: Pr (D = + | S3 = +, S4 = +) = 0.775.
6. Thus using aforementioned margins confidence stopping criterion used Gao Koller (2011).
7. Note exact numbers CPTs necessary grasp examples CPTs
provided readers may reconstruct networks.

608

fiAlgorithms Applications Same-Decision Probability

2. Case 2: Pr (D = + | S3 = +, S4 = +) = 0.599.
using previously discussed margin stopping criterion, would seem Case
1 could stop information gathering, whereas Case 2 information gathering
necessary. However, compute SDP cases insights
nature robustness settings. Case 1, find SDP 0.781, whereas
Case 2, find SDP 1.0 even though Case 1 margin higher,
greater chance decision would change given information.
demonstrates cannot use solely margin determine whether stop
information gathering.
clear examples SDP useful stopping criterion. First, SDP
pinpoint situations observations unnecessary would never
reverse decision consideration. Second, SDP also identify situations
decision made robust, likely change upon making
observations. addition examples, Appendix A.2 show SDP
useful stopping criterion context utility-based decisions (e.g. influence diagrams).
4.2 SDP Selection Criterion
turn attention use SDP criterion deciding variables
observe next, assuming stopping criterion indicates observations
necessary. proposal based using VOI selection criterion (see Equation 3),
choosing SDP reward function. call SDP gain, formally
defined as:
Definition 2. Given Definition 4 SDP, SDP gain observing variables G
variables H defined expected SDP observing G H subtracted SDP
H:
G(G) = E(G, H, e, ) SDP (d, H, e, ),
(6)
expected SDP defined as:
E(G, H, e, ) =

X

SDP (d, H \ G, ge, )Pr (g|e)

(7)

g

defined decision made given current evidence.
Note observe variables G H expected SDP 1.0,
indicates observing G making decision, remaining variables H \ G
rendered completely redundant observation effect decision.
goal using SDP gain selection criterion observe variables which,
average, allow stable decision given collected observations.
next provide example using SDP selection criterion, contrasting
two selection criteria: One based reducing entropy hypothesis variable
D, another based maximizing gap decision probability Pr (d|e)
given threshold (Krause & Guestrin, 2009). criteria motivated
reducing uncertainty, show indeed lead less stable decisions
SDP used.
609

fiChen, Choi & Darwiche




+


Pr (D)
0.5
0.5
S1

S2

Figure 3: Bayesian network CPTs given Appendix C.

example given Bayesian network Figure 3, hypothesis
variable S1 /S2 sensors. decision triggered Pr (D = + | e) .80,
evidence e sensors S1 S2 . observations (empty evidence e), SDP
0.595, suggesting observations may needed. Assuming limited number
observations (Heckerman et al., 1995), using myopic approach observing one
variable time (Dittmer & Jensen, 1997), need select next variable
observe.
Note maximizing VOI negative entropy reward function amounts
maximizing mutual information, H(D, X) = H(D) H(D | X) (Cover & Thomas, 1991;
Krause & Guestrin, 2005). mutual information variable sensor S2
0.53 whereas mutual information sensor S1 0.278. Hence, observing
S2 reduce entropy most. terms margin confidence, another reward
function used Krause Guestrin (2009), observing S2 average lead 0.7
margin states = + = , whereas observing S1 lead 0.6
margin two states.
However, compute corresponding SDP gains, G(S1 ) G(S2 ), find
observing S1 will, average, lead improving decision stability most. particular, observing S1 would give us SDP either 1 0.81 expected SDP
0.905, whereas observing S2 would give us SDP either 0.7625, 0.5, 1
expected SDP 0.805. Therefore, G(S1 ) = 0.31 G(S2 ) = 0.21. Hence, observing S1
average allow us make decision less likely change due additional
information (beyond S1 ).
intuition occurs although observing S2 leads greater information gain observing S1 , superfluous information. Note Pr (D = + | S2 = ) =
0.0625, whereas Pr (D = + | S1 = ) = 0.2. Clearly, see observing S2 lead
skewed distribution minimal conditional entropy. However, context
threshold-based decisions, make decision based solely whether Pr (D = + | e)
threshold, meaning may put much emphasis much
threshold Pr (D = + | e) is. case, although observing S2
average lead extreme distribution, observing S2 = leads making extremely
nonrobust decision (a decision would change 50% time observation S1 ).
Observing S1 making decision leads much robust decision. example
demonstrates usefulness SDP selection criterion threshold-based decisions,
SDP used select observations lead robust decisions.
610

fiAlgorithms Applications Same-Decision Probability


+


Pr (D)
0.3
0.7



E1

H1

H3

H2

Figure 4: Naive Bayes network (CPTs defined Appendix C).

5. Computing Same-Decision Probability
Computing SDP involves computing expectation hidden variables H.
naive brute-force algorithm would enumerate check whether Pr (d | h, e)
instantiations h H. present algorithm save us need explore
every possible instantiation h. make algorithm easier understand, first
describe compute SDP Naive Bayes network. trivial problem
show Section 7 computing SDP Naive Bayes network NP-hard.
generalize algorithm arbitrary networks.
5.1 Computing SDP Naive Bayes Networks
find convenient implement test Pr (d | h, e) log-odds
domain, where:
log O(d | h, e) = log

Pr (d | h, e)
Pr (d | h, e)

(8)


define log-odds threshold = log 1T
and, equivalently, test whether
log O(d | h, e) .
Naive Bayes network class variable, H E leaf variables,
Q H, posterior log-odds observing partial instantiation q = {h1 , . . . , hj }
written as:

log O(d | q, e) = log O(d | e) +

j
X

w hi

(9)

i=1

whi weight evidence hi defined as:
whi = log

Pr (hi | d, e)
Pr (hi | d, e)

(10)

weight evidence whi contribution evidence hi quantity
log O(d | q, e) (Chan & Darwiche, 2003). Note weights computed time
space linear |H| using floating point representation.8 Table 3 depicts weights
evidence network Figure 4.
8. Additionally, note Equation 10, since Naive Bayes networks Hi d-separated E given
d, term e dropped equation. leave term general networks, Hi
may d-separated E.

611

fiChen, Choi & Darwiche


1
2
3

w hi
3.0
1.22
1.22

w hi
-2.17
-1.22
-1.22

Table 3: Weights evidence attributes Figure 4.
H1
0.0
H2
3.0

H2
-2.17

H3
4.22
5.44

H3
1.78
3.0

3.0

H3
0.95
0.56

0.27

2.17

H3
3.39
2.17

4.61

Figure 5: search tree network Figure 4. solid line indicates + dashed
line indicates . quantity log O(d | q, e) displayed next node q
tree. Nodes log O(d | q, e) = 0 shown bold.

One compute SDP enumerating instantiations variables H
using Equation 9 test whether log O(d | h, e) . Figure 5 depicts search tree
Naive Bayes network Figure 4, used purpose. leaves
tree correspond instantiations h variables H. generally, every node
tree corresponds instantiation q, Q H.
brute-force computation SDP would entail:
1. Initializing total SDP 0.
2. Visiting every leaf node h search tree.
3. Checking whether log O(d | h, e) so, adding Pr (h | e) total SDP.
Figure 5 depicts quantity log O(d | q, e) node q tree, indicating five
leaf nodes (i.e., five instantiations variables H) indeed contribute SDP.
state key observation underlying proposed algorithm. Consider node
corresponding instantiation H1 = + search tree, log O(d | H1 = +, e) = 3.0.
four completions h instantiation (i.e., four leaf nodes it)
log O(d | h, e) = 0. Hence, really need visit leaves add
contributions Pr (h|e) individually SDP. Instead, simply add Pr (H1 = +|e)
SDP, equals sum Pr (h|e) leaves. importantly,
detect leaves contribute SDP computing lower bound using
weights depicted Table 3. is, two weights variable H2 , minimum
1.22. Moreover, two weights variable H3 , minimum
1.22. Hence, lowest contribution log-odds made leaf node H1 = +
612

fiAlgorithms Applications Same-Decision Probability

H1
0.0
3.0

H2
-2.17
H3
0.95
0.27

3.39

2.17

Figure 6: reduced search tree network Figure 5.
1.22 1.22 = 2.44. Adding contribution current log-odds 3.0
lead log-odds .56, still passes given threshold.
similar technique used compute upper bounds, allowing us detect nodes
search tree leaf contribute SDP. Consider example
node corresponding instantiation H1 = , H2 = , log O(d | H1 = , H2 =
, e) = 3.39. Neither leaves node contribute SDP
log-odds pass threshold. detected considering weights
evidence variable H3 computing maximum weights (1.22). Adding
current log-odds 3.39 gives 2.17, still threshold. Hence,
leaf node H1 = , H2 = contribute SDP part search tree
also pruned.
apply pruning technique based lower upper bounds, actually
end exploring portion tree shown Figure 6. pseudocode
final algorithm shown Algorithm 1. Note takes linear time compute
upper lower bounds. Additionally, note specific ordering H
search tree constructed directly linked amount pruning. use ordering
heuristic ranks query variable Hi difference corresponding upper
lower bound H ordered greatest difference lowest difference allow
earlier pruning.
5.2 Computing SDP Arbitrary Networks
generalize algorithm arbitrary networks viewing networks Naive
Bayes networks aggregate attributes. this, first need following notion.
Definition 3. partition H given E set S1 , . . . , Sk that: Si H;
Si Sj = ; S1 . . . Sk = H; Si independent (d-separated) Sj , 6= j, given
E.
Figure 7 depicts example partition.
intuition behind partition allows us view arbitrary network
Naive Bayes network, class variable aggregate attributes S1 , . . . , Sk . is,
aggregate attribute Si viewed variable states si , allowing us view
instantiation h set values s1 , . . . , sk . have:

613

fiChen, Choi & Darwiche

Algorithm 1 Computing SDP Naive Bayes network. Note: q = {h1 , . . . , hj },
P
wq defined ji=1 whi .

input:
N : Naive Bayes network class variable
H: attributes {H1 , . . . , Hk }
: log-odds threshold
e: evidence
output: Same-Decision Probability p

main:
global p 0.0 (initial probability)
q {} (initial instantiation empty set)
depth 0 (initial depth search tree)
DFS SDP(q, H, depth)
return p
1: procedure DFS SDP(q, H, depth)
P
2:
U pperBound log O(d | e) + wq + ki=depth+1 maxhi whi
P
3:
LowerBound log O(d | e) + wq + ki=depth+1 minhi whi
4:
(U pperBound < ) return
5:
else (LowerBound )
6:
add Pr (q | e) p, return
7:
else
8:
depth < k
9:
value hdepth+1 attribute Hdepth+1
10:
DFS SDP(qhdepth+1 , H \ Hdepth+1 , depth + 1)
Proposition 1. partial instantiation q = {s1 , . . . , sj },
log O(d | q, e) = log O(d | e) +

j
X

w si ,

(11)

i=1


wsi = log

Pr (si , | d, e)
Pr (si | d, e)

Proof.
Pr (d | q, e)
Pr (d | q, e)
Pr (d | e)Pr (s1 | d, e) . . . Pr (sj | d, e)
= log
Pr (d | e)Pr (s1 | d, e) . . . Pr (sj | d, e)

log O(d | q, e) = log

= log O(d | e) +

j
X
i=1

614

w si

(12)

fiAlgorithms Applications Same-Decision Probability

E1

X1

H1

H4



X2

H3

H5

E2

X3

H6

H2

Figure 7: partition H given E is: S1 = {H1 , H2 , H3 } S2 = {H4 }, S3 =
{H5 , H6 }.

Since Equations 11 12 analogous Equations 9 10, use Algorithm 1 arbitrary network. usage, however, requires auxiliary computations
needed readily available Naive Bayes networks. discuss
computations next.
5.2.1 Finding Partition
first need compute partition S1 , . . . , Sk , done pruning network
structure follows: delete edges outgoing nodes evidence E hypothesis D,
delete (successively) leaf nodes neither H, E D. identify
components X1 , . . . , Xk resulting network define non-empty Si = H Xi
element partition. guarantees original network structure, Si
d-separated Sj E 6= j (see (Darwiche, 2009)). Figure 7, network
pruning leads components X1 = {X1 , X2 , E2 , H1 , H2 , H3 }, X2 = {D, E1 , H4 }
X3 = {X3 , H5 , H6 }.
5.2.2 Computing Posterior Log-Odds, Probability Weights Evidence
quantities O(d | e), Pr (q | e) wsi , referenced Lines 2, 3, 6
algorithm, simple closed forms Naive Bayes networks. arbitrary networks,
however, computing quantities requires inference using algorithm
variable elimination described Darwiche (2009). Note network pruning
deleting edges removing leaf nodes, discussed above, guarantees
factor used variable elimination variables component Xi . Hence,
variable elimination applied component Xi isolation, sufficient
obtain needed quantities.
615

fiChen, Choi & Darwiche

5.2.3 Computing Min Max Evidence Weights
finally show compute upper lower bounds, maxsi wsi minsi wsi ,
referenced Lines 2 3 algorithm. quantities also
computed using variable elimination, applied component Xi isolation.
case, however, must eliminate variables Xi \ Si first variables Si . Moreover,
first set variables summed-out, second set variables maxd-out
mind-out, depending whether need maxsi wsi minsi wsi . Finally, elimination
process applied twice, evidence d, e second time evidence d, e.
precisely, every component Xi set factors case =
= d. Using variable ordering, perform variable elimination
sets factors eliminate

left
Q iany nonquery (intermediary) variables
Q



set factors = Pr (Si , d, e), set factors = Pr (Si , d, e).
Since elimination order same, thus one-to-one matching

Pr (ei ,S )
factors sets, define new set factors = id = Pr id (ei ,Si ) .






calculate wsi wsi respectively maximizing minimizing variables.
Note summing variables maximizing variables variable elimination
algorithm used Dechter (1999) order solve MAP. algorithm differs
perform maximization minimization (to calculate wsi wsi ),
set factors instead factors (di di ) result simply summing
intermediary variables.
Note similarly Dechter (1999), first summing variables
performing maximization (and minimization case), elimination order
case constrained, meaning may forced use poor ordering variable
elimination results high treewidth.
5.3 Complexity Analysis
Let n number variables network, h = |H|, w = maxi wi ,
wi width constrained elimination order used
component Xi . best-case

time complexityof algorithm n exp w worst-case time complexity
n exp (w + h) . intuition behind bounds computing
maximum
minimum weights aggregate attribute takes time n exp w . also bounds
complexity computing O(d|e), Pr (q|e) corresponding weights wsi . Moreover,
depending weights
threshold , traversing search tree take anywhere
constant time exp h . Since depth-first
search implemented linear

space, space complexity n exp w .

6. Experimental Results
performed several experiments real synthetic networks test performance algorithm across wide variety network structures, ranging simple
Naive Bayes networks highly connected networks. Real networks either learned
datasets provided UCI Machine Learning Repository (Bache & Lichman, 2013)
616

fiAlgorithms Applications Same-Decision Probability

Network
car
emdec6g
tcc4e
ttt
caa
voting
nav
fire
chess

source
UCI
HRL
HRL
UCI
CRESST
UCI
CRESST
CRESST
UCI

|H|
|h|
6
144
8
256
9
512
9
19683
14
16384
16
65536
20 1572864
24 16777216
30 1610612736

naive
0.131
0.407
0.470
6.234
6.801
21.35
642.88



approx
0.118
0.245
0.257
0.133
0.145
0.176
0.856
0.183
*

new
0.049
0.294
0.149
0.091
0.167
0.128
0.178
0.508
15.53

Table 4: Algorithm comparison real networks. show time, seconds, takes
algorithm, naive, approx, new compute SDP different networks.
Note indicates computation complete 20 minute
time limit constrained. Moreover, * indicates sufficient
memory complete computation.

provided HRL Laboratories CRESST.9 majority real networks used
diagnostic networks, made clear variable selected decision
variable would either knowledge fault variable. unclear cases,
decision variable picked random. query evidence variables selected
random real networks.
Besides algorithm, two options available compute SDP: 1.
naive method brute-force computation enumerating possible instantiations
2. approximate algorithm developed Choi et al. (2012). compare algorithm
two approaches, compute SDP real networks.
network selected least 80% total network variables query variables
could emphasize size query set greatly influences computation
time. computation given 20 minutes complete. believe value
threshold greatly affect running time, computed SDP thresholds =
[0.01, 0.1, 0.2, . . . , 0.8, 0.9, 0.99] took worst-case time. results experiments
three algorithms shown Table 4. Note |H| number query
variables |h| number instantiations naive algorithm must enumerate over.
Moreover, indicates computation complete 20 minute time limit
* indicates sufficient memory complete computation. networks
{car,ttt,voting,nav,chess} Naive Bayes networks whereas networks {caa,fire}
polytree networks others general networks.
Given real networks tested algorithm on, clear algorithm
outperforms naive implementation approximate algorithm Naive
Bayes networks polytree networks. Note approximation algorithm based
variable elimination use certain constrained orders. Naive Bayes
9. http://www.cse.ucla.edu/

617

fiChen, Choi & Darwiche

4000
3500

Average Explored Instantiations Running Time
Number instantiations (x 10e3)

3000
2500
2000
1500
1000
500
01

Time (s)
2

3

4
5
Number subnetworks

6

7

8

Figure 8: Synthetic network average running time average number instantiations
explored number connected components.

network hypothesis root, approximation algorithm forced
use particularly poor ordering, explains failure chess network.
analyze general network structure selected threshold affects
performance algorithm, generated synthetic networks 100 variables
varying treewidth using BNGenerator (Ide, Cozman, & Ramos, 2004). network,
randomly selected decision variable, 25 query variables, evidence variables.10
generated partition network grouped networks size obtained
partition (k). goal test algorithms running time ability prune
search-space depends k. average time average number instantiations
explored shown Figure 8.
general, see k increases, number instantiations explored
algorithm decreases runtime improves. network becomes similar
Naive Bayes structure increasing k. Moreover, larger k is, levels
search tree, means algorithm opportunities prune.
worst case, network may unable disconnected (k = 1). However, even
case algorithm still, average, efficient compared brute-force
implementation cases, computing maximum minimum weight
observing H, find exist h change decision.
found that, given time limit 2 hours, brute-force algorithm could solve
synthetic networks, whereas approach solved 70% networks.
also test threshold affects computation time. Here, calculate posterior
probability decision variable run repeatedly algorithm thresholds
varying increments away. average running time increments seen
Figure 9. evident threshold set away initial
10. synthetic networks binary, brute-force approach would need explore 225 instantiations.

618

fiAlgorithms Applications Same-Decision Probability

1800
1600

Average Explored Instantiations Running Time
Number instantiations (x 10e3)

1400
1200
1000
800
600
400
200
00.0

Time (s)
0.1

0.2
0.3
0.4
0.5
Threshold distance initial posterior

0.6

Figure 9: Synthetic network average running time average number instantiations
explored threshold distance initial posterior probability.

posterior probability, algorithm finishes much faster, perhaps expected since
usage extreme thresholds would allow search space pruning.
Overall, experimental results show algorithm able solve many SDP
problems reach existing methods. also confirm algorithm
completes much faster network disconnected threshold far
away initial posterior probability decision variable.

7. Complexity Computing Same-Decision Probability
present new complexity results SDP. first prove complexity
computing SDP Naive Bayes structures NP-hard. show general
complexity computing SDP lies complexity class general expectation
computation problem applicable wide variety queries graphical models,
computation non-myopic value information.
7.1 Computing SDP Naive Bayes
SDP known PPPP -complete (Choi et al., 2012). show SDP remains
hard Naive Bayes networks.
Theorem 1. Computing Same-Decision Probability Naive Bayes network NPhard.
Proof. reduce number partition problem defined Karp (1972) computing
SDP Naive Bayes model. Suppose given set positive P
integers c1P
, . . . , cn ,
wish determine whether exists {1, . . . , n} jI ci = j6I cj .
solve considering Naive Bayes network binary class variable
uniform probability, binary attributes H1 , . . . , Hn CPTs leading weights
619

fiChen, Choi & Darwiche

evidence wHi =T = ci wHi =F = ci . construction CPTs done
solving following system equations:
Pr (Hi = | = )
Pr (Hi = | = F )
Pr (Hi = F | = )
ci = log
Pr (Hi = F | = F )
1 = Pr (Hi = | = ) + Pr (Hi = F | = )
ci = log

1 = Pr (Hi = | = F ) + Pr (Hi = F | = F )

leave exact derivations (see Exercise 3.27 Darwiche, 2009). get
result that:
Pr (Hi = | = F ) = Pr (Hi = F | = ) =

2ci

1
+1

Pr (Hi = | = ) = Pr (Hi = F | = F ) = 1

2ci

1
+1

Note given CPTs defined wHi =T = ci wHi =F =
ci , set integers partitioned instantiation h = {h1 , . . . , hn }
P
n
i=1 whi = 0 since would include indices hi = case.
First,
PnThe Naive Bayes network satisfies number properties shall use
Pnext.
n
whi either 0, 1, 1 since weights whi integers. Next, i=1 whi = c,
i=1P
ni=1 whi = c hi 6= hi . Finally, Pr (h1 , . . . , hn ) = Pr (h1 , . . . , hn ) hi 6= hi ,
uniform probability distribution leaf Hi defined
symmetric CPT.
Consider following SDP (the last step based properties):
SDP (D = T, {H1 , . . . , Hn }, {}, 2/3)
X
[Pr (D = | h1 , . . . , hn ) 2/3]Pr (h1 , . . . , hn )
=
h1 ,...,hn

=

X

[log O(D = | h1 , . . . , hn ) 1]Pr (h1 , . . . , hn )

h1 ,...,hn

=

X

h1 ,...,hn

"

1 X
=
2

n
X

h1 ,...,hn



Pn

i=1 whi

#

whi 1 Pr (h1 , . . . , hn )

i=1

"

n
X

#

whi 6= 0 Pr (h1 , . . . , hn )

i=1

= 0 instantiation h1 , . . . , hn iff
" n
#
X X
whi 6= 0 Pr (h1 , . . . , hn ) < 1
h1 ,...,hn

i=1

620

fiAlgorithms Applications Same-Decision Probability

Hence, partitioning problem solved iff
SDP (D = T, {H1 , . . . , Hn }, {}, 2/3) < 1/2

7.2 Complexity Computing Non-myopic VOI
SDP shown PPPP -complete problem Choi et al. (2012). class PPPP
essentially counting variant NPPP class, contains polynomial hierarchy
PH MAP problem complete (Park & Darwiche, 2004). show
section general problem computing expectations also PPPP -complete,
non-myopic VOI SDP instance expectation. Thus, development
algorithms compute SDP beneficial problems PPPP class,
turn benefits computing assortment expectations, including non-myopic VOI.
proposed expectation computation based using reward function R
properties review next. particular, function R assumed map
probability distribution Pr (D | e) numeric value. also assume minimum
l maximum u range polytime computable. assumptions
limitingfor example, entropy utility expressed using reward functions
fall category (Krause & Guestrin, 2009).
consider following computation expectations.
D-EPT: Given polynomial-time computable reward function R, hypothesis variable
D, unobserved variables H, evidence e, real number N , distribution Pr induced
Bayesian network variables X,11 expectation decision problem asks:
E=

X

R(Pr (D | h, e))Pr (h | e)

h

greater N ?
Note SDP falls special case reward function R SDP indicator
function (see Definition 4). example, definition used Choi et al. (2012),
decision function outputs one two decisions depending whether Pr (d|e) >
value threshold .
following theorems, proofs Appendix B.
Theorem 2. D-EPT PPPP -hard.
Theorem 3. D-EPT PPPP .
shows D-EPT PPPP -complete implies computational problems
computing non-myopic VOI using variety reward functions also PPPP complete.
11. proof also holds influence diagrams constrained one decision node.

621

fiChen, Choi & Darwiche

8. Conclusion
paper, discussed commonly used information gathering criteria
graphical models value information reviewed recently introduced
notion Same-Decision Probability (SDP). paper, proposed usage
SDP decision making tool showing concrete examples usefulness
stopping criterion selection criterion. stopping criterion, SDP allow
us determine observations necessary. selection criterion, usage
SDP allow us select observations allow us increase decision robustness.
justified usage SDP, proposed exact algorithm
computation. Experimental results show algorithm comparable running time
previous approximate algorithm also much faster naive brute-force
algorithm. Finally, presented several new complexity results.

Acknowledgements
paper combines extends work presented Chen, Choi, Darwiche (2012b,
2013). work partially supported ONR grant #N00014-12-1-0423, NSF
grant #IIS-1118122, NSF grant #IIS-0916161. would also like thank National
Center Research Evaluation, Standards, & Student Testing Hughes Research Lab
contributing sample diagnostic networks.

Appendix A. Miscellaneous Topics
section go details notions mentioned earlier
paper. particular, continue discussion Section 2.3 go notion
non-myopic value information. Additionally, also continue left
Section 4.1 expand upon notion SDP stopping criterion context
utility-based decisions.
Appendix A.1 Non-myopic Value Information
Myopic value information often used many applications easy compute
(Dittmer & Jensen, 1997; Vomlel, 2004; Gao & Koller, 2011). However, problem
myopic selection optimal, times whole greater sum
parts, individual observation set H seemingly may provide significant
value, VOI observing H high. instance, take function
= X1 X2 , alone neither X1 X2 useful, together determinative
(Bilgic & Getoor, 2011). computing non-myopic VOI optimal
VOI obtained.
Due aforementioned problems using myopic VOI, recently, researchers
recently suggested using non-myopic VOI instead myopic VOI proposed various methods compute non-myopic VOI (Heckerman, Horvitz, & Middleton,
1993; Liao & Ji, 2008; Krause & Guestrin, 2009; Zhang & Ji, 2010; Bilgic & Getoor, 2011).
Computing non-myopic VOI hidden variables H difficult involves com622

fiAlgorithms Applications Same-Decision Probability

puting expectation possible values H, quickly becomes intractable
H becomes larger.
Existing algorithms computing non-myopic VOI approximate algorithms
(Heckerman et al., 1993; Liao & Ji, 2008) relatively limited algorithms restricted
tree networks leaf variables (Krause & Guestrin, 2009). Bilgic Getoor
(2011) developed Value Information Lattice (VOILA), framework
subsets hidden variables H examined, optimal subset features
found increase classification accuracy meeting budget constraint.
Appendix A.2 SDP Stopping Criterion Utility-based Decisions
cases expected utility different decisions, well cost reducing
uncertainty (making observations), quantified. common decision-theoretic
setting (Howard, 1966; Howard & Matheson, 1984), influence diagrams commonly
used. Influence diagrams seen Bayesian networks incorporate decision
utility nodes (Howard & Matheson, 1984; Zhang, 1998; Kjrulff & Madsen, 2008).
selection criterion decision-theoretic setting clear: observations lead
greatest increase expected utility selected. usage utilities observation
costs prevalent; however, numerous researchers noted difficulty coming
actual numerical quantities (Glasziou & Hilden, 1989; Lu & Przytula, 2006;
Bilgic & Getoor, 2011).
show SDP used stopping criterion decision-theoretic context expected-utility decisions influence diagrams (Howard & Matheson, 1984),
extend definition SDP general setting allow applications.
particular, assume F polytime computable decision function outputs
decision based distribution Pr (D | e). instance, decision function
commonly used classification select class highest posterior probability arg maxd Pr (d | e) (Friedman et al., 1997), whereas threshold-based decisions,
decision function would simply select decision Pr (D = | e) .
SDP thus defined probability decision would made
hidden states variables H known (Chen et al., 2012b).
Definition 4 (Same-Decision Probability Generalized ). Given decision function F,
hypothesis variable D, unobserved variables H, evidence e, Same-Decision Probability (SDP) defined
X
[F(Pr (D | h, e))]h Pr (h | e)
(13)
SDP (F, D, H, e) =
h

[F(Pr (D | h, e))]h indicator function

1 F(Pr (D | h, e)) = F(Pr (D | e))
=
0 otherwise.
original SDP definition, however, assumed binary variable,
F(Pr (D | e)) = Pr (d | e) threshold (Darwiche & Choi, 2010).
consider use SDP stopping criterion context expectedutility decisions influence diagrams (Howard & Matheson, 1984). particular,
623

fiChen, Choi & Darwiche

Q

C




P

Figure 10: influence diagram investment problem.
show using SDP, distinguish high-risk, high-reward scenarios lowrisk, low-reward scenarios otherwise indistinguishable consider usage
VOI/utilities alone.
Consider influence diagram Figure 10, consists Bayesian network
three variables (C, Q S), decision node I, utility node P direct
function utility function u. influence diagram models investment problem
venture capital firm deciding whether invest amount $5 million
tech startup (I = ) allowing money collect interest bank (I = F ).
example, profit investment (P ) depends decision (I) success
company (S), turn depends two factors: (1) whether existing competitor
companies successful (C) (2) whether co-founders startup high
quality, original idea (Q). C Q unobserved initially independent
other. Variable latent hypothesis variable case thus cannot observed.
Variables C Q, however, observed price.
goal choose decision = maximum expected utility:
X
EU (i | e) =
Pr (s | e)u(i, s),


u(i, s) utility decision = given evidence e variables C Q.
Figures 11 12 contain two different parameterizations influence diagram
Figure 10. refer different scenarios investment problem.
scenarios, given evidence variables C Q, best decision = F ,
expected utility $500K. decision maker may commit decision decide
observe variables C Q, hope finding better decision light
additional information. classical stopping criterion compute maximum
expected utility given observe variables C Q (Heckerman et al., 1993; Dittmer
& Jensen, 1997):
X
max
EU (i | c, q)Pr (c, q).


c,q

scenarios, maximum expected utility comes $1, 180K, showing
observations may lead better decision.12
12. According formulation Krause Guestrin (2009), computed VOI variables
C Q using reward function.

624

fiAlgorithms Applications Same-Decision Probability

Q

F

Pr (Q)
0.4
0.6

C

F

Pr (C)
0.6
0.4

Q


F
F

Pr (S = | .)
0.60
0.90
0.20
0.30

C

F

F



F
F



F

F

u(I, S)
$5 106
$5 106
$5 105
$5 105

Figure 11: parameterization influence diagram Figure 10.

Q

F

Pr (Q)
0.1
0.9

C

F

Pr (C)
0.9
0.1

Q


F
F

Pr (S = | .)
0.05
0.98
0.01
0.05

C

F

F



F
F



F

F

u(I, S)
$7 107
$5 106
$5 105
$5 105

Figure 12: parameterization influence diagram Figure 10.
point, two scenarios indistinguishable viewpoint
classical decision making tools. Remember Krause Guestrin (2009) Bilgic
Getoor (2011) remark budget observations expended long
value information observation greater cost observation. According
selection criteria, variables thus observed, expected
financial gain could well increase.
SDP, however, finds two scenarios different. particular,
respect variables C Q, SDP 60% first scenario 99% second
scenario. is, even though stand make better decision scenarios upon
observing variables C Q (at least respect financial gain), even though
expected benefit observations scenarios, unlikely
would change current decision = F second scenario comparison
first. Hence, given additional information provided SDP, decision maker may
act quite differently two scenarios. Indeed, take closer look second
scenario, state world (when = ) deciding invest would yield
large financial gain. However, chance state manifesting extremely
625

fiChen, Choi & Darwiche

small (analogous lottery), meaning risk-conscious decision maker may
averse gamble second scenario even waste resources observe variables
C D. Note example assumed utility incorporate
risk-factor, rational decision maker would always choose gather
information despite low probability changing current decision.
illustrates usefulness SDP stopping criterion context expectedutility decisions influence diagrams. Namely, using SDP, distinguish
two different scenarios, otherwise indistinguishable consider utilities
alone.

Appendix B. Proofs
section provide proofs Theorems 2 3.
Proof Theorem 2. show D-EPT PPPP -hard reduction following decision problem D-SDP, corresponds originally proposed notion same-decision
probability threshold-based decisions (Darwiche & Choi, 2010).
D-SDP: Given decision based probability Pr (d | e) surpassing threshold , set
unobserved variables H, probability p, same-decision probability:
X
[Pr (d | h, e) ]Pr (h | e)
(14)
h

greater p?
Here, [.] denotes indicator function evaluates 1 enclosed expression
satisfied, 0 otherwise. D-SDP shown PPPP -complete Choi et al. (2012).
same-decision probability corresponds expectation respect distribution Pr (H | e), using reward function:

1 Pr (d | h, e)
R(Pr (D | h, e)) =
0 otherwise.
Thus same-decision probability iff expectation .
Proof Theorem 3. show D-EPT PPPP , provide probabilistic polynomialtime algorithm, access PP oracle, answers decision problem D-EPT
correctly probability greater 21 . proof generalizes simplifies proof
given Choi et al. (2012) D-SDP.
Consider following probabilistic algorithm determines E > N :
1. Sample complete instantiation x Bayesian network, probability Pr (x).
linear time, using forward sampling (Henrion, 1986).
2. x compatible e, use PP-oracle compute = R(Pr (D | h, e)).
First, reward function R computed polynomial time, definition.
Second, Pr (D | h, e) computed using PP-oracle, since inference #Pcomplete (Roth, 1996), since PPP = P#P .
626

fiAlgorithms Applications Same-Decision Probability

3. Define function a(t) = 12 + 21 tN
ul , defines probability used probabilistic
algorithm guess whether E > N (see Lemma 1).
4. Declare E > N probability:
a(t) x compatible e;


1
2

x compatible e.

probability declaring E > N is:
r=

X
h

greater

1
2

1
a(t)Pr (h, e) + (1 Pr (e))
2

(15)

iff following set equivalent statements hold:
X

a(t)Pr (h, e) >

h

X

a(t)Pr (h | e) >

h

1
2


1
1tN
Pr (h | e) >
+
2 2 ul
2


X 1tN
Pr (h | e) > 0
2 ul
h
X
(t N )Pr (h | e) > 0

X 1
h

Pr (e)
2

h

X

R(Pr (D | h, e))Pr (h | e) > N.

h

Thus r >

1
2

iff E > N .

Lemma 1. function a(t) =

1
2

+

1 tN
2 ul

maps reward probability [0, 1].

Proof. Values u l given, denote upper lower bounds reward t,
also threshold N . Thus tN
ul [1, 1].
Note a(t) denotes probability used algorithm declare whether E > N ,
higher lower depending value reward = R(Pr (D | h, e)).

Appendix C. Conditional Probability Tables
section provide conditional probability tables networks Figures 1, 2, 3,
4.

627

fiChen, Choi & Darwiche


+


Pr (D)
0.5
0.5

Hi


p
p
n
n
l
l


+
+



Xi
+

+

+

+


X1
+

+


Ei
+
+
+
+
+
+
+
+

Pr (X1 | D)
0.9
0.1
0.1
0.9

X1
+
+



Pr (Ei | Hi , Xi )
1.0
0.0
1.0
1.0
0.0
0.0
0.0
1.0

Hi

p
n
l

X2
+

+


Pr (X2 | X1 )
0.9
0.1
0.1
0.9

Pr (Hi )
0.81
0.09
0.09
0.01

Figure 13: CPTs Bayesian network given Figure 1. Note
CPTs variables Ei , lines case Ei = + given, since
Pr (Ei = |Hi , Xi ) = 1 Pr (Ei = +|Hi , Xi ).

S1 Pr (S1 | D)
+ +
0.65
+
0.35
0.30
+

0.70

S3 Pr (S3 | D)
+ +
0.65
+
0.35
0.35
+

0.65

S2 Pr (S2 | D)
+ +
0.60
+
0.40
+
0.30

0.70

S4 Pr (S4 | D)
+ +
0.65
+
0.35
+
0.35

0.65

Table 5: CPTs network Figure 2. Parameterization 2.

628

fiAlgorithms Applications Same-Decision Probability

S1 Pr (S1 | D)
+ +
0.50
0.50
+
+
0.40

0.60

S3 Pr (S3 | D)
+ +
0.55
0.45
+
+
0.45

0.55

S2 Pr (S2 | D)
+ +
0.50
+
0.50
+
0.40

0.60

S4 Pr (S4 | D)
+ +
0.55
+
0.45
+
0.45

0.55

Table 6: CPTs network Figure 2. Parameterization 3.

S2 Pr (S2 | D)
+ +
0.75
+
0.2
0.05
+
+
0.05

0.2

0.75

S1 Pr (S1 | D)
+ +
0.8
0.2
+
+
0.2

0.8

Table 7: CPTs Bayesian network Figure 3.

H1 Pr (H1 | D)
+ +
0.80
+
0.20
+
0.10

0.90

H2 Pr (H2 | D)
+ +
0.70
+
0.30
+
0.30

0.70

Table 8: CPTs network Figure 4. Pr (H3 | D), Pr (E1 | D) Pr (H2 |D)
equal.

629

fiChen, Choi & Darwiche

References
Arroyo, I., & Woolf, B. (2005). Inferring learning attitudes Bayesian network
log file data. Proceedings 12th International Conference Artificial
Intelligence Education, pp. 3340.
Bache, K., & Lichman, M. (2013). UCI machine learning repository..
Bilgic, M., & Getoor, L. (2011). Value information lattice: Exploiting probabilistic independence effective feature subset acquisition. Journal Artificial Intelligence
Research (JAIR), 41, 6995.
Butz, C. J., Hua, S., & Maguire, R. B. (2004). web-based intelligent tutoring system
computer programming. Web Intelligence, pp. 159165. IEEE Computer Society.
Chan, H., & Darwiche, A. (2003). Reasoning Bayesian network classifiers. Proceedings 19th Conference Uncertainty Artificial Intelligence, pp. 107115.
Chen, J., Low, K. H., Tan, C. K.-Y., Oran, A., Jaillet, P., Dolan, J., & Sukhatme, G.
(2012a). Decentralized data fusion active sensing mobile sensors modeling
predicting spatiotemporal traffic phenomena. Proceedings Twenty-Eighth
Conference Annual Conference Uncertainty Artificial Intelligence (UAI-12), pp.
163173, Corvallis, Oregon. AUAI Press.
Chen, S., Choi, A., & Darwiche, A. (2012b). Same-Decision Probability: new tool
decision making. Proceedings Sixth European Workshop Probabilistic
Graphical Models, pp. 5158.
Chen, S., Choi, A., & Darwiche, A. (2013). exact algorithm computing SameDecision Probability. Proceedings 23rd International Joint Conference
Artificial Intelligence, pp. 25252531.
Choi, A., Xue, Y., & Darwiche, A. (2012). Same-Decision Probability: confidence measure threshold-based decisions. International Journal Approximate Reasoning
(IJAR), 2, 14151428.
Conati, C., Gertner, A., & VanLehn, K. (2002). Using Bayesian networks manage uncertainty student modeling. User Modeling User-Adapted Interaction, 12 (4),
371417.
Cover, T. M., & Thomas, J. A. (1991). Elements Information Theory. Wiley-Interscience.
Darwiche, A. (2009). Modeling Reasoning Bayesian Networks (1st edition). Cambridge University Press.
Darwiche, A., & Choi, A. (2010). Same-Decision Probability: confidence measure
threshold-based decisions noisy sensors. Proceedings Fifth European
Workshop Probabilistic Graphical Models, pp. 113120.
Dechter, R. (1999). Bucket elimination: unifying framework reasoning. Artificial
Intelligence, 113 (1), 4185.
Dittmer, S., & Jensen, F. (1997). Myopic value information influence diagrams. Proceedings Thirteenth Conference Annual Conference Uncertainty Artificial
Intelligence (UAI-97), pp. 142149.
630

fiAlgorithms Applications Same-Decision Probability

Friedman, N., Geiger, D., & Goldszmidt, M. (1997). Bayesian network classifiers. Machine
Learning, 29 (2-3), 131163.
Gao, T., & Koller, D. (2011). Active classification based value classifier. Advances
Neural Information Processing Systems (NIPS 2011).
Gertner, A. S., Conati, C., & VanLehn, K. (1998). Procedural help Andes: Generating hints using Bayesian network student model. Proceedings National
Conference Artificial Intelligence, pp. 106111.
Glasziou, P., & Hilden, J. (1989). Test selection measures. Medical Decision Making, 9 (2),
133141.
Greiner, R., Grove, A. J., & Roth, D. (2002). Learning cost-sensitive active classifiers.
Artificial Intelligence, 139 (2), 137174.
Hamscher, W., Console, L., & de Kleer, J. (Eds.). (1992). Readings Model-Based Diagnosis. Morgan Kaufmann Publishers Inc.
Heckerman, D., Breese, J. S., & Rommelse, K. (1995). Decision-theoretic troubleshooting.
Communications ACM, 38 (3), 4957.
Heckerman, D., Horvitz, E., & Middleton, B. (1993). approximate nonmyopic computation value information. IEEE Transactions Pattern Analysis Machine
Intelligence, 15 (3), 292298.
Henrion, M. (1986). Propagating uncertainty Bayesian networks probabilistic logic
sampling. Proceedings Second Annual Conference Uncertainty Artificial
Intelligence (UAI-86), pp. 149163.
Howard, R. A. (1966). Information value theory. IEEE Transactions Systems Science
Cybernetics, 2 (1), 2226.
Howard, R. A., & Matheson, J. E. (Eds.). (1984). Readings Principles Applications Decision Analysis. Strategic Decision Group.
Ide, J. S., Cozman, F. G., & Ramos, F. T. (2004). Generating random Bayesian networks
constraints induced width. Proceedings 16th European Conference
Artificial Intelligence, pp. 323327.
Jordan, A. (2002). discriminative vs. generative classifiers: comparison logistic
regression naive Bayes. Advances Neural Information Processing Systems, 14,
841.
Kahn, C. E., Roberts, L. M., Shaffer, K. A., & Haddawy, P. (1997). Construction
Bayesian network mammographic diagnosis breast cancer. Computers Biology
Medicine, 27 (1), 1929.
Karp, R. M. (1972). Reducibility among combinatorial problems. Complexity Computer Computations. Springer.
Kjrulff, U. B., & Madsen, A. L. (2008). Bayesian Networks Influence Diagrams:
Guide Construction Analysis. Springer.
Krause, A., & Guestrin, C. (2005). Near-optimal nonmyopic value information graphical models. 21st Conference Uncertainty Artificial Intelligence, pp. 324331.
631

fiChen, Choi & Darwiche

Krause, A., & Guestrin, C. (2009). Optimal value information graphical models.
Journal Artificial Intelligence Research (JAIR), 35, 557591.
Kruegel, C., Mutz, D., Robertson, W., & Valeur, F. (2003). Bayesian event classification
intrusion detection. Proceedings Annual Computer Security Applications
Conference (ACSAC).
Liao, W., & Ji, Q. (2008). Efficient non-myopic value-of-information computation influence diagrams. International Journal Approximate Reasoning, 49 (2), 436450.
Lindley, D. V. (1956). measure information provided experiment. Annals
Mathematical Statistics, 27 (4), 9861005.
Lu, T.-C., & Przytula, K. W. (2006). Focusing strategies multiple fault diagnosis.
Proceedings 19th International FLAIRS Conference, pp. 842847.
Millan, E., Descalco, L., Castillo, G., Oliveira, P., & Diogo, S. (2013). Using Bayesian
networks improve knowledge assessment. Computers & Education, 60 (1), 436447.
Modelo-Howard, G., Bagchi, S., & Lebanon, G. (2008). Determining placement intrusion detectors distributed application Bayesian network modeling.
Proceedings 11th International Symposium Recent Advances Intrusion
Detection, pp. 271290.
Munie, M., & Shoham, Y. (2008). Optimal testing structured knowledge. AAAI08:
Proceedings 23rd National Conference Artificial intelligence, pp. 10691074.
Ognibene, D., & Demiris, Y. (2013). Towards active event recognition. Proceedings
23rd International Joint Conference Artificial Intelligence, pp. 24952501.
Park, J. D., & Darwiche, A. (2004). Complexity results approximation strategies
MAP explanations. Journal Artificial Intelligence Research (JAIR), 21, 101133.
Pauker, S. G., & Kassirer, J. P. (1980). threshold approach clinical decision making..
New England Journal Medicine, 302 (20), 110917.
Raiffa, H. (1968). Decision Analysis Introductory Lectures Choices Uncertainty.
Addison-Wesley.
Ramoni, M., & Sebastiani, P. (2001). Robust Bayes classifiers. Artificial Intelligence, 125 (12), 209226.
Roth, D. (1996). hardness approximate reasoning. Artificial Intelligence, 82, 273
302.
Shann, M., & Seuken, S. (2013). active learning approach home heating
smart grid. Proceedings 23rd International Joint Conference Artificial
Intelligence, pp. 28922899.
Stratonovich, R. (1965). value information. Izvestiya USSR Academy Sciences,
Technical Cybernetics, 5, 312.
van der Gaag, L. C., & Coupe, V. M. H. (1999). Sensitivity analysis threshold decision
making Bayesian belief networks. AI*IA, pp. 3748.
Vomlel, J. (2004). Bayesian networks educational testing. International Journal
Uncertainty, Fuzziness Knowledge-Based Systems, 12 (supp01), 83100.
632

fiAlgorithms Applications Same-Decision Probability

Xenos, M. (2004). Prediction assessment student behaviour open distance
education computers using Bayesian networks. Computers & Education, 43 (4),
345359.
Yu, S., Krishnapuram, B., Rosales, R., & Rao, R. B. (2009). Active sensing. International
Conference Artificial Intelligence Statistics, pp. 639646.
Zhang, N. L. (1998). Probabilistic inference influence diagrams. Computational Intelligence, pp. 514522.
Zhang, Y., & Ji, Q. (2010). Efficient sensor selection active information fusion. IEEE
Transactions Systems, Man, Cybernetics, Part B, 40 (3), 719728.

633

fiJournal Artificial Intelligence Research 49 (2014) 143-170

Submitted 10/13; published 02/14

Procedural Characterization
Solution Concepts Games
Joseph Y. Halpern

halpern@cs.cornell.edu

Computer Science Department
Cornell University
Ithaca, NY 14853, USA

Yoram Moses

moses@ee.technion.ac.il

Department Electrical Engineering
TechnionIsrael Institute Technology
Haifa, 32000, Israel

Abstract
show game-theoretic solution concepts Nash equilibrium, correlated
equilibrium, rationalizability, sequential equilibrium given uniform definition
terms knowledge-based program counterfactual semantics. precise sense,
program viewed providing procedural characterization rationality.

1. Introduction
general intuition that, many situations, players depends
know. leads hope describe players actions procedurally using
knowledge-based (kb) programs (Fagin, Halpern, Moses, & Vardi, 1995, 1997) form
know (or know) X . example, kb program could say
dont know Ann received information, send text message,
written
Ki (Ann received info) send Ann text message.
kb program form standard . . . statement, except test
clause involves knowledge (expressed using modal operator Ki ).
Knowledge-based programs successfully applied distributed computing,
help design new protocols clarify understanding existing
protocols (see, e.g., Fagin et al., 1997; Dwork & Moses, 1990; Hadzilacos, 1987; Halpern,
Moses, & Waarts, 2001; Halpern & Zuck, 1992; Mazer & Lochovsky, 1990; Mazer, 1990;
Moses & Kislev, 1993; Moses & Tuttle, 1988; Neiger & Bazzi, 1992; Neiger & Toueg, 1993).
also applied successfully planning (Brafman, Latombe, Moses, & Shoham,
1997; Lang & Zanuttini, 2012, 2013; Reiter, 2001). paper, initiate project
use kb programs game theory. seems like particularly fruitful application
area, since seems kind reasoning people employ games
decision-making problems.
focus one application kb programs game theory: characterizing solution concepts. Many solution concepts considered game-theory literature, ranging
Nash equilibrium correlated equilibrium refinements Nash equilibrium
c
2014
AI Access Foundation. rights reserved.

fiHalpern & Moses

sequential equilibrium weaker notions rationalizability (see Osborne & Rubinstein, 1994, overview).
Typically, solution concepts assume players rational, sense
players strategy represents best response beliefs strategies
players using. Indeed, number epistemic characterizations various
solution concepts provided literature. particular interest us
characterizations terms common knowledge rationality. characterizations
following flavor: ~ satisfies solution concept X iff state
model (a) common knowledge players rational, (b) players
playing strategy profile ~ , (possibly) (c) satisfies additional property.
additional properties needed X rationalizability (Brandenburger & Dekel, 1987);
get correlated equilibrium assume players common prior (Aumann,
1987); get Nash equilibrium assume prior takes strategy choices
uncorrelated (Aumann, 1987).1 Similar results proved sequential equilibrium
perfect equilibrium (Halpern & Moses, 2010).
standard semantics kb programs (see Section 2) essentially ensures kb
programs run players common knowledge. Thus, might hope
could find kb program captures rationality, could use give
procedural characterization various solution concepts. paper show
goal attainable.
Consider following kb program EQi player i, Ai () denotes possible
actions available player game . (This program applies normal-form
extensive-form games. extensive-form game , Ai () union actions
available information sets; assume without loss generality sets
actions different information sets disjoint.)
action Ai ()
V
Ki (intendi (a) a0 Ai () EUi (a) EUi (a0 ))
play a.
Intuitively, think program one ensures players expected utility
maximizers: Player follows action playing action maximizes expected
utility. literally, EQi says player play action currently intends
(that intended semantics intendi (a)), utility
less utility would playing alternative action. EUi (a0 ) represents
expected utility play a0 (conditional beliefs current information
set consider extensive-form games).2 utility taken respect player
current probability distribution (which viewed distribution strategy
profiles players, thus represents beliefs players
doing).
1. Although Aumann (1987) state result Nash equilibrium explicitly, follows easily
results correlated equilibrium.
2. Note EUi (a0 ) incorporates counterfactual. situation actually intending
play a, EUi (a0 ) expected utility would play a0 instead. preliminary
version paper (Halpern & Moses, 2007), made counterfactual reasoning explicit
counterfactual operator language. Following suggestion reviewer, suppressed
counterfactual here, focus issues interest us.

144

fiA Procedural Characterization Game Concepts

Programs generally viewed describing various actions supposed
performed, thereby providing procedural specification behavior. Knowledge-based programs are, general, somewhat different. example, consider program EQi .
written assuming player already chosen strategy. One possible way

view EQ (i.e., (EQ1 , . . . , EQn )) specifying that, given last-minute chance
change minds, none (utility-maximizing) players would reason deviate
individual choices.
test EQi seen embodying (one standard form of) rationality: says
act maximize expected utility. common knowledge
player follows EQi (recall semantics kb programs essentially ensures
programs run commonly known), then, intuitively, players
common knowledge rationality, equilibrium. Indeed, show,

appropriate assumptions, played players act according EQ


instance standard solution concept. EQ captures many solution concepts uniform
way. Solution concepts differ assumptions made players beliefs.
assumptions essentially ones arose logical characterizations solution
concepts mentioned above. Thus, example, correlated equilibrium, rather
requiring common knowledge rationality common prior,

require players use EQ common prior; similarly solution
concepts.
semantics kb programs allows us capture assumptions players
beliefs restricting appropriate systems. upshot single kb program
arguably gives procedural embodiment rationality. Moreover, common knowledge
program run provides us characterization perhaps
common solution concepts used game theory: Nash equilibrium, correlated equilibrium,
rationalizability, sequential equilibrium, perfect equilibrium.
considerable work last two decades focusing interplay modal logic game theory, specifically epistemic logic solution
concepts games (see, e.g., Aumann & Brandenburger, 1995; Benthem, 2007, 2010; Bruin,
2010; Bonanno, 2002; Harrenstein, Hoek, Meyer, & Witteveen, 2002; Lorini & Schwarzentruber, 2010). paper differs line work relates equilibrium notions
knowledge-based programs, shows procedural commonality among equilibrium
notions, well slightly varying epistemic assumptions gives rise different
notions.
rest paper devoted making claims precise. Section 2,
review relevant background game theory knowledge-based programs. give
formal semantics kb programs, use runs-and-systems framework (Fagin et al.,
1995), used computer science literature represent complex systems.
specialize framework represent games interest here.
Section 3, show EQ characterizes Nash equilibrium, correlated equilibrium,
rationalizability, sequential equilibrium game , appropriate context.
conclude Section 4 discussion results, implications possible
extensions, general discussion potential use kb programs game theory.
particular, argue despite non-negligible overhead involved dealing
145

fiHalpern & Moses

knowledge-based programs, using gives us flexible powerful tool capturing
intuitions best response.

2. Background Definitions
section, review relevant background games knowledge-based programs,
define semantics knowledge-based program EQi formally. describe
need proving results. reader encouraged consult standard game
theory text (e.g., Osborne & Rubinstein, 1994) game theory, work
Fagin et al. (1995, 1997) runs-and-systems framework knowledgebased programs.
2.1 Games Strategies
game extensive form described game tree = . utility ui (h) defined
terminal history h game tree (where terminal history game tree
path leading root leaf), specifying player utility history
played. Let Z denote set terminal histories. (We omit subscript clear
context.) Although typical assume one player time moves
extensive-form game, allow arbitrary subsets players move. added generality
allows us view normal-form games special case extensive-form games. Thus,
associated non-leaf node subset players whose move node.3
non-leaf node w , bijection possible sets moves
played w successors w. w0 successor w corresponds
particular set moves, w0 thought outcome playing moves
w. nodes player moves partitioned information sets.
behavioral strategy player extensive-form game associates
information set distribution (I) actions played I. Thus,
strategy player tells player node game tree
supposed move. fact strategy determines actions function
information sets captures intuition that, nodes player cannot tell apart,
player must thing. pure strategy Si deterministic, specifying single
action per information set. (Of course, pure strategy viewed special case
behavioral strategy; behavioral strategy puts probability 1 particular
action information set.) Since game tree assumed finite,
finitely many pure strategy profiles. mixed strategy distribution
pure strategies.4 Note player using mixed strategy randomizes once,
beginning game; way contrast, player using behavioral strategy randomizes
information set. pure (resp., mixed; behavioral) strategy profile tuple ~ =
(1 , . . . , n ) specifying pure (resp., mixed; behavioral) strategy player. usual,
given profile ~x, denote ~xi partial profile containing component players
3. ease exposition, point consider games moves nature.
difficulty dealing moves nature; discuss Section 4.
4. consistently use Si denote pure strategy denote mixed strategy behavioral
strategy.

146

fiA Procedural Characterization Game Concepts

~ = (S1 , . . . , Sn )
i. denote = S(T ) set pure strategy profiles
game tree .
normal-form game viewed special case extensive-form game
player makes one move, players move simultaneously. tree corresponding game depth one: nodes root leaves.
2.2 Runs-and-Systems Framework
explain kb programs, must first describe runs-and-systems framework. assume
that, given point time, player game local state. local state
could include history game point, strategy used player,
perhaps features players type, beliefs strategies
used players. shall see, purposes paper, model games,
players local state essentially consist strategy information set. global
state profile local states: one local state player.
run sequence global states; formally, run function times global
states. Thus, r(m) global state run r time m. definiteness, assume
time ranges natural numbers here. point pair (r, m) consisting run r
time m. Let ri (m) local state point (r, m); is, r(m) = (s1 , . . . , sn ),
ri (m) = si . system set runs. probabilistic system tuple PS = (R,
~ ),
R system
~ = (1 , . . . , n ) associates probability runs R
player i. Intuitively, represents player prior beliefs. special case
1 = = n = , players common prior R. case, write
(R, ).
2.3 Modeling Game System
game , associate system R . describing system R ,
decide model players local states, is, know point
system? part, details matter analysis paper,
critical effect analyses. believe one advantages
runs-and-systems approach forces modeler think carefully
players local states be.
case normal-form game , time 0, take players local state
consist pure strategy intending play; players local state times
1 consists strategy played (which take one
intending play) utility. Even think player mixed
strategy, think pure strategy local state pure strategy
player chooses tossing coin. could, course, also include mixed strategy
players state. turns would make difference; player strategy
encoded distribution runs. upshot approach modeling things
~
identify run R pure strategy profile ; denote rS
~
run coresponding strategy profile S.
take simple example, consider normal-form game n Figure 1,
two players, Alice (the row player) Bob (the column player): four runs
Rn , corresponding four strategy profiles game. run r(T,L) ,
147

fiHalpern & Moses


B

L
(3, 3)
(4, 1)

R
(1, 4)
(0, 0)

Figure 1: simple 2-player game n .

r(T,L) (0) = (T, L) r(T,L) (1) = ((T, 3), (L, 3)). run, Alices initial state ,
intended strategy, state times 1 (T, 3), strategy utility.
extensive-form game, take runs R correspond terminal histories
game tree; one run rh corresponding history h. points run
rh correspond nodes history h. is, global state rh (m) corresponds
mth node w history h. (If greater length h, rh (m) = rh (|h|).)
Suppose moves node w. take local state rh (m) form
(Iw , a), Iw information set w, move makes information
set Iw history h. Intuitively, saying knows information set, move
intending make. solution concepts analyze extensive-form games,
assume using behavioral strategy. Thus, think outcome
coin toss information set behavioral strategy. still need represent
local state points correspond nodes w move. details
local state points move matter much. definiteness,
move node w corresponding (rh , m), take local state
Iw0 , w0 recent node preceding w move; moved
prior w, take local state h i. w final node terminal
history, also encode utility local state, normal-form games.
Thus, state encodes information happened thus far (this Iw
component), whether move (this captured whether
action component local state), intends move, (at
points correspond end game), players utility.
solution concepts focus extensive-form games, think
players using behavioral strategy. However, normal-form games,
encode behavioral strategy local state. again, turn
behavioral strategy encoded probability distribution runs.5 could also
included game players local states, since implicitly assuming
game common knowledge. would change anything analysis;
done simply avoid cluttering notation. course, would
appropriate thing games players fully aware game
played (see, e.g., Halpern & Rego, 2013).
5. alert reader may spotted potential problem here. Runs equilibrium path (and hence,
information sets equilibrium path) get probability 0, may seem cannot use
probability runs infer behavioral strategy information sets. But, shall see,
probability runs actually use nonstandard probability infinitesimally close
actual probability generated strategy profile. nonstandard probability gives positive
probability runs, hence used infer behavioral strategy. artifact
approach. contexts, may well want include behavioral strategy local state.

148

fiA Procedural Characterization Game Concepts

Consider 2-player extensive-form game e Figure 2, player 1 moves w1 ,
player 2 moves information set {w2 , w3 }:
b1 ! !

!r (3,4)
!

!
fi
!!
!
r!
#aaa
#
w
2
2
ab
#
aa
a1 #
aa
ar (3,2)
#
#
#
#
#
w1rc
c
c

ca2
c
c

b1 ! !

!
c
!!
w
!
3
c
c!
ra
aa


2
ab
aa


!r (1,1)
!


ar (1,2)

Figure 2: extensive-form game e .
four runs , corresponding four terminal histories. Call
histories h1 h4 , going top bottom. Thus, rh1 (where utility (3,4)), 1s local
state rh1 (0) ({w1 }, a1 ), 2s local state h i. rh1 (1), 1s local state {w1 },
2s ({w2 , w3 }, b1 ), rh1 (2), local state ({w1 }, 3), 2s local state
({w2 , w3 }, 4).
Since bijection runs R normal-form game pure strategy
profiles, distribution pure strategies normal-form game identified
distribution runs R . Thus, associate mixed strategy profile ~
normal-form game probabilistic system (R , ~ ), ~ distribution
strategy profiles (and hence also runs) induced ~ . Note according ~ , players
strategy choices uncorrelated; probability player chooses Si player j
chooses Sj product probability chooses Si probability
j chooses Sj . Similarly, extensive-form game , behavioral strategy profile ~
induces distribution histories, hence also runs R . denote
distribution ~ .
2.4 Knowledge-Based Programs
knowledge-based program syntactic object. purposes, knowledge-based
program player taken form
1 a1
2 a2
...,
149

fiHalpern & Moses

aj action i, j Boolean combination formulas
form Ki , nested occurrences K` operators. assume
tests 1 , 2 , . . . mutually exclusive, that, kb program player i, one
tests evaluates true local state player moves. program
EQi written form simply replacing . . . statement one line
possible action game . is, action Ai (),
line EQi form
Ki (intendi (a)

^

EUi (a) EUi (a0 )) play a.

a0 Si (A)

Since player intends play one action point (r, m) (R ,
~ ), tests
EQi mutually exclusive. tests necessarily exhaustive, since point
strategy player uses best response, test form
satisfied. Roughly speaking, none tests satisfied, nothing (and
performs null action skip).
want define means (probabilistic) system PS compatible
kb program. Intuitively, case moves made PS
ones recommended kb program. simplicity, give enough required
definitions able handle case PS form (R ,
~ ) kb
program EQi . details, interested reader consult Fagin et al. (1995,
1997).
first step making precise, standard system PS = (R ,
~ ),
associate formula set [[]]PS points PS. Intuitively, [[]]PS set
points R true. intendi (a) easy:
[[intendi (a)]]PS set points (r, m) PS moves node w
game tree associated (r, m) action encoded local state.
Note kb program Pgi player attempt override intentions; is,
program line form play a0 that, point (r, m)
probabilistic system PS, true (i.e., (r, m) [[]]PS ), action local state
a, a0 . case, shall see, Pg would compatible PS.
semantics knowledge defined usual: formula Ki true true
points considers possible. view information point (r, m)
encapsulated local state (r, m), denote ri (m). Thus, set
points considers possible point (r, m) Ki (r, m) = {(r0 , m0 ) : ri0 (m0 ) = ri (m)};
Ki (r, m) consists points local state (r, m).
[[Ki ]]PS set points (r, m) Ki (r, m) [[]]PS .
remains give semantics formulas form EUi (a0 ) EUi (a). Clearly
expected utility would obtain play a0 point (r, m) depends
beliefs players (r, m). Roughly speaking, beliefs
obtained conditioning prior beliefs Ki (r, m). small technical
problem here. probability distribution distribution runs; Ki (r, m) set
150

fiA Procedural Characterization Game Concepts

points. cannot condition Ki (r, m). enable conditioning, first associate
Ki (r, m) set R[Ki (r, m)] runs go points Ki (r, m); is,
R[Ki (r, m)] = {r0 : (r0 , m) Ki (r, m)).
define i,r,m = | R[Ki (r, m)]. (For purposes paper, specify
i,r,m (R[Ki (r, m)]) = 0. turns irrelevant discussion.) Recall
bijection runs R pure strategy profiles. Moreover, since player
knows strategy, runs R[Ki (r, m)], player using strategy. Thus,
~i . use distribution compute EUi (a)
i,r,m determines distribution
0
EUi (a ). case normal-form game , suffices compute expected utility
play a0 (although a0 may fact strategy intends use
runs R[Ki (r, m)]), assumption players use strategy
intending use; strategy changes. extensive-form game,
considering change a0 run r, keep actions fixed (i.e.,
actions players throughout run, actions information set I),
consider utility resulting run.
normal-form game PS = (R ,
~ ), [[EUi (a) EUi (a0 )]]PS consists
points (r, m) expected utility using least high
using a0 , expectation taken respect distribution
strategy profiles ai players, determined i,r,m .
extensive-form game, point (r, m) player intends play action a,
information set I, move. compute EUi (a0 ), run r0 Ki (r, m),
let hr0 [a/a0 ] history sequence actions played
player r0 , except information set I, plays a0 rather a.
P
EUi (a0 ) = r0 Ki (r,m) i,r,m (r0 )ui (hr0 [a/a0 ]). Again, [[EUi (a) EUi (a0 )]]PS consists
points (r, m) moves EUi (a0 ) (computed above) higher
EUi (a).
Since player knows strategy (it appears local state), (r, m) [[intendi (a)]]PS ,
Ki (r, m) [[intendi (a)]]PS . Similarly, since i,r,m = i,r0 ,m0 (r0 , m0 ) Ki (r, m), player
knows probability distribution, (r, m) [[EUi (a) EUi (a0 )]]PS , Ki (r, m)
V
0
[[EUi (a) EUi (a0 )]]PS . Hence, formula intendi (a)
a0 Ai () EUi (a) EUi (a )
V
0
equivalent epistemic formula Ki (intendi (a)
a0 Ai () EUi (a) EUi (a )); is,
V
0
intendi (a) a0 Ai () EUi (a) EUi (a ) true iff player knows it. kept Ki
kb program emphasize formula whose truth depends
knows believes, thus test act on.


Intuitively, system PS compatible kb program profile Pg PS could
arisen player uses Pgi . formalize follows.
~ r R 0,
Definition 2.1 PS compatible kb program profile Pg
action profile ~a (a) applying ~a (r, m) results (r, + 1) (see
below) (b) (R[Ki (r, m)]) > 0 (r | R[Ki (r, m)]) > 0, either
line ai Pgi (r, m) [[]]PS , line ai
null move skip.
151

fiHalpern & Moses

explained means apply action profile ~a point (r, m).
general definition involves viewing action profiles transformers global states (see
Fagin et al., 1995, 1997). Rather going details general definition


here, give definition case PS form (R , ) Pg EQ .
need paper, case, definition quite simple.
~
~
~
normal-form game, action profile ~a applied rS (0) results rS (1) iff ~a = S;
~
~
1, ~a applied rS (m) results rS (m + 1) iff a1 = = skip.
extensive-form game, ~a applied rh (m) results rh (m + 1) iff ai = skip
move information set associated rh (m) (which means that, particular,
greater equal length h, ai = skip players i) and,
move I, ai move encoded rih (m). Roughly speaking, means

normal-form game , PS = (R , ) compatible EQ iff, player run r

(r) > 0, according EQ r(0) intends according
local state ri (0). Thus, intends play strategy S, must case
EUi (S) EUi (S 0 ) strategies 0 player i. analogous statement true
extensive-form games, although compute whether EUi (a) EUi (a0 ) point (r, m),
use probability conditioned R[Ki (r, m)]. is, ai action played
(r, m), ai really best response i, given beliefs (r, m).
observation makes proofs results relatively straightforward, important
note really instance general semantics kb programs.

3. Main Results
section, show EQ captures number standard solution concepts.
start considering solution concepts normal-form games, move extensiveform games.
3.1 Capturing Solution Concepts Normal-Form Games
show EQ captures three studied solution concepts normal-form games:
Nash equilibrium, correlated equilibrium, rationalizability. differences
captured highlights distinctions notions.
3.1.1 Nash Equilibrium
Recall (R, ) probabilistic system players common prior
runs.
Theorem 3.1 mixed strategy profile ~ Nash equilibrium normal-form game

iff (R , ~ ) compatible EQ .
Proof

First suppose ~ = (1 , . . . , n ) Nash equilibrium game . see

~
PS = (R , ~ ) compatible EQ , suffices show ~ (rS ) > 0,
~
~
Si best response respect ~ | R[Ki (rS , 0)]. (We need consider (rS , 0)
normal-form game, moves time 0.)
152

fiA Procedural Characterization Game Concepts

~

Note ~ | R[Ki (rS , 0)] = ~i (under obvious identification ~ | Ki (r, 0)
distribution Si ). Since ~ Nash equilibrium, Si must best response ~i .
~
Thus, strategies 0 Si (), must (rS , 0) [[EUi (S) EUi (S 0 )]]PS .

follows PS = (R , ~ ) compatible EQ .

converse, suppose (R , ~ ) compatible EQ . want show
~ Nash equilibrium. suffices show pure strategy Si support
~i
best response ~i . Let Si support . Choose strategy profile
~
~



support ~i . ~ (r ) > 0. Moreover, ~ | R[Ki (r , 0)] = ~i . Since (R , ~ )

~
compatible EQ ~ (rS ) > 0, must case that, strategies 0 Si (),
~
(rS , 0) [[EUi (S) EUi (S 0 )]]PS . is, indeed best response ~i .
Consider game n described Figure 1. easy check game three
Nash equilibria: two equilibria pure strategies: (B, L) (T, R).
also equilibrium mixed strategies Alice randomizes (uniformly)
B, Bob randomizes L R. means three probabilistic
systems form (Rn , ) compatible EQn . first, puts probability 1
r(B,L) ; second, puts probability 1 r(T,R) , third, puts uniform
probability four runs system.
3.1.2 Correlated Equilibrium
well known, players sometimes achieve better outcomes Nash equilibrium
access helpful mediator. Consider simple 2-player game n described
Figure 1. Recall total utility three Nash equilibria games
(that is, sum utilities two players) 5. get higher total
utility using trusted mediator, makes recommendation choosing random
(T, L), (T, R), (B, L). gives player expected utility 8/3; thus,
total utility 16/3. example correlated equilibrium since, example,
mediator chooses (T, L), thus sends recommendation Alice L Bob,
Alice considers equally likely Bob told L R, thus incentive
deviate; similarly, Bob incentive deviate. general, distribution pure
strategy profiles correlated equilibrium players cannot better following
mediators recommendation mediator makes recommendations according . (Note
that, example, mediator chooses (pure) strategy profile (S1 , . . . , Sn ) according
, mediator recommends Si player i; player told nothing strategy
profile except Si .) Roughly speaking, correlated equilibrium distribution
(pure) strategy profiles every strategy player positive probability
best response conditional probability | projected onto Si . (Note
~ 0 0 = , | viewed
support | consists strategy profiles

distribution Si . Intuitively, player knows prior probability pure
strategy profiles told play , believes probability
strategy profiles Si played players described | (projected onto
Si ). Conversely, distribution pure strategy profiles that, player
every strategy player given positive probability best response
| , correlated equilibrium. Formally, following definition.
153

fiHalpern & Moses

Definition 3.2 (Aumann, 1974) distribution pure strategy profiles correlated
equilibrium player i, strategy player (S) > 0 (where
~ 0 0 = S), strategy 0
identify set pure strategy profiles

player i,
X

ui (S, Si )(Si | S)

Si Si

X

ui (S 0 , Si )(Si | S).

Si Si

is, correlated equilibrium when, every player i, mediator tells play
strategy positive probability according , gain switching
0 , given beliefs players do, conditional player
told S.
Clearly distribution strategy profiles game identified distribution runs R . easily capture correlated equilibrium using EQ
way generalizes Theorem 3.1. difference Theorem 3.1 Theorem 3.3 ~ Theorem 3.1 product measure, distribution runs
Theorem 3.3 necessarily product measure (indeed, product measure iff
correlated equilibrium Nash equilibrium).
Theorem 3.3 distribution strategy profiles correlated equilibrium

(normal-form) game iff (R , ) compatible EQ .
Proof proof proceeds along lines similar Theorem 3.1.
~
Suppose correlated equilibrium (rS ) > 0. Again, must show
~
~
Si best response | R[Ki (rS , 0)]. R[Ki (rS , 0)] consists precisely runs
player plays Si . Thus, i,rS~ ,m = | Si . Since correlated equilibrium, Si

best response | Si ; thus easily follows (R , ) compatible EQ .
converse, suppose distribution strategy profiles (R , )

compatible EQ . want show correlated equilibrium. Suppose
strategy player positive probability according . Thus,
~
run r = rS (r) > 0 Si = . seen, i,r,0 = | . Since

(R , ) compatible EQ , must case best response | ,
determines beliefs (r, 0). Thus, correlated equilibrium.
Note fact intended strategy included local state normal-form
games ensures i,rS~ ,0 = | Si . Intuitively, correlated equilibrium, mediator
tells strategy follow, uses information determining best response.
Thus, local state model information. way contrast, Theorem 3.1 would
hold even strategy part local state. Since ~ product measure
Theorem 3.1, would still case i,r,0 = ~i runs r.
3.1.3 Rationalizability
characterization Nash equilibrium correlated equilibrium involves common prior runs. Dropping assumption gives rise another standard solution concept: rationalizability (Bernheim, 1984; Pearce, 1984). Intuitively, strategy player
154

fiA Procedural Characterization Game Concepts

rationalizable best response beliefs player may
strategies players following, assuming strategies
best response beliefs one players strategies players
following, on.
Following Osborne Rubinstein (1994), say strategy player game
rationalizable if, player j, set Zj Sj () and, strategy Zj ,
probability measure j,T Sj () whose support subset Zj
Zi ;
player j strategy Zj , strategy best response (the beliefs)
j,T .
Intuitively, strategies Zi rationalizable strategies player i. Player
justify playing strategy Zi because, assumption, distribution Zi
(representing beliefs strategies players using)
best response. Moreover, strategies assigns positive probability
themselve justifiable, since Zi , best responses beliefs
place positive probability strategies justifiable, on.
ease exposition, consider pure rationalizable strategies. essentially
without loss generality. easy see mixed strategy player best
response beliefs player iff pure strategy support best
response . Moreover, assume without loss generality support
consists pure strategy profiles.
Notice game n Figure 1, strategies rationalizable. Alice playing
justified Alice believes Bob play R; Bob playing R justified believes
Alice ; Alice playing B justified Alice believes Bob play L; Bob
playing L justified believes Alice play R.
following theorem characterizes rationalizability framework. Note
assume common prior, vector
~ = (1 , . . . , n ),
necessarily identical, describing players beliefs.
Theorem 3.4 pure strategy player (normal-form) game rationalizable
iff exists probabilistic system PS = (R ,
~ ) and, player j, exists set
Zj Sj (a) j gives every strategy Zj positive probability; (b) support

j contained Z = Z1 Zn , (c) Zi , (d) (R ,
~ ) compatible EQ .
Proof Suppose PS = (R ,
~ ) probabilistic system satisfying four properties
above. want show rationalizable. Take sets Zi guaranteed exist
assumptions theorem sets Zi definition rationalizability.
Zj , let j,T j | projected onto Sj . Note j | well defined,
since j (T ) > 0. Moreover, support j,T contained Zj , since support
j contained Z. show every Zj best response j,T . Since
~
~
j (T ) > 0, must run rS Sj = j (rS ) > 0. easy see

j,rS~ ,0 = j | = j,T . Since (R ,
~ ) compatible EQ , must case
best response j,T . Thus, rationalizable.
155

fiHalpern & Moses

converse, suppose Si rationalizable. Thus, player j,
exist set Zj and, strategy Zj , measure j,T Sj ()
~ = j,S (S~j )/|Zj | Sj Zj , taking
best response j,T . Define j taking j (S)
j
~ = 0 otherwise. First, observe j probability S: strategy Sj Zj ,
j (S)
j (Sj Sj ) = j,Sj (Sj )/|Zj | = 1/|Zj |; result easily follows. Moreover,
Sj , j (S) > 0 iff Zj (of course, j (S) j (S Sj ). since
support j,T contained Zj strategy Sj , easily follows
support j contained Z. Finally, Zi , construction. Since best response

j,T Zj , easily follows PS = (R ,
~ ) compatible EQ .
see strategies n rationalizable, actually take 1 = 2
distributions assign probability 1/2 (T, R) (B, L). easy see
satisfies conditions Theorem 3.4, taking Z1 = {T, B} Z2 = {L, R}.
However, take 1 = 2 . long support 1 2
{(T, R), (B, L)}, choice 1 2 works.
Osborne Rubinsteins definition rationalizability allows j,T j
believes players strategy choices correlated. literature, players
assumed believe players choices made independently. add
latter requirement, must impose requirement probability measures
1 , . . . , n Theorem 3.4.
important characterization rationalizability strategy part
local state. Intuitively, strategy together beliefs strategies
remaining players determine type. modeling rationalizability, suffices assume
strategy determines beliefs, identify type strategy. including
strategy local state, basically allowing different types player i.
3.2 Capturing Solution Concepts Extensive-Form Games
consider solution concepts extensive-form games. Recall that, case,
assume players using behavioral strategies.
3.2.1 Nash Equilibrium
get essentially result Theorem 3.1: behavioral strategy profile ~
Nash equilibrium extensive-form game iff (R , ~ ) compatible EQ .
However, number new subtleties arise extensive-form games. First, Nash equilibrium extensive-form game require players make best response
equilibrium path. dealt definition compatibility since fact
consider points (r, m) (Ki (r, m)) > 0 means considering
points equilibrium path.
Another subtlety arises fact that, determining whether best response
point (r, m), player allowed change completely different strategy i0 .
definition EQ extensive-form games considers changing different
action. show suffices, appeal result known literature
one-deviation property (Osborne & Rubinstein, 1994). one-deviation property holds
if, order check behavioral strategy best response , suffices
156

fiA Procedural Characterization Game Concepts

check local changes ; is, suffices check behavioral strategies differ
modifying one information set.
Let [I/a] behavioral strategy like except assigns probability
1 action information set I. Strategies form [I/a] consider
show one-deviation property holds information set I. best response
information set allows changes I, information sets preceded
I. analysis considers called games perfect recall. Roughly
speaking, game perfect recall, players recall moves made
information sets passed through. recollection formalized
putting conditions information sets. omit formal definition perfect recall
(see Osborne & Rubinstein, 1994). finite extensive-form game perfect recall,
player i, define partial order player information sets
0 if, every history h I, prefix h0 h 0 . Thus, 0 0
preceded I, or, equivalently, appears game tree. Given two information
sets, say precedes 0 , write 0 , = 0 0 comes history
game (i.e., node 0 preceded node game tree). games
perfect recall, partial order; cannot two distinct information sets
0 0 0 I. Given information set player i, denote [i0 , I, ]
strategy player agrees information sets 0 player
0 agrees i0 information sets.
recall notion best response behavioral strategies given Halpern
(2013). belief system (Kreps & Wilson, 1982) function associates
information set probability, denoted , histories I. Given behavioral strategy
~ belief system extensive-form game , let Pr~ denote distribution
terminal histories induced ~ define
EUi ((~ , ) | I) =

XX

(h)Pr~ (z | h)ui (z).

hI zZ

Thus, expected utility (~ , ) conditional reaching captures expected payoff
player ~ played information set on, given relative likelihood
histories determined . Finally, ~ completely-mixed behavioral strategy
profile, let ~ belief system determined ~ obvious way:
~I (h) = Pr~ (h | I).
Definition 3.5 (Halpern, 2013) 0 information set player
0 conditional
reached positive probability ~ 0 , -best response ~i
reached using ~ 0 if, every strategy player i,
0

0

0
0
EUi (((i , ~i
), ~I ) | I) EUi (((i , ~i
), ~I ) | I) .
0
strategy -best response relative ~ 0 -best response ~i
0
conditional reached using ~ information sets reached
positive probability ~ 0 . strategy ~i best response relative ~ 0 (resp.,
best response conditional reached using ~ 0 ) 0-best response
relative ~ 0 (resp., 0-best response conditional reached I).

157

fiHalpern & Moses

0
Thus, best response relative ~ 0 best response

0
information set player reached positive probability ~ ,
assume ~ 0 determines probability histories and, best responding,
allow player make arbitrary changes reached. determines
probability reaching I.
next result basically one-deviation property; shows strategy
optimal respect local changes fact best response.

Theorem 3.6 Let game perfect recall. strategy best response response
relative ~ iff EUi (~ ) EUi (i [I/a], ~i ) information set player
reached positive probability ~ action play I.
Proof essentially proved Selten (1975), briefly sketch argument
here. Clearly, best response relative ~ reached ~
positive probability, EUi (((~ , ~I ) | I) EUi ((i [I/a], ~i ), ~I ) | I) information sets reached positive probability according ~ player
moves, actions take I. converse, suppose EUi (((~ , ~I ) |
I) EUi ((i [I/a], ~i ), ~I ) | I) information sets reached positive
probability according ~ player moves, actions take I.
way contradiction, suppose best response relative ~ .
must information set reached positive probability ~
strategy player EUi (([i , I, ], ~i ), ~I ) | I) > EUi (((~ , ~I ) | I). get
easy contradiction considering latest information set player reached
positive probability ~ inequality holds (so information set
0 6= 0 , inequality hold). (Since game perfect recall,
notion latest information set well defined.)
Theorem 3.7 behavioral strategy profile ~ Nash equilibrium extensive-form
game iff (R , ~ ) compatible EQ .
omit proof, since easier (and similar spirit) proofs presented
later section.
3.2.2 Perfect Equilibrium
start considering (trembling-hand) perfect equilibrium (Selten, 1975). defined
normal-form games extensive-form games. ease exposition, focus
definition extensive-form games, although essentially approach applies
normal-form games.
idea ~ perfect equilibrium if, best response ~i ,
best response even players j 6= tremble, (with exceedingly small
probability) play strategy j .
make precise, define completely
mixed (behavioral) strategy player strategy where, information set
player i, action played played positive probability. Observe
~ completely mixed strategy extensive-form game , reach
every information set player positive probability. extensive-form
158

fiA Procedural Characterization Game Concepts

game , strategy profile ~ perfect equilibrium iff exists sequence ~ n
completely mixed strategies ~ n ~ and, n information set
n conditional reached I. Intuitively, ~
n
player i, best response ~i

n
represents tremble; ~i , n = 1, 2, 3, . . . sequence trembles converging ~ .
strategy must best response tremble sequence. Thus, strategy
perfect equilibrium profile ~ best response possible trembles,
trembles along one particular path converging ~ . (The definition perfect equilibrium
essentially normal-form games, except need condition
information set.)
result depends characterization perfect equilibrium given Halpern (2009,
2013) uses nonstandard probabilities, assign infinitesimal probabilities
strategy profiles. discrete nonstandard probability distribution set runs discrete
probability distribution assigns nonstandard probabilities runs sum
runs adds 1.
Halpern (2009) shows using nonstandard probability, capture Seltens
intuition trembling-hand equilibrium without needing explicitly refer sequences
strategy profiles, done Seltens original definition. idea sequence
converging ~ Seltens original definition replaced single completely mixed
strategy profile infinitesimally close ~ . make precise, need
definitions. well known every nonstandard real number , closest
standard real number denoted st() IR, called standard part : difference
| st()| infinitesimal. Given nonstandard probability measure , define
standard probability measure st() taking st()(w) = st((w)) states .
Two possibly nonstandard distributions 0 differ infinitesimally st() = st( 0 ).
While, Selten shows, perfect equilibrium always exists normal-form games,
necessarily exist arbitrary extensive-form game. However, exist
extensive-form games perfect recall. state Halperns characterization
trembling-hand equilibrium. say two behavioral strategies i0 player
differ infinitesimally distributions (I) i0 (I) differ infinitesimally
information set player I. Two strategy profiles ~ = (1 , . . . , n ) ~ 0 = (10 , . . . , n0 )
differ infinitesimally differs infinitesimally i0 I, every = 1, . . . , n.
Theorem 3.8 (Halpern, 2009, 2013) behavioral strategy profile ~ = (1 , . . . , n )
perfect equilibrium extensive-form game perfect recall iff exists nonstandard completely mixed behavioral strategy profile ~ 0 differs infinitesimally ~
0 relative ~
best response
0 player i.
dealing standard probabilities, definition probabilistic system


PS = (R,
~ ) compatible knowledge-based program profile Pg, required
action played Pgi (r, m) played system PS (r, m)
runs r (r | R[Ki (r, m)]) > 0. want restrict runs
positive probability, runs nontrivial positive probability.
obvious choice would require st(i (r | R[Ki (r, m)])) > 0. settings
players following behavioral strategy, requirement would would restrict runs r
where, times m0 > m, player j moves information set associated (r, m0 ),
move made j given positive standard probability behavioral strategy.
159

fiHalpern & Moses

would like case well move made (r, m). Since encode
intended move (r, m) local state ri (m) (recall local state models
information made coin toss), conditional Ki (r, m), player intended
move probability 1, even infinitesimal probability according strategy.
simplicity, describe requirement want systems form
R . systems, information set , let R[I] consist runs go
information set I. Note moves I, R[I] disjoint union
sets form R[Ki (r, m)], runs r local state form (I, a).
define means PS = (R ,
~ ),
~ profile nonstandard probability
measures before, except clause (b), replace requirement
(r | R[Ki (r, m)]) > 0 st(i (r | R[Ki (r, m)])) > 0, moves information set
associated (r, m), strengthen requirement st(i (r | R[I])) > 0.
Since (r | R[I]) convex combination terms form (r | R[Ki (r0 , m)]),
sum taken points (r0 , m) node associated (r0 , m)
(R[Ki (r0 , m)]) > 0, (r | R[Ki (r0 , m)]) = 0 (r, m)
/ Ki (r0 , m), easily follows
st(i (r | R[I])) > 0 st(i (r | R[I])) > 0.
standard probability measures , easy see (R[Ki (r, m)]) > 0
(r | R[Ki (r, m)]) > 0 iff (R[Ki (r, m)]) > 0 (r | R[I]), really
generalization standard definitions.6
Roughly speaking, says compatibility required points
places significant probability moves made strategy used i. (This made
precise proof Theorem 3.9.)
Note since one player moves node w extensive-form game (since
allow moves nature), action profile ~a applying ~a r(m) results

r(m + 1), aj = skip j 6= i. (r, m)
/ [[]]PS test EQj ;
tests true points j moves.
Theorem 3.9 strategy profile ~ perfect equilibrium extensive-form game
perfect recall iff exists (possibly nonstandard) completely mixed behavioral strategy

profile ~ 0 differs infinitesimally i0 (R , ~0 ) compatible EQ .
Proof Suppose ~ = (1 , . . . , n ) perfect equilibrium . Theorem 3.8,
exists nonstandard completely mixed strategy profile ~ 0 differs infinitesimally
0 relative ~
~ best response
0 , player = 1, . . . , n.

show PS = (R , ~0 ) compatible EQ . Suppose information set
= Ki (r, m) associated (r, m) one moves, st(~0 (r | R[I])) > 0.
(Note since ~ 0 completely mixed, guaranteed ~0 (R[I]) > 0.) Let
6. reader may wonder take ri (m) information set, rather
include action plans do. former choice would simplified discussion
above, kb program EQ meaningful, know action do. Note
considering information two stages: tossed coin
determine next action, tossed it. conditioning information
tossed coin, even though local state models situation tossed coin. Using
intuition extend definition compatibility beyond scope systems form R ,
long system generated players running randomized programs (like behavioral strategies),
although making precise beyond scope paper.

160

fiA Procedural Characterization Game Concepts

action encoded ri (m); is, action plans play (r, m). Since
st(~ (r | R[I])) > 0, must case action given positive standard
probability (completely mixed) distribution i0 (I). Since ~ perfect equilibrium,
Theorem 3.8 best response relative ~ . Let = [i0 , I, ].
definition, agree actions I. Since gives positive standard
probability I, . Theorem 3.6, must least good response
0 , action a0 play I. Since gives positive standard
[I/a0 ] ~i

0 action
probability, [I/a] must least good response [I/a0 ] ~i
0
0
, conditional reaching using ~ . easy see expected utility [I/a]
(resp., [I/a0 ]) conditional reaching value EUi (a) (resp., EUi (a0 ))
point (r, m). Thus, (r, m) [[EUi (a) EUi (a0 )]]PS , PS compatible EQ .
converse, suppose ~ 0 completely mixed behavioral strategy profile

differs infinitesimally i0 (R , ~0 ) compatible EQ . Let
~ = st(~ 0 ). Again, let = [i0 , I, ]. Theorems 3.8 3.6, suffices show
information set player action a0 play I, strategy
0 conditional reached using ~
least good response [I/a0 ] ~i
0 .
this, suffices show action support (I) = (I), strategy
0 conditional reached using
[I/a] least good response [I/a0 ] ~i
~ 0 . fix information set player moves suppose support
(I). Let r history reaches = Ki (r, m) plays
players play action given positive standard probability ~ (and hence also
~ 0 ) points preceding (r, m). Thus, st(~ (r | R[I])) > 0. Since PS compatible
EQ , must case (r, m) [[EUi (a) EUi (a0 )]]PS . first half
0 conditional
proof, follows [I/a] least good response [I/a0 ] ~i
reached using ~ 0 . Thus, ~ perfect equilibrium.
3.2.3 Sequential Equilibrium
next characterize sequential equilibrium terms EQ . Recall sequential equilibrium (Kreps & Wilson, 1982) assessment, pair (~ , ), ~ behavioral
strategy profile belief system, is, function determines every information set probability histories I. Intuitively, information set
player i, subjective assessment relative likelihood histories
I. Roughly speaking, assessment sequential equilibrium (a) every information set player moves chooses best response given beliefs
histories information set strategies players, (b) beliefs
consistent strategy profile played. omit formal definition here,
instead use characterization sequential equilibrium due Halpern (2009).
Theorem 3.10 (Halpern, 2009, 2013) assessment (~ , ) sequential equilibrium
extensive-form game perfect recall iff exist infinitesimal
nonstandard completely mixed strategy profile ~ 0 differs infinitesimally ~
-best response relative ~ , player i.
difference sequential equilibrium perfect equilibrium characterization perfect equilibrium must best response relative
161

fiHalpern & Moses

~ sequential equilibrium, need -best response infinitesimal . capture difference, dealing sequential equilibrium, reinterpret
formula EUi (a) EUi (a0 ) ignore infinitesimal differences. Thus, formula
true unless st(EUi (a0 ) EUi (a)) > 0 (or, equivalently, true standard part
expected utility using greater equal standard part expected

utility using a0 ). PS st-compatible EQ (standing compatible respect


standard values) PS compatible EQ reinterpretation EQ . Clearly,
probability distributions PS standard, notions compatibility

st-compatibility EQ PS coincide.
Theorem 3.11 assessment (~ , ) sequential equilibrium finite extensiveform game perfect recall iff exists (possibly nonstandard) completely mixed strategy

profile ~ 0 differs infinitesimally i0 (R , ~0 ) st-compatible EQ .
Proof proof almost identical Theorem 3.9, replacing best response
-best response, compatible st-compatible. leave details reader.

3.2.4 Subgame-Perfect Equilibrium
Subgame-perfect equilibrium, defined Selten (1965), usually considered games
perfect information, information sets singletons. games perfect information, subgame perfection, sequential equilibrium, trembling-hand perfect equilibrium
agree, need provide separate characterization. However, subgame
perfection actually defined arbitrary games perfect recall.
Given game perfect information node w , subtree rooted w
determines subgame denote w if, every information set includes
node w0 w , nodes w . example, subtree
game e Figure 2 determine subgame, since information set {w2 , w3 }
includes node w2 (namely, w2 itself), w3 w2 .
strategy profile ~ subgame-perfect equilibrium if, every subgame w , ~ restricted
nodes w Nash equilibrium w . Note subgame perfection places
requirements action played nodes determine subgames, beyond
fact action must part Nash equilibrium nodes higher tree
determine subgames.
use program much like EQ characterize subgame-perfect equilibrium
arbitrary games perfect recall. need make two changes EQ . First,
need say best response required points subgame holds,
(r, m) [[subgame]]PS node w associated (r, m) determines subgame. (Note
[[subgame]]PS consists points game perfect information.) Second, need
say constraints points subgame hold. So,
action Ai (), two lines form
V
Ki (intendi (a) subgame a0 Si (A) EUi (a) EUi (a0 )) play
V
Ki (intendi (a) a0 Si (A) EUi (a) EUi (a0 )) play a.
Call resulting program SUBEQi .
162

fiA Procedural Characterization Game Concepts

changes make clear subgame perfect somewhat awkward notion
games players perfect information. case, change,
analogue Theorem 3.9 holds subgame perfect equilibria.
Theorem 3.12 strategy profile ~ subgame-perfect equilibrium extensiveform game perfect recall iff exists (possibly nonstandard) completely mixed
behavioral strategy profile ~ 0 differs infinitesimally i0 (R , ~0 )
subgame compatible SUBEQ .
omit proof here, similar spirit Theorem 3.9.

4. Discussion Conclusions
essential intuition many solution concepts (it common knowledge that)
players making best response beliefs. shown procedural

intuition captured single knowledge-based program, denoted EQ . differences solutions concepts lies differences assumptions players
beliefs counts best response.
Nash equilibrium, players believe mixed strategy profile played (and
common belief one is).
correlated equilibrium, players believe correlated strategy profile
played (and common belief one is).
perfect equilibrium, viewed believing nonstandard completely
mixed strategy profile played (and common belief one
is), caring happens situations positive standard probability.
sequential equilibrium, similarly viewed believing nonstandard
completely mixed strategy profile played (and common belief
one is), caring happens states positive standard
probability best responses respect standard differences (an better
response infinitesimal viewed better).
rationalizability, different players may hold different beliefs strategy
profile played.
unification given kb programs arguably give insight, clearly
significant amount overhead kb program framework. certainly reasonable
ask whether worth dealing overhead get unification, given
intuitions certainly well understood game-theory literature.
sole advantage using kb programs prove theorems paper,
perhaps answer no, believe kb program framework offers
much game theory unification. one thing, kb programs
capture intuition best response generally. give examples here:
163

fiHalpern & Moses

Dealing moves nature: assumed simplicity
moves nature extensive-form games analyzed. deal moves
nature, first expand notion global state includes local
state nature, local states players. think natures
local state consisting current node game tree. addition, think
nature, like players, following behavioral strategy (where natures move
depends local state). minor changes, results still go through,
change. particular, theorems paper continue hold even
games nature moves, change proof.
Bayesian games: Bayesian game, players types. think type
description players private information. assumed commonlyknown distribution type profiles. strategy viewed function
types actions. players utility depends action profile type
profile. standard solution concept considered Bayesian games Bayes-Nash
equilibrium. Bayes-Nash equilibrium, player wants switch different
strategy, since results lower expected utility (see Osborne & Rubinstein,
1994, details). capture Bayes-Nash equilibrium framework.
players local state would include players type, run characterized strategy profile type profile. means set runs
R larger. changes, analogue Theorem 3.1 holds Bayes-Nash
equilibrium.
Beyond expected utility maximization: solution concepts considered paper based maximizing expected utility. also consider solution concepts based decision criteria. example, Boutilier
Hyafil (2004) consider minimax-regret equilibria, player uses strategy
best-response minimax-regret sense choices players.
Similarly, use maximin equilibria (Aghassi & Bertsimas, 2006). pointed
Chu Halpern (2003), decision rules viewed instances
generalized notion expected utility, (a) uncertainty represented
plausibility measure, generalization probability measure, (b) utilities elements arbitrary partially ordered space, (c) plausibilities utilities
combined using , generalizations + . interpreting EUi = u
appropriately, capture exotic solution concepts well. Moreover,
applying ideas essentially proof capture solution concepts games game common knowledge, players
aware available moves, discussed Halpern Rego (2013).
results mentioned straightforward, much spirit
results already shown. interesting situation arises consider games
imperfect recall. Part overhead framework need specify exactly
players local states are, is, know. context games
perfect recall, perhaps important, move games imperfect
recall, becomes highly significant. Consider single-player game depicted Figure 3,
first introduced Piccione Rubinstein (1997).
164

fiA Procedural Characterization Game Concepts

x0
.5

.5
z0



x2

x1

z1



2

2

B

B
x3
L
z2

R

L

6

2

z3
3

X

x4
R
z4

z5
4

Figure 3: game imperfect recall.
hard show strategy maximizes expected utility example
chooses move node x1 , move B node x2 , move R information set X
consisting x3 x4 . Call strategy . Let 0 strategy choosing move B
x1 , move x2 , move L X. Piccione Rubinstein argue node x1
reached, player reconsider, decide switch 0 . indeed
leads better payoff, resulting strategy (i.e., starting switching 0
x2 , x2 reached) legal strategy original game; player moves left x3
right x4 , although two nodes information set.
question players local state becomes critical. include
players behavior strategy local state modeled extensive-form,
could done change. Suppose game imperfect recall.
First note include players strategy local state, system R
corresponding game, h history ending z5 , point (rh , 2), player
knows x4 , despite information set. instance general
phenomenon: game imperfect recall, strategy player using gives
information node information set at. cannot happen game
perfect recall.
Suppose ease exposition include players strategy local state.
happens player switches strategy. local state change then?
local state includes new strategy (whether includes original strategy),
set runs arises player sticks x2 , switches 0 x1 ,
player reaches x3 , knows x3 , reaches x4 , knows
x4 . information set correctly representing players knowledge all!7
key point runs-and-systems framework forces modeler consider
questions like whether player able keep track changes strategy; moreover,
answers must reflected choice local state. recent work
7. point already made Halpern (1997).

165

fiHalpern & Moses

defining notions like sequential equilibrium games imperfect recall (see, e.g., Halpern
& Pass, 2011b; Kline, 2005; Marple & Shoham, 2012). believe program EQ
and, generally, use runs-and-systems framework provide insight
problem.
Interesting new issues arise add computation picture. Equilibrium
notions take computation account considered Halpern Pass
(2011a). seems notion computational Nash equilibrium defined Halpern
Pass, players choose Turing machine play them, captured using EQ
well. because, roughly speaking, charge computation
Turing machine best response Turing machines chosen
players. impose cost, might need computational
algorithmic notions knowledge (such notions discussed Fagin et al., 1995, ch. 10).
conclude two directions research. First, although
focused using kb programs characterize solution concepts here, idea agents
actions depend knowledge beliefs seems like natural way characterize
strategies games, meta-strategies classes games. Sayings look
leap trust, verify really shorthand knowledge-based programs.
believe useful insights agents play games gained thinking
knowledge level way. Indeed, preconditions actions depend
knowledge belief; agents utility also depend beliefs.
key insight psychological games (Geanakoplos, Pearce, & Stacchetti, 1989). would
interesting extend knowledge-based programs knowledge-based utilities.
Finally, although talked kb programs procedural, fact,
procedure given calculation relevant knowledge, really amounts
best-response computation. non-probabilistic setting, conditions
kb program implemented unique standard program (i.e., one without tests
knowledge) shown Fagin et al. (1995, Section 7.2). results carry
probabilistic systems (since give indication compute relevant
probabilities). Nevertheless, given beliefs, kb programs viewed defining
agent act. computing equilibrium, beliefs typically determined
strategy profile. is, start beliefs determine act.
Rather, solutions concepts considered here, fixed point:
beliefs determine strategies (each players strategy best response beliefs),
strategies determine beliefs. However, believe that, applications
kb programs, may well possible view kb program providing procedural
specification. leave topic research.

Acknowledgments
thank reviewers perceptive comments, led many improvements
paper. material paper appeared preliminary form (Halpern &
Moses, 2007). Joe Halperns work paper supported part NSF grants
IIS-0534064, IIS-0812045, IIS-0911036, CCF-1214844, AFOSR grants FA9550-08-10438 FA9550-09-1-0266, DoD Multidisciplinary University Research Initiative
(MURI) program administered AFOSR grant N00014-01-1-0795, ARO
166

fiA Procedural Characterization Game Concepts

grant W911NF-09-1-0281. Yoram Moses Israel Pollak academic chair Technion;
work supported part Israel Science Foundation grant ISF 1520/11.

References
Aghassi, M., & Bertsimas, D. (2006). Robust game theory. Mathematical Programming,
Series B, 107 (12), 231273.
Aumann, R. J. (1974). Subjectivity correlation randomized strategies. Journal
Mathematical Economics, 1, 6796.
Aumann, R. J. (1987). Correlated equilibrium expression Bayesian rationality.
Econometrica, 55, 118.
Aumann, R. J., & Brandenburger, A. (1995). Epistemic conditions Nash equilibrium.
Econometrica, 63 (5), 11611180.
Benthem, J. van (2007). Rational dynamics epistemic logic games. International
Game Theory Review, 9 (1), 1345. (Reprinted corrections International Game
Theory Review, 9:2, 377-409.).
Benthem, J. van (2010). Modal Logic Open Minds. Center Study Logic
Information-Lecture Notes.
Bernheim, B. D. (1984). Rationalizable strategic behavior. Econometrica, 52 (4), 10071028.
Bonanno, G. (2002). Modal logic game theory: two alternative approaches. Risk
Decision Policy, 7, 309324.
Brafman, R. I., Latombe, J.-C., Moses, Y., & Shoham, Y. (1997). Applications logic
knowledge motion planning uncertainty. Journal ACM, 44 (5),
633668.
Brandenburger, A., & Dekel, E. (1987). Rationalizability correlated equilibria. Econometrica, 55, 13911402.
Bruin, B. de (2010). Explaining Games: Epistemic Programme Game Theory, Vol.
346. Synthese Library.
Chu, F., & Halpern, J. Y. (2003). Great expectations. Part I: customizability
generalized expected utility. Proc. Eighteenth International Joint Conference
Artificial Intelligence (IJCAI 03), pp. 291296.
Dwork, C., & Moses, Y. (1990). Knowledge common knowledge Byzantine environment: crash failures. Information Computation, 88 (2), 156186.
Fagin, R., Halpern, J. Y., Moses, Y., & Vardi, M. Y. (1995). Reasoning Knowledge.
MIT Press, Cambridge, Mass. slightly revised paperback version published
2003.
167

fiHalpern & Moses

Fagin, R., Halpern, J. Y., Moses, Y., & Vardi, M. Y. (1997). Knowledge-based programs.
Distributed Computing, 10 (4), 199225.
Geanakoplos, J., Pearce, D., & Stacchetti, E. (1989). Psychological games sequential
rationality. Games Economic Behavior, 1 (1), 6080.
Hadzilacos, V. (1987). knowledge-theoretic analysis atomic commitment protocols.
Proc. 6th ACM Symposium Principles Database Systems, pp. 129134.
Halpern, J. Y. (1997). ambiguities interpretation game trees. Games
Economic Behavior, 20, 6696.
Halpern, J. Y. (2009). nonstandard characterization sequential equilibrium, perfect
equilibrium, proper equilibrium. International Journal Game Theory, 38 (1),
3750.
Halpern, J. Y. (2013). nonstandard characterization sequential equilibrium, perfect
equilibrium, proper equilibrium: Erratum. Unpublished manuscript.
Halpern, J. Y., & Moses, Y. (2007). Characterizing solution concepts games using
knowledge-based programs. Proc. Twentieth International Joint Conference
Artificial Intelligence (IJCAI 07), pp. 13001307.
Halpern, J. Y., & Moses, Y. (2010). Characterizing solution concepts games using common knowledge rationality. Unpublished manuscript.
Halpern, J. Y., Moses, Y., & Waarts, O. (2001). characterization eventual Byzantine
agreement. SIAM Journal Computing, 31 (3), 838865.
Halpern, J. Y., & Pass, R. (2011a). Algorithmic rationality: Game theory costly computation.. Available www.cs.cornell.edu/home/halpern/papers/algrationality.pdf;
appear, Journal Economic Theory. preliminary version title Game
theory costly computation appears Proc. First Symposium Innovations
Computer Science, 2010.
Halpern,
J. Y., & Pass,
R. (2011b).
Sequential equilibrium
games imperfect recall.
Unpublished manuscript;
available
www.cs.cornell.edu/home/halpern/papers/imperfect.pdf.




Halpern, J. Y., & Rego, L. C. (2013). Extensive games possibly unaware players.
Mathematical Social Sciences. appear.
Halpern, J. Y., & Zuck, L. D. (1992). little knowledge goes long way: knowledge-based
derivations correctness proofs family protocols. Journal ACM,
39 (3), 449478.
Harrenstein, P., Hoek, W. van der, Meyer, J.-J. C., & Witteveen, C. (2002). modal
logic interpretations games. ECAI, pp. 2832.
168

fiA Procedural Characterization Game Concepts

Hyafil, N., & Boutilier, C. (2004). Regret minimizing equilibria mechanisms games
strict type uncertainty. Proc. Twentieth Conference Uncertainty Artificial Intelligence (UAI 2004), pp. 268277.
Kline, J. J. (2005). Imperfect recall relationships solution concepts
extensive games. Economic Theory, 25, 703710.
Kreps, D. M., & Wilson, R. B. (1982). Sequential equilibria. Econometrica, 50, 863894.
Lang, J., & Zanuttini, B. (2012). Knowledge-based programs plansthe complexity
plan verification. Proceedings 20th European Conference AI (ECAI 2012),
pp. 504504.
Lang, J., & Zanuttini, B. (2013). Knowledge-based programs plans: succinctness
complexity plan existence. Theoretical Aspects Rationality Knowledge:
Proc. Fourteenth Conference (TARK 2013), pp. 138147.
Lorini, E., & Schwarzentruber, F. (2010). modal logic epistemic games. Games, 1 (4),
478526.
Marple, A., & Shoham, Y. (2012). Equilibria finite games imperfect recall. Unpublished manuscript.
Mazer, M. S. (1990). link knowledge communication faulty distributed
systems. Theoretical Aspects Reasoning Knowledge: Proc. Third Conference, pp. 289304.
Mazer, M. S., & Lochovsky, F. H. (1990). Analyzing distributed commitment reasoning
knowledge. Tech. rep. CRL 90/10, DEC-CRL.
Moses, Y., & Kislev, O. (1993). Knowledge-oriented programming. Proc. 12th ACM
Symposium Principles Distributed Computing, pp. 261270.
Moses, Y., & Tuttle, M. R. (1988). Programming simultaneous actions using common
knowledge. Algorithmica, 3, 121169.
Neiger, G., & Bazzi, R. (1992). Using knowledge optimally achieve coordination distributed systems. Theoretical Aspects Reasoning Knowledge: Proc. Fourth
Conference, pp. 4359.
Neiger, G., & Toueg, S. (1993). Simulating real-time clocks common knowledge
distributed systems. Journal ACM, 40 (2), 334367.
Osborne, M. J., & Rubinstein, A. (1994). Course Game Theory. MIT Press, Cambridge, Mass.
Pearce, D. G. (1984). Rationalizable strategic behavior problem perfection.
Econometrica, 52 (4), 10291050.
Piccione, M., & Rubinstein, A. (1997). interpretation decision problems
imperfect recall. Games Economic Behavior, 20 (1), 324.
169

fiHalpern & Moses

Reiter, R. (2001). knowledge-based programming sensing situation calculus.
ACM Transactions Computational Logic, 2 (4), 433457.
Selten, R. (1965).
Spieltheoretische Behandlung eines Oligopolmodells mit Nachfragetragheit. Zeitschrift fur Gesamte Staatswissenschaft, 121, 301324 667689.
Selten, R. (1975). Reexamination perfectness concept equilibrium points extensive games. International Journal Game Theory, 4, 2555.

170

fiJournal Artificial Intelligence Research 49 (2014) 363-402

Submitted 09/13; published 02/14

Multiagent Knowing Dynamic Systems
Vaishak Belle

vaishak@cs.toronto.edu

Dept. Computer Science, University Toronto,
Toronto, Ontario, Canada M5S 3H5

Gerhard Lakemeyer

gerhard@cs.rwth-aachen.de

Dept. Computer Science, RWTH Aachen University,
52056 Aachen, Germany

Abstract
idea knowing collection sentences, proposed Levesque, previously shown useful characterizing knowledge-based agents: terms specification,
precise perspicuous account beliefs non-beliefs obtained monotonic setting.
Levesques logic based first-order modal language quantifying-in, thus allowing
de versus de dicto distinctions, among things. However, logic recent dynamic
extension deal case single agent. work, propose first-order multiagent framework knowledge, actions, sensing knowing, shown inherit
features single agent version. significantly, prove reduction theorems means
reasoning knowledge actions framework simplifies non-epistemic,
non-dynamic reasoning initial situation.

1. Introduction
considering knowledge-based agents dynamic worlds, much depends known
not, evolves. Making telephone call, example, requires knowing
referent, number known, lookup telephone directory must attempted,
agent would sufficient information complete task. Essentially, agent
deliberates act sensing agents knowledge base (KB) informs agent
ignorant fact, perhaps one necessary achieving goal. Moreover, taking
pragmatic point view, desirable designing agents, modeler would provide
certain facts may leave others unsaid. Think simple blocks world domain find
red block table. agent would told red block, absence complete
description location every block domain, agent make partial
information. Thus, least, needed compact way write knowledge
base, thereby providing full specification beliefs non-beliefs, account
changes acting sensing, query language explicitly refers knowledge.1
One way view first requirement think beliefs agent exactly
follow assumption KB believed. Perhaps general account
capture beliefs KB OL: logic knowing Levesque (1990). Levesques
proposal remarkably simple. augments logic belief (Hintikka, 1962; Kripke, 1963; Fagin,
1. use terms knowledge belief interchangeably understanding knowledge need necessarily true real world.
c
2014
AI Access Foundation. rights reserved.

fiBelle & Lakemeyer

Halpern, Moses, & Vardi, 1995), (say) modality K denotes knowledge, modality
capture notion knowing. Beliefs reasoned terms valid sentences
form:
OKB K
read KB believed agent, agent knows .
particularly interesting new modality allows one draw conclusions known also not. is, p Kq and, introspection, p KKq come valid. Note quite different classical epistemic
logic (Fagin et al., 1995), sense replace K, neither sentences
valid. consequence, example, O(Tel(A, 1234) Tel(B, 1234)) agent concludes
K(x. Tel(x, 1234) KTel(x, 1234)). says agent knows someone whose
telephone number 1234 without knowing who, usually referred de dicto versus de
distinctions knowledge (Kaplan, 1968). Thus, agent able reason ignorance,
quantificational language, without told explicitly know.
OL capture desiderata beliefs, include notions actions.
obtain many features OL dynamic setting, logic ES (Lakemeyer & Levesque, 2011)
proposed amalgamates OL situation calculus (McCarthy & Hayes, 1969; Reiter,
2001; Scherl & Levesque, 2003). situation calculus popular general formalism
representing reasoning dynamic domains. ES (situation-suppressed) modal dialect
situation calculus2 formulas like traditional dynamic logic (Harel, Kozen, &
Tiuryn, 2000),
[pickup(obj5)](Holding(obj5) Holding(obj3))
says picking obj5, agent holding obj5 obj3. ES, one stipulates
set axioms capturing application domain known agent,
obtains entailments regarding beliefs, non-beliefs, belief expansion resolve agents
ignorance acts perceives environment. example,
= {SF(senseFragility(x)) Fragile(x)},
roughly says sequence actions, agent perform fragility sensing
action, SF would inform robot whether object sensed fragile not. obj5 object
fragile real world, ES allows us reason entailments sort:
1. |= Fragile(obj5) K(Fragile(obj5));
2. |= Fragile(obj5) [senseFragility(obj5)]K(Fragile(obj5));
which, English, says although agent know obj5 fragile initially,
sensing.
ES allows Reiter-style basic action theories, also equipped important
result (Reiter, 2001; Scherl & Levesque, 2003): regression theorem knowledge.
2. certain assumptions, valid sentences ES mapped valid sentences classical situation calculus (Lakemeyer & Levesque, 2011). is, ES serve semantic basis situation calculus
workable model theory.

364

fiMultiagent Knowing Dynamic Systems

is, sentences goals future, even mentioning belief, reduced questions
(perhaps involving knowledge) initial state only. importantly, significant result
OL called representation theorem (Levesque & Lakemeyer, 2001) leveraged
reduce epistemic queries initial state first-order reasoning task. effect, modal
reasoning necessary.
However, ES deals single agent case. Many AI applications formalisms needed involve multiple agents. might imagine robot following lead another agent, perhaps second robot, coordinate deliveries items rooms.
Similarly, imagine two agents playing game cards other. others,
modeling reasoning beliefs non-beliefs agents real world
agents world interest. case card game, example, especially fair
one, agents might believe initially opponents know rules game.
might justify certain strategies depend lack information opponents part.
extending ES multiagent case, however, first need account knowing
multiagent case. number previous proposals (Lakemeyer, 1993; Halpern, 1993;
Halpern & Lakemeyer, 2001; Waaler & Solhaug, 2005) attempted multiagent extensions
OL, propositional. Besides, significantly deviate Levesques simple model
theory. recent work (Belle & Lakemeyer, 2010a), able show natural generalization OL n-agent case exist first-order language. article, continue
line work propose n-agent generalization ES.3 projection problem (Reiter,
2001), interested reasoning goals (perhaps involving multiagent beliefs)
actions, show regression property provable. Finally, also obtain representation
theorem n-agent case means modal reasoning necessary. survey
related literature greater detail Section 5 results differ existing results
epistemic situation calculus (Scherl & Levesque, 2003), extends situation calculus
notion knowledge realized terms accessibility relation situations.
(That is, situations viewed possible worlds.) instance, regression property different
previous multiagent generalizations (Shapiro, Lesperance, & Levesque, 2002; Kelly & Pearce,
2008) epistemic situation calculus background theory may involve nesting
knowing operators, Alice knows Bob knows rules game.
Capturing multiagent knowing possible-world models include explicit accessibility relations worlds (Fagin et al., 1995), required classical epistemic situation calculus,
known problematic (Halpern & Lakemeyer, 2001; Belle & Lakemeyer, 2010a),
statements obvious counterparts previous proposals. Similarly, reduction
knowledge first-order reasoning investigated restricted setting Reiter (2001),
single agent case only.
paper structured follows. first introduce logic, followed discussion basic
action theories. Subsequently, prove regression property generalized representation
theorem. end discussing related work. Appendices contain proofs main results,
is, regression property representation theorem.

3. preliminary version work appears proceedings Twenty-Fourth AAAI Conference Artificial
Intelligence, Atlanta, Georgia, USA, July 11-15, 2010 (Belle & Lakemeyer, 2010b).

365

fiBelle & Lakemeyer

2. Formalism
let ESn first-order modal language consisting formulas symbols following
vocabulary:
first-order variables object sort: x1 , x2 , . . . , y1 , y2 , . . .;
first-order variables action sort: a1 , a2 , . . .;
fluent predicates arity k: F1 , F2 , . . .; example, Wet;
rigid predicates arity k: G1 , G2 , . . .; example, Fragile;
fluent function symbols arity k: f1 , f2 , . . .; example, distance;
rigid function symbols arity k: g1 , g2 , . . .; example, pickup, senseColor;
countably infinite standard names: # 1, # 2, . . . objects actions;
connectives symbols: =, , , , Ki , Oi , [a], , parenthesis, period comma.
following, ease exposition, assume {A, B} Ki Oi , is, two
agents B. extension agents straightforward.
remark standard names rigid designators, is, mean entity
possible worlds (see below). thought constants satisfying unique
name assumption infinitary version domain closure. symbols means
quantification understood substitutionally. Readers familiar classical situation calculus (Reiter, 2001) may note situation terms appear language. Therefore,
distinguish fluents, whose values change actions, rigids, whose values not,
syntactically well semantically. ESn also assumed contain distinguished predicate Poss
distinguished functions SFi , take action argument. Essentially, Poss(a)
says executable; SFi (a) refers agent sensing outcomes performing a, shown
single agent case previous section using fragility sensing action. Section 3 discuss
detail multiple agents.
terms ESn sort action object, least set that:
every standard name first-order variable term corresponding sort;
t1 , . . . , tk terms (of sort) f k-ary function, f (t1 , . . . , tk ) term.
primitive term, mean one form f (n1 , . . . , nk ) f (fluent rigid) function
symbol ni standard names.
well-formed formulas ESn form least set that:
t1 , . . . , tk terms, F k-ary predicate symbol F(t1 , . . . , tk ) (atomic)
formula;
t1 t2 terms, (t1 = t2 ) formula;
366

fiMultiagent Knowing Dynamic Systems

action term formula [t] formula;
formulas, x first-order variable following also formulas:
, , x, , Ki , Oi .
usual, treat connectives abbreviations. is, abbreviates , abbreviates ( ) ( ).
ESn two epistemic modalities. read Ki knows , read Oi
knows . ESn also includes dynamic modalities. read [a] holds
read holds possible action sequences.
formula without free variables called sentence. also refer certain kinds
formulas following terminology:
formula operators called bounded.
formula [t] operators called static.
formula mention Oi called basic. (The formula may mention KA
KB .)
formula Ki , Oi , [t], Poss SFi called fluent.4
example, P(# 1) [t]KA P(# 2) bounded, static; P(# 1) KA P(# 2) static basic,
fluent formula; P(# 1) OA P(# 2) Poss(t) static formula, neither basic
formula fluent formula; (P(# 1) P(# 2)) Q( f (# 3)) fluent formula.
2.1 Semantics
semantics provided terms possible worlds. purpose semantics determine
values fluents, initially sequence actions. Therefore, ESn , similar
idea situation trees (Reiter, 2001), worlds determine changing values fluents
actions; see Figure 1 intuition. precisely,
let Z denote finite sequences action names, including hi, empty sequence
(corresponding initial situation);
world w W function G Z {0, 1}, G set primitive
atoms, Z N (preserving sorts), set primitive terms,
satisfying rigidity constraint: g rigid function predicate symbol, z
z0 Z, w[g(n1 , ..., nk ), z] = w[g(n1 , ..., nk ), z0 ].
interpret arbitrary terms, proceed follows. mentioned earlier, names rigid
designators. Given term without variables, world w sequence z, define |t|zw (to read
co-referring standard name given w z) by:
1. |t|zw = name;
4. situation calculus (Reiter, 2001), correspond formulas uniform situation term.

367

fiBelle & Lakemeyer

p, q, . . .

a1

p, q, . . .

ak

a1

p, q, . . .

...

..
.

hi

a2

p, q, . . .

ak

...

ak

a1

...

..
.

p, q, . . .

a1

ak

...

..
.

Figure 1: possible world.
2. | f (t1 , . . . , tk )|zw = w[ f (n1 , . . . , nk ), z], |ti |zw = ni .
Agents may, course, incomplete knowledge. distinguish uncertainty real
world, stipulate epistemic states model multiple possibilities. Standard accounts multiagent epistemic states based Kripke frames (Fagin et al., 1995). multiagent knowing,
however, Kripke-based accounts turn problematic, seen work Halpern
(1993), Lakemeyer (1993), Halpern Lakemeyer (2001) Waaler Solhaug (2005).
example, Lakemeyer (1993) shows certain types epistemic states cannot constructed
approach. work Halpern (1993), epistemic operators interact intuitive
manner (Halpern & Lakemeyer, 2001). work Halpern Lakemeyer (2001), semantic
notion validity defined directly language, making proposal unnatural. Serious complications present later proposals well (Waaler & Solhaug, 2005). Moreover, none
extended quantified language. discussion issues needed purposes article; interested readers referred earlier work (Belle & Lakemeyer, 2010a).
work, proposed alternative called k-structures, shown generalize
Levesques (1990) proposal many agent case appropriate intuitive manner.
structures deviate Kripke-based accounts defining epistemic states increasing depths.
turns out, structures also natural extension dynamic setting, present
below. first define notion depth formulas following way:
Definition 1 i-depth ESn , denoted ||i , defined inductively (Mi denotes Ki Oi ):
||i = 1 atomic formulas;
||i = ||i ;
368

fiMultiagent Knowing Dynamic Systems

|x|i = ||i ;
|[a]|i = ||i ;
||i = ||i ;
| |i = max(||i , ||i );
|Mi |i = ||i ,
|M j |i = || j + 1 j , i.
formula depth k max(||A , ||B ) = k.
Given formula A-depth k B-depth j, say formula A, B-depth k, j
brevity. say objective epistemic operators mentioned . formula called
i-objective epistemic operators occur within scope another epistemic
operator form j , j , i, Mi denotes Ki Oi . formula called i-subjective
every atom scope epistemic operator epistemic operators occur
within scope another epistemic operator form Mi . Intuitively, i-subjective formulas
represent beliefs world whereas i-objective formulas determine true
world perspective, may include beliefs agents i.
Example 2 Consider formula KA KB KA p KB [t]q. Here:
|KA KB KA p KB [t]q|A = max(|KA KB KA p|A , |KB [t]q|A ) = 3
1. |KA KB KA p|A = |KA KB KA p|A = |KB KA p|A = 1 + |KA p|B = 2 + |p|A = 3,
2. |KB [t]q|A = 1 + |[t]q|B = 1 + |q|B = 2.
|KA KB KA p KB [t]q|B = max(|KA KB KA p|B , |KB [t]q|B ) = 4
1. |KA KB KA p|B = |KA KB KA p|B = 1 + |KB KA p|A = 1 + 3 (as shown above) = 4,
2. |KB [t]q|B = |[t]q|B = |q|B = 1.
Therefore, depth formula 4. Consider disjuncts. KA KB KA p
A-subjective well B-objective. hand, KB [t]q B-subjective well
A-objective. Moreover, KA KB KA p KB [t]q neither A-subjective B-subjective.
matter, neither A-objective B-objective.
beliefs agent captured means k-structure defined set W:
Definition 3 k-structure ek , k 1, defined inductively as:
e1 W {{}},
ek W Ek1 , Em set m-structures.
369

fiBelle & Lakemeyer

is, e1 simply set worlds. e2 set form {(w, e1 ), (w0 , e0 1 ), . . .} states
w agent, say A, believes B consider worlds e1 possible, w0 believes B
consider worlds e0 1 possible. captures intuition partial information
B, beliefs B differ different worlds.5 modeling k-structure, say ek ,
j
denote ekA . Analogously, modeling j-structure, say e j , B denote eB .
structures essentially represents initial beliefs agent, is, initial state
knowledge. actions occur, perhaps agent acquires new information result
possibilities epistemic state may discarded course
actions (Scherl & Levesque, 2003). Following Lakemeyer Levesque (2011), capture
feature means compatibility relation 'iz worlds (relative agent i), looks
truth real world means sensing. define w0 'iz w inductively following:
w0 'ihi w worlds w0 w;
w0 'izr w iff w0 'iz w w0 [SFi (r), z] = w[SFi (r), z].
j

define ek A, e j B world w (k, j)-model (ekA , eB , w). idea
formulas maximal A-depth k maximal B-depth j interpreted wrt
(k, j)-models. determine whether formula true sequence actions z given
j
(k, j)-model, write ekA , eB , w, z |= . definition truth follows:
j

1. ekA , eB , w, z |= P(t1 , . . . , tk ) iff w[P(n1 , . . . , nk ), z] = 1 |ti |zw = ni ;
j

2. ekA , eB , w, z |= t1 = t2 iff n1 n2 standard names, |ti |zw = ni ;
j

j

3. ekA , eB , w, z |= iff ekA , eB , w, z 6|= ;
j

j

j

4. ekA , eB , w, z |= iff ekA , eB , w, z |= ekA , eB , w, z |= ;
j

j

j

j

5. ekA , eB , w, z |= x iff ekA , eB , w, z |= nx every name n appropriate sort;
6. ekA , eB , w, z |= [t] iff ekA , eB , w, z r |= |t|zw = r;
j

j

7. ekA , eB , w, z |= iff ekA , eB , w, z z0 |= every z0 Z;
j

8. ekA , eB , w, z |= KA iff w0 'Az w, ek1 (for B),
k
k k1
0
(w0 , ek1
B ) eA eA , eB , w , z |= ;
j

9. ekA , eB , w, z |= OA iff w0 'Az w, ek1 (for B),
k
k k1
0
(w0 , ek1
B ) eA iff eA , eB , w , z |= .

analogous fashion, semantics KB OB specified. Here, Ki classical
epistemic operator. may read Ki (at least) believed Ki certainly
preclude Ki ( ) holding general. hand, Oi holds epistemic
5. Levesques (1990) notion epistemic state simply set worlds. easy see single
agent need 1-structures, coincides Levesques account.

370

fiMultiagent Knowing Dynamic Systems

state one contains structures satisfying . essence (Levesque, 1990),
definition Oi differs Ki using iff rather if.6
j
j
Given sentence maximal A, B-depth k, j, write ekA , eB , w |= mean ekA , eB , w, hi |= .
j
say sentence maximal A, B-depth k, j satisfiable (k, j)-model (ekA , eB , w)
j
ekA , eB , w |= . set sentences maximal A, B-depth k, j above,
j
write |= (read: entails ) iff every (k, j)-model ekA , eB , w |= 0 every
j
0 ekA , eB , w |= . write |= (read: valid) mean {} |= .
j

often write {}, eB , w |= A-objective k-structure irrelevant.
Analogously, B-objective formulas, often write ekA , {}, w |= . formula objective, omit structures B altogether simply write w |= .
2.2 Properties
differ slightly usual semantical accounts satisfaction relation undefined
formulas whose depth exceeds certain number. Nevertheless, able show far
entailment concerned, account present serious limitations. Let us begin
simple examples.
Example 4 Let p atom. following sentences valid. method proving
examples look sentence decide depth models. (We use
TRUE denote tautologous sentence, x. (x = x).)
1. OA TRUE KA KB p.
sentence A-subjective A-depth 2. consider 2-structure satisfies
OA TRUE. one: let e2A = W 2W . Clearly e2A , {}, w |= OA TRUE. (We reiterate
epistemic state B irrelevant, simply write (ekA , {}, w) ignore
structure B.) easy verify e2 satisfies OA TRUE. e2A , {}, w |=
KA KB p iff (w0 , e1B ) e2A e2A , e1B , w0 |= KB p. construction,
(w, e1B ) e2A e1B = {(w, {}) | w |= p} e2A , e1B , w |= KB p.
2. OA TRUE KA KB p.
Construct e2A item 1. e2A , {}, w |= KA KB p iff (w0 , e1B ) e2A ,
e2A , e1B , w0 |= KB p. construction, (w, e1B ) e2A e1B = {(w, {}) | w 6|= p} and,
e2A , e1B , w |= KB p.
3. OA (p OB p) KA p.
consider 2-structure satisfying OA (p OB p) prove KA p also
satisfied structure. let W p = {w | w |= p}. Clearly e1B = {(w, {}) | w W p }
1-structure B satisfies OB p. Similarly, 2-structure e2A = {(w, e1B ) | w W p }
2-structure satisfies OA (p OB p). follows e2A , {}, w |= KA p since
w0 (w0 , e1B ) e2A satisfy p construction.
6. literature, closer examination relationship modalities, third modality denote
agent knows often included logical language (Halpern & Lakemeyer, 2001; Levesque &
Lakemeyer, 2001). modality need concern us here. refer interested readers earlier work
semantics given operator using k-structures (Belle & Lakemeyer, 2010a).

371

fiBelle & Lakemeyer

4. OA (p OB p) KA KB p.
2-structure e2A constructed item 3. follows e2A , {}, w |= KA KB p since
worlds
{w00 | (w00 , {}) e1B (w0 , e1B ) e2A w0 }
satisfy p construction.
5. OA (p OB p) (KA KB KA p KA KB KA p).
Using ideas item 1 2, follows OB p KB KA p KB KA p valid. Let e3A
structure satisfies OA (p OB p). Since (w0 , e2B ) e3A , e3A , e2B , w0 |= p OB p,
follows e3A , e2B , w0 |= KB KA p KB KA p. Therefore e3A , {}, w |= KA (KB KA p
KB KA p).
Items 1 2 tell us knows TRUE, correctly reasons ignorance:
know whether B knows p. Items 3 4 tell us knows {p, OB p},
correctly believes B believe p. Finally, item 5 tells us since believes B
knows p, believes B cannot tell whether knows p.
examples, (appropriately) chose structures certain depth interpret sentences corresponding depth. However, far validity goes, models higher depth
considered. is, formula maximal A, B-depth k, j true (k, j)-models,
formula also true (k0 , j0 )-models, k0 k j0 j. demonstrate property,
0
0
construct every ekA , k-structure eA kk , agree formulas maximal A-depth
k. Analogously, j-structure agrees formulas maximal B-depth j constructed
j0
every eB .
j0

0

j0

0

Definition 5 Given ekA eB , inductively define k-structure eA kk j-structure eB j
k0 k 1 j0 j 1, respectively:
eA 11 = e1A ;
eB 11 = e1B ;
0

0

0

eA k1 = {(w, {}) | (w, ekB 1 ) ekA } k0 > 1;
j0

j0 1

j0

eB 1 = {(w, {}) | (w, eA ) eB } j0 > 1;
0

0

0

0

1
eA kk = {(w, eB kk1
) | (w, ekB 1 ) ekA } k > 1;
j0

j0 1

j0 1

j0

eB j = {(w, eA j1 ) | (w, eA ) eB } j > 1.
0

definition hand, get following property relating k0 -structures ekA j0 0
j0
j0
structures eB , corresponding k-structures eA kk j-structures eB j respectively.
Lemma 6 Let k0 k j0 j. maximum A-depth k maximum B-depth j:
0

j0

0

j0

ekA , eB , w |= iff eA kk , eB j , w |= .
372

fiMultiagent Knowing Dynamic Systems

proof hard, tedious. arguments result appear elsewhere (Belle & Lakemeyer, 2010a), reproduce here.7
Theorem 7 formulas A, B-depth k, j, true (k, j)-models, true
(k0 , j0 )-models, k0 k j0 j.
0

j0

0

j0

Proof: Suppose true (k, j)-models. Given (ekA , eB , w), assumption eA kk , eB j , w |=
0

j0

. previous lemma, ekA , eB , w |= .
follows one may speak valid sentences logic without explicitly speculating depths depths models need be. is, may simply assume
models appropriate depths, sense depths equal exceed depth
sentences. example, obtain following result knowledge k-structures
K45n properties (Fagin et al., 1995), well universal existential versions Barcan
formula. Moreover, properties hold number actions performed.
Lemma 8 Let ESn -formulas. following sentences valid:
1. (Ki Ki ( ) Ki );
2. (Ki Ki Ki );
3. (Ki Ki Ki );
4. (xKi Ki x);
5. (xKi Ki x).
Proof: proofs similar. show item 3 4. Let A. case symmetric.
j

k
3. Suppose ekA , eB , w, z |= KA . w0 'zA w, (w0 , ek1
B ) eA
k1
k
k1
0
00
00

0
00
0
eA , eB , w , z |= . Let w world w 'z w , (w , eB ) ekA . Clearly
j
ekA , e0B k1 , w00 , z |= KA . Since w00 'zA w, get ekA , eB , w, z |= KA KA .
j

j

4. Suppose ekA , eB , w, z |= xKA . ekA , eB , w, z |= (KA )nx every name n. is,
j
k
ekA , eB , w, z |= KA nx every n. w0 'zA w, (w0 , ek1
B ) eA
j
0
x
k k1
0
k
ekA , ek1
B , w , z |= n every n iff definition eA , eB , w , z |= x. Therefore eA , eB , w, z |=
KA x.
Apart K45n belief properties, relationship knowing knowledge
also established using notion validity:
Lemma 9 Suppose p q atoms, ESn -formula. following valid:
7. actions considered work, interpreted wrt worlds extension argument
straightforward.

373

fiBelle & Lakemeyer

1. Oi Ki ;
2. Oi p Ki q.
Proof: Item 1 easy consequence semantics. item 2, observe definition
knowing, structures satisfy p q, must exist p q atoms,
included epistemic state Oi p holds. Therefore q cannot known.
Item 1 says whatever known also believed agent. Item 2, course, relates
knowing non-beliefs. straightforward generalize arguments properties
also capture valid sentences Example 4 involving multiagent nested beliefs.
Finally, specifying agent, want allow agents false beliefs.
permitted, demonstrated means following property shows
possible know (and know) formula false real world, also possible
know (and know) formula true real world.
Lemma 10 Let p atom. following sentences satisfiable (let Mi denote Ki Oi ):
1. p Mi p;
2. p Mi p.
Proof: show Mi = OA . case Mi = OB symmetric. arguments Mi = Ki
analogous. item 1, let w world w |= p, W p = {w0 | w0 |= p}. Let e1A
set {(w0 , {}) | w0 W p }. follows e1A , {}, w |= p OA p.
item 2, suppose w |= p, W0p = W p {w }. Let e1A = {(w0 , {}) | w0 W0p }. Then,
get e1A , {}, w |= p OA p.
concluding section, let us briefly reflect fact k-structures finite
depth. suppose knows , depth k. Using k-structures alone allows us reason
believed believed, depth k. example, OA P(# 1) entails
KA P(# 1), KA P(# 2), KA P(# 3), . . . shown Lemma 9. Moreover, already observed Example 4, logic correctly captures ignorant beliefs depth greater k. is,
using simple example agent knows TRUE depth 1, saw sentences
OA TRUE KA KB p OA TRUE KA KB p valid. So, although KB finite
depth, able ask queries depth sense determining whether sentence
Oi Ki valid.
purposes, restriction parameter k seems harmless sense
agents usually finite knowledge base sentences maximal depth k
ignorant known depths higher k. one aspect cannot
handle: property simultaneously satisfying infinite set sentences unbounded depth.
Indeed, k-structures cannot used purpose simply because, fixed k, satisfaction
relation undefined formulas beyond depth k.
One prominent application property notion common knowledge (Fagin et al.,
1995). go details here, common knowledge modality allows logic
374

fiMultiagent Knowing Dynamic Systems

reason sentences (Ki K j )k , appears scope k sequences Ki K j ,
k. Even though nature common knowledge infinitary, sense essentially
corresponds infinite conjunction, nonetheless given finite axiomatic characterization, making useful operator certain applications (Fagin et al., 1995). Thus,
include notion common knowledge logic, would get entailments
believed arbitrary depths. current model, however, cannot captured.
certainly restriction, willing pay price return get, first time,
simple model theory multiagent knowing (Belle & Lakemeyer, 2010a).

3. Basic Action Theories
Let us consider equivalent basic action theories situation calculus. Since situations
appear language, ES, basic action theories require foundational axioms
like Reiters second-order induction axiom situations (Reiter, 2001).
Definition 11 Given set fluents F , set ESn sentences called basic action theory
(BAT) F iff = 0 pre post sense mentions fluents F and8
1. 0 set fluent sentences;
2. pre singleton sentence form:
Poss(a)
fluent formula;9
3. post set includes sentences form:
[a]F(~x) F ,
one fluent predicate F, sentences form:
[a] f (~x) = u f ,
one fluent function f , F f fluent formulas;10
4. sense set sentences similar one Poss form:
SFi (a) = x ,
one agent i, fluent formula.
8. follow usual convention free variables universally quantified outside.
9. assume lower syntactic precedence logical connectives, Poss(a) stands
a.(Poss(a) ).
10. [a] construct higher precedence logical connectives. is, [a] f (x1 , . . . , xk ) = f abbreviates
a.([a] f (x1 , . . . , xk ) = f ).

375

fiBelle & Lakemeyer

idea 0 expresses true initially, pre one large precondition axiom, post
successor state axioms, one per fluent, formulated incorporate Reiters solution
frame problem. sense accommodates intuition sensing results agents may differ
various actions. example, B senses reading letter, would expect B
learn contents letter. Here, follow convention (Scherl & Levesque, 2003)
every action returns sensing result. actions forward, return sensing
information, SFi defined return special standard name NIL.
Knowledge initial situation may incomplete. precisely, distinguish
true real world agents know believe world.
course, believes world may differ Bs knowledge. Moreover, believes
B know may differ B actually believes. One way capture generality
first insist action theory modeling real world, say . Then, might imagine differing
basic action theories subsequent levels beliefs agents, illustrated following
theory:11
(1)
OA ( OB ( . . .)) OB ( 0 OA ( . . .))
(with superscripts) basic action theories may differ arbitrarily. Here,
represents true real world, (with superscripts) represent agents beliefs.
example, represents believes B know. extension, then, n agents k levels,
would expect n k + 1 action theories, one perhaps differing arbitrarily other.
ease exposition, consider following simple case remainder article.
simple case stipulates represents view world, believes also
represents Bs view world. reasonable applications simple card games,
consider below. None technical results, including regression property
representation theorem, hinge stipulation, however. See Section 4.4 discussions.
background theory, then, special case (1), illustrated following sentence:
OA ( OB ( . . .)) OB ( 0 OA ( 0 . . .))

(2)

where, again, , 0 may differ arbitrarily.
Formally, order prepare agents may beliefs arbitrary (but finite) depth,
introduce following inductive definition basic action theory :
let OKnow [A, 1] = OA ;
let OKnow [B, 1] = OB ;
k > 1, let OKnow [A, k] = OA ( OKnow [B, k 1]);
j > 1, let OKnow [B, j] = OB ( OKnow [A, j 1]).
Given basic action theories , 0 , remainder article interested
theories form
OKnow [A, k] OKnow 0 [B, j]
(3)
11. sequel, background theory stipulations assume nesting knowing operators. possibilities, course, Oi ( (K j K j )). defer discussions Section 4.4.

376

fiMultiagent Knowing Dynamic Systems

says believes action theory k levels, i.e. believes B also believe
on, B believes action theory 0 j levels. presenting technical results
reasoning actions, show example formalism used model
domains, appropriate properties regarding knowledge, introspection sensing.
Example 12 Imagine two agents playing simple card game. imagine deck cards, numbered 1 52. Two face-down cards dealt, one B. Player
picks card, reads card decides challenge player j ( j , i). challenge posed,
player card highest number wins game.
begin stipulating preconditions domain. Let pre following:
Poss(a)
x[a = picki (x) y(Holdingi (y))]
x[a = seei (x) Holdingi (x)]
= challengei TRUE.
English: sensing actions seei explained below, sense assume holding
object. let picki physical action, require object x picked up,
holding anything else. fluent-changing action domain challengei , post
two elements:
[a]Holdingi (x) = picki (x) Holdingi (x).
[a]Losei Losei
= challengei (num(cardi ) < num(card j ))
= challenge j (num(card j ) > num(cardi )).
cardi card dealt i, num rigid function representing cards
number, Losei indicates lost game. is, challenges, would win
higher number.
Let us formalize sensing axioms. reads card, expect discover
number card. Actions public, despite fact B observes reading card, B
expected discover contents card. asymmetry captured letting sense
contain following sentence:
[a]SFi (a) =
x[a = seei (x) = num(x)]
x[a = seei (x) = NIL].
English: sensing results action seei (x) informs number card x,
sensing results every action returns NIL. is, NIL obtained senses
physical actions, well observes j reading card means see j .
Finally, stipulate initial theories, done. let 0 following:
x[Holdingi (x)];
num(cardA ) , num(cardB );
377

fiBelle & Lakemeyer

x[num(x) = # 1 . . . num(x) = # 52];
# 1 < # 2 < # 3 < . . . < # 51 < # 52;
LoseA LoseB .
Here, supposing cardA card dealt, cardB one B
dealt. Basically, 0 says numbers cardA cardB different one
{1, . . . , 52} initially, player lost game.
0 represents initial assumptions game. general, players may access additional information. unfair setting, instance, might imagine B knows card
does. current purposes, however, simply assume 0 believes, well
believes j believe, levels. model real world, let
0 = 0 {num(cardA ) = # 1, num(cardB ) = # 52}.
Letting = 0 pre post sense , letting = 0 , development leads theory
following form:
OKnow [A, k] OKnow [B, j]
(4)
Prior analyzing entailments (4), convenient state lemma regarding model
(4) constructed. that, use notion modal depth formula,
refers epistemic modalities formula.
Definition 13 modal depth formula defined inductively:
modal() = 0 atomic formulas;
modal( ) = max(modal(), modal());
modal(x) = modal();
modal([t]) = modal();
modal() = modal();
modal() = modal();
modal(Mi ) = 1 + modal() Mi {Ki , Oi }.
example, p [t]q, p q atoms, formula mentioning epistemic operators
modal depth 0. KA KB p, contrast, modal depth 2. Essentially, modal
depth simply counts epistemic modalities formula completely ignores indices
modalities. surprisingly, differs i-depth formulas. example, modal
depth KA p 1, |KA p|A 1, |KA p|B 2. contrast, modal depth KA KA p 2,
A-depth 1 B-depth 2, case KA p.
Suppose objective sentence, possibly basic action theory. Let us denote set
worlds {w | w |= } W . Further, let e1 = W {{}}. Let ek = {(w, ek1
) | w W } defined
inductively. Then,
378

fiMultiagent Knowing Dynamic Systems

j

Lemma 14 Suppose objective sentence. Suppose w world e kA e B
j
constructed above. e kA , e B , w |= OKnow [A, k] OKnow [B, j].
Proof: proof induction modal depth background theory, Definition
13 provides. First note modal depth background theory l,
sentence form OKnow [A, k] OKnow [B, j] k l, j l k j l.
Since OKnow [i, k] interpreted wrt epistemic state, treat A-subjective Bsubjective formulas background theory individually. base case theories modal
depth 1, considering sentence form Oi . prove base case, consider
world w0 . Clearly w0 'hi w definition. construction, (w0 , {}) e 1A iff w0 |= . Therefore
e 1A , {}, w |= OA . Analogously e 1B .
Suppose lemma holds background theories modal depth k 1, is, e k1

)


k-structure

satisfies OKnow [A, k 1]. analogously stated B. Let (w0 , e k1
B
0 |= OKnow [B, k 1]. is,
e kA . construction w0 |= . induction hypothesis, {}, e k1
,
w

B
k
k1
0
k
construction, (w0 , e k1
B ) e iff {}, e B , w |= OKnow [B, k 1]. Therefore e , {}, w |=
k
OA ( OKnow [B, k 1]), is, e , {}, w |= OKnow [A, k].
Using lemma, consider properties (4):
Proposition 15 following sentences entailed sentence (4), k > 1 j > 1.
1. KA (num(cardA ) = # 1).
Initially, know details card. (That is, non-beliefs obtained via
knowing.)
2. [pickA (cardA )][seeA (cardA )]KA (num(cardA ) = # 1).
sensing, knows lowest number.
3. [pickA (cardA )][seeA (cardA )]KB xKA (num(cardA ) = x).
B observes reading card, B knows knows cardA holds him.
is, B de dicto knowledge knowledge.
4. [pickA (cardA )][seeA (cardA )]xKB (num(cardA ) = x).
case B knows card observes sensing. is, B
de knowledge card.
5. [pickA (cardA )][seeA (cardA )]KA xKB (num(cardA ) = x).
Moreover, knows B know card.
6. [pickA (cardA )][seeA (cardA )][pickB (cardB )][seeB (cardB )]Ki ([challengeB ]LoseA )
{A, B}.
sensing, B believe would lose game challenged B.
379

fiBelle & Lakemeyer

3,1

3,2

2,3

2,1

1,3

1,2

3,1

3,2

2,3

2,1

1,3

1,2

3,1

3,2

2,3

2,1

1,3

1,2

X X X X

Figure 2: depicts compatibility worlds actions, shown wrt 3-card deck simplicitys sake. Here, worlds characterized terms numbers cards,
therefore, simply labeled (n, m), n denotes number card
denotes number Bs card world. first line represents uncertainty initially, second senses # 1, case worlds
card discarded. third represents Bs belief epistemic state
observes sensing card. is, know card has,
know considers two worlds possible, grouped shown, without knowing
group represents truth.

j

j

Proof: Let = (ekA , eB , w) model (4). easy see ekA eB would
Lemma 14, w world satisfying (4). Below, let r denote pickA (cardA ) let
r0 denote seeA (cardA ).
j

1. Assume contrary. Suppose ekA , eB , w |= KA (num(cardA ) = # 1). (w0 , ek1
B )
#
k
k
k1
0
eA , get eA , eB , w |= (num(cardA ) = 1).
Now, observe 0 says value num(cardA ) {1, . . . , 52}. Thus, construction (and definition W), worlds w W (say) w |= (num(cardA ) =
#
k
k1
2), w 'Ahi w, (w , ek1
B ) eA eB . contradiction.
2. executes r r0 , follows worlds w0 W w0 [SFA (r0 ), r]
= w[SFA (r0 ), r] = # 1 considered evaluating A-subjective formulas. (These
j
worlds agree number card real world.) Therefore ekA , eB , w, r r0 |=
k
0
k k1
0
0
KA (num(cardA ) = # 1) since every (w0 , ek1
B ) eA w 'rr0 w, eA , eB , w , r r |=
#
(num(cardA ) = 1) definition semantics sensing axioms sense .
380

fiMultiagent Knowing Dynamic Systems

j1

j

B w iff w [SF (r 0 ), r] = w[SF (r 0 ), r]. Since
3. Consider (w , eA ) eB . get w 'rr
0
B
B
0
SFB (r) = SFB (r ) = NIL worlds satisfying , item 3 hold must follow
j
j1 j
j1 j
j1
every (w0 , eA ) eB , eA , eB , w0 , r r0 |= xKA (num(cardA ) = x), eA , eB , w0 , r
r0 |= KA (num(cardA ) = n) n. Using arguments item 2, easily shown
j1 j

0
case. is, eA , eB , w0 |= KA (num(cardA ) = n) iff every w00 'rr
0 w ,
j2
j1
j1 j2
00
00
00

(w , eB ) eA , eA , eB , w |= (num(cardA ) = n). holds w 'rr0 w0
hold w00 , r r0 |= (num(cardA ) = n).
j1

intuitive argument follows. Suppose B considered j-structures (w, eA ) possible, w real world. would able infer cardA number. since
j1
j1
epistemic state {(w0 , eA ), (w00 , eA ), . . .} believes worlds w0 knows
number well is, know real world.
effect, structures inform B card # 1, others
inform card different number, leaving uncertain. case 3-card
deck, Figure 2 illustrates development.
4. follows arguments previous item. Basically, every w0 W ,
j1
w0 [SFB (r), r] = NIL = w[SFB (r), r]. evaluating B-subjective formulas every (w0 , eA )
j
j
eB considered, including ones (say) w0 , rr0 |= (num(cardA ) = # 2). Thus ekA , eB , w, r 6|=
#
KB (num(cardA ) = 1).
k
0
5. Consider (w0 , ek1
B ) eA w 'rr0 w. arguments item 4, follows

0
0
ekA , ek1
B , w , r r 6|= xKB (num(cardA ) = x).
j

Therefore, ekA , eB , w, r r0 |= KA xKB (num(cardA ) = x).
6. property follows logical deduction. sensing, players know
cards. lowest number, B highest. Since agents know
numbers unique, numbers one {1, . . . , 52}, infer would lose
challenged.

4. Regression
fundamental reasoning task dynamic domains projection (Reiter, 2001),
infer whether holds sequence actions a1 , . . . , ak executed:
|= [a1 ] . . . [ak ].
Reiter (2001) developed important solution projection problem situation calculus
called regression. idea reduce query future query 0 initial
situation successively replacing fluents rhs successor state axioms
resulting sentence 0 contains actions. need verify whether 0 entailed
initial theory.
context multiagent systems, might, example, interested reasoning
entailments background theory (3) stipulates beliefs agents application domain:
(3) |= [a1 ] . . . [ak ]
381

fiBelle & Lakemeyer

perhaps mentions belief operators.
Reiters (2001) results extended Scherl Levesque (2003) handle knowledge
situation calculus, shown carry ES (Lakemeyer & Levesque, 2011).
section, generalize results background theories form (3) involving multiagent
knowing operators. first recap regression objective formulas ES.
4.1 Regressing Objective Formulas
Without loss generality, assume query syntactically reformulated follows:
1. quantifiers use distinct variables, say formulas rectified;
2. formulas certain normal form called NF (defined below).
applying transformations, query becomes amenable regression. first syntactic
manipulation required way regression handles quantifiers, lead incorrect transformations variables distinct. second required giving simple
formulation regression.
Definition 16 formula NF every function symbol f occurs equality expressions form f (t1 , . . . , tk ) = t0 , ti t0 either variables names.
immediate verify every formula rewritten one NF, transformation
linear size formula. instance, f (g(x)) = f 0 (x) equivalent y, u. f (y) =
u f 0 (x) = u g(x) = y. Further, definition, term appears either argument
function action operator [t], follows either (action) name variable.
following use denote sequences consist action variables action names.
Lakemeyer Levesque (2011) define regression operator R, applicable
bounded objective formula.12 formula rectified NF, transformed
formula satisfying conditions.
Definition 17 Define R[], regression bounded basic formula wrt , fluent
formula R[hi, ]. sequence action names variables , R[, ] defined inductively:
1. R[, t1 = t2 ] = (t1 = t2 ) t1 t2 mention functional fluents;
2. R[, x] = xR[, ];
3. R[, ] = R[, ] R[, ];
4. R[, ] = R[, ];
5. R[, [t]] = R[ t, ];
6. R[, Poss(t)] = R[, ];
12. Roughly speaking, correspond class formulas Reiter (2001) deems regressable situation
calculus.

382

fiMultiagent Knowing Dynamic Systems

7. R[, G(t1 , . . . , tk )] = G(t1 , . . . , Gk ) rigid predicate G;
8. R[, F(t1 , . . . , tk )] fluent predicate F defined inductively :
(a) R[hi, F(t1 , . . . , tk )] = F(t1 , . . . , tk );
(b) R[ t, F(t1 , . . . , tk )] = R[, F ta tx1 1......tkxk ];
9. R[, f (t1 , . . . , tk ) = t0 ] fluent function f defined inductively by:
(a) R[hi, f (t1 , . . . , tk ) = t0 ] = ( f (t1 , . . . , tk ) = t0 );
(b) R[ t, f (t1 , . . . , tk ) = t0 ] = R[, y. ( f )at tx11 ...... txk k = t0 ].
Note definition includes , F f rhs precondition axiom
successor state axioms .
main result regarding Definition 17 evaluation objective bounded sentences
reduces query initial theory.
Theorem 18 (Lakemeyer & Levesque, 2011) Let basic action theory, whose initial theory
0 , let objective bounded sentence. R[] fluent sentence satisfies:
|= iff 0 |= R[].
4.2 Regressing Multiagent Beliefs
Let us consider general case regression bounded sentences mentioning belief
operators. first needs equivalent successor state axiom knowledge, tell
us knowledge regressed wrt action. following theorem generalizes similar
result Lakemeyer Levesque (2004) many agent case.
Theorem 19 (Successor State Axiom Knowledge.)
|= [a]Ki ()
x. SFi (a) = x Ki (SFi (a) = x [a]).
Proof: Let A, case symmetric. only-if direction, suppose
j
j
ekA , eB , w, z |= [r]KA ar action name r. Abbreviate ar 0 . Suppose ekA , eB , w, z |=
j
SFA (r) = n. suffices show ekA , eB , w, z |= KA (SFA (r) = n [r]0 ).
k
0
0
suppose (w0 , ek1
B ) eA w [SFA (r), z] = n. Since w 'zr w, follows assumption
0
0
k k1
0
0
k k1
0
0
ekA , ek1
B , w , z r |= , i.e. eA , eB , w , z |= [r] . Thus eA , eB , w , z |= SFA (r) = n [r] ,
j
follows ekA , eB , w0 , z |= KA (SFA (r) = n [r]0 ).
j

Conversely, suppose ekA , eB , w, z |= SFA (r) = n KA (SFA (r) = n [r]0 ). need
j
k
0
k k1
0
0
show ekA , eB , w, z |= [r]KA (0 ), i.e. (w0 , ek1
B ) eA w 'z w, eA , eB , w , zr |= .
k
k1
Suppose w0 'Azr w, i.e. w0 [SFA (r), z] = n (w0 , ek1
B ) eA eB . assumption,
j
0
0
k k1
0
k
0
ekA , ek1
B , w , z r |= . eA , eB , w , z |= [r], get eA , eB , w, z |= KA ([r] ).

383

fiBelle & Lakemeyer

theorem essentially says knowledge action depends known before,
future would look like contingent sensing result. Note theorem
stipulation action theory (Scherl & Levesque, 2003), theorem logic.
mentioned earlier case (3), need three basic action theories , 0 .
idea behind regression transform objective formulas wrt , subjective ones regressed
wrt 0 . Consequently, R defined wrt , 0 . precisely, define regression
operator R[, , 0 , , ] wrt basic action theory true real world, basic
action theory believes levels, basic action theory 0 B believes
levels, expected (3).
Definition 20 define R[, , 0 , ], regression bounded basic formula wrt ,
0 , R[, , 0 , hi, ]. given sequence action names variables , define
R[, , 0 , , ] inductively by:
1.-9. See Definition 17. (Note definition uses rhs precondition axiom
successor state axioms .)
10. R[, , 0 , , SFA (t) = t0 ] = R[, , 0 , , tx0 ] uses rhs sensing axioms
;
11. R[, , 0 , , SFB (t) = t0 ] = R[, , 0 , , B tx0 ] uses rhs sensing axioms
0 ;
12. R[, , 0 , , KA ] defined inductively by:
(a) R[, , 0 , hi, KA ] = KA (R[, , , hi, ]);
(b) R[, , 0 , t, KA ] = R[, , 0 , , ], rhs equivalence Theorem
19 agent index A.
13. R[, , 0 , , KB ] defined inductively by:
(a) R[, , 0 , hi, KB ] = KB (R[ 0 , 0 , 0 , hi, ]);
(b) R[, , 0 , t, KB ] = R[, , 0 , , ], rhs equivalence Theorem
19 agent index B.
regression operator multiagent case works follows. initial situation, regressing
KA equivalent regressing wrt basic action theory believes levels. Similarly, initial situation, regressing KB equivalent regressing wrt basic action theory
0 B believes levels. generally, regressing Ki wrt action sequence
t, equivalent regressing rhs Theorem 19 wrt first substituting t.
simplicity, often write R[, ] instead R[, , 0 , , ]. ready prove
main result section bounded basic sentences:13
13. Roughly speaking, correspond class regressable formulas epistemic situation calculus (Scherl
& Levesque, 2003).

384

fiMultiagent Knowing Dynamic Systems

Theorem 21 Suppose bounded basic sentence maximal A, B-depth k, j. Let , 0
basic action theories. R[hi, ] static sentence satisfies:
|= iff 0 0 |= R[hi, ]
= OKnow [A, k] OKnow 0 [B, j]
0 = OKnow0 [A, k] OKnow0 0 [B, j].
is, solve projection task verifying whether entailed regressing
verifying entailment conjunction true initially agent
knowing initial beliefs. proof theorem provided Appendix A.
Readers noticed theorem assumes background theory beliefs
level k B beliefs level j, given query whose maximal A, B-depth k, j. syntactic
restriction essential relatively simple regression operator well-defined. see that,
suppose interested verifying whether KA KB [r] entailed OA (), basic
action theory. definition regression operator given above, evaluating query reduces
regressing [r] wrt , correct transformation beliefs
Bs knowledge world. fact, formula KA KB [r] seem amenable
regression wrt OA () since simply clear one regress subformula KB [r].
note formula KA KB [r] depth 2 transformation indeed correct
wrt initial knowledge least depth 2, OA ( OB ).
Readers also notice restricting regression operator bounded basic sentences. least two reasons limitation. First, note language expressive enough refer knowing non-initial situations; agent knows basic action
theory, one presumes action agent knows another basic action theory. Regressing latter intuitively lead sentence talks known
action executed, currently cannot expressed language. Second, note
basic action theory contains sentences successor state axioms bounded.
So, action left formula form Oi (), argument
would contain sentences bounded, would regressable.
Theorem 18 limited regressing bounded formulas. Nevertheless, regression operator covers
class formulas considered Scherl Levesque (2003), sufficient
practical purposes.
Example 22 illustrate regression using card game. Suppose interested checking
whether (4) Section 3 entails following sentence:
[pickA (cardA )][seeA (cardA )](KA (num(cardA ) = # 1) KB (num(cardA ) = # 1)).

(5)

is, picks card senses, knows card B learn this.
Use r pickA (cardA ), r0 seeA (cardA ) (num(cardA ) = # 1). Begin
R[, , , r r0 , KA KB ]
= R[, , , r r0 , KA ] R[, , , r r0 , KB ]
385

fiBelle & Lakemeyer

Consider [r][r0 ]KA . have:
R[, , , r r0 , KA ]
= R[, , , r, x(SFA (r0 ) = x KA (SFA (r0 ) = x [r0 ]))]
= x. R[, , , r, SFA (r0 ) = x] R[, , , r, KA (SFA (r0 ) = x [r0 ])]
= x. R[, , , r, num(cardA ) = x]
R[, , , hi, y. SFA (r) = KA (SFA (r) = [r])]
= x. num(cardA ) = x y. = NIL KA (R[, , , hi, SFA (r) = [r]])
= x. num(cardA ) = x y. = NIL
KA (y = NIL (num(cardA ) = x num(cardA ) = # 1))
Here, denotes (SFA (r0 ) = x [r0 ]).
reductions mostly involve repeated applications knowledge successor state axiom,
logical connectives. Then, step 4, regressing knowledge wrt hi, replace basic
action theories R operator one believes, expected Rule 12(a) Definition
20. Regarding Rs result, since 0 contains num(cardA ) = # 1, hard see
0 OKnow0 [A, k] OKnow0 [B, j] |= R[, , , r r0 , KA ].
Simplifying R[, , , r r0 , KB ] analogous, dissimilarity arising regressing Bs
beliefs wrt r0 , obtains sensing result NIL:
R[, , , r r0 , KB ]
= R[, , , r r0 , KB ]
= [x. x = NIL y. = NIL KB (y = NIL (x = NIL num(cardA ) = # 1))].
One may verify
0 OKnow0 [A, k] OKnow0 [B, j] |= R[, , , r r0 , KB ].
Therefore,
0 OKnow0 [A, k] OKnow0 [B, j] |= R[, , , r r0 , KA KB ].
means Theorem 21, allows us conclude query (5) indeed entailed (4).
Example 23 regress nested beliefs example. Suppose interested checking
whether (4) Section 3 entails following sentence:
[pickA (cardA )][seeA (cardA )]KA KB (num(cardA ) = # 1).
386

(6)

fiMultiagent Knowing Dynamic Systems

done above, let r denote pickA (cardA ), r0 denote seeA (cardA ), denote num(cardA ) =
1. Then:

#

R[, , , r r0 , KA KB ]
= R[, , , r, x(SFA (r0 ) = x KA (SFA (r0 ) = x [r0 ]KB ))]
= x. R[, , , r, num(cardA ) = x] R[, , , r, KA (x = num(cardA ) [r0 ]KB )]
= x. num(cardA ) = x
R[, , , hi, y(SFA (r) = KA (SFA (r) = [r]))]
= x. num(cardA ) = x y. = NIL KA (R[, , , hi, = NIL [r]]).
Here, denotes (num(cardA ) = x [r0 ]KB ).
reduction leads to:
x. num(cardA ) = x y. = NIL KA (y = NIL R[, , , hi, [r]]).

(7)

Let us consider R[, , , hi, [r]]. (on simplification):
R[, , , hi, [r]]
= (num(cardA ) = x) R[, , , hi, [r][r0 ]KB ].
Following reduction R[, , , hi, [r][r0 ]KB ] done previous example,
shown
0 OKnow0 [A, k] OKnow0 [B, j] |= (7).
Using regression property, is, Theorem 21, conclude (6) entailed (4). Therefore, done. (We reiterate knowledge Bs non-beliefs beliefs
B knows.)
Analogously, entailments Proposition 15 verified using regression.
regression allows us reduce questions knowledge action queries
initial beliefs, next section go even replace reasoning knowledge
classical first-order reasoning.
4.3 Representation Theorem
representation theorem result means reasoning knowledge reduced
first-order theorem proving. presentation generalizes single agent variant (Lakemeyer
& Levesque, 2004).
basic idea substitute believed sentences instances. example, suppose
believes sentence :
= {Smaller(n2 , n1 ), Smaller(n3 , n1 ) Smaller(n4 , n1 )}.
is, blocks world domain: n2 smaller n1 , n3 smaller n1 n4 smaller
n1 . Supposing ask:
Ki x. (Smaller(x, n1 ) Ki Smaller(x, n1 ))
387

(8)

fiBelle & Lakemeyer

is, know block smaller n1 , know one? answer
certainly yes list smaller blocks known incomplete, except n2 . essential
step replace Ki Smaller(x, n1 ) x = n2 . Then, shown query reduces
verifying x. (Smaller(x, n1 ) x , n2 ) entailed .
make intuition precise, first define procedure Res[, ], introduced originally
Levesque (1990), obtain known instances entailed ,
fluent formulas. mention free variables, Res checks whether entails
sentence .
Definition 24 Let fluent formula, fluent sentence. Let n1 , . . . , nk names
occurring n0 name occurring . Then, Res[, ] defined as:
1. free variables, Res[, ] TRUE |= FALSE otherwise.
2. x free variable , Res[, ] defined as:
((x = n1 ) Res[nx1 , ])
...
((x = nk ) Res[nxk , ])
0

((x , n1 ) . . . (x , nk ) Res[nx0 , ]nx ).
instance, Smaller(x, n1 ) above, Res[, ] would simplify to:
(x = n2 ) Res[nx2 , ]
where, further, Res[nx2 , ] TRUE |= Smaller(n2 , n1 ).
Given formula Ki known i, idea reason knowledge
utilizing Res. course, discussed earlier, multiagent case account
knowledge bases different levels, is, addressing background theories form (3).
proceed follows. Let 0 denote initial theories (fluent sentences) believed
B levels respectively. Then, given bounded basic sentence, first use regression
obtain static basic sentence. static basic , define kk,0 follows:
Definition 25 Let 0 fluent sentences, static basic sentences.
define fluent sentence kk,0 by:
1. kk,0 = objective;
2. kk,0 = kk,0 ;
3. k k,0 = kk,0 kk,0 ;
4. kxk,0 = xkk,0 ;
5. kKA k,0 = Res[kk, , ];
6. kKB k,0 = Res[kk0 ,0 , 0 ].
388

fiMultiagent Knowing Dynamic Systems

Intuitively, given objective KB believes levels objective KB 0 B
believes levels, conceptually simple reduction operator obtained. reader may
notice similarity regression operator, viz. whenever KA encountered reduction continued wrt KB . Analogously, reduction continued wrt 0 whenever KB
encountered.
present main result section, relating R k k,0 :
Theorem 26 Let , 0 basic action theories. Suppose basic bounded sentence
maximal A, B-depth k, j,
|= iff

|= 0 kR[hi, ]k0 ,0 0 .

= OKnow [A, k] OKnow 0 [B, j].
is, query perhaps action operators entailed background theory iff regressed
query reduced representation theorem wrt 0 0 0 entailed set sentences
true initially. Thus, modal reasoning necessary. proof theorem appears
Appendix B.
Example 27 Let us consider projection query Example 22. Consider, example,
question whether (4) Section 3 entails:
[pickA (cardA )][seeA (cardA )]KA (num(cardA ) = # 1).

(9)

means Theorem 26, get |= (4) (9) iff
|= {num(cardA ) = # 1, num(cardB ) = # 52, 0 } kR[, , , hi, (9)]k0 ,0

(10)

(10) true, first consider R[, , , hi, (9)] simplifies
x. x = num(cardA ) y. = NIL KA

(11)


= NIL (num(cardA ) = x num(cardA ) = # 1).
Next, observe k(11)k0 ,0 yields
x. x = num(cardA ) y. = NIL Res[kk0 ,0 , 0 ].

(12)

note Res[kk0 ,0 , 0 ] reduces
x = # 1 = NIL.

(13)

reduction follows. Res[kk0 ,0 , 0 ] = Res[, 0 ] objective. Now, Res[, 0 ]
2 free variables: x y. definition Res, possible substitutions n chosen
xy
x respectively names 0 {}, check whether Res[n , 0 ] true.
389

fiBelle & Lakemeyer

case substitutions # 1 NIL x respectively. Therefore, Res[, 0 ] yields
(13). Replacing (13) (12), get:
x[x = num(cardA ) y[y = NIL (x = # 1 = NIL)]].

(14)

Thus, (10), ask true following first-order formula valid:
{num(cardA ) = # 1, num(cardB ) = # 52, 0 } (14).
answer clearly yes, therefore, |= (4) (9).
standard first-order theorem proving employed reasoning multiagent systems
ESn . caveat, however. Unlike standard theorem proving, set basic bounded formulas follow basic action theory applying representation theorem recursively
enumerable (Rogers Jr., 1987). precisely, item 1 Ress definition, note appeal
validity, returning TRUE, appeal falsifiability, returning FALSE (Levesque &
Lakemeyer, 2001).
4.4 Discussions
wrapping section, let us reflect limitations regression property
representation theorem. Clearly, represent special case, one form (say, theories
depth 2):
OA ( OB ) OB ( OA )
agent knows , also believes agents hold beliefs. hard
generalize results cases form:
OA ( OB 0 ) OB ( OA 0 )
where, , 0 , 0 may differ arbitrarily. idea, surprisingly, relate depth
formula sentence believed agent corresponding depth. example, p
atom, one would evaluate [r]KA p wrt [r]KB p wrt . next level, given formula
[r]KA ([r0 ]KB p), would evaluate [r0 ]KB p wrt 0 , given resultant formula , would
evaluate [r]KA wrt . precisely, regression operator representation theorem
defined terms sentences true real world, well ones believed: , 0 ,
0 . (That is, instead three theories wrt R defined knowledge bases arbitrary
depths, Section 4, would 5 theories knowledge bases depth 2.) Using
techniques presented here, hard show that, yet again, would obtain property
analogous Theorem 26, modal reasoning necessary. allow beliefs
differ arbitrarily actions, think expecting initial specification makes assumptions
agents know reasonable. (Note also 0 first-order theory,
is, complete knowledge assumption made anywhere else paper.) Therefore,
general setting would cover broad range application domains. return, slightly
involved definition R k k needed.
However, may domains make case still kinds initial states,
OA ( (KB KB 0 )) KB ( KA ())
390

fiMultiagent Knowing Dynamic Systems

one knows B knows B knows 0 . also example modeler
given full characterization Bs knowledge base. Appealing underlying semantics
reason properties knowledge examples well-defined, course, since
simply checking validity well-formed formulas logic. far effectiveness
reasoning concerned, note significantly, regression basic bounded formulas
limited nature initial theory. aspect problem.
little say reduction knowledge operators cases. Indeed, version
Theorem 21 provable, regression, one would replace basic action theories
initial components only, Theorem 26 need hold. Thus, cases, modal reasoning
perhaps necessary.

5. Related Work
article focused knowing knowledge multiagent dynamic setting. particular,
modal dialect ES situation calculus, along associated reduction theorems,
generalized many agent case.
underlying language situation calculus received lot attention action
community. are, course, alternate formalisms, fluent calculus (Thielscher,
1999) closely related approaches, based dynamic logics (Gerbrandy &
Groeneveld, 1997; Demolombe, 2003; Demolombe, Herzig, & Varzinczak, 2003; Van Ditmarsch,
Herzig, & De Lima, 2007). particular, action modality ES, inherit here, taken
dynamic logic. However, significant differences. example, Van Ditmarsch et al.
(2007) consider epistemic extension dynamic logic regression property,
propositional, consider knowing. Demolombe (2003), hand, considers
form knowing, work, like original ES, restricted single agent case.
Also, notion regression. details single agent version ES related various action proposals, see discussion Lakemeyer Levesque (2004).
worth mentioning situation calculus previously extended deal multiple agents (Shapiro et al., 2002). Recently, fact, Kelly Pearce (2008) formulate evaluation
epistemic queries, including queries common knowledge (Fagin et al., 1995), means
meta-level operator using regression. contrast ideas, mainly concerned
identifying regression works presence multiagent knowing operators.
argued earlier, able define initial knowledge terms known one obtains
natural means reasoning beliefs non-beliefs. Moreover, epistemic situation
calculus Scherl Levesque equivalent representation theorem. Therefore, approaches would require form modal reasoning initial situation.14
aspects, moreover, approaches comparable. one hand, contrast Kelly
Pearce observed Section 2.2 common knowledge cannot captured semantics. hand, integrating knowing situation calculus situation terms
explicit, derivatives Scherl-Levesque scheme, problematic (Lakemeyer,
1996; Lakemeyer & Levesque, 1998, 2004).
14. Special cases reduction knowledge treated, example, Reiter (2001) Lakemeyer
Lesperance (2012).

391

fiBelle & Lakemeyer

note reasoning knowledge multiagent systems important area artificial intelligence, numerous formal systems studied (Fagin et al., 1995; Wooldridge,
2009). example, properties similar ones obtained card game studied article
also considered work Van Ditmarsch (2002). However, many systems propositional. significantly, knowing, feature appropriate beliefs entailments
knowledge base known, addressed.
pointed out, Levesque (1990) among first propose notion knowing
logic OL, number related notions (Halpern & Moses, 1984; Hoek & Thijsse,
2002; Pratt-Hartmann, 2000). discuss here, relationships OL,
treated elsewhere (Rosati, 2000; Halpern & Lakemeyer, 2001; Levesque & Lakemeyer, 2001).
Readers also referred work Levesque Lakemeyer (2001) comprehensive
study OL; example, shown compactness property hold objective
fragment OL. Halpern Pass (2009) consider related probabilistic variant knowing
studying certain kinds strategies game theory.
Since Levesques proposal, generalizations many agent case attempted number papers (Lakemeyer, 1993; Halpern, 1993; Halpern & Lakemeyer, 2001; Waaler & Solhaug,
2005). point earlier work (Belle & Lakemeyer, 2010a), approaches
undesirable features. k-structures approach (Belle & Lakemeyer, 2010a), hand,
shown satisfactorily capture multiagent knowing. work, also discuss number aspects multiagent knowing, including, example, sound complete
axiomatization propositional case.15
Finally, remark intuition k-structures seems closely related proposal
knowledge structures (Fagin, Halpern, & Vardi, 1991). Although restricted propositional language, although actions knowing considered, proposal also based
epistemic states various depths. (See Kaneko Suzuki, 2003, similar semantical notions
game theory.) agent, 1-world simply set truth assignments primitive propositions.
roughly corresponds set worlds, similar 1-structure. However, 2-world considers
triple: truth assignment primitive propositions, 1-world A, 1-world B.
differs proposal slightly. also expect k-worlds satisfy various constraints, including one knowledge always correct. Despite differences, also motivated
ease capturing non-beliefs, investigation correspondences
two approaches perhaps worthy study.

6. Conclusions
work considered reasoning knowing many agents dynamic domains.
language introduced first-order formalism allows us reason knowledge, knowing, actions sensing. knowing distinctive advantages view knowledgebased agent possible specify sentences precisely characterize knowledge
base, logically infer corresponding beliefs non-beliefs (with quantifying-in)
characterization. Building previous work multiagent knowing (Belle & Lakemeyer,
2010a) modal fragment situation calculus (Lakemeyer & Levesque, 2004), semantical
15. OLs axiomatization first-order language (Levesque, 1990) shown incomplete Halpern
Lakemeyer (1995); also show complete axiomatization cannot recursive.

392

fiMultiagent Knowing Dynamic Systems

account first discussed. showed knowledge appropriate properties, despite semantics slightly deviating usual Kripke-structure account. considered notion
basic action theory, explored projection tasks terms simple card game. particular,
non-trivial knowledge change mechanisms sensing demonstrated formalism.
One important methodology reasoning actions literature regression, extensively used planning methodologies (Fritz, 2009), proved version regression
formalism. this, reasoning actions knowledge reduces reasoning knowledge initial state only. Next, generalized representation theorem (Levesque & Lakemeyer, 2001) reduce reasoning knowledge initial state first-order reasoning.
Thus, modal reasoning necessary. believe results together underlying logic
enhance current paradigms logical modeling intelligent agents (Fagin et al., 1995;
Wooldridge, 2009), especially sense formal specifications knowledge-based systems.
many avenues future work. important observation OL Levesque (1990)
knowledge base includes beliefs itself, certain flavor nonmonotonicity
exhibited. fact, beliefs logically follow related precise way fixed-point
definition autoepistemic logic (Moore, 1985). previously shown (Belle & Lakemeyer,
2010a) notions generalize multiagent case well, used multiagent
autoepistemic reasoning. example, Fred tells Sara recently bought bird, Fred might
come assume Sara believes bird flies, without explicitly suggesting
fact. ESn , course, would allow notions studied dynamic setting (Kakas,
Michael, & Miller, 2008; Lakemeyer & Levesque, 2009).
long-lived agents, regression would become infeasible millions actions,
would need periodically update knowledge base, referred progression (Lin &
Reiter, 1997). STRIPS technology, instance, simple form progression (Reiter, 2001).
Recently, computational methodology progression studied context
knowing (Lakemeyer & Levesque, 2009). idea, roughly, agent knows basic
action theory 0 pre post sense , action, agent knows another basic
action theory 0 0 pre post sense , 0 0 progression 0 . Here, knowing
characterizes knowledge base precise way actions. account might suggest
ways study notions multiagent setting, actions, agent would update
beliefs world would also update beliefs agents know.
Finally, extensions probabilistic nondeterminism (Gabaldon & Lakemeyer, 2007; Belle &
Lakemeyer, 2011) development strategies coalitions agents (Alur, Henzinger, & Kupferman, 2002; Giacomo, Lesperance, & Pearce, 2010) worth exploring
knowing framework, perhaps along lines Halpern Pass (2009).

Acknowledgements
thank reviewers many helpful comments suggestions. work carried
first author supported graduate school GK 643 RWTH Aachen University
funded DFG (German Research Foundation) scholarship.
393

fiBelle & Lakemeyer

Appendix A. Proof Regression Property
section, prove Theorem 21. begin useful lemmas turning
main theorem. follows, make use following special construction. Given
world w, define another world w like w except satisfies pre , post sense
sentences .
Definition 28 Let w world, z Z basic action theory fluents F . w
world satisfying following conditions:
1. f < F , w [ f (n1 , . . . , nk ), z] = w[ f (n1 , . . . , nk ), z];
2. f F , w defined inductively by:
(a) w [ f (n1 , . . . , nk ), hi] = w[ f (n1 , . . . , nk ), hi];
k
(b) w [ f (n1 , . . . , nk ), z r] = iff w , z |= ( f )ar xn11,...,x
,...,nk ;

3. w [Poss(r), z] = 1 iff w , z |= ar ;
4. w [SFi (r), z] = iff w , z |= ar mx ;
f , rhs successor state, precondition sensing axioms respectively,
appearing basic action theory .
following properties shown regarding w relation w:
Lemma 29 (Lakemeyer & Levesque, 2004)
1. w, w exists unique.
2. w |= 0 w |= .
3. w |= w = w .
4. Let bounded objective sentence, suppose rectified NF. Let z Z.
w |= R[z, ] iff w , z |= .
Proof: proof lemma given elsewhere (Lakemeyer & Levesque, 2004). Later
section, arguments analogous proof item 4 needed, include proof
item here.
Item 4 proven induction length . treat length Poss(r) SFi (r)
length ar ar plus 1. consider non-trivial cases below:
case Poss(r).
w , z |= Poss(r)
iff w , z |= ar definition w
iff w |= R[z, ar ] induction
394

fiMultiagent Knowing Dynamic Systems

iff w |= R[z, Poss(r)] definition R.
case SFi (r) = m.
w , z |= SFi (r) =
iff w , z |= ar definition w
iff w |= R[z, ar ] induction
iff w |= R[z, SFi (r) = m] definition R.
case fluents f F . Note that, definition NF, ground atoms form f (n1 , . . . , nk ) = m.
proof sub-induction z.
1. w |= f (n1 , . . . , nk ) =
iff w |= f (n1 , . . . , nk ) = definition w
iff w |= R[hi, f (n1 , . . . , nk ) = m] definition R.
2. w , z r |= f (n1 , . . . , nk ) =
k
iff w , z |= f ar xn11,...,x
,...,nk definition w


x
,...,x
1
iff w |= R[z, f r n1 ,...,nkk ] sub-induction
iff w |= R[z r, f (n1 , . . . , nk ) = m] definition R.

proceed prove similar properties epistemic states. Given ek basic action
theory , let us define e k inductively by:
1. e 1 = {(w , {}) | (w, {}) e1 };
2. e k = {(w , e k1 ) | (w, ek1 ) ek }.
addition, using notation nested knowing operators (see Section 3), brevity, let
0 = OKnow0 [A, k] OKnow0 0 [B, j],
= OKnow [A, k] OKnow 0 [B, j].
Then, item 2 Lemma 29 extended knowledge following manner:
j

j

Lemma 30 Suppose ekA , eB , w |= 0 . e kA , e 0 B , w |= .
Proof: proof simple induction modal depth (Definition 13) background theory.
Recall modal depth background theory l, sentence form
OKnow0 [A, k] OKnow0 0 [B, j] k l, j l k j l.
base case theory modal depth 1. suppose e1A , e1B , w |= OA (0 ) OB (0 0 ).
show (w0 , {}) e 1A iff w0 |= . that, get e 1A , {}, w |= OA . case e 0 1B entirely
analogous, means shown e 1A , e 0 1B , w |= OA () OB ( 0 ).
Suppose w |= . w |= 0 therefore, assumption, (w, {}) e1A . Lemma 29,
w = w therefore, (w, {}) e 1A .
395

fiBelle & Lakemeyer

Conversely, let (w, {}) e 1A . definition, (w0 , {}) e1A w0 = w. since
|= 0 , follows Lemma 29 w |= . Thus, e 1A , {}, w |= OA ().
satisfies
Assume hypothesis holds theories modal depth k 1, is, ek1

j
k
k
OKnow0 [A, k1] e satisfies OKnow [A, k1], similarly B. Now, suppose eA , eB , w |=
k
0
0 k1
k k1
k
0 . Then, (w0 , ek1
B ) eA iff eA , eB , w |= 0 OKnow0 [B, k 1]. show (w , eB ) e iff
0
k
e kA , ek1
B , w |= OKnow [B, k 1], get e , {}, w |= OKnow [A, k]. argument
j
symmetric eB , therefore, lemmas claim follows.

w0

0 k1
k k1
Consider ek1
B w e , eB , w |= OKnow [B, k 1]. Now, consider eB
k1
0
{}, eB , w |= OKnow0 [B, k 1]. Since w |= , Lemma 29 w = w also, w |= 0 .
follows (w, e0B k1 ) ekA assumption. induction hypothesis, {}, e 0 k1
B , w |= OKnow [B, k
k1
k1
0
k
0
1]. definition, (w, e B ) e . easy argument shows e B = ek1
B .
k1
k
k1
Conversely, consider (w, eB ) eA . assumption, {}, eB , w |= 0 OKnow0 [B, k 1].
Lemma 14, w |= . induction hypothesis, {}, e k1
B , w |= OKnow [B, k 1]. definition,
k.
(w , e k1
)

e

B


generalize item 4 Lemma 29 knowledge.
j

j

Lemma 31 ekA , eB , w |= R[, , 0 , z, ] iff e kA , e 0 B , w , z |= .
Proof: proof induction z, sub-induction .
Let z = hi. case objective formulas proceeds exactly Lemma 29. let us consider
case A-subjective formulas.
j
e kA , e 0 B , w , z |= KA
k
k k1
iff (w, ek1
B ) e , e , eB , w |=
k
k
k1
k
iff (w, ek1
B ) eA , e , e B , w |= definition e
k
k k1
iff (w, ek1
B ) eA , eA , eB , w |= R[hi, ] sub-induction
j

iff ekA , eB , w |= KA R[hi, ]
j

iff ekA , eB , w |= R[hi, KA ] definition R.
case B-subjective formulas symmetric.
Now, consider case z r. proof precisely base case, except subjective formulas, prove follows. show argument A-subjective formulas.
arguments B-subjective formulas symmetric.
j
e kA , e 0 B , w , z r |= KA
j

iff e kA , e 0 B , w , z |= [r]KA definition
j

iff e kA , e 0 B , w , z |= ar rhs Theorem 19 [r]KA
j

iff ekA , eB , w |= R[z, ar ] main induction
396

fiMultiagent Knowing Dynamic Systems

j

iff ekA , eB , w |= R[z r, KA ] definition R.
ready prove Theorem 21. restate claim below:
Theorem 21 Suppose bounded basic sentence maximal A, B-depth k, j. Let , 0
basic action theories. R[hi, ] static sentence satisfies:
|= iff 0 0 |= R[hi, ]
= OKnow [A, k] OKnow 0 [B, j]
0 = OKnow0 [A, k] OKnow0 0 [B, j].
Proof: Let us denote 0 0 0 .
j

only-if direction, suppose |= suppose ekA , eB , w |= 0 . is, w |=
j
0 Lemma 29, w |= . Further, Lemma 30, e kA , e 0 B , w |= . assumption,
j
j
e kA , e 0 B , w |= . Then, Lemma 31, ekA , eB , w |= R[hi, ].
j

Conversely, suppose 0 |= R[hi, ] let ekA , eB , w |= . w |= 0 . Suppose
j
j
j
e0 kA , e0 B , w |= 0 . assumption e0 kA , e0 B , w |= R[hi, ]. Lemma 31, e 0 kA , e 0 0 B , w |= .
j
Lemma 29, w = w. Lemma 30, e 0 kA , e 0 0 B , w |= . Since ekA e 0 kA k-structures
OKnow [A, k] holds, simple induction argument shows e 0 kA = ekA . Analogously,
j
j
j
e 0 0 B eB same. Therefore ekA , eB , w |= .

Appendix B. Proof Representation Theorem
section, prove Theorem 26. proceed first relating valid fluent sentences ESn
non-dynamic fragment OLn (Belle & Lakemeyer, 2010a). this, go
essential details OLn . Roughly speaking, OLn ESn without dynamic operators {[t], }
distinguished symbols {Poss, SFi .} static world w W function primitive sentences
{0, 1} primitive terms standard names. Epistemic states OLn k-structures
static worlds. notions carry OLn , simply ignoring dynamic aspects.
j
example, specify semantics KA wrt triple (ekA , eB , w) w W follows:
j

0 k1
k
k k1
0
ekA , eB , w |= KA iff w0 W , ek1
B , (w , eB ) eA , eA , eB , w |= .

words, roughly, dropped action sequence z compatibility relation 'zA
semantical definition KA ESn . Terminology formulas, objective basic
analogously defined OLn .
present three formal properties regarding OLn ESn sentences:
Lemma 32 OLn , valid OLn iff valid ESn .
Lemma 33 ESn fluent sentence z action sequence, R[, , 0 , z, ]
objective OLn -sentence.
397

fiBelle & Lakemeyer

proofs straightforward generalizations analogous results regarding OL ES, appearing Theorem 6, Lemma 9 Lemma 10 work Lakemeyer Levesque (2004),
therefore reproduced here. example, Lemma 32, main technical scheme relate
ES (and thus ESn ) worlds OL (and thus OLn ) worlds. Lemma 33, clearly objective OL
sentences also objective OLn sentences, claim follows.
Lemma 34 bounded basic sentence z action sequence, R[, , 0 , z, ]
basic OLn sentence.
Proof: proof induction . fluent sentence argument immediate
owing Lemma 33. Poss, R[z, Poss(t)] = R[z, ], fluent formula, Lemma
ay
ay
33 applies. SFi , R[z, SFi (t) = t0 ] = R[z, t0 ], again, t0 fluent formula. [t],
R[z, [t]] = R[z t, ] basic OLn sentence induction.
KA , sub-induction z. case KB analogous. R[hi, KA ] = KA R[hi, ].
Since main induction, R[hi, ] basic, KA R[hi, ] also basic. R[z t, KA ] =
R[z, ], rhs Theorem 19 [t]KA . sub-induction hypothesis Lemma
33, also basic.
prove three main results essential Theorem 26. prepare that, given
static worlds W objective OLn -sentence , let:
W = {w | w |= , w W };
e 1 = W {{}};
e k = {(w, e k1 ) | w W }.
sequel, benefiting Lemma 32, simply argue using OLn -models, is, ignoring
dynamic notions.
j

Lemma 35 Let 0 objective OLn sentences let e kA e0 B above. Let
objective formula free variables x1 , . . . , xk . vector standard names n1 , . . . , nk
world w:
j
x1 ,...,xk
k
e kA , e0 B , w |= KA nx11 ,...,x
,...,nk iff |= Res[, ]n1 ,...,nk .
k
Analogously KB nx11 ,...,x
,...,nk .

x1 ,...,xk
k
k
Proof: Lemma 7, follows e kA , {}, w |= KA nx11 ,...,x
,...,nk iff e 1 , {}, w |= KA n1 ,...,nk
KA A-depth 1. sufficient show that:
x1 ,...,xk
k
e k1 , {}, w |= KA nx11 ,...,x
,...,nk iff |= Res[, ]n1 ,...,nk .

(15)

Note e k1 = {(w, {}) | w |= }, (15) simply proved OL (Levesque & Lakemeyer, 2001, Lemma 7.2.2).
Theorem 36 Let basic OLn formula maximal A, B-depth k, j free variables
j
x1 , . . . , xk . Let e kA , e0 B before, w world, n1 , . . . , nk vector names.
x1 ,...,xk
k
e kA , e0 B , w |= nx11 ,...,x
,...,nk iff w |= kk,0 n1 ,...,nk .
j

398

fiMultiagent Knowing Dynamic Systems

Proof: proof induction structure . atom equality, lemma
clearly holds since objective. induction, lemma also holds negations, disjunctions
quantifiers.
Now, consider KA . (The case KB symmetric.)
k
e kA , {}, w |= KA nx11 ,...,x
,...,nk

x1 ,...,xk
k
0 k1
0
iff e kA , ek1
B , w |= n1 ,...,nk (w , eB ) e

k
induction hypothesis
iff w0 |= kk,0 nx11 ,...,x
,...,nk
k
k
objective
since kk,0 nx11 ,...,x
iff e kA , {}, w |= KA kk,0 nx11 ,...,x
,...,nk
,...,nk

k
k
, ]nx11 ,...,x
iff |= Res[kk,0 nx11 ,...,x
,...,nk Lemma 35
,...,nk

k
definition Res
iff |= kKA k,0 nx11 ,...,x
,...,nk

k
iff w |= kKA k,0 nx11 ,...,x
result Res objective formula use
,...,nk
k
predicates function symbols. Therefore, kKA k,0 nx11 ,...,x
either valid unsatisfi,...,nk
able.

Theorem 37 Suppose maximal A, B-depth k, j. Let , 0 objective OLn sentences.

|= iff |= kk,0 .
= OKnow [A, k] OKnow0 [B, j].
j

Proof: direction, suppose (ekA , eB , w) model . easy verify ekA = e kA
j
j
j
eB = e0 B , so, w world satisfying . Since |= , ekA , eB , w |= iff w |= kk,0
Theorem 36. model satisfies kk,0 . Therefore, |= kk,0 |= kk,0 .
j

Conversely, suppose |= kk,0 . Now, let (ekA , eB , w) model . easy
j
j
verify ekA = e kA eB = e0 B . Further, since w |= w |= kk,0 . Theorem 36,
j
ekA , eB , w |= .
Finally, turn proof Theorem 26. restate claim below.
Theorem 26 Let , 0 basic action theories. Suppose basic bounded sentence
maximal A, B-depth k, j,
|= iff

|= 0 kR[hi, ]k0 ,0 0 .

= OKnow [A, k] OKnow 0 [B, j].
Proof: OKnow [A, k] OKnow 0 [B, j] |=
iff 0 OKnow0 [A, k] OKnow0 0 [B, j] |= R[hi, ] regression property Theorem 21
iff 0 OKnow0 [A, k] OKnow0 0 [B, j] R[hi, ] valid OLn Lemma 32, owing
fact R[hi, ] also (basic) OLn sentence Lemma 34
iff 0 kR[hi, ]k0 ,0 0 valid OLn Theorem 37.
399

fiBelle & Lakemeyer

References
Alur, R., Henzinger, T. A., & Kupferman, O. (2002). Alternating-time temporal logic. J. ACM,
49(5), 672713.
Belle, V., & Lakemeyer, G. (2010a). Multi-agent only-knowing revisited. Proc. KR, pp. 4960.
Belle, V., & Lakemeyer, G. (2010b). Reasoning imperfect information games epistemic
situation calculus. Proc. AAAI, pp. 255261.
Belle, V., & Lakemeyer, G. (2011). semantical account progression presence uncertainty. Proc. AAAI, pp. 165170.
Demolombe, R. (2003). Belief change: situation calculus modal logic. Proc. Nonmonotonic Reasoning, Action, Change (NRAC).
Demolombe, R., Herzig, A., & Varzinczak, I. (2003). Regression modal logic. Journal Applied
Non-Classical Logics, 13(2), 165185.
Fagin, R., Halpern, J. Y., Moses, Y., & Vardi, M. Y. (1995). Reasoning Knowledge. MIT
Press.
Fagin, R., Halpern, J. Y., & Vardi, M. Y. (1991). model-theoretic analysis knowledge. J. ACM,
38(2), 382428.
Fritz, C. (2009). Monitoring Generation Execution Optimal Plans. Ph.D. thesis, University Toronto.
Gabaldon, A., & Lakemeyer, G. (2007). ESP: logic only-knowing, noisy sensing acting.
Proc. AAAI, pp. 974979.
Gerbrandy, J., & Groeneveld, W. (1997). Reasoning information change. J. Logic, Lang.
Inf., 6(2), 147169.
Giacomo, G. D., Lesperance, Y., & Pearce, A. R. (2010). Situation calculus based programs
representing reasoning game structures. KR.
Halpern, J. Y. (1993). Reasoning knowing many agents. Proc. AAAI, pp. 655
661.
Halpern, J. Y., & Lakemeyer, G. (1995). Levesques axiomatization knowing incomplete.
Artificial Intelligence, 74(2), 381387.
Halpern, J. Y., & Moses, Y. (1984). Towards theory knowledge ignorance: Preliminary
report. Proc. NMR, pp. 125143.
Halpern, J. Y., & Pass, R. (2009). logical characterization iterated admissibility. Proc.
TARK, pp. 146155.
Halpern, J., & Lakemeyer, G. (2001). Multi-agent knowing. Journal Logic Computation,
11(1), 251265.
Harel, D., Kozen, D., & Tiuryn, J. (2000). Dynamic logic. MIT Press.
Hintikka, J. (1962). Knowledge belief: introduction logic two notions. Cornell
University Press.
Hoek, W. V. D., & Thijsse, E. (2002). general approach multi-agent minimal knowledge:
tools samples. Studia Logica, 72(1), 6184.
400

fiMultiagent Knowing Dynamic Systems

Kakas, A. C., Michael, L., & Miller, R. (2008). Fred meets tweety. ECAI, pp. 747748.
Kaneko, M., & Suzuki, N.-Y. (2003). Epistemic models shallow depths decision making
games: Horticulture. Journal Symbolic Logic, 68(1), pp. 163186.
Kaplan, D. (1968). Quantifying in. Synthese, 19(1), 178214.
Kelly, R. F., & Pearce, A. R. (2008). Complex epistemic modalities situation calculus.
Proc. KR, pp. 611620.
Kripke, S. (1963). Semantical considerations modal logic. Acta Philosophica Fennica, 16,
8394.
Lakemeyer, G. (1996). knowing situation calculus. Proc. KR, pp. 1425.
Lakemeyer, G., & Levesque, H. J. (2011). semantic characterization useful fragment
situation calculus knowledge. Artificial Intelligence, 175, 142164.
Lakemeyer, G., & Levesque, H. J. (2004). Situations, si! situation terms, no!. Proc. KR, pp.
516526.
Lakemeyer, G., & Levesque, H. (1998). AOL: logic acting, sensing, knowing, knowing. Proc. KR, pp. 316329.
Lakemeyer, G. (1993). know: study multi-agent autoepistemic reasoning. Proc.
IJCAI, pp. 376381.
Lakemeyer, G., & Lesperance, Y. (2012). Efficient reasoning multiagent epistemic logics.
Proc. ECAI, pp. 498503.
Lakemeyer, G., & Levesque, H. (2009). semantical account progression presence
defaults. Conceptual Modeling: Foundations Applications, pp. 8298. Springer.
Levesque, H. J. (1990). know: study autoepistemic logic. Artificial Intelligence, 42(2-3),
263309.
Levesque, H., & Lakemeyer, G. (2001). logic knowledge bases. MIT Press.
Lin, F., & Reiter, R. (1997). progress database. Artificial Intelligence, 92(1-2), 131167.
McCarthy, J., & Hayes, P. J. (1969). philosophical problems standpoint artificial
intelligence. Machine Intelligence, pp. 463502.
Moore, R. C. (1985). Semantical considerations nonmonotonic logic. Artificial Intelligence,
25(1), 7594.
Pratt-Hartmann, I. (2000). Total knowledge. Proc. AAAI, pp. 423428.
Reiter, R. (2001). Knowledge action: logical foundations specifying implementing dynamical systems. MIT Press.
Rogers Jr., H. (1987). Theory recursive functions effective computability. MIT Press.
Rosati, R. (2000). decidability complexity reasoning knowing. Artificial
Intelligence, 116(1-2), 193215.
Scherl, R. B., & Levesque, H. J. (2003). Knowledge, action, frame problem. Artificial
Intelligence, 144(1-2), 139.
401

fiBelle & Lakemeyer

Shapiro, S., Lesperance, Y., & Levesque, H. (2002). cognitive agents specification language
verification environment multiagent systems. Proc. AAMAS, pp. 1926.
Thielscher, M. (1999). situation calculus fluent calculus: state update axioms solution
inferential frame problem. Artificial Intelligence, 111(1-2), 277299.
Van Ditmarsch, H., Herzig, A., & De Lima, T. (2007). Optimal regression reasoning
knowledge actions. Proc. AAAI, pp. 10701075.
Van Ditmarsch, H. (2002). Descriptions game actions. Journal Logic, Language Information, 11(3), 349365.
Waaler, A., & Solhaug, B. (2005). Semantics multi-agent knowing: extended abstract.
Proc. TARK, pp. 109125.
Wooldridge, M. (2009). Introduction Multiagent Systems (2 edition). Wiley, Chichester, UK.

402

fiJournal Artificial Intelligence Research 49 (2014) 527-568

Submitted 10/13; published 03/14

Large-Scale Optimization Evaluation Functions
Minimax Search
Kunihito Hoki

hoki@cs.uec.ac.jp

Department Communication Engineering Informatics
University Electro-Communications

Tomoyuki Kaneko

kaneko@acm.org

Department Graphics Computer Sciences
University Tokyo

Abstract
paper presents new method, Minimax Tree Optimization (MMTO), learn
heuristic evaluation function practical alpha-beta search program. evaluation
function may linear non-linear combination weighted features, weights
parameters optimized. control search results move decisions agree game records human experts, well-modeled objective function
minimized designed. Moreover, numerical iterative method used find local
minima objective function, forty million parameters adjusted
using small number hyper parameters. method applied shogi, major
variant chess evaluation function must handle larger state space
chess. Experimental results show large-scale optimization evaluation
function improves playing strength shogi programs, new method performs
significantly better methods. Implementation new method shogi
program Bonanza made substantial contributions programs first-place finish
2013 World Computer Shogi Championship. Additionally, present preliminary evidence
broader applicability method two-player games chess.

1. Introduction
Heuristic search powerful method artificial intelligence. 1997, chess-playing
computer Deep Blue defeated world chess champion Garry Kasparov (Campbell, Hoane,
& Hsu, 2002). computer decided moves making large number searches
minimax game tree using heuristic evaluation functions. framework
artificial intelligence, heuristic evaluation functions, well search methods,
crucial making strong computer players. Thus, researchers working various games
made substantial efforts quest create effective evaluation functions using machine learning techniques (Furnkranz, 2001). However, fully automated learning
heuristic evaluation functions remains challenging goal chess variants. example, developers reported majority features weights Deep Blue
created/tuned hand (Campbell et al., 2002). said recent top-level chess
programs tune parameters automatically, although yet find
publication describing methods use. Moreover, reinforcement learning
applied chess (Baxter, Tridgell, & Weaver, 2000; Veness, Silver, Uther, & Blair, 2009).
c
2014
AI Access Foundation. rights reserved.

fiHoki & Kaneko

However, best authors knowledge, evaluation functions learned
methods reported literature still weaker best hand-crafted functions
terms chess-playing strength.
paper, revisit idea behind earlier research learning chess evaluation
functions (Marsland, 1985; Hsu, Anantharaman, Campbell, & Nowatzyk, 1990; Tesauro,
2001) reformulate task optimization problem using alternative learning
method, called Minimax Tree Optimization (MMTO). objective optimize
full set parameters evaluation function search results match
desired move decisions, e.g., recorded moves grandmaster games. evaluation
functions learned iteration two procedures: (1) shallow heuristic search
training positions using current parameters (2) parameter update guided
approximation gradient objective function. achieve scalability stability,
introduce new combination optimization techniques: simplified loss function, gridadjacent update, equality constraint, l1 -regularization. One resulting merits
MMTO ensure existence local minimum within convenient range
parameters.
study demonstrates performance MMTO shogi, variant chess
evaluation functions need handle wider variety features positions Western
chess. Implementation MMTO shogi program Bonanza (described Section 4.6)
made substantial contribution programs first-place finish 2013 World Computer Shogi Championship. rules shogi, well survey approaches artificial
intelligence, described literature (Iida, Sakuta, & Rollason, 2002). Basic techniques, minimax search guided heuristic evaluation functions, effective
shogi chess. However, drop rule allows player reuse captured pieces
significantly changes properties: (1) number legal moves, well average
game length, greater chess, (2) endgame databases available, (3)
material balance less important chess, especially endgame. Thus,
performance shogi program dependent quality evaluation function.
experiments, first show full set parameters evaluation
functions optimized respect rate agreement training set.
that, examine performance various learned evaluation functions terms
rates agreement test positions win rates references. Scalability
demonstrated forty million parameters, far many tune
hand. features used piece values extended versions piece-square tables
commonly used learn evaluation functions chess (Tesauro, 2001; Baxter et al.,
2000; Veness et al., 2009). also briefly examine performance MMTO chess
catch glimpse applicability MMTO games.
rest paper organized follows. next section reviews related research.
third section presents MMTO method. fourth section shows experimental
results, forty million parameters adjusted better performance, compares
performance method existing methods. last section presents
concluding remarks. paper incorporates extends previous work (Hoki &
Kaneko, 2012; Kaneko & Hoki, 2012).
528

fiLarge-Scale Optimization Evaluation Functions Minimax Search

2. Related Work
section reviews related research learning evaluation functions. First, describe
supervised learning methods use desired moves. Second, discuss learning
methods, including regression reinforcement learning. Third, briefly discuss difficulty supervised learning terms numerical optimization. Although machine learning
components besides evaluation functions game programs would interesting
research topic (Bjornsson & Marsland, 2002; Tsuruoka, Yokoyama, & Chikayama, 2002;
Coulom, 2007; Silver & Tesauro, 2009), review focuses research
done learning evaluation functions.
2.1 Learning Desired Moves Chess
Grandmaster games popular source information learning chess. Let us say
set positions P desired moves position P. Typically,
positions moves sampled grandmaster games. chess program
evaluation function e(p, w ), p game position feature weight vector w
contains parameters adjusted.
Let us assume evaluation function e(p, w ) partially differentiable respect
wi i. Here, wi i-th component w .
P example, function could
linear combination weighted features, i.e., e(p, w ) = wi fi (p), fi (p) i-th
feature value position p. aim learning find better weight vector w
strengthening play program. hypothesis behind kind learning
computer play agrees desired moves, better plays.
Let us begin simple intuitive goal: make results one-ply search agree
desired moves. simplicity, let us assume maximizing player moves first
root position p. one-ply search, move highest evaluation value
selected. Thus, w adjusted desired move highest evaluation
moves. goal formally written mathematical minimization problem
objective function:
P
w) =
JH
(w

X X

H (e(p.m, w ) e(p.dp , w )) .

(1)

pP mM0p

Here, p.m position move position p, dp desired move position p, M0p
set legal moves p excluding dp , H(x) Heaviside step function, i.e.,
H(x) equals 1 x 0, 0 otherwise. objective function counts number
moves evaluation value greater equal desired move,
better w found minimizing Eq. (1). Although several studies attempted
machine learning basis framework (Nitsche, 1982; van der Meulen, 1989;
Anantharaman, 1997), numerical procedures complicated, adjustment
large-scale vector w seemed present practical difficulties.
Marsland (1985) presented notable extension wherein continuous function used
conventional optimization techniques exploited. Here, continuous function
difference substituted non-continuous step function Eq. (1). interesting
529

fiHoki & Kaneko

modified function
w) =
J2P (w

X X

[max {0, e(p.m, w ) e(p.dp , w )}]2 .

(2)

pP mM0p

meaning function value different Eq. (1); i.e., function
count number moves evaluation value greater equal
w ) helps reduce function
desired move. However, gradient vector w J2P (w
value numerically. Marsland also introduced inequality constraints order keep
evaluation right range. However, literature provide experimental
results practical chess programs.
second notable extension proposed early development chess machines
Deep Thought (Nowatzyk, 2000; Hsu et al., 1990). Here, positions compared
p.m, rather wp.m , is, one leaves principal variations (PVs), possibly
several plies p.m. extension carries least-square fitting evaluation
w ) does. Instead, biases
values. Therefore, max function J2P (w
p.dp
value e(w , w ) used least-square fitting, evaluation value
p .d
p .m
desired move dp , e(w p , w ) lower another move m, e(w
, w ).
third notable extension comparison training proposed Tesauro (2001).
Tesauro modified objective function
X X
p .d
P
p .m
w) =
Jct
(w
Tct (e(w p , w ) e(w
, w )),
pP mM0p

Tct (x) = [(R(x)) 1]2 ,

(3)

standard sigmoid function, R heuristic rescaling factor positive
differences, i.e., R(x) = x x 0, R(x) = cx constant c > 1 otherwise. Note
R(x) still continuous function. important property modified objective
function value derivative zero limit difference x goes
positive infinity, respectively one zero limit difference
x goes negative infinity. Therefore, Tct (x) Eq. (3) continuous approximation
H(x) Eq. (1). Note property explicitly stated Tesauro,
notably distinct work. number feature weights adjusted
method less two hundred. Tesauro also mentioned application small-bit
integers, used adjust weights Deep Blue. However, neither
clarified procedure mentioned whether weights automatically adjusted
experiment.
Table 1 summarizes related work. existing methods possesses least
one three important properties optimization, i.e., continuity, minimax searches,
assured local minimum. However, none three properties. Also,
existing methods (Nowatzyk, 2000; Hsu et al., 1990; Tesauro, 2001) try
decrease functions iteration much possible. revisit issues
Section 2.3. hand, method, MMTO, scalability high-dimensional
learning. Moreover, empirically show decrease objective function value
leads increase playing strength. existing methods shown
property.
530

fiLarge-Scale Optimization Evaluation Functions Minimax Search

Method
(Nitsche, 1982)
(Marsland, 1985)
(van der Meulen, 1989)
(Hsu et al., 1990)
(Anantharaman, 1997)
Comparison training
MMTO

Continuity

Search

Assured local minimum












Yes


Yes

Yes
Yes
Yes
Yes



Yes
Yes

Yes


Yes

Table 1: Summary learning methods using desired moves training positions
adjust feature weights evaluation functions. first column name
method piece literature. second column describes continuity
objective functions respect feature weights. Yes means
continuity depends kind search method used. third column indicates
whether objective functions use minimax searches depths 1,
instead comparisons legal moves root position. fourth column
shows whether hyper parameters objective functions assure local
minimum found.

2.2 Methods Learning Evaluation Functions
Many researchers utilized information sources desired moves.
example, studies Othello dating 1990s compare desired moves
moves (Fawcett, 1993). However, practical famous machine learning
method yielded strong programs based regression desired value
using 1.5 million features (Buro, 1995, 2002). Othello, different evaluation functions
used game stages determined basis number discs play. Thus,
desired values training positions obtained complete endgame search
well heuristic search evaluation functions learned later game stages.
method also successfully applied card games (Buro, Long, Furtak, & Sturtevant,
2009), chess variants. best authors knowledge, learning based
regression win/loss-labeled data yielded decent evaluation functions chess
variants. Except using desired moves, Buros method properties
similar listed Table 1; objective function continuity well assured
local minimum, method scalable. Gomboc, Buro, Marsland (2005) proposed
learn game records annotated human experts; however, feature weights
adjusted experiments small part full evaluation functions.
Reinforcement learning (Sutton & Barto, 1998), especially temporal difference learning,
famous success Backgammon (Tesauro, 2002), considered promising
way avoid difficulty finding desired values regression. approach
applied chess shown improve strength programs (Baxter
et al., 2000; Levinson & Weber, 2001; Veness et al., 2009). KnightCap program
achieved rating 2, 150 points Free Internet Chess Server (FICS1 )
1. Free Internet Chess Server, http://www.freechess.org, last access: 2013

531

fiHoki & Kaneko

Easy
(a)

Single minimum

Dicult
(b)

(c)

(d)

Smooth Non-dieren able

(e)

Narrow trough Non-con nuous

Figure 1: Example illustrating difficulties facing minimization procedure.
2, 575 points highest peak Internet Chess Club (ICC) (Baxter et al., 2000).
Another program achieved 2, 338 points highest peak ICC (Veness et al., 2009).
However, strong human players ratings 3, 000 points ICC,
difference means programs reached top level chess programs;
is, evaluation functions tuned reinforcement learning yet reached level
best-handcrafted evaluation functions chess. Moreover, number feature
weights adjusted order thousands. checkers, evaluation functions
trained temporal difference learning reportedly comparable best handcrafted
efforts (Schaeffer, Hlynka, & Jussila, 2001). also reported player stronger
expert human checker players created using neural networks trained
evolutionary strategy (Chellapilla & Fogel, 1999). Here, features beyond piece
differentials given neural network priori.
Many machine learning techniques (Baxter et al., 2000; Veness et al., 2009)
applied shogi. However, despite efforts many programmers researchers, adjustment full weight vector evaluation function remains challenging goal.
studies published far adjusted piece values small part feature
weights evaluation functions (Beal & Smith, 2001; Ugajin & Kotani, 2010).
2.3 Learning Numerical Optimization
learning methods reviewed Section 2.1 objective functions decrease;
learning process extended numerical optimization using functions.
performance numerical optimization sensitive surface objective function.
Figure 1 shows properties particular sorts functions difficulties regarding
numerical minimization. easiest one among convex function (a); local
minimum exists, global minimum. Function (b) multiple local minima; however, still thought easy problem, various minimization algorithms
using gradients Hessian matrices effective it. would desirable design
learning method using, say, linear logistic regression, uses one two types
objective function (Buro, 2002).
contrast, non-differentiable functions (c) (e) often difficult
minimize differentiable ones. quadratic model, Hessian
approximation conjugated gradient method (Bertsekas & Bertsekas, 2008),
always appropriate functions. Function (d) also difficult target,
important local minimum hidden inside deep narrow trough, quite difficult
find using numerical iteration methods. difficult example minimization
532

fiLarge-Scale Optimization Evaluation Functions Minimax Search

non-continuous function (e); even primitive iterative methods gradient decent
capable finding minimum. extreme case would function
analytical formula gradient unavailable. case, learning method would
able use partial derivatives, minima would obtained using
derivative-free methods, e.g., sampling methods (Bjornsson & Marsland, 2002; Coulom,
2012).
Theorems Appendix show minimax value continuous always
partially differentiable. Thus, existing methods incorporate minimax search
(Hsu et al., 1990; Tesauro, 2001) MMTO listed Table 1 type (c). Moreover,
certain forward pruning techniques may cause discontinuities. Therefore, even learning
methods type (e). overcome difficulty, MMTO well-modeled objective
function updates feature weights careful manner.

3. Minimax Tree Optimization
Minimax Tree Optimization (MMTO) extension comparison training reach
first intuitive goal embodied Eq. (1). purpose extension overcome
practical difficulties stabilize mathematical optimization procedure largescale feature weight vector w . Given set training positions P desired move dp
position p, MMTO optimizes weight vector w minimax search
w better agrees desired moves.
weight vector w improved iteration sub-procedures (see Figure 2).
iteration t, first step consists tree searches identify one leaves
PVs w (t) legal moves training positions P. PV leaf w (t) depends
feature weights w (t) evaluation function, new PV obtained
w (t) updated (We discuss issue Section 3.5). second step calculation
approximate partial derivatives, depends PV weight vector.
last step update weight vector. numerical stability, difference
w (t + 1) w (t)| must kept small distorted drastic changes
|w
partial derivatives. Section 3.4 shows grid-adjacent update ensures this.
3.1 Objective Function Minimized
objective function
P
w ) = J(P, w ) + JC (w
w ) + JR (w
w ),
JMmto
(w

(4)

first term J(P, w ) right side main part. terms JC
JR constraint regularization terms, respectively, defined Section 3.2.
first term
X X
J(P, w ) =
(s(p.dp , w ) s(p.m, w )) ,
(5)
pP mM0p

s(p, w ) minimax value identified tree search position p. (x)
1/(1 + exp(ax)), horizontally mirrored sigmoid function. slope (x)
controlled constant parameter > 0. large limit, (x) becomes Heaviside
533

fiHoki & Kaneko



fi

wp.(t)

1. Perform game-tree search identify PV leaves
child positions
p.m position p training set P, w (t) weight vector
t-th iteration w (0) initial guess.
2. Calculate partial-derivative approximation well-modeled objective
p .m
w
function defined Section 3.1 using w
(t) (t). objective
function employs differentiable approximation H(x) (see Section 3.1),
well constraint regularization term (see Section 3.2).



3. Obtain new weight vector w (t+1) w (t) using grid-adjacent update
guided partial derivatives computed step 2 (see Section 3.4). Go
back step 1, terminate optimization objective function
value converges (see Section 4).



Figure 2: Minimax Tree Optimization: Iteration searches update using partial
derivatives

step function H(x). Thus, main differences first intuitive objective function
P (w
w ) Eq. (1) use (x) smooth approximation H(x) use
JH
w )
search result s(p, w ) instead raw evaluation e(p, w ). difference J2P (w
P
w
w
Eq. (2) Jct (w ) Eq. (3) J(P, ) simpler closer first intuitive one
w ) JR (w
w ) Eq (4).
Eq. (1). Moreover, none existing studies incorporate JC (w
minimax value s(p, w ) equals raw evaluation value e(wp , w ), e(p, w )
evaluation position p wp one PV leaves identified tree search rooted
p weight vector w . cases, derivatives s(p, w ) equal derivatives
e(wp , w ). reasons, PV leaves identified step 1 Figure 2.
3.2 Constraint Regularization Terms
computer programs chess variants, evaluation values typically represented
integers. Signed 16-bit integers especially preferred corresponding transposition tables memory efficient. Thus, restrict range absolute
value evaluation function e(p, w ). Moreover, search results change
w constant factor > 0, restriction
one uses scaled weight vector w
stabilizes numerical optimization procedure value uncertain.
w ) = 0 g(w
w 0 ) Eq. (4),
restriction, introduce constraint term JC (w
0
w ) = 0 equality constraint, 0 Lagrange multiplier.
subset w , g(w
w ) (see
addition constraint term, also introduce regularization term JR (w
w ) = 1 |w
w 00 |, 1 > 0
last term Eq. (4)). use l1 -regularization JR (w
constant variable, w 00 subset w . l1 -regularization widely used deal highdimensional parameters, whereas l2 -regularization used avoid over-fitting (Tibshirani,
1996).

w0

534

fiLarge-Scale Optimization Evaluation Functions Minimax Search

P (w
w ) exists
constraint regularization terms ensure local minimum JMmto
finite range w . hand, depending P distribution dp ,
P (w
w ) Eq. (2), Jct
w ) Eq. (3).
property always true J(P, w ) itself, J2P (w
constraint l1 -regularization terms similar functionalities; i.e., restrict
range absolute value evaluation function e(p, w ). However, distinctions important practice l1 -regularization makes weight vector w 00 sparse
whereas constraint term not. Thus, regularization term suitable minor
features rarely seen, whereas constraint term suitable major features
appear often training set. Moreover, terms useful controlling
strength restriction. major feature values usually change often
minor feature values, magnitudes partial derivatives respect major feature
weights usually greater respect minor feature weights. adjust
strength l1 -regularization term weaker constraint term.
example, experiments used constraint term piece values
feature values, i.e., number pieces owned black/white, change single games
shogi. many weights penalized l1 -regularization. weight
w 0 , w 00 ).
controlled either constraint l1 -regularization term, i.e., w = (w
partial derivatives respect major minor feature weights differed several
orders magnitude, difficult stabilize optimization procedure means
single hyper parameter 1 .

3.3 Partial Derivative Approximation
iteration, feature weights updated basis partial derivatives
P (w
w ) defined Eq. (4). partial derivative, exists,
objective function JMmto
P



w) =
w) +
w ).
JMmto (w
J(P, w ) +
JC (w
JR (w
wi
wi
wi
wi

(6)


w ) right side treated intuitive manner; sgn(wi )1
last term w
JR (w

00
wi w , 0 otherwise. Function sgn(x) 1 x > 0, 0 x = 0, 1 x < 0.

w ) 0 wi
JC (w
/ w 0 . case wi w 0
partial derivative constraint term w

discussed Section 3.5.
partial derivative J(P, w ) always exist, minimax value
s(p, w ) always differentiable. Instead, use approximation,


J(P, w ) =
wi


X X
(s(p.dp , w ) s(p.m, w ))
wi
0

(7)



X X
p .d
e(w p , w ) e(wp.m , w )
wi
0

(8)

pP mMp

pP mMp

=

X X

p.d

0 (e(w p , w ) e(wp.m , w ))

pP mM0p


p .d p
e(w , w ) e(wp.m , w ) ,
wi

0 (x) = ddx (x). approximation Eq. (7) Eq. (8) makes computation
tractable, identify PV leaves step 1 Figure 2. stated Appendix A,
535

fiHoki & Kaneko

minimax value s(p, w ) found search continuous, therefore, function
J(P, w ) also continuous. Moreover, approximate value equivalent partial
derivative unique PV exists position. Appendix also discusses con
ditions w
s(p, w ) exists. Note found errors caused

approximation sufficiently small shogi application (Kaneko & Hoki, 2012).
Previous studies (Baxter et al., 2000; Tesauro, 2001) use approximation well.
3.4 Grid-Adjacent Update
numerical stability, grid-adjacent update step 3 (see Figure 2) used get
w (t + 1) w (t). Consider simple n-dimensional grid distance two
adjacent points h. Suppose h integer, e.g., h = 1. grid-adjacent update,
feature vector w (t) always one points grid, i-th component
wi (t + 1) adjacent wi (t):
wi (t + 1) = wi (t) h sgn(

P (w
w (t))
JMmto
).
wi

Thus, |wi (t+1)wi (t)| = |wi | = h 0 i. update decrease objective
P (w
P (w
w ) w
w w JMmto
w ) 0 errors approximation (see
function JMmto
Eq. (8)) negligible. Moreover, h must small enough update
p
p
change PV, i.e., w
(t) = w (t+1) majority positions p searched step 1.
Although MMTO focuses optimization weight vectors represented integers,
noted gradient descent update suitable even one uses floatingpoint feature weights. preliminary experiments indicate partial derivatives
J(P, w ) respect major minor feature weights differ seven orders
w proportional gradient vector may
magnitude. Thus, update vector w
appropriate updating minor feature weights small step. Thus, step
size component weight vector fixed grid-adjacent update,
might able controlled ways (see, e.g., Duchi, Hazan, & Singer, 2011).
3.5 Combination Techniques Practical Issues
MMTO combination above-described techniques. subsection discusses
practical issues combination alternatives; relate external constraints
learning (e.g., many weeks wait results), depend properties domain MMTO applied.
3.5.1 Lagrange Multiplier Grid-Adjacent Update
numerical stability, MMTO explores restricted parameter space constraint
w ) = 0. this, Lagrange multiplier 0 JC (w
w ) set
satisfied, i.e., JC (w
w)
J(P,w
0
median partial derivatives { wi | wi w } order maintain constraint
w 0 ) = 0 iteration. result, wi0 h n feature weights, h n feature
g(w
weights, 0 one feature weight, number feature weights w 0 2n + 1.
w ) constant iterations.
hand, 1 regularization term JR (w
536

fiLarge-Scale Optimization Evaluation Functions Minimax Search

3.5.2 Search Depth
game tree searches step 1 Figure 2 time-consuming step MMTO.
Tesauro (2001) shown use quiescence search yields better evaluation
functions. Thus, expected deeper searches MMTO yield better evaluation
functions. hand, must handle large amount training positions,
search time tends grow exponentially increase search depth. Therefore,
experiments use 1-ply standard search together quiescence search. Here,
quiescence search called every frontier node standard search. observed
evaluation functions learned shallow searches still effective playing games
deep searches (see Section 4.4). Similar results reported Tesauro.
3.5.3 Reuse PV Efficiency Learning
step 1 Figure 2 time-consuming part, worth considering omitting
assuming wp (t) = wp (t1) certain frequency. experiments, steps 2 3
repeated 32 times without running step 1. counted number iterations
run step 1. is, iteration ran single step 1 32 pairs steps 2 3.
number 32 would domain dependent set small enough update
change PV positions.
3.5.4 Pruning Trees
Pruning techniques dramatically reduce number searched nodes hence speed
learning. Fortunately, pruning introduce discontinuities objective
function. hand, pruning methods, including futility pruning (Schaeffer,
1986), may introduce discontinuities (see Appendix A.4). Therefore, robustness
whole learning procedure examined pruning techniques used.
far authors experience goes, objective function futility pruning seems
continuous (see Section 4.5).
3.5.5 Convergence Performance Measurement
termination criteria usually difficult determine iterative computations.
case learning shogi evaluation function, convergence objective function
MMTO seems significant criteria, rate agreement test set
Elo rating learned evaluation function also converge converges. Note
rate agreement measured separate test set training set
order detect overfitting (see Section 4.3).
3.5.6 Duplication Positions Alternative Moves
Game records usually duplications positions desired moves opening
phase. Although ideal distributions positions desired moves unknown,
decided remove duplications training test sets simplicity.
is, use pair hposition, movei iteration. duplications
detected Zobrist hashing (1990). Note two different moves may
suggested position training test sets, objective function
537

fiHoki & Kaneko

becomes smaller tree search rooted position matches one moves.
result, conflicting goals move better move b vice versa
independently augmented objective function cancel
moves played position. experience, adaptation seems work
reasonably well shogi, best solution may depend target game.

4. Experiments
evaluated effectiveness MMTO experiments number feature
weights evaluation function varied thirteen forty million.
found MMTO works better comparison training intuitive modifications
terms rate agreement, speed convergence, game-playing strength.
w ) regularization term JR (w
w ) help inalso observed constraint term JC (w
crease performance evaluation functions terms rate agreement
test set. see numerical convergence, investigated surfaces objective
function MMTO limited number feature weights experimentally found
MMTO finds local minima reasonable range feature weights. Finally, carried
preliminary experiments chess well experiments data quality dependence.
4.1 Setup: Evaluation Functions, Features, Game Records
experiments described section used Bonanza, whose source code
available online (Hoki & Muramatsu, 2012). performance Bonanza major tournaments discussed Section 4.6. Bonanza uses techniques MMTO, PVS (Pearl,
1980; Marsland & Campbell, 1982; Reinefeld, 1983), capture search frontier nodes
quiescence search, transposition tables (Zobrist, 1990; Russell & Norvig, 2002), static exchange evaluation (Reul, 2010), killer history heuristics (Akl & Newborn, 1977; Schaeffer, 1989), null move pruning (Adelson-Velskiy, Arlazarov, & Donskoy, 1975; Heinz, 1999),
futility pruning (Schaeffer, 1986; Heinz, 1998), late move reductions (Romstad, 2010).
also uses opening-book database randomly chose opening lines
self-play experiments. game records training test sets exclusively
chosen games played famous tournaments2 . 48, 566 game records
total. 30, 000 games played professional players using standard
time controls, i.e., one ten hours side byoyomi period (once time
2. abbreviated tournament name, number games used, date range games are: Juni,
12827, 19462010; Kisei, 3286, 19622010; Ryuo, 3279, 19872010; Osho, 2286, 19502010; Oui, 2017,
19592010; Ouza, 1849, 19522010; NHK-cup, 1745, 19512010; Ginga, 1735, 19912010; Kio, 1620,
19732010; Shinjino, 1332, 19692010; Zen-nihon-proshogi, 1160, 19822001; Hayazashi-shogi-senshuken,
945, 19722003; Judan, 764, 19621987; Meisho, 752, 19731989; Joryu-meijin, 608, 19742010; Meijin,
551, 19352010; All-star-kachinuki, 545, 19782003; Rating-senshuken, 476, 19872007; Asahi-open,
429, 20012007; Heisei-saikyo, 412, 19922007; Teno, 351, 19841992; Joryu-osho, 351, 19792010;
Kurashiki-touka, 314, 19932010; Nihon-series, 304, 19812010; 3-dan-league, 283, 19632009; Ladiesopen, 255, 19872007; Joryu-oui, 253, 19902010; Shoureikai, 217, 19412008; Gakusei-osho, 212, 1972
2006; Hayazashi-shinei, 206, 19822002; Gakusei-ouza, 191, 20012006; Asahi-amashogi, 187, 19802009;
Wakajishi, 183, 19531991; Kudan, 182, 19471961; Gakusei-meijin, 177, 19722006; Shogi-Renmei-cup,
172, 19671984; Tatsujin, 160, 19932010; Kinsho-cup, 156, 20022005; Amateur-meijin, 146, 19482009;
Kashima-cup, 119, 19962006; Grand-champion, 111, 19812008; Saikyosya-kettei, 101, 19541973; Miscellaneous, 5317, 16072010.

538

fiLarge-Scale Optimization Evaluation Functions Minimax Search

evaluation function
13
X



e
fi (p) fiA (p) wiA
i=1
X
B
B
B
eB
fkj
(p) fkj
(p) wkj
eC
eD

k,j
X

0 ,l
k,k
X

dimension
13
60, 876

C
C
C
fkk
0 l (p) fkk 0 l (p) wkk 0 l

2, 425, 950




fkjj 0 (p) fkjj
0 (p) wkjj 0

44, 222, 454

k,jj 0

Table 2: Dimensions evaluation functions. evaluation function linear combination weighted features. eA evaluates material balance, others
evaluate variety positional scores using extended piece-square tables.

expired, player move within sixty seconds). tournaments employed rapid
time controls 30 seconds per move top-level amateur players participants.
Table 2 shows four basic evaluation functions, eA material balance
others positional scores. experiments used sum functions, i.e.,
eA , eAB = eA + eB , eABC = eAB + eC , eABCD = eABC + eD . evaluation functions
anti-symmetric respect exchange black white: e(p, w ) = e(p, w ). Here,
p complete reversal black white sides position p; is, black plays
white white plays black3 . reversal, pieces owned black white
p regarded white black pieces p, respectively. Also, evaluation functions
symmetric respect right-and-left mirroring position: e(p, w ) = e(p, w ), p
mirror image p along file e.
function eA (p, w ) used evaluate material balance. 13 types
pieces shogi (Iida et al., 2002). feature fiA (p) represents number i-th
type owned black position p, wiA relative value i-th type piece.
partial derivative evaluation function respect wiA eA (p, w )/wiA =
fiA (p) fiA (p).
function eB (p, w B ) linear combination weighted two-piece-square features.
natural extensions one-piece-square features employed recent
machine learning studies chess evaluations (Baxter et al., 2000; Tesauro, 2001; Veness
et al., 2009). two-piece-square features used evaluate conditions
B (p) indicator function returns one
king another piece. feature fkj
conditions k j exist position p. Otherwise, returns zero. Condition
k represents location black king (there 81 squares), j represents
type, owner (black white), location piece. 1, 476 different
conditions j minor conditions merged. Thus, total number
kingpiece conditions 81 1, 476 = 119, 556 mirror symmetric conditions
merged.
3. Following shogi notation, black white refer players plays first second, respectively.

539

fiHoki & Kaneko

Similarly, functions eC (p, w C ) eD (p, w ) used evaluate kingking
C (p)
piece features kingpiecepiece features, respectively. indicator function fkk
0l
represents location two kings (k, k 0 ) condition (type location)
(p) represents location black king k
black piece l. indicator function fkjj
0
conditions two black white pieces (j, j 0 ).
Game tree searches required identify PV leaf positions MMTO obtain
best moves measure rate agreement. purposes, nominal depth 1
search used together quiescence search. normalize objective function
values, objective function values divided total number move pairs, Z P =
P
0
pP |Mp |. constraint function set


w )=
g(w

13
X

!
wiA

6, 500.

(9)

i=1

Also, accordance magnitude constraint, horizontally mirrored
sigmoid function (x) = 1/(1 + exp(ax)) set 0.0273 (x) would vary signifiw ) = 0.00625 (|w
wB| +
cantly x changed hundred. regularization term JR (w
C

w | + |w
w |). intuitive explanation penalty strength absolute value
|w
wi increased 160 improves relationship evaluation
values desired move another legal move. sums eB , eC , eD computed
using 32-bit integers, divided 25 order fit evaluation value
16-bit integer. Step h grid-adjacent update set smallest integer value 1.
4.2 Learning Piece Values
First, feature weights w = w evaluation function eA adjusted MMTO
comparison training, starting initial value wiA = 500 i. Tesauro
(2001) used floating-point feature weights conventional gradient descent method.
is, weight vector w updated
P
w ),
w (t) = w (t) rw Jct
(w

(10)

r constant training rate hand-tuned 0.5. components w used tree
search rounded nearest integer values. rescaling factor R Eq. (3) set
p .d
0.0025 accordance range difference | e(w p , w ) e(wp.m , w )| 50
5, 000. experiment 13 piece values adjusted w , 1, 000
game records used compose training set P. set 101,898 desired moves
Z P = 7, 936, 180 move pairs removing duplications handicapped games.
One problem observed comparison training slow learning: shown Figure 3, phase iterative procedure (from iteration 1 10) mainly adjusting
pawn value, partial differential value Eq. (3) pawns largest
phase. good pawn value found, phase II (from iteration 10 100)
mainly adjusting promoted rook promoted bishop values. values
highest second highest reasonable game play. long period time taken
w ) Eq. (3) scales poorly. general problem
phase II indicates JctP (w
gradient descent methods multiple degrees freedom (Nocedal & Wright, 2006),
540

fiLarge-Scale Optimization Evaluation Functions Minimax Search

pro_rook

2500

Phase II

Phase

Phase III
pro_bishop

Piece weight

2000
gold
bishop
rook
pro_pawn
pro_knight
silver
pro_silver
pro_lance
knight
lance

1500

1000

500

pawn
0

2

1

3

4 5 6

2

3

4 5 6

10

2

3

4 5 6

100

1000

Iteration

Figure 3: Results comparison training piece weights shogi. horizontal axis
plots number iterations logarithmic scale.

cope it, learning rate r cannot greater 0.5 accordance largest
partial derivative experiments.
second problem convergence: phase III (after iteration 100) Figure 3,
piece values keep increasing without changing ratio piece values, even though
relative ratios piece values room improvement. problem inherent
objective function comparison training, Eq. (3) explicit term
avoid it. extreme case training data satisfy inequality condition
p .d
e(w p , w ) e(wp.m , w ) moves position p, piece values diverge infinity
w ) minimized. fact, found training data
value JctP (w
experiment satisfied condition 94% pairs best another legal move.
Moreover, extreme case, training satisfy inequality
condition move position p Eq. (3), piece values shrink zero.
MMTO deals problems making grid-adjacent updates keeping
w ). weighted vector w converged
magnitudes constant constraint term JC (w
40 iterations (see Figure 4); value promoted rook 945
pawn 122. Note number iterations counted number step (1)s
throughout experiments.
4.3 Scalability Learning Practical Evaluation Functions
learning piece values, adjusted weight vectors positional scores.
time, large number training records used cope high-dimensional weight
vectors. main training set P 4, 467, 116 desired moves Z P = 368, 313, 024
541

fiHoki & Kaneko

pro_rook
pro_bishop
rook
bishop
gold
pro_knight
silver
pro_pawn
pro_lance
pro_silver
knight
lance
pawn

Piece weight

800

600

400

200
2

1

3

4

5 6 7 8

2

10
Iteration

3

4

5 6 7 8

100

Figure 4: Results MMTO piece weights.
move pairs removing duplications handicap games 47, 566 game records.
test set 103, 105 desired moves removing duplications handicap games
another 1, 000 game records. feature weights eAB adjusted MMTO
comparison training intuitive modifications. initial feature weights
w (0), w B (0)) used three methods; w (0) optimized MMTO
(w
previous experiment, w B (0) = 0. that, show scalability, feature weights
eABC eABCD optimized MMTO order. adjust feature weights
eABC , optimized feature weights eAB used initial feature weights w (0)
w B (0), 0 used w C (0). Similarly, eABCD , optimized feature weights
eABC used initial feature weights w (0), w B (0), w C (0), 0 used
w (0).
Comparison training eABC eABCD tested learning eAB yielded
small improvements. rate r Eq. (10) hand tuned 0.031. example
intuitive modifications stabilize iterative procedure, constant-step update
also tested learning eAB . case, training rate r0 (t) substituted r

P
w (t))|,
r0 (t) = rc /|w (t) Jct
(w
constant-step modification conservatively updated w using constant step rc
hand tuned 1, 000. value r rc best five trials. Another
intuitive modification reuse PV, explained Section 3.5, PVs
used 32 times rate r Eq. (10) 0.01. rescaling factor R Eq. (3)
set 0.0025, value satisfactory previous experiment shown
Figure 3. Although three methods different, iterations consumed almost
amount time. time-consuming step experiments
game tree search identify PV leaf positions.
rate agreement test set shown Figure 5. Here, agreement means
legal move obtained highest value tree search desired move.
542

fiLarge-Scale Optimization Evaluation Functions Minimax Search

0

b2_c2_h6
b2_c2_b4

35

-20
d2_b2_f3
-40

b2_c2_b3
d2_f3_c4

-60

Positional weight

Agreement (%)

30

25

ABCD

MMTO (e
)
ABC
MMTO (e )
AB
MMTO (e )
AB
CT (e , reuse PV)
AB
CT (e , constant step)
AB
CT (e )

20

15

2

1

3

4

5 6 7 8

2

10

3

4

5 6 7 8

b2_c2_a3
d2_f3_b3

-80

b2_b1_c2
-100

b2_c2_a2

-120

-140
b2_d1_c2

2

100

Iteration

0

50

100
150
Iteration

200

Figure 5: (Left panel) Improvement rate agreement test set MMTO
comparison training (CT). (Right panel) Improvement feature weights
positional features eD . Feature weight b2 c2 b4 indicates black king
b2 two gold generals c2 b4. Similarly, feature weights b2 c2 h6,
b2 c2 b3, b2 c2 a3, b2 b1 c2, b2 c2 a2, b2 d1 c2 indicate two gold generals
king b2. Feature weight d2 b2 f3 indicates black king d2
opponents two gold generals b2 f3. Similarly, feature weights
d2 f3 b3 d2 f3 c4 indicate opponents two gold generals king
d2. Here, value divided 25 .

rate calculated excluding positions one legal move, positions
easy checkmate sequence identified shallow-depth
search. Tied values counted, either.
performances MMTO, comparison training, variations compared
case learning eAB . see figure agreement rates comparison
training constant-step modification unstable substantially lower
MMTO. also see reuse-of-PV modification increases stability
reduces step length 0.031 0.01 reduces computation time learning
almost 32 times reduces number time-consuming PV updates.
MMTO full evaluation function eABCD highest rate (37%). largescale optimization weight vector wD increased level agreement 200 iterations.
543

fiHoki & Kaneko

without constraint
constraint

Pawn value

140
120
100
2

1

3 4 5 6

2

10
Iteration

3 4 5 6

2

100

Figure 6: Effect constraint term MMTO (eAB ).
computation took week using Intel X5690 workstation. agreement ratio
test set converged 100 iterations. However, feature weights converge.
w ) Eq. (9) improves stability MMTO
Figure 6 shows constraint JC (w
response pawn-value changes eAB learning. see value keeps
w ) turned converges 100 iterations
increasing JC (w
constraint turned on. One feature weights overflowed comparison training
eABC , another reason results eABC shown comparison
w ) little effect learning eAB ,
training. regularization term JR (w
improvement agreement rates MMTO mainly due use constraint
w ) grid-adjacent updates.
JC (w
w ) important optimizing larger weight vectors. FigThe regularization term JR (w
w ) Eq. (4) improves weight vector enlarged evaluation
ure 7 shows JR (w
function eABCD . Without regularization term, objective function value rate
agreement training set increase number iterations. However,
also linear increment absolute value weight vectors, distorts
rate agreement test set 50-th iteration. 200-th iteration,
0.2% components w zero. hand, 96.3% components
w zero regularization term. results indicate MMTO without
regularization suffers overfitting training set large-scale weight vector
used. similar effect regularization also occurs MMTO used eABC
learning, though effect smaller eABCD .
4.4 Improvements Strength
analyze relationship agreement rate strength, programs learned MMTO comparison training (Figure 5) play games
reference shogi program many times. reference program version GPS Shogi
released 2008 (Kaneko, 2009). open source program finalist past
world computer shogi championships. completely different evaluation function
majority parameters hand tuned. version GPS Shogi
serves reference program popular game server shogi programs4 . matches
follows: reference program (4 105 nodes/move) vs. four learned programs,
4. http://wdoor.c.u-tokyo.ac.jp/shogi/, last access: 2013 (in Japanese).

544

fiObjective function

Large-Scale Optimization Evaluation Functions Minimax Search

0.06
0.05
0.04
0.03
0.02

Agreement (%)

60

l1-regularization
without l1-regularization

55
50

training set

45

test set

40



10

B

| |+| |+| |

10

C

35
11
10

10

9

2

1

3

4 5 6

2

10

3

4 5 6

2

100

Iteration

Figure 7: Effect regularization term MMTO (eABCD ).
reference program (2105 nodes/move) vs. two learned programs evaluation
function eA eAB , reference program (8 105 nodes/move) vs. two learned
programs evaluation functions eABC eABCD . 500 games played
match. weight vectors obtained 1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 112, 128, 144
iterations tested learning configuration. Thus, total 8 13 500 = 52, 000
games played. learned programs searched 4 105 nodes per move. programs
ran single thread searched similar numbers nodes second.
measured playing strength terms Elo rating, popular way
represent relative strength two-player games. winning probability two
players estimated 1/(1 + 10d/400 ), difference ratings.
example, rating player higher player B 150, winning
percentage player 70%. Here, ratings determined using maximum
likelihood estimation games.
Figure 8 shows Elo rating player. see MMTO eAB significantly outperformed comparison training initial feature weights.
MMTO used eAB , winning percentage reference (400k/move) stably increased 11.2% (1, 800 Elo points) 59.4% (2, 210 Elo points). contrast, comparison
545

fiElo Rating

Hoki & Kaneko

2500
2400
2300
2200
2100
2000
1900
1800
1700
1600
1500

MMTO (ABCD)
MMTO (ABC)
MMTO (AB)
Comparison training (AB)
Reference (800k)
Reference (400k)
Reference (200k)

1

10
Iteration

100

Figure 8: Improvements strength (Elo rating) achieved MMTO comparison training.

Opponent
Player 1
Player 2

Depth 2
94 2%
77 3%

Depth 3
89 3%
75 3%

Depth 4
82 3%
77 3%

Depth 5
85 3%
82 3%

Depth 6
78 3%
81 3%

Depth 7
81 3%
85 3%

Depth 8
78 3%
84 3%

Table 3: Winning percentages program learned game tree search various
depths. Opponent player 1 program search depth reduced
1, opponent player 2 also program uses weight vector
learning.

training 19.5% (1, 910 Elo points) games. results shown Figs. 5
8 indicate MMTO outperforms comparison training.
large number features also contributed playing strength programs
learned MMTO. Although eABC showed small improvement terms agreement
rate Elo rating, eABCD consistently yielded significant improvements two criteria. Thus, concluded MMTO scales well forty million features. Note
computational cost eABCD reasonably small practical game play.
number features appear position 2, 800 less even total
number features forty million. Also, summations Table 2 maintained incremental manner program makes unmakes move. sort
feature design similar famous Othello program (Buro, 2002). result,
Bonanza using eABCD searched 3 106 nodes/sec Intel Xeon X5680 12
threads. speed slower many chess programs, average
strong shogi programs. addition, found Bonanza using eABCD trained
MMTO played better comparable top shogi programs actual
tournaments. details discussed Section 4.6.
Two additional fixed-depth self-play experiments conducted see evaluation
functions trained using shallow searches (depth 1 quiescence search) effective
deep searches. Table 3 shows winning percentages learned program various
546

fiLarge-Scale Optimization Evaluation Functions Minimax Search

search depths game play. learned program eABCD evaluation function yielded
200-th iteration (Figure 5). winning percentages program
(player 1) search depth reduced 1 around 80%. Thus, see
deeper learned program searched, stronger program was. Tesauro (2001) also
reported similar results using comparison training. addition, winning percentage
80% program (player 2) searched depth used eABC
200-th iteration. Thus, use eABCD trained 200 iterations effective
even program searched deeper. Here, winning percentages computed
thousand games (Seventy-six games less ending draws exceeding 300 moves
counted). Fifty megabytes memory assigned transposition table
program. uncertainties indicated 3 estimated conducting two-sided test
significance level 5% one-thousand games.
4.5 Numerical Stability Convergence
investigated continuity partial differentiability objective function
convergence feature weights empirical manner. forward pruning techniques game tree searches speed MMTO practical applications, methods
always maintain continuous search values, shown Appendix A.4. Moreover,
objective function contains large number search values. means difficult
estimate properties theoretical manner.
make empirical investigation manageable, used smallest evaluation
function eA deals thirteen shogi piece values. Moreover, reduced number
game records 1, 000; game records 98, 224 desired moves Z P = 7, 900, 993
move pairs removing duplications handicapped games.
4.5.1 Surface Objective Function
investigated function surface main part objective function J(P, w )
MMTO Eq. (4) generating contour maps millions sampling vectors w .
Note contour line (isovalue surface) curve along functions take
value. contour lines certain properties: gradient function
perpendicular lines, magnitude gradient large two lines
close together. addition, closed-loop contour line indicates location local
minimum maximum.
Two thirteen piece values weight vector w sampled order draw
contour maps two-dimensional functions interval 5 piece value.
remaining eleven pieces assigned reasonable values; 118 (pawn), 273 (lance), 318
(knight), 477 (silver general), 562 (gold general), 620 (bishop), 734 (rook), 485 (promoted
pawn), 387 (promoted lance), 445 (promoted knight), 343 (promoted silver), 781 (promoted
w ) ignored w
bishop), 957 (promoted rook). constraint term JC (w
w ) turned piece values.
could freely changed regularization term JR (w
nominal depth 1 search, together quiescence search, used.
analyzed two pairs: hgold, bishopi, hpawn, promoted lancei. Figure 9 shows
enlargement contour map J(P, wgold , wbishop ). contour interval 5 104 .
map computed ranges [200, 1100] bishop [100, 930]
547

fiHoki & Kaneko

(3) bishop=pro_bishop

(4) bishop=dragon
(5) gold=bishop

(2) bishop=rook

(1) bishop=silver

Gold general weight

(6) gold=pro_bishop

(8) gold=rook
700
600

x x

500
400
400

Objective function

(7) gold=pro_rook

800

0.164

(9) gold=silver
500

(1) (5)

600 700 800
Bishop weight

(2)

(9)

0.162
0.160

900

(5) (6)
(8)

(7)

(3) (4)

0.158
400 500 600 700 800
Bishop weight

500 600 700 800 900
Gold general weight

Figure 9: (Upper panel) Enlarged contour map J(P, wgold , wbishop ). dashed lines
indicate critical boundaries two-dimensional function
partially differentiable. two minima indicated x. (Bottom panel)
Cross sections contour map. left one shows intersection
map line wgold = 560, shows wbishop = 620.

gold general. Note function simply increases interesting
structures outside enlarged map. Figure 10 shows enlargement contour
map J(P, wpawn , wpro lance ). contour interval 1 103 . map computed
ranges [10, 500] pawn [200, 700] promoted lance.
see maps local minima within reasonable ranges
sudden changes function values. Although function depends large
number empirical search values, s(p, w ), approximately continuous amenable
optimization basis gradients approximated MMTO.
hand, maps illustrate three difficulties. first difficulty clear
edges contour lines. indicate function partially differentiable
points edges. dashed lines maps critical boundaries
profit loss ratio material exchanges inverts itself. example, silver usually
548

fiLarge-Scale Optimization Evaluation Functions Minimax Search

(1) pro_lance=lance (2) pro_lance=knight (3) pro_lance=silver
(4) pawn=silver

Pawn weight

400
(5) pawn=knight
300

(6) pawn=lance
(7) lance promotion=pawn

200
X

100

200

300

400

X

500

600

700

Objective function

Promoted lance weight
0.1584
0.1583
(2) (7) (3)
0.1582
0.1581 (1)
0.1580
0.1579
200 300 400 500 600 700
Promoted lance weight

0.20
0.19
0.18
0.17
0.16

(7) (6) (5)
(4)

100 200 300 400 500
Pawn weight

Figure 10: (Upper panel) Enlarged contour map J(P, wpawn , wpro lance ). dashed
lines indicate critical boundaries two-dimensional function
partially differentiable. two minima indicated x. (Bottom panel)
Cross sections contour map. left one shows intersection
map line wpawn = 125, shows wpro lance = 450.

less valuable bishop, capturing silver becomes profitable capturing
bishop bishop value smaller 477. boundary labeled bishop=silver
Figure 9. discussed Appendix A, function always partially differentiable
critical boundaries, multiple moves share best value. Note
boundaries theory, e.g., bishop=promoted knight boundary. Whether
boundary visible depends training set evaluation features. addition,
boundaries become winding curves non-linear evaluation function used instead
linear weighted sum.
second difficulty, scaling problem, illustrated Figure 10. map,
see scales two piece values differ two orders magnitude.
is, pawn-value variation five hundred changes function value 0.04, whereas
promoted-lance-value variation five hundred changes function value 4 104 .
difference scaling, surface along promoted lance almost flat.
property explains pawn value optimized earlier pieces
comparison training, shown Figure 3. property ill-scaling disadvantageous
comes optimizing promoted-lance value using naive gradient decent method.
549

fiHoki & Kaneko

Methods based second-order partial derivatives approximations Hessian matrix
resolve problem; however, behave poorly non-partially differentiable points
many boundaries. two difficulties point grid-adjacent update MMTO
effective.
third difficulty multiple local minima two maps.
means results MMTO depend initial values chance ending
local rather global minimum. investigate problem next
subsection 4.5.2.
4.5.2 Empirical Convergence Local-Minima Properties
previous subsection, examined two-dimensional cross sections function
J(P, w ). subsection, loosen restriction two thirteen dimensions,
sufficiently large express piece values shogi. aim experiment
catch glimpse global map numerical convergences arbitrary initial
guesses values pieces.
purpose, Monte Carlo sampling initial guess, w (0), carried
enumerate local minima analyze optimized vectors. ran 444 MMTO
randomized initial values. Here, uniformly distributed integer range [0, 32767]
assigned vector component, resulting vector scaled satisfy
w ) = 0.
equality condition g(w
Figure 11 shows cosine similarity objective-function value hundred 444
runs. Here, cosine similarity weight vector measured relative best vector
whose objective function smallest among 444 vectors 100 iterations.
majority runs, see function values weight vectors converged
numerically 50 iterations. Here, regard iteration procedure converged
function values similarities oscillate show neither steady increase
decrease 50-th 100-th iteration. Although convergence almost assured
MMTO thirteen piece values, would difficult achieve feature weights
optimized. example, Figure 5 shows convergence twothousand iterations using eABCD . 200 iterations took week Intel
X5690 workstation, could afford investigate convergence eABCD
current hardware. However, 200 iterations nonetheless achieved significant improvement
strength, shown Figure 8.
also see trials MMTO ended multiple local minima.
Although multiplicity minima generally undesirable optimization,
other, favorable properties. first property run MMTO changed
weight-vector components sufficient amount. is, cosine similarity
444 optimized vectors localized range [0.925, 1], random
initial vectors widely spread (see top panel Figure 12). second property
weak correlation cosine similarities initial optimized
vectors. means starting better initial vector terms cosine similarity
beneficial (see top panel Figure 12). However, starting better initial
vector terms objective function value beneficial (see middle panel
Figure 12). third distribution local minima formed structures (see
550

fiLarge-Scale Optimization Evaluation Functions Minimax Search

0.95
0.90
0.85
0.80
0.98

Similarity

Cosine similarity weight vector

1.00

0.75
0.70

0.97
0.96
0.95

Objective function

0.65

Objective function

0.30

0.170
0.165

0.25
0.160
60 80
Iteration

0.20

2

1

3

4

5 6 7 89

10
Iteration

2

3

4

5 6 7 89

100

Figure 11: hundred runs MMTO weight vector w consisting thirteen piece
values. initial vectors set using pseudo-random numbers. inset
enlargement showing appearance numerical convergences.
top panel shows cosine similarities relative best weight vector.
bottom panel shows values objective function.

bottom panel Figure 12). is, lower local minimum is, similar
becomes best vector. Moreover, number local minima decreases weight
vector gets farther away best.
also investigated dependence performance nominal search depth
step (1) shown Figure 2. Similar results terms convergence distribution
local minima obtained using deeper search nominal depth 2.
MMTO depth 2 consumes time MMTO depth 1, number
551

fiInitial objective function

Cosine similarity initial vector

Hoki & Kaneko

1.0
0.9
0.8
0.7
0.6
0.35

corr = 0.27

0.30

0.25

0.20
corr = -0.06

Optimized objective function

0.180
0.175
0.170
0.165
0.160
corr = -0.55
0.94

0.96

0.98

1.00

Cosine similarity optimized vector

Figure 12: Scatter plots 444 trials thirteen-dimensional weight vectors. vector
expresses thirteen piece values. cosine similarity vector measured
relative best vector. initial vector consists uniform pseudo-random
numbers, optimized one 100-th vector MMTO iterations
starting initial one. inset shows correlation coefficient
scatter plot.

random initial vectors reduced 78, number iterations reduced
sixty sake speed. majority runs, function values weight
vectors converged 50 iterations. Figure 13 shows strength (Elo rating) objective552

fiLarge-Scale Optimization Evaluation Functions Minimax Search

100
depth 1 (corr = -0.60)
depth 2 (corr = -0.86)

Elo rating

50
0
-50
-100
-150
0.150

0.155

0.160

0.165

0.170

0.175

0.180

Objective function

Figure 13: Scatter plots thirteen-dimensional weight vectors. 444 vectors indicated
crosses learned nominal depth 1 search step (1), 78
vectors indicated squares learned depth 2 search.

function value 78 runs depth 2 (squares) 444 runs depth 1 (crosses).
Here, Elo ratings identified using maximum likelihood estimation 894, 244
random-pairing games (5 104 nodes/move). Elo rating depth 1 17
average depth 2 41 average. Also, correlation coefficient
Elo rating objective function value depth 2 0.86 depth
1 0.60. Moreover, compared performance two best vectors gave
smallest objective function values. Here, computed winning probability
best results depth 1 2. player allowed use one second move,
one core Intel Xeon X5680 fifty megabytes memory assigned
transposition table. excluding two drawn games two games exceeding thousand
moves, obtained 43.6% winning rate program using best results
depth 2. results indicate MMTO better depth 2 depth 1.
4.6 Performance MMTO Tournament Conditions
MMTO invented developer Bonanza made one best programs
shogi. Moreover, ideas behind earlier versions MMTO published Japanese
(Hoki, 2006) adopted many developers dramatically changed shogi
programs.
One authors started developing Bonanza 2004, published program files
web 2005, published source codes web 2009 (Hoki, 2013). paper
gives detailed descriptions evaluation-function learning, whereas literature (Hoki
& Muramatsu, 2012) gives detailed descriptions game-tree pruning Bonanza.
addition learning method MMTO, Bonanza uses evaluation function eABCD
shown Table 2. earlier versions 2009 used subset eABCD modified
553

fiHoki & Kaneko

1
2
3
4
5

2006 May
Bonanza
YSS
KCC Shogi
TACOS
Gekisashi

2007 May
YSS
Tanase Shogi
Gekisashi
Bonanza
Bingo Shogi

2008 May
Gekisashi
Tanase Shogi
Bonanza
YSS
Bingo Shogi

2009 May
GPS Shogi
Otsuki Shogi
Monju
KCC Shogi
Bonanza

1
2
3
4
5

2010 May
Gekisashi
Shueso
GPS Shogi
Bonkras
Bonanza Feliz

2011 May
Bonkras
Bonanza
Shueso
Gekisashi
ponanza

2012 May
GPS Shogi
Puella
Tsutsukana
ponanza
Shueso

2013 May
Bonanza
ponanza
GPS Shogi
Gekisashi
NineDayFever

Table 4: Program names results recent World Computer Shogi Championship.
MMTO, earlier version variant MMTO, learning method
influenced MMTO used.

l2-regularization (Hoki, 2006). Subsequent versions fully evaluate eABCD learned l1regularization.
Table 4 shows results World Computer Shogi Championships. Since 2006,
performance Bonanza examined several computer shogi tournaments,
participant connects server program plays shogi time control
25 minutes side. Bonanza received first prize twice, second prize once, third
prize once. Moreover, players entitled Bonanza Feliz Monju used evaluation functions obtained MMTO. Thus, claim Bonanza uses MMTO,
plays better comparable top programs shogi, including commercial ones. method clearly plays level handcrafted shogi programs. Moreover,
descriptions learning shogi evaluation functions earlier version MMTO
published Hoki (2006) Japanese quickly recognized significant advances. fact, shogi program conventional handcrafted evaluation functions
broken top five last five years tournaments. One interesting case
results GPS Shogi (Kaneko, 2009), winner 2009 2012 tournaments,
source codes available online (Tanaka Kaneko, 2013). 2003 2008,
program uses handcrafted evaluation function 2009 used variant MMTO
results dramatically improved. variants MMTO used program differ
accordance content policy program. example, Tanase Shogi,
runner-up program 2008, used learning method based MMTO handcrafted
evaluation functions. Bonkras, ponanza, Puella , NineDayFever also used variants MMTO. excellent results make clear MMTO outperforms conventional
programs use handcrafted evaluation functions played extremely well recent
shogi tournaments.
554

fiLarge-Scale Optimization Evaluation Functions Minimax Search

noted versions Bonanza add small amount randomness
grid-adjacent updates. However, omitted discussion using randomness
paper clear whether added randomness improved quality
evaluation function not. source codes various versions Bonanza available
online (Hoki, 2013) source code MMTO two files, learn1.c learn2.c.
4.7 Preliminary Experiments Chess
far, discussed performance MMTO shogi. expect MMTO
would effective two-player perfect information games provided certain
conditions met: (1) sufficient number game records available, (2) minimax
searches guided heuristic evaluations effective, (3) analytic partial derivatives
evaluation function respect variables available. example, MMTO
would yield interesting results applied game solved
means (e.g., van den Herik, Uiterwijk, & van Rijswijck, 2002). Also, would yield
interesting results game Go Monte-Carlo tree searches effective
minimax searches guided heuristic evaluation function (Kocsis & Szepesvari, 2006;
Gelly & Silver, 2011; Browne, Powley, Whitehouse, Lucas, Cowling, Rohlfshagen, Tavener,
Perez, Samothrakis, & Colton, 2012; Gelly, Kocsis, Schoenauer Sebag, Silver, Szepesvari, &
Teytaud, 2012). Moreover, simpler learning method (e.g., regression method Othello,
Buro, 2002) would preferable MMTO, sufficiently effective.
conducted preliminary experiments chess catch glimpse applicability
MMTO games. Note already evaluation functions chess
outplay grandmasters, whereas none shogi. Thus, might difficult
improve well-crafted chess evaluation functions. experiment, chose opensource program (Crafty) fair implementation chess program (Hyatt, 2013).
original evaluation function tightly tuned simple multivariable
function. Thus, sake simplicity, modify way except add
new linear combination weighted two-pieces-square features. features used
evaluate conditions king another piece, eB Section 4.1.
mirror symmetric property described Section 4.1 applied features
pawn exists eighth rank counted. results, total number added
weights w B 39, 312. chess position possesses thirty fewer two-piecessquare features, additional computational time due modification became
almost negligible help pawn hash table lazy evaluation technique
come original.
training test sets composed using game records Free Internet
Chess Server (FICS). games played using standard time control server
two players ratings 2, 600 more. training set P 1, 267, 032 desired
moves Z P = 33, 619, 904 move pairs removing duplications 13, 440 game
records, whereas test set P 101, 982 desired moves Z P = 2, 755, 217 move pairs
removing duplications 1, 000 game records.
Figure 14 shows rate agreement test set number correct answers
chess problems iteration. Here, sigmoid function set 0.00341,
w B ) = 0.156|w
w B |.
equality constraint used, regularization term JR (w
555

fiHoki & Kaneko

Agreement (%)

35.2

1270

34.8

1260
1250

Agreement
Number correct answers

34.4
2

3

4

5

6

7 8 9

1

2

3

4

5

10

6

1240

7 8 9

100

Number correct answers

1280

Iteration

Figure 14: Improvement rate agreement test set (solid line) number
correct answers 2, 180 problems (dashed line) chess. two-piece-square
weights w B adjusted using MMTO.

Rating
Win

10101279
33 3%

12801489
35 3%

14901769
39 4%

17702049
43 4%

2050
42 4%

Table 5: Dependence strength (winning percentages) learned programs
quality (ratings players) training set. uncertainty indicated 3
estimated conducting two-sided test significance level 5% 1, 000
games.

total 2, 180 chess problems Encyclopedia Chess Middlegames (the second
section 879 problems), Win Chess (300 problems), Winning Chess Sacrifices
(1, 001 problems) used (Krogius, Livsic, Parma, & Taimanov, 1980; Reinfeld, 2001,
1969). learned program searched 5 104 nodes per problem eight megabytes
memory assigned transposition table. see agreement rate well
number correct answers tends improve number iterations grows, though
differences moderate. means MMTO found room improvement
well-implemented chess program. results indicate MMTO useful way
learn heuristic evaluation functions chess, especially one design evaluation
features suitable learning.
4.8 Data Quality Dependence
assess importance quality game records, conducted additional experiments using game records players various levels experience shogi. Here,
eABCD learned using results eABC Figure 5 initial value. results
summarized Table 5. training set composed records 47, 566
rapid time control (30 seconds per move) games played amateurs popular Internet
shogi site, Shogi Club 245 . first line table shows ratings amateur
players. second line shows winning percentages learned evaluation function
5. Shogi Club 24, http://www.shogidojo.com, last access: 2013.

556

fiLarge-Scale Optimization Evaluation Functions Minimax Search

evaluation function trained grandmaster-game records. Here, evaluation function learned 200 iterations. winning percentages computed
averaging results thousand games (About 15 drawn games games exceeding
300 moves counted). player allowed use one second one core
Intel Xeon X5680 move, fifty megabytes memory assigned
transposition table. Table 5 shows significance quality training set; use
game records stronger players made program stronger.

5. Conclusion
presented method, Minimax Tree Optimization (MMTO), uses game records
adjust full set feature weights evaluation function two-player game.
learning MMTO designed search results match desired moves,
e.g., recorded moves grandmaster games. MMTO consists two procedures: (1)
shallow heuristic search training positions using current feature weights
(2) update guided approximation gradient objective function.
new combination simple smooth approximation step function grid-adjacent
updates standard techniques, i.e., gradient guided optimization, constraints, regularization, contributed scalability stability MMTO led showing
substantial improvements existing methods.
performance MMTO demonstrated experiments shogi, variant chess
larger number legal moves. MMTO clearly outperformed existing methods.
addition, experimental results rate agreement playing strength indicate
MMTO adjust forty million parameters. Possible future work would automated
adjustment step length theoretical convergence analysis.

Acknowledgments
grateful Dr. Masakazu Muramatsu support work.

Appendix A. Notes Continuity Partial Differentiability
Minimax Value
saw Section 4.5 objective function MMTO piecewise smooth surface.
Appendix, theoretically discuss continuity partial differentiability
w ) respect w RN , w vector parameters
minimax value vp (w
evaluation function e(p, w ) p position. continuity minimax value
ensures continuity main part objective function MMTO defined Eq. (5).
partial differentiability analysis gives conditions approximation inside
MMTO described Section 3.3 valid. first analyze single minimax tree, assuming
tree known fixed. Then, extend discussion game-tree-search
methods possibly explore different trees different w .
Definition 1. evaluation function e(, ) (P, RN ) 7 R function, P set
positions target game, R set real numbers, RN N -dimensional
557

fiHoki & Kaneko

Euclidean space. evaluation function e(p, w ) continuous respect parameters w position p P w RN . Moreover, evaluation function
e(p, w ) partially differentiable respect component w w RN .
continuity partial differentiability evaluation function feasible assumptions. Note evaluation based ordinary piece-square table
properties, recent machine learning evaluation functions (Baxter et al.,
2000; Veness et al., 2009; Buro, 2002).
Definition 2. theoretical game graph G finite, directed acyclic, connected graph
representing possible transitions states target game, node (resp. edge)
represents position (resp. move). set nodes G corresponds P; V (G) = P.
minimax graph finite connected sub-graph G. convention, use term
minimax tree minimax graph even tree. denote set minimax
trees G T. node called maximizing (resp. minimizing) node corresponding
position maximizing (resp. minimizing) player move. destination edge
maximizing (resp. minimizing) node source edge minimizing
(resp. maximizing) node. clearly assume node n single position p,
denote evaluation function e(n, w ).
Let Lr,T set leaf nodes entire sub-tree Tr Tr rooted node r.
omit tree use Lr obvious. denote set immediate successors
(or children) node n tree Cn,T Cn . Note Cn = n leaf.
standard notation, node (or vertex) graph denoted n V (T ). However,
Appendix, omit V (.) write n obvious.
w ) value associated node n minimax
Definition 3. minimax value vn,T (w
tree defined recursively tree structure static evaluation function
e(n, w ), follows:

n leaf,
e(n, w )
w ) n non-leaf maximizing node,
w) =
maxcCn,T vc (w
vn,T (w
(11)

w
mincCn,T vc (w ) n non-leaf minimizing node.
w ) obvious. two minimax values b
omit tree use vn (w
maximizing (resp. minimizing) node, say better b > b (resp. b < a).
A.1 Continuity Minimax Value
continuity minimax value follows continuity evaluation function.
w ) continuous respect w minimax
Theorem 4. minimax value vn,T (w
w ) = vn,T (w
w 0 ), equivalently,
tree w RN . is, limw w
w 0 vn,T (w
w w 0 | < logically implies
w 0 RN > 0, exists > 0 |w
0
w ) vn,T (w
w )| < .
|vn,T (w
following assertion ordinary properties basic functions max
min common sense analysis. rather difficult, however, find suitable
reference containing it. therefore give proof useful subsequent
discussion.
558

fiLarge-Scale Optimization Evaluation Functions Minimax Search

x), ..., fk (x
x) continuous function
Proposition 5. Let k natural number f1 (x
x)) continuous function RN . Similarly, mini (fi (x
x))
RN 7 R. Then, maxi (fi (x
N
continuous function R .
x) continuous, x 0 RN > 0, exists
Proof. fi (x
x x0 | < implies |fi (x
x) fi (x
x0 )| < . Hence, choose = mini ,
> 0 |x
0
0
x x | < implies |fi (x
x) fi (x
x )| < = 1, . . . , k; is,
|x
x0 ) < fi (x
x) < fi (x
x0 ) + ,
fi (x

= 1, . . . , k.

Note ai < bi = 1, . . . , k obviously implies maxi ai < maxi bi . Thus,
inequalities obtain
x0 ) < max fi (x
x) < max fi (x
x0 ) + ,
max fi (x






is,

x) max fi (x
x0 )| < .
| max fi (x




x). proof similar mini fi (x
x).
implies continuity maxi fi (x
Let r root given tree . Now, prove Theorem 4 basis
mathematical induction leaf nodes Lr,T root r. is, leaf node
n Lr,T , minimax value continuous continuity evaluation
w ) = e(n, w ). internal node n, assume continuity holds
function; vn,T (w
child c Cn,T . induction hypothesis Proposition 5 ensure continuity
w ).
vn,T (w
A.2 Stability Principal Variations
subsection, showed continuity minimax values continuity
min max functions. Here, show best moves principal variations
stable changes leaves small enough. analyze stability order
discuss partial differentiability.
+
w ), hereafter called best children, denotes set
(w
Definition 6. symbol Cn,T
children node n tree minimax value n:
+
w ) = {c Cn,T |vc (w
w ) = vn (w
w )}.
(w
Cn,T
+

w ). Here, \ B denotes
w ); is, Cn,T \ Cn,T
(w
(w
denote rest children Cn,T
set difference, i.e., {e|e e
/ B}.

child considered best choice parent node minimax value
child parent node. two children share value,
w ) contains one child. Otherwise, number nodes Cn+ (w
w ) greater
Cn+ (w
one.
Definition 7. Let r root tree T. principal variation (abbreviated PV
w ) tree sub-tree obtained closure best children
short) (w
root:
w ) = {r},
0 (w
+

w ) = {c Cn,T
w ) | n i1 (w
w )} > 0,
(w
(w
w) =
(w


[

w ).
(w

i=0

559

fiHoki & Kaneko

n0 2

}
!
n1 2 n2 2 n3-1

!

n4 7 n5 2 n6-1

Figure 15: Example minimax tree (graph) transposition n5
+
+

w ) = Cn,T
w ) Cn,T
w ) = n (w
w ). Also, denote leaves
Note Cn,T
(w
(w
(w



w ) L (w
w ), is, (w
w ) Lr,T .
(w

Example 8. Figure 15 shows small minimax tree two best children root n0 ;
maximizing minimizing nodes denoted boxes circles, respectively. Here,
Cn+0 = {n1 , n2 } Cn+1 = {n5 }. principal variation tree {n0 , n1 , n2 , n5 }.
Lemma 9. internal node n tree w 0 RN , exists
w 1 w 0 | < n , set best
positive number n w 1 satisfying |w
1
0
children node n w subset one w :
+
+
w 0 ), w 1 s.t. |w
w 1 w 0 | < n .
w 1 ) Cn,T
(w
(w
Cn,T

w 0 ) empty, assertion trivial.
Proof. child values same, i.e., Cn (w
Otherwise, let 0 minimum absolute difference best value
w 0 ) vc (w
w 0 )| > 0. continuity minimax
values, i.e., 0 = mincCn (w
w 0 ) |vn (w
w 1 w 0 | < n ,
values ensures existence n w 1 satisfying |w
1
0
1
0
w ) vc (w
w )| < 0 /2 also |vn (w
w ) vn (w
w )| < 0 /2. definition
maxcCn |vc (w

0
w ) satisfies
n triangle inequalities, c Cn,T (w
w 0 ) vn (w
w 0 )|
0 |vc (w
w 0 ) vc (w
w 1 )| + |vc (w
w 1 ) vn (w
w 0 )|
|vc (w
w 0 ) vc (w
w 1 )| + |vc (w
w 1 ) vn (w
w 1 )| + |vn (w
w 1 ) vn (w
w 0 )|
|vc (w


w 1 ) vn (w
w 1 )| + 0 + 0
< |vc (w
2
2
1
1
w ) vn (w
w )| + 0 .
= |vc (w
w 1 ) vn (w
w 1 )| > 0 0 = 0, namely, vc (w
w 1 ) 6= vn (w
w 1 ). implies definition
Thus, |vc (w
+
w 1 ).
(irrespective whether n max min node) c 6 Cn,T
(w
Definition 10. tree stability tree minimum value n among
nodes n , n positive number satisfying Lemma 9. Note minimum
value > 0 exists finite.
Example 11. reference Figure 15, suppose leaf value changes 0.1.
w 1 ) vn (w
w 0 )| 0.1 internal node n heights 1, 2,
Then, proven |vn (w
3 order: obvious n4 , n5 , n6 , proven n1 , n2 n3 ,
finally n0 . see neither n4 n6 become new best node result
change.
560

fiLarge-Scale Optimization Evaluation Functions Minimax Search


p

vn


u
0





w1)
vn (w

w0)
(w
j

w1)
vc (w
(c Cn+ )
/ h
w 1 ) (c
vc (w
/ Cn+ )
q



w 1 ) maximizing-node n, w 1 changes along i-th comFigure 16: Sketch vn (w
0
w 1 ) n equals vc (w
w 1 ) one old best
ponent wi + h w 0 . Here, vn (w
+
0
w ).
children c Cn (w

A.3 Partial Differentiability
show partial differentiability, well partial derivative, minimax
value node tree depends principal variations. denote right
left partial derivatives function RN 7 R point x 0
f 0
x ) =
(x
x+


f (x01 , . . . , x0i + h, . . . , x0N ) f (x01 , . . . , x0N )
,
h+0
h

(12)

f 0
x ) =
(x
x


f (x01 , . . . , x0i + h, . . . , x0N ) f (x01 , . . . , x0N )
.
h0
h

(13)

lim
lim

Let us pay attention single parameter xi changes h limit opf
0
erations. Hereafter, parameters held constant often omitted x
+ (x ),
x one-dimensional parameter interest. use symbol
analogy partial derivative order forget parameters
omitted.
w ) tree
Theorem 12. node n principal variation (w
w ) partial derivative evaluation
w RN , exists leaf la L (w

w ): vn+ (w
w ) = w
function equals right partial derivative vn (w
e(la , w ). Similarly,

w


w ) partial derivative evaluation function equals
exists leaf lb L (w

w ), vn (w
w ) = w
left partial derivative vn (w
e(lb , w ).

w


proof theorem, given end subsection, based stability
0 ) |w
w 1 w 0 | = |h|
best moves. assume w 1 = (w10 , . . . , wi0 + h, . . . , wN
sufficiently small Appendix A.3. Consequently, |h| < , node n
tree w 0 RN ,

1
(n:leaf)

e(n, w )
1 ) (n:maximizing node)
1
w
max
v
(w
+
0
c
w )=
w )
vn (w
cCn,T (w

min +
w 1 ) (n:minimizing node).
w 0 ) vc (w
cC
(w
n,T

561

(14)

fiHoki & Kaneko

w 1 ) changing h, n maxExample 13. Figure 16 sketches example vn (w
w 0 ) h = 0. value
imizing node. three best children value vn (w
continuously (not always linearly) changes h. best child depends sign
w 0 ) h less . minimax
h, always one c Cn+ (w
w 0 ) sufficiently less (by least 0 ) vn (w
w 0 )
values children c Cn (w
h = 0.
w ) given
next goal show right left partial derivatives vn (w
w ), respectively.
right left partial derivatives one best children Cn+ (w
following propositions describe ordinary properties right left limits
basic functions max min. Similar arguments found comprehensive textbook
calculus. give detailed proof here, however, rather difficult find
precisely assertion textbook.
Proposition 14. Let k natural number f1 (x), ..., fk (x) continuous
function R 7 R. Suppose functions value point x0 , i.e.,
fi
0
maxi fi (x0 ) = mini fi (x0 ), right partial derivative x
+ (x ). Then,
0
right partial derivative minimum maximum fi (x) point x exists
equal minimum maximum right partial derivatives fi (x0 ), respectively.
maxi fi 0
fi
mini fi 0
fi
(x ) = max + (x0 ),
(x ) = min + (x0 ).
+
+
x
x
x
x
Proof. Let o(h) Landaus symbol, let us use denote residual terms converging
0
0
0 faster h, i.e., limh+0 o(h)
h = 0. Recall fi (x ) = f1 (x ) = 1, . . . , k.
positive h,


fi 0
0
max fi (x + h) max fi (x ) = max fi (x ) + h + (x ) + o(h) max fi (x0 )




x


fi
= max f1 (x0 ) + h + (x0 ) + o(h) f1 (x0 )

x


fi 0
= h max + (x ) + o(h)
x
0

0

Eq. (12), function maxi fi (x) point x0 right partial derivative maxi
argument applies right partial derivative mini fi (x).

fi
(x0 ).
x+

Proposition 15. Suppose functions value point x0
fi
0
functions left derivative x
(x ). Then, left partial derivative minimum
maximum fi (x) point x0 equal maximum minimum left partial
derivatives fi (x0 ):
maxi fi 0
fi
mini fi 0
fi
(x ) = min (x0 ),
(x ) = max (x0 ).


x
x
x
x
562

fiLarge-Scale Optimization Evaluation Functions Minimax Search

Proof. Using similar algebra proof Proposition 14, find negative h,


fi 0
0
0
max fi (x + h) max fi (x ) = h min (x ) + o(h).


x
fi
0
Eq. (13), function maxi fi (x) point x0 left partial derivative mini x
(x ).
Note min max switched algebra negativity h.
argument applies left partial derivative mini fi (x).

Lemma 16. Let gi+ (n, w ) =

vn
w)
(w
wi+

(resp. gi (n, w ) =

vn
w )) right (resp.
(w
wi
w RN internal

left)

w ).
partial derivative minimax value vn (w
node
w ) tree T, exist right left partial derivatives
n principal variation (w
w ) respect = 1, . . . , N . right left partial
gi+ (n, w ) gi (n, w ) vn (w
derivatives are:

+
maxcC + (w
w ) gi (c, w ) (n: maximizing node)
n,T
+
gi (n, w ) =
+
mincC + (w
w ) gi (c, w ) (n: minimizing node)
n,T


mincC + (w
w ) gi (c, w ) (n: maximizing node)
n,T

gi (n, w ) =

(n: minimizing node).
maxcC + (w
w ) gi (c, w )
n,T

Proof. prove equalities basis mathematical induction leaf nodes
w ), definition evaluation function,
Lr,T root r. leaf n L (w
w ) clearly continuous partially differentiable respect
minimax value vn (w
component w RN . internal node n, assume, induction hypothesis,
right partial derivative gi+ (c, w ) left partial derivative gi (c, w ) exist
w 1 ) Cn+ (w
w 0 ) |h| < Eq. (14).
child c Cn,T . Recall Cn+ (w
induction hypothesis Proposition 14,
maxcCn+ (w
w ) vc
wi+

mincCn+ (w
vc
vc
w ) vc
w ),
w ) = min
w ).
(w
(w
+
+
+ (w
+
+
w
w
w
w)
w)
cCn (w
cCn (w




w ) = max
(w

Similarly, Proposition 15,
maxcCn+ (w
w ) vc
wi

mincCn+ (w
vc
vc
w ) vc
w ),
w ) = max
w ).
(w
(w


(w
+
+
w
w
w
w)
w)
cCn (w
cCn (w




w ) = min
(w

w ), obvious gi+ (n, w ) =
Now, prove Theorem 12. leaf n L (w

w ), Lemma 16 ensures left
= w
e(n, w ). internal node n (w

right partial derivatives gi+ (n, w ) gi (n, w ) given one best children.
w )
Thus, root r, always exist leaves la lb L (w
gi (n, w )

gi+ (r, w ) =


wi

gi (r, w ) =

e(la , w ),
563


wi

e(lb , w ).

(15)

fiHoki & Kaneko


g + (n, w 0 ) = 0
g (n, w 0 ) = 1

wi

e(a, w 0 ) = 1
e(a, w 0 ) = 0

n






g + (r, w 0 ) = g (r, w 0 ) = 0
w0) = 0
vr (w

r

c
&b


wi

e(c, w 0 ) = 0
e(c, w 0 ) = 0


wi

e(b, w 0 ) = 0
e(b, w 0 ) = 0

w ) exists w 0 , equal partial
Figure 17: Although partial derivative vr (w

0
derivative PV leaf wi e(a, w ).

w )
Remark 17. definition, gi+ (n, w 0 ) = gi (n, w 0 ), partial derivative vn (w
0

0
w ) satisfying
respect wi exists point w leaf l L (w


w0) =
vn (w
e(l, w 0 ).
wi
wi

(16)

w ) respect
Remark 18. = 1, . . . , N , partial derivative minimax value vn (w

0
0

w 0 ).
wi exists w equals wi e(l, w ), l unique element L (w
w ) partial derivative
Remark 19. exists tree Tr minimax value vn (w
0
w 0 )| > 1)
respect wi w , even leaves l PV unique (|L (w

0
give different partial derivatives wi e(l, w ). example sketched Figure 17,
partial derivative 1 0 b c.
A.4 Game-Tree Search Pruning Techniques
Consider game tree search function takes root position r evaluationw ) minimax values
function parameters w inputs, yields minimax tree TrS (w
(w
w
w
vn,Tr (w
(w
)


n


).

call

game-tree
search

static,
provided yields
w)
r


0
w )) = V (Tr (w
w )), root r. Then,
constant tree respect w , i.e., V (Tr (w
w ) yielded static game-tree
theorems 4 12 apply minimax value vr,TrS (w
search. example, fixed-depth minimax search minimax search considering limited
types moves (e.g., capture promotion) static game-tree search. minimax search
stand pat used quiescence search (Beal, 1990) static, too. Note stand
pat node n equivalent virtual move adding evaluation function e(n, w )
w ) Eq. (11), even n leaf node.
candidate node value vn (w
pruning techniques incorporated, part tree pruned explored.
0
w ) TrS (w
w ) yielded
Consider static search S, pruning 0 , tree TrS (w
0
. call pruning conservative, provided yields minimax value
w ) = vr,T S0 (w
w ). Theorem 4 applies minimax
root r w RN : vr,TrS (w
w ) (w
r
w
value root r, vr,T S0 (w
(w
),
yielded



static
game-tree search conservative
w)
r
pruning. Standard pruning (Knuth & Moore, 1975) conservative pruning. However,
many pruning techniques, e.g., static exchange evaluation (Reul, 2010), (extended) futility
pruning (Heinz, 1998), null move pruning (Adelson-Velskiy et al., 1975), late move
reductions (Romstad, 2010), prune sub-tree without prove sub564

fiLarge-Scale Optimization Evaluation Functions Minimax Search

tree irrelevant minimax value root. Thus, pruning techniques
generally conservative.
A.5 Summary
minimax value root tree explored game-tree search wellconfigured pruning techniques continuous. result suggests continuity
objective function MMTO Eq. (4), empirically observed Section 4.5.
partial differentiability, Theorem 12 suggest feasible consider leaves
principal variations search tree. one principal variation, stated
Remark 18, use partial derivative unique leaf introduced Section 3.3
correct. Otherwise, i.e., multiple principal variations, partial derivative
may exist different partial derivative one leaves, stated
Remark 19. Although frequency cases depends target game
evaluation features, almost negligible experiments discussed previous work
(Kaneko & Hoki, 2012).

References
Adelson-Velskiy, G. M., Arlazarov, V. L., & Donskoy, M. V. (1975). methods
controlling tree search chess programs. Artificial Intelligence, 6 (4), 361 371.
Akl, S. G., & Newborn, M. M. (1977). principal continuation killer heuristic.
Proceedings 1977 Annual Conference, ACM 77, pp. 466473, New York, NY,
USA. ACM.
Anantharaman, T. (1997). Evaluation tuning computer chess: Linear discriminant methods. ICCA Journal, 20 (4), 224242.
Baxter, J., Tridgell, A., & Weaver, L. (2000). Learning play chess using temporaldifferences. Machine Learning, 40 (3), 242263.
Beal, D. F. (1990). generalised quiescence search algorithm. Artificial Intelligence, 43,
8598.
Beal, D. F., & Smith, M. C. (2001). Temporal difference learning applied game playing
results application shogi. Theoretical Computer Science, 252 (1-2), 105
119.
Bertsekas, D. P., & Bertsekas, D. P. (2008). Nonlinear Programming (2nd edition). Athena
Scientific.
Bjornsson, Y., & Marsland, T. A. (2002). Learning control search extensions. Caulfield,
H. J., Chen, S.-H., Cheng, H.-D., Duro, R. J., Honavar, V., Kerre, E. E., Lu, M.,
Romay, M. G., Shih, T. K., Ventura, D., Wang, P. P., & Yang, Y. (Eds.), JCIS, pp.
446449. JCIS / Association Intelligent Machinery, Inc.
Browne, C., Powley, E., Whitehouse, D., Lucas, S., Cowling, P., Rohlfshagen, P., Tavener,
S., Perez, D., Samothrakis, S., & Colton, S. (2012). survey monte carlo tree
search methods. Computational Intelligence AI Games, IEEE Transactions
on, 4 (1), 143.
565

fiHoki & Kaneko

Buro, M. (2002). Improving heuristic mini-max search supervised learning. Artificial
Intelligence, 134 (12), 8599.
Buro, M., Long, J. R., Furtak, T., & Sturtevant, N. R. (2009). Improving state evaluation,
inference, search trick-based card games. IJCAI, pp. 14071413.
Buro, M. (1995). Statistical feature combination evaluation game positions.
Journal Artificial Intelligence Research, 3, 373382.
Campbell, M., Hoane, Jr., A. J., & Hsu, F.-h. (2002). Deep Blue. Artificial Intelligence,
134 (12), 5783.
Chellapilla, K., & Fogel, D. (1999). Evolving neural networks play checkers without
relying expert knowledge. Neural Networks, IEEE Transactions on, 10 (6), 1382
1391.
Coulom, R. (2007). Computing Elo Ratings move patterns game go. ICGA
Journal, 30 (4), 198208.
Coulom, R. (2012). Clop: Confident local optimization noisy black-box parameter tuning.
Herik, H., & Plaat, A. (Eds.), Advances Computer Games 13, No. 7168 LNCS,
pp. 146157. Springer-Verlag.
Duchi, J., Hazan, E., & Singer, Y. (2011). Adaptive subgradient methods online learning
stochastic optimization. Journal Machine Learning Research, 12, 21212159.
Fawcett, T. E. (1993). Feature Discovery Problem Solving Systems. Ph.D. thesis, Department Computer Science, University Massachusetts, Amherst.
Furnkranz, J. (2001). Machine learning games: survey. Machines learn play
games, pp. 1159. Nova Science Publishers, Commack, NY, USA.
Gelly, S., Kocsis, L., Schoenauer M., Sebag, M., Silver, D., Szepesvari, C., & Teytaud, O.
(2012). grand challenge computer go: Monte carlo tree search extensions.
Commun. ACM, 55 (3), 106113.
Gelly, S., & Silver, D. (2011). Monte-carlo tree search rapid action value estimation
computer go. Artificial Intelligence, 175 (11), 18561875.
Gomboc, D., Buro, M., & Marsland, T. A. (2005). Tuning evaluation functions maximizing concordance. Theoretical Computer Science, 349 (2), 202229.
Heinz, E. A. (1998). Extended futility pruning. ICCA Journal, 21 (2), 7583.
Heinz, E. A. (1999). Adaptive null-move pruning. ICCA Journal, 22 (3), 123132.
Hoki, K. Bonanza computer shogi program.. http://www.geocities.jp/bonanza_
shogi/ Last access: 2013. Japanese.
Hoki, K. (2006). Optimal control minimax search results learn positional evaluation.
11th Game Programming Workshop (GPW2006), pp. 7883, Kanagawa, Japan.
Japanese.
Hoki, K., & Kaneko, T. (2012). global landscape objective functions optimization shogi piece values game-tree search. van den Herik, H. J., &
Plaat, A. (Eds.), Advances Computer Games 13, No. 7168 LNCS, pp. 184195.
Springer-Verlag.
566

fiLarge-Scale Optimization Evaluation Functions Minimax Search

Hoki, K., & Muramatsu, M. (2012). Efficiency three forward-pruning techniques shogi:
Futility pruning, null-move pruning, late move reduction (LMR). Entertainment
Computing, 3 (3), 5157.
Hsu, F.-h., Anantharaman, T. S., Campbell, M. S., & Nowatzyk, A. (1990). Deep Thought.
Marsland, T. A., & Schaeffer, J. (Eds.), Computers, Chess, Cognition, pp.
5578. Springer-Verlag.
Iida, H., Sakuta, M., & Rollason, J. (2002). Computer shogi. Artificial Intelligence, 134 (1
2), 121144.
Kaneko, T. (2009). Recent improvements computer shogi GPS-Shogi. IPSJ Magazine, 50 (9), 878886. Japanese.
Kaneko, T., & Hoki, K. (2012). Analysis evaluation-function learning comparison
sibling nodes. van den Herik, H. J., & Plaat, A. (Eds.), Advances Computer
Games 13, No. 7168 LNCS, pp. 158169. Springer-Verlag.
Knuth, D. E., & Moore, R. W. (1975). analysis alpha-beta pruning. Artificial
Intelligence, 6 (4), 293326.
Kocsis, L., & Szepesvari, C. (2006). Bandit based monte-carlo planning. Machine Learning: ECML 2006, Vol. 4212, pp. 282293. Springer.
Krogius, N., Livsic, A., Parma, B., & Taimanov, M. (1980). Encyclopedia Chess Middlegames: Combinations. Chess Informant.
Levinson, R., & Weber, R. (2001). Chess neighborhoods, function combination, reinforcement learning. Marsland, T. A., & Frank, I. (Eds.), Computer Games,
No. 2063 LNCS, pp. 133150. Springer-Verlag.
Marsland, T. A. (1985). Evaluation function factors. ICCA Journal, 8 (2), 4757.
Marsland, T. A., & Campbell, M. (1982). Parallel search strongly ordered game trees.
ACM Computing Surveys, 14 (4), 533551.
Nitsche, T. (1982). learning chess program. Advances Computer Chess 3, pp.
113120. Pergamon Press.
Nocedal, J., & Wright, S. (2006). Numerical Optimization. Springer-Verlag.
Nowatzyk, A. (2000). http://tim-mann.org/DT_eval_tune.txt.
Pearl, J. (1980). Scout: simple game-searching algorithm proven optimal properties.
Proceedings First Annual National Conference Artificial Intelligence,
pp. 143145.
Reinefeld, A. (1983). improvement scout tree search algorithm. ICCA Journal,
6 (4), 414.
Reinfeld, F. (1969). 1001 Winning Chess Sacrifices Combinations. Wilshire Book
Company.
Reinfeld, F. (2001). Win Chess (Dover Books Chess). Dover Publications.
Reul, F. (2010). Static exchange evaluation -approach. ICGA Journal, 33 (1), 317.
567

fiHoki & Kaneko

Romstad, T. Introduction Late Move Reductions. http://www.glaurungchess.com/
lmr.html, Last access: 2010.
Russell, S. J., & Norvig, P. (2002). Artificial Intelligence: Modern Approach (2nd Edition).
Prentice Hall.
Schaeffer, J. (1986). Experiments search knowledge. Ph.D. Thesis, Department
Computing Science, University Waterloo, Canada.
Schaeffer, J. (1989). history heuristic alpha-beta search enhancements practice.
IEEE Transactions Pattern Analysis Machine Intelligence, PAMI-11 (1), 1203
1212.
Schaeffer, J., Hlynka, M., & Jussila, V. (2001). Temporal difference learning applied
high-performance game-playing program. IJCAI01: Proceedings 17th
international joint conference Artificial intelligence, pp. 529534, San Francisco,
CA, USA. Morgan Kaufmann Publishers Inc.
Silver, D., & Tesauro, G. (2009). Monte-carlo simulation balancing. ICML 09: Proceedings 26th Annual International Conference Machine Learning, pp. 945952.
ACM.
Sutton, R. S., & Barto, A. G. (1998). Reinforcement Learning: Introduction (Adaptive
Computation Machine Learning). MIT Press.
Tanaka, T., & Kaneko, T. GPS Shogi.. http://gps.tanaka.ecc.u-tokyo.ac.jp/
gpsshogi/ Last access: 2013. Japanese.
Tesauro, G. (2001). Comparison training chess evaluation functions. Machines
Learn Play Games, pp. 117130. Nova Science Publishers.
Tesauro, G. (2002). Programming backgammon using self-teaching neural nets. Artificial
Intelligence, 134 (12), 181199.
Tibshirani, R. (1996). Regression shrinkage selection via lasso. J. Royal. Statist.
Soc B, 58 (1), 267288.
Tsuruoka, Y., Yokoyama, D., & Chikayama, T. (2002). Game-tree search algorithm based
realization probability. ICGA Journal, 25 (3), 145152.
Ugajin, T., & Kotani, Y. (2010). Learning evaluation function based tree strap shogi.
15th Game Programming Workshop, pp. 114118. Japanese.
van den Herik, H. J., Uiterwijk, J. W. H. M., & van Rijswijck, J. (2002). Games solved:
future. Artif. Intell., 134 (1-2), 277311.
van der Meulen, M. (1989). Weight assessment evaluation functions. Beal, D. (Ed.),
Advances in. Computer Chess 5, pp. 8189.
Veness, J., Silver, D., Uther, W., & Blair, A. (2009). Bootstrapping game tree search.
Advances Neural Information Processing Systems 22, pp. 19371945.
Zobrist, A. L. (1990). new hashing method application game playing. ICCA
Journal, 13 (2), 6973.

568

fiJournal Artificial Intelligence Research 49 (2014) 323-361

Submitted 08/13; published 02/14

Symmetric Subgame-Perfect Equilibria
Resource Allocation
Ludek Cigler
Boi Faltings

ludek.cigler@epfl.ch
boi.faltings@epfl.ch

Artificial Intelligence Laboratory
Ecole Polytechnique Federale de Lausanne
CH-1015 Lausanne, Switzerland

Abstract
analyze symmetric protocols rationally coordinate asymmetric, efficient
allocation infinitely repeated N -agent, C-resource allocation problems,
resources homogeneous. Bhaskar proposed one way achieve 2-agent, 1resource games: Agents start symmetrically randomizing actions, soon
choose different actions, start follow potentially asymmetric convention prescribes actions on. extend concept convention
general case infinitely repeated resource allocation games N agents C
resources. show convention, exists symmetric subgame-perfect
equilibrium implements it. present two conventions: bourgeois, agents
stick first allocation; market, agents pay use resources,
observe global coordination signal allows alternate different allocations. define price anonymity convention ratio maximum
social payoff (asymmetric) strategy profile expected social payoff
subgame-perfect equilibrium implements convention. show
price anonymity bourgeois convention infinite, market convention decreases
price reducing conflict agents.

1. Introduction
many situations, agents coordinate use resource. One wireless channel used one device, one parking slot may occupied one vehicle,
etc. problem often, agents identical preferences: Everyone prefers
access rather yield. Similarly, everyone prefers parking slot rather leave
car home. However, multiple agents try use one resource simultaneously,
collide everyone loses.
Consider simple example: two agents want access single resource. describe
problem game. agents two actions: yield (Y ) access (A). agent
yields, gets payoff 0. agent accesses resource agent
yields, gets payoff 1. agents access resource time,
incur cost > 0.
normal form game looks follows:



c
2014
AI Access Foundation. rights reserved.


0, 0
1, 0


0, 1
,

fiCigler & Faltings

symmetric game, two efficient Nash equilibria (NE) asymmetric:
either one agent yields one accesses resource, vice versa.
symmetric equilibrium outcome mixed NE agents access resource
1
probability Pr(A) := ||+1
. However, mixed equilibrium efficient,
expected payoff agents 0.
Asymmetric equilibria symmetric games undesirable two reasons: First,
fair. example, one agent access resource. Second, coordinating
asymmetric equilibrium difficult. Imagine agents identical
anonymous, i.e. cannot observe identity, identity agent.
cannot prescribe different strategy agents. Agents peer-to-peer
file-sharing networks assumed anonymous (Chothia & Chatzikokolakis, 2005),
well agents wireless sensor networks (Durresi, Paruchuri, Durresi, & Barolli,
2005).
Consider following example: Millions wireless sensors produced
pipeline. take two randomly, put room. one
frequency sensors transmit measurements. sensor know
transmit stay quiet? factory could program half sensors
transmit odd slots, half transmit even slots. Nevertheless,
would likely odd-even pair sensors, would pair
sensors transmit time.
Aumann (1974) proposed notion correlated equilibria fixes issues
Nash equilibria resource allocation game above. correlated equilibrium
(CE) probability distribution joint strategy profiles game. correlation
device samples distribution recommends action agent play.
probability distribution CE agents incentive deviate
recommended action. correlation device takes away burden coordination
anonymous agents. follow strategy: correlation
device told me.
smart correlation device, send agent different private
signal, available? still reach correlated equilibrium outcome, one
anonymous agents play identical strategies, yet achieve efficient fair allocation? previous work (Cigler & Faltings, 2011), proposed algorithm
allows agents learn correlated equilibrium outcome repeated play.
considered special case resource allocation problem. proposed use global
coordination signal multi-agent learning reach symmetric, fair efficient outcome (Wang et al. (2011) later implemented approach actual wireless network
achieved throughput 3 higher standard ALOHA protocols).
coordination signal previous work (Cigler & Faltings, 2011) differ
smart correlation device assumed Aumann (1974)? Firstly, public
cannot send private signals agents. private signals necessary anonymous
agents implement desirable correlated equilibrium single stage resource allocation
game. anonymous agents follow strategy given public signal
value. Secondly, coordination signal specific game. requirement
ergodic, i.e. regularly sends possible values. example
324

fiSymmetric Subgame-Perfect Equilibria Resource Allocation

signal day week, decimal value price certain stock, even noise
frequency.
However, previous solution major limitation: learning algorithm
equilibrium repeated game. selfish agent could force everyone else yield
accessing time, securing resource herself. Therefore, paper, focus
learning algorithms equilibria repeated game. propose
distributed algorithm find allocation set resources symmetric
fair, also equilibrium. draw inspiration works Bhaskar (2000)
Kuzmics, Palfrey, Rogers (2010) symmetric equilibria symmetric repeated
games.
Assume agents play infinitely repeated game, discount future payoffs
common discount factor 0 < < 1. strategy agent mapping
history play probability distribution actions. goal find
symmetric subgame perfect equilibrium. subgame perfect equilibrium strategy profile
(vector strategies every agent) NE history, including
cannot occur equilibrium path.
symmetric subgame perfect equilibria study following form:
agents start choosing actions randomly, according given probability distribution. soon play (asymmetric) pure-strategy Nash equilibrium
game, adopt convention, prescribes actions deterministically
on. Bhaskar (2000) gives two examples conventions symmetric 2-agent, 2-action
games:
Bourgeois Agents keep using action played last round;
Egalitarian Agents play action opponent last round.
paper, extend notion convention arbitrary resource allocation problems N agents C homogeneous resources, show convention,
exists symmetric subgame-perfect equilibrium reaches convention. give
closed form expression calculate subgame-perfect equilibrium bourgeois convention, show small number resources C, convention leads zero
expected payoff. means price anonymity bourgeois convention .
present market convention generalization egalitarian convention
Bhaskar (2000). main idea 1) agents pay price successful access
resource, 2) round game, observe global coordination
signal k {1, . . . , K}, based decide whether resource access.
agents decreasing marginal utility accessing often. price helps
decrease demand resources, global coordination signal effectively
increases capacity K-times. show compared bourgeois convention,
market convention improves expected payoff. price anonymity therefore finite.
paper structured follows: Section 2, review basic notions game
theory, present general definitions conventions implementations.
Section 3, formally define resource allocation game N players C resources,
show convention, exists symmetric subgame-perfect equilibrium
implements it. Section 4 present two concrete examples convention: bourgeois
325

fiCigler & Faltings

market conventions discuss properties. Section 5 discuss relationship
work work folk theorems game theory. Finally, Section 6 concludes.

2. Preliminaries
section, first introduce basic concepts game theory going
use throughout paper. Then, define notion price anonymity. Finally,
give general definition convention implementation.
2.1 Game Theory
Game theory study interactions among independent, self-interested agents.
agent participates game called player. player utility function
associated state world. Self-interested players take actions achieve
state world maximizes utility. Game theory studies attempts
predict behaviour, well final outcome interactions. Leyton-Brown
Shoham (2008) give complete introduction game theory.
basic way represent strategic interaction (game) using so-called normal
form.
Definition 1. (Normal form game) finite, N -person normal-form game tuple
G = (N, A, u),
N set N players;
= A1 A2 . . . , Ai set actions available player i. vector
= (a1 , a2 , . . . , ) called action profile;
u = (u1 , u2 , . . . , uN ), ui : R utility function player assigns
action vector certain utility (payoff).
paper, studying symmetric games. games, players
anonymous, thing influences outcome number agents
took certain action.
Definition 2. (Symmetric game) say normal-form game G = (N, A, u)
symmetric game, permutation vector players : N N, holds
strategy vector = (1 , 2 , . . . , N ) N,
ui (1 , 2 , . . . , N ) = u(i) ((1) , (2) , . . . , (N ) ).
Besides playing single deterministic action, player also choose action
randomly certain probability distribution.
Definition 3. (Mixed strategy) mixed strategy selects probability distribution
entire action space, i.e. (Ai ). mixed strategy profile vector mixed
strategies player. mixed strategy , define support supp(i )
supp(i ) = {ai Ai : (ai ) > 0} .
326

fiSymmetric Subgame-Perfect Equilibria Resource Allocation

Given game specified using normal form, players choose
strategy? players know strategies others, choose action
quite easily: pick strategy maximizes payoff given everyone else
playing:
Definition 4. (Best response) say mixed strategy player best
response strategy profile opponents strategy i0 ,
ui (i , ) ui (i0 , ).
mentioned earlier, one basic goals game theory predict outcome
strategic interaction. outcome stable therefore, usually called
equilibrium. One requirement outcome equilibrium none
players incentive change strategy, i.e. players play best-response
strategies others. defines perhaps important equilibrium concept,
Nash equilibrium:
Definition 5. (Nash equilibrium) strategy profile = (1 , 2 , . . . , N ) Nash
equilibrium (NE) every player i, strategy best response strategies
others .
Correlated equilibrium extends notion Nash equilibrium. canonical interpretation, assumes central correlation device samples space
possible outcomes game according probability distribution, recommends action play player. player incentive deviate
recommended action. formal definition follows:
Definition 6. (Correlated equilibrium) Given N -player game G = (N, A, u),
correlated equilibrium tuple (v, , ), v tuple random variables v =
(v1 , v2 , . . . , vN ) domains = (D1 , D2 , . . . , DN ), joint probability distribution
v, = (1 , 2 , . . . , N ) vector mappings : Di 7 Ai , player
every mapping 0i : Di 7 Ai case
X

(d)ui (1 (d1 ), 2 (d2 ), . . . , N (dN ))

dD

X


(d)ui 01 (d1 ), 02 (d2 ), . . . , 0N (dN ) .

dD

equilibrium, agent chooses best strategy himself. Oftentimes, end
result best agents whole. analyze overall utility game
outcome agents, define social payoff:
Definition 7. (Social payoff ) (mixed) strategy P
vector (1 , 2 , . . . , N ), define
social payoff sum utilities players, N
i=1 ui (1 , 2 , . . . , N ).
2.2 Repeated Game
repeated game, players play given game (for example specified normal
form) repeatedly. call normal form game played round
stage game.
327

fiCigler & Faltings

(1)

(2)

Definition 8. (Future discounted payoff ) Given infinite sequence payoffs ri , ri , . . .
player discount factor , 0 < < 1, future discounted payoff player
Ei :=


X

(j)

j ri .

j=1

Definition 9. (Infinitely repeated game) Let G = (N, A, u) normal form game.
infinitely repeated version G game G discounting game players
play normal form game G infinite number rounds. payoff player
game G defined future discounted reward ri ().
paper, study symmetric equilibria extended version repeated
game, so-called augmented game. assume every round game, players
observe common coordination signal, condition strategy
use. general, coordination signal random integer taken set
{0, 1, . . . , K 1}. practice, piece information observable everyone:
price certain stock given time, temperature room, day week, etc.
signal allow agents coordinate efficiently, time
realistic general correlation device recommends actions agents,
assumed definition correlated equilibria.
Definition 10. (Augmented repeated game) Let G = (N, A, u) normal form
game, let K := {0, 1, . . . , K 1} set coordination signals. augmented infinitely
repeated version G game G discounting game players play normal
form game G infinite number rounds. round t, players observe
coordination signal kt K. coordination signal chosen uniform distribution
K. players discount future payoff discount factor .
W.l.o.g., always assume repeated games augmented, since ordinary
repeated game, assume one coordination signal. Therefore,
rest paper, whenever refer repeated game strategy etc., always
assume game augmented coordination signal.
Definition 11. (History repeated game) Let G infinitely repeated game
discounting. define history ht play round 0

t1
t1
ht := ((a01 , a02 , . . . , a0N ), k0 ), . . . , ((at1
1 , a2 , . . . , ), kt1 )
ati action taken player round t, kt signal players
observe round t.
Definition 12. (Strategy repeated game) strategy repeated game
player function history ht currently observed coordination signal kt
probability distribution action space,
: (ht , kt ) 7 (Ai ).
define Nash equilibrium repeated game way
stage game (we treat repeated game normal form game
players commit strategy entire game front).
328

fiSymmetric Subgame-Perfect Equilibria Resource Allocation

Definition 13. (Nash equilibrium repeated game) strategy profile =
(1 , 2 , . . . , N ) Nash equilibrium infinitely repeated game player
i,
Ei (i , ) Ei (0i , )
(1)
alternative strategy repeated game 0i . Ei ((i , ), ht , kt ) future
discounted payoff player adopts strategy players adopt
strategy vector .
following text, use notion future discounted social payoff:
Definition 14. (Future discounted social payoff ) Given strategy profile
infinitely repeated game G, future discounted social payoff defined
E() :=

N
X

Ei ().

(2)

i=1

repeated games, exists stronger notion equilibria, refinement
standard Nash equilibrium definition.
Definition 15. (Subgame-perfect equilibrium) Let G infinitely repeated game
discount factor 0 < < 1. strategy vector = (1 , 2 , . . . , N ) subgame-perfect
equilibrium game G player i,
Ei ((i , ), ht , kt ) Ei ((0i , ), ht , kt )
strategy 0i , history ht coordination signal kt .
subgame-perfect equilibrium, players play best-response strategy given
history play, including histories cannot occur follow equilibrium
strategy beginning. notion subgame-perfect equilibria eliminates way
non-credible threats, equilibria player threatens someone else strategy
player might prefer avoid supposed executed.
2.3 Price Anonymity
Section 1, seen simple resource-allocation game, symmetric
equilibrium leads significantly lower payoff asymmetric equilibria. Symmetry
equilibria natural requirement players same, i.e. anonymous.
much social payoff sacrifice requirement symmetry? Inspired
price anarchy Koutsoupias Papadimitriou (1999), propose price
anonymity measure efficient given symmetric strategy vector (the term
price anonymity used previously different context Bonnet & Raynal, 2011).
given symmetric strategy vector stage game , calculate ratio
social payoff efficient (potentially asymmetric) Nash equilibrium
game, social payoff strategy vector . formal definition follows:
329

fiCigler & Faltings

Definition 16. (Price anonymity Nash equilibrium) Let G symmetric
game, let = (1 , 2 , . . . , N ) symmetric Nash equilibrium (that i, j : = j ),
let (mixed) Nash equilibrium game G maximum social payoff.
define price anonymity strategy vector follows:
RG () :=

E( )
.
E()

Definition 17. (Price anonymity stage game) Let G symmetric game,
) symmetric Nash equilibrium minimal social payoff,
let = (1 , 2 , . . . , N
let (mixed) Nash equilibrium game G maximum social payoff.
define price anonymity game G follows:
RG :=

E( )
.
E( )

infinitely repeated games, define price anonymity subgame-perfect
equilibria:
Definition 18. (Price anonymity repeated game) Let G symmetric game,
let = (1 , 2 , . . . , N ) symmetric subgame-perfect equilibrium minimal social
payoff, let subgame-perfect equilibrium game G maximum social
payoff. define price anonymity game G follows:
RG :=

E()
.
E( )

2.4 Conventions Implementations
shown example 2-agent, 1-resource allocation game Section 1,
exist symmetric games nevertheless asymmetric efficient equilibria.
allow central coordination device, agents play symmetric efficient
correlated equilibrium selects randomly set efficient Nash equilibria. Without device, stage game, way reach symmetric efficient outcome
equilibrium.
However, agents play game repeatedly, use history play
condition strategy. two agents different histories, take different
actions future. first round game though, history empty
everyone. Therefore, symmetric strategy players randomize order ever
reach point histories agents distinct.
Bhaskar (2000) considered problem playing asymmetric outcomes stage
game using symmetric strategy repeated game. work considers games 2
players 2 actions, 1-resource allocation game. idea two players start playing randomly, using probability distribution actions.
randomize reach round happen play pure-strategy Nash
equilibrium (that is, take different action each). call round asynchrony
round. Then, agents start following so-called convention. convention maps
asymmetric pure-strategy Nash equilibrium (potentially asymmetric) strategy vector
agents adopt.
330

fiSymmetric Subgame-Perfect Equilibria Resource Allocation

already mentioned two basic conventions proposed Bhaskar (2000):
bourgeois egalitarian convention. 1-resource allocation game, asynchrony
round, one agent chooses action one chooses . call agent
chose asynchrony round winner. agent loser. bourgeois
convention guarantees agents keep playing NE forever after. way,
winner forever guaranteed higher payoff loser. egalitarian
convention, players alternate two pure-strategy Nash equilibria. way
payoffs winner loser closer.
infinitely repeated game discounting, social payoff depend two
things: discount factor , probability collision, probability
players play action A. big difference winner loser
payoff, losers fight back harder, play preferred action
higher probability. increase probability collision. egalitarian
convention, payoffs loser closer winner. Therefore, agents
collide less often, also reach asynchrony faster.
another example convention, Kuzmics et al. (2010) analyze Nash demand
game. Nash demand game game N players choose N actions
labeled 1, . . . , N . players choose distinct action, player receives payoff
equal label chosen action. two players chose
action, every player (including chose action alone) receives zero payoff.
pure-strategy Nash equilibrium, players choose different action. Naturally,
player prefers equilibrium one chose action N .
Nash demand game, also define bourgeois egalitarian conventions.
Kuzmics et al. (2010) define three notions payoff symmetry:
Ex-ante agents expected payoffs game starts.
Ex-post agents expected payoffs asynchrony occurs (regardless
winner).
Strong ex-post agents payoff along realization play.
bourgeois convention ex-ante payoff symmetric, since asynchrony occurs, winner gets higher payoff loser. egalitarian convention strong
ex-post payoff symmetric. fact, Kuzmics et al. (2010) show Nash demand
game, convention socially efficient, must strong ex-post payoff symmetric.
intuition order maximize social efficiency, want reach asynchrony fast
possible. possible agents choose actions uniformly random.
indifferent action choose moment
asynchrony occurs.
formally define convention augmented repeated game N agents.
Definition 19. (Convention) Let G = (N , A, u)
let G repeated version game G.
maps vector pure-strategy Nash equilibria
= (a1 , a2 , . . . , aK ) vector strategies
331

symmetric normal form game
define convention function
game G signal value
repeated game G,

fiCigler & Faltings

permutation : N N set players,
(((a1 ), . . . , (aK ))) = ((a1 , a2 , . . . , aK ))

(3)

is, convention permutation permutation convention (here denotes
strategy player i). strategies different coordination signal value.

use notation (a) := a(1) , . . . , a(N ) , ((a)) := (1) (a), . . . , (N ) (a)
denote permutation history vector using , permutation strategy
vectors respectively.
definition convention generalizes definition Bhaskar (2000) gave symmetric
games 2 players two actions , . Bhaskar defined convention mapping
set Nash equilibrium action profiles {(, ), (, )} set strategies
players alternate strategy profiles (, ) (, ) order. definition,
convention maps Nash equilibrium stage game strategy profile, provided
satisfies permutation condition.
Intuitively, convention prescribes agent potentially different role. problem
anonymous agents learn role. call learning algorithm
use implementation convention.
Definition 20. (Implementation) Let G infinitely repeated game, let
convention defined game. implementation convention strategy
vector infinitely repeated game, function assigns
: (ht , kt ) 7 (A1 ) . . . (AN ),
satisfies following conditions:
Let ht history game time t.
1. players already played pure-strategy Nash equilibrium coordination signals k K round t0 < (t0 round played
NE last signal), follow strategy prescribed convention
history ht \ ht0 (that is, history round t0 + 1 onwards).
2. Otherwise, let kt signal observed current round, let vector =
(a1 , a2 , . . . , aK ) ak action vector last round signal
k observed (if signal k observed yet, define ak = ). Then, actions
players current round depend vector (abusing notation,
write (ht , kt ) = (a, kt )), permutation : {1, 2, . . . , N }
{1, 2, . . . , N },

(,1 ((a), kt ), . . . , ,N ((a), kt )) = ,(1) (a, kt ), . . . , ,(N ) (a, kt ) ,
strategy current round depends actions played
last round signal observed, current coordination signal.
Section 3, concerned equilibrium strategies resource allocation
game. is, look symmetric subgame-perfect equilibria. construct
equilibria, define concepts equilibrium convention, equilibrium
implementation.
332

fiSymmetric Subgame-Perfect Equilibria Resource Allocation

Definition 21. (Equilibrium convention) Let G infinitely repeated game, let
convention. say convention equilibrium convention
every vector pure-strategy Nash equilibria = (a1 , . . . , aK ), (a) vector subgameperfect equilibria game G.
Definition 22. (Equilibrium implementation) Let G infinitely repeated game,
equilibrium convention, implementation convention . say
equilibrium implementation subgame-perfect equilibrium.

3. Resource Allocation Game
section, first formally define resource allocation game, discuss
Nash equilibria. show equilibrium convention resource
allocation game, exists equilibrium implementation.
3.1 Definitions
first define resource allocation game, restricted notions uniform convention uniform implementation.
Definition 23. (Resource allocation game) resource allocation game GN,C game
N agents. agent access one C identical resources. agent chooses
action ai Ai = {Y, A1 , A2 , . . . , AC }, action ai = means yield, action
ai = Ac means access resource c. resources identical, define
special meta-action ai = A. take action means choose access, choose
resource uniformly random set available resources.
payoff function agent defined follows:

0
ai =



1
ai 6= Y,
ui (a1 , . . . , ai , . . . , ) :=
(4)
j
6= i, aj 6= ai



< 0 otherwise
game set pure strategy NEs C agents access resource ci
N C agents not. also symmetric mixed strategy NE agent
decides play action probability

(
! )
||
Pr(ai > 0) := min C 1 N 1
,1 .
(5)
1 + ||
Note high enough values C, agents always choose access. 1
Since assume resources identical, agents start following
convention, expected future payoff shouldnt depend resource
1. resource allocation game defined instance class games known potential games
(Monderer & Shapley, 1996). (exact) potential game, exists potential function : R
00
ai Ai , a0i , ai Ai ,
(a0i , ai ) (a00i , ai ) = ui (a0i , ai ) ui (a00i , ai ).

333

fiCigler & Faltings

accessed Nash equilibrium. therefore restrict so-called uniform
conventions:
Definition 24. (Uniform convention) Let GN,C resource allocation game, GN,C
infinitely repeated version. Let convention. say convention
uniform convention, following holds: Let = (a1 , a2 , . . . , aK ) vector purestrategy Nash equilibria coordination signal. Let player i, ci number
signals player accesses resource action vector a.
i, j : ci = cj = Ei ((a)) = Ej ((a)).
is, number signals two players access resource
same, expected payoff remainder game too.
Definition 25. (Losers, winners, claimed unclaimed resources) Let GN,C
infinitely repeated resource allocation game, let ht history play round t,
let ak = (ak1 , ak2 , . . . , akN ) action vector played last round signal k
observed.
Player winner signal k aki = Ai players j 6= i, akj 6= Ai ;
Player loser signal k otherwise;
Resource c claimed signal k, exists exactly one player aki = Ac ;
Resource c unclaimed signal k otherwise.
signal k never observed before, players losers resources
unclaimed signal k.
Definition 26. (Uniform implementation) Let GN,C infinitely repeated resource
allocation game, let uniform convention. uniform implementation defined
follows: Let ht history game time t, let kt signal observed
current round.
1. players already played pure-strategy Nash equilibrium coordination signals follow strategy prescribed convention .
2. Otherwise, let n number losers signal kt , let c number
unclaimed resources signal k. strategy prescribed implementation
round following:
action vector co occupied resources, nA agents access resource,
exact potential function resource allocation game
(a) := co + (nA co ).
Exact potential games also referred congestion games (Rosenthal, 1973). Finite versions
games always guaranteed pure-strategy Nash equilibrium. Moreover, agents
reach pure-strategy Nash equilibrium starting arbitrary action vector a0 iteratively
playing best-response action, one one. players anonymous update strategies
simultaneously, study paper, doesnt hold. Hence, theory potential games cannot
applied scenario study paper.

334

fiSymmetric Subgame-Perfect Equilibria Resource Allocation

Agents follow implementation

Asynchrony

Initial state

Agents follow
convention

n=4
c=3

n=3
c=2

n=2
c=1

n=1
c=0

Figure 1: Learning play convention resource allocation game N = 4 agents
C = 3 resources. state, denote number losers
current state n, number unclaimed resources c. Winners denoted
black circles, losers light grey circles. asynchrony state,
3 winners one loser. Arrows indicate possible transitions
states. players reach asynchrony state, start following
convention next round on.

player winner signal kt , access resource
last time signal kt observed.
player loser, access choose access unclaimed resource r
p
probability 0 (n,c)
1. probability accessing claimed resource
c
zero.
remainder section, instead studying general strategies repeated
game, limit strategies uniform implementation.
Figure 1 shows agents learn follow convention N = 4 C = 3.
Assume players adopt convention , use implementation . Initially,
losers, implementation prescribes strategy them.
agent accesses resource alone, becomes winner access
resource agents reach asynchrony round (a state resource accessed
exactly one agent).
Definition 27. (Expected payoff functions EA EY ) Let GN,C infinitely
repeated resource allocation game, let uniform convention equilibrium
implementation. Let ht history game round t, k K,
Nash equilibrium reached (and convention activated yet).
Let nk number losers signal k K ck number unclaimed resources
signal k K. Let p = (pn1 ,c1 , . . . , pnK ,cK ) access probability losers
335

fiCigler & Faltings

signal k K. Let kt currently observed coordination signal. Let w (nw )
expected payoff new winner (player loser previous rounds becomes
winner round t) given nw new winners round t. Let l (nw )
expected payoff player stays loser, nw new winners round t.
Assume player loser signal kt . define expected payoff functions EA
EY takes action (or ) signal kt , adopts strategy prescribed
implementation signals:
EA (p, kt ) :=
min(n,c)

X

[Pr( wins & nw winners|A)w (nw ) + Pr( loses & nw winners|A)( + l (nw ))]

nw =1







K
X






+ Pr(0 winners|A) +
E
(p,
k)
+
(p
E
(p,
l)
+
(1

p
)E
(p,
l))
n
,c
n
,c



l
l
l
l

K
l=1
l6=k

(6)
min(n,c)

EY (p, k) :=

X

Pr(nw winners|Y ) l (nw )

nw =1





K
X


EY (p, k) +
(pnl ,cl EA (p, l) + (1 pnl ,cl )EY (p, l))
+ Pr(0 winners|Y )


K

(7)

l=1
l6=k

3.2 Existence Equilibrium Implementation
ready prove uniform equilibrium convention, exists
equilibrium implementation.
Lemma 1. signal k K, functions EA EY continuous p h0, 1iK .
Proof. probabilities Pr(nw winners|A) Pr(nw winners|Y ) continuous.
functions EA EY sums products continuous functions, must continuous.
Lemma 2. Functions EA EY well-defined k K p h0, 1iK .
Proof. fixed p, , functions EA EY define system 2K linear equations.
write system (I A)E = b, E = (EA,1 , . . . , EA,K , EY,1 , . . . , EY,K )
vector variables corresponding payoff functions, b R2K 2K 2K unit
matrix. matrix defined follows: first K rows correspond variables EA,k
second K rows correspond variables EY,k .
elements row k corresponding EA,k defined as:

l = k
Pr(0 winners|A, pnk ,ck ) K



0
l = K + k
Ak,l :=

Pr(0
winners|A,
p
)


p
l K, l 6= k

nk ,ck
nl ,cl

K


Pr(0 winners|A, pnk ,ck ) K (1 pnl ,cl ) K < l 2K, l 6= K + k
336

fiSymmetric Subgame-Perfect Equilibria Resource Allocation

elements row K + k corresponding EY,k defined as:

AK+k,l


Pr(0 winners|Y, pnk ,ck )



0
:=
Pr(0
winners|Y, pnk ,ck )



Pr(0 winners|Y, pnk ,ck )


K

K

K




pnl ,cl
(1 pnl ,cl )

l =K +k
l=k
l K, l 6= k
K < l 2K, l 6= K + k

system equations unique solution matrix non-singular.
equivalent saying det(A) 6= 0.
PK
matrix diagonally dominant, aii >
j=1,j6=i |aij |.
P2K
0 < < 1, rows matrix sum l=1 Ak,l = Pr(0 winners|A, pnk ,ck )
P
1 < k K, 2K
l=1 AK+k,l = Pr(0 winners|Y, pnk ,ck ) K < K + k 2K.
known diagonally dominant matrices non-singular (Taussky, 1949). Therefore, unique solution E system exists functions EA , EY well-defined
fixed p, .
Lemma 3. exists p k K, one following true:
1. pk = 0 EY (p , k) > EA (p , k);
2. pk = 1 EA (p , k) > EY (p , k);
3. 0 < pk < 1 EA (p , k) = EY (p , k).
p defines symmetric best-response strategy losers.
Proof. Fix . show arbitrary p every signal k K,
exists p0k satisfies one three conditions Lemma 3 above.
contradiction, assume p0k = 0, EY (p0 , k) EA (p0 , k) p0k = 1,
EA (p0 , k) EY (p0 , k). fact functions EA EY well-defined
continuous 0 pk 1, must intersect 0 < p0k < 1.
this, must exist vector p k K, conditions
Lemma 3 satisfied.
Corollary 1. Let GN,C infinitely repeated resource allocation game. uniform
equilibrium convention game GN,C , exists equilibrium implementation .
illustrate different equilibrium payoffs agents get adopt different
conventions, consider resource allocation game N = 4 agents C = 1 (to
simplify presentation, assume K = 1). Assume round t, resource
claimed yet, n = 4 losers c = 1 unclaimed resource.
agent becomes winner round t, agents adopt extended uniform convention
prescribes strategies on.
comparison, assume agents adopt either convention 1 , convention

2 . adopt convention 1 , winners expected payoff w1 = 4, losers
expected payoff l = 0. hand, adopt convention 2 , winners
1

expected payoff w2 = 2, losers expected payoff l2 = 1.
337

fiCigler & Faltings

(a) Convention 1

(b) Convention 2

Figure 2: Example expected payoff functions resource allocation game N = 4
agents, C = 1 resources, cost collision = 2 discount factor = 0.8,
1 E 1 expected payoff
given access probability p. function EA

functions accessing yielding, agents use extended convention
2 E 2 expected payoff functions agents use
1 . Similarly, EA

extended convention 2 . Convention 1 expected winner payoff w1 = 4,
expected loser payoff l = 0. Convention 2 expected winner payoff
1

w2 = 2 expected loser payoff l2 = 1.
equilibrium implementation 1 convention 1 , agents access
resource probability p1 , expected payoff E1 = 0.
equilibrium implementation 2 convention 2 , agents access resource
probability p2 < p1 , expected payoff E2 > E1 = 0.

1 E 1 convention , E 2
Figure 2 shows expected payoff functions (EA
1


2

EY convention 2 ), depending access probability p. see
equilibrium implementation payoff E2 convention 2 higher equilibrium
payoff E1 convention 1 , even though sum winner loser payoffs higher
convention 1 . loser receives positive payoff agents adopt
convention 2 ; agents less likely fight become winner, access
resource lower probability p2 < p1 . way, less collisions,
agents receive higher expected social payoff adopt convention 2 .

3.3 Calculating Equilibrium
symmetric subgame-perfect equilibrium guaranteed exist, order actually
play it, agents need able calculate it. always possible obtain
338

fiSymmetric Subgame-Perfect Equilibria Resource Allocation

closed form probability accessing resource. Therefore, show
calculate equilibrium strategy numerically.
Let p probability vector k signal. Let p0 := (p1 , p2 , . . . , pk = 0, . . . , pK ), i.e.
vector p pk set 0. Let p1 := (p1 , p2 , . . . , pk = 1, . . . , pK ). Lemma 3 know
either EY (p0 , k) > EA (p0 , k), EA (p1 , k) > EY (p1 , k) two functions intersect
0 pk 1. Furthermore, know EA (p0 , k) = w (c) since probability
successfully claiming resource 1 everyone else yields, also EY (p0 , k) = 0.
Therefore, EY (p0 , k) > EA (p0 , k) iff w (c) > 0.
W.l.o.g, assume w (c) > 0. Algorithm 1 shows calculate
probability vector.
Algorithm 1 Calculating equilibrium probabilities
subset {1, 2, . . . , K}
Let system equations

/ S, contains two equations E(p, i). One corresponding EA (p, i), one
EY (p, i) (see Equations 6 7).
j S, set pj := 1. contains one equation E(p, j), corresponding
EA (p, j).
system 2K |S| equations 2K |S| variables.
Solve numerically system equations .
exists solution
/ S, 0 pi 1
found solution
break;
end
end
numerical algorithm complexity exponential K, therefore suitable small K. Section 4.2.3, show conditions access probabilities easy compute define -equilibrium repeated game. is,
agent gain factor deviating prescribed strategy.

4. Actual Conventions
previous section, shown find symmetric way reach
convention, provided agents access resources certain probability.
also shown calculate resource access probability every stage game.
section, would like show specific examples conventions agents
adopt, discuss properties.
4.1 Bourgeois Convention
bourgeois convention simplest one. agent accessed resource
successfully first time, keep accessing forever. say agent
claimed resource. dont need coordination signal implement it, set
K := 1.
339

fiCigler & Faltings

describe decision problem point view agent . Assume
N agents C resources. round t, let ct number resources
claimed yet, nt := N C +ct number players claimed
resource yet. Assume players besides use following strategy:
player claimed resource previously, keep accessing it;
player hasnt claimed resource yet (she loser), choose access
probability pct choose actual resource access uniformly random.
Definition 28. (Expected payoff function Bourgeois convention) Let p :=
(p1 , p2 , . . . , pC ) probability vector, pc probability
losers access c unclaimed resources. define expected payoff
function player choose access (play A, choose access
choose resource uniformly random) yield (play ), respectively:



p n1
1
p n1
EA (p, c) := 1

+ 1 1
()
c
1
c
c
X
Pr( loses nw = l|A) E(p, c l);
+


l=0

EY (p, c) :=

c
X

Pr(nw = l|Y ) E(p, c l);

l=0

equations, E(p, c) = max {EA (p, c), EY (p, c)}.
Lemma 4. p 1 c C, E(p, c) 0.
Proof. matter strategy opponents, agent chooses always yield,
payoff 0.
Lemma 5. Let p probability vector defines strategies losers,
let ct number unclaimed resources round t. c ct , EA (p, c) = EY (p, c),
c ct , E(p, c) = 0.
Proof. ct unclaimed resources round t, every following round t0
c ct unclaimed resources (in bourgeois convention, agents never release
claimed resources). agent indifferent actions every round
following round t, means indifferent strategy subgame
prescribes every round strategy. (expected) payoff strategy
prescribes always 0. Therefore, expected payoff subgame strategy
must 0 well.
purpose problem, unclaimed resources identical. Therefore
parameter losers strategy probability agents decide
access resource chosen uniformly random. Lemma 5 shows necessary
condition p agent indifferent. following lemma shows p exists
unique.
340

fiSymmetric Subgame-Perfect Equilibria Resource Allocation

Lemma 6. Assumeat timer

ct unclaimed resources. Let c ct unclaimed
||
resources pc = c 1 n1 ||+ 1
probability losers play A.
1

c ct unclaimed resources, agent indifferent yielding accessing.
given c, probability unique interval [0, c].
Proof. Lemma 5 know agent indifferent (i.e. EA (p, c) = EY (p, c)),
must E(p, c) = 0 1 c ct .
Definition 28, expected profit agent playing following
best-response strategy (with zero payoff)




pc n1
1
pc n1
EA (p, c) = 1

+ 1 1
()
c
1
c
(8)
+ Pr( loses nw = 0|A) E(p, c).
pc probability losers access. want EA (p, c) =
EY (p, c) = 0. holds pc defined lemma above.
Function EA decreasing pc interval [0, c], function EY constantly 0.
Therefore, intersection unique interval [0, c].
Lemma 7. Assume opponents havent claimed resource access resource probability p < pc . best-response agent access.
Proof. probability agent claims successfully resource playing

p n1
Pr(claim resource|A) := 1
(9)
c
probability increases p decreases. Therefore expected profit playing
increasing p decreases, whereas profit playing stays 0.
Theorem 8. Define agents strategy follows: c unclaimed resources,
play probability pc := min (1, pc ) (where pc defined Lemma 6). joint
strategy profile = (1 , 2 , . . . , N ) c, c = subgame-perfect equilibrium
infinitely repeated resource allocation game.
Proof. Lemma 6, pc < 1, agent indifferent playing playing A,
therefore happily follow strategy . Lemma 7, pc = 1 < pc , best response
agent play A, strategy prescribes.
Theorem 9. c N, pc = pc , E(p, c) = 0.
Proof. proceed induction.
c = 0, expected payoff trivially E(p, 0) = 0, free resources.
Let j < c, E(p, j) = 0 pc = pc . agent plays , expected payoff clearly 0
(it 0 0 future induction hypothesis). agent plays A,
expected payoff (by Definition 28):

pc n1
1

EA (p, c) := 1
c
1


c
(10)


X
pc n1
Pr( loses nw = l|A) E(p, c l)
+ 1 1
() +
c
l=0

341

fiCigler & Faltings

way pc defined, induction hypothesis E(p, j) = 0
j < c, get
EA (p, c) := Pr( loses nw = 0|A) E(c, )
= Pr( loses nw = 0|A) max{EA (p, c), EY (p, c)}

(11)

Since Pr( loses nw = 0|A) < 1, must EA (p, c) = 0.
Theorem 10. pc < pc , E(p, c) > 0.
Proof. Lemma 7 know pc < pc , best response access,
E(p, c) = EA (p, c). Lemma 4 know j, E(p, j) 0. pc < pc ,
Definition 28 see E(p, c) > 0.
Theorem 10 shows enough resources pc 1, expected payoff
agents, even access time, positive.
Given number agents N , discount factor collision cost , necessary
number resources c expected payoff positive is:
c :=
1

1
r
n1

||
1
||+ 1

(12)

Figure 3 illustrates value c depending N , , respectively. Figure 3a shows
number resources c increases N increases naturally, agents need
resources.
Figure 3b shows hand increasing discount factor , necessary number resources drops. high , agents almost indifferent
winning winning later. Section 4.2.3, explore idea
detail show high enough delta, strategy prescribes agents
access constant probability reach asynchrony -equilibrium
resource allocation game.
Finally, Figure 3c shows increasing number resources necessary
bourgeois convention positive payoff, collision cost increases. increase
almost linear . higher cost collision, lower expected
payoff accessing EA . bourgeois convention positive expected payoff,
need EA > 0 0 p 1.
Let us look price anonymity bourgeois convention (as defined
Definition 16).
Theorem 11. price anonymity bourgeois convention infinite.
Proof. highest social payoff strategy profile achieve N -agent, C-resource
allocation game (N C)
C
max E( ) :=
.
(13)
1
achieved every round, every resource accessed exactly one agent.
strategy profile obviously asymmetric.
342

fiSymmetric Subgame-Perfect Equilibria Resource Allocation

25

20

200

20
15

150

15
C*

C*
10

C*
100

10
5
0
0

50

5
5

10
N

15

20

0
0

0.5


(a) N

1

0
0

50


(b)

100

(c)

Figure 3: Minimum number resources c needed expected payoff bourgeois
convention positive, depending N , , . One parameter varying,
parameters set N = 10, = 0.8, = 2. varying N ,
dashed line shows c = N .

3.5
N=3
N=4
3

2.5
R
2

1.5

1
0.1

0.2

0.3

0.4

0.5

0.6

0.7

0.8

0.9

Figure 4: Market convention: Price anonymity C = 1, K = N , = 0.5 varying .

agent knew part bourgeois convention play beginning
game, convention would socially efficient. However, agents anonymous,
learn part convention play randomization.
bourgeois convention small C relative N , randomization
agents indifferent accessing resource yielding, expected
payoff zero. Therefore, price anonymity infinite.
4.2 Market Convention
saw bourgeois convention leads zero expected social payoff small
number resources. would like improve expected payoff here. bourgeois
convention, agents receive zero expected payoff demand resources
high compared supply. need decrease demand, increasing
343

fiCigler & Faltings

2.5
N=3
N=4

2
R

1.5

1
0

1

2

3

4

5

Figure 5: Market convention: Price anonymity C = 1, K = N , = 0.9 varying .

supply. often achieved markets. Shneidman et al. (2005) present
reasons markets might appropriate resource allocation.
assume following:
Agents observe K 1 coordination signals.
Agents decreasing marginal utility access resource often.
pay fixed price per successful access, point agent prefers
access resource one signal K. practice, could implemented central authority observes convergence rate agents,
dynamically increases decreases price achieve convergence.
assumptions define call market convention, winners access claimed resource signals observed first claimed it.
price agents pay serves decrease demand. coordination signal effectively increases supply resources K-times, resource allocation may
different signal values.
know implement convention C 1 resources using symmetric
play (see Section 3). small K, also use Algorithm 1 calculate access
probabilities. ease exposition, first describe market convention
C = 1 resource. generalize description C > 1 resources.
4.2.1 One Resource
agent accesses resource one signal, need K = N signals make
sure everyone gets access once.
N -agent, 1-resource case, imagine still n agents playing (N n)
agents already claimed resource signal. Imagine n agents
observe one n signals resource claimed.
344

fiSymmetric Subgame-Perfect Equilibria Resource Allocation

Assume agents access resource probability pn . expected payoff
accessing resource agent



1
EA (pn , n) := (1 pn )
1+

N 1




n
+ 1 (1 pn )n1 +
EA (pn , n)
N (N n)
n1



(14)

expected payoff yielding agent

EY (pn , n) := (n 1)pn (1 pn )n2 E(n 1)


n
EY (pn , n)
+ 1 (n 1)pn (1 pn )n2
N (N n)

(15)

pn = 1, accessing resource always lead collision, payoff
accessing negative. pn = 0, accessing resource always claim it,
payoff accessing positive. equilibrium, agents indifferent
accessing yielding. Therefore, want find pn EA (pn , n) =
EY (pn , n) = E(n).
Finding closed form expression pn difficult, use Algorithm 1
calculate probability, well expected payoff E(n), numerically (albeit practice
small K).
Figures 4 5 show price anonymity market convention (as defined
Definition 16) varying discount factor , varying cost collision , respectively.
Section 4.1, price anonymity C = 1 . contrast, market
convention price cases finite relatively small.
4.2.2 Multiple Resources
Assume C 1. given round, denote c := (c1 , c2 , . . . , cK )
vector resources claimed yet value coordination
signal k {1, 2, . . . , K}. denote n number players claimed
resource yet signal value. Finally, let p := (pn,c1 , pn,c2 , . . . , pn,cK ) vector
probabilities, pn,ck denotes probability loser access resource
signal k K, given ck resources available.
Corollary 1, know market convention, exists equilibrium
implementation. look like exactly? order able express (albeit
numerically), need define expected payoff functions players receive
action.
345

fiCigler & Faltings

number losers n, observed coordination signal k vectors p c,
define expected payoff functions player takes action , respectively:
EA (p, c, n, k) := Pr( wins|A) w + (1 Pr( wins|A)) ()
min(ck ,n)

+

X

Pr( loses, nw winners|A) E(p, (ck nw , ck ), n nw )

nw =1

+ Pr(nw = 0|A)


EA (p, c, n, k)
K



+ Pr(nw = 0|A)
K

K
X
l=1
l6=k

(16)



(pn,cl EA (p, c, n, l) + (1 pn,cl )EY (p, c, n, l))


min(n,c)

EY (p, c, n, k) :=

X

Pr(nw winners|Y ) E(p, (ck nw , ck ), n nw )

nw =1


+ Pr(nw = 0|Y )



K
X


EY (p, c, n, k) +
(pn,cl EA (p, c, n, l) + (1 pn,cl )EY (p, c, n, l))


K
l=1
l6=k

(17)
equations above, E(p, c, n) expected payoff players observe
coordination signal. defined
E(p, c, n) :=

K
1 X
E(p, c, n, k).
K
k=1


winner payoff w defined w := 1 + K(1)
. winner
access one signal: current round, future round
probability K1 .
probabilities nw winners cases?
start simplest case, Pr(nw winners|Y ), given n agents (including
agent ), ck resources agents except play action probability pk .
problem calculating probability similar well-known balls-andbins problem (Raab & Steger, 1998). balls-and-bins problem assume
n balls randomly assigned one c bins. goal find
probability bins exactly one ball them. express probability
(n, c, i).
Ni ways pick balls, place bins bin
one ball, place remaining n balls remaining c bins randomly,


c n
Ni :=
i! (c i)ni


346

(18)

fiSymmetric Subgame-Perfect Equilibria Resource Allocation

total cn ways arrange n balls c bins. Therefore, probability
(n, c, i) total number ways place n balls c bins exactly one
ball obtained generalized inclusion-exclusion principle:
1
(n, c, i) := n
c
1
= n
c
=

min(c,n)

X

ji

(1)

j=i
min(c,n)

X

ji

(1)

j=i


j
Nj



j
c n
j! (c j)nj

j
j

(19)



min(c,n)
nj
X
n! c
ji c (c j)
(1)
.
j (n j)!
cn
j=i


ci
simplification above, use absorption identity ji jc = ci ji
.
use function calculate Pr(nw winners|Y )? n 1 agents (other
) decide play action probability pk , choose resource access
randomly. agents choose access resource correspond balls-and-bins
problem. Therefore,
Pr(nw winners|Y ) :=

n1
X


n1
pk (1 pk )n1i (i, c, nw ).


i=0

(20)

calculate probability Pr( wins|A), proceed follows. assume w.l.o.g
accesses resource 1. agents (out n 1) choose action
A. need choose resource 1. Therefore,
Pr( wins|A) :=

n1
X
i=0




n1
1

n1i
pk (1 pk )
1
c


(21)

Finally, calculate probability Pr( loses, nw winners|A), use
balls-and-bins problem. Given 0 n 1 agents choose action A,
0 j agents choose resource agent . remaining
(i j) agents face balls-and-bins problem c 1 bins (1 bin already occupied
agent ). Therefore,
Pr( loses, nw winners|A) :=

n1
j
X n 1
X

1
1 ij
1
(i j, c 1, nw )
pik (1 pk )n1i

j
c
c
i=1

j=1

(22)
expressed expected payoff functions EA EY explicitly,
use Algorithm 1 calculate equilibrium access probabilities expected payoffs.
Figures 6 7 show price anonymity market convention C = 3, K = 2
N = C K = 6. discount factor grows, price anonymity decreases
347

fiCigler & Faltings

600

Price anonymity

500

400

300

200

100

0
0.1

0.2

0.3

0.4

0.5


0.6

0.7

0.8

0.9

Figure 6: Market convention: Price anonymity N = 6, C = 3, K = 2, = 0.5
varying .

2.6
2.5

Price anonymity

2.4
2.3
2.2
2.1
2
1.9
1.8
1.7
0

1

2

3

4

5



Figure 7: Market convention: Price anonymity N = 6, C = 3, K = 2, = 0.9
varying .

(note Figure 6 y-axis logarithmic). small , benefit
winning resource right away much higher payoff winning later.
hand, gets closer 1, agents dont care whether win later.
Since market convention guarantees everyone able access resource
signal value, 1, expected payoff winner losers
same. Also, 1, cost agents pay learning convention decreases
compared payoff obtain learnt it.
increases, price anonymity increases. cost collision direct
effect expected payoff functions EA EY . Therefore, expected equilibrium
348

fiSymmetric Subgame-Perfect Equilibria Resource Allocation

payoff higher cost lower. Changing effect optimal
asymmetric outcome though, since agents dont pay cost
collisions.
4.2.3 -equilibrium
Calculating equilibrium access probabilities market convention difficult
need use numerical algorithm, number signals K grows, number
equations grows exponentially. Therefore, would like find access probabilities
easy compute agents incentive deviate small. Indeed,
game theory often interested -equilibria, agent improve payoff
> 0.
market pricing ensures agent wants access resource one signal
value. also doesnt depend access probabilities agents, utility
functions. agents converge asynchrony round (i.e. pure-strategy NE
resource allocation every signal value), future expected payoff
K 1
,
1

(23)

agent improve payoff deviating since players playing PSNE
stage game round.
agents havent claimed resource yet play action constant
probability 0 < pconst < 1, expected time reach asynchrony finite.
(from properties balls-and-bins problem, see Section 4.3, Raab & Steger,
1998). prove following theorem:
Theorem 12. Suppose N -agent, C-resource allocation game, agents adopt
market convention following implementation: agents havent claimed
resource yet play action constant probability pconst (we call constantprobability implementation). Let E() expected payoff agent case
given discount factor . Let E 0 () expected payoff best-response strategy
convention implementation.
> 0, exists 0 < 0 < 1 , 0 < 1,
E()
> 1 .
E 0 ()

(24)

Proof. market pricing, agent wants access one resource one
value coordination signal. best-response payoff E 0
E 0 ()

K 1
,
1

(25)

matter strategy agents play.
agents adopt market convention constant-probability implementation, every round converge PSNE, receive payoff
< 0 (the collision cost) 1. reach PSNE, expected payoff
K 1
1
349

(26)

fiCigler & Faltings

stated above. therefore say
E()


X
i=0


1
+ K 1
Pr(agents reach PSNE steps)
1
1



(27)

define random variable X X = agents reach PSNE
exactly steps. properties expected value, ee


(1 E X ) + K 1 E X
E()
.
(28)
1
function (x) := x convex function. Jensens inequality (1906), know


E X E[X] .
(29)
Therefore,

1 E[X] + K 1 E[X]
E()

.
E 0 ()
K 1

(30)

expected time E[X] reach PSNE finite doesnt depend ,
treat constant. E[X] continuous , monotonous lim1 E[X] = 1,
see given > 0, exists 0 < 0 < 1 , 0 < 1,
E()
> 1 .
E 0 ()

(31)

ensuring agent wants access resource one signal value,
market convention makes cooperative strategy previous work (Cigler &
Faltings, 2011) almost rational.
4.3 Expected Convergence Time
section, analyze expected number rounds agents need
converge perfect allocation resources (one resources used exactly one,
collisions). first prove upper bound expected number
steps convergence bourgeois convention, present experiments
market convention.
4.3.1 Bourgeois Convention
order prove convergence bourgeois convention, describe execution
Markov chain. Markov chain describing execution bourgeois convention
N -agent, C-resource allocation game chain whose state round Xt {0, 1, . . . , C},
Xt = c means c unclaimed resources round t.
interested expected number rounds take Markov chain
reach state 0 started state C. called expected hitting time:
350

fiSymmetric Subgame-Perfect Equilibria Resource Allocation

Definition 29. (Norris, 1998) (Hitting time) Let (Xt )t0 Markov chain state
space I. Given probability space (, , Pr), hitting time subset random
variable H : {0, 1, . . .} {} given
H () = inf{t 0 : Xt () A}
general, expected hitting time set states found solving
system linear equations:
Theorem 13. vector mean hitting times k = E(H ) = (kiA : I) minimal
non-negative solution system linear equations

ki = 0 P

(32)

kiA = 1 + j
p
k
/A
ij j
/
Solving analytically Markov chain however difficult. Fortunately,
Markov chain one absorbing state = 0, move state
j j, use following theorem derive upper bound hitting time
(proved Rego, 1992):
Theorem 14. Let = {0}.
1 : E(Xt+1 |Xt = i) <
> 1,


kiA < log +





1

order use Theorem 14, need calculate expected state E(Xt+1 |Xt = c).
Lemma 15. Let Xt = c, let n := N C + c agents claimed
n1
resource claimed
resource yet. Let us denote q(n, c) = pc n 1 pc
round agents play subgame-perfect equilibrium strategy vector described above.
next expected state
E(Xt+1 |Xt = c) := (1 q(n, c)) c
Proof. resource i, denote Wi random variable, Wi = 1 resource
claimed round t, Wi = 0 otherwise. random variable Wi Bernoullidistributed probability q(n, c).
next expected state
" c
#
c
X
X
E(Xt+1 |Xt = c) = c E
Wi = c
E[Wi ] = (1 q(n, c)) c,
(33)
i=1

i=1

E[Wi ] = q(n, c).
following lemmas, denote
:=

||
1
|| + 1
351

(34)

fiCigler & Faltings

Lemma 16. given collision cost discount factor , exists constant
0 < < 1 c n, p < 1.
Proof. According
definition subgame-perfect equilibrium strategy, p := c


n1
1
.
want p < 1, equivalent


n1
c 1
<1
(35)


1 n1
1
<
(36)
c
(37)
know c n,



n1
1 n1
1
1
1
e .
c
n

(38)

therefore set e < , access probability p < 1.
Lemma 17. given , exists 0 < < 1 c,
E(Xt+1 |Xt = c) (1 ) c

Proof. prove lemma two cases: p <
1 andwhen
p = 1.
First, let us prove case p < 1, p = c 1 n1 . Therefore, q(n, c) =


1 n1 n . shown n,


q(n, c) = 1


n log .

n1

let p = 1. Lemma 16 must c > n.



n1
c
1 n1
1
q(n, c) := 1
1
,
n
c
n
q(n, c) increasing c.


1

1
n

n1

e .

(39)

(40)

(41)

fixed , , constants, set
:= min( e , log ).

(42)

above, proves lemma.
Theorem 18. expected time agents converge resource allocation
resources claimed O(log C).
352

fiSymmetric Subgame-Perfect Equilibria Resource Allocation

Proof. shown express expected convergence time expected
hitting time certain Markov chain.
Lemma 17 saw exists c,
E(Xt+1 |Xt = c) (1 ) c.
combine result Theorem 14 show expected hitting
time state C state 0


1
1
0
kN < dlog 1 Ce +
log C = O(log C),
(43)
1


constant.

4.3.2 Market Convention
market convention, unfortunately difficult express expected number
convergence steps closed-form expression. However, use linear programming
calculate expected number convergence steps given parameters N , C, K,
.
Markov chain market convention K signals C resources looks
follows: state time Vt {0, 1, . . . , C}K , Vtk denotes many resources
claimed signal k. initial state V0 V0k = C
k {1, . . . , K}. N C K,Pthe final state Vtk = 0 k. N < C K,
final states k{1,...,K} Vtk = C K N .
transition probabilities two states Vi Vj , Vi 6= Vj , following:
Suppose k : Vjk < Vik l 6= k : Vjl 6= Vil . Let us denote c := Vik , i.e. number
unclaimed resources state Vi signal k, n := N (C Vik ) number agents
claimed resource signal k state Vi .
Pr(Vt+1

n
1 X n
= Vj |Vt = Vi ) :=
p (1 pk )nm (m, c, Vik Vjk )
K
k

(44)

m=0

Otherwise Vj 6= Vi , Pr(Vt+1 = Vj |Vt = Vi ) := 0.
Figure 8 shows expected number rounds converge varying discount factor
. Generally, would expect access probability increase increasing , since
profit winning resource increases. increase convergence
time. However, experiments influence convergence time negligible,
although observe slight increase increases. Figure 9 shows convergence
varying collision cost . close 0, convergence time remains stable. However,
high cost , convergence time increases linearly . case, high cost
collision drives resource access probability low, agents try avoid collisions
costs.
Figure 10 shows expected convergence increase number resources C
number agents N proportionally. increase convergence time still sub-linear
increase C.
353

fiCigler & Faltings

7.8

Convergence steps

7.78
7.76
7.74
7.72
7.7
7.68
7.66
0

0.2

0.4

0.6

0.8

1



Figure 8: Market convention: Expected number convergence steps given N = 6, C = 3,
K = 2, = 1.0 varying .

50
45

Convergence steps

40
35
30
25
20
15
10
5 4
10

2

10

0

10


2

10

4

10

Figure 9: Market convention: Expected number convergence steps given N = 6, C = 3,
K = 2, = 0.9 varying .

354

fiSymmetric Subgame-Perfect Equilibria Resource Allocation

13
12

Convergence steps

11
10
9
8
7
6
5
4
1

1.5

2

2.5

3
C

3.5

4

4.5

5

Figure 10: Market convention: Expected number convergence steps given K = 2, = 0.9,
= 1.0 varying number resources C agents N = 2 C.

C&F11
Bourgeois
Egalitarian2
Market

ex-post fair
(X)1

X
X

efficient
X

X
?

equilibrium

X
X
X

Table 1: Properties conventions
4.4 Convention Properties
compare properties following conventions: C&F11, channel allocation
algorithm presented previous work (Cigler & Faltings, 2011); bourgeois egalitarian
conventions, presented Bhaskar (2000); market convention, presented above.
compare conventions according following properties:
Ex-post fairness expected payoff agents even asynchrony?
Efficiency convention maximize social welfare among possible conventions?
Equilibrium convention equilibrium implementation?
Table 1 summarizes properties conventions. C&F11 convention
approximately ex-post fair. fairness improving number coordination signals
increases, agents might worse payoff others. hand,
efficient, least discounting ( = 1). However, equilibrium
1. Fair asymptotically, N .
2. 2-agents, 1-resource games.

355

fiCigler & Faltings

repeated game. bourgeois convention neither fair efficient, fact
expected payoff agents 0 (for small number resources). equilibrium
implementation though, since agents indifferent winner loser.
egalitarian convention fair, efficient equilibrium implementation. However,
defined games 2 agents 1 resource. Finally, market convention fair
also equilibrium implementation. clearly efficient bourgeois
convention. Nevertheless, finding efficient convention remains open problem.

5. Folk Theorems Symmetric Equilibria
previous sections, analyzed special kind symmetric equilibria
resource allocation game. agents first followed Markovian implementation,
soon play pure-strategy NE, adopted convention. infinitely repeated
game discounting, set Nash equilibria characterized using so-called folk
theorem. name indicates known used well
first published, follow version described Fudenberg Maskin (1986).
Informally, folk theorem states infinitely repeated game, every feasible
individually rational payoff vector stage game, exists Nash equilibrium
repeated game average payoffs per round correspond stage game
payoff vector.
payoff vector individually rational Pareto-dominates minimax payoff
stage game. player i, minimax payoff
vi := min max ui (i , ).




(45)

simplify notation, Fudenberg Maskin (1986) normalize payoffs
) = (0, 0, . . . , 0). Let
minimax payoffs, (v1 , v2 , . . . , vN
U := {(v1 , . . . , vN )|(a1 , . . . , ) . . . s.t. u(a1 , . . . , ) = (v1 , . . . , vN )},
V := convex hull U,
V := {(v1 , . . . , vN ) V |vi > 0 i}.
set V set feasible payoffs stage games (that is, payoffs
achieved playing mixed correlated strategy). set V subset feasible
payoffs also individually rational.
Theorem 19. (Fudenberg & Maskin, 1986) (v1 , . . . , vN ) V , discount
factor close enough 1, exists Nash equilibrium infinitely repeated game
discounting where, i, average payoff player vi .
idea proof follows: agents cycle prescribed sequence
game outcomes achieve desired payoffs. one player deviates, others
punish playing minimax strategy forever after.
focus far finding symmetric equilibrium strategies. folk theorem doesnt say anything whether equilibrium strategy symmetric, even
payoff vector symmetric. Nevertheless, define another class symmetric
356

fiSymmetric Subgame-Perfect Equilibria Resource Allocation

strategies infinitely repeated game, one based conventions
implementations. strategies following form: players follow symmetric
(mixed) strategy stage game. one player deviates strategy, players
punish following minimax strategy. resource allocation game, minimax payoff (0, 0, . . . , 0) achieved mixed strategy Nash equilibrium.
Folk theorem, strategy sustained Nash equilibrium repeated
game (though necessarily subgame-perfect equilibrium).
symmetric strategy stage resource allocation game vector access probabilities q = (q1 , q2 , . . . , qC ) qc probability agent access resource c.
interested finding access probability vector q achieves highest expected
payoff.
given access probability vector q, expected payoff agent receives
follows:
C
X



E(q) :=
qj (1 qj )N 1 1 1 (1 qj )N 1 ||
(46)
j=1

Theorem 20. resource allocation game N = 2 agents C = 1 resource,
resource access probability maximizes expected payoff stage game
q =

1
1

.
2 1 + ||

(47)

Proof. calculate derivative expected payoff function Equation 46 N = 2
C = 1:
E(q)
= 1 2q (1 + ||)
q
Setting first derivative equal 0, get
q =

1
1

.
2 1 + ||

Since second derivative
2 E(q)
= 1 || < 0,
2q
probability q local maximum expected payoff function E(q).
Corollary 2. resource allocation game N = 2 agents C = 1 resource,
highest expected payoff symmetric strategy stage game
E =

1
1

.
4 1 + ||

(48)

Corollary 3. resource allocation game N = 2 agents C = 1 resource,
price anonymity strategy accesses optimal access probability q
4 (1 + ||).
357

fiCigler & Faltings

2

10

Folk theorem
Market convention

R 1
10

0

10

0

1

2

3

4

5



Figure 11: Price anonymity symmetric strategy following folk theorem,
compared price anonymity market convention N = 3, C = 1
varying cost collision .

general case resource allocation game N agents C resources,

46 (given constraint
PC find probability vector maximizes Equation
2
j=1 qj 1) using method Lagrangian multipliers .
P
2. goal maximize E(q1 , q2 , . . . , qC ) q0 + C
i=1 qi = 1 qi 0, q0
probability agent yields. Lagrangian function
(q0 , q1 , . . . , qC , ) := E(q1 , q2 , . . . , qC ) +

q0 +

C
X

!
qi 1 .

i=1

first partial derivatives

:=
q0

E
:=
+
qi
qi

(49)
(50)

= (1 ||) (1 qi )N 1 qi (1 + ||) (N 1) (1 qi )N 2 || + 1 C

:= q0 +


C
X

1.

(51)
(52)

i=1

necessary condition solution maximum
partial derivatives Lagrangian
P
function 0. Therefore, := 0 q0 := 1 C
i=1 qi . qi , 1 C find solution

= 0 using numerical root-finding algorithm. point partial derivatives
qi
zero, compare E(q) (finite) number extreme points.

358

fiSymmetric Subgame-Perfect Equilibria Resource Allocation

Figure 11 compares price anonymity folk-theorem-based symmetric strategy
price anonymity market convention, N = 3 agents C = 1 resource.
Since price anonymity folk theorem strategy doesnt depend discount
factor (it needs high enough strategy equilibrium), show
graph varying collision cost . price anonymity folk-theorem strategy
order magnitude higher price anonymity market convention.

6. Conclusions
paper, considered symmetric protocols rationally coordinate asymmetric,
efficient allocation infinitely repeated resource allocation game discounting N agents
C resources. assumed agents identical, resources
homogeneous. based work idea Bhaskar (2000): let agents choose
actions randomly, adopt certain convention. generalize work
Bhaskar arbitrary resource allocation problem N agents C resources.
show convention, exists symmetric subgame-perfect equilibrium
implements it. presented two conventions repeated resource allocation
game: bourgeois market convention. defined price anonymity ratio
expected social payoff best asymmetric strategy profile expected
social payoff given symmetric Nash equilibrium. showed price
anonymity bourgeois convention infinite (at least small number resources),
price anonymity market convention finite relatively small.
market convention reduces demand imposing price successful access,
time increasing supply agents condition strategy
global coordination signal k {1, . . . , K}. way, conflict agents
reduced. also showed analytically agents adopt bourgeois convention,
converge perfect resource allocation polynomial time.
market convention, calculating equilibrium access probabilities difficult.
need use numerical algorithm, whose complexity exponential number
coordination signals K. However, market mechanism already makes sure agent
wants access resource one coordination signal. Therefore, showed
cooperative solution agents access resources constant probability
-equilibrium, given discount factor high enough.
future work, would like investigate whether exist efficient conventions market convention (i.e. conventions smaller price anonymity).
general, finding optimal convention NP-hard problem (Balan, Richards, & Luke,
2011), restricted set infinitely repeated resource allocation games, might
able find optimal convention, similar Thue-Morse sequence (Richman, 2001)
used Kuzmics et al. (2010) Nash demand game.

Acknowledgements
particularly thankful David Parkes giving first author unique opportunity spend weeks lab Harvard. Davids openness unparalleled
knowledge really helped originate work. would also like thank Kate
359

fiCigler & Faltings

Larson reading draft paper helping make theoretical analysis much
readable.

References
Aumann, R. (1974). Subjectivity correlation randomized strategies. Journal
Mathematical Economics, 1 (1), 6796.
Balan, G., Richards, D., & Luke, S. (2011). Long-term fairness bounded worst-case
losses. Autonomous Agents Multi-Agent Systems, 22 (1), 4363.
Bhaskar, V. (2000). Egalitarianism efficiency repeated symmetric games. Games
Economic Behavior, 32 (2), 247262.
Bonnet, F., & Raynal, M. (2011). price anonymity: Optimal consensus despite
asynchrony, crash, anonymity. ACM Trans. Auton. Adapt. Syst., 6 (4), 23:1
23:28.
Chothia, T., & Chatzikokolakis, K. (2005). survey anonymous peer-to-peer filesharing. Embedded Ubiquitous ComputingEUC 2005 Workshops, pp. 744755.
Springer.
Cigler, L., & Faltings, B. (2011). Reaching correlated equilibria multi-agent learning. 10th International Conference Autonomous Agents Multiagent
Systems-Volume 2, pp. 509516. International Foundation Autonomous Agents
Multiagent Systems.
Durresi, A., Paruchuri, V., Durresi, M., & Barolli, L. (2005). hierarchical anonymous
communication protocol sensor networks. Embedded Ubiquitous Computing
EUC 2005, pp. 11231132. Springer.
Fudenberg, D., & Maskin, E. (1986). folk theorem repeated games discounting
incomplete information. Econometrica, 54 (3), 533554.
Jensen, J. L. (1906). Sur les fonctions convexes et les inegalites entre les valeurs moyennes.
Acta Mathematica, 30 (1), 175193.
Koutsoupias, E., & Papadimitriou, C. (1999). Worst-case equilibria. Proceedings
16th annual conference Theoretical aspects computer science, STACS99, pp.
404413, Berlin, Heidelberg. Springer-Verlag.
Kuzmics, C., Palfrey, T., & Rogers, B. (2010). Symmetric players repeated games: Theory
evidence..
Leyton-Brown, K., & Shoham, Y. (2008). Essentials Game Theory: Concise, Multidisciplinary Introduction. Morgan & Claypool, San Rafael, CA.
Monderer, D., & Shapley, L. S. (1996). Potential games. Games economic behavior,
14 (1), 124143.
Norris, J. R. (1998). Markov Chains (Cambridge Series Statistical Probabilistic
Mathematics). Cambridge University Press.
360

fiSymmetric Subgame-Perfect Equilibria Resource Allocation

Raab, M., & Steger, A. (1998). Balls Bins Simple Tight Analysis, Vol. 1518
Lecture Notes Computer Science, chap. 13, pp. 159170. Springer Berlin Heidelberg,
Berlin, Heidelberg.
Rego, V. (1992). Naive asymptotics hitting time bounds markov chains. Acta Informatica, 29 (6), 579594.
Richman, R. M. (2001). Recursive binary sequences differences. Complex Systems, 13 (4),
381392.
Rosenthal, R. W. (1973). class games possessing pure-strategy nash equilibria. International Journal Game Theory, 2 (1), 6567.
Shneidman, J., Ng, C., Parkes, D. C., Auyoung, A., Snoeren, A. C., Vahdat, A., & Chun, B.
(2005). markets could (but dont currently) solve resource allocation problems
systems. USENIX 05: Proceedings 10th USENIX Workshop Hot
Topics Operating Systems, p. 7.
Taussky, O. (1949). recurring theorem determinants. American Mathematical
Monthly, 56 (10), 672676.
Wang, L., Wu, K., Hamdi, M., & Ni, L. M. (2011). Attachment learning multi-channel
allocation distributed OFDMA networks. Parallel Distributed Systems, International Conference on, 0, 520527.

361

fiJournal Artificial Intelligence Research 49 (2014) 207240

Submitted 08/13; published 02/14

Selfishness Level Strategic Games
Krzysztof R. Apt
Guido Schafer

k.r.apt@cwi.nl
g.schaefer@cwi.nl

Centre Mathematics Computer Science (CWI)
Networks Optimization Group
Science Park 123
1098 XG Amsterdam
Netherlands

Abstract
introduce new measure discrepancy strategic games social
welfare Nash equilibrium social optimum, call selfishness level.
smallest fraction social welfare needs offered player
achieve social optimum realized pure Nash equilibrium. selfishness level
unrelated price stability price anarchy invariant positive
linear transformations payoff functions. Also, naturally applies solution
concepts forms games.
study selfishness level several well-known strategic games. allows us
quantify implicit tension within game players individual interests
impact decisions society whole. analyses reveal selfishness
level often provides deeper understanding characteristics underlying game
influence players willingness cooperate.
particular, selfishness level finite ordinal potential games finite,
weakly acyclic games infinite. derive explicit bounds selfishness level
fair cost sharing games linear congestion games, depend specific parameters
underlying game independent number players. Further, show
selfishness level n-players Prisoners Dilemma c/(b(n1)c), b
c benefit cost cooperation, respectively, n-players public goods
game (1 nc )/(c 1), c public good multiplier, Travelers
Dilemma game 12 (b 1), b bonus. Finally, selfishness level Cournot
competition (an example infinite ordinal potential game), Tragedy Commons,
Bertrand competition infinite.

intelligent way selfish
work welfare others
Dalai-Lama1

1. Introduction
discrepancy strategic games social welfare Nash equilibrium
social optimum long recognized economists. One flagship examples
Cournot competition, strategic game involving firms simultaneously choose
1. (Bowles, 2004, p. 109).
c
2014
AI Access Foundation. rights reserved.

fiApt & Schafer

production levels homogeneous product. payoff functions game describe
firms profit presence production costs, assumption price
product depends negatively total output. well-known (see, e.g., Jehle &
Reny, 2011, pp. 174175) price social optimum strictly higher
Nash equilibrium, shows competition producers product
drives price down.
computer science discrepancy led introduction notions
price anarchy (Koutsoupias & Papadimitriou, 2009) price stability (Schulz
& Moses, 2003; Anshelevich, Dasgupta, Kleinberg, Tardos, Wexler, & Roughgarden, 2008)
measure ratio social welfare worst and, respectively, best Nash
equilibrium social optimum. originated huge research effort aiming determining ratios specific strategic games possess (pure) Nash equilibria.
two notions descriptive sense assess existing situation.
Said differently, notions quantify discrepancy social welfare Nash
equilibrium social optimum given initial payoff functions. contrast, propose
notion normative sense explains change payoff functions
resolve discrepancy. Intuitively, asking question much social
welfare needs added players payoff functions individual preferences
bring optimal outcome society. abstract level, approach
propose related one proposed Axelrod (1984, p. 134), chapter
Promote Cooperation, cite: excellent way promote cooperation
society teach people care welfare others.
approach draws concept altruistic games (see, e.g., Ledyard, 1995,
recently Marco & Morgan, 2007). games players payoff modified
adding positive fraction social welfare considered joint strategy
original payoff. selfishness level game defined infimum
0 modification yields social optimum realized pure Nash
equilibrium. underlying property monotonic sense 0
social optimum pure Nash equilibrium, also case every .
Intuitively, selfishness level game viewed measure players
willingness cooperate. low selfishness level indicates players open
align interests sense small share social welfare sufficient
motivate choose social optimum. contrast, high selfishness level suggests
players reluctant cooperate large share social welfare needed
stimulate cooperation among them. infinite selfishness level means cooperation
cannot achieved means.
Notions like price stability price anarchy developed measure
quality equilibria. contrast, notion selfishness level regarded
measure willingness cooperate. general, notions incomparable (as
also argue formally) provide different insights underlying game.
main motivation analyzing selfishness level strategic games gain
deeper understanding characteristics influence players willingness cooperate. turns out, several games studied paper selfishness level provides
insights. illustrate point, briefly elaborate findings public
goods game fair cost sharing game.
208

fiSelfishness Level Strategic Games

public goods game n players want contribute public good.
Every player chooses amount si [0, b] contributes. central authority collects
individual contributions, multiplies sum c > 1 (for simplicity assume
n c) distributes resulting
amount evenly among players. payoff
c P
player thus pi (s) := b si + n j sj . (unique) Nash equilibrium, every player
attempts free ride contributing 0 public good (which dominant strategy),
social optimum every player contributes full amount b. show,
selfishness level game (1 nc )/(c 1). bound suggests temptation
free ride (i) increases number players grows (ii) decreases parameter
c increases. phenomena observed experimental economists, (see, e.g.,
discussion Ledyard, 1995, Section III.C.2). comparison, price stability (which
coincides price anarchy) game c.
fair cost sharing game every player chooses facility set facilities Si E
available (for simplicity discuss case players choose single
facility). cost ce every used facility e E shared evenly among players using
it. prove, selfishness level game max{0, 12 cmax /cmin 1},
cmax cmin refer largest smallest cost facility, respectively. analysis
therefore reveals threshold phenomenon also makes sense intuitively: order
motivate cooperation among players crucial convince players access
facility cost cmin adhere social optimum. cmax 2cmin easy
social optimum player either shares cost facility e ce cmin
least one player uses facility cost cmin exclusively himself. Thus,
self-interest player cooperate choose social optimum case.
cmax > 2cmin players reluctant cooperate fraction social welfare
needs offered incite cooperation grows proportionally cmax /cmin .
Anshelevich et al. (2008) showed price stability price anarchy
game Hn n, respectively, n denotes number players.2
measures depend number players. contrast, notion reveals dependency
discrepancy costs facilities.
large body literature experimental economics indicates players tendency cooperate social dilemmas like Prisoners dilemma, Travelers dilemma
public goods game, even though behavior ruled standard game-theoretic
analysis. Several studies suggest willingness cooperate depends certain parameters underlying game (like group-size, magnitude payoffs, etc.); see, e.g., Isaac
Walker (1988), Cooper, DeJong, Forsythe, Ross (1996), Goeree Holt (2001),
Becker, Carter, Naeve (2005), Dreber, Rand, Fudenberg, Nowak (2008).
example, Dreber et al. observe Prisoners dilemma willingness cooperate
increases ratio cost benefit cooperation. therefore study selfishness level parameterized versions games. findings show selfishness
level also exhibits dependency certain parameters game.
paper, define selfishness level taking pure Nash equilibrium
solution concept. line price anarchy price stability
defined originally (Koutsoupias & Papadimitriou, 2009; Schulz & Moses, 2003; Anshelevich
2. Hn denotes nth Harmonic number.

209

fiApt & Schafer

et al., 2008). However, definition applies equally well solution concepts
forms games. discuss matters final section.
1.1 Contributions
main contributions presented paper follows:
1. introduce (in Section 2) notion selfishness level game, derive basic
properties elaborate connections efficiency measures models
altruism.
particular, show selfishness level game unrelated price
stability price anarchy. Moreover, selfishness level invariant positive linear transformations payoff functions. also show
model equivalent models altruism studied before.
consequence, bounds selfishness level directly transfer alternative
models.
2. derive (in Section 3) characterization result allows us determine
selfishness level strategic game.
characterization shows selfishness level determined maximum
appeal factor unilateral profitable deviations specific social optima,
call stable. result, focus deviations stable social optima
only. Intuitively, appeal factor single player deviation refers ratio
gain payoff resulting loss social welfare.
3. use (in Section 4) characterization result analyze selfishness level
several classical strategic games.
games study fundamental often used illustrate consequences
selfish behavior effects competition. summary results given
Table 1. particular, derive explicit bounds selfishness level fair cost
sharing games congestion games linear delay functions. obtained bounds
depend specific parameters underlying game, find informative.
also show bounds tight certain instances.
4. also show (in Section 5) selfishness level notion naturally extends
solution concepts types games, instance mixed Nash equilibria
extensive games.

1.2 Related Work
articles algorithmic game theory literature study influence
altruism strategic games (Caragiannis, Kaklamanis, Kanellopoulos, Kyropoulou, &
Papaioannou, 2010; Chen, de Keijzer, Kempe, & Schafer, 2011; Chen & Kempe, 2008;
Elias, Martignon, Avrachenkov, & Neglia, 2010; Hoefer & Skopalik, 2009). works,
altruistic player behavior modeled altering players perceived payoff order
account also welfare others. models differ way combine players
210

fiSelfishness Level Strategic Games

Game

Selfishness level

Ordinal potential games
Weakly acyclic games
Fair cost sharing games (singleton)

finite

1}
max{0, 12 ccmax
min

Fair cost sharing games (integer costs)
Linear congestion games (singleton)
Linear congestion games (integer coefficients)
Prisoners Dilemma n players
Public goods game
Travelers dilemma
Cournout competition
Tragedy commons
Bertrand competition

max{0, 12 Lcmax 1}
max min
max{0, 12 (1
12 }
max )amin

max{0, 21 (Lmax min 1)}

c

b(n1)c
c
1 n
max{0, c1 }
1

2 (b 1)





Table 1: Selfishness level games studied paper.
see Section 4 definitions respective parameters games.

individual payoff payoffs players. studies descriptive
sense aim understanding impact altruistic behavior specific strategic
games.
Closest work articles Elias et al. (2010) Chen et al. (2011).
Elias et al. study inefficiency equilibria network design games (which constitute
special case cost sharing games considered here) altruistic (or, call
it, socially-aware) players. here, define players cost function
individual cost plus times social cost. derive lower upper bounds
price anarchy price stability, respectively, modified game. particular,
show price stability (Hn + )/(1 + ), n number
players.
Chen et al. (2011) introduce framework study robust price anarchy,
refers worst-case inefficiency solution concepts coarse correlated
equilibria (see Roughgarden, 2009) altruistic extensions strategic games.
model, player perceived cost convex combination (1 ) times individual cost
plus times social cost, [0, 1] altruism level player i. players
uniform altruism level = , model relates one consider
setting = /(1 ) (see Section 2.3 details). Although main focus
paper, authors also provide upper bounds 2/(1 + ) (1 )Hn +
price stability linear congestion games fair cost sharing games, respectively.
Note three cases mentioned price stability approaches 1
goes . seems suggest selfishness level games . However,
case analyses reveal.
211

fiApt & Schafer

Two models altruism proposed literature. Chen Kempe (2008)
define perceived cost player (1 ) times individual cost plus /n times
social cost, [0, 1]. Caragiannis et al. (2010) define perceived cost player
(1 ) times individual cost plus times sum costs players (i.e.,
excluding player i), [0, 1]. Also two models shown equivalent
model using simple transformations (see Section 2.3 details).
Subsequently, mention related approaches normative. Conceptually,
selfishness level notion related Stackelberg threshold introduced Sharma
Williamson (2009) (see also Kaporis & Spirakis, 2009). authors consider network
routing games fraction [0, 1] flow first routed centrally
remaining flow routed selfishly. Stackelberg threshold refers smallest
value needed improve upon social cost Nash equilibrium flow.
related paper, Hoefer Skopalik (2009) study minimum number, termed
optimal stability threshold, (pure) altruists needed congestion game induce
Nash equilibrium social optimum. show number computed
polynomial time singleton congestion games.
network congestion games, researchers studied effect imposing tolls edges
network order reduce inefficiency Nash equilibria (see, e.g., Beckmann,
McGuire, & Winsten, 1956). high-level perspective, approaches also
regarded normative.
Recently, Capraro (2013) proposed new normative approach measure incentive
cooperation symmetric games tension selfish altruistic
behavior. solution concept pure Nash equilibrium transformed game
strategies certain mixed strategic original game. strategies depend
incentive risk deviating cooperation original game. Strikingly,
Capraros conclusions influence parameters Prisoners Dilemma,
Travelers Dilemma public goods game consistent ours.
several papers propose notions allowing assess stability
Nash equilibria. mention below. Christodoulou, Koutsoupias, Spirakis
(2011) study inefficiency approximate Nash equilibria congestion games.
(1+)-approximate Nash equilibrium cost player (1+) times cost
experiences every unilateral deviation. authors derive (almost) tight bounds
price stability price anarchy linear (non-atomic atomic)

congestion
games function . particular, obtain bound min{1, (1 + 3)/( + 3)}
price stability atomic linear congestion games. context, alternative
notion assess stability Nash equilibria comes ones mind consider
smallest 0 social optimum realized (1 + )-Nash equilibrium. Note
bound implies 1 linear congestion games.
comment idea detail Section 5.2.
Anshelevich, Das, Naamad (2009) consider problem incentivizing players
participate socially desirable matchings adding switching costs player deviations.
model, additional cost player incurs changing strategy accounts
fraction individual cost. Adopting viewpoint, authors study
inefficiency (1 + )-approximate stable matchings. derive bounds price
stability price anarchy (1 + )-approximate stable matchings function
212

fiSelfishness Level Strategic Games

0. Related work article Biro, Manlove, Mittal (2010) study
problem computing optimal matching minimum number blocking pairs.
Furthermore, Balcan, Blum, Mansour (2009) study impact advertising strategies players order induce select efficient equilibria. precisely,
model authority first proposes strategy player accepted
player probability . accepting player adheres proposed strategy
remaining players play best response (assuming strategies accepting
players fixed). final step players follow best response dynamics Nash
equilibrium reached. authors analyze inefficiency resulting equilibria
fair cost sharing games, machine scheduling games party affiliation games. particular, fair cost sharing games show expected cost resulting equilibrium
factor O(log n/) away social optimum.

2. Selfishness Level
section, formally introduce notion selfishness level, establish properties relate notions altruism.
2.1 Definition
strategic game (in short, game) G = (N, {Si }iN , {pi }iN ) given set N =
{1, . . . , n} n > 1 players, non-empty set strategies Si every player N ,
payoff function pi every player N pi : S1 Sn R. players choose
strategies simultaneously every player N aims choosing strategy si Si
maximize individual payoff pi (s), = (s1 , . . . , sn ).
call S1 Sn joint strategy denote ith element si . denote
(s1 , . . . , si1 , si+1 , . . . , sn ) si similarly Si . Further, write (si , si )
(s1 , . . . , si1 , si , si+1 , . . . , sn ), assume si Si . Sometimes, focusing
player write (si , si ) instead s.
joint strategy Nash equilibrium {1, . . . , n} si Si ,
pi (si , si ) pi (si , si ). Further, given joint strategy call sum SW (s) :=
P
n
i=1 pi (s) social welfare s. social welfare maximal call
social optimum.
shall also consider cost variant games use cost functions,
written ci , instead payoff functions pi . setup objective player
minimize costs, joint strategy Nash equilibrium {1, . . . , n}
si Si , ci (si , si ) ci (si , si ). Further,
instead social welfare one considers
P
social cost s, defined SC(s) := ni=1 ci (s).
Given strategic game G := (N, {Si }iN , {pi }iN ) 0 define game
G() := (N, {Si }iN , {ri }iN ) putting ri (s) := pi (s) + SW (s). > 0
payoff player G() game depends social welfare players. G()
altruistic version game G.
Suppose 0 pure Nash equilibrium G() social optimum
G(). say G -selfish. define selfishness level G
inf{ R+ | G -selfish}.
213

(1)

fiApt & Schafer

adopt convention infimum empty set . Further, stipulate
selfishness level G denoted + iff selfishness level G R+
G -selfish (equivalently, infimum belong set). show
(Theorem 2) pathological infinite games exist selfishness level
kind; none studied games type.
give remarks proceed.
1. definitions refer strategic games player maximizes
payoff function pi social welfare joint strategy given SW (s).
definitions obviously apply case use cost functions social cost.
2. definitions altruistic version game conceivable and, depending
underlying application, might seem natural one use here.
However, show Section 2.3 definition equivalent several
models altruism proposed literature.
3. selfishness level refers smallest Nash equilibrium G()
also social optimum. Alternatively, one might interested smallest
every Nash equilibrium G() corresponds social optimum. However,
explained Section 5.2, alternative notion always meaningful.
4. definition extends obvious way solution concepts (e.g., mixed
correlated equilibria) forms games (e.g., subgame perfect equilibria
extensive games). briefly comment extensions Section 5.
Note social welfare joint strategy G() equals (1 + n)SW (s),
social optima G G() coincide. Hence replace definition -selfish
game reference social optimum G() one social optimum G.
shall proofs below.
Intuitively, low selfishness level means share social welfare needed
induce players choose social optimum small. share viewed
incentive needed realize social optimum. Let us illustrate definition various
simple examples.
Example 1. Prisoners Dilemma
C


C
1, 1
2, 1


1, 2
0, 0

C


C
3, 3
3, 0


0, 3
0, 0

Consider Prisoners Dilemma game G (on left) resulting game G()
= 1 (on right). latter game social optimum, (C, C), also Nash
equilibrium. One easily check < 1, (C, C) also social optimum G()
Nash equilibrium. selfishness level game 1.
Example 2. Battle Sexes
F
B

F
2, 1
0, 0
214

B
0, 0
1, 2

fiSelfishness Level Strategic Games

Nash equilibrium also social optimum, selfishness level game
0.
Example 3. Matching Pennies

H


H
1, 1
1, 1


1, 1
1, 1

Since social welfare joint strategy 0, game G() identical
original game Nash equilibrium exists. selfishness level
game . generally, selfishness level constant sum game 0 Nash
equilibrium otherwise .
Example 4. Game bad Nash equilibrium
following game results equipping player Matching Pennies game
third strategy E (for edge):
H
1, 1
1, 1
1, 1

H

E


1, 1
1, 1
1, 1

E
1, 1
1, 1
1, 1

unique Nash equilibrium (E, E). easy check selfishness level
game . (This also immediate consequence Theorem 4 (iii) below.)
Example 5. Game Nash equilibrium
Consider game G left resulting game G() = 1 right.

C


C
2, 2
3, 0


2, 0
1, 1

C


C
6, 6
6, 3


4, 2
3, 3

game G Nash equilibrium, game G(1) social optimum,
(C, C), also Nash equilibrium. Prisoners Dilemma game one easily check
< 1, (C, C) also social optimum G() Nash equilibrium.
selfishness level game G 1.
2.2 Properties
Recall that, given finite game G Nash equilibrium, price stability
ratio SW (s)/SW (s ) social optimum Nash equilibrium
highest social welfare G. price anarchy defined ratio SW (s)/SW (s )
social optimum Nash equilibrium lowest social welfare
G.
price stability G 1 iff selfishness level 0. However, general
relation two notions. following observation also shows
selfishness level finite game arbitrary real number.
215

fiApt & Schafer

Theorem 1. every finite > 0 > 1 finite game whose selfishness level
whose price stability .
Proof. Consider following generalized form, denote P D(, ), Pris
oners Dilemma game G x = +1
:
C


C
1, 1
x + 1, 0


0, x + 1
1 1
,

game game G() 0, (C, C) unique social optimum.
compute selfishness level need consider game G() stipulate (C, C)
Nash equilibrium. leads inequality 1 + 2 ( + 1)(x + 1),
x
, i.e., . selfishness level G . Moreover, price
follows 1x
stability , since (D, D) Nash equilibrium.
notion selfishness level invariant simple payoff transformations.
direct consequence following observation, given game G value
denote G + (respectively, aG) game obtained G adding payoff
function value (respectively, multiplying payoff function a).
Proposition 1. Consider game G 0.
(i) every a, G -selfish iff G + -selfish.
(ii) every > 0, G -selfish iff aG -selfish.
Proof. (i) suffices note r[a]i (s) = ri (s) + + a, ri r[a]i payoff
functions player games G() (G + a)(). every joint strategy
Nash equilibrium G() iff Nash equilibrium (G + a)(),
social optimum G() iff social optimum (G + a)().

(ii) suffices note every > 0, r[a]i (s) = ari (s), time r[a]i
payoff function player game (aG)(), argue above.
Proposition 1 implies selfishness level invariant game transformations form t(G) := aG + b, > 0. contrast notions price
anarchy price stability invariant game transformations
form t(G) := aG, > 0.
Note selfishness level invariant multiplication payoff functions value 0. Indeed, = 0 game aG selfishness level 0.
< 0 take game G Example 4 whose selfishness level . game aG
joint strategy (E, E) Nash equilibrium social optimum, selfishness
level aG 0.
proposition also allows us frame notion selfishness level
following way. Suppose original n-player game G given game designer
fixed budget SW (s) joint strategy selfishness level G < .
game designer distribute budget SW (s) joint strategy
216

fiSelfishness Level Strategic Games

among players resulting game Nash equilibrium coincides
social optimum? scaling G() factor := 1/(1 + n) ensure
joint strategy social welfare original game G aG() same. Using
Proposition 1, conclude smallest non-negative real aG()
Nash equilibrium social optimum. game aG() viewed
intended transformation G. is, payoff function pi game G transformed
payoff function
ri (s) :=


1
pi (s) +
SW (s).
1 + n
1 + n

Let us return borderline case selfishness level denoted
following result.

+ .

Theorem 2. every 0 exists game whose selfishness level + .
Proof. first prove result = 0. is, show exists game
-selfish every > 0, 0-selfish. end use games P D(, )
defined proof Theorem 1.
construct strategic game G = (N, {Si }iN , {pi }iN ) two players N = {1, 2}
combining, arbitrary fixed > 1, infinitely many P D(, ) games > 0
follows: > 0 rename strategies P D(, ) game to, respectively,
C() D() denote corresponding payoff functions pi . set strategies
player N Si = {C() | > 0} {D() | > 0} payoff defined

(
pi (si , si ) {si , si } {C(), D()} > 0
pi (si , si ) :=
0
otherwise.
Every social optimum G form (C(), C()), > 0. (Note
exploit > 1 here.) argument given proof Theorem 1, (C(), C())
> 0 Nash equilibrium game G() deviations C()
strategy C() D() 6= yield payoff 0. Thus, G -selfish every > 0.
Finally, observe G 0-selfish every Nash equilibrium G form
(D(), D()), > 0.
deal general case prove two claims independent interest.
Claim 1. every game G 0 game G G () = G.
Proof. define payoff player game G
pi (s) := pi (s)


SW (s),
1 + n

217

fiApt & Schafer

pi payoff game G. Denote SW (s) social welfare joint strategy
game G ri payoff function player game G ().
ri (s) = pi (s) + SW (s)


n

SW (s) + SW (s)
SW (s)
= pi (s)
1 + n
1 + n



n2
= pi (s) +

SW (s)
1 + n 1 + n
= pi (s).

Claim 2. every game G , 0
G( + ) = G()




1 + n



.

Proof. Denote SW (s) social welfare joint strategy game G(), pi , ri

).
r payoff functions player games G, G(), G()( 1+n
ri (s) := pi (s) + SW (s),


SW (s)
1 + n

= pi (s) + SW (s) +
(SW (s) + nSW (s))
1 + n



n
= pi (s) + +
+
SW (s)
1 + n 1 + n
= pi (s) + ( + )SW (s),

ri (s) = ri (s) +

proves claim.
prove general case fix 0 > 0 take game G whose selfishness level
0+ . Claim 1 game G G () = G. G -selfish, since
G 0-selfish.
Further, Claim 2
G ( + ) = G ()
choice game G
proof.




1 + n


1+n -selfish,



=G




1 + n



.

G ( + )-selfish, concludes

218

fiSelfishness Level Strategic Games

2.3 Alternative Definitions
definition selfishness level depends way altruistic versions
original game defined. Three models altruism proposed literature.
before, let G := (N, {Si }iN , {pi }iN ) strategic game. Consider following four
definitions altruistic versions G:
Model (Elias et al., 2010): every 0, G() := (N, {Si }iN , {ri }iN )
ri (s) = pi (s) + SW (s)

N.

(2)

Model B (Chen & Kempe, 2008): every [0, 1], G() := (N, {Si }iN , {ri }iN )


(3)
ri (s) = (1 )pi (s) + SW (s) N.
n
Model C (Chen et al., 2011): every [0, 1], G() := (N, {Si }iN , {ri }iN )
ri (s) = (1 )pi (s) + SW (s) N.

(4)

Model (Caragiannis et al., 2010): every [0, 1], G() := (N, {Si }iN , {ri }iN )

ri (s) = (1 )pi (s) + (SW (s) pi (s)) N.
(5)
selfishness level notion Model extends Models B, C obvious
way: say G -selfish [0, 1] iff pure Nash equilibrium
altruistic version G() also social optimum. selfishness level G respect
Model B defined infimum [0, 1] G -selfish.
respective notions Models C defined analogously.
following theorem shows selfishness level game respect Models
A, B, C relate via simple transformations. (Note Model
transformation applies [0, 12 ].)
Theorem 3. Consider strategic game G := (N, {Si }iN , {pi }iN ) altruistic versions defined according Models A, B, C above.
(i) G -selfish R+ iff G -selfish =

n
1+n

[0, 1].

(ii) G -selfish R+ iff G -selfish =


1+

[0, 1].

(iii) G -selfish R+ iff G -selfish =


1+2

[0, 21 ].

Proof. prove following general claim. Fix x, > 0. every [0, x1 ], define
G() := (N, {Si }iN , {ri }iN )
ri (s) = (1 x)pi (s) +


SW (s).


show G -selfish 0 iff G -selfish =
219

(6)

1+xy

[0, x1 ].

fiApt & Schafer

substituting =
ri (s) =


1+xy

(6), obtain

1

1
pi (s) +
SW (s) =
r (s).
1 + xy
1 + xy
1 + xy

1
> 0 every 0 pure Nash equilibria social
consequence, since 1+xy
1
1
optima, respectively, G() 1+xy
G() coincide. Thus, G -selfish iff 1+xy
G
1
-selfish. Also, follows Proposition 1 1+xy G -selfish iff G -selfish.
Further, note



1
1
1
lim
=
1 lim
= .
1 + xy
1 + xy
x
x

is, selfishness level G respect Model iff selfishness level G
respect G() x1 .
Now, (i) follows x = 1 = n, (ii) follows x = = 1
(iii) follows x = 2 = 1.

3. Characterization Result
characterize games finite selfishness level. end shall need
following notion. call social optimum stable N si Si
following holds:
(si , si ) social optimum, pi (si , si ) pi (si , si ).
words, social optimum stable player better unilaterally deviating
another social optimum.
turn order determine selfishness level game need
consider deviations stable social optima. Consider deviation si player
stable social optimum s. player better deviating si , definition
social welfare decreases, i.e., SW (si , si ) SW (si , si ) > 0. original game
decrease small, gain player large, strategy si attractive
socially acceptable option player i. define player appeal factor strategy si
given social optimum
AFi (si , s) :=

pi (si , si ) pi (si , si )
.
SW (si , si ) SW (si , si )

follows shall characterize selfishness level terms bounds
appeal factors profitable deviations stable social optimum. First, note following
properties social optima.
Lemma 1. Consider strategic game G := (N, {Si }iN , {pi }iN ) 0.
(i) Nash equilibrium G() social optimum G, stable
social optimum G.
220

fiSelfishness Level Strategic Games

(ii) stable social optimum G, Nash equilibrium G() iff
N si Ui (s), AFi (si , s),
Ui (s) := {si Si | pi (si , si ) > pi (si , si )}.

(7)

set Ui (s), > sign replaced , called upper contour set (see,
e.g., Ritzberger, 2002, p. 193). Note stable social optimum, si Ui (s)
implies SW (si , si ) > SW (si , si ).
Proof. (i) Suppose Nash equilibrium G() social optimum G.
Consider joint strategy (si , si ) social optimum. definition Nash
equilibrium
pi (si , si ) + SW (si , si ) pi (si , si ) + SW (si , si ),
pi (si , si ) pi (si , si ), desired.
(ii) Suppose stable social optimum G. Nash equilibrium
G() iff N si Si
pi (si , si ) + SW (si , si ) pi (si , si ) + SW (si , si ).

(8)

pi (si , si ) pi (si , si ), (8) holds 0 since social optimum.
pi (si , si ) > pi (si , si ), then, since stable social optimum G, SW (si , si ) >
SW (si , si ).
(8) holds N si Si iff


pi (si , si ) pi (si , si )
= AFi (si , s)
SW (si , si ) SW (si , si )

holds N si Ui (s).
leads us following result.
Theorem 4. Consider strategic game G := (N, {Si }iN , {pi }iN ).
(i) selfishness level G finite iff stable social optimum exists (s) :=
supiN, si Ui (s) AFi (si , s) finite.
(ii) selfishness level G finite, equals minsSSO (s), SSO
set stable social optima.
(iii) G finite, selfishness level finite iff stable social optimum.
particular, G unique social optimum, selfishness level finite.
(iv) > 0 G -selfish, G -selfish.
Proof. (i) (iv) follow Lemma 1, (ii) (i) Lemma 1, (iii) (i).
Using theorem exhibit class games n players
selfishness level unbounded. fact, following general result holds.
221

fiApt & Schafer

Theorem 5. function f : N R+ exists class games n players,
n > 1, selfishness level game n players equals f (n).
Proof. Assume n > 1 players player two strategies, 1 0. Denote
1 joint strategy strategy equals 1 1i joint strategy
opponents player entry equals 1. payoff player defined
follows:


= 1
0
pi (s) := f (n)
si = 0 j < i, sj = 1

f (n)+1
n1
otherwise.
6= 1, pi (s) = f (n) smallest index player si = 0 otherwise
pi (s) = f (n)+1
n1 . Note SW (1) = 0 SW (s) = 1 6= 1. 1 unique social
optimum.
pi (0, 1i ) pi (1) = f (n) SW (1) SW (0, 1i ) = 1. Theorem 4 (ii)
selfishness level equals f (n).

4. Examples
use characterization result determine compute upper bound
selfishness level selected games. First, exhibit well-known class games
(see Monderer & Shapley, 1996) selfishness level finite.
4.1 Ordinal Potential Games
Given game G := (N, {Si }iN , {pi }iN ), function P : S1 Sn R called
ordinal potential function G N , si Si si , si Si , pi (si , si ) >
pi (si , si ) iff P (si , si ) > P (si , si ). game possesses ordinal potential function
called ordinal potential game.
Theorem 6. Every finite ordinal potential game finite selfishness level.
Proof. social optimum largest potential stable social optimum.
claim follows Theorem 4 (ii).
particular, every finite congestion game (see Rosenthal, 1973) finite selfishness
level. shall derive explicit bounds two special cases games Sections 4.3
4.4.
4.2 Weakly Acyclic Games
Given game G := (N, {Si }iN , {pi }iN ), path S1 Sn sequence (s1 , s2 , . . . )
k1
joint strategies every k > 1 player sk = (si , si
)
k1

si 6= si
(see, e.g., Monderer & Shapley, 1996). path called improvement
path maximal k > 1, pi (sk ) > pi (sk1 ), player deviated
sk1 . game G finite improvement property (FIP ) every improvement
path finite. game G called weakly acyclic every joint strategy exists
finite improvement path starts (see, e.g., Milchtaich, 1996; Young, 1993).
222

fiSelfishness Level Strategic Games

Finite games FIP coincide ordinal potential games. Theorem 6 games finite selfishness level. contrast, selfishness level weakly
acyclic game infinite. Indeed, following game easily seen weakly acyclic:

H

E

H
1, 1
1, 1
0.5, 1


1, 1
1, 1
0.5, 1

E
1, 0.5
1, 0.5
0.5, 0.5

Yet, account Theorem 4 (iii), selfishness level infinite.
4.3 Fair Cost Sharing Games
next subsection consider cost-minimization instead payoff-maximization
games. Recall games player wants P
minimize individual cost function ci social cost defined SC(s) = ci (s).
fair cost sharing game (see, e.g., Anshelevich et al., 2008) players allocate facilities
share cost used facilities fair manner. Formally, fair cost sharing game
given G = (N, E, {Si }iN , {ce }eE ), N = {1, . . . , n} set players, E
set facilities, Si 2E set facility subsets available player i, ce R+
cost facility e E. called singleton cost sharing game every N
every si Si : |si | = 1. joint strategy S1 Sn let xe (s)
number players using facility e E, i.e., xe (s) = |{i N | e si }|. cost facility
e E evenly
P shared among players using it. is, cost player defined
ci (s) = esi ce /xe (s).
first consider singleton cost sharing games. Let cmax = maxeE ce cmin =
mineE ce refer maximum minimum costs facilities, respectively.
Proposition 2. selfishness level singleton cost sharing game
1}. Moreover, bound tight.
max{0, 21 ccmax
min
result contrasted price stability Hn price anarchy
n cost sharing games (Anshelevich et al., 2008). Cost sharing games admit exact
potential function thus Theorem 6 selfishness level finite. However,
tight example given proof Proposition 2 shows, selfishness level
arbitrarily large (as cmax /cmin ) even n = 2 players two facilities.
order prove Proposition 2, first derive expression appeal factor
arbitrary fair cost sharing games, specialize singleton cost sharing games
prove claim.
Let stable social optimum. Note exists Theorem 4 (iii) Theorem 6.
consider cost minimization game appeal factor player defined

ci (si , si ) ci (si , si )
(9)
AFi (si , s) :=
SC(si , si ) SC(si , si )
condition Theorem 4 (i) reads (s) := maxiN, si Ui (s) AFi (si , s), Ui (s) :=
{si Si | ci (si , si ) < ci (si , si )}.
223

fiApt & Schafer

Fix player let = (si , si ) si Ui (s). use xe xe refer
xe (s) xe (s ), respectively. Note



xe + 1 e si \ si ,
xe = xe 1 e si \ si ,


xe
otherwise.



ci (s) ci (si , si ) =

X ce
X
ce

.
xe
xe + 1



esi \si

(10)

esi \si

Further, difficult verify
SC(si , si ) SC(s) =

X

esi \si : xe =0

ce

X

ce .

(11)

1.

(12)

esi \si : xe =1

Thus,
AFi (si , s)

=

P

ce
esi \si : xe 2 xe

P



esi \si : xe =0 ce

P



use prove Proposition 2.

ce
esi \si : xe 1 xe +1

P

esi \si : xe =1 ce

Proof Proposition 2. Let stable social optimum (which exists Theorem 4 (iii)
Theorem 6). Ui (s) = every N selfishness level 0 Theorem 4 (ii).
Otherwise, player N Ui (s) 6= . Recall singleton cost
sharing game, players strategy set consists singleton facility sets. Let si = {e}
si = {e } singleton sets facilities chosen player = (si , si )
si Ui (s). Clearly, e 6= e .
Note SC(si , si ) SC(s) must positive si Ui (s) thus (11) implies
xe = 0. Therefore, (10) reduces ci (s) ci (si , si ) = ce /xe ce . xe = 1
ce > ce si Ui (s). contradiction assumption
SC(si , si ) SC(s) = ce ce > 0. Thus xe 2. Note also implies ce > 2ce
thus cmax > 2cmin .
Using (12), obtain
AFi (si , s)

=

ce
xe

ce

1

1 cmax
1.
2 cmin

claim follows Theorem 4 (ii).
following example shows bound tight. Suppose N = {1, 2}, E =
{e1 , e2 }, S1 = {{e1 }}, S2 = {{e1 }, {e2 }}, ce1 = cmax ce2 = cmin cmax > 2cmin .
joint strategy = ({e1 }, {e1 }) unique social optimum SC(s) = cmax
c2 (s) = cmax /2. Suppose player 2 deviates s2 = {e2 }. SC(s2 , s1 ) = cmax + cmin
c2 (s2 , s1 ) = cmin . Thus AFi (s2 , s) = ( 21 cmax cmin )/cmin = 12 cmax /cmin 1.
224

fiSelfishness Level Strategic Games

following example shows bound similar one above, i.e., bounding
selfishness level terms ratio cmax /cmin , hold arbitrary fair cost
sharing games. particular, shows minimum difference two costs
facilities (here ) must enter bound selfishness level arbitrary fair cost sharing
games.
Example 6. Let N = {1, 2}, E = {e1 , e2 , e3 }, S1 = {{e1 }}, S2 = {{e1 , e3 }, {e2 }}, ce1 =
cmax , ce2 = cmin + > 0 ce3 = cmin . joint strategy = ({e1 }, {e1 , e3 })
unique social optimum SC(s) = cmax + cmin c2 (s) = cmax /2 + cmin . Suppose
player 2 deviates s2 = {e2 }. SC(s2 , s1 ) = cmax + cmin + c2 (s2 , s1 ) = cmin + .
Thus AFi (s2 , s) = ( 12 cmax )/ = 21 cmax / 1, approaches 0.
next derive bound arbitrary fair cost sharing games non-negative integer
costs. Let L maximum number facilities player choose, i.e., L :=
maxiN,si Si |si |.
Proposition 3. selfishness level fair cost sharing game non-negative integer
costs max{0, 21 Lcmax 1}. Moreover, bound tight.
Proof. Let stable social optimum. proof Proposition 2, Ui (s) =
every N selfishness level 0 Theorem 4 (ii). Otherwise, player
N Ui (s) 6= . Let = (si , si ) si Ui (s). Note denominator
appeal factor (12) least 1 stable, si Ui (s) ce N
e E. Thus
P
P
ce
e
es \si : xe 1 xec+1
: x 2
es
\s
x
e

e



P
1
AFi (si , s) = P
esi \si : xe =0 ce
esi \si : xe =1 ce
X
1
ce
1 Lcmax 1.

xe
2

esi \si : xe 2

claim follows Theorem 4 (ii).
following example shows bound tight. Suppose given L
cmax . Let N = {1, . . . , n} E = {e1 , . . . , en } n = L + 1. Define Si = {{ei }}
every N \ {n} Sn = {{e1 , . . . , en1 }, {en }}. Let cei = cmax every N \ {n}
cen = 1. joint strategy = ({e1 }, . . . , {en1 }, {e1 , . . . , en1 }) unique social
optimum SC(s) = (n 1)cmax cn (s) = (n 1)cmax /2. Suppose player n deviates
sn = {en }. SC(sn , sn ) = (n 1)cmax + 1 cn (sn , sn ) = 1. Thus AFi (sn , s) =
1
1
2 (n 1)cmax 1 = 2 Lcmax 1.
Remark 1. bound selfishness level fair cost sharing game non-negative
rational costs ce Q+ every facility e E using Proposition 3 following
scaling argument: Simply scale costs integers, e.g., multiplying
least common multiplier q N denominators. Note scaling change
selfishness level game Proposition 1. However, change maximum
facility cost thus q enters bound. Also note scaling implicitly takes care
effect observed Example 6: Suppose cmax cmin integers = 1/q
q N. costs multiplied q Proposition 3 yields (non-tight)
bound qcmax 1 = cmax / 1 selfishness level, approaches q .
225

fiApt & Schafer

4.4 Linear Congestion Games
congestion game G := (N, E, {Si }iN , {de }eE ) given set players N =
{1, . . . , n}, set facilities E delay function de : N R+ every facility e E,
strategy set Si 2E every player N . joint strategy S1 Sn ,
define xe (s) number players using facility e E, i.e.,Pxe (s) = |{i N | e si }|.
goal player minimize individual cost ci (s) = esi de (xe (s)).
call congestion game symmetric common strategy set 2E
Si = i. singleton every strategy si Si singleton set, i.e.,
every N every si Si , |si | = 1. linear congestion game, delay function
every facility e E form de (x) = ae x + , ae , R+ non-negative
real numbers.
first derive bound selfishness level symmetric singleton linear congestion
games. turns out, bound similar one singleton cost sharing games
extend symmetric singleton linear congestion games. Instead, crucial insight
selfishness level depends discrepancy facilities stable social
optimum. make notion precise.
Let stable social optimum let xe refer xe (s). Define discrepancy
two facilities e e ae + ae > 0
(xe , xe ) =

2ae xe + 2ae xe +

.
ae + ae
ae + ae

(13)

show (xe , xe ) [1, 1]. Define max (s) maximum discrepancy
two facilities e e ae + ae > 0 (xe , xe ) < 1;
formally, let
max (s) = max
{(xe , xe ) | ae + ae > 0 (xe , xe ) < 1}.

e,e E

Let max maximum discrepancy stable social optima, i.e., max = maxsSSO max (s).
Further, let max := maxeE (ae + ) min := mineE (ae + ). Moreover, let amin
minimum non-zero coefficient latency function, i.e., amin = mineE:ae >0 ae .
Proposition 4. selfishness level symmetric singleton linear congestion game



1
1 max min

.
max 0,
2 (1 max )amin 2
Moreover, bound tight.
first prove discrepancy two facilities bounded:
Claim 3. Let social optimum e, e E two facilities ae + ae > 0.
discrepancy e e satisfies (xe , xe ) [1, 1].

Proof. Let = xe + xe total number players facilities e e s. Note
since social optimum strategy sets symmetric, distributed among xe
xe social cost two facilities minimized. Said differently, xe = x
minimizes function
f (x, t) := ae x2 + x + ae (t x)2 + (t x).
226

fiSelfishness Level Strategic Games

hard verify minimum f (x, t) (for fixed t) attained (not
necessarily integral) point
2ae +
.
x0 :=
2(ae + ae )
f (x, t) parabola minimum x0 , integral point xe minimizes
f (x, t) given point obtained rounding x0 nearest integer. Let xe := x0 + 21
point, = (xe , xe ) [1, 1], xe = xe . Note choice
unique, unless x0 half-integral case {1, 1}. Solving equations
yields definition (13).
Proof Proposition 4. Let stable social optimum. Note exists Theorem 4 (iii) Theorem 6. Ui (s) = every N selfishness level 0
Theorem 4 (ii). Otherwise, player N Ui (s) 6= . Let = (si , si )
si Ui (s). use xe xe refer xe (s) xe (s ) every facility e E,
respectively. Note every e E



xe + 1 e si \ si ,
(14)
xe = xe 1 e si \ si ,


xe
otherwise.
Let si = {e} si = {e } sets facilities chosen player , respectively.
Exploiting (14), obtain
ci (si , si ) ci (si , si ) = ae xe + ae (xe + 1) .

(15)

SC(si , si ) SC(si , si ) = ae (2xe + 1) + ae (2xe 1) .

(16)

Moreover,

Note ci (si , si ) ci (si , si ) > 0 si Ui (s) definition
Ui (s) (7). Further, SC(si , si ) SC(si , si ) > 0 stable social optimum
si Ui (s). Thus, must hold ae + ae > 0; otherwise ae = ae = 0 (15)
(16) yield contradiction.
Let = (xe , xe ) discrepancy e e s. Note [1, 1]
Claim 3. Using definition (13), rewrite (15) (16)
ci (si , si ) ci (si , si ) = 12 (ae + ae ) + 21 21 ae

SC(si , si ) SC(si , si ) = (1 )(ae + ae ).
conclude 6= 1.
Thus,
1
2
1

2

AFi (si , s) =

1 (ae + ) (ae + ) 1
(ae + ae ) + 2ae
=

(1 )(ae + ae )
2
(1 )(ae + ae )
2
max min
1

.
(1 max )amin 2


227

fiApt & Schafer

claim follows Theorem 4 (ii).
following example shows bound tight even n = 2 players two
facilities. Let N = {1, 2}, E = {e, e } S1 = S2 = {{e}, {e }}. Suppose given
[0, 1) ae R+ . Define de (x) = (2 + )ae de (x) = ae x. joint strategy =
({e}, {e }) unique social optimum SC(s) = (3 + )ae . c1 (s) = (2 + )ae
c2 (s) = ae . Suppose player 1 deviates s1 = {e }. SC(s1 , s2 ) = 4ae
c1 (s1 , s2 ) = 2ae . Thus AFi (s1 , s) = /(1 ), matches precisely upper bound
given above. case [1, 0] proven analogously.
Observe selfishness level depends ratio (max min )/amin 1/(1
max ). particular, selfishness level becomes arbitrarily large max approaches 1.
next derive bound selfishness level arbitrary congestion games linear
delay functions non-negative integer coefficients, i.e., de (x) = ae x + ae , N
every e E. Let L maximum number facilities player choose,
i.e., L := maxiN,si Si |si |.
Proposition 5. selfishness level linear congestion game non-negative integer
coefficients max{0, 12 (Lmax min 1)}. Moreover, bound tight.
linear congestion games, price anarchy known 25 (see Christodoulou &
Koutsoupias, 2005; Awerbuch, Azar, & Epstein, 2013). bound shows selfishness
level depends maximum number facilities strategy set magnitude
coefficients delay functions.
Proof Proposition 5. Let stable social optimum. Note exists Theorem
4 (iii) Theorem 6. Ui (s) = every N selfishness level 0
Theorem 4 (ii). Otherwise, player N Ui (s) 6= . Let = (si , si )
si Ui (s). use xe xe refer xe (s) xe (s ), respectively.
Exploiting (14), obtain
ci (si , si ) ci (si , si ) =

X

esi \si

(ae xe + )

X

(ae (xe + 1) + ).

esi \si

Similarly,
SC(si , si ) SC(si , si ) =
+

X

(xe + 1)(ae (xe + 1) + ) xe (ae xe + )

X

(xe 1)(ae (xe 1) + ) xe (ae xe + )

X

(ae (2xe + 1) + )

esi \si

esi \si

=

esi \si

X

esi \si

(ae (2xe 1) + ).

P
Given congestion vector x = (xe )eE , define P (x) := esi \s (ae xe + ) Q(x) :=

P
es \si (ae (xe + 1) + ). Note P (x) Q(x) integers ae , N


228

fiSelfishness Level Strategic Games

every facility e E. Note definitions, P (1) =
P
Q(0) = es \si (ae + ).


AFi (si , s) =

P

esi \si (ae

+ )

P (x) Q(x)
.
2Q(x) Q(0) 2P (x) + P (1)

si Ui (s), know P (x) > Q(x) 2Q(x) Q(0) > 2P (x) P (1).
obtain
Q(x) + 1 P (x) Q(x) + 12 (P (1) Q(0) 1).
Exploiting inequalities, obtain
AFi (si , s)

1
1
(P (1) Q(0) 1) =
2
2

X

esi \si

(ae + )

1
(|si \ si | max |si \ si | min 1).
2

X

esi \si


(ae + ) 1

Note |si \ si | 1; otherwise, si si thus SC(si , si ) SC(s) contradicts
si Ui (s). expression thus 12 (Lmax min 1). claim
follows Theorem 4 (ii).
following example shows bound tight. Fix L, max min
(2n 1)min = Lmax + 1 integer n. Consider congestion game
N = {1, . . . , n} E = {e1 , . . . , eL+1 }. Define Si = {{eL+1 }} every N \ {n}
Sn = {{e1 , . . . , eL }, {eL+1 }}. Let deL+1 (x) = min x dei (x) = max every
{1, . . . , L}. joint strategy = ({eL+1 }, . . . , {eL+1 }, {e1 , . . . , eL }) SC(s) =
min (n 1)2 + Lmax cn (s) = Lmax . player n deviates sn = {eL+1 }
SC(sn , sn ) = min n2 = min (n 1)2 + min (2n 1) cn (sn , sn ) = min n.
Exploiting (2n 1)min = Lmax + 1, conclude SC(s) < SC(sn , sn )
cn (s) > cn (sn , sn ) (for n 3). Thus, social optimum sn Ui (s). obtain
1
Lmax min n
= Lmax (Lmax + min + 1)
min (2n 1) Lmax
2
1
= (Lmax min 1).
2

AFn (sn , s) =

Remark 2. use Proposition 5 scaling argument outlined Remark 1
derive bounds selfishness level congestion games linear delay functions
non-negative rational coefficients.
4.5 Prisoners Dilemma n Players
assume player N
P = {1, . . . , n} two strategies, 1 (cooperate) 0
(defect). put pi (s) := csi + b j6=i sj , b > c. Intuitively, b stands benefit
cooperation c cost cooperation.
Proposition 6. selfishness level n-players Prisoners Dilemma game
229

c
b(n1)c .

fiApt & Schafer

Intuitively, means number players Prisoners Dilemma game
increases, smaller share social welfare needed resolve underlying conflict.
observation holds value benefit. is, acuteness
dilemma diminishes number players also diminishes value
benefit grows. formal reason appeal factor unilateral deviation
social optimum inversely proportional number players inversely
proportional benefit.
Proof. game = 1 unique social optimum, N , pi (s) =
bn (b + c) SW (s) = bn2 (b + c)n. Consider joint strategy (si , si )
player deviates strategy si = 0. pi (si , si ) = bn b
c
. claim
SW (si , si ) = bn2 (b + c)n + c b(n 1). Hence AFi (si , s) = b(n1)c
follows Theorem 4 (ii).
particular, n = b = 2 c = 1 get original Prisoners Dilemma game
considered Example 1 already argued selfishness level 1.
4.6 Public Goods
consider public goods game n players. Every player N = {1, . . . , n} chooses
amount si [0, b] contributes public good, b R+ budget.
game designer collects individual contributions players, multiplies sum
c > 1 distributes resulting
amount evenly among players. payoff player
c P
thus pi (s) := b si + n jN sj .
1 c
Proposition 7. selfishness level n-players public goods game max 0, c1n .

game, every player incentive free ride contributing 0
public good (which dominant strategy c n). exactly n-players
Prisoners Dilemma game (where defect dominant strategy c > 0). However,
proposition reveals fixed c, contrast Prisoners Dilemma game,
temptation becomes stronger number players increases. Also, fixed number
players temptation becomes weaker c increases.
P
Proof Proposition 7. Note SW (s) = bn+(c1) si . unique social optimum
game therefore = b pi (s) = cb every N SW (s) = cbn. Suppose
player deviates choosing si [0, b). pi (si , si ) = cb + (1 nc )(b si ). Thus,
pi (si , si ) pi (s) = (1 nc )(b si )

SW (s) SW (si , si ) = (c 1)(b si ).

1 nc 0 Ui (s) = selfishness level zero. Otherwise, 1 nc > 0
Ui (s) = [0, b). conclude case AFi (si , s) = (1 nc )/(c1) every si Ui (s).
claim follows Theorem 4 (ii).
230

fiSelfishness Level Strategic Games

4.7 Travelers Dilemma
strategic game discussed Basu (1994) two players N = {1, 2}, strategy set
Si = {2, . . . , 100} every player i, payoff function pi every defined


si = si

pi (s) := si + b
si < si


si b otherwise,

b > 1 bonus.

Proposition 8. selfishness level Travelers Dilemma game

b1
2 .

Proof. unique social optimum game = (100, 100), (2, 2) unique
Nash equilibrium. player deviates strategy si 99, player
remains 100, respective payoffs become si + b si b, social welfare becomes

2si . AFi (si , s) = (si + b 100)/(200 2si ). maximum, b1
2 , reached si = 99.
claim follows Theorem 4 (ii).
Intuitively, means bonus b increases larger share social welfare
needs used ensure cooperation.
4.8 Tragedy Commons
Assume player N = {1, . . . , n} real interval [0, 1] set strategies.
players strategy chosen fraction common resource. Let (see Osborne, 2005,
Exercise 63.1 Tardos & Vazirani, 2007, pp. 67):




pi (s) := max 0, si 1

n
X
j=1

sj



.

payoff function reflects fact players enjoyment common resource depends positively chosen fraction resource negatively total
fraction common resource used players. Additionally, total fraction
common resource players exceeds feasible level, 1, players enjoyment
resource becomes zero.
Proposition 9. selfishness level n-players Tragedy Commons game .
Intuitively, result means game matter much involve
players sharing social welfare cannot achieve select social optimum.
Proof.
Pfirst determine stable social optima game. Fix joint strategy
let :=
jN sj . > 1, social welfare 0. assume 1.
SW (s) = t(1 t). expression becomes maximal precisely = 12
social optima stable.
equals 14 . game infinitely many P
Take stable social optimum s. jN sj = 21 . Fix {1, . . . , n}. Denote si
P
consider strategy x player pi (x, si ) > pi (a, si ). j6=i sj +x 6= 21 ,
SW (a, si ) > SW (x, si ).
231

fiApt & Schafer


P pi (a, si ) = 2 SW (a, si ) =
j6=i sj + x < 1 hence

pi (x, si ) = x(a +

1
2

x)

1
4.

Further, pi (x, si ) > pi (a, si ) implies

SW (x, si ) = ( 12 + x)(1

1
2

+ x) =

1
4

(a x)2 .

Also x 6= a. Hence
AFi (x, s) =

(a x)(x 12 )
12
x 12
pi (x, si ) pi (a, si )
=
=
1
+
=
SW (a, si ) SW (x, si )
(a x)2
ax
ax

1
1
Since pi (x, si ) pi (a, si ) =
P(a x)(x 21) pi (x, si ) > pi (a, si ) iff < x < 2
1
1
> x > 2 . 2 , since j6=i sj +a = 2 . conjunction pi (x, si ) > pi (a, si )
SW (x, si ) < SW (a, si ) holds iff < x < 12 . maxa<x< 1 AFi (x, s) = .
2
arbitrary stable social optimum, claim follows Theorem 4 (i).

4.9 Cournot Competition
consider Cournot competition n firms linear inverse demand function
constant returns scale (see, e.g., Jehle & Reny, 2011, pp. 174175). assume
playerPi N = {1, . . . , n} strategy set Si = R+ payoff function
pi (s) := si (a b jN sj ) csi given a, b, c, > c P
0 b > 0.
price product represented expression b jN sj production cost corresponding production
level si csi . follows rewrite
P
payoff function pi (s) := si (d b jN sj ), := c. Note payoffs
negative, case tragedy commons game. Still proofs
similar games.
Proposition 10. selfishness level n-players Cournot competition game .
Proof.
P first determine stable social optima game. Fix joint strategy
let := jN sj . SW (s) = t(d bt). expression becomes maximal precisely

. game infinitely many social optima stable.
= 2b
P
P

Take stable social optimum s. jN sj = 2b
. Fix N . Let u := j6=i sj .
every strategy z player
pi (z, si ) = bz 2 + (d bu)z

SW (z, si ) = bz 2 + (d 2bu)z + u(d bu).

Denote si consider strategy x player pi (x, si ) > pi (y, si ).

, SW (y, si ) > SW (x, si ).
u + x 6= 2b

pi (x, si ) pi (y, si ) = b(x2 2 ) + (d bu)(x y)

= b(x y)(x + + u db ) = b(x y)(x


2b ),


) account equality u+y =
last equality holds since u db = (y+ 2b
Further,

SW (y, si ) SW (x, si ) = b(x2 2 ) (d 2bu)(x y)

= b(x y)(x + + 2u db ) = b(x y)2 ,
232


2b .

fiSelfishness Level Strategic Games

last equality holds since 2u db = 2y account equality u + =
x 6= y. Hence
AFi (x, s) =


2b .



x 2b
2b
pi (x, si ) pi (y, si )
=
= 1 +
.
SW (y, si ) SW (x, si )
xy
yx


Since pi (x, si )pi (y, si ) = b(yx)(x 2b
) pi (x, si )pi (y, si ) > 0 iff < x <



> x > 2b . 2b , since u + = 2b . conjunction pi (x, si ) > pi (y, si )

SW (x, si ) > SW (y, si ) holds iff < x < 2b
. supy<x< AFi (x, s) = .
2b
arbitrary stable social optimum, claim follows Theorem 4 (i).

2b

proof shows every stable social optimum s, every player exist
deviating strategies arbitrary high appeal factor. fact, limxy+ AFi (x, s) = ,
i.e., appeal factor deviating strategy x converges converges
right original strategy s.
4.10 Bertrand Competition
Next, consider Bertrand competition, game concerned simultaneous selection
prices product two firms (see, e.g., Jehle & Reny, 2011, pp. 175177).
product sold firm chose lower price. case tie product
sold firms profits split. assume firm identical
marginal costs c > 0 fixed cost, strategy set Si equals [c, ab ),
c < ab . payoff function player {1, 2} given

c < si < s3i

(si c)(a bsi )
1
pi (si , s3i ) := 2 (si c)(a bsi ) c < si = s3i


0
otherwise.

Proposition 11. selfishness level Bertrand competition game .
Proof. Let := a+bc
2b . SW (s) > 0, SW (s) = (s0 c)(abs0 ), s0 := min(s1 , s2 ).
Note (c, ab ), since assumption bc < a. Hence social optimum iff
min(s1 , s2 ) = d.
social optimum s1 6= s2 , player larger si profitably
deviate s3i (that equals d), (s3i , s3i ) remains social optimum.
stable social optimum (d, d).
Fix {1, 2}. Note si slightly lower d, pi (si , d) > pi (d, d). Further,
lim (pi (si , d) pi (d, d)) = 12 (d c)(a bd),

si



lim (SW (d, d) SW (si , d)) = 0

si

SW (d, d) SW (si , d) 6= 0 si 6= d. Hence
pi (si , d) pi (d, d)
= .
c<si <d SW (d, d) SW (si , d)
sup

claim follows Theorem 4 (i).
233

fiApt & Schafer

5. Extensions Future Research Directions
introduced selfishness level game new measure discrepancy
social welfare Nash equilibrium social optimum. studies reveal
selfishness level often provides deeper insights characteristics influence
players willingness cooperate. conclude mentioning natural extensions
future research directions.
5.1 Extensions
definition selfishness level naturally extends solution concepts
forms games.
5.1.1 Mixed Nash Equilibria
mixed Nash equilibria simply adapt definitions stipulating strategic
game G -selfish mixed Nash equilibrium G() social optimum,
also allow social optima mixed strategies. selfishness level G defined
(1).
example, notion selfishness level Matching Pennies game (Example 3) 0 since unique mixed Nash equilibrium, ( 21 H + 21 T, 12 H + 12 ), also social
optimum. Matching Pennies game pure Nash equilibrium. contrast, game
Example 4 pure Nash equilibrium. use mixed Nash equilibria
selfishness level also becomes 0. games selfishness level changed ,
pure Nash equilibria used, 0, mixed Nash equilibria used.
Further, finite selfishness level finite game decrease use mixed Nash
equilibria. example consider following amalgamation Matching Pennies
(with payoffs increased 2) Prisoners Dilemma (with payoffs increased 1) games:

H

C


H
3, 1
1, 3
0, 0
0, 0


1, 3
3, 1
0, 0
0, 0

C
0, 0
0, 0
2, 2
3, 0


0, 0
0, 0
0, 3
1, 1

game unique stable social optimum, (C, C), unique pure Nash equilibrium, (D, D). easy check using Theorem 4 (ii) selfishness level 1.
hand, use mixed Nash equilibria selfishness level becomes 0.
Indeed, ( 12 H + 21 T, 12 H + 12 ) mixed Nash equilibrium social optimum
mixed strategies.
5.1.2 Extensive Games
also consider extensive games subgame perfect equilibria. example
consider six-period version centipede game (see, e.g., Osborne, 2005):
234

fiSelfishness Level Strategic Games

1

C

2

C

1

C

2

C

1

C

2

C













(1, 0)

(0, 2)

(3, 1)

(2, 4)

(5, 3)

(4, 6)

(6, 5)

unique subgame perfect equilibrium player chooses every period
resulting payoffs (1, 0). contrast, social optimum obtained player
chooses C every period resulting payoffs (6, 5). seek
resulting game G() latter pair strategies forms subgame perfect equilibrium.
particular, player 2 choose last round G() action C. happens
5 + (6 + 5) 6 + (4 + 6) holds iff 1. Now, = 1 game G()
following payoffs:
1

C

2

C

1

C

2

C









(2, 1)

(2, 4)

(7, 5)

(8, 10)

1

C


2

C

(17, 16)



(13, 11) (14, 16)

game pair strategies player chooses C every period
subgame perfect equilibrium social optimum yields payoffs (17, 16).
conclude (appropriately adapted) selfishness level game 1.
leave future work study alternatives.
5.2 Future Research Directions
several intriguing questions left open. discuss future research
directions below.
5.2.1 Abstract Games
would interesting define notion selfishness level abstract games.
games payoffs replaced preference relations (see Osborne &
Rubinstein, 1994). preference relation set mean linear ordering
A. precisely, abstract game defined (N, {Si }iN , {i }iN )
players preference relation defined set S1 Sn joint strategies.
realization abstract game (N, {Si }iN , {i }iN ) mean strategic game
(N, {Si }iN , {pi }iN ) N s, S1 Sn iff
pi (s) pi (s ).
Unfortunately, clear this. First, note notion Nash
equilibrium well defined abstract games. However, counterpart
notion social optimum, since global preference relation set joint
strategies.
tempting circumvent difficulty defining notion selfishness level
abstract game G using realizations G corresponding games G ((G )),
235

fiApt & Schafer

(G ) selfishness level G . Unfortunately resulting strategic games G ((G )),
G realization G realizations single abstract game, detour
allow us associate initial abstract game another one.
example take two realizations abstract Prisoners Dilemma game
corresponding games G ((G )):
C

C


C
2, 2
3, 0
C
2, 2
2.5, 0


0, 3
1, 1

0, 3
1, 1

C


C
6, 6
6, 3

C


C
6, 6
5, 2.5


3, 6
3, 3

3, 6
3, 3

realizations selfishness level 1 transformed games correspond abstract game, since first transformed game p2 (D, C)
p2 (D, D), second one p2 (D, D) > p2 (D, C).
5.2.2 Selfishness Function
approach assigned game positive real number, selfishness level.
natural generalization idea would assign game G function
fG : R+ R+ , f () equals price stability game G().
selfishness level G inf{ R+ | fG () = 1}.
function fG studied altruistic extensions linear congestion games
fair cost sharing games (Chen et al., 2011; Elias et al., 2010). However, papers
upper bounds fG derived, light results obtained cannot
tight. would interesting determine fG exactly games. would probably
require generalization characterization result presented paper.
5.2.3 Alternative Approach Based Price Anarchy
defined selfishness level game smallest price stability
G() 1. Alternatively, one might define selfishness level smallest
price anarchy G() 1. alternative approach often yields value . Take
instance following coordination game G:

1, 1
0, 0


B

B
0, 0
0, 0

every 0 (A, A) social optimum G() social welfare 2 + 4,
(B, B) Nash equilibrium G() social welfare 0. alternative
selfishness level game G , original selfishness level course 0.
another example consider game G left corresponding game G()
right:

B


1, 1
0, 3

B
3, 0
0, 0


B


1 + 2, 1 + 2
3, 3 + 3
236

B
3 + 3, 3 + 3
0, 0

fiSelfishness Level Strategic Games

selfishness level 1, since smallest value (A, B) Nash equilibrium G(). hand, focus price anarchy, need
choose smallest (A, A) Nash equilibrium G() (A, B) is.
case iff 3 > 1 + 2, i.e., > 1. alternative selfishness level
game G 1+ .
view examples find alternative approach promising. Still,
might interesting clarify games yields finite values.
5.2.4 Alternative Approach Based Approximate Nash Equilibria
mentioned related work section, alternative approach measure stability equilibria game following. Given payoff-maximization game G =
(N, {Si }iN , {pi }iN ), call G -stable 0 exists social optimum
also (1 + )-approximate Nash equilibrium, i.e., every player N every
si Si , (1 + )pi (s) pi (si , si ).3 define stability level G infimum
0 G -stable. Intuitively, stability level means alter
players incentives scaling payoffs factor (1 + ) social optimum
realized Nash equilibrium.
would interesting study stability level game relates selfishness
level. Using definitions, easy see game G admits social
optimum every player N every si Si , pi (s) SW (s)SW (si , si ),
G -stable G -selfish.4 Said differently, stability level G
selfishness level. Similarly, reverse inequality holds G -selfish G
-stable.
particular, observation applied fair cost sharing games,
every joint strategy holds every N every si Si , ci (si , si )
SC(si , si ) SC(s) (see also (11) Section 4.3). conclude stability level
fair cost sharing game G selfishness level. consequence, bounds
selfishness level derived Section 4.3 extend stability level case.
Further, hard verify stability level singleton cost sharing games
least max{0, 21 cmax /cmin 1} cost sharing games integer costs least
max{0, 21 Lcmax 1} considering examples given proofs Proposition 2
Proposition 3, respectively. Thus, games stability level coincides
selfishness level.
However, seen two notions always coincide. public
goods game another example holds exists social optimum
every player N every si Si , pi (s) SW (s) SW (si , si ) (see proof
Proposition 7). Thus, stability level game selfishness level.
fact, simple calculations show stability level max{0, (1 nc )/c} max{0, (1
c
n )/(c 1)}, latter selfishness level game.
leave future work investigate stability level relation
selfishness level.
3. cost-minimization games, require ci (s) (1 + )ci (si , si ).
4. cost-minimization games, inequality reads ci (si , si ) SC(si , si ) SC(s).

237

fiApt & Schafer

5.2.5 Social Welfare Functions
paper exclusively concentrated social welfare functions defined
sum individual payoffs players. leave future research study
selfishness level games social welfare functions, e.g., maximizing minimum
payoff players.

Acknowledgments
preliminary version paper appeared Proceedings 5th International
Symposium Algorithmic Game Theory (Apt & Schafer, 2012).
acknowledge initial discussions Po-An Chen final discussions Valerio
Capraro. also thank anonymous reviewers preliminary version valuable
comments. particularly grateful three reviewers JAIR helpful
remarks.
Krzysztof R. Apt also affiliated University Amsterdam, Institute Logic,
Language Computation, Science Park 107, 1098 XG Amsterdam, Netherlands.
Guido Schafer also affiliated VU University Amsterdam, Department
Econometrics Operations Research, De Boelelaan 1105, 1081 HV Amsterdam,
Netherlands.

References
Anshelevich, E., Dasgupta, A., Kleinberg, J., Tardos, E., Wexler, T., & Roughgarden, T.
(2008). price stability network design fair cost allocation. SIAM
Journal Computing, 38 (4), 16021623.
Anshelevich, E., Das, S., & Naamad, Y. (2009). Anarchy, stability, utopia: Creating
better matchings. Proc. 2nd International Symposium Algorithmic Game Theory
(SAGT09), Lecture Notes Computer Science 5814, pp. 159170. Springer.
Apt, K. R., & Schafer, G. (2012). Selfishness level strategic games. Proc. 5th International Symposium Algorithmic Game Theory (SAGT12), pp. 1324. Springer.
Ashlagi, I., Monderer, D., & Tennenholtz, M. (2008). value correlation. Journal
Artificial Intelligence Research, 33, 575613.
Awerbuch, B., Azar, Y., & Epstein, A. (2013). price routing unsplittable flow. SIAM
Journal Computing, 42 (1), 160177.
Axelrod, R. (1984). Evolution Cooperation. Basic Books.
Balcan, M.-F., Blum, A., & Mansour, Y. (2009). Improved equilibria via public service
advertising. Proceedings 20th Annual ACM-SIAM Symposium Discrete
Algorithms, pp. 728737. Society Industrial Applied Mathematics.
Basu, K. (1994). travelers dilemma: paradoxes rationality game theory. American
Economic Review, 84 (2), 391395.
Becker, T. C., Carter, M., & Naeve, J. (2005). Experts playing travelers dilemma.
Tech. rep. 252/2005, Department Economics, University Hohenheim, Germany.
238

fiSelfishness Level Strategic Games

Beckmann, M., McGuire, B., & Winsten, C. (1956). Studies Economics Transportation. Yale University Press, New Haven.
Biro, P., Manlove, D. F., & Mittal, S. (2010). Size versus stability marriage problem.
Theoretical Computer Science, 411 (1618), 18281841.
Bowles, S. (2004). Microeconomics: Behavior, Institutions, Evolution. Princeton University Press, Princeton.
Capraro, V. (2013). model human cooperation social dilemmas. PLoS ONE, 8 (8),
16. e72427.
Caragiannis, I., Kaklamanis, C., Kanellopoulos, P., Kyropoulou, M., & Papaioannou, E.
(2010). impact altruism efficiency atomic congestion games.
Proc. 5th Symposium Trustworthy Global Computing, pp. 172188.
Chen, P.-A., & Kempe, D. (2008). Altruism, selfishness, spite traffic routing.
Proc. 10th ACM Conference Electronic Commerce, pp. 140149.
Chen, P.-A., de Keijzer, B., Kempe, D., & Schafer, G. (2011). robust price anarchy
altruistic games. Proc. 7th Workshop Internet Network Economics, pp.
383390.
Christodoulou, G., & Koutsoupias, E. (2005). price anarchy finite congestion
games. Proc. 37th Annual ACM Symposium Theory Computing, pp. 6773.
Christodoulou, G., Koutsoupias, E., & Spirakis, P. G. (2011). performance
approximate equilibria incongestion games. Algorithmica, 61 (1), 116140.
Cooper, R., DeJong, D. V., Forsythe, R., & Ross, T. W. (1996). Cooperation without reputation: Experimental evidence prisoners dilemma games. Games Economic
Behavior, 12 (2), 187218.
Dreber, A., Rand, D., Fudenberg, D., & Nowak, M. (2008). Winners dont punish. Nature,
452, 348351.
Elias, J., Martignon, F., Avrachenkov, K., & Neglia, G. (2010). Socially-aware network
design games. Proc. INFOCOM 2010, pp. 4145.
Feldman, M., & Tamir, T. (2009). Approximate strong equilibrium job scheduling games.
Journal Artificial Intelligence Research, 36, 387414.
Fiat, A., Karlin, A., Koutsoupias, E., & Vidali, A. (2013). Approaching utopia: strong truthfulness externality-resistant mechanisms. Proceedings 4th conference
Innovations Theoretical Computer Science, pp. 221230. ACM.
Goeree, J. K., & Holt, C. A. (2001). Ten little treasures game theory ten intuitive
contradictions. American Economic Review, 91, 14021422.
Hoefer, M., & Skopalik, A. (2009). Altruism atomic congestion games. Proc. 17th
European Symposium Algorithms, pp. 179189.
Isaac, R. M., & Walker, J. M. (1988). Group size effects public goods provision:
voluntary contributions mechanism. Quarterly Journal Economics, 103 (1),
179199.
239

fiApt & Schafer

Jehle, G., & Reny, P. (2011). Advanced Microeconomic Theory (Third edition). Addison
Wesley, New York, NY.
Jurca, R., & Faltings, B. (2009). Mechanisms making crowds truthful. Journal
Artificial Intelligence Research, 34, 209253.
Kaporis, A. C., & Spirakis, P. G. (2009). price optimum stackelberg games
arbitrary single commodity networks latency functions. Theoretical Computer
Science, 410 (8-10), 745755.
Koutsoupias, E., & Papadimitriou, C. H. (2009). Worst-case equilibria. Computer Science
Review, 3 (2), 6569.
Ledyard, J. O. (1995). Public Goods: Survey Experimental Research, chap. 2, pp.
111194. Handbook Experimental Economics. Princeton University Press.
Marco, G. D., & Morgan, J. (2007). Slightly altruistic equilibria normal form games.
Working paper 185, Center Studies Economics Finance, University
Salerno, Italy. Available http://www.csef.it/WP/wp185.pdf.
Milchtaich, I. (1996). Congestion games player-specific payoff functions. Games
Economic Behaviour, 13, 111124.
Monderer, D., & Shapley, L. S. (1996). Potential games. Games Economic Behaviour,
14, 124143.
Osborne, M. J. (2005). Introduction Game Theory. Oxford University Press, Oxford.
Osborne, M. J., & Rubinstein, A. (1994). Course Game Theory. MIT Press,
Cambridge, Massachusetts.
Ritzberger, K. (2002). Foundations Non-cooperative Game Theory. Oxford University
Press, Oxford.
Rosenthal, R. W. (1973). class games possessing pure-strategy Nash equilibria. International Journal Game Theory, pp. 6567.
Roughgarden, T. (2009). Intrinsic robustness price anarchy. Proc. 41st Annual
ACM Symposium Theory Computing, pp. 513522.
Schulz, A. S., & Moses, N. E. S. (2003). performance user equilibria traffic
networks. SODA, pp. 8687.
Sharma, Y., & Williamson, D. P. (2009). Stackelberg thresholds network routing games
value altruism. Games Economic Behavior, 67 (1), 174190.
Tardos, E., & Vazirani, V. J. (2007). Basic solution concepts computational issues.
Nisan, N., Roughgarden, T., Tardos, E., & Vazirani, V. J. (Eds.), Algorithmic Game
Theory, chap. 1, pp. 328. Cambridge University Press.
Young, H. P. (1993). evolution conventions. Econometrica, 61 (1), 5784.

240

fiJournal Artificial Intelligence Research 49 (2014) 451-500

Submitted 10/13; published 03/14

Text-Based Twitter User Geolocation Prediction
Bo Han

HANB @ STUDENT. UNIMELB . EDU . AU

University Melbourne, VIC 3010, Australia
NICTA Victoria Research Laboratory

Paul Cook

PAULCOOK @ UNIMELB . EDU . AU

University Melbourne, VIC 3010, Australia

Timothy Baldwin

TB @ LDWIN . NET

University Melbourne, VIC 3010, Australia
NICTA Victoria Research Laboratory

Abstract
Geographical location vital geospatial applications like local search event detection.
paper, investigate improve task text-based geolocation prediction Twitter
users. Previous studies topic typically assumed geographical references (e.g.,
gazetteer terms, dialectal words) text indicative authors location. However,
references often buried informal, ungrammatical, multilingual data, therefore
non-trivial identify exploit. present integrated geolocation prediction framework
investigate factors impact prediction accuracy. First, evaluate range feature
selection methods obtain location indicative words. evaluate impact nongeotagged tweets, language, user-declared metadata geolocation prediction. addition,
evaluate impact temporal variance model generalisation, discuss users differ
terms geolocatability.
achieve state-of-the-art results text-based Twitter user geolocation task, also
provide extensive exploration task date. findings provide valuable insights
design robust, practical text-based geolocation prediction systems.

1. Introduction
growing volume user-generated text posted social media services Twitter, Facebook, Tumblr leveraged many purposes ranging natural disaster response targeted advertising (Tuten, 2008; Nunez-Redo, Daz, Gil, Gonzalez, & Huerta, 2011; Yin, Lampert,
Cameron, Robinson, & Power, 2012). many circumstances important know users location order accomplish tasks effectively. example, disaster response managers must
know direct resources order effectively coordinate aid, advertisers could benefit
tailoring advertisements users location. Similarly, search results localisation hinges
knowledge users location. Although many social media services allow user declare
location, metadata known unstructured ad hoc (Hecht, Hong, Suh, & Chi, 2011)
(e.g., melbo denoting Melbourne, AU 1 ), well oftentimes non-geographical (e.g.,
1. Throughout paper, present city names ISO 3166-1 alpha-2 country-level designators AU =
Australia CA = Canada. US-based city names mentioned context North American
regional dataset used experimentation (NA), use ISO 3166-2:US designator US-CA = California
US-PA = Pennsylvania.
c
2014
AI Access Foundation. rights reserved.

fiH , C OOK & BALDWIN

little bubble). Text-based geolocation automatically predicting users location based
content messages therefore becoming increasing interest (e.g., Cheng, Caverlee, &
Lee, 2010, others). paper investigate improve text-based geolocation prediction
Twitter users. Specifically, exploit tweets profile information given user infer
primary city-level location, claim sufficiently fine-grained support sorts
applications mentioned above.
well established previous work (e.g., Wing & Baldridge, 2011, others), reasonable assume user posts social media reflect geospatial locum, lexical priors
differ region region. example, user London much likely talk Piccadilly tube user New York Beijing. say words uniquely
associated London, course: tube could certainly mentioned user outside UK.
However, use range words high relative frequency strongly indicative
fact user located London. work area utilises geotagged data ground truth
evaluation (e.g., Eisenstein, OConnor, Smith, & Xing, 2010, others). geotagged data
contains GPS coordinates inserted users consent GPS-enabled device smartphone, offers accurate information users position time tweeting. Although
approaches text-based geolocation offering increasingly promising results, studies date
topic limited number important ways. raise key issues Section
3 investigate turn, focusing following issues:
1.1 Location Indicative Words
Text-based geolocation prediction models social media predominantly based full text
data tweets, including common words geospatial dimension (e.g., today), potentially
hampering prediction, large number words observed tweets, leading
slower, memory-intensive models. tackle automatically finding location indicative
words (LIWs) via feature selection, demonstrating reduced feature set boosts geolocation accuracy. Section 5, carry extensive evaluation wide range feature selection
methods proposed literature, show information gain ratio-based approach outperforms benchmark geolocation prediction methods 10.6 percentage points terms accuracy,
reduces median prediction error distance 209km publicly-available regional (North
America) dataset. similarly demonstrate effectiveness LIW selection global dataset
Section 6.
1.2 Non-geotagged Tweets
addition experimenting geotagged data, extend analysis incorporate nongeotagged tweets. recent work (e.g., Roller, Speriosu, Rallapalli, Wing, & Baldridge, 2012)
incorporated non-geotagged training data, although little work analysed contribution
non-geotagged data, i.e., extent incorporating non-geotagged data improves geolocation accuracy. Furthermore, evaluation previous models restricted geotagged data
(in order access ground truth) although goal line research able
infer locations users whose locations known. However, unclear well models
evaluated geotagged data generalise non-geotagged data. example, geotagged tweets sent GPS-enabled devices smartphones, non-geotagged tweets
452

fiT EXT-BASED WITTER U SER G EOLOCATION P REDICTION

sent range devices (including desktop computers), two types data could
different characteristics (Gouws, Metzler, Cai, & Hovy, 2011).
Section 7, address issues training testing geotagged tweets, non-geotagged
tweets, combination two. show exploiting users non-geotagged tweets,
city-level accuracy improved 12.6% 28.0% benchmark dataset, underlining
potential contribution non-geotagged data. Furthermore, numbers also suggest
model trained geotagged data indeed generalises non-geotagged data, although sub-domain
differences geotagged data non-geotagged data observed.
1.3 Language Influence
exceptions (e.g., Kinsella, Murdock, & OHare, 2011), text-based geolocation
studies carried English-only setting, primarily English setting.
high-accuracy language identification tools (Lui & Baldwin, 2012; Nakatani, 2010) readily
available, problem: messages target language identified, text-based
geolocation methods applied messages. However, remains seen whether
text-based geolocation approaches shown work well English perform well
languages, perform well multilingual setting. English tweeted throughout
world, whereas languages Indonesian primarily tweeted localised areas. such,
performance methods developed tested English data could different applied languages. investigate language influence multilingual dataset Section
8. results suggest model indeed generalises monolingual English multilingual setting. Furthermore, experiments reveal geolocation prediction much easier
languages geographically-restricted use (e.g., Indonesian) languages
diverse usage (e.g., English). go show composite model consisting
number monolingual geolocation models based language identification outperforms model
trained multilingual data.
1.4 Metadata Ensemble Learning
Although tweet-based geolocation worthy study right, tweets accompanied
rich metadata public user profiles. metadata included payload JSON objects containing tweets, offers complementary information may exploited improve accuracy,
e.g., timezone data user-declared location. work utilising
timezone (Mahmud, Nichols, & Drews, 2012) user-declared location (Hecht et al., 2011) information user geolocation, metadata remains largely untouched literature. Section
9, investigate performance metadata-based geolocation models compare
benchmark methods. show incorporating information metadata tweet message stacking-based approach, city-level accuracy 49.1%, median prediction error
distance 9km, achieved global dataset, substantial improvement
base classifiers.
1.5 Temporal Influence
Twitter growing evolving medium, data Twitter streams tends locally temporal time posting. addition evaluating geolocation model old
453

fiH , C OOK & BALDWIN

time-homogeneous data (sampled time period training data), Section 10
evaluate trained model new time-heterogeneous dataset, collected approximately one year training test data used earlier experiments. observed
moderate decline results indicates stacked geolocation model indeed influenced
temporal changes. Error analysis reveals primarily caused unreliability
base model trained user-declared locations. contrast, find models trained tweet
text timezone information relatively insensitive temporal changes. finding
one hand justifies efforts to-date pursuing better text-based geolocation prediction,
hand suggests user-declared location data used, model periodically
updated remain current temporal changes.
1.6 User Geolocatability Prediction Confidence
discuss geolocatability users regard tweeting behaviour Section 11.
instance, mentioning many local place names strong influence prediction
accuracy? Experiments suggest number LIWs (in particular, gazetted location names)
user-declared metadata key geolocating user. different tweeting behaviours
among users, users equally geolocatable, predictions proportion
reliable. conduct pilot study approximating prediction confidence
range variables Section 12.
paper advances state-of-the-art text-based geolocation prediction number
directions, provides practical guidelines design text-based geolocation application.
paper builds previously-published work (Han, Cook, & Baldwin, 2012b, 2013)
much extensive evaluation, new work following areas:
large-scale comparative evaluation twelve feature selection methods user geolocation
nine considered earlier work Sections 46.
analysis impact training non-geotagged data Section 7.
new set experiments, subsequent analysis, examining influence language
Section 8.
analysis utility user-supplied metadata ensemble learning Section 9.
More-detailed analysis model generalisation temporal change Section 10 including
city-level meta-analysis.
new pilot study user geolocatablility privacy Section 11.
proposed text-based method primarily uses words geolocation prediction, intentionally excludes Twitter specific entities, hashtags user mentions. prediction accuracy
therefore largely depends whether text contains sufficient geospatial information geolocation prediction. Therefore, although paper focuses exclusively Twitter, proposed method
could equally applied forms social media text, Facebook status updates
user-submitted comments (to services YouTube).
454

fiT EXT-BASED WITTER U SER G EOLOCATION P REDICTION

2. Related Work
acknowledging potential privacy concerns (Mao, Shuai, & Kapadia, 2011; Pontes, Vasconcelos, Almeida, Kumaraguru, & Almeida, 2012), accurate geolocation prediction key driver
location-specific services localised search, target research across
different disciplines. example, tagging user queries (Wang, Wang, Xie, Forman,
Lu, Ma, & Li, 2005; Backstrom, Kleinberg, Kumar, & Novak, 2008; Yi, Raghavan, & Leggetter,
2009) web pages (Ding, Gravano, & Shivakumar, 2000; Amitay, HarEl, Sivan, & Soffer, 2004;
Zong, Wu, Sun, Lim, & Goh, 2005; Silva, Martins, Chaves, Afonso, & Cardoso, 2006; Bennett,
Radlinski, White, & Yilmaz, 2011) considered information retrieval. geographical
information science, primary focus recognising location mentions text (Leidner
& Lieberman, 2011), named entity recognition tools typically employed detect extract
mentions (Quercini, Samet, Sankaranarayanan, & Lieberman, 2010; Gelernter & Mushegian,
2011). Within social media realm, geolocation methods applied images Flickr
(Crandall, Backstrom, Huttenlocher, & Kleinberg, 2009; Serdyukov, Murdock, & van Zwol, 2009;
Hauff & Houben, 2012; OHare & Murdock, 2013; Laere, Schockaert, & Dhoedt, 2013), Wikipedia
articles (Lieberman & Lin, 2009), individual tweets (Kinsella et al., 2011), Twitter users (Eisenstein
et al., 2010; Cheng et al., 2010; Kinsella et al., 2011; Wing & Baldridge, 2011; Roller et al., 2012;
Han et al., 2012b), identifying words topics Twitter salient particular
regions (Eisenstein et al., 2010; Yin, Cao, Han, Zhai, & Huang, 2011; Hong, Ahmed, Gurumurthy,
Smola, & Tsioutsiouliklis, 2012; Dalvi, Kumar, & Pang, 2012).
Identifying Twitter users locations non-trivial, mainly due unavailability reliable
geographic information. Although Twitter allows users declare location user profile,
location descriptions unstructured ad hoc (Cheng et al., 2010; Hecht et al., 2011), e.g.,
people use vernacular expressions philly, non-standard spellings Filladephia,
refer Philadelphia; non-geographical descriptions like heart also commonly found.
Without appropriate processing, value location fields greatly limited. Hecht et al.
(2011) demonstrate trivially using location fields off-the-shelf geolocation tools ineffective. Alternatively, tweets sent mobile devices geotagged accurate GPS
coordinates, however, proportion geotagged tweets estimated mere 1% (Cheng
et al., 2010), location vast majority users geotagged. Methods based
IP addresses (Buyukokkten, Cho, Garcia-Molina, Gravano, & Shivakumar, 1999) applied
task, general web contexts shown achieve around 90% accuracy mapping
Internet hosts locations (Padmanabhan & Subramanian, 2001). methods applicable Twitter many social media services, however, IP address device
message sent cannot accessed via public APIs. Doubtless Twitter
access information use user geolocation, although even here, geographical divisions IP addresses always credible. instance, departments international
corporation might use IP address range, true locations could spread across
world. VPNs also complication approaches. third-party service provider making
use Twitter data, however, look sources geospatially-identifying information,
including text content users posts metadata information, targeted research.
spatial data mining community, geographical references (e.g., gazetteer terms) text
also exploited infer geolocation. Intuitively, place frequently mentioned user
tweets, likely tweeting region. Methods building intuition range
455

fiH , C OOK & BALDWIN

naive gazetteer matching rule-based approaches (Bilhaut, Charnois, Enjalbert, & Mathet, 2003),
machine learning-based methods (primarily based named entity recognition: Quercini et al.,
2010; Gelernter & Mushegian, 2011). Despite encouraging results approach longer
homogeneous documents sets (Quercini et al., 2010), performance impeded
nature tweets: short informal, chances user mentioning gazetted
places tweets high. Moreover, handling vernacular place names, e.g., melbo
Melbourne, approach limited. reliance named entity recognition thwarted
unedited nature social media data, spelling capitalisation much ad hoc
edited document collections (Ritter, Clark, Mausam, & Etzioni, 2011; Han, Cook, & Baldwin,
2012a).
Moving beyond off-the-shelf solutions, recently, many robust machine learning methods
applied geolocation, primary approach estimate locations based
textual content tweets. instance, Cheng et al. (2010) exploit words known primarily used particular regions, along smoothing techniques, improve simple generative
geolocation model applied data continental United States. Wing Baldridge
(2011) divide worlds surface uniform-size grid, compare distribution words
given users tweets grid cell using Kullback-Leibler (KL) divergence identify
users likely location. One limitation approach grid cells rural areas tend
contain tweets, many tweets urban grid cells. Roller et al.
(2012) therefore extend method use adaptive grid representation cells contain
approximately amount data, based k-d tree (Bentley, 1975). Kinsella et al. (2011)
examine geolocation prediction different granularities (e.g., zip codes, city, state country).
Chang, Lee, M., Lee (2012) prune noisy data based geometrically-local words (i.e., words
occur geographically close other, found limited number cities)
non-stop words dis-similar stop words, experiment reduced feature set
using Gaussian mixture model Maximum Likelihood Estimation location prediction.
Beyond purely text-based methods (language model-based methods), sources information
also integrated. Li, Serdyukov, de Vries, Eickhoff, Larson (2011) investigate geolocation prediction based linear rank combination text temporal factors. Mahmud et al.
(2012) combine timezone information content-based classifiers hierarchical model geolocation. particular, nouns, hashtags, place names considered content method.
Schulz, Hadjakos, Paulheim, Nachtwey, Muhlhauser (2013) combine scores various geographical sources (e.g., tweet text, user profile data). sum scores location represented
aggregated height polygon-partitioned map, highest polygon predicted
location.
Topics discussed Twitter vary across geographical regions. Intuitively, instance, Americans likely talk NBA baseball Australians (who probably mention AFL
rugby often). capture regional topic variations Twitter, topic modelling-based
approaches also used incorporate geographical regions generative process.
instance, Eisenstein et al. (2010) introduce geographical variable (r); instead generating observed word w per-word topic distribution z standard Latent Dirichlet Allocation
(LDA) model (Blei, Ng, & Jordan, 2003), proposed approach refines step additionally
modeling topic distributions across different geographical regions, i.e., w generated
per-word region-topic distribution rz . Therefore, observed user locations generated
geographical regions region variable topic modeling linked user geographical
456

fiT EXT-BASED WITTER U SER G EOLOCATION P REDICTION

locations. Generally, users location predicted regional level adopting location
centroid geotagged tweets region. Hong et al. (2012) improve approach
considering fine-grained factors additive generative model. addition introducing
per-region topic variance, incorporate per-user topic variance, regional language model,
global background topics. compensate computational complexity associated
extra hidden variables, adopt sparse modeling inference. top geolocation prediction tasks, many research problems also involve modelling geographical locations.
Dalvi et al. (2012) exploit impact geographical locations users discussions pre-defined
objects (e.g., restaurants) tweets. Yin et al. (2011) propose ways discover compare topics
geographical regions jointly modelling locations text. Despite benefits incorporating per-region topic variance models, concerns prevent us using topic modeling
approaches study. First, temporal currency geographical topics limited, e.g.,
Olympics playoffs. temporally-specific topics less indicative location future inference, e.g., geolocating users model trained. Furthermore, topic modelling
generally computationally expensive, suffers efficiency problems applied large volumes data, available social media. Therefore experiment language
model-based methods better suited large-scale data.
Social network information, including explicit friendship relations (Backstrom, Sun, &
Marlow, 2010; Sadilek, Kautz, & Bigham, 2012; Rout, Bontcheva, Preotiuc-Pietro, & Cohn, 2013)
implicit social interactions (Chandra, Khan, & Muhaya, 2011; Jurgens, 2013), shown
effective predicting locations. City-level prediction results range approximately 50
80% (Rout et al., 2013) depending wide range factors including user density social
network precise scope geolocation prediction task. However, social networks
dynamic, information often difficult obtain text data large scale.
instance, obtaining social network information requires multiple requests rate-limited Twitter
API reconstruct full social graph. therefore focus approaches based text,
metadata accompanies individual tweet, leave possibility integrating social
network information future work.

3. Key Questions Geolocation Prediction Framework
Though various geolocation prediction approaches proposed adapted social media
data, fundamental questions remain. rest paper, address
questions turn.
Given text-based methods rely salient words local particular regions disambiguate
geolocations, location indicative words improve accuracy using full word
set?
model trained geotagged data generalise non-geotagged data? impact
adding non-geotagged texts training test data? inherent sub-domain
difference geotagged non-geotagged tweets given geotagged tweets primarily sent mobile devices?
geolocation prediction accuracy vary language? example, user primarily
tweets Japanese geolocatable user tweets mostly English? language
457

fiH , C OOK & BALDWIN

influence accuracy, exploit improve multilingual geolocation prediction?
user-declared text metadata provide geographical information complementary
tweets themselves? make use multiple sources textual data
produce accurate geolocation predictor?
Twitter rapidly growing evolving, temporal factors influence model
generalisation? model trained old data perform comparably new test data?
perspective privacy protection, users tweeting behaviour affect
geolocatability, i.e., ability model predict location? steps user
take reduce risk inadvertently leaking geographical information sharing
tweets public?
measures prediction confidence formulated estimate accuracy geolocation prediction?
paper, focus predicting Twitter users primary (referred home) geolocation, following Cheng et al. (2010) others, assume given user based
single city-based location throughout time period study. approach geolocation prediction
text classification task. Tweets city taken represent class. tweets
given user aggregated assigned users primary location. characterise geolocation prediction four key components, discuss turn below: (1) representation
different geolocations, (2) model, (3) feature set, (4) data.
3.1 Representation: Earth Grid vs. City
Geolocations captured points, clustered based grid (Wing & Baldridge, 2011;
Roller et al., 2012), city centres (Cheng et al., 2010; Kinsella et al., 2011) topic regions (Eisenstein et al., 2010; Hong et al., 2012). point-based representation presents computational challenges, fine-grained standard classification methods. dynamic location partitioning, granularity regions hard control potentially vary across time,
number regions variable depend dataset potentially also vary across
time. Fixed grid-based representations hindered considerable variability
shape size geographical regions: coarse-grained grid cell perhaps appropriate central
Siberia, densely-populated linguistically/culturally diverse regions Luxembourg,
doesnt lead natural representation administrative, population-based language boundaries region. therefore opt city-based representation, able capture
boundaries intuitively. downside representation inappropriate classifying users rural areas. see Figure 1, however, bulk Twitter users are,
unsurprisingly, based cities.
Following Han et al. (2012b), use publicly-available Geonames dataset basis
city-level classes.2 dataset contains city-level metadata, including full city name, population, latitude longitude. city associated hierarchical regional information,
state country based in, London, GB, e.g., distinguished London, CA.
2. http://www.geonames.org, accessed October 25th, 2012.

458

fiT EXT-BASED WITTER U SER G EOLOCATION P REDICTION

hence use city-region-country format represent city (e.g., Toronto, CA represented
toronto-08-ca, 08 signifies province Ontario ca signifies Canada).3
region coding schemes vary across countries, employ first- second-level region
fields Geonames region. Furthermore, second-level field specific (i.e., longer
4 letters setting), incorporate first-level region field (e.g., instead using
melbourne-07-24600-au, use melbourne-07-au). Moreover, cities sometimes
complex structure (e.g., Boston, US colloquially refers metropolitan area rather
city, made cities including Boston, Revere Chelsea), collapse together cities
adjacent one another within single administrative region, follows:
1. Identify cities share region code (i.e., located state,
province, county, etc.) Geonames dataset.
2. region, find city c highest population.
3. Collapse cities within 50km c c.4
4. Select next-largest city c, repeat.
5. Remove cities population less 100K. remaining cities form citybased representation geolocations.
result methodology, Boston, US ends single city (incorporating Revere
Chelsea), neighbouring Manchester, US discrete city (incorporating Bedford)
New Hampshire. algorithm identifies total 3,709 collapsed cities throughout world.
3.2 Geolocation Prediction Models
Various machine learning algorithms applied task multi-class text categorisation.
However, many state-of-the-art learning algorithms appropriate particular task
reasons scalability. example, support vector machines (Vapnik, 1995) well suited
massively multi-class problems (i.e., 3,709 cities case). Finally, would ideally like
learning algorithm easily retrained, e.g., incorporate new training data
Twitter data stream. such, primarily experiment simple learning algorithms
ensemble learning geolocation prediction.
3.2.1 G ENERATIVE VS . ISCRIMINATIVE ODELS
Generative models (e.g., naive Bayes) based estimation joint probability observing
word vector class (i.e., P (w1 , w2 , . . . , wn , ci ), w1 , w2 , . . . words ci C
city combined set cities C). contrast, discriminative models based estimation
class given word vector (i.e., P (c|w1 , w2 , . . . , wn )). objective models find
3. Country code information found http://download.geonames.org/export/dump/countryInfo.txt
4. use great-circle distance (Vincenty, 1975) distance calculations experiments, opposed
Euclidean distance, properly capture three-dimensional surface earth. proximity cities varies
across world, e.g., cities east coast United States much closer major cities
Australia. therefore scope explore impact 50km setting city label set, leave
future work.

459

fiH , C OOK & BALDWIN

city cmax C relevant probability maximised. experiments, experiment
models. instance, choose state-of-the-art discriminative geolocation model based
KL divergence k-d tree partitioned unigrams (KL) (Roller et al., 2012). also adopt
generative multinomial naive Bayes (NB) model (Hecht et al., 2011) default benchmark,
two reasons: (1) incorporates class prior, allowing classify instance absence
features shared training data; (2) generative models outperform discriminative models
training data relatively scarce (Ng & Jordan, 2002).5
3.2.2 INGLE VS . E NSEMBLE ODELS
addition single model comparisons (e.g., discriminative KL vs. generative NB Sections 5
6), combine multiple base classifiers e.g., heterogeneous NB models trained
Twitter text user metadata improve accuracy. First, investigate
accuracies base classifiers correlations them. Then, apply different ensemble
learning strategies Section 9.
3.3 Feature Set
Predominantly, geolocations inferred based geographical references text, e.g., place
names, local topics dialectal words. However, references often buried noisy tweet
text, lexical variants (e.g., tmrw tomorrow) common words without geospatial dimension (e.g., weather, twitter) prevalent. noisy words potential mislead
model also slow processing speed. tackle issue, perform feature selection identify location indicative words. Rather engineering new features attempting
capture named entities (e.g., White House) higher-order n-grams, focus feature selection simple word unigrams (see Section 4). partly pragmatic consideration,
unigram tokenisation simpler.6 Partly, however, comparability past work, determining whether strategically-selected subset words lead significant gains prediction
accuracy (see Sections 5 6).
addition feature selection, feature set refined extended various
ways. instance, feature selection enhanced incorporating non-geotagged tweet data.
Furthermore, languages used shape feature set, words different languages
carry varying amounts geospatial information, e.g., Dutch primarily used
Netherlands, Dutch words usually location indicative English words. Moreover, userprovided metadata (e.g., location timezone) readily accessible tweet JSON objects.
metadata appended extra text features, addition features derived tweet text.
investigate impact factors later sections.

5. certainly abundance Twitter data train models over, number Twitter users sufficient amounts geotagged tweets able perform geolocation prediction small, relative number
parameters model (the product number features classes).
6. Also, preliminary results named entities higher order n-grams disappointing.

460

fiT EXT-BASED WITTER U SER G EOLOCATION P REDICTION

Proportion tweets
(relative preceding step)

Filtering criterion
Geotagged
Near city
Non-duplicate non-Foursquare
English

0.008
0.921
0.888
0.513

Table 1: Proportion tweets remaining filtering data based series cascaded criteria.
numbers based Twitter corpus collected two months.

3.4 Data
Geolocation prediction models primarily trained tested geotagged data.7 use
regional datasets (i.e., geotagged tweets collected continental US: Eisenstein et al.,
2010; Mahmud et al., 2012) global datasets (Kinsella et al., 2011; Han et al., 2012b)
research. accessibility issues (e.g., many tweets older datasets deleted
thus accessible now) data sparseness (e.g., 10K users study
Eisenstein et al., 2010), able experiment small number public datasets.
paper, employ three geotagged datasets:
1. regional North American geolocation dataset Roller et al. (2012) (NA hereafter),
benchmarking purposes. NA contains 500K users (38M tweets) total 378
pre-defined cities. NA used as-is ensure comparability previous work Section 5.
2. dataset global coverage constructed us earlier work (Han et al., 2012b) (WORLD
hereafter), collected via Twitter public Streaming API8 21 Sep, 2011 29 Feb,
2012. tweet collection shaped different evaluation tasks, e.g., geotagged
English data WORLD Section 6, incorporating non-geotagged English data WORLD+NG
Section 7, multilingual geotagged data WORLD+ML Section 8 rich metadata
WORLD+META Section 9.
3. second dataset global coverage novel research (LIVE), contains tweets
collected 1 year WORLD (from 3 Mar, 2013 3 May, 2013), analyse
influence temporal recency geolocation prediction. Unlike two datasets, LIVE
used test dataset, Section 10.
WORLD restricted English tweets order create dataset similar NA (in
English predominant language), covering entire world. pre-processed filtering data follows. First, non-geotagged tweets removed. Next, eliminated
tweets arent close city dividing earth 0.5 0.5 grid cells, discarding
tweet city Geonames class set found 8 neighbouring grid
cells. assign user single city majority tweets occur.
7. One exception Cheng et al. (2010), train users whose user-declared metadata location fields correspond canonical locations (e.g., Boston, MA), test users whose locations indicated GPS coordinates
metadata.
8. https://dev.twitter.com/docs/streaming-apis

461

fiCumulative distribution tweets

H , C OOK & BALDWIN

0.9

0.8

0.7

5%

15% 25% 35% 45% 55% 65% 75% 85% 95%
Top N% cities

1

1

number users
10 100 1000

number users
100
10000

Figure 1: Cumulative coverage tweets increasing numbers cities based 26 million geotagged tweets.

1

10
100
1000
10000
Number geotagged tweets

1
5
50
500
5000
Mean distance city centre (kilometres)

Figure 2: number users different numbers tweets, different mean distances
city center, WORLD.

remove cities fewer 50 feature types (i.e., word types) reduce data sparsity.
results 3135 cities WORLD (as opposed 3709 cities full Geonames class set).
eliminated exact duplicate tweets Foursquare check-ins (which encode user location
form Im . . . ). that, non-English tweets removed using langid.py,
open-source language identification tool (Lui & Baldwin, 2012). filtering summarised
Table 1 also shows proportion tweets remaining step. total number
users tweets WORLD 1.4M 12M, respectively. Similar NA, development
test datasets contain 10K users, remainder users used training. development test data sampled user least 10 geotagged tweets alleviate
data sparsity.9 tokenised tweets Twitter-specific tokeniser (adapted OConnor,
Krieger, & Ahn, 2010).
Although certainly instances social media users high mobility (Li, Wang, &
Chang, 2012), recent studies shown users tend tweet within limited region
(Cho, Myers, & Leskovec, 2011; Hecht et al., 2011). also analyse spread WORLD
9. restriction applied training data.

462

fiT EXT-BASED WITTER U SER G EOLOCATION P REDICTION

Figure 2, terms of: (1) number users least 10 geotagged tweets; (2) number
users differing levels geographical spread tweets, measured average distance
users tweets centre city user allocated.10
preliminary analysis shows users relatively small number geotagged tweets,
users stay near single city (e.g., 83% users geographical spread 50 kilometres
less). high proportion users average distance 1km city centre artefact
geotagged tweets mapped city centre performing analysis. order
investigate coverage proposed city-based partition, examine recall original
sample 26 million geotagged tweets (prior filtering, described above). analysis reveals
92.1% tweets close (in neighbouring 0.5 0.5 grid cell) one pre-defined
cities, top 40% cities contain 90% geotagged tweets filtering, shown
Figure 1. supports assumption (geotagged) Twitter users based cities.
3.5 Evaluation Measures
formulated geolocation prediction task discrete class space use
city class set, possible use simple classification accuracy evaluate models. However,
given class labels location (in form latitudelongitude coordinates),
also sensitise evaluation distance-based predictive error. instance, correct
location user Seattle, US, prediction Portland, US arguably better prediction
Los Angeles, US, basis geospatial proximity. use number evaluation measures
capture spatial proximity, line previous work (Wing & Baldridge, 2011; Roller et al.,
2012):11
1. Acc: city-level accuracy, i.e., proportion predictions correspond correct city;
2. Acc@161: proportion predictions within distance 161 kilometres (100
miles) correct city-level location. empirical measure (Cheng et al., 2010)
relaxed version Acc, capturing near-miss predictions.
3. Acc@C: country-level accuracy, i.e., proportion predicted locations
country corresponding true locations. measure useful applications relying
country-specific Twitter data, e.g., sentiment analysis specific countries.
4. Median: median prediction error, measured kilometres predicted city centres
true geolocations. prefer use median, opposed mean, distance
median less sensitive wildly incorrect predictions e.g., user London, GB
classified based Sydney, AU. contrast, mean distance increase substantially due small number extreme misclassifications, although effect limited
inherently-bounded regional datasets NA.
10. geographical spread calculated random sub-sample 10 tweets given user, efficiency reasons.
11. recent work, Priedhorsky, Culotta, Valle (2014) additionally proposed set probabilistic metrics
evaluate tweet-based geolocation prediction, including using expected distance tweets true point
location random point location drawn probability distribution geolocation model.
strongly support new direction geolocation modelling evaluation, depending application context,
argue point- region-based representations related discrete evaluation measures equally important
user geolocation research.

463

fiH , C OOK & BALDWIN

4. Finding Location Indicative Words
Precise user locations individual messages embedded geotagged tweets form
latitudelongitude coordinates. mapping coordinates cities representing tweet
bag words, able make connections words (i.e., features) cities (i.e.,
classes). section, present range methods ranking words location
indicativeness, i.e., degree word associated particular cities. Words either
explicitly (e.g., place names) implicitly (e.g., dialectal words, slang local references) encode
geographical information collectively referred location indicative words (LIWs);
words aim automatically identify. Examples LIWs are:
1. local words (1-local) used primarily single city, namely yinz (used Pittsburgh
refer second-person plural pronoun), dippy (used Pittsburgh refer style fried
egg, something dipped coffee) hoagie (used primarily Philadelphia,
refer kind sandwich);12
2. semi-local words (n-local) refer feature relatively limited subset cities,
namely ferry (found, e.g., Seattle, New York Sydney), Chinatown (common many
largest cities US, Canada Australia, much less common European
Asian cities), tram (found, e.g., Vienna, Melbourne Prague)
addition LIWs common words (common) arent expected substantial
regional frequency variation, namely twitter, iphone today.
remainder section, present various feature selection methods identifying
LIWs, drawn work Han et al. (2012b), Chang et al. (2012) Laere et al. (2013).
feature selection methods broadly categorised three types: (1) statistical; (2) informationtheoretic; (3) heuristic. reduce low-utility words noise, feature selection methods,
remove words include non-alphabetic letters, less 3 letters long,
word frequency < 10.
4.1 Statistical-Based Methods
Statistical hypothesis testing often used determine whether event occurs chance (i.e.,
null hypothesis) (i.e., alternative hypothesis) particular confidence level (e.g., 95%
p < 0.05). case, event defined co-occurrence word city,
null hypothesis assumes co-occurrence chance, i.e., word city independent.
goal feature selection find wordcity pairs null hypothesis rejected.
4.1.1 2



L OG -L IKELIHOOD

2 statistic commonly used examine degree independence random variables. contingency table representing observations variables formed, Table 2.
general form statistic is:
n

(Oi Ei )2


Ei

12. words identified aid datasets regional words DARE: http://dare.wisc.edu/.

464

fiT EXT-BASED WITTER U SER G EOLOCATION P REDICTION

c
Ow,c
Ow,c

w
non-w word

c
Ow,c
Ow,c

Table 2: Contingency table word city co-occurrence
Oi represents observation (i.e., co-occurrence city (c) word (w)), n
number cells table. Ow,c Ow,c denote occurrence word w city c non-w
words cities c, respectively. Ew,c denotes expected frequency w c, calculated
marginal probabilities total counts N :
Ow,c + Ow,c Ow,c + Ow,c

N
N
N
= Ow,c + Ow,c + Ow,c + Ow,c

Ew,c = P (w) P (c) N =
N

2 statistic larger number 2 distribution, respect degrees
freedom (in case, 1), null hypothesis city c word w independent rejected.
many statistical tests, 2 ineffective counts low. address
word frequency thresholding use massive amounts training data.
Conventionally, 2 used identify set features satisfies pre-defined confidence
level (e.g., p < 0.05). However, case LIW selection, instead use 2 statistic rank
wordcity pairs. selection LIWs deferred parameter tuning state,
boundary LIWs common words optimised using development data.
point, different ranking LIWs produced per city, desire global
ranking LIWs capturing ability discriminate cities combined label set.
various ways aggregation. suggested Laere et al. (2013), one approach
selecting n features based 2 iteratively aggregate top-m features city
n features obtained. Alternatively, ranked based highest-scoring occurrence
given word city, first sorting cityword 2 test pairs, selecting first
occurrence word type aggregated ranking. two aggregation approaches produce
different feature selection rankings, distinguished using Chi MaxChi , respectively.13
Similar 2 test, log-likelihood ratio (Loglike: Dunning, 1993) also applied
LIW selection (Laere et al., 2013). Loglike test determines whether h0 (the null hypothesis,
i.e., word independent city) likely h1 (the alternative hypothesis, i.e.,
word dependent city). Following Dunning, likelihood hypothesis, L(), estimated
using binomial distributions.
( )
( )
k1
k2
n1 k1 n1
n2 k2 n2
L(h1 ) = p1 (1 p1 )
p (1 p2 )
k1 2
k2
p1 = P (w|c) =

Ow,c
k1
=
n1
Ow,c + Ow,c

13. One possible alternative computing 2 word city, aggregating values final
ranking words, would compute single 2 value word contingency table 2 rows
Table 2, one column per city. Nevertheless, standard use 2 feature selection,
leave possibility future work.

465

fiH , C OOK & BALDWIN

Ow,c
k2
=
n2
Ow,c + Ow,c
k1 (k2 ) represents occurrences word w city c (not city c), n1 (n2 ) represents word
occurrences city c (not city c). L(h0 ) special case L(h1 ) p1 p2 equal,
below:
p2 = P (w|c) =

Ow,c + Ow,c
N
Loglike test statistic expanded using observations:
p1 = p2 = p =

Loglike(w) = 2[Ow,c log Ow,c + Ow,c log Ow,c + Ow,c log Ow,c + Ow,c log Ow,c + N log N
(Ow,c + Ow,c ) log(Ow,c + Ow,c ) (Ow,c + Ow,c ) log(Ow,c + Ow,c )
(Ow,c + Ow,c ) log(Ow,c + Ow,c ) (Ow,c + Ow,c ) log(Ow,c + Ow,c )]
calculated Loglike wordcity pair, aggregate across cities similarly
Chi (by selecting top-m features per city n features obtained), following Laere et al.
(2013).14
4.1.2 R IPLEY K TATISTIC
Spatial information also incorporated hypothesis testing. example, Ripley K
function (Ripley: OSullivan & Unwin, 2010) measures whether given set points generated
homogeneous Poisson distribution. test statistic calculates number point pairs
within given distance square total number points. regards LIW
selection, set points (Qw ) subset geotagged users using particular word w. test
statistic formulated follows (Laere, Quinn, Schockaert, & Dhoedt, 2014):
K() =

|{p, q Qw : distance(p, q) }|
|Qw |2

represents total area consideration (e.g., whole North America,
whole globe); dropped generating ranking.
larger value K() indicates greater geographical compactness set Qw (i.e., p q
spatially close). However, |Qw | (i.e., number users use word w) varies considerably
across words, dominate overall statistic. number variations proposed
alleviate effect, including replacing denominator factor based L1, taking
logarithm overall value (Laere et al., 2014). quadratic computational complexity
Ripley becomes issue |Qw | large (i.e., common words). Randomised methods
usually adopted tackle issue, e.g., subsampling points training data Ripley calculation relative different distances . experiments, adopt optimised implementation
Laere et al. using = 100km 5K samples.
4.2 Information Theory-Based Methods
addition statistical methods, also experiment information-theoretic feature selection
methods based measures shown effective text classification tasks, e.g.,
Information Gain (IG) (Yang & Pedersen, 1997).
14. Note also that, see later experiments, almost empirical difference two
aggregation methods 2 , choice aggregation method largely arbitrary.

466

fiT EXT-BASED WITTER U SER G EOLOCATION P REDICTION

4.2.1 NFORMATION G G R ATIO
Information Gain (IG) measures decrease class entropy word brings about, higher
values indicate greater predictability basis feature. Given set words w, IG
word w w across cities (c) calculated follows:
IG(w) = H(c) H(c|w)
H(c|w)


P (w)
P (c|w)logP (c|w) + P (w)
P (c|w)logP (c|w)
cc

cc

P (w) P (w) represent probabilities presence absence word w, respectively. H(c) words, H(c|w) conditional entropy given w
needs calculated rank features.
Words carry varying amounts intrinsic entropy, defined as:
IV (w) = P (w)logP (w) P (w)logP (w)
Local words occurring small number cities often low intrinsic entropy, nonlocal common words high intrinsic entropy (akin inverse city frequency; see Section 4.3.1).
words comparable IG values, words smaller intrinsic entropies preferred.
Therefore, following Quinlan (1993) normalise IG(w) using intrinsic entropy
word w, IV (w), culminating information gain ratio (IGR):
IGR(w) =

IG(w)
IV (w)

4.2.2 L OGISTIC R EGRESSION -BASED F EATURE W EIGHTS
previous two information-theoretic feature selection methods (IG IGR) optimise across
classes simultaneously. Given LIWs may strongly associated certain locations,
less tied locations, also conduct per-class feature selection based logistic
regression (LR) modelling.15 consider method information theoretic
maximisation entropy cases uncertainty training data.
Given collection cities c, LR model calculates probability user (e.g., represented
word sequence: w1 , w2 , . . . , wn ) assigned city c c linearly combining eligible LR
feature weights:
P (c|w1 , w2 , . . . , wn ) =



1
exp(
k fk )
Z
k=1

Z normalisation factor, total number features, fk k features
feature weights, respectively. discriminative models, possible incorporate
arbitrary features LR, however, feature (function) task canonically defined word
wi city c: w occurs set messages users class c, feature fk (wi , c)
15. logistic regression modeller, use toolkit Zhang Le (https://github.com/lzhang10/maxent),
30 iterations L-BFGS (Nocedal, 1980) training data.

467

fiH , C OOK & BALDWIN

denoted [class = c wi c]. fk maps feature weight denoted k R. method
results per-city word ranking words ranked decreasing order k ,
derive combined feature ranking manner MaxChi , following Han et al. (2012b).16
Notably, incorporating regularisation factor balances model fitness complexity, could
potentially achieve better results. dont explicitly perform regularisation modelling stage.
Instead, first obtain feature list ranked LR feature selection methods
evaluate subset top-n ranked features development data. fact equivalent
filter-based regularisation (cf. filter-based feature selection: Guyon & Elisseeff, 2003),
leave experimentation regularisation integrated models future work.
4.2.3 ISTRIBUTION IFFERENCE
LIW selection likened finding words maximally dissimilar stop words (Chang
et al., 2012). Stop words like today widely used across many cities, thus exhibit
relatively flat distribution. contrast, LIWs predominantly used particular areas,
skewed distribution. capture intuition, LIW selection based
distribution difference across cities stop words potential LIW candidates (i.e.,
non-stop words). Given pre-defined set stop words S, distribution difference calculated
as:
DistDi (wns ) =



Di (wns , ws )

ws

Count(ws )
Count(S)

Count(ws ) Count(S) denote number occurrences stop word ws total
number occurrences stop words, respectively. difference (i.e., Di (wns , ws ))
stop word ws non-stop word wns evaluated various ways, e.g., symmetric KLdivergence (DistDiskl ), total variance (DistDitv ) absolute probability difference across
cities c (Chang et al., 2012):
Diskl (wns , ws ) =



P (c|wns ) log

cc

Ditv (wns , ws ) =



P (c|ws )
P (c|wns )
+ P (c|ws ) log
P (c|ws )
P (c|wns )

|P (c|wns ) P (c|ws )|

cc

P (c|wns ) P (c|ws ) denote probability word occurring city per-word
city distribution wns ws , respectively. non-stop words sorted distribution
difference decreasing order. experiments, use implementation Chang et al..
4.3 Heuristic-Based Methods
commonly-used feature selection methods, number heuristics used select
LIWs.
4.3.1 ECOUPLING C ITY F REQUENCY W ORD F REQUENCY
High-utility LIWs following properties:
16. LogLike, choice aggregation method largely arbitrary, based empirical results 2 .

468

fiT EXT-BASED WITTER U SER G EOLOCATION P REDICTION

1. High Term Frequency (TF ): reasonable expectation observing
users tweets city.
2. High Inverse City Frequency (ICF ): word occur tweets associated relatively small number cities.
calculate ICF word w simply as:
icf w =

|c|
cf w

c set cities cf w number cities users use w training data.
Combining two together, seeking words high TF -ICF , analogous seeking words
high TF -IDF values information retrieval. standard TF -IDF formulations, multiply
TF IDF . simple product TF ICF tends dominated TF component,
however: example, twitter scores highly Jakarta, twitter high TF .
resolve decoupling two factors applying radix sort ranking: first rank features
ICF TF , decreasing order. approach largely based inverse city
frequency, denote ICF below.
4.3.2 G EOGRAPHICAL PREAD ENSITY
LIWs peaky geographical distributions (Cheng et al., 2010). section, discuss two
heuristic measures LIW selection based geographical distribution word.
Geographical spread (GeoSpread : Laere et al., 2013) estimates flatness words distribution cities. First, earth divided 1 latitude 1 longitude cells. word
w, cells w occurs stored. Then, neighbouring cells containing w merged
multi-pass scanning cells merged. number cells containing w
merging stored. Finally, GeoSpread score word w calculated follows:
GeoSpread (w) =

# cells containing w merging
Max (w)

Max (w) represents maximum frequency w original unmerged cells.
Smaller values indicate greater location indicativeness. measure originally used rank
Flickr tags locality, e.g., London location-indicative beautiful. ignores influence stop words, common Flickr tags. However, stop words like
frequent Twitter, occur many locations, making numerator small denominator
large. Furthermore, stop word frequencies cells usually high. Consequently, similarly small GeoSpread London, undesirable. words, GeoSpread flawed
able distinguish stop words local words, although effective ranking
less common words (e.g., London vs. beautiful).
Geographical density (GeoDen: Chang et al., 2012) strategically selects peaky words occurring
dense areas. Given subset cities c c word w w used, GeoDen calculated
469

fiH , C OOK & BALDWIN

as:




cc

GeoDen(w) =
|c |2
|c |

cj ,ck c j=k dist(cj ,ck )
|c |(|c |1)





=

P (c|w)

cc

P (c|w)

cj ,ck c j=k dist(cj ,ck )
|c |1

dist(cj , ck ) great-circle distance cities cj ck . Similarly, P (c|w) denotes
distribution word w across city c c . denominator made square
number cities |c | w occurs (which similar effect ICF above),
average distance cities w used. LIWs generally skewed geographical
distribution small number locations, meaning denominator small numerator
large. issue measure computational complexity common words occur
many cities. Furthermore, cities containing small number occurrences w
incorporated, avoid systematic noise, e.g., travellers posting trip. One approach
counter issues set minimum P (c|w) threshold cities, perform randomised
sampling c . paper, follow Chang et al. constructing final c : first, cities
containing w ranked P (c|w) decreasing order, c formed adding cities according
rank, stopping sum P (c|w) exceeds pre-defined threshold r. choose r = 0.1
experiments, based findings Chang et al..

5. Benchmarking Experiments NA
section, compare discuss proposed feature selection methods. particular,
investigate whether using LIWs geolocation prediction better using full
set features, various configurations models location partitions Section 5.2.
subsequent experiments section exclusively based public NA dataset. adopt
user partitions training, dev test used original paper (Roller et al., 2012).
primarily use city-based class representation experiments NA, additionally
present results using original k-d tree partitions learned Roller et al. Section 5.2, direct
comparability published results. distance-based evaluation measures (Acc@161
Median), calculate users location based centroid tweets, and, depending
class representation used, represent predicted location either: (a) city centre; (b)
user-centroid given k-d tree cell. case Acc city-based class representation,
map centroid user nearest city centre 50km away, use basis
Acc calculation. case city centre satisfies constraint,17 map
user NULL class, always misclassify user.18
5.1 Comparison Feature Selection Methods
First, compare effectiveness various feature selection methods NA using citybased class representation. total, 214K features extracted training section NA.
17. occurs 1139 ( 11.4%) test users.
18. such, upper bound Acc city-based representation 0.886. Note also Acc k-d tree vs.
city-based representation comparable, different class structure granularity.

470

fiT EXT-BASED WITTER U SER G EOLOCATION P REDICTION

0.4

Acc161

0.3

0.2
ICF
GeoDen
Ripley
IGR
Loglike
Chi

0.1

0.0
2% 8%

16%

24%

32%

40%

48%

56%

64%

72%

80%

88%

96%

Top N% Features

Figure 3: Acc@161 varying levels feature selection NA dataset, based citybased class representation.

select top-n% features, step size 2%, use selected features within
multinomial naive Bayes learner (we return explore choice learner Section 5.2).
tuning n methods based Acc@161 10K held-out users development
data. present results sample feature selection methods Figure 3, omitting methods
largely identical behaviour methods presented graph, namely:
{DistDitv , DistDiskl } ICF
MaxChi Chi
{LR, IG, GeoSpread } LogLike
methods, best result achieved proper subset features based feature
selection, although proportion features gives best results given method
varies greatly (e.g., optima Ripley, IGR GeoDen 10%, 88% 66%, respectively).
observation agrees expectations that: (1) small number features
used, trained model generally underfits data; (2) model trained using full
feature set, noisy words (e.g., the) cause overfitting. instance, using top 2%
features IGR, likely class users features noting users feature
representation default majority class, namely Los Angeles, US-CA Monterrey, MX,
Spanish words highly location-indicative small number Mexican cities
NA dataset. features selected last generally high-frequency function words (e.g.,
the) common words (e.g., facebook), give little indication geolocation, lead
prediction errors.
Two patterns observed results: (1) Chi , MaxChi , IG, LogLike, GeoSpread , LR
Ripley (i.e., local methods, initially select features class, exception
471

fiH , C OOK & BALDWIN

IG Ripley) achieve highest Acc@161 early stage, numbers drop gradually; (2) ICF , IGR, DistDiskl , DistDitv GeoDen (i.e., collective group,
select features classes once) gradually increase accuracy features added,
reach peak majority features selected, drop accuracy sharply.
difference behaviour attributed types word preferred methods.
local methods tend prefer 1-local words taking LR, example, city names (e.g.,
philadelphia) names upper-level administrative regions (e.g., georgia) frequently occur
upper reaches ranking. addition gazetted words, many local/regional words
also found upper reaches feature ranking, including informal place names (e.g., philly,
informal name Philadelphia, US-PA), local transport references (e.g., skytrain, public transport system Vancouver, CA) local greetings (e.g., aloha Honolulu, US-HI). However,
reasonable believe 1-local words words predominantly used one city
rarely mentioned cities common. result, accuracy bounded
limited number true 1-local words. could reason early, yet remarkably
high, peak accuracy, subsequent sharp decline, Ripley; reliance pairwise
distances users using given word, Ripley tends rank 1-local words highly. contrast,
collective methods assume words carry varying amounts geospatial information. leveraging combinations LIWs, true location user collectively inferred. instance,
brunswick common suburb/street name many cities, e.g., Melbourne, AU London, GB.
word alone insufficient make reliable predictions. However, LIWs (e.g., tram
Flinders, uniquely disambiguating themselves) also observed,
chance location Melbourne, AU becomes high, since unlikely users
cities Melbourne, AU would use combination words. strategy also
explained information-theoretic terms: knowing words, extra information obtained,
consequently entropy continuously reduced prediction geolocation becomes
certain.
Among feature selection methods, IGR, GeoDen Ripley stand-out methods
terms Acc@161. compare accuracy classifiers trained using optimised
set LIWs (based development data) full model. performance measured
10K held-out test users, using city-based class representation. results displayed
Table 3 (for subset feature selection methods displayed Figure 3),
show using LIWs offers improvement full feature set evaluation measures
feature selection methods, except slight dips Acc@C IGR GeoDen. Nevertheless, numbers clearly demonstrate feature selection improve text-based geolocation
prediction accuracy. IGR performs best terms accuracy, achieving 8.9% 14.2% absolute
improvements Acc Acc@161, respectively, full feature set.
5.2 Comparison Benchmarks
compare best-performing method Section 5.1 number benchmarks
baselines. experiment two class representations: (1) city-based class representation based Geonames; (2) k-d tree based partitioning Roller et al. (2012),
creates grid cells containing roughly even amounts data differing geographical sizes,
higher-population areas represented finer-grained grids.19 class representations,
19. Recent work (Schulz et al., 2013) also considers irregular-sized polygons, based administrative regions like cities.

472

fiT EXT-BASED WITTER U SER G EOLOCATION P REDICTION

Dataset

Features

Acc

Acc@161

Acc@C

Median

NA

Full
ICF
Chi
IGR
LogLike
GeoDen
Ripley

0.171
0.209
0.233
0.260
0.191
0.258
0.236

0.308
0.359
0.402
0.450
0.343
0.445
0.432

0.831
0.840
0.850
0.811
0.836
0.791
0.849

571
533
385
260
489
282
306

Table 3: Results full feature set compared representative sample
feature selection methodologies NA city-based class representation. best
numbers shown boldface.

compare learners without feature selection. observed previously, Acc comparable across two class representations. Results based distance-based measures (Acc@161
Median), hand, directly comparable. Acc@C results presented kd tree based class representation k-d tree cells map cleanly onto national borders;
although could certainly take country centroid given k-d tree cell lies
country label entire cell, approach would ignore known geo-political boundaries.
consider following methods:
Baseline: geographical distribution tweets skewed towards higher-population
areas (as indicated Figure 1), consider most-frequent class baseline. assign
users coordinates most-common city centre (or k-d tree grid centroid)
training data.
Placemaker: Following Kinsella et al. (2011), obtain results Yahoo! Placemaker,20
publicly-available geolocation service. first 50K bytes (the maximum query length allowed Placemaker) tweets user passed Placemaker queries.
returned city centre predictions mapped collapsed city representations.
queries without results, predicted location outside North America, back
most-frequent class baseline.21
Multinomial naive Bayes: model used Section 5.1.
KL divergence: previous best results NA achieved using KL divergence k-d
tree grid (Roller et al., 2012). Using k-d tree, earths surface partitioned nearrectangular polygons vary size, contain approximately number users.
Locations represented cells grid. KL divergence utilised measure
similarity distribution words users aggregated tweets grid
cell, predicted location centroid most-similar grid cell.22
20. http://developer.yahoo.com/geo/placemaker/, accessed August 2012.
21. alternative would query Placemaker tweet, aggregate predictions (e.g., selecting
majority location) get final user-level prediction. However, Kinsella et al. (2011) found accuracy
approach largely similar approach use.
22. use settings Roller et al. (2012): median-based k-d tree partition, partition containing
approximately 1050 users.

473

fiH , C OOK & BALDWIN

Partition

Method

City

Baseline
Placemaker
NB
NB+IGR
LR
LR+IGR

Acc

Acc@161

Acc@C

Median

0.003
0.049
0.171
0.260
0.129
0.229

0.062
0.150
0.308
0.450
0.232
0.406

0.947
0.525
0.831
0.811
0.756
0.842

3089
1857
571
260
878
369

Table 4: Geolocation performance using city-based partition NA. Results using optimised
feature set (+IGR) also shown. best-performing method evaluation measure class representation shown boldface.

Partition

Method

k-d tree

Baseline
NB
NB+IGR
KL
KL+IGR

Acc

Acc@161

Acc@C

Median

0.003
0.122
0.153
0.117
0.161

0.118
0.367
0.432
0.344
0.437







1189
404
280
469
273

Table 5: Geolocation performance using k-d tree-based partition NA. Results using optimised feature set (+IGR) also shown. best-performing method evaluation
measure class representation shown boldface.

Logistic regression: also apply logistic regression Section 4.2.2 learner. Instead
modelling data, use IGR-selected features Section 5.1. regularisation commonly employed logistic regression learners, made conscious choice
use experiments implementation regulariser would differ across
learners complicate direct comparison feature selection methods (i.e. would
difficult tease apart impact specific regulariser feature selection). said that, objective maximise raw classifier accuracy distinct
exploring impact different features feature selection methods classification accuracy would advocate incorporation regulariser.
Instead evaluating every possible combination model, partition feature set, choose
representative combinations test extent LIWs improve accuracy. results
city-based partition shown Table 4. begin considering baseline results. mostfrequent class city-based representation Los Angeles, US-CA.23 majority class
baseline Placemaker perform well multinomial naive Bayes (NB) logistic regression
(LR), high Median distances. Furthermore, using features selected Section 5.1 (i.e., NB+IGR LR+IGR), performance improved large margin
models, demonstrating identification LIWs improve text-based geolocation prediction. Finally, although LR performs poorly compared NB, LR+IGR still improves substantially
23. New York divided suburbs, manhattan-ny061-us, brooklyn-ny047-us, Geonames.
artefact this, suburbs merged single city.

474

fiT EXT-BASED WITTER U SER G EOLOCATION P REDICTION

LR. plan explore reasons LRs poor performance future work. Overall,
NB+IGR performs best city-based representation terms Acc, Acc@161, Median
distance.
Turning k-d tree-based partition Table 5, observe low performance
most-frequent class baseline (i.e., grid cell near New York state). NB KL representative
generative discriminative models, respectively evaluated using software provided
Roller et al. (2012).24 approaches clearly outperform baseline k-d tree class
representation. Furthermore, performance increases using resultant feature set
LIWs,25 demonstrating variety approaches, identification LIWs improve textbased geolocation.
Overall, compared previously-published results k-d tree based representation (KL),
IGR-based feature selection city-based partition achieves 10.6% absolute improvement
terms Acc@161, reduces Median prediction error 209km.
results k-d tree based representation, clear KL NB better
task: terms Acc@161, NB outperforms KL, KL+IGR outperforms NB+IGR.
differences small, however, suggesting two methods largely indistinguishable
user geolocation task. question class representation used user geolocation, empirically, seems little separate two, although experimentation
may shed light issue. city-based approach intuitive, enables convenient
country-level mapping coarser-grained geolocation tasks. Furthermore, observation
Figure 1 suggests Twitter users cities. therefore use city-based partition
remainder paper consistency ease interpretation.
spin-off benefit feature selection leads compact models,
efficient terms computational processing memory. Comparing model based LIWs
selected using IGR full model, find prediction time faster factor
roughly five.

6. Experiments WORLD
addition establishing comparisons NA, evaluate feature selection methods
WORLD. extends evaluation regional benchmarks global geolocation performance. Similar NA, WORLD reserve 10K random users dev test,
remainder users used training (preprocessed described Section 3.4).
experiments WORLD related datasets, base evaluation city label set.
apply tuning procedure used NA obtain optimal feature set
feature selection method. present results representative sample best-performing
methods Figure 4. again, omit methods largely identical behaviour
methods, namely:
{DistDitv , DistDiskl } ICF
{MaxChi , Chi , LogLike, IG, GeoSpread } LR
24. https://github.com/utcompling/textgrounder/wiki/RollerEtAl_EMNLP2012
25. Note LIWs selected, small proportion users end features. users geolocatable
case KL, discriminative model. turn feature selection users, backoff full feature
set, number test instances consistent rows.

475

fiH , C OOK & BALDWIN

0.25

Acc161

0.20
0.15
0.10
ICF
GeoDen
Ripley
IGR
LR

0.05
0.00
2% 8%

16%

24%

32%

40%

48%

56%

64%

72%

80%

88%

96%

Top N% Features

Figure 4: Acc@161 varying percentages features selected using representative feature selection methods WORLD dataset.

biggest differences Figure 3 are: (1) 2 -based methods converge behaviour
LR, LogLike related methods; (2) LR performs marginally better LogLike,
thus method present graph.
Despite difference scope data size, overall trend WORLD mirrors
NA. particular, GeoDen, IGR Ripley achieve best Acc@161 numbers dev data,
although numbers lower achieved NA Figure 3. WORLD
fewer tweets per user NA (as utilise geo-tagged data), disambiguation
global level also makes challenging task.
results multinomial naive Bayes chosen feature selection methods WORLD
shown Table 6. GeoDen (62%), IGR (86%) Ripley (20%) achieve best
accuracy, although clear winner: IGR achieves best Acc Ripley achieves
best Acc@161. Nevertheless, improved city-based Acc Acc@161 numbers confirm
general effectiveness feature selection. basis similar results earlier NA
results (in IGR delivers better results), adopt IGR default LIW feature selection
method remainder paper.
summary, findings utility feature selection Table 3 (NA) Table 6 (WORLD)
tell similar story, namely feature selection improves user geolocation accuracy. impact
feature selection NA much greater WORLD, WORLD larger number
classes smaller average number tweets per user also per class, making
challenging dataset.
476

fiT EXT-BASED WITTER U SER G EOLOCATION P REDICTION

Dataset

Features

Acc

Acc@161

Acc@C

Median

WORLD

Full
ICF
IGR
LR
GeoDen
Ripley

0.081
0.110
0.126
0.104
0.123
0.121

0.200
0.241
0.262
0.233
0.266
0.268

0.807
0.788
0.684
0.792
0.691
0.582

886
837
913
640
842
1128

Table 6: Results full feature set compared representative sample feature
selection methodologies WORLD using NB. best numbers shown boldface.

Train
G
G+NG
G
G+NG

Test
G
G
G+NG
G+NG

Acc
0.126
0.170
0.187
0.280

Acc@161
0.262
0.323
0.366
0.492

Acc@C
0.684
0.733
0.835
0.878

Median
913
615
398
170

G
G+NG

NG
NG

0.161
0.241

0.331
0.440

0.790
0.826

516
272

G
G

G-small
NG-small

0.121
0.114

0.258
0.248

0.675
0.666

960
1057

Table 7: results geolocation models trained tested geotagged (G) non-geotagged
(NG) tweets, combination.

7. Exploiting Non-geotagged Tweets
Twitter-based geolocation research carried date (Eisenstein et al., 2010; Wing & Baldridge, 2011) trained geotagged tweets, tweets known geographical
coordinates. work (Roller et al., 2012) also incorporated non-geotagged tweets
users whose location inferred geotagged tweets. Clearly, possible effectively
utilise non-geotagged tweets, data sparsity ameliorated (as arent restricting
training approximately 1% tweets known location), clear tradeoff
confidence place labels associated tweets/users. section,
investigate utility non-geotagged tweets geolocation prediction.
experiments section, rest paper, use WORLD+NG denote
dataset incorporates geotagged non-geotagged tweets users
WORLD. refer subparts dataset consisting geotagged non-geotagged tweets
G NG, respectively. 194M tweets WORLD+NG, 12M geotagged remaining 182M non-geotagged. use partitioning users training, development,
testing sets WORLD+NG WORLD. compare relative impact NG
train test geolocation method G, NG, combination. Results presented
Table 7.
first row Table 7 shows results using geotagged data (our best result Table
6). rows two three, show results data user training test
477

fiH , C OOK & BALDWIN

datasets, respectively, expanded incorporate non-geotagged data (without changing set
users label user either case). cases, evaluation measures,
performance substantially better benchmark (i.e., first row). finding line
Cheng et al.s (2010) results data spareness big issue text-based geolocation. also
validates hypothesis non-geotagged tweets indicative location. best results
achieved non-geotagged tweets incorporated training testing data (shown
row four). case achieve accuracy 28.0%, 15.4 percentage point increase
benchmark using geotagged tweets represent given user. Moreover, prediction
within 161km correct location almost one every two users, country-level
accuracy reaches almost 88%.26
Although research text-based geolocation used geotagged data evaluation, ultimate goal line research able reliably predict locations users
location known, i.e., non-geotagged data. geotagged tweets
typically sent via GPS-enabled devices smartphones, non-geotagged tweets sent
wider range devices, could systematic differences content geotagged
non-geotagged tweets. examine issue rows five six Table 7, test
model non-geotagged data. case know test users gold-standard location
based geotagged tweets. However geotagged tweets used represent user
test instance; instead, user represented non-geotagged tweets. results
actually better experiments training data tested geotagged
tweets (i.e., rows one two table).27 confirms model trained G G+NG
indeed generalises NG data. However, clear whether finding due
much non-geotagged geotagged data given user, whether property
non-geotagged data makes easier classify. explore question, carry following additional experiment. First, construct new dataset NG-small down-sampling NG
contain number features per user G (in terms feature token count). make
comparison fairer, constructed second new dataset G-small exclude
test users G tweets NG tweets. guarantees users NG-small contain
number LIWs G-small. average five iterations random subsampling,
list result final row Table 7.28 see results NG-small
good G-small (i.e., row seven), suggesting might minor sub-domain differences
geotagged non-geotagged tweets, though strong conclusion cannot drawn without
in-depth analysis. One possible explanation could differences (e.g., demographic variations) users non-geotagged tweets users
non-geotagged tweets geotagged tweets; however, comparing two sources beyond
scope paper. Nonetheless, results suggest difference NG G largely due
abundant data NG. explanation also supported recent work Priedhorsky
et al. (2014).

26. Note evaluation exactly set users four cases; changes whether
incorporate extra tweets pre-existing set users, training test data.
27. remove users geotagged tweets test data, reducing number users marginally
10,000 9,767.
28. Note calculated variance five iterations random subsampling, found negligible
evaluation measures.

478

fiT EXT-BASED WITTER U SER G EOLOCATION P REDICTION

summary, quantitatively demonstrated impact non-geotagged tweets geolocation prediction, verified models trained geotagged data indeed applicable
non-geotagged data, even though minor sub-domain differences appear exist. also established representing user combination geotagged non-geotagged tweets
produces best results.

8. Language Influence Geolocation Prediction
Previous research text-based geolocation primarily focused English data. studies
either explicitly excluded non-English data, based datasets consisting primarily English messages, e.g., selection tweets predominantly English-speaking
regions (Eisenstein et al., 2010; Cheng et al., 2010; Wing & Baldridge, 2011; Roller et al., 2012).
However, Twitter multilingual medium languages might powerful indicators
location: example, user posts mostly Japanese tweets, could strong indication
user based Japan, could used bias class priors user. section,
explore influence language geolocation prediction. predominant language
given tweet identified using langid.py,29 trained recognise 97 languages
(Lui & Baldwin, 2012).
create dataset consisting multilingual geotagged tweets, extract geotagged data
regardless language Twitter crawl WORLD based on. multilingual dataset consists 23M tweets 2.1M users. 12M tweets English WORLD,
remaining 11M tweets languages. Figure 5 shows proportion tweets
fifteen common languages dataset.30 immediate observation large difference language distribution observe geo-tagged tweets compared
observed tweets (irrespective geotag: Hong, Convertino, & Chi, 2011; Baldwin, Cook,
Lui, MacKinlay, & Wang, 2013): among higher-density languages Twitter, appears
weak positive bias towards English users geotagging tweets, strong negative bias
Japanese, Korean German users geotagging tweets. speculate
negative bias caused stronger concerns/awareness privacy issues countries Japan,
South Korea, Germany Austria. explored question whether bias influenced
choice Twitter client looking distribution Twitter clients used post messages
English, German, Japanese Korean: (a) overall (irrespective whether message
geotagged not), based 1M sample tweets 28 Sep, 2011; (b) geotagged
tweets, based WORLD. Overall, found huge variety choice client used
within given language (with top-10 clients accounting 6578% posts, depending
language), significant differences popular clients languages (e.g. Keitai Web
popular client Japanese, web English German, Twitter Android
Korean). geotagged tweets, hand, much greater consistency,
three popular clients languages Twitter iOS, Twitter Android
foursquare, accounting relatively constant two-thirds posts language.
suggestive fact choice client one factor biasing relative proportion
29. Based simplifying assumptions that: (a) every tweet contains linguistic content; (b) tweets monolingual, least predominantly single language.
30. represent languages Figure 5 using two-letter ISO 639-1 codes.

479

fiH , C OOK & BALDWIN

0.3
0.2
0.1

Percentage

0.4

0.5

0.53

0.09

0.0

0.04 0.03 0.03

en

es

pt

ja

nl

0.02 0.02 0.02 0.02 0.01 0.01 0.01 0.01 0.01 0.01
id



ru

de

tr

fr

ms

th

ko

ar

Languages

Figure 5: percentage tweets WORLD+ML written fifteen frequent
languages collected Twitter data. fifteen languages account 88%
tweets full dataset.

geotagged tweets different languages, although research required fully understand
effect.
training, development test data re-partitioned multilingual setting stratify
language, resultant dataset referred WORLD+ML. Again, development
testing sets consist 10K users each, remaining users training set WORLD.
Although Section 7 showed adding non-geotagged data improves geolocation accuracy,
experiments section based geotagged data, prohibitive computational cost experimenting much larger dataset. Note doesnt limit generalisability results, simply means careful compare monolingual
results Table 7 based geotagged tweets (the first row).
first compare geolocation performance multilingual setting English-only
setting, comparison past work geolocation considered. data WORLD+ML
partitioned two subsets E NE according whether majority given
users tweets English non-English, respectively. 10K test users WORLD+ML,
5,916 English 4,084 non-English. One challenge multilingual setting
experiments tokenisation. Although rudimentary tokenisation many languages English
French accomplished using whitespace punctuation, tokenisation much
challenging languages Japanese Chinese represent word boundaries
480

fiT EXT-BASED WITTER U SER G EOLOCATION P REDICTION

Train

Test

E+NE
E+NE
E+NE
E

E+NE
E
NE
E

Acc

Acc@161

Acc@C

0.196
0.134
0.287
0.169

0.343
0.256
0.468
0.317

0.772
0.715
0.855
0.746

Median
466
1067
200
632

Table 8: Results multilingual geolocation, training testing English (E) non-English
(NE) users, combination.

whitespace. However, amongst most-common languages Twitter (as shown Figure
5), Japanese language accounts substantial portion data (> 1%)
requires specialised tokenisation strategy (compared English). Japanese tweets
apply Japanese morphological segmenter MeCab (with IPA dictionary),31 post-correct
tokenisation errors relating Twitter-specific tokens mentions, hashtags, URLs (e.g.,
instances MeCab over-segments mention multiple morphemes). non-Japanese
tweets, apply tokeniser based regular expressions used previous English-only
experiments.
resolving tokenisation issue, apply IGR method Section 4.2.1
select optimised feature selection cut-off, based Acc development data. observe
much larger proportion tokens selected multilingual setting compared
English-only experiments. example, 400K token types multilingual experiment,
384K (the top 96%) selected location-indicative, English-only case 83K (the top
86%) location-indicative words selected total 96K token types.
experimental results shown Table 8.32 first row gives results training
testing full dataset English non-English tweets. next two rows show
results testing English (E) non-English (NE) subsets data. much lower
accuracy E compared NE indicates English tweets much difficult geolocate
non-English tweets. One reason many non-English languages,
strong bias towards small number cities. verify calculating class entropy
respective language training data. class probabilities smoothed using simple
add- method, = 1/3709 (where 3709 size class set). shown Table 9,
class entropy English (en) data largest, indicating English prevalent across large
number locations. contrast, Thai (th) Turkish (tr) much smaller entropies, suggesting
location distributions heavily skewed, user geolocation languages
easier English.
explore extent geolocatability user varies respect predominant language tweets, break results language Table 10,
shows results top-10 frequent languages (by number tweets) least 100 users
test data. cut-off users ensures consider under-represented languages.
31. http://sourceforge.net/projects/mecab/
32. English-only results reported comparable experiment Table 7 using
geotagged data, test sets consist different users two cases.

481

fiH , C OOK & BALDWIN

Language

Entropy

Language

Entropy

Language

Entropy

en
es
pt
ja
nl

6.279
5.069
4.144
3.523
3.820

id

ru
de
tr

3.868
5.244
3.772
6.207
2.888

fr
ms
th
ko
ar

5.538
3.970
2.697
2.781
3.281

Table 9: Geolocation class entropy top-15 languages

Lang.
en
es
pt
id
nl
ja
ru
tr
ar
th


No.
5916
945
673
398
342
298
217
186
164
154

Per-language Majority Class

Unified Multilingual

Monolingual Partitioning

Acc Acc@161 Acc@C Med.

Acc Acc@161 Acc@C Med.

Acc Acc@161 Acc@C Med.

0.019
0.116
0.223
0.264
0.175
0.326
0.336
0.538
0.335
0.325

0.039
0.159
0.296
0.472
0.789
0.530
0.378
0.656
0.470
0.766

0.655 3671
0.324 4267
0.952 490
0.899 197
0.889
87
0.960
96
0.857 633
0.930
0
0.463 379
0.981
20

0.134
0.267
0.232
0.324
0.173
0.336
0.346
0.538
0.354
0.279

0.256
0.346
0.305
0.565
0.789
0.544
0.387
0.656
0.488
0.623

0.715 1067
0.734 391
0.952 490
0.965 115
0.889
87
0.956
95
0.862 633
0.930
0
0.500 301
0.792
41

0.169
0.362
0.400
0.440
0.298
0.463
0.341
0.522
0.457
0.325

0.317
0.478
0.489
0.736
0.871
0.695
0.378
0.645
0.591
0.766

0.746
0.802
0.961
0.960
0.845
0.950
0.862
0.930
0.750
0.974

632
185
200
16
58
27
633
0
21
30

10000 0.107

0.189

0.693 2805

0.196

0.343

0.772

0.255

0.425

0.802

302

466

Table 10: Geolocation performance comparison top-10 frequent languages
multilingual test data, using (1) language prior (i.e., city language mostly
used); (2) unified multilingual model (i.e., training testing multilingual data
regardless languages); (3) language-partitioned monolingual models (i.e., first
identify primary language users, train one model per language, classify test
users model corresponding language tweets)

observe results vary remarkably language multilingual section Table
10. results overall lowest English (en), although lowest country-level accuracy
Arabic (ar); speculate caused large number countries Arabic spoken
in, relatively small number Arabic speakers training data. Furthermore, citylevel accuracy better 30% Indonesian (id), Japanese (ja), Russian (ru), Turkish (tr)
Arabic (ar); regions languages commonly-spoken geographicallyrestricted English, suggesting geolocation accuracy languages smaller geographic footprints tend higher languages widely-used throughout
larger geographical area. finding agrees recent work Priedhorsky et al. (2014),
underlines power language information predicting locations. best city-level
accuracy 53.8% observed Turkish (one languages lowest city-level entropy).
Manually inspecting outputs, find model predicts city Istanbul
Turkish users, large proportion Turkish tweets come city.
482

fiT EXT-BASED WITTER U SER G EOLOCATION P REDICTION

Based finding, consider language-based benchmark predicts
frequent city given predominant language users tweets (denoted Per-language Majority
Class). also observe performance gap multilingual model English (the second
row Table 8) English-only model (the bottom row Table 8). results show
target data known written single language monolingual model outperforms
multilingual one. also suggests alternative approach multilingual geolocation prediction:
rather training predicting multilingual data (E+NE), train evaluate models
language-specific data. Motivated observation, also apply monolingual partitioned
model users particular language based langid.py (i.e., language partitions), e.g.,
selecting Japanese users training data, applying Japanese-specific model
Japanese users test data. denoted Monolingual Partitioning Table 10,
contrasted simple approach combined model languages users (Unified
Multilingual).
comparing Per-language Majority Class Unified Multilingual model, find
unified model performs better overall, exception Thai (th) Dutch (nl),
associated small number cities, one city much larger
others (Bangkok, TH Amsterdam, NL, respectively). relatively poor results
benchmark method languages English (en) Spanish (es) frequent
Twitter, relatively poor overall performance, Per-language Majority Class
appropriate method task. Nevertheless, using Monolingual Partitioning model,
results far superior, partitioning effect language seen. suggests
modelling language independently improve geolocation performance.
summary, series experiments shown influence language geolocation prediction. Among top-10 languages found Twitter, English difficult perform user
geolocation over, English global language. Despite language variance, multilingual
geolocation prediction certainly feasible, although best way leverage language geolocation prediction training language-partitioned monolingual models geolocating users based
primary language.

9. Incorporating User Meta Data

metadata accompanying tweets valuable source geographical information beyond
available tweets. section, explore incorporating metadata information textbased geolocation system. begin selecting four metadata fields could potentially provide
insights location user, first evaluate models trained sources
information. consider number ways incorporate information metadata
best text-based method developed Section 7. discussed Section 8, language
strong influence geolocation prediction, English-posting users hardest geolocate.
such, experiment English data (i.e., WORLD+NG) remainder paper.
483

fiH , C OOK & BALDWIN

Data
Training
Test

LOC

TZ

DESC

0.813
0.813

0.752
0.753

0.760
0.761

Table 11: proportion users non-empty metadata fields WORLD+NG
9.1 Unlock Potential User-Declared Metadata
choose following four user-supplied metadata fields study: location (LOC), timezone
(TZ), description (DESC), users real name (RNAME).33 contrast rich social network
information much expensive extract, metadata fields included
JSON object provided Twitter Streaming API, i.e., extract metadata
extra crawling cost. information, however, dynamic, i.e., users change profiles,
including metadata interest us. aggregating extracted tweet-level metadata
user, calculate ratio users change metadata field. 18% users changed
DESC field approximately five months dataset collected.
time period, fields considered, less 8% users updated data.
Given relatively small number profile updates, ignore influence changes,
use frequent value metadata field user experiments.
user-supplied metadata imprecise inaccurate, user free
enter whatever textual information choose. example, LOC fields accurate
descriptions geographical locations (e.g., best place universe). Moreover, although
LOC fields canonical renderings users true location (e.g., Boston, MA, USA), large
number abbreviations non-standard forms also observed (e.g., MEL Melbourne, AU).
Cheng et al. (2010) find small proportion location fields US-based dataset
canonical locations (i.e., form city, state). Nevertheless, non-standard inaccurate
location fields might still carry information location (Kinsella et al., 2011), similarly
text tweets indicate location without explicitly mentioning place names.
metadata fields also differ respect explicitness location information
encode. instance, LOC TZ give direct location information, DESC might contain
references location, e.g., geek Lisp developer Bangalore. Although RNAME
directly encode location regional preferences names (Bergsma, Dredze, Van Durme,
Wilson, & Yarowsky, 2013), e.g., Petrov might common Russia, name Hasegawa
might common Japan. Finally, tweets consider, text field (i.e.,
content tweet itself) RNAME always present, LOC, TZ, DESC missing
user chosen supply information. proportion non-empty metadata fields
LOC , TZ DESC users WORLD+NG listed Table 11.
9.2 Results Metadata-Based Classifiers
variable reliability explicitness selected metadata, incorporate
fields statistical geolocation model similar manner message text. prelimi33. user-supplied real name could name i.e., necessarily users actual name different
field users screen name.

484

fiT EXT-BASED WITTER U SER G EOLOCATION P REDICTION

Classifier
LOC
TZ
DESC
RNAME
BASELINE
TEXT

Acc

Acc@161

Acc@C

Median

0.405
0.064
0.048
0.045

0.525
0.171
0.117
0.109

0.834
0.565
0.526
0.550

92
1330
2907
2611

0.008
0.280

0.019
0.492

0.600
0.878

3719
170

Table 12: performance NB classifiers based individual metadata fields, well baseline, text-only classifier IGR feature selection.

nary experiments, considered bag-of-words features metadata fields, well bag-ofcharacter n-gram features n {1, ..., 4}.34 found character 4-grams perform best,
report results using features here. (A bag-of-character 4-grams represents frequency
four-character sequence including start end symbol.) geolocation performance
classifier trained features metadata field isolation, well performance
frequent city baseline (BASELINE) best purely text-based classifier (TEXT, replicated
Table 7), shown Table 12.
classifier based metadata field outperforms baseline terms Acc, Acc@161,
Median error distance. suggests metadata fields indeed encode geographicallyidentifying information, though classifiers less competitive TEXT. Notably, despite
potential noise user-supplied location fields, classifier (LOC) achieves even better
performance purely text-based method, reaching city-level accuracy 40%, predicting location within 161km true location half users. suggests LOC
contains valuable information, even though LOC fields noisy (Cheng et al., 2010),
easily captured off-the-shelf geolocation tools (Hecht et al., 2011). Manual analysis suggests
many vernacular place names captured statistical modelling, Kiladelphia
Philly used represent Philadelphia. utility metadata fields also confirmed recent
work Priedhorsky et al. (2014).
9.3 Ensemble Learning Text-Based Classifiers
analyse behaviour four metadata classifiers, consider pairwise city-level
prediction agreement them. Cohens Kappa (Carletta, 1996) conventional metric
evaluate inter-annotator agreement categorical items (such predicted cities case);
larger Kappa values indicate higher pairwise agreement. double fault measure (Giacinto &
Roli, 2001) incorporates gold-standard information, equal proportion test cases
classifiers make false prediction. measure offers empirical lowest error bound
pairwise ensemble classifier performance.
34. Although could certainly also consider character n-grams text-based classifier, opted bag-ofwords representation explicitly captures LIWs believe especially important geolocation.
could also location-indicative character n-grams, exploration leave future work.

485

fiH , C OOK & BALDWIN

TEXT

0.461

0.689

0.702

0.704

0.181

LOC

0.577

0.578

0.581

0.066

0.063

TZ

0.903

0.907

0.067

0.041

0.085

DESC

0.923

0.065

0.049

0.080

0.088

RNAME

Table 13: Pairwise correlation base classifiers using Cohens Kappa (bottom left, light
grey; higher numbers indicate greater prediction similarity) double fault measure
(top right, white; lower numbers indicate greater prediction similarity).

Pairwise scores Cohens Kappa double fault measure shown Table 13.
Kappa scores (bottom-left Table 13) low, indicating little agreement
classifiers. classifiers achieve better baseline performance, also give quite
different outputs, might possible combine classifiers achieve better performance.
double fault results (top-right) suggest improved accuracy could obtained
combining classifiers.
combine individual classifiers using meta-classification. first adopt feature concatenation strategy incrementally combines feature vectors TEXT, LOC, TZ, DESC
RNAME . also consider stacked generalisation (Wolpert, 1992), referred simply stacking,
outputs base classifiers, true city-level locations, used train
second classifier produces final output. base classifiers, second classifier,
referred L0 L1 classifiers, respectively. conventional applications stacking,
homogeneous training data used train heterogeneous L0 classifiers; case, however,
train homogeneous L0 multinomial Bayes models heterogeneous data (i.e., different types
data TEXT, LOC, TZ). consider logistic regression (Fan, Chang, Hsieh, Wang, &
Lin, 2008) multinomial Bayes L1 classifier.
carry 10-fold cross validation training users obtain L1 (final) classifier
results, standard procedure stacking experiments. use stratified sampling partitioning
data number users different cities varies remarkably, simple random
sample could bias towards bigger cities. ensemble learning results tabulated Table
14.
combination TEXT LOC improvement LOC (i.e., best results far).
However, using feature concatenation multinomial naive Bayes stacking, accuracy generally
drops metadata feature sets perform relatively poorly isolation (i.e., TZ, DESC, RNAME)
incorporated. hand, using logistic regression stacking, see small increases
accuracy features perform less well isolation incorporated. Though DESC RNAME
moderately useful (as shown Table 12), fields contribute little strong ensembles
(i.e., TEXT, LOC TZ). best model (using logistic regression stacking features)
assigns users correct city almost 50% test cases, Median error
9km. Moreover, approach country-level accuracy reaches almost 92%, indicating
effectiveness method coarse-grained geolocation task.
486

fiT EXT-BASED WITTER U SER G EOLOCATION P REDICTION

Feature concatenation
Acc
Acc@161
0.444
0.646
0.429
0.639
0.319
0.529
0.294
0.503

1.
2.
3.
4.

Features
TEXT + LOC
1. + TZ
2. + DESC
3. + RNAME

Acc@C
0.923
0.929
0.912
0.912

Median
27
32
127
156

1.
2.
3.
4.

Multinomial Bayes stacking
Features
Acc
Acc@161 Acc@C
TEXT + LOC
0.470
0.660
0.933
1. + TZ
0.460
0.653
0.930
2. + DESC
0.451
0.645
0.931
3. + RNAME 0.451
0.645
0.931

Median
19
23
27
27

1.
2.
3.
4.

Logistic regression stacking
Features
Acc
Acc@161 Acc@C
TEXT + LOC
0.483
0.653
0.903
1. + TZ
0.490
0.665
0.917
2. + DESC
0.490
0.666
0.919
3. + RNAME 0.491
0.667
0.919

Median
14
9
9
9

Table 14: performance classifiers combining information text metadata using feature concatenation (top), multinomial Bayes stacking (middle), logistic regression
stacking (bottom). Features 1. + TZ refer features used row 1.
combination TZ.

interesting observe that, found NB outperform LR standalone classifier
Section 5.2, L1 classifier, LR clearly outperforms NB. reason almost certainly fact use much smaller feature set relative number training instances
stacking experiments, circumstances, discriminative models tend outperform
generative models (Ng & Jordan, 2002).

10. Temporal Influence
addition held-out English test data WORLD+NG, also developed new geotagged
test dataset measure impact time model generalisation. training test data
WORLD+NG time-homogeneous randomly partitioned based data collected
period. contrast, new test dataset (LIVE) much newer, collected 1
year later WORLD+NG. Given Twitter users topics change rapidly, key question
whether statistical model learned old training data still effective new
test data? question implications maintenance retraining geolocation models
time. experiments section train WORLD+NG test new dataset.
LIVE data collected 48 hours 3 Mar, 2013 5 Mar, 2013, based geotagged tweets users whose declared language English. Recent status updates (up 200)
crawled user, langid.py applied data remove remnant nonEnglish messages. addition filtering users less 10 geotagged tweets test data
WORLD+NG, exclude users less 50% geotagged tweets one
487

fiH , C OOK & BALDWIN

Features
1. TEXT
2. LOC
3. TZ
1. + 2. + 3.

Acc
0.280
0.405
0.064
0.490

Features
1. TEXT
2. LOC
3. TZ
1. + 2. + 3.

Acc
0.268
0.326
0.065
0.406

WORLD+NG
Acc@161 Acc@C
0.492
0.878
0.525
0.834
0.171
0.565
0.665
0.917
LIVE
Acc@161
0.510
0.465
0.160
0.614

Acc@C
0.901
0.813
0.525
0.901

Median
170
92
1330
9

Median
151
306
1529
40

Table 15: Generalisation comparison time-homogeneous WORLD+NG timeheterogeneous LIVE (1. + 2. + 3. denotes stacking TEXT, LOC TZ).

city. users geotagged tweets spread across different locations, less
credible adopt users frequent location true primary location evaluation.
post-check WORLD+NG test data shows 9,977 10K users satisfy requirement
geographical coherence, arent unnecessarily biasing data LIVE applying
criterion. Finally, status updates aggregated user-level, WORLD+NG.
filtering, 32K users obtained, forming final LIVE dataset.
use TEXT, LOC TZ section, require less computation achieve
accuracy comparable best results, shown Table 14. temporal factor impact
geolocation prediction model generalisation revealed accuracy WORLD+NG LIVE
shown Table 15. Acc Acc@161 numbers stacked model (1. + 2. + 3.) drop
approximately 8 5 percentage points, respectively, LIVE compared WORLD+NG.
Median prediction error distance also increases moderately 9km 40km. decomposing
stacked models evaluating base classifiers, find accuracy declines
primarily caused accuracy drops LOC classifier new LIVE data, approximately
9% Acc 6% Acc@161. could viewed type over-fitting, stacked
classifier relying heavily predictions LOC base classifier. TZ classifier
performs relatively constantly terms accuracy, although Median error increases slightly.
TEXT classifier remarkably robust, numbers except Acc improving marginally.
investigate poor LOC classifier generalisation LIVE. First, down-sample
LIVE 10K users, size WORLD+NG, compare per-city prediction numbers two datasets using LOC classifier. find two factors jointly cause accuracy
decrease LIVE: (1) composition test users, (2) decline per-city recall. instance, 80 test users London, GB WORLD+NG. number sharply increases 155
LIVE, meaning influence London, GB test users overall accuracy LIVE almost
doubled. Furthermore, recall proportion users given location correctly
predicted location London, GB drops 0.676 WORLD+NG
0.568 LIVE. observe proportion empty LOC fields among London, GB test users
jumps 13% (WORLD+NG) 26% (LIVE). reduces utility LOC data LIVE
488

fiT EXT-BASED WITTER U SER G EOLOCATION P REDICTION

Rank

cities LIVE

1
2
3
4
5
6
7
8
9
10

Los Angeles, US
Kuala Lumpur,
London, GB
Jakarta, ID
Anaheim, US
Singapore, SG
Fort Worth, US
Chicago, US
Pittsburgh, US
San Antonio, US

LIVE users

LIVE recall

WORLD+NG users

WORLD+NG recall

201
168
155
129
85
76
76
72
72
66

0.766
0.482
0.568
0.550
0.447
0.474
0.289
0.569
0.431
0.455

81
50
80
86
26
160
35
123
39
82

0.691
0.560
0.675
0.686
0.346
0.556
0.371
0.577
0.487
0.585

Table 16: number test users, recall using
LIVE, compared WORLD+NG.

LOC ,

city, top-10 largest cities

explains per-city recall drops: test users empty LOC field assigned
city highest class prior model (i.e., Los Angeles, US). Overall, ratios empty
LOC fields WORLD+NG test data LIVE 0.176 0.305, respectively, suggesting
user-declared locations LIVE carry much less geospatial information WORLD+NG.
show comparisons top-10 cities terms test users Table 16,35 accuracy
highly-represented cities greater impact overall results smaller cities.
Like London, GB, cities shown Table 16 experience lower recall scores LIVE, many
test users LIVE WORLD+NG. Nevertheless, cities higher
recall test users LIVE, e.g., Los Angeles, US Anaheim, US Table 16. overall
numbers are, course, determined aggregated performance cities. provide insight, 35.6% cities WORLD+NG 40% recall, number 28.5%
LIVE.
important base classifier stacked model, LOC accuracy numbers
influenced temporal changes, whether increased reluctance supply userdeclared location (although admittedly users geotag tweets), primarily due variance user proportions different cities sampled stream. Either way, periodically retrained LOC classifier would, doubt, go way towards remedying temporal gap. Overall,
numbers suggest time-homogeneous data (WORLD+NG) easier classify timeheterogeneous data (LIVE). However, training old data testing new data
shown empirically viable TEXT TZ base classifiers particular. result also
validates efforts optimise text-based user geolocation classification accuracy. Recently, similar
results tweet-level geolocation prediction observed Priedhorsky et al. (2014), supporting
claim accuracy geolocation prediction suffers diachronic mismatches
training test data.

35. observe city proportions changed drastically WORLD+NG LIVE. reasons
unclear, speculate due significant shifts microblogging usage different locations
around world.

489

fiH , C OOK & BALDWIN

11. User Tweeting Behaviour
improved extended text-based geolocation prediction, shift focus user
geolocatability. user wishes keep geolocation private, simply disable public
access tweets metadata. However, users choose share (non-geotagged) tweets,
different tweeting behaviours make susceptible geolocation privacy attacks? investigate question, section, discuss impact user behaviour
geolocation accuracy relative predictions LIVE based stacking model Section
10.36
obvious first rule thumb, geotagged tweets avoided, provide
immediate access users geographical footprint, e.g., favourite bars, office address.
Second, immediate implication finding location metadata strong predictor
geolocation (Section 9.2), user wants avoid privacy attacks, avoid presenting
location metadata, effect disabling LOC base classifier stacked classifier. Third, text
users posts used geolocate user (at approximately 27% Acc, Table 15).
investigate impact volume tweets user geolocatability, perform breakdown
results LIVE across two dimensions: (1) number LIWs, investigate whether
sheer volume tweets user makes geolocatable; (2) source geospatial
information exploit geolocation model. evaluate questions Figure 6
four feature combination settings, relative the: (1) tweet text-based classifier; (2) tweet textbased classifier gazetteer names removed;37 (3) metadata stacking using LOC TZ (invariant
tweet number changes); (4) stacking TEXT, LOC TZ users. case,
partition data 20 partitions 5% users each, ranked total number LIWs
contained combined posts user. addition Acc user partition,
also indicate average number LIWs per user partition (as shown second y-axis,
right side graph).
Overall, LIWs contained users tweets, higher Acc text-based methods. gazetted terms removed tweets, Acc drops large margin. suggests
gazetted terms play crucial role user geolocation. Metadata also contributes substantially accuracy, improving text-based accuracy consistently. Moreover, user tweets lot, Acc
tweet text-based approach comparable best model, even without access metadata
(as shown top right corner graph). overall recommendation, users wish
obfuscate location leave metadata fields blank avoid mentioning LIWs (e.g.,
gazetted terms dialectal words) tweets. make difficult best geolocation models infer location correctly (as demonstrated bottom left graph).
similar conclusion user geolocatability recently obtained Priedhorsky et al. (2014).
help privacy-conscious Twitter users avoid geolocated tweets, made
list LIWs publicly available.38

36. analysis limited behaviours could easily adopted many users. Given system predicts
likely city fixed set given user, one simple way avoid geolocated move far away
cities. However, seems unlikely strategy would widely adopted.
37. gazetteer based ASCII city names Geonames data.
38. http://www.csse.unimelb.edu.au/tim/etc/liw-jair.tgz

490

fiT EXT-BASED WITTER U SER G EOLOCATION P REDICTION

100
200
300
400
Number Location Indicative Words

0.5

Text
Text without gazetteers
Metadata stacking (LOC, TZ)
Stacking (TEXT, LOC, TZ)

Accuracy

0.4
0.3
0.2
0.1
Number Location Indicative Words (LIWs)

0.0
20%

40%
60%
Location Indicative Word partitions

80%

0

0.6

100%

Figure 6: impact use LIWs geolocation accuracy. Users sorted number
LIWs tweets, partitioned 20 bins. Metadata includes LOC TZ.

12. Prediction Confidence
task setup date, forced models geolocate users. practice, however,
many users dont explicitly mention geolocating words posts, making task nigh
impossible even human oracle. alternative approach would predict user geolocation
model confident prediction. Here, consider range variables
potentially indicate prediction confidence.
Absolute probability (AP): consider predictions probability specified threshold.
Prediction coherence (PC): hypothesise reliable predictions, top-ranked locations
tend geographically close. preliminary exploration coherence, formulate PC sum reciprocal ranks predictions corresponding second-level
administrative region class representation (i.e., state province) top-ranking
prediction, calculated top-10 predictions.39 example, suppose top-10 secondlevel predictions following states US: US-TX, US-FL, US-TX, US-TX,
US-CA, US-TX, US-TX, US-FL, US-CA, US-NY. top-ranking state-level prediction
therefore US-TX, also occurs ranks 3, 4, 6 7 (for different cities Texas).
case, PC would 11 + 13 + 14 + 16 + 17 .
Probability ratio (PR): model confident prediction, first prediction tend
much probable predictions. formulate intuition PR, ratio
probability first second most-probable predictions.
39. could measured average distance top predictions well.

491

fiH , C OOK & BALDWIN

0.8

Acc@161

0.6

0.4
Absolute Probability (AP)
Prediction Coherence (PC)
Probability Ratio (PR)
Feature Number (FN)
Feature Weight (FW)

0.2

0.05 0.15 0.25 0.35 0.45 0.55 0.65 0.75 0.85 0.95
Recall

Figure 7: Acc@161 classification top-n% most-confident predictions measure
text-based prediction confidence NA

Feature number (FN): take number features found users posts prediction
accuracy. intuition geolocation prediction based features
reliable prediction based fewer features.
Feature weight (FW): Similar FN, case use sum IGR features, rather
number features.
investigate variables NA LIVE results. particular, evaluate using text-based model, experiment text-based user geolocation
section. Nevertheless, exploration metadata classifiers also possible. sort
predictions confidence (independently measure prediction confidence) measure
Acc@161 among top-n% predictions following values n: {0.0, 0.05, ..., 1.0}, akin
precisionrecall curve, shown Figures 7 8. Results Acc show similar trend,
omitted paper.
naive AP method least reliable with, surprisingly, accuracy increasing AP decreases
figures. appears raw probabilities accurate reflection prediction
confidence. find larger AP usually indicates user LIW features,
model often geolocates user city highest class prior. comparison, PR
focuses relative, opposed raw, probabilities performs much better, higher
PR generally corresponding higher accuracy. addition, PC shows different trends two
figures. achieves comparable performance PR NA, however incapable estimating
global prediction confidence. largely world-level PC numbers often
small less discriminating regional PC numbers, reducing utility geographic
proximity top predictions. Furthermore, FN FW display similar overall trends PR,
dont outperform PR.
492

fiT EXT-BASED WITTER U SER G EOLOCATION P REDICTION

Acc@161

0.8

0.6

0.4
Absolute Probability (AP)
Prediction Coherence (PC)
Probability Ratio (PR)
Feature Number (FN)
Feature Weight (FW)

0.2

0.05 0.15 0.25 0.35 0.45 0.55 0.65 0.75 0.85 0.95
Recall

Figure 8: Acc@161 classification top-n% most-confident predictions measure
text-based prediction confidence LIVE

experiments suggest indeed trade-off coverage accuracy,
could exploited obtain higher-accuracy predictions applications require
data classified. PR, well FN FW, fairly effective indicators predictive accuracy. extension line research would investigate prediction
confidence per city, e.g., users New York, US predictable users Boston,
US?

13. Future Work
research could expanded number directions. First, hierarchical classification models (Mahmud et al., 2012; Ahmed, Hong, & Smola, 2013) becoming increasingly popular,
could combined stacked model. Although explicit social network data (e.g., followers)
non-trivial retrieve, user interactions reconstructed content tweets (e.g.,
replies, retweets user mentions: Jurgens, 2013). implicit network information could
combined current text-based geolocation methods improve geolocation accuracy. Additionally, hypothesise text-based geolocation prediction challenging task
humans, method achieving surpassing accuracy levels human. would
interesting test hypothesis, e.g., using crowdsourcing methods.
Recently, Priedhorsky et al. (2014) proposed evaluating message-level geolocation. use
Gaussian mixture models characterise n-gram probability distributions evaluate geolocation prediction accuracy using probabilistic metrics. conclusions strongly agree
findings, although task setting user-level evaluation metrics different.
future, plan adapt methods tweet-level geolocation carry systematic evaluation
probabilistic analysis geolocation.
493

fiH , C OOK & BALDWIN

14. Summary
paper, investigated series key issues relating text-based geolocation prediction
Twitter users. applied number feature selection methods identify location indicative
words (LIWs), demonstrated effectiveness feature selection regional (NA)
global (WORLD) datasets. extended study analyse impact non-geotagged data,
influence language complementary geographical information user metadata.
evaluated model time-heterogeneous dataset assess models sensitivity
temporal change. Moreover, discussed users tweeting behaviour affects geolocation
prediction, drew conclusions users make less easily geolocatable. Finally,
explored various indicators estimate prediction confidence, terms balance
prediction coverage accuracy.
number conclusions drawn study, corresponding different sections
paper. believe findings contribute deeper understanding text-based geolocation
prediction, shape design practical solutions problem:
demonstrate explicit selection location indicative words improves geolocation prediction accuracy, compared using full feature set.
Non-geotagged tweets (from users whose location known) boost prediction accuracy
substantially training testing. also demonstrate modeling geotagged
data inferencing non-geotagged data indeed feasible. largely
similarity geotagged data non-geotagged data, although minor differences
observed geotagged non-geotagged tweets.
Modelling inference multilingual data viable easier monolingual English data. tweet language strongly affects prediction accuracy. Due
uneven geographical distribution languages tweets, users geographically-diverse languages (e.g., English Spanish) much harder geolocate users geographicallyfocused languages (e.g., Japanese Dutch). Although trivially determining locations based
language tweets fine geographically-focused languages, insufficient
majority users post tweets using geographically-diverse languages. integrating
language information different ways, found training range monolingual models
based language identification, predicting location using model based users
primary language, achieves better results monolithic multilingual model.
User-declared metadata, though noisy unstructured, offers complementary location-indicative information contained tweets. combining tweet metadata information stacking, best global geolocation results attained: 49% English
users correctly predicted city level, Median error distance 9km.
Results time-heterogeneous evaluation suggest applying model trained old data
predict new data generally feasible. Although user-declared location field (LOC)
sensitive temporal change, classifiers based tweet content (TEXT) user timezone
(TZ) generalise reasonably well across time.
pilot study user geolocatability led following recommendations preserve
geolocation privacy: (1) reduce usage location indicative words, particularly gazetted
494

fiT EXT-BASED WITTER U SER G EOLOCATION P REDICTION

terms; (2) delete location-sensitive metadata (e.g., user-declared location timezone
metadata).
Probability ratio, measures ratio probability top prediction
second prediction, used estimate prediction confidence, select users
system prediction accurate, e.g., downstream applications require
more-reliable geolocation predictions exhaustive user geolocation required.

Acknowledgments
authors wish thank Stephen Roller Jason Baldridge making data tools available
replicate NA experiments.
NICTA funded Australian government represented Department Broadband,
Communication Digital Economy, Australian Research Council ICT Centre
Excellence programme.

References
Ahmed, A., Hong, L., & Smola, A. J. (2013). Hierarchical geographical modeling user locations
social media posts. Proceedings 22nd international conference World Wide
Web, WWW 13, pp. 2536, Rio de Janeiro, Brazil.
Amitay, E., HarEl, N., Sivan, R., & Soffer, A. (2004). Web-a-where: geotagging web content.
Proceedings 27th Annual International ACM SIGIR Conference Research
Development Information Retrieval (SIGIR 2004), pp. 273280, Sheffield, UK.
Backstrom, L., Kleinberg, J., Kumar, R., & Novak, J. (2008). Spatial variation search engine
queries. Proceeding 17th international conference World Wide Web, WWW 08,
pp. 357366, Beijing, China.
Backstrom, L., Sun, E., & Marlow, C. (2010). Find can: improving geographical prediction social spatial proximity. Proceedings 19th International Conference
World Wide Web, pp. 6170, Raleigh, USA.
Baldwin, T., Cook, P., Lui, M., MacKinlay, A., & Wang, L. (2013). noisy social media text,
diffrnt social media sources?. Proceedings 6th International Joint Conference
Natural Language Processing (IJCNLP 2013), pp. 356364, Nagoya, Japan.
Bennett, P. N., Radlinski, F., White, R. W., & Yilmaz, E. (2011). Inferring using location
metadata personalize web search. Proceedings 34th International ACM SIGIR
Conference Research Development Information Retrieval, SIGIR 11, pp. 135144,
Beijing, China.
Bentley, J. L. (1975). Multidimensional binary search trees used associative searching. Communication ACM, 18(9), 509517.
Bergsma, S., Dredze, M., Van Durme, B., Wilson, T., & Yarowsky, D. (2013). Broadly improving
user classification via communication-based name location clustering Twitter.
Proceedings 2013 Conference North American Chapter Association
495

fiH , C OOK & BALDWIN

Computational Linguistics: Human Language Technologies (NAACL-HLT 2013), pp. 1010
1019, Atlanta, USA.
Bilhaut, F., Charnois, T., Enjalbert, P., & Mathet, Y. (2003). Geographic reference analysis geographic document querying. Proceedings HLT-NAACL 2003 workshop Analysis
geographic references - Volume 1, pp. 5562, Edmonton, Canada.
Blei, D. M., Ng, A. Y., & Jordan, M. I. (2003). Latent Dirichlet Allocation. Journal Machine
Learning Research, 3, 9931022.
Buyukokkten, O., Cho, J., Garcia-Molina, H., Gravano, L., & Shivakumar, N. (1999). Exploiting
geographical location information web pages. ACM SIGMOD Workshop Web
Databases (WebDB99), pp. 9196, Philadelphia, USA.
Carletta, J. (1996). Assessing agreement classification tasks: kappa statistic. Computational
Linguistics, 22(2), 249254.
Chandra, S., Khan, L., & Muhaya, F. (2011). Estimating Twitter user location using social
interactionsa content based approach. 2011 IEEE Third International Conference
Privacy, Security, Risk Trust (PASSAT) 2011 IEEE Third International Conference
Social Computing (SocialCom), pp. 838843, Boston, USA.
Chang, H.-w., Lee, D., M., E., & Lee, J. (2012). @Phillies tweeting Philly? predicting Twitter
user locations spatial word usage. IEEE/ACM International Conference Advances
Social Networks Analysis Mining (ASONAM), pp. 111118, Istanbul, Turkey.
Cheng, Z., Caverlee, J., & Lee, K. (2010). tweet: content-based approach
geo-locating twitter users. Proceedings 19th ACM International Conference
Information Knowledge Management, pp. 759768, Toronto, Canada.
Cho, E., Myers, S. A., & Leskovec, J. (2011). Friendship mobility: user movement locationbased social networks. Proceedings 17th ACM SIGKDD International Conference
Knowledge Discovery Data Mining, pp. 10821090, San Diego, USA.
Crandall, D. J., Backstrom, L., Huttenlocher, D., & Kleinberg, J. (2009). Mapping worlds
photos. Proceedings 18th international conference World wide web, WWW 09,
pp. 761770, Madrid, Spain.
Dalvi, N., Kumar, R., & Pang, B. (2012). Object matching tweets spatial models.
Proceedings Fifth ACM International Conference Web Search Data Mining
(WSDM 2012), pp. 4352, Seattle, USA.
Ding, J., Gravano, L., & Shivakumar, N. (2000). Computing geographical scopes web resources.
Proceedings 26th International Conference Large Data Bases, VLDB 00,
pp. 545556, Cairo, Egypt.
Dunning, T. (1993). Accurate methods statistics surprise coincidence. Computational
Linguistics, 19(1), 6174.
Eisenstein, J., OConnor, B., Smith, N. A., & Xing, E. P. (2010). latent variable model
geographic lexical variation. Proceedings 2010 Conference Empirical Methods
Natural Language Processing (EMNLP 2010), pp. 12771287, Cambridge, USA.
Fan, R.-E., Chang, K.-W., Hsieh, C.-J., Wang, X.-R., & Lin, C.-J. (2008). LIBLINEAR: library
large linear classification. Journal Machine Learning Research, 9, 18711874.
496

fiT EXT-BASED WITTER U SER G EOLOCATION P REDICTION

Gelernter, J., & Mushegian, N. (2011). Geo-parsing messages microtext. Transactions GIS,
15(6), 753773.
Giacinto, G., & Roli, F. (2001). Design effective neural network ensembles image classification purposes. Image Vision Computing, 19(910), 699707.
Gouws, S., Metzler, D., Cai, C., & Hovy, E. (2011). Contextual bearing linguistic variation
social media. Proceedings Workshop Languages Social Media, LSM 11, pp.
2029, Portland, USA.
Guyon, I., & Elisseeff, A. (2003). introduction variable feature selection. Journal
Machine Learning Research, 3, 11571182.
Han, B., Cook, P., & Baldwin, T. (2012a). Automatically constructing normalisation dictionary
microblogs. Proceedings Joint Conference Empirical Methods Natural
Language Processing Computational Natural Language Learning 2012 (EMNLP-CoNLL
2012), pp. 421432, Jeju, Korea.
Han, B., Cook, P., & Baldwin, T. (2012b). Geolocation prediction social media data finding
location indicative words. Proceedings 24th International Conference Computational Linguistics, pp. 10451062, Mumbai, India.
Han, B., Cook, P., & Baldwin, T. (2013). stacking-based approach Twitter user geolocation
prediction. Proceedings 51st Annual Meeting Association Computational
Linguistics: System Demonstrations, pp. 712, Sofia, Bulgaria.
Hauff, C., & Houben, G.-J. (2012). Geo-location estimation Flickr images: social web based
enrichment. Proceedings 34th European Conference Advances Information
Retrieval, pp. 8596, Barcelona, Spain.
Hecht, B., Hong, L., Suh, B., & Chi, E. H. (2011). Tweets Justin Biebers heart: dynamics
location field user profiles. Proceedings SIGCHI Conference Human
Factors Computing Systems, pp. 237246, Vancouver, Canada.
Hong, L., Ahmed, A., Gurumurthy, S., Smola, A. J., & Tsioutsiouliklis, K. (2012). Discovering
geographical topics Twitter stream. Proceedings 21st International Conference
World Wide Web (WWW 2012), pp. 769778, Lyon, France.
Hong, L., Convertino, G., & Chi, E. H. (2011). Language matters Twitter: large scale study.
Proceedings 5th International Conference Weblogs Social Media (ICWSM
2011), pp. 518521, Barcelona, Spain.
Jurgens, D. (2013). Thats friends for: Inferring location online social media platforms
based social relationships. Proceedings 7th International Conference Weblogs
Social Media (ICWSM 2013), pp. 273282, Boston, USA.
Kinsella, S., Murdock, V., & OHare, N. (2011). Im eating sandwich Glasgow: modeling
locations tweets. Proceedings 3rd international workshop Search mining
user-generated contents, pp. 6168, Glasgow, UK.
Laere, O. V., Quinn, J., Schockaert, S., & Dhoedt, B. (2014). Spatially-aware term selection
geotagging. IEEE Transactions Knowledge Data Engineering, 26(1), 221234.
Laere, O. V., Schockaert, S., & Dhoedt, B. (2013). Georeferencing Flickr resources based textual
meta-data. Information Sciences, 238, 5274.
497

fiH , C OOK & BALDWIN

Leidner, J. L., & Lieberman, M. D. (2011). Detecting geographical references form place
names associated spatial natural language. SIGSPATIAL Special, 3(2), 511.
Li, R., Wang, S., & Chang, K. C.-C. (2012). Multiple location profiling users relationships
social network content. VLDB, 5(11), 16031614.
Li, W., Serdyukov, P., de Vries, A. P., Eickhoff, C., & Larson, M. (2011). tweet.
Proceedings 20th ACM International Conference Information Knowledge
Management (CIKM 2011), pp. 24732476, Glasgow, UK.
Lieberman, M. D., & Lin, J. (2009). edit: Locating Wikipedia contributors
edit histories. Proceedings 3rd International Conference Weblogs
Social Media (ICWSM 2009), pp. 106113, San Jose, USA.
Lui, M., & Baldwin, T. (2012). langid.py: off-the-shelf language identification tool. Proceedings 50th Annual Meeting Association Computational Linguistics (ACL
2012) Demo Session, pp. 2530, Jeju, Korea.
Mahmud, J., Nichols, J., & Drews, C. (2012). tweet from? Inferring home locations
Twitter users. Proceedings 6th International Conference Weblogs Social
Media (ICWSM 2012), pp. 511514, Dublin, Ireland.
Mao, H., Shuai, X., & Kapadia, A. (2011). Loose tweets: analysis privacy leaks Twitter.
Proceedings 10th Annual ACM Workshop Privacy Electronic Society, pp.
112, Chicago, USA.
Nakatani, S. (2010). Language detection library Java. http://code.google.com/p/
language-detection/.
Ng, A. Y., & Jordan, M. I. (2002). discriminative vs. generative classifiers: comparison
logistic regression naive Bayes. Advances Neural Information Processing Systems
14 (NIPS-02), pp. 841848, Whistler, Canada.
Nocedal, J. (1980). Updating quasi-Newton matrices limited storage. Mathematics Computation, 35(151), 773782.
Nunez-Redo, M., Daz, L., Gil, J., Gonzalez, D., & Huerta, J. (2011). Discovery integration
Web 2.0 content geospatial information structures: use case wild fire monitoring.
Proceedings 6th International Conference Availability, Reliability Security, pp.
5068, Vienna, Austria.
OConnor, B., Krieger, M., & Ahn, D. (2010). TweetMotif: Exploratory search topic summarization Twitter. Proceedings Fourth International AAAI Conference Weblogs
Social Media, pp. 384385, Washington, D.C., USA.
OHare, N., & Murdock, V. (2013). Modeling locations social media. Information Retrieval,
16(1), 3062.
OSullivan, D., & Unwin, D. J. (2010). Point Pattern Analysis, pp. 121155. John Wiley & Sons,
Inc.
Padmanabhan, V. N., & Subramanian, L. (2001). investigation geographic mapping techniques internet hosts. Proceedings 2001 Conference Applications, Technologies, Architectures, Protocols Computer Communications, SIGCOMM 01, pp.
173185, San Diego, USA.
498

fiT EXT-BASED WITTER U SER G EOLOCATION P REDICTION

Pontes, T., Vasconcelos, M., Almeida, J., Kumaraguru, P., & Almeida, V. (2012). know
live: Privacy characterization Foursquare behavior. 4th International Workshop
Location-Based Social Networks (LBSN 2012), Pittsburgh, USA.
Priedhorsky, R., Culotta, A., & Valle, S. Y. D. (2014). Inferring origin locations tweets
quantitative confidence. Proceedings 17th ACM Conference Computer Supported
Cooperative Work Social Computing, Baltimore, USA. appear.
Quercini, G., Samet, H., Sankaranarayanan, J., & Lieberman, M. D. (2010). Determining spatial
reader scopes news sources using local lexicons. Proceedings 18th SIGSPATIAL
International Conference Advances Geographic Information Systems, GIS 10, pp. 43
52, San Jose, USA.
Quinlan, J. R. (1993). C4.5: Programs Machine Learning. Morgan Kaufmann, San Mateo,
USA.
Ritter, A., Clark, S., Mausam, & Etzioni, O. (2011). Named entity recognition tweets: experimental study. Proceedings 2011 Conference Empirical Methods Natural
Language Processing, pp. 15241534, Edinburgh, UK.
Roller, S., Speriosu, M., Rallapalli, S., Wing, B., & Baldridge, J. (2012). Supervised text-based
geolocation using language models adaptive grid. Proceedings 2012 Joint
Conference Empirical Methods Natural Language Processing Computational Natural Language Learning, pp. 15001510, Jeju Island, Korea.
Rout, D. P., Bontcheva, K., Preotiuc-Pietro, D., & Cohn, T. (2013). Wheres @wally?: classification approach geolocating users based social ties. Proceedings 24th ACM
Conference Hypertext Social Media, pp. 1120, Paris, France.
Sadilek, A., Kautz, H., & Bigham, J. P. (2012). Finding friends following
are. Proceedings Fifth ACM International Conference Web Search Data
Mining, pp. 723732, Seattle, USA.
Schulz, A., Hadjakos, A., Paulheim, H., Nachtwey, J., & Muhlhauser, M. (2013). multi-indicator
approach geolocalization tweets. Proceedings 7th International Conference
Weblogs Social Media (ICWSM 2013), pp. 573582, Boston, USA.
Serdyukov, P., Murdock, V., & van Zwol, R. (2009). Placing Flickr photos map. Proceedings 32nd International ACM SIGIR Conference Research Development
Information Retrieval (SIGIR 2009), pp. 484491, Boston, USA.
Silva, M. J., Martins, B., Chaves, M. S., Afonso, A. P., & Cardoso, N. (2006). Adding geographic
scopes web resources. Computers, Environment Urban Systems, 30, 378399.
Tuten, T. L. (2008). Advertising 2.0: Social media marketing Web 2.0 world. Praeger Publishers,
Westport, USA.
Vapnik, V. N. (1995). nature Statistical Learning Theory. Springer-Verlag, New York, USA.
Vincenty, T. (1975). Direct inverse solutions geodesics ellipsoid application
nested equations. Survey Review, 22(176), 8893.
Wang, L., Wang, C., Xie, X., Forman, J., Lu, Y., Ma, W.-Y., & Li, Y. (2005). Detecting dominant
locations search queries. Proceedings 28th Annual International ACM SIGIR
499

fiH , C OOK & BALDWIN

Conference Research Development Information Retrieval (SIGIR 2005), pp. 424
431, Salvador, Brazil.
Wing, B. P., & Baldridge, J. (2011). Simple supervised document geolocation geodesic grids.
Proceedings 49th Annual Meeting Association Computational Linguistics:
Human Language Technologies, pp. 955964, Portland, USA.
Wolpert, D. H. (1992). Stacked generalization. Neural Networks, 5(2), 241259.
Yang, Y., & Pedersen, J. O. (1997). comparative study feature selection text categorization.
Proceedings Fourteenth International Conference Machine Learning, ICML 97,
pp. 412420, San Francisco, USA.
Yi, X., Raghavan, H., & Leggetter, C. (2009). Discovering users specific geo intention web
search. Proceedings 18th International Conference World Wide Web, WWW 09,
pp. 481490, Madrid, Spain.
Yin, J., Lampert, A., Cameron, M., Robinson, B., & Power, R. (2012). Using social media
enhance emergency situation awareness. Intelligent Systems, 27(6), 5259.
Yin, Z., Cao, L., Han, J., Zhai, C., & Huang, T. (2011). Geographical topic discovery comparison. Proceedings 20th International Conference World Wide Web, pp. 247256,
Hyderabad, India.
Zong, W., Wu, D., Sun, A., Lim, E.-P., & Goh, D. H.-L. (2005). assigning place names
geography related web pages. ACM/IEEE Joint Conference Digital Libraries, pp. 354
362, Denver, USA.

500

fiJournal Artificial Intelligence Research 49 (2014) 1-47

Submitted 7/13; published 1/14

Multimodal Distributional Semantics
Elia Bruni

elia.bruni@unitn.it

Center Mind/Brain Sciences,
University Trento, Italy

Nam Khanh Tran

ntran@l3s.de

L3S Research Center,
Hannover, Germany

Marco Baroni

marco.baroni@unitn.it

Center Mind/Brain Sciences,
University Trento, Italy
Department Information Engineering Computer Science,
University Trento, Italy

Abstract
Distributional semantic models derive computational representations word meaning
patterns co-occurrence words text. models success
story computational linguistics, able provide reliable estimates semantic
relatedness many semantic tasks requiring them. However, distributional models
extract meaning information exclusively text, extremely impoverished
basis compared rich perceptual sources ground human semantic knowledge.
address lack perceptual grounding distributional models exploiting computer
vision techniques automatically identify discrete visual words images,
distributional representation word extended also encompass co-occurrence
visual words images associated with. propose flexible architecture
integrate text- image-based distributional information, show set
empirical tests integrated model superior purely text-based approach,
provides somewhat complementary semantic information respect latter.

1. Introduction
distributional hypothesis states words occur similar contexts semantically similar. claim multiple theoretical roots psychology, structuralist linguistics, lexicography possibly even later writings Wittgenstein (Firth, 1957;
Harris, 1954; Miller & Charles, 1991; Wittgenstein, 1953). However, distributional hypothesis huge impact computational linguistics last two decades mainly
empirical reasons, is, suggests simple practical method harvest
word meaning representations large scale: record contexts words
occur easy-to-assemble large collections texts (corpora) use contextual profiles surrogates meaning. Nearly contemporary corpus-based approaches
semantics rely contextual evidence one way another, systematic
extensive application distributional methods found call distributional
semantic models (DSMs), also known literature vector space semantic space
2014 AI Access Foundation. rights reserved.

fiBruni, Tran & Baroni

models meaning (Landauer & Dumais, 1997; Sahlgren, 2006; Schtze, 1997; Turney &
Pantel, 2010).
DSMs, meaning word approximated vector keeps track
patterns co-occurrence word text corpora, degree semantic
similarity or, generally, relatedness (Budanitsky & Hirst, 2006) two words
precisely quantified terms geometric distance vectors representing
them. example, car automobile might occur terms street, gas
driver, thus distributional vectors likely close, cuing fact
words synonyms. Extended empirical evidence shown distributional
semantics good harvesting effective meaning representations large scale,
confirming validity distributional hypothesis (see references Section 2.1
below).
Still, successes, distributional semantics suffers obvious limitation
represents meaning word entirely terms connections words. long
tradition studies cognitive science philosophy stressed models
meaning symbols (e.g., words) entirely accounted terms symbols (e.g.,
words) without links outside world (e.g., via perception) deeply problematic, issue often referred symbol grounding problem (Harnad, 1990).
DSMs also come attack lack grounding (Glenberg & Robertson,
2000).1 Although specific criticisms vented might entirely well-founded
(Burgess, 2000), little doubt limitation textual contexts makes
DSMs dissimilar humans, who, thanks senses, access rich sources
perceptual knowledge learning meaning words much cognitive scientists argued meaning directly embodied sensory-motor processing
(see work de Vega, Glenberg, & Graesser, 2008, different views embodiment
cognitive science). Indeed, last decades large amount behavioural neuroscientific evidence amassed indicating knowledge words concepts
inextricably linked perceptual motor systems. example, perceiving actiondenoting verbs kick lick involves activation areas brain controlling
foot tongue movements, respectively (Pulvermueller, 2005). Hansen, Olkkonen, Walter, Gegenfurtner (2006) asked subjects adjust color fruit images objects
appeared achromatic. objects generally adjusted color shifted
away subjects gray point direction opposite typical color fruit,
e.g., bananas shifted towards blue subjects overcorrected typical
yellow color. Typical color also influences lexical access: example, subjects faster
naming pumpkin picture presented orange grayscale
representation, slowest another color (Therriault, Yaxley, & Zwaan, 2009).
final example, Kaschak, Madden, Therriault, Yaxley, Aveyard, Blanchard, Zwaan
(2005) found subjects slower processing sentence describing action
sentence presented concurrently visual stimulus depicting motion opposite
1. Harnard, original paper, discussing formal symbols, postulated Fodors language
thought (Fodor, 1975), rather words natural language. However, latter
represented terms connections words, case DSMs, grounding problem
arises, follow recent literature issue referring symbol grounding,
symbols natural language words.

2

fiMultimodal Distributional Semantics

direction described (e.g., car approached harder process concurrently
perception motion away you). See review Barsalou (2008) review
evidence conceptual linguistic competence strongly embodied.
One might argue concerns DSMs grounded embodied
exaggerated, overlook fact patterns linguistic co-occurrence
exploited DSMs reflect semantic knowledge acquired perception,
linguistic perceptual information strongly correlated (Louwerse, 2011).
dogs often brown pink, likely talk brown dogs
pink dogs. Consequently, child learn useful facts meaning concept
denoted dog direct perception linguistic input (this explains, among
things, congenitally blind subjects excellent knowledge color terms;
see, e.g., Connolly, Gleitman, & Thompson-Schill, 2007). One could hypothesize
meaning representations extracted text corpora indistinguishable
derived perception, making grounding redundant. However, fairly
extensive literature showing case. Many studies (Andrews, Vigliocco,
& Vinson, 2009; Baroni, Barbu, Murphy, & Poesio, 2010; Baroni & Lenci, 2008; Riordan
& Jones, 2011) underlined text-derived DSMs capture encyclopedic, functional
discourse-related properties word meanings, tend miss concrete aspects.
Intuitively, might harvest text information bananas tropical eatable,
yellow (because authors write obvious statements
bananas yellow). hand, studies show how, humans
asked describe concepts, features produce (equivalent sense contextual
features exploited DSMs) preponderantly perceptual nature: Bananas yellow,
tigers stripes, on.2
discrepancy DSMs humans not, per se, proof DSMs
face empirical difficulties computational semantic models. However, interested
potential implications DSMs models humans acquire use language
case many DSM developers (e.g., Griffiths, Steyvers, & Tenenbaum, 2007;
Landauer & Dumais, 1997; Lund & Burgess, 1996, many others) complete
lack grounding perception serious blow psychological plausibility,
exposes criticism classic ungrounded symbolic models received.
Even empirical level, reasonable expect DSMs enriched perceptual
information would outperform purely textual counterparts: Useful computational semantic models must capture human semantic knowledge, human semantic knowledge
strongly informed perception.
accept grounding DSMs perception desirable avenue research,
must ask find practical source perceptual information embed DSMs.
Several interesting recent experiments use features produced human subjects concept
description tasks (so-called semantic norms) surrogate true perceptual features
(Andrews et al., 2009; Johns & Jones, 2012; Silberer & Lapata, 2012; Steyvers, 2010).
reasonable first step, integration methods proposed studies
2. perfectly fair, tendency might part triggered fact that, subjects asked
describe concepts, might encouraged focus perceptual aspects experimenters
instructions. example McRae, Cree, Seidenberg, McNorgan (2005) asked subjects list first
physical properties, internal external parts, [the object] looks.

3

fiBruni, Tran & Baroni

quite sophisticated, using subject-produced features unsatisfactory practically
theoretically (see however work reported Kievit-Kylar & Jones, 2011,
crowdsourcing project addressing kinds concerns). Practically, using subjectgenerated properties limits experiments words denote concepts described
semantic norms, even large norms contain features hundred concepts.
Theoretically, features produced subjects concept description tasks far removed
sort implicit perceptual features supposed stand for. example,
since expressed words, limited conveyed verbally.
Moreover, subjects tend produce salient distinctive properties.
state dogs head, since thats hardly distinctive feature animal!
article, explore direct route integrate perceptual information
DSMs. exploit recent advances computer vision (Grauman & Leibe, 2011)
availability documents combine text images automatically extract visual
features naturally co-occurring words multimodal corpora. imagebased features combined standard text-based features obtain perceptuallyenhanced distributional vectors. this, rely natural extension distributional hypothesis, encompasses similarity linguistic context, also
similarity visual context. Interestingly, Landauer Dumais, one classic papers
laid groundwork distributional semantics, already touched grounding
issue proposed, speculatively, solution along lines one implementing
here: [I]f one judiciously added numerous pictures scenes without rabbits
context columns [. . . ] corpus matrix, filled handful appropriate cells
rabbit hare word rows, [a DSM] could easily learn words rabbit hare
go pictures containing rabbits ones without, forth. (Landauer &
Dumais, 1997, p. 227).3
Although vision one source perceptual data, reasonable starting point,
convenience (availability suitable data train models)
probably dominating modality determining word meaning. one piece
evidence claim, widely used subject-generated semantic norms McRae et al.
(2005) contain 3,594 distinct perceptual features total, and, these, 3,099 (86%)
visual nature!
relatively low-level noisy features extract images multimodal corpora contribute meaningful information distributional representation
word meaning? report results systematic comparison network semantic relations entertained set concrete nouns traditional text-based
novel image-based distributional spaces confirming image-based features are, indeed,
semantically meaningful. Moreover, expected, provide somewhat complementary
information respect text-based features. thus found practical effective way extract perceptual information, must consider next combine textand image-derived features build multimodal distributional semantic model.
propose general parametrized architecture multimodal fusion that, given appropriate
sample data, automatically determines optimal mixture text- image-based features used target semantic task. Finally, evaluate multimodal DSMs
3. thank Mike Jones pointing interesting historical connection us.

4

fiMultimodal Distributional Semantics

two separate semantic tasks, namely predicting degree semantic relatedness assigned
word pairs humans, categorizing nominal concepts classes. show
tasks multimodal DSMs consistently outperform purely textual models, confirming
supposition that, like humans, performance computational models
meaning improves meaning grounded perception.
article structured follows. Section 2 provides relevant background
computational linguistics image analysis, discusses related work. lay
general architecture multimodal fusion distributional semantics Section 3.
necessary implementation details provided Section 4. Section 5 presents experiments tested approach. Section 6 concludes summarizing current
results well sketching come next.

2. Background Related Work
section first give brief introduction traditional distributional semantic models
(i.e., based solely textual information). Then, describe image analysis
techniques adopt extract manipulate visual information. Next, discuss earlier
attempts construct multimodal distributional representation meaning. Finally,
describe relevant strategies combine information coming text images
proposed inside computer vision community.
2.1 Distributional Semantics
last decades, number different distributional semantic models (DSMs) word
meaning proposed computational linguistics, relying assumption
word meaning learned directly linguistic environment.
Semantic space models one common types DSM. approximate
meaning words vectors record distributional history corpus
(Turney & Pantel, 2010). distributional semantic model encoded matrix whose
rows semantic vectors representing meanings set target words.
component semantic vector function occurrence counts corresponding
target word certain context (see Lowe, 2001, formal treatment). Definitions
context range simple ones (such documents occurrence another word
inside fixed window target word) linguistically sophisticated ones (such
occurrence certain words connected target special syntactic relations)
(Pad & Lapata, 2007; Sahlgren, 2006; Turney & Pantel, 2010). raw targetcontext counts collected, transformed association scores typically
discount weights components whose corresponding word-context pairs high
probability chance co-occurrence (Evert, 2005). rank matrix containing
semantic vectors rows optionally decreased dimensionality reduction,
might provide beneficial smoothing getting rid noise components and/or allow
efficient storage computation (Landauer & Dumais, 1997; Sahlgren, 2005; Schtze,
1997). Finally, distributional semantic similarity pair target words estimated
similarity function takes semantic vectors input returns scalar
similarity score output.
5

fiBruni, Tran & Baroni

many different semantic space models literature. Probably best
known Latent Semantic Analysis (LSA, Landauer & Dumais, 1997), highdimensional semantic space words derived use co-occurrence information
words passages occur. Another well-known example
Hyperspace Analog Language model (HAL, Lund & Burgess, 1996), word
represented vector containing weighted co-occurrence values word
words fixed window. semantic space models rely syntactic relations instead
windows (Grefenstette, 1994; Curran & Moens, 2002; Pad & Lapata, 2007). General
overviews semantic space models provided Clark (2013), Erk (2012), Manning
Schtze (1999), Sahlgren (2006) Turney Pantel (2010).
recently, probabilistic topic models receiving increasing attention
alternative implementation DSMs (Blei, Ng, & Jordan, 2003; Griffiths et al., 2007).
Probabilistic topic models also rely co-occurrence information large corpora derive meaning but, differently semantic space models, based assumption
words corpus exhibit probabilistic structure connected topics. Words
represented points high-dimensional space probability distribution
set topics. Conversely, topic defined probability distribution
different words. Probabilistic topic models tackle problem meaning representation
means statistical inference: use word corpus infer hidden topic structure.
Distributional semantic models, whether geometric probabilistic kind,
ultimately mainly used provide similarity score arbitrary pairs words,
also employ them. Indeed, models shown effective
modeling wide range semantic tasks including judgments semantic relatedness
word categorization.
several data sets assess well DSM captures human intuitions
semantic relatedness, Rubenstein Goodenough set (Rubenstein & Goodenough, 1965) WordSim353 (Finkelstein, Gabrilovich, Matias, Rivlin, Solan, Wolfman,
& Ruppin, 2002). Usually constructed asking subjects rate set word
pairs according similarity scale. Then, average rating pair taken
estimate perceived relatedness words (e.g., dollar-buck: 9.22, cord-smile:
0.31). measure well distributional model approximates human semantic intuitions,
usually correlation measure similarity scores generated model
human ratings computed. highest correlation aware WordSim353
set also employ 0.80 obtained model called Temporal
Semantic Analysis, captures patterns word usage time concepts
represented time series corpus temporally-ordered documents (Radinsky,
Agichtein, Gabrilovich, & Markovitch, 2011). temporal knowledge could integrated
perceptual knowledge encode model. direct comparison point,
Agirre, Alfonseca, Hall, Kravalova, Pasa, Soroa (2009) presented extensive evaluation distributional WordNet-based semantic models WordSim, achieving
maximum correlation 0.66 across various parameters.4
4. WordNet, available http://wordnet.princeton.edu/, large computational lexicon English
nouns, verbs, adjectives adverbs grouped sets synonyms (synsets), expressing
distinct concept.

6

fiMultimodal Distributional Semantics

Humans good grouping together words (or concepts denote)
classes based semantic relatedness (Murphy, 2002), therefore cognitive-aware
representation meaning must show proficiency also categorization (e.g., Poesio
& Almuhareb, 2005; Baroni et al., 2010). Concept categorization moreover useful
applications automated ontology construction recognizing textual entailment.
Unlike similarity ratings, categorization requires discrete decision group coordinates/cohyponyms class performed applying standard clustering techniques
model-generated vectors representing words categorized. example,
Almuhareb-Poesio data set (Almuhareb & Poesio, 2005), also employ below,
includes 402 concepts WordNet, balanced terms frequency degree ambiguity. distributional model Rothenhusler Schtze (2009) exploits syntactic
information reach state-of-the-art performance Almuhareb-Poesio data set (maximum clustering purity across various parameter: 0.79). window-based distributional
approach Baroni Lenci (2010), directly comparable text-based models,
achieves 0.65 purity.
semantic tasks DSMs applied include semantic priming, generation
salient properties concepts intuitions thematic fit verb arguments (see,
e.g., Baroni & Lenci, 2010; Baroni et al., 2010; McDonald & Brew, 2004; Pad & Lapata,
2007; Pad, Pad, & Erk, 2007). Distributional semantic vectors used wide
range applications require representation word meaning, particular
objective measure meaning relatedness, including document classification, clustering
retrieval, question answering, automatic thesaurus generation, word sense disambiguation,
query expansion, textual advertising areas machine translation (Dumais, 2003;
Turney & Pantel, 2010).
2.2 Visual Words
Ideally, build multimodal DSM, would like extract visual information
images way similar text. Thanks well-known image
analysis technique, namely bag-of-visual-words (BoVW), indeed possible discretize
image content produce visual units somehow comparable words text, known
visual words (Bosch, Zisserman, & Munoz, 2007; Csurka, Dance, Fan, Willamowski, &
Bray, 2004; Nister & Stewenius, 2006; Sivic & Zisserman, 2003; Yang, Jiang, Hauptmann,
& Ngo, 2007). Therefore, semantic vectors extracted corpus images
associated target (textual) words using similar pipeline commonly
used construct text-based vectors: Collect co-occurrence counts target words
discrete image-based contexts (visual words), approximate semantic relatedness
two words similarity function visual words representing them.
BoVW technique extract visual word representations documents inspired
traditional bag-of-words (BoW) method Information Retrieval. BoW turn
dictionary-based method represent (textual) document bag (i.e., order
considered), contains words dictionary. BoVW extends idea visual
documents (namely images), describing collection discrete regions, capturing
appearance ignoring spatial structure (the visual equivalent ignoring word
order text). bag-of-visual-word representation image convenient image7

fiBruni, Tran & Baroni






ffffff

fififi






Figure 1: Representing images BoVW: (i) Salient image patches keypoints contain rich local information detected represented vectors low-level
features called descriptors; (ii) Descriptors mapped visual words
basis distance centers clusters corresponding visual words


(the preliminary clustering step shown
figure); (iii) Images finally
represented bag-of-visual-words feature vector according distribution
visual words contain. Images depicting things rotations,
occlusions, small differences low-level descriptors might still similar
distribution visual words, hence object traced robustly
across images conditions change.

analysis point view translates usually large set high-dimensional local
descriptors single sparse vector representation across images. Importantly, size
original set varies image image, bag-of-visual-word representation
fixed dimensionality. Therefore, machine learning algorithms default expect
fixed-dimensionality vectors input (e.g., supervised classification unsupervised
clustering) used tackle typical image analysis tasks object recognition,
image segmentation, video tracking, motion detection, etc.
specifically, similarly terms text document, image local interest
points keypoints defined salient image patches contain rich local information
image. However keypoint types images come off-the-shelf like word
8

fiMultimodal Distributional Semantics

types text documents. Local interest points grouped types (i.e., visual
words) within across images, image represented number
occurrences type it, analogously BoW. following pipeline typically
followed. every image data set, keypoints automatically detected (note
recent approaches dense, pixelwise sampling keypoints preferred
detecting salient ones only, solution also adopt,
explained Section 4.2.2) represented vectors low-level features called descriptors.
Keypoint vectors grouped across images number clusters based
similarity descriptor space. cluster treated discrete visual word.
keypoints mapped onto visual words, image represented BoVW feature
vector recording many times visual word occurs it. way, move
representing image varying number high-dimensional keypoint descriptor vectors
representation terms single visual word count vector fixed dimensionality
across images, advantages discussed above. Visual word assignment
use represent image content exemplified Figure 1, two images
similar content described terms bag-of-visual-word vectors.
kind image content visual word captures exactly depends number
factors, including descriptors used identify represent keypoints, clustering
algorithm number target visual words selected. general, local interest points
assigned visual word tend patches similar low-level appearance;
local patterns need correlated object-level parts present images
(Grauman & Leibe, 2011).
2.3 Multimodal Distributional Semantics
availability large amounts mixed media Web, one hand,
discrete representation images visual words, other, escaped attention
computational linguists interested enriching distributional representations word
meaning visual features.
Feng Lapata (2010) propose first multimodal distributional semantic model.
generative probabilistic setting requires extraction textual visual features
mixed-media corpus, latent dimensions estimated
probabilistic process assumes document generated sampling textual
visual words. Words represented distribution set latent
multimodal dimensions topics (Griffiths et al., 2007) derived surface textual
visual features. Feng Lapata experiment collection documents downloaded
BBC News website corpus. test semantic representations
free association norms Nelson, McEvoy, Schreiber (1998) subset 253
pairs WordSim, obtaining gains performance visual information taken
account (correlations human judgments 0.12 0.32 respectively), compared
textual modality standalone (0.08 0.25 respectively), even performance still
well state-of-the-art WordSim (see Section 2.1 above).
main drawbacks approach textual visual data must
extracted corpus, thus limiting choice corpora used,
generative probabilistic approach, elegant, allow much flexibility
9

fiBruni, Tran & Baroni

two information channels combined. Below, re-implement Feng
Lapata method (MixLDA) training ESP-Game data set, source labeled
images adopt model. possible data set contains images
textual labels describing them. general, recapture Feng Lapatas
idea common latent semantic space latent multimodal mixing step pipeline
(see Section 3.2.1 below).
Leong Mihalcea (2011) also exploit textual visual information obtain multimodal distributional semantic model. Feng Lapata merge two sources
information learning joint semantic model, Leong Mihalcea propose strategy
akin call Scoring Level fusion below: Come separate text-
image-based similarity estimates, combine obtain multimodal score.
particular, use two combination methods: summing scores computing
harmonic mean. Differently Feng Lapata, Leong Mihalcea extract visual information corpus manually coded resource, namely ImageNet
database (Deng, Dong, Socher, Li, & Fei-Fei, 2009), large-scale ontology images.5 Using
handcoded annotated visual resource ImageNet faces sort problems
using manually developed lexical database WordNet faces respect
textual information, is, applications severely limited ImageNet coverage (for
example, ImageNet currently restricted nominal concepts), interest
model computational simulation word meaning acquisition naturally occurring language visual data somewhat reduced (humans learn meaning
mountain set carefully annotated images mountains little else crowding
occluding scene). evaluation, Leong Mihalcea experiment small subsets WordSim, obtaining improvements, although level report
(the highest reported correlation 0.59 56 word pairs). Furthermore use
data set tune test models.
Bruni, Tran, Baroni (2011) propose instead directly concatenate textand image-based vectors produce single multimodal vector represent words,
call Feature Level fusion below. text-based distributional vector representing word, taken state-of-the-art distributional semantic model (Baroni &
Lenci, 2010), concatenated vector representing word visual features, extracted images ESP-Game collection also use here.
obtain promising performance WordSim test sets, although appreciably lower
results report (we obtain maximum correlation 0.52 text-
image-based features used together; compare Table 2 below).
Attempts use multimodal models derived text images perform
specific semantic tasks also reported. Bergsma Goebel (2011) use textual
image-based cues model selectional preferences verbs (which nouns likely
arguments verbs). experiment shows several cases visual information
useful text task. example, looking textual corpora words
carillon, migas mamey, much useful information obtained guess
three plausible argument verb eat. hand, also show
5. http://image-net.org/

10

fiMultimodal Distributional Semantics

that, exploiting Google image search functionality,6 enough images words
found vision-based model edible things classify correctly.
Finally, evaluate multimodal models task discovering color concrete objects, showing relation words denoting concrete things
typical color better captured visual information also taken account (Bruni,
Boleda, Baroni, & Tran, 2012). Moreover, show multimodality helps distinguishing literal nonliteral uses color terms.
2.4 Multimodal Fusion
textual information used image analysis, mostly done different
aims ours: Text used improve image-related tasks, typically
attempt model relation specific images specific words textual passages
(e.g., Barnard, Duygulu, Forsyth, de Freitas, Blei, & Jordan, 2003; Berg, Berg, & Shih,
2010; Farhadi, Hejrati, Sadeghi, Young, Rashtchian, Hockenmaier, & Forsyth, 2010; Griffin,
Wahab, & Newell, 2013; Kulkarni, Premraj, Dhar, Li, Choi, Berg, & Berg, 2011).
contrast, (i) want use image-derived features improve representation word
meaning (ii) interested capturing meaning word types basis
sets images connected word, model specific word-image relations.
Despite differences, challenges addressed image analysis literature deals exploiting textual cues similar ones face. particular,
problem merging, fusing, textual visual cues common representational
space exactly face construct multimodal semantic space.
Traditionally, image analysis community distinguishes two classes fusion
schemes, namely early fusion late fusion. former fuses modalities feature space,
latter fuses modalities semantic similarity space, analogously call
Feature Level Scoring Level fusion, respectively. example, Escalante, Hrnadez,
Sucar, Montes (2008) propose image retrieval system multimodal documents.
early late fusion strategies combination image textual
channels considered. Early fusion settings include weighted linear combination
two channels global strategy different retrieval systems used contemporarily
entire, joint data set. Late fusion strategies include per-modality strategy,
documents retrieved using one channel hierarchical setting
first text, image combination used independently query database
results aggregated four weighted combinations. Vreeswijk, Huurnink,
Smeulders (2011) train visual concept classifier abstract subject categories
biology history using late fusion approach image text information
combined output level, is, first obtaining classification scores image-
text-based models separately joining them. Similarly multimodal mixing
step, Pham, Maillot, Lim, Chevallet (2007) Caicedo, Ben-Abdallah, Gonzlez,
Nasraoui (2012) propose early fusion two inputs mapped onto
latent space using dimensionality reduction techniques (e.g., Singular Value Decomposition).
multimodal representation obtained way directly used retrieve image
documents.
6. http://images.google.com/

11

fiBruni, Tran & Baroni

3. Framework Multimodal Distributional Semantics
section, general flexible architecture multimodal semantics presented.
architecture makes use distributional semantic models based textual visual
information build multimodal representation meaning. merge two sources,
uses parameter-based pipeline able capture previously proposed combination
strategies, advantage explored within single system.
3.1 Input Multimodal Architecture
construct multimodal representation meaning, semantic model single
modality implemented. Independently actual parameters chosen
creation (that, point view, black box), requirements
model satisfy order guarantee good functioning framework.
first place, modality must provide separate representation, leave room
various fusion strategies afterwards. Then, modality must encode semantic
information pertaining word interest fixed-size vectorial representation.
Moreover, assume text- image-based vectors normalized arranged
matrices words rows co-occurring elements columns.
follows, assume harvested matrix text-based semantic vectors,
one image-based semantic vectors set target words, representing,
respectively, verbal visual information words. Section 4 give
details specific implementation construct matrices.
3.2 Multimodal Fusion
pipeline based two main steps:
(1) Latent Multimodal Mixing: text vision matrices concatenated, obtaining single matrix whose row vectors projected onto single, common space
make interact.
(2) Multimodal Similarity Estimation: Information text- image-based
matrices combined two ways obtain similarity estimates pairs target
words: Feature Level Scoring Level.
Figure 2 describes infrastructure propose fusion. First, introduce mixing
phase promote interaction modalities call Latent Multimodal Mixing.
step part approaches would consider Feature Level fusion (see
below), keep separated might benefit Scoring Level fusion well.
mixing performed, proceed integrate textual visual features.
reviewed Section 2.4 above, literature fusion performed two main levels,
Feature Level Scoring Level. first case features first combined
considered single input operations, second case task performed separately
different sets features separate results combined. approach
advantages limitations incorporated
multimodal infrastructure together constitute call Multimodal Similarity
12

fiMultimodal Distributional Semantics

ff
fi













fi
fi






ff
fi








fi



Figure 2: Multimodal fusion combining textual visual information semantic
model.



Estimation. Feature Level approach requires one learning step (i.e., determining
parameters feature vector combination) offers richer vector-based representation
combined information, also used purposes (e.g., image text
features could used together train classifier). Benefits Scoring Level approach
include possibility different representations (in principle, even vectorial)
different similarity scores different modalities ease increasing (or decreasing)
number different modalities used representation.
3.2.1 Latent Multimodal Mixing
preparatory step textual visual components projected
onto common representation lower dimensionality discover correlated latent factors.
result new connections made source matrix taking account
information connections present matrix, originating patterns covariance overlap. Importantly, assume mixing done via dimensionality
reduction technique following characteristics: parameter k determines
13

fiBruni, Tran & Baroni

dimensionality reduced space fact k equals rank
original matrix reduced matrix identical considered good approximation
original one. commonly used Singular Value Decomposition reduction method
adopt mixing step satisfies constraints.
toy example mixing might beneficial, consider concepts pizza
coin, could use features text-based semantic vectors (i.e., record cooccurrences target words concepts part vector dimensions).
words likely occur similar contexts text, obviously visually similar. So, original text features pizza coin might highly correlated.
However, mixing multimodal space, might associated (have high
weights on) reduced space component, similar distributions
visual features cue roundness. Consequently, two textual features originally
uncorrelated might drawn closer multimodal mixing, corresponding concepts visually similar, resulting mixed textual features are, sense,
visually enriched, vice versa mixed visual features (interestingly, psychologists
shown that, certain conditions, words pizza coin, strongly
associated perceptually similar, prime other; e.g., Pecher, Zeelenberg, & Raaijmakers, 1998).
Note matrices obtained splitting reduced-rank matrix back
original textual visual blocks number feature columns original
textual visual blocks, values smoothed dimensionality
reduction (we explain details achieved specific implementation
next paragraph). matrices used calculate similarity score word
pair (re-)merging information feature scoring levels.
Mixing SVD implementation, perform mixing across text- imagebased features applying Singular Value Decomposition (SVD)7 matrix obtained concatenating two feature types row-wise (so row concatenated
matrix describes target word textual visual space). SVD widely used technique
find best approximation original data points space lower underlying
dimensionality whose basis vectors (principal components latent dimensions)
selected capture much variance original space possible (Manning,
Raghavan, & Schtze, 2008, Ch. 18). performing SVD concatenated textual
visual matrices, project two types information space,
described linear combinations principal components. Following description
Pham et al. (2007), SVD matrix rank r factorization form
= U V




U : matrix eigenvectors derived




: r r diagonal matrix singular values

: square roots eigenvalues







V : matrix eigenvectors derived

7. Computed SVDLIBC: http://tedlab.mit.edu/~dr/SVDLIBC/

14

fiMultimodal Distributional Semantics

context, matrix given normalizing two feature matrices separately
concatenating. selecting k largest values matrix keeping
corresponding columns matrices U V , reduced matrix Mk given
Mk = Uk k Vkt
k < r dimensionality latent space. Mk keeps number
columns/dimensions , rank k. k free parameter tune
development sets. Note k equals rank original matrix, trivially
Mk = . Thus consider performing SVD reduction special case
SVD, helps searching optimal parameters.
Note also that, n columns, Vkt k n matrix, Mk
number columns . first j columns contain textual features, columns
j + 1 n contain visual features, hold Mk , although latter
values features affected global SVD smoothing. Thus,
current implementation pipeline Figure 2, block splitting attained simply
dividing Mk textual mixed matrix containing first j columns, visual mixed
matrix containing remaining columns.
3.2.2 Multimodal Similarity Estimation
Similarity Function Following distributional hypothesis, DSMs describe word
terms contexts occurs. Therefore, measure similarity two words
DSMs need function capable determining similarity two descriptions (i.e.,
two semantic vectors). literature, many different similarity functions
used compare two semantic vectors, including cosine similarity, Euclidean distance, L1
norm, Jaccards coefficient, Jensen-Shannon divergence, Lins similarity. extensive
evaluation different similarity measures, see work Weeds (2003).
focus cosine similarity since shown effective measure
many semantic benchmarks (Bullinaria & Levy, 2007; Pad & Lapata, 2007). Also,
given system based geometric principles, cosine, together Euclidean
distance, principled choice measure similarity. example,
measures listed above, developed probabilistic considerations,
applicable vectors encode well-formed probability distributions, typically
case (for example, multimodal mixing, vectors might contain negative
values).
cosine two semantic vectors b dot product divided product
lengths:
Pi=n

i=1 ai bi
qP
i=n 2
i=n 2


i=1
i=1 bi

cos(a, b) = qP

cosine ranges 0 (orthogonal vectors) |1| (parallel vectors pointing
opposite directions cosine values 1 -1, respectively).
15

fiBruni, Tran & Baroni

Feature Level Fusion Feature Level fusion (FL), use linear weighted fusion
method combine text- image-based feature vectors words single representation use latter estimate similarity pairs. linear weighted
combination function defined
F = Ft (1 ) Fv
vector-concatenate operator.
Scoring Level Fusion Scoring Level fusion (SL), text- image-based matrices
used estimate similarity pairs independently. scores combined obtain
final estimate using linear weighted scoring function:
= St + (1 ) Sv
General Form Special Cases Given fixed normalized text- image-based
matrices, multimodal approach parametrized k (dimensionality latent space),
FL vs. SL, (weight text component FL similarity estimation) (weight text
component SL).
Note k=r, r rank original combined matrix, Latent Multimodal
Mixing returns original combined matrix (no actual mixing). Picking SL =1
=0 corresponds using textual visual matrix only, respectively. thus derive
special cases models text (k=r, SL, =1) images (k=r, SL, =0)
used (called Text Image models Results section below). simple approach
Bruni et al. (2011), two matrices concatenated without mixing,
parametrization k=r, FL, =0.5 (called NaiveFL model, below). summing approach
Leong Mihalcea (2011) corresponds k=r, SL, =0.5 (NaiveSL, below). Picking
k<r, SL, =1 amounts performing latent multimodal mixing, using textual
features only; reverse mixed image features = 0 (Textmixed
Imagemixed , respectively). Reducing models parametrized
approach means that, given development set specific task requires similarity
measurements, discover data-driven way various models best
task hand (for example, certain task might discover better
using text only, another mixed text features, yet another text image
features, on).
Formally, given set k1 , ..., kn R n dimensionalities latent space (with kn
equal original dimensionality, arbitrary steps chosen values),
sets 1 , ..., R potential weights text block FL (with 1 = 0 = 1)
1 , ..., l R l weights text block SL (with 1 = 0 l = 1),
calculate number possible configurations explore totc = n(m + l). Unless n,
l large (i.e., consider small intervals values tested),
completely feasible perform full search best parameters certain task
without approximate optimization methods. experiments, n = 9, = l = 11,
consequently totc = 198.
16

fiMultimodal Distributional Semantics

4. Implementation Details
implementation multimodal framework visual feature extraction
procedure publicly available open source.8 Moreover visual feature extraction
procedure presented Bruni, Bordignon, Liska, Uijlings, Sergienya (2013).
4.1 Construction Text-Based Semantic Matrix
reviewed Section 2.1 above, text-based distributional model encoded matrix whose rows semantic vectors representing meaning set target words.
Important parameters model choice target contextual elements,
source corpora used extract co-occurrence information, context delimiting
scope co-occurrence, function transform raw counts statistical association scores downplaying impact frequent elements.
Source Corpora collect co-occurrence counts concatenation two corpora,
ukWaC Wackypedia (size: 1.9B 820M running words, tokens, respectively).
ukWaC collection Web pages based linguistically-controlled crawl .uk
domain conducted mid 2000s. Wackypedia built mid-2009 dump
English Wikipedia. corpora automatically annotated lemma (dictionary form) part-of-speech (POS) category information using TreeTagger,9
freely publicly available,10 widely used linguistic research.
Target Context Elements Since source corpora annotated lemma
part-of-speech information, take account extracting target context
words (e.g., string sang treated instance verb lemma sing). collect
semantic vectors set 30K target words (lemmas), namely top 20K frequent
nouns, 5K frequent adjectives 5K frequent verbs combined corpora.
30K lemmas also employed contextual elements (consequently, textbased semantic models encoded 30K30K matrix). Note combine
text matrices image-based ones, preserve rows (target words)
also image-based vector, trimming matrix size 20,52530K.
Context define context terms words co-occur within window fixed
width, tradition popular HAL model (Lund & Burgess, 1996). Window-based
models attractive simplicity fact require resourceintensive advanced linguistic annotation. moreover reported
state art various semantic tasks (Rapp, 2003; Sahlgren, 2008), Bruni,
Uijlings, Baroni, Sebe (2012) show window-based methods use
outperform document-as-context model sophisticated syntax- lexicalpattern-based model MEN WordSim test sets introduced Section 5.2
(see also post-hoc analysis using document-based model discussed end
Section 5.2.2 below). consider two variants, Window2 Window20 (we chose
particular variants arbitrarily, representatives narrow wide windows, respectively).
8. See https://github.com/s2m/FUSE/ https://github.com/vsem/, respectively.
9. http://www.ims.uni-stuttgart.de/projekte/corplex/TreeTagger/
10. http://wacky.sslmit.unibo.it/

17

fiBruni, Tran & Baroni

Window2 records sentence-internal co-occurrence nearest 2 content words left
right target word (function words articles prepositions ignored).
Window20 considers larger window 20 content words left right target.
narrower window expected capture narrower kind semantic similarity,
one exists terms closely taxonomically related, example coordinate
concepts (dog cat) pairs superordinate subordinate concepts (animal
dog). rationale behind expectation terms share many narrow-window
collocates similar, semantically syntactically.
hand, broader window capture broader kind topical similarity, one
would expect words tend occur paragraphs (for example, war oil,
rather distant concepts taxonomic sense, might easily occur
discourse). See work Sahlgren (2006) discussion effects context
width distributional semantic models.
Association Score transform raw co-occurrence counts nonnegative Local Mutual Information (LMI) association scores. LMI scores obtained multiplying raw
counts Pointwise Mutual Information, nonnegative case close approximation Log-Likelihood Ratio scores, one widely used weighting
schemes computational linguistics (Evert, 2005). nonnegative LMI target element
context element c defined as:


P(t, c)
,0
P(t)P(c)



LM I(t, c) = max Count(t, c) log

worth observing that, extensive study parameters affect quality
semantic vectors, Bullinaria Levy (2007) Bullinaria Levy (2012) found
model similar Window2 (co-occurrence statistics ukWaC, narrow window,
lemmatized content word collocates, nonnegative pointwise mutual information instead
LMI) performs near top variety semantic tasks. Thus, independent
grounds claim using state-of-the-art text-based model.
4.2 Construction Image-Based Semantic Matrix
Given image-based semantic vectors novelty respect text-based ones,
next subsections dedicate space constructed them, including
full details source corpus utilize input pipeline (Section 4.2.1),
particular image analysis technique choose extract visual collocates finally
arrange semantic vectors constitute visual block distributional
semantic matrix (Section 4.2.2).
4.2.1 Image Source Corpus
adopt source corpus ESP-Game data set11 contains 100K images, labeled
famous game purpose developed Louis von Ahn, two
11. http://www.cs.cmu.edu/~biglou/resources/

18

fiMultimodal Distributional Semantics


fffi fiff
fifi fffi
fifi

fffi
ff fififf fi



fi ff

fi

fififffi

fifi


fifi ff
fi ff

fi ff fi
fi


Figure
3: Samples images tags ESP-Game data set

people partnered online must independently rapidly agree appropriate word
label random selected images. word entered partners certain number
game rounds, word added tag image, becomes taboo term
next rounds game involving image, encourage players produce
terms describing image (Von Ahn, 2006). tags images data set form
vocabulary 20,515 distinct word types. Images 14 tags average (4.56 standard
deviation), word tag 70 images average (737.71 standard deviation).
words format text-based models, tags lemmatized POS-tagged. annotate words parts speech, could
run POS-tagger, since words context (i.e., tag appears alphabetically
within small list words labeling image within ordinary sentence
required POS-tagger). Thus used heuristic method, assigned words
ESP-Game vocabulary frequent tag textual corpora.
ESP-Game corpus interesting data set point view since,
one hand, rather large know tags contains related images.
hand, product experts labelling representative images,
noisy annotation process often poor-quality uninteresting images (e.g., logos) randomly
downloaded Web. Thus, analogously characteristics textual corpus,
algorithms must able exploit large-scale statistical information, robust
noise. cleaner illustrative examples concept available
carefully constructed databases ImageNet (see Section 2.3), noisy tag annotations
19

fiBruni, Tran & Baroni

available massive scale sites Flickr12 Facebook,13 want
eventually exploit data important methods work noisy input.
advantage ESP-Game respect ImageNet images associated
concrete noun categories also adjectives, verbs nouns related
events (e.g., vacation, party, travel, etc). practical point view, clean
data sets ImageNet still relatively small, making experimentation standard
benchmarks difficult. concrete, looking benchmarks experiment with, mid
2013, ImageNet covers half pairs WordSim353 test set, less
40% Almuhareb-Poesio words. future want explore
extent higher-quality data sources improve image-based models, require larger
databases, benchmarks relying restricted vocabulary.
image samples Figure 6 exemplify different kinds noise characterize
ESP-Game data set. top bottom left top right images
scene cluttered partially occluded. top center image hardly good representative accompanying words building, tower(s) square. Similarly, center
bottom image partially good illustration coin, certainly good
example man! Finally, bottom right image useless visual feature extraction
perspective.
4.2.2 Image-Based Semantic Vector Construction
collect co-occurrence counts target words image-based contexts adopting
BoVW pipeline that, already explained 2.2, particularly convenient order
discretize visual information visual collocates. adopting currently
considered standard implementation BoVW. future, could explore
cutting-edge ways build image-based semantic vectors, local linear encoding
(Wang, Yang, Yu, Lv, Huang, & Gong, 2010) Fisher encoding (Perronnin, Sanchez, &
Mensink, 2010). Chatfield, Lempitsky, Vedaldi, Zisserman (2011) present systematic
evaluation several recent methods.
current implementation composed following steps: (i) Extraction
local descriptors, is, vectors low-level features encode geometric
information area around keypoint, i.e., pixel interest (here, SIFT descriptors); (ii) Constructing vector representation image assigning
local descriptors clusters corresponding visual words, recording distribution
across clusters vector (this presupposes preliminary step clustering
algorithm applied whole image collection sample, determine visual word vocabulary) (iii) Including spatial information representation
spatial binning; (iv) Summing visual word occurrences across list images associated
word label obtain co-occurrence counts associated word label
transforming counts association scores, analogously done text
analysis. process (without spatial binning) schematically illustrated Figure 4,
hypothetical example three images collection labeled
word monkey. details follow.
12. http://www.flickr.com
13. http://www.facebook.com

20

fiMultimodal Distributional Semantics

Dense sampling
pixels
interest

Mapping SIFT
descriptors visual
word clusters

Extracting
local
descriptors

SIFT 4x4

monkey:

0

4

monkey

3

4

0

3

+

Labeled
images

monkey:

2

11

Instance
counts

+

monkey
monkey:

0

3

9

0

monkey:

2

18

12

7

monkey
Total
counts

Figure 4: procedure build image-based semantic vector target word. First,
bag-of-visual-word representation image labeled target word
computed (in case, three images labeled target word monkey).
Then, visual word occurrences across instance counts summed obtain
co-occurrence counts associated target word.

Local Descriptors construct local descriptors pixels interest use ScaleInvariant Feature Transform (SIFT) (Lowe, 1999, 2004). chose SIFT invariance
image scale, orientation, noise, distortion partial invariance illumination changes.
SIFT vector formed measuring local image gradients region around
location orientation feature multiple scales. particular, contents
4 4 sampling subregions explored around keypoint. resulting
16 samples, magnitude gradients 8 orientations calculated, would
already result SIFT feature vector 128 components. However, extract color
SIFT descriptors HSV (Hue, Saturation Value) space (Bosch, Zisserman, & Munoz,
2008). use HSV encodes color information similar way humans
21

fiBruni, Tran & Baroni

do. compute SIFT descriptors HSV component. gives 3128 dimensions
per descriptor, 128 per channel. Color channels averaged obtain final
128-dimensional descriptors. experimented also different color scales,
LUV, LAB RGB, obtaining significantly worse performance compared HSV
development set introduced 5.2.1, therefore conduct experiments
them. Van de Sande, Gevers, Snoek (2010) present systematic evaluation color
features.
Instead searching interesting keypoints salient patch detection algorithm,
use computationally intensive also thorough dense keypoint sampling
approach, patches fixed size localized regular grid covering whole image
repeated multiple scales. SIFT descriptors computed regular grid every
five pixels, four scales (10, 15, 20, 25 pixel radii) zeroing low contrast descriptors.
extraction use vl_phow command included VLFeat toolbox (Vedaldi
& Fulkerson, 2010). implementation shown close Lowes original
much faster dense feature extraction. Nowak, Jurie, Triggs (2006) report
systematic evaluation different patch sampling strategies.
Importantly, SIFT feature vectors extracted large corpus representative
images populate feature space, subsequently quantized discrete number
visual words clustering. step performed, every SIFT vector (local descriptor)
original new images translated visual word determining
cluster nearest quantized space.
Visual Vocabulary map SIFT descriptors visual words, first cluster local
descriptors extracted images training image corpus 3128-dimensional
space using k-means clustering algorithm, encode descriptor index
cluster (visual word) belongs. k-means common way constructing
visual vocabularies (Grauman & Leibe, 2011). Given set x1 , ..., xn RD n training
descriptors, k-means aims partition n descriptors k sets (k n) minimize
P
cumulative approximation error ni=1 ||xi qi ||2 , K centroids 1 , ..., K RD
data-to-means assignments q1 , ..., qN {1, ..., K}. use approximated version
k-means called Lloyds algorithm (1982) implemented VLFeat toolbox.
construct visual vocabulary extracted SIFT descriptors 100K
images ESP-Game data set. tune parameter k used MEN development
set (see Section 5.2.1). varying k 500 5000 steps 500, found
optimal k 5000. likely performance peaked even 5000
visual words enhancements could attained adopting larger visual vocabularies
via efficient implementations BoVW pipeline, example Chatfield et al.
(2011).
Image Representation Given set descriptors x1 , ..., xn sampled image, let
qi assignment descriptor xi corresponding visual word. bag-ofvisual-words representation image nonnegative vector v Rk vk = |{i :
qi = k}|, q ranging 1 number visual words vocabulary (in
case, 5000). representation vector visual words obtained via hard quantization
(i.e., assignment local descriptor vector single nearest codeword).
22

fiMultimodal Distributional Semantics

Spatial Binning consolidated way introducing weak geometry BoVW use
spatial histograms (Grauman & Darrell, 2005; Lazebnik, Schmid, & Ponce, 2006).
main idea divide image several (spatial) regions perform entire visual
word extraction counting pipeline region concatenate vectors.
experiments spatial regions obtained dividing image 4 4, total
16 regions. Therefore, crossing values k spatial region, increase
feature dimensions 16 times, total 80,000 components vectors.
Co-occurrence Counts Weighting BoVW representations built,
target (textual) word associated list images labeled it;
visual word occurrences across list images summed obtain co-occurrence
counts associated target (textual) word. total, 20,515 target words (those
constitute ESP-Game tags) image-based semantic vector associated.
Also image-based semantic matrix, like text-based one, raw counts
transformed nonnegative LMI. difference LMI computed
target element textual word context element c visual word instead.
Note that, like standard textual approach, accumulating visual words
images contain word without taking account fact words might
denote concepts multiple appearances, polysemous even hide homonyms
(our bank vector include visual words extracted river well building pictures).
interesting direction research would cluster images associated
word order distinguish visual senses word, e.g., along lines
done textual models Reisinger Mooney (2010).
4.3 Multimodal Fusion Tuning
performed two separate parameter optimizations, one specifically semantic relatedness task (using MEN development, see Section 5.2.1) specifically
clustering task (using Battig, see Section 5.3.1). determined best model
performing exhaustive search across SVD k (from 24 212 powers 2), FL SL
varying 0 1 (inclusive) steps 0.1 similarly . total, 198 models explored one highest performance development data
chosen. Note tuning performed separately Window2 Window20 models.

4.4 MixLDA
reimplement Feng Lapatas approach (discussed Section 2.3) comparable
setting ours, treat ESP-Game data set mixed-media corpus
image together associated tags constitutes document. image, extract
image-based features procedure described 4.2.2 use words
labeling image obtain text-based features. features stored
term-by-document matrix, image treated document term
either textual tag visual word extracted image. obtain matrix size
90K100K, 10K textual words (the word list resulting intersection
words used experimental data sets), 80K visual words 100K documents (images).
23

fiBruni, Tran & Baroni

Latent Dirichlet Allocation (MixLDA) model trained matrix tuned
MEN development set varying number topics Kt .14 optimal value find
Kt = 128. MixLDA, target word evaluation set represented
vector giving distribution 128 latent topics.

5. Experiments
test semantic representation three different tasks, is, evaluating distribution different kinds semantic relations among words neighbours (5.1), modeling
word relatedness judgments (5.2) clustering words superordinate concepts (5.3).
Together, tasks give us clear idea general quality models
relative contribution visual information meaning representation.
5.1 Differentiation Semantic Relations
acquire qualitative insight well text- image-based models capturing word meaning, test BLESS (Baroni-Lenci Evaluation Semantic Similarity), benchmark recently introduced Baroni Lenci (2011) analyze specific
aspects lexico-semantic knowledge. Rather focusing point estimate quality
model specific semantic task, BLESS allows us assess overall pattern
semantic relations model tends capture. run BLESS evaluation
combining textual visual channels together sanity check semantic
meaningfulness image-based vectors, looking potential complementary information respect text motivate fusion. Note since
combining textual visual sources, tuning parameters report.
5.1.1 Benchmark Method
BLESS contains set 200 pivot words denoting concrete concepts (we use 184 pivots,
since remaining 16 sufficiently large set related words covered
models). pivots, data set contains number related words,
relata, instantiating following 8 common semantic relations pivots: coord:
relatum noun co-hyponym (coordinate) pivot (alligator-lizard);
hyper: relatum noun hypernym (superordinate) pivot (alligatorreptile); mero: relatum noun referring meronym, is, part material
pivot (alligator-teeth); attri: relatum adjective expressing attribute
pivot (alligator-ferocious); event: relatum verb referring action
event involving concept (alligator-swim); ran.n, ran.j ran.v, finally, control
cases pivot matched set random nouns (alligator-trombone), adjectives
(alligator-electronic) verbs (alligator-conclude), respectively.
pivot, BLESS contains set relata category (ranging 7 hypernyms 33 random nouns per pivot average). way, BLESS highlight
broader semantic properties model independently specific preferences.
example, model assigns high score alligator-ferocious model
assigns high score alligator-green correctly treated models picked
14. LDA computed Gensim: http://radimrehurek.com/gensim/

24

fiMultimodal Distributional Semantics

relevant attribute alligators. time, comparison specific relata
selected models allows granular qualitative analysis differences.
Following guidelines Baroni Lenci (2011), analyze semantic model
follows. compute cosine model vectors representing 184
pivots relata, picking relatum highest cosine
8 relations (the nearest hypernym, nearest random noun, etc.). transform
8 similarity scores collected way pivot onto standardized z scores (to
get rid pivot-specific effects), produce boxplot summarizing distribution
scores per relation across 184 pivots (for example, leftmost box first panel
Figure 5 reports distribution 184 standardized cosines nearest coordinate relata
respective pivots). Besides analyzing distributions qualitatively, also discuss
significant differences cosines different relation types obtained via
Tukeys Honestly Significance tests, thus correcting multiple pairwise comparisons (Abdi
& Williams, 2010).
5.1.2 Results
Fig. 5, report BLESS nearest relata distributions purely textual model Window20 (the Window2 distribution shows even stronger skew favour coordinate
neighbours) purely visual model call Image next sections. patterns
produced text-based model (left panel) illustrate sensible word meaning profile
look like: coordinates similar terms (an alligator maximally similar
crocodile), followed superordinates (reptile) parts (teeth). Semantically related
adjectives (attri: ferocious) verbs (event: swim) less close pivots, still
random item.
right panel shows distribution relata image-based semantic vectors.
overall pattern quite similar one observed text-based vectors:
clear preference coordinates, followed hypernyms parts, attributes
events, random relata away pivots semantically
meaningful categories. models, coordinates significantly closer relata
hypernyms meronyms, significantly closer attributes events,
turn significantly closer random category. Although difference
hypernyms parts significant either representation, intriguingly
image-based vectors show slight preference imageable parts (teeth)
abstract hypernyms (reptile). difference statistical import one
events attributes, text-based model shows significant preference
events, whereas two categories statistically indistinguishable image-based
model (as see shortly, relative preference latter attributes probably
due tendency pick perceptual adjectives denoting color size).
Looking closely specific relata picked text- image-based models,
striking differences pertain, again, attributes. text- image-based
models picked attribute pivot 20% cases (compare 40%
overlap across non-random relation types). Table 1 reports attributes picked
text- vs. image-based models 20 random cases two mismatch.
25

fiBruni, Tran & Baroni

Image-based semantic vectors

-2

-2

-1

-1

0

0

1

1

2

2

Text-based semantic vectors

COORD

HYPER

MERO

ATTRI

EVENT

RAN.N

RAN.J

RAN.V

COORD

HYPER

MERO

ATTRI

EVENT

RAN.N

RAN.J

RAN.V

Figure 5: Distribution z-normalized cosines words instantiating various relations across
BLESS pivots. Text-based vectors Window20 model.

pivot
cabbage
carrot
cherry
deer
dishwasher
elephant
glider
gorilla
hat
hatchet

text
leafy
fresh
ripe
wild
electric
wild
heavy
wild
white
sharp

image
white
orange
red
brown
white
white
white
black
old
short

pivot
helicopter
onion
oven
plum
sofa
sparrow
stove
tanker
toaster
trout

text
heavy
fresh
electric
juicy
comfortable
wild
electric
heavy
electric
fresh

image
old
white
new
red
old
little
hot
grey
new
old

Table 1: Attributes preferred text- (Window20) vs. image-based models.

26

fiMultimodal Distributional Semantics

immediately clear table that, despite fact pivots nouns
denoting concrete concepts, text-based model almost never picks adjectives denoting
salient perceptual properties (and particular visual properties: white hat leafy
cabbage). text-based model focuses instead encyclopedic properties fresh,
ripe, wild, electric comfortable. line earlier analyses ungrounded
semantics provided text-based models (Andrews et al., 2009; Baroni et al., 2010; Baroni
& Lenci, 2008; Riordan & Jones, 2011), differs greatly trend found
image-based model. 12/20 cases, closest attribute latter model color.
remaining cases, size (short, little), one instance hot and, surprisingly, four
old.
conclude, analysis presented confirms, one hand, hypothesis
image-based distributional vectors contain sufficient information capture network
sensible word meaning relations. other, intriguing differences relations picked text- image-based models, pointing complementarity.
5.2 Word Relatedness
standard distributional semantics literature (Budanitsky & Hirst, 2006; Sahlgren,
2006), assess performance models task predicting degree semantic relatedness two words rated human judges. test models
WS MEN benchmarks.
5.2.1 Benchmarks Method
WS, is, WordSim35315 (see also Section 2.1) widely used benchmark constructed
asking 13 subjects rate set 353 word pairs 11-point meaning similarity scale
averaging ratings (e.g., dollar/buck gets high average rating, professor/cucumber
low one). target words cover 252 WS pairs (thus, correlations reported
directly comparable reported studies used WS). However,
text-based models much higher WS coverage (96%). evaluated larger WS
set cover, Window2 Window20 achieve 0.64 0.68 correlations, respectively.
thus comparing multimodal approach purely textual models
state art WS (see results reported Section 2.1 above).
second benchmark use, MEN (for Marco, Elia Nam, resource creators)
developed us, specifically purpose testing multimodal models. created
large data set that, comparable WS benchmarks commonly used
computational semantics community, contains words appear image
labels ESP-Game MIRFLICKR-1M16 collections, thus ensuring full coverage
researchers train visual models resources. MEN consists 3,000 word pairs
[0, 1]-normalized semantic relatedness ratings provided Amazon Mechanical Turk
workers (via CrowdFlower17 interface). example, beach/sand MEN score
0.96, bakery/zebra received 0 score.
15. http://www.cs.technion.ac.il/~gabr/resources/data/wordsim353/
16. http://press.liacs.nl/mirflickr/
17. http://crowdflower.com/

27

fiBruni, Tran & Baroni

Compared WS, MEN sufficiently large allow us separate development
test data, avoiding issues overfitting. use indeed 2,000 MEN pairs (development set)
model tuning 1,000 pairs evaluation (test set). Importantly, development
set used find best configuration MEN test set WS.
Thus, WS evaluation illustrates well parameters learned training data
specific data set generalize applied semantic task different
data set.
Models evaluated follows. pair data set, compute cosine
model vectors representing words pair, calculate Spearman
correlation cosines (pooled) human ratings pairs, idea
higher correlation better model simulate relatedness
scores.
MEN Construction earlier version MEN used first time
authors Bruni et al. (2012) since current article first major publication
focus specifically it, recently improved benchmark
extending ratings, provide details constructed.
word pairs constitute MEN randomly selected words occur
least 700 times concatenated ukWaC Wackypedia text corpora least 50
times tags ESP-Game MIRFLICKR-1M tagged image collections. order
avoid picking pairs weakly related, would happen sample
random word pairs list, ranked possible pairs cosines according
text-based model Window20. gather 3000 word pairs needed construction
MEN, subsequently picked first 1000 word pairs, another 1000 sampled
pairs placed 1001 3000 cosine-ranked list last block 1000 pairs
remaining items.
acquire human semantic relatedness judgments, decided ask comparative
judgments two pair exemplars time rather absolute scores single pairs,
done creators WS. constitute natural way evaluate
target pairs, since human judgments comparative nature. person evaluates
given target, vacuum, relation certain context.
Moreover, binary choices preferred make construction right
wrong control items straightforward (see Footnote 18). Operationally, word pair
randomly matched comparison pair coming set 3000 items
rated single Turker either less related comparison item.
validity approach confirmed high annotation accuracy observe
control set,18 high correlation MEN scores ratings collected
Likert scale report below.
18. control items correct annotations created prior running job Amazon Mechanical Turk,
act hidden tests randomly shown Turkers complete job. way,
calculate quality contributors performance reject annotations accuracy
drops certain percentage (we set required minimum precision equal 70%, obtained
almost 100% average accuracy overall). Control items also great help train quickly new workers
perform required task. create control items harvested two equally-sized sets word
pairs WS, one containing pairs high relatedness score, one containing pairs
low relatedness score. control item obtained juxtaposing high score pair
low score pair treating pair higher score one selected

28

fiMultimodal Distributional Semantics

instructions, annotators warned sometimes candidate pairs could
contain words related meaning cases asked pick pair
strongly related words (e.g., wheels-car dog-race somewhat related pairs,
first one preferred every car wheels every dog involved
race). cases, annotators could find neither pair contains closely related
words, cases instructed pick pair contained slightly
related words (e.g., neither auction-car cup-asphalt closely related words,
first pair picked fancy vintage cars sold auctions). requested
participants native speakers accepted connecting English
speaking country. cannot guarantee non-natives take part study,
subject filtering techniques based control pairs (see Footnote 18) ensures
data speakers good command English retained.
transform binary preference data relatedness scores retrieved pairs,
evaluated 50 randomly picked comparison pairs, thus received score
50-point scale (given number times 50 pair picked
related two). score subsequently normalized 0 1 dividing
number times pair picked related 50. example, fun-night
chosen related comparison pair 20 times, thus normalized score
given 20 50 = 0.4. Note that, comparison, recorded preference
assigned one two pairs, avoid dependencies final scores assigned
different pairs (that is, times pair selected random comparison item
another pair counted ratings pair).
raters saw MEN pairs matched different random items, number
pairs also varying rater rater, possible compute annotator agreement
scores MEN. However, get sense human agreement, first third author
rated 3,000 pairs (presented different random orders) standard 1-7 Likert scale.
Spearman correlation two authors 0.68, correlation average
ratings MEN scores 0.84. one hand, high correlation suggests
MEN contains meaningful semantic ratings. other, also taken
upper bound computational models realistically achieve simulating
human MEN judgments.
high-score MEN pairs include pairs terms strictly taxonomically close (cathedral-church: 0.94) also terms connected broader semantic
relations, whole-part (flower-petal: 0.92), item related event (boat-fishing: 0.9),
etc. reason, prefer refer MEN semantic relatedness rather
similarity score data set. Note WS also capturing broader notion relatedness (Agirre et al., 2009). MEN publicly available downloaded from:
http://clic.cimec.unitn.it/~elia.bruni/MEN.
5.2.2 Results
Table 2 reports correlations MEN testing WS data sets using either
Window2 Window20 textual model. automated tuning method selected k = 29
annotators related. control items manually checked. Examples control items
hotel-word vs. psychology-depression, telephone-communication vs. face-locomotive.

29

fiBruni, Tran & Baroni

Model
Text
Image
NaiveFL
NaiveSL
MixLDA
Textmixed
Imagemixed
TunedFL
TunedSL

Window2
MEN WS
0.73
0.70
0.43
0.36
0.75
0.67
0.76
0.69
0.30
0.23
0.77 0.73
0.55
0.52
0.78 0.72
0.78 0.71

Window20
MEN WS
0.68
0.70
0.43
0.36
0.73
0.67
0.74
0.64
0.30
0.23
0.74 0.75
0.57
0.51
0.76 0.75
0.77 0.72

Table 2: Spearman correlation models MEN WordSim (all coefficients significant p < 0.001). TunedFL model selected automatically MEN
development data; TunedSL automatically tuned fixing SL similarity estimation.

(when textual information comes Window2) k = 210 (with Window20) optimal,
Feature Level (FL) similarity estimation = 0.5 cases (since input
matrices row-normalized, latter setting assigns equal weights textual
visual components). models called TunedFL table. Scoring Level
(SL) strategy (again similar weights assigned two channels, k values
TunedFL) performed slightly worse TunedFL, report results
best SL-based models tuned development MEN data well (TunedSL).
models reported table (NaiveFL, NaiveSL, MixLDA, Textmixed Imagemixed ),
parameters tuned manually order gain insights combination strategies
representing ideas earlier literature.19
first two rows table show results text- image-based models,
mixing. Text shows comparable performances data sets. Image correlates
significantly better MEN WS correlations lower Text,
accordance found earlier studies. next three rows find
results earlier multimodal approaches took consideration (Bruni et al., 2011;
Feng & Lapata, 2010; Leong & Mihalcea, 2011). NaiveFL approach (analogous
Bruni et al.s method), textual visual matrices concatenated without
mixing, performs slightly better Text MEN, attains lower performance WS.
Also NaiveSL (equivalent Leong Mihalceas summing approach), text
image sources combined scoring level, obtains improvements MEN, loosing
several correlation points WS compared Text.
implementation MixLDA achieves poor results MEN WS. One
might attribute fact Feng Lapatas approach constrained using
source textual visual model image data set poor source
19. Textmixed Imagemixed , best k values found development data.
set 210 textual sources.

30

fiMultimodal Distributional Semantics

Textmixed
TunedFL
TunedSL

Window2
0.47
0.46
0.46

Window20
0.49
0.49
0.47

Table 3: Pearson correlation best multimodal combinations WordSim
subset covered Feng Lapata (2010) (all coefficients significant p <
0.001; Pearson used instead Spearman full comparability Feng
Lapata). models assigned 0 similarity 71/253 pairs
missing vector. Feng Lapata (2010) report 0.32 correlation MixLDA.

textual data. approach however also outperforming original MixLDA
large margin latter WS test set, strongly disfavoured. particular,
Feng Lapata (2010) report correlation 0.32 subset 253 WS pairs covered
model. tested system subset, despite fact
missing one vectors 71 pairs (almost one third), models
forced assign 0 cosines cases. Despite huge handicap, models
still attaining much higher correlations original MixLDA Feng Lapata
pairs, illustrated interesting fusion strategies Table 3.
Analyzing effects fusion strategies, first see uniform enhancement MEN WS Textmixed Imagemixed (the models obtained first
performing latent multimodal mixing combined matrix, using textual features Textmixed visual features Imagemixed ). Textmixed reaches best
performance overall WS source textual models, significantly better
Text MEN according two-tailed paired permutation test (Moore & McCabe,
2005). Looking automatically selected TunedFL model, reaches best performance overall. significantly outperforms Text models data sets,
significantly better Textmixed MEN Window20 (the difference approaching significance Window2 well: p = 0.06). TunedSL also competitive.
also significantly better Text window sizes Textmixed Window20.
noticeably worse TunedFL WS Window20 only, actually
slight advantage MEN Window20 (the difference TunedFL TunedSL
never significant).
worth remarking Textmixed bit worse full fusion models,
still achieves high correlations human judgments extremely high
correlation TunedFL best model ( = 0.98). suggests
benefits multimodality already captured latent mixing. Textmixed attractive
model less parameters whole pipeline compact
TunedFL, since discards visual features using mixing.
Validating Results shown significant improvements visual features added distributional models, one could object improvements due
fact using information: larger number features (higher-dimensional
31

fiBruni, Tran & Baroni

vectors) Feature Level fusion, complex model (two similarity scores
independent variables predict human judgments) Scoring Level fusion. experiments provide evidence respond objection.
First, built purely textual models number features multimodal
models is, instead collecting co-occurrence target terms 30K
frequent content lemmas corpus (see Section 4.1 above), extended list
context items 110K frequent content lemmas. results larger
textual models virtually identical 30K-dimensional vectors reported
Table 2 (correlation Window20 model MEN 0.69 instead 0.68). Thus,
least using large corpus window-based approach, 30K features
pretty much exhausted useful textual information, nature, simply
quantity extra visual features add matters.
answer objection Scoring Level approach using complex model,
two independent variables (text- image-base similarities) instead one, casted
problem standard inferential statistical terms (see, e.g, Baayen, 2008, ch. 6). Specifically, fitted ordinary linear regression models predict MEN WS ratings
text-based similarities vs. text- image-based similarities (for comparability
Spearman correlation results reported above, analyses also replicated
transforming ratings similarities ranks). variables highly significant
experiments, and, importantly, sequential F-tests nested models revealed
cases adding image-based similarities explains significantly variance
would expected chance given extra parameter (p < 0.01).
Qualitative Analysis acquire qualitative insights multimodality contributing meaning representation, first picked top 200 related pairs
combined MEN WS norms, would confident indeed highly
related pairs humans, looked, within subset, pairs
pronounced difference cosines Text TunedFL, using Window20
textual source. is, first column Table 4 presents pairs considered
related humans relatedness better captured Text, second column
pairs relatedness better captured TunedFL.
Notice 7/10 relations better captured TunedFL coordinates
synonyms pertaining concrete objects (candy/chocolate, bicycle/bike, apple/cherry,
military/soldier, paws/whiskers, stream/waterfall cheetah/lion), indeed
maximally visually similar (either objects or, case paws/whiskers,
surrounds). purely text-based model, hand, captures relations
times day, that, imageable, well-delimited concrete objects
(dawn/dusk, sunrise/sunset). captures properties concepts expressed adjectives
(dog/canine, skyscraper/tall, cat/feline, pregnancy/pregnant, rain/misty), least one
case spotting relation requires encyclopedic knowledge (grape/wine). thus
hypothesize added value multimodally-enhanced model derives
power vision finding relations concrete objects taxonomic level,
results detecting particularly tight forms relatedness, synonymy
coordination.
32

fiMultimodal Distributional Semantics

Text
dawn/dusk
sunrise/sunset
canine/dog
grape/wine
foliage/plant
foliage/petal
skyscraper/tall
cat/feline
pregnancy/pregnant
misty/rain

TunedFL
pet/puppy
candy/chocolate
paw/pet
bicycle/bike
apple/cherry
copper/metal
military/soldier
paws/whiskers
stream/waterfall
cheetah/lion

Table 4: Top 10 pairs whose relatedness better captured Text (Window20)
vs. TunedFL.

observed one reviewer, given taxonomic nature information captured
multimodal approach, interesting compare future work features
directly extracted linguistic taxonomy, WordNet. observe passing
manually-constructed resource, unlike extracted textual corpora, likely
reflect linguistic perceptual knowledge lexicographers built
it.
Going opposite direction, another reviewer observed might get
mileage combining visual features textual models less taxonomic nature.
hypothesis partially confirmed fact obtain larger relative improvement mixing vision Window20 Window2 (look back Table 2, see
Section 4.1 think narrower window mainly captures taxonomic
relations, larger one broader topical themes). explore conjecture,
re-ran MEN WS experiments combining visual vectors document-based
textual model (i.e., semantic space whose dimensions record number occurrences
words documents). space expected capture mostly topical information,
estimates relatedness basis tendency words occur
documents (Sahlgren, 2006). document-based model alone good
window-based models (it obtained Spearman correlation 0.68 MEN 0.63
WS), combining image-based models led relative improvements comparable
inferior attained Window20 (the best combined-model correlations
0.73 MEN 0.70 WS). conclude that, looking textual models
complementary respect visual information seems reasonable direction
develop multimodal systems cover broader range semantic phenomena, simply
emphasizing topical side textual models evidently suffice.
33

fiBruni, Tran & Baroni

5.2.3 Concreteness Factor Modeling Relatedness Ratings: Pilot
Study
previous experiments, observed trend towards division labour text- image-based models, latter apt capturing similarity
among concrete concepts properties. One strongest limitations current
version framework fact every target word assumed equally perceptually salient consequently uniformly enriched visual information. Intuitively,
might want distinguish instead concrete words, chair cat, require
integration perceptual information representation, abstract words,
consequence absurd, represented purely symbolic/linguistic basis.
Indeed, Recchia Jones (2012) recently presented evidence that, lexical decision
naming tasks, rich physical contexts favour activation concrete concepts, whereas rich
linguistic contexts facilitate activation abstract concepts. follow-up pilot
experiment presented section want pave way systematic introduction concreteness factor multimodal meaning representation. Operationally,
separate abstract concrete word pairs semantic relatedness benchmark
MEN, assessing contribution textual visual information approximating word
meaning two domains independently. Importantly, use automated method
determine word concrete abstract, eye future integration
automatically-determined abstractness score fusion algorithm.
particular, use abstractness scores automatically assigned algorithm recently introduced Turney, Neuman, Assaf, Cohen (2011). Scores calculated
computing difference sum text-based semantic similarities target
word set concrete paradigm words sum semantic similarities
set abstract paradigm words. words (i.e., paradigm words words
abstractness score computed) represented co-occurrence based
matrix gathered large corpus university websites. Co-occurrence counts
transformed Positive Pointwise Mutual Information scores (Church & Hanks, 1990)
resulting matrix smoothed SVD. Pairwise semantic similarity measured
cosines. paradigm words turn selected supervised learning method
trained subject-rated words MRC Psycholinguistic Database Machine Usable
Dictionary (Coltheart, 1981). Examples highly abstract words automatically rated
list purvey: 1.00, sense: 0.96 improbable: 0.92, examples highly concrete
words (i.e., words low abstractness score) donut: 0.00, bullet: 0.07 shoe:
0.10.
abstractness score assigned MEN testing words, divided
data set two subsets, one containing concrete word pairs (MEN-conc, 837
pairs), containing abstract pairs mixed pairs, pairs formed one
concrete one abstract word (MEN-abst, 163 pairs). word considered concrete
abstract score 0.5, abstract otherwise. example, word pair arm-bicycle
considered concrete (with scores 0.33 0.35 respectively), fun-relax considered
abstract (with scores 0.6 0.59 respectively) design-orange considered mixed
(with scores 0.55 0.20 respectively). experimented Window20 purely
34

fiMultimodal Distributional Semantics

Model
Window20
Image
TunedFL

MEN-conc
0.70
0.47
0.78

MEN-abst
0.51
0.37
0.52

MEN-full
0.68
0.43
0.76

Table 5: Spearman correlation models MEN divided concrete abstract
subsets. Results full data set also repeated. coefficients significant
p < 0.001.

textual model, Image usual visual model TunedFL trained MEN development
multimodal model.
Table 5 show correlation scores three models two MEN subsets
(as well repeating correlations attain full set). First all, worth
noticing models higher correlations MEN-conc MEN-abst, suggesting
approximating similarity judgments pairs concrete pairs general easier
task distributional semantics (and, suspect, humans well!). Besides broad
effect, also observe clear interaction added value visual component
MEN-abst MEN-conc. fact, TunedFL gains 11% performance
MEN-conc compared Window20, performance essentially
text-only model case MEN-abst. indicates visual information
mostly beneficial concrete domain, maintains neutral (timidly positive)
impact abstract domain (recall that, case, MEN-abst also contains mixed
pairs).
conclude, section followed qualitative analysis main
relatedness results pilot experiment focusing concreteness factor. showed
divide MEN benchmark concrete abstract subsets, visual
information enhances text-based model concrete domain, impact
strong. exploited automatic scoring function divide data set
concrete abstract subsets. thus see results reporting also
validation Turney et al.s algorithm, and, importantly purposes,
encouragement incorporate automated abstractness/concreteness scoring way
model mixes textual visual information word-by-word basis.
5.3 Concept Categorization
verify conclusions reached WS MEN extend different semantic tasks and,
particular, assess whether multimodal approach able capture organize
meaning humans do, use two existing concept categorization benchmarks
call Battig Almuhareb-Poesio (AP), respectively, goal cluster set
(nominal) concepts broader categories, already discussed Section 2.1.
particular, use Battig exclusively tuning (in way used MEN
development set previous section) AP testing. results AP
reported. word relatedness task tuning testing sets quite similar
35

fiBruni, Tran & Baroni

(MEN development MEN testing two subsets data set words
WS similar MEN), task challenging since Battig AP
two independent data sets built following different strategies populated
different kinds concepts, namely concrete unambiguous concepts Battig,
vs. mixture concrete abstract, possibly ambiguous concepts AP. adopted
present challenging training testing regime felt neither data set
sufficient size allow split development testing data. details follow.
5.3.1 Benchmarks Method
Battig benchmark introduced Baroni et al. (2010) based Battig
Montague norms Van Overschelde, Rawson, Dunlosky (2004). consists
83 highly prototypical concepts 10 common concrete categories (up 10 concepts
per class). Battig contains basic-level concepts belonging categories bird (eagle,
owl. . . ), kitchenware (bowl, spoon. . . ) vegetable (broccoli, potato. . . ). version
cover 77 concepts 10 different classes.
AP introduced Almuhareb Poesio (2005) made 402 nouns
21 different WordNet classes. version cover, AP contains 231 concepts
clustered 21 classes vehicle (airplane, car. . . ), time (aeon, future. . . ) social
unit (brigade, nation). data set contains many difficult cases unusual ambiguous
instances class, casuarina samba trees.
sets, following original proponents others, cluster words based
pairwise cosines semantic space defined model using CLUTO toolkit
(Karypis, 2003). use CLUTOs built-in repeated bisections global optimization
method, accepting CLUTOs default values. Cluster quality often evaluated
percentage purity (Zhao & Karypis, 2003). nir number items i-th true
(gold standard) class assigned r-th cluster, n total number items,
k number clusters,
purity =

X
1 i=n
max (nri )
n i=1

words, number items belonging majority true class (i.e., represented
class cluster) summed across clusters divided total number items.
best scenario purity 1 approach 0 cluster quality deteriorates.
Since lack full AP coverage, results report directly comparable
studies used it. However, text-based models perfect coverage,
evaluated full set achieve purities 0.67 (Window2) 0.61 (Window2),
state-of-the-art levels comparable models, reported Section 2.1 above.
So, again, confidently claim improvements achieved multimodality
obtained comparing approach competitive purely textual models.
5.3.2 Results
Table 6 reports percentage purities AP clustering task. Also best automatically selected model (TunedFL) uses FL similarity estimation previous task,
similar SVD k (27 Window2 29 Window20) (0.5) parameters
36

fiMultimodal Distributional Semantics

Model
Text
Image
NaiveFL
NaiveSL
MixLDA
Textmixed
Imagemixed
TunedFL
TunedSL

Window2
AP
0.73
0.26
0.74
0.65
0.14
0.74
0.35
0.74
0.75

Window20
AP
0.65
0.26
0.64
0.66
0.14
0.67
0.29
0.69
0.69

Table 6: Percentage purities models AP. TunedFL model automatically
selected Battig data; TunedSL automatically tuned fixing SL similarity estimation.

ones found relatedness, suggesting particular parameter choice robust
could used out-of-the-box tasks well. TunedSL best SL-based method
tuning Battig set (same ks TunedFL, = 0.5 Window20 = 0.9
Window2).
Analogously previous semantic task, see Image model alone
level text models, although AP purities significantly chance
(p < 0.05 based simulated distributions random cluster assignment). Thus,
confirmation fact image-based vectors capture important aspects
meaning. previous task, MixLDA achieves poor results.
Looking text-based models enhanced visual information, see general
improvement performance almost multimodal combination strategies, except
NaiveFL Window20 NaiveSL Window2. Even Textmixed benefits
visual smoothing cases, outperformed TunedFL, whose performance
similar TunedSL, actually slightly better Window2. Interestingly, TunedSL outperforms Text Window2 despite fact single combination
strongly unbalanced towards textual similarity ( = 0.9), indicating visual information beneficial even textual information accounts lions share
composed estimate.
Like relatedness task, adding equal amount textual features instead
image-based ones help Window20 (0.66 purity 110K textual features)
even lowers performance Window2 (0.69 purity). Thus, improvement brought
visual features must attributed quality, quantity.
According two-tailed permutation test, even largest difference TunedFL
Text Window20 significant. might due brittleness purity
statistics leading high variance permutations, possibly suboptimal tuning.
Recall, respect, tuning phase performed rather different data
set (Battig) compared data set eventually evaluated models (AP).
37

fiBruni, Tran & Baroni

However, overall trends encouraging, line found
relatedness study.

6. Conclusion
paper provided extensive introduction new approach distributional semantics named Multimodal Distributional Semantics. multimodal
distributional semantic model integrates traditional text-based representation meaning
information coming vision. way, tries answer critique distributional models lack grounding, since base representation meaning entirely
linguistic input, neglecting statistical information inherent perceptual experience,
humans instead exploit. course, truly multimodal representation meaning
account entire spectrum human senses. hand, line
research still embryonic stage still shortage perceptual data
available techniques automatize processing. why, article,
focused analysis visual perceptual channel, disposal
large data sets effective methods analyze them.
particular, exploited ESP-Game data set, image documents
tagged words describing content. harvest visual information adopted
bag-of-visual-words technique, discretizes image content ways analogous
standard text-based distributional representations. introduced multimodal framework
optimizes text-image fusion data-driven fashion development data.
conducted number experiments assess quality obtained models.
first investigated general semantic properties purely image-based model,
assess overall quality well look information complementary present
text. found systematic differences two modalities, preference
encyclopedic properties text-based model perceptual properties case
image-based model. proceeded test selection models obtained combination
text- image-based representations via multimodal framework. used two
benchmarks word relatedness one benchmark word categorization
cases obtained systematic improvement performance multimodal models
compared models based standalone channels.
Still, looking numerical results, cannot deny improvement performance attained including visual information dramatic. Indeed, pessimistic
interpretation experiments could confirm hypothesis Louwerse
others (e.g., Louwerse, 2011; Louwerse & Connell, 2011; Tillman, Datla, Hutchinson, &
Louwerse, 2012) perceptual information already encoded, sufficient degree,
linguistic data, direct visual features dont bring much table. However, showed
various statistical validation tests important result, namely
adding visual information improves using text alone, robust reliable. think
realistic take-home message experiments reported, establishing
basic result mentioned, drawbacks overcome
work.
First all, deliberately used general semantic benchmarks state-of-the-art text
models, performance computational methods might getting close
38

fiMultimodal Distributional Semantics

ceiling. 0.78 correlation, best models still percentage points go
MEN (estimated upper bound based raters agreement: 0.84, see Section 5.2.1),
improvements bound quite small. Concerning AP benchmark, consider
difficult would even humans categorize casuarina samba among
trees. Indeed, error analysis TunedFL clustering results suggests factors
might lead better performance little vision. example,
model wrongly clusters branch (a social unit according AP) trees, merges
concepts melon peach (fruit AP) mandarin lime (trees). lack
contextual information, hard dispute model choices. Similarly, TunedFL
splits AP animal class cluster small domestic mammals (cats, dogs, kittens,
mice, puppies rats) cluster containing everything else (mostly larger mammals
cows elephants). Again, clustering procedure information
classes searching (e.g., animals general, small animals),
hard see performance could improved thanks better semantic features, visual
kinds. Moreover, data sets include abstract terms, specifically
designed test grounded aspects meaning, visual features might help
most. think made sense start investigation general benchmarks
semantics, opposed ad hoc test sets, show viability multimodal approach.
However, future want focus experimental challenges strengths
visually-enhanced models might emerge clearly. took first step direction
Bruni et al. (2012), focused specifically visual features help
processing literal metaphorical colours.
Another factor take account large-scale image data sets
techniques extract features infancy, might able
improve performance developing better image-based models. Regarding data
sets, explained Section 4.2.1 chose ESP-Game, obviously
sub-optimal many respects, also discuss there. Regarding features,
mentioned beginning Section 4.2.2, recent advances image processing,
Fisher encoding, might lead better ways extract information contained images.
experiments, also compared automatically tuned multimodal model
settings, showing overall stability superiority, two important caveats.
First, experiments good results already obtained using visual information
smooth text features, without using visual features directly (what called
Textmixed approach). Note already multimodal approach, visual
information crucially used improve quality textual dimensions, indeed
weve seen consistently outperforms using non-multimodally-smoothed text features.
Textmixed good full tuned model, simplicity makes
attractive approach.
Second, although automated tuning led us prefer Feature Level Scoring Level
fusion development sets, TunedSL clearly worse TunedFL one case
(with Window20 WS), suggesting that, least evaluation settings considered,
difference two fusion strategies crucial. However, comparing
naive versions strategies tuned ones across results, clear
tuning important obtain consistently good performance, confirming usefulness
general fusion architecture.
39

fiBruni, Tran & Baroni

also conducted pilot experiment concreteness/abstractness factor, assess
impact meaning representation check good candidate new
weighted-fusion strategy plan investigate future. fact, current version
multimodal framework, parametrization combination strategy works
global level (i.e, words). could productive combine textual
visual information word-by-word basis, tune two modality contributions
meaning representation depending particular nature single word. Concrete
vs. abstract constitute neat binary distinction words, rather
thought ideal distinction offset less abrupt, real-world formulation,
takes account degree according certain word considered concrete
abstract. doubt words backdrop, squalor sharp evoke
perceptual cues gathered experience them, time
unequivocal amount abstractness accompanying them. plan also refine
concreteness scoring method order make focus specifically imageable
components concreteness, expect relevant visual channel.
developments focus techniques extract image-based semantic
models. example, pilot study (Bruni et al., 2012), exploit new methods developed
computer vision improve object recognition capturing object location (Felzenszwalb,
Girshick, McAllester, & Deva Ramanan, 2010; de Sande, Uijlings, Gevers, & Smeulders,
2011). show possible extract better image-based semantic vectors first
localizing objects denoted words extracting visual information
object location surround independently. Interestingly, discovered
image-based semantic vectors extracted object surround effective
based object location tested word relatedness task. example,
fact pictures containing deers wolves depict similar surrounds tells us
creatures live similar environments, thus likely somewhat
related. seen distributional hypothesis transposed images: objects
semantically similar occur similar visual contexts. Nevertheless, work
considered proof concept, since experimented 20 words only. future
studies test larger number words.
obviously much room improvement, many exciting routes
explore, hope framework empirical results presented study
convinced reader multimodal distributional semantics promising avenue
pursue development human-like models meaning.

Acknowledgments
thank Jasper Uijlings valuable suggestions image analysis pipeline.
lot code many ideas came Giang Binh Tran, owe Gemma Boleda many
ideas useful comments. Peter Turney kindly shared abstractness score list
used Section 5.2.3 Yair Neuman generously helped preliminary analysis
impact abstractness multimodal models. Mirella Lapata kindly made
WordSim353 set used experiments Feng Lapata (2010) available us.
thank JAIR associated editor reviewers helpful suggestions constructive
40

fiMultimodal Distributional Semantics

criticism. Google partially funded project Google Research Award third
author. BLESS study Section 5.1.2 first presented Bruni et al. (2012).

References
Abdi, H., & Williams, L. (2010). Newman-Keuls Tukey test. Salkind, N., Frey, B., &
Dougherty, D. (Eds.), Encyclopedia Research Design, pp. 897904. Sage, Thousand
Oaks, CA.
Agirre, E., Alfonseca, E., Hall, K., Kravalova, J., Pasa, M., & Soroa, A. (2009). study
similarity relatedness using distributional WordNet-based approaches.
Proceedings HLT-NAACL, pp. 1927, Boulder, CO.
Almuhareb, A., & Poesio, M. (2005). Concept learning categorization web.
Proceedings CogSci, pp. 103108, Stresa, Italy.
Andrews, M., Vigliocco, G., & Vinson, D. (2009). Integrating experiential distributional
data learn semantic representations. Psychological Review, 116 (3), 463498.
Baayen, H. (2008). Analyzing Linguistic Data: Practical Introduction Statistics using
R. Cambridge University Press, Cambridge, UK.
Barnard, K., Duygulu, P., Forsyth, D., de Freitas, N., Blei, D., & Jordan, M. (2003). Matching words pictures. Journal Machine Learning Research, 3, 11071135.
Baroni, M., Barbu, E., Murphy, B., & Poesio, M. (2010). Strudel: distributional semantic
model based properties types. Cognitive Science, 34 (2), 222254.
Baroni, M., & Lenci, A. (2008). Concepts properties word spaces. Italian Journal
Linguistics, 20 (1), 5588.
Baroni, M., & Lenci, A. (2010). Distributional Memory: general framework corpusbased semantics. Computational Linguistics, 36 (4), 673721.
Baroni, M., & Lenci, A. (2011). BLESSed distributional semantic evaluation.
Proceedings EMNLP GEMS Workshop, pp. 110, Edinburgh, UK.
Barsalou, L. (2008). Grounded cognition. Annual Review Psychology, 59, 617645.
Berg, T., Berg, A., & Shih, J. (2010). Automatic attribute discovery characterization
noisy Web data. ECCV, pp. 663676, Crete, Greece.
Bergsma, S., & Goebel, R. (2011). Using visual information predict lexical preference.
Proceedings RANLP, pp. 399405, Hissar, Bulgaria.
Blei, D. M., Ng, A. Y., & Jordan, M. I. (2003). Latent Dirichlet allocation. Journal
Machine Learning Research, 3, 9931022.
Bosch, A., Zisserman, A., & Munoz, X. (2007). Image classification using random forests
ferns. Proceedings ICCV, pp. 18, Rio de Janeiro, Brazil.
Bosch, A., Zisserman, A., & Munoz, X. (2008). Scene classification using hybrid generative/discriminative approach. IEEE Transactions Pattern Analysis Machine
Intelligence, 30 (4).
Bruni, E., Boleda, G., Baroni, M., & Tran, N. K. (2012). Distributional semantics
Technicolor. Proceedings ACL, pp. 136145, Jeju Island, Korea.
41

fiBruni, Tran & Baroni

Bruni, E., Bordignon, U., Liska, A., Uijlings, J., & Sergienya, I. (2013). Vsem: open
library visual semantics representation. Proceedings ACL, Sofia, Bulgaria.
Bruni, E., Tran, G. B., & Baroni, M. (2011). Distributional semantics text images.
Proceedings EMNLP GEMS Workshop, pp. 2232, Edinburgh, UK.
Bruni, E., Uijlings, J., Baroni, M., & Sebe, N. (2012). Distributional semantics eyes:
Using image analysis improve computational representations word meaning.
Proceedings ACM Multimedia, pp. 12191228, Nara, Japan.
Budanitsky, A., & Hirst, G. (2006). Evaluating WordNet-based measures lexical semantic
relatedness. Computational Linguistics, 32 (1), 1347.
Bullinaria, J., & Levy, J. (2007). Extracting semantic representations word cooccurrence statistics: computational study. Behavior Research Methods, 39, 510
526.
Bullinaria, J., & Levy, J. (2012). Extracting semantic representations word cooccurrence statistics: Stop-lists, stemming SVD. Behavior Research Methods,
44, 890907.
Burgess, C. (2000). Theory operational definitions computational memory models:
response Glenberg Robertson. Journal Memory Language, 43 (3),
402408.
Caicedo, J., Ben-Abdallah, J., Gonzlez, F., & Nasraoui, O. (2012). Multimodal representation, indexing, automated annotation retrieval image collections via nonnegative matrix factorization. Neurocomputing, 76 (1), 5060.
Chatfield, K., Lempitsky, V., Vedaldi, A., & Zisserman, A. (2011). devil
details: evaluation recent feature encoding methods. Proceedings BMVC,
Dundee, UK.
Church, K., & Hanks, P. (1990). Word association norms, mutual information, lexicography. Computational Linguistics, 16 (1), 2229.
Clark, S. (2013). Vector space models lexical meaning. Lappin, S., & Fox, C. (Eds.),
Handbook Contemporary Semantics, 2nd ed. Blackwell, Malden, MA. press.
Coltheart, M. (1981). MRC psycholinguistic database. Quarterly Journal Experimental Psychology, 33.
Connolly, A., Gleitman, L., & Thompson-Schill, S. (2007). Effect congenital blindness
semantic representation everyday concepts. Proceedings National
Academy Sciences, 104 (20), 82418246.
Csurka, G., Dance, C., Fan, L., Willamowski, J., & Bray, C. (2004). Visual categorization
bags keypoints. Workshop Statistical Learning Computer Vision,
ECCV, pp. 122, Prague, Czech Republic.
Curran, J., & Moens, M. (2002). Improvements automatic thesaurus extraction.
Proceedings ACL Workshop Unsupervised Lexical Acquisition, pp. 5966,
Philadelphia, PA.
42

fiMultimodal Distributional Semantics

de Sande, K. V., Uijlings, J., Gevers, T., & Smeulders, A. (2011). Segmentation selective
search object recognition. Proceedings ICCV, pp. 18791886, Barcelona,
Spain.
de Vega, M., Glenberg, A., & Graesser, A. (Eds.). (2008). Symbols Embodiment: Debates
Meaning Cognition. Oxford University Press, Oxford, UK.
Deng, J., Dong, W., Socher, R., Li, L.-J., & Fei-Fei, L. (2009). Imagenet: large-scale
hierarchical image database. Proceedings CVPR, pp. 248255, Miami Beach,
FL.
Dumais, S. (2003). Data-driven approaches information access. Cognitive Science, 27,
491524.
Erk, K. (2012). Vector space models word meaning phrase meaning: survey..
Language Linguistics Compass, 6 (10), 635653.
Escalante, H. J., Hrnadez, C. A., Sucar, L. E., & Montes, M. (2008). Late fusion heterogeneous methods multimedia image retrieval. Proceedings ICMR, Vancouver,
Canada.
Evert, S. (2005). Statistics Word Cooccurrences. Dissertation, Stuttgart University.
Farhadi, A., Hejrati, M., Sadeghi, M. A., Young, P., Rashtchian, C., Hockenmaier, J., &
Forsyth, D. (2010). Every picture tells story: Generating sentences images.
Proceedings ECCV, Crete, Greece.
Felzenszwalb, P., Girshick, R., McAllester, D., & Deva Ramanan, D. (2010). Object detection discriminatively trained part based models. IEEE Transactions Pattern
Analysis Machine Intelligence, 32, 16271645.
Feng, Y., & Lapata, M. (2010). Visual information semantic representation. Proceedings HLT-NAACL, pp. 9199, Los Angeles, CA.
Finkelstein, L., Gabrilovich, E., Matias, Y., Rivlin, E., Solan, Z., Wolfman, G., & Ruppin,
E. (2002). Placing search context: concept revisited. ACM Transactions
Information Systems, 20 (1), 116131.
Firth, J. R. (1957). Papers Linguistics, 1934-1951. Oxford University Press, Oxford,
UK.
Fodor, J. (1975). Language Thought. Crowell Press, New York.
Glenberg, A., & Robertson, D. (2000). Symbol grounding meaning: comparison
high-dimensional embodied theories meaning. Journal Memory Language, 3 (43), 379401.
Grauman, K., & Darrell, T. (2005). pyramid match kernel: Discriminative classification
sets image features. Proceedings ICCV, pp. 14581465, Beijing, China.
Grauman, K., & Leibe, B. (2011). Visual Object Recognition. Morgan & Claypool, San
Francisco.
Grefenstette, G. (1994). Explorations Automatic Thesaurus Discovery. Kluwer, Boston,
MA.
43

fiBruni, Tran & Baroni

Griffin, L., Wahab, H., & Newell, A. (2013). Distributional learning appearance. PLoS
ONE, 8 (2). Published online: http://www.plosone.org/article/info:doi/10.
1371/journal.pone.0058074.
Griffiths, T., Steyvers, M., & Tenenbaum, J. (2007). Topics semantic representation.
Psychological Review, 114, 211244.
Hansen, T., Olkkonen, M., Walter, S., & Gegenfurtner, K. (2006). Memory modulates color
appearance. Nature Neuroscience, 9, 13671368.
Harnad, S. (1990). symbol grounding problem. Physica D: Nonlinear Phenomena,
42 (1-3), 335346.
Harris, Z. (1954). Distributional structure. Word, 10 (2-3), 14561162.
Johns, B., & Jones, M. (2012). Perceptual inference global lexical similarity. Topics
Cognitive Science, 4 (1), 103120.
Karypis, G. (2003). CLUTO: clustering toolkit. Tech. rep. 02-017, University Minnesota
Department Computer Science.
Kaschak, M., Madden, C., Therriault, D., Yaxley, R., Aveyard, M., Blanchard, A., & Zwaan,
R. (2005). Perception motion affects language processing. Cognition, 94, B79B89.
Kievit-Kylar, B., & Jones, M. (2011). Semantic Pictionary project. Proceedings
CogSci, pp. 22292234, Austin, TX.
Kulkarni, G., Premraj, V., Dhar, S., Li, S., Choi, Y., Berg, A. C., & Berg, T. L. (2011).
Baby talk: Understanding generating simple image descriptions. Proceedings
CVPR, Colorado Springs, MSA.
Landauer, T., & Dumais, S. (1997). solution Platos problem: latent semantic analysis theory acquisition, induction, representation knowledge. Psychological
Review, 104 (2), 211240.
Lazebnik, S., Schmid, C., & Ponce, J. (2006). Beyond bags features: Spatial pyramid
matching recognizing natural scene categories. Proceedings CVPR, pp. 2169
2178, Washington, DC.
Leong, C. W., & Mihalcea, R. (2011). Going beyond text: hybrid image-text approach
measuring word relatedness. Proceedings IJCNLP, pp. 14031407.
Lloyd, S. (1982). Least squares quantization PCM. IEEE Transactions Information
Theory, 28, 129137.
Louwerse, M. (2011). Symbol interdependency symbolic embodied cognition. Topics
Cognitive Science, 3, 273302.
Louwerse, M., & Connell, L. (2011). taste words: Linguistic context perceptual
simulation predict modality words. Cognitive Science, 35, 381398.
Lowe, D. (1999). Object recognition local scale-invariant features. Proceedings
ICCV, pp. 11501157.
Lowe, D. (2004). Distinctive image features scale-invariant keypoints. International
Journal Computer Vision, 60 (2).
44

fiMultimodal Distributional Semantics

Lowe, W. (2001). Towards theory semantic space. Proceedings CogSci, pp. 576581,
Edinburgh, UK.
Lund, K., & Burgess, C. (1996). Producing high-dimensional semantic spaces lexical
co-occurrence. Behavior Research Methods, 28, 203208.
Manning, C., Raghavan, P., & Schtze, H. (2008). Introduction Information Retrieval.
Cambridge University Press, Cambridge, UK.
Manning, C., & Schtze, H. (1999). Foundations Statistical Natural Language Processing.
MIT Press, Cambridge, MA.
McDonald, S., & Brew, C. (2004). distributional model semantic context effects
lexical processing. Proceedings ACL, pp. 1724, Barcelona, Spain.
McRae, K., Cree, G., Seidenberg, M., & McNorgan, C. (2005). Semantic feature production
norms large set living nonliving things. Behavior Research Methods, 37 (4),
547559.
Miller, G., & Charles, W. (1991). Contextual correlates semantic similarity. Language
Cognitive Processes, 6 (1), 128.
Moore, D., & McCabe, G. (2005). Introduction Practice Statistics (5 edition).
Freeman, New York.
Murphy, G. (2002). Big Book Concepts. MIT Press, Cambridge, MA.
Nelson, D., McEvoy, C., & Schreiber, T. (1998). University South Florida word association, rhyme, word fragment norms. http://www.usf.edu/FreeAssociation/.
Nister, D., & Stewenius, H. (2006). Scalable recognition vocabulary tree. Proceedings 2006 IEEE Computer Society Conference Computer Vision Pattern
Recognition - Volume 2, CVPR 06, pp. 21612168.
Nowak, E., Jurie, F., & Triggs, B. (2006). Sampling strategies bag-of-features image
classification. Proceedings ECCV, pp. 490503, Graz, Austria.
Pad, S., & Lapata, M. (2007). Dependency-based construction semantic space models.
Computational Linguistics, 33 (2), 161199.
Pad, U., Pad, S., & Erk, K. (2007). Flexible, corpus-based modelling human plausibility
judgements. Proceedings EMNLP, pp. 400409, Prague, Czech Republic.
Pecher, D., Zeelenberg, R., & Raaijmakers, J. (1998). pizza prime coin? Perceptual
priming lexical decision pronunciation. Journal Memory Language, 38,
401418.
Perronnin, F., Sanchez, J., & Mensink, T. (2010). Improving fisher kernel large-scale
image classification. Proceedings ECCV, pp. 143156, Berlin, Heidelberg.
Pham, T.-T., Maillot, N., Lim, J.-H., & Chevallet, J.-P. (2007). Latent semantic fusion
model image retrieval annotation. Proceedings CIKM, pp. 439443,
Lisboa, Portugal.
Poesio, M., & Almuhareb, A. (2005). Identifying concept attributes using classifier.
Proceedings ACL Workshop Deep Lexical Semantics, pp. 1827, Ann Arbor,
MI.
45

fiBruni, Tran & Baroni

Pulvermueller, F. (2005). Brain mechanisms linking language action. Nature Reviews
Neuroscience, 6, 576582.
Radinsky, K., Agichtein, E., Gabrilovich, E., & Markovitch, S. (2011). word time:
computing word relatedness using temporal semantic analysis. Proceedings
WWW, pp. 337346, Hyderabad, India.
Rapp, R. (2003). Word sense discovery based sense descriptor dissimilarity. Proceedings 9th MT Summit, pp. 315322, New Orleans, LA.
Recchia, G., & Jones, M. (2012). semantic richness abstract concepts. Frontiers
Human Neuroscience, 6 (315).
Reisinger, J., & Mooney, R. J. (2010). Multi-prototype vector-space models word meaning. Proceedings NAACL, pp. 109117, Los Angeles, CA.
Riordan, B., & Jones, M. (2011). Redundancy perceptual linguistic experience:
Comparing feature-based distributional models semantic representation. Topics
Cognitive Science, 3 (2), 143.
Rothenhusler, K., & Schtze, H. (2009). Unsupervised classification dependency
based word spaces. Proceedings EACL GEMS Workshop, pp. 1724, Athens,
Greece.
Rubenstein, H., & Goodenough, J. (1965). Contextual correlates synonymy. Communications ACM, 8 (10), 627633.
Sahlgren, M. (2005). introduction random indexing. http://www.sics.se/~mange/
papers/RI_intro.pdf.
Sahlgren, M. (2006). Word-Space Model. Dissertation, Stockholm University.
Sahlgren, M. (2008). distributional hypothesis. Italian Journal Linguistics, 20 (1),
3353.
Schtze, H. (1997). Ambiguity Resolution Natural Language Learning. CSLI, Stanford,
CA.
Silberer, C., & Lapata, M. (2012). Grounded models semantic representation. Proceedings EMNLP-CoNLL, pp. 14231433, Jeju, Korea.
Sivic, J., & Zisserman, A. (2003). Video Google: text retrieval approach object matching videos. Proceedings ICCV, pp. 14701477, Nice, France.
Steyvers, M. (2010). Combining feature norms text data topic models. Acta
Psychologica, 133 (3), 234243.
Therriault, D., Yaxley, R., & Zwaan, R. (2009). role color diagnosticity object
recognition representation. Cognitive Processing, 10 (4), 335342.
Tillman, R., Datla, V., Hutchinson, S., & Louwerse, M. (2012). head toe: Embodiment statistical linguistic frequencies. Proceedings CogSci, pp.
24342439, Austin, TX.
Turney, P., Neuman, Y., Assaf, D., & Cohen, Y. (2011). Literal metaphorical sense
identification concrete abstract context. Proceedings EMNLP, pp.
680690, Edinburgh, UK.
46

fiMultimodal Distributional Semantics

Turney, P., & Pantel, P. (2010). frequency meaning: Vector space models semantics. Journal Artificial Intelligence Research, 37, 141188.
Van de Sande, K., Gevers, T., & Snoek, C. (2010). Evaluating color descriptors object
scene recognition. IEEE Transactions Pattern Analysis Machine Intelligence,
32 (9), 15821596.
Van Overschelde, J., Rawson, K., & Dunlosky, J. (2004). Category norms: updated
expanded version Battig Montague (1969) norms. Journal Memory
Language, 50, 289335.
Vedaldi, A., & Fulkerson, B. (2010). Vlfeat open portable library computer
vision algorithms. Proceedings ACM Multimedia, pp. 14691472, Firenze, Italy.
Von Ahn, L. (2006). Games purpose. Computer, 29 (6), 9294.
Vreeswijk, D. T., Huurnink, B., & Smeulders, A. W. (2011). Text image subject
classifiers: dense works better. Proceedings ACM Multimedia, pp. 14491452,
Scottsdale, AZ.
Wang, J., Yang, J., Yu, K., Lv, F., Huang, T., & Gong, Y. (2010). Locality-constrained
linear coding image classification. Proceedings CVPR, pp. 33603367, San
Francisco, CA.
Weeds, J. (2003). Measures Applications Lexical Distributional Similarity. Ph.D.
thesis, Department Informatics, University Sussex.
Wittgenstein, L. (1953). Philosophical Investigations. Blackwell, Oxford, UK. Translated
G.E.M. Anscombe.
Yang, J., Jiang, Y.-G., Hauptmann, A., & Ngo, C.-W. (2007). Evaluating bag-of-visualwords representations scene classification. Wang, J. Z., Boujemaa, N., Bimbo,
A. D., & Li, J. (Eds.), Multimedia Information Retrieval, pp. 197206. ACM.
Zhao, Y., & Karypis, G. (2003). Criterion functions document clustering: Experiments
analysis. Tech. rep. 01-40, University Minnesota Department Computer
Science.

47

fiJournal Articial Intelligence Research 49 (2014) 669-703

Submitted 11/13; published 4/14

Improved Separations Regular Resolution Clause
Learning Proof Systems
Maria Luisa Bonet

bonet@lsi.upc.edu

Lenguajes Sistemas Informaticos,
Universidad Politecnica de Cataluna,
Barcelona, Spain

Sam Buss

sbuss@math.ucsd.edu

Department Mathematics,
University California, San Diego,
La Jolla, CA 92093-0112, USA

Jan Johannsen

jan.johannsen@ifi.lmu.de

Institut fur Informatik,
Ludwig-Maximilians Universitat Munchen,
D-80538 Munchen, Germany

Abstract
paper studies relationship resolution conict driven clause learning (CDCL) without restarts, refutes conjectured possible separations. prove
guarded, xor-ied pebbling tautology clauses, Urquhart proved hard
regular resolution, well guarded graph tautology clauses Alekhnovich, Johannsen, Pitassi, Urquhart polynomial size pool resolution refutations use
input lemmas learned clauses. latter set clauses, extend prove
CDCL search without restarts refute clauses polynomial time, provided
makes right choices decision literals clause learning. holds even
CDCL search required greedily process conicts arising unit propagation.
refutes conjecture guarded graph tautology clauses guarded xor-ied
pebbling tautology clauses used separate CDCL without restarts general
resolution. Together subsequent results Buss Kolodziejczyk, means lack
good conjectures establish exact logical strength conict-driven
clause learning without restarts.

1. Introduction
problem SAT deciding satisability propositional CNF formulas great theoretical practical interest. Even though SAT NP-complete, industrial instances
hundreds thousands variables routinely solved state-of-the-art SAT solvers.
solvers use conict-driven clause learning (CDCL) based work MarquesSilva Sakallah (1999). CDCL solvers use DPLL (Davis-Putnam-LogemannLoveland) search procedure clause learning, extended additional techniques
fast backtracking, restarts, variable selection heuristics.
c
2014
AI Access Foundation. rights reserved.

fiBonet, Buss, & Johannsen

Without clause learning, DPLL procedure equivalent tree-like resolution.
addition clause learning,1 CDCL becomes considerably powerful. fact, CDCL
together unlimited restarts capable polynomially simulating general resolution
proofs (Pipatsrisawat & Darwiche, 2011). Without restarts, CDCL known polynomially
simulate regular resolution (Buss, Homann, & Johannsen, 2008). Furthermore, general
resolution known strictly stronger regular resolution (Alekhnovich, Johannsen,
Pitassi, & Urquhart, 2007). However, exact power CDCL without restarts unknown.
question interesting CDCL without restarts core search method
SAT aolvers, also better understanding power CDCL may
lead better understanding practical performance SAT solvers.
Alekhnovich et al. (2007) Urquhart (2011) gave three examples unsatisable sets
clauses require exponentially longer regular resolution refutations (general)
resolution refutations. view fact CDCL without restarts lies regular resolution resolution, three examples conjecturally good candidates
showing CDCL without restarts cannot polynomially simulate general resolution.
present paper refutes conjectures two examples; namely, prove
CDCL without restarts give polynomial size refutations guarded graph tautologies clauses Alekhnovich et al. guarded xor-ied pebbling tautologies clauses
Urquhart, provided CDCL search makes optimal choices decision literals
learning clauses forgetting learned clauses. former tautology, show
CDCL search required greedy never ignore contradictions
found unit propagation. follows two tautologies give superpolynomial separation resolution refutations CDCL refutations without restarts.
Buss Kolodziejczyk (2012) subsequently proved similar result Stone tautologies, Alekhnovich et al. proved give exponential separation regular resolution
resolution. Thus, presently conjectured examples tautologies would
provide exponential separation power CDCL without restarts
power resolution. hand, looks dicult prove CDCL without
restarts polynomially simulate resolution. consequently lack good conjectures
characterize exact strength CDCL without restarts.
Beame, Kautz, Sabharwal (2004) gave rst theoretical analysis CDCL. Among
things, noted CDCL restarts simulates general resolution. construction, however, rather unnatural requires CDCL algorithm ignore
contradictions. situation rectied Pipatsrisawat Darwiche (2011),
showed CDCL solvers restarts use unit propagation never ignore contradictions also simulate resolution. proof based technique absorption
rst dened Atserias, Fichte, Thurley (2011).
Beame et al. (2004) also studied CDCL without restarts. Using proof trace extensions,
showed CDCL without restarts strictly stronger natural proof
system strictly weaker resolution. natural proof system one proofs
increase length superpolynomially variables restricted constants; natural
1. paper, use CDCL synonym DPLL clause learning. discuss whether
CDCL without restarts polynomially simulate resolution, mean whether simulation possible
correct choices decision literals learned clauses.

670

fiSeparations Regular Resolution

proof systems include systems tree-like regular resolution. proof trace
method changes formulas introducing extraneous variables clauses,
eect giving CDCL freedom choosing decision variables branching.
Buss et al. (2008) Hertel, Bacchus, Pitassi, Van Gelder (2008) gave improved
versions proof trace extension method extraneous variables depend
set clauses refuted resolution refutation clauses.
drawback remains, however, proof trace extension method gives contrived sets
clauses contrived resolution refutations, consequently give much insight
power CDCL.
two approaches formalizing CDCL without restarts static proof
system rather proof search algorithm. rst pool resolution degenerate
resolution inference, due Van Gelder (2005) studied Hertel et al. (2008).
Pool resolution requires proofs depth-rst regular traversal similarly search
space DPLL algorithm. Degenerate resolution allows resolution inferences one
hypotheses may lacking occurrences resolution literal. (Detailed
denitions given Section 2.) Van Gelder argued pool resolution degenerate
resolution inferences simulates wide range CDCL algorithms without restarts.
also gave proof, using techniques Alekhnovich et al. (2007), pool resolution
degenerate inferences stronger regular resolution, using extraneous variables similar
proof trace extensions.
second approach due Buss et al. (2008) introduced dierent degenerate resolution rule called w-resolution, proof system, called regWRTI, based
w-resolution clause learning input lemmas. proved regWRTI exactly
captures non-greedy CDCL without restarts. discussed below, non-greedy means
contradictions may need ignored CDCL search.
remains open whether CDCL without restarts, pool resolution (with without
degenerate inferences), regWRTI proof system polynomially simulate general resolution. One approach answering questions try separate pool resolution
regWRTI general resolution. However, best so-far obtained separations resolution apply weaker system regular resolution, based work Alekhnovich
et al. (2007) Urquhart (2011) giving exponential separations regular resolution
general resolution. Alekhnovich et al. proved exponential separation regular
resolution resolution two families tautologies, variants graph tautology
clauses GT Stone pebbling tautology clauses. Urquhart subsequently gave
related separation using dierent set pebbling tautology clauses denoted denoted .2 present paper calls GT clauses guarded graph tautology clauses,
denotes GGT instead GT ; denition given Section 4. Section 3 denes
guarded xor-ified pebbling tautology clauses GPebk (G), essentially
clauses .
obvious question whether pool resolution regWRTI polynomial size refutations GGT, GPebk , Stone clauses. present paper resolves rst two
questions showing pool resolution regRTI indeed polynomial size
2. Huang Yu (1987) also gave separation regular resolution general resolution,
single set clauses. Goerdt (1993) gave quasipolynomial separation regular resolution general
resolution.

671

fiBonet, Buss, & Johannsen

refutations GGT GPebk clauses. refutations avoid use extraneous
variables style proof trace extensions; furthermore, use traditional
resolution rule require degenerate resolution inferences w-resolution inferences.
addition, use learning input clauses; thus, refutations also regWRTI
refutations (and fact regRTI refutations) terminology Buss et al. (2008).
corollary characterization regWRTI Buss et al., GGT GPebk
polynomial size refutations found CDCL without restarts.
Stone clauses recently shown also regRTI refutations Buss
Kolodziejczyk (2012); although use rather dierent method present paper.
Thus, none three principles separate CDCL without restarts general resolution.
natural speculate perhaps pool resolution, regWRTI, CDCL without restarts
simulate general resolution. However, hard optimistic simulations
exist, unable extend methods Buss Kolodziejczyk
give polynomial simulation general resolution CDCL without restarts.
results proved giving regRTI refutations invoking result Buss
et al. (2008, Thm. 5.6) states regWRTI refutation size n set clauses
translated CDCL refutation use restarts runtime polynomially bounded n. mentioned theorem Buss et al. applies CDCL algorithms
learn clauses using framework Marques-Silva Sakallah (1999) (see also
Beame et al., 2004), make important assumptions. rst assumption
CDCL algorithm makes optimal choices decision literals learned clauses;
second assumption CDCL algorithm may non-greedy.
Informally, fact CDCL search must make optimal choices decision literals
learned clauses means Buss et al. (2008) prove equivalence regWRTI
nondeterministic CDCL search without restarts. assumption nondeterminism
probably unavoidable light conditional non-automatizability resolution proved
Alekhnovich Razborov (2001). However, reasonable assumption
characterizing CDCL search terms formal proof system. Furthermore, lower bounds
sizes regWRTI refutations imply lower bounds runtimes CDCL
without restarts.
CDCL search called non-greedy allowed ignore contradictions continuing assign decision literals. Implemented CDCL algorithms always greedy;
namely, learn conicts backtrack whenever possible; probably rare
event non-greedy CDCL algorithms would consistently outperform greedy algorithms,
least practical applications. (However, open question.) upper bounds
CDCL without restarts obtained via upper bounds regWRTI refutations potentially
give non-greedy CDCL searches. guarded graph tautologies, however, prove
more, namely greedy unit propagating CDCL without restarts give polynomial
size refutations guarded graph tautology clauses provided makes optimal choices
decision literals learning forgetting clauses.
conjecture guarded xor-ied pebbling tautologies GPebk also refuted polynomial size greedy unit propagating CDCL without restarts. Preliminary
investigations reveal obstacle; however, technical details quite involved, due
length present paper, carried complete construction.
tautology seems require separate proof. Indeed, open whether greedy unit
672

fiSeparations Regular Resolution

propagating CDCL without restarts simulate arbitrary regRTI proofs, even arbitrary
(dag-like) regular resolution refutations.
outline paper follows. Section 2 denes resolution, degenerate resolution, w-resolution, regular, tree, pool resolution. concludes
denition greedy unit propagating. Section 3 denes GPeb tautologies, including xor-ication guarded initial clauses. proves existence polynomial
size pool resolution regRTI refutations guarded xor-ied GPebk clauses.
rst idea proof try follow regular refutations unguarded Pebk
clauses. refutations cannot used directly however, since initial clauses
Pebk guarded GPebk clauses yields refutations violate
regularity/pool property. So, second idea proof search branches needed
learn initial unguarded Pebk clauses. generates additional clauses must
proved, tricky part sure exactly right set additional clauses
generated.
Section 4 turns graph tautology clauses GTn guarded versions, GGTn .
rst denes clauses states main theorems polynomial size refutations
GGTn clauses pool resolution regRTI. Section 4.1 denes notion bipartite
partial order, discusses regular refutations graph tautology clauses GTn
given Stalmarck (1996) Bonet Galesi (2001). Section 4.2 constructs
pool/regRTI refutations GGTn clauses. intuition construction similar
constructions pebbling tautologies, technical details much
involved. Section 5 concludes explicit description polynomial time greedy
unit propagating CDCL search without restarts refutes GGTn clauses.
paper reworking expansion extended abstract (Bonet & Buss,
2012a) unpublished preprint (Bonet & Buss, 2012b) rst two authors.
earlier versions included results GGT tautologies consider
GPeb principles.

2. Preliminaries
Propositional formulas dened set variables connectives , .
use notation x express negation x x. literal either variable x
negated variable x. clause C set literals, interpreted disjunction
members. empty clause, 2, truth value False. shall use formulas
conjunctive normal form, CNF; namely, formula set (conjunction) clauses.
often use disjunction (), union (), comma (,) interchangeably.
Definition 1. three forms resolution dened take two clauses B called
premises literal x called resolution variable, produce new clause C called
resolvent.


B
C
/ x
/ B. dierent forms resolution are:
cases, required x
Resolution rule. hypotheses forms := x B := B x.
resolvent C B .
673

fiBonet, Buss, & Johannsen

Degenerate resolution rule. (Van Gelder, 2005; Hertel et al., 2008) x x B,
apply resolution rule obtain C. contains x, B doesnt contain x,
resolvent C B. doesnt contain x, B contains x, resolvent C
A. neither B contains literal x x, C lesser B
according tiebreaking ordering clauses.
w-resolution rule. (Buss et al., 2008) B above, infer clause C :=
/ (resp., x
/ B), called phantom
(A \ {x}) (B \ {x}). literal x
literal (resp., B).
Degenerate w-resolution combine weakening resolution. course, wellknown adding weakening resolution increase refutational strength
resolution; however, point allowing degenerate w-resolution derivation
may learn clauses parts derivation would otherwise
pruned away weakening allowed. reason, degenerate w-resolution
actually correspond better DPLL search resolution does.
Definition 2. resolution derivation, proof, clause C CNF formula F
sequence clauses C1 , . . . , Cs C = Cs clause
sequence either clause F resolution resolvent two previous clauses.
derived clause, Cs , empty clause, called resolution refutation F .
general concepts degenerate w-resolution derivations refutations
dened similarly. size proof number clauses proof.
use terms proof derivation interchangeably. derivation represented
directed acyclic graph (dag) vertices C1 , . . . , Cs , clause F
out-degree 0, vertices C1 , . . . , Cs edges pointing two
clauses derived. empty clause in-degree 0.
Resolution sound complete refutational sense: CNF formula F
refutation F unsatisable. Furthermore, derivation clause C
F , C consequence F ; is, every truth assignment , satises
F satises C. Conversely, C consequence F derivation
C C F .
resolution refutation regular provided that, along path directed acyclic
graph, variable resolved once. resolution derivation clause C
regular provided that, addition, variable appearing C used resolution
variable derivation. refutation tree-like underlying graph tree,
occurrence clause refutation used premise inference.
next dene version pool resolution, using conventions Buss et al. (2008)
called tree-like regular resolution lemmas regRTL. idea
clauses obtained previously proof used freely learned lemmas. able
talk clauses previously obtained, need dene ordering clauses.
Definition 3. Given tree , post-order ordering <T nodes dened follows:
u node , v node subtree rooted left child u, w node
subtree rooted right child u, v <T w <T u.
674

fiSeparations Regular Resolution

Definition 4. pool resolution proof (also called regRTL proof) set initial
clauses F resolution proof tree fullls following conditions: (a) leaf
labeled either clause F clause (called lemma) appears earlier
tree <T ordering; (b) internal node labeled clause literal,
clause obtained resolution clauses labeling nodes children resolving
given literal; (c) proof tree regular; (d) root labeled conclusion
clause. labeling root empty clause 2, pool resolution proof pool
refutation.
notions degenerate pool resolution proof pool w-resolution proof dened similarly, allowing degenerate resolution w-resolution inferences, respectively.
Van Gelder (2005) Hertel et al. (2008) dened pool resolution degenerate
pool resolution system, notion pool resolution restrictive theirs.
denition equivalent one Buss (2009), however. also equivalent
system regRTL dened Buss et al. (2008). Pool w-resolution system
regWRTL Buss et al. open whether systems pool resolution, degenerate
pool resolution, pool w-resolution distinct. present paper give examples
superpolynomial separations three systems regular resolution.
lemma clause (a) denition called input lemma derived
input subderivation, namely subderivation inference least one
hypothesis member F lemma. Input resolution
trivial resolution Beame et al. (2004), used characterize clauses
learned conicts found unit propagation (see also Chang, 1970). use input
subderivations learning clauses pool resolution proofs due Buss et al. (2008).
terminology, pool resolution proof uses input lemmas called regRTI
proof. Likewise regWRTL proof uses input lemmas called regWRTI proof.
understand nomenclature; reg stands regular, W w-resolution, RT
resolution tree, L lemma, input lemma.
Based denition Van Gelder (2005), C pool dened pool falsied
literals clause C. denition pool includes phantom literals used
w-resolution inferences:
Definition 5. Let R tree-like, regular refutation lemmas using degenerate resolution, w-resolution, resolution. Let C clause R. Then, clause C pool dened
equal
C pool := {x : literal x occurs, either explicitly phantom literal,
clause R lies branch
root node R including C},
Note C C pool , regularity R ensures C pool contains contradictory
literals.

3. Guarded, Xor-ified, Pebbling Principles
section gives polynomial size regRTI refutations guarded pebbling tautology
clauses Urquhart (2011) proved require exponential size regular resolution proofs.
675

fiBonet, Buss, & Johannsen

Definition 6. pointed dag G = (V, E) directed acyclic graph single sink
every vertex G indegree either 0 2. pebbling tautology clauses
Peb(G) pointed dag G following unsatisable set clauses variables xv
v V :
() xs , every source V ,
() xu xv xw , every vertex w two (immediate) predecessors u v,
() xt , sink vertex.
clauses Peb(G) Horn clauses hence short tree-like resolution refutation linear size. However, clauses made dicult refute using orication xor-ication (see Ben-Sasson, Impagliazzo, & Wigderson, 2004; Ben-Sasson,
2009, Urquhart, 2011). dene Urquharts (2011) xor-ication pebbling
tautology clause. Xor-ication, two variables, due Alekhnovich Razborov
discussed Ben-Sasson (2009), similar or-ication used Ben-Sasson
et al. (2004) replaces variable disjunction two variables. intuition
xor-ication variable xu replaced set clauses expresses
exclusive xu,1 xu,k k new variables.
Definition 7. Let k > 0, xu variable Peb(G). Let xu,1 , . . . , xu,k new
k
variables, let x1u,j xu,j , x1
u,j complement xu,j . Dene xu set
clauses form
1
2
k
xiu,2
xiu,k
(1)
xiu,1
even number values ij equal 1 (and rest equal 1). Dually, dene xk
u
set clauses form (1) odd number ij equal 1. Note
k
2k1 clauses xk
u xu . C clause C = z1 z , zi
literal xu xu , C k set clauses form
C1 C2 C ,
Ci zik . 2(k1) many clauses C k .
Definition 8. xor-ified pebbling tautology clauses Pebk (G) set clauses C k
C Peb(G). G n vertices, Pebk (G) O(23k n) clauses.
Definition 9. Let G pointed graph n vertices k = k(n) > 0. Let
function domain set clauses Pebk (G) range set variables xu,i
Pebk (G), that, C, variable (C) used C. guarded xor-ified
pebbling tautology clauses, GPebk (G), clauses form
C (C)



C (C)

C Pebk (G).
GPebk (G) clauses depend choice ; however, suppressed
notation. GPebk (G) consists O(23k n) clauses.
denitions Pebk (G) GPebk (G) dier somewhat Urquharts,
dierences inessential make dierence asymptotic proof sizes.
676

fiSeparations Regular Resolution

course, Pebk (G) clauses readily derivable GPebk (G) clauses
resolving guard literals given . simple polynomial size regular
resolution refutations Pebk (G) clauses; hence polynomial size,
regular, resolution refutations GPebk (G) clauses. Indeed, Urquhart (2011) proved
pointed graphs G n vertices values k = k(n) = O(log log n),
functions , regular resolution refutations GPebk (G) clauses require size
2
2(n/((log n) log log n)) .
Theorem 10. guarded xor-ified pebbling tautology clauses GPebk (G) polynomial
size regRTI refutations, thus polynomial size pool refutations.
make simple observations working xor-ied clauses proving
Theorem 10.
Lemma 11. Let u vertex G. tree-like regular refutation clauses
k
k
k
xk
u xu 2 1 resolution inferences, height k, 2 leaf clauses. resolution
variables variables xu,i .
Proof. immediate inspection: refutation consists resolving literals xu,i successively = 1, 2, . . . , k, giving refutation height k. refutation
corresponds complete binary decision tree k many variables xu,i ; leaf
k
clauses refutation members xk
u xu .
refutation Lemma 11 viewed k-translation proof
xu



xu

next lemma describes similar k-translation proof
C, xu

D, xu
C,

Lemma 12. Let u vertex G, let C clauses contain
either xu xu . clause (C D)k tree-like regular derivation
clauses (C xu )k (D xu )k variables used resolution variables
exactly variables xu,i . derivation 2k 1 resolution inferences, height k,
2k leaf clauses.
Proof. Fix clause E (C D)k ; must describe derivation clauses
(C xu )k (D xu )k . Let EC subclause E C k , let
ED subclause E k . C non-empty intersection, EC
ED disjoint; however, event, E = EC ED .
Form refutation Lemma 11. add EC every leaf clause x
u , add
k
ED every leaf clause xu , add E every non-leaf clause. gives desired
derivation E.
Lemma 12 lets us generalize construction k-translations proofs.
typical example, next lemma gives k-translation following derivation:
677

fiBonet, Buss, & Johannsen

xu , x v , xw
xv , xw

xu
xw

xv

Lemma 13. Let w vertex G, u v predecessors. Then, clause
k
k
xk
w dag-like regular resolution derivation P clauses xu , xv ,
k
2k
(xu xv xw ) . derivation contains < 2 resolution inferences resolves
resolve
literals xu,i xv,i . addition, paths P lead clauses xk
v
exactly literals xv,i .
Lemma 13 follows applying Lemma 12 twice.
important note left-to-right order leaves derivation
Lemma 13 altered changing left-to-right order hypotheses resolution
inferences. particular, given leaf clause refutation P , order
hypotheses resolution inferences leftmost leaf clause.
useful needs learned.
Definition 14. Gw induced pointed subgraph G sink w containing
vertices vertex w reachable. G[w] subgraph G obtained
making vertex w leaf removing incoming edges, removing
vertices sink vertex G longer reachable. Note G[w] pointed
dag sink G.
vertex u ancestor w u = w u Gw, i.e., path
u w. call u v independent ancestors w provided u, v, w distinct
u (Gw)[v] v (Gw)[u]. means path u w
contain v, path v w contain u. write G[u, v]
G[u][v] = G[v][u].
generally, let 0 u1 , . . . , u , w distinct vertices. say u1 , . . . , u
independent ancestors w, every , path ui w
contain uj j = i. write G[u1 , . . . , u ] G[u1 ] [u ]. Note denition
G[u1 , . . . , u ] independent order ui s.
Since G dag, possible u v independent ancestors w, also
u ancestor v vice-versa.
next lemma states polynomial size regular resolution refutations
Pebk (G) clauses also apply subgraphs Gw (Gw)[u1 , . . . , u ]. write
Pebk
(G) denote k-translations Peb(G) clauses type () (), omitting
u
clauses type (), similarly GPebk
(G). save space, often write
instead u1 , . . . , u . instance, next lemma, ((Gw)[u]) \ {u, w} shorthand
((Gw)[u1 , . . . , u ]) \ {u1 , . . . , u , w}.
Lemma 15. Let w vertex G. Let 0 u1 , . . . u independent ancestors w.
clause (xu1 xu xw )k regular resolution derivation
u]). derivation uses resolution variables form xv,i
clauses Pebk
((Gw)[
v ((Gw)[u]) \ {u, w}. derivation dag-like size O(23k n) height O(kn).
Proof. simple regular dag-like derivation P xu1 xu xw clauses
() () (non-xoried) Peb(G), size O(n) n size G. P proceeds
678

fiSeparations Regular Resolution

visiting vertices v depth-rst traversal (Gw)[u] deriving subclause Cv
xu1 xu xv : subclause Cv contains xv xui path
ui v contains uj . v leaf distinct uj s, Cv xv
also Peb(G) clause type (). v immediate predecessors v1 v2 , Cv
formed resolving Cv1 Cv2 Peb(G) clause xv1 xv2 xv type ().
let U clause (xu1 xu )k W clause xk
w . need
give derivation U W . claim k-translation P k P forms desired
derivation. this, clause Cv P translated 2k1 many clauses CX
X xk
v . CX subclause U X; namely subclause omits literals
xui,j xui,j U xui
/ Cv . v1 v2 two immediate ancestors v
k
before, X xv , clause CX derived P k 22k2 many clauses CX1
CX2 Xi (xvi )k = 1, 2. Lemma 13, subderivation P k
height 2k size 22k , resolves exactly variables xv1 ,j xv2 ,j .
result variable xv,j resolved P k precisely xv resolved
P . And, since P size O(n), P k size O(23k n) height O(kn).
Proof. (of Theorem 10.) construct series LR partial refutations, denoted
R0 , R1 , R2 , . . .; process eventually terminates pool resolution (regRTL) refutation GPebk (G). terminology LR partial indicates refutation
constructed left-to-right order, left part refutation properly formed,
many remaining leaves labeled unnished clauses instead valid
learned clauses initial clauses GPebk (G).
LR partial refutation R tree nodes labeled clauses form correct
regRTI resolution refutation (and thus correct pool resolution refutation), except
unnished clauses leaves. Furthermore, must satisfy following conditions:
a. Rt tree nodes labeled clauses. root labeled empty clause.
non-leaf node Rt left child right child, clauses labeling
nodes form valid resolution inference.
b. leaf Rt either nished unnished. nished node leaf L labeled
either clause GPebk (G) clause derived input
subderivation Rt left L post-order. input subderivation may
contain unnished leaves.
c. unnished leaf labeled clause C E k E clause form
xu1 xu xw 0 u1 , . . . , u independent ancestors w. Furthermore
C pool contains literal xv,i v (Gw)[u] \ {u, w}.
introduce new notational convention describe (sub)clauses Rt . w vertex

k
G, notation W W denotes clause xk
w , W W denotes clause xw .


notation W W way denotes negation W W ; instead, names
clauses, overline meant serve reminder semantic meaning.
initial LR-partial refutation R0 formed follows. Let Q refutation
obtained k-translation inference
xt


679

xt

fiBonet, Buss, & Johannsen

given Lemma 11, sink G. 2k leaf clauses Q: half
k
labeled clauses xk
half labeled clauses xt .
derivation
Form R0 Q replacing leaf clause xk

, (T )

, (T )


resolving guard literal (T ). inferences regular, since (T ) xt,i .
clauses , (T ) , (T ) GPebk (G) hence nished clauses.
k
= 0;
leaf clauses, form xk
, satisfy condition c. = C xt
unnished clauses R0 .
inductive step 0, LR partial refutation Rt transformed Rt+1 .
goal replace one unnished leaf Rt , either derivation containing
nished leaves, derivation learns one Pebk (G) clause adding
polynomially many unnished leaves.
Consider leftmost unnished leaf Rt . condition c., clause C
k
form U 1 , . . . , U , W 0, U xk
ui , W xw . Lemma 15,
k
dag-like regular refutation P C clauses Peb ((Gw)[u]). wish
u])
convert P (if possible) derivation C clauses GPebk
((Gw)[
already learned clauses Rt . Consider particular leaf clause P ,
u]): needs handled way makes P valid
Pebk
((Gw)[
derivation. four cases consider:
(i) clause already learned input lemma Rt left C, may
used P is.
remaining cases, assume learned input lemma.
(ii) Let = (D). either member C pool , add literal
every clause reaching rst clause appears. replaces
u]) clauses Dy Dy. construction, preserves
one GPebk
((Gw)[
validity resolution inferences Rt well regularity property.
(iii) Suppose cases (i) (ii) apply used P resolution
variable D. case, replace resolution inference deriving
y. preserves regularity derivation. also makes
learned clause.
possible C Pebk
(G) clause. so, C = P trivial
derivation containing C, one cases (i)-(iii) holds.
leaf clauses P treated cases (i)-(iii), successfully
transformed P (still dag-like) derivation P satises regularity
leaf clauses GPebk (G) already learned input lemmas Rt . result
Buss et al. (2008, Thm. 3.3), P converted regRTI proof P conclusion
P , preserving regularity conditions, size P bounded twice
product size P height P . Therefore, size P O((23k n)(kn)) =
680

fiSeparations Regular Resolution

O(k23k n2 ). Form Rt+1 replacing clause C Rt derivation P . Rt+1 satises
conditions a.-c., one fewer unnished clauses Rt .
However, even one leaf clause P fails cases (i)-(iii), completely dierent
construction used form Rt+1 . Fix leaf clause P fall cases
(i)-(iii). unnished clause C Rt replaced small derivation C
learns (in leftmost inference), adds O(23k ) new unnished clauses
Rt+1 .
leaf clause k-translation () () clause Pebk (G) thus
k
either form E x
e source e G form A, B, E xa ,
k
B xk
b , E xe a, b, e vertices Gw b two predecessors
e G. Without loss generality, b ancestor G; otherwise interchange
b. two cases depending whether E A, B, E.
e source node G. claim e, u1 , . . . , u
First suppose E xk
e
independent ancestors w. already remarked, P trivial derivation since
otherwise cases (i)-(iii) would hold; therefore e equal w. Consequently, E
subclause nal clause C = U 1 , . . . U , W P . Hence xe,i resolved P .
Since P formed using Lemma 15, e therefore cannot equal ui . Since e (Gw)[u],
must exist path e w avoids nodes ui . Thus, since e source
node, vertices e, u1 , . . . , u independent ancestors w.
form Rt+1 , rst replace derivation P k-translation following:
xe

xe , U 1 , . . . , U , W
U 1, . . . , U , W

(2)

Note (2) contains blend variables Peb(G) (non-xoried) Pebk (G)
(xor-ied). However, still form k-translation Q: leaf clauses Q


k
2k clauses form E xk
e form E , U 1 , . . . , U , W E xe . choosing
appropriate left-to-right order hypotheses Q, arrange = E
leftmost leaf clause Q. Let = (D). one variables xe,i ,
C pool since condition (ii) hold D. Therefore, regularity condition
preserved modify Q replacing
D, (D)

D, (D)


(3)

Form Rt+1 Rt replacing C modied Q. causes become learned
input lemma Rt+1 . leaf clauses Q satisfy condition c. Rt+1
thus become unnished clauses Rt+1 : right D. adds < 2k
new unnished clauses Rt+1 . number inferences derivation structure less
2k .
Second suppose A, B, E, b predecessors e G. Suppose
moment e = w, nodes u1 , . . . , u distinct b.
reasoning previous case, e equal ui . begin replacing
681

fiBonet, Buss, & Johannsen

derivation P k-translation Q of:
xa , xb , xe
U , xa
U , xb , xe
U b , xb
U , U b , xe
Uw , x e , W
U 1, . . . , U , W

(4)

Ua , Ub Uw (possibly empty) sets literals form partition set
{U 1 , . . . , U }. must dene Ua , Ub , Uw (the k-translation of) clause
Ua , xa , clause Ub , xb clause Uw , xe , W fulll condition c. order
legitimate unnished leaves.
Since u1 , . . . , u independent ancestors w, x paths 1 , . . . , G
path ui w contain uj j = i. Call
a-path contains node a. Call b-path contains b contain a.
Finally, call w-path contains neither b. Then, dene Ua set
Ui a-path. Likewise, let Ub (respectively, Uw ) set Ui
b-path (respectively w-path). Clearly, Ua , Ub Uw form partition
{U1 , . . . , U }. Also, ui Ui Ua form set independent ancestors a, Ua , xa
satises condition c. Likewise, clauses Ub , xb Uw , xe , W also satisfy condition c.
prove latter, note path ui w contains e must contain least one
b.
k-translation Q (4) leftmost leaf clause. Let = (D).
one variables xa,i , xb,i , xe,i , C pool since condition (ii)
hold D. Therefore, regularity condition preserved modify Q replacing
(3). Form Rt+1 Rt replacing C modied Q. causes
become learned input lemma Rt+1 . previously argued, leaf clauses
Q become valid unnished clauses satisfy condition c. Rt+1 gains < 23k new
inferences, less 3 2k new unnished clauses.
still consider cases u1 , . . . , u , b distinct.
2 (very similar) cases one ui {a, b}. instance, suppose
u1 = ui equal b. claim clause U1 . prove
this, note dierent U1 , literal xu1 ,j xu1 ,j appearing
appears negated form xu1 ,j xu1 ,j (respectively) U1 . implies
derivation P uses xu1 ,j resolution variable, contradicting fact P formed
via Lemma 15. = U1 , form Q k-translation
U 1 , xb , xe
U b , xb
U b , U 1 , xe
U w , xe , W
U 1, . . . , U , W
Ub Uw dened (and Ua equals {U1 }). Order Q
leftmost leaf clause, form Rt+1 previous paragraph.
case i, j = j, ui = uj = b, proof
structure even simpler: Suppose u1 = u2 = b. Similarly previous case,
B must U1 U2 , respectively. let Q k-translation
U 1 , U 2 , xe
xe , U 3 , . . . , U , W
U 1, . . . , U , W
682

fiSeparations Regular Resolution

(so Uw = {U3 , . . . , U }) proceed before.
Finally, consider case w = e. Clearly, Ui ancestor either b.
Therefore, Ui Ua Ub . refutation Rt+1 formed proof structure
(4), omitting last inference.
concludes construction Rt+1 Rt . process constructing Rt halts
remaining unnished clauses, yields nal refutation R
valid regRTI refutation GPebk (G) clauses.
need bound size refutation R. First consider Rt+1 formed
Rt . cases (i)-(iii), unnished leaf completely handled without adding
new unnished leaves. cases, O(k23k n2 ) many new clauses introduced
Rt+1 . case (iv), new Pebk (G) clause learned input lemma adding
O(3 2k ) many new unnished leaves Rt+1 (and O(23k ) new clauses).
Even though exponentially many potential unnished clauses, case (iv) construction occur polynomially many times polynomially
many Pebk (G) clauses learned. Indeed, < n23(k1) many Pebk (G)
clauses. Therefore, O(n23(k1) 3 2k ) many distinct unnished leaf clauses appear construction R. Consequently, cases (i)-(iii) occur many times.
Therefore, total number clauses R bounded O(n23(k1) 3 2k k23k n2 ) =
O(27k n3 ). Thus size R polynomially bounded size GPebk (G) clauses;
fact, bounded degree three polynomial.
completes proof Theorem 10.

4. Guarded Graph Tautologies
dene various graph tautologies, sometimes also called ordering principles.
use size parameter n > 1, variables xi,j i, j [n] = j, [n] =
{0, 1, 2, . . . , n1}. variable xi,j intuitively represent condition j
intended total, linear order. thus always adopt simplifying convention
xi,j xj,i identical literal, i.e., variables xi,j < j actually exist,
xj,i j < notation xi,j , xj,i stands xi,j . identication
makes essential dierence complexity proofs tautologies, reduces
number literals clauses, simplies denitions. particular, means
axioms antisymmetry totality .
following GTn clauses based tautologies dened Krishnamurthy
(1985). tautologies, similar ones, also studied Stalmarck (1996),
Bonet Galesi (2001), Segerlind, Buss, Impagliazzo (2004), Beckmann Buss
(2005), Van Gelder (2006), Alekhnovich et al. (2007) Johannsen (2009).
Definition 16. Let n > 1. GTn following set clauses:

( ) clauses j=i xj,i , value < n.
( ) transitivity clauses Ti,j,k := xi,j xj,k xk,i distinct i, j, k [n].
Note clauses Ti,j,k , Tj,k,i Tk,i,j identical. reason Van Gelder
(2005) uses name triangles (NT) similar principle.
next denition due Alekhnovich et al. (2007), used notation GTn .
used particular functions r lower bound proof, since upper
683

fiBonet, Buss, & Johannsen

bound proof depend details r leave unspecied.
require r(i, j, k) = s(i, j, k) set {r(i, j, k), s(i, j, k)} {i, j, k}. addition,
w.l.o.g., r(i, j, k) = r(j, k, i) = r(k, i, j), similarly s.
Definition 17. Let n 1, let r(i, j, k) s(i, j, k) functions mapping [n]3 [n]
above. guarded graph tautology clauses, GGTn , consist of:

( ) clauses j=i xj,i , value < n.
( ) guarded transitivity clauses Ti,j,k xr,s Ti,j,k xr,s , distinct i, j, k
[n], r = r(i, j, k) = s(i, j, k).
Note GGTn clauses depend functions r s; suppressed
notation. rst main result guarded graph tautologies is:
Theorem 18. guarded graph tautology clauses GGTn polynomial size pool resolution (regRTL) refutations.
proof Theorem 18 construct pool refutations form regular tree-like
refutations lemmas. key part learning transitive closure clauses
derived using resolution guarded transitivity clauses GGTn . slightly modied
construction, uses result Buss et al. (2008), gives instead tree-like regular resolution
refutations input lemmas. establish following:
Theorem 19. guarded graph tautology clauses GGTn polynomial size, tree-like
regular resolution refutations input lemmas (regRTI refutations).
discussed introduction, Theorem 19 result Buss et al. (2008) together
imply GGTn clauses shown unsatisable non-greedy polynomial size CDCL.
follows via mentioned theorem Buss et al. (2008, Thm. 5.6), since refutations
GGTn regRTI, hence regWRTI, proofs sense Buss et al.. Theorem 31
Section 5 improve giving greedy CDCL refutations.
Theorem 19 strictly stronger Theorem 18, nd convenient prove
Theorem 18 rst.
4.1 Resolution Refutations Guarded Graph Tautologies
following theorem important ingredient upper bound proof.
Theorem 20. (Stalmarck, 1996; Bonet & Galesi, 2001; Van Gelder, 2006) sets GTn
regular resolution refutations Pn polynomial size O(n3 ).
proofs Theorems 18 19 use refutation Pn black box:
property needed Pn regular polynomial size. Section 5 need use
details Pn however.
Proof. (Proof sketch Theorem 20.) , k [n], dene clause Totk,

xj, ,
Totk, :=
j[k+1]\{}

684

fiSeparations Regular Resolution

Tot3,3

Tot3,2

Tot3,1

Tot3,0

Tot2,2

Tot2,1

Tot2,0

Tot1,1

Tot1,0
Tot0,0 = 2

Figure 1: Main structure regular refutation Pn GTn clauses, n = 4.
Inferences resolve transitivity clauses Ti,j,k shown: slanted
line Totk+1,k+1 Totk, represents k many resolution inferences
clauses T,i,k+1 [k + 1] \ {}. subderivation hypotheses Totk,k
Totk, conclusion Totk1, input derivation.

expresses condition predecessor j k. course, clauses Totn1, ,
= 0, 1, . . . , n 1, initial clauses ( ) GTn . Note Tot0,0 empty
clause.
pictured Figure 1, Pn proceeds deriving Totk, Totk+1,k+1 Totk+1,
k = n2, . . . , 0 k, deriving empty clause Tot0,0 . rst part
derivation Totk, resolves Totk+1,k+1 successively k many transitivity clauses
T,i,k+1 [k + 1] \ {}. convention xi, x,i literal, T,i,k+1
clause xi, , xi,k+1 , xk+1, . resolution T,i,k+1 uses xi,k+1 resolution
literal eect adding xk+1, clause, replacing xi,k+1 xi, . Thus,
conclusion k resolution steps

xk+1,
xi, .
i[k+1]\{}

One nal resolution Totk+1, literal xk+1, yields Totk, desired.
regularity Pn evident inspection.
refutations Pn modied give refutations GGTn rst deriving
transitive clause Ti,j,k two guarded transitivity clauses ( ). however
destroys regularity property, already discussed, polynomial size regular refutations exist GGTn (Alekhnovich et al., 2007).
usual, partial order [n] antisymmetric, transitive binary relation [n].
primarily interested bipartite partial orders, partial orders
chain inequalities x z.
Definition 21. bipartite partial order binary relation [n] domain
range intersect. write x (x, y) . set -minimal
elements denoted .
righthand side Figure 2 shows example. bipartiteness arises
/ .
fact [n] \ partition [n] two sets. j, j
685

fiBonet, Buss, & Johannsen

10
6

11
7

8

9



:
1

2

3

4

6

[n] :
1

2

10 7 8 9 11
3

4

5

5

Figure 2: Example dag (left) associated bipartite partial order (right).
addition, contains isolated points . permitted empty
relation, = [n].
(bipartite) partial order [n] also viewed directed acyclic graph (dag)
G = ([n], ); note [n] set vertices, set edges G. Conversely,
dene mapping arbitrary dag G = ([n], ) associated bipartite partial
order :
Definition 22. Let G = ([n], ) dag. write x +
denote G contains
path length 1 x y. bipartite partial order associated G dened
letting x hold precisely x -minimal G (that is, x indegree 0)
x +
y.
Note denition require transitive. easy check
associated fact bipartite partial order. intuition retains
information whether +
j minimal elements i, forgets ordering
imposes non-minimal elements.
dene graph tautology clauses GT,n relative follows.
Definition 23. Let bipartite partial order [n]. GT,n contains:

() clauses j=i xj,i , value .
() transitivity clauses Ti,j,k := xi,j xj,k xk,i distinct i, j, k . (Vertices
i, j, k Figure 3 show example.)
() transitivity clauses Ti,j,k distinct i, j, k i, j k
j k. (As shown Figure 3.)
set GT,n satisable nonempty. example, assignment
/ every , sets variables
sets xj,i true xed j
false. However, applied restriction, GT,n becomes unsatisable.
say, assignment satises GT,n consistent . fact
proved regular derivation P described next lemma.

Definition 24. bipartite partial order, clause ( )

:= {xi,j : j}.
Lemma
25. Let bipartite partial order [n]. regular derivation P

( ) set GT,n .
variables resolved P following: variables xi,j
/ , , k.
i, j , variables xi,k k
686

fiSeparations Regular Resolution

1

[n] \ :

2

:



3

k
j

k

Figure 3: bipartite partial order pictured, ordered pairs shown
directed edges. (For instance, j k holds.) set set minimal
vertices. nodes i, j, k shown example nodes used transitivity
axiom xi,j xj,k xk,i type (). nodes i, j, k example nodes
transitivity axiom type ().

Lemma 25 implies bipartite partial order associated dag ,
P resolve literal whose value set . proved noting
/ .
j, j
empty, = [n] clauses type (). case, GT,n
identical GTn , P Lemma 25 refutation GTn
Theorem 20.
Proof. renumbering vertices, assume w.l.o.g. = {0, . . . , m1}.
k m, least one value j j k: let Jk arbitrary
value j. Note Jk < m.
Fix ; is, < m. Recall clause type () GT,n
j=i xj,i . resolve clause successively, k k,
clauses Ti,Jk ,k type ()
xi,Jk xJk ,k xk,i
using resolution variables xk,i . (Note Jk = since k.) yields clause Totm1,i :




xi,Jk
xJk ,k
xk,i
xk,i .
km
k

km
k

km
k

k<m
k=i

rst two disjuncts shown come
side literals clauses Ti,Jk ,k ;
last two disjuncts come literals j=i xj,i resolved on. Since
literal xi,Jk literal xJk ,i since Jk < m, literals rst disjunct
also contained fourth disjunct. Thus, eliminating duplicate literals, Totm1,i equal
clause



xJk ,k
xk,i
xk,i .
(5)
Si Totm1,i :=
km
k

km
k

k<m
k=i

Si dened equal rst two big disjuncts lefthand side equation,
Totm1,i before, namely last big disjunct righthand side.
Repeating process, obtain derivations clauses Totm1,i < m.
subclauses Totm1,i ( ) clauses GTm . Thus, clauses Totm1,i
give ( ) clauses GTm , Si added side literals. Moreover, clauses
type () GT,n exactly transitivity clauses GTm . clauses
687

fiBonet, Buss, & Johannsen

Tot3,3

Tot3,2

Tot3,1

Tot3,0

Tot3,3

Tot3,2

Tot3,1

Tot3,0

Tot2,2

Tot2,1

Tot2,0

Tot1,1

Tot1,0

Tot0,0 = ( )

Figure 4: Main structure regular derivation P , = 4. initial clauses
GTm clauses. Inferences resolve transitivity clauses Ti,j,k
shown: slanted lines top row vertical lines represent multiple resolution
inferences transitivity clauses.

combined exactly refutation GTm described Theorem 20, carrying along
extra side literals Si ; namely carrying along literals xJk ,k Jk k, xi,k k.
Since refutation GTm uses transitivity clauses since xJk ,k literal
xi,k k, yields resolution derivation P clause
{xi,k : k}.

clause ( ) desired.

just-constructed derivation P ( ) structure shown Figure 4:
clauses Totk,i equal
Totk,i


Si Totk,i
Totk,i
=
im1 m1

j=i Sj Totk,i

k = 1
< k < 1
= k

(6)

show P regular, note rst parts P deriving clauses Toti,m
regular construction, use resolution variables xk,i < k,
k. remaining part P also regular Theorem 20, uses resolution
variables xi,j i, j m.
4.2 Pool w-Resolution Refutations GGTn
prove Theorem 18, indicate minor changes needed prove Theorem 19.
Proof. (Theorem 18) construct nite sequence LR partial refutations,
denoted R0 , R1 , R2 , . . .. terminates nitely many steps desired pool
(regRTL) refutation R GGTn . LR partial refutation Rt correct pool
688

fiSeparations Regular Resolution

resolution refutation, except possibly presence unnished clauses leaves.
Unnished clauses correspond bipartite partial orders. Rt satisfy
following conditions:
a. R tree. root labeled empty clause. non-leaf node R
left child right child; clause labeling node derived resolution
clauses two children.
b. clause C occurring R, set ordered pairs (C) dened (C) =
{i, j : xi,j C pool }. many cases, (C) dag, always true.
instance, C transitivity axiom, (C) 3-cycle dag.
d. Leaves either nished unnished. nished leaf L labeled either
clause GGTn clause occurs left L post-order traversal
R.
e. unnished leaf labeled clause C, set (C) dag. Furthermore, letting

bipartite partial order associated (C), clause C equal ( ).
Property e. particularly crucial novel construction. shown below,
unnished leaf, labeled clause C = ( ), replaced derivation S.
derivation often based P , thus might expected end exactly
clause C; however, resolution inferences needed P might disallowed
regularity property pool resolution proofs. mean instead
derivation clause C C C C pool . condition C C pool required
literal x C \ C handled modifying refutation R propagating
x downward R reaching clause already contains x. Since C C pool ,
clause exists. fact C C implies enough literals present
derivation use (non-degenerate) resolution inferences virtue fact
constructions pick C contains literals must present use
resolution literals.
construction begins letting R0 empty refutation, containing
empty clause. course, clause unnished leaf, () = . Thus R0 valid
LR partial refutation.
induction step, Rt constructed already. Let C leftmost unnished
clause Rt . Rt+1 formed replacing C (LR-partial) derivation
clause C C C C pool .
need describe S. Let bipartite partial order
associated (C),
consider derivation P Lemma 25. Since C ( ) condition e., nal
line P clause C. intuition would like let P . rst
diculty P dag-like, LR-partial refutation intended
tree-like, diculty, however, circumvented expanding P ,
regular, tree-like regular derivation lemmas simple expedient using
depth-rst traversal P . second, serious, diculty P derivation
GTn , GGTn . Namely, derivation P uses transitivity clauses GTn
initial clauses instead guarded transitivity clauses GGTn . transitivity clauses
Ti,j,k := xi,j xj,k xk,i P handled one time described below. four
689

fiBonet, Buss, & Johannsen

separate constructions: case (i) requires change P ; cases (ii) (iii) require small
changes; fourth case, subproof P abandoned favor learning
transitivity clause.
remark Lemma 25, literal C pool used resolution literal P .
(i) Suppose transitivity clause Ti,j,k P already appears earlier Rt , is, left
C post-order. Ti,j,k already learned, used freely P .
(Since building pool resolution refutation, w-resolution refutation,
need Ti,j,k input lemma.)
remaining cases (ii)-(iv), transitivity clause Ti,j,k yet learned. Let guard
variable Ti,j,k xr,s , r = r(i, j, k) = s(i, j, k).
(ii) Suppose case (i) apply guard variable xr,s negation xr,s
member C pool . guard variable thus used resolution variable somewhere
along branch root clause C. Then, mentioned above, Lemma 25
implies xr,s resolved P . Therefore, add literal xr,s xr,s
(respectively) clause Ti,j,k every clause path Ti,j,k
reaching clause already contains literal. replaces Ti,j,k one
initial clauses Ti,j,k xr,s Ti,j,k xr,s GGTn . Note adds literal xr,s
xr,s nal clause C modied P . maintains property
C C C pool .
(iii) Suppose case (i) apply xr,s used resolution variable
Ti,j,k P neither xr,s xr,s member C pool . case, P
modied derive clause Ti,j,k two GGTn clauses Ti,j,k xr,s
Ti,j,k xr,s resolving xr,s . maintains regularity derivation.
also means henceforth Ti,j,k learned.
transitivity clauses P handled cases (i)-(iii), use P
dene Rt+1 . Namely, let P derivation P modied applications cases
(ii) (iii). derivation P regular dag-like, recast tree-like
derivation lemmas, using depth-rst traversal P . size linear
size P , since lemmas need repeated. nal line clause C ,
namely C plus literals introduced case (ii). derivation Rt+1 formed Rt
replacing clause C derivation C , propagating new literal
x C \ C towards root Rt , adding x clause reaching
clause already contains x. derivation contains unnished leaf, Rt+1
contains one fewer unnished leaves Rt .
hand, even one transitivity axiom Ti,j,k P covered
three cases, case (iv) must used instead. introduces completely dierent
construction form S:
(iv) Let Ti,j,k transitivity axiom P covered cases (i)-(iii).
case, guard variable xr,s used resolution variable P somewhere
Ti,j,k ; general, means cannot use resolution xr,s derive Ti,j,k
maintaining desired pool property. Hence, P longer used,
690

fiSeparations Regular Resolution

instead form short left-branching path learns Ti,j,k .
generate two three new unnished leaf nodes. Since unnished leaf nodes
LR partial derivation must labeled clauses bipartite partial orders,
also necessary attach short derivations unnished leaf nodes make
unnished leaf clauses correspond correctly bipartite partial orders.
unnished leaf nodes kept Rt+1 handled later stages.
construction described detail next, depends whether Ti,j,k type
() (). base case R0 type (), describe type () construction
rst somewhat simpler.
Suppose Ti,j,k type (), thus xj,k appears C. (Refer Figure 3.) Let xr,s
guard variable transitivity axiom Ti,j,k . derivation form
S1 . . .. . .
xi,j , xj,k , xk,i , xr,s
xi,j , xj,k , xk,i , xr,s
...
xi,j , xj,k , xk,i
xi,j , xi,k , [jk;jR(i)]
xi,j , xj,k , [jk;jR(i)]
xj,k , [jk]

S2 . . .. . .
...
xj,i , xj,k , [jk;iR(j)]

notation [jk] denotes disjunction negations literals omitting
literal xj,k . write iR(j) indicate literals xi, j . (The R(j) means
range j.) Thus [jk;iR(j)] denotes clause containing negations literals
, omitting xj,k literals xi, j . clause [jk;jR(i)] dened
similarly.
upper leftmost inference resolution inference variable xr,s . Since
Ti,j,k covered either case (i) (ii), variable xr,s C pool . Thus,
use xr,s resolution variable violate regularity. Furthermore, since Ti,j,k
type (), (C) j, j (C) i, (C) k, k (C) i. Thus literals xi,j xi,k
C pool , also resolved without violating regularity.
Let C1 C2 nal clauses S1 S2 , let C1 clause C1
C. set (C2 ) obtained adding j, (C), similarly (C1 ) (C)
plus i, j. Since Ti,j,k type (), i, j . Therefore, since (C) dag, (C2 )
dags
(C1 ) also dags. Let 2 1 bipartite orders associated
(respectively). form subderivation S1 contains clause ( 1 )
unnished clause. require adding inferences S1 add remove
appropriate literals. rst step type already occurs going C1 C1
since removed xj,k added xi,k , reecting fact j 1 -minimal
/ 1 . Similarly, form S2 unnished clause
thus
xi,k 1 xj,k
( 2 ).
rst describe subderivation S2 . situation pictured Figure 5,
shows extract Figure 3: edges shown part (a) gure correspond
literals present nal line C2 S2 . particular, recall literals xi,
j omitted last line S2 . (Correspondingly, edge 1
omitted Figure 5.) last line C2 S2 may correspond bipartite partial
order may partition [n] minimal non-minimal elements; thus, C2 may
qualify unnished node Rt+1 . (An example Figure 5(a)
691

fiBonet, Buss, & Johannsen

1

2

k

1

3


j
(a) xj,k , xi,2 , xj,i ,

2

k

3


j
(b) xj,k , xi,2 , xj,i ,

Figure 5: partial orders fragment S2 shown (7).

j (C2 ) (C2 ) 2 , corresponding xj,i xi,2 C2 .) bipartite partial
order 2 associated (C2 ) equal bipartite partial order agrees
except condition replaced condition j 2 . (This represented
Figure 5(b) fact edge 2 replaced edge
/ M2 .)
j 2 . Note vertex longer minimal element 2 ; is,

wish form S2 regular derivation clause xj,i , [jk;iR(j)] clause
( 2 ).
subderivation S2 replacing xi,2 xj,2 2 follows, letting
[jk;iR(j);i2] .
. . .. . . rest S2
S2 . . .. . .
...
...
xj,i , xi,2 , x2 ,j
xj,k , xj,2 , xj,i ,
xj,k , xi,2 , xj,i ,

(7)

part labeled rest S2 handle similarly literals
j . nal line S2 transitivity axiom Tj,i,2 . GTn axiom,
GGTn axiom; however, handled methods cases (i)-(iii). Namely,
Tj,i,2 already learned appearing somewhere left Rt , S2
single clause. Otherwise, let guard variable Tj,i,2 xr ,s . xr ,s used
resolution variable Tj,i,2 , replace Tj,i,2 Tj,i,2 xr ,s Tj,i2 xr ,s ,
propagate xr ,s xr ,s clauses branch leading Tj,i,2 reaching
clause already contains literal. Finally, xr ,s used resolution
variable Rt C, let S2 consist resolution inference deriving (and learning)
Tj,i,2 clauses Tj,i,2 , xr ,s Tj,i,2 , xr ,s .
complete construction S2 , inference (7) repeated value
. result S2 one unnished leaf clause, labeled
j
clause ( 2 ).
next describe subderivation S1 . situation shown Figure 6.
formation S2 , nal clause C1 S1 may need modied order correspond
bipartite partial order 1 associated (C1 ). First, note literal
xj,k already replaced xi,k nal clause S1 . change needed
that, every j , must replace xj, xi, since
j 1 1 . Vertex 3 Figure 6 example value . ordering
nal clause S1 shown part (a), desired ordered pairs 1 shown
part (b). Note j longer minimal element 1 .
692

fiSeparations Regular Resolution

1

2

k

1

3


j
(a) xi,k , xj,3 , xi,j ,

2

3

k


j
(b) xi,k , xi,3 , xi,j ,

Figure 6: partial orders fragment S1 shown (8).
replacement xj,3 xi,3 eected following inference, letting
[jk;jR(i);j3] .
. . .. . . rest S1
S1 . . .. . .
...
...
(8)
xi,j , xj,3 , x3 ,i
xi,k , xi,3 , xi,j ,

xi,k , xj,3 , xi,j ,
rest S1 handle similarly literals j .
Note nal clause S1 transitivity axiom Ti,j,3 . subderivation S1
formed exactly way S2 formed above. Namely, depending
status guard variable xr ,s Ti,j,3 , one following done: (i) clause Ti,j,3
already learned used is, (ii) one xr ,s xr ,s added clause
propagated proof, (iii) clause Ti,j,3 inferred using resolution xr ,s
becomes learned.
complete construction S1 , inference (8) repeated value
j . result S1 one unnished leaf clause,
corresponds bipartite partial order 1 .
completes construction subcase (iv) Ti,j,k type ().
suppose Ti,j,k type (). (For instance, values i, j, k Figure 3.) case,
form
S3 . . .. . .
Ti,j,k , xr,s Ti,j,k , xr,s
...
S4 . . .. . .
Ti,j,k
xi,j , xi,k , [jR(i),kR(ij)]
...
xi,j , xj,k , [jR(i),kR(ij)]
xi,j , xk,j , [jR(ik)]
xi,j , [jR(ik)]


S5 . . .. . .
...
xj,i , [iR(j)]

xr,s guard variable Ti,j,k . write [ [jR(ik)] ] mean negations
literals omitting literal xj, k . Similarly,
[jR(i),kR(ij)] indicates negations literals , omitting literals xj,
literals xk, either j .
Note resolution xr,s used derive Ti,j,k violate regularity, since
otherwise Ti,j,k would covered case (ii). Likewise, resolutions xi,j , xi,k
xj,k violate regularity since Ti,j,k type ().
subderivation S5 formed exactly like S2 above, exception
literal xj,k present. Thus omit description S5 .
next describe construction S4 . Let C4 nal clause ofS4 ; easy
check (C4 ) dag. before, must derive C4 clause ( 4 ) 4
bipartite partial order associated (C4 ). typical situation shown Figure 7.
693

fiBonet, Buss, & Johannsen

1

2

1

3

j

k
(a) xi,j , xk,j , xj,2 ,

2

3

j
k
(b) xi,j , xi,2 , xk,j , xk,2 ,


Figure 7: partial orders changed S4 .
pictured there, necessary add literals xi, j ,
removing xj, ; examples equal 2 3 Figure 7. time,
must add literals xk, j k , removing xj, ; examples
equal 1 and, again, 2 gure.
vertex 3 j 3 k 3 3 , done similarly
inferences (7) (8) without side literal xj,k :
. . .. . . rest S4
S4 . . .. . .
...
...
xi,j , xj,3 , x3 ,i
xi,3 , xk,j , xi,j ,
xj,3 , xk,j , xi,j ,

(9)

[jR(ik);j3] . transitivity axiom Ti,j,3 shown last line S4 handled
exactly before. construction repeated 3 s.
vertices 1 j 1 1 k 1 handled exactly
way. (The side literals change time reect literals already
replaced.)
Finally, consider vertex 2 2 j 2 k 2 . handled
derivation
S4 . . .. . .
...
xi,j , xj,2 , x2 ,i

. . .. . . rest S4
S4 . . .. . .
...
...
xk,j , xj,2 , x2 ,k
xi,j , xi,2 , xk,j , xk,2 ,
xi,j , xi,2 , xk,j , xj,2 ,
xi,j , xk,j , xj,2 ,

before, set side literals changed reect literals already
added removed S4 created. subderivations S4 S4
transitivity axioms Ti,j,2 Tk,j,2 handled exactly before, depending status
guard variables.
Finally, describe form S3 . this, must form bipartite partial order 3
associated (C3 ), C3 nal clause S3 . obtain 3 , need
add literals xi, either j k ,
removing literals xj, xk, . done exactly construction used
(9). literals [jR(i);kR(ij)] exactly literals needed carry
out. construction quite similar constructions, omit
description.
completes description construct LR partial refutations Rt .
process stops Rt unnished clauses. claim process stops
polynomially many stages.
694

fiSeparations Regular Resolution

prove this, recall Rt+1 formed handling leftmost unnished clause
using one cases (i)-(iv). rst three cases, unnished clause replaced
derivation based P bipartite order . Since P size O(n3 ), means
number clauses Rt+1 number clauses Rt plus O(n3 ).
Also, construction, Rt+1 one fewer unnished clauses Rt . case (iv) however,
Rt+1 formed adding O(n) many clauses Rt plus adding either two three
new unnished leaf clauses. addition, case (iv) always causes least
n
one transitivity
axiom Ti,j,k learned.
Therefore, case (iv) occur 2 3 = O(n3 ) times.
Consequently 3 2 n3 = O(n3 ) many unnished clauses added throughout
entire process.
process stops Rt unnished clauses
n
follows
3
6 3 = O(n ). Therefore pool refutation GGTn O(n6 ) lines.
Since GGTn principle O(n3 ) many clauses, number inferences refutation
bounded quadratic polynomial number clauses refuted.
inspection, clause refutation contains O(n2 ) literals.
largest clauses corresponding (small modications of) bipartite partial
orders, bipartite partial orders contain O(n2 ) many ordered pairs.
Furthermore, refutations Pn GTn contain clauses size O(n2 ).
Q.E.D. Theorem 18
Theorem 19 proved nearly construction. fact, change
needed construction P . Recall proof Theorem 18, pool
derivation formed using depth-rst traversal P . sucient
Theorem 19, since derivation must use input lemmas. Instead,
use result Buss et al. (2008, Thm. 3.3), states (regular)
dag-like resolution derivation transformed (regular) tree-like derivation
input lemmas. Forming way P suces proof Theorem 19:
lemmas either transitive closure axioms derived earlier Rt derived
input subderivations earlier post-order S. Since transitive closure axioms
appeared earlier Rt derived resolving two GGTn axioms, lemmas used
input lemmas.
transformation theorem Buss et al. (2008, Thm. 3.3) may multiply size
derivation depth original derivation. proofs P depth O(n),
regRTI refutation overall size O(n7 ). completes proof Theorem 19.

5. Greedy Unit Propagating CDCL
section proves guarded graph tautology clauses GGTn refuted
polynomial-time greedy, unit propagating CDCL search without restarts. One diculty
even know whether regular dag-like resolution refutations polynomially simulated greedy, unit propagating CDCL without restarts. Therefore, must
rst establish Theorems 26 30 showing greedy, unit propagating CDCL
refutations without restarts graph tautologies GTn GT,n . Theorem 31
gives polynomial-time greedy, unit propagating CDCL algorithm (without restarts)
GGTn . intuition CDCL search traverses regRTI refutations GGTn
695

fiBonet, Buss, & Johannsen

Theorem 19, learning transitivity clauses Ti,j,k whenever possible. also need
use notion absorption used Atserias et al. (2011) Pipatsrisawat
Darwiche (2011).
give quick overview CDCL search algorithms clause learning algorithms;
greater detail, see works Marques-Silva Sakallah (1999) Beame et al. (2004).
Given set clauses input, CDCL search maintains stack literals assigned
value True collection learned clauses. simplied, general, form
procedure CDCL without restarts follows:
Input: set clauses.
Algorithm:
Set := .
Loop:
unit propagation yields contradiction,
Halt. unsatisable.
Else unit propagation assigned literals
yields contradiction,
Infer zero clauses input resolution based
conict, add . (Learning)
Select , set = \ . (Garbage collection)
Unassign last assigned literal. (Backtracking)
Else literals assigned value,
Halt. satisable.
Else
Choose unassigned literal, assign value True.
Endif
above-described CDCL algorithm lacks many important features usual implementations CDCL algorithms. However, simplied CDCL algorithm polynomially simulate sophisticated implementations CDCL learning unlearning
appropriate clauses. Conversely, sophisticated CDCL algorithms polynomially simulate simplied CDCL algorithm, since proving polynomial time
runtime simplied algoithm, certainly implies polynomial time runtime
sophisticated CDCL algorithms (subject usual specifying decision literals
set clauses learned garbage collected).
clause learning used Theorems 26 30 usual rst-UIP (unique
implication point) clause learning, learn clauses obtained picking
cut conict graph, common CDCL algorithms.
Theorem 26. Greedy, unit propagating CDCL search without restarts refute GTn
clauses polynomial time.
Proof. Recall construction refutations Pn GTn clauses pictured
Figure 1. key property needed derivation Totk,j Totk+1,k+1
Totk+1,j input derivation, permit learning Totk,j Totk+1,k+1
Totk+1,j learned.
696

fiSeparations Regular Resolution

give direct description CDCL search. search initially chooses
set literals x1,0 , x2,1 . . ., xn2,n3 true decision literals, order, xi+1,i
set true (decision) level + 1. literal xi,j interpreted meaning j
partial order ; thus decision literals express n 2 n 3 1 0 holds.
Unit propagation transitive closure clauses implies literals xj,i ,
words j i, 0 < j n 2. literal xj,i derived level j.
reaching literal xn2,n3 , unit propagations possible. But, upon
assigning xn2,n3 true, clause Totn1,n2 becomes unit clause, xn1,n2 inferred. words, n 1 n 2 inferred. Now, literals xn2,j , unit
propagations transitive closure clauses gives xn1,j , n j, j < n2.
falsies Totn1,n1 , yields conict, CDCL search backtracks previous
level.
backtracks, CDCL algorithm learns two clauses Totn3,n3 xn3,n2
Totn2,n2 , sets decision literal xn2,n3 false level n 3. rst clause
learned taking decision literal xn2,n3 UIP, since literals xn3,j j <
n3 literals level < n3 used infer level n2 literals conict
graph. see possible learn second clause Totn2,n2, note conict
obtained via unit propagation decision literal xn2,n3 literals xn2,j ,
Totn2,n2 contains exactly negations literals. literals xn2,j
set level n 2, Totn2,n2 learned UIP; nonetheless, falls within
commonly permitted CDCL learning. Totn3,n3 xn3,n2 learned,
literal xn3,n2 follows single unit propagation.
rst backtrack, decision literals x1,0 , x2,1 , . . ., xn3,n4 set true
decision literals, Totn2,n2 Totn3,n3 xn3,n2 learned, xn3,n2 true
level n 3 unit propagation. possible use unit propagation get yet another
conict. However, instead describing this, go general cases.
general case, parameters , r, 0 < r < < n either
= r + 1 = n 1. general case, literals x1,0 , x2,1 , . . ., x,1 set true
rst decision literals literals x,+2, x,+3 , . . . , x,r set next
decision literals, three clauses Tots, , Tot, x,+1 , Totk,k k >
learned. (Refer Figure 1. situation previous paragraph = n 3,
r = n 2, = n 1.) Using Tot, x,+1 unit propagation, literal x,+1
set level . terms , literals set true express conditions
1 1 0

j j = + 1, . . . , r.

(10)

r < 1 = n 2, unit propagation yield contradiction, CDCL search
proceeds setting x,r+1 true next decision literal. CDCL search
general case parameters , r+1, n1.
r = 1, unit propagation transitivity clauses yields x,j , namely j,
j [s] \ {}. makes Tots, unit clause thus xs, , namely , set true
unit propagation. Using literals x,j again, unit propagation transitivity clauses
falsies learned clause Tots,s . CDCL algorithm backtracks one level.
r > + 1, learns Tots1, . learned since conict obtained
literals x,j j [s] \ {}. learned clause Tots, forgotten garbage collection.
puts CDCL search new general situation parameters , r1, s1.
697

fiBonet, Buss, & Johannsen

r = + 1 = 1, two clauses Tot, Tot1,1 x1, learned instead.
second clause clause obtained usual learning algorithm using decision
literal x,1 UIP. clause Tot, learned since conict graph used
literals x,j j < obtain conict: obtained UIP, obtained
using cut conict graph. Garbage collection used forget clauses
Tot, x,+1 Tots, . puts CDCL search general case, new
, r, parameters equal 1, , n 1, respectively.
CDCL search ends dealing case = 0, r = 1 = 2. case,
empty clause Tot0,0 learned, CDCL search halts, establishing GTn
unsatisable.
next theorem discusses greedy, unit propagating CDCL search simulate
derivations P graph tautologies GT,n obtained restricting GTn
bipartite partial order . course, fully make sense, since CDCL search
simulates refutations, derivations. really want simulate P
subderivation regRTI refutations GGTn constructed Theorem 19. this,
let C clause regRTI refutation GGTn . Let dag j
xi,j C pool , let associated bipartite partial order, C clause ( ).
claim greedy, unit propagating CDCL refutation (non-guarded) GT,n
clauses literals xi,j j. words, greedy, unit propagating
CDCL search refute GTn clauses set literals C pool false.
state Theorem 30 full generality, need following denitions.
modications denitions Atserias et al. (2011) Pipatsrisawat Darwiche (2011).
Definition 27. Let C clause x literal C. say C u.p.-absorbed x
set clauses provided every literal C \ {x} set false, x implied
unit propagation using clauses . say C u.p.-absorbed provided
u.p.-absorbed every x C. say C absorbed provided
literals C set false, unit propagation using yields contradiction.
clause C becomes u.p.-absorbed, becomes redundant terms unit propagation. particular, adding C additional clause would yield additional
conicts would make possible learn additional clauses conicts.
need slightly general denition, however.
Definition 28. Let C above, let L set literals. write L denote
set unit clauses {x} x L, i.e. clauses asserting every x L false. C
L-absorbed L-u.p.-absorbed (at x) provided absorbed u.p.-absorbed (at x)
L, respectively.
Suppose C L-u.p.-absorbed. intuition current set initial
learned clauses CDCL search S, literals L set false (either
decision literals unit propagation). Then, unit propagation L yields
contradiction unit propagation L {C} does. learned clause
former may need include additional literals L however. state formally:
Lemma 29. Let set clauses, L set literals set false above, C
L-u.p.-absorbed . Suppose unit propagation L {C} yields contradiction
698

fiSeparations Regular Resolution

allows clause learned. unit propagation L also yields contradiction,
allows clause learned L.
proof Lemma 29 almost immediate denitions, left reader.
Note additional literals L appear precisely negations
literals L needed simulate invocation C unit propagation.
Theorem 30. Let define dag [n], let bipartite partial order
associated . greedy, unit propagating CDCL search finds
refutation GT,n clauses unit clauses xi,j j.
Proof. proof Lemma 25, let = [m] Jk Jk k k m.
Let L set literals xi,j j. Let greedy, unit propagating
CDCL search refuting GTm clauses size polynomial given Theorem 26.
wish prove transformed greedy, unit propagating CDCL search
refutes GT,n clauses clauses L. search mimic closely,
setting decision literals order S, learn clauses Toti,j place
clauses Toti,j . (Compare Figures 1 4.)
must use GT,n clauses initial clauses instead GTm clauses used S.
First consider GTm transitivity clause used S; type ( ) Denition 17
equal Ti,j,k distinct i, j, k < m. such, also GT,n clause type ()
thus already available use.

Second, consider totality clause Totm1,i = k[m]\{i} xk,i type ( ) used
unit propagation search S. clause may L-u.p.-absorbed GT,n
clauses. But, not, L-absorbed GT,n suce search
succeed. see L-absorbed, suppose point unit propagation
Totm1,i used obtain conict. case, one literal Totm1,i
set false, namely j0 [m] \ {i} set literals xj,i
j [m] \ {i, j0 } false infers xj0 ,i unit propagation. new search also
set literals xj,i j [m] \ {i, j0 } false needs infer xj0 ,i ; must use
GT,n clause Totn1,i instead GTm clause Totm1,i . Consider xk,i Totn1,i
k m. j [m] \ {i, j0 } j k (we let Jk denote j),
then, since xj,k L, unit propagation transitivity clause Ti,j,k sets xi,k true, i.e.,
falsies xk,i Totn1,i . holds k m, Totn1,i reduced unit
xj0 ,i , Totm1,i L-u.p.-absorbed xj0 ,i GT,n . Otherwise Totm1,i L-u.p..absorbed. case, let k1 , . . . , kR values j0 kr 1 r R,
just-described unit propagation able reduce Totn1,i (non-unit) clause
xj0 ,i xk1 ,i xkR ,i . search branches set xj0 ,i false decision literal.
Unit propagation transitivity clauses Ti,j0 ,kr , r R falsies literals xkr ,i
thereby falsies Totn1,i . backtracks learns clause Si Totm1,i (see (5)).
course clause Totm1,i . Totm1,i learned, since literals
Si L set false, obtain conict way S.
general, literals Toti,j \ Toti,j members L, set false .
thus straightforward check remaining steps simulated directly
using exactly decision literals, obtaining conict clauses
way, learning clauses Toti,j instead clauses Toti,j .
699

fiBonet, Buss, & Johannsen

describe greedy unit propagating CDCL without restart procedures
refute GGTn clauses.
Theorem 31. CDCL without restart search procedures greedy unit
propagating, refute GGTn clauses polynomial time.
Proof. basic idea greedy, unit propagating CDCL search follows
structure refutation described proofs Theorems 18 19; is, follows
stages construction LR-partial refutations.
stage corresponds unnished clause C LR-partial refutation,
set transitivity clauses Ti,j,k learned clauses, set zero
literals xi,j true. literals describe dag , namelyi j xi,j set
true. Let associated bipartite partial order, C = ( ). set every
xi,j true j. possible, use refutation Theorem 30
backtrack current stage; otherwise, branch learn another transitivity
clause. rst possibility holds provided every transitivity clause Ti,j,k , type ()
() needed refutation GT,n either learned C pool -u.p.-absorbed S.
Otherwise, suppose transitivity clause Ti,j,k type () neither learned
pool
-u.p.-absorbed. Following pattern argument case proof
C
Theorem 18, sets xi,j true decision literal. Since Ti,j,k type (), xi,j
already set. claim setting xi,j true yield contradiction unit
propagation. prove claim, note way unit propagation occur
(guarded unguarded) transitivity clause becomes unit clause. Referring back
Figure 3, (possibly guarded) transitivity clauses become unit upon
setting xi,j true clauses Ti,j, set xj, true. Therefore unit
propagation yielda contradiction xi,j . sets xk,i true. Since Ti,j,k
type () C = ( ), set xj,k true; therefore, unit propagation yields
contradiction Ti,j,k Ti,j,k . this, backtracks, setting xi,k true
learning Ti,j,k .
backtracking, stage corresponding clause C1 subrefutation S1
proof Theorem 18. Let L1 literals set false, 1 dag dened
literals L1 , let 1 associated bipartite order. needs infer literals
xi, 1 . done using transitivity clauses. L1 -u.p.-absorbed transitivity
clause used directly. transitivity clauses Ti,j, , xi,j xj, set true,
branches set x,i false decision literal, obtains immediate contradiction
unit propagation two GGTn clauses Ti,j, backtracks, learning Ti,j,
inferring xi, unit propagation. literals xi, 1 set true,
stage corresponding unnished clause.
backtracks stage corresponding clause C1 , enters stage
corresponding C2 . handled similarly.
argument case transitivity clause Ti,j,k type ()
learned similar. follow construction proof Theorem 18,
use stages correspond clauses C3 , C4 , C5 . Since construction quite
similar, omit description.
Theorem 31 shows close correspondence regRTI proofs GGTn
clauses greedy, unit propagating CDCL refutations without restarts. open, how700

fiSeparations Regular Resolution

ever, whether arbitrary regRTI regWRTI refutation converted polynomial
size greedy, unit propagating CDCL refutation without restarts. even open whether every (dag-like) regular refutation corresponds greedy, unit propagating CDCL refutation
without restarts.

Acknowledgements
grateful J. Homann assisting correction earlier version
proof Theorem 19. also thank A. Van Gelder, L. Kolodziejczyk, A. Beckmann,
T. Pitassi, three anonymous referees encouragement, suggestions, useful substantial comments.
M. L. Bonet supported part grant TIN2010-20967-C04-02, Research
Abroad Fellowship (Generalitat de Catalunya BE, 2012).
S. Buss supported part National Science Foundation grants DMS-0700533,
DMS-1101228 CCF-1213151, grant Simons Foundation (#208717
Sam Buss). also thanks John Templeton Foundation supporting participation
CRM Innity Project Centre de Recerca Matematica, Barcelona, Catalonia,
Spain results obtained.
S. Buss J. Johannsen thank Ban International Research Station workshop Proof Complexity (11w5103) held October 2011 part
results obtained.

References
Alekhnovich, M., Johannsen, J., Pitassi, T., & Urquhart, A. (2007). exponential separation regular general resolution. Theory Computing, 3 (5), 81102.
Alekhnovich, M., & Razborov, A. A. (2001). Resolution automatizable unless W [P ]
tractable. Proc. 42nd IEEE Conf. Foundations Computer Science (FOCS),
pp. 210219.
Atserias, A., Fichte, J. K., & Thurley, M. (2011). Clause-learning algorithms many
restarts bounded-width resolution. Journal Artificial Intelligence Research, 40,
353373.
Beame, P., Kautz, H. A., & Sabharwal, A. (2004). Towards understanding harnessing
potential clause learning. J. Artificial Intelligence Research, 22, 319351.
Beckmann, A., & Buss, S. R. (2005). Separation results size constant-depth
propositional proofs. Annals Pure Applied Logic, 136, 3055.
Ben-Sasson, E. (2009). Size space tradeos resolution. SIAM Journal Computing,
38 (6), 25112525.
Ben-Sasson, E., Impagliazzo, R., & Wigderson, A. (2004). Near optimal separation treelike general resolution. Combinatorica, 24 (4), 585603.
Bonet, M. L., & Buss, S. R. (2012a). improved separation regular resolution pool
resolution clause learning. Proc. 15th International Conference Theory
701

fiBonet, Buss, & Johannsen

Applications Satisfiability Testing SAT 2012, Lecture Notes Computer Science
#7317, pp. 4557.
Bonet, M. L., & Buss, S. R. (2012b). improved separation regular resolution pool
resolution clause learning. Full version, arxiv.org, arXiv:1202.2296v2 [cs.LO].
Bonet, M. L., & Galesi, N. (2001). Optimality size-width tradeos resolution. Computational Complexity, 10 (4), 461474.
Buss, S., & Kolodziejczyk, L. (2012). Small stone pool. Submitted publication.
Buss, S. R. (2009). Pool resolution NP-hard recognise. Archive Mathematical Logic,
48 (8), 793798.
Buss, S. R., Homann, J., & Johannsen, J. (2008). Resolution trees lemmas: Resolution
renements characterize DLL-algorithms clause learning. Logical Methods
Computer Science, 4, 4:13 (4:13), 118.
Chang, C. L. (1970). unit proof input proof theorem proving. J. ACM,
17 (4), 698707.
Goerdt, A. (1993). Regular resolution versus unrestricted resolution. SIAM Journal
Computing, 22 (4), 661683.
Hertel, P., Bacchus, F., Pitassi, T., & Van Gelder, A. (2008). Clause learning eectively
p-simulate general propositional resolution. Proc. 23rd AAAI Conf. Artificial
Intelligence (AAAI 2008), pp. 283290. AAAI Press.
Huang, W., & Yu, X. (1987). DNF without regular shortest consensus path. SIAM
Journal Computing, 16 (5), 836840.
Johannsen, J. (2009). exponential lower bound width-restricted clause learning.
Proc. 12th International Conference Theory Applications Satisfiability
Testing SAT 2009, Lecture Notes Computer Science #5584, pp. 128140.
Krishnamurthy, B. (1985). Short proofs tricky formulas. Acta Informatica, 22 (3), 253
275.
Marques-Silva, J. P., & Sakallah, K. A. (1999). GRASP new search algorithm
satisability. IEEE Transactions Computers, 48 (5), 506521.
Pipatsrisawat, K., & Darwiche, A. (2011). power clause-learning SAT solvers
resolution engines. Artificial Intelligence, 172 (2), 512525.
Segerlind, N., Buss, S. R., & Impagliazzo, R. (2004). switching lemma small restrictions
lower bounds k-DNF resolution. SIAM Journal Computing, 33 (5), 1171
1200.
Stalmarck, G. (1996). Short resolution proofs sequence tricky formulas. Acta
Informatica, 33 (3), 277280.
Urquhart, A. (2011). near-optimal separation regular general resolution. SIAM
Journal Computing, 40 (1), 107121.
Van Gelder, A. (2005). Pool resolution relation regular resolution DPLL
clause learning. Logic Programming, Artificial Intelligence, Reasoning
(LPAR 2005), Lecture Notes Computer Science 3835, pp. 580594. Springer-Verlag.
702

fiSeparations Regular Resolution

Van Gelder, A. (2006). Preliminary report input cover number metric propositional resolution proofs. Theory Applications Satisfiability Testing - SAT
2006, Lecture Notes Computer Science 4121, pp. 4853. Springer Verlag.

703

fiJournal Artificial Intelligence Research 49 (2014) 569-600

Submitted 04/2013; published 04/2014

Inapproximability Treewidth,
One-Shot Pebbling, Related Layout Problems
Yu (Ledell) Wu
Per Austrin
Toniann Pitassi
David Liu

wuyu@cs.toronto.edu
austrin@cs.toronto.edu
toni@cs.toronto.edu
liudavid@cs.toronto.edu

Department Computer Science
University Toronto, Ontario, Canada

Abstract
Graphical models, Bayesian Networks Markov networks play important
role artificial intelligence machine learning. Inference central problem
solved networks. This, problems graph models often
known hard solve general, tractable graphs bounded Treewidth.
Therefore, finding approximating Treewidth graph fundamental problem
related inference graphical models. paper, study approximability
number graph problems: Treewidth Pathwidth graphs, Minimum Fill-In, OneShot Black (and Black-White) pebbling costs directed acyclic graphs, variety
different graph layout problems Minimum Cut Linear Arrangement Interval
Graph Completion. show that, assuming recently introduced Small Set Expansion
Conjecture, problems NP-hard approximate within constant factor
polynomial time.

1. Introduction
Graphical models provide computational framework efficiently manipulating probability distributions high dimensional spaces, often involving hundreds thousands
variables. framework found applications enormous range domains including: medical fault diagnosis, image understanding, speech recognition, web search,
coding theory, statistical physics (Koller & Friedman, 2009). graphical model
efficient representation joint distribution set n random variables. Even
random variables binary, well known arbitrary joint distribution
requires specification 2n probabilities. Luckily, real world, often structure distribution allows one express succinctly. graphical model
represents joint probability distribution graph vertices represent
random variables, dependences modeled graph structure. Associated
vertex graph conditional probability table, specifies conditional probabilities random variable, conditioned neighboring vertices. two
common types graphical models Bayesian networks (also called belief networks),
underlying graph directed, Markov networks (also called Markov random
fields), underlying graph undirected. basic problem graphical
models inference problem, problem computing posterior marginal
c
2014
AI Access Foundation. rights reserved.

fiWu, Austrin, Pitassi, & Liu

distribution variable vertex. Unfortunately, inference general well-known
NP-hard compute exactly well approximate (Roth, 1996).
Despite intractability, important class bounded Treewidth instances probabilistic inference identified shown exactly computable polynomial
time. Treewidth graph (Robertson & Seymour, 1984, 1986) fundamental parameter graph measures close graph tree. Treewidth
closely related notions machine learning Branch-width, Clique-width
Elimination-width (for overview Treewidth related notions, see Bodlaender,
Gilbert, Hafsteinsson, & Kloks, 1995). graphs small Treewidth
tree decomposition known, dynamic programming algorithm yields polynomial-time
algorithm. Particular algorithms probabilistic inference bounded Treewidth graphs
junction-tree method, variable elimination clique trees (e.g. see Koller & Friedman, 2009, ch. 9, 10). algorithms runs time exponential Treewidth
tree decomposition polynomial size graph. Thus graphs tree
decomposition bounded Treewidth given, inference polynomial-time computable.
ideas also yield polynomial-time algorithms often even linear time algorithms small Treewidth instances astonishing variety NP-hard problems, including: satisfiability, counting satisfying assignments, constraint satisfaction, vertex cover, maximum independent set, Hamiltonian circuit, query optimization, matrix decomposition, generally problems definable monadic second-order logic. (See
excellent survey Bodlaender, 2005 motivation, including theoretical well practical applications Treewidth.) One catch problems, algorithm
must begin finding tree decomposition, use decomposition solve
problem. Given tree decomposition, algorithm typically exponential width
underlying tree decomposition. Thus need efficient algorithms actually compute Treewidth given graph, find tree decompositions optimal
close optimal width.
Unfortunately, many good heuristics finding good tree decomposition, NP-hard general determine Treewidth graph (Arnborg, Corneil,
& Proskurowski, 1987). However, Bodlaender et al. (1995) obtained O(log n) factor
approximation algorithm Treewidth. fact, actually show factor
c approximation algorithm vertex separator, O(c) approximation algorithm Treewidth. factor b approximation algorithm Treewidth
O(b log n) approximation algorithm related Pathwidth
problem.

best currently known approximation factor vertex separator O( log n) (Feige, Hajiaghayi, & Lee, 2005)p
thus best algorithm Treewidth finds
tree decomposition
within O( log n) factor optimal width, O(( log n)(log n)) factor
approximation algorithm Pathwidth.
longstanding open question whether constant factor approximation algorithm Treewidth. algorithm would lead faster algorithms
find good tree-decompositions problems mentioned above. current best
known algorithm achieves constant factor approximation Treewidth runs time
2O(w) O(n), w Treewidth underlying graph, achieves factor 5 approximation (Bodlaender, 2007) (Earlier approximation algorithms similar runtimes
Reed, 1992; Amir, 2001). book devoted Treewidth Kloks (1994, p. 62) states:
570

fiInapproximability Treewidth Related Problems

feel one biggest open problems research dealing
Treewidth Pathwidth moment. fast algorithms solving NPhard problems graphs bounded Treewidth ever become practical importance, undoubtedly importance find good tree-decompositions
graphs. Since (current best) approximations make many
algorithms practical, great interest know whether approximations
small constant exist.
Nearly twenty years later, still open problem whether polynomialtime algorithm approximate Treewidth within constant factor. Similarly, approximability many related graph layout problems also unresolved, including Minimum Cut
Linear Arrangement Interval Graph Completion. paper, make important
step resolve problem showing Treewidth, Pathwidth, host related
graph layout problems hard approximate within constant factor,
Small Set Expansion (SSE) conjecture (Raghavendra & Steurer, 2010).
SSE conjecture strengthened version conjecture P different
NP warrants explanation. next subsection (Section 1.1), explain
SSE conjecture, relates P versus NP question related conjectures.
state main hardness results Treewidth, pebbling problems graph layout
problems (Sections 1.2, 1.4, 1.5), discuss related results Section 1.6.
1.1 Small Set Expansion Conjecture
P versus NP problem important intriguing open problem field
computational complexity theory. Many decision problems theory practice
proven NP-hard, indicates impossible compute polynomial
time, widely believed conjecture P 6= NP. discovery PCP theorem
late 80s (Arora, Lund, Motwani, Sudan, & Szegedy, 1998; Arora & Safra, 1998) made
possible prove many optimization problems, approximating optimal value
within certain factor hard computing exact optimal value. words,
conjecture P 6= NP, possible approximate certain optimization
problems within factor depends problem. Celebrated results show
NP-hard approximate MAX-3SAT within ratio 78 + > 0 (Hastad,
2001), gives optimal lower bound, since simple algorithm achieves
approximation ratio 78 . Also, NP-hard approximate clique within n1
factor > 0 (Hastad, 1999). Despite success, many important problems,
hardness approximation results obtained PCP theorem matched
best approximation algorithms known. example, still significant gaps
understanding optimal approximability factor important problems as:
Vertex Cover, Max-Cut, Bipartite Clique, Kernel Clustering.
formulation Unique Games Conjecture (UGC) due Khot (2002) intended clarify approximability many optimization problems. conjecture postulates problem determining value certain type game, known
unique game, NP-hard. conjecture inspired remarkable body work since
formulation. UGC, many known algorithms approximation proven
tight (for excellent survey topic, see Khot & Vishnoi, 2005). instance,
571

fiWu, Austrin, Pitassi, & Liu

UGC, Vertex Cover problem NP-hard approximate within factor 2 ,
> 0 (Khot & Regev, 2008). Perhaps strikingly, Raghavendra (2008) proved
UGC, semi-definite programming (SDP) approximation algorithm
large class constraint satisfaction problems (CSP) essentially best one hope
for. specifically, showed every maximum constraint satisfaction problem (Max
CSP) associated sharp approximation threshold : every > 0, one achieve
approximation polynomial time using SDP, obtaining + approximation
NP-hard. Thus, UGC become central open problem inapproximability
encapsulates barrier designing better polynomial time approximation algorithms
large class problems.
Despite tremendous progress, still remain important yet stubborn problems
Treewidth, Balanced Separator, Minimum Linear Arrangement (MLA), many
graph layout problems whose approximation status remains unresolved even assuming
UGC. Intuitively hard instances problems seem require
certain global structure expansion. (Expansion graph property akin
high connectivity, requires every subset vertices large large
boundary.) Typical reductions problems gadget reductions preserve
global properties unique games instance, lack expansion. Therefore,
barring radically new types reductions preserve global properties, proving
hardness problems seems require stronger version UGC, instance
guaranteed certain expansion properties.
work Raghavendra Steurer (2010), Small Set Expansion (SSE) Conjecture introduced, shown implies UGC, SSE Conjecture
follows one assumes UGC true somewhat expanding graphs. follow-up
work Raghavendra et al. (2012), shown SSE Conjecture fact equivalent UGC somewhat expanding graphs, SSE Conjecture implies
NP-hardness approximation balanced separator MLA. light, Small
Set Expansion conjecture serves natural unified conjecture yields implications UGC also hardness expansion-like problems could resolved
UGC.
main contribution paper prove wide range graph layout
problems SSE-hard approximate within constant factor. problems,
evidence hardness approximation known prior results. Moreover,
show Treewidth, Pathwidth, Minimum Fill-In SSE-hard approximate within
constant factor. first result giving hardness (relative) approximation
problems, gives evidence constant factor approximation algorithm exists
them.
noted status SSE conjecture open point.
particular, recent results (Arora, Barak, & Steurer, 2010; Barak, Raghavendra, & Steurer,
2011; Guruswami & Sinop, 2011) give subexponential-time algorithms small set expansion. Still despite recent progress providing evidence SSE conjecture,
remains open. SSE-hardness results Treewidth related problems may therefore
viewed establishing new connection fundamental conjecture complexity
theory, approximability ubiquitous problem artificial intelligence.
572

fiInapproximability Treewidth Related Problems

1.2 Width Parameters Graphs
mentioned earlier, determining exact Treewidth graph producing associated optimal tree decomposition (see Definition 2.1) known NP-hard (Arnborg
et al., 1987), central open problem determine whether exists
polynomial time constant factor approximation algorithm Treewidth (see e.g., Bodlaender et al., 1995; Feige et al., 2005; Bodlaender, 2005). current best polynomial time
approximation algortihm
Treewidth (Feige et al., 2005), computes Treewidth tw(G)
p
within factor O( log tw(G)). hand, hardness result date
Treewidth shows NP-hard compute Treewidth within additive error n
> 0 (Bodlaender et al., 1995). hardness approximation known
even possibility polynomial-time approximation scheme Treewidth
ruled out. many important special classes graphs, planar graphs (Seymour &
Thomas, 1994), asteroidal triple-free graphs (Bouchitte & Todinca, 2003), H-minor-free
graphs (Feige et al., 2005), constant factor approximations known, general case
remained elusive.
positive side, large body literature developing fixed-parameter algorithms Treewidth. Exactly determining Treewidth fixed-parameter tractable:
linear time algorithm computing (exact) Treewidth graphs constant treewidth (Bodlaender, 1996). specifically exact algorithm runs time
2poly(k) poly(n). Constant factor approximation algorithms achieve better dependence
treewidth, k, n, best algorithm running time 2O(k) O(n) (Bodlaender, 2007).
related graph parameter so-called Pathwidth, viewed measuring
close G path. Pathwidth pw(G) always least tw(G), much
larger. current state affairs similar Treewidth;pthough current best
approximation algorithm approximation ratio O( log pw(G) log n) (Feige
et al., 2005), best hardness result NP-hardness additive n error approximation.
Using recently proposed Small Set Expansion (SSE) Conjecture (Raghavendra &
Steurer, 2010) discussed earlier, show tw(G) pw(G) hard approximate within constant factor. fact, show something stronger: hard
distinguish graphs small Pathwidth graphs large Treewidth. Specifically:
Theorem 1.1. every > 1 c > 0 given graph G = (V, E)
SSE-hard distinguish case pw(G) c |V | case
tw(G) c |V |.
particular, Treewidth Pathwidth SSE-hard approximate within
constant factor.
first result giving hardness (relative) approximation problems,
gives evidence constant factor approximation algorithm exists either
them.
1.3 Minimum Fill-In
closely related graph theoretic property Minimum Fill-In graph, minimum number edges required add graph triangulate (i.e., make chordal).
573

fiWu, Austrin, Pitassi, & Liu

property important applications sparse matrix computations (and particular Gaussian elimination) artificial intelligence (see excellent survey Heggernes,
2006).
Minimum Fill-in known fixed parameter tractable since 1994,
Kaplan et al. (1994) gave O(|E|16k ) algorithm, k number edges required.
there, several improvements running time given, recent
2012 Fomin Villanger (2012),
gave first subexponential parameterized

algorithm, running time O(2O( k log k) + k 2 |V | |E|). work Natanzon et al.
(1998), polynomial time approximation algorithm presented, computed value
8k 2 , k optimal solution. graphs degree bounded d,
algorithm achieves approximation ratio O(d2.5 log4 (kd)).
remains best polynomial time approximation algorithm known date.
particular, remained open question whether polynomial time constant factor
approximation algorithm exists. paper, show possible, assuming
SSE Conjecture.
Theorem 1.2. SSE-hard approximate Minimum Fill-In graph within
constant factor.
1.4 Pebbling Problems
Graph pebbling rich relatively mature topic theoretical computer science. Pebbling game defined directed acyclic graph (DAG), goal pebble
sink nodes DAG according certain rules, using minimum number pebbles.
rules pebbling follows. black pebble placed node
nodes immediate predecessors contain pebbles, always removed. white pebble
always placed node, removed nodes immediate
predecessors contain pebbles. pebbling strategy process pebbling sink nodes
graph according rules. pebbling cost pebbling strategy
maximum number pebbles used strategy. Black-White pebbling cost
DAG minimum pebbling cost possible pebbling strategies. black pebbling
cost minimum pebbling cost pebbling strategies use black pebbles.
Pebbling games originally devised studying programming languages compiler construction, later found broad range applications computational
complexity theory. Pebbling tool studying relationship computation
time space means game played directed acyclic graphs. employed
model register allocation, analyze relative power time space Turing
machine resources. comprehensive recent survey graph pebbling, see work
Nordstrom (2010).
Apart cost pebbling, another important measure pebbling time,
number steps (pebble placements/removals) performed. context measuring
memory used computations, corresponds computation time, hence keeping
pebbling time small natural priority. extreme case refer
One-Shot Pebbling, also known progressive pebbling, considered literature (e.g.,
Sethi, 1973; Lengauer, 1981; Kirousis & Papadimitriou, 1986). One-Shot Pebbling,
574

fiInapproximability Treewidth Related Problems

restriction node receive pebble once. Note restriction
cause huge increase pebbling cost graph (Lengauer & Tarjan, 1982).
One-Shot Pebbling problem easier analyze following reasons.
original pebbling problem, order achieve minimum pebbling number, pebbling
time might required exponentially long, becomes impractical n
large. hand, One-Shot Pebbling problem amenable complexity
theoretic analysis minimizes space used computation subject execution
time minimum. particular, decision problem One-Shot Pebbling NP
(whereas unrestricted pebbling problems PSPACE-complete).
One-Shot
Black Pebbling problem One-Shot Black-White Pebbling problems

admit O( log n log n) approximation ratio. show SSE-hard approximate within constant factor. black pebbling show holds single
sink DAGs in-degree 2, canonical setting pebbling games (it seems
plausible black-white hardness shown hold case well, though
attempted prove this).
Theorem 1.3. SSE-hard approximate One-Shot Black Pebbling problem within
constant factor, even DAGs single sink maximum in-degree 2.
Theorem 1.4. SSE-hard approximate One-Shot Black-White Pebbling problem
within constant factor.
hardness approximation result form known One-Shot Pebbling
problems. believe results extended obtain hardness
relaxed versions bounded time pebbling costs well. currently working this,
preliminary results.
1.5 Connection: Layout Problems
graph width One-Shot Pebbling problems discussed previous sections may
first glance appear unrelated. However, sets problems instances
general family problems, known graph layout problems. graph layout problem
(also known arrangement problem, vertex ordering problem), goal find
ordering vertices, optimizing condition edges, adjacent pairs
close. Layout problems important class problems applications
many areas VLSI circuit design.
classic example Minimum Cut Linear Arrangement problem (MCLA).
problem, objective find permutation vertices V undirected graph
G = (V, E), largest number edges crossing point,
max |{(u, v) E|(u) < (v)}|,


(1)

minimized. MCLA closely related Minimum Linear Arrangement problem
(MLA), max (1) replaced sum.

MCLA problem approximated within factor O(log n log n).
best knowledge, hardness approximation MCLA literature.
cousin MLA recently proved SSE-hard approximate within constant factor
575

fiWu, Austrin, Pitassi, & Liu

(Raghavendra et al., 2012), observe hardness applies MCLA
problem.
Theorem 1.5. SSE-hard approximate Minimum Cut Linear Arrangement problem within constant factor.
Another example graph layout Interval Graph Completion Problem (IGC).
problem, objective find supergraph G0 = (V, E 0 ) G vertex set
V , G0 interval graph (i.e., intersection graph set intervals
real line) minimum number edges. immediately appearing
layout problem, using simple structural characterization interval graphs (Ramalingam
& Rangan, 1988) one show IGC reformulated finding permutation
vertices minimizes sum longest edges going vertex, i.e.,
minimizing
X
max max{(v) (u), 0}.
(2)
uV

(u,v)E

See, example, work Charikar
et al. (2010). current best approximation
algorithm IGC achieves ratio O( log n log log n) (Charikar et al., 2010). turns
SSE Conjecture used prove super-constant hardness problem
well.
Theorem 1.6. SSE-hard approximate Interval Graph Completion problem within
constant factor.
distinction IGC whether one counts number edges final
interval graph common definition whether one counts
number edges added make G interval graph (which makes problem harder
approximability viewpoint). result holds common definition therefore
applies also harder version. Note Interval Graph Completion well connected
Pathwidth: pathwidth graph G one less smallest clique number
interval graph contains G subgraph.
Theorems 1.5 1.6 two examples layout problems prove hardness
approximation for. varying precise objective function also considering directed
acyclic graphs, case permutation must topological ordering
graph, one obtain wide variety graph layout problems. consider set eight
problems, generated three natural variations (see Section 2.3 precise details),
show super-constant SSE-based hardness unified way. set
problems includes MLA, MCLA, IGC, problems Bandwidth (but
hand, strong NP-hardness inapproximability results Bandwidth already
known Dubey, Feige, & Unger, 2011). See Table 1 Section 2.3 complete list
problems covered.
Theorem 1.7. Assuming SSE Conjecture, problems listed Table 1 (see page 581)
NP-hard approximate within constant factor.
Let us return problems discussed previous sections.
surprising One-Shot Black Pebbling problem equivalent graph layout
576

fiInapproximability Treewidth Related Problems

problem: one-shot constraint reduces problem determining order
pebble vertices; ordering induces pebbling strategy obvious way. (Given
graph layout ordering, vertices black pebbled order, black
pebble removed soon vertex longer needed. Conversely, black
pebbling sequence induces corresponding ordering vertices.) black-white
case, known One-Shot Black-White Pebbling cost interreducible
layout problem undirected graph G. layout problems included
set problems show hardness for, Theorems 1.3 1.4 follow immediately
Theorem 1.7.
Turning width parameters, Treewidth equivalent graph layout problem
called elimination width. objective function somewhat intricate
set basic layout problems consider Theorem 1.7, able extend
results hold also elimination width. Pathwidth also known equivalent
certain graph layout problem, fact equivalent layout problem
One-Shot Black-White Pebbling reduces to. use connections prove hardness
approximation Treewidth Pathwidth, thereby obtaining Theorem 1.1.
1.6 Previous Work
reader may noticed, problems mentioned, best current algorithms
achieve similar poly-logarithmic approximation ratios. Given close relation,
course surprising. algorithms obtained recursively applying
algorithm c-balanced separator problem, objective find bipartition
vertices graph sides contain least c fraction vertices,
number edges crossing partition minimized.
pioneering work separators Leighton Rao (1999), O(log n) approximation algorithm c-balanced separator given, used design O(log2 n)
approximation algorithm number graph layout problems MLA, MCLA,
Register Sufficiency. Later, Rao Richa (1998) improved approximation algorithm MLA ratio O(log n log log n), using spreading metric method.
groundbreaking work Arora et al. (2009),
semidefinite programming used give

improved approximation ratio O( log n) c-balanced separator. Using
ideas,
improved algorithms ordering problems found, O( log n log log n)
approximation algorithm IGC MLA (Charikar et al., 2010),
O( log n) approximation algorithm Treewidth (Feige et al., 2005) O( log n log n) approximation
algorithm Pathwidth (Feige et al., 2005).
known Register Sufficiency problem (also known One-Shot Black Pebbling) admits O(log2 n) approximation algorithm (Ravi, Agrawal, & Klein, 1991).
observe plugging improved approximation algorithm direct vertex separator (Agarwal, Charikar, Makarychev, &Makarychev, 2005) algorithm Ravi et
al. (1991), one improve O( log n log n) approximation algorithm.
Again, algorithms, approximation algorithm c-balanced separator plays
key role. improved algorithm c-balanced separator also improve approximation algorithms problems. hand, hardness approximating
577

fiWu, Austrin, Pitassi, & Liu

c-balanced separator (Raghavendra et al., 2012) necessarily imply hardness
approximating layout problems.
hardness side, work builds upon work Raghavendra et al. (2012),
showed SSE Conjecture implies superconstant hardness approximation
MLA (and c-balanced separator). hardness relative approximation
aware problems result work Ambuhl et al. (2007),
showing MLA PTAS unless NP randomized subexponential time
algorithms.
1.7 Organization
outline rest paper follows. Section 2, formally define
layout problems studied well Treewidth, Pathwidth, Minimum Fill-In.
giving overview reductions used Section 3 give full proof Theorem 1.7
Section 4. Then, Section 5 give lower bound Treewidth combined
results Section 4 gives Theorem 1.1. Section 6 give lower bound
Minimum Fill-In. Finally Section 7 give additional reductions pebbling
instances order achieve indegree 2 single sinks, promised Theorem 1.3.
end concluding remarks Section 8.

2. Definitions Preliminaries
undirected graph G = (V, E), subsets S, 0 V , E(S, 0 ) denotes set
edges go 0 . words, E(S, 0 ) set edges (u, v) E
u v 0 .
2.1 Treewidth, Elimination Width, Pathwidth
Definition 2.1 (Tree decomposition, Treewidth). Let G = (V, E) graph, tree,
let V = (Vt )tT family vertex sets Vt V indexed vertices .
pair (T, V) called tree decomposition G satisfies following three conditions:
(T1) V = tT Vt ;
(T2) every edge e E, exists endpoints e lie Vt ;
(T3) every vertex v V , {t | v Vt } subtree .
width (T, V) number max{|Vt |1 | }, Treewidth G, denoted
tw(G), minimum width tree decomposition G.
Definition 2.2. Let G = (V, E) graph, let v1 , . . . , vn ordering
vertices. Consider following process: vertex vi order, add edges turn
neighborhood vi clique, remove vi G. elimination ordering
G. width elimination ordering maximum vi degree vi
vi eliminated. elimination width G minimum width elimination
order.
578

fiInapproximability Treewidth Related Problems

Theorem 2.3 (See e.g., Bodlaender, 2007). every graph G, elimination width G
equals tw(G).
Thus Treewidth another example layout problem. principle layout problem
formulated framework Section 2.3, choice cost function
involved vertex- edge-counting considered there.
Definition 2.4 (Path decomposition, Pathwidth). Given graph G, say (T, V)
path decomposition G tree decomposition G path. Pathwidth
G, denoted pw(G), minimum width path decomposition G.
claimed earlier, Pathwidth fact equivalent graph layout problem. (See
next section formal definition layout.)
Theorem 2.5 (Kinnersley, 1992). every graph G, pw(G) = Layout(G; V, max).
2.2 Minimum Fill-In
Definition 2.6 (Chordal, Triangulation). graph G chordal every cycle
length least 4 chord. (possibly non-chordal) graph G, triangulation
G supergraph G chordal.
Definition 2.7 (Minimum Fill-In). Minimum Fill-In graph G minimum
number edges required add G triangulate it; i.e., resulting supergraph
chordal.
problem determining Minimum Fill-In graph sometimes called
Chordal Graph Completion problem.
perfect elimination ordering G elimination ordering edges
ever added G. Put another way, vertex vi , neighbours appearing
ordering form clique.
Theorem 2.8 (Fulkerson & Gross, 1965). graph G chordal
perfect elimination ordering.
Treewidth Minimum Fill-In related following theorem.
Theorem 2.9 (Folklore). Suppose G graph Treewidth k. every triangulation
G clique size k + 1.
2.3 Graph Layout Problems
subsection, describe set graph layout problems consider. problem
set described three parameters, giving rise several different problems.
three parameters means interesting graph layout problems (and
settings give rise less uninteresting layout problems). However,
sufficient capture problems interested except Treewidth, principle
could incorporated well though refrain order keep definitions
simple (see Section 2.1 details).
579

fiWu, Austrin, Pitassi, & Liu

First word notation. Throughout paper, G = (V, E) denotes undirected
graph, = (V, E) denotes directed (acyclic) graph. Letting n denote number
vertices graph, interested bijective mappings : V [n]. say
edge (u, v) E crosses point [n] (with respect permutation , always
clear context), (u) < (v).
consider following variations:
1. Undirected directed acyclic: case undirected graph G, ordering
vertices feasible solution. case DAG D, topological
orderings feasible solutions.
2. Counting edges vertices: point [n] ordering, interested
set Ei () edges crossing point. counting edges, use cardinality
Ei basic measure. counting vertices, count set vertices
Vi left incident upon edge crossing i. words, Vi
projection Ei () left-hand side vertices. Formally:
Ei () = {e E | (u) < (v) e = (u, v)}
Vi () = {u V | (u) < (v) (u, v) E}
refer |Ei ()| |Vi ()| (depending whether counting edges vertices)
cost i.
3. Aggregation sum max: given ordering , aggregate costs
point [n], either summation taking maximum cost.
Given choices, objective find feasible ordering minimizes
aggregated cost.
Definition 2.10. (Layout value) graph H (either undirected graph G DAG
D), cost function C (either E V ), aggregation function agg : R R (either
max), define Layout(H; C, agg) minimum aggregated cost feasible
orderings H. Formally:
Layout(H; C, agg) =

min

agg |Ci ()|.

feasible i[n]

Example 2.11.
Layout(G; E, max) = min max |Ei ()|,


i[n]

ranges orderings V (G). recognize Section 1.5
Minimum Cut Linear Arrangement value G.
Example 2.12.
Layout(D; V, max) = min max |Vi ()|,


i[n]

ranges topological orderings DAG D. shall see Section 2.4,
precisely One-Shot Black Pebbling cost D.
580

fiInapproximability Treewidth Related Problems

Problem
undir. edge
sum
undir. edge max
undir.

vertex

sum

undir.

vertex

max

DAG

edge

sum

DAG
DAG
DAG

edge
vertex
vertex

max
sum
max

Also known / Equivalent
Minimum/Optimal Linear Arrangement
Minimum Cut Linear Arrangement
CutWidth
Interval Graph Completion
SumCut
Pathwidth
One-Shot Black-White Pebbling
Minimum Storage-Time Sequencing
Directed MLA/OLA

One-Shot Black Pebbling
Register Sufficiency

Table 1: Taxonomy Layout Problems
Combining different choices gives rise total eight layout problems (some
natural others). Several appear literature one names,
turn equivalent1 problems first sight appear different.
summarize names Table 1. cases standard definitions
problems look somewhat different definition given (e.g., Pathwidth,
One-Shot Pebbling, Interval Graph Completion). Pebbling Pathwidth
problems, discuss equivalences definitions following two sections.
Interval Graph Completion, recall Section 1.5 objective minimize
X
max max{(v) (u), 0}.
uV

(u,v)E

words, counting longest edge going right point i.
length edge l edge contributes 1 Vi (), . . . , Vi+l1 () hence
objective rewritten
X
|Vi ()|,
uV

Interval Graph Completion precisely Layout(G; V, ).
2.4 Pebbling Problems
section define pebbling problems one-shot versions.
Definition 2.13. (Pebbling Configurations) Let = (V, E) directed acyclic graph
(DAG). pebbling configuration pair (B, W ) (disjoint) subsets vertices
(representing set B vertices black pebbles, set W vertices
white pebbles them).
1. Here, consider two optimization problems equivalent reductions change
objective values additive constant.

581

fiWu, Austrin, Pitassi, & Liu

Definition 2.14. (Black Black-White Pebbling Strategies) Let = (V, E) directed acyclic graph. Black-White Pebbling strategy sequence pebble configurations P = {P0 , . . . , P } that:
(i) first last configurations contain pebbles; P0 = P = (, ).
(ii) sink vertex u pebbled least once, i.e., Pt = (Bt , Wt )
u Bt Wt .
(iii) configuration follows previous configuration one following
rules:
(a) black pebble removed vertex.
(b) black pebble placed pebble-free vertex v immediate
predecessors v pebbled.
(c) white pebble placed pebble-free vertex.
(d) white pebble removed vertex v immediate predecessors v pebbled.
Black Pebbling Strategy G Black-White Pebbling strategy white
pebbles used.
cost pebbling strategy cost(P) = max0t {|Bt Wt |}. Black-White
Pebbling cost minimum cost Black-White Pebbling strategy D,
similarly Black Pebbling cost minimum cost Black Pebbling Strategy
D.
Definition 2.15. (One-Shot Black One-Shot Black-White Pebbling) One-Shot Black
(resp. Black-White) pebbling strategy Black (resp. Black-White) Pebbling strategy
node pebbled once. One-Shot Black (resp. Black-White) pebbling
cost D, denoted BP1s (D) (resp. BWP1s (D)) minimum cost One-Shot Black
(resp. Black-White) Pebbling strategy D.
mentioned Table 1, One-Shot Pebbling problems formulated Layout
problems.
Lemma 2.16. every DAG = (V, E), BP1s (D) = Layout(D, V, max).
Proof. Suppose optimal ordering Layout(D, V, max), pebble vertices according . remove pebble vertex u successors
u pebbled. Since topological order D, valid pebbling strategy.
easy verify pebbling (i), number pebbles graph |Vi ()|.
Therefore number pebbles used strategy Layout(D, V, max).
hand, suppose optimal pebbling strategy, let ordering vertices
receive pebble . consider number pebbles graph pebbling
i-th vertex . vertex u pebble, vertex successor
yet pebbled, pebble u cannot removed, since u cannot
pebbled again. Therefore number pebbles graph least |Vi ()|. Thus
BP1s (D) maxi[n] |Vi ()| Layout(D, V, max).
582

fiInapproximability Treewidth Related Problems

One-Shot Black-White Pebbling, following reductions Lengauer
(1981), showing One-Shot Black-White Pebbling equivalent undirected MaxVertex Layout Problem.
Lemma 2.17 (Lengauer, 1981). given DAG = (V, E), let GD = (V, ED )
undirected graph ED = {(v, w) | (v, w) E} {(v, w) | u, (v, u), (w, u) E}.
BWP1s (D) = Layout(GD , V, max) 1.
Lemma 2.18 (Lengauer, 1981). undirected graph G = (V, E), let DG = (V E, EG )
DAG EG = {(v, e) | e E, v V, v e}.
Layout(G, V, max) = BWP1s (DG ) + 2.
2.5 Small Set Expansion Conjecture
section define SSE Conjecture. Let G = (V, E) undirected d-regular
graph. set V vertices, write G (S) (normalized) edge expansion
S,
|E(S, V \ S)|
G (S) =
d|S|
Small Set Expansion Problem parameters , denoted SSE(, ), asks G
small set expand whether small sets highly expanding.
Definition 2.19 (SSE(, )). Given d-regular graph G = (V, E) 2 , SSE(, ) problem
distinguishing following two cases:
Yes V |S| = |V | G (S) .
every V |S| = |V | holds G (S) 1 .
problem introduced Raghavendra Steurer (Raghavendra & Steurer,
2010), conjectured problem hard.
Conjecture 2.20 (Small Set Expansion Conjecture). every > 0, > 0
SSE(, ) NP-hard.
become common conjecture like (such Unique Games Conjecture),
say problem SSE-hard hard solve SSE problem. Formally,
decision problem P (e.g., gap version optimization problem) SSE-hard
> 0 every > 0, SSE(, ) polynomially reduces P.
Subsequently, Raghavendra et al. (2012) showed SSE Problem turn
reduced quantitatively stronger form itself. state stronger version, need
first define Gaussian noise stability.
Definition 2.21. Let [1, 1]. define : [0, 1] [0, 1]


() = Pr X 1 () 1 ()
1 inverse function normal distribution, X jointly normal
1
random variables mean 0 covariance matrix
.
1
2. constant

583

fiWu, Austrin, Pitassi, & Liu

property shall need following well-known fact asymptotic
behaviour close 1 bounded away 0.
Fact 2.22. (Raghavendra et al., 2012) constant c > 0 sufficiently
small [1/10, 1/2],

1 () (1 c ).
state strong form SSE Conjecture.
Conjecture 2.23 (SSE Conjecture, Equivalent Formulation). every integer q > 0
, > 0, NP-hard distinguish following two cases given d-regular
graph G = (V, E)
Yes partition V q equi-sized sets S1 , . . . , Sq G (Si ) 2
every 1 q.
every V , letting = |S|/|V |, holds G (S) 1 (1/2 () + )/.
future reference, let us make two remarks strong form conjecture.
Remark 2.24. Yes case Conjecture 2.23, number edges leaving Si

|E(Si , V \ Si )|3 = G (Si )d|S| 4|E|/q.
particular, total number edges contained one Si
1X
|E(Si , V \ Si )| 2|E|.
2


Remark 2.25. Using Fact 2.22 see that, case Conjecture 2.23,

G (S) c0 ,

constant c0 > 0, provided [1/10, 1/2] setting . particular,

every |V |/10 |S| 9|V |/10, |E(S, V \ S)| c |E| (switching roles
V \ |S| > |V |/2), constant c > 0 (not constant Fact 2.22).

3. Brief Overview Reductions
section, give brief overview reductions used prove layout
problems Table 1 SSE-hard approximate within constant factor. full
details reductions found Section 4.
two undirected edge problems (i.e., MLA MCLA), hardness follows
immediately strong form SSE Conjecture (Conjecture 2.23) case
MLA proved work Raghavendra et al. (2012) proof MCLA
similar. starting point remaining problems. Unfortunately, results
3. E(S1 , S2 ) indicates number edges vertex set S1 S2

584

fiInapproximability Treewidth Related Problems

SSE
Problem

Undirected Edge
Problems (MLA/MCLA)
expansion

Directed Problems

Nice Pebbling
Instances

Undirected Vertex
Problems

Treewidth

Figure 1: Overview Reductions. Dashed arrows indicate reduction obtained
identity mapping, whereas solid arrows indicate nontrivial transformation
one problem other.

follow hardness MLA/MCLA black-box way; soundness analyses
end use expansion properties original SSE instance.
give reduction MLA/MCLA four directed problems. reduction simply creates bipartite graph vertex set union edges
vertices original graph G, directed arcs edge e vertices incident
upon e G. use direction crucial: essentially ensures vertex
edge counts feasible ordering corresponds closely number edges
crossing point induced ordering G.
obtain hardness remaining two undirected problems, perform similar
reduction directed case, creating bipartite graph edge-vertex incidences.
However, since creating undirected graph, longer force edges
chosen vertices upon incident, key property
reduction directed case. order overcome this, duplicate original vertex
large number times. gives huge penalties orderings essentially
obey desired direction edges, makes reduction work out.
results Treewidth, presented Section 5, follows additional
analysis instances produced reduction undirected vertex problems.
Finally, reduction directed problems, implying hardness One-Shot Black
Pebbling, produce kind nice instances promised Theorem 1.3.
Section 7, give additional transformation achieve properties.
Figure 1 gives high-level overview reductions.

4. Hardness Layout Problems
section, show layout problems defined Section 2.3 SSEhard approximate within constant factor. also shows Pathwidth
One-Shot Pebbling problems hard approximate within constant.
4.1 Hardness MCLA MLA
section, recall proof work Raghavendra et al. (2012) MLA,
observe applies MCLA well. undirected graph G, let us write MCLA(G)
585

fiWu, Austrin, Pitassi, & Liu

(resp., MLA(G)) MCLA value (resp., MLA value) G, i.e.,
MLA(G) = Layout(G; E, ) = min


X

|Ei ()|

i[n]

MCLA(G) = Layout(G; E, max) = min max |Ei ()|.


i[n]

Theorem 4.1. every > 0, given graph G = (V, E), SSE-hard distinguish
between:
Yes MLA(G) O( |V | |E|) MCLA(G) O(|E|)

every V |V |/10 |S| 9|V |/10, holds |E(S, V \ S)| ( |E|).


particular, MLA(G) ( |V | |E|) MCLA(G) ( |E|).
Proof. use instances Conjecture 2.23 q = 1/. Let G = (V, E)
instance Conjecture 2.23.
Yes case, disjoint sets S1 , . . . , Sq set Sj , |Sj | = n/q = n,
G (Sj ) 2. give ordering : V [1, .., n] vertices maxi[n] |Ei ()|
3|E| follows. Order vertices S1 , . . . , Sq (with order within Sj chosen arbitrary) let order . [n], show |Ei ()| 3|E|. Suppose
1 (i) vertex Sj . edge Ei () either end-points inside Sj , endpoints two different Sk s. total number edges inside Sj dn/2 = |E|.
Moreover, Remark 2.24, total number edges end-points two different Sk
2|E|. Therefore, MCLA(G) maxi |Ei ()| 3|E|. MLA value
bounded similarly.
property instance Conjecture 2.23 (via Remark 2.25),
implications MLA MCLA values immediate.
4.2 Reduction Directed Graphs
Given undirected graph G = (V, E), construct directed graph = (V 0 , E 0 )
follows. order distinguish elements V E elements V 0 E 0 ,
refer elements V vertices, elements E edges, elements V 0 nodes,
elements E 0 arcs.
node vertex edge G, i.e., V 0 = V E.
graph bipartite bipartition V, E, arc e E v V
e incident upon v. Formally,
V0 = V E
E 0 = {(e, v) | e E, v V, v e}.
See also Figure 2.
remainder section devoted analyzing reduction. First, easy
give upper bound four Layout values terms MLA MCLA values
G.
586

fiInapproximability Treewidth Related Problems

u

v

v

u

w

(u, v)

G

w

(u, w)


Figure 2: reduction G D.

Lemma 4.2. DAG constructed G satisfies following:
Layout(D; E, ) (MLA(G) + O(|E|)) (d + 1)
Layout(D; E, max) MCLA(G) + d.
Note that, purposes applying graphs Theorem 4.1 error term
|E| (resp. d) insignifcant compared MLA (resp. MCLA) value G.
Proof. Consider ordering V . set vertices V , let u (S) denote
vertex comes first ordering .
extend ordering 0 V 0 inserting edge e = (u, v) immediately
vertex u (e). easy see node z V 0 ,
|Ez ( 0 )| |Eu (z) ()| +
Ev () vertex v abbreviation E(v) (). immediately implies
Layout(D; E, max) max0 |Ez ( 0 )| max |Eu ()| + d,
uV

zV

Setting optimal MCLA ordering G, obtain second claim Lemma.
Similarly, using |u1
(v)| + 1 every v V , get
X X
X
X
Layout(D; E, )
|Ez ( 0 )| =
|Ez ( 0 )| (d + 1)
|Ev ()| + d|V 0 |,
zV 0

vV

zV 0
u (z)=v

vV

Setting optimal MLA ordering G using |V 0 | = O(|E|), obtain first
claim Lemma.
Next use Theorem 4.1 argue converse direction.
Lemma 4.3. Let 0 < 1. Suppose G property every |V |/10 |S|

9|V |/10 |E(S, V \ S)| ( |E|). Then,

Layout(D; V, ) ( |E|2 )

Layout(D; V, max) ( |E|)
587

fiWu, Austrin, Pitassi, & Liu

Proof. Let 0 ordering V 0 . Using expansion property Theorem 4.1, well
show ordering must high cost. point [N ], let Si set vertices
V appear 0 .
bound Layout(D; V, max) immediate: consider point [N ]

|Si | = |V |/2. expansion property |E(Si , V \ Si )| ( |E|), since
edge e one endpoints point i, node e must appear

point thus |Vi ( 0 )| |E(Si , V \ Si )| ( |E|).
Let us turn Layout(D; V, ). Write ci fraction edges e appear
(or at) point 0 . shall show whenever 1/5 ci 4/5, |Vi ( 0 )|


( |E|), giving total Layout(D; V, ) ( |E|2 ).
simple counting argument,
d|Si | 2(1 ci )|E|,
implying |Si | (1 ci )|V | ci 4/5 least 1/5 fraction vertices.

addition |Si | 9|V |/10, argument gives |Vi ( 0 )| ( |E|). remaining case
|Si | 9|V |/10. Si incident upon least 9/10 fraction edges.
implies number edges incident upon Si , appearing 0 , least

|E|(ci 1/10) ci 1/5 ( |E|).
Combining Lemma 4.2 Lemma 4.3, Theorem 4.1, using fact edge
costs always larger corresponding vertex costs, immediately obtain
following theorem.
Theorem 4.4. Given DAG D, Layout(D; E, max), Layout(D; E, ), Layout(D; V, max),
Layout(D; V, ) SSE-hard approximate within constant factor, even
DAGs maximum path length 1 (i.e., every vertex source sink).
Proof. Given graph G, Theorem 4.1 says SSE-hard distinguish
Yes MLA(G) O( |V | |E|) MCLA(G) O(|E|)

every V |V |/10 |S| 9|V |/10, holds |E(S, V \ S)| ( |E|).


particular, MLA(G) ( |V | |E|) MCLA(G) ( |E|).
Applying reduction directed graphs, Lemma 4.2 tells us Yes case becomes
Layout(D; E, ) (d + 1)O(|V ||E| + |E|) = O(|E|2 )
Layout(D; E, max) O(|E|),
Lemma 4.3 tells us case becomes

Layout(D; V, ) ( |E|2 )

Layout(D; V, max) ( |E|).

thereby establishing hardness factor (1/ ) four problems (using
Layout(D; V, ) Layout(D; E, )).
588

fiInapproximability Treewidth Related Problems

u1 , . . . , ur

u

(u, v)

v

(u, w)

(w, v)

w
v1 , . . . , vr

w1 , . . . , wr

G0

G

Figure 3: reduction G G0 , illustrated r = 3.

Remark 4.5. fact see that, Theorem 4.1, four hardness results apply
instance, SSE-hard distinguish four Layout values high
low.
One-Shot Black Pebbling problem precisely Layout(D; V, max), obtain hardness One-Shot Black Pebbling immediate corollary. However, instances
single-sink DAGs maximum indegree 2, promised Theorem 1.3. Section 7
show transform instances obtain DAGs.
4.3 Undirected Vertex Problems
reduction undirected vertex problems similar reduction directed
problems given previous section. before, introduce nodes every edge
G. directed case, interested orderings edge appears
two endpoints, cannot use direction force anymore. Instead, ensure
orderings like incur high cost replicating node corresponding
vertex G many times.
Given undirected graph G = (V, E), construct new graph G0 = (V 0 , E 0 )
follows.
r nodes G0 vertex one node edge G, i.e., V 0 =
V [r] E. vertex u V write u1 , . . . , ur denote r copies u refer
set r nodes vertex group. graph G0 bipartite bipartition
V [r], E, edge G0 e E v V [r] e incident upon
v. Formally,
V 0 = {v | v V, [r]} {e | e E}
E 0 = {(e, v ) | e E, v V, v e, [r]}.
See also Figure 3.

589

fiWu, Austrin, Pitassi, & Liu

Lemma 4.6. graph G0 constructed G satisfies following:
Layout(G0 ; V, ) (d + r) MLA(G)
Layout(G0 ; V, max) MCLA(G).
Proof. proceed proof Lemma 4.2. ordering V naturally induces
ordering 0 V 0 : put r copies u V consecutively, vertices V appearing
order , insert edge e E immediately first vertex. Again,
edge e E, let u (e) denote endpoint e appears first . Similarly,
copy v V 0 v V , let u (v ) = v. easy see constructed ordering 0
satisfies
|Vz ( 0 )| |Eu (z) ()|
every z V 0 . immediately implies
Layout(G0 ; V, max) max0 |Vz ( 0 )| max |Eu ()|,
zV

uV

Similarly, Lemma 4.2 use |u1
()| + r get
X
X
Layout(G0 ; V, )
|Vz ( 0 )| (d + r)
|Ev ()|.
zV 0

vV

Lemma 4.7. Let 0 < 1. Suppose G property every |V |/10 |S|

9|V |/10 |E(S, V \ S)| ( |E|). Then, r |V | |E|,

Layout(G0 ; V, ) ( r |V | |E|)

Layout(G0 ; V, max) ( |E|)
Proof. Let 0 ordering V 0 . First following simple claim, establishing
good orderings, vertices appear edges.
Claim 4.8. Suppose vertex u V , least r/2 copies u G0 appear
edge e = (u, v) E adjacent upon u.

max |Vi ( 0 )| r/4 ( |E|)
i[N ]
X

|Vi ( 0 )| (r/4)2 ( r |V | |E|).
i[N ]

Proof. Let I1 first half positions copies u appear e, I2
second half. Thus, |I1 |, |I2 | r/4. element I1 contributes Vi ( 0 )
I2 , giving claimed bounds.
Thus may without loss generality assume vertex u V , least r/2
r copies G0 appear edges adjacent upon u. on, let us discard
r/2 bad copies vertex V appear edges.
decreases cost 0 , still r|V |/2 vertex nodes left.
Let i1 (first) point 0 r|V |/10 vertex nodes left i1 ,
i2 (last) point 0 r|V |/10 vertex nodes right i2 .
590

fiInapproximability Treewidth Related Problems


Claim 4.9. point i1 i2 , |Vi ( 0 )| ( |E|).
Proof. Let V (resp. V ) set vertices u copy u appears
|/10
(resp. i). |S|, |T | r|Vr/2
|V |/5, = V . Thus
partition V 0 S, 0 |S 0 |, |T 0 | 4|V |/5. expansion

property G |E(S 0 , 0 )| ( |E|). Further, also |Vi ( 0 )| |E(S 0 , 0 )|
e E(S 0 , 0 ) must appear 0 (because one endpoints S)
edge crossing (because endpoints ).
Claim 4.9, proof lemma follows immediately.
previous section, combine Lemma 4.6 Lemma 4.7,
Theorem 4.1, obtain:
Theorem 4.10. Given graph G, Layout(G; V, max), Layout(G; V, ) SSE-hard
approximate within constant factor, even bipartite graphs.
Pathwidth problem precisely Layout(G; V, max), obtain hardness Pathwidth immediate corollary. next section, well show stronger soundness
required Theorem 1.1.

5. Hardness Treewidth
section shall complete proof Theorem 1.1 showing hard instances
Pathwidth Theorem 4.10 also large Treewidth.
Lemma 5.1. Let 0 < 1. Let G = (V, E) undirected graph property

every |V |/10 |S| 9|V |/10 |E(S, V \ S)| ( |E|), let G0 graph
obtained applying reduction Section 4.3 G. Then, r |V | |E|,

tw(G0 ) ( |E|)
prove Lemma 5.1, shall use fact Treewidth graph closely
related expansion-like property called 1/2-separator number, defined work
Bodlaender et al. (1995).
Definition 5.2 (1/2-vertex separator, 1/2-separator number). Let G = (V, E) undirected graph. W V , 1/2-vertex separator W G set V vertices
every connected component graph G[V S] contains |W |/2 vertices
W . Let G (1/2, W ) denote minimum size 1/2-vertex separator W G.
define 1/2-separator number K1/2 (G)
K1/2 (G) = max G (1/2, W ).
W V

Lemma 5.3 (Bodlaender et al., 1995). every graph G = (V, E), holds tw(G)
K1/2 (G) 1.
Using this, straightforward prove lower bound Treewidth.
591

fiWu, Austrin, Pitassi, & Liu


Proof Lemma 5.1. Well show G0 (1/2, V 0 ) ( |E|) (i.e. choose W = V 0 ).
Suppose C optimal 1/2-vertex separator V 0 separates V 0 \ C l sets
V10 , . . . , Vl0 , size |V 0 |/2. merge two sets V10 , . . . , Vl0 combining
vertex set them. merging different Vi0 may assume two sets
V10 V20 , size least |V 0 |/5 (this achieved always merging two sets
smallest number vertices, whever two sets left).
Now, similarly proof Claim 4.9, let V (resp. V ) set vertices
v copy V appears V10 (resp. V20 ). |V10 |, |V20 | r|V |/5, implies
|S|, |T | least |V |/5, furthermore = V (since otherwise r copies

vertex C, implying |C| r ( |E|)). thus choose balanced

partition 0 , 0 0 S, 0 , |E(S 0 , 0 )| ( |E|). every
edge e = (u, v) u 0 v 0 must belong C, since connected (in G0 )
every copy u v.

6. Hardness Minimum Fill-In
section, use previous construction results Treewidth prove inapproximability Minimum Fill-In. Specifically, show applying construction
SSE instances produces graphs high Minimum Fill-In, Yes instances
yields graphs low Minimum Fill-In.
Lemma 6.1. Let 0 < 1. Let G = (V, E) undirected graph property

every |V |/10 |S| 9|V |/10 |E(S, V \ S)| ( |E|), let G0
graph obtained applying reduction Section 4.3 G. Then, r |V | |E|, least
(|E|2 ) edges must added triangulate G0 .
Proof. use observation G0 bipartite. Consider minimum triangulation
G, must clique size tw(G0 ) + 1. Lemma 5.1, one set bipartition

G must ( |E|) vertices clique, since vertices independent
G0 , (|E|2 ) edges must added.
Note lemma holds independently choice q. prove good
upper bound Yes instances.
Lemma 6.2. Let > 0 q = 1/2 . Let G = (V, E) d-regular graph, suppose
partition V q equi-sized sets S1 , . . . , Sq G (Si ) 2 every
1 q.
Let G0 = (V 0 , E 0 ) graph obtained applying reduction Section 4.3 G.
G0 triangulation |E 0 | + O(2 |E|2 ) edges.
Suppose G = (V, E) Yes instance Conjecture 2.23 parameters q, ,
q = 1/2 , apply previous construction r |V | |E| get graph G0 = (V 0 , E 0 ).
G0 triangulation |E 0 | + O(2 |E|2 ) edges.
Proof. Note suffices find good ordering vertices G0 close
perfect elimination ordering, i.e., requires additional edges turn
perfect elimination ordering. i, define set
Ei = {(u, v) E | u, v Si }.
592

fiInapproximability Treewidth Related Problems

Also define set cut edges Ec = {(u, v) E | u Si , v Sj , 6= j}. Clearly, Ei
together Ec form partition E. define subsets Ec Eci = E(Si , V \Si ),
set cut edges Si . definition Si , G (Si ) 2, hence |Eci |
4|E|/q = 43 |E|. Well identify Ei Ec subsets constructed graph.
let ordering V 0 r|V | vertex copies appear first (in
order), followed sets E1 , . . . , Eq , Ec order, within set vertex
order arbitrary. consider following supergraph H G0 obtained by:
making set Ei Eci clique
making Ec clique/
Claim 1: adds O(2 |E|2 ) edges.
|

Note |Ei Eci | d|Si | = d|V
= 2 |E|
q
2 . Thus making Ei Ec clique requires
1
4
2
O( |E| ) edges. Since q = 2 cliques total, requires O(2 |E|2 )
edges total. Finally, Remark 2.24, |Ec | 2|E|, making clique takes O(2 |E|2 )
edges well.
Claim 2: Adding edges makes perfect elimination ordering H.
Consider vertex copy v k X. neighbours H edges incident
v; v Si , edges must Ei Eci . every vertex X satisfies
perfect elimination property. consider (u, v) Ei . edge neighbours
Ei Eci . Finally, every edge vertex (u, v) Ec , neighbours appear
respect also Ec .
Putting two claims together yields desired result.

Combining two lemmas prove Theorem 1.2.

7. Nicer Pebbling Instances
section show transform hard instances One-Shot Black Pebbling
in-degree bounded 2 single sinks.
Lemma 7.1. Given DAG = (V, E) polynomial time construct DAG
D0 = (V 0 , E 0 ) D0 single sink
BP1s (D) BP1s (D0 ) BP1s (D) + + 1,
number sinks D. Furthermore, maximum in-degree D0
larger maximum in-degree D, provided quantity least 2.
Proof. Construct D0 adding binary tree leaves D, identifying leaves
tree sinks D. is, D0 consists binary tree leaves top
copy leaves binary tree identified sinks D.
number vertices D0 equal |D| + |s| 1. Note binary tree leaves
suffice. properties D0 easily verified. Since D0 super-DAG D,
pebbling cost must least BP1s (D). Conversely, valid pebbling D0 obtained
using One-Shot Pebbling without removing pebbles sinks,
pebbling tree.
593

fiWu, Austrin, Pitassi, & Liu

Figure 4: Pyramid size 4
in-degree, prove following.
Lemma 7.2. Given DAG = (V, E) polynomial time construct DAG
D0 = (V 0 , E 0 ) every node D0 in-degree 2
BP1s (D) BP1s (D0 ) BP1s (D) + d,
maximum in-degree D. Furthermore, single sink
D0 .
proving Lemma 7.2, let us see use two Lemmas derive Theorem 1.3.
Proof Theorem 1.3. (the proof of) Theorem 4.4, reduction takes
instance (G = (V, E) Conjecture 2.23 produces dag BP1s (D) =

Layout(D; V, max) = O(|E|) G Yes instance, BP1s (D) = ( |E|) G
instance. number sinks |V | = 2|E|/d, much smaller O(|E|)
provided 1/ (which may assumed without loss generality). maximum indegree maximum degree G = O(1). Applying reduction
Lemma 7.1 reduction Lemma 7.2 obtain dag D0 single sink
in-degree 2 BP1s (D) BP1s (D0 ) BP1s (D) + + 2|E|/d. Since + 2|E|/d
O(|E|) BP1s (D), conclude SSE-hard distinguish BP1s (D0 )

O(|E|) BP1s (D0 ) ( |E|).
7.1 Lemma 7.2
section prove Lemma 7.2. First, recall definition pyramid graph.
Definition 7.3. pyramid graph size layered graph indegree two, layers,
labelled 0, 1, . . . , d1. Layer zero (the input layer) consists vertices, layer contains
vertices. Call vertices layer vi1 , . . . vidi . i, 1 1, 1 j i,
j
j+1
Vertex vij incoming edges vertices vi1
vi1
. See Figure 4.
reduction Lemma 7.2 produce DAGs indegree 2 follows. Construct D0
replacing vertex u pyramid Pu size d(u) (here, d(u) denotes indegree
u), d(u) vertices layer 0 Pu identified predecessors u, u
identified vertex layer d(u) 1 Pu . See Figure 5.
594

fiInapproximability Treewidth Related Problems

u1

v1

v2

v3

u2

v4

v5

u1

v6

v7

v1

v2

u2

v3

v4

v5

v6

v7

Figure 5: Reduction DAGs indegree 2
prove lemma need show D0 constructed way satisfies
BP1s (D) BP1s (D0 ) BP1s (D) + d,
maximum indegree vertex u D.
follows whenever say pebbling strategy D0 always refer
One-Shot Black Pebbling strategy D0 .
upper bound BP1s (D0 ) trivial: valid pebbling strategy D,
clearly create corresponding pebbling strategy D0 pebbling
pyramid whenever pebbles sink pyramid. takes additional
pebbles.
direction, want show pebbling strategy D0 converted
pebbling strategy D. first show D0 assumed particular
normal form, using normal form, show simulate pebbling.
Definition 7.4. Let 0 pebbling strategy D0 . is, 0 sequence configurations, configuration set black pebble placements,
sequence configurations follows black pebbling rules. say configuration
c 0 saturated respect pyramid Pu c first time 0
black pebble path cutting sink Pu sources Pu . (The cut
include sources sink Pu .) Note cut size 1.
Claim 7.5. Let 0 pebbling strategy D0 . assume without loss generality
0 following normal form. configuration c0 0 , c0 saturated
respect pyramid Pu , subsequent moves 0 pebble sink Pu (in obvious
way), removing black pebbles internal nodes Pu .
Proof Sketch. show pebbling strategy converted normal form
strategy pebbling cost. saturated configuration c0 , must 1
pebbles internal nodes Pu . subsequently pebble sink p, never use
1 pebbles internal nodes p, pebbles graph stay
were. Thus normal form use pebbles original strategy.
Furthermore, since internal nodes pyramid used pebble sink
pyramid, lost anything pebbling sink removing
internal black pebbles.
595

fiWu, Austrin, Pitassi, & Liu

assume pebbling 0 D0 normal form. is,
configuration saturated (with respect pyramid Pu ), next thing happens
0 pebble sink Pu . (After pebbling sink, touched whatever
pebbles source nodes Pu , pebble sink node Pu ,
internal pebbles Pu .)
strategy constructing pebbling, S, D, given normal form pebbling, 0
0
follows. node v D, pebble v whenever first pebbled 0 ,
remove pebble v soon successors v (in original graph D) pebbled.
want argue cost pebbling strategy greater 0 .
see this, use following Lemma.
Lemma 7.6. minimal-length One-Shot Black Pebbling size pyramid,
number pebbles pyramid point time, sources pebbled,
must least number sources pyramid pebbled far.
Assuming Lemma clear 0 normal form pebbling D0 ,
pyramid Pu D0 , configuration c0 , k pebbles Pu c0 ,
corresponding configuration c D, k pebbles source nodes
Pu . see this, first notice Lemma, time pyramid pebbled
D0 time source nodes pyramid pebbled first time,
number pebbles pyramid least large number source
nodes contain pebbles. normal form property D0 , soon
source nodes D0 pebbled first time, strategy pebbles sink D0 ,
thus number corresponding pebbles never greater number
pebbles D0 .
Proof Lemma 7.6. Let P size pyramid graph, let One-Shot Black
Pebbling P . Let c configuration occurring set source nodes
pebbled c source nodes P 0 , P 0 size d0 subpyramid P . want argue c must contain least d0 pebbles. Assume without
loss generality P 0 leftmost sub-pyramid P , size d0 < (with source
0
vertices v01 , . . . , v0d .) Consider outer rightmost vertices P 0 vertices labels
0
0
vd10 1 , vd20 2 , . . . , v1d 1 , v0d . Relabel outer rightmost vertices P 0 vd1 , ..., v0 ,
vd1 sink vertex P 0 , < 1, vi rightmost vertex P 0 level i.
Corresponding named vertex vi diagonal set vertices, diag(vi ), beginning
vi travelling southwest source vertex P 0 . Note sets diag(vi ) pairwise
disjoint. argue i, 0 1, least one vertex diag(vi ) must
appear c. see this, first notice vi , vertex vi0 immediate
successor vi lies outside P 0 . vertex vi0 must pebbled point,
furthermore must pebbled time configuration c, since pebbling vi0
requires pebbling source vertex P P 0 , source vertices
pebbled far source vertices P 0 . order pebble vi0
future, minimal-length pebbling, must black pebble vertex
diag(vi ) c. (In minimal-length pebbling graph G, set configurations
removed pebbling, results longer black pebbling G.) Thus,
shown c configuration d0 < source vertices pebbled thus
far, must d0 vertices pebbled c.
596

fiInapproximability Treewidth Related Problems

8. Conclusion Open Problems
proved SSE-hardness approximation variety graph problems. importantly obtained first inapproximability result Treewidth problem
Minimum Fill-In.
remarks order. status SSE conjecture is, point time,
uncertain, results therefore taken absolute evidence
polynomial time approximation algorithm (e.g.) Treewidth. However,
least, results give indication difficulty involved obtaining
algorithm Treewidth, builds connection two important problems.
also find remarkable simple reductions proofs are. leave choice
whether view healthy sign strength SSE Conjecture, whether
view indication conjecture strong, reader.
many important open questions natural avenues work, including:
1. seems plausible results extended wider range graph layout
problems. instance, two choices aggregators max viewed
taking ` `1 norms, seems likely results would apply `p
norm (though aware previous literature studying variants).
2. would nice obtain hardness approximation result problems based
weaker hardness assumption UGC. conjectured work
Raghavendra et al. (2012) SSE conjecture equivalent UGC. Alternatively,
would nice show hardness problems imply hardness
SSE Problem.
3. pebbling, would interesting obtain results unrestricted pebbling problems (for finding exact pebbling cost even PSPACE-hard).
far aware, nothing known problems, even, say, whether one
obtain non-trivial approximation NP. mentioned introduction,
currently working extending One-Shot Pebbling results bounded time
pebblings. preliminary progress hopeful relax
pebbling results much larger class pebblings.

Acknowledgments
Research supported NSERC.

References

Agarwal, A., Charikar, M., Makarychev, K., & Makarychev, Y. (2005). O( logn) approximation algorithms min UnCut, min 2CNF deletion, directed cut problems.
Proceedings thirty-seventh annual ACM Symposium Theory computing,
STOC 05, pp. 573581, New York, NY, USA. ACM.
597

fiWu, Austrin, Pitassi, & Liu

Ambuhl, C., Mastrolilli, M., & Svensson, O. (2007). Inapproximability Results Sparsest
Cut, Optimal Linear Arrangement, Precedence Constrained Scheduling. Proceedings 48th Annual IEEE Symposium Foundations Computer Science,
FOCS 07, pp. 329337, Washington, DC, USA. IEEE Computer Society.
Amir, E. (2001). Efficient approximation triangulation minimum treewidth. Proceedings 17th Conference Uncertainty Artificial Intelligence, pp. 715.
Morgan Kaufmann Publishers.
Arnborg, S., Corneil, D. G., & Proskurowski, A. (1987). Complexity finding embeddings
k-tree. SIAM J. Algebraic Discrete Methods, 8, 277284.
Arora, S., Barak, B., & Steurer, D. (2010). Subexponential algorithms unique games
related problems. Annual Symposium Foundations Computer Science,
FOCS 10, pp. 563572.
Arora, S., Lund, C., Motwani, R., Sudan, M., & Szegedy, M. (1998). Proof verification
hardness approximation problems. J. ACM, 45 (3), 501555.
Arora, S., Rao, S., & Vazirani, U. (2009). Expander flows, geometric embeddings graph
partitioning. J. ACM, 56, 5:15:37.
Arora, S., & Safra, S. (1998). Probabilistic checking proofs: new characterization np.
J. ACM, 45 (1), 70122.
Barak, B., Raghavendra, P., & Steurer, D. (2011). Rounding semidefinite programming
hierarchies via global correlation. ECCC Report TR11-065.
Bodlaender, H. L., Gilbert, J. R., Hafsteinsson, H., & Kloks, T. (1995). Approximating
treewidth, pathwidth, frontsize, shortest elimination tree. Journal Algorithms,
18 (2), 238255.
Bodlaender, H. (2007). Treewidth: Structure algorithms. Prencipe, G., & Zaks, S.
(Eds.), Structural Information Communication Complexity, Vol. 4474 Lecture
Notes Computer Science, pp. 1125. Springer Berlin / Heidelberg. 10.1007/978-3540-72951-8 3.
Bodlaender, H. L. (1996). linear-time algorithm finding tree-decompositions Small
Treewidth. SIAM Journal Computing, 25 (6), 13051317.
Bodlaender, H. L. (2005). Discovering treewidth. SOFSEM, pp. 116.
Bouchitte, V., & Todinca, I. (2003). Approximating treewidth at-free graphs. Discrete
Applied Mathematics, 131 (1), 1137.
Charikar, M., Hajiaghayi, M., Karloff, H., & Rao, S. (2010). l22 spreading metrics vertex
ordering problems. Algorithmica, 56, 577604.
Dubey, C. K., Feige, U., & Unger, W. (2011). Hardness results approximating
bandwidth. J. Comput. Syst. Sci., 77 (1), 6290.
Feige, U., Hajiaghayi, M., & Lee, J. R. (2005). Improved approximation algorithms
minimum-weight vertex separators. Proceedings thirty-seventh annual ACM
Symposium Theory computing, STOC 05, pp. 563572, New York, NY, USA.
ACM.
598

fiInapproximability Treewidth Related Problems

Fomin, F. V., & Villanger, Y. (2012). Subexponential parameterized algorithm minimum
fill-in. Proceedings Twenty-Third Annual ACM-SIAM Symposium Discrete
Algorithms, SODA 12, pp. 17371746. SIAM.
Fulkerson, D. R., & Gross, O. A. (1965). Incidence matrices interval graphs. Pacific
Journal Mathematics, 15, 835855.
Guruswami, V., & Sinop, A. K. (2011). Lasserre hierarchy, higher eigenvalues, approximation schemes quadratic integer programming psd objectives..
Hastad, J. (1999). Clique hard approximate withinn 1- . Acta Mathematica, 182 (1),
105142.
Hastad, J. (2001). optimal inapproximability results. J. ACM, 48 (4), 798859.
Heggernes, P. (2006). Minimal triangulations graphs: survey. Discrete Mathematics.
Kaplan, H., Shamir, R., & Tarjan, R. E. (1994). Tractability parameterized completion problems chordal interval graphs: Minimum fill-in physical mapping
(extended abstract). SIAM J. Comput, 28, 780791.
Khot, S., & Regev, O. (2008). Vertex cover might hard approximate within 2- .
Journal Computer System Sciences, 74 (3), 335349.
Khot, S., & Vishnoi, N. (2005). unique games conjecture. Annual Symposium
Foundations Computer Science, Vol. 46 FOCS 05, p. 3. IEEE COMPUTER
SOCIETY PRESS.
Khot, S. (2002). power unique 2-prover 1-round games. Proceedings
thiry-fourth annual ACM Symposium Theory Computing, STOC 02, pp. 767
775, New York, NY, USA. ACM.
Kinnersley, N. G. (1992). vertex separation number graph equals path-width.
Information Processing Letters, 42 (6), 345350.
Kirousis, L. M., & Papadimitriou, C. H. (1986). Searching pebbling. Theor. Comput.
Sci., 47, 205218.
Kloks, T. (1994). Treewidth: computations approximations, Vol. 842. Springer.
Koller, D., & Friedman, N. (2009). Probabilistic Graphical Models: Principles Techniques. MIT press.
Leighton, T., & Rao, S. (1999). Multicommodity max-flow min-cut theorems use
designing approximation algorithms. J. ACM, 46, 787832.
Lengauer, T. (1981). Black-white pebbles graph separation. Acta Informatica, 16,
465475. 10.1007/BF00264496.
Lengauer, T., & Tarjan, R. E. (1982). Asymptotically tight bounds time-space trade-offs
pebble game. J. ACM, 29, 10871130.
Natanzon, A., Shamir, R., & Sharan, R. (1998). polynomial approximation algorithm
minimum fill-in problem. Proceedings thirtieth annual ACM Symposium
Theory Computing, STOC 98, pp. 4147, New York, NY, USA. ACM.
Nordstrom, J. (2010). New wine old wineskins: survey pebbling classics
supplemental results. Draft manuscript.
599

fiWu, Austrin, Pitassi, & Liu

Raghavendra, P. (2008). Optimal algorithms inapproximability results every csp?.
Proceedings 40th annual ACM Symposium Theory computing, pp. 245
254. ACM.
Raghavendra, P., & Steurer, D. (2010). Graph expansion unique games conjecture.
Proceedings 42nd ACM Symposium Theory computing, STOC 10, pp.
755764, New York, NY, USA. ACM.
Raghavendra, P., Steurer, D., & Tulsiani, M. (2012). Reductions Expansion Problems. IEEE Conference Computational Complexity.
Ramalingam, G., & Rangan, C. P. (1988). unified approach domination problems
interval graphs. Inf. Process. Lett., 27, 271274.
Rao, S., & Richa, A. W. (1998). New approximation techniques ordering problems.
Proceedings ninth annual ACM-SIAM Symposium Discrete Algorithms,
SODA 98, pp. 211218, Philadelphia, PA, USA. Society Industrial Applied
Mathematics.
Ravi, R., Agrawal, A., & Klein, P. (1991). Ordering problems approximated: single-processor
scheduling interval graph completion. Albert, J., Monien, B., & Artalejo, M.
(Eds.), Automata, Languages Programming, Vol. 510 Lecture Notes Computer Science, pp. 751762. Springer Berlin / Heidelberg. 10.1007/3-540-54233-7180.
Reed, B. A. (1992). Finding approximate separators computing tree width quickly.
Proceedings Twenty-fourth Annual ACM Symposium Theory Computing,
STOC 92, pp. 221228, New York, NY, USA. ACM.
Robertson, N., & Seymour, P. D. (1984). Graph minors. III. Planar tree-width. J. Comb.
Theory, Ser. B, 36 (1), 4964.
Robertson, N., & Seymour, P. D. (1986). Graph minors. II. Algorithmic aspects treewidth. Journal Algorithms, 7 (3), 309322.
Roth, D. (1996). hardness approximate reasoning. Artificial Intelligence, 82 (1),
273302.
Sethi, R. (1973). Complete register allocation problems. Proceedings fifth annual
ACM Symposium Theory computing, STOC 73, pp. 182195, New York, NY,
USA. ACM.
Seymour, P. D., & Thomas, R. (1994). Call routing ratcatcher. Combinatorica,
14 (2), 217241.

600

fiJournal Artificial Intelligence Research 49 (2014) 705-731

Submitted 12/13; published 4/14

Convergence Q-learning Variant
Continuous States Actions
Stephen Carden

carden@clemson.edu

Department Mathematical Sciences,
Clemson University

Abstract
paper presents reinforcement learning algorithm solving infinite horizon
Markov Decision Processes expected total discounted reward criterion
state action spaces continuous. algorithm based Watkins Q-learning,
uses Nadaraya-Watson kernel smoothing generalize knowledge unvisited states.
expected, continuity conditions must imposed mean rewards transition
probabilities. Using results kernel regression theory, algorithm proven capable
producing Q-value function estimate uniformly within arbitrary tolerance
true Q-value function probability one. algorithm applied
example problem empirically show convergence well.

1. Introduction
Markov Decision Process (MDP) stochastic control problem, usually considered
discrete time. time step, system state controller chooses action.
system transitions new state probability distribution depends
previous state action utilized. reward (or cost, authors)
also received. rewards allowed random variables distribution
depends state action utilized. goal find policy (a function
maps states actions) maximizes rewards (or minimizes costs) according
measure goodness. consider MDPs terminal, absorbing
states. case, common optimality criterion expected total discounted reward.
MDPs criterion finite state-action spaces well studied.
state transition probabilities reward means known, dynamic programming
methods obtain optimal policy finite number steps (Ross, 1992). However,
probabilities rewards initially unknown transitions rewards simulated
observed, problem becomes much difficult, one amenable methods
reinforcement learning.
Watkins (1989) developed Q-learning, novel popular algorithm learning
value state-action pair optimal policy without explicitly calculating transition
probabilities mean rewards. values used construct optimal
policy. finite number states actions, learned values proven
converge true values. However, problems large number states
actions may cause values converge unreasonably slowly. Furthermore, number
state-action pairs infinite, convergence guarantee longer holds. natural
question whether knowledge gained observation generalized using
function approximators similar states actions, whether state-action values
c
2014
AI Access Foundation. rights reserved.

fiCarden

still converge, either theoretically empirically. immediacy question apparent
even Watkins thesis (1989), form function approximation, CMAC (Albus,
1975), used solution two example problems large number state-action
pairs.
Function approximators reinforcement learning may cause value estimates converge
suboptimal values (Bertsekas, 1995), oscillate (Gordon, 1996), even diverge (Fairbank
& Alonso, 2012; Tsitsiklis & Van Roy, 1996). However, used carefully, also
impressively effective. famous example success large yet finite state-action
space TD-Gammon program (Tesauro, 1995), used temporal difference learning
(Sutton, 1988) neural network generalize knowledge. eventually learned
competitive tournament-level human backgammon players. Scenarios continuous
states finite actions well studied. Empirical convergence observed
CMACs (Sutton, 1996), neural networks (Rummery & Niranjan, 1994; ten Hagen,
1991), regression trees (Ernst et al., 2005). Theoretically, positive
results well. parametric function approximator yield convergent results satisfies
certain interpolation properties (Szepesvari & Smart, 2004). non-parametric technique,
kernel regression, also proven converge optimal values (Ormoneit & Sen,
1999).
Problems states actions allowed continuous
less well-studied. One major reason constructing policy requires taking
supremum possible actions, straightforward actions finite
generally difficult continuous. difficulty, though present, prevented
researchers developing techniques make process manageable. One method
calculate values discrete set actions, use weighted average produce
continuous valued action (Millan et al., 2002). Baird Klopf (1993) specifically designed
function approximator, termed wire-fitting, supremum action
space immediately obtained. Wire-fitting combined neural networks
learn thruster-control order drive submersible target success (Gaskett
et al., 1999). Algorithms allowing stochastic policies rapidly choose actions
probability distribution, Sequential Monte Carlo Learning (Lazaric et al., 2008).
Despite practical success algorithms, little theoretical
investigation convergence properties actions continuous. purpose
paper present is, knowledge, first off-policy Q-learning variant
allowing continuous state actions proven converge optimal values
probability one. Specifically, state action spaces allowed infinite
compact subsets Euclidean space, sufficiently small kernel regression
bandwidth suitable continuity conditions random rewards transition probabilities, one may obtain Q-value function estimate uniformly within arbitrary
tolerance true Q-value function. Though intention algorithm fill
theoretical gap, results proof-of-concept example implementation provided.
particular method knowledge generalization Nadaraya-Watson kernel regression, memory-based non-parametric smoothing technique well-studied properties. similar function approximators used Ormoneit Sen (1999)
Santamara et al. (1996). distinction made Nadaraya-Watson kernel
regression use kernel functions so-called kernel trick context
706

fiA Continuous Action Q-learning Variant

reinforcement learning. methods similar use kernel function
deliver non-linear regression results kernel based weighted sums, intermediate
methodologies quite different. See work Taylor Parr (2009) discussion
kernelized value function methods, work Xu et al. (2007) application
kernelized regression policy iteration.
Section 2, Markov Decision Processes defined. Section 3 introduces NadarayaWatson kernel regression describes algorithm uses kernel smoothing obtain
function estimates Q-value state-action pair. main result
paper, theoretical convergence continuous state action algorithm, stated
Section 4 along sufficient conditions convergence. Section 5 describes strategy
proof, proves set lemmas, finally proves main result. example
implementation along discussion practical difficulties Section 6. Finally,
Section 7 concludes ideas extensions.

2. Description Continuous Markov Decision Process
assumed reader familiar basic theory discrete Markov Decision
Processes. introduction, recommend texts Puterman (1994) Ross
(1992). paper consider Markov Decision Processes state action
spaces discrete, compact subsets Euclidean space. Let S, state
space, compact subset Euclidean space dimension dS B(S) Borel algebra S. Let A, action space, compact subset Euclidean space dimension
dA . Note subset Rd = dS + dA . Elements space
written (s, a) make state action clear, computational purposes
best regarded numerical vectors. Transitions states governed
function P : B(S) R+ satisfying:
B B(S), P (, B, a) : R+ measurable function.
A, P (s, , a) : B(S) R+ probability measure S.
B B(S), P (s, B, ) : R+ measurable function.
state action (s, a) random reward R(s, a) bounded constant
C0 .
Markov Decision Process proceeds follows: process begins state
controller chooses action A. random reward R(s, a) received
system transitions new state accordance probability measure P (s, , a).
system progresses next time step, scenario repeats new state.
reward distributions transition probabilities assumed Markov property:
depend current state action; depend history
previous states actions.
policy measurable function : A. settings, policies allowed
stochastic non-stationary, restrict attention deterministic policies.
Define P (s, B) := P (s, B, (s)). P transition kernel Markov chain
space S.
707

fiCarden

Let , 0 < < 1, discount factor. Let (st , ) (random) state action
time t. policy , value state defined expected total
discounted reward criterion:
"
#
X
V (s) = E
R(st , (st ))|s0 = .
t=0


policy optimal satisfies V (s) = sup V (s), S.


goal find algorithm will, suitable conditions, converge
optimal policy. end, define Q-values
Z
Q (s, a) := E[R(s, a)] +
V (t)P (s, dt, a).


continuous version discrete definition made Watkins (1989). Intuitively
Q (s, a) value obtained start state s, utilize action a, follow policy
thereafter. Consider Q-values associated optimal policy : Q (s, a) :=

Q (s, a). learn values Q (s, a) (s, a), optimal policy easily
recovered setting
(s) = argsup Q (s, a).
aA

3. Description Algorithm
section introduce form function approximator used,
describe algorithm generate sequence estimates optimal Q-values.
3.1 Nadaraya-Watson Kernel Regression
Nadaraya-Watson kernel regression (Watson, 1964; Nadaraya, 1964) smoothing technique estimates value point weighted average nearby observations,
using non-negative kernel function assign weights observations based distance. Kernels typically symmetric, peak zero, decrease away zero
weight observation inversely related distance. Formally, require
K : Rd R+ multivariate function satisfying:
R
KI. K integrable: Rd K(u)du < .
KII. K bounded: ||K|| < CK < .
KIII. K compact support: exists L <
K(u) = 0 ||u|| > L.
KIV. K Lipschitz: exists < u, u0 Rd ,
|K(u) K(u0 )| ||u u0 || .
708

fiA Continuous Action Q-learning Variant

compact support condition required applications (indeed, Gaussian
function common kernel choice) used reduce computation load
assigning zero weight sufficiently distant observations.
bandwidth h > 0 parameter used fine-tune level smoothing. Define
Kh (u) :=

1
K(u/h).
h

u non-scalar, division may understood component-wise. Values h
large small relative sample size tend oversmooth overfit data.
Typically using kernel regression bandwidth decreases toward zero number
observations increases. discussion particulars bandwidth selection beyond
scope paper, rule thumb obtained assuming Gaussian density
1
unit variance h = n 4+d , n number observations dimension
(Hardle, 2004). rule thumb regarded starting value, definitive
answer. example, cross-validation common method selecting bandwidths.
information, interested reader referred texts Silverman (1986)
Simonoff (1996). purpose algorithm follow, need constant
bandwidth sufficiently small.
Given set n ordered pairs (xi , yi ) bandwidth h, Nadaraya-Watson estimator
Pn
Kh (x xi )yi

ch (x) = Pi=1
.
n
i=1 Kh (x xi )
3.2 Algorithm
use following notation. n > 0,
h fixed bandwidth.
fixed discount factor.
(sn , ) state-action pair beginning iteration n.
rn sample reward observed iteration n.
un state transitioned iteration n.
b h,n1 (un , a), Q
b h,n1 (un , a) defined (2).
yh,n := rn + supaA Q
description algorithm.
b h,0 (s, a) = 0
1. Set initial Q-value estimate function zero everywhere. Q
(s, a) A. Choose initial state s1 .
2. n > 0, pick action -greedily (or according exploration
method). Define function h,n : [0, 1]

P

P Kh ((s, a) (sn , ))
nj=1 Kh ((s, a) (sj , aj )) 6= 0
n
h,n (s, a) =
(1)
j=1 Kh ((s, a) (sj , aj ))
P

0
nj=1 Kh ((s, a) (sj , aj )) = 0
709

fiCarden

use update Q-value estimate function setting
b h,n (s, a) := (1 h,n (s, a))Q
b h,n1 (s, a) + h,n (s, a)yh,n .
Q

(2)

Set sn+1 = un .
Note result Equation (2), one may show induction
Pn
P

j=1 Kh ((s, a) (sj , aj ))yh,j

P
nj=1 Kh ((s, a) (sj , aj )) 6= 0

n

j=1 Kh ((s, a) (sj , aj ))
b h,n (s, a) =
P
Q
b

Qh,0 (s, a)
nj=1 Kh ((s, a) (sj , aj )) = 0.




(3)

Equation (2) updates conceptually performed form familiar
classic Q-learning, Equation (3) calculations made. estimates
produced algorithm essentially kernel-smoothed averages terms yh,n :=
b h,n1 (un , a).
rn + supaA Q
Algorithm 1 Pseudocode theoretical algorithm
Initialize h = bandwidth value, = maximum iterations,
= discount factor, = exploration parameter
b h,0 (s, a) = 0 (s, a)
Initialize Q
Set initial state s1
i=1:m
r = Uniform(0,1) random value
r < ai = random action
else
b h,n1 (si , a)
ai = supaA Q
end
ui = next state, ri = reward
b h,i1 (ui , a)
yh,i := ri + supaA Q
Pi
j=1 Kh ((s,a)(sj ,aj ))yh,j
b h,i (s, a) = P
Q

si+1 = ui
end

j=1

Kh ((s,a)(sj ,aj ))

4. Statement Theorem
Assume following conditions hold:
AI. state-action pair utilized beginning iteration (regarded
random variable due exploration random transitions) density f :
R positive everywhere uniformly continuous bounded second
derivatives.
AII. Rewards bounded. exists C0 < (s, a) A,
R(s, a) < C0 .
710

fiA Continuous Action Q-learning Variant

AIII. expected values rewards Lipschitz continuous across state-action
space. exists Cr (s1 , a1 ), (s2 , a2 ) A,
|E[R(s1 , a1 )] E[R(s2 , a2 )]| Cr ||(s1 , a1 ) (s2 , a2 )||.
Also, E[R(s, a)]f (s, a) uniformly continuous bounded second derivatives.
AIV. Transition probabilities converge weakly Lipschitz continuously. Let g : R
continuous bounded. exists Ct (s1 , a1 ), (s2 , a2 ) A,
fiZ
fi
Z
fi
fi
fi g(u)P (s1 , du, a1 ) g(u)P (s2 , du, a2 )fi Ct ||g(u)|| ||(s1 , a1 ) (s2 , a2 )||
fi
fi
Also,
tives.

R

g(u)P (s, du, a)f (s, a) uniformly continuous bounded second deriva-

Theorem 1. Let assumptions AI. - AIV. kernel conditions KI. - KIV. hold
b h,n (s, a) defined (2). probability one, > 0, exists h = h()
Q
N = N (h, ) n > N
sup

b h,n (s, a) Q (s, a)| < .
|Q

(4)

(s,a)SA

5. Lemmas Proof Theorem
proof strategy inspired Watkins original proof finite spaces. interested
reader, suggest technical report (Watkins & Dayan, 1992) followed Watkins
thesis. method different later approaches proving convergence Qlearning, Tsitsiklis (1994) Jaakkola et al. (1993), variations
extensions stochastic approximation theory. Although Watkins method rely
stochastic approximation result minor way, key intuition Q-learning
imitates model estimation.
One strengths Q-learning require model system
estimated maintained. However, learned Q-values optimal values model
constructed appropriately assigning weights observed rewards
transitions. Specifically, learning parameters used update value estimates used
weight reward transition observations carefully define artificial process,
learned Q-value estimates optimal artificial process. rewards
transitions observed, artificial process becomes similar real process,
optimal Q-values two processes become similar, thus learned values
converge optimal values real process. Watkins called artificial process
Action Replay Process.
proof strategy summarized following five steps:
1. fixed bandwidth value, define auxiliary Action Replay Process (ARP).
artificial process purely proof device.
b h,n (s, a) optimal Q-value function ARP
2. Show function Q
corresponding bandwidth.
711

fiCarden

3. Show sufficiently small bandwidths, rewards transition probabilities
ARP become arbitrarily close original process.
4. Show two MDPs similar rewards transition probabilities similar
optimal Q-values.
5. optimal values ARP converge optimal values original process.
Hence step 2, Q-values learned algorithm converge optimal Qvalues.
5.1 Construction ARP (Action Replay Process)
ARP defined. finite length, terminating MDP. Pick bandwidth
value h, keep fixed throughout discussion follows. suggest thinking
ARP card game. Suppose one preparing run algorithm Section
3. Also suppose deck index cards. iteration algorithm,
b h,k (), h,k () >. values
write following values card: < sk , ak , uk , rk , Q
regarded random variables depending random states, actions, rewards
original process rather fixed values particular sample trajectory.
b h,0 () written. card bottom, stack
also card initial Q
cards ascending order iteration shown Figure 1.
b h,n (), h,n () >
< sn , , un , rn , Q

Level n

b h,n1 (), h,n1 () >
< sn1 , an1 , un1 , rn1 , Q

Level n 1

..
..
..
b h,2 (), h,2 () >
< s2 , a2 , u2 , r2 , Q

Level 2

b h,1 (), h,1 () >
< s1 , a1 , u1 , r1 , Q

Level 1

b h,0 () >
<Q

Level 0

Figure 1: ARP envisioned stack cards.

States state ARP 2-tuple < s, n > consisting state original state
space non-negative level n tells us card inspected.
cards level n ignored, leaving us finite stack cards. state
level 0 terminal, absorbing state.
Actions actions ARP actions real process, A.
712

fiA Continuous Action Q-learning Variant

Transitions Rewards Suppose ARP state < s, n > action chosen.
Inspect card corresponding level n. probability h,n (s, a), accept
card receive reward rn transition state < un , n 1 >. Otherwise, ignore
card inspect card level n 1. probability h,n1 (s, a), accept
card, receive reward rn1 transition state < un1 , n 2 >. Otherwise,
continue inspecting cards one accepted, probability accepting
card level k h,k (s, a). bottom card corresponding level 0 reached
(that is, state < s, 0 > action utilized) reward Qh,0 (s, a)
received ARP terminates.
ARP MDP, optimal Q-values. Let Qh (< s, n >, a) function
giving optimal Q-values state < s, n > action ARP bandwidth h.
5.2 Lemmas
optimal Q-values level n ARP corresponding bandwidth h learned
Q-value estimates original process iteration n defined (2).
Lemma 1.
b h,n (s, a), (s, a) A, n 0.
Qh (< s, n >, a) = Q
Proof. Proceed induction level n ARP. Recall ARP state
b h,0 (s, a) process terminates.
< s, 0 > action used, reward Q
Thus
b h,0 (s, a)
Qh (< s, 0 >, a) = Q
proves n = 0 case.
b h,n1 (s, a) states
suppose way induction Qh (< s, n 1 >, a) = Q
actions. Let ARP state < s, n > action utilized. Recall
construction ARP,
probability h,n (s, a) receive reward rn transition < un , n 1 >.
Otherwise,
probability 1 h,n (s, a) card thrown away situation identical
utilizing state < s, n 1 >.
conditioning whether level n card accepted not,
induction hypothesis (2):
Qh (< s, n >, a) = (1 h,n (s, a))Qh (< s, n 1 >, a)
+ h,n (s, a)(rn + sup Qh (< un , n 1 >, b))
bA

b h,n1 (s, a)
= (1 h,n (s, a))Q
b h,n1 (un , b))
+ h,n (s, a)(rn + sup Q
bA

b h,n1 (s, a) + h,n (s, a)yh,n
= (1 h,n (s, a))Q
b h,n (s, a).
=Q

713

fiCarden

following lemma, needed proof Lemma 3, shows
grows uniformly across state-action space.

Pn

k=1 h,k (s, a)

Lemma 2. assumption AI. holds, probability one,
lim

inf

n
X

n (s,a)SA

h,k (s, a) .

(5)

k=1

Proof. compact, covered finite number disjoint sets fixed
positive diameter set positive Lebesgue measure. Choose diameter
u, u0 set implies Kh (u u0 ) > > 0. Suppose J sets needed,
denote B1 , B2 , ..., BJ . Set T0 = 0 k > 0, let Tk denote first time
set visited least k times. Note AI. Borel-Cantelli
Lemma, P (Tk < ) = 1. Fix (s, a) A, letting CK denote bound
kernel values,
Tn
X
k=1

h,k (s, a) =

n
X

Tk
X

h,j (s, a)

k=1 j=Tk1 +1

n
X
k=1

n
X 1
=
Tk .
CK Tk
CK



k=1

terms Tk , k > 0, independent bounded random variables
are. Set W1 = T1 . Ignoring previous visits sets prior time T1 , set W2
number steps T1 Bj visited again. obvious W2 T2 T1 .
Likewise, k > 1, set Wk number steps Tk1 set visited
again, Wk Tk Tk1 . Notice W1 , W2 , ... i.i.d. random variables. Applying
inequalities, one may write
T11 = W11
T21 (W1 + W2 )1
..
.

1
k
X
1
Wj .
k

j=1


Tn
X
k=1


1
n
k
X X
h,k (s, a)
Wj .
CK
k=1

j=1

1
Pn Pk
suffices show
goes infinity probability one. Set
k=1
j=1 Wj
Pn
Pn
Pn 1 k
P
1
1
Sn = k=1 Wk . k=1 Sk = k=1 k Sk . Since Skk E[W
> 0, nk=1 k1 Skk
1]
probability one. (s, a) arbitrary, proves result.
next lemma shows one starts ARP sufficiently high level,
probability ending certain level fixed number actions made
arbitrarily small.
714

fiA Continuous Action Q-learning Variant

Lemma 3. Let > 0, l0 level ARP, positive integer n represent length
sequence actions followed. exists level l > l0 ARP
starts level l follows sequence n actions, probability ending
level l0 less .
Proof. Proceed induction. Consider first case n = 1. > l0 , suppose
ARP state < s, > action utilized. Transitioning state level l0
means card level l0 accepted. probability accepting card
level k 1 h,k (s, a), probability accepting none
k=l0 (1 h,k (s, a)).
well-known inequality real analysis yields



k=l0 (1 h,k (s, a)) < e

Pm

k=l0

h,k (s,a)

.

follows Lemma 2 possible choose l1 > l1 implies

X

inf
(s,a)SA

h,k (s, a) > log .

k=l0





P (ending l0 ) =
k=l0 (1 h,k (s, a)) < e

Pm

k=l0

h,k (s,a)

< .

sequence n actions, exists l1 probability ending
l0 l1 one transition less 2 induction l2
probability ending l1 n 1 transitions less 2 . ARP starts
level l2 ,
P (below l0 n transitions)
=P (below l0 n transitions|above l1 n 1 transitions)
P (above l1 n 1 transitions)
+P (below l0 n transitions|below l1 n 1 transitions)
P (below l1 n 1 transitions)


1 + 1 = .
2
2
next lemma allows one work finite sequences actions rather infinite
ones arbitrarily small error.
Lemma 4. Consider value state specific sequence n actions (a0 , a1 , ..., an1 )
followed process terminated:
"n1
#
X

E
R(st , )|s0 = .
t=0

Also consider value state n actions followed
arbitrary policy :
"n1
#

X
X


E
R(st , ) +
R(st , (st ))|s0 = .
t=0

t=n

difference two values goes zero n increases towards infinity.
715

fiCarden

Proof. interested difference
"n1
#
"n1
#

X
X
X
E
R(st , ) +
R(st , (st ))|s0 = E
R(st , )|s0 = .
t=n

t=0

t=0

difference clearly expectation second term first expectation.
rewards bounded C0 , use change variables v = n write
"
#
"
#
X
X

v+n
E
R(st , (st ))|s0 = = E

R(sv , (sv ))|s0 =
t=n

v=0

"
nE


X

#
v |R(sv , (sv ))||s0 =

v=0

n


X

v C0 = n

v=0

C0
1

goes zero n goes infinity.
next lemma consider reward received ARP state < s, n >
action utilized. random quantity depends state-actions chosen
rewards received original process, also depends levels ARP
accepted state transitions. ARP constructed bandwidth h
b h,n (s, a)] denote
rewards received state < s, n > utilizing action a, let E[R
expectation taken ARP state transitions, sequence state-actions
b h,n (s, a)] constant,
rewards original process. Note E[R
random quantity defined sample space original process.
Similarly, probability ARP transitioning state set B(S) also
random variable depending state-actions chosen original process.
ARP constructed bandwidth h starting state < s, n > utilizing action
a, let Pbh,n (s, T, a) denote random probability ARP transitioning state
set .
next lemma shows high enough levels, rewards transition probabilities ARP close rewards transition probabilities original
process.
Lemma 5. assumptions AI.-AIV. kernel conditions KI.-KIV. met,
a) probability one, > 0 exists h = h(, ) N = N (, h)
n > N ,
fi
fi
fib
fi
sup fiE[R
(s,
a)]

E[R(s,
a)]
fi < .
h,n
(s,a)SA

b) probability one, > 0 g : R integrable, continuous,
bounded, exists h() N (, h) n > N ,
fiZ
fi
Z
fi
fi
b
fi
sup fi g(u)Ph,n (s, du, a)
g(u)P (s, du, a)fifi < .
(s,a)SA





716

fiA Continuous Action Q-learning Variant

Proof. Consider expected reward associated state-action (s, a) level n
ARP. Condition whether card level n accepted. probability 1 h,n (s, a)
accept card, expected reward level n 1. probability
h,n (s, a) level n card accepted receive reward rn . special case n = 0,
b h,0 (s, a). expected rewards
lowest level ARP receive reward Q
satisfy recursive relationship
b h,0 (s, a)] = Q
b h,0 (s, a),
E[R
b h,n (s, a)] = (1 h,n (s, a))E[Rh,n1 (s, a)] + h,n (s, a)rn , n > 0.
E[R

show induction
Pn
j=1 Kh ((s, a) (sj , aj ))rj
b
E[Rh,n (s, a)] = Pn
j=1 Kh ((s, a) (sj , aj ))


Pn

j=1 Kh ((s, a)

(sj , aj )) 6= 0. n = 1 case,

b h,1 (s, a)] = (1 h,1 (s, a))Q
b h,0 (s, a) + h,1 r1 .
E[R
Replace h,1 (s, a) terms per definition (1).
P1

b h,1 (s, a)] =
E[R

1

j=1 Kh ((s, a)
P1
j=1 Kh ((s, a)

(sj , aj ))
(sj , aj ))

!

P1

b h,0 (s, a) + Pj=1
Q
1

Kh ((s, a) (sj , aj ))

j=1 Kh ((s, a)

(sj , aj ))

r1

= r1 .
assume induction hypothesis holds n 1.
b h,n (s, a)] = (1 h,n (s, a))E[R
b h,n1 (s, a)] + h,n (s, a)rn
E[R
! Pn1
!
Pn1
j=1 Kh ((s, a) (sj , aj ))
j=1 Kh ((s, a) (sj , aj ))rj
= Pn
Pn1
j=1 Kh ((s, a) (sj , aj ))
j=1 Kh ((s, a) (sj , aj ))
Kh ((s, a) (sj , aj ))
+ Pn
rn
j=1 Kh ((s, a) (sj , aj ))
Pn
j=1 Kh ((s, a) (sj , aj ))rj
= Pn
.
j=1 Kh ((s, a) (sj , aj ))
expected rewards ARP equivalent kernel regression estimates. Assumptions AI., AII., AIII., kernel conditions KI.-KIV. meet technical conditions
Hansen (2008). See Theorem 9 page 735. yields
sup

b h,n (s, a)] E[R(s, a)]| <
|E[R

(s,a)SA

sufficiently large n, proves part a).
717

fiCarden

part b), recall un denotes state transitioned iteration n.
Consider random variable indicator function event n-th transition
original process B(S).
(
1 un
1T (un ) =
0 un
/T .
Similar rewards, transition probabilities ARP level n conditioned
whether level n card accepted not. Assume state-action (s, a).
probability 1 h,n (s, a), accept card probability transitioning
level n 1. probability h,n (s, a) level n card accepted
value 1T (un ) tells us whether transition not. Thus relation
Pbh,1 (s, T, a) =h,1 (s, a)1T (u1 ),
Pbh,n (s, T, a) =(1 h,n (s, a))Pbh,n1 (s, T, a) + h,n (s, a)1T (un ).
P
Let g : R simple function, g(u) =
i=1 ai 1Ti (u). apply relation
integral g find
Z


X
X
g(u)Pbh,1 (s, du, a) =
ai Pbh,1 (s, Ti , a) =
ai 1Ti (u1 )
i=1

i=1

= g(u1 )

Z

X
g(u)Pbh,n (s, du, a) =
ai Pbh,1 (s, Ti , a)
=

i=1

X

h

ai (1 h,n (s, a))Pbh,n1 (s, Ti , a) + h,n1 (s, a)1Ti (un )

j=1

Z
= (1 h,n1 (s, a))

g(u)Pbh,n1 (s, du, a) + h,n (s, a)g(un ).

Using common argument measure theory, relation also holds integrable
function approximating simple functions. rest proof proceeds part
a), assumptions AI., AIV., kernel conditions KI.-KIV. fulfilling requirements
Hansens Theorem 9.
Definition. given MDP, let Q(s1 , < a1 , a2 , ..., , >) denote expected discounted reward received process starts state s1 actions a1 , a2 , ...,
utilized consecutively process terminates. Formally


n
X
Q(s1 , < a1 , a2 , ..., , >) = E
j1 R(sj , aj )
j=1

718

fiA Continuous Action Q-learning Variant

chance transitioning states s2 , ..., sn understood governed
P (sj , , aj ).
following lemma shows state-action values possess sort continuity.
property needed apply Lemma 7 state-action values.
Lemma 6. assumptions AII., AIII., AIV. hold, n, fixed
arbitrary sequence actions < a1 , a2 , ..., >, function f : R defined
f (s) = Q(s, < a1 , a2 , ..., , >)
Lipschitz continuous.
Proof. Consider first case n = 1. Let s1 , s2 S. AIII.
|Q(s1 , < a1 , >) Q(s2 , < a1 , >)|
=|E[R(s1 , a1 )] E[R(s2 , a1 )]| Cr ||(s1 , a1 ) (s2 , a1 )||.
considering case n > 1, notice assumption AII.


n
X
|Q(s, < a1 , a2 , ..., , >)| E
j1 |R(sj , aj )|
j=1




X

j1 C0

j=1

=

C0
.
1

Applying AIII. difference means AIV. difference integrals,
n > 1 s1 , s2
|f (s1 ) f (s2 )| =|Q(s1 , < a1 , ..., , t) Q(s2 , < a1 , ..., , >)|
|E[R(s1 , a1 )] E[R(s2 , a1 )]|
fi Z
fi
+ fifi
Q(u, < a2 , ...an , >)P (s1 , du, a1 )
fi
ZS
fi

Q(u, < a2 , ...an , >)P (s2 , du, a1 )fifi


Cr ||((s1 , a1 ) (s2 , a1 ))|| + Ct ||Q(u, < a2 , ...an , >)|| ||(s1 , a1 ) (s2 , a1 )||
C0
Cr ||((s1 , a1 ) (s2 , a1 ))|| + Ct
||(s1 , a1 ) (s2 , a1 )||.
1
C0
} inserting last inequality,
taking C1 = 2 max{Cr , C1

|f (s1 ) f (s2 )| C1 ||(s1 , a1 ) (s2 , a1 )||.
Finally, notice ||(s1 , a1 )(s2 , a1 )|| = ||s1 s2 || properties Euclidean metric.
end
|f (s1 ) f (s2 )| C1 ||s1 s2 ||,
proves result.
719

fiCarden

next lemma, suppose one two MDPs defined state action
space. (s, a) A, let R(i) (s, a) P (i) (s, , a) denote rewards transition
probabilities process = 1, 2. lemma show expected rewards
transition probabilities processes sufficiently close, expected discounted
reward series actions also close.
Lemma 7. Suppose assumptions required Lemma 6 hold. > 0 sequence
actions length n, exists r (n, ) (n, ) g : R continuous
C0
||g|| 1
following two conditions hold:
1.
sup
(s,a)SA

fi
fi
fi
fi
fiE[R(1) (s, a)] E[R(2) (s, a)]fi < r (n, )

2.
sup
(s,a)SA

fi
fiZ
Z
fi
fi
(2)
fi < (n, ),
fi g(u)P (1) (s, du, a)
g(u)P
(s,
du,
a)
fi
fi




sequence actions length n,
|Q(1) (s1 , < a1 , a2 , ..., , >) Q(2) (s1 , < a1 , a2 , ..., , >)| < .
Proof. proceed induction n, number actions executed. n = 1,
take r (1, ) = .
|Q(1) (s1 , < a1 , >) Q(2) (s1 , < a1 , >)| = |E[R(1) (s1 , a1 )] E[R(2) (s1 , a1 )]| < r = .
assume induction hypothesis
holds sequence
actions


length n1. Take



r (n, ) = min 3 , r (n 1, 3 ) , (n, ) = min 3 , (n 1, 3 ) . sequence
length n, condition state s2 write
|Q(1) (s1 , < a1 , ..., , >) Q(2) (s1 , < a1 , ..., , >)|
|E[R(1) (s1 , a1 )] E[R(2) (s1 , a1 )]|
fiZ
fi
+ fifi Q(1) (s2 , < a2 , ..., , >)P (1) (s1 , ds2 , a1 )
fi
Z
fi
(2)
(2)

Q (s2 , < a2 , ..., , >)P (s1 , ds2 , a1 )fifi .


720

(6)
(7)
(8)

fiA Continuous Action Q-learning Variant

Add subtract

R


Q(1) (s2 , < a2 , ..., , >)P (2) (s1 , ds2 , a1 ):

|Q(1) (s1 , < a1 , ..., , >) Q(2) (s1 , < a1 , ..., , >)|
|E[R(1) (s1 , a1 )] E[R(2) (s1 , a1 )]|
fiZ
fi
+ fifi Q(1) (s2 , < a2 , ..., , >)P (1) (s1 , ds2 , a1 )
fi
ZS
fi
(1)
(2)
Q (s2 , < a2 , ..., , >)P (s1 , ds2 , a1 )fifi

fiZS
fi
+ fifi Q(1) (s2 , < a2 , ..., , >)P (2) (s1 , ds2 , a1 )
fi
ZS
fi
(2)
(2)
Q (s2 , < a2 , ..., , >)P (s1 , ds2 , a1 )fifi



Lemma 6 value function continuous, assumption first difference
made smaller /3 choice r , second difference made small choice
, third difference made small induction hypothesis. difference
less 3 , result proved.
5.3 Proof Theorem
prepared prove Theorem 1.
Proof. terms subscripts denote values ARP bandwidth h.
terms subscripts refer original process. policy , consider
difference
|Qh (< s, n >, a) Q (s, a)|
|Qh (<

(9)

s, n >, a) Qh (< s, n >, < a, (s2 ), ..., (sm ), >)|

+ |Qh (< s, n >, < a, (s2 ), ..., (sm ), >) Q(s, < a, (s2 ), ..., (sm ), >)|


+ |Q(s, < a, (s2 ), ..., (sm ), >) Q (s, a)| .

(10)
(11)
(12)

Lemma 4, chosen large enough lines (10) (12) less 3 .
Lemma 5, exists h N N iterations run,
rewards transition probabilities ARP become arbitrarily close
real process. Furthermore, Lemma 3 higher level N1 one starts
level N1 , probability straying N performing actions less
(1)
12C0 . level N , requirements apply Lemma 7 met, one
0
make line (11) less 12C02C
(1) . ARP stray level N ,
2C0
difference bounded 1
mentioned Lemma 6. conditioning whether
ARP strays level N ,

|Qh (< s, n >, < a, (s2 ), ..., (sm ), >) Q(s, < a, (s2 ), ..., (sm ), >)|




2C0
12C0 (1 )

2C0 (1 )

+
= .
1
12C0
12C0 (1 )
12C0
3
721

fiCarden

follows
|Qh (< s, n >, a) Q (s, a)| < .
policy arbitrary, replace policy optimal real
process, . know
fi
fi
fi
fi
fiQh (< s, n >, a) Q (s, a)fi < .
claim also gives optimal values ARP. not,
policy 0 gave higher values, consider
fi
fi
fiQ 0 (< s, n >, a) Q0 (s, a)fi
h


made arbitrarily small, would imply Q0 (s, a) > Q (s, a) contradicts
choice optimal policy.
|Qh (< s, n >, a) Q (s, a)| < .
b h (s, a). Thus
Lemma 1, Qh (< s, n >, a) = Q
fi
fi
fib
fi
fiQh,n (s, a) Q (s, a)fi < .
(s, a) arbitrary, convergence uniform.

6. Experimental Results
primary intent paper therefore also algorithm serve addition
theory continuous domain reinforcement learning providing asymptotic convergence results. section explore practical application algorithm show
minor modification capable obtaining satisfactory solution standard
benchmark problem reasonable amount time.
section detail application Mountain Car problem (Moore, 1991).
state space consists two variables: position p car, constrained
interval [1, 1] velocity v, constrained [3, 3]. action space consists
single variable, force applied vehicle along line tangent road value
[4, 4]. car starts bottom hill standstill, corresponding initial
state (.5, 0). goal drive car top hill positive direction,
i.e., p > 1 keeping velocity bounds. goal reached, reward 1
experienced trial terminates. car goes bounds (that is, p < 1
|v| > 3) reward 1 received trial terminates. states
reward received zero. hill defined expression

p2 + p
p < 0
H(p) = p
p 0 .

2
1+5p

Figure 2 shows shape hill, initial position, location goal.
problem non-trivial maximum force positive direction large
enough move directly goal. Instead, agent must learn build momentum
alternating acceleration trying move goal.
722

fiA Continuous Action Q-learning Variant

1
0.8
0.6
0.4
0.2
0
0.2
0.4
0.6
0.8
1
1

0.8 0.6 0.4 0.2

0
0.2
Position

0.4

0.6

0.8

1

Figure 2: hill mountain car climb. circle represents initial position,
star represents goal.

6.1 Examination Assumptions
Assumptions AI.-AIV., sufficient ensure convergence, quite strong. fact,
many standard problems Reinforcement Learning meet them.
example, rewards often discontinuous nature, states emit zero
reward crossing boundary suddenly yields reward penalty. purpose
section show proposed algorithm somewhat robust. is, even
presence violated conditions, obtain policies adequate solving problem
hand. Specifically, see Mountain Car problem violates two four
assumptions, yet algorithm still produces policy reach goal state.
first assumption continuous analogue classic Q-learnings requirement
every state-action pair visited infinite number times. require distribution
(sn , ) possess density positive sufficiently smooth. However, given
dynamics Mountain Car, areas state space inaccessible
available actions. Consider state consisting position p = .9 velocity
v = 2.9. position top hill near goal. maximum acceleration
negative direction strong enough produce negative velocity large 2.9
space given.
Figure 3 suggests density state space adequately smooth,
clear states visited. However, state space
restricted set accessible states, seems reasonable density everywhere
positive.
second assumption requires bounded rewards. Mountain Car problem clearly
satisfies this.
723

fiCarden

Figure 3: histogram showing frequency visits across state space.

third assumption requires rewards Lipschitz continuous. common
Reinforcement Learning rewards zero state-action space,
goal state emitting positive rewards penalties issued leaving boundaries entering
undesirable states. exactly case Mountain Car. One could circumvent
problem replacing impulse rewards low-variance Gaussian density function
centered goal state, use similar method smoothing rewards without disrupting
overall reward structure.
fourth assumption requires weak convergence transition probability measures
states actions become similar. Furthermore, convergence must uniform
across state-action space. problem smooth, deterministic transitions
Mountain Car, easy verify convergence distribution un (the state
transitioned to) state-actions (sn , ) converge, equivalent weak convergence
(see Jacod & Protter, 2003, ch. 18).
noted strength assumptions directly linked desire
value function estimate converge uniformly. Kernel methods achieve weaker
forms convergence much weaker assumptions. example, Devroye Gyorfi
(1985) show proper bandwith selection, kernel density estimates converge
L1 conditions density estimated. suggests kernel-based
algorithms may able return good policies despite discontinuities reward function,
case Mountain Car problem. However, thoroughly
investigated problems yet.
6.2 Computational Considerations
advantage non-parametric approximators potential represent
function arbitrary precision, cost increased computational load
724

fiA Continuous Action Q-learning Variant

observations used. following paragraphs discuss suggestions
alleviating problem.
One idea selective observations kept use future calculations
discarding rest. example, consider boundary reached
first time, rewards received equal zero, initialized function value.
Recording observations slow future value function computations
add knowledge system. Suppose state-action (s, a), reward
rn received next state un . One may choose discard experience
b h,n1 (un , b) Q
b h,n1 (s, a)| <
|rn + sup Q
bA

tolerance . keeping experiences potential improve value
function estimate ensures algorithm learns efficiently.
Another idea to, point, begin discarding old observations new ones
b h,n1 (un , b)
recorded keep fixed number memory. Consider terms rn + supbA Q
b h,n1 (un , b) yet calculated enough data give
calculated early, value Q
good estimate. Dropping old values favor new ones serves double purpose capping increasing computational load speeding convergence value estimates. Care
taken region state-action space left without observations
performing kernel regression.
third option, approach taken example, seed algorithm
fixed number randomly-generated episodes reached goal
beginning standard -greedy exploration strategy. Exploration episodes generated
using random action selection. Episodes reach penalty state fail find goal
within 500 iterations discarded, successful episodes passed algorithm.
20 episodes, algorithm chooses random actions probability optimal
(based current knowledge) actions otherwise. point iterations passed
learning algorithm.
mentioned introduction, taking supremum possible actions
given state is, general, difficult problem. Mountain Car problem,
one action variable, suitable choice kernel function allows exact solutions.
Epanechnikov kernel defined
(
3
(1 x2 ) |x| < 1
e
K (x) = 4
(13)
0
otherwise
common choice kernel regression minimizes approximation mean
integrated square error (see Silverman, 1986, section 3.3.2 details). three
dimensional Mountain Car problem, define multivariate kernel product
Epanechnikov kernels variable. is, state-action pairs represented
(pk , vk , ak ), define
K((p1 , v1 , a1 ) (p2 , v2 , a2 )) = K e (p1 p2 )K e (v1 v2 )K e (a1 a2 )
advantage formulating kernel way numerator derivative
respect action variable quadratic action variable. Epanechnikov kernel non-zero finite interval, domain action variable broken
725

fiCarden

finite number intervals quadratic coefficients constant. Thus
points candidate maxima either root one finite number quadratics
breakpoints intervals. Using method, optimal action calculated
relatively efficiently. routine finds multiple actions optimal value, ties
broken randomly. Currently, strategy works problems one action
variable, though possibility extending higher dimensions investigated.
6.3 Results

3

2

Velocity

1

0

1

2

3

1

0.8 0.6 0.4 0.2

0
0.2
Position

0.4

0.6

0.8

1

Figure 4: trajectory state space obtained final policy.

4

3

2

Action

1

0

1

2

3

4
0

2

4

6

8

10

12

14

Iteration

Figure 5: Actions chosen final policy.
726

fiA Continuous Action Q-learning Variant

Implementation MATLAB 2012b Ubuntu 12.04 hardware Intel
Xeon 3.47 gigahertz processor 24 gigabytes RAM. 7,500 iterations recorded
858 seconds. Parameter values bandwidth h = .2, exploration parameter = .9,
discount factor = .9, k = 20 successful episodes initialize 1 .
policy obtained near-optimal. Figure 4 shows trajectory car
state space. car begins accelerating negative direction, travels partway
hill left, changes positive acceleration reaches goal. Figure
5 shows action selection time. optimal policy choose actions extreme
ends action interval, learned policy sometimes chooses actions near
boundary. Figure 6 shows iterations time. initially surprising
phenomena here. One would expect number iterations per second increase
data collected, around 400 iterations calculations actually speed up.
reason small amount data available, action-selection subroutine
find many actions maximum value. candidate best action kept
memory tie randomly broken end subroutine. data
collected, ties occur less commonly, subroutine finishes less time. brief
time, increase speed faster action-selection outpaces decrease speed
accumulating data. time, phenomena vanishes, algorithm slows
again. Figure 7 shows iterations time 25,000 iterations. plot
clear described phenomena temporary.
Another unexpected occurence involved optimal bandwidth. Repeating experiment multiple times different bandwidths revealed best results obtained
algorithm learned bandwidth .2 used smaller bandwidth, .07,
building final policy. Early trials resulted policy could find goal spent
time necessary building momentum. Upon investigation found
value state-actions corresponding initial state calculated using values
initial position positive velocity. caused policy use positive acceleration
(the best action velocity already positive) rather negative acceleration (the
best action velocity zero) initial state. smaller bandwidth, specifically
.07, avoided issue. Note using .07 algorithm learning phase
yield good results sufficiently generalize small amount
data available. suggests even though convergence proof uses fixed
bandwidth, practice best decrease bandwidth amount data increases.

7. Conclusion
paper presented reinforcement learning algorithm continuous states actions proven converge optimal solution. Knowledge generalization based
Nadaraya-Watson kernel regression. similar previous result Ormoneit
Sen (1999), uses kernel-smoothing problems continuous state space
finite number actions. algorithm presented different important
ways. First, actions allowed continuous. However, introduces burden
ensuring small changes actions result small changes transition dynamics. Second,
assumption distribution states weaker. Ormoneit Sens Assumption
1. full source code, see online appendix associated publication.

727

fiCarden

8000
7000
6000

Iterations

5000
4000
3000
2000
1000
0

0

100

200

300

400
500
600
Time (seconds)

700

800

900

1000

Figure 6: Graph 7,500 iterations completed time.
4

2.5

x 10

2

Iterations

1.5

1

0.5

0

0

1000

2000

3000
Time (seconds)

4000

5000

6000

Figure 7: Graph 25,000 iterations completed time.
3 requires states sampled uniformly state space. weakened
present paper requiring distribution states positive smooth
density.
presented algorithm sequential updates single observation.
primary reason considering sequential rather batch-mode algorithm
Watkins proof strategy applied directly possible. However, applications,
batch-mode version possesses many advantages. Informal experiments Mountain
Car Inverted Pendulum problems batch-mode implementation produced
better results typically quarter amount time sequential algorithm requires.
728

fiA Continuous Action Q-learning Variant

One practical difficulties implementing algorithm amount
computation required increases recorded observation. addition ideas
Section 6, author experimented sparsifying selecting grid points
{(sj , aj )|j = 1, ..., } state-action space assigning point value
performing kernel regression values yield predictions similar predictions
obtained using kernel regression entire set observations. Essentially, idea
use kernel radial basis function fixed locations state-action space learn
weights each. Specifically, suppose N transitions observed, N ,
b h,i1 (ui , a)|i = 1, ..., N } recorded. Define
{(si , ai )|i = 1, ...N } {yh,i := ri + supaA Q
matrix XN entry-wise
Kh ((si , ai ) (sj , aj ))
Xi,j = PM
j=1 Kh ((si , ai ) (sj , aj )
~N 1 Yi = yh,i . Solve ~ minimizes ||X ~
~ ||2 . state-action (s, a), deand
~ 1 (s, a) Kj (s, a) = K((s, a) (sj , aj )). value (s, a) estimated
fine K
~ future observations, update ~ described Chambers (1971).
~ (s, a).
K
method requires computation linear number observations constant
storage requirements.
fourth assumption concerns weak convergence state transition probability measures. state-action space separable, possible define metric set
transition measures convergence metric equivalent weak convergence.
See, example, Prokhorov metric (Billingsley, 1999). Therefore possible restate
assumption four succint manner sometimes easier verify. However,
extra work required derive properties needed convergence proof.
author chosen state assumption four manner simplifies proof.

Acknowledgements
author would like thank Peter Kiessler technical advice, three anonymous referees
many helpful comments, Tanya Carden Kris Kelly proofreading.

References
Albus, J. S. (1975). new approach manipulator control: cerebellar model articulation controller (CMAC). Journal Dynamic Systems, Measurement, Control,
97, 220227.
Baird, L. C., & Klopf, A. H. (1993). Reinforcement learning high-dimensional, continuous actions. Tech. rep. WLTR-93-1147, Wright-Patterson Air Force Base Ohio:
Wright Laboratory.
Bertsekas, D. P. (1995). counterexample temporal differences learning. Neural Computation, 7 (2), 270279.
Billingsley, P. (1999). Convergence probability measures (Second edition). Wiley Series
Probability Statistics: Probability Statistics. John Wiley & Sons Inc., New
York. Wiley-Interscience Publication.
729

fiCarden

Devroye, L., & Gyorfi, L. (1985). Nonparametric density estimation: L1 view. Wiley
series probability mathematical statistics. Wiley.
Ernst, D., Geurts, P., & Wehenkel, L. (2005). Tree-based batch mode reinforcement learning.
Journal Machine Learning Research, 6, 503556.
Fairbank, M., & Alonso, E. (2012). divergence reinforcement learning algorithms
value-iteration function approximation. Proceedings IEEE International
Joint Conference Neural Networks.
Gaskett, C., Wettergreen, D., & Zelinsky, A. (1999). Q-learning continuous state
action spaces. Australian Joint Conference Artificial Intelligence, pp. 417428.
Springer-Verlag.
Gordon, G. J. (1996). Chattering SARSA(lambda) - CMU learning lab internal report.
Tech. rep., Carnegie Mellon University.
Hansen, B. E. (2008). Uniform convergence rates kernel estimation dependent data.
Econometric Theory.
Hardle, W. (2004). Nonparametric Semiparametric Models. Springer Series Statistics.
Springer Berlin Heidelberg.
Jaakkola, T., Jordan, M. I., & Singh, S. P. (1994). Convergence stochastic iterative
dynamic programming algorithms. Neural Computation, 6, 11851201.
Jacod, J., & Protter, P. (2003). Probability Essentials. Universitext (1979). Springer.
Lazaric, A., Restelli, M., & Bonarini, A. (2007). Reinforcement learning continuous action
spaces sequential Monte Carlo methods. Adv. Neural Information Proc.
Systems.
Millan, J. R., Posenato, D., & Dedieu, E. (2002). Continuous-action Q-learning. Machine
Learning.
Moore, A. (1991). Efficient Memory-based Learning Robot Control.
Robotics Institute, Carnegie Mellon University.

Ph.D. thesis,

Nadaraya, E. (1964). estimating regression. Theory Probability Applications,
9, 141142.
Ormoneit, D., & Sen, S. (1999). Kernel-based reinforcement learning. Machine Learning.
Puterman, M. L. (1994). Markov Decision Processes: Discrete Stochastic Dynamic Programming. Wiley-Interscience.
Ross, S. (1992). Applied Probability Models Optimization Applications. Dover Books
Mathematics. Dover Publications.
Rummery, G. A., & Niranjan, M. (1994). On-line Q-learning using connectionist systems.
Tech. rep., Cambridge University Engineering Department.
Santamara, J. C., Sutton, R. S., & Ram, A. (1996). Experiments reinforcement
learning problems continuous state action spaces. Adaptive Behavor.
Silverman, B. W. (1986). Density estimation statistics data analysis. Chapman
Hall, London.
730

fiA Continuous Action Q-learning Variant

Simonoff, J. (1996). Smoothing methods statistics. Springer, New York.
Sutton, R. S. (1988). Learning predict methods temporal differences. Machine
Learning, 3, 944.
Sutton, R. S. (1996). Generalization reinforcement learning: Successful examples using
sparse coarse coding. Advances Neural Information Processing Systems 8, pp.
10381044. MIT Press.
Szepesvari, C., & Smart, W. D. (2004). Interpolation-based Q-learning. Proceedings
International Conference Machine Learning, pp. 791798. ACM Press.
Taylor, G., & Parr, R. (2009). Kernelized Value Function Approximation Reinforcement
Learning. Proceedings 26th International Conference Machine Learning,
pp. 10171024.
ten Hagen, S. H. (2001). Continuous State Space Q-Learning Control Nonlinear
Systems. Ph.D. thesis, University Amsterdam.
Tesauro, G. (1995). Temporal difference learning TD-Gammon. Commun. ACM, 38 (3),
5868.
Tsitsiklis, J. N. (1994). Asynchronous stochastic approximation Q-learning. Machine
Learning, pp. 185202.
Tsitsiklis, J. N., & Van Roy, B. (1996). Feature-based methods large scale dynamic
programming. Machine Learning, 22 (13), 5994.
Watkins, C. (1989). Learning Delayed Rewards. Ph.D. thesis, University Cambridge.
Watkins, C. J. C. H., & Dayan, P. (1992). Technical note: Q-learning. Machine Learning,
8, 279292.
Watson, G. S. (1964). Smooth regression analysis. Sankhya: Indian Journal Statistics, 26, 359372.
Xu, X., Hu, D., & Lu, X. (2007). Kernel-based least squares policy iteration reinforcement learning. IEEE Transactions Neural Networks, 18 (4), 973992.

731

fiJournal Artificial Intelligence Research 49 (2014) 635-668

Submitted 01/14; published 04/14

Algorithms Argumentation Semantics: Labeling Attacks
Generalization Labeling Arguments
Samer Nofal

AMER .N OFAL @ GJU . EDU . JO

Dept. Computer Science, German-Jordanian University
P.O. Box 35247, Amman 11180, Jordan

Katie Atkinson
Paul E. Dunne

K.M.ATKINSON @ LIVERPOOL . AC . UK
P.E.D UNNE @ LIVERPOOL . AC . UK

Dept. Computer Science, University Liverpool
Ashton Street, Liverpool L69 3BX, United Kingdom

Abstract
Dung argumentation framework (AF) pair (A, R): set abstract arguments
R binary relation, so-called attack relation, capturing conflicting arguments. Labeling based algorithms enumerating extensions (i.e. sets acceptable arguments)
set arguments (i.e. elements A) subject labeling.
paper present implemented algorithms listing extensions labeling attacks (i.e. elements R) along arguments. Specifically, algorithms concerned enumerating
extensions AF number argumentation semantics: preferred, stable, complete,
semi stable, stage, ideal grounded. algorithms impact, particular, enumerating
extensions AF-extended models allow attacks attacks. demonstrate impact,
instantiate algorithms example models: namely argumentation frameworks
recursive attacks (AFRA), thereby end unified algorithms enumerate extensions
AF / AFRA.

1. Introduction
Computational argumentation, covering theory applications, attracted major attention
AI research community, notably last twenty years (e.g. Bench-Capon & Dunne, 2007;
Besnard & Hunter, 2008; Rahwan & Simari, 2009; Modgil, Toni, Bex, Bratko, Chesnevar, Dvorak,
Falappa, Fan, Gaggl, Garca, Gonzalez, Gordon, Leite, Mozina, Reed, Simari, Szeider, Torroni, &
Woltran, 2013). Dungs abstract argumentation frameworks (AFs) (Dung, 1995) widely studied
model AF described pair (A, R): set abstract arguments R AA
binary relation, so-called attack relation, represent conflicting arguments. central notion
AFs argumentation semantics: set criteria characterise acceptable arguments;
define criteria rigorously section 2. different reasons number argumentation
semantics proposed literature. Explaining reasons detail scope
paper; however, see work Baroni, Caminada, Giacomin (2011a) excellent
introduction argumentation semantics.
various argumentation semantics, one might find multiple distinct extensions (defined
section 2). Labeling based algorithms (e.g. Dimopoulos, Magirou, & Papadimitriou, 1997; Doutre
& Mengin, 2001; Modgil & Caminada, 2009) listing extensions developed
arguments (i.e. elements A) target labeled. paper illustrate
enumerate extensions several argumentation semantics labeling attacks (i.e. elements R)
c
2014
AI Access Foundation. rights reserved.

fiN OFAL , ATKINSON , & UNNE

along arguments, instead labeling arguments solely. particularly interest listing
extensions AF-extended formalisms allow attacks attacks (e.g. Modgil, 2009b; Gabbay,
2009; Baroni, Cerutti, Giacomin, & Guida, 2011b). show throughout paper, term
labeling based algorithms argumentation semantics distinguished common term
labeling based semantics, although concepts involve labeling mapping. former term
(i.e. labeling based algorithms) refers course actions extension enumeration
process classifies arguments: might extension excluded
respective extension. classification essential order construct concrete
extensions given AF. later term (i.e. labeling based semantics) refers approach
describing (i.e. constructing) extensions using labeling mapping.
section 2 provide necessary background materials. section 3 review explicit algorithms selection dominant argumentation semantics: preferred, stable, complete, semi
stable, stage, ideal grounded. algorithms list extensions labeling arguments only.
section 4 develop, respective argumentation semantics, definite algorithms
enumerating extensions argumentation framework recursive attacks (AFRA): AFextended model allows attacks attacks (Baroni et al., 2011b). algorithms construct
extensions labeling attacks together arguments. Since AF special case AFRA (Baroni et al., 2011b), developed algorithms AFRA also list extensions AF. section 5
report experiments concerning practical efficiency algorithms. Section 6 concludes
paper summary review related work.

2. Preliminaries
start definition Dungs argumentation frameworks (Dung, 1995).
Definition 1. (Dungs Argumentation Frameworks)
argumentation framework (or AF) pair (A, R) set arguments R
binary relation.
refer (x, y) R x attacks (or attacked x). denote {x} respectively
subset containing arguments attack (resp. attacked by) argument x,
extending notation natural way sets arguments, A,
{x}+


S+

=
=

{ : x s.t. {x} }
{ : x s.t. {x}+ }

Given subset A,
x acceptable w.r.t. every (y, x) R, z
(z, y) R.
conflict free (x, y) S, (x, y)
/ R.
admissible conflict free every x acceptable w.r.t. S.
preferred extension maximal (w.r.t. ) admissible set.
stable extension conflict free S+ = \ S.
636

fiA LGORITHMS RGUMENTATION EMANTICS

Figure 1: argumentation framework.
complete extension admissible set x acceptable
w.r.t. S, x S.
stage extension conflict free S+ maximal (w.r.t. ).
semi stable extension admissible S+ maximal (w.r.t. ).
ideal extension maximal (w.r.t. ) admissible set contained every preferred extension.
grounded extension least fixed point F(T ) = {x |
x acceptable w.r.t. }.
Preferred, complete, stable grounded semantics introduced work Dung (1995),
whereas stage semantics, ideal semantics semi stable semantics presented papers
Verheij (1996), Dung, Mancarella, Toni (2007) Caminada, Carnielli, Dunne (2012)
respectively. give example, consider framework depicted figure 1 nodes represent
arguments edges correspond attacks (i.e. elements R). example {b, d}
preferred, grounded, stable, ideal, complete, semi stable stage extension. Note
intend example show differences semantics.
Offering explicit means weaken attacks, formalisms Modgil (2009b), Gabbay
(2009) Baroni et al. (2011b) extend AFs attacks (i.e. elements R) subject
attacks themselves. present extension enumeration algorithms instance formalisms: namely argumentation frameworks recursive attacks (AFRA) introduced Baroni et
al. (2011b).
Definition 2. argumentation framework recursive attacks (AFRA) pair (A, R)
set arguments R set pairs (x, y) x (y R).
Let x = (y, z) R say source x, denoted src(x) = y, z target
x, denoted trg(x) = z.
Let x R R say directly de f eats x x = trg(y).
Let x, R say indirectly de f eats x src(x) = trg(y).
Let x R R, say de f eats x directly indirectly defeats x.
Given subset R,
conflict free exist x, s.t. x defeats y.
element x R acceptable w.r.t. R : defeats x,
z z defeats y.
admissible conflict free x S, x acceptable w.r.t. S.
637

fiN OFAL , ATKINSON , & UNNE

Figure 2: argumentation framework recursive attacks.
preferred extension maximal (w.r.t. ) admissible set.
/ S,
stable extension conflict free x R : x
exists de f eats x.
complete extension admissible every element R,
acceptable w.r.t. S, belongs S.
stage (resp. semi stable) extension conflict free (resp. admissible)
{x | s.t. defeats x} maximal (w.r.t. ).
ideal extension maximal (w.r.t. ) admissible set contained every preferred extension.
grounded extension least fixed point F(T ) = {x R |
x acceptable w.r.t. }.
Referring figure 2, {b, d, h, e} grounded, stable, preferred, ideal, complete, stage
semi stable extension.
consider issue expressing AFRA AF. Let H = (A, R) AFRA,
corresponding AF H = (A , R ) defined = R R = {(x, y) | x,
R x de f eats y}. example, corresponding AF AFRA depicted figure 2
described = {b, c, d, e, f , g, h} R = {(e, g), ( f , e), (g, e), (g, d), (h, c), (h, f ), (h, g)}.

3. Algorithms Selection Argumentation Semantics
section review explicit algorithms list, number argumentation semantics,
extensions AF labeling arguments solely. Particularly, subsection 3.1 recall
algorithm Nofal, Atkinson Dunne (2014) preferred semantics. section 3.2 present
new implementation algorithm Dimopoulos et al. (1997) stable semantics.
modify algorithm Nofal, Atkinson Dunne (2014) produce specific algorithms
complete, stage, semi stable ideal semantics subsections 3.3, 3.4, 3.5 3.6 respectively.
subsection 3.7 present implementation building grounded extension.
3.1 Enumerating Preferred Extensions AF
Algorithm 1 lists preferred extensions AF. Algorithm 1 taken work Nofal,
Atkinson Dunne (2014) shown algorithm likely efficient
algorithms Doutre Mengin (2001), Modgil Caminada (2009). recall
638

fiA LGORITHMS RGUMENTATION EMANTICS

algorithm 1 implemented algorithms present paper seen extension
algorithm. algorithm backtracking procedure traverses abstract binary search
tree. core notion algorithm related use five labels: IN, OUT, MUST OUT,
BLANK UNDEC. Informally, label identifies arguments might preferred
extension. label identifies argument attacked argument. BLANK
label unprocessed argument whose final label decided yet. MUST label
identifies arguments attack arguments. UNDEC label designates arguments might
included preferred extension might defended argument.
enumerate preferred extensions algorithm 1 starts BLANK default label
arguments. initial state represents root node search tree. algorithm forks
left (resp. right) child (i.e. state) picking argument, BLANK, labeled (resp.
UNDEC). Every time argument, say x, labeled neighbour arguments labels
might change every {x}+ label becomes every z {x} \{x}+
label z becomes MUST OUT. process, i.e. forking new children, continues
every x label x BLANK. point, algorithm captures preferred extension
every x label x belongs {IN,OUT,UNDEC} {x | label x
IN} subset previously found preferred extension (if exists). algorithm
backtracks try find preferred extensions. important kinds algorithms
exploit properties whereby might bypass expanding child search tree, thus considerable
time might saved. Algorithm 1 uses two pruning properties:
1. Algorithm 1 (lines 12-17) skips labeling argument (i.e. skips expanding left child)
z {y} label z w {z}
BLANK label. words, z labeled later
w {z} label w OUT, MUST UNDEC. Thus, efficient skip
trying include argument attacked z preferred extension.
2. Algorithm 1 (lines 19-22) skips labeling argument UNDEC (i.e. skips expanding right
child) every z {y} current label z MUST OUT.
admissible set, say S, constructed UNDEC {y}
admissible also. Recall preferred extensions maximal admissible sets, hence
need label UNDEC.
Another fundamental issue take account selection BLANK arguments
labeled IN. point behind adopting selection strategy try achieve preferred extension efficiently. critical problem constructing one extension.
Therefore, algorithm 1 (line 8) applies following selection options:
1. Algorithm 1 tries select first BLANK argument, say y, attacked
attacked OUT/MUST arguments only. justification selection related
second pruning property used algorithm. Note earlier pick
labeled IN, bigger part search tree avoided. Recall lead
expanding right child according second pruning property.
2. Otherwise algorithm picks BLANK argument, say y, |{z : z {y}+
label z OUT}| maximal. intuition maximising number
arguments minimise number BLANK/MUST arguments. Thus,
639

fiN OFAL , ATKINSON , & UNNE

Figure 3: Enumerating preferred extensions AF using algorithm 1.
new generated state (i.e. child), due selecting y, much closer state
preferred extension captured. Recall preferred extension achieved
x label x IN, UNDEC.
Algorithm 1, like algorithms paper, self-contained self-explanatory. Figure 3,
however, illustrates algorithm 1 running AF.
3.2 Enumerating Stable Extensions AF
Algorithm 2 lists stable extensions. Algorithm 2 seen new implementation
algorithm Dimopoulos et al. (1997). Algorithm 2 differs algorithm 1 two ways:
640

fiA LGORITHMS RGUMENTATION EMANTICS

Algorithm 1: Enumerating preferred extensions AF (A, R).
1
2
3
4
5

6
7
8

9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26

Lab : {IN, OUT, MUST OUT,UNDEC, BLANK}; Lab 0;
/
foreach x Lab Lab {(x, BLANK)};
E pre f erred 2A ; E pre f erred 0;
/
call find-preferred-extensions(Lab);
report E pre f erred set preferred extensions;
procedure find-preferred-extensions(Lab) begin
: Lab(y) = BLANK
select Lab(y) = BLANK z {y} Lab(z) {OUT, MUST },
otherwise select Lab(y) = BLANK s.t. z : Lab(z) = BLANK, |{x : x
{y}+ Lab(x) = }| |{x : x {z}+ Lab(x) = }|;
Lab Lab;
Lab (y) IN;
foreach z {y}+ Lab (z) ;
foreach z {y}
Lab (z) {UNDEC, BLANK}
Lab (z) MUST ;
w {z} : Lab (w) = BLANK
Lab(y) UNDEC;
goto line 7;
call find-preferred-extensions(Lab );
z {y} : Lab(z) {BLANK,UNDEC}
Lab(y) UNDEC;
else
Lab Lab ;
x : Lab(x) = MUST
{x | Lab(x) = IN};
E pre f erred : E pre f erred E pre f erred {S};
end procedure

641

fiN OFAL , ATKINSON , & UNNE

1. Algorithm 2 uses four labels: IN, OUT, BLANK MUST OUT. usage labels
outlined algorithm 1 one distinction: role UNDEC label used algorithm 1 overloaded MUST label. Meaning, algorithm 2 MUST
label used also labeling argument, say x, trying build stable extension without x.
argument, say x, outside candidate stable extension attacked
argument extension, hence x labeled MUST (not UNDEC
case algorithm 1.)
2. algorithm 1, P = {w | label w IN} preferred extension
x A, label x BLANK MUST P subset previously
found preferred extension. algorithm 2 (line 24) set {w | label w IN} stable
extension every x A, label x BLANK MUST OUT.
Algorithm 2: Enumerating stable extensions AF (A, R).
1
2
3
4
5

6
7
8

9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26

Lab : {IN, OUT, MUST OUT, BLANK}; Lab 0;
/
foreach x Lab Lab {(x, BLANK)};
Estable 2A ; Estable 0;
/
call find-stable-extensions(Lab);
report Estable set stable extensions;
procedure find-stable-extensions(Lab) begin
: Lab(y) = BLANK
select Lab(y) = BLANK z {y} Lab(z) {OUT, MUST },
otherwise select Lab(y) = BLANK s.t. z : Lab(z) = BLANK, |{x : x
{y}+ Lab(x) = }| |{x : x {z}+ Lab(x) = }|;
Lab Lab;
Lab (y) IN;
foreach z {y}+ Lab (z) ;
foreach z {y}
Lab (z) = BLANK
Lab (z) MUST ;
w {z} Lab (w) = BLANK
Lab(y) MUST ;
goto line 7;
call find-stable-extensions(Lab );
z {y} : Lab(z) = BLANK
Lab(y) MUST ;
else
Lab Lab ;
x : Lab(x) = MUST
{x | Lab(x) = IN};
Estable Estable {S};
end procedure

642

fiA LGORITHMS RGUMENTATION EMANTICS

3.3 Enumerating Complete Extensions AF
Algorithm 3 lists complete extensions. Algorithm 3 modification algorithm 1 enumerates preferred extensions. algorithm 1, P = {w | label w IN} preferred extension
x A, label x BLANK MUST P subset
previously found preferred extension. algorithm 3 (line 10) set {w | label w IN}
complete extension
C1. every x A, label x MUST
C2. z UNDEC (or BLANK) label every {z} label
OUT.
Recall complete extension admissible set every x acceptable respect
S, x belongs S. Thus, condition C1 ensures admissibility C2 guarantees completeness.
3.4 Enumerating Stage Extensions AF
Algorithm 4 lists stage extensions. Algorithm 4 alteration algorithm 1 enumerates
preferred extensions. Algorithm 4 uses four labels: IN, OUT, UNDEC BLANK. usage
labels outlined algorithm 1 one distinction: role MUST label used
algorithm 1 overloaded UNDEC label. Meaning, algorithm 4 UNDEC label
used also identifying arguments attack argument. argument attacks
argument stage extension necessarily attacked argument extension.
Algorithm 4 constructs conflict free subsets A. particular, algorithm 4 (line 26) keeps
record conflict free set {w | label w IN} x A, label
x BLANK. constructing conflict free subsets, algorithm 4 decides conflict
free subset, say S, stage extension S+ maximal, see lines 5-9. might
expected, argument selection pruning strategies used admissibility based semantics
applicable stage semantics, based conflict free sets. Therefore, pruning
strategy skip labeling argument, say y, UNDEC z {y}+ {y} ,
label z UNDEC. based following property: conflict free set, say S,
captured UNDEC {y} also conflict free, hence,
need label UNDEC since {y} S; recall algorithm 4 labels argument UNDEC
trying build stage extension excluding argument. selecting next BLANK argument
labeled IN, consider rule:
R1. select BLANK argument s.t. z {y}+ {y} , label z UNDEC.
R2. otherwise select BLANK argument |{x : x {y}+ {y} label x
BLANK}| maximal.
Note correlation R1 applied pruning strategy: earlier label
argument selected R1 IN, bigger part search tree bypassed.
Regarding benefit R2, recall aim argument selection accelerate achieving
goal state, conflict free subset S+ maximal x
BLANK label. Indeed, R2 minimises number BLANK arguments maximising number
OUT/UNDEC arguments.
643

fiN OFAL , ATKINSON , & UNNE

Algorithm 3: Enumerating complete extensions AF (A, R).
1
2
3
4
5

6
7
8
9
10
11
12

13
14
15
16
17
18
19
20
21
22
23
24
25
26
27

Lab : {IN, OUT, MUST OUT,UNDEC, BLANK}; Lab 0;
/
foreach x Lab Lab {(x, BLANK)};
Ecomplete 2A ; Ecomplete 0;
/
call find-complete-extensions(Lab);
report Ecomplete set complete extensions;
procedure find-complete-extensions(Lab) begin
: Lab(y) = MUST
x : Lab(x) {UNDEC, BLANK} z {x} Lab(z) =
{w | Lab(w) = IN};
Ecomplete Ecomplete {S};
: Lab(y) = BLANK
select Lab(y) = BLANK z {y} Lab(z) {OUT, MUST },
otherwise select Lab(y) = BLANK s.t. z : Lab(z) = BLANK, |{x : x
{y}+ Lab(x) = }| |{x : x {z}+ Lab(x) = }|;
Lab Lab;
Lab (y) IN;
foreach z {y}+ Lab (z) ;
foreach z {y}
Lab (z) {UNDEC, BLANK}
Lab (z) MUST ;
w {z} : Lab (w) = BLANK
Lab(y) UNDEC;
goto line 11;
call find-complete-extensions(Lab );
z {y} : Lab(z) {BLANK,UNDEC}
Lab(y) UNDEC;
else
Lab Lab ;
end procedure

644

fiA LGORITHMS RGUMENTATION EMANTICS

Algorithm 4: Enumerating stage extensions AF (A, R).
1
2
3
4
5
6
7
8
9
10
11

12
13
14

15
16
17
18
19
20
21
22
23
24
25
26
27

Lab : {IN, OUT,UNDEC, BLANK}; Lab 0;
/
foreach x Lab Lab {(x, BLANK)};
Estage {Lab1 | Lab1 : {IN, OUT,UNDEC, BLANK}}; Estage 0;
/
call find-conflict-free-sets(Lab);
foreach Lab1 Estage
foreach Lab2 Estage
{x : Lab1 (x) {IN, }} ( {z : Lab2 (z) {IN, }}
Estage Estage \ {Lab1 };
continue next iteration line 5;
foreach Lab1 Estage
report {x : Lab1 (x) = IN} stage extension ;
procedure find-conflict-free-sets(Lab) begin
: Lab(y) = BLANK
select Lab(y) = BLANK z {y}+ {y} Lab(z) {OUT,UNDEC},
otherwise select Lab(y) = BLANK z : Lab(z) = BLANK, |{x : x
{y}+ {y} Lab(x) = BLANK}| |{x : x {z}+ {z} Lab(x) = BLANK}|;
Lab Lab;
Lab (y) IN;
foreach z {y}+ Lab (z) ;
foreach z {y}
Lab (z) {BLANK}
Lab (z) UNDEC;
call find-conflict-free-sets(Lab );
z {y}+ {y} Lab(z) = BLANK
Lab(y) UNDEC;
else
Lab Lab ;
Estage Estage {Lab};
end procedure

645

fiN OFAL , ATKINSON , & UNNE

3.5 Enumerating Semi Stable Extensions AF
Algorithm 5 enumerates semi stable extensions. Again, algorithm 5 reproduction algorithm 1. Actually, algorithm 5 firstly builds admissible sets. Then, algorithm decides
admissible set, say S, semi stable extension S+ maximal; see lines 6-10.

Algorithm 5: Enumerating semi stable extensions AF (A, R).
1
2
3
4
5
6
7
8
9
10
11
12

13
14
15

16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32

Lab : {IN, OUT, MUST OUT,UNDEC, BLANK}; Lab 0;
/
foreach x Lab Lab {(x, BLANK)};
Esemistable {Lab1 | Lab1 : {IN, OUT, MUST OUT,UNDEC, BLANK}};
Esemistable 0;
/
call find-admissible-sets(Lab);
foreach Lab1 Esemistable
foreach Lab2 Esemistable
{x : Lab1 (x) {IN, }} ( {z : Lab2 (z) {IN, }}
Esemistable Esemistable \ {Lab1 };
continue next iteration line 6;
foreach Lab1 Esemistable
report {x : Lab1 (x) = IN} semi stable extension ;
procedure find-admissible-sets(Lab) begin
: Lab(y) = BLANK
select Lab(y) = BLANK z {y} Lab(z) {OUT, MUST },
otherwise select Lab(y) = BLANK s.t. z : Lab(z) = BLANK, |{x : x
{y}+ Lab(x) = }| |{x : x {z}+ Lab(x) = }|;
Lab Lab;
Lab (y) IN;
foreach z {y}+ Lab (z) ;
foreach z {y}
Lab (z) {UNDEC, BLANK}
Lab (z) MUST ;
w {z} : Lab (w) = BLANK
Lab(y) UNDEC;
goto line 14;
call find-admissible-sets(Lab );
z {y} : Lab(z) {BLANK,UNDEC}
Lab(y) UNDEC;
else
Lab Lab ;
x : Lab(x) = MUST
Esemistable Esemistable {Lab};
end procedure

646

fiA LGORITHMS RGUMENTATION EMANTICS

3.6 Constructing Ideal Extension AF
Algorithm 6 builds ideal extension. algorithm modification algorithm 1. Algorithm 6
(line 28) records {w | label w IN} admissible set x A, label
x BLANK MUST OUT. However, algorithm also constructs (line 27) = {x |
exists admissible set x + }. building set admissible sets
constructed, algorithm 6 considers admissible set ideal extension
= 0;
/ see lines 6-8. Recall ideal extension maximal (w.r.t. ) admissible
set contained every preferred extension. Satisfying condition = 0/ implies
arguments attacked admissible set (see definition above),
means contained every preferred extension. ensure maximal, algorithm 6 collects
admissible sets descending order: larger sets smaller ones. consequence, algorithm
checks collected admissible sets condition = 0/ starting larger admissible sets
smaller ones.
3.7 Constructing Grounded Extension AF
Algorithm 7 viewed another implementation algorithm described Modgil
Caminada (2009) building grounded extension.

4. Labeling Attacks Generalization Labeling Arguments
section illustrate enumerate extensions, number argumentation semantics, labeling attacks together arguments instead labeling arguments solely. end,
develop algorithms listing extensions AFRA (Baroni et al., 2011b) preferred,
stable, complete, stage, semi stable, ideal grounded semantics subsections 4.1, 4.2, 4.3, 4.4,
4.5, 4.6 4.7 respectively. algorithms basically generalization algorithms
presented previous section, hence algorithms list extensions AF / AFRA.
4.1 Enumerating Preferred Extensions AF / AFRA
Algorithm 8 enumerates preferred extensions AFRA. Algorithm 8 generalization
algorithm 1. idea based using five labels: IN, OUT, MUST OUT, BLANK UNDEC.
BLANK label initial label arguments attacks. BLANK attack R labeled
indicate might preferred extension. argument x labeled
R label trg(y) = x. attack z R labeled
R label trg(y) {z, src(z)}. BLANK argument x labeled IN,
implying x might preferred extension, R label
src(y) = x z R : trg(z) = x label z OUT. attack labeled UNDEC
try find preferred extension excluding y. attack z label BLANK/UNDEC labeled
MUST R label trg(z) {y, src(y)}. Every
time attack labeled labels attacks arguments might change accordingly, see
lines 10-20 algorithm 8. selection rule, line 8 represents strategy algorithm
selects next attack, BLANK, labeled IN. rule grounds parallel
selection rule applied algorithm 1 enumerating preferred extensions AF. Likewise,
algorithm 8 applies two pruning tactics:
647

fiN OFAL , ATKINSON , & UNNE

Algorithm 6: Constructing ideal extension AF (A, R).
1
2
3
4
5
6
7
8

9
10
11

12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29

Lab : {IN, OUT, MUST OUT,UNDEC, BLANK}; Lab 0;
/
foreach x Lab Lab {(x, BLANK)};
Eideal : Z 2A ; Eideal 0;
/
0;
/
call find-admissible-sets(Lab);
foreach = 1 .. |Eideal |
Eideal (i) = 0/
report Eideal (i) ideal extension; exit;
procedure find-admissible-sets(Lab) begin
: Lab(y) = BLANK
select Lab(y) = BLANK z {y} Lab(z) {OUT, MUST },
otherwise select Lab(y) = BLANK s.t. z : Lab(z) = BLANK, |{x : x
{y}+ Lab(x) = }| |{x : x {z}+ Lab(x) = }|;
Lab Lab;
Lab (y) IN;
foreach z {y}+ Lab (z) ;
foreach z {y}
Lab (z) {UNDEC, BLANK}
Lab (z) MUST ;
w {z} : Lab (w) = BLANK
Lab(y) UNDEC;
goto line 10;
call find-admissible-sets(Lab );
z {y} : Lab(z) {BLANK,UNDEC}
Lab(y) UNDEC;
else
Lab Lab ;
w : Lab(w) = MUST
{x | Lab(x) = };
Eideal Eideal {(|Eideal | + 1, {z | Lab(z) = IN})};
end procedure

Algorithm 7: Constructing grounded extension AF (A, R).
1
2
3
4
5
6
7

Lab : {IN, OUT,UNDEC}; Lab 0;
/
foreach w Lab Lab {(w,UNDEC)};
x Lab(x) = UNDEC : {x} Lab(y) =
foreach x Lab(x) = UNDEC : {x} Lab(y) =
Lab(x) IN;
foreach z {x}+ Lab(z) ;
report grounded extension {w | Lab(w) = IN};

648

fiA LGORITHMS RGUMENTATION EMANTICS

Figure 4: algorithm 8 works AFRA.
1. Algorithm 8 (lines 17- 20) skips labeling attack (i.e. skips expanding left child)

z : trg(z) {y, src(y)} label f z
w label BLANK : trg(w) {z, src(z)}.
2. Algorithm 8 (lines 22- 25) skips labeling attack UNDEC (i.e. skips expanding right
child) z R : trg(z) {y, src(y)}, label z MUST OUT.
get general idea algorithm 8 see figure 4 shows algorithm works
AFRA depicted figure 2.
4.2 Enumerating Stable Extensions AF / AFRA
Algorithm 9 enumerates stable extensions. Actually, algorithm 9 modification algorithm 8
lists preferred extensions. However two differences:
1. Algorithm 9 uses four labels: IN, OUT, BLANK MUST OUT. usage labels
outlined algorithm 8 one difference: role UNDEC label used algorithm 8 overloaded MUST label. is, algorithm 9 MUST
label used also labeling attack, say x, trying build stable extension without x.
attack, say x, outside candidate stable extension defeated
attack extension, hence x labeled MUST OUT.
2. algorithm 8 find preferred extension, say P, x R, x
BLANK MUST P subset previously found preferred extension.
algorithm 9 encounter stable extension x R, x BLANK
MUST OUT.
649

fiN OFAL , ATKINSON , & UNNE

Algorithm 8: Enumerating preferred extensions AFRA (A, R).
1
2
3
4
5

6
7
8

9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27

28
29
30
31

Lab : (A R) {IN, OUT, MUST OUT,UNDEC, BLANK}; Lab 0;
/
foreach x R Lab Lab {(x, BLANK)};
E pre f erred 2AR ; E pre f erred 0;
/
call find-preferred-extensions(Lab);
report E pre f erred set preferred extensions;
procedure find-preferred-extensions(Lab) begin
R : Lab(y) = BLANK
select R Lab(y) = BLANK
z R : trg(z) {y, src(y)} Lab(z) {OUT, MUST }, otherwise select R
Lab(y) = BLANK z R : Lab(z) = BLANK
|{x : src(x) = trg(y) Lab(x) = }| |{x : src(x) = trg(z) Lab(x) = }|;
Lab Lab;
Lab (y) IN;
Lab (src(y)) IN;
Lab (trg(y)) ;
trg(y)
foreach z R : src(z) = trg(y)
Lab (z) ;
foreach z R : Lab (z) {BLANK,UNDEC} trg(z) {y, src(y)}
Lab (z) MUST ;
w R : Lab (w) = BLANK trg(w) {z, src(z)}
Lab(y) UNDEC;
goto line 7;
call find-preferred-extensions(Lab );
z R : Lab(z) {BLANK,UNDEC} trg(z) {y, src(y)}
Lab(y) UNDEC;
else
Lab Lab ;
w R : Lab(w) = MUST
foreach x Lab(x) = BLANK s.t. z R : trg(z) = x (Lab(z) = )
Lab(x) IN;
{x R | Lab(x) = IN};
E pre f erred (S )
E pre f erred E pre f erred {S};
end procedure

650

fiA LGORITHMS RGUMENTATION EMANTICS

Algorithm 9: Enumerating stable extensions AFRA (A, R).
1
2
3
4
5

6
7
8

9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27

28
29

Lab : (A R) {IN, OUT, MUST OUT, BLANK}; Lab 0;
/
foreach x R Lab Lab {(x, BLANK)};
E stable 2AR ; E stable 0;
/
call find-stable-extensions(Lab);
report E stable set stable extensions;
procedure find-stable-extensions(Lab) begin
R : Lab(y) = BLANK
select R Lab(y) = BLANK
z R : trg(z) {y, src(y)} Lab(z) {OUT, MUST }, otherwise select R
Lab(y) = BLANK z R : Lab(z) = BLANK
|{x : src(x) = trg(y) Lab(x) = }| |{x : src(x) = trg(z) Lab(x) = }|;
Lab Lab;
Lab (y) IN;
Lab (src(y)) IN;
Lab (trg(y)) ;
trg(y)
foreach z R : src(z) = trg(y)
Lab (z) ;
foreach z R : Lab (z) = BLANK trg(z) {y, src(y)}
Lab (z) MUST ;
w R : Lab (w) = BLANK trg(w) {z, src(z)}
Lab(y) MUST ;
goto line 7;
call find-stable-extensions(Lab );
z R : Lab(z) = BLANK trg(z) {y, src(y)}
Lab(y) MUST ;
else
Lab Lab ;
w R : Lab(w) = MUST
foreach x Lab(x) = BLANK s.t. z R : trg(z) = x (Lab(z) = )
Lab(x) IN;
E stable E stable {{x R | Lab(x) = IN}};
end procedure

651

fiN OFAL , ATKINSON , & UNNE

4.3 Enumerating Complete Extensions AF / AFRA
Algorithm 10 enumerates complete extensions. Again, algorithm 10 modification algorithm 8 lists preferred extensions. algorithm 8 achieve preferred extension, say P,
x R, label x BLANK MUST P subset
previously found preferred extension. However, algorithm 10 (line 7) encounter complete
extension
C1. z R MUST label
C2. exist w R
(a) label w UNDEC BLANK
(b) R : trg(y) {w, src(w)}, label OUT.
Thus, C1 ensures admissibility C2 guarantees completeness.
4.4 Enumerating Stage Extensions AF / AFRA
Algorithm 11 lists stage extensions. algorithm rewrite algorithm 8. However, algorithm 11 uses four labels: IN, OUT, BLANK UNDEC. usage labels outlined
algorithm 8 one difference: role MUST label used algorithm 8
overloaded UNDEC label. is, algorithm 11 UNDEC label used also identifying attacks attack argument/attack. attack defeats argument/attack
stage extension necessarily defeated attack extension.
Algorithm 11 (lines 14-29) finds set conflict free subsets R rather constructing
admissible subsets done algorithm 8. algorithm 8 set {w R | label w IN}
reported admissible set x R, label x BLANK
MUST OUT. algorithm 11 set {w R | label w IN} recorded conflict free
set (i.e. stage extension candidate) x R, label x BLANK,
see lines 14 & 31. building set conflict free subsets, algorithm 11 decides conflict
free subset R stage extension {x | : defeats x} maximal, see
lines 6-10. stated earlier, argument selection pruning strategies used semantics
based admissible sets applicable stage semantics, based conflict free
sets. Therefore, pruning strategy (line 29 algorithm 11) skip labeling attack UNDEC
(i.e. skip expanding right child)
z R : trg(z) {y, src(y)} trg(y) {z, src(z)},
label f z UNDEC.
based property conflict free set, say S, formed UNDEC
{y} also conflict free, hence, need label UNDEC since {y} S.
selecting next BLANK attack labeled IN, apply following rule (see line 15):
R1. select BLANK attack s.t. z R : trg(z) {y, src(y)} trg(y) {z, src(z)},
label z UNDEC.
R2. otherwise select BLANK attack |{x : label x BLANK (src(x) =
trg(y) trg(x) {y, src(y)})}| maximal.
652

fiA LGORITHMS RGUMENTATION EMANTICS

Algorithm 10: Enumerating complete extensions AFRA (A, R).
1
2
3
4
5

6
7

8

9
10
11

12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29

Lab : (A R) {IN, OUT, MUST OUT,UNDEC, BLANK}; Lab 0;
/
foreach x R Lab Lab {(x, BLANK)};
E complete 2AR ; E complete 0;
/
call find-complete-extensions(Lab);
report E complete set complete extensions;
procedure find-complete-extensions(Lab) begin
v R Lab(v) = MUST w R : Lab(w) {UNDEC, BLANK}
R : trg(y) {w, src(w)} Lab(y) =
foreach x Lab(x) = BLANK s.t. z R : trg(z) = x (Lab(z) = )
Lab(x) IN;
E complete E complete {{x R | Lab(x) = IN)}};
R : Lab(y) = BLANK
select R Lab(y) = BLANK
z R : trg(z) {y, src(y)} Lab(z) {OUT, MUST }, otherwise select R
Lab(y) = BLANK z R : Lab(z) = BLANK
|{x : src(x) = trg(y) Lab(x) = }| |{x : src(x) = trg(z) Lab(x) = }|;
Lab Lab;
Lab (y) IN;
Lab (src(y)) IN;
Lab (trg(y)) ;
trg(y)
foreach z R : src(z) = trg(y)
Lab (z) ;
foreach z R : Lab (z) {BLANK,UNDEC} trg(z) {y, src(y)}
Lab (z) MUST ;
w R : Lab (w) = BLANK trg(w) {z, src(z)}
Lab(y) UNDEC;
goto line 10;
call find-complete-extensions(Lab );
z R : Lab(z) {BLANK,UNDEC} trg(z) {y, src(y)}
Lab(y) UNDEC;
else
Lab Lab ;
end procedure

653

fiN OFAL , ATKINSON , & UNNE

aim R1 maximise gain applied pruning strategy. Meaning, earlier
label selected argument R1 IN, greater saving terms part
search tree pruned. Regarding R2, note goal state (i.e. conflict free set) reached
x R, label x BLANK. Thus, R2 tries maximise
number OUT/UNDEC attacks/arguments, implies minimising number BLANK
attacks/arguments.
4.5 Enumerating Semi Stable Extensions AF / AFRA
Algorithm 12 lists semi stable extensions. Algorithm 12 variation algorithm 8
basically constructs admissible sets. Algorithm 12 (line 31) records set {w | label w IN}
admissible set (that semi stable extension candidate) x R,
label x BLANK MUST OUT. constructing set admissible sets, algorithm 12
decides admissible set semi stable extension {x | : defeats x}
maximal, see lines 6-10.
4.6 Constructing Ideal Extension AF / AFRA
Algorithm 13 builds ideal extension. particular, algorithm 13 finds admissible sets (lines 1028) way algorithm 8 does. However, enumerating admissible sets algorithm 13
(line 31) also builds set
= {x R | admissible set trg(y) {x, src(x)}}
building set admissible sets constructed, algorithm 13 decides
admissible set ideal extension = 0,
/ see lines 6-8. Recall
ideal extension maximal (w.r.t. ) admissible set contained every preferred
extension. Satisfying condition = 0/ implies arguments/attacks defeated
admissible set (see definition above), means contained every preferred
extension. ensure maximal, algorithm 13 collects admissible sets descending order:
larger sets smaller ones. consequence, algorithm checks collected admissible sets
condition = 0/ starting larger admissible sets smaller ones.
4.7 Constructing Grounded Extension AF / AFRA
Algorithm 14 builds grounded extension. Algorithm 14 actually generalization algorithm 7.

5. Practical Efficiency
algorithms presented paper implemented C++ Fedora (release 13) based
machine 4 processors (Intel core i5-750 2.67GHz) 16GB memory. evaluation criterion, considered average elapsed time measured seconds; elapsed time obtained
using time command Linux. present experimental results two purposes. First,
explore efficiency algorithms section 3. second purpose, confirm
generalized algorithms section 4, enumerate extensions labeling attacks together
arguments, perform efficiently algorithms section 3, enumerate extensions
labeling arguments alone.
654

fiA LGORITHMS RGUMENTATION EMANTICS

Algorithm 11: Enumerating stage extensions AFRA (A, R).
1
2
3
4
5
6
7
8
9
10
11
12

13
14
15

16
17
18
19
20
21
22
23
24
25
26
27
28
29
30

31
32

Lab : (A R) {IN, OUT,UNDEC, BLANK}; Lab 0;
/
foreach x R Lab Lab {(x, BLANK)};
E stage {Lab1 | Lab1 : (A R) {IN, OUT,UNDEC, BLANK}};
E stage 0;
/
call find-conflict-free-sets(Lab);
foreach Lab1 E stage
foreach Lab2 E stage
{x : Lab1 (x) {IN, }} ( {z : Lab2 (z) {IN, }}
E stage E stage \ {Lab1 };
continue next iteration line 6;
foreach Lab1 E stage
report {x : Lab1 (x) = IN} stage extension ;
procedure find-conflict-free-sets(Lab) begin
R : Lab(y) = BLANK
select R Lab(y) = BLANK s.t.
z R : trg(z) {y, src(y)} trg(y) {z, src(z)} (Lab(z) {OUT,UNDEC}),
otherwise select R Lab(y) = BLANK s.t.
z R : Lab(z) = BLANK |{x : Lab(x) = BLANK (src(x) = trg(y) trg(x)
{y, src(y))}}| |{x : Lab(x) = BLANK (src(x) = trg(z) trg(x) {z, src(z))}}|;
Lab Lab;
Lab (y) IN;
Lab (src(y)) IN;
Lab (trg(y)) ;
trg(y)
foreach z R : src(z) = trg(y)
Lab (z) ;
foreach z R : Lab (z) = BLANK trg(z) {y, src(y)}
Lab (z) UNDEC;
call find-conflict-free-sets(Lab );
z R : Lab(z) = BLANK (trg(z) {y, src(y)} trg(y) {z, src(z)})
Lab(y) UNDEC;
else
Lab Lab ;
foreach x Lab(x) = BLANK s.t. z R : trg(z) = x (Lab(z) = )
Lab(x) IN;
E stage E stage {Lab};
end procedure

655

fiN OFAL , ATKINSON , & UNNE

Algorithm 12: Enumerating semi stable extensions AFRA (A, R).
1
2
3
4
5
6
7
8
9
10
11
12

13
14
15

16
17
18
19
20
21
22
23
24
25
26
27
28
29
30

31
32

Lab : (A R) {IN, OUT, MUST OUT,UNDEC, BLANK}; Lab 0;
/
foreach x R Lab Lab {(x, BLANK)};
E semistable {Lab1 | Lab1 : (A R) {IN, OUT, MUST OUT,UNDEC, BLANK}};
E semistable 0;
/
call find-admissible-sets(Lab);
foreach Lab1 E semistable
foreach Lab2 E semistable
{x : Lab1 (x) {IN, }} ( {z : Lab2 (z) {IN, }}
E semistable E semistable \ {Lab1 };
continue next iteration line 6;
foreach Lab1 E semistable
report {x : Lab1 (x) = IN} semi stable extension ;
procedure find-admissible-sets(Lab) begin
R : Lab(y) = BLANK
select R Lab(y) = BLANK s.t.
z R : trg(z) {y, src(y)} Lab(z) {OUT, MUST }, otherwise select R
Lab(y) = BLANK s.t. z R : Lab(z) = BLANK |{x : src(x) = trg(y) Lab(x) =
}| |{x : src(x) = trg(z) Lab(x) = }|;
Lab Lab; Lab (y) IN; Lab (src(y)) IN;
Lab (trg(y)) ;
trg(y)
foreach z R : src(z) = trg(y) Lab (z) ;
foreach z R : Lab(z) {BLANK,UNDEC} trg(z) {y, src(y)}
Lab (z) MUST ;
w R : Lab (w) = BLANK trg(w) {z, src(z)}
Lab(y) UNDEC; goto line 14;
call find-admissible-sets(Lab );
z R : Lab(z) {BLANK,UNDEC} trg(z) {y, src(y)}
Lab(y) UNDEC;
else
Lab Lab ;
R : Lab(y) = MUST
foreach x Lab(x) = BLANK s.t. z R : trg(z) = x (Lab(z) = )
Lab(x) IN;
E semistable E semistable {Lab};
end procedure

656

fiA LGORITHMS RGUMENTATION EMANTICS

Algorithm 13: Constructing ideal extension AFRA (A, R).
1
2
3
4
5
6
7
8

9
10
11

12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30

31
32
33

Lab : (A R) {IN, OUT, MUST OUT,UNDEC, BLANK}; Lab 0;
/
foreach x R Lab Lab {(x, BLANK)};
E ideal : Z 2AR ; E ideal 0;
/
0;
/
call find-admissible-sets(Lab);
foreach : 1 |E ideal |
/ S)
x E ideal (i) (x
report E ideal (i) ideal extension; exit;
procedure find-admissible-sets(Lab) begin
R : Lab(y) = BLANK
select R Lab(y) = BLANK s.t.
z R : trg(z) {y, src(y)} Lab(z) {OUT, MUST }, otherwise select R
Lab(y) = BLANK z R : Lab(z) = BLANK
|{x : src(x) = trg(y) Lab(x) = }| |{x : src(x) = trg(z) Lab(x) = }|;
Lab Lab;
Lab (y) IN;
Lab (src(y)) IN;
Lab (trg(y)) ;
trg(y)
foreach z R : src(z) = trg(y)
Lab (z) ;
foreach z R : Lab (z) {BLANK,UNDEC} trg(z) {y, src(y)}
Lab (z) MUST ;
w R : Lab (w) = BLANK trg(w) {z, src(z)}
Lab(y) UNDEC;
goto line 10;
call find-admissible-sets(Lab );
z R : Lab(z) {BLANK,UNDEC} trg(z) {y, src(y)}
Lab(y) UNDEC;
else
Lab Lab ;
w R : Lab(w) = MUST
foreach x Lab(x) = BLANK s.t. z R : trg(z) = x (Lab(z) = )
Lab(x) IN;
{x R | Lab(x) = };
E ideal E ideal {(|E ideal | + 1, {z | Lab(z) = IN})};
end procedure

657

fiN OFAL , ATKINSON , & UNNE

Algorithm 14: Constructing grounded extension AFRA (A, R).
1
2
3
4

5
6
7
8
9
10
11

12

Lab : (A R) {IN, OUT,UNDEC}; Lab 0;
/
foreach w R Lab Lab {(w,UNDEC)};
x R Lab(x) = UNDEC s.t. R : trg(y) {x, src(x)} (Lab(y) = )
foreach x R Lab(x) = UNDEC s.t. R : trg(y) {x, src(x)} (Lab(y) = )

Lab(x) IN;
Lab(src(x)) IN;
Lab(trg(x)) ;
trg(x)
foreach z R : trg(x) = src(z)
Lab(z) ;
foreach x Lab(x) = UNDEC s.t. z R : trg(z) = x (Lab(z) = )
Lab(x) IN;
report grounded extension {w R | Lab(w) = IN};

compared algorithms dynPARTIX, implemented system based
dynamic programming algorithm Dvorak, Pichler, Woltran (2012b). Given AF, dynPARTIX basically computes tree decomposition AF extensions enumerated based
tree decomposition. algorithm used dynPARTIX fixed-parameter tractable
time complexity depends tree width given AF linear size
AF (Dvorak et al., 2012b). Since dynPARTIX computes extensions preferred, stable
complete semantics, figures 5, 6 & 7 depict respectively efficiency algorithms 1, 2 & 3 versus dynPARTIX. summary, figures show algorithms likely efficient
dynPARTIX. running experiments represented figures, set time
limit 120 seconds every execution. 1000 runs, dynPARTIX encountered 316 timeouts
enumerating preferred extensions 827 timeouts enumerating complete extensions.
timeouts plotted within figures 120 seconds. explains steady behavior dynPARTIX noted, particularly, figure 7. see performance algorithms 1-7
contrast behavior algorithms 8-14 present figures 8-14 respectively. profiling algorithms 1-7, reported running times including time needed get corresponding AF
AFRA. Note process (i.e. expressing AFRA AF) runs polynomial time:
worst quadratic time. figures 8-14 plot running times 1000 instances AFRA randomly
generated |A| = 5 R = R1 R2 s.t. R1 R2 R1 . instances |R|
grows 0 100 probability, used setting attacks random generation, goes {0.01,0.02,0.03,...,1}. Note instances |A| = 5 considered
quite small. example, randomly generated AFRA |A| = 5 |R| = 49 corresponding AF |A| = 54 |R| = 190. Again, emphasize aim experiments
compare performance algorithms 1-7 performance algorithms 8-14.
mean experiments check scalability algorithms, although important issue
examined. Said that, crucial evaluation consider large frameworks
higher level recursive attacks. Back results experiments, case involved
exceeding 120-second time limit occurred enumerating semi stable extensions. Referring
658

fiA LGORITHMS RGUMENTATION EMANTICS

Figure 5: Enumerating preferred extensions 1000 instances AF |A|=40, p
{0.01, 0.02, 0.03, ..., 1} tracked average elapsed time 10 instances generated
randomly probability p (i.e. probability x attacks x, A).

figure 12 note algorithm 5 (resp. 12) encountered 68 (resp. 66) timeouts. bottom
line conclusion figures is: enumerating extensions AFRA labeling attacks together
arguments seems efficient enumerating extensions corresponding AF via
labeling arguments alone.

6. Discussion Conclusion
started paper refining implemented algorithms1 enumerating extensions Dungs
argumentation frameworks (AFs) number argumentation semantics: preferred, stable,
complete, stage, semi stable, ideal grounded. Algorithms semantics, except stage
grounded semantics, share similar core structure: basically build admissible sets
order construct extensions. case stage semantics, algorithm actually constructs
conflict free sets purpose listing stage extensions, hence, algorithm applies
slightly different approach expanding search tree elaborated earlier. Concerning
grounded semantics, presented algorithm builds grounded extension polynomial time.
Furthermore, explored practical efficiency algorithms profiling performance
running wide spectrum AF instances: sparse instances dense ones. essence
algorithms construct extensions using total function maps arguments solely
set labels reflecting different states illustrated paper. Then, generalized
algorithms using total mapping labels attacks together arguments. implemented
generalized algorithms enumerate extensions AFRA, AF-extended model
1. C++ implementations found http://sourceforge.net/projects/argtools/files/

659

fiN OFAL , ATKINSON , & UNNE

Figure 6: Enumerating stable extensions 1000 instances AF |A|=60, p
{0.01, 0.02, 0.03, ..., 1} tracked average elapsed time 10 instances generated
randomly probability p.

Figure 7: Enumerating complete extensions 1000 instances AF |A|=30, p
{0.01, 0.02, 0.03, ..., 1} tracked average elapsed time 10 instances generated
randomly probability p.

660

fiA LGORITHMS RGUMENTATION EMANTICS

Figure 8: Enumerating preferred extensions 1000 instances AFRA, p
{0.01, 0.02, 0.03, ..., 1} tracked average elapsed time 10 instances generated
randomly probability p.

Figure 9: Enumerating stable extensions 1000 instances AFRA, p
{0.01, 0.02, 0.03, ..., 1} tracked average elapsed time 10 instances generated
randomly probability p.

661

fiN OFAL , ATKINSON , & UNNE

Figure 10: Enumerating complete extensions 1000 instances AFRA, p
{0.01, 0.02, 0.03, ..., 1} tracked average elapsed time 10 instances generated
randomly probability p.

Figure 11: Listing stage extensions 1000 instances AFRA, p
{0.01, 0.02, 0.03, ..., 1} tracked average elapsed time 10 instances generated randomly probability p.

662

fiA LGORITHMS RGUMENTATION EMANTICS

Figure 12: Listing semi stable extensions 1000 instances AFRA, p
{0.01, 0.02, 0.03, ..., 1} tracked average elapsed time 10 instances generated
randomly probability p.

Figure 13: Constructing ideal extension 1000 instances AFRA, p
{0.01, 0.02, 0.03, ..., 1} tracked average elapsed time 10 instances generated
randomly probability p.

663

fiN OFAL , ATKINSON , & UNNE

Figure 14: Constructing grounded extension 1000 instances AFRA, p
{0.01, 0.02, 0.03, ..., 1} tracked average elapsed time 10 instances generated
randomly probability p.

allows attacks attacks. words, offered unified approach enumerating extensions
AF/AFRA, given fact AF special case AFRA (Baroni et al., 2011b).
hand, showed labeling attacks alongside arguments potentially used
basis enumerating extensions related formalisms allow attacks attacks (e.g. Modgil,
2009b; Gabbay, 2009); nonetheless confirmed research. fact, extensions
instance formalisms listed working corresponding AF. However,
demonstrated enumerate extensions AFRA applying labeling directly native
form without compromising running time efficiency. omitted soundness/completeness
proof presented algorithms since follows immediately proof algorithm
Nofal, Atkinson Dunne (2014) preferred semantics. algorithms presented paper
handle frameworks self-attacking arguments perfectly. However, algorithms
easily modified initial label self-attacking argument UNDEC instead
BLANK. instance, change necessary made algorithm 1 modify line 2
follows
foreach x
(x, x) R Lab Lab {(x,UNDEC)};
else Lab Lab {(x, BLANK)};
general, UNDEC label (instead BLANK label) default label
argument/attack extension, like self-attacking arguments outgoing
attacks simply arguments present conflict themselves. Recall BLANK
arguments/attacks tried label.
future work, plan study additional options argument selection. Also, intend
evaluate strategies pruning search space.
664

fiA LGORITHMS RGUMENTATION EMANTICS

discuss related work. existing algorithms Doutre Mengin (2001) Modgil
Caminada (2009) listing preferred extensions also re-engineered towards enumerating
extensions argumentation semantics. example, papers Caminada (2007, 2010)
presented algorithms enumerating semi stable, respectively stage, extensions building
algorithm Modgil Caminada (2009). However, algorithms present paper based
algorithm Nofal, Atkinson Dunne (2014) enumerating preferred extensions,
likely efficient existing algorithms (Nofal et al., 2014). give
examples related work labeling-based semantics. theory Caminada Gabbay (2009)
defined argumentation semantics using total mapping : {IN, OUT,UNDEC} that,
broadly speaking, labeled arguments correspond extension, say S,
labeled arguments correspond S+ UNDEC labeled arguments correspond \ (S S+ ).
hard see connection algorithms theory Caminada Gabbay
(2009). example, algorithm 1 capture preferred extension arguments
mapped one labels: IN, UNDEC. Listing works present labelingbased semantics, paper Modgil (2009a) defined labeling-based semantics extended
AF Modgil (2009b) Villata, Boella, van der Torre (2011) described argumentation
semantics terms attacks arguments. Also, work Gabbay (2009) set argumentation
semantics AF-extended model Barringer, Gabbay, Woods (2005) among
features allow attacks attacks. topic extension computation general, study
Li, Oren, Norman (2012) examined approximation versus exact computations, whereas
experiments Baumann, Brewka, Wong (2012), Liao, Lei, Dai (2013) evaluated effect
splitting AF computation preferred extensions. work Dondio (2013) studied,
grounded semantics, acceptance status argument varies subgraphs
given AF. Computational complexity argumentation semantics widely studied (see e.g.
Dimopoulos, Nebel, & Toni, 2000; Dunne, 2007, 2009; Ordyniak & Szeider, 2011). Another line
research concerns encoding computational problems AFs formalisms solving
using respective solver (e.g. Besnard & Doutre, 2004; Nieves, Cortes, & Osorio, 2008;
Egly, Gaggl, & Woltran, 2010; Amgoud & Devred, 2011; Dvorak, Jarvisalo, Wallner, & Woltran,
2012a; Cerutti, Dunne, Giacomin, & Vallati, 2013; Charwat, Dvorak, Gaggl, Wallner, & Woltran,
2013), approaches called reduction based methods. stress focus paper
algorithmic based implementations argumentation semantics.

Acknowledgments
thank anonymous reviewers comments improved presentation work.

References
Amgoud, L., & Devred, C. (2011). Argumentation frameworks constraint satisfaction problems.
Benferhat, S., & Grant, J. (Eds.), SUM, Vol. 6929 Lecture Notes Computer Science,
pp. 110122. Springer.
Baroni, P., Caminada, M., & Giacomin, M. (2011a). introduction argumentation semantics.
Knowledge Engineering Review, 26(4), 365410.
665

fiN OFAL , ATKINSON , & UNNE

Baroni, P., Cerutti, F., Giacomin, M., & Guida, G. (2011b). Argumentation framework recursive attacks. International Journal Approximate Reasoning, 52(1), 1937.
Barringer, H., Gabbay, D., & Woods, J. (2005). Temporal dynamics support attack networks:
argumentation zoology. Hutter, D., & Stephan, W. (Eds.), Mechanizing Mathematical Reasoning, Vol. 2605 Lecture Notes Computer Science, pp. 5998. Springer.
Baumann, R., Brewka, G., & Wong, R. (2012). Splitting argumentation frameworks: empirical
evaluation. Modgil, S., Oren, N., & Toni, F. (Eds.), First International Workshop Theory
Applications Formal Argumentation 2011, Vol. 7132 Lecture Notes Computer
Science, pp. 1731. Springer.
Bench-Capon, T., & Dunne, P. (2007). Argumentation artificial intelligence. Artificial Intelligence, 171, 619641.
Besnard, P., & Doutre, S. (2004). Checking acceptability set arguments. Delgrande,
J., & Schaub, T. (Eds.), NMR, pp. 5964.
Besnard, P., & Hunter, A. (2008). Elements Argumentation. MIT press.
Caminada, M. (2007). algorithm computing semi-stable semantics. Mellouli, K. (Ed.),
ECSQARU, Vol. 4724 Lecture Notes Computer Science, pp. 222234. Springer.
Caminada, M. (2010). algorithm stage semantics. Baroni, P., Cerutti, F., Giacomin, M., &
Simari, G. (Eds.), COMMA, Vol. 216 Frontiers Artificial Intelligence Applications,
pp. 147158. IOS Press.
Caminada, M., Carnielli, W., & Dunne, P. (2012). Semi-stable semantics. J. Log. Comput., 22(5),
12071254.
Caminada, M., & Gabbay, D. (2009). logical account formal argumentation. Studia Logica,
93(2-3), 109145.
Cerutti, F., Dunne, P., Giacomin, M., & Vallati, M. (2013). sat-based approach computing
extensions abstract argumentation. TAFA, Second International Workshop Theory
Applications Formal Argumentation.
Charwat, G., Dvorak, W., Gaggl, S., Wallner, J., & Woltran, S. (2013). Implementing abstract argumentation - survey. Tech. rep. DBAI-TR-2013-82, Technische Universitat Wien, Database
Artificial Intelligence Group.
Dimopoulos, Y., Magirou, V., & Papadimitriou, C. (1997). kernels, defaults even graphs.
Annals Mathematics Artificial Intelligence, 20, 112.
Dimopoulos, Y., Nebel, B., & Toni, F. (2000). Finding admissible preferred arguments
hard. Cohn, A., Giunchiglia, F., & Selman, B. (Eds.), KR, pp. 5361. Morgan
Kaufmann.
Dondio, P. (2013). Computing grounded semantics subgraphs argumentation
framework: empirical evaluation. CLIMA, XIV Workshop Computational Logic
Multi-Agent Systems.
Doutre, S., & Mengin, J. (2001). Preferred extensions argumentation frameworks: Query answering computation. Gore, R., Leitsch, A., & Nipkow, T. (Eds.), IJCAR, Vol. 2083
Lecture Notes Computer Science, pp. 272288. Springer.
666

fiA LGORITHMS RGUMENTATION EMANTICS

Dung, P. (1995). acceptability arguments fundamental role non monotonic
reasoning, logic programming n-person games. Artificial Intelligence, 77(2), 321357.
Dung, P., Mancarella, P., & Toni, F. (2007). Computing ideal skeptical argumentation. Artificial
Intelligence, 171(10-15), 642674.
Dunne, P. (2007). Computational properties argument systems satisfying graph-theoretic constraints. Artificial Intelligence, 171, 701729.
Dunne, P. (2009). computational complexity ideal semantics. Artificial Intelligence, 173(18),
1559 1591.
Dvorak, W., Jarvisalo, M., Wallner, J. P., & Woltran, S. (2012a). Complexity-sensitive decision
procedures abstract argumentation. Brewka, G., Eiter, T., & McIlraith, S. (Eds.), KR.
AAAI Press.
Dvorak, W., Pichler, R., & Woltran, S. (2012b). Towards fixed-parameter tractable algorithms
abstract argumentation. Artificial Intelligence, 186, 137.
Egly, U., Gaggl, S., & Woltran, S. (2010). Answer-set programming encodings argumentation
frameworks. Argument Computation, 1(2), 147177.
Gabbay, D. (2009). Semantics higher level attacks extended argumentation frames part 1:
Overview. Studia Logica, 93(2-3), 357381.
Li, H., Oren, N., & Norman, T. (2012). Probabilistic argumentation frameworks. Modgil, S.,
Oren, N., & Toni, F. (Eds.), First International Workshop Theory Applications
Formal Argumentation 2011, Vol. 7132 Lecture Notes Computer Science, pp. 116.
Springer.
Liao, B., Lei, L., & Dai, J. (2013). Computing preferred labellings exploiting sccs
sceptically rejected arguments. TAFA, Second International Workshop Theory Applications Formal Argumentation.
Modgil, S. (2009a). Labellings games extended argumentation frameworks. Boutilier, C.
(Ed.), IJCAI, pp. 873878.
Modgil, S. (2009b). Reasoning preferences argumentation frameworks. Artificial Intelligence, 173, 901934.
Modgil, S., & Caminada, M. (2009). Proof theories algorithms abstract argumentation
frameworks. Rahwan, I., & Simari, G. (Eds.), Argumentation Artificial Intelligence, pp.
105129. Springer.
Modgil, S., Toni, F., Bex, F., Bratko, I., Chesnevar, C., Dvorak, W., Falappa, M., Fan, X., Gaggl, S.,
Garca, A., Gonzalez, M., Gordon, T., Leite, J., Mozina, M., Reed, C., Simari, G., Szeider, S.,
Torroni, P., & Woltran, S. (2013). added value argumentation. Ossowski, S. (Ed.),
Agreement Technologies, Vol. 8 Law, Governance Technology Series, pp. 357403.
Springer Netherlands.
Nieves, J., Cortes, U., & Osorio, M. (2008). Preferred extensions stable models. Theory
Practice Logic Programming, 8(4), 527543.
Nofal, S., Atkinson, K., & Dunne, P. (2014). Algorithms decision problems argument systems
preferred semantics. Artif. Intell., 207, 2351.
667

fiN OFAL , ATKINSON , & UNNE

Ordyniak, S., & Szeider, S. (2011). Augmenting tractable fragments abstract argumentation.
Walsh, T. (Ed.), Proceedings 22nd International Joint Conference Artificial Intelligence IJCAI 2011, pp. 10331038.
Rahwan, I., & Simari, G. (2009). Argumentation Artificial Intelligence. Springer.
Verheij, B. (1996). Two approaches dialectical argumentation: admissible sets argumentation
stages. Proceedings Eighth Dutch Conference AI, pp. 357368.
Villata, S., Boella, G., & van der Torre, L. (2011). Attack semantics abstract argumentation.
Walsh, T. (Ed.), Proceedings 22nd International Joint Conference Artificial Intelligence IJCAI 2011, pp. 406413.

668

fiJournal Artificial Intelligence Research 49 (2014) 733-773

Submitted 07/13; published 04/14

Comparative Evaluation Link-Based Approaches
Candidate Ranking Link-to-Wikipedia Systems
Norberto Fernandez Garca
Jesus Arias Fisteus
Luis Sanchez Fernandez

berto@it.uc3m.es
jaf@it.uc3m.es
luiss@it.uc3m.es

Telematics Engineering Department
Universidad Carlos III de Madrid
Avda. Universidad, 30, E-28911
Leganes, Madrid, Spain.

Abstract
recent years, task automatically linking pieces text (anchors) mentioned
document Wikipedia articles represent meaning anchors received
extensive research attention. Typically, link-to-Wikipedia systems try find set
Wikipedia articles candidates represent meaning anchor and, later,
rank candidates select appropriate one. ranking process
systems rely context information obtained document anchor
mentioned and/or Wikipedia. paper center attention use
Wikipedia links context information. particular, offer review several candidate
ranking approaches state-of-the-art rely Wikipedia link information.
addition, provide comparative empirical evaluation different approaches
five different corpora: TAC 2010 corpus four corpora built actual Wikipedia
articles news items.

1. Introduction
Due important volume information contained Wikipedia, also open
nature content, on-line encyclopedia adopted recent times useful
resource computational linguistics tasks like name translation (Lin, Snover, & Ji, 2011),
named entity recognition (Nothman, Murphy, & Curran, 2009), etc.
development automatic link discovery systems (Erbs, Zesch, & Gurevych, 2011)
another area research Wikipedia important impact. task
discovering links Wikipedia articles addressed, slight variants
different names, different communities. instance, Hachey et al. (2013) distinguish
named entity linking, addressed context Knowledge Base Population
(KBP) track (National Institute Standards Technology, 2014b) Text Analysis
Conference (TAC) (National Institute Standards Technology, 2014a), wikification, addressed Link-the-Wiki track Initiative Evaluation XML
retrieval (INEX) (INEX, 2014). cases goal automatically find Wikipedia
articles represent meaning certain piece text document define
link Wikipedia using anchor piece text. However, differences
aspects like anchors considered (only named entities named entity linking, named
c
2014
AI Access Foundation. rights reserved.

fiFernandez Garca, Arias Fisteus & Sanchez Fernandez

entities common terms wikification) whether Wikipedia considered
complete source knowledge (wikification) (named entity linking).
Henceforth, simply refer link-to-Wikipedia general task discovering
links Wikipedia, includes wikification named entity linking particular
cases.
According Erbs et al. (2011), task discovering links divided series
steps. include: identifying anchors linked, searching candidate link
targets anchor, selecting best candidate results searching
step. common link-to-Wikipedia approaches address steps independently
sequentially (though also examples steps independent,
like Cucerzan, 2012 Sil, 2013).
Due important role (Ji, Grishman, & Dang, 2011), context paper
center attention last aforementioned processes. referred
disambiguation Hachey et al. (2011). However, selecting best link target
usually involves creating ranking candidates choose one highest
rank, authors refer process target ranking (Erbs et al., 2011) candidate
ranking (Guo, Tang, Che, Liu, & Li, 2011; Ploch, Hennig, de Luca, & Albayrak, 2011; Ji
et al., 2011). article, also adopt term candidate ranking.
order select best Wikipedia article link given anchor, candidate
ranking process relies context information provided set features.
features extracted document anchor placed (the context document)
and/or different Wikipedia articles considered candidates become link target.
According Erbs et al. (2011) features classified three groups: (1)
extracted text document/articles, (2) extracted titles;
(3) based existing links. latter subject study paper.
Traditional research area computational linguistics shown effectiveness using WordNet (Miller, 1995) graph links tasks like computing semantic relatedness (Budanitsky & Hirst, 2006) performing word sense disambiguation (Navigli &
Lapata, 2010). case link discovery, Erbs et al. (2011) indicate that, enough
training information available, link-based approaches outperform text-based ones.
Taking account, surprising find many link-to-Wikipedia approaches
use features candidate ranking based information links. examples work Milne Witten (2008b), Pilz (2010), Radford et al. (2010), Fernandez
et al. (2010), Guo et al. (2011), Ploch et al. (2011) Ratinov et al. (2011).
Given ample variety link-based features candidate ranking described
state art, comparative analysis different alternatives useful decide
approach (or approaches) considered designing link-to-Wikipedia
systems. However, using results published state art difficult
compare across systems ranking performance different link-based approaches.
First, link-to-Wikipedia systems usually evaluated end-to-end setup, is,
evaluation involves ranking stage, also candidate searching
candidate selection processes. Thus, impact performance different system
components mixed. Second, general, link-to-Wikipedia systems rely
link-based features rank candidates, also combine features
types. Thus, effects different contributions ranking process also mixed.
734

fiEvaluation Link-Based Approaches Candidate Ranking Link-to-Wikipedia

Taking account, main goals paper twofold: (1) offer overview
link-based approaches candidate ranking link-to-Wikipedia systems; and, (2) perform
empirical evaluation compare approaches. order address aforementioned difficulties, we: (1) focus analysis candidate ranking stage, isolating
much possible candidate search/selection stages; (2) consider linkbased features, combined based text titles. similar comparison is,
knowledge authors, available time writing.
rest paper organized follows: section 2 presents definitions
formal description problem addressed. Section 3 outlines different linkbased approaches compared. Section 4 describes setup empirical evaluation
carried out, well results. Section 5 offers overview related work.
Finally, section 6 closes paper concluding remarks future lines work.

2. Definitions Problem Formalization
section introduce definitions nomenclature helpful
rest article.
textual document mentions anchor going linked Wikipedia
named context document represented dc .
set Wikipedia articles denoted W , whereas particular Wikipedia
articles represented wi , = 1, . . . , |W |. case consider set W
Wikipedia pages belong Main namespace (Wikipedia, 2014b)
represent non-ambiguous concepts (that is, disambiguation pages filtered out).
denote C(dc , a) set Wikipedia articles {c1 , c2 , . . . , c|C(dc ,a)| }, ck W
selected candidates fit meaning dc .
link l defined duple l = (src(l), dest(l)), src(l) represents
document source link dest(l) document pointed
link, is, destination.
denote F (d) set documents destination forward links
d, is: F (d) = {f | l, src(l) = dest(l) = f }. Similarly, represent
B(d) set documents source backward links d, is: B(d) =
{b | l, src(l) = b dest(l) = d}. paper, use information provided
Wikipedia links. Thus, consider Wikipedia articles members F (d)
B(d). Note also F (d) B(d) sets and, thus, consider
duplicates. However, might happen document several links pointing
destination. order represent information, denote number links
source document destination document n(s, d) .
Taking account aforementioned definitions, candidate ranking process
addressed context paper may formalized follows:
Definition 1. Given context document dc , mentions anchor a, set
candidate Wikipedia articles C(dc , a), candidate ranking task consists ordering
members C(dc , a) according rating. rating measures suitability
candidate represent meaning anchor. candidate ci C(dc , a)
highest rank, fits best meaning anchor context document
dc , selected define new link (dc , ci ).
735

fiFernandez Garca, Arias Fisteus & Sanchez Fernandez

aspects stressed definition:
introduce restriction nature anchors linked.
particular, may represent either named entities (persons, organizations, etc.)
common terms.
previous related work (Cucerzan, 2007; Mihalcea & Csomai, 2007; Han,
Sun, & Zhao, 2011), address paper scenario adequate
Wikipedia article linked exist.

3. Overview Approaches
describe different candidate ranking approaches evaluated
paper. common source context information links.
particular, links considered available context document, dc , well
constitute link structure Wikipedia, including links to/from
candidate Wikipedia articles, ci C(dc , a).
However, approaches considered use link information
manner. particular, classify two families, name (1) bag-oflinks approaches, (2) graph approaches. main difference
second group links used build graph structure, later analyzed
select best candidate. case approaches first group.
3.1 Bag-of-Links Approaches
section present set approaches characteristic common:
rely building graph link context information rank candidates.
Nevertheless, approaches family also differences way address
task. particular, distinguish least three alternative groups:
approaches rely similarity metrics compute similarity score
context document candidate, later select candidate
highest score (the similar one).
Another alternative rely popularity metrics, simply try compute
popularity score candidate. popular candidate selected.
approaches rely information provided context document.
ranking process also modeled statistical problem. Statistical methods
used select likely candidate, given context information.
accordance classification, following sections describe group approaches.
3.1.1 Similarity Metrics
first similarity metrics consider relatedness, computed basis
Wikipedia Link-based Measure (Milne & Witten, 2008a). relatedness used feature
736

fiEvaluation Link-Based Approaches Candidate Ranking Link-to-Wikipedia

link-to-Wikipedia approaches Milne Witten (2008b), Han Zhao
(2009), Kulkarni et al. (2009), Pilz (2010), Fahrni et al. (2011), Han et al. (2011) Ratinov
et al. (2011).
Basically, relatedness allows compute similarity two Wikipedia documents wi , wj links common. original definition Milne
Witten (2008a), computed as:
RB (wi , wj ) =

log(max{|B(wi )|, |B(wj )|}) log(|B(wi ) B(wj )|)
log(|W |) log(min{|B(wi )|, |B(wj )|})

(1)

According Milne Witten (2008a), relatedness metrics based Normalized Google Distance (NGD), defined Cilibrasi Vitanyi (2007). NGD based
intuition terms similar related meaning co-occur frequently
documents. Thus, given pair terms, Google search engine used obtain
pages mention terms. Pages mention indicate relatedness,
pages one suggest unrelatedness. indicated Milne Witten
(2008a), relatedness metrics, defined equation 1, shares inspiring principle, uses Wikipedia links instead Google search results account mentions.
distance metrics, relatedness values expected smaller similar
Wikipedia articles are. However, easy transform distance metrics
similarity metrics following approach Gracia Mena (2008), requires
computation of:
simRB (wi , wj ) = e2RB (wi ,wj )

(2)

second similarity metrics Wikipedia articles considered based
computing Pointwise Mutual Information (PMI) sets links articles
compared. instance, used Ratinov et al. (2011) link-to-Wikipedia
task. defined work as:
PB (wi , wj ) =

|B(wi ) B(wj )|/|W |
(|B(wi )|/|W |)(|B(wj )|/|W |)

(3)

Note definitions equations (1) (3) rely backlinks (B(x)) computation. However, indicated Ratinov et al. (2011), relatedness PMI
also computed using outgoing links document. paper explore
compare alternatives denote relatedness similarity PMI computed
forward links simRF PF respectively.
Taking aforementioned definitions account, Wikipedia article {c1 , . . . , ck }
C(dc , a) compute relatedness PMI Wikipedia articles linked
dc , is, fj F (dc ). Combining different values obtain final
relatedness PMI ci dc . According Ratinov et al. (2011) several ways
combine values may followed, taking average maximum.
explore different possibilities paper. particular, relatedness:
737

fiFernandez Garca, Arias Fisteus & Sanchez Fernandez

RelFA (ci , dc ) =

RelB
(ci , dc ) =

1
|F (dc )|
1
|F (dc )|

RelFM (ci , dc )

=


RelB
(ci , dc ) =

X

simRF (ci , fj )

(4)

X

simRB (ci , fj )

(5)

max

simRF (ci , fj )

(6)

max

simRB (ci , fj )

(7)

fj F (dc )

fj F (dc )
fj F (dc )
fj F (dc )

Whereas Pointwise Mutual Information computed as:
P IFA (ci , dc ) =

1
|F (dc )|

1

P IB
(ci , dc ) =
|F (dc )|
P IFM (ci , dc )

=


P IB
(ci , dc ) =

X

PF (ci , fj )

(8)

X

PB (ci , fj )

(9)

max

PF (ci , fj )

(10)

max

PB (ci , fj )

(11)

fj F (dc )

fj F (dc )
fj F (dc )
fj F (dc )

Another well-known approach compute document similarity within natural language processing information retrieval communities cosine similarity. Basically,
vector built represent context document candidate article. Then, similarity context document candidate computed cosine
angle respective vectors. Several approaches state art (Bunescu
& Pasca, 2006; Fader, Soderland, & Etzioni, 2009; Nguyen & Cao, 2010; Fahrni et al.,
2011; Ploch et al., 2011; Ratinov et al., 2011) use cosine similarity. However,
differences features used build vector representations
documents.
case, requirement considering solely links context information.
Thus, document represented using links mentioned
document. similar approach model documents compute cosine similarity
used, instance, Fahrni et al. (2011) Ploch et al. (2011).
particular, document represented vector vd R|W | . component
vd,i , = 1, . . . , |W | vector vd computed traditional term frequency
(TF), inverse document frequency (IDF) product (Manning, Raghavan, & Schtze, 2008)
follows:
vd,i = F (d, wi ) IDF (wi ) = P

|W |
n(d, wi )
log
|B(wi )|
wj F (d) n(d, wj )

(12)

Note F (d) contain certain Wikipedia article wi , n(d, wi ) = 0,
F (d, wi ) = 0 and, thus, vd,i = 0. Due this, vector vd expected sparse.
738

fiEvaluation Link-Based Approaches Candidate Ranking Link-to-Wikipedia

Given two documents compared (for instance, dc Wikipedia article ci
C(dc , a)), cosine similarity metrics computed cosine angle
vectors two documents, follows:
simcos (vci , vdc ) =

vdc vci
||vdc ||2 ||vci ||2

(13)

Finally, Radford et al. (2010) suggest metrics based Wikipedia link structure,
also interpreted similarity metrics. order compute metrics,
following equation computed candidate ci C(dc , a):
simR (ci , dc ) = log(|B(ci ) Ldc | + 1) + 1

(14)

Ldc set built union backlinks Wikipedia articles
linked dc :
Ldc =

[

B(fi )

(15)

fi F (dc )

aforementioned similarity metrics trivially used address candidate
ranking process. candidate ci C(dc , a) selected link destination
maximal similarity context document dc :
arg max{simf (ci , dc )}
ci

(16)

, RelM , P , P ,
simf represents one functions: RelFA , RelFM , RelB
B
F
F
, P , sim
P IB
cos , simR .
B

3.1.2 Popularity Metrics
Algorithms based popularity metrics constitute second group bag-of-links
family.
first approach could used compute popularity certain candidate,
ci C(dc , a), simply counting number Wikipedia articles link it, is,
indegree, |B(ci )| or, alternatively, number Wikipedia articles linked it,
outdegree, |F (ci )|. metrics considered, instance, work Dredze et al.
(2010), Guo et al. (2011) Cao et al. (2011).
Fader et al. (2009) describe popularity score also based incoming links
Wikipedia candidate ci :
|B(ci )|
))
(17)

parameter set = 15 (Fader et al., 2009).
Finally, degree centrality certain Wikipedia candidate article ci also
considered bag-of-links popularity metrics. Hachey et al. (2011) define degree
centrality as:
popF (ci ) = (1 + log(1 +

D(ci ) =

|B(ci )|
|W | 1

739

(18)

fiFernandez Garca, Arias Fisteus & Sanchez Fernandez

Note that, indicated beginning section, aforementioned popularity
metrics take account information provided context document.
depend information obtained candidates.
aforementioned metrics used rank candidates popularity. Then,
popular candidate ci C(dc , a) selected link destination. Taking
account functions |B(ci )| involved aforementioned approaches (linear,
logarithm) monotonically increasing functions, order (ranking) provided
cases same. Due this, context paper, consider evaluation
indegree outdegree only:

arg max{indegree(ci )}

(19)

arg max{outdegree(ci )}

(20)

ci

ci

3.1.3 Statistical Techniques
candidate ranking process addressing context paper also
mathematically modeled using statistical techniques, suggested work
Fader et al. (2009) Han Sun (2011).
particular case, considering set Wikipedia articles linked dc , F (dc ) =
{f1 , . . . , f|F (dc )| } input features, destination computed selecting
Wikipedia article ci C(dc , a) maximizes conditional probability:
P (ci /f1 , . . . , f|F (dc )| ) fi F (dc )

(21)

number features |F (dc )| considered relatively large, estimating values
conditional probability equation (21) ci would complex problem. Due
this, practice, problem reformulated make treatable. particular:
(1) Bayes rule used reverse conditional probability equation (21); and, (2)
assumed features (links F (dc ) case) conditionally independent
(Naive Bayes assumption).
result problem reformulation known state art Naive
Bayes classifier (Manning et al., 2008). specific scenario, classifier
able distinguish classes (the different ci C(dc , a)) likely
anchor a.
Mathematically, expression use select best ci using maximum
posteriori decision rule (Manning et al., 2008) is:
|F (dc )|

arg max{N B(ci , dc )} = arg max{log P (ci ) +
ci

ci

X

n(dc , fj ) log P (fj /ci )}

(22)

j=1

logarithm function used avoid underflows (as suggested Manning et al.,
2008).
order compute values equation (22) ci , need know value
two probabilities: (1) prior probability class ci , P (ci ); and, (2) conditional
740

fiEvaluation Link-Based Approaches Candidate Ranking Link-to-Wikipedia

probabilities P (fj /ci ). estimate two probabilities follow approach described
Manning et al. (2008):
P
bj B(ci ) n(bj , ci )
P
(23)
P (ci ) = P
wi W
fj F (wi ) n(wi , fj )

is, P (ci ) represents Maximum Likelihood Estimate (MLE) probability
certain document contains link ci , computed dividing number actual
links ci total number links Wikipedia:
P
1 + bi B(ci ) n(bi , fj )
P
P (fj /ci ) = P
(24)
wj W (1 +
bi B(ci ) n(bi , wj ))

case, P (fj /ci ) represents probability anchor linking fj
document already contains link ci . Again, MLE also used conditional
probabilities and, thus, probabilities computed dividing number links
fj documents contain link ci total number links documents
contain link ci . seen MLE smoothed using Laplace smoothing
avoid zeros.
3.2 Graph Approaches
second family link-based approaches candidate ranking consider graph
approaches, rely building graph processing select best candidate.
3.2.1 PageRank Personalized PageRank
first algorithm consider within graph family PageRank, first defined
Page et al. (1999), widely known due use part Google search engine.
Examples application PageRank method candidate ranking found
instance work Fernandez et al. (2010), Dredze et al. (2010) Hachey et al.
(2011).
Basically, PageRank algorithm used compute popularity
certain page, taking account popularity number pages link it. Using
mathematical formulation described Brin Page (1998) particular scenario
addressing paper, compute popularity P R(wi ) Wikipedia
article wi , need solve following equation:
P R(wi ) =

(1 d)
+d[
|W |

X

wj B(wi )

1
P R(wj ) ]
|F (wj )|

(25)

damping factor set 0 1, typically set
0.85 according Brin Page (1998) Hachey et al. (2011).
Note that, according equation (25), taking account links to/from
Wikipedia, computing PageRank general scenario requires complete information link structure Web, computationally expensive problem.
simplification also assumed Fernandez et al. (2010) Hachey et al. (2011).
741

fiFernandez Garca, Arias Fisteus & Sanchez Fernandez

Note also that, happens popularity metrics described section 3.1.2,
PageRank metrics depend context information dc , graph
built link structure Wikipedia. However, context information dc
included process using variant algorithm known Personalized PageRank
Topic-Sensitive PageRank (Haveliwala, 2003). algorithm used instance Yeh
et al. (2009) define semantic relatedness metrics.
main difference classical PageRank Personalized PageRank that,
instead relying uniform damping vector, biased give relevance
given set resources (Haveliwala, 2003). particular case, resources
articles linked dc , is, members F (dc ). practice, equation (25) adapted
follows compute Personalized PageRank:

P P R(wi , dc ) =









d[

X

1
P P R(wj , dc )] wi
/ F (dc )
|F (wj )|

X

1
P P R(wj , dc )] wi F (dc )
|F (wj )|

wj B(wi )






(1 d) F (dc , wi ) + [

wj B(wi )

F (dc , wi ) represents term frequency link wi context
document dc , computed indicated equation (12).
PageRank Personalized PageRank values computed, used
rank candidates. article ci C(dc , a) highest P R(ci ) P P R(ci , dc )
value selected link destination:

arg max{P R(ci )}

(26)

arg max{P P R(ci , dc )}

(27)

ci

ci

3.2.2 Random Walk
Several works state art (Gentile et al., 2009; Fernandez et al., 2010; Han et al.,
2011; Ploch et al., 2011; Jimenez et al., 2013) define techniques link several anchors
context document time. Usually, approaches address candidate
ranking process building graph computing random walk (Spitzer, 1976)
graph rank nodes.
Though approaches share underlying principle, differences
mainly two aspects: nature nodes considered part
graph nature edges. instance, Gentile et al. (2009) indicate
nodes represent either concepts (candidates) features (like words title
certain candidate), edges link candidates specific features. Han et al.
(2011) define nodes anchor linked candidates. edges link
anchor candidates also candidates among basis
relatedness (see section 3.1.1). work Fernandez et al. (2010) nodes include
candidates, edges defined basis information co-occurrence
742

fiEvaluation Link-Based Approaches Candidate Ranking Link-to-Wikipedia

candidates Wikipedia articles. similar approach used Ploch et al. (2011),
including nodes candidates edges defined basis Wikipedia links.
Note PageRank metrics also interpreted random walk (Page et al.,
1999). However, PageRank, described section 3.2.1, operates graph
whole link structure Wikipedia, approaches section build graphs,
typically much smaller tailored concrete scenario addressed.
approaches Gentile et al. (2009) Han et al. (2011) rely text-based features
build graphs: work Gentile et al. (2009) features used nodes
graph, whereas Han et al. (2011) use text-based similarity metrics compute
weights edges connecting anchor candidates. Due this, context
paper evaluate approaches Fernandez et al. (2010) Ploch et al. (2011),
rely link information.
indicated above, Fernandez et al. (2010) Ploch et al. (2011) designed
approaches link time several anchors context document. Thus,
need adapt approaches scenario addressed paper,
anchor considered. so, element F (dc ) treated single-element
pseudo-candidate set anchor ai dc = 1, . . . , |F (dc )|.
compute score candidate ci C(dc , a) according Ploch et al. (2011)
(that name RWP (ci , dc ))) build graph nodes candidates
pseudo-candidates (that is, elements C(dc , a) plus Wikipedia articles linked
F (dc )). edge two nodes appears link Wikipedia
articles represented nodes. graph built, PageRank algorithm
applied graph. score assigned node PageRank value.
similar approach used case Fernandez et al. (2010). Again, nodes
include candidates pseudo-candidates, case edges represent cooccurrences. particular, edge node wi node wj when:
1. least third Wikipedia article wk links wi wj , is,
wi , wj F (wk ). edges assigned weights according to:
weightC (wi wj ) =

|B(wi ) B(wj )|
|B(wi )|

(28)

2. direct link exists wi wj , is, wj F (wi ). edges assigned
weights follows:
weightL (wi wj ) = Fij IDFj = P

n(wi , wj )
|W |
log
|B(wj )|
wk F (wi ) n(wi , wk )

(29)

two nodes wi wj match conditions above, is, directly
linked co-occur third article wk , single edge created combines
contributions follows:

weight(wi wj ) =

kL
kC
weightC (wi wj ) +
weightL (wi wj )
kC + kL
kC + kL
743

(30)

fiFernandez Garca, Arias Fisteus & Sanchez Fernandez

kL kC configuration parameters. case use values
kL = 0.55 kC = 0.25 suggested Fernandez et al. (2010).
weighted, directed graph built, PageRank computed graph.
score candidate ci C(dc , a), named RWF (ci , dc ), PageRank value
candidate node graph. scores candidates computed,
candidate highest score selected best one:
arg max{RWP (ci , dc )}

(31)

arg max{RWF (ci , dc )}

(32)

ci

ci

Note that, approaches listed section 3, might happen different
members candidates set obtain weight and, thus, would tie
ranking. used frequently linked (MFL) algorithm break potential
ties. algorithm simply assigns weight candidate according total number
incoming links, is:
F L(ci , dc ) =

X

n(bj , ci )

(33)

bj B(ci )

4. Comparative Evaluation
section reports results evaluation different approaches described
section 3. organized follows: experimental setup (Wikipedia dataset, corpora,
etc.) used evaluation outlined section 4.1, whereas section 4.2 reports
quantitative results well analysis interpretation results.
4.1 Experimental Setup
order evaluate approaches described section 3, need set elements: (1)
corpora queries evaluate approaches; (2) information Wikipedia link
structure used input different approaches; (3) adequate metrics
measure compare performance approach. next sections describe
three elements briefly:
4.1.1 Corpora Queries
order evaluate different approaches, need corpora containing link-to-Wikipedia
queries. According definition problem (see section 2) queries
corpora provide:
anchor going linked.
context document dc anchor appears. links document
provide context information used algorithms.
set candidates, C(dc , a), Wikipedia articles potential targets
anchor.
744

fiEvaluation Link-Based Approaches Candidate Ranking Link-to-Wikipedia

golden standard indicates correct answer (candidate C(dc , a) ranked
top) query. golden standard used compute performance
algorithms evaluated.
state art, distinguish different approaches regarding corpora
use empirical evaluation. first approach build specific corpora. followed
early work (Bunescu & Pasca, 2006; Cucerzan, 2007; Mihalcea & Csomai, 2007), well
recent work (Milne & Witten, 2008b; Nguyen & Cao, 2010; Pilz, 2010).
common approach within first group use corpus subset Wikipedia articles
compare links suggested automatic algorithms provided Wikipedia
editors (see instance Bunescu & Pasca, 2006; Cucerzan, 2007; Milne & Witten, 2008b;
Nguyen & Cao, 2010 Pilz, 2010). methodology also used context
INEX Link-the-wiki track (Huang, Xu, Trotman, & Geva, 2008). second alternative
use already available corpora, like TAC/KBP corpus (used instance Han &
Sun, 2011 Hachey et al., 2011), corpora defined Cucerzan (2007) (used
instance Gentile et al., 2009 Ratinov et al., 2011).
context paper, adopt approaches. particular, use
following corpora comparative evaluation:
Cucerzan work Cucerzan (2007) authors use two different corpora, one
built Wikipedia articles manually annotated MSNBC (MSNBC,
2014) news items. used corpora build own. order so,
proceeded follows:
1. documents Cucerzan corpora contain set pairs {anchor, Wikipedia
article}, one representing potential link-to-Wikipedia query. select
randomly 250 pairs Cucerzans corpora. pairs provide us
anchor linked golden standard (correct answer
query).
2. typical approach among systems TAC/KBP generate candidate
set, C(dc , a), rely information retrieval techniques (Ji et al., 2011).
paper adopt approach. However, difference TAC/KBP
scenario, evaluation involves stages entity linking, center
evaluation candidate ranking stage. Due this, interested
isolating much possible stage potential bad performance
particular candidate search implementation. is, interested
analyzing performance different candidate ranking approaches assuming
candidate search stage ideal, sense always returns
correct candidate among candidate set. Obviously, exist
ideal candidate searcher. Thus, practice, rely state art
search engine (Google) append correct answer candidate set
case found search engine. particular, query Google
search engine text anchor site:en.wikipedia.org restriction,
filtering top-10 Google results Wikipedia pages included
Main namespace. case correct Wikipedia article linked
745

fiFernandez Garca, Arias Fisteus & Sanchez Fernandez

included within Google result set, appended end, though
happens limited number queries: Curcerzan Wikipedia
corpus correct candidate added 9 250 queries (3.6%),
Curcerzan news corpus added 14 250 queries (5.6%).
3. Finally, rest pairs {anchor, Wikipedia article} included
document query selected, obtain Wikipedia article
component used context information (links F (dc )), filtering
links articles included candidate set order avoid bias.
Ad-hoc corpora Two ad-hoc corpora used evaluation. One corpus
(Wikipedia random corpus) built following methodology suggested
previous works state art, is, selecting set 500 Wikipedia articles
using Random article page (Wikipedia, 2014a).
second ad-hoc corpus (Wikinews corpus) built using documents
English Wikinews site (Wikinews, 2014b). documents represent news items.
usually annotated human editors Wikipedia links. case 500
news items selected Random article functionality Wikinews (Wikinews,
2014a).
document total set 1000 documents two ad-hoc corpora,
built link-to-Wikipedia query using following procedure:
1. Wikipedia link randomly selected document.
2. selected link obtain anchor golden standard (link
destination Wikipedia).
3. use anchor Google search engine build candidate set,
indicated case Cucerzan corpora. Again, append correct
candidate included Google result set. particular,
correct candidate added 14 500 queries (2.8%) case
Wikinews corpus 36 500 queries (7.2%) Wikipedia random
corpus.
4. query context information obtained rest links
document, filtering linking members candidate set order
avoid bias.
TAC2010 TAC 2010 dataset includes total 2250 entity linking queries and,
one, provides anchor linked, context document dc
golden standard. used dataset basis build last corpus involved
evaluation. order so, proceeded follows:
1. total set 2250 queries, 1230 golden standard NIL answer,
is, Wikipedia article link cases. Thus, correct
candidate instance exists and, due this, difficult take advantage
queries evaluate candidate ranking process. Taking account,
discard queries keep remaining 1020.
746

fiEvaluation Link-Based Approaches Candidate Ranking Link-to-Wikipedia

2. documents TAC 2010 corpus contain links. Thus, use
following procedure order obtain context links needed
algorithms:
query, analyze context document dc using natural language
processing techniques. particular, extract named entities (persons,
locations organizations) text using Stanford NER tool (Finkel,
Grenager, & Manning, 2005).
Then, link detected entities Wikipedia using Google. particular,
query Google search engine text named entity
site:en.wikipedia.org restriction, filtering top-10 Google results
Wikipedia pages included Main namespace, assigning
link top result filtered list. discard named entities
Google results found. links named entities Wikipedia defined
procedure used context information candidate ranking,
filtering context links members candidate set
order avoid bias.
discard queries context information available, is,
NER tool find named entities dc , filtered
process linking Wikipedia. results total 1012 valid
queries.
3. candidate set C(dc , a) query obtained using procedure
previous corpora: using Google search anchor appending
correct candidate case found (which happens 70 1012 queries
(6.9%)).
summarize, carry evaluation five different corpora (Cucerzan news,
Cucerzan Wikipedia, Wikipedia random, Wikinews TAC 2010)1 , add
total 2512 link-to-Wikipedia queries. Boxplot diagrams representing distributions
corpus number candidates (|C(dc , a)|) per query, number links
(|F (dc )|) per query, shown Figures 1 2 respectively.
Note appending correct candidate candidates set needed 143
2513 queries. indicates Google performs quite well candidate searcher
case, candidate recall near 95% (considering first 10 results).
put result context, indicate Hachey et al. (2013) compare several
candidate search approaches TAC 2009 dataset report candidate recall
75% limited maximum 10 results. However results similar
Lehmann et al. (2010), authors use Google search combined
set additional techniques report 97% candidate recall TAC 2009 dataset.
4.1.2 Wikipedia Link Structure
approaches described section 3 require information Wikipedia link structure carry candidate ranking process. case, information
1. corpora available download at: http://www.it.uc3m.es/berto/link-to-wikipedia/survey/

747

fiFernandez Garca, Arias Fisteus & Sanchez Fernandez

2

4

6

8

10

Distribution number candidates per query corpus

Cucerzan News

Cucerzan Wiki.

Wiki. Random

Wikinews

TAC2010

Figure 1: Boxplot diagram number candidates (|C(dc , a)|) per query
corpus.

0

50

100

150

200

250

300

350

Distribution number context links per query corpus

Cucerzan News

Cucerzan Wiki.

Wiki. Random

Wikinews

TAC2010

Figure 2: Boxplot diagram number links context (|F (dc )|) per query
corpus.

748

fiEvaluation Link-Based Approaches Candidate Ranking Link-to-Wikipedia

obtained dump Wikipedia page links provided DBpedia (Bizer et al., 2009)
version 3.82 , generated full Wikipedia dump dated June 2012.
links dump preprocessed follows:
redirections resolved, using redirections mapping table DBpedia
3.83 .
indicated section 2, consider Wikipedia pages belong
Main namespace. Thus, links from/to pages namespaces (like Talk pages,
User pages, etc.) removed.
Using information provided disambiguation map DBpedia 3.84 ,
links from/to disambiguation pages also removed.
inner links (from article itself) also filtered out.
evaluation corpora described section 4.1.1 include cases Wikipedia
articles. separate input data evaluation data, links source
destination one Wikipedia articles included evaluation corpora
filtered out.
4.1.3 Performance Metrics
measure compare performance considered approaches, need
adequate metrics. well-known evaluation metrics link-to-Wikipedia approaches
accuracy, used instance Bunescu Pasca (2006), Cucerzan (2007), Hachey et al.
(2011), Ratinov et al. (2011) Hachey et al. (2013). accuracy computed
percentage queries candidate selected algorithm correct one,
or, formally:
Accuracy =

1 X
S(q)
|Q|

(34)

qQ

Q represents set evaluation queries, q particular query set, S(q)
function S(q) = 1 candidate article ranked top query q
correct answer S(q) = 0 otherwise.
However, center evaluation candidate ranking stage link-toWikipedia task, accuracy presents limitation: take account actual
position correct answer within ranking produced algorithm. example,
one algorithm ranks correct answer query 2nd position, whereas another
algorithm ranks 8th position, contribution query accuracy
zero cases, despite first algorithm ranked correct answer higher.
scenarios link-to-Wikipedia approaches work human-supervision (for instance, systems used within production process news agency (Fernandez
2. http://downloads.dbpedia.org/3.8/en/page links en.nt.bz2 (April, 2014)
3. http://downloads.dbpedia.org/3.8/en/redirects transitive en.nt.bz2 (April, 2014)
4. http://downloads.dbpedia.org/3.8/en/disambiguations en.nt.bz2 (April, 2014)

749

fiFernandez Garca, Arias Fisteus & Sanchez Fernandez

et al., 2006) add metadata news items) particular order candidates relevant, case top-ranked candidate correct one, human supervisor
continue reading ranked list candidates select another option. Obviously,
nearer top correct candidate list suggestions, better.
Taking account, decided report performance using accuracy,
also two position-based discounting schemes measure overall quality ranked
list results:
Mean Reciprocal Rank (MRR) used instance evaluation question
answering systems (Voorhees, 1999). MRR set evaluation queries Q
computed as:
RR(Q) =

1 X 1
|Q|
r(q)

(35)

qQ

r(q) represents position correct candidate rank query
q Q.
shown equation 35, MRR penalizes differences position severely.
Taking account, also report results Discounted Cumulative
Gain certain level K (DCG@K), introduces smoother penalization
position. DCG@K computed as:
k
1 X X 2R(q,i) 1
DCG@K(Q) =
|Q|
log2 (1 + i)

(36)

qQ i=1

Q represents set evaluation queries, q particular query set,
R(q, i) relevance score given candidate article position query q.
adopt binary relevance model and, thus, R(q, i) = 1 candidate position
correct answer R(q, i) = 0 otherwise. Furthermore, consider
single candidate relevant query. Taking account, DCG@K
equivalent normalized version, Normalized Discounted Cumulative Gain
K (NDCG@K) (Manning et al., 2008), equation 36 simplified into:

1 X
DCG@K(Q) =
f (q, k) f (q, k) =
|Q|
qQ

(

1
log2 (1+r(q))

r(q) <= k

0

r(q) > k

(37)

r(q) represents position correct candidate rank query q.
seen equation 37, bigger value r(q) (that is, farther away
correct candidate top rank) lesser value term added
DCG@K. Note also DCG@1 would equivalent accuracy defined
equation 34.
750

fiEvaluation Link-Based Approaches Candidate Ranking Link-to-Wikipedia

Figure 3: Taxonomy different approaches considered evaluation.
4.2 Evaluation
section reports results empirical evaluation approaches.
structured presentation results three parts: section 4.2.1 compares individual
algorithms described section 3, section 4.2.2 analyzes combination different approaches use machine learning techniques and, finally, section 4.2.3 evaluates
impact changing search stage performance algorithms.
4.2.1 Comparison Individual Approaches
approaches described section 3 (summarized taxonomy shown Figure 3)
evaluated corpora described section 4.1.1. Table 1 reports accuracy
obtained approach different evaluation corpora. highlighted
boldface best accuracy among link-based evaluated approaches particular
corpus.
Table 1 includes column (Overall) reports results obtained corpus
generated aggregating queries. last column, Confidence Interval (Overall),
reports 95% confidence interval accuracy Overall case, computed using
bootstrap methods suggested Adibi, Cohen, Morrison (2004).
seen Approach column Table 1, apart approaches considered section 3, include results two naive algorithms reference baselines:
(1) random algorithm, simply ranks candidates randomly; and, (2)
frequently linked (MFL) algorithm, described section 3 (see equation (33)). also
report (see row Google) accuracy obtained using trivial ranker simply returns
751

fiFernandez Garca, Arias Fisteus & Sanchez Fernandez

candidates order defined corpus (that is,
order returned Google, correct candidate end found
Google)5 .
Cucerzan
Approach
Random
MFL
Google
RelFA
RelFM

RelB

RelB
P IFA
P IFM

P IB

P IB
simcos
simR
indegree
outdegree
NB
PR
PPR
RWP
RWF

Wiki.

News

Wiki

Random

0.133
0.700
0.844
0.568
0.416
0.716
0.576
0.204
0.140
0.272
0.192
0.440
0.760
0.700
0.532
0.772
0.684
0.692
0.776
0.760

0.149
0.630
0.883
0.458
0.406
0.651
0.542
0.233
0.229
0.321
0.285
0.486
0.687
0.647
0.462
0.719
0.623
0.687
0.663
0.715

0.153
0.571
0.795
0.489
0.365
0.717
0.597
0.289
0.252
0.421
0.383
0.483
0.687
0.581
0.327
0.729
0.565
0.697
0.647
0.643

TAC
Wikinews
0.155
0.676
0.914
0.436
0.338
0.694
0.526
0.206
0.174
0.318
0.274
0.516
0.734
0.670
0.472
0.752
0.668
0.702
0.752
0.744

2010
0.118
0.668
0.748
0.495
0.227
0.738
0.418
0.081
0.055
0.237
0.167
0.421
0.725
0.671
0.579
0.766
0.635
0.553
0.732
0.740

Overall
0.137
0.650
0.813
0.486
0.313
0.715
0.503
0.174
0.144
0.301
0.245
0.461
0.719
0.653
0.491
0.752
0.631
0.639
0.717
0.721

Confidence
Interval
(Overall)
(0.124, 0.151)
(0.631, 0.668)
(0.798, 0.828)
(0.466, 0.505)
(0.295, 0.331)
(0.696, 0.732)
(0.483, 0.522)
(0.160, 0.189)
(0.130, 0.157)
(0.283, 0.319)
(0.228, 0.262)
(0.441, 0.480)
(0.701, 0.736)
(0.634, 0.671)
(0.471, 0.510)
(0.734, 0.768)
(0.612, 0.650)
(0.619, 0.657)
(0.698, 0.734)
(0.703, 0.738)

Table 1: Accuracy obtained different approaches evaluation corpora.
Figure 4 shows DCG@K different values K Overall aggregated corpus.
MRR values different evaluation corpora reported Table 2, where, again,
highlighted boldface best MRR among link-based evaluated approaches
particular corpus. Furthermore, order provide detailed idea
differences among methods, show Figure 5 percentage queries
correct candidate ranked position K (with K 1 10) algorithm.
also provide empirical results run-time different algorithms. particular, average run-time per query (in seconds) measured Linux
2.6.32, Intel Core i7 2.80GHz PC 16GB RAM one second approaches except RWF P P R, run closer 4 571 seconds per query respectively. relatively large response time P P R due fact algorithm uses
context information personalize PageRank damping vector. Taking account that,
general, query different context, means need run PageRank
5. Note Google case, queries correct candidate appended result set
accounted errors computing accuracy.

752

fiEvaluation Link-Based Approaches Candidate Ranking Link-to-Wikipedia

Approach
Random
MFL
Google
RelFA
RelFM

RelB

RelB
P IFA
P IFM

P IB

P IB
simcos
simR
indegree
outdegree
NB
PR
PPR
RWP
RWF

Cucerzan
News
Wiki
0.347 0.370
0.806 0.763
0.894 0.922
0.727 0.651
0.607 0.600
0.830 0.787
0.727 0.710
0.428 0.458
0.356 0.440
0.500 0.543
0.415 0.502
0.650 0.671
0.850 0.813
0.806 0.773
0.700 0.648
0.859 0.834
0.799
0.76
0.812 0.801
0.864 0.796
0.854 0.821

Wiki.
Random
0.374
0.726
0.858
0.667
0.573
0.830
0.746
0.501
0.463
0.622
0.570
0.666
0.805
0.729
0.550
0.832
0.719
0.810
0.778
0.774

Wikinews
0.379
0.794
0.939
0.635
0.548
0.820
0.705
0.435
0.403
0.547
0.503
0.699
0.837
0.793
0.655
0.848
0.786
0.810
0.847
0.837

TAC
2010
0.326
0.791
0.828
0.688
0.473
0.847
0.643
0.318
0.271
0.490
0.414
0.620
0.838
0.794
0.730
0.861
0.774
0.734
0.837
0.836

Overall
0.353
0.778
0.872
0.673
0.534
0.831
0.691
0.403
0.361
0.534
0.472
0.653
0.830
0.780
0.668
0.850
0.767
0.778
0.826
0.824

Table 2: MRR obtained different approaches evaluation corpora.
computation whole Wikipedia graph query corpus, process
time consuming6 . Note, however, used Python implementation
optimized and, thus, results provided reference.
contextualize results reported Table 1, indicate TAC 2010
corpus using evaluation practically equivalent (apart 8 queries
removed due lack context information, indicated section 4.1.1) Non-NIL
queries TAC 2010 dataset. Due this, results reported column TAC 2010
Table 1 roughly compared (less 1% error) TAC 2010 Non-NIL
accuracy reported papers state art. instance, best performing
approach TAC 2010 (Lehmann et al., 2010) reported accuracy Non-NIL queries
80.6%. Note, however, cautious comparisons, results
reporting would equivalent obtained end-to-end system using
ideal candidate search stage (we always append correct candidate) without
candidate selection process (we report results candidate ranking stage).
Analyzing results reported Table 1, first conclusion may drawn
overall accuracy achieved using Google ranking better obtained
evaluated approaches. However, observe results obtained
6. According Bianchini, Gori, Scarselli (2005), computation depends linearly number
edges Wikipedia graph.

753

fiFernandez Garca, Arias Fisteus & Sanchez Fernandez

Algorithms
RelAF

0.75

RelM
F
RelAB
RelM
B
PMIAF

DCG@K

PMIM
F
PMIAB
PMIM
B
simCOS

0.50

simR
indegree
outdegree
NB
PR
PPR
RWP
RWF

0.25

1

2

3

4

5

6

7

8

9

10

K

Figure 4: DCG@K values different algorithms considered evaluated
Overall corpus generated aggregating queries.

individual corpus, also note using Google always best approach.
particular, accuracy N B TAC 2010 corpus slightly better achieved
Google.
interpret findings, take account previous work area
(notably Chang et al., 2010) already pointed using Google produces
relatively good results entity linking task (accuracy near 78% TAC 2009 experimental setup). sense, overall performance obtained Google completely
unexpected. degradation performance TAC 2010 case partially explained
754

fiEvaluation Link-Based Approaches Candidate Ranking Link-to-Wikipedia

100%

90%

80%
Position (K)

Percentage queries

70%

10
9

60%

8
7
6

50%

5
4

40%

3
2

30%

1

20%

10%

RWF

RWP

PPR

PR

NB

outdegree

indegree

simR

simCOS

PMIM
B

PMIAB

PMIM
F

PMIAF

RelM
B

RelAB

RelM
F

RelAF

0%

Algorithms

Figure 5: Percentage queries correct candidate ranked position K (with
K 1 10) different algorithms compared.

755

fiFernandez Garca, Arias Fisteus & Sanchez Fernandez

fact corpus specifically built entity linking task using careful
targeted process7 . Due this, queries TAC 2010 corpus expected
challenging. instance, common case8 within corpus groups queries
sharing anchor linked, different correct answers depending
particular query. case, queries share anchor, also share Google
ranking and, thus, top ranked candidate but, correct answer changes
queries, using always Google top ranked candidate answer introduces errors.
Note also using Google taking advantage context information,
expected valuable decide best link anchor, especially
queries challenging.
second conclusion naive popularity metrics like indegree (or F L,
whose performance similar indegree) produce reasonably accurate results.
aspect consistent previous work state art (Ji & Grishman, 2011)
authors indicate naive candidate ranking approaches based web popularity
achieve accuracies around 71% TAC 2010 corpus.
Another aspect highlighted that, consistently across evaluation corpora,
indegree metrics produces better accuracy outdegree, indicates
number backlinks offers better representation popularity Wikipedia article
number outgoing links. One aspect may explain, least partially,
difference performance fact number outgoing links may high due
several reasons. Wikipedia article long (which indicates received
extensive attention Wikipedia contributors is, sense, popular) expect
links shorter articles. However, cases
Wikipedia article contain many outgoing links. case, instance, articles
represent hub links, List articles.
test hypothesis outdegree metrics introduces bias favor hubs like
List articles, compared number queries candidate ranked
top indegree outdegree list (its title starts List ) different corpora.
results shown Table 3, x, proportion queries candidate
ranked top list, whereas proportion queries candidate
ranked top list correct answer. is:
Queries top ranked candidate list
Total number queries corpus

(38)

Queries top ranked candidate list correct
Queries top ranked candidate list

(39)

x=

y=

seen Table 3, outdegree metrics ranks list pages frequently
top indegree metrics. also seen that, cases,
candidate ranked top list, correct answer. particularity explains
significant part difference overall results indegree outdegree.
7. indicated TAC KBP 2010 task definition document, available at:
http://www.it.uc3m.es/berto/link-to-wikipedia/survey/KBP2010 TaskDefinition.pdf (April, 2014)
8. identified total 144 queries (approximately 14%) following pattern.

756

fiEvaluation Link-Based Approaches Candidate Ranking Link-to-Wikipedia

Approach
Name
Param
x
indegree

x
outdegree


Cucerzan
News Wiki
0.004 0.004
1.0
1.0
0.06 0.088
1.0
1.0

Wiki.
Random
0.022
0.818
0.138
0.956

Wikinews
0.006
0.667
0.078
0.974

TAC
2010
0.014
1.0
0.049
1.0

Overall
0.012
0.903
0.078
0.979

Table 3: Comparison indegree outdegree regarding tendency rank
Wikipedia list top.

difference performance using backlinks forward links also
noticed similarity metrics, approaches relying backlink information
, RelM , P , P ) produce better results corresponding metrics work(RelB
B
B
B
ing forward links (RelFA , RelFM , P IFA , P IFM ).
According results Table 1, also pointed that, among linkbased approaches evaluated, taking advantage context information is, general,
beneficial. support conclusion compare results F L N B. Note
N B uses prior P (ci ) (see equations (22) (23)), basically normalized
version F L. However, N B combines prior probabilities P (fj /ci ),
capture context information. seen Tables 1 2, result combination N B produces better results F L. Note also none alternatives
use popularity information included among top-5 link-based evaluated
). However, using context
approaches higher accuracy (N B, RWF , simR , RWP , RelB
information sufficient condition ensure good performance, reflected
results PMI variants.
Another conclusion reached that, cases relatedness PMI
metrics, averaging pairwise similarities candidate articles F (dc )
, P , RelA P ) produces, consistently across corpora, better
(as done RelB
B
F
F
, P , RelM P ).
accuracy relying maximum (as done RelB
B
F
F
possible explanation result relying maximum similarity
take account one elements F (dc ) (the one maximizes similarity)
represent semantics document dc , whereas, averaging, elements
F (dc ) contribute final similarity value. reasonable think set
forward links dc provides accurate representation semantics context
document single link document.

objective testing intuition, implemented two new variants RelB
, name RelM (P ) P (P ). order obtain RelM (P )(c , )
P IB
c
B
B
B
scores compute simRB (ci , fj ) fj F (dc ) equation (7). However, instead
selecting maximum value, done equation (7), select certain percentage
P top values average them. instance, |F (dc )| = 10 P = 50%,
select top 5 simRB (ci , fj ) values average them. Note that, approach,
. obtain
P = 100% scores would equivalent obtained RelB
(P )(c , ) scores proceed similar way, using P (c , f ) values
P IB
c
B j
(P )
(see equation (11)) instead simRB (ci , fj ) ones. evaluated RelB
757

fiFernandez Garca, Arias Fisteus & Sanchez Fernandez

0.7

RelAB

Accuracy

0.6

RelM
B
0.5

Algorithms
PMIM
B ( P)
RelM
B ( P)

0.4

PMIAB
0.3

PMIM
B

10%

30%

50%

70%

90%

Percentage
(P ) P (P ) approaches different values
Figure 6: Accuracy values RelB
B
percentage P evaluated Overall corpus generated aggregating
queries.

(P ) variants overall aggregated corpus different values percentage P .
P IB
Figure 6 reports accuracy obtained new variants. also included
, P , RelA
references horizontal lines representing overall accuracy RelB
B
B

P IB . seen, increasing context information improves results.
Also related relatedness PMI metrics fact results obtained
PMI variants quite poor compared equivalent relatedness variants.
(0.715) P (0.301).
example, see difference overall accuracy RelB
B

758

fiEvaluation Link-Based Approaches Candidate Ranking Link-to-Wikipedia

inspection results P revealed that, using absolute values instead
logarithmic values (as relatedness), PMI sensitive outliers. order
verify quantify observation, decided compare results PMI two
alternatives:
implemented logarithmically smoothed version averaging PMI variants
adapting equations (8) (9) follows:

logP IFA (ci , dc ) =

logP IB
(ci , dc ) =

1
|F (dc )|
1
|F (dc )|

X

log[PF (ci , fj )]

(40)

X

log[PB (ci , fj )]

(41)

fj F (dc )

fj F (dc )

used symmetric conditional probability (SCP), introduced da Silva
Lopes (1999). SCP two Wikipedia documents wi , wj computed as:
SB (wi , wj ) =

|B(wi ) B(wj )|2
|B(wi )||B(wj )|

(42)

also adapted use forward links as:
SF (wi , wj ) =

|F (wi ) F (wj )|2
|F (wi )||F (wj )|

(43)

Using equations (42) (43) following two metrics implemented:
SCPFA (ci , dc ) =
SCPBA (ci , dc ) =

1
|F (dc )|
1
|F (dc )|

X

[SF (ci , fj )]

X

[SB (ci , fj )]

(44)

fj F (dc )

(45)

fj F (dc )

run approaches corpora, report results Table 4 (accuracies)
Table 5 (MRR). seen comparing results Table 4
Table 1, significant increase performance achieved using
P IFA P IB
logarithmically smoothed version P I. also seen accuracies reported
similar
SCPFA SCPBA better P IFA P IB
, respectively.
results relatedness variants RelFA RelB
4.2.2 Combining Individual Approaches
want also explore possibility combining results different link-based
approaches test whether better results obtained not. approach
follow combine alternatives described section 3 based supervised machine
learning techniques. particular, use learning rank (Joachims, 2002) method.
759

fiFernandez Garca, Arias Fisteus & Sanchez Fernandez

Cucerzan
Approach
logP IFA

logP IB
SCPFA
SCPBA

Wiki.

News

Wiki

Random

0.392
0.552
0.500
0.728

0.357
0.550
0.454
0.634

0.423
0.669
0.441
0.693

TAC
Wikinews
0.370
0.590
0.404
0.658

2010
0.396
0.674
0.286
0.550

Overall
0.392
0.632
0.378
0.626

Confidence
Interval
(Overall)
(0.372, 0.411)
(0.612, 0.650)
(0.359, 0.397)
(0.607, 0.645)

Table 4: Accuracy obtained logarithmically smoothed P variants SCP based metrics evaluation corpora.

Approach
logP IFA

logP IB

SCPF
SCPBA

Cucerzan
News Wiki
0.604 0.574
0.735 0.714
0.681 0.648
0.835 0.788

Wiki.
Random
0.623
0.800
0.637
0.815

Wikinews
0.580
0.752
0.610
0.797

TAC
2010
0.607
0.805
0.545
0.741

Overall
0.601
0.778
0.600
0.781

Table 5: MRR obtained logarithmically smoothed P variants SCP -based
metrics evaluation corpora.

Though several learning rank algorithms available state art (Liu, 2009),
decided rely ListN et method described Cao et al. (2007). decision
backed results reported Chen Ji (2011), several alternatives
evaluated compared context entity linking problem. particular,
took advantage open source implementation ListN et provided University
Massachusetts RankLib package (Van B. Dang, 2014).
Basically, use scores returned individual approaches section 3 features
taken account ListN et algorithm. values features normalized
range [0, 1] avoid bias might favor them.
tested three different combinations approaches. first variant (that
name ListN etAll ) combines link-based approaches evaluation (that is,
algorithms included Table 1 except Google naive references F L
Random). second variant (ListN etT op ) combines top-5 best performing linkbased algorithms evaluation (according Overall accuracy Table 1, is, N B,
). Finally, third case (ListN et
RWF , simR , RWP , RelB
op+Google ) combines top5 best performing link-based algorithms Google baseline. cases,
used configuration parameters ListN et suggested RankLib
implementation (1500 epochs learning rate 105 ).
order report accuracy, MRR DCG@K ListN et variants, use
results obtained averaging 10 repetitions 10-fold cross validation particular
corpus analyzed. Table 6 reports accuracy different corpora combinations considered, Table 7 reports MRR results
760

fiEvaluation Link-Based Approaches Candidate Ranking Link-to-Wikipedia

Approach
ListN etAll
ListN etT op
ListN etT op+Google

Cucerzan
News Wiki
0.780 0.716
0.824 0.786
0.854 0.864

Wiki.
Random
0.742
0.769
0.850

Wikinews
0.738
0.803
0.877

TAC
2010
0.678
0.793
0.816

Overall
0.705
0.797
0.846

Table 6: Accuracy obtained combining approaches section 3 ListN et
evaluation corpora.

Approach
ListN etAll
ListN etT op
ListN etT op+Google

Cucerzan
News Wiki
0.867 0.834
0.888 0.879
0.916 0.930

Wiki.
Random
0.847
0.865
0.916

Wikinews
0.848
0.885
0.929

TAC
2010
0.812
0.882
0.894

Overall
0.828
0.882
0.913

Table 7: MRR obtained combining approaches section 3 ListN et
evaluation corpora.

combinations. Figure 7 compares DCG@K achieved ListN et variants Overall
case top-5 link-based evaluated approaches.
compare accuracy values reported Table 6 Table 1.
overall case, best result obtained ListN etT op+Google . ListN etT op combination
shows lower performance Google reference, outperforms N B (the best
individual algorithms comparison). Regarding ListN etAll variant, accuracy
lower obtained Google N B. Similar conclusions also reached
Figure 7 DCG@K metrics overall case. conclusions suggest
particular combinations features positive impact results.
However, cautious results, because, indicated Vanwinckelen (2012), repeated cross validation assumed provide perfectly precise
estimates models predictive accuracy. fact, Vanwinckelen (2012) recommend reporting confidence intervals making significance claims repeated cross validation. report that, though popular among researchers, practice contribute
misleading interpretations.
4.2.3 Effect Changes Search Stage
indicated section 4.1.1, order isolate results candidate ranking algorithms evaluated potential bad performance particular candidate search
implementation, would need rely ideal candidate search stage, sense
always returns correct answer among candidate set. Obviously,
exist ideal candidate searcher. Thus, practice, try mimic behavior,
relied state art search engine (Google) appended correct answer
candidate set case found search engine.
761

fiFernandez Garca, Arias Fisteus & Sanchez Fernandez

0.90

Algorithms
RelAB

0.85

simR

DCG@K

NB
RWP
RWF
ListNetAll

0.80

ListNetTop
ListNetTop+Google

0.75

0.70
1

2

3

4

5

6

7

8

9

10

K

Figure 7: DCG@K values top-5 link-based evaluated approaches ListN et variants evaluated Overall corpus generated aggregating
queries.

762

fiEvaluation Link-Based Approaches Candidate Ranking Link-to-Wikipedia

However, also interested evaluating impact results achieved
different algorithms aforementioned conditions change restrictive
setup. order so, proceeded follows:
used information retrieval library Apache Lucene (Apache Software Foundation, 2014) build index titles DBpedia 3.8 pages. title
processed StandardAnalyzer Lucene.
1012 queries TAC 2010 corpus carried following
process:
anchor query used search Lucene index candidates, C(dc , a). result set limited top-10 entries, like previous experiments. However, contrary previous experiments,
Lucene return correct answer within result set, append
it.
documents TAC 2010 corpus contain context links,
automatically generated using similar approach one described
section 4.1.1: named entities obtained context documents using
Stanford NER resolved links querying Lucene text
named entity assigning link destination top result search
engine (as usual, filtering links articles included within
candidate set).
Using aforementioned procedure built new version TAC 2010 corpus
annotated Lucene. Thus, two variants TAC 2010:
TAC 2010 Google, Google used candidate searcher correct
candidate appended Google results set case found.
version used experiments previous sections.
TAC 2010 Lucene, version built following procedure described
section.
run evaluated approaches, well references Random F L,
TAC 2010 Lucene corpus. accuracies achieved different algorithms
95% confidence intervals shown Figure 8. ease comparison, depicted
figure accuracies TAC 2010 Google corpus. also included
(with name Search) accuracy achieved candidate ranking provided
search engine (either Google Lucene) directly used.
first aspect noted results reported Figure 8 that, surprisingly,
accuracies obtained different approaches using Lucene search are, general,
lower. Note Lucene case including correct candidate
candidates set. Thus, many queries (363 cases, almost 36% total queries)
impossible candidate rankers rank correct candidate top.
Another issue highlighted that, look top-5 best performing link-based
, greatly reduced
approaches Table 1: N B, RWF , simR , RWP , RelB
763

fiFernandez Garca, Arias Fisteus & Sanchez Fernandez

0.8

Accuracy

0.6

Case
Google

0.4

Lucene

0.2

RWF

RWP

PPR

PR

NB

indegree

outdegree

simR

simCOS

PMIM
B

PMIAB

PMIM
F

PMIAF

RelM
B

RelAB

RelM
F

RelAF

Search

MFL

Random

0.0

Algorithms

Figure 8: Accuracy obtained different approaches TAC 2010 Google TAC
2010 Lucene corpora.

performance TAC 2010 Lucene corpus. fact, though N B top performing
corpus, statistically significant difference popularity approaches like
indegree PageRank (P R). possible explanation result TAC 2010
corpus context information automatically generated search engine
supervised. Thus, expect noisy. noise affects N B, RWF , simR ,
, rely context information take decisions, impact
RWP , RelB
indegree P R, rely context information. Note that, though noise
context information affects cases Google Lucene used search
764

fiEvaluation Link-Based Approaches Candidate Ranking Link-to-Wikipedia

engines, better performance Google (note results Search) makes much worse
Lucene case.

5. Related Work
foundations link-to-Wikipedia task found two different research communities. First, area related traditional computational linguistics tasks like
cross-document co-reference resolution (Bagga & Baldwin, 1998), word sense disambiguation (Navigli, 2009). main difference respect traditional tasks
Wikipedia used source knowledge instead lexicons WordNet (Miller,
1995) typically used former work (see instance Li, Szpakowicz, & Matwin, 1995).
Second, link-to-Wikipedia task also related link prediction task link mining (Getoor & Diehl, 2005), though case goal mainly decide whether two
objects (for instance, two actors social network, actor event) linked
not, instead finding best link destination Wikipedia particular anchor
text document.
Traditionally, works Bunescu Pasca (2006) Cucerzan (2007)
considered seminal area. Since publication papers problem
linking anchors text document Wikipedia articles addressed several
works, like referenced section 3.
Two initiatives also especially relevant sense: Knowledge Base Population (KBP) track Text Analysis Conference (TAC), Link-the-Wiki track
Initiative Evaluation XML retrieval (INEX). initiatives share goal:
offer common environment (corpora, performance metrics, etc) allow fair comparative evaluation different techniques and, thus, foster area research. However,
indicated introductory section, approach link-to-Wikipedia task slight
differences. case KBP, final aim automatically populate Knowledge
Base (KB) built Wikipedia information named entities. Thus, linkto-Wikipedia variant (named entity linking) focused entities covers case
good Wikipedia target exists link, case indicates need add
new entry KB. case Link-the-Wiki INEX track, focus set
keeping links date rich dynamic hypermedia document collection (such
wiki). Therefore, link-to-Wikipedia variant (wikification) covers common terms
named entities anchors linked, pay special attention case
good Wikipedia target exists, case link needs created.
cases, overview papers published organizers events (Huang
et al., 2008, 2009, 2010; Ji et al., 2010, 2011; Ji & Grishman, 2011) offer good source
references area. However, comparisons provided works refer
systems taking part TAC/KBP INEX, external work. Furthermore,
indicated introductory section, link-to-Wikipedia systems combine, general,
variety techniques features different types (based text, links, etc.) address
task. results reported overviews refer usually full systems,
difficult analyze compare performance individual techniques part
systems. goal work analysis comparison link-based
techniques.
765

fiFernandez Garca, Arias Fisteus & Sanchez Fernandez

surveys related task link-to-Wikipedia and, thus, relevant purposes paper Navigli Lapata (2010), Chen Ji (2011), Hachey
et al. (2013).
Chen Ji (2011) evaluate several supervised candidate rankers named entity
linking, compare reference unsupervised approaches: naive algorithm
three different similarity metrics based textual features. main goal comparison
assess machine learning mechanism (maximum entropy, SVM, SV rank
ListNet) top performing. Thus, results reported Chen Ji (2011)
paper complementary, because, indicated section 4.2.2, different
approaches analyzed used features supervised systems. Obviously,
requires know supervised techniques work better (Chen & Ji, 2011), also
know link-based techniques better, goal paper.
Hachey et al. (2013) re-implement compare three different named entity linking
systems state art. However, main goal work different ours,
aim Hachey et al. (2013) analyze impact candidate searching
candidate ranking stages final performance entity linking system.
Navigli Lapata (2010) compare several metrics based graph connectivity, including also considered paper, like PageRank indegree. However,
work different scope ours: centered different task (word sense
disambiguation), uses different data source (WordNet).
knowledge authors, previous overview comparison different linkbased approaches candidate ranking link-to-Wikipedia systems, proposed
paper, available time writing.

6. Conclusions Future Lines
paper presented overview link-based approaches candidate ranking
link-to-Wikipedia systems. Apart overview, comparative analysis
different approaches also carried out. structured analysis three parts:
first part devoted compare performance individual approaches
according three metrics (accuracy, DCG@K MRR) five different corpora
(Cucerzan news, Cucerzan Wikipedia, random Wikipedia articles, random Wikinews
articles TAC 2010). results part analysis indicate that, though
naive approaches based popularity candidates perform reasonably
well, taking advantage context information is, general, beneficial linkbased approaches. also found using information backlinks
obtain better results using forward links techniques.
second part analysis combined different approaches using
ListNet. main conclusion part that, according results obtained,
combining algorithms produce positive effects performance.
Finally, third part analysis devoted evaluate impact
candidate search stage candidate ranking results, impact found
significant.
766

fiEvaluation Link-Based Approaches Candidate Ranking Link-to-Wikipedia

Regarding potential future lines development work described paper,
first aspect consider evaluate impact quality context links
performance algorithms. also want analyze effect ignoring links
might introducing noise ranking process, like Lists. opposite case,
interested measuring impact including links pages namespaces,
like Categories, considered paper. sense, taking Categories
account open door use semantic relatedness measures based
information, like described Ponzetto Strube (2007).
According results paper, using ListNet combine algorithms produce
positive effects performance cases. However, exhaustive analysis different
combinations carried out. Thus, another potential line development could
exploring combinations algorithms, either taking advantage proposals
mechanisms feature selection learning rank (Geng, Liu, Qin, & Li, 2007)
empirically.
analyzed different algorithms perspective performance
link-to-Wikipedia task. computational complexity aspects addressed.
exhaustive analysis different algorithms along line left future work.
suggested section 4.1.3, link-to-Wikipedia systems integrated content
production workflows, interact human supervisors. Assessing
impact human factor final performance systems also constitute
area future research.
Finally, though paper centered attention candidate ranking
stage, link-to-Wikipedia systems usually include processing stages: identifying
anchors linked, searching candidate links anchors, deciding whether
link suggested (detect NIL answers). end-to-end evaluation including
additional processing stages also interesting line continue work reported
paper.

Acknowledgements
memoriam Concepcion Garca Alonso (1943-2012) passengers passed
away Angrois railway accident (24/Jul/2013).

References
Adibi, J., Cohen, P. R., & Morrison, C. T. (2004). Measuring confidence intervals link
discovery: bootstrap approach. Proceedings ACM Special Interest Group
Knowledge Discovery Data Mining (ACM-SIGKDD-04.
Apache Software Foundation (2014). Apache Lucene - Welcome Apache Lucene. Available
at: http://lucene.apache.org/.
Bagga, A., & Baldwin, B. (1998). Entity-based cross-document coreferencing using
Vector Space Model. Proceedings 17th international conference Computational linguistics - Volume 1, COLING 98, pp. 7985, Stroudsburg, PA, USA.
Association Computational Linguistics.
767

fiFernandez Garca, Arias Fisteus & Sanchez Fernandez

Bianchini, M., Gori, M., & Scarselli, F. (2005). Inside PageRank. ACM Trans. Internet
Technol., 5 (1), 92128.
Bizer, C., Lehmann, J., Kobilarov, G., Auer, S., Becker, C., Cyganiak, R., & Hellmann, S.
(2009). DBpedia - crystallization point Web Data. Web Semant., 7 (3),
154165.
Brin, S., & Page, L. (1998). anatomy large-scale hypertextual Web search engine.
Comput. Netw. ISDN Syst., 30 (1-7), 107117.
Budanitsky, A., & Hirst, G. (2006). Evaluating WordNet-based Measures Lexical Semantic Relatedness. Comput. Linguist., 32 (1), 1347.
Bunescu, R. C., & Pasca, M. (2006). Using Encyclopedic Knowledge Named entity
Disambiguation. Proceedings 11st Conference European Chapter
Association Computational Linguistics, EACL.
Cao, Y., Lin, C., & Zheng, G. (2011). MSRA TAC 2011: Entity Linking. Proceedings
Knowledge Base Population (KBP) track 4th Text Analysis Conference
(TAC). National Institute Standards Technololgy (NIST).
Cao, Z., Qin, T., Liu, T.-Y., Tsai, M.-F., & Li, H. (2007). Learning rank: pairwise
approach listwise approach. ICML 07: Proceedings 24th international
conference Machine learning, pp. 129136, New York, NY, USA. ACM.
Chang, A., Spitkovsky, V., Yeh, E., Aguirre, E., & Manning, C. (2010). Stanford-UBC Entity
Linking TAC-KBP. Proceedings Knowledge Base Population (KBP) track
3rd Text Analysis Conference (TAC).
Chen, Z., & Ji, H. (2011). Collaborative ranking: case study entity linking. Proceedings Conference Empirical Methods Natural Language Processing, EMNLP
11, pp. 771781, Stroudsburg, PA, USA. Association Computational Linguistics.
Cilibrasi, R. L., & Vitanyi, P. M. B. (2007). Google Similarity Distance. IEEE Trans.
Knowl. Data Eng., 19 (3), 370383.
Cucerzan, S. (2007). Large-Scale Named Entity Disambiguation Based Wikipedia Data.
Proceedings EMNLP-CoNLL 2007, pp. 708716.
Cucerzan, S. (2012). MSR System Entity Linking TAC 2012. Proceedings
Knowledge Base Population (KBP) track 5th Text Analysis Conference
(TAC).
da Silva, J. F., & Lopes, G. P. (1999). local maxima method fair dispersion normalization extracting multi-word units corpora. Sixth Meeting Mathematics
Language.
Dredze, M., McNamee, P., Rao, D., Gerber, A., & Finin, T. (2010). Entity disambiguation
knowledge base population. Proceedings 23rd International Conference
Computational Linguistics, COLING 10, pp. 277285, Stroudsburg, PA, USA.
Association Computational Linguistics.
Erbs, N., Zesch, T., & Gurevych, I. (2011). Link Discovery: Comprehensive Analysis.
Proceedings 2011 IEEE Fifth International Conference Semantic Computing,
ICSC 11, pp. 8386, Washington, DC, USA. IEEE Computer Society.
768

fiEvaluation Link-Based Approaches Candidate Ranking Link-to-Wikipedia

Fader, A., Soderland, S., & Etzioni, O. (2009). Scaling Wikipedia-based Named Entity
Disambiguation Arbitrary Web Text. Proceedings WikiAI 09 - IJCAI
Workshop: User Contributed Knowledge Artificial Intelligence: Evolving Synergy, Pasadena, CA, USA.
Fahrni, A., Nastase, V., & Strube, M. (2011). HITS Cross-lingual Entity Linking System
TAC 2011: One Model Languages. Proceedings Knowledge Base
Population (KBP) track 4th Text Analysis Conference (TAC). National Institute
Standards Technololgy (NIST).
Fernandez, N., Fisteus, J., Sanchez, L., & Martin, E. (2010). WebTLab: Cooccurence
based Approach KBP 2010 Entity-Linking Task. Proceedings Knowledge
Base Population (KBP) track 3rd Text Analysis Conference (TAC). National
Institute Standards Technololgy (NIST).
Fernandez, N., Blazquez, J. M., Fisteus, J. A., Sanchez, L., Sintek, M., Bernardi, A., Fuentes,
M., Marrara, A., & Ben-Asher, Z. (2006). NEWS: Bringing Semantic Web Technologies News Agencies. Semantic Web - ISWC 2006, Vol. 4273 Lecture
Notes Computer Science, pp. 778791. Springer Berlin Heidelberg.
Finkel, J. R., Grenager, T., & Manning, C. (2005). Incorporating Non-local Information
Information Extraction Systems Gibbs Sampling. Proceedings 43nd
Annual Meeting Association Computational Linguistics (ACL 2005), pp.
363370.
Geng, X., Liu, T.-Y., Qin, T., & Li, H. (2007). Feature selection ranking. Proceedings
30th annual international ACM SIGIR conference Research development
information retrieval, SIGIR 07, pp. 407414, New York, NY, USA. ACM.
Gentile, A., Zhang, Z., Xia, L., & Iria, J. (2009). Graph-based Semantic Relatedness
Named Entity Disambiguation. Proceeding 1st International Conference
Software, Services Semantic Technologies (S3T).
Getoor, L., & Diehl, C. P. (2005). Link mining: survey. SIGKDD Explor. Newsl., 7 (2),
312.
Gracia, J., & Mena, E. (2008). Web-Based Measure Semantic Relatedness. Proceedings
9th international conference Web Information Systems Engineering, WISE
08, pp. 136150.
Guo, Y., Tang, G., Che, W., Liu, T., & Li, S. (2011). HIT Approaches Entity Linking
TAC 2011. Proceedings Knowledge Base Population (KBP) track 4th
Text Analysis Conference (TAC). National Institute Standards Technololgy
(NIST).
Hachey, B., Radford, W., & Curran, J. R. (2011). Graph-based named entity linking
Wikipedia. Proceedings 12th international conference Web information
system engineering, WISE11, pp. 213226, Berlin, Heidelberg. Springer-Verlag.
Hachey, B., Radford, W., Nothman, J., Honnibal, M., & Curran, J. R. (2013). Evaluating
Entity Linking Wikipedia. Artificial Intelligence, 194 (0), 130 150.
Han, X., & Sun, L. (2011). generative entity-mention model linking entities
knowledge base. Proceedings 49th Annual Meeting Association
769

fiFernandez Garca, Arias Fisteus & Sanchez Fernandez

Computational Linguistics: Human Language Technologies - Volume 1, HLT 11, pp.
945954, Stroudsburg, PA, USA. Association Computational Linguistics.
Han, X., Sun, L., & Zhao, J. (2011). Collective entity linking web text: graph-based
method. Proceedings 34th international ACM SIGIR conference Research
development Information Retrieval, SIGIR 11, pp. 765774, New York, NY,
USA. ACM.
Han, X., & Zhao, J. (2009). Named entity disambiguation leveraging Wikipedia semantic
knowledge. Proceedings 18th ACM conference Information knowledge
management, CIKM 09, pp. 215224, New York, NY, USA. ACM.
Haveliwala, T. H. (2003). Topic-Sensitive PageRank: Context-Sensitive Ranking Algorithm Web Search. IEEE Trans. Knowl. Data Eng., 15 (4), 784796.
Huang, D. W., Xu, Y., Trotman, A., & Geva, S. (2008). Overview INEX 2007 Link
Wiki Track. Fuhr, N., Kamps, J., Lalmas, M., & Trotman, A. (Eds.), Focused
Access XML Documents, pp. 373387. Springer-Verlag, Berlin, Heidelberg.
Huang, D. W. C., Geva, S., & Trotman, A. (2009). Overview INEX 2008 Link
Wiki Track. Geva, S., Kamps, J., & Trotman, A. (Eds.), Advances Focused
Retrieval, Vol. 5631 Lecture Notes Computer Science, pp. 314325. Springer
Berlin Heidelberg.
Huang, W., Geva, S., & Trotman, A. (2010). Overview INEX 2009 Link Wiki
Track. Geva, S., Kamps, J., & Trotman, A. (Eds.), Focused Retrieval Evaluation, Vol. 6203 Lecture Notes Computer Science, pp. 312323. Springer Berlin
Heidelberg.
INEX (2014). INEX 2014 main page. Available at:
https://inex.mmci.uni-saarland.de/.
Ji, H., & Grishman, R. (2011). Knowledge base population: Successful approaches
challenges. Proceedings 49th Annual Meeting Association Computational Linguistics (ACL), pp. 11481158.
Ji, H., Grishman, R., & Dang, H. T. (2011). Overview TAC2011 Knowledge Base
Population Track. Proceedings Knowledge Base Population (KBP) track
4th Text Analysis Conference (TAC).
Ji, H., Grishman, R., Dang, H. T., Griffitt, K., & Ellis, J. (2010). Overview TAC2010
Knowledge Base Population Track. Proceedings Knowledge Base Population
(KBP) track 3rd Text Analysis Conference (TAC).
Jimenez, M., Fernandez, N., Fisteus, J., & Sanchez, L. (2013). WikiIdRank++: extensions
improvements WikiIdRank system entity linking. International Journal
Artificial Intelligence Tools, 22 (3).
Joachims, T. (2002). Optimizing search engines using clickthrough data. Proceedings
eighth ACM SIGKDD international conference Knowledge discovery data
mining, KDD 02, pp. 133142, New York, NY, USA. ACM.
Kulkarni, S., Singh, A., Ramakrishnan, G., & Chakrabarti, S. (2009). Collective annotation
Wikipedia entities web text. Proceedings 15th ACM SIGKDD inter770

fiEvaluation Link-Based Approaches Candidate Ranking Link-to-Wikipedia

national conference Knowledge discovery data mining, KDD 09, pp. 457466,
New York, NY, USA. ACM.
Lehmann, J., Monahan, S., Nezda, L., Jung, A., & Shi, Y. (2010). LCC Approaches
Knowledge Base Population TAC 2010. Proceedings Knowledge Base
Population (KBP) track 3rd Text Analysis Conference (TAC).
Li, X., Szpakowicz, S., & Matwin, S. (1995). WordNet-based algorithm word sense
disambiguation. Proceedings 14th international joint conference Artificial
intelligence - Volume 2, IJCAI95, pp. 13681374, San Francisco, CA, USA. Morgan
Kaufmann Publishers Inc.
Lin, W.-P., Snover, M., & Ji, H. (2011). Unsupervised language-independent name translation mining Wikipedia infoboxes. Proceedings First Workshop
Unsupervised Learning NLP, EMNLP 11, pp. 4352, Stroudsburg, PA, USA. Association Computational Linguistics.
Liu, T.-Y. (2009). Learning Rank Information Retrieval. Found. Trends Inf. Retr.,
3 (3), 225331.
Manning, C. D., Raghavan, P., & Schtze, H. (2008). Introduction Information Retrieval.
Cambridge University Press, New York, NY, USA.
Mihalcea, R., & Csomai, A. (2007). Wikify!: linking documents encyclopedic knowledge.
Proceedings sixteenth ACM conference Conference information
knowledge management, CIKM 07, pp. 233242, New York, NY, USA. ACM.
Miller, G. A. (1995). WordNet: lexical database English. Commun. ACM, 38 (11),
3941.
Milne, D., & Witten, I. H. (2008a). effective, low-cost measure semantic relatedness obtained Wikipedia links. Proceedings first AAAI Workshop
Wikipedia Artificial Intelligence (WIKIAI08).
Milne, D., & Witten, I. H. (2008b). Learning link Wikipedia. Proceedings
17th ACM conference Information knowledge management, CIKM 08, pp.
509518, New York, NY, USA. ACM.
MSNBC (2014). MSNBC: news, video progressive community. Available at:
http://www.msnbc.msn.com.
National Institute Standards Technology (2014a). Text Analysis Conference (TAC).
Available at: http://www.nist.gov/tac/.
National Institute Standards Technology (2014b). Text Analysis Conference (TAC)
KBP 2014 Tracks. Available at: http://www.nist.gov/tac/2014/KBP/.
Navigli, R. (2009). Word sense disambiguation: survey. ACM Comput. Surv., 41 (2),
10:110:69.
Navigli, R., & Lapata, M. (2010). Experimental Study Graph Connectivity
Unsupervised Word Sense Disambiguation. IEEE Trans. Pattern Anal. Mach. Intell.,
32 (4), 678692.
771

fiFernandez Garca, Arias Fisteus & Sanchez Fernandez

Nguyen, H., & Cao, T. (2010). Exploring Wikipedia Text Features Named Entity
Disambiguation. Nguyen, N., Le, M., & Swiatek, J. (Eds.), Intelligent Information
Database Systems, Vol. 5991 Lecture Notes Computer Science, pp. 1120.
Springer Berlin / Heidelberg.
Nothman, J., Murphy, T., & Curran, J. R. (2009). Analysing Wikipedia gold-standard
corpora NER training. Proceedings 12th Conference European
Chapter Association Computational Linguistics, EACL 09, pp. 612620,
Stroudsburg, PA, USA. Association Computational Linguistics.
Page, L., Brin, S., Motwani, R., & Winograd, T. (1999). PageRank Citation Ranking:
Bringing Order Web. Technical report 1999-66, Stanford InfoLab.
Pilz, A. (2010). Entity Disambiguation using Link based Relations extracted
Wikipedia. First Workshop Automated Knowledge Base Construction (AKBC
2010), Grenoble, France.
Ploch, D., Hennig, L., de Luca, E. W., & Albayrak, S. (2011). DAI Approaches
TAC-KBP 2011 Entity Linking Task. Proceedings Knowledge Base Population (KBP) track 4th Text Analysis Conference (TAC). National Institute
Standards Technololgy (NIST).
Ponzetto, S. P., & Strube, M. (2007). Knowledge derived Wikipedia computing
semantic relatedness. J. Artif. Int. Res., 30 (1), 181212.
Radford, W., Hachey, B., Nothma, J., Honnibal, M., & Curran, J. (2010). CMCRC
TAC 2010: Document-level Entity Linking graph-based re-ranking. Proceedings 3rd Text Analysis Conference (TAC), National Institute Standards
Technology, NIST, Maryland, USA.
Ratinov, L., Roth, D., Downey, D., & Anderson, M. (2011). Local global algorithms
disambiguation Wikipedia. Proceedings 49th Annual Meeting
Association Computational Linguistics: Human Language Technologies - Volume
1, HLT 11, pp. 13751384, Stroudsburg, PA, USA. Association Computational
Linguistics.
Sil, A. (2013). Exploring Re-ranking Approaches Joint Named-entityrecognition
Linking. Proceedings Sixth Workshop Ph.D. Students Information
Knowledge Management, PIKM 13, pp. 1118.
Spitzer, F. (1976). Principles Random Walk (2nd Edition). Springer.
Van B. Dang (2014). RankLib (software package). Available at:
http://people.cs.umass.edu/vdang/ranklib.html.
Vanwinckelen, Gitte; Blockeel, H. (2012). estimating model accuracy repeated
cross-validation. Proceedings 21st Belgian-Dutch Conference Machine
Learning, pp. 3944.
Voorhees, E. (1999). TREC-8 Question Answering Track Report. Proceedings 8th
Text Retrieval Conference, pp. 7782.
Wikinews (2014a). Wikinews Random Page Generator. Available at:
http://en.wikinews.org/wiki/Special:Random.
772

fiEvaluation Link-Based Approaches Candidate Ranking Link-to-Wikipedia

Wikinews (2014b). Wikinews, free news source. Available at:
http://en.wikinews.org/.
Wikipedia (2014a). Wikipedia Random Page Generator. Available at:
http://en.wikipedia.org/wiki/Special:Random.
Wikipedia (2014b). Wikipedia:Namespace - Wikipedia, free encyclopedia. Available at:
http://en.wikipedia.org/wiki/Wikipedia:Namespace.
Yeh, E., Ramage, D., Manning, C. D., Aguirre, E., & Soroa, A. (2009). WikiWalk: random
walks Wikipedia semantic relatedness. Proceedings 2009 Workshop
Graph-based Methods Natural Language Processing, TextGraphs-4, pp. 4149,
Stroudsburg, PA, USA. Association Computational Linguistics.

773

fiJournal Artificial Intelligence Research 49 (2014) 269321

Submitted 09/13; published 02/14

Efficient HEX-Program Evaluation Based Unfounded Sets
EITER @ KR . TUWIEN . AC .
FINK @ KR . TUWIEN . AC .
TKREN @ KR . TUWIEN . AC .

Thomas Eiter
Michael Fink
Thomas Krennwallner
Christoph Redl

REDL @ KR . TUWIEN . AC .

Institut fur Informationssysteme
Technische Universitat Wien
Favoritenstrae 9-11, A-1040 Vienna, Austria
PETERSCHUELLER @ SABANCIUNIV. EDU

Peter Schuller
Faculty Engineering Natural Sciences
Sabanci University
Orhanli, Tuzla, 34956 Istanbul, Turkey

Abstract
HEX-programs extend logic programs answer set semantics external computations external atoms. reasoning ground Horn programs nonmonotonic external atoms polynomial complexity already second level polynomial hierarchy,
minimality checking answer set candidates needs special attention. end, present
approach based unfounded sets generalization related techniques ASP programs.
unfounded set detection expressed propositional SAT problem, provide two
different encodings optimizations them. integrate approach previously
developed evaluation framework HEX-programs, enriched additional learning techniques aim avoiding reconstruction related unfounded sets. Furthermore,
provide syntactic criterion allows one skip minimality check many cases.
experimental evaluation shows new approach significantly decreases runtime.

1. Introduction
Answer Set Programming (ASP) declarative problem solving approach. Due expressive
extensions efficient systems like SMODELS (Simons, Niemela, & Soininen, 2002), DLV (Leone,
Pfeifer, Faber, Eiter, Gottlob, Perri, & Scarcello, 2006) CLASP (Gebser, Kaufmann, & Schaub,
2012), gaining popularity many applications (Brewka, Eiter, & Truszczynski, 2011).
However, current trends computing, context awareness distributed systems, raised
need access external sources program. instance, external sources Web range
light-weight data access (e.g., XML, RDF, data bases) knowledge-intensive formalisms
(e.g., OWL ontologies).
cater need, Eiter, Ianni, Schindlauer, Tompits (2005) defined HEX-programs
extension ASP so-called external atoms, user couple external
information source logic program. Roughly, atoms pass information, given predicate extensions, program external source returns output values (abstract)
function computes. example, rule nb(X, ) &neighbor [0 map 0 , X](Y ) may informally import point X map stored file map (in particular data format),
point neighborhood X predicate nb. convenient external access
c
2014
AI Access Foundation. rights reserved.

fiE ITER , F INK , K RENNWALLNER , R EDL , & CH ULLER

exploited many applications, including querying data ontologies (Eiter et al., 2008b; Hoehndorf et al., 2007; Marano et al., 2010), e-government (Zirtiloglu & Yolum, 2008), fuzzy answer set
programming (Nieuwenborgh, Cock, & Vermeir, 2007a), multi-context reasoning (Brewka & Eiter,
2007; Eiter et al., 2012b), (Nieuwenborgh et al., 2007b; Basol et al., 2010). formalism highly
expressive recursive data exchange rules external sources possible.
semantics HEX-programs model-based given answer sets following approach Faber, Leone, Pfeifer (2011), extends answer set semantics logic programs (Gelfond & Lifschitz, 1991) logic programs aggregates; Faber et al. approach
(known FLP semantics) preserves property answer sets have, spirit
closed world assumption, smallest positive information content, formally captured
minimality condition models.
current approach evaluation HEX-programs (Eiter et al., 2006a, 2011) rewrite
given HEX-program answer set program (i) eliminating external atoms favor auxiliary
atoms using called replacement atoms, (ii) introducing auxiliary rules answer
sets HEX-program correspond subset answers sets resulting program
auxiliary atoms faithfully represent values external atoms; compatibility
condition answer set tested postcheck.
computing answer sets (disjunctive) logic program P like , different methods
proposed. immediate one implement definition answer set test whether
given interpretation minimal model called reduct program P wrt. interpretation; end, suitable candidate answer set might guessed generated heuristics.
approach essentially adopted solvers G N (Janhunen et al., 2006) CMODELS
(Lierler, 2005), use test logic program, respectively SAT encoding. different
approach presented Leone et al. (1997) based notion unfounded set (Van Gelder,
Ross, & Schlipf, 1991), extended normal (non-disjunctive) disjunctive logic
programs. Intuitively, set U atoms unfounded wrt. model program P , switching
atoms U false lead violated rules; answer sets P models
unfounded-free, i.e., models disjoint respective unfounded sets. checking
(un)foundedness given candidate answer set, Koch et al. (2003) presented SAT encoding.
Drescher et al. (2008) later exploited findings Leone et al. extend technique
conflict-driven clause learning used CLASP solver disjunctive logic programs.
quoted works, however, access external sources issue, thus
cannot deployed HEX-programs. fact, addition compatibility check answer set
replacement program , current HEX evaluation must second step test minimality
interpretation induced HEX-program wrt. program reduct. method,
refer explicit FLP check, turns less efficient practice, often dominates
total runtime; thus efficient method desirable.
Motivated seminal approach Leone et al., consider paper use
unfounded sets alternative explicit FLP check HEX-programs, refer
unfounded set check. end, extend notion unfounded sets disjunctive logic
programs HEX-programs, following lines Faber (2005), unfounded sets logic
programs aggregates defined, consider use combination clause learning
techniques. main contributions summarized follows:
present basic encoding unfounded set existence set nogoods, i.e., constraints
satisfied, show solutions 1-1 correspondence
270

fiE FFICIENT HEX-P ROGRAM E VALUATION BASED U NFOUNDED ETS

unfounded sets. latter thus computed running SAT solver, followed postprocessing step checks values replacement atoms compatible
external call results. Benchmarks show strategy already efficient
explicit FLP check.
present advanced encoding unfounded set existence reusable
interpretation. Compared first encoding, conceptually involved
(slightly) higher initialization cost, advantage reused unfounded set checks needs separate initialization check. benchmarks show
advanced encoding superior first one many practical problems.
Next, consider optimizations hinge dependencies external ordinary
atoms determined careful analysis. optimizations integrated
encodings adding nogoods restrict search space relevant parts.
consider exploit information gained unfounded set check candidate answer set answer set candidate generation, i.e., evaluation program . Adopting Conflict Driven Clause Learning approach (Drescher et al., 2008), step
recently enhanced external behavior learning (Eiter et al., 2012a), nogoods describing external source behavior learned search guide model generation
towards proper guesses. show learn candidate generation step additional
nogoods unfounded sets avoid reconstruction related unfounded
sets, yielding gain.
present syntactic decision criterion used decide whether program possibly unfounded sets. result check negative, computationally
expensive search unfounded sets skipped entirely. criterion based atom
dependency and, loosely speaking, says cyclic dependencies ground atoms
external atoms. property efficiently checked given ground HEXprogram using standard methods. fact applies range applications, particular
input-stratified programs, external sources accessed workflow produce input next stage computation. However, advanced applications HEX-programs
cycles external atoms, e.g., natural encodings problems multi-context
systems (Brewka & Eiter, 2007) abstract argumentation systems (Dung, 1995),
FLP check simply skipped.
elaboration, consider program decomposition based dependency
graph induced program (note exploiting syntactic modularization unfounded sets traced back Leone et al., 1997; Koch et al., 2003). show
unfounded set wrt. candidate answer set exactly components C
decomposition unfounded set wrt. A; computing decomposition
realized efficiently incur large overhead, apply decision criterion
skipping FLP check efficiently finer-grained level, search unfounded sets
guided relevant program parts.
experimental evaluation advanced reasoning applications shows unfounded sets
checking combined learning methods Eiter et al. (2012a) improves HEX-program
evaluation considerably, sometimes drastically. specifically, benchmark applications
271

fiE ITER , F INK , K RENNWALLNER , R EDL , & CH ULLER

include reasoning tasks Multi-Context Systems (Brewka & Eiter, 2007; Eiter et al., 2012b),
abstract argumentation (Dung, 1995), terminological default reasoning description logic
knowledge bases (Baader & Hollunder, 1995), conformant planning (Goldman & Boddy,
1996; Smith & Weld, 1998). experiments carried DLVHEX version
2.3.0, prototype solver HEX-programs, extended support techniques
developed paper. decomposition approach yield considerable gain,
appears e.g. HEX-encoding Dung-style argumentation semantics (Dung, 1995)
DL-programs (Eiter et al., 2008a). hand, terminological default
reasoning benchmark, syntactic criterion lets us conclude FLP check obsolete.
conclusion, new approach enables significant speedup thus enlarges scope
HEX applicability.
1.1 Organization
rest paper organized follows. next section provides preliminaries HEXprograms evaluation via answer sets transformed ASP program without external
atoms. Section 3, define unfounded sets present basic uniform encoding
unfounded set search using nogoods. Section 4 considers refinements optimizations
encodings, well external behavior learning prevent reconstruction unfounded sets.
Section 5, give syntactic decision criterion avoid FLP check program decomposition method exploiting it. Experimental results prototype implementation reported
Section 6. Section 7, consider related work extensions approach. Section 8,
conclude point issues research.

2. Preliminaries
section, start basic definitions, introduce HEX-programs.
accordance Gebser et al. (2012) Eiter et al. (2012a), (signed) literal positive
negative formula Ta resp. Fa, ground atom form p(c1 , . . . , c` ), predicate p
constants c1 , . . . , c` , abbreviated p(c). literal = Ta = Fa, let denote opposite, i.e.,
Ta = Fa Fa = Ta. assignment (finite) set atoms consistent set signed
literals Ta Fa, Ta expresses true Fa false; complete,
also called interpretation, assignment A0 exists. denote = {a | Ta A}
AF = {a | Fa A} set atoms true resp. false A, ext(q, A) = {c |
Tq(c) A} extension predicate q A. Furthermore, A|q set literals
atoms predicate q A. ForSa list q = q1 , . . . , qk predicates, write p q iff qi = p
1 k, let A|q = j A|qj .
nogood set {L1 , . . . , Ln } signed literals Li , 1 n. interpretation
solution nogood (resp. set nogoods), iff 6 (resp. 6 ).
Example 1 interpretation = {Ta, Fb, Tc} solution nogood {Ta, Tb, Tc}
{Ta, Fb, Tc}.
2.1 HEX-Programs
Next, recall syntax semantics HEX-programs.
272

fiE FFICIENT HEX-P ROGRAM E VALUATION BASED U NFOUNDED ETS

2.1.1 HEX -P ROGRAM YNTAX
introduced Eiter et al. (2005), HEX-programs generalization (disjunctive) extended
logic programs answer set semantics (Gelfond & Lifschitz, 1991). HEX-programs extend
ASP programs external atoms, enable bidirectional interaction program
external sources computation. External atoms list input parameters (constants predicate names) list output parameters. Informally, evaluate external atom, reasoner
passes constants extensions predicates input tuple external source associated external atom. external source computes output tuples matched
output list. Syntactically, ground external atom form
&g[p](c),

(1)

&g external predicate, p = p1 , . . . , pk input list consisting predicate names
object constants, c = c1 , . . . , cl output list consisting constant terms. Predicates
input list sometimes called input predicates.
default literal formula b b, b ground ordinary atom form p(c1 , . . . , c` )
constants ci , 1 `, external atom. every set ordinary external atoms,
let = {not b | b S}.
Ground HEX-programs defined similar ground ASP programs.
Definition 1 (Ground HEX-programs) ground HEX-program consists rules
a1 ak b1 , . . . , bm , bm+1 , . . . , bn ,

(2)

ai ordinary ground atom, bj either ordinary ground atom ground
external atom, k + n > 0.1
rule r, head H(r) = {a1 , . . . , ak } body B(r) = B + (r) B (r),
B + (r) = {b1 , . . . , bm } positive body, B (r) = {bm+1 , . . . , bn } negative body.
B(r) = , r fact, omit . program , let A() set ordinary
atoms EA() set external atoms occurring . default literal b, let tb = Ta
b = atom a, tb = Fa b = a. Furthermore, f b = Fa b = f b = Ta
b = a.
call rule r constraint, B(r) = .
Example 2 rule r = ab c, H(r) = {a, b}, B + (r) = {c} B (r) = {d}.
tc = Tc, f c = Fc, = Fd f = Td.
also consider non-ground programs (i.e., variables allowed place object constants) examples. particular, external atoms &g[X](Y) may contain variables
input list X output list Y. programs, suitable safety conditions allow using
grounding procedure transforms program variable-free program answer sets (Eiter, Ianni, Schindlauer, & Tompits, 2006). However, limit formal investigation
ground programs.
1. simplicity, formally introduce strong negation view, customary, classical literals new
atoms together constraint disallows simultaneously true.

273

fiE ITER , F INK , K RENNWALLNER , R EDL , & CH ULLER

Example 3 program
domain(a); domain(b)
sel (X) domain(X), nsel (X)

nsel (X) domain(X), sel (X)

encodes problem partitioning two domain elements b two sets sel nsel .
2.1.2 HEX -P ROGRAM EMANTICS
ordinary ground atom true relative assignment A, denoted |= a, Ta
false otherwise. default-negated ground atom true relative assignment A, denoted
|= a, Fa false otherwise.
semantics ground external atom form (1) wrt. interpretation given
value 1+k+l-ary Boolean oracle function f&g defined possible values A, p
c, &g[p](c) true relative A, denoted |= &g[p](c), f&g (A, p, c) = 1.
Example 4 (Set Partitioning) Consider program

sel (a) domain(a), &diff [domain, nsel ](a)

nsel (a) domain(a), &diff [domain, sel ](a)

domain(a)

predicates p q, &diff [p, q](X) computes set elements X
extension p extension q. Informally, program implements choice
sel (a) nsel (a).
Satisfaction ordinary rules ASP programs (Gelfond & Lifschitz, 1991) extended
programs obvious way: rule r satisfied assignment A, denoted |= r,
iff |= h h H(r), 6|= b b B + (r), |= b b B (r).
program satisfied assignment iff |= r r . interpretation model
program , denoted |= , iff |= r r .
notion extension ext(, A) external predicates &g input lists p naturally
defined ext(&g[p], A) = {c | f&g (A, p, c) = 1}.
HEX -rules

Definition 2 (FLP-Reduct (Faber et al., 2011)) interpretation program ,
FLP-reduct wrt. set f = {r | |= b, b B(r)} rules whose
body satisfied A.
assignment A1 smaller equal another assignment A2 wrt. program , denoted
A1 A2 , iff {Ta A1 | A()} {Ta A2 | A()}.
Definition 3 (Answer Set) answer set -minimal model f .
Example 5 Consider program :

p &id [q]()
qp

f&id (A, p) = 1 iff Tp true. answer set A1 = ; indeed
-minimal model f A1 = . Note A2 = {Tp, Tq} answer set ,
minimal model f A2 = .
274

fiE FFICIENT HEX-P ROGRAM E VALUATION BASED U NFOUNDED ETS

2.2 Evaluation HEX-Programs
possible way determine answer sets HEX-program use transformation
ASP program without external atoms whose answer sets encompass answer sets .
describe transformation. external atom = &g[p](c) rule r replaced
ordinary ground replacement atom = e&g[p] (c) (resulting rule r), additional
rule e&g[p] (c) ne &g[p] (c) added program. answer sets resulting guessing
program determined ASP solver projected non-replacement atoms. However,
resulting assignments might spurious answer sets , values &g[p] e&g[p] (c)
relative interpretation may coincide. answer set thus merely candidate
must checked external sources. discrepancy found, model candidate
compatible set . precisely,
Definition 4 (Compatible Set) compatible set program assignment
(i) answer set (Gelfond & Lifschitz, 1991) guessing program ,
(ii) f&g (A, p, c) = 1 iff Te&g[p] (c) external atoms &g[p](c) , i.e., guessed
values coincide values oracle functions.
subset compatible sets represents answer sets , answer set
given restriction unique compatible set non-replacement atoms.
formally, answer set program corresponds compatible set
(, A) = {Tea , Fne | external atom , |= e}

{Fea , Tne | external atom , 6|= e} .

filter compatible sets yield answer sets, compatible set
checked models FLP reduct. specific, procedure called explicit FLP
check constructs reduct f checks whether model A0 smaller A;
A0 found, rejects A, otherwise outputs answer set.
explicit FLP check rewrites HEX-program ASP program without external atoms
amounts search answer sets following program, truth values
replacement atoms coincide according oracle function values:
Check (, A) = f { | A(), Ta 6 A} {a a0 | Ta A}
{ smaller } {smaller | A(), Ta A} .
consists reduct f rules restrict search proper subinterpretations A,
smaller new atom. Moreover, actually need search models
compatible sets, rules form a0 (where a0 new atom Ta A) make sure
atoms arbitrarily true without justifying rule .
Proposition 1 Let interpretation extracted compatible set program .
program Check (, A) answer set A0 f&g (A0 , p, c) = 1 iff Te&g[p] (c) A0
external atoms &g[p](c) , answer set .
guessing rules, rewrite rules f except guesses replacement
atoms constraints follows:
CheckOptimized (, A) = fA { | A(), Ta 6 A} {a a0 | Ta A}
{ smaller } {smaller | A(), Ta A}.
275

fiE ITER , F INK , K RENNWALLNER , R EDL , & CH ULLER

add external replacement
atoms + guessing rules




Step S1

External Atom
Evaluation

Main Search (CDNL)

Plugin
1

Model Candidates
check unverified
external atom guesses

..
.

Compatible Sets

Step S2

FLP Check
(Unfounded Set Check)

Answer
Sets

Plugin
k

Figure 1: Overview framework evaluating HEX-programs.
fA denotes FLP reduct wrt. interpretation rule form (2) except
guessing rules replacement atoms rewritten
a1 , . . . , ak , b1 , . . . , bm , bm+1 , . . . , bn .
Proposition 2 Let interpretation extracted compatible set program .
program CheckOptimized (, A) answer set A0 f&g (A0 , p, c) = 1
Te&g[p] (c) A0 external atoms &g[p](c) , answer set .
program efficient evaluation. comparison Section 6 uses optimized
version explicit check, still demonstrates significant performance gain novel
approach.
Example 6 (contd) Reconsider program = { p &id [q](); q p } above.
corresponding guessing program = {p e&id[q] (); q p; e&id[q] ()ne &id[q] () } yields
compatible sets A1 = A2 = {Tp, Tq, Te&id[p] }. A1 = also -minimal
model f A1 = , A2 = {Tp, Tq} -minimal model f A2 = . Indeed,
program
Check (, A2 ) = {p p0 ; q q 0 ; e&id[q] () e0&id[q] () } { smaller }

{smaller p} {smaller q; smaller e&id[q] ()}

answer set A0 =

n

Fp, Tp0 , Fq, Tq 0 , Fe&id[q] (), Tne &id[q] (), Te0&id[q] (), Tsmaller

f&id (A0 , q, ) = 0 Fe&id[q] () A0 .
276

fiE FFICIENT HEX-P ROGRAM E VALUATION BASED U NFOUNDED ETS


compatible
set

Basic
Encoding

Uniform
Encoding





Assumptions

AA

search UFS
candidates
FLP Checks
verify
candidate

Main Search
(CDNL)

External
Atom
Evaluation

UFS
unfounded free

Figure 2: FLP Check based Unfounded Sets

complete prodedure computing answer sets HEX-programs described Eiter
et al. (2012a) shown block diagram Figure 1; first version introducing approach
DLVHEX version 2.1.0. Step S1 enumerates compatible sets; reuse part evaluation
process prior work modify it. Step S2 checks whether compatible set indeed
HEX answer set. improvement efficiency S2 focus work. S1 transforms
input program introducing replacement atoms guesses replacement atoms.
main search enumerates model candidates, i.e., answer sets . (Depending heuristics,
search evaluate external atoms guiding search.) Model candidates verified
semantics external atoms. check fails, main search continues enumerate model
candidates; check succeeds, model candidate compatible set. S2 checks whether
compatible set answer set . Previous work realized step using explicit FLP check.
work propose two alternatives carry FLP check based unfounded sets.
Figure 2 depicts block diagram FLP checks proposed work, called basic
uniform encoding. encodings SAT theories. basic encoding builds program
compatible set A. uniform encoding based (hence reuse
compatible sets), however requires us set solver assumptions based A. encoding
(and assumptions) used search unfounded set (UFS) candidates (by SAT solver).
UFS candidate verified values external atoms (these guessed UFS
encoding). UFS candidates fail external atom check, UFS candidates,
unfounded-free compatible set hence answer set . Otherwise FLP check
found unfounded set wrt. main search continues looking new model candidate.
next describe encodings UFS-checking.
277

fiE ITER , F INK , K RENNWALLNER , R EDL , & CH ULLER

3. Unfounded Set Detection
described Section 2.2, minimality check, also called explicit FLP check, computationally costly involves much overhead: models Check (, A) must enumerated,
calls external sources test compatibility must made. Even worse, need
search smaller model smaller compatible set, Check (, A) usually (to
experience) even models original program. Moreover, appears many
current application scenarios smaller model reduct f , i.e., assignments
extracted compatible sets pass FLP check. two possible reliefs: developing
cheaper minimality check avoid minimality check possible. section targets
former idea, latter one addressed Section 5.
end, present novel FLP check algorithm based unfounded sets (UFS). Instead
explicitly searching smaller models reduct, check whether candidate answer set
unfounded-free. end, use unfounded sets HEX-programs akin Faber (2005)
programs arbitrary aggregates.
Definition 5 (Unfounded Set) Given program assignment A, let X set ordinary ground atoms appearing . Then, X unfounded set wrt. if, rule
r
atoms X head, least one following conditions holds,
.
.X = (A \ {Ta | X}) {Fa | X}:
(i) literal B(r) false wrt. A,
.

(ii) literal B(r) false wrt. .X,
(iii) atom H(r) \ X true wrt. A.
Intuitively, unfounded set set atoms circularly support other;
assigning false, violation rule introduced. answer sets,
minimality enforces subset atoms true answer set form unfounded set; fact, answer sets characterized terms unfounded sets, using following
notion.
Definition 6 (Unfounded-free Interpretations) interpretation program unfoundedfree, iff X = , every unfounded set X wrt. A.
following result generalization respective result ordinary (disjunctive) logic
programs (Leone et al., 1997) logic programs aggregates (Faber, 2005).
Theorem 3 (Characterization Answer Sets) model HEX-program answer set
iff unfounded-free.
Example 7 Consider program A1 Example 6. Trivially, A1 unfounded-free,
thus A1 answer set . hand, set X. = {p, q} unfounded set w.r.t. A2 ,
since X intersects head p &id [q]() .X 6|= &id [q](). Therefore A2
unfounded-free answer set .
278

fiE FFICIENT HEX-P ROGRAM E VALUATION BASED U NFOUNDED ETS

3.1 Basic Encoding Unfounded Set Search
realize search unfounded sets using nogoods, i.e., given assignment
construct set nogoods, solutions set correspond (potential) unfounded sets;
use SAT solver search unfounded sets.
specifically, encoding unfounded set detection uses set



= N, O, ,
contains necessary constraints set optional optimization
nogoods N,
,
nogoods prune irrelevant parts search space; latter related one Drescher
et al. (2008) respects external atoms. idea set ordinary atoms solution

represents (potential) unfounded set U wrt. A, .while replacement atoms encode
truth values corresponding external atoms .U .
rule r, let Bo+ (r) B + (r) consist ordinary atoms, let (r) B(r) consist

external replacement atoms. Then,
built atoms A( ) = A() {hr , lr | r },
hr , lr new atoms every rule r . necessary part


= {{Fa | Ta A}}
N,
r Rr,A


consists nogood {Fa | Ta A}, eliminates unfounded sets intersect
true atoms A, nogoods Rr,A = Hr,A Cr,A every r
Hr,A = {{Thr } {Fh | h H(r)}} {{Fhr , Th} | h H(r)}, called head criterion,
encodes
hr true rule r iff atom H(r) unfounded set;

{{Thr }



{Fa | B + (r), |= a} {ta | B (r)}
e

Cr,A =

{Th
|
h

H(r),

|=
h}}
|= B(r),



{}
otherwise,
called conditional part Cr,A , encodes Condition (i), (ii) (iii) Definition 5 must
hold hr true.
specifically, unfounded set U rule r H(r) U 6= (hr true) must
happen |= B(r) (Condition
(i) fails), Bo+ (r) |= unfounded set
.
(r) true .U (Condition (ii) fails), h H(r) |= h
,A
defined Section 4.
unfounded set (Condition (iii) fails). Concrete instances
Example 8 Consider = {r1 : p &id [p]()} compatible set = {Tp, Te&id[p] }.
A2
nogood set N,
{{Thr1 , Fp}, {Fhr1 , Tp}, {Thr1 , Te&id[p] (), Tp}}.

Towards computing unfounded sets, observe every unfounded set extended solution


nogood set
A( ). Conversely, solutions include specific extensions
unfounded sets, given unfounded set U assigning true atoms U , hr
H(r) intersects U , replacement atoms e&g[p] (c) &g[p](c) true
.
.U , assigning false atoms A(A
). formally,
Definition 7 (Induced Assignment Unfounded Set wrt.
) Let U unfounded set

program wrt. assignment A. assignment induced U wrt.
, denoted (U, , , A),

0

0
(U,
, , A) = (U, , A) {Fa | A( ), Ta 6 (U, , A)} ,
279

fiE ITER , F INK , K RENNWALLNER , R EDL , & CH ULLER


I0 (U, , A) = {Ta | U } {Thr | r , H(r) U 6= }
.
{Te&g[p] (c) | &g[p](c) EA(), .U |= &g[p](c)} .
call set N nogoods conservative, holds every unfounded set U wrt.

(U,
, , A) solution N . show solutions include assignments
,A
induced unfounded sets wrt. A, assuming conservative.
Proposition 4 Let U unfounded set program wrt. assignment U 6= .

(U,
, , A) solution .
Note converse hold, i.e., every solution corresponds induced assignment; intuitively reflect semantics external sources. Regardless
immediately obtain Proposition 4 useful test unfounded-freeness.

Corollary 5
solution, U = every unfounded set U .

Using following result, find unfounded sets wrt. among solutions

using postcheck external atoms.
Theorem 6 Let solution

.

(a) Te&g[p] (c) 6|= &g[p](c) implies .U |= &g[p](c);
.

(b) Fe&g[p] (c) |= &g[p](c) implies .U 6|= &g[p](c)
U = {a | A(), Ta S}. U unfounded set wrt. A.
Informally, proposition states non-replacement atoms true also
appear form unfounded set, provided truth replacement atoms e&g[p] (c) co.
incides truth corresponding &g[p](c) .U (as Definition 7). However,
check required truth values e&g[p] (c) &g[p](c) differ.
gives rise important optimization implementation: external atoms, whose (known) truth
value &g[p](c) matches truth value e&g[p] (c) S, need postchecked.
follows immediately Definition 7 postcheck eliminate unfounded sets,
formalized following proposition.
Proposition 7 Let U unfounded set program wrt. assignment U 6= .
(U,
, , A) fulfills Conditions (a) (b) Theorem 6.
Example 9 Reconsider program = {r1 : p &id [p]()} Example 8 compatible set
A2
A2 = {Tp, Te&id[p] }. nogood set N,
= {{Thr1 , Fp}, {Fhr1 , Tp}, {Thr1 , Te&id[p] (), Tp}}
solutions {Thr1 , Tp, Fe&id[p] ()}, correspond unfounded set U = {p}. Here,
.
Fe&id[p] () represents A2 .U 6|= &id [p]().
Note due premises Conditions (a) (b) Theorem 6, postcheck faster
Te&g[p] (c) whenever |= &g[p](c) holds many external atoms .
exploited construction follows: absolutely necessary set truth
value e&g[p] (c) differently, carry value &g[p](c) A. Specifically,
successful e&g[p] (c) occur
.
280

fiE FFICIENT HEX-P ROGRAM E VALUATION BASED U NFOUNDED ETS

3.2 Uniform Encoding Unfounded Set Search
encoding
presented previous subsection disadvantage depends
current assignment A. Therefore needs generated separately every unfounded set
check assignment changed (which likely). causes significant overhead,
present advanced encoding reused assignment. introduce
additional variables represent truth values atoms current assignment. Prior
unfounded set check, current assignment injected setting values variables
fixed values, done using assumptions supported modern SAT solvers
CLASP. Changing assumptions much easier changing encoding, leads
additional speedup cases, especially programs need many unfounded set checks.
advanced encoding uses set nogoods. before, idea set ordinary
atoms solution represents (potential) unfounded set U wrt. assignment A,.
replacement atoms encode truth values corresponding external atoms
.U . encoding conceptually complex
; initialization computationally
(slightly) costly, hence advantages new encoding become visible instances
many compatible sets (thus many unfounded set checks), might counterproductive
small instances.
nogood set built atoms fresh atoms occurring :
hr lr , every rule r , aA every ordinary atom A() (i.e. ordinary atoms
.
replacement atom auxiliaries), aA.U
, aAU , aAU every ordinary atom A().
.
auxiliary atoms aA , aA.U
, aAU , aAU used make encoding usable assignment
A. unfounded set check respect certain assignment, temporarily
add assumptions solver force certain truth values atoms aA A()
depending current
assignment A. Intuitively, aA represents truth value
.
.
aA.U .U (where U current unfounded set), aAU represents true
contained U , aAU represents false contained U .
end, set assumptions consistent set signed literals. solution
nogood resp. set nogoods satisfies A, A. is, assumptions fix truth value
atoms. Modern ASP SAT solvers support assumptions natively, easily
undone without complete reset reasoner recreating whole problem instance.
essential feature efficiently implementing improved encoding.
encoding
= N, O, ,


N, = {{Fa | A()}} aA() Da r (Hr Cr ) necessary part
{Fa | A()} encodes search nonempty unfounded set;



{FaAU , TaA , Ta}, {TaAU , FaA }, {TaAU , Fa}
Da =
{FaAU , FaA }, {FaAU , Ta}, {TaAU , TaA , Fa}



.
.
.
{TaA.U
, FaA }, {TaA.U
, Ta}, {FaA.U
, TaA , Fa}

encodes aAU true iff aA true, aAU true iff aA false true,
.
aA.U
true iff aA true false;

Hr = {{Thr } {Fh | h H(r)}} {{Fhr , Th} | h H(r)}
encodes hr true rule r iff atom H(r) unfounded set;
281

fiE ITER , F INK , K RENNWALLNER , R EDL , & CH ULLER



{{Thr }



{Ta | B + (r)} {Fa | B (r)}


Cr =
+ (r)} {ta | B (r)}

{Fa
|


B
e

AU



{Th
|
h

H(r)}}
AU

(i)
(ii)
(iii)

encodes hr true, one (i), (ii) (iii) Definition 5 must hold.
specifically, unfounded set U rule r H(r) U 6= (hr true)
must happen |= B(r) (Condition (i) fails),. Bo+ (r) |=
unfounded set (r) true .U (Condition (ii) fails),
h H(r) |= h unfounded set (Condition (iii) fails).

Example 10 = {r1 : p &id [p]() } Example 6, constructed nogood set
= {{Fp}, {FpAU , TpA , Tp}, {TpAU , FpA }, {TpAU , Fp},

.
, FpA },
{FpAU , Fp}, {FpAU , Tp}, {TpAU , TpA , Fp}, {TpA.U

.
.
{TpA.U
, Tp}, {FpA.U
, TpA , Fp},

{Thr1 , Fp}, {Fhr1 , Tp}, {Thr1 , Te&id[p] ()A , Te&id[p] (), TpAU }} .

Towards computing unfounded sets, observe every unfounded set extended solution
set nogoods A( ). Conversely, solutions include specific extensions
unfounded sets, characterized induced assignments; is, assigning true
atoms U , hr H(r) intersects U , replacement atoms e&g[p] (c)
.
&g[p](c) true .U , appropriate truth values auxiliary atoms according
intuitive meaning, assigning false atoms A( ). formally, leads
us following assignment:
Definition 8 (Induced Assignment Unfounded Set wrt. ) Let U unfounded set
program wrt. assignment A. assignment induced U wrt. , denoted (U, , , A),

(U, , , A) = I0 (U, , A) {Fa | A( ), Ta 6 I0 (U, , A)} ,

I0 (U, , A) = {Ta | U } {Thr | r , H(r) U 6= }
.
{Te&g[p] (c) | &g[p](c) EA(), .U |= &g[p](c)}
{TaA | A(), Ta A} {TaA | EA(), |= a}
{TaAU | A(), Ta A, U }
.
{TaA.U
| A(), Ta A, 6 U }
{TaAU | A(), Fa U } .
adopt assignment assumption set

AA = {TaA | A(), Ta A} {FaA | A(), Fa A}

{TaA | EA(), |= a} {FaA | EA(), 6|= a} ,

assignments induced unfounded sets wrt. solutions wrt. AA (but
conversely, intuitively latter reflect semantics external sources).
before, call set nogoods N conservative, (U, , , A) solution N
every unfounded set U wrt. A. property, interpretations solutions
whole nogood set comply assumptions A.
282

fiE FFICIENT HEX-P ROGRAM E VALUATION BASED U NFOUNDED ETS

Proposition 8 Let U unfounded set program wrt. assignment U 6= .
O, conservative, (U, , , A) solution satisfies AA .
Corollary 9 solution satisfies AA , U = every unfounded set
U (assuming O, conservative).

next property allows us find unfounded sets wrt. among solutions
satisfy AA using postcheck external atoms.
Theorem 10 Let solution (with conservative O, ) satisfies AA
.

(a) Te&g[p] (c) 6|= &g[p](c) implies .U |= &g[p](c);
.

(b) Fe&g[p] (c) |= &g[p](c) implies .U 6|= &g[p](c),

U = {a A() | Ta S}. U unfounded set wrt. A.


, proposition states non-replacement atoms true appear
form unfounded set, provided replacement atom e&g[p] (c) truth
.
value &g[p](c) .U (as Definition 8). Again, check required truth
value e&g[p] (c) different one &g[p](c) A.
Similarly encoding , follows immediately Definition 8 postcheck
eliminate unfounded sets, formalized following proposition.
Proposition 11 Let U unfounded set program wrt. assignment U 6=
. (U, , , A) fulfills Conditions (a) (b) Theorem 10.
Example 11 Reconsider program = {r1 : p &id [p]()} Example 6 compatible
set A2 = {Tp, Te&id[p] }. nogood set
= {{Fp}, {FpAU , TpA , Tp}, {TpAU , FpA }, {TpAU , Fp},

.
{FpAU , Fp}, {FpAU , Tp}, {TpAU , TpA , Fp}, {TpA.U
, FpA },

.
.
{TpA.U
, Tp}, {FpA.U
, TpA , Fp},

{Thr1 , Fp}, {Fhr1 , Tp}, {Thr1 , Te&id[p] ()A , Te&id[p] (), TpAU }}
assumptions AA2 = {TpA } solutions {Thr1 , Tp, TpA , Fe&id[p] , TpAU , TpAU ,
.
FpA.U
}, correspond unfounded set U = {p}. Here, Fe&id[p] () represents
.
A2 .U 6|= &id [p]().
see Section 6 encoding superior
many practically relevant
programs. effect becomes especially visible need many unfounded set checks, intuitively case many answer sets exist; reusability encoding beneficial,
small programs answer sets, incurred overhead lead savings.

4. Optimization Learning
section first discuss refinements optimizations nogood encodings UFS
search. particular, present nogoods prune irrelevant parts search space;
integrated encodings
suitable adjustments. that, propose
strategy learning nogoods detected unfounded sets, avoiding unfounded set
generated later again.
283

fiE ITER , F INK , K RENNWALLNER , R EDL , & CH ULLER

4.1 Optimization
present three optimizations turned effective improving UFS search,
second third exclude other, i.e., used simultaneously.
4.1.1 R ESTRICTING UFS EARCH ATOMS C OMPATIBLE ET
First, atoms program relevant unfounded set search: atoms false
ignored.
Proposition 12 Suppose U unfounded set wrt. interpretation 6|=
U . U \ {a} unfounded set wrt. A.
nogoods optimization simple. encoding
, add conservative
encoding
nogood {Ta} A() 6|= optimization part O,
conservative nogood {FaA , Ta} A() optimization part O, .
4.1.2 AVOIDING G UESSES R EPLACEMENT ATOMS
situations, truth value replacement atom b solution
resp.
assumptions AA irrelevant. is, STb = (S \ {Tb, Fb}) {Tb} SFb = (S \
{Tb, Fb}) {Fb} solutions
resp. satisfy AA , represent
unfounded set. set truth value b (arbitrary) fixed value instead inspecting
alternatives. next proposition states sufficient criterion irrelevance.
Proposition 13 Let b replacement atom, let solution
resp. satisfying
AA . every rule r b B + (r) B (r) |= B(r), either
(a) Bo+ (r) |= a, holds Ta S,
(b) H(r) |= a, holds Fa S,

STb SFb solutions
resp. satisfy AA .
property utilized adding conservative nogoods. Recall A(A
) A( )
contain atoms lr every r . intuitively serve encode solution
resp.
assumptions AA whether truth values replacement atoms B(r) relevant
set arbitrarily. following nogoods label relevant rules r, forcing lr false iff

conditions Proposition 13 holds. encoding
, add O, rule r:
+
LA
,r ={{Tlr , Ta} | Bo (r), |= a} {{Tlr , Fa} | H(r), |= a}
{{Flr } {Fa | Bo+ (r), |= a} {Ta | H(r), |= a}} .

encoding , add O, rule r:
L,r ={{Tlr , Ta, TaA } | Bo+ (r)} {{Tlr , Fa, TaA } | H(r)}
{{Flr } {FaAU | Bo+ (r)} {TaAU | H(r)}} .
constraints exclusively enforce either Tlr Flr . Hence, truth value lr deterministically depends atoms, i.e., nogoods cause additional guessing.
Proposition 13 set truth value replacement atom b arbitrarily, lr false
r b B + (r) b B (r). However, must ensured changing truth
284

fiE FFICIENT HEX-P ROGRAM E VALUATION BASED U NFOUNDED ETS

value replacement atoms harm satisfaction conditions Theorem 6 (resp.
Theorem 10).
mentioned Theorem 6, beneficial set truth value e&g[p] (c) one
&g[p](c) A, reduce number external atoms must checked.
Importantly, also relaxes antecedence conditions Theorem 6 (resp. Theorem 10),
guarantees harmed. following nogoods enforce coherent interpretation
replacement atoms.

encoding
add O, rule r:



F,r
= {Flr | b B + (r) B (r)} {Fb} | b (r), |= b


{Flr | b B + (r) B (r)} {Tb} | b (r), 6|= b ,
encoding add O, rule r:


F,r = {Flr | b B + (r) B (r)} {TbA , Fb} | b (r)


{Flr | b B + (r) B (r)} {FbA , Tb} | b (r) .



summary, encoding
optimization part O,
= r LA

,r F,r
encoding optimization part O, = r L,r F,r .
give example optimization using encoding .
Example 12 Consider program = {r1 : p &id [p](); r2 : q &id [q]()}, compatible set = {Tp, Tq, Te&id[p] (), Te&id[q] ()}. necessary part encoding

solutions S1 {Thr1 , Tp, Fe&id[p] (), Fhr2 , Fq, Fe&id[q] ()} S2 {Thr1 , Tp, Fe&id[p] (),
Fhr2 , Fq, Te&id[q] ()} (which represent unfounded set U = {p}). Here, optimizaA
tion part r2 , LA
r2 Fr2 = {{Tlr2 , Fq}, {Flr2 , Tq}, {Flr2 , Te&id[q] ()}}, eliminates solutions S2

. beneficial solutions S1 postcheck easier (e&id[q] () S1 &id [q]()
truth value A).
Note optimization used, rules r atom lr fact needed
thus unconstrained. avoid exponential increase number UFS candidates,
atoms set fixed value.
4.1.3 E XCHANGING N OGOODS B ETWEEN UFS EARCH
third optimization allows exchange learned knowledge external atoms
UFS check main search compatible sets. purpose, first define nogoods
correctly describe input-output relationship external atoms.
Definition 9 nogood form N = {Tt1 , . . . , Ttn , Ff1 , . . . , Ffm , e&g[p] (c)},
F, valid input-output-relationship, every assignment N \{e&g[p] (c)}
holds |= &g[p](c) = F, 6|= &g[p](c) = T.

Here, signed literals atoms ti , 1 n, resp. fj , 1 j m, reflect relevant true
resp. false atoms interpretation A, built predicates occur input list p. Techniques learning nogoods described Eiter et al. (2012a) exploit properties
external sources (such monotonicity functionality) restrict size N .
Let N nogood valid input-output-relationship learned main search,
i.e., compatible sets , let F = = F.
285

fiE ITER , F INK , K RENNWALLNER , R EDL , & CH ULLER

Definition 10 (Nogood Transformation ) valid input-output relationship N = {Tt1 ,
. . . , Ttn , Ff1 , . . . , Ffm , e&g[p] (c)} assignment A, nogood transformation defined


Fti 1 n,

(N, A) = { {Ft1 , . . . , Ftn } {e&g[p] (c)}


{Tfi | 1 m, |= fi } }
otherwise.
next result states (N, A) considered, valid input-output relationships N
assignments A, without losing unfounded sets.
Proposition 14 Let N valid input-output relationship, let U unfounded set wrt.
contains conservative nogoods, (U, , , A) solution (N, A)
A. O,



(i.e., also nogoods (N, A) conservative).
Hence, valid input-output relationships external atoms learned search
compatible sets reused (applying transformation) UFS check. Moreover,
evaluation external atoms postcheck candidate unfounded sets (i.e., solutions

), valid input-output relationships might learned. turn used
(further) unfounded set checks (in transformed form) also search compatible sets.
Example 13 (Set Partitioning) program Example 4, consider compatible set
= {Tdomain(a), Tsel (a), Te&diff [nsel] (a)}. Suppose main search learned inputoutput relationship N = {Tdomain(a), Fnsel (a), Fe&diff [nsel] (a)}. transformed nogood
(N,A)={{Fdomain(a), Fe&diff [nsel] (a)}}; intuitively encodes domain(a)
.
unfounded set U , e&diff [nsel] (a) true .U . holds e&diff [nsel] (a)
true change truth value domain(a) becomes false.
learning technique adopted encoding follows.
Definition 11 (Nogood Transformation ) valid input-output relationship N , nogood
transformation defined
.
.
(N ) = {{e&g[p] (c)} {Tt1A , Ft1 , . . . , TtnA , Ftn , Ff1 A.U
, . . . , Ffm A.U
}} .

Compared (N, A), main difference (N ) reusable every assignment, similar
definition unfounded set detection problem .
next result states (N ) considered, valid input-output relationships N
assignments A, without losing unfounded sets.
Proposition 15 Let N valid input-output relationship, let U unfounded set wrt.
A. O, contains conservative nogoods, (U, , , A) solution (N )
(i.e., also nogoods (N ) conservative).
Hence, also encoding valid input-output relationships external atoms
learned search compatible sets reused vice versa.
286

fiE FFICIENT HEX-P ROGRAM E VALUATION BASED U NFOUNDED ETS

Example 14 (contd) Reconsider program Example 4 compatible set =
{Tdomain(a), Tsel (a), Te&diff [domain,nsel] (a)}. Suppose main search learned inputoutput relationship N = {Tdomain(a), Fnsel (a), Fe&diff [domain,nsel] (a)}. transformed nogood
.
.
(N )={{Tdomain(a)A , Fdomain(a), Fnsel (a)A.U
, Fe&diff [domain,nsel] (a)A.U
}} ;

intuitively encodes domain(a)
true assignment
unfounded set U ,
.
.
nsel (a) false .U , e&diff [domain,nsel] (a) true .U . holds
e&diff [domain,nsel] (a) true change truth value domain(a) gets false.
nogood exchange also benefits advanced encoding. previous encoding
,
needed build SAT instance scratch every unfounded set check. Thus, nogoods
learned main search compatible sets need transformed added UFS detection problem every check (otherwise lost). new encoding , done
learned nogoods kept multiple unfounded set checks. also allows us
make use advanced forgetting heuristics SAT solvers effective.
Finally, important note optimizations presented Section 4.1.2 4.1.3
used simultaneously (differently optimizations Section 4.1.1 4.1.2 resp. 4.1.1
4.1.3), result contradictions due (transformed) learned nogoods. thus disabled
optimization avoiding guesses replacement atoms (Section 4.1.2) experiments.
4.2 Learning Nogoods Unfounded Sets
considered merely detecting unfounded sets. strategy learn detected
unfounded sets main search compatible sets missing. next develop strategy
call unfounded set learning (UFL).
Example 15 Consider program = { p &id [p](); x1 x2 xk }. know
Example 7, U = {p} UFS subprogram 0 = { p &id [p]() } wrt. = {Tp, Te&id ()}.
true moreover every A0 A; i.e., p must never true.
program Example 15 many compatible sets, half (all p true) fail
UFS check reason. thus develop strategy generating additional nogoods
guide search compatible sets way unfounded sets reconsidered.
present two strategies, focus first one experiments shown
first one superior instances.
4.2.1 UFS-BASED L EARNING
unfounded set U wrt. define set L1 (U, , A) learned nogoods follows.
Suppose r1 , . . . , rj rules r H(r) U 6= U Bo+ (r) = , i.e.,
set external rules wrt. U (rules directly depend positively U ).
L1 (U, , A) = {{0 , 1 , . . . , j } | 0 {Ta | U }, Hi 1 j)} ,
Hi = {Th | h H(ri ) \ U, |= h} {Fb | b Bo+ (ri ), 6|= b}. Formally show
adding set nogoods correct, i.e., prune answer sets:
287

fiE ITER , F INK , K RENNWALLNER , R EDL , & CH ULLER

Proposition 16 U unfounded set wrt. A, every answer set solution
nogoods L1 (U, , A).
Example 16 Consider program Example 15 suppose found unfounded
set U = {p} wrt. interpretation = {Tp, Tx1 } {Fxi | 1 < k}. learned nogood
L1 (U, A, ) = {Tp} immediately guides search part search tree p false,
i.e., roughly half guesses avoided.
4.2.2 R EDUCT-BASED L EARNING
different learning strategy based models f rather
unfounded set U itself,
.
hinging observation every unfounded set U , .U model f ; hence
U 6= refutes minimal model f . noted Faber (2005) aggregates.
exploit
construct nogoods nonempty U wrt. model follows.
.
interpretation .U model f , programs 0 f.A . Hence,
assignment A0 falsifies least rules falsifies, A0 (A .U )T , A0
answer set . yields following nogood set L2 (U, , A). Suppose r1 , . . . , rn
rules r FLP-reduct wrt. (i.e., 6|= B(ri ).
.

L2 (U, , A) = {{Ta | (A .U )T } {0 , 1 , . . . , n }

| 0 {Ta | U }, Hi 1 n} ,

Hi = {ta | B(r),
6|= a}, 1 n. is, nogood consists true-part
.

smaller
model


.U
reduct f , unfounded atom 0 (i.e. true
.
.U ), false body literal (1 n) rule unsatisfied body wrt. A.
Example 17 Let = {p &id [p](); q &id [q]()}, &id [a]() evaluates true iff
true. Suppose = {Tp, Tq}.
U = {Tp, Tq} unfounded set wrt. A.
.
construction rule .U = {}, 0 {Tp, Tq} n = 0 (because rule bodies
satisfied wrt. A). learned nogoods L2 (U, , A) = {{Tp}, {Tq}}.
Example 17, learned nogoods immediately guide search interpretation
{Fp, Fq}, one becomes answer set. Formally, show:
Proposition 17 U unfounded set wrt. |= , answer set
solution nogoods L2 (U, , A).
However, L2 (U, , A) appeared clearly inferior L1 (U, , A) Section 4.2.1. Informally, nogoods overfit detected unfounded set generalize well ones.

5. Deciding Necessity Minimality Check
Although minimality check based unfounded sets efficient explicit minimality check, computational costs still high. Moreover, evaluation computing
compatible set A, ASP solver already made unfounded set check, safely
assume founded perspective ASP solver. Hence, remaining unfounded
sets discovered ASP solver must involve external sources, behavior
fully captured ASP solver.
288

fiE FFICIENT HEX-P ROGRAM E VALUATION BASED U NFOUNDED ETS

section pursue ideas give decision criterion deciding whether UFS check necessary. eventually define class programs needs additional
UFS check. Intuitively, show every unfounded set already detected
construction contains input atoms external atoms involved cycles. program
input atom, UFS check superfluous. Afterwards, show apply criterion, holds practically relevant cases, program components; often yields additional
speedup. However, also cases UFS check skipped; e.g., recursive
URL retrieval web resource (which requires cyclic use external atom).
5.1 Basic Decision Criterion
start definition atom dependency.
Definition 12 (Atom Dependency) ground program , ground atoms p(c) q(d),
say
(i) p(c) depends q(d), denoted p(c) q(d), rule r p(c) H(r)
q(d) B(r);

(ii) p(c) depends externally q(d), denoted p(c) e q(d), rule r external atom
&g[q1 , . . . , qn ](e) B + (r)B (r) exist p(c) H(r) q {q1 , . . . , qn }.
following, consider dependency graphs GR
= (V, E) ground program , whose
vertices V ground atoms whose edges E given binary relation R ground
atoms (E = R). call p(c) q(d) also ordinary edge p(c) e q(d) e-edge.
establish lemma allows us restrict attention core unfounded set,
i.e., essential part; disregard atoms cut GR
, defined follows.
Definition 13 (Cut) Let U unfounded set wrt. A. set atoms C U cut GR
,

(i) b e
/ GR
, C b U (C incoming e-edge U ),
R
(ii) b 6 GR
b 6 G , C b U \ C (there ordinary edges
C U \ C).

first prove cuts removed unfounded sets resulting set still
unfounded set.
Lemma 18 (Unfounded Set Reduction Lemma) Let U unfounded set wrt. complete
assignment A, let C cut GR
. Then, = U \ C unfounded set wrt. A.
Example 18 Consider following program:
= {r &id [r]();

p &id [r]();

p q;

q p} .

p q, q p, r e r p e r. unfounded set U = {p, q, r}
wrt. = {Tp, Tq, Tr}. Observe C = {p, q} cut GR
, therefore U \ C = {r}
unfounded set wrt. A.
289

fiE ITER , F INK , K RENNWALLNER , R EDL , & CH ULLER

Next prove intuitively, unfounded set U , either input external
atom unfounded itself, U already detected evaluated.
Lemma 19 (EA-Input Unfoundedness) Let U unfounded set wrt. assignment A.
GR
edge x e x, U , U unfounded set wrt. A.
Example 19 Reconsider program Example 18. unfounded set U 0 = {p, q}
wrt. A0 = {Tp, Tq, Fr} already detected
= { e&id[r] () ne &id[r] () ;

r e&id[r] ();

p e&id[r] ();

p q;

q p}

evaluated ASP solver edges p e q q e p exist. contrast,
unfounded set U 00 = {p, q, r} wrt. A00 = {Tp, Tq, Tr} detected ASP solver
p, r U 00 p e r.
Thus, unfounded sets wrt. recognized evaluation
cyclic dependencies input atoms external atom. Programs acyclic dependencies
need additional UFS checks.
Recall cycle wrt. binary relation R sequence C = c0 , c1 , . . . , cn , cn+1 elements,
n 0, (ci , ci+1 ) R 0 n c0 = cn+1 . set contains cycle wrt. R,
cycle C = c0 , c1 , . . . , cn , cn+1 wrt. R ci 0 n + 1.
Informally, next proposition states unfounded set wrt. contains
cycle input atoms external atom corresponds unfounded set
wrt. A, i.e., unfoundedness already detected evaluated.
Let = e , inverse (i.e. = {(x, y) | (y, x) }).
cycle c0 , c1 , . . . , cn , cn+1 called e-cycle, contains e-edge, i.e., ci e ci+1
0 n.
Theorem 20 (Relevance e-cycles) Let U 6= unfounded set wrt. interpretation
contain e-cycle . nonempty unfounded set wrt. A.
Corollary 21 program e-cycle unfounded set wrt. interpretation A, unfounded-free .
corollary used increase performance evaluation algorithm follows:
cycle containing e-edges, explicit unfounded set check necessary unfounded set check evaluation sufficient. Note test
done efficiently (in fact linear time, similar deciding stratifiability ordinary logic
program). Moreover, practice one abstract using analogous relations
level predicate symbols instead atoms. Clearly, e-cycle predicate dependency graph, also e-cycle atom dependency graph. Hence, predicate
dependency graph safely used decide whether unfounded set check skipped.
Example 20 example programs far need UFS check, program = {out(X)
&diff [set 1 , set 2 ](X)}F , diff computes set difference unary predicates set 1 set 2
F set facts, needs UFS check e-cycle . Also program
= {str (Z) dom(Z), str (X), str (Y ), &concat[X, ](Z)} (where &concat takes two
constants computes string concatenation) needs UFS check; cycle
external atom, e-cycle .
290

fiE FFICIENT HEX-P ROGRAM E VALUATION BASED U NFOUNDED ETS

Unfortunately, converse Theorem 20 hold, is, may fail unfoundedfree wrt. unfounded set wrt. contains e-cycle; thus, condition Corollary 21
necessary unfounded-freeness wrt. A. However, following generalization
Theorem 20 allows us conclude unfounded-free wrt. A, every unfounded set U
wrt. must contain atom provides input external atom cycle .
Definition 14 (Cyclic Input Atoms) program , atom cyclic input atom,
edge b e path b exists.
Let CA() denote set cyclic input atoms program .
Theorem 22 (Unfoundedness Cyclic Input Atom) Let U 6= unfounded set wrt.
U CA() = . Then, nonempty unfounded set wrt. A.
consequence Theorem 22, add nogood {Fa | CA()}
.
using predicate symbols instead atoms reduces overhead dependency graph.
Example 21 Reconsider Example 18. U = {p, q} unfounded set wrt. =
{Tp, Tq, Fr}; U disjoint CA() = {r}, detected evaluation .
5.2 Program Decomposition
usefulness decision criterion increased decomposing program components, criterion applied componentwise. allows us restrict UFS
check components e-cycles, e-cycle-free components ignored.
Let C partitioning ordinary atoms A() subset-maximal strongly connected
components e . define partition C C subprogram C associated
C C = {r | H(r) C 6= }.
next show program unfounded set U wrt. A, U C unfounded set
wrt. subprogram strongly connected component C.
Theorem 23 Let U 6= unfounded set wrt. A. Then, C C holds U C
nonempty unfounded set C wrt. A.
Note constraints (i.e., rules empty head) harm proposition. constraint
r kind B(r) rewritten p B(r), p new atom p, C = {p} strongly
connected component C = {r}, contain e-cycle. Thus, rewritten
constraints according subprograms C ignored anyways.
proposition states search unfounded sets done independently subprograms C C C. unfounded set wrt. assignment, also
unfounded set least one program component wrt. assignment. know Corollary 21
programs without e-cycles contain unfounded sets already detected
solved. apply Theorem 23 subprograms C , safely ignore e-cycle-free
program components.
Example 22 Reconsider program Example 18. C contains components C1 =
{p, q} C2 = {r} C1 = {p &id [r ](); p q; q p} C2 = {r
&id [r ]()}. Theorem 23, unfounded set wrt. assignment gives rise
291

fiE ITER , F INK , K RENNWALLNER , R EDL , & CH ULLER

unfounded set either C1 C2 . E.g., consider U = {p, q, r} = {Tp, Tq, Tr};
U {r} = {r} unfounded set C2 wrt. A. C1 e-cycles, conclude
Corollary 21 unfounded sets C1 already detected (resp., C1 ) evaluated.
Hence, C2 needs additional UFS check. Indeed, unfounded set
detected evaluated {r}, unfounded wrt. interpretation {Tr}
C2 .
Finally, show splitting, i.e., component-wise check foundedness, lead
spurious unfounded sets.
Proposition 24 U unfounded set C wrt. U C, U unfounded
set wrt. A.
results generalized subprograms larger strongly connected components; however, leave detailed study future work.

6. Implementation Evaluation
implementing technique, integrated CLASP prototype system DLVHEX; use
CLASP ASP solver computing compatible sets SAT solver solving nogood
set UFS check.
experiments, also use external behavior learning (EBL) developed Eiter
et al. (2012a). basic idea learn additional nogoods evaluations external atoms,
capture (parts of) behavior external sources. Thus, nogoods eliminate model
candidates violate known semantics external atoms.
Regarding concrete setting, large number combinations EBL techniques
presented paper. Indeed, may either activate deactivate external behavior learning
use either explicit UFS-based minimality check. latter case, use
unfounded set learning (UFL), decision criterion skipping unfounded set check
exploited ignored, program decomposition might used not. Moreover, choose
encodings . total, 34 different settings.
However, restrict discussion interesting configurations. general,
activate developed features stepwise tables efficiency increases left
right. start traditional algorithm based explicit minimality check without
learning techniques Eiter et al. (2012a) paper (i.e., conflict-driven learning
inside CLASP used). next step add external behavior learning, UFL possible explicit check. switch explicit minimality check UFS-based
check without learning without exploiting decision criterion program decomposition.
Nevertheless, naive kind UFS-based minimality checking often efficient
explicit minimality check EBL. next step, add decision criterion program
decomposition. following, monolithic (mol) means decision criterion
program decomposition off, modular (mod) on. Next add EBL UFL
UFS-based minimality check, finally switch encoding (including EBL,
UFL modular decomposition). However, might skip steps specific benchmarks argue uninteresting respective cases. Detailed instance information
results combinations parameters available.2
2. http://www.kr.tuwien.ac.at/research/projects/hexhex/ufs

292

fiE FFICIENT HEX-P ROGRAM E VALUATION BASED U NFOUNDED ETS

Briefly, results show clear improvement, synthetic application instances,
UFS check EBL. Moreover, closer analysis shows UFS check decreases
cases runtime also number enumerated candidates (UFS resp. model
candidates FLP reduct) number external atom evaluations.
evaluated implementation Linux server two 12-core AMD 6176 SE CPUs
128GB RAM running DLVHEX version 2.3.0. evaluated techniques configured using
commandline arguments. best knowledge, DLVHEX implementation
HEX semantics. test run CPU usage limited two CPU cores, running Condor
load distribution system ensures robust runtimes (i.e., multiple runs instance
negligible deviations). timeout uniformly set 300 seconds instance;
parameter value, average runtime instances printed timeouts, whose number
shown parentheses, fully taken account.
6.1 Detailed Benchmark Description Experimental Results
give detailed description benchmarks used experiments, present
results experimental evaluation.
6.1.1 ET PARTITIONING
benchmark extends program Example 4 additional constraint
sel (X), sel (Y ), sel (Z), X 6= Y, X 6= Z, 6= Z
varies size domain. results shown Table 1. see big advantage
UFS check explicit check, computing answer sets finding first one.
closer investigation shows improvement mainly due optimizations Section 4,
make UFS check investigate significantly fewer candidates explicit FLP check.
Furthermore UFS check requires fewer external computations.
explicit UFS-based minimality check benefit EBL compute
answer sets, results show UFS-based check benefits more. contrast, UFL (not
shown table) lead speedup unfounded sets found program.
decision criterion program decomposition improve runtime slightly small instances. However, large instances decision criterion cannot avoid UFS check
components program cyclic structure. Thus single UFS check whole
program replaced multiple UFS checks individual program components, involves
overhead becomes visible computing answer sets.
compute one answer set, EBL turns counter-productive. learning involved additional overhead, cannot profit much learned
knowledge abort first answer set, hence costs exceed benefit.
Using encoding instead increases efficiency case,
large number answer sets also large number answer set candidates. Thus, reusable
encoding beneficial, even compute one answer set.
Since evaluation program unfounded sets encountered, obvious
additional unfounded set checks partial interpretations increase overhead benefit;
hence discuss respective results.
293

fidomain

E ITER , F INK , K RENNWALLNER , R EDL , & CH ULLER

explicit

5 (1)
6 (1)
7 (1)
8 (1)
9 (1)
10 (1)
15 (1)
20 (1)
25 (1)

300.00 (1)
300.00 (1)
300.00 (1)
300.00 (1)
300.00 (1)
300.00 (1)
300.00 (1)
300.00 (1)
300.00 (1)

+EBL

answer sets
UFS
UFS
mol
mod

+EBL



explicit

300.00 (1)
0.33 (0)
0.32 (0) 0.09 (0)
300.00 (1)
0.77 (0)
0.81 (0) 0.12 (0)
300.00 (1)
1.73 (0)
1.78 (0) 0.20 (0)
300.00 (1)
4.35 (0)
4.17 (0) 0.31 (0)
300.00 (1) 10.42 (0) 10.21 (0) 0.47 (0)
300.00 (1) 26.31 (0) 25.13 (0) 0.53 (0)
300.00 (1) 300.00 (1) 300.00 (1) 2.83 (0)
300.00 (1) 300.00 (1) 300.00 (1) 12.98 (0)
300.00 (1) 300.00 (1) 300.00 (1) 45.18 (0)

0.07 (0)
0.10 (0)
0.13 (0)
0.16 (0)
0.23 (0)
0.29 (0)
0.79 (0)
1.95 (0)
4.11 (0)

54.02 (0)
300.00 (1)
300.00 (1)
300.00 (1)
300.00 (1)
300.00 (1)
300.00 (1)
300.00 (1)
300.00 (1)

first answer set
+EBL UFS UFS +EBL
mol
mod
53.80 (0)
300.00 (1)
300.00 (1)
300.00 (1)
300.00 (1)
300.00 (1)
300.00 (1)
300.00 (1)
300.00 (1)

0.05 (0)
0.04 (0)
0.06 (0)
0.07 (0)
0.08 (0)
0.09 (0)
0.19 (0)
0.38 (0)
0.70 (0)

0.05 (0)
0.05 (0)
0.06 (0)
0.06 (0)
0.07 (0)
0.09 (0)
0.15 (0)
0.29 (0)
0.47 (0)

0.05 (0)
0.06 (0)
0.06 (0)
0.07 (0)
0.08 (0)
0.11 (0)
0.27 (0)
0.57 (0)
1.09 (0)


0.05 (0)
0.06 (0)
0.07 (0)
0.07 (0)
0.09 (0)
0.12 (0)
0.26 (0)
0.57 (0)
1.08 (0)

Table 1: Set Partitioning Benchmark Results
Note results comparable Eiter et al. (2012a), previous work
focused computation subset-minimal compatible sets perform minimality
check wrt. reduct, i.e., semantics different.
6.1.2 N ONMONOTONIC ULTI -C ONTEXT YSTEMS
Nonmonotonic Multi-Context-Systems (MCSs) (Brewka & Eiter, 2007) generic formalism
aligning knowledge bases called contexts, emerged approach Ghidini
Giunchiglia (2001). contexts interlinked via bridge rules enable belief exchange
across contexts; MCS semantics requires local belief sets compliant bridge
rules. compliance impossible achieve; is, MCS inconsistent. understand
reasons latter, Eiter et al. (2012b) defined inconsistency explanations (IEs) MCS,
computed HEX-program encoding. encoding based Saturation,
general technique solving p2 problems disjunctive answer set programming (cf.,
Leone et al., 2006). Intuitively, quantified Boolean formula (QBF) form XY(X, Y)
evaluated using technique follows. Disjunctions used guess whether variable v
true false. spoil atom made true whenever evaluates true given truth assignments
X Y. Finally whenever spoil true, literals set true; creates unique
assignment respective atoms. Given guess X, unique spoil extension answer
set guesses truth assignments make spoil atom true saturate guess
become unique extensionthis holds due minimality condition answer sets
reduct (see Definition 3).
use HEX-encoding computing IEs benchmark, saturation rich cycles external atoms disjunctive rule heads. External atoms benchmark evaluate
semantics contexts MCS (i.e., local belief sets models).
use random instances different MCS topologies, i.e., connection graphs contexts, created MCS benchmark generator.3 Note topologies structure bound
certain system sizes (number contexts), difficulty instances varies among
topologies; thus larger instances may shorter runtimes. instances 10 contexts,
consisting randomly generated consistent normal answer set program.
3. Described http://www.kr.tuwien.ac.at/research/systems/dmcs/experiments.html, online available https://dmcs.
svn.sourceforge.net/svnroot/dmcs/dmcs/trunk

294

fiE FFICIENT HEX-P ROGRAM E VALUATION BASED U NFOUNDED ETS

#ctx
3 (6)
4 (10)
5 (8)
6 (6)
7 (12)
8 (5)
9 (8)
10 (11)

explicit

+EBL

UFS
mol

UFS
mod

+EBL

+UFL



4.78 (0)
51.90 (1)
149.53 (3)
159.41 (3)
231.23 (9)
244.39 (4)
300.00 (8)
300.00 (11)

3.97 (0)
45.91 (1)
137.95 (3)
154.69 (3)
227.45 (9)
204.92 (3)
278.44 (7)
268.78 (9)

2.96 (0)
48.71 (1)
150.80 (3)
157.62 (3)
234.74 (9)
246.42 (4)
300.00 (8)
300.00 (11)

2.97 (0)
48.59 (1)
150.64 (3)
157.72 (3)
234.63 (9)
246.34 (4)
300.00 (8)
300.00 (11)

1.65 (0)
23.48 (0)
94.45 (1)
151.89 (3)
216.75 (8)
190.60 (3)
264.65 (6)
247.16 (8)

0.08 (0)
0.10 (0)
0.10 (0)
0.12 (0)
0.17 (0)
0.17 (0)
0.22 (0)
0.25 (0)

0.08 (0)
0.11 (0)
0.12 (0)
0.15 (0)
0.20 (0)
0.21 (0)
0.24 (0)
0.31 (0)

Table 2: Consistent MCSs Benchmark Results

#ctx

explicit

+EBL

3.29 (0)
41.57 (1)
154.55 (5)
130.90 (7)
166.14 (5)
261.96 (5)
286.74 (13)
300.00 (12)

2.70 (0)
17.94 (0)
148.11 (5)
102.57 (6)
118.04 (5)
143.75 (2)
206.10 (9)
300.00 (12)

#ctx

explicit

+EBL

3 (9)
4 (14)
5 (11)
6 (18)
7 (13)
8 (6)
9 (14)
10 (12)

0.09 (0)
0.13 (0)
0.16 (0)
0.18 (0)
0.19 (0)
0.23 (0)
0.32 (0)
0.44 (0)

0.09 (0)
0.14 (0)
0.17 (0)
0.19 (0)
0.17 (0)
0.20 (0)
0.27 (0)
0.33 (0)

3 (9)
4 (14)
5 (11)
6 (18)
7 (13)
8 (6)
9 (14)
10 (12)

answer sets
UFS
UFS
mol
mod

+EBL

+UFL



2.34 (0)
37.03 (1)
153.94 (5)
128.12 (7)
157.06 (5)
263.00 (5)
287.32 (12)
300.00 (12)

1.09 (0)
6.05 (0)
108.87 (2)
87.75 (4)
107.50 (4)
118.36 (2)
189.48 (8)
290.18 (11)

0.14 (0)
2.71 (0)
3.65 (0)
10.61 (0)
84.08 (2)
55.86 (1)
124.34 (5)
290.69 (11)

0.14 (0)
0.61 (0)
1.28 (0)
1.55 (0)
29.47 (0)
51.13 (1)
130.56 (6)
277.05 (11)

first answer set
UFS
UFS
mol
mod

+EBL

+UFL



0.08 (0)
0.12 (0)
0.14 (0)
0.15 (0)
0.15 (0)
0.17 (0)
0.22 (0)
0.29 (0)

0.08 (0)
0.11 (0)
0.14 (0)
0.15 (0)
0.15 (0)
0.17 (0)
0.23 (0)
0.29 (0)

0.09 (0)
0.13 (0)
0.16 (0)
0.18 (0)
0.17 (0)
0.19 (0)
0.28 (0)
0.34 (0)

2.44 (0)
37.04 (1)
154.17 (5)
128.26 (7)
157.67 (5)
262.95 (5)
287.10 (12)
300.00 (12)

0.08 (0)
0.11 (0)
0.14 (0)
0.16 (0)
0.17 (0)
0.21 (0)
0.28 (0)
0.39 (0)

0.08 (0)
0.12 (0)
0.14 (0)
0.16 (0)
0.17 (0)
0.20 (0)
0.28 (0)
0.39 (0)

Table 3: Inconsistent MCSs Benchmark Results

number candidates smaller models FLP reduct equals number unfounded
set candidates unfounded set corresponds smaller model. However, stop
enumeration soon smaller model respectively unfounded set found, explicit
UFS check may consider depending specific program solver heuristics different numbers
interpretations. explains UFS check sometimes slightly slower explicit
check. However, delay different UFS candidates always smaller, sometimes
makes faster even visits candidates.
results consistent inconsistent MCSs shown Table 2 3, respectively,
number instances system size given parentheses. Intuitively, consistent
inconsistent MCSs dual, candidate explicit resp. UFS check fails (i.e., stops
early), vs. (or many) candidates check succeeds (stops late). However, mixed
results permit us draw solid conclusions computational relationship evaluation
295

fiE ITER , F INK , K RENNWALLNER , R EDL , & CH ULLER

methods. Nonetheless, see UFS check based often much faster
explicit check (up three orders magnitude).
consistent MCSs IEs hence answer sets, need distinguish
computing one answer sets. effects external behavior learning (Eiter et al.,
2012a) unfounded set learning clearly evident MCS benchmarks, computing first answer sets. UFS check profits EBL explicit check,
adding advantage. activating UFL (which possible explicit check)
gain another significant speedup.
discuss effects syntactic decision criterion program decomposition. Due
saturation, encoding contains cycles nearly cycles HEX-program contain
least one external atom. Therefore, decision criterion reduce set atoms,
UFS check needs performed, atoms defined EDB.
yield significant efficiency improvements. However, benchmark results MCS instances
confirm syntactic check cheap hurt performance. 186 instances,
total runtime decision criterion program decomposition 11,695 seconds compared
11,702 seconds without, number instance timeouts same.
use encoding instead , observe another significant speedup computing
IEs inconsistent MCSs. usually exist many answer sets (often thousands),
thus reusable encoding beneficial. contrast, compute first answer set
MCS consistent (no answer set exists), check involved encoding
slightly slower; reusability pay abort first answer set.
summary, observe encoding leads significant performance gain
encoding , decision criterion decomposition help. next benchmark
observe opposite effects.
6.1.3 BSTRACT RGUMENTATION
benchmark compute ideal set extensions (Dung, Mancarella, & Toni, 2007) randomly
generated instances abstract argumentation frameworks (AFs) (Dung, 1995) different sizes.
problem checking whether given set arguments ideal set AF co-NPcomplete (Dunne, 2009). benchmark use HEX encoding mirrors complexity:
guesses set checks ideality using Saturation technique involving external atom
(see Appendix A.1).
Table 4 shows results different numbers arguments, entry average
30 benchmark instances. compare following configurations computing
first answer set.
first column explicit minimality check without learning techniques. second
column shows learning (EBL) leads almost runtime results. explained
structure encoding, allow effectively reusing learned nogoods.
third column, perform UFS-based minimality check using encoding ,
without applying decision criterion decomposition. observe already
significant improvements compared explicit minimality check, illustrating effectiveness
new approach. Similar MCS benchmark, number reduct model candidates
equal number UFS candidates cases, UFS check enumerates
candidates faster; explains observed speedup.
296

fi#args

E FFICIENT HEX-P ROGRAM E VALUATION BASED U NFOUNDED ETS

#args

1 (30)
2 (30)
3 (30)
4 (30)
5 (30)
6 (30)
7 (30)
8 (30)
9 (30)
10 (30)
11 (30)
12 (30)
13 (30)
14 (30)
15 (30)
16 (30)
17 (30)
18 (30)
19 (30)
20 (30)

1 (30)
2 (30)
3 (30)
4 (30)
5 (30)
6 (30)
7 (30)
8 (30)
9 (30)
10 (30)
11 (30)
12 (30)
13 (30)
14 (30)
15 (30)
16 (30)
17 (30)
18 (30)
19 (30)
20 (30)

explicit

+EBL

0.06 (0)
0.08 (0)
0.11 (0)
0.19 (0)
0.32 (0)
0.71 (0)
1.58 (0)
4.75 (0)
14.02 (0)
41.10 (0)
129.35 (1)
250.16 (12)
294.91 (27)
290.01 (29)
290.01 (29)
300.00 (30)
300.00 (30)
300.00 (30)
300.00 (30)
300.00 (30)

0.06 (0)
0.07 (0)
0.10 (0)
0.19 (0)
0.32 (0)
0.72 (0)
1.66 (0)
5.04 (0)
14.97 (0)
44.38 (0)
139.80 (2)
258.82 (17)
296.67 (27)
290.01 (29)
290.01 (29)
300.00 (30)
300.00 (30)
300.00 (30)
300.00 (30)
300.00 (30)

answer sets
UFS
UFS
mol
mod
0.05 (0)
0.06 (0)
0.08 (0)
0.14 (0)
0.26 (0)
0.55 (0)
1.16 (0)
3.06 (0)
8.65 (0)
24.53 (0)
51.39 (0)
119.44 (0)
274.65 (19)
290.00 (29)
290.00 (29)
300.00 (30)
300.00 (30)
300.00 (30)
280.39 (28)
278.20 (27)

explicit

+EBL

0.05 (0)
0.07 (0)
0.09 (0)
0.14 (0)
0.22 (0)
0.46 (0)
0.76 (0)
2.34 (0)
7.35 (0)
19.47 (0)
63.39 (1)
119.65 (4)
197.04 (14)
227.27 (22)
260.02 (26)
230.04 (23)
250.03 (25)
270.02 (27)
230.06 (23)
220.07 (22)

0.05 (0)
0.07 (0)
0.09 (0)
0.14 (0)
0.22 (0)
0.47 (0)
0.79 (0)
2.44 (0)
7.82 (0)
21.05 (0)
67.39 (1)
126.18 (4)
201.27 (15)
227.72 (22)
260.02 (26)
230.04 (23)
250.03 (25)
270.02 (27)
230.06 (23)
220.07 (22)

0.05 (0)
0.06 (0)
0.08 (0)
0.12 (0)
0.18 (0)
0.33 (0)
0.52 (0)
1.09 (0)
1.86 (0)
4.73 (0)
9.34 (0)
12.49 (0)
24.26 (0)
51.38 (3)
79.93 (3)
80.10 (4)
81.90 (5)
127.43 (8)
173.16 (13)
167.72 (12)

first answer set
UFS
UFS
mol
mod
0.05 (0)
0.06 (0)
0.08 (0)
0.12 (0)
0.21 (0)
0.42 (0)
0.68 (0)
1.98 (0)
5.76 (0)
15.37 (0)
26.30 (0)
60.88 (0)
149.25 (3)
218.00 (17)
260.01 (26)
230.02 (23)
250.01 (25)
270.01 (27)
211.12 (21)
200.29 (20)

0.05 (0)
0.06 (0)
0.08 (0)
0.10 (0)
0.15 (0)
0.27 (0)
0.37 (0)
0.89 (0)
1.36 (0)
3.54 (0)
4.61 (0)
6.11 (0)
16.34 (0)
41.28 (2)
40.92 (2)
40.63 (3)
35.24 (2)
74.89 (5)
66.58 (4)
81.81 (5)

+EBL
+UFL



0.05 (0)
0.06 (0)
0.08 (0)
0.12 (0)
0.18 (0)
0.33 (0)
0.51 (0)
1.08 (0)
1.84 (0)
4.58 (0)
9.34 (0)
12.38 (0)
24.33 (0)
51.65 (3)
78.00 (3)
77.91 (4)
77.04 (5)
126.57 (8)
148.13 (10)
167.02 (12)

0.05 (0)
0.07 (0)
0.09 (0)
0.13 (0)
0.19 (0)
0.36 (0)
0.56 (0)
1.15 (0)
1.95 (0)
4.79 (0)
9.48 (0)
12.39 (0)
24.44 (0)
51.98 (3)
78.19 (3)
77.95 (4)
76.85 (5)
125.91 (8)
147.62 (10)
166.07 (12)

+EBL
+UFL



0.05 (0)
0.06 (0)
0.07 (0)
0.10 (0)
0.15 (0)
0.27 (0)
0.37 (0)
0.90 (0)
1.28 (0)
3.53 (0)
4.66 (0)
6.11 (0)
16.49 (0)
41.68 (2)
41.38 (2)
40.69 (3)
35.60 (2)
75.47 (5)
67.03 (4)
82.33 (5)

0.05 (0)
0.06 (0)
0.08 (0)
0.12 (0)
0.17 (0)
0.29 (0)
0.40 (0)
0.94 (0)
1.34 (0)
3.68 (0)
4.69 (0)
6.13 (0)
16.50 (0)
41.76 (2)
41.62 (2)
40.84 (3)
35.57 (2)
75.10 (5)
67.04 (4)
82.45 (5)

Table 4: Argumentation Benchmark Results

enable decision criterion program decomposition, observe
speedup. cycles argumentation instances usually involve small parts
overall program; thus UFS search significantly simplified excluding large program parts. observed program decomposition without decision criterion
counter-productive (not shown table), single UFS search whole program
replaced many UFS searches program components (without decision criterion,
check excluded). incurs overhead.
297

fiE ITER , F INK , K RENNWALLNER , R EDL , & CH ULLER

fifth column enable EBL UFL, leads small speedup cases.
However, already mentioned above, effective reuse learned nogoods possible.
Switching encoding leads small speedup cases, also counterproductive others. programs benchmark usually
compatible sets, unfounded set checks need performed. Hence lower
initialization overhead encoding influence runtime dramatically.
hand, higher complexity encoding increases runtime small instances.
6.1.4 EFAULT R EASONING ESCRIPTION L OGICS
prominent instance HEX-programs DL-programs, combine description logic ontologies rules; result using special external atom available DL-plugin
DLVHEX . Via DL-programs, obtain encoding terminological default reasoning description logic ontologies approach Baader Hollunder (1995) HEX-programs,
defaults require cyclic dependencies external atoms. However, dependencies
involve default negated atoms, cycles according Definition 12, respects
positive dependencies. Hence, decision criterion comes conclusion UFS check
required.
used variants benchmarks presented Eiter et al. (2012a), query wines
ontology classify red white wines, wine assumed white unless
ontology explicitly entails opposite. scenario, decision criterion eliminates
unfounded set checks. However, one compatible set per instance, would
one unfounded set check anyway, hence speedup due decision criterion significant. effect decision criterion increased slightly modifying scenario
multiple compatible sets. done, instance, nondeterministic
default classifications, e.g., wine Italian, either French Spanish default.
experiments shown small number compatible sets, performance enhancement
due decision criterion marginal, increases larger numbers compatible sets.
instance, 243 compatible sets (and thus 243 unfounded set checks) could observe speedup
13.59 12.19 seconds.
6.1.5 C ONFORMANT P LANNING
classical AI planning, planning domain contains description actions preconditions
effects world. Finding plan means find sequence actions reaches given
initial state state fulfilling given goal condition. Conformant planning (Goldman & Boddy, 1996;
Smith & Weld, 1998) problem initial state partially specified and/or
domain nondeterministic, executing plan reach goal regardless
action outcomes actual initial state.
experimented simple conformant planning domain: two robots limited
sensor range patrol area, object unknown initial location. goal find
sequence movements two robots detect object cases. experiments used encoding realizes conformant planning using Saturation (see above)
contains external atom computing whether patrol robots detect object (cf. Appendix A.2).
general, deciding existence short (polynomial length bounded) conformant plan p3 298

fimap size
34 (10)
44 (10)
54 (10)
64 (10)
74 (10)
84 (10)
94 (10)
104 (10)
114 (10)
124 (10)
134 (10)
144 (10)
154 (10)
164 (10)

plan length

34 (10)
44 (10)
54 (10)
64 (10)
74 (10)
84 (10)
94 (10)
104 (10)
114 (10)
124 (10)
134 (10)
144 (10)
154 (10)
164 (10)

answer sets
explicit

UFS
mol

UFS
mod

+EBL

+UFL


-EBL-UFL


+EBL+UFL

1
1
1
2
2
3
3
4
4
5
5
6
6
7

7.10 (0)
10.66 (0)
10.69 (0)
206.45 (2)
258.82 (5)
300.00 (10)
300.00 (10)
300.00 (10)
300.00 (10)
300.00 (10)
300.00 (10)
300.00 (10)
300.00 (10)
300.00 (10)

0.12 (0)
0.16 (0)
0.15 (0)
1.98 (0)
2.85 (0)
36.80 (0)
43.20 (0)
300.00 (10)
299.76 (9)
300.00 (10)
300.00 (10)
300.00 (10)
300.00 (10)
300.00 (10)

0.11 (0)
0.15 (0)
0.15 (0)
1.38 (0)
1.79 (0)
16.41 (0)
19.53 (0)
274.53 (5)
239.61 (5)
300.00 (10)
300.00 (10)
300.00 (10)
300.00 (10)
300.00 (10)

0.11 (0)
0.15 (0)
0.14 (0)
1.67 (0)
2.44 (0)
40.94 (0)
78.11 (0)
300.00 (10)
300.00 (10)
300.00 (10)
300.00 (10)
300.00 (10)
300.00 (10)
300.00 (10)

0.12 (0)
0.15 (0)
0.14 (0)
1.69 (0)
2.43 (0)
40.99 (0)
77.10 (0)
300.00 (10)
300.00 (10)
300.00 (10)
300.00 (10)
300.00 (10)
300.00 (10)
300.00 (10)

0.12 (0)
0.15 (0)
0.13 (0)
1.09 (0)
1.50 (0)
10.42 (0)
13.91 (0)
203.70 (2)
174.86 (2)
300.00 (10)
300.00 (10)
300.00 (10)
300.00 (10)
300.00 (10)

0.14 (0)
0.18 (0)
0.15 (0)
1.35 (0)
1.84 (0)
13.88 (0)
19.62 (0)
252.31 (5)
209.41 (3)
300.00 (10)
300.00 (10)
300.00 (10)
300.00 (10)
300.00 (10)

first answer set

plan length

map size

E FFICIENT HEX-P ROGRAM E VALUATION BASED U NFOUNDED ETS

explicit

UFS
mol

UFS
mod

+EBL

+UFL


-EBL-UFL


+EBL+UFL

1
1
1
2
2
3
3
4
4
5
5
6
6
7

0.89 (0)
1.36 (0)
2.23 (0)
7.21 (0)
17.39 (0)
139.26 (1)
150.50 (3)
255.89 (7)
300.00 (10)
287.76 (9)
300.00 (10)
300.00 (10)
300.00 (10)
300.00 (10)

0.05 (0)
0.06 (0)
0.06 (0)
0.22 (0)
0.34 (0)
6.07 (0)
3.24 (0)
92.19 (2)
97.11 (2)
198.75 (5)
287.07 (9)
300.00 (10)
300.00 (10)
300.00 (10)

0.05 (0)
0.05 (0)
0.07 (0)
0.15 (0)
0.22 (0)
2.73 (0)
1.47 (0)
47.58 (0)
39.99 (0)
143.52 (4)
211.97 (5)
244.33 (7)
300.00 (10)
300.00 (10)

0.05 (0)
0.05 (0)
0.06 (0)
0.14 (0)
0.21 (0)
2.73 (0)
1.69 (0)
82.84 (2)
84.08 (1)
184.81 (5)
277.79 (9)
300.00 (10)
300.00 (10)
300.00 (10)

0.05 (0)
0.06 (0)
0.06 (0)
0.14 (0)
0.20 (0)
2.69 (0)
1.70 (0)
82.52 (2)
83.85 (1)
184.78 (5)
277.71 (9)
300.00 (10)
300.00 (10)
300.00 (10)

0.06 (0)
0.06 (0)
0.07 (0)
0.12 (0)
0.17 (0)
1.45 (0)
0.89 (0)
24.23 (0)
19.53 (0)
131.46 (4)
165.64 (4)
213.89 (5)
285.36 (9)
300.00 (10)

0.06 (0)
0.06 (0)
0.07 (0)
0.13 (0)
0.18 (0)
1.78 (0)
1.16 (0)
31.36 (0)
25.85 (0)
136.64 (4)
185.84 (4)
232.85 (6)
296.10 (9)
300.00 (10)

Table 5: Conformant Planning Benchmark Results
complete, see Turner (2002), action executability decidable polynomial time, problem
p2 ; example domain enjoys property.
results displayed Table 5, shows averages 10 instances per size.
instances consist n4 grids n {3, . . . , 16}, plan length required finding solution
increases larger instance sizes. (This number robots increase
two robots must still cover whole area.) Instances generated randomly placing
robots opposite quarters map.
expected observe explicit FLP check performs worst, followed monolithic
UFS check encoding, modular UFS encoding; UFS encoding (without
external behavior unfounded set learning) performs best. External behavior learning (EBL)
unfounded set learning (UFL) improve performance, contrary increases run
times significantly modular UFS check slightly check. EBL change
times significantly explicit check, therefore omit results explicit +EBL.
looking profiling information domain found reasons: (a) external
atoms depend large part interpretation (locations robots) EBL cannot cut away
299

fiE ITER , F INK , K RENNWALLNER , R EDL , & CH ULLER

significant portions search space; (b) evaluating external atom takes negligible amount
time, beneficial effects EBL outweighed computational overhead. UFL
observed benchmark instances contain unfounded sets (pruning less half
answer set candidates) thus UFL cannot improve performance given overhead incurs.
conclude scenarios, using EBL UFL reduce efficiency.
check UFS check encoding constructed once, overhead EBL
UFL observed encoding longer big impact. Nevertheless without
learning slightly outperforms UFL EBL. analysis number UFS checks
number external atom evaluations (not shown table) revealed UFL EBL decreases
(i) number unfounded set checks needed (ii) number external atoms evaluated (in
one 94 instance, 5132 3341). Thus external computations would costly,
positive effects UFL EBL would outweigh computational overhead would
beneficial activate UFL EBL domain.
Interestingly, small map sizes see encoding, 34 instances actually
seem harder solve larger 44 54 instances. instances
require plan length 1 find solution; larger instances constrained smaller
instances robots less freedom move around still detecting objects.
Hence, 54 maps solver finds solutions faster 44 maps.
conclusion benchmark depending computational task external
atoms, UFL EBL beneficial harmful efficiency reasoning.
6.2 Summary
experiments shown learning technique EBL developed Eiter et al. (2012a)
techniques introduced paper lead significant performance improvements cases,
exceptions specific benchmarks. effects external behavior learning (EBL)
clearly evident explicit minimality check unfounded set-based check,
even prominent latter. Independently whether EBL used not, unfounded set
checking pushes efficiency HEX-program evaluation compared explicit minimality checking. Moreover, allows learning additional nogoods, also advantageous
benchmarks. Regarding two problem encodings, benchmarks show UFS check
usually faster encoding encoding, however former UFS check
involves initialization overhead, might counterproductive small programs.
decision criterion may lead additional speedup introduce notable overhead, thus always activated. Finally, program decomposition often leads additional
performance gain, used combination decision criterion otherwise single UFS check replaced multiple UFS checks, involves overhead.

7. Discussion
discuss related work outline possible starting points extensions.
7.1 Related Work
Constraint answer set solving (Gebser, Ostrowski, & Schaub, 2009) seen special case
HEX-programs. extends ASP dedicated constraint atoms rule bodies (comparisons
300

fiE FFICIENT HEX-P ROGRAM E VALUATION BASED U NFOUNDED ETS

numeric constraint variables) allow bidirectional exchange information
logic program constraint solver. constraint solver concrete instance
external source, HEX-programs support arbitrary external sources. idea external behavior
learning (EBL), introduced Eiter et al. (2012a) related work Drescher
Walsh (2012) since approaches generate nogoods on-the-fly.
Besides grounding, one main differences ASP SAT solving foundedness,
i.e., truth atom answer set justified non-circular derivation rules
facts. account circularity, notion unfounded set introduced van Gelder et
al. (1991) defining well-founded semantics logic programs negation, constructing
least fixpoint monotone operator partial assignments; total fixpoints operator
correspond stable models logic program. actually allows give characterization
stable models terms unfounded sets. fact, unfounded set checking turned
fruitful model-based approach ASP solving, equally successful syntactic counterpart
known loop formulas (Lin & Zhao, 2004; Lee & Lifschitz, 2003; Lee, 2005). Different kinds
unfounded set checks different complexities developed various program classes.
computation answer sets model generate test approach, pursued
many ASP solvers, requires form minimality check unfounded set check carried
already ordinary logic programs (i.e., absence external atoms). However, normal
program test tractable frequently realized using source pointers (Simons et al., 2002).
Intuitively, reasoner stores atom pointer rule possibly supports atom.
list source pointers updated propagation. point supporting
rule atom, conclude atom must false.
context ASP, notion unfounded set explicitly formulated extended disjunctive logic programs Leone et al. (1997), proved stable models
disjunctive logic program models unfounded-free. results basis
architecture DLV solver, generates answer set candidates checked
unfounded-freeness. test, like answer set checking disjunctive answer set programs,
co-NP-complete (Faber, 2005), reduced Koch et al. (2003) unsatisfiability testing
SAT instance. approach later extended conflict-driven learning unfounded
set checking Drescher et al. (2008), two instances CLASP solver, ASP instance
SAT instance, used generate check answer set candidates, respectively. parallel
work, technique recently refined exploiting assumptions encoding
unfounded set search need adopted current assignment (Gebser, Kaufmann, & Schaub, 2013). related uniform encoding unfounded set search,
still restricted disjunctive ASP without external sources. HEX-programs, unfounded set
search needs respect semantics external atoms thus general problem. Alviano, Calimeri, Faber, Leone, Perri (2011) consider normal logic programs monotone
antimonotone aggregate atoms, defined unfounded sets programs. Based this,
extended well-founded semantics Van Gelder et al. (1991), whichalthough closely
relatedis weaker general FLP semantics (Faber et al., 2011).
considered unfounded set checking presence external sources FLP
answer sets, results Drescher et al. (2008) immediately carry over. Indeed,
already ground Horn programs, presence nonmonotonic external atoms decidable
polynomial time makes unfoundedness checking intractable (more precisely, co-NP-complete),
deciding existence FLP answer set p2 -complete problem ground case.
301

fiE ITER , F INK , K RENNWALLNER , R EDL , & CH ULLER

computationally harder external atoms, complexity may increase relative oracle
external function (see Faber, 2005). However, results paper still apply
cases.
Drescher et al. (2008) employed also splitting technique, goes back work Leone
et al. (1997); related program decomposition, works ASP programs without external sources only. Note notion splitting different well-known splitting sets
Lifschitz Turner (1994), consider positive dependencies ordinary atoms.
consider e-cycles, specific HEX-programs, interest Drescher et al. (2008)
head-cycles, may arise disjunctive rule heads. fact, approach may regarded extension one Drescher et al., since evaluation follows principles
performing UFS checks case head-cycles.
evaluation FLP semantics, unfounded set check explicit FLP check instrumental. mention semantics HEX-programs may involve step
intractable general (as follows Leone et al., 2006, already ground Horn programs
nonmonotonic external atoms decidable polynomial time). instance, Shen (2011)
Shen Wang (2011) present well-justified semantics unfounded set checking essentially replaced fixpoint iteration which, intuitively, tests model candidate reproduces
excludes circular justifications. However, complexity answer set computation
decrease approach general, particular deciding well-justified answer set existence ground Horn programs nonmonotonic external atoms decidable polynomial
time p2 -complete, thus hard deciding existence answer sets Definition 3.
7.2 Extensions
designed unfounded set check postcondition test; like explicit FLP check,
carried complete assignment generated answer set candidate.
However, certain cases might obvious partial interpretation (in truth values
open) extended answer set, existence unfounded set guaranteed
extension complete assignment. One backtrack earlier, intuitively leads
saving certain classes instances.
Exploring idea, generalized framework control component decides, based heuristics, unfounded set check carried out; standard setting,
whenever assignment model generation complete (i.e., complete assignment
given).
UFS check partial assignments, sound respect extension complete
assignment, possible ASP solver finished unit propagation maximal subset
program interpretation already complete it, guessed values external
atom replacements correct. thus used criterion, easy test, greedy
heuristics issue UFS checks prototype system.
However, contrast initial expectation, found benchmarks UFS
check wrt. partial assignments productive. closer look reveals essentially nogood learning unfounded sets (UFL) effectively avoids reconstruction
unfounded set anyway. therefore rarely happens UFS checking wrt. partial interpretation
identifies unfounded set earlier UFS checking wrt. complete interpretations. Therefore,
believe UFS checking wrt. partial interpretation rarely identifies unfounded set earlier
UFS checking wrt. complete assignments. UFS checking HEX-programs involves evalu302

fi#args

E FFICIENT HEX-P ROGRAM E VALUATION BASED U NFOUNDED ETS

5 (1)
6 (1)
7 (1)
8 (1)
9 (1)
10 (1)
15 (1)
20 (1)
25 (1)


+EBL+UFL

answer sets
partial (periodic) partial (max)
+EBL+UFL
+EBL+UFL

0.07 (0)
0.10 (0)
0.13 (0)
0.18 (0)
0.24 (0)
0.29 (0)
0.80 (0)
1.96 (0)
4.15 (0)

0.09 (0)
0.13 (0)
0.15 (0)
0.20 (0)
0.26 (0)
0.33 (0)
0.96 (0)
2.46 (0)
5.52 (0)

0.11 (0)
0.15 (0)
0.19 (0)
0.26 (0)
0.35 (0)
0.47 (0)
1.61 (0)
4.92 (0)
11.25 (0)


+EBL+UFL

first answer set
partial (periodic)
+EBL+UFL

partial (max)
+EBL+UFL

0.05 (0)
0.06 (0)
0.07 (0)
0.08 (0)
0.09 (0)
0.11 (0)
0.24 (0)
0.51 (0)
0.97 (0)

0.06 (0)
0.07 (0)
0.08 (0)
0.10 (0)
0.12 (0)
0.14 (0)
0.38 (0)
0.97 (0)
1.98 (0)

0.07 (0)
0.09 (0)
0.11 (0)
0.14 (0)
0.17 (0)
0.21 (0)
0.73 (0)
2.30 (0)
4.50 (0)

#ctx

Table 6: Set Partitioning UFS Checking Partial Assignments

3 (6)
4 (10)
5 (8)
6 (6)
7 (12)
8 (5)
9 (8)
10 (11)


+EBL+UFL

partial (periodically)
+EBL+UFL

partial (max)
+EBL+UFL

0.08 (0)
0.11 (0)
0.12 (0)
0.15 (0)
0.20 (0)
0.21 (0)
0.24 (0)
0.31 (0)

0.09 (0)
0.11 (0)
0.12 (0)
0.15 (0)
0.20 (0)
0.21 (0)
0.24 (0)
0.31 (0)

0.10 (0)
0.12 (0)
0.13 (0)
0.16 (0)
0.21 (0)
0.22 (0)
0.27 (0)
0.32 (0)

#ctx

Table 7: Consistent MCSs Benchmark Results UFS Checking Partial Assignments

3 (9)
4 (14)
5 (11)
6 (18)
7 (13)
8 (6)
9 (14)
10 (12)


+EBL+UFL
0.14 (0)
0.61 (0)
1.28 (0)
1.55 (0)
29.47 (0)
51.13 (1)
130.56 (6)
277.05 (11)

answer sets
partial (periodic) partial (max)
+EBL+UFL
+EBL+UFL
0.13 (0)
0.64 (0)
1.36 (0)
1.67 (0)
31.54 (0)
51.22 (1)
130.99 (6)
277.20 (11)

0.16 (0)
0.88 (0)
1.81 (0)
2.49 (0)
44.90 (1)
51.66 (1)
133.84 (6)
278.21 (11)


+EBL+UFL

first answer set
partial (periodic)
+EBL+UFL

partial (max)
+EBL+UFL

0.09 (0)
0.13 (0)
0.16 (0)
0.18 (0)
0.17 (0)
0.19 (0)
0.28 (0)
0.34 (0)

0.09 (0)
0.13 (0)
0.16 (0)
0.18 (0)
0.17 (0)
0.20 (0)
0.27 (0)
0.35 (0)

0.10 (0)
0.14 (0)
0.17 (0)
0.18 (0)
0.18 (0)
0.21 (0)
0.28 (0)
0.36 (0)

Table 8: Inconsistent MCSs Benchmark Results UFS Checking Partial Assignments
ation external sources compatibility testing, easily leads costs higher
potential savings. detailed analysis requires studies; since results seem
promising, leave possible future work.
Table 610 show benchmark results UFS checking wrt. partial assignments enabled
computing first answer set only.
first column shows runtime UFS checking wrt. complete interpretations only, using
encoding , EBL UFL (equivalent last column tables Section 6). second
column shows results UFS checking wrt. partial assignments, using heuristics
performs UFS check periodically (periodic). third column shows runtimes UFS
check always performed, propagation technique derive truth values (max).
303

fi#args

E ITER , F INK , K RENNWALLNER , R EDL , & CH ULLER

1 (30)
2 (30)
3 (30)
4 (30)
5 (30)
6 (30)
7 (30)
8 (30)
9 (30)
10 (30)
11 (30)
12 (30)
13 (30)
14 (30)
15 (30)
16 (30)
17 (30)
18 (30)
19 (30)
20 (30)


+EBL+UFL
0.05 (0)
0.07 (0)
0.09 (0)
0.13 (0)
0.19 (0)
0.36 (0)
0.56 (0)
1.15 (0)
1.95 (0)
4.79 (0)
9.48 (0)
12.39 (0)
24.44 (0)
51.98 (3)
78.19 (3)
77.95 (4)
76.85 (5)
125.91 (8)
147.62 (10)
166.07 (12)

answer sets
partial (periodic) partial (max)
+EBL+UFL
+EBL+UFL
0.05 (0)
0.06 (0)
0.09 (0)
0.14 (0)
0.20 (0)
0.36 (0)
0.56 (0)
1.15 (0)
1.94 (0)
4.80 (0)
9.49 (0)
12.42 (0)
24.45 (0)
52.03 (3)
78.14 (3)
77.99 (4)
76.86 (5)
126.17 (8)
147.51 (10)
165.96 (12)

0.05 (0)
0.07 (0)
0.10 (0)
0.16 (0)
0.22 (0)
0.39 (0)
0.59 (0)
1.19 (0)
2.01 (0)
4.96 (0)
9.71 (0)
12.79 (0)
25.32 (0)
52.57 (3)
79.81 (3)
79.52 (4)
77.82 (5)
128.83 (8)
149.62 (10)
168.53 (12)


+EBL+UFL

first answer set
partial (periodic)
+EBL+UFL

partial (max)
+EBL+UFL

0.05 (0)
0.06 (0)
0.08 (0)
0.12 (0)
0.17 (0)
0.29 (0)
0.40 (0)
0.94 (0)
1.34 (0)
3.68 (0)
4.69 (0)
6.13 (0)
16.50 (0)
41.76 (2)
41.62 (2)
40.84 (3)
35.57 (2)
75.10 (5)
67.04 (4)
82.45 (5)

0.05 (0)
0.07 (0)
0.08 (0)
0.12 (0)
0.16 (0)
0.29 (0)
0.40 (0)
0.94 (0)
1.35 (0)
3.67 (0)
4.71 (0)
6.11 (0)
16.46 (0)
41.80 (3)
41.53 (2)
40.79 (3)
35.53 (2)
75.32 (5)
66.88 (4)
82.27 (5)

0.05 (0)
0.07 (0)
0.09 (0)
0.14 (0)
0.18 (0)
0.31 (0)
0.42 (0)
0.96 (0)
1.39 (0)
3.75 (0)
4.74 (0)
6.23 (0)
16.80 (0)
41.98 (3)
42.02 (2)
41.04 (3)
35.58 (2)
75.37 (5)
67.59 (4)
82.90 (5)

Table 9: Argumentation UFS Checking Partial Assignments
observed UFS checking wrt. partial assignments lead speedup
case. Quite contrary, instances significantly higher runtimes frequent unfounded set checks. best visible set partitioning benchmark (Table 6),
computing explanations inconsistent MCSs 5, 6 7 contexts (Table 9), computing answer sets conformant planning benchmark (Table 10). set partitioning
benchmark effects especially significant, expected every compatible set
unfounded-free. Thus, additional UFS checks always counterproductive. consistent
multi-context systems, reasoning fast anyway, thus frequency UFS checking significant impact (Table 7). argumentation benchmark also observe slight slowdown
frequent UFS checking, although less dramatic benchmarks
propagation methods applicable frequently thus fewer UFS checks performed
even setting max (Table 9).
hand, ASP solving (where extra costs incur), UFS checks partial
interpretations may still beneficial, reported Gebser et al. (2013). conclusion, UFS
checks partial assignments HEX-programs require tailored heuristics take
structure program, also domain-specific knowledge account, remains
future work.

8. Conclusion
HEX -programs expressive extension non-monotonic logic programs access external
information via external atoms; supported plugin architecture fruitfully deployed
range applications. External atoms however make efficient evaluation HEX-programs
challenging task, particular compute answer sets HEX-program ,
models subset-minimal models FLP-reduct f (which keeps rules whose

304

fi#ctx

E FFICIENT HEX-P ROGRAM E VALUATION BASED U NFOUNDED ETS

34 (10)
44 (10)
54 (10)
64 (10)
74 (10)
84 (10)
94 (10)
104 (10)
114 (10)
124 (10)
134 (10)
144 (10)
154 (10)
164 (10)

1
1
1
2
2
3
3
4
4
5
5
6
6
7

answer sets
partial (periodic) partial (max)
+EBL+UFL
+EBL+UFL
+EBL+UFL

first answer set
partial (periodic) partial (max)
+EBL+UFL
+EBL+UFL
+EBL+UFL

0.14 (0)
0.18 (0)
0.15 (0)
1.35 (0)
1.84 (0)
13.88 (0)
19.62 (0)
252.31 (5)
209.41 (3)
300.00 (10)
300.00 (10)
300.00 (10)
300.00 (10)
300.00 (10)

0.06 (0)
0.06 (0)
0.07 (0)
0.13 (0)
0.18 (0)
1.78 (0)
1.16 (0)
31.36 (0)
25.85 (0)
136.64 (4)
185.84 (4)
232.85 (6)
296.10 (9)
300.00 (10)

0.14 (0)
0.17 (0)
0.15 (0)
1.35 (0)
1.83 (0)
14.23 (0)
19.96 (0)
257.18 (5)
214.72 (3)
300.00 (10)
300.00 (10)
300.00 (10)
300.00 (10)
300.00 (10)

0.16 (0)
0.20 (0)
0.18 (0)
1.48 (0)
2.03 (0)
17.27 (0)
23.75 (0)
289.20 (7)
244.84 (5)
300.00 (10)
300.00 (10)
300.00 (10)
300.00 (10)
300.00 (10)

0.06 (0)
0.06 (0)
0.07 (0)
0.13 (0)
0.18 (0)
1.86 (0)
1.18 (0)
33.40 (0)
27.15 (0)
137.22 (4)
188.73 (4)
235.06 (7)
297.42 (9)
300.00 (10)

0.08 (0)
0.08 (0)
0.09 (0)
0.15 (0)
0.21 (0)
2.36 (0)
1.42 (0)
49.36 (0)
37.64 (0)
142.74 (4)
209.44 (4)
243.73 (7)
300.00 (10)
300.00 (10)

Table 10: Conformant Planning UFS Checking Partial Assignments

bodies satisfied). improve expensive test (which customary implementations
far), presented alternative test based unfounded sets obtain adapting
notion unfounded set aggregates Faber (2005) external atoms. Also Alviano et al. (2011)
use related notion unfounded sets programs aggregates, restrict discussion
monotonic antimonotonic aggregates. realized unfounded set (UFS) checking
transformation SAT solving, satisfying assignments constructed CNF generate
candidate unfounded sets, turn subject (rather simple) postcheck takes external
atom evaluation account.
particular, provided two SAT encodings UFS checking: conceptually simple
encoding
, needs initialization every UFS check, advanced encoding ,
reused UFS checks. boost performance, shown learn
unfounded sets deriving nogoods, i.e., constraints (possibly involving also external atoms)
guide future search model generation help avoid unfounded sets regenerated.
elaboration, refined basic approach suitable program splitting,
UFS check carried independently program components, cutting complexity.
Furthermore, presented syntactic criterion allows us decide efficiently whether
UFS check safely skipped component whole program, exploiting answer
set candidates model search special unfounded sets involve cyclic input
external atoms; HEX-programs simple applications, usually case.
experimental evaluation new approach, considered different combinations
techniques comprised problems various domains including multi-context systems,
abstract argumentation, default reasoning ontologies, conformant planning, HEXprograms serve easy-cut declarative problem solving, shown efficient
traditional minimal model check; lead exponential gains yields often drastic performance improvements, slower (except cases marginal amount).
Furthermore, reusable encoding turned beneficial programs require many
unfounded set checks, includes programs many answer sets.
305

fiE ITER , F INK , K RENNWALLNER , R EDL , & CH ULLER

8.1 Future work
issue improvement approach paper heuristics UFS checking partial assignments. natural heuristics considered counterproductive,
others might lead additional speedup cases. However, may require incorporate
domain-specific knowledge external atoms; currently done learning algorithms heuristics. line, one might consider developing heuristics
dynamically choosing UFS search encodings presented, study heuristics
guiding unfounded set search, i.e., variable selection SAT solver. Currently,
implementation applies heuristics unfounded set search model generation process. However, experimental comparison explicit minimality check terms
considered candidate sets suggests room improvement employing suitable
choices. Developing appropriate heuristics validating effectiveness candidate set enumeration remains explored. Finally, obvious issue criteria allow skip
UFS check simplify efficiently tested.

Acknowledgments
Preliminary results work presented 13th European Conference Logics
Artificial Intelligence (JELIA 2012), September 26-28, 2012, Toulouse, France (Eiter, Fink, Krennwallner, Redl, & Schuller, 2012c), 5th Workshop Answer Set Programming
Computing Paradigms (ASPOCP 2012), September 4, 2012, Budapest, Hungary (Eiter, Fink, Krennwallner, Redl, & Schuller, 2012b). grateful anonymous reviewers helpful
constructive comments. work supported Austrian Science Fund (FWF) via
projects P20840, P20841, P24090, Vienna Science Technology Fund (WWTF)
project ICT08-020. Peter Schuller supported TUBITAK Fellowship 2216.

Appendix A. Benchmark Encodings
appendix, give details benchmark encodings (those described references). note encodings developed tuned
good performance serve merely experimental comparison various FLP check realizations. Benchmark encodings HEX-plugins publicly available https://github.com/
hexhex/benchmarks.
A.1 Abstract Argumentation
Abstract Argumentation benchmark results Section 6.1 obtained using following
encoding, derived encodings admissible preferred set extensions argumentation framework (A, att) described Egly, Gaggl, Woltran (2010).
Input instances benchmark defined set arguments encoded facts arg(a)
set att attacks arguments, encoded facts att(a, b)
(a, b) A. encoding consists following rules x, y, z A; similar
encodings explained detail Egly et al. (2010) (but without use external atoms).
define defeat attacks.
defeat(x, y) att(x, y).
306

fiE FFICIENT HEX-P ROGRAM E VALUATION BASED U NFOUNDED ETS

guess set using predicates inS outS .
inS (x) outS (x), arg(x).

outS (x) inS (x), arg(x).

require arguments conflict-free defended S.

inS (x), inS (y), defeat(x, y).

defeated (x) inS (y), defeat(y, x).

notDefended (x) defeat(y, x), defeated (y).
inS (x), notDefended (x).

saturation define linear order arguments, including infimum supremum.
lt(x, y) arg(x), arg(y).

(x < y)

nsucc(x, z) lt(x, y), lt(y, z).

succ(x, y) lt(x, y), nsucc(x, y).
ninf (x) lt(y, x).

nsup(x) lt(x, y).

inf (x) ninf (x), arg(x).

sup(x) nsup(x), arg(x).

perform guess set using disjunction.

inT (x) outT (x) arg(x).

check argument whether spoil answer set .
sInT upto (y) inf (y), inS (y), inT (y).
sInT upto (y) inf (y), outS (y).

sInT upto (y) succ(z, y), inS (y), inT (y), sInT upto (z).
sInT upto (y) succ(z, y), outS (y), sInT upto (z).
sInT sup(y), sInT upto (y).
spoil sInT .

also spoil answer set preferred extension, determined external atom
semantic function f&argSemExt f&argSemExt (A, pref , arg, att, inT , unused , spoil ) =
1 iff Fspoil extension predicate inT preferred set extension argumentation
framework specified extension predicates arg att. Internally, external atom uses
another ASP program compute semantics. check performed using ASP encoding
preferred extensions Egly et al. (2010).
tIsNotPref &argSemExt[pref , arg, att, inT , unused , spoil ]().
spoil tIsNotPref .

Note parameters pref unused support general functionalities f&argSemExt
relevant benchmark. create unique answer set whenever spoil true
require spoiled answer sets returned.
inT (x) spoil , arg(x).
sInT spoil .

outT (x) spoil , arg(x).

tIsNotPref spoil .

spoil .

Given instance encoded above, answer set program exists iff exists
ideal set extension given argumentation framework.
307

fiE ITER , F INK , K RENNWALLNER , R EDL , & CH ULLER

A.2 Conformant Planning
Conformant Planning benchmark results Section 6.1 obtained using following encoding.
Input instances benchmark defined set R robots, sets X valid x
coordinates environment, maximum plan length l; instance contains robot
r R initial position (x, y) facts robo X (r, x, 0) robo (r, y, 0). encoding consists
following rules where, unless stated otherwise, 0 < l, r R, x X, .
robot generate four possible moves environment.
move(r, x, + 1, t) move(r, x, + 1, t) robo X (r, x, t), robo (r, y, t).

(y + 1 )

move(r, x + 1, y, t) move(r, x + 1, y, t) robo X (r, x, t), robo (r, y, t).

(x + 1 X)

move(r, x, 1, t) move(r, x, 1, t) robo X (r, x, t), robo (r, y, t).

(y 1 )

move(r, x 1, y, t) move(r, x 1, y, t) robo X (r, x, t), robo (r, y, t).

(x 1 X)

disallow moving multiple locations standing still (the latter strictly necessary
obtained experimental results way).
move(r, x1 , y1 , t), move(r, x1 , y2 , t).

(x1 , x2 X, x1 < x2 , y1 , y2 )

move(r, x, y1 , t), move(r, x, y2 , t).

(y1 , y2 Y, y1 < y2 )

move (r, t) move(r, x, y, t).

move (r, t).

effect moving deterministic change location.
robo X (r, x, + 1) move(r, x, y, t).

robo (r, y, + 1) move(r, x, y, t).

saturation guess position object.
obj X (x) obj X (x) .

obj X (y) obj (y) .

spoil answer set object multiple locations.
spoil obj X (x1 ), obj X (x2 ).

(x1 , x2 X, x1 < x2 )

spoil obj (y1 ), obj (y2 ).

(y1 , y2 Y, y1 < y2 )

spoil answer set object location.
objectHasNoXUpTo(1) obj X (1).

objectHasNoXUpTo(x) objectHasNoXUpTo(x 1), obj X (x).
spoil objectHasNoXUpTo(xmax ).

objectHasNoYUpTo(1) obj (1).

objectHasNoYUpTo(y) objectHasNoYUpTo(y 1), obj (y).
spoil objectHasNoYUpTo(ymax ).

(x 1 X)

(xmax = max(X))
(y 1 )

(ymax = max(Y ))

spoil answer set object sensed, determined external atom
semantic function f&sense f&sense (A, robo X , robo , obj X , obj , range, spoil ) = 1 iff
308

fiE FFICIENT HEX-P ROGRAM E VALUATION BASED U NFOUNDED ETS

Tspoil predicates robo X , robo , obj X , obj represent state robot
distance less range object, i.e., robot detect object. Theq
implementation
external atom realized C++ consists verifying range
2x + 2y
bookkeeping code extract x A.
spoil &sense[robo X , robo , obj X , obj , range, spoil ]().
create unique answer set whenever spoil true require spoiled answer sets
returned.
obj X (x) spoil .

obj X (x) spoil .

objectHasNoXUpTo(x) spoil .

objectHasNoYUpTo(y) spoil .

obj (x) spoil .

obj (x) spoil .

spoil .

Given instance encoded above, answer set program exists iff exists
sequence movements ensures detect object matter located. Furthermore
movements required detect object, i.e., conformant plan, encoded answer set
extension move predicate.

Appendix B. Proofs
Proof Proposition 1. () Let A0 answer set Check (, A) f&g (A0 , p, c) = 1
iff Te&g[p] (c) A0 external atoms &g[p](c) .
Since compatible set , f&g (A, p, c) = 1 iff Te&g[p] (c) external atoms

&g[p](c) . Thus, f f replacement atoms place external atoms,
additional guessing rules replacement atoms. Since A0 model Check (, A)
also model f . Let A00 = {Ta A0 | A()} {Fa A0 | A()}. Since
f&g (A0 , p, c) = 1 iff Te&g[p] (c) A0 external atoms &g[p](c) assumption, A00
model f .
Since A0 answer set Check (, A), Check (, A) A()
Ta 6 (and thus Ta 6 A), {Ta A00 | A()} A. Finally, due { smaller }
{smaller | A(), Ta A} Check (, A), least one A()
s.t. Ta (and thus also Ta A), Fa A0 (and thus also Fa A00 ). Therefore
{Ta A00 | A()} ( model , thus answer set .
() answer set , model A00 f smaller
positive part, i.e., {Ta A00 } ( {Ta A}. Let
A0 = (, A00 ) {Ta0 | Ta A, Fa A00 } {Fa0 | Ta A, Ta A00 } {Tsmaller }.
show A0 answer set Check (, A) f&g (A0 , p, c) = 1 iff Te&g[p] (c) A0
external atoms &g[p](c) .
Since extracted compatible set , f f
replacement atoms place external atoms, additional guessing rules replacement
atoms. Since A00 model f , truth values replacement atoms A0 coincide
309

fiE ITER , F INK , K RENNWALLNER , R EDL , & CH ULLER

oracle functions definition (, A00 ), set exactly one ea ne
external atom true (and thus satisfy guessing rules replacement atoms), A0
model f . Since {Ta A00 } ( {Ta A} thus also {Ta A0 | A()} ( {Ta
| A()}, corresponding constraint Check (, A) violated. Moreover,
Ta either Ta A0 Ta0 A0 , thus corresponding rule a0
Check (, A) satisfied. Finally, since Tsmaller A0 , rules {smaller |
A(), Ta A} satisfied constraint smaller fire. Thus A0 model
Check (, A).
0
show A0 also subset-minimal model f Check (, A)A . Observe
0

f Check (, A)A = f {a a0 | Ta A}

{smaller | A(), Ta A}.
0

However, atom A(f Check (, A)A ) Ta A0 changed false, interpretation model anymore corresponding rule a0 violated, one
a0 true A0 definition; thus interpretation smaller positive part A0
0
model f Check (, A)A . Hence A0 answer set Check (, A).
Finally, f&g (A0 , p, c) = 1 iff Te&g[p] (c) A0 external atoms &g[p](c) definition (, A00 ).
2
Proof Proposition 2. result follows Proposition 1 fact programs
Check (, A) CheckOptimized (, A) answer sets. Indeed, construction
programs models; consequently, every answer set A0 Check (, A) (which
0
model Check (, A)) model f CheckOptimized (, A)A . A0 minimal model
0
f Check (, A)A , due guessing rules a0 , Ta A, ea ne ,
external atoms Check (, A), either {Ta, Fa0 } A0 {Fa, Ta0 } A0 (but
both) either {Tea , Fne } A0 {Fea , Tne } A0 (but both); furthermore, due
constraints every A() Ta
/ A, Fa A0 a.
guessing rules constraints also CheckOptimized (, A), every model A00
0
CheckOptimized (, A)A A00 CheckOptimized(,A) A0 atoms a, a0 , ea , ne
must thus value A0 ; consequently, also smaller must value
0
A0 . follows A0 minimal model f CheckOptimized (, A)A , i.e., A0 answer set
CheckOptimized (, A). argument every answer set CheckOptimized (, A)
answer set Check (, A) analogous.
2
Proof Theorem 3. argument proves Corollary 3 Faber (2005) used mutatis
mutandi prove statement, external atoms place aggregates.
2
Proof Proposition 4. proceed contraposition show (U,
, , A)


solution , U cannot unfounded set U 6= .
First observe nogoods Hr,A demand Thr true rule r solution

head atom h H(r) rule U . truth values hr
h H(r) defined (U,
, , A) exactly criterion, nogood Hr,A
violated
involved contradiction. Furthermore, nogood {Fa | Ta A} N,



(U,
, , A) U = ; hence, (U, , , A) solution
310

fiE FFICIENT HEX-P ROGRAM E VALUATION BASED U NFOUNDED ETS

conservative, rule r nogood C
U 6= , O,
r,A must
violated. is, know following: Thr (U,
,
,
A)
(and
therefore
H(r)
U 6= ),


+

Fa (U, , , A) Bo (r), ta (U, , , A) (r), Th
(U,
, , A) h H(r) |= h. Moreover, Cr,A 6= . show
implies none conditions (i)(iii) Definition 5 holds r wrt. U A,
means U unfounded set.
Condition (i) hold r |= B(r) (otherwise Cr,A = ).
Condition (ii)
hold r. Suppose contrary holds. must
.
b B(r) s.t. .U 6|= b. Cr,A 6= , know |= b. make case
distinction type b:
b positive default
literal A(), Fb (U,
, , A) therefore b 6 U .
.
Consequently .U |= b. Contradiction.
.
b negative default literal A() , |= b implies .U |= b. Contradiction.
b positive default-negated replacement atom,
tb (U,
, , A).
.

implies, definition (U, , , A), .U |= b. Contradiction.
Condition (iii) hold r Th (U,
, , A) thus, definition
(U,
,
,
A),
h

U


h

H(r)


|=
h.
Thus

6|= H(r) \ U .
2


Proof Theorem 6. Suppose U unfounded set. r s.t. H(r)U 6=
none conditions (i)(iii) Definition 5 satisfied. show cannot
solution
satisfies conditions (a) (b), proves result.
Condition (i) hold, nogood form
{{Thr } {Fa | Bo+ (r), |= a} {ta | (r)} {Th | h H(r), |= h}}


.
show contains signed literals nogood, i.e., nogood violated
assignment S.
Since H(r) U 6= , Thr (otherwise nogood HrA violated). U
unfounded set, Condition (ii) .in Definition 5 hold. Consider Bo+ (r) s.t. |= a.
6 U , otherwise .U 6|= contradiction assumption
Condition (ii) unsatisfied. Fa (because complete would imply U
otherwise).
.
consider &g[p](c) EA(r). .U |= &g[p](c) (as (ii) violated).
6|= &g[p](c), Condition (i) would satisfied, hence |= &g[p](c). Te&g[p] (c)
.
S, otherwise .U 6|= &g[p](c)
precondition (b) proposition. Next consider
.
&g[p](c) (r). .U 6|= &g[p](c) (as (ii) violated). |= &g[p](c),
Condition (i) would satisfied, hence 6|= &g[p](c). Fe&g[p] (c) S, otherwise
.
.U |= &g[p](c) precondition (a) proposition. Therefore, ta
(r).
Finally, Condition (iii) Definition 5 hold, h U therefore also Th
h H(r) |= a.
concludes proof cannot solution
satisfying (a) (b), U
unfounded set.
2
Proof Proposition 7. Let = (U,
&g[y](x)
, , A). external atom
.
Te&g[y] (x) S, definition (U,
,
,
A)




.U |= &g[y](x)

311

fiE ITER , F INK , K RENNWALLNER , R EDL , & CH ULLER

(satisfying (a)). external atom &g[y](x) Fe&g[y] (x) S, definition
.
(U,
2
, , A) .U 6|= &g[y](x) (satisfying (b)).
Proof Proposition 8. proceed contraposition show (U, , , A)
solution assumptions AA , U cannot unfounded set U 6= .
First observe nogoods Hr demand Thr true rule r
head atom h H(r) rule U . Moreover, nogoods Da
A() force
.
.
aA.U true Ta
/ U , equivalent Ta .U ; aAU
true Ta U ; aAU true Fa U .
.
truth values hr r , aA.U
aAU aAU A()
(U, , , A) defined exactly conditions, contradiction must involve Cr
r . Furthermore, nogood {Fa | A()} violated (U, , , A)
A() U = , thus U 6= ; hence, (U, , , A) solution
U 6= , since O, conservative, rule r nogood Cr must violated.
is, know following:
(I) Thr (U, , , A) (and therefore H(r) U 6= ),
(II) TaA (U, , , A) B + (r) FaA (U, , , A) B (r),
(III) FaAU (U, , , A) Bo+ (r), ta (U, , , A) (r),
(IV) ThAU (U, , , A) h H(r).

show implies none conditions Definition 5 holds r wrt. U
A, means U unfounded set (hr true (U, , , A), implies
H(r) U 6= x).
Condition (i) hold r (II), assumptions AA implies |=
B(r). Condition (ii) does. hold r. Suppose contrary holds. must
b B(r) s.t. .U 6|= b. Since Condition (i) already known violated,
assume |= b. make case distinction type b:
.
b positive default literal A() , b U (otherwise .U |= b).
definition (U, , , A) TbAU (U, , , A), contradicts
(III).
.
b negative default literal A() , |= b implies .U |= b. Contradiction.
b positive default-negated replacement atom,
tb (U, , , A).
.
implies, definition (U, , , A), .U |= b. Contradiction.
Condition (iii) hold r ThAU (U, , , A) thus, definition
(U, , , A), h U h H(r) |= h. Thus 6|= H(r) \ U . 2
Proof Theorem 10. Suppose U unfounded set. r exists
H(r) U 6= none conditions (i)(iii) Definition 5 satisfied. show S,
assuming AA satisfied (a) (b) hold, cannot solution .
Due rule r, (more specifically, N, ) contains nogood N form
N = { {Thr }
{TaA | B + (r)} {FaA | B (r)}
{FaAU | Bo+ (r)} {ta | (r)}
{ThAU | h H(r)} }.
312

fiE FFICIENT HEX-P ROGRAM E VALUATION BASED U NFOUNDED ETS

show contains signed literals N , i.e., N violated S. H(r) U 6= ,
Thr (otherwise nogood Hr violated). Furthermore, U unfounded set,
Condition (i) Definition 5 hold U wrt. A, hence |= B(r). assumptions
AA thus enforce TaA B + (r) FaA B (r).
Consider next arbitrary Bo+ (r). Condition (ii) Definition 5 hold U
wrt. A, |= 6 U ; latter implies definition U Fa S.
nogood {TaAU , Fa} conclude FaAU S.
next
show every (r), holds ta S. Indeed, let &g[p](c) EA(r).
.
.U |= &g[p](c) (as Condition (ii) violated). Furthermore, |= &g[p](c), 6|=
&g[p](c) would imply Condition (i) satisfied. Thus Condition (b)
hypothesis,
.
follows Te&g[p] (c) S. Similarly, let &g[p](c) (r). .U 6|= &g[p](c) (as
Condition (ii) violated) 6|= &g[p](c) |= &g[p](c) would satisfy Condition (i). Thus
Condition (a) hypothesis, follows Fe&g[p] (c) S. Thus ta
(r).
Finally, Condition (iii) Definition 5 hold U wrt. A, h U
therefore also Th h H(r) |= a. is, h H(r), either FhA
Th S. nogoods {FhAU , FhA }, {FhAU , Th} Dh , cases
ThAU S.
Hence, N holds, i.e., N violated S, thus solution . completes
proof result.
2
Proof Proposition 11. Let = (U, , , A). external atom
&g[y](x)
.
Te&g[y] (x) S, definition (U, , , A) .U |= &g[y](x)
(satisfying (a)). external atom &g[y](x) Fe&g[y] (x) S, definition
.
2
(U,
, , A) .U 6|= &g[y](x) (satisfying (b)).
Proof Proposition 12. show U \ {a} unfounded set wrt. A, consider r
H(r) (U \ {a}) 6= . show one conditions (i)(iii) Definition 5
holds r. hypothesis, U unfounded set wrt. A, H(r) (U \ {a}) 6= implies
H(r)U 6= . Condition (i) holds U , also holds wrt. U \{a} condition depends
.
r A. Also
Condition (ii) holds U , also holds wrt. U \ {a} .U
.
equivalent .(U \ {a}) since 6|= a. Finally, Condition (iii) holds U ,
atom b H(r) \ U exists |= b. 6|= a, follows 6= b hence condition (iii)
holds U \ {a}. proves result.
2
Proof Proposition 13. Suppose changing truth value b turns solution

counterexample Sb
(resp. ). is, Sb must violate nogood N resp.
(N ) containing b, i.e., either Tb N Fb N .
+

encoding
, nogood N corresponds rule b B (r) b B (r)
+
|= B(r), N contains also signed literals (1) Fa Bo |= (2) Ta
H(r) |= a. hypothesis, either (a) Ta Bo+ (r)
|= a, (b) Fa H(r) |= a. nogood cannot violated,
(a) contradicts one (1) (b) contradicts one (2).
encoding , nogood N corresponds rule r b B + (r) b B (r).
nogood contains also signed literals (1) TaA B + (r) FaA B (r), (2)
FaAU Bo+ , (3) ThAU h H(r). (1) since solution
313

fiE ITER , F INK , K RENNWALLNER , R EDL , & CH ULLER

AA , |= B(r). hypothesis, either (a) Ta Bo+ (r)
|= a, (b) Fa H(r) |= a. nogood N cannot
violated, (a) contradicts part (2) definition AA aAU , (b) contradicts part (3)
definition AA hAU .
2
Proof Proposition 14.
(N, A) = proposition trivially holds. Otherwise
(N, A) = {C} know Tti 1 n. Suppose C violated

(U,
, , A). Fti (U, , , A) therefore ti 6 U 1 n,

Tfi (U, , , A) 1 |= fi , e&g[p] (c) (U,
, , A).
.
.
.U |= ti 1 n .U 6|= fi 1 . m.
nogood N valid input-output-relationship, implies &g[p](c) .U . definition

(U,
, , A), e&g[p] (c) (U, , , A), contradicts assumption
(N, A) violated.
2
Proof Proposition 15. know (N ) = {C}. Suppose (U, , , A) violates C.
TtiA (U, , , A) therefore Tti Fti (U, , , A) 1 n;
.
Ffi A.U
(U, , , A) therefore either Ffi fi U , 1 m;
e&g[p] (c) I(U, , A).

then, definition (U, , , A), Tti
ti 6 U 1 n, hence
.
.
.U |= ti 1 n. Moreover, .U 6|= fi 1
m.
.
nogood N valid input-output-relationship, implies &g[p](c) .U .
hand, definition (U, , , A), e&g[p] (c) (U, , , A); contradicts
assumption nogood C violated.
2
Proof Proposition 16. Suppose answer set A0 exists solution
L1 (U, , A), i.e., violates nogood N = {0 , 1 , . . . , n } L1 (U, , A). show
case U unfounded set wrt. A0 U A0 6= ; means A0
not-unfounded-free, contradicts A0 answer set .
Let r rule H(r) U 6= . show one conditions (i)(iii)
Definition 5 holds.
Bo+ (r) U 6= , Condition (ii) holds. Hence assume following Bo+ (r)
U = , means r external rule wrt. U . N
1 n either (1) = Th h H(r) h 6 U |= h, (2) = Fb
b Bo+ (r) 6|= b. Since A0 violates N assumption, A0 . Case (1)
Condition (iii) satisfied, Case (2) Condition (i) satisfied.
Moreover, definition L1 U exists Ta A0 , i.e., A0 intersects U .
proves result.
2
Proof Proposition 17. Towards contradiction,
suppose answer set A0
.
solution L2 (U, , A). Let N = {Ta | .U } {0 , 1 , . . . , n } L2 (U, , A)
violated nogood. A0 1 n, know A0 falsifies (at least) bodies
0
rules falsified A; consequently,
f f . |=
hypothesis
.
.
; hence, also .U |= f A0 .
U unfounded set follows



.U
|=
f

.
.
Moreover, Ta A0 all. .U , therefore A0T (A .U )T . 0 A0 ,
0
conclude A0T ) (A .U )T , i.e., A0 subset-minimal model . Consequently,
A0 answer set , contradiction.
2
314

fiE FFICIENT HEX-P ROGRAM E VALUATION BASED U NFOUNDED ETS

Proof Lemma 18. = , result holds trivially. Otherwise, let r
H(r) 6= . show one conditions (i)(iii) Definition 5 holds. Observe
H(r) U 6= U . Since U unfounded set wrt. A, either
(i) 6|= b b B(r);
.

(ii) .U 6|= b b B(r);
(iii) |= h h H(r) \ U .
Case (i), the. condition also holds wrt. . case (ii), let H(r) , b B(r)
.U 6|= b. make case distinction: either b ordinary literal external
one.
.
b ordinary default-negated
atom

c,



.U 6|= b implies Tc c 6 U ,
.
therefore also .Y 6|= b. assume b ordinary atom. b 6 U 6|= b
Case (i) applies, assume b U . H(r) b B(r), b therefore
either a, b C a, b (because
ordinary edges C ).
.
assumption , therefore b , hence .Y 6|= b.
b external literal, q U e q q 6 . Otherwise, would
imply q C C would incoming e-edge, contradicts assumption C
cut .of GR
q , therefore truth value b
. Hence,. q U e q, also
.
.U .Y same. Hence .Y 6|= b.
Case (iii), also |= h h H(r) \ U therefore H(r) \
H(r) \ U .
2
Proof Lemma 19. U = , result holds trivially. Otherwise, suppose r
H(r) U . Observe r cannot external atom guessing rule U contains
ordinary atoms. show one conditions Definition 5 holds r wrt. A.
r external atom guessing rule, corresponding rule r containing
external atoms place replacement atoms. U unfounded set H(r) =
H(r), either:
(i) 6|= b b B(r);
.

(ii) .U 6|= b b B(r);
(iii) |= h h H(r) \ U
Case (i), let b B(r) 6|= b b corresponding literal B(b) (which
b ordinary corresponding replacement literal b external). also 6|= b
compatible.
Case (ii), make case distinction:. either b ordinary external.
b ordinary, b B(r) .U 6|= b holds equivalent
ordinary atoms.
b external atom default-negated external atom, atom p(c) U input
it, i.e., p predicate input parameter b; otherwise
e p(c), contradicting
.
assumption U
internal e-edges. .U implies 6|= b truth
.
value b .U same. Therefore apply Case (i).
315

fiE ITER , F INK , K RENNWALLNER , R EDL , & CH ULLER

Case (iii), also |= h h H(r) \ U H(r) = H(r) contains ordinary
atoms equivalent ordinary atoms.
2
Proof Theorem 20. define reachable set R(a) atom
R(a) = {b | (a, b) { } },
i.e., set atoms b U reachable using edges e-edges.
first assume U contains least one e-edge, i.e., x, U x e y.
show u U outgoing e-edge (i.e., u e v v U ),
R(u) incoming e-edges U (i.e., v R(u) b U , b 6e v holds).
Suppose contrary outgoing e-edges, reachable set R(a) incoming
e-edge U . construct e-cycle , contradicts assumption. Start
arbitrary node c0 U outgoing e-edge, let p0 (possibly empty) path
(under ) c0 node d0 R(c0 ) d0 incoming e-edge, i.e.,
c1 c1 e d0 ; note c1 6 R(c0 ).4 assumption, also node d1 R(c1 )
incoming e-edge (from node c2 6 R(c1 )). Let p1 path c1 d1 , etc. iteration
construct concatenation paths p0 , (d0 , c1 ), p1 , (d1 , c2 ), p2 , . . . , pi , (di , ci+1 ), . . .,
pi ci di paths within reachable sets, (di , ci+1 ) e-edges
reachable sets. However, U finite nodes path must equal, i.e.,
subsequence constructed sequence represents e-cycle (in reverse order).
proves u node outgoing e-edge R(u) incoming e-edges.
next show R(u) cut GR
. Condition (i) immediately satisfied definition u.
Condition (ii) shown follows. Let u0 R(u) v 0 U \ R(u). show u0 6 v 0
v 0 6 u0 . Suppose, towards contradiction, u0 v 0 . u0 R(u), path
u u0 . u0 v 0 , would also path u v 0
v 0 would R(u), contradiction. Analogously, v 0 u0 would also imply
path u v 0 path u u0 , contradiction.
Therefore, R(u) U cut GR
, Lemma 18, follows U \R(u) unfounded
set. Observe U \ R(u) contains one e-edge less U u outgoing e-edge
U \ R(u) 6= ; indeed, assumption w U exists u e w, clearly
w 6 R(u). iterating argument, number e-edges unfounded set reduced
zero nonempty core. Eventually Lemma 19 applies, proving remaining set
unfounded set .
2
Proof Corollary 21. Towards contradiction, suppose unfounded set U wrt. exists.
U contains e-cycle e-cycle . Theorem 20
unfounded set wrt. A, contradicts assumption unfounded set wrt. A.
2
Proof Theorem 22. U contains cyclic input atoms, cycles containing
e-edges atom dependency graph broken, i.e., U contain e-cycle
. Theorem 20 exists nonempty unfounded set wrt. A.
2
4. Whenever x e x, U , path x , otherwise would
e-cycle .

316

fiE FFICIENT HEX-P ROGRAM E VALUATION BASED U NFOUNDED ETS

Proof Theorem 23. Let U nonempty unfounded set wrt. A. C decomposition A() strongly connected components, component dependency graph
hC, {(C1 , C2 ) | C1 , C2 C, a1 C1 , a2 C2 : (a1 , a2 ) e }i
acyclic. Following hierarchical component dependency graph nodes without predecessor components downwards, find first component nonempty intersection
U , i.e., exists component C C C U 6= C 0 U = transitive
predecessor components C 0 C.
show U C unfounded set C wrt. A. Let r C rule
H(r) (U C) 6= . show one conditions (i)-(iii) Definition 5 holds
r wrt. U C.
U unfounded set wrt. know one conditions (i)(iii) holds
r wrt. U . case Condition (i), trivially holds also wrt. U C condition depends assignment A, unfounded set U ; case
Condition (iii), clearly holds H(r) \ U 6= included H(r) \ (U C).
.
case Condition (ii), .U 6|= b (ordinary external) body
literal
.
b . B(r). show next truth value literals B(r) .U
.(U C), proves Condition (ii) holds also wrt. U C.
b =. ordinary atom a, Ta 6 U consequently 6 U C,
hence A. .(U C) 6|= b. b ordinary atom, either Fb A, implies immediately
.(U C) 6|= b, b U . latter case b either predecessor component
C 0 C C (since h b h H(r)). since U C 0 =
predecessor
.
components C, know b C therefore b (U C), implies .(U C) 6|= b.
b positive default-negated external atom, input atoms b either
predecessor component C 0 C C (since h e h H(r)). show .with
similar argument

truth value input atom .U
.
.
.(U

C):



.U |=
a, Ta 6 U , hence 6 (U C)
.
.
therefore
.(U C) |= a. .U 6|= a, either Fa A, immediately implies
.
.(U C) 6|= a, U . latter case must C U. C 0 =
predecessor components C 0 C. Therefore (U C) and. consequently. .(U C) 6|= a.
input atoms truth value .U .(U C),
holds also positive default-negated external atom b itself.
2
Proof Proposition 24. U = , result holds trivially. definition C ,
H(r) C = r \ C . hypothesis U C. H(r) U =
r \ C U unfounded set wrt. A.
2

References
Alviano, M., Calimeri, F., Faber, W., Leone, N., & Perri, S. (2011). Unfounded Sets WellFounded Semantics Answer Set Programs Aggregates. Journal Artificial Intelligence Research, 42, 487527.
Baader, F., & Hollunder, B. (1995). Embedding Defaults Terminological Knowledge Representation Formalisms. Journal Automated Reasoning, 14(1), 149180.
317

fiE ITER , F INK , K RENNWALLNER , R EDL , & CH ULLER

Basol, S., Erdem, O., Fink, M., & Ianni, G. (2010). HEX Programs Action Atoms.
Hermenegildo, M., & Schaub, T. (Eds.), Technical Communications 26th International
Conference Logic Programming (ICLP10), Vol. 7 Leibniz International Proceedings
Informatics (LIPIcs), pp. 2433, Dagstuhl, Germany. Schloss DagstuhlLeibniz-Zentrum
fuer Informatik.
Brewka, G., & Eiter, T. (2007). Equilibria Heterogeneous Nonmonotonic Multi-Context Systems. Holte, R. C., & Howe, A. (Eds.), 22nd AAAI Conference Artificial Intelligence
(AAAI07), pp. 385390. AAAI Press.
Brewka, G., Eiter, T., & Truszczynski, M. (2011). Answer set programming glance. Communications ACM, 54(12), 92103.
Drescher, C., Gebser, M., Grote, T., Kaufmann, B., Konig, A., Ostrowski, M., & Schaub, T. (2008).
Conflict-driven disjunctive answer set solving. Brewka, G., & Lang, J. (Eds.), 11th International Conference Principles Knowledge Representation Reasoning (KR 2008),
Sydney, Australia, September 16-19, 2008, pp. 422432. AAAI Press.
Drescher, C., & Walsh, T. (2012). Answer set solving lazy nogood generation. Dovier,
A., & Costa, V. S. (Eds.), Technical Communications 28th International Conference
Logic Programming (ICLP 2012), Vol. 17 Leibniz International Proceedings Informatics
(LIPIcs), pp. 188200. Schloss DagstuhlLeibniz-Zentrum fuer Informatik.
Dung, P. M. (1995). acceptability arguments fundamental role nonmonotonic
reasoning, logic programming n-person games. Artificial Intelligence, 77(2), 321357.
Dung, P., Mancarella, P., & Toni, F. (2007). Computing ideal sceptical argumentation. Artificial
Intelligence, 171, 642674.
Dunne, P. E. (2009). computational complexity ideal semantics. Artificial Intelligence,
173(18), 15591591.
Egly, U., Gaggl, S. A., & Woltran, S. (2010). Answer-set programming encodings argumentation
frameworks. Argument Computation, 1(2), 147177.
Eiter, T., Fink, M., Ianni, G., Krennwallner, T., & Schuller, P. (2011). Pushing Efficient Evaluation
HEX Programs Modular Decomposition. Delgrande, J., & Faber, W. (Eds.), 11th International Conference Logic Programming Nonmonotonic Reasoning (LPNMR11),
Vol. 6645 LNAI, pp. 93106. Springer.
Eiter, T., Fink, M., Krennwallner, T., & Redl, C. (2012a). Conflict-driven ASP Solving External
Sources. Theory Practice Logic Programming, 12(4-5), 659679.
Eiter, T., Fink, M., Krennwallner, T., Redl, C., & Schuller, P. (2012b). Eliminating Unfounded Set
Checking HEX-Programs. Fink, M., & Lierler, Y. (Eds.), 5th Workshop Answer
Set Programming Computing Paradigms (ASPOCP 2012), September 4, 2012,
Budapest, Hungary, pp. 8397.
Eiter, T., Fink, M., Krennwallner, T., Redl, C., & Schuller, P. (2012c). Exploiting Unfounded Sets
HEX-Program Evaluation. del Cerro, L. F., Herzig, A., & Mengin, J. (Eds.), 13th
European Conference Logics Artificial Intelligence (JELIA 2012), September 26-28,
2012, Toulouse, France, Vol. 7519 LNCS, pp. 160175. Springer.
318

fiE FFICIENT HEX-P ROGRAM E VALUATION BASED U NFOUNDED ETS

Eiter, T., Fink, M., Schuller, P., & Weinzierl, A. (2012b). Finding explanations inconsistency
nonmonotonic multi-context systems. Tech. rep. INFSYS RR-1843-12-09, INFSYS RR1843-03-08, Inst. fur Informationssysteme, TU Wien. Preliminary version Proc. 12th International Conference Knowledge Representation Reasoning (KR 2010), pp. 329339,
AAAI Press, 2010.
Eiter, T., Ianni, G., Krennwallner, T., & Schindlauer, R. (2008a). Exploiting conjunctive queries
description logic programs. Annals Mathematics Artificial Intelligence, 53(14),
115152.
Eiter, T., Ianni, G., Lukasiewicz, T., Schindlauer, R., & Tompits, H. (2008b). Combining answer set
programming description logics semantic web. Artificial Intelligence, 172(1213), 14951539.
Eiter, T., Ianni, G., Schindlauer, R., & Tompits, H. (2005). Uniform Integration Higher-Order
Reasoning External Evaluations Answer-Set Programming. Kaelbling, L. P., &
Saffiotti, A. (Eds.), 19th International Joint Conference Artificial Intelligence (IJCAI05),
pp. 9096. Professional Book Center.
Eiter, T., Ianni, G., Schindlauer, R., & Tompits, H. (2006a). dlvhex: Prover Semantic-Web
Reasoning Answer-Set Semantics. Proceedings ICLP06 Workshop
Applications Logic Programming Semantic Web Semantic Web Services (ALPSWS2006), pp. 3339. CEUR WS.
Eiter, T., Ianni, G., Schindlauer, R., & Tompits, H. (2006). Effective Integration Declarative Rules
External Evaluations Semantic-Web Reasoning. Sure, Y., & Domingue, J. (Eds.),
3rd European Conference Semantic Web (ESWC06), Vol. 4011 LNCS, pp. 273287.
Springer.
Faber, W. (2005). Unfounded sets disjunctive logic programs arbitrary aggregates.
Baral, C., Greco, G., Leone, N., & Terracina, G. (Eds.), 8th International Conference Logic
Programming Nonmonotonic Reasoning (LPNMR05), Vol. 3662, pp. 4052. Springer.
Faber, W., Leone, N., & Pfeifer, G. (2011). Semantics complexity recursive aggregates
answer set programming. Artificial Intelligence, 175(1), 278298.
Gebser, M., Ostrowski, M., & Schaub, T. (2009). Constraint answer set solving. Hill, P., & Warren, D. (Eds.), Proceedings Twenty-fifth International Conference Logic Programming (ICLP09), Vol. 5649 Lecture Notes Computer Science, pp. 235249. SpringerVerlag.
Gebser, M., Kaufmann, B., & Schaub, T. (2012). Conflict-driven answer set solving: theory
practice. Artificial Intelligence, 187188, 5289.
Gebser, M., Kaufmann, B., & Schaub, T. (2013). Advanced conflict-driven disjunctive answer
set solving. Proceedings Twenty-Third International Joint Conference Artificial
Intelligence, IJCAI13, pp. 912918. AAAI Press.
Gelfond, M., & Lifschitz, V. (1991). Classical Negation Logic Programs Disjunctive
Databases. New Generation Computing, 9(34), 365386.
Ghidini, C., & Giunchiglia, F. (2001).
Local models semantics, contextual reasoning=locality+compatibility. Artificial Intelligence, 127(2), 221259.
319

fiE ITER , F INK , K RENNWALLNER , R EDL , & CH ULLER

Goldman, R., & Boddy, M. (1996). Expressive Planning Explicit Knowledge. Drabble, B.
(Ed.), 3rd International Conference Artificial Intelligence Planning Systems (AIPS96),
pp. 110117. AAAI Press.
Hoehndorf, R., Loebe, F., Kelso, J., & Herre, H. (2007). Representing default knowledge biomedical ontologies: application integration anatomy phenotype ontologies. BMC
Bioinformatics, 8, 377.
Janhunen, T., Niemela, I., Seipel, D., Simons, P., & You, J.-H. (2006). Unfolding partiality
disjunctions stable model semantics. ACM Trans. Comput. Log., 7(1), 137.
Koch, C., Leone, N., & Pfeifer, G. (2003). Enhancing disjunctive logic programming systems
SAT checkers. Artificial Intelligence, 151(12), 177212.
Lee, J. (2005). model-theoretic counterpart loop formulas. Kaelbling, L. P., & Saffiotti,
A. (Eds.), 19th International Joint Conference Artificial Intelligence (IJCAI05), pp. 503
508. Professional Book Center.
Lee, J., & Lifschitz, V. (2003). Loop Formulas Disjunctive Logic Programs. Palamidessi, C.
(Ed.), 19th International Conference Logic Programming (ICLP03), Vol. 2916 LNCS,
pp. 451465. Springer.
Leone, N., Pfeifer, G., Faber, W., Eiter, T., Gottlob, G., Perri, S., & Scarcello, F. (2006). DLV
System Knowledge Representation Reasoning. ACM Transactions Computational
Logic, 7(3), 499562.
Leone, N., Rullo, P., & Scarcello, F. (1997). Disjunctive Stable Models: Unfounded Sets, Fixpoint
Semantics, Computation. Information Computation, 135(2), 69112.
Lierler, Y. (2005). cmodels - SAT-Based Disjunctive Answer Set Solver. Baral, C., Greco, G.,
Leone, N., & Terracina, G. (Eds.), 8th International Conference Logic Programming
Nonmonotonic Reasoning (LPNMR 2005), Vol. 3662 Lecture Notes Computer Science,
pp. 447451. Springer.
Lifschitz, V., & Turner, H. (1994). Splitting logic program. Hentenryck, P. V. (Ed.), 11th
International Conference Logic Programming (ICLP94), pp. 2337. MIT Press.
Lin, F., & Zhao, Y. (2004). ASSAT: computing answer sets logic program SAT solvers.
Artificial Intelligence, 157(12), 115137.
Marano, M., Obermeier, P., & Polleres, A. (2010). Processing RIF OWL2RL within DLVHEX.
Hitzler, P., & Lukasiewicz, T. (Eds.), 4th International Conference Web Reasoning
Rule Systems (RR10), Vol. 6333 LNCS, pp. 244250. Springer.
Nieuwenborgh, D. V., Cock, M. D., & Vermeir, D. (2007a). Computing fuzzy answer sets using
dlvhex. Dahl, V., & Niemela, I. (Eds.), 23rd International Conference Logic Programming (ICLP07), Vol. 4670 LNCS, pp. 449450. Springer.
Nieuwenborgh, D. V., Eiter, T., & Vermeir, D. (2007b). Conditional planning external functions. Baral, C., Brewka, G., & Schlipf, J. S. (Eds.), 9th International Conference Logic
Programming Nonmonotonic Reasoning (LPNMR07), Vol. 4483 LNCS, pp. 214227.
Springer.
Shen, Y.-D. (2011). Well-supported semantics description logic programs. Walsh, T. (Ed.),
22nd International Joint Conference Artificial Intelligence (IJCAI11), pp. 10811086.
AAAI Press.
320

fiE FFICIENT HEX-P ROGRAM E VALUATION BASED U NFOUNDED ETS

Shen, Y.-D., & Wang, K. (2011). Extending logic programs description logic expressions
semantic web. Aroyo, L., Welty, C., Alani, H., Taylor, J., Bernstein, A., Kagal, L., Noy,
N. F., & Blomqvist, E. (Eds.), 10th International Semantic Web Conference (ISWC11), Vol.
7031 LNCS, pp. 633648. Springer.
Simons, P., Niemela, I., & Soininen, T. (2002). Extending implementing stable model
semantics. Artificial Intelligence, 138(1-2), 181234.
Smith, D. E., & Weld, D. S. (1998). Conformant Graphplan. Mostow, J., Rich, C., & Buchanan,
B. (Eds.), 15th National Conference Artificial Intelligence (AAAI98), pp. 889896. AAAI
Press / MIT Press.
Turner, H. (2002). Polynomial-length planning spans polynomial hierarchy. Flesca, S., Greco,
S., Leone, N., & Ianni, G. (Eds.), European Conference Logics Artificial Intelligence
(JELIA02), Vol. 2424 LNCS, pp. 111124. Springer.
Van Gelder, A., Ross, K. A., & Schlipf, J. S. (1991). Well-Founded Semantics General
Logic Programs. Journal ACM, 38(3), 619649.
Zakraoui, J., & Zagler, W. L. (2011). logical approach web user interface adaptation.
Holzinger, A., & Simonic, K.-M. (Eds.), 7th Conference Workgroup Human-Computer
Interaction Usability Engineering Austrian Computer Society (USAB11), Vol.
7058 LNCS, pp. 645656. Springer.
Zirtiloglu, H., & Yolum, P. (2008). Ranking semantic information e-government: complaints
management. 1st International Workshop Ontology-supported Business Intelligence
(OBI08), No. 5 OBI08, p. 7. ACM.

321

fiJournal Artificial Intelligence Research 49 (2014) 79-109

Submitted 07/13; published 01/14

Closure Consistency Logic-Associated Argumentation
Phan Minh Dung
Phan Minh Thang

dung.phanminh@gmail.com
thangfm@gmail.com

Computer Science Information Management Program
Asian Institute Technology
GPO Box 4, Klong Luang, Pathumthani 12120, Thailand

Abstract
Properties like logical closure consistency important properties logical
reasoning system. Caminada Amgoud showed every logic-based argument
system satisfies relevant properties. conditions like closure contraposition transposition monotonic part underlying logic, ASPIC-like systems
satisfy properties. contrast, logical closure consistency properties
well-understood well-known widely applied systems like logic programming
assumption based argumentation. Though conditions like closure contraposition
transposition seem intuitive ASPIC-like systems, rule many sensible ASPIC-like
systems satisfy properties closure consistency.
present new condition referred self-contradiction axiom guarantees
consistency property ASPIC-like assumption-based systems implied
properties closure contraposition transposition. develop logicassociated abstract argumentation framework, associating abstract argumentation
abstract logics represent conclusions arguments. show logic-associated
abstract argumentation frameworks capture ASPIC-like systems (without preferences)
assumption-based argumentation. present two simple natural properties compactness cohesion logic-associated abstract argumentation frameworks show
capture logical closure consistency properties. demonstrate
assumption-based argumentation ASPIC-like systems, cohesion follows naturally
self-contradiction axiom. give translation ASPIC-like systems (without preferences) equivalent assumption-based systems keeps self-contradiction
axiom invariant.

1. Introduction
Properties like logical closure consistency important properties logical reasoning system. Caminada Amgoud (2007) showed every logic-based argument
system satisfies relevant properties. conditions like closure contraposition transposition monotonic part underlying logic,1 properties
fulfilled ASPIC systems. Prakken (2010) later Modgil Prakken (2013)
developed idea ASPIC+, rich complex logic-based argumentation
system.
following example illustrates many sensible ASPIC assumptionbased systems satisfy properties closure consistency neither closed
contraposition transposition.
1. precise definition closure contraposition transposition given section 4.
c
2014
AI Access Foundation. rights reserved.

fiDung & Thang

Example 1 Consider ASPIC-like system = (RS, RD)
1. RD = RD0 RD1 set defeasible rules
(a) RD0 consists two defeasible rules
d1 : p f

d2 : b f

representing defaults birds fly, penguins dont
(b) RD1 consists single defeasible rule
th bh
representing default Thais normally black hair
2. RS = RS0 RS1 set strict rules
(a) RS0 consists three strict rules
p

pb

p Oj(d2 )

Oj(d2 ) means rule d2 applicable,
(b) RS1 consists single strict rule
th
difficult see satisfies properties closure consistency.
Even though neither closed contraposition transposition,
reason rule systems like consideration long capture
intuition concerned applications. fact, systems like often offer natural representation concerned applications closed contraposition
transposition. illuminate point, imagine another ASPIC-like system containing
strict defeasible rules closed contraposition.2
Suppose interested colour hair concerned Thai individual.
Consider argument : th bh. Let B1 : p f B2 : p b f . Let
CN consequence operator defined strict rules3 . f CN ({f, bh}),
follows closure contraposition property CN, bh CN ({f, f }). Therefore argument B conclusion bh contains B1 , B2 subarguments. B
hence attacks A. B attacked (by undercut) argument C : p Oj(d2 ) B2
attack C, accepted grounded extension. set {A}
admissible. words, draw conclusion hair colour Thais,
system needs resolve completely unrelated controversy flying capabilities
penguins birds.
2. example, adding absurdity rules representing proposition inconsistency implies
every thing, form a, l atom appearing RS RD l literal
set atoms. difficult see closed contraposition (see appendix section 1).
3. precise definition given definition 1.

80

fiClosure Consistency Logic-Associated Argumentation

general, condition closure contraposition creates attack
defeasible argument inconsistency ASPIC systems. words, systems happen contain knowledge several causally independent domains like
flying penguins hair colour Thais, closure contraposition interlink
making necessary resolve possible inconsistencies parts systems able answer query, independent whether inconsistencies
causally related query not.4
contrast, argument systems like AS, attack {A}
admissible. Controversy flying capabilities penguins effect
acceptance A.
Though closure transposition avoids problem conflict propagation,
adopted many well-known practical systems indiscriminate application
could lead counter-intuitive result many cases. example, consider simplified
version example birds fly penguins dont aspic+ whose set strict rules
closure transposition following strict rules:
app, b f

p f

pb

p app

app ordinary premise app = app.
Therefore rule app p included set strict rules.
Suppose knowledge base consists ordinary premise app stating
default birds fly applicable.
Without information, two arguments are: app B
p.
Accepting ordinary premise app simply says information
default birds fly applied. say anything penguin. closure
transposition implies definitely penguin around (a rather slippery way
make conclusion).
context logic programming, rule app p also rather unnatural app
viewed assumption explicit negation operator whose intuitive reading
explicit negation assertion based hard evidence,
another assumption (Gelfond & Lifschitz, 1990).
contrast ASPIC systems, much research done study logical
closure consistency semantics well-known widely applied systems
like logic programming assumption based argumentation (Gelfond & Lifschitz, 1988;
Lifschitz, 1999; Bondarenko, Dung, Kowalski, & Toni, 1997). Properties like closure
transposition contraposition embraced logic programming assumption based
argumentation. Prakken (2012) observed assumption-based argumentation yields
unintuitive argument unwanted conclusion inference rules satisfy transposition property. hence natural ask
whether conditions implied conditions closure contraposition transposition still guaranteeing important properties logical closure
consistency,
4. Pollock (1995) Wu (2012) also pointed classical propositional proof systems propagate
conflicts throughout knowledge bases unrelated parts.

81

fiDung & Thang

whether logical closure consistency properties could stated studied
general framework generalizing assumption-based ASPIC-like systems possibly
also logic-based argument systems ?
present paper new condition referred self-contradiction axiom5
guarantees consistency complete extension semantics implied
conditions closure contraposition transposition time, also
includes systems could avoid problem conflict-propagation. example 1
AS, satisfy self-contradiction axiom.
turns consistency closure properties logic-based argument systems could studied within general logic-associated abstract argumentation framework,
obtained associating abstract argumentation abstract logics represent conclusions arguments. demonstrate logic-associated abstract argumentation frameworks capture ASPIC-like systems (without preferences) assumption-based argumentation. present two simple natural properties compactness cohesion
logic-associated abstract argumentation frameworks show capture logical
closure consistency complete extension semantics. demonstrate
assumption-based argumentation ASPIC-like systems cohesion follows naturally
self-contradiction axiom.
give translation ASPIC-like systems (without preferences) equivalent assumption-based systems keeps self-contradiction property invariant.
paper structured follows. section 2 recall abstract argumentation
Tarski abstract logics. introduce section 3 framework abstract argumentation associated abstract logics sentences abstract logics represent
argument conclusions. present section two simple natural conditions compactness cohesion show ensure satisfaction properties logical
closure consistency complete extensions. sections 4, 5 show compactness
cohesions could captured naturally ASPIC-like systems assumption-based argumentation. introduce section 4 fundamental axiom self-contradiction show
connections properties closure contraposition transposition. provide section 6 transformation ASPIC-like systems equivalent
assumption-based framework. section 7, discuss recent systems based
Tarskis abstract logics. conclude.6

2. Preliminaries
abstract argumentation framework (Dung, 1995) defined simply pair (AR, att)
set arguments AR att AR AR (A, B) att represents attack
argument argument B. set argument attacks argument
argument attacks A. attacks another set attacks argument
. conflict-free attack itself. conflicting attacks itself.
argument acceptable wrt set arguments attacks attack A.
admissible conflict-free counter-attacks attack it. semantics
5. intuitive reading self-contradiction X causes contradiction X contradicts
itself.
6. preliminary extended abstract paper published Dung Thang (2011).

82

fiClosure Consistency Logic-Associated Argumentation

abstract argumentation determined acceptability arguments various
associated notions extensions. complete extension admissible set containing every
argument acceptable wrt it. Complete extensions could also viewed conflict-free fixed
points characteristic function F : 2AR 2AR defined F (S) = set acceptable
arguments wrt S. Preferred extensions maximal conflict-free fixed points F
least fixed point F called grounded extension. could many preferred
extensions, exists unique grounded extension. stable extension conflict-free
set arguments attacks every argument belonging it.
Amgoud Besnard (2009) proposed use Tarskis abstract logic argumentation characterized simply consequence operator.
Given language L well-formed formulas, Tarski abstract logic (Amgoud & Besnard,
2009) defined consequence operator CN: 2L 2L following axioms
satisfied:
1. (Expansion)

X CN (X)

2. (Idempotence)
3. (Finiteness)

CN (CN (X)) = CN (X)

CN (X) = {CN (Y ) | X finite }

4. (Absurdity)

CN ({x}) = L x L

5. (Coherence)

CN () 6= L

introduce consequence operator set strict inference rules.
strict rule7 form
1 , . . . , n
1 , . . . , n , L.
Definition 1 Let RS set strict rules. Define consequence operator CNRS :
2L 2L follows: set X L, CNRS (X) smallest set
1. X CNRS (X),
2. rule 1 , . . . n RS, {1 , . . . n } CNRS (X) CNRS (X).


3. Associating Abstract Argumentation Abstract Logics
Intuitively, argument proof conclusion. many cases, proofs constructed following proof theory formal logics. logics could nonmonotonic. notions closure consistency defined according monotonic
parts underlying logics.
Many logics underlying argumentation systems like assumption-based argumentation
ASPIC-systems always impose absurdity axiom. motivates slight
generalization Tarski abstract logics following definition.
7. often also referred inference rules assumption-based argumentation.

83

fiDung & Thang

Definition 2 Given language L, abstract logic defined pair (CN, CON RA)
CN: 2L 2L represents consequence operator CON RA 2L collection
contradictory sets following axioms hold:
1. CN satisfies expansion, idempotence finiteness axioms.
2. (Weak Absurdity) CON RA superset also belongs CON RA.8
3. (Weak Coherence) CN () 6 CON RA.
Given abstract logic (CN, CON RA), X closed iff X = CN (X). set X
CON RA said contradictory.
set X L said inconsistent iff closure CN (X) contradictory.9 X said
consistent iff inconsistent. X minimal inconsistent iff X inconsistent
proper subset X consistent.10
Definition 3 say abstract logic satisfies
strong absurdity axiom CON RA 6= X CON RA, CN (X) = L.

follows immediately abstract logic Tarski abstract logic satisfies
strong absurdity axiom x L {x} inconsistent.11
Example 2 Let RS0 = { wr; go; b hw; hw} set strict rules,12
L language consisting literals whose atoms occur rules RS0 . Define
AL0 = (CN0 , CON RA) follows:
X CON RA iff X contains pair literals {l, l}.
CN0 consequence operator defined RS0 .
illustration, CN0 () = {wr, go}, CN0 ({m}) = {wr, go, m, hw} CN0 ({m, b}) =
{wr, go, m, hw, b, hw}. Hence set {m, b} inconsistent contradictory.
difficult see AL0 abstract logic. CN0 ({hw, hw}) =
{hw, hw}, follows AL0 satisfy strong absurdity axiom.
8. Note CON RA could empty like case definite logic programs L consists
positive literals. Nonetheless, CON RA 6= L CON RA.
9. words, set sentences X inconsistent contradiction could derived though
contradiction may present directly X (i.e. inconsistent set may contradictory).
10. proper subset X subset X 6= X.
11. Tarskian one, abstract logic needs satisfy absurdity coherence. {x}
inconsistent, CN ({x}) contradictory. Since strong absurdity satisfied, CN (CN ({x})) = L.
idempotence, CN (CN ({x})) = CN ({x}). Hence CN ({x}) = L. coherence holds.
weak coherence axiom abstract logic, CN () 6 CON RA. Due strong absurdity,
CON RA 6= . Due weak absurdity, fact CON RA 6= , follows L
CON RA. Hence CN () 6= L.
12. rules taken example Caminada Amgoud (2007) wr = John wears
something looks like wedding ring, = John married, hw = John wife, go =
John often goes late, b = John bachelor.

84

fiClosure Consistency Logic-Associated Argumentation

Inspired Amgoud Besnards idea (2009), use abstract logics represent
conclusions arguments difference them, specify detail structure
individual arguments.
Definition 4 logic-associated argumentation framework language L
quadruple (AF, , AL, Cnl)
1. AF = (AR, att) abstract argumentation framework,
2. AL = (CN, CON RA) abstract logic L,
3. Cnl : AR L assigns argument A, conclusion Cnl(A) L,
4. partial order13 AR B means subargument B
arguments C AR, C attacks C attacks B.
Remark 1
set arguments, Cnl(S) denotes set conclusions
arguments S.
set subarguments denoted Sub(A). set arguments S,
Sub(S) contains subarguments arguments S.

next give example logic-associated argumentation framework.
Example 3 Let LAF0 = (AF0 , 0 , AL0 , Cnl) AL0 defined example 2
AF0 = (AR0 , att0 )
1. arguments AR0 constructed rules set strict rules RS0
example 2, set defeasible rules RD = {wr m; go b}. 6
arguments14 :
A1 : wr, A3 : wr m, A5 : wr hw.
A2 : go, A4 : go b,

A6 : go b hw.

Attack relation: A5 attacks A6 vice versa. attacks. Let
att0 = {(A5 , A6 ), (A6 , A5 )}.
2. subargument relation 0 reflexive transitive closure A1 A3 A5
A2 A4 A6 .
Definition 5 Let LAF = (AF, , AL, Cnl), AL = (CN, CON RA), logic-associated
argumentation framework.
1. LAF said satisfy closure-property complete extension E AF,
Cnl(E) closed wrt AL.
13. partial order reflexive, asymmetric transitive relation.
14. precise definition see definition 12.

85

fiDung & Thang

2. LAF said satisfy consistency-property complete extension E
AF, Cnl(E) consistent wrt AL.
Example 4 (Continuation example 3)
grounded extension AF0 GE = {A1 , A2 , A3 , A4 }. two preferred
extensions E1 = {A1 , A2 , A3 , A4 , A5 } E2 = {A1 , A2 , A3 , A4 , A6 }.
Cnl(GE) = {wr, go, m, b} CN0 (Cnl(GE)) = Cnl(GE) {hw, hw}. Hence
set conclusions arguments grounded extension neither closed consistent wrt abstract logic AL0 . Hence LAF0 satisfies neither closure-property
consistency-property.
also easy see sets conclusions arguments two preferred
extensions neither closed consistent either.
Example 5 (Continuation example 4)
Let RS1 = RS0 {hw m, hw b}. consequence operator wrt RS1
denoted CN1 . Let AL1 = (CN1 , CON RA) AF1 = (AR1 , att1 )
AR1 = AR0 {A7 , A8 } A7 : A5 b A8 : A6 m,15
att1 = {(A7 , A4 ), (A7 , A6 ), (A7 , A8 ), (A8 , A3 ), (A8 , A5 ), (A8 , A7 )},
1 reflexive transitive closure 0 {A5 A7 , A6 A8 }.
grounded extension AF1 GE = {A1 , A2 }. Two preferred extensions AF1
E1 = {A1 , A2 , A3 , A5 , A7 } E2 = {A1 , A2 , A4 , A6 , A8 }.
difficult see sets Cnl(GE ) = {wr, go}, Cnl(E1 ) = {wr, go, m, hw, b},
Cnl(E2 ) = {wr, go, b, hw, m} closed consistent.
Let LAF1 = (AF1 , 1 , AL1 , Cnl). closure consistency properties satisfied
LAF1 .
end section, assume arbitrary fixed logicassociated framework LAF = (AF, , AL, Cnl).
turns closure consistency properties based intuitive
idea base argument.
Definition 6 Let argument BA finite set subarguments A. BA
said base following conditions satisfied:
1. Cnl(A) CN (Cnl(BA))
2. argument C, C attacks iff C attacks BA.
easy see argument A, {A} base A.
example 3, though Cnl(A5 ) CN0 (Cnl(A3 )), {A3 } base A5 since A6
attacks A5 A6 attack A3 .
Note empty set base arguments A1 A2 .
contrast, example 5, {A3 } base A5 A7 {A4 } base A6 A8 .
15. i.e. A7 wr hw b, A8 go b hw m.

86

fiClosure Consistency Logic-Associated Argumentation

Definition 7
1. argument said generated set arguments
base BA BA Sub(S).
2. set arguments generated denoted GN(S).
follows immediately
Lemma 1 Let set arguments. following assertions hold:
1. argument A, generated {A}.
2. Sub(S) GN (S).
3. Cnl(GN (S)) CN (Cnl(Sub(S))).
4. CN (Cnl(GN (S))) = CN (Cnl(Sub(S))).
5. argument C, C attacks GN (S) iff C attacks S.
Proof See appendix section 3.
Theorem 1 Let E complete extension. GN (E) = E
Proof See appendix section 3.
Theorem 1 motivates following definitions 8, 9.
Definition 8 say logic-associated argumentation framework LAF compact
set arguments S, Cnl(GN (S)) closed.
argumentation framework example 3 compact since = {A3 }, GN (S) =
{A1 , A2 , A3 } Cnl(GN (S)) = {wr, go, m} closed since CN ({wr, go, m}) = {wr, go, m, hw}.
contrast, argumentation framework example 5 compact. example,
GN (S) = {A1 , A2 , A3 , A5 , A7 } (wrt LAF1 ) Cnl(GN (S)) = {wr, go, m, hw, b}
closed consistent.
Theorem 2 compact logic-associated argumentation framework satisfies closureproperty.
Proof. Let E complete extension. compactness, follows Cnl(GN (E))
closed. theorem 1, Cnl(E) closed.
lemma 1, follows LAF compact iff Cnl(GN (S)) = CN (Cnl(Sub(S))) iff
CN (Cnl(Sub(S))) Cnl(GN (S)). proved
Lemma 2 LAF compact iff set arguments, CN (Cnl(Sub(S))) Cnl(GN (S))
Notation 1 Abusing notations simplicity, often refer set arguments
inconsistent (resp. consistent) Cnl(Sub(S)) inconsistent (resp. consistent).
87

fiDung & Thang

Intuitively, inconsistency among set arguments indicates possible conflict among
generated arguments. insight motivates following definitions.
Definition 9 logic-associated argumentation framework LAF said cohesive
inconsistent set argument S, GN (S) conflicting.
illustration, consider logic-associated argumentation framework example 3.
Let = {A3 , A4 }. clear inconsistent. difficult see
base argument {A5 , A6 } contains argument itself. Therefore GN (S) =
{A1 , A2 , A3 , A4 }. GN (S) thus conflict-free. framework LAF0 hence cohesive.
Note argumentation framework LAF1 example 5 compact cohesive.
Theorem 3 Let LAF cohesive logic-associated argumentation framework. LAF
satisfies consistency-property.
Proof Let E complete extension. Suppose Cnl(E) inconsistent. cohesion
LAF, follows GN (E) conflicting. theorem 1, E conflicting. Contradiction.
Hence Cnl(E) consistent.
follows immediately theorems 2 3:
Corollary 1 Let LAF compact cohesive logic-associated argumentation framework. LAF satisfies closure- consistency-properties.
next sections, show ASPIC-like systems (without preferences) assumptionbased argumentation instances logic-associated argumentation frameworks.
also introduce axiom self-contradiction guarantee cohesion (and consistency)
systems.

4. Argumentation Strict Defeasible Rules
assume language L literals literal atom explicit negation
atom a. set literals said contradictory contains pair a, a.
important note identify a. X L, denote X = {l | l
X}.
defeasible rule form
1 , . . . , n
1 , . . . , n , L.
Definition 10 rule-based argumentation system pair = (RS, RD) set RS
strict rules set RD defeasible rules CNRS () contradictory.
following definition 11 identifies abstract logic underlying rule-based argumentation system = (RS, RD).
88

fiClosure Consistency Logic-Associated Argumentation

Definition 11 Let = (RS, RD) rule-based argumentation system. Define
ALAS = (CNAS , CON RAAS )
CON RAAS collection contradictory sets CNAS = CNRS .
follows immediately
Lemma 3 ALAS abstract logic.
recall arguments attack relations rule-based argumentation systems
introduced Caminada Amgoud (2007), Prakken (2010), Pollock (1987), Modgil
Prakken (2013).
Definition 12

1. Rules form / , arguments conclusion .

2. Let r strict/defeasible rule form 1 , . . . , n / , n 0. suppose A1 , . . . , , n 0, arguments conclusions 1 , . . . , n respectively.
A1 , . . . , / argument conclusion last rule r.
3. Every argument constructed applying finitely many times two steps.
next introduce key notations.
Notation 2
1. strict argument argument containing defeasible rule. Nonstrict arguments called defeasible arguments.
2. basic defeasible argument argument whose last rule defeasible one,
i.e. form A1 , . . . , .
basic defeasible argument B, last rule B denoted Lr(B).
3. B subargument argument form A1 , . . . , / , denoted
B A, B = B subargument Ai .
Remark 2 conclusion argument denoted Cnl(A).
Remark 3 Arguments form A1 , . . . , / also often viewed proof
trees root labelled children root roots subtrees
A1 , . . . , . Note n = 0, proof tree consists root.
Illustrations argumentation systems based strict defeasible rules given
examples 3, 5.
following notion attack adopted articles Caminada Amgoud (2007),
Prakken (2010), Pollock (1987), Modgil Prakken (2013).
Definition 13 argument attacks argument B (on B) B basic defeasible
subargument B one following conditions satisfied:
89

fiDung & Thang

1. (Undercutting) Cnl(A) = Oj(Lr(B )) defeasible rule r, Oj(r) atom
denoting rule r applicable.
2. (Rebutting) Cnl(A) = Cnl(B ).
Remark 4 simplicity, identify rule-based argumentation system logicassociated argumentation framework (AFAS , , ALAS , Cnl) AFAS argumentation framework obtained according definitions 12,13.
Theorem 4 Rule-based argumentation systems compact.
Proof See appendix section 4.
following lemma reveals simple important relation arguments
basic defeasible subarguments.
Lemma 4 Let argument BD set basic defeasible subarguments A.
Cnl(A) CNAS (Cnl(BD)).
Proof See appendix section 4.
introduce fundamental condition underlying cohesion rule-based argumentation.
Definition 14 abstract logic ALAS said satisfy
self-contradiction axiom minimal inconsistent set X L : X CNAS (X).16

example illustrates intuition self-contradiction axiom using
famous birds fly penguins dont-example.
Example 6 Let = (RS, RD) RD consists two defeasible rules:
d1 : p f

d2 : b f

RS consists three strict rules
r0 : p

r1 : p b

r2 : p Oj(d2 )

Oj(d2 ) atom stating rule d2 applicable.
obvious set strict rules RS closed transposition. also
straightforward see CNAS ({f, f }) = {f, f } =
6 L. Hence underlying abstract
logic ALAS satisfies neither strong absurdity axiom closure transposition
property.17
16. intuitive reading self-contradiction X causes contradiction X contradicts
itself.
17. See section 4.1 precise definitions closure transposition contraposition relationships strong absurdity self-contradiction

90

fiClosure Consistency Logic-Associated Argumentation

difficult see ALAS satisfies self-contradiction axiom.18
difficult see satisfies properties closure consistency.
following theorem shows self-contradiction sufficient cohesion.
Theorem 5 Suppose ALAS satisfies self-contradiction axiom. cohesive.
Proof See appendix section 4.
follows immediately corollary 1
Corollary 2 Suppose ALAS satisfies self-contradiction axiom. satisfies
closure- consistency-properties.
next relate theorem 5 corollary 2 results Caminada Amgoud
(2007), Prakken (2010), Modgil Prakken (2013).
4.1 Sufficient Conditions Self-Contradiction Abstract Logics ALAS
simplicity, possibilities misunderstanding, often write respectively
CN , CON RA AL CNAS , CON RAAS ALAS section.
first recall definitions closure contraposition transposition
articles Caminada Amgoud (2007), Prakken (2010), Modgil Prakken (2013).
Definition 15

1. AL said

closed contraposition set X L, X CN (X)
CN (X \ {} {}).
2. set strict rules RS said
closed transposition rule 1 , . . . , n RS, rules
form 1 , . . . , i1 , , i+1 , n also belong RS.
relations closure contraposition axioms self-contradiction
strong absurdity illuminated following lemma.
Lemma 5
1. AL closed contraposition, AL satisfies strong absurdity
axiom.
2. AL satisfies strong absurdity axiom AL satisfies self-contradiction axiom.
18. Let minimal inconsistent set. show CNAS (S). contradictory minimality
implies = {a, a} L. self-contradiction axioms holds obviously. Suppose
contradictory. Hence pair {a, a} CNAS (S) atom a. difficult
see CNAS (S) = CNAS () S. Therefore CNAS (S) \ CNAS () = {p, b, Oj(d2 )}. follows
{a, a} CNAS () 6= {a, a} 6= . minimality S, consists exactly one element.
Therefore : CNAS (S).

91

fiDung & Thang

Proof See appendix section 4.
relations closure transposition self-contradiction axiom
illuminated following lemma.
Lemma 6 Let = (RS, RD) set strict rules RS closed transposition. ALAS satisfies self-contradiction axiom.
Proof See appendix section 4.
following example shows reverses assertions lemmas 5, 6 hold
general.
Example 7 Let L = {a, a, b, b}. Let CONTRA set contradictory sets
L.
1. X L, define CN (X) = X. obvious abstract logic AL =
(CN, CON RA) satisfies self-contradiction axiom strong absurdity
axiom.
2. Consider set strict rules RS consisting normal rule b together
absurdity rules form x, x x {a, b}, L. Let CN
consequence operator wrt RS.
obvious AL = (CN, CON RA) satisfies strong absurdity axiom (and
hence also self-contradiction axiom). b CN ({a}), 6 CN ({b}) =
{b}, follows AL closed contraposition.
clear set strict rules closed transposition.
3. Consider set strict rules RS consisting two strict rules b b
a. clear rule set closed transposition corresponding
consequence operator satisfy strong absurdity axiom.
following picture illustrates relationships key properties rule-based
argumentation.

Figure 1:

92

fiClosure Consistency Logic-Associated Argumentation

5. Assumption-Based Argumentation
Given logical language L, assumption-based argumentation (ABA) framework (Bondarenko et al., 1997) triple F = (R, A, ) R set inference rules form
(total) one-one
1 , . . . n (for n 0), L set assumptions,
mapping L, x referred contrary x following
properties satisfied:
assumptions appear heads rules R,
contraries assumptions assumptions,
L contains explicit negation operator CNR () contradictory wrt
, i.e. L, {, } 6 CNR ().
following edition birds fly penguins dont example provides illustration.
Example 8 F = (R, A,

) R consists rules

ab1 , p f

ab2 , b f

p

pb

p ab2

= {not ab1 , ab2 } ab1 = ab1 , ab2 = ab2
identify structure abstract logics underlying ABA frameworks below.
5.1 Assumption-based Abstract Logics
set X L said contradictory iff
X contradictory wrt


, i.e. exists assumption {, } X,

X contradictory wrt ,19 i.e. exists L {, } X.
Definition 16 Let F = (R, A,

) ABA framework. Define

ALF = (CNF , CON RAF )

1. CNF = CNR .
2. CON RAF set contradictory sets.
follows immediately
Lemma 7 ALF abstract logic.
19. L contains explicit negation operator .

93

fiDung & Thang

Remark 5 simplicity, possibilities misunderstanding, often write
section CN (S) CON RA CNF (S) CON RAF respectively.
adapt self-contradiction axiom assumption-based argumentation below.
Definition 17 Let F ABA framework. say abstract logic ALF satisfies

ab-self-contradiction axiom20 inconsistent set assumptions X,
X CNF (X).
5.2 Closure Consistency Assumption-Based Argumentation
first recall definitions arguments attack relation associated ABA framework.
Definition 18
1. assumption argument whose support conclusion
{}, respectively.
2. Let 1 , . . . n rule. suppose A1 , . . . , arguments
conclusions 1 , . . . , n respectively. A1 , . . . , argument whose
conclusion whose support union supports A1 , . . . ,
3. Every argument constructed applying finitely many times two steps.
Remark 6 Arguments often viewed proof trees. Arguments form A1 , . . . ,
proof trees root labelled children root roots
subtrees A1 , . . . , . Note n = 0, proof tree consists root.
assumption proof tree consists root labelled
Notation 3

1. support argument denoted supp(A).

support set arguments union supports individual
argument denoted supp(S).
2. conclusion argument denoted Cnl(A).
Definition 19
supp(B).

1. argument attacks argument B Cnl(A) =

2. say B subargument argument form A1 , . . . , Ak , denoted
B A, B = B subargument Ai .
Remark 7 simplicity, identify assumption-based framework F logicassociated argumentation framework (AFF , , ALF , Cnl) AFF argumentation
framework generated F (according definitions 18, 19).
difficult see
Theorem 6 ABA frameworks compact.
20. ab stands assumption-based.

94

fiClosure Consistency Logic-Associated Argumentation

Proof See appendix section 5.

Theorem 7 Let F ABA framework. ALF satisfies ab-self-contradiction axiom,
F cohesive.
Proof See appendix section 5.
follows immediately theorems 6,7, corollary 1
Corollary 3 Let F ABA framework. ALF satisfies ab-self-contradiction axiom,
F satisfies closure- consistency-properties.
5.3 Logic Programming
Logic programming could classified three different classes definite programs,
normal programs extended programs increasing complexity. Bondarenko, Dung,
Kowalski Toni(1997) showed logic programs instances assumption-based
argumentation. discuss underlying abstract logics classes selfcontradiction axiom.
5.3.1 Definite Logic Programs
definite logic program simply assumption-based argumentation framework F =
(R, A, ) based language L
1. L consists ground atoms set assumptions empty.
2. Rules R form a1 , . . . , h h, a1 , . . . , atoms L.
contradiction L, CON RAF = . ab-self-contradiction axiom
hold trivially. Since attack arguments, extension set
arguments. closure consistency properties hold obviously.

5.3.2 Normal Logic Programs
normal logic program assumption-based argumentation framework F = (R, A,
based language L

)

1. L consists atoms form a, b, . . . together negation-as-failure literals
form atom.
2. Assumptions negation-as-failure literals whose contraries a.
3. Rules R form l1 , . . . , ln h h atom l1 , . . . , ln literals
L.
95

fiDung & Thang

CON RAF consists subsets L contain pair a, atom a.
ab-self-contradiction axiom holds obviously.21 closure consistency properties hence hold extensions normal programs.

5.3.3 Extended Logic Programs
extended logic program (Gelfond & Lifschitz, 1990; Lifschitz, 1999) assumptionbased argumentation framework F = (R, A, ) based language L
1. L consists atoms form a, b, . . . explicit negations a, b, . . . together
negation-as-failure literals form l l classical literal (i.e.
atom explicit negation atom).
2. Assumptions negation-as-failure literals l whose contraries l.
3. R consists rules form l1 , . . . , ln h h classical literal
l1 , . . . , ln literals L
CON RAF consists subsets L contain pair a, atom
pair l, l classical literal l.
theorems 6,7 corollary 3, follows immediately
Corollary 4 Let F extended logic program. CNF () contradictory wrt
ALF satisfies ab-self-contradiction axiom F compact cohesive hence
satisfies closure consistency properties.

6. Translating Rule-Based Argumentation Assumption-Based
Argumentation
showed previous two sections self-contradiction axioms sufficient
natural conditions ensuring closure consistency properties assumptionbased rule-based argumentation.
section, argue self-contradiction axiom rule-based systems
subsumed assumption-based self-contradiction axiom giving translation
rule-based systems equivalent assumption-based ones. generally, translation suggests rule-based argument systems (without preferences) subsumed
assumption-based argumentation.
Let = (RS, RD) arbitrary fixed rule-based argumentation system
r RD, rule RS RD whose head coincides Oj(r)
whose body contains occurrence Oj(r). translate assumption-based
system following definition.
Definition 20 (AS) = (R, A,

) defined follows:

21. give short proof here. Let X inconsistent set assumptions. Hence assumption
s.t. {, } CNF (X). Since assumptions appear heads rules, X.

96

fiClosure Consistency Logic-Associated Argumentation

1. = {Oj(r) | r RD } {not l | l head rule RD}
Oj(r) viewed assumption indicating rule r applicable l
negation-as-failure assumption stating evidence-to-the-contrary
l.
2.

R = RS {T r(r) | r RD }
r(r) form
Oj(r), h, 1 , . . . , n h
r form 1 , . . . , n h

3.

Oj(r) = Oj(r) l = l

Remark 8 Since rule RS RD whose head form Oj(r), assumption coincides head rule R. Therefore CNT (AS) ()
contradictory wrt . difficult see CNT (AS) () = CNAS (). CNT (AS) ()
hence contradictory wrt . Therefore CNT (AS) () contradictory.
(AS) hence assumption-based argumentation system.
(AS) distinct systems, attentive reader may ask sense
equivalent?
giving formal elaboration question, let us look example.
Example 9 Consider simple rule-based system consisting one strict rule one
defeasible rule :
r0 : b
r1 : b f
two arguments here:
A1 : b A2 : A1 f
arguments attack other. Hence complete extension E
contains arguments A1 , A2 .
corresponding assumption-based system (AS) consists two rules:
b

Oj(r1 ), f, b f

four arguments assumption-based system:
B1 : b

B2 : C 0 , C 1 , B1 f

C0 : Oj(r1 )

C1 : f

attacks four arguments. complete extension E
(AS) consists four arguments. fact information contained E fully captured set = {B1 , B2 } since C0 , C1 subarguments B2 , hence attack
97

fiDung & Thang

also attack B2 . could view set equivalent representative
E . could viewed representing core E .
equivalence E E captured correspondence arguments
A1 , A2 arguments B1 , B2 respectively.
Note arguments C0 , C1 extension E (AS) explicitly represent implicit
meta-level information contained extension E AS, namely, defeasible rule r1 applicable argument conclusion f .
Let AF0 = (AR0 , att0 ), AF1 = (AR1 , att1 ) argumentation frameworks corresponding AS, (AS) respectively.
Definition 21 Let set arguments AF1 . core S, denoted Core(S),
defined
Core(S) = \
i.e Core(S) contains arguments assumptions.
illustration, example 9, Core(E ) = {B1 , B2 }.
Lemma 8
1. Let set arguments AF1 argument AF1 .
holds: acceptable wrt iff acceptable wrt Core(S).
2. Let set arguments AF1 . admissible iff Core(S) admissible.
Proof See appendix section 6.
following lemma states complete sets identified uniquely cores.
Lemma 9 Let E, E complete extensions AF1 . holds:
E = E iff Core(E) = Core(E )
Proof See appendix section 6.
present bijection complete extensions AF0 complete extensions
AF1 defining natural one-one mapping AR0 AR1 :
Definition 22 Define
C : AR0 AR1
following properties satisfied:
1. form A1 , . . . , h, n 0, C(A) form
C(A1 ), . . . , C(An ) h 22
22. Note form h, C(A) = A.

98

fiClosure Consistency Logic-Associated Argumentation

2. basic defeasible argument form A1 , . . . , h C(A)
form
Oj(r), h, C(A1 ), . . . , C(An ) h 23
r last rule A.
set arguments AR0 , let C(S) = {C(A) | }. follows
Lemma 10 Let A, B AR0 AR0 . following observations hold:
1. Cnl(A) = Cnl(C(A)).
2. C one-one mapping AR0 onto AR1 \
3. (A, B) att0 iff (C(A), C(B)) att1 .
4. admissible AF0 C(S) admissible AF1 .
5. acceptable wrt iff C(A) acceptable wrt C(S)
Proof See appendix section 6.
Let L language
L0 = L \ {Oj(r), Oj(r) | r defeasible rule AS}
equivalence (AS) established following theorem.
Theorem 8 complete extension E AF0 complete extension E AF1
vice versa following properties hold:
1. C(E) = Core(E )
2. literal l L0 ,

l Cnl(E) iff l Cnl(E )

Proof See appendix section 6.
following theorem shows self-contradiction axiom rule-based argumentation subsumed ab-self-contradiction axiom assumption-based argumentation.
Let ALi = (CNi , CON RAi ), = 0,1, abstract logics associated AS, (AS)
respectively.
Theorem 9 AL0 satisfies self-contradiction axiom AL1 satisfies ab-selfcontradiction axiom.
Proof See appendix section 6.
23. Note defeasible rule r form h, C(A) form Oj(r), h, h.

99

fiDung & Thang

7. Discussion
Amgoud Besnard (2009) introduced use Tarskis abstract logic study
consistency property logic-based argumentation. following, discuss
compactness cohesion could fulfilled systems.
remarked earlier, Tarski abstract logic represented abstract logic
CON RA 6= X CON RA, CN (X) = L x L
CN ({x}) CON RA.
Tarski abstract logic said adjunctive x, L, CN ({x}) 6=
CN ({x, y}) 6= CN ({y}) exists z CN ({z}) = CN ({x, y}).
knowledge base defined set L x , x consistent.
argument pair = (X, ) X finite consistent support
denoted supp(A), CN (X) conclusion denoted Cnl(A).
support set arguments union supports individual arguments.
AR denotes set arguments .
X called minimal conflict set X inconsistent proper subset X
consistent.24
rest discussion, assume minimal conflict sets contain two
elements.
Let att AR AR attack relation.
1. att said context-sensitive iff a, b AR, supp(a)supp(b) inconsistent
either (a, b) att (b, a) att.
2. att said conflict-dependent iff a, b AR, (a, b) att supp(a)
supp(b) inconsistent.
3. att said symmetric iff a, b AR, (a, b) att (b, a) att.
argument B said subargument argument A, denoted B B =
B = ({}, ) supp(A).
Lemma 11 minimal conflict sets binary attack relation att contextsensitive, conflict-dependent symmetric LAF = (AF, , AL, Cnl) compact
cohesive logic-associated argumentation framework.
Proof See appendix section 7.
follows immediately theorem 1:
Corollary 5 minimal conflict sets binary attack relation att contextsensitive, conflict-dependent symmetric LAF satisfies properties closure
consistency.
24. difficult see minimal conflict set finite CN (X) = L, L = CN ({x})
x L, follows x CN (X). finiteness axiom, finite subset X
x CN (Y ). Hence CN (Y ) = L. minimality X, follows X = . X hence
finite.

100

fiClosure Consistency Logic-Associated Argumentation

Corollary 5 rather limited due restrictions imposed attack relations.
structure arguments rather poor abstract logics reveal
structure consequence relation. approach marrying abstract argumentation abstract logics resulting logic-associated abstract argumentation addresses
problem specifying subargument structure relation attack relation.
Caminada Amgoud (2007) also studied unrestricted rebuts two arguments contrary conclusions considered attack other. Defeasible argumentation attacks based unrestricted rebuts violates consistency closure
properties except grounded semantics. Unrestricted rebuts gain much attention research assumption-based argumentation logic programming.
suggests relevant structural features underlying unrestricted attacks
still understood. sensible idea could study kind attacks within
proposed framework logic-associated abstract argumentation could shed lights
instances defeasible assumption-based argumentation.
Non-interference, another key rationality postulate structured argumentation
proposed Caminada, Carnielli, Dunne (2012) studied extensively Caminada et al. (2012), Wu (2012). Non-interference conceptually different consistency closure properties later properties could viewed correctness
argument systems former structural modularity. focus
correctness argument systems, study structural modularity outside
scope paper. Nonetheless, non-interference seems related property
localizing conflicts arguments systems say argument system localized
argument attacking every argument. difficult see aspic systems
closed contraposition localized rebutting attack it.
contrast, self-contradiction axiom allows us develop localized aspic systems. would
interesting see two concepts localized conflicts non-interference
interrelated.
Toni (2008) generalized assumption-based argumentation represent reasoning
strict defeasible rules satisfying rational properties logical closure
consistency. showed section 6, standard assumption-based argumentation
captures rule-based argumentation system simple elegant transformation. Hence
necessary generalize assumption-based argumentation capture defeasible reasoning strict defeasible rules. Nevertheless, proposal Toni (2008) interesting.
Nielsen Parson (2007) also proposed generalization abstract argumentation
allowing sets attacking arguments. Prakken (2010) Modgil Prakken (2013)
also studied preferences arguments. would interesting see whether
properties compactness cohesion satisfied frameworks.
believe compactness cohesion self-contradiction properties could
serve guideline principles design logic-based argumentation systems ensure
satisfaction properties logical closure consistency. pointed Caminada
Amgoud (2007), several argument systems (Garcia & Simari, 2004; Governatori,
Maher, Antoniou, & Billington, 2004) satisfying consistency property. would
interesting see results paper could applied them.
101

fiDung & Thang

Appendix A. Section 1
Let CN consequence operator wrt . clear CN () = {p, b, Oj(d2 ), th}.
Let c CN (X) c L X L. Let x X. show x CN (Y )
= X \ {x} {c}. c CN (), absurdity rules, follows immediately
x CN (Y ). Suppose c 6 CN (). Hence c CN (X) iff c X X contains pair
literals a, a. c X x 6= c, c . Hence {c, c} . absurdity
rules, L = CN (Y ). c X x = c x . Hence x CN (Y ). X contains
pair literals a, x 6 {a, a}, L = CN (Y ). x {a, a} x .

Appendix B. Section 3
Lemma 1 Let set arguments. following assertions hold:
1. argument A, generated {A}.
2. Sub(S) GN (S).
3. Cnl(GN (S)) CN (Cnl(Sub(S))).
4. CN (Cnl(GN (S))) = CN (Cnl(Sub(S))).
5. argument C, C attacks GN (S) iff C attacks S.
Proof first assertion obvious definitions 6 7. Since Sub(S),
{A} Sub(S), follows immediately first assertion argument Sub(S)
generated S. third assertion follow immediately definitions 6 7.
fourth assertion follows second third ones.
GN (S), clear C attacks S, C attacks GN (S). Suppose C attacks
GN (S). Let GN (S) s.t. C attacks A. Let BA base BA Sub(S).
C hence attacks BA. Therefore C attacks Sub(S). Thus C attacks S.
Theorem 1 Let E complete extension. GN (E) = E
Proof Since attack GN (E) attack E (lemma 1, last assertion),
attack GN (E) counterattacked E E complete extension. Therefore
GN (E) E. second assertion lemma 1, follows E GN (E). Hence GN (E) =
E.

Appendix C. Section 4
Remark 9 strict argument X L strict argument set rules RS {
| X}.
Remark 10 strict argument X, set premises A, denoted P rem(A),
set literals X labelling leaves (viewed proof tree).
Theorem 4 Rule-based argumentation systems compact.

102

fiClosure Consistency Logic-Associated Argumentation

Proof Let rule-based system let set arguments wrt
CNAS (Cnl(Sub(S))). lemma 2, need show Cnl(GN (S)).
Let X minimal subset Cnl(Sub(S)) CNAS (X). Hence
strict argument A0 X conclusion . let SX minimal set arguments
Sub(S) s.t. Cnl(SX ) = X. Let argument obtained replacing leaf
A0 (viewed proof tree) labelled literal X argument conclusion
SX . obvious conclusion . show SX base
A. Suppose B argument attacking A. Since A0 strict argument X, B must
attack basic defeasible subargument argument SX . Hence B attacks SX . Thus
GN (S). Hence Cnl(GN (S)). proved rule-based argumentation system compact.
Lemma 4 Let argument BD set basic defeasible subarguments
A. Cnl(A) CNAS (Cnl(BD)).
Proof induction size A.
Basic Step form / .
Suppose form CNAS (). BD = , lemma holds.
Suppose form BD = {A}. lemma holds.
Inductive Step. Suppose form A1 , . . . , /
Suppose form A1 , . . . , BD. lemma holds obviously.
Suppose form A1 , . . . , . Hence BD union sets
BD1 , . . . , BDn basic defeasible subarguments A1 , . . . , respectively. induction hypothesis, Cnl(Ai ) CNAS (Cnl(BDi )), 0 n. Hence Cnl(A) CNAS (Cnl(BD)).

Theorem 5 Suppose ALAS satisfies self-contradiction axiom. cohesive.
Proof Let inconsistent set arguments. Hence Cnl(Sub(S)) inconsistent. Define
BD set basic defeasible arguments Sub(S). clear BD 6= .
lemma 4, follows Cnl(Sub(S) CNAS (Cnl(BD)). Hence CNAS (Cnl(Sub(S))) =
CNAS (Cnl(BD)). Cnl(BD) therefore inconsistent. Since ALAS satisfies self-contradiction
axiom, Cnl(BD) CNAS (Cnl(BD)). Let B BD
Cnl(B) = . CNAS (Cnl(Sub(S))) = CNAS (Cnl(BD)), follows CNAS (Cnl(Sub(S))).
compactness Sub(S) GN (S), follows argument
GN (S) Cnl(A) = . Hence attacks B. Since B BD Sub(S)
GN (S), GN (S) conflicting.
Lemma 5
1. AL closed contraposition, AL satisfies strong absurdity axiom.
2. AL satisfies strong absurdity axiom AL satisfies self-contradiction
axiom.
Proof
103

fiDung & Thang

1. Suppose AL closed contraposition. Let X CON RA. Hence
atom s.t. {a, a} X. CN ({a, }) literal ,
closure contraposition property, follows CN ({a, a}). Hence
CN (X) literal . proved L = CN (X) X CON RA.
definition 10, follows AL satisfies strong absurdity axiom.
2. Suppose AL satisfies strong absurdity axiom. Let X L X minimal
inconsistent. Therefore CN (X) CON RA. idempotence axiom
strong absurdity axiom, CN (X) = L. holds obviously: X CN (X).
Lemma 6 Let = (RS, RD) set strict rules RS closed transposition. ALAS satisfies self-contradiction axiom.
Proof first prove following assertion.
Assertion: Let strict argument X conclusion =
6 P rem(A) X.
P rem(A), argument B premises P rem(A) {}
conclusion .
Proof prove induction height (as proof tree).25
height 0, theorem obvious.
Suppose form A1 , . . . , Cnl(Ai ) = . Let P rem(A).
Without loss generality, let P rem(An ). closure transposition, rule
1 , . . . , n1 , n also belongs RS. Let B argument A1 , . . . , An1 ,
n .
induction hypothesis, proof tree r whose premises P rem(An )
{n } whose conclusion .
Let r tree obtained r replacing occurrence premise n
argument B. clear P rem(T r ) P rem(A) {} Cnl(T r ) = .
Let X L s.t. X minimal inconsistent. Hence two arguments A0 , A1
premises X conclusions , respectively. minimality X,
holds: X = P rem(A0 ) P rem(A1 ). Let X. Without loss generality, suppose
P rem(A0 ). assertion, follows exists argument B
conclusion P rem(B) P rem(A0 ) {}. Let argument obtained
replacing leaf labelled B tree A1 . clear P rem(A) X
conclusion .

Appendix D. Section 5
Theorem 6 ABA frameworks compact.
Proof Let set arguments. Let SU = Sub(S) CSU = Cnl(SU ).
need prove CN (CSU ) Cnl(GN (S)) (lemma 2). Let CN (CSU ). easy
see argument (viewed proof tree) conclusion whose leaves
25. height proof tree length (the number links) longest path root leaf
node.

104

fiClosure Consistency Logic-Associated Argumentation

labelled sentences CSU . Expand proof tree leaf labelled CSU
proof tree representing argument SU conclusion . new proof tree
corresponds argument B conclusion . proof trees SU used
expand obviously form base B. hence clear B generated S.
Theorem 7 Let F ABA framework. ALF satisfies ab-self-contradiction axiom,
F cohesive.
Proof Let inconsistent set arguments. Hence supp(S) inconsistent. Since
CNF satisfies assumption-based self-contradiction axiom, supp(S)
CNF (supp(S)). lemma 2, argument GN (S)
Cnl(A) = . obvious attacks argument whose premises contain .
Since GN (S), GN (S) hence conflicting.

Appendix E. Section 6
Lemma 8
1. Let set arguments AF1 argument AF1 . holds:
acceptable wrt iff acceptable wrt Core(S).
2. Let set arguments AF1 . admissible iff Core(S) admissible.
Proof
1. Since Core(S) S, acceptable wrt Core(S), obviously acceptable wrt S.
Suppose acceptable wrt S. Let B attack A. Hence s.t.
attacks B. Therefore assumption. Hence Core(S). B hence
attacked Core(S), i.e. acceptable Core(S).
2. Follows immediately previous assertion.
Lemma 9. Let E, E complete extensions AF1 . holds:
E = E iff Core(E) = Core(E )
Proof need show Core(E) = Core(E ) implies E = E . reverse
direction obvious. Let Core(E) = Core(E ) = S. Let E \ S. hence
assumption acceptable wrt E. lemma 8, acceptable wrt S. Thus acceptable
wrt E (lemma 8). Hence E . Similarly, could show assumption E \
belongs E. thus proved E = E .
Lemma 10 Let A, B AR0 AR0 . following observations hold:
1. Cnl(A) = Cnl(C(A)).
2. C one-one mapping AR0 onto AR1 \
105

fiDung & Thang

3. (A, B) att0 iff (C(A), C(B)) att1 .
4. admissible AF0 C(S) admissible AF1 .
5. acceptable wrt iff C(A) acceptable wrt C(S)
Proof
1. first assertion obvious.
2. obvious argument AR0 C(A) A.
Viewing argument AR0 proof tree, height tree defined
length (i.e. number links) longest path root leaf. Let AR0,k
set trees height k AR0 . prove induction C one-one
AR0,k .
obvious C one-one AR0,0 . Suppose C one-one AR0,k . Let A, B
two different arguments AR0,k+1 . last rules A,B different
obvious C(A), C(B) different. Suppose last rules A,B identical.
A, B respectively forms A1 , . . . , / h, B1 , . . . , Bn / h.
Without loss generality, assume A1 6= B1 . Hence induction
hypothesis, C(A1 ) 6= C(B1 ). Therefore C(A) 6= C(B).
also straightforward prove induction B AR1 \ A,
AR0 C(A) = B.
3. (a) Suppose (A, B) att0 . Let B basic defeasible subargument B
attacks B (on B ). two cases:
i. Cnl(A) = Oj(Lr(B )) (undercut attack). Cnl(A) = Cnl(C(A)),
follows Cnl(C(A)) = Oj(Lr(B)) Oj(Lr(B)) supp(C(B)). C(A)
hence attacks C(B) wrt att1 .
ii. Cnl(A) = h h = Cnl(B ). Hence Cnl(C(A)) = h h
supp(C(B)). C(A) hence attacks C(B) wrt att1 .
(b) Suppose (C(A), C(B)) att1 . two cases:
i. Cnl(C(A)) = Oj(r) defeasible rule r Oj(r) supp(C(B)).
Cnl(A) = Cnl(C(A)), follows Cnl(A) = Oj(r) r defeasible
rule B. Hence basic defeasible subargument B B
Lr(B ) = r. Hence attacks B B AF0 .
ii. Cnl(C(A)) = h h supp(B). Hence basic defeasible
rule r B hd(r) = h. Therefore subargument B B
Lr(B ) = r. Hence attacks B B (by rebutting) AF0 .
4. assertion 3, clear conflict-free iff C(S) conflict-free.
Suppose defends attacks. Let attack C(S) AF1 . Therefore
assumption. second assertion, B = C 1 (A). assertion
3, follows B attacks S. Therefore attacks B. Hence C(S) attacks A.
106

fiClosure Consistency Logic-Associated Argumentation

Suppose C(S) defends attacks. Let attack AF0 . Let B = C(A).
assertion 3, follows B attacks C(S). Therefore C(S) attacks B. Hence attacks
A.
5. Follows immediately assertion 3.
Theorem 8 complete extensions E AF0 complete extension E
AF1 vice versa following properties hold:
1. C(E) = Core(E )
2. literal l L0 , l Cnl(E) iff l Cnl(E )
Proof Let E complete extension AF0 . assertion 4 lemma 10, follows
= C(E) admissible. Let set assumptions acceptable wrt S. show
E = complete. Let B AF1 acceptable wrt E . Suppose B
assumption. Let = C 1 (B). lemma 10, assertion 5, acceptable wrt E. Hence
E. Therefore B S. B assumption, B . proved E
complete Core(E ) = C(E). uniqueness E follows directly lemma 9.
Let l L0 l Cnl(E ). Since l 6 A, clear l Cnl(Core(E )). Hence
l Cnl(C(E)). first assertion lemma 10, follows l Cnl(E).
Theorem 9 AL0 satisfies self-contradiction axiom AL1 satisfies ab-selfcontradiction axiom.
Proof Suppose AL0 satisfies self-contradiction axiom. Let X inconsistent
set assumptions (AS). want show exists X
CN1 (X). Suppose contrary. follows immediately atom
{a, a} CN1 (X). two cases.
Case 1: {a, a} =
6 . Since 6 A, assumption. classical negation
apply negation-as-failure literal, follows = Oj(d) RD.
Oj(d) = CN1 (X), contradiction hypothesis 6 X
CN1 (X). case hence occur.
Case 2: {a, a} = . Therefore {a, a} X = . Let S1 set arguments
AR1 \ whose support subset X. {a, a} CN1 (X) \ X, follows S1 6= .
difficult see Cnl(S1 ) = CN1 (X) \ X. Let S0 set arguments
AR0 S0 = C 1 (S1 ). Cnl(S0 ) = Cnl(S1 ), follows Cnl(S0 )
closed (wrt CN0 ). also easy see Sub(S0 ) = S0 . Let BS set basic
defeasible arguments S0 . lemma 4, clear CN0 (Cnl(BS)) = Cnl(S0 ). Since
{a, a} CN1 (X) \ X = Cnl(S0 ) = CN0 (Cnl(BS)), Cnl(BS) hence also inconsistent
wrt AS. AL0 satisfies self-contradiction axiom, literal h Cnl(BS)
h CN0 (Cnl(BS)). Let = h. h Cnl(BS), follows
supp(C(BS)) supp(S1 ) = X. h CN0 (Cnl(BS)) = Cnl(S1 ) = CN1 (X) \ X,
follows CN1 (X). Contradiction.
proved AL1 satisfies assumption-based self-contradiction axiom.
107

fiDung & Thang

Appendix F. Section 7
Lemma 11 minimal conflict sets binary attack relation att contextsensitive, conflict-dependent symmetric LAF = (AF, , AL, Cnl) compact
cohesive logic-associated argumentation framework.
Proof show LAF logic-associated argumentation framework, need show
A, B, C AR, C attacks B B C attacks A. B = A, nothing prove. Suppose B = ({}, ) supp(A). conflict-dependency,
follows supp(C) {} inconsistent. Hence supp(C) supp(A) inconsistent.
context-sensitivity symmetry attack relation, follows C attacks A.
Let set arguments CN (Cnl(Sub(S))). Hence exists finite
X supp(S) CN (X). Let = (X, ). Let X = {({}, ) | X}.
clear X Sub(S). show X base A. Suppose B attacks A. Hence
conflict-dependency att, exists minimal conflict set {, } supp(A),
supp(B). Hence B attacks argument ({}, ) X . Hence GN (S).
proved CN (Cnl(Sub(S))) Cnl(GN (S). Hence lemma 2, AF compact.
Let inconsistent set arguments. Hence supp(S) inconsistent. exists
binary minimal conflict set {, } supp(S). Hence arguments = ({}, ), B = ({}, )
attack other. A, B GN (S), GN (S) conflicting.

References
Amgoud, L., & Besnard, P. (2009). Bridging gap abstract argumentation
systems logic. SUM, pp. 1227.
Bondarenko, A., Dung, P., Kowalski, R., & Toni, F. (1997). abstract, argumentationtheoretic approach default reasoning. Artif. Intell., 93, 63101.
Caminada, M., & Amgoud, L. (2007). evaluation argumentation formalisms.
Artificial Intelligence, 171, 286310.
Caminada, M., Carnielli, W., & Dunne, P. (2012). Semi-stable semantics. Journal Logic
Computation, 22 (5), 12071254.
Dung, P. M. (1995). acceptability arguments fundamental role nonmonotonic reasoning, logic programming n-person gamescceptability arguments
fundamental role nonmono- tonic reasoning, logic programming n-person
games. Artif. Intell., 77 (2), 321358.
Dung, P. M., & Thang, P. M. (2011). Closure consistency rationalities logic-based argumentation. Balduccini, M., & Son, T. C. (Eds.), Logic Programming, Knowledge
Representation, Nonmonotonic Reasoning, Vol. 6565, pp. 3343. Springer.
Garcia, A., & Simari, G. (2004). Defeasible logic programming: argumentative approach.
TPLP, 4 (1-2), 95138.
Gelfond, M., & Lifschitz, V. (1988). stable model semantics logic programming.
ICLP/SLP, pp. 579597. MIT Press.
108

fiClosure Consistency Logic-Associated Argumentation

Gelfond, M., & Lifschitz, V. (1990). Logic programs classical negation. ICLP, pp.
579597. MIT Press.
Governatori, G., Maher, M., Antoniou, G., & Billington, D. (2004). Argumentation semantics defeasible logic. J. Log. Comput., 14 (5), 675702.
Lifschitz, V. (1999). Answer set planning (abstract). LPNMR, pp. 373374. MIT Press.
Modgil, S., & Prakken, H. (2013). general account argumentation preferences.
Artificial Intelligence, 195, 361397.
Nielsen, S., & Parson, S. (2007). generation dungs abstract framework argumentation: Arguing sets attacking arguments. LNCS, No. 4766, pp. 5473.
Springer Verlag.
Pollock, J. (1995). Cognitive carpentry: blueprint build person.. MIT Press,
Cambridge MA.
Pollock, J. (1987). Defeasible reasoning. Cognitive Science, 11 (4), 481518.
Prakken, H. (2010). abstract framework argumentation structured arguments.
J. Arguments Computation, 1 (2), 93124.
Prakken, H. (2012). reflection two current trends formal argumentation. Artikis, A., Craven, R., Cicekli, N. K., Sadighi, B., & Stathis, K. (Eds.), Logic Programs,
Norms Action, Vol. 7360 Lecture Notes Computer Science, pp. 249272.
Springer Verlag.
Toni, F. (2008). Assumption-based argumentation closed consistent defeasible reasoning. JSAI, 390402.
Wu, Y. (2012). Arguments Conclusions. Ph.D. thesis, University Luxemburg.

109

fiJournal Artificial Intelligence Research 49 (2014) 171-206

Submitted 07/13; published 02/14

Representing Reasoning Rules
General Games Imperfect Information
Stephan Schiel

stephans@ru.is

School Computer Science, Reykjavk University,
Menntavegur 1, 101 Reykjavk ICELAND

Michael Thielscher

mit@cse.unsw.edu.au

School Computer Science Engineering,
University New South Wales,
Sydney, NSW 2052 AUSTRALIA

Abstract
general game player system play previously unknown games
given rules. purpose, Game Description Language (GDL)
developed high-level knowledge representation formalism communicate game rules
players. paper, address fundamental limitation state-of-the-art methods
systems General Game Playing, namely, confined deterministic games
complete information game state. develop simple yet expressive extension
standard GDL allows formalising rules arbitrary finite, n-player games
randomness incomplete state knowledge. second part paper,
address intricate reasoning challenge general game-playing systems comes
new description language. develop full embedding extended GDL
Situation Calculus augmented Scherl Levesques knowledge fluent . formally
prove provides sound complete reasoning method players knowledge
game states well knowledge players.

1. Introduction
General Game Playing (GGP) concerned development systems understand rules previously unknown games learn play games well without
human intervention. annual AAAI GGP Competition, established
2005 foster research area, led number successful approaches systems (Kuhlmann, Dresner, & Stone, 2006; Clune, 2007; Schiel & Thielscher, 2007; Kaiser,
2008; Finnsson & Bjornsson, 2008; Kissmann & Edelkamp, 2011; Mehat & Cazenave, 2011;
Kirci, Sturtevant, & Schaeer, 2011). General game-playing programs quintessential
example systems end users customise specific tasks. makes
GGP interesting challenging problem AI, involving many fundamental issues
reasoning, learning, planning decision making (Pell, 1993). Consequently, General
Game Playing broader significance variety AI disciplines beyond conventional
computer game playing (Genesereth, Love, & Pell, 2005).
c
2014
AI Access Foundation. rights reserved.

fiSchiffel & Thielscher

1.1 Representing Rules General Games
first AAAI Competition saw introduction general Game Description Language (GDL) foundation general game-playing systems (Genesereth et al., 2005).
machine-processable languages specification games existed before, notably Gala (for: Game Language). latter never used purpose
front-end system computing optimal strategies game trees (Koller
& Pfeer, 1997). Presumably tight coupling programming language (Prolog)
operationalrather declarativesemantics prevented Gala adopted
others system-independent game specification language.
GDL allows description game finitely many players finitely
many legal moves state, moves deterministic fully observable,
complete game rules known player. Simultaneous moves possible,
provides restricted form imperfect information. However, players always
immediately informed others moves hence always perfect information
game state every round.
GDL organisers AAAI GGP Competition sought high-level game
specification language admits purely declarative reading. Thus, enables general
game-playing systems reason rules previously unknown game, example, order extract game-specific knowledge automatically design evaluation
functions. proved successful problems studied extensively
recent past (Kuhlmann et al., 2006; Kaiser, 2007; Clune, 2007; Schiel & Thielscher,
2007; Edelkamp & Kissmann, 2008; Schiel & Thielscher, 2009; Ruan, van der Hoek, &
Wooldridge, 2009; Schiel, 2010; Thielscher & Voigt, 2010). GDL purely declarative
language tradition AI Planning languages fact seen multi-agent
extension thereof since existing planning languages always describe problem perspective single agenteven case adversarial planning (Jensen & Veloso, 2000).
presence agents actions goals crucial since reasoning
intentions basis Opponent Modelling, central aspect GGP
goes beyond AI Planning (Genesereth et al., 2005). GDL inherits existing planning languages compactness specifications, contrasts encoding
techniques, instance use propositionalised graphs (La Mura, 2000).
Despite steady progress, current state art General Game Playing limited
deterministic games complete information game state, owing restricted expressiveness original GDL. covers variety classic games Chess,
Go, Chinese Checkers etc. excludes games elements chance like Backgammon;
games information asymmetry Bridge Poker; games involve private communication among cooperating players like Bughouse Chess, negotiations
like Diplomacy. Moreover, envisaged applications General Game Playing systems,
automated trading agents (Thielscher & Zhang, 2010), usually characterised
imperfect information.
paper, lay foundations truly general game-playing systems developing analysing extension existing description language GDL-II (for Game
172

fiRepresenting Reasoning General Games

Description Language Imperfect/Incomplete Information).1 GDL-II allow
description extensive-form game finitely many players finitely many
legal moves state moves nondeterministic players
imperfect asymmetric information. Although GDL-II based assumption game rules fully known player, incomplete-information
gamesin game-theoretic sense (Rasmusen, 2007), is, players know
exactly goal type opponents arecan modelled extended
language via standard Harsanyi (1967) transformation adding unobserved move
nature beginning.
1.2 Reasoning Rules General Games
Game descriptions GDL-II include precise specification information
players get throughout game. rules game imply anything
players use information, is, conclusions draw it,
combine already know, whether memorise it. separate
questions concern reasoning game-playing agents perform basis
rules game. clear separation two issues means that, example, perfect
recall (Rasmusen, 2007) property individual players depends reasoning
mechanism implemented them, rather property game itself.
basic GDL, players always informed others moves, reasoning
rules game rather straightforward: simple, Prolog-like inference engine
suces compute ones everyone elses legal moves maintain complete
state description throughout match (Genesereth et al., 2005). contrast, playing
arbitrary games incomplete state knowledge poses intricate reasoning challenge
general game-playing systems: Imperfect information information asymmetry require
player draw conclusions percepts entail current
position, everybody elses possible moves, well
players may know.
Action formalisms like classic Situation Calculus (McCarthy, 1963) developed precisely purpose. readily available, deploy General
Game Playing presupposes proper translation GDL-II existing, suitably expressive action language. Therefore, second part paper address problem
reasoning GDL-II presenting full embedding extended general game
description language suitably extended variant Situation Calculus.
1.3 Overview Results
specific contributions paper foundations General Game Playing
summarised follows:
1. show addition two keywords GDL suces obtain
desired generality game description language: first, called sees, used
1. unfortunate clash terminology, agent know full state environment
said incomplete information AI, whereas Game Theory, players know full
state turn, game said imperfect information.

173

fiSchiffel & Thielscher

control information player gets. second, called random, denotes
special player chooses moves randomly.
2. develop new execution model GDL-II demonstrate howdespite
conceptual simplicity representation languagethe operational semantics gives
rise intricate epistemic model, provides players sucient information
enable reason knowledge knowledge
opponents, predict knowledge evolve, reason
players know players knowledge.
3. develop new communication protocol GDL-II address practical issues
arise General Game Playing imperfect information.
4. investigate expressive power high-level knowledge representation language relating mathematical concept extensive-form games (Rasmusen,
2007).
5. extend Situation Calculus includes Scherl Levesques knowledge fluent (Scherl & Levesque, 2003) multi-agent knowledge, simultaneous moves,
new concept derived action predicates.
6. present mapping GDL-II fully embedded extended Situation
Calculus, formally prove provides correct axiomatic account
semantics GDL-II, enables players draw conclusions
players knowledge past, present, future game states.
paper proceeds follows. next section, introduce GDL-II extension GDL randomness imperfect information, use various examples
demonstrate range phenomena games described new language.
also develop modified execution model GDL-II. Section 3, show
language suciently expressive give rise intricate multi-agent epistemic model,
relate language extensive-form games. Section 4, present
formal embedding language Situation Calculus prove correctness
translation. discuss related work Section 5 conclude Section 6.

2. Describing General Imperfect-Information Games Randomness
General Game Playing requires formal language describing rules arbitrary games.
complete game description needs provide
names players,
initial position,
legal moves aect position,
terminating winning criteria.
174

fiRepresenting Reasoning General Games

role(R)
init(F)
true(F)
legal(R,M)
does(R,M)
next(F)
terminal
goal(R,V)
sees(R,P)
random

R player
F holds initial position
F holds current position
R move current position
player R move
F holds next position
current position terminal
R scores V points current position
R perceives P next position
random player

Table 1: GDL-II keywords. Standard GDL comprises top eight. keywords
accompanied auxiliary, pre-defined predicate distinct(X,Y), meaning
syntactic inequality two arguments (Love et al., 2006).

description language GDL developed purpose (Genesereth et al.,
2005; Love, Hinrichs, Haley, Schkufza, & Genesereth, 2006). emphasis high-level,
declarative game rules easy understand maintain. time, GDL
precise semantics fully machine-processable. Moreover, background knowledge
requireda set rules player needs know order able play
previously unknown game.
GDL based standard syntax semantics Logic Programming.
special keywords used dierent elements game description mentioned above.
original game description language GDL uses first eight keywords shown Table 1.
version GDL suitable describing finite, synchronous, deterministic
n-player game (Genesereth et al., 2005).2 execution model entails complete state
information: initial position fully specified players immediately informed
others moves, (joint) moves deterministic.
Although GDL developed complete-information games only, surprisingly simple
extension syntax suces generalise arbitrary (discrete finite) games
information asymmetry random moves.
1. new keyword random introduced special role.
assumed player always makes purely random choice among legal
moves position. allows game designer describe elements chance,
rolling dice shuing cards.
2. second new keyword sees(R,P) introduced specifying conditions
player R receives information (i.e., perceives) P.
ensure greatest flexibility, arbitrary terms may serve percepts P.
allow game designer players observe specific state features actions,
games may also feature rules according players informed logical
2. Synchronous means players move simultaneously. setting, turn-taking games modelled
allowing players one legal move, without eect, turn.

175

fiSchiffel & Thielscher

combinations conditions receive partial information state feature
move another player.
language extension accompanied modified execution model,
players longer informed others moves default; rather,
get see game rules entail percepts.
refer Table 1 list keywords new language GDL-II.
2.1 Examples
Prior giving precise definition syntax semantics illustrate expressiveness
extended Game Description Language several examples; first third
recur later paper.
2.1.1 Example 1 (Krieg-Tictactoe)
rules Figure 1 describe standard Tic-Tac-Toe twist players
cannot see opponents moves, like chess variant Kriegspiel (Pritchard, 1994),
hence name.3
two roles initial position given lines 12 lines 47, respectively.
moves specified rules head legal (lines 914): player whose turn
attempt mark cell already tried earlier
game. player noop , move without eect.
position update specified rules head next (lines 1829):
submitted move mark (M, N ) player R valid (where valid means
targeted cell still blank; cf. line 16) every feature current position continues
hold, change overall state tried (R, M, N ) becomes true.4
Otherwise cell coordinates (M, N ) marked none cells
change. Moreover, control goes opponent.
clauses head sees (lines 3133) say player whose turn always
informed this. suces player perceive yourmove ,
follows must opponents turn.
!
2.1.2 Example 2 (Coloured Trails)
class games popular research test-bed decision-making negotiation
competitive setting (Grosz, Kraus, Talman, Stossel, & Havlin, 2004). specific game
comes one fixed protocols defining possible interactions among players.
3. word notation: paper largely concerned semantics behind GDL
game descriptions, interpreted logic programs. reason use standard
Prolog syntax GDL, variables indicated uppercase letters. contrast
customary KIF-notation GDL introduced Genesereth et al. (2005). KIF-syntax also
allows disjunctions clause bodies, easily transformed normal logic program
clauses (Lloyd, 1987). Throughout paper, use clause (game) rule interchangeably.
4. important note dierence legal valid moves Krieg-Tictactoe: attempt
mark cell considered legal, moves accepted valid actually possible
current position. Feature tried (R, M, N ) used prevent player resubmitting previously
rejected move.

176

fiRepresenting Reasoning General Games

1
2

role(xplayer).
role(oplayer).

3
4
5
6
7

init(control(xplayer)).
init(cell(1,1,b)).
init(cell(1,2,b)).
init(cell(2,1,b)).
init(cell(2,2,b)).
init(cell(3,1,b)).
init(cell(3,2,b)).

init(cell(1,3,b)).
init(cell(2,3,b)).
init(cell(3,3,b)).

8
9
10
11
12
13
14

legal(xplayer,mark(M,N)) :- true(control(xplayer)), true(cell(M,N,Z)),
distinct(Z,x), true(tried(xplayer,M,N)).
legal(oplayer,mark(M,N)) :- true(control(oplayer)), true(cell(M,N,Z)),
distinct(Z,o), true(tried(oplayer,M,N)).
legal(xplayer,noop)
:- true(control(oplayer)).
legal(oplayer,noop)
:- true(control(xplayer)).

15
16

validmove :- does(R,mark(M,N)), true(cell(M,N,b)).

17
18
19

next(F)
:- validmove, true(F).
next(tried(R,M,N)) :- validmove, does(R,mark(M,N)).

20
21
22
23
24
25
26
27
28
29

next(cell(M,N,x))
next(cell(M,N,o))
next(cell(M,N,Z))

:- validmove, does(xplayer,mark(M,N)).
:- validmove, does(oplayer,mark(M,N)).
:- validmove, true(cell(M,N,Z)),
does(R,mark(I,J)), distinct(M,I).
next(cell(M,N,Z))
:- validmove, true(cell(M,N,Z)),
does(R,mark(I,J)), distinct(N,J).
next(control(oplayer)) :- validmove, true(control(xplayer)).
next(control(xplayer)) :- validmove, true(control(oplayer)).
next(tried(R,M,N))
:- validmove, true(tried(R,M,N)).

30
31
32
33

sees(R,
yourmove) :- validmove, true(control(R)).
sees(xplayer,yourmove) :validmove, true(control(oplayer)).
sees(oplayer,yourmove) :validmove, true(control(xplayer)).

Figure 1: GDL-II description Krieg-Tictactoe. game positions encoded
using three features control (R), cell(M, N, Z), tried (R, M, N ),
R {xplayer , oplayer }; M, N {1, 2, 3}; Z {x, o, b}, b meaning
blank. sake simplicity, omitted (straightforward) specification terminating conditions goal values.

example, simple negotiation may consist player R oering player exchange
two chips, C D. formalised GDL-II clauses:
legal(R,propose(S,tradeChips(C,D))) :true(hasChip(R,C)), true(hasChip(S,D)), distinct(R,S).
sees(S,offer(R,C,D)) :- does(R,propose(S,tradeChips(C,D))).
rules communication private: addressee gets see oer. !
177

fiSchiffel & Thielscher

2.1.3 Example 3 (Monty Hall)
second running example, rules Figure 2 describe simple famous game
car prize hidden behind one three doors candidate given two
chances pick door. host modelled new pre-defined role random.5
Lines 17 introduce players names state features hold initially.
possible moves specified lines 917: First, random player decides place
car and, simultaneously, candidate chooses door. Next, host (i.e., random)
opens door one car behind one candidate
chosen. Finally, candidate either stick earlier choice (noop ) switch
door still closed.
candidates percept throughout game, viz. door gets opened,
defined rule head sees (line 19). remaining clauses specify position update (lines 2131), fact game ends candidates final decision
(line 33), payo candidate depending whether got door right
end (lines 3536).
!
2.1.4 Example 4 (Poker)
Together two new keywords used describe kinds card games,
typically characterised randomness (shuing) information asymmetry (individual hands). single card dealt face player, say, axiomatised thus:
legal(random,deal(P,C)) :- role(P), in_deck(C),
distinct(P,random).
next(in_hand(P,C))
:- does(random,deal(P,C)).
sees(P,your_card(C)) :- does(random,deal(P,C)).
Here, player dealt card see it. Multiple cards handed
single move takes card separate argument players
get see argument positions correspond cards. contrast, card dealt
face-up, Texas Holdem, would axiomatised follows.
legal(random,deal_river(C)) :- in_deck(C).
next(river(C))
:- does(random,deal_river(C)).
sees(P,river(C)) :- does(random,deal_river(C)), role(P).
Here, players informed river card.

!

example game descriptions illustrate two new features GDL-II: special
role random used model nature, always moves randomly. keyword sees
controls information players game state. Although players
full knowledge game rules including initial state, imperfect asymmetric
knowledge later states natural consequence players individual limited
percepts.
5. Although random pre-defined constant, needs declared role (line 2) goal
(line 37). way GDL-II supports upward compatibility original GDL.

178

fiRepresenting Reasoning General Games

1
2

role(candidate).
role(random).

3
4
5
6
7

init(closed(1)).
init(closed(2)).
init(closed(3)).
init(step(1)).

8
9
10
11
12

legal(random,hide_car(D)) :- true(step(1)), true(closed(D)).
legal(random,open_door(D)) :- true(step(2)), true(closed(D)),
true(car(D)), true(chosen(D)).
legal(random,noop)
:- true(step(3)).

13
14
15
16
17

legal(candidate,choose(D))
legal(candidate,noop)
legal(candidate,noop)
legal(candidate,switch)

::::-

true(step(1)), true(closed(D)).
true(step(2)).
true(step(3)).
true(step(3)).

18
19

sees(candidate,D) :- does(random,open_door(D)).

20
21
22
23
24
25
26

next(car(D))
next(car(D))
next(closed(D))
next(chosen(D))
next(chosen(D))
next(chosen(D))

::::::-

27

does(random,hide_car(D)).
true(car(D)).
true(closed(D)), does(random,open_door(D)).
does(candidate,choose(D)).
true(chosen(D)), does(candidate,switch).
does(candidate,switch),
true(closed(D)), true(chosen(D)).

28
29
30
31

next(step(2)) :- true(step(1)).
next(step(3)) :- true(step(2)).
next(step(4)) :- true(step(3)).

32
33

terminal :- true(step(4)).

34
35
36
37

goal(candidate,100) :- true(chosen(D)), true(car(D)).
goal(candidate, 0) :- true(chosen(D)), true(car(D)).
goal(random,
0).

Figure 2: GDL-II description Monty Hall game (Rosenhouse, 2009).
2.2 Formal Syntax
GDL-II based standard syntax logic programs, including negation.
Definition 1
Consider signature function symbols (including constants) variables.
term either variable, function symbol terms arguments.
atom predicate symbol terms arguments.
literal atom negation.
179

fiSchiffel & Thielscher

clause form h :- b1 , . . . , bn ., h (the head) atom
b1 , . . . , bn (the body) literals (n 0), meaning b1 , . . . , bn together
imply h.
GDL-II imposes following restrictions use pre-defined keywords Table 1.
Definition 2
dependency graph set G clauses directed, labeled graph whose nodes
+
q G
predicate symbols occur G positive edge p


contains clause p(s) :- . . . , q(t ), . . . ., negative edge p q G contains clause
p(s) :- . . . , q(t ), . . . . say p depends q G path p q
dependency graph G.
GDL-II game description finite set clauses
role appears facts (i.e., clauses empty body) body clauses;
init appears head clauses depend true,
legal, does, next, terminal, goal;
true appears body clauses;
appears body clauses, none legal, terminal, goal
depends does;
next sees appear head clauses;
distinct appears body clauses. 6
2.3 Valid Game Descriptions
order admit unambiguous interpretation game, GDL-II descriptions must obey
general syntactic restrictions, inherited predecessor GDL.
Definition 3
constitute valid GDL-II description, set clauses G must satisfy following.
1. G stratified, is, cycles involving negative edge dependency
graph G (Apt, Blair, & Walker, 1987; Gelder, 1989).
2. G allowed, is, variable clause occurs least one positive atom
body (Lloyd & Topor, 1986).
3. p q occur cycle dependency graph G contains clause
p(s) :- q1 (t1 ), . . . , q(v1 , . . . , vk ), . . . , qn (tn ).
every vi {v1 , . . . , vk },
vi ground,
6. formal meaning predicate given tacitly assuming unary clause distinct(s, t).,
every pair s, syntactically dierent, ground (i.e., variable-free) terms.

180

fiRepresenting Reasoning General Games

vi element s,

vi element tj (1 j n) qj appear cycle
p.
last condition imposes restriction combination function symbols recursion ensure finiteness decidability relevant derivations (Love et al., 2006).
reader invited verify example game descriptions Figure 1 2 satisfy
requirements valid GDL-II description. syntactic restrictions ensure set
game rules eectively unambiguously interpreted state transition system
formal game model, describe next.
2.4 Semantics
unique game model obtained valid GDL-II game description using concept
stable model logic program negation (Gelfond & Lifschitz, 1988).
Definition 4
set clauses G set ground atoms M, let GM set negation-free
implications h b1 . . . bk obtained taking ground instances clauses G
deleting clauses negative body literal bi bi M,
deleting negative body literals remaining clauses.
stable model G least model GM .
useful property stable models provide unique model whenever underlying
set clauses stratified (Gelfond & Lifschitz, 1988), requirement valid GDL-II
specifications according Definition 3. Moreover, syntactic restrictions GDL-II
ensure model finite logic programs considera property inherited
original GDL (Love et al., 2006). Hence, following game model GDL-II
assume finite set players, finite states, finitely many legal moves state.
shall denote SM [G] unique stable model stratified set clauses G.
Specifically, then, derivable instances keyword role(R) given game
description define players. initial state composed derivable instances
init(F). order determine legal moves given state, state
encoded first, using keyword true. Let, end, = {f1 , . . . , fn } state (i.e.,
finite set ground terms, a.k.a. fluents), game description G augmented
n facts
def
true = { true(f1 ).
...
true(fn ).}
instances legal(R,M) derivable G true define legal
moves player R position . way, clauses terminal
goal(R,V) define termination goal values relative encoding given
position.

Example 2 (continued)
rules Figure 1 entail Krieg-Tictactoe features two roles xplayer oplayer .
181

fiSchiffel & Thielscher

initial position 0 = {control (xplayer ), cell (1, 1, b), . . . , cell (3, 3, b)}. 0 true
added rules infer legal(xplayer , mark (M, N )) combination
coordinates M, N {1, 2, 3}, oplayer one move noop .
!
Determining position update percepts players requires encoding
current position move player. Suppose joint move
players r1 , . . . , rk take moves m1 , . . . , mk , let
def

= { does(r1 , m1 ).

...

does(rk , mk ). }

Taken together, instances next(F) derivable G true compose
updated position. Similarly, derivable instances keyword sees(R,P) describe
player perceives joint move played position .
Example 4 (continued)
According rules Figure 2, initial position Monty Hall game given
0 = {closed (1), closed (2), closed (3), step(1)}. three legal moves
player state, viz. hide car (D) random choose (D) candidate ,
{1, 2, 3}. Consider, say, 1 = {random ( hide car (1), candidate ( choose(3)},
0 true
added game rules, clauses keyword next determine
1
updated state 1 = {car (1), chosen (3), closed (1), closed (2), closed (3), step(2)}. According clause keyword sees candidate perceives nothing stage
hence cannot know car hidden behind door 1.
!
summarised following definition.
Definition 5
Let G valid GDL-II description. game semantics G state transition
system (R, 0 , T, l, u, I, g) given
roles R = {r : role(r) SM[G]};
initial position 0 = {f : init(f ) SM[G]};
terminal positions = { : terminal SM[G true ]};
legal moves l = {(r, m, ) : legal(r, m) SM[G true ]};
state update function u(, ) = {f : next(f ) SM[G true ]}, joint
moves states ;
information relation = {(r, , , p) : sees(r, p) SM[G true ]};
goal relation g = {(r, v, ) : goal(r, v) SM[G true ]}.
182

fiRepresenting Reasoning General Games

2.5 New Execution Model
additional elements GDL-II modified semantics require new execution
model games incomplete state information randomness: Starting initial
position, state player chooses legal move. special random role
assumed choose randomly uniform probability among legal moves.7 Given
joint move game state changes u(, ). contrast execution model
GDL (Genesereth et al., 2005; Love et al., 2006; Schiel & Thielscher, 2010), players
informed joint move; rather role r R \ {random} gets see
p satisfies I(r, , , p). game ends soon terminal state reached,
goal relation determines result players. modified execution model
spelled Figure 3. straightforwardly implemented Game Master,
runs game collecting moves, allows maintain actual game state
thus compute percepts also determine end match resulting
goal values players.
1. Send r R \ {random} GDL-II description inform
individual roles r (e.g., xplayer oplayer ). Set := 0 .
2. appropriate time, collect move mr player r R\{random}
and, case random R, choose uniform probability element random
set {m : (random, m, ) l}. Set := {r1 ( mr1 , . . . , rk ( mrk }.
3. Send r R \ {random} set percepts {p : (r, , , p) I}. Set :=
u(, ).
4. Repeat 2. 3. . Determine result v r R (r, v, ) g.
Figure 3: Game play GDL-II given game (R, 0 , T, l, u, I, g).
2.6 New Communication Protocol
changes execution model GDL GDL-II require modifications
communication protocol Game Master program general game players.
First all, Game Master inform players individual percepts
instead joint move previous step. practical purposes, Game Master
also confirm back individual move well current step game.
information useful players become aware communication problems (such
dropped messages timeouts) able recover problems least
cases. order make transition GDL GDL-II easier, keep
communication protocol defined Love et al. (2006) apply necessary
changes.
7. Note necessarily mean resulting states equal probability. example,
tossing unfair coin shows head probability 13 may axiomatised GDL-II three
legal moves random, two eect (the coin showing tails). stress basic
GDL-II could easily extended syntactic means specifying non-uniform transition probabilities.

183

fiSchiffel & Thielscher

communication Game Master players happens HTTP
messages, players take role HTTP servers serve moves
Game Master. body HTTP messages commands encoded using
Knowledge Interchange Format (KIF) (Genesereth, 1991). use messages START,
PLAY STOP follows.
(START <MATCHID> <ROLE> <DESCRIPTION> <STARTCLOCK> <PLAYCLOCK>)
first message sent player. contains unique identifier
match (<MATCHID>) informs player role game (<ROLE>),
game rules (<DESCRIPTION>) well time constraints start-up phase
(<STARTCLOCK>) submitting moves (<PLAYCLOCK>). Players supposed
reply message string READY within <STARTCLOCK> seconds.
message identical start message original GDL communication
protocol.
(PLAY <MATCHID> <TURN> <LASTMOVE> <PERCEPTS>)
message sent player step match. informs player
number moves far game (<TURN>), last move (<LASTMOVE>),
percepts (<PERCEPTS>) according information relation .

<TURN> 0 first play message increased one every subsequent step
game. first play message, previous move, <LASTMOVE>
NIL.
Players supposed reply within <PLAYCLOCK> seconds next move.
submit legal move time, Game Master make random
selection behalf. case <LASTMOVE> argument next message,
informs player move, vital knowledge able continue.

(STOP <MATCHID> <TURN> <LASTMOVE> <PERCEPTS>)
message sent player last step match, is,
terminal state reached. structure play message above.
Players reply message string DONE.
Note parameter <LASTMOVE> play stop messages necessary
want guarantee players always know move case dropped messages
timeouts. worth stressing information cannot provided game
rule like sees(R,lastmove(M)) :- does(R,M). clause redundant light
execution model GDL-II Figure 3, implies players always choose,
hence know, moves anyway.

3. Expressive Power GDL-II
Percepts GDL-II arbitrary terms triggered arbitrary conditions
current state joint move. provides greater flexibility standard definition
sensing action planning domain description languages, agent learns
truth values one fluents (Golden & Weld, 1996; Petrick & Bacchus,
184

fiRepresenting Reasoning General Games

2004). Observations GDL-II need related ones move, especially
appropriate multi-agent setting, often players see something side-eect
someone elses actions. point case rules 32 33 Figure 1. follows
spirit behind general eect axioms GDL, is, rules next, also may
independent specific move. simple example rules 2931 Figure 2.
GDL-II descriptions solely concerned providing players objective
description rules game. puts contrast also standard axiomatisations
action formalisms (Lakemeyer & Levesque, 1998; Thielscher, 2000; Scherl & Levesque,
2003; Forth & Shanahan, 2004), observations described terms
aect knowledge agent. game description language simpler regard
agnostic players use percept draw inferences, combine
already know, whether remember it.
conceptual simplicity describing observations GDL-II notwithstanding,
language extension gives rise intricate epistemic model player can,
principle, know position players knowledge. example,
GDL-II rules Krieg-Tictactoe shown Figure 1 imply one cell carry xplayer
mark first round oplayer unable determine one. Moreover,
provided perfect recall (Rasmusen, 2007) capable drawing right
conclusions, players know others knowledge lack knowledge,
respectively. following, analyse formally semantics GDL-II
description execution model Figure 3 entail knowledge player
perfect reasoning capabilities point game play.
3.1 Legal Play Sequences
begin defining set possible ways game develop.
Definition 6
Consider game (R, 0 , T, l, u, I, g). legal play sequence
1

2

n

0 1 . . . n1 n
n 0 {1, . . . , n},
joint move, i.e., mapping players r individual move, (r);
(r, (r), i1 ) l r R (that is, players make legal moves);
= u(i , i1 ) (position update).
Furthermore, {0 , . . . , n1 } = , is, last state may terminal.
following definition characterises precisely player perfect reasoning
capabilities principle know specific stage course game.
Definition 7


n
1
2
n


n two legal play
Let = 0 1 . . . n1 n = 0 1 1 2 . . . n1
sequences game roles R, initial state 0 , information relation . player
r R \ {random} cannot distinguish if, if, following holds
{1, . . . , n}.
185

fiSchiffel & Thielscher

, p ) I}
1. {p : (r, , i1 , p) I} = {p : (r, , i1

2. (r) = (r).
Example 2 (continued)
Let 1 initial state Krieg-Tictactoe, cells empty, consider
two legal play sequences:
= 0

{xplayer $mark (1,3),oplayer $noop}

= 0

{xplayer $mark (2,2),oplayer $noop}




1

{xplayer $noop,oplayer $mark (2,2)}



{xplayer $noop,oplayer $mark (2,2)}
1


2

(1)

2

(2)

Role xplayer distinguish already first round dierent
moves. contrast, oplayer finds two sequences indistinguishable step since
took move, noop , got percept {yourmove} rule 30 Figure 1.
Ultimately, however, oplayer also able distinguish (1) (2) because, according
game rules, second move perceives { } {yourmove} (where
attempted mark non-blank cell).
!
(In-)distinguishable play sequences used also ensure game descriptions
obey desirable properties following two, straightforward consequence
Definition 7.
1. game description roles R legality relation l entails players
always know legal moves r R \ {random} two legal
play sequences , leading states n , n
{m : (r, m, n ) l} = {m : (r, , n ) l}
, indistinguishable r.
2. game description roles R, terminal states , goal relation g entails
players know end game result
r R \ {random} two legal play sequences , leading states n , n

n T, n



{n , n } T, {v : (r, v, n ) g} = {v : (r, v , n ) g}

, indistinguishable r.
fair game always satisfy properties, proving new
game may dicult practice since general requires checking possible legal
play sequences. easy way around this, namely, adding sees-rules
always inform players explicitly legal moves, termination, goal values.
hand, games may especially designed test ability players
logically infer legal moves highly incomplete knowledge.
186

fiRepresenting Reasoning General Games

Example 4 (continued)
candidate axiomatisation Monty Hall game (cf. Figure 2) always
derive legal moves game ends. easily seen fact
determine value step fluent times. hand, candidate
never receives enough information able know result. example, cannot
distinguish two legal play sequences:
= 0

{candidate$choose door (1),random $hide car (1)}



{candidate$choose door (1),random $hide car (2)}

= 0




1

{candidate $noop,random $open door (3)}



{candidate $noop,random $open door (3)}
1


2
2

matter action candidate chooses end, result dierent
goal value .
!
Knowledge object level, considered thus far, lifted higher
levels determine players know others knowledge.
possible GDL-II description game provides complete rules players,
able derive information roles get see
(hypothetical) legal play sequence. Formalising requires constructing suitable
epistemic structure based possible play sequences. Consider, end, every
function K maps every pair (r, i) onto set legal play sequences player r
state cannot distinguish . Meta-level knowledge obtained follows.
Definition 8

game develops according , far player r knows, functions K
possible indistinguishable r.
Put words, meta-level knowledge characterised set possible sets legal play
sequences. follows player knows holds K-sets considers possible.
If, say, Krieg-Tictactoe match unfolds according example sequence
(cf. (2)) xplayer knows oplayer knows cell (2, 2) marked.
process iterated inductively determine arbitrary levels meta-knowledge,
shows common knowledge game rules necessarily mean common
knowledge players. example, possible obtain situation 3-player
game player knows property f player B knows knows
f , player C considers possible knows nothing f : let
make move learns f game B (but C ) always
informed moves.
conclude analysis (in-)distinguishable play sequences proving GDL-II
provides true extension GDL since game agents derive complete
state every round easily specified GDL-II.
Proposition 1 Consider game roles R random R
clause keyword sees
sees(R1,moves(R,M)) :- role(R1), does(R,M).
two legal play sequences , length n 0
indistinguishable r R.
187

fiSchiffel & Thielscher

Proof :
induction n. n = 0 one legal play sequence, viz.
initial game state 0 , establishes claim. induction step, suppose


two legal play sequences , leading states n+1 = n+1
indistinguishable role r R. Definition 7 follows , shortened
one step indistinguishable player. induction hypothesis,
possible identical step n. Hence, two legal play sequences
form
n+1
n
1
= 0 . . . n n+1
1

n

= 0 . . . n

n+1


n+1


Definition 5 follows state update deterministic, hence n+1 = n+1
implies

n+1 = n+1 . latter conjunction clause sees implies
percepts roles dier state n joint move n+1 taken instead n+1 .
contradicts assumption indistinguishable role r,
establishes claim.
!

3.2 GDL-II vs. Extensive Form
virtue state-transition semantics concept indistinguishable play sequences, every terminating GDL-II game understood so-called extensive-form
game. following, assume reader familiar basic notion
mathematical game tree imperfect information (Rasmusen, 2007; Leyton-Brown &
Shoham, 2008), based general concept information sets model
partial observability information asymmetry. sees(R,P) predicate GDL-II
used equally generally. main reason percepts confined specific
observables (e.g., state features opponents moves) arbitrary symbols used
identifiers desired information partition.
3.2.1 GDL-II Extensive-Form Games
given GDL-II game, corresponding extensive-form game obtained two
steps.
1. Using arbitrary fixed order roles, joint moves GDL-II serialised
way player aware simultaneous moves players (Rasmusen, 2007).
2. information sets player r identified set legal play sequences
player cannot distinguish.
example, Figure 4 depicts extensive-form game thus obtained Monty
Hall game description Figure 2.
important realise percepts GDL-II may sometimes provide information
contained state nonetheless needs taken account
partitioning nodes information sets. following example illustrates ability
solve game may depend information.
188

fiRepresenting Reasoning General Games
!


1 1 1
hide car(3)

3
3 3




hide car(2)


!
!
!



choose(1)

choose(3)
..
choose(3)
choose(1)


.






choose(2)
choose(2)
!
!
!
!
!
!



open(3)
open(2) open(3)
open(2)
open(3)
open(3)
open(1)
open(1)
1
1
1
1
2 !
2 !
!
! 2
!
! 2
!
!
..
..
..
..
..
..


.
.
.
.
.
.

switch
switch


noop
noop
!
!
!
!
hide car(1)

100

0

0

0

1

0

1

100

Figure 4: Monty Hall game Figure 2 mapped onto extensive form (with nodes
branches omitted). numbers right indicate player owns
nodes height (0 = random, 1 = candidate ). Dotted lines connect
nodes information set candidate.

3.2.2 Example 5 (Spy & Spy)
GDL-II Figure 5 describes game one spy sees three coloured
wires used arm bomb. signal name colour second spy,
tries disarm bomb. win second player cuts right wire lose
otherwise. Hence, first spy every incentive help second spy,
seems one obvious rational move, namely, signal colour wire.
crux, however, game rules, colour signalled logically
independent colour wire used arm bomb. illustrated
game tree Figure 6: second player distinguish possible states
round 2, is, {armed (red ), step(3)} , {armed (blue), step(3)} ,
{armed (green), step(3)}, would belong information set, matter
colour signalled. would leave players better choice
moving randomly.
!
3.2.3 Extensive-Form Games GDL-II
describe faithfully GDL-II (that is, move-by-move) game given extensive form,
two issues need addressed.
1. given information sets need encoded appropriate sees-rules
individual players. achieved indexing sets always letting
owner see index nothing else.
2. Non-uniform probabilities moves nature need mapped onto uniform probability distributions randoms moves. achieved introducing
189

fiSchiffel & Thielscher

1
2
3

role(spy1).
role(spy2).
role(random).

4
5
6
7

colour(red).
colour(blue).
colour(green).

8
9

init(step(1)).

10
11
12
13

legal(random,arm_bomb(C)) :- colour(C), true(step(1)).
legal(spy1,signal(C))
:- colour(C), true(step(2)).
legal(spy2,cut_wire(C))
:- colour(C), true(step(3)).

14
15
16
17

legal(random,noop) :- true(step(1))
legal(spy1,noop)
:- true(step(2))
legal(spy2,noop)
:- true(step(3))

18
19
20

sees(spy1,C) :- does(random,arm_bomb(C)).
sees(spy2,C) :- does(spy1,signal(C)).

21
22
23
24
25
26
27

next(armed(C))
next(armed(C))
next(explosion)
next(step(2))
next(step(3))
next(step(4))

::::::-

does(random,arm_bomb(C)).
true(armed(C)).
does(spy2,cut_wire(C)), true(armed(C)).
true(step(1)).
true(step(2)).
true(step(3)).

28
29

terminal :- true(step(4)).

30
31
32
33
34
35

goal(spy1,100) :- true(explosion).
goal(spy2,100) :- true(explosion).
goal(spy1, 0) :true(explosion).
goal(spy2, 0) :true(explosion).
goal(random,0).

Figure 5: GDL-II description cooperative Spy & Spy game.

proportional number moves dierent names lead successor state.
finite extensive-form game described GDL-II using single fluent
indicate node game specifying arc tree state
transition. Using methods Schulte Delgrande (2004), shown
resulting GDL-II description correct finite n-player game extensive form
perfect recall. size description resulting transformation obviously
order original game tree since moves parallelised states encoded
individual objects rather factored atomic features. Hence, unlike
Monty Hall rules Figure 2, say, direct construction exploit conciseness
descriptions made possible high-level knowledge representation language.
190

fiRepresenting Reasoning General Games
!


1 1 1
arm bomb(green)

3
3 3




arm bomb(blue)


!
!
!



signal(green)

signal(red)
..
signal(red)
signal(green)




.






signal(blue)
signal(blue)
!
!
!
!
!
!
arm bomb(red)

armed(red)
step(3)

armed(red)
step(3)

armed(red)
step(3)

armed(blue)
step(3)

armed(blue)
step(3)

armed(blue)
step(3)

Figure 6: game Figure 5 mapped onto extensive form (with nodes branches
omitted). Dotted lines connect nodes spy2 cannot distinguish. nodes
depth 3 identical states collapsed onto single node,
would information set player.

4. Logic Reasoning GDL-II Games
Building basic general game player, e.g. one knows move legally,
relatively simple task restriction perfect-information games. general
case, however, even basic game play much intricate problem. Recall, example,
description Krieg-Tictactoe game Figure 1. rules lines 3133 specify
players percepts, indicating player control next informed
fact. suces since players able always derive whether
turn. must capable inferring
perceive yourmove , must opponents turn. Another example
(strategically useful) inference would conclude cell must carry opponents
marker tried mark perceive yourmove again, implying
attempt must unsuccessful.
Drawing conclusions sort domain action theories, Situation Calculus oldest technique formalising automating reasoning actions (McCarthy, 1963). second part paper, lay foundations building
general game-playing systems capable reasoning imperfect information. Using existing techniques like Situation Calculus purpose requires full embedding
game description language GDL-II formalisms.
following, develop mapping based Situation Calculus variant
uses special fluent represent knowledge agents (Scherl & Levesque, 2003).
slightly modify extend formalism purposes. Generally speaking, Situation Calculus predicate logic pre-defined language
elements:
constant s0 , denotes initial situation, along constructor Do(A, S)
denote situation resulting action situation S;
predicate Holds(F, S), denotes fluent F (i.e., atomic state feature)
true situation S;
191

fiSchiffel & Thielscher

predicate Poss(A, S), denotes action possible situation S.
4.1 Compound Actions
games two players, positions updated consequence players
moving simultaneously. adequate formalisation Situation Calculus therefore
need identify concept action vector m1 , . . . , mk containing one move
player. given GDL-II description, domain moves implicitly determined
(second) arguments keywords legal does; e.g. mark (M, N )
noop Krieg-Tictactoe. Assuming arbitrary fixed order players, say
(xplayer , oplayer ), define simple axiom identifies individual move player r
action vector:
(3)
Act(ri , M1 , . . . , Mi , . . . , Mk ) = Mi .
instance, Act(xplayer , mark (1, 3), noop ) = mark (1, 3).
4.2 Derived Action Predicates
Given GDL-II game description G, identify primitive fluents terms occur
scope either keywords init(F), true(F), next(F); Figure 1
control (R), cell (M, N, Z), tried (R, M, N ). derived fluents take domainspecific predicates depend true G. Derived fluents (Davis,
1990) require successor state axioms truth-values fully
determined game rules values primitive fluents fixed (successor)
situation. keywords terminal goal(R,V) treated derived fluents too.
addition, mapping GDL-II Situation Calculus requires introduction
new concept derived action predicate. domain-specific predicates
depend true G. example validmove description
Krieg-Tictactoe (cf. line 16 Figure 1). Similar derived fluents, truth-value
derived action predicate fully determined game rules fixed
values primitive fluents situation (compound) action taken
situation.
4.3 Mapping
show GDL-II description G mappedin modular wayinto
Situation Calculus theory. First, atoms occur G rewritten follows.
replaced f (X,
S) derived action predicates
1. derived fluents f (X)
p(X,
A, S), indicating dependence situation action A,
p(X)
8
respectively.
2. init(F ) replaced Holds(F, s0 ).
3. true(F ) replaced Holds(F, S).
4. next(F ) replaced Holds(F, Do(A, S)).
8. mapping also applies derived fluents legal(R, ) , goal(R, V ) , terminal.

192

fiRepresenting Reasoning General Games

5. does(R, ) replaced Act(R, A) = .
example, clause line 16 Figure 1 becomes
validmove(A, S) Act(R, A) = mark (M, N ) Holds(cell(M, N, b), S) .
GDL-II game descriptions based negation-as-failure principle, is, every
proposition cannot derived game rules supposed false. reflect
Situation Calculus theory, use completion (Clark, 1978) clauses
replace clauses G p head
following way: every predicate p(X),

!
= body .

()X
(4)
p(X)
p(t ):-body G

,
variables occur
context use () abbreviation

either body X .
4.3.1 Initial Situation
transformation defined yields following axiomatisation initial situation:
!
Holds(F, s0 )
()F = body .
init(t):-body G

4.3.2 Preconditions
Based completion legal according (4), i.e.,
!
()R = r = body ,
Legal(R, M, S)
legal(r,m):-body G

define precondition axiom compound actions situations thus:
Poss(A, S) R. Legal(R, Act(R, A), S) .

(5)

4.3.3 Effects
result transformation above, obtain general successor state axiom (Reiter,
1991) follows:
!
()F = body .
(6)
Holds(F, Do(A, S))
next(t):-body G

4.3.4 Knowledge
Scherl Levesque (2003) use special fluent K(S , S)to read as: situation
accessible situation Sin order axiomatise knowledge states (of agent)
Situation Calculus. use straightforward generalisation multi-agent case,
K(R, , S) expresses player R considers possible situation S. allows
us formalise subjective knowledge similar Scherl Levesque thus:
Knows(R, , S) = . K(R, , S) [S ] .
def

193

(7)

fiSchiffel & Thielscher

Here, reified formula situation argument fluents suppressed;
[S ] means situation arguments reinstated . example,
Knows(xplayer , X, Y. cell (X, Y, b), s0 )
stands . K(xplayer , , s0 )X, Y. Holds(cell (X, Y, b), ). express knowledge
player another players knowledge, macro definition (7) easily extended
form nested expressions,
Knows(xplayer , Knows(oplayer , control (oplayer )), Do(mark (1, 1), noop , s0 )) .
also possible define common knowledge group players property
shared situations belonging reflexive transitive closure combined
accessibility relations.
GDL-II players complete knowledge initial situation. terms
Situation Calculus,
(8)
K(R, S, s0 ) = s0 .
eects actions percepts knowledge states players defined
successor state axiom special fluent K, adapt Scherl Levesques
definition follows:
K(R, , Do(A, S)) , . = Do(A , ) K(R, , S)
Poss(A , )Act(R, A) = Act(R, )
P. Sees(R, P, A, S) Sees(R, P, , ) .

(9)

Put words, player considers possible situation joint move if,
if, obtained situation conceivable S;
executable ; player move A; players sensing
result , identical sensing result actual A, (so cannot
distinguish two).
noted axioms (8) (9) postulate perfect recall common
knowledge game rules among players: actual situation Do(. . . , S0 )
situations consistent players previous information accessible.
Moreover, accessible situations form Do(. . . , S0 ) too, implies
every situation belonging reflexive transitive closure combined players
accessibility relations governed precondition eect rules described
axioms (5)(6).
4.4 Completion Semantics Stable Models
axiomatisation applies Clarks completion given set GDL-II game rules.
general, however, first-order semantics completion (stratified) logic program
weak fully characterise (unique) stable model presence redundant
rules like validmove :- validmove. stable model remains
superfluous clauses added, Clarks completion weakened them. example,
mentioned rule (assuming clauses) stable model empty
194

fiRepresenting Reasoning General Games

set, first-order semantics completion admits two modelsone
validmode holds one false.
issue resolved second-order axiom (Ferraris, Lee, & Lifschitz, 2011).
Denoted SM [F ], axiom provides stable model operator arbitrary first-order
formulas F . operator SM [F ] defined following way:
Definition 9
= (U1 , . . . , Un ) list distinct
Let P = (P1 , . . . , Pn ) list predicates U

= P denote conjunction
predicate variables length P . Furthermore, let U
(X)
Pi (X)
= 1, . . . , n . U
P denote
formulas X.U



< P stands
conjunction formulas X.Ui (X)Pi (X) = 1, . . . , n , U




(U P ) (U = P ) .
expression SM[F ; P ] stands second-order sentence
.(U
< P ) F (U
) ,
F U
) defined recursively:
F (U
Pi (t ) = Ui (t ) list terms;
F = F atomic formula F contain members P ;
(F G) = F G ;
(F G) = F G ;
(F G) = (F G ) (F G) ;
(F ) = (F ) ;
(F G) = (F G) (G F ) ;
) = X.F
;
(X.F
) = X.F
.
(X.F
Expression SM[F ] shorthand SM[F ; P ] P list predicates F .
models SM [F ] stable models F . Specifically, F completion
stratified logic program, SM [F ] unique Herbrand model corresponds
unique stable model logic program.
last step translation therefore add axiom SM [F ] , F
conjunction rules transformed game description.
noted Situation Calculus typically uses second-order induction
axiom limit set situations smallest set containing s0 closed
operator. However, dierent SM [F ], induction axiom sucient
enforce unique model presence redundant rules.
195

fiSchiffel & Thielscher

4.5 Soundness Completeness
theory obtained transformation developed previous section indeed
Situation Calculus theory, show now.
Proposition 2 Let G valid GDL-II game description axiomatisation
obtained transformation defined above. syntactically correct
Situation Calculus theory.
Proof :
Situation Calculus theory, must include precondition axiom

action a(X) form
S) (X,
S) .
Poss(a(X),
S) must refer situation S. general preconThe formula (X,
dition axiom (5), variable instantiated every compound action obtain
axiom form above. right-hand side (5) free variables
contains reference situation besides S.

Furthermore, must contain successor state axioms primitive fluent f (X)
following form:
Do(A, S)) (X,
A, S) .
Holds(f (X),
A, S) must refer situation S. general
Again, formula (X,
successor state axiom (6) variable F instantiated every primitive fluent
obtain axiom form above. right-hand side (6) refers bodies
rules head next(F ). According syntactic restrictions GDL-II bodies
may depend init next therefore indeed never refer situation
besides S.
!
show transformation previous section sound complete, is, GDL-II game description resulting Situation Calculus theory
equivalent terms knowledge inferred them. this, first
recall Definition 6 notion legal play sequence:
1

2

n

0 1 . . . n1 n .
Intuitively, sequence interpreted situation
Do(An , . . . , Do(A2 , Do(A1 , s0 )) . . .)
Situation Calculus, joint move = {(r1 , m1 ), . . . , (rk , mk )} corresponds
compound action Ai = m1 , . . . , mk . following theorem states given
state joint move, GDL-II game rules Situation Calculus theory entail
propositions.
Theorem 3 Let G valid GDL-II game description Situation Calculus
theory obtained G translation defined above. Furthermore, let
1
n
= 0 . . . n legal play sequence game corresponding situation
= Do(An , . . . , Do(A1 , s0 ) . . .); joint move legal n ; compound
action corresponding .
GDL-II description, let translation Situation
every predicate p(X)

A, S), examples given below.
Calculus denoted p (X,
196

fiRepresenting Reasoning General Games

truet (F, A, S) = Holds(F, S),
A, S) = p(X,
S) derived fluents,
pt (X,
A, S) = p(X,
A, S) derived action predicates.
pt (X,
GDL-II description, p(X)
SM [G ntrue ]
every predicate p(X)


|= p (X, A, S).
Proof :
theorem follows construction Situation Calculus theory
Section 4.3 result Ferraris et al. (2011) according unique stable model
stratified logic program equivalent Herbrand model SM [F ] F
conjunction completion program.
!
main proposition states indistinguishable legal play sequences player
correspond situations player considers mutually possible, vice versa.
implies players use Situation Calculus theory reason knowledge
past, present, future positions well knowledge players.
Proposition 4 Let G valid GDL-II description semantics (R, 0 , T, l, u, I, g)
Situation Calculus theory obtained G translation defined
above. Let two legal play sequences
1

n





= 0 . . . n ,
n
= 0 1 . . .
n

game corresponding situations = Do(An , . . . , Do(A1 , s0 ) . . .) =
Do(An , . . . , Do(A1 , s0 ) . . .). role r R cannot distinguish |= K(r, , S).
Proof :
prove proposition induction length n sequence .
base case n = 0 one legal play sequencethe initial state 0
corresponding initial situation s0 . Accordingly, (8), |= K(r, S, s0 ) = s0 ,
proves base case.
induction step, consider two legal play sequences
n+1

+ = n+1



n+1



+
= n+1

corresponding situations Do(An+1 , S) Do(An+1 , ), respectively.
indistinguishable r if, if,
show + , +
|= K(r, Do(An+1 , ), Do(An+1 , S)) .
successor state axiom special fluent K (cf. axiom (9)), know
K(r, Do(An+1 , ), Do(An+1 , S)) if, if, following hold.
(a) K(r, , S);
(b) Poss(An+1 , );
(c) Act(r, An+1 ) = Act(r, An+1 );
197

fiSchiffel & Thielscher

(d) P. Sees(r, P, An+1 , S) Sees(r, P, An+1 , ).
show one holds.
induction hypotheses, (a) holds.
definition legal play sequence (Definition 6) follows players
move n+1 legal state n , is, players r,
legal(r, n+1 (r)) SM [G ntrue ] .
Theorem 3 conclude holds exactly |= Legal(r, n+1 (r), )
players r. n+1 (r) = Act(r, An+1 ), equivalent right hand side
precondition axiom (5) hence equivalent Poss(An+1 , ). Thus (b) follows.
According Definition 7, provided indistinguishable role r, +
indistinguishable r if, if,
+
{p : (r, n+1 , n , p) I} = {p : (r, n+1 , n , p ) I}
n+1 (r) =

n+1 (r)

(10)
(11)

definition Act(r, A) (cf. (3)), Act(r, An+1 ) = n+1 (r) Act(r, An+1 ) =
n+1 (r) . Thus, equation (11) holds (c).
Definition 5, = {(r, , , p) : sees(r, p) SM [G true ]}. Thus,
(r, n+1 , n , p) if, if, sees(r, p) SM [G ntrue
n+1 ] . Theorem 3,
equivalent |= Sees(r, p, An+1 , S) . reasoning holds right hand
side (10). Thus, (10) holds case (d) holds.
proves (a) (d) consequences induction hypothesis. Hence,
,
K(r, Do(An+1 , ), Do(An+1 , S)) holds if, if, r cannot distinguish + +
concludes induction step proof.
!
4.6 Practical Considerations
completeness result requires second-order axiom SM [F ] translated game
description. practice, avoided confine finitely many
situations. syntactic restrictions GDL-II imply every ground atom depends
finitely many ground atoms; consequence restricted recursion
according Definition 3. mapping extends GDL rules situation arguments,
also finitely many ground instances considered Theorem 3
legal play sequences fixed hence situations depth-restricted. case
suces consider finite subset R(P, F ) grounding program P decide
whether ground atom F entailed P (Bonatti, 2001). Thus, consider finite
ground program replace second-order axiom propositional loop formulas (Lin &
Zhao, 2004) reconcile semantics GDL-II Situation Calculus theory.
solution applies whenever confine finitely many ground situations
reasoning problem hand.9
9. also remark issue actually little relevance practice General Game Playing;
e.g. none numerous games played past AAAI Competitions featured logically redundant
clauses players recognise.

198

fiRepresenting Reasoning General Games

Although points mind decidability reasoning issue, tractability
still is. possible construct game rules computing legal moves alone
expensive kind planning ahead reasonable amount time. practically
viable approach use sound incomplete proof methods (Haufe & Thielscher,
2012; Thielscher, 2013).

5. Related Work
new language GDL-II first extension existing GDL nondeterministic
games imperfect information. idea behind General Game Playing goes
back early work Pitrat (1968) and, later, Pell (1993). define formal languages
describe whole classes games, languages even less general basic
GDL perfect-information games. Earlier work also includes definition Gala
describing general games imperfect information (Koller & Pfeer, 1997).
main dierence GDL-II Gala tightly coupled programming language
(Prolog) therefore operationalrather declarativesemantics.
mentioned also GDL-II draws concepts used Action
Planning Languages (Lobo, Mendez, & Taylor, 2001) represent eects actions
presence incomplete knowledge. GDL-II seen generalising line work
multi-agent competitive settings.
keyword sees introduced Game Description Language allows
us describe players percepts side-eects moves. dierent traditional modelling reasoning actions observations direct eects sensing
actions (Scherl & Levesque, 2003; Thielscher, 2000; Lobo et al., 2001) especially
appropriate multi-player games agents may see something without acted,
e.g., observe players moves cards dealt.
translation GDL-II Situation Calculus first full embedding
GDL-II action formalism; recent mapping (Thielscher, 2011) Action Description Language C+ (Giunchiglia, Lee, Lifschitz, McCain, & Turner, 2004) restricted
basic GDL hence covers neither imperfect information games knowledge
sensing. expect translation provide basis mappings GDL-II
existing action languages, example, one developed Lobo et al. (2001).
opens road full range applicable methods systems exist reasoning
actions AI planning.
Situation Calculus previously shown viable formalism representing reasoning games Schulte Delgrande (2004), also use Situation
Calculus variant knowledge (Scherl & Levesque, 2003) axiomatise extensive-form
games. one hand, approach general deal
infinite games, assume perfect recall restricted uniform probabilities
natures moves. hand, restrictions make GDL-II compact
axiomatisation language focuses rules games rather reason
them. addition, GDL-II state update semantics, general preferred
usual regression semantics Situation Calculus performance reasons.
limitation Schulte Delgrandes axiomatisation restriction knowledge
fluent K(S , S) single agent (namely, player whose move situation S,
199

fiSchiffel & Thielscher

assuming players move simultaneously). allow reasoning
knowledge player situations, one agent
conclude another agent would know. remedied recent definition
multi-agent epistemic variant Situation Calculus axiomatising games (Belle &
Lakemeyer, 2010). Despite notable dierences GDL-II variant Situation
Calculus, e.g. restriction non-simultaneous moves augmentation domain
theory epistemic theory subjective knowledge, believe translation
similar one presented paper constructed full GDL-II
embedded suitably adapted version Belle Lakemeyers approach.
formalisms beside Situation Calculus reasoning knowledge
actions multi-agent environments, example, epistemic logic developed Belardinelli Lomuscio (2009). translation GDL-II formalism seems possible
might interesting model checkers logic available (Lomuscio, Qu,
& Raimondi, 2009).
Several General Game Playing systems exist able play games encoded
GDL-II (Schofield, Cerexhe, & Thielscher, 2012; Edelkamp, Federholzner, & Kissmann,
2012). Although systems reason game well, focus lies
solving specific reasoning tasks (such computing legal moves possible continuations
game) time constraints.

6. Conclusion
One reasons General Game Playing yet found many applications
outside game-playing area could, current state art restricted
deterministic games complete state information. Aiming overcoming limitation,
defined conceptually simple yet powerful extension Game Description
Language representing rules general games information asymmetry
random moves. shown GDL-II, notationally simple is, gives rise
intricate epistemic model thus suces provide players information need
reason knowledge well players front
game play.
argued language extension suces describe finite n-player
game extensive form perfect recall. shows purpose General
Game Playing language GDL-II considered complete; additional elements
serve obtain succinct descriptions (e.g., allowing explicit specifications
non-uniform probabilities moves random) needed concept
General Game Playing extended beyond current setting, e.g. open-world
games Scrabble (Sheppard, 2002) systems play real, physical games (Barbu,
Narayanaswamy, & Siskind, 2010).
second part paper, presented embedding extended game
description language suitable variant Situation Calculus features multiagent knowledge, simultaneous actions, action-independent sensing. GDL-II
game description defines observations players make throughout game
use information, Situation Calculus axiomatisation tells players
200

fiRepresenting Reasoning General Games

reason percepts entail current position,
possible moves, players may know.
central aspect work distinction objective information
one hand aects epistemic state agent hand. dierence manifests two key predicates paper: GDL-II keyword sees(R,P)
describes objective information Knows(R, , S) Situation Calculus axiomatises subjective knowledge. distinction also present two semantics given
paper: state transition systems model rules game environment Situation Calculus axiomatisations model information processing players. draws
connection work general distinction often made AI
functionality agents properties task environments (Russell & Norvig, 2010).
Seen perspective, GDL-II extends GDL enables us describe larger
class game environments rule-based language. Meanwhile, Situation Calculus axiomatisation viewed model game-playing agents whose functionality includes
perfect recall reasoning abilities. interesting direction future work develop
alternative Situation Calculus axiomatisations reasoning GDL-II games use
study types agents, e.g. memoryless purely reactive, well
aspects bounded rationality game-playing programs (Russell & Wefald, 1991).
Beyond General Game Playing therefore envision applications GDL-II AI
areas game models arise, automated trading agents (Thielscher & Zhang,
2010), Multiagent Planning (Larbi, Konieczny, & Marquis, 2007), Multiagent Systems
general. general description language games kind potentially useful
wherever need compact high-level yet machine-processable specifications
problem domains applications form games. Also potential using
available General Game Playing infrastructure systems developing testing
new games modelling, simulating, reasoning dynamic environments like,
example, economic systems. However, additions language, arithmetic,
might necessary allow concise descriptions domains. addition,
GDL-II General Game Playing infrastructure used tools teaching
AI development agent programs dynamic environments several university
courses.10

Acknowledgments
thank Joohyung Lee anonymous reviewers earlier version paper thoughtful constructive comments. research supported
Australian Research Councils (ARC) Discovery Projects funding scheme (project
number DP 120102023) Icelandic Centre Research (RANNIS, grant number 210019). second author recipient ARC Future Fellowship (project
number FT 0991348). also aliated University Western Sydney.

10. material available www.general-game-playing.de/teaching/teaching.html

201

fiSchiffel & Thielscher

References
Apt, K., Blair, H., & Walker, A. (1987). Towards theory declarative knowledge.
Minker, J. (Ed.), Foundations Deductive Databases Logic Programming, chap. 2,
pp. 89148. Morgan Kaufmann.
Barbu, A., Narayanaswamy, S., & Siskind, J. (2010). Learning physically-instantiated game
play visual observation. Proceedings IEEE International Conference
Robotics Automation (ICRA), pp. 18791886, Anchorage. IEEE Press.
Belardinelli, F., & Lomuscio, A. (2009). Quantified epistemic logics reasoning
knowledge multi-agent systems. Artificial Intelligence, 173 (910), 9821013.
Belle, V., & Lakemeyer, G. (2010). Reasoning imperfect information games
epistemic situation calculus. Fox, M., & Poole, D. (Eds.), Proceedings AAAI
Conference Artificial Intelligence, pp. 255260, Atlanta. AAAI Press.
Bonatti, P. (2001). Reasoning open logic programs. Eiter, T., Faber, W., &
Trusczynski, M. (Eds.), Proceedings International Conference Logic Programming Nonmonotonic Reasoning (LPNMR), Vol. 2173 LNCS, pp. 147159,
Vienna. Springer.
Clark, K. (1978). Negation failure. Gallaire, H., & Minker, J. (Eds.), Logic Data
Bases, pp. 293322. Plenum Press.
Clune, J. (2007). Heuristic evaluation functions general game playing. Proceedings
AAAI Conference Artificial Intelligence, pp. 11341139, Vancouver. AAAI
Press.
Davis, E. (1990). Representations Commonsense Knowledge. Morgan Kaufmann.
Edelkamp, S., Federholzner, T., & Kissmann, P. (2012). Searching partial belief states
general games incomplete information. Glimm, B., & Kruger, A. (Eds.),
Proceedings German Annual Conference Artificial Intelligence (KI), Vol.
7526 LNCS, pp. 2536, Saarbrucken, Germany. Springer.
Edelkamp, S., & Kissmann, P. (2008). Symbolic classification general two-player games.
Dengel, A., Berns, K., Breuel, T., Bomarius, F., & Roth-Berghofer, T. (Eds.),
Proceedings German Annual Conference Artificial Intelligence (KI), Vol.
5243 LNCS, pp. 185192, Kaiserslautern. Springer.
Ferraris, P., Lee, J., & Lifschitz, V. (2011). Stable models circumscription. Artificial
Intelligence, 175 (1), 236263.
Finnsson, H., & Bjornsson, Y. (2008). Simulation-based approach general game playing. Proceedings AAAI Conference Artificial Intelligence, pp. 259264,
Chicago. AAAI Press.
Forth, J., & Shanahan, M. (2004). Indirect conditional sensing event calculus.
de Mantras, R. L., & Saitta, L. (Eds.), Proceedings European Conference
Artificial Intelligence (ECAI), pp. 900904, Valencia, Spain. IOS Press.
Gelder, A. V. (1989). alternating fixpoint logic programs negation. Proceedings 8th Symposium Principles Database Systems, pp. 110. ACM
SIGACT-SIGMOD.
202

fiRepresenting Reasoning General Games

Gelfond, M., & Lifschitz, V. (1988). stable model semantics logic programming.
Kowalski, R., & Bowen, K. (Eds.), Proceedings International Joint Conference
Symposium Logic Programming (IJCSLP), pp. 10701080, Seattle. MIT Press.
Genesereth, M. (1991). Knowledge interchange format. Allen, J. F., Fikes, R., & Sandewall, E. (Eds.), Proceedings International Conference Principles Knowledge Representation Reasoning (KR), pp. 599600, Cambridge. Morgan Kaufmann.
Genesereth, M., Love, N., & Pell, B. (2005). General game playing: Overview AAAI
competition. AI Magazine, 26 (2), 6272.
Giunchiglia, E., Lee, J., Lifschitz, V., McCain, N., & Turner, H. (2004). Nonmonotonic
causal theories. Artificial Intelligence, 153 (12), 49104.
Golden, K., & Weld, D. (1996). Representing sensing actions: middle ground revisited.
Aiello, L. C., Doyle, J., & Shapiro, S. (Eds.), Proceedings International
Conference Principles Knowledge Representation Reasoning (KR), pp. 174
185, Cambridge, MA. Morgan Kaufmann.
Grosz, B., Kraus, S., Talman, S., Stossel, B., & Havlin, M. (2004). influence social
dependencies decision-making: Initial investigations new game. Proceedings International Conference Autonomous Agents Multiagent Systems
(AAMAS), pp. 782789, New York.
Harsanyi, J. (1967). Games incomplete information played Bayesian players,
IIII: Part I. basic model. Management Science, 14 (3), 159182.
Haufe, S., & Thielscher, M. (2012). Automated verification epistemic properties general game playing. Brewka, G., Eiter, T., & McIlraith, S. (Eds.), Proceedings
International Conference Principles Knowledge Representation Reasoning
(KR), pp. 339349, Rome. AAAI Press.
Jensen, R., & Veloso, M. (2000). OBDD-based universal planning synchronized agents
non-deterministic domains. Journal Artificial Intelligence Research, 13, 189226.
Kaiser, D. (2007). Automatic feature extraction autonomous general game playing
agents. Durfee, E., Yokoo, M., Huhns, M., & Shehory, O. (Eds.), Proceedings
International Conference Autonomous Agents Multiagent Systems (AAMAS),
Honolulu.
Kaiser, D. (2008). design implementation successful general game playing
agent. Wilson, D., & Sutclie, G. (Eds.), Proceedings International Florida
Artificial Intelligence Research Society Conference (FLAIRS), pp. 110115, Key West.
AAAI Press.
Kirci, M., Sturtevant, N., & Schaeer, J. (2011). GGP feature learning algorithm. KI
Kunstliche Intelligenz, 25, 3542. Springer.
Kissmann, P., & Edelkamp, S. (2011). Gamer, general game playing agent. KIKunstliche
Intelligenz, 25, 4952. Springer.
Koller, D., & Pfeer, A. (1997). Representations solutions game-theoretic problems.
Artificial Intelligence, 94 (1), 167215.
203

fiSchiffel & Thielscher

Kuhlmann, G., Dresner, K., & Stone, P. (2006). Automatic heuristic construction
complete general game player. Proceedings AAAI Conference Artificial
Intelligence, pp. 14571462, Boston. AAAI Press.
La Mura, P. (2000). Game networks. Proceedings Conference Uncertainty
Artificial Intelligence (UAI), pp. 335342, Stanford. Morgan Kaufmann.
Lakemeyer, G., & Levesque, H. (1998). AOL : logic acting, sensing, knowing,
knowing. Cohn, A. G., Schubert, L. K., & Shapiro, S. C. (Eds.), Proceedings
International Conference Principles Knowledge Representation Reasoning
(KR), pp. 316327, Trento. AAAI Press.
Larbi, R. B., Konieczny, S., & Marquis, P. (2007). Extending classical planning
multi-agent case: game-theoretic approach. Mellouli, K. (Ed.), Proceedings
European Conference Symbolic Quantitative Approaches Reasoning
Uncertainty (ECSQARU), Vol. 4724 LNCS, pp. 6375, Hammamet. Springer.
Leyton-Brown, K., & Shoham, Y. (2008). Essentials Game Theory. Synthesis Lectures
Artificial Intelligence Machine Learning. Morgan & Claypool.
Lin, F., & Zhao, Y. (2004). ASSAT: Computing answer sets logic program SAT
solvers. Artificial Intelligence, 157, 115137.
Lloyd, J. (1987). Foundations Logic Programming (second, extended edition). Series
Symbolic Computation. Springer.
Lloyd, J., & Topor, R. (1986). basis deductive database systems II. Journal Logic
Programming, 3 (1), 5567.
Lobo, J., Mendez, G., & Taylor, S. R. (2001). Knowledge action description language
. Theory Practice Logic Programming, 1 (2), 129184.

Lomuscio, A., Qu, H., & Raimondi, F. (2009). MCMAS: model checker verification multi-agent systems. Proceedings International Conference Computer Aided Verification (CAV), Vol. 5643 LNCS, pp. 682688, Grenoble, France.
Springer.
Love, N., Hinrichs, T., Haley, D., Schkufza, E., & Genesereth, M. (2006). General Game
Playing: Game Description Language Specification. Tech. rep. LG200601, Stanford
Logic Group, Computer Science Department, Stanford University, 353 Serra Mall,
Stanford, CA 94305. Available at: games.stanford.edu.
McCarthy, J. (1963). Situations Actions Causal Laws. Stanford Artificial Intelligence Project, Memo 2, Stanford University, CA.
Mehat, J., & Cazenave, T. (2011). parallel general game player. KIKunstliche Intelligenz, 25, 4347. Springer.
Pell, B. (1993). Strategy Generation Evaluation Meta-Game Playing. Ph.D. thesis,
Trinity College, University Cambridge.
Petrick, R., & Bacchus, F. (2004). Extending knowledge-based approach planning
incomplete information sensing. Dubois, D., Welty, C., & Williams, M.A. (Eds.), Proceedings International Conference Principles Knowledge
Representation Reasoning (KR), pp. 613622, Whistler. AAAI Press.
204

fiRepresenting Reasoning General Games

Pitrat, J. (1968). Realization general game playing program. Morrell, A. (Ed.),
Proceedings IFIP Congress, pp. 15701574, Edinburgh.
Pritchard, D. (1994). Encycolpedia Chess Variants. Godalming.
Rasmusen, E. (2007). Games Information: Introduction Game Theory (4th
edition). Blackwell Publishing.
Reiter, R. (1991). frame problem situation calculus: simple solution (sometimes) completeness result goal regression. Lifschitz, V. (Ed.), Artificial
Intelligence Mathematical Theory Computation, pp. 359380. Academic Press.
Rosenhouse, J. (2009). Monty Hall Problem. Oxford University Press.
Ruan, J., van der Hoek, W., & Wooldridge, M. (2009). Verification games game
description language. Journal Logic Computation, 19 (6), 11271156.
Russell, S., & Norvig, P. (2010). Artificial Intelligence: Modern Approach (3rd edition).
Prentice Hall.
Russell, S., & Wefald, E. (1991). Right Thing: Studies Limited Rationality. MIT
Press.
Scherl, R., & Levesque, H. (2003). Knowledge, action, frame problem. Artificial
Intelligence, 144 (1), 139.
Schiel, S. (2010). Symmetry detection general game playing. Proceedings
AAAI Conference Artificial Intelligence, pp. 980985, Atlanta. AAAI Press.
Schiel, S., & Thielscher, M. (2007). Fluxplayer: successful general game player. Proceedings AAAI Conference Artificial Intelligence, pp. 11911196, Vancouver.
AAAI Press.
Schiel, S., & Thielscher, M. (2009). Automated theorem proving general game playing.
Proceedings International Joint Conference Artificial Intelligence (IJCAI),
pp. 911916, Pasadena.
Schiel, S., & Thielscher, M. (2010). multiagent semantics Game Description
Language. Filipe, J., Fred, A., & Sharp, B. (Eds.), Agents Artificial Intelligence,
Vol. 67 Communications Computer Information Science, pp. 4455. Springer.
Schofield, M., Cerexhe, T., & Thielscher, M. (2012). HyperPlay: solution general
game playing imperfect information. Proceedings AAAI Conference
Artificial Intelligence, pp. 16061612, Toronto. AAAI Press.
Schulte, O., & Delgrande, J. (2004). Representing von Neumann-Morgenstern games
situation calculus. Annals Mathematics Artificial Intelligence, 42 (13),
73101.
Sheppard, B. (2002). World-championship-caliber Scrabble. Artificial Intelligence, 134 (1
2), 241275.
Thielscher, M. (2000). Representing knowledge robot. Cohn, A., Giunchiglia,
F., & Selman, B. (Eds.), Proceedings International Conference Principles
Knowledge Representation Reasoning (KR), pp. 109120, Breckenridge. Morgan
Kaufmann.
205

fiSchiffel & Thielscher

Thielscher, M. (2011). Translating general game descriptions action language.
Balduccinin, M., & Son, T. (Eds.), Logic Programming, Knowledge Representation,
Nonmonotonic Reasoning: Essays Honor Michael Gelfond, Vol. 6565
LNAI, pp. 300314. Springer.
Thielscher, M. (2013). Filtering logic programs application general game
playing. Proceedings AAAI Conference Artificial Intelligence, Bellevue.
AAAI Press.
Thielscher, M., & Voigt, S. (2010). temporal proof system general game playing.
Fox, M., & Poole, D. (Eds.), Proceedings AAAI Conference Artificial
Intelligence, pp. 10001005, Atlanta. AAAI Press.
Thielscher, M., & Zhang, D. (2010). general game descriptions market specification language general trading agents. David, E., Gerding, E., Sarne, D., &
Shehory, O. (Eds.), Agent-Mediated Electronic Commerce: Designing Trading Strategies Mechanisms Electronic Markets, Vol. 59 LNBIP, pp. 259274. Springer.

206

fiJournal Artificial Intelligence Research 49 (2014) 403-449

Submitted 10/13; published 03/14

Mechanisms Fair Allocation Problems:
No-Punishment Payment Rules Verifiable Settings
Gianluigi Greco

ggreco@mat.unical.it

Dipartimento di Matematica e Informatica
Universita della Calabria
I-87036 Rende, Italy

Francesco Scarcello

scarcello@dimes.unical.it

DIMES
Universita della Calabria
I-87036 Rende, Italy

Abstract
Mechanism design considered context fair allocations indivisible goods
monetary compensation, focusing problems agents declarations allocated goods verified payments performed. setting considered
verification might subject errors, payments awarded presumption innocence, incorrect declared values necessarily mean manipulation
attempts agents. Within setting, mechanism designed shown
truthful, efficient, budget-balanced. Moreover, agents utilities fairly determined
Shapley value suitable coalitional games, enjoy highly desirable properties
equal treatment equals, envy-freeness, stronger one called individual-optimality.
particular, latter property guarantees that, every agent, her/his utility
maximum possible one alternative optimal allocation.
computational complexity proposed mechanism also studied. turns
#P-complete that, deal applications many agents involved,
two polynomial-time randomized variants also proposed: one still truthful
efficient, approximately budget-balanced high probability, another
one truthful expectation, still budget-balanced efficient.

1. Introduction
Whenever outcome social choice process depends information collected
number self-interested agents, strategic issues may come play. Indeed, agents
may find convenient misreport types, i.e., relevant information
private knowledge, (global) best possible solution missed.
cases, mechanism design techniques used solution approaches, augment
combinatorial algorithms appropriate monetary payments, aimed motivating
agents truthfully report private types (see, e.g., Nisan, Roughgarden, Tardos, &
Vazirani, 2007; Shoham & Leyton-Brown, 2009).
class social choice utilitarian problems, agent types encode (monetary) valuations set solutions goal compute solution maximizing social
welfare, i.e., sum agents true evaluations. prominent role mechanism design
problems class played Vickrey-Clarke-Grove (VCG) paradigm (Vick-

c
2014
AI Access Foundation. rights reserved.

fiGreco & Scarcello

ery, 1961; Clarke, 1971; Groves, 1973), general method designing truthful
mechanisms, i.e., mechanisms truth-telling dominant strategy agent.
particular, VCG mechanisms efficient. is, guarantee solution maximizing social welfare actually computed. However, budget-balanced, i.e.,
algebraic sum monetary transfers always zero mechanisms class
run deficit. fact, well-known drawback VCG mechanisms (see, e.g.,
Archer & Tardos, 2007), essentially best one hope do, given classical
impossibility theorems (Green & Laffont, 1977; Hurwicz, 1975) stating truthful
mechanism designed always efficient budget-balanced.
many practical applications, however, payments agents performed
final outcome known, kind verification reported types might
possible. additional power considered classical mechanism-design setting
and, fact, whenever verification allowed, impossibility results might longer
hold. Mechanisms verification introduced Nisan Ronen (2001),
considered verification task scheduling problem: agents declaring
amount time need solve task, goal tasks solved,
minimizing completion time last-solved one (hence, make-span).
context, payments computed actual task release times observed,
have, instance, ability punish agent whose declared ability
verified different actual performance process.
Compared standard mechanisms (see, e.g., Nisan et al., 2007), verification
received considerably less attention literature (see, e.g., Nisan & Ronen, 2001;
Auletta, De Prisco, Penna, & Persiano, 2009; Penna & Ventre, 2012a; Krysta & Ventre,
2010; Ferrante, Parlato, Sorrentino, & Ventre, 2009; Penna & Ventre, 2012b; Auletta,
De Prisco, Penna, Persiano, & Ventre, 2006; Auletta, Penna, Persiano, & Ventre, 2011).
particular, works consider verification ability partial, sense agents
reporting restricted true types plus certain specific kinds deviations (e.g., values
lower true ones) verification focused detecting lies only.
extension model recently proposed Caragiannis, Elkind,
Szegedy, Yu (2012), assume a-priori restrictions agents reported types,
within setting agent cheating her/his type caught probability may depend her/his true type, reported type, both. fact, despite
different facets verification power, mechanisms verification proposed
literature share idea providing incentives truthfully report private types
exploiting intimidation punishing agents caught lying. Moreover,
budget limits considered approaches (see, e.g., Nisan & Ronen,
2001), mechanism verification designed budget-balanced,
focus truthfulness efficiency.
paper, consider instead budget-balanced mechanism based model
verification restriction possible declarations (hence, arbitrary
deviations possible), nevertheless punishment used verification
process. design constraint guided real-world applications clearly
emerges punishing approach would hardly acceptable agents, unless clear
proof deliberate malevolent behavior exhibited. Moreover, even case
punishment proportional amount discrepancy declared
404

fiMechanisms Fair Allocation Problems

verified values attributed malevolent behavior. resulting setting shares
spirit work Feige Tennenholtz (2011), observed possible
discrepancies agents declarations third-party verified values often
due different reasons, particular fact agents, malevolent,
might still unable accurately collect and/or report information valuations.
detail, Feige Tennenholtz (2011) considered scheduling problem single
machine agent reports length her/his job scheduler needs finish
many jobs possible given deadline. Differently earlier literature, assumed
agents uncertain job lengths, instance, limited
computational resources. Moving observation mechanisms verification
often designed way performs well agents accurate information
private features, might perform arbitrarily bad agents uncertain
information, Feige Tennenholtz proposed use forgiving mechanisms,
punishments used enforce truthfulness. mechanisms applied
two models uncertainty: One probabilistic nature, another (called
qualitative private input) quantitative model explaining extent
agents trust estimate, preference agent various lotteries
might even inconsistent probability distribution.
paper follow work Feige Tennenholtz (2011) particular
qualitative model uncertainty. Moreover, addition subjective perspective
problem, uncertainty inherent private inputs, also take account
dual (objective) perspective, discrepancies declared verified values
might due errors occur verification process. Indeed, verification
practically implemented sensing parameters become observable
mechanism performed, sensing clearly affected errors (it unrealistic assume
carried arbitrary precision).
fact, matter perspective (objective vs subjective) problem
discussed analyzed, intrinsic limit mechanisms verification clearly
emerged: Whenever agent misreports her/his type detected verifier,
punishing agent might effective mathematical studies, inappropriate
real life situations uncertainty inherent. Accordingly, therefore assume
limited use verification power given hand made. particular,
goal paper design mechanisms based punishments (while
nonetheless resulting truthful, efficient, budget-balanced) tolerant
measurement errors uncertain inputs, sense small errors determine
small deviations outcome would obtained errors all.
1.1 Mechanisms Fair Division Monetary Compensation
consider mechanisms verification context fair allocation problems (see,
e.g., Moulin, 2003; Young, 1994; Thomson, 2011). assume given set
indivisible goods allocated set agents. agent equipped private preference relation, encoded real-valued function (basically, monetary
valuation) possible goodsformal definitions Section 2. agent
allocated one good, case her/his evaluation additive them. More-

405

fiGreco & Scarcello

over, goods indivisible, i.e., good allocated one agent most. However,
monetary transfers allowed, terms payments charged agents monetary
compensations provided them. goal find efficient allocation, is, allocation maximizing total value allocated goods, designing rules guaranteeing
certain desirable properties achieved, truthfulness individual rationality, i.e., agent ever worse she/he would without participating
mechanism. Moreover, want obtain outcomes politically acceptable.
is, agents perceive designed mechanism fair one (see, e.g., Brandt, Conitzer,
& Endriss, 2012), independently rules leading honest. instance,
desirable agent envies allocation agent, selected
outcome Pareto efficient, i.e., must different allocation preferred
agents strictly preferred least one them.
model and, particular, properties fair allocations indivisible objects
monetary transfers studied, e.g., Svensson (1983), Bevia (1998), Maskin
(1987), Tadenuma Thomson (1993), Meertens, Potters, Reijnierse (2002), Tadenuma Thomson (1991), Alkan, Demange, Gale (1991), Willson (2003), Su (1999),
Yang (2001), Quinzii (1984), Sakai (2007). Moreover, procedures compute fair allocations proposed Aragones (1995), Klijn (2000), Haake, Raith, Su (2002),
Brams Kilgour (2001), Potthoff (2002), Abdulkadiroglu, Sonmez, Unver (2004).
None approaches listed above, however, guarantee elicitation honest
preferences agents. fact, question designing truthful fair mechanisms
recently considered well (Andersson & Svensson, 2008; Andersson, 2009; Svensson, 2009; Yengin, 2012; Ohseto, 2004; Porter, Shoham, & Tennenholtz, 2004; Shioura,
Sun, & Yang, 2006). approaches, budget limits sometimes enforced
mechanisms defined cannot run deficit, budget-balance never guaranteed.
Indeed, comes surprise, given truthful mechanism simultaneously fair (e.g., envy-free Pareto-efficient) budget-balanced (see, e.g., Tadenuma
& Thomson, 1995; Alcalde & Barbera, 1994; Andersson, Svensson, & Ehlers, 2010).
circumvent impossibility, approaches studied focus weaker
notions truthfulness. instance, Andersson et al. (2010) Pathak (2013) consider
notion degree manipulability used compare ease manipulation allocation mechanisms, whereas notion weak strategy-proofness considered
Lindner (2010), i.e., cheating agents always risking actual loss, never
guaranteed cheat successfully.
paper, depart settings studied earlier approaches,
interested applications form verification available mechanism
time deciding monetary compensations among agents. particular, assume
valuations well allocation scenarios determined objective properties
goods agents observed measured verifier, allocation
performed payments computed. Note information allocated
goods verified hence used mechanism. framework, classical
impossibility results longer hold. Indeed, propose mechanisms allocation problems
enjoy number highly desirable properties, particular truthful, efficient,
budget-balanced, individually rational, fair, even though agents verified incorrect
declarations punished. Observe kind a-posteriori knowledge
406

fiMechanisms Fair Allocation Problems

payment time quite common many applications. also point
cases thorough verification could also performed advance, order get best
performances independently agents declarations. However, practice done
either money time restrictions, convenient allocate goods
basis agents declarations (especially mechanism makes honest enough).
Anyway, results used even full information known mechanism,
provide fair division enjoying number desirable properties listed below.
Appendix reports number examples possible applications proposed
framework, including real-world case Italian research-assessment program,
first motivated work.
completeness, leave section recalling work, well
mentioned related literature, deals setting monetary transfers allowed.
fact, fair division indivisible goods without money transfers also attracted attention
literature. instance, topic studied Bouveret Lang (2008)
points view compact representation (for expressing preference relations)
computational complexity (of reasoning efficiency fairness concepts
resulting framework), Lipton, Markakis, Mossel, Saberi (2004) point
view defining approximation schemes envy-freeness. Finally, relevant point
that, paper papers discussed above, allocations assumed computed
centralized way. However, might relevant cases adopt decentralized
approaches, based successive negotiations goods (and money) groups
agents. reader interested distributed negotiation frameworks referred work
Sandholm (1998), Dunne, Wooldridge, Laurence (2005), Dunne (2005), Endriss,
Maudet, Sadri, Toni (2006), references therein.
1.2 Contributions
paper, study allocation problems strategic setting agents misreport
private types, study mechanisms verification algorithmic
computational complexity viewpoint.
1.2.1 Algorithmic Issues
show given setting none classical impossibility theorems discussed
holds. particular, exhibit payment rule p turns optimal allocation
algorithm, i.e., algorithm computing optimal allocation given reported types,
mechanism verification that:
mechanism truthful. shown pointing number properties
allocation problems interest own.
mechanism efficient, budget-balanced, individually rational, envy-free, Pareto
efficient.
payment rule indifferent w.r.t. values (possibly misreports) declared goods
occur allocation selected (and hence verified).

407

fiGreco & Scarcello

agent, her/his utility (when truthtelling) maximum one possible
allocations. particular, utility indifferent w.r.t. specific choice allocated
goods optimal allocations. Note strong fairness property, immediately entails envy-freeness Pareto-efficiency.
Verification used force truthfulness punishing agents whose reported values found different verified ones, mechanism forgiving sense recently discussed Feige Tennenholtz (2011). Moreover,
mechanism shown tolerant discrepancies emerging declared types
verified/true ones. is, properties hold equilibrium agents
report true types, also preserved approximatively case discrepancies,
guarantee within constant factor distance declared
types verified/true ones. Note generally possible mechanisms
based punishment approaches where, enforce truthfulness, punishment might
disproportional harm done misreporting (cf. Feige & Tennenholtz, 2011).
Agents utilities distributed according Shapley value two suitably-associated
coalitional gamessee, e.g., (Nisan et al., 2007), comprehensive introduction
sharing problems coalitional games. fact, Shapley value prototypical
solution concept fair division monetary compensations,1 desirable properties (games associated with) allocation problems extensively studied
literature (e.g., Moulin, 1992; Maniquet, 2003; Mishra & Rangarajan, 2007).
Note Shapely value studied mechanism-design contexts too,
emphasis given pricing problem service provider (Moulin & Shenker,
2001; Moulin, 1999; Jain & Vazirani, 2001): cost providing service function
sets customers, goal determining customers (and
price) receive it. model gives rise cross-monotonic cost-sharing
game, Shapley-value based sharing mechanisms defined truthful
budget-balanced, achieve lowest worst-case loss efficiency utility
profiles (Moulin & Shenker, 2001). respect, pricing rule p abstractly
viewed witness that, whenever (partial) verification possible, Shapley-valued based
mechanisms may also implemented loss efficiency all.
1.2.2 Complexity Issues
Computing optimal allocation basis reported types easy task,
carried via adaptations classical matching algorithms. However, one might
suspect computing payments computationally-efficient, based
computation Shapley value. indeed challenging task involves iterating
possible subsets agents. analyze issues, provide following
contributions:
show computing Shapley value allocation problems inherently intractable, fact, #P-complete. Note #P-hardness results problems involving
1. Depending application, solutions concepts different Shapley value might appropriate. instance, bankruptcy problems, nucleolus considered appropriate
solution concept fair distribution (Aumann & Maschler, 1985).

408

fiMechanisms Fair Allocation Problems

Shapley value computation proven literature, instance, weighted
voting games (Deng & Papadimitriou, 1994), minimum spanning-tree games (Nagamochi, Zeng, Kabutoya, & Ibaraki, 1997), games associated normative systems (Agotnes, van der Hoek, Tennenholtz, & Wooldridge, 2009). Moreover, #Phardness results established Banzhaf power index, solution
concept closely related Shapley value (see, e.g., Bachrach & Rosenschein, 2009,
2008; Bachrach, Zuckerman, Wooldridge, & Rosenschein, 2013).
Therefore, order deal also scenarios involving large number agents, two
modified rules, p p , presented, allow us employ fully polynomialtime randomized approximation scheme Shapley value computation. resulting polynomial-time mechanisms retain properties p . particular,
mechanism based p universally truthful, efficient, high-probability
approximately budget-balanced. Instead, mechanism based p truthful expectation, always efficient budget-balanced.
1.2.3 Organization
rest paper organized follows. Section 2 illustrates formal framework
basic concepts design mechanisms verification, whose desirable properties
illustrated Section 3. payment rule p defined Section 4, connections
coalitional games pointed Section 5. Rules p p defined Section 6,
computational issues dealt with. comparison related works reported
Section 7, concluding remarks discussed Section 8. Finally, Appendix
illustrates real-world case study application examples notions presented
paper.

2. Formal Framework
section, define formal framework studying allocation problems based
mechanism design tools. particular, focus mechanisms equipped verification
ability meets no-punishment perspective.
2.1 Allocation Scenarios
focus allocation problems goods set G allocated set
agents = {1, ..., n} way overall value allocated goods maximum
feasible allocations, is, social welfare maximized. precisely,
allocation function : 2G mapping agent non-empty set
goods (i) G (i) (j) = , j 6= i. Moreover, given vector
upper-bound constraints = (1 , ..., n ) specifies maximum number goods
assigned agent A. tuple = hA, G, called allocation
scenario. mapping : 2G feasible allocation scenario
allocation goods G agents that, agent A, |(i)| holds.
Observe required goods G allocated agents.
Note applications maximum number goods assigned
agent represents ability (e.g., maximum number tasks she/he
409

fiGreco & Scarcello

execute), hence next represent function = fu (i ), objective
property agent (e.g., her/his speed) fu public-knowledge computable function.
Note setting general earlier approaches literature
upper bounds fixed independent agents features.
Moreover, paper assume value good g agent determined
objective property g good, well property agent.
Formally, assume good valuations encoded valuation vector w = (w1 , ..., wn )
where, A, valuation function assigns good g G real value
wi (g) = fv (g , ), public-knowledge computable function fv .2
idea verifier, best described next section, able measure,
allocation goods agents performed, objective property g
every allocated good g objective property every agent. Therefore,
using (public) function fv , possible compute values goods
assigned agent. believe assumption valuations
functions objective properties goods agents holds many applications
allocation problems, particular social welfare maximized
(since typically measurable value). provide examples Appendix A,
including real-world application evaluation research activities Italy,
originally motivated present work.
Let us fix allocation scenario = hA,
PG, valuation vector w = (w1 , ..., wn ).
Let allocation. Define
wi () =
g(i) wi (g), A, denote
P
val(, w) overall value iA wi (). say optimal (for S) w.r.t. w
feasible allocation feasible allocation 0 val( 0 , w) >
val(, w). value optimal allocation w.r.t. w denoted opt(S, w).
allocation algorithm function mapping allocation scenario
vector w feasible allocation A(S, w) S. algorithm optimal A(S, w)
optimal allocation w.r.t. w, given pair (S, w).
2.2 Strategic Issues Verification
consider classical setting mechanism design optimal allocations
computed context neither agent-depending upper bounds valuation
vector w known allocation algorithm. Therefore, even optimal algorithm
hand, enough information find optimal allocation, general.
fact, assume usual agent privately knows certain features,
called type, determining maximum number goods allocated
her/him, well function wi encoding her/his preferences allocations. Note
that, setting, type agent naturally consists her/his characterizing property
plus property g , good g (s)he interested in. Section 3.2, also consider
happens agent may subjective, possibly incorrect, perception
properties (including her/his characterizing property ).
2. Note that, sake simplicity, use two functions fu fv agents. However, nothing
changes paper consider slightly general version different agents may
different public functions.

410

fiMechanisms Fair Allocation Problems

Figure 1: Running example Section 2.
assume type agent taken set available types,
denote cartesian product 1 n possible agents types. Then,
consider direct revelation mechanisms agents asked report types let
mechanism compute allocation. so, agents self-interested, strategic
issues come play.
agent A, hereinafter assume ti always denotes true type
agent i, i.e., type owned private knowledge, di her/his declared
type. Then, = (t1 , ..., tn ) = (d1 , ..., dn ) vectors true declared types,
respectively. general, happen coincide t, agents find
convenient misreport types.
(true declared) type vector = (1 , ..., n ) , denote hereinafter
= hA, G, allocation scenario , is, scenario vector
= (1 , ..., n ) that, A, upper bound determined
type . Similarly, denote w = (w1 , ..., wn ) valuation vector wi
valuation function determined type , A.
Example 2.1. Let us consider two agents, a1 a2 , type vector = (t1 , t2 ),
allocation scenario St = hA, G, illustrated Figure 1(I) means intuitive
graphical notation, = {a1 , a2 }, G = {g1 , ..., g8 }, = (3, 3). Moreover, consider
valuation vector w wt = (wa1 , wa2 ) that, edge connecting
a1 (resp., a2 ) gj Figure 1(I), wa1 (gj ) (resp., wa2 (gj )) value associated
it. Otherwise, i.e., edge connecting a1 (resp., a2 ) gj , wa1 (gj )
(resp., wa2 (gj )) negative number, say 1. Given setting, easily seen
optimal allocation St w.r.t. wt allocation (a1 ) = {g1 , g2 , g4 }
(a2 ) = {g5 , g7 , g8 }see Figure 1(II). Note wa1 ( ) = 25 wa2 ( ) = 26.
Consider allocation Figure 1(III). Note another optimal allocation. However, wa1 ( ) = 26 > wa1 ( ) wa2 ( ) = 25 < wa2 ( ).


411

fiGreco & Scarcello

Figure 2: Strategic manipulation.
Example 2.2. Consider setting Example 2.1, type vector private
knowledge agents. Moreover, assume vector declared types
Sd = St (the allocation scenario correct one) vector wd one
illustrated Figure 2(I), negative edges omitted. Basically, agent a2 truthfully
reports her/his type, agent a1 reports type values goods g2
g3 underestimated. Therefore, wd 6= wt holds. optimal allocation
Sd w.r.t. wd shown Figure 2(II). emerges that, declarations agent
a1 , convenient include g2 g3 . fact, coincides optimal
allocation depicted Figure 1(III). Hence, misreporting type, agent a1
guarantee overall value goods assigned her/him 26. Instead,
truthfully reporting type, a1 might risk allocation selected,
overall value goods assigned her/him 25.
Finally, consider slight variant problem instance actual value good
g7 6 (instead 8) a2 . Then, egoistic behavior agent a1 also leads
allocation longer optimal. Indeed, due low declared values g2 g3 ,
good g7 selected allocated a2 unique (wrong) optimal allocation, whose
total value 49 (instead 51).

paper, focus allocation problems kind verification reported types possible, objective properties agents goods observed
measured (we say verified, hereinafter) third-party verifier allocation
performed. Recall
Sin general subset goods actually assigned agent
. Denote set iA (i) G allocated goods img(). Thus, model,
good g img(), objective property g verified, nothing said
non-allocated hence non-observed goods. Moreover, agent participating mechanism, property determines upper-bound constraint
preferences good allocations verifiable, too. Thus, using verifier,
correct allocation scenario restriction img() valuation functions
determined, formalized next.
Definition 2.3. Let vector true types. Then, verifier v (for t) function
mapping allocation pair Sv() , wv() that:
(1) Sv() actual allocation scenario St (in particular, true upper bound fu (i )
computed verifier agent i);
(2) wv() = (wv1 , ..., wvn ) vector that, agent A, wvi : img() R
function assigning good g img() actual value fv (g , ) agent
412

fiMechanisms Fair Allocation Problems

i. Observe that, definition framework, wvi coincides restriction
img() valuation function wti : G R determined (true) type ti .
2
worthwhile noting verifier general unable discover whether
agent misreported her/his type, goods allocated undergo
measurement process. pinpoint actually case practical applications,
measurements non-allocated goods may technically unfeasible simply
expensive (in money time). refer reader Appendix A.1 (in particular, subsections A.1.1A.1.3) exemplification notions real-world case study
Italian research evaluation (VQR).
Example 2.4. Consider setting Example 2.2, recall agent a1 finds
convenient underestimate true values g2 g3 . However, since g2 g3
selected , see Figure 2(II), way discover a1
actually misreported her/his type.

cases, constraints allocation scenario depend specific
application agents types, item (1) immaterial. generally,
however, proposed setting allows us model classes problems types play
role even definitions upper-bound constraints.
completeness, remark results paper easily shown hold
even allocation problems every agent must get minimum number goods
greater one (defined specific application). However, sake presentation
prefer keep standard setting non-empty set goods assigned
agent, long her/his upper bound constraint met.
2.3 Payment Rules Mechanisms Verification
order encourage agents truthfully report private types, design mechanisms
monetary transfers performed, verification process.
sake presentation, let us assume St = hA, G, allocation scenario
(recall denotes vector true types), vector declared types
associated allocation scenario Sd = hA, G, i, v verifier (for t).
payment rule p defined vector functions (p1 , ..., pn ), pi (, wd , v)
amount money given agent i, basis given allocation ,
vector declared valuations wd , verifier v. Observe that, notation,
negative value pi (, wd , v) means amount money charged i. Let wt
vector (w1 , ..., wn ). Then, (quasi-linear) utility p, sometimes called individual
welfare, defined value ui,p (, wd , v) = wi () + pi (, wd , v). verifier v
always understood, ui,p (, wd , v) pi (, wd , v) simply denoted ui,p (, wd )
pi (, wd ), respectively. Moreover, whenever payment rule also understood
context, utility simply denoted ui (, wd ).
payments computed verification process, define amount
money pi (, wd ) paid agent i, exploit verifier v. Accordingly, desirable
goods allocated, hence verified, play role definition
payments. latter property formalized below.

413

fiGreco & Scarcello

verifiability: Let d0 d00 two type vectors, let wd0 = (w10 , ..., wn0 ) wd00 =
(w100 , ..., wn00 ) associated valuations. Moreover, let mapping
feasible allocation scenarios Sd0 Sd00 . Then, A, pi (, wd0 ) =
pi (, wd00 ) whenever wi0 (g) = wi00 (g) holds every allocated good g img(). Therefore,
d0 d00 undistinguishable far computation payments concerned,
even differ unallocated goods. is, payment rule depends
goods subject verifier evaluation.
mechanism verification pair (A, p), allocation algorithm
p payment rule exploit verifier v. mechanism (A, p) viewed
consisting following two-phases: First, agents report declaration vector d,
feasible allocation = A(wd ) Sd computed. Second, v() made available,
payments given rule p calculated respect allocation
valuations wd , exploiting knowledge v(). goal design payment rule p
guaranteeing declared types lead allocation maximizing social welfare,
i.e., optimal allocation St w.r.t. wt . might problematic as,
setting, even fact feasible allocation St guaranteed,
allocation scenario depends types agents might St 6= Sd .
order accomplish goal, use optimal allocation algorithm A,
need p encourages agents truthfully report private types. Formally,
type vector = (1 , ..., n ) type , A, let (i , )
type vector (1 , ..., i1 , , i+1 , ..., n ) . Then, shall consider following concept
truthful mechanism.
Definition 2.5. Let (A, p) mechanism verification, let agent A.
say dominant strategy agent w.r.t. (A, p) if, type vector ,
ui (A(w(i ,i ) ), w(i ,i ) ) ui (A(w ), w ) holds. mechanism (A, p) truthful if,
A, ti dominant strategy.
2
Example 2.6. Consider setting discussed Example 2.2, trivial payment
rule p payment actually performed. Consider optimal allocation
(for St w.r.t. wt ) depicted Figure 1(II), note ua1 ( , wt ) = 25. Instead,
allocation depicted Figure 2(II), ua1 ( , wt ) = 26, unique
optimal allocation Sd = St w.r.t. wd , = (da1 , ta1 ).
Therefore, mechanism (A, p ), optimal allocation algorithm
A(wt ) = , truthful. generally, optimal allocation algorithm A,
example witnessing (A, p ) truthful easily defined suitably adapting
above. Hence, non-trivial payment rules necessary encourage agents truthfully
report types.

comparison approach verification existing ones reported Section 7.

3. Properties (Truthful) Mechanisms
section, discuss desiderata mechanisms lead fair allocations
tolerant uncertain inputs. Note design mechanisms able
deal two issues interest even settings strategic, i.e., even
414

fiMechanisms Fair Allocation Problems

granted agents truthfully report types. Exemplifications
proposed notions reported Appendix A.1.4, completes description case
study regarding Italian research evaluation (VQR). examples described
Appendix A.2 Appendix A.3.
3.1 Fairness Issues Desirable Properties
Let (A, p) truthful mechanism verification. paper, focus number
(ex-post) properties mechanism, checked equilibrium agents
truthfully report private types.
(allocative) efficiency: A(wt ) optimal allocation St w.r.t. wt . is, social
welfare maximized.
individual rationality: ui (A(w(ti ,i ) ), w(ti ,i ) ) 0, agent
type vector agents \ {i}. Hence, voluntary participation agent
take part allocation problem encouraged (independently whether
agents actually report true types not).
P
(strong) budget-balance: iA pi (A(wt ), wt ) = 0. words, transfer
money scenario.
envy-freeness: pair agents i, j A, feasible allocation St
(i) A(wt )(j) 6= , ui (A(wt ), wt ) ui (, wt ).
Pareto-efficiency: feasible allocation St that: (1) ui (, wt )
ui (A(wt ), wt ), agent A, (2) agent j uj (, wt ) >
uj (A(wt ), wt ). is, A(wt ) Pareto-dominated allocation.
equal treatment equals: pair agents i, j = j wi = wj ,
wt = (w1 , ..., wn ), must case ui (A(wt ), wt ) = uj (A(wt ), wt ).
individual optimality: ui (A(wt ), wt ) ui (, wt ), feasible allocation St .
Note properties make sense even settings strategic,
goal compute fair allocation. Indeed, setting strategic,
agents report true types, even without monetary incentive. However, without
payments, fairness cannot achieved general: think, instance, scenario
two agents, a1 a2 , one good g value agents.
case, matter optimal allocation considered (where g assigned either a1
a2 ), one two agents would envy other. makes clear payment rules
play role encourage agents reports true types, also
crucial induce agents perceive given allocation fair one. fact,
properties, last, classically considered context fair allocation
problems, also absence strategic issues.
Here, additionally considered individual optimality, readily seen
imply envy-freeness Pareto-efficiency. also entails unique possible
415

fiGreco & Scarcello

vector utilities agents. particular, means agents utilities sensible
possible alternative allocations, hence independent specific set allocated
goods selected optimal algorithm A.
Example 3.1. Consider trivial payment rule p discussed Example 2.6. Consider
optimal allocation depicted Figure 1(II), compare allocation
Figure 1(III). Recall another optimal allocation (for St w.r.t. wt ). Moreover,
p , ua1 ( , wt ) = 25 ua1 ( , wt ) = 26 hold. Therefore, optimization perspective choice immaterial, a1 might good arguments
complain selected place . fact, p individually optimal.

Individual optimality definitely desirable requirement, still miss something. Indeed, notice property trivially satisfied fully uniform payment
rule, guarantees agent gets utility, matter her/his valuation
goods. course, desirable general. Rather, meritocracy somehow
addressed, true fair rule reflect actual contribution agent
overall value allocation.
Let allocation St , necessarily optimal one w.r.t. wt , define
marginal contribution non-empty set C agents w.r.t. wt value:
marg,wt (C) = opt(hA, img(), i, wt ) opt(hA \ C, img(), i, wt ).

(1)

words, marginal contribution marg,wt (C) agents C assesses loss
overall value would register agents C part problem.
Example 3.2. Consider setting Example 2.1 optimal allocation Figure 1(II). Note marg ,wt ({a1 }) = marg ,wt ({a2 }) = 51 26 = 25. Therefore, two
agents (viewed singletons) marginal contribution, defining payment
rule leads utilities equally sharing overall value 51 natural option.
Consider different setting, true types induce allocation scenario
St vector wt , valuation good g8 agent a2 ,
110 instead 10. case, would still remain optimal allocation, overall
value 151. Moreover, marginal contribution a1 affected modification,
marginal contribution a2 would become 151 26 = 125. witnesses a2
contributes a1 , payment rule leading equally sharing overall value
longer perceived fair one.

intuition conveyed example formalized via following
requirement.
P
marginality: non-empty set C agents,
iC ui (A(wt ), wt )
margA(wt ),wt (C). Hence, group agents gets least marginal contribution
given allocation.
3.2 Sensing Errors
conclude presentation (strategic) setting fair allocation problems illustrating subtle issues arising process verification. starting point
416

fiMechanisms Fair Allocation Problems

discussion observation verifiers practically implemented sensing
parameters (in setting parameters , agent i, g , allocated
good g) become observable allocation performed that, real-world
applications, sensing subject errors; instance, limited precision
measurement instruments. Therefore, unrealistic assume verifier
always able exactly discover (i.e., arbitrary precision) actual upper bounds
scenario St valuation vector wt , might problematic decide whether
observed discrepancy verified values declared ones due strategic
behavior sensing errors. fact, sensing troubles arise even settings
relevant information available public knowledge acquired via sensing
environment, i.e., even getting rid strategic consideration.
discussed Introduction, issue pointed recent work
Feige Tennenholtz (2011), though slightly different perspective. There, observed mechanisms verification often designed way performs well
agents accurate information private inputs, might perform arbitrarily
bad agents uncertain private features. Uncertainty might
result hardware measurement errors, due limited computational resources
employed agents identifying declared valuations. instance, setting,
type agent consists her/his characterizing property plus property g ,
good g (s)he interested in. According perspective Feige Tennenholtz
(2011), agent might estimate type. instance, agent might
enough computational resources precisely determine properties g
goods g, type actually represent subjective perception them.
light observations, clearly emerges punishing agents might
effective mathematical studies, inappropriate real life situations
uncertainty inherent due measurements errors uncertain inputs. Therefore, addition requirements discussed far, another desirable property mechanism
use punishment (or forgiving, sense Feige & Tennenholtz, 2011).
punishment: type vector , feasible allocation ,
agent A, case pi (, w ) = pi (, w(ti ,i ) ). is, discrepancies
given type (possibly declared) true/verified one
impact payment agent i. words, may think payments
always computed presumption innocence, incorrect declared values
mean manipulation attempts agents.
Moreover, admit sensing errors (or uncertain inputs) might occur,
relevant quantitatively assess impact, too. Ideally, would like deal
mechanisms tolerate errors, sense small errors determine
small deviations outcome would obtained errors all. Note
generally possible mechanisms based punishment approaches where,
enforce truthfulness, punishment might disproportional harm done
misreporting (cf. Feige & Tennenholtz, 2011). next formalize final desideratum.
type vector , set C agents, set G0 G goods,
let us define hC, G0 , restriction scenario hA, G, agents C
417

fiGreco & Scarcello

goods G0 considered.3 Moreover, given two type vectors , denote
[, ] set type vectors form (X1 , ..., Xn ), Xi {i , },
A. Then, distance dist w (, ) valuation vector w
(or dist(, ), w understood context) defined looking worst
possible impact type vectors [, ] may optimal solutions computed
possible restrictions given setting:
dist w (, ) =

max

CA, G0 G, 0 , 00 [,]

|opt(hC, G0 , 0 i, w0 ) opt(hC, G0 , 00 i, w00 )|.

Now, recall truthful mechanism always convenient agents report
true types. Assume however agents declare type vector different
true type vector t.4 consequence, get revealed setting St valuation vector
wt = (w1 , ..., wn ), available verifier v discloses information scenario St
vector wt = (w1 , ..., wn ) (restricted allocated goods). standard mechanisms
design settings (and particular punishment approaches), guarantee
property could given case, mechanisms designed analyzed
reports truthful. Instead, would like mechanisms tolerant sensing
errors, formalized below.
error tolerance: constant c 0 that, type vector
agent A, |ui (A(wt ), wt ) ui (A(wt ), wt )| c dist(t, t).
Intuitively, error tolerant mechanism, consequences errors good
allocation outcomes produce linear distorting effect agents utilities (and, turn
various properties mechanism). particular, property stated
without assumption sensing errors come play. Indeed, notion
dist(t, t) formalizes errors global perspective. instance, require
errors affect uniformly valuations agents, might well case
errors biased towards specific agent.

4. Mechanisms Verification Allocation Problems
section, introduce mechanism verification allocation problems start
analysis, preliminary proving properties hold optimal allocations.
4.1 General Properties Allocation Problems
Let given type vector, consider allocation scenario = hA, G, i,
= (1 , ..., n ), together valuations given w = (w1 , ..., wn ). start
3. Note little abuse notation: vector hC, G0 , fact restriction C. However,
keep notation simple, write , confusion may arise. Similarly, valuation vector
w transparently considered valuation vector subset agents C Awe
get rid unused components associated agents \ C.
4. property discussed perspective uncertain inputs. adaptation case
verification errors (or case types errors occur) easy task, mainly
matter different interpretation concepts.

418

fiMechanisms Fair Allocation Problems

Figure 3: One-good version allocation problem Example 4.1, two allocations
associated update graph, defined proof Theorem 4.4.
graphical representation, crossing lines represent edges bipartite cliques
connecting two groups virtual agents goods interested in.

observing optimization problem used allocate goods agents equivalently reformulated way precisely one good allocated agent.
Intuitively, may replace agent fresh agents valuations i.
remark equivalence used combinatorial optimization purposes,
i.e., without affecting game theoretic issue.
Let us formalize intuition. First, denote S1 one-good version
hA1 , G, 1i scenario , where:

A1 set agents iA clones(i) agent A, clones(i)
set fresh agents;
1 vector components 1.
Moreover, denote w1 vector agents A1 where, agent c A1 ,
component wc1 associated c wc1 = wi , agent
c clones(i) holds. Thus, allocation problem S1 considering
vector w1 , clone c clones(i) gets exactly one good, valuations
agent w .
Example 4.1. Consider scenario St = hA, {g1 , ..., g8 }, i, = {a1 , a2 },
vector wt = (wa1 , wa2 ) discussed Example 2.1. one-good version scenario
St1 = hA1 , {g1 , ..., g8 }, 1i shown Figure 3(I). Note set agents scenario
A1 = {(a1 )1 , (a1 )2 , (a1 )3 , (a2 )1 , (a2 )2 , (a2 )3 }, clones(ai ) = {(ai )1 , (ai )2 , (ai )3 },
1
{1, 2}. Indeed, recall = (3, 3). Finally, vector wt1 w(a
=
1 )h
1

wa1 (resp., w(a2 )h = wa2 ), h {1, 2, 3}.
419

fiGreco & Scarcello

Now, consider scenario hC, G0 , i, i.e., restriction hA, G, agents
C goods G0 considered, let C1 allocation
one-good version
0
0
1
G
hC, G , . Consider function C : C 2 C (i) = cclones(i) C1 (c),
A. Note |C (i)| , A. Therefore, C feasible allocation
hC, G0 , i, denoted -good(C1 ). Moreover, construction, val(C , w ) = val(C1 , w1 ).
Conversely, feasible allocation C hC, G0 , associated non-empty set
one-good(C ) allocations C1 hC, G0 , i1 C = -good(C1 ), also
called one-good forms C . following immediate definition one-good
version forms.
Fact 4.2. Let given type vector, let S1 one-good version , let
C1 allocation S1 . Then, C1 optimal allocation S1 w.r.t. w1 if,
if, -good(C1 ) optimal allocation w.r.t. w .
Example 4.3. Consider setting Example 4.1, allocation
(a1 ) = {g1 , g2 , g3 } (a2 ) = {g5 , g7 , g8 }. Note optimal allocation
w.r.t. valuation vector wt (reported Figure 1(I)), val(, wt ) = 50
opt(St , wt ) = 51 (see, e.g., optimal allocation Figure 1(II)). Now, notice
allocation depicted Figure 3(II) indeed associated one-good form allocation,
actually optimal allocation St1 w.r.t. wt1 , Fact 4.2.

position stating property holds optimal allocation .
property fact interest own, i.e., independently application
study fair allocation problems. words, tells us that, whenever interested
allocating goods subset agents, may safely consider goods img(),
rather whole set G. case, basic technical ingredient showing
number key properties because, intuitively, allows us get rid alternative (optimal)
allocations, possibly based non-allocated goods G \ img().
Theorem 4.4. Let given type vector, let optimal allocation
hA, G, w.r.t. w , let C set agents. Then, every optimal allocation
hC, img(), w.r.t. w optimal allocation hC, G, w.r.t. w .
Proof. Let C set agents, assume C optimal allocation
hC, img(), w.r.t. w . shall show C optimal allocation unrestricted
problem hC, G, w.r.t. w , too.
end, consider optimal allocation C problem hC, G,
goods G available agents C. next prove val(C , w ) = val(C , w ).
clearly follows optimality C img(C ) img() holds. Therefore,
strictly better C , C must allocate good G \ img(). Assume thus
contradiction val(C , w ) < val(C , w ), hence img(C ) 6 img(), entails
img() G. Consider two allocations C1 one-good(C ) 1C one-good(C ),
observe first that: val(C1 , w1 ) = val(C , w ) < val(C , w ) = val(1C , w1 ).
Let L set agents whose good-assignment according
allocations, i.e., L = {c C 1 | 1C (c) = C1 (c)}. Then, define (C1 , 1C ) = (C 1 \ L {s, t}, E)
directed graph, called update graph C1 w.r.t. 1C , whose nodes agents
C 1 change goods two allocations plus two distinguished nodes t,
whose edges E defined follows:
420

fiMechanisms Fair Allocation Problems

edge agent c agent c0 1C (c0 ) = C1 (c) 6= ;
edge agent c0 agent c 1C (c0 ) = C1 (c) 6= ;
edge agent c agent c0 1C (c0 ) = C1 (c) 6= ;
edges E.
example construction, consider Figure 3(IV) showing update graph allocation shown Figure 3(II) w.r.t. allocation shown Figure 3(III).
agent gets one good C1 1C , node (C1 , 1C ) exactly
one incoming edge one outgoing edge. Moreover, construction, incoming
edge, outgoing edge. Thus, update graph consists number paths
number cycles, disjoint other.
Let {1 , ..., h } set possible paths cycles (C1 , 1C ),
path cycle = 1 , ..., , let agents(i ) set {1 , ..., } \ {s, t}.
addition, let us fix following notation: function : X 2G given
domain X, let [X 0 ] denote restriction (sub-)domain X 0 X. Moreover,
: X2 2G2 two domains X1 X2 ,
given two functions 1 : X1 2G1 2 U
respectively,
= , let 1 2 : X1 X2 2G1 G2 function
U X1 X2 U
(1 2 )[X1 ] = 1 (1 2 )[X2 ] = 2 .
construction update graph, note 1C expressed terms
disjoint paths/cycles 1 , ..., h following expression:
C1 [C 1 \

h
[

agents(i )]

h
]

1C [agents(i )].

i=1

i=1

Observe that, val(C1 , w1 ) < val(1C , w1 ), must exists set agents
agents(k ), associated disjoint path/cycle k , 1 k h, value
goods allocated agents according 1C greater corresponding
value theUsame agents obtained C1 . Then, consider function k = C1 [C 1 \
agents(k )] 1C [agents(k )], note first k allocation hC, G, i1 .
particular, note that, agent c C 1 , |k (c)| = 1 holds,
U constraint
actually holds C1 1C , definition operator . Moreover,
choice k , also val(k , w1 ) > val(C1 , w1 ).
Note k either cycle path form s, 2 , . . . , m1 ,
1C (2 ) img(), img(k ) img() would hold. Indeed, definition edges
update graph, first node path (that is, 2 case k path) may
1C (2 ) \ img() 6= . However, observed above, impossible
val(k , w1 ) > val(C1 , w1 ) would contradict optimality C1 , hence optimality
C , Fact 4.2. Therefore, conclude k path form s, 2 , . . . , m1 ,
k (2 ) = 1C (2 ) = {g 0 } G \ img(). is, allocation k (over agents
C 1 ) img(k ) = {g 0 } img(C1 ) \ C1 (m1 ). particular, observe
C1 (m1 ) img() \ img(k ) holds, definition edges update graph
since edge m1 t.
Let us come back optimal allocation hA, G, w.r.t. w , let 1
(optimal) allocation one-good(). Let C 1 set agents 2
421

fiGreco & Scarcello

Input:
Assumption:
Notation:
1.
2.
3.
4.
5.
6.
7.
8.

type vector , feasible allocation ;
verifier v (for t) available, v() = (v1 , ..., vn );
= hA, G, i, w = (w1 , ..., wn ), wv() = (wv1 , ..., wvn );

Let C denote set possible subsets A;
C C,
b Compute optimal allocation C,i hC, img(), (vi ,i ) w.r.t. w(vi ,i ) ;
agent A,
| set C C P
C,
1
(=val(C,i , w(vi ,i ) ));
| | Let C,i (, ) := wvi (C,i ) + jC\{i} wj (C,i );
P
(=val(C\{i},i , w(vi ,i ) ));
| b Let 2C,i (, ) := jC\{i} wj (C\{i},i );
P
(1C,i (, ) 2C,i (, ));
| Let (, w ) := CC (|A||C|)!(|C|1)!
|A|!

9. b

Define pi (, w ) := (, w ) wvi ();

Figure 4: Payment rule p .


goods cA 1 (c) allocated agents according 1 equal
set
0
00
00
00
cA k (c)\{g }G , G img()\img(k ) |G | 1. Note set
property fact exists: start {2 } add agents agents(k )
c found 1 (c) img()
U 1 \1img(k ).
Consider = k [A] [A \ A] note well-defined,
construction set guarantees good allocated according k [A]
allocated 1 agents A1 \ A, vice-versa. Moreover, feasible allocation
hA, G, i1 . Indeed, agent c A1 , |(c)| = 1 holds, constraint actually
holds k 1 . Eventually, since 1 optimal allocation hA, G, i1 w.r.t. w1 ,
val( 1 , w1 ) val(, w1 ) holds. Thus, construction , get val( 1 [A], w1 )
val([A], w1 ) = val(k [A], w1 ). U
Finally, let C0 = k [C 1 \ A] 1 [A] note C0 feasible allocation
hC, G, i1 , arguments used show feasible allocation.
Moreover, observe val(C0 , w1 ) val(k , w1 ) > val(C1 , w1 ) img(C0 ) img().
latter, recall 2 agent C 1 k (2 )\img() 6= .
Again, entails C1 optimal w.r.t. w1 hence, Fact 4.2, C also
optimal hC, img(), w.r.t. w . Contradiction.
result immediately entails following two corollaries.
Corollary 4.5. optimal allocation hA, G, w.r.t. w set
C agents, opt(hC, img(), i, w ) = opt(hC, G, i, w ).
Corollary 4.6. Let optimal allocation hA, G, w.r.t. w , let 0
feasible allocation hA, G, i, hence val(, w ) val( 0 , w ). Then, set
C agents, opt(hC, img(), i, w ) opt(hC, img( 0 ), i, w ).

422

fiMechanisms Fair Allocation Problems

4.2 Design Truthful Mechanism
Consider payment rule p defined Figure 4: given type vector ,
feasible allocation selects goods img() G agents
A. Moreover, use verifier v (for vector true types t) that, given , able
compute actual scenario Sv() valuation vector wv() = (wv1 , ..., wvn )
allocated goods img(). Note that, sake presentation, section
convenient look output verifier list equivalent types v() = (v1 , ..., vn )
vi , agent i, upper bound constraint goods valuation
img() computed verifier v. Then, usual, (vi , ) denotes
type vector obtained replacing type verified type vi . particular,
w(vi ,i ) denotes valuation vector (defined img()) function wvi used
place valuation function declared .
first three steps, payment rule associates optimal allocation C,i
hC, img(), (vi ,i ) w.r.t. w(vi ,i ) set C C agents agent A,
C powerset A, i.e., set possible subsets agents. Then,
agent A, rule computes value (, w ) step 8, means formula
depends valuations associated allocations C,i C\{i},i , C C.
particular, defines two terms (1C,i (, ) 2C,i (, )), evaluate allocations
C,i C\{i},i , respectively, w.r.t. valuation vector w(vi ,i ) . Actually, term
2C,i (, ), valuation immaterial C\{i},i allocation C \ {i}. Finally,
payment pi (, w) defined step 9 difference (, w ) wvi ().
Note payment rule depends values goods img(),
verifiable, according definition provided Section 2.3. Moreover note that,
far paying agent concerned, rule depends values given wvi
allocated goods, i.e., values returned verifier, rather wi . Thus,
declaration immaterial far computation payment concerned,
next fact easily follows.
Fact 4.7 (no punishment). type vector , feasible allocation
, agent A, case pi (, w ) = pi (, w(ti ,i ) ).
Moreover, note idea underlying definition p that, verification
performed, utility function precisely coincide bonus (, w ), hence
sharing spirit5 approach Nisan Ronen (2001).
Lemma 4.8. type vector feasible allocation ,
case ui (, w ) = (, w ).
exploiting characterization, show first crucial result payment rule p , i.e., mechanism (A, p ) truthful, provided arbitrary
optimal allocation algorithm.
get high-level intuition proof observe (, w ) depends two
groups terms, 2C,i (, ) basically independent given agent i. Thus,
5. say spirit, peculiar form (, w ) formally fit framework considered
Nisan Ronen (2001).

423

fiGreco & Scarcello

goal agent maximize terms form 1C,i (, ) defined step 6
valuations optimal allocations computed (in step 3) considering verified type,
focusing goods img() (so verified values coincide true ones),
considering subsets whole set agents. salient machinery provided
Corollary 4.5, according always convenient agent report
true type. Indeed, optimal allocation computed via based true type
agent i, Corollary 4.5 guarantees 1C,i (, ) get maximum possible
value possible allocations scenarios obtained considering subsets agents,
i.e., independently allocation actually selected. done without
strategically interacting agents. Therefore, designing payment rule
way depends values returned verifier, end
verifiable rule using punishment, also obtain truthful mechanism based it.
Theorem 4.9 (truthfulness). Let optimal allocation algorithm. Then, mechanism verification (A, p ) truthful.
Proof. show that, agent reported type vector d,
following holds: ui (A(w(ti ,di ) ), w(ti ,di ) ) ui (A(wd ), wd ); hence, Lemma 4.8,
(A(w(ti ,di ) ), w(ti ,di ) ) (A(wd ), wd ).
Consider construction reported Figure 4 two cases = =
(ti , di ), let = A(wd ) 0 = A(w(ti ,di ) ) corresponding optimal allocations
(for scenarios Sd S(ti ,di ) , respectively) received input payment rule
0 )
Figure 4. set C C agents, agent A, let C,i (resp., C,i
allocation computed step 3. Note step well defined,
optimal allocation always exists. Indeed, note exist feasible allocations
scenario , e.g., allocation : C 2img() (j) = {g} good
g (j). is, allocation trivially satisfies every upper-bound constraint, since
assigns one good agent.
show following two properties hold, C C A:
(A) 1C,i ( 0 , (ti , di )) 1C,i (, d),
(B) 2C,i ( 0 , (ti , di )) = 2C,i (, d).
order prove (A), observe step 6, 1C,i ( 0 , (ti , di )) = val(C,i , w(vi ,di ) ) =
0
val(C,i , w(ti ,di ) ), last equality holds C,i
img( 0 ), true
0
optimal allocation
valuation disclosed verifier. Then, observe C,i
0
0
hC, img( ), (vi ,di ) = hC, img( ), (ti ,di ) w.r.t. w(vi ,di ) and, hence, w.r.t. w(ti ,di ) ,
0 = A(w(ti ,di ) ) optimal allocation S(ti ,di ) = hA, G, (ti ,di ) w.r.t. w(ti ,di ) .
Thus, Corollary 4.5, get following expression:
0
1C,i ( 0 , (ti , di )) = val(C,i
, w(ti ,di ) ) = opt(hC, G, (ti ,di ) i, w(ti ,di ) ).

(2)

Similarly, 1C,i (, d) = val(C,i , w(vi ,di ) ) = val(C,i , w(ti ,di ) ) holds. Thus,
use Equation 2, order get 1C,i ( 0 , (ti , di )) = opt(hC, G, (ti ,di ) i, w(ti ,di ) )
val(C,i , w(ti ,di ) ). shows (A) holds.

424

fiMechanisms Fair Allocation Problems

0
Let us focus (B). step 7, 2C,i ( 0 , (ti , di )) = val(C\{i},i
, w(vi ,di ) )
2
0
whereas C,i (, d) = val(C\{i},i , w(vi ,di ) ). Recall C\{i},i (resp., C\{i},i ) optimal allocation hC \{i}, img(), (vi ,di ) (resp., hC \{i}, img( 0 ), (vi ,di ) i) w.r.t. w(vi ,di ) .
Then, fact evaluation immaterial here, C\{i},i (resp.,
0
C\{i},i
) optimal allocation hC \ {i}, img(), (resp., hC \ {i}, img( 0 ), (ti ,di ) i)
w.r.t. wd (resp., w(ti ,di ) ). Then, recall (resp., 0 ) optimal allocation
Sd (resp., S(ti ,di ) ) w.r.t. wd (resp., w(ti ,di ) ). Thus, Corollary 4.5, 2C,i ( 0 , (ti , di )) =
opt(hC \ {i}, G, (ti ,di ) i, w(ti ,di ) ). Moreover, get:

2C,i (, d) = opt(hC \ {i}, G, i, wd ).

(3)

Eventually, 2C,i ( 0 , (ti , di )) = opt(hC \ {i}, G, (ti ,di ) i, w(ti ,di ) ) = opt(hC \
{i}, G, i, wd ) holds, valuation immaterial, get (B) Equation 3.
4.3 Properties Truthful Strategies
Let us analyze relevant properties hold whenever agents choose dominant strategy truthfully reporting private types. first property useful
characterization agents utilities.
Theorem 4.10. optimal allocation St = hA, G, w.r.t. wt ,
agent A, holds that:
ui (, wt ) =


X (|A| |C|)!(|C| 1)!
opt(hC, G, i, wt ) opt(hC \ {i}, G, i, wt ) .
|A|!

CC

Proof. Lemma 4.8, know ui (, wt ) = (, wt ). Then, set C C
agents, agent A, consider expressions 1C,i (, t) 2C,i (, t) defined
step 6 step 7, respectively, mechanism Figure 4. Note that,
properties verifier v stated Definition 2.3 fact payment rule consider goods allocated via , 1C,i (, t) = val(C,i , w(vi ,ti ) ) = val(C,i , wt )
2C,i (, t) = val(C,i , w(vi ,ti ) ) = val(C\{i},i , wt ) hold, C,i C\{i},i optimal
allocations hC, img(), w.r.t. wt hC \ {i}, img(), w.r.t. wt , respectively.
Thus, 1C,i (, t) = opt(hC, img(), i, wt ) 2C,i (, t) = opt(hC \ {i}, img(), i, wt ).
follows that:
ui (, wt ) =

X (|A| |C|)!(|C| 1)!
(opt(hC, img(), i, wt ) opt(hC \ {i}, img(), i, wt )) .
|A|!

CC

(4)

Recall Corollary 4.5 that, optimal allocation hA, G, w.r.t. wt
set C C agents, opt(hC, img(), i, wt ) = opt(hC, G, i, wt ). Therefore,
1C,i (, t) = opt(hC, G, i, wt ) 2C,i (, t) = opt(hC \ {i}, G, i, wt ). using
equalities, result follows Equation 4.
agents utilities completely independent particular optimal allocation ,
every agent gets precisely utility every optimal allocation.
425

fiGreco & Scarcello

Corollary 4.11. Let 0 two optimal allocations St w.r.t. wt . Then, ui (, wt ) =
ui ( 0 , wt ) holds, A.
Example 4.12. Consider scenario = hA, G, i, = {a1 , a2 } G =
{g1 , ..., g8 }, valuation vector wt = (wa1 , wa2 ) discussed Example 2.1, allocation illustrated Figure 1(I)). Then, have:
ua1 ( , wt ) =

1
2 (opt(h{a1 , a2 }, G, i, wt ) opt(h{a2 }, G, i, wt ))+
1
2 (opt(h{a1 }, G, i, wt ) opt(h{}, G, i, wt ))+
1
2 (opt(h{a2 }, G, i, wt ) opt(h{a2 }, G, i, wt ) =
1
1
1
51
2 (51 26) + 2 (26 0) + 2 (26 26) = 2 .

instance, note opt(h{a1 }, G, i, wt )) = 26, allocate g1 , g4 , g5
a1 , (s)he agent scenario.
Similarly, get ua2 ( , wt ) = 51
2 . is, two agents share precisely half
total value, based payment scheme. fact, looking allocation
Figure 1(II), one might navely suppose a2 contributed a1 overall
value associated . However, due specific allocation considered,
actual values goods two agents. Indeed, fairness utility
values resulting payment rule suddenly appears considering existence
alternative allocation Figure 1(II), symmetric w.r.t.
seems a1 contributed a2 overall value: matter fact, two
agents completely interchangeable optimal allocations, correctly reflected
payment scheme (without need actually looking ). particular,
Corollary 4.11, agents indifferent w.r.t. specific optimal allocation selected,
hence case equally divide available value themselves.

basic properties mechanism pointed next.
Theorem 4.13 (basic properties). Let optimal allocation algorithm. Then,
mechanism (A, p ) efficient guarantees equal treatment equals. Moreover,
valuations non-negative, (A, p ) individually rational.
Proof. clear (A, p ) satisfies efficiency equal treatment equals.
Let agent recall Lemma 4.8 that, type vector
allocation , ui (, w ) = (, w ) holds. Consider payment rule
p defined Figure 4, observe (, w ) defined weighted summation,
coalitions C C, terms form 1C,i (, ) 2C,i (, ). particular,
weights positive claim 1C,i (, ) 2C,i (, ) 0 holds. Indeed,
check that, definition, 1C,i (, ) = opt(hC, img(), i, w ) 2C,i (, ) = opt(hC \
{i}, img(), i, w ). So, hypothesis valuations non-negative,
opt(hC, img(), i, w ) opt(hC \ {i}, img(), i, w ) 0 holds, C
agent A. Thus, ui (, w ) 0, hence fact (A, p ) individually rational trivially
follows (even independently allocation , whether agent truthtelling).
Moreover, mechanism also tolerant sensing errors (or uncertain inputs),
sense Section 3.2.
426

fiMechanisms Fair Allocation Problems

Theorem 4.14 (error tolerance). Let optimal allocation algorithm. Then,
mechanism (A, p ) type vector agent A, |ui (A(wt ), wt )
ui (A(wt ), wt )| 3 dist(t, t).
Proof. Consider construction reported Figure 4 two cases = = t,
let = A(wt ) = A(wt ) corresponding allocations received input
payment rule (optimal w.r.t. wt wt , respectively). Moreover, set C C
agents agent A, let C,i C,i corresponding allocations computed
step 3. Then, get:
1C,i (, t) = opt(hC, G, i, wt ), Equation 2 proof Theorem 4.9;
1C,i (, t) = opt(hC, img(), (ti ,ti )i, w(ti ,ti ) ), step 3 Figure 4 fact
true valuation agent disclosed verifier C,i img().
2C,i (, t) = opt(hC \ {i}, G, i, wt ), Equation 3 proof Theorem 4.9;
2C,i (, t) = opt(hC \ {i}, G, i, wt ), Equation 3;
Note |1C,i (, t) opt(hC, img(), i, wt )| dist(t, t). Moreover, since
optimal allocation w.r.t. wt , Corollary 4.5, opt(hC, img(), i, wt ) = opt(hC, G, i, wt )
and, hence, |1C,i (, t) opt(hC, G, i, wt )| dist(t, t) holds. Then, observe
|opt(hC, G, i, wt ) 1C,i (, t)| dist(t, t). Therefore, conclude |1C,i (, t)
1C,i (, t)| 2 dist(t, t).
Similarly, |2C,i (, t) 2C,i (, t)| dist(t, t) holds. Hence, putting together,
derive |(1C,i (, t) 2C,i (, t)) (1C,i (, t) 1C,i (, t))| 3 dist(t, t).
light expression step 7 Figure 4,
|i (, wt ) (, wt )|

X (|A| |C|)!(|C| 1)!
3 dist(t, t).
|A|!

CC

P
conclude proof, observe CC (|A||C|)!(|C|1)!
= 1 holds, |i (, wt )
|A|!
(, wt )| 3 dist(t, t).
Therefore, Lemma 4.8, get |ui (A(wt ), wt )
ui (A(wt ), wt )| = |i (, wt ) (, wt )| 3 dist(t, t).
fact, next show (A, p ), optimal allocation algorithm, satisfies
remaining properties discussed Section 3.1. end, first discuss
interpretation p context coalitional games.

5. Coalitional Game Theory Viewpoint
coalitional game modeled pair G = hN, i, N = {1, ..., n} finite
set agents, function associating coalition R N real-value
(R) R, ({}) = 0, meant encode worth agents C obtain
collaborating other. function supermodular (resp., submodular )
(R ) + (R ) (R) + (T ) (resp., (R ) + (R ) (R) + (T )) holds,
pair coalitions R, N .
427

fiGreco & Scarcello

fundamental problem coalitional games single desirable outcomes, usually called solution concepts, terms appropriate notions
worth distribuP
n
tions, i.e., vectors payoffs x = (x1 , ..., xn ) R xi = (N ).
question studied economics game theory aim providing arguments
counterarguments proposals reasonable mathematical renderings
intuitive concepts fairness stability. background coalitional
games, reader referred to, e.g., work Osborne Rubinstein (1994).
Here, consider Shapley value G = hN, i, well-known solution
concept that:
X (|N | |R|)!(|R| 1)!
(G) =
((R) (R \ {i})), N.
|N |!
RN

Indeed, shall show mechanism defined Section 4 nice interpretation
terms Shapley value suitable-defined coalitional games. correspondence
exploited prove properties mechanism, equilibrium
agents truthfully report types.
5.1 Shapley Value Allocation Games
consider two coalitional games defined top allocation problem.
marg
best
Definition 5.1. Given valuation vector w, define Gw
= hA, margw Gw
=
hA, bestw coalitional games such, set C agents,

margw (C) = opt(hA, G, i, wt ) opt(hA \ C, G, i, wt ); and,
bestw (C) = opt(hC, G, i, wt ).

2

Recall Section 3.1 defined concept marginal contribution
marg,w (C) coalition C respect given allocation (because sensible
set goods allocated ). definition, slight abuse notation,
defined similar concept margw (C), depend goods allocation.
turns two concepts actually coincide optimal allocations.
Theorem 5.2. Let optimal allocation St w.r.t. wt , let C
arbitrary set agents. Then, marg,w (C) = margw (C).
Proof. Let optimal allocation St = hA, G, w.r.t. wt , hence optimal
hA, img(), w.r.t. wt . is, opt(St , wt ) = opt(hA, img(), i, wt ). Moreover, set C agents, Corollary 4.5, opt(hA \ C, img(), i, wt ) =
opt(hA\C, G, i, wt ) holds. Therefore, margw (C) = opt(St , wt )opt(hA\C, G, i, wt ) =
opt(hA, img(), i, wt ) opt(hA \ C, img(), i, wt ), result follows value
equivalent definition marg,w (C) Equation 1 (on page 416).
Note also bestw (C) best contribution C, computed assuming agents
best
already
C agents allocation problem. particular, game Gw
considered Moulin (1992), precisely setting fair division allocation
best
submodular.
problems. There, shown cost function associated Gw
428

fiMechanisms Fair Allocation Problems

Proposition 5.3. function bestw submodular.
marg
Since opt(hC, G, i, wt ) = bestw (C), turns Gw
called
best
literature dual game Gw , following result known hold. Nevertheless,
give direct proof, completeness.

Corollary 5.4. function margw supermodular.
Proof. Let St = hA, G, given scenario. result follows noticing
margw (C) = opt(hA, G, i, wt ) opt(hA \ C, G, i, wt ) = opt(hA, G, i, wt ) bestw (A \
C), set agents C A. Therefore, bestw (C) = opt(hA, G, i, wt )margw (A\C).
Thus, bestw (R ) + bestw (R ) bestw (R) + bestw (T ) holds R, A,
margw (A \ (R )) + margw (A \ (R )) margw (A \ R) + margw (A \ )
holds well, R, A. Eventually, letting R0 = \ R 0 = \ , get
margw (R0 0 ) + margw (R0 0 )) margw (R0 ) + margw (T 0 ), R0 , 0 A.
is, margw supermodular.
second relevant property payment rule Section 4 coincides
best
Shapley value game Gw
associated w. result follows comparing utility function Theorem 4.10 expression Shapley value coalitional
best
game Gw
. Moreover, show result established dual game
marg
Gt , Shapley values two games identicalfor similar correspondences
Shapley values different games, see also works Maniquet (2003) Kalai
Samet (1983).
Theorem 5.5. optimal allocation St w.r.t. wt , agent A,
marg
best
).
) = (Gw
holds ui (, wt ) = (, wt ) = (Gw
Proof. comparing utility function Theorem 4.10 expression
best
associating coalition C agents
Shapley value coalitional game Gw
worth opt(hC, G, i, wt ), immediately get that, optimal allocation St
best
).
w.r.t. wt , agent A, holds ui (, wt ) = (, wt ) = (Gw
marg
best
order conclude proof, show agent A, (Gw ) = (Gw
)
holds. end, first note Shapley values written follows:
P
marg
(Gw
) = CA,iC (|A||C|)!(|C|1)!
TC0 ,
|A|!
best
(Gw
)=

P

CA,iC

(|A||C|)!(|C|1)!
TC ,
|A|!

TC0 = margw (C)margw (C\{i}) TC = opt(hC, G, i, wt )opt(hC\{i}, G, i, wt ).
Then, claim that:
(1) set C agents C, set C = (A \ C) {i} TC0 = TC,

set C = (A \ C)
{i} 0 = .
(2) set C agents C,
C
C

429

fiGreco & Scarcello

(1) Let C C, observe TC0 = margw (C) margw (C \ {i}) =
(opt(St , wt ) opt(hA \ C, G, i, wt )) (opt(St , wt ) opt(hA \ (C \ {i}), G, i, wt )) =
opt(hA \ (C \ {i}), G, i, wt ) opt(hA \ C, G, i, wt ) = opt(h(A \ C) {i}), G, i, wt )
opt(hA \ C, G, i, wt ). Thus, let C = (A \ C) {i}, note TC0 = TC.
G, i, wt )
observe = opt(hC,
(2) Let C C,
C


opt(hC \ {i}, G, i, wt ) = (opt(St , wt ) opt(hC \ {i}, G, i, wt )) (opt(St , wt )
G, i, wt )) = marg ((A \ C)
{i}) marg (A \ C).
Thus, let C = (A \ C)
{i}
opt(hC,
w
w
0
note TC = TC.
marg
best
(1) (2) hold, given two expressions (Gw
) (Gw
), conclude
two values coincide.

5.2 Marginality, Budget-Balancedness, Individual Optimality
established precise correspondence mechanism
Shapley value associated allocation games, show desirable properties p . fact, exploit following well-known properties (see, e.g., Osborne &
Rubinstein, 1994; Young, 1985) Shapley value game G = hN, i:
(I)

P



(G) = (N );

(II) P
supermodular (resp., submodular ),
iR (G) (R)), coalition R N .

P

iR (G)

(R) (resp.,

(III) G 0 = hN, 0 game 0 (R) (R), R N , (G 0 ) (G),
agent N .
particular, Property
(II) entails Shapley value supermodular game
P
marg
) margw (R). means Shapley value
Gw iR (Gw
game belongs another important solution concept coalitional games called core (Osborne & Rubinstein, 1994), highly desirable stability, every coalition
marg
gets least worth deserves according function margw .
agents Gw
context, easily entail utility every group (coalition) agents
C (i.e., sum utilities agents C), less actual marginal contribution best possible allocations. Note considering collective utility
particularly useful whenever reason terms fairness groups agents, rather
singletons. first pinpoint bestw (C) margw (C) provide upper bound
lower bound, respectively, utility C.
marg

Theorem 5.6. Let
Pan optimal allocation St w.r.t. wt . Then, set C
agents, bestw (C) iC ui (, wt ) margw (C).

marg
best
), agent
) = (Gw
Proof. Theorem 5.5, know ui (, wt ) = (Gw
optimal allocation . Then, simply recall function margw (resp.,
marg
best
bestw ) associated game Gw
(resp., Gw
) supermodular (resp.,
P submodular)

Corollary
5.4
(resp.,
Proposition
5.3).
Hence,

result
follows

iC ui (, wt ) =
P
P
marg
best

(G
)


property
(II).

(G
)
=
iC w
iC w

430

fiMechanisms Fair Allocation Problems

combining result Theorem 5.2, immediately get following.
Corollary 5.7 (marginality).
P Let optimal allocation algorithm. Then, mechanism (A, p ) iC ui (A(wt ), wt ) margA(wt ),w (C), set C A.
Hence, payment rule p optimal allocation algorithms, get mechanisms
accurately take care marginality property defined Section 3.1. next result
pertains budget-balance property mechanisms. Again, correspondence
Shapley value crucial establish result.
Theorem
5.8. Let optimal allocation St w.r.t. wt .
P

p
(,
w
) = 0.
iA

Then, holds

best
), agent optiProof. Theorem 5.5, know ui (, wt ) = (Gw
best
best
mal allocation ,

(G
)


Shapley
value

G
w . property (I)
Pof Shapley
P
P w best
best
)=
value, know iA (Gw ) = bestw (A). Thus, iA ui (, wt ) = iA (Gw
opt(hA, G, i, wt ). definition utility letting wt = (w1 , ..., wn ), folP
P
P


lows opt(hA, G, i, wt ) =
iA pi (, w). Hence,
iA wi ()
iA pi (, wt ) =
opt(hA, G, i, wt ) val(, wt ) = 0, indeed optimal allocation w.r.t. wt .

Corollary 5.9 (budget-balancedness). Let optimal allocation algorithm. Then,
mechanism (A, p ) budget-balanced.
Finally, complete picture analysis proving strong fairness property
proposed payment rule p : words, best outcome every agent always
determined (global) optimal allocation. Moreover, Corollary 4.11, agent
indifferent specific optimal allocation considered. is, chosen
optimal allocation leads best results agents.
Lemma 5.10. Let 0 two feasible allocations St optimal w.r.t. wt ,
hence val(, wt ) val( 0 , wt ). Then, ui (, wt ) ui ( 0 , wt ), A. Moreover, 0 optimal, exists agent ui (, wt ) > ui ( 0 , wt ).
Proof. allocation , consider coalitional game G = hA, v v (C) =
opt(hC, img(), i, wt ), C A. looking expression Shapley value
G , easy check ui (, wt ) = (G ) (just use reasoning proof
Theorem 4.10). Assume 0 allocation val(, wt ) val( 0 , wt ),
0
consider value v (C) = opt(hC, img( 0 ), i, wt ), C A. Corollary 4.6,
0
v (C) v (C), C A. Then, derive ui (, wt ) = (G )
0
(G ) = ui ( 0 , w) every A, property (III).
assume 0 optimal, thus val(, wt ) > val( 0 , wt ). Therefore,
0
grand-coalition A, v (A) > v (A). property (I) Shapley
0
value, (and all) total value v (A) distributed agents. follows
0
exists agent ui (, wt ) = (G ) > (G ) = ui ( 0 , wt ).
focusing optimal allocation algorithms, lemma immediately entails
following two fairness properties.

431

fiGreco & Scarcello

Theorem 5.11 (individual optimality). Let optimal allocation algorithm.
Then, agent feasible allocation St , ui (A(wt ), wt ) ui (, wt ).
Corollary 5.12 (Pareto-efficiency envy-freeness). Let optimal allocation
algorithm. Then, mechanism (A, p ) Pareto efficient envy-free.
Note individual optimality guarantees much classical Pareto efficiency
envy-freeness, entails mechanism leads unique evaluation,
independently chosen optimal allocation. particular, Pareto set singleton.

6. Complexity Issues
section, shall reconsider mechanism verification computational
perspective. Note first computing optimal allocation basis reported
types easy task, carried via adaptations classical matching algorithms. Indeed, light Fact 4.2, computing optimal allocation arbitrary
scenario (with agents goods G) reduces computing optimal allocation
scenario agent (in A1 ) gets one good. equivalent finding matching
maximum weight complete bipartite graph set disjoint nodes A1
G, edge weights encoded via function w1 . combinatorial problem
known feasible polynomial time (e.g., Schrijver, 2003).
6.1 Hardness Result
Despite fact optimal allocations computed polynomial time, mechanism computationally-efficient, since payments unlikely computable
polynomial time. Indeed, next show computation problem complete
complexity class #P (see Papadimitriou, 1993).
Let us recall counting Turing machine standard nondeterministic Turing
machine auxiliary output device prints binary notation number
accepting computations induced input. (worst-case) time complexity f (n)
longest accepting computation induced set inputs size n takes f (n) steps.
Then, #P class functions computed counting Turing machines
polynomial time complexity. prototypical #P-complete problem count number
truth variable assignments satisfy Boolean formula. course, NP#P,
polynomial-time algorithm solving #P-complete problem would imply P = NP.
Theorem 6.1. Computing Shapley value coalitional games associated allocation
problems (as Definition 5.1) #P-complete.
Proof. problem belongs #P, computing Shapley value known feasible #P class coalitional games polynomial-time value/cost functions (c.f.
Deng & Papadimitriou, 1994). show #P-hard, exhibit reduction
following problem: Let G = (A B, E) bipartite graph |A| = |B| = n, E B,
|E| = n. Recall matching set E 0 E edges pair
distinct edges (a, b) (a0 , b0 ) E 0 , 6= a0 b 6= b0 hold. matching E 0 perfect
|E 0 | = n. problem counting number perfect matchings bipartite
graphs #P-complete (Valiant, 1979a).
432

fiMechanisms Fair Allocation Problems

Given graph G = (A B, E) constant k 1 (which shall fix below),
build polynomial-time tuple S(G) = hA, G, vector wt that:

(1) = {} (a,b)E {(a, b)1 , ..., (a, b)k }, i.e., agents one-to-one associated k
distinct clones edge (a, b) E, plus distinguished agent . Note |A| > n,
considered bipartite graphs n holds.
(2) G = {g } B, i.e., goods correspond nodes, plus distinguished good g .
(3) = 1 (a,b)i = 2, (a, b) {1, ..., k}, components
associated agents (a, b)i , respectively.
(4) agent c A, associated component wc vector wt defined
follows. (a, b)i A, w(a,b)i (a) = 2, w(a,b)i (b) = 2, w(a,b)i (g ) = 1, w(a,b)i (x) = 0,
x (A B) \ {a, b}. Moreover, w (g ) = 1, w (x0 ) = 0, x0 (A B).
Let us fix notations. set E 0 E edges, let match(E 0 ) denote
size largest set E 00 E 0 edges matching. set C \ {}
agents, let A(C) = {a | (a, b)i C} B(C) = {b | (a, b)i C}. Finally, say
C \ {} tight contain two agents form (a, b)i (a, b)j ,
6= j, i.e., associated edge G.
Observe that, set C \ {} agents,
opt(hC {}, G, i, wt ) opt(hC, G, i, wt ) =



1
0

C tight, |C| = A(C) = B(C)
otherwise

(5)

Indeed, C0 optimal allocation hC {}, G, w.r.t. wt , always
val(C0 , t) = 2 |A(C)| + 2 |B(C)| + 1. Instead, C optimal allocation hC, G,
w.r.t. wt ,

2 |A(C)| + 2 |B(C)|
C tight, |C| = A(C) = B(C)
val(C ) =
2 |A(C)| + 2 |B(C)| + 1 otherwise
best

exploiting Equation 5, express Shapley value game GS(G),t
agent convenient way. Let Xh denote number sets C \ {} agents
tight |C| = |A(C)| = |B(C)| = h, let X0 = 1. Then,

|A|1
best
(Gw
)=

X (|A| h 1)!(h)!
Xh .
|A|!

(6)

h=0

particular, let us focus coefficient Xh . Denote Yh number matchings
G whose cardinality h. construction S(G) immediate check
matching cardinality h G, precisely k h sets agents C \ {}
tight |C| = |A(C)| = |B(C)| = h. Thus, rewrite expression:
|A|1
best
(Gw
)=

X

(Zh Yh ) k h , Zh =

h=0

433

(|A|h1)!(h)!
.
|A|!

(7)

fiGreco & Scarcello

best
expression one above, given value (Gw
), known
certain circumstances reconstruct polynomial time value single term
form Zh Yh (see Fact 6 work Valiant (1979b)): need integer constant
> 2 that, h {0, ..., |A| 1}, Zh Yh A, k A2 . case,
noticed that, h {0, ..., |A|1}, Zh Yh 1 holds, Yh |A|!/((h)!(|A| h)!).
best
), compute polynomial
Thus, k = 9, that, given value (Gw
time terms. particular, compute polynomial time term associated
h = |A| = |B| = n, recall |A| > n. term form Zn Yn , Yn
number perfect matchings G. Thus, putting together since Zn
computed polynomial time (as size numbers n |A| logarithmic
w.r.t. size G), number perfect matchings bipartite graphs counted
polynomial time too, concludes proof.

Lemma 4.8 Theorem 5.5, following immediate.
Corollary 6.2. Computing payments given rule p #P-complete.
6.2 Fully Polynomial-Time Randomized Approximation Scheme
approach circumvent intractability Shapley value based approximation:
game G = hN, i, vector -approximation Shapley value |i (G)|
(G) holds, N .
Recently, sampling method conceived Bachrach, Markakis, Resnick, Procaccia,
Rosenschein, Saberi (2010) special class simple coalitional games
extended deal arbitrary games supermodular monotone 6 (Liben-Nowell,
Sharp, Wexler, & Woods, 2012), assumption value (R) computed
oracle unitary cost, R N . result that, > 0
> 0, possible compute time poly(N, 1/, log(1/)) vector approximation Shapley value probability failure . method
properties called fully polynomial-time randomized approximation scheme.
Next, propose payment rule p founded sampling strategy described
work Liben-Nowell et al. (2012). payment rule, reported Figure 5, samples
subsets storing C (together subsets functionally determined
samples), computes value (, w ) Figure 4, C playing
role power-set C. process repeated (log(1/)) times, componentwise median vector payments computed. resulting payment eventually
defined step 9.
new rule p gives rise randomized mechanism course still verifiable
uses punishment. Moreover, mechanism truthful even realization
set C, sampled step 1, known beforehand.7 Formally, mechanism turns
universally truthful, i.e., probability distribution deterministic truthful
mechanisms (see, e.g., Dobzinski & Dughmi, 2009).
6. Monotonicity G = hN, means (R) (T ), R N .
7. evidences truthfulness desideratum, need implement payment
rule computing Shapley value coalitional game associated allocation problem (as
Definition 5.1), fact concept defined possible subsets shown
computationally hard Theorem 6.1.

434

fiMechanisms Fair Allocation Problems

Input:
type vector , feasible allocation , integer > 0;
Assumption: verifier v (for t) available, v() = (v1 , ..., vn );
Notation:
= hA, G, i, w = (w1 , ..., wn ), wv() = (wv1 , ..., wvn );
1.
2.
3.
4.
5.
6.
7.
8.
9.

Generate set C subsets A,
let C := C {(A \ C) {i} | C C, C} {A};
C C,
| Compute optimal allocation C,i hC, img(), (vi ,i ) w.r.t. w(vi ,i ) ;
b Compute optimal allocation C\{i},i hC \ {i}, img(), (vi ,i ) w.r.t. w(vi ,i ) ;
agent A,
b Compute (, w ) Figure 4 (steps 48), C := C;
Repeat (log(1/)) times steps 1, 2, 5,
w ) component-wise median vector vectors (, w );
Let (,
Define pi (, w ) := (, w ) wvi ();
Figure 5: Payment rule p .

Theorem 6.3. Let optimal allocation algorithm. Then, mechanism (A, p )
universally truthful.
Proof. result follows inspecting proof Theorem 4.9 rule p Section 4.
Indeed, immediately checked proof depend specific
subset coalitions C, thus smoothly applies set coalitions C used
Figure 5, instead possible subsets A. Note particular that, proof
Theorem 4.9, properties (A) (B) precisely guaranteeing truthfulness,
properties hold given coalition C. Therefore, still hold subset
coalitions randomly chosen mechanism.
Similarly, inspecting proofs Section 4, universally truthful mechanism,
following properties seen hold every realization random coin tosses.
Theorem 6.4 (basic properties). Let optimal allocation algorithm. Then,
mechanism (A, p ) efficient guarantees equal treatment equals. Moreover,
valuations non-negative, (A, p ) individually rational.
deeper analysis payment rule p , next point relationship
utility values approximations Shapley value, equilibrium agents
report true types.
Lemma 6.5. Let = {1, ..., |A|}, let = (|A|2 /2 ). optimal allocation
St w.r.t. wt , vector (u1,p (, wt ), ..., u|A|,p (, wt )) -approximation
marg
best
Shapley value Gw
(and Gw
) probability 1 , coincides expectation.
Proof. exploiting line reasoning proofs Section 4 p ,
see (, wt ) (at step 6 algorithm Figure 5) rewritten follows:
(, wt ) =

X (|A| |C|)!(|C| 1)!
(bestw (C) bestw (C \ {i})) .
|A|!

CC

435

fiGreco & Scarcello

Then, observe construction C step 1, set C C agent
A, set (A \ C) {i} C, too. Thus, apply line reasoning
proof Theorem 5.5, order conclude that:
(, wt ) =

X (|A| |C|)!(|C| 1)!
(margw (C) margw (C \ {i})) .
|A|!

CC

marg
= hA, margw supermodular Corollary 5.4. MoreNow, recall game Gw
marg
over, Gw clearly monotone. Thus, Liben-Nowell et al. (2012), expression
marg
, approximates value
coincides expectation Shapley value Gw
constant probability. Steps 7 8 serve amplify probability (c.f. Liben-Nowell
et al., 2012), get fully polynomial-time randomized approximation scheme.
result follows step 9 implements usual bonus compensation approach,
ui,p (, wt ) coincides expression, (cf. Lemma 4.8).

Note approach Liben-Nowell
P et al. (2012), final normalization step
carried would guarantee
iA u1,p (, wt ) = margw (A) = bestw (A).
Unfortunately, way truthfulness might lost, hence include normalization procedure payment rule. consequence, mechanism p
guarantee (for instance) budget-balancedness Pareto-efficiency. However,
Lemma 6.5, since expected utility profile coincides Shapley value, p enjoys
expectation properties p including two ones. particular,
still approximate counterparts Theorem 5.6 Theorem 5.8.
Theorem 6.6. Let optimal allocation St w.r.t. wt . Let = (|A|2 /2 ). Then,
probability 1 ,
P
(1 + ) bestw (C) iC ui,p (, wt ) (1 ) margw (C), C A;
val(, wt )

P


iA pi (, wt )

val(, wt ).

Proof. Here, observe
Lemma 6.5 TheoremP5.5, set
Pthat, light P
C A, (1) iC ui,p (, wt ) iC ui,p (, wt ) (1+) iC ui,p (, wt ).
result follows substituting bounds Theorem 5.6 Theorem 5.8,
respectively, simple algebraic manipulations.
Finally, propose randomized mechanism able guarantee economic efficiency budget-balancedness. price paid however truthfulness
holds expectation only. mechanism based payment rule call p .
Theorem 6.7. Let optimal allocation algorithm. Then, (randomized)
mechanism verification (A, p ) truthful expectation, (at truthful
equilibrium) efficient budget-balanced. Moreover, valuations non-negative,
(A, p ) individually rational.
Proof. payment rule p follows steps Figure 5, minor modifications
step 8 step 9: First, step 8, whenever compute median value (, w )
agent i, also compute corresponding value (, wv() ) (evaluated revealed
436

fiMechanisms Fair Allocation Problems

types rather reported ones). Then, define normalization factor R =
P
opt(hA, img(), v() i, wv() )/( iA (, wv() )), that, step 9, pi (, w ) eventually
returned wvi () (, w ) R.
Concerning truthfulness, note expected value R 1. Indeed,
Lemma 6.5, expected value (, wv() ) (, wv() ); hence, sum
values coincides opt(hA, img(), v() i, wv() ) efficiency Shapley value
(as proof Theorem 5.8). Thus, expected utility agent payment
rule p coincides (actual, i.e., expectation) utility rule p .
Hence, truthfulness expectation follows Theorem 6.3. Now, check that,
truthful equilibrium, maximum social welfare achieved (equilibrium efficiency)
P
P
iA pi (, wt ) = opt(hA, img(), i, wv() ) iA (, wt ) R = 0. is,
mechanism budget-balanced, too. Finally, mechanism p seen individuallyrational, exploiting line reasoning one used mechanism based
p , since corresponding proof Section 4 affected sampling strategy.
Again, Lemma 6.5, remaining properties hold expectation.

7. Related approaches Mechanisms Verification
next review main approaches literature mechanisms verification,
point differences w.r.t. proposal.
First observe that, differently general setting types agents
determine vector upper bounds allocation problem, earlier approaches assumed agent types impact underlying combinatorial problem, type vector precisely coincides valuation vector. Instead,
deal explicitly allocation constraints goods valuations. instance,
scheduling problem formalized setting, private type agent/machine
speed, valuation function fully determined speed size
job processed. Then, verifier asked measure speed
agents/machinessee also Appendix A. fact, immediate encode valuations
types well, price however hiding true complexity (or simplicity)
setting. instance, example, type agent vector
valuations, would miss information agent ultimately characterized
one (observable) parameter only.
substantial differences earlier approaches proposal come
definition utility agent. works Auletta et al. (2009), Penna
Ventre (2012a, 2012b), Krysta Ventre (2010), Auletta et al. (2006) Ferrante
et al. (2009), individual welfare agent i, given outcome vector
reported types, assumed following form:

0
caught lying
ui,p (, d) = ti ()
pi (, d) otherwise
pi (, ) payment depend vector true types.
papers, information assumed available payment time
whether reported type di agent differs actual true type ti .

437

fiGreco & Scarcello

role played verifier, fact pi (, d) exploit possibility partially
revealing ti . Moreover, payment scheme adopted punishes agents caught
lying. Hence, verification process provides smaller amount information
verification process approach, rules used discourage strategic behaviors
stronger based punishing agents. Also, works assume
agents misreporting restricted certain kinds lies (e.g., values lower
corresponding true ones), form one-sided verification suffices.
Recently, model (partial) verification extended Caragiannis
et al. (2012) setting agent cheating her/his type identified
probability may depend her/his true type, reported type, both. fact,
Caragiannis et al. also showed cases verification help
one-sided. payment scheme exactly one discussed
and, hence, verification exploit (possibly partial) knowledge actual
true type punishment approach still used. main novelty, addition
probabilistic verification, constraint type agent report
cheating.
Finally, different kind verification model goes back seminal paper Nisan
Ronen (2001), actually closer no-punishment perspective,
agent principle paid mechanism even caught lying. Given
n agents, Nisan Ronen consider vector e = (e1 , ..., en ) observed agent types,
completely known verification process. Moreover, individual utility
agent form ui,p (, d) = ei () pi (, d), vector e
framework plays role verifiers output approach. first difference
work Nisan Ronen approach that, model, agents
misreporting restricted certain kinds lies. hand, consider
restriction form valuation functions, since verification model assumes
valuations determined objective observable properties goods agents
(encoded functions form g , defined Section 2). consequence,
payment time, valuation agent known every good img(). Instead,
setting Nisan Ronen, valuation agent goods img() \ (i)
remains unknown even verification performed. results presented
paper, turns difference two framework crucial overcome
classical impossibility results, meet desirable properties (without using
punishing power).

8. Conclusion
paper, proposed analyzed mechanisms fair allocation problems
setting agents declarations regard objective properties goods agents, thus
(partially) verified payments made. particular, considered
model verification able disclose true values allocated goods, contrast
previous approaches literature partial probabilistic verification
considered. However, use verification power fact quite limited,
payment rules designed punishment meted agents whose
declarations match output verification process. requirement crucial
438

fiMechanisms Fair Allocation Problems

practical applications framework, Italian research evaluation described
(Greco & Scarcello, 2013) (and summarized Appendix), discrepancy
declared verified values may due sensing errors subjective issues
cannot interpreted agents lies punished.
challenge show that, framework, truthfulness, efficiency, budgetbalancedness, fairness (as well desirable properties discussed Section 2)
achieved simultaneously, unlike classical setting. worthwhile noting that,
one guaranteed agents truthfully report true types (no strategic behaviors)
or, equivalently, types given public knowledge, problem quite easy.
instance, one use payments way agent gets her/his utility
Shapley value according either coalitional game defined Section 5. Moreover,
fairness issue, properties obtained even using simple
uniform payment rule. However, whenever agents may behave strategically, reporting
true type longer dominant strategy, approaches used. fact, truthfulness
might enforced equipping mechanism suitable punishment rules. However,
already argued would appropriate context, typically
resulting mechanism would error tolerant.
looking proposed framework abstract perspective, one may notice
based two fundamental ingredients: base combinatorial problem determines
feasible optimal allocations, game-theoretic notion describes considered fair, respect agents contributions expectations. Namely, application
domain allocation problems addressed paper, weighted matching basic
combinatorial problem Shapley value natural game-theoretic solution
concept. perspective, natural research direction study different instances
abstract framework mechanisms verification, combinatorial
problems (colorings, coverings, etc.) different solution concepts (Nucleolus, Banzhaf
index, etc.) may appropriate best describe problem hands.
Another interesting avenue research would study modification
framework agents preferences directly expressed terms real-valued
functions, rather formalized terms orderings/ranks available goods.
particularly interesting given that, strategic setting defined, agents
declarations contribute definition goods selected,
determine values.

Acknowledgments
thank anonymous referees Associate Editor useful comments.

Appendix A. Application Scenarios
Fair allocation monetary compensation intensively studied literature,
often settings parameters interest public knowledge (or, simply,
getting rid strategic issues). One example application discussed literature
parking space benefit allocation workplace, employee gets parking
space share fixed benefits package. House allocation problems another

439

fiGreco & Scarcello

classical example, agents collectively set houses, look systematic
way exclusively assigning house agent, possibly monetary compensations.
third example room assignment-rent division, group agents rent house,
getting room paying share rent.
following, illustrate applications fair allocation problems fit
general framework discussed Section 2. applications shall discuss, part
relevant information private knowledge agents, verification adopted
measure observable properties payment phase. Nonetheless, stress
that, even relevant information available public knowledge could
measured advance, applications would still remain interest, show
need defining allocation policies guarantee fair and/or error tolerant solutions.
A.1 Italian Research Assessment Program (VQR) 20042010
start overview possible application scenarios focusing real-world case
study first motivated investigation allocation problems. application
best described companion paper (Greco & Scarcello, 2013), applies results
presented specific case Italian research assessment program.
A.1.1 Setting
2012, National Agency Evaluation Universities Research Institutes
(ANVUR) promoted VQR assessment program devoted evaluate quality
whole Italian research production. first application, program focuses
period 2004-2010, evaluation repeated regular basis (the next one
cover years 20112014).
first phase program, every structure R (a university research institute)
selects submits ANVUR set P products, constraints (i)
product univocally associated author (even product co-authored)
(ii) three products associated author affiliated R.8
abstract terms, R computes phase allocation , img() = P ,
scenario R set agents/researchers affiliated R, P set
goods/products co-authored, r R, r = 3
associated constraint number goods/products allocated r. way
allocation performed described below.
second phase, ANVUR evaluates products P equipping
quality score, expressed number.9 Hence, phase defines official valuation
that, product p (r), w(p) quality score assigned ANVUR p.
overall score R sum values products P ,
used proportionally transfer R funds allocated Ministry support research
activities next years, data new evaluation subsequent period
available.
8. simplify here. Actually, number publications may less three, authors.
9. set possible scores defined VQR guidelines. ends, detail immaterial
scores viewed (arbitrary) real numbers.

440

fiMechanisms Fair Allocation Problems

A.1.2 Need Fair Division
VQR program actually assigns score structure R, also
substructures (e.g., departments, R university). course, expected
impact funds redistribution inside every research structure, therefore
crucial problem define fair rule funds redistribution, is, rule capable
assign funds clearly reflecting true contribution researcher/substructure
performances structure whole. Moreover, recruitment policies
universities going evaluated well, looking (VQR) performances
researchers hired recently. However, redistribution rule specified
program, researchers believe evaluation
P (the contribution of)
r R coincide overall value wr () =
p(r) w(p) products
allocated r submission phase. course fair general,
product p P co-authored two researchers R, (and, turn,
structures) might claim contribution even product formally allocated
one them.10 Therefore, sophisticated approaches defined
proper evaluation individuals substructures.
A.1.3 Strategic Issues Verification VQR Program
Recall goal structure R submit ANVUR (in first phase program) products likely get highest possible scores (in second phase).
end, publicly available evaluation criteria allow one perform ranking products, ideally equipping quality score
assigned ANVUR subsequent phase. time economic
reasons, first evaluation phase based self-evaluations performed
authors products, clearly assumed best experts research
subjects. Moreover, structures, decide precise allocation products, hence
deal conflicts related co-authored products, researchers performed choices
decentralized way; structures set optimization framework compute
optimal allocation, based agents declarations. case, abstracting
specific method adopted end feasible allocation submitted VQR,
strategic issues emerged phase. particular, researchers r R
guided allocation products (e.g., cheating quality) supposed
personal interest maximizing value wr (). Clearly enough, way optimal product
selections hardly achieved structure.
Note VQR case perfectly fits framework allocation problems: research products indivisible goods allocated researchers/agents, initially
declare goods valuations. Moreover, social welfare total ANVUR score
research structure, distributed budget-balanced way researchers,
hence substructures, fair way. Note upper bound constraint
researcher (3 products, exceptions) depend type case,
10. problem occur products co-authored researchers belonging different structures.
Indeed, product submitted several structures (assigned different co-author
them). Thus, given research structure R, co-authors interest affiliated
R.

441

fiGreco & Scarcello

parameter fixed ANVUR. Therefore, private information agents
limited good valuations. Moreover, observe specific valuation functions occurring VQR fit verification model proposed paper. particular, every
research product objective value, measured verifier
allocated hence submitted product (while nothing said products
allocated researcher). Thus, ANVUR precisely acts verifier model.
A.1.4 Mechanisms VQR Program
basic approach assigning researcher r R value wr () precisely
(trivial no-payment) rule p Example 2.6. There, observed mechanisms
based rule truthful general. Moreover, Example 3.1 also emerged
rule fair (in particular) combined optimal allocation algorithm
(in order guarantee efficiency). Therefore, rule highly undesirable, different
kinds mechanisms defined VQR setting.
fact, would like end mechanism able able collect
correct self-evaluations (truthfulness) obtain maximum possible performance
(efficiency) research structures. two goals, however, accomplished
together fairness. Indeed, would like guarantee every researcher group
researchers get least marginal contributions, resulting mechanism
also individually optimal. latter property important application, since
guarantees that, researcher, her/his score maximum one possible
alternative allocations, including allocations using products submitted
structure hence verified. Moreover, also relevant properties
guaranteed via mechanisms enjoying verifiability property, payment rule
uses certified valuations (it would unacceptable use product values
verified ANVUR).
Finally, worthwhile noting ANVUR guidelines defines range possible product values determined, e.g., publishing venues citation indices, pointing
peer-reviews also used override basic classification (e.g., papers published good journal without many citations, explicit authors
request). Clearly enough, entails discrepancies authors declarations
ANVUR evaluations might well emerge even absence malicious behavior. Hence,
no-punishment (and error-tolerant) approach seems unavoidable concrete
politically acceptable application mechanism.
A.2 (Cooperative) Scheduling Task Allocation
Assume h jobs set J = {1 , ..., h } executed within deadline d,
n agents/machines, m1 , ..., mn , n h, available execute parallel
jobs. machine mi , {1..., n}, let J denote set jobs mi
principle execute. sets determined, instance, physical, technological,
accessibility constraints known scheduler, precise speed
machines guarantee process known scheduler, declared
agents. assumed machine mi always work speed independently
workload actually assigned (for considered jobs hand). sake
442

fiMechanisms Fair Allocation Problems

simplicity, assume also job consists workload wl ,
executed job, fixed profit pr earned. Moreover, profit pr add earned
scheduler jobs correctly executed, (part it) distributed
agents. Every machine participating process execute least one job (i.e.,
assuming many jobs executed machine machines
comparable speeds convenient use them). Furthermore, every machine
dedicated process aims executing many jobs J possible,
cannot earn profit external jobs (not J ).
Therefore, allocation problem goods/jobs set {1 , ..., h }
allocated/scheduled agents/machines set {m1 , ..., mn }. Here,
private type agent mi speed si (devoted process), {1, ..., n}.
Moreover, vector upper bounds number goods allocated

agents defined (si ) = b ds
wl c, {1, ..., n}. Note, particular,
jobs completed within deadline, upper bound constraints
allocation scenario functions types/speeds agents/machines. Finally,
define valuation vector w = (w1 , ..., wh ) that, {1, ..., n}, wi (x ) = pr ,
x ; wi (x ) = 1, x 6 . Note case valuations independent
types agents (of course, assuming single job executed
within deadline d).
Given task carried different agents, sensible
allocations perceived fair ones (see, e.g., Porter et al., 2004). end,
mechanism monetary compensations described paper adopted. fact,
note strategic issues come play, egoistic behavior agents may lead
allocations optimal possibly miss extra-reward pr add . Observe
scheduler may act verifier model, end process. Indeed,
allocation computed jobs executed based it, immediately
verify truthfulness agents declarations looking amount time used
machine execute jobs assigned it.
Furthermore, practice, speed values given finite precision, well
physical verification subject measurement errors. reason, even mechanism
tolerant errors, based punishments.
example, consider following task allocation problem,
viewed variation previous one: Assume company select agents
e1 , ..., en perform given set tasks {t1 , ..., tm } within certain deadline, assume
company know precisely whether agents necessary
skills (experience, strength, speed, competence, etc.). instance, may happen
company starting new line production new tasks, tasks
executed means crowdsourcing, agents selected internet call.
Therefore, case agents types declarations comprise skills
number tasks able execute within required deadline. Valuation functions
encode profit earned agent executing given task (where value 0
means agent able execute task). Note upper
bound constraints allocation scenario valuations functions depend agents
types. Again, mechanism monetary compensations used, order provide
fair distribution company reward tasks, encourage agents truthfully
443

fiGreco & Scarcello

declare skills. Note framework verification proposed paper
used assumption agents skills necessary proposed set tasks
observed evaluated verifier, (at least) end process,
agents performed work (possibly failures).
A.3 Protocols Wireless Communication Networks
conclude overview possible applications considering cost problem where,
moreover, private information, hence strategic behavior. remark
proposal described paper used even mechanism design
necessary, one still needs policy fair division enjoys properties described
Section 3.1 (e.g., envy freeness, individual optimality, on). fact, fairness
issues currently attracting much attention design scheduling protocols
wireless communication networks, underlying problem bandwidth allocation;
instance, design protocols high-speed wide area wireless networks,
role monetary compensation played adjustments priorities users (see,
e.g., Jalali, Padovani, & Pankaj, 2000). Moreover, number network applications
emerging direct forms monetary compensation considered.
example, let us consider ad-hoc networks, self-organizing wireless infrastructures mobile nodes cooperatively act via multi-hop routing transmit data even
source destination nodes transmission ranges. Cooperation
achieved associating credit balance node, nodes use credits pay
sending traffic, earn credits forwarding traffic nodes compensate bandwidth power consumptionsee, instance, work Gobel, Krzesinski,
Mandjes (2009) references therein. Consider setting nodes s1 , ..., sn
willing transmit data ad-hoc network. given configuration
network, nodes r1 , ..., rm used forward data. particular, whenever
si rj , {1, ..., n} j {1, ..., m}, within transmission ranges,
denote ci,j credit paid si transfer data via rj large enough value ci,j
used state transmission possible. resulting cost problem
modeled via allocation scenario = 1, valuation vector
wi (rj ) = ci,j , {1, ..., n} j {1, ..., m}. Thus, maximizing social
welfare amounts minimizing overall credits paid source nodes.
easily seen that, even private information everything public,
fairness issues emerge context, too. Indeed, different sources may want use
routing node transfer data. instance, simple setting = 2
n = 2 r1 preferred routing node s1 s2 (i.e., c1,1 < c1,2
c2,1 < c2,2 ), node forced transfer data via r2 might perceive
given allocation unfair. suggests credits paid source nodes
adjusted via payment rules that, proposal, based Shapley value
coalitional games described Section 5.
setting similar one discussed emerges wireless cooperative file sharing
systems, mobile subscribers cluster together downloading (portions of) files
interest long-range cellular links, exchanging short-range radio communications wireless local area network. systems cooperative environments,

444

fiMechanisms Fair Allocation Problems

whose benefits appreciated terms increased throughput reduced
energy consumption, also terms economic advantages users content
providers. order effective, however, fair allocation protocols designed,
whose goal encourage cooperation (see, e.g., Militano, Iera, & Scarcello, 2013).

References
Abdulkadiroglu, A., Sonmez, T., & Unver, M. U. (2004). Room assignment-rent division:
market approach. Social Choice Welfare, 22, 515538.
Agotnes, T., van der Hoek, W., Tennenholtz, M., & Wooldridge, M. (2009). Power
normative systems. Proc. AAMAS09, pp. 145152.
Alcalde, J., & Barbera, S. (1994). Top dominance possibility strategyproof stable
allocations matching problems. Economic Theory, 4, 417435.
Alkan, A., Demange, G., & Gale, D. (1991). Fair allocation indivisible goods criteria
justice. Econometrica, 59 (4), 102339.
Andersson, T. (2009). general strategy-proof fair allocation mechanism revisited. Economics Bulletin, 29 (3), 17171722.
Andersson, T., & Svensson, L.-G. (2008). Non-manipulable assignment individuals
positions revisited. Mathematical Social Sciences, 56 (3), 350354.
Andersson, T., Svensson, L.-G., & Ehlers, L. (2010). Budget-balance, fairness minimal
manipulability. Working papers 2010:16, Lund University, Department Economics.
Aragones, E. (1995). derivation money rawlsian solution. Social Choice
Welfare, 12, 267276.
Archer, A., & Tardos, E. (2007). Frugal path mechanisms. ACM Transactions Algorithms, 3, 122.
Auletta, V., De Prisco, R., Penna, P., & Persiano, G. (2009). power verification
one-parameter agents. Journal Computer System Sciences, 75, 190211.
Auletta, V., De Prisco, R., Penna, P., Persiano, G., & Ventre, C. (2006). New constructions
mechanisms verification. Proc. ICALP06, pp. 596607.
Auletta, V., Penna, P., Persiano, G., & Ventre, C. (2011). Alternatives truthfulness
hard recognize. Autonomous Agents Multi-Agent Systems, 22 (1), 200216.
Aumann, R. J., & Maschler, M. (1985). Game-theoretic analysis bankruptcy problem
talmud. Journal Economic Theory, 36 (2), 195213.
Bachrach, Y., Markakis, E., Resnick, E., Procaccia, A. D., Rosenschein, J. S., & Saberi, A.
(2010). Approximating power indices: theoretical empirical analysis. Autonomous
Agents Multi-Agent Systems, 20, 105122.
Bachrach, Y., & Rosenschein, J. S. (2008). Coalitional skill games. Proc. AAMAS08,
pp. 10231030.
Bachrach, Y., & Rosenschein, J. (2009). Power threshold network flow games. Autonomous Agents Multi-Agent Systems, 18 (1), 106132.

445

fiGreco & Scarcello

Bachrach, Y., Zuckerman, M., Wooldridge, M., & Rosenschein, J. (2013). Proof systems
transformation games. Annals Mathematics Artificial Intelligence, 67 (1),
130.
Bevia, C. (1998). Fair allocation general model indivisible goods. Review
Economic Design, 3, 195213.
Bouveret, S., & Lang, J. (2008). Efficiency envy-freeness fair division indivisible goods: Logical representation complexity. Journal Artificial Intelligence
Research, 32, 525564.
Brams, S. J., & Kilgour, D. M. (2001). Competitive fair division. Journal Political
Economy, 109 (2), 418443.
Brandt, F., Conitzer, V., & Endriss, U. (2012). Multiagent Systems, chap. Computational
Social Choices. MIT Press.
Caragiannis, I., Elkind, E., Szegedy, M., & Yu, L. (2012). Mechanism design: partial
probabilistic verification. Proc. EC12, pp. 266283.
Clarke, E. (1971). Multipart pricing public goods. Public Choice, 8, 1933.
Deng, X., & Papadimitriou, C. H. (1994). complexity cooperative solution concepts. Mathematics Operations Research, 19, 257266.
Dobzinski, S., & Dughmi, S. (2009). power randomization algorithmic mechanism design. Proc. FOCS09, pp. 505514.
Dunne, P. E. (2005). Extremal behaviour multiagent contract negotiation. Journal
Artificial Intelligence Research, 23, 4178.
Dunne, P. E., Wooldridge, M., & Laurence, M. (2005). complexity contract negotiation. Artificial Intelligence, 164 (1-2), 2346.
Endriss, U., Maudet, N., Sadri, F., & Toni, F. (2006). Negotiating socially optimal allocations resources. Journal Artificial Intelligence Research, 25, 315348.
Feige, U., & Tennenholtz, M. (2011). Mechanism design uncertain inputs: (to err
human, forgive divine). Proc. STOC11, pp. 549558.
Ferrante, A., Parlato, G., Sorrentino, F., & Ventre, C. (2009). Fast payment schemes
truthful mechanisms verification. Theoretical Computer Science, 410, 886899.
Gobel, J., Krzesinski, A., & Mandjes, M. (2009). Incentive-based control ad hoc networks:
performance study. Computer Networks, 53 (14), 24272443.
Greco, G., & Scarcello, F. (2013). Fair division rules funds distribution: case
italian research assessment program (vqr 2004-2010). Intelligenza Artificiale, 7 (1),
4556.
Green, J., & Laffont, J. (1977). Characterization satisfactory mechanisms revelation preferences public goods. Econometrica, 45 (2), 427438.
Groves, T. (1973). Incentives teams. Econometrica, 41, 617631.
Haake, C.-J., Raith, M. G., & Su, F. E. (2002). Bidding envy-freeness: procedural
approach n-player fair-division problems. Social Choice Welfare, 19 (4), 723
749.
446

fiMechanisms Fair Allocation Problems

Hurwicz, L. (1975). existence allocation systems whose manipulative nash equilibria pareto optimal. Unpublished paper, presented third World Congress
Economic Sosciety, Toronto.
Jain, K., & Vazirani, V. (2001). Applications approximation algorithms cooperative
games. Proc. STOC01, pp. 364372.
Jalali, A., Padovani, R., & Pankaj, R. (2000). Data throughput cdma-hdr high efficiencyhigh data rate personal communication wireless system. Proc. IEEE VTC00,
Vol. 3, pp. 18541858.
Kalai, E., & Samet, D. (1983). weighted Shapley values. Discussion papers 602, Northwestern University, Center Mathematical Studies Economics Management
Science.
Klijn, F. (2000). algorithm envy-free allocations economy indivisible
objects money. Social Choice Welfare, 17 (2), 201215.
Krysta, P., & Ventre, C. (2010). Combinatorial auctions verification tractable.
Proc. ESA10, pp. 3950.
Liben-Nowell, D., Sharp, A., Wexler, T., & Woods, K. (2012). Computing Shapley value
supermodular coalitional games. Proc. COCOON12, pp. 568579.
Lindner, C. (2010). market-affected sealed-bid auction protocol. Proc. SETN10,
pp. 193202.
Lipton, R. J., Markakis, E., Mossel, E., & Saberi, A. (2004). approximately fair allocations indivisible goods. Proc. EC04, pp. 125131.
Maniquet, F. (2003). characterization Shapley value queueing problems. Journal
Economic Theory, 109 (1), 90103.
Maskin, E. (1987). Fair Allocation Indivisible Goods, pp. 341349. MacMillan.
Meertens, M., Potters, J., & Reijnierse, H. (2002). Envy-free pareto efficient allocations
economies indivisible goods money. Mathematical Social Sciences, 44 (3),
223233.
Militano, L., Iera, A., & Scarcello, F. (2013). fair cooperative content-sharing service.
Computer Networks, 57 (9), 19551973.
Mishra, D., & Rangarajan, B. (2007). Cost sharing job scheduling problem. Social
Choice Welfare, 29 (3), 369382.
Moulin, H. (1992). application Shapley value fair division money. Econometrica, 60 (6), 133149.
Moulin, H. (1999). Incremental cost sharing: Characterization coalition strategyproofness. Social Choice Welfare, 16 (2), 279320.
Moulin, H. (2003). Fair Division Collective Welfare. MIT Press.
Moulin, H., & Shenker, S. (2001). Strategyproof sharing submodular costs: budget balance
versus effciency. Economic Theory, 18 (3), 511533.
Nagamochi, H., Zeng, D.-Z., Kabutoya, N., & Ibaraki, T. (1997). Complexity minimum base game matroids. Mathematics Operations Research, 22, 146164.
447

fiGreco & Scarcello

Nisan, N., & Ronen, A. (2001). Algorithmic mechanism design. Games Economic
Behavior, 35, 166196.
Nisan, N., Roughgarden, T., Tardos, E., & Vazirani, V. V. (2007). Algorithmic Game
Theory. Cambridge University Press, Cambridge, UK.
Ohseto, S. (2004). Implementing egalitarian-equivalent allocation indivisible goods
restricted domains. Economic Theory, 23, 659670 (2004).
Osborne, M. J., & Rubinstein, A. (1994). Course Game Theory. MIT Press,
Cambridge, MA, USA.
Papadimitriou, C. H. (1993). Computational Complexity. Addison-Wesley.
Pathak, A.P., S. T. (2013). Comparing mechanisms vulnerability manipulation.
American Economic Review, 103 (27), 80106.
Penna, P., & Ventre, C. (2012a). Collusion-resistant mechanisms verification yielding
optimal solutions. ACM Transaction Computation Theory, 4 (2), 117.
Penna, P., & Ventre, C. (2012b). Optimal collusion-resistant mechanisms verification. Games Economic Behavior, press, electronically available doi
10.1016/j.geb.2012.09.002.
Porter, R., Shoham, Y., & Tennenholtz, M. (2004). Fair imposition. Journal Economic
Theory, 118 (2), 209228.
Potthoff, R. F. (2002). Use linear programming find envy-free solution closest
bramskilgour gap solution housemates problem. Group Decision
Negotiation, 11, 405414.
Quinzii, M. (1984). Core competitive equilibria indivisibilities. International
Journal Game Theory, 13, 4160.
Sakai, T. (2007). Fairness implementability allocation indivisible objects
monetary compensations. Journal Mathematical Economics, 43 (5), 549563.
Sandholm, T. (1998). Contract types satisficing task allocation: theoretical results.
AAAI Spring Symposium: Satisficing Models.
Schrijver, A. (2003). Combinatorial Optimization: Polyhedra Efficiency. SpringerVerlag.
Shioura, A., Sun, N., & Yang, Z. (2006). Efficient strategy proof fair allocation algorithms.
Journal Operations Research Society Japan, 49 (2), 144150.
Shoham, Y., & Leyton-Brown, K. (2009). Multiagent Systems. Cambridge University Press.
Su, F. (1999). Rental harmony: Sperners lemma fair division. American Mathematical
Monthly, 106, 930942.
Svensson, L.-G. (1983). Large indivisibles: analysis respect price equilibrium
fairness. Econometrica, 51 (4), pp. 939954.
Svensson, L.-G. (2009). Coalitional strategy-proofness fairness. Economic Theory, 40,
227245.

448

fiMechanisms Fair Allocation Problems

Tadenuma, K., & Thomson, W. (1991). No-envy consistency economies indivisible goods. Econometrica, 59 (6), 175567.
Tadenuma, K., & Thomson, W. (1993). fair allocation indivisible good
monetary compensations possible. Mathematical Social Sciences, 25 (2), 117132.
Tadenuma, K., & Thomson, W. (1995). Games fair division. Games Economic
Behavior, 9 (2), 191204.
Thomson, W. (2011). Fair allocation rules. Kenneth J. Arrow, A. S., & Suzumura, K.
(Eds.), Handbook Social Choice Welfare, Vol. 2, pp. 393506. Elsevier.
Valiant, L. G. (1979a). complexity computing permanent. Theoretical Computer
Science, 8 (2), 189201.
Valiant, L. G. (1979b). complexity enumeration reliability problems. SIAM
Journal Computing, 8 (3), 410421.
Vickery, W. (1961). Counterspeculation, auctions competitive sealed tenders. Journal
Finance, 837.
Willson, S. J. (2003). Money-egalitarian-equivalent gain-maximin allocations indivisible items monetary compensation. Social Choice Welfare, 20, 247259.
Yang, Z. (2001). intersection theorem unbounded set application fair
allocation problem. Journal Optimization Theory Applications, 110, 429443.
Yengin, D. (2012). Egalitarian-equivalent groves mechanisms allocation heterogenous objects. Social Choice Welfare, 38 (1), 137160.
Young, H. P. (1985). Monotonic solutions cooperative games. International Journal
Game Theory, 14, 6572.
Young, H. P. (1994). Equity Theory Practice. Princeton University Press.

449

fiJournal Artificial Intelligence Research 49 (2014) 241-267

Submitted 08/13; published 02/14

Empirical Evaluation Ranking Measures
Respect Robustness Noise
Daniel Berrar

berrar.d.aa@m.titech.ac.jp

Interdisciplinary Graduate School Science Engineering
Tokyo Institute Technology
4259 Nagatsuta, Midori-ku, Yokohama 226-8502, Japan

Abstract
Ranking measures play important role model evaluation selection. Using
synthetic real-world data sets, investigate different types levels
noise affect area ROC curve (AUC), area ROC convex hull,
scored AUC, Kolmogorov-Smirnov statistic, H-measure. experiments,
AUC was, overall, robust among measures, thereby reinvigorating
reliable metric despite well-known deficiencies. paper also introduces novel
ranking measure, remarkably robust noise yet conceptually simple.

1. Introduction
Various metrics exist evaluate performance predictive model, often
clear one actually choose concrete problem hand (Hand, 2006;
Prati, Batista, & Monard, 2011; Hernandez-Orallo, Flach, & Ferri, 2012; Bradley, 2013;
Parker, 2013). also known different metrics quantify different aspects model
(Caruana & Niculescu-Mizil, 2004; Ferri, Hernandez-Orallo, & Modroiu, 2009). practice,
fair objective comparison predictive models therefore trivial, particularly
data affected noise. Here, consider problem binary classification
ranking problems, pervasive numerous applications (Prati et al., 2011),
ranging web-based recommender systems search engines biomedical classifiers.
goal study investigate robust various ranking measures
different types different levels noise. Particularly, interested robustness
widely used AUC whether recently proposed alternatives, H-measure
(Hand, 2009), indeed preferable. addition, present novel performance measure,
called truncated average Kolmogorov-Smirnov statistic (taKS). measure derived
distance true positive rate (TPR) false positive rate (FPR) curves,
similarly classic Kolmogorov-Smirnov statistic (KS).
Surprisingly experimental studies focused comparison performance measures predictive models. course, different measures may quantify different aspects
model, may make little sense compare across different classes.
make sense compare metrics within class, example, ranking measures
robustness noise. knowledge, comprehensive study date
carried Ferri et al. (2009) investigated relations various performance
measures observed measures essentially measure quite different aspects;
observation also made Caruana Niculescu-Mizil (2004). recent comparative study
c
2014
AI Access Foundation. rights reserved.

fiBerrar

Parker (2013) focused ranking measures; study recommends H-measure
advises AUC. theoretical approach comparison performance
measures found work Flach (2003). Hernandez-Orallo et al. (2012) provide
comprehensive view different measures related other.
summary, main insights following. First, among conventional measures, AUC arguably robust across wide range noise levels types.
result confirms fact, AUC reliable measure, although
criticized incoherent potentially misleading (Hilden, 1991; Lobo, Jimenez-Valverde,
& Real, 2008; Hand, 2009; Hand & Anagnostopoulos, 2013; Parker, 2013). Therefore,
experiments lend empirical support AUC robust measure model
evaluation selection. Second, overall, magnitude differences robustness
commonly used measures dramatic relatively low noise levels.
Third, proposed new measure, taKS, also remarkably robust noise,
conceptually simple neat geometrical interpretation.
paper organized follows. First, briefly review ranking measures
included comparative study. Then, give rationale new measure,
beginning introductory example describing formal details. Section 4,
report results comparative study involving synthetic real-world data
sets. Section 5 concludes paper discussion.

2. Brief Review Investigated Ranking Measures
Let data set contain k instances (or cases) xi , = 1..k. case, exactly one class
associated, i.e., (y, xi ), {0, 1}, 1 denotes positive class 0 denotes
negative class. Commonly, predictive models generate numeric score xi ,
quantifies degree class membership case class, example,
class posterior probability. data set contains positive negative examples,
predictive model either used ranker classifier. scores
expressed ordinal scale, model use scores rank cases
least likely positive. setting threshold ranking score, s(x),
C{s(x) t} = 1, turn ranker (crisp) classifier.
2.1 Area ROC Curve (AUC)
Arguably commonly used ranking measure AUC. used model
selection various applications, ranging data mining competitions biomedical tests
(Berrar & Flach, 2012). AUC area ROC curve, depicts tradeoffs false positive rate (or 1 minus specificity, depicted x-axis)
true positive rate (or sensitivity, depicted y-axis). trade-offs correspond
possible binary classifications dichotomization continuous outputs
model would allow. AUC equivalent Wilcoxon rank-sum statistic (Bamber,
1975; Hanley & McNeil, 1983) interpreted conditional probability: given
randomly selected positive negative case, AUC probability classifier
assigns higher score positive case (i.e., ranks negative case).
Let P denote probability randomly selected actual positive case, x+ ,
higher ranking score, s+ , randomly selected negative case, x , i.e., s+ > . Here,
242

fiAn Empirical Evaluation Ranking Measures Respect Robustness Noise

higher ranking score means x+ ranked x , f (s+ ) g(s )
distribution functions scores (Hilden, 1991). Following Hildens notation, AUC
written
Z

ZZ
AUC = Pr{s+ > |x+ x } =

f (s+ )ds+ g(s )ds =

F (s ) dG(s ).

(1)

s+ >s

AUC calculated different ways empirical ROC curve; practical guide, see tutorial Fawcett (2004). ROC analysis integral part
evaluation machine learning algorithms (Bradley, 1997). Whereas ROC curves widely
(and rightly so) considered useful, theoretical practical shortcomings AUC
pointed (Hilden, 1991; Adams & Hand, 1999; Bengio, Mariethoz, & Keller,
2005; Webb & Ting, 2005; Lobo et al., 2008; Hand, 2009; Hanczar, Hua, Sima, Weinstein,
Bittner, & Dougherty, 2010; Hand & Anagnostopoulos, 2013; Parker, 2013). particular
problem AUC incoherent, sense assumes different
cost distributions different classifiers (Hand, 2009). One first criticisms,
insightful example showing area comparisons misleading, found
work Hilden (1991). Hand (2009), too, considers AUC fundamentally incoherent. Recently, however, Hand Anagnostopoulos (2013) showed AUC coherent
measure, certain assumptions may hold real applications.
2.2 Scored Area ROC Curve (sAUC)
AUC measures well positive negative cases ranked relative
other, consider actual ranking scores. means margin
scores irrelevant. Intuitively, however, seems reasonable take scores
somehow account. Various alternatives AUC suggested
that; example scored AUC (sAUC) (Wu & Flach, 2005; Wu, Flach, & Ferri, 2007).
Let n+ denote total number positive cases n denote total number
negative cases. Let {s1+ , ...sn+ } denote predicted ranking scores positive cases
{s1 , ...sn } denote scores negative cases, s1+ ... sn+
s1 ... sn . si+ sj assumed normalized [0, 1],
= 1, ...n+ j = 1, ...n . Let I() indicator function I(true) = 1
I(f alse) = 0. sAUC defined
n+ n
1 XX
sAUC =
(si+ sj )I(si+ > sj ).
n+ n

(2)

i=1 j=1

indicator function I(si+ > sj ) assesses ranking ability, factor (si+
sj ) evaluates score differences. Without factor, Equation 2 equivalent
AUC. exist variants soft-AUC (Calders & Jaroszewicz, 2007)
probabilistic AUC (pAUC) (Ferri, Flach, Hernandez-Orallo, & Senad, 2005); however,
according Vanderlooy Hullermeier (2008), none proposed alternatives
AUC effective model evaluation. therefore consider variants
comparative analysis.
243

fiBerrar

2.3 Area ROC Convex Hull (AUCH)
ROC convex hull defined convex hull encloses operating points
ROC curve (Provost & Fawcett, 2001; Flach, 2010). Note, curve called convex
straight line interpolating two points curve never curve.1
ROC convex hull results interpolation following k points,
ordered based increasing values abscissa: origin (xi , yi ) = (0, 0),
minimum set points spanning concavities, point (1,1). area
ROC convex hull, AUCH, always least large AUC. AUCH
calculated shown Equation 3.

AUCH =

k1
X

yi (xi+1 xi ) + 0.5(yi+1 yi )(xi+1 xi ).

(3)

i=1

2.4 H-measure
order address incoherence AUC, Hand (2009) proposed H-measure. Let
denote classification threshold, let TPR(t) FPR(t) denote corresponding
true positive false positive rate, respectively. overall misclassification loss
c+ + (1TPR(t))+c (FPR(t)), c+ cost associated misclassification
positive case c cost associated misclassification negative case,
+ prior probabilities positive negative cases, respectively.
R

Hmeasure = 1
+


R

Q(T (c), c)u(c)dc
,
R1
cu(c)dc + (1 c)u(c)dc

(4)



0

c = c+ /(c+ + c ); (c) = arg mint {c+ (1 TPR(t)) + (1 c) FPR(t)}; Q(t, c) =
R1
{c+ (1 TPR(t)) + (1 c) FPR(t)}(c+ + c ); u(c) = c(1 c)/ c(1 c)dc.
0

H-measure measure overall misclassification loss function
class-specific misclassification costs prior probabilities positive negative
cases (Hand, 2009). contrast, AUC measures ranking performance entire
space classification thresholds independent costs class priors. Flach et al.
(2011) showed that, two small variations, H-measure linear transformation
area cost curve, proposed Drummond Holte (2006).
2.5 Kolmogorov-Smirnov Statistic (KS)
Kolmogorov-Smirnov goodness-of-fit test single sample test ordinal data
assesses whether distribution n scores follows specific theoretical empirical
distribution (Sheskin, 2007). test statistic, KS, defined maximum value
absolute difference two cumulative distributions. assess ranking
1. mathematical terms, curve considered concave, whereas standard machine learning
terminology uses convex.

244

fiAn Empirical Evaluation Ranking Measures Respect Robustness Noise

Figure 1: (a) Classification result toy data set 4 cases, (a) optimal model 3
possible thresholds, (b) another model 3 possible thresholds; (c) yet another model,
5 possible thresholds (Real: real class label, 1 = positive class; Score: predicted score
positive class).

ability classifier, distributions given true positive rates false
positive rates classification thresholds. KS statistics simple geometrical
interpretation maximum distance TPR FPR curves,

KS = max{|TPRi FPRi |},

(5)

TPRi FPRi denote true positive rate false positive rate ith
threshold, respectively (see Figure 2 example).

3. Truncated Average Kolmogorov-Smirnov Statistic (taKS)
section, propose new ranking measure, called truncated average KolmogorovSmirnov statistic (taKS).
3.1 Introductory Example
Let us consider prediction results arbitrary test set comprising k cases,
belong either positive negative class. optimal model assign score
1 positive score 0 negative case. Consider another model
assigns scores s1 , s2 ...sk k test cases, s1 s2 ... sk , also
happen lead perfect ranking. Figure 1 illustrates idea using toy data set
k = 4 cases. models example indeed ranking performance,
consequently, ranking measures like AUC distinguish them.
nothing wrong matters relative ordering cases, irrespective
actual ranking scores. Note, optimal model always allows exactly three
possible thresholds: (1) one threshold separating positive negative cases (t2
Figure 1a); (2) one top threshold (i.e., TPR = 0 FPR = 0; t1 Figure 1a); (3)
one bottom threshold (i.e., TPR = 1 FPR = 1; t3 Figure 1a).
Assume three models enter data mining competition. Let us
assume we, judges, see final predictions shown Figure 1.
information models calibration scores,
except higher scores reflect relative confidence case belongs positive
class. assumptions shall allowed now.
245

fiBerrar

probably agree model (a) winner, one runnerup, (b) (c)? answer question, could consider ranking scores, example,
calculating sum squared errors (SSE) related measure Brier score.
approach would tell us model (c) SSE = 0.18 preferable model (b)
SSE = 0.50. However, approach makes tacit assumption models, (b)
(c), produce comparable scores range, maybe posterior probabilities [0, 1].
course often reasonable assumption, necessarily
case. addition, assumption actually allowed.
allowed assumptions calibration? Let us speculate
design model (b) could produced probabilities larger 0.7 smaller
0.4. Based minimum message length theory, may indeed make sense prevent
model making overly confident predictions, example, limiting estimates
specific range (Korb, Hope, & Hughes, 2001).2 particular assumption,
may look performance model (b) new light. fact, difference
scores (a) (b) reduces merely different scaling. Could model (b)
careful model? Granted, assumption scores comparable (e.g.,
[0, 1]) plausible. point take actual scores account,
make assumptions models calibrations. Furthermore,
scores model (c) higher level granularity model (b), might
say model (c) refined coarser model (b). refinement
necessarily indicate better model?
Let us look another difference models: number possible
thresholds. number depends refinement scores, actual
values. idea combine number ranking performance.
3.2 Formal Details
Visually, represent class discrimination plotting true positive
false positive rates function threshold diagram. interpolating
points, obtain corresponding TPR FPR curves (henceforth referred
TPR-FPR plot, also known Kolmogorov-Smirnov chart).
Figure 2 illustrates TPR-FPR curves toy data set. test case
threshold classified positive case. instance, threshold t6 leads 4 true
positive 1 false positive classifications 4 positive cases 1 negative case
located threshold; corresponding rates TPR = 54 FPR = 15 (Figure 2b).
Class discrimination could quantified terms area curves (ABC).
Definition 1. Area curves
area curves (ABC) area TPR curve FPR curve,
result interpolating true positive false positive rates based n
2. reason overly confident predictions turn incorrect lead dramatic
information-theoretic penalty; example, penalty incorrect prediction confidence 1
. Korb et al. (2001), example, allowed range [min, max] = [0.5(n + 1)1 , (n + 0.5)(n + 1)1 ],
n number test cases.

246

fiAn Empirical Evaluation Ranking Measures Respect Robustness Noise

Figure 2: (a) example binary classification task involving ten test cases. (b)
ranking scores allow 11 classification thresholds, corresponding one TPR one
FPR point. Interpolation points gives TPR FPR curves. distance
curves maximal t6 .

possible thresholds,
Zn
ABC = |

Zn
TPR(x)dx

1

FPR(x)dx|.

(6)

1

Note, absolute value necessary accept model could also perform
worse random guessing, means FPR curve could TPR
curve, thereby leading negative value ABC. remainder paper,
work signed ABC, though. Applying trapezoidal rule, obtain

ABC =

n1
X
i=1
n1
X

1
TPRi (xi+1 xi ) + (TPRi+1 TPRi )(xi+1 xi )
2

1
FPRi (xi+1 xi ) + (FPRi+1 FPRi )(xi+1 xi )
2
i=1


n1
X
1
1
=
(xi+1 xi ) TPRi + (TPRi+1 TPRi ) FPRi (FPRi+1 FPRi )
2
2



=

i=1
n1
X

1
2

(xi+1 xi ) [(TPRi FPRi ) + (TPRi+1 FPRi+1 )],

i=1

247

fiBerrar

TPRi FPRi denote true positive rate false positive rate ith
threshold, respectively. require thresholds abscissa equidistant
[0, 1], first threshold linearly mapped 0 last threshold, n, mapped
1
. Denoting j = + 1,
1 (this condition relaxed later). (xi+1 xi ) = n1
obtain

ABC =

n1

n1

i=1

j=2

1 X
1 X
(TPRi FPRi ) +
(TPRj FPRj ).
2n 2
2n 2

Note, true positive false positive rates always zero first threshold,
TPR1 = FPR1 = 0, obtain
n1

ABC =

1 X
(TPRi FPRi )
n1

(7)

i=2

Consider optimal model assigns score 1 cases class 1 score
0 cases class 0. Here, n = 3, ABC = 12 (1 0) = 12 . possible
another, suboptimal model larger ABC. example, assume ranking score
= 2 ranked positive case identical score = 1 ranked positive case.
Figure 3c shows example suboptimal model ABC > 0.5. Thus, model
evaluation selection, ABC used directly.
1
However, use ABC derive performance measure. Consider factor n1
Equation 7. replacing 1 denominator 2, obtain average
distances points spanning TPR FPR curves, excluding start-point
end-point. consider new measure, value optimal model
always 1, model score higher. immediately obvious
thresholds abscissa scaled [0, 1], FPR TPR ordinate
range 0 1. area within boundaries cannot larger 1. Thus,
distance pair (TPRi ,FPRi ) cannot larger 1, therefore average
distances cannot larger 1.
Definition 2. Truncated average Kolmogorov-Smirnov statistic (taKS)
Let model produce ranking scores sa R, = 1..k k test cases belonging either
positive negative class, sa1 sa sa+1 sa , sb : 6= b sa 6= sb . Let n > 2
denote number possible thresholds ti , ti1 < ti < ti+1 , scores allow. Let
TPRi FPRi denote true positive false positive rates, respectively, result
particular threshold ti . taKS defined average distances
true positive rates false positive rates, excluding points (0,0)
(1,1),
n1

1 X
taKS =
(TPRi FPRi ).
n2
i=2

248

(8)

fiAn Empirical Evaluation Ranking Measures Respect Robustness Noise

Note, relax condition thresholds x-axis
equidistant [0, 1]. matters taKS distances points
spanning TPR FPR curves; scaling x-axis irrelevant. pseudocode
deriving taKS given Appendix (algorithm 1).
3.3 Illustration taKS
Figure 3 shows TPR-FPR plots resulting taKS nine different prediction
results. scores models Figure 3a-b different, relative order
cases same, models ranking performance. Here, taKS 1.0
optimal model (Figure 3a), 0.556 model allowing 11 thresholds (Figure 3b),
0.600 model allowing 10 thresholds. examples also illustrate using
ABC misleading: would erronously prefer model Figure 3c ABC
= 0.533 optimal model ABC = 0.500.
scores (b) (c) different case #1. Model (b) predicted 0.95
whereas model (c) predicted 0.80. Provided models equally calibrated, one
could argue (b) better (has smaller SSE), taKS therefore misleading.3
reasoning plausible, opposite could also happened. Suppose
model (c) produces 0.95 cases #1 #2. value taKS remains
(i.e., 0.60), points us better model. Either scenario equally likely
priori, correct incorrect decisions balance, average, example.
means half time, taKS points us better model. Note, AUC
indifferent examples, making difference (b) (c) either scenario.
used AUC, could guess one better, (b) (c); thus, would
correct half time, too. Consequently, compared AUC (or
ranking measure, matter), taKS provide advantage example
provide disadvantage, either.
Figure 3d-f shows three models make ranking errors. models
ranking performance, score different taKS. model Figure 3e scores
larger taKS model Figure 3f. model Figure 3e assigned score
(0.80) cases #1 #2; model Figure 3f assigned score (0.60)
cases #4 #5. models allow number thresholds (i.e., 10),
taKS identifies model Figure 3e preferable one larger ABC.
Figure 3g-i show three particular models. model Figure 3g perfect antimodel predicts like mirror image optimal model. Consequently, resulting
taKS 1. Another particular model shown Figure 3h. model assigns
score cases; thus, allows two possible thresholds, TPR FPR
curves fall onto line. ABC defined, taKS defined,
either. Figure 3i shows results random prediction, leading taKS ABC
zero. Note, AUC defined Figure 3h; AUC 0.5
AUC Figure 3i.

3. Thanks anonymous reviewer pointing out!

249

fiBerrar

Figure 3: TPR (red) FPR (black) curves taKS nine classification results (cf.
inset table). (a) Best possible predictions 3 possible thresholds; (b) perfect ranking
11 possible thresholds; (c) perfect ranking 10 possible thresholds; (d) prediction
ranking errors 11 possible thresholds; (e) prediction ranking errors 10
possible thresholds; (f) prediction ranking errors 10 possible thresholds; (g) worst
possible prediction 3 possible thresholds; (h) cases ranking score,
neither ABC taKS defined; (i) random prediction 5 possible thresholds.

250

fiAn Empirical Evaluation Ranking Measures Respect Robustness Noise

3.4 Notes taKS
name implies, taKS closely related Kolmogorov-Smirnov (KS) statistic,
i.e., maximum distance TPR FPR curves (cf. Equation 5). contrast,
taKS average distance curves, excluding start- endpoint
(0,0) (1,1), respectively. introductory example (Figure 2), KS = 35 (for
threshold t6 ) taKS = 13 .
optimal model, scores 1 positive cases 0 negative cases,
taKS = 1. Also, model assigns score s+ positive
score negative cases taKS = 1. Thus, taKS distinguish
optimal model another model that, say, assigns 0.7 positive cases 0.4
negative cases. worst-possible model (i.e., one assigns 1 cases
class 0 0 cases class 1), taKS = 1. expected value taKS random
model 0. model assigns score cases, taKS defined
number possible thresholds n = 2, would lead division zero
Equation 8. Graphically, TPR FPR curves straight lines (0,0)
(1,1). Note, conventional ranking measures AUC defined
case.
Like AUC, taKS aggregate measure performance final classification
result. advantage ROC plots visualize performance
one classifier diagram, contrast TPR-FPR plots used
paper. limitation taKS following. two models equally calibrated,
scenarios taKS larger model larger SSE, thereby leading
us potentially inferior model (for examle, cf. Figure 3b-c). average, however,
scenarios balance scenarios opposite case.

4. Robustness Analysis
considered synthetic real-world data sets study robustness ranking
measures various types levels noise. adopted approach similiar one
described Ferri et al. (2009). main idea same: consider two models, C1
C2 , C1 truly better model. Then, progressively added noise.
question whether performance measures still identify C1 better model.
measure Xi considered robust another measure Xj Xi less affected
increasing levels noise. Below, describe different types noise
investigated experiments. experiments described pseudocode Appendix
carried R2.10.1 (R Development Core Team, 2009).
4.1 Synthetic Data Sets
considered predictions two classifiers, C1 C2 , hypothetical test set
comprising 100 cases, described Ferri et al. (2009). number test cases
arguably little influence experiments, provided small.
generated vector 100 real numbers randomly sampling uniform distribution
[0, 1], represent ranking scores positive class. membership scores
interpreted class posterior probabilities. positive class label assigned
251

fiBerrar

numbers 0.5, negative class label assigned remaining numbers.
Next, randomly selected 10 scores replaced real number,
randomly sampled [0, 1]. resulting numbers represented predictions C1 .
threshold 0.5, expected accuracy C1 95% expect half
new scores (i.e., 5 10) wrong.
predictions C2 C1 , except selected 10
predictions random replaced real number, randomly sampled
[0, 1]. Thus, without noise, C2 expected perform worse C1 , expected
accuracy 90%. difference two classifiers, however, expected
become blurred increasing levels noise.
considered three types noise: misclassification noise, probability noise, class
proportion noise (described below). level noise, generated model, C1
C2 , n = 10000 times, time evaluating performance based different ranking
measures. measure, counted many times erroneously indicated
C2 better C1 . Let X() denote value performance measure X
classifier. error rate measure X given


1
X(C2 ) > X(C1 )




n

1X
0.5 X(C2 ) = X(C1 )
(X) =
(X), (X) =

n

i=1



0
X(C2 ) < X(C1 )

(9)

plotting (X) measures function noise level, compare
resilience noise. example, measure Xi robust measure Xj ,
error rate Xi consistently lower; hence, curve Xi
curve Xj .
4.1.1 Misclassification Noise
First, considered noise affects class labels. experiment evaluates
sensitive measures respect mislabelings. investigated noise levels ranging
0% (i.e., class label altered) 100% (i.e., class label altered
determined flip coin). noise level 0%, expect error scores
0 C1 clearly better C2 . contrast, class labels random,
expect difference models, error score around 0.5.
class label noise 0% 70% (Figure 4), error rates
H-measure Kolmogorov-Smirnov statistic slightly
measures. AUCH slightly robust AUC taKS less robust
H-measure Kolmogorov-Smirnov statistic. sAUC least robust
experiment. Overall, however, see dramatic differences measures.
expected, measures around 0.5 noise level 100%. error rates
AUC taKS virtually identical experiment.
252

fiAn Empirical Evaluation Ranking Measures Respect Robustness Noise

Figure 4: Synthetic data, experiment #1. Robustness misclassification noise.

4.1.2 Probability Noise
noise affects class membership scores. experiment evaluates sensitive
measures posterior class probabilities well estimated. noise
randomly sampled uniform distribution [x, x], x ranged 0 (i.e.,
noise) 0.5 (i.e., 100% noise) stepsize 0.005. noise added ranking
scores.
noise affects class posterior probabilities (Figure 5), sAUC performs
worst. Kolmogorov-Smirnov statistic next least robust, followed Hmeasure. AUC taKS robust experiment; error rates
almost identical. AUCH slightly less robust two measures.
4.1.3 Class Proportion Noise
noise affects class proportions. experiment evaluates sensitive measures changes class distribution drifts. changed class frequencies
progressively deleting x% cases positive class. noise x% ranged 5%
95%.
noise affects class frequencies (Figure 6), measures except sAUC perform similarly. AUC, AUCH, H-measure, KS, taKS, error rates remarkably low noise levels around 80%. Thus, contrast sAUC, measures
cope quite well even classes heavily imbalanced.
253

fiBerrar

Figure 5: Synthetic data, experiment #2. Robustness probability noise.
4.2 Real-World Data Sets
experiments synthetic data sets, investigated wide range noise levels,
including arguably unrealistically high real-world data sets. Therefore,
limited next experiments noise level neither small cause
noticeable effect large unrealistic. assumed noise level 10% would
meet requirement.
experiments synthetic data sets, observed class proportion
noise little effect performance measures, except unrealistically high noise
levels. Therefore, excluded type noise following experiments. Instead,
considered new type noise could study before: attribute noise, affects
attributes either training set entire data set.
used naive Bayes learning construct base classifier. concrete learning
algorithm assumed little influence experimental results. denoted
predicted scores classifier C1 . randomly selected 10% scores
replaced score random number, uniformly sampled [0, 1].
result C2 . Without noise, C1 clearly better corrupted competitor, C2 .
used ten benchmark data sets UCI repository (Bache & Lichman, 2013).
Experiment #1: Misclassification Noise Affecting Entire Data Set
first experiment, investigated resilience noise affecting class labels
entire data set. data set, selected 10% class labels randomly
254

fiAn Empirical Evaluation Ranking Measures Respect Robustness Noise

Figure 6: Synthetic data, experiment #3. Robustness class proportion noise.

assigned either positive negative label. Then, compared performance C1
C2 10-fold cross-validation. repeated experiment 1000 times recorded
many times C2 declared better model respective ranking measure (see
Appendix A, algorithm 2).
Experiment #2: Misclassification Noise Affecting Training Set
second experiment, investigated resilience noise affecting class labels
training set. training set, selected 10% class labels randomly
assigned either positive negative label. Then, compared performance C1
C2 10-fold cross-validation. repeated experiment 1000 times recorded
many times C2 declared better model respective ranking measure (see
Appendix A, algorithm 3).
Experiment #3: Attribute Noise Affecting Entire Data Set
third experiment, investigated resilience noise affecting attribute values entire data set. data set attribute, selected 10%
values randomly permuted them. Then, compared performance C1 C2
10-fold cross-validation. repeated experiment 1000 times recorded many
times C2 declared better model respective ranking measure (see Appendix
A, algorithm 4).

255

fiBerrar

Experiment #4: Attribute Noise Affecting Training Set
fourth experiment, investigated resilience noise affecting attribute values training set only. training set attribute, selected 10%
values randomly permuted them. Then, compared performance C1 C2
10-fold cross-validation. repeated experiment 1000 times recorded many
times C2 declared better model respective ranking measure (see Appendix
A, algorithm 5).

Table 1 shows error rates ranking measures real-world data sets.
make several interesting observations. First, data sets, error rates
performance measures relatively small drastically different other.
exception sAUC, whose error rates indeed remarkably high (between 64.8%
78.3%) data sets Liver Transfusion four experiments. Liver
Transfusion data sets 6 4 attributes, respectively, comparatively
difficult classify data sets.4 data sets Liver Transfusion,
error rates highest four experiments, whereas error rates virtually
neglibile data set Credit. speculate data sets intrinsically
easy classify, injected noise negligible effect ranking measures.
data set easy classify, expect classifier produces scores close
0 1, fewer scores around 0.5. Now, created C2 randomly selecting
scores C1 re-assigning random number [0, 1] scores. means
expect larger number extreme scores (which likely
correct, classification tasks relatively easy) mapped less extreme scores.
Consequently, quite easy identify C1 better model, regardless whichever
measure used. contrast, data set intrinscically difficult classify,
even tiny amounts added noise may wreak havoc. seems case sAUC
particular. Note, sAUC implicitly rewards classifiers boldness: sAUC
classifier scores close 0 1 larger sAUC classifier
less extreme scores, although latter may make fewer ranking errors; Vanderlooy
Hullermeier (2008, p.252) give illustrative example.
Second, error rates are, overall, higher noise affects entire data sets
error rates noise affects training sets. unexpected
latter case, portion original data remains intact.
Third, overall, observe positive correlation measures, differences error rates remarkable data sets. example, experiment #2,
error rate H-measure (10.9%) three times error rate AUC
(3.3%) data set Spect; hand, error rate AUC (1.4%) seven
times H-measure (0.2%) data set House. Interestingly, H-measure
has, average, slightly higher error rates AUC taKS noise affects
class labels. somewhat unexpected H-measure performed relatively
well corresponding experiments synthetic data sets (Figure 4). However,
differences average error rates relatively small might perhaps explained
4. checked analyzing (uncorrupted) data sets 100 times repeated 10-fold cross-validation.
naive Bayes classifier achieved lowest AUC Liver Transfusion.

256

fiAn Empirical Evaluation Ranking Measures Respect Robustness Noise

Experiment #1

Experiment #2

Experiment #3

Experiment #4

Sonar
Spect
Heart
Liver
Ionosphere
House
Cylinder
Credit
Transfusion
Pima
Sonar
Spect
Heart
Liver
Ionosphere
House
Cylinder
Credit
Transfusion
Pima
Sonar
Spect
Heart
Liver
Ionosphere
House
Cylinder
Credit
Transfusion
Pima
Sonar
Spect
Heart
Liver
Ionosphere
House
Cylinder
Credit
Transfusion
Pima

H-measure
10.30
13.90
1.50
18.10
0.40
0.20
0.40
0.00
5.50
0.40
5.30
10.90
0.30
16.50
0.00
0.20
0.00
0.00
3.40
0.10
8.00
8.80
0.50
18.40
0.10
0.00
0.30
0.00
3.90
0.10
5.50
12.10
0.50
14.90
0.10
0.00
0.00
0.00
2.50
0.10

AUC
8.80
8.90
1.80
16.70
0.70
1.50
1.00
0.00
3.40
0.00
4.80
3.30
0.20
13.20
0.00
1.40
0.10
0.00
0.90
0.00
6.30
3.50
0.90
15.60
0.30
0.00
0.20
0.00
2.10
0.00
4.50
4.00
0.90
13.40
0.00
0.00
0.00
0.00
1.50
0.10

AUCH
11.70
9.60
1.70
17.50
0.80
1.20
1.20
0.00
4.60
0.10
6.70
4.50
0.30
14.00
0.00
1.30
0.10
0.00
1.30
0.00
8.10
3.40
0.70
16.80
0.30
0.00
0.30
0.00
3.00
0.00
5.80
5.20
0.70
13.70
0.00
0.00
0.10
0.00
2.00
0.10

sAUC
10.70
2.80
0.10
70.20
0.00
0.00
7.90
0.10
78.30
0.10
6.30
0.70
0.00
66.50
0.00
0.00
2.90
0.00
69.80
0.10
6.00
1.40
0.10
64.80
0.00
0.00
2.50
0.10
74.60
0.00
5.40
1.20
0.00
65.90
0.00
0.00
5.10
0.00
70.80
0.20

KS
12.05
11.20
1.60
19.30
0.50
0.10
0.80
0.00
7.30
1.00
7.15
6.95
0.70
17.10
0.10
0.20
0.10
0.00
2.90
0.30
9.40
6.90
1.00
21.00
0.10
0.00
0.70
0.00
3.80
0.20
5.85
7.10
0.80
17.20
0.20
0.00
0.30
0.00
2.80
0.10

taKS
7.00
8.80
1.80
16.80
0.50
1.00
0.80
0.00
3.20
0.00
3.40
2.80
0.20
13.20
0.00
1.10
0.00
0.00
0.70
0.00
4.30
2.90
0.90
15.60
0.30
0.00
0.00
0.00
1.70
0.00
3.20
3.40
0.90
13.50
0.00
0.00
0.00
0.00
1.50
0.10

Table 1: Error rates [%] ranking measures. Experiment #1: 10% class labels
data set randomly assigned; Experiment #2: 10% class labels
training set randomly assigned; Experiment #3: 10% values attribute
randomly permuted data set; Experiment #4: 10% values
attribute randomly permuted training set. data set analyzed 1000
times 10-fold cross-validation. Lowest error rates shown boldface.

257

fiBerrar

statistical fluctuations. alternative explanation experiments synthetic
data, ranking scores [0, 1] equally likely. experiments real-world
data sets, however, case. data sets relatively easy classify.
Therefore, expect see scores concentrated towards 1 0 fewer scores
around 0.5, might negative effect H-measure; however,
speculation.

5. Discussion Conclusions
Ranking measures play important role model evaluation selection. Using
synthetic real-world data sets, compared robustness various ranking measures
different types levels noise. AUC recently criticized incoherent
measure (Hand, 2009; Hand & Anagnostopoulos, 2013; Parker, 2013); nonetheless,
arguably robust among conventional measures experiments.
important finding, lends empirical credibility AUC complements
recently published vindications (Flach, Hernandez-Orallo, & Ferri, 2011; Hernandez-Orallo
et al., 2012; Bradley, 2013). AUC also robust sAUC, confirms
observations Vanderlooy Hullermeier (2008) sAUC efficient
alternative AUC.
experiments synthetic data sets, KS H-measure performed best
misclassification noise. probability noise, however, performed worse
AUC AUCH. metrics except sAUC performed less similarly
class proportion noise. Overall, differences metrics respect
resilience noise rather small relatively low noise levels synthetic data. Also,
investigated real-world data sets, magnitude difference arguably
dramatic. sAUC used caution, though, performed
poorly experiments synthetic data (notably class proportion noise, Figure 6)
experiments difficult real-world data sets (Liver, Transfusion).
observations confirm earlier results, showed sAUC robust
noise (Ferri et al., 2009).
experiments allow conclusion H-measure preferable
AUC respect robustness. Also, believe H-measure arguably
intricate measures, geometrical interpretation straightforward AUC. course mean H-measure useful
AUC always trusted. Hilden (1991) describes interesting example
AUC fact misleading. Also, note Parker (2013) comes conclusion
different ours: recommends H-measure, empirical theoretical
grounds. However, Parker evaluated measure based (dis-)agreement
measures, based robustness noise.
also proposed novel ranking measure, called taKS. key characteristic
measure simplicity. taKS easily derived, simple geometrical interpretation average distance two curves: true positive false positive
rate curve, plotted function classification threshold. study, taKS
remarkably robust noise. However, caution arguments AUC
(Hilden, 1991; Hand, 2009; Hand & Anagnostopoulos, 2013) dismissed light258

fiAn Empirical Evaluation Ranking Measures Respect Robustness Noise

heartedly. Particularly, Parker (2013) recently extended Hands analysis, showing
related metrics (the area Cohens curve average precision) similarly incoherent. According Parkers theorem 1, problem measures result
integration possible classification thresholds. taKS measured via normalized
summation, could similarly incoherent. experimental results promising,
research needed elucidate usefulness taKS. Many open questions remain,
example, precise relation taKS measures, example,
partial AUC (McClish, 1989)? taKS (in-)coherent? particularly,
role data set idiosyncrasies selection ranking measure? also remember results empirical studies viewed isolation
backdrop previous research. AUC remarkably robust experiments,
successfully used numerous studies; addition, recently vindicated
theoretically (Hernandez-Orallo et al., 2012). Taken together, therefore conclude
AUC might still good choice practical applications.
Finally, note investigated metrics share important caveat: scalars,
cannot paint full picture classifiers performance. condensing performance
single number, bound lose important information behavior
model range operating conditions, generally better described twodimensional plots ROC curves. One always wary reading much
single number. single number misleading. hand, scalars
obvious advantage allow us tabulate results various classifiers easily.
desirable compare large number models, generally case
data mining competitions, example.

Acknowledgments
thank three anonymous reviewers much detailed constructive
comments greatly helped improve manuscript.

259

fiBerrar

Appendix A. Pseudocodes
Algorithm 1 Pseudocode taKS.
Require: matrix X k rows (one test case) 2 columns (first column: real class
label; second column: predicted score positive class, s+ ). X ordered based decreasing
values s+ ; least two scores must different. # scores identical taKS
defined.
1: TPR, FPR < 0 > # lists, containing one element: 0
2: tp, fp 0
3: np number positive cases X; nn number negative cases X
4: 1
5: (i number rows X)
6: threshold
7: ii
8: scorei s+ ith case
9:
(scoreii+1 == scorei ) (ii +1 number cases X)
10:
threshold threshold + 1
11:
ii ii + 1
12:
end
13: tp number positive cases threshold
14: fp number negative cases threshold
15: push tp/np onto TPR; push fp/nn onto FPR
16: threshold + 1
17: end
18: taKS mean(TPR\{first, last} FPR\{first, last})
19: return taKS

260

fiAn Empirical Evaluation Ranking Measures Respect Robustness Noise

Algorithm 2 Real-world data set, experiment #1. Corrupt 10% class labels
data set
Require: data set
1: = 1 1000
2: Randomly select 10% cases randomly assign class label.
3:
k = 1 10
4:
Sample k-th training k-th test set corrupted D.
5:
Build naive Bayes classifier k-th training set.
6:
Apply classifier k-th test set obtain output C1k .
7:
Derive Xk (C1k ).
8:
Randomly select 10% prediction scores C1k .
9:
Replace selected score random number [0, 1] obtain C2k .
10:
Derive Xk (C2k ).
11:
end
12:
X(C1 ) average Xk (C1k ).
13:
X(C2 ) average Xk (C2k ).
14:
X(C2 ) > X(C1 )
15:
(X) (X) + 1
16:
else
17:
X(C2 ) == X(C1 )
18:
(X) (X) + 0.5
19:
else
20:
(X) (X) + 0
21:
end
22:
end
23: end
24: return (X)

261

fiBerrar

Algorithm 3 Real-world data set, experiment #2. Corrupt 10% class labels per
training set
Require: data set
1: = 1 1000
2:
k = 1 10
3:
Sample k-th training k-th test set D.
4:
Randomly select 10% training cases.
5:
Randomly assign class label selected cases.
6:
Build naive Bayes classifier k-th corrupted training set.
7:
Apply classifier k-th test set obtain output C1k .
8:
Derive Xk (C1k ).
9:
Randomly select 10% prediction scores C1k .
10:
Replace selected score random number [0, 1] obtain C2k .
11:
Derive Xk (C2k ).
12:
end
13:
X(C1 ) average Xk (C1k ).
14:
X(C2 ) average Xk (C2k ).
15:
X(C2 ) > X(C1 )
16:
(X) (X) + 1
17:
else
18:
X(C2 ) == X(C1 )
19:
(X) (X) + 0.5
20:
else
21:
(X) (X) + 0
22:
end
23:
end
24: end
25: return (X)

262

fiAn Empirical Evaluation Ranking Measures Respect Robustness Noise

Algorithm 4 Real-world data set, experiment #3. Corrupt 10% attribute values
data set
Require: data set
1: = 1 1000
2: Randomly select 10% values attribute D.
3: Randomly permute selected values per attribute.
4:
k = 1 10
5:
Sample k-th training k-th test set corrupted D.
6:
Build naive Bayes classifier k-th corrupted training set.
7:
Apply classifier k-th test set obtain output C1k .
8:
Derive Xk (C1k ).
9:
Randomly select 10% prediction scores C1k .
10:
Replace selected score random number [0, 1] obtain C2k .
11:
Derive Xk (C2k ).
12:
end
13:
X(C1 ) average Xk (C1k ).
14:
X(C2 ) average Xk (C2k ).
15:
X(C2 ) > X(C1 )
16:
(X) (X) + 1
17:
else
18:
X(C2 ) == X(C1 )
19:
(X) (X) + 0.5
20:
else
21:
(X) (X) + 0
22:
end
23:
end
24: end
25: return (X)

263

fiBerrar

Algorithm 5 Real-world data set, experiment #4. Corrupt 10% attribute values
per training set
Require: data set
1: = 1 1000
2:
k = 1 10
3:
Sample k-th training k-th test set D.
4:
training set only: select 10% values attribute.
5:
Randomly permute selected values per attribute.
6:
Build naive Bayes classifier k-th corrupted training set.
7:
Apply classifier k-th test set obtain output C1k .
8:
Derive Xk (C1k ).
9:
Randomly select 10% prediction scores C1k .
10:
Replace selected score random number [0, 1] obtain C2k .
11:
Derive Xk (C2k ).
12:
end
13:
X(C1 ) average Xk (C1k ).
14:
X(C2 ) average Xk (C2k ).
15:
X(C2 ) > X(C1 )
16:
(X) (X) + 1
17:
else
18:
X(C2 ) == X(C1 )
19:
(X) (X) + 0.5
20:
else
21:
(X) (X) + 0
22:
end
23:
end
24: end
25: return (X)

264

fiAn Empirical Evaluation Ranking Measures Respect Robustness Noise

References
Adams, N., & Hand, D. (1999). Comparing classifiers misallocation costs
uncertain. Pattern Recognition, 32 (7), 11391147.
Bache, K., & Lichman, M. (2013).
UCI machine learning repository.
[http://archive.ics.uci.edu/ml]. Irvine, CA: University California, School
Information Computer Science.
Bamber, D. (1975). area ordinal dominance graph area
receiver operating characteristic curve. Journal Mathematical Psychology, 12, 387
415.
Bengio, S., Mariethoz, J., & Keller, M. (2005). expected performance curve. Proceedings
ICML 2005 workshop ROC Analysis Machine Learning, 916.
Berrar, D., & Flach, P. (2012). Caveats pitfalls ROC analysis clinical microarray
research (and avoid them). Briefings Bioinformatics, 13 (1), 8397.
Bradley, A. (1997). use area ROC curve evaluation machine
learning algorithms. Pattern Recognition, 30 (3), 11451159.
Bradley, A. (2013). ROC curve equivalence using Kolmogorov-Smirnov test. Pattern
Recognition Letters, 34 (5), 470475.
Calders, T., & Jaroszewicz, S. (2007). Efficient AUC optimization classification. Kok,
J., Koronacki, J., de Mantaras, R., Matwin, S., Mladenic, D., & Skowron, A. (Eds.),
Proceedings 11th European Conference Principles Practice Knowledge
Discovery Databases, pp. 4253. Springer.
Caruana, R., & Niculescu-Mizil, A. (2004). Data mining metric space: empirical
analysis supervised learning performance criteria. Proceedings 10th ACM
SIGKDD International Conference Knowledge Discovery Data Mining, pp.
6978. ACM Press.
Drummond, C., & Holte, R. (2006). Cost curves: improved method visualizing
classifier performance. Machine Learning, 65, 95130.
Fawcett, T. (2004). ROC graphs: Notes practical considerations researchers. Kluwer
Academic Publishers, 138.
Ferri, C., Flach, P., Hernandez-Orallo, J., & Senad, A. (2005). Modifying ROC curves
incorporate predicted probabilities. Proceedings 2nd Workshop ROC
Analysis Machine Learning. Bonn, Germany.
Ferri, C., Hernandez-Orallo, J., & Modroiu, R. (2009). experimental comparison
performance measures classification. Pattern Recognition Letters, 30, 2738.
Flach, P. (2003). geometry ROC space: understanding machine learning metrics
ROC isometrics. Proceedings 20th International Conference
Machine Learning, pp. 194201. AAAI Press.
Flach, P. (2010). ROC analysis. Sammut, C., & Webb, G. (Eds.), Encyclopedia
Machine Learning, pp. 869874. Springer.
265

fiBerrar

Flach, P., Hernandez-Orallo, J., & Ferri, C. (2011). coherent interpretation AUC
measure aggregated classification performance. Proceedings 28th
International Conference Machine Learning, pp. 6978.
Hanczar, B., Hua, J., Sima, C., Weinstein, J., Bittner, M., & Dougherty, E. (2010). Smallsample precision ROC-related estimates. Bioinformatics, 26, 822830.
Hand, D. (2006). Classifier technology illusion progress. Statistical Science,
21 (1), 114.
Hand, D. (2009). Measuring classifier performance: coherent alternative area
ROC curve. Machine Learning, 77, 103123.
Hand, D., & Anagnostopoulos, C. (2013). area receiver operating characteristic curve appropriate measure classifier performance?. Pattern
Recognition Letters, 34 (5), 492495.
Hanley, J., & McNeil, B. (1983). method comparing areas receiver operating
characteristic curves derived cases. Radiology, 148 (3), 839843.
Hernandez-Orallo, J., Flach, P., & Ferri, C. (2012). unified view performance metrics:
Translating threshold choice expected classification loss. Journal Machine
Learning Research, 13, 28132869.
Hilden, J. (1991). area ROC curve competitors. Medical Decision
Making, 11 (2), 95101.
Korb, K., Hope, L., & Hughes, M. (2001). evaluation predictive learners:
theoretical empirical results. DeRaedt, L., & Flach, P. (Eds.), Lecture Notes
Artificial Intelligence, pp. 276287. Springer.
Lobo, J., Jimenez-Valverde, A., & Real, R. (2008). AUC: misleading measure
performance predictive distribution models. Global Ecology Biogeography, 17,
145151.
McClish, D. (1989). Analyzing portion ROC curve. Medical Decision Making, 9 (3),
190195.
Parker, C. (2013). measuring performance binary classifiers. Knowledge
Information Systems, 35, 131152.
Prati, R., Batista, G., & Monard, M. (2011). survey graphical methods classification predictive performance evaluation. IEEE Transactions Knowledge Data
Engineering, 23 (11), 16011618.
Provost, F., & Fawcett, T. (2001). Robust classification imprecise environments. Machine
Learning, 42 (3), 203231.
R Development Core Team (2009). R: Language Environment Statistical Computing. R Foundation Statistical Computing, Vienna, Austria. ISBN 3-900051-07-0.
Sheskin, D. (2007). Handbook Parametric Nonparametric Statistical Procedures. 4th
Edition, Chapman Hall, London/New York.
Vanderlooy, S., & Hullermeier, E. (2008). critical analysis variants AUC. Machine
Learning, 72, 247262.
266

fiAn Empirical Evaluation Ranking Measures Respect Robustness Noise

Webb, G., & Ting, K. (2005). application ROC analysis predict classification
performance varying class distributions. Machine Learning, 58 (1), 2532.
Wu, S., & Flach, P. (2005). scored AUC metric classifier evaluation selection.
Proceedings Second Workshop ROC Analysis Machine Learning.
Wu, S., Flach, P., & Ferri, C. (2007). improved model selection heuristic AUC.
Kok, J., Koronacki, J., de Mantaras, R., Matwin, S., Mladenic, D., & Skowron, A.
(Eds.), Proceedings 18th European Conference Machine Learning (ECML
2007), pp. 478489. Springer.

267

fiJournal Artificial Intelligence Research 49 (2014) 111-142

Submitted 10/13; published 02/14

Towards Minimizing Disappointment Repeated Games
Jacob W. Crandall

JCRANDALL @ MASDAR . AC . AE

Masdar Institute Science Technology
Abu Dhabi, United Arab Emirates

Abstract
consider problem learning repeated games arbitrary associates. Specifically, study ability expert algorithms quickly learn effective strategies repeated
games, towards ultimate goal learning near-optimal behavior arbitrary associate
within handful interactions. contribution three-fold. First, advocate new
metric, called disappointment, evaluating expert algorithms repeated games. Unlike minimizing traditional notions regret, minimizing disappointment repeated games equivalent
maximizing payoffs. Unfortunately, eliminating disappointment impossible guarantee general. However, possible expert algorithm quickly achieve low disappointment
many known classes algorithms many games. Second, show popular existing expert
algorithms often fail achieve low disappointment variety associates, particularly
early rounds game. Finally, describe new meta-algorithm applied existing
expert algorithms substantially reduce disappointment many two-player repeated games
associates follow various static, reinforcement learning, expert algorithms.

1. Introduction
Many real-world environments require machines interact repeatedly independent, selfinterested entities, including people machines. finitely repeated interactions
endure unknown periods time ranging minutes, hours, days, months, even years.
successful interactions, machines must employ algorithms quickly learn good
strategies arbitrary (likely adaptive) associates.
Many algorithms repeated games developed last several decades, including reinforcement learning algorithms (e.g., Watkins & Dayan, 1992; Littman, 1994, 2001; Bowling
& Veloso, 2002; Greenwald & Hall, 2003; Crandall & Goodrich, 2011), opponent modeling algorithms (e.g., Fudenberg & Levine, 1998; Ganzfried & Sandholm, 2011), algorithms computing
desirable equilibria (e.g., Littman & Stone, 2005; Cote & Littman, 2008; Johanson, Bard, Lanctot,
Gibson, & Bowling, 2012), expert algorithms (e.g., Auer, Cesa-Bianchi, & Fischer, 2002; de
Farias & Megiddo, 2004; Auer, Cesa-Bianchi, Freund, & Schapire, 1995). sometimes successful, algorithms typically one following shortcomings preclude
use. First, many algorithms learn slowly. achieve successful behavior
thousands interactions, even simple games (e.g., Crandall & Goodrich, 2011). Second,
existing algorithms often myopic. fail learn profitable strategies long-term interactions. Third, many algorithms successful limited set associates.
long-term goal identify algorithms learn near-optimal behavior arbitrary associate within handful interactions. paper, focus potential
expert algorithms achieve goal two-player normal-form games. round, expert
algorithm selects expert predefined set experts dictate agents behavior
c
2014
AI Access Foundation. rights reserved.

fiC RANDALL

round. algorithmic structure several potential strengths. First, offers simple flexible design process. One create experts perform well specific scenarios agent
likely encounter (such paired particular associate) without worrying one
expert must perform well scenarios. expert algorithm responsible finding best
expert specific scenario run time. Second, experts complicated necessary.
Though focus normal-form games paper, experts compute complex equilibria
execute sophisticated algorithms also derived stochastic dynamics games. two
advantages give rise third potential advantage: expert algorithms potential learn
effective strategies quickly, particularly experts employ precomputed strategies.
expert algorithm evaluated based ability learn select successful experts. Several
metrics defined used literature measure success expert algorithm
process, perhaps popular regret (Foster & Vohra, 1999; Greenwald &
Jafari, 2003; Bowling, 2004; Gordon, Greenwald, & Marks, 2008). Loosely, expert algorithms
(external) regret difference payoffs agent would received always
followed best expert associates observed actions payoffs actually received.
context repeated games, regret desirable notion since provides simple generalizable
benchmark success. Unfortunately, minimizing regret always correspond maximizing
payoffs. paper, advocate alternative metric, called disappointment, equivalent
maximizing payoffs still providing simple generalizable benchmark success.
many algorithms guaranteed achieve regret (e.g., Bowling, 2004;
Foster & Vohra, 1999; Gordon et al., 2008), show impossible algorithm
guaranteed disappointment unknown associate. However, possible
algorithm quickly achieve maintain low disappointment classes algorithms
many repeated games. first evaluate effectiveness several existing expert algorithms
achieve low disappointment paired various (1) non-adapting, (2) reinforcement learning,
(3) expert algorithms two-player games. Finally, describe new meta-algorithm
enhancing expert algorithms. show substantially reduces disappointment
algorithms associates short- long-term interactions.
Section 2, discuss evaluation expert algorithms. doing, define disappointment establish several theoretical results, derive research agenda. Section 3,
define method generating effective set experts repeated normal-form games.
evaluate ability existing expert algorithms select effective experts across ten different repeated games Section 4. propose meta-algorithm enhancing expert algorithms
Section 5, evaluate effectiveness Section 6. conclude reflect Section 7.

2. Evaluating Expert Algorithms
section, review existing evaluation metrics repeated games, define discuss disappointment, compare existing metrics. Finally, formally state research agenda.
2.1 Notation Terminology
consider two-player repeated normal-form games, consist set joint actions =
A1 A2 , Ai player (or agent) action set, payoff function : R2 .
round t, agent independently selects action
ati Ai . resulting joint action






= (a1 , a2 ) produces payoff pair m1 (a ), m2 (a ) , mi (at ) payoff agent i.
112

fiT OWARDS INIMIZING ISAPPOINTMENT



R EPEATED G AMES

simplicity, assume that, A, mi (a) [0, 1], maxaA mi (a) = 1, minaA mi (a) = 0.
Play repeats unknown number rounds. refer two agents i.
use terms policy strategy refer agents select actions. Agent
policy probability distribution action set Ai . probability distribution specifies
probability agent selects action. strategy rule defines agents policies
state world. context experts used paper, world states typically defined
previous joint action played agents game. use notation ui (i , )
denote agent expected payoff round plays policy associate plays .
use notation (i , ) denote agent average expected per-round payoff time
perpetually plays strategy associate perpetually plays strategy .
make several assumptions. First, initially assume game played perfect information: players know others payoff matrix. later relax assumption account
occasions players incorrectly assess associates payoffs. Second, focus
general-sum repeated games, specifically address constant-sum games. However, many
concepts discussed herein also apply constant-sum games.
round t, expert algorithm employed agent selects expert ti set
experts . expert dictates policy executed agent round t. simplicity
analysis, literature often considers experts always play single action policy.
make assumption paper. Experts also sophisticated automata learning
algorithms.
2.2 Metrics
Currently, universally accepted metric evaluating well expert algorithms select
experts repeated games. Existing metrics typically define desirable performance benchmark
algorithm achieve compare payoffs obtained algorithms benchmark.
reliable indicators success, metrics payoff comparable.
Definition 2.1 (Payoff comparable): Let B two distinct algorithms, let o,M,T


o,M,T
B
denote average per-round payoff obtained B, respectively, associate
repeated game length payoff matrix . evaluation metric payoff comparable if,
scenario defined o, , , rates higher B o,M,T
> o,M,T
.

B
words, evaluation metric payoff comparable success defined metric
implies success respect maximizing agents average per-round payoff.
seek evaluation metric (1) defines generalizable (and desirable) performance benchmark (2) payoff comparable. discuss several metrics respect two attributes.
2.2.1 R EGRET
Regret become popular performance metric evaluating effectiveness learning rules
repeated games. notion re-discovered independently several times various
names (Foster & Vohra, 1999). Several forms regret formulated, including external
regret internal (or swap) regret. simplicity argument, focus external regret.
113

fiC RANDALL

Formally, agent total external regret round
RTi = max



X

uti (, ati )


X

mi (at ),

(1)

t=1

t=1

uti (, ati ) agent expected payoff round if, round {1, , t}, agent
followed expert agent played observed action ai . Agent average
external regret round
RTi =

RTi
.


(2)

RTi 0 means expert algorithm done least well would done
always followed best expert given associate would still played observed actions.
Agent said regret limT RTi 0. agents use no-regret learning
rules, play converges correlated equilibria (Greenwald & Jafari, 2003; Gordon et al., 2008).
performance benchmark (the estimated payoffs best expert) used calculate regret
simple generalizable scenario. However, regret payoff comparable. assumption
agent behavior affect agent future actions clearly violated agent
executes learning algorithm even simple automata. limiting assumption means regret
minimization imply payoff maximization. fact, demonstrate Section 2.3, low
regret sometimes strongly correlates low payoffs.
Several alterations regret made attempt alleviate shortcomings. example, Chang (2007) proposed modified form regret considers multi-period strategies.
modification provides effective evaluations simple automata tit-for-tat (at
expense increased computation complexity), still address general deficiency
regret minimization imply payoff maximization ones associate learns. Alternatively, Bowling (2004) embraced regret minimum criterion despite limitations, advocated
more: algorithm also converge achieve negative regret self play. Though
addition makes metric stronger, make metric payoff comparable.
2.2.2 E XPERIENCED R EGRET
alternative metric devised de Farias Megiddo (2003, 2004), refer experienced regret (e-regret), compares agents average payoff rounds actual average
payoff obtained successful expert rounds followed. Let xTi () average
payoff obtained agent round followed expert round , given by1
PT
I(, ti )mi (at )
,
(3)
xTi () = t=1
PT
t)
I(,

t=1


I(, ti ) indicator function returns 1 = ti 0 otherwise. Then, e-regret

1X
mi (at ).
EiT = max xTi ()

t=1

1. exception, never played time , xTi () = 0.

114

(4)

fiT OWARDS INIMIZING ISAPPOINTMENT



R EPEATED G AMES

regret (Eq. 1), minuend Eq. (4) independent subtrahend.
general case, xTi () different depending sequence experts (and, hence, actions)
agent plays. such, max xTi () guaranteed stable metric success
agents performance compared. Lower e-regret guaranteed correspond higher
payoffs (and often not; see Section 2.3). Thus, e-regret payoff comparable general.
exception, de Farias Megiddo (2004) showed minimizing e-regret limit
directly translate maximizing payoffs flexible opponents, associates
agents average payoff rounds + converges (as )
limit independent history play prior round t. flexible opponents,
followed sufficiently large number rounds (approaching infinity) selected, xti ()
vary substantially depending sequence experts chosen (and, hence, minuend
Eq. (4) independent subtrahend). circumstances, minimizing e-regret equates
maximizing payoffs. Using reasoning, de Farias Megiddo also established well-defined
performance guarantees (in limit) expert algorithm EEE flexible opponents.
performance bounds provided de Farias Megiddo (2004) appealing
special case, adopt e-regret evaluation metric repeated games two reasons.
First, though set flexible opponents includes useful classes algorithms, include
many algorithms agent likely encounter, many expert algorithms (including EEE
itself) learning algorithms. Second, performance bounds EEE flexible
opponents true limit. Since interactions infinite, interested
metric provide accurate measure success time interval.
summary, regret e-regret desirable since provide generalizable performance
benchmarks expert algorithms. Unfortunately, evaluation metrics payoff comparable arbitrary associates. Hence, adopt alternative (though related) metric
evaluating effectively expert algorithms select experts repeated games.
2.2.3 ISAPPOINTMENT
External regret e-regret imply simple notion success: expert algorithm perform
least well would performed always followed best expert. Disappointment
targets notion, minus assumption agent actions impact agent future
() policy agent would played round agent
actions. Formally, let
always followed expert round t. Agent total disappointment2 round
DiT = max


())
uti (,


X


uti (,
())


X

mi (at ),

(5)

t=1

t=1


agent expected payoff round if, round {1, , t},
(). Agent average
agent followed expert agent acted according
disappointment round
DiT =

DiT
.


(6)

2. paper accepted publication, became aware recent work defining policy regret (Arora, Dekel,
& Tewari, 2012; Cesa-Bianchi, Dekel, & Shamir, 2013). Disappointment captures notion policy regret,
except disappointment allows experts implement complex (even adaptive) algorithms rather
actions action sequences. generalization somewhat trivial, term policy regret seem fit
given experts. Rather continue overload term regret, refer metric disappointment.

115

fiC RANDALL

c


C
0.60, 0.60
1.00, 0.00


0.00, 1.00
0.20, 0.20

c

0.84, 0.84 0.33, 1.00
b 1.00, 0.33 0.00, 0.00

(a) Prisoners Dilemma

(b) Chicken

Table 1: Payoff matrices PD Chicken. cell, row players payoffs listed
first, followed column players.
Agent said disappointment limT DiT 0.
make several observations Eq. (5). First, minuend subtrahend independent.
Unlike Eqs. (1) (4), computation agents best expert measured Eq. (5) independent agent played. minuend simply constant specifying well agent would
done always followed best expert, hence stable benchmark success.
agents disappointment benchmark minus accumulated payoffs. Hence, disappointment
payoff comparable: algorithms receive higher payoffs given associate achieve lower
disappointment algorithms receive lower payoffs associate (and vice versa).
Second, agent influenced agent actions, ati good approximation
(). cases, disappointment external regret essentially equivalent.

desirable since minimizing regret equivalent maximizing payoffs cases.
Third, like external regret, disappointment negative. Negative disappointment indicates
expert algorithm performed better would performed always followed
best expert. However, sometimes possible, achieving negative disappointment
extremely difficult unknown associates. Thus, immediate goal, focus finding
expert algorithms achieve (or come close achieving) disappointment.
Finally, strength regret e-regret computed run time
repeated game unknown associate. Thus, regret used part algorithm
addition evaluation metric. Indeed, regret used algorithmic tool various
no-regret algorithms. downside, since minimizing regret necessarily correspond
maximizing payoffs, use regret algorithmic tool lead low payoffs
scenarios. hand, minuend Eq. (5) cannot computed run time
unknown associate. Thus, disappointment limited metric evaluate algorithms
repeated games; clear could used algorithmic tool.
2.3 Examples: Regret vs. Disappointment
illustrate differences disappointment regret several examples. First, consider
expert algorithm playing repeated prisoners dilemma (PD; Table 1a) tit-for-tat (TFT;
Axelrod, 1984). expert algorithm disposal two experts: AC, expert always recommends cooperate, AD, expert always recommends defect. Figure 1 shows average
payoff, average regret, average disappointment 20 rounds algorithm always cooperates always defects. Since always following AC would produce higher payoff always
following AD (0.6 opposed 0.24), AC best expert. such, always cooperating zero
disappointment always defecting high disappointment. hand, always cooperating high regret, always defecting zero regret. Thus, scenario, minimizing
regret correspond maximizing payoffs, minimizing disappointment does.
116

fiT OWARDS INIMIZING ISAPPOINTMENT



R EPEATED G AMES

TFT Prisoners Dilemma
0.7
Average payoff
Average regret
Average disappointment

0.6
0.5
0.4
0.3
0.2
0.1
0
Always Cooperate

Always Defect

Figure 1: Comparison average payoff, regret, disappointment PD (T = 20).

Similar results observed learning algorithms play repeated
PD. example, Figures 2a 2c plot average payoffs six different learning algorithms
(Exp3, UCB1, EEE, S, BR1, BR2) algorithms corresponding average regret
average disappointment, respectively, paired four different associates3 . Figure 2a shows
algorithms achieved lower regret tended higher performance BR1,
WoLF-PHC, Exp3, S. S, algorithms higher regret received substantially higher payoffs. hand, Figure 2c shows decreasing disappointment
four algorithms resulted directly higher payoffs PD.
Regret even less indicative performance Chicken (Table 1b) associates.
game, lower regret tends lead higher payoffs WoLF-PHC, Exp3,
BR1, (Figure 2b). PD, lower regret correlates lower payoffs Chicken,
lower disappointment always translates directly higher payoffs (Figure 2d).
Figures 2e2h demonstrate deficiencies e-regret evaluation metric PD
Chicken associates. 1000 rounds, lower e-regret BR1
PD Chicken correspond higher payoffs (Figures 2e 2f). Discrepancies
even pronounced 50,000 rounds. PD, algorithms low e-regret S,
wildly different average payoffs (Figure 2g). Similar, though identical, trends occur
Chicken (Figure 2h).
2.4 Research Agenda
absence single, universally accepted, evaluation metric repeated games, sets performance criteria proposed (e.g., Powers & Shoham, 2005a; Crandall & Goodrich, 2011).
Researchers advocating agendas argued successful algorithms simultaneously satisfy criteria identified set. example, Powers Shoham (2005a) argued
successful algorithms simultaneously satisfy three performance criteria:
Targeted Optimality: member target set associates, algorithm achieves
within expected value best response associates actual play.
3. See Appendix implementation details. experts used Exp3, UCB, EEE, described Section 3.
regrets disappointments BR1 BR2 computed respect experts.

117

fi0.60

0.90

0.55

0.85

0.50

Average Payoff

Average Payoff

C RANDALL

0.45
0.40
0.35
0.30
BR1
WoLFPHC

Exp3

0.25
0.20
0.15
0

0.05

0.1

0.15

0.2

0.25

0.3

0.80
0.75
0.70
0.65

BR1
WoLFPHC

Exp3

0.60
0.55

0.35

0

0.05

Average Regret

(a) PD: R1000
vs. 1000


0.90

0.50

BR1
WoLFPHC

Exp3

0.85

Average Payoff

Average Payoff

0.55

0.15

(b) Chicken: R1000
vs. 1000



BR1
WoLFPHC

Exp3

0.60

0.1

Average Regret

0.45
0.40
0.35
0.30

0.80
0.75
0.70
0.65

0.25
0.60

0.20
0.15
0

0.55
0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4 0.45

0

Average Disappointment

0.85

0.50

Average Payoff

Average Payoff

0.90

0.55

0.45
0.40
0.35
0.30
BR1
WoLFPHC

Exp3

0.15
0

0.05

0.1

0.15

0.35

0.75
0.70
0.65

0.55

0.2

0

0.05

0.1

0.15

0.2

eregret

(f) Chicken: Ei1000 vs. 1000

0.90

BR1
WoLFPHC

Exp3

0.80

Average Payoff

Average Payoff

0.3

0.60

BR1
WoLFPHC

Exp3

0.50

0.25

0.80

(e) PD: Ei1000 vs. 1000


0.55

0.2

BR1
WoLFPHC

Exp3

eregret

0.60

0.15

(d) Chicken: Di1000 vs. 1000


0.60

0.20

0.1

Average Disappointment

(c) PD: Di1000 vs. 1000


0.25

0.05

0.45
0.40
0.35
0.30

0.70
0.60
0.50

0.25
0.40

0.20
0.15
0

0.05

0.1

0.15

0.30
0

0.2

eregret

0.05

0.1

0.15

0.2

eregret

(g) PD: Ei50000 vs. 50000


(h) Chicken: Ei50000 vs. 50000


Figure 2: Average regret (ab), disappointment (cd), e-regret (eh) plotted average
payoffs (1000
) various pairings PD Chicken. point average 50 trials.

E-regret cannot computed BR1 BR2, results excluded (eh).

118

fiT OWARDS INIMIZING ISAPPOINTMENT



R EPEATED G AMES

Compatibility: self-play, algorithm achieves least within payoff
Nash equilibrium Pareto dominated another Nash equilibrium.
Safety: associate, algorithm always receives least within security
value game.
set experts satisfies certain properties, expert algorithm guaranteed
disappointment also satisfy desirable performance criteria. Let Safety
, Comp
,


TargetOpt

behavior
rules/algorithms

would
satisfy

Safety,
Compatibility,

Targeted

Optimality properties, respectively, always followed. Then, expert algorithm
disappointment satisfy Safety, Compatibility, Targeted Optimality properties,
respectively, experts set available experts .
Proposition 2.1 Let expert algorithm, let Safety
, Comp
, TargetOpt
, let A(i )



algorithm uses select experts . guaranteed disappointment,
A(i ) satisfy Safety, Compatibility, Targeted Optimality performance criteria.
Proof. proof follows directly Eq. (5). associates possible games,
know guaranteed disappointment, A(i )s average payoff
least high limit security value minus , since least well limit
. Thus, satisfies Safety criteria. Similarly,
would done always followed Safety

self play, A(i ) perform least well limit Comp
, least well

TargetOpt

associates targeted set associates. Hence, also meet
Compatibility Targeted Optimality performance criteria.
argue difficult find Safety
, Comp
, TargetOpt
. example, Safety




expert always plays agents maximin strategy. Comp



expert


TargetOpt
follows Littmans Stones Godfather strategy (Littman & Stone, 2005).
could
number algorithms derive best response memory bounded opponents,
algorithm described Chakraborty Stone (2010).
Similar arguments show expert algorithm guaranteed disappointment
also meet performance criteria, performance criteria advocated Crandall
Goodrich (2011). Additionally, suppose consists three experts: Expert 1 acts optimally
associates behavior class X, Expert 2 acts optimally associates behavior
class Y, Expert 3 acts optimally associates behavior class Z. Then,
expert algorithm guaranteed disappointment, A(i ) learn act optimally
playing associates behavior classes X, Y, Z.
short, find (1) expert algorithm guaranteed disappointment
(2) good set experts, agent performs well repeated games.
Given results, tempting research agenda find algorithm always achieves
disappointment. Unfortunately, unless agent omniscient, goal impossible.
Proposition 2.2 unknown associate, expert algorithm guarantee average
disappointment less 1 vimm , vimm = maxi mini ui (i , ) maximin
(i.e., security) value.
119

fiC RANDALL

Proof. adapt example de Farias Megiddo (2003). Let particular string
actions length 100. Consider agent playing repeated PD associate (agent i)
following strategy. rounds 100, always cooperate. > 100, always cooperate
agent actions matched rounds 100; otherwise, always play attack policy
attack = arg min

maxi ui (i , ) (defect). Suppose agent expert plays
string first 100 rounds, defects rounds thereafter. large , best
expert (against associate) would get average payoff near 1. But, without omniscience,
expert algorithm cannot know follow expert first 100 rounds, therefore
unlikely follow 100. Thus, maximum payoff guarantee
vimm = 0.2. Thus, DiT 1 vimm .
less ambitious, still extremely challenging, research agenda find algorithm
quickly achieves low disappointment associating member target set associates
across many repeated games. common target set algorithms memory-bounded
algorithms (e.g., de Farias & Megiddo, 2004; Chakraborty & Stone, 2010; Arora et al., 2012; CesaBianchi et al., 2013), since theoretical guarantees easier establish algorithms.
However, find appealing target set associates broad enough cover
many state-of-the-art algorithms published literature, would presumably set
likely associates agent would face. example, algorithms literature include static
(memory-bounded) algorithms automata, reinforcement learning algorithms, expert algorithms. Thus, paper, focus finding expert algorithms achieve low disappointment
associates three classes algorithms.
theoretical treatment aim extremely challenging beyond scope
paper. Rather, starting point, empirically evaluate disappointment algorithms
various static, reinforcement learning, expert algorithms literature. doing,
seek algorithm quickly achieves low disappointment algorithm consider.
Let set opponent algorithms considered. Then, max disappointment algorithm
respect rounds


(, ),
DA
(, ) = max DA


(7)

(, ) average disappointment algorithm associate .
DA
Though tempting focus asymptotic performance (as ), interactions repeat
tens hundreds times many realistic scenarios. such, seek identify expert
algorithms quickly achieve low disappointment static associates, reinforcement learning
algorithms, expert algorithms. Thus, primarily focus disappointment achieved
algorithms first 1000 rounds, though also consider longer-term performance.
Section 4 evaluate several existing algorithms respect disappointment.
so, describe method computing good set experts repeated general-sum games.

3. Computing Set Experts Arbitrary Repeated Games
success agent employing expert algorithm depends expert algorithms ability select effective experts (and, thus, minimize disappointment) effectiveness
set experts . Given importance , give considerable attention computing
120

fiT OWARDS INIMIZING ISAPPOINTMENT



R EPEATED G AMES

c

0.33, 0.33 0.67, 1.00
b 1.00, 0.67 0.00, 0.00

c

1.00, 1.00 0.00, 0.75
b 0.75, 0.00 0.50, 0.50

c

0.84, 0.33 0.84, 0.00
b 0.00, 1.00 1.00, 0.67

c

0.00, 0.00 0.00, 1.00
b 1.00, 0.00 0.00, 0.00

(a) Leader

(b) Stag hunt

(c) Security Game

(d) Offset Game

c

1.00, 1.00 0.00, 0.00
b 0.00, 0.00 0.50, 0.50

c

0.00, 0.00 0.67, 1.00
b 1.00, 0.67 0.33, 0.33

c

0.00, 1.00 1.00, 0.67
b 0.33, 0.00 0.67, 0.33

(e) Common Interest

(f) Battle Sexes

(g) Tricky Game


b
c


0, 0
0, 1
1, 0

e
1, 0
0, 0
0, 1

f
0, 1
1, 0
0, 0

(h) Shapleys Game

Table 2: Payoff matrices eight different games.
good set experts repeated normal-form games. potential associate game
agent might encounter, set experts include least one expert perform well.
Littman Stone (2001) grouped algorithms repeated games two classes: leaders
followers. Leaders typically effective associating follower algorithms,
standard reinforcement learning opponent modeling algorithms. Follower algorithms
typically effective leader strategies static algorithms. Thus, order
high-performing expert scenario agent might encounter, good set experts must
contain leader follower experts.
3.1 Leader Experts
Based premise associate play best response, leader strategies designed
play strategies cause associates play portion desirable solution (sometimes called
targeted pair) (Littman & Stone, 2001). solution sequence joint actions
agents repeatedly play. solution produces expected payoff profile v(s) = (vi (s), vi (s)).
example, solution = <(c, C), (d, C)> PD corresponds situation
column player always cooperates row player alternates cooperating defecting.
produces expected payoff profile v(s) = (0.8, 0.3) payoffs given Table 1a.
Since often unclear solution agent target, define set potential target
solutions . contains solutions satisfy following three criteria. First, consists
solutions agents expected payoff vi exceeds maximin value vimm . Second,
line Occams razor, consists solutions sequences one two joint actions. Solutions longer sequences likely complex many potential associates identify,
especially interactions last tens rounds, exclude them. Third, solutions
must enforceable. must possible make playing solution associates best response.
Formally, agent plays strategy , agent best response
bri (ti ) = arg max (i , ).


(8)

Recall (i , ) average per-round payoff strategies played.
cardinality (||) varies game game. example, PD, || = 6,
|| = 9 Shapleys Game (Table 2h). Furthermore, set 50 randomly-generated 5-action
games, found || vary 18 187.
121

fiC RANDALL

No.
1
2
3
4

Target solution (s)
<(c, C)>
<(d, C), (c, D)>
<(c, C), (d, D)>
<(d, D)>

v1 (s)
0.60
0.50
0.40
0.20

Strategy
g2t > 0, play iattack . Otherwise, play
portion current joint action
sequence s.

Table 3: Leader experts generated player 1 PD.
Though enforceable, solutions made associates best response associate conditions strategy many previous joint actions. curse dimensionality,
algorithms designed learn quickly condition strategy previous joint actions. Thus, form separate leader expert () target solutions
bri () requires associate remember single joint action. leader experts
incentivize associates play portion target solution punishing deviations
using similar mechanism used previously defined leader strategies (e.g., Littman &
Stone, 2005; Crandall & Goodrich, 2005). associate conformed
benefited deviating it, leader expert plays portion s. However, associate
benefited deviating s, leader expert plays attack policy iattack .
defines much
Formally, leader expert keeps track guilt parameter gi
1
associate benefited deviating s. Initially, gi = 0. Subsequently,
t+1
gi





0
max


0, gi

+ mi

(at )




ai = bi gi = 0
vi + otherwise

(9)

bti agent current action defined target solution small nonnegative
= 0 = 0.0 otherwise. g > 0, agent recently
value. use = 0.1 gi


benefited (or least hurt) deviating s. discourage behavior, leader
= 0, leader expert plays portion s.
expert plays attack policy iattack . gi
Table 3 lists four leader experts generated PD. Note expert created
target solutions <(c, C), (d, C)> <(c, C), (c, D)> , since solutions
enforceable associate learns best response conditioned last joint action.
3.2 Follower Experts
Followers learn play best response estimated strategy associate. consider
three types follower experts, estimates associates strategy different way.
first experts models associate using fictitious play assessment conditioned
last joint action played. Let ti (a, ai ) number times agent played ai
given previous joint action round t. Then, estimated probability agent plays
ai given previous joint action


(a, ai ) = P

ti (a, ai )
.

bi Ai (a, bi )

(10)

expert computes automaton best responds agents future discounted reward
. refer expert .
(we use discount factor = 0.95) given

122

fiT OWARDS INIMIZING ISAPPOINTMENT

No.
1
2

Target solution (s)
(none)
(none)

v1 (s)
1 (br1 (2t ), 2t )
v1mm = 0.20

3
4
5
6
7
8

<(c, C), (d, C)>
<(c, C)>
<(d, C), (c, D)>
<(c, C), (d, D)>
<(c, C), (c, D)>
<(d, D)>

0.80
0.60
0.50
0.40
0.30
0.20



R EPEATED G AMES

Strategy
br1 (2t )
1mm
at1 s, play portion next
joint action s. Otherwise, randomly select
joint action play portion
joint action.

Table 4: Follower experts generated player 1 PD.
second follower expert, called mm
, assumes associate trying exploit it. Thus,
best response play maximin strategy (or policy), given
imm = arg max min ui (i , ).




(11)

Finally, associate could also using leader strategy, computed Section 3.1. Thus, include set experts follower expert . experts
always play part s. joint action solution played previous round,
experts randomly select joint action solution sequence play agents corresponding action.
Table 4 lists eight follower experts generated PD method.
3.3 Set Experts
set experts used expert algorithms remainder paper consists
follower leader experts described. scenarios encountered, least one
experts capable performing effectively. associate employs follower algorithm,
expert algorithm select number leader experts could induce desirable behavior associate. Similarly, associate employs leader algorithm, Godfather
Bully (Littman & Stone, 2001), expert algorithm select corresponding follower expert.
Additionally, diversity experts good expert algorithm able
obtain high payoffs expert algorithms, including select similar set
experts. case, expert algorithms must negotiate follower leader roles.
illustration performance experts three different associates several
repeated games provided Appendix B. example, set experts contains least
one high-performing expert. However, results also illustrate identifying best expert
run time extremely difficult. Sometimes best performing expert must followed
consistently many rounds produces high payoffs.

4. Results Existing Expert Algorithms
Existing expert algorithms typically evaluated terms regret. section, evaluate several algorithms repeated normal-form games terms disappointment. Specifically, analyze average disappointment four existing expert algorithms twelve
123

fiC RANDALL

different algorithms across ten repeated games. Recall goal find expert algorithm
quickly achieves maintains low disappointment static algorithms, reinforcement
learning algorithms, expert algorithms.
four expert algorithms Exp3, UCB1, EEE, S. Exp3 UCB1 well-known expert algorithms well-defined regret bounds multi-armed adversarial multi-armed bandit
problems, respectively. algorithms shown perform effectively repeated games (Bouzy & Metivier, 2010). EEE -greedy expert algorithm designed repeated
games played learning associates. , shown e-regret (de
Farias & Megiddo, 2003, 2004). aspiration-based algorithm shown perform well expert algorithm (Bouzy, Metivier, & Pellier, 2011), though originally
designed such. interest space, omit detailed overviews algorithms. Instead,
refer reader Appendix A, provides references descriptions analysis
algorithms, also specifies parameter values used generate results paper.
compare average disappointment four expert algorithms paired
twelve representative algorithms: four static algorithms (A0, Random, Godfather, Bully), four
reinforcement learning algorithms (BR1, BR2, Q-learning, WoLF-PHC), other. Implementation details twelve algorithms also supplied Appendix A. Comparisons
made across ten games shown Tables 1 2. well-studied games literature, representing different challenge. successful games, algorithm
must able learn make accept profitable compromises many different situations.
average disappointment across games pairing shown Figure 3. figure
shows that, first 1000 rounds, typically lower average disappointment
associate three expert algorithms. Additionally, despite popularity theoretical
properties, Exp3 performs worst four expert algorithms associate.
Results vary somewhat associate. four expert algorithms eventually obtain low
disappointment static algorithm, Figures 3a3d show reaches average
disappointment less 0.05 within 1000 episodes four static associates.
expert algorithms unable so, large part due relatively large number experts
. Ss mechanism selecting experts allows find best expert faster
algorithms. exception, effective Random, especially long run,
sometimes never learn play best expert. example, learn play best
response Random PD, three algorithms eventually do.
reinforcement learning algorithms adapt time, achieving low average disappointment associates difficult static algorithms. statement
confirmed performance four expert algorithms BR1, BR2, WoLF-PHC,
Q-learning (Figures 3e3h). associates, none four expert algorithms achieves
low disappointment first 1000 rounds. average disappointment quickly increases
first 50-200 rounds, slowly decreases plateaus thereafter.
four expert algorithms also high disappointment (Figures 3i3l).
self play, manages achieve average disappointment 0.05, none three
algorithms first 1000 rounds expert algorithm. fact, Exp3,
average disappointment expert algorithm increases throughout first 1000 rounds.
short, none four expert algorithms quickly achieves low disappointment static
algorithms, reinforcement learning algorithms, expert algorithms. Thus, next section,
describe new meta-algorithm designed enhance performance existing expert algorithms.
124

fiT OWARDS INIMIZING ISAPPOINTMENT

0.2
0.15
0.1
0.05

200

400

600

800

0.25
0.2
0.15
0.1
0.05
0
0

1000

0.35
EEE

UCB1
Exp3

0.3

200

400



0.1
0.05

600

800

0.2
0.15
0.1

EEE

UCB1
Exp3

0.05
0
0

1000

200

400

0.1

EEE

UCB1
Exp3

0.05

600

800

EEE

UCB1
Exp3
200

400

0.2

0.1
0.05

200

400

600

800

0.2
0.15
0.1
0.05

200

400

0.1
0.05

600



(j) UCB1

800

1000

800

1000

(i) Exp3
0.35

0.3
0.25
0.2
0.15
0.1

EEE

UCB1
Exp3

0.05
0
0

600



200

400

600



(k) EEE

800

1000

Average Disappointment

0.15

Average Disappointment

0.2

1000

EEE

UCB1
Exp3

0.25

0
0

1000

0.35

0.25

800

0.3

(h) Q-learning
EEE

UCB1
Exp3

0.3

600

0.35
EEE

UCB1
Exp3



0.35

400

0.1
0.05

(f) BR2

0.15

(g) WoLF-PHC

200

0.2



0.25

0
0

1000

1000

0.15

0
0

1000

Average Disappointment

0.2
0.15

Average Disappointment

Average Disappointment

800

0.3



Average Disappointment

600

0.35

0.25

800

0.3

(e) BR1

0.3

600

0.25



0.35

0
0

400

0.35

0.25

(d) Godfather

400

200

(c) Bully

0.3



200

0.1
0.05



Average Disappointment

0.2
0.15

Average Disappointment

Average Disappointment

0.25

400

0.2
0.15

0
0

1000

0.35
EEE

UCB1
Exp3

0.3

200

0.25

(b) Random

0.35

0
0

800

EEE

UCB1
Exp3

0.3



(a) A0

0
0

600

Average Disappointment

0.25

0
0

R EPEATED G AMES

0.35
EEE

UCB1
Exp3

0.3

Average Disappointment

Average Disappointment

0.35



EEE

UCB1
Exp3

0.3
0.25
0.2
0.15
0.1
0.05
0
0

200

400

600

800

1000



(l)

Figure 3: average disappointment time four expert algorithms twelve associates. Results average 50 trials ten selected games.

125

fiC RANDALL

Section 6, demonstrate meta-algorithm improves Exp3, UCB1, EEE,
consistently achieve much lower disappointment associates.

5. Enhancing Existing Expert Algorithms
failure expert algorithms consistently achieve low disappointment adapting
agents appears tied algorithms exploration strategies. Early game, expert
algorithms tend spend many rounds following ineffective experts seek determine
experience experts effective. result, receive low average payoffs early
rounds game. Furthermore, frequent changes behavior caused cycling many
experts incoherent outsider. Thus, associates unlikely determine coordinate
behavior strike mutually beneficial compromises. adaptive associates whose internal
models conditioned somewhat associates behavior, process often leads low
payoffs (and, hence, high disappointment) short long term. section,
describe rather simple meta-algorithm designed overcome deficiency.
5.1 New Meta-Algorithm
purpose meta-algorithm help expert algorithm explore effectiveness set
experts effectively. computing highest expected payoff (or potential)
expert, supplying expert algorithm subset experts whose potential
meets performance threshold. Experts lower potential followed experts
higher potentials demonstrated inability meet potentials.
performance threshold round determined using aspiration learning (Karandikar,
Mookherjee, R., & Vega-Redondo, 1998; Stimpson, Goodrich, & Walters, 2001; Chasparis, Shamma,
& Arapostathis, 2010). aspiration learning, agent maintains aspiration ti . algorithm,
1i initialized potential (see Section 5.3) expert highest potential. Formally,
let zit () denote potential expert round t. Then,
1i = max zi1 ().


(12)

(Appendix A), round new expert selected, ti updated follows:
ti =
+ (1 )rit ,


(13)

rit average payoff received agent last rounds, number consecutive
rounds expert followed, [0, 1] learning rate (we use = 0.99).
performance threshold round agents minimum aspiration level ki
time interval k [, t], 1 t. expert whose potential meets exceeds
performance threshold considered selection round t; experts not.4 Formally,
round t, experts selected set
(t) = { : zit () min ki }.
k[,t]

(14)

(t) defined Eq. (14) empty, default expert added (t). set experts
defined Section 3, add expert plays best response fictitious-play assessment
conditioned previous joint action. is, (t) = {i } cases.
4. before, disappointment always computed using full set experts .

126

fiT OWARDS INIMIZING ISAPPOINTMENT



R EPEATED G AMES

Algorithm 1 meta-algorithm (for agent i) enhance expert algorithms.
Input:
(the expert algorithm), (the set experts), (the payoff matrix)
Initialize:
t=1
Compute zit ()
Initialize ti = maxi zit ()
repeat
Compute (t) = { : zit () min [,t] }, 0 <
Execute (and update) A(i (t)) rounds, specified A. Observer rit+ .
t= t+
Update ti =
+ (1 )rit


Compute zi ()
Game

complete meta-algorithm stated Algorithm 1. make two observations. First,
meta-algorithm embodies optimism-in-uncertainty principle (Brafman & Tennenholtz, 2003).
aspiration level initially set high, expert presumed able meet highest
potential. experts fail meet highest potentials (which causes aspiration level
fall; Eq. 13) algorithm consider selecting experts lower potential. Second,
aspiration updates similar nature previous work aspiration learning (Karandikar et al.,
1998; Stimpson et al., 2001; Chasparis et al., 2010), aspiration level used differently
meta-algorithm. Rather use ti determine whether action expert repeated
next round, use ti prune set selectable experts.
5.2 Properties Reduced Set (t)
Selecting experts (t) rather leaves open possibility (t) might
contain best expert. However, certain parameter settings, meta-algorithm either
obtain average payoffs less best expert limit, best expert contained
(t) > . Let vi () denote highest possible average per-round payoff agent
could ever obtain always follow expert , let denote best expert game
associate question, let ti average payoff obtained agent time t.
following proposition.
Proposition 5.1 = 1 , zit () vi (), one following must hold:
Condition 1: limt ti zit ( )
Condition 2: , (t)
Condition 1 equates expert algorithm disappointment, Condition 2 says
eventually enter (and perpetually remain in) (t). proof proposition
straightforward. Since aspiration level ti fading average payoff agent, must
time fall zit ( ) average payoff ti perpetually zit ( ). case,
accordance Eq. (14), would (t) thereafter.
typical aspiration learning (Karandikar et al., 1998), use = (i.e., performance
threshold ti ) generating results shown next section. means implemen127

fiC RANDALL

tation technically satisfy conditions Proposition 5.1. However, observed
that, practice, algorithm achieves similar results = 1 = t.
5.3 Computing Potential
strategies learning processes target value, value equilibrium
solution current expected value learning process. always conforming
pre-condition Proposition 5.1, target values often sufficient determining
potential experts practice. demonstrate define potential experts using set
experts, defined Section 3.
Let lead
denote set leader experts . assumption rational

(follower) associate, highest expected payoff (or potential) reasonably expect
leader expert lead
obtain expected per-round payoff agent receive

opponent plays best response strategy. Formally, lead
t,

zit () = (, bri ()).

(15)

Let follow
denote set follower experts excluding maximin besti
response experts (mm
, respectively). associate appears playing portion

target solution corresponding expert follow
, potential agents expected

payoff target solution corresponding expert played. Let sti denote observed
strategy employed agent round t. Then,

(bri (sti ), sti ) bri (sti )

zi ()
(16)
0
otherwise
determine strategies associate could playing, agent models agent actions
given previous joint action a. Since agent could change sti time, partial
estimate sti may available. agent remembers last round k agent changed
action given previous joint action A. actions taken round k onward define sti .
Formally, agent estimated strategy given
j
ai j [k, t) : aj =
sti (a)
(17)

otherwise
agent estimate sti consistent leader strategy corresponding follow
,


agent assumes playing leader strategy computing zi ().
mm z ( ) =
potentials maximin best-response experts zit (mm
) = vi



(bri (i ), ), respectively.
5.4 Safety
Safety, guarantee expected average payoffs substantially maximin
value vimm , perhaps oldest objective repeated games (Fudenberg & Levine, 1998).
expert algorithm guaranteed regret guaranteed safety
safe. However, expert algorithms well-defined regret bounds, add
mechanism meta-algorithm ensures safety. call mechanism safety override
since overrides Eq. (14) certain conditions.
128

fiT OWARDS INIMIZING ISAPPOINTMENT



R EPEATED G AMES

safety override adopted security mechanism described Crandall Goodrich
(2011). sum agents payoffs ever less constant Ci

PTwhat would

achieved always received maximin value (i.e., =1 mi (a ) + Ci <
vimm ), (t) = {mm
}. guarantees agents expected average payoff
mm
less vi , regardless game associate. proof safety provided
mechanism given Crandall Goodrich (2011). used Ci = 100 implementation.
5.5 Best Response
Previous work shown value properly balancing optimistic, best response, secure
attitudes repeated games (Crandall & Goodrich, 2011). Eqs. (1214) induce optimistic attitude, safety override secure attitude. Finally, add best-response override.
algorithm sets (t) = {i } following two conditions met:
1. (t); see Eq. (14) conjunction safety override.
2. historical average per-round payoff playing high expert.
Formally, let xti () weighted average per-round payoff5 received agent
round followed expert round t. Then, (t), xti (i ) xti ().
override use algorithms like S, learn effectively many algorithms, sometimes learn best response static agents (such Random).

6. Results Enhanced Expert Algorithms
enhanced four expert algorithms evaluated Section 4 meta-algorithm. call
enhanced versions algorithms Exp3++, UCB++, EEE++, S++, respectively.
algorithms identical original algorithms except select experts (t) rather
. first evaluate whether expert algorithms consistently achieve low disappointment
twelve associates before. also compare payoffs algorithms
top-performing algorithms literature perfect imperfect information settings.
6.1 Static, Reinforcement Learning, Expert Algorithms
average disappointment enhanced original algorithms twelve associates
across ten games shown Figure 4. enhanced algorithm substantially less average
disappointment original algorithm. enhanced algorithms quickly reach low levels
disappointment (Figure 4a). 1000 rounds, average disappointment enhanced
algorithms 0.05 (Figure 4b), substantially less original algorithms. Similar improvements present terms max disappointment (Figure 5).
meta-algorithm consistently produces substantial decreases disappointment
associates ten games (not shown). Figure 6 shows average disappointment EEE++
Exp3++ associate across games. static associates (Figures 6a6d),
EEE++ Exp3++ achieve low average disappointment well 1000 rounds.
meta-algorithm produces even greater decreases average disappointment reinforcement learning algorithms (Figures 6e6f) expert algorithms (Figures 6i6l). algorithms
5. Initially, x1i () = 1. xti () updated round followed: xti () = xt1
() + (1 )mi (at ),

= max(1/ti (), 2(1 )) ti () number times agent played round t.

129

fi0.2
EEE

UCB1
Exp3
EEE++
S++
UCB1++
Exp3++

0.15

0.1

0.05

0
0

50

100

150

200

250

300

350

Average Disappointment (T = 1000)

Average Disappointment

C RANDALL

0.15

0.1

0.05

0



(a) Average disappointment time

Original
++

0.2

Exp3

UCB1

EEE



(b) Average disappointment (T=1000)

Figure 4: Average disappointment across selected games associates.

0.3

EEE

UCB1
Exp3
EEE++
S++
UCB1++
Exp3++

0.25
0.2
0.15
0.1
0.05
0
0

50

100

150

200

250

300

350

Max Disappointment (T = 1000)

Max Disappointment

0.35

0.35

0.25
0.2
0.15
0.1
0.05
0


(a) Max disappointment time

Original
++

0.3

Exp3

UCB1

EEE



(b) Max disappointment (T=1000)

Figure 5: Max disappointment (Eq. 7).

enhanced meta-algorithm also achieve higher payoffs self play original algorithms (Figure 7).
One interesting exception previously stated trend EEE performs better
Bully first 100 rounds EEE++ (Figure 6c). Bully, best-performing
experts (see Figure 11 Appendix B) tend high potential games, experts
high potential often achieve high payoffs well. Hence, takes many rounds
agents aspiration level falls far enough best expert (t). causes EEE++
higher disappointment early rounds. best expert appears (t), average
disappointment quickly decreases.
Finally, Figure 8 shows average payoffs obtained algorithms associates
50,000 rounds. Even 50,000 rounds, enhanced expert algorithms outperform
original algorithms. UCB1 best performance four original algorithms
50,000, enhanced algorithms substantially higher payoffs. Thus, enhancements improve algorithms near term, also long term.
130

fiT OWARDS INIMIZING ISAPPOINTMENT

0.2
0.15
0.1
0.05

200

400

600

800

0.25
0.2
0.15
0.1
0.05
0
0

1000

0.35
EEE
EEE++
Exp3
Exp3++

0.3

200

400



0.1
0.05

600

800

0.2
0.15
0.1
0.05
0
0

1000

200

400

0.1
0.05

600

800

0.1
0.05

200

400

0.2

0.1
0.05

200

400

600

800

0.2
0.15
0.1
0.05

200

400

0.15
0.1
0.05

600



(j) UCB1

800

1000

0.25

800

1000

(i) Exp3
0.35

EEE
EEE++
Exp3
Exp3++

0.2
0.15
0.1
0.05
0
0

600



Average Disappointment

0.2

Average Disappointment

0.25

1000

EEE
EEE++
Exp3
Exp3++

0.25

0
0

1000

0.35
0.3

800

0.3

(h) Q-learning
EEE
EEE++
Exp3
Exp3++

0.3

600

0.35
EEE
EEE++
Exp3
Exp3++



0.35

400

0.2

(f) BR2

0.15

(g) WoLF-PHC

200

EEE
EEE++
Exp3
Exp3++



0.25

0
0

1000

1000

0.15

0
0

1000

Average Disappointment

0.2
0.15

Average Disappointment

Average Disappointment

800

0.3



Average Disappointment

600

0.35

0.25

800

0.25

(e) BR1
EEE
EEE++
Exp3
Exp3++

0.3

600

0.3



0.35

0
0

400

0.35
EEE
EEE++
Exp3
Exp3++

0.25

(d) Godfather

400

200

(c) Bully

0.3



200

0.1
0.05



Average Disappointment

0.2
0.15

Average Disappointment

Average Disappointment

0.25

400

0.2
0.15

0
0

1000

0.35
EEE
EEE++
Exp3
Exp3++

0.3

200

0.25

(b) Random

0.35

0
0

800

EEE
EEE++
Exp3
Exp3++

0.3



(a) A0

0
0

600

Average Disappointment

0.25

0
0

R EPEATED G AMES

0.35
EEE
EEE++
Exp3
Exp3++

0.3

Average Disappointment

Average Disappointment

0.35



200

400

600



(k) EEE

800

1000

EEE
EEE++
Exp3
Exp3++

0.3
0.25
0.2
0.15
0.1
0.05
0
0

200

400

600

800

1000



(l)

Figure 6: Average disappointment time associate across selected games.
Results average 50 trials ten selected games.

131

fiC RANDALL

Average Payoff (T = 1000)

0.9
Original
++
0.8
0.7
0.6
0.5
0.4
0.3

Exp3

UCB1

EEE



Figure 7: Average payoffs self play 1000 rounds across selected games.

Average Payoff

0.8
EEE

UCB1
Exp3
EEE++
S++
UCB1++
Exp3++

0.75

0.7

0.65

0.6
0

10,000

20,000

30,000

40,000

50,000



Figure 8: Average payoffs time across selected games associates.

6.2 Meta-Algorithm Works
meta-algorithm two different components: (1) method distinguishing experts
likely successful (2) best response safety overrides.
combined impact overrides max disappointment enhanced algorithms shown
Figure 9. overrides typically lower algorithms max disappointment small
margin, small number cases (e.g., static agents) overrides responsible
substantial improvements. many scenarios, overrides invoked.
Thus, meta-algorithm improves original algorithms primarily via mechanism distinguishing successful experts unsuccessful experts. original expert algorithms tend
spend many rounds following ineffective experts seek determine experience
experts effective. resulting frequent changes behavior caused cycling
many experts incoherent associates, making difficult agents coordinate behavior
strike mutually beneficial compromises. hand, enhanced algorithms select
fewer experts early rounds game, produces predictable behavior associates
easily model adapt to. This, turn, allows quickly find mutually beneficial
compromises, lead higher payoffs short long term.
132

fiOriginal
+ (no overrides)
++

0.2
0.15
0.1
0.05
0

Exp3

UCB1

EEE



(a) static algorithms



0.3
Original
+ (no overrides)
++

0.25
0.2
0.15
0.1
0.05
0

Exp3

UCB1

EEE



(b) RL algorithms

R EPEATED G AMES

Max Disappointment (T = 1000)

0.3
0.25

Max Disappointment (T = 1000)

Max Disappointment (T = 1000)

OWARDS INIMIZING ISAPPOINTMENT

0.3
Original
+ (no overrides)
++

0.25
0.2
0.15
0.1
0.05
0

Exp3

UCB1

EEE



(c) expert algorithms

Figure 9: Max disappointment 1000 1000 rounds class associates.

6.3 Comparison Top-Performing Algorithms
shown meta-algorithm helps expert algorithms quickly achieve maintain low
disappointment variety static, reinforcement learning, expert algorithms across
many repeated games. illustrate value contribution, compare average payoffs enhanced algorithms top-performing algorithms repeated games.
compare algorithms state-of-the-art learning algorithms, ran several round-robin
tournaments involving eight algorithms: S++, EEE++, six algorithms literature: MQubed, Manipulator-Bully, Manipulator-Godfather, BR1, Godfather, Bully (see Appendix A).
algorithms chosen due elite attributes. example, Bully Godfather
leader algorithms well-understood equilibrium characteristics (Littman & Stone, 2001, 2005).
algorithms precompute desirable behaviors, good standards performance early
rounds repeated games. M-Qubed reinforcement learning algorithm demonstrated
superior asymptotic performance several empirical studies (Crandall & Goodrich, 2011; Bouzy
& Metivier, 2010). makes good standard comparison long-term (or asymptotic)
performance. Manipulator combines Godfather Bully BR1 maximin strategy imm
provide theoretical guarantees respect targeted optimality, safety, compatibility (Powers
& Shoham, 2005a).
point, assumed perfect information, wherein player perfect knowledge
players payoffs. relax assumption consider scenarios
players normally distributed errors assessments players payoffs. Thus,
conducted three separate round-robin tournaments: one perfect information (No Noise),
two different sizes errors payoff assessment ( = 0.15 = 0.30, respectively).
tournament, algorithm paired seven algorithms
50 random 3-action repeated games. game consisted 50,000 rounds. compare
algorithms average per-round payoff eight pairings short term
(over first 100 1000 rounds) asymptotically (over last 1000 rounds). random
games tend produce less variation average payoffs selected games6 , use random
games guard overfitting selected games.
results tournaments summarized Figure 10.
6. One comparison 16 algorithms showed 0.07 difference average payoffs best- worstperforming algorithms (Crandall & Goodrich, 2011)

133

fiC RANDALL

Average Payoff

0.85
0.8
S++
EEE++
MQubed
BR1
Bully
Godfather
ManipulatorBully
ManipulatorGF

0.75
0.7
0.65
0.6
0.55

Noise

Noise: = 0.15 Noise: = 0.30

(a) Averaged first 100 rounds

Average Payoff

0.85
0.8
S++
EEE++
MQubed
BR1
Bully
Godfather
ManipulatorBully
ManipulatorGF

0.75
0.7
0.65
0.6
0.55

Noise

Noise: = 0.15 Noise: = 0.30

(b) Averaged first 1000 rounds

Average Payoff

0.85
0.8
S++
EEE++
MQubed
BR1
Bully
Godfather
ManipulatorBully
ManipulatorGF

0.75
0.7
0.65
0.6
0.55

Noise

Noise: = 0.15 Noise: = 0.30

(c) Averaged rounds 49,001 50,000

Figure 10: Average payoffs perfect (No Noise) imperfect (Noise: = 0.15 = 0.30,
respectively) information round-robin tournaments involving 50 random 3-action games.

134

fiT OWARDS INIMIZING ISAPPOINTMENT



R EPEATED G AMES

6.3.1 P ERFECT NFORMATION
Unsurprisingly, Godfather Manipulator-GF (which identical first 100 rounds)
highest average payoffs first 100 rounds (Figures 10a). However, average payoffs
S++ EEE++ perfect information far behind. T-tests show difference
average performance S++ Godfather statistically significant 100 rounds
(p = 0.194), though difference EEE++ Godfather (p = 0.004). payoffs
algorithms substantially lower. 1000 rounds, S++ EEE++ outperformed
six algorithms perfect information (Figure 10b). 1000 rounds, difference S++ EEE++ statistically significant, though differences S++
six algorithms (p < 0.010). Thus, short-term performances S++
EEE++ favorable compared algorithms perfect information.
long-term performance S++ EEE++ matches M-Qubed perfect information games (Figure 10c). Given M-Qubeds top asymptotic performance previous studies
(Crandall & Goodrich, 2011; Bouzy & Metivier, 2010), results speak effectiveness
enhanced algorithms.
6.3.2 MPERFECT NFORMATION
Godfather Bully compute equilibrium strategies based knowledge payoffs
associates. using precomputed strategies, algorithms quickly achieve high payoffs. MQubed BR1, hand, seek learn effective behaviors experience. MQubed eventually quite effective, learning processes often takes many rounds. S++, EEE++,
Manipulator-Godfather, Manipulator-Bully both. combine computation equilibria game begins learning experience. result, tend
perform effectively short-term long-term perfect information.
However, since computing (and agreeing upon) equilibrium sometimes requires perfect information, algorithms potentially limited given perfect knowledge associates
payoffs uncommon. However, uncommon agents estimates payoffs
others, though sometimes estimates error. model scenarios imperfect
information tournaments. results tournaments also shown Figure 10.
figure shows early later rounds game, Godfather, Bully, ManipulatorGodfather, Manipulator-Bully negatively impacted errors assessments
associates payoffs. average payoffs fall substantially (and statistically significantly)
medium errors assessment ( = 0.15) large errors assessment ( = 0.30).
hand, S++ EEE++ slightly affected moderate high errors
assessments. Thus, continue perform par M-Qubed asymptotically (Figure 10c),
maintaining highest performance early rounds game.
Manipulator algorithms, S++, EEE++ utilize precomputed strategies learn
experiences, S++ EEE++ substantially affected imperfect information,
Manipulator algorithms are. two primary differences Manipulator
algorithms enhanced expert algorithms cause difference. First, Manipulator algorithms compute single equilibrium strategy, enhanced expert algorithms compute
many equilibria strategies (the various experts). Second, Manipulator algorithms execute experts
serially. algorithms first execute respective leader strategy. respective leader strategy fails produce desired payoffs, switch following BR1, on. hand,
135

fiC RANDALL

S++ EEE++ continue evaluate multiple experts (essentially parallel). results,
algorithms much robust errors assessments associates payoffs.

7. Conclusions Discussion
paper, introduced new metric, called disappointment, evaluating expert algorithms
repeated games. Disappointment similar regret, except disappointment built
assumption agents actions influence associates future behavior. result,
minimizing disappointment always equivalent maximizing accumulated payoffs repeated
game, whereas case regret. showed impossible create
algorithm guaranteed disappointment scenarios without omniscience,
possible create algorithms quickly achieve (and maintain) low disappointment many
algorithms many repeated games.
accomplish goal, presented new meta-algorithm used enhance existing
expert algorithms. algorithm reduces set selectable experts combining aspiration
learning equilibrium computation. showed resulting algorithms quickly achieve
maintain low disappointment associating various static algorithms, reinforcement
learning algorithms, expert algorithms. also showed expert algorithms, given
good set experts, outperform top-performing algorithms literature.
7.1 Reflections Learning Using Experts
meta-algorithm presented enhancing expert algorithms alters order experts
selected. computing highest expected payoff (or potential) expert,
supplying expert algorithm subset experts whose potential meets performance threshold, determined aspiration learning. Experts lower potential
selected experts higher potential demonstrated inability meet potentials.
application optimism-in-uncertainty principle (Brafman & Tennenholtz, 2003) allows
expert algorithms learn effective strategies quickly ensuring expert algorithm
access best expert long term.
Several previously proposed algorithms (e.g., Powers & Shoham, 2005a, 2005b; Knobbout &
Vreeswijk, 2011) select experts serial fashion, beginning expert highest potential. results imperfect information advocate integrated approach
experts evaluated parallel. allows agents better negotiate leader follower
roles, turn leads better chances profitable cooperation compromise.
7.2 Extensions Stochastic Games
expert algorithms discussed analyzed also applied two-player repeated
stochastic games least two different ways. First, Pepper (Crandall, 2012) used extend
algorithm designed repeated normal-form games repeated stochastic games. Pepper uses
separate instance learning algorithm designed normal-form games stage game
stochastic game. Future work determine quickly enhanced expert algorithms
learn stochastic games extended Pepper.
Second, experts complex necessary. Several algorithms computing equilibrium strategies stochastic games recently developed (e.g., Cote & Littman, 2008;
136

fiT OWARDS INIMIZING ISAPPOINTMENT



R EPEATED G AMES

Johanson et al., 2012). equilibrium strategies could define set experts used
enhanced expert algorithms stochastic games. Future work involves identifying effective
set experts stochastic games.

Acknowledgments
would like thank three anonymous reviewers provided detailed constructive feedback.
suggestions, questions, comments greatly improved paper.

Appendix A. Specification Algorithms
Table 5 states parameters settings used algorithm used paper. algorithm
carefully analyzed ensure behaved defined. Parameters algorithms
selected balancing two objectives. First, desired algorithms perform
intended algorithms authors. Second, sought optimize algorithms short-term
performance (i.e., first 1000 rounds) compromising long-term performance.
Since implementation expert algorithm provided literature (though
maintain general principles algorithm), provide details algorithm.
Though originally designed expert algorithm, shown effective
learning select among learning experts repeated games (Bouzy et al., 2011). learns
aspiration level, searches expert obtains payoffs meets aspiration.
sets initial aspiration 1i one, highest payoff. randomly selects expert
, follows joint action played twice. determined comparing
latest joint action Hc , set joint actions played far. ti updated follows:
t|Hc |

ti (i )|Hc |

+ (1 (i )|Hc | )rit ,

(18)

(0, 1) learning rate rit average payoff obtained agent since last
expert selected. updating ti , selects new expert:
(
(t|Hc |)

prob. f (ti , rit )


(19)
random(i ) otherwise
Here, random(i ) denotes random selection , f (ti , rit ) agents inertia given
f (ti , rit ) = min(1, rit /ti

|Hc |

).

(20)

Eq. (20) specifies agent selects expert played previous episode rit
|H |
meets exceeds ti . not, randomly selects new expert probability rit /ti c . Hc
reset include last joint action played, process repeats.

Appendix B. Performance Individual Experts
illustrate effectiveness experts defined Section 3, plot running average payoff
experts three different associates Chicken, PD, Offset, Tricky (Tables 1
2). results shown Figure 11. make several observations. First, scenario,
137

fiC RANDALL

Algorithm
A0
Random
Bully
Godfather

Description Parameters
agent always selects first action.
Randomly selects action uniform distribution action set Ai .
leader strategy (Section 3.1) solution = arg maxs vi (s).
mm
).
leader strategy (Section 3.1) solution = arg maxs (vi (s) vimm )(vi (s) vi
(a) Static algorithms

Algorithm
BR1

Description Parameters
model-based reinforcement learning algorithm encodes state previous joint action.
algorithm estimates associates behavior using fictitious-play assessment conditioned
current state (Eq. 10), computes best response using value iteration (discount factor
1
= 0.95). uses -greedy exploration, = 10+t/10
.

BR2

Identical BR1 except encodes state previous two joint actions.

WoLF-PHC

1
4
See Bowling Veloso (2002). Figure 2, = 100+t/10000
, = 0.05, l = 20000+t
,
1
1
1
2
1
w = 20000+t . Otherwise, = 10+t/100 , = 10+t/100 , l = 100+t/100 , w = 100+t/100

Q-learning

model-free reinforcement learning algorithm proposed Watkins (1992). implementation
encodes state previous joint action uses -greedy exploration. Q-values initialized
1
1
1
highest possible value 1
. = 10+t/10
, = 0.95, = 10+t/100
(b) Reinforcement learning algorithms

Algorithm
Exp3

Description Parameters
expert algorithm (Auer et al., 1995) well-defined regret bounds multi-armed bandit
problem. shown effective repeated games (Bouzy & Metivier, 2010; Crandall &
Goodrich, 2011; Chang & Kaelbling, 2005). implementation evaluates
p expert
= |Ai ||Ai | rounds selecting new expert. = /|i |, = |i |ln(|i |)/(e 1)T0 ,
T0 expected number rounds game.

UCB1

expert algorithm (Auer et al., 2002) well-defined regret bounds adversarial multiarmed bandit problem. proved effective repeated games (Bouzy & Metivier, 2010).
implementation evaluates expert = |Ai ||Ai | rounds selecting new expert.

EEE

-greedy expert algorithm designed repeated games played adaptive associates
1
(de Farias & Megiddo, 2004). = |Ai ||Ai |, = 10+t/10



aspiration-based algorithm original proposed Karandikar et al. (1998), also analyzed
Stimpson et al. (2001). See text Appendix A. = 0.99
(c) Expert algorithms

Algorithm
M-Qubed

Description Parameters
RL algorithm highest asymptotic performance several studies (Crandall & Goodrich,
2011; Bouzy & Metivier, 2010). Parameters set work Crandall Goodrich (2011).

ManipulatorBully

la Powers Shoham (2005a), algorithm serially follows three experts. first 150
rounds, follows Bully. Thereafter, payoffs become lower expected, switches BR1.
300 rounds, payoffs ever drop vimm , plays mm
thereafter.


ManipulatorGodfather

la Powers Shoham (2005a), algorithm serially follows three experts. first 150
rounds, follows Godfather. Thereafter, payoffs become lower expected, switches
BR1. 300 rounds, payoffs ever drop vimm , plays mm
thereafter.

(d) algorithms: standards comparison

Table 5: Algorithmic parameters used paper.

138

fiT OWARDS INIMIZING ISAPPOINTMENT

Chicken: Experts Bully

0.6
0.5
0.4
0.3
0.2
0.1
200

400

600

800

0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
0

1000

1

Running Average Payoff

Running Average Payoff

Running Average Payoff

0.7

200

400



PD: Experts Bully

0.7
0.6
0.5
0.4
0.3
0.2
0.1
600

800

0.7
0.6
0.5
0.4
0.3
0.2
0.1
200

400

400

800

0.6
0.5
0.4
0.3
0.2
0.1
600

800

0.7
0.6
0.5
0.4
0.3
0.2
0.1
200

400

0.7
0.6
0.5
0.4
0.3
0.2
0.1
200

(g)

400

600

800

0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
0

1000

200

400

Tricky: Experts BR1

0.5
0.4
0.3
0.2
0.1
600

800

1000

Tricky: Experts

0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
0

1000

1

Running Average Payoff

Running Average Payoff

0.6

800

(i)

1

0.7

600



(h)

0.8

1000

Offset: Experts



0.9

800

(f)

0.8

Tricky: Experts Bully

600

1



1

1000



0.9

0
0

1000

800

0.8

0
0

1000

Running Average Payoff

0.7

600

0.9

Offset: Experts BR1

0.8

(j)

200

(e)

0.9



0.1



Running Average Payoff

Running Average Payoff

600

1

400

0.2

PD: Experts

0.8

Offset: Experts Bully

200

0.3

(c)

0.9

0
0

1000

1

400

0.4

1

(d)

200

0.5



Running Average Payoff

Running Average Payoff

Running Average Payoff

0.8

400

0.6

PD: Experts BR1

0.9

200

0.7

0
0

1000

1



Running Average Payoff

800

0.8

(b)

1

0
0

600

0.9



(a)

0
0

Chicken: Experts

1

0.8

0
0

R EPEATED G AMES

Chicken: Experts BR1

1
0.9

0
0



200

400

600

800

1000

0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
0

200

400



(k)

600

800

1000



(l)

Figure 11: Running average payoffs expert BR1, S, Bully four different
games. Results average 50 trials.

139

fiC RANDALL

least one expert performs well opponent. example, Chicken,
ideal algorithm able eventually achieve average payoff near 1 BR1
many rounds. Several experts achieve performance level (Figures 11b 11c).
Bully, best possible average payoff 0.33, several experts achieve (Figure 11a).
Furthermore, PD, expert eventually obtains average payoff mutual
cooperation (0.6) associate (Figures 11d11f).
Second, Figure 11 illustrates different payoffs possible different associates.
example, Chicken Tricky, best expert Bully substantially lower
payoffs (despite playing optimally) best experts BR1 S. note disappointment normalizes performance cases average disappointment zero
indicates effective play relative set experts.
Third, reaching highest possible payoff sometimes requires lot patience. example,
Chicken (Figure 11c), best expert 100 rounds best expert 1000
rounds. repeatedly following expert many rounds associate learn
accept equilibrium offered expert. illustrates difficult expert algorithms
maintain low disappointment time.

References
Arora, R., Dekel, O., & Tewari, A. (2012). Online bandit learning adaptive adversary:
regret policy regret. Proceedings 29th International Conference Machine
Learning, pp. 15031510.
Auer, P., Cesa-Bianchi, N., & Fischer, P. (2002). Finite-time analysis multi-armed bandit
problem. Machine Learning, 47, 235256.
Auer, P., Cesa-Bianchi, N., Freund, Y., & Schapire, R. E. (1995). Gambling rigged casino:
adversarial multi-armed bandit problem. Proceedings 36th Symposium
Foundations Computer Science, pp. 322331.
Axelrod, R. (1984). Evolution Cooperation. Basic Books.
Bouzy, B., & Metivier, M. (2010). Multi-agent learning experiments repeated matrix games.
Proceedings 27th International Conference Machine Learning, pp. 119126.
Bouzy, B., Metivier, M., & Pellier, D. (2011). Hedging algorithms repeated matrix games.
ECML Workshop Machine Learning Data Mining Around Games, Athens,
Greece.
Bowling, M. (2004). Convergence no-regret multiagent learning. Advances Neural
Information Processing Systems 17, pp. 209216.
Bowling, M., & Veloso, M. (2002). Multiagent learning using variable learning rate. Artificial
Intelligence, 136(2), 215250.
Brafman, R. I., & Tennenholtz, M. (2003). R-max general polynomial time algorithm nearoptimal reinforcement learning. Journal Machine Learning Research, 3, 213231.
Cesa-Bianchi, N., Dekel, O., & Shamir, O. (2013). Online learning switching costs
adaptive adversaries. Advances Neural Information Processing Systems 26, pp. 1160
1168.
140

fiT OWARDS INIMIZING ISAPPOINTMENT



R EPEATED G AMES

Chakraborty, D., & Stone, P. (2010). Convergence, targeted optimality, safety multiagent
learning. Proceedings 27th International Conference Machine Learning, pp.
191198.
Chang, Y., & Kaelbling, L. P. (2005). Hedge learning: Regret-minimization learning experts.
Proceedings 22nd International Conference Machine Learning, pp. 121128.
Chang, Y.-H. (2007). regrets no-regret. Artificial Intelligence, 171(7), 434439.
Chasparis, G., Shamma, J., & Arapostathis, A. (2010). Aspiration learning coordination games.
Proceedings 49th IEEE Conference Decision Control, pp. 57565761.
Cote, E. M. D., & Littman, M. L. (2008). polynomial-time Nash equilibrium algorithm
repeated stochastic games. Proceedings 24th Conference Uncertainty Artificial
Intelligence, pp. 419426.
Crandall, J. W. (2012). add Pepper: extending learning algorithms repeated matrix games
repeated markov games. Proceedings 11th International Conference Autonomous
Agents Multiagent Systems, pp. 399406.
Crandall, J. W., & Goodrich, M. A. (2011). Learning compete, coordinate, cooperate
repeated games using reinforcement learning. Machine Learning, 82(3), 281314.
Crandall, J. W., & Goodrich, M. A. (2005). Learning teach follow repeated games.
AAAI workshop Multiagent Learning, Pittsburgh, PA.
de Farias, D., & Megiddo, N. (2003). combine expert (or novice) advice actions
impact environment. Advances Neural Information Processing Systems 16.
de Farias, D., & Megiddo, N. (2004). Explorationexploitation tradeoffs expert algorithms
reactive environments. Advances Neural Information Processing Systems 17, pp. 409
416.
Foster, D. P., & Vohra, R. (1999). Regret on-line decision problem. Games Economic
Behavior, 29, 735.
Fudenberg, D., & Levine, D. K. (1998). Theory Learning Games. MIT Press.
Ganzfried, S., & Sandholm, T. (2011). Game theory-based opponent modeling large imperfectinformation games. Proceedings 10th International Conference Autonomous
Agents Multiagent Systems, pp. 533540.
Gordon, G. J., Greenwald, A., & Marks, C. (2008). No-regret learning convex games. Proceedings 25th International Conference Machine Learning, pp. 360367.
Greenwald, A., & Jafari, A. (2003). general class no-regret learning algorithms gametheoretic equilibria. Proceedings 16th Annual Conference Computational Learning Theory, pp. 212.
Greenwald, A., & Hall, K. (2003). Correlated Q-learning. Proceedings 20th International
Conference Machine Learning, pp. 242249.
Johanson, M., Bard, N., Lanctot, M., Gibson, R., & Bowling, M. (2012). Efficient Nash equilibrium
approximation Monte Carlo counterfactual regret minimization. Proceedings
11th International Conference Autonomous Agents Multiagent Systems, pp. 837
846.
141

fiC RANDALL

Karandikar, R., Mookherjee, D., R., D., & Vega-Redondo, F. (1998). Evolving aspirations
cooperation. Journal Economic Theory, 80, 292331.
Knobbout, M., & Vreeswijk, G. A. (2011). Sequential targeted optimality new criterion
teaching following repeated games. Proceedings 10th International Conference Autonomous Agents Multiagent Systems, pp. 517524.
Littman, M. L. (1994). Markov games framework multi-agent reinforcement learning.
Proceedings 11th International Conference Machine Learning, pp. 157163.
Littman, M. L. (2001). Friend-or-foe: Q-learning general-sum games. Proceedings 18th
International Conference Machine Learning, pp. 322328.
Littman, M. L., & Stone, P. (2001). Leading best-response strategies repeated games. IJCAI
workshop Economic Agents, Models, Mechanisms, Seattle, WA.
Littman, M. L., & Stone, P. (2005). polynomial-time Nash equilibrium algorithm repeated
games. Decision Support Systems, 39, 5566.
Powers, R., & Shoham, Y. (2005a). Learning opponents bounded memory. Proceedings 19th International Joint Conference Artificial Intelligence, pp. 817822.
Powers, R., & Shoham, Y. (2005b). New criteria new algorithm learning multi-agent
systems. Advances Neural Information Processing Systems 17, pp. 10891096.
Stimpson, J. R., Goodrich, M. A., & Walters, L. C. (2001). Satisficing learning cooperation
prisoners dilemma. Proceedings 17th National Conference Artificial
Intelligence, pp. 535544.
Watkins, C. J., & Dayan, P. (1992). Q-learning. Machine Learning, 8, 279292.

142

fiJournal Artificial Intelligence Research 49 (2014) 49-78

Submitted 07/13; published 01/14

Robustness Stability Constraint Programming
Dynamism Uncertainty
Laura Climent

LCLIMENT @ DSIC . UPV. ES

Instituto de Automatica e Informatica Industrial
Universidad Politecnica de Valencia, Spain.

Richard J. Wallace

R . WALLACE @4 C . UCC . IE

INSIGHT Center Data Analytics
Department Computer Science. University College Cork, Ireland.

Miguel A. Salido

MSALIDO @ DSIC . UPV. ES

Instituto de Automatica e Informatica Industrial
Universidad Politecnica de Valencia, Spain.

Federico Barber

FBARBER @ DSIC . UPV. ES

Instituto de Automatica e Informatica Industrial
Universidad Politecnica de Valencia, Spain.

Abstract
Many real life problems solved constraint programming, come uncertain
dynamic environments. dynamism, original problem may change time,
thus solution found original problem may become invalid. reason, dealing
problems become important issue fields constraint programming.
cases, extant knowledge uncertain dynamic environment. cases,
information fragmentary unknown. paper, extend concept robustness
stability Constraint Satisfaction Problems (CSPs) ordered domains, limited
assumptions need made possible changes. present search algorithm searches
robust stable solutions CSPs nature. well-known meeting
criteria simultaneously desirable objective constraint solving uncertain dynamic
environments. also present compelling evidence search algorithm outperforms
general-purpose algorithms dynamic CSPs using random instances benchmarks derived
real life problems.

1. Introduction
Constraint programming powerful tool solving many artificial intelligence problems
modeled CSPs. Much effort spent increasing efficiency algorithms
solving CSPs, reflected literature. However, techniques assume set
variables, domains constraints involved CSP known fixed problem
modeled. strong limitation deal real life situations problems
may come uncertain dynamic environments. Due dynamism environment,
original problem corresponding modeled CSP may evolve. addition, since
c
2014
AI Access Foundation. rights reserved.

fiC LIMENT, WALLACE , ALIDO & BARBER

real world uncertain nature, information dynamism environment may
incomplete, erroneous even may exist. situations, solution holds original
model become invalid changes original problem.
approaches deal situation classified as: (i) reactive approaches, whose
main objective obtain new solution similar possible previous solution (the solution
found changes occurred) efficient way, (ii) proactive approaches, use
knowledge possible future changes order avoid minimize effects (for survey
see Verfaillie & Jussien, 2005). Thus, proactive approaches applied changes occur,
reactive approaches applied changes invalidate original solution.
Reactive approaches re-solve CSP solution loss, consumes computational
time. clear inconvenience, especially deal short-term changes, solution loss frequent. addition, many applications, online planning scheduling,
time required calculate new solution may long actions taken redress
situation. addition, loss solution several negative effects modeled situation. example, task assignment production system several machines, could cause
shutdown production system, breakage machines, loss material/object
production, etc. transport timetabling problem, solution loss, due disruption
point, may produce delay propagates entire schedule. negative effects
probably entail economic loss well.
Proactive approaches try avoid drawbacks stated and, therefore, highly valued dealing problems uncertain dynamic environments. Given advantages
proactive approaches potentially offer, paper restrict approach. Heretofore two main types proactive approaches considered, distinguished
basis characteristics solutions obtain, called robust flexible
(see Section 2). important survey constraint solving uncertain dynamic environments
(Verfaillie & Jussien, 2005), authors mention possibility developing proactive strategies
combine solution features robustness flexibility. state: production
solutions time robust flexible, every chance resist changes
easily adapted resist, obviously desirable objective. paper,
present algorithm meets objective combining solution robustness stability.
solution feature stability special case flexibility.
Many proactive approaches proposed literature assume existence knowledge
uncertain dynamic environment (see Section 3). cases difficult characterize
robustness solutions detailed information possible future changes available. consider situations added difficulty stemming fact
limited assumptions changes made. discussion focuses CSPs ordered
discrete domains model problems order elements domain
significant. cases, common type change problems may undergo restrictive
modifications bounds solution space. assumptions motivations
introduced Climent et al. (2013). Moreover, examples real life problems exhibit
type dynamism described, specifically, temporal reasoning-based problems, spatial geometric reasoning problems, design problems. temporal problems, delays inherent
feature, implies restrictive modifications bounds involved disruptions.
instance, Fu, Lau, Varakantham, Xiao (2012) stated unexpected external events
manpower availability, weather changes, etc. lead delays advances completion activities
50

fiROBUSTNESS TABILITY C ONSTRAINT P ROGRAMMING DYNAMISM U NCERTAINTY

scheduling problems. spatial geometric reasoning problems, constraints readjusted due measurement errors. latter also occur design problems, data
completely certain.
paper, present algorithm searches solutions CSPs ordered domains,
robust also stable often repaired using value similar
magnitude undergo value loss. paper organized follows. next section recalls
general definitions. Section 3 gives brief account earlier proactive procedures. Section 4
presents new conception robustness stability exists order elements
domain. Sections 5 6 describe main objective finding solutions meet stability
robustness criteria simultaneously. Then, Section 7 search algorithm meets
objectives explained. Section 8 presents case study scheduling problems. Section 9 describes
experiments various types CSPs, showing effectiveness present approach
finding solutions stable robust. Section 10 gives conclusions.

2. Technical Background
section give basic definitions used rest paper, following standard
notations definitions literature.
Definition 2.1 Constraint Satisfaction Problem (CSP) represented triple P = hX , D, Ci
X finite set variables X = {x1 , x2 , ..., xn }, set domains = {D1 , D2 , ..., Dn }
variable xi X set values variable take, C
finite set constraints C = {C1 , C2 , ..., Cm } restrict values variables simultaneously take. denote DC set unary constraints associated D.
Definition 2.2 tuple assignment values subset variables Xt X .
tuple feasible call s. means assignment domain values
variables violate constraint. complete assignment (it involves
variables CSP), solution CSP. Xs subset variables involved
s. X \Xs set unassigned variables s. value assigned variable x
denoted s(x). addition, denote Ds (x) D(x) subset domain values
variable x consistent s.
number possible tuples constraint
Q Ci C composed elements
Cartesian product domains var(Ci ): xj var(Ci ) Dj , var(Ci ) X set
variables involved Ci (scope Ci ).
Definition 2.3 tightness constraint ratio number forbidden tuples
number possible tuples. Tightness defined within interval [0,1].
Inferential processes CSPs narrow search space possible partial solutions. work
use one known used consistency procedure: arc-consistency.
Definition 2.4 CSP arc-consistent (Mackworth, 1977a) iff pair constrained variables
xi xj , value Di exists least one value b Dj partial
assignment (xi = a, xj = b) satisfies constraints related xi xj . value
51

fiC LIMENT, WALLACE , ALIDO & BARBER

domain variable arc-consistent eliminated part
solution. domain variable arc-consistent iff values arc-consistent. Thus,
problem arc-consistent iff arcs arc-consistent:
Cij C, D(xi ), b D(xj ): b satisfy Cij .
following, several properties associated solutions problems come
dynamic environments defined.
Definition 2.5 robust solution CSP within set solutions one highest
likelihood remaining solution given set changes CSP.
Definition 2.6 flexible solution anything (a partial solution, complete solution, conditional
solution, set solutions, etc.) that, case change, easily modified produce solution
new problem (Verfaillie & Jussien, 2005).
specific concept flexibility concept stability.
Definition 2.7 solution s1 stable another solution s2 if, event
change invalidates them, closer alternative s1 s2 exists (modified work
presented Hebrard, 2006).
main difference Definition 2.7 Definition 2.6 former introduces
concept closer solution. measurement closeness made calculating distances
solutions. concrete information distance equations explained following
sections. would like remark Definition 2.5 consider alterations original
solution resistance changes problem. hand, Definition 2.6
Definition 2.7 consider changes original solution new solution produced
change problem.

3. Related Work: Proactive Approaches
Several approaches proposed past handling type problem,
classified based kind solutions obtain. Thus, techniques search robust
solutions others search flexible solutions (for survey see Verfaillie & Jussien, 2005).
section describe techniques search robust solutions limitations.
discuss technique searches certain type stable solutions: super-solutions.
3.1 Searching Robust Solutions
Many earlier approaches search robust solutions use additional information uncertain dynamic environment problem occurs, often involves probabilistic representations. one example type, information gathered form penalties
values invalidated changes problem (Wallace & Freuder, 1998). Nevertheless, Probabilistic CSP model (PCSP) (Fargier & Lang, 1993), exists information
associated constraint, expressing probability existence. techniques focus
dynamism variables CSP. instance, Mixed CSP model (MCSP) (Fargier,
52

fiROBUSTNESS TABILITY C ONSTRAINT P ROGRAMMING DYNAMISM U NCERTAINTY

Lang, & Schiex, 1996) subsequent Uncertain CSP model (UCSP) (Yorke-Smith & Gervet,
2009) consider dynamism certain uncontrollable variables take different values
uncertain domains. related model, uses Simple Temporal Networks, adds data
time uncertainties preferences, represent starting ending times events (STPPUs) (Rossi, Venable, & Yorke-Smith, 2006). Stochastic CSP model (SCSP) (Walsh, 2002)
also considers probability distributions associated uncontrollable variables. Branching
CSP model (BCSP) considers possible addition variables (with certain associated gain)
current problem (Fowler & Brown, 2000).
models, form algorithm dependent detailed knowledge
dynamic environment. purpose, list possible changes required explicit
representation uncertainty, often form associated probability distribution. result,
approaches cannot used necessary information unknown. many real problems,
however, knowledge possible changes either limited non-existent. Hence,
important need techniques find robust solutions kind environment.
instance, Climent et al. (2013) cope CSPs model problems order
domain elements significant. Specifically, CSPs modeled Weighted Constraint
Satisfaction Problems (WCSPs) (Larrosa & Schiex, 2004) penalizing valid tuples based
coverings. Instead requiring extra detailed dynamism information, authors make limited
assumptions concerning changes might occur, related nature CSPs
ordered domains. Specifically, dynamism assumed take form restrictions bounds
solution space. paper, make assumptions dynamism.
previous WCSP modeling approach computes robustness based feasible neighbours compose
covering surrounds analyzed value respect constraint boundary. Thus,
cases neighbour feasible respect one bound another bound,
neighbour feasible solution space. reason, approach obtains robustness
approximations problems high relation constraints.
hand, algorithm described paper computes feasible assignments respect entire
solution space, avoids weakness WCSP modeling approach explained above.
comparison approaches found Section 9.
3.2 Searching Super-Solutions
Techniques search stable solutions certain type, denoted super-solutions,
presented Hebrard (2006). goal able repair invalid solution changes
occur, minimal changes specified advance. Since another approach
require detailed additional information changes problem, interest
compare search algorithm introduced paper.
Definition 3.1 solution (a, b)-super-solution loss values variables
repaired assigning values variables changing values b
variables (Hebrard, 2006).
CSPs, major focus finding (1, 0)-super-solutions. high
computational cost computing b > 0 > 1. one reasons analyze
particular super-solution case paper. reason given Verfaillie Jussien
(2005), authors state desirable objective limit much possible changes
53

fiC LIMENT, WALLACE , ALIDO & BARBER

produced solution, motives search (a, 0)-super-solutions. general, unusual find (1, 0)-super-solutions variables repaired. reason, Hebrard
(2006) also developed branch bound-based algorithm finding solutions close
(1, 0)-super-solutions, i.e., number repairable variables maximized (also called maximizing (1, 0)-repairability).

4. Extending Robustness Stability CSPs Ordered Domains
section extend original definition solution robustness (Definition 2.5) solution
stability (Definition 2.7) consider CSPs ordered domains, limited assumptions
made changes problem derived inherent structure. Given
framework therefore existence significant order values domains,
reasonable assume original bounds solution space restricted relaxed,
even cover possible changes. bounds solution space delimited
domains constraints CSP. Note possibility solution loss exists
changes original bounds solution space restrictive. reason,
solution located farther away bounds likely remain solution. Given
assumptions, specialize Definition 2.5 framework follows.
Definition 4.1 robust solution CSP ordered domains without detailed dynamism
data solution maximizes distance dynamic bounds solution space.
Furthermore, definition stable solutions CSPs ordered domains made
precise possible define specific notion closeness two solutions
due existent order domain values. Hebrard (2006) measures level dissimilarity
two solutions counting
Pn number variables take different values solutions, i.e.,
Hamming distance ( i=1 (s1i 6= s2i )). Later, Hebrard, OSullivan, Walsh (2007) consider
another similarity measure: Manhattan distance.
P measure uses sum absolute difference values (of variable) solutions ( ni=1 |s1i s2i |). Note unlike Hamming
distance, Manhattan distance requires order elements order calculate absolute
difference values. following definition, apply Manhattan distance notion
stable solutions CSPs ordered domains.
Definition 4.2 Given order relationship values set solutions, solution s1
stable another solution s2 iff, event change invalidates them, exists
alternative solution s1 lower Manhattan distance Manhattan distance
alternative solution s2.
Furthermore, present extension Definition 3.1 CSPs ordered domains fixing
maximum Manhattan distance original solution repaired solution,
called c.
Definition 4.3 solution (a, b, c)-super-solution loss values variables most,
repaired assigning values whose Manhattan distance respect original
values lower equal c, involves changing values b variables most.
definition also holds (1, 0, c)-super-solutions (1, 0, c)-repairability,
main focus stability analysis paper.
54

fiROBUSTNESS TABILITY C ONSTRAINT P ROGRAMMING DYNAMISM U NCERTAINTY

5. Searching Robust Stable Solutions: General Main Objective
order find robust stable solutions CSPs ordered domains assumptions,
combine robustness stability criteria presented Section 4. mentioned, calculating
distances required search robust solutions framework. However, measure
distance dynamic bounds solution space always obvious easy derive,
since bounds delimited domains constraints CSP, latter may
extensionally expressed. However, deductions minimum distances bounds
made based feasibility neighbours solution. idea first motivated
simple example formalized.
Example 5.1 Figure 1 shows two solution spaces (one convex non-convex) whose
dynamic bounds marked contiguous lines. robust solutions according Definition
4.1 highlighted. Note two contiguous feasible neighbours sides
assignment (discontinuous lines).

(a) Convex Solution Space

(b) Non-convex Solution Space

Figure 1: Robust solutions different solution spaces.
example, conclude ensure solution located
least distance bound certain direction n-dimensional space tuples
distances lower equal direction feasible. Therefore, number
feasible contiguous surrounding neighbours solution measure robustness
solution face restrictive changes affect original bounds solution space (see
Definition 4.1). addition fulfilling main objective finding solutions whose values
high number feasible neighbours close assignment, criterion used obtain
solutions high stability. value assigned variable least one
feasible neighbour values, variable repairable. is, assigned value
lost, easily repaired assigning neighbour value (since value consistent
rest values assignment). Regarding stability notion Definition 4.2, note
difference lost value repairable value low, since immediate
neighbours. fact, value difference one, minimum possible.
55

fiC LIMENT, WALLACE , ALIDO & BARBER

set feasible contiguous neighbour values value v differences greater
k respect v increasing, decreasing, directions respect order
relationship denoted Nk (x, v, s, ). Value v feasible value variable x feasible
partial/complete assignment s. Here, say values feasible, mean
also feasible respect s. (Recall use Ds (x) D(x) subset domain values
consistent feasible partial assignment s.) list operators composed
set paired elements, operator pairs. operator pair denoted {{>, +}, {<, }}.
operator pairs fix order directions analyze. Thus, set {>, +} refers values greater
v (increasing direction) set {<, } refers values lower v (decreasing direction).
operator pair, operator position j referenced ij . instance, list
operators = {{>, +}, {<, }}, operator pair 1 references {>, +} operator 12
references operator +. Given notation, define Nk (x, v, s, ) as:
Nk (x, v, s, )= {w Ds (x) : , w i1 v |v w| k

(1)

z j [1 . . . (|v w| 1)], (v z2 j) Ds (x)}
first condition Equation 1 ensures value w greater lower v according
operator i1 {>, <} distance values less equal k.
second condition ensures values closer v w also feasible values s.
least one not, value w cannot belong Nk (x, v, s, ). mentioned previously,
set feasible neighbours value contiguous. Otherwise, infeasible
space value another feasible value. instance, Figure 1(b) value 5
belong Nk (y, 2, {x = 2}, ) k value 4 feasible value
therefore outside bounds solution space.
general case CSPs ordered domains assume bounds
dynamic, desirable objective find contiguous surrounding feasible neighbours
sides. reason = {{>, +}, {<, }}. list operator pairs, last condition
Equation 1 checks values directions closer v w, also feasible
values s. instance, Figure 1(b), Nk (y, 2, {x = 2}, {{>, +}, {<, }}) = {1, 3} k
value. Note neighbours sides value 2 respect axis. Section
8, show specific case desirable apply one operator pair due
nature problem.
apply Equation 1 domains ordered Z, monotonic order-preserving
function applied. instance, consider = {f reezing, cold, mild, warm, hot,
boiling}, monotonic function assigns greater values values higher temperatures could
defined. example, f (f reezing) = 1, f (cold) = 2, f (mild) = 3, f (warm) = 4, f (hot) =
5 f (boiling) = 6.

6. Objective Function
Section 5 stated main desirable objective selected value many contiguous feasible neighbours certain direction, determine minimum distance
value bound direction. approximating distance several values assigned
(partial complete assignment), compute number neighbours value. Therefore,
56

fiROBUSTNESS TABILITY C ONSTRAINT P ROGRAMMING DYNAMISM U NCERTAINTY

define objective function search algorithm sum size Nk (x, v, s, )
(denoted |Nk (x, v, s, )|) variable x X . incomplete assignment, calculate
maximum |Nk (x, v, s, )| v Ds (x) unassigned variable x X \Xs (upper
bound). Note maximum size set neighbour values variable | | k,
| | number pair operators. Thus, maximum size set neighbour values
2k composed two operator pairs k composed one operator pair. Note
also necessary check values Ds (x) if, least one them, size
set maximum possible. following equation, formalize objective function
used search algorithm.

f (s, k, ) = {

X

max{|Nk (x, v, s, )|, v Ds (x)} +

X

|Nk (y, s(y), s, )|}

(2)

yXs

xX \Xs

Example 5.1, robust solutions Figures 1(a) 1(b) (highlighted solutions) f (s, k, {{>, +}, {<, }}) = 4, k 1, since every value assigned solution
two contiguous neighbours sides.
Next, give formal rationale using total number neighbours solution (sum
feasible surrounding neighbours value solution) measure robustness.
k = 1, convex solution space, value either zero, one two feasible neighbours. discount case zero neighbours assignment zero feasible
neighbours, must part singleton domain, part solutions.
need consider values one two feasible neighbours.
case, solution greater sum one whose assignments feasible neighbour pairs. easily seen consider difference solution whose
values one feasible neighbour solution; difference equal
number feasible neighbour pairs associated latters assignments.
Proposition 1. assume two feasible neighbours confers greater robustness
one probabilities single changes independent, solution
greater feasible neighbour-sum another also robust, vice versa.
non-convex case, unfortunately possible one assignment zero feasible
neighbours, assignments variable one two. case, cannot
assume Proposition 1. However, number variables problem increases, becomes
increasingly unlikely variable assignment zero feasible neighbours
associated largest neighbour-sum remaining variables.
Regarding measure stability, solution maximizes (1, 0, k)-repairability (see
Definition 4.3) also maximizes number variables repaired neighbour value
distance less equal k (without modifying variable). However, obtain robust
solutions maximize sum neighbour values value solution. Note even
maximization criteria identical, mentioned, number variables
problem increases, becomes increasingly unlikely non-repairable variable associated
largest neighbour-sum remaining variables. work use
technique finding robust stable solutions CSPs ordered domains. Nevertheless,
basic units measure criteria different.
57

fiC LIMENT, WALLACE , ALIDO & BARBER

7. Search Algorithm
section present algorithm finding robust stable solutions according main
objective described Section 6. purpose, incorporated optimization criterion
Branch & Bound algorithm (Algorithm 1) maximizes objective function f (s, k, )
(see Equation 2). mentioned, function sums |Nk | assigned variable maximum
possible |Nk | unassigned variable. Note computation upper bound final
total number feasible contiguous neighbours solution.
Algorithm 1 (B&B-Nk ) anytime algorithm uses inference process prunes
branches whose objective function value lower equal current maximum function
value obtained, referred lb (lower bound). process stops branches
explored pruned, providing solution maximum f (s, k, ). hand,
limit search time therefore quality best solution found fixing time cutoff.
course, time Algorithm 1 spends searching, robust stable solution
provided be. addition, compute maximum possible objective function value,
maximum number neighbours variable multiplied number variables
CSP, denoted ub (upper bound). Thus, objective function value new solution found
equal ub, algorithm stops, since solution optimal.
Algorithm 1: B&B-Nk : Branch & Bound anytime algorithm
Data: P = hX , D, Ci, , k, scale, m, time cutoff (optional)
Result: s, Nk , lb
; // Partial assignment
Xs ; // Set variables assigned
Nk ; // Set contiguous surrounding neighbours
lb 1; // Maximum f (s, k, ) solutions
ub | | k |X |;
1;
GAC3-Nk (P, s, Xs , Nk , , k, lb);
repeat
restarting-scratch new solution found
1;
C scale mi ; //number fails cutoff
+ 1;
time cutoff MGAC3-Nk (P, s, Xs , Nk , , k, lb, 0, C, ub);
implemented Branch & Bound algorithm using Geometric restart strategy (Walsh,
1999) order reduce repetition fails search due early wrong assignments
(thrashing). Thus, time number failures (referenced nbF ) reaches number-offails cutoff value condition (C) checked Algorithm 3, algorithm restarts search
scratch, except constraint weights stored dom/wdeg heuristic variable selection
(Boussemart et al., 2004). value number fails cutoff increased geometrically Algorithm 1 according scale factor (referred scale) multiplicative factor (referred
m). implemented two different options carry solution found. first,
called restarting-completion, first solution found, algorithm continues search
58

fiROBUSTNESS TABILITY C ONSTRAINT P ROGRAMMING DYNAMISM U NCERTAINTY

completion (this done assigning huge number representing number fails cutoff).
second option, called restarting-scratch, solution found, algorithm restarts
search scratch also restarts number fails cutoff computation (the constraint weighs
remain same). instances large domain sizes, restarting option effective
avoids spending large amount time specific branch. latter happens
Algorithm 1 checks many domain values variables located low levels search tree, objective function partial assignment better current maximum (lb).
case, exists time cutoff, Algorithm 1 could analyze branches tree
may contain solutions better quality.
inference process carried Algorithm 2 (GAC3-Nk ), extension
well-known AC3 (Mackworth, 1977b) performs Generalized Arc Consistency (GAC) (Mohr
& Henderson, 1986; Bessiere, 2006). specific notation included, var(c),
scope c C. original seekSupport function GAC3 searches support
domain value. modified function slightly providing set values
analysed parameter function. Thus, values deleted
exist consistent support respect partial assignment, seekSupport returns
false. function first called values domain variables (for checking
partial assignment GAC3) later Nk assigned variables (for checking
Nk (x, s(x), s, ) GAC3 respect s). order ensure contiguity values Nk ,
Algorithm 2 checks consistency subsets Ni Nk , equal one initially,
increased one unit least one values Ni inconsistent reaches value
k. complexity updating Ni reduced | | domains ordered. Note
case greater lower values candidates set, updating
cost 2 i. composing set contiguous neighbour values GAC3 respect s,
Algorithm 2 analyzes objective function f (s, k, ) greater lb. not,
GAC3, returns false.
Algorithm 3 (MGAC3-Nk ) performs Maintaining GAC3 procedure assigning variable x X new value v D(x), value selected GAC3-Nk respect s.
implemented two value selection heuristics: lexicographical order selection value
maximizes |Nk (x, v, s, )|, starting intermediate values. real life problems
lexicographical selection order effective finding feasible solutions quickly.
example scheduling problems, whose domain values represent time units; hence importance
selecting low values order exceed maximum fixed makespan. However,
important select low values, heuristic starts intermediate values may offer better
results selecting values maximize objective function current node
search tree. Furthermore, since search starts intermediate values, likelihood selecting
values located far domain bounds higher.
Algorithm 3 also responsible updating set assigned variables Xs , partial assignment maximum objective function value lb (for solution found). Furthermore,
stores domains set neighbours variables making assignment. Note
variable x assigned, D(x) contains single value value assigned x. Algorithm 2 (GAC3-Nk ) returns false, Algorithm 3 (MGAC3-Nk ) carries backtracking
process also restores domains set neighbours variables.
reduce computational time deal CSPs convex domains, implemented Bounds Arc Consistency discrete CSPs (Lhomme, 1993). main feature
59

fiC LIMENT, WALLACE , ALIDO & BARBER

Algorithm 2: GAC3-Nk : Global Arc Consistency algorithm
Data: P, s, Xs , Nk , , k, lb, nbF
Result: D, Nk , nbF
Q {(x, c), c C, x var(c)} // var(c) scope c
Q 6=
(x, c) takeElement(Q);
seekD seekSupport(x, D(x), c); // Found support D(x) c?
D(x) =
nbF nbF + 1; // number failures
return false
seekD
Q Q {(y, c ), c C c 6= c x, var(c ) x 6= y}
x Xs
1;
repeat
update Ni (x, s(x), s, ) applying Equation 1;
seekN seekSupport(x, Ni (x, s(x), s, ), c);
+ 1;
seekN = false > k;
Nk (x, s(x), s, ) Ni (x, s(x), s, )
return f (s, k, ) > lb // See Equation 2

consistency technique arc consistency restricted respect bounds
convex domain. Thus, including search algorithm affects seekSupport function, instead seeking support set values, checks minimum
maximum bounds. Note implementation necessary search robust stable solutions; however allows significant reduction search time. apply bounds
consistency tentative values assignment set neighbours, since
require complete consistency check. Otherwise could exist infeasible gaps, would
break contiguity requirement ensures minimum distances bounds.

8. Case Study: Searching Robust Stable Schedules
types real life problems whose structure provide us specific information
dynamism. section analyze well known type problem literature:
scheduling problems. problems converted satisfiability problems fixing
maximum makespan, modeled CSPs. CSP modeling usually consists
associating start end time task particular variable (in paper use
start time). domain associated variable represents possible time units, means
possible fix maximum desired makespan. Finally, duration tasks
order (if exists) fixed means CSP constraints.
section, first explain robustness scheduling measurement units,
describe objective function CSPs model scheduling problems give example
application.
60

fiROBUSTNESS TABILITY C ONSTRAINT P ROGRAMMING DYNAMISM U NCERTAINTY

Algorithm 3: MGAC3-Nk : Maintaining Global Arc Consistency
Data: P, s, Xs , Nk , , k, lb, nbF, C, ub
Result: s, Nk , lb
select x X \Xs ; // dom/wdeg heuristic
Xs Xs x;
save Nk ;
D(x) 6= nbF < C
select min(v) D(x); // Heuristic 1: lexicographical value order
select v D(x), max{|Nk (x, v, s, )|} starting intermediate values; // Heuristic 2
{x = v}
D(x) v;
GAC3-Nk (P, s, Xs , Nk , k, lb, nbF )
Xs = X
// New solution found
lb f (s, k, );
lb = ub
return true // Best possible sum achieved
C ; // restarting-completion
return false // restarting-scratch
MGAC3-Nk (P, s, Xs , Nk , k, lb, nbF, C, uB)
return true
restore D\D(x) Nk ;
s\{x = v};
Xs Xs \x;
return false

8.1 Robustness Measurement Scheduling
section, introduce several criteria measuring scheduling robustness.
purpose, use terms buffers slack refer spare time related tasks.
two main factors enhance capability schedule absorb unexpected delays
activities: number buffers duration. Ideally, according robustness criterion,
buffer time long possible longer is, longer delays
able absorb. reason another straight-forward robustness measurement proposed
Leon et al. (1994) slack average schedule. combination duration
buffers distribution across schedule provides accurate robustness measure

denoted Rslack
. slight variant measure introduced Surico et al. (2008) consists
maximizing slack average (shorted avg) minimizing standard deviation (shorted
std) schedule s. regulating importance standard deviation term, authors
use parameter called , take value interval [0.2,0.25], according authors
considerations.


Rslack
= avg(slack) std(slack)

61

(3)

fiC LIMENT, WALLACE , ALIDO & BARBER

Another means measuring robustness system, defined Kitano (2007) related
resistance perturbations certain probability occurrence. approach
extended Escamilla et al. (2012) scheduling problems probabilities task delays
, Z discrete set unexpected
unknown. robustness measure denoted RF,Z
delays duration tasks, F measures whether schedule still feasible disruption
1
, z Z probability
(F (z) = 1 satisfiable, otherwise F (z) = 0) p(z) = |z|
instance z Z (i.e., delays considered probability occurrence).

RF,Z
=

X

p(z) F (z)

(4)

zZ

8.2 Objective Function Scheduling
CSP models scheduling problems, fact domain values represent time units implications respect measures robustness stability. problems, value
solution lost, lower values cannot used replacing unfeasible value represent time units already taken place. Thus, incident, time point
available, neither values lower t. Therefore, lower feasible neighbours
improve robustness stability solution CSP models scheduling problem
(since cannot absorb delays used repairable values). Given characteristics,
main desirable objective search neighbours greater value assigned. this,
fix set operators = {{>, +}} scheduling problems. illustrated below.
Example 8.1 consider toy scheduling problem two tasks: T0 T1 . duration two time units must executed order listed. maximum makespan
allowed six time units. Figure 2 see associated CSP model solution space.
variables X0 X1 represent start times tasks T0 T1 , respectively. domain
variables (represented discontinuous lines) [0 . . . 4], preserves maximum
makespan six time units (the maximum start time task maximum makespan minus
duration aforesaid task). one constraint controlling execution order tasks
(T0 must start T1 ), C0 : X1 X0 + 2. solution space represented dark
gray area, six solutions (black dots).
specific information given dynamic environment, schedule
robust? stated Section 8.1, greater number time buffers greater duration, robust schedule is. determine solution modeled
CSP meets requirements? answer obtained determining feasible contiguous
neighbours greater values, located distances less equal k solution. However,
depending value k, either prioritize selection schedules large number
short time buffers prioritize selection schedules lower number long time
buffers. number greater feasible neighbours associated value variable corresponds
total amount slack located task represented variable. Thus, slack
able absorb delay previous task long itself, without modifying tasks
present schedule (robustness feature). Furthermore, slack following task sufficient
absorb delay, start following task delayed (after repairing broken assigned
value) long enough buffer associated later task (stability feature).
62

fiROBUSTNESS TABILITY C ONSTRAINT P ROGRAMMING DYNAMISM U NCERTAINTY

3

4

X1

0

1

2

C0

0

1

2

3

4

X0

Figure 2: CSP model associated Example 8.1 solution space.
example, two-dimensional CSP representing scheduling problem
two tasks, three schedules robust according criteria stated above.
maximize sum distances greater values located distance one (k = 1)
value assignment, obtain solution shown Figure 3(a), whose sum f (s0 , k =
1, {>, +}) = 1 + 1. first number Nk (x0 , v0 , s, {>, +}) second Nk (x1 , v1 , s, {>, +}),
v0 v1 values assigned variables x0 x1 respectively. Note sums
neighbours greater solution values located distance one
f (s1 , k = 1, {>, +}) = 1 + 0 f (s2 , k = 1, {>, +}) = 0 + 1, respectively. following (a)
figures, greater neighbours indicated elipse, arrow pointing solution (the
circled dot). associated (b) figures, schedules equivalent solutions marked (a)
shown. Note greater neighbours indicated (a) figures correspond slack
(b) figures. instance, Figure 3(b) task associated slack duration one,
corresponds existence one greater neighbour value assignment Figure 3(a).
hand, maximize sum greater neighbors values k > 1, three
solutions represented Figures 3(a), 4(a) 5(a) classified best solutions according
objective function. computation sum neighbours located distance lower
equal k, k > 1 is: f (s0 , k > 1, {>, +}) = 1 + 1 (Figure 3(a)), f (s1 , k > 1, {>, +}) = 2 + 0
(Figure 4(a)) f (s2 , k > 1, {>, +}) = 0 + 2 (Figure 5(a)). Note schedules Figures
4(b) 5(b) one time buffer, duration two time units, unlike schedule
represented Figure 3(b) two time buffers one unit each. Thus, fixing k = 1
prioritize seek high number time buffers. However, greater k values, prioritize
duration, even case distribution may optimal.
consider stability solutions, small modifications solutions always
preferred. case, possible task starts scheduled time, reassigning
start time closer greater neighbour, composing another schedule similar
original one. Therefore, search feasible greater neighbours (which introduces buffers
tasks schedule) improving both, robustness stability obtained schedules.
search schedules buffers k time units also achieved model
reformulation techniques. achieved adding two variables original variable (the
variables represent start time tasks). One variable represents slack following
task variable represents sum slack original starting time.
63

fiC LIMENT, WALLACE , ALIDO & BARBER

0

1

2

X0

4
3

Slack

T0

2

X1

0
(a) Solution space.

1

2

T1
3

4

Slack
5

6

(b) Schedule marked solution.

Figure 3: Robust schedule s0 = (x0 = 0, x1 = 3) Example 8.1 greater neighbours
k 1.

0

1

2

X0

4
3

Slack

T0

2

X1

0
(a) Solution space.

1

2

3

T1
4

5

6

(b) Schedule marked solution.

Figure 4: Robust schedule s1 = (x0 = 0, x1 = 4) Example 8.1 greater neighbours
k > 1.

0

1

2

X0

4
3

T0

2

X1

0
(a) Solution space.

1

Slack

T1
2

3

4

5

6

(b) Schedule marked solution.

Figure 5: Robust schedule s2 = (x0 = 0, x1 = 2) Example 8.1 greater neighbours
k > 1.

64

fiROBUSTNESS TABILITY C ONSTRAINT P ROGRAMMING DYNAMISM U NCERTAINTY

instance, let pi starting time task xi . Thus, would add constraint pi = pi + si ,
si represents slack associated task xi . addition, depending maximum desired
duration buffers, another constraint may added, si k. case, delay
k timeP
units. addition, objective function express goal maximizing total
slack (max ni=1 si ) must defined.
Furthermore, proactive specific approaches scheduling problems involve
CSP found Herroelen Leus (2005) survey. main advantage approach
presented paper proactive alternatives scheduling problems approach
applied slack-values require consistency check. requirement necessary
scheduling problems intermediate non-valid slack values possible. Examples type
problem scheduling problems limited machine availability (see, instance Schmidt,
2000). cases, machines unavailable certain time intervals; reason, tasks
require resources cannot executed time units. happens
scheduling operators, workers breaks day. Moreover,
also exist reactive approaches, re-schedule activities disruption invalidates
original schedule found. example, solving dynamic Resource-Constrained Project Scheduling
Problems (RCPSP) (Elkhyari, Gueret, & Jussien, 2004).

9. Experimental Results
section, present results experiments designed evaluate performance Algorithm 1. Solutions obtained restarting-completion procedure referred neighbour
solutions graphs tables throughout section. Solutions obtained restarting-scratch
referred neighbour solutions(R). Experiments done random problems
benchmarks presented literature. random instances generator (RBGenerator 2.0),
benchmarks parser XCSP instances found Christophe Lecoutres web
page 1 .
addition assessing search Algorithm 1, also evaluated two proactive methods
require specific additional information dynamism. One WCSP
modeling technique (Climent et al., 2013), based dynamism assumptions
present work. solutions obtained technique referred WCSP-mod
solutions. evaluated approach scheduling problems
consider adaptation scheduling problems presented Section 8.2 (neighbouring values lower magnitude considered). proactive approach
maximizes (1, 0)-repairability (see Section 3.2). implement technique, modified Algorithm 1 (B&B-Nk ) exchanging MGAC3-Nk GAC3-Nk algorithms MAC+
GAC+ (Hebrard, 2006), respectively. solutions obtained technique referred
(1, 0)-super-solutions. addition, solutions ordinary CSP solver analyzed (referred simple solutions), order detect whether cases solutions
similar robustness and/or stability.
addition, added geometric restart (restarting-completion) bounds consistency techniques explained Section 7 ordinary CSP solver super-solutions solver order
provide computational advantages. approach models CSPs WCSP,
1. http://www.cril.univ-artois.fr/ lecoutre/index.html

65

fiC LIMENT, WALLACE , ALIDO & BARBER

used solver one used Climent et al. (2013): ToulBar22 . necessary
use different solver evaluation technique approach requires WCSP
solver. approaches evaluated, values selected lexicographical order
time cutoff fixed 100 seconds. Experiments run Intel Core i5-650 Processor (3.20
Ghz). addition, geometric restart, scale factor fixed 10 multiplicative
factor 1.5.
evaluation based two main features solutions obtained proactive approaches:
stability robustness. tables section, best robustness/stability results obtained
marked bold. accordance assumptions laid previous sections, use
robustness stability measures described Section 4. Here, note ordinary CSP
solver super-solutions solver consider dynamism assumptions WCSP
modeling technique approach presented paper. say, consider
possible future restrictive modifications bounds solution space CSPs ordered
domains. Regarding stability, technique maximizes (1, 0)-repairability searches
stable solutions according Definition 3.1. However, mentioned above, paper analyze
precise concept stability CSPs ordered domains, (1, 0, c)-repairability (see
Definition 4.3).
9.1 Robustness Analysis General CSPs
section analyze robustness stability solutions obtained wide range
tightness values. purpose, random CSPs generated RBGenerator 2.0,
non-convex constraints represented extensionally. non-convexity domains, bounds consistency technique cannot used. CSPs generated 25 variables
domain size 30 200 binary constraints. Domain values integer values interval
[0, 29]. tightness values analyzed 0.1, 0.2, 0.3. (Note: 0.34 critical value
tightness CSP typology.) tightness generated 10 random instances
solved Algorithm 1 k = 1. analysis deal general case CSPs
ordered domains (see Section 5.1) fixed set operators search algorithm
= {{>, +}, {<, }} value selection heuristic 2 (see Section 7), maximizes
|Nk (x, v, s, )| starting intermediate values.
mentioned previously, usually feasible compute complete set solutions
CSP. reason, order measure robustness solutions obtained four
approaches, sampled closest surrounding neighbours (k = 1). Thus, closest surrounding neighbour solution CSP, means analyzed solution could become
infeasible change magnitude one greater original bound/s invalidate
neighbour. hand, neighbour solution CSP, means restrictive modification would invalidate analyzed solution. Therefore, satisfiability checking
random sample neighbours solutions provides estimation likelihood
solutions remain valid, say, estimation robustness.
sampling feasibility neighbourhood solutions, made certain number
random modifications magnitude k values assigned variables solutions.
number values assigned variables solutions modified, denoted
nbV arM od [1 . . . 10]. value nbV arM od, sampled 500 neighbours
2. http://carlit.toulouse.inra.fr/cgi-bin/awki.cgi/ToolBarIntro

66

fiROBUSTNESS TABILITY C ONSTRAINT P ROGRAMMING DYNAMISM U NCERTAINTY

solution analyzed checked feasibility. average number feasible neighbours
type solution shown Table 9.1. observed Algorithm 1 either restarting
option dramatically outperformed ordinary CSP solver technique maximizes
(1, 0)-repairability. also outperformed WCSP modeling approach tightness 0.2 0.3.
weakness latter approach obtains robustness approximations problems
high relation constraints, computes feasible neighbours
constraint boundary. Thus, higher tightness, higher likelihood existence
neighbour tuples feasible one constraint/domain another one.
conflicting situations less frequent unconstrained instances. reason, tightness
0.1 performance modeling approach better. However, obtains better robustness
results Algorithm 1 highly unrestricted instances high nbV arM od values. regard
Algorithm 1, restarting-completion option provides better results restarting-scratch
(differentiated R) unconstrained instances, preform similarly higher
tightness values. Figure 6(b) selected nbV arM od = 2 emphasize trends robustness
stability function varying tightness.
tightness

0.1

0.2

nbV arM od

2

Approach

Average Number feasible neighbours sample

simple
super
WCSP-m
neigh
neigh(R)

7.2
8.8
152.4
206.8
191.6

4

0.6
0.6
60.2
75
74.4

6

0
0
24.5
27.4
24.4

8

0
0
12.8
10.8
7.9

10

0
0
5.8
3.8
2.9

2

0.2
1
5.7
36.2
33.9

0.3
4

0
0
0.1
2.5
2

6

0
0
0
0
0.5

8

10

2

4

6

0
0
0
0
0.1

0
0
0
0
0

0
0.4
0.4
2.8
2.5

0
0
0.1
0.1
0

0
0
0
0
0

Table 1: Robustness Analysis Based tightness (< 2, 25, 30, 200, tightness >).
stability measurement, (1, 0, 1)-repairability used (see Definition 4.3), measures number variables replaced value located distance one
value assigned without modifying rest values solution. Stability results shown
Figure 6(a). mentioned, solution value lost, objective find closest repairable
values. reason, algorithm consider feasible values k units greater
smaller value assigned, since could result future solutions Manhattan
distance new solution original one would exaggeratedly great (see Section
4). hand, technique maximizes (1, 0)-repairability considers value
repairable value. fact represents disadvantage searching repairable values
ordered domains. observed Figure 6(a), see poor performance
super-solutions (1, 0, 1)-repairability.
would like note CSPs highly restricted, stability robustness
solutions obtained evaluated methods similar. due fact
cases CSPs solutions consequently distances solutions
bounds low. instances, number solutions low
solutions scattered within tuple-space, likelihood solution located
bounds solution space high. reason, likelihood variable
67

fiC LIMENT, WALLACE , ALIDO & BARBER

25
neighbours solution
neighbours (R) solution
simple solution
(1,0)-super-solution
WCSP-mod solution

(1, 0, 1)-repairability

20

15

10

5

0
0.1

0.2
Tightness

0.3

Average sampling number neighbour solutions

(a) Stability analysis
neighbours solution
neighbours (R) solution
simple solution
(1,0)-super-solution
WCSP-mod solution

200

150

100

50

0
0.1

0.2
Tightness

0.3

(b) Robustness analysis nbV arM od = 2

Figure 6: Combined robustness-stability based tightness (< 2, 25, 30, 200, tightness >).
curves shifted improving clarity graph.

68

fiROBUSTNESS TABILITY C ONSTRAINT P ROGRAMMING DYNAMISM U NCERTAINTY

feasible repairable value near-by low. even case none solutions
assignment feasible neighbours located distance k. case, solutions
equally robust stable k value.
9.2 Scheduling Benchmarks Evaluation
section, evaluate approaches scheduling benchmarks literature order
determine robustness schedules obtained wide range k values. analyzed five
sets 10 job-shop CSP instances, studied Sadeh Fox (1996). instance composed
10 jobs five tasks five resources. job random linear sequence
resources visit, exception bottleneck resources, visited fixed
number operations (in order increase resource contention).
analysis deals scheduling problems (see Section 8) fixed set
operators search Algorithm 1 = {{>, +}} value selection done heuristic
1, values selected lexicographical order. Regarding proactive technique
evaluated, author (1, 0)-repairability approach (Hebrard, 2006) made extension
concept breakage (the loss assigned value) scheduling problems. breakage
kind problem considered delay duration task. Therefore, values
greater value assigned time units considered repairable values. reason,
evaluation scheduling problems, incorporated condition (1, 0)-repairability
approach. proper comparison approach approaches, used values
k parameters. following, order avoid term repetition, assume = k.
Note ordinary CSP solver use parameter, obtains schedule
value k.
measuring robustness schedules obtained, used robustness measures introduced Section 8.1. first robustness assessment made measuring total slack whose
duration exceed k, denoted tS(k). addition, accurate measure

(k) (see Equation 3), measures average total slack, minus standard
also used, Rslack
deviation multiplied parameter. parameter fixed 0.25, inside
interval authors consider appropriate parameter. Another robustness measure used

based resistance schedule faced perturbations, denoted RF,Z
(see Equation 4), Z set incidents consist delays durations maxd tasks.
used 2 different values maxd : 1 k. case, independently simulated 500
delays maxd units equal probability entire schedule checked schedule
remained valid. stability measurement, again, (1, 0, 1)-repairability used (see Definition
4.3), equivalent measurement number buffers schedule, denoted
nbB. Note desired objective cases repairs necessary, start time
task delayed short time possible.
following figures tables show evaluation two Sadeh problem sets.
problem sets obtained similar results. show results e0ddr1 e0ddr2 benchmarks order compare robustness stability schedules obtained different numbers
bottlenecks problem (other parameters fixed). Sadeh stated e0ddr1 benchmark
contained one bottleneck hand, e0ddr2 benchmark contained two bottlenecks.
Tables 9.2 9.2 show means robustness stability measures scheduling problems. addition, measurements shown, including number schedules obtained nbS,
69

fiC LIMENT, WALLACE , ALIDO & BARBER

total number restarts done search algorithm nbR, total number nodes explored nbN
total number failures nbF . Figure 7 shows stability robustness measurements

(k) e0ddr1. horizontal axis
(vertical axis): mean number buffers mean Rslack
figures represents value ratio parameters k.
k

Approach

nbS

nbR

nbN

nbF

nbB

tS(k)


Rslack
(k)


RF,Z
(1)


RF,Z
(k)

1

simple
super
neigh
neigh(R)

1
9.1
12.7
15.5

3.1
3.1
3.1
28.8

208
7770.4
10171.1
2820.4

85
3043.7
2465.9
628.1

16.1
21.4
27.8
31.3

16.1
21.4
27.8
31.3

0.208
0.308
0.436
0.509

0.328
0.434
0.562
0.628

0.338
0.43
0.555
0.618

3

simple
super
neigh
neigh(R)

1
7.3
15.9
15.5

3.1
3.1
3.1
27.7

208
8138.2
5880.5
2406.5

85
2619.2
2485.1
670.5

16.1
18.9
20.9
22.3

44.3
52.4
59.4
62.1

0.555
0.702
0.832
0.886

0.328
0.384
0.424
0.448

0.311
0.36
0.409
0.413

5

simple
super
neigh
neigh(R)

1
7.1
19
12.9

3.1
3.1
3.1
23.8

208
8373.2
3947.7
2082.3

85
2654.2
1674.7
517.8

16.1
19.1
19.5
20.2

67.8
82.9
86.3
87.3

0.832
1.101
1.159
1.182

0.328
0.388
0.396
0.406

0.288
0.343
0.364
0.35

7

simple
super
neigh
neigh(R)

1
6.5
19.9
11.5

3.1
3.1
3.1
21.2

208
8319.1
3205.9
1871.8

85
3219.5
1032.6
489.5

16.1
18.1
18.9
18.7

88.1
101.8
107.8
108.6

1.057
1.298
1.4
1.413

0.328
0.368
0.384
0.376

0.271
0.303
0.331
0.314

9

simple
super
neigh
neigh(R)

1
5.7
20.8
11.4

3.1
3.1
3.1
19.7

208
8715.7
2793.6
1711.4

85
2620.7
974.2
462.8

16.1
17.6
18.6
18.2

105.7
117.6
126.5
126

1.242
1.452
1.602
1.588

0.328
0.358
0.378
0.368

0.257
0.277
0.303
0.293

11

simple
super
neigh
neigh(R)

1
6
19
7.9

3.1
3.1
3.1
16.9

208
8019.9
2518.5
1593.9

85
1775.8
844.4
435.5

16.1
18.2
18.1
18.4

120.5
133.6
140.2
138.8

1.389
1.629
1.72
1.693

0.328
0.37
0.368
0.374

0.244
0.256
0.28
0.277

Table 2: Evaluation e0ddr1 benchmark.
expected, schedules obtained approaches e0ddr1 benchmark
robust stable e0ddr2 benchmark (see Tables 9.2 9.2) robustness
analysis, see algorithm k = 11 (for restarting options) increased robustness
(k) 0.5 units problems one bottleneck. Therefore,
measure RF,Z
expected, fewer bottlenecks scheduling problem has, robust schedule obtained
algorithm. Detailed results robustness measures found columns tS(k),

(1) Rs (k) tables. instance, largest k value analyzed (k =
Rslack
(k), RF,Z
F,Z
11), total sum buffer times duration k schedule obtained Algorithm
1 restarting-completion 140.2 time units e0ddr1 benchmark 109.67 time units
e0ddr2 benchmark (more 30 time units difference). Regarding stability analysis,
algorithm k = 1 restarting-scratch (differentiated R) found schedules four mean
number buffers (nbB) problems one bottleneck problems two
70

fiROBUSTNESS TABILITY C ONSTRAINT P ROGRAMMING DYNAMISM U NCERTAINTY

k

Approach

nbS

nbR

nbN

nbF

nbB

tS(k)


Rslack
(k)


RF,Z
(1)


RF,Z
(k)

1

simple
super
neigh
neigh(R)

0.9
6.5
10.1
12.4

4
3.9
4
25.4

227
8024.33
11264.22
2555.67

98.89
1975.67
1865.22
709.33

14.11
19.89
24.33
27.44

14.11
19.89
24.33
27.44

0.17
0.28
0.37
0.43

0.28
0.4
0.49
0.55

0.28
0.41
0.49
0.55

3

simple
super
neigh
neigh(R)

0.9
4.9
16.4
11.9

4
3.9
3.9
22.2

227
8602.67
7141.78
2282.67

98.89
1198.67
1711.33
503.89

14.11
17.33
20.22
20.11

37.56
47.22
56
55.22

0.44
0.61
0.77
0.76

0.28
0.35
0.4
0.4

0.25
0.32
0.37
0.37

5

simple
super
neigh
neigh(R)

0.9
4.4
17.3
8.6

4
3.9
3.9
18.9

227
9102.78
5755.22
2036.11

98.89
743.67
1657.33
452.78

14.11
17.11
18.11
17.89

55.11
70.89
76.67
73.89

0.63
0.89
0.99
0.95

0.28
0.34
0.36
0.36

0.22
0.29
0.31
0.3

7

simple
super
neigh
neigh(R)

0.9
3.8
15.2
7.7

4
3.9
3.9
17.5

227
9721.67
4903
1827.44

98.89
914.22
1272.56
428.78

14.11
15.78
16.89
17.22

68.22
82.22
88.78
88.67

0.75
0.97
1.09
1.09

0.28
0.32
0.34
0.35

0.2
0.25
0.26
0.26

9

simple
super
neigh
neigh(R)

0.9
3.1
15.7
6.4

4
3.9
3.9
16.2

227
9971
4344.44
1657.56

98.89
959.56
1161.78
449.22

14.11
15.56
16.78
16.78

78.67
92.89
101.11
100.44

0.84
1.06
1.2
1.19

0.28
0.31
0.34
0.34

0.18
0.21
0.24
0.23

11

simple
super
neigh
neigh(R)

0.9
2.3
14.7
5.6

4
3.9
3.9
14.4

227
10698.22
4251.78
1588.89

98.89
1090.44
1223.56
390

14.11
15.22
16.22
16.11

87.44
98.89
109.67
107.67

0.91
1.08
1.25
1.22

0.28
0.3
0.32
0.32

0.16
0.19
0.21
0.2

Table 3: Evaluation e0ddr2 benchmark.

71

fiC LIMENT, WALLACE , ALIDO & BARBER

32
neighbours solution
neighbours solution (R)
simple solution
(1,0)-super-solution

30

Mean number buffers

28
26
24
22
20
18
16
1

3

5

7

9

11

k

(a) Stability analysis
1.8
neighbours solution
neighbours solution (R)
simple solution
(1,0)-super-solution

1.6

Mean RslackS(k)

1.4
1.2
1
0.8
0.6
0.4
0.2
1

3

5

7

9

11

k

(b) Robustness analysis

Figure 7: Combined robustness-stability k parameter: mean measures e0ddr1 benchmark.

72

fiROBUSTNESS TABILITY C ONSTRAINT P ROGRAMMING DYNAMISM U NCERTAINTY

bottlenecks best case. Therefore, expected, fewer bottlenecks scheduling problem
has, stable schedule obtained algorithm.
tables figure, see Algorithm 1 either restarting option outperformed ordinary CSP solver technique maximizes (1, 0)-repairability.
Furthermore, analysis k parameter shows parameters lowest values, number buffers schedules found algorithm markedly greater
two techniques (see Figure 7(a)). contrast, improvement robustness algorithm
respect ordinary solver little marked greater k values. comparison
(1, 0)-repairability technique shows tendency e0ddr2 benchmark (see nbB Table
9.2).
Regarding robustness measures plotted figure shown
(1) measure number
Tables 9.2 9.2, see correlation RF,Z
(1)
buffers. relation expected, since random incidents generated measuring RF,Z
delays one unit time. Therefore, buffers (whatever duration) greater

likelihood schedule absorb delays one time unit. addition, tS(k), Rslack
(k)

RF,Z (k) measures correlated. Recall tS(k) total slack whose duration

(k) average minus standard deviation multiplied parameter.
exceed k Rslack
Therefore, unless distribution slack poor, two values must proportional.

(k), greater proportionality respect
Note lower parameter Rslack

two robustness measures. RF,Z (k) measure calculated generating random delays
duration k schedule. reason, robustness measure strongly related
two aforementioned. example relation aforementioned measurement
units observed Table 9.2 k = 11, schedules obtained restarting-scratch
(1) values, schedules
option (differentiated R) greater numbers buffers RF,Z

(k) values.
obtained restarting-completion option greater tS(k), Rslack
(k) RF,Z
means latter greater total slack whose duration exceed k, distribution
limited.
Tables 9.2 9.2 also observe measurements correlated robustness
stability, important information still extracted them. k > 1, restartingcompletion algorithm finds greater mean number solutions (nbS). k = 1
restarting-scratch (differentiated R) find solutions. greater k is, easier
find new solutions whose objective function better maximum one (if instance
highly restricted). reason, mean number solutions found greater high
k values. restarting options, mean number solutions considerably higher
approach maximizes (1, 0)-repairability. effect stronger greater values
k condition repairable value latter technique becomes restrictive.
Moreover, technique considers feasible values domains repairable values; result,
feasibility checking slower techniques assume k neighbours (as technique
does). expected, mean number restarts (nbR) much greater restarting-scratch
option techniques restart finding first solution. consequence,
mean number nodes explored (nbN ) mean number failures (nbF ) lower.
schedules obtained Algorithm 1 lowest k value highest number buffers.
hand, robustness measures greater greater k values. Depending
dynamic nature problem, would desirable prioritize higher number
buffers short duration lower number buffers long duration (if two features cannot
73

fiC LIMENT, WALLACE , ALIDO & BARBER

maximized). Thus, known possible future delays duration
least time units, make sense compute k values lower obtained
time buffers could absorb delay. hand, known possible future delays
cannot duration greater d, make sense compute k values greater
time units may decrease number buffers. Hence, information
possible future changes have, better robustness results obtain. However, even
information unknown, obtain schedule certain level robustness
stability setting k intermediate value Algorithm 1.
34
neighbours solution
neighbours solution (R)
simple solution
(1,0)-super-solution

32

Mean number buffers

30
28
26
24
22
20
18
16
10

20

30

40

50
60
Time(s)

70

80

90

100

70

80

90

100

(a) k = 1
34
neighbours solution
neighbours solution (R)
simple solution
(1,0)-super-solution

32

Mean number buffers

30
28
26
24
22
20
18
16
10

20

30

40

50
60
Time(s)

(b) k = 7

Figure 8: Mean number buffers time intervals e0ddr1 benchmark.
evaluation consists analyzing best results obtained technique
fixed cutoff time. However, also wanted analyze change degree robustness
stability schedules found time. evaluation, used e0ddr1 benchmark
determined mean 50 instances interval time discretization 10
74

fiROBUSTNESS TABILITY C ONSTRAINT P ROGRAMMING DYNAMISM U NCERTAINTY

seconds. Figures 8(a) 8(b) show mean number buffers found approach k = 1
k = 7. measures shown since similar trends found cases. would
like highlight 20 seconds simple solution technique find better schedules
searches one schedule instance (which done less equal 20
seconds). remarkable aspect k = 1 Algorithm 1 restarting options
obtains greater number buffer times approach maximizes (1, 0)-repairability,
k = 1 time intervals (see Figure 8(a)).
hand, Figure 8(b), represents k = 7, shows unstable results. Since
difficult find buffers seven time units, may happen algorithm sacrifices
shorter buffers order find one buffer seven time units. Thus, even overall tendency
measure increase time, entirely uniform. hand,
upward shape trend approach searches super-solutions due fact
considers values repairable possible alternative start time task
follows task sharing resource, equivalent slack associated
task schedule. reason, schedules better technique may contain lower
number buffers. feature marked greater values k, since repairable values
least k unit times greater assigned values, therefore unlikely
find repairable values close assigned ones.
concluded general approach maximizes (1, 0)-repairability finds
solutions lower robustness stability (considering closest repairable values)
approach aforementioned reason. Another disadvantage assumes delays
duration d. Thus, values greater value considered repairable values.
However, consider k neighbours therefore, slacks duration lower k also
valued objective function contrast (1, 0)-repairability objective function.
basis evaluation, conclude difference performance
two restarting options (restarting-completion restarting-scratch) significant. Sometimes, time needed restart scratch solution makes option less effective
restarting-completion. cases, restarting-completion option loses time branches
better solutions, restarting-scratch explores branches. instance,
random experiments, restarting-completion provided slightly better results generally (see Table 9.1 Figure 6(b)), scheduling problems, restarting-scratch obtained schedules
bit robust stable lower k values (see k [1, 5] Figure 7). greater k
values, restarting options gave similar results.

10. Conclusions
paper extend concept robustness stability CSPs discrete ordered
domains limited assumptions made changes problems. particular, uncertainty statistics probabilities incidences occur
original problem. context, reasonable assume original bounds solution
space may undergo restrictive modifications, introduced Climent et al. (2013). Therefore, main objective searching robust solutions find solutions maximize
Euclidean distances dynamic bounds solution space. hand, main
objective searching stable solutions terms repairable variables find solutions whose
repairable values close possible broken assignments.
75

fiC LIMENT, WALLACE , ALIDO & BARBER

paper, present new search algorithm combines criteria robustness
stability framework. algorithm developed paper searches solution
maximizes sum contiguous feasible surrounding neighbours distances k less
values solution. obtained solutions high probability remaining valid
possible future restrictive changes constraints domains original problem
(robustness criterion), also high number variables easily repaired
value distance lower equal k undergo value loss (stability criterion).
evaluated new algorithm experiments well-known scheduling benchmarks
well random CSPs. shown versions new algorithm outperform
three approaches evaluated: ordinary CSP solvers, technique maximizes
(1, 0)-repairability, approach models CSPs WCSPs many conditions
real differences robustness solutions might obtained. latter occurs
problem constrained valid solutions. respect
two restarting options developed algorithm, found performance
significantly different, although certain situations advantage one other.
slightly constrained CSPs, algorithm obtains solutions greatest number closer
neighbour solutions, greatest (1, 0, 1)-repairability highest values specific measures
scheduling robustness. Furthermore, shown increasing k large problems,
also increase robustness, although may happen (1, 0, 1)-repairability decreases.
instance, scheduling problems schedules obtained lower k values tend maximize
number buffers even size small. However, computation higher k values tends
give priority duration buffers consequence, number buffers obtained
lower. Therefore, depending dynamic nature problem, would desirable
prioritize higher number short buffers lower number long buffers (if
possible maximize features).
extension robustness stability definition CSPs discrete ordered
domains development search algorithm finding robust stable solutions
context, useful practical many real life situations problems undergo restrictive
changes added difficulty information possible future changes limited
non-existent. Even difficult conditions, search algorithm able provide stable
robust solutions. Finding solutions located far away dynamic bounds important
face restrictive modifications bounds solution space. Moreover, cases
value lost, important replace nearby value order solution
similar possible original one. closeness feature handled algorithm
approach searches super-solutions.

Acknowledgments
work partially supported research project TIN2010-20976-C02-01 FPU
program fellowship (Min. de Ciencia e Innovacion, Spain). wish thank Dr. Christophe
Lecoutre Dr. Diarmuid Grimes assistance.
76

fiROBUSTNESS TABILITY C ONSTRAINT P ROGRAMMING DYNAMISM U NCERTAINTY

References
Bessiere, C. (2006). Constraint propagation. Foundations Artificial Intelligence, 2, 2983.
Boussemart, F., Hemery, F., Lecoutre, C., & Sais, L. (2004). Boosting systematic search weighting constraints. Proceedings 16th European Conference Artificial Intelligence
(ECAI-04), Vol. 16, p. 146.
Climent, L., Wallace, R. J., Salido, M. A., & Barber, F. (2013). Modeling robustness CSPs
weighted CSPs. Proceedings 10th International Conference Integration Artificial Intelligence Operations Research techniques Constraint Programming (CPAIOR13), pp. 4460.
Elkhyari, A., Gueret, C., & Jussien, N. (2004). Constraint programming dynamic scheduling
problems. Hiroshi Kise, editor, ISS04 International Scheduling Symposium, pp. 8489.
Escamilla, J., Rodriguez-Molins, M., Salido, M., Sierra, M., Menca, C., & Barber, F. (2012). Robust solutions job-shop scheduling problems operators. 24th IEEE International
Conference Tools Artificial Intelligence (ICTAI-12), pp. 209306.
Fargier, H., & Lang, J. (1993). Uncertainty Constraint Satisfaction Problems: probabilistic approach. Proceedings Symbolic Quantitative Approaches Reasoning Uncertainty (EC-SQARU-93), pp. 97104.
Fargier, H., Lang, J., & Schiex, T. (1996). Mixed Constraint Satisfaction: framework decision
problems incomplete knowledge. Proceedings 13th National Conference
Artificial Intelligence (AAAI-96), pp. 175180.
Fowler, D., & Brown, K. (2000). Branching Constraint Satisfaction Problems solutions robust
likely changes. Proceedings International Conference Principles
Practice Constraint Programming (CP-2000), pp. 500504.
Fu, N., Lau, H., Varakantham, P., & Xiao, F. (2012). Robust local search solving RCPSP/max
durational uncertainty. Journal Artificial Intelligence Research, 43, 4386.
Hebrard, E. (2006). Robust Solutions Constraint Satisfaction Optimisation Uncertainty. Ph.D. thesis, University New South Wales.
Hebrard, E., OSullivan, B., & Walsh, T. (2007). Distance constraints Constraint Satisfaction.
Proceedings 20th International Joint Conference Artificial Intelligence (IJCAI-07),
pp. 106111.
Herroelen, W., & Leus, R. (2005). Project scheduling uncertainty: Survey research potentials. European Journal Operational Research, 165(2), 289306.
Kitano, H. (2007). Towards theory biological robustness. Molecular Systems Biology, 3(1).
Larrosa, J., & Schiex, T. (2004). Solving weighted CSP maintaining arc consistency. Artificial
Intelligence, 159, 126.
Leon, V., Wu, S., & Robert, H. (1994). Robustness measures robust scheduling job shops.
IIE transactions, 26(5), 3243.
Lhomme, O. (1993). Consistency techniques numeric CSPs. Proceedings 13th International Joint Conference Artificial Intelligence (IJCAI-93), Vol. 13, pp. 232232.
77

fiC LIMENT, WALLACE , ALIDO & BARBER

Mackworth, A. (1977a). Consistency network relations. Artificial Intelligence, 8, 99118.
Mackworth, A. (1977b). reading sketch maps. Proceedings 5th International Joint
Conference Artificial Intelligence (IJCAI-77), pp. 598606.
Mohr, R., & Henderson, T. C. (1986). Arc path consistency revisited. Artificial intelligence,
28(2), 225233.
Rossi, F., Venable, K., & Yorke-Smith, N. (2006). Uncertainty soft temporal constraint problems:
general framework controllability algorithms fuzzy case. Journal Artificial
Intelligence Research, 27(1), 617674.
Sadeh, N., & Fox, M. (1996). Variable value ordering heuristics job shop scheduling
Constraint Satisfaction Problem. Artificial Intelligence, 86(1), 141.
Schmidt, G. (2000). Scheduling limited machine availability. European Journal Operational
Research, 121(1), 115.
Surico, M., Kaymak, U., Naso, D., & Dekker, R. (2008). Hybrid meta-heuristics robust
scheduling. ERIM Report Series Reference No. ERS-2006-018-LIS, Available SSRN:
http://ssrn.com/abstract=902747.
Verfaillie, G., & Jussien, N. (2005). Constraint solving uncertain dynamic environments:
survey. Constraints, 10(3), 253281.
Wallace, R., & Freuder, E. (1998). Stable solutions Dynamic Constraint Satisfaction Problems.
Proceedings 4th International Conference Principles Practice Constraint Programming (CP-98), pp. 447461.
Walsh, T. (1999). Search small world. Proceedings International Joint Conference
Artificial Intelligence, Vol. 16, pp. 11721177.
Walsh, T. (2002). Stochastic Constraint Programming. Proceedings 15th European Conference Artificial Intelligence (ECAI-02), pp. 111115.
Yorke-Smith, N., & Gervet, C. (2009). Certainty closure: Reliable constraint reasoning incomplete erroneous data. Journal ACM Transactions Computational Logic (TOCL),
10(1), 3.

78

fi
