Journal Artificial Intelligence Research 49 (2014) 501-525Submitted 09/13; published 03/14Information-Theoretic Multi-view Domain Adaptation: TheoreticalEmpirical StudyPei YangYANGPEI @ SCUT. EDU . CNSouth China University TechnologyGuangzhou, ChinaWei GaoWGAO @ QF. ORG . QAQatar Computing Research InstituteQatar Foundation, Doha, QatarAbstractMulti-view learning aims improve classification performance leveraging consistencyamong different views data. incorporation multiple views paid little attentionstudies domain adaptation, view consistency based source data largely violatedtarget domain due distribution gap different domain data. paper, leverage multiple views cross-domain document classification. central idea strengthenviews consistency target data identifying associations domain-specific featuresdifferent domains. present Information-theoretic Multi-view Adaptation Model (IMAM)using multi-way clustering scheme, word link clusters draw together seemingly unrelated features across domains, boosts consistency document clusteringsbased respective word link views. Moreover, demonstrate IMAMalways find document clustering minimal disagreement rate overlap viewbased clusterings. provide theoretical empirical justifications proposed method.experiments show IMAM significantly outperforms traditional multi-view algorithm cotraining, co-training-based adaptation algorithm CODA, single-view transfer model CoCClarge-margin-based multi-view transfer model MVTL-LM.1. Introductionmany mission-critical applications data mining, natural language processing informationretrieval, typically expensive time-consuming obtain appropriate training data learnneeded models. example, sentiment classifiers online reviews need work properlydata different types products; search engines must provide consistent quality serviceWeb data markets different languages verticals. However, training data commonlyexist limited number domains. Collecting annotating data different domainswould become practically prohibitive.Domain adaptation task utilizes training data domain (i.e., out-of-domainsource domain) effectively transform relevant knowledge domain taskperformed (i.e., in-domain target domain). Abundant labeled data may exist source domainwebpage data training general Web search ranker, readily availabletarget domains ranking systems image search music search. out-of-domaindata commonly drawn form feature distribution differentin-domain counterpart. Bridging domain gap challenging issue model learnedsource domain generalized well target domain. practical reasons, domain adaptationc2014AI Access Foundation. rights reserved.fiYANG & G AOgreat importance many real-world applications, entity mention detection (DaumeIII & Marcu, 2006), document classification (Sarinnapakorn & Kubat, 2007), sentiment classification (Blitzer, Dredze, & Pereira, 2007), part-of-speech tagging (Jiang & Zhai, 2007),recently Web search ranking (Gao, Cai, Wong, & Zhou, 2010; Cai, Gao, Zhou, & Wong, 2011a,2011b; Gao & Yang, 2014).Many types data represented multiple independent sets features, reflectingdifferent views data. example, document classification, Web document features consistword-based features also features based link structures among documents (Blum & Mitchell, 1998); Web search, document rankers accept query-dependentfeatures (e.g., tfidf, BM25, language-modeling IR scores, etc.) well query-independent features (e.g., page rank, inlink/outlink numbers, url click count, etc.) (Gao, Blitzer, Zhou, & Wong,2009). Traditionally, learning scheme called multi-view learning aims improve classifiersleveraging redundancy consistency among distinct views (Blum & Mitchell, 1998;Ruping & Scheffer, 2005; Abney, 2002). Existing methods multi-view learning designeddata single domain, assumes either view alone predict in-domainclass consistently accurately. However, view-consistency assumption largely violatedsetting domain adaptation training test data drawn different distributions(which empirically justified experiment section). case, domain adaptationmultiple views data needs investigated carefully.Little research done multi-view domain adaptation literature. Zhang, He,Liu, Si, Lawrence (2011) proposed instance-based multi-view transfer learning approachintegrates loss cross-domain classification multi-view consistency large marginframework. However, instance-level approach assumes useful source training examples identified reused train target model. cannot mine relationships featurelevel correlation source-specific target-specific features, may performpoorly since target-specific features key good adaptation performance (Blitzer, Kakade,& Foster, 2011).work, present Information-theoretical Multi-view Adaptation Model (IMAM)combines paradigms multi-view learning domain adaptation based co-clusteringframework (Dhillon, Mallela, & Modha, 2003) aims transfer knowledge across domainsmultiple subspaces features complementarily. IMAM exploits multi-way-clustering-based classification scheme simultaneously cluster documents, words links respective clusters.word link clusterings automatically associate specific features different domains seemingly may directly correlated. correlations bridge domain gapenhance consistency distinct views clustering (i.e., classifying) target data.consistent views, better document clustering, better wordlink clustering, creates cycle positive feedback gradually improves adaptationperformance. essence, enhanced consistency views helps bridge domain gap (i.e.,finding cross-domain feature correlations), vice versa. also provide theoretical justifications proposed approach regarding objective, convergence property optimalsolution. experimental results demonstrate IMAM significantly outperforms state-ofthe-art baselines including traditional single-domain multi-view algorithm co-training (Blum &Mitchell, 1998), co-training-based domain adaptation algorithm CODA (Chen, Weinberger, &Blitzer, 2011), single-view transfer learning algorithm CoCC (Dai, Xue, Yang, & Yu, 2007a)instance-level multi-view transfer learning algorithm MVTL-LM (Zhang et al., 2011).502fiI NFORMATION -T HEORETIC ULTI - VIEW OMAIN DAPTATIONrest paper organized follows: Section 2 reviews related work; Section 3describes background concepts build model; Section 4 presents proposedIMAM model corresponding algorithm; Section 5 analyses realization consistencydistinct views model; Section 6 discusses experiments results; Finally,conclude Section 7 prospects future work.2. Literature ReviewDomain adaptation assumes multiple tasks benefit certain structures data shared different distributions. Existing methods divided instance-based approach (Jiang& Zhai, 2007; Dai, Yang, Xue, & Yu, 2007b), feature-based approach (Blitzer et al., 2007; Dai etal., 2007a) parameter-based approach (Dayanik, Lewis, Madigan, Menkov, & Genkin, 2006).Pan Yang (2010) presented comprehensive survey transfer learning described domain adaptation sub-category transfer learning. would give comprehensive reviewdomain adaptation reason. Interested readers may refer survey paper (Pan & Yang,2010) details.work closely related done Dai et al. (2007a), proposed coclustering-based classification (CoCC) algorithm learn out-of-domain data applylearned classifier in-domain task. CoCC extended information-theoretic co-clusteringmethod proposed Dhillon et al. (2003), in-domain constraints added word clustersprovide class structure partial categorization knowledge. However, CoCC single-viewalgorithm cannot leverage complementary nature multiple views. frameworkextension single-view CoCC, algorithm focused strengthening consistencypredictions distinct views across two domains, considered key successmulti-view domain adaptation.Multi-view learning studied extensively single-domain setting. Co-trainingfirst multi-view algorithm, trained learner view labeled exampleslet learner label unlabeled examples receive highest confidence (Blum & Mitchell,1998). proved two independent yet consistent views used learn concept PAC framework based labeled many unlabeled examples. Many extensionsproposed following idea co-training. Collins Singer (1999) introduced explicitobjective function measures compatibility learned hypotheses used boosting optimize function. Dasgupta, Littman, McAllester (2001) provided PAC-like guaranteesco-training providing upper bound error classifiers learned two views. Abney(2002) relaxed view independence assumption suggested may underlyingprinciple gives rise family new methods: disagreement rate two independenthypotheses upper bounds error rate either hypothesis. Sridharan Kakade (2008) proposedinformation-theoretic framework multi-view learning. showed derive incompatibility functions certain loss functions interest minimizing incompatibilityunlabeled data helps reduce expected loss test data. Nevertheless, multi-view learning generally effective domain adaptation since treat domain divergence indiscriminately,empirically justified experiments (see Experiments Results section).Multi-view adaptation well studied literature. Daume III, Kumar, Saha (2010)proposed co-regularization based approach (EA++) semi-supervised domain adaptation. EA++builds feature augmentation harnesses unlabeled data target domain assist trans503fiYANG & G AOfer information source target. Different EA++ aims make differenthypotheses learned different distributions agree unlabeled data, consider true multiview setting try make hypotheses learned different views consistent other.Furthermore, EA++ builds classifier transformed feature space via feature augmentation,proposed method learns hypotheses mapped feature space via multi-way clustering. Chen et al. (2011) proposed CODA adaptation based co-training (Blum & Mitchell,1998), however pseudo multi-view algorithm original data oneview. order apply CODA real multi-view data, views first concatenated split multiple pseudo-views. Therefore, suitable natural truemulti-view case ours. Lawrence (2011) proposed graph-based learning frameworktackle problems feature heterogeneity task heterogeneity. algorithmtransductive learning approach. Zhang Huan (2012) proposed inductive multi-view learningalgorithm multiple related tasks. used co-regularization obtain view-based classifiers agree unlabeled data ensure learned functions similarview across different tasks. two algorithms designed multi-tasklearning rather transfer learning. Zhang et al. (2011) proposed instance-level multi-viewtransfer algorithm integrates classification loss view consistency terms based large margin framework. instance-level approach assumes similar source training examplesidentified reused train target model. However, performance instance-basedapproach generally poor new target features lack support source data (Blitzer et al.,2011). focus feature-level multi-view adaptation, adaptation takes place multiple transformed feature spaces simultaneously complementarily. best knowledge,existing work focused feature-level multi-view domain adaptation exceptpreliminary study recently published (Yang, Gao, Tan, & Wong, 2012). paper extendswork Yang et al. (2012) substantially providing detailed algorithm, theoretical justificationcomprehensive empirical evaluation, specifically presented preliminaryversion.3. Background Conceptsmulti-view approach based co-clustering (Dhillon et al., 2003) co-clustering-basedclassification (CoCC) model (Dai et al., 2007a) building underlying clusters view.going details model, briefly describe background conceptslemmas related co-clustering techniques section.Mutual information fundamental measure quantify mutual dependence two random variables. Let I(X, ) mutual information variables X , definedP Pp(x,y)I(X, ) = x p(x, y)log p(x)p(y)(Cover & Thomas, 1991). Mutual information alsoexpressed form Kullback-Leibler (KL) divergence, i.e., I(X, ) = (p(x, y)||p(x)p(y)).Given two discrete random variables X joint probability distribution p(x, y), co-clusteringapproach (Dhillon et al., 2003) aims simultaneously cluster X disjoint clusters X,disjoint clusters . quality co-clustering measured resulting loss based mutualinformation:I(X, ) I(X, )given X , since I(X, ) fixed, minimizing equation equivalentmaximizing I(X, ).504fiI NFORMATION -T HEORETIC ULTI - VIEW OMAIN DAPTATIONp(x) p(y)simplicity expression, joint distribution q(x, y) = p(x, y) p(x)p(y) definedapproximate probability p(x, y) co-clustering (X, ). Note distribution q(x, y)preserves marginals p(x, y). is, x x, y, q(x) = p(x)q(x) =Xq(x, y) =XXp(x, y)yyp(x) p(y) Xp(x)=p(x, y)= p(x).p(x) p(y)p(x)Likewise q(y) = p(y).Dhillon et al. (2003) proved loss mutual information pre- post-clusteringreformulated KL-divergence p(x, y) approximation q(x, y),given following lemma:Lemma 3.1. fixed co-clustering (X, ), loss mutual information expressedI(X, ) I(X, ) = (p(x, y)||q(x, y)) ,D(||) KL-divergence, q(x, y) distribution formq(x, y) = p(x, y)p(x) p(y),p(x) p(y)x x y.completeness clarity, reproduce illustrative example given Dhillon et al.(2003) interpreting Lemma 3.1. Consider joint distribution (X, ) represented 6*6matrix below:.05 .05 .05 000.05 .05 .05 000000.05.05.05000 .05 .05 .05.04 .04 0 .04 .04 .04.04 .04 .040.04 .04follows naturally rows divided three clusters: x1 = {x1 , x2 }, x2 = {x3 , x4 }x3 = {x5 , x6 }, columns clustering is: y1 = {y1 , y2 , y3 }, y2 = {y4 , y5 , y6 }. resultingjoint distribution (X, ) given by:.3 00 .3.2 .2verified mutual information loss co-clustering .0957, minimum among possible co-clusterings.4. Information-Theoretic Multi-view Adaptation Model (IMAM)first introduce motivation, describe model algorithm.505fiYANG & G AO4.1 MotivationTraditional multi-view learning co-training framework (Blum & Mitchell, 1998) employstwo basic assumptions: (1) target functions view agree labels examples(consistency assumption); (2) views independent given class label (independenceassumption). first assumption reduces complex learning problem search compatiblefunctions; second assumption allows model achieve high-confidence predictions sincebecomes unlikely consistent classifiers trained independent views agree incorrectlabel.Considering training test data drawn different distributions, nonetheless, consistency assumption mostly violated distinct views agreeing labels sourcedata unnecessarily compatible labels target examples due domain gap. Therefore, expected traditional multi-view learning framework work effectivelyacross different domains, empirically justified comparison experiments. Hence,enhance consistency among multiple views bridge gap among different domainssimultaneously key issue multi-view domain adaptation approach succeed.Without loss generality, focus cross-domain document classification paperdocument representation consists two views word link. Given text documents two domains, would set common word features available domains,considered domain-independent features, remaining words would regarded eithersource-specific target-specific features. taxonomy regarding domain-independentdomain-specific features also apply inter-document links, e.g., hyperlinks citationsfeatures.single views perspective, source-specific target-specific features drawn together mining co-occurrence domain-independent features. IMAM exploits multiway clustering correlate seemingly unrelated domain-specific features via domainindependent features act bridge. correlations help bridge domain gap facilitate adaptation (Dai et al., 2007a). multiple views perspective, word link clustersconstructed two domains high quality, corresponding target document clusteringresulted either view subsequently improved due effect co-clustering (Dhillonet al., 2003). expected predictive power distinct views target data tendsbecome concordant approaches optimal solution. model leverages complementary cooperation different views yield better adaptation performance.Next, present representational preliminaries objective functionmulti-view adaptation model, iterative two-phase algorithm presented optimizeobjective.4.2 Graphical RepresentationLet DS training documents source domain DT unlabeled documentstarget domain. source target data assumed draw different feature spacesi.i.d. assumption longer holds. features defined source target domainothers defined domains. simply expand feature space includefeatures domains missing features either domain replenished 0. Let Wvocabulary entire document collection = DS DT . representedbag-of-words set {w|w w W }. Let L set links (hyperlinks citations)506fiI NFORMATION -T HEORETIC ULTI - VIEW OMAIN DAPTATIONcollection. also represented bag-of-links set {l|l dl L}. L naturallyform independent sets features respectively corresponding word view link view. Let Cdenote set class labels shared two domains. source document ds DSlabeled unique class label c C. objective assign appropriate class labeltarget document dt DT accurately possible. Note assume labeled dataavailable target domain, follows transductive learning scheme. Transductive approachtypical domain adaptation setting, general widely applicable differentscenarios including inductive setting small number labeled target data exist.Figure 1 shows graphical multi-view adaption model representation, D, W Lrespective clusterings documents, words links. Additionally, multi-way clusteringsmutually constrain subject various explicit implicit association relationships. Explicit association includes two types constraints: (1) Document clustering constrainedword clustering link clustering; (2) Word link clustering constrained document clustering class labels. Implicit association means class label knowledge transferredsource documents target documents word link clusters.Figure 1: graphical representation proposed multi-view adaptation model.model incorporates multi-way clustering scheme simultaneously clusters documents, words links. clustering functions defined CD (d) = documents,w l represent correspondingCW (w) = w words CL (l) = l links, d,clusters.4.3 Preliminaries Co-clustering-Based ClassificationDai et al. (2007a) proposed co-clustering-based classification framework, namely CoCC, learnclassifier source-domain documents use classify target-domain documents.approach, co-clustering leveraged bridge transfer knowledge sourcetarget.Co-clustering aims simultaneously cluster target documents DT clusters DT wordsW clusters W . Since problem classify target-domain documents, key make useknowledge classes data source domain co-clustering process. kindcorrelation source document class knowledge target document clusteringestablished considering respective relationship word clusters intermediary.good word clustering minimize loss mutual information class labelswords clustering source data, meanwhile minimize507fiYANG & G AOloss documents words target data. Therefore, loss function CoCC (Dai etal., 2007a) formulated follows:hI(DT , W ) I(DT , W ) + I(C, W ) I(C, W )trade-off parameter balances effect word clusters co-clusteringword clustering.4.4 Objective Functionextend information-theoretic framework co-clustering (Dhillon et al., 2003) coclustering-based classification (Dai et al., 2007a) incorporating loss terms multipleviews. Co-clustering aims minimize loss mutual information pre- postclustering respect pair clustering variables, documents words. objective Information-theoretic Multi-view Adaptation Model (IMAM) minimize losstrading different views:= W + (1 )L(1)hW = I(DT , W ) I(DT , W ) + I(C, W ) I(C, W )hL = I(DT , L) I(DT , L) + I(C, L) I(C, L) .(2)(3)W L loss terms based word view link view, respectively, trade-offcoefficient. Eq. 2, I(DT , W ) I(DT , W ) measures loss word-document co-clustering,I(C, W ) I(C, W ) measures loss vocabulary class labels, weightloss word clustering. Class labels act indirect constraints added vocabulary via sourcedocuments propagated target documents co-clustering. Eq. 3,similar loss term link view. = 1, function relies text information only,reduces CoCC (Dai et al., 2007a). unlike CoCC (Dai et al., 2007a), aim learncross-domain classifiers multi-view data.worth noting substituting Eq. 2 3 Eq. 1 ignoring constant terms,reformulate problem following maximization, kind easier interpret:hI(DT , W ) + (1 )I(DT , L) + I(C, W ) + (1 )I(C, L)first two terms enforce view consistency DT , means documentclusters DT preserve mutual information words links much possible,last two terms enforce transfer information source target via agreement labelsC, indicates source label knowledge maximally preserved wordlink clusters.Given multi-view data data different domains, central problem would different views could cooperate form consistent target class output scenariodifferent domain data follow different distributions. challenging view consistency based source data largely violated target domain due domain gap. tackleproblem, aim simultaneously enhance consistency among multiple views bridge508fiI NFORMATION -T HEORETIC ULTI - VIEW OMAIN DAPTATIONgap among different domains unified objective. IMAM exploits multi-way clustering enrich common words (and links) drawing together seemingly unrelated source-specifictarget-specific words (and links). correlations bridge domain gap facilitate adaptation process. hand, IMAM takes weighted combination view-based lossmutual information. pointed Section 5 (Consistency Multiple Views), optimal document clustering optimize weighted sum word-view link-view document clusteringfunctions, try minimize disagreement different views. Moreover, multi-wayclustering scheme imposes constraints document word/link clustering,make mutually benefit other. summary, IMAM uses boosting procedureenhance view consistency bridge domain gap simultaneously, expectedimprove adaptation performance multi-view data.4.5 IMAM AlgorithmBased q(x, y) defined Section 3, also define corresponding conditional distribution q(x|y) = q(x,y)p(y) co-clustering. x x, easily prove q(x|y) =p(x|x)p(x|y). Therefore, w w, l l, c C, calculate setq(d|w), q(l|d),q(d|l), q(c|w), q(c|l).conditional distributions including q(w|d),objective Eq. 1 hard optimize directly contains mutual informationtwo clusterings, combinatorial optimization problem. Therefore, transformform KL-divergence two conditional distributions Lemma 4.1 order facilitatesearch optimal value. Let D(p(x|y)||q(x|y)) denote KL-divergence p(x|y)q(x|y), definedD(p(x|y)||q(x|y)) =Xp(x|y)logxp(x|y).q(x|y)following lemma, using similar technique Dhillon et al. (2003), provideproof Appendix A.Lemma 4.1 (Objective functions). Equation 1 turned form alternate minimizationtwo objectives:(i) document clustering keeping word link clustering fixed, minimizeX+ C (W , L)=p(d)D (d, d)C (W , L) constant1= D(p(w|d)||q(w|d))+ (1 )D(p(l|d)||q(l|d)).(d, d)(ii) word link clustering keeping document clustering fixed, minimizeXX=p(w)W (w, w) + (1 )p(l)L (l, l)wlh1. prove C (W , L) = (I(C, W ) I(C, W )) + (1 )(I(C, L) I(C, L)) , MIclass label variables constant.509fiYANG & G AOAlgorithm 1 Algorithm IMAMInput:Document-term matrices DS W DT W ;Document-link matrices DS L DT L;Class label c C assigned doc DS ;# document clusters (i.e., # classes);Output:Class label assigned document DT ;(0)(0)1: Set = 0. Initialize document clustering CD using NBC. Initialize word clustering CW link clus(0)tering CL randomly;q (0) (l|d),q (0) (d|w), q (0) (d|l), q (0) (c|w), q (0) (c|l);2: Initialize distributions q (0) (w|d),3: repeat4:Document clustering: d, find new cluster index using Eq. 4;5:Keep q (t+1) (c|w) = q (t) (c|w) q (t+1) (c|l) = q (t) (c|l);q (t+1) (l|d),q (t+1) (d|w), q (t+1) (d|l);Update q (t+1) (w|d),6:Word clustering: word w, find new cluster index using Eq. 5;Link clustering: link l, find new cluster index using Eq. 6;q (t+2) (l|d),q (t+2) (d|w), q (t+2) (d|l), q (t+2) (c|w) q (t+2) (c|l);7:Update q (t+2) (w|d),8:= + 2;9: documents cluster index needs adjust10: unlabeled DT11:Assign class label based Eq. 7;12: endfeature v (e.g., w l) feature set V (e.g., W L)V (v, v) = D(p(d|v)||q(d|v)) + D(p(c|v)||q(c|v)).intuition optimization given document-word document-link matrices,let us simultaneously re-order documents two matrices documents mappingfirst document cluster arranged first, followed documents mapping second cluster,on. good document clustering tries ensure consistency different views.Next, let us simultaneously re-order words links document-word document-link matricessimilar way. good word (or link) clustering draws indirectly related domain-specific words(or links) together since may co-occur domain-independent words (or links)documents. document-word-link interaction helps finding optimal multi-way clustering.Lemma 4.1 allows us alternately reorder either documents words links,shown Algorithm 1, way mutual information loss decreases monotonically (seeLemma 4.2).4.5.1 LGORITHM(0)(0)(0)algorithm starts initial multi-clustering (CD , CW , CL ) iteratively refinesalgorithm converges. algorithm uses two-phase iterative procedure minimizeloss, first searches best document clustering keeping word linkclustering unchanged, clusters words links document clustering remains fixed.step 1, Naive Bayes classifier (NBC) trained source data DS used predictclass target data DT , produces initial document clustering entire D. Note510fiI NFORMATION -T HEORETIC ULTI - VIEW OMAIN DAPTATIONcluster index source documents fixed class labels. Thus, allocation targetdocument certain cluster also means document assigned corresponding classlabel. worth noting since objective Eq. 1 non-convex, somewhat sensitiveinitialization. Hence, instead random initialization, use NBC generate initial documentclusterings keep start good points.Step 4 updates cluster index d:h(t+1)+ (1 )D(p(l|d)||q (t) (l|d))CD (d) = arg min D(p(w|d)||q (t) (w|d))(4)Step 6 updates cluster index w:h(t+2)CW (w) = arg min D(p(d|w)||q (t+1) (d|w)) + D(p(c|w)||q (t+1) (c|w))(5)wupdates cluster index l:h(t+2)CL (l) = arg min D(p(d|l)||q (t+1) (d|l)) + D(p(c|l)||q (t+1) (c|l))(6)lNote Algorithm 1 separately update membership word link sinceimplicit association relationships word clustering link clustering via document clustering. document clustering acts bridge make word clustering linkclustering mutually affect other.finishing multi-way clustering procedure, assign target document DTclass label predictedh+ (1 )D(p(l|c)||q(l|d))c = arg min D(p(w|c)||q(w|d))(7)cCLemma 4.2 guarantees convergence algorithm, proof givenAppendix B borrowing similar technique Dhillon et al. (2003). Note findingglobal minimum multi-way clustering NP-hard, IMAM uses greedy approach findlocal minimum, guarantee global optimum. usually run experimentsmultiple times average performance different runs.Lemma 4.2 (Convergence). IMAM monotonically reduces objective given Equation 1.is,(t) (t+1)(t+1) (t+2)= 0, 2, 4, . . .5. Consistency Multiple Viewssection, present consistency document clustering target data could enhanced among multiple views, key issue multi-view adaptation method.511fiYANG & G AOparticularly discuss relationship disagreement rate views optimal document clustering function.(t+1)iteration Algorithm 1, optimal document clustering function CD(see Eq. 4)minimize weighted sum KL-divergences used optimal word-view link-view document clustering functions shown above. optimal word-view clustering functionsdenoted follows:(t+1)CDW (d) = arg min D(p(w|d)||q (t) (w|d))(8)similarly link-view function(t+1)CDL (d) = arg min D(p(l|d)||q (t) (l|d))(9)(t+1)(t+1)central idea document clusterings CDW CDL based two viewsdrawn closer iteration due word link clusterings (Eq. 5 6) bring together(t+1)seemingly unrelated source-specific target-specific features. Meanwhile, CDcombinestwo views reallocates documents maintains consistency view-basedclusterings much possible.5.1 Disagreement Rate ViewsD} set document clustering functionsSuppose = {Fi |Fi (d) = d,number clusters fixed. document, consistency indicator function respecttwo clustering functions defined follows (Round indicator omitted simplicity):Definition 1 (Indicator function) D, Fi , Fj1, Fi (d) = Fj (d);Fi ,Fj (d) =0, otherwisedefine disagreement rate two view-based clustering functions:Definition 2 (View disagreement rate) Fi FjPF ,F (d)(Fi , Fj ) = 1 dD j|D|(10)Obviously, (CDW , CDL ) denotes disagreement rate word-view link-viewclustering functions. Abney (2002) suggests disagreement rate two independent hypotheses upper-bounds error rate either hypothesis. minimizing disagreement rateunlabeled data, error rate view minimized (so overall error). However,disagreement rate function continuous convex, difficult optimize directly2 .Alternatively, minimize mutual information loss Eq. 1 surrogate disagreementrate function. believe mutual information loss good surrogate because, discussedSection 4.4, Eq. 1 aims enhance view consistency, equivalent minimizingdisagreement rate views. Moreover, show empirically optimizing Eq. 1 disagreement rate (CDW , CDL ) indeed monotonically decreased iterations experiments(see Section 6).2. Abney (2002) used greedy approach.512fiI NFORMATION -T HEORETIC ULTI - VIEW OMAIN DAPTATION5.2 View CombinationNote practice view-based document clusterings Eq. 8 Eq. 9 computedexplicitly. Instead, Eq. 4 directly optimizes view combination produces document clustering. Therefore, necessary disclose consistent combined view-based clusteringcould individual view-based clusterings.Fi , obtain disagreement rate (Fi , CDW CDL ), CDW CDL denotes clustering resulting overlap individual view-based clusterings. Noteco-training style algorithms usually assume multiple views redundant. Thus,intersection would empty. obtain Lemma 5.1 below, proof givenAppendix C.Lemma 5.1. optimal document clustering function CD IMAM model always minimizesdisagreement rate Fi(CD , CDW CDL ) = min (Fi , CDW CDL )Fimeanwhile, (CD , CDW CDL ) = (CDW , CDL ).Lemma 5.1 suggests IMAM always finds document clustering minimal disagreement rate overlap individual view-based clusterings, minimal valuedisagreement rate equals disagreement rate individual view-based clusterings.6. Experiments Resultssection, empirically evaluate IMAM algorithm cross-domain document classification tasks comparison state-of-the-art baselines.6.1 Data SetupCora (McCallum, Nigam, Rennie, & Seymore, 2000) online archive contains approximately 37,000 computer science research papers 1 million links among documents.documents categorized hierarchical structure. selected subset Cora, contains 5 top categories 10 sub-categories (the numbers parenthesis):- DA 1: /data structures algorithms theory/computational complexity/ (711)- DA 2: /data structures algorithms theory/computational geometry/ (459)- EC 1: /encryption compression/encryption/ (534)- EC 2: /encryption compression/compression/ (530)- NT 1: /networking/protocols/ (743)- NT 2: /networking/routing/ (477)- OS 1: /operating systems/realtime/ (595)- OS 2: /operating systems/memory management/ (1,102)- ML 1: /machine learning/probabilistic methods/ (687)- ML 2: /machine learning/genetic algorithms/ (670)Based dataset, used similar way Dai et al. (2007a) construct trainingtest sets. set, chose two top categories, one positive classnegative. Different sub-categories deemed different domains. task definedtop category classification. example, subset denoted DA-EC consists source domain:513fiYANG & G AODA 1(+), EC 1(-); target domain: DA 2(+), EC 2(-). method ensures domainslabeled unlabeled data related due top categories, domains differentdrawn different sub-categories. preprocessing common practice datapreparation adaptation purpose. previous work (Ling, Dai, Xue, Yang, & Yu, 2008; Daiet al., 2007a) found baseline SVM well transductive SVM classifiers trained sourcedomain data performed much worse target domain, implying large domain gap them.finding dataset using transductive SVM.preprocessed data text link information. texts, removed stopwords low-frequency words count less 5. links, removed links less5 citation counts. standard TF-IDF (Salton & Buckley, 1988) technique appliedtext link datasets. Moreover, generated merged dataset concatenatingword link features together.Reuters-21578 (Lewis, 2004) widely used evaluation automatic text categorizationalgorithms. Reuters-21578 corpus also hierarchical structure, contains 5 top categories.used pre-processed version corpus public accessible3 . statisticsdataset seen Table 1. Based data, generated separate information representingtwo views: first view corresponds features using TF-IDF scores terms; secondview corresponds topic-based features (i.e. document-topic distributions) obtained applying probabilistic Latent Semantic Analysis (pLSA)4 term counts information, topicnumber set 200.SubsetOrgs-PeopleOrgs-PlacesPeople-PlacesSourceOrgsPeople.src (1,237)OrgsPlaces.src (1,016)PeoplePlaces.src (1,077)TargetOrgsPeople.tar (1,208)OrgsPlaces.tar (1,043)PeoplePlaces.tar (1,077)Table 1: statistics Reuters-21578 dataset.Using Cora dataset, conducted experiments IMAM studying influence different parameters manifestation view disagreement rate. Also, compared IMAMvarious state-of-the-art domain adaptation algorithms Cora Reuters datasets. orderavoid infinity values, applied Laplacian smoothing computing KL-divergence.6.2 Parameter Sensitivityfirst studied influence important parameters, i.e., number word/link clusters,, .6.2.1 NFLUENCE C LUSTER N UMBERFigure 2 shows error rate curves varying different number word (and link) clusters4 subsets: DA-EC, DA-NT, DA-OS EC-NT. X-axis represents number word (andlink) clusters tuned 32 512. According performance shown figure,empirically set number word (and link) clusters 128.3. http://www.cse.ust.hk/TL/dataset/Reuters.zip.4. http://lear.inrialpes.fr/people/verbeek/code/plsa.tar.gz.514fiI NFORMATION -T HEORETIC ULTI - VIEW OMAIN DAPTATIONFigure 2: Error rate curves varying different number word/link clusters.6.2.2 NFLUENCEFigure 3 shows performance curves vary different values . error rate generallydecreases first increases augmented. always, algorithm performs worstmodel heavily relies either text information (0.9 1.0) link structure(0 0.1). setting 0.5 0.8 achieved best results subsets. implies two views document complementary. Therefore, remainingexperiments, set value 0.7.Figure 3: Error rate curves varying different settings .6.2.3 NFLUENCEused propagating class labels source document class target document clusteringword link clusters. Surprisingly, observe significant influencesubsets. used NBC initialize document clusterings good startingpoint, class information, though accurately, could largely propagated wordslink clusters next iteration. observation similar Dai et al. (2007a)number word clusters appropriately provided. empirically set 0.5trying 0, 0.25, 0.5, 1, 2 4.515fiYANG & G AOsourcetargetDA-EC0.1790.251DA-NT0.1570.224DA-OS0.1880.275DA-ML0.1840.211EC-NT0.2100.234Average0.1840.239Table 2: view disagreement rates different domains using co-training.IterationDA-ECDA-NTDA-OSDA-MLEC-NT10.1940.3400.1470.2950.1290.2520.1660.3060.3110.32120.1530.1320.0830.1000.0640.0920.1020.1070.2500.13730.1490.1110.0710.0760.0520.0680.0710.0760.2280.11240.1440.1010.0650.0690.0470.0600.0650.0620.2190.09650.1440.0950.0640.0640.0410.0520.0640.0540.2170.0890.9980.9960.9980.9840.988Table 3: View disagreement rate () error rate () decrease iterations. correlation denoted .6.3 View Disagreement Ratesection, studied view disagreement rate two different purposes: (1) experimentally verified view consistency assumption violated due distinct domainstraditional multi-view learning using co-training, justified motivation reduce viewdisagreement rate; (2) examined property view disagreement rate based methodrevealed relationship cross-domain classification performance.6.3.1 C -T RAININGexperiment, subset, source data splitted two portions, one portiontraining testing. traditional multi-view algorithm co-training (Blum &Mitchell, 1998) trained source training set, model evaluatedsource test set target test set separately. first result corresponds single-domainperformance second corresponds cross-domain performance.shown Table 2, clear view disagreement rate target domain considerably higher source domain. implies domain gap likely deteriorateview consistency. Abney (2002) pointed out, view consistency directly related classificationerror rate, upper bounded view disagreement rate. finding experimentseems consistent claim, furthermore, implies would helpful overcomedomain gap enhancing view consistency target data.6.3.2 IMAMexamined variance disagreement rate (CDW , CDL ) view-based clusteringscorrelation error rate .516fiI NFORMATION -T HEORETIC ULTI - VIEW OMAIN DAPTATIONused Pearsons correlation measure dependence disagreement rate errorrate, takes value -1 (perfect negative correlation) 1 (perfect positive correlation). Table 3 shows monotonic decrease disagreement rate error rateiterations, correlation nearly perfectly positive. indicates IMAM may gradually improves adaptation performance strengthening consistency different views,alternatively, IMAM increases classification performance, causes different viewsconsistent. procedures therefore reciprocal causation. achievedmutual reinforcement word link clustering draws together target-specificsource-specific features, originally unrelated could co-occur common features across two domains.6.4 Convergenceconvergence property IMAM shown Figure 4. IMAM uses two-phase iterative procedure find local optimal point. convergence guaranteed Lemma 4.2. seenumber documents needed reassigned different clusters decreases fastfirst 5 iterations reaches 0 10 iterations. Thus, terminate algorithmmaximum 15 iterations.Figure 4: Number documents needed reassigned different clusters varies iterations.6.5 Algorithms Comparisoncompared IMAM variety state-of-the-art algorithms including Transductive SVM5(TSVM) (Joachims, 1999) semi-supervised classifier, co-training (Co-Train) (Blum &Mitchell, 1998), co-clustering-based single-view transfer learning CoCC (Dai et al., 2007a),large-margin-based multi-view transfer learning MVTL-LM (Zhang et al., 2011) cotraining-based adaptation algorithm CODA6 (Chen et al., 2011). used Cora Reutersdatasets comparative study.datasets, ease presentation, used postfix -C, -L -CL denoteclassifier fed data different views. Cora dataset, -C, -L -CL represent text5. http://svmlight.joachims.org/.6. http://www1.cse.wustl.edu/mchen/code/coda.tar.517fiYANG & G AOSubsetDA-ECDA-NTDA-OSDA-MLEC-NTEC-OSEC-MLNT-OSNT-MLOS-MLAverageTSVM-C0.2930.1750.2760.2170.3050.3550.3330.3640.2050.2020.272TSVM-L0.1570.1370.2610.1140.2200.2010.2050.5010.1060.1700.207TSVM-CL0.2140.1140.2620.1070.1770.2450.1680.3960.1010.1790.196Co-Train0.2300.1630.1750.1710.2960.1750.2060.2200.1320.1280.190MVTL-LM0.1920.1080.0680.1830.2610.1760.2640.2880.0710.1260.174CODA0.2340.0760.1090.1500.1780.1870.3220.2400.0250.0870.161CoCC-C0.1490.1060.0750.1090.2250.1370.2030.1070.0540.0510.122CoCC-L0.2270.1320.0860.0980.2960.1160.2690.1420.0940.0510.151CoCC-CL0.1870.1150.0670.0950.2390.1250.2370.1150.0470.0620.129IMAM0.1380.0690.0390.0470.1910.0740.1730.0700.0310.0210.085Table 4: Error rate classification adaptation Cora dataset.SubsetOrgsPeopleOrgsPlacesPeoplePlacesAverageTSVM-C0.2460.2780.2940.273TSVM-L0.2630.3040.3350.301TSVM-CL0.2270.2630.2860.259Co-Train0.2510.2700.3180.280MVTL-LM0.2300.2490.2600.246CODA0.1770.2260.2750.226CoCC-C0.1850.2140.2450.215CoCC-L0.2190.2350.2620.239CoCC-CL0.1910.2210.2480.220IMAM0.1530.1920.2180.188Table 5: Error rate classification adaptation Reuters-21578 dataset.view, link view two views, respectively; Reuters dataset, correspond term view, topicview two views. examined classifier inherently multi-view, viewss datafed it. algorithm include TSVM-CL, co-training, MVTL-LM, CoCC-CL, IMAM.Since CODA pseudo multi-view adaptation algorithm, fit scenario, CODA fedmerged view could automatically split sub-views. algorithm,parameters tuned using five-fold cross-validation training data. cancel localoptimal results, repeated algorithms five times subset reported average errorrate.algorithms trained source data tested target data.classification error rate target data used evaluation metric, defined rationumber misclassified documents total documents.6.6 Performance ComparisonTable 4 shows results comparison Cora dataset, Table 5 shows Reuters21578. consistent findings two datasets.datasets, TSVM performed poorly adaptation using either content link features alone. Simply merging two sets features makes improvements, implying textlink Cora data (or, term topic Reuters data) complementary, may degradeconfidence classifier instances whose features become conflictingmerging. Co-training avoid problem boosting confidence classifiers builtdistinct views complementary way, performance comparable TSVM thoughuses weaker base classifier. Since TSVM co-training consider distributiongap, performed clearly worse CoCC even though CoCC single-view approach.datasets, CODA outperformed co-training MVTL-LM splitting feature spacemultiple pseudo views iteratively adding shared source target features basedcompatibility across domains. However, could comparably effective IMAM.seems pseudo views automatically generated CODA complementaryoriginal view partition two datasets. performed even worse COCC singleview setting, indicating sometimes pseudo views might detrimental. relatively lowerperformance CODA may explained follows. might happen original formationtwo views data reasonably good, combined one view,likely CODA could stuck poor locally optimal decomposition features due518fiI NFORMATION -T HEORETIC ULTI - VIEW OMAIN DAPTATIONnon-smooth, non-convex nature objective function. Since model parametersinitialized randomly, repeating algorithm guarantee better solution. contrast,objective function IMAM, although non-convex, smooth, also, instead using randominitialization used NBC initialize document clusters ensure good starting point.IMAM significantly outperformed CoCC-C CoCC-L subsets. average,error rate IMAM 30.3% lower CoCC-C (or 43.7% lower CoCCL). IMAM effectively leverages distinct complementary views. ComparedCoCC, using source training data improve view consistency target data key competency IMAM. Moreover, IMAM performed much better CoCC-CL. Unlike CoCC-CLsimply concatenates two-view data, technique strengthen view consistencybootstrapping two CoCC models iteratively complementarily. model two CoCCmodels communicate complementarily iteration, consequently boosts consistencytwo views.result shows multi-view adaptation using MVTL-LM performs worse IMAMsubsets. general explanation suggests instance-based approach relying instanceweighting effective data different domains drawn different featurespaces. Although MVTL-LM regulates view consistency domains instances, cannotidentify useful correlation target-specific source-specific features,key success adaptation especially domain gap large little commonalitycould found. contrast, CoCC IMAM use co-clustering multi-way clustering findcorrelation.Note use different ways generate multi-view data two datasets. DifferentCora dataset natural multiple views, i.e., text link, generate termtopic views Reuters-21578 dataset based text information only. Nevertheless, resultsdatasets show IMAM works well different types multi-view data usingmulti-way clustering enhance view consistency.7. Conclusion Future Workpresented novel feature-level multi-view adaptation approach called IMAM cross-domaindocument classification. thrust technique incorporate distinct views documentfeatures multi-way clustering framework gradually strengthen view consistencyclassifying target documents. improvements state-of-the-art baselines substantial.provided theoretical empirical justifications regarding properties proposedalgorithm. Experiments show considerably outperforms state-of-the-art baselines including multi-view single-domain algorithm co-training, co-training-based adaptation CODA,single-view adaptation CoCC well instance-level multi-view adaptation MVLT-LM.Multi-view domain adaptation promising direction since underlying principle practice still open questions. part ongoing work, explore foundationslimitations multi-view domain adaptation. example, multiple views might hurt adaptation performance domains views dissimilar. Although observedexperiments, needs analyzed deeply. addition, due practical reasons,directly optimize consistency measure, i.e., view disagreement rate. Instead, adoptedinformation-theoretical framework optimize mutual information loss, worked wellmay ideal solution. future, study techniques directly optimizeconsistency measure views.519fiYANG & G AOAppendix A. Proof Lemma 4.1Proof. proof Lemma 4.1 divided two parts.(i) document clustering:Note word link clusterings keep fixed phase. Thus mutual informationclass label word (or link) clusters remains unchanged document clusteringphase, is,hC (W , L) = (I(C, W ) I(C, W )) + (1 )(I(C, L) I(C, L))constant. using Eq. 1, obtainC (W , L)= W + (1 )L C (W , L)hh= I(DT ; W ) I(DT ; W ) + (1 ) I(DT ; L) I(DT ; L)XXX XXX X Xw)p(d,w)p(d,p(d, w) log=p(d, w) logw)p(d)p(w)p(d)p(w dd wwwdd wwXXXXXXXXp(d, l)p(d, l)p(d, l) log+ (1 )p(d, l) logl)p(d)p(l)p(d)p(l=XXX X=XXX X=XXX X=XXp(d, w) logw dd www dd wwp(d)XXddlXXXXw)l)p(d, w)p(d)p(p(d, l)p(d)p(+ (1 )p(d, l) logw)p(d)p(w)l)p(d)p(l)p(d,p(d,lddXXXXp(d, w)p(d, l)p(d, w) log+ (1 )p(d, l) logq(d, w)q(d, l)p(d)p(w|d) logw dd wwdd=ddXXp(w|d) logw wwp(w|d)+ (1 )q(w|d)lddXXXXp(w|d)+ (1 )q(w|d)p(d)p(l|d) logddlXXp(d)ddXXlh+ (1 )D(p(l|d)||q(l|d))p(d) D(p(w|d)||q(w|d))p(l|d)q(l|d)p(l|d) logp(l|d)q(l|d)dd=Xp(d)D (d, d)(ii) word link clustering:Note document clusterings remains unchanged phase. Using similar techniqueabove, obtain=Xp(w)W (w, w) + (1 )wXlcombining steps (i) (ii), Lemma 4.1 proved.520p(l)L (l, l)fiI NFORMATION -T HEORETIC ULTI - VIEW OMAIN DAPTATIONAppendix B. Proof Lemma 4.2Proof. proof Lemma 4.2 divided two parts.(i) document clustering: Note word link clusterings keep fixed phase.(t)(a)(t)XC (W , L) =h(t)+ (1 )D(p(l|d)||q (t) (l|d))p(d) D(p(w|d)||q (w|d))Xd:C (t) (d)=d=XXp(d)Xp(w|d) logwd:C (t) (d)=dXp(l|d)p(w|d)+ (1 )p(l|d) logq (t) (w|d)q (t) (l|d)l(b)XXp(d)Xp(w|d)p(w|d) logwd:C (t) (d)=d(c)X=Xp(d)Xp(w|d) logwd:C (t+1) (d)=d+ (1 )(t+1)q (t) (w|CD(d))Xp(l|d)p(l|d) log(t+1)q (t) (l|CD(d))lXp(w|d)p(l|d)+ (1 )p(l|d) logq (t) (w|d)q (t) (l|d)l(d)X=Xd:C (t+1) (d)=dXp(d)wXp(w|d)p(w|d) logq (t) (w|w)q (t) (w|d)(t+1)w:C(w)=wW+ (1 )XXp(l|d) logl l:C (t+1) (l)=lL=Xd:C (t+1) (d)=dq (t) (l|l)q (t) (l|d)Xp(l|d)Xp(d)wXp(w|d)p(w|d) logq (t) (w|w)(t+1)w:C(w)=wW+ (1 )XXl l:C (t+1) (l)=lLp(l|d)p(l|d) logq (t) (l|l){z|}+XXd:C (t+1) (d)=dXp(d)wXp(w|d) log(t+1)w:C(w)=wW"=I+XXwXd:CX(t+1)(t+1)(d)=d w:C(w)=wWXd:CX(t+1)(t+1)(d)=d l:C(l)=lLXX (t+1)w) logq(d,w(e)I+1q (t) (w|d)X (t+1)X (t+1)logq(d)q(w|d)wXXp(d)d:C (t+1) (d)=d+ (1 )1p(d)p(l|d) logq (t) (l|d)+ (1 )=X1q (t+1) (w|d)Xw(t+1)w:C(w)=wWXp(l|d) logXp(d)d:C (t+1) (d)=d(1 )Xq (t) (l|d)X+ (1 )p(w|d) logq (t) (l|d)X (t+1)logq(l|d)l1q (t+1) (l|d)p(w|d)q (t) (w|w)q (t+1) (w|d)#p(l|d)Xw(t+1)w:C(w)=wWl l:C (t+1) (l)=lL1q (t) (l|l)q (t+1) (l|d)Xp(l|d) log#X (t+1)l) logq(d,"Xl l:C (t+1) (l)=lLlXl l:C (t+1) (l)=lL(f )p(l|d) logp(w|d)+q (t+1) (w|w)q (t+1) (w|d)p(w|d) log#p(l|d)q (t+1) (l|l)q (t+1) (l|d)=X=XXd:C (t+1) (d)=dXp(d)wXw:C(t+1)(w)=wWp(w|d) logp(w|d)q (t+1) (w|d)(t+1)=+ (1 )X(t+1)C(W , L)521Xl l:C (t+1) (l)=lLh(t+1)+ (1 )D(p(l|d)||q (t+1) (l|d))p(d) D(p(w|d)||q(w|d))Xd:C (t+1) (d)=d(g)11p(d)p(w|d) logq (t) (w|d)"=+ (1 )XX+ (1 )=I+q (t) (w|d)Xl1p(l|d) logp(l|d)q (t+1) (l|d)fiYANG & G AO(a) follows Lemma 4.1, (b) follows Step 4 IMAM algorithm, (c) follows rearranging summation, (d) (f) follow since hold word link clustersfixed Step 4, (e) follows non-negativity KL-divergence, (g) follows Lemma 4.1. Since word link clusters remain unchanged document clustering, i.e.,(t)(t+1)C (W , L) = C (W , L), prove (t) (t+1) .(ii) word link clustering: Note document clusterings remains unchangedphase. using properties Step 6 similar technique above, prove(t+1) =XX(t+1)p(w)W(w, w) + (1 )XXl(t+1)l:CL(l)=lw w:C (t+1) (w)=wWX=(t+2)X(t+2)p(w)W (w, w)+ (1 )Xw w:C (t+2) (w)=wWlX(t+2)l:CL(t+1)p(l)L(t+2)p(l)L(l,l)(l,l)(l)=lcombining steps (i) (ii), follows every iteration algorithm IMAM monotonically decreases objective function.Appendix C. Proof Lemma 5.1Proof. document document cluster D,(i) CDW (d) = CDL (d)brevity, denote cluster , i.e., CDW (d) = CDL (d) = . using Eq. 4, Eq. 8Eq. 9, obtainD(p(w|d)||q(w|d )) D(p(w|d)||q(w|d))D(p(l|d)||q(l|d ))D(p(l|d)||q(l|d))+ (1 )D(p(l|d)||q(l|d))D(p(w|d)||q(w|d )) + (1 )D(p(l|d)||q(l|d )) D(p(w|d)||q(w|d))CD (d) = CDW (d) = CDL (d) =CD ,CDW CDL (d) = 1(ii) CDW (d) 6= CDL (d)Obviously, CD ,CDW CDL (d) = 0. combining (i) (ii), obtain1, CDW (d) = CDL (d);CD ,CDW CDL (d) = CDW ,CDL (d) =0, otherwiseFi , indicator function Fi ,CDW CDL (d) rewritten1, CDW (d) = CDL (d) = Fi (d);0, CDW (d) = CDL (d) 6= Fi (d);Fi ,CDW CDL (d) =0, otherwiseThus, CD ,CDW CDL (d) Fi ,CDW CDL (d). inequation holds true Fi .Therefore, based definition disagreement rate obtainP(Fi , CDW CDL ) = 1dDFi ,CDW CDL (d)|D|P1dDCD ,CDW CDL (d)|D|Meanwhile, obtain (CD , CDW CDL ) = (CDW , CDL ).522= (CD , CDW CDL )fiI NFORMATION -T HEORETIC ULTI - VIEW OMAIN DAPTATIONReferencesAbney, S. (2002). Bootstrapping. Proceedings 40th Annual Meeting AssociationComputational Linguistics, July 6-12, 2002, Philadelphia, PA, USA, pp. 360367.Blitzer, J., Dredze, M., & Pereira, F. (2007). Biographies, bollywood, boom-boxes blenders:Domain adaptation sentiment classification. Proceedings 45th Annual MeetingAssociation Computational Linguistics, June 23-30, 2007, Prague, Czech Republic,pp. 440447.Blitzer, J., Kakade, S., & Foster, D. P. (2011). Domain adaptation coupled subspaces. Proceedings 14th International Conference Artificial Intelligence Statistics, April11-13, 2011, Ft. Lauderdale, FL, USA, pp. 173181.Blum, A., & Mitchell, T. (1998). Combining labeled unlabeled data co-training. Proceedings 11th Annual Conference Computational Learning Theory, Madison, Wisconsin, USA, July 24-26, 1998, pp. 92100.Cai, P., Gao, W., Zhou, A. Y., & Wong, K. F. (2011a). Relevant knowledge helps choosing rightteacher: Active query selection ranking adaptation. Proceedings 34th International ACM SIGIR Conference Research Development Information Retrieval, July24-28, 2011, Beijing, China, pp. 115124.Cai, P., Gao, W., Zhou, A. Y., & Wong, K. F. (2011b). Query weighting ranking model adaptation. Proceedings 49th Annual Meeting Association Computational Linguistics: Human Language Technologies, June 19-24, Portland, Oregon, USA, pp. 112122.Chen, M.M., Weinberger, K. Q., & Blitzer, J. (2011). Co-training domain adaptation. Proceedings Advances Neural Information Processing Systems 24, December 12-14, 2011,Granada, Spain, pp. 19.Collins, M., & Singer, Y. (1999). Unsupervised models named entity classification. Proceedings 1999 Joint SIGDAT Conference Empirical Methods Natural Language Processing Large Corpora, pp. 100110.Cover, T. M., & Thomas, J. A. (1991). Elements information theory. Wiley-Interscience.Dai, W. Y., Xue, G. R., Yang, Q., & Yu, Y. (2007a). Co-clustering based classification outof-domain documents. Proceedings 13th ACM SIGKDD International ConferenceKnowledge Discovery Data Mining, San Jose, California, USA, August 12-15, 2007,pp. 210219.Dai, W. Y., Yang, Q., Xue, G. R., & Yu, Y. (2007b). Boosting transfer learning. Proceedings24th International Conference Machine Learning, Corvallis, Oregon, USA, June20-24, 2007, pp. 193200.Dasgupta, S., Littman, M. L., & McAllester, D. (2001). PAC generalization bounds co-training.Proceedings Advances Neural Information Processing Systems 14, December 9-14,2002, Vancouver, British Columbia, Canada, pp. 375382.Daume III, H., & Marcu, D. (2006). Domain adaptation statistical classifiers. Journal ArtificialIntelligence Research, 26(2006):101126.523fiYANG & G AODaume III, H., Kumar, A., & Saha, A. (2010). Co-regularization based semi-supervised domainadaptation. Proceedings Advances Neural Information Processing Systems 23, December 6-9, 2010, Vancouver, Canada, pp. 478496.Dayanik, A. A., Lewis, D. D., Madigan, D., Menkov, V., & Genkin, A. (2006). Constructing informative prior distributions domain knowledge text classification. Proceedings29th Annual International ACM SIGIR Conference Research DevelopmentInformation Retrieval, Seattle, Washington, USA, August 6-11, 2006, pp. 493500.Dhillon, I. S., Mallela, S., & Modha, D. S. (2003). Information-theoretic co-clustering. Proceedings Ninth ACM SIGKDD International Conference Knowledge Discovery DataMining, Washington, DC, USA, August 24 - 27, 2003, pp. 210219.Gao, W., Blitzer, J., Zhou, M., & Wong, K. F. (2009). Exploiting bilingual information improveweb search. Proceedings 47th Annual Meeting Association ComputationalLinguistics 4th International Joint Conference Natural Language ProcessingAFNLP, August 2-7, 2009, Singapore, pp. 10751083.Gao, W., Cai, P., Wong, K. F., & Zhou, A. Y. (2010). Learning rank using training datarelated domain. Proceedings 33rd Annual International ACM SIGIR ConferenceResearch Development Information Retrieval, July 19-23, 2010, Geneva, Switzerland,pp. 162169.Gao, W., & Yang, P. (2014). Democracy good ranking: Towards multi-view rank learningadaptation web search. Proceedings 7th International ACM Conference WebSearch Data Mining, Feburary 25-27, 2014, New York City, USA, pp. 6372.He, J. R., & Lawrence, R. (2011) graph-based framework multi-task multi-view learning.Proceedings 28th International Conference Machine Learning, Washington, Jun28-Jul 2, 2011, pp. 2532.Lewis, D. D. (2004). Reuters-21578 test collection. http://www.daviddlewis.com/.Joachims, T. (1999). Transductive inference text classification using support vector machines.Proceedings 16th International Conference Machine Learning, Bled, Slovenia,June 27-30, 1999, pp. 200209.Jiang, J., & Zhai, C. X. (2007). Instance weighting domain Adaptation NLP. Proceedings45th Annual Meeting Association Computational Linguistics, June 23-30, 2007,Prague, Czech Republic, pp. 264271.Ling, X., Dai, W. Y., Xue, G. R., Yang, Q., & Yu, Y. (2008). Spectral domain-transfer learning.Proceedings 14th ACM SIGKDD International Conference Knowledge DiscoveryData Mining, Las Vegas, Nevada, USA, August 24-27, 2008, pp. 488496.McCallum, A. K., Nigam, K., Rennie, J., & Seymore, K. (2000). Automating constructionInternet portals machine learning. Information Retrieval, 3(2):127163.Pan, S. J., & Yang, Q. (2010). survey transfer learning. IEEE Transactions KnowledgeData Engineering, 22(10):13451359.Ruping, S., & Scheffer, T. (2005). Learning multiple views. Proceedings 2005 ICMLWorkshop Learning Multiple Views.524fiI NFORMATION -T HEORETIC ULTI - VIEW OMAIN DAPTATIONSalton, G., & Buckley, C. (1988). Term-weighting approaches automatic text retrieval. Information Processing & Management, 24(5):513523.Sarinnapakorn, K., & Kubat, M. (2007). Combining sub-classifiers text categorization: DSTbased solution case study. IEEE Transactions Knowledge Data Engineering,19(12):16381651.Sridharan, K., & Kakade, S. M. (2008). information theoretic framework multi-view learning. Proceedings 21st Annual Conference Learning Theory, Helsinki, Finland,July 9-12, 2008, pp. 403414.Yang, P., Gao, W., Tan, Q., & Wong, K. F. (2012). Information-theoretic multi-view domain adaptation. Proceedings 50th Annual Meeting Association Computational Linguistics, July 8-11, 2012, Jeju Island, Korea, pp. 270274.Zhang, D., He, J. R., Liu, Y., Si, L., & Lawrence, R. D. (2011). Multi-view transfer learninglarge margin approach. Proceedings 17th ACM SIGKDD International Conference Knowledge Discovery Data Mining, San Diego, CA, USA, August 21-24, 2011,pp. 12081216.Zhang, J. T., & Huan, J. (2012). Inductive multi-task learning multiple view data. Proceedings 18th ACM SIGKDD International Conference Knowledge Discovery DataMining, Beijing, China, August 12-16, 2012, pp. 543551.525fiJournal Artificial Intelligence Research 49 (2014) 601-633Submitted 10/13; published 04/14Algorithms ApplicationsSame-Decision ProbabilitySuming ChenArthur ChoiAdnan Darwichesuming@cs.ucla.eduaychoi@cs.ucla.edudarwiche@cs.ucla.eduComputer Science DepartmentUniversity California, Los AngelesLos Angeles, CA 90095Abstractmaking decisions uncertainty, optimal choices often difficultdiscern, especially enough information gathered. Two key questionsregard relate whether one stop information gathering process commitdecision (stopping criterion), not, information gather next (selectioncriterion). paper, show recently introduced notion, Same-DecisionProbability (SDP), useful stopping selection criterion, provide additional insight allow robust decision making variety scenarios.query shown highly intractable, PPPP -complete, exemplaryclass queries correspond computation certain expectations. propose first exact algorithm computing SDP, demonstrate effectivenessseveral real synthetic networks. Finally, present new complexity results,complexity computing SDP models Naive Bayes structure. Additionally,prove computing non-myopic value information completecomplexity class computing SDP.1. IntroductionProbabilistic graphical models often used model variety decision problems,e.g., medical diagnosis (Pauker & Kassirer, 1980; Kahn, Roberts, Shaffer, & Haddawy,1997; van der Gaag & Coupe, 1999), fault diagnosis (Lu & Przytula, 2006), classification(Friedman, Geiger, & Goldszmidt, 1997; Ramoni & Sebastiani, 2001; Jordan, 2002), troubleshooting (Heckerman, Breese, & Rommelse, 1995), educational diagnosis (Butz, Hua, &Maguire, 2004; Arroyo & Woolf, 2005; Millan, Descalco, Castillo, Oliveira, & Diogo, 2013),intrusion detection (Kruegel, Mutz, Robertson, & Valeur, 2003; Modelo-Howard,Bagchi, & Lebanon, 2008). similar applications, decision maker typicallyposition must decide tests perform observations makeorder make better informed decision. Perhaps critically, decision maker mustalso decide stop making observations commit particular decision.Same-Decision Probability (SDP) recently proposed Darwiche Choi(2010), order help quantify robustness decision, context decisionmaking Bayesian networks. short, SDP probability would makedecision, perform observations yet made.such, SDP treated measure decisions robustness respectc2014AI Access Foundation. rights reserved.fiChen, Choi & Darwicheunknown variables, quantifying confidence would make decision, evenmade observations.paper, show apply SDP tool information gathering,particular, way determine stop information gathering (as stopping criterion), not, pieces information gather next (as selection criterion).compare SDP classical stopping selection criteria illustrative examples.instance, demonstrate SDP distinguish stable unstabledecisions indistinguishable classical criteria. Additionally, also showscenarios classical criteria may call performing observations,SDP indicates decision unlikely change.Notably, SDP shown highly intractable, Choi, Xue, Darwiche(2012), exact computation SDP limited toy examples,variables, brute-force enumeration. paper, propose first exactalgorithm computing SDP. algorithm applied real-world networksscope brute-force enumeration previously proposed approximationalgorithms, applied synthetic networks many 100 variables.provide new complexity results SDP, highlight relativeintractability (even Naive Bayes networks), also relationship broader classexpectation computation problems, emphasizing broader importance developingeffective algorithms SDP related problems.paper thus structured follows. first introduce notation discusscommon stopping selection criteria Section 2. review previously introduced work SDP Section 3. Section 4, discuss SDP appliedstopping criterion selection criterion. Section 5, present novelexact algorithm computing SDP discuss experimental results Section 6.Section 7, present recent complexity results SDP. concludepaper Section 8.2. Related Workmaking decisions uncertainty, may difficult finalize decisionpresence unobserved variables. Given unobserved variables, two fundamental questions. first question whether, given current observations, decisionmaker ready commit decision. refer stopping criterionmaking decision. Assuming stopping criterion met, second questionadditional observations made decision maker ready make decision. typically requires selection criterion based measure quantifyingobservations value information (VOI). section, first introduce necessarynotation, review commonly used stopping selection criteria.2.1 NotationThroughout paper, use standard notation variables instantiations,variables denoted upper case letters X instantiations lower caseletters x. Additionally, sets variables denoted bold upper case letters Xinstantiations bold lower case letters x. assume state world602fiAlgorithms Applications Same-Decision Probabilitydescribed random variables X, evidence E X includes known variables,hidden variables U X include unknown variables. definition, E U =EU = X. often discuss ramifications observing subset hidden variablesH U decision making. Furthermore, use U denote main hypothesisvariable forms basis decision.12.2 Stopping CriterionGiven hidden variables model choice whetherobserve subset, stopping criterion determines stop processinformation gathering commit decision. Note concerned makingdecision based hypothesis variable, state patients health.stopping criterion, basic approach used variety domains commitdecision belief certain event crosses threshold, donePauker Kassirer (1980), Kruegel et al. (2003), Lu Przytula (2006). However,approach may robust, observations may cause beliefevent fall threshold. Van der Gaag Bodlaender (2011) note possibilitypose STOP problem, asks whether present evidence gatheredsufficient diagnosis, exists relevant evidencegathered.approaches involve ensuring uncertainty surrounding decision variablesufficiently reduced. instance, Gao Koller (2011) stop information gathering1) conditional entropy interest variable reduced beyond threshold 2)margin first second likely states interest variablethreshold. case, clear threshold-based stopping criteria ubiquitousdecision making uncertainty.Alternatively, also several stopping criteria involve existencebudget, abstract quantity represent available resourcesused information gathering. budget may representative numberobservations allowed (Modelo-Howard et al., 2008; Munie & Shoham, 2008; Yu,Krishnapuram, Rosales, & Rao, 2009; Chen, Low, Tan, Oran, Jaillet, Dolan, & Sukhatme,2012a), terms monetary amount may spent observations varyingcost (Greiner, Grove, & Roth, 2002; Krause & Guestrin, 2009; Bilgic & Getoor, 2011).context budget, general stopping criterion continue make observationsbudget completely expended, done Modelo-Howard et al. (2008)Munie Shoham (2008). Krause Guestrin (2009) Bilgic Getoor (2011) notebudget expended caveat value informationobservation least cost observation.2.3 Selection Criterion: Value Informationstopping criterion determine observations necessary, selectioncriterion used determine variables selected observation.Ideally, want observe variables give us additional information regards1. work presented paper extended case multiple hypothesis variables,focus case one hypothesis variable simplicity.603fiChen, Choi & Darwichedecision variable. However, due resource constraints (such limited budget)often possible. basic approach, common selection criterion selectobservations minimize conditional entropy decision variable (Vomlel,2004; Lu & Przytula, 2006; Krause & Guestrin, 2009; Yu et al., 2009; Zhang & Ji, 2010;Gao & Koller, 2011; Ognibene & Demiris, 2013; Shann & Seuken, 2013). entropyvariable X defined as:H(X) =XPr (x) log Pr (x)(1)xmeasure uncertainty variables state entropy variablehigh, means much uncertainty value variable takes.2uncertainty decision variables true state makes difficult make decision. Thus,natural selection criterion observe variables minimize conditional entropydecision variable, conditional entropy variable given variable X definedas:H(D | X) =XH(D | x)Pr (x)(2)xconditional entropy thus expectation entropy wouldobserving X. similar selection criterion observe variables greatlyincrease margin posterior probabilities first second most-likelystates decision variable (Krause & Guestrin, 2009).selection criteria involve utilizing notion value information (VOI) orderquantify value various observations (Lindley, 1956; Stratonovich, 1965; Howard,1966; Raiffa, 1968). VOI set variables depend various measures.two example selection criteria discussed, measures would entropymargins confidence. instance, observing variable X would reduce conditionalentropy H(D | X) observing variable X would (H(D | X) < H(D | X )),value observing X would higher.Krause Guestrin (2009) define general notion VOI based differentreward functions. particular, given arbitrary reward function R,3 hypothesis variableD, evidence e, VOI observing hidden variables H is:V(R, D, H, e) = ER(R, D, H, e) R(Pr (D | e))(3)ER(R, D, H, e) =XR(Pr (D | h, e))Pr (h | e)(4)hexpected reward observing variables H R(Pr (D | e)) rewardobserved variables H. definition, reward function used Lu2. information theory, logarithm typically assumed base-2 (Cover & Thomas, 1991),also assume throughout paper convenience.3. reward function assumed take input probability distribution hypothesis variable,Pr (D), return numeric value. discuss reward functions Section 7.2.604fiAlgorithms Applications Same-Decision Probability+Pr (D | E1 = +, E2 = +)0.8809520.119048X1X2E1E2H1H2Figure 1: simple Bayesian network, sensor readings {E1 = +, E2 = +}. Variables H1H2 represent health sensors E1 E2 . left posteriordecision variable D. Network CPTs found Appendix C Figure 13.Przytula (2006) Krause Guestrin (2009) select variables order minimizeconditional entropy R(Pr (D | e)) = H(D | e), maximizing expectedreward observing variables H equivalent minimizing conditional entropyH(D | H). possible reward functions involve utility-based reward functionsthreshold-based reward functions (Munie & Shoham, 2008).4Note vast majority selection criteria use myopic approach,possible observations, one observation considered time, observationhighest VOI selected time. approach greedy short-sightedoptimal VOI computed computing non-myopically (Bilgic & Getoor,2011). discuss usage non-myopic VOI Appendix A.1.3. Same-Decision ProbabilitySame-Decision Probability (SDP) initially introduced Darwiche Choi (2010)confidence measure threshold-based decisions Bayesian networks noisysensor readings. Prior formally defining SDP, first show example provideintuition. Consider Bayesian network Figure 1, models scenario involvinghypothesis variable D, two noisy sensors E1 E2 influence beliefhypothesis d. Networks typically used compute belief hypothesisgiven sensor readings, Pr (d | e). basis whether make decision oftendepends whether posterior probability hypothesis surpassesthreshold (Hamscher, Console, & de Kleer, 1992; Heckerman et al., 1995; Kruegelet al., 2003; Lu & Przytula, 2006).Figure 1 shows particular reading two sensors resulting belief Pr (D = + |E1 = +, E2 = +). Suppose threshold = 0.6, Pr (d | e) , would makecertain decision. Notice Figure 1 health sensors modeled variablesH1 H2 . sensor either truthful, stuck positive (readings always display +),lying (readings show opposite value actual value) (Darwiche & Choi, 2010).variables observed, could informed us trustworthiness4. reward functions, see list provided Krause Guestrin (2009).605fiChen, Choi & DarwicheH1plplplH2ppplllPr (h | e)0.7810710.0964290.0010710.0964290.0214290.0011900.0010710.0011900.000119Pr (d | h, e)0.900.820.100.900.500.100.900.180.10Table 1: Scenarios h sensor readings e = {E1 = +, E2 = +} network Figure 1,H = {H1 , H2 }. Cases threshold = 0.6 bold. Note t, p, lrespectively represent truthful, stuck positive, lying sensor.sensors E1 E2 thus allow us make better decision. want makemore-informed decision based probability Pr (d | h, e) instead making decisionbased Pr (d | e).Consider Table 1, enumerates possible health states sensors.four cases probability hypothesis pass threshold (in bold),leading decision. five scenarios, different decision wouldmade. SDP thus probability four scenarios decisionwould made. example, SDP is:0.781071 + 0.096429 + 0.096429 + 0.001071 = 0.975indicating relatively robust decision.Choi et al. (2012) define SDP formally as:Definition 1 (Same-Decision Probability). Let N Bayesian network conditionedevidence e, given hypothesis d, threshold , setunobserved variables H. Suppose making decision confirmed thresholdPr (d | e) . Same-Decision Probability scenarioX[Pr (d | e, h) ]Pr (h | e),(5)SDP (d, H, e, ) =h[Pr (d | h, e) ] indicator function1 Pr (d | e, h)[Pr (d | h, e) ] =0 otherwise.SDP notably hard compute. Choi et al. (2012) prove computing SDPgeneral PPPP -complete.5 previous work SDP (Darwiche & Choi, 2010;Choi et al., 2012), two options computing SDP5. class PPPP thought counting variant NPPP class, contains polynomialtime hierarchy PH MAP problem complete (Park & Darwiche, 2004).606fiAlgorithms Applications Same-Decision Probability+Pr (D)0.50.5S1S2S3S4Figure 2: Bayesian network intrusion detection, CPTs given Table 21. approximate algorithm developed Choi et al. (2012). algorithm usesaugmented variable elimination algorithm produces potentially weak boundbased one-sided Chebyshev inequality.2. naive brute-force method enumerates possible instantiations.4. Applying Same-Decision Probabilityinvestigate use SDP stopping criterion selection criterion.contrast usage SDP traditional methods discussed Section 2, findusing SDP provide insight decision maker scenarios.4.1 SDP Stopping Criteriondefinition SDP, see calculating high SDP, contrast calculatinglow SDP, would indicate higher degree readiness make decision, chancesdecision changing given evidence gathering lower. section showcomputing SDP provide additional insight thus distinguish scenariosotherwise indistinguishable based standard stopping criteria.threshold-based decision classical notion decision making uncertainty,commonly used requires utilities elicited. Examples thresholdbased decisions prevalent educational diagnosis (Gertner, Conati, & VanLehn,1998; Conati, Gertner, & VanLehn, 2002; Butz et al., 2004; Xenos, 2004; Arroyo & Woolf,2005; Munie & Shoham, 2008), intrusion detection (Kruegel et al., 2003; Modelo-Howardet al., 2008), fault diagnosis (Heckerman et al., 1995; Lu & Przytula, 2006), medicaldiagnosis (Pauker & Kassirer, 1980; Kahn et al., 1997; van der Gaag & Coupe, 1999).Consider sensor network Figure 2, may correspond intrusion detectionapplication discussed Kruegel et al. (2003). Here, hypothesis variable ={+, } = + implying intrusion. Suppose commit decision, stopperforming observations, belief event = + surpasses threshold ,say = 0.55. four sensors model, S1 , S2 , S3 S4 , whose readings mayaffect decision.Consider two following scenarios:1. S1 = + S2 = +.2. S3 = + S4 = +.607fiChen, Choi & DarwicheS1 Pr (S1 | D)+ +0.55+0.45+0.450.55S3 Pr (S3 | D)+ +0.60+0.40+0.400.60S2 Pr (S2 | D)+ +0.550.45++0.450.55S4 Pr (S4 | D)+ +0.650.35++0.350.65Table 2: CPTs network Figure 2. Parameterization 1.Since Pr (D = + | S1 = +, S2 = +) = 0.60 > 0.55 Pr (D = + | S3 = +, S4 = +) =0.74 > 0.55, clear cases threshold crossed. deemobservations necessary based beliefs surpassing threshold.Hence, using thresholds stopping criterion (as commonly done, see Kruegelet al., 2003; Lu & Przytula, 2006; Gao & Koller, 2011), two scenarios identicalinformation gathered decision made.viewpoint SDP, however, two scenarios different. particular, first scenario leads SDP 52.97%. means 47.03% chancedifferent decision would made observe two unobservedsensors S3 S4 . second scenario, however, leads SDP 100%. is,would certainty know would make decision also observetwo unobserved sensors S1 S2 : matter readings S1 S2 could be,beliefs event = + would always surpass threshold 0.55. Indeed,see Table 2, sensors S1 S2 strong sensors S3 S4 ,example, strong enough reverse decision.example provides clear illustration utility SDP stopping criterion.However, may argue clear second case, stop gatheringinformation Pr (D = + | S3 = +, S4 = +) = 0.74 larger margin thresholdPr (D = + | S1 = +, S2 = +) = 0.60.6 However, show following exampledeciding stop based solely margin robust. Considersensor network Figure 2 parameterizations sensor network shown Table 5Table 6 (found Appendix C), respectively refer Case 1 Case 2.7Note example, use threshold = 0.5.cases, S3 = + S4 = + observed, Pr (D = + | S3 = +, S4 = +) .particular,1. Case 1: Pr (D = + | S3 = +, S4 = +) = 0.775.6. Thus using aforementioned margins confidence stopping criterion used Gao Koller (2011).7. Note exact numbers CPTs necessary grasp examples CPTsprovided readers may reconstruct networks.608fiAlgorithms Applications Same-Decision Probability2. Case 2: Pr (D = + | S3 = +, S4 = +) = 0.599.using previously discussed margin stopping criterion, would seem Case1 could stop information gathering, whereas Case 2 information gatheringnecessary. However, compute SDP cases insightsnature robustness settings. Case 1, find SDP 0.781, whereasCase 2, find SDP 1.0 even though Case 1 margin higher,greater chance decision would change given information.demonstrates cannot use solely margin determine whether stopinformation gathering.clear examples SDP useful stopping criterion. First, SDPpinpoint situations observations unnecessary would neverreverse decision consideration. Second, SDP also identify situationsdecision made robust, likely change upon makingobservations. addition examples, Appendix A.2 show SDPuseful stopping criterion context utility-based decisions (e.g. influence diagrams).4.2 SDP Selection Criterionturn attention use SDP criterion deciding variablesobserve next, assuming stopping criterion indicates observationsnecessary. proposal based using VOI selection criterion (see Equation 3),choosing SDP reward function. call SDP gain, formallydefined as:Definition 2. Given Definition 4 SDP, SDP gain observing variables Gvariables H defined expected SDP observing G H subtracted SDPH:G(G) = E(G, H, e, ) SDP (d, H, e, ),(6)expected SDP defined as:E(G, H, e, ) =XSDP (d, H \ G, ge, )Pr (g|e)(7)gdefined decision made given current evidence.Note observe variables G H expected SDP 1.0,indicates observing G making decision, remaining variables H \ Grendered completely redundant observation effect decision.goal using SDP gain selection criterion observe variables which,average, allow stable decision given collected observations.next provide example using SDP selection criterion, contrastingtwo selection criteria: One based reducing entropy hypothesis variableD, another based maximizing gap decision probability Pr (d|e)given threshold (Krause & Guestrin, 2009). criteria motivatedreducing uncertainty, show indeed lead less stable decisionsSDP used.609fiChen, Choi & Darwiche+Pr (D)0.50.5S1S2Figure 3: Bayesian network CPTs given Appendix C.example given Bayesian network Figure 3, hypothesisvariable S1 /S2 sensors. decision triggered Pr (D = + | e) .80,evidence e sensors S1 S2 . observations (empty evidence e), SDP0.595, suggesting observations may needed. Assuming limited numberobservations (Heckerman et al., 1995), using myopic approach observing onevariable time (Dittmer & Jensen, 1997), need select next variableobserve.Note maximizing VOI negative entropy reward function amountsmaximizing mutual information, H(D, X) = H(D) H(D | X) (Cover & Thomas, 1991;Krause & Guestrin, 2005). mutual information variable sensor S20.53 whereas mutual information sensor S1 0.278. Hence, observingS2 reduce entropy most. terms margin confidence, another rewardfunction used Krause Guestrin (2009), observing S2 average lead 0.7margin states = + = , whereas observing S1 lead 0.6margin two states.However, compute corresponding SDP gains, G(S1 ) G(S2 ), findobserving S1 will, average, lead improving decision stability most. particular, observing S1 would give us SDP either 1 0.81 expected SDP0.905, whereas observing S2 would give us SDP either 0.7625, 0.5, 1expected SDP 0.805. Therefore, G(S1 ) = 0.31 G(S2 ) = 0.21. Hence, observing S1average allow us make decision less likely change due additionalinformation (beyond S1 ).intuition occurs although observing S2 leads greater information gain observing S1 , superfluous information. Note Pr (D = + | S2 = ) =0.0625, whereas Pr (D = + | S1 = ) = 0.2. Clearly, see observing S2 leadskewed distribution minimal conditional entropy. However, contextthreshold-based decisions, make decision based solely whether Pr (D = + | e)threshold, meaning may put much emphasis muchthreshold Pr (D = + | e) is. case, although observing S2average lead extreme distribution, observing S2 = leads making extremelynonrobust decision (a decision would change 50% time observation S1 ).Observing S1 making decision leads much robust decision. exampledemonstrates usefulness SDP selection criterion threshold-based decisions,SDP used select observations lead robust decisions.610fiAlgorithms Applications Same-Decision Probability+Pr (D)0.30.7E1H1H3H2Figure 4: Naive Bayes network (CPTs defined Appendix C).5. Computing Same-Decision ProbabilityComputing SDP involves computing expectation hidden variables H.naive brute-force algorithm would enumerate check whether Pr (d | h, e)instantiations h H. present algorithm save us need exploreevery possible instantiation h. make algorithm easier understand, firstdescribe compute SDP Naive Bayes network. trivial problemshow Section 7 computing SDP Naive Bayes network NP-hard.generalize algorithm arbitrary networks.5.1 Computing SDP Naive Bayes Networksfind convenient implement test Pr (d | h, e) log-oddsdomain, where:log O(d | h, e) = logPr (d | h, e)Pr (d | h, e)(8)define log-odds threshold = log 1Tand, equivalently, test whetherlog O(d | h, e) .Naive Bayes network class variable, H E leaf variables,Q H, posterior log-odds observing partial instantiation q = {h1 , . . . , hj }written as:log O(d | q, e) = log O(d | e) +jXw hi(9)i=1whi weight evidence hi defined as:whi = logPr (hi | d, e)Pr (hi | d, e)(10)weight evidence whi contribution evidence hi quantitylog O(d | q, e) (Chan & Darwiche, 2003). Note weights computed timespace linear |H| using floating point representation.8 Table 3 depicts weightsevidence network Figure 4.8. Additionally, note Equation 10, since Naive Bayes networks Hi d-separated E givend, term e dropped equation. leave term general networks, Himay d-separated E.611fiChen, Choi & Darwiche123w hi3.01.221.22w hi-2.17-1.22-1.22Table 3: Weights evidence attributes Figure 4.H10.0H23.0H2-2.17H34.225.44H31.783.03.0H30.950.560.272.17H33.392.174.61Figure 5: search tree network Figure 4. solid line indicates + dashedline indicates . quantity log O(d | q, e) displayed next node qtree. Nodes log O(d | q, e) = 0 shown bold.One compute SDP enumerating instantiations variables Husing Equation 9 test whether log O(d | h, e) . Figure 5 depicts search treeNaive Bayes network Figure 4, used purpose. leavestree correspond instantiations h variables H. generally, every nodetree corresponds instantiation q, Q H.brute-force computation SDP would entail:1. Initializing total SDP 0.2. Visiting every leaf node h search tree.3. Checking whether log O(d | h, e) so, adding Pr (h | e) total SDP.Figure 5 depicts quantity log O(d | q, e) node q tree, indicating fiveleaf nodes (i.e., five instantiations variables H) indeed contribute SDP.state key observation underlying proposed algorithm. Consider nodecorresponding instantiation H1 = + search tree, log O(d | H1 = +, e) = 3.0.four completions h instantiation (i.e., four leaf nodes it)log O(d | h, e) = 0. Hence, really need visit leaves addcontributions Pr (h|e) individually SDP. Instead, simply add Pr (H1 = +|e)SDP, equals sum Pr (h|e) leaves. importantly,detect leaves contribute SDP computing lower bound usingweights depicted Table 3. is, two weights variable H2 , minimum1.22. Moreover, two weights variable H3 , minimum1.22. Hence, lowest contribution log-odds made leaf node H1 = +612fiAlgorithms Applications Same-Decision ProbabilityH10.03.0H2-2.17H30.950.273.392.17Figure 6: reduced search tree network Figure 5.1.22 1.22 = 2.44. Adding contribution current log-odds 3.0lead log-odds .56, still passes given threshold.similar technique used compute upper bounds, allowing us detect nodessearch tree leaf contribute SDP. Consider examplenode corresponding instantiation H1 = , H2 = , log O(d | H1 = , H2 =, e) = 3.39. Neither leaves node contribute SDPlog-odds pass threshold. detected considering weightsevidence variable H3 computing maximum weights (1.22). Addingcurrent log-odds 3.39 gives 2.17, still threshold. Hence,leaf node H1 = , H2 = contribute SDP part search treealso pruned.apply pruning technique based lower upper bounds, actuallyend exploring portion tree shown Figure 6. pseudocodefinal algorithm shown Algorithm 1. Note takes linear time computeupper lower bounds. Additionally, note specific ordering Hsearch tree constructed directly linked amount pruning. use orderingheuristic ranks query variable Hi difference corresponding upperlower bound H ordered greatest difference lowest difference allowearlier pruning.5.2 Computing SDP Arbitrary Networksgeneralize algorithm arbitrary networks viewing networks NaiveBayes networks aggregate attributes. this, first need following notion.Definition 3. partition H given E set S1 , . . . , Sk that: Si H;Si Sj = ; S1 . . . Sk = H; Si independent (d-separated) Sj , 6= j, givenE.Figure 7 depicts example partition.intuition behind partition allows us view arbitrary networkNaive Bayes network, class variable aggregate attributes S1 , . . . , Sk . is,aggregate attribute Si viewed variable states si , allowing us viewinstantiation h set values s1 , . . . , sk . have:613fiChen, Choi & DarwicheAlgorithm 1 Computing SDP Naive Bayes network. Note: q = {h1 , . . . , hj },Pwq defined ji=1 whi .input:N : Naive Bayes network class variableH: attributes {H1 , . . . , Hk }: log-odds thresholde: evidenceoutput: Same-Decision Probability pmain:global p 0.0 (initial probability)q {} (initial instantiation empty set)depth 0 (initial depth search tree)DFS SDP(q, H, depth)return p1: procedure DFS SDP(q, H, depth)P2:U pperBound log O(d | e) + wq + ki=depth+1 maxhi whiP3:LowerBound log O(d | e) + wq + ki=depth+1 minhi whi4:(U pperBound < ) return5:else (LowerBound )6:add Pr (q | e) p, return7:else8:depth < k9:value hdepth+1 attribute Hdepth+110:DFS SDP(qhdepth+1 , H \ Hdepth+1 , depth + 1)Proposition 1. partial instantiation q = {s1 , . . . , sj },log O(d | q, e) = log O(d | e) +jXw si ,(11)i=1wsi = logPr (si , | d, e)Pr (si | d, e)Proof.Pr (d | q, e)Pr (d | q, e)Pr (d | e)Pr (s1 | d, e) . . . Pr (sj | d, e)= logPr (d | e)Pr (s1 | d, e) . . . Pr (sj | d, e)log O(d | q, e) = log= log O(d | e) +jXi=1614w si(12)fiAlgorithms Applications Same-Decision ProbabilityE1X1H1H4X2H3H5E2X3H6H2Figure 7: partition H given E is: S1 = {H1 , H2 , H3 } S2 = {H4 }, S3 ={H5 , H6 }.Since Equations 11 12 analogous Equations 9 10, use Algorithm 1 arbitrary network. usage, however, requires auxiliary computationsneeded readily available Naive Bayes networks. discusscomputations next.5.2.1 Finding Partitionfirst need compute partition S1 , . . . , Sk , done pruning networkstructure follows: delete edges outgoing nodes evidence E hypothesis D,delete (successively) leaf nodes neither H, E D. identifycomponents X1 , . . . , Xk resulting network define non-empty Si = H Xielement partition. guarantees original network structure, Sid-separated Sj E 6= j (see (Darwiche, 2009)). Figure 7, networkpruning leads components X1 = {X1 , X2 , E2 , H1 , H2 , H3 }, X2 = {D, E1 , H4 }X3 = {X3 , H5 , H6 }.5.2.2 Computing Posterior Log-Odds, Probability Weights Evidencequantities O(d | e), Pr (q | e) wsi , referenced Lines 2, 3, 6algorithm, simple closed forms Naive Bayes networks. arbitrary networks,however, computing quantities requires inference using algorithmvariable elimination described Darwiche (2009). Note network pruningdeleting edges removing leaf nodes, discussed above, guaranteesfactor used variable elimination variables component Xi . Hence,variable elimination applied component Xi isolation, sufficientobtain needed quantities.615fiChen, Choi & Darwiche5.2.3 Computing Min Max Evidence Weightsfinally show compute upper lower bounds, maxsi wsi minsi wsi ,referenced Lines 2 3 algorithm. quantities alsocomputed using variable elimination, applied component Xi isolation.case, however, must eliminate variables Xi \ Si first variables Si . Moreover,first set variables summed-out, second set variables maxd-outmind-out, depending whether need maxsi wsi minsi wsi . Finally, eliminationprocess applied twice, evidence d, e second time evidence d, e.precisely, every component Xi set factors case == d. Using variable ordering, perform variable eliminationsets factors eliminateleftQ iany nonquery (intermediary) variablesQset factors = Pr (Si , d, e), set factors = Pr (Si , d, e).Since elimination order same, thus one-to-one matchingPr (ei ,S )factors sets, define new set factors = id = Pr id (ei ,Si ) .calculate wsi wsi respectively maximizing minimizing variables.Note summing variables maximizing variables variable eliminationalgorithm used Dechter (1999) order solve MAP. algorithm differsperform maximization minimization (to calculate wsi wsi ),set factors instead factors (di di ) result simply summingintermediary variables.Note similarly Dechter (1999), first summing variablesperforming maximization (and minimization case), elimination ordercase constrained, meaning may forced use poor ordering variableelimination results high treewidth.5.3 Complexity AnalysisLet n number variables network, h = |H|, w = maxi wi ,wi width constrained elimination order usedcomponent Xi . best-casetime complexityof algorithm n exp w worst-case time complexityn exp (w + h) . intuition behind bounds computingmaximumminimum weights aggregate attribute takes time n exp w . also boundscomplexity computing O(d|e), Pr (q|e) corresponding weights wsi . Moreover,depending weightsthreshold , traversing search tree take anywhereconstant time exp h . Since depth-firstsearch implemented linearspace, space complexity n exp w .6. Experimental Resultsperformed several experiments real synthetic networks test performance algorithm across wide variety network structures, ranging simpleNaive Bayes networks highly connected networks. Real networks either learneddatasets provided UCI Machine Learning Repository (Bache & Lichman, 2013)616fiAlgorithms Applications Same-Decision ProbabilityNetworkcaremdec6gtcc4etttcaavotingnavfirechesssourceUCIHRLHRLUCICRESSTUCICRESSTCRESSTUCI|H||h|6144825695129196831416384166553620 157286424 1677721630 1610612736naive0.1310.4070.4706.2346.80121.35642.88approx0.1180.2450.2570.1330.1450.1760.8560.183*new0.0490.2940.1490.0910.1670.1280.1780.50815.53Table 4: Algorithm comparison real networks. show time, seconds, takesalgorithm, naive, approx, new compute SDP different networks.Note indicates computation complete 20 minutetime limit constrained. Moreover, * indicates sufficientmemory complete computation.provided HRL Laboratories CRESST.9 majority real networks useddiagnostic networks, made clear variable selected decisionvariable would either knowledge fault variable. unclear cases,decision variable picked random. query evidence variables selectedrandom real networks.Besides algorithm, two options available compute SDP: 1.naive method brute-force computation enumerating possible instantiations2. approximate algorithm developed Choi et al. (2012). compare algorithmtwo approaches, compute SDP real networks.network selected least 80% total network variables query variablescould emphasize size query set greatly influences computationtime. computation given 20 minutes complete. believe valuethreshold greatly affect running time, computed SDP thresholds =[0.01, 0.1, 0.2, . . . , 0.8, 0.9, 0.99] took worst-case time. results experimentsthree algorithms shown Table 4. Note |H| number queryvariables |h| number instantiations naive algorithm must enumerate over.Moreover, indicates computation complete 20 minute time limit* indicates sufficient memory complete computation. networks{car,ttt,voting,nav,chess} Naive Bayes networks whereas networks {caa,fire}polytree networks others general networks.Given real networks tested algorithm on, clear algorithmoutperforms naive implementation approximate algorithm NaiveBayes networks polytree networks. Note approximation algorithm basedvariable elimination use certain constrained orders. Naive Bayes9. http://www.cse.ucla.edu/617fiChen, Choi & Darwiche40003500Average Explored Instantiations Running TimeNumber instantiations (x 10e3)3000250020001500100050001Time (s)2345Number subnetworks678Figure 8: Synthetic network average running time average number instantiationsexplored number connected components.network hypothesis root, approximation algorithm forceduse particularly poor ordering, explains failure chess network.analyze general network structure selected threshold affectsperformance algorithm, generated synthetic networks 100 variablesvarying treewidth using BNGenerator (Ide, Cozman, & Ramos, 2004). network,randomly selected decision variable, 25 query variables, evidence variables.10generated partition network grouped networks size obtainedpartition (k). goal test algorithms running time ability prunesearch-space depends k. average time average number instantiationsexplored shown Figure 8.general, see k increases, number instantiations exploredalgorithm decreases runtime improves. network becomes similarNaive Bayes structure increasing k. Moreover, larger k is, levelssearch tree, means algorithm opportunities prune.worst case, network may unable disconnected (k = 1). However, evencase algorithm still, average, efficient compared brute-forceimplementation cases, computing maximum minimum weightobserving H, find exist h change decision.found that, given time limit 2 hours, brute-force algorithm could solvesynthetic networks, whereas approach solved 70% networks.also test threshold affects computation time. Here, calculate posteriorprobability decision variable run repeatedly algorithm thresholdsvarying increments away. average running time increments seenFigure 9. evident threshold set away initial10. synthetic networks binary, brute-force approach would need explore 225 instantiations.618fiAlgorithms Applications Same-Decision Probability18001600Average Explored Instantiations Running TimeNumber instantiations (x 10e3)14001200100080060040020000.0Time (s)0.10.20.30.40.5Threshold distance initial posterior0.6Figure 9: Synthetic network average running time average number instantiationsexplored threshold distance initial posterior probability.posterior probability, algorithm finishes much faster, perhaps expected sinceusage extreme thresholds would allow search space pruning.Overall, experimental results show algorithm able solve many SDPproblems reach existing methods. also confirm algorithmcompletes much faster network disconnected threshold faraway initial posterior probability decision variable.7. Complexity Computing Same-Decision Probabilitypresent new complexity results SDP. first prove complexitycomputing SDP Naive Bayes structures NP-hard. show generalcomplexity computing SDP lies complexity class general expectationcomputation problem applicable wide variety queries graphical models,computation non-myopic value information.7.1 Computing SDP Naive BayesSDP known PPPP -complete (Choi et al., 2012). show SDP remainshard Naive Bayes networks.Theorem 1. Computing Same-Decision Probability Naive Bayes network NPhard.Proof. reduce number partition problem defined Karp (1972) computingSDP Naive Bayes model. Suppose given set positive Pintegers c1P, . . . , cn ,wish determine whether exists {1, . . . , n} jI ci = j6I cj .solve considering Naive Bayes network binary class variableuniform probability, binary attributes H1 , . . . , Hn CPTs leading weights619fiChen, Choi & Darwicheevidence wHi =T = ci wHi =F = ci . construction CPTs donesolving following system equations:Pr (Hi = | = )Pr (Hi = | = F )Pr (Hi = F | = )ci = logPr (Hi = F | = F )1 = Pr (Hi = | = ) + Pr (Hi = F | = )ci = log1 = Pr (Hi = | = F ) + Pr (Hi = F | = F )leave exact derivations (see Exercise 3.27 Darwiche, 2009). getresult that:Pr (Hi = | = F ) = Pr (Hi = F | = ) =2ci1+1Pr (Hi = | = ) = Pr (Hi = F | = F ) = 12ci1+1Note given CPTs defined wHi =T = ci wHi =F =ci , set integers partitioned instantiation h = {h1 , . . . , hn }Pni=1 whi = 0 since would include indices hi = case.First,PnThe Naive Bayes network satisfies number properties shall usePnext.nwhi either 0, 1, 1 since weights whi integers. Next, i=1 whi = c,i=1Pni=1 whi = c hi 6= hi . Finally, Pr (h1 , . . . , hn ) = Pr (h1 , . . . , hn ) hi 6= hi ,uniform probability distribution leaf Hi definedsymmetric CPT.Consider following SDP (the last step based properties):SDP (D = T, {H1 , . . . , Hn }, {}, 2/3)X[Pr (D = | h1 , . . . , hn ) 2/3]Pr (h1 , . . . , hn )=h1 ,...,hn=X[log O(D = | h1 , . . . , hn ) 1]Pr (h1 , . . . , hn )h1 ,...,hn=Xh1 ,...,hn"1 X=2nXh1 ,...,hnPni=1 whi#whi 1 Pr (h1 , . . . , hn )i=1"nX#whi 6= 0 Pr (h1 , . . . , hn )i=1= 0 instantiation h1 , . . . , hn iff" n#X Xwhi 6= 0 Pr (h1 , . . . , hn ) < 1h1 ,...,hni=1620fiAlgorithms Applications Same-Decision ProbabilityHence, partitioning problem solved iffSDP (D = T, {H1 , . . . , Hn }, {}, 2/3) < 1/27.2 Complexity Computing Non-myopic VOISDP shown PPPP -complete problem Choi et al. (2012). class PPPPessentially counting variant NPPP class, contains polynomial hierarchyPH MAP problem complete (Park & Darwiche, 2004). showsection general problem computing expectations also PPPP -complete,non-myopic VOI SDP instance expectation. Thus, developmentalgorithms compute SDP beneficial problems PPPP class,turn benefits computing assortment expectations, including non-myopic VOI.proposed expectation computation based using reward function Rproperties review next. particular, function R assumed mapprobability distribution Pr (D | e) numeric value. also assume minimuml maximum u range polytime computable. assumptionslimitingfor example, entropy utility expressed using reward functionsfall category (Krause & Guestrin, 2009).consider following computation expectations.D-EPT: Given polynomial-time computable reward function R, hypothesis variableD, unobserved variables H, evidence e, real number N , distribution Pr inducedBayesian network variables X,11 expectation decision problem asks:E=XR(Pr (D | h, e))Pr (h | e)hgreater N ?Note SDP falls special case reward function R SDP indicatorfunction (see Definition 4). example, definition used Choi et al. (2012),decision function outputs one two decisions depending whether Pr (d|e) >value threshold .following theorems, proofs Appendix B.Theorem 2. D-EPT PPPP -hard.Theorem 3. D-EPT PPPP .shows D-EPT PPPP -complete implies computational problemscomputing non-myopic VOI using variety reward functions also PPPP complete.11. proof also holds influence diagrams constrained one decision node.621fiChen, Choi & Darwiche8. Conclusionpaper, discussed commonly used information gathering criteriagraphical models value information reviewed recently introducednotion Same-Decision Probability (SDP). paper, proposed usageSDP decision making tool showing concrete examples usefulnessstopping criterion selection criterion. stopping criterion, SDP allowus determine observations necessary. selection criterion, usageSDP allow us select observations allow us increase decision robustness.justified usage SDP, proposed exact algorithmcomputation. Experimental results show algorithm comparable running timeprevious approximate algorithm also much faster naive brute-forcealgorithm. Finally, presented several new complexity results.Acknowledgementspaper combines extends work presented Chen, Choi, Darwiche (2012b,2013). work partially supported ONR grant #N00014-12-1-0423, NSFgrant #IIS-1118122, NSF grant #IIS-0916161. would also like thank NationalCenter Research Evaluation, Standards, & Student Testing Hughes Research Labcontributing sample diagnostic networks.Appendix A. Miscellaneous Topicssection go details notions mentioned earlierpaper. particular, continue discussion Section 2.3 go notionnon-myopic value information. Additionally, also continue leftSection 4.1 expand upon notion SDP stopping criterion contextutility-based decisions.Appendix A.1 Non-myopic Value InformationMyopic value information often used many applications easy compute(Dittmer & Jensen, 1997; Vomlel, 2004; Gao & Koller, 2011). However, problemmyopic selection optimal, times whole greater sumparts, individual observation set H seemingly may provide significantvalue, VOI observing H high. instance, take function= X1 X2 , alone neither X1 X2 useful, together determinative(Bilgic & Getoor, 2011). computing non-myopic VOI optimalVOI obtained.Due aforementioned problems using myopic VOI, recently, researchersrecently suggested using non-myopic VOI instead myopic VOI proposed various methods compute non-myopic VOI (Heckerman, Horvitz, & Middleton,1993; Liao & Ji, 2008; Krause & Guestrin, 2009; Zhang & Ji, 2010; Bilgic & Getoor, 2011).Computing non-myopic VOI hidden variables H difficult involves com622fiAlgorithms Applications Same-Decision Probabilityputing expectation possible values H, quickly becomes intractableH becomes larger.Existing algorithms computing non-myopic VOI approximate algorithms(Heckerman et al., 1993; Liao & Ji, 2008) relatively limited algorithms restrictedtree networks leaf variables (Krause & Guestrin, 2009). Bilgic Getoor(2011) developed Value Information Lattice (VOILA), frameworksubsets hidden variables H examined, optimal subset featuresfound increase classification accuracy meeting budget constraint.Appendix A.2 SDP Stopping Criterion Utility-based Decisionscases expected utility different decisions, well cost reducinguncertainty (making observations), quantified. common decision-theoreticsetting (Howard, 1966; Howard & Matheson, 1984), influence diagrams commonlyused. Influence diagrams seen Bayesian networks incorporate decisionutility nodes (Howard & Matheson, 1984; Zhang, 1998; Kjrulff & Madsen, 2008).selection criterion decision-theoretic setting clear: observations leadgreatest increase expected utility selected. usage utilities observationcosts prevalent; however, numerous researchers noted difficulty comingactual numerical quantities (Glasziou & Hilden, 1989; Lu & Przytula, 2006;Bilgic & Getoor, 2011).show SDP used stopping criterion decision-theoretic context expected-utility decisions influence diagrams (Howard & Matheson, 1984),extend definition SDP general setting allow applications.particular, assume F polytime computable decision function outputsdecision based distribution Pr (D | e). instance, decision functioncommonly used classification select class highest posterior probability arg maxd Pr (d | e) (Friedman et al., 1997), whereas threshold-based decisions,decision function would simply select decision Pr (D = | e) .SDP thus defined probability decision would madehidden states variables H known (Chen et al., 2012b).Definition 4 (Same-Decision Probability Generalized ). Given decision function F,hypothesis variable D, unobserved variables H, evidence e, Same-Decision Probability (SDP) definedX[F(Pr (D | h, e))]h Pr (h | e)(13)SDP (F, D, H, e) =h[F(Pr (D | h, e))]h indicator function1 F(Pr (D | h, e)) = F(Pr (D | e))=0 otherwise.original SDP definition, however, assumed binary variable,F(Pr (D | e)) = Pr (d | e) threshold (Darwiche & Choi, 2010).consider use SDP stopping criterion context expectedutility decisions influence diagrams (Howard & Matheson, 1984). particular,623fiChen, Choi & DarwicheQCPFigure 10: influence diagram investment problem.show using SDP, distinguish high-risk, high-reward scenarios lowrisk, low-reward scenarios otherwise indistinguishable consider usageVOI/utilities alone.Consider influence diagram Figure 10, consists Bayesian networkthree variables (C, Q S), decision node I, utility node P directfunction utility function u. influence diagram models investment problemventure capital firm deciding whether invest amount $5 milliontech startup (I = ) allowing money collect interest bank (I = F ).example, profit investment (P ) depends decision (I) successcompany (S), turn depends two factors: (1) whether existing competitorcompanies successful (C) (2) whether co-founders startup highquality, original idea (Q). C Q unobserved initially independentother. Variable latent hypothesis variable case thus cannot observed.Variables C Q, however, observed price.goal choose decision = maximum expected utility:XEU (i | e) =Pr (s | e)u(i, s),u(i, s) utility decision = given evidence e variables C Q.Figures 11 12 contain two different parameterizations influence diagramFigure 10. refer different scenarios investment problem.scenarios, given evidence variables C Q, best decision = F ,expected utility $500K. decision maker may commit decision decideobserve variables C Q, hope finding better decision lightadditional information. classical stopping criterion compute maximumexpected utility given observe variables C Q (Heckerman et al., 1993; Dittmer& Jensen, 1997):XmaxEU (i | c, q)Pr (c, q).c,qscenarios, maximum expected utility comes $1, 180K, showingobservations may lead better decision.1212. According formulation Krause Guestrin (2009), computed VOI variablesC Q using reward function.624fiAlgorithms Applications Same-Decision ProbabilityQFPr (Q)0.40.6CFPr (C)0.60.4QFFPr (S = | .)0.600.900.200.30CFFFFFFu(I, S)$5 106$5 106$5 105$5 105Figure 11: parameterization influence diagram Figure 10.QFPr (Q)0.10.9CFPr (C)0.90.1QFFPr (S = | .)0.050.980.010.05CFFFFFFu(I, S)$7 107$5 106$5 105$5 105Figure 12: parameterization influence diagram Figure 10.point, two scenarios indistinguishable viewpointclassical decision making tools. Remember Krause Guestrin (2009) BilgicGetoor (2011) remark budget observations expended longvalue information observation greater cost observation. Accordingselection criteria, variables thus observed, expectedfinancial gain could well increase.SDP, however, finds two scenarios different. particular,respect variables C Q, SDP 60% first scenario 99% secondscenario. is, even though stand make better decision scenarios uponobserving variables C Q (at least respect financial gain), even thoughexpected benefit observations scenarios, unlikelywould change current decision = F second scenario comparisonfirst. Hence, given additional information provided SDP, decision maker mayact quite differently two scenarios. Indeed, take closer look secondscenario, state world (when = ) deciding invest would yieldlarge financial gain. However, chance state manifesting extremely625fiChen, Choi & Darwichesmall (analogous lottery), meaning risk-conscious decision maker mayaverse gamble second scenario even waste resources observe variablesC D. Note example assumed utility incorporaterisk-factor, rational decision maker would always choose gatherinformation despite low probability changing current decision.illustrates usefulness SDP stopping criterion context expectedutility decisions influence diagrams. Namely, using SDP, distinguishtwo different scenarios, otherwise indistinguishable consider utilitiesalone.Appendix B. Proofssection provide proofs Theorems 2 3.Proof Theorem 2. show D-EPT PPPP -hard reduction following decision problem D-SDP, corresponds originally proposed notion same-decisionprobability threshold-based decisions (Darwiche & Choi, 2010).D-SDP: Given decision based probability Pr (d | e) surpassing threshold , setunobserved variables H, probability p, same-decision probability:X[Pr (d | h, e) ]Pr (h | e)(14)hgreater p?Here, [.] denotes indicator function evaluates 1 enclosed expressionsatisfied, 0 otherwise. D-SDP shown PPPP -complete Choi et al. (2012).same-decision probability corresponds expectation respect distribution Pr (H | e), using reward function:1 Pr (d | h, e)R(Pr (D | h, e)) =0 otherwise.Thus same-decision probability iff expectation .Proof Theorem 3. show D-EPT PPPP , provide probabilistic polynomialtime algorithm, access PP oracle, answers decision problem D-EPTcorrectly probability greater 21 . proof generalizes simplifies proofgiven Choi et al. (2012) D-SDP.Consider following probabilistic algorithm determines E > N :1. Sample complete instantiation x Bayesian network, probability Pr (x).linear time, using forward sampling (Henrion, 1986).2. x compatible e, use PP-oracle compute = R(Pr (D | h, e)).First, reward function R computed polynomial time, definition.Second, Pr (D | h, e) computed using PP-oracle, since inference #Pcomplete (Roth, 1996), since PPP = P#P .626fiAlgorithms Applications Same-Decision Probability3. Define function a(t) = 12 + 21 tNul , defines probability used probabilisticalgorithm guess whether E > N (see Lemma 1).4. Declare E > N probability:a(t) x compatible e;12x compatible e.probability declaring E > N is:r=Xhgreater121a(t)Pr (h, e) + (1 Pr (e))2(15)iff following set equivalent statements hold:Xa(t)Pr (h, e) >hXa(t)Pr (h | e) >h1211tNPr (h | e) >+2 2 ul2X 1tNPr (h | e) > 02 ulhX(t N )Pr (h | e) > 0X 1hPr (e)2hXR(Pr (D | h, e))Pr (h | e) > N.hThus r >12iff E > N .Lemma 1. function a(t) =12+1 tN2 ulmaps reward probability [0, 1].Proof. Values u l given, denote upper lower bounds reward t,also threshold N . Thus tNul [1, 1].Note a(t) denotes probability used algorithm declare whether E > N ,higher lower depending value reward = R(Pr (D | h, e)).Appendix C. Conditional Probability Tablessection provide conditional probability tables networks Figures 1, 2, 3,4.627fiChen, Choi & Darwiche+Pr (D)0.50.5Hippnnll++Xi++++X1++Ei++++++++Pr (X1 | D)0.90.10.10.9X1++Pr (Ei | Hi , Xi )1.00.01.01.00.00.00.01.0HipnlX2++Pr (X2 | X1 )0.90.10.10.9Pr (Hi )0.810.090.090.01Figure 13: CPTs Bayesian network given Figure 1. NoteCPTs variables Ei , lines case Ei = + given, sincePr (Ei = |Hi , Xi ) = 1 Pr (Ei = +|Hi , Xi ).S1 Pr (S1 | D)+ +0.65+0.350.30+0.70S3 Pr (S3 | D)+ +0.65+0.350.35+0.65S2 Pr (S2 | D)+ +0.60+0.40+0.300.70S4 Pr (S4 | D)+ +0.65+0.35+0.350.65Table 5: CPTs network Figure 2. Parameterization 2.628fiAlgorithms Applications Same-Decision ProbabilityS1 Pr (S1 | D)+ +0.500.50++0.400.60S3 Pr (S3 | D)+ +0.550.45++0.450.55S2 Pr (S2 | D)+ +0.50+0.50+0.400.60S4 Pr (S4 | D)+ +0.55+0.45+0.450.55Table 6: CPTs network Figure 2. Parameterization 3.S2 Pr (S2 | D)+ +0.75+0.20.05++0.050.20.75S1 Pr (S1 | D)+ +0.80.2++0.20.8Table 7: CPTs Bayesian network Figure 3.H1 Pr (H1 | D)+ +0.80+0.20+0.100.90H2 Pr (H2 | D)+ +0.70+0.30+0.300.70Table 8: CPTs network Figure 4. Pr (H3 | D), Pr (E1 | D) Pr (H2 |D)equal.629fiChen, Choi & DarwicheReferencesArroyo, I., & Woolf, B. (2005). Inferring learning attitudes Bayesian networklog file data. Proceedings 12th International Conference ArtificialIntelligence Education, pp. 3340.Bache, K., & Lichman, M. (2013). UCI machine learning repository..Bilgic, M., & Getoor, L. (2011). Value information lattice: Exploiting probabilistic independence effective feature subset acquisition. Journal Artificial IntelligenceResearch (JAIR), 41, 6995.Butz, C. J., Hua, S., & Maguire, R. B. (2004). web-based intelligent tutoring systemcomputer programming. Web Intelligence, pp. 159165. IEEE Computer Society.Chan, H., & Darwiche, A. (2003). Reasoning Bayesian network classifiers. Proceedings 19th Conference Uncertainty Artificial Intelligence, pp. 107115.Chen, J., Low, K. H., Tan, C. K.-Y., Oran, A., Jaillet, P., Dolan, J., & Sukhatme, G.(2012a). Decentralized data fusion active sensing mobile sensors modelingpredicting spatiotemporal traffic phenomena. Proceedings Twenty-EighthConference Annual Conference Uncertainty Artificial Intelligence (UAI-12), pp.163173, Corvallis, Oregon. AUAI Press.Chen, S., Choi, A., & Darwiche, A. (2012b). Same-Decision Probability: new tooldecision making. Proceedings Sixth European Workshop ProbabilisticGraphical Models, pp. 5158.Chen, S., Choi, A., & Darwiche, A. (2013). exact algorithm computing SameDecision Probability. Proceedings 23rd International Joint ConferenceArtificial Intelligence, pp. 25252531.Choi, A., Xue, Y., & Darwiche, A. (2012). Same-Decision Probability: confidence measure threshold-based decisions. International Journal Approximate Reasoning(IJAR), 2, 14151428.Conati, C., Gertner, A., & VanLehn, K. (2002). Using Bayesian networks manage uncertainty student modeling. User Modeling User-Adapted Interaction, 12 (4),371417.Cover, T. M., & Thomas, J. A. (1991). Elements Information Theory. Wiley-Interscience.Darwiche, A. (2009). Modeling Reasoning Bayesian Networks (1st edition). Cambridge University Press.Darwiche, A., & Choi, A. (2010). Same-Decision Probability: confidence measurethreshold-based decisions noisy sensors. Proceedings Fifth EuropeanWorkshop Probabilistic Graphical Models, pp. 113120.Dechter, R. (1999). Bucket elimination: unifying framework reasoning. ArtificialIntelligence, 113 (1), 4185.Dittmer, S., & Jensen, F. (1997). Myopic value information influence diagrams. Proceedings Thirteenth Conference Annual Conference Uncertainty ArtificialIntelligence (UAI-97), pp. 142149.630fiAlgorithms Applications Same-Decision ProbabilityFriedman, N., Geiger, D., & Goldszmidt, M. (1997). Bayesian network classifiers. MachineLearning, 29 (2-3), 131163.Gao, T., & Koller, D. (2011). Active classification based value classifier. AdvancesNeural Information Processing Systems (NIPS 2011).Gertner, A. S., Conati, C., & VanLehn, K. (1998). Procedural help Andes: Generating hints using Bayesian network student model. Proceedings NationalConference Artificial Intelligence, pp. 106111.Glasziou, P., & Hilden, J. (1989). Test selection measures. Medical Decision Making, 9 (2),133141.Greiner, R., Grove, A. J., & Roth, D. (2002). Learning cost-sensitive active classifiers.Artificial Intelligence, 139 (2), 137174.Hamscher, W., Console, L., & de Kleer, J. (Eds.). (1992). Readings Model-Based Diagnosis. Morgan Kaufmann Publishers Inc.Heckerman, D., Breese, J. S., & Rommelse, K. (1995). Decision-theoretic troubleshooting.Communications ACM, 38 (3), 4957.Heckerman, D., Horvitz, E., & Middleton, B. (1993). approximate nonmyopic computation value information. IEEE Transactions Pattern Analysis MachineIntelligence, 15 (3), 292298.Henrion, M. (1986). Propagating uncertainty Bayesian networks probabilistic logicsampling. Proceedings Second Annual Conference Uncertainty ArtificialIntelligence (UAI-86), pp. 149163.Howard, R. A. (1966). Information value theory. IEEE Transactions Systems ScienceCybernetics, 2 (1), 2226.Howard, R. A., & Matheson, J. E. (Eds.). (1984). Readings Principles Applications Decision Analysis. Strategic Decision Group.Ide, J. S., Cozman, F. G., & Ramos, F. T. (2004). Generating random Bayesian networksconstraints induced width. Proceedings 16th European ConferenceArtificial Intelligence, pp. 323327.Jordan, A. (2002). discriminative vs. generative classifiers: comparison logisticregression naive Bayes. Advances Neural Information Processing Systems, 14,841.Kahn, C. E., Roberts, L. M., Shaffer, K. A., & Haddawy, P. (1997). ConstructionBayesian network mammographic diagnosis breast cancer. Computers BiologyMedicine, 27 (1), 1929.Karp, R. M. (1972). Reducibility among combinatorial problems. Complexity Computer Computations. Springer.Kjrulff, U. B., & Madsen, A. L. (2008). Bayesian Networks Influence Diagrams:Guide Construction Analysis. Springer.Krause, A., & Guestrin, C. (2005). Near-optimal nonmyopic value information graphical models. 21st Conference Uncertainty Artificial Intelligence, pp. 324331.631fiChen, Choi & DarwicheKrause, A., & Guestrin, C. (2009). Optimal value information graphical models.Journal Artificial Intelligence Research (JAIR), 35, 557591.Kruegel, C., Mutz, D., Robertson, W., & Valeur, F. (2003). Bayesian event classificationintrusion detection. Proceedings Annual Computer Security ApplicationsConference (ACSAC).Liao, W., & Ji, Q. (2008). Efficient non-myopic value-of-information computation influence diagrams. International Journal Approximate Reasoning, 49 (2), 436450.Lindley, D. V. (1956). measure information provided experiment. AnnalsMathematical Statistics, 27 (4), 9861005.Lu, T.-C., & Przytula, K. W. (2006). Focusing strategies multiple fault diagnosis.Proceedings 19th International FLAIRS Conference, pp. 842847.Millan, E., Descalco, L., Castillo, G., Oliveira, P., & Diogo, S. (2013). Using Bayesiannetworks improve knowledge assessment. Computers & Education, 60 (1), 436447.Modelo-Howard, G., Bagchi, S., & Lebanon, G. (2008). Determining placement intrusion detectors distributed application Bayesian network modeling.Proceedings 11th International Symposium Recent Advances IntrusionDetection, pp. 271290.Munie, M., & Shoham, Y. (2008). Optimal testing structured knowledge. AAAI08:Proceedings 23rd National Conference Artificial intelligence, pp. 10691074.Ognibene, D., & Demiris, Y. (2013). Towards active event recognition. Proceedings23rd International Joint Conference Artificial Intelligence, pp. 24952501.Park, J. D., & Darwiche, A. (2004). Complexity results approximation strategiesMAP explanations. Journal Artificial Intelligence Research (JAIR), 21, 101133.Pauker, S. G., & Kassirer, J. P. (1980). threshold approach clinical decision making..New England Journal Medicine, 302 (20), 110917.Raiffa, H. (1968). Decision Analysis Introductory Lectures Choices Uncertainty.Addison-Wesley.Ramoni, M., & Sebastiani, P. (2001). Robust Bayes classifiers. Artificial Intelligence, 125 (12), 209226.Roth, D. (1996). hardness approximate reasoning. Artificial Intelligence, 82, 273302.Shann, M., & Seuken, S. (2013). active learning approach home heatingsmart grid. Proceedings 23rd International Joint Conference ArtificialIntelligence, pp. 28922899.Stratonovich, R. (1965). value information. Izvestiya USSR Academy Sciences,Technical Cybernetics, 5, 312.van der Gaag, L. C., & Coupe, V. M. H. (1999). Sensitivity analysis threshold decisionmaking Bayesian belief networks. AI*IA, pp. 3748.Vomlel, J. (2004). Bayesian networks educational testing. International JournalUncertainty, Fuzziness Knowledge-Based Systems, 12 (supp01), 83100.632fiAlgorithms Applications Same-Decision ProbabilityXenos, M. (2004). Prediction assessment student behaviour open distanceeducation computers using Bayesian networks. Computers & Education, 43 (4),345359.Yu, S., Krishnapuram, B., Rosales, R., & Rao, R. B. (2009). Active sensing. InternationalConference Artificial Intelligence Statistics, pp. 639646.Zhang, N. L. (1998). Probabilistic inference influence diagrams. Computational Intelligence, pp. 514522.Zhang, Y., & Ji, Q. (2010). Efficient sensor selection active information fusion. IEEETransactions Systems, Man, Cybernetics, Part B, 40 (3), 719728.633fiJournal Artificial Intelligence Research 49 (2014) 143-170Submitted 10/13; published 02/14Procedural CharacterizationSolution Concepts GamesJoseph Y. Halpernhalpern@cs.cornell.eduComputer Science DepartmentCornell UniversityIthaca, NY 14853, USAYoram Mosesmoses@ee.technion.ac.ilDepartment Electrical EngineeringTechnionIsrael Institute TechnologyHaifa, 32000, IsraelAbstractshow game-theoretic solution concepts Nash equilibrium, correlatedequilibrium, rationalizability, sequential equilibrium given uniform definitionterms knowledge-based program counterfactual semantics. precise sense,program viewed providing procedural characterization rationality.1. Introductiongeneral intuition that, many situations, players dependsknow. leads hope describe players actions procedurally usingknowledge-based (kb) programs (Fagin, Halpern, Moses, & Vardi, 1995, 1997) formknow (or know) X . example, kb program could saydont know Ann received information, send text message,writtenKi (Ann received info) send Ann text message.kb program form standard . . . statement, except testclause involves knowledge (expressed using modal operator Ki ).Knowledge-based programs successfully applied distributed computing,help design new protocols clarify understanding existingprotocols (see, e.g., Fagin et al., 1997; Dwork & Moses, 1990; Hadzilacos, 1987; Halpern,Moses, & Waarts, 2001; Halpern & Zuck, 1992; Mazer & Lochovsky, 1990; Mazer, 1990;Moses & Kislev, 1993; Moses & Tuttle, 1988; Neiger & Bazzi, 1992; Neiger & Toueg, 1993).also applied successfully planning (Brafman, Latombe, Moses, & Shoham,1997; Lang & Zanuttini, 2012, 2013; Reiter, 2001). paper, initiate projectuse kb programs game theory. seems like particularly fruitful applicationarea, since seems kind reasoning people employ gamesdecision-making problems.focus one application kb programs game theory: characterizing solution concepts. Many solution concepts considered game-theory literature, rangingNash equilibrium correlated equilibrium refinements Nash equilibriumc2014AI Access Foundation. rights reserved.fiHalpern & Mosessequential equilibrium weaker notions rationalizability (see Osborne & Rubinstein, 1994, overview).Typically, solution concepts assume players rational, senseplayers strategy represents best response beliefs strategiesplayers using. Indeed, number epistemic characterizations varioussolution concepts provided literature. particular interest uscharacterizations terms common knowledge rationality. characterizationsfollowing flavor: ~ satisfies solution concept X iff statemodel (a) common knowledge players rational, (b) playersplaying strategy profile ~ , (possibly) (c) satisfies additional property.additional properties needed X rationalizability (Brandenburger & Dekel, 1987);get correlated equilibrium assume players common prior (Aumann,1987); get Nash equilibrium assume prior takes strategy choicesuncorrelated (Aumann, 1987).1 Similar results proved sequential equilibriumperfect equilibrium (Halpern & Moses, 2010).standard semantics kb programs (see Section 2) essentially ensures kbprograms run players common knowledge. Thus, might hopecould find kb program captures rationality, could use giveprocedural characterization various solution concepts. paper showgoal attainable.Consider following kb program EQi player i, Ai () denotes possibleactions available player game . (This program applies normal-formextensive-form games. extensive-form game , Ai () union actionsavailable information sets; assume without loss generality setsactions different information sets disjoint.)action Ai ()VKi (intendi (a) a0 Ai () EUi (a) EUi (a0 ))play a.Intuitively, think program one ensures players expected utilitymaximizers: Player follows action playing action maximizes expectedutility. literally, EQi says player play action currently intends(that intended semantics intendi (a)), utilityless utility would playing alternative action. EUi (a0 ) representsexpected utility play a0 (conditional beliefs current informationset consider extensive-form games).2 utility taken respect playercurrent probability distribution (which viewed distribution strategyprofiles players, thus represents beliefs playersdoing).1. Although Aumann (1987) state result Nash equilibrium explicitly, follows easilyresults correlated equilibrium.2. Note EUi (a0 ) incorporates counterfactual. situation actually intendingplay a, EUi (a0 ) expected utility would play a0 instead. preliminaryversion paper (Halpern & Moses, 2007), made counterfactual reasoning explicitcounterfactual operator language. Following suggestion reviewer, suppressedcounterfactual here, focus issues interest us.144fiA Procedural Characterization Game ConceptsPrograms generally viewed describing various actions supposedperformed, thereby providing procedural specification behavior. Knowledge-based programs are, general, somewhat different. example, consider program EQi .written assuming player already chosen strategy. One possible wayview EQ (i.e., (EQ1 , . . . , EQn )) specifying that, given last-minute chancechange minds, none (utility-maximizing) players would reason deviateindividual choices.test EQi seen embodying (one standard form of) rationality: saysact maximize expected utility. common knowledgeplayer follows EQi (recall semantics kb programs essentially ensuresprograms run commonly known), then, intuitively, playerscommon knowledge rationality, equilibrium. Indeed, show,appropriate assumptions, played players act according EQinstance standard solution concept. EQ captures many solution concepts uniformway. Solution concepts differ assumptions made players beliefs.assumptions essentially ones arose logical characterizations solutionconcepts mentioned above. Thus, example, correlated equilibrium, ratherrequiring common knowledge rationality common prior,require players use EQ common prior; similarly solutionconcepts.semantics kb programs allows us capture assumptions playersbeliefs restricting appropriate systems. upshot single kb programarguably gives procedural embodiment rationality. Moreover, common knowledgeprogram run provides us characterization perhapscommon solution concepts used game theory: Nash equilibrium, correlated equilibrium,rationalizability, sequential equilibrium, perfect equilibrium.considerable work last two decades focusing interplay modal logic game theory, specifically epistemic logic solutionconcepts games (see, e.g., Aumann & Brandenburger, 1995; Benthem, 2007, 2010; Bruin,2010; Bonanno, 2002; Harrenstein, Hoek, Meyer, & Witteveen, 2002; Lorini & Schwarzentruber, 2010). paper differs line work relates equilibrium notionsknowledge-based programs, shows procedural commonality among equilibriumnotions, well slightly varying epistemic assumptions gives rise differentnotions.rest paper devoted making claims precise. Section 2,review relevant background game theory knowledge-based programs. giveformal semantics kb programs, use runs-and-systems framework (Fagin et al.,1995), used computer science literature represent complex systems.specialize framework represent games interest here.Section 3, show EQ characterizes Nash equilibrium, correlated equilibrium,rationalizability, sequential equilibrium game , appropriate context.conclude Section 4 discussion results, implications possibleextensions, general discussion potential use kb programs game theory.particular, argue despite non-negligible overhead involved dealing145fiHalpern & Mosesknowledge-based programs, using gives us flexible powerful tool capturingintuitions best response.2. Background Definitionssection, review relevant background games knowledge-based programs,define semantics knowledge-based program EQi formally. describeneed proving results. reader encouraged consult standard gametheory text (e.g., Osborne & Rubinstein, 1994) game theory, workFagin et al. (1995, 1997) runs-and-systems framework knowledgebased programs.2.1 Games Strategiesgame extensive form described game tree = . utility ui (h) definedterminal history h game tree (where terminal history game treepath leading root leaf), specifying player utility historyplayed. Let Z denote set terminal histories. (We omit subscript clearcontext.) Although typical assume one player time movesextensive-form game, allow arbitrary subsets players move. added generalityallows us view normal-form games special case extensive-form games. Thus,associated non-leaf node subset players whose move node.3non-leaf node w , bijection possible sets movesplayed w successors w. w0 successor w correspondsparticular set moves, w0 thought outcome playing movesw. nodes player moves partitioned information sets.behavioral strategy player extensive-form game associatesinformation set distribution (I) actions played I. Thus,strategy player tells player node game treesupposed move. fact strategy determines actions functioninformation sets captures intuition that, nodes player cannot tell apart,player must thing. pure strategy Si deterministic, specifying singleaction per information set. (Of course, pure strategy viewed special casebehavioral strategy; behavioral strategy puts probability 1 particularaction information set.) Since game tree assumed finite,finitely many pure strategy profiles. mixed strategy distributionpure strategies.4 Note player using mixed strategy randomizes once,beginning game; way contrast, player using behavioral strategy randomizesinformation set. pure (resp., mixed; behavioral) strategy profile tuple ~ =(1 , . . . , n ) specifying pure (resp., mixed; behavioral) strategy player. usual,given profile ~x, denote ~xi partial profile containing component players3. ease exposition, point consider games moves nature.difficulty dealing moves nature; discuss Section 4.4. consistently use Si denote pure strategy denote mixed strategy behavioralstrategy.146fiA Procedural Characterization Game Concepts~ = (S1 , . . . , Sn )i. denote = S(T ) set pure strategy profilesgame tree .normal-form game viewed special case extensive-form gameplayer makes one move, players move simultaneously. tree corresponding game depth one: nodes root leaves.2.2 Runs-and-Systems Frameworkexplain kb programs, must first describe runs-and-systems framework. assumethat, given point time, player game local state. local statecould include history game point, strategy used player,perhaps features players type, beliefs strategiesused players. shall see, purposes paper, model games,players local state essentially consist strategy information set. globalstate profile local states: one local state player.run sequence global states; formally, run function times globalstates. Thus, r(m) global state run r time m. definiteness, assumetime ranges natural numbers here. point pair (r, m) consisting run rtime m. Let ri (m) local state point (r, m); is, r(m) = (s1 , . . . , sn ),ri (m) = si . system set runs. probabilistic system tuple PS = (R,~ ),R system~ = (1 , . . . , n ) associates probability runs Rplayer i. Intuitively, represents player prior beliefs. special case1 = = n = , players common prior R. case, write(R, ).2.3 Modeling Game Systemgame , associate system R . describing system R ,decide model players local states, is, know pointsystem? part, details matter analysis paper,critical effect analyses. believe one advantagesruns-and-systems approach forces modeler think carefullyplayers local states be.case normal-form game , time 0, take players local stateconsist pure strategy intending play; players local state times1 consists strategy played (which take oneintending play) utility. Even think player mixedstrategy, think pure strategy local state pure strategyplayer chooses tossing coin. could, course, also include mixed strategyplayers state. turns would make difference; player strategyencoded distribution runs. upshot approach modeling things~identify run R pure strategy profile ; denote rS~run coresponding strategy profile S.take simple example, consider normal-form game n Figure 1,two players, Alice (the row player) Bob (the column player): four runsRn , corresponding four strategy profiles game. run r(T,L) ,147fiHalpern & MosesBL(3, 3)(4, 1)R(1, 4)(0, 0)Figure 1: simple 2-player game n .r(T,L) (0) = (T, L) r(T,L) (1) = ((T, 3), (L, 3)). run, Alices initial state ,intended strategy, state times 1 (T, 3), strategy utility.extensive-form game, take runs R correspond terminal historiesgame tree; one run rh corresponding history h. points runrh correspond nodes history h. is, global state rh (m) correspondsmth node w history h. (If greater length h, rh (m) = rh (|h|).)Suppose moves node w. take local state rh (m) form(Iw , a), Iw information set w, move makes informationset Iw history h. Intuitively, saying knows information set, moveintending make. solution concepts analyze extensive-form games,assume using behavioral strategy. Thus, think outcomecoin toss information set behavioral strategy. still need representlocal state points correspond nodes w move. detailslocal state points move matter much. definiteness,move node w corresponding (rh , m), take local stateIw0 , w0 recent node preceding w move; movedprior w, take local state h i. w final node terminalhistory, also encode utility local state, normal-form games.Thus, state encodes information happened thus far (this Iwcomponent), whether move (this captured whetheraction component local state), intends move, (atpoints correspond end game), players utility.solution concepts focus extensive-form games, thinkplayers using behavioral strategy. However, normal-form games,encode behavioral strategy local state. again, turnbehavioral strategy encoded probability distribution runs.5 could alsoincluded game players local states, since implicitly assuminggame common knowledge. would change anything analysis;done simply avoid cluttering notation. course, wouldappropriate thing games players fully aware gameplayed (see, e.g., Halpern & Rego, 2013).5. alert reader may spotted potential problem here. Runs equilibrium path (and hence,information sets equilibrium path) get probability 0, may seem cannot useprobability runs infer behavioral strategy information sets. But, shall see,probability runs actually use nonstandard probability infinitesimally closeactual probability generated strategy profile. nonstandard probability gives positiveprobability runs, hence used infer behavioral strategy. artifactapproach. contexts, may well want include behavioral strategy local state.148fiA Procedural Characterization Game ConceptsConsider 2-player extensive-form game e Figure 2, player 1 moves w1 ,player 2 moves information set {w2 , w3 }:b1 ! !!r (3,4)!!fi!!!r!#aaa#w22ab#aaa1 #aaar (3,2)#####w1rcccca2ccb1 ! !!c!!w!3cc!raaa2abaa!r (1,1)!ar (1,2)Figure 2: extensive-form game e .four runs , corresponding four terminal histories. Callhistories h1 h4 , going top bottom. Thus, rh1 (where utility (3,4)), 1s localstate rh1 (0) ({w1 }, a1 ), 2s local state h i. rh1 (1), 1s local state {w1 },2s ({w2 , w3 }, b1 ), rh1 (2), local state ({w1 }, 3), 2s local state({w2 , w3 }, 4).Since bijection runs R normal-form game pure strategyprofiles, distribution pure strategies normal-form game identifieddistribution runs R . Thus, associate mixed strategy profile ~normal-form game probabilistic system (R , ~ ), ~ distributionstrategy profiles (and hence also runs) induced ~ . Note according ~ , playersstrategy choices uncorrelated; probability player chooses Si player jchooses Sj product probability chooses Si probabilityj chooses Sj . Similarly, extensive-form game , behavioral strategy profile ~induces distribution histories, hence also runs R . denotedistribution ~ .2.4 Knowledge-Based Programsknowledge-based program syntactic object. purposes, knowledge-basedprogram player taken form1 a12 a2...,149fiHalpern & Mosesaj action i, j Boolean combination formulasform Ki , nested occurrences K` operators. assumetests 1 , 2 , . . . mutually exclusive, that, kb program player i, onetests evaluates true local state player moves. programEQi written form simply replacing . . . statement one linepossible action game . is, action Ai (),line EQi formKi (intendi (a)^EUi (a) EUi (a0 )) play a.a0 Si (A)Since player intends play one action point (r, m) (R ,~ ), testsEQi mutually exclusive. tests necessarily exhaustive, since pointstrategy player uses best response, test formsatisfied. Roughly speaking, none tests satisfied, nothing (andperforms null action skip).want define means (probabilistic) system PS compatiblekb program. Intuitively, case moves made PSones recommended kb program. simplicity, give enough requireddefinitions able handle case PS form (R ,~ ) kbprogram EQi . details, interested reader consult Fagin et al. (1995,1997).first step making precise, standard system PS = (R ,~ ),associate formula set [[]]PS points PS. Intuitively, [[]]PS setpoints R true. intendi (a) easy:[[intendi (a)]]PS set points (r, m) PS moves node wgame tree associated (r, m) action encoded local state.Note kb program Pgi player attempt override intentions; is,program line form play a0 that, point (r, m)probabilistic system PS, true (i.e., (r, m) [[]]PS ), action local statea, a0 . case, shall see, Pg would compatible PS.semantics knowledge defined usual: formula Ki true truepoints considers possible. view information point (r, m)encapsulated local state (r, m), denote ri (m). Thus, setpoints considers possible point (r, m) Ki (r, m) = {(r0 , m0 ) : ri0 (m0 ) = ri (m)};Ki (r, m) consists points local state (r, m).[[Ki ]]PS set points (r, m) Ki (r, m) [[]]PS .remains give semantics formulas form EUi (a0 ) EUi (a). Clearlyexpected utility would obtain play a0 point (r, m) dependsbeliefs players (r, m). Roughly speaking, beliefsobtained conditioning prior beliefs Ki (r, m). small technicalproblem here. probability distribution distribution runs; Ki (r, m) set150fiA Procedural Characterization Game Conceptspoints. cannot condition Ki (r, m). enable conditioning, first associateKi (r, m) set R[Ki (r, m)] runs go points Ki (r, m); is,R[Ki (r, m)] = {r0 : (r0 , m) Ki (r, m)).define i,r,m = | R[Ki (r, m)]. (For purposes paper, specifyi,r,m (R[Ki (r, m)]) = 0. turns irrelevant discussion.) Recallbijection runs R pure strategy profiles. Moreover, since playerknows strategy, runs R[Ki (r, m)], player using strategy. Thus,~i . use distribution compute EUi (a)i,r,m determines distribution0EUi (a ). case normal-form game , suffices compute expected utilityplay a0 (although a0 may fact strategy intends useruns R[Ki (r, m)]), assumption players use strategyintending use; strategy changes. extensive-form game,considering change a0 run r, keep actions fixed (i.e.,actions players throughout run, actions information set I),consider utility resulting run.normal-form game PS = (R ,~ ), [[EUi (a) EUi (a0 )]]PS consistspoints (r, m) expected utility using least highusing a0 , expectation taken respect distributionstrategy profiles ai players, determined i,r,m .extensive-form game, point (r, m) player intends play action a,information set I, move. compute EUi (a0 ), run r0 Ki (r, m),let hr0 [a/a0 ] history sequence actions playedplayer r0 , except information set I, plays a0 rather a.PEUi (a0 ) = r0 Ki (r,m) i,r,m (r0 )ui (hr0 [a/a0 ]). Again, [[EUi (a) EUi (a0 )]]PS consistspoints (r, m) moves EUi (a0 ) (computed above) higherEUi (a).Since player knows strategy (it appears local state), (r, m) [[intendi (a)]]PS ,Ki (r, m) [[intendi (a)]]PS . Similarly, since i,r,m = i,r0 ,m0 (r0 , m0 ) Ki (r, m), playerknows probability distribution, (r, m) [[EUi (a) EUi (a0 )]]PS , Ki (r, m)V0[[EUi (a) EUi (a0 )]]PS . Hence, formula intendi (a)a0 Ai () EUi (a) EUi (a )V0equivalent epistemic formula Ki (intendi (a)a0 Ai () EUi (a) EUi (a )); is,V0intendi (a) a0 Ai () EUi (a) EUi (a ) true iff player knows it. kept Kikb program emphasize formula whose truth dependsknows believes, thus test act on.Intuitively, system PS compatible kb program profile Pg PS couldarisen player uses Pgi . formalize follows.~ r R 0,Definition 2.1 PS compatible kb program profile Pgaction profile ~a (a) applying ~a (r, m) results (r, + 1) (seebelow) (b) (R[Ki (r, m)]) > 0 (r | R[Ki (r, m)]) > 0, eitherline ai Pgi (r, m) [[]]PS , line ainull move skip.151fiHalpern & Mosesexplained means apply action profile ~a point (r, m).general definition involves viewing action profiles transformers global states (seeFagin et al., 1995, 1997). Rather going details general definitionhere, give definition case PS form (R , ) Pg EQ .need paper, case, definition quite simple.~~~normal-form game, action profile ~a applied rS (0) results rS (1) iff ~a = S;~~1, ~a applied rS (m) results rS (m + 1) iff a1 = = skip.extensive-form game, ~a applied rh (m) results rh (m + 1) iff ai = skipmove information set associated rh (m) (which means that, particular,greater equal length h, ai = skip players i) and,move I, ai move encoded rih (m). Roughly speaking, meansnormal-form game , PS = (R , ) compatible EQ iff, player run r(r) > 0, according EQ r(0) intends accordinglocal state ri (0). Thus, intends play strategy S, must caseEUi (S) EUi (S 0 ) strategies 0 player i. analogous statement trueextensive-form games, although compute whether EUi (a) EUi (a0 ) point (r, m),use probability conditioned R[Ki (r, m)]. is, ai action played(r, m), ai really best response i, given beliefs (r, m).observation makes proofs results relatively straightforward, importantnote really instance general semantics kb programs.3. Main Resultssection, show EQ captures number standard solution concepts.start considering solution concepts normal-form games, move extensiveform games.3.1 Capturing Solution Concepts Normal-Form Gamesshow EQ captures three studied solution concepts normal-form games:Nash equilibrium, correlated equilibrium, rationalizability. differencescaptured highlights distinctions notions.3.1.1 Nash EquilibriumRecall (R, ) probabilistic system players common priorruns.Theorem 3.1 mixed strategy profile ~ Nash equilibrium normal-form gameiff (R , ~ ) compatible EQ .ProofFirst suppose ~ = (1 , . . . , n ) Nash equilibrium game . see~PS = (R , ~ ) compatible EQ , suffices show ~ (rS ) > 0,~~Si best response respect ~ | R[Ki (rS , 0)]. (We need consider (rS , 0)normal-form game, moves time 0.)152fiA Procedural Characterization Game Concepts~Note ~ | R[Ki (rS , 0)] = ~i (under obvious identification ~ | Ki (r, 0)distribution Si ). Since ~ Nash equilibrium, Si must best response ~i .~Thus, strategies 0 Si (), must (rS , 0) [[EUi (S) EUi (S 0 )]]PS .follows PS = (R , ~ ) compatible EQ .converse, suppose (R , ~ ) compatible EQ . want show~ Nash equilibrium. suffices show pure strategy Si support~ibest response ~i . Let Si support . Choose strategy profile~~support ~i . ~ (r ) > 0. Moreover, ~ | R[Ki (r , 0)] = ~i . Since (R , ~ )~compatible EQ ~ (rS ) > 0, must case that, strategies 0 Si (),~(rS , 0) [[EUi (S) EUi (S 0 )]]PS . is, indeed best response ~i .Consider game n described Figure 1. easy check game threeNash equilibria: two equilibria pure strategies: (B, L) (T, R).also equilibrium mixed strategies Alice randomizes (uniformly)B, Bob randomizes L R. means three probabilisticsystems form (Rn , ) compatible EQn . first, puts probability 1r(B,L) ; second, puts probability 1 r(T,R) , third, puts uniformprobability four runs system.3.1.2 Correlated Equilibriumwell known, players sometimes achieve better outcomes Nash equilibriumaccess helpful mediator. Consider simple 2-player game n describedFigure 1. Recall total utility three Nash equilibria games(that is, sum utilities two players) 5. get higher totalutility using trusted mediator, makes recommendation choosing random(T, L), (T, R), (B, L). gives player expected utility 8/3; thus,total utility 16/3. example correlated equilibrium since, example,mediator chooses (T, L), thus sends recommendation Alice L Bob,Alice considers equally likely Bob told L R, thus incentivedeviate; similarly, Bob incentive deviate. general, distribution purestrategy profiles correlated equilibrium players cannot better followingmediators recommendation mediator makes recommendations according . (Notethat, example, mediator chooses (pure) strategy profile (S1 , . . . , Sn ) according, mediator recommends Si player i; player told nothing strategyprofile except Si .) Roughly speaking, correlated equilibrium distribution(pure) strategy profiles every strategy player positive probabilitybest response conditional probability | projected onto Si . (Note~ 0 0 = , | viewedsupport | consists strategy profilesdistribution Si . Intuitively, player knows prior probability purestrategy profiles told play , believes probabilitystrategy profiles Si played players described | (projected ontoSi ). Conversely, distribution pure strategy profiles that, playerevery strategy player given positive probability best response| , correlated equilibrium. Formally, following definition.153fiHalpern & MosesDefinition 3.2 (Aumann, 1974) distribution pure strategy profiles correlatedequilibrium player i, strategy player (S) > 0 (where~ 0 0 = S), strategy 0identify set pure strategy profilesplayer i,Xui (S, Si )(Si | S)Si SiXui (S 0 , Si )(Si | S).Si Siis, correlated equilibrium when, every player i, mediator tells playstrategy positive probability according , gain switching0 , given beliefs players do, conditional playertold S.Clearly distribution strategy profiles game identified distribution runs R . easily capture correlated equilibrium using EQway generalizes Theorem 3.1. difference Theorem 3.1 Theorem 3.3 ~ Theorem 3.1 product measure, distribution runsTheorem 3.3 necessarily product measure (indeed, product measure iffcorrelated equilibrium Nash equilibrium).Theorem 3.3 distribution strategy profiles correlated equilibrium(normal-form) game iff (R , ) compatible EQ .Proof proof proceeds along lines similar Theorem 3.1.~Suppose correlated equilibrium (rS ) > 0. Again, must show~~Si best response | R[Ki (rS , 0)]. R[Ki (rS , 0)] consists precisely runsplayer plays Si . Thus, i,rS~ ,m = | Si . Since correlated equilibrium, Sibest response | Si ; thus easily follows (R , ) compatible EQ .converse, suppose distribution strategy profiles (R , )compatible EQ . want show correlated equilibrium. Supposestrategy player positive probability according . Thus,~run r = rS (r) > 0 Si = . seen, i,r,0 = | . Since(R , ) compatible EQ , must case best response | ,determines beliefs (r, 0). Thus, correlated equilibrium.Note fact intended strategy included local state normal-formgames ensures i,rS~ ,0 = | Si . Intuitively, correlated equilibrium, mediatortells strategy follow, uses information determining best response.Thus, local state model information. way contrast, Theorem 3.1 wouldhold even strategy part local state. Since ~ product measureTheorem 3.1, would still case i,r,0 = ~i runs r.3.1.3 Rationalizabilitycharacterization Nash equilibrium correlated equilibrium involves common prior runs. Dropping assumption gives rise another standard solution concept: rationalizability (Bernheim, 1984; Pearce, 1984). Intuitively, strategy player154fiA Procedural Characterization Game Conceptsrationalizable best response beliefs player maystrategies players following, assuming strategiesbest response beliefs one players strategies playersfollowing, on.Following Osborne Rubinstein (1994), say strategy player gamerationalizable if, player j, set Zj Sj () and, strategy Zj ,probability measure j,T Sj () whose support subset ZjZi ;player j strategy Zj , strategy best response (the beliefs)j,T .Intuitively, strategies Zi rationalizable strategies player i. Playerjustify playing strategy Zi because, assumption, distribution Zi(representing beliefs strategies players using)best response. Moreover, strategies assigns positive probabilitythemselve justifiable, since Zi , best responses beliefsplace positive probability strategies justifiable, on.ease exposition, consider pure rationalizable strategies. essentiallywithout loss generality. easy see mixed strategy player bestresponse beliefs player iff pure strategy support bestresponse . Moreover, assume without loss generality supportconsists pure strategy profiles.Notice game n Figure 1, strategies rationalizable. Alice playingjustified Alice believes Bob play R; Bob playing R justified believesAlice ; Alice playing B justified Alice believes Bob play L; Bobplaying L justified believes Alice play R.following theorem characterizes rationalizability framework. Noteassume common prior, vector~ = (1 , . . . , n ),necessarily identical, describing players beliefs.Theorem 3.4 pure strategy player (normal-form) game rationalizableiff exists probabilistic system PS = (R ,~ ) and, player j, exists setZj Sj (a) j gives every strategy Zj positive probability; (b) supportj contained Z = Z1 Zn , (c) Zi , (d) (R ,~ ) compatible EQ .Proof Suppose PS = (R ,~ ) probabilistic system satisfying four propertiesabove. want show rationalizable. Take sets Zi guaranteed existassumptions theorem sets Zi definition rationalizability.Zj , let j,T j | projected onto Sj . Note j | well defined,since j (T ) > 0. Moreover, support j,T contained Zj , since supportj contained Z. show every Zj best response j,T . Since~~j (T ) > 0, must run rS Sj = j (rS ) > 0. easy seej,rS~ ,0 = j | = j,T . Since (R ,~ ) compatible EQ , must casebest response j,T . Thus, rationalizable.155fiHalpern & Mosesconverse, suppose Si rationalizable. Thus, player j,exist set Zj and, strategy Zj , measure j,T Sj ()~ = j,S (S~j )/|Zj | Sj Zj , takingbest response j,T . Define j taking j (S)j~ = 0 otherwise. First, observe j probability S: strategy Sj Zj ,j (S)j (Sj Sj ) = j,Sj (Sj )/|Zj | = 1/|Zj |; result easily follows. Moreover,Sj , j (S) > 0 iff Zj (of course, j (S) j (S Sj ). sincesupport j,T contained Zj strategy Sj , easily followssupport j contained Z. Finally, Zi , construction. Since best responsej,T Zj , easily follows PS = (R ,~ ) compatible EQ .see strategies n rationalizable, actually take 1 = 2distributions assign probability 1/2 (T, R) (B, L). easy seesatisfies conditions Theorem 3.4, taking Z1 = {T, B} Z2 = {L, R}.However, take 1 = 2 . long support 1 2{(T, R), (B, L)}, choice 1 2 works.Osborne Rubinsteins definition rationalizability allows j,T jbelieves players strategy choices correlated. literature, playersassumed believe players choices made independently. addlatter requirement, must impose requirement probability measures1 , . . . , n Theorem 3.4.important characterization rationalizability strategy partlocal state. Intuitively, strategy together beliefs strategiesremaining players determine type. modeling rationalizability, suffices assumestrategy determines beliefs, identify type strategy. includingstrategy local state, basically allowing different types player i.3.2 Capturing Solution Concepts Extensive-Form Gamesconsider solution concepts extensive-form games. Recall that, case,assume players using behavioral strategies.3.2.1 Nash Equilibriumget essentially result Theorem 3.1: behavioral strategy profile ~Nash equilibrium extensive-form game iff (R , ~ ) compatible EQ .However, number new subtleties arise extensive-form games. First, Nash equilibrium extensive-form game require players make best responseequilibrium path. dealt definition compatibility since factconsider points (r, m) (Ki (r, m)) > 0 means consideringpoints equilibrium path.Another subtlety arises fact that, determining whether best responsepoint (r, m), player allowed change completely different strategy i0 .definition EQ extensive-form games considers changing differentaction. show suffices, appeal result known literatureone-deviation property (Osborne & Rubinstein, 1994). one-deviation property holdsif, order check behavioral strategy best response , suffices156fiA Procedural Characterization Game Conceptscheck local changes ; is, suffices check behavioral strategies differmodifying one information set.Let [I/a] behavioral strategy like except assigns probability1 action information set I. Strategies form [I/a] considershow one-deviation property holds information set I. best responseinformation set allows changes I, information sets precededI. analysis considers called games perfect recall. Roughlyspeaking, game perfect recall, players recall moves madeinformation sets passed through. recollection formalizedputting conditions information sets. omit formal definition perfect recall(see Osborne & Rubinstein, 1994). finite extensive-form game perfect recall,player i, define partial order player information sets0 if, every history h I, prefix h0 h 0 . Thus, 0 0preceded I, or, equivalently, appears game tree. Given two informationsets, say precedes 0 , write 0 , = 0 0 comes historygame (i.e., node 0 preceded node game tree). gamesperfect recall, partial order; cannot two distinct information sets0 0 0 I. Given information set player i, denote [i0 , I, ]strategy player agrees information sets 0 player0 agrees i0 information sets.recall notion best response behavioral strategies given Halpern(2013). belief system (Kreps & Wilson, 1982) function associatesinformation set probability, denoted , histories I. Given behavioral strategy~ belief system extensive-form game , let Pr~ denote distributionterminal histories induced ~ defineEUi ((~ , ) | I) =XX(h)Pr~ (z | h)ui (z).hI zZThus, expected utility (~ , ) conditional reaching captures expected payoffplayer ~ played information set on, given relative likelihoodhistories determined . Finally, ~ completely-mixed behavioral strategyprofile, let ~ belief system determined ~ obvious way:~I (h) = Pr~ (h | I).Definition 3.5 (Halpern, 2013) 0 information set player0 conditionalreached positive probability ~ 0 , -best response ~ireached using ~ 0 if, every strategy player i,0000EUi (((i , ~i), ~I ) | I) EUi (((i , ~i), ~I ) | I) .0strategy -best response relative ~ 0 -best response ~i0conditional reached using ~ information sets reachedpositive probability ~ 0 . strategy ~i best response relative ~ 0 (resp.,best response conditional reached using ~ 0 ) 0-best responserelative ~ 0 (resp., 0-best response conditional reached I).157fiHalpern & Moses0Thus, best response relative ~ 0 best response0information set player reached positive probability ~ ,assume ~ 0 determines probability histories and, best responding,allow player make arbitrary changes reached. determinesprobability reaching I.next result basically one-deviation property; shows strategyoptimal respect local changes fact best response.Theorem 3.6 Let game perfect recall. strategy best response responserelative ~ iff EUi (~ ) EUi (i [I/a], ~i ) information set playerreached positive probability ~ action play I.Proof essentially proved Selten (1975), briefly sketch argumenthere. Clearly, best response relative ~ reached ~positive probability, EUi (((~ , ~I ) | I) EUi ((i [I/a], ~i ), ~I ) | I) information sets reached positive probability according ~ playermoves, actions take I. converse, suppose EUi (((~ , ~I ) |I) EUi ((i [I/a], ~i ), ~I ) | I) information sets reached positiveprobability according ~ player moves, actions take I.way contradiction, suppose best response relative ~ .must information set reached positive probability ~strategy player EUi (([i , I, ], ~i ), ~I ) | I) > EUi (((~ , ~I ) | I). geteasy contradiction considering latest information set player reachedpositive probability ~ inequality holds (so information set0 6= 0 , inequality hold). (Since game perfect recall,notion latest information set well defined.)Theorem 3.7 behavioral strategy profile ~ Nash equilibrium extensive-formgame iff (R , ~ ) compatible EQ .omit proof, since easier (and similar spirit) proofs presentedlater section.3.2.2 Perfect Equilibriumstart considering (trembling-hand) perfect equilibrium (Selten, 1975). definednormal-form games extensive-form games. ease exposition, focusdefinition extensive-form games, although essentially approach appliesnormal-form games.idea ~ perfect equilibrium if, best response ~i ,best response even players j 6= tremble, (with exceedingly smallprobability) play strategy j .make precise, define completelymixed (behavioral) strategy player strategy where, information setplayer i, action played played positive probability. Observe~ completely mixed strategy extensive-form game , reachevery information set player positive probability. extensive-form158fiA Procedural Characterization Game Conceptsgame , strategy profile ~ perfect equilibrium iff exists sequence ~ ncompletely mixed strategies ~ n ~ and, n information setn conditional reached I. Intuitively, ~nplayer i, best response ~inrepresents tremble; ~i , n = 1, 2, 3, . . . sequence trembles converging ~ .strategy must best response tremble sequence. Thus, strategyperfect equilibrium profile ~ best response possible trembles,trembles along one particular path converging ~ . (The definition perfect equilibriumessentially normal-form games, except need conditioninformation set.)result depends characterization perfect equilibrium given Halpern (2009,2013) uses nonstandard probabilities, assign infinitesimal probabilitiesstrategy profiles. discrete nonstandard probability distribution set runs discreteprobability distribution assigns nonstandard probabilities runs sumruns adds 1.Halpern (2009) shows using nonstandard probability, capture Seltensintuition trembling-hand equilibrium without needing explicitly refer sequencesstrategy profiles, done Seltens original definition. idea sequenceconverging ~ Seltens original definition replaced single completely mixedstrategy profile infinitesimally close ~ . make precise, needdefinitions. well known every nonstandard real number , closeststandard real number denoted st() IR, called standard part : difference| st()| infinitesimal. Given nonstandard probability measure , definestandard probability measure st() taking st()(w) = st((w)) states .Two possibly nonstandard distributions 0 differ infinitesimally st() = st( 0 ).While, Selten shows, perfect equilibrium always exists normal-form games,necessarily exist arbitrary extensive-form game. However, existextensive-form games perfect recall. state Halperns characterizationtrembling-hand equilibrium. say two behavioral strategies i0 playerdiffer infinitesimally distributions (I) i0 (I) differ infinitesimallyinformation set player I. Two strategy profiles ~ = (1 , . . . , n ) ~ 0 = (10 , . . . , n0 )differ infinitesimally differs infinitesimally i0 I, every = 1, . . . , n.Theorem 3.8 (Halpern, 2009, 2013) behavioral strategy profile ~ = (1 , . . . , n )perfect equilibrium extensive-form game perfect recall iff exists nonstandard completely mixed behavioral strategy profile ~ 0 differs infinitesimally ~0 relative ~best response0 player i.dealing standard probabilities, definition probabilistic systemPS = (R,~ ) compatible knowledge-based program profile Pg, requiredaction played Pgi (r, m) played system PS (r, m)runs r (r | R[Ki (r, m)]) > 0. want restrict runspositive probability, runs nontrivial positive probability.obvious choice would require st(i (r | R[Ki (r, m)])) > 0. settingsplayers following behavioral strategy, requirement would would restrict runs rwhere, times m0 > m, player j moves information set associated (r, m0 ),move made j given positive standard probability behavioral strategy.159fiHalpern & Moseswould like case well move made (r, m). Since encodeintended move (r, m) local state ri (m) (recall local state modelsinformation made coin toss), conditional Ki (r, m), player intendedmove probability 1, even infinitesimal probability according strategy.simplicity, describe requirement want systems formR . systems, information set , let R[I] consist runs goinformation set I. Note moves I, R[I] disjoint unionsets form R[Ki (r, m)], runs r local state form (I, a).define means PS = (R ,~ ),~ profile nonstandard probabilitymeasures before, except clause (b), replace requirement(r | R[Ki (r, m)]) > 0 st(i (r | R[Ki (r, m)])) > 0, moves information setassociated (r, m), strengthen requirement st(i (r | R[I])) > 0.Since (r | R[I]) convex combination terms form (r | R[Ki (r0 , m)]),sum taken points (r0 , m) node associated (r0 , m)(R[Ki (r0 , m)]) > 0, (r | R[Ki (r0 , m)]) = 0 (r, m)/ Ki (r0 , m), easily followsst(i (r | R[I])) > 0 st(i (r | R[I])) > 0.standard probability measures , easy see (R[Ki (r, m)]) > 0(r | R[Ki (r, m)]) > 0 iff (R[Ki (r, m)]) > 0 (r | R[I]), reallygeneralization standard definitions.6Roughly speaking, says compatibility required pointsplaces significant probability moves made strategy used i. (This madeprecise proof Theorem 3.9.)Note since one player moves node w extensive-form game (sinceallow moves nature), action profile ~a applying ~a r(m) resultsr(m + 1), aj = skip j 6= i. (r, m)/ [[]]PS test EQj ;tests true points j moves.Theorem 3.9 strategy profile ~ perfect equilibrium extensive-form gameperfect recall iff exists (possibly nonstandard) completely mixed behavioral strategyprofile ~ 0 differs infinitesimally i0 (R , ~0 ) compatible EQ .Proof Suppose ~ = (1 , . . . , n ) perfect equilibrium . Theorem 3.8,exists nonstandard completely mixed strategy profile ~ 0 differs infinitesimally0 relative ~~ best response0 , player = 1, . . . , n.show PS = (R , ~0 ) compatible EQ . Suppose information set= Ki (r, m) associated (r, m) one moves, st(~0 (r | R[I])) > 0.(Note since ~ 0 completely mixed, guaranteed ~0 (R[I]) > 0.) Let6. reader may wonder take ri (m) information set, ratherinclude action plans do. former choice would simplified discussionabove, kb program EQ meaningful, know action do. Noteconsidering information two stages: tossed coindetermine next action, tossed it. conditioning informationtossed coin, even though local state models situation tossed coin. Usingintuition extend definition compatibility beyond scope systems form R ,long system generated players running randomized programs (like behavioral strategies),although making precise beyond scope paper.160fiA Procedural Characterization Game Conceptsaction encoded ri (m); is, action plans play (r, m). Sincest(~ (r | R[I])) > 0, must case action given positive standardprobability (completely mixed) distribution i0 (I). Since ~ perfect equilibrium,Theorem 3.8 best response relative ~ . Let = [i0 , I, ].definition, agree actions I. Since gives positive standardprobability I, . Theorem 3.6, must least good response0 , action a0 play I. Since gives positive standard[I/a0 ] ~i0 actionprobability, [I/a] must least good response [I/a0 ] ~i00, conditional reaching using ~ . easy see expected utility [I/a](resp., [I/a0 ]) conditional reaching value EUi (a) (resp., EUi (a0 ))point (r, m). Thus, (r, m) [[EUi (a) EUi (a0 )]]PS , PS compatible EQ .converse, suppose ~ 0 completely mixed behavioral strategy profilediffers infinitesimally i0 (R , ~0 ) compatible EQ . Let~ = st(~ 0 ). Again, let = [i0 , I, ]. Theorems 3.8 3.6, suffices showinformation set player action a0 play I, strategy0 conditional reached using ~least good response [I/a0 ] ~i0 .this, suffices show action support (I) = (I), strategy0 conditional reached using[I/a] least good response [I/a0 ] ~i~ 0 . fix information set player moves suppose support(I). Let r history reaches = Ki (r, m) playsplayers play action given positive standard probability ~ (and hence also~ 0 ) points preceding (r, m). Thus, st(~ (r | R[I])) > 0. Since PS compatibleEQ , must case (r, m) [[EUi (a) EUi (a0 )]]PS . first half0 conditionalproof, follows [I/a] least good response [I/a0 ] ~ireached using ~ 0 . Thus, ~ perfect equilibrium.3.2.3 Sequential Equilibriumnext characterize sequential equilibrium terms EQ . Recall sequential equilibrium (Kreps & Wilson, 1982) assessment, pair (~ , ), ~ behavioralstrategy profile belief system, is, function determines every information set probability histories I. Intuitively, information setplayer i, subjective assessment relative likelihood historiesI. Roughly speaking, assessment sequential equilibrium (a) every information set player moves chooses best response given beliefshistories information set strategies players, (b) beliefsconsistent strategy profile played. omit formal definition here,instead use characterization sequential equilibrium due Halpern (2009).Theorem 3.10 (Halpern, 2009, 2013) assessment (~ , ) sequential equilibriumextensive-form game perfect recall iff exist infinitesimalnonstandard completely mixed strategy profile ~ 0 differs infinitesimally ~-best response relative ~ , player i.difference sequential equilibrium perfect equilibrium characterization perfect equilibrium must best response relative161fiHalpern & Moses~ sequential equilibrium, need -best response infinitesimal . capture difference, dealing sequential equilibrium, reinterpretformula EUi (a) EUi (a0 ) ignore infinitesimal differences. Thus, formulatrue unless st(EUi (a0 ) EUi (a)) > 0 (or, equivalently, true standard partexpected utility using greater equal standard part expectedutility using a0 ). PS st-compatible EQ (standing compatible respectstandard values) PS compatible EQ reinterpretation EQ . Clearly,probability distributions PS standard, notions compatibilityst-compatibility EQ PS coincide.Theorem 3.11 assessment (~ , ) sequential equilibrium finite extensiveform game perfect recall iff exists (possibly nonstandard) completely mixed strategyprofile ~ 0 differs infinitesimally i0 (R , ~0 ) st-compatible EQ .Proof proof almost identical Theorem 3.9, replacing best response-best response, compatible st-compatible. leave details reader.3.2.4 Subgame-Perfect EquilibriumSubgame-perfect equilibrium, defined Selten (1965), usually considered gamesperfect information, information sets singletons. games perfect information, subgame perfection, sequential equilibrium, trembling-hand perfect equilibriumagree, need provide separate characterization. However, subgameperfection actually defined arbitrary games perfect recall.Given game perfect information node w , subtree rooted wdetermines subgame denote w if, every information set includesnode w0 w , nodes w . example, subtreegame e Figure 2 determine subgame, since information set {w2 , w3 }includes node w2 (namely, w2 itself), w3 w2 .strategy profile ~ subgame-perfect equilibrium if, every subgame w , ~ restrictednodes w Nash equilibrium w . Note subgame perfection placesrequirements action played nodes determine subgames, beyondfact action must part Nash equilibrium nodes higher treedetermine subgames.use program much like EQ characterize subgame-perfect equilibriumarbitrary games perfect recall. need make two changes EQ . First,need say best response required points subgame holds,(r, m) [[subgame]]PS node w associated (r, m) determines subgame. (Note[[subgame]]PS consists points game perfect information.) Second, needsay constraints points subgame hold. So,action Ai (), two lines formVKi (intendi (a) subgame a0 Si (A) EUi (a) EUi (a0 )) playVKi (intendi (a) a0 Si (A) EUi (a) EUi (a0 )) play a.Call resulting program SUBEQi .162fiA Procedural Characterization Game Conceptschanges make clear subgame perfect somewhat awkward notiongames players perfect information. case, change,analogue Theorem 3.9 holds subgame perfect equilibria.Theorem 3.12 strategy profile ~ subgame-perfect equilibrium extensiveform game perfect recall iff exists (possibly nonstandard) completely mixedbehavioral strategy profile ~ 0 differs infinitesimally i0 (R , ~0 )subgame compatible SUBEQ .omit proof here, similar spirit Theorem 3.9.4. Discussion Conclusionsessential intuition many solution concepts (it common knowledge that)players making best response beliefs. shown proceduralintuition captured single knowledge-based program, denoted EQ . differences solutions concepts lies differences assumptions playersbeliefs counts best response.Nash equilibrium, players believe mixed strategy profile played (andcommon belief one is).correlated equilibrium, players believe correlated strategy profileplayed (and common belief one is).perfect equilibrium, viewed believing nonstandard completelymixed strategy profile played (and common belief oneis), caring happens situations positive standard probability.sequential equilibrium, similarly viewed believing nonstandardcompletely mixed strategy profile played (and common beliefone is), caring happens states positive standardprobability best responses respect standard differences (an betterresponse infinitesimal viewed better).rationalizability, different players may hold different beliefs strategyprofile played.unification given kb programs arguably give insight, clearlysignificant amount overhead kb program framework. certainly reasonableask whether worth dealing overhead get unification, givenintuitions certainly well understood game-theory literature.sole advantage using kb programs prove theorems paper,perhaps answer no, believe kb program framework offersmuch game theory unification. one thing, kb programscapture intuition best response generally. give examples here:163fiHalpern & MosesDealing moves nature: assumed simplicitymoves nature extensive-form games analyzed. deal movesnature, first expand notion global state includes localstate nature, local states players. think natureslocal state consisting current node game tree. addition, thinknature, like players, following behavioral strategy (where natures movedepends local state). minor changes, results still go through,change. particular, theorems paper continue hold evengames nature moves, change proof.Bayesian games: Bayesian game, players types. think typedescription players private information. assumed commonlyknown distribution type profiles. strategy viewed functiontypes actions. players utility depends action profile typeprofile. standard solution concept considered Bayesian games Bayes-Nashequilibrium. Bayes-Nash equilibrium, player wants switch differentstrategy, since results lower expected utility (see Osborne & Rubinstein,1994, details). capture Bayes-Nash equilibrium framework.players local state would include players type, run characterized strategy profile type profile. means set runsR larger. changes, analogue Theorem 3.1 holds Bayes-Nashequilibrium.Beyond expected utility maximization: solution concepts considered paper based maximizing expected utility. also consider solution concepts based decision criteria. example, BoutilierHyafil (2004) consider minimax-regret equilibria, player uses strategybest-response minimax-regret sense choices players.Similarly, use maximin equilibria (Aghassi & Bertsimas, 2006). pointedChu Halpern (2003), decision rules viewed instancesgeneralized notion expected utility, (a) uncertainty representedplausibility measure, generalization probability measure, (b) utilities elements arbitrary partially ordered space, (c) plausibilities utilitiescombined using , generalizations + . interpreting EUi = uappropriately, capture exotic solution concepts well. Moreover,applying ideas essentially proof capture solution concepts games game common knowledge, playersaware available moves, discussed Halpern Rego (2013).results mentioned straightforward, much spiritresults already shown. interesting situation arises consider gamesimperfect recall. Part overhead framework need specify exactlyplayers local states are, is, know. context gamesperfect recall, perhaps important, move games imperfectrecall, becomes highly significant. Consider single-player game depicted Figure 3,first introduced Piccione Rubinstein (1997).164fiA Procedural Characterization Game Conceptsx0.5.5z0x2x1z122BBx3Lz2RL62z33Xx4Rz4z54Figure 3: game imperfect recall.hard show strategy maximizes expected utility examplechooses move node x1 , move B node x2 , move R information set Xconsisting x3 x4 . Call strategy . Let 0 strategy choosing move Bx1 , move x2 , move L X. Piccione Rubinstein argue node x1reached, player reconsider, decide switch 0 . indeedleads better payoff, resulting strategy (i.e., starting switching 0x2 , x2 reached) legal strategy original game; player moves left x3right x4 , although two nodes information set.question players local state becomes critical. includeplayers behavior strategy local state modeled extensive-form,could done change. Suppose game imperfect recall.First note include players strategy local state, system Rcorresponding game, h history ending z5 , point (rh , 2), playerknows x4 , despite information set. instance generalphenomenon: game imperfect recall, strategy player using givesinformation node information set at. cannot happen gameperfect recall.Suppose ease exposition include players strategy local state.happens player switches strategy. local state change then?local state includes new strategy (whether includes original strategy),set runs arises player sticks x2 , switches 0 x1 ,player reaches x3 , knows x3 , reaches x4 , knowsx4 . information set correctly representing players knowledge all!7key point runs-and-systems framework forces modeler considerquestions like whether player able keep track changes strategy; moreover,answers must reflected choice local state. recent work7. point already made Halpern (1997).165fiHalpern & Mosesdefining notions like sequential equilibrium games imperfect recall (see, e.g., Halpern& Pass, 2011b; Kline, 2005; Marple & Shoham, 2012). believe program EQand, generally, use runs-and-systems framework provide insightproblem.Interesting new issues arise add computation picture. Equilibriumnotions take computation account considered Halpern Pass(2011a). seems notion computational Nash equilibrium defined HalpernPass, players choose Turing machine play them, captured using EQwell. because, roughly speaking, charge computationTuring machine best response Turing machines chosenplayers. impose cost, might need computationalalgorithmic notions knowledge (such notions discussed Fagin et al., 1995, ch. 10).conclude two directions research. First, althoughfocused using kb programs characterize solution concepts here, idea agentsactions depend knowledge beliefs seems like natural way characterizestrategies games, meta-strategies classes games. Sayings lookleap trust, verify really shorthand knowledge-based programs.believe useful insights agents play games gained thinkingknowledge level way. Indeed, preconditions actions dependknowledge belief; agents utility also depend beliefs.key insight psychological games (Geanakoplos, Pearce, & Stacchetti, 1989). wouldinteresting extend knowledge-based programs knowledge-based utilities.Finally, although talked kb programs procedural, fact,procedure given calculation relevant knowledge, really amountsbest-response computation. non-probabilistic setting, conditionskb program implemented unique standard program (i.e., one without testsknowledge) shown Fagin et al. (1995, Section 7.2). results carryprobabilistic systems (since give indication compute relevantprobabilities). Nevertheless, given beliefs, kb programs viewed definingagent act. computing equilibrium, beliefs typically determinedstrategy profile. is, start beliefs determine act.Rather, solutions concepts considered here, fixed point:beliefs determine strategies (each players strategy best response beliefs),strategies determine beliefs. However, believe that, applicationskb programs, may well possible view kb program providing proceduralspecification. leave topic research.Acknowledgmentsthank reviewers perceptive comments, led many improvementspaper. material paper appeared preliminary form (Halpern &Moses, 2007). Joe Halperns work paper supported part NSF grantsIIS-0534064, IIS-0812045, IIS-0911036, CCF-1214844, AFOSR grants FA9550-08-10438 FA9550-09-1-0266, DoD Multidisciplinary University Research Initiative(MURI) program administered AFOSR grant N00014-01-1-0795, ARO166fiA Procedural Characterization Game Conceptsgrant W911NF-09-1-0281. Yoram Moses Israel Pollak academic chair Technion;work supported part Israel Science Foundation grant ISF 1520/11.ReferencesAghassi, M., & Bertsimas, D. (2006). Robust game theory. Mathematical Programming,Series B, 107 (12), 231273.Aumann, R. J. (1974). Subjectivity correlation randomized strategies. JournalMathematical Economics, 1, 6796.Aumann, R. J. (1987). Correlated equilibrium expression Bayesian rationality.Econometrica, 55, 118.Aumann, R. J., & Brandenburger, A. (1995). Epistemic conditions Nash equilibrium.Econometrica, 63 (5), 11611180.Benthem, J. van (2007). Rational dynamics epistemic logic games. InternationalGame Theory Review, 9 (1), 1345. (Reprinted corrections International GameTheory Review, 9:2, 377-409.).Benthem, J. van (2010). Modal Logic Open Minds. Center Study LogicInformation-Lecture Notes.Bernheim, B. D. (1984). Rationalizable strategic behavior. Econometrica, 52 (4), 10071028.Bonanno, G. (2002). Modal logic game theory: two alternative approaches. RiskDecision Policy, 7, 309324.Brafman, R. I., Latombe, J.-C., Moses, Y., & Shoham, Y. (1997). Applications logicknowledge motion planning uncertainty. Journal ACM, 44 (5),633668.Brandenburger, A., & Dekel, E. (1987). Rationalizability correlated equilibria. Econometrica, 55, 13911402.Bruin, B. de (2010). Explaining Games: Epistemic Programme Game Theory, Vol.346. Synthese Library.Chu, F., & Halpern, J. Y. (2003). Great expectations. Part I: customizabilitygeneralized expected utility. Proc. Eighteenth International Joint ConferenceArtificial Intelligence (IJCAI 03), pp. 291296.Dwork, C., & Moses, Y. (1990). Knowledge common knowledge Byzantine environment: crash failures. Information Computation, 88 (2), 156186.Fagin, R., Halpern, J. Y., Moses, Y., & Vardi, M. Y. (1995). Reasoning Knowledge.MIT Press, Cambridge, Mass. slightly revised paperback version published2003.167fiHalpern & MosesFagin, R., Halpern, J. Y., Moses, Y., & Vardi, M. Y. (1997). Knowledge-based programs.Distributed Computing, 10 (4), 199225.Geanakoplos, J., Pearce, D., & Stacchetti, E. (1989). Psychological games sequentialrationality. Games Economic Behavior, 1 (1), 6080.Hadzilacos, V. (1987). knowledge-theoretic analysis atomic commitment protocols.Proc. 6th ACM Symposium Principles Database Systems, pp. 129134.Halpern, J. Y. (1997). ambiguities interpretation game trees. GamesEconomic Behavior, 20, 6696.Halpern, J. Y. (2009). nonstandard characterization sequential equilibrium, perfectequilibrium, proper equilibrium. International Journal Game Theory, 38 (1),3750.Halpern, J. Y. (2013). nonstandard characterization sequential equilibrium, perfectequilibrium, proper equilibrium: Erratum. Unpublished manuscript.Halpern, J. Y., & Moses, Y. (2007). Characterizing solution concepts games usingknowledge-based programs. Proc. Twentieth International Joint ConferenceArtificial Intelligence (IJCAI 07), pp. 13001307.Halpern, J. Y., & Moses, Y. (2010). Characterizing solution concepts games using common knowledge rationality. Unpublished manuscript.Halpern, J. Y., Moses, Y., & Waarts, O. (2001). characterization eventual Byzantineagreement. SIAM Journal Computing, 31 (3), 838865.Halpern, J. Y., & Pass, R. (2011a). Algorithmic rationality: Game theory costly computation.. Available www.cs.cornell.edu/home/halpern/papers/algrationality.pdf;appear, Journal Economic Theory. preliminary version title Gametheory costly computation appears Proc. First Symposium InnovationsComputer Science, 2010.Halpern,J. Y., & Pass,R. (2011b).Sequential equilibriumgames imperfect recall.Unpublished manuscript;availablewww.cs.cornell.edu/home/halpern/papers/imperfect.pdf.Halpern, J. Y., & Rego, L. C. (2013). Extensive games possibly unaware players.Mathematical Social Sciences. appear.Halpern, J. Y., & Zuck, L. D. (1992). little knowledge goes long way: knowledge-basedderivations correctness proofs family protocols. Journal ACM,39 (3), 449478.Harrenstein, P., Hoek, W. van der, Meyer, J.-J. C., & Witteveen, C. (2002). modallogic interpretations games. ECAI, pp. 2832.168fiA Procedural Characterization Game ConceptsHyafil, N., & Boutilier, C. (2004). Regret minimizing equilibria mechanisms gamesstrict type uncertainty. Proc. Twentieth Conference Uncertainty Artificial Intelligence (UAI 2004), pp. 268277.Kline, J. J. (2005). Imperfect recall relationships solution conceptsextensive games. Economic Theory, 25, 703710.Kreps, D. M., & Wilson, R. B. (1982). Sequential equilibria. Econometrica, 50, 863894.Lang, J., & Zanuttini, B. (2012). Knowledge-based programs plansthe complexityplan verification. Proceedings 20th European Conference AI (ECAI 2012),pp. 504504.Lang, J., & Zanuttini, B. (2013). Knowledge-based programs plans: succinctnesscomplexity plan existence. Theoretical Aspects Rationality Knowledge:Proc. Fourteenth Conference (TARK 2013), pp. 138147.Lorini, E., & Schwarzentruber, F. (2010). modal logic epistemic games. Games, 1 (4),478526.Marple, A., & Shoham, Y. (2012). Equilibria finite games imperfect recall. Unpublished manuscript.Mazer, M. S. (1990). link knowledge communication faulty distributedsystems. Theoretical Aspects Reasoning Knowledge: Proc. Third Conference, pp. 289304.Mazer, M. S., & Lochovsky, F. H. (1990). Analyzing distributed commitment reasoningknowledge. Tech. rep. CRL 90/10, DEC-CRL.Moses, Y., & Kislev, O. (1993). Knowledge-oriented programming. Proc. 12th ACMSymposium Principles Distributed Computing, pp. 261270.Moses, Y., & Tuttle, M. R. (1988). Programming simultaneous actions using commonknowledge. Algorithmica, 3, 121169.Neiger, G., & Bazzi, R. (1992). Using knowledge optimally achieve coordination distributed systems. Theoretical Aspects Reasoning Knowledge: Proc. FourthConference, pp. 4359.Neiger, G., & Toueg, S. (1993). Simulating real-time clocks common knowledgedistributed systems. Journal ACM, 40 (2), 334367.Osborne, M. J., & Rubinstein, A. (1994). Course Game Theory. MIT Press, Cambridge, Mass.Pearce, D. G. (1984). Rationalizable strategic behavior problem perfection.Econometrica, 52 (4), 10291050.Piccione, M., & Rubinstein, A. (1997). interpretation decision problemsimperfect recall. Games Economic Behavior, 20 (1), 324.169fiHalpern & MosesReiter, R. (2001). knowledge-based programming sensing situation calculus.ACM Transactions Computational Logic, 2 (4), 433457.Selten, R. (1965).Spieltheoretische Behandlung eines Oligopolmodells mit Nachfragetragheit. Zeitschrift fur Gesamte Staatswissenschaft, 121, 301324 667689.Selten, R. (1975). Reexamination perfectness concept equilibrium points extensive games. International Journal Game Theory, 4, 2555.170fiJournal Artificial Intelligence Research 49 (2014) 363-402Submitted 09/13; published 02/14Multiagent Knowing Dynamic SystemsVaishak Bellevaishak@cs.toronto.eduDept. Computer Science, University Toronto,Toronto, Ontario, Canada M5S 3H5Gerhard Lakemeyergerhard@cs.rwth-aachen.deDept. Computer Science, RWTH Aachen University,52056 Aachen, GermanyAbstractidea knowing collection sentences, proposed Levesque, previously shown useful characterizing knowledge-based agents: terms specification,precise perspicuous account beliefs non-beliefs obtained monotonic setting.Levesques logic based first-order modal language quantifying-in, thus allowingde versus de dicto distinctions, among things. However, logic recent dynamicextension deal case single agent. work, propose first-order multiagent framework knowledge, actions, sensing knowing, shown inheritfeatures single agent version. significantly, prove reduction theorems meansreasoning knowledge actions framework simplifies non-epistemic,non-dynamic reasoning initial situation.1. Introductionconsidering knowledge-based agents dynamic worlds, much depends knownnot, evolves. Making telephone call, example, requires knowingreferent, number known, lookup telephone directory must attempted,agent would sufficient information complete task. Essentially, agentdeliberates act sensing agents knowledge base (KB) informs agentignorant fact, perhaps one necessary achieving goal. Moreover, takingpragmatic point view, desirable designing agents, modeler would providecertain facts may leave others unsaid. Think simple blocks world domain findred block table. agent would told red block, absence completedescription location every block domain, agent make partialinformation. Thus, least, needed compact way write knowledgebase, thereby providing full specification beliefs non-beliefs, accountchanges acting sensing, query language explicitly refers knowledge.1One way view first requirement think beliefs agent exactlyfollow assumption KB believed. Perhaps general accountcapture beliefs KB OL: logic knowing Levesque (1990). Levesquesproposal remarkably simple. augments logic belief (Hintikka, 1962; Kripke, 1963; Fagin,1. use terms knowledge belief interchangeably understanding knowledge need necessarily true real world.c2014AI Access Foundation. rights reserved.fiBelle & LakemeyerHalpern, Moses, & Vardi, 1995), (say) modality K denotes knowledge, modalitycapture notion knowing. Beliefs reasoned terms valid sentencesform:OKB Kread KB believed agent, agent knows .particularly interesting new modality allows one draw conclusions known also not. is, p Kq and, introspection, p KKq come valid. Note quite different classical epistemiclogic (Fagin et al., 1995), sense replace K, neither sentencesvalid. consequence, example, O(Tel(A, 1234) Tel(B, 1234)) agent concludesK(x. Tel(x, 1234) KTel(x, 1234)). says agent knows someone whosetelephone number 1234 without knowing who, usually referred de dicto versus dedistinctions knowledge (Kaplan, 1968). Thus, agent able reason ignorance,quantificational language, without told explicitly know.OL capture desiderata beliefs, include notions actions.obtain many features OL dynamic setting, logic ES (Lakemeyer & Levesque, 2011)proposed amalgamates OL situation calculus (McCarthy & Hayes, 1969; Reiter,2001; Scherl & Levesque, 2003). situation calculus popular general formalismrepresenting reasoning dynamic domains. ES (situation-suppressed) modal dialectsituation calculus2 formulas like traditional dynamic logic (Harel, Kozen, &Tiuryn, 2000),[pickup(obj5)](Holding(obj5) Holding(obj3))says picking obj5, agent holding obj5 obj3. ES, one stipulatesset axioms capturing application domain known agent,obtains entailments regarding beliefs, non-beliefs, belief expansion resolve agentsignorance acts perceives environment. example,= {SF(senseFragility(x)) Fragile(x)},roughly says sequence actions, agent perform fragility sensingaction, SF would inform robot whether object sensed fragile not. obj5 objectfragile real world, ES allows us reason entailments sort:1. |= Fragile(obj5) K(Fragile(obj5));2. |= Fragile(obj5) [senseFragility(obj5)]K(Fragile(obj5));which, English, says although agent know obj5 fragile initially,sensing.ES allows Reiter-style basic action theories, also equipped importantresult (Reiter, 2001; Scherl & Levesque, 2003): regression theorem knowledge.2. certain assumptions, valid sentences ES mapped valid sentences classical situation calculus (Lakemeyer & Levesque, 2011). is, ES serve semantic basis situation calculusworkable model theory.364fiMultiagent Knowing Dynamic Systemsis, sentences goals future, even mentioning belief, reduced questions(perhaps involving knowledge) initial state only. importantly, significant resultOL called representation theorem (Levesque & Lakemeyer, 2001) leveragedreduce epistemic queries initial state first-order reasoning task. effect, modalreasoning necessary.However, ES deals single agent case. Many AI applications formalisms needed involve multiple agents. might imagine robot following lead another agent, perhaps second robot, coordinate deliveries items rooms.Similarly, imagine two agents playing game cards other. others,modeling reasoning beliefs non-beliefs agents real worldagents world interest. case card game, example, especially fairone, agents might believe initially opponents know rules game.might justify certain strategies depend lack information opponents part.extending ES multiagent case, however, first need account knowingmultiagent case. number previous proposals (Lakemeyer, 1993; Halpern, 1993;Halpern & Lakemeyer, 2001; Waaler & Solhaug, 2005) attempted multiagent extensionsOL, propositional. Besides, significantly deviate Levesques simple modeltheory. recent work (Belle & Lakemeyer, 2010a), able show natural generalization OL n-agent case exist first-order language. article, continueline work propose n-agent generalization ES.3 projection problem (Reiter,2001), interested reasoning goals (perhaps involving multiagent beliefs)actions, show regression property provable. Finally, also obtain representationtheorem n-agent case means modal reasoning necessary. surveyrelated literature greater detail Section 5 results differ existing resultsepistemic situation calculus (Scherl & Levesque, 2003), extends situation calculusnotion knowledge realized terms accessibility relation situations.(That is, situations viewed possible worlds.) instance, regression property differentprevious multiagent generalizations (Shapiro, Lesperance, & Levesque, 2002; Kelly & Pearce,2008) epistemic situation calculus background theory may involve nestingknowing operators, Alice knows Bob knows rules game.Capturing multiagent knowing possible-world models include explicit accessibility relations worlds (Fagin et al., 1995), required classical epistemic situation calculus,known problematic (Halpern & Lakemeyer, 2001; Belle & Lakemeyer, 2010a),statements obvious counterparts previous proposals. Similarly, reductionknowledge first-order reasoning investigated restricted setting Reiter (2001),single agent case only.paper structured follows. first introduce logic, followed discussion basicaction theories. Subsequently, prove regression property generalized representationtheorem. end discussing related work. Appendices contain proofs main results,is, regression property representation theorem.3. preliminary version work appears proceedings Twenty-Fourth AAAI Conference ArtificialIntelligence, Atlanta, Georgia, USA, July 11-15, 2010 (Belle & Lakemeyer, 2010b).365fiBelle & Lakemeyer2. Formalismlet ESn first-order modal language consisting formulas symbols followingvocabulary:first-order variables object sort: x1 , x2 , . . . , y1 , y2 , . . .;first-order variables action sort: a1 , a2 , . . .;fluent predicates arity k: F1 , F2 , . . .; example, Wet;rigid predicates arity k: G1 , G2 , . . .; example, Fragile;fluent function symbols arity k: f1 , f2 , . . .; example, distance;rigid function symbols arity k: g1 , g2 , . . .; example, pickup, senseColor;countably infinite standard names: # 1, # 2, . . . objects actions;connectives symbols: =, , , , Ki , Oi , [a], , parenthesis, period comma.following, ease exposition, assume {A, B} Ki Oi , is, twoagents B. extension agents straightforward.remark standard names rigid designators, is, mean entitypossible worlds (see below). thought constants satisfying uniquename assumption infinitary version domain closure. symbols meansquantification understood substitutionally. Readers familiar classical situation calculus (Reiter, 2001) may note situation terms appear language. Therefore,distinguish fluents, whose values change actions, rigids, whose values not,syntactically well semantically. ESn also assumed contain distinguished predicate Possdistinguished functions SFi , take action argument. Essentially, Poss(a)says executable; SFi (a) refers agent sensing outcomes performing a, shownsingle agent case previous section using fragility sensing action. Section 3 discussdetail multiple agents.terms ESn sort action object, least set that:every standard name first-order variable term corresponding sort;t1 , . . . , tk terms (of sort) f k-ary function, f (t1 , . . . , tk ) term.primitive term, mean one form f (n1 , . . . , nk ) f (fluent rigid) functionsymbol ni standard names.well-formed formulas ESn form least set that:t1 , . . . , tk terms, F k-ary predicate symbol F(t1 , . . . , tk ) (atomic)formula;t1 t2 terms, (t1 = t2 ) formula;366fiMultiagent Knowing Dynamic Systemsaction term formula [t] formula;formulas, x first-order variable following also formulas:, , x, , Ki , Oi .usual, treat connectives abbreviations. is, abbreviates , abbreviates ( ) ( ).ESn two epistemic modalities. read Ki knows , read Oiknows . ESn also includes dynamic modalities. read [a] holdsread holds possible action sequences.formula without free variables called sentence. also refer certain kindsformulas following terminology:formula operators called bounded.formula [t] operators called static.formula mention Oi called basic. (The formula may mention KAKB .)formula Ki , Oi , [t], Poss SFi called fluent.4example, P(# 1) [t]KA P(# 2) bounded, static; P(# 1) KA P(# 2) static basic,fluent formula; P(# 1) OA P(# 2) Poss(t) static formula, neither basicformula fluent formula; (P(# 1) P(# 2)) Q( f (# 3)) fluent formula.2.1 Semanticssemantics provided terms possible worlds. purpose semantics determinevalues fluents, initially sequence actions. Therefore, ESn , similaridea situation trees (Reiter, 2001), worlds determine changing values fluentsactions; see Figure 1 intuition. precisely,let Z denote finite sequences action names, including hi, empty sequence(corresponding initial situation);world w W function G Z {0, 1}, G set primitiveatoms, Z N (preserving sorts), set primitive terms,satisfying rigidity constraint: g rigid function predicate symbol, zz0 Z, w[g(n1 , ..., nk ), z] = w[g(n1 , ..., nk ), z0 ].interpret arbitrary terms, proceed follows. mentioned earlier, names rigiddesignators. Given term without variables, world w sequence z, define |t|zw (to readco-referring standard name given w z) by:1. |t|zw = name;4. situation calculus (Reiter, 2001), correspond formulas uniform situation term.367fiBelle & Lakemeyerp, q, . . .a1p, q, . . .aka1p, q, . . .......hia2p, q, . . .ak...aka1......p, q, . . .a1ak......Figure 1: possible world.2. | f (t1 , . . . , tk )|zw = w[ f (n1 , . . . , nk ), z], |ti |zw = ni .Agents may, course, incomplete knowledge. distinguish uncertainty realworld, stipulate epistemic states model multiple possibilities. Standard accounts multiagent epistemic states based Kripke frames (Fagin et al., 1995). multiagent knowing,however, Kripke-based accounts turn problematic, seen work Halpern(1993), Lakemeyer (1993), Halpern Lakemeyer (2001) Waaler Solhaug (2005).example, Lakemeyer (1993) shows certain types epistemic states cannot constructedapproach. work Halpern (1993), epistemic operators interact intuitivemanner (Halpern & Lakemeyer, 2001). work Halpern Lakemeyer (2001), semanticnotion validity defined directly language, making proposal unnatural. Serious complications present later proposals well (Waaler & Solhaug, 2005). Moreover, noneextended quantified language. discussion issues needed purposes article; interested readers referred earlier work (Belle & Lakemeyer, 2010a).work, proposed alternative called k-structures, shown generalizeLevesques (1990) proposal many agent case appropriate intuitive manner.structures deviate Kripke-based accounts defining epistemic states increasing depths.turns out, structures also natural extension dynamic setting, presentbelow. first define notion depth formulas following way:Definition 1 i-depth ESn , denoted ||i , defined inductively (Mi denotes Ki Oi ):||i = 1 atomic formulas;||i = ||i ;368fiMultiagent Knowing Dynamic Systems|x|i = ||i ;|[a]|i = ||i ;||i = ||i ;| |i = max(||i , ||i );|Mi |i = ||i ,|M j |i = || j + 1 j , i.formula depth k max(||A , ||B ) = k.Given formula A-depth k B-depth j, say formula A, B-depth k, jbrevity. say objective epistemic operators mentioned . formula calledi-objective epistemic operators occur within scope another epistemicoperator form j , j , i, Mi denotes Ki Oi . formula called i-subjectiveevery atom scope epistemic operator epistemic operators occurwithin scope another epistemic operator form Mi . Intuitively, i-subjective formulasrepresent beliefs world whereas i-objective formulas determine trueworld perspective, may include beliefs agents i.Example 2 Consider formula KA KB KA p KB [t]q. Here:|KA KB KA p KB [t]q|A = max(|KA KB KA p|A , |KB [t]q|A ) = 31. |KA KB KA p|A = |KA KB KA p|A = |KB KA p|A = 1 + |KA p|B = 2 + |p|A = 3,2. |KB [t]q|A = 1 + |[t]q|B = 1 + |q|B = 2.|KA KB KA p KB [t]q|B = max(|KA KB KA p|B , |KB [t]q|B ) = 41. |KA KB KA p|B = |KA KB KA p|B = 1 + |KB KA p|A = 1 + 3 (as shown above) = 4,2. |KB [t]q|B = |[t]q|B = |q|B = 1.Therefore, depth formula 4. Consider disjuncts. KA KB KA pA-subjective well B-objective. hand, KB [t]q B-subjective wellA-objective. Moreover, KA KB KA p KB [t]q neither A-subjective B-subjective.matter, neither A-objective B-objective.beliefs agent captured means k-structure defined set W:Definition 3 k-structure ek , k 1, defined inductively as:e1 W {{}},ek W Ek1 , Em set m-structures.369fiBelle & Lakemeyeris, e1 simply set worlds. e2 set form {(w, e1 ), (w0 , e0 1 ), . . .} statesw agent, say A, believes B consider worlds e1 possible, w0 believes Bconsider worlds e0 1 possible. captures intuition partial informationB, beliefs B differ different worlds.5 modeling k-structure, say ek ,jdenote ekA . Analogously, modeling j-structure, say e j , B denote eB .structures essentially represents initial beliefs agent, is, initial stateknowledge. actions occur, perhaps agent acquires new information resultpossibilities epistemic state may discarded courseactions (Scherl & Levesque, 2003). Following Lakemeyer Levesque (2011), capturefeature means compatibility relation 'iz worlds (relative agent i), lookstruth real world means sensing. define w0 'iz w inductively following:w0 'ihi w worlds w0 w;w0 'izr w iff w0 'iz w w0 [SFi (r), z] = w[SFi (r), z].jdefine ek A, e j B world w (k, j)-model (ekA , eB , w). ideaformulas maximal A-depth k maximal B-depth j interpreted wrt(k, j)-models. determine whether formula true sequence actions z givenj(k, j)-model, write ekA , eB , w, z |= . definition truth follows:j1. ekA , eB , w, z |= P(t1 , . . . , tk ) iff w[P(n1 , . . . , nk ), z] = 1 |ti |zw = ni ;j2. ekA , eB , w, z |= t1 = t2 iff n1 n2 standard names, |ti |zw = ni ;jj3. ekA , eB , w, z |= iff ekA , eB , w, z 6|= ;jjj4. ekA , eB , w, z |= iff ekA , eB , w, z |= ekA , eB , w, z |= ;jjjj5. ekA , eB , w, z |= x iff ekA , eB , w, z |= nx every name n appropriate sort;6. ekA , eB , w, z |= [t] iff ekA , eB , w, z r |= |t|zw = r;jj7. ekA , eB , w, z |= iff ekA , eB , w, z z0 |= every z0 Z;j8. ekA , eB , w, z |= KA iff w0 'Az w, ek1 (for B),kk k10(w0 , ek1B ) eA eA , eB , w , z |= ;j9. ekA , eB , w, z |= OA iff w0 'Az w, ek1 (for B),kk k10(w0 , ek1B ) eA iff eA , eB , w , z |= .analogous fashion, semantics KB OB specified. Here, Ki classicalepistemic operator. may read Ki (at least) believed Ki certainlypreclude Ki ( ) holding general. hand, Oi holds epistemic5. Levesques (1990) notion epistemic state simply set worlds. easy see singleagent need 1-structures, coincides Levesques account.370fiMultiagent Knowing Dynamic Systemsstate one contains structures satisfying . essence (Levesque, 1990),definition Oi differs Ki using iff rather if.6jjGiven sentence maximal A, B-depth k, j, write ekA , eB , w |= mean ekA , eB , w, hi |= .jsay sentence maximal A, B-depth k, j satisfiable (k, j)-model (ekA , eB , w)jekA , eB , w |= . set sentences maximal A, B-depth k, j above,jwrite |= (read: entails ) iff every (k, j)-model ekA , eB , w |= 0 everyj0 ekA , eB , w |= . write |= (read: valid) mean {} |= .joften write {}, eB , w |= A-objective k-structure irrelevant.Analogously, B-objective formulas, often write ekA , {}, w |= . formula objective, omit structures B altogether simply write w |= .2.2 Propertiesdiffer slightly usual semantical accounts satisfaction relation undefinedformulas whose depth exceeds certain number. Nevertheless, able show farentailment concerned, account present serious limitations. Let us beginsimple examples.Example 4 Let p atom. following sentences valid. method provingexamples look sentence decide depth models. (We useTRUE denote tautologous sentence, x. (x = x).)1. OA TRUE KA KB p.sentence A-subjective A-depth 2. consider 2-structure satisfiesOA TRUE. one: let e2A = W 2W . Clearly e2A , {}, w |= OA TRUE. (We reiterateepistemic state B irrelevant, simply write (ekA , {}, w) ignorestructure B.) easy verify e2 satisfies OA TRUE. e2A , {}, w |=KA KB p iff (w0 , e1B ) e2A e2A , e1B , w0 |= KB p. construction,(w, e1B ) e2A e1B = {(w, {}) | w |= p} e2A , e1B , w |= KB p.2. OA TRUE KA KB p.Construct e2A item 1. e2A , {}, w |= KA KB p iff (w0 , e1B ) e2A ,e2A , e1B , w0 |= KB p. construction, (w, e1B ) e2A e1B = {(w, {}) | w 6|= p} and,e2A , e1B , w |= KB p.3. OA (p OB p) KA p.consider 2-structure satisfying OA (p OB p) prove KA p alsosatisfied structure. let W p = {w | w |= p}. Clearly e1B = {(w, {}) | w W p }1-structure B satisfies OB p. Similarly, 2-structure e2A = {(w, e1B ) | w W p }2-structure satisfies OA (p OB p). follows e2A , {}, w |= KA p sincew0 (w0 , e1B ) e2A satisfy p construction.6. literature, closer examination relationship modalities, third modality denoteagent knows often included logical language (Halpern & Lakemeyer, 2001; Levesque &Lakemeyer, 2001). modality need concern us here. refer interested readers earlier worksemantics given operator using k-structures (Belle & Lakemeyer, 2010a).371fiBelle & Lakemeyer4. OA (p OB p) KA KB p.2-structure e2A constructed item 3. follows e2A , {}, w |= KA KB p sinceworlds{w00 | (w00 , {}) e1B (w0 , e1B ) e2A w0 }satisfy p construction.5. OA (p OB p) (KA KB KA p KA KB KA p).Using ideas item 1 2, follows OB p KB KA p KB KA p valid. Let e3Astructure satisfies OA (p OB p). Since (w0 , e2B ) e3A , e3A , e2B , w0 |= p OB p,follows e3A , e2B , w0 |= KB KA p KB KA p. Therefore e3A , {}, w |= KA (KB KA pKB KA p).Items 1 2 tell us knows TRUE, correctly reasons ignorance:know whether B knows p. Items 3 4 tell us knows {p, OB p},correctly believes B believe p. Finally, item 5 tells us since believes Bknows p, believes B cannot tell whether knows p.examples, (appropriately) chose structures certain depth interpret sentences corresponding depth. However, far validity goes, models higher depthconsidered. is, formula maximal A, B-depth k, j true (k, j)-models,formula also true (k0 , j0 )-models, k0 k j0 j. demonstrate property,00construct every ekA , k-structure eA kk , agree formulas maximal A-depthk. Analogously, j-structure agrees formulas maximal B-depth j constructedj0every eB .j00j00Definition 5 Given ekA eB , inductively define k-structure eA kk j-structure eB jk0 k 1 j0 j 1, respectively:eA 11 = e1A ;eB 11 = e1B ;000eA k1 = {(w, {}) | (w, ekB 1 ) ekA } k0 > 1;j0j0 1j0eB 1 = {(w, {}) | (w, eA ) eB } j0 > 1;00001eA kk = {(w, eB kk1) | (w, ekB 1 ) ekA } k > 1;j0j0 1j0 1j0eB j = {(w, eA j1 ) | (w, eA ) eB } j > 1.0definition hand, get following property relating k0 -structures ekA j0 0j0j0structures eB , corresponding k-structures eA kk j-structures eB j respectively.Lemma 6 Let k0 k j0 j. maximum A-depth k maximum B-depth j:0j00j0ekA , eB , w |= iff eA kk , eB j , w |= .372fiMultiagent Knowing Dynamic Systemsproof hard, tedious. arguments result appear elsewhere (Belle & Lakemeyer, 2010a), reproduce here.7Theorem 7 formulas A, B-depth k, j, true (k, j)-models, true(k0 , j0 )-models, k0 k j0 j.0j00j0Proof: Suppose true (k, j)-models. Given (ekA , eB , w), assumption eA kk , eB j , w |=0j0. previous lemma, ekA , eB , w |= .follows one may speak valid sentences logic without explicitly speculating depths depths models need be. is, may simply assumemodels appropriate depths, sense depths equal exceed depthsentences. example, obtain following result knowledge k-structuresK45n properties (Fagin et al., 1995), well universal existential versions Barcanformula. Moreover, properties hold number actions performed.Lemma 8 Let ESn -formulas. following sentences valid:1. (Ki Ki ( ) Ki );2. (Ki Ki Ki );3. (Ki Ki Ki );4. (xKi Ki x);5. (xKi Ki x).Proof: proofs similar. show item 3 4. Let A. case symmetric.jk3. Suppose ekA , eB , w, z |= KA . w0 'zA w, (w0 , ek1B ) eAk1kk1000000000eA , eB , w , z |= . Let w world w 'z w , (w , eB ) ekA . ClearlyjekA , e0B k1 , w00 , z |= KA . Since w00 'zA w, get ekA , eB , w, z |= KA KA .jj4. Suppose ekA , eB , w, z |= xKA . ekA , eB , w, z |= (KA )nx every name n. is,jkekA , eB , w, z |= KA nx every n. w0 'zA w, (w0 , ek1B ) eAj0xk k10kekA , ek1B , w , z |= n every n iff definition eA , eB , w , z |= x. Therefore eA , eB , w, z |=KA x.Apart K45n belief properties, relationship knowing knowledgealso established using notion validity:Lemma 9 Suppose p q atoms, ESn -formula. following valid:7. actions considered work, interpreted wrt worlds extension argumentstraightforward.373fiBelle & Lakemeyer1. Oi Ki ;2. Oi p Ki q.Proof: Item 1 easy consequence semantics. item 2, observe definitionknowing, structures satisfy p q, must exist p q atoms,included epistemic state Oi p holds. Therefore q cannot known.Item 1 says whatever known also believed agent. Item 2, course, relatesknowing non-beliefs. straightforward generalize arguments propertiesalso capture valid sentences Example 4 involving multiagent nested beliefs.Finally, specifying agent, want allow agents false beliefs.permitted, demonstrated means following property showspossible know (and know) formula false real world, also possibleknow (and know) formula true real world.Lemma 10 Let p atom. following sentences satisfiable (let Mi denote Ki Oi ):1. p Mi p;2. p Mi p.Proof: show Mi = OA . case Mi = OB symmetric. arguments Mi = Kianalogous. item 1, let w world w |= p, W p = {w0 | w0 |= p}. Let e1Aset {(w0 , {}) | w0 W p }. follows e1A , {}, w |= p OA p.item 2, suppose w |= p, W0p = W p {w }. Let e1A = {(w0 , {}) | w0 W0p }. Then,get e1A , {}, w |= p OA p.concluding section, let us briefly reflect fact k-structures finitedepth. suppose knows , depth k. Using k-structures alone allows us reasonbelieved believed, depth k. example, OA P(# 1) entailsKA P(# 1), KA P(# 2), KA P(# 3), . . . shown Lemma 9. Moreover, already observed Example 4, logic correctly captures ignorant beliefs depth greater k. is,using simple example agent knows TRUE depth 1, saw sentencesOA TRUE KA KB p OA TRUE KA KB p valid. So, although KB finitedepth, able ask queries depth sense determining whether sentenceOi Ki valid.purposes, restriction parameter k seems harmless senseagents usually finite knowledge base sentences maximal depth kignorant known depths higher k. one aspect cannothandle: property simultaneously satisfying infinite set sentences unbounded depth.Indeed, k-structures cannot used purpose simply because, fixed k, satisfactionrelation undefined formulas beyond depth k.One prominent application property notion common knowledge (Fagin et al.,1995). go details here, common knowledge modality allows logic374fiMultiagent Knowing Dynamic Systemsreason sentences (Ki K j )k , appears scope k sequences Ki K j ,k. Even though nature common knowledge infinitary, sense essentiallycorresponds infinite conjunction, nonetheless given finite axiomatic characterization, making useful operator certain applications (Fagin et al., 1995). Thus,include notion common knowledge logic, would get entailmentsbelieved arbitrary depths. current model, however, cannot captured.certainly restriction, willing pay price return get, first time,simple model theory multiagent knowing (Belle & Lakemeyer, 2010a).3. Basic Action TheoriesLet us consider equivalent basic action theories situation calculus. Since situationsappear language, ES, basic action theories require foundational axiomslike Reiters second-order induction axiom situations (Reiter, 2001).Definition 11 Given set fluents F , set ESn sentences called basic action theory(BAT) F iff = 0 pre post sense mentions fluents F and81. 0 set fluent sentences;2. pre singleton sentence form:Poss(a)fluent formula;93. post set includes sentences form:[a]F(~x) F ,one fluent predicate F, sentences form:[a] f (~x) = u f ,one fluent function f , F f fluent formulas;104. sense set sentences similar one Poss form:SFi (a) = x ,one agent i, fluent formula.8. follow usual convention free variables universally quantified outside.9. assume lower syntactic precedence logical connectives, Poss(a) standsa.(Poss(a) ).10. [a] construct higher precedence logical connectives. is, [a] f (x1 , . . . , xk ) = f abbreviatesa.([a] f (x1 , . . . , xk ) = f ).375fiBelle & Lakemeyeridea 0 expresses true initially, pre one large precondition axiom, postsuccessor state axioms, one per fluent, formulated incorporate Reiters solutionframe problem. sense accommodates intuition sensing results agents may differvarious actions. example, B senses reading letter, would expect Blearn contents letter. Here, follow convention (Scherl & Levesque, 2003)every action returns sensing result. actions forward, return sensinginformation, SFi defined return special standard name NIL.Knowledge initial situation may incomplete. precisely, distinguishtrue real world agents know believe world.course, believes world may differ Bs knowledge. Moreover, believesB know may differ B actually believes. One way capture generalityfirst insist action theory modeling real world, say . Then, might imagine differingbasic action theories subsequent levels beliefs agents, illustrated followingtheory:11(1)OA ( OB ( . . .)) OB ( 0 OA ( . . .))(with superscripts) basic action theories may differ arbitrarily. Here,represents true real world, (with superscripts) represent agents beliefs.example, represents believes B know. extension, then, n agents k levels,would expect n k + 1 action theories, one perhaps differing arbitrarily other.ease exposition, consider following simple case remainder article.simple case stipulates represents view world, believes alsorepresents Bs view world. reasonable applications simple card games,consider below. None technical results, including regression propertyrepresentation theorem, hinge stipulation, however. See Section 4.4 discussions.background theory, then, special case (1), illustrated following sentence:OA ( OB ( . . .)) OB ( 0 OA ( 0 . . .))(2)where, again, , 0 may differ arbitrarily.Formally, order prepare agents may beliefs arbitrary (but finite) depth,introduce following inductive definition basic action theory :let OKnow [A, 1] = OA ;let OKnow [B, 1] = OB ;k > 1, let OKnow [A, k] = OA ( OKnow [B, k 1]);j > 1, let OKnow [B, j] = OB ( OKnow [A, j 1]).Given basic action theories , 0 , remainder article interestedtheories formOKnow [A, k] OKnow 0 [B, j](3)11. sequel, background theory stipulations assume nesting knowing operators. possibilities, course, Oi ( (K j K j )). defer discussions Section 4.4.376fiMultiagent Knowing Dynamic Systemssays believes action theory k levels, i.e. believes B also believeon, B believes action theory 0 j levels. presenting technical resultsreasoning actions, show example formalism used modeldomains, appropriate properties regarding knowledge, introspection sensing.Example 12 Imagine two agents playing simple card game. imagine deck cards, numbered 1 52. Two face-down cards dealt, one B. Playerpicks card, reads card decides challenge player j ( j , i). challenge posed,player card highest number wins game.begin stipulating preconditions domain. Let pre following:Poss(a)x[a = picki (x) y(Holdingi (y))]x[a = seei (x) Holdingi (x)]= challengei TRUE.English: sensing actions seei explained below, sense assume holdingobject. let picki physical action, require object x picked up,holding anything else. fluent-changing action domain challengei , posttwo elements:[a]Holdingi (x) = picki (x) Holdingi (x).[a]Losei Losei= challengei (num(cardi ) < num(card j ))= challenge j (num(card j ) > num(cardi )).cardi card dealt i, num rigid function representing cardsnumber, Losei indicates lost game. is, challenges, would winhigher number.Let us formalize sensing axioms. reads card, expect discovernumber card. Actions public, despite fact B observes reading card, Bexpected discover contents card. asymmetry captured letting sensecontain following sentence:[a]SFi (a) =x[a = seei (x) = num(x)]x[a = seei (x) = NIL].English: sensing results action seei (x) informs number card x,sensing results every action returns NIL. is, NIL obtained sensesphysical actions, well observes j reading card means see j .Finally, stipulate initial theories, done. let 0 following:x[Holdingi (x)];num(cardA ) , num(cardB );377fiBelle & Lakemeyerx[num(x) = # 1 . . . num(x) = # 52];# 1 < # 2 < # 3 < . . . < # 51 < # 52;LoseA LoseB .Here, supposing cardA card dealt, cardB one Bdealt. Basically, 0 says numbers cardA cardB different one{1, . . . , 52} initially, player lost game.0 represents initial assumptions game. general, players may access additional information. unfair setting, instance, might imagine B knows carddoes. current purposes, however, simply assume 0 believes, wellbelieves j believe, levels. model real world, let0 = 0 {num(cardA ) = # 1, num(cardB ) = # 52}.Letting = 0 pre post sense , letting = 0 , development leads theoryfollowing form:OKnow [A, k] OKnow [B, j](4)Prior analyzing entailments (4), convenient state lemma regarding model(4) constructed. that, use notion modal depth formula,refers epistemic modalities formula.Definition 13 modal depth formula defined inductively:modal() = 0 atomic formulas;modal( ) = max(modal(), modal());modal(x) = modal();modal([t]) = modal();modal() = modal();modal() = modal();modal(Mi ) = 1 + modal() Mi {Ki , Oi }.example, p [t]q, p q atoms, formula mentioning epistemic operatorsmodal depth 0. KA KB p, contrast, modal depth 2. Essentially, modaldepth simply counts epistemic modalities formula completely ignores indicesmodalities. surprisingly, differs i-depth formulas. example, modaldepth KA p 1, |KA p|A 1, |KA p|B 2. contrast, modal depth KA KA p 2,A-depth 1 B-depth 2, case KA p.Suppose objective sentence, possibly basic action theory. Let us denote setworlds {w | w |= } W . Further, let e1 = W {{}}. Let ek = {(w, ek1) | w W } definedinductively. Then,378fiMultiagent Knowing Dynamic SystemsjLemma 14 Suppose objective sentence. Suppose w world e kA e Bjconstructed above. e kA , e B , w |= OKnow [A, k] OKnow [B, j].Proof: proof induction modal depth background theory, Definition13 provides. First note modal depth background theory l,sentence form OKnow [A, k] OKnow [B, j] k l, j l k j l.Since OKnow [i, k] interpreted wrt epistemic state, treat A-subjective Bsubjective formulas background theory individually. base case theories modaldepth 1, considering sentence form Oi . prove base case, considerworld w0 . Clearly w0 'hi w definition. construction, (w0 , {}) e 1A iff w0 |= . Thereforee 1A , {}, w |= OA . Analogously e 1B .Suppose lemma holds background theories modal depth k 1, is, e k1)k-structuresatisfies OKnow [A, k 1]. analogously stated B. Let (w0 , e k1B0 |= OKnow [B, k 1]. is,e kA . construction w0 |= . induction hypothesis, {}, e k1,wBkk10kconstruction, (w0 , e k1B ) e iff {}, e B , w |= OKnow [B, k 1]. Therefore e , {}, w |=kOA ( OKnow [B, k 1]), is, e , {}, w |= OKnow [A, k].Using lemma, consider properties (4):Proposition 15 following sentences entailed sentence (4), k > 1 j > 1.1. KA (num(cardA ) = # 1).Initially, know details card. (That is, non-beliefs obtained viaknowing.)2. [pickA (cardA )][seeA (cardA )]KA (num(cardA ) = # 1).sensing, knows lowest number.3. [pickA (cardA )][seeA (cardA )]KB xKA (num(cardA ) = x).B observes reading card, B knows knows cardA holds him.is, B de dicto knowledge knowledge.4. [pickA (cardA )][seeA (cardA )]xKB (num(cardA ) = x).case B knows card observes sensing. is, Bde knowledge card.5. [pickA (cardA )][seeA (cardA )]KA xKB (num(cardA ) = x).Moreover, knows B know card.6. [pickA (cardA )][seeA (cardA )][pickB (cardB )][seeB (cardB )]Ki ([challengeB ]LoseA ){A, B}.sensing, B believe would lose game challenged B.379fiBelle & Lakemeyer3,13,22,32,11,31,23,13,22,32,11,31,23,13,22,32,11,31,2X X X XFigure 2: depicts compatibility worlds actions, shown wrt 3-card deck simplicitys sake. Here, worlds characterized terms numbers cards,therefore, simply labeled (n, m), n denotes number carddenotes number Bs card world. first line represents uncertainty initially, second senses # 1, case worldscard discarded. third represents Bs belief epistemic stateobserves sensing card. is, know card has,know considers two worlds possible, grouped shown, without knowinggroup represents truth.jjProof: Let = (ekA , eB , w) model (4). easy see ekA eB wouldLemma 14, w world satisfying (4). Below, let r denote pickA (cardA ) letr0 denote seeA (cardA ).j1. Assume contrary. Suppose ekA , eB , w |= KA (num(cardA ) = # 1). (w0 , ek1B )#kkk10eA , get eA , eB , w |= (num(cardA ) = 1).Now, observe 0 says value num(cardA ) {1, . . . , 52}. Thus, construction (and definition W), worlds w W (say) w |= (num(cardA ) =#kk12), w 'Ahi w, (w , ek1B ) eA eB . contradiction.2. executes r r0 , follows worlds w0 W w0 [SFA (r0 ), r]= w[SFA (r0 ), r] = # 1 considered evaluating A-subjective formulas. (Thesejworlds agree number card real world.) Therefore ekA , eB , w, r r0 |=k0k k100KA (num(cardA ) = # 1) since every (w0 , ek1B ) eA w 'rr0 w, eA , eB , w , r r |=#(num(cardA ) = 1) definition semantics sensing axioms sense .380fiMultiagent Knowing Dynamic Systemsj1jB w iff w [SF (r 0 ), r] = w[SF (r 0 ), r]. Since3. Consider (w , eA ) eB . get w 'rr0BB0SFB (r) = SFB (r ) = NIL worlds satisfying , item 3 hold must followjj1 jj1 jj1every (w0 , eA ) eB , eA , eB , w0 , r r0 |= xKA (num(cardA ) = x), eA , eB , w0 , rr0 |= KA (num(cardA ) = n) n. Using arguments item 2, easily shownj1 j0case. is, eA , eB , w0 |= KA (num(cardA ) = n) iff every w00 'rr0 w ,j2j1j1 j2000000(w , eB ) eA , eA , eB , w |= (num(cardA ) = n). holds w 'rr0 w0hold w00 , r r0 |= (num(cardA ) = n).j1intuitive argument follows. Suppose B considered j-structures (w, eA ) possible, w real world. would able infer cardA number. sincej1j1epistemic state {(w0 , eA ), (w00 , eA ), . . .} believes worlds w0 knowsnumber well is, know real world.effect, structures inform B card # 1, othersinform card different number, leaving uncertain. case 3-carddeck, Figure 2 illustrates development.4. follows arguments previous item. Basically, every w0 W ,j1w0 [SFB (r), r] = NIL = w[SFB (r), r]. evaluating B-subjective formulas every (w0 , eA )jjeB considered, including ones (say) w0 , rr0 |= (num(cardA ) = # 2). Thus ekA , eB , w, r 6|=#KB (num(cardA ) = 1).k05. Consider (w0 , ek1B ) eA w 'rr0 w. arguments item 4, follows00ekA , ek1B , w , r r 6|= xKB (num(cardA ) = x).jTherefore, ekA , eB , w, r r0 |= KA xKB (num(cardA ) = x).6. property follows logical deduction. sensing, players knowcards. lowest number, B highest. Since agents knownumbers unique, numbers one {1, . . . , 52}, infer would losechallenged.4. Regressionfundamental reasoning task dynamic domains projection (Reiter, 2001),infer whether holds sequence actions a1 , . . . , ak executed:|= [a1 ] . . . [ak ].Reiter (2001) developed important solution projection problem situation calculuscalled regression. idea reduce query future query 0 initialsituation successively replacing fluents rhs successor state axiomsresulting sentence 0 contains actions. need verify whether 0 entailedinitial theory.context multiagent systems, might, example, interested reasoningentailments background theory (3) stipulates beliefs agents application domain:(3) |= [a1 ] . . . [ak ]381fiBelle & Lakemeyerperhaps mentions belief operators.Reiters (2001) results extended Scherl Levesque (2003) handle knowledgesituation calculus, shown carry ES (Lakemeyer & Levesque, 2011).section, generalize results background theories form (3) involving multiagentknowing operators. first recap regression objective formulas ES.4.1 Regressing Objective FormulasWithout loss generality, assume query syntactically reformulated follows:1. quantifiers use distinct variables, say formulas rectified;2. formulas certain normal form called NF (defined below).applying transformations, query becomes amenable regression. first syntacticmanipulation required way regression handles quantifiers, lead incorrect transformations variables distinct. second required giving simpleformulation regression.Definition 16 formula NF every function symbol f occurs equality expressions form f (t1 , . . . , tk ) = t0 , ti t0 either variables names.immediate verify every formula rewritten one NF, transformationlinear size formula. instance, f (g(x)) = f 0 (x) equivalent y, u. f (y) =u f 0 (x) = u g(x) = y. Further, definition, term appears either argumentfunction action operator [t], follows either (action) name variable.following use denote sequences consist action variables action names.Lakemeyer Levesque (2011) define regression operator R, applicablebounded objective formula.12 formula rectified NF, transformedformula satisfying conditions.Definition 17 Define R[], regression bounded basic formula wrt , fluentformula R[hi, ]. sequence action names variables , R[, ] defined inductively:1. R[, t1 = t2 ] = (t1 = t2 ) t1 t2 mention functional fluents;2. R[, x] = xR[, ];3. R[, ] = R[, ] R[, ];4. R[, ] = R[, ];5. R[, [t]] = R[ t, ];6. R[, Poss(t)] = R[, ];12. Roughly speaking, correspond class formulas Reiter (2001) deems regressable situationcalculus.382fiMultiagent Knowing Dynamic Systems7. R[, G(t1 , . . . , tk )] = G(t1 , . . . , Gk ) rigid predicate G;8. R[, F(t1 , . . . , tk )] fluent predicate F defined inductively :(a) R[hi, F(t1 , . . . , tk )] = F(t1 , . . . , tk );(b) R[ t, F(t1 , . . . , tk )] = R[, F ta tx1 1......tkxk ];9. R[, f (t1 , . . . , tk ) = t0 ] fluent function f defined inductively by:(a) R[hi, f (t1 , . . . , tk ) = t0 ] = ( f (t1 , . . . , tk ) = t0 );(b) R[ t, f (t1 , . . . , tk ) = t0 ] = R[, y. ( f )at tx11 ...... txk k = t0 ].Note definition includes , F f rhs precondition axiomsuccessor state axioms .main result regarding Definition 17 evaluation objective bounded sentencesreduces query initial theory.Theorem 18 (Lakemeyer & Levesque, 2011) Let basic action theory, whose initial theory0 , let objective bounded sentence. R[] fluent sentence satisfies:|= iff 0 |= R[].4.2 Regressing Multiagent BeliefsLet us consider general case regression bounded sentences mentioning beliefoperators. first needs equivalent successor state axiom knowledge, tellus knowledge regressed wrt action. following theorem generalizes similarresult Lakemeyer Levesque (2004) many agent case.Theorem 19 (Successor State Axiom Knowledge.)|= [a]Ki ()x. SFi (a) = x Ki (SFi (a) = x [a]).Proof: Let A, case symmetric. only-if direction, supposejjekA , eB , w, z |= [r]KA ar action name r. Abbreviate ar 0 . Suppose ekA , eB , w, z |=jSFA (r) = n. suffices show ekA , eB , w, z |= KA (SFA (r) = n [r]0 ).k00suppose (w0 , ek1B ) eA w [SFA (r), z] = n. Since w 'zr w, follows assumption00k k100k k100ekA , ek1B , w , z r |= , i.e. eA , eB , w , z |= [r] . Thus eA , eB , w , z |= SFA (r) = n [r] ,jfollows ekA , eB , w0 , z |= KA (SFA (r) = n [r]0 ).jConversely, suppose ekA , eB , w, z |= SFA (r) = n KA (SFA (r) = n [r]0 ). needjk0k k100show ekA , eB , w, z |= [r]KA (0 ), i.e. (w0 , ek1B ) eA w 'z w, eA , eB , w , zr |= .kk1Suppose w0 'Azr w, i.e. w0 [SFA (r), z] = n (w0 , ek1B ) eA eB . assumption,j00k k10k0ekA , ek1B , w , z r |= . eA , eB , w , z |= [r], get eA , eB , w, z |= KA ([r] ).383fiBelle & Lakemeyertheorem essentially says knowledge action depends known before,future would look like contingent sensing result. Note theoremstipulation action theory (Scherl & Levesque, 2003), theorem logic.mentioned earlier case (3), need three basic action theories , 0 .idea behind regression transform objective formulas wrt , subjective ones regressedwrt 0 . Consequently, R defined wrt , 0 . precisely, define regressionoperator R[, , 0 , , ] wrt basic action theory true real world, basicaction theory believes levels, basic action theory 0 B believeslevels, expected (3).Definition 20 define R[, , 0 , ], regression bounded basic formula wrt ,0 , R[, , 0 , hi, ]. given sequence action names variables , defineR[, , 0 , , ] inductively by:1.-9. See Definition 17. (Note definition uses rhs precondition axiomsuccessor state axioms .)10. R[, , 0 , , SFA (t) = t0 ] = R[, , 0 , , tx0 ] uses rhs sensing axioms;11. R[, , 0 , , SFB (t) = t0 ] = R[, , 0 , , B tx0 ] uses rhs sensing axioms0 ;12. R[, , 0 , , KA ] defined inductively by:(a) R[, , 0 , hi, KA ] = KA (R[, , , hi, ]);(b) R[, , 0 , t, KA ] = R[, , 0 , , ], rhs equivalence Theorem19 agent index A.13. R[, , 0 , , KB ] defined inductively by:(a) R[, , 0 , hi, KB ] = KB (R[ 0 , 0 , 0 , hi, ]);(b) R[, , 0 , t, KB ] = R[, , 0 , , ], rhs equivalence Theorem19 agent index B.regression operator multiagent case works follows. initial situation, regressingKA equivalent regressing wrt basic action theory believes levels. Similarly, initial situation, regressing KB equivalent regressing wrt basic action theory0 B believes levels. generally, regressing Ki wrt action sequencet, equivalent regressing rhs Theorem 19 wrt first substituting t.simplicity, often write R[, ] instead R[, , 0 , , ]. ready provemain result section bounded basic sentences:1313. Roughly speaking, correspond class regressable formulas epistemic situation calculus (Scherl& Levesque, 2003).384fiMultiagent Knowing Dynamic SystemsTheorem 21 Suppose bounded basic sentence maximal A, B-depth k, j. Let , 0basic action theories. R[hi, ] static sentence satisfies:|= iff 0 0 |= R[hi, ]= OKnow [A, k] OKnow 0 [B, j]0 = OKnow0 [A, k] OKnow0 0 [B, j].is, solve projection task verifying whether entailed regressingverifying entailment conjunction true initially agentknowing initial beliefs. proof theorem provided Appendix A.Readers noticed theorem assumes background theory beliefslevel k B beliefs level j, given query whose maximal A, B-depth k, j. syntacticrestriction essential relatively simple regression operator well-defined. see that,suppose interested verifying whether KA KB [r] entailed OA (), basicaction theory. definition regression operator given above, evaluating query reducesregressing [r] wrt , correct transformation beliefsBs knowledge world. fact, formula KA KB [r] seem amenableregression wrt OA () since simply clear one regress subformula KB [r].note formula KA KB [r] depth 2 transformation indeed correctwrt initial knowledge least depth 2, OA ( OB ).Readers also notice restricting regression operator bounded basic sentences. least two reasons limitation. First, note language expressive enough refer knowing non-initial situations; agent knows basic actiontheory, one presumes action agent knows another basic action theory. Regressing latter intuitively lead sentence talks knownaction executed, currently cannot expressed language. Second, notebasic action theory contains sentences successor state axioms bounded.So, action left formula form Oi (), argumentwould contain sentences bounded, would regressable.Theorem 18 limited regressing bounded formulas. Nevertheless, regression operator coversclass formulas considered Scherl Levesque (2003), sufficientpractical purposes.Example 22 illustrate regression using card game. Suppose interested checkingwhether (4) Section 3 entails following sentence:[pickA (cardA )][seeA (cardA )](KA (num(cardA ) = # 1) KB (num(cardA ) = # 1)).(5)is, picks card senses, knows card B learn this.Use r pickA (cardA ), r0 seeA (cardA ) (num(cardA ) = # 1). BeginR[, , , r r0 , KA KB ]= R[, , , r r0 , KA ] R[, , , r r0 , KB ]385fiBelle & LakemeyerConsider [r][r0 ]KA . have:R[, , , r r0 , KA ]= R[, , , r, x(SFA (r0 ) = x KA (SFA (r0 ) = x [r0 ]))]= x. R[, , , r, SFA (r0 ) = x] R[, , , r, KA (SFA (r0 ) = x [r0 ])]= x. R[, , , r, num(cardA ) = x]R[, , , hi, y. SFA (r) = KA (SFA (r) = [r])]= x. num(cardA ) = x y. = NIL KA (R[, , , hi, SFA (r) = [r]])= x. num(cardA ) = x y. = NILKA (y = NIL (num(cardA ) = x num(cardA ) = # 1))Here, denotes (SFA (r0 ) = x [r0 ]).reductions mostly involve repeated applications knowledge successor state axiom,logical connectives. Then, step 4, regressing knowledge wrt hi, replace basicaction theories R operator one believes, expected Rule 12(a) Definition20. Regarding Rs result, since 0 contains num(cardA ) = # 1, hard see0 OKnow0 [A, k] OKnow0 [B, j] |= R[, , , r r0 , KA ].Simplifying R[, , , r r0 , KB ] analogous, dissimilarity arising regressing Bsbeliefs wrt r0 , obtains sensing result NIL:R[, , , r r0 , KB ]= R[, , , r r0 , KB ]= [x. x = NIL y. = NIL KB (y = NIL (x = NIL num(cardA ) = # 1))].One may verify0 OKnow0 [A, k] OKnow0 [B, j] |= R[, , , r r0 , KB ].Therefore,0 OKnow0 [A, k] OKnow0 [B, j] |= R[, , , r r0 , KA KB ].means Theorem 21, allows us conclude query (5) indeed entailed (4).Example 23 regress nested beliefs example. Suppose interested checkingwhether (4) Section 3 entails following sentence:[pickA (cardA )][seeA (cardA )]KA KB (num(cardA ) = # 1).386(6)fiMultiagent Knowing Dynamic Systemsdone above, let r denote pickA (cardA ), r0 denote seeA (cardA ), denote num(cardA ) =1. Then:#R[, , , r r0 , KA KB ]= R[, , , r, x(SFA (r0 ) = x KA (SFA (r0 ) = x [r0 ]KB ))]= x. R[, , , r, num(cardA ) = x] R[, , , r, KA (x = num(cardA ) [r0 ]KB )]= x. num(cardA ) = xR[, , , hi, y(SFA (r) = KA (SFA (r) = [r]))]= x. num(cardA ) = x y. = NIL KA (R[, , , hi, = NIL [r]]).Here, denotes (num(cardA ) = x [r0 ]KB ).reduction leads to:x. num(cardA ) = x y. = NIL KA (y = NIL R[, , , hi, [r]]).(7)Let us consider R[, , , hi, [r]]. (on simplification):R[, , , hi, [r]]= (num(cardA ) = x) R[, , , hi, [r][r0 ]KB ].Following reduction R[, , , hi, [r][r0 ]KB ] done previous example,shown0 OKnow0 [A, k] OKnow0 [B, j] |= (7).Using regression property, is, Theorem 21, conclude (6) entailed (4). Therefore, done. (We reiterate knowledge Bs non-beliefs beliefsB knows.)Analogously, entailments Proposition 15 verified using regression.regression allows us reduce questions knowledge action queriesinitial beliefs, next section go even replace reasoning knowledgeclassical first-order reasoning.4.3 Representation Theoremrepresentation theorem result means reasoning knowledge reducedfirst-order theorem proving. presentation generalizes single agent variant (Lakemeyer& Levesque, 2004).basic idea substitute believed sentences instances. example, supposebelieves sentence := {Smaller(n2 , n1 ), Smaller(n3 , n1 ) Smaller(n4 , n1 )}.is, blocks world domain: n2 smaller n1 , n3 smaller n1 n4 smallern1 . Supposing ask:Ki x. (Smaller(x, n1 ) Ki Smaller(x, n1 ))387(8)fiBelle & Lakemeyeris, know block smaller n1 , know one? answercertainly yes list smaller blocks known incomplete, except n2 . essentialstep replace Ki Smaller(x, n1 ) x = n2 . Then, shown query reducesverifying x. (Smaller(x, n1 ) x , n2 ) entailed .make intuition precise, first define procedure Res[, ], introduced originallyLevesque (1990), obtain known instances entailed ,fluent formulas. mention free variables, Res checks whether entailssentence .Definition 24 Let fluent formula, fluent sentence. Let n1 , . . . , nk namesoccurring n0 name occurring . Then, Res[, ] defined as:1. free variables, Res[, ] TRUE |= FALSE otherwise.2. x free variable , Res[, ] defined as:((x = n1 ) Res[nx1 , ])...((x = nk ) Res[nxk , ])0((x , n1 ) . . . (x , nk ) Res[nx0 , ]nx ).instance, Smaller(x, n1 ) above, Res[, ] would simplify to:(x = n2 ) Res[nx2 , ]where, further, Res[nx2 , ] TRUE |= Smaller(n2 , n1 ).Given formula Ki known i, idea reason knowledgeutilizing Res. course, discussed earlier, multiagent case accountknowledge bases different levels, is, addressing background theories form (3).proceed follows. Let 0 denote initial theories (fluent sentences) believedB levels respectively. Then, given bounded basic sentence, first use regressionobtain static basic sentence. static basic , define kk,0 follows:Definition 25 Let 0 fluent sentences, static basic sentences.define fluent sentence kk,0 by:1. kk,0 = objective;2. kk,0 = kk,0 ;3. k k,0 = kk,0 kk,0 ;4. kxk,0 = xkk,0 ;5. kKA k,0 = Res[kk, , ];6. kKB k,0 = Res[kk0 ,0 , 0 ].388fiMultiagent Knowing Dynamic SystemsIntuitively, given objective KB believes levels objective KB 0 Bbelieves levels, conceptually simple reduction operator obtained. reader maynotice similarity regression operator, viz. whenever KA encountered reduction continued wrt KB . Analogously, reduction continued wrt 0 whenever KBencountered.present main result section, relating R k k,0 :Theorem 26 Let , 0 basic action theories. Suppose basic bounded sentencemaximal A, B-depth k, j,|= iff|= 0 kR[hi, ]k0 ,0 0 .= OKnow [A, k] OKnow 0 [B, j].is, query perhaps action operators entailed background theory iff regressedquery reduced representation theorem wrt 0 0 0 entailed set sentencestrue initially. Thus, modal reasoning necessary. proof theorem appearsAppendix B.Example 27 Let us consider projection query Example 22. Consider, example,question whether (4) Section 3 entails:[pickA (cardA )][seeA (cardA )]KA (num(cardA ) = # 1).(9)means Theorem 26, get |= (4) (9) iff|= {num(cardA ) = # 1, num(cardB ) = # 52, 0 } kR[, , , hi, (9)]k0 ,0(10)(10) true, first consider R[, , , hi, (9)] simplifiesx. x = num(cardA ) y. = NIL KA(11)= NIL (num(cardA ) = x num(cardA ) = # 1).Next, observe k(11)k0 ,0 yieldsx. x = num(cardA ) y. = NIL Res[kk0 ,0 , 0 ].(12)note Res[kk0 ,0 , 0 ] reducesx = # 1 = NIL.(13)reduction follows. Res[kk0 ,0 , 0 ] = Res[, 0 ] objective. Now, Res[, 0 ]2 free variables: x y. definition Res, possible substitutions n chosenxyx respectively names 0 {}, check whether Res[n , 0 ] true.389fiBelle & Lakemeyercase substitutions # 1 NIL x respectively. Therefore, Res[, 0 ] yields(13). Replacing (13) (12), get:x[x = num(cardA ) y[y = NIL (x = # 1 = NIL)]].(14)Thus, (10), ask true following first-order formula valid:{num(cardA ) = # 1, num(cardB ) = # 52, 0 } (14).answer clearly yes, therefore, |= (4) (9).standard first-order theorem proving employed reasoning multiagent systemsESn . caveat, however. Unlike standard theorem proving, set basic bounded formulas follow basic action theory applying representation theorem recursivelyenumerable (Rogers Jr., 1987). precisely, item 1 Ress definition, note appealvalidity, returning TRUE, appeal falsifiability, returning FALSE (Levesque &Lakemeyer, 2001).4.4 Discussionswrapping section, let us reflect limitations regression propertyrepresentation theorem. Clearly, represent special case, one form (say, theoriesdepth 2):OA ( OB ) OB ( OA )agent knows , also believes agents hold beliefs. hardgeneralize results cases form:OA ( OB 0 ) OB ( OA 0 )where, , 0 , 0 may differ arbitrarily. idea, surprisingly, relate depthformula sentence believed agent corresponding depth. example, patom, one would evaluate [r]KA p wrt [r]KB p wrt . next level, given formula[r]KA ([r0 ]KB p), would evaluate [r0 ]KB p wrt 0 , given resultant formula , wouldevaluate [r]KA wrt . precisely, regression operator representation theoremdefined terms sentences true real world, well ones believed: , 0 ,0 . (That is, instead three theories wrt R defined knowledge bases arbitrarydepths, Section 4, would 5 theories knowledge bases depth 2.) Usingtechniques presented here, hard show that, yet again, would obtain propertyanalogous Theorem 26, modal reasoning necessary. allow beliefsdiffer arbitrarily actions, think expecting initial specification makes assumptionsagents know reasonable. (Note also 0 first-order theory,is, complete knowledge assumption made anywhere else paper.) Therefore,general setting would cover broad range application domains. return, slightlyinvolved definition R k k needed.However, may domains make case still kinds initial states,OA ( (KB KB 0 )) KB ( KA ())390fiMultiagent Knowing Dynamic Systemsone knows B knows B knows 0 . also example modelergiven full characterization Bs knowledge base. Appealing underlying semanticsreason properties knowledge examples well-defined, course, sincesimply checking validity well-formed formulas logic. far effectivenessreasoning concerned, note significantly, regression basic bounded formulaslimited nature initial theory. aspect problem.little say reduction knowledge operators cases. Indeed, versionTheorem 21 provable, regression, one would replace basic action theoriesinitial components only, Theorem 26 need hold. Thus, cases, modal reasoningperhaps necessary.5. Related Workarticle focused knowing knowledge multiagent dynamic setting. particular,modal dialect ES situation calculus, along associated reduction theorems,generalized many agent case.underlying language situation calculus received lot attention actioncommunity. are, course, alternate formalisms, fluent calculus (Thielscher,1999) closely related approaches, based dynamic logics (Gerbrandy &Groeneveld, 1997; Demolombe, 2003; Demolombe, Herzig, & Varzinczak, 2003; Van Ditmarsch,Herzig, & De Lima, 2007). particular, action modality ES, inherit here, takendynamic logic. However, significant differences. example, Van Ditmarsch et al.(2007) consider epistemic extension dynamic logic regression property,propositional, consider knowing. Demolombe (2003), hand, considersform knowing, work, like original ES, restricted single agent case.Also, notion regression. details single agent version ES related various action proposals, see discussion Lakemeyer Levesque (2004).worth mentioning situation calculus previously extended deal multiple agents (Shapiro et al., 2002). Recently, fact, Kelly Pearce (2008) formulate evaluationepistemic queries, including queries common knowledge (Fagin et al., 1995), meansmeta-level operator using regression. contrast ideas, mainly concernedidentifying regression works presence multiagent knowing operators.argued earlier, able define initial knowledge terms known one obtainsnatural means reasoning beliefs non-beliefs. Moreover, epistemic situationcalculus Scherl Levesque equivalent representation theorem. Therefore, approaches would require form modal reasoning initial situation.14aspects, moreover, approaches comparable. one hand, contrast KellyPearce observed Section 2.2 common knowledge cannot captured semantics. hand, integrating knowing situation calculus situation termsexplicit, derivatives Scherl-Levesque scheme, problematic (Lakemeyer,1996; Lakemeyer & Levesque, 1998, 2004).14. Special cases reduction knowledge treated, example, Reiter (2001) LakemeyerLesperance (2012).391fiBelle & Lakemeyernote reasoning knowledge multiagent systems important area artificial intelligence, numerous formal systems studied (Fagin et al., 1995; Wooldridge,2009). example, properties similar ones obtained card game studied articlealso considered work Van Ditmarsch (2002). However, many systems propositional. significantly, knowing, feature appropriate beliefs entailmentsknowledge base known, addressed.pointed out, Levesque (1990) among first propose notion knowinglogic OL, number related notions (Halpern & Moses, 1984; Hoek & Thijsse,2002; Pratt-Hartmann, 2000). discuss here, relationships OL,treated elsewhere (Rosati, 2000; Halpern & Lakemeyer, 2001; Levesque & Lakemeyer, 2001).Readers also referred work Levesque Lakemeyer (2001) comprehensivestudy OL; example, shown compactness property hold objectivefragment OL. Halpern Pass (2009) consider related probabilistic variant knowingstudying certain kinds strategies game theory.Since Levesques proposal, generalizations many agent case attempted number papers (Lakemeyer, 1993; Halpern, 1993; Halpern & Lakemeyer, 2001; Waaler & Solhaug,2005). point earlier work (Belle & Lakemeyer, 2010a), approachesundesirable features. k-structures approach (Belle & Lakemeyer, 2010a), hand,shown satisfactorily capture multiagent knowing. work, also discuss number aspects multiagent knowing, including, example, sound completeaxiomatization propositional case.15Finally, remark intuition k-structures seems closely related proposalknowledge structures (Fagin, Halpern, & Vardi, 1991). Although restricted propositional language, although actions knowing considered, proposal also basedepistemic states various depths. (See Kaneko Suzuki, 2003, similar semantical notionsgame theory.) agent, 1-world simply set truth assignments primitive propositions.roughly corresponds set worlds, similar 1-structure. However, 2-world considerstriple: truth assignment primitive propositions, 1-world A, 1-world B.differs proposal slightly. also expect k-worlds satisfy various constraints, including one knowledge always correct. Despite differences, also motivatedease capturing non-beliefs, investigation correspondencestwo approaches perhaps worthy study.6. Conclusionswork considered reasoning knowing many agents dynamic domains.language introduced first-order formalism allows us reason knowledge, knowing, actions sensing. knowing distinctive advantages view knowledgebased agent possible specify sentences precisely characterize knowledgebase, logically infer corresponding beliefs non-beliefs (with quantifying-in)characterization. Building previous work multiagent knowing (Belle & Lakemeyer,2010a) modal fragment situation calculus (Lakemeyer & Levesque, 2004), semantical15. OLs axiomatization first-order language (Levesque, 1990) shown incomplete HalpernLakemeyer (1995); also show complete axiomatization cannot recursive.392fiMultiagent Knowing Dynamic Systemsaccount first discussed. showed knowledge appropriate properties, despite semantics slightly deviating usual Kripke-structure account. considered notionbasic action theory, explored projection tasks terms simple card game. particular,non-trivial knowledge change mechanisms sensing demonstrated formalism.One important methodology reasoning actions literature regression, extensively used planning methodologies (Fritz, 2009), proved version regressionformalism. this, reasoning actions knowledge reduces reasoning knowledge initial state only. Next, generalized representation theorem (Levesque & Lakemeyer, 2001) reduce reasoning knowledge initial state first-order reasoning.Thus, modal reasoning necessary. believe results together underlying logicenhance current paradigms logical modeling intelligent agents (Fagin et al., 1995;Wooldridge, 2009), especially sense formal specifications knowledge-based systems.many avenues future work. important observation OL Levesque (1990)knowledge base includes beliefs itself, certain flavor nonmonotonicityexhibited. fact, beliefs logically follow related precise way fixed-pointdefinition autoepistemic logic (Moore, 1985). previously shown (Belle & Lakemeyer,2010a) notions generalize multiagent case well, used multiagentautoepistemic reasoning. example, Fred tells Sara recently bought bird, Fred mightcome assume Sara believes bird flies, without explicitly suggestingfact. ESn , course, would allow notions studied dynamic setting (Kakas,Michael, & Miller, 2008; Lakemeyer & Levesque, 2009).long-lived agents, regression would become infeasible millions actions,would need periodically update knowledge base, referred progression (Lin &Reiter, 1997). STRIPS technology, instance, simple form progression (Reiter, 2001).Recently, computational methodology progression studied contextknowing (Lakemeyer & Levesque, 2009). idea, roughly, agent knows basicaction theory 0 pre post sense , action, agent knows another basicaction theory 0 0 pre post sense , 0 0 progression 0 . Here, knowingcharacterizes knowledge base precise way actions. account might suggestways study notions multiagent setting, actions, agent would updatebeliefs world would also update beliefs agents know.Finally, extensions probabilistic nondeterminism (Gabaldon & Lakemeyer, 2007; Belle &Lakemeyer, 2011) development strategies coalitions agents (Alur, Henzinger, & Kupferman, 2002; Giacomo, Lesperance, & Pearce, 2010) worth exploringknowing framework, perhaps along lines Halpern Pass (2009).Acknowledgementsthank reviewers many helpful comments suggestions. work carriedfirst author supported graduate school GK 643 RWTH Aachen Universityfunded DFG (German Research Foundation) scholarship.393fiBelle & LakemeyerAppendix A. Proof Regression Propertysection, prove Theorem 21. begin useful lemmas turningmain theorem. follows, make use following special construction. Givenworld w, define another world w like w except satisfies pre , post sensesentences .Definition 28 Let w world, z Z basic action theory fluents F . wworld satisfying following conditions:1. f < F , w [ f (n1 , . . . , nk ), z] = w[ f (n1 , . . . , nk ), z];2. f F , w defined inductively by:(a) w [ f (n1 , . . . , nk ), hi] = w[ f (n1 , . . . , nk ), hi];k(b) w [ f (n1 , . . . , nk ), z r] = iff w , z |= ( f )ar xn11,...,x,...,nk ;3. w [Poss(r), z] = 1 iff w , z |= ar ;4. w [SFi (r), z] = iff w , z |= ar mx ;f , rhs successor state, precondition sensing axioms respectively,appearing basic action theory .following properties shown regarding w relation w:Lemma 29 (Lakemeyer & Levesque, 2004)1. w, w exists unique.2. w |= 0 w |= .3. w |= w = w .4. Let bounded objective sentence, suppose rectified NF. Let z Z.w |= R[z, ] iff w , z |= .Proof: proof lemma given elsewhere (Lakemeyer & Levesque, 2004). Latersection, arguments analogous proof item 4 needed, include proofitem here.Item 4 proven induction length . treat length Poss(r) SFi (r)length ar ar plus 1. consider non-trivial cases below:case Poss(r).w , z |= Poss(r)iff w , z |= ar definition wiff w |= R[z, ar ] induction394fiMultiagent Knowing Dynamic Systemsiff w |= R[z, Poss(r)] definition R.case SFi (r) = m.w , z |= SFi (r) =iff w , z |= ar definition wiff w |= R[z, ar ] inductioniff w |= R[z, SFi (r) = m] definition R.case fluents f F . Note that, definition NF, ground atoms form f (n1 , . . . , nk ) = m.proof sub-induction z.1. w |= f (n1 , . . . , nk ) =iff w |= f (n1 , . . . , nk ) = definition wiff w |= R[hi, f (n1 , . . . , nk ) = m] definition R.2. w , z r |= f (n1 , . . . , nk ) =kiff w , z |= f ar xn11,...,x,...,nk definition wx,...,x1iff w |= R[z, f r n1 ,...,nkk ] sub-inductioniff w |= R[z r, f (n1 , . . . , nk ) = m] definition R.proceed prove similar properties epistemic states. Given ek basic actiontheory , let us define e k inductively by:1. e 1 = {(w , {}) | (w, {}) e1 };2. e k = {(w , e k1 ) | (w, ek1 ) ek }.addition, using notation nested knowing operators (see Section 3), brevity, let0 = OKnow0 [A, k] OKnow0 0 [B, j],= OKnow [A, k] OKnow 0 [B, j].Then, item 2 Lemma 29 extended knowledge following manner:jjLemma 30 Suppose ekA , eB , w |= 0 . e kA , e 0 B , w |= .Proof: proof simple induction modal depth (Definition 13) background theory.Recall modal depth background theory l, sentence formOKnow0 [A, k] OKnow0 0 [B, j] k l, j l k j l.base case theory modal depth 1. suppose e1A , e1B , w |= OA (0 ) OB (0 0 ).show (w0 , {}) e 1A iff w0 |= . that, get e 1A , {}, w |= OA . case e 0 1B entirelyanalogous, means shown e 1A , e 0 1B , w |= OA () OB ( 0 ).Suppose w |= . w |= 0 therefore, assumption, (w, {}) e1A . Lemma 29,w = w therefore, (w, {}) e 1A .395fiBelle & LakemeyerConversely, let (w, {}) e 1A . definition, (w0 , {}) e1A w0 = w. since|= 0 , follows Lemma 29 w |= . Thus, e 1A , {}, w |= OA ().satisfiesAssume hypothesis holds theories modal depth k 1, is, ek1jkkOKnow0 [A, k1] e satisfies OKnow [A, k1], similarly B. Now, suppose eA , eB , w |=k00 k1k k1k0 . Then, (w0 , ek1B ) eA iff eA , eB , w |= 0 OKnow0 [B, k 1]. show (w , eB ) e iff0ke kA , ek1B , w |= OKnow [B, k 1], get e , {}, w |= OKnow [A, k]. argumentjsymmetric eB , therefore, lemmas claim follows.w00 k1k k1Consider ek1B w e , eB , w |= OKnow [B, k 1]. Now, consider eBk10{}, eB , w |= OKnow0 [B, k 1]. Since w |= , Lemma 29 w = w also, w |= 0 .follows (w, e0B k1 ) ekA assumption. induction hypothesis, {}, e 0 k1B , w |= OKnow [B, kk1k10k01]. definition, (w, e B ) e . easy argument shows e B = ek1B .k1kk1Conversely, consider (w, eB ) eA . assumption, {}, eB , w |= 0 OKnow0 [B, k 1].Lemma 14, w |= . induction hypothesis, {}, e k1B , w |= OKnow [B, k 1]. definition,k.(w , e k1)eBgeneralize item 4 Lemma 29 knowledge.jjLemma 31 ekA , eB , w |= R[, , 0 , z, ] iff e kA , e 0 B , w , z |= .Proof: proof induction z, sub-induction .Let z = hi. case objective formulas proceeds exactly Lemma 29. let us considercase A-subjective formulas.je kA , e 0 B , w , z |= KAkk k1iff (w, ek1B ) e , e , eB , w |=kkk1kiff (w, ek1B ) eA , e , e B , w |= definition ekk k1iff (w, ek1B ) eA , eA , eB , w |= R[hi, ] sub-inductionjiff ekA , eB , w |= KA R[hi, ]jiff ekA , eB , w |= R[hi, KA ] definition R.case B-subjective formulas symmetric.Now, consider case z r. proof precisely base case, except subjective formulas, prove follows. show argument A-subjective formulas.arguments B-subjective formulas symmetric.je kA , e 0 B , w , z r |= KAjiff e kA , e 0 B , w , z |= [r]KA definitionjiff e kA , e 0 B , w , z |= ar rhs Theorem 19 [r]KAjiff ekA , eB , w |= R[z, ar ] main induction396fiMultiagent Knowing Dynamic Systemsjiff ekA , eB , w |= R[z r, KA ] definition R.ready prove Theorem 21. restate claim below:Theorem 21 Suppose bounded basic sentence maximal A, B-depth k, j. Let , 0basic action theories. R[hi, ] static sentence satisfies:|= iff 0 0 |= R[hi, ]= OKnow [A, k] OKnow 0 [B, j]0 = OKnow0 [A, k] OKnow0 0 [B, j].Proof: Let us denote 0 0 0 .jonly-if direction, suppose |= suppose ekA , eB , w |= 0 . is, w |=j0 Lemma 29, w |= . Further, Lemma 30, e kA , e 0 B , w |= . assumption,jje kA , e 0 B , w |= . Then, Lemma 31, ekA , eB , w |= R[hi, ].jConversely, suppose 0 |= R[hi, ] let ekA , eB , w |= . w |= 0 . Supposejjje0 kA , e0 B , w |= 0 . assumption e0 kA , e0 B , w |= R[hi, ]. Lemma 31, e 0 kA , e 0 0 B , w |= .jLemma 29, w = w. Lemma 30, e 0 kA , e 0 0 B , w |= . Since ekA e 0 kA k-structuresOKnow [A, k] holds, simple induction argument shows e 0 kA = ekA . Analogously,jjje 0 0 B eB same. Therefore ekA , eB , w |= .Appendix B. Proof Representation Theoremsection, prove Theorem 26. proceed first relating valid fluent sentences ESnnon-dynamic fragment OLn (Belle & Lakemeyer, 2010a). this, goessential details OLn . Roughly speaking, OLn ESn without dynamic operators {[t], }distinguished symbols {Poss, SFi .} static world w W function primitive sentences{0, 1} primitive terms standard names. Epistemic states OLn k-structuresstatic worlds. notions carry OLn , simply ignoring dynamic aspects.jexample, specify semantics KA wrt triple (ekA , eB , w) w W follows:j0 k1kk k10ekA , eB , w |= KA iff w0 W , ek1B , (w , eB ) eA , eA , eB , w |= .words, roughly, dropped action sequence z compatibility relation 'zAsemantical definition KA ESn . Terminology formulas, objective basicanalogously defined OLn .present three formal properties regarding OLn ESn sentences:Lemma 32 OLn , valid OLn iff valid ESn .Lemma 33 ESn fluent sentence z action sequence, R[, , 0 , z, ]objective OLn -sentence.397fiBelle & Lakemeyerproofs straightforward generalizations analogous results regarding OL ES, appearing Theorem 6, Lemma 9 Lemma 10 work Lakemeyer Levesque (2004),therefore reproduced here. example, Lemma 32, main technical scheme relateES (and thus ESn ) worlds OL (and thus OLn ) worlds. Lemma 33, clearly objective OLsentences also objective OLn sentences, claim follows.Lemma 34 bounded basic sentence z action sequence, R[, , 0 , z, ]basic OLn sentence.Proof: proof induction . fluent sentence argument immediateowing Lemma 33. Poss, R[z, Poss(t)] = R[z, ], fluent formula, Lemmaayay33 applies. SFi , R[z, SFi (t) = t0 ] = R[z, t0 ], again, t0 fluent formula. [t],R[z, [t]] = R[z t, ] basic OLn sentence induction.KA , sub-induction z. case KB analogous. R[hi, KA ] = KA R[hi, ].Since main induction, R[hi, ] basic, KA R[hi, ] also basic. R[z t, KA ] =R[z, ], rhs Theorem 19 [t]KA . sub-induction hypothesis Lemma33, also basic.prove three main results essential Theorem 26. prepare that, givenstatic worlds W objective OLn -sentence , let:W = {w | w |= , w W };e 1 = W {{}};e k = {(w, e k1 ) | w W }.sequel, benefiting Lemma 32, simply argue using OLn -models, is, ignoringdynamic notions.jLemma 35 Let 0 objective OLn sentences let e kA e0 B above. Letobjective formula free variables x1 , . . . , xk . vector standard names n1 , . . . , nkworld w:jx1 ,...,xkke kA , e0 B , w |= KA nx11 ,...,x,...,nk iff |= Res[, ]n1 ,...,nk .kAnalogously KB nx11 ,...,x,...,nk .x1 ,...,xkkkProof: Lemma 7, follows e kA , {}, w |= KA nx11 ,...,x,...,nk iff e 1 , {}, w |= KA n1 ,...,nkKA A-depth 1. sufficient show that:x1 ,...,xkke k1 , {}, w |= KA nx11 ,...,x,...,nk iff |= Res[, ]n1 ,...,nk .(15)Note e k1 = {(w, {}) | w |= }, (15) simply proved OL (Levesque & Lakemeyer, 2001, Lemma 7.2.2).Theorem 36 Let basic OLn formula maximal A, B-depth k, j free variablesjx1 , . . . , xk . Let e kA , e0 B before, w world, n1 , . . . , nk vector names.x1 ,...,xkke kA , e0 B , w |= nx11 ,...,x,...,nk iff w |= kk,0 n1 ,...,nk .j398fiMultiagent Knowing Dynamic SystemsProof: proof induction structure . atom equality, lemmaclearly holds since objective. induction, lemma also holds negations, disjunctionsquantifiers.Now, consider KA . (The case KB symmetric.)ke kA , {}, w |= KA nx11 ,...,x,...,nkx1 ,...,xkk0 k10iff e kA , ek1B , w |= n1 ,...,nk (w , eB ) ekinduction hypothesisiff w0 |= kk,0 nx11 ,...,x,...,nkkkobjectivesince kk,0 nx11 ,...,xiff e kA , {}, w |= KA kk,0 nx11 ,...,x,...,nk,...,nkkk, ]nx11 ,...,xiff |= Res[kk,0 nx11 ,...,x,...,nk Lemma 35,...,nkkdefinition Resiff |= kKA k,0 nx11 ,...,x,...,nkkiff w |= kKA k,0 nx11 ,...,xresult Res objective formula use,...,nkkpredicates function symbols. Therefore, kKA k,0 nx11 ,...,xeither valid unsatisfi,...,nkable.Theorem 37 Suppose maximal A, B-depth k, j. Let , 0 objective OLn sentences.|= iff |= kk,0 .= OKnow [A, k] OKnow0 [B, j].jProof: direction, suppose (ekA , eB , w) model . easy verify ekA = e kAjjjeB = e0 B , so, w world satisfying . Since |= , ekA , eB , w |= iff w |= kk,0Theorem 36. model satisfies kk,0 . Therefore, |= kk,0 |= kk,0 .jConversely, suppose |= kk,0 . Now, let (ekA , eB , w) model . easyjjverify ekA = e kA eB = e0 B . Further, since w |= w |= kk,0 . Theorem 36,jekA , eB , w |= .Finally, turn proof Theorem 26. restate claim below.Theorem 26 Let , 0 basic action theories. Suppose basic bounded sentencemaximal A, B-depth k, j,|= iff|= 0 kR[hi, ]k0 ,0 0 .= OKnow [A, k] OKnow 0 [B, j].Proof: OKnow [A, k] OKnow 0 [B, j] |=iff 0 OKnow0 [A, k] OKnow0 0 [B, j] |= R[hi, ] regression property Theorem 21iff 0 OKnow0 [A, k] OKnow0 0 [B, j] R[hi, ] valid OLn Lemma 32, owingfact R[hi, ] also (basic) OLn sentence Lemma 34iff 0 kR[hi, ]k0 ,0 0 valid OLn Theorem 37.399fiBelle & LakemeyerReferencesAlur, R., Henzinger, T. A., & Kupferman, O. (2002). Alternating-time temporal logic. J. ACM,49(5), 672713.Belle, V., & Lakemeyer, G. (2010a). Multi-agent only-knowing revisited. Proc. KR, pp. 4960.Belle, V., & Lakemeyer, G. (2010b). Reasoning imperfect information games epistemicsituation calculus. Proc. AAAI, pp. 255261.Belle, V., & Lakemeyer, G. (2011). semantical account progression presence uncertainty. Proc. AAAI, pp. 165170.Demolombe, R. (2003). Belief change: situation calculus modal logic. Proc. Nonmonotonic Reasoning, Action, Change (NRAC).Demolombe, R., Herzig, A., & Varzinczak, I. (2003). Regression modal logic. Journal AppliedNon-Classical Logics, 13(2), 165185.Fagin, R., Halpern, J. Y., Moses, Y., & Vardi, M. Y. (1995). Reasoning Knowledge. MITPress.Fagin, R., Halpern, J. Y., & Vardi, M. Y. (1991). model-theoretic analysis knowledge. J. ACM,38(2), 382428.Fritz, C. (2009). Monitoring Generation Execution Optimal Plans. Ph.D. thesis, University Toronto.Gabaldon, A., & Lakemeyer, G. (2007). ESP: logic only-knowing, noisy sensing acting.Proc. AAAI, pp. 974979.Gerbrandy, J., & Groeneveld, W. (1997). Reasoning information change. J. Logic, Lang.Inf., 6(2), 147169.Giacomo, G. D., Lesperance, Y., & Pearce, A. R. (2010). Situation calculus based programsrepresenting reasoning game structures. KR.Halpern, J. Y. (1993). Reasoning knowing many agents. Proc. AAAI, pp. 655661.Halpern, J. Y., & Lakemeyer, G. (1995). Levesques axiomatization knowing incomplete.Artificial Intelligence, 74(2), 381387.Halpern, J. Y., & Moses, Y. (1984). Towards theory knowledge ignorance: Preliminaryreport. Proc. NMR, pp. 125143.Halpern, J. Y., & Pass, R. (2009). logical characterization iterated admissibility. Proc.TARK, pp. 146155.Halpern, J., & Lakemeyer, G. (2001). Multi-agent knowing. Journal Logic Computation,11(1), 251265.Harel, D., Kozen, D., & Tiuryn, J. (2000). Dynamic logic. MIT Press.Hintikka, J. (1962). Knowledge belief: introduction logic two notions. CornellUniversity Press.Hoek, W. V. D., & Thijsse, E. (2002). general approach multi-agent minimal knowledge:tools samples. Studia Logica, 72(1), 6184.400fiMultiagent Knowing Dynamic SystemsKakas, A. C., Michael, L., & Miller, R. (2008). Fred meets tweety. ECAI, pp. 747748.Kaneko, M., & Suzuki, N.-Y. (2003). Epistemic models shallow depths decision makinggames: Horticulture. Journal Symbolic Logic, 68(1), pp. 163186.Kaplan, D. (1968). Quantifying in. Synthese, 19(1), 178214.Kelly, R. F., & Pearce, A. R. (2008). Complex epistemic modalities situation calculus.Proc. KR, pp. 611620.Kripke, S. (1963). Semantical considerations modal logic. Acta Philosophica Fennica, 16,8394.Lakemeyer, G. (1996). knowing situation calculus. Proc. KR, pp. 1425.Lakemeyer, G., & Levesque, H. J. (2011). semantic characterization useful fragmentsituation calculus knowledge. Artificial Intelligence, 175, 142164.Lakemeyer, G., & Levesque, H. J. (2004). Situations, si! situation terms, no!. Proc. KR, pp.516526.Lakemeyer, G., & Levesque, H. (1998). AOL: logic acting, sensing, knowing, knowing. Proc. KR, pp. 316329.Lakemeyer, G. (1993). know: study multi-agent autoepistemic reasoning. Proc.IJCAI, pp. 376381.Lakemeyer, G., & Lesperance, Y. (2012). Efficient reasoning multiagent epistemic logics.Proc. ECAI, pp. 498503.Lakemeyer, G., & Levesque, H. (2009). semantical account progression presencedefaults. Conceptual Modeling: Foundations Applications, pp. 8298. Springer.Levesque, H. J. (1990). know: study autoepistemic logic. Artificial Intelligence, 42(2-3),263309.Levesque, H., & Lakemeyer, G. (2001). logic knowledge bases. MIT Press.Lin, F., & Reiter, R. (1997). progress database. Artificial Intelligence, 92(1-2), 131167.McCarthy, J., & Hayes, P. J. (1969). philosophical problems standpoint artificialintelligence. Machine Intelligence, pp. 463502.Moore, R. C. (1985). Semantical considerations nonmonotonic logic. Artificial Intelligence,25(1), 7594.Pratt-Hartmann, I. (2000). Total knowledge. Proc. AAAI, pp. 423428.Reiter, R. (2001). Knowledge action: logical foundations specifying implementing dynamical systems. MIT Press.Rogers Jr., H. (1987). Theory recursive functions effective computability. MIT Press.Rosati, R. (2000). decidability complexity reasoning knowing. ArtificialIntelligence, 116(1-2), 193215.Scherl, R. B., & Levesque, H. J. (2003). Knowledge, action, frame problem. ArtificialIntelligence, 144(1-2), 139.401fiBelle & LakemeyerShapiro, S., Lesperance, Y., & Levesque, H. (2002). cognitive agents specification languageverification environment multiagent systems. Proc. AAMAS, pp. 1926.Thielscher, M. (1999). situation calculus fluent calculus: state update axioms solutioninferential frame problem. Artificial Intelligence, 111(1-2), 277299.Van Ditmarsch, H., Herzig, A., & De Lima, T. (2007). Optimal regression reasoningknowledge actions. Proc. AAAI, pp. 10701075.Van Ditmarsch, H. (2002). Descriptions game actions. Journal Logic, Language Information, 11(3), 349365.Waaler, A., & Solhaug, B. (2005). Semantics multi-agent knowing: extended abstract.Proc. TARK, pp. 109125.Wooldridge, M. (2009). Introduction Multiagent Systems (2 edition). Wiley, Chichester, UK.402fiJournal Artificial Intelligence Research 49 (2014) 527-568Submitted 10/13; published 03/14Large-Scale Optimization Evaluation FunctionsMinimax SearchKunihito Hokihoki@cs.uec.ac.jpDepartment Communication Engineering InformaticsUniversity Electro-CommunicationsTomoyuki Kanekokaneko@acm.orgDepartment Graphics Computer SciencesUniversity TokyoAbstractpaper presents new method, Minimax Tree Optimization (MMTO), learnheuristic evaluation function practical alpha-beta search program. evaluationfunction may linear non-linear combination weighted features, weightsparameters optimized. control search results move decisions agree game records human experts, well-modeled objective functionminimized designed. Moreover, numerical iterative method used find localminima objective function, forty million parameters adjustedusing small number hyper parameters. method applied shogi, majorvariant chess evaluation function must handle larger state spacechess. Experimental results show large-scale optimization evaluationfunction improves playing strength shogi programs, new method performssignificantly better methods. Implementation new method shogiprogram Bonanza made substantial contributions programs first-place finish2013 World Computer Shogi Championship. Additionally, present preliminary evidencebroader applicability method two-player games chess.1. IntroductionHeuristic search powerful method artificial intelligence. 1997, chess-playingcomputer Deep Blue defeated world chess champion Garry Kasparov (Campbell, Hoane,& Hsu, 2002). computer decided moves making large number searchesminimax game tree using heuristic evaluation functions. frameworkartificial intelligence, heuristic evaluation functions, well search methods,crucial making strong computer players. Thus, researchers working various gamesmade substantial efforts quest create effective evaluation functions using machine learning techniques (Furnkranz, 2001). However, fully automated learningheuristic evaluation functions remains challenging goal chess variants. example, developers reported majority features weights Deep Bluecreated/tuned hand (Campbell et al., 2002). said recent top-level chessprograms tune parameters automatically, although yet findpublication describing methods use. Moreover, reinforcement learningapplied chess (Baxter, Tridgell, & Weaver, 2000; Veness, Silver, Uther, & Blair, 2009).c2014AI Access Foundation. rights reserved.fiHoki & KanekoHowever, best authors knowledge, evaluation functions learnedmethods reported literature still weaker best hand-crafted functionsterms chess-playing strength.paper, revisit idea behind earlier research learning chess evaluationfunctions (Marsland, 1985; Hsu, Anantharaman, Campbell, & Nowatzyk, 1990; Tesauro,2001) reformulate task optimization problem using alternative learningmethod, called Minimax Tree Optimization (MMTO). objective optimizefull set parameters evaluation function search results matchdesired move decisions, e.g., recorded moves grandmaster games. evaluationfunctions learned iteration two procedures: (1) shallow heuristic searchtraining positions using current parameters (2) parameter update guidedapproximation gradient objective function. achieve scalability stability,introduce new combination optimization techniques: simplified loss function, gridadjacent update, equality constraint, l1 -regularization. One resulting meritsMMTO ensure existence local minimum within convenient rangeparameters.study demonstrates performance MMTO shogi, variant chessevaluation functions need handle wider variety features positions Westernchess. Implementation MMTO shogi program Bonanza (described Section 4.6)made substantial contribution programs first-place finish 2013 World Computer Shogi Championship. rules shogi, well survey approaches artificialintelligence, described literature (Iida, Sakuta, & Rollason, 2002). Basic techniques, minimax search guided heuristic evaluation functions, effectiveshogi chess. However, drop rule allows player reuse captured piecessignificantly changes properties: (1) number legal moves, well averagegame length, greater chess, (2) endgame databases available, (3)material balance less important chess, especially endgame. Thus,performance shogi program dependent quality evaluation function.experiments, first show full set parameters evaluationfunctions optimized respect rate agreement training set.that, examine performance various learned evaluation functions termsrates agreement test positions win rates references. Scalabilitydemonstrated forty million parameters, far many tunehand. features used piece values extended versions piece-square tablescommonly used learn evaluation functions chess (Tesauro, 2001; Baxter et al.,2000; Veness et al., 2009). also briefly examine performance MMTO chesscatch glimpse applicability MMTO games.rest paper organized follows. next section reviews related research.third section presents MMTO method. fourth section shows experimentalresults, forty million parameters adjusted better performance, comparesperformance method existing methods. last section presentsconcluding remarks. paper incorporates extends previous work (Hoki &Kaneko, 2012; Kaneko & Hoki, 2012).528fiLarge-Scale Optimization Evaluation Functions Minimax Search2. Related Worksection reviews related research learning evaluation functions. First, describesupervised learning methods use desired moves. Second, discuss learningmethods, including regression reinforcement learning. Third, briefly discuss difficulty supervised learning terms numerical optimization. Although machine learningcomponents besides evaluation functions game programs would interestingresearch topic (Bjornsson & Marsland, 2002; Tsuruoka, Yokoyama, & Chikayama, 2002;Coulom, 2007; Silver & Tesauro, 2009), review focuses researchdone learning evaluation functions.2.1 Learning Desired Moves ChessGrandmaster games popular source information learning chess. Let us sayset positions P desired moves position P. Typically,positions moves sampled grandmaster games. chess programevaluation function e(p, w ), p game position feature weight vector wcontains parameters adjusted.Let us assume evaluation function e(p, w ) partially differentiable respectwi i. Here, wi i-th component w .P example, function couldlinear combination weighted features, i.e., e(p, w ) = wi fi (p), fi (p) i-thfeature value position p. aim learning find better weight vector wstrengthening play program. hypothesis behind kind learningcomputer play agrees desired moves, better plays.Let us begin simple intuitive goal: make results one-ply search agreedesired moves. simplicity, let us assume maximizing player moves firstroot position p. one-ply search, move highest evaluation valueselected. Thus, w adjusted desired move highest evaluationmoves. goal formally written mathematical minimization problemobjective function:Pw) =JH(wX XH (e(p.m, w ) e(p.dp , w )) .(1)pP mM0pHere, p.m position move position p, dp desired move position p, M0pset legal moves p excluding dp , H(x) Heaviside step function, i.e.,H(x) equals 1 x 0, 0 otherwise. objective function counts numbermoves evaluation value greater equal desired move,better w found minimizing Eq. (1). Although several studies attemptedmachine learning basis framework (Nitsche, 1982; van der Meulen, 1989;Anantharaman, 1997), numerical procedures complicated, adjustmentlarge-scale vector w seemed present practical difficulties.Marsland (1985) presented notable extension wherein continuous function usedconventional optimization techniques exploited. Here, continuous functiondifference substituted non-continuous step function Eq. (1). interesting529fiHoki & Kanekomodified functionw) =J2P (wX X[max {0, e(p.m, w ) e(p.dp , w )}]2 .(2)pP mM0pmeaning function value different Eq. (1); i.e., functioncount number moves evaluation value greater equalw ) helps reduce functiondesired move. However, gradient vector w J2P (wvalue numerically. Marsland also introduced inequality constraints order keepevaluation right range. However, literature provide experimentalresults practical chess programs.second notable extension proposed early development chess machinesDeep Thought (Nowatzyk, 2000; Hsu et al., 1990). Here, positions comparedp.m, rather wp.m , is, one leaves principal variations (PVs), possiblyseveral plies p.m. extension carries least-square fitting evaluationw ) does. Instead, biasesvalues. Therefore, max function J2P (wp.dpvalue e(w , w ) used least-square fitting, evaluation valuep .dp .mdesired move dp , e(w p , w ) lower another move m, e(w, w ).third notable extension comparison training proposed Tesauro (2001).Tesauro modified objective functionX Xp .dPp .mw) =Jct(wTct (e(w p , w ) e(w, w )),pP mM0pTct (x) = [(R(x)) 1]2 ,(3)standard sigmoid function, R heuristic rescaling factor positivedifferences, i.e., R(x) = x x 0, R(x) = cx constant c > 1 otherwise. NoteR(x) still continuous function. important property modified objectivefunction value derivative zero limit difference x goespositive infinity, respectively one zero limit differencex goes negative infinity. Therefore, Tct (x) Eq. (3) continuous approximationH(x) Eq. (1). Note property explicitly stated Tesauro,notably distinct work. number feature weights adjustedmethod less two hundred. Tesauro also mentioned application small-bitintegers, used adjust weights Deep Blue. However, neitherclarified procedure mentioned whether weights automatically adjustedexperiment.Table 1 summarizes related work. existing methods possesses leastone three important properties optimization, i.e., continuity, minimax searches,assured local minimum. However, none three properties. Also,existing methods (Nowatzyk, 2000; Hsu et al., 1990; Tesauro, 2001) trydecrease functions iteration much possible. revisit issuesSection 2.3. hand, method, MMTO, scalability high-dimensionallearning. Moreover, empirically show decrease objective function valueleads increase playing strength. existing methods shownproperty.530fiLarge-Scale Optimization Evaluation Functions Minimax SearchMethod(Nitsche, 1982)(Marsland, 1985)(van der Meulen, 1989)(Hsu et al., 1990)(Anantharaman, 1997)Comparison trainingMMTOContinuitySearchAssured local minimumYesYesYesYesYesYesYesYesYesYesTable 1: Summary learning methods using desired moves training positionsadjust feature weights evaluation functions. first column namemethod piece literature. second column describes continuityobjective functions respect feature weights. Yes meanscontinuity depends kind search method used. third column indicateswhether objective functions use minimax searches depths 1,instead comparisons legal moves root position. fourth columnshows whether hyper parameters objective functions assure localminimum found.2.2 Methods Learning Evaluation FunctionsMany researchers utilized information sources desired moves.example, studies Othello dating 1990s compare desired movesmoves (Fawcett, 1993). However, practical famous machine learningmethod yielded strong programs based regression desired valueusing 1.5 million features (Buro, 1995, 2002). Othello, different evaluation functionsused game stages determined basis number discs play. Thus,desired values training positions obtained complete endgame searchwell heuristic search evaluation functions learned later game stages.method also successfully applied card games (Buro, Long, Furtak, & Sturtevant,2009), chess variants. best authors knowledge, learning basedregression win/loss-labeled data yielded decent evaluation functions chessvariants. Except using desired moves, Buros method propertiessimilar listed Table 1; objective function continuity well assuredlocal minimum, method scalable. Gomboc, Buro, Marsland (2005) proposedlearn game records annotated human experts; however, feature weightsadjusted experiments small part full evaluation functions.Reinforcement learning (Sutton & Barto, 1998), especially temporal difference learning,famous success Backgammon (Tesauro, 2002), considered promisingway avoid difficulty finding desired values regression. approachapplied chess shown improve strength programs (Baxteret al., 2000; Levinson & Weber, 2001; Veness et al., 2009). KnightCap programachieved rating 2, 150 points Free Internet Chess Server (FICS1 )1. Free Internet Chess Server, http://www.freechess.org, last access: 2013531fiHoki & KanekoEasy(a)Single minimumDicult(b)(c)(d)Smooth Non-dieren able(e)Narrow trough Non-con nuousFigure 1: Example illustrating difficulties facing minimization procedure.2, 575 points highest peak Internet Chess Club (ICC) (Baxter et al., 2000).Another program achieved 2, 338 points highest peak ICC (Veness et al., 2009).However, strong human players ratings 3, 000 points ICC,difference means programs reached top level chess programs;is, evaluation functions tuned reinforcement learning yet reached levelbest-handcrafted evaluation functions chess. Moreover, number featureweights adjusted order thousands. checkers, evaluation functionstrained temporal difference learning reportedly comparable best handcraftedefforts (Schaeffer, Hlynka, & Jussila, 2001). also reported player strongerexpert human checker players created using neural networks trainedevolutionary strategy (Chellapilla & Fogel, 1999). Here, features beyond piecedifferentials given neural network priori.Many machine learning techniques (Baxter et al., 2000; Veness et al., 2009)applied shogi. However, despite efforts many programmers researchers, adjustment full weight vector evaluation function remains challenging goal.studies published far adjusted piece values small part featureweights evaluation functions (Beal & Smith, 2001; Ugajin & Kotani, 2010).2.3 Learning Numerical Optimizationlearning methods reviewed Section 2.1 objective functions decrease;learning process extended numerical optimization using functions.performance numerical optimization sensitive surface objective function.Figure 1 shows properties particular sorts functions difficulties regardingnumerical minimization. easiest one among convex function (a); localminimum exists, global minimum. Function (b) multiple local minima; however, still thought easy problem, various minimization algorithmsusing gradients Hessian matrices effective it. would desirable designlearning method using, say, linear logistic regression, uses one two typesobjective function (Buro, 2002).contrast, non-differentiable functions (c) (e) often difficultminimize differentiable ones. quadratic model, Hessianapproximation conjugated gradient method (Bertsekas & Bertsekas, 2008),always appropriate functions. Function (d) also difficult target,important local minimum hidden inside deep narrow trough, quite difficultfind using numerical iteration methods. difficult example minimization532fiLarge-Scale Optimization Evaluation Functions Minimax Searchnon-continuous function (e); even primitive iterative methods gradient decentcapable finding minimum. extreme case would functionanalytical formula gradient unavailable. case, learning method wouldable use partial derivatives, minima would obtained usingderivative-free methods, e.g., sampling methods (Bjornsson & Marsland, 2002; Coulom,2012).Theorems Appendix show minimax value continuous alwayspartially differentiable. Thus, existing methods incorporate minimax search(Hsu et al., 1990; Tesauro, 2001) MMTO listed Table 1 type (c). Moreover,certain forward pruning techniques may cause discontinuities. Therefore, even learningmethods type (e). overcome difficulty, MMTO well-modeled objectivefunction updates feature weights careful manner.3. Minimax Tree OptimizationMinimax Tree Optimization (MMTO) extension comparison training reachfirst intuitive goal embodied Eq. (1). purpose extension overcomepractical difficulties stabilize mathematical optimization procedure largescale feature weight vector w . Given set training positions P desired move dpposition p, MMTO optimizes weight vector w minimax searchw better agrees desired moves.weight vector w improved iteration sub-procedures (see Figure 2).iteration t, first step consists tree searches identify one leavesPVs w (t) legal moves training positions P. PV leaf w (t) dependsfeature weights w (t) evaluation function, new PV obtainedw (t) updated (We discuss issue Section 3.5). second step calculationapproximate partial derivatives, depends PV weight vector.last step update weight vector. numerical stability, differencew (t + 1) w (t)| must kept small distorted drastic changes|wpartial derivatives. Section 3.4 shows grid-adjacent update ensures this.3.1 Objective Function Minimizedobjective functionPw ) = J(P, w ) + JC (ww ) + JR (ww ),JMmto(w(4)first term J(P, w ) right side main part. terms JCJR constraint regularization terms, respectively, defined Section 3.2.first termX XJ(P, w ) =(s(p.dp , w ) s(p.m, w )) ,(5)pP mM0ps(p, w ) minimax value identified tree search position p. (x)1/(1 + exp(ax)), horizontally mirrored sigmoid function. slope (x)controlled constant parameter > 0. large limit, (x) becomes Heaviside533fiHoki & Kanekofiwp.(t)1. Perform game-tree search identify PV leaveschild positionsp.m position p training set P, w (t) weight vectort-th iteration w (0) initial guess.2. Calculate partial-derivative approximation well-modeled objectivep .mwfunction defined Section 3.1 using w(t) (t). objectivefunction employs differentiable approximation H(x) (see Section 3.1),well constraint regularization term (see Section 3.2).3. Obtain new weight vector w (t+1) w (t) using grid-adjacent updateguided partial derivatives computed step 2 (see Section 3.4). Goback step 1, terminate optimization objective functionvalue converges (see Section 4).Figure 2: Minimax Tree Optimization: Iteration searches update using partialderivativesstep function H(x). Thus, main differences first intuitive objective functionP (ww ) Eq. (1) use (x) smooth approximation H(x) useJHw )search result s(p, w ) instead raw evaluation e(p, w ). difference J2P (wPwwEq. (2) Jct (w ) Eq. (3) J(P, ) simpler closer first intuitive onew ) JR (ww ) Eq (4).Eq. (1). Moreover, none existing studies incorporate JC (wminimax value s(p, w ) equals raw evaluation value e(wp , w ), e(p, w )evaluation position p wp one PV leaves identified tree search rootedp weight vector w . cases, derivatives s(p, w ) equal derivativese(wp , w ). reasons, PV leaves identified step 1 Figure 2.3.2 Constraint Regularization Termscomputer programs chess variants, evaluation values typically representedintegers. Signed 16-bit integers especially preferred corresponding transposition tables memory efficient. Thus, restrict range absolutevalue evaluation function e(p, w ). Moreover, search results changew constant factor > 0, restrictionone uses scaled weight vector wstabilizes numerical optimization procedure value uncertain.w ) = 0 g(ww 0 ) Eq. (4),restriction, introduce constraint term JC (w0w ) = 0 equality constraint, 0 Lagrange multiplier.subset w , g(ww ) (seeaddition constraint term, also introduce regularization term JR (ww ) = 1 |ww 00 |, 1 > 0last term Eq. (4)). use l1 -regularization JR (wconstant variable, w 00 subset w . l1 -regularization widely used deal highdimensional parameters, whereas l2 -regularization used avoid over-fitting (Tibshirani,1996).w0534fiLarge-Scale Optimization Evaluation Functions Minimax SearchP (ww ) existsconstraint regularization terms ensure local minimum JMmtofinite range w . hand, depending P distribution dp ,P (ww ) Eq. (2), Jctw ) Eq. (3).property always true J(P, w ) itself, J2P (wconstraint l1 -regularization terms similar functionalities; i.e., restrictrange absolute value evaluation function e(p, w ). However, distinctions important practice l1 -regularization makes weight vector w 00 sparsewhereas constraint term not. Thus, regularization term suitable minorfeatures rarely seen, whereas constraint term suitable major featuresappear often training set. Moreover, terms useful controllingstrength restriction. major feature values usually change oftenminor feature values, magnitudes partial derivatives respect major featureweights usually greater respect minor feature weights. adjuststrength l1 -regularization term weaker constraint term.example, experiments used constraint term piece valuesfeature values, i.e., number pieces owned black/white, change single gamesshogi. many weights penalized l1 -regularization. weightw 0 , w 00 ).controlled either constraint l1 -regularization term, i.e., w = (wpartial derivatives respect major minor feature weights differed severalorders magnitude, difficult stabilize optimization procedure meanssingle hyper parameter 1 .3.3 Partial Derivative Approximationiteration, feature weights updated basis partial derivativesP (ww ) defined Eq. (4). partial derivative, exists,objective function JMmtoPw) =w) +w ).JMmto (wJ(P, w ) +JC (wJR (wwiwiwiwi(6)w ) right side treated intuitive manner; sgn(wi )1last term wJR (w00wi w , 0 otherwise. Function sgn(x) 1 x > 0, 0 x = 0, 1 x < 0.w ) 0 wiJC (w/ w 0 . case wi w 0partial derivative constraint term wdiscussed Section 3.5.partial derivative J(P, w ) always exist, minimax values(p, w ) always differentiable. Instead, use approximation,J(P, w ) =wiX X(s(p.dp , w ) s(p.m, w ))wi0(7)X Xp .de(w p , w ) e(wp.m , w )wi0(8)pP mMppP mMp=X Xp.d0 (e(w p , w ) e(wp.m , w ))pP mM0pp .d pe(w , w ) e(wp.m , w ) ,wi0 (x) = ddx (x). approximation Eq. (7) Eq. (8) makes computationtractable, identify PV leaves step 1 Figure 2. stated Appendix A,535fiHoki & Kanekominimax value s(p, w ) found search continuous, therefore, functionJ(P, w ) also continuous. Moreover, approximate value equivalent partialderivative unique PV exists position. Appendix also discusses conditions ws(p, w ) exists. Note found errors causedapproximation sufficiently small shogi application (Kaneko & Hoki, 2012).Previous studies (Baxter et al., 2000; Tesauro, 2001) use approximation well.3.4 Grid-Adjacent Updatenumerical stability, grid-adjacent update step 3 (see Figure 2) used getw (t + 1) w (t). Consider simple n-dimensional grid distance twoadjacent points h. Suppose h integer, e.g., h = 1. grid-adjacent update,feature vector w (t) always one points grid, i-th componentwi (t + 1) adjacent wi (t):wi (t + 1) = wi (t) h sgn(P (ww (t))JMmto).wiThus, |wi (t+1)wi (t)| = |wi | = h 0 i. update decrease objectiveP (wP (ww ) ww w JMmtow ) 0 errors approximation (seefunction JMmtoEq. (8)) negligible. Moreover, h must small enough updateppchange PV, i.e., w(t) = w (t+1) majority positions p searched step 1.Although MMTO focuses optimization weight vectors represented integers,noted gradient descent update suitable even one uses floatingpoint feature weights. preliminary experiments indicate partial derivativesJ(P, w ) respect major minor feature weights differ seven ordersw proportional gradient vector maymagnitude. Thus, update vector wappropriate updating minor feature weights small step. Thus, stepsize component weight vector fixed grid-adjacent update,might able controlled ways (see, e.g., Duchi, Hazan, & Singer, 2011).3.5 Combination Techniques Practical IssuesMMTO combination above-described techniques. subsection discussespractical issues combination alternatives; relate external constraintslearning (e.g., many weeks wait results), depend properties domain MMTO applied.3.5.1 Lagrange Multiplier Grid-Adjacent Updatenumerical stability, MMTO explores restricted parameter space constraintw ) = 0. this, Lagrange multiplier 0 JC (ww ) setsatisfied, i.e., JC (ww)J(P,w0median partial derivatives { wi | wi w } order maintain constraintw 0 ) = 0 iteration. result, wi0 h n feature weights, h n featureg(wweights, 0 one feature weight, number feature weights w 0 2n + 1.w ) constant iterations.hand, 1 regularization term JR (w536fiLarge-Scale Optimization Evaluation Functions Minimax Search3.5.2 Search Depthgame tree searches step 1 Figure 2 time-consuming step MMTO.Tesauro (2001) shown use quiescence search yields better evaluationfunctions. Thus, expected deeper searches MMTO yield better evaluationfunctions. hand, must handle large amount training positions,search time tends grow exponentially increase search depth. Therefore,experiments use 1-ply standard search together quiescence search. Here,quiescence search called every frontier node standard search. observedevaluation functions learned shallow searches still effective playing gamesdeep searches (see Section 4.4). Similar results reported Tesauro.3.5.3 Reuse PV Efficiency Learningstep 1 Figure 2 time-consuming part, worth considering omittingassuming wp (t) = wp (t1) certain frequency. experiments, steps 2 3repeated 32 times without running step 1. counted number iterationsrun step 1. is, iteration ran single step 1 32 pairs steps 2 3.number 32 would domain dependent set small enough updatechange PV positions.3.5.4 Pruning TreesPruning techniques dramatically reduce number searched nodes hence speedlearning. Fortunately, pruning introduce discontinuities objectivefunction. hand, pruning methods, including futility pruning (Schaeffer,1986), may introduce discontinuities (see Appendix A.4). Therefore, robustnesswhole learning procedure examined pruning techniques used.far authors experience goes, objective function futility pruning seemscontinuous (see Section 4.5).3.5.5 Convergence Performance Measurementtermination criteria usually difficult determine iterative computations.case learning shogi evaluation function, convergence objective functionMMTO seems significant criteria, rate agreement test setElo rating learned evaluation function also converge converges. Noterate agreement measured separate test set training setorder detect overfitting (see Section 4.3).3.5.6 Duplication Positions Alternative MovesGame records usually duplications positions desired moves openingphase. Although ideal distributions positions desired moves unknown,decided remove duplications training test sets simplicity.is, use pair hposition, movei iteration. duplicationsdetected Zobrist hashing (1990). Note two different moves maysuggested position training test sets, objective function537fiHoki & Kanekobecomes smaller tree search rooted position matches one moves.result, conflicting goals move better move b vice versaindependently augmented objective function cancelmoves played position. experience, adaptation seems workreasonably well shogi, best solution may depend target game.4. Experimentsevaluated effectiveness MMTO experiments number featureweights evaluation function varied thirteen forty million.found MMTO works better comparison training intuitive modificationsterms rate agreement, speed convergence, game-playing strength.w ) regularization term JR (ww ) help inalso observed constraint term JC (wcrease performance evaluation functions terms rate agreementtest set. see numerical convergence, investigated surfaces objectivefunction MMTO limited number feature weights experimentally foundMMTO finds local minima reasonable range feature weights. Finally, carriedpreliminary experiments chess well experiments data quality dependence.4.1 Setup: Evaluation Functions, Features, Game Recordsexperiments described section used Bonanza, whose source codeavailable online (Hoki & Muramatsu, 2012). performance Bonanza major tournaments discussed Section 4.6. Bonanza uses techniques MMTO, PVS (Pearl,1980; Marsland & Campbell, 1982; Reinefeld, 1983), capture search frontier nodesquiescence search, transposition tables (Zobrist, 1990; Russell & Norvig, 2002), static exchange evaluation (Reul, 2010), killer history heuristics (Akl & Newborn, 1977; Schaeffer, 1989), null move pruning (Adelson-Velskiy, Arlazarov, & Donskoy, 1975; Heinz, 1999),futility pruning (Schaeffer, 1986; Heinz, 1998), late move reductions (Romstad, 2010).also uses opening-book database randomly chose opening linesself-play experiments. game records training test sets exclusivelychosen games played famous tournaments2 . 48, 566 game recordstotal. 30, 000 games played professional players using standardtime controls, i.e., one ten hours side byoyomi period (once time2. abbreviated tournament name, number games used, date range games are: Juni,12827, 19462010; Kisei, 3286, 19622010; Ryuo, 3279, 19872010; Osho, 2286, 19502010; Oui, 2017,19592010; Ouza, 1849, 19522010; NHK-cup, 1745, 19512010; Ginga, 1735, 19912010; Kio, 1620,19732010; Shinjino, 1332, 19692010; Zen-nihon-proshogi, 1160, 19822001; Hayazashi-shogi-senshuken,945, 19722003; Judan, 764, 19621987; Meisho, 752, 19731989; Joryu-meijin, 608, 19742010; Meijin,551, 19352010; All-star-kachinuki, 545, 19782003; Rating-senshuken, 476, 19872007; Asahi-open,429, 20012007; Heisei-saikyo, 412, 19922007; Teno, 351, 19841992; Joryu-osho, 351, 19792010;Kurashiki-touka, 314, 19932010; Nihon-series, 304, 19812010; 3-dan-league, 283, 19632009; Ladiesopen, 255, 19872007; Joryu-oui, 253, 19902010; Shoureikai, 217, 19412008; Gakusei-osho, 212, 19722006; Hayazashi-shinei, 206, 19822002; Gakusei-ouza, 191, 20012006; Asahi-amashogi, 187, 19802009;Wakajishi, 183, 19531991; Kudan, 182, 19471961; Gakusei-meijin, 177, 19722006; Shogi-Renmei-cup,172, 19671984; Tatsujin, 160, 19932010; Kinsho-cup, 156, 20022005; Amateur-meijin, 146, 19482009;Kashima-cup, 119, 19962006; Grand-champion, 111, 19812008; Saikyosya-kettei, 101, 19541973; Miscellaneous, 5317, 16072010.538fiLarge-Scale Optimization Evaluation Functions Minimax Searchevaluation function13Xefi (p) fiA (p) wiAi=1XBBBeBfkj(p) fkj(p) wkjeCeDk,jX0 ,lk,kXdimension1360, 876CCCfkk0 l (p) fkk 0 l (p) wkk 0 l2, 425, 950fkjj 0 (p) fkjj0 (p) wkjj 044, 222, 454k,jj 0Table 2: Dimensions evaluation functions. evaluation function linear combination weighted features. eA evaluates material balance, othersevaluate variety positional scores using extended piece-square tables.expired, player move within sixty seconds). tournaments employed rapidtime controls 30 seconds per move top-level amateur players participants.Table 2 shows four basic evaluation functions, eA material balanceothers positional scores. experiments used sum functions, i.e.,eA , eAB = eA + eB , eABC = eAB + eC , eABCD = eABC + eD . evaluation functionsanti-symmetric respect exchange black white: e(p, w ) = e(p, w ). Here,p complete reversal black white sides position p; is, black playswhite white plays black3 . reversal, pieces owned black whitep regarded white black pieces p, respectively. Also, evaluation functionssymmetric respect right-and-left mirroring position: e(p, w ) = e(p, w ), pmirror image p along file e.function eA (p, w ) used evaluate material balance. 13 typespieces shogi (Iida et al., 2002). feature fiA (p) represents number i-thtype owned black position p, wiA relative value i-th type piece.partial derivative evaluation function respect wiA eA (p, w )/wiA =fiA (p) fiA (p).function eB (p, w B ) linear combination weighted two-piece-square features.natural extensions one-piece-square features employed recentmachine learning studies chess evaluations (Baxter et al., 2000; Tesauro, 2001; Venesset al., 2009). two-piece-square features used evaluate conditionsB (p) indicator function returns oneking another piece. feature fkjconditions k j exist position p. Otherwise, returns zero. Conditionk represents location black king (there 81 squares), j representstype, owner (black white), location piece. 1, 476 differentconditions j minor conditions merged. Thus, total numberkingpiece conditions 81 1, 476 = 119, 556 mirror symmetric conditionsmerged.3. Following shogi notation, black white refer players plays first second, respectively.539fiHoki & KanekoSimilarly, functions eC (p, w C ) eD (p, w ) used evaluate kingkingC (p)piece features kingpiecepiece features, respectively. indicator function fkk0lrepresents location two kings (k, k 0 ) condition (type location)(p) represents location black king kblack piece l. indicator function fkjj0conditions two black white pieces (j, j 0 ).Game tree searches required identify PV leaf positions MMTO obtainbest moves measure rate agreement. purposes, nominal depth 1search used together quiescence search. normalize objective functionvalues, objective function values divided total number move pairs, Z P =P0pP |Mp |. constraint function setw )=g(w13X!wiA6, 500.(9)i=1Also, accordance magnitude constraint, horizontally mirroredsigmoid function (x) = 1/(1 + exp(ax)) set 0.0273 (x) would vary signifiw ) = 0.00625 (|wwB| +cantly x changed hundred. regularization term JR (wCw | + |ww |). intuitive explanation penalty strength absolute value|wwi increased 160 improves relationship evaluationvalues desired move another legal move. sums eB , eC , eD computedusing 32-bit integers, divided 25 order fit evaluation value16-bit integer. Step h grid-adjacent update set smallest integer value 1.4.2 Learning Piece ValuesFirst, feature weights w = w evaluation function eA adjusted MMTOcomparison training, starting initial value wiA = 500 i. Tesauro(2001) used floating-point feature weights conventional gradient descent method.is, weight vector w updatedPw ),w (t) = w (t) rw Jct(w(10)r constant training rate hand-tuned 0.5. components w used treesearch rounded nearest integer values. rescaling factor R Eq. (3) setp .d0.0025 accordance range difference | e(w p , w ) e(wp.m , w )| 505, 000. experiment 13 piece values adjusted w , 1, 000game records used compose training set P. set 101,898 desired movesZ P = 7, 936, 180 move pairs removing duplications handicapped games.One problem observed comparison training slow learning: shown Figure 3, phase iterative procedure (from iteration 1 10) mainly adjustingpawn value, partial differential value Eq. (3) pawns largestphase. good pawn value found, phase II (from iteration 10 100)mainly adjusting promoted rook promoted bishop values. valueshighest second highest reasonable game play. long period time takenw ) Eq. (3) scales poorly. general problemphase II indicates JctP (wgradient descent methods multiple degrees freedom (Nocedal & Wright, 2006),540fiLarge-Scale Optimization Evaluation Functions Minimax Searchpro_rook2500Phase IIPhasePhase IIIpro_bishopPiece weight2000goldbishoprookpro_pawnpro_knightsilverpro_silverpro_lanceknightlance15001000500pawn02134 5 6234 5 610234 5 61001000IterationFigure 3: Results comparison training piece weights shogi. horizontal axisplots number iterations logarithmic scale.cope it, learning rate r cannot greater 0.5 accordance largestpartial derivative experiments.second problem convergence: phase III (after iteration 100) Figure 3,piece values keep increasing without changing ratio piece values, even thoughrelative ratios piece values room improvement. problem inherentobjective function comparison training, Eq. (3) explicit termavoid it. extreme case training data satisfy inequality conditionp .de(w p , w ) e(wp.m , w ) moves position p, piece values diverge infinityw ) minimized. fact, found training datavalue JctP (wexperiment satisfied condition 94% pairs best another legal move.Moreover, extreme case, training satisfy inequalitycondition move position p Eq. (3), piece values shrink zero.MMTO deals problems making grid-adjacent updates keepingw ). weighted vector w convergedmagnitudes constant constraint term JC (w40 iterations (see Figure 4); value promoted rook 945pawn 122. Note number iterations counted number step (1)sthroughout experiments.4.3 Scalability Learning Practical Evaluation Functionslearning piece values, adjusted weight vectors positional scores.time, large number training records used cope high-dimensional weightvectors. main training set P 4, 467, 116 desired moves Z P = 368, 313, 024541fiHoki & Kanekopro_rookpro_bishoprookbishopgoldpro_knightsilverpro_pawnpro_lancepro_silverknightlancepawnPiece weight80060040020021345 6 7 8210Iteration345 6 7 8100Figure 4: Results MMTO piece weights.move pairs removing duplications handicap games 47, 566 game records.test set 103, 105 desired moves removing duplications handicap gamesanother 1, 000 game records. feature weights eAB adjusted MMTOcomparison training intuitive modifications. initial feature weightsw (0), w B (0)) used three methods; w (0) optimized MMTO(wprevious experiment, w B (0) = 0. that, show scalability, feature weightseABC eABCD optimized MMTO order. adjust feature weightseABC , optimized feature weights eAB used initial feature weights w (0)w B (0), 0 used w C (0). Similarly, eABCD , optimized feature weightseABC used initial feature weights w (0), w B (0), w C (0), 0 usedw (0).Comparison training eABC eABCD tested learning eAB yieldedsmall improvements. rate r Eq. (10) hand tuned 0.031. exampleintuitive modifications stabilize iterative procedure, constant-step updatealso tested learning eAB . case, training rate r0 (t) substituted rPw (t))|,r0 (t) = rc /|w (t) Jct(wconstant-step modification conservatively updated w using constant step rchand tuned 1, 000. value r rc best five trials. Anotherintuitive modification reuse PV, explained Section 3.5, PVsused 32 times rate r Eq. (10) 0.01. rescaling factor R Eq. (3)set 0.0025, value satisfactory previous experiment shownFigure 3. Although three methods different, iterations consumed almostamount time. time-consuming step experimentsgame tree search identify PV leaf positions.rate agreement test set shown Figure 5. Here, agreement meanslegal move obtained highest value tree search desired move.542fiLarge-Scale Optimization Evaluation Functions Minimax Search0b2_c2_h6b2_c2_b435-20d2_b2_f3-40b2_c2_b3d2_f3_c4-60Positional weightAgreement (%)3025ABCDMMTO (e)ABCMMTO (e )ABMMTO (e )ABCT (e , reuse PV)ABCT (e , constant step)ABCT (e )201521345 6 7 8210345 6 7 8b2_c2_a3d2_f3_b3-80b2_b1_c2-100b2_c2_a2-120-140b2_d1_c22100Iteration050100150Iteration200Figure 5: (Left panel) Improvement rate agreement test set MMTOcomparison training (CT). (Right panel) Improvement feature weightspositional features eD . Feature weight b2 c2 b4 indicates black kingb2 two gold generals c2 b4. Similarly, feature weights b2 c2 h6,b2 c2 b3, b2 c2 a3, b2 b1 c2, b2 c2 a2, b2 d1 c2 indicate two gold generalsking b2. Feature weight d2 b2 f3 indicates black king d2opponents two gold generals b2 f3. Similarly, feature weightsd2 f3 b3 d2 f3 c4 indicate opponents two gold generals kingd2. Here, value divided 25 .rate calculated excluding positions one legal move, positionseasy checkmate sequence identified shallow-depthsearch. Tied values counted, either.performances MMTO, comparison training, variations comparedcase learning eAB . see figure agreement rates comparisontraining constant-step modification unstable substantially lowerMMTO. also see reuse-of-PV modification increases stabilityreduces step length 0.031 0.01 reduces computation time learningalmost 32 times reduces number time-consuming PV updates.MMTO full evaluation function eABCD highest rate (37%). largescale optimization weight vector wD increased level agreement 200 iterations.543fiHoki & Kanekowithout constraintconstraintPawn value140120100213 4 5 6210Iteration3 4 5 62100Figure 6: Effect constraint term MMTO (eAB ).computation took week using Intel X5690 workstation. agreement ratiotest set converged 100 iterations. However, feature weights converge.w ) Eq. (9) improves stability MMTOFigure 6 shows constraint JC (wresponse pawn-value changes eAB learning. see value keepsw ) turned converges 100 iterationsincreasing JC (wconstraint turned on. One feature weights overflowed comparison trainingeABC , another reason results eABC shown comparisonw ) little effect learning eAB ,training. regularization term JR (wimprovement agreement rates MMTO mainly due use constraintw ) grid-adjacent updates.JC (ww ) important optimizing larger weight vectors. FigThe regularization term JR (ww ) Eq. (4) improves weight vector enlarged evaluationure 7 shows JR (wfunction eABCD . Without regularization term, objective function value rateagreement training set increase number iterations. However,also linear increment absolute value weight vectors, distortsrate agreement test set 50-th iteration. 200-th iteration,0.2% components w zero. hand, 96.3% componentsw zero regularization term. results indicate MMTO withoutregularization suffers overfitting training set large-scale weight vectorused. similar effect regularization also occurs MMTO used eABClearning, though effect smaller eABCD .4.4 Improvements Strengthanalyze relationship agreement rate strength, programs learned MMTO comparison training (Figure 5) play gamesreference shogi program many times. reference program version GPS Shogireleased 2008 (Kaneko, 2009). open source program finalist pastworld computer shogi championships. completely different evaluation functionmajority parameters hand tuned. version GPS Shogiserves reference program popular game server shogi programs4 . matchesfollows: reference program (4 105 nodes/move) vs. four learned programs,4. http://wdoor.c.u-tokyo.ac.jp/shogi/, last access: 2013 (in Japanese).544fiObjective functionLarge-Scale Optimization Evaluation Functions Minimax Search0.060.050.040.030.02Agreement (%)60l1-regularizationwithout l1-regularization5550training set45test set4010B| |+| |+| |10C3511101092134 5 621034 5 62100IterationFigure 7: Effect regularization term MMTO (eABCD ).reference program (2105 nodes/move) vs. two learned programs evaluationfunction eA eAB , reference program (8 105 nodes/move) vs. two learnedprograms evaluation functions eABC eABCD . 500 games playedmatch. weight vectors obtained 1, 2, 4, 8, 16, 32, 48, 64, 80, 96, 112, 128, 144iterations tested learning configuration. Thus, total 8 13 500 = 52, 000games played. learned programs searched 4 105 nodes per move. programsran single thread searched similar numbers nodes second.measured playing strength terms Elo rating, popular wayrepresent relative strength two-player games. winning probability twoplayers estimated 1/(1 + 10d/400 ), difference ratings.example, rating player higher player B 150, winningpercentage player 70%. Here, ratings determined using maximumlikelihood estimation games.Figure 8 shows Elo rating player. see MMTO eAB significantly outperformed comparison training initial feature weights.MMTO used eAB , winning percentage reference (400k/move) stably increased 11.2% (1, 800 Elo points) 59.4% (2, 210 Elo points). contrast, comparison545fiElo RatingHoki & Kaneko25002400230022002100200019001800170016001500MMTO (ABCD)MMTO (ABC)MMTO (AB)Comparison training (AB)Reference (800k)Reference (400k)Reference (200k)110Iteration100Figure 8: Improvements strength (Elo rating) achieved MMTO comparison training.OpponentPlayer 1Player 2Depth 294 2%77 3%Depth 389 3%75 3%Depth 482 3%77 3%Depth 585 3%82 3%Depth 678 3%81 3%Depth 781 3%85 3%Depth 878 3%84 3%Table 3: Winning percentages program learned game tree search variousdepths. Opponent player 1 program search depth reduced1, opponent player 2 also program uses weight vectorlearning.training 19.5% (1, 910 Elo points) games. results shown Figs. 58 indicate MMTO outperforms comparison training.large number features also contributed playing strength programslearned MMTO. Although eABC showed small improvement terms agreementrate Elo rating, eABCD consistently yielded significant improvements two criteria. Thus, concluded MMTO scales well forty million features. Notecomputational cost eABCD reasonably small practical game play.number features appear position 2, 800 less even totalnumber features forty million. Also, summations Table 2 maintained incremental manner program makes unmakes move. sortfeature design similar famous Othello program (Buro, 2002). result,Bonanza using eABCD searched 3 106 nodes/sec Intel Xeon X5680 12threads. speed slower many chess programs, averagestrong shogi programs. addition, found Bonanza using eABCD trainedMMTO played better comparable top shogi programs actualtournaments. details discussed Section 4.6.Two additional fixed-depth self-play experiments conducted see evaluationfunctions trained using shallow searches (depth 1 quiescence search) effectivedeep searches. Table 3 shows winning percentages learned program various546fiLarge-Scale Optimization Evaluation Functions Minimax Searchsearch depths game play. learned program eABCD evaluation function yielded200-th iteration (Figure 5). winning percentages program(player 1) search depth reduced 1 around 80%. Thus, seedeeper learned program searched, stronger program was. Tesauro (2001) alsoreported similar results using comparison training. addition, winning percentage80% program (player 2) searched depth used eABC200-th iteration. Thus, use eABCD trained 200 iterations effectiveeven program searched deeper. Here, winning percentages computedthousand games (Seventy-six games less ending draws exceeding 300 movescounted). Fifty megabytes memory assigned transposition tableprogram. uncertainties indicated 3 estimated conducting two-sided testsignificance level 5% one-thousand games.4.5 Numerical Stability Convergenceinvestigated continuity partial differentiability objective functionconvergence feature weights empirical manner. forward pruning techniques game tree searches speed MMTO practical applications, methodsalways maintain continuous search values, shown Appendix A.4. Moreover,objective function contains large number search values. means difficultestimate properties theoretical manner.make empirical investigation manageable, used smallest evaluationfunction eA deals thirteen shogi piece values. Moreover, reduced numbergame records 1, 000; game records 98, 224 desired moves Z P = 7, 900, 993move pairs removing duplications handicapped games.4.5.1 Surface Objective Functioninvestigated function surface main part objective function J(P, w )MMTO Eq. (4) generating contour maps millions sampling vectors w .Note contour line (isovalue surface) curve along functions takevalue. contour lines certain properties: gradient functionperpendicular lines, magnitude gradient large two linesclose together. addition, closed-loop contour line indicates location localminimum maximum.Two thirteen piece values weight vector w sampled order drawcontour maps two-dimensional functions interval 5 piece value.remaining eleven pieces assigned reasonable values; 118 (pawn), 273 (lance), 318(knight), 477 (silver general), 562 (gold general), 620 (bishop), 734 (rook), 485 (promotedpawn), 387 (promoted lance), 445 (promoted knight), 343 (promoted silver), 781 (promotedw ) ignored wbishop), 957 (promoted rook). constraint term JC (ww ) turned piece values.could freely changed regularization term JR (wnominal depth 1 search, together quiescence search, used.analyzed two pairs: hgold, bishopi, hpawn, promoted lancei. Figure 9 showsenlargement contour map J(P, wgold , wbishop ). contour interval 5 104 .map computed ranges [200, 1100] bishop [100, 930]547fiHoki & Kaneko(3) bishop=pro_bishop(4) bishop=dragon(5) gold=bishop(2) bishop=rook(1) bishop=silverGold general weight(6) gold=pro_bishop(8) gold=rook700600x x500400400Objective function(7) gold=pro_rook8000.164(9) gold=silver500(1) (5)600 700 800Bishop weight(2)(9)0.1620.160900(5) (6)(8)(7)(3) (4)0.158400 500 600 700 800Bishop weight500 600 700 800 900Gold general weightFigure 9: (Upper panel) Enlarged contour map J(P, wgold , wbishop ). dashed linesindicate critical boundaries two-dimensional functionpartially differentiable. two minima indicated x. (Bottom panel)Cross sections contour map. left one shows intersectionmap line wgold = 560, shows wbishop = 620.gold general. Note function simply increases interestingstructures outside enlarged map. Figure 10 shows enlargement contourmap J(P, wpawn , wpro lance ). contour interval 1 103 . map computedranges [10, 500] pawn [200, 700] promoted lance.see maps local minima within reasonable rangessudden changes function values. Although function depends largenumber empirical search values, s(p, w ), approximately continuous amenableoptimization basis gradients approximated MMTO.hand, maps illustrate three difficulties. first difficulty clearedges contour lines. indicate function partially differentiablepoints edges. dashed lines maps critical boundariesprofit loss ratio material exchanges inverts itself. example, silver usually548fiLarge-Scale Optimization Evaluation Functions Minimax Search(1) pro_lance=lance (2) pro_lance=knight (3) pro_lance=silver(4) pawn=silverPawn weight400(5) pawn=knight300(6) pawn=lance(7) lance promotion=pawn200X100200300400X500600700Objective functionPromoted lance weight0.15840.1583(2) (7) (3)0.15820.1581 (1)0.15800.1579200 300 400 500 600 700Promoted lance weight0.200.190.180.170.16(7) (6) (5)(4)100 200 300 400 500Pawn weightFigure 10: (Upper panel) Enlarged contour map J(P, wpawn , wpro lance ). dashedlines indicate critical boundaries two-dimensional functionpartially differentiable. two minima indicated x. (Bottom panel)Cross sections contour map. left one shows intersectionmap line wpawn = 125, shows wpro lance = 450.less valuable bishop, capturing silver becomes profitable capturingbishop bishop value smaller 477. boundary labeled bishop=silverFigure 9. discussed Appendix A, function always partially differentiablecritical boundaries, multiple moves share best value. Noteboundaries theory, e.g., bishop=promoted knight boundary. Whetherboundary visible depends training set evaluation features. addition,boundaries become winding curves non-linear evaluation function used insteadlinear weighted sum.second difficulty, scaling problem, illustrated Figure 10. map,see scales two piece values differ two orders magnitude.is, pawn-value variation five hundred changes function value 0.04, whereaspromoted-lance-value variation five hundred changes function value 4 104 .difference scaling, surface along promoted lance almost flat.property explains pawn value optimized earlier piecescomparison training, shown Figure 3. property ill-scaling disadvantageouscomes optimizing promoted-lance value using naive gradient decent method.549fiHoki & KanekoMethods based second-order partial derivatives approximations Hessian matrixresolve problem; however, behave poorly non-partially differentiable pointsmany boundaries. two difficulties point grid-adjacent update MMTOeffective.third difficulty multiple local minima two maps.means results MMTO depend initial values chance endinglocal rather global minimum. investigate problem nextsubsection 4.5.2.4.5.2 Empirical Convergence Local-Minima Propertiesprevious subsection, examined two-dimensional cross sections functionJ(P, w ). subsection, loosen restriction two thirteen dimensions,sufficiently large express piece values shogi. aim experimentcatch glimpse global map numerical convergences arbitrary initialguesses values pieces.purpose, Monte Carlo sampling initial guess, w (0), carriedenumerate local minima analyze optimized vectors. ran 444 MMTOrandomized initial values. Here, uniformly distributed integer range [0, 32767]assigned vector component, resulting vector scaled satisfyw ) = 0.equality condition g(wFigure 11 shows cosine similarity objective-function value hundred 444runs. Here, cosine similarity weight vector measured relative best vectorwhose objective function smallest among 444 vectors 100 iterations.majority runs, see function values weight vectors convergednumerically 50 iterations. Here, regard iteration procedure convergedfunction values similarities oscillate show neither steady increasedecrease 50-th 100-th iteration. Although convergence almost assuredMMTO thirteen piece values, would difficult achieve feature weightsoptimized. example, Figure 5 shows convergence twothousand iterations using eABCD . 200 iterations took week IntelX5690 workstation, could afford investigate convergence eABCDcurrent hardware. However, 200 iterations nonetheless achieved significant improvementstrength, shown Figure 8.also see trials MMTO ended multiple local minima.Although multiplicity minima generally undesirable optimization,other, favorable properties. first property run MMTO changedweight-vector components sufficient amount. is, cosine similarity444 optimized vectors localized range [0.925, 1], randominitial vectors widely spread (see top panel Figure 12). second propertyweak correlation cosine similarities initial optimizedvectors. means starting better initial vector terms cosine similaritybeneficial (see top panel Figure 12). However, starting better initialvector terms objective function value beneficial (see middle panelFigure 12). third distribution local minima formed structures (see550fiLarge-Scale Optimization Evaluation Functions Minimax Search0.950.900.850.800.98SimilarityCosine similarity weight vector1.000.750.700.970.960.95Objective function0.65Objective function0.300.1700.1650.250.16060 80Iteration0.2021345 6 7 8910Iteration2345 6 7 89100Figure 11: hundred runs MMTO weight vector w consisting thirteen piecevalues. initial vectors set using pseudo-random numbers. insetenlargement showing appearance numerical convergences.top panel shows cosine similarities relative best weight vector.bottom panel shows values objective function.bottom panel Figure 12). is, lower local minimum is, similarbecomes best vector. Moreover, number local minima decreases weightvector gets farther away best.also investigated dependence performance nominal search depthstep (1) shown Figure 2. Similar results terms convergence distributionlocal minima obtained using deeper search nominal depth 2.MMTO depth 2 consumes time MMTO depth 1, number551fiInitial objective functionCosine similarity initial vectorHoki & Kaneko1.00.90.80.70.60.35corr = 0.270.300.250.20corr = -0.06Optimized objective function0.1800.1750.1700.1650.160corr = -0.550.940.960.981.00Cosine similarity optimized vectorFigure 12: Scatter plots 444 trials thirteen-dimensional weight vectors. vectorexpresses thirteen piece values. cosine similarity vector measuredrelative best vector. initial vector consists uniform pseudo-randomnumbers, optimized one 100-th vector MMTO iterationsstarting initial one. inset shows correlation coefficientscatter plot.random initial vectors reduced 78, number iterations reducedsixty sake speed. majority runs, function values weightvectors converged 50 iterations. Figure 13 shows strength (Elo rating) objective552fiLarge-Scale Optimization Evaluation Functions Minimax Search100depth 1 (corr = -0.60)depth 2 (corr = -0.86)Elo rating500-50-100-1500.1500.1550.1600.1650.1700.1750.180Objective functionFigure 13: Scatter plots thirteen-dimensional weight vectors. 444 vectors indicatedcrosses learned nominal depth 1 search step (1), 78vectors indicated squares learned depth 2 search.function value 78 runs depth 2 (squares) 444 runs depth 1 (crosses).Here, Elo ratings identified using maximum likelihood estimation 894, 244random-pairing games (5 104 nodes/move). Elo rating depth 1 17average depth 2 41 average. Also, correlation coefficientElo rating objective function value depth 2 0.86 depth1 0.60. Moreover, compared performance two best vectors gavesmallest objective function values. Here, computed winning probabilitybest results depth 1 2. player allowed use one second move,one core Intel Xeon X5680 fifty megabytes memory assignedtransposition table. excluding two drawn games two games exceeding thousandmoves, obtained 43.6% winning rate program using best resultsdepth 2. results indicate MMTO better depth 2 depth 1.4.6 Performance MMTO Tournament ConditionsMMTO invented developer Bonanza made one best programsshogi. Moreover, ideas behind earlier versions MMTO published Japanese(Hoki, 2006) adopted many developers dramatically changed shogiprograms.One authors started developing Bonanza 2004, published program filesweb 2005, published source codes web 2009 (Hoki, 2013). papergives detailed descriptions evaluation-function learning, whereas literature (Hoki& Muramatsu, 2012) gives detailed descriptions game-tree pruning Bonanza.addition learning method MMTO, Bonanza uses evaluation function eABCDshown Table 2. earlier versions 2009 used subset eABCD modified553fiHoki & Kaneko123452006 MayBonanzaYSSKCC ShogiTACOSGekisashi2007 MayYSSTanase ShogiGekisashiBonanzaBingo Shogi2008 MayGekisashiTanase ShogiBonanzaYSSBingo Shogi2009 MayGPS ShogiOtsuki ShogiMonjuKCC ShogiBonanza123452010 MayGekisashiShuesoGPS ShogiBonkrasBonanza Feliz2011 MayBonkrasBonanzaShuesoGekisashiponanza2012 MayGPS ShogiPuellaTsutsukanaponanzaShueso2013 MayBonanzaponanzaGPS ShogiGekisashiNineDayFeverTable 4: Program names results recent World Computer Shogi Championship.MMTO, earlier version variant MMTO, learning methodinfluenced MMTO used.l2-regularization (Hoki, 2006). Subsequent versions fully evaluate eABCD learned l1regularization.Table 4 shows results World Computer Shogi Championships. Since 2006,performance Bonanza examined several computer shogi tournaments,participant connects server program plays shogi time control25 minutes side. Bonanza received first prize twice, second prize once, thirdprize once. Moreover, players entitled Bonanza Feliz Monju used evaluation functions obtained MMTO. Thus, claim Bonanza uses MMTO,plays better comparable top programs shogi, including commercial ones. method clearly plays level handcrafted shogi programs. Moreover,descriptions learning shogi evaluation functions earlier version MMTOpublished Hoki (2006) Japanese quickly recognized significant advances. fact, shogi program conventional handcrafted evaluation functionsbroken top five last five years tournaments. One interesting caseresults GPS Shogi (Kaneko, 2009), winner 2009 2012 tournaments,source codes available online (Tanaka Kaneko, 2013). 2003 2008,program uses handcrafted evaluation function 2009 used variant MMTOresults dramatically improved. variants MMTO used program differaccordance content policy program. example, Tanase Shogi,runner-up program 2008, used learning method based MMTO handcraftedevaluation functions. Bonkras, ponanza, Puella , NineDayFever also used variants MMTO. excellent results make clear MMTO outperforms conventionalprograms use handcrafted evaluation functions played extremely well recentshogi tournaments.554fiLarge-Scale Optimization Evaluation Functions Minimax Searchnoted versions Bonanza add small amount randomnessgrid-adjacent updates. However, omitted discussion using randomnesspaper clear whether added randomness improved qualityevaluation function not. source codes various versions Bonanza availableonline (Hoki, 2013) source code MMTO two files, learn1.c learn2.c.4.7 Preliminary Experiments Chessfar, discussed performance MMTO shogi. expect MMTOwould effective two-player perfect information games provided certainconditions met: (1) sufficient number game records available, (2) minimaxsearches guided heuristic evaluations effective, (3) analytic partial derivativesevaluation function respect variables available. example, MMTOwould yield interesting results applied game solvedmeans (e.g., van den Herik, Uiterwijk, & van Rijswijck, 2002). Also, would yieldinteresting results game Go Monte-Carlo tree searches effectiveminimax searches guided heuristic evaluation function (Kocsis & Szepesvari, 2006;Gelly & Silver, 2011; Browne, Powley, Whitehouse, Lucas, Cowling, Rohlfshagen, Tavener,Perez, Samothrakis, & Colton, 2012; Gelly, Kocsis, Schoenauer Sebag, Silver, Szepesvari, &Teytaud, 2012). Moreover, simpler learning method (e.g., regression method Othello,Buro, 2002) would preferable MMTO, sufficiently effective.conducted preliminary experiments chess catch glimpse applicabilityMMTO games. Note already evaluation functions chessoutplay grandmasters, whereas none shogi. Thus, might difficultimprove well-crafted chess evaluation functions. experiment, chose opensource program (Crafty) fair implementation chess program (Hyatt, 2013).original evaluation function tightly tuned simple multivariablefunction. Thus, sake simplicity, modify way except addnew linear combination weighted two-pieces-square features. features usedevaluate conditions king another piece, eB Section 4.1.mirror symmetric property described Section 4.1 applied featurespawn exists eighth rank counted. results, total number addedweights w B 39, 312. chess position possesses thirty fewer two-piecessquare features, additional computational time due modification becamealmost negligible help pawn hash table lazy evaluation techniquecome original.training test sets composed using game records Free InternetChess Server (FICS). games played using standard time control servertwo players ratings 2, 600 more. training set P 1, 267, 032 desiredmoves Z P = 33, 619, 904 move pairs removing duplications 13, 440 gamerecords, whereas test set P 101, 982 desired moves Z P = 2, 755, 217 move pairsremoving duplications 1, 000 game records.Figure 14 shows rate agreement test set number correct answerschess problems iteration. Here, sigmoid function set 0.00341,w B ) = 0.156|ww B |.equality constraint used, regularization term JR (w555fiHoki & KanekoAgreement (%)35.2127034.812601250AgreementNumber correct answers34.4234567 8 91234510612407 8 9100Number correct answers1280IterationFigure 14: Improvement rate agreement test set (solid line) numbercorrect answers 2, 180 problems (dashed line) chess. two-piece-squareweights w B adjusted using MMTO.RatingWin1010127933 3%1280148935 3%1490176939 4%1770204943 4%205042 4%Table 5: Dependence strength (winning percentages) learned programsquality (ratings players) training set. uncertainty indicated 3estimated conducting two-sided test significance level 5% 1, 000games.total 2, 180 chess problems Encyclopedia Chess Middlegames (the secondsection 879 problems), Win Chess (300 problems), Winning Chess Sacrifices(1, 001 problems) used (Krogius, Livsic, Parma, & Taimanov, 1980; Reinfeld, 2001,1969). learned program searched 5 104 nodes per problem eight megabytesmemory assigned transposition table. see agreement rate wellnumber correct answers tends improve number iterations grows, thoughdifferences moderate. means MMTO found room improvementwell-implemented chess program. results indicate MMTO useful waylearn heuristic evaluation functions chess, especially one design evaluationfeatures suitable learning.4.8 Data Quality Dependenceassess importance quality game records, conducted additional experiments using game records players various levels experience shogi. Here,eABCD learned using results eABC Figure 5 initial value. resultssummarized Table 5. training set composed records 47, 566rapid time control (30 seconds per move) games played amateurs popular Internetshogi site, Shogi Club 245 . first line table shows ratings amateurplayers. second line shows winning percentages learned evaluation function5. Shogi Club 24, http://www.shogidojo.com, last access: 2013.556fiLarge-Scale Optimization Evaluation Functions Minimax Searchevaluation function trained grandmaster-game records. Here, evaluation function learned 200 iterations. winning percentages computedaveraging results thousand games (About 15 drawn games games exceeding300 moves counted). player allowed use one second one coreIntel Xeon X5680 move, fifty megabytes memory assignedtransposition table. Table 5 shows significance quality training set; usegame records stronger players made program stronger.5. Conclusionpresented method, Minimax Tree Optimization (MMTO), uses game recordsadjust full set feature weights evaluation function two-player game.learning MMTO designed search results match desired moves,e.g., recorded moves grandmaster games. MMTO consists two procedures: (1)shallow heuristic search training positions using current feature weights(2) update guided approximation gradient objective function.new combination simple smooth approximation step function grid-adjacentupdates standard techniques, i.e., gradient guided optimization, constraints, regularization, contributed scalability stability MMTO led showingsubstantial improvements existing methods.performance MMTO demonstrated experiments shogi, variant chesslarger number legal moves. MMTO clearly outperformed existing methods.addition, experimental results rate agreement playing strength indicateMMTO adjust forty million parameters. Possible future work would automatedadjustment step length theoretical convergence analysis.Acknowledgmentsgrateful Dr. Masakazu Muramatsu support work.Appendix A. Notes Continuity Partial DifferentiabilityMinimax Valuesaw Section 4.5 objective function MMTO piecewise smooth surface.Appendix, theoretically discuss continuity partial differentiabilityw ) respect w RN , w vector parametersminimax value vp (wevaluation function e(p, w ) p position. continuity minimax valueensures continuity main part objective function MMTO defined Eq. (5).partial differentiability analysis gives conditions approximation insideMMTO described Section 3.3 valid. first analyze single minimax tree, assumingtree known fixed. Then, extend discussion game-tree-searchmethods possibly explore different trees different w .Definition 1. evaluation function e(, ) (P, RN ) 7 R function, P setpositions target game, R set real numbers, RN N -dimensional557fiHoki & KanekoEuclidean space. evaluation function e(p, w ) continuous respect parameters w position p P w RN . Moreover, evaluation functione(p, w ) partially differentiable respect component w w RN .continuity partial differentiability evaluation function feasible assumptions. Note evaluation based ordinary piece-square tableproperties, recent machine learning evaluation functions (Baxter et al.,2000; Veness et al., 2009; Buro, 2002).Definition 2. theoretical game graph G finite, directed acyclic, connected graphrepresenting possible transitions states target game, node (resp. edge)represents position (resp. move). set nodes G corresponds P; V (G) = P.minimax graph finite connected sub-graph G. convention, use termminimax tree minimax graph even tree. denote set minimaxtrees G T. node called maximizing (resp. minimizing) node correspondingposition maximizing (resp. minimizing) player move. destination edgemaximizing (resp. minimizing) node source edge minimizing(resp. maximizing) node. clearly assume node n single position p,denote evaluation function e(n, w ).Let Lr,T set leaf nodes entire sub-tree Tr Tr rooted node r.omit tree use Lr obvious. denote set immediate successors(or children) node n tree Cn,T Cn . Note Cn = n leaf.standard notation, node (or vertex) graph denoted n V (T ). However,Appendix, omit V (.) write n obvious.w ) value associated node n minimaxDefinition 3. minimax value vn,T (wtree defined recursively tree structure static evaluation functione(n, w ), follows:n leaf,e(n, w )w ) n non-leaf maximizing node,w) =maxcCn,T vc (wvn,T (w(11)wmincCn,T vc (w ) n non-leaf minimizing node.w ) obvious. two minimax values bomit tree use vn (wmaximizing (resp. minimizing) node, say better b > b (resp. b < a).A.1 Continuity Minimax Valuecontinuity minimax value follows continuity evaluation function.w ) continuous respect w minimaxTheorem 4. minimax value vn,T (ww ) = vn,T (ww 0 ), equivalently,tree w RN . is, limw ww 0 vn,T (ww w 0 | < logically impliesw 0 RN > 0, exists > 0 |w0w ) vn,T (ww )| < .|vn,T (wfollowing assertion ordinary properties basic functions maxmin common sense analysis. rather difficult, however, find suitablereference containing it. therefore give proof useful subsequentdiscussion.558fiLarge-Scale Optimization Evaluation Functions Minimax Searchx), ..., fk (xx) continuous functionProposition 5. Let k natural number f1 (xx)) continuous function RN . Similarly, mini (fi (xx))RN 7 R. Then, maxi (fi (xNcontinuous function R .x) continuous, x 0 RN > 0, existsProof. fi (xx x0 | < implies |fi (xx) fi (xx0 )| < . Hence, choose = mini ,> 0 |x00x x | < implies |fi (xx) fi (xx )| < = 1, . . . , k; is,|xx0 ) < fi (xx) < fi (xx0 ) + ,fi (x= 1, . . . , k.Note ai < bi = 1, . . . , k obviously implies maxi ai < maxi bi . Thus,inequalities obtainx0 ) < max fi (xx) < max fi (xx0 ) + ,max fi (xis,x) max fi (xx0 )| < .| max fi (xx). proof similar mini fi (xx).implies continuity maxi fi (xLet r root given tree . Now, prove Theorem 4 basismathematical induction leaf nodes Lr,T root r. is, leaf noden Lr,T , minimax value continuous continuity evaluationw ) = e(n, w ). internal node n, assume continuity holdsfunction; vn,T (wchild c Cn,T . induction hypothesis Proposition 5 ensure continuityw ).vn,T (wA.2 Stability Principal Variationssubsection, showed continuity minimax values continuitymin max functions. Here, show best moves principal variationsstable changes leaves small enough. analyze stability orderdiscuss partial differentiability.+w ), hereafter called best children, denotes set(wDefinition 6. symbol Cn,Tchildren node n tree minimax value n:+w ) = {c Cn,T |vc (ww ) = vn (ww )}.(wCn,T+w ). Here, \ B denotesw ); is, Cn,T \ Cn,T(w(wdenote rest children Cn,Tset difference, i.e., {e|e e/ B}.child considered best choice parent node minimax valuechild parent node. two children share value,w ) contains one child. Otherwise, number nodes Cn+ (ww ) greaterCn+ (wone.Definition 7. Let r root tree T. principal variation (abbreviated PVw ) tree sub-tree obtained closure best childrenshort) (wroot:w ) = {r},0 (w+w ) = {c Cn,Tw ) | n i1 (ww )} > 0,(w(ww) =(w[w ).(wi=0559fiHoki & Kanekon0 2}!n1 2 n2 2 n3-1!n4 7 n5 2 n6-1Figure 15: Example minimax tree (graph) transposition n5++w ) = Cn,Tw ) Cn,Tw ) = n (ww ). Also, denote leavesNote Cn,T(w(w(ww ) L (ww ), is, (ww ) Lr,T .(wExample 8. Figure 15 shows small minimax tree two best children root n0 ;maximizing minimizing nodes denoted boxes circles, respectively. Here,Cn+0 = {n1 , n2 } Cn+1 = {n5 }. principal variation tree {n0 , n1 , n2 , n5 }.Lemma 9. internal node n tree w 0 RN , existsw 1 w 0 | < n , set bestpositive number n w 1 satisfying |w10children node n w subset one w :++w 0 ), w 1 s.t. |ww 1 w 0 | < n .w 1 ) Cn,T(w(wCn,Tw 0 ) empty, assertion trivial.Proof. child values same, i.e., Cn (wOtherwise, let 0 minimum absolute difference best valuew 0 ) vc (ww 0 )| > 0. continuity minimaxvalues, i.e., 0 = mincCn (ww 0 ) |vn (ww 1 w 0 | < n ,values ensures existence n w 1 satisfying |w1010w ) vc (ww )| < 0 /2 also |vn (ww ) vn (ww )| < 0 /2. definitionmaxcCn |vc (w0w ) satisfiesn triangle inequalities, c Cn,T (ww 0 ) vn (ww 0 )|0 |vc (ww 0 ) vc (ww 1 )| + |vc (ww 1 ) vn (ww 0 )||vc (ww 0 ) vc (ww 1 )| + |vc (ww 1 ) vn (ww 1 )| + |vn (ww 1 ) vn (ww 0 )||vc (ww 1 ) vn (ww 1 )| + 0 + 0< |vc (w2211w ) vn (ww )| + 0 .= |vc (ww 1 ) vn (ww 1 )| > 0 0 = 0, namely, vc (ww 1 ) 6= vn (ww 1 ). implies definitionThus, |vc (w+w 1 ).(irrespective whether n max min node) c 6 Cn,T(wDefinition 10. tree stability tree minimum value n amongnodes n , n positive number satisfying Lemma 9. Note minimumvalue > 0 exists finite.Example 11. reference Figure 15, suppose leaf value changes 0.1.w 1 ) vn (ww 0 )| 0.1 internal node n heights 1, 2,Then, proven |vn (w3 order: obvious n4 , n5 , n6 , proven n1 , n2 n3 ,finally n0 . see neither n4 n6 become new best node resultchange.560fiLarge-Scale Optimization Evaluation Functions Minimax Searchpvnu0w1)vn (ww0)(wjw1)vc (w(c Cn+ )/ hw 1 ) (cvc (w/ Cn+ )qw 1 ) maximizing-node n, w 1 changes along i-th comFigure 16: Sketch vn (w0w 1 ) n equals vc (ww 1 ) one old bestponent wi + h w 0 . Here, vn (w+0w ).children c Cn (wA.3 Partial Differentiabilityshow partial differentiability, well partial derivative, minimaxvalue node tree depends principal variations. denote rightleft partial derivatives function RN 7 R point x 0f 0x ) =(xx+f (x01 , . . . , x0i + h, . . . , x0N ) f (x01 , . . . , x0N ),h+0h(12)f 0x ) =(xxf (x01 , . . . , x0i + h, . . . , x0N ) f (x01 , . . . , x0N ).h0h(13)limlimLet us pay attention single parameter xi changes h limit opf0erations. Hereafter, parameters held constant often omitted x+ (x ),x one-dimensional parameter interest. use symbolanalogy partial derivative order forget parametersomitted.w ) treeTheorem 12. node n principal variation (ww ) partial derivative evaluationw RN , exists leaf la L (ww ): vn+ (ww ) = wfunction equals right partial derivative vn (we(la , w ). Similarly,ww ) partial derivative evaluation function equalsexists leaf lb L (ww ), vn (ww ) = wleft partial derivative vn (we(lb , w ).wproof theorem, given end subsection, based stability0 ) |ww 1 w 0 | = |h|best moves. assume w 1 = (w10 , . . . , wi0 + h, . . . , wNsufficiently small Appendix A.3. Consequently, |h| < , node ntree w 0 RN ,1(n:leaf)e(n, w )1 ) (n:maximizing node)1wmaxv(w+0cw )=w )vn (wcCn,T (wmin +w 1 ) (n:minimizing node).w 0 ) vc (wcC(wn,T561(14)fiHoki & Kanekow 1 ) changing h, n maxExample 13. Figure 16 sketches example vn (ww 0 ) h = 0. valueimizing node. three best children value vn (wcontinuously (not always linearly) changes h. best child depends signw 0 ) h less . minimaxh, always one c Cn+ (ww 0 ) sufficiently less (by least 0 ) vn (ww 0 )values children c Cn (wh = 0.w ) givennext goal show right left partial derivatives vn (ww ), respectively.right left partial derivatives one best children Cn+ (wfollowing propositions describe ordinary properties right left limitsbasic functions max min. Similar arguments found comprehensive textbookcalculus. give detailed proof here, however, rather difficult findprecisely assertion textbook.Proposition 14. Let k natural number f1 (x), ..., fk (x) continuousfunction R 7 R. Suppose functions value point x0 , i.e.,fi0maxi fi (x0 ) = mini fi (x0 ), right partial derivative x+ (x ). Then,0right partial derivative minimum maximum fi (x) point x existsequal minimum maximum right partial derivatives fi (x0 ), respectively.maxi fi 0fimini fi 0fi(x ) = max + (x0 ),(x ) = min + (x0 ).++xxxxProof. Let o(h) Landaus symbol, let us use denote residual terms converging000 faster h, i.e., limh+0 o(h)h = 0. Recall fi (x ) = f1 (x ) = 1, . . . , k.positive h,fi 00max fi (x + h) max fi (x ) = max fi (x ) + h + (x ) + o(h) max fi (x0 )xfi= max f1 (x0 ) + h + (x0 ) + o(h) f1 (x0 )xfi 0= h max + (x ) + o(h)x00Eq. (12), function maxi fi (x) point x0 right partial derivative maxiargument applies right partial derivative mini fi (x).fi(x0 ).x+Proposition 15. Suppose functions value point x0fi0functions left derivative x(x ). Then, left partial derivative minimummaximum fi (x) point x0 equal maximum minimum left partialderivatives fi (x0 ):maxi fi 0fimini fi 0fi(x ) = min (x0 ),(x ) = max (x0 ).xxxx562fiLarge-Scale Optimization Evaluation Functions Minimax SearchProof. Using similar algebra proof Proposition 14, find negative h,fi 000max fi (x + h) max fi (x ) = h min (x ) + o(h).xfi0Eq. (13), function maxi fi (x) point x0 left partial derivative mini x(x ).Note min max switched algebra negativity h.argument applies left partial derivative mini fi (x).Lemma 16. Let gi+ (n, w ) =vnw)(wwi+(resp. gi (n, w ) =vnw )) right (resp.(wwiw RN internalleft)w ).partial derivative minimax value vn (wnodew ) tree T, exist right left partial derivativesn principal variation (ww ) respect = 1, . . . , N . right left partialgi+ (n, w ) gi (n, w ) vn (wderivatives are:+maxcC + (ww ) gi (c, w ) (n: maximizing node)n,T+gi (n, w ) =+mincC + (ww ) gi (c, w ) (n: minimizing node)n,TmincC + (ww ) gi (c, w ) (n: maximizing node)n,Tgi (n, w ) =(n: minimizing node).maxcC + (ww ) gi (c, w )n,TProof. prove equalities basis mathematical induction leaf nodesw ), definition evaluation function,Lr,T root r. leaf n L (ww ) clearly continuous partially differentiable respectminimax value vn (wcomponent w RN . internal node n, assume, induction hypothesis,right partial derivative gi+ (c, w ) left partial derivative gi (c, w ) existw 1 ) Cn+ (ww 0 ) |h| < Eq. (14).child c Cn,T . Recall Cn+ (winduction hypothesis Proposition 14,maxcCn+ (ww ) vcwi+mincCn+ (wvcvcw ) vcw ),w ) = minw ).(w(w+++ (w++wwww)w)cCn (wcCn (ww ) = max(wSimilarly, Proposition 15,maxcCn+ (ww ) vcwimincCn+ (wvcvcw ) vcw ),w ) = maxw ).(w(w(w++wwww)w)cCn (wcCn (ww ) = min(ww ), obvious gi+ (n, w ) =Now, prove Theorem 12. leaf n L (ww ), Lemma 16 ensures left= we(n, w ). internal node n (wright partial derivatives gi+ (n, w ) gi (n, w ) given one best children.w )Thus, root r, always exist leaves la lb L (wgi (n, w )gi+ (r, w ) =wigi (r, w ) =e(la , w ),563wie(lb , w ).(15)fiHoki & Kanekog + (n, w 0 ) = 0g (n, w 0 ) = 1wie(a, w 0 ) = 1e(a, w 0 ) = 0ng + (r, w 0 ) = g (r, w 0 ) = 0w0) = 0vr (wrc&bwie(c, w 0 ) = 0e(c, w 0 ) = 0wie(b, w 0 ) = 0e(b, w 0 ) = 0w ) exists w 0 , equal partialFigure 17: Although partial derivative vr (w0derivative PV leaf wi e(a, w ).w )Remark 17. definition, gi+ (n, w 0 ) = gi (n, w 0 ), partial derivative vn (w00w ) satisfyingrespect wi exists point w leaf l L (ww0) =vn (we(l, w 0 ).wiwi(16)w ) respectRemark 18. = 1, . . . , N , partial derivative minimax value vn (w00w 0 ).wi exists w equals wi e(l, w ), l unique element L (ww ) partial derivativeRemark 19. exists tree Tr minimax value vn (w0w 0 )| > 1)respect wi w , even leaves l PV unique (|L (w0give different partial derivatives wi e(l, w ). example sketched Figure 17,partial derivative 1 0 b c.A.4 Game-Tree Search Pruning TechniquesConsider game tree search function takes root position r evaluationw ) minimax valuesfunction parameters w inputs, yields minimax tree TrS (w(wwwvn,Tr (w(w)n).callgame-treesearchstatic,provided yieldsw)r0w )) = V (Tr (ww )), root r. Then,constant tree respect w , i.e., V (Tr (ww ) yielded static game-treetheorems 4 12 apply minimax value vr,TrS (wsearch. example, fixed-depth minimax search minimax search considering limitedtypes moves (e.g., capture promotion) static game-tree search. minimax searchstand pat used quiescence search (Beal, 1990) static, too. Note standpat node n equivalent virtual move adding evaluation function e(n, w )w ) Eq. (11), even n leaf node.candidate node value vn (wpruning techniques incorporated, part tree pruned explored.0w ) TrS (ww ) yieldedConsider static search S, pruning 0 , tree TrS (w0. call pruning conservative, provided yields minimax valuew ) = vr,T S0 (ww ). Theorem 4 applies minimaxroot r w RN : vr,TrS (ww ) (wrwvalue root r, vr,T S0 (w(w),yieldedstaticgame-tree search conservativew)rpruning. Standard pruning (Knuth & Moore, 1975) conservative pruning. However,many pruning techniques, e.g., static exchange evaluation (Reul, 2010), (extended) futilitypruning (Heinz, 1998), null move pruning (Adelson-Velskiy et al., 1975), late movereductions (Romstad, 2010), prune sub-tree without prove sub564fiLarge-Scale Optimization Evaluation Functions Minimax Searchtree irrelevant minimax value root. Thus, pruning techniquesgenerally conservative.A.5 Summaryminimax value root tree explored game-tree search wellconfigured pruning techniques continuous. result suggests continuityobjective function MMTO Eq. (4), empirically observed Section 4.5.partial differentiability, Theorem 12 suggest feasible consider leavesprincipal variations search tree. one principal variation, statedRemark 18, use partial derivative unique leaf introduced Section 3.3correct. Otherwise, i.e., multiple principal variations, partial derivativemay exist different partial derivative one leaves, statedRemark 19. Although frequency cases depends target gameevaluation features, almost negligible experiments discussed previous work(Kaneko & Hoki, 2012).ReferencesAdelson-Velskiy, G. M., Arlazarov, V. L., & Donskoy, M. V. (1975). methodscontrolling tree search chess programs. Artificial Intelligence, 6 (4), 361 371.Akl, S. G., & Newborn, M. M. (1977). principal continuation killer heuristic.Proceedings 1977 Annual Conference, ACM 77, pp. 466473, New York, NY,USA. ACM.Anantharaman, T. (1997). Evaluation tuning computer chess: Linear discriminant methods. ICCA Journal, 20 (4), 224242.Baxter, J., Tridgell, A., & Weaver, L. (2000). Learning play chess using temporaldifferences. Machine Learning, 40 (3), 242263.Beal, D. F. (1990). generalised quiescence search algorithm. Artificial Intelligence, 43,8598.Beal, D. F., & Smith, M. C. (2001). Temporal difference learning applied game playingresults application shogi. Theoretical Computer Science, 252 (1-2), 105119.Bertsekas, D. P., & Bertsekas, D. P. (2008). Nonlinear Programming (2nd edition). AthenaScientific.Bjornsson, Y., & Marsland, T. A. (2002). Learning control search extensions. Caulfield,H. J., Chen, S.-H., Cheng, H.-D., Duro, R. J., Honavar, V., Kerre, E. E., Lu, M.,Romay, M. G., Shih, T. K., Ventura, D., Wang, P. P., & Yang, Y. (Eds.), JCIS, pp.446449. JCIS / Association Intelligent Machinery, Inc.Browne, C., Powley, E., Whitehouse, D., Lucas, S., Cowling, P., Rohlfshagen, P., Tavener,S., Perez, D., Samothrakis, S., & Colton, S. (2012). survey monte carlo treesearch methods. Computational Intelligence AI Games, IEEE Transactionson, 4 (1), 143.565fiHoki & KanekoBuro, M. (2002). Improving heuristic mini-max search supervised learning. ArtificialIntelligence, 134 (12), 8599.Buro, M., Long, J. R., Furtak, T., & Sturtevant, N. R. (2009). Improving state evaluation,inference, search trick-based card games. IJCAI, pp. 14071413.Buro, M. (1995). Statistical feature combination evaluation game positions.Journal Artificial Intelligence Research, 3, 373382.Campbell, M., Hoane, Jr., A. J., & Hsu, F.-h. (2002). Deep Blue. Artificial Intelligence,134 (12), 5783.Chellapilla, K., & Fogel, D. (1999). Evolving neural networks play checkers withoutrelying expert knowledge. Neural Networks, IEEE Transactions on, 10 (6), 13821391.Coulom, R. (2007). Computing Elo Ratings move patterns game go. ICGAJournal, 30 (4), 198208.Coulom, R. (2012). Clop: Confident local optimization noisy black-box parameter tuning.Herik, H., & Plaat, A. (Eds.), Advances Computer Games 13, No. 7168 LNCS,pp. 146157. Springer-Verlag.Duchi, J., Hazan, E., & Singer, Y. (2011). Adaptive subgradient methods online learningstochastic optimization. Journal Machine Learning Research, 12, 21212159.Fawcett, T. E. (1993). Feature Discovery Problem Solving Systems. Ph.D. thesis, Department Computer Science, University Massachusetts, Amherst.Furnkranz, J. (2001). Machine learning games: survey. Machines learn playgames, pp. 1159. Nova Science Publishers, Commack, NY, USA.Gelly, S., Kocsis, L., Schoenauer M., Sebag, M., Silver, D., Szepesvari, C., & Teytaud, O.(2012). grand challenge computer go: Monte carlo tree search extensions.Commun. ACM, 55 (3), 106113.Gelly, S., & Silver, D. (2011). Monte-carlo tree search rapid action value estimationcomputer go. Artificial Intelligence, 175 (11), 18561875.Gomboc, D., Buro, M., & Marsland, T. A. (2005). Tuning evaluation functions maximizing concordance. Theoretical Computer Science, 349 (2), 202229.Heinz, E. A. (1998). Extended futility pruning. ICCA Journal, 21 (2), 7583.Heinz, E. A. (1999). Adaptive null-move pruning. ICCA Journal, 22 (3), 123132.Hoki, K. Bonanza computer shogi program.. http://www.geocities.jp/bonanza_shogi/ Last access: 2013. Japanese.Hoki, K. (2006). Optimal control minimax search results learn positional evaluation.11th Game Programming Workshop (GPW2006), pp. 7883, Kanagawa, Japan.Japanese.Hoki, K., & Kaneko, T. (2012). global landscape objective functions optimization shogi piece values game-tree search. van den Herik, H. J., &Plaat, A. (Eds.), Advances Computer Games 13, No. 7168 LNCS, pp. 184195.Springer-Verlag.566fiLarge-Scale Optimization Evaluation Functions Minimax SearchHoki, K., & Muramatsu, M. (2012). Efficiency three forward-pruning techniques shogi:Futility pruning, null-move pruning, late move reduction (LMR). EntertainmentComputing, 3 (3), 5157.Hsu, F.-h., Anantharaman, T. S., Campbell, M. S., & Nowatzyk, A. (1990). Deep Thought.Marsland, T. A., & Schaeffer, J. (Eds.), Computers, Chess, Cognition, pp.5578. Springer-Verlag.Iida, H., Sakuta, M., & Rollason, J. (2002). Computer shogi. Artificial Intelligence, 134 (12), 121144.Kaneko, T. (2009). Recent improvements computer shogi GPS-Shogi. IPSJ Magazine, 50 (9), 878886. Japanese.Kaneko, T., & Hoki, K. (2012). Analysis evaluation-function learning comparisonsibling nodes. van den Herik, H. J., & Plaat, A. (Eds.), Advances ComputerGames 13, No. 7168 LNCS, pp. 158169. Springer-Verlag.Knuth, D. E., & Moore, R. W. (1975). analysis alpha-beta pruning. ArtificialIntelligence, 6 (4), 293326.Kocsis, L., & Szepesvari, C. (2006). Bandit based monte-carlo planning. Machine Learning: ECML 2006, Vol. 4212, pp. 282293. Springer.Krogius, N., Livsic, A., Parma, B., & Taimanov, M. (1980). Encyclopedia Chess Middlegames: Combinations. Chess Informant.Levinson, R., & Weber, R. (2001). Chess neighborhoods, function combination, reinforcement learning. Marsland, T. A., & Frank, I. (Eds.), Computer Games,No. 2063 LNCS, pp. 133150. Springer-Verlag.Marsland, T. A. (1985). Evaluation function factors. ICCA Journal, 8 (2), 4757.Marsland, T. A., & Campbell, M. (1982). Parallel search strongly ordered game trees.ACM Computing Surveys, 14 (4), 533551.Nitsche, T. (1982). learning chess program. Advances Computer Chess 3, pp.113120. Pergamon Press.Nocedal, J., & Wright, S. (2006). Numerical Optimization. Springer-Verlag.Nowatzyk, A. (2000). http://tim-mann.org/DT_eval_tune.txt.Pearl, J. (1980). Scout: simple game-searching algorithm proven optimal properties.Proceedings First Annual National Conference Artificial Intelligence,pp. 143145.Reinefeld, A. (1983). improvement scout tree search algorithm. ICCA Journal,6 (4), 414.Reinfeld, F. (1969). 1001 Winning Chess Sacrifices Combinations. Wilshire BookCompany.Reinfeld, F. (2001). Win Chess (Dover Books Chess). Dover Publications.Reul, F. (2010). Static exchange evaluation -approach. ICGA Journal, 33 (1), 317.567fiHoki & KanekoRomstad, T. Introduction Late Move Reductions. http://www.glaurungchess.com/lmr.html, Last access: 2010.Russell, S. J., & Norvig, P. (2002). Artificial Intelligence: Modern Approach (2nd Edition).Prentice Hall.Schaeffer, J. (1986). Experiments search knowledge. Ph.D. Thesis, DepartmentComputing Science, University Waterloo, Canada.Schaeffer, J. (1989). history heuristic alpha-beta search enhancements practice.IEEE Transactions Pattern Analysis Machine Intelligence, PAMI-11 (1), 12031212.Schaeffer, J., Hlynka, M., & Jussila, V. (2001). Temporal difference learning appliedhigh-performance game-playing program. IJCAI01: Proceedings 17thinternational joint conference Artificial intelligence, pp. 529534, San Francisco,CA, USA. Morgan Kaufmann Publishers Inc.Silver, D., & Tesauro, G. (2009). Monte-carlo simulation balancing. ICML 09: Proceedings 26th Annual International Conference Machine Learning, pp. 945952.ACM.Sutton, R. S., & Barto, A. G. (1998). Reinforcement Learning: Introduction (AdaptiveComputation Machine Learning). MIT Press.Tanaka, T., & Kaneko, T. GPS Shogi.. http://gps.tanaka.ecc.u-tokyo.ac.jp/gpsshogi/ Last access: 2013. Japanese.Tesauro, G. (2001). Comparison training chess evaluation functions. MachinesLearn Play Games, pp. 117130. Nova Science Publishers.Tesauro, G. (2002). Programming backgammon using self-teaching neural nets. ArtificialIntelligence, 134 (12), 181199.Tibshirani, R. (1996). Regression shrinkage selection via lasso. J. Royal. Statist.Soc B, 58 (1), 267288.Tsuruoka, Y., Yokoyama, D., & Chikayama, T. (2002). Game-tree search algorithm basedrealization probability. ICGA Journal, 25 (3), 145152.Ugajin, T., & Kotani, Y. (2010). Learning evaluation function based tree strap shogi.15th Game Programming Workshop, pp. 114118. Japanese.van den Herik, H. J., Uiterwijk, J. W. H. M., & van Rijswijck, J. (2002). Games solved:future. Artif. Intell., 134 (1-2), 277311.van der Meulen, M. (1989). Weight assessment evaluation functions. Beal, D. (Ed.),Advances in. Computer Chess 5, pp. 8189.Veness, J., Silver, D., Uther, W., & Blair, A. (2009). Bootstrapping game tree search.Advances Neural Information Processing Systems 22, pp. 19371945.Zobrist, A. L. (1990). new hashing method application game playing. ICCAJournal, 13 (2), 6973.568fiJournal Artificial Intelligence Research 49 (2014) 323-361Submitted 08/13; published 02/14Symmetric Subgame-Perfect EquilibriaResource AllocationLudek CiglerBoi Faltingsludek.cigler@epfl.chboi.faltings@epfl.chArtificial Intelligence LaboratoryEcole Polytechnique Federale de LausanneCH-1015 Lausanne, SwitzerlandAbstractanalyze symmetric protocols rationally coordinate asymmetric, efficientallocation infinitely repeated N -agent, C-resource allocation problems,resources homogeneous. Bhaskar proposed one way achieve 2-agent, 1resource games: Agents start symmetrically randomizing actions, soonchoose different actions, start follow potentially asymmetric convention prescribes actions on. extend concept conventiongeneral case infinitely repeated resource allocation games N agents Cresources. show convention, exists symmetric subgame-perfectequilibrium implements it. present two conventions: bourgeois, agentsstick first allocation; market, agents pay use resources,observe global coordination signal allows alternate different allocations. define price anonymity convention ratio maximumsocial payoff (asymmetric) strategy profile expected social payoffsubgame-perfect equilibrium implements convention. showprice anonymity bourgeois convention infinite, market convention decreasesprice reducing conflict agents.1. Introductionmany situations, agents coordinate use resource. One wireless channel used one device, one parking slot may occupied one vehicle,etc. problem often, agents identical preferences: Everyone prefersaccess rather yield. Similarly, everyone prefers parking slot rather leavecar home. However, multiple agents try use one resource simultaneously,collide everyone loses.Consider simple example: two agents want access single resource. describeproblem game. agents two actions: yield (Y ) access (A). agentyields, gets payoff 0. agent accesses resource agentyields, gets payoff 1. agents access resource time,incur cost > 0.normal form game looks follows:c2014AI Access Foundation. rights reserved.0, 01, 00, 1,fiCigler & Faltingssymmetric game, two efficient Nash equilibria (NE) asymmetric:either one agent yields one accesses resource, vice versa.symmetric equilibrium outcome mixed NE agents access resource1probability Pr(A) := ||+1. However, mixed equilibrium efficient,expected payoff agents 0.Asymmetric equilibria symmetric games undesirable two reasons: First,fair. example, one agent access resource. Second, coordinatingasymmetric equilibrium difficult. Imagine agents identicalanonymous, i.e. cannot observe identity, identity agent.cannot prescribe different strategy agents. Agents peer-to-peerfile-sharing networks assumed anonymous (Chothia & Chatzikokolakis, 2005),well agents wireless sensor networks (Durresi, Paruchuri, Durresi, & Barolli,2005).Consider following example: Millions wireless sensors producedpipeline. take two randomly, put room. onefrequency sensors transmit measurements. sensor knowtransmit stay quiet? factory could program half sensorstransmit odd slots, half transmit even slots. Nevertheless,would likely odd-even pair sensors, would pairsensors transmit time.Aumann (1974) proposed notion correlated equilibria fixes issuesNash equilibria resource allocation game above. correlated equilibrium(CE) probability distribution joint strategy profiles game. correlationdevice samples distribution recommends action agent play.probability distribution CE agents incentive deviaterecommended action. correlation device takes away burden coordinationanonymous agents. follow strategy: correlationdevice told me.smart correlation device, send agent different privatesignal, available? still reach correlated equilibrium outcome, oneanonymous agents play identical strategies, yet achieve efficient fair allocation? previous work (Cigler & Faltings, 2011), proposed algorithmallows agents learn correlated equilibrium outcome repeated play.considered special case resource allocation problem. proposed use globalcoordination signal multi-agent learning reach symmetric, fair efficient outcome (Wang et al. (2011) later implemented approach actual wireless networkachieved throughput 3 higher standard ALOHA protocols).coordination signal previous work (Cigler & Faltings, 2011) differsmart correlation device assumed Aumann (1974)? Firstly, publiccannot send private signals agents. private signals necessary anonymousagents implement desirable correlated equilibrium single stage resource allocationgame. anonymous agents follow strategy given public signalvalue. Secondly, coordination signal specific game. requirementergodic, i.e. regularly sends possible values. example324fiSymmetric Subgame-Perfect Equilibria Resource Allocationsignal day week, decimal value price certain stock, even noisefrequency.However, previous solution major limitation: learning algorithmequilibrium repeated game. selfish agent could force everyone else yieldaccessing time, securing resource herself. Therefore, paper, focuslearning algorithms equilibria repeated game. proposedistributed algorithm find allocation set resources symmetricfair, also equilibrium. draw inspiration works Bhaskar (2000)Kuzmics, Palfrey, Rogers (2010) symmetric equilibria symmetric repeatedgames.Assume agents play infinitely repeated game, discount future payoffscommon discount factor 0 < < 1. strategy agent mappinghistory play probability distribution actions. goal findsymmetric subgame perfect equilibrium. subgame perfect equilibrium strategy profile(vector strategies every agent) NE history, includingcannot occur equilibrium path.symmetric subgame perfect equilibria study following form:agents start choosing actions randomly, according given probability distribution. soon play (asymmetric) pure-strategy Nash equilibriumgame, adopt convention, prescribes actions deterministicallyon. Bhaskar (2000) gives two examples conventions symmetric 2-agent, 2-actiongames:Bourgeois Agents keep using action played last round;Egalitarian Agents play action opponent last round.paper, extend notion convention arbitrary resource allocation problems N agents C homogeneous resources, show convention,exists symmetric subgame-perfect equilibrium reaches convention. giveclosed form expression calculate subgame-perfect equilibrium bourgeois convention, show small number resources C, convention leads zeroexpected payoff. means price anonymity bourgeois convention .present market convention generalization egalitarian conventionBhaskar (2000). main idea 1) agents pay price successful accessresource, 2) round game, observe global coordinationsignal k {1, . . . , K}, based decide whether resource access.agents decreasing marginal utility accessing often. price helpsdecrease demand resources, global coordination signal effectivelyincreases capacity K-times. show compared bourgeois convention,market convention improves expected payoff. price anonymity therefore finite.paper structured follows: Section 2, review basic notions gametheory, present general definitions conventions implementations.Section 3, formally define resource allocation game N players C resources,show convention, exists symmetric subgame-perfect equilibriumimplements it. Section 4 present two concrete examples convention: bourgeois325fiCigler & Faltingsmarket conventions discuss properties. Section 5 discuss relationshipwork work folk theorems game theory. Finally, Section 6 concludes.2. Preliminariessection, first introduce basic concepts game theory goinguse throughout paper. Then, define notion price anonymity. Finally,give general definition convention implementation.2.1 Game TheoryGame theory study interactions among independent, self-interested agents.agent participates game called player. player utility functionassociated state world. Self-interested players take actions achievestate world maximizes utility. Game theory studies attemptspredict behaviour, well final outcome interactions. Leyton-BrownShoham (2008) give complete introduction game theory.basic way represent strategic interaction (game) using so-called normalform.Definition 1. (Normal form game) finite, N -person normal-form game tupleG = (N, A, u),N set N players;= A1 A2 . . . , Ai set actions available player i. vector= (a1 , a2 , . . . , ) called action profile;u = (u1 , u2 , . . . , uN ), ui : R utility function player assignsaction vector certain utility (payoff).paper, studying symmetric games. games, playersanonymous, thing influences outcome number agentstook certain action.Definition 2. (Symmetric game) say normal-form game G = (N, A, u)symmetric game, permutation vector players : N N, holdsstrategy vector = (1 , 2 , . . . , N ) N,ui (1 , 2 , . . . , N ) = u(i) ((1) , (2) , . . . , (N ) ).Besides playing single deterministic action, player also choose actionrandomly certain probability distribution.Definition 3. (Mixed strategy) mixed strategy selects probability distributionentire action space, i.e. (Ai ). mixed strategy profile vector mixedstrategies player. mixed strategy , define support supp(i )supp(i ) = {ai Ai : (ai ) > 0} .326fiSymmetric Subgame-Perfect Equilibria Resource AllocationGiven game specified using normal form, players choosestrategy? players know strategies others, choose actionquite easily: pick strategy maximizes payoff given everyone elseplaying:Definition 4. (Best response) say mixed strategy player bestresponse strategy profile opponents strategy i0 ,ui (i , ) ui (i0 , ).mentioned earlier, one basic goals game theory predict outcomestrategic interaction. outcome stable therefore, usually calledequilibrium. One requirement outcome equilibrium noneplayers incentive change strategy, i.e. players play best-responsestrategies others. defines perhaps important equilibrium concept,Nash equilibrium:Definition 5. (Nash equilibrium) strategy profile = (1 , 2 , . . . , N ) Nashequilibrium (NE) every player i, strategy best response strategiesothers .Correlated equilibrium extends notion Nash equilibrium. canonical interpretation, assumes central correlation device samples spacepossible outcomes game according probability distribution, recommends action play player. player incentive deviaterecommended action. formal definition follows:Definition 6. (Correlated equilibrium) Given N -player game G = (N, A, u),correlated equilibrium tuple (v, , ), v tuple random variables v =(v1 , v2 , . . . , vN ) domains = (D1 , D2 , . . . , DN ), joint probability distributionv, = (1 , 2 , . . . , N ) vector mappings : Di 7 Ai , playerevery mapping 0i : Di 7 Ai caseX(d)ui (1 (d1 ), 2 (d2 ), . . . , N (dN ))dDX(d)ui 01 (d1 ), 02 (d2 ), . . . , 0N (dN ) .dDequilibrium, agent chooses best strategy himself. Oftentimes, endresult best agents whole. analyze overall utility gameoutcome agents, define social payoff:Definition 7. (Social payoff ) (mixed) strategy Pvector (1 , 2 , . . . , N ), definesocial payoff sum utilities players, Ni=1 ui (1 , 2 , . . . , N ).2.2 Repeated Gamerepeated game, players play given game (for example specified normalform) repeatedly. call normal form game played roundstage game.327fiCigler & Faltings(1)(2)Definition 8. (Future discounted payoff ) Given infinite sequence payoffs ri , ri , . . .player discount factor , 0 < < 1, future discounted payoff playerEi :=X(j)j ri .j=1Definition 9. (Infinitely repeated game) Let G = (N, A, u) normal form game.infinitely repeated version G game G discounting game playersplay normal form game G infinite number rounds. payoff playergame G defined future discounted reward ri ().paper, study symmetric equilibria extended version repeatedgame, so-called augmented game. assume every round game, playersobserve common coordination signal, condition strategyuse. general, coordination signal random integer taken set{0, 1, . . . , K 1}. practice, piece information observable everyone:price certain stock given time, temperature room, day week, etc.signal allow agents coordinate efficiently, timerealistic general correlation device recommends actions agents,assumed definition correlated equilibria.Definition 10. (Augmented repeated game) Let G = (N, A, u) normal formgame, let K := {0, 1, . . . , K 1} set coordination signals. augmented infinitelyrepeated version G game G discounting game players play normalform game G infinite number rounds. round t, players observecoordination signal kt K. coordination signal chosen uniform distributionK. players discount future payoff discount factor .W.l.o.g., always assume repeated games augmented, since ordinaryrepeated game, assume one coordination signal. Therefore,rest paper, whenever refer repeated game strategy etc., alwaysassume game augmented coordination signal.Definition 11. (History repeated game) Let G infinitely repeated gamediscounting. define history ht play round 0t1t1ht := ((a01 , a02 , . . . , a0N ), k0 ), . . . , ((at11 , a2 , . . . , ), kt1 )ati action taken player round t, kt signal playersobserve round t.Definition 12. (Strategy repeated game) strategy repeated gameplayer function history ht currently observed coordination signal ktprobability distribution action space,: (ht , kt ) 7 (Ai ).define Nash equilibrium repeated game waystage game (we treat repeated game normal form gameplayers commit strategy entire game front).328fiSymmetric Subgame-Perfect Equilibria Resource AllocationDefinition 13. (Nash equilibrium repeated game) strategy profile =(1 , 2 , . . . , N ) Nash equilibrium infinitely repeated game playeri,Ei (i , ) Ei (0i , )(1)alternative strategy repeated game 0i . Ei ((i , ), ht , kt ) futurediscounted payoff player adopts strategy players adoptstrategy vector .following text, use notion future discounted social payoff:Definition 14. (Future discounted social payoff ) Given strategy profileinfinitely repeated game G, future discounted social payoff definedE() :=NXEi ().(2)i=1repeated games, exists stronger notion equilibria, refinementstandard Nash equilibrium definition.Definition 15. (Subgame-perfect equilibrium) Let G infinitely repeated gamediscount factor 0 < < 1. strategy vector = (1 , 2 , . . . , N ) subgame-perfectequilibrium game G player i,Ei ((i , ), ht , kt ) Ei ((0i , ), ht , kt )strategy 0i , history ht coordination signal kt .subgame-perfect equilibrium, players play best-response strategy givenhistory play, including histories cannot occur follow equilibriumstrategy beginning. notion subgame-perfect equilibria eliminates waynon-credible threats, equilibria player threatens someone else strategyplayer might prefer avoid supposed executed.2.3 Price AnonymitySection 1, seen simple resource-allocation game, symmetricequilibrium leads significantly lower payoff asymmetric equilibria. Symmetryequilibria natural requirement players same, i.e. anonymous.much social payoff sacrifice requirement symmetry? Inspiredprice anarchy Koutsoupias Papadimitriou (1999), propose priceanonymity measure efficient given symmetric strategy vector (the termprice anonymity used previously different context Bonnet & Raynal, 2011).given symmetric strategy vector stage game , calculate ratiosocial payoff efficient (potentially asymmetric) Nash equilibriumgame, social payoff strategy vector . formal definition follows:329fiCigler & FaltingsDefinition 16. (Price anonymity Nash equilibrium) Let G symmetricgame, let = (1 , 2 , . . . , N ) symmetric Nash equilibrium (that i, j : = j ),let (mixed) Nash equilibrium game G maximum social payoff.define price anonymity strategy vector follows:RG () :=E( ).E()Definition 17. (Price anonymity stage game) Let G symmetric game,) symmetric Nash equilibrium minimal social payoff,let = (1 , 2 , . . . , Nlet (mixed) Nash equilibrium game G maximum social payoff.define price anonymity game G follows:RG :=E( ).E( )infinitely repeated games, define price anonymity subgame-perfectequilibria:Definition 18. (Price anonymity repeated game) Let G symmetric game,let = (1 , 2 , . . . , N ) symmetric subgame-perfect equilibrium minimal socialpayoff, let subgame-perfect equilibrium game G maximum socialpayoff. define price anonymity game G follows:RG :=E().E( )2.4 Conventions Implementationsshown example 2-agent, 1-resource allocation game Section 1,exist symmetric games nevertheless asymmetric efficient equilibria.allow central coordination device, agents play symmetric efficientcorrelated equilibrium selects randomly set efficient Nash equilibria. Without device, stage game, way reach symmetric efficient outcomeequilibrium.However, agents play game repeatedly, use history playcondition strategy. two agents different histories, take differentactions future. first round game though, history emptyeveryone. Therefore, symmetric strategy players randomize order everreach point histories agents distinct.Bhaskar (2000) considered problem playing asymmetric outcomes stagegame using symmetric strategy repeated game. work considers games 2players 2 actions, 1-resource allocation game. idea two players start playing randomly, using probability distribution actions.randomize reach round happen play pure-strategy Nashequilibrium (that is, take different action each). call round asynchronyround. Then, agents start following so-called convention. convention mapsasymmetric pure-strategy Nash equilibrium (potentially asymmetric) strategy vectoragents adopt.330fiSymmetric Subgame-Perfect Equilibria Resource Allocationalready mentioned two basic conventions proposed Bhaskar (2000):bourgeois egalitarian convention. 1-resource allocation game, asynchronyround, one agent chooses action one chooses . call agentchose asynchrony round winner. agent loser. bourgeoisconvention guarantees agents keep playing NE forever after. way,winner forever guaranteed higher payoff loser. egalitarianconvention, players alternate two pure-strategy Nash equilibria. waypayoffs winner loser closer.infinitely repeated game discounting, social payoff depend twothings: discount factor , probability collision, probabilityplayers play action A. big difference winner loserpayoff, losers fight back harder, play preferred actionhigher probability. increase probability collision. egalitarianconvention, payoffs loser closer winner. Therefore, agentscollide less often, also reach asynchrony faster.another example convention, Kuzmics et al. (2010) analyze Nash demandgame. Nash demand game game N players choose N actionslabeled 1, . . . , N . players choose distinct action, player receives payoffequal label chosen action. two players choseaction, every player (including chose action alone) receives zero payoff.pure-strategy Nash equilibrium, players choose different action. Naturally,player prefers equilibrium one chose action N .Nash demand game, also define bourgeois egalitarian conventions.Kuzmics et al. (2010) define three notions payoff symmetry:Ex-ante agents expected payoffs game starts.Ex-post agents expected payoffs asynchrony occurs (regardlesswinner).Strong ex-post agents payoff along realization play.bourgeois convention ex-ante payoff symmetric, since asynchrony occurs, winner gets higher payoff loser. egalitarian convention strongex-post payoff symmetric. fact, Kuzmics et al. (2010) show Nash demandgame, convention socially efficient, must strong ex-post payoff symmetric.intuition order maximize social efficiency, want reach asynchrony fastpossible. possible agents choose actions uniformly random.indifferent action choose momentasynchrony occurs.formally define convention augmented repeated game N agents.Definition 19. (Convention) Let G = (N , A, u)let G repeated version game G.maps vector pure-strategy Nash equilibria= (a1 , a2 , . . . , aK ) vector strategies331symmetric normal form gamedefine convention functiongame G signal valuerepeated game G,fiCigler & Faltingspermutation : N N set players,(((a1 ), . . . , (aK ))) = ((a1 , a2 , . . . , aK ))(3)is, convention permutation permutation convention (here denotesstrategy player i). strategies different coordination signal value.use notation (a) := a(1) , . . . , a(N ) , ((a)) := (1) (a), . . . , (N ) (a)denote permutation history vector using , permutation strategyvectors respectively.definition convention generalizes definition Bhaskar (2000) gave symmetricgames 2 players two actions , . Bhaskar defined convention mappingset Nash equilibrium action profiles {(, ), (, )} set strategiesplayers alternate strategy profiles (, ) (, ) order. definition,convention maps Nash equilibrium stage game strategy profile, providedsatisfies permutation condition.Intuitively, convention prescribes agent potentially different role. problemanonymous agents learn role. call learning algorithmuse implementation convention.Definition 20. (Implementation) Let G infinitely repeated game, letconvention defined game. implementation convention strategyvector infinitely repeated game, function assigns: (ht , kt ) 7 (A1 ) . . . (AN ),satisfies following conditions:Let ht history game time t.1. players already played pure-strategy Nash equilibrium coordination signals k K round t0 < (t0 round playedNE last signal), follow strategy prescribed conventionhistory ht \ ht0 (that is, history round t0 + 1 onwards).2. Otherwise, let kt signal observed current round, let vector =(a1 , a2 , . . . , aK ) ak action vector last round signalk observed (if signal k observed yet, define ak = ). Then, actionsplayers current round depend vector (abusing notation,write (ht , kt ) = (a, kt )), permutation : {1, 2, . . . , N }{1, 2, . . . , N },(,1 ((a), kt ), . . . , ,N ((a), kt )) = ,(1) (a, kt ), . . . , ,(N ) (a, kt ) ,strategy current round depends actions playedlast round signal observed, current coordination signal.Section 3, concerned equilibrium strategies resource allocationgame. is, look symmetric subgame-perfect equilibria. constructequilibria, define concepts equilibrium convention, equilibriumimplementation.332fiSymmetric Subgame-Perfect Equilibria Resource AllocationDefinition 21. (Equilibrium convention) Let G infinitely repeated game, letconvention. say convention equilibrium conventionevery vector pure-strategy Nash equilibria = (a1 , . . . , aK ), (a) vector subgameperfect equilibria game G.Definition 22. (Equilibrium implementation) Let G infinitely repeated game,equilibrium convention, implementation convention . sayequilibrium implementation subgame-perfect equilibrium.3. Resource Allocation Gamesection, first formally define resource allocation game, discussNash equilibria. show equilibrium convention resourceallocation game, exists equilibrium implementation.3.1 Definitionsfirst define resource allocation game, restricted notions uniform convention uniform implementation.Definition 23. (Resource allocation game) resource allocation game GN,C gameN agents. agent access one C identical resources. agent choosesaction ai Ai = {Y, A1 , A2 , . . . , AC }, action ai = means yield, actionai = Ac means access resource c. resources identical, definespecial meta-action ai = A. take action means choose access, chooseresource uniformly random set available resources.payoff function agent defined follows:0ai =1ai 6= Y,ui (a1 , . . . , ai , . . . , ) :=(4)j6= i, aj 6= ai< 0 otherwisegame set pure strategy NEs C agents access resource ciN C agents not. also symmetric mixed strategy NE agentdecides play action probability(! )||Pr(ai > 0) := min C 1 N 1,1 .(5)1 + ||Note high enough values C, agents always choose access. 1Since assume resources identical, agents start followingconvention, expected future payoff shouldnt depend resource1. resource allocation game defined instance class games known potential games(Monderer & Shapley, 1996). (exact) potential game, exists potential function : R00ai Ai , a0i , ai Ai ,(a0i , ai ) (a00i , ai ) = ui (a0i , ai ) ui (a00i , ai ).333fiCigler & Faltingsaccessed Nash equilibrium. therefore restrict so-called uniformconventions:Definition 24. (Uniform convention) Let GN,C resource allocation game, GN,Cinfinitely repeated version. Let convention. say conventionuniform convention, following holds: Let = (a1 , a2 , . . . , aK ) vector purestrategy Nash equilibria coordination signal. Let player i, ci numbersignals player accesses resource action vector a.i, j : ci = cj = Ei ((a)) = Ej ((a)).is, number signals two players access resourcesame, expected payoff remainder game too.Definition 25. (Losers, winners, claimed unclaimed resources) Let GN,Cinfinitely repeated resource allocation game, let ht history play round t,let ak = (ak1 , ak2 , . . . , akN ) action vector played last round signal kobserved.Player winner signal k aki = Ai players j 6= i, akj 6= Ai ;Player loser signal k otherwise;Resource c claimed signal k, exists exactly one player aki = Ac ;Resource c unclaimed signal k otherwise.signal k never observed before, players losers resourcesunclaimed signal k.Definition 26. (Uniform implementation) Let GN,C infinitely repeated resourceallocation game, let uniform convention. uniform implementation definedfollows: Let ht history game time t, let kt signal observedcurrent round.1. players already played pure-strategy Nash equilibrium coordination signals follow strategy prescribed convention .2. Otherwise, let n number losers signal kt , let c numberunclaimed resources signal k. strategy prescribed implementationround following:action vector co occupied resources, nA agents access resource,exact potential function resource allocation game(a) := co + (nA co ).Exact potential games also referred congestion games (Rosenthal, 1973). Finite versionsgames always guaranteed pure-strategy Nash equilibrium. Moreover, agentsreach pure-strategy Nash equilibrium starting arbitrary action vector a0 iterativelyplaying best-response action, one one. players anonymous update strategiessimultaneously, study paper, doesnt hold. Hence, theory potential games cannotapplied scenario study paper.334fiSymmetric Subgame-Perfect Equilibria Resource AllocationAgents follow implementationAsynchronyInitial stateAgents followconventionn=4c=3n=3c=2n=2c=1n=1c=0Figure 1: Learning play convention resource allocation game N = 4 agentsC = 3 resources. state, denote number loserscurrent state n, number unclaimed resources c. Winners denotedblack circles, losers light grey circles. asynchrony state,3 winners one loser. Arrows indicate possible transitionsstates. players reach asynchrony state, start followingconvention next round on.player winner signal kt , access resourcelast time signal kt observed.player loser, access choose access unclaimed resource rpprobability 0 (n,c)1. probability accessing claimed resourceczero.remainder section, instead studying general strategies repeatedgame, limit strategies uniform implementation.Figure 1 shows agents learn follow convention N = 4 C = 3.Assume players adopt convention , use implementation . Initially,losers, implementation prescribes strategy them.agent accesses resource alone, becomes winner accessresource agents reach asynchrony round (a state resource accessedexactly one agent).Definition 27. (Expected payoff functions EA EY ) Let GN,C infinitelyrepeated resource allocation game, let uniform convention equilibriumimplementation. Let ht history game round t, k K,Nash equilibrium reached (and convention activated yet).Let nk number losers signal k K ck number unclaimed resourcessignal k K. Let p = (pn1 ,c1 , . . . , pnK ,cK ) access probability losers335fiCigler & Faltingssignal k K. Let kt currently observed coordination signal. Let w (nw )expected payoff new winner (player loser previous rounds becomeswinner round t) given nw new winners round t. Let l (nw )expected payoff player stays loser, nw new winners round t.Assume player loser signal kt . define expected payoff functions EAEY takes action (or ) signal kt , adopts strategy prescribedimplementation signals:EA (p, kt ) :=min(n,c)X[Pr( wins & nw winners|A)w (nw ) + Pr( loses & nw winners|A)( + l (nw ))]nw =1KX+ Pr(0 winners|A) +E(p,k)+(pE(p,l)+(1p)E(p,l))n,cn,cllllKl=1l6=k(6)min(n,c)EY (p, k) :=XPr(nw winners|Y ) l (nw )nw =1KXEY (p, k) +(pnl ,cl EA (p, l) + (1 pnl ,cl )EY (p, l))+ Pr(0 winners|Y )K(7)l=1l6=k3.2 Existence Equilibrium Implementationready prove uniform equilibrium convention, existsequilibrium implementation.Lemma 1. signal k K, functions EA EY continuous p h0, 1iK .Proof. probabilities Pr(nw winners|A) Pr(nw winners|Y ) continuous.functions EA EY sums products continuous functions, must continuous.Lemma 2. Functions EA EY well-defined k K p h0, 1iK .Proof. fixed p, , functions EA EY define system 2K linear equations.write system (I A)E = b, E = (EA,1 , . . . , EA,K , EY,1 , . . . , EY,K )vector variables corresponding payoff functions, b R2K 2K 2K unitmatrix. matrix defined follows: first K rows correspond variables EA,ksecond K rows correspond variables EY,k .elements row k corresponding EA,k defined as:l = kPr(0 winners|A, pnk ,ck ) K0l = K + kAk,l :=Pr(0winners|A,p)pl K, l 6= knk ,cknl ,clKPr(0 winners|A, pnk ,ck ) K (1 pnl ,cl ) K < l 2K, l 6= K + k336fiSymmetric Subgame-Perfect Equilibria Resource Allocationelements row K + k corresponding EY,k defined as:AK+k,lPr(0 winners|Y, pnk ,ck )0:=Pr(0winners|Y, pnk ,ck )Pr(0 winners|Y, pnk ,ck )KKKpnl ,cl(1 pnl ,cl )l =K +kl=kl K, l 6= kK < l 2K, l 6= K + ksystem equations unique solution matrix non-singular.equivalent saying det(A) 6= 0.PKmatrix diagonally dominant, aii >j=1,j6=i |aij |.P2K0 < < 1, rows matrix sum l=1 Ak,l = Pr(0 winners|A, pnk ,ck )P1 < k K, 2Kl=1 AK+k,l = Pr(0 winners|Y, pnk ,ck ) K < K + k 2K.known diagonally dominant matrices non-singular (Taussky, 1949). Therefore, unique solution E system exists functions EA , EY well-definedfixed p, .Lemma 3. exists p k K, one following true:1. pk = 0 EY (p , k) > EA (p , k);2. pk = 1 EA (p , k) > EY (p , k);3. 0 < pk < 1 EA (p , k) = EY (p , k).p defines symmetric best-response strategy losers.Proof. Fix . show arbitrary p every signal k K,exists p0k satisfies one three conditions Lemma 3 above.contradiction, assume p0k = 0, EY (p0 , k) EA (p0 , k) p0k = 1,EA (p0 , k) EY (p0 , k). fact functions EA EY well-definedcontinuous 0 pk 1, must intersect 0 < p0k < 1.this, must exist vector p k K, conditionsLemma 3 satisfied.Corollary 1. Let GN,C infinitely repeated resource allocation game. uniformequilibrium convention game GN,C , exists equilibrium implementation .illustrate different equilibrium payoffs agents get adopt differentconventions, consider resource allocation game N = 4 agents C = 1 (tosimplify presentation, assume K = 1). Assume round t, resourceclaimed yet, n = 4 losers c = 1 unclaimed resource.agent becomes winner round t, agents adopt extended uniform conventionprescribes strategies on.comparison, assume agents adopt either convention 1 , convention2 . adopt convention 1 , winners expected payoff w1 = 4, losersexpected payoff l = 0. hand, adopt convention 2 , winners1expected payoff w2 = 2, losers expected payoff l2 = 1.337fiCigler & Faltings(a) Convention 1(b) Convention 2Figure 2: Example expected payoff functions resource allocation game N = 4agents, C = 1 resources, cost collision = 2 discount factor = 0.8,1 E 1 expected payoffgiven access probability p. function EAfunctions accessing yielding, agents use extended convention2 E 2 expected payoff functions agents use1 . Similarly, EAextended convention 2 . Convention 1 expected winner payoff w1 = 4,expected loser payoff l = 0. Convention 2 expected winner payoff1w2 = 2 expected loser payoff l2 = 1.equilibrium implementation 1 convention 1 , agents accessresource probability p1 , expected payoff E1 = 0.equilibrium implementation 2 convention 2 , agents access resourceprobability p2 < p1 , expected payoff E2 > E1 = 0.1 E 1 convention , E 2Figure 2 shows expected payoff functions (EA12EY convention 2 ), depending access probability p. seeequilibrium implementation payoff E2 convention 2 higher equilibriumpayoff E1 convention 1 , even though sum winner loser payoffs higherconvention 1 . loser receives positive payoff agents adoptconvention 2 ; agents less likely fight become winner, accessresource lower probability p2 < p1 . way, less collisions,agents receive higher expected social payoff adopt convention 2 .3.3 Calculating Equilibriumsymmetric subgame-perfect equilibrium guaranteed exist, order actuallyplay it, agents need able calculate it. always possible obtain338fiSymmetric Subgame-Perfect Equilibria Resource Allocationclosed form probability accessing resource. Therefore, showcalculate equilibrium strategy numerically.Let p probability vector k signal. Let p0 := (p1 , p2 , . . . , pk = 0, . . . , pK ), i.e.vector p pk set 0. Let p1 := (p1 , p2 , . . . , pk = 1, . . . , pK ). Lemma 3 knoweither EY (p0 , k) > EA (p0 , k), EA (p1 , k) > EY (p1 , k) two functions intersect0 pk 1. Furthermore, know EA (p0 , k) = w (c) since probabilitysuccessfully claiming resource 1 everyone else yields, also EY (p0 , k) = 0.Therefore, EY (p0 , k) > EA (p0 , k) iff w (c) > 0.W.l.o.g, assume w (c) > 0. Algorithm 1 shows calculateprobability vector.Algorithm 1 Calculating equilibrium probabilitiessubset {1, 2, . . . , K}Let system equations/ S, contains two equations E(p, i). One corresponding EA (p, i), oneEY (p, i) (see Equations 6 7).j S, set pj := 1. contains one equation E(p, j), correspondingEA (p, j).system 2K |S| equations 2K |S| variables.Solve numerically system equations .exists solution/ S, 0 pi 1found solutionbreak;endendnumerical algorithm complexity exponential K, therefore suitable small K. Section 4.2.3, show conditions access probabilities easy compute define -equilibrium repeated game. is,agent gain factor deviating prescribed strategy.4. Actual Conventionsprevious section, shown find symmetric way reachconvention, provided agents access resources certain probability.also shown calculate resource access probability every stage game.section, would like show specific examples conventions agentsadopt, discuss properties.4.1 Bourgeois Conventionbourgeois convention simplest one. agent accessed resourcesuccessfully first time, keep accessing forever. say agentclaimed resource. dont need coordination signal implement it, setK := 1.339fiCigler & Faltingsdescribe decision problem point view agent . AssumeN agents C resources. round t, let ct number resourcesclaimed yet, nt := N C +ct number players claimedresource yet. Assume players besides use following strategy:player claimed resource previously, keep accessing it;player hasnt claimed resource yet (she loser), choose accessprobability pct choose actual resource access uniformly random.Definition 28. (Expected payoff function Bourgeois convention) Let p :=(p1 , p2 , . . . , pC ) probability vector, pc probabilitylosers access c unclaimed resources. define expected payofffunction player choose access (play A, choose accesschoose resource uniformly random) yield (play ), respectively:p n11p n1EA (p, c) := 1+ 1 1()c1ccXPr( loses nw = l|A) E(p, c l);+l=0EY (p, c) :=cXPr(nw = l|Y ) E(p, c l);l=0equations, E(p, c) = max {EA (p, c), EY (p, c)}.Lemma 4. p 1 c C, E(p, c) 0.Proof. matter strategy opponents, agent chooses always yield,payoff 0.Lemma 5. Let p probability vector defines strategies losers,let ct number unclaimed resources round t. c ct , EA (p, c) = EY (p, c),c ct , E(p, c) = 0.Proof. ct unclaimed resources round t, every following round t0c ct unclaimed resources (in bourgeois convention, agents never releaseclaimed resources). agent indifferent actions every roundfollowing round t, means indifferent strategy subgameprescribes every round strategy. (expected) payoff strategyprescribes always 0. Therefore, expected payoff subgame strategymust 0 well.purpose problem, unclaimed resources identical. Thereforeparameter losers strategy probability agents decideaccess resource chosen uniformly random. Lemma 5 shows necessarycondition p agent indifferent. following lemma shows p existsunique.340fiSymmetric Subgame-Perfect Equilibria Resource AllocationLemma 6. Assumeat timerct unclaimed resources. Let c ct unclaimed||resources pc = c 1 n1 ||+ 1probability losers play A.1c ct unclaimed resources, agent indifferent yielding accessing.given c, probability unique interval [0, c].Proof. Lemma 5 know agent indifferent (i.e. EA (p, c) = EY (p, c)),must E(p, c) = 0 1 c ct .Definition 28, expected profit agent playing followingbest-response strategy (with zero payoff)pc n11pc n1EA (p, c) = 1+ 1 1()c1c(8)+ Pr( loses nw = 0|A) E(p, c).pc probability losers access. want EA (p, c) =EY (p, c) = 0. holds pc defined lemma above.Function EA decreasing pc interval [0, c], function EY constantly 0.Therefore, intersection unique interval [0, c].Lemma 7. Assume opponents havent claimed resource access resource probability p < pc . best-response agent access.Proof. probability agent claims successfully resource playingp n1Pr(claim resource|A) := 1(9)cprobability increases p decreases. Therefore expected profit playingincreasing p decreases, whereas profit playing stays 0.Theorem 8. Define agents strategy follows: c unclaimed resources,play probability pc := min (1, pc ) (where pc defined Lemma 6). jointstrategy profile = (1 , 2 , . . . , N ) c, c = subgame-perfect equilibriuminfinitely repeated resource allocation game.Proof. Lemma 6, pc < 1, agent indifferent playing playing A,therefore happily follow strategy . Lemma 7, pc = 1 < pc , best responseagent play A, strategy prescribes.Theorem 9. c N, pc = pc , E(p, c) = 0.Proof. proceed induction.c = 0, expected payoff trivially E(p, 0) = 0, free resources.Let j < c, E(p, j) = 0 pc = pc . agent plays , expected payoff clearly 0(it 0 0 future induction hypothesis). agent plays A,expected payoff (by Definition 28):pc n11EA (p, c) := 1c1c(10)Xpc n1Pr( loses nw = l|A) E(p, c l)+ 1 1() +cl=0341fiCigler & Faltingsway pc defined, induction hypothesis E(p, j) = 0j < c, getEA (p, c) := Pr( loses nw = 0|A) E(c, )= Pr( loses nw = 0|A) max{EA (p, c), EY (p, c)}(11)Since Pr( loses nw = 0|A) < 1, must EA (p, c) = 0.Theorem 10. pc < pc , E(p, c) > 0.Proof. Lemma 7 know pc < pc , best response access,E(p, c) = EA (p, c). Lemma 4 know j, E(p, j) 0. pc < pc ,Definition 28 see E(p, c) > 0.Theorem 10 shows enough resources pc 1, expected payoffagents, even access time, positive.Given number agents N , discount factor collision cost , necessarynumber resources c expected payoff positive is:c :=11rn1||1||+ 1(12)Figure 3 illustrates value c depending N , , respectively. Figure 3a showsnumber resources c increases N increases naturally, agents needresources.Figure 3b shows hand increasing discount factor , necessary number resources drops. high , agents almost indifferentwinning winning later. Section 4.2.3, explore ideadetail show high enough delta, strategy prescribes agentsaccess constant probability reach asynchrony -equilibriumresource allocation game.Finally, Figure 3c shows increasing number resources necessarybourgeois convention positive payoff, collision cost increases. increasealmost linear . higher cost collision, lower expectedpayoff accessing EA . bourgeois convention positive expected payoff,need EA > 0 0 p 1.Let us look price anonymity bourgeois convention (as definedDefinition 16).Theorem 11. price anonymity bourgeois convention infinite.Proof. highest social payoff strategy profile achieve N -agent, C-resourceallocation game (N C)Cmax E( ) :=.(13)1achieved every round, every resource accessed exactly one agent.strategy profile obviously asymmetric.342fiSymmetric Subgame-Perfect Equilibria Resource Allocation2520200201515015C*C*10C*10010500505510N1520000.5(a) N10050(b)100(c)Figure 3: Minimum number resources c needed expected payoff bourgeoisconvention positive, depending N , , . One parameter varying,parameters set N = 10, = 0.8, = 2. varying N ,dashed line shows c = N .3.5N=3N=432.5R21.510.10.20.30.40.50.60.70.80.9Figure 4: Market convention: Price anonymity C = 1, K = N , = 0.5 varying .agent knew part bourgeois convention play beginninggame, convention would socially efficient. However, agents anonymous,learn part convention play randomization.bourgeois convention small C relative N , randomizationagents indifferent accessing resource yielding, expectedpayoff zero. Therefore, price anonymity infinite.4.2 Market Conventionsaw bourgeois convention leads zero expected social payoff smallnumber resources. would like improve expected payoff here. bourgeoisconvention, agents receive zero expected payoff demand resourceshigh compared supply. need decrease demand, increasing343fiCigler & Faltings2.5N=3N=42R1.51012345Figure 5: Market convention: Price anonymity C = 1, K = N , = 0.9 varying .supply. often achieved markets. Shneidman et al. (2005) presentreasons markets might appropriate resource allocation.assume following:Agents observe K 1 coordination signals.Agents decreasing marginal utility access resource often.pay fixed price per successful access, point agent prefersaccess resource one signal K. practice, could implemented central authority observes convergence rate agents,dynamically increases decreases price achieve convergence.assumptions define call market convention, winners access claimed resource signals observed first claimed it.price agents pay serves decrease demand. coordination signal effectively increases supply resources K-times, resource allocation maydifferent signal values.know implement convention C 1 resources using symmetricplay (see Section 3). small K, also use Algorithm 1 calculate accessprobabilities. ease exposition, first describe market conventionC = 1 resource. generalize description C > 1 resources.4.2.1 One Resourceagent accesses resource one signal, need K = N signals makesure everyone gets access once.N -agent, 1-resource case, imagine still n agents playing (N n)agents already claimed resource signal. Imagine n agentsobserve one n signals resource claimed.344fiSymmetric Subgame-Perfect Equilibria Resource AllocationAssume agents access resource probability pn . expected payoffaccessing resource agent1EA (pn , n) := (1 pn )1+N 1n+ 1 (1 pn )n1 +EA (pn , n)N (N n)n1(14)expected payoff yielding agentEY (pn , n) := (n 1)pn (1 pn )n2 E(n 1)nEY (pn , n)+ 1 (n 1)pn (1 pn )n2N (N n)(15)pn = 1, accessing resource always lead collision, payoffaccessing negative. pn = 0, accessing resource always claim it,payoff accessing positive. equilibrium, agents indifferentaccessing yielding. Therefore, want find pn EA (pn , n) =EY (pn , n) = E(n).Finding closed form expression pn difficult, use Algorithm 1calculate probability, well expected payoff E(n), numerically (albeit practicesmall K).Figures 4 5 show price anonymity market convention (as definedDefinition 16) varying discount factor , varying cost collision , respectively.Section 4.1, price anonymity C = 1 . contrast, marketconvention price cases finite relatively small.4.2.2 Multiple ResourcesAssume C 1. given round, denote c := (c1 , c2 , . . . , cK )vector resources claimed yet value coordinationsignal k {1, 2, . . . , K}. denote n number players claimedresource yet signal value. Finally, let p := (pn,c1 , pn,c2 , . . . , pn,cK ) vectorprobabilities, pn,ck denotes probability loser access resourcesignal k K, given ck resources available.Corollary 1, know market convention, exists equilibriumimplementation. look like exactly? order able express (albeitnumerically), need define expected payoff functions players receiveaction.345fiCigler & Faltingsnumber losers n, observed coordination signal k vectors p c,define expected payoff functions player takes action , respectively:EA (p, c, n, k) := Pr( wins|A) w + (1 Pr( wins|A)) ()min(ck ,n)+XPr( loses, nw winners|A) E(p, (ck nw , ck ), n nw )nw =1+ Pr(nw = 0|A)EA (p, c, n, k)K+ Pr(nw = 0|A)KKXl=1l6=k(16)(pn,cl EA (p, c, n, l) + (1 pn,cl )EY (p, c, n, l))min(n,c)EY (p, c, n, k) :=XPr(nw winners|Y ) E(p, (ck nw , ck ), n nw )nw =1+ Pr(nw = 0|Y )KXEY (p, c, n, k) +(pn,cl EA (p, c, n, l) + (1 pn,cl )EY (p, c, n, l))Kl=1l6=k(17)equations above, E(p, c, n) expected payoff players observecoordination signal. definedE(p, c, n) :=K1 XE(p, c, n, k).Kk=1winner payoff w defined w := 1 + K(1). winneraccess one signal: current round, future roundprobability K1 .probabilities nw winners cases?start simplest case, Pr(nw winners|Y ), given n agents (includingagent ), ck resources agents except play action probability pk .problem calculating probability similar well-known balls-andbins problem (Raab & Steger, 1998). balls-and-bins problem assumen balls randomly assigned one c bins. goal findprobability bins exactly one ball them. express probability(n, c, i).Ni ways pick balls, place bins binone ball, place remaining n balls remaining c bins randomly,c nNi :=i! (c i)ni346(18)fiSymmetric Subgame-Perfect Equilibria Resource Allocationtotal cn ways arrange n balls c bins. Therefore, probability(n, c, i) total number ways place n balls c bins exactly oneball obtained generalized inclusion-exclusion principle:1(n, c, i) := nc1= nc=min(c,n)Xji(1)j=imin(c,n)Xji(1)j=ijNjjc nj! (c j)njjj(19)min(c,n)njXn! cji c (c j)(1).j (n j)!cnj=icisimplification above, use absorption identity ji jc = ci ji.use function calculate Pr(nw winners|Y )? n 1 agents (other) decide play action probability pk , choose resource accessrandomly. agents choose access resource correspond balls-and-binsproblem. Therefore,Pr(nw winners|Y ) :=n1Xn1pk (1 pk )n1i (i, c, nw ).i=0(20)calculate probability Pr( wins|A), proceed follows. assume w.l.o.gaccesses resource 1. agents (out n 1) choose actionA. need choose resource 1. Therefore,Pr( wins|A) :=n1Xi=0n11n1ipk (1 pk )1c(21)Finally, calculate probability Pr( loses, nw winners|A), useballs-and-bins problem. Given 0 n 1 agents choose action A,0 j agents choose resource agent . remaining(i j) agents face balls-and-bins problem c 1 bins (1 bin already occupiedagent ). Therefore,Pr( loses, nw winners|A) :=n1jX n 1X11 ij1(i j, c 1, nw )pik (1 pk )n1ijcci=1j=1(22)expressed expected payoff functions EA EY explicitly,use Algorithm 1 calculate equilibrium access probabilities expected payoffs.Figures 6 7 show price anonymity market convention C = 3, K = 2N = C K = 6. discount factor grows, price anonymity decreases347fiCigler & Faltings600Price anonymity50040030020010000.10.20.30.40.50.60.70.80.9Figure 6: Market convention: Price anonymity N = 6, C = 3, K = 2, = 0.5varying .2.62.5Price anonymity2.42.32.22.121.91.81.7012345Figure 7: Market convention: Price anonymity N = 6, C = 3, K = 2, = 0.9varying .(note Figure 6 y-axis logarithmic). small , benefitwinning resource right away much higher payoff winning later.hand, gets closer 1, agents dont care whether win later.Since market convention guarantees everyone able access resourcesignal value, 1, expected payoff winner loserssame. Also, 1, cost agents pay learning convention decreasescompared payoff obtain learnt it.increases, price anonymity increases. cost collision directeffect expected payoff functions EA EY . Therefore, expected equilibrium348fiSymmetric Subgame-Perfect Equilibria Resource Allocationpayoff higher cost lower. Changing effect optimalasymmetric outcome though, since agents dont pay costcollisions.4.2.3 -equilibriumCalculating equilibrium access probabilities market convention difficultneed use numerical algorithm, number signals K grows, numberequations grows exponentially. Therefore, would like find access probabilitieseasy compute agents incentive deviate small. Indeed,game theory often interested -equilibria, agent improve payoff> 0.market pricing ensures agent wants access resource one signalvalue. also doesnt depend access probabilities agents, utilityfunctions. agents converge asynchrony round (i.e. pure-strategy NEresource allocation every signal value), future expected payoffK 1,1(23)agent improve payoff deviating since players playing PSNEstage game round.agents havent claimed resource yet play action constantprobability 0 < pconst < 1, expected time reach asynchrony finite.(from properties balls-and-bins problem, see Section 4.3, Raab & Steger,1998). prove following theorem:Theorem 12. Suppose N -agent, C-resource allocation game, agents adoptmarket convention following implementation: agents havent claimedresource yet play action constant probability pconst (we call constantprobability implementation). Let E() expected payoff agent casegiven discount factor . Let E 0 () expected payoff best-response strategyconvention implementation.> 0, exists 0 < 0 < 1 , 0 < 1,E()> 1 .E 0 ()(24)Proof. market pricing, agent wants access one resource onevalue coordination signal. best-response payoff E 0E 0 ()K 1,1(25)matter strategy agents play.agents adopt market convention constant-probability implementation, every round converge PSNE, receive payoff< 0 (the collision cost) 1. reach PSNE, expected payoffK 11349(26)fiCigler & Faltingsstated above. therefore sayE()Xi=01+ K 1Pr(agents reach PSNE steps)11(27)define random variable X X = agents reach PSNEexactly steps. properties expected value, ee(1 E X ) + K 1 E XE().(28)1function (x) := x convex function. Jensens inequality (1906), knowE X E[X] .(29)Therefore,1 E[X] + K 1 E[X]E().E 0 ()K 1(30)expected time E[X] reach PSNE finite doesnt depend ,treat constant. E[X] continuous , monotonous lim1 E[X] = 1,see given > 0, exists 0 < 0 < 1 , 0 < 1,E()> 1 .E 0 ()(31)ensuring agent wants access resource one signal value,market convention makes cooperative strategy previous work (Cigler &Faltings, 2011) almost rational.4.3 Expected Convergence Timesection, analyze expected number rounds agents needconverge perfect allocation resources (one resources used exactly one,collisions). first prove upper bound expected numbersteps convergence bourgeois convention, present experimentsmarket convention.4.3.1 Bourgeois Conventionorder prove convergence bourgeois convention, describe executionMarkov chain. Markov chain describing execution bourgeois conventionN -agent, C-resource allocation game chain whose state round Xt {0, 1, . . . , C},Xt = c means c unclaimed resources round t.interested expected number rounds take Markov chainreach state 0 started state C. called expected hitting time:350fiSymmetric Subgame-Perfect Equilibria Resource AllocationDefinition 29. (Norris, 1998) (Hitting time) Let (Xt )t0 Markov chain statespace I. Given probability space (, , Pr), hitting time subset randomvariable H : {0, 1, . . .} {} givenH () = inf{t 0 : Xt () A}general, expected hitting time set states found solvingsystem linear equations:Theorem 13. vector mean hitting times k = E(H ) = (kiA : I) minimalnon-negative solution system linear equationski = 0 P(32)kiA = 1 + jpk/Aij j/Solving analytically Markov chain however difficult. Fortunately,Markov chain one absorbing state = 0, move statej j, use following theorem derive upper bound hitting time(proved Rego, 1992):Theorem 14. Let = {0}.1 : E(Xt+1 |Xt = i) <> 1,kiA < log +1order use Theorem 14, need calculate expected state E(Xt+1 |Xt = c).Lemma 15. Let Xt = c, let n := N C + c agents claimedn1resource claimedresource yet. Let us denote q(n, c) = pc n 1 pcround agents play subgame-perfect equilibrium strategy vector described above.next expected stateE(Xt+1 |Xt = c) := (1 q(n, c)) cProof. resource i, denote Wi random variable, Wi = 1 resourceclaimed round t, Wi = 0 otherwise. random variable Wi Bernoullidistributed probability q(n, c).next expected state" c#cXXE(Xt+1 |Xt = c) = c EWi = cE[Wi ] = (1 q(n, c)) c,(33)i=1i=1E[Wi ] = q(n, c).following lemmas, denote:=||1|| + 1351(34)fiCigler & FaltingsLemma 16. given collision cost discount factor , exists constant0 < < 1 c n, p < 1.Proof. Accordingdefinition subgame-perfect equilibrium strategy, p := cn11.want p < 1, equivalentn1c 1<1(35)1 n11<(36)c(37)know c n,n11 n1111e .cn(38)therefore set e < , access probability p < 1.Lemma 17. given , exists 0 < < 1 c,E(Xt+1 |Xt = c) (1 ) cProof. prove lemma two cases: p <1 andwhenp = 1.First, let us prove case p < 1, p = c 1 n1 . Therefore, q(n, c) =1 n1 n . shown n,q(n, c) = 1n log .n1let p = 1. Lemma 16 must c > n.n1c1 n11q(n, c) := 11,ncnq(n, c) increasing c.11nn1e .(39)(40)(41)fixed , , constants, set:= min( e , log ).(42)above, proves lemma.Theorem 18. expected time agents converge resource allocationresources claimed O(log C).352fiSymmetric Subgame-Perfect Equilibria Resource AllocationProof. shown express expected convergence time expectedhitting time certain Markov chain.Lemma 17 saw exists c,E(Xt+1 |Xt = c) (1 ) c.combine result Theorem 14 show expected hittingtime state C state 0110kN < dlog 1 Ce +log C = O(log C),(43)1constant.4.3.2 Market Conventionmarket convention, unfortunately difficult express expected numberconvergence steps closed-form expression. However, use linear programmingcalculate expected number convergence steps given parameters N , C, K,.Markov chain market convention K signals C resources looksfollows: state time Vt {0, 1, . . . , C}K , Vtk denotes many resourcesclaimed signal k. initial state V0 V0k = Ck {1, . . . , K}. N C K,Pthe final state Vtk = 0 k. N < C K,final states k{1,...,K} Vtk = C K N .transition probabilities two states Vi Vj , Vi 6= Vj , following:Suppose k : Vjk < Vik l 6= k : Vjl 6= Vil . Let us denote c := Vik , i.e. numberunclaimed resources state Vi signal k, n := N (C Vik ) number agentsclaimed resource signal k state Vi .Pr(Vt+1n1 X n= Vj |Vt = Vi ) :=p (1 pk )nm (m, c, Vik Vjk )Kk(44)m=0Otherwise Vj 6= Vi , Pr(Vt+1 = Vj |Vt = Vi ) := 0.Figure 8 shows expected number rounds converge varying discount factor. Generally, would expect access probability increase increasing , sinceprofit winning resource increases. increase convergencetime. However, experiments influence convergence time negligible,although observe slight increase increases. Figure 9 shows convergencevarying collision cost . close 0, convergence time remains stable. However,high cost , convergence time increases linearly . case, high costcollision drives resource access probability low, agents try avoid collisionscosts.Figure 10 shows expected convergence increase number resources Cnumber agents N proportionally. increase convergence time still sub-linearincrease C.353fiCigler & Faltings7.8Convergence steps7.787.767.747.727.77.687.6600.20.40.60.81Figure 8: Market convention: Expected number convergence steps given N = 6, C = 3,K = 2, = 1.0 varying .5045Convergence steps403530252015105 410210010210410Figure 9: Market convention: Expected number convergence steps given N = 6, C = 3,K = 2, = 0.9 varying .354fiSymmetric Subgame-Perfect Equilibria Resource Allocation1312Convergence steps111098765411.522.53C3.544.55Figure 10: Market convention: Expected number convergence steps given K = 2, = 0.9,= 1.0 varying number resources C agents N = 2 C.C&F11BourgeoisEgalitarian2Marketex-post fair(X)1XXefficientXX?equilibriumXXXTable 1: Properties conventions4.4 Convention Propertiescompare properties following conventions: C&F11, channel allocationalgorithm presented previous work (Cigler & Faltings, 2011); bourgeois egalitarianconventions, presented Bhaskar (2000); market convention, presented above.compare conventions according following properties:Ex-post fairness expected payoff agents even asynchrony?Efficiency convention maximize social welfare among possible conventions?Equilibrium convention equilibrium implementation?Table 1 summarizes properties conventions. C&F11 conventionapproximately ex-post fair. fairness improving number coordination signalsincreases, agents might worse payoff others. hand,efficient, least discounting ( = 1). However, equilibrium1. Fair asymptotically, N .2. 2-agents, 1-resource games.355fiCigler & Faltingsrepeated game. bourgeois convention neither fair efficient, factexpected payoff agents 0 (for small number resources). equilibriumimplementation though, since agents indifferent winner loser.egalitarian convention fair, efficient equilibrium implementation. However,defined games 2 agents 1 resource. Finally, market convention fairalso equilibrium implementation. clearly efficient bourgeoisconvention. Nevertheless, finding efficient convention remains open problem.5. Folk Theorems Symmetric Equilibriaprevious sections, analyzed special kind symmetric equilibriaresource allocation game. agents first followed Markovian implementation,soon play pure-strategy NE, adopted convention. infinitely repeatedgame discounting, set Nash equilibria characterized using so-called folktheorem. name indicates known used wellfirst published, follow version described Fudenberg Maskin (1986).Informally, folk theorem states infinitely repeated game, every feasibleindividually rational payoff vector stage game, exists Nash equilibriumrepeated game average payoffs per round correspond stage gamepayoff vector.payoff vector individually rational Pareto-dominates minimax payoffstage game. player i, minimax payoffvi := min max ui (i , ).(45)simplify notation, Fudenberg Maskin (1986) normalize payoffs) = (0, 0, . . . , 0). Letminimax payoffs, (v1 , v2 , . . . , vNU := {(v1 , . . . , vN )|(a1 , . . . , ) . . . s.t. u(a1 , . . . , ) = (v1 , . . . , vN )},V := convex hull U,V := {(v1 , . . . , vN ) V |vi > 0 i}.set V set feasible payoffs stage games (that is, payoffsachieved playing mixed correlated strategy). set V subset feasiblepayoffs also individually rational.Theorem 19. (Fudenberg & Maskin, 1986) (v1 , . . . , vN ) V , discountfactor close enough 1, exists Nash equilibrium infinitely repeated gamediscounting where, i, average payoff player vi .idea proof follows: agents cycle prescribed sequencegame outcomes achieve desired payoffs. one player deviates, otherspunish playing minimax strategy forever after.focus far finding symmetric equilibrium strategies. folk theorem doesnt say anything whether equilibrium strategy symmetric, evenpayoff vector symmetric. Nevertheless, define another class symmetric356fiSymmetric Subgame-Perfect Equilibria Resource Allocationstrategies infinitely repeated game, one based conventionsimplementations. strategies following form: players follow symmetric(mixed) strategy stage game. one player deviates strategy, playerspunish following minimax strategy. resource allocation game, minimax payoff (0, 0, . . . , 0) achieved mixed strategy Nash equilibrium.Folk theorem, strategy sustained Nash equilibrium repeatedgame (though necessarily subgame-perfect equilibrium).symmetric strategy stage resource allocation game vector access probabilities q = (q1 , q2 , . . . , qC ) qc probability agent access resource c.interested finding access probability vector q achieves highest expectedpayoff.given access probability vector q, expected payoff agent receivesfollows:CXE(q) :=qj (1 qj )N 1 1 1 (1 qj )N 1 ||(46)j=1Theorem 20. resource allocation game N = 2 agents C = 1 resource,resource access probability maximizes expected payoff stage gameq =11.2 1 + ||(47)Proof. calculate derivative expected payoff function Equation 46 N = 2C = 1:E(q)= 1 2q (1 + ||)qSetting first derivative equal 0, getq =11.2 1 + ||Since second derivative2 E(q)= 1 || < 0,2qprobability q local maximum expected payoff function E(q).Corollary 2. resource allocation game N = 2 agents C = 1 resource,highest expected payoff symmetric strategy stage gameE =11.4 1 + ||(48)Corollary 3. resource allocation game N = 2 agents C = 1 resource,price anonymity strategy accesses optimal access probability q4 (1 + ||).357fiCigler & Faltings210Folk theoremMarket conventionR 110010012345Figure 11: Price anonymity symmetric strategy following folk theorem,compared price anonymity market convention N = 3, C = 1varying cost collision .general case resource allocation game N agents C resources,46 (given constraintPC find probability vector maximizes Equation2j=1 qj 1) using method Lagrangian multipliers .P2. goal maximize E(q1 , q2 , . . . , qC ) q0 + Ci=1 qi = 1 qi 0, q0probability agent yields. Lagrangian function(q0 , q1 , . . . , qC , ) := E(q1 , q2 , . . . , qC ) +q0 +CX!qi 1 .i=1first partial derivatives:=q0E:=+qiqi(49)(50)= (1 ||) (1 qi )N 1 qi (1 + ||) (N 1) (1 qi )N 2 || + 1 C:= q0 +CX1.(51)(52)i=1necessary condition solution maximumpartial derivatives LagrangianPfunction 0. Therefore, := 0 q0 := 1 Ci=1 qi . qi , 1 C find solution= 0 using numerical root-finding algorithm. point partial derivativesqizero, compare E(q) (finite) number extreme points.358fiSymmetric Subgame-Perfect Equilibria Resource AllocationFigure 11 compares price anonymity folk-theorem-based symmetric strategyprice anonymity market convention, N = 3 agents C = 1 resource.Since price anonymity folk theorem strategy doesnt depend discountfactor (it needs high enough strategy equilibrium), showgraph varying collision cost . price anonymity folk-theorem strategyorder magnitude higher price anonymity market convention.6. Conclusionspaper, considered symmetric protocols rationally coordinate asymmetric,efficient allocation infinitely repeated resource allocation game discounting N agentsC resources. assumed agents identical, resourceshomogeneous. based work idea Bhaskar (2000): let agents chooseactions randomly, adopt certain convention. generalize workBhaskar arbitrary resource allocation problem N agents C resources.show convention, exists symmetric subgame-perfect equilibriumimplements it. presented two conventions repeated resource allocationgame: bourgeois market convention. defined price anonymity ratioexpected social payoff best asymmetric strategy profile expectedsocial payoff given symmetric Nash equilibrium. showed priceanonymity bourgeois convention infinite (at least small number resources),price anonymity market convention finite relatively small.market convention reduces demand imposing price successful access,time increasing supply agents condition strategyglobal coordination signal k {1, . . . , K}. way, conflict agentsreduced. also showed analytically agents adopt bourgeois convention,converge perfect resource allocation polynomial time.market convention, calculating equilibrium access probabilities difficult.need use numerical algorithm, whose complexity exponential numbercoordination signals K. However, market mechanism already makes sure agentwants access resource one coordination signal. Therefore, showedcooperative solution agents access resources constant probability-equilibrium, given discount factor high enough.future work, would like investigate whether exist efficient conventions market convention (i.e. conventions smaller price anonymity).general, finding optimal convention NP-hard problem (Balan, Richards, & Luke,2011), restricted set infinitely repeated resource allocation games, mightable find optimal convention, similar Thue-Morse sequence (Richman, 2001)used Kuzmics et al. (2010) Nash demand game.Acknowledgementsparticularly thankful David Parkes giving first author unique opportunity spend weeks lab Harvard. Davids openness unparalleledknowledge really helped originate work. would also like thank Kate359fiCigler & FaltingsLarson reading draft paper helping make theoretical analysis muchreadable.ReferencesAumann, R. (1974). Subjectivity correlation randomized strategies. JournalMathematical Economics, 1 (1), 6796.Balan, G., Richards, D., & Luke, S. (2011). Long-term fairness bounded worst-caselosses. Autonomous Agents Multi-Agent Systems, 22 (1), 4363.Bhaskar, V. (2000). Egalitarianism efficiency repeated symmetric games. GamesEconomic Behavior, 32 (2), 247262.Bonnet, F., & Raynal, M. (2011). price anonymity: Optimal consensus despiteasynchrony, crash, anonymity. ACM Trans. Auton. Adapt. Syst., 6 (4), 23:123:28.Chothia, T., & Chatzikokolakis, K. (2005). survey anonymous peer-to-peer filesharing. Embedded Ubiquitous ComputingEUC 2005 Workshops, pp. 744755.Springer.Cigler, L., & Faltings, B. (2011). Reaching correlated equilibria multi-agent learning. 10th International Conference Autonomous Agents MultiagentSystems-Volume 2, pp. 509516. International Foundation Autonomous AgentsMultiagent Systems.Durresi, A., Paruchuri, V., Durresi, M., & Barolli, L. (2005). hierarchical anonymouscommunication protocol sensor networks. Embedded Ubiquitous ComputingEUC 2005, pp. 11231132. Springer.Fudenberg, D., & Maskin, E. (1986). folk theorem repeated games discountingincomplete information. Econometrica, 54 (3), 533554.Jensen, J. L. (1906). Sur les fonctions convexes et les inegalites entre les valeurs moyennes.Acta Mathematica, 30 (1), 175193.Koutsoupias, E., & Papadimitriou, C. (1999). Worst-case equilibria. Proceedings16th annual conference Theoretical aspects computer science, STACS99, pp.404413, Berlin, Heidelberg. Springer-Verlag.Kuzmics, C., Palfrey, T., & Rogers, B. (2010). Symmetric players repeated games: Theoryevidence..Leyton-Brown, K., & Shoham, Y. (2008). Essentials Game Theory: Concise, Multidisciplinary Introduction. Morgan & Claypool, San Rafael, CA.Monderer, D., & Shapley, L. S. (1996). Potential games. Games economic behavior,14 (1), 124143.Norris, J. R. (1998). Markov Chains (Cambridge Series Statistical ProbabilisticMathematics). Cambridge University Press.360fiSymmetric Subgame-Perfect Equilibria Resource AllocationRaab, M., & Steger, A. (1998). Balls Bins Simple Tight Analysis, Vol. 1518Lecture Notes Computer Science, chap. 13, pp. 159170. Springer Berlin Heidelberg,Berlin, Heidelberg.Rego, V. (1992). Naive asymptotics hitting time bounds markov chains. Acta Informatica, 29 (6), 579594.Richman, R. M. (2001). Recursive binary sequences differences. Complex Systems, 13 (4),381392.Rosenthal, R. W. (1973). class games possessing pure-strategy nash equilibria. International Journal Game Theory, 2 (1), 6567.Shneidman, J., Ng, C., Parkes, D. C., Auyoung, A., Snoeren, A. C., Vahdat, A., & Chun, B.(2005). markets could (but dont currently) solve resource allocation problemssystems. USENIX 05: Proceedings 10th USENIX Workshop HotTopics Operating Systems, p. 7.Taussky, O. (1949). recurring theorem determinants. American MathematicalMonthly, 56 (10), 672676.Wang, L., Wu, K., Hamdi, M., & Ni, L. M. (2011). Attachment learning multi-channelallocation distributed OFDMA networks. Parallel Distributed Systems, International Conference on, 0, 520527.361fiJournal Artificial Intelligence Research 49 (2014) 207240Submitted 08/13; published 02/14Selfishness Level Strategic GamesKrzysztof R. AptGuido Schaferk.r.apt@cwi.nlg.schaefer@cwi.nlCentre Mathematics Computer Science (CWI)Networks Optimization GroupScience Park 1231098 XG AmsterdamNetherlandsAbstractintroduce new measure discrepancy strategic games socialwelfare Nash equilibrium social optimum, call selfishness level.smallest fraction social welfare needs offered playerachieve social optimum realized pure Nash equilibrium. selfishness levelunrelated price stability price anarchy invariant positivelinear transformations payoff functions. Also, naturally applies solutionconcepts forms games.study selfishness level several well-known strategic games. allows usquantify implicit tension within game players individual interestsimpact decisions society whole. analyses reveal selfishnesslevel often provides deeper understanding characteristics underlying gameinfluence players willingness cooperate.particular, selfishness level finite ordinal potential games finite,weakly acyclic games infinite. derive explicit bounds selfishness levelfair cost sharing games linear congestion games, depend specific parametersunderlying game independent number players. Further, showselfishness level n-players Prisoners Dilemma c/(b(n1)c), bc benefit cost cooperation, respectively, n-players public goodsgame (1 nc )/(c 1), c public good multiplier, TravelersDilemma game 12 (b 1), b bonus. Finally, selfishness level Cournotcompetition (an example infinite ordinal potential game), Tragedy Commons,Bertrand competition infinite.intelligent way selfishwork welfare othersDalai-Lama11. Introductiondiscrepancy strategic games social welfare Nash equilibriumsocial optimum long recognized economists. One flagship examplesCournot competition, strategic game involving firms simultaneously choose1. (Bowles, 2004, p. 109).c2014AI Access Foundation. rights reserved.fiApt & Schaferproduction levels homogeneous product. payoff functions game describefirms profit presence production costs, assumption priceproduct depends negatively total output. well-known (see, e.g., Jehle &Reny, 2011, pp. 174175) price social optimum strictly higherNash equilibrium, shows competition producers productdrives price down.computer science discrepancy led introduction notionsprice anarchy (Koutsoupias & Papadimitriou, 2009) price stability (Schulz& Moses, 2003; Anshelevich, Dasgupta, Kleinberg, Tardos, Wexler, & Roughgarden, 2008)measure ratio social welfare worst and, respectively, best Nashequilibrium social optimum. originated huge research effort aiming determining ratios specific strategic games possess (pure) Nash equilibria.two notions descriptive sense assess existing situation.Said differently, notions quantify discrepancy social welfare Nashequilibrium social optimum given initial payoff functions. contrast, proposenotion normative sense explains change payoff functionsresolve discrepancy. Intuitively, asking question much socialwelfare needs added players payoff functions individual preferencesbring optimal outcome society. abstract level, approachpropose related one proposed Axelrod (1984, p. 134), chapterPromote Cooperation, cite: excellent way promote cooperationsociety teach people care welfare others.approach draws concept altruistic games (see, e.g., Ledyard, 1995,recently Marco & Morgan, 2007). games players payoff modifiedadding positive fraction social welfare considered joint strategyoriginal payoff. selfishness level game defined infimum0 modification yields social optimum realized pure Nashequilibrium. underlying property monotonic sense 0social optimum pure Nash equilibrium, also case every .Intuitively, selfishness level game viewed measure playerswillingness cooperate. low selfishness level indicates players openalign interests sense small share social welfare sufficientmotivate choose social optimum. contrast, high selfishness level suggestsplayers reluctant cooperate large share social welfare neededstimulate cooperation among them. infinite selfishness level means cooperationcannot achieved means.Notions like price stability price anarchy developed measurequality equilibria. contrast, notion selfishness level regardedmeasure willingness cooperate. general, notions incomparable (asalso argue formally) provide different insights underlying game.main motivation analyzing selfishness level strategic games gaindeeper understanding characteristics influence players willingness cooperate. turns out, several games studied paper selfishness level providesinsights. illustrate point, briefly elaborate findings publicgoods game fair cost sharing game.208fiSelfishness Level Strategic Gamespublic goods game n players want contribute public good.Every player chooses amount si [0, b] contributes. central authority collectsindividual contributions, multiplies sum c > 1 (for simplicity assumen c) distributes resultingamount evenly among players. payoffc Pplayer thus pi (s) := b si + n j sj . (unique) Nash equilibrium, every playerattempts free ride contributing 0 public good (which dominant strategy),social optimum every player contributes full amount b. show,selfishness level game (1 nc )/(c 1). bound suggests temptationfree ride (i) increases number players grows (ii) decreases parameterc increases. phenomena observed experimental economists, (see, e.g.,discussion Ledyard, 1995, Section III.C.2). comparison, price stability (whichcoincides price anarchy) game c.fair cost sharing game every player chooses facility set facilities Si Eavailable (for simplicity discuss case players choose singlefacility). cost ce every used facility e E shared evenly among players usingit. prove, selfishness level game max{0, 12 cmax /cmin 1},cmax cmin refer largest smallest cost facility, respectively. analysistherefore reveals threshold phenomenon also makes sense intuitively: ordermotivate cooperation among players crucial convince players accessfacility cost cmin adhere social optimum. cmax 2cmin easysocial optimum player either shares cost facility e ce cminleast one player uses facility cost cmin exclusively himself. Thus,self-interest player cooperate choose social optimum case.cmax > 2cmin players reluctant cooperate fraction social welfareneeds offered incite cooperation grows proportionally cmax /cmin .Anshelevich et al. (2008) showed price stability price anarchygame Hn n, respectively, n denotes number players.2measures depend number players. contrast, notion reveals dependencydiscrepancy costs facilities.large body literature experimental economics indicates players tendency cooperate social dilemmas like Prisoners dilemma, Travelers dilemmapublic goods game, even though behavior ruled standard game-theoreticanalysis. Several studies suggest willingness cooperate depends certain parameters underlying game (like group-size, magnitude payoffs, etc.); see, e.g., IsaacWalker (1988), Cooper, DeJong, Forsythe, Ross (1996), Goeree Holt (2001),Becker, Carter, Naeve (2005), Dreber, Rand, Fudenberg, Nowak (2008).example, Dreber et al. observe Prisoners dilemma willingness cooperateincreases ratio cost benefit cooperation. therefore study selfishness level parameterized versions games. findings show selfishnesslevel also exhibits dependency certain parameters game.paper, define selfishness level taking pure Nash equilibriumsolution concept. line price anarchy price stabilitydefined originally (Koutsoupias & Papadimitriou, 2009; Schulz & Moses, 2003; Anshelevich2. Hn denotes nth Harmonic number.209fiApt & Schaferet al., 2008). However, definition applies equally well solution conceptsforms games. discuss matters final section.1.1 Contributionsmain contributions presented paper follows:1. introduce (in Section 2) notion selfishness level game, derive basicproperties elaborate connections efficiency measures modelsaltruism.particular, show selfishness level game unrelated pricestability price anarchy. Moreover, selfishness level invariant positive linear transformations payoff functions. also showmodel equivalent models altruism studied before.consequence, bounds selfishness level directly transfer alternativemodels.2. derive (in Section 3) characterization result allows us determineselfishness level strategic game.characterization shows selfishness level determined maximumappeal factor unilateral profitable deviations specific social optima,call stable. result, focus deviations stable social optimaonly. Intuitively, appeal factor single player deviation refers ratiogain payoff resulting loss social welfare.3. use (in Section 4) characterization result analyze selfishness levelseveral classical strategic games.games study fundamental often used illustrate consequencesselfish behavior effects competition. summary results givenTable 1. particular, derive explicit bounds selfishness level fair costsharing games congestion games linear delay functions. obtained boundsdepend specific parameters underlying game, find informative.also show bounds tight certain instances.4. also show (in Section 5) selfishness level notion naturally extendssolution concepts types games, instance mixed Nash equilibriaextensive games.1.2 Related Workarticles algorithmic game theory literature study influencealtruism strategic games (Caragiannis, Kaklamanis, Kanellopoulos, Kyropoulou, &Papaioannou, 2010; Chen, de Keijzer, Kempe, & Schafer, 2011; Chen & Kempe, 2008;Elias, Martignon, Avrachenkov, & Neglia, 2010; Hoefer & Skopalik, 2009). works,altruistic player behavior modeled altering players perceived payoff orderaccount also welfare others. models differ way combine players210fiSelfishness Level Strategic GamesGameSelfishness levelOrdinal potential gamesWeakly acyclic gamesFair cost sharing games (singleton)finite1}max{0, 12 ccmaxminFair cost sharing games (integer costs)Linear congestion games (singleton)Linear congestion games (integer coefficients)Prisoners Dilemma n playersPublic goods gameTravelers dilemmaCournout competitionTragedy commonsBertrand competitionmax{0, 12 Lcmax 1}max minmax{0, 12 (112 }max )aminmax{0, 21 (Lmax min 1)}cb(n1)cc1 nmax{0, c1 }12 (b 1)Table 1: Selfishness level games studied paper.see Section 4 definitions respective parameters games.individual payoff payoffs players. studies descriptivesense aim understanding impact altruistic behavior specific strategicgames.Closest work articles Elias et al. (2010) Chen et al. (2011).Elias et al. study inefficiency equilibria network design games (which constitutespecial case cost sharing games considered here) altruistic (or, callit, socially-aware) players. here, define players cost functionindividual cost plus times social cost. derive lower upper boundsprice anarchy price stability, respectively, modified game. particular,show price stability (Hn + )/(1 + ), n numberplayers.Chen et al. (2011) introduce framework study robust price anarchy,refers worst-case inefficiency solution concepts coarse correlatedequilibria (see Roughgarden, 2009) altruistic extensions strategic games.model, player perceived cost convex combination (1 ) times individual costplus times social cost, [0, 1] altruism level player i. playersuniform altruism level = , model relates one considersetting = /(1 ) (see Section 2.3 details). Although main focuspaper, authors also provide upper bounds 2/(1 + ) (1 )Hn +price stability linear congestion games fair cost sharing games, respectively.Note three cases mentioned price stability approaches 1goes . seems suggest selfishness level games . However,case analyses reveal.211fiApt & SchaferTwo models altruism proposed literature. Chen Kempe (2008)define perceived cost player (1 ) times individual cost plus /n timessocial cost, [0, 1]. Caragiannis et al. (2010) define perceived cost player(1 ) times individual cost plus times sum costs players (i.e.,excluding player i), [0, 1]. Also two models shown equivalentmodel using simple transformations (see Section 2.3 details).Subsequently, mention related approaches normative. Conceptually,selfishness level notion related Stackelberg threshold introduced SharmaWilliamson (2009) (see also Kaporis & Spirakis, 2009). authors consider networkrouting games fraction [0, 1] flow first routed centrallyremaining flow routed selfishly. Stackelberg threshold refers smallestvalue needed improve upon social cost Nash equilibrium flow.related paper, Hoefer Skopalik (2009) study minimum number, termedoptimal stability threshold, (pure) altruists needed congestion game induceNash equilibrium social optimum. show number computedpolynomial time singleton congestion games.network congestion games, researchers studied effect imposing tolls edgesnetwork order reduce inefficiency Nash equilibria (see, e.g., Beckmann,McGuire, & Winsten, 1956). high-level perspective, approaches alsoregarded normative.Recently, Capraro (2013) proposed new normative approach measure incentivecooperation symmetric games tension selfish altruisticbehavior. solution concept pure Nash equilibrium transformed gamestrategies certain mixed strategic original game. strategies dependincentive risk deviating cooperation original game. Strikingly,Capraros conclusions influence parameters Prisoners Dilemma,Travelers Dilemma public goods game consistent ours.several papers propose notions allowing assess stabilityNash equilibria. mention below. Christodoulou, Koutsoupias, Spirakis(2011) study inefficiency approximate Nash equilibria congestion games.(1+)-approximate Nash equilibrium cost player (1+) times costexperiences every unilateral deviation. authors derive (almost) tight boundsprice stability price anarchy linear (non-atomic atomic)congestiongames function . particular, obtain bound min{1, (1 + 3)/( + 3)}price stability atomic linear congestion games. context, alternativenotion assess stability Nash equilibria comes ones mind considersmallest 0 social optimum realized (1 + )-Nash equilibrium. Notebound implies 1 linear congestion games.comment idea detail Section 5.2.Anshelevich, Das, Naamad (2009) consider problem incentivizing playersparticipate socially desirable matchings adding switching costs player deviations.model, additional cost player incurs changing strategy accountsfraction individual cost. Adopting viewpoint, authors studyinefficiency (1 + )-approximate stable matchings. derive bounds pricestability price anarchy (1 + )-approximate stable matchings function212fiSelfishness Level Strategic Games0. Related work article Biro, Manlove, Mittal (2010) studyproblem computing optimal matching minimum number blocking pairs.Furthermore, Balcan, Blum, Mansour (2009) study impact advertising strategies players order induce select efficient equilibria. precisely,model authority first proposes strategy player acceptedplayer probability . accepting player adheres proposed strategyremaining players play best response (assuming strategies acceptingplayers fixed). final step players follow best response dynamics Nashequilibrium reached. authors analyze inefficiency resulting equilibriafair cost sharing games, machine scheduling games party affiliation games. particular, fair cost sharing games show expected cost resulting equilibriumfactor O(log n/) away social optimum.2. Selfishness Levelsection, formally introduce notion selfishness level, establish properties relate notions altruism.2.1 Definitionstrategic game (in short, game) G = (N, {Si }iN , {pi }iN ) given set N ={1, . . . , n} n > 1 players, non-empty set strategies Si every player N ,payoff function pi every player N pi : S1 Sn R. players choosestrategies simultaneously every player N aims choosing strategy si Simaximize individual payoff pi (s), = (s1 , . . . , sn ).call S1 Sn joint strategy denote ith element si . denote(s1 , . . . , si1 , si+1 , . . . , sn ) si similarly Si . Further, write (si , si )(s1 , . . . , si1 , si , si+1 , . . . , sn ), assume si Si . Sometimes, focusingplayer write (si , si ) instead s.joint strategy Nash equilibrium {1, . . . , n} si Si ,pi (si , si ) pi (si , si ). Further, given joint strategy call sum SW (s) :=Pni=1 pi (s) social welfare s. social welfare maximal callsocial optimum.shall also consider cost variant games use cost functions,written ci , instead payoff functions pi . setup objective playerminimize costs, joint strategy Nash equilibrium {1, . . . , n}si Si , ci (si , si ) ci (si , si ). Further,instead social welfare one considersPsocial cost s, defined SC(s) := ni=1 ci (s).Given strategic game G := (N, {Si }iN , {pi }iN ) 0 define gameG() := (N, {Si }iN , {ri }iN ) putting ri (s) := pi (s) + SW (s). > 0payoff player G() game depends social welfare players. G()altruistic version game G.Suppose 0 pure Nash equilibrium G() social optimumG(). say G -selfish. define selfishness level Ginf{ R+ | G -selfish}.213(1)fiApt & Schaferadopt convention infimum empty set . Further, stipulateselfishness level G denoted + iff selfishness level G R+G -selfish (equivalently, infimum belong set). show(Theorem 2) pathological infinite games exist selfishness levelkind; none studied games type.give remarks proceed.1. definitions refer strategic games player maximizespayoff function pi social welfare joint strategy given SW (s).definitions obviously apply case use cost functions social cost.2. definitions altruistic version game conceivable and, dependingunderlying application, might seem natural one use here.However, show Section 2.3 definition equivalent severalmodels altruism proposed literature.3. selfishness level refers smallest Nash equilibrium G()also social optimum. Alternatively, one might interested smallestevery Nash equilibrium G() corresponds social optimum. However,explained Section 5.2, alternative notion always meaningful.4. definition extends obvious way solution concepts (e.g., mixedcorrelated equilibria) forms games (e.g., subgame perfect equilibriaextensive games). briefly comment extensions Section 5.Note social welfare joint strategy G() equals (1 + n)SW (s),social optima G G() coincide. Hence replace definition -selfishgame reference social optimum G() one social optimum G.shall proofs below.Intuitively, low selfishness level means share social welfare neededinduce players choose social optimum small. share viewedincentive needed realize social optimum. Let us illustrate definition varioussimple examples.Example 1. Prisoners DilemmaCC1, 12, 11, 20, 0CC3, 33, 00, 30, 0Consider Prisoners Dilemma game G (on left) resulting game G()= 1 (on right). latter game social optimum, (C, C), also Nashequilibrium. One easily check < 1, (C, C) also social optimum G()Nash equilibrium. selfishness level game 1.Example 2. Battle SexesFBF2, 10, 0214B0, 01, 2fiSelfishness Level Strategic GamesNash equilibrium also social optimum, selfishness level game0.Example 3. Matching PenniesHH1, 11, 11, 11, 1Since social welfare joint strategy 0, game G() identicaloriginal game Nash equilibrium exists. selfishness levelgame . generally, selfishness level constant sum game 0 Nashequilibrium otherwise .Example 4. Game bad Nash equilibriumfollowing game results equipping player Matching Pennies gamethird strategy E (for edge):H1, 11, 11, 1HE1, 11, 11, 1E1, 11, 11, 1unique Nash equilibrium (E, E). easy check selfishness levelgame . (This also immediate consequence Theorem 4 (iii) below.)Example 5. Game Nash equilibriumConsider game G left resulting game G() = 1 right.CC2, 23, 02, 01, 1CC6, 66, 34, 23, 3game G Nash equilibrium, game G(1) social optimum,(C, C), also Nash equilibrium. Prisoners Dilemma game one easily check< 1, (C, C) also social optimum G() Nash equilibrium.selfishness level game G 1.2.2 PropertiesRecall that, given finite game G Nash equilibrium, price stabilityratio SW (s)/SW (s ) social optimum Nash equilibriumhighest social welfare G. price anarchy defined ratio SW (s)/SW (s )social optimum Nash equilibrium lowest social welfareG.price stability G 1 iff selfishness level 0. However, generalrelation two notions. following observation also showsselfishness level finite game arbitrary real number.215fiApt & SchaferTheorem 1. every finite > 0 > 1 finite game whose selfishness levelwhose price stability .Proof. Consider following generalized form, denote P D(, ), Prisoners Dilemma game G x = +1:CC1, 1x + 1, 00, x + 11 1,game game G() 0, (C, C) unique social optimum.compute selfishness level need consider game G() stipulate (C, C)Nash equilibrium. leads inequality 1 + 2 ( + 1)(x + 1),x, i.e., . selfishness level G . Moreover, pricefollows 1xstability , since (D, D) Nash equilibrium.notion selfishness level invariant simple payoff transformations.direct consequence following observation, given game G valuedenote G + (respectively, aG) game obtained G adding payofffunction value (respectively, multiplying payoff function a).Proposition 1. Consider game G 0.(i) every a, G -selfish iff G + -selfish.(ii) every > 0, G -selfish iff aG -selfish.Proof. (i) suffices note r[a]i (s) = ri (s) + + a, ri r[a]i payofffunctions player games G() (G + a)(). every joint strategyNash equilibrium G() iff Nash equilibrium (G + a)(),social optimum G() iff social optimum (G + a)().(ii) suffices note every > 0, r[a]i (s) = ari (s), time r[a]ipayoff function player game (aG)(), argue above.Proposition 1 implies selfishness level invariant game transformations form t(G) := aG + b, > 0. contrast notions priceanarchy price stability invariant game transformationsform t(G) := aG, > 0.Note selfishness level invariant multiplication payoff functions value 0. Indeed, = 0 game aG selfishness level 0.< 0 take game G Example 4 whose selfishness level . game aGjoint strategy (E, E) Nash equilibrium social optimum, selfishnesslevel aG 0.proposition also allows us frame notion selfishness levelfollowing way. Suppose original n-player game G given game designerfixed budget SW (s) joint strategy selfishness level G < .game designer distribute budget SW (s) joint strategy216fiSelfishness Level Strategic Gamesamong players resulting game Nash equilibrium coincidessocial optimum? scaling G() factor := 1/(1 + n) ensurejoint strategy social welfare original game G aG() same. UsingProposition 1, conclude smallest non-negative real aG()Nash equilibrium social optimum. game aG() viewedintended transformation G. is, payoff function pi game G transformedpayoff functionri (s) :=1pi (s) +SW (s).1 + n1 + nLet us return borderline case selfishness level denotedfollowing result.+ .Theorem 2. every 0 exists game whose selfishness level + .Proof. first prove result = 0. is, show exists game-selfish every > 0, 0-selfish. end use games P D(, )defined proof Theorem 1.construct strategic game G = (N, {Si }iN , {pi }iN ) two players N = {1, 2}combining, arbitrary fixed > 1, infinitely many P D(, ) games > 0follows: > 0 rename strategies P D(, ) game to, respectively,C() D() denote corresponding payoff functions pi . set strategiesplayer N Si = {C() | > 0} {D() | > 0} payoff defined(pi (si , si ) {si , si } {C(), D()} > 0pi (si , si ) :=0otherwise.Every social optimum G form (C(), C()), > 0. (Noteexploit > 1 here.) argument given proof Theorem 1, (C(), C())> 0 Nash equilibrium game G() deviations C()strategy C() D() 6= yield payoff 0. Thus, G -selfish every > 0.Finally, observe G 0-selfish every Nash equilibrium G form(D(), D()), > 0.deal general case prove two claims independent interest.Claim 1. every game G 0 game G G () = G.Proof. define payoff player game Gpi (s) := pi (s)SW (s),1 + n217fiApt & Schaferpi payoff game G. Denote SW (s) social welfare joint strategygame G ri payoff function player game G ().ri (s) = pi (s) + SW (s)nSW (s) + SW (s)SW (s)= pi (s)1 + n1 + nn2= pi (s) +SW (s)1 + n 1 + n= pi (s).Claim 2. every game G , 0G( + ) = G()1 + n.Proof. Denote SW (s) social welfare joint strategy game G(), pi , ri).r payoff functions player games G, G(), G()( 1+nri (s) := pi (s) + SW (s),SW (s)1 + n= pi (s) + SW (s) +(SW (s) + nSW (s))1 + nn= pi (s) + ++SW (s)1 + n 1 + n= pi (s) + ( + )SW (s),ri (s) = ri (s) +proves claim.prove general case fix 0 > 0 take game G whose selfishness level0+ . Claim 1 game G G () = G. G -selfish, sinceG 0-selfish.Further, Claim 2G ( + ) = G ()choice game Gproof.1 + n1+n -selfish,=G1 + n.G ( + )-selfish, concludes218fiSelfishness Level Strategic Games2.3 Alternative Definitionsdefinition selfishness level depends way altruistic versionsoriginal game defined. Three models altruism proposed literature.before, let G := (N, {Si }iN , {pi }iN ) strategic game. Consider following fourdefinitions altruistic versions G:Model (Elias et al., 2010): every 0, G() := (N, {Si }iN , {ri }iN )ri (s) = pi (s) + SW (s)N.(2)Model B (Chen & Kempe, 2008): every [0, 1], G() := (N, {Si }iN , {ri }iN )(3)ri (s) = (1 )pi (s) + SW (s) N.nModel C (Chen et al., 2011): every [0, 1], G() := (N, {Si }iN , {ri }iN )ri (s) = (1 )pi (s) + SW (s) N.(4)Model (Caragiannis et al., 2010): every [0, 1], G() := (N, {Si }iN , {ri }iN )ri (s) = (1 )pi (s) + (SW (s) pi (s)) N.(5)selfishness level notion Model extends Models B, C obviousway: say G -selfish [0, 1] iff pure Nash equilibriumaltruistic version G() also social optimum. selfishness level G respectModel B defined infimum [0, 1] G -selfish.respective notions Models C defined analogously.following theorem shows selfishness level game respect ModelsA, B, C relate via simple transformations. (Note Modeltransformation applies [0, 12 ].)Theorem 3. Consider strategic game G := (N, {Si }iN , {pi }iN ) altruistic versions defined according Models A, B, C above.(i) G -selfish R+ iff G -selfish =n1+n[0, 1].(ii) G -selfish R+ iff G -selfish =1+[0, 1].(iii) G -selfish R+ iff G -selfish =1+2[0, 21 ].Proof. prove following general claim. Fix x, > 0. every [0, x1 ], defineG() := (N, {Si }iN , {ri }iN )ri (s) = (1 x)pi (s) +SW (s).show G -selfish 0 iff G -selfish =219(6)1+xy[0, x1 ].fiApt & Schafersubstituting =ri (s) =1+xy(6), obtain11pi (s) +SW (s) =r (s).1 + xy1 + xy1 + xy1> 0 every 0 pure Nash equilibria socialconsequence, since 1+xy11optima, respectively, G() 1+xyG() coincide. Thus, G -selfish iff 1+xyG1-selfish. Also, follows Proposition 1 1+xy G -selfish iff G -selfish.Further, note111lim=1 lim= .1 + xy1 + xyxxis, selfishness level G respect Model iff selfishness level Grespect G() x1 .Now, (i) follows x = 1 = n, (ii) follows x = = 1(iii) follows x = 2 = 1.3. Characterization Resultcharacterize games finite selfishness level. end shall needfollowing notion. call social optimum stable N si Sifollowing holds:(si , si ) social optimum, pi (si , si ) pi (si , si ).words, social optimum stable player better unilaterally deviatinganother social optimum.turn order determine selfishness level game needconsider deviations stable social optima. Consider deviation si playerstable social optimum s. player better deviating si , definitionsocial welfare decreases, i.e., SW (si , si ) SW (si , si ) > 0. original gamedecrease small, gain player large, strategy si attractivesocially acceptable option player i. define player appeal factor strategy sigiven social optimumAFi (si , s) :=pi (si , si ) pi (si , si ).SW (si , si ) SW (si , si )follows shall characterize selfishness level terms boundsappeal factors profitable deviations stable social optimum. First, note followingproperties social optima.Lemma 1. Consider strategic game G := (N, {Si }iN , {pi }iN ) 0.(i) Nash equilibrium G() social optimum G, stablesocial optimum G.220fiSelfishness Level Strategic Games(ii) stable social optimum G, Nash equilibrium G() iffN si Ui (s), AFi (si , s),Ui (s) := {si Si | pi (si , si ) > pi (si , si )}.(7)set Ui (s), > sign replaced , called upper contour set (see,e.g., Ritzberger, 2002, p. 193). Note stable social optimum, si Ui (s)implies SW (si , si ) > SW (si , si ).Proof. (i) Suppose Nash equilibrium G() social optimum G.Consider joint strategy (si , si ) social optimum. definition Nashequilibriumpi (si , si ) + SW (si , si ) pi (si , si ) + SW (si , si ),pi (si , si ) pi (si , si ), desired.(ii) Suppose stable social optimum G. Nash equilibriumG() iff N si Sipi (si , si ) + SW (si , si ) pi (si , si ) + SW (si , si ).(8)pi (si , si ) pi (si , si ), (8) holds 0 since social optimum.pi (si , si ) > pi (si , si ), then, since stable social optimum G, SW (si , si ) >SW (si , si ).(8) holds N si Si iffpi (si , si ) pi (si , si )= AFi (si , s)SW (si , si ) SW (si , si )holds N si Ui (s).leads us following result.Theorem 4. Consider strategic game G := (N, {Si }iN , {pi }iN ).(i) selfishness level G finite iff stable social optimum exists (s) :=supiN, si Ui (s) AFi (si , s) finite.(ii) selfishness level G finite, equals minsSSO (s), SSOset stable social optima.(iii) G finite, selfishness level finite iff stable social optimum.particular, G unique social optimum, selfishness level finite.(iv) > 0 G -selfish, G -selfish.Proof. (i) (iv) follow Lemma 1, (ii) (i) Lemma 1, (iii) (i).Using theorem exhibit class games n playersselfishness level unbounded. fact, following general result holds.221fiApt & SchaferTheorem 5. function f : N R+ exists class games n players,n > 1, selfishness level game n players equals f (n).Proof. Assume n > 1 players player two strategies, 1 0. Denote1 joint strategy strategy equals 1 1i joint strategyopponents player entry equals 1. payoff player definedfollows:= 10pi (s) := f (n)si = 0 j < i, sj = 1f (n)+1n1otherwise.6= 1, pi (s) = f (n) smallest index player si = 0 otherwisepi (s) = f (n)+1n1 . Note SW (1) = 0 SW (s) = 1 6= 1. 1 unique socialoptimum.pi (0, 1i ) pi (1) = f (n) SW (1) SW (0, 1i ) = 1. Theorem 4 (ii)selfishness level equals f (n).4. Examplesuse characterization result determine compute upper boundselfishness level selected games. First, exhibit well-known class games(see Monderer & Shapley, 1996) selfishness level finite.4.1 Ordinal Potential GamesGiven game G := (N, {Si }iN , {pi }iN ), function P : S1 Sn R calledordinal potential function G N , si Si si , si Si , pi (si , si ) >pi (si , si ) iff P (si , si ) > P (si , si ). game possesses ordinal potential functioncalled ordinal potential game.Theorem 6. Every finite ordinal potential game finite selfishness level.Proof. social optimum largest potential stable social optimum.claim follows Theorem 4 (ii).particular, every finite congestion game (see Rosenthal, 1973) finite selfishnesslevel. shall derive explicit bounds two special cases games Sections 4.34.4.4.2 Weakly Acyclic GamesGiven game G := (N, {Si }iN , {pi }iN ), path S1 Sn sequence (s1 , s2 , . . . )k1joint strategies every k > 1 player sk = (si , si)k1si 6= si(see, e.g., Monderer & Shapley, 1996). path called improvementpath maximal k > 1, pi (sk ) > pi (sk1 ), player deviatedsk1 . game G finite improvement property (FIP ) every improvementpath finite. game G called weakly acyclic every joint strategy existsfinite improvement path starts (see, e.g., Milchtaich, 1996; Young, 1993).222fiSelfishness Level Strategic GamesFinite games FIP coincide ordinal potential games. Theorem 6 games finite selfishness level. contrast, selfishness level weaklyacyclic game infinite. Indeed, following game easily seen weakly acyclic:HEH1, 11, 10.5, 11, 11, 10.5, 1E1, 0.51, 0.50.5, 0.5Yet, account Theorem 4 (iii), selfishness level infinite.4.3 Fair Cost Sharing Gamesnext subsection consider cost-minimization instead payoff-maximizationgames. Recall games player wants Pminimize individual cost function ci social cost defined SC(s) = ci (s).fair cost sharing game (see, e.g., Anshelevich et al., 2008) players allocate facilitiesshare cost used facilities fair manner. Formally, fair cost sharing gamegiven G = (N, E, {Si }iN , {ce }eE ), N = {1, . . . , n} set players, Eset facilities, Si 2E set facility subsets available player i, ce R+cost facility e E. called singleton cost sharing game every Nevery si Si : |si | = 1. joint strategy S1 Sn let xe (s)number players using facility e E, i.e., xe (s) = |{i N | e si }|. cost facilitye E evenlyP shared among players using it. is, cost player definedci (s) = esi ce /xe (s).first consider singleton cost sharing games. Let cmax = maxeE ce cmin =mineE ce refer maximum minimum costs facilities, respectively.Proposition 2. selfishness level singleton cost sharing game1}. Moreover, bound tight.max{0, 21 ccmaxminresult contrasted price stability Hn price anarchyn cost sharing games (Anshelevich et al., 2008). Cost sharing games admit exactpotential function thus Theorem 6 selfishness level finite. However,tight example given proof Proposition 2 shows, selfishness levelarbitrarily large (as cmax /cmin ) even n = 2 players two facilities.order prove Proposition 2, first derive expression appeal factorarbitrary fair cost sharing games, specialize singleton cost sharing gamesprove claim.Let stable social optimum. Note exists Theorem 4 (iii) Theorem 6.consider cost minimization game appeal factor player definedci (si , si ) ci (si , si )(9)AFi (si , s) :=SC(si , si ) SC(si , si )condition Theorem 4 (i) reads (s) := maxiN, si Ui (s) AFi (si , s), Ui (s) :={si Si | ci (si , si ) < ci (si , si )}.223fiApt & SchaferFix player let = (si , si ) si Ui (s). use xe xe referxe (s) xe (s ), respectively. Notexe + 1 e si \ si ,xe = xe 1 e si \ si ,xeotherwise.ci (s) ci (si , si ) =X ceXce.xexe + 1esi \si(10)esi \siFurther, difficult verifySC(si , si ) SC(s) =Xesi \si : xe =0ceXce .(11)1.(12)esi \si : xe =1Thus,AFi (si , s)=Pceesi \si : xe 2 xePesi \si : xe =0 cePuse prove Proposition 2.ceesi \si : xe 1 xe +1Pesi \si : xe =1 ceProof Proposition 2. Let stable social optimum (which exists Theorem 4 (iii)Theorem 6). Ui (s) = every N selfishness level 0 Theorem 4 (ii).Otherwise, player N Ui (s) 6= . Recall singleton costsharing game, players strategy set consists singleton facility sets. Let si = {e}si = {e } singleton sets facilities chosen player = (si , si )si Ui (s). Clearly, e 6= e .Note SC(si , si ) SC(s) must positive si Ui (s) thus (11) impliesxe = 0. Therefore, (10) reduces ci (s) ci (si , si ) = ce /xe ce . xe = 1ce > ce si Ui (s). contradiction assumptionSC(si , si ) SC(s) = ce ce > 0. Thus xe 2. Note also implies ce > 2cethus cmax > 2cmin .Using (12), obtainAFi (si , s)=cexece11 cmax1.2 cminclaim follows Theorem 4 (ii).following example shows bound tight. Suppose N = {1, 2}, E ={e1 , e2 }, S1 = {{e1 }}, S2 = {{e1 }, {e2 }}, ce1 = cmax ce2 = cmin cmax > 2cmin .joint strategy = ({e1 }, {e1 }) unique social optimum SC(s) = cmaxc2 (s) = cmax /2. Suppose player 2 deviates s2 = {e2 }. SC(s2 , s1 ) = cmax + cminc2 (s2 , s1 ) = cmin . Thus AFi (s2 , s) = ( 21 cmax cmin )/cmin = 12 cmax /cmin 1.224fiSelfishness Level Strategic Gamesfollowing example shows bound similar one above, i.e., boundingselfishness level terms ratio cmax /cmin , hold arbitrary fair costsharing games. particular, shows minimum difference two costsfacilities (here ) must enter bound selfishness level arbitrary fair cost sharinggames.Example 6. Let N = {1, 2}, E = {e1 , e2 , e3 }, S1 = {{e1 }}, S2 = {{e1 , e3 }, {e2 }}, ce1 =cmax , ce2 = cmin + > 0 ce3 = cmin . joint strategy = ({e1 }, {e1 , e3 })unique social optimum SC(s) = cmax + cmin c2 (s) = cmax /2 + cmin . Supposeplayer 2 deviates s2 = {e2 }. SC(s2 , s1 ) = cmax + cmin + c2 (s2 , s1 ) = cmin + .Thus AFi (s2 , s) = ( 12 cmax )/ = 21 cmax / 1, approaches 0.next derive bound arbitrary fair cost sharing games non-negative integercosts. Let L maximum number facilities player choose, i.e., L :=maxiN,si Si |si |.Proposition 3. selfishness level fair cost sharing game non-negative integercosts max{0, 21 Lcmax 1}. Moreover, bound tight.Proof. Let stable social optimum. proof Proposition 2, Ui (s) =every N selfishness level 0 Theorem 4 (ii). Otherwise, playerN Ui (s) 6= . Let = (si , si ) si Ui (s). Note denominatorappeal factor (12) least 1 stable, si Ui (s) ce Ne E. ThusPPceees \si : xe 1 xec+1: x 2es\sxeeP1AFi (si , s) = Pesi \si : xe =0 ceesi \si : xe =1 ceX1ce1 Lcmax 1.xe2esi \si : xe 2claim follows Theorem 4 (ii).following example shows bound tight. Suppose given Lcmax . Let N = {1, . . . , n} E = {e1 , . . . , en } n = L + 1. Define Si = {{ei }}every N \ {n} Sn = {{e1 , . . . , en1 }, {en }}. Let cei = cmax every N \ {n}cen = 1. joint strategy = ({e1 }, . . . , {en1 }, {e1 , . . . , en1 }) unique socialoptimum SC(s) = (n 1)cmax cn (s) = (n 1)cmax /2. Suppose player n deviatessn = {en }. SC(sn , sn ) = (n 1)cmax + 1 cn (sn , sn ) = 1. Thus AFi (sn , s) =112 (n 1)cmax 1 = 2 Lcmax 1.Remark 1. bound selfishness level fair cost sharing game non-negativerational costs ce Q+ every facility e E using Proposition 3 followingscaling argument: Simply scale costs integers, e.g., multiplyingleast common multiplier q N denominators. Note scaling changeselfishness level game Proposition 1. However, change maximumfacility cost thus q enters bound. Also note scaling implicitly takes careeffect observed Example 6: Suppose cmax cmin integers = 1/qq N. costs multiplied q Proposition 3 yields (non-tight)bound qcmax 1 = cmax / 1 selfishness level, approaches q .225fiApt & Schafer4.4 Linear Congestion Gamescongestion game G := (N, E, {Si }iN , {de }eE ) given set players N ={1, . . . , n}, set facilities E delay function de : N R+ every facility e E,strategy set Si 2E every player N . joint strategy S1 Sn ,define xe (s) number players using facility e E, i.e.,Pxe (s) = |{i N | e si }|.goal player minimize individual cost ci (s) = esi de (xe (s)).call congestion game symmetric common strategy set 2ESi = i. singleton every strategy si Si singleton set, i.e.,every N every si Si , |si | = 1. linear congestion game, delay functionevery facility e E form de (x) = ae x + , ae , R+ non-negativereal numbers.first derive bound selfishness level symmetric singleton linear congestiongames. turns out, bound similar one singleton cost sharing gamesextend symmetric singleton linear congestion games. Instead, crucial insightselfishness level depends discrepancy facilities stable socialoptimum. make notion precise.Let stable social optimum let xe refer xe (s). Define discrepancytwo facilities e e ae + ae > 0(xe , xe ) =2ae xe + 2ae xe +.ae + aeae + ae(13)show (xe , xe ) [1, 1]. Define max (s) maximum discrepancytwo facilities e e ae + ae > 0 (xe , xe ) < 1;formally, letmax (s) = max{(xe , xe ) | ae + ae > 0 (xe , xe ) < 1}.e,e ELet max maximum discrepancy stable social optima, i.e., max = maxsSSO max (s).Further, let max := maxeE (ae + ) min := mineE (ae + ). Moreover, let aminminimum non-zero coefficient latency function, i.e., amin = mineE:ae >0 ae .Proposition 4. selfishness level symmetric singleton linear congestion game11 max min.max 0,2 (1 max )amin 2Moreover, bound tight.first prove discrepancy two facilities bounded:Claim 3. Let social optimum e, e E two facilities ae + ae > 0.discrepancy e e satisfies (xe , xe ) [1, 1].Proof. Let = xe + xe total number players facilities e e s. Notesince social optimum strategy sets symmetric, distributed among xexe social cost two facilities minimized. Said differently, xe = xminimizes functionf (x, t) := ae x2 + x + ae (t x)2 + (t x).226fiSelfishness Level Strategic Gameshard verify minimum f (x, t) (for fixed t) attained (notnecessarily integral) point2ae +.x0 :=2(ae + ae )f (x, t) parabola minimum x0 , integral point xe minimizesf (x, t) given point obtained rounding x0 nearest integer. Let xe := x0 + 21point, = (xe , xe ) [1, 1], xe = xe . Note choiceunique, unless x0 half-integral case {1, 1}. Solving equationsyields definition (13).Proof Proposition 4. Let stable social optimum. Note exists Theorem 4 (iii) Theorem 6. Ui (s) = every N selfishness level 0Theorem 4 (ii). Otherwise, player N Ui (s) 6= . Let = (si , si )si Ui (s). use xe xe refer xe (s) xe (s ) every facility e E,respectively. Note every e Exe + 1 e si \ si ,(14)xe = xe 1 e si \ si ,xeotherwise.Let si = {e} si = {e } sets facilities chosen player , respectively.Exploiting (14), obtainci (si , si ) ci (si , si ) = ae xe + ae (xe + 1) .(15)SC(si , si ) SC(si , si ) = ae (2xe + 1) + ae (2xe 1) .(16)Moreover,Note ci (si , si ) ci (si , si ) > 0 si Ui (s) definitionUi (s) (7). Further, SC(si , si ) SC(si , si ) > 0 stable social optimumsi Ui (s). Thus, must hold ae + ae > 0; otherwise ae = ae = 0 (15)(16) yield contradiction.Let = (xe , xe ) discrepancy e e s. Note [1, 1]Claim 3. Using definition (13), rewrite (15) (16)ci (si , si ) ci (si , si ) = 12 (ae + ae ) + 21 21 aeSC(si , si ) SC(si , si ) = (1 )(ae + ae ).conclude 6= 1.Thus,1212AFi (si , s) =1 (ae + ) (ae + ) 1(ae + ae ) + 2ae=(1 )(ae + ae )2(1 )(ae + ae )2max min1.(1 max )amin 2227fiApt & Schaferclaim follows Theorem 4 (ii).following example shows bound tight even n = 2 players twofacilities. Let N = {1, 2}, E = {e, e } S1 = S2 = {{e}, {e }}. Suppose given[0, 1) ae R+ . Define de (x) = (2 + )ae de (x) = ae x. joint strategy =({e}, {e }) unique social optimum SC(s) = (3 + )ae . c1 (s) = (2 + )aec2 (s) = ae . Suppose player 1 deviates s1 = {e }. SC(s1 , s2 ) = 4aec1 (s1 , s2 ) = 2ae . Thus AFi (s1 , s) = /(1 ), matches precisely upper boundgiven above. case [1, 0] proven analogously.Observe selfishness level depends ratio (max min )/amin 1/(1max ). particular, selfishness level becomes arbitrarily large max approaches 1.next derive bound selfishness level arbitrary congestion games lineardelay functions non-negative integer coefficients, i.e., de (x) = ae x + ae , Nevery e E. Let L maximum number facilities player choose,i.e., L := maxiN,si Si |si |.Proposition 5. selfishness level linear congestion game non-negative integercoefficients max{0, 12 (Lmax min 1)}. Moreover, bound tight.linear congestion games, price anarchy known 25 (see Christodoulou &Koutsoupias, 2005; Awerbuch, Azar, & Epstein, 2013). bound shows selfishnesslevel depends maximum number facilities strategy set magnitudecoefficients delay functions.Proof Proposition 5. Let stable social optimum. Note exists Theorem4 (iii) Theorem 6. Ui (s) = every N selfishness level 0Theorem 4 (ii). Otherwise, player N Ui (s) 6= . Let = (si , si )si Ui (s). use xe xe refer xe (s) xe (s ), respectively.Exploiting (14), obtainci (si , si ) ci (si , si ) =Xesi \si(ae xe + )X(ae (xe + 1) + ).esi \siSimilarly,SC(si , si ) SC(si , si ) =+X(xe + 1)(ae (xe + 1) + ) xe (ae xe + )X(xe 1)(ae (xe 1) + ) xe (ae xe + )X(ae (2xe + 1) + )esi \siesi \si=esi \siXesi \si(ae (2xe 1) + ).PGiven congestion vector x = (xe )eE , define P (x) := esi \s (ae xe + ) Q(x) :=Pes \si (ae (xe + 1) + ). Note P (x) Q(x) integers ae , N228fiSelfishness Level Strategic Gamesevery facility e E. Note definitions, P (1) =PQ(0) = es \si (ae + ).AFi (si , s) =Pesi \si (ae+ )P (x) Q(x).2Q(x) Q(0) 2P (x) + P (1)si Ui (s), know P (x) > Q(x) 2Q(x) Q(0) > 2P (x) P (1).obtainQ(x) + 1 P (x) Q(x) + 12 (P (1) Q(0) 1).Exploiting inequalities, obtainAFi (si , s)11(P (1) Q(0) 1) =22Xesi \si(ae + )1(|si \ si | max |si \ si | min 1).2Xesi \si(ae + ) 1Note |si \ si | 1; otherwise, si si thus SC(si , si ) SC(s) contradictssi Ui (s). expression thus 12 (Lmax min 1). claimfollows Theorem 4 (ii).following example shows bound tight. Fix L, max min(2n 1)min = Lmax + 1 integer n. Consider congestion gameN = {1, . . . , n} E = {e1 , . . . , eL+1 }. Define Si = {{eL+1 }} every N \ {n}Sn = {{e1 , . . . , eL }, {eL+1 }}. Let deL+1 (x) = min x dei (x) = max every{1, . . . , L}. joint strategy = ({eL+1 }, . . . , {eL+1 }, {e1 , . . . , eL }) SC(s) =min (n 1)2 + Lmax cn (s) = Lmax . player n deviates sn = {eL+1 }SC(sn , sn ) = min n2 = min (n 1)2 + min (2n 1) cn (sn , sn ) = min n.Exploiting (2n 1)min = Lmax + 1, conclude SC(s) < SC(sn , sn )cn (s) > cn (sn , sn ) (for n 3). Thus, social optimum sn Ui (s). obtain1Lmax min n= Lmax (Lmax + min + 1)min (2n 1) Lmax21= (Lmax min 1).2AFn (sn , s) =Remark 2. use Proposition 5 scaling argument outlined Remark 1derive bounds selfishness level congestion games linear delay functionsnon-negative rational coefficients.4.5 Prisoners Dilemma n Playersassume player NP = {1, . . . , n} two strategies, 1 (cooperate) 0(defect). put pi (s) := csi + b j6=i sj , b > c. Intuitively, b stands benefitcooperation c cost cooperation.Proposition 6. selfishness level n-players Prisoners Dilemma game229cb(n1)c .fiApt & SchaferIntuitively, means number players Prisoners Dilemma gameincreases, smaller share social welfare needed resolve underlying conflict.observation holds value benefit. is, acutenessdilemma diminishes number players also diminishes valuebenefit grows. formal reason appeal factor unilateral deviationsocial optimum inversely proportional number players inverselyproportional benefit.Proof. game = 1 unique social optimum, N , pi (s) =bn (b + c) SW (s) = bn2 (b + c)n. Consider joint strategy (si , si )player deviates strategy si = 0. pi (si , si ) = bn bc. claimSW (si , si ) = bn2 (b + c)n + c b(n 1). Hence AFi (si , s) = b(n1)cfollows Theorem 4 (ii).particular, n = b = 2 c = 1 get original Prisoners Dilemma gameconsidered Example 1 already argued selfishness level 1.4.6 Public Goodsconsider public goods game n players. Every player N = {1, . . . , n} choosesamount si [0, b] contributes public good, b R+ budget.game designer collects individual contributions players, multiplies sumc > 1 distributes resultingamount evenly among players. payoff playerc Pthus pi (s) := b si + n jN sj .1 cProposition 7. selfishness level n-players public goods game max 0, c1n .game, every player incentive free ride contributing 0public good (which dominant strategy c n). exactly n-playersPrisoners Dilemma game (where defect dominant strategy c > 0). However,proposition reveals fixed c, contrast Prisoners Dilemma game,temptation becomes stronger number players increases. Also, fixed numberplayers temptation becomes weaker c increases.PProof Proposition 7. Note SW (s) = bn+(c1) si . unique social optimumgame therefore = b pi (s) = cb every N SW (s) = cbn. Supposeplayer deviates choosing si [0, b). pi (si , si ) = cb + (1 nc )(b si ). Thus,pi (si , si ) pi (s) = (1 nc )(b si )SW (s) SW (si , si ) = (c 1)(b si ).1 nc 0 Ui (s) = selfishness level zero. Otherwise, 1 nc > 0Ui (s) = [0, b). conclude case AFi (si , s) = (1 nc )/(c1) every si Ui (s).claim follows Theorem 4 (ii).230fiSelfishness Level Strategic Games4.7 Travelers Dilemmastrategic game discussed Basu (1994) two players N = {1, 2}, strategy setSi = {2, . . . , 100} every player i, payoff function pi every definedsi = sipi (s) := si + bsi < sisi b otherwise,b > 1 bonus.Proposition 8. selfishness level Travelers Dilemma gameb12 .Proof. unique social optimum game = (100, 100), (2, 2) uniqueNash equilibrium. player deviates strategy si 99, playerremains 100, respective payoffs become si + b si b, social welfare becomes2si . AFi (si , s) = (si + b 100)/(200 2si ). maximum, b12 , reached si = 99.claim follows Theorem 4 (ii).Intuitively, means bonus b increases larger share social welfareneeds used ensure cooperation.4.8 Tragedy CommonsAssume player N = {1, . . . , n} real interval [0, 1] set strategies.players strategy chosen fraction common resource. Let (see Osborne, 2005,Exercise 63.1 Tardos & Vazirani, 2007, pp. 67):pi (s) := max 0, si 1nXj=1sj.payoff function reflects fact players enjoyment common resource depends positively chosen fraction resource negatively totalfraction common resource used players. Additionally, total fractioncommon resource players exceeds feasible level, 1, players enjoymentresource becomes zero.Proposition 9. selfishness level n-players Tragedy Commons game .Intuitively, result means game matter much involveplayers sharing social welfare cannot achieve select social optimum.Proof.Pfirst determine stable social optima game. Fix joint strategylet :=jN sj . > 1, social welfare 0. assume 1.SW (s) = t(1 t). expression becomes maximal precisely = 12social optima stable.equals 14 . game infinitely many PTake stable social optimum s. jN sj = 21 . Fix {1, . . . , n}. Denote siPconsider strategy x player pi (x, si ) > pi (a, si ). j6=i sj +x 6= 21 ,SW (a, si ) > SW (x, si ).231fiApt & SchaferP pi (a, si ) = 2 SW (a, si ) =j6=i sj + x < 1 hencepi (x, si ) = x(a +12x)14.Further, pi (x, si ) > pi (a, si ) impliesSW (x, si ) = ( 12 + x)(112+ x) =14(a x)2 .Also x 6= a. HenceAFi (x, s) =(a x)(x 12 )12x 12pi (x, si ) pi (a, si )==1+=SW (a, si ) SW (x, si )(a x)2axax11Since pi (x, si ) pi (a, si ) =P(a x)(x 21) pi (x, si ) > pi (a, si ) iff < x < 211> x > 2 . 2 , since j6=i sj +a = 2 . conjunction pi (x, si ) > pi (a, si )SW (x, si ) < SW (a, si ) holds iff < x < 12 . maxa<x< 1 AFi (x, s) = .2arbitrary stable social optimum, claim follows Theorem 4 (i).4.9 Cournot Competitionconsider Cournot competition n firms linear inverse demand functionconstant returns scale (see, e.g., Jehle & Reny, 2011, pp. 174175). assumeplayerPi N = {1, . . . , n} strategy set Si = R+ payoff functionpi (s) := si (a b jN sj ) csi given a, b, c, > c P0 b > 0.price product represented expression b jN sj production cost corresponding productionlevel si csi . follows rewritePpayoff function pi (s) := si (d b jN sj ), := c. Note payoffsnegative, case tragedy commons game. Still proofssimilar games.Proposition 10. selfishness level n-players Cournot competition game .Proof.P first determine stable social optima game. Fix joint strategylet := jN sj . SW (s) = t(d bt). expression becomes maximal precisely. game infinitely many social optima stable.= 2bPPTake stable social optimum s. jN sj = 2b. Fix N . Let u := j6=i sj .every strategy z playerpi (z, si ) = bz 2 + (d bu)zSW (z, si ) = bz 2 + (d 2bu)z + u(d bu).Denote si consider strategy x player pi (x, si ) > pi (y, si )., SW (y, si ) > SW (x, si ).u + x 6= 2bpi (x, si ) pi (y, si ) = b(x2 2 ) + (d bu)(x y)= b(x y)(x + + u db ) = b(x y)(x2b ),) account equality u+y =last equality holds since u db = (y+ 2bFurther,SW (y, si ) SW (x, si ) = b(x2 2 ) (d 2bu)(x y)= b(x y)(x + + 2u db ) = b(x y)2 ,2322b .fiSelfishness Level Strategic Gameslast equality holds since 2u db = 2y account equality u + =x 6= y. HenceAFi (x, s) =2b .x 2b2bpi (x, si ) pi (y, si )== 1 +.SW (y, si ) SW (x, si )xyyxSince pi (x, si )pi (y, si ) = b(yx)(x 2b) pi (x, si )pi (y, si ) > 0 iff < x <> x > 2b . 2b , since u + = 2b . conjunction pi (x, si ) > pi (y, si )SW (x, si ) > SW (y, si ) holds iff < x < 2b. supy<x< AFi (x, s) = .2barbitrary stable social optimum, claim follows Theorem 4 (i).2bproof shows every stable social optimum s, every player existdeviating strategies arbitrary high appeal factor. fact, limxy+ AFi (x, s) = ,i.e., appeal factor deviating strategy x converges convergesright original strategy s.4.10 Bertrand CompetitionNext, consider Bertrand competition, game concerned simultaneous selectionprices product two firms (see, e.g., Jehle & Reny, 2011, pp. 175177).product sold firm chose lower price. case tie productsold firms profits split. assume firm identicalmarginal costs c > 0 fixed cost, strategy set Si equals [c, ab ),c < ab . payoff function player {1, 2} givenc < si < s3i(si c)(a bsi )1pi (si , s3i ) := 2 (si c)(a bsi ) c < si = s3i0otherwise.Proposition 11. selfishness level Bertrand competition game .Proof. Let := a+bc2b . SW (s) > 0, SW (s) = (s0 c)(abs0 ), s0 := min(s1 , s2 ).Note (c, ab ), since assumption bc < a. Hence social optimum iffmin(s1 , s2 ) = d.social optimum s1 6= s2 , player larger si profitablydeviate s3i (that equals d), (s3i , s3i ) remains social optimum.stable social optimum (d, d).Fix {1, 2}. Note si slightly lower d, pi (si , d) > pi (d, d). Further,lim (pi (si , d) pi (d, d)) = 12 (d c)(a bd),silim (SW (d, d) SW (si , d)) = 0siSW (d, d) SW (si , d) 6= 0 si 6= d. Hencepi (si , d) pi (d, d)= .c<si <d SW (d, d) SW (si , d)supclaim follows Theorem 4 (i).233fiApt & Schafer5. Extensions Future Research Directionsintroduced selfishness level game new measure discrepancysocial welfare Nash equilibrium social optimum. studies revealselfishness level often provides deeper insights characteristics influenceplayers willingness cooperate. conclude mentioning natural extensionsfuture research directions.5.1 Extensionsdefinition selfishness level naturally extends solution conceptsforms games.5.1.1 Mixed Nash Equilibriamixed Nash equilibria simply adapt definitions stipulating strategicgame G -selfish mixed Nash equilibrium G() social optimum,also allow social optima mixed strategies. selfishness level G defined(1).example, notion selfishness level Matching Pennies game (Example 3) 0 since unique mixed Nash equilibrium, ( 21 H + 21 T, 12 H + 12 ), also socialoptimum. Matching Pennies game pure Nash equilibrium. contrast, gameExample 4 pure Nash equilibrium. use mixed Nash equilibriaselfishness level also becomes 0. games selfishness level changed ,pure Nash equilibria used, 0, mixed Nash equilibria used.Further, finite selfishness level finite game decrease use mixed Nashequilibria. example consider following amalgamation Matching Pennies(with payoffs increased 2) Prisoners Dilemma (with payoffs increased 1) games:HCH3, 11, 30, 00, 01, 33, 10, 00, 0C0, 00, 02, 23, 00, 00, 00, 31, 1game unique stable social optimum, (C, C), unique pure Nash equilibrium, (D, D). easy check using Theorem 4 (ii) selfishness level 1.hand, use mixed Nash equilibria selfishness level becomes 0.Indeed, ( 12 H + 21 T, 12 H + 12 ) mixed Nash equilibrium social optimummixed strategies.5.1.2 Extensive Gamesalso consider extensive games subgame perfect equilibria. exampleconsider six-period version centipede game (see, e.g., Osborne, 2005):234fiSelfishness Level Strategic Games1C2C1C2C1C2C(1, 0)(0, 2)(3, 1)(2, 4)(5, 3)(4, 6)(6, 5)unique subgame perfect equilibrium player chooses every periodresulting payoffs (1, 0). contrast, social optimum obtained playerchooses C every period resulting payoffs (6, 5). seekresulting game G() latter pair strategies forms subgame perfect equilibrium.particular, player 2 choose last round G() action C. happens5 + (6 + 5) 6 + (4 + 6) holds iff 1. Now, = 1 game G()following payoffs:1C2C1C2C(2, 1)(2, 4)(7, 5)(8, 10)1C2C(17, 16)(13, 11) (14, 16)game pair strategies player chooses C every periodsubgame perfect equilibrium social optimum yields payoffs (17, 16).conclude (appropriately adapted) selfishness level game 1.leave future work study alternatives.5.2 Future Research Directionsseveral intriguing questions left open. discuss future researchdirections below.5.2.1 Abstract Gameswould interesting define notion selfishness level abstract games.games payoffs replaced preference relations (see Osborne &Rubinstein, 1994). preference relation set mean linear orderingA. precisely, abstract game defined (N, {Si }iN , {i }iN )players preference relation defined set S1 Sn joint strategies.realization abstract game (N, {Si }iN , {i }iN ) mean strategic game(N, {Si }iN , {pi }iN ) N s, S1 Sn iffpi (s) pi (s ).Unfortunately, clear this. First, note notion Nashequilibrium well defined abstract games. However, counterpartnotion social optimum, since global preference relation set jointstrategies.tempting circumvent difficulty defining notion selfishness levelabstract game G using realizations G corresponding games G ((G )),235fiApt & Schafer(G ) selfishness level G . Unfortunately resulting strategic games G ((G )),G realization G realizations single abstract game, detourallow us associate initial abstract game another one.example take two realizations abstract Prisoners Dilemma gamecorresponding games G ((G )):CCC2, 23, 0C2, 22.5, 00, 31, 10, 31, 1CC6, 66, 3CC6, 65, 2.53, 63, 33, 63, 3realizations selfishness level 1 transformed games correspond abstract game, since first transformed game p2 (D, C)p2 (D, D), second one p2 (D, D) > p2 (D, C).5.2.2 Selfishness Functionapproach assigned game positive real number, selfishness level.natural generalization idea would assign game G functionfG : R+ R+ , f () equals price stability game G().selfishness level G inf{ R+ | fG () = 1}.function fG studied altruistic extensions linear congestion gamesfair cost sharing games (Chen et al., 2011; Elias et al., 2010). However, papersupper bounds fG derived, light results obtained cannottight. would interesting determine fG exactly games. would probablyrequire generalization characterization result presented paper.5.2.3 Alternative Approach Based Price Anarchydefined selfishness level game smallest price stabilityG() 1. Alternatively, one might define selfishness level smallestprice anarchy G() 1. alternative approach often yields value . Takeinstance following coordination game G:1, 10, 0BB0, 00, 0every 0 (A, A) social optimum G() social welfare 2 + 4,(B, B) Nash equilibrium G() social welfare 0. alternativeselfishness level game G , original selfishness level course 0.another example consider game G left corresponding game G()right:B1, 10, 3B3, 00, 0B1 + 2, 1 + 23, 3 + 3236B3 + 3, 3 + 30, 0fiSelfishness Level Strategic Gamesselfishness level 1, since smallest value (A, B) Nash equilibrium G(). hand, focus price anarchy, needchoose smallest (A, A) Nash equilibrium G() (A, B) is.case iff 3 > 1 + 2, i.e., > 1. alternative selfishness levelgame G 1+ .view examples find alternative approach promising. Still,might interesting clarify games yields finite values.5.2.4 Alternative Approach Based Approximate Nash Equilibriamentioned related work section, alternative approach measure stability equilibria game following. Given payoff-maximization game G =(N, {Si }iN , {pi }iN ), call G -stable 0 exists social optimumalso (1 + )-approximate Nash equilibrium, i.e., every player N everysi Si , (1 + )pi (s) pi (si , si ).3 define stability level G infimum0 G -stable. Intuitively, stability level means alterplayers incentives scaling payoffs factor (1 + ) social optimumrealized Nash equilibrium.would interesting study stability level game relates selfishnesslevel. Using definitions, easy see game G admits socialoptimum every player N every si Si , pi (s) SW (s)SW (si , si ),G -stable G -selfish.4 Said differently, stability level Gselfishness level. Similarly, reverse inequality holds G -selfish G-stable.particular, observation applied fair cost sharing games,every joint strategy holds every N every si Si , ci (si , si )SC(si , si ) SC(s) (see also (11) Section 4.3). conclude stability levelfair cost sharing game G selfishness level. consequence, boundsselfishness level derived Section 4.3 extend stability level case.Further, hard verify stability level singleton cost sharing gamesleast max{0, 21 cmax /cmin 1} cost sharing games integer costs leastmax{0, 21 Lcmax 1} considering examples given proofs Proposition 2Proposition 3, respectively. Thus, games stability level coincidesselfishness level.However, seen two notions always coincide. publicgoods game another example holds exists social optimumevery player N every si Si , pi (s) SW (s) SW (si , si ) (see proofProposition 7). Thus, stability level game selfishness level.fact, simple calculations show stability level max{0, (1 nc )/c} max{0, (1cn )/(c 1)}, latter selfishness level game.leave future work investigate stability level relationselfishness level.3. cost-minimization games, require ci (s) (1 + )ci (si , si ).4. cost-minimization games, inequality reads ci (si , si ) SC(si , si ) SC(s).237fiApt & Schafer5.2.5 Social Welfare Functionspaper exclusively concentrated social welfare functions definedsum individual payoffs players. leave future research studyselfishness level games social welfare functions, e.g., maximizing minimumpayoff players.Acknowledgmentspreliminary version paper appeared Proceedings 5th InternationalSymposium Algorithmic Game Theory (Apt & Schafer, 2012).acknowledge initial discussions Po-An Chen final discussions ValerioCapraro. also thank anonymous reviewers preliminary version valuablecomments. particularly grateful three reviewers JAIR helpfulremarks.Krzysztof R. Apt also affiliated University Amsterdam, Institute Logic,Language Computation, Science Park 107, 1098 XG Amsterdam, Netherlands.Guido Schafer also affiliated VU University Amsterdam, DepartmentEconometrics Operations Research, De Boelelaan 1105, 1081 HV Amsterdam,Netherlands.ReferencesAnshelevich, E., Dasgupta, A., Kleinberg, J., Tardos, E., Wexler, T., & Roughgarden, T.(2008). price stability network design fair cost allocation. SIAMJournal Computing, 38 (4), 16021623.Anshelevich, E., Das, S., & Naamad, Y. (2009). Anarchy, stability, utopia: Creatingbetter matchings. Proc. 2nd International Symposium Algorithmic Game Theory(SAGT09), Lecture Notes Computer Science 5814, pp. 159170. Springer.Apt, K. R., & Schafer, G. (2012). Selfishness level strategic games. Proc. 5th International Symposium Algorithmic Game Theory (SAGT12), pp. 1324. Springer.Ashlagi, I., Monderer, D., & Tennenholtz, M. (2008). value correlation. JournalArtificial Intelligence Research, 33, 575613.Awerbuch, B., Azar, Y., & Epstein, A. (2013). price routing unsplittable flow. SIAMJournal Computing, 42 (1), 160177.Axelrod, R. (1984). Evolution Cooperation. Basic Books.Balcan, M.-F., Blum, A., & Mansour, Y. (2009). Improved equilibria via public serviceadvertising. Proceedings 20th Annual ACM-SIAM Symposium DiscreteAlgorithms, pp. 728737. Society Industrial Applied Mathematics.Basu, K. (1994). travelers dilemma: paradoxes rationality game theory. AmericanEconomic Review, 84 (2), 391395.Becker, T. C., Carter, M., & Naeve, J. (2005). Experts playing travelers dilemma.Tech. rep. 252/2005, Department Economics, University Hohenheim, Germany.238fiSelfishness Level Strategic GamesBeckmann, M., McGuire, B., & Winsten, C. (1956). Studies Economics Transportation. Yale University Press, New Haven.Biro, P., Manlove, D. F., & Mittal, S. (2010). Size versus stability marriage problem.Theoretical Computer Science, 411 (1618), 18281841.Bowles, S. (2004). Microeconomics: Behavior, Institutions, Evolution. Princeton University Press, Princeton.Capraro, V. (2013). model human cooperation social dilemmas. PLoS ONE, 8 (8),16. e72427.Caragiannis, I., Kaklamanis, C., Kanellopoulos, P., Kyropoulou, M., & Papaioannou, E.(2010). impact altruism efficiency atomic congestion games.Proc. 5th Symposium Trustworthy Global Computing, pp. 172188.Chen, P.-A., & Kempe, D. (2008). Altruism, selfishness, spite traffic routing.Proc. 10th ACM Conference Electronic Commerce, pp. 140149.Chen, P.-A., de Keijzer, B., Kempe, D., & Schafer, G. (2011). robust price anarchyaltruistic games. Proc. 7th Workshop Internet Network Economics, pp.383390.Christodoulou, G., & Koutsoupias, E. (2005). price anarchy finite congestiongames. Proc. 37th Annual ACM Symposium Theory Computing, pp. 6773.Christodoulou, G., Koutsoupias, E., & Spirakis, P. G. (2011). performanceapproximate equilibria incongestion games. Algorithmica, 61 (1), 116140.Cooper, R., DeJong, D. V., Forsythe, R., & Ross, T. W. (1996). Cooperation without reputation: Experimental evidence prisoners dilemma games. Games EconomicBehavior, 12 (2), 187218.Dreber, A., Rand, D., Fudenberg, D., & Nowak, M. (2008). Winners dont punish. Nature,452, 348351.Elias, J., Martignon, F., Avrachenkov, K., & Neglia, G. (2010). Socially-aware networkdesign games. Proc. INFOCOM 2010, pp. 4145.Feldman, M., & Tamir, T. (2009). Approximate strong equilibrium job scheduling games.Journal Artificial Intelligence Research, 36, 387414.Fiat, A., Karlin, A., Koutsoupias, E., & Vidali, A. (2013). Approaching utopia: strong truthfulness externality-resistant mechanisms. Proceedings 4th conferenceInnovations Theoretical Computer Science, pp. 221230. ACM.Goeree, J. K., & Holt, C. A. (2001). Ten little treasures game theory ten intuitivecontradictions. American Economic Review, 91, 14021422.Hoefer, M., & Skopalik, A. (2009). Altruism atomic congestion games. Proc. 17thEuropean Symposium Algorithms, pp. 179189.Isaac, R. M., & Walker, J. M. (1988). Group size effects public goods provision:voluntary contributions mechanism. Quarterly Journal Economics, 103 (1),179199.239fiApt & SchaferJehle, G., & Reny, P. (2011). Advanced Microeconomic Theory (Third edition). AddisonWesley, New York, NY.Jurca, R., & Faltings, B. (2009). Mechanisms making crowds truthful. JournalArtificial Intelligence Research, 34, 209253.Kaporis, A. C., & Spirakis, P. G. (2009). price optimum stackelberg gamesarbitrary single commodity networks latency functions. Theoretical ComputerScience, 410 (8-10), 745755.Koutsoupias, E., & Papadimitriou, C. H. (2009). Worst-case equilibria. Computer ScienceReview, 3 (2), 6569.Ledyard, J. O. (1995). Public Goods: Survey Experimental Research, chap. 2, pp.111194. Handbook Experimental Economics. Princeton University Press.Marco, G. D., & Morgan, J. (2007). Slightly altruistic equilibria normal form games.Working paper 185, Center Studies Economics Finance, UniversitySalerno, Italy. Available http://www.csef.it/WP/wp185.pdf.Milchtaich, I. (1996). Congestion games player-specific payoff functions. GamesEconomic Behaviour, 13, 111124.Monderer, D., & Shapley, L. S. (1996). Potential games. Games Economic Behaviour,14, 124143.Osborne, M. J. (2005). Introduction Game Theory. Oxford University Press, Oxford.Osborne, M. J., & Rubinstein, A. (1994). Course Game Theory. MIT Press,Cambridge, Massachusetts.Ritzberger, K. (2002). Foundations Non-cooperative Game Theory. Oxford UniversityPress, Oxford.Rosenthal, R. W. (1973). class games possessing pure-strategy Nash equilibria. International Journal Game Theory, pp. 6567.Roughgarden, T. (2009). Intrinsic robustness price anarchy. Proc. 41st AnnualACM Symposium Theory Computing, pp. 513522.Schulz, A. S., & Moses, N. E. S. (2003). performance user equilibria trafficnetworks. SODA, pp. 8687.Sharma, Y., & Williamson, D. P. (2009). Stackelberg thresholds network routing gamesvalue altruism. Games Economic Behavior, 67 (1), 174190.Tardos, E., & Vazirani, V. J. (2007). Basic solution concepts computational issues.Nisan, N., Roughgarden, T., Tardos, E., & Vazirani, V. J. (Eds.), Algorithmic GameTheory, chap. 1, pp. 328. Cambridge University Press.Young, H. P. (1993). evolution conventions. Econometrica, 61 (1), 5784.240fiJournal Artificial Intelligence Research 49 (2014) 451-500Submitted 10/13; published 03/14Text-Based Twitter User Geolocation PredictionBo HanHANB @ STUDENT. UNIMELB . EDU . AUUniversity Melbourne, VIC 3010, AustraliaNICTA Victoria Research LaboratoryPaul CookPAULCOOK @ UNIMELB . EDU . AUUniversity Melbourne, VIC 3010, AustraliaTimothy BaldwinTB @ LDWIN . NETUniversity Melbourne, VIC 3010, AustraliaNICTA Victoria Research LaboratoryAbstractGeographical location vital geospatial applications like local search event detection.paper, investigate improve task text-based geolocation prediction Twitterusers. Previous studies topic typically assumed geographical references (e.g.,gazetteer terms, dialectal words) text indicative authors location. However,references often buried informal, ungrammatical, multilingual data, thereforenon-trivial identify exploit. present integrated geolocation prediction frameworkinvestigate factors impact prediction accuracy. First, evaluate range featureselection methods obtain location indicative words. evaluate impact nongeotagged tweets, language, user-declared metadata geolocation prediction. addition,evaluate impact temporal variance model generalisation, discuss users differterms geolocatability.achieve state-of-the-art results text-based Twitter user geolocation task, alsoprovide extensive exploration task date. findings provide valuable insightsdesign robust, practical text-based geolocation prediction systems.1. Introductiongrowing volume user-generated text posted social media services Twitter, Facebook, Tumblr leveraged many purposes ranging natural disaster response targeted advertising (Tuten, 2008; Nunez-Redo, Daz, Gil, Gonzalez, & Huerta, 2011; Yin, Lampert,Cameron, Robinson, & Power, 2012). many circumstances important know users location order accomplish tasks effectively. example, disaster response managers mustknow direct resources order effectively coordinate aid, advertisers could benefittailoring advertisements users location. Similarly, search results localisation hingesknowledge users location. Although many social media services allow user declarelocation, metadata known unstructured ad hoc (Hecht, Hong, Suh, & Chi, 2011)(e.g., melbo denoting Melbourne, AU 1 ), well oftentimes non-geographical (e.g.,1. Throughout paper, present city names ISO 3166-1 alpha-2 country-level designators AU =Australia CA = Canada. US-based city names mentioned context North Americanregional dataset used experimentation (NA), use ISO 3166-2:US designator US-CA = CaliforniaUS-PA = Pennsylvania.c2014AI Access Foundation. rights reserved.fiH , C OOK & BALDWINlittle bubble). Text-based geolocation automatically predicting users location basedcontent messages therefore becoming increasing interest (e.g., Cheng, Caverlee, &Lee, 2010, others). paper investigate improve text-based geolocation predictionTwitter users. Specifically, exploit tweets profile information given user inferprimary city-level location, claim sufficiently fine-grained support sortsapplications mentioned above.well established previous work (e.g., Wing & Baldridge, 2011, others), reasonable assume user posts social media reflect geospatial locum, lexical priorsdiffer region region. example, user London much likely talk Piccadilly tube user New York Beijing. say words uniquelyassociated London, course: tube could certainly mentioned user outside UK.However, use range words high relative frequency strongly indicativefact user located London. work area utilises geotagged data ground truthevaluation (e.g., Eisenstein, OConnor, Smith, & Xing, 2010, others). geotagged datacontains GPS coordinates inserted users consent GPS-enabled device smartphone, offers accurate information users position time tweeting. Althoughapproaches text-based geolocation offering increasingly promising results, studies datetopic limited number important ways. raise key issues Section3 investigate turn, focusing following issues:1.1 Location Indicative WordsText-based geolocation prediction models social media predominantly based full textdata tweets, including common words geospatial dimension (e.g., today), potentiallyhampering prediction, large number words observed tweets, leadingslower, memory-intensive models. tackle automatically finding location indicativewords (LIWs) via feature selection, demonstrating reduced feature set boosts geolocation accuracy. Section 5, carry extensive evaluation wide range feature selectionmethods proposed literature, show information gain ratio-based approach outperforms benchmark geolocation prediction methods 10.6 percentage points terms accuracy,reduces median prediction error distance 209km publicly-available regional (NorthAmerica) dataset. similarly demonstrate effectiveness LIW selection global datasetSection 6.1.2 Non-geotagged Tweetsaddition experimenting geotagged data, extend analysis incorporate nongeotagged tweets. recent work (e.g., Roller, Speriosu, Rallapalli, Wing, & Baldridge, 2012)incorporated non-geotagged training data, although little work analysed contributionnon-geotagged data, i.e., extent incorporating non-geotagged data improves geolocation accuracy. Furthermore, evaluation previous models restricted geotagged data(in order access ground truth) although goal line research ableinfer locations users whose locations known. However, unclear well modelsevaluated geotagged data generalise non-geotagged data. example, geotagged tweets sent GPS-enabled devices smartphones, non-geotagged tweets452fiT EXT-BASED WITTER U SER G EOLOCATION P REDICTIONsent range devices (including desktop computers), two types data coulddifferent characteristics (Gouws, Metzler, Cai, & Hovy, 2011).Section 7, address issues training testing geotagged tweets, non-geotaggedtweets, combination two. show exploiting users non-geotagged tweets,city-level accuracy improved 12.6% 28.0% benchmark dataset, underliningpotential contribution non-geotagged data. Furthermore, numbers also suggestmodel trained geotagged data indeed generalises non-geotagged data, although sub-domaindifferences geotagged data non-geotagged data observed.1.3 Language Influenceexceptions (e.g., Kinsella, Murdock, & OHare, 2011), text-based geolocationstudies carried English-only setting, primarily English setting.high-accuracy language identification tools (Lui & Baldwin, 2012; Nakatani, 2010) readilyavailable, problem: messages target language identified, text-basedgeolocation methods applied messages. However, remains seen whethertext-based geolocation approaches shown work well English perform welllanguages, perform well multilingual setting. English tweeted throughoutworld, whereas languages Indonesian primarily tweeted localised areas. such,performance methods developed tested English data could different applied languages. investigate language influence multilingual dataset Section8. results suggest model indeed generalises monolingual English multilingual setting. Furthermore, experiments reveal geolocation prediction much easierlanguages geographically-restricted use (e.g., Indonesian) languagesdiverse usage (e.g., English). go show composite model consistingnumber monolingual geolocation models based language identification outperforms modeltrained multilingual data.1.4 Metadata Ensemble LearningAlthough tweet-based geolocation worthy study right, tweets accompaniedrich metadata public user profiles. metadata included payload JSON objects containing tweets, offers complementary information may exploited improve accuracy,e.g., timezone data user-declared location. work utilisingtimezone (Mahmud, Nichols, & Drews, 2012) user-declared location (Hecht et al., 2011) information user geolocation, metadata remains largely untouched literature. Section9, investigate performance metadata-based geolocation models comparebenchmark methods. show incorporating information metadata tweet message stacking-based approach, city-level accuracy 49.1%, median prediction errordistance 9km, achieved global dataset, substantial improvementbase classifiers.1.5 Temporal InfluenceTwitter growing evolving medium, data Twitter streams tends locally temporal time posting. addition evaluating geolocation model old453fiH , C OOK & BALDWINtime-homogeneous data (sampled time period training data), Section 10evaluate trained model new time-heterogeneous dataset, collected approximately one year training test data used earlier experiments. observedmoderate decline results indicates stacked geolocation model indeed influencedtemporal changes. Error analysis reveals primarily caused unreliabilitybase model trained user-declared locations. contrast, find models trained tweettext timezone information relatively insensitive temporal changes. findingone hand justifies efforts to-date pursuing better text-based geolocation prediction,hand suggests user-declared location data used, model periodicallyupdated remain current temporal changes.1.6 User Geolocatability Prediction Confidencediscuss geolocatability users regard tweeting behaviour Section 11.instance, mentioning many local place names strong influence predictionaccuracy? Experiments suggest number LIWs (in particular, gazetted location names)user-declared metadata key geolocating user. different tweeting behavioursamong users, users equally geolocatable, predictions proportionreliable. conduct pilot study approximating prediction confidencerange variables Section 12.paper advances state-of-the-art text-based geolocation prediction numberdirections, provides practical guidelines design text-based geolocation application.paper builds previously-published work (Han, Cook, & Baldwin, 2012b, 2013)much extensive evaluation, new work following areas:large-scale comparative evaluation twelve feature selection methods user geolocationnine considered earlier work Sections 46.analysis impact training non-geotagged data Section 7.new set experiments, subsequent analysis, examining influence languageSection 8.analysis utility user-supplied metadata ensemble learning Section 9.More-detailed analysis model generalisation temporal change Section 10 includingcity-level meta-analysis.new pilot study user geolocatablility privacy Section 11.proposed text-based method primarily uses words geolocation prediction, intentionally excludes Twitter specific entities, hashtags user mentions. prediction accuracytherefore largely depends whether text contains sufficient geospatial information geolocation prediction. Therefore, although paper focuses exclusively Twitter, proposed methodcould equally applied forms social media text, Facebook status updatesuser-submitted comments (to services YouTube).454fiT EXT-BASED WITTER U SER G EOLOCATION P REDICTION2. Related Workacknowledging potential privacy concerns (Mao, Shuai, & Kapadia, 2011; Pontes, Vasconcelos, Almeida, Kumaraguru, & Almeida, 2012), accurate geolocation prediction key driverlocation-specific services localised search, target research acrossdifferent disciplines. example, tagging user queries (Wang, Wang, Xie, Forman,Lu, Ma, & Li, 2005; Backstrom, Kleinberg, Kumar, & Novak, 2008; Yi, Raghavan, & Leggetter,2009) web pages (Ding, Gravano, & Shivakumar, 2000; Amitay, HarEl, Sivan, & Soffer, 2004;Zong, Wu, Sun, Lim, & Goh, 2005; Silva, Martins, Chaves, Afonso, & Cardoso, 2006; Bennett,Radlinski, White, & Yilmaz, 2011) considered information retrieval. geographicalinformation science, primary focus recognising location mentions text (Leidner& Lieberman, 2011), named entity recognition tools typically employed detect extractmentions (Quercini, Samet, Sankaranarayanan, & Lieberman, 2010; Gelernter & Mushegian,2011). Within social media realm, geolocation methods applied images Flickr(Crandall, Backstrom, Huttenlocher, & Kleinberg, 2009; Serdyukov, Murdock, & van Zwol, 2009;Hauff & Houben, 2012; OHare & Murdock, 2013; Laere, Schockaert, & Dhoedt, 2013), Wikipediaarticles (Lieberman & Lin, 2009), individual tweets (Kinsella et al., 2011), Twitter users (Eisensteinet al., 2010; Cheng et al., 2010; Kinsella et al., 2011; Wing & Baldridge, 2011; Roller et al., 2012;Han et al., 2012b), identifying words topics Twitter salient particularregions (Eisenstein et al., 2010; Yin, Cao, Han, Zhai, & Huang, 2011; Hong, Ahmed, Gurumurthy,Smola, & Tsioutsiouliklis, 2012; Dalvi, Kumar, & Pang, 2012).Identifying Twitter users locations non-trivial, mainly due unavailability reliablegeographic information. Although Twitter allows users declare location user profile,location descriptions unstructured ad hoc (Cheng et al., 2010; Hecht et al., 2011), e.g.,people use vernacular expressions philly, non-standard spellings Filladephia,refer Philadelphia; non-geographical descriptions like heart also commonly found.Without appropriate processing, value location fields greatly limited. Hecht et al.(2011) demonstrate trivially using location fields off-the-shelf geolocation tools ineffective. Alternatively, tweets sent mobile devices geotagged accurate GPScoordinates, however, proportion geotagged tweets estimated mere 1% (Chenget al., 2010), location vast majority users geotagged. Methods basedIP addresses (Buyukokkten, Cho, Garcia-Molina, Gravano, & Shivakumar, 1999) appliedtask, general web contexts shown achieve around 90% accuracy mappingInternet hosts locations (Padmanabhan & Subramanian, 2001). methods applicable Twitter many social media services, however, IP address devicemessage sent cannot accessed via public APIs. Doubtless Twitteraccess information use user geolocation, although even here, geographical divisions IP addresses always credible. instance, departments internationalcorporation might use IP address range, true locations could spread acrossworld. VPNs also complication approaches. third-party service provider makinguse Twitter data, however, look sources geospatially-identifying information,including text content users posts metadata information, targeted research.spatial data mining community, geographical references (e.g., gazetteer terms) textalso exploited infer geolocation. Intuitively, place frequently mentioned usertweets, likely tweeting region. Methods building intuition range455fiH , C OOK & BALDWINnaive gazetteer matching rule-based approaches (Bilhaut, Charnois, Enjalbert, & Mathet, 2003),machine learning-based methods (primarily based named entity recognition: Quercini et al.,2010; Gelernter & Mushegian, 2011). Despite encouraging results approach longerhomogeneous documents sets (Quercini et al., 2010), performance impedednature tweets: short informal, chances user mentioning gazettedplaces tweets high. Moreover, handling vernacular place names, e.g., melboMelbourne, approach limited. reliance named entity recognition thwartedunedited nature social media data, spelling capitalisation much ad hocedited document collections (Ritter, Clark, Mausam, & Etzioni, 2011; Han, Cook, & Baldwin,2012a).Moving beyond off-the-shelf solutions, recently, many robust machine learning methodsapplied geolocation, primary approach estimate locations basedtextual content tweets. instance, Cheng et al. (2010) exploit words known primarily used particular regions, along smoothing techniques, improve simple generativegeolocation model applied data continental United States. Wing Baldridge(2011) divide worlds surface uniform-size grid, compare distribution wordsgiven users tweets grid cell using Kullback-Leibler (KL) divergence identifyusers likely location. One limitation approach grid cells rural areas tendcontain tweets, many tweets urban grid cells. Roller et al.(2012) therefore extend method use adaptive grid representation cells containapproximately amount data, based k-d tree (Bentley, 1975). Kinsella et al. (2011)examine geolocation prediction different granularities (e.g., zip codes, city, state country).Chang, Lee, M., Lee (2012) prune noisy data based geometrically-local words (i.e., wordsoccur geographically close other, found limited number cities)non-stop words dis-similar stop words, experiment reduced feature setusing Gaussian mixture model Maximum Likelihood Estimation location prediction.Beyond purely text-based methods (language model-based methods), sources informationalso integrated. Li, Serdyukov, de Vries, Eickhoff, Larson (2011) investigate geolocation prediction based linear rank combination text temporal factors. Mahmud et al.(2012) combine timezone information content-based classifiers hierarchical model geolocation. particular, nouns, hashtags, place names considered content method.Schulz, Hadjakos, Paulheim, Nachtwey, Muhlhauser (2013) combine scores various geographical sources (e.g., tweet text, user profile data). sum scores location representedaggregated height polygon-partitioned map, highest polygon predictedlocation.Topics discussed Twitter vary across geographical regions. Intuitively, instance, Americans likely talk NBA baseball Australians (who probably mention AFLrugby often). capture regional topic variations Twitter, topic modelling-basedapproaches also used incorporate geographical regions generative process.instance, Eisenstein et al. (2010) introduce geographical variable (r); instead generating observed word w per-word topic distribution z standard Latent Dirichlet Allocation(LDA) model (Blei, Ng, & Jordan, 2003), proposed approach refines step additionallymodeling topic distributions across different geographical regions, i.e., w generatedper-word region-topic distribution rz . Therefore, observed user locations generatedgeographical regions region variable topic modeling linked user geographical456fiT EXT-BASED WITTER U SER G EOLOCATION P REDICTIONlocations. Generally, users location predicted regional level adopting locationcentroid geotagged tweets region. Hong et al. (2012) improve approachconsidering fine-grained factors additive generative model. addition introducingper-region topic variance, incorporate per-user topic variance, regional language model,global background topics. compensate computational complexity associatedextra hidden variables, adopt sparse modeling inference. top geolocation prediction tasks, many research problems also involve modelling geographical locations.Dalvi et al. (2012) exploit impact geographical locations users discussions pre-definedobjects (e.g., restaurants) tweets. Yin et al. (2011) propose ways discover compare topicsgeographical regions jointly modelling locations text. Despite benefits incorporating per-region topic variance models, concerns prevent us using topic modelingapproaches study. First, temporal currency geographical topics limited, e.g.,Olympics playoffs. temporally-specific topics less indicative location future inference, e.g., geolocating users model trained. Furthermore, topic modellinggenerally computationally expensive, suffers efficiency problems applied large volumes data, available social media. Therefore experiment languagemodel-based methods better suited large-scale data.Social network information, including explicit friendship relations (Backstrom, Sun, &Marlow, 2010; Sadilek, Kautz, & Bigham, 2012; Rout, Bontcheva, Preotiuc-Pietro, & Cohn, 2013)implicit social interactions (Chandra, Khan, & Muhaya, 2011; Jurgens, 2013), showneffective predicting locations. City-level prediction results range approximately 5080% (Rout et al., 2013) depending wide range factors including user density socialnetwork precise scope geolocation prediction task. However, social networksdynamic, information often difficult obtain text data large scale.instance, obtaining social network information requires multiple requests rate-limited TwitterAPI reconstruct full social graph. therefore focus approaches based text,metadata accompanies individual tweet, leave possibility integrating socialnetwork information future work.3. Key Questions Geolocation Prediction FrameworkThough various geolocation prediction approaches proposed adapted social mediadata, fundamental questions remain. rest paper, addressquestions turn.Given text-based methods rely salient words local particular regions disambiguategeolocations, location indicative words improve accuracy using full wordset?model trained geotagged data generalise non-geotagged data? impactadding non-geotagged texts training test data? inherent sub-domaindifference geotagged non-geotagged tweets given geotagged tweets primarily sent mobile devices?geolocation prediction accuracy vary language? example, user primarilytweets Japanese geolocatable user tweets mostly English? language457fiH , C OOK & BALDWINinfluence accuracy, exploit improve multilingual geolocation prediction?user-declared text metadata provide geographical information complementarytweets themselves? make use multiple sources textual dataproduce accurate geolocation predictor?Twitter rapidly growing evolving, temporal factors influence modelgeneralisation? model trained old data perform comparably new test data?perspective privacy protection, users tweeting behaviour affectgeolocatability, i.e., ability model predict location? steps usertake reduce risk inadvertently leaking geographical information sharingtweets public?measures prediction confidence formulated estimate accuracy geolocation prediction?paper, focus predicting Twitter users primary (referred home) geolocation, following Cheng et al. (2010) others, assume given user basedsingle city-based location throughout time period study. approach geolocation predictiontext classification task. Tweets city taken represent class. tweetsgiven user aggregated assigned users primary location. characterise geolocation prediction four key components, discuss turn below: (1) representationdifferent geolocations, (2) model, (3) feature set, (4) data.3.1 Representation: Earth Grid vs. CityGeolocations captured points, clustered based grid (Wing & Baldridge, 2011;Roller et al., 2012), city centres (Cheng et al., 2010; Kinsella et al., 2011) topic regions (Eisenstein et al., 2010; Hong et al., 2012). point-based representation presents computational challenges, fine-grained standard classification methods. dynamic location partitioning, granularity regions hard control potentially vary across time,number regions variable depend dataset potentially also vary acrosstime. Fixed grid-based representations hindered considerable variabilityshape size geographical regions: coarse-grained grid cell perhaps appropriate centralSiberia, densely-populated linguistically/culturally diverse regions Luxembourg,doesnt lead natural representation administrative, population-based language boundaries region. therefore opt city-based representation, able captureboundaries intuitively. downside representation inappropriate classifying users rural areas. see Figure 1, however, bulk Twitter users are,unsurprisingly, based cities.Following Han et al. (2012b), use publicly-available Geonames dataset basiscity-level classes.2 dataset contains city-level metadata, including full city name, population, latitude longitude. city associated hierarchical regional information,state country based in, London, GB, e.g., distinguished London, CA.2. http://www.geonames.org, accessed October 25th, 2012.458fiT EXT-BASED WITTER U SER G EOLOCATION P REDICTIONhence use city-region-country format represent city (e.g., Toronto, CA representedtoronto-08-ca, 08 signifies province Ontario ca signifies Canada).3region coding schemes vary across countries, employ first- second-level regionfields Geonames region. Furthermore, second-level field specific (i.e., longer4 letters setting), incorporate first-level region field (e.g., instead usingmelbourne-07-24600-au, use melbourne-07-au). Moreover, cities sometimescomplex structure (e.g., Boston, US colloquially refers metropolitan area rathercity, made cities including Boston, Revere Chelsea), collapse together citiesadjacent one another within single administrative region, follows:1. Identify cities share region code (i.e., located state,province, county, etc.) Geonames dataset.2. region, find city c highest population.3. Collapse cities within 50km c c.44. Select next-largest city c, repeat.5. Remove cities population less 100K. remaining cities form citybased representation geolocations.result methodology, Boston, US ends single city (incorporating RevereChelsea), neighbouring Manchester, US discrete city (incorporating Bedford)New Hampshire. algorithm identifies total 3,709 collapsed cities throughout world.3.2 Geolocation Prediction ModelsVarious machine learning algorithms applied task multi-class text categorisation.However, many state-of-the-art learning algorithms appropriate particular taskreasons scalability. example, support vector machines (Vapnik, 1995) well suitedmassively multi-class problems (i.e., 3,709 cities case). Finally, would ideally likelearning algorithm easily retrained, e.g., incorporate new training dataTwitter data stream. such, primarily experiment simple learning algorithmsensemble learning geolocation prediction.3.2.1 G ENERATIVE VS . ISCRIMINATIVE ODELSGenerative models (e.g., naive Bayes) based estimation joint probability observingword vector class (i.e., P (w1 , w2 , . . . , wn , ci ), w1 , w2 , . . . words ci Ccity combined set cities C). contrast, discriminative models based estimationclass given word vector (i.e., P (c|w1 , w2 , . . . , wn )). objective models find3. Country code information found http://download.geonames.org/export/dump/countryInfo.txt4. use great-circle distance (Vincenty, 1975) distance calculations experiments, opposedEuclidean distance, properly capture three-dimensional surface earth. proximity cities variesacross world, e.g., cities east coast United States much closer major citiesAustralia. therefore scope explore impact 50km setting city label set, leavefuture work.459fiH , C OOK & BALDWINcity cmax C relevant probability maximised. experiments, experimentmodels. instance, choose state-of-the-art discriminative geolocation model basedKL divergence k-d tree partitioned unigrams (KL) (Roller et al., 2012). also adoptgenerative multinomial naive Bayes (NB) model (Hecht et al., 2011) default benchmark,two reasons: (1) incorporates class prior, allowing classify instance absencefeatures shared training data; (2) generative models outperform discriminative modelstraining data relatively scarce (Ng & Jordan, 2002).53.2.2 INGLE VS . E NSEMBLE ODELSaddition single model comparisons (e.g., discriminative KL vs. generative NB Sections 56), combine multiple base classifiers e.g., heterogeneous NB models trainedTwitter text user metadata improve accuracy. First, investigateaccuracies base classifiers correlations them. Then, apply different ensemblelearning strategies Section 9.3.3 Feature SetPredominantly, geolocations inferred based geographical references text, e.g., placenames, local topics dialectal words. However, references often buried noisy tweettext, lexical variants (e.g., tmrw tomorrow) common words without geospatial dimension (e.g., weather, twitter) prevalent. noisy words potential misleadmodel also slow processing speed. tackle issue, perform feature selection identify location indicative words. Rather engineering new features attemptingcapture named entities (e.g., White House) higher-order n-grams, focus feature selection simple word unigrams (see Section 4). partly pragmatic consideration,unigram tokenisation simpler.6 Partly, however, comparability past work, determining whether strategically-selected subset words lead significant gains predictionaccuracy (see Sections 5 6).addition feature selection, feature set refined extended variousways. instance, feature selection enhanced incorporating non-geotagged tweet data.Furthermore, languages used shape feature set, words different languagescarry varying amounts geospatial information, e.g., Dutch primarily usedNetherlands, Dutch words usually location indicative English words. Moreover, userprovided metadata (e.g., location timezone) readily accessible tweet JSON objects.metadata appended extra text features, addition features derived tweet text.investigate impact factors later sections.5. certainly abundance Twitter data train models over, number Twitter users sufficient amounts geotagged tweets able perform geolocation prediction small, relative numberparameters model (the product number features classes).6. Also, preliminary results named entities higher order n-grams disappointing.460fiT EXT-BASED WITTER U SER G EOLOCATION P REDICTIONProportion tweets(relative preceding step)Filtering criterionGeotaggedNear cityNon-duplicate non-FoursquareEnglish0.0080.9210.8880.513Table 1: Proportion tweets remaining filtering data based series cascaded criteria.numbers based Twitter corpus collected two months.3.4 DataGeolocation prediction models primarily trained tested geotagged data.7 useregional datasets (i.e., geotagged tweets collected continental US: Eisenstein et al.,2010; Mahmud et al., 2012) global datasets (Kinsella et al., 2011; Han et al., 2012b)research. accessibility issues (e.g., many tweets older datasets deletedthus accessible now) data sparseness (e.g., 10K users studyEisenstein et al., 2010), able experiment small number public datasets.paper, employ three geotagged datasets:1. regional North American geolocation dataset Roller et al. (2012) (NA hereafter),benchmarking purposes. NA contains 500K users (38M tweets) total 378pre-defined cities. NA used as-is ensure comparability previous work Section 5.2. dataset global coverage constructed us earlier work (Han et al., 2012b) (WORLDhereafter), collected via Twitter public Streaming API8 21 Sep, 2011 29 Feb,2012. tweet collection shaped different evaluation tasks, e.g., geotaggedEnglish data WORLD Section 6, incorporating non-geotagged English data WORLD+NGSection 7, multilingual geotagged data WORLD+ML Section 8 rich metadataWORLD+META Section 9.3. second dataset global coverage novel research (LIVE), contains tweetscollected 1 year WORLD (from 3 Mar, 2013 3 May, 2013), analyseinfluence temporal recency geolocation prediction. Unlike two datasets, LIVEused test dataset, Section 10.WORLD restricted English tweets order create dataset similar NA (inEnglish predominant language), covering entire world. pre-processed filtering data follows. First, non-geotagged tweets removed. Next, eliminatedtweets arent close city dividing earth 0.5 0.5 grid cells, discardingtweet city Geonames class set found 8 neighbouring gridcells. assign user single city majority tweets occur.7. One exception Cheng et al. (2010), train users whose user-declared metadata location fields correspond canonical locations (e.g., Boston, MA), test users whose locations indicated GPS coordinatesmetadata.8. https://dev.twitter.com/docs/streaming-apis461fiCumulative distribution tweetsH , C OOK & BALDWIN0.90.80.75%15% 25% 35% 45% 55% 65% 75% 85% 95%Top N% cities11number users10 100 1000number users10010000Figure 1: Cumulative coverage tweets increasing numbers cities based 26 million geotagged tweets.110100100010000Number geotagged tweets15505005000Mean distance city centre (kilometres)Figure 2: number users different numbers tweets, different mean distancescity center, WORLD.remove cities fewer 50 feature types (i.e., word types) reduce data sparsity.results 3135 cities WORLD (as opposed 3709 cities full Geonames class set).eliminated exact duplicate tweets Foursquare check-ins (which encode user locationform Im . . . ). that, non-English tweets removed using langid.py,open-source language identification tool (Lui & Baldwin, 2012). filtering summarisedTable 1 also shows proportion tweets remaining step. total numberusers tweets WORLD 1.4M 12M, respectively. Similar NA, developmenttest datasets contain 10K users, remainder users used training. development test data sampled user least 10 geotagged tweets alleviatedata sparsity.9 tokenised tweets Twitter-specific tokeniser (adapted OConnor,Krieger, & Ahn, 2010).Although certainly instances social media users high mobility (Li, Wang, &Chang, 2012), recent studies shown users tend tweet within limited region(Cho, Myers, & Leskovec, 2011; Hecht et al., 2011). also analyse spread WORLD9. restriction applied training data.462fiT EXT-BASED WITTER U SER G EOLOCATION P REDICTIONFigure 2, terms of: (1) number users least 10 geotagged tweets; (2) numberusers differing levels geographical spread tweets, measured average distanceusers tweets centre city user allocated.10preliminary analysis shows users relatively small number geotagged tweets,users stay near single city (e.g., 83% users geographical spread 50 kilometresless). high proportion users average distance 1km city centre artefactgeotagged tweets mapped city centre performing analysis. orderinvestigate coverage proposed city-based partition, examine recall originalsample 26 million geotagged tweets (prior filtering, described above). analysis reveals92.1% tweets close (in neighbouring 0.5 0.5 grid cell) one pre-definedcities, top 40% cities contain 90% geotagged tweets filtering, shownFigure 1. supports assumption (geotagged) Twitter users based cities.3.5 Evaluation Measuresformulated geolocation prediction task discrete class space usecity class set, possible use simple classification accuracy evaluate models. However,given class labels location (in form latitudelongitude coordinates),also sensitise evaluation distance-based predictive error. instance, correctlocation user Seattle, US, prediction Portland, US arguably better predictionLos Angeles, US, basis geospatial proximity. use number evaluation measurescapture spatial proximity, line previous work (Wing & Baldridge, 2011; Roller et al.,2012):111. Acc: city-level accuracy, i.e., proportion predictions correspond correct city;2. Acc@161: proportion predictions within distance 161 kilometres (100miles) correct city-level location. empirical measure (Cheng et al., 2010)relaxed version Acc, capturing near-miss predictions.3. Acc@C: country-level accuracy, i.e., proportion predicted locationscountry corresponding true locations. measure useful applications relyingcountry-specific Twitter data, e.g., sentiment analysis specific countries.4. Median: median prediction error, measured kilometres predicted city centrestrue geolocations. prefer use median, opposed mean, distancemedian less sensitive wildly incorrect predictions e.g., user London, GBclassified based Sydney, AU. contrast, mean distance increase substantially due small number extreme misclassifications, although effect limitedinherently-bounded regional datasets NA.10. geographical spread calculated random sub-sample 10 tweets given user, efficiency reasons.11. recent work, Priedhorsky, Culotta, Valle (2014) additionally proposed set probabilistic metricsevaluate tweet-based geolocation prediction, including using expected distance tweets true pointlocation random point location drawn probability distribution geolocation model.strongly support new direction geolocation modelling evaluation, depending application context,argue point- region-based representations related discrete evaluation measures equally importantuser geolocation research.463fiH , C OOK & BALDWIN4. Finding Location Indicative WordsPrecise user locations individual messages embedded geotagged tweets formlatitudelongitude coordinates. mapping coordinates cities representing tweetbag words, able make connections words (i.e., features) cities (i.e.,classes). section, present range methods ranking words locationindicativeness, i.e., degree word associated particular cities. Words eitherexplicitly (e.g., place names) implicitly (e.g., dialectal words, slang local references) encodegeographical information collectively referred location indicative words (LIWs);words aim automatically identify. Examples LIWs are:1. local words (1-local) used primarily single city, namely yinz (used Pittsburghrefer second-person plural pronoun), dippy (used Pittsburgh refer style friedegg, something dipped coffee) hoagie (used primarily Philadelphia,refer kind sandwich);122. semi-local words (n-local) refer feature relatively limited subset cities,namely ferry (found, e.g., Seattle, New York Sydney), Chinatown (common manylargest cities US, Canada Australia, much less common EuropeanAsian cities), tram (found, e.g., Vienna, Melbourne Prague)addition LIWs common words (common) arent expected substantialregional frequency variation, namely twitter, iphone today.remainder section, present various feature selection methods identifyingLIWs, drawn work Han et al. (2012b), Chang et al. (2012) Laere et al. (2013).feature selection methods broadly categorised three types: (1) statistical; (2) informationtheoretic; (3) heuristic. reduce low-utility words noise, feature selection methods,remove words include non-alphabetic letters, less 3 letters long,word frequency < 10.4.1 Statistical-Based MethodsStatistical hypothesis testing often used determine whether event occurs chance (i.e.,null hypothesis) (i.e., alternative hypothesis) particular confidence level (e.g., 95%p < 0.05). case, event defined co-occurrence word city,null hypothesis assumes co-occurrence chance, i.e., word city independent.goal feature selection find wordcity pairs null hypothesis rejected.4.1.1 2L OG -L IKELIHOOD2 statistic commonly used examine degree independence random variables. contingency table representing observations variables formed, Table 2.general form statistic is:n(Oi Ei )2Ei12. words identified aid datasets regional words DARE: http://dare.wisc.edu/.464fiT EXT-BASED WITTER U SER G EOLOCATION P REDICTIONcOw,cOw,cwnon-w wordcOw,cOw,cTable 2: Contingency table word city co-occurrenceOi represents observation (i.e., co-occurrence city (c) word (w)), nnumber cells table. Ow,c Ow,c denote occurrence word w city c non-wwords cities c, respectively. Ew,c denotes expected frequency w c, calculatedmarginal probabilities total counts N :Ow,c + Ow,c Ow,c + Ow,cNNN= Ow,c + Ow,c + Ow,c + Ow,cEw,c = P (w) P (c) N =N2 statistic larger number 2 distribution, respect degreesfreedom (in case, 1), null hypothesis city c word w independent rejected.many statistical tests, 2 ineffective counts low. addressword frequency thresholding use massive amounts training data.Conventionally, 2 used identify set features satisfies pre-defined confidencelevel (e.g., p < 0.05). However, case LIW selection, instead use 2 statistic rankwordcity pairs. selection LIWs deferred parameter tuning state,boundary LIWs common words optimised using development data.point, different ranking LIWs produced per city, desire globalranking LIWs capturing ability discriminate cities combined label set.various ways aggregation. suggested Laere et al. (2013), one approachselecting n features based 2 iteratively aggregate top-m features cityn features obtained. Alternatively, ranked based highest-scoring occurrencegiven word city, first sorting cityword 2 test pairs, selecting firstoccurrence word type aggregated ranking. two aggregation approaches producedifferent feature selection rankings, distinguished using Chi MaxChi , respectively.13Similar 2 test, log-likelihood ratio (Loglike: Dunning, 1993) also appliedLIW selection (Laere et al., 2013). Loglike test determines whether h0 (the null hypothesis,i.e., word independent city) likely h1 (the alternative hypothesis, i.e.,word dependent city). Following Dunning, likelihood hypothesis, L(), estimatedusing binomial distributions.( )( )k1k2n1 k1 n1n2 k2 n2L(h1 ) = p1 (1 p1 )p (1 p2 )k1 2k2p1 = P (w|c) =Ow,ck1=n1Ow,c + Ow,c13. One possible alternative computing 2 word city, aggregating values finalranking words, would compute single 2 value word contingency table 2 rowsTable 2, one column per city. Nevertheless, standard use 2 feature selection,leave possibility future work.465fiH , C OOK & BALDWINOw,ck2=n2Ow,c + Ow,ck1 (k2 ) represents occurrences word w city c (not city c), n1 (n2 ) represents wordoccurrences city c (not city c). L(h0 ) special case L(h1 ) p1 p2 equal,below:p2 = P (w|c) =Ow,c + Ow,cNLoglike test statistic expanded using observations:p1 = p2 = p =Loglike(w) = 2[Ow,c log Ow,c + Ow,c log Ow,c + Ow,c log Ow,c + Ow,c log Ow,c + N log N(Ow,c + Ow,c ) log(Ow,c + Ow,c ) (Ow,c + Ow,c ) log(Ow,c + Ow,c )(Ow,c + Ow,c ) log(Ow,c + Ow,c ) (Ow,c + Ow,c ) log(Ow,c + Ow,c )]calculated Loglike wordcity pair, aggregate across cities similarlyChi (by selecting top-m features per city n features obtained), following Laere et al.(2013).144.1.2 R IPLEY K TATISTICSpatial information also incorporated hypothesis testing. example, Ripley Kfunction (Ripley: OSullivan & Unwin, 2010) measures whether given set points generatedhomogeneous Poisson distribution. test statistic calculates number point pairswithin given distance square total number points. regards LIWselection, set points (Qw ) subset geotagged users using particular word w. teststatistic formulated follows (Laere, Quinn, Schockaert, & Dhoedt, 2014):K() =|{p, q Qw : distance(p, q) }||Qw |2represents total area consideration (e.g., whole North America,whole globe); dropped generating ranking.larger value K() indicates greater geographical compactness set Qw (i.e., p qspatially close). However, |Qw | (i.e., number users use word w) varies considerablyacross words, dominate overall statistic. number variations proposedalleviate effect, including replacing denominator factor based L1, takinglogarithm overall value (Laere et al., 2014). quadratic computational complexityRipley becomes issue |Qw | large (i.e., common words). Randomised methodsusually adopted tackle issue, e.g., subsampling points training data Ripley calculation relative different distances . experiments, adopt optimised implementationLaere et al. using = 100km 5K samples.4.2 Information Theory-Based Methodsaddition statistical methods, also experiment information-theoretic feature selectionmethods based measures shown effective text classification tasks, e.g.,Information Gain (IG) (Yang & Pedersen, 1997).14. Note also that, see later experiments, almost empirical difference twoaggregation methods 2 , choice aggregation method largely arbitrary.466fiT EXT-BASED WITTER U SER G EOLOCATION P REDICTION4.2.1 NFORMATION G G R ATIOInformation Gain (IG) measures decrease class entropy word brings about, highervalues indicate greater predictability basis feature. Given set words w, IGword w w across cities (c) calculated follows:IG(w) = H(c) H(c|w)H(c|w)P (w)P (c|w)logP (c|w) + P (w)P (c|w)logP (c|w)ccccP (w) P (w) represent probabilities presence absence word w, respectively. H(c) words, H(c|w) conditional entropy given wneeds calculated rank features.Words carry varying amounts intrinsic entropy, defined as:IV (w) = P (w)logP (w) P (w)logP (w)Local words occurring small number cities often low intrinsic entropy, nonlocal common words high intrinsic entropy (akin inverse city frequency; see Section 4.3.1).words comparable IG values, words smaller intrinsic entropies preferred.Therefore, following Quinlan (1993) normalise IG(w) using intrinsic entropyword w, IV (w), culminating information gain ratio (IGR):IGR(w) =IG(w)IV (w)4.2.2 L OGISTIC R EGRESSION -BASED F EATURE W EIGHTSprevious two information-theoretic feature selection methods (IG IGR) optimise acrossclasses simultaneously. Given LIWs may strongly associated certain locations,less tied locations, also conduct per-class feature selection based logisticregression (LR) modelling.15 consider method information theoreticmaximisation entropy cases uncertainty training data.Given collection cities c, LR model calculates probability user (e.g., representedword sequence: w1 , w2 , . . . , wn ) assigned city c c linearly combining eligible LRfeature weights:P (c|w1 , w2 , . . . , wn ) =1exp(k fk )Zk=1Z normalisation factor, total number features, fk k featuresfeature weights, respectively. discriminative models, possible incorporatearbitrary features LR, however, feature (function) task canonically defined wordwi city c: w occurs set messages users class c, feature fk (wi , c)15. logistic regression modeller, use toolkit Zhang Le (https://github.com/lzhang10/maxent),30 iterations L-BFGS (Nocedal, 1980) training data.467fiH , C OOK & BALDWINdenoted [class = c wi c]. fk maps feature weight denoted k R. methodresults per-city word ranking words ranked decreasing order k ,derive combined feature ranking manner MaxChi , following Han et al. (2012b).16Notably, incorporating regularisation factor balances model fitness complexity, couldpotentially achieve better results. dont explicitly perform regularisation modelling stage.Instead, first obtain feature list ranked LR feature selection methodsevaluate subset top-n ranked features development data. fact equivalentfilter-based regularisation (cf. filter-based feature selection: Guyon & Elisseeff, 2003),leave experimentation regularisation integrated models future work.4.2.3 ISTRIBUTION IFFERENCELIW selection likened finding words maximally dissimilar stop words (Changet al., 2012). Stop words like today widely used across many cities, thus exhibitrelatively flat distribution. contrast, LIWs predominantly used particular areas,skewed distribution. capture intuition, LIW selection baseddistribution difference across cities stop words potential LIW candidates (i.e.,non-stop words). Given pre-defined set stop words S, distribution difference calculatedas:DistDi (wns ) =Di (wns , ws )wsCount(ws )Count(S)Count(ws ) Count(S) denote number occurrences stop word ws totalnumber occurrences stop words, respectively. difference (i.e., Di (wns , ws ))stop word ws non-stop word wns evaluated various ways, e.g., symmetric KLdivergence (DistDiskl ), total variance (DistDitv ) absolute probability difference acrosscities c (Chang et al., 2012):Diskl (wns , ws ) =P (c|wns ) logccDitv (wns , ws ) =P (c|ws )P (c|wns )+ P (c|ws ) logP (c|ws )P (c|wns )|P (c|wns ) P (c|ws )|ccP (c|wns ) P (c|ws ) denote probability word occurring city per-wordcity distribution wns ws , respectively. non-stop words sorted distributiondifference decreasing order. experiments, use implementation Chang et al..4.3 Heuristic-Based Methodscommonly-used feature selection methods, number heuristics used selectLIWs.4.3.1 ECOUPLING C ITY F REQUENCY W ORD F REQUENCYHigh-utility LIWs following properties:16. LogLike, choice aggregation method largely arbitrary, based empirical results 2 .468fiT EXT-BASED WITTER U SER G EOLOCATION P REDICTION1. High Term Frequency (TF ): reasonable expectation observingusers tweets city.2. High Inverse City Frequency (ICF ): word occur tweets associated relatively small number cities.calculate ICF word w simply as:icf w =|c|cf wc set cities cf w number cities users use w training data.Combining two together, seeking words high TF -ICF , analogous seeking wordshigh TF -IDF values information retrieval. standard TF -IDF formulations, multiplyTF IDF . simple product TF ICF tends dominated TF component,however: example, twitter scores highly Jakarta, twitter high TF .resolve decoupling two factors applying radix sort ranking: first rank featuresICF TF , decreasing order. approach largely based inverse cityfrequency, denote ICF below.4.3.2 G EOGRAPHICAL PREAD ENSITYLIWs peaky geographical distributions (Cheng et al., 2010). section, discuss twoheuristic measures LIW selection based geographical distribution word.Geographical spread (GeoSpread : Laere et al., 2013) estimates flatness words distribution cities. First, earth divided 1 latitude 1 longitude cells. wordw, cells w occurs stored. Then, neighbouring cells containing w mergedmulti-pass scanning cells merged. number cells containing wmerging stored. Finally, GeoSpread score word w calculated follows:GeoSpread (w) =# cells containing w mergingMax (w)Max (w) represents maximum frequency w original unmerged cells.Smaller values indicate greater location indicativeness. measure originally used rankFlickr tags locality, e.g., London location-indicative beautiful. ignores influence stop words, common Flickr tags. However, stop words likefrequent Twitter, occur many locations, making numerator small denominatorlarge. Furthermore, stop word frequencies cells usually high. Consequently, similarly small GeoSpread London, undesirable. words, GeoSpread flawedable distinguish stop words local words, although effective rankingless common words (e.g., London vs. beautiful).Geographical density (GeoDen: Chang et al., 2012) strategically selects peaky words occurringdense areas. Given subset cities c c word w w used, GeoDen calculated469fiH , C OOK & BALDWINas:ccGeoDen(w) =|c |2|c |cj ,ck c j=k dist(cj ,ck )|c |(|c |1)=P (c|w)ccP (c|w)cj ,ck c j=k dist(cj ,ck )|c |1dist(cj , ck ) great-circle distance cities cj ck . Similarly, P (c|w) denotesdistribution word w across city c c . denominator made squarenumber cities |c | w occurs (which similar effect ICF above),average distance cities w used. LIWs generally skewed geographicaldistribution small number locations, meaning denominator small numeratorlarge. issue measure computational complexity common words occurmany cities. Furthermore, cities containing small number occurrences wincorporated, avoid systematic noise, e.g., travellers posting trip. One approachcounter issues set minimum P (c|w) threshold cities, perform randomisedsampling c . paper, follow Chang et al. constructing final c : first, citiescontaining w ranked P (c|w) decreasing order, c formed adding cities accordingrank, stopping sum P (c|w) exceeds pre-defined threshold r. choose r = 0.1experiments, based findings Chang et al..5. Benchmarking Experiments NAsection, compare discuss proposed feature selection methods. particular,investigate whether using LIWs geolocation prediction better using fullset features, various configurations models location partitions Section 5.2.subsequent experiments section exclusively based public NA dataset. adoptuser partitions training, dev test used original paper (Roller et al., 2012).primarily use city-based class representation experiments NA, additionallypresent results using original k-d tree partitions learned Roller et al. Section 5.2, directcomparability published results. distance-based evaluation measures (Acc@161Median), calculate users location based centroid tweets, and, dependingclass representation used, represent predicted location either: (a) city centre; (b)user-centroid given k-d tree cell. case Acc city-based class representation,map centroid user nearest city centre 50km away, use basisAcc calculation. case city centre satisfies constraint,17 mapuser NULL class, always misclassify user.185.1 Comparison Feature Selection MethodsFirst, compare effectiveness various feature selection methods NA using citybased class representation. total, 214K features extracted training section NA.17. occurs 1139 ( 11.4%) test users.18. such, upper bound Acc city-based representation 0.886. Note also Acc k-d tree vs.city-based representation comparable, different class structure granularity.470fiT EXT-BASED WITTER U SER G EOLOCATION P REDICTION0.4Acc1610.30.2ICFGeoDenRipleyIGRLoglikeChi0.10.02% 8%16%24%32%40%48%56%64%72%80%88%96%Top N% FeaturesFigure 3: Acc@161 varying levels feature selection NA dataset, based citybased class representation.select top-n% features, step size 2%, use selected features withinmultinomial naive Bayes learner (we return explore choice learner Section 5.2).tuning n methods based Acc@161 10K held-out users developmentdata. present results sample feature selection methods Figure 3, omitting methodslargely identical behaviour methods presented graph, namely:{DistDitv , DistDiskl } ICFMaxChi Chi{LR, IG, GeoSpread } LogLikemethods, best result achieved proper subset features based featureselection, although proportion features gives best results given methodvaries greatly (e.g., optima Ripley, IGR GeoDen 10%, 88% 66%, respectively).observation agrees expectations that: (1) small number featuresused, trained model generally underfits data; (2) model trained using fullfeature set, noisy words (e.g., the) cause overfitting. instance, using top 2%features IGR, likely class users features noting users featurerepresentation default majority class, namely Los Angeles, US-CA Monterrey, MX,Spanish words highly location-indicative small number Mexican citiesNA dataset. features selected last generally high-frequency function words (e.g.,the) common words (e.g., facebook), give little indication geolocation, leadprediction errors.Two patterns observed results: (1) Chi , MaxChi , IG, LogLike, GeoSpread , LRRipley (i.e., local methods, initially select features class, exception471fiH , C OOK & BALDWINIG Ripley) achieve highest Acc@161 early stage, numbers drop gradually; (2) ICF , IGR, DistDiskl , DistDitv GeoDen (i.e., collective group,select features classes once) gradually increase accuracy features added,reach peak majority features selected, drop accuracy sharply.difference behaviour attributed types word preferred methods.local methods tend prefer 1-local words taking LR, example, city names (e.g.,philadelphia) names upper-level administrative regions (e.g., georgia) frequently occurupper reaches ranking. addition gazetted words, many local/regional wordsalso found upper reaches feature ranking, including informal place names (e.g., philly,informal name Philadelphia, US-PA), local transport references (e.g., skytrain, public transport system Vancouver, CA) local greetings (e.g., aloha Honolulu, US-HI). However,reasonable believe 1-local words words predominantly used one cityrarely mentioned cities common. result, accuracy boundedlimited number true 1-local words. could reason early, yet remarkablyhigh, peak accuracy, subsequent sharp decline, Ripley; reliance pairwisedistances users using given word, Ripley tends rank 1-local words highly. contrast,collective methods assume words carry varying amounts geospatial information. leveraging combinations LIWs, true location user collectively inferred. instance,brunswick common suburb/street name many cities, e.g., Melbourne, AU London, GB.word alone insufficient make reliable predictions. However, LIWs (e.g., tramFlinders, uniquely disambiguating themselves) also observed,chance location Melbourne, AU becomes high, since unlikely userscities Melbourne, AU would use combination words. strategy alsoexplained information-theoretic terms: knowing words, extra information obtained,consequently entropy continuously reduced prediction geolocation becomescertain.Among feature selection methods, IGR, GeoDen Ripley stand-out methodsterms Acc@161. compare accuracy classifiers trained using optimisedset LIWs (based development data) full model. performance measured10K held-out test users, using city-based class representation. results displayedTable 3 (for subset feature selection methods displayed Figure 3),show using LIWs offers improvement full feature set evaluation measuresfeature selection methods, except slight dips Acc@C IGR GeoDen. Nevertheless, numbers clearly demonstrate feature selection improve text-based geolocationprediction accuracy. IGR performs best terms accuracy, achieving 8.9% 14.2% absoluteimprovements Acc Acc@161, respectively, full feature set.5.2 Comparison Benchmarkscompare best-performing method Section 5.1 number benchmarksbaselines. experiment two class representations: (1) city-based class representation based Geonames; (2) k-d tree based partitioning Roller et al. (2012),creates grid cells containing roughly even amounts data differing geographical sizes,higher-population areas represented finer-grained grids.19 class representations,19. Recent work (Schulz et al., 2013) also considers irregular-sized polygons, based administrative regions like cities.472fiT EXT-BASED WITTER U SER G EOLOCATION P REDICTIONDatasetFeaturesAccAcc@161Acc@CMedianNAFullICFChiIGRLogLikeGeoDenRipley0.1710.2090.2330.2600.1910.2580.2360.3080.3590.4020.4500.3430.4450.4320.8310.8400.8500.8110.8360.7910.849571533385260489282306Table 3: Results full feature set compared representative samplefeature selection methodologies NA city-based class representation. bestnumbers shown boldface.compare learners without feature selection. observed previously, Acc comparable across two class representations. Results based distance-based measures (Acc@161Median), hand, directly comparable. Acc@C results presented kd tree based class representation k-d tree cells map cleanly onto national borders;although could certainly take country centroid given k-d tree cell liescountry label entire cell, approach would ignore known geo-political boundaries.consider following methods:Baseline: geographical distribution tweets skewed towards higher-populationareas (as indicated Figure 1), consider most-frequent class baseline. assignusers coordinates most-common city centre (or k-d tree grid centroid)training data.Placemaker: Following Kinsella et al. (2011), obtain results Yahoo! Placemaker,20publicly-available geolocation service. first 50K bytes (the maximum query length allowed Placemaker) tweets user passed Placemaker queries.returned city centre predictions mapped collapsed city representations.queries without results, predicted location outside North America, backmost-frequent class baseline.21Multinomial naive Bayes: model used Section 5.1.KL divergence: previous best results NA achieved using KL divergence k-dtree grid (Roller et al., 2012). Using k-d tree, earths surface partitioned nearrectangular polygons vary size, contain approximately number users.Locations represented cells grid. KL divergence utilised measuresimilarity distribution words users aggregated tweets gridcell, predicted location centroid most-similar grid cell.2220. http://developer.yahoo.com/geo/placemaker/, accessed August 2012.21. alternative would query Placemaker tweet, aggregate predictions (e.g., selectingmajority location) get final user-level prediction. However, Kinsella et al. (2011) found accuracyapproach largely similar approach use.22. use settings Roller et al. (2012): median-based k-d tree partition, partition containingapproximately 1050 users.473fiH , C OOK & BALDWINPartitionMethodCityBaselinePlacemakerNBNB+IGRLRLR+IGRAccAcc@161Acc@CMedian0.0030.0490.1710.2600.1290.2290.0620.1500.3080.4500.2320.4060.9470.5250.8310.8110.7560.84230891857571260878369Table 4: Geolocation performance using city-based partition NA. Results using optimisedfeature set (+IGR) also shown. best-performing method evaluation measure class representation shown boldface.PartitionMethodk-d treeBaselineNBNB+IGRKLKL+IGRAccAcc@161Acc@CMedian0.0030.1220.1530.1170.1610.1180.3670.4320.3440.4371189404280469273Table 5: Geolocation performance using k-d tree-based partition NA. Results using optimised feature set (+IGR) also shown. best-performing method evaluationmeasure class representation shown boldface.Logistic regression: also apply logistic regression Section 4.2.2 learner. Insteadmodelling data, use IGR-selected features Section 5.1. regularisation commonly employed logistic regression learners, made conscious choiceuse experiments implementation regulariser would differ acrosslearners complicate direct comparison feature selection methods (i.e. woulddifficult tease apart impact specific regulariser feature selection). said that, objective maximise raw classifier accuracy distinctexploring impact different features feature selection methods classification accuracy would advocate incorporation regulariser.Instead evaluating every possible combination model, partition feature set, chooserepresentative combinations test extent LIWs improve accuracy. resultscity-based partition shown Table 4. begin considering baseline results. mostfrequent class city-based representation Los Angeles, US-CA.23 majority classbaseline Placemaker perform well multinomial naive Bayes (NB) logistic regression(LR), high Median distances. Furthermore, using features selected Section 5.1 (i.e., NB+IGR LR+IGR), performance improved large marginmodels, demonstrating identification LIWs improve text-based geolocation prediction. Finally, although LR performs poorly compared NB, LR+IGR still improves substantially23. New York divided suburbs, manhattan-ny061-us, brooklyn-ny047-us, Geonames.artefact this, suburbs merged single city.474fiT EXT-BASED WITTER U SER G EOLOCATION P REDICTIONLR. plan explore reasons LRs poor performance future work. Overall,NB+IGR performs best city-based representation terms Acc, Acc@161, Mediandistance.Turning k-d tree-based partition Table 5, observe low performancemost-frequent class baseline (i.e., grid cell near New York state). NB KL representativegenerative discriminative models, respectively evaluated using software providedRoller et al. (2012).24 approaches clearly outperform baseline k-d tree classrepresentation. Furthermore, performance increases using resultant feature setLIWs,25 demonstrating variety approaches, identification LIWs improve textbased geolocation.Overall, compared previously-published results k-d tree based representation (KL),IGR-based feature selection city-based partition achieves 10.6% absolute improvementterms Acc@161, reduces Median prediction error 209km.results k-d tree based representation, clear KL NB bettertask: terms Acc@161, NB outperforms KL, KL+IGR outperforms NB+IGR.differences small, however, suggesting two methods largely indistinguishableuser geolocation task. question class representation used user geolocation, empirically, seems little separate two, although experimentationmay shed light issue. city-based approach intuitive, enables convenientcountry-level mapping coarser-grained geolocation tasks. Furthermore, observationFigure 1 suggests Twitter users cities. therefore use city-based partitionremainder paper consistency ease interpretation.spin-off benefit feature selection leads compact models,efficient terms computational processing memory. Comparing model based LIWsselected using IGR full model, find prediction time faster factorroughly five.6. Experiments WORLDaddition establishing comparisons NA, evaluate feature selection methodsWORLD. extends evaluation regional benchmarks global geolocation performance. Similar NA, WORLD reserve 10K random users dev test,remainder users used training (preprocessed described Section 3.4).experiments WORLD related datasets, base evaluation city label set.apply tuning procedure used NA obtain optimal feature setfeature selection method. present results representative sample best-performingmethods Figure 4. again, omit methods largely identical behaviourmethods, namely:{DistDitv , DistDiskl } ICF{MaxChi , Chi , LogLike, IG, GeoSpread } LR24. https://github.com/utcompling/textgrounder/wiki/RollerEtAl_EMNLP201225. Note LIWs selected, small proportion users end features. users geolocatablecase KL, discriminative model. turn feature selection users, backoff full featureset, number test instances consistent rows.475fiH , C OOK & BALDWIN0.25Acc1610.200.150.10ICFGeoDenRipleyIGRLR0.050.002% 8%16%24%32%40%48%56%64%72%80%88%96%Top N% FeaturesFigure 4: Acc@161 varying percentages features selected using representative feature selection methods WORLD dataset.biggest differences Figure 3 are: (1) 2 -based methods converge behaviourLR, LogLike related methods; (2) LR performs marginally better LogLike,thus method present graph.Despite difference scope data size, overall trend WORLD mirrorsNA. particular, GeoDen, IGR Ripley achieve best Acc@161 numbers dev data,although numbers lower achieved NA Figure 3. WORLDfewer tweets per user NA (as utilise geo-tagged data), disambiguationglobal level also makes challenging task.results multinomial naive Bayes chosen feature selection methods WORLDshown Table 6. GeoDen (62%), IGR (86%) Ripley (20%) achieve bestaccuracy, although clear winner: IGR achieves best Acc Ripley achievesbest Acc@161. Nevertheless, improved city-based Acc Acc@161 numbers confirmgeneral effectiveness feature selection. basis similar results earlier NAresults (in IGR delivers better results), adopt IGR default LIW feature selectionmethod remainder paper.summary, findings utility feature selection Table 3 (NA) Table 6 (WORLD)tell similar story, namely feature selection improves user geolocation accuracy. impactfeature selection NA much greater WORLD, WORLD larger numberclasses smaller average number tweets per user also per class, makingchallenging dataset.476fiT EXT-BASED WITTER U SER G EOLOCATION P REDICTIONDatasetFeaturesAccAcc@161Acc@CMedianWORLDFullICFIGRLRGeoDenRipley0.0810.1100.1260.1040.1230.1210.2000.2410.2620.2330.2660.2680.8070.7880.6840.7920.6910.5828868379136408421128Table 6: Results full feature set compared representative sample featureselection methodologies WORLD using NB. best numbers shown boldface.TrainGG+NGGG+NGTestGGG+NGG+NGAcc0.1260.1700.1870.280Acc@1610.2620.3230.3660.492Acc@C0.6840.7330.8350.878Median913615398170GG+NGNGNG0.1610.2410.3310.4400.7900.826516272GGG-smallNG-small0.1210.1140.2580.2480.6750.6669601057Table 7: results geolocation models trained tested geotagged (G) non-geotagged(NG) tweets, combination.7. Exploiting Non-geotagged TweetsTwitter-based geolocation research carried date (Eisenstein et al., 2010; Wing & Baldridge, 2011) trained geotagged tweets, tweets known geographicalcoordinates. work (Roller et al., 2012) also incorporated non-geotagged tweetsusers whose location inferred geotagged tweets. Clearly, possible effectivelyutilise non-geotagged tweets, data sparsity ameliorated (as arent restrictingtraining approximately 1% tweets known location), clear tradeoffconfidence place labels associated tweets/users. section,investigate utility non-geotagged tweets geolocation prediction.experiments section, rest paper, use WORLD+NG denotedataset incorporates geotagged non-geotagged tweets usersWORLD. refer subparts dataset consisting geotagged non-geotagged tweetsG NG, respectively. 194M tweets WORLD+NG, 12M geotagged remaining 182M non-geotagged. use partitioning users training, development,testing sets WORLD+NG WORLD. compare relative impact NGtrain test geolocation method G, NG, combination. Results presentedTable 7.first row Table 7 shows results using geotagged data (our best result Table6). rows two three, show results data user training test477fiH , C OOK & BALDWINdatasets, respectively, expanded incorporate non-geotagged data (without changing setusers label user either case). cases, evaluation measures,performance substantially better benchmark (i.e., first row). finding lineCheng et al.s (2010) results data spareness big issue text-based geolocation. alsovalidates hypothesis non-geotagged tweets indicative location. best resultsachieved non-geotagged tweets incorporated training testing data (shownrow four). case achieve accuracy 28.0%, 15.4 percentage point increasebenchmark using geotagged tweets represent given user. Moreover, predictionwithin 161km correct location almost one every two users, country-levelaccuracy reaches almost 88%.26Although research text-based geolocation used geotagged data evaluation, ultimate goal line research able reliably predict locations userslocation known, i.e., non-geotagged data. geotagged tweetstypically sent via GPS-enabled devices smartphones, non-geotagged tweets sentwider range devices, could systematic differences content geotaggednon-geotagged tweets. examine issue rows five six Table 7, testmodel non-geotagged data. case know test users gold-standard locationbased geotagged tweets. However geotagged tweets used represent usertest instance; instead, user represented non-geotagged tweets. resultsactually better experiments training data tested geotaggedtweets (i.e., rows one two table).27 confirms model trained G G+NGindeed generalises NG data. However, clear whether finding duemuch non-geotagged geotagged data given user, whether propertynon-geotagged data makes easier classify. explore question, carry following additional experiment. First, construct new dataset NG-small down-sampling NGcontain number features per user G (in terms feature token count). makecomparison fairer, constructed second new dataset G-small excludetest users G tweets NG tweets. guarantees users NG-small containnumber LIWs G-small. average five iterations random subsampling,list result final row Table 7.28 see results NG-smallgood G-small (i.e., row seven), suggesting might minor sub-domain differencesgeotagged non-geotagged tweets, though strong conclusion cannot drawn withoutin-depth analysis. One possible explanation could differences (e.g., demographic variations) users non-geotagged tweets usersnon-geotagged tweets geotagged tweets; however, comparing two sources beyondscope paper. Nonetheless, results suggest difference NG G largely dueabundant data NG. explanation also supported recent work Priedhorskyet al. (2014).26. Note evaluation exactly set users four cases; changes whetherincorporate extra tweets pre-existing set users, training test data.27. remove users geotagged tweets test data, reducing number users marginally10,000 9,767.28. Note calculated variance five iterations random subsampling, found negligibleevaluation measures.478fiT EXT-BASED WITTER U SER G EOLOCATION P REDICTIONsummary, quantitatively demonstrated impact non-geotagged tweets geolocation prediction, verified models trained geotagged data indeed applicablenon-geotagged data, even though minor sub-domain differences appear exist. also established representing user combination geotagged non-geotagged tweetsproduces best results.8. Language Influence Geolocation PredictionPrevious research text-based geolocation primarily focused English data. studieseither explicitly excluded non-English data, based datasets consisting primarily English messages, e.g., selection tweets predominantly English-speakingregions (Eisenstein et al., 2010; Cheng et al., 2010; Wing & Baldridge, 2011; Roller et al., 2012).However, Twitter multilingual medium languages might powerful indicatorslocation: example, user posts mostly Japanese tweets, could strong indicationuser based Japan, could used bias class priors user. section,explore influence language geolocation prediction. predominant languagegiven tweet identified using langid.py,29 trained recognise 97 languages(Lui & Baldwin, 2012).create dataset consisting multilingual geotagged tweets, extract geotagged dataregardless language Twitter crawl WORLD based on. multilingual dataset consists 23M tweets 2.1M users. 12M tweets English WORLD,remaining 11M tweets languages. Figure 5 shows proportion tweetsfifteen common languages dataset.30 immediate observation large difference language distribution observe geo-tagged tweets comparedobserved tweets (irrespective geotag: Hong, Convertino, & Chi, 2011; Baldwin, Cook,Lui, MacKinlay, & Wang, 2013): among higher-density languages Twitter, appearsweak positive bias towards English users geotagging tweets, strong negative biasJapanese, Korean German users geotagging tweets. speculatenegative bias caused stronger concerns/awareness privacy issues countries Japan,South Korea, Germany Austria. explored question whether bias influencedchoice Twitter client looking distribution Twitter clients used post messagesEnglish, German, Japanese Korean: (a) overall (irrespective whether messagegeotagged not), based 1M sample tweets 28 Sep, 2011; (b) geotaggedtweets, based WORLD. Overall, found huge variety choice client usedwithin given language (with top-10 clients accounting 6578% posts, dependinglanguage), significant differences popular clients languages (e.g. Keitai Webpopular client Japanese, web English German, Twitter AndroidKorean). geotagged tweets, hand, much greater consistency,three popular clients languages Twitter iOS, Twitter Androidfoursquare, accounting relatively constant two-thirds posts language.suggestive fact choice client one factor biasing relative proportion29. Based simplifying assumptions that: (a) every tweet contains linguistic content; (b) tweets monolingual, least predominantly single language.30. represent languages Figure 5 using two-letter ISO 639-1 codes.479fiH , C OOK & BALDWIN0.30.20.1Percentage0.40.50.530.090.00.04 0.03 0.03enesptjanl0.02 0.02 0.02 0.02 0.01 0.01 0.01 0.01 0.01 0.01idrudetrfrmsthkoarLanguagesFigure 5: percentage tweets WORLD+ML written fifteen frequentlanguages collected Twitter data. fifteen languages account 88%tweets full dataset.geotagged tweets different languages, although research required fully understandeffect.training, development test data re-partitioned multilingual setting stratifylanguage, resultant dataset referred WORLD+ML. Again, developmenttesting sets consist 10K users each, remaining users training set WORLD.Although Section 7 showed adding non-geotagged data improves geolocation accuracy,experiments section based geotagged data, prohibitive computational cost experimenting much larger dataset. Note doesnt limit generalisability results, simply means careful compare monolingualresults Table 7 based geotagged tweets (the first row).first compare geolocation performance multilingual setting English-onlysetting, comparison past work geolocation considered. data WORLD+MLpartitioned two subsets E NE according whether majority givenusers tweets English non-English, respectively. 10K test users WORLD+ML,5,916 English 4,084 non-English. One challenge multilingual settingexperiments tokenisation. Although rudimentary tokenisation many languages EnglishFrench accomplished using whitespace punctuation, tokenisation muchchallenging languages Japanese Chinese represent word boundaries480fiT EXT-BASED WITTER U SER G EOLOCATION P REDICTIONTrainTestE+NEE+NEE+NEEE+NEENEEAccAcc@161Acc@C0.1960.1340.2870.1690.3430.2560.4680.3170.7720.7150.8550.746Median4661067200632Table 8: Results multilingual geolocation, training testing English (E) non-English(NE) users, combination.whitespace. However, amongst most-common languages Twitter (as shown Figure5), Japanese language accounts substantial portion data (> 1%)requires specialised tokenisation strategy (compared English). Japanese tweetsapply Japanese morphological segmenter MeCab (with IPA dictionary),31 post-correcttokenisation errors relating Twitter-specific tokens mentions, hashtags, URLs (e.g.,instances MeCab over-segments mention multiple morphemes). non-Japanesetweets, apply tokeniser based regular expressions used previous English-onlyexperiments.resolving tokenisation issue, apply IGR method Section 4.2.1select optimised feature selection cut-off, based Acc development data. observemuch larger proportion tokens selected multilingual setting comparedEnglish-only experiments. example, 400K token types multilingual experiment,384K (the top 96%) selected location-indicative, English-only case 83K (the top86%) location-indicative words selected total 96K token types.experimental results shown Table 8.32 first row gives results trainingtesting full dataset English non-English tweets. next two rows showresults testing English (E) non-English (NE) subsets data. much loweraccuracy E compared NE indicates English tweets much difficult geolocatenon-English tweets. One reason many non-English languages,strong bias towards small number cities. verify calculating class entropyrespective language training data. class probabilities smoothed using simpleadd- method, = 1/3709 (where 3709 size class set). shown Table 9,class entropy English (en) data largest, indicating English prevalent across largenumber locations. contrast, Thai (th) Turkish (tr) much smaller entropies, suggestinglocation distributions heavily skewed, user geolocation languageseasier English.explore extent geolocatability user varies respect predominant language tweets, break results language Table 10,shows results top-10 frequent languages (by number tweets) least 100 userstest data. cut-off users ensures consider under-represented languages.31. http://sourceforge.net/projects/mecab/32. English-only results reported comparable experiment Table 7 usinggeotagged data, test sets consist different users two cases.481fiH , C OOK & BALDWINLanguageEntropyLanguageEntropyLanguageEntropyenesptjanl6.2795.0694.1443.5233.820idrudetr3.8685.2443.7726.2072.888frmsthkoar5.5383.9702.6972.7813.281Table 9: Geolocation class entropy top-15 languagesLang.enesptidnljarutrarthNo.5916945673398342298217186164154Per-language Majority ClassUnified MultilingualMonolingual PartitioningAcc Acc@161 Acc@C Med.Acc Acc@161 Acc@C Med.Acc Acc@161 Acc@C Med.0.0190.1160.2230.2640.1750.3260.3360.5380.3350.3250.0390.1590.2960.4720.7890.5300.3780.6560.4700.7660.655 36710.324 42670.952 4900.899 1970.889870.960960.857 6330.93000.463 3790.981200.1340.2670.2320.3240.1730.3360.3460.5380.3540.2790.2560.3460.3050.5650.7890.5440.3870.6560.4880.6230.715 10670.734 3910.952 4900.965 1150.889870.956950.862 6330.93000.500 3010.792410.1690.3620.4000.4400.2980.4630.3410.5220.4570.3250.3170.4780.4890.7360.8710.6950.3780.6450.5910.7660.7460.8020.9610.9600.8450.9500.8620.9300.7500.9746321852001658276330213010000 0.1070.1890.693 28050.1960.3430.7720.2550.4250.802302466Table 10: Geolocation performance comparison top-10 frequent languagesmultilingual test data, using (1) language prior (i.e., city language mostlyused); (2) unified multilingual model (i.e., training testing multilingual dataregardless languages); (3) language-partitioned monolingual models (i.e., firstidentify primary language users, train one model per language, classify testusers model corresponding language tweets)observe results vary remarkably language multilingual section Table10. results overall lowest English (en), although lowest country-level accuracyArabic (ar); speculate caused large number countries Arabic spokenin, relatively small number Arabic speakers training data. Furthermore, citylevel accuracy better 30% Indonesian (id), Japanese (ja), Russian (ru), Turkish (tr)Arabic (ar); regions languages commonly-spoken geographicallyrestricted English, suggesting geolocation accuracy languages smaller geographic footprints tend higher languages widely-used throughoutlarger geographical area. finding agrees recent work Priedhorsky et al. (2014),underlines power language information predicting locations. best city-levelaccuracy 53.8% observed Turkish (one languages lowest city-level entropy).Manually inspecting outputs, find model predicts city IstanbulTurkish users, large proportion Turkish tweets come city.482fiT EXT-BASED WITTER U SER G EOLOCATION P REDICTIONBased finding, consider language-based benchmark predictsfrequent city given predominant language users tweets (denoted Per-language MajorityClass). also observe performance gap multilingual model English (the secondrow Table 8) English-only model (the bottom row Table 8). results showtarget data known written single language monolingual model outperformsmultilingual one. also suggests alternative approach multilingual geolocation prediction:rather training predicting multilingual data (E+NE), train evaluate modelslanguage-specific data. Motivated observation, also apply monolingual partitionedmodel users particular language based langid.py (i.e., language partitions), e.g.,selecting Japanese users training data, applying Japanese-specific modelJapanese users test data. denoted Monolingual Partitioning Table 10,contrasted simple approach combined model languages users (UnifiedMultilingual).comparing Per-language Majority Class Unified Multilingual model, findunified model performs better overall, exception Thai (th) Dutch (nl),associated small number cities, one city much largerothers (Bangkok, TH Amsterdam, NL, respectively). relatively poor resultsbenchmark method languages English (en) Spanish (es) frequentTwitter, relatively poor overall performance, Per-language Majority Classappropriate method task. Nevertheless, using Monolingual Partitioning model,results far superior, partitioning effect language seen. suggestsmodelling language independently improve geolocation performance.summary, series experiments shown influence language geolocation prediction. Among top-10 languages found Twitter, English difficult perform usergeolocation over, English global language. Despite language variance, multilingualgeolocation prediction certainly feasible, although best way leverage language geolocation prediction training language-partitioned monolingual models geolocating users basedprimary language.9. Incorporating User Meta Datametadata accompanying tweets valuable source geographical information beyondavailable tweets. section, explore incorporating metadata information textbased geolocation system. begin selecting four metadata fields could potentially provideinsights location user, first evaluate models trained sourcesinformation. consider number ways incorporate information metadatabest text-based method developed Section 7. discussed Section 8, languagestrong influence geolocation prediction, English-posting users hardest geolocate.such, experiment English data (i.e., WORLD+NG) remainder paper.483fiH , C OOK & BALDWINDataTrainingTestLOCTZDESC0.8130.8130.7520.7530.7600.761Table 11: proportion users non-empty metadata fields WORLD+NG9.1 Unlock Potential User-Declared Metadatachoose following four user-supplied metadata fields study: location (LOC), timezone(TZ), description (DESC), users real name (RNAME).33 contrast rich social networkinformation much expensive extract, metadata fields includedJSON object provided Twitter Streaming API, i.e., extract metadataextra crawling cost. information, however, dynamic, i.e., users change profiles,including metadata interest us. aggregating extracted tweet-level metadatauser, calculate ratio users change metadata field. 18% users changedDESC field approximately five months dataset collected.time period, fields considered, less 8% users updated data.Given relatively small number profile updates, ignore influence changes,use frequent value metadata field user experiments.user-supplied metadata imprecise inaccurate, user freeenter whatever textual information choose. example, LOC fields accuratedescriptions geographical locations (e.g., best place universe). Moreover, althoughLOC fields canonical renderings users true location (e.g., Boston, MA, USA), largenumber abbreviations non-standard forms also observed (e.g., MEL Melbourne, AU).Cheng et al. (2010) find small proportion location fields US-based datasetcanonical locations (i.e., form city, state). Nevertheless, non-standard inaccuratelocation fields might still carry information location (Kinsella et al., 2011), similarlytext tweets indicate location without explicitly mentioning place names.metadata fields also differ respect explicitness location informationencode. instance, LOC TZ give direct location information, DESC might containreferences location, e.g., geek Lisp developer Bangalore. Although RNAMEdirectly encode location regional preferences names (Bergsma, Dredze, Van Durme,Wilson, & Yarowsky, 2013), e.g., Petrov might common Russia, name Hasegawamight common Japan. Finally, tweets consider, text field (i.e.,content tweet itself) RNAME always present, LOC, TZ, DESC missinguser chosen supply information. proportion non-empty metadata fieldsLOC , TZ DESC users WORLD+NG listed Table 11.9.2 Results Metadata-Based Classifiersvariable reliability explicitness selected metadata, incorporatefields statistical geolocation model similar manner message text. prelimi33. user-supplied real name could name i.e., necessarily users actual name differentfield users screen name.484fiT EXT-BASED WITTER U SER G EOLOCATION P REDICTIONClassifierLOCTZDESCRNAMEBASELINETEXTAccAcc@161Acc@CMedian0.4050.0640.0480.0450.5250.1710.1170.1090.8340.5650.5260.550921330290726110.0080.2800.0190.4920.6000.8783719170Table 12: performance NB classifiers based individual metadata fields, well baseline, text-only classifier IGR feature selection.nary experiments, considered bag-of-words features metadata fields, well bag-ofcharacter n-gram features n {1, ..., 4}.34 found character 4-grams perform best,report results using features here. (A bag-of-character 4-grams represents frequencyfour-character sequence including start end symbol.) geolocation performanceclassifier trained features metadata field isolation, well performancefrequent city baseline (BASELINE) best purely text-based classifier (TEXT, replicatedTable 7), shown Table 12.classifier based metadata field outperforms baseline terms Acc, Acc@161,Median error distance. suggests metadata fields indeed encode geographicallyidentifying information, though classifiers less competitive TEXT. Notably, despitepotential noise user-supplied location fields, classifier (LOC) achieves even betterperformance purely text-based method, reaching city-level accuracy 40%, predicting location within 161km true location half users. suggests LOCcontains valuable information, even though LOC fields noisy (Cheng et al., 2010),easily captured off-the-shelf geolocation tools (Hecht et al., 2011). Manual analysis suggestsmany vernacular place names captured statistical modelling, KiladelphiaPhilly used represent Philadelphia. utility metadata fields also confirmed recentwork Priedhorsky et al. (2014).9.3 Ensemble Learning Text-Based Classifiersanalyse behaviour four metadata classifiers, consider pairwise city-levelprediction agreement them. Cohens Kappa (Carletta, 1996) conventional metricevaluate inter-annotator agreement categorical items (such predicted cities case);larger Kappa values indicate higher pairwise agreement. double fault measure (Giacinto &Roli, 2001) incorporates gold-standard information, equal proportion test casesclassifiers make false prediction. measure offers empirical lowest error boundpairwise ensemble classifier performance.34. Although could certainly also consider character n-grams text-based classifier, opted bag-ofwords representation explicitly captures LIWs believe especially important geolocation.could also location-indicative character n-grams, exploration leave future work.485fiH , C OOK & BALDWINTEXT0.4610.6890.7020.7040.181LOC0.5770.5780.5810.0660.063TZ0.9030.9070.0670.0410.085DESC0.9230.0650.0490.0800.088RNAMETable 13: Pairwise correlation base classifiers using Cohens Kappa (bottom left, lightgrey; higher numbers indicate greater prediction similarity) double fault measure(top right, white; lower numbers indicate greater prediction similarity).Pairwise scores Cohens Kappa double fault measure shown Table 13.Kappa scores (bottom-left Table 13) low, indicating little agreementclassifiers. classifiers achieve better baseline performance, also give quitedifferent outputs, might possible combine classifiers achieve better performance.double fault results (top-right) suggest improved accuracy could obtainedcombining classifiers.combine individual classifiers using meta-classification. first adopt feature concatenation strategy incrementally combines feature vectors TEXT, LOC, TZ, DESCRNAME . also consider stacked generalisation (Wolpert, 1992), referred simply stacking,outputs base classifiers, true city-level locations, used trainsecond classifier produces final output. base classifiers, second classifier,referred L0 L1 classifiers, respectively. conventional applications stacking,homogeneous training data used train heterogeneous L0 classifiers; case, however,train homogeneous L0 multinomial Bayes models heterogeneous data (i.e., different typesdata TEXT, LOC, TZ). consider logistic regression (Fan, Chang, Hsieh, Wang, &Lin, 2008) multinomial Bayes L1 classifier.carry 10-fold cross validation training users obtain L1 (final) classifierresults, standard procedure stacking experiments. use stratified sampling partitioningdata number users different cities varies remarkably, simple randomsample could bias towards bigger cities. ensemble learning results tabulated Table14.combination TEXT LOC improvement LOC (i.e., best results far).However, using feature concatenation multinomial naive Bayes stacking, accuracy generallydrops metadata feature sets perform relatively poorly isolation (i.e., TZ, DESC, RNAME)incorporated. hand, using logistic regression stacking, see small increasesaccuracy features perform less well isolation incorporated. Though DESC RNAMEmoderately useful (as shown Table 12), fields contribute little strong ensembles(i.e., TEXT, LOC TZ). best model (using logistic regression stacking features)assigns users correct city almost 50% test cases, Median error9km. Moreover, approach country-level accuracy reaches almost 92%, indicatingeffectiveness method coarse-grained geolocation task.486fiT EXT-BASED WITTER U SER G EOLOCATION P REDICTIONFeature concatenationAccAcc@1610.4440.6460.4290.6390.3190.5290.2940.5031.2.3.4.FeaturesTEXT + LOC1. + TZ2. + DESC3. + RNAMEAcc@C0.9230.9290.9120.912Median27321271561.2.3.4.Multinomial Bayes stackingFeaturesAccAcc@161 Acc@CTEXT + LOC0.4700.6600.9331. + TZ0.4600.6530.9302. + DESC0.4510.6450.9313. + RNAME 0.4510.6450.931Median192327271.2.3.4.Logistic regression stackingFeaturesAccAcc@161 Acc@CTEXT + LOC0.4830.6530.9031. + TZ0.4900.6650.9172. + DESC0.4900.6660.9193. + RNAME 0.4910.6670.919Median14999Table 14: performance classifiers combining information text metadata using feature concatenation (top), multinomial Bayes stacking (middle), logistic regressionstacking (bottom). Features 1. + TZ refer features used row 1.combination TZ.interesting observe that, found NB outperform LR standalone classifierSection 5.2, L1 classifier, LR clearly outperforms NB. reason almost certainly fact use much smaller feature set relative number training instancesstacking experiments, circumstances, discriminative models tend outperformgenerative models (Ng & Jordan, 2002).10. Temporal Influenceaddition held-out English test data WORLD+NG, also developed new geotaggedtest dataset measure impact time model generalisation. training test dataWORLD+NG time-homogeneous randomly partitioned based data collectedperiod. contrast, new test dataset (LIVE) much newer, collected 1year later WORLD+NG. Given Twitter users topics change rapidly, key questionwhether statistical model learned old training data still effective newtest data? question implications maintenance retraining geolocation modelstime. experiments section train WORLD+NG test new dataset.LIVE data collected 48 hours 3 Mar, 2013 5 Mar, 2013, based geotagged tweets users whose declared language English. Recent status updates (up 200)crawled user, langid.py applied data remove remnant nonEnglish messages. addition filtering users less 10 geotagged tweets test dataWORLD+NG, exclude users less 50% geotagged tweets one487fiH , C OOK & BALDWINFeatures1. TEXT2. LOC3. TZ1. + 2. + 3.Acc0.2800.4050.0640.490Features1. TEXT2. LOC3. TZ1. + 2. + 3.Acc0.2680.3260.0650.406WORLD+NGAcc@161 Acc@C0.4920.8780.5250.8340.1710.5650.6650.917LIVEAcc@1610.5100.4650.1600.614Acc@C0.9010.8130.5250.901Median1709213309Median151306152940Table 15: Generalisation comparison time-homogeneous WORLD+NG timeheterogeneous LIVE (1. + 2. + 3. denotes stacking TEXT, LOC TZ).city. users geotagged tweets spread across different locations, lesscredible adopt users frequent location true primary location evaluation.post-check WORLD+NG test data shows 9,977 10K users satisfy requirementgeographical coherence, arent unnecessarily biasing data LIVE applyingcriterion. Finally, status updates aggregated user-level, WORLD+NG.filtering, 32K users obtained, forming final LIVE dataset.use TEXT, LOC TZ section, require less computation achieveaccuracy comparable best results, shown Table 14. temporal factor impactgeolocation prediction model generalisation revealed accuracy WORLD+NG LIVEshown Table 15. Acc Acc@161 numbers stacked model (1. + 2. + 3.) dropapproximately 8 5 percentage points, respectively, LIVE compared WORLD+NG.Median prediction error distance also increases moderately 9km 40km. decomposingstacked models evaluating base classifiers, find accuracy declinesprimarily caused accuracy drops LOC classifier new LIVE data, approximately9% Acc 6% Acc@161. could viewed type over-fitting, stackedclassifier relying heavily predictions LOC base classifier. TZ classifierperforms relatively constantly terms accuracy, although Median error increases slightly.TEXT classifier remarkably robust, numbers except Acc improving marginally.investigate poor LOC classifier generalisation LIVE. First, down-sampleLIVE 10K users, size WORLD+NG, compare per-city prediction numbers two datasets using LOC classifier. find two factors jointly cause accuracydecrease LIVE: (1) composition test users, (2) decline per-city recall. instance, 80 test users London, GB WORLD+NG. number sharply increases 155LIVE, meaning influence London, GB test users overall accuracy LIVE almostdoubled. Furthermore, recall proportion users given location correctlypredicted location London, GB drops 0.676 WORLD+NG0.568 LIVE. observe proportion empty LOC fields among London, GB test usersjumps 13% (WORLD+NG) 26% (LIVE). reduces utility LOC data LIVE488fiT EXT-BASED WITTER U SER G EOLOCATION P REDICTIONRankcities LIVE12345678910Los Angeles, USKuala Lumpur,London, GBJakarta, IDAnaheim, USSingapore, SGFort Worth, USChicago, USPittsburgh, USSan Antonio, USLIVE usersLIVE recallWORLD+NG usersWORLD+NG recall2011681551298576767272660.7660.4820.5680.5500.4470.4740.2890.5690.4310.45581508086261603512339820.6910.5600.6750.6860.3460.5560.3710.5770.4870.585Table 16: number test users, recall usingLIVE, compared WORLD+NG.LOC ,city, top-10 largest citiesexplains per-city recall drops: test users empty LOC field assignedcity highest class prior model (i.e., Los Angeles, US). Overall, ratios emptyLOC fields WORLD+NG test data LIVE 0.176 0.305, respectively, suggestinguser-declared locations LIVE carry much less geospatial information WORLD+NG.show comparisons top-10 cities terms test users Table 16,35 accuracyhighly-represented cities greater impact overall results smaller cities.Like London, GB, cities shown Table 16 experience lower recall scores LIVE, manytest users LIVE WORLD+NG. Nevertheless, cities higherrecall test users LIVE, e.g., Los Angeles, US Anaheim, US Table 16. overallnumbers are, course, determined aggregated performance cities. provide insight, 35.6% cities WORLD+NG 40% recall, number 28.5%LIVE.important base classifier stacked model, LOC accuracy numbersinfluenced temporal changes, whether increased reluctance supply userdeclared location (although admittedly users geotag tweets), primarily due variance user proportions different cities sampled stream. Either way, periodically retrained LOC classifier would, doubt, go way towards remedying temporal gap. Overall,numbers suggest time-homogeneous data (WORLD+NG) easier classify timeheterogeneous data (LIVE). However, training old data testing new datashown empirically viable TEXT TZ base classifiers particular. result alsovalidates efforts optimise text-based user geolocation classification accuracy. Recently, similarresults tweet-level geolocation prediction observed Priedhorsky et al. (2014), supportingclaim accuracy geolocation prediction suffers diachronic mismatchestraining test data.35. observe city proportions changed drastically WORLD+NG LIVE. reasonsunclear, speculate due significant shifts microblogging usage different locationsaround world.489fiH , C OOK & BALDWIN11. User Tweeting Behaviourimproved extended text-based geolocation prediction, shift focus usergeolocatability. user wishes keep geolocation private, simply disable publicaccess tweets metadata. However, users choose share (non-geotagged) tweets,different tweeting behaviours make susceptible geolocation privacy attacks? investigate question, section, discuss impact user behaviourgeolocation accuracy relative predictions LIVE based stacking model Section10.36obvious first rule thumb, geotagged tweets avoided, provideimmediate access users geographical footprint, e.g., favourite bars, office address.Second, immediate implication finding location metadata strong predictorgeolocation (Section 9.2), user wants avoid privacy attacks, avoid presentinglocation metadata, effect disabling LOC base classifier stacked classifier. Third, textusers posts used geolocate user (at approximately 27% Acc, Table 15).investigate impact volume tweets user geolocatability, perform breakdownresults LIVE across two dimensions: (1) number LIWs, investigate whethersheer volume tweets user makes geolocatable; (2) source geospatialinformation exploit geolocation model. evaluate questions Figure 6four feature combination settings, relative the: (1) tweet text-based classifier; (2) tweet textbased classifier gazetteer names removed;37 (3) metadata stacking using LOC TZ (invarianttweet number changes); (4) stacking TEXT, LOC TZ users. case,partition data 20 partitions 5% users each, ranked total number LIWscontained combined posts user. addition Acc user partition,also indicate average number LIWs per user partition (as shown second y-axis,right side graph).Overall, LIWs contained users tweets, higher Acc text-based methods. gazetted terms removed tweets, Acc drops large margin. suggestsgazetted terms play crucial role user geolocation. Metadata also contributes substantially accuracy, improving text-based accuracy consistently. Moreover, user tweets lot, Acctweet text-based approach comparable best model, even without access metadata(as shown top right corner graph). overall recommendation, users wishobfuscate location leave metadata fields blank avoid mentioning LIWs (e.g.,gazetted terms dialectal words) tweets. make difficult best geolocation models infer location correctly (as demonstrated bottom left graph).similar conclusion user geolocatability recently obtained Priedhorsky et al. (2014).help privacy-conscious Twitter users avoid geolocated tweets, madelist LIWs publicly available.3836. analysis limited behaviours could easily adopted many users. Given system predictslikely city fixed set given user, one simple way avoid geolocated move far awaycities. However, seems unlikely strategy would widely adopted.37. gazetteer based ASCII city names Geonames data.38. http://www.csse.unimelb.edu.au/tim/etc/liw-jair.tgz490fiT EXT-BASED WITTER U SER G EOLOCATION P REDICTION100200300400Number Location Indicative Words0.5TextText without gazetteersMetadata stacking (LOC, TZ)Stacking (TEXT, LOC, TZ)Accuracy0.40.30.20.1Number Location Indicative Words (LIWs)0.020%40%60%Location Indicative Word partitions80%00.6100%Figure 6: impact use LIWs geolocation accuracy. Users sorted numberLIWs tweets, partitioned 20 bins. Metadata includes LOC TZ.12. Prediction Confidencetask setup date, forced models geolocate users. practice, however,many users dont explicitly mention geolocating words posts, making task nighimpossible even human oracle. alternative approach would predict user geolocationmodel confident prediction. Here, consider range variablespotentially indicate prediction confidence.Absolute probability (AP): consider predictions probability specified threshold.Prediction coherence (PC): hypothesise reliable predictions, top-ranked locationstend geographically close. preliminary exploration coherence, formulate PC sum reciprocal ranks predictions corresponding second-leveladministrative region class representation (i.e., state province) top-rankingprediction, calculated top-10 predictions.39 example, suppose top-10 secondlevel predictions following states US: US-TX, US-FL, US-TX, US-TX,US-CA, US-TX, US-TX, US-FL, US-CA, US-NY. top-ranking state-level predictiontherefore US-TX, also occurs ranks 3, 4, 6 7 (for different cities Texas).case, PC would 11 + 13 + 14 + 16 + 17 .Probability ratio (PR): model confident prediction, first prediction tendmuch probable predictions. formulate intuition PR, ratioprobability first second most-probable predictions.39. could measured average distance top predictions well.491fiH , C OOK & BALDWIN0.8Acc@1610.60.4Absolute Probability (AP)Prediction Coherence (PC)Probability Ratio (PR)Feature Number (FN)Feature Weight (FW)0.20.05 0.15 0.25 0.35 0.45 0.55 0.65 0.75 0.85 0.95RecallFigure 7: Acc@161 classification top-n% most-confident predictions measuretext-based prediction confidence NAFeature number (FN): take number features found users posts predictionaccuracy. intuition geolocation prediction based featuresreliable prediction based fewer features.Feature weight (FW): Similar FN, case use sum IGR features, rathernumber features.investigate variables NA LIVE results. particular, evaluate using text-based model, experiment text-based user geolocationsection. Nevertheless, exploration metadata classifiers also possible. sortpredictions confidence (independently measure prediction confidence) measureAcc@161 among top-n% predictions following values n: {0.0, 0.05, ..., 1.0}, akinprecisionrecall curve, shown Figures 7 8. Results Acc show similar trend,omitted paper.naive AP method least reliable with, surprisingly, accuracy increasing AP decreasesfigures. appears raw probabilities accurate reflection predictionconfidence. find larger AP usually indicates user LIW features,model often geolocates user city highest class prior. comparison, PRfocuses relative, opposed raw, probabilities performs much better, higherPR generally corresponding higher accuracy. addition, PC shows different trends twofigures. achieves comparable performance PR NA, however incapable estimatingglobal prediction confidence. largely world-level PC numbers oftensmall less discriminating regional PC numbers, reducing utility geographicproximity top predictions. Furthermore, FN FW display similar overall trends PR,dont outperform PR.492fiT EXT-BASED WITTER U SER G EOLOCATION P REDICTIONAcc@1610.80.60.4Absolute Probability (AP)Prediction Coherence (PC)Probability Ratio (PR)Feature Number (FN)Feature Weight (FW)0.20.05 0.15 0.25 0.35 0.45 0.55 0.65 0.75 0.85 0.95RecallFigure 8: Acc@161 classification top-n% most-confident predictions measuretext-based prediction confidence LIVEexperiments suggest indeed trade-off coverage accuracy,could exploited obtain higher-accuracy predictions applications requiredata classified. PR, well FN FW, fairly effective indicators predictive accuracy. extension line research would investigate predictionconfidence per city, e.g., users New York, US predictable users Boston,US?13. Future Workresearch could expanded number directions. First, hierarchical classification models (Mahmud et al., 2012; Ahmed, Hong, & Smola, 2013) becoming increasingly popular,could combined stacked model. Although explicit social network data (e.g., followers)non-trivial retrieve, user interactions reconstructed content tweets (e.g.,replies, retweets user mentions: Jurgens, 2013). implicit network information couldcombined current text-based geolocation methods improve geolocation accuracy. Additionally, hypothesise text-based geolocation prediction challenging taskhumans, method achieving surpassing accuracy levels human. wouldinteresting test hypothesis, e.g., using crowdsourcing methods.Recently, Priedhorsky et al. (2014) proposed evaluating message-level geolocation. useGaussian mixture models characterise n-gram probability distributions evaluate geolocation prediction accuracy using probabilistic metrics. conclusions strongly agreefindings, although task setting user-level evaluation metrics different.future, plan adapt methods tweet-level geolocation carry systematic evaluationprobabilistic analysis geolocation.493fiH , C OOK & BALDWIN14. Summarypaper, investigated series key issues relating text-based geolocation predictionTwitter users. applied number feature selection methods identify location indicativewords (LIWs), demonstrated effectiveness feature selection regional (NA)global (WORLD) datasets. extended study analyse impact non-geotagged data,influence language complementary geographical information user metadata.evaluated model time-heterogeneous dataset assess models sensitivitytemporal change. Moreover, discussed users tweeting behaviour affects geolocationprediction, drew conclusions users make less easily geolocatable. Finally,explored various indicators estimate prediction confidence, terms balanceprediction coverage accuracy.number conclusions drawn study, corresponding different sectionspaper. believe findings contribute deeper understanding text-based geolocationprediction, shape design practical solutions problem:demonstrate explicit selection location indicative words improves geolocation prediction accuracy, compared using full feature set.Non-geotagged tweets (from users whose location known) boost prediction accuracysubstantially training testing. also demonstrate modeling geotaggeddata inferencing non-geotagged data indeed feasible. largelysimilarity geotagged data non-geotagged data, although minor differencesobserved geotagged non-geotagged tweets.Modelling inference multilingual data viable easier monolingual English data. tweet language strongly affects prediction accuracy. Dueuneven geographical distribution languages tweets, users geographically-diverse languages (e.g., English Spanish) much harder geolocate users geographicallyfocused languages (e.g., Japanese Dutch). Although trivially determining locations basedlanguage tweets fine geographically-focused languages, insufficientmajority users post tweets using geographically-diverse languages. integratinglanguage information different ways, found training range monolingual modelsbased language identification, predicting location using model based usersprimary language, achieves better results monolithic multilingual model.User-declared metadata, though noisy unstructured, offers complementary location-indicative information contained tweets. combining tweet metadata information stacking, best global geolocation results attained: 49% Englishusers correctly predicted city level, Median error distance 9km.Results time-heterogeneous evaluation suggest applying model trained old datapredict new data generally feasible. Although user-declared location field (LOC)sensitive temporal change, classifiers based tweet content (TEXT) user timezone(TZ) generalise reasonably well across time.pilot study user geolocatability led following recommendations preservegeolocation privacy: (1) reduce usage location indicative words, particularly gazetted494fiT EXT-BASED WITTER U SER G EOLOCATION P REDICTIONterms; (2) delete location-sensitive metadata (e.g., user-declared location timezonemetadata).Probability ratio, measures ratio probability top predictionsecond prediction, used estimate prediction confidence, select userssystem prediction accurate, e.g., downstream applications requiremore-reliable geolocation predictions exhaustive user geolocation required.Acknowledgmentsauthors wish thank Stephen Roller Jason Baldridge making data tools availablereplicate NA experiments.NICTA funded Australian government represented Department Broadband,Communication Digital Economy, Australian Research Council ICT CentreExcellence programme.ReferencesAhmed, A., Hong, L., & Smola, A. J. (2013). Hierarchical geographical modeling user locationssocial media posts. Proceedings 22nd international conference World WideWeb, WWW 13, pp. 2536, Rio de Janeiro, Brazil.Amitay, E., HarEl, N., Sivan, R., & Soffer, A. (2004). Web-a-where: geotagging web content.Proceedings 27th Annual International ACM SIGIR Conference ResearchDevelopment Information Retrieval (SIGIR 2004), pp. 273280, Sheffield, UK.Backstrom, L., Kleinberg, J., Kumar, R., & Novak, J. (2008). Spatial variation search enginequeries. Proceeding 17th international conference World Wide Web, WWW 08,pp. 357366, Beijing, China.Backstrom, L., Sun, E., & Marlow, C. (2010). Find can: improving geographical prediction social spatial proximity. Proceedings 19th International ConferenceWorld Wide Web, pp. 6170, Raleigh, USA.Baldwin, T., Cook, P., Lui, M., MacKinlay, A., & Wang, L. (2013). noisy social media text,diffrnt social media sources?. Proceedings 6th International Joint ConferenceNatural Language Processing (IJCNLP 2013), pp. 356364, Nagoya, Japan.Bennett, P. N., Radlinski, F., White, R. W., & Yilmaz, E. (2011). Inferring using locationmetadata personalize web search. Proceedings 34th International ACM SIGIRConference Research Development Information Retrieval, SIGIR 11, pp. 135144,Beijing, China.Bentley, J. L. (1975). Multidimensional binary search trees used associative searching. Communication ACM, 18(9), 509517.Bergsma, S., Dredze, M., Van Durme, B., Wilson, T., & Yarowsky, D. (2013). Broadly improvinguser classification via communication-based name location clustering Twitter.Proceedings 2013 Conference North American Chapter Association495fiH , C OOK & BALDWINComputational Linguistics: Human Language Technologies (NAACL-HLT 2013), pp. 10101019, Atlanta, USA.Bilhaut, F., Charnois, T., Enjalbert, P., & Mathet, Y. (2003). Geographic reference analysis geographic document querying. Proceedings HLT-NAACL 2003 workshop Analysisgeographic references - Volume 1, pp. 5562, Edmonton, Canada.Blei, D. M., Ng, A. Y., & Jordan, M. I. (2003). Latent Dirichlet Allocation. Journal MachineLearning Research, 3, 9931022.Buyukokkten, O., Cho, J., Garcia-Molina, H., Gravano, L., & Shivakumar, N. (1999). Exploitinggeographical location information web pages. ACM SIGMOD Workshop WebDatabases (WebDB99), pp. 9196, Philadelphia, USA.Carletta, J. (1996). Assessing agreement classification tasks: kappa statistic. ComputationalLinguistics, 22(2), 249254.Chandra, S., Khan, L., & Muhaya, F. (2011). Estimating Twitter user location using socialinteractionsa content based approach. 2011 IEEE Third International ConferencePrivacy, Security, Risk Trust (PASSAT) 2011 IEEE Third International ConferenceSocial Computing (SocialCom), pp. 838843, Boston, USA.Chang, H.-w., Lee, D., M., E., & Lee, J. (2012). @Phillies tweeting Philly? predicting Twitteruser locations spatial word usage. IEEE/ACM International Conference AdvancesSocial Networks Analysis Mining (ASONAM), pp. 111118, Istanbul, Turkey.Cheng, Z., Caverlee, J., & Lee, K. (2010). tweet: content-based approachgeo-locating twitter users. Proceedings 19th ACM International ConferenceInformation Knowledge Management, pp. 759768, Toronto, Canada.Cho, E., Myers, S. A., & Leskovec, J. (2011). Friendship mobility: user movement locationbased social networks. Proceedings 17th ACM SIGKDD International ConferenceKnowledge Discovery Data Mining, pp. 10821090, San Diego, USA.Crandall, D. J., Backstrom, L., Huttenlocher, D., & Kleinberg, J. (2009). Mapping worldsphotos. Proceedings 18th international conference World wide web, WWW 09,pp. 761770, Madrid, Spain.Dalvi, N., Kumar, R., & Pang, B. (2012). Object matching tweets spatial models.Proceedings Fifth ACM International Conference Web Search Data Mining(WSDM 2012), pp. 4352, Seattle, USA.Ding, J., Gravano, L., & Shivakumar, N. (2000). Computing geographical scopes web resources.Proceedings 26th International Conference Large Data Bases, VLDB 00,pp. 545556, Cairo, Egypt.Dunning, T. (1993). Accurate methods statistics surprise coincidence. ComputationalLinguistics, 19(1), 6174.Eisenstein, J., OConnor, B., Smith, N. A., & Xing, E. P. (2010). latent variable modelgeographic lexical variation. Proceedings 2010 Conference Empirical MethodsNatural Language Processing (EMNLP 2010), pp. 12771287, Cambridge, USA.Fan, R.-E., Chang, K.-W., Hsieh, C.-J., Wang, X.-R., & Lin, C.-J. (2008). LIBLINEAR: librarylarge linear classification. Journal Machine Learning Research, 9, 18711874.496fiT EXT-BASED WITTER U SER G EOLOCATION P REDICTIONGelernter, J., & Mushegian, N. (2011). Geo-parsing messages microtext. Transactions GIS,15(6), 753773.Giacinto, G., & Roli, F. (2001). Design effective neural network ensembles image classification purposes. Image Vision Computing, 19(910), 699707.Gouws, S., Metzler, D., Cai, C., & Hovy, E. (2011). Contextual bearing linguistic variationsocial media. Proceedings Workshop Languages Social Media, LSM 11, pp.2029, Portland, USA.Guyon, I., & Elisseeff, A. (2003). introduction variable feature selection. JournalMachine Learning Research, 3, 11571182.Han, B., Cook, P., & Baldwin, T. (2012a). Automatically constructing normalisation dictionarymicroblogs. Proceedings Joint Conference Empirical Methods NaturalLanguage Processing Computational Natural Language Learning 2012 (EMNLP-CoNLL2012), pp. 421432, Jeju, Korea.Han, B., Cook, P., & Baldwin, T. (2012b). Geolocation prediction social media data findinglocation indicative words. Proceedings 24th International Conference Computational Linguistics, pp. 10451062, Mumbai, India.Han, B., Cook, P., & Baldwin, T. (2013). stacking-based approach Twitter user geolocationprediction. Proceedings 51st Annual Meeting Association ComputationalLinguistics: System Demonstrations, pp. 712, Sofia, Bulgaria.Hauff, C., & Houben, G.-J. (2012). Geo-location estimation Flickr images: social web basedenrichment. Proceedings 34th European Conference Advances InformationRetrieval, pp. 8596, Barcelona, Spain.Hecht, B., Hong, L., Suh, B., & Chi, E. H. (2011). Tweets Justin Biebers heart: dynamicslocation field user profiles. Proceedings SIGCHI Conference HumanFactors Computing Systems, pp. 237246, Vancouver, Canada.Hong, L., Ahmed, A., Gurumurthy, S., Smola, A. J., & Tsioutsiouliklis, K. (2012). Discoveringgeographical topics Twitter stream. Proceedings 21st International ConferenceWorld Wide Web (WWW 2012), pp. 769778, Lyon, France.Hong, L., Convertino, G., & Chi, E. H. (2011). Language matters Twitter: large scale study.Proceedings 5th International Conference Weblogs Social Media (ICWSM2011), pp. 518521, Barcelona, Spain.Jurgens, D. (2013). Thats friends for: Inferring location online social media platformsbased social relationships. Proceedings 7th International Conference WeblogsSocial Media (ICWSM 2013), pp. 273282, Boston, USA.Kinsella, S., Murdock, V., & OHare, N. (2011). Im eating sandwich Glasgow: modelinglocations tweets. Proceedings 3rd international workshop Search mininguser-generated contents, pp. 6168, Glasgow, UK.Laere, O. V., Quinn, J., Schockaert, S., & Dhoedt, B. (2014). Spatially-aware term selectiongeotagging. IEEE Transactions Knowledge Data Engineering, 26(1), 221234.Laere, O. V., Schockaert, S., & Dhoedt, B. (2013). Georeferencing Flickr resources based textualmeta-data. Information Sciences, 238, 5274.497fiH , C OOK & BALDWINLeidner, J. L., & Lieberman, M. D. (2011). Detecting geographical references form placenames associated spatial natural language. SIGSPATIAL Special, 3(2), 511.Li, R., Wang, S., & Chang, K. C.-C. (2012). Multiple location profiling users relationshipssocial network content. VLDB, 5(11), 16031614.Li, W., Serdyukov, P., de Vries, A. P., Eickhoff, C., & Larson, M. (2011). tweet.Proceedings 20th ACM International Conference Information KnowledgeManagement (CIKM 2011), pp. 24732476, Glasgow, UK.Lieberman, M. D., & Lin, J. (2009). edit: Locating Wikipedia contributorsedit histories. Proceedings 3rd International Conference WeblogsSocial Media (ICWSM 2009), pp. 106113, San Jose, USA.Lui, M., & Baldwin, T. (2012). langid.py: off-the-shelf language identification tool. Proceedings 50th Annual Meeting Association Computational Linguistics (ACL2012) Demo Session, pp. 2530, Jeju, Korea.Mahmud, J., Nichols, J., & Drews, C. (2012). tweet from? Inferring home locationsTwitter users. Proceedings 6th International Conference Weblogs SocialMedia (ICWSM 2012), pp. 511514, Dublin, Ireland.Mao, H., Shuai, X., & Kapadia, A. (2011). Loose tweets: analysis privacy leaks Twitter.Proceedings 10th Annual ACM Workshop Privacy Electronic Society, pp.112, Chicago, USA.Nakatani, S. (2010). Language detection library Java. http://code.google.com/p/language-detection/.Ng, A. Y., & Jordan, M. I. (2002). discriminative vs. generative classifiers: comparisonlogistic regression naive Bayes. Advances Neural Information Processing Systems14 (NIPS-02), pp. 841848, Whistler, Canada.Nocedal, J. (1980). Updating quasi-Newton matrices limited storage. Mathematics Computation, 35(151), 773782.Nunez-Redo, M., Daz, L., Gil, J., Gonzalez, D., & Huerta, J. (2011). Discovery integrationWeb 2.0 content geospatial information structures: use case wild fire monitoring.Proceedings 6th International Conference Availability, Reliability Security, pp.5068, Vienna, Austria.OConnor, B., Krieger, M., & Ahn, D. (2010). TweetMotif: Exploratory search topic summarization Twitter. Proceedings Fourth International AAAI Conference WeblogsSocial Media, pp. 384385, Washington, D.C., USA.OHare, N., & Murdock, V. (2013). Modeling locations social media. Information Retrieval,16(1), 3062.OSullivan, D., & Unwin, D. J. (2010). Point Pattern Analysis, pp. 121155. John Wiley & Sons,Inc.Padmanabhan, V. N., & Subramanian, L. (2001). investigation geographic mapping techniques internet hosts. Proceedings 2001 Conference Applications, Technologies, Architectures, Protocols Computer Communications, SIGCOMM 01, pp.173185, San Diego, USA.498fiT EXT-BASED WITTER U SER G EOLOCATION P REDICTIONPontes, T., Vasconcelos, M., Almeida, J., Kumaraguru, P., & Almeida, V. (2012). knowlive: Privacy characterization Foursquare behavior. 4th International WorkshopLocation-Based Social Networks (LBSN 2012), Pittsburgh, USA.Priedhorsky, R., Culotta, A., & Valle, S. Y. D. (2014). Inferring origin locations tweetsquantitative confidence. Proceedings 17th ACM Conference Computer SupportedCooperative Work Social Computing, Baltimore, USA. appear.Quercini, G., Samet, H., Sankaranarayanan, J., & Lieberman, M. D. (2010). Determining spatialreader scopes news sources using local lexicons. Proceedings 18th SIGSPATIALInternational Conference Advances Geographic Information Systems, GIS 10, pp. 4352, San Jose, USA.Quinlan, J. R. (1993). C4.5: Programs Machine Learning. Morgan Kaufmann, San Mateo,USA.Ritter, A., Clark, S., Mausam, & Etzioni, O. (2011). Named entity recognition tweets: experimental study. Proceedings 2011 Conference Empirical Methods NaturalLanguage Processing, pp. 15241534, Edinburgh, UK.Roller, S., Speriosu, M., Rallapalli, S., Wing, B., & Baldridge, J. (2012). Supervised text-basedgeolocation using language models adaptive grid. Proceedings 2012 JointConference Empirical Methods Natural Language Processing Computational Natural Language Learning, pp. 15001510, Jeju Island, Korea.Rout, D. P., Bontcheva, K., Preotiuc-Pietro, D., & Cohn, T. (2013). Wheres @wally?: classification approach geolocating users based social ties. Proceedings 24th ACMConference Hypertext Social Media, pp. 1120, Paris, France.Sadilek, A., Kautz, H., & Bigham, J. P. (2012). Finding friends followingare. Proceedings Fifth ACM International Conference Web Search DataMining, pp. 723732, Seattle, USA.Schulz, A., Hadjakos, A., Paulheim, H., Nachtwey, J., & Muhlhauser, M. (2013). multi-indicatorapproach geolocalization tweets. Proceedings 7th International ConferenceWeblogs Social Media (ICWSM 2013), pp. 573582, Boston, USA.Serdyukov, P., Murdock, V., & van Zwol, R. (2009). Placing Flickr photos map. Proceedings 32nd International ACM SIGIR Conference Research DevelopmentInformation Retrieval (SIGIR 2009), pp. 484491, Boston, USA.Silva, M. J., Martins, B., Chaves, M. S., Afonso, A. P., & Cardoso, N. (2006). Adding geographicscopes web resources. Computers, Environment Urban Systems, 30, 378399.Tuten, T. L. (2008). Advertising 2.0: Social media marketing Web 2.0 world. Praeger Publishers,Westport, USA.Vapnik, V. N. (1995). nature Statistical Learning Theory. Springer-Verlag, New York, USA.Vincenty, T. (1975). Direct inverse solutions geodesics ellipsoid applicationnested equations. Survey Review, 22(176), 8893.Wang, L., Wang, C., Xie, X., Forman, J., Lu, Y., Ma, W.-Y., & Li, Y. (2005). Detecting dominantlocations search queries. Proceedings 28th Annual International ACM SIGIR499fiH , C OOK & BALDWINConference Research Development Information Retrieval (SIGIR 2005), pp. 424431, Salvador, Brazil.Wing, B. P., & Baldridge, J. (2011). Simple supervised document geolocation geodesic grids.Proceedings 49th Annual Meeting Association Computational Linguistics:Human Language Technologies, pp. 955964, Portland, USA.Wolpert, D. H. (1992). Stacked generalization. Neural Networks, 5(2), 241259.Yang, Y., & Pedersen, J. O. (1997). comparative study feature selection text categorization.Proceedings Fourteenth International Conference Machine Learning, ICML 97,pp. 412420, San Francisco, USA.Yi, X., Raghavan, H., & Leggetter, C. (2009). Discovering users specific geo intention websearch. Proceedings 18th International Conference World Wide Web, WWW 09,pp. 481490, Madrid, Spain.Yin, J., Lampert, A., Cameron, M., Robinson, B., & Power, R. (2012). Using social mediaenhance emergency situation awareness. Intelligent Systems, 27(6), 5259.Yin, Z., Cao, L., Han, J., Zhai, C., & Huang, T. (2011). Geographical topic discovery comparison. Proceedings 20th International Conference World Wide Web, pp. 247256,Hyderabad, India.Zong, W., Wu, D., Sun, A., Lim, E.-P., & Goh, D. H.-L. (2005). assigning place namesgeography related web pages. ACM/IEEE Joint Conference Digital Libraries, pp. 354362, Denver, USA.500fiJournal Artificial Intelligence Research 49 (2014) 1-47Submitted 7/13; published 1/14Multimodal Distributional SemanticsElia Brunielia.bruni@unitn.itCenter Mind/Brain Sciences,University Trento, ItalyNam Khanh Tranntran@l3s.deL3S Research Center,Hannover, GermanyMarco Baronimarco.baroni@unitn.itCenter Mind/Brain Sciences,University Trento, ItalyDepartment Information Engineering Computer Science,University Trento, ItalyAbstractDistributional semantic models derive computational representations word meaningpatterns co-occurrence words text. models successstory computational linguistics, able provide reliable estimates semanticrelatedness many semantic tasks requiring them. However, distributional modelsextract meaning information exclusively text, extremely impoverishedbasis compared rich perceptual sources ground human semantic knowledge.address lack perceptual grounding distributional models exploiting computervision techniques automatically identify discrete visual words images,distributional representation word extended also encompass co-occurrencevisual words images associated with. propose flexible architectureintegrate text- image-based distributional information, show setempirical tests integrated model superior purely text-based approach,provides somewhat complementary semantic information respect latter.1. Introductiondistributional hypothesis states words occur similar contexts semantically similar. claim multiple theoretical roots psychology, structuralist linguistics, lexicography possibly even later writings Wittgenstein (Firth, 1957;Harris, 1954; Miller & Charles, 1991; Wittgenstein, 1953). However, distributional hypothesis huge impact computational linguistics last two decades mainlyempirical reasons, is, suggests simple practical method harvestword meaning representations large scale: record contexts wordsoccur easy-to-assemble large collections texts (corpora) use contextual profiles surrogates meaning. Nearly contemporary corpus-based approachessemantics rely contextual evidence one way another, systematicextensive application distributional methods found call distributionalsemantic models (DSMs), also known literature vector space semantic space2014 AI Access Foundation. rights reserved.fiBruni, Tran & Baronimodels meaning (Landauer & Dumais, 1997; Sahlgren, 2006; Schtze, 1997; Turney &Pantel, 2010).DSMs, meaning word approximated vector keeps trackpatterns co-occurrence word text corpora, degree semanticsimilarity or, generally, relatedness (Budanitsky & Hirst, 2006) two wordsprecisely quantified terms geometric distance vectors representingthem. example, car automobile might occur terms street, gasdriver, thus distributional vectors likely close, cuing factwords synonyms. Extended empirical evidence shown distributionalsemantics good harvesting effective meaning representations large scale,confirming validity distributional hypothesis (see references Section 2.1below).Still, successes, distributional semantics suffers obvious limitationrepresents meaning word entirely terms connections words. longtradition studies cognitive science philosophy stressed modelsmeaning symbols (e.g., words) entirely accounted terms symbols (e.g.,words) without links outside world (e.g., via perception) deeply problematic, issue often referred symbol grounding problem (Harnad, 1990).DSMs also come attack lack grounding (Glenberg & Robertson,2000).1 Although specific criticisms vented might entirely well-founded(Burgess, 2000), little doubt limitation textual contexts makesDSMs dissimilar humans, who, thanks senses, access rich sourcesperceptual knowledge learning meaning words much cognitive scientists argued meaning directly embodied sensory-motor processing(see work de Vega, Glenberg, & Graesser, 2008, different views embodimentcognitive science). Indeed, last decades large amount behavioural neuroscientific evidence amassed indicating knowledge words conceptsinextricably linked perceptual motor systems. example, perceiving actiondenoting verbs kick lick involves activation areas brain controllingfoot tongue movements, respectively (Pulvermueller, 2005). Hansen, Olkkonen, Walter, Gegenfurtner (2006) asked subjects adjust color fruit images objectsappeared achromatic. objects generally adjusted color shiftedaway subjects gray point direction opposite typical color fruit,e.g., bananas shifted towards blue subjects overcorrected typicalyellow color. Typical color also influences lexical access: example, subjects fasternaming pumpkin picture presented orange grayscalerepresentation, slowest another color (Therriault, Yaxley, & Zwaan, 2009).final example, Kaschak, Madden, Therriault, Yaxley, Aveyard, Blanchard, Zwaan(2005) found subjects slower processing sentence describing actionsentence presented concurrently visual stimulus depicting motion opposite1. Harnard, original paper, discussing formal symbols, postulated Fodors languagethought (Fodor, 1975), rather words natural language. However, latterrepresented terms connections words, case DSMs, grounding problemarises, follow recent literature issue referring symbol grounding,symbols natural language words.2fiMultimodal Distributional Semanticsdirection described (e.g., car approached harder process concurrentlyperception motion away you). See review Barsalou (2008) reviewevidence conceptual linguistic competence strongly embodied.One might argue concerns DSMs grounded embodiedexaggerated, overlook fact patterns linguistic co-occurrenceexploited DSMs reflect semantic knowledge acquired perception,linguistic perceptual information strongly correlated (Louwerse, 2011).dogs often brown pink, likely talk brown dogspink dogs. Consequently, child learn useful facts meaning conceptdenoted dog direct perception linguistic input (this explains, amongthings, congenitally blind subjects excellent knowledge color terms;see, e.g., Connolly, Gleitman, & Thompson-Schill, 2007). One could hypothesizemeaning representations extracted text corpora indistinguishablederived perception, making grounding redundant. However, fairlyextensive literature showing case. Many studies (Andrews, Vigliocco,& Vinson, 2009; Baroni, Barbu, Murphy, & Poesio, 2010; Baroni & Lenci, 2008; Riordan& Jones, 2011) underlined text-derived DSMs capture encyclopedic, functionaldiscourse-related properties word meanings, tend miss concrete aspects.Intuitively, might harvest text information bananas tropical eatable,yellow (because authors write obvious statementsbananas yellow). hand, studies show how, humansasked describe concepts, features produce (equivalent sense contextualfeatures exploited DSMs) preponderantly perceptual nature: Bananas yellow,tigers stripes, on.2discrepancy DSMs humans not, per se, proof DSMsface empirical difficulties computational semantic models. However, interestedpotential implications DSMs models humans acquire use languagecase many DSM developers (e.g., Griffiths, Steyvers, & Tenenbaum, 2007;Landauer & Dumais, 1997; Lund & Burgess, 1996, many others) completelack grounding perception serious blow psychological plausibility,exposes criticism classic ungrounded symbolic models received.Even empirical level, reasonable expect DSMs enriched perceptualinformation would outperform purely textual counterparts: Useful computational semantic models must capture human semantic knowledge, human semantic knowledgestrongly informed perception.accept grounding DSMs perception desirable avenue research,must ask find practical source perceptual information embed DSMs.Several interesting recent experiments use features produced human subjects conceptdescription tasks (so-called semantic norms) surrogate true perceptual features(Andrews et al., 2009; Johns & Jones, 2012; Silberer & Lapata, 2012; Steyvers, 2010).reasonable first step, integration methods proposed studies2. perfectly fair, tendency might part triggered fact that, subjects askeddescribe concepts, might encouraged focus perceptual aspects experimentersinstructions. example McRae, Cree, Seidenberg, McNorgan (2005) asked subjects list firstphysical properties, internal external parts, [the object] looks.3fiBruni, Tran & Baroniquite sophisticated, using subject-produced features unsatisfactory practicallytheoretically (see however work reported Kievit-Kylar & Jones, 2011,crowdsourcing project addressing kinds concerns). Practically, using subjectgenerated properties limits experiments words denote concepts describedsemantic norms, even large norms contain features hundred concepts.Theoretically, features produced subjects concept description tasks far removedsort implicit perceptual features supposed stand for. example,since expressed words, limited conveyed verbally.Moreover, subjects tend produce salient distinctive properties.state dogs head, since thats hardly distinctive feature animal!article, explore direct route integrate perceptual informationDSMs. exploit recent advances computer vision (Grauman & Leibe, 2011)availability documents combine text images automatically extract visualfeatures naturally co-occurring words multimodal corpora. imagebased features combined standard text-based features obtain perceptuallyenhanced distributional vectors. this, rely natural extension distributional hypothesis, encompasses similarity linguistic context, alsosimilarity visual context. Interestingly, Landauer Dumais, one classic paperslaid groundwork distributional semantics, already touched groundingissue proposed, speculatively, solution along lines one implementinghere: [I]f one judiciously added numerous pictures scenes without rabbitscontext columns [. . . ] corpus matrix, filled handful appropriate cellsrabbit hare word rows, [a DSM] could easily learn words rabbit harego pictures containing rabbits ones without, forth. (Landauer &Dumais, 1997, p. 227).3Although vision one source perceptual data, reasonable starting point,convenience (availability suitable data train models)probably dominating modality determining word meaning. one pieceevidence claim, widely used subject-generated semantic norms McRae et al.(2005) contain 3,594 distinct perceptual features total, and, these, 3,099 (86%)visual nature!relatively low-level noisy features extract images multimodal corpora contribute meaningful information distributional representationword meaning? report results systematic comparison network semantic relations entertained set concrete nouns traditional text-basednovel image-based distributional spaces confirming image-based features are, indeed,semantically meaningful. Moreover, expected, provide somewhat complementaryinformation respect text-based features. thus found practical effective way extract perceptual information, must consider next combine textand image-derived features build multimodal distributional semantic model.propose general parametrized architecture multimodal fusion that, given appropriatesample data, automatically determines optimal mixture text- image-based features used target semantic task. Finally, evaluate multimodal DSMs3. thank Mike Jones pointing interesting historical connection us.4fiMultimodal Distributional Semanticstwo separate semantic tasks, namely predicting degree semantic relatedness assignedword pairs humans, categorizing nominal concepts classes. showtasks multimodal DSMs consistently outperform purely textual models, confirmingsupposition that, like humans, performance computational modelsmeaning improves meaning grounded perception.article structured follows. Section 2 provides relevant backgroundcomputational linguistics image analysis, discusses related work. laygeneral architecture multimodal fusion distributional semantics Section 3.necessary implementation details provided Section 4. Section 5 presents experiments tested approach. Section 6 concludes summarizing currentresults well sketching come next.2. Background Related Worksection first give brief introduction traditional distributional semantic models(i.e., based solely textual information). Then, describe image analysistechniques adopt extract manipulate visual information. Next, discuss earlierattempts construct multimodal distributional representation meaning. Finally,describe relevant strategies combine information coming text imagesproposed inside computer vision community.2.1 Distributional Semanticslast decades, number different distributional semantic models (DSMs) wordmeaning proposed computational linguistics, relying assumptionword meaning learned directly linguistic environment.Semantic space models one common types DSM. approximatemeaning words vectors record distributional history corpus(Turney & Pantel, 2010). distributional semantic model encoded matrix whoserows semantic vectors representing meanings set target words.component semantic vector function occurrence counts correspondingtarget word certain context (see Lowe, 2001, formal treatment). Definitionscontext range simple ones (such documents occurrence another wordinside fixed window target word) linguistically sophisticated ones (suchoccurrence certain words connected target special syntactic relations)(Pad & Lapata, 2007; Sahlgren, 2006; Turney & Pantel, 2010). raw targetcontext counts collected, transformed association scores typicallydiscount weights components whose corresponding word-context pairs highprobability chance co-occurrence (Evert, 2005). rank matrix containingsemantic vectors rows optionally decreased dimensionality reduction,might provide beneficial smoothing getting rid noise components and/or allowefficient storage computation (Landauer & Dumais, 1997; Sahlgren, 2005; Schtze,1997). Finally, distributional semantic similarity pair target words estimatedsimilarity function takes semantic vectors input returns scalarsimilarity score output.5fiBruni, Tran & Baronimany different semantic space models literature. Probably bestknown Latent Semantic Analysis (LSA, Landauer & Dumais, 1997), highdimensional semantic space words derived use co-occurrence informationwords passages occur. Another well-known exampleHyperspace Analog Language model (HAL, Lund & Burgess, 1996), wordrepresented vector containing weighted co-occurrence values wordwords fixed window. semantic space models rely syntactic relations insteadwindows (Grefenstette, 1994; Curran & Moens, 2002; Pad & Lapata, 2007). Generaloverviews semantic space models provided Clark (2013), Erk (2012), ManningSchtze (1999), Sahlgren (2006) Turney Pantel (2010).recently, probabilistic topic models receiving increasing attentionalternative implementation DSMs (Blei, Ng, & Jordan, 2003; Griffiths et al., 2007).Probabilistic topic models also rely co-occurrence information large corpora derive meaning but, differently semantic space models, based assumptionwords corpus exhibit probabilistic structure connected topics. Wordsrepresented points high-dimensional space probability distributionset topics. Conversely, topic defined probability distributiondifferent words. Probabilistic topic models tackle problem meaning representationmeans statistical inference: use word corpus infer hidden topic structure.Distributional semantic models, whether geometric probabilistic kind,ultimately mainly used provide similarity score arbitrary pairs words,also employ them. Indeed, models shown effectivemodeling wide range semantic tasks including judgments semantic relatednessword categorization.several data sets assess well DSM captures human intuitionssemantic relatedness, Rubenstein Goodenough set (Rubenstein & Goodenough, 1965) WordSim353 (Finkelstein, Gabrilovich, Matias, Rivlin, Solan, Wolfman,& Ruppin, 2002). Usually constructed asking subjects rate set wordpairs according similarity scale. Then, average rating pair takenestimate perceived relatedness words (e.g., dollar-buck: 9.22, cord-smile:0.31). measure well distributional model approximates human semantic intuitions,usually correlation measure similarity scores generated modelhuman ratings computed. highest correlation aware WordSim353set also employ 0.80 obtained model called TemporalSemantic Analysis, captures patterns word usage time conceptsrepresented time series corpus temporally-ordered documents (Radinsky,Agichtein, Gabrilovich, & Markovitch, 2011). temporal knowledge could integratedperceptual knowledge encode model. direct comparison point,Agirre, Alfonseca, Hall, Kravalova, Pasa, Soroa (2009) presented extensive evaluation distributional WordNet-based semantic models WordSim, achievingmaximum correlation 0.66 across various parameters.44. WordNet, available http://wordnet.princeton.edu/, large computational lexicon Englishnouns, verbs, adjectives adverbs grouped sets synonyms (synsets), expressingdistinct concept.6fiMultimodal Distributional SemanticsHumans good grouping together words (or concepts denote)classes based semantic relatedness (Murphy, 2002), therefore cognitive-awarerepresentation meaning must show proficiency also categorization (e.g., Poesio& Almuhareb, 2005; Baroni et al., 2010). Concept categorization moreover usefulapplications automated ontology construction recognizing textual entailment.Unlike similarity ratings, categorization requires discrete decision group coordinates/cohyponyms class performed applying standard clustering techniquesmodel-generated vectors representing words categorized. example,Almuhareb-Poesio data set (Almuhareb & Poesio, 2005), also employ below,includes 402 concepts WordNet, balanced terms frequency degree ambiguity. distributional model Rothenhusler Schtze (2009) exploits syntacticinformation reach state-of-the-art performance Almuhareb-Poesio data set (maximum clustering purity across various parameter: 0.79). window-based distributionalapproach Baroni Lenci (2010), directly comparable text-based models,achieves 0.65 purity.semantic tasks DSMs applied include semantic priming, generationsalient properties concepts intuitions thematic fit verb arguments (see,e.g., Baroni & Lenci, 2010; Baroni et al., 2010; McDonald & Brew, 2004; Pad & Lapata,2007; Pad, Pad, & Erk, 2007). Distributional semantic vectors used widerange applications require representation word meaning, particularobjective measure meaning relatedness, including document classification, clusteringretrieval, question answering, automatic thesaurus generation, word sense disambiguation,query expansion, textual advertising areas machine translation (Dumais, 2003;Turney & Pantel, 2010).2.2 Visual WordsIdeally, build multimodal DSM, would like extract visual informationimages way similar text. Thanks well-known imageanalysis technique, namely bag-of-visual-words (BoVW), indeed possible discretizeimage content produce visual units somehow comparable words text, knownvisual words (Bosch, Zisserman, & Munoz, 2007; Csurka, Dance, Fan, Willamowski, &Bray, 2004; Nister & Stewenius, 2006; Sivic & Zisserman, 2003; Yang, Jiang, Hauptmann,& Ngo, 2007). Therefore, semantic vectors extracted corpus imagesassociated target (textual) words using similar pipeline commonlyused construct text-based vectors: Collect co-occurrence counts target wordsdiscrete image-based contexts (visual words), approximate semantic relatednesstwo words similarity function visual words representing them.BoVW technique extract visual word representations documents inspiredtraditional bag-of-words (BoW) method Information Retrieval. BoW turndictionary-based method represent (textual) document bag (i.e., orderconsidered), contains words dictionary. BoVW extends idea visualdocuments (namely images), describing collection discrete regions, capturingappearance ignoring spatial structure (the visual equivalent ignoring wordorder text). bag-of-visual-word representation image convenient image7fiBruni, Tran & BaronifffffffififiFigure 1: Representing images BoVW: (i) Salient image patches keypoints contain rich local information detected represented vectors low-levelfeatures called descriptors; (ii) Descriptors mapped visual wordsbasis distance centers clusters corresponding visual words(the preliminary clustering step shownfigure); (iii) Images finallyrepresented bag-of-visual-words feature vector according distributionvisual words contain. Images depicting things rotations,occlusions, small differences low-level descriptors might still similardistribution visual words, hence object traced robustlyacross images conditions change.analysis point view translates usually large set high-dimensional localdescriptors single sparse vector representation across images. Importantly, sizeoriginal set varies image image, bag-of-visual-word representationfixed dimensionality. Therefore, machine learning algorithms default expectfixed-dimensionality vectors input (e.g., supervised classification unsupervisedclustering) used tackle typical image analysis tasks object recognition,image segmentation, video tracking, motion detection, etc.specifically, similarly terms text document, image local interestpoints keypoints defined salient image patches contain rich local informationimage. However keypoint types images come off-the-shelf like word8fiMultimodal Distributional Semanticstypes text documents. Local interest points grouped types (i.e., visualwords) within across images, image represented numberoccurrences type it, analogously BoW. following pipeline typicallyfollowed. every image data set, keypoints automatically detected (noterecent approaches dense, pixelwise sampling keypoints preferreddetecting salient ones only, solution also adopt,explained Section 4.2.2) represented vectors low-level features called descriptors.Keypoint vectors grouped across images number clusters basedsimilarity descriptor space. cluster treated discrete visual word.keypoints mapped onto visual words, image represented BoVW featurevector recording many times visual word occurs it. way, moverepresenting image varying number high-dimensional keypoint descriptor vectorsrepresentation terms single visual word count vector fixed dimensionalityacross images, advantages discussed above. Visual word assignmentuse represent image content exemplified Figure 1, two imagessimilar content described terms bag-of-visual-word vectors.kind image content visual word captures exactly depends numberfactors, including descriptors used identify represent keypoints, clusteringalgorithm number target visual words selected. general, local interest pointsassigned visual word tend patches similar low-level appearance;local patterns need correlated object-level parts present images(Grauman & Leibe, 2011).2.3 Multimodal Distributional Semanticsavailability large amounts mixed media Web, one hand,discrete representation images visual words, other, escaped attentioncomputational linguists interested enriching distributional representations wordmeaning visual features.Feng Lapata (2010) propose first multimodal distributional semantic model.generative probabilistic setting requires extraction textual visual featuresmixed-media corpus, latent dimensions estimatedprobabilistic process assumes document generated sampling textualvisual words. Words represented distribution set latentmultimodal dimensions topics (Griffiths et al., 2007) derived surface textualvisual features. Feng Lapata experiment collection documents downloadedBBC News website corpus. test semantic representationsfree association norms Nelson, McEvoy, Schreiber (1998) subset 253pairs WordSim, obtaining gains performance visual information takenaccount (correlations human judgments 0.12 0.32 respectively), comparedtextual modality standalone (0.08 0.25 respectively), even performance stillwell state-of-the-art WordSim (see Section 2.1 above).main drawbacks approach textual visual data mustextracted corpus, thus limiting choice corpora used,generative probabilistic approach, elegant, allow much flexibility9fiBruni, Tran & Baronitwo information channels combined. Below, re-implement FengLapata method (MixLDA) training ESP-Game data set, source labeledimages adopt model. possible data set contains imagestextual labels describing them. general, recapture Feng Lapatasidea common latent semantic space latent multimodal mixing step pipeline(see Section 3.2.1 below).Leong Mihalcea (2011) also exploit textual visual information obtain multimodal distributional semantic model. Feng Lapata merge two sourcesinformation learning joint semantic model, Leong Mihalcea propose strategyakin call Scoring Level fusion below: Come separate text-image-based similarity estimates, combine obtain multimodal score.particular, use two combination methods: summing scores computingharmonic mean. Differently Feng Lapata, Leong Mihalcea extract visual information corpus manually coded resource, namely ImageNetdatabase (Deng, Dong, Socher, Li, & Fei-Fei, 2009), large-scale ontology images.5 Usinghandcoded annotated visual resource ImageNet faces sort problemsusing manually developed lexical database WordNet faces respecttextual information, is, applications severely limited ImageNet coverage (forexample, ImageNet currently restricted nominal concepts), interestmodel computational simulation word meaning acquisition naturally occurring language visual data somewhat reduced (humans learn meaningmountain set carefully annotated images mountains little else crowdingoccluding scene). evaluation, Leong Mihalcea experiment small subsets WordSim, obtaining improvements, although level report(the highest reported correlation 0.59 56 word pairs). Furthermore usedata set tune test models.Bruni, Tran, Baroni (2011) propose instead directly concatenate textand image-based vectors produce single multimodal vector represent words,call Feature Level fusion below. text-based distributional vector representing word, taken state-of-the-art distributional semantic model (Baroni &Lenci, 2010), concatenated vector representing word visual features, extracted images ESP-Game collection also use here.obtain promising performance WordSim test sets, although appreciably lowerresults report (we obtain maximum correlation 0.52 text-image-based features used together; compare Table 2 below).Attempts use multimodal models derived text images performspecific semantic tasks also reported. Bergsma Goebel (2011) use textualimage-based cues model selectional preferences verbs (which nouns likelyarguments verbs). experiment shows several cases visual informationuseful text task. example, looking textual corpora wordscarillon, migas mamey, much useful information obtained guessthree plausible argument verb eat. hand, also show5. http://image-net.org/10fiMultimodal Distributional Semanticsthat, exploiting Google image search functionality,6 enough images wordsfound vision-based model edible things classify correctly.Finally, evaluate multimodal models task discovering color concrete objects, showing relation words denoting concrete thingstypical color better captured visual information also taken account (Bruni,Boleda, Baroni, & Tran, 2012). Moreover, show multimodality helps distinguishing literal nonliteral uses color terms.2.4 Multimodal Fusiontextual information used image analysis, mostly done differentaims ours: Text used improve image-related tasks, typicallyattempt model relation specific images specific words textual passages(e.g., Barnard, Duygulu, Forsyth, de Freitas, Blei, & Jordan, 2003; Berg, Berg, & Shih,2010; Farhadi, Hejrati, Sadeghi, Young, Rashtchian, Hockenmaier, & Forsyth, 2010; Griffin,Wahab, & Newell, 2013; Kulkarni, Premraj, Dhar, Li, Choi, Berg, & Berg, 2011).contrast, (i) want use image-derived features improve representation wordmeaning (ii) interested capturing meaning word types basissets images connected word, model specific word-image relations.Despite differences, challenges addressed image analysis literature deals exploiting textual cues similar ones face. particular,problem merging, fusing, textual visual cues common representationalspace exactly face construct multimodal semantic space.Traditionally, image analysis community distinguishes two classes fusionschemes, namely early fusion late fusion. former fuses modalities feature space,latter fuses modalities semantic similarity space, analogously callFeature Level Scoring Level fusion, respectively. example, Escalante, Hrnadez,Sucar, Montes (2008) propose image retrieval system multimodal documents.early late fusion strategies combination image textualchannels considered. Early fusion settings include weighted linear combinationtwo channels global strategy different retrieval systems used contemporarilyentire, joint data set. Late fusion strategies include per-modality strategy,documents retrieved using one channel hierarchical settingfirst text, image combination used independently query databaseresults aggregated four weighted combinations. Vreeswijk, Huurnink,Smeulders (2011) train visual concept classifier abstract subject categoriesbiology history using late fusion approach image text informationcombined output level, is, first obtaining classification scores image-text-based models separately joining them. Similarly multimodal mixingstep, Pham, Maillot, Lim, Chevallet (2007) Caicedo, Ben-Abdallah, Gonzlez,Nasraoui (2012) propose early fusion two inputs mapped ontolatent space using dimensionality reduction techniques (e.g., Singular Value Decomposition).multimodal representation obtained way directly used retrieve imagedocuments.6. http://images.google.com/11fiBruni, Tran & Baroni3. Framework Multimodal Distributional Semanticssection, general flexible architecture multimodal semantics presented.architecture makes use distributional semantic models based textual visualinformation build multimodal representation meaning. merge two sources,uses parameter-based pipeline able capture previously proposed combinationstrategies, advantage explored within single system.3.1 Input Multimodal Architectureconstruct multimodal representation meaning, semantic model singlemodality implemented. Independently actual parameters chosencreation (that, point view, black box), requirementsmodel satisfy order guarantee good functioning framework.first place, modality must provide separate representation, leave roomvarious fusion strategies afterwards. Then, modality must encode semanticinformation pertaining word interest fixed-size vectorial representation.Moreover, assume text- image-based vectors normalized arrangedmatrices words rows co-occurring elements columns.follows, assume harvested matrix text-based semantic vectors,one image-based semantic vectors set target words, representing,respectively, verbal visual information words. Section 4 givedetails specific implementation construct matrices.3.2 Multimodal Fusionpipeline based two main steps:(1) Latent Multimodal Mixing: text vision matrices concatenated, obtaining single matrix whose row vectors projected onto single, common spacemake interact.(2) Multimodal Similarity Estimation: Information text- image-basedmatrices combined two ways obtain similarity estimates pairs targetwords: Feature Level Scoring Level.Figure 2 describes infrastructure propose fusion. First, introduce mixingphase promote interaction modalities call Latent Multimodal Mixing.step part approaches would consider Feature Level fusion (seebelow), keep separated might benefit Scoring Level fusion well.mixing performed, proceed integrate textual visual features.reviewed Section 2.4 above, literature fusion performed two main levels,Feature Level Scoring Level. first case features first combinedconsidered single input operations, second case task performed separatelydifferent sets features separate results combined. approachadvantages limitations incorporatedmultimodal infrastructure together constitute call Multimodal Similarity12fiMultimodal Distributional SemanticsfffifififffifiFigure 2: Multimodal fusion combining textual visual information semanticmodel.Estimation. Feature Level approach requires one learning step (i.e., determiningparameters feature vector combination) offers richer vector-based representationcombined information, also used purposes (e.g., image textfeatures could used together train classifier). Benefits Scoring Level approachinclude possibility different representations (in principle, even vectorial)different similarity scores different modalities ease increasing (or decreasing)number different modalities used representation.3.2.1 Latent Multimodal Mixingpreparatory step textual visual components projectedonto common representation lower dimensionality discover correlated latent factors.result new connections made source matrix taking accountinformation connections present matrix, originating patterns covariance overlap. Importantly, assume mixing done via dimensionalityreduction technique following characteristics: parameter k determines13fiBruni, Tran & Baronidimensionality reduced space fact k equals rankoriginal matrix reduced matrix identical considered good approximationoriginal one. commonly used Singular Value Decomposition reduction methodadopt mixing step satisfies constraints.toy example mixing might beneficial, consider concepts pizzacoin, could use features text-based semantic vectors (i.e., record cooccurrences target words concepts part vector dimensions).words likely occur similar contexts text, obviously visually similar. So, original text features pizza coin might highly correlated.However, mixing multimodal space, might associated (have highweights on) reduced space component, similar distributionsvisual features cue roundness. Consequently, two textual features originallyuncorrelated might drawn closer multimodal mixing, corresponding concepts visually similar, resulting mixed textual features are, sense,visually enriched, vice versa mixed visual features (interestingly, psychologistsshown that, certain conditions, words pizza coin, stronglyassociated perceptually similar, prime other; e.g., Pecher, Zeelenberg, & Raaijmakers, 1998).Note matrices obtained splitting reduced-rank matrix backoriginal textual visual blocks number feature columns originaltextual visual blocks, values smoothed dimensionalityreduction (we explain details achieved specific implementationnext paragraph). matrices used calculate similarity score wordpair (re-)merging information feature scoring levels.Mixing SVD implementation, perform mixing across text- imagebased features applying Singular Value Decomposition (SVD)7 matrix obtained concatenating two feature types row-wise (so row concatenatedmatrix describes target word textual visual space). SVD widely used techniquefind best approximation original data points space lower underlyingdimensionality whose basis vectors (principal components latent dimensions)selected capture much variance original space possible (Manning,Raghavan, & Schtze, 2008, Ch. 18). performing SVD concatenated textualvisual matrices, project two types information space,described linear combinations principal components. Following descriptionPham et al. (2007), SVD matrix rank r factorization form= U VU : matrix eigenvectors derived: r r diagonal matrix singular values: square roots eigenvaluesV : matrix eigenvectors derived7. Computed SVDLIBC: http://tedlab.mit.edu/~dr/SVDLIBC/14fiMultimodal Distributional Semanticscontext, matrix given normalizing two feature matrices separatelyconcatenating. selecting k largest values matrix keepingcorresponding columns matrices U V , reduced matrix Mk givenMk = Uk k Vktk < r dimensionality latent space. Mk keeps numbercolumns/dimensions , rank k. k free parameter tunedevelopment sets. Note k equals rank original matrix, triviallyMk = . Thus consider performing SVD reduction special caseSVD, helps searching optimal parameters.Note also that, n columns, Vkt k n matrix, Mknumber columns . first j columns contain textual features, columnsj + 1 n contain visual features, hold Mk , although lattervalues features affected global SVD smoothing. Thus,current implementation pipeline Figure 2, block splitting attained simplydividing Mk textual mixed matrix containing first j columns, visual mixedmatrix containing remaining columns.3.2.2 Multimodal Similarity EstimationSimilarity Function Following distributional hypothesis, DSMs describe wordterms contexts occurs. Therefore, measure similarity two wordsDSMs need function capable determining similarity two descriptions (i.e.,two semantic vectors). literature, many different similarity functionsused compare two semantic vectors, including cosine similarity, Euclidean distance, L1norm, Jaccards coefficient, Jensen-Shannon divergence, Lins similarity. extensiveevaluation different similarity measures, see work Weeds (2003).focus cosine similarity since shown effective measuremany semantic benchmarks (Bullinaria & Levy, 2007; Pad & Lapata, 2007). Also,given system based geometric principles, cosine, together Euclideandistance, principled choice measure similarity. example,measures listed above, developed probabilistic considerations,applicable vectors encode well-formed probability distributions, typicallycase (for example, multimodal mixing, vectors might contain negativevalues).cosine two semantic vectors b dot product divided productlengths:Pi=ni=1 ai biqPi=n 2i=n 2i=1i=1 bicos(a, b) = qPcosine ranges 0 (orthogonal vectors) |1| (parallel vectors pointingopposite directions cosine values 1 -1, respectively).15fiBruni, Tran & BaroniFeature Level Fusion Feature Level fusion (FL), use linear weighted fusionmethod combine text- image-based feature vectors words single representation use latter estimate similarity pairs. linear weightedcombination function definedF = Ft (1 ) Fvvector-concatenate operator.Scoring Level Fusion Scoring Level fusion (SL), text- image-based matricesused estimate similarity pairs independently. scores combined obtainfinal estimate using linear weighted scoring function:= St + (1 ) SvGeneral Form Special Cases Given fixed normalized text- image-basedmatrices, multimodal approach parametrized k (dimensionality latent space),FL vs. SL, (weight text component FL similarity estimation) (weight textcomponent SL).Note k=r, r rank original combined matrix, Latent MultimodalMixing returns original combined matrix (no actual mixing). Picking SL =1=0 corresponds using textual visual matrix only, respectively. thus derivespecial cases models text (k=r, SL, =1) images (k=r, SL, =0)used (called Text Image models Results section below). simple approachBruni et al. (2011), two matrices concatenated without mixing,parametrization k=r, FL, =0.5 (called NaiveFL model, below). summing approachLeong Mihalcea (2011) corresponds k=r, SL, =0.5 (NaiveSL, below). Pickingk<r, SL, =1 amounts performing latent multimodal mixing, using textualfeatures only; reverse mixed image features = 0 (TextmixedImagemixed , respectively). Reducing models parametrizedapproach means that, given development set specific task requires similaritymeasurements, discover data-driven way various models besttask hand (for example, certain task might discover betterusing text only, another mixed text features, yet another text imagefeatures, on).Formally, given set k1 , ..., kn R n dimensionalities latent space (with knequal original dimensionality, arbitrary steps chosen values),sets 1 , ..., R potential weights text block FL (with 1 = 0 = 1)1 , ..., l R l weights text block SL (with 1 = 0 l = 1),calculate number possible configurations explore totc = n(m + l). Unless n,l large (i.e., consider small intervals values tested),completely feasible perform full search best parameters certain taskwithout approximate optimization methods. experiments, n = 9, = l = 11,consequently totc = 198.16fiMultimodal Distributional Semantics4. Implementation Detailsimplementation multimodal framework visual feature extractionprocedure publicly available open source.8 Moreover visual feature extractionprocedure presented Bruni, Bordignon, Liska, Uijlings, Sergienya (2013).4.1 Construction Text-Based Semantic Matrixreviewed Section 2.1 above, text-based distributional model encoded matrix whose rows semantic vectors representing meaning set target words.Important parameters model choice target contextual elements,source corpora used extract co-occurrence information, context delimitingscope co-occurrence, function transform raw counts statistical association scores downplaying impact frequent elements.Source Corpora collect co-occurrence counts concatenation two corpora,ukWaC Wackypedia (size: 1.9B 820M running words, tokens, respectively).ukWaC collection Web pages based linguistically-controlled crawl .ukdomain conducted mid 2000s. Wackypedia built mid-2009 dumpEnglish Wikipedia. corpora automatically annotated lemma (dictionary form) part-of-speech (POS) category information using TreeTagger,9freely publicly available,10 widely used linguistic research.Target Context Elements Since source corpora annotated lemmapart-of-speech information, take account extracting target contextwords (e.g., string sang treated instance verb lemma sing). collectsemantic vectors set 30K target words (lemmas), namely top 20K frequentnouns, 5K frequent adjectives 5K frequent verbs combined corpora.30K lemmas also employed contextual elements (consequently, textbased semantic models encoded 30K30K matrix). Note combinetext matrices image-based ones, preserve rows (target words)also image-based vector, trimming matrix size 20,52530K.Context define context terms words co-occur within window fixedwidth, tradition popular HAL model (Lund & Burgess, 1996). Window-basedmodels attractive simplicity fact require resourceintensive advanced linguistic annotation. moreover reportedstate art various semantic tasks (Rapp, 2003; Sahlgren, 2008), Bruni,Uijlings, Baroni, Sebe (2012) show window-based methods useoutperform document-as-context model sophisticated syntax- lexicalpattern-based model MEN WordSim test sets introduced Section 5.2(see also post-hoc analysis using document-based model discussed endSection 5.2.2 below). consider two variants, Window2 Window20 (we choseparticular variants arbitrarily, representatives narrow wide windows, respectively).8. See https://github.com/s2m/FUSE/ https://github.com/vsem/, respectively.9. http://www.ims.uni-stuttgart.de/projekte/corplex/TreeTagger/10. http://wacky.sslmit.unibo.it/17fiBruni, Tran & BaroniWindow2 records sentence-internal co-occurrence nearest 2 content words leftright target word (function words articles prepositions ignored).Window20 considers larger window 20 content words left right target.narrower window expected capture narrower kind semantic similarity,one exists terms closely taxonomically related, example coordinateconcepts (dog cat) pairs superordinate subordinate concepts (animaldog). rationale behind expectation terms share many narrow-windowcollocates similar, semantically syntactically.hand, broader window capture broader kind topical similarity, onewould expect words tend occur paragraphs (for example, war oil,rather distant concepts taxonomic sense, might easily occurdiscourse). See work Sahlgren (2006) discussion effects contextwidth distributional semantic models.Association Score transform raw co-occurrence counts nonnegative Local Mutual Information (LMI) association scores. LMI scores obtained multiplying rawcounts Pointwise Mutual Information, nonnegative case close approximation Log-Likelihood Ratio scores, one widely used weightingschemes computational linguistics (Evert, 2005). nonnegative LMI target elementcontext element c defined as:P(t, c),0P(t)P(c)LM I(t, c) = max Count(t, c) logworth observing that, extensive study parameters affect qualitysemantic vectors, Bullinaria Levy (2007) Bullinaria Levy (2012) foundmodel similar Window2 (co-occurrence statistics ukWaC, narrow window,lemmatized content word collocates, nonnegative pointwise mutual information insteadLMI) performs near top variety semantic tasks. Thus, independentgrounds claim using state-of-the-art text-based model.4.2 Construction Image-Based Semantic MatrixGiven image-based semantic vectors novelty respect text-based ones,next subsections dedicate space constructed them, includingfull details source corpus utilize input pipeline (Section 4.2.1),particular image analysis technique choose extract visual collocates finallyarrange semantic vectors constitute visual block distributionalsemantic matrix (Section 4.2.2).4.2.1 Image Source Corpusadopt source corpus ESP-Game data set11 contains 100K images, labeledfamous game purpose developed Louis von Ahn, two11. http://www.cs.cmu.edu/~biglou/resources/18fiMultimodal Distributional Semanticsfffi fifffifi fffifififffiff fififf fifi fffifififffififififi fffi fffi ff fifiFigure3: Samples images tags ESP-Game data setpeople partnered online must independently rapidly agree appropriate wordlabel random selected images. word entered partners certain numbergame rounds, word added tag image, becomes taboo termnext rounds game involving image, encourage players produceterms describing image (Von Ahn, 2006). tags images data set formvocabulary 20,515 distinct word types. Images 14 tags average (4.56 standarddeviation), word tag 70 images average (737.71 standard deviation).words format text-based models, tags lemmatized POS-tagged. annotate words parts speech, couldrun POS-tagger, since words context (i.e., tag appears alphabeticallywithin small list words labeling image within ordinary sentencerequired POS-tagger). Thus used heuristic method, assigned wordsESP-Game vocabulary frequent tag textual corpora.ESP-Game corpus interesting data set point view since,one hand, rather large know tags contains related images.hand, product experts labelling representative images,noisy annotation process often poor-quality uninteresting images (e.g., logos) randomlydownloaded Web. Thus, analogously characteristics textual corpus,algorithms must able exploit large-scale statistical information, robustnoise. cleaner illustrative examples concept availablecarefully constructed databases ImageNet (see Section 2.3), noisy tag annotations19fiBruni, Tran & Baroniavailable massive scale sites Flickr12 Facebook,13 wanteventually exploit data important methods work noisy input.advantage ESP-Game respect ImageNet images associatedconcrete noun categories also adjectives, verbs nouns relatedevents (e.g., vacation, party, travel, etc). practical point view, cleandata sets ImageNet still relatively small, making experimentation standardbenchmarks difficult. concrete, looking benchmarks experiment with, mid2013, ImageNet covers half pairs WordSim353 test set, less40% Almuhareb-Poesio words. future want exploreextent higher-quality data sources improve image-based models, require largerdatabases, benchmarks relying restricted vocabulary.image samples Figure 6 exemplify different kinds noise characterizeESP-Game data set. top bottom left top right imagesscene cluttered partially occluded. top center image hardly good representative accompanying words building, tower(s) square. Similarly, centerbottom image partially good illustration coin, certainly goodexample man! Finally, bottom right image useless visual feature extractionperspective.4.2.2 Image-Based Semantic Vector Constructioncollect co-occurrence counts target words image-based contexts adoptingBoVW pipeline that, already explained 2.2, particularly convenient orderdiscretize visual information visual collocates. adopting currentlyconsidered standard implementation BoVW. future, could explorecutting-edge ways build image-based semantic vectors, local linear encoding(Wang, Yang, Yu, Lv, Huang, & Gong, 2010) Fisher encoding (Perronnin, Sanchez, &Mensink, 2010). Chatfield, Lempitsky, Vedaldi, Zisserman (2011) present systematicevaluation several recent methods.current implementation composed following steps: (i) Extractionlocal descriptors, is, vectors low-level features encode geometricinformation area around keypoint, i.e., pixel interest (here, SIFT descriptors); (ii) Constructing vector representation image assigninglocal descriptors clusters corresponding visual words, recording distributionacross clusters vector (this presupposes preliminary step clusteringalgorithm applied whole image collection sample, determine visual word vocabulary) (iii) Including spatial information representationspatial binning; (iv) Summing visual word occurrences across list images associatedword label obtain co-occurrence counts associated word labeltransforming counts association scores, analogously done textanalysis. process (without spatial binning) schematically illustrated Figure 4,hypothetical example three images collection labeledword monkey. details follow.12. http://www.flickr.com13. http://www.facebook.com20fiMultimodal Distributional SemanticsDense samplingpixelsinterestMapping SIFTdescriptors visualword clustersExtractinglocaldescriptorsSIFT 4x4monkey:04monkey3403+Labeledimagesmonkey:211Instancecounts+monkeymonkey:0390monkey:218127monkeyTotalcountsFigure 4: procedure build image-based semantic vector target word. First,bag-of-visual-word representation image labeled target wordcomputed (in case, three images labeled target word monkey).Then, visual word occurrences across instance counts summed obtainco-occurrence counts associated target word.Local Descriptors construct local descriptors pixels interest use ScaleInvariant Feature Transform (SIFT) (Lowe, 1999, 2004). chose SIFT invarianceimage scale, orientation, noise, distortion partial invariance illumination changes.SIFT vector formed measuring local image gradients region aroundlocation orientation feature multiple scales. particular, contents4 4 sampling subregions explored around keypoint. resulting16 samples, magnitude gradients 8 orientations calculated, wouldalready result SIFT feature vector 128 components. However, extract colorSIFT descriptors HSV (Hue, Saturation Value) space (Bosch, Zisserman, & Munoz,2008). use HSV encodes color information similar way humans21fiBruni, Tran & Baronido. compute SIFT descriptors HSV component. gives 3128 dimensionsper descriptor, 128 per channel. Color channels averaged obtain final128-dimensional descriptors. experimented also different color scales,LUV, LAB RGB, obtaining significantly worse performance compared HSVdevelopment set introduced 5.2.1, therefore conduct experimentsthem. Van de Sande, Gevers, Snoek (2010) present systematic evaluation colorfeatures.Instead searching interesting keypoints salient patch detection algorithm,use computationally intensive also thorough dense keypoint samplingapproach, patches fixed size localized regular grid covering whole imagerepeated multiple scales. SIFT descriptors computed regular grid everyfive pixels, four scales (10, 15, 20, 25 pixel radii) zeroing low contrast descriptors.extraction use vl_phow command included VLFeat toolbox (Vedaldi& Fulkerson, 2010). implementation shown close Lowes originalmuch faster dense feature extraction. Nowak, Jurie, Triggs (2006) reportsystematic evaluation different patch sampling strategies.Importantly, SIFT feature vectors extracted large corpus representativeimages populate feature space, subsequently quantized discrete numbervisual words clustering. step performed, every SIFT vector (local descriptor)original new images translated visual word determiningcluster nearest quantized space.Visual Vocabulary map SIFT descriptors visual words, first cluster localdescriptors extracted images training image corpus 3128-dimensionalspace using k-means clustering algorithm, encode descriptor indexcluster (visual word) belongs. k-means common way constructingvisual vocabularies (Grauman & Leibe, 2011). Given set x1 , ..., xn RD n trainingdescriptors, k-means aims partition n descriptors k sets (k n) minimizePcumulative approximation error ni=1 ||xi qi ||2 , K centroids 1 , ..., K RDdata-to-means assignments q1 , ..., qN {1, ..., K}. use approximated versionk-means called Lloyds algorithm (1982) implemented VLFeat toolbox.construct visual vocabulary extracted SIFT descriptors 100Kimages ESP-Game data set. tune parameter k used MEN developmentset (see Section 5.2.1). varying k 500 5000 steps 500, foundoptimal k 5000. likely performance peaked even 5000visual words enhancements could attained adopting larger visual vocabulariesvia efficient implementations BoVW pipeline, example Chatfield et al.(2011).Image Representation Given set descriptors x1 , ..., xn sampled image, letqi assignment descriptor xi corresponding visual word. bag-ofvisual-words representation image nonnegative vector v Rk vk = |{i :qi = k}|, q ranging 1 number visual words vocabulary (incase, 5000). representation vector visual words obtained via hard quantization(i.e., assignment local descriptor vector single nearest codeword).22fiMultimodal Distributional SemanticsSpatial Binning consolidated way introducing weak geometry BoVW usespatial histograms (Grauman & Darrell, 2005; Lazebnik, Schmid, & Ponce, 2006).main idea divide image several (spatial) regions perform entire visualword extraction counting pipeline region concatenate vectors.experiments spatial regions obtained dividing image 4 4, total16 regions. Therefore, crossing values k spatial region, increasefeature dimensions 16 times, total 80,000 components vectors.Co-occurrence Counts Weighting BoVW representations built,target (textual) word associated list images labeled it;visual word occurrences across list images summed obtain co-occurrencecounts associated target (textual) word. total, 20,515 target words (thoseconstitute ESP-Game tags) image-based semantic vector associated.Also image-based semantic matrix, like text-based one, raw countstransformed nonnegative LMI. difference LMI computedtarget element textual word context element c visual word instead.Note that, like standard textual approach, accumulating visual wordsimages contain word without taking account fact words mightdenote concepts multiple appearances, polysemous even hide homonyms(our bank vector include visual words extracted river well building pictures).interesting direction research would cluster images associatedword order distinguish visual senses word, e.g., along linesdone textual models Reisinger Mooney (2010).4.3 Multimodal Fusion Tuningperformed two separate parameter optimizations, one specifically semantic relatedness task (using MEN development, see Section 5.2.1) specificallyclustering task (using Battig, see Section 5.3.1). determined best modelperforming exhaustive search across SVD k (from 24 212 powers 2), FL SLvarying 0 1 (inclusive) steps 0.1 similarly . total, 198 models explored one highest performance development datachosen. Note tuning performed separately Window2 Window20 models.4.4 MixLDAreimplement Feng Lapatas approach (discussed Section 2.3) comparablesetting ours, treat ESP-Game data set mixed-media corpusimage together associated tags constitutes document. image, extractimage-based features procedure described 4.2.2 use wordslabeling image obtain text-based features. features storedterm-by-document matrix, image treated document termeither textual tag visual word extracted image. obtain matrix size90K100K, 10K textual words (the word list resulting intersectionwords used experimental data sets), 80K visual words 100K documents (images).23fiBruni, Tran & BaroniLatent Dirichlet Allocation (MixLDA) model trained matrix tunedMEN development set varying number topics Kt .14 optimal value findKt = 128. MixLDA, target word evaluation set representedvector giving distribution 128 latent topics.5. Experimentstest semantic representation three different tasks, is, evaluating distribution different kinds semantic relations among words neighbours (5.1), modelingword relatedness judgments (5.2) clustering words superordinate concepts (5.3).Together, tasks give us clear idea general quality modelsrelative contribution visual information meaning representation.5.1 Differentiation Semantic Relationsacquire qualitative insight well text- image-based models capturing word meaning, test BLESS (Baroni-Lenci Evaluation Semantic Similarity), benchmark recently introduced Baroni Lenci (2011) analyze specificaspects lexico-semantic knowledge. Rather focusing point estimate qualitymodel specific semantic task, BLESS allows us assess overall patternsemantic relations model tends capture. run BLESS evaluationcombining textual visual channels together sanity check semanticmeaningfulness image-based vectors, looking potential complementary information respect text motivate fusion. Note sincecombining textual visual sources, tuning parameters report.5.1.1 Benchmark MethodBLESS contains set 200 pivot words denoting concrete concepts (we use 184 pivots,since remaining 16 sufficiently large set related words coveredmodels). pivots, data set contains number related words,relata, instantiating following 8 common semantic relations pivots: coord:relatum noun co-hyponym (coordinate) pivot (alligator-lizard);hyper: relatum noun hypernym (superordinate) pivot (alligatorreptile); mero: relatum noun referring meronym, is, part materialpivot (alligator-teeth); attri: relatum adjective expressing attributepivot (alligator-ferocious); event: relatum verb referring actionevent involving concept (alligator-swim); ran.n, ran.j ran.v, finally, controlcases pivot matched set random nouns (alligator-trombone), adjectives(alligator-electronic) verbs (alligator-conclude), respectively.pivot, BLESS contains set relata category (ranging 7 hypernyms 33 random nouns per pivot average). way, BLESS highlightbroader semantic properties model independently specific preferences.example, model assigns high score alligator-ferocious modelassigns high score alligator-green correctly treated models picked14. LDA computed Gensim: http://radimrehurek.com/gensim/24fiMultimodal Distributional Semanticsrelevant attribute alligators. time, comparison specific relataselected models allows granular qualitative analysis differences.Following guidelines Baroni Lenci (2011), analyze semantic modelfollows. compute cosine model vectors representing 184pivots relata, picking relatum highest cosine8 relations (the nearest hypernym, nearest random noun, etc.). transform8 similarity scores collected way pivot onto standardized z scores (toget rid pivot-specific effects), produce boxplot summarizing distributionscores per relation across 184 pivots (for example, leftmost box first panelFigure 5 reports distribution 184 standardized cosines nearest coordinate relatarespective pivots). Besides analyzing distributions qualitatively, also discusssignificant differences cosines different relation types obtained viaTukeys Honestly Significance tests, thus correcting multiple pairwise comparisons (Abdi& Williams, 2010).5.1.2 ResultsFig. 5, report BLESS nearest relata distributions purely textual model Window20 (the Window2 distribution shows even stronger skew favour coordinateneighbours) purely visual model call Image next sections. patternsproduced text-based model (left panel) illustrate sensible word meaning profilelook like: coordinates similar terms (an alligator maximally similarcrocodile), followed superordinates (reptile) parts (teeth). Semantically relatedadjectives (attri: ferocious) verbs (event: swim) less close pivots, stillrandom item.right panel shows distribution relata image-based semantic vectors.overall pattern quite similar one observed text-based vectors:clear preference coordinates, followed hypernyms parts, attributesevents, random relata away pivots semanticallymeaningful categories. models, coordinates significantly closer relatahypernyms meronyms, significantly closer attributes events,turn significantly closer random category. Although differencehypernyms parts significant either representation, intriguinglyimage-based vectors show slight preference imageable parts (teeth)abstract hypernyms (reptile). difference statistical import oneevents attributes, text-based model shows significant preferenceevents, whereas two categories statistically indistinguishable image-basedmodel (as see shortly, relative preference latter attributes probablydue tendency pick perceptual adjectives denoting color size).Looking closely specific relata picked text- image-based models,striking differences pertain, again, attributes. text- image-basedmodels picked attribute pivot 20% cases (compare 40%overlap across non-random relation types). Table 1 reports attributes pickedtext- vs. image-based models 20 random cases two mismatch.25fiBruni, Tran & BaroniImage-based semantic vectors-2-2-1-1001122Text-based semantic vectorsCOORDHYPERMEROATTRIEVENTRAN.NRAN.JRAN.VCOORDHYPERMEROATTRIEVENTRAN.NRAN.JRAN.VFigure 5: Distribution z-normalized cosines words instantiating various relations acrossBLESS pivots. Text-based vectors Window20 model.pivotcabbagecarrotcherrydeerdishwasherelephantglidergorillahathatchettextleafyfreshripewildelectricwildheavywildwhitesharpimagewhiteorangeredbrownwhitewhitewhiteblackoldshortpivothelicopteronionovenplumsofasparrowstovetankertoastertrouttextheavyfreshelectricjuicycomfortablewildelectricheavyelectricfreshimageoldwhitenewredoldlittlehotgreynewoldTable 1: Attributes preferred text- (Window20) vs. image-based models.26fiMultimodal Distributional Semanticsimmediately clear table that, despite fact pivots nounsdenoting concrete concepts, text-based model almost never picks adjectives denotingsalient perceptual properties (and particular visual properties: white hat leafycabbage). text-based model focuses instead encyclopedic properties fresh,ripe, wild, electric comfortable. line earlier analyses ungroundedsemantics provided text-based models (Andrews et al., 2009; Baroni et al., 2010; Baroni& Lenci, 2008; Riordan & Jones, 2011), differs greatly trend foundimage-based model. 12/20 cases, closest attribute latter model color.remaining cases, size (short, little), one instance hot and, surprisingly, fourold.conclude, analysis presented confirms, one hand, hypothesisimage-based distributional vectors contain sufficient information capture networksensible word meaning relations. other, intriguing differences relations picked text- image-based models, pointing complementarity.5.2 Word Relatednessstandard distributional semantics literature (Budanitsky & Hirst, 2006; Sahlgren,2006), assess performance models task predicting degree semantic relatedness two words rated human judges. test modelsWS MEN benchmarks.5.2.1 Benchmarks MethodWS, is, WordSim35315 (see also Section 2.1) widely used benchmark constructedasking 13 subjects rate set 353 word pairs 11-point meaning similarity scaleaveraging ratings (e.g., dollar/buck gets high average rating, professor/cucumberlow one). target words cover 252 WS pairs (thus, correlations reporteddirectly comparable reported studies used WS). However,text-based models much higher WS coverage (96%). evaluated larger WSset cover, Window2 Window20 achieve 0.64 0.68 correlations, respectively.thus comparing multimodal approach purely textual modelsstate art WS (see results reported Section 2.1 above).second benchmark use, MEN (for Marco, Elia Nam, resource creators)developed us, specifically purpose testing multimodal models. createdlarge data set that, comparable WS benchmarks commonly usedcomputational semantics community, contains words appear imagelabels ESP-Game MIRFLICKR-1M16 collections, thus ensuring full coverageresearchers train visual models resources. MEN consists 3,000 word pairs[0, 1]-normalized semantic relatedness ratings provided Amazon Mechanical Turkworkers (via CrowdFlower17 interface). example, beach/sand MEN score0.96, bakery/zebra received 0 score.15. http://www.cs.technion.ac.il/~gabr/resources/data/wordsim353/16. http://press.liacs.nl/mirflickr/17. http://crowdflower.com/27fiBruni, Tran & BaroniCompared WS, MEN sufficiently large allow us separate developmenttest data, avoiding issues overfitting. use indeed 2,000 MEN pairs (development set)model tuning 1,000 pairs evaluation (test set). Importantly, developmentset used find best configuration MEN test set WS.Thus, WS evaluation illustrates well parameters learned training dataspecific data set generalize applied semantic task differentdata set.Models evaluated follows. pair data set, compute cosinemodel vectors representing words pair, calculate Spearmancorrelation cosines (pooled) human ratings pairs, ideahigher correlation better model simulate relatednessscores.MEN Construction earlier version MEN used first timeauthors Bruni et al. (2012) since current article first major publicationfocus specifically it, recently improved benchmarkextending ratings, provide details constructed.word pairs constitute MEN randomly selected words occurleast 700 times concatenated ukWaC Wackypedia text corpora least 50times tags ESP-Game MIRFLICKR-1M tagged image collections. orderavoid picking pairs weakly related, would happen samplerandom word pairs list, ranked possible pairs cosines accordingtext-based model Window20. gather 3000 word pairs needed constructionMEN, subsequently picked first 1000 word pairs, another 1000 sampledpairs placed 1001 3000 cosine-ranked list last block 1000 pairsremaining items.acquire human semantic relatedness judgments, decided ask comparativejudgments two pair exemplars time rather absolute scores single pairs,done creators WS. constitute natural way evaluatetarget pairs, since human judgments comparative nature. person evaluatesgiven target, vacuum, relation certain context.Moreover, binary choices preferred make construction rightwrong control items straightforward (see Footnote 18). Operationally, word pairrandomly matched comparison pair coming set 3000 itemsrated single Turker either less related comparison item.validity approach confirmed high annotation accuracy observecontrol set,18 high correlation MEN scores ratings collectedLikert scale report below.18. control items correct annotations created prior running job Amazon Mechanical Turk,act hidden tests randomly shown Turkers complete job. way,calculate quality contributors performance reject annotations accuracydrops certain percentage (we set required minimum precision equal 70%, obtainedalmost 100% average accuracy overall). Control items also great help train quickly new workersperform required task. create control items harvested two equally-sized sets wordpairs WS, one containing pairs high relatedness score, one containing pairslow relatedness score. control item obtained juxtaposing high score pairlow score pair treating pair higher score one selected28fiMultimodal Distributional Semanticsinstructions, annotators warned sometimes candidate pairs couldcontain words related meaning cases asked pick pairstrongly related words (e.g., wheels-car dog-race somewhat related pairs,first one preferred every car wheels every dog involvedrace). cases, annotators could find neither pair contains closely relatedwords, cases instructed pick pair contained slightlyrelated words (e.g., neither auction-car cup-asphalt closely related words,first pair picked fancy vintage cars sold auctions). requestedparticipants native speakers accepted connecting Englishspeaking country. cannot guarantee non-natives take part study,subject filtering techniques based control pairs (see Footnote 18) ensuresdata speakers good command English retained.transform binary preference data relatedness scores retrieved pairs,evaluated 50 randomly picked comparison pairs, thus received score50-point scale (given number times 50 pair pickedrelated two). score subsequently normalized 0 1 dividingnumber times pair picked related 50. example, fun-nightchosen related comparison pair 20 times, thus normalized scoregiven 20 50 = 0.4. Note that, comparison, recorded preferenceassigned one two pairs, avoid dependencies final scores assigneddifferent pairs (that is, times pair selected random comparison itemanother pair counted ratings pair).raters saw MEN pairs matched different random items, numberpairs also varying rater rater, possible compute annotator agreementscores MEN. However, get sense human agreement, first third authorrated 3,000 pairs (presented different random orders) standard 1-7 Likert scale.Spearman correlation two authors 0.68, correlation averageratings MEN scores 0.84. one hand, high correlation suggestsMEN contains meaningful semantic ratings. other, also takenupper bound computational models realistically achieve simulatinghuman MEN judgments.high-score MEN pairs include pairs terms strictly taxonomically close (cathedral-church: 0.94) also terms connected broader semanticrelations, whole-part (flower-petal: 0.92), item related event (boat-fishing: 0.9),etc. reason, prefer refer MEN semantic relatedness rathersimilarity score data set. Note WS also capturing broader notion relatedness (Agirre et al., 2009). MEN publicly available downloaded from:http://clic.cimec.unitn.it/~elia.bruni/MEN.5.2.2 ResultsTable 2 reports correlations MEN testing WS data sets using eitherWindow2 Window20 textual model. automated tuning method selected k = 29annotators related. control items manually checked. Examples control itemshotel-word vs. psychology-depression, telephone-communication vs. face-locomotive.29fiBruni, Tran & BaroniModelTextImageNaiveFLNaiveSLMixLDATextmixedImagemixedTunedFLTunedSLWindow2MEN WS0.730.700.430.360.750.670.760.690.300.230.77 0.730.550.520.78 0.720.78 0.71Window20MEN WS0.680.700.430.360.730.670.740.640.300.230.74 0.750.570.510.76 0.750.77 0.72Table 2: Spearman correlation models MEN WordSim (all coefficients significant p < 0.001). TunedFL model selected automatically MENdevelopment data; TunedSL automatically tuned fixing SL similarity estimation.(when textual information comes Window2) k = 210 (with Window20) optimal,Feature Level (FL) similarity estimation = 0.5 cases (since inputmatrices row-normalized, latter setting assigns equal weights textualvisual components). models called TunedFL table. Scoring Level(SL) strategy (again similar weights assigned two channels, k valuesTunedFL) performed slightly worse TunedFL, report resultsbest SL-based models tuned development MEN data well (TunedSL).models reported table (NaiveFL, NaiveSL, MixLDA, Textmixed Imagemixed ),parameters tuned manually order gain insights combination strategiesrepresenting ideas earlier literature.19first two rows table show results text- image-based models,mixing. Text shows comparable performances data sets. Image correlatessignificantly better MEN WS correlations lower Text,accordance found earlier studies. next three rows findresults earlier multimodal approaches took consideration (Bruni et al., 2011;Feng & Lapata, 2010; Leong & Mihalcea, 2011). NaiveFL approach (analogousBruni et al.s method), textual visual matrices concatenated withoutmixing, performs slightly better Text MEN, attains lower performance WS.Also NaiveSL (equivalent Leong Mihalceas summing approach), textimage sources combined scoring level, obtains improvements MEN, loosingseveral correlation points WS compared Text.implementation MixLDA achieves poor results MEN WS. Onemight attribute fact Feng Lapatas approach constrained usingsource textual visual model image data set poor source19. Textmixed Imagemixed , best k values found development data.set 210 textual sources.30fiMultimodal Distributional SemanticsTextmixedTunedFLTunedSLWindow20.470.460.46Window200.490.490.47Table 3: Pearson correlation best multimodal combinations WordSimsubset covered Feng Lapata (2010) (all coefficients significant p <0.001; Pearson used instead Spearman full comparability FengLapata). models assigned 0 similarity 71/253 pairsmissing vector. Feng Lapata (2010) report 0.32 correlation MixLDA.textual data. approach however also outperforming original MixLDAlarge margin latter WS test set, strongly disfavoured. particular,Feng Lapata (2010) report correlation 0.32 subset 253 WS pairs coveredmodel. tested system subset, despite factmissing one vectors 71 pairs (almost one third), modelsforced assign 0 cosines cases. Despite huge handicap, modelsstill attaining much higher correlations original MixLDA Feng Lapatapairs, illustrated interesting fusion strategies Table 3.Analyzing effects fusion strategies, first see uniform enhancement MEN WS Textmixed Imagemixed (the models obtained firstperforming latent multimodal mixing combined matrix, using textual features Textmixed visual features Imagemixed ). Textmixed reaches bestperformance overall WS source textual models, significantly betterText MEN according two-tailed paired permutation test (Moore & McCabe,2005). Looking automatically selected TunedFL model, reaches best performance overall. significantly outperforms Text models data sets,significantly better Textmixed MEN Window20 (the difference approaching significance Window2 well: p = 0.06). TunedSL also competitive.also significantly better Text window sizes Textmixed Window20.noticeably worse TunedFL WS Window20 only, actuallyslight advantage MEN Window20 (the difference TunedFL TunedSLnever significant).worth remarking Textmixed bit worse full fusion models,still achieves high correlations human judgments extremely highcorrelation TunedFL best model ( = 0.98). suggestsbenefits multimodality already captured latent mixing. Textmixed attractivemodel less parameters whole pipeline compactTunedFL, since discards visual features using mixing.Validating Results shown significant improvements visual features added distributional models, one could object improvements duefact using information: larger number features (higher-dimensional31fiBruni, Tran & Baronivectors) Feature Level fusion, complex model (two similarity scoresindependent variables predict human judgments) Scoring Level fusion. experiments provide evidence respond objection.First, built purely textual models number features multimodalmodels is, instead collecting co-occurrence target terms 30Kfrequent content lemmas corpus (see Section 4.1 above), extended listcontext items 110K frequent content lemmas. results largertextual models virtually identical 30K-dimensional vectors reportedTable 2 (correlation Window20 model MEN 0.69 instead 0.68). Thus,least using large corpus window-based approach, 30K featurespretty much exhausted useful textual information, nature, simplyquantity extra visual features add matters.answer objection Scoring Level approach using complex model,two independent variables (text- image-base similarities) instead one, castedproblem standard inferential statistical terms (see, e.g, Baayen, 2008, ch. 6). Specifically, fitted ordinary linear regression models predict MEN WS ratingstext-based similarities vs. text- image-based similarities (for comparabilitySpearman correlation results reported above, analyses also replicatedtransforming ratings similarities ranks). variables highly significantexperiments, and, importantly, sequential F-tests nested models revealedcases adding image-based similarities explains significantly variancewould expected chance given extra parameter (p < 0.01).Qualitative Analysis acquire qualitative insights multimodality contributing meaning representation, first picked top 200 related pairscombined MEN WS norms, would confident indeed highlyrelated pairs humans, looked, within subset, pairspronounced difference cosines Text TunedFL, using Window20textual source. is, first column Table 4 presents pairs consideredrelated humans relatedness better captured Text, second columnpairs relatedness better captured TunedFL.Notice 7/10 relations better captured TunedFL coordinatessynonyms pertaining concrete objects (candy/chocolate, bicycle/bike, apple/cherry,military/soldier, paws/whiskers, stream/waterfall cheetah/lion), indeedmaximally visually similar (either objects or, case paws/whiskers,surrounds). purely text-based model, hand, captures relationstimes day, that, imageable, well-delimited concrete objects(dawn/dusk, sunrise/sunset). captures properties concepts expressed adjectives(dog/canine, skyscraper/tall, cat/feline, pregnancy/pregnant, rain/misty), least onecase spotting relation requires encyclopedic knowledge (grape/wine). thushypothesize added value multimodally-enhanced model derivespower vision finding relations concrete objects taxonomic level,results detecting particularly tight forms relatedness, synonymycoordination.32fiMultimodal Distributional SemanticsTextdawn/dusksunrise/sunsetcanine/doggrape/winefoliage/plantfoliage/petalskyscraper/tallcat/felinepregnancy/pregnantmisty/rainTunedFLpet/puppycandy/chocolatepaw/petbicycle/bikeapple/cherrycopper/metalmilitary/soldierpaws/whiskersstream/waterfallcheetah/lionTable 4: Top 10 pairs whose relatedness better captured Text (Window20)vs. TunedFL.observed one reviewer, given taxonomic nature information capturedmultimodal approach, interesting compare future work featuresdirectly extracted linguistic taxonomy, WordNet. observe passingmanually-constructed resource, unlike extracted textual corpora, likelyreflect linguistic perceptual knowledge lexicographers builtit.Going opposite direction, another reviewer observed might getmileage combining visual features textual models less taxonomic nature.hypothesis partially confirmed fact obtain larger relative improvement mixing vision Window20 Window2 (look back Table 2, seeSection 4.1 think narrower window mainly captures taxonomicrelations, larger one broader topical themes). explore conjecture,re-ran MEN WS experiments combining visual vectors document-basedtextual model (i.e., semantic space whose dimensions record number occurrenceswords documents). space expected capture mostly topical information,estimates relatedness basis tendency words occurdocuments (Sahlgren, 2006). document-based model alone goodwindow-based models (it obtained Spearman correlation 0.68 MEN 0.63WS), combining image-based models led relative improvements comparableinferior attained Window20 (the best combined-model correlations0.73 MEN 0.70 WS). conclude that, looking textual modelscomplementary respect visual information seems reasonable directiondevelop multimodal systems cover broader range semantic phenomena, simplyemphasizing topical side textual models evidently suffice.33fiBruni, Tran & Baroni5.2.3 Concreteness Factor Modeling Relatedness Ratings: PilotStudyprevious experiments, observed trend towards division labour text- image-based models, latter apt capturing similarityamong concrete concepts properties. One strongest limitations currentversion framework fact every target word assumed equally perceptually salient consequently uniformly enriched visual information. Intuitively,might want distinguish instead concrete words, chair cat, requireintegration perceptual information representation, abstract words,consequence absurd, represented purely symbolic/linguistic basis.Indeed, Recchia Jones (2012) recently presented evidence that, lexical decisionnaming tasks, rich physical contexts favour activation concrete concepts, whereas richlinguistic contexts facilitate activation abstract concepts. follow-up pilotexperiment presented section want pave way systematic introduction concreteness factor multimodal meaning representation. Operationally,separate abstract concrete word pairs semantic relatedness benchmarkMEN, assessing contribution textual visual information approximating wordmeaning two domains independently. Importantly, use automated methoddetermine word concrete abstract, eye future integrationautomatically-determined abstractness score fusion algorithm.particular, use abstractness scores automatically assigned algorithm recently introduced Turney, Neuman, Assaf, Cohen (2011). Scores calculatedcomputing difference sum text-based semantic similarities targetword set concrete paradigm words sum semantic similaritiesset abstract paradigm words. words (i.e., paradigm words wordsabstractness score computed) represented co-occurrence basedmatrix gathered large corpus university websites. Co-occurrence countstransformed Positive Pointwise Mutual Information scores (Church & Hanks, 1990)resulting matrix smoothed SVD. Pairwise semantic similarity measuredcosines. paradigm words turn selected supervised learning methodtrained subject-rated words MRC Psycholinguistic Database Machine UsableDictionary (Coltheart, 1981). Examples highly abstract words automatically ratedlist purvey: 1.00, sense: 0.96 improbable: 0.92, examples highly concretewords (i.e., words low abstractness score) donut: 0.00, bullet: 0.07 shoe:0.10.abstractness score assigned MEN testing words, divideddata set two subsets, one containing concrete word pairs (MEN-conc, 837pairs), containing abstract pairs mixed pairs, pairs formed oneconcrete one abstract word (MEN-abst, 163 pairs). word considered concreteabstract score 0.5, abstract otherwise. example, word pair arm-bicycleconsidered concrete (with scores 0.33 0.35 respectively), fun-relax consideredabstract (with scores 0.6 0.59 respectively) design-orange considered mixed(with scores 0.55 0.20 respectively). experimented Window20 purely34fiMultimodal Distributional SemanticsModelWindow20ImageTunedFLMEN-conc0.700.470.78MEN-abst0.510.370.52MEN-full0.680.430.76Table 5: Spearman correlation models MEN divided concrete abstractsubsets. Results full data set also repeated. coefficients significantp < 0.001.textual model, Image usual visual model TunedFL trained MEN developmentmultimodal model.Table 5 show correlation scores three models two MEN subsets(as well repeating correlations attain full set). First all, worthnoticing models higher correlations MEN-conc MEN-abst, suggestingapproximating similarity judgments pairs concrete pairs general easiertask distributional semantics (and, suspect, humans well!). Besides broadeffect, also observe clear interaction added value visual componentMEN-abst MEN-conc. fact, TunedFL gains 11% performanceMEN-conc compared Window20, performance essentiallytext-only model case MEN-abst. indicates visual informationmostly beneficial concrete domain, maintains neutral (timidly positive)impact abstract domain (recall that, case, MEN-abst also contains mixedpairs).conclude, section followed qualitative analysis mainrelatedness results pilot experiment focusing concreteness factor. showeddivide MEN benchmark concrete abstract subsets, visualinformation enhances text-based model concrete domain, impactstrong. exploited automatic scoring function divide data setconcrete abstract subsets. thus see results reporting alsovalidation Turney et al.s algorithm, and, importantly purposes,encouragement incorporate automated abstractness/concreteness scoring waymodel mixes textual visual information word-by-word basis.5.3 Concept Categorizationverify conclusions reached WS MEN extend different semantic tasks and,particular, assess whether multimodal approach able capture organizemeaning humans do, use two existing concept categorization benchmarkscall Battig Almuhareb-Poesio (AP), respectively, goal cluster set(nominal) concepts broader categories, already discussed Section 2.1.particular, use Battig exclusively tuning (in way used MENdevelopment set previous section) AP testing. results APreported. word relatedness task tuning testing sets quite similar35fiBruni, Tran & Baroni(MEN development MEN testing two subsets data set wordsWS similar MEN), task challenging since Battig APtwo independent data sets built following different strategies populateddifferent kinds concepts, namely concrete unambiguous concepts Battig,vs. mixture concrete abstract, possibly ambiguous concepts AP. adoptedpresent challenging training testing regime felt neither data setsufficient size allow split development testing data. details follow.5.3.1 Benchmarks MethodBattig benchmark introduced Baroni et al. (2010) based BattigMontague norms Van Overschelde, Rawson, Dunlosky (2004). consists83 highly prototypical concepts 10 common concrete categories (up 10 conceptsper class). Battig contains basic-level concepts belonging categories bird (eagle,owl. . . ), kitchenware (bowl, spoon. . . ) vegetable (broccoli, potato. . . ). versioncover 77 concepts 10 different classes.AP introduced Almuhareb Poesio (2005) made 402 nouns21 different WordNet classes. version cover, AP contains 231 conceptsclustered 21 classes vehicle (airplane, car. . . ), time (aeon, future. . . ) socialunit (brigade, nation). data set contains many difficult cases unusual ambiguousinstances class, casuarina samba trees.sets, following original proponents others, cluster words basedpairwise cosines semantic space defined model using CLUTO toolkit(Karypis, 2003). use CLUTOs built-in repeated bisections global optimizationmethod, accepting CLUTOs default values. Cluster quality often evaluatedpercentage purity (Zhao & Karypis, 2003). nir number items i-th true(gold standard) class assigned r-th cluster, n total number items,k number clusters,purity =X1 i=nmax (nri )n i=1words, number items belonging majority true class (i.e., representedclass cluster) summed across clusters divided total number items.best scenario purity 1 approach 0 cluster quality deteriorates.Since lack full AP coverage, results report directly comparablestudies used it. However, text-based models perfect coverage,evaluated full set achieve purities 0.67 (Window2) 0.61 (Window2),state-of-the-art levels comparable models, reported Section 2.1 above.So, again, confidently claim improvements achieved multimodalityobtained comparing approach competitive purely textual models.5.3.2 ResultsTable 6 reports percentage purities AP clustering task. Also best automatically selected model (TunedFL) uses FL similarity estimation previous task,similar SVD k (27 Window2 29 Window20) (0.5) parameters36fiMultimodal Distributional SemanticsModelTextImageNaiveFLNaiveSLMixLDATextmixedImagemixedTunedFLTunedSLWindow2AP0.730.260.740.650.140.740.350.740.75Window20AP0.650.260.640.660.140.670.290.690.69Table 6: Percentage purities models AP. TunedFL model automaticallyselected Battig data; TunedSL automatically tuned fixing SL similarity estimation.ones found relatedness, suggesting particular parameter choice robustcould used out-of-the-box tasks well. TunedSL best SL-based methodtuning Battig set (same ks TunedFL, = 0.5 Window20 = 0.9Window2).Analogously previous semantic task, see Image model alonelevel text models, although AP purities significantly chance(p < 0.05 based simulated distributions random cluster assignment). Thus,confirmation fact image-based vectors capture important aspectsmeaning. previous task, MixLDA achieves poor results.Looking text-based models enhanced visual information, see generalimprovement performance almost multimodal combination strategies, exceptNaiveFL Window20 NaiveSL Window2. Even Textmixed benefitsvisual smoothing cases, outperformed TunedFL, whose performancesimilar TunedSL, actually slightly better Window2. Interestingly, TunedSL outperforms Text Window2 despite fact single combinationstrongly unbalanced towards textual similarity ( = 0.9), indicating visual information beneficial even textual information accounts lions sharecomposed estimate.Like relatedness task, adding equal amount textual features insteadimage-based ones help Window20 (0.66 purity 110K textual features)even lowers performance Window2 (0.69 purity). Thus, improvement broughtvisual features must attributed quality, quantity.According two-tailed permutation test, even largest difference TunedFLText Window20 significant. might due brittleness puritystatistics leading high variance permutations, possibly suboptimal tuning.Recall, respect, tuning phase performed rather different dataset (Battig) compared data set eventually evaluated models (AP).37fiBruni, Tran & BaroniHowever, overall trends encouraging, line foundrelatedness study.6. Conclusionpaper provided extensive introduction new approach distributional semantics named Multimodal Distributional Semantics. multimodaldistributional semantic model integrates traditional text-based representation meaninginformation coming vision. way, tries answer critique distributional models lack grounding, since base representation meaning entirelylinguistic input, neglecting statistical information inherent perceptual experience,humans instead exploit. course, truly multimodal representation meaningaccount entire spectrum human senses. hand, lineresearch still embryonic stage still shortage perceptual dataavailable techniques automatize processing. why, article,focused analysis visual perceptual channel, disposallarge data sets effective methods analyze them.particular, exploited ESP-Game data set, image documentstagged words describing content. harvest visual information adoptedbag-of-visual-words technique, discretizes image content ways analogousstandard text-based distributional representations. introduced multimodal frameworkoptimizes text-image fusion data-driven fashion development data.conducted number experiments assess quality obtained models.first investigated general semantic properties purely image-based model,assess overall quality well look information complementary presenttext. found systematic differences two modalities, preferenceencyclopedic properties text-based model perceptual properties caseimage-based model. proceeded test selection models obtained combinationtext- image-based representations via multimodal framework. used twobenchmarks word relatedness one benchmark word categorizationcases obtained systematic improvement performance multimodal modelscompared models based standalone channels.Still, looking numerical results, cannot deny improvement performance attained including visual information dramatic. Indeed, pessimisticinterpretation experiments could confirm hypothesis Louwerseothers (e.g., Louwerse, 2011; Louwerse & Connell, 2011; Tillman, Datla, Hutchinson, &Louwerse, 2012) perceptual information already encoded, sufficient degree,linguistic data, direct visual features dont bring much table. However, showedvarious statistical validation tests important result, namelyadding visual information improves using text alone, robust reliable. thinkrealistic take-home message experiments reported, establishingbasic result mentioned, drawbacks overcomework.First all, deliberately used general semantic benchmarks state-of-the-art textmodels, performance computational methods might getting close38fiMultimodal Distributional Semanticsceiling. 0.78 correlation, best models still percentage points goMEN (estimated upper bound based raters agreement: 0.84, see Section 5.2.1),improvements bound quite small. Concerning AP benchmark, considerdifficult would even humans categorize casuarina samba amongtrees. Indeed, error analysis TunedFL clustering results suggests factorsmight lead better performance little vision. example,model wrongly clusters branch (a social unit according AP) trees, mergesconcepts melon peach (fruit AP) mandarin lime (trees). lackcontextual information, hard dispute model choices. Similarly, TunedFLsplits AP animal class cluster small domestic mammals (cats, dogs, kittens,mice, puppies rats) cluster containing everything else (mostly larger mammalscows elephants). Again, clustering procedure informationclasses searching (e.g., animals general, small animals),hard see performance could improved thanks better semantic features, visualkinds. Moreover, data sets include abstract terms, specificallydesigned test grounded aspects meaning, visual features might helpmost. think made sense start investigation general benchmarkssemantics, opposed ad hoc test sets, show viability multimodal approach.However, future want focus experimental challenges strengthsvisually-enhanced models might emerge clearly. took first step directionBruni et al. (2012), focused specifically visual features helpprocessing literal metaphorical colours.Another factor take account large-scale image data setstechniques extract features infancy, might ableimprove performance developing better image-based models. Regarding datasets, explained Section 4.2.1 chose ESP-Game, obviouslysub-optimal many respects, also discuss there. Regarding features,mentioned beginning Section 4.2.2, recent advances image processing,Fisher encoding, might lead better ways extract information contained images.experiments, also compared automatically tuned multimodal modelsettings, showing overall stability superiority, two important caveats.First, experiments good results already obtained using visual informationsmooth text features, without using visual features directly (what calledTextmixed approach). Note already multimodal approach, visualinformation crucially used improve quality textual dimensions, indeedweve seen consistently outperforms using non-multimodally-smoothed text features.Textmixed good full tuned model, simplicity makesattractive approach.Second, although automated tuning led us prefer Feature Level Scoring Levelfusion development sets, TunedSL clearly worse TunedFL one case(with Window20 WS), suggesting that, least evaluation settings considered,difference two fusion strategies crucial. However, comparingnaive versions strategies tuned ones across results, cleartuning important obtain consistently good performance, confirming usefulnessgeneral fusion architecture.39fiBruni, Tran & Baronialso conducted pilot experiment concreteness/abstractness factor, assessimpact meaning representation check good candidate newweighted-fusion strategy plan investigate future. fact, current versionmultimodal framework, parametrization combination strategy worksglobal level (i.e, words). could productive combine textualvisual information word-by-word basis, tune two modality contributionsmeaning representation depending particular nature single word. Concretevs. abstract constitute neat binary distinction words, ratherthought ideal distinction offset less abrupt, real-world formulation,takes account degree according certain word considered concreteabstract. doubt words backdrop, squalor sharp evokeperceptual cues gathered experience them, timeunequivocal amount abstractness accompanying them. plan also refineconcreteness scoring method order make focus specifically imageablecomponents concreteness, expect relevant visual channel.developments focus techniques extract image-based semanticmodels. example, pilot study (Bruni et al., 2012), exploit new methods developedcomputer vision improve object recognition capturing object location (Felzenszwalb,Girshick, McAllester, & Deva Ramanan, 2010; de Sande, Uijlings, Gevers, & Smeulders,2011). show possible extract better image-based semantic vectors firstlocalizing objects denoted words extracting visual informationobject location surround independently. Interestingly, discoveredimage-based semantic vectors extracted object surround effectivebased object location tested word relatedness task. example,fact pictures containing deers wolves depict similar surrounds tells uscreatures live similar environments, thus likely somewhatrelated. seen distributional hypothesis transposed images: objectssemantically similar occur similar visual contexts. Nevertheless, workconsidered proof concept, since experimented 20 words only. futurestudies test larger number words.obviously much room improvement, many exciting routesexplore, hope framework empirical results presented studyconvinced reader multimodal distributional semantics promising avenuepursue development human-like models meaning.Acknowledgmentsthank Jasper Uijlings valuable suggestions image analysis pipeline.lot code many ideas came Giang Binh Tran, owe Gemma Boleda manyideas useful comments. Peter Turney kindly shared abstractness score listused Section 5.2.3 Yair Neuman generously helped preliminary analysisimpact abstractness multimodal models. Mirella Lapata kindly madeWordSim353 set used experiments Feng Lapata (2010) available us.thank JAIR associated editor reviewers helpful suggestions constructive40fiMultimodal Distributional Semanticscriticism. Google partially funded project Google Research Award thirdauthor. BLESS study Section 5.1.2 first presented Bruni et al. (2012).ReferencesAbdi, H., & Williams, L. (2010). Newman-Keuls Tukey test. Salkind, N., Frey, B., &Dougherty, D. (Eds.), Encyclopedia Research Design, pp. 897904. Sage, ThousandOaks, CA.Agirre, E., Alfonseca, E., Hall, K., Kravalova, J., Pasa, M., & Soroa, A. (2009). studysimilarity relatedness using distributional WordNet-based approaches.Proceedings HLT-NAACL, pp. 1927, Boulder, CO.Almuhareb, A., & Poesio, M. (2005). Concept learning categorization web.Proceedings CogSci, pp. 103108, Stresa, Italy.Andrews, M., Vigliocco, G., & Vinson, D. (2009). Integrating experiential distributionaldata learn semantic representations. Psychological Review, 116 (3), 463498.Baayen, H. (2008). Analyzing Linguistic Data: Practical Introduction Statistics usingR. Cambridge University Press, Cambridge, UK.Barnard, K., Duygulu, P., Forsyth, D., de Freitas, N., Blei, D., & Jordan, M. (2003). Matching words pictures. Journal Machine Learning Research, 3, 11071135.Baroni, M., Barbu, E., Murphy, B., & Poesio, M. (2010). Strudel: distributional semanticmodel based properties types. Cognitive Science, 34 (2), 222254.Baroni, M., & Lenci, A. (2008). Concepts properties word spaces. Italian JournalLinguistics, 20 (1), 5588.Baroni, M., & Lenci, A. (2010). Distributional Memory: general framework corpusbased semantics. Computational Linguistics, 36 (4), 673721.Baroni, M., & Lenci, A. (2011). BLESSed distributional semantic evaluation.Proceedings EMNLP GEMS Workshop, pp. 110, Edinburgh, UK.Barsalou, L. (2008). Grounded cognition. Annual Review Psychology, 59, 617645.Berg, T., Berg, A., & Shih, J. (2010). Automatic attribute discovery characterizationnoisy Web data. ECCV, pp. 663676, Crete, Greece.Bergsma, S., & Goebel, R. (2011). Using visual information predict lexical preference.Proceedings RANLP, pp. 399405, Hissar, Bulgaria.Blei, D. M., Ng, A. Y., & Jordan, M. I. (2003). Latent Dirichlet allocation. JournalMachine Learning Research, 3, 9931022.Bosch, A., Zisserman, A., & Munoz, X. (2007). Image classification using random forestsferns. Proceedings ICCV, pp. 18, Rio de Janeiro, Brazil.Bosch, A., Zisserman, A., & Munoz, X. (2008). Scene classification using hybrid generative/discriminative approach. IEEE Transactions Pattern Analysis MachineIntelligence, 30 (4).Bruni, E., Boleda, G., Baroni, M., & Tran, N. K. (2012). Distributional semanticsTechnicolor. Proceedings ACL, pp. 136145, Jeju Island, Korea.41fiBruni, Tran & BaroniBruni, E., Bordignon, U., Liska, A., Uijlings, J., & Sergienya, I. (2013). Vsem: openlibrary visual semantics representation. Proceedings ACL, Sofia, Bulgaria.Bruni, E., Tran, G. B., & Baroni, M. (2011). Distributional semantics text images.Proceedings EMNLP GEMS Workshop, pp. 2232, Edinburgh, UK.Bruni, E., Uijlings, J., Baroni, M., & Sebe, N. (2012). Distributional semantics eyes:Using image analysis improve computational representations word meaning.Proceedings ACM Multimedia, pp. 12191228, Nara, Japan.Budanitsky, A., & Hirst, G. (2006). Evaluating WordNet-based measures lexical semanticrelatedness. Computational Linguistics, 32 (1), 1347.Bullinaria, J., & Levy, J. (2007). Extracting semantic representations word cooccurrence statistics: computational study. Behavior Research Methods, 39, 510526.Bullinaria, J., & Levy, J. (2012). Extracting semantic representations word cooccurrence statistics: Stop-lists, stemming SVD. Behavior Research Methods,44, 890907.Burgess, C. (2000). Theory operational definitions computational memory models:response Glenberg Robertson. Journal Memory Language, 43 (3),402408.Caicedo, J., Ben-Abdallah, J., Gonzlez, F., & Nasraoui, O. (2012). Multimodal representation, indexing, automated annotation retrieval image collections via nonnegative matrix factorization. Neurocomputing, 76 (1), 5060.Chatfield, K., Lempitsky, V., Vedaldi, A., & Zisserman, A. (2011). devildetails: evaluation recent feature encoding methods. Proceedings BMVC,Dundee, UK.Church, K., & Hanks, P. (1990). Word association norms, mutual information, lexicography. Computational Linguistics, 16 (1), 2229.Clark, S. (2013). Vector space models lexical meaning. Lappin, S., & Fox, C. (Eds.),Handbook Contemporary Semantics, 2nd ed. Blackwell, Malden, MA. press.Coltheart, M. (1981). MRC psycholinguistic database. Quarterly Journal Experimental Psychology, 33.Connolly, A., Gleitman, L., & Thompson-Schill, S. (2007). Effect congenital blindnesssemantic representation everyday concepts. Proceedings NationalAcademy Sciences, 104 (20), 82418246.Csurka, G., Dance, C., Fan, L., Willamowski, J., & Bray, C. (2004). Visual categorizationbags keypoints. Workshop Statistical Learning Computer Vision,ECCV, pp. 122, Prague, Czech Republic.Curran, J., & Moens, M. (2002). Improvements automatic thesaurus extraction.Proceedings ACL Workshop Unsupervised Lexical Acquisition, pp. 5966,Philadelphia, PA.42fiMultimodal Distributional Semanticsde Sande, K. V., Uijlings, J., Gevers, T., & Smeulders, A. (2011). Segmentation selectivesearch object recognition. Proceedings ICCV, pp. 18791886, Barcelona,Spain.de Vega, M., Glenberg, A., & Graesser, A. (Eds.). (2008). Symbols Embodiment: DebatesMeaning Cognition. Oxford University Press, Oxford, UK.Deng, J., Dong, W., Socher, R., Li, L.-J., & Fei-Fei, L. (2009). Imagenet: large-scalehierarchical image database. Proceedings CVPR, pp. 248255, Miami Beach,FL.Dumais, S. (2003). Data-driven approaches information access. Cognitive Science, 27,491524.Erk, K. (2012). Vector space models word meaning phrase meaning: survey..Language Linguistics Compass, 6 (10), 635653.Escalante, H. J., Hrnadez, C. A., Sucar, L. E., & Montes, M. (2008). Late fusion heterogeneous methods multimedia image retrieval. Proceedings ICMR, Vancouver,Canada.Evert, S. (2005). Statistics Word Cooccurrences. Dissertation, Stuttgart University.Farhadi, A., Hejrati, M., Sadeghi, M. A., Young, P., Rashtchian, C., Hockenmaier, J., &Forsyth, D. (2010). Every picture tells story: Generating sentences images.Proceedings ECCV, Crete, Greece.Felzenszwalb, P., Girshick, R., McAllester, D., & Deva Ramanan, D. (2010). Object detection discriminatively trained part based models. IEEE Transactions PatternAnalysis Machine Intelligence, 32, 16271645.Feng, Y., & Lapata, M. (2010). Visual information semantic representation. Proceedings HLT-NAACL, pp. 9199, Los Angeles, CA.Finkelstein, L., Gabrilovich, E., Matias, Y., Rivlin, E., Solan, Z., Wolfman, G., & Ruppin,E. (2002). Placing search context: concept revisited. ACM TransactionsInformation Systems, 20 (1), 116131.Firth, J. R. (1957). Papers Linguistics, 1934-1951. Oxford University Press, Oxford,UK.Fodor, J. (1975). Language Thought. Crowell Press, New York.Glenberg, A., & Robertson, D. (2000). Symbol grounding meaning: comparisonhigh-dimensional embodied theories meaning. Journal Memory Language, 3 (43), 379401.Grauman, K., & Darrell, T. (2005). pyramid match kernel: Discriminative classificationsets image features. Proceedings ICCV, pp. 14581465, Beijing, China.Grauman, K., & Leibe, B. (2011). Visual Object Recognition. Morgan & Claypool, SanFrancisco.Grefenstette, G. (1994). Explorations Automatic Thesaurus Discovery. Kluwer, Boston,MA.43fiBruni, Tran & BaroniGriffin, L., Wahab, H., & Newell, A. (2013). Distributional learning appearance. PLoSONE, 8 (2). Published online: http://www.plosone.org/article/info:doi/10.1371/journal.pone.0058074.Griffiths, T., Steyvers, M., & Tenenbaum, J. (2007). Topics semantic representation.Psychological Review, 114, 211244.Hansen, T., Olkkonen, M., Walter, S., & Gegenfurtner, K. (2006). Memory modulates colorappearance. Nature Neuroscience, 9, 13671368.Harnad, S. (1990). symbol grounding problem. Physica D: Nonlinear Phenomena,42 (1-3), 335346.Harris, Z. (1954). Distributional structure. Word, 10 (2-3), 14561162.Johns, B., & Jones, M. (2012). Perceptual inference global lexical similarity. TopicsCognitive Science, 4 (1), 103120.Karypis, G. (2003). CLUTO: clustering toolkit. Tech. rep. 02-017, University MinnesotaDepartment Computer Science.Kaschak, M., Madden, C., Therriault, D., Yaxley, R., Aveyard, M., Blanchard, A., & Zwaan,R. (2005). Perception motion affects language processing. Cognition, 94, B79B89.Kievit-Kylar, B., & Jones, M. (2011). Semantic Pictionary project. ProceedingsCogSci, pp. 22292234, Austin, TX.Kulkarni, G., Premraj, V., Dhar, S., Li, S., Choi, Y., Berg, A. C., & Berg, T. L. (2011).Baby talk: Understanding generating simple image descriptions. ProceedingsCVPR, Colorado Springs, MSA.Landauer, T., & Dumais, S. (1997). solution Platos problem: latent semantic analysis theory acquisition, induction, representation knowledge. PsychologicalReview, 104 (2), 211240.Lazebnik, S., Schmid, C., & Ponce, J. (2006). Beyond bags features: Spatial pyramidmatching recognizing natural scene categories. Proceedings CVPR, pp. 21692178, Washington, DC.Leong, C. W., & Mihalcea, R. (2011). Going beyond text: hybrid image-text approachmeasuring word relatedness. Proceedings IJCNLP, pp. 14031407.Lloyd, S. (1982). Least squares quantization PCM. IEEE Transactions InformationTheory, 28, 129137.Louwerse, M. (2011). Symbol interdependency symbolic embodied cognition. TopicsCognitive Science, 3, 273302.Louwerse, M., & Connell, L. (2011). taste words: Linguistic context perceptualsimulation predict modality words. Cognitive Science, 35, 381398.Lowe, D. (1999). Object recognition local scale-invariant features. ProceedingsICCV, pp. 11501157.Lowe, D. (2004). Distinctive image features scale-invariant keypoints. InternationalJournal Computer Vision, 60 (2).44fiMultimodal Distributional SemanticsLowe, W. (2001). Towards theory semantic space. Proceedings CogSci, pp. 576581,Edinburgh, UK.Lund, K., & Burgess, C. (1996). Producing high-dimensional semantic spaces lexicalco-occurrence. Behavior Research Methods, 28, 203208.Manning, C., Raghavan, P., & Schtze, H. (2008). Introduction Information Retrieval.Cambridge University Press, Cambridge, UK.Manning, C., & Schtze, H. (1999). Foundations Statistical Natural Language Processing.MIT Press, Cambridge, MA.McDonald, S., & Brew, C. (2004). distributional model semantic context effectslexical processing. Proceedings ACL, pp. 1724, Barcelona, Spain.McRae, K., Cree, G., Seidenberg, M., & McNorgan, C. (2005). Semantic feature productionnorms large set living nonliving things. Behavior Research Methods, 37 (4),547559.Miller, G., & Charles, W. (1991). Contextual correlates semantic similarity. LanguageCognitive Processes, 6 (1), 128.Moore, D., & McCabe, G. (2005). Introduction Practice Statistics (5 edition).Freeman, New York.Murphy, G. (2002). Big Book Concepts. MIT Press, Cambridge, MA.Nelson, D., McEvoy, C., & Schreiber, T. (1998). University South Florida word association, rhyme, word fragment norms. http://www.usf.edu/FreeAssociation/.Nister, D., & Stewenius, H. (2006). Scalable recognition vocabulary tree. Proceedings 2006 IEEE Computer Society Conference Computer Vision PatternRecognition - Volume 2, CVPR 06, pp. 21612168.Nowak, E., Jurie, F., & Triggs, B. (2006). Sampling strategies bag-of-features imageclassification. Proceedings ECCV, pp. 490503, Graz, Austria.Pad, S., & Lapata, M. (2007). Dependency-based construction semantic space models.Computational Linguistics, 33 (2), 161199.Pad, U., Pad, S., & Erk, K. (2007). Flexible, corpus-based modelling human plausibilityjudgements. Proceedings EMNLP, pp. 400409, Prague, Czech Republic.Pecher, D., Zeelenberg, R., & Raaijmakers, J. (1998). pizza prime coin? Perceptualpriming lexical decision pronunciation. Journal Memory Language, 38,401418.Perronnin, F., Sanchez, J., & Mensink, T. (2010). Improving fisher kernel large-scaleimage classification. Proceedings ECCV, pp. 143156, Berlin, Heidelberg.Pham, T.-T., Maillot, N., Lim, J.-H., & Chevallet, J.-P. (2007). Latent semantic fusionmodel image retrieval annotation. Proceedings CIKM, pp. 439443,Lisboa, Portugal.Poesio, M., & Almuhareb, A. (2005). Identifying concept attributes using classifier.Proceedings ACL Workshop Deep Lexical Semantics, pp. 1827, Ann Arbor,MI.45fiBruni, Tran & BaroniPulvermueller, F. (2005). Brain mechanisms linking language action. Nature ReviewsNeuroscience, 6, 576582.Radinsky, K., Agichtein, E., Gabrilovich, E., & Markovitch, S. (2011). word time:computing word relatedness using temporal semantic analysis. ProceedingsWWW, pp. 337346, Hyderabad, India.Rapp, R. (2003). Word sense discovery based sense descriptor dissimilarity. Proceedings 9th MT Summit, pp. 315322, New Orleans, LA.Recchia, G., & Jones, M. (2012). semantic richness abstract concepts. FrontiersHuman Neuroscience, 6 (315).Reisinger, J., & Mooney, R. J. (2010). Multi-prototype vector-space models word meaning. Proceedings NAACL, pp. 109117, Los Angeles, CA.Riordan, B., & Jones, M. (2011). Redundancy perceptual linguistic experience:Comparing feature-based distributional models semantic representation. TopicsCognitive Science, 3 (2), 143.Rothenhusler, K., & Schtze, H. (2009). Unsupervised classification dependencybased word spaces. Proceedings EACL GEMS Workshop, pp. 1724, Athens,Greece.Rubenstein, H., & Goodenough, J. (1965). Contextual correlates synonymy. Communications ACM, 8 (10), 627633.Sahlgren, M. (2005). introduction random indexing. http://www.sics.se/~mange/papers/RI_intro.pdf.Sahlgren, M. (2006). Word-Space Model. Dissertation, Stockholm University.Sahlgren, M. (2008). distributional hypothesis. Italian Journal Linguistics, 20 (1),3353.Schtze, H. (1997). Ambiguity Resolution Natural Language Learning. CSLI, Stanford,CA.Silberer, C., & Lapata, M. (2012). Grounded models semantic representation. Proceedings EMNLP-CoNLL, pp. 14231433, Jeju, Korea.Sivic, J., & Zisserman, A. (2003). Video Google: text retrieval approach object matching videos. Proceedings ICCV, pp. 14701477, Nice, France.Steyvers, M. (2010). Combining feature norms text data topic models. ActaPsychologica, 133 (3), 234243.Therriault, D., Yaxley, R., & Zwaan, R. (2009). role color diagnosticity objectrecognition representation. Cognitive Processing, 10 (4), 335342.Tillman, R., Datla, V., Hutchinson, S., & Louwerse, M. (2012). head toe: Embodiment statistical linguistic frequencies. Proceedings CogSci, pp.24342439, Austin, TX.Turney, P., Neuman, Y., Assaf, D., & Cohen, Y. (2011). Literal metaphorical senseidentification concrete abstract context. Proceedings EMNLP, pp.680690, Edinburgh, UK.46fiMultimodal Distributional SemanticsTurney, P., & Pantel, P. (2010). frequency meaning: Vector space models semantics. Journal Artificial Intelligence Research, 37, 141188.Van de Sande, K., Gevers, T., & Snoek, C. (2010). Evaluating color descriptors objectscene recognition. IEEE Transactions Pattern Analysis Machine Intelligence,32 (9), 15821596.Van Overschelde, J., Rawson, K., & Dunlosky, J. (2004). Category norms: updatedexpanded version Battig Montague (1969) norms. Journal MemoryLanguage, 50, 289335.Vedaldi, A., & Fulkerson, B. (2010). Vlfeat open portable library computervision algorithms. Proceedings ACM Multimedia, pp. 14691472, Firenze, Italy.Von Ahn, L. (2006). Games purpose. Computer, 29 (6), 9294.Vreeswijk, D. T., Huurnink, B., & Smeulders, A. W. (2011). Text image subjectclassifiers: dense works better. Proceedings ACM Multimedia, pp. 14491452,Scottsdale, AZ.Wang, J., Yang, J., Yu, K., Lv, F., Huang, T., & Gong, Y. (2010). Locality-constrainedlinear coding image classification. Proceedings CVPR, pp. 33603367, SanFrancisco, CA.Weeds, J. (2003). Measures Applications Lexical Distributional Similarity. Ph.D.thesis, Department Informatics, University Sussex.Wittgenstein, L. (1953). Philosophical Investigations. Blackwell, Oxford, UK. TranslatedG.E.M. Anscombe.Yang, J., Jiang, Y.-G., Hauptmann, A., & Ngo, C.-W. (2007). Evaluating bag-of-visualwords representations scene classification. Wang, J. Z., Boujemaa, N., Bimbo,A. D., & Li, J. (Eds.), Multimedia Information Retrieval, pp. 197206. ACM.Zhao, Y., & Karypis, G. (2003). Criterion functions document clustering: Experimentsanalysis. Tech. rep. 01-40, University Minnesota Department ComputerScience.47fiJournal Articial Intelligence Research 49 (2014) 669-703Submitted 11/13; published 4/14Improved Separations Regular Resolution ClauseLearning Proof SystemsMaria Luisa Bonetbonet@lsi.upc.eduLenguajes Sistemas Informaticos,Universidad Politecnica de Cataluna,Barcelona, SpainSam Busssbuss@math.ucsd.eduDepartment Mathematics,University California, San Diego,La Jolla, CA 92093-0112, USAJan Johannsenjan.johannsen@ifi.lmu.deInstitut fur Informatik,Ludwig-Maximilians Universitat Munchen,D-80538 Munchen, GermanyAbstractpaper studies relationship resolution conict driven clause learning (CDCL) without restarts, refutes conjectured possible separations. proveguarded, xor-ied pebbling tautology clauses, Urquhart proved hardregular resolution, well guarded graph tautology clauses Alekhnovich, Johannsen, Pitassi, Urquhart polynomial size pool resolution refutations useinput lemmas learned clauses. latter set clauses, extend proveCDCL search without restarts refute clauses polynomial time, providedmakes right choices decision literals clause learning. holds evenCDCL search required greedily process conicts arising unit propagation.refutes conjecture guarded graph tautology clauses guarded xor-iedpebbling tautology clauses used separate CDCL without restarts generalresolution. Together subsequent results Buss Kolodziejczyk, means lackgood conjectures establish exact logical strength conict-drivenclause learning without restarts.1. Introductionproblem SAT deciding satisability propositional CNF formulas great theoretical practical interest. Even though SAT NP-complete, industrial instanceshundreds thousands variables routinely solved state-of-the-art SAT solvers.solvers use conict-driven clause learning (CDCL) based work MarquesSilva Sakallah (1999). CDCL solvers use DPLL (Davis-Putnam-LogemannLoveland) search procedure clause learning, extended additional techniquesfast backtracking, restarts, variable selection heuristics.c2014AI Access Foundation. rights reserved.fiBonet, Buss, & JohannsenWithout clause learning, DPLL procedure equivalent tree-like resolution.addition clause learning,1 CDCL becomes considerably powerful. fact, CDCLtogether unlimited restarts capable polynomially simulating general resolutionproofs (Pipatsrisawat & Darwiche, 2011). Without restarts, CDCL known polynomiallysimulate regular resolution (Buss, Homann, & Johannsen, 2008). Furthermore, generalresolution known strictly stronger regular resolution (Alekhnovich, Johannsen,Pitassi, & Urquhart, 2007). However, exact power CDCL without restarts unknown.question interesting CDCL without restarts core search methodSAT aolvers, also better understanding power CDCL maylead better understanding practical performance SAT solvers.Alekhnovich et al. (2007) Urquhart (2011) gave three examples unsatisable setsclauses require exponentially longer regular resolution refutations (general)resolution refutations. view fact CDCL without restarts lies regular resolution resolution, three examples conjecturally good candidatesshowing CDCL without restarts cannot polynomially simulate general resolution.present paper refutes conjectures two examples; namely, proveCDCL without restarts give polynomial size refutations guarded graph tautologies clauses Alekhnovich et al. guarded xor-ied pebbling tautologies clausesUrquhart, provided CDCL search makes optimal choices decision literalslearning clauses forgetting learned clauses. former tautology, showCDCL search required greedy never ignore contradictionsfound unit propagation. follows two tautologies give superpolynomial separation resolution refutations CDCL refutations without restarts.Buss Kolodziejczyk (2012) subsequently proved similar result Stone tautologies, Alekhnovich et al. proved give exponential separation regular resolutionresolution. Thus, presently conjectured examples tautologies wouldprovide exponential separation power CDCL without restartspower resolution. hand, looks dicult prove CDCL withoutrestarts polynomially simulate resolution. consequently lack good conjecturescharacterize exact strength CDCL without restarts.Beame, Kautz, Sabharwal (2004) gave rst theoretical analysis CDCL. Amongthings, noted CDCL restarts simulates general resolution. construction, however, rather unnatural requires CDCL algorithm ignorecontradictions. situation rectied Pipatsrisawat Darwiche (2011),showed CDCL solvers restarts use unit propagation never ignore contradictions also simulate resolution. proof based technique absorptionrst dened Atserias, Fichte, Thurley (2011).Beame et al. (2004) also studied CDCL without restarts. Using proof trace extensions,showed CDCL without restarts strictly stronger natural proofsystem strictly weaker resolution. natural proof system one proofsincrease length superpolynomially variables restricted constants; natural1. paper, use CDCL synonym DPLL clause learning. discuss whetherCDCL without restarts polynomially simulate resolution, mean whether simulation possiblecorrect choices decision literals learned clauses.670fiSeparations Regular Resolutionproof systems include systems tree-like regular resolution. proof tracemethod changes formulas introducing extraneous variables clauses,eect giving CDCL freedom choosing decision variables branching.Buss et al. (2008) Hertel, Bacchus, Pitassi, Van Gelder (2008) gave improvedversions proof trace extension method extraneous variables dependset clauses refuted resolution refutation clauses.drawback remains, however, proof trace extension method gives contrived setsclauses contrived resolution refutations, consequently give much insightpower CDCL.two approaches formalizing CDCL without restarts static proofsystem rather proof search algorithm. rst pool resolution degenerateresolution inference, due Van Gelder (2005) studied Hertel et al. (2008).Pool resolution requires proofs depth-rst regular traversal similarly searchspace DPLL algorithm. Degenerate resolution allows resolution inferences onehypotheses may lacking occurrences resolution literal. (Detaileddenitions given Section 2.) Van Gelder argued pool resolution degenerateresolution inferences simulates wide range CDCL algorithms without restarts.also gave proof, using techniques Alekhnovich et al. (2007), pool resolutiondegenerate inferences stronger regular resolution, using extraneous variables similarproof trace extensions.second approach due Buss et al. (2008) introduced dierent degenerate resolution rule called w-resolution, proof system, called regWRTI, basedw-resolution clause learning input lemmas. proved regWRTI exactlycaptures non-greedy CDCL without restarts. discussed below, non-greedy meanscontradictions may need ignored CDCL search.remains open whether CDCL without restarts, pool resolution (with withoutdegenerate inferences), regWRTI proof system polynomially simulate general resolution. One approach answering questions try separate pool resolutionregWRTI general resolution. However, best so-far obtained separations resolution apply weaker system regular resolution, based work Alekhnovichet al. (2007) Urquhart (2011) giving exponential separations regular resolutiongeneral resolution. Alekhnovich et al. proved exponential separation regularresolution resolution two families tautologies, variants graph tautologyclauses GT Stone pebbling tautology clauses. Urquhart subsequently gaverelated separation using dierent set pebbling tautology clauses denoted denoted .2 present paper calls GT clauses guarded graph tautology clauses,denotes GGT instead GT ; denition given Section 4. Section 3 denesguarded xor-ified pebbling tautology clauses GPebk (G), essentiallyclauses .obvious question whether pool resolution regWRTI polynomial size refutations GGT, GPebk , Stone clauses. present paper resolves rst twoquestions showing pool resolution regRTI indeed polynomial size2. Huang Yu (1987) also gave separation regular resolution general resolution,single set clauses. Goerdt (1993) gave quasipolynomial separation regular resolution generalresolution.671fiBonet, Buss, & Johannsenrefutations GGT GPebk clauses. refutations avoid use extraneousvariables style proof trace extensions; furthermore, use traditionalresolution rule require degenerate resolution inferences w-resolution inferences.addition, use learning input clauses; thus, refutations also regWRTIrefutations (and fact regRTI refutations) terminology Buss et al. (2008).corollary characterization regWRTI Buss et al., GGT GPebkpolynomial size refutations found CDCL without restarts.Stone clauses recently shown also regRTI refutations BussKolodziejczyk (2012); although use rather dierent method present paper.Thus, none three principles separate CDCL without restarts general resolution.natural speculate perhaps pool resolution, regWRTI, CDCL without restartssimulate general resolution. However, hard optimistic simulationsexist, unable extend methods Buss Kolodziejczykgive polynomial simulation general resolution CDCL without restarts.results proved giving regRTI refutations invoking result Busset al. (2008, Thm. 5.6) states regWRTI refutation size n set clausestranslated CDCL refutation use restarts runtime polynomially bounded n. mentioned theorem Buss et al. applies CDCL algorithmslearn clauses using framework Marques-Silva Sakallah (1999) (see alsoBeame et al., 2004), make important assumptions. rst assumptionCDCL algorithm makes optimal choices decision literals learned clauses;second assumption CDCL algorithm may non-greedy.Informally, fact CDCL search must make optimal choices decision literalslearned clauses means Buss et al. (2008) prove equivalence regWRTInondeterministic CDCL search without restarts. assumption nondeterminismprobably unavoidable light conditional non-automatizability resolution provedAlekhnovich Razborov (2001). However, reasonable assumptioncharacterizing CDCL search terms formal proof system. Furthermore, lower boundssizes regWRTI refutations imply lower bounds runtimes CDCLwithout restarts.CDCL search called non-greedy allowed ignore contradictions continuing assign decision literals. Implemented CDCL algorithms always greedy;namely, learn conicts backtrack whenever possible; probably rareevent non-greedy CDCL algorithms would consistently outperform greedy algorithms,least practical applications. (However, open question.) upper boundsCDCL without restarts obtained via upper bounds regWRTI refutations potentiallygive non-greedy CDCL searches. guarded graph tautologies, however, provemore, namely greedy unit propagating CDCL without restarts give polynomialsize refutations guarded graph tautology clauses provided makes optimal choicesdecision literals learning forgetting clauses.conjecture guarded xor-ied pebbling tautologies GPebk also refuted polynomial size greedy unit propagating CDCL without restarts. Preliminaryinvestigations reveal obstacle; however, technical details quite involved, duelength present paper, carried complete construction.tautology seems require separate proof. Indeed, open whether greedy unit672fiSeparations Regular Resolutionpropagating CDCL without restarts simulate arbitrary regRTI proofs, even arbitrary(dag-like) regular resolution refutations.outline paper follows. Section 2 denes resolution, degenerate resolution, w-resolution, regular, tree, pool resolution. concludesdenition greedy unit propagating. Section 3 denes GPeb tautologies, including xor-ication guarded initial clauses. proves existence polynomialsize pool resolution regRTI refutations guarded xor-ied GPebk clauses.rst idea proof try follow regular refutations unguarded Pebkclauses. refutations cannot used directly however, since initial clausesPebk guarded GPebk clauses yields refutations violateregularity/pool property. So, second idea proof search branches neededlearn initial unguarded Pebk clauses. generates additional clauses mustproved, tricky part sure exactly right set additional clausesgenerated.Section 4 turns graph tautology clauses GTn guarded versions, GGTn .rst denes clauses states main theorems polynomial size refutationsGGTn clauses pool resolution regRTI. Section 4.1 denes notion bipartitepartial order, discusses regular refutations graph tautology clauses GTngiven Stalmarck (1996) Bonet Galesi (2001). Section 4.2 constructspool/regRTI refutations GGTn clauses. intuition construction similarconstructions pebbling tautologies, technical details muchinvolved. Section 5 concludes explicit description polynomial time greedyunit propagating CDCL search without restarts refutes GGTn clauses.paper reworking expansion extended abstract (Bonet & Buss,2012a) unpublished preprint (Bonet & Buss, 2012b) rst two authors.earlier versions included results GGT tautologies considerGPeb principles.2. PreliminariesPropositional formulas dened set variables connectives , .use notation x express negation x x. literal either variable xnegated variable x. clause C set literals, interpreted disjunctionmembers. empty clause, 2, truth value False. shall use formulasconjunctive normal form, CNF; namely, formula set (conjunction) clauses.often use disjunction (), union (), comma (,) interchangeably.Definition 1. three forms resolution dened take two clauses B calledpremises literal x called resolution variable, produce new clause C calledresolvent.BC/ x/ B. dierent forms resolution are:cases, required xResolution rule. hypotheses forms := x B := B x.resolvent C B .673fiBonet, Buss, & JohannsenDegenerate resolution rule. (Van Gelder, 2005; Hertel et al., 2008) x x B,apply resolution rule obtain C. contains x, B doesnt contain x,resolvent C B. doesnt contain x, B contains x, resolvent CA. neither B contains literal x x, C lesser Baccording tiebreaking ordering clauses.w-resolution rule. (Buss et al., 2008) B above, infer clause C :=/ (resp., x/ B), called phantom(A \ {x}) (B \ {x}). literal xliteral (resp., B).Degenerate w-resolution combine weakening resolution. course, wellknown adding weakening resolution increase refutational strengthresolution; however, point allowing degenerate w-resolution derivationmay learn clauses parts derivation would otherwisepruned away weakening allowed. reason, degenerate w-resolutionactually correspond better DPLL search resolution does.Definition 2. resolution derivation, proof, clause C CNF formula Fsequence clauses C1 , . . . , Cs C = Cs clausesequence either clause F resolution resolvent two previous clauses.derived clause, Cs , empty clause, called resolution refutation F .general concepts degenerate w-resolution derivations refutationsdened similarly. size proof number clauses proof.use terms proof derivation interchangeably. derivation representeddirected acyclic graph (dag) vertices C1 , . . . , Cs , clause Fout-degree 0, vertices C1 , . . . , Cs edges pointing twoclauses derived. empty clause in-degree 0.Resolution sound complete refutational sense: CNF formula Frefutation F unsatisable. Furthermore, derivation clause CF , C consequence F ; is, every truth assignment , satisesF satises C. Conversely, C consequence F derivationC C F .resolution refutation regular provided that, along path directed acyclicgraph, variable resolved once. resolution derivation clause Cregular provided that, addition, variable appearing C used resolutionvariable derivation. refutation tree-like underlying graph tree,occurrence clause refutation used premise inference.next dene version pool resolution, using conventions Buss et al. (2008)called tree-like regular resolution lemmas regRTL. ideaclauses obtained previously proof used freely learned lemmas. abletalk clauses previously obtained, need dene ordering clauses.Definition 3. Given tree , post-order ordering <T nodes dened follows:u node , v node subtree rooted left child u, w nodesubtree rooted right child u, v <T w <T u.674fiSeparations Regular ResolutionDefinition 4. pool resolution proof (also called regRTL proof) set initialclauses F resolution proof tree fullls following conditions: (a) leaflabeled either clause F clause (called lemma) appears earliertree <T ordering; (b) internal node labeled clause literal,clause obtained resolution clauses labeling nodes children resolvinggiven literal; (c) proof tree regular; (d) root labeled conclusionclause. labeling root empty clause 2, pool resolution proof poolrefutation.notions degenerate pool resolution proof pool w-resolution proof dened similarly, allowing degenerate resolution w-resolution inferences, respectively.Van Gelder (2005) Hertel et al. (2008) dened pool resolution degeneratepool resolution system, notion pool resolution restrictive theirs.denition equivalent one Buss (2009), however. also equivalentsystem regRTL dened Buss et al. (2008). Pool w-resolution systemregWRTL Buss et al. open whether systems pool resolution, degeneratepool resolution, pool w-resolution distinct. present paper give examplessuperpolynomial separations three systems regular resolution.lemma clause (a) denition called input lemma derivedinput subderivation, namely subderivation inference least onehypothesis member F lemma. Input resolutiontrivial resolution Beame et al. (2004), used characterize clauseslearned conicts found unit propagation (see also Chang, 1970). use inputsubderivations learning clauses pool resolution proofs due Buss et al. (2008).terminology, pool resolution proof uses input lemmas called regRTIproof. Likewise regWRTL proof uses input lemmas called regWRTI proof.understand nomenclature; reg stands regular, W w-resolution, RTresolution tree, L lemma, input lemma.Based denition Van Gelder (2005), C pool dened pool falsiedliterals clause C. denition pool includes phantom literals usedw-resolution inferences:Definition 5. Let R tree-like, regular refutation lemmas using degenerate resolution, w-resolution, resolution. Let C clause R. Then, clause C pool denedequalC pool := {x : literal x occurs, either explicitly phantom literal,clause R lies branchroot node R including C},Note C C pool , regularity R ensures C pool contains contradictoryliterals.3. Guarded, Xor-ified, Pebbling Principlessection gives polynomial size regRTI refutations guarded pebbling tautologyclauses Urquhart (2011) proved require exponential size regular resolution proofs.675fiBonet, Buss, & JohannsenDefinition 6. pointed dag G = (V, E) directed acyclic graph single sinkevery vertex G indegree either 0 2. pebbling tautology clausesPeb(G) pointed dag G following unsatisable set clauses variables xvv V :() xs , every source V ,() xu xv xw , every vertex w two (immediate) predecessors u v,() xt , sink vertex.clauses Peb(G) Horn clauses hence short tree-like resolution refutation linear size. However, clauses made dicult refute using orication xor-ication (see Ben-Sasson, Impagliazzo, & Wigderson, 2004; Ben-Sasson,2009, Urquhart, 2011). dene Urquharts (2011) xor-ication pebblingtautology clause. Xor-ication, two variables, due Alekhnovich Razborovdiscussed Ben-Sasson (2009), similar or-ication used Ben-Sassonet al. (2004) replaces variable disjunction two variables. intuitionxor-ication variable xu replaced set clauses expressesexclusive xu,1 xu,k k new variables.Definition 7. Let k > 0, xu variable Peb(G). Let xu,1 , . . . , xu,k newkvariables, let x1u,j xu,j , x1u,j complement xu,j . Dene xu setclauses form12kxiu,2xiu,k(1)xiu,1even number values ij equal 1 (and rest equal 1). Dually, dene xkuset clauses form (1) odd number ij equal 1. Notek2k1 clauses xku xu . C clause C = z1 z , ziliteral xu xu , C k set clauses formC1 C2 C ,Ci zik . 2(k1) many clauses C k .Definition 8. xor-ified pebbling tautology clauses Pebk (G) set clauses C kC Peb(G). G n vertices, Pebk (G) O(23k n) clauses.Definition 9. Let G pointed graph n vertices k = k(n) > 0. Letfunction domain set clauses Pebk (G) range set variables xu,iPebk (G), that, C, variable (C) used C. guarded xor-ifiedpebbling tautology clauses, GPebk (G), clauses formC (C)C (C)C Pebk (G).GPebk (G) clauses depend choice ; however, suppressednotation. GPebk (G) consists O(23k n) clauses.denitions Pebk (G) GPebk (G) dier somewhat Urquharts,dierences inessential make dierence asymptotic proof sizes.676fiSeparations Regular Resolutioncourse, Pebk (G) clauses readily derivable GPebk (G) clausesresolving guard literals given . simple polynomial size regularresolution refutations Pebk (G) clauses; hence polynomial size,regular, resolution refutations GPebk (G) clauses. Indeed, Urquhart (2011) provedpointed graphs G n vertices values k = k(n) = O(log log n),functions , regular resolution refutations GPebk (G) clauses require size22(n/((log n) log log n)) .Theorem 10. guarded xor-ified pebbling tautology clauses GPebk (G) polynomialsize regRTI refutations, thus polynomial size pool refutations.make simple observations working xor-ied clauses provingTheorem 10.Lemma 11. Let u vertex G. tree-like regular refutation clauseskkkxku xu 2 1 resolution inferences, height k, 2 leaf clauses. resolutionvariables variables xu,i .Proof. immediate inspection: refutation consists resolving literals xu,i successively = 1, 2, . . . , k, giving refutation height k. refutationcorresponds complete binary decision tree k many variables xu,i ; leafkclauses refutation members xku xu .refutation Lemma 11 viewed k-translation proofxuxunext lemma describes similar k-translation proofC, xuD, xuC,Lemma 12. Let u vertex G, let C clauses containeither xu xu . clause (C D)k tree-like regular derivationclauses (C xu )k (D xu )k variables used resolution variablesexactly variables xu,i . derivation 2k 1 resolution inferences, height k,2k leaf clauses.Proof. Fix clause E (C D)k ; must describe derivation clauses(C xu )k (D xu )k . Let EC subclause E C k , letED subclause E k . C non-empty intersection, ECED disjoint; however, event, E = EC ED .Form refutation Lemma 11. add EC every leaf clause xu , addkED every leaf clause xu , add E every non-leaf clause. gives desiredderivation E.Lemma 12 lets us generalize construction k-translations proofs.typical example, next lemma gives k-translation following derivation:677fiBonet, Buss, & Johannsenxu , x v , xwxv , xwxuxwxvLemma 13. Let w vertex G, u v predecessors. Then, clausekkxkw dag-like regular resolution derivation P clauses xu , xv ,k2k(xu xv xw ) . derivation contains < 2 resolution inferences resolvesresolveliterals xu,i xv,i . addition, paths P lead clauses xkvexactly literals xv,i .Lemma 13 follows applying Lemma 12 twice.important note left-to-right order leaves derivationLemma 13 altered changing left-to-right order hypotheses resolutioninferences. particular, given leaf clause refutation P , orderhypotheses resolution inferences leftmost leaf clause.useful needs learned.Definition 14. Gw induced pointed subgraph G sink w containingvertices vertex w reachable. G[w] subgraph G obtainedmaking vertex w leaf removing incoming edges, removingvertices sink vertex G longer reachable. Note G[w] pointeddag sink G.vertex u ancestor w u = w u Gw, i.e., pathu w. call u v independent ancestors w provided u, v, w distinctu (Gw)[v] v (Gw)[u]. means path u wcontain v, path v w contain u. write G[u, v]G[u][v] = G[v][u].generally, let 0 u1 , . . . , u , w distinct vertices. say u1 , . . . , uindependent ancestors w, every , path ui wcontain uj j = i. write G[u1 , . . . , u ] G[u1 ] [u ]. Note denitionG[u1 , . . . , u ] independent order ui s.Since G dag, possible u v independent ancestors w, alsou ancestor v vice-versa.next lemma states polynomial size regular resolution refutationsPebk (G) clauses also apply subgraphs Gw (Gw)[u1 , . . . , u ]. writePebk(G) denote k-translations Peb(G) clauses type () (), omittinguclauses type (), similarly GPebk(G). save space, often writeinstead u1 , . . . , u . instance, next lemma, ((Gw)[u]) \ {u, w} shorthand((Gw)[u1 , . . . , u ]) \ {u1 , . . . , u , w}.Lemma 15. Let w vertex G. Let 0 u1 , . . . u independent ancestors w.clause (xu1 xu xw )k regular resolution derivationu]). derivation uses resolution variables form xv,iclauses Pebk((Gw)[v ((Gw)[u]) \ {u, w}. derivation dag-like size O(23k n) height O(kn).Proof. simple regular dag-like derivation P xu1 xu xw clauses() () (non-xoried) Peb(G), size O(n) n size G. P proceeds678fiSeparations Regular Resolutionvisiting vertices v depth-rst traversal (Gw)[u] deriving subclause Cvxu1 xu xv : subclause Cv contains xv xui pathui v contains uj . v leaf distinct uj s, Cv xvalso Peb(G) clause type (). v immediate predecessors v1 v2 , Cvformed resolving Cv1 Cv2 Peb(G) clause xv1 xv2 xv type ().let U clause (xu1 xu )k W clause xkw . needgive derivation U W . claim k-translation P k P forms desiredderivation. this, clause Cv P translated 2k1 many clauses CXX xkv . CX subclause U X; namely subclause omits literalsxui,j xui,j U xui/ Cv . v1 v2 two immediate ancestors vkbefore, X xv , clause CX derived P k 22k2 many clauses CX1CX2 Xi (xvi )k = 1, 2. Lemma 13, subderivation P kheight 2k size 22k , resolves exactly variables xv1 ,j xv2 ,j .result variable xv,j resolved P k precisely xv resolvedP . And, since P size O(n), P k size O(23k n) height O(kn).Proof. (of Theorem 10.) construct series LR partial refutations, denotedR0 , R1 , R2 , . . .; process eventually terminates pool resolution (regRTL) refutation GPebk (G). terminology LR partial indicates refutationconstructed left-to-right order, left part refutation properly formed,many remaining leaves labeled unnished clauses instead validlearned clauses initial clauses GPebk (G).LR partial refutation R tree nodes labeled clauses form correctregRTI resolution refutation (and thus correct pool resolution refutation), exceptunnished clauses leaves. Furthermore, must satisfy following conditions:a. Rt tree nodes labeled clauses. root labeled empty clause.non-leaf node Rt left child right child, clauses labelingnodes form valid resolution inference.b. leaf Rt either nished unnished. nished node leaf L labeledeither clause GPebk (G) clause derived inputsubderivation Rt left L post-order. input subderivation maycontain unnished leaves.c. unnished leaf labeled clause C E k E clause formxu1 xu xw 0 u1 , . . . , u independent ancestors w. FurthermoreC pool contains literal xv,i v (Gw)[u] \ {u, w}.introduce new notational convention describe (sub)clauses Rt . w vertexkG, notation W W denotes clause xkw , W W denotes clause xw .notation W W way denotes negation W W ; instead, namesclauses, overline meant serve reminder semantic meaning.initial LR-partial refutation R0 formed follows. Let Q refutationobtained k-translation inferencext679xtfiBonet, Buss, & Johannsengiven Lemma 11, sink G. 2k leaf clauses Q: halfklabeled clauses xkhalf labeled clauses xt .derivationForm R0 Q replacing leaf clause xk, (T ), (T )resolving guard literal (T ). inferences regular, since (T ) xt,i .clauses , (T ) , (T ) GPebk (G) hence nished clauses.k= 0;leaf clauses, form xk, satisfy condition c. = C xtunnished clauses R0 .inductive step 0, LR partial refutation Rt transformed Rt+1 .goal replace one unnished leaf Rt , either derivation containingnished leaves, derivation learns one Pebk (G) clause addingpolynomially many unnished leaves.Consider leftmost unnished leaf Rt . condition c., clause Ckform U 1 , . . . , U , W 0, U xkui , W xw . Lemma 15,kdag-like regular refutation P C clauses Peb ((Gw)[u]). wishu])convert P (if possible) derivation C clauses GPebk((Gw)[already learned clauses Rt . Consider particular leaf clause P ,u]): needs handled way makes P validPebk((Gw)[derivation. four cases consider:(i) clause already learned input lemma Rt left C, mayused P is.remaining cases, assume learned input lemma.(ii) Let = (D). either member C pool , add literalevery clause reaching rst clause appears. replacesu]) clauses Dy Dy. construction, preservesone GPebk((Gw)[validity resolution inferences Rt well regularity property.(iii) Suppose cases (i) (ii) apply used P resolutionvariable D. case, replace resolution inference derivingy. preserves regularity derivation. also makeslearned clause.possible C Pebk(G) clause. so, C = P trivialderivation containing C, one cases (i)-(iii) holds.leaf clauses P treated cases (i)-(iii), successfullytransformed P (still dag-like) derivation P satises regularityleaf clauses GPebk (G) already learned input lemmas Rt . resultBuss et al. (2008, Thm. 3.3), P converted regRTI proof P conclusionP , preserving regularity conditions, size P bounded twiceproduct size P height P . Therefore, size P O((23k n)(kn)) =680fiSeparations Regular ResolutionO(k23k n2 ). Form Rt+1 replacing clause C Rt derivation P . Rt+1 satisesconditions a.-c., one fewer unnished clauses Rt .However, even one leaf clause P fails cases (i)-(iii), completely dierentconstruction used form Rt+1 . Fix leaf clause P fall cases(i)-(iii). unnished clause C Rt replaced small derivation Clearns (in leftmost inference), adds O(23k ) new unnished clausesRt+1 .leaf clause k-translation () () clause Pebk (G) thuskeither form E xe source e G form A, B, E xa ,kB xkb , E xe a, b, e vertices Gw b two predecessorse G. Without loss generality, b ancestor G; otherwise interchangeb. two cases depending whether E A, B, E.e source node G. claim e, u1 , . . . , uFirst suppose E xkeindependent ancestors w. already remarked, P trivial derivation sinceotherwise cases (i)-(iii) would hold; therefore e equal w. Consequently, Esubclause nal clause C = U 1 , . . . U , W P . Hence xe,i resolved P .Since P formed using Lemma 15, e therefore cannot equal ui . Since e (Gw)[u],must exist path e w avoids nodes ui . Thus, since e sourcenode, vertices e, u1 , . . . , u independent ancestors w.form Rt+1 , rst replace derivation P k-translation following:xexe , U 1 , . . . , U , WU 1, . . . , U , W(2)Note (2) contains blend variables Peb(G) (non-xoried) Pebk (G)(xor-ied). However, still form k-translation Q: leaf clauses Qk2k clauses form E xke form E , U 1 , . . . , U , W E xe . choosingappropriate left-to-right order hypotheses Q, arrange = Eleftmost leaf clause Q. Let = (D). one variables xe,i ,C pool since condition (ii) hold D. Therefore, regularity conditionpreserved modify Q replacingD, (D)D, (D)(3)Form Rt+1 Rt replacing C modied Q. causes become learnedinput lemma Rt+1 . leaf clauses Q satisfy condition c. Rt+1thus become unnished clauses Rt+1 : right D. adds < 2knew unnished clauses Rt+1 . number inferences derivation structure less2k .Second suppose A, B, E, b predecessors e G. Supposemoment e = w, nodes u1 , . . . , u distinct b.reasoning previous case, e equal ui . begin replacing681fiBonet, Buss, & Johannsenderivation P k-translation Q of:xa , xb , xeU , xaU , xb , xeU b , xbU , U b , xeUw , x e , WU 1, . . . , U , W(4)Ua , Ub Uw (possibly empty) sets literals form partition set{U 1 , . . . , U }. must dene Ua , Ub , Uw (the k-translation of) clauseUa , xa , clause Ub , xb clause Uw , xe , W fulll condition c. orderlegitimate unnished leaves.Since u1 , . . . , u independent ancestors w, x paths 1 , . . . , Gpath ui w contain uj j = i. Calla-path contains node a. Call b-path contains b contain a.Finally, call w-path contains neither b. Then, dene Ua setUi a-path. Likewise, let Ub (respectively, Uw ) set Uib-path (respectively w-path). Clearly, Ua , Ub Uw form partition{U1 , . . . , U }. Also, ui Ui Ua form set independent ancestors a, Ua , xasatises condition c. Likewise, clauses Ub , xb Uw , xe , W also satisfy condition c.prove latter, note path ui w contains e must contain least oneb.k-translation Q (4) leftmost leaf clause. Let = (D).one variables xa,i , xb,i , xe,i , C pool since condition (ii)hold D. Therefore, regularity condition preserved modify Q replacing(3). Form Rt+1 Rt replacing C modied Q. causesbecome learned input lemma Rt+1 . previously argued, leaf clausesQ become valid unnished clauses satisfy condition c. Rt+1 gains < 23k newinferences, less 3 2k new unnished clauses.still consider cases u1 , . . . , u , b distinct.2 (very similar) cases one ui {a, b}. instance, supposeu1 = ui equal b. claim clause U1 . provethis, note dierent U1 , literal xu1 ,j xu1 ,j appearingappears negated form xu1 ,j xu1 ,j (respectively) U1 . impliesderivation P uses xu1 ,j resolution variable, contradicting fact P formedvia Lemma 15. = U1 , form Q k-translationU 1 , xb , xeU b , xbU b , U 1 , xeU w , xe , WU 1, . . . , U , WUb Uw dened (and Ua equals {U1 }). Order Qleftmost leaf clause, form Rt+1 previous paragraph.case i, j = j, ui = uj = b, proofstructure even simpler: Suppose u1 = u2 = b. Similarly previous case,B must U1 U2 , respectively. let Q k-translationU 1 , U 2 , xexe , U 3 , . . . , U , WU 1, . . . , U , W682fiSeparations Regular Resolution(so Uw = {U3 , . . . , U }) proceed before.Finally, consider case w = e. Clearly, Ui ancestor either b.Therefore, Ui Ua Ub . refutation Rt+1 formed proof structure(4), omitting last inference.concludes construction Rt+1 Rt . process constructing Rt haltsremaining unnished clauses, yields nal refutation Rvalid regRTI refutation GPebk (G) clauses.need bound size refutation R. First consider Rt+1 formedRt . cases (i)-(iii), unnished leaf completely handled without addingnew unnished leaves. cases, O(k23k n2 ) many new clauses introducedRt+1 . case (iv), new Pebk (G) clause learned input lemma addingO(3 2k ) many new unnished leaves Rt+1 (and O(23k ) new clauses).Even though exponentially many potential unnished clauses, case (iv) construction occur polynomially many times polynomiallymany Pebk (G) clauses learned. Indeed, < n23(k1) many Pebk (G)clauses. Therefore, O(n23(k1) 3 2k ) many distinct unnished leaf clauses appear construction R. Consequently, cases (i)-(iii) occur many times.Therefore, total number clauses R bounded O(n23(k1) 3 2k k23k n2 ) =O(27k n3 ). Thus size R polynomially bounded size GPebk (G) clauses;fact, bounded degree three polynomial.completes proof Theorem 10.4. Guarded Graph Tautologiesdene various graph tautologies, sometimes also called ordering principles.use size parameter n > 1, variables xi,j i, j [n] = j, [n] ={0, 1, 2, . . . , n1}. variable xi,j intuitively represent condition jintended total, linear order. thus always adopt simplifying conventionxi,j xj,i identical literal, i.e., variables xi,j < j actually exist,xj,i j < notation xi,j , xj,i stands xi,j . identicationmakes essential dierence complexity proofs tautologies, reducesnumber literals clauses, simplies denitions. particular, meansaxioms antisymmetry totality .following GTn clauses based tautologies dened Krishnamurthy(1985). tautologies, similar ones, also studied Stalmarck (1996),Bonet Galesi (2001), Segerlind, Buss, Impagliazzo (2004), Beckmann Buss(2005), Van Gelder (2006), Alekhnovich et al. (2007) Johannsen (2009).Definition 16. Let n > 1. GTn following set clauses:( ) clauses j=i xj,i , value < n.( ) transitivity clauses Ti,j,k := xi,j xj,k xk,i distinct i, j, k [n].Note clauses Ti,j,k , Tj,k,i Tk,i,j identical. reason Van Gelder(2005) uses name triangles (NT) similar principle.next denition due Alekhnovich et al. (2007), used notation GTn .used particular functions r lower bound proof, since upper683fiBonet, Buss, & Johannsenbound proof depend details r leave unspecied.require r(i, j, k) = s(i, j, k) set {r(i, j, k), s(i, j, k)} {i, j, k}. addition,w.l.o.g., r(i, j, k) = r(j, k, i) = r(k, i, j), similarly s.Definition 17. Let n 1, let r(i, j, k) s(i, j, k) functions mapping [n]3 [n]above. guarded graph tautology clauses, GGTn , consist of:( ) clauses j=i xj,i , value < n.( ) guarded transitivity clauses Ti,j,k xr,s Ti,j,k xr,s , distinct i, j, k[n], r = r(i, j, k) = s(i, j, k).Note GGTn clauses depend functions r s; suppressednotation. rst main result guarded graph tautologies is:Theorem 18. guarded graph tautology clauses GGTn polynomial size pool resolution (regRTL) refutations.proof Theorem 18 construct pool refutations form regular tree-likerefutations lemmas. key part learning transitive closure clausesderived using resolution guarded transitivity clauses GGTn . slightly modiedconstruction, uses result Buss et al. (2008), gives instead tree-like regular resolutionrefutations input lemmas. establish following:Theorem 19. guarded graph tautology clauses GGTn polynomial size, tree-likeregular resolution refutations input lemmas (regRTI refutations).discussed introduction, Theorem 19 result Buss et al. (2008) togetherimply GGTn clauses shown unsatisable non-greedy polynomial size CDCL.follows via mentioned theorem Buss et al. (2008, Thm. 5.6), since refutationsGGTn regRTI, hence regWRTI, proofs sense Buss et al.. Theorem 31Section 5 improve giving greedy CDCL refutations.Theorem 19 strictly stronger Theorem 18, nd convenient proveTheorem 18 rst.4.1 Resolution Refutations Guarded Graph Tautologiesfollowing theorem important ingredient upper bound proof.Theorem 20. (Stalmarck, 1996; Bonet & Galesi, 2001; Van Gelder, 2006) sets GTnregular resolution refutations Pn polynomial size O(n3 ).proofs Theorems 18 19 use refutation Pn black box:property needed Pn regular polynomial size. Section 5 need usedetails Pn however.Proof. (Proof sketch Theorem 20.) , k [n], dene clause Totk,xj, ,Totk, :=j[k+1]\{}684fiSeparations Regular ResolutionTot3,3Tot3,2Tot3,1Tot3,0Tot2,2Tot2,1Tot2,0Tot1,1Tot1,0Tot0,0 = 2Figure 1: Main structure regular refutation Pn GTn clauses, n = 4.Inferences resolve transitivity clauses Ti,j,k shown: slantedline Totk+1,k+1 Totk, represents k many resolution inferencesclauses T,i,k+1 [k + 1] \ {}. subderivation hypotheses Totk,kTotk, conclusion Totk1, input derivation.expresses condition predecessor j k. course, clauses Totn1, ,= 0, 1, . . . , n 1, initial clauses ( ) GTn . Note Tot0,0 emptyclause.pictured Figure 1, Pn proceeds deriving Totk, Totk+1,k+1 Totk+1,k = n2, . . . , 0 k, deriving empty clause Tot0,0 . rst partderivation Totk, resolves Totk+1,k+1 successively k many transitivity clausesT,i,k+1 [k + 1] \ {}. convention xi, x,i literal, T,i,k+1clause xi, , xi,k+1 , xk+1, . resolution T,i,k+1 uses xi,k+1 resolutionliteral eect adding xk+1, clause, replacing xi,k+1 xi, . Thus,conclusion k resolution stepsxk+1,xi, .i[k+1]\{}One nal resolution Totk+1, literal xk+1, yields Totk, desired.regularity Pn evident inspection.refutations Pn modied give refutations GGTn rst derivingtransitive clause Ti,j,k two guarded transitivity clauses ( ). howeverdestroys regularity property, already discussed, polynomial size regular refutations exist GGTn (Alekhnovich et al., 2007).usual, partial order [n] antisymmetric, transitive binary relation [n].primarily interested bipartite partial orders, partial orderschain inequalities x z.Definition 21. bipartite partial order binary relation [n] domainrange intersect. write x (x, y) . set -minimalelements denoted .righthand side Figure 2 shows example. bipartiteness arises/ .fact [n] \ partition [n] two sets. j, j685fiBonet, Buss, & Johannsen10611789:12346[n] :1210 7 8 9 113455Figure 2: Example dag (left) associated bipartite partial order (right).addition, contains isolated points . permitted emptyrelation, = [n].(bipartite) partial order [n] also viewed directed acyclic graph (dag)G = ([n], ); note [n] set vertices, set edges G. Conversely,dene mapping arbitrary dag G = ([n], ) associated bipartite partialorder :Definition 22. Let G = ([n], ) dag. write x +denote G containspath length 1 x y. bipartite partial order associated G denedletting x hold precisely x -minimal G (that is, x indegree 0)x +y.Note denition require transitive. easy checkassociated fact bipartite partial order. intuition retainsinformation whether +j minimal elements i, forgets orderingimposes non-minimal elements.dene graph tautology clauses GT,n relative follows.Definition 23. Let bipartite partial order [n]. GT,n contains:() clauses j=i xj,i , value .() transitivity clauses Ti,j,k := xi,j xj,k xk,i distinct i, j, k . (Verticesi, j, k Figure 3 show example.)() transitivity clauses Ti,j,k distinct i, j, k i, j kj k. (As shown Figure 3.)set GT,n satisable nonempty. example, assignment/ every , sets variablessets xj,i true xed jfalse. However, applied restriction, GT,n becomes unsatisable.say, assignment satises GT,n consistent . factproved regular derivation P described next lemma.Definition 24. bipartite partial order, clause ( ):= {xi,j : j}.Lemma25. Let bipartite partial order [n]. regular derivation P( ) set GT,n .variables resolved P following: variables xi,j/ , , k.i, j , variables xi,k k686fiSeparations Regular Resolution1[n] \ :2:3kjkFigure 3: bipartite partial order pictured, ordered pairs showndirected edges. (For instance, j k holds.) set set minimalvertices. nodes i, j, k shown example nodes used transitivityaxiom xi,j xj,k xk,i type (). nodes i, j, k example nodestransitivity axiom type ().Lemma 25 implies bipartite partial order associated dag ,P resolve literal whose value set . proved noting/ .j, jempty, = [n] clauses type (). case, GT,nidentical GTn , P Lemma 25 refutation GTnTheorem 20.Proof. renumbering vertices, assume w.l.o.g. = {0, . . . , m1}.k m, least one value j j k: let Jk arbitraryvalue j. Note Jk < m.Fix ; is, < m. Recall clause type () GT,nj=i xj,i . resolve clause successively, k k,clauses Ti,Jk ,k type ()xi,Jk xJk ,k xk,iusing resolution variables xk,i . (Note Jk = since k.) yields clause Totm1,i :xi,JkxJk ,kxk,ixk,i .kmkkmkkmkk<mk=irst two disjuncts shown comeside literals clauses Ti,Jk ,k ;last two disjuncts come literals j=i xj,i resolved on. Sinceliteral xi,Jk literal xJk ,i since Jk < m, literals rst disjunctalso contained fourth disjunct. Thus, eliminating duplicate literals, Totm1,i equalclausexJk ,kxk,ixk,i .(5)Si Totm1,i :=kmkkmkk<mk=iSi dened equal rst two big disjuncts lefthand side equation,Totm1,i before, namely last big disjunct righthand side.Repeating process, obtain derivations clauses Totm1,i < m.subclauses Totm1,i ( ) clauses GTm . Thus, clauses Totm1,igive ( ) clauses GTm , Si added side literals. Moreover, clausestype () GT,n exactly transitivity clauses GTm . clauses687fiBonet, Buss, & JohannsenTot3,3Tot3,2Tot3,1Tot3,0Tot3,3Tot3,2Tot3,1Tot3,0Tot2,2Tot2,1Tot2,0Tot1,1Tot1,0Tot0,0 = ( )Figure 4: Main structure regular derivation P , = 4. initial clausesGTm clauses. Inferences resolve transitivity clauses Ti,j,kshown: slanted lines top row vertical lines represent multiple resolutioninferences transitivity clauses.combined exactly refutation GTm described Theorem 20, carrying alongextra side literals Si ; namely carrying along literals xJk ,k Jk k, xi,k k.Since refutation GTm uses transitivity clauses since xJk ,k literalxi,k k, yields resolution derivation P clause{xi,k : k}.clause ( ) desired.just-constructed derivation P ( ) structure shown Figure 4:clauses Totk,i equalTotk,iSi Totk,iTotk,i=im1 m1j=i Sj Totk,ik = 1< k < 1= k(6)show P regular, note rst parts P deriving clauses Toti,mregular construction, use resolution variables xk,i < k,k. remaining part P also regular Theorem 20, uses resolutionvariables xi,j i, j m.4.2 Pool w-Resolution Refutations GGTnprove Theorem 18, indicate minor changes needed prove Theorem 19.Proof. (Theorem 18) construct nite sequence LR partial refutations,denoted R0 , R1 , R2 , . . .. terminates nitely many steps desired pool(regRTL) refutation R GGTn . LR partial refutation Rt correct pool688fiSeparations Regular Resolutionresolution refutation, except possibly presence unnished clauses leaves.Unnished clauses correspond bipartite partial orders. Rt satisfyfollowing conditions:a. R tree. root labeled empty clause. non-leaf node Rleft child right child; clause labeling node derived resolutionclauses two children.b. clause C occurring R, set ordered pairs (C) dened (C) ={i, j : xi,j C pool }. many cases, (C) dag, always true.instance, C transitivity axiom, (C) 3-cycle dag.d. Leaves either nished unnished. nished leaf L labeled eitherclause GGTn clause occurs left L post-order traversalR.e. unnished leaf labeled clause C, set (C) dag. Furthermore, lettingbipartite partial order associated (C), clause C equal ( ).Property e. particularly crucial novel construction. shown below,unnished leaf, labeled clause C = ( ), replaced derivation S.derivation often based P , thus might expected end exactlyclause C; however, resolution inferences needed P might disallowedregularity property pool resolution proofs. mean insteadderivation clause C C C C pool . condition C C pool requiredliteral x C \ C handled modifying refutation R propagatingx downward R reaching clause already contains x. Since C C pool ,clause exists. fact C C implies enough literals presentderivation use (non-degenerate) resolution inferences virtue factconstructions pick C contains literals must present useresolution literals.construction begins letting R0 empty refutation, containingempty clause. course, clause unnished leaf, () = . Thus R0 validLR partial refutation.induction step, Rt constructed already. Let C leftmost unnishedclause Rt . Rt+1 formed replacing C (LR-partial) derivationclause C C C C pool .need describe S. Let bipartite partial orderassociated (C),consider derivation P Lemma 25. Since C ( ) condition e., nalline P clause C. intuition would like let P . rstdiculty P dag-like, LR-partial refutation intendedtree-like, diculty, however, circumvented expanding P ,regular, tree-like regular derivation lemmas simple expedient usingdepth-rst traversal P . second, serious, diculty P derivationGTn , GGTn . Namely, derivation P uses transitivity clauses GTninitial clauses instead guarded transitivity clauses GGTn . transitivity clausesTi,j,k := xi,j xj,k xk,i P handled one time described below. four689fiBonet, Buss, & Johannsenseparate constructions: case (i) requires change P ; cases (ii) (iii) require smallchanges; fourth case, subproof P abandoned favor learningtransitivity clause.remark Lemma 25, literal C pool used resolution literal P .(i) Suppose transitivity clause Ti,j,k P already appears earlier Rt , is, leftC post-order. Ti,j,k already learned, used freely P .(Since building pool resolution refutation, w-resolution refutation,need Ti,j,k input lemma.)remaining cases (ii)-(iv), transitivity clause Ti,j,k yet learned. Let guardvariable Ti,j,k xr,s , r = r(i, j, k) = s(i, j, k).(ii) Suppose case (i) apply guard variable xr,s negation xr,smember C pool . guard variable thus used resolution variable somewherealong branch root clause C. Then, mentioned above, Lemma 25implies xr,s resolved P . Therefore, add literal xr,s xr,s(respectively) clause Ti,j,k every clause path Ti,j,kreaching clause already contains literal. replaces Ti,j,k oneinitial clauses Ti,j,k xr,s Ti,j,k xr,s GGTn . Note adds literal xr,sxr,s nal clause C modied P . maintains propertyC C C pool .(iii) Suppose case (i) apply xr,s used resolution variableTi,j,k P neither xr,s xr,s member C pool . case, Pmodied derive clause Ti,j,k two GGTn clauses Ti,j,k xr,sTi,j,k xr,s resolving xr,s . maintains regularity derivation.also means henceforth Ti,j,k learned.transitivity clauses P handled cases (i)-(iii), use Pdene Rt+1 . Namely, let P derivation P modied applications cases(ii) (iii). derivation P regular dag-like, recast tree-likederivation lemmas, using depth-rst traversal P . size linearsize P , since lemmas need repeated. nal line clause C ,namely C plus literals introduced case (ii). derivation Rt+1 formed Rtreplacing clause C derivation C , propagating new literalx C \ C towards root Rt , adding x clause reachingclause already contains x. derivation contains unnished leaf, Rt+1contains one fewer unnished leaves Rt .hand, even one transitivity axiom Ti,j,k P coveredthree cases, case (iv) must used instead. introduces completely dierentconstruction form S:(iv) Let Ti,j,k transitivity axiom P covered cases (i)-(iii).case, guard variable xr,s used resolution variable P somewhereTi,j,k ; general, means cannot use resolution xr,s derive Ti,j,kmaintaining desired pool property. Hence, P longer used,690fiSeparations Regular Resolutioninstead form short left-branching path learns Ti,j,k .generate two three new unnished leaf nodes. Since unnished leaf nodesLR partial derivation must labeled clauses bipartite partial orders,also necessary attach short derivations unnished leaf nodes makeunnished leaf clauses correspond correctly bipartite partial orders.unnished leaf nodes kept Rt+1 handled later stages.construction described detail next, depends whether Ti,j,k type() (). base case R0 type (), describe type () constructionrst somewhat simpler.Suppose Ti,j,k type (), thus xj,k appears C. (Refer Figure 3.) Let xr,sguard variable transitivity axiom Ti,j,k . derivation formS1 . . .. . .xi,j , xj,k , xk,i , xr,sxi,j , xj,k , xk,i , xr,s...xi,j , xj,k , xk,ixi,j , xi,k , [jk;jR(i)]xi,j , xj,k , [jk;jR(i)]xj,k , [jk]S2 . . .. . ....xj,i , xj,k , [jk;iR(j)]notation [jk] denotes disjunction negations literals omittingliteral xj,k . write iR(j) indicate literals xi, j . (The R(j) meansrange j.) Thus [jk;iR(j)] denotes clause containing negations literals, omitting xj,k literals xi, j . clause [jk;jR(i)] denedsimilarly.upper leftmost inference resolution inference variable xr,s . SinceTi,j,k covered either case (i) (ii), variable xr,s C pool . Thus,use xr,s resolution variable violate regularity. Furthermore, since Ti,j,ktype (), (C) j, j (C) i, (C) k, k (C) i. Thus literals xi,j xi,kC pool , also resolved without violating regularity.Let C1 C2 nal clauses S1 S2 , let C1 clause C1C. set (C2 ) obtained adding j, (C), similarly (C1 ) (C)plus i, j. Since Ti,j,k type (), i, j . Therefore, since (C) dag, (C2 )dags(C1 ) also dags. Let 2 1 bipartite orders associated(respectively). form subderivation S1 contains clause ( 1 )unnished clause. require adding inferences S1 add removeappropriate literals. rst step type already occurs going C1 C1since removed xj,k added xi,k , reecting fact j 1 -minimal/ 1 . Similarly, form S2 unnished clausethusxi,k 1 xj,k( 2 ).rst describe subderivation S2 . situation pictured Figure 5,shows extract Figure 3: edges shown part (a) gure correspondliterals present nal line C2 S2 . particular, recall literals xi,j omitted last line S2 . (Correspondingly, edge 1omitted Figure 5.) last line C2 S2 may correspond bipartite partialorder may partition [n] minimal non-minimal elements; thus, C2 mayqualify unnished node Rt+1 . (An example Figure 5(a)691fiBonet, Buss, & Johannsen12k13j(a) xj,k , xi,2 , xj,i ,2k3j(b) xj,k , xi,2 , xj,i ,Figure 5: partial orders fragment S2 shown (7).j (C2 ) (C2 ) 2 , corresponding xj,i xi,2 C2 .) bipartite partialorder 2 associated (C2 ) equal bipartite partial order agreesexcept condition replaced condition j 2 . (This representedFigure 5(b) fact edge 2 replaced edge/ M2 .)j 2 . Note vertex longer minimal element 2 ; is,wish form S2 regular derivation clause xj,i , [jk;iR(j)] clause( 2 ).subderivation S2 replacing xi,2 xj,2 2 follows, letting[jk;iR(j);i2] .. . .. . . rest S2S2 . . .. . .......xj,i , xi,2 , x2 ,jxj,k , xj,2 , xj,i ,xj,k , xi,2 , xj,i ,(7)part labeled rest S2 handle similarly literalsj . nal line S2 transitivity axiom Tj,i,2 . GTn axiom,GGTn axiom; however, handled methods cases (i)-(iii). Namely,Tj,i,2 already learned appearing somewhere left Rt , S2single clause. Otherwise, let guard variable Tj,i,2 xr ,s . xr ,s usedresolution variable Tj,i,2 , replace Tj,i,2 Tj,i,2 xr ,s Tj,i2 xr ,s ,propagate xr ,s xr ,s clauses branch leading Tj,i,2 reachingclause already contains literal. Finally, xr ,s used resolutionvariable Rt C, let S2 consist resolution inference deriving (and learning)Tj,i,2 clauses Tj,i,2 , xr ,s Tj,i,2 , xr ,s .complete construction S2 , inference (7) repeated value. result S2 one unnished leaf clause, labeledjclause ( 2 ).next describe subderivation S1 . situation shown Figure 6.formation S2 , nal clause C1 S1 may need modied order correspondbipartite partial order 1 associated (C1 ). First, note literalxj,k already replaced xi,k nal clause S1 . change neededthat, every j , must replace xj, xi, sincej 1 1 . Vertex 3 Figure 6 example value . orderingnal clause S1 shown part (a), desired ordered pairs 1 shownpart (b). Note j longer minimal element 1 .692fiSeparations Regular Resolution12k13j(a) xi,k , xj,3 , xi,j ,23kj(b) xi,k , xi,3 , xi,j ,Figure 6: partial orders fragment S1 shown (8).replacement xj,3 xi,3 eected following inference, letting[jk;jR(i);j3] .. . .. . . rest S1S1 . . .. . .......(8)xi,j , xj,3 , x3 ,ixi,k , xi,3 , xi,j ,xi,k , xj,3 , xi,j ,rest S1 handle similarly literals j .Note nal clause S1 transitivity axiom Ti,j,3 . subderivation S1formed exactly way S2 formed above. Namely, dependingstatus guard variable xr ,s Ti,j,3 , one following done: (i) clause Ti,j,3already learned used is, (ii) one xr ,s xr ,s added clausepropagated proof, (iii) clause Ti,j,3 inferred using resolution xr ,sbecomes learned.complete construction S1 , inference (8) repeated valuej . result S1 one unnished leaf clause,corresponds bipartite partial order 1 .completes construction subcase (iv) Ti,j,k type ().suppose Ti,j,k type (). (For instance, values i, j, k Figure 3.) case,formS3 . . .. . .Ti,j,k , xr,s Ti,j,k , xr,s...S4 . . .. . .Ti,j,kxi,j , xi,k , [jR(i),kR(ij)]...xi,j , xj,k , [jR(i),kR(ij)]xi,j , xk,j , [jR(ik)]xi,j , [jR(ik)]S5 . . .. . ....xj,i , [iR(j)]xr,s guard variable Ti,j,k . write [ [jR(ik)] ] mean negationsliterals omitting literal xj, k . Similarly,[jR(i),kR(ij)] indicates negations literals , omitting literals xj,literals xk, either j .Note resolution xr,s used derive Ti,j,k violate regularity, sinceotherwise Ti,j,k would covered case (ii). Likewise, resolutions xi,j , xi,kxj,k violate regularity since Ti,j,k type ().subderivation S5 formed exactly like S2 above, exceptionliteral xj,k present. Thus omit description S5 .next describe construction S4 . Let C4 nal clause ofS4 ; easycheck (C4 ) dag. before, must derive C4 clause ( 4 ) 4bipartite partial order associated (C4 ). typical situation shown Figure 7.693fiBonet, Buss, & Johannsen1213jk(a) xi,j , xk,j , xj,2 ,23jk(b) xi,j , xi,2 , xk,j , xk,2 ,Figure 7: partial orders changed S4 .pictured there, necessary add literals xi, j ,removing xj, ; examples equal 2 3 Figure 7. time,must add literals xk, j k , removing xj, ; examplesequal 1 and, again, 2 gure.vertex 3 j 3 k 3 3 , done similarlyinferences (7) (8) without side literal xj,k :. . .. . . rest S4S4 . . .. . .......xi,j , xj,3 , x3 ,ixi,3 , xk,j , xi,j ,xj,3 , xk,j , xi,j ,(9)[jR(ik);j3] . transitivity axiom Ti,j,3 shown last line S4 handledexactly before. construction repeated 3 s.vertices 1 j 1 1 k 1 handled exactlyway. (The side literals change time reect literals alreadyreplaced.)Finally, consider vertex 2 2 j 2 k 2 . handledderivationS4 . . .. . ....xi,j , xj,2 , x2 ,i. . .. . . rest S4S4 . . .. . .......xk,j , xj,2 , x2 ,kxi,j , xi,2 , xk,j , xk,2 ,xi,j , xi,2 , xk,j , xj,2 ,xi,j , xk,j , xj,2 ,before, set side literals changed reect literals alreadyadded removed S4 created. subderivations S4 S4transitivity axioms Ti,j,2 Tk,j,2 handled exactly before, depending statusguard variables.Finally, describe form S3 . this, must form bipartite partial order 3associated (C3 ), C3 nal clause S3 . obtain 3 , needadd literals xi, either j k ,removing literals xj, xk, . done exactly construction used(9). literals [jR(i);kR(ij)] exactly literals needed carryout. construction quite similar constructions, omitdescription.completes description construct LR partial refutations Rt .process stops Rt unnished clauses. claim process stopspolynomially many stages.694fiSeparations Regular Resolutionprove this, recall Rt+1 formed handling leftmost unnished clauseusing one cases (i)-(iv). rst three cases, unnished clause replacedderivation based P bipartite order . Since P size O(n3 ), meansnumber clauses Rt+1 number clauses Rt plus O(n3 ).Also, construction, Rt+1 one fewer unnished clauses Rt . case (iv) however,Rt+1 formed adding O(n) many clauses Rt plus adding either two threenew unnished leaf clauses. addition, case (iv) always causes leastnone transitivityaxiom Ti,j,k learned.Therefore, case (iv) occur 2 3 = O(n3 ) times.Consequently 3 2 n3 = O(n3 ) many unnished clauses added throughoutentire process.process stops Rt unnished clausesnfollows36 3 = O(n ). Therefore pool refutation GGTn O(n6 ) lines.Since GGTn principle O(n3 ) many clauses, number inferences refutationbounded quadratic polynomial number clauses refuted.inspection, clause refutation contains O(n2 ) literals.largest clauses corresponding (small modications of) bipartite partialorders, bipartite partial orders contain O(n2 ) many ordered pairs.Furthermore, refutations Pn GTn contain clauses size O(n2 ).Q.E.D. Theorem 18Theorem 19 proved nearly construction. fact, changeneeded construction P . Recall proof Theorem 18, poolderivation formed using depth-rst traversal P . sucientTheorem 19, since derivation must use input lemmas. Instead,use result Buss et al. (2008, Thm. 3.3), states (regular)dag-like resolution derivation transformed (regular) tree-like derivationinput lemmas. Forming way P suces proof Theorem 19:lemmas either transitive closure axioms derived earlier Rt derivedinput subderivations earlier post-order S. Since transitive closure axiomsappeared earlier Rt derived resolving two GGTn axioms, lemmas usedinput lemmas.transformation theorem Buss et al. (2008, Thm. 3.3) may multiply sizederivation depth original derivation. proofs P depth O(n),regRTI refutation overall size O(n7 ). completes proof Theorem 19.5. Greedy Unit Propagating CDCLsection proves guarded graph tautology clauses GGTn refutedpolynomial-time greedy, unit propagating CDCL search without restarts. One dicultyeven know whether regular dag-like resolution refutations polynomially simulated greedy, unit propagating CDCL without restarts. Therefore, mustrst establish Theorems 26 30 showing greedy, unit propagating CDCLrefutations without restarts graph tautologies GTn GT,n . Theorem 31gives polynomial-time greedy, unit propagating CDCL algorithm (without restarts)GGTn . intuition CDCL search traverses regRTI refutations GGTn695fiBonet, Buss, & JohannsenTheorem 19, learning transitivity clauses Ti,j,k whenever possible. also needuse notion absorption used Atserias et al. (2011) PipatsrisawatDarwiche (2011).give quick overview CDCL search algorithms clause learning algorithms;greater detail, see works Marques-Silva Sakallah (1999) Beame et al. (2004).Given set clauses input, CDCL search maintains stack literals assignedvalue True collection learned clauses. simplied, general, formprocedure CDCL without restarts follows:Input: set clauses.Algorithm:Set := .Loop:unit propagation yields contradiction,Halt. unsatisable.Else unit propagation assigned literalsyields contradiction,Infer zero clauses input resolution basedconict, add . (Learning)Select , set = \ . (Garbage collection)Unassign last assigned literal. (Backtracking)Else literals assigned value,Halt. satisable.ElseChoose unassigned literal, assign value True.Endifabove-described CDCL algorithm lacks many important features usual implementations CDCL algorithms. However, simplied CDCL algorithm polynomially simulate sophisticated implementations CDCL learning unlearningappropriate clauses. Conversely, sophisticated CDCL algorithms polynomially simulate simplied CDCL algorithm, since proving polynomial timeruntime simplied algoithm, certainly implies polynomial time runtimesophisticated CDCL algorithms (subject usual specifying decision literalsset clauses learned garbage collected).clause learning used Theorems 26 30 usual rst-UIP (uniqueimplication point) clause learning, learn clauses obtained pickingcut conict graph, common CDCL algorithms.Theorem 26. Greedy, unit propagating CDCL search without restarts refute GTnclauses polynomial time.Proof. Recall construction refutations Pn GTn clauses picturedFigure 1. key property needed derivation Totk,j Totk+1,k+1Totk+1,j input derivation, permit learning Totk,j Totk+1,k+1Totk+1,j learned.696fiSeparations Regular Resolutiongive direct description CDCL search. search initially choosesset literals x1,0 , x2,1 . . ., xn2,n3 true decision literals, order, xi+1,iset true (decision) level + 1. literal xi,j interpreted meaning jpartial order ; thus decision literals express n 2 n 3 1 0 holds.Unit propagation transitive closure clauses implies literals xj,i ,words j i, 0 < j n 2. literal xj,i derived level j.reaching literal xn2,n3 , unit propagations possible. But, uponassigning xn2,n3 true, clause Totn1,n2 becomes unit clause, xn1,n2 inferred. words, n 1 n 2 inferred. Now, literals xn2,j , unitpropagations transitive closure clauses gives xn1,j , n j, j < n2.falsies Totn1,n1 , yields conict, CDCL search backtracks previouslevel.backtracks, CDCL algorithm learns two clauses Totn3,n3 xn3,n2Totn2,n2 , sets decision literal xn2,n3 false level n 3. rst clauselearned taking decision literal xn2,n3 UIP, since literals xn3,j j <n3 literals level < n3 used infer level n2 literals conictgraph. see possible learn second clause Totn2,n2, note conictobtained via unit propagation decision literal xn2,n3 literals xn2,j ,Totn2,n2 contains exactly negations literals. literals xn2,jset level n 2, Totn2,n2 learned UIP; nonetheless, falls withincommonly permitted CDCL learning. Totn3,n3 xn3,n2 learned,literal xn3,n2 follows single unit propagation.rst backtrack, decision literals x1,0 , x2,1 , . . ., xn3,n4 set truedecision literals, Totn2,n2 Totn3,n3 xn3,n2 learned, xn3,n2 truelevel n 3 unit propagation. possible use unit propagation get yet anotherconict. However, instead describing this, go general cases.general case, parameters , r, 0 < r < < n either= r + 1 = n 1. general case, literals x1,0 , x2,1 , . . ., x,1 set truerst decision literals literals x,+2, x,+3 , . . . , x,r set nextdecision literals, three clauses Tots, , Tot, x,+1 , Totk,k k >learned. (Refer Figure 1. situation previous paragraph = n 3,r = n 2, = n 1.) Using Tot, x,+1 unit propagation, literal x,+1set level . terms , literals set true express conditions1 1 0j j = + 1, . . . , r.(10)r < 1 = n 2, unit propagation yield contradiction, CDCL searchproceeds setting x,r+1 true next decision literal. CDCL searchgeneral case parameters , r+1, n1.r = 1, unit propagation transitivity clauses yields x,j , namely j,j [s] \ {}. makes Tots, unit clause thus xs, , namely , set trueunit propagation. Using literals x,j again, unit propagation transitivity clausesfalsies learned clause Tots,s . CDCL algorithm backtracks one level.r > + 1, learns Tots1, . learned since conict obtainedliterals x,j j [s] \ {}. learned clause Tots, forgotten garbage collection.puts CDCL search new general situation parameters , r1, s1.697fiBonet, Buss, & Johannsenr = + 1 = 1, two clauses Tot, Tot1,1 x1, learned instead.second clause clause obtained usual learning algorithm using decisionliteral x,1 UIP. clause Tot, learned since conict graph usedliterals x,j j < obtain conict: obtained UIP, obtainedusing cut conict graph. Garbage collection used forget clausesTot, x,+1 Tots, . puts CDCL search general case, new, r, parameters equal 1, , n 1, respectively.CDCL search ends dealing case = 0, r = 1 = 2. case,empty clause Tot0,0 learned, CDCL search halts, establishing GTnunsatisable.next theorem discusses greedy, unit propagating CDCL search simulatederivations P graph tautologies GT,n obtained restricting GTnbipartite partial order . course, fully make sense, since CDCL searchsimulates refutations, derivations. really want simulate Psubderivation regRTI refutations GGTn constructed Theorem 19. this,let C clause regRTI refutation GGTn . Let dag jxi,j C pool , let associated bipartite partial order, C clause ( ).claim greedy, unit propagating CDCL refutation (non-guarded) GT,nclauses literals xi,j j. words, greedy, unit propagatingCDCL search refute GTn clauses set literals C pool false.state Theorem 30 full generality, need following denitions.modications denitions Atserias et al. (2011) Pipatsrisawat Darwiche (2011).Definition 27. Let C clause x literal C. say C u.p.-absorbed xset clauses provided every literal C \ {x} set false, x impliedunit propagation using clauses . say C u.p.-absorbed providedu.p.-absorbed every x C. say C absorbed providedliterals C set false, unit propagation using yields contradiction.clause C becomes u.p.-absorbed, becomes redundant terms unit propagation. particular, adding C additional clause would yield additionalconicts would make possible learn additional clauses conicts.need slightly general denition, however.Definition 28. Let C above, let L set literals. write L denoteset unit clauses {x} x L, i.e. clauses asserting every x L false. CL-absorbed L-u.p.-absorbed (at x) provided absorbed u.p.-absorbed (at x)L, respectively.Suppose C L-u.p.-absorbed. intuition current set initiallearned clauses CDCL search S, literals L set false (eitherdecision literals unit propagation). Then, unit propagation L yieldscontradiction unit propagation L {C} does. learned clauseformer may need include additional literals L however. state formally:Lemma 29. Let set clauses, L set literals set false above, CL-u.p.-absorbed . Suppose unit propagation L {C} yields contradiction698fiSeparations Regular Resolutionallows clause learned. unit propagation L also yields contradiction,allows clause learned L.proof Lemma 29 almost immediate denitions, left reader.Note additional literals L appear precisely negationsliterals L needed simulate invocation C unit propagation.Theorem 30. Let define dag [n], let bipartite partial orderassociated . greedy, unit propagating CDCL search findsrefutation GT,n clauses unit clauses xi,j j.Proof. proof Lemma 25, let = [m] Jk Jk k k m.Let L set literals xi,j j. Let greedy, unit propagatingCDCL search refuting GTm clauses size polynomial given Theorem 26.wish prove transformed greedy, unit propagating CDCL searchrefutes GT,n clauses clauses L. search mimic closely,setting decision literals order S, learn clauses Toti,j placeclauses Toti,j . (Compare Figures 1 4.)must use GT,n clauses initial clauses instead GTm clauses used S.First consider GTm transitivity clause used S; type ( ) Denition 17equal Ti,j,k distinct i, j, k < m. such, also GT,n clause type ()thus already available use.Second, consider totality clause Totm1,i = k[m]\{i} xk,i type ( ) usedunit propagation search S. clause may L-u.p.-absorbed GT,nclauses. But, not, L-absorbed GT,n suce searchsucceed. see L-absorbed, suppose point unit propagationTotm1,i used obtain conict. case, one literal Totm1,iset false, namely j0 [m] \ {i} set literals xj,ij [m] \ {i, j0 } false infers xj0 ,i unit propagation. new search alsoset literals xj,i j [m] \ {i, j0 } false needs infer xj0 ,i ; must useGT,n clause Totn1,i instead GTm clause Totm1,i . Consider xk,i Totn1,ik m. j [m] \ {i, j0 } j k (we let Jk denote j),then, since xj,k L, unit propagation transitivity clause Ti,j,k sets xi,k true, i.e.,falsies xk,i Totn1,i . holds k m, Totn1,i reduced unitxj0 ,i , Totm1,i L-u.p.-absorbed xj0 ,i GT,n . Otherwise Totm1,i L-u.p..absorbed. case, let k1 , . . . , kR values j0 kr 1 r R,just-described unit propagation able reduce Totn1,i (non-unit) clausexj0 ,i xk1 ,i xkR ,i . search branches set xj0 ,i false decision literal.Unit propagation transitivity clauses Ti,j0 ,kr , r R falsies literals xkr ,ithereby falsies Totn1,i . backtracks learns clause Si Totm1,i (see (5)).course clause Totm1,i . Totm1,i learned, since literalsSi L set false, obtain conict way S.general, literals Toti,j \ Toti,j members L, set false .thus straightforward check remaining steps simulated directlyusing exactly decision literals, obtaining conict clausesway, learning clauses Toti,j instead clauses Toti,j .699fiBonet, Buss, & Johannsendescribe greedy unit propagating CDCL without restart proceduresrefute GGTn clauses.Theorem 31. CDCL without restart search procedures greedy unitpropagating, refute GGTn clauses polynomial time.Proof. basic idea greedy, unit propagating CDCL search followsstructure refutation described proofs Theorems 18 19; is, followsstages construction LR-partial refutations.stage corresponds unnished clause C LR-partial refutation,set transitivity clauses Ti,j,k learned clauses, set zeroliterals xi,j true. literals describe dag , namelyi j xi,j settrue. Let associated bipartite partial order, C = ( ). set everyxi,j true j. possible, use refutation Theorem 30backtrack current stage; otherwise, branch learn another transitivityclause. rst possibility holds provided every transitivity clause Ti,j,k , type ()() needed refutation GT,n either learned C pool -u.p.-absorbed S.Otherwise, suppose transitivity clause Ti,j,k type () neither learnedpool-u.p.-absorbed. Following pattern argument case proofCTheorem 18, sets xi,j true decision literal. Since Ti,j,k type (), xi,jalready set. claim setting xi,j true yield contradiction unitpropagation. prove claim, note way unit propagation occur(guarded unguarded) transitivity clause becomes unit clause. Referring backFigure 3, (possibly guarded) transitivity clauses become unit uponsetting xi,j true clauses Ti,j, set xj, true. Therefore unitpropagation yielda contradiction xi,j . sets xk,i true. Since Ti,j,ktype () C = ( ), set xj,k true; therefore, unit propagation yieldscontradiction Ti,j,k Ti,j,k . this, backtracks, setting xi,k truelearning Ti,j,k .backtracking, stage corresponding clause C1 subrefutation S1proof Theorem 18. Let L1 literals set false, 1 dag denedliterals L1 , let 1 associated bipartite order. needs infer literalsxi, 1 . done using transitivity clauses. L1 -u.p.-absorbed transitivityclause used directly. transitivity clauses Ti,j, , xi,j xj, set true,branches set x,i false decision literal, obtains immediate contradictionunit propagation two GGTn clauses Ti,j, backtracks, learning Ti,j,inferring xi, unit propagation. literals xi, 1 set true,stage corresponding unnished clause.backtracks stage corresponding clause C1 , enters stagecorresponding C2 . handled similarly.argument case transitivity clause Ti,j,k type ()learned similar. follow construction proof Theorem 18,use stages correspond clauses C3 , C4 , C5 . Since construction quitesimilar, omit description.Theorem 31 shows close correspondence regRTI proofs GGTnclauses greedy, unit propagating CDCL refutations without restarts. open, how700fiSeparations Regular Resolutionever, whether arbitrary regRTI regWRTI refutation converted polynomialsize greedy, unit propagating CDCL refutation without restarts. even open whether every (dag-like) regular refutation corresponds greedy, unit propagating CDCL refutationwithout restarts.Acknowledgementsgrateful J. Homann assisting correction earlier versionproof Theorem 19. also thank A. Van Gelder, L. Kolodziejczyk, A. Beckmann,T. Pitassi, three anonymous referees encouragement, suggestions, useful substantial comments.M. L. Bonet supported part grant TIN2010-20967-C04-02, ResearchAbroad Fellowship (Generalitat de Catalunya BE, 2012).S. Buss supported part National Science Foundation grants DMS-0700533,DMS-1101228 CCF-1213151, grant Simons Foundation (#208717Sam Buss). also thanks John Templeton Foundation supporting participationCRM Innity Project Centre de Recerca Matematica, Barcelona, Catalonia,Spain results obtained.S. Buss J. Johannsen thank Ban International Research Station workshop Proof Complexity (11w5103) held October 2011 partresults obtained.ReferencesAlekhnovich, M., Johannsen, J., Pitassi, T., & Urquhart, A. (2007). exponential separation regular general resolution. Theory Computing, 3 (5), 81102.Alekhnovich, M., & Razborov, A. A. (2001). Resolution automatizable unless W [P ]tractable. Proc. 42nd IEEE Conf. Foundations Computer Science (FOCS),pp. 210219.Atserias, A., Fichte, J. K., & Thurley, M. (2011). Clause-learning algorithms manyrestarts bounded-width resolution. Journal Artificial Intelligence Research, 40,353373.Beame, P., Kautz, H. A., & Sabharwal, A. (2004). Towards understanding harnessingpotential clause learning. J. Artificial Intelligence Research, 22, 319351.Beckmann, A., & Buss, S. R. (2005). Separation results size constant-depthpropositional proofs. Annals Pure Applied Logic, 136, 3055.Ben-Sasson, E. (2009). Size space tradeos resolution. SIAM Journal Computing,38 (6), 25112525.Ben-Sasson, E., Impagliazzo, R., & Wigderson, A. (2004). Near optimal separation treelike general resolution. Combinatorica, 24 (4), 585603.Bonet, M. L., & Buss, S. R. (2012a). improved separation regular resolution poolresolution clause learning. Proc. 15th International Conference Theory701fiBonet, Buss, & JohannsenApplications Satisfiability Testing SAT 2012, Lecture Notes Computer Science#7317, pp. 4557.Bonet, M. L., & Buss, S. R. (2012b). improved separation regular resolution poolresolution clause learning. Full version, arxiv.org, arXiv:1202.2296v2 [cs.LO].Bonet, M. L., & Galesi, N. (2001). Optimality size-width tradeos resolution. Computational Complexity, 10 (4), 461474.Buss, S., & Kolodziejczyk, L. (2012). Small stone pool. Submitted publication.Buss, S. R. (2009). Pool resolution NP-hard recognise. Archive Mathematical Logic,48 (8), 793798.Buss, S. R., Homann, J., & Johannsen, J. (2008). Resolution trees lemmas: Resolutionrenements characterize DLL-algorithms clause learning. Logical MethodsComputer Science, 4, 4:13 (4:13), 118.Chang, C. L. (1970). unit proof input proof theorem proving. J. ACM,17 (4), 698707.Goerdt, A. (1993). Regular resolution versus unrestricted resolution. SIAM JournalComputing, 22 (4), 661683.Hertel, P., Bacchus, F., Pitassi, T., & Van Gelder, A. (2008). Clause learning eectivelyp-simulate general propositional resolution. Proc. 23rd AAAI Conf. ArtificialIntelligence (AAAI 2008), pp. 283290. AAAI Press.Huang, W., & Yu, X. (1987). DNF without regular shortest consensus path. SIAMJournal Computing, 16 (5), 836840.Johannsen, J. (2009). exponential lower bound width-restricted clause learning.Proc. 12th International Conference Theory Applications SatisfiabilityTesting SAT 2009, Lecture Notes Computer Science #5584, pp. 128140.Krishnamurthy, B. (1985). Short proofs tricky formulas. Acta Informatica, 22 (3), 253275.Marques-Silva, J. P., & Sakallah, K. A. (1999). GRASP new search algorithmsatisability. IEEE Transactions Computers, 48 (5), 506521.Pipatsrisawat, K., & Darwiche, A. (2011). power clause-learning SAT solversresolution engines. Artificial Intelligence, 172 (2), 512525.Segerlind, N., Buss, S. R., & Impagliazzo, R. (2004). switching lemma small restrictionslower bounds k-DNF resolution. SIAM Journal Computing, 33 (5), 11711200.Stalmarck, G. (1996). Short resolution proofs sequence tricky formulas. ActaInformatica, 33 (3), 277280.Urquhart, A. (2011). near-optimal separation regular general resolution. SIAMJournal Computing, 40 (1), 107121.Van Gelder, A. (2005). Pool resolution relation regular resolution DPLLclause learning. Logic Programming, Artificial Intelligence, Reasoning(LPAR 2005), Lecture Notes Computer Science 3835, pp. 580594. Springer-Verlag.702fiSeparations Regular ResolutionVan Gelder, A. (2006). Preliminary report input cover number metric propositional resolution proofs. Theory Applications Satisfiability Testing - SAT2006, Lecture Notes Computer Science 4121, pp. 4853. Springer Verlag.703fiJournal Artificial Intelligence Research 49 (2014) 569-600Submitted 04/2013; published 04/2014Inapproximability Treewidth,One-Shot Pebbling, Related Layout ProblemsYu (Ledell) WuPer AustrinToniann PitassiDavid Liuwuyu@cs.toronto.eduaustrin@cs.toronto.edutoni@cs.toronto.eduliudavid@cs.toronto.eduDepartment Computer ScienceUniversity Toronto, Ontario, CanadaAbstractGraphical models, Bayesian Networks Markov networks play importantrole artificial intelligence machine learning. Inference central problemsolved networks. This, problems graph models oftenknown hard solve general, tractable graphs bounded Treewidth.Therefore, finding approximating Treewidth graph fundamental problemrelated inference graphical models. paper, study approximabilitynumber graph problems: Treewidth Pathwidth graphs, Minimum Fill-In, OneShot Black (and Black-White) pebbling costs directed acyclic graphs, varietydifferent graph layout problems Minimum Cut Linear Arrangement IntervalGraph Completion. show that, assuming recently introduced Small Set ExpansionConjecture, problems NP-hard approximate within constant factorpolynomial time.1. IntroductionGraphical models provide computational framework efficiently manipulating probability distributions high dimensional spaces, often involving hundreds thousandsvariables. framework found applications enormous range domains including: medical fault diagnosis, image understanding, speech recognition, web search,coding theory, statistical physics (Koller & Friedman, 2009). graphical modelefficient representation joint distribution set n random variables. Evenrandom variables binary, well known arbitrary joint distributionrequires specification 2n probabilities. Luckily, real world, often structure distribution allows one express succinctly. graphical modelrepresents joint probability distribution graph vertices representrandom variables, dependences modeled graph structure. Associatedvertex graph conditional probability table, specifies conditional probabilities random variable, conditioned neighboring vertices. twocommon types graphical models Bayesian networks (also called belief networks),underlying graph directed, Markov networks (also called Markov randomfields), underlying graph undirected. basic problem graphicalmodels inference problem, problem computing posterior marginalc2014AI Access Foundation. rights reserved.fiWu, Austrin, Pitassi, & Liudistribution variable vertex. Unfortunately, inference general well-knownNP-hard compute exactly well approximate (Roth, 1996).Despite intractability, important class bounded Treewidth instances probabilistic inference identified shown exactly computable polynomialtime. Treewidth graph (Robertson & Seymour, 1984, 1986) fundamental parameter graph measures close graph tree. Treewidthclosely related notions machine learning Branch-width, Clique-widthElimination-width (for overview Treewidth related notions, see Bodlaender,Gilbert, Hafsteinsson, & Kloks, 1995). graphs small Treewidthtree decomposition known, dynamic programming algorithm yields polynomial-timealgorithm. Particular algorithms probabilistic inference bounded Treewidth graphsjunction-tree method, variable elimination clique trees (e.g. see Koller & Friedman, 2009, ch. 9, 10). algorithms runs time exponential Treewidthtree decomposition polynomial size graph. Thus graphs treedecomposition bounded Treewidth given, inference polynomial-time computable.ideas also yield polynomial-time algorithms often even linear time algorithms small Treewidth instances astonishing variety NP-hard problems, including: satisfiability, counting satisfying assignments, constraint satisfaction, vertex cover, maximum independent set, Hamiltonian circuit, query optimization, matrix decomposition, generally problems definable monadic second-order logic. (Seeexcellent survey Bodlaender, 2005 motivation, including theoretical well practical applications Treewidth.) One catch problems, algorithmmust begin finding tree decomposition, use decomposition solveproblem. Given tree decomposition, algorithm typically exponential widthunderlying tree decomposition. Thus need efficient algorithms actually compute Treewidth given graph, find tree decompositions optimalclose optimal width.Unfortunately, many good heuristics finding good tree decomposition, NP-hard general determine Treewidth graph (Arnborg, Corneil,& Proskurowski, 1987). However, Bodlaender et al. (1995) obtained O(log n) factorapproximation algorithm Treewidth. fact, actually show factorc approximation algorithm vertex separator, O(c) approximation algorithm Treewidth. factor b approximation algorithm TreewidthO(b log n) approximation algorithm related Pathwidthproblem.best currently known approximation factor vertex separator O( log n) (Feige, Hajiaghayi, & Lee, 2005)pthus best algorithm Treewidth findstree decompositionwithin O( log n) factor optimal width, O(( log n)(log n)) factorapproximation algorithm Pathwidth.longstanding open question whether constant factor approximation algorithm Treewidth. algorithm would lead faster algorithmsfind good tree-decompositions problems mentioned above. current bestknown algorithm achieves constant factor approximation Treewidth runs time2O(w) O(n), w Treewidth underlying graph, achieves factor 5 approximation (Bodlaender, 2007) (Earlier approximation algorithms similar runtimesReed, 1992; Amir, 2001). book devoted Treewidth Kloks (1994, p. 62) states:570fiInapproximability Treewidth Related Problemsfeel one biggest open problems research dealingTreewidth Pathwidth moment. fast algorithms solving NPhard problems graphs bounded Treewidth ever become practical importance, undoubtedly importance find good tree-decompositionsgraphs. Since (current best) approximations make manyalgorithms practical, great interest know whether approximationssmall constant exist.Nearly twenty years later, still open problem whether polynomialtime algorithm approximate Treewidth within constant factor. Similarly, approximability many related graph layout problems also unresolved, including Minimum CutLinear Arrangement Interval Graph Completion. paper, make importantstep resolve problem showing Treewidth, Pathwidth, host relatedgraph layout problems hard approximate within constant factor,Small Set Expansion (SSE) conjecture (Raghavendra & Steurer, 2010).SSE conjecture strengthened version conjecture P differentNP warrants explanation. next subsection (Section 1.1), explainSSE conjecture, relates P versus NP question related conjectures.state main hardness results Treewidth, pebbling problems graph layoutproblems (Sections 1.2, 1.4, 1.5), discuss related results Section 1.6.1.1 Small Set Expansion ConjectureP versus NP problem important intriguing open problem fieldcomputational complexity theory. Many decision problems theory practiceproven NP-hard, indicates impossible compute polynomialtime, widely believed conjecture P 6= NP. discovery PCP theoremlate 80s (Arora, Lund, Motwani, Sudan, & Szegedy, 1998; Arora & Safra, 1998) madepossible prove many optimization problems, approximating optimal valuewithin certain factor hard computing exact optimal value. words,conjecture P 6= NP, possible approximate certain optimizationproblems within factor depends problem. Celebrated results showNP-hard approximate MAX-3SAT within ratio 78 + > 0 (Hastad,2001), gives optimal lower bound, since simple algorithm achievesapproximation ratio 78 . Also, NP-hard approximate clique within n1factor > 0 (Hastad, 1999). Despite success, many important problems,hardness approximation results obtained PCP theorem matchedbest approximation algorithms known. example, still significant gapsunderstanding optimal approximability factor important problems as:Vertex Cover, Max-Cut, Bipartite Clique, Kernel Clustering.formulation Unique Games Conjecture (UGC) due Khot (2002) intended clarify approximability many optimization problems. conjecture postulates problem determining value certain type game, knownunique game, NP-hard. conjecture inspired remarkable body work sinceformulation. UGC, many known algorithms approximation proventight (for excellent survey topic, see Khot & Vishnoi, 2005). instance,571fiWu, Austrin, Pitassi, & LiuUGC, Vertex Cover problem NP-hard approximate within factor 2 ,> 0 (Khot & Regev, 2008). Perhaps strikingly, Raghavendra (2008) provedUGC, semi-definite programming (SDP) approximation algorithmlarge class constraint satisfaction problems (CSP) essentially best one hopefor. specifically, showed every maximum constraint satisfaction problem (MaxCSP) associated sharp approximation threshold : every > 0, one achieveapproximation polynomial time using SDP, obtaining + approximationNP-hard. Thus, UGC become central open problem inapproximabilityencapsulates barrier designing better polynomial time approximation algorithmslarge class problems.Despite tremendous progress, still remain important yet stubborn problemsTreewidth, Balanced Separator, Minimum Linear Arrangement (MLA), manygraph layout problems whose approximation status remains unresolved even assumingUGC. Intuitively hard instances problems seem requirecertain global structure expansion. (Expansion graph property akinhigh connectivity, requires every subset vertices large largeboundary.) Typical reductions problems gadget reductions preserveglobal properties unique games instance, lack expansion. Therefore,barring radically new types reductions preserve global properties, provinghardness problems seems require stronger version UGC, instanceguaranteed certain expansion properties.work Raghavendra Steurer (2010), Small Set Expansion (SSE) Conjecture introduced, shown implies UGC, SSE Conjecturefollows one assumes UGC true somewhat expanding graphs. follow-upwork Raghavendra et al. (2012), shown SSE Conjecture fact equivalent UGC somewhat expanding graphs, SSE Conjecture impliesNP-hardness approximation balanced separator MLA. light, SmallSet Expansion conjecture serves natural unified conjecture yields implications UGC also hardness expansion-like problems could resolvedUGC.main contribution paper prove wide range graph layoutproblems SSE-hard approximate within constant factor. problems,evidence hardness approximation known prior results. Moreover,show Treewidth, Pathwidth, Minimum Fill-In SSE-hard approximate withinconstant factor. first result giving hardness (relative) approximationproblems, gives evidence constant factor approximation algorithm existsthem.noted status SSE conjecture open point.particular, recent results (Arora, Barak, & Steurer, 2010; Barak, Raghavendra, & Steurer,2011; Guruswami & Sinop, 2011) give subexponential-time algorithms small set expansion. Still despite recent progress providing evidence SSE conjecture,remains open. SSE-hardness results Treewidth related problems may thereforeviewed establishing new connection fundamental conjecture complexitytheory, approximability ubiquitous problem artificial intelligence.572fiInapproximability Treewidth Related Problems1.2 Width Parameters Graphsmentioned earlier, determining exact Treewidth graph producing associated optimal tree decomposition (see Definition 2.1) known NP-hard (Arnborget al., 1987), central open problem determine whether existspolynomial time constant factor approximation algorithm Treewidth (see e.g., Bodlaender et al., 1995; Feige et al., 2005; Bodlaender, 2005). current best polynomial timeapproximation algortihmTreewidth (Feige et al., 2005), computes Treewidth tw(G)pwithin factor O( log tw(G)). hand, hardness result dateTreewidth shows NP-hard compute Treewidth within additive error n> 0 (Bodlaender et al., 1995). hardness approximation knowneven possibility polynomial-time approximation scheme Treewidthruled out. many important special classes graphs, planar graphs (Seymour &Thomas, 1994), asteroidal triple-free graphs (Bouchitte & Todinca, 2003), H-minor-freegraphs (Feige et al., 2005), constant factor approximations known, general caseremained elusive.positive side, large body literature developing fixed-parameter algorithms Treewidth. Exactly determining Treewidth fixed-parameter tractable:linear time algorithm computing (exact) Treewidth graphs constant treewidth (Bodlaender, 1996). specifically exact algorithm runs time2poly(k) poly(n). Constant factor approximation algorithms achieve better dependencetreewidth, k, n, best algorithm running time 2O(k) O(n) (Bodlaender, 2007).related graph parameter so-called Pathwidth, viewed measuringclose G path. Pathwidth pw(G) always least tw(G), muchlarger. current state affairs similar Treewidth;pthough current bestapproximation algorithm approximation ratio O( log pw(G) log n) (Feigeet al., 2005), best hardness result NP-hardness additive n error approximation.Using recently proposed Small Set Expansion (SSE) Conjecture (Raghavendra &Steurer, 2010) discussed earlier, show tw(G) pw(G) hard approximate within constant factor. fact, show something stronger: harddistinguish graphs small Pathwidth graphs large Treewidth. Specifically:Theorem 1.1. every > 1 c > 0 given graph G = (V, E)SSE-hard distinguish case pw(G) c |V | casetw(G) c |V |.particular, Treewidth Pathwidth SSE-hard approximate withinconstant factor.first result giving hardness (relative) approximation problems,gives evidence constant factor approximation algorithm exists eitherthem.1.3 Minimum Fill-Inclosely related graph theoretic property Minimum Fill-In graph, minimum number edges required add graph triangulate (i.e., make chordal).573fiWu, Austrin, Pitassi, & Liuproperty important applications sparse matrix computations (and particular Gaussian elimination) artificial intelligence (see excellent survey Heggernes,2006).Minimum Fill-in known fixed parameter tractable since 1994,Kaplan et al. (1994) gave O(|E|16k ) algorithm, k number edges required.there, several improvements running time given, recent2012 Fomin Villanger (2012),gave first subexponential parameterizedalgorithm, running time O(2O( k log k) + k 2 |V | |E|). work Natanzon et al.(1998), polynomial time approximation algorithm presented, computed value8k 2 , k optimal solution. graphs degree bounded d,algorithm achieves approximation ratio O(d2.5 log4 (kd)).remains best polynomial time approximation algorithm known date.particular, remained open question whether polynomial time constant factorapproximation algorithm exists. paper, show possible, assumingSSE Conjecture.Theorem 1.2. SSE-hard approximate Minimum Fill-In graph withinconstant factor.1.4 Pebbling ProblemsGraph pebbling rich relatively mature topic theoretical computer science. Pebbling game defined directed acyclic graph (DAG), goal pebblesink nodes DAG according certain rules, using minimum number pebbles.rules pebbling follows. black pebble placed nodenodes immediate predecessors contain pebbles, always removed. white pebblealways placed node, removed nodes immediatepredecessors contain pebbles. pebbling strategy process pebbling sink nodesgraph according rules. pebbling cost pebbling strategymaximum number pebbles used strategy. Black-White pebbling costDAG minimum pebbling cost possible pebbling strategies. black pebblingcost minimum pebbling cost pebbling strategies use black pebbles.Pebbling games originally devised studying programming languages compiler construction, later found broad range applications computationalcomplexity theory. Pebbling tool studying relationship computationtime space means game played directed acyclic graphs. employedmodel register allocation, analyze relative power time space Turingmachine resources. comprehensive recent survey graph pebbling, see workNordstrom (2010).Apart cost pebbling, another important measure pebbling time,number steps (pebble placements/removals) performed. context measuringmemory used computations, corresponds computation time, hence keepingpebbling time small natural priority. extreme case referOne-Shot Pebbling, also known progressive pebbling, considered literature (e.g.,Sethi, 1973; Lengauer, 1981; Kirousis & Papadimitriou, 1986). One-Shot Pebbling,574fiInapproximability Treewidth Related Problemsrestriction node receive pebble once. Note restrictioncause huge increase pebbling cost graph (Lengauer & Tarjan, 1982).One-Shot Pebbling problem easier analyze following reasons.original pebbling problem, order achieve minimum pebbling number, pebblingtime might required exponentially long, becomes impractical nlarge. hand, One-Shot Pebbling problem amenable complexitytheoretic analysis minimizes space used computation subject executiontime minimum. particular, decision problem One-Shot Pebbling NP(whereas unrestricted pebbling problems PSPACE-complete).One-ShotBlack Pebbling problem One-Shot Black-White Pebbling problemsadmit O( log n log n) approximation ratio. show SSE-hard approximate within constant factor. black pebbling show holds singlesink DAGs in-degree 2, canonical setting pebbling games (it seemsplausible black-white hardness shown hold case well, thoughattempted prove this).Theorem 1.3. SSE-hard approximate One-Shot Black Pebbling problem withinconstant factor, even DAGs single sink maximum in-degree 2.Theorem 1.4. SSE-hard approximate One-Shot Black-White Pebbling problemwithin constant factor.hardness approximation result form known One-Shot Pebblingproblems. believe results extended obtain hardnessrelaxed versions bounded time pebbling costs well. currently working this,preliminary results.1.5 Connection: Layout Problemsgraph width One-Shot Pebbling problems discussed previous sections mayfirst glance appear unrelated. However, sets problems instancesgeneral family problems, known graph layout problems. graph layout problem(also known arrangement problem, vertex ordering problem), goal findordering vertices, optimizing condition edges, adjacent pairsclose. Layout problems important class problems applicationsmany areas VLSI circuit design.classic example Minimum Cut Linear Arrangement problem (MCLA).problem, objective find permutation vertices V undirected graphG = (V, E), largest number edges crossing point,max |{(u, v) E|(u) < (v)}|,(1)minimized. MCLA closely related Minimum Linear Arrangement problem(MLA), max (1) replaced sum.MCLA problem approximated within factor O(log n log n).best knowledge, hardness approximation MCLA literature.cousin MLA recently proved SSE-hard approximate within constant factor575fiWu, Austrin, Pitassi, & Liu(Raghavendra et al., 2012), observe hardness applies MCLAproblem.Theorem 1.5. SSE-hard approximate Minimum Cut Linear Arrangement problem within constant factor.Another example graph layout Interval Graph Completion Problem (IGC).problem, objective find supergraph G0 = (V, E 0 ) G vertex setV , G0 interval graph (i.e., intersection graph set intervalsreal line) minimum number edges. immediately appearinglayout problem, using simple structural characterization interval graphs (Ramalingam& Rangan, 1988) one show IGC reformulated finding permutationvertices minimizes sum longest edges going vertex, i.e.,minimizingXmax max{(v) (u), 0}.(2)uV(u,v)ESee, example, work Charikaret al. (2010). current best approximationalgorithm IGC achieves ratio O( log n log log n) (Charikar et al., 2010). turnsSSE Conjecture used prove super-constant hardness problemwell.Theorem 1.6. SSE-hard approximate Interval Graph Completion problem withinconstant factor.distinction IGC whether one counts number edges finalinterval graph common definition whether one countsnumber edges added make G interval graph (which makes problem harderapproximability viewpoint). result holds common definition thereforeapplies also harder version. Note Interval Graph Completion well connectedPathwidth: pathwidth graph G one less smallest clique numberinterval graph contains G subgraph.Theorems 1.5 1.6 two examples layout problems prove hardnessapproximation for. varying precise objective function also considering directedacyclic graphs, case permutation must topological orderinggraph, one obtain wide variety graph layout problems. consider set eightproblems, generated three natural variations (see Section 2.3 precise details),show super-constant SSE-based hardness unified way. setproblems includes MLA, MCLA, IGC, problems Bandwidth (buthand, strong NP-hardness inapproximability results Bandwidth alreadyknown Dubey, Feige, & Unger, 2011). See Table 1 Section 2.3 complete listproblems covered.Theorem 1.7. Assuming SSE Conjecture, problems listed Table 1 (see page 581)NP-hard approximate within constant factor.Let us return problems discussed previous sections.surprising One-Shot Black Pebbling problem equivalent graph layout576fiInapproximability Treewidth Related Problemsproblem: one-shot constraint reduces problem determining orderpebble vertices; ordering induces pebbling strategy obvious way. (Givengraph layout ordering, vertices black pebbled order, blackpebble removed soon vertex longer needed. Conversely, blackpebbling sequence induces corresponding ordering vertices.) black-whitecase, known One-Shot Black-White Pebbling cost interreduciblelayout problem undirected graph G. layout problems includedset problems show hardness for, Theorems 1.3 1.4 follow immediatelyTheorem 1.7.Turning width parameters, Treewidth equivalent graph layout problemcalled elimination width. objective function somewhat intricateset basic layout problems consider Theorem 1.7, able extendresults hold also elimination width. Pathwidth also known equivalentcertain graph layout problem, fact equivalent layout problemOne-Shot Black-White Pebbling reduces to. use connections prove hardnessapproximation Treewidth Pathwidth, thereby obtaining Theorem 1.1.1.6 Previous Workreader may noticed, problems mentioned, best current algorithmsachieve similar poly-logarithmic approximation ratios. Given close relation,course surprising. algorithms obtained recursively applyingalgorithm c-balanced separator problem, objective find bipartitionvertices graph sides contain least c fraction vertices,number edges crossing partition minimized.pioneering work separators Leighton Rao (1999), O(log n) approximation algorithm c-balanced separator given, used design O(log2 n)approximation algorithm number graph layout problems MLA, MCLA,Register Sufficiency. Later, Rao Richa (1998) improved approximation algorithm MLA ratio O(log n log log n), using spreading metric method.groundbreaking work Arora et al. (2009),semidefinite programming used giveimproved approximation ratio O( log n) c-balanced separator. Usingideas,improved algorithms ordering problems found, O( log n log log n)approximation algorithm IGC MLA (Charikar et al., 2010),O( log n) approximation algorithm Treewidth (Feige et al., 2005) O( log n log n) approximationalgorithm Pathwidth (Feige et al., 2005).known Register Sufficiency problem (also known One-Shot Black Pebbling) admits O(log2 n) approximation algorithm (Ravi, Agrawal, & Klein, 1991).observe plugging improved approximation algorithm direct vertex separator (Agarwal, Charikar, Makarychev, &Makarychev, 2005) algorithm Ravi etal. (1991), one improve O( log n log n) approximation algorithm.Again, algorithms, approximation algorithm c-balanced separator playskey role. improved algorithm c-balanced separator also improve approximation algorithms problems. hand, hardness approximating577fiWu, Austrin, Pitassi, & Liuc-balanced separator (Raghavendra et al., 2012) necessarily imply hardnessapproximating layout problems.hardness side, work builds upon work Raghavendra et al. (2012),showed SSE Conjecture implies superconstant hardness approximationMLA (and c-balanced separator). hardness relative approximationaware problems result work Ambuhl et al. (2007),showing MLA PTAS unless NP randomized subexponential timealgorithms.1.7 Organizationoutline rest paper follows. Section 2, formally definelayout problems studied well Treewidth, Pathwidth, Minimum Fill-In.giving overview reductions used Section 3 give full proof Theorem 1.7Section 4. Then, Section 5 give lower bound Treewidth combinedresults Section 4 gives Theorem 1.1. Section 6 give lower boundMinimum Fill-In. Finally Section 7 give additional reductions pebblinginstances order achieve indegree 2 single sinks, promised Theorem 1.3.end concluding remarks Section 8.2. Definitions Preliminariesundirected graph G = (V, E), subsets S, 0 V , E(S, 0 ) denotes setedges go 0 . words, E(S, 0 ) set edges (u, v) Eu v 0 .2.1 Treewidth, Elimination Width, PathwidthDefinition 2.1 (Tree decomposition, Treewidth). Let G = (V, E) graph, tree,let V = (Vt )tT family vertex sets Vt V indexed vertices .pair (T, V) called tree decomposition G satisfies following three conditions:(T1) V = tT Vt ;(T2) every edge e E, exists endpoints e lie Vt ;(T3) every vertex v V , {t | v Vt } subtree .width (T, V) number max{|Vt |1 | }, Treewidth G, denotedtw(G), minimum width tree decomposition G.Definition 2.2. Let G = (V, E) graph, let v1 , . . . , vn orderingvertices. Consider following process: vertex vi order, add edges turnneighborhood vi clique, remove vi G. elimination orderingG. width elimination ordering maximum vi degree vivi eliminated. elimination width G minimum width eliminationorder.578fiInapproximability Treewidth Related ProblemsTheorem 2.3 (See e.g., Bodlaender, 2007). every graph G, elimination width Gequals tw(G).Thus Treewidth another example layout problem. principle layout problemformulated framework Section 2.3, choice cost functioninvolved vertex- edge-counting considered there.Definition 2.4 (Path decomposition, Pathwidth). Given graph G, say (T, V)path decomposition G tree decomposition G path. PathwidthG, denoted pw(G), minimum width path decomposition G.claimed earlier, Pathwidth fact equivalent graph layout problem. (Seenext section formal definition layout.)Theorem 2.5 (Kinnersley, 1992). every graph G, pw(G) = Layout(G; V, max).2.2 Minimum Fill-InDefinition 2.6 (Chordal, Triangulation). graph G chordal every cyclelength least 4 chord. (possibly non-chordal) graph G, triangulationG supergraph G chordal.Definition 2.7 (Minimum Fill-In). Minimum Fill-In graph G minimumnumber edges required add G triangulate it; i.e., resulting supergraphchordal.problem determining Minimum Fill-In graph sometimes calledChordal Graph Completion problem.perfect elimination ordering G elimination ordering edgesever added G. Put another way, vertex vi , neighbours appearingordering form clique.Theorem 2.8 (Fulkerson & Gross, 1965). graph G chordalperfect elimination ordering.Treewidth Minimum Fill-In related following theorem.Theorem 2.9 (Folklore). Suppose G graph Treewidth k. every triangulationG clique size k + 1.2.3 Graph Layout Problemssubsection, describe set graph layout problems consider. problemset described three parameters, giving rise several different problems.three parameters means interesting graph layout problems (andsettings give rise less uninteresting layout problems). However,sufficient capture problems interested except Treewidth, principlecould incorporated well though refrain order keep definitionssimple (see Section 2.1 details).579fiWu, Austrin, Pitassi, & LiuFirst word notation. Throughout paper, G = (V, E) denotes undirectedgraph, = (V, E) denotes directed (acyclic) graph. Letting n denote numbervertices graph, interested bijective mappings : V [n]. sayedge (u, v) E crosses point [n] (with respect permutation , alwaysclear context), (u) < (v).consider following variations:1. Undirected directed acyclic: case undirected graph G, orderingvertices feasible solution. case DAG D, topologicalorderings feasible solutions.2. Counting edges vertices: point [n] ordering, interestedset Ei () edges crossing point. counting edges, use cardinalityEi basic measure. counting vertices, count set verticesVi left incident upon edge crossing i. words, Viprojection Ei () left-hand side vertices. Formally:Ei () = {e E | (u) < (v) e = (u, v)}Vi () = {u V | (u) < (v) (u, v) E}refer |Ei ()| |Vi ()| (depending whether counting edges vertices)cost i.3. Aggregation sum max: given ordering , aggregate costspoint [n], either summation taking maximum cost.Given choices, objective find feasible ordering minimizesaggregated cost.Definition 2.10. (Layout value) graph H (either undirected graph G DAGD), cost function C (either E V ), aggregation function agg : R R (eithermax), define Layout(H; C, agg) minimum aggregated cost feasibleorderings H. Formally:Layout(H; C, agg) =minagg |Ci ()|.feasible i[n]Example 2.11.Layout(G; E, max) = min max |Ei ()|,i[n]ranges orderings V (G). recognize Section 1.5Minimum Cut Linear Arrangement value G.Example 2.12.Layout(D; V, max) = min max |Vi ()|,i[n]ranges topological orderings DAG D. shall see Section 2.4,precisely One-Shot Black Pebbling cost D.580fiInapproximability Treewidth Related ProblemsProblemundir. edgesumundir. edge maxundir.vertexsumundir.vertexmaxDAGedgesumDAGDAGDAGedgevertexvertexmaxsummaxAlso known / EquivalentMinimum/Optimal Linear ArrangementMinimum Cut Linear ArrangementCutWidthInterval Graph CompletionSumCutPathwidthOne-Shot Black-White PebblingMinimum Storage-Time SequencingDirected MLA/OLAOne-Shot Black PebblingRegister SufficiencyTable 1: Taxonomy Layout ProblemsCombining different choices gives rise total eight layout problems (somenatural others). Several appear literature one names,turn equivalent1 problems first sight appear different.summarize names Table 1. cases standard definitionsproblems look somewhat different definition given (e.g., Pathwidth,One-Shot Pebbling, Interval Graph Completion). Pebbling Pathwidthproblems, discuss equivalences definitions following two sections.Interval Graph Completion, recall Section 1.5 objective minimizeXmax max{(v) (u), 0}.uV(u,v)Ewords, counting longest edge going right point i.length edge l edge contributes 1 Vi (), . . . , Vi+l1 () henceobjective rewrittenX|Vi ()|,uVInterval Graph Completion precisely Layout(G; V, ).2.4 Pebbling Problemssection define pebbling problems one-shot versions.Definition 2.13. (Pebbling Configurations) Let = (V, E) directed acyclic graph(DAG). pebbling configuration pair (B, W ) (disjoint) subsets vertices(representing set B vertices black pebbles, set W verticeswhite pebbles them).1. Here, consider two optimization problems equivalent reductions changeobjective values additive constant.581fiWu, Austrin, Pitassi, & LiuDefinition 2.14. (Black Black-White Pebbling Strategies) Let = (V, E) directed acyclic graph. Black-White Pebbling strategy sequence pebble configurations P = {P0 , . . . , P } that:(i) first last configurations contain pebbles; P0 = P = (, ).(ii) sink vertex u pebbled least once, i.e., Pt = (Bt , Wt )u Bt Wt .(iii) configuration follows previous configuration one followingrules:(a) black pebble removed vertex.(b) black pebble placed pebble-free vertex v immediatepredecessors v pebbled.(c) white pebble placed pebble-free vertex.(d) white pebble removed vertex v immediate predecessors v pebbled.Black Pebbling Strategy G Black-White Pebbling strategy whitepebbles used.cost pebbling strategy cost(P) = max0t {|Bt Wt |}. Black-WhitePebbling cost minimum cost Black-White Pebbling strategy D,similarly Black Pebbling cost minimum cost Black Pebbling StrategyD.Definition 2.15. (One-Shot Black One-Shot Black-White Pebbling) One-Shot Black(resp. Black-White) pebbling strategy Black (resp. Black-White) Pebbling strategynode pebbled once. One-Shot Black (resp. Black-White) pebblingcost D, denoted BP1s (D) (resp. BWP1s (D)) minimum cost One-Shot Black(resp. Black-White) Pebbling strategy D.mentioned Table 1, One-Shot Pebbling problems formulated Layoutproblems.Lemma 2.16. every DAG = (V, E), BP1s (D) = Layout(D, V, max).Proof. Suppose optimal ordering Layout(D, V, max), pebble vertices according . remove pebble vertex u successorsu pebbled. Since topological order D, valid pebbling strategy.easy verify pebbling (i), number pebbles graph |Vi ()|.Therefore number pebbles used strategy Layout(D, V, max).hand, suppose optimal pebbling strategy, let ordering verticesreceive pebble . consider number pebbles graph pebblingi-th vertex . vertex u pebble, vertex successoryet pebbled, pebble u cannot removed, since u cannotpebbled again. Therefore number pebbles graph least |Vi ()|. ThusBP1s (D) maxi[n] |Vi ()| Layout(D, V, max).582fiInapproximability Treewidth Related ProblemsOne-Shot Black-White Pebbling, following reductions Lengauer(1981), showing One-Shot Black-White Pebbling equivalent undirected MaxVertex Layout Problem.Lemma 2.17 (Lengauer, 1981). given DAG = (V, E), let GD = (V, ED )undirected graph ED = {(v, w) | (v, w) E} {(v, w) | u, (v, u), (w, u) E}.BWP1s (D) = Layout(GD , V, max) 1.Lemma 2.18 (Lengauer, 1981). undirected graph G = (V, E), let DG = (V E, EG )DAG EG = {(v, e) | e E, v V, v e}.Layout(G, V, max) = BWP1s (DG ) + 2.2.5 Small Set Expansion Conjecturesection define SSE Conjecture. Let G = (V, E) undirected d-regulargraph. set V vertices, write G (S) (normalized) edge expansionS,|E(S, V \ S)|G (S) =d|S|Small Set Expansion Problem parameters , denoted SSE(, ), asks Gsmall set expand whether small sets highly expanding.Definition 2.19 (SSE(, )). Given d-regular graph G = (V, E) 2 , SSE(, ) problemdistinguishing following two cases:Yes V |S| = |V | G (S) .every V |S| = |V | holds G (S) 1 .problem introduced Raghavendra Steurer (Raghavendra & Steurer,2010), conjectured problem hard.Conjecture 2.20 (Small Set Expansion Conjecture). every > 0, > 0SSE(, ) NP-hard.become common conjecture like (such Unique Games Conjecture),say problem SSE-hard hard solve SSE problem. Formally,decision problem P (e.g., gap version optimization problem) SSE-hard> 0 every > 0, SSE(, ) polynomially reduces P.Subsequently, Raghavendra et al. (2012) showed SSE Problem turnreduced quantitatively stronger form itself. state stronger version, needfirst define Gaussian noise stability.Definition 2.21. Let [1, 1]. define : [0, 1] [0, 1]() = Pr X 1 () 1 ()1 inverse function normal distribution, X jointly normal1random variables mean 0 covariance matrix.12. constant583fiWu, Austrin, Pitassi, & Liuproperty shall need following well-known fact asymptoticbehaviour close 1 bounded away 0.Fact 2.22. (Raghavendra et al., 2012) constant c > 0 sufficientlysmall [1/10, 1/2],1 () (1 c ).state strong form SSE Conjecture.Conjecture 2.23 (SSE Conjecture, Equivalent Formulation). every integer q > 0, > 0, NP-hard distinguish following two cases given d-regulargraph G = (V, E)Yes partition V q equi-sized sets S1 , . . . , Sq G (Si ) 2every 1 q.every V , letting = |S|/|V |, holds G (S) 1 (1/2 () + )/.future reference, let us make two remarks strong form conjecture.Remark 2.24. Yes case Conjecture 2.23, number edges leaving Si|E(Si , V \ Si )|3 = G (Si )d|S| 4|E|/q.particular, total number edges contained one Si1X|E(Si , V \ Si )| 2|E|.2Remark 2.25. Using Fact 2.22 see that, case Conjecture 2.23,G (S) c0 ,constant c0 > 0, provided [1/10, 1/2] setting . particular,every |V |/10 |S| 9|V |/10, |E(S, V \ S)| c |E| (switching rolesV \ |S| > |V |/2), constant c > 0 (not constant Fact 2.22).3. Brief Overview Reductionssection, give brief overview reductions used prove layoutproblems Table 1 SSE-hard approximate within constant factor. fulldetails reductions found Section 4.two undirected edge problems (i.e., MLA MCLA), hardness followsimmediately strong form SSE Conjecture (Conjecture 2.23) caseMLA proved work Raghavendra et al. (2012) proof MCLAsimilar. starting point remaining problems. Unfortunately, results3. E(S1 , S2 ) indicates number edges vertex set S1 S2584fiInapproximability Treewidth Related ProblemsSSEProblemUndirected EdgeProblems (MLA/MCLA)expansionDirected ProblemsNice PebblingInstancesUndirected VertexProblemsTreewidthFigure 1: Overview Reductions. Dashed arrows indicate reduction obtainedidentity mapping, whereas solid arrows indicate nontrivial transformationone problem other.follow hardness MLA/MCLA black-box way; soundness analysesend use expansion properties original SSE instance.give reduction MLA/MCLA four directed problems. reduction simply creates bipartite graph vertex set union edgesvertices original graph G, directed arcs edge e vertices incidentupon e G. use direction crucial: essentially ensures vertexedge counts feasible ordering corresponds closely number edgescrossing point induced ordering G.obtain hardness remaining two undirected problems, perform similarreduction directed case, creating bipartite graph edge-vertex incidences.However, since creating undirected graph, longer force edgeschosen vertices upon incident, key propertyreduction directed case. order overcome this, duplicate original vertexlarge number times. gives huge penalties orderings essentiallyobey desired direction edges, makes reduction work out.results Treewidth, presented Section 5, follows additionalanalysis instances produced reduction undirected vertex problems.Finally, reduction directed problems, implying hardness One-Shot BlackPebbling, produce kind nice instances promised Theorem 1.3.Section 7, give additional transformation achieve properties.Figure 1 gives high-level overview reductions.4. Hardness Layout Problemssection, show layout problems defined Section 2.3 SSEhard approximate within constant factor. also shows PathwidthOne-Shot Pebbling problems hard approximate within constant.4.1 Hardness MCLA MLAsection, recall proof work Raghavendra et al. (2012) MLA,observe applies MCLA well. undirected graph G, let us write MCLA(G)585fiWu, Austrin, Pitassi, & Liu(resp., MLA(G)) MCLA value (resp., MLA value) G, i.e.,MLA(G) = Layout(G; E, ) = minX|Ei ()|i[n]MCLA(G) = Layout(G; E, max) = min max |Ei ()|.i[n]Theorem 4.1. every > 0, given graph G = (V, E), SSE-hard distinguishbetween:Yes MLA(G) O( |V | |E|) MCLA(G) O(|E|)every V |V |/10 |S| 9|V |/10, holds |E(S, V \ S)| ( |E|).particular, MLA(G) ( |V | |E|) MCLA(G) ( |E|).Proof. use instances Conjecture 2.23 q = 1/. Let G = (V, E)instance Conjecture 2.23.Yes case, disjoint sets S1 , . . . , Sq set Sj , |Sj | = n/q = n,G (Sj ) 2. give ordering : V [1, .., n] vertices maxi[n] |Ei ()|3|E| follows. Order vertices S1 , . . . , Sq (with order within Sj chosen arbitrary) let order . [n], show |Ei ()| 3|E|. Suppose1 (i) vertex Sj . edge Ei () either end-points inside Sj , endpoints two different Sk s. total number edges inside Sj dn/2 = |E|.Moreover, Remark 2.24, total number edges end-points two different Sk2|E|. Therefore, MCLA(G) maxi |Ei ()| 3|E|. MLA valuebounded similarly.property instance Conjecture 2.23 (via Remark 2.25),implications MLA MCLA values immediate.4.2 Reduction Directed GraphsGiven undirected graph G = (V, E), construct directed graph = (V 0 , E 0 )follows. order distinguish elements V E elements V 0 E 0 ,refer elements V vertices, elements E edges, elements V 0 nodes,elements E 0 arcs.node vertex edge G, i.e., V 0 = V E.graph bipartite bipartition V, E, arc e E v Ve incident upon v. Formally,V0 = V EE 0 = {(e, v) | e E, v V, v e}.See also Figure 2.remainder section devoted analyzing reduction. First, easygive upper bound four Layout values terms MLA MCLA valuesG.586fiInapproximability Treewidth Related Problemsuvvuw(u, v)Gw(u, w)Figure 2: reduction G D.Lemma 4.2. DAG constructed G satisfies following:Layout(D; E, ) (MLA(G) + O(|E|)) (d + 1)Layout(D; E, max) MCLA(G) + d.Note that, purposes applying graphs Theorem 4.1 error term|E| (resp. d) insignifcant compared MLA (resp. MCLA) value G.Proof. Consider ordering V . set vertices V , let u (S) denotevertex comes first ordering .extend ordering 0 V 0 inserting edge e = (u, v) immediatelyvertex u (e). easy see node z V 0 ,|Ez ( 0 )| |Eu (z) ()| +Ev () vertex v abbreviation E(v) (). immediately impliesLayout(D; E, max) max0 |Ez ( 0 )| max |Eu ()| + d,uVzVSetting optimal MCLA ordering G, obtain second claim Lemma.Similarly, using |u1(v)| + 1 every v V , getX XXXLayout(D; E, )|Ez ( 0 )| =|Ez ( 0 )| (d + 1)|Ev ()| + d|V 0 |,zV 0vVzV 0u (z)=vvVSetting optimal MLA ordering G using |V 0 | = O(|E|), obtain firstclaim Lemma.Next use Theorem 4.1 argue converse direction.Lemma 4.3. Let 0 < 1. Suppose G property every |V |/10 |S|9|V |/10 |E(S, V \ S)| ( |E|). Then,Layout(D; V, ) ( |E|2 )Layout(D; V, max) ( |E|)587fiWu, Austrin, Pitassi, & LiuProof. Let 0 ordering V 0 . Using expansion property Theorem 4.1, wellshow ordering must high cost. point [N ], let Si set verticesV appear 0 .bound Layout(D; V, max) immediate: consider point [N ]|Si | = |V |/2. expansion property |E(Si , V \ Si )| ( |E|), sinceedge e one endpoints point i, node e must appearpoint thus |Vi ( 0 )| |E(Si , V \ Si )| ( |E|).Let us turn Layout(D; V, ). Write ci fraction edges e appear(or at) point 0 . shall show whenever 1/5 ci 4/5, |Vi ( 0 )|( |E|), giving total Layout(D; V, ) ( |E|2 ).simple counting argument,d|Si | 2(1 ci )|E|,implying |Si | (1 ci )|V | ci 4/5 least 1/5 fraction vertices.addition |Si | 9|V |/10, argument gives |Vi ( 0 )| ( |E|). remaining case|Si | 9|V |/10. Si incident upon least 9/10 fraction edges.implies number edges incident upon Si , appearing 0 , least|E|(ci 1/10) ci 1/5 ( |E|).Combining Lemma 4.2 Lemma 4.3, Theorem 4.1, using fact edgecosts always larger corresponding vertex costs, immediately obtainfollowing theorem.Theorem 4.4. Given DAG D, Layout(D; E, max), Layout(D; E, ), Layout(D; V, max),Layout(D; V, ) SSE-hard approximate within constant factor, evenDAGs maximum path length 1 (i.e., every vertex source sink).Proof. Given graph G, Theorem 4.1 says SSE-hard distinguishYes MLA(G) O( |V | |E|) MCLA(G) O(|E|)every V |V |/10 |S| 9|V |/10, holds |E(S, V \ S)| ( |E|).particular, MLA(G) ( |V | |E|) MCLA(G) ( |E|).Applying reduction directed graphs, Lemma 4.2 tells us Yes case becomesLayout(D; E, ) (d + 1)O(|V ||E| + |E|) = O(|E|2 )Layout(D; E, max) O(|E|),Lemma 4.3 tells us case becomesLayout(D; V, ) ( |E|2 )Layout(D; V, max) ( |E|).thereby establishing hardness factor (1/ ) four problems (usingLayout(D; V, ) Layout(D; E, )).588fiInapproximability Treewidth Related Problemsu1 , . . . , uru(u, v)v(u, w)(w, v)wv1 , . . . , vrw1 , . . . , wrG0GFigure 3: reduction G G0 , illustrated r = 3.Remark 4.5. fact see that, Theorem 4.1, four hardness results applyinstance, SSE-hard distinguish four Layout values highlow.One-Shot Black Pebbling problem precisely Layout(D; V, max), obtain hardness One-Shot Black Pebbling immediate corollary. However, instancessingle-sink DAGs maximum indegree 2, promised Theorem 1.3. Section 7show transform instances obtain DAGs.4.3 Undirected Vertex Problemsreduction undirected vertex problems similar reduction directedproblems given previous section. before, introduce nodes every edgeG. directed case, interested orderings edge appearstwo endpoints, cannot use direction force anymore. Instead, ensureorderings like incur high cost replicating node correspondingvertex G many times.Given undirected graph G = (V, E), construct new graph G0 = (V 0 , E 0 )follows.r nodes G0 vertex one node edge G, i.e., V 0 =V [r] E. vertex u V write u1 , . . . , ur denote r copies u referset r nodes vertex group. graph G0 bipartite bipartitionV [r], E, edge G0 e E v V [r] e incident uponv. Formally,V 0 = {v | v V, [r]} {e | e E}E 0 = {(e, v ) | e E, v V, v e, [r]}.See also Figure 3.589fiWu, Austrin, Pitassi, & LiuLemma 4.6. graph G0 constructed G satisfies following:Layout(G0 ; V, ) (d + r) MLA(G)Layout(G0 ; V, max) MCLA(G).Proof. proceed proof Lemma 4.2. ordering V naturally inducesordering 0 V 0 : put r copies u V consecutively, vertices V appearingorder , insert edge e E immediately first vertex. Again,edge e E, let u (e) denote endpoint e appears first . Similarly,copy v V 0 v V , let u (v ) = v. easy see constructed ordering 0satisfies|Vz ( 0 )| |Eu (z) ()|every z V 0 . immediately impliesLayout(G0 ; V, max) max0 |Vz ( 0 )| max |Eu ()|,zVuVSimilarly, Lemma 4.2 use |u1()| + r getXXLayout(G0 ; V, )|Vz ( 0 )| (d + r)|Ev ()|.zV 0vVLemma 4.7. Let 0 < 1. Suppose G property every |V |/10 |S|9|V |/10 |E(S, V \ S)| ( |E|). Then, r |V | |E|,Layout(G0 ; V, ) ( r |V | |E|)Layout(G0 ; V, max) ( |E|)Proof. Let 0 ordering V 0 . First following simple claim, establishinggood orderings, vertices appear edges.Claim 4.8. Suppose vertex u V , least r/2 copies u G0 appearedge e = (u, v) E adjacent upon u.max |Vi ( 0 )| r/4 ( |E|)i[N ]X|Vi ( 0 )| (r/4)2 ( r |V | |E|).i[N ]Proof. Let I1 first half positions copies u appear e, I2second half. Thus, |I1 |, |I2 | r/4. element I1 contributes Vi ( 0 )I2 , giving claimed bounds.Thus may without loss generality assume vertex u V , least r/2r copies G0 appear edges adjacent upon u. on, let us discardr/2 bad copies vertex V appear edges.decreases cost 0 , still r|V |/2 vertex nodes left.Let i1 (first) point 0 r|V |/10 vertex nodes left i1 ,i2 (last) point 0 r|V |/10 vertex nodes right i2 .590fiInapproximability Treewidth Related ProblemsClaim 4.9. point i1 i2 , |Vi ( 0 )| ( |E|).Proof. Let V (resp. V ) set vertices u copy u appears|/10(resp. i). |S|, |T | r|Vr/2|V |/5, = V . Thuspartition V 0 S, 0 |S 0 |, |T 0 | 4|V |/5. expansionproperty G |E(S 0 , 0 )| ( |E|). Further, also |Vi ( 0 )| |E(S 0 , 0 )|e E(S 0 , 0 ) must appear 0 (because one endpoints S)edge crossing (because endpoints ).Claim 4.9, proof lemma follows immediately.previous section, combine Lemma 4.6 Lemma 4.7,Theorem 4.1, obtain:Theorem 4.10. Given graph G, Layout(G; V, max), Layout(G; V, ) SSE-hardapproximate within constant factor, even bipartite graphs.Pathwidth problem precisely Layout(G; V, max), obtain hardness Pathwidth immediate corollary. next section, well show stronger soundnessrequired Theorem 1.1.5. Hardness Treewidthsection shall complete proof Theorem 1.1 showing hard instancesPathwidth Theorem 4.10 also large Treewidth.Lemma 5.1. Let 0 < 1. Let G = (V, E) undirected graph propertyevery |V |/10 |S| 9|V |/10 |E(S, V \ S)| ( |E|), let G0 graphobtained applying reduction Section 4.3 G. Then, r |V | |E|,tw(G0 ) ( |E|)prove Lemma 5.1, shall use fact Treewidth graph closelyrelated expansion-like property called 1/2-separator number, defined workBodlaender et al. (1995).Definition 5.2 (1/2-vertex separator, 1/2-separator number). Let G = (V, E) undirected graph. W V , 1/2-vertex separator W G set V verticesevery connected component graph G[V S] contains |W |/2 verticesW . Let G (1/2, W ) denote minimum size 1/2-vertex separator W G.define 1/2-separator number K1/2 (G)K1/2 (G) = max G (1/2, W ).W VLemma 5.3 (Bodlaender et al., 1995). every graph G = (V, E), holds tw(G)K1/2 (G) 1.Using this, straightforward prove lower bound Treewidth.591fiWu, Austrin, Pitassi, & LiuProof Lemma 5.1. Well show G0 (1/2, V 0 ) ( |E|) (i.e. choose W = V 0 ).Suppose C optimal 1/2-vertex separator V 0 separates V 0 \ C l setsV10 , . . . , Vl0 , size |V 0 |/2. merge two sets V10 , . . . , Vl0 combiningvertex set them. merging different Vi0 may assume two setsV10 V20 , size least |V 0 |/5 (this achieved always merging two setssmallest number vertices, whever two sets left).Now, similarly proof Claim 4.9, let V (resp. V ) set verticesv copy V appears V10 (resp. V20 ). |V10 |, |V20 | r|V |/5, implies|S|, |T | least |V |/5, furthermore = V (since otherwise r copiesvertex C, implying |C| r ( |E|)). thus choose balancedpartition 0 , 0 0 S, 0 , |E(S 0 , 0 )| ( |E|). everyedge e = (u, v) u 0 v 0 must belong C, since connected (in G0 )every copy u v.6. Hardness Minimum Fill-Insection, use previous construction results Treewidth prove inapproximability Minimum Fill-In. Specifically, show applying constructionSSE instances produces graphs high Minimum Fill-In, Yes instancesyields graphs low Minimum Fill-In.Lemma 6.1. Let 0 < 1. Let G = (V, E) undirected graph propertyevery |V |/10 |S| 9|V |/10 |E(S, V \ S)| ( |E|), let G0graph obtained applying reduction Section 4.3 G. Then, r |V | |E|, least(|E|2 ) edges must added triangulate G0 .Proof. use observation G0 bipartite. Consider minimum triangulationG, must clique size tw(G0 ) + 1. Lemma 5.1, one set bipartitionG must ( |E|) vertices clique, since vertices independentG0 , (|E|2 ) edges must added.Note lemma holds independently choice q. prove goodupper bound Yes instances.Lemma 6.2. Let > 0 q = 1/2 . Let G = (V, E) d-regular graph, supposepartition V q equi-sized sets S1 , . . . , Sq G (Si ) 2 every1 q.Let G0 = (V 0 , E 0 ) graph obtained applying reduction Section 4.3 G.G0 triangulation |E 0 | + O(2 |E|2 ) edges.Suppose G = (V, E) Yes instance Conjecture 2.23 parameters q, ,q = 1/2 , apply previous construction r |V | |E| get graph G0 = (V 0 , E 0 ).G0 triangulation |E 0 | + O(2 |E|2 ) edges.Proof. Note suffices find good ordering vertices G0 closeperfect elimination ordering, i.e., requires additional edges turnperfect elimination ordering. i, define setEi = {(u, v) E | u, v Si }.592fiInapproximability Treewidth Related ProblemsAlso define set cut edges Ec = {(u, v) E | u Si , v Sj , 6= j}. Clearly, Eitogether Ec form partition E. define subsets Ec Eci = E(Si , V \Si ),set cut edges Si . definition Si , G (Si ) 2, hence |Eci |4|E|/q = 43 |E|. Well identify Ei Ec subsets constructed graph.let ordering V 0 r|V | vertex copies appear first (inorder), followed sets E1 , . . . , Eq , Ec order, within set vertexorder arbitrary. consider following supergraph H G0 obtained by:making set Ei Eci cliquemaking Ec clique/Claim 1: adds O(2 |E|2 ) edges.|Note |Ei Eci | d|Si | = d|V= 2 |E|q2 . Thus making Ei Ec clique requires142O( |E| ) edges. Since q = 2 cliques total, requires O(2 |E|2 )edges total. Finally, Remark 2.24, |Ec | 2|E|, making clique takes O(2 |E|2 )edges well.Claim 2: Adding edges makes perfect elimination ordering H.Consider vertex copy v k X. neighbours H edges incidentv; v Si , edges must Ei Eci . every vertex X satisfiesperfect elimination property. consider (u, v) Ei . edge neighboursEi Eci . Finally, every edge vertex (u, v) Ec , neighbours appearrespect also Ec .Putting two claims together yields desired result.Combining two lemmas prove Theorem 1.2.7. Nicer Pebbling Instancessection show transform hard instances One-Shot Black Pebblingin-degree bounded 2 single sinks.Lemma 7.1. Given DAG = (V, E) polynomial time construct DAGD0 = (V 0 , E 0 ) D0 single sinkBP1s (D) BP1s (D0 ) BP1s (D) + + 1,number sinks D. Furthermore, maximum in-degree D0larger maximum in-degree D, provided quantity least 2.Proof. Construct D0 adding binary tree leaves D, identifying leavestree sinks D. is, D0 consists binary tree leaves topcopy leaves binary tree identified sinks D.number vertices D0 equal |D| + |s| 1. Note binary tree leavessuffice. properties D0 easily verified. Since D0 super-DAG D,pebbling cost must least BP1s (D). Conversely, valid pebbling D0 obtainedusing One-Shot Pebbling without removing pebbles sinks,pebbling tree.593fiWu, Austrin, Pitassi, & LiuFigure 4: Pyramid size 4in-degree, prove following.Lemma 7.2. Given DAG = (V, E) polynomial time construct DAGD0 = (V 0 , E 0 ) every node D0 in-degree 2BP1s (D) BP1s (D0 ) BP1s (D) + d,maximum in-degree D. Furthermore, single sinkD0 .proving Lemma 7.2, let us see use two Lemmas derive Theorem 1.3.Proof Theorem 1.3. (the proof of) Theorem 4.4, reduction takesinstance (G = (V, E) Conjecture 2.23 produces dag BP1s (D) =Layout(D; V, max) = O(|E|) G Yes instance, BP1s (D) = ( |E|) Ginstance. number sinks |V | = 2|E|/d, much smaller O(|E|)provided 1/ (which may assumed without loss generality). maximum indegree maximum degree G = O(1). Applying reductionLemma 7.1 reduction Lemma 7.2 obtain dag D0 single sinkin-degree 2 BP1s (D) BP1s (D0 ) BP1s (D) + + 2|E|/d. Since + 2|E|/dO(|E|) BP1s (D), conclude SSE-hard distinguish BP1s (D0 )O(|E|) BP1s (D0 ) ( |E|).7.1 Lemma 7.2section prove Lemma 7.2. First, recall definition pyramid graph.Definition 7.3. pyramid graph size layered graph indegree two, layers,labelled 0, 1, . . . , d1. Layer zero (the input layer) consists vertices, layer containsvertices. Call vertices layer vi1 , . . . vidi . i, 1 1, 1 j i,jj+1Vertex vij incoming edges vertices vi1vi1. See Figure 4.reduction Lemma 7.2 produce DAGs indegree 2 follows. Construct D0replacing vertex u pyramid Pu size d(u) (here, d(u) denotes indegreeu), d(u) vertices layer 0 Pu identified predecessors u, uidentified vertex layer d(u) 1 Pu . See Figure 5.594fiInapproximability Treewidth Related Problemsu1v1v2v3u2v4v5u1v6v7v1v2u2v3v4v5v6v7Figure 5: Reduction DAGs indegree 2prove lemma need show D0 constructed way satisfiesBP1s (D) BP1s (D0 ) BP1s (D) + d,maximum indegree vertex u D.follows whenever say pebbling strategy D0 always referOne-Shot Black Pebbling strategy D0 .upper bound BP1s (D0 ) trivial: valid pebbling strategy D,clearly create corresponding pebbling strategy D0 pebblingpyramid whenever pebbles sink pyramid. takes additionalpebbles.direction, want show pebbling strategy D0 convertedpebbling strategy D. first show D0 assumed particularnormal form, using normal form, show simulate pebbling.Definition 7.4. Let 0 pebbling strategy D0 . is, 0 sequence configurations, configuration set black pebble placements,sequence configurations follows black pebbling rules. say configurationc 0 saturated respect pyramid Pu c first time 0black pebble path cutting sink Pu sources Pu . (The cutinclude sources sink Pu .) Note cut size 1.Claim 7.5. Let 0 pebbling strategy D0 . assume without loss generality0 following normal form. configuration c0 0 , c0 saturatedrespect pyramid Pu , subsequent moves 0 pebble sink Pu (in obviousway), removing black pebbles internal nodes Pu .Proof Sketch. show pebbling strategy converted normal formstrategy pebbling cost. saturated configuration c0 , must 1pebbles internal nodes Pu . subsequently pebble sink p, never use1 pebbles internal nodes p, pebbles graph staywere. Thus normal form use pebbles original strategy.Furthermore, since internal nodes pyramid used pebble sinkpyramid, lost anything pebbling sink removinginternal black pebbles.595fiWu, Austrin, Pitassi, & Liuassume pebbling 0 D0 normal form. is,configuration saturated (with respect pyramid Pu ), next thing happens0 pebble sink Pu . (After pebbling sink, touched whateverpebbles source nodes Pu , pebble sink node Pu ,internal pebbles Pu .)strategy constructing pebbling, S, D, given normal form pebbling, 00follows. node v D, pebble v whenever first pebbled 0 ,remove pebble v soon successors v (in original graph D) pebbled.want argue cost pebbling strategy greater 0 .see this, use following Lemma.Lemma 7.6. minimal-length One-Shot Black Pebbling size pyramid,number pebbles pyramid point time, sources pebbled,must least number sources pyramid pebbled far.Assuming Lemma clear 0 normal form pebbling D0 ,pyramid Pu D0 , configuration c0 , k pebbles Pu c0 ,corresponding configuration c D, k pebbles source nodesPu . see this, first notice Lemma, time pyramid pebbledD0 time source nodes pyramid pebbled first time,number pebbles pyramid least large number sourcenodes contain pebbles. normal form property D0 , soonsource nodes D0 pebbled first time, strategy pebbles sink D0 ,thus number corresponding pebbles never greater numberpebbles D0 .Proof Lemma 7.6. Let P size pyramid graph, let One-Shot BlackPebbling P . Let c configuration occurring set source nodespebbled c source nodes P 0 , P 0 size d0 subpyramid P . want argue c must contain least d0 pebbles. Assume withoutloss generality P 0 leftmost sub-pyramid P , size d0 < (with source0vertices v01 , . . . , v0d .) Consider outer rightmost vertices P 0 vertices labels00vd10 1 , vd20 2 , . . . , v1d 1 , v0d . Relabel outer rightmost vertices P 0 vd1 , ..., v0 ,vd1 sink vertex P 0 , < 1, vi rightmost vertex P 0 level i.Corresponding named vertex vi diagonal set vertices, diag(vi ), beginningvi travelling southwest source vertex P 0 . Note sets diag(vi ) pairwisedisjoint. argue i, 0 1, least one vertex diag(vi ) mustappear c. see this, first notice vi , vertex vi0 immediatesuccessor vi lies outside P 0 . vertex vi0 must pebbled point,furthermore must pebbled time configuration c, since pebbling vi0requires pebbling source vertex P P 0 , source verticespebbled far source vertices P 0 . order pebble vi0future, minimal-length pebbling, must black pebble vertexdiag(vi ) c. (In minimal-length pebbling graph G, set configurationsremoved pebbling, results longer black pebbling G.) Thus,shown c configuration d0 < source vertices pebbled thusfar, must d0 vertices pebbled c.596fiInapproximability Treewidth Related Problems8. Conclusion Open Problemsproved SSE-hardness approximation variety graph problems. importantly obtained first inapproximability result Treewidth problemMinimum Fill-In.remarks order. status SSE conjecture is, point time,uncertain, results therefore taken absolute evidencepolynomial time approximation algorithm (e.g.) Treewidth. However,least, results give indication difficulty involved obtainingalgorithm Treewidth, builds connection two important problems.also find remarkable simple reductions proofs are. leave choicewhether view healthy sign strength SSE Conjecture, whetherview indication conjecture strong, reader.many important open questions natural avenues work, including:1. seems plausible results extended wider range graph layoutproblems. instance, two choices aggregators max viewedtaking ` `1 norms, seems likely results would apply `pnorm (though aware previous literature studying variants).2. would nice obtain hardness approximation result problems basedweaker hardness assumption UGC. conjectured workRaghavendra et al. (2012) SSE conjecture equivalent UGC. Alternatively,would nice show hardness problems imply hardnessSSE Problem.3. pebbling, would interesting obtain results unrestricted pebbling problems (for finding exact pebbling cost even PSPACE-hard).far aware, nothing known problems, even, say, whether oneobtain non-trivial approximation NP. mentioned introduction,currently working extending One-Shot Pebbling results bounded timepebblings. preliminary progress hopeful relaxpebbling results much larger class pebblings.AcknowledgmentsResearch supported NSERC.ReferencesAgarwal, A., Charikar, M., Makarychev, K., & Makarychev, Y. (2005). O( logn) approximation algorithms min UnCut, min 2CNF deletion, directed cut problems.Proceedings thirty-seventh annual ACM Symposium Theory computing,STOC 05, pp. 573581, New York, NY, USA. ACM.597fiWu, Austrin, Pitassi, & LiuAmbuhl, C., Mastrolilli, M., & Svensson, O. (2007). Inapproximability Results SparsestCut, Optimal Linear Arrangement, Precedence Constrained Scheduling. Proceedings 48th Annual IEEE Symposium Foundations Computer Science,FOCS 07, pp. 329337, Washington, DC, USA. IEEE Computer Society.Amir, E. (2001). Efficient approximation triangulation minimum treewidth. Proceedings 17th Conference Uncertainty Artificial Intelligence, pp. 715.Morgan Kaufmann Publishers.Arnborg, S., Corneil, D. G., & Proskurowski, A. (1987). Complexity finding embeddingsk-tree. SIAM J. Algebraic Discrete Methods, 8, 277284.Arora, S., Barak, B., & Steurer, D. (2010). Subexponential algorithms unique gamesrelated problems. Annual Symposium Foundations Computer Science,FOCS 10, pp. 563572.Arora, S., Lund, C., Motwani, R., Sudan, M., & Szegedy, M. (1998). Proof verificationhardness approximation problems. J. ACM, 45 (3), 501555.Arora, S., Rao, S., & Vazirani, U. (2009). Expander flows, geometric embeddings graphpartitioning. J. ACM, 56, 5:15:37.Arora, S., & Safra, S. (1998). Probabilistic checking proofs: new characterization np.J. ACM, 45 (1), 70122.Barak, B., Raghavendra, P., & Steurer, D. (2011). Rounding semidefinite programminghierarchies via global correlation. ECCC Report TR11-065.Bodlaender, H. L., Gilbert, J. R., Hafsteinsson, H., & Kloks, T. (1995). Approximatingtreewidth, pathwidth, frontsize, shortest elimination tree. Journal Algorithms,18 (2), 238255.Bodlaender, H. (2007). Treewidth: Structure algorithms. Prencipe, G., & Zaks, S.(Eds.), Structural Information Communication Complexity, Vol. 4474 LectureNotes Computer Science, pp. 1125. Springer Berlin / Heidelberg. 10.1007/978-3540-72951-8 3.Bodlaender, H. L. (1996). linear-time algorithm finding tree-decompositions SmallTreewidth. SIAM Journal Computing, 25 (6), 13051317.Bodlaender, H. L. (2005). Discovering treewidth. SOFSEM, pp. 116.Bouchitte, V., & Todinca, I. (2003). Approximating treewidth at-free graphs. DiscreteApplied Mathematics, 131 (1), 1137.Charikar, M., Hajiaghayi, M., Karloff, H., & Rao, S. (2010). l22 spreading metrics vertexordering problems. Algorithmica, 56, 577604.Dubey, C. K., Feige, U., & Unger, W. (2011). Hardness results approximatingbandwidth. J. Comput. Syst. Sci., 77 (1), 6290.Feige, U., Hajiaghayi, M., & Lee, J. R. (2005). Improved approximation algorithmsminimum-weight vertex separators. Proceedings thirty-seventh annual ACMSymposium Theory computing, STOC 05, pp. 563572, New York, NY, USA.ACM.598fiInapproximability Treewidth Related ProblemsFomin, F. V., & Villanger, Y. (2012). Subexponential parameterized algorithm minimumfill-in. Proceedings Twenty-Third Annual ACM-SIAM Symposium DiscreteAlgorithms, SODA 12, pp. 17371746. SIAM.Fulkerson, D. R., & Gross, O. A. (1965). Incidence matrices interval graphs. PacificJournal Mathematics, 15, 835855.Guruswami, V., & Sinop, A. K. (2011). Lasserre hierarchy, higher eigenvalues, approximation schemes quadratic integer programming psd objectives..Hastad, J. (1999). Clique hard approximate withinn 1- . Acta Mathematica, 182 (1),105142.Hastad, J. (2001). optimal inapproximability results. J. ACM, 48 (4), 798859.Heggernes, P. (2006). Minimal triangulations graphs: survey. Discrete Mathematics.Kaplan, H., Shamir, R., & Tarjan, R. E. (1994). Tractability parameterized completion problems chordal interval graphs: Minimum fill-in physical mapping(extended abstract). SIAM J. Comput, 28, 780791.Khot, S., & Regev, O. (2008). Vertex cover might hard approximate within 2- .Journal Computer System Sciences, 74 (3), 335349.Khot, S., & Vishnoi, N. (2005). unique games conjecture. Annual SymposiumFoundations Computer Science, Vol. 46 FOCS 05, p. 3. IEEE COMPUTERSOCIETY PRESS.Khot, S. (2002). power unique 2-prover 1-round games. Proceedingsthiry-fourth annual ACM Symposium Theory Computing, STOC 02, pp. 767775, New York, NY, USA. ACM.Kinnersley, N. G. (1992). vertex separation number graph equals path-width.Information Processing Letters, 42 (6), 345350.Kirousis, L. M., & Papadimitriou, C. H. (1986). Searching pebbling. Theor. Comput.Sci., 47, 205218.Kloks, T. (1994). Treewidth: computations approximations, Vol. 842. Springer.Koller, D., & Friedman, N. (2009). Probabilistic Graphical Models: Principles Techniques. MIT press.Leighton, T., & Rao, S. (1999). Multicommodity max-flow min-cut theorems usedesigning approximation algorithms. J. ACM, 46, 787832.Lengauer, T. (1981). Black-white pebbles graph separation. Acta Informatica, 16,465475. 10.1007/BF00264496.Lengauer, T., & Tarjan, R. E. (1982). Asymptotically tight bounds time-space trade-offspebble game. J. ACM, 29, 10871130.Natanzon, A., Shamir, R., & Sharan, R. (1998). polynomial approximation algorithmminimum fill-in problem. Proceedings thirtieth annual ACM SymposiumTheory Computing, STOC 98, pp. 4147, New York, NY, USA. ACM.Nordstrom, J. (2010). New wine old wineskins: survey pebbling classicssupplemental results. Draft manuscript.599fiWu, Austrin, Pitassi, & LiuRaghavendra, P. (2008). Optimal algorithms inapproximability results every csp?.Proceedings 40th annual ACM Symposium Theory computing, pp. 245254. ACM.Raghavendra, P., & Steurer, D. (2010). Graph expansion unique games conjecture.Proceedings 42nd ACM Symposium Theory computing, STOC 10, pp.755764, New York, NY, USA. ACM.Raghavendra, P., Steurer, D., & Tulsiani, M. (2012). Reductions Expansion Problems. IEEE Conference Computational Complexity.Ramalingam, G., & Rangan, C. P. (1988). unified approach domination problemsinterval graphs. Inf. Process. Lett., 27, 271274.Rao, S., & Richa, A. W. (1998). New approximation techniques ordering problems.Proceedings ninth annual ACM-SIAM Symposium Discrete Algorithms,SODA 98, pp. 211218, Philadelphia, PA, USA. Society Industrial AppliedMathematics.Ravi, R., Agrawal, A., & Klein, P. (1991). Ordering problems approximated: single-processorscheduling interval graph completion. Albert, J., Monien, B., & Artalejo, M.(Eds.), Automata, Languages Programming, Vol. 510 Lecture Notes Computer Science, pp. 751762. Springer Berlin / Heidelberg. 10.1007/3-540-54233-7180.Reed, B. A. (1992). Finding approximate separators computing tree width quickly.Proceedings Twenty-fourth Annual ACM Symposium Theory Computing,STOC 92, pp. 221228, New York, NY, USA. ACM.Robertson, N., & Seymour, P. D. (1984). Graph minors. III. Planar tree-width. J. Comb.Theory, Ser. B, 36 (1), 4964.Robertson, N., & Seymour, P. D. (1986). Graph minors. II. Algorithmic aspects treewidth. Journal Algorithms, 7 (3), 309322.Roth, D. (1996). hardness approximate reasoning. Artificial Intelligence, 82 (1),273302.Sethi, R. (1973). Complete register allocation problems. Proceedings fifth annualACM Symposium Theory computing, STOC 73, pp. 182195, New York, NY,USA. ACM.Seymour, P. D., & Thomas, R. (1994). Call routing ratcatcher. Combinatorica,14 (2), 217241.600fiJournal Artificial Intelligence Research 49 (2014) 705-731Submitted 12/13; published 4/14Convergence Q-learning VariantContinuous States ActionsStephen Cardencarden@clemson.eduDepartment Mathematical Sciences,Clemson UniversityAbstractpaper presents reinforcement learning algorithm solving infinite horizonMarkov Decision Processes expected total discounted reward criterionstate action spaces continuous. algorithm based Watkins Q-learning,uses Nadaraya-Watson kernel smoothing generalize knowledge unvisited states.expected, continuity conditions must imposed mean rewards transitionprobabilities. Using results kernel regression theory, algorithm proven capableproducing Q-value function estimate uniformly within arbitrary tolerancetrue Q-value function probability one. algorithm appliedexample problem empirically show convergence well.1. IntroductionMarkov Decision Process (MDP) stochastic control problem, usually considereddiscrete time. time step, system state controller chooses action.system transitions new state probability distribution dependsprevious state action utilized. reward (or cost, authors)also received. rewards allowed random variables distributiondepends state action utilized. goal find policy (a functionmaps states actions) maximizes rewards (or minimizes costs) accordingmeasure goodness. consider MDPs terminal, absorbingstates. case, common optimality criterion expected total discounted reward.MDPs criterion finite state-action spaces well studied.state transition probabilities reward means known, dynamic programmingmethods obtain optimal policy finite number steps (Ross, 1992). However,probabilities rewards initially unknown transitions rewards simulatedobserved, problem becomes much difficult, one amenable methodsreinforcement learning.Watkins (1989) developed Q-learning, novel popular algorithm learningvalue state-action pair optimal policy without explicitly calculating transitionprobabilities mean rewards. values used construct optimalpolicy. finite number states actions, learned values provenconverge true values. However, problems large number statesactions may cause values converge unreasonably slowly. Furthermore, numberstate-action pairs infinite, convergence guarantee longer holds. naturalquestion whether knowledge gained observation generalized usingfunction approximators similar states actions, whether state-action valuesc2014AI Access Foundation. rights reserved.fiCardenstill converge, either theoretically empirically. immediacy question apparenteven Watkins thesis (1989), form function approximation, CMAC (Albus,1975), used solution two example problems large number state-actionpairs.Function approximators reinforcement learning may cause value estimates convergesuboptimal values (Bertsekas, 1995), oscillate (Gordon, 1996), even diverge (Fairbank& Alonso, 2012; Tsitsiklis & Van Roy, 1996). However, used carefully, alsoimpressively effective. famous example success large yet finite state-actionspace TD-Gammon program (Tesauro, 1995), used temporal difference learning(Sutton, 1988) neural network generalize knowledge. eventually learnedcompetitive tournament-level human backgammon players. Scenarios continuousstates finite actions well studied. Empirical convergence observedCMACs (Sutton, 1996), neural networks (Rummery & Niranjan, 1994; ten Hagen,1991), regression trees (Ernst et al., 2005). Theoretically, positiveresults well. parametric function approximator yield convergent results satisfiescertain interpolation properties (Szepesvari & Smart, 2004). non-parametric technique,kernel regression, also proven converge optimal values (Ormoneit & Sen,1999).Problems states actions allowed continuousless well-studied. One major reason constructing policy requires takingsupremum possible actions, straightforward actions finitegenerally difficult continuous. difficulty, though present, preventedresearchers developing techniques make process manageable. One methodcalculate values discrete set actions, use weighted average producecontinuous valued action (Millan et al., 2002). Baird Klopf (1993) specifically designedfunction approximator, termed wire-fitting, supremum actionspace immediately obtained. Wire-fitting combined neural networkslearn thruster-control order drive submersible target success (Gaskettet al., 1999). Algorithms allowing stochastic policies rapidly choose actionsprobability distribution, Sequential Monte Carlo Learning (Lazaric et al., 2008).Despite practical success algorithms, little theoreticalinvestigation convergence properties actions continuous. purposepaper present is, knowledge, first off-policy Q-learning variantallowing continuous state actions proven converge optimal valuesprobability one. Specifically, state action spaces allowed infinitecompact subsets Euclidean space, sufficiently small kernel regressionbandwidth suitable continuity conditions random rewards transition probabilities, one may obtain Q-value function estimate uniformly within arbitrarytolerance true Q-value function. Though intention algorithm filltheoretical gap, results proof-of-concept example implementation provided.particular method knowledge generalization Nadaraya-Watson kernel regression, memory-based non-parametric smoothing technique well-studied properties. similar function approximators used Ormoneit Sen (1999)Santamara et al. (1996). distinction made Nadaraya-Watson kernelregression use kernel functions so-called kernel trick context706fiA Continuous Action Q-learning Variantreinforcement learning. methods similar use kernel functiondeliver non-linear regression results kernel based weighted sums, intermediatemethodologies quite different. See work Taylor Parr (2009) discussionkernelized value function methods, work Xu et al. (2007) applicationkernelized regression policy iteration.Section 2, Markov Decision Processes defined. Section 3 introduces NadarayaWatson kernel regression describes algorithm uses kernel smoothing obtainfunction estimates Q-value state-action pair. main resultpaper, theoretical convergence continuous state action algorithm, statedSection 4 along sufficient conditions convergence. Section 5 describes strategyproof, proves set lemmas, finally proves main result. exampleimplementation along discussion practical difficulties Section 6. Finally,Section 7 concludes ideas extensions.2. Description Continuous Markov Decision Processassumed reader familiar basic theory discrete Markov DecisionProcesses. introduction, recommend texts Puterman (1994) Ross(1992). paper consider Markov Decision Processes state actionspaces discrete, compact subsets Euclidean space. Let S, statespace, compact subset Euclidean space dimension dS B(S) Borel algebra S. Let A, action space, compact subset Euclidean space dimensiondA . Note subset Rd = dS + dA . Elements spacewritten (s, a) make state action clear, computational purposesbest regarded numerical vectors. Transitions states governedfunction P : B(S) R+ satisfying:B B(S), P (, B, a) : R+ measurable function.A, P (s, , a) : B(S) R+ probability measure S.B B(S), P (s, B, ) : R+ measurable function.state action (s, a) random reward R(s, a) bounded constantC0 .Markov Decision Process proceeds follows: process begins statecontroller chooses action A. random reward R(s, a) receivedsystem transitions new state accordance probability measure P (s, , a).system progresses next time step, scenario repeats new state.reward distributions transition probabilities assumed Markov property:depend current state action; depend historyprevious states actions.policy measurable function : A. settings, policies allowedstochastic non-stationary, restrict attention deterministic policies.Define P (s, B) := P (s, B, (s)). P transition kernel Markov chainspace S.707fiCardenLet , 0 < < 1, discount factor. Let (st , ) (random) state actiontime t. policy , value state defined expected totaldiscounted reward criterion:"#XV (s) = ER(st , (st ))|s0 = .t=0policy optimal satisfies V (s) = sup V (s), S.goal find algorithm will, suitable conditions, convergeoptimal policy. end, define Q-valuesZQ (s, a) := E[R(s, a)] +V (t)P (s, dt, a).continuous version discrete definition made Watkins (1989). IntuitivelyQ (s, a) value obtained start state s, utilize action a, follow policythereafter. Consider Q-values associated optimal policy : Q (s, a) :=Q (s, a). learn values Q (s, a) (s, a), optimal policy easilyrecovered setting(s) = argsup Q (s, a).aA3. Description Algorithmsection introduce form function approximator used,describe algorithm generate sequence estimates optimal Q-values.3.1 Nadaraya-Watson Kernel RegressionNadaraya-Watson kernel regression (Watson, 1964; Nadaraya, 1964) smoothing technique estimates value point weighted average nearby observations,using non-negative kernel function assign weights observations based distance. Kernels typically symmetric, peak zero, decrease away zeroweight observation inversely related distance. Formally, requireK : Rd R+ multivariate function satisfying:RKI. K integrable: Rd K(u)du < .KII. K bounded: ||K|| < CK < .KIII. K compact support: exists L <K(u) = 0 ||u|| > L.KIV. K Lipschitz: exists < u, u0 Rd ,|K(u) K(u0 )| ||u u0 || .708fiA Continuous Action Q-learning Variantcompact support condition required applications (indeed, Gaussianfunction common kernel choice) used reduce computation loadassigning zero weight sufficiently distant observations.bandwidth h > 0 parameter used fine-tune level smoothing. DefineKh (u) :=1K(u/h).hu non-scalar, division may understood component-wise. Values hlarge small relative sample size tend oversmooth overfit data.Typically using kernel regression bandwidth decreases toward zero numberobservations increases. discussion particulars bandwidth selection beyondscope paper, rule thumb obtained assuming Gaussian density1unit variance h = n 4+d , n number observations dimension(Hardle, 2004). rule thumb regarded starting value, definitiveanswer. example, cross-validation common method selecting bandwidths.information, interested reader referred texts Silverman (1986)Simonoff (1996). purpose algorithm follow, need constantbandwidth sufficiently small.Given set n ordered pairs (xi , yi ) bandwidth h, Nadaraya-Watson estimatorPnKh (x xi )yich (x) = Pi=1.ni=1 Kh (x xi )3.2 Algorithmuse following notation. n > 0,h fixed bandwidth.fixed discount factor.(sn , ) state-action pair beginning iteration n.rn sample reward observed iteration n.un state transitioned iteration n.b h,n1 (un , a), Qb h,n1 (un , a) defined (2).yh,n := rn + supaA Qdescription algorithm.b h,0 (s, a) = 01. Set initial Q-value estimate function zero everywhere. Q(s, a) A. Choose initial state s1 .2. n > 0, pick action -greedily (or according explorationmethod). Define function h,n : [0, 1]PP Kh ((s, a) (sn , ))nj=1 Kh ((s, a) (sj , aj )) 6= 0nh,n (s, a) =(1)j=1 Kh ((s, a) (sj , aj ))P0nj=1 Kh ((s, a) (sj , aj )) = 0709fiCardenuse update Q-value estimate function settingb h,n (s, a) := (1 h,n (s, a))Qb h,n1 (s, a) + h,n (s, a)yh,n .Q(2)Set sn+1 = un .Note result Equation (2), one may show inductionPnPj=1 Kh ((s, a) (sj , aj ))yh,jPnj=1 Kh ((s, a) (sj , aj )) 6= 0nj=1 Kh ((s, a) (sj , aj ))b h,n (s, a) =PQbQh,0 (s, a)nj=1 Kh ((s, a) (sj , aj )) = 0.(3)Equation (2) updates conceptually performed form familiarclassic Q-learning, Equation (3) calculations made. estimatesproduced algorithm essentially kernel-smoothed averages terms yh,n :=b h,n1 (un , a).rn + supaA QAlgorithm 1 Pseudocode theoretical algorithmInitialize h = bandwidth value, = maximum iterations,= discount factor, = exploration parameterb h,0 (s, a) = 0 (s, a)Initialize QSet initial state s1i=1:mr = Uniform(0,1) random valuer < ai = random actionelseb h,n1 (si , a)ai = supaA Qendui = next state, ri = rewardb h,i1 (ui , a)yh,i := ri + supaA QPij=1 Kh ((s,a)(sj ,aj ))yh,jb h,i (s, a) = PQsi+1 = uiendj=1Kh ((s,a)(sj ,aj ))4. Statement TheoremAssume following conditions hold:AI. state-action pair utilized beginning iteration (regardedrandom variable due exploration random transitions) density f :R positive everywhere uniformly continuous bounded secondderivatives.AII. Rewards bounded. exists C0 < (s, a) A,R(s, a) < C0 .710fiA Continuous Action Q-learning VariantAIII. expected values rewards Lipschitz continuous across state-actionspace. exists Cr (s1 , a1 ), (s2 , a2 ) A,|E[R(s1 , a1 )] E[R(s2 , a2 )]| Cr ||(s1 , a1 ) (s2 , a2 )||.Also, E[R(s, a)]f (s, a) uniformly continuous bounded second derivatives.AIV. Transition probabilities converge weakly Lipschitz continuously. Let g : Rcontinuous bounded. exists Ct (s1 , a1 ), (s2 , a2 ) A,fiZfiZfififi g(u)P (s1 , du, a1 ) g(u)P (s2 , du, a2 )fi Ct ||g(u)|| ||(s1 , a1 ) (s2 , a2 )||fifiAlso,tives.Rg(u)P (s, du, a)f (s, a) uniformly continuous bounded second deriva-Theorem 1. Let assumptions AI. - AIV. kernel conditions KI. - KIV. holdb h,n (s, a) defined (2). probability one, > 0, exists h = h()QN = N (h, ) n > Nsupb h,n (s, a) Q (s, a)| < .|Q(4)(s,a)SA5. Lemmas Proof Theoremproof strategy inspired Watkins original proof finite spaces. interestedreader, suggest technical report (Watkins & Dayan, 1992) followed Watkinsthesis. method different later approaches proving convergence Qlearning, Tsitsiklis (1994) Jaakkola et al. (1993), variationsextensions stochastic approximation theory. Although Watkins method relystochastic approximation result minor way, key intuition Q-learningimitates model estimation.One strengths Q-learning require model systemestimated maintained. However, learned Q-values optimal values modelconstructed appropriately assigning weights observed rewardstransitions. Specifically, learning parameters used update value estimates usedweight reward transition observations carefully define artificial process,learned Q-value estimates optimal artificial process. rewardstransitions observed, artificial process becomes similar real process,optimal Q-values two processes become similar, thus learned valuesconverge optimal values real process. Watkins called artificial processAction Replay Process.proof strategy summarized following five steps:1. fixed bandwidth value, define auxiliary Action Replay Process (ARP).artificial process purely proof device.b h,n (s, a) optimal Q-value function ARP2. Show function Qcorresponding bandwidth.711fiCarden3. Show sufficiently small bandwidths, rewards transition probabilitiesARP become arbitrarily close original process.4. Show two MDPs similar rewards transition probabilities similaroptimal Q-values.5. optimal values ARP converge optimal values original process.Hence step 2, Q-values learned algorithm converge optimal Qvalues.5.1 Construction ARP (Action Replay Process)ARP defined. finite length, terminating MDP. Pick bandwidthvalue h, keep fixed throughout discussion follows. suggest thinkingARP card game. Suppose one preparing run algorithm Section3. Also suppose deck index cards. iteration algorithm,b h,k (), h,k () >. valueswrite following values card: < sk , ak , uk , rk , Qregarded random variables depending random states, actions, rewardsoriginal process rather fixed values particular sample trajectory.b h,0 () written. card bottom, stackalso card initial Qcards ascending order iteration shown Figure 1.b h,n (), h,n () >< sn , , un , rn , QLevel nb h,n1 (), h,n1 () >< sn1 , an1 , un1 , rn1 , QLevel n 1......b h,2 (), h,2 () >< s2 , a2 , u2 , r2 , QLevel 2b h,1 (), h,1 () >< s1 , a1 , u1 , r1 , QLevel 1b h,0 () ><QLevel 0Figure 1: ARP envisioned stack cards.States state ARP 2-tuple < s, n > consisting state original statespace non-negative level n tells us card inspected.cards level n ignored, leaving us finite stack cards. statelevel 0 terminal, absorbing state.Actions actions ARP actions real process, A.712fiA Continuous Action Q-learning VariantTransitions Rewards Suppose ARP state < s, n > action chosen.Inspect card corresponding level n. probability h,n (s, a), acceptcard receive reward rn transition state < un , n 1 >. Otherwise, ignorecard inspect card level n 1. probability h,n1 (s, a), acceptcard, receive reward rn1 transition state < un1 , n 2 >. Otherwise,continue inspecting cards one accepted, probability acceptingcard level k h,k (s, a). bottom card corresponding level 0 reached(that is, state < s, 0 > action utilized) reward Qh,0 (s, a)received ARP terminates.ARP MDP, optimal Q-values. Let Qh (< s, n >, a) functiongiving optimal Q-values state < s, n > action ARP bandwidth h.5.2 Lemmasoptimal Q-values level n ARP corresponding bandwidth h learnedQ-value estimates original process iteration n defined (2).Lemma 1.b h,n (s, a), (s, a) A, n 0.Qh (< s, n >, a) = QProof. Proceed induction level n ARP. Recall ARP stateb h,0 (s, a) process terminates.< s, 0 > action used, reward QThusb h,0 (s, a)Qh (< s, 0 >, a) = Qproves n = 0 case.b h,n1 (s, a) statessuppose way induction Qh (< s, n 1 >, a) = Qactions. Let ARP state < s, n > action utilized. Recallconstruction ARP,probability h,n (s, a) receive reward rn transition < un , n 1 >.Otherwise,probability 1 h,n (s, a) card thrown away situation identicalutilizing state < s, n 1 >.conditioning whether level n card accepted not,induction hypothesis (2):Qh (< s, n >, a) = (1 h,n (s, a))Qh (< s, n 1 >, a)+ h,n (s, a)(rn + sup Qh (< un , n 1 >, b))bAb h,n1 (s, a)= (1 h,n (s, a))Qb h,n1 (un , b))+ h,n (s, a)(rn + sup QbAb h,n1 (s, a) + h,n (s, a)yh,n= (1 h,n (s, a))Qb h,n (s, a).=Q713fiCardenfollowing lemma, needed proof Lemma 3, showsgrows uniformly across state-action space.Pnk=1 h,k (s, a)Lemma 2. assumption AI. holds, probability one,liminfnXn (s,a)SAh,k (s, a) .(5)k=1Proof. compact, covered finite number disjoint sets fixedpositive diameter set positive Lebesgue measure. Choose diameteru, u0 set implies Kh (u u0 ) > > 0. Suppose J sets needed,denote B1 , B2 , ..., BJ . Set T0 = 0 k > 0, let Tk denote first timeset visited least k times. Note AI. Borel-CantelliLemma, P (Tk < ) = 1. Fix (s, a) A, letting CK denote boundkernel values,TnXk=1h,k (s, a) =nXTkXh,j (s, a)k=1 j=Tk1 +1nXk=1nX 1=Tk .CK TkCKk=1terms Tk , k > 0, independent bounded random variablesare. Set W1 = T1 . Ignoring previous visits sets prior time T1 , set W2number steps T1 Bj visited again. obvious W2 T2 T1 .Likewise, k > 1, set Wk number steps Tk1 set visitedagain, Wk Tk Tk1 . Notice W1 , W2 , ... i.i.d. random variables. Applyinginequalities, one may writeT11 = W11T21 (W1 + W2 )1...1kX1Wj .kj=1TnXk=11nkX Xh,k (s, a)Wj .CKk=1j=11Pn Pksuffices showgoes infinity probability one. Setk=1j=1 WjPnPnPn 1 kP11Sn = k=1 Wk . k=1 Sk = k=1 k Sk . Since Skk E[W> 0, nk=1 k1 Skk1]probability one. (s, a) arbitrary, proves result.next lemma shows one starts ARP sufficiently high level,probability ending certain level fixed number actions madearbitrarily small.714fiA Continuous Action Q-learning VariantLemma 3. Let > 0, l0 level ARP, positive integer n represent lengthsequence actions followed. exists level l > l0 ARPstarts level l follows sequence n actions, probability endinglevel l0 less .Proof. Proceed induction. Consider first case n = 1. > l0 , supposeARP state < s, > action utilized. Transitioning state level l0means card level l0 accepted. probability accepting cardlevel k 1 h,k (s, a), probability accepting nonek=l0 (1 h,k (s, a)).well-known inequality real analysis yieldsk=l0 (1 h,k (s, a)) < ePmk=l0h,k (s,a).follows Lemma 2 possible choose l1 > l1 impliesXinf(s,a)SAh,k (s, a) > log .k=l0P (ending l0 ) =k=l0 (1 h,k (s, a)) < ePmk=l0h,k (s,a)< .sequence n actions, exists l1 probability endingl0 l1 one transition less 2 induction l2probability ending l1 n 1 transitions less 2 . ARP startslevel l2 ,P (below l0 n transitions)=P (below l0 n transitions|above l1 n 1 transitions)P (above l1 n 1 transitions)+P (below l0 n transitions|below l1 n 1 transitions)P (below l1 n 1 transitions)1 + 1 = .22next lemma allows one work finite sequences actions rather infiniteones arbitrarily small error.Lemma 4. Consider value state specific sequence n actions (a0 , a1 , ..., an1 )followed process terminated:"n1#XER(st , )|s0 = .t=0Also consider value state n actions followedarbitrary policy :"n1#XXER(st , ) +R(st , (st ))|s0 = .t=0t=ndifference two values goes zero n increases towards infinity.715fiCardenProof. interested difference"n1#"n1#XXXER(st , ) +R(st , (st ))|s0 = ER(st , )|s0 = .t=nt=0t=0difference clearly expectation second term first expectation.rewards bounded C0 , use change variables v = n write"#"#XXv+nER(st , (st ))|s0 = = ER(sv , (sv ))|s0 =t=nv=0"nEX#v |R(sv , (sv ))||s0 =v=0nXv C0 = nv=0C01goes zero n goes infinity.next lemma consider reward received ARP state < s, n >action utilized. random quantity depends state-actions chosenrewards received original process, also depends levels ARPaccepted state transitions. ARP constructed bandwidth hb h,n (s, a)] denoterewards received state < s, n > utilizing action a, let E[Rexpectation taken ARP state transitions, sequence state-actionsb h,n (s, a)] constant,rewards original process. Note E[Rrandom quantity defined sample space original process.Similarly, probability ARP transitioning state set B(S) alsorandom variable depending state-actions chosen original process.ARP constructed bandwidth h starting state < s, n > utilizing actiona, let Pbh,n (s, T, a) denote random probability ARP transitioning stateset .next lemma shows high enough levels, rewards transition probabilities ARP close rewards transition probabilities originalprocess.Lemma 5. assumptions AI.-AIV. kernel conditions KI.-KIV. met,a) probability one, > 0 exists h = h(, ) N = N (, h)n > N ,fififibfisup fiE[R(s,a)]E[R(s,a)]fi < .h,n(s,a)SAb) probability one, > 0 g : R integrable, continuous,bounded, exists h() N (, h) n > N ,fiZfiZfifibfisup fi g(u)Ph,n (s, du, a)g(u)P (s, du, a)fifi < .(s,a)SA716fiA Continuous Action Q-learning VariantProof. Consider expected reward associated state-action (s, a) level nARP. Condition whether card level n accepted. probability 1 h,n (s, a)accept card, expected reward level n 1. probabilityh,n (s, a) level n card accepted receive reward rn . special case n = 0,b h,0 (s, a). expected rewardslowest level ARP receive reward Qsatisfy recursive relationshipb h,0 (s, a)] = Qb h,0 (s, a),E[Rb h,n (s, a)] = (1 h,n (s, a))E[Rh,n1 (s, a)] + h,n (s, a)rn , n > 0.E[Rshow inductionPnj=1 Kh ((s, a) (sj , aj ))rjbE[Rh,n (s, a)] = Pnj=1 Kh ((s, a) (sj , aj ))Pnj=1 Kh ((s, a)(sj , aj )) 6= 0. n = 1 case,b h,1 (s, a)] = (1 h,1 (s, a))Qb h,0 (s, a) + h,1 r1 .E[RReplace h,1 (s, a) terms per definition (1).P1b h,1 (s, a)] =E[R1j=1 Kh ((s, a)P1j=1 Kh ((s, a)(sj , aj ))(sj , aj ))!P1b h,0 (s, a) + Pj=1Q1Kh ((s, a) (sj , aj ))j=1 Kh ((s, a)(sj , aj ))r1= r1 .assume induction hypothesis holds n 1.b h,n (s, a)] = (1 h,n (s, a))E[Rb h,n1 (s, a)] + h,n (s, a)rnE[R! Pn1!Pn1j=1 Kh ((s, a) (sj , aj ))j=1 Kh ((s, a) (sj , aj ))rj= PnPn1j=1 Kh ((s, a) (sj , aj ))j=1 Kh ((s, a) (sj , aj ))Kh ((s, a) (sj , aj ))+ Pnrnj=1 Kh ((s, a) (sj , aj ))Pnj=1 Kh ((s, a) (sj , aj ))rj= Pn.j=1 Kh ((s, a) (sj , aj ))expected rewards ARP equivalent kernel regression estimates. Assumptions AI., AII., AIII., kernel conditions KI.-KIV. meet technical conditionsHansen (2008). See Theorem 9 page 735. yieldssupb h,n (s, a)] E[R(s, a)]| <|E[R(s,a)SAsufficiently large n, proves part a).717fiCardenpart b), recall un denotes state transitioned iteration n.Consider random variable indicator function event n-th transitionoriginal process B(S).(1 un1T (un ) =0 un/T .Similar rewards, transition probabilities ARP level n conditionedwhether level n card accepted not. Assume state-action (s, a).probability 1 h,n (s, a), accept card probability transitioninglevel n 1. probability h,n (s, a) level n card acceptedvalue 1T (un ) tells us whether transition not. Thus relationPbh,1 (s, T, a) =h,1 (s, a)1T (u1 ),Pbh,n (s, T, a) =(1 h,n (s, a))Pbh,n1 (s, T, a) + h,n (s, a)1T (un ).PLet g : R simple function, g(u) =i=1 ai 1Ti (u). apply relationintegral g findZXXg(u)Pbh,1 (s, du, a) =ai Pbh,1 (s, Ti , a) =ai 1Ti (u1 )i=1i=1= g(u1 )ZXg(u)Pbh,n (s, du, a) =ai Pbh,1 (s, Ti , a)=i=1Xhai (1 h,n (s, a))Pbh,n1 (s, Ti , a) + h,n1 (s, a)1Ti (un )j=1Z= (1 h,n1 (s, a))g(u)Pbh,n1 (s, du, a) + h,n (s, a)g(un ).Using common argument measure theory, relation also holds integrablefunction approximating simple functions. rest proof proceeds parta), assumptions AI., AIV., kernel conditions KI.-KIV. fulfilling requirementsHansens Theorem 9.Definition. given MDP, let Q(s1 , < a1 , a2 , ..., , >) denote expected discounted reward received process starts state s1 actions a1 , a2 , ...,utilized consecutively process terminates. FormallynXQ(s1 , < a1 , a2 , ..., , >) = Ej1 R(sj , aj )j=1718fiA Continuous Action Q-learning Variantchance transitioning states s2 , ..., sn understood governedP (sj , , aj ).following lemma shows state-action values possess sort continuity.property needed apply Lemma 7 state-action values.Lemma 6. assumptions AII., AIII., AIV. hold, n, fixedarbitrary sequence actions < a1 , a2 , ..., >, function f : R definedf (s) = Q(s, < a1 , a2 , ..., , >)Lipschitz continuous.Proof. Consider first case n = 1. Let s1 , s2 S. AIII.|Q(s1 , < a1 , >) Q(s2 , < a1 , >)|=|E[R(s1 , a1 )] E[R(s2 , a1 )]| Cr ||(s1 , a1 ) (s2 , a1 )||.considering case n > 1, notice assumption AII.nX|Q(s, < a1 , a2 , ..., , >)| Ej1 |R(sj , aj )|j=1Xj1 C0j=1=C0.1Applying AIII. difference means AIV. difference integrals,n > 1 s1 , s2|f (s1 ) f (s2 )| =|Q(s1 , < a1 , ..., , t) Q(s2 , < a1 , ..., , >)||E[R(s1 , a1 )] E[R(s2 , a1 )]|fi Zfi+ fifiQ(u, < a2 , ...an , >)P (s1 , du, a1 )fiZSfiQ(u, < a2 , ...an , >)P (s2 , du, a1 )fifiCr ||((s1 , a1 ) (s2 , a1 ))|| + Ct ||Q(u, < a2 , ...an , >)|| ||(s1 , a1 ) (s2 , a1 )||C0Cr ||((s1 , a1 ) (s2 , a1 ))|| + Ct||(s1 , a1 ) (s2 , a1 )||.1C0} inserting last inequality,taking C1 = 2 max{Cr , C1|f (s1 ) f (s2 )| C1 ||(s1 , a1 ) (s2 , a1 )||.Finally, notice ||(s1 , a1 )(s2 , a1 )|| = ||s1 s2 || properties Euclidean metric.end|f (s1 ) f (s2 )| C1 ||s1 s2 ||,proves result.719fiCardennext lemma, suppose one two MDPs defined state actionspace. (s, a) A, let R(i) (s, a) P (i) (s, , a) denote rewards transitionprobabilities process = 1, 2. lemma show expected rewardstransition probabilities processes sufficiently close, expected discountedreward series actions also close.Lemma 7. Suppose assumptions required Lemma 6 hold. > 0 sequenceactions length n, exists r (n, ) (n, ) g : R continuousC0||g|| 1following two conditions hold:1.sup(s,a)SAfififififiE[R(1) (s, a)] E[R(2) (s, a)]fi < r (n, )2.sup(s,a)SAfifiZZfifi(2)fi < (n, ),fi g(u)P (1) (s, du, a)g(u)P(s,du,a)fifisequence actions length n,|Q(1) (s1 , < a1 , a2 , ..., , >) Q(2) (s1 , < a1 , a2 , ..., , >)| < .Proof. proceed induction n, number actions executed. n = 1,take r (1, ) = .|Q(1) (s1 , < a1 , >) Q(2) (s1 , < a1 , >)| = |E[R(1) (s1 , a1 )] E[R(2) (s1 , a1 )]| < r = .assume induction hypothesisholds sequenceactionslength n1. Taker (n, ) = min 3 , r (n 1, 3 ) , (n, ) = min 3 , (n 1, 3 ) . sequencelength n, condition state s2 write|Q(1) (s1 , < a1 , ..., , >) Q(2) (s1 , < a1 , ..., , >)||E[R(1) (s1 , a1 )] E[R(2) (s1 , a1 )]|fiZfi+ fifi Q(1) (s2 , < a2 , ..., , >)P (1) (s1 , ds2 , a1 )fiZfi(2)(2)Q (s2 , < a2 , ..., , >)P (s1 , ds2 , a1 )fifi .720(6)(7)(8)fiA Continuous Action Q-learning VariantAdd subtractRQ(1) (s2 , < a2 , ..., , >)P (2) (s1 , ds2 , a1 ):|Q(1) (s1 , < a1 , ..., , >) Q(2) (s1 , < a1 , ..., , >)||E[R(1) (s1 , a1 )] E[R(2) (s1 , a1 )]|fiZfi+ fifi Q(1) (s2 , < a2 , ..., , >)P (1) (s1 , ds2 , a1 )fiZSfi(1)(2)Q (s2 , < a2 , ..., , >)P (s1 , ds2 , a1 )fififiZSfi+ fifi Q(1) (s2 , < a2 , ..., , >)P (2) (s1 , ds2 , a1 )fiZSfi(2)(2)Q (s2 , < a2 , ..., , >)P (s1 , ds2 , a1 )fifiLemma 6 value function continuous, assumption first differencemade smaller /3 choice r , second difference made small choice, third difference made small induction hypothesis. differenceless 3 , result proved.5.3 Proof Theoremprepared prove Theorem 1.Proof. terms subscripts denote values ARP bandwidth h.terms subscripts refer original process. policy , considerdifference|Qh (< s, n >, a) Q (s, a)||Qh (<(9)s, n >, a) Qh (< s, n >, < a, (s2 ), ..., (sm ), >)|+ |Qh (< s, n >, < a, (s2 ), ..., (sm ), >) Q(s, < a, (s2 ), ..., (sm ), >)|+ |Q(s, < a, (s2 ), ..., (sm ), >) Q (s, a)| .(10)(11)(12)Lemma 4, chosen large enough lines (10) (12) less 3 .Lemma 5, exists h N N iterations run,rewards transition probabilities ARP become arbitrarily closereal process. Furthermore, Lemma 3 higher level N1 one startslevel N1 , probability straying N performing actions less(1)12C0 . level N , requirements apply Lemma 7 met, one0make line (11) less 12C02C(1) . ARP stray level N ,2C0difference bounded 1mentioned Lemma 6. conditioning whetherARP strays level N ,|Qh (< s, n >, < a, (s2 ), ..., (sm ), >) Q(s, < a, (s2 ), ..., (sm ), >)|2C012C0 (1 )2C0 (1 )+= .112C012C0 (1 )12C03721fiCardenfollows|Qh (< s, n >, a) Q (s, a)| < .policy arbitrary, replace policy optimal realprocess, . knowfififififiQh (< s, n >, a) Q (s, a)fi < .claim also gives optimal values ARP. not,policy 0 gave higher values, considerfififiQ 0 (< s, n >, a) Q0 (s, a)fihmade arbitrarily small, would imply Q0 (s, a) > Q (s, a) contradictschoice optimal policy.|Qh (< s, n >, a) Q (s, a)| < .b h (s, a). ThusLemma 1, Qh (< s, n >, a) = QfififibfifiQh,n (s, a) Q (s, a)fi < .(s, a) arbitrary, convergence uniform.6. Experimental Resultsprimary intent paper therefore also algorithm serve additiontheory continuous domain reinforcement learning providing asymptotic convergence results. section explore practical application algorithm showminor modification capable obtaining satisfactory solution standardbenchmark problem reasonable amount time.section detail application Mountain Car problem (Moore, 1991).state space consists two variables: position p car, constrainedinterval [1, 1] velocity v, constrained [3, 3]. action space consistssingle variable, force applied vehicle along line tangent road value[4, 4]. car starts bottom hill standstill, corresponding initialstate (.5, 0). goal drive car top hill positive direction,i.e., p > 1 keeping velocity bounds. goal reached, reward 1experienced trial terminates. car goes bounds (that is, p < 1|v| > 3) reward 1 received trial terminates. statesreward received zero. hill defined expressionp2 + pp < 0H(p) = pp 0 .21+5pFigure 2 shows shape hill, initial position, location goal.problem non-trivial maximum force positive direction largeenough move directly goal. Instead, agent must learn build momentumalternating acceleration trying move goal.722fiA Continuous Action Q-learning Variant10.80.60.40.200.20.40.60.8110.8 0.6 0.4 0.200.2Position0.40.60.81Figure 2: hill mountain car climb. circle represents initial position,star represents goal.6.1 Examination AssumptionsAssumptions AI.-AIV., sufficient ensure convergence, quite strong. fact,many standard problems Reinforcement Learning meet them.example, rewards often discontinuous nature, states emit zeroreward crossing boundary suddenly yields reward penalty. purposesection show proposed algorithm somewhat robust. is, evenpresence violated conditions, obtain policies adequate solving problemhand. Specifically, see Mountain Car problem violates two fourassumptions, yet algorithm still produces policy reach goal state.first assumption continuous analogue classic Q-learnings requirementevery state-action pair visited infinite number times. require distribution(sn , ) possess density positive sufficiently smooth. However, givendynamics Mountain Car, areas state space inaccessibleavailable actions. Consider state consisting position p = .9 velocityv = 2.9. position top hill near goal. maximum accelerationnegative direction strong enough produce negative velocity large 2.9space given.Figure 3 suggests density state space adequately smooth,clear states visited. However, state spacerestricted set accessible states, seems reasonable density everywherepositive.second assumption requires bounded rewards. Mountain Car problem clearlysatisfies this.723fiCardenFigure 3: histogram showing frequency visits across state space.third assumption requires rewards Lipschitz continuous. commonReinforcement Learning rewards zero state-action space,goal state emitting positive rewards penalties issued leaving boundaries enteringundesirable states. exactly case Mountain Car. One could circumventproblem replacing impulse rewards low-variance Gaussian density functioncentered goal state, use similar method smoothing rewards without disruptingoverall reward structure.fourth assumption requires weak convergence transition probability measuresstates actions become similar. Furthermore, convergence must uniformacross state-action space. problem smooth, deterministic transitionsMountain Car, easy verify convergence distribution un (the statetransitioned to) state-actions (sn , ) converge, equivalent weak convergence(see Jacod & Protter, 2003, ch. 18).noted strength assumptions directly linked desirevalue function estimate converge uniformly. Kernel methods achieve weakerforms convergence much weaker assumptions. example, Devroye Gyorfi(1985) show proper bandwith selection, kernel density estimates convergeL1 conditions density estimated. suggests kernel-basedalgorithms may able return good policies despite discontinuities reward function,case Mountain Car problem. However, thoroughlyinvestigated problems yet.6.2 Computational Considerationsadvantage non-parametric approximators potential representfunction arbitrary precision, cost increased computational load724fiA Continuous Action Q-learning Variantobservations used. following paragraphs discuss suggestionsalleviating problem.One idea selective observations kept use future calculationsdiscarding rest. example, consider boundary reachedfirst time, rewards received equal zero, initialized function value.Recording observations slow future value function computationsadd knowledge system. Suppose state-action (s, a), rewardrn received next state un . One may choose discard experienceb h,n1 (un , b) Qb h,n1 (s, a)| <|rn + sup QbAtolerance . keeping experiences potential improve valuefunction estimate ensures algorithm learns efficiently.Another idea to, point, begin discarding old observations new onesb h,n1 (un , b)recorded keep fixed number memory. Consider terms rn + supbA Qb h,n1 (un , b) yet calculated enough data givecalculated early, value Qgood estimate. Dropping old values favor new ones serves double purpose capping increasing computational load speeding convergence value estimates. Caretaken region state-action space left without observationsperforming kernel regression.third option, approach taken example, seed algorithmfixed number randomly-generated episodes reached goalbeginning standard -greedy exploration strategy. Exploration episodes generatedusing random action selection. Episodes reach penalty state fail find goalwithin 500 iterations discarded, successful episodes passed algorithm.20 episodes, algorithm chooses random actions probability optimal(based current knowledge) actions otherwise. point iterations passedlearning algorithm.mentioned introduction, taking supremum possible actionsgiven state is, general, difficult problem. Mountain Car problem,one action variable, suitable choice kernel function allows exact solutions.Epanechnikov kernel defined(3(1 x2 ) |x| < 1eK (x) = 4(13)0otherwisecommon choice kernel regression minimizes approximation meanintegrated square error (see Silverman, 1986, section 3.3.2 details). threedimensional Mountain Car problem, define multivariate kernel productEpanechnikov kernels variable. is, state-action pairs represented(pk , vk , ak ), defineK((p1 , v1 , a1 ) (p2 , v2 , a2 )) = K e (p1 p2 )K e (v1 v2 )K e (a1 a2 )advantage formulating kernel way numerator derivativerespect action variable quadratic action variable. Epanechnikov kernel non-zero finite interval, domain action variable broken725fiCardenfinite number intervals quadratic coefficients constant. Thuspoints candidate maxima either root one finite number quadraticsbreakpoints intervals. Using method, optimal action calculatedrelatively efficiently. routine finds multiple actions optimal value, tiesbroken randomly. Currently, strategy works problems one actionvariable, though possibility extending higher dimensions investigated.6.3 Results32Velocity1012310.8 0.6 0.4 0.200.2Position0.40.60.81Figure 4: trajectory state space obtained final policy.432Action10123402468101214IterationFigure 5: Actions chosen final policy.726fiA Continuous Action Q-learning VariantImplementation MATLAB 2012b Ubuntu 12.04 hardware IntelXeon 3.47 gigahertz processor 24 gigabytes RAM. 7,500 iterations recorded858 seconds. Parameter values bandwidth h = .2, exploration parameter = .9,discount factor = .9, k = 20 successful episodes initialize 1 .policy obtained near-optimal. Figure 4 shows trajectory carstate space. car begins accelerating negative direction, travels partwayhill left, changes positive acceleration reaches goal. Figure5 shows action selection time. optimal policy choose actions extremeends action interval, learned policy sometimes chooses actions nearboundary. Figure 6 shows iterations time. initially surprisingphenomena here. One would expect number iterations per second increasedata collected, around 400 iterations calculations actually speed up.reason small amount data available, action-selection subroutinefind many actions maximum value. candidate best action keptmemory tie randomly broken end subroutine. datacollected, ties occur less commonly, subroutine finishes less time. brieftime, increase speed faster action-selection outpaces decrease speedaccumulating data. time, phenomena vanishes, algorithm slowsagain. Figure 7 shows iterations time 25,000 iterations. plotclear described phenomena temporary.Another unexpected occurence involved optimal bandwidth. Repeating experiment multiple times different bandwidths revealed best results obtainedalgorithm learned bandwidth .2 used smaller bandwidth, .07,building final policy. Early trials resulted policy could find goal spenttime necessary building momentum. Upon investigation foundvalue state-actions corresponding initial state calculated using valuesinitial position positive velocity. caused policy use positive acceleration(the best action velocity already positive) rather negative acceleration (thebest action velocity zero) initial state. smaller bandwidth, specifically.07, avoided issue. Note using .07 algorithm learning phaseyield good results sufficiently generalize small amountdata available. suggests even though convergence proof uses fixedbandwidth, practice best decrease bandwidth amount data increases.7. Conclusionpaper presented reinforcement learning algorithm continuous states actions proven converge optimal solution. Knowledge generalization basedNadaraya-Watson kernel regression. similar previous result OrmoneitSen (1999), uses kernel-smoothing problems continuous state spacefinite number actions. algorithm presented different importantways. First, actions allowed continuous. However, introduces burdenensuring small changes actions result small changes transition dynamics. Second,assumption distribution states weaker. Ormoneit Sens Assumption1. full source code, see online appendix associated publication.727fiCarden800070006000Iterations5000400030002000100000100200300400500600Time (seconds)7008009001000Figure 6: Graph 7,500 iterations completed time.42.5x 102Iterations1.510.500100020003000Time (seconds)400050006000Figure 7: Graph 25,000 iterations completed time.3 requires states sampled uniformly state space. weakenedpresent paper requiring distribution states positive smoothdensity.presented algorithm sequential updates single observation.primary reason considering sequential rather batch-mode algorithmWatkins proof strategy applied directly possible. However, applications,batch-mode version possesses many advantages. Informal experiments MountainCar Inverted Pendulum problems batch-mode implementation producedbetter results typically quarter amount time sequential algorithm requires.728fiA Continuous Action Q-learning VariantOne practical difficulties implementing algorithm amountcomputation required increases recorded observation. addition ideasSection 6, author experimented sparsifying selecting grid points{(sj , aj )|j = 1, ..., } state-action space assigning point valueperforming kernel regression values yield predictions similar predictionsobtained using kernel regression entire set observations. Essentially, ideause kernel radial basis function fixed locations state-action space learnweights each. Specifically, suppose N transitions observed, N ,b h,i1 (ui , a)|i = 1, ..., N } recorded. Define{(si , ai )|i = 1, ...N } {yh,i := ri + supaA Qmatrix XN entry-wiseKh ((si , ai ) (sj , aj ))Xi,j = PMj=1 Kh ((si , ai ) (sj , aj )~N 1 Yi = yh,i . Solve ~ minimizes ||X ~~ ||2 . state-action (s, a), deand~ 1 (s, a) Kj (s, a) = K((s, a) (sj , aj )). value (s, a) estimatedfine K~ future observations, update ~ described Chambers (1971).~ (s, a).Kmethod requires computation linear number observations constantstorage requirements.fourth assumption concerns weak convergence state transition probability measures. state-action space separable, possible define metric settransition measures convergence metric equivalent weak convergence.See, example, Prokhorov metric (Billingsley, 1999). Therefore possible restateassumption four succint manner sometimes easier verify. However,extra work required derive properties needed convergence proof.author chosen state assumption four manner simplifies proof.Acknowledgementsauthor would like thank Peter Kiessler technical advice, three anonymous refereesmany helpful comments, Tanya Carden Kris Kelly proofreading.ReferencesAlbus, J. S. (1975). new approach manipulator control: cerebellar model articulation controller (CMAC). Journal Dynamic Systems, Measurement, Control,97, 220227.Baird, L. C., & Klopf, A. H. (1993). Reinforcement learning high-dimensional, continuous actions. Tech. rep. WLTR-93-1147, Wright-Patterson Air Force Base Ohio:Wright Laboratory.Bertsekas, D. P. (1995). counterexample temporal differences learning. Neural Computation, 7 (2), 270279.Billingsley, P. (1999). Convergence probability measures (Second edition). Wiley SeriesProbability Statistics: Probability Statistics. John Wiley & Sons Inc., NewYork. Wiley-Interscience Publication.729fiCardenDevroye, L., & Gyorfi, L. (1985). Nonparametric density estimation: L1 view. Wileyseries probability mathematical statistics. Wiley.Ernst, D., Geurts, P., & Wehenkel, L. (2005). Tree-based batch mode reinforcement learning.Journal Machine Learning Research, 6, 503556.Fairbank, M., & Alonso, E. (2012). divergence reinforcement learning algorithmsvalue-iteration function approximation. Proceedings IEEE InternationalJoint Conference Neural Networks.Gaskett, C., Wettergreen, D., & Zelinsky, A. (1999). Q-learning continuous stateaction spaces. Australian Joint Conference Artificial Intelligence, pp. 417428.Springer-Verlag.Gordon, G. J. (1996). Chattering SARSA(lambda) - CMU learning lab internal report.Tech. rep., Carnegie Mellon University.Hansen, B. E. (2008). Uniform convergence rates kernel estimation dependent data.Econometric Theory.Hardle, W. (2004). Nonparametric Semiparametric Models. Springer Series Statistics.Springer Berlin Heidelberg.Jaakkola, T., Jordan, M. I., & Singh, S. P. (1994). Convergence stochastic iterativedynamic programming algorithms. Neural Computation, 6, 11851201.Jacod, J., & Protter, P. (2003). Probability Essentials. Universitext (1979). Springer.Lazaric, A., Restelli, M., & Bonarini, A. (2007). Reinforcement learning continuous actionspaces sequential Monte Carlo methods. Adv. Neural Information Proc.Systems.Millan, J. R., Posenato, D., & Dedieu, E. (2002). Continuous-action Q-learning. MachineLearning.Moore, A. (1991). Efficient Memory-based Learning Robot Control.Robotics Institute, Carnegie Mellon University.Ph.D. thesis,Nadaraya, E. (1964). estimating regression. Theory Probability Applications,9, 141142.Ormoneit, D., & Sen, S. (1999). Kernel-based reinforcement learning. Machine Learning.Puterman, M. L. (1994). Markov Decision Processes: Discrete Stochastic Dynamic Programming. Wiley-Interscience.Ross, S. (1992). Applied Probability Models Optimization Applications. Dover BooksMathematics. Dover Publications.Rummery, G. A., & Niranjan, M. (1994). On-line Q-learning using connectionist systems.Tech. rep., Cambridge University Engineering Department.Santamara, J. C., Sutton, R. S., & Ram, A. (1996). Experiments reinforcementlearning problems continuous state action spaces. Adaptive Behavor.Silverman, B. W. (1986). Density estimation statistics data analysis. ChapmanHall, London.730fiA Continuous Action Q-learning VariantSimonoff, J. (1996). Smoothing methods statistics. Springer, New York.Sutton, R. S. (1988). Learning predict methods temporal differences. MachineLearning, 3, 944.Sutton, R. S. (1996). Generalization reinforcement learning: Successful examples usingsparse coarse coding. Advances Neural Information Processing Systems 8, pp.10381044. MIT Press.Szepesvari, C., & Smart, W. D. (2004). Interpolation-based Q-learning. ProceedingsInternational Conference Machine Learning, pp. 791798. ACM Press.Taylor, G., & Parr, R. (2009). Kernelized Value Function Approximation ReinforcementLearning. Proceedings 26th International Conference Machine Learning,pp. 10171024.ten Hagen, S. H. (2001). Continuous State Space Q-Learning Control NonlinearSystems. Ph.D. thesis, University Amsterdam.Tesauro, G. (1995). Temporal difference learning TD-Gammon. Commun. ACM, 38 (3),5868.Tsitsiklis, J. N. (1994). Asynchronous stochastic approximation Q-learning. MachineLearning, pp. 185202.Tsitsiklis, J. N., & Van Roy, B. (1996). Feature-based methods large scale dynamicprogramming. Machine Learning, 22 (13), 5994.Watkins, C. (1989). Learning Delayed Rewards. Ph.D. thesis, University Cambridge.Watkins, C. J. C. H., & Dayan, P. (1992). Technical note: Q-learning. Machine Learning,8, 279292.Watson, G. S. (1964). Smooth regression analysis. Sankhya: Indian Journal Statistics, 26, 359372.Xu, X., Hu, D., & Lu, X. (2007). Kernel-based least squares policy iteration reinforcement learning. IEEE Transactions Neural Networks, 18 (4), 973992.731fiJournal Artificial Intelligence Research 49 (2014) 635-668Submitted 01/14; published 04/14Algorithms Argumentation Semantics: Labeling AttacksGeneralization Labeling ArgumentsSamer NofalAMER .N OFAL @ GJU . EDU . JODept. Computer Science, German-Jordanian UniversityP.O. Box 35247, Amman 11180, JordanKatie AtkinsonPaul E. DunneK.M.ATKINSON @ LIVERPOOL . AC . UKP.E.D UNNE @ LIVERPOOL . AC . UKDept. Computer Science, University LiverpoolAshton Street, Liverpool L69 3BX, United KingdomAbstractDung argumentation framework (AF) pair (A, R): set abstract argumentsR binary relation, so-called attack relation, capturing conflicting arguments. Labeling based algorithms enumerating extensions (i.e. sets acceptable arguments)set arguments (i.e. elements A) subject labeling.paper present implemented algorithms listing extensions labeling attacks (i.e. elements R) along arguments. Specifically, algorithms concerned enumeratingextensions AF number argumentation semantics: preferred, stable, complete,semi stable, stage, ideal grounded. algorithms impact, particular, enumeratingextensions AF-extended models allow attacks attacks. demonstrate impact,instantiate algorithms example models: namely argumentation frameworksrecursive attacks (AFRA), thereby end unified algorithms enumerate extensionsAF / AFRA.1. IntroductionComputational argumentation, covering theory applications, attracted major attentionAI research community, notably last twenty years (e.g. Bench-Capon & Dunne, 2007;Besnard & Hunter, 2008; Rahwan & Simari, 2009; Modgil, Toni, Bex, Bratko, Chesnevar, Dvorak,Falappa, Fan, Gaggl, Garca, Gonzalez, Gordon, Leite, Mozina, Reed, Simari, Szeider, Torroni, &Woltran, 2013). Dungs abstract argumentation frameworks (AFs) (Dung, 1995) widely studiedmodel AF described pair (A, R): set abstract arguments R AAbinary relation, so-called attack relation, represent conflicting arguments. central notionAFs argumentation semantics: set criteria characterise acceptable arguments;define criteria rigorously section 2. different reasons number argumentationsemantics proposed literature. Explaining reasons detail scopepaper; however, see work Baroni, Caminada, Giacomin (2011a) excellentintroduction argumentation semantics.various argumentation semantics, one might find multiple distinct extensions (definedsection 2). Labeling based algorithms (e.g. Dimopoulos, Magirou, & Papadimitriou, 1997; Doutre& Mengin, 2001; Modgil & Caminada, 2009) listing extensions developedarguments (i.e. elements A) target labeled. paper illustrateenumerate extensions several argumentation semantics labeling attacks (i.e. elements R)c2014AI Access Foundation. rights reserved.fiN OFAL , ATKINSON , & UNNEalong arguments, instead labeling arguments solely. particularly interest listingextensions AF-extended formalisms allow attacks attacks (e.g. Modgil, 2009b; Gabbay,2009; Baroni, Cerutti, Giacomin, & Guida, 2011b). show throughout paper, termlabeling based algorithms argumentation semantics distinguished common termlabeling based semantics, although concepts involve labeling mapping. former term(i.e. labeling based algorithms) refers course actions extension enumerationprocess classifies arguments: might extension excludedrespective extension. classification essential order construct concreteextensions given AF. later term (i.e. labeling based semantics) refers approachdescribing (i.e. constructing) extensions using labeling mapping.section 2 provide necessary background materials. section 3 review explicit algorithms selection dominant argumentation semantics: preferred, stable, complete, semistable, stage, ideal grounded. algorithms list extensions labeling arguments only.section 4 develop, respective argumentation semantics, definite algorithmsenumerating extensions argumentation framework recursive attacks (AFRA): AFextended model allows attacks attacks (Baroni et al., 2011b). algorithms constructextensions labeling attacks together arguments. Since AF special case AFRA (Baroni et al., 2011b), developed algorithms AFRA also list extensions AF. section 5report experiments concerning practical efficiency algorithms. Section 6 concludespaper summary review related work.2. Preliminariesstart definition Dungs argumentation frameworks (Dung, 1995).Definition 1. (Dungs Argumentation Frameworks)argumentation framework (or AF) pair (A, R) set arguments Rbinary relation.refer (x, y) R x attacks (or attacked x). denote {x} respectivelysubset containing arguments attack (resp. attacked by) argument x,extending notation natural way sets arguments, A,{x}+S+=={ : x s.t. {x} }{ : x s.t. {x}+ }Given subset A,x acceptable w.r.t. every (y, x) R, z(z, y) R.conflict free (x, y) S, (x, y)/ R.admissible conflict free every x acceptable w.r.t. S.preferred extension maximal (w.r.t. ) admissible set.stable extension conflict free S+ = \ S.636fiA LGORITHMS RGUMENTATION EMANTICSFigure 1: argumentation framework.complete extension admissible set x acceptablew.r.t. S, x S.stage extension conflict free S+ maximal (w.r.t. ).semi stable extension admissible S+ maximal (w.r.t. ).ideal extension maximal (w.r.t. ) admissible set contained every preferred extension.grounded extension least fixed point F(T ) = {x |x acceptable w.r.t. }.Preferred, complete, stable grounded semantics introduced work Dung (1995),whereas stage semantics, ideal semantics semi stable semantics presented papersVerheij (1996), Dung, Mancarella, Toni (2007) Caminada, Carnielli, Dunne (2012)respectively. give example, consider framework depicted figure 1 nodes representarguments edges correspond attacks (i.e. elements R). example {b, d}preferred, grounded, stable, ideal, complete, semi stable stage extension. Noteintend example show differences semantics.Offering explicit means weaken attacks, formalisms Modgil (2009b), Gabbay(2009) Baroni et al. (2011b) extend AFs attacks (i.e. elements R) subjectattacks themselves. present extension enumeration algorithms instance formalisms: namely argumentation frameworks recursive attacks (AFRA) introduced Baroni etal. (2011b).Definition 2. argumentation framework recursive attacks (AFRA) pair (A, R)set arguments R set pairs (x, y) x (y R).Let x = (y, z) R say source x, denoted src(x) = y, z targetx, denoted trg(x) = z.Let x R R say directly de f eats x x = trg(y).Let x, R say indirectly de f eats x src(x) = trg(y).Let x R R, say de f eats x directly indirectly defeats x.Given subset R,conflict free exist x, s.t. x defeats y.element x R acceptable w.r.t. R : defeats x,z z defeats y.admissible conflict free x S, x acceptable w.r.t. S.637fiN OFAL , ATKINSON , & UNNEFigure 2: argumentation framework recursive attacks.preferred extension maximal (w.r.t. ) admissible set./ S,stable extension conflict free x R : xexists de f eats x.complete extension admissible every element R,acceptable w.r.t. S, belongs S.stage (resp. semi stable) extension conflict free (resp. admissible){x | s.t. defeats x} maximal (w.r.t. ).ideal extension maximal (w.r.t. ) admissible set contained every preferred extension.grounded extension least fixed point F(T ) = {x R |x acceptable w.r.t. }.Referring figure 2, {b, d, h, e} grounded, stable, preferred, ideal, complete, stagesemi stable extension.consider issue expressing AFRA AF. Let H = (A, R) AFRA,corresponding AF H = (A , R ) defined = R R = {(x, y) | x,R x de f eats y}. example, corresponding AF AFRA depicted figure 2described = {b, c, d, e, f , g, h} R = {(e, g), ( f , e), (g, e), (g, d), (h, c), (h, f ), (h, g)}.3. Algorithms Selection Argumentation Semanticssection review explicit algorithms list, number argumentation semantics,extensions AF labeling arguments solely. Particularly, subsection 3.1 recallalgorithm Nofal, Atkinson Dunne (2014) preferred semantics. section 3.2 presentnew implementation algorithm Dimopoulos et al. (1997) stable semantics.modify algorithm Nofal, Atkinson Dunne (2014) produce specific algorithmscomplete, stage, semi stable ideal semantics subsections 3.3, 3.4, 3.5 3.6 respectively.subsection 3.7 present implementation building grounded extension.3.1 Enumerating Preferred Extensions AFAlgorithm 1 lists preferred extensions AF. Algorithm 1 taken work Nofal,Atkinson Dunne (2014) shown algorithm likely efficientalgorithms Doutre Mengin (2001), Modgil Caminada (2009). recall638fiA LGORITHMS RGUMENTATION EMANTICSalgorithm 1 implemented algorithms present paper seen extensionalgorithm. algorithm backtracking procedure traverses abstract binary searchtree. core notion algorithm related use five labels: IN, OUT, MUST OUT,BLANK UNDEC. Informally, label identifies arguments might preferredextension. label identifies argument attacked argument. BLANKlabel unprocessed argument whose final label decided yet. MUST labelidentifies arguments attack arguments. UNDEC label designates arguments mightincluded preferred extension might defended argument.enumerate preferred extensions algorithm 1 starts BLANK default labelarguments. initial state represents root node search tree. algorithm forksleft (resp. right) child (i.e. state) picking argument, BLANK, labeled (resp.UNDEC). Every time argument, say x, labeled neighbour arguments labelsmight change every {x}+ label becomes every z {x} \{x}+label z becomes MUST OUT. process, i.e. forking new children, continuesevery x label x BLANK. point, algorithm captures preferred extensionevery x label x belongs {IN,OUT,UNDEC} {x | label xIN} subset previously found preferred extension (if exists). algorithmbacktracks try find preferred extensions. important kinds algorithmsexploit properties whereby might bypass expanding child search tree, thus considerabletime might saved. Algorithm 1 uses two pruning properties:1. Algorithm 1 (lines 12-17) skips labeling argument (i.e. skips expanding left child)z {y} label z w {z}BLANK label. words, z labeled laterw {z} label w OUT, MUST UNDEC. Thus, efficient skiptrying include argument attacked z preferred extension.2. Algorithm 1 (lines 19-22) skips labeling argument UNDEC (i.e. skips expanding rightchild) every z {y} current label z MUST OUT.admissible set, say S, constructed UNDEC {y}admissible also. Recall preferred extensions maximal admissible sets, henceneed label UNDEC.Another fundamental issue take account selection BLANK argumentslabeled IN. point behind adopting selection strategy try achieve preferred extension efficiently. critical problem constructing one extension.Therefore, algorithm 1 (line 8) applies following selection options:1. Algorithm 1 tries select first BLANK argument, say y, attackedattacked OUT/MUST arguments only. justification selection relatedsecond pruning property used algorithm. Note earlier picklabeled IN, bigger part search tree avoided. Recall leadexpanding right child according second pruning property.2. Otherwise algorithm picks BLANK argument, say y, |{z : z {y}+label z OUT}| maximal. intuition maximising numberarguments minimise number BLANK/MUST arguments. Thus,639fiN OFAL , ATKINSON , & UNNEFigure 3: Enumerating preferred extensions AF using algorithm 1.new generated state (i.e. child), due selecting y, much closer statepreferred extension captured. Recall preferred extension achievedx label x IN, UNDEC.Algorithm 1, like algorithms paper, self-contained self-explanatory. Figure 3,however, illustrates algorithm 1 running AF.3.2 Enumerating Stable Extensions AFAlgorithm 2 lists stable extensions. Algorithm 2 seen new implementationalgorithm Dimopoulos et al. (1997). Algorithm 2 differs algorithm 1 two ways:640fiA LGORITHMS RGUMENTATION EMANTICSAlgorithm 1: Enumerating preferred extensions AF (A, R).1234567891011121314151617181920212223242526Lab : {IN, OUT, MUST OUT,UNDEC, BLANK}; Lab 0;/foreach x Lab Lab {(x, BLANK)};E pre f erred 2A ; E pre f erred 0;/call find-preferred-extensions(Lab);report E pre f erred set preferred extensions;procedure find-preferred-extensions(Lab) begin: Lab(y) = BLANKselect Lab(y) = BLANK z {y} Lab(z) {OUT, MUST },otherwise select Lab(y) = BLANK s.t. z : Lab(z) = BLANK, |{x : x{y}+ Lab(x) = }| |{x : x {z}+ Lab(x) = }|;Lab Lab;Lab (y) IN;foreach z {y}+ Lab (z) ;foreach z {y}Lab (z) {UNDEC, BLANK}Lab (z) MUST ;w {z} : Lab (w) = BLANKLab(y) UNDEC;goto line 7;call find-preferred-extensions(Lab );z {y} : Lab(z) {BLANK,UNDEC}Lab(y) UNDEC;elseLab Lab ;x : Lab(x) = MUST{x | Lab(x) = IN};E pre f erred : E pre f erred E pre f erred {S};end procedure641fiN OFAL , ATKINSON , & UNNE1. Algorithm 2 uses four labels: IN, OUT, BLANK MUST OUT. usage labelsoutlined algorithm 1 one distinction: role UNDEC label used algorithm 1 overloaded MUST label. Meaning, algorithm 2 MUSTlabel used also labeling argument, say x, trying build stable extension without x.argument, say x, outside candidate stable extension attackedargument extension, hence x labeled MUST (not UNDECcase algorithm 1.)2. algorithm 1, P = {w | label w IN} preferred extensionx A, label x BLANK MUST P subset previouslyfound preferred extension. algorithm 2 (line 24) set {w | label w IN} stableextension every x A, label x BLANK MUST OUT.Algorithm 2: Enumerating stable extensions AF (A, R).1234567891011121314151617181920212223242526Lab : {IN, OUT, MUST OUT, BLANK}; Lab 0;/foreach x Lab Lab {(x, BLANK)};Estable 2A ; Estable 0;/call find-stable-extensions(Lab);report Estable set stable extensions;procedure find-stable-extensions(Lab) begin: Lab(y) = BLANKselect Lab(y) = BLANK z {y} Lab(z) {OUT, MUST },otherwise select Lab(y) = BLANK s.t. z : Lab(z) = BLANK, |{x : x{y}+ Lab(x) = }| |{x : x {z}+ Lab(x) = }|;Lab Lab;Lab (y) IN;foreach z {y}+ Lab (z) ;foreach z {y}Lab (z) = BLANKLab (z) MUST ;w {z} Lab (w) = BLANKLab(y) MUST ;goto line 7;call find-stable-extensions(Lab );z {y} : Lab(z) = BLANKLab(y) MUST ;elseLab Lab ;x : Lab(x) = MUST{x | Lab(x) = IN};Estable Estable {S};end procedure642fiA LGORITHMS RGUMENTATION EMANTICS3.3 Enumerating Complete Extensions AFAlgorithm 3 lists complete extensions. Algorithm 3 modification algorithm 1 enumerates preferred extensions. algorithm 1, P = {w | label w IN} preferred extensionx A, label x BLANK MUST P subsetpreviously found preferred extension. algorithm 3 (line 10) set {w | label w IN}complete extensionC1. every x A, label x MUSTC2. z UNDEC (or BLANK) label every {z} labelOUT.Recall complete extension admissible set every x acceptable respectS, x belongs S. Thus, condition C1 ensures admissibility C2 guarantees completeness.3.4 Enumerating Stage Extensions AFAlgorithm 4 lists stage extensions. Algorithm 4 alteration algorithm 1 enumeratespreferred extensions. Algorithm 4 uses four labels: IN, OUT, UNDEC BLANK. usagelabels outlined algorithm 1 one distinction: role MUST label usedalgorithm 1 overloaded UNDEC label. Meaning, algorithm 4 UNDEC labelused also identifying arguments attack argument. argument attacksargument stage extension necessarily attacked argument extension.Algorithm 4 constructs conflict free subsets A. particular, algorithm 4 (line 26) keepsrecord conflict free set {w | label w IN} x A, labelx BLANK. constructing conflict free subsets, algorithm 4 decides conflictfree subset, say S, stage extension S+ maximal, see lines 5-9. mightexpected, argument selection pruning strategies used admissibility based semanticsapplicable stage semantics, based conflict free sets. Therefore, pruningstrategy skip labeling argument, say y, UNDEC z {y}+ {y} ,label z UNDEC. based following property: conflict free set, say S,captured UNDEC {y} also conflict free, hence,need label UNDEC since {y} S; recall algorithm 4 labels argument UNDECtrying build stage extension excluding argument. selecting next BLANK argumentlabeled IN, consider rule:R1. select BLANK argument s.t. z {y}+ {y} , label z UNDEC.R2. otherwise select BLANK argument |{x : x {y}+ {y} label xBLANK}| maximal.Note correlation R1 applied pruning strategy: earlier labelargument selected R1 IN, bigger part search tree bypassed.Regarding benefit R2, recall aim argument selection accelerate achievinggoal state, conflict free subset S+ maximal xBLANK label. Indeed, R2 minimises number BLANK arguments maximising numberOUT/UNDEC arguments.643fiN OFAL , ATKINSON , & UNNEAlgorithm 3: Enumerating complete extensions AF (A, R).123456789101112131415161718192021222324252627Lab : {IN, OUT, MUST OUT,UNDEC, BLANK}; Lab 0;/foreach x Lab Lab {(x, BLANK)};Ecomplete 2A ; Ecomplete 0;/call find-complete-extensions(Lab);report Ecomplete set complete extensions;procedure find-complete-extensions(Lab) begin: Lab(y) = MUSTx : Lab(x) {UNDEC, BLANK} z {x} Lab(z) ={w | Lab(w) = IN};Ecomplete Ecomplete {S};: Lab(y) = BLANKselect Lab(y) = BLANK z {y} Lab(z) {OUT, MUST },otherwise select Lab(y) = BLANK s.t. z : Lab(z) = BLANK, |{x : x{y}+ Lab(x) = }| |{x : x {z}+ Lab(x) = }|;Lab Lab;Lab (y) IN;foreach z {y}+ Lab (z) ;foreach z {y}Lab (z) {UNDEC, BLANK}Lab (z) MUST ;w {z} : Lab (w) = BLANKLab(y) UNDEC;goto line 11;call find-complete-extensions(Lab );z {y} : Lab(z) {BLANK,UNDEC}Lab(y) UNDEC;elseLab Lab ;end procedure644fiA LGORITHMS RGUMENTATION EMANTICSAlgorithm 4: Enumerating stage extensions AF (A, R).123456789101112131415161718192021222324252627Lab : {IN, OUT,UNDEC, BLANK}; Lab 0;/foreach x Lab Lab {(x, BLANK)};Estage {Lab1 | Lab1 : {IN, OUT,UNDEC, BLANK}}; Estage 0;/call find-conflict-free-sets(Lab);foreach Lab1 Estageforeach Lab2 Estage{x : Lab1 (x) {IN, }} ( {z : Lab2 (z) {IN, }}Estage Estage \ {Lab1 };continue next iteration line 5;foreach Lab1 Estagereport {x : Lab1 (x) = IN} stage extension ;procedure find-conflict-free-sets(Lab) begin: Lab(y) = BLANKselect Lab(y) = BLANK z {y}+ {y} Lab(z) {OUT,UNDEC},otherwise select Lab(y) = BLANK z : Lab(z) = BLANK, |{x : x{y}+ {y} Lab(x) = BLANK}| |{x : x {z}+ {z} Lab(x) = BLANK}|;Lab Lab;Lab (y) IN;foreach z {y}+ Lab (z) ;foreach z {y}Lab (z) {BLANK}Lab (z) UNDEC;call find-conflict-free-sets(Lab );z {y}+ {y} Lab(z) = BLANKLab(y) UNDEC;elseLab Lab ;Estage Estage {Lab};end procedure645fiN OFAL , ATKINSON , & UNNE3.5 Enumerating Semi Stable Extensions AFAlgorithm 5 enumerates semi stable extensions. Again, algorithm 5 reproduction algorithm 1. Actually, algorithm 5 firstly builds admissible sets. Then, algorithm decidesadmissible set, say S, semi stable extension S+ maximal; see lines 6-10.Algorithm 5: Enumerating semi stable extensions AF (A, R).1234567891011121314151617181920212223242526272829303132Lab : {IN, OUT, MUST OUT,UNDEC, BLANK}; Lab 0;/foreach x Lab Lab {(x, BLANK)};Esemistable {Lab1 | Lab1 : {IN, OUT, MUST OUT,UNDEC, BLANK}};Esemistable 0;/call find-admissible-sets(Lab);foreach Lab1 Esemistableforeach Lab2 Esemistable{x : Lab1 (x) {IN, }} ( {z : Lab2 (z) {IN, }}Esemistable Esemistable \ {Lab1 };continue next iteration line 6;foreach Lab1 Esemistablereport {x : Lab1 (x) = IN} semi stable extension ;procedure find-admissible-sets(Lab) begin: Lab(y) = BLANKselect Lab(y) = BLANK z {y} Lab(z) {OUT, MUST },otherwise select Lab(y) = BLANK s.t. z : Lab(z) = BLANK, |{x : x{y}+ Lab(x) = }| |{x : x {z}+ Lab(x) = }|;Lab Lab;Lab (y) IN;foreach z {y}+ Lab (z) ;foreach z {y}Lab (z) {UNDEC, BLANK}Lab (z) MUST ;w {z} : Lab (w) = BLANKLab(y) UNDEC;goto line 14;call find-admissible-sets(Lab );z {y} : Lab(z) {BLANK,UNDEC}Lab(y) UNDEC;elseLab Lab ;x : Lab(x) = MUSTEsemistable Esemistable {Lab};end procedure646fiA LGORITHMS RGUMENTATION EMANTICS3.6 Constructing Ideal Extension AFAlgorithm 6 builds ideal extension. algorithm modification algorithm 1. Algorithm 6(line 28) records {w | label w IN} admissible set x A, labelx BLANK MUST OUT. However, algorithm also constructs (line 27) = {x |exists admissible set x + }. building set admissible setsconstructed, algorithm 6 considers admissible set ideal extension= 0;/ see lines 6-8. Recall ideal extension maximal (w.r.t. ) admissibleset contained every preferred extension. Satisfying condition = 0/ impliesarguments attacked admissible set (see definition above),means contained every preferred extension. ensure maximal, algorithm 6 collectsadmissible sets descending order: larger sets smaller ones. consequence, algorithmchecks collected admissible sets condition = 0/ starting larger admissible setssmaller ones.3.7 Constructing Grounded Extension AFAlgorithm 7 viewed another implementation algorithm described ModgilCaminada (2009) building grounded extension.4. Labeling Attacks Generalization Labeling Argumentssection illustrate enumerate extensions, number argumentation semantics, labeling attacks together arguments instead labeling arguments solely. end,develop algorithms listing extensions AFRA (Baroni et al., 2011b) preferred,stable, complete, stage, semi stable, ideal grounded semantics subsections 4.1, 4.2, 4.3, 4.4,4.5, 4.6 4.7 respectively. algorithms basically generalization algorithmspresented previous section, hence algorithms list extensions AF / AFRA.4.1 Enumerating Preferred Extensions AF / AFRAAlgorithm 8 enumerates preferred extensions AFRA. Algorithm 8 generalizationalgorithm 1. idea based using five labels: IN, OUT, MUST OUT, BLANK UNDEC.BLANK label initial label arguments attacks. BLANK attack R labeledindicate might preferred extension. argument x labeledR label trg(y) = x. attack z R labeledR label trg(y) {z, src(z)}. BLANK argument x labeled IN,implying x might preferred extension, R labelsrc(y) = x z R : trg(z) = x label z OUT. attack labeled UNDECtry find preferred extension excluding y. attack z label BLANK/UNDEC labeledMUST R label trg(z) {y, src(y)}. Everytime attack labeled labels attacks arguments might change accordingly, seelines 10-20 algorithm 8. selection rule, line 8 represents strategy algorithmselects next attack, BLANK, labeled IN. rule grounds parallelselection rule applied algorithm 1 enumerating preferred extensions AF. Likewise,algorithm 8 applies two pruning tactics:647fiN OFAL , ATKINSON , & UNNEAlgorithm 6: Constructing ideal extension AF (A, R).1234567891011121314151617181920212223242526272829Lab : {IN, OUT, MUST OUT,UNDEC, BLANK}; Lab 0;/foreach x Lab Lab {(x, BLANK)};Eideal : Z 2A ; Eideal 0;/0;/call find-admissible-sets(Lab);foreach = 1 .. |Eideal |Eideal (i) = 0/report Eideal (i) ideal extension; exit;procedure find-admissible-sets(Lab) begin: Lab(y) = BLANKselect Lab(y) = BLANK z {y} Lab(z) {OUT, MUST },otherwise select Lab(y) = BLANK s.t. z : Lab(z) = BLANK, |{x : x{y}+ Lab(x) = }| |{x : x {z}+ Lab(x) = }|;Lab Lab;Lab (y) IN;foreach z {y}+ Lab (z) ;foreach z {y}Lab (z) {UNDEC, BLANK}Lab (z) MUST ;w {z} : Lab (w) = BLANKLab(y) UNDEC;goto line 10;call find-admissible-sets(Lab );z {y} : Lab(z) {BLANK,UNDEC}Lab(y) UNDEC;elseLab Lab ;w : Lab(w) = MUST{x | Lab(x) = };Eideal Eideal {(|Eideal | + 1, {z | Lab(z) = IN})};end procedureAlgorithm 7: Constructing grounded extension AF (A, R).1234567Lab : {IN, OUT,UNDEC}; Lab 0;/foreach w Lab Lab {(w,UNDEC)};x Lab(x) = UNDEC : {x} Lab(y) =foreach x Lab(x) = UNDEC : {x} Lab(y) =Lab(x) IN;foreach z {x}+ Lab(z) ;report grounded extension {w | Lab(w) = IN};648fiA LGORITHMS RGUMENTATION EMANTICSFigure 4: algorithm 8 works AFRA.1. Algorithm 8 (lines 17- 20) skips labeling attack (i.e. skips expanding left child)z : trg(z) {y, src(y)} label f zw label BLANK : trg(w) {z, src(z)}.2. Algorithm 8 (lines 22- 25) skips labeling attack UNDEC (i.e. skips expanding rightchild) z R : trg(z) {y, src(y)}, label z MUST OUT.get general idea algorithm 8 see figure 4 shows algorithm worksAFRA depicted figure 2.4.2 Enumerating Stable Extensions AF / AFRAAlgorithm 9 enumerates stable extensions. Actually, algorithm 9 modification algorithm 8lists preferred extensions. However two differences:1. Algorithm 9 uses four labels: IN, OUT, BLANK MUST OUT. usage labelsoutlined algorithm 8 one difference: role UNDEC label used algorithm 8 overloaded MUST label. is, algorithm 9 MUSTlabel used also labeling attack, say x, trying build stable extension without x.attack, say x, outside candidate stable extension defeatedattack extension, hence x labeled MUST OUT.2. algorithm 8 find preferred extension, say P, x R, xBLANK MUST P subset previously found preferred extension.algorithm 9 encounter stable extension x R, x BLANKMUST OUT.649fiN OFAL , ATKINSON , & UNNEAlgorithm 8: Enumerating preferred extensions AFRA (A, R).12345678910111213141516171819202122232425262728293031Lab : (A R) {IN, OUT, MUST OUT,UNDEC, BLANK}; Lab 0;/foreach x R Lab Lab {(x, BLANK)};E pre f erred 2AR ; E pre f erred 0;/call find-preferred-extensions(Lab);report E pre f erred set preferred extensions;procedure find-preferred-extensions(Lab) beginR : Lab(y) = BLANKselect R Lab(y) = BLANKz R : trg(z) {y, src(y)} Lab(z) {OUT, MUST }, otherwise select RLab(y) = BLANK z R : Lab(z) = BLANK|{x : src(x) = trg(y) Lab(x) = }| |{x : src(x) = trg(z) Lab(x) = }|;Lab Lab;Lab (y) IN;Lab (src(y)) IN;Lab (trg(y)) ;trg(y)foreach z R : src(z) = trg(y)Lab (z) ;foreach z R : Lab (z) {BLANK,UNDEC} trg(z) {y, src(y)}Lab (z) MUST ;w R : Lab (w) = BLANK trg(w) {z, src(z)}Lab(y) UNDEC;goto line 7;call find-preferred-extensions(Lab );z R : Lab(z) {BLANK,UNDEC} trg(z) {y, src(y)}Lab(y) UNDEC;elseLab Lab ;w R : Lab(w) = MUSTforeach x Lab(x) = BLANK s.t. z R : trg(z) = x (Lab(z) = )Lab(x) IN;{x R | Lab(x) = IN};E pre f erred (S )E pre f erred E pre f erred {S};end procedure650fiA LGORITHMS RGUMENTATION EMANTICSAlgorithm 9: Enumerating stable extensions AFRA (A, R).1234567891011121314151617181920212223242526272829Lab : (A R) {IN, OUT, MUST OUT, BLANK}; Lab 0;/foreach x R Lab Lab {(x, BLANK)};E stable 2AR ; E stable 0;/call find-stable-extensions(Lab);report E stable set stable extensions;procedure find-stable-extensions(Lab) beginR : Lab(y) = BLANKselect R Lab(y) = BLANKz R : trg(z) {y, src(y)} Lab(z) {OUT, MUST }, otherwise select RLab(y) = BLANK z R : Lab(z) = BLANK|{x : src(x) = trg(y) Lab(x) = }| |{x : src(x) = trg(z) Lab(x) = }|;Lab Lab;Lab (y) IN;Lab (src(y)) IN;Lab (trg(y)) ;trg(y)foreach z R : src(z) = trg(y)Lab (z) ;foreach z R : Lab (z) = BLANK trg(z) {y, src(y)}Lab (z) MUST ;w R : Lab (w) = BLANK trg(w) {z, src(z)}Lab(y) MUST ;goto line 7;call find-stable-extensions(Lab );z R : Lab(z) = BLANK trg(z) {y, src(y)}Lab(y) MUST ;elseLab Lab ;w R : Lab(w) = MUSTforeach x Lab(x) = BLANK s.t. z R : trg(z) = x (Lab(z) = )Lab(x) IN;E stable E stable {{x R | Lab(x) = IN}};end procedure651fiN OFAL , ATKINSON , & UNNE4.3 Enumerating Complete Extensions AF / AFRAAlgorithm 10 enumerates complete extensions. Again, algorithm 10 modification algorithm 8 lists preferred extensions. algorithm 8 achieve preferred extension, say P,x R, label x BLANK MUST P subsetpreviously found preferred extension. However, algorithm 10 (line 7) encounter completeextensionC1. z R MUST labelC2. exist w R(a) label w UNDEC BLANK(b) R : trg(y) {w, src(w)}, label OUT.Thus, C1 ensures admissibility C2 guarantees completeness.4.4 Enumerating Stage Extensions AF / AFRAAlgorithm 11 lists stage extensions. algorithm rewrite algorithm 8. However, algorithm 11 uses four labels: IN, OUT, BLANK UNDEC. usage labels outlinedalgorithm 8 one difference: role MUST label used algorithm 8overloaded UNDEC label. is, algorithm 11 UNDEC label used also identifying attacks attack argument/attack. attack defeats argument/attackstage extension necessarily defeated attack extension.Algorithm 11 (lines 14-29) finds set conflict free subsets R rather constructingadmissible subsets done algorithm 8. algorithm 8 set {w R | label w IN}reported admissible set x R, label x BLANKMUST OUT. algorithm 11 set {w R | label w IN} recorded conflict freeset (i.e. stage extension candidate) x R, label x BLANK,see lines 14 & 31. building set conflict free subsets, algorithm 11 decides conflictfree subset R stage extension {x | : defeats x} maximal, seelines 6-10. stated earlier, argument selection pruning strategies used semanticsbased admissible sets applicable stage semantics, based conflict freesets. Therefore, pruning strategy (line 29 algorithm 11) skip labeling attack UNDEC(i.e. skip expanding right child)z R : trg(z) {y, src(y)} trg(y) {z, src(z)},label f z UNDEC.based property conflict free set, say S, formed UNDEC{y} also conflict free, hence, need label UNDEC since {y} S.selecting next BLANK attack labeled IN, apply following rule (see line 15):R1. select BLANK attack s.t. z R : trg(z) {y, src(y)} trg(y) {z, src(z)},label z UNDEC.R2. otherwise select BLANK attack |{x : label x BLANK (src(x) =trg(y) trg(x) {y, src(y)})}| maximal.652fiA LGORITHMS RGUMENTATION EMANTICSAlgorithm 10: Enumerating complete extensions AFRA (A, R).1234567891011121314151617181920212223242526272829Lab : (A R) {IN, OUT, MUST OUT,UNDEC, BLANK}; Lab 0;/foreach x R Lab Lab {(x, BLANK)};E complete 2AR ; E complete 0;/call find-complete-extensions(Lab);report E complete set complete extensions;procedure find-complete-extensions(Lab) beginv R Lab(v) = MUST w R : Lab(w) {UNDEC, BLANK}R : trg(y) {w, src(w)} Lab(y) =foreach x Lab(x) = BLANK s.t. z R : trg(z) = x (Lab(z) = )Lab(x) IN;E complete E complete {{x R | Lab(x) = IN)}};R : Lab(y) = BLANKselect R Lab(y) = BLANKz R : trg(z) {y, src(y)} Lab(z) {OUT, MUST }, otherwise select RLab(y) = BLANK z R : Lab(z) = BLANK|{x : src(x) = trg(y) Lab(x) = }| |{x : src(x) = trg(z) Lab(x) = }|;Lab Lab;Lab (y) IN;Lab (src(y)) IN;Lab (trg(y)) ;trg(y)foreach z R : src(z) = trg(y)Lab (z) ;foreach z R : Lab (z) {BLANK,UNDEC} trg(z) {y, src(y)}Lab (z) MUST ;w R : Lab (w) = BLANK trg(w) {z, src(z)}Lab(y) UNDEC;goto line 10;call find-complete-extensions(Lab );z R : Lab(z) {BLANK,UNDEC} trg(z) {y, src(y)}Lab(y) UNDEC;elseLab Lab ;end procedure653fiN OFAL , ATKINSON , & UNNEaim R1 maximise gain applied pruning strategy. Meaning, earlierlabel selected argument R1 IN, greater saving terms partsearch tree pruned. Regarding R2, note goal state (i.e. conflict free set) reachedx R, label x BLANK. Thus, R2 tries maximisenumber OUT/UNDEC attacks/arguments, implies minimising number BLANKattacks/arguments.4.5 Enumerating Semi Stable Extensions AF / AFRAAlgorithm 12 lists semi stable extensions. Algorithm 12 variation algorithm 8basically constructs admissible sets. Algorithm 12 (line 31) records set {w | label w IN}admissible set (that semi stable extension candidate) x R,label x BLANK MUST OUT. constructing set admissible sets, algorithm 12decides admissible set semi stable extension {x | : defeats x}maximal, see lines 6-10.4.6 Constructing Ideal Extension AF / AFRAAlgorithm 13 builds ideal extension. particular, algorithm 13 finds admissible sets (lines 1028) way algorithm 8 does. However, enumerating admissible sets algorithm 13(line 31) also builds set= {x R | admissible set trg(y) {x, src(x)}}building set admissible sets constructed, algorithm 13 decidesadmissible set ideal extension = 0,/ see lines 6-8. Recallideal extension maximal (w.r.t. ) admissible set contained every preferredextension. Satisfying condition = 0/ implies arguments/attacks defeatedadmissible set (see definition above), means contained every preferredextension. ensure maximal, algorithm 13 collects admissible sets descending order:larger sets smaller ones. consequence, algorithm checks collected admissible setscondition = 0/ starting larger admissible sets smaller ones.4.7 Constructing Grounded Extension AF / AFRAAlgorithm 14 builds grounded extension. Algorithm 14 actually generalization algorithm 7.5. Practical Efficiencyalgorithms presented paper implemented C++ Fedora (release 13) basedmachine 4 processors (Intel core i5-750 2.67GHz) 16GB memory. evaluation criterion, considered average elapsed time measured seconds; elapsed time obtainedusing time command Linux. present experimental results two purposes. First,explore efficiency algorithms section 3. second purpose, confirmgeneralized algorithms section 4, enumerate extensions labeling attacks togetherarguments, perform efficiently algorithms section 3, enumerate extensionslabeling arguments alone.654fiA LGORITHMS RGUMENTATION EMANTICSAlgorithm 11: Enumerating stage extensions AFRA (A, R).1234567891011121314151617181920212223242526272829303132Lab : (A R) {IN, OUT,UNDEC, BLANK}; Lab 0;/foreach x R Lab Lab {(x, BLANK)};E stage {Lab1 | Lab1 : (A R) {IN, OUT,UNDEC, BLANK}};E stage 0;/call find-conflict-free-sets(Lab);foreach Lab1 E stageforeach Lab2 E stage{x : Lab1 (x) {IN, }} ( {z : Lab2 (z) {IN, }}E stage E stage \ {Lab1 };continue next iteration line 6;foreach Lab1 E stagereport {x : Lab1 (x) = IN} stage extension ;procedure find-conflict-free-sets(Lab) beginR : Lab(y) = BLANKselect R Lab(y) = BLANK s.t.z R : trg(z) {y, src(y)} trg(y) {z, src(z)} (Lab(z) {OUT,UNDEC}),otherwise select R Lab(y) = BLANK s.t.z R : Lab(z) = BLANK |{x : Lab(x) = BLANK (src(x) = trg(y) trg(x){y, src(y))}}| |{x : Lab(x) = BLANK (src(x) = trg(z) trg(x) {z, src(z))}}|;Lab Lab;Lab (y) IN;Lab (src(y)) IN;Lab (trg(y)) ;trg(y)foreach z R : src(z) = trg(y)Lab (z) ;foreach z R : Lab (z) = BLANK trg(z) {y, src(y)}Lab (z) UNDEC;call find-conflict-free-sets(Lab );z R : Lab(z) = BLANK (trg(z) {y, src(y)} trg(y) {z, src(z)})Lab(y) UNDEC;elseLab Lab ;foreach x Lab(x) = BLANK s.t. z R : trg(z) = x (Lab(z) = )Lab(x) IN;E stage E stage {Lab};end procedure655fiN OFAL , ATKINSON , & UNNEAlgorithm 12: Enumerating semi stable extensions AFRA (A, R).1234567891011121314151617181920212223242526272829303132Lab : (A R) {IN, OUT, MUST OUT,UNDEC, BLANK}; Lab 0;/foreach x R Lab Lab {(x, BLANK)};E semistable {Lab1 | Lab1 : (A R) {IN, OUT, MUST OUT,UNDEC, BLANK}};E semistable 0;/call find-admissible-sets(Lab);foreach Lab1 E semistableforeach Lab2 E semistable{x : Lab1 (x) {IN, }} ( {z : Lab2 (z) {IN, }}E semistable E semistable \ {Lab1 };continue next iteration line 6;foreach Lab1 E semistablereport {x : Lab1 (x) = IN} semi stable extension ;procedure find-admissible-sets(Lab) beginR : Lab(y) = BLANKselect R Lab(y) = BLANK s.t.z R : trg(z) {y, src(y)} Lab(z) {OUT, MUST }, otherwise select RLab(y) = BLANK s.t. z R : Lab(z) = BLANK |{x : src(x) = trg(y) Lab(x) =}| |{x : src(x) = trg(z) Lab(x) = }|;Lab Lab; Lab (y) IN; Lab (src(y)) IN;Lab (trg(y)) ;trg(y)foreach z R : src(z) = trg(y) Lab (z) ;foreach z R : Lab(z) {BLANK,UNDEC} trg(z) {y, src(y)}Lab (z) MUST ;w R : Lab (w) = BLANK trg(w) {z, src(z)}Lab(y) UNDEC; goto line 14;call find-admissible-sets(Lab );z R : Lab(z) {BLANK,UNDEC} trg(z) {y, src(y)}Lab(y) UNDEC;elseLab Lab ;R : Lab(y) = MUSTforeach x Lab(x) = BLANK s.t. z R : trg(z) = x (Lab(z) = )Lab(x) IN;E semistable E semistable {Lab};end procedure656fiA LGORITHMS RGUMENTATION EMANTICSAlgorithm 13: Constructing ideal extension AFRA (A, R).123456789101112131415161718192021222324252627282930313233Lab : (A R) {IN, OUT, MUST OUT,UNDEC, BLANK}; Lab 0;/foreach x R Lab Lab {(x, BLANK)};E ideal : Z 2AR ; E ideal 0;/0;/call find-admissible-sets(Lab);foreach : 1 |E ideal |/ S)x E ideal (i) (xreport E ideal (i) ideal extension; exit;procedure find-admissible-sets(Lab) beginR : Lab(y) = BLANKselect R Lab(y) = BLANK s.t.z R : trg(z) {y, src(y)} Lab(z) {OUT, MUST }, otherwise select RLab(y) = BLANK z R : Lab(z) = BLANK|{x : src(x) = trg(y) Lab(x) = }| |{x : src(x) = trg(z) Lab(x) = }|;Lab Lab;Lab (y) IN;Lab (src(y)) IN;Lab (trg(y)) ;trg(y)foreach z R : src(z) = trg(y)Lab (z) ;foreach z R : Lab (z) {BLANK,UNDEC} trg(z) {y, src(y)}Lab (z) MUST ;w R : Lab (w) = BLANK trg(w) {z, src(z)}Lab(y) UNDEC;goto line 10;call find-admissible-sets(Lab );z R : Lab(z) {BLANK,UNDEC} trg(z) {y, src(y)}Lab(y) UNDEC;elseLab Lab ;w R : Lab(w) = MUSTforeach x Lab(x) = BLANK s.t. z R : trg(z) = x (Lab(z) = )Lab(x) IN;{x R | Lab(x) = };E ideal E ideal {(|E ideal | + 1, {z | Lab(z) = IN})};end procedure657fiN OFAL , ATKINSON , & UNNEAlgorithm 14: Constructing grounded extension AFRA (A, R).123456789101112Lab : (A R) {IN, OUT,UNDEC}; Lab 0;/foreach w R Lab Lab {(w,UNDEC)};x R Lab(x) = UNDEC s.t. R : trg(y) {x, src(x)} (Lab(y) = )foreach x R Lab(x) = UNDEC s.t. R : trg(y) {x, src(x)} (Lab(y) = )Lab(x) IN;Lab(src(x)) IN;Lab(trg(x)) ;trg(x)foreach z R : trg(x) = src(z)Lab(z) ;foreach x Lab(x) = UNDEC s.t. z R : trg(z) = x (Lab(z) = )Lab(x) IN;report grounded extension {w R | Lab(w) = IN};compared algorithms dynPARTIX, implemented system baseddynamic programming algorithm Dvorak, Pichler, Woltran (2012b). Given AF, dynPARTIX basically computes tree decomposition AF extensions enumerated basedtree decomposition. algorithm used dynPARTIX fixed-parameter tractabletime complexity depends tree width given AF linear sizeAF (Dvorak et al., 2012b). Since dynPARTIX computes extensions preferred, stablecomplete semantics, figures 5, 6 & 7 depict respectively efficiency algorithms 1, 2 & 3 versus dynPARTIX. summary, figures show algorithms likely efficientdynPARTIX. running experiments represented figures, set timelimit 120 seconds every execution. 1000 runs, dynPARTIX encountered 316 timeoutsenumerating preferred extensions 827 timeouts enumerating complete extensions.timeouts plotted within figures 120 seconds. explains steady behavior dynPARTIX noted, particularly, figure 7. see performance algorithms 1-7contrast behavior algorithms 8-14 present figures 8-14 respectively. profiling algorithms 1-7, reported running times including time needed get corresponding AFAFRA. Note process (i.e. expressing AFRA AF) runs polynomial time:worst quadratic time. figures 8-14 plot running times 1000 instances AFRA randomlygenerated |A| = 5 R = R1 R2 s.t. R1 R2 R1 . instances |R|grows 0 100 probability, used setting attacks random generation, goes {0.01,0.02,0.03,...,1}. Note instances |A| = 5 consideredquite small. example, randomly generated AFRA |A| = 5 |R| = 49 corresponding AF |A| = 54 |R| = 190. Again, emphasize aim experimentscompare performance algorithms 1-7 performance algorithms 8-14.mean experiments check scalability algorithms, although important issueexamined. Said that, crucial evaluation consider large frameworkshigher level recursive attacks. Back results experiments, case involvedexceeding 120-second time limit occurred enumerating semi stable extensions. Referring658fiA LGORITHMS RGUMENTATION EMANTICSFigure 5: Enumerating preferred extensions 1000 instances AF |A|=40, p{0.01, 0.02, 0.03, ..., 1} tracked average elapsed time 10 instances generatedrandomly probability p (i.e. probability x attacks x, A).figure 12 note algorithm 5 (resp. 12) encountered 68 (resp. 66) timeouts. bottomline conclusion figures is: enumerating extensions AFRA labeling attacks togetherarguments seems efficient enumerating extensions corresponding AF vialabeling arguments alone.6. Discussion Conclusionstarted paper refining implemented algorithms1 enumerating extensions Dungsargumentation frameworks (AFs) number argumentation semantics: preferred, stable,complete, stage, semi stable, ideal grounded. Algorithms semantics, except stagegrounded semantics, share similar core structure: basically build admissible setsorder construct extensions. case stage semantics, algorithm actually constructsconflict free sets purpose listing stage extensions, hence, algorithm appliesslightly different approach expanding search tree elaborated earlier. Concerninggrounded semantics, presented algorithm builds grounded extension polynomial time.Furthermore, explored practical efficiency algorithms profiling performancerunning wide spectrum AF instances: sparse instances dense ones. essencealgorithms construct extensions using total function maps arguments solelyset labels reflecting different states illustrated paper. Then, generalizedalgorithms using total mapping labels attacks together arguments. implementedgeneralized algorithms enumerate extensions AFRA, AF-extended model1. C++ implementations found http://sourceforge.net/projects/argtools/files/659fiN OFAL , ATKINSON , & UNNEFigure 6: Enumerating stable extensions 1000 instances AF |A|=60, p{0.01, 0.02, 0.03, ..., 1} tracked average elapsed time 10 instances generatedrandomly probability p.Figure 7: Enumerating complete extensions 1000 instances AF |A|=30, p{0.01, 0.02, 0.03, ..., 1} tracked average elapsed time 10 instances generatedrandomly probability p.660fiA LGORITHMS RGUMENTATION EMANTICSFigure 8: Enumerating preferred extensions 1000 instances AFRA, p{0.01, 0.02, 0.03, ..., 1} tracked average elapsed time 10 instances generatedrandomly probability p.Figure 9: Enumerating stable extensions 1000 instances AFRA, p{0.01, 0.02, 0.03, ..., 1} tracked average elapsed time 10 instances generatedrandomly probability p.661fiN OFAL , ATKINSON , & UNNEFigure 10: Enumerating complete extensions 1000 instances AFRA, p{0.01, 0.02, 0.03, ..., 1} tracked average elapsed time 10 instances generatedrandomly probability p.Figure 11: Listing stage extensions 1000 instances AFRA, p{0.01, 0.02, 0.03, ..., 1} tracked average elapsed time 10 instances generated randomly probability p.662fiA LGORITHMS RGUMENTATION EMANTICSFigure 12: Listing semi stable extensions 1000 instances AFRA, p{0.01, 0.02, 0.03, ..., 1} tracked average elapsed time 10 instances generatedrandomly probability p.Figure 13: Constructing ideal extension 1000 instances AFRA, p{0.01, 0.02, 0.03, ..., 1} tracked average elapsed time 10 instances generatedrandomly probability p.663fiN OFAL , ATKINSON , & UNNEFigure 14: Constructing grounded extension 1000 instances AFRA, p{0.01, 0.02, 0.03, ..., 1} tracked average elapsed time 10 instances generatedrandomly probability p.allows attacks attacks. words, offered unified approach enumerating extensionsAF/AFRA, given fact AF special case AFRA (Baroni et al., 2011b).hand, showed labeling attacks alongside arguments potentially usedbasis enumerating extensions related formalisms allow attacks attacks (e.g. Modgil,2009b; Gabbay, 2009); nonetheless confirmed research. fact, extensionsinstance formalisms listed working corresponding AF. However,demonstrated enumerate extensions AFRA applying labeling directly nativeform without compromising running time efficiency. omitted soundness/completenessproof presented algorithms since follows immediately proof algorithmNofal, Atkinson Dunne (2014) preferred semantics. algorithms presented paperhandle frameworks self-attacking arguments perfectly. However, algorithmseasily modified initial label self-attacking argument UNDEC insteadBLANK. instance, change necessary made algorithm 1 modify line 2followsforeach x(x, x) R Lab Lab {(x,UNDEC)};else Lab Lab {(x, BLANK)};general, UNDEC label (instead BLANK label) default labelargument/attack extension, like self-attacking arguments outgoingattacks simply arguments present conflict themselves. Recall BLANKarguments/attacks tried label.future work, plan study additional options argument selection. Also, intendevaluate strategies pruning search space.664fiA LGORITHMS RGUMENTATION EMANTICSdiscuss related work. existing algorithms Doutre Mengin (2001) ModgilCaminada (2009) listing preferred extensions also re-engineered towards enumeratingextensions argumentation semantics. example, papers Caminada (2007, 2010)presented algorithms enumerating semi stable, respectively stage, extensions buildingalgorithm Modgil Caminada (2009). However, algorithms present paper basedalgorithm Nofal, Atkinson Dunne (2014) enumerating preferred extensions,likely efficient existing algorithms (Nofal et al., 2014). giveexamples related work labeling-based semantics. theory Caminada Gabbay (2009)defined argumentation semantics using total mapping : {IN, OUT,UNDEC} that,broadly speaking, labeled arguments correspond extension, say S,labeled arguments correspond S+ UNDEC labeled arguments correspond \ (S S+ ).hard see connection algorithms theory Caminada Gabbay(2009). example, algorithm 1 capture preferred extension argumentsmapped one labels: IN, UNDEC. Listing works present labelingbased semantics, paper Modgil (2009a) defined labeling-based semantics extendedAF Modgil (2009b) Villata, Boella, van der Torre (2011) described argumentationsemantics terms attacks arguments. Also, work Gabbay (2009) set argumentationsemantics AF-extended model Barringer, Gabbay, Woods (2005) amongfeatures allow attacks attacks. topic extension computation general, studyLi, Oren, Norman (2012) examined approximation versus exact computations, whereasexperiments Baumann, Brewka, Wong (2012), Liao, Lei, Dai (2013) evaluated effectsplitting AF computation preferred extensions. work Dondio (2013) studied,grounded semantics, acceptance status argument varies subgraphsgiven AF. Computational complexity argumentation semantics widely studied (see e.g.Dimopoulos, Nebel, & Toni, 2000; Dunne, 2007, 2009; Ordyniak & Szeider, 2011). Another lineresearch concerns encoding computational problems AFs formalisms solvingusing respective solver (e.g. Besnard & Doutre, 2004; Nieves, Cortes, & Osorio, 2008;Egly, Gaggl, & Woltran, 2010; Amgoud & Devred, 2011; Dvorak, Jarvisalo, Wallner, & Woltran,2012a; Cerutti, Dunne, Giacomin, & Vallati, 2013; Charwat, Dvorak, Gaggl, Wallner, & Woltran,2013), approaches called reduction based methods. stress focus paperalgorithmic based implementations argumentation semantics.Acknowledgmentsthank anonymous reviewers comments improved presentation work.ReferencesAmgoud, L., & Devred, C. (2011). Argumentation frameworks constraint satisfaction problems.Benferhat, S., & Grant, J. (Eds.), SUM, Vol. 6929 Lecture Notes Computer Science,pp. 110122. Springer.Baroni, P., Caminada, M., & Giacomin, M. (2011a). introduction argumentation semantics.Knowledge Engineering Review, 26(4), 365410.665fiN OFAL , ATKINSON , & UNNEBaroni, P., Cerutti, F., Giacomin, M., & Guida, G. (2011b). Argumentation framework recursive attacks. International Journal Approximate Reasoning, 52(1), 1937.Barringer, H., Gabbay, D., & Woods, J. (2005). Temporal dynamics support attack networks:argumentation zoology. Hutter, D., & Stephan, W. (Eds.), Mechanizing Mathematical Reasoning, Vol. 2605 Lecture Notes Computer Science, pp. 5998. Springer.Baumann, R., Brewka, G., & Wong, R. (2012). Splitting argumentation frameworks: empiricalevaluation. Modgil, S., Oren, N., & Toni, F. (Eds.), First International Workshop TheoryApplications Formal Argumentation 2011, Vol. 7132 Lecture Notes ComputerScience, pp. 1731. Springer.Bench-Capon, T., & Dunne, P. (2007). Argumentation artificial intelligence. Artificial Intelligence, 171, 619641.Besnard, P., & Doutre, S. (2004). Checking acceptability set arguments. Delgrande,J., & Schaub, T. (Eds.), NMR, pp. 5964.Besnard, P., & Hunter, A. (2008). Elements Argumentation. MIT press.Caminada, M. (2007). algorithm computing semi-stable semantics. Mellouli, K. (Ed.),ECSQARU, Vol. 4724 Lecture Notes Computer Science, pp. 222234. Springer.Caminada, M. (2010). algorithm stage semantics. Baroni, P., Cerutti, F., Giacomin, M., &Simari, G. (Eds.), COMMA, Vol. 216 Frontiers Artificial Intelligence Applications,pp. 147158. IOS Press.Caminada, M., Carnielli, W., & Dunne, P. (2012). Semi-stable semantics. J. Log. Comput., 22(5),12071254.Caminada, M., & Gabbay, D. (2009). logical account formal argumentation. Studia Logica,93(2-3), 109145.Cerutti, F., Dunne, P., Giacomin, M., & Vallati, M. (2013). sat-based approach computingextensions abstract argumentation. TAFA, Second International Workshop TheoryApplications Formal Argumentation.Charwat, G., Dvorak, W., Gaggl, S., Wallner, J., & Woltran, S. (2013). Implementing abstract argumentation - survey. Tech. rep. DBAI-TR-2013-82, Technische Universitat Wien, DatabaseArtificial Intelligence Group.Dimopoulos, Y., Magirou, V., & Papadimitriou, C. (1997). kernels, defaults even graphs.Annals Mathematics Artificial Intelligence, 20, 112.Dimopoulos, Y., Nebel, B., & Toni, F. (2000). Finding admissible preferred argumentshard. Cohn, A., Giunchiglia, F., & Selman, B. (Eds.), KR, pp. 5361. MorganKaufmann.Dondio, P. (2013). Computing grounded semantics subgraphs argumentationframework: empirical evaluation. CLIMA, XIV Workshop Computational LogicMulti-Agent Systems.Doutre, S., & Mengin, J. (2001). Preferred extensions argumentation frameworks: Query answering computation. Gore, R., Leitsch, A., & Nipkow, T. (Eds.), IJCAR, Vol. 2083Lecture Notes Computer Science, pp. 272288. Springer.666fiA LGORITHMS RGUMENTATION EMANTICSDung, P. (1995). acceptability arguments fundamental role non monotonicreasoning, logic programming n-person games. Artificial Intelligence, 77(2), 321357.Dung, P., Mancarella, P., & Toni, F. (2007). Computing ideal skeptical argumentation. ArtificialIntelligence, 171(10-15), 642674.Dunne, P. (2007). Computational properties argument systems satisfying graph-theoretic constraints. Artificial Intelligence, 171, 701729.Dunne, P. (2009). computational complexity ideal semantics. Artificial Intelligence, 173(18),1559 1591.Dvorak, W., Jarvisalo, M., Wallner, J. P., & Woltran, S. (2012a). Complexity-sensitive decisionprocedures abstract argumentation. Brewka, G., Eiter, T., & McIlraith, S. (Eds.), KR.AAAI Press.Dvorak, W., Pichler, R., & Woltran, S. (2012b). Towards fixed-parameter tractable algorithmsabstract argumentation. Artificial Intelligence, 186, 137.Egly, U., Gaggl, S., & Woltran, S. (2010). Answer-set programming encodings argumentationframeworks. Argument Computation, 1(2), 147177.Gabbay, D. (2009). Semantics higher level attacks extended argumentation frames part 1:Overview. Studia Logica, 93(2-3), 357381.Li, H., Oren, N., & Norman, T. (2012). Probabilistic argumentation frameworks. Modgil, S.,Oren, N., & Toni, F. (Eds.), First International Workshop Theory ApplicationsFormal Argumentation 2011, Vol. 7132 Lecture Notes Computer Science, pp. 116.Springer.Liao, B., Lei, L., & Dai, J. (2013). Computing preferred labellings exploiting sccssceptically rejected arguments. TAFA, Second International Workshop Theory Applications Formal Argumentation.Modgil, S. (2009a). Labellings games extended argumentation frameworks. Boutilier, C.(Ed.), IJCAI, pp. 873878.Modgil, S. (2009b). Reasoning preferences argumentation frameworks. Artificial Intelligence, 173, 901934.Modgil, S., & Caminada, M. (2009). Proof theories algorithms abstract argumentationframeworks. Rahwan, I., & Simari, G. (Eds.), Argumentation Artificial Intelligence, pp.105129. Springer.Modgil, S., Toni, F., Bex, F., Bratko, I., Chesnevar, C., Dvorak, W., Falappa, M., Fan, X., Gaggl, S.,Garca, A., Gonzalez, M., Gordon, T., Leite, J., Mozina, M., Reed, C., Simari, G., Szeider, S.,Torroni, P., & Woltran, S. (2013). added value argumentation. Ossowski, S. (Ed.),Agreement Technologies, Vol. 8 Law, Governance Technology Series, pp. 357403.Springer Netherlands.Nieves, J., Cortes, U., & Osorio, M. (2008). Preferred extensions stable models. TheoryPractice Logic Programming, 8(4), 527543.Nofal, S., Atkinson, K., & Dunne, P. (2014). Algorithms decision problems argument systemspreferred semantics. Artif. Intell., 207, 2351.667fiN OFAL , ATKINSON , & UNNEOrdyniak, S., & Szeider, S. (2011). Augmenting tractable fragments abstract argumentation.Walsh, T. (Ed.), Proceedings 22nd International Joint Conference Artificial Intelligence IJCAI 2011, pp. 10331038.Rahwan, I., & Simari, G. (2009). Argumentation Artificial Intelligence. Springer.Verheij, B. (1996). Two approaches dialectical argumentation: admissible sets argumentationstages. Proceedings Eighth Dutch Conference AI, pp. 357368.Villata, S., Boella, G., & van der Torre, L. (2011). Attack semantics abstract argumentation.Walsh, T. (Ed.), Proceedings 22nd International Joint Conference Artificial Intelligence IJCAI 2011, pp. 406413.668fiJournal Artificial Intelligence Research 49 (2014) 733-773Submitted 07/13; published 04/14Comparative Evaluation Link-Based ApproachesCandidate Ranking Link-to-Wikipedia SystemsNorberto Fernandez GarcaJesus Arias FisteusLuis Sanchez Fernandezberto@it.uc3m.esjaf@it.uc3m.esluiss@it.uc3m.esTelematics Engineering DepartmentUniversidad Carlos III de MadridAvda. Universidad, 30, E-28911Leganes, Madrid, Spain.Abstractrecent years, task automatically linking pieces text (anchors) mentioneddocument Wikipedia articles represent meaning anchors receivedextensive research attention. Typically, link-to-Wikipedia systems try find setWikipedia articles candidates represent meaning anchor and, later,rank candidates select appropriate one. ranking processsystems rely context information obtained document anchormentioned and/or Wikipedia. paper center attention useWikipedia links context information. particular, offer review several candidateranking approaches state-of-the-art rely Wikipedia link information.addition, provide comparative empirical evaluation different approachesfive different corpora: TAC 2010 corpus four corpora built actual Wikipediaarticles news items.1. IntroductionDue important volume information contained Wikipedia, also opennature content, on-line encyclopedia adopted recent times usefulresource computational linguistics tasks like name translation (Lin, Snover, & Ji, 2011),named entity recognition (Nothman, Murphy, & Curran, 2009), etc.development automatic link discovery systems (Erbs, Zesch, & Gurevych, 2011)another area research Wikipedia important impact. taskdiscovering links Wikipedia articles addressed, slight variantsdifferent names, different communities. instance, Hachey et al. (2013) distinguishnamed entity linking, addressed context Knowledge Base Population(KBP) track (National Institute Standards Technology, 2014b) Text AnalysisConference (TAC) (National Institute Standards Technology, 2014a), wikification, addressed Link-the-Wiki track Initiative Evaluation XMLretrieval (INEX) (INEX, 2014). cases goal automatically find Wikipediaarticles represent meaning certain piece text document definelink Wikipedia using anchor piece text. However, differencesaspects like anchors considered (only named entities named entity linking, namedc2014AI Access Foundation. rights reserved.fiFernandez Garca, Arias Fisteus & Sanchez Fernandezentities common terms wikification) whether Wikipedia consideredcomplete source knowledge (wikification) (named entity linking).Henceforth, simply refer link-to-Wikipedia general task discoveringlinks Wikipedia, includes wikification named entity linking particularcases.According Erbs et al. (2011), task discovering links divided seriessteps. include: identifying anchors linked, searching candidate linktargets anchor, selecting best candidate results searchingstep. common link-to-Wikipedia approaches address steps independentlysequentially (though also examples steps independent,like Cucerzan, 2012 Sil, 2013).Due important role (Ji, Grishman, & Dang, 2011), context papercenter attention last aforementioned processes. referreddisambiguation Hachey et al. (2011). However, selecting best link targetusually involves creating ranking candidates choose one highestrank, authors refer process target ranking (Erbs et al., 2011) candidateranking (Guo, Tang, Che, Liu, & Li, 2011; Ploch, Hennig, de Luca, & Albayrak, 2011; Jiet al., 2011). article, also adopt term candidate ranking.order select best Wikipedia article link given anchor, candidateranking process relies context information provided set features.features extracted document anchor placed (the context document)and/or different Wikipedia articles considered candidates become link target.According Erbs et al. (2011) features classified three groups: (1)extracted text document/articles, (2) extracted titles;(3) based existing links. latter subject study paper.Traditional research area computational linguistics shown effectiveness using WordNet (Miller, 1995) graph links tasks like computing semantic relatedness (Budanitsky & Hirst, 2006) performing word sense disambiguation (Navigli &Lapata, 2010). case link discovery, Erbs et al. (2011) indicate that, enoughtraining information available, link-based approaches outperform text-based ones.Taking account, surprising find many link-to-Wikipedia approachesuse features candidate ranking based information links. examples work Milne Witten (2008b), Pilz (2010), Radford et al. (2010), Fernandezet al. (2010), Guo et al. (2011), Ploch et al. (2011) Ratinov et al. (2011).Given ample variety link-based features candidate ranking describedstate art, comparative analysis different alternatives useful decideapproach (or approaches) considered designing link-to-Wikipediasystems. However, using results published state art difficultcompare across systems ranking performance different link-based approaches.First, link-to-Wikipedia systems usually evaluated end-to-end setup, is,evaluation involves ranking stage, also candidate searchingcandidate selection processes. Thus, impact performance different systemcomponents mixed. Second, general, link-to-Wikipedia systems relylink-based features rank candidates, also combine featurestypes. Thus, effects different contributions ranking process also mixed.734fiEvaluation Link-Based Approaches Candidate Ranking Link-to-WikipediaTaking account, main goals paper twofold: (1) offer overviewlink-based approaches candidate ranking link-to-Wikipedia systems; and, (2) performempirical evaluation compare approaches. order address aforementioned difficulties, we: (1) focus analysis candidate ranking stage, isolatingmuch possible candidate search/selection stages; (2) consider linkbased features, combined based text titles. similar comparison is,knowledge authors, available time writing.rest paper organized follows: section 2 presents definitionsformal description problem addressed. Section 3 outlines different linkbased approaches compared. Section 4 describes setup empirical evaluationcarried out, well results. Section 5 offers overview related work.Finally, section 6 closes paper concluding remarks future lines work.2. Definitions Problem Formalizationsection introduce definitions nomenclature helpfulrest article.textual document mentions anchor going linked Wikipedianamed context document represented dc .set Wikipedia articles denoted W , whereas particular Wikipediaarticles represented wi , = 1, . . . , |W |. case consider set WWikipedia pages belong Main namespace (Wikipedia, 2014b)represent non-ambiguous concepts (that is, disambiguation pages filtered out).denote C(dc , a) set Wikipedia articles {c1 , c2 , . . . , c|C(dc ,a)| }, ck Wselected candidates fit meaning dc .link l defined duple l = (src(l), dest(l)), src(l) representsdocument source link dest(l) document pointedlink, is, destination.denote F (d) set documents destination forward linksd, is: F (d) = {f | l, src(l) = dest(l) = f }. Similarly, representB(d) set documents source backward links d, is: B(d) ={b | l, src(l) = b dest(l) = d}. paper, use information providedWikipedia links. Thus, consider Wikipedia articles members F (d)B(d). Note also F (d) B(d) sets and, thus, considerduplicates. However, might happen document several links pointingdestination. order represent information, denote number linkssource document destination document n(s, d) .Taking account aforementioned definitions, candidate ranking processaddressed context paper may formalized follows:Definition 1. Given context document dc , mentions anchor a, setcandidate Wikipedia articles C(dc , a), candidate ranking task consists orderingmembers C(dc , a) according rating. rating measures suitabilitycandidate represent meaning anchor. candidate ci C(dc , a)highest rank, fits best meaning anchor context documentdc , selected define new link (dc , ci ).735fiFernandez Garca, Arias Fisteus & Sanchez Fernandezaspects stressed definition:introduce restriction nature anchors linked.particular, may represent either named entities (persons, organizations, etc.)common terms.previous related work (Cucerzan, 2007; Mihalcea & Csomai, 2007; Han,Sun, & Zhao, 2011), address paper scenario adequateWikipedia article linked exist.3. Overview Approachesdescribe different candidate ranking approaches evaluatedpaper. common source context information links.particular, links considered available context document, dc , wellconstitute link structure Wikipedia, including links to/fromcandidate Wikipedia articles, ci C(dc , a).However, approaches considered use link informationmanner. particular, classify two families, name (1) bag-oflinks approaches, (2) graph approaches. main differencesecond group links used build graph structure, later analyzedselect best candidate. case approaches first group.3.1 Bag-of-Links Approachessection present set approaches characteristic common:rely building graph link context information rank candidates.Nevertheless, approaches family also differences way addresstask. particular, distinguish least three alternative groups:approaches rely similarity metrics compute similarity scorecontext document candidate, later select candidatehighest score (the similar one).Another alternative rely popularity metrics, simply try computepopularity score candidate. popular candidate selected.approaches rely information provided context document.ranking process also modeled statistical problem. Statistical methodsused select likely candidate, given context information.accordance classification, following sections describe group approaches.3.1.1 Similarity Metricsfirst similarity metrics consider relatedness, computed basisWikipedia Link-based Measure (Milne & Witten, 2008a). relatedness used feature736fiEvaluation Link-Based Approaches Candidate Ranking Link-to-Wikipedialink-to-Wikipedia approaches Milne Witten (2008b), Han Zhao(2009), Kulkarni et al. (2009), Pilz (2010), Fahrni et al. (2011), Han et al. (2011) Ratinovet al. (2011).Basically, relatedness allows compute similarity two Wikipedia documents wi , wj links common. original definition MilneWitten (2008a), computed as:RB (wi , wj ) =log(max{|B(wi )|, |B(wj )|}) log(|B(wi ) B(wj )|)log(|W |) log(min{|B(wi )|, |B(wj )|})(1)According Milne Witten (2008a), relatedness metrics based Normalized Google Distance (NGD), defined Cilibrasi Vitanyi (2007). NGD basedintuition terms similar related meaning co-occur frequentlydocuments. Thus, given pair terms, Google search engine used obtainpages mention terms. Pages mention indicate relatedness,pages one suggest unrelatedness. indicated Milne Witten(2008a), relatedness metrics, defined equation 1, shares inspiring principle, uses Wikipedia links instead Google search results account mentions.distance metrics, relatedness values expected smaller similarWikipedia articles are. However, easy transform distance metricssimilarity metrics following approach Gracia Mena (2008), requirescomputation of:simRB (wi , wj ) = e2RB (wi ,wj )(2)second similarity metrics Wikipedia articles considered basedcomputing Pointwise Mutual Information (PMI) sets links articlescompared. instance, used Ratinov et al. (2011) link-to-Wikipediatask. defined work as:PB (wi , wj ) =|B(wi ) B(wj )|/|W |(|B(wi )|/|W |)(|B(wj )|/|W |)(3)Note definitions equations (1) (3) rely backlinks (B(x)) computation. However, indicated Ratinov et al. (2011), relatedness PMIalso computed using outgoing links document. paper explorecompare alternatives denote relatedness similarity PMI computedforward links simRF PF respectively.Taking aforementioned definitions account, Wikipedia article {c1 , . . . , ck }C(dc , a) compute relatedness PMI Wikipedia articles linkeddc , is, fj F (dc ). Combining different values obtain finalrelatedness PMI ci dc . According Ratinov et al. (2011) several wayscombine values may followed, taking average maximum.explore different possibilities paper. particular, relatedness:737fiFernandez Garca, Arias Fisteus & Sanchez FernandezRelFA (ci , dc ) =RelB(ci , dc ) =1|F (dc )|1|F (dc )|RelFM (ci , dc )=RelB(ci , dc ) =XsimRF (ci , fj )(4)XsimRB (ci , fj )(5)maxsimRF (ci , fj )(6)maxsimRB (ci , fj )(7)fj F (dc )fj F (dc )fj F (dc )fj F (dc )Whereas Pointwise Mutual Information computed as:P IFA (ci , dc ) =1|F (dc )|1P IB(ci , dc ) =|F (dc )|P IFM (ci , dc )=P IB(ci , dc ) =XPF (ci , fj )(8)XPB (ci , fj )(9)maxPF (ci , fj )(10)maxPB (ci , fj )(11)fj F (dc )fj F (dc )fj F (dc )fj F (dc )Another well-known approach compute document similarity within natural language processing information retrieval communities cosine similarity. Basically,vector built represent context document candidate article. Then, similarity context document candidate computed cosineangle respective vectors. Several approaches state art (Bunescu& Pasca, 2006; Fader, Soderland, & Etzioni, 2009; Nguyen & Cao, 2010; Fahrni et al.,2011; Ploch et al., 2011; Ratinov et al., 2011) use cosine similarity. However,differences features used build vector representationsdocuments.case, requirement considering solely links context information.Thus, document represented using links mentioneddocument. similar approach model documents compute cosine similarityused, instance, Fahrni et al. (2011) Ploch et al. (2011).particular, document represented vector vd R|W | . componentvd,i , = 1, . . . , |W | vector vd computed traditional term frequency(TF), inverse document frequency (IDF) product (Manning, Raghavan, & Schtze, 2008)follows:vd,i = F (d, wi ) IDF (wi ) = P|W |n(d, wi )log|B(wi )|wj F (d) n(d, wj )(12)Note F (d) contain certain Wikipedia article wi , n(d, wi ) = 0,F (d, wi ) = 0 and, thus, vd,i = 0. Due this, vector vd expected sparse.738fiEvaluation Link-Based Approaches Candidate Ranking Link-to-WikipediaGiven two documents compared (for instance, dc Wikipedia article ciC(dc , a)), cosine similarity metrics computed cosine anglevectors two documents, follows:simcos (vci , vdc ) =vdc vci||vdc ||2 ||vci ||2(13)Finally, Radford et al. (2010) suggest metrics based Wikipedia link structure,also interpreted similarity metrics. order compute metrics,following equation computed candidate ci C(dc , a):simR (ci , dc ) = log(|B(ci ) Ldc | + 1) + 1(14)Ldc set built union backlinks Wikipedia articleslinked dc :Ldc =[B(fi )(15)fi F (dc )aforementioned similarity metrics trivially used address candidateranking process. candidate ci C(dc , a) selected link destinationmaximal similarity context document dc :arg max{simf (ci , dc )}ci(16), RelM , P , P ,simf represents one functions: RelFA , RelFM , RelBBFF, P , simP IBcos , simR .B3.1.2 Popularity MetricsAlgorithms based popularity metrics constitute second group bag-of-linksfamily.first approach could used compute popularity certain candidate,ci C(dc , a), simply counting number Wikipedia articles link it, is,indegree, |B(ci )| or, alternatively, number Wikipedia articles linked it,outdegree, |F (ci )|. metrics considered, instance, work Dredze et al.(2010), Guo et al. (2011) Cao et al. (2011).Fader et al. (2009) describe popularity score also based incoming linksWikipedia candidate ci :|B(ci )|))(17)parameter set = 15 (Fader et al., 2009).Finally, degree centrality certain Wikipedia candidate article ci alsoconsidered bag-of-links popularity metrics. Hachey et al. (2011) define degreecentrality as:popF (ci ) = (1 + log(1 +D(ci ) =|B(ci )||W | 1739(18)fiFernandez Garca, Arias Fisteus & Sanchez FernandezNote that, indicated beginning section, aforementioned popularitymetrics take account information provided context document.depend information obtained candidates.aforementioned metrics used rank candidates popularity. Then,popular candidate ci C(dc , a) selected link destination. Takingaccount functions |B(ci )| involved aforementioned approaches (linear,logarithm) monotonically increasing functions, order (ranking) providedcases same. Due this, context paper, consider evaluationindegree outdegree only:arg max{indegree(ci )}(19)arg max{outdegree(ci )}(20)cici3.1.3 Statistical Techniquescandidate ranking process addressing context paper alsomathematically modeled using statistical techniques, suggested workFader et al. (2009) Han Sun (2011).particular case, considering set Wikipedia articles linked dc , F (dc ) ={f1 , . . . , f|F (dc )| } input features, destination computed selectingWikipedia article ci C(dc , a) maximizes conditional probability:P (ci /f1 , . . . , f|F (dc )| ) fi F (dc )(21)number features |F (dc )| considered relatively large, estimating valuesconditional probability equation (21) ci would complex problem. Duethis, practice, problem reformulated make treatable. particular:(1) Bayes rule used reverse conditional probability equation (21); and, (2)assumed features (links F (dc ) case) conditionally independent(Naive Bayes assumption).result problem reformulation known state art NaiveBayes classifier (Manning et al., 2008). specific scenario, classifierable distinguish classes (the different ci C(dc , a)) likelyanchor a.Mathematically, expression use select best ci using maximumposteriori decision rule (Manning et al., 2008) is:|F (dc )|arg max{N B(ci , dc )} = arg max{log P (ci ) +ciciXn(dc , fj ) log P (fj /ci )}(22)j=1logarithm function used avoid underflows (as suggested Manning et al.,2008).order compute values equation (22) ci , need know valuetwo probabilities: (1) prior probability class ci , P (ci ); and, (2) conditional740fiEvaluation Link-Based Approaches Candidate Ranking Link-to-Wikipediaprobabilities P (fj /ci ). estimate two probabilities follow approach describedManning et al. (2008):Pbj B(ci ) n(bj , ci )P(23)P (ci ) = Pwi Wfj F (wi ) n(wi , fj )is, P (ci ) represents Maximum Likelihood Estimate (MLE) probabilitycertain document contains link ci , computed dividing number actuallinks ci total number links Wikipedia:P1 + bi B(ci ) n(bi , fj )PP (fj /ci ) = P(24)wj W (1 +bi B(ci ) n(bi , wj ))case, P (fj /ci ) represents probability anchor linking fjdocument already contains link ci . Again, MLE also used conditionalprobabilities and, thus, probabilities computed dividing number linksfj documents contain link ci total number links documentscontain link ci . seen MLE smoothed using Laplace smoothingavoid zeros.3.2 Graph Approachessecond family link-based approaches candidate ranking consider graphapproaches, rely building graph processing select best candidate.3.2.1 PageRank Personalized PageRankfirst algorithm consider within graph family PageRank, first definedPage et al. (1999), widely known due use part Google search engine.Examples application PageRank method candidate ranking foundinstance work Fernandez et al. (2010), Dredze et al. (2010) Hachey et al.(2011).Basically, PageRank algorithm used compute popularitycertain page, taking account popularity number pages link it. Usingmathematical formulation described Brin Page (1998) particular scenarioaddressing paper, compute popularity P R(wi ) Wikipediaarticle wi , need solve following equation:P R(wi ) =(1 d)+d[|W |Xwj B(wi )1P R(wj ) ]|F (wj )|(25)damping factor set 0 1, typically set0.85 according Brin Page (1998) Hachey et al. (2011).Note that, according equation (25), taking account links to/fromWikipedia, computing PageRank general scenario requires complete information link structure Web, computationally expensive problem.simplification also assumed Fernandez et al. (2010) Hachey et al. (2011).741fiFernandez Garca, Arias Fisteus & Sanchez FernandezNote also that, happens popularity metrics described section 3.1.2,PageRank metrics depend context information dc , graphbuilt link structure Wikipedia. However, context information dcincluded process using variant algorithm known Personalized PageRankTopic-Sensitive PageRank (Haveliwala, 2003). algorithm used instance Yehet al. (2009) define semantic relatedness metrics.main difference classical PageRank Personalized PageRank that,instead relying uniform damping vector, biased give relevancegiven set resources (Haveliwala, 2003). particular case, resourcesarticles linked dc , is, members F (dc ). practice, equation (25) adaptedfollows compute Personalized PageRank:P P R(wi , dc ) =d[X1P P R(wj , dc )] wi/ F (dc )|F (wj )|X1P P R(wj , dc )] wi F (dc )|F (wj )|wj B(wi )(1 d) F (dc , wi ) + [wj B(wi )F (dc , wi ) represents term frequency link wi contextdocument dc , computed indicated equation (12).PageRank Personalized PageRank values computed, usedrank candidates. article ci C(dc , a) highest P R(ci ) P P R(ci , dc )value selected link destination:arg max{P R(ci )}(26)arg max{P P R(ci , dc )}(27)cici3.2.2 Random WalkSeveral works state art (Gentile et al., 2009; Fernandez et al., 2010; Han et al.,2011; Ploch et al., 2011; Jimenez et al., 2013) define techniques link several anchorscontext document time. Usually, approaches address candidateranking process building graph computing random walk (Spitzer, 1976)graph rank nodes.Though approaches share underlying principle, differencesmainly two aspects: nature nodes considered partgraph nature edges. instance, Gentile et al. (2009) indicatenodes represent either concepts (candidates) features (like words titlecertain candidate), edges link candidates specific features. Han et al.(2011) define nodes anchor linked candidates. edges linkanchor candidates also candidates among basisrelatedness (see section 3.1.1). work Fernandez et al. (2010) nodes includecandidates, edges defined basis information co-occurrence742fiEvaluation Link-Based Approaches Candidate Ranking Link-to-Wikipediacandidates Wikipedia articles. similar approach used Ploch et al. (2011),including nodes candidates edges defined basis Wikipedia links.Note PageRank metrics also interpreted random walk (Page et al.,1999). However, PageRank, described section 3.2.1, operates graphwhole link structure Wikipedia, approaches section build graphs,typically much smaller tailored concrete scenario addressed.approaches Gentile et al. (2009) Han et al. (2011) rely text-based featuresbuild graphs: work Gentile et al. (2009) features used nodesgraph, whereas Han et al. (2011) use text-based similarity metrics computeweights edges connecting anchor candidates. Due this, contextpaper evaluate approaches Fernandez et al. (2010) Ploch et al. (2011),rely link information.indicated above, Fernandez et al. (2010) Ploch et al. (2011) designedapproaches link time several anchors context document. Thus,need adapt approaches scenario addressed paper,anchor considered. so, element F (dc ) treated single-elementpseudo-candidate set anchor ai dc = 1, . . . , |F (dc )|.compute score candidate ci C(dc , a) according Ploch et al. (2011)(that name RWP (ci , dc ))) build graph nodes candidatespseudo-candidates (that is, elements C(dc , a) plus Wikipedia articles linkedF (dc )). edge two nodes appears link Wikipediaarticles represented nodes. graph built, PageRank algorithmapplied graph. score assigned node PageRank value.similar approach used case Fernandez et al. (2010). Again, nodesinclude candidates pseudo-candidates, case edges represent cooccurrences. particular, edge node wi node wj when:1. least third Wikipedia article wk links wi wj , is,wi , wj F (wk ). edges assigned weights according to:weightC (wi wj ) =|B(wi ) B(wj )||B(wi )|(28)2. direct link exists wi wj , is, wj F (wi ). edges assignedweights follows:weightL (wi wj ) = Fij IDFj = Pn(wi , wj )|W |log|B(wj )|wk F (wi ) n(wi , wk )(29)two nodes wi wj match conditions above, is, directlylinked co-occur third article wk , single edge created combinescontributions follows:weight(wi wj ) =kLkCweightC (wi wj ) +weightL (wi wj )kC + kLkC + kL743(30)fiFernandez Garca, Arias Fisteus & Sanchez FernandezkL kC configuration parameters. case use valueskL = 0.55 kC = 0.25 suggested Fernandez et al. (2010).weighted, directed graph built, PageRank computed graph.score candidate ci C(dc , a), named RWF (ci , dc ), PageRank valuecandidate node graph. scores candidates computed,candidate highest score selected best one:arg max{RWP (ci , dc )}(31)arg max{RWF (ci , dc )}(32)ciciNote that, approaches listed section 3, might happen differentmembers candidates set obtain weight and, thus, would tieranking. used frequently linked (MFL) algorithm break potentialties. algorithm simply assigns weight candidate according total numberincoming links, is:F L(ci , dc ) =Xn(bj , ci )(33)bj B(ci )4. Comparative Evaluationsection reports results evaluation different approaches describedsection 3. organized follows: experimental setup (Wikipedia dataset, corpora,etc.) used evaluation outlined section 4.1, whereas section 4.2 reportsquantitative results well analysis interpretation results.4.1 Experimental Setuporder evaluate approaches described section 3, need set elements: (1)corpora queries evaluate approaches; (2) information Wikipedia linkstructure used input different approaches; (3) adequate metricsmeasure compare performance approach. next sections describethree elements briefly:4.1.1 Corpora Queriesorder evaluate different approaches, need corpora containing link-to-Wikipediaqueries. According definition problem (see section 2) queriescorpora provide:anchor going linked.context document dc anchor appears. links documentprovide context information used algorithms.set candidates, C(dc , a), Wikipedia articles potential targetsanchor.744fiEvaluation Link-Based Approaches Candidate Ranking Link-to-Wikipediagolden standard indicates correct answer (candidate C(dc , a) rankedtop) query. golden standard used compute performancealgorithms evaluated.state art, distinguish different approaches regarding corporause empirical evaluation. first approach build specific corpora. followedearly work (Bunescu & Pasca, 2006; Cucerzan, 2007; Mihalcea & Csomai, 2007), wellrecent work (Milne & Witten, 2008b; Nguyen & Cao, 2010; Pilz, 2010).common approach within first group use corpus subset Wikipedia articlescompare links suggested automatic algorithms provided Wikipediaeditors (see instance Bunescu & Pasca, 2006; Cucerzan, 2007; Milne & Witten, 2008b;Nguyen & Cao, 2010 Pilz, 2010). methodology also used contextINEX Link-the-wiki track (Huang, Xu, Trotman, & Geva, 2008). second alternativeuse already available corpora, like TAC/KBP corpus (used instance Han &Sun, 2011 Hachey et al., 2011), corpora defined Cucerzan (2007) (usedinstance Gentile et al., 2009 Ratinov et al., 2011).context paper, adopt approaches. particular, usefollowing corpora comparative evaluation:Cucerzan work Cucerzan (2007) authors use two different corpora, onebuilt Wikipedia articles manually annotated MSNBC (MSNBC,2014) news items. used corpora build own. order so,proceeded follows:1. documents Cucerzan corpora contain set pairs {anchor, Wikipediaarticle}, one representing potential link-to-Wikipedia query. selectrandomly 250 pairs Cucerzans corpora. pairs provide usanchor linked golden standard (correct answerquery).2. typical approach among systems TAC/KBP generate candidateset, C(dc , a), rely information retrieval techniques (Ji et al., 2011).paper adopt approach. However, difference TAC/KBPscenario, evaluation involves stages entity linking, centerevaluation candidate ranking stage. Due this, interestedisolating much possible stage potential bad performanceparticular candidate search implementation. is, interestedanalyzing performance different candidate ranking approaches assumingcandidate search stage ideal, sense always returnscorrect candidate among candidate set. Obviously, existideal candidate searcher. Thus, practice, rely state artsearch engine (Google) append correct answer candidate setcase found search engine. particular, query Googlesearch engine text anchor site:en.wikipedia.org restriction,filtering top-10 Google results Wikipedia pages includedMain namespace. case correct Wikipedia article linked745fiFernandez Garca, Arias Fisteus & Sanchez Fernandezincluded within Google result set, appended end, thoughhappens limited number queries: Curcerzan Wikipediacorpus correct candidate added 9 250 queries (3.6%),Curcerzan news corpus added 14 250 queries (5.6%).3. Finally, rest pairs {anchor, Wikipedia article} includeddocument query selected, obtain Wikipedia articlecomponent used context information (links F (dc )), filteringlinks articles included candidate set order avoid bias.Ad-hoc corpora Two ad-hoc corpora used evaluation. One corpus(Wikipedia random corpus) built following methodology suggestedprevious works state art, is, selecting set 500 Wikipedia articlesusing Random article page (Wikipedia, 2014a).second ad-hoc corpus (Wikinews corpus) built using documentsEnglish Wikinews site (Wikinews, 2014b). documents represent news items.usually annotated human editors Wikipedia links. case 500news items selected Random article functionality Wikinews (Wikinews,2014a).document total set 1000 documents two ad-hoc corpora,built link-to-Wikipedia query using following procedure:1. Wikipedia link randomly selected document.2. selected link obtain anchor golden standard (linkdestination Wikipedia).3. use anchor Google search engine build candidate set,indicated case Cucerzan corpora. Again, append correctcandidate included Google result set. particular,correct candidate added 14 500 queries (2.8%) caseWikinews corpus 36 500 queries (7.2%) Wikipedia randomcorpus.4. query context information obtained rest linksdocument, filtering linking members candidate set orderavoid bias.TAC2010 TAC 2010 dataset includes total 2250 entity linking queries and,one, provides anchor linked, context document dcgolden standard. used dataset basis build last corpus involvedevaluation. order so, proceeded follows:1. total set 2250 queries, 1230 golden standard NIL answer,is, Wikipedia article link cases. Thus, correctcandidate instance exists and, due this, difficult take advantagequeries evaluate candidate ranking process. Taking account,discard queries keep remaining 1020.746fiEvaluation Link-Based Approaches Candidate Ranking Link-to-Wikipedia2. documents TAC 2010 corpus contain links. Thus, usefollowing procedure order obtain context links neededalgorithms:query, analyze context document dc using natural languageprocessing techniques. particular, extract named entities (persons,locations organizations) text using Stanford NER tool (Finkel,Grenager, & Manning, 2005).Then, link detected entities Wikipedia using Google. particular,query Google search engine text named entitysite:en.wikipedia.org restriction, filtering top-10 Google resultsWikipedia pages included Main namespace, assigninglink top result filtered list. discard named entitiesGoogle results found. links named entities Wikipedia definedprocedure used context information candidate ranking,filtering context links members candidate setorder avoid bias.discard queries context information available, is,NER tool find named entities dc , filteredprocess linking Wikipedia. results total 1012 validqueries.3. candidate set C(dc , a) query obtained using procedureprevious corpora: using Google search anchor appendingcorrect candidate case found (which happens 70 1012 queries(6.9%)).summarize, carry evaluation five different corpora (Cucerzan news,Cucerzan Wikipedia, Wikipedia random, Wikinews TAC 2010)1 , addtotal 2512 link-to-Wikipedia queries. Boxplot diagrams representing distributionscorpus number candidates (|C(dc , a)|) per query, number links(|F (dc )|) per query, shown Figures 1 2 respectively.Note appending correct candidate candidates set needed 1432513 queries. indicates Google performs quite well candidate searchercase, candidate recall near 95% (considering first 10 results).put result context, indicate Hachey et al. (2013) compare severalcandidate search approaches TAC 2009 dataset report candidate recall75% limited maximum 10 results. However results similarLehmann et al. (2010), authors use Google search combinedset additional techniques report 97% candidate recall TAC 2009 dataset.4.1.2 Wikipedia Link Structureapproaches described section 3 require information Wikipedia link structure carry candidate ranking process. case, information1. corpora available download at: http://www.it.uc3m.es/berto/link-to-wikipedia/survey/747fiFernandez Garca, Arias Fisteus & Sanchez Fernandez246810Distribution number candidates per query corpusCucerzan NewsCucerzan Wiki.Wiki. RandomWikinewsTAC2010Figure 1: Boxplot diagram number candidates (|C(dc , a)|) per querycorpus.050100150200250300350Distribution number context links per query corpusCucerzan NewsCucerzan Wiki.Wiki. RandomWikinewsTAC2010Figure 2: Boxplot diagram number links context (|F (dc )|) per querycorpus.748fiEvaluation Link-Based Approaches Candidate Ranking Link-to-Wikipediaobtained dump Wikipedia page links provided DBpedia (Bizer et al., 2009)version 3.82 , generated full Wikipedia dump dated June 2012.links dump preprocessed follows:redirections resolved, using redirections mapping table DBpedia3.83 .indicated section 2, consider Wikipedia pages belongMain namespace. Thus, links from/to pages namespaces (like Talk pages,User pages, etc.) removed.Using information provided disambiguation map DBpedia 3.84 ,links from/to disambiguation pages also removed.inner links (from article itself) also filtered out.evaluation corpora described section 4.1.1 include cases Wikipediaarticles. separate input data evaluation data, links sourcedestination one Wikipedia articles included evaluation corporafiltered out.4.1.3 Performance Metricsmeasure compare performance considered approaches, needadequate metrics. well-known evaluation metrics link-to-Wikipedia approachesaccuracy, used instance Bunescu Pasca (2006), Cucerzan (2007), Hachey et al.(2011), Ratinov et al. (2011) Hachey et al. (2013). accuracy computedpercentage queries candidate selected algorithm correct one,or, formally:Accuracy =1 XS(q)|Q|(34)qQQ represents set evaluation queries, q particular query set, S(q)function S(q) = 1 candidate article ranked top query qcorrect answer S(q) = 0 otherwise.However, center evaluation candidate ranking stage link-toWikipedia task, accuracy presents limitation: take account actualposition correct answer within ranking produced algorithm. example,one algorithm ranks correct answer query 2nd position, whereas anotheralgorithm ranks 8th position, contribution query accuracyzero cases, despite first algorithm ranked correct answer higher.scenarios link-to-Wikipedia approaches work human-supervision (for instance, systems used within production process news agency (Fernandez2. http://downloads.dbpedia.org/3.8/en/page links en.nt.bz2 (April, 2014)3. http://downloads.dbpedia.org/3.8/en/redirects transitive en.nt.bz2 (April, 2014)4. http://downloads.dbpedia.org/3.8/en/disambiguations en.nt.bz2 (April, 2014)749fiFernandez Garca, Arias Fisteus & Sanchez Fernandezet al., 2006) add metadata news items) particular order candidates relevant, case top-ranked candidate correct one, human supervisorcontinue reading ranked list candidates select another option. Obviously,nearer top correct candidate list suggestions, better.Taking account, decided report performance using accuracy,also two position-based discounting schemes measure overall quality rankedlist results:Mean Reciprocal Rank (MRR) used instance evaluation questionanswering systems (Voorhees, 1999). MRR set evaluation queries Qcomputed as:RR(Q) =1 X 1|Q|r(q)(35)qQr(q) represents position correct candidate rank queryq Q.shown equation 35, MRR penalizes differences position severely.Taking account, also report results Discounted CumulativeGain certain level K (DCG@K), introduces smoother penalizationposition. DCG@K computed as:k1 X X 2R(q,i) 1DCG@K(Q) =|Q|log2 (1 + i)(36)qQ i=1Q represents set evaluation queries, q particular query set,R(q, i) relevance score given candidate article position query q.adopt binary relevance model and, thus, R(q, i) = 1 candidate positioncorrect answer R(q, i) = 0 otherwise. Furthermore, considersingle candidate relevant query. Taking account, DCG@Kequivalent normalized version, Normalized Discounted Cumulative GainK (NDCG@K) (Manning et al., 2008), equation 36 simplified into:1 XDCG@K(Q) =f (q, k) f (q, k) =|Q|qQ(1log2 (1+r(q))r(q) <= k0r(q) > k(37)r(q) represents position correct candidate rank query q.seen equation 37, bigger value r(q) (that is, farther awaycorrect candidate top rank) lesser value term addedDCG@K. Note also DCG@1 would equivalent accuracy definedequation 34.750fiEvaluation Link-Based Approaches Candidate Ranking Link-to-WikipediaFigure 3: Taxonomy different approaches considered evaluation.4.2 Evaluationsection reports results empirical evaluation approaches.structured presentation results three parts: section 4.2.1 compares individualalgorithms described section 3, section 4.2.2 analyzes combination different approaches use machine learning techniques and, finally, section 4.2.3 evaluatesimpact changing search stage performance algorithms.4.2.1 Comparison Individual Approachesapproaches described section 3 (summarized taxonomy shown Figure 3)evaluated corpora described section 4.1.1. Table 1 reports accuracyobtained approach different evaluation corpora. highlightedboldface best accuracy among link-based evaluated approaches particularcorpus.Table 1 includes column (Overall) reports results obtained corpusgenerated aggregating queries. last column, Confidence Interval (Overall),reports 95% confidence interval accuracy Overall case, computed usingbootstrap methods suggested Adibi, Cohen, Morrison (2004).seen Approach column Table 1, apart approaches considered section 3, include results two naive algorithms reference baselines:(1) random algorithm, simply ranks candidates randomly; and, (2)frequently linked (MFL) algorithm, described section 3 (see equation (33)). alsoreport (see row Google) accuracy obtained using trivial ranker simply returns751fiFernandez Garca, Arias Fisteus & Sanchez Fernandezcandidates order defined corpus (that is,order returned Google, correct candidate end foundGoogle)5 .CucerzanApproachRandomMFLGoogleRelFARelFMRelBRelBP IFAP IFMP IBP IBsimcossimRindegreeoutdegreeNBPRPPRRWPRWFWiki.NewsWikiRandom0.1330.7000.8440.5680.4160.7160.5760.2040.1400.2720.1920.4400.7600.7000.5320.7720.6840.6920.7760.7600.1490.6300.8830.4580.4060.6510.5420.2330.2290.3210.2850.4860.6870.6470.4620.7190.6230.6870.6630.7150.1530.5710.7950.4890.3650.7170.5970.2890.2520.4210.3830.4830.6870.5810.3270.7290.5650.6970.6470.643TACWikinews0.1550.6760.9140.4360.3380.6940.5260.2060.1740.3180.2740.5160.7340.6700.4720.7520.6680.7020.7520.74420100.1180.6680.7480.4950.2270.7380.4180.0810.0550.2370.1670.4210.7250.6710.5790.7660.6350.5530.7320.740Overall0.1370.6500.8130.4860.3130.7150.5030.1740.1440.3010.2450.4610.7190.6530.4910.7520.6310.6390.7170.721ConfidenceInterval(Overall)(0.124, 0.151)(0.631, 0.668)(0.798, 0.828)(0.466, 0.505)(0.295, 0.331)(0.696, 0.732)(0.483, 0.522)(0.160, 0.189)(0.130, 0.157)(0.283, 0.319)(0.228, 0.262)(0.441, 0.480)(0.701, 0.736)(0.634, 0.671)(0.471, 0.510)(0.734, 0.768)(0.612, 0.650)(0.619, 0.657)(0.698, 0.734)(0.703, 0.738)Table 1: Accuracy obtained different approaches evaluation corpora.Figure 4 shows DCG@K different values K Overall aggregated corpus.MRR values different evaluation corpora reported Table 2, where, again,highlighted boldface best MRR among link-based evaluated approachesparticular corpus. Furthermore, order provide detailed ideadifferences among methods, show Figure 5 percentage queriescorrect candidate ranked position K (with K 1 10) algorithm.also provide empirical results run-time different algorithms. particular, average run-time per query (in seconds) measured Linux2.6.32, Intel Core i7 2.80GHz PC 16GB RAM one second approaches except RWF P P R, run closer 4 571 seconds per query respectively. relatively large response time P P R due fact algorithm usescontext information personalize PageRank damping vector. Taking account that,general, query different context, means need run PageRank5. Note Google case, queries correct candidate appended result setaccounted errors computing accuracy.752fiEvaluation Link-Based Approaches Candidate Ranking Link-to-WikipediaApproachRandomMFLGoogleRelFARelFMRelBRelBP IFAP IFMP IBP IBsimcossimRindegreeoutdegreeNBPRPPRRWPRWFCucerzanNewsWiki0.347 0.3700.806 0.7630.894 0.9220.727 0.6510.607 0.6000.830 0.7870.727 0.7100.428 0.4580.356 0.4400.500 0.5430.415 0.5020.650 0.6710.850 0.8130.806 0.7730.700 0.6480.859 0.8340.7990.760.812 0.8010.864 0.7960.854 0.821Wiki.Random0.3740.7260.8580.6670.5730.8300.7460.5010.4630.6220.5700.6660.8050.7290.5500.8320.7190.8100.7780.774Wikinews0.3790.7940.9390.6350.5480.8200.7050.4350.4030.5470.5030.6990.8370.7930.6550.8480.7860.8100.8470.837TAC20100.3260.7910.8280.6880.4730.8470.6430.3180.2710.4900.4140.6200.8380.7940.7300.8610.7740.7340.8370.836Overall0.3530.7780.8720.6730.5340.8310.6910.4030.3610.5340.4720.6530.8300.7800.6680.8500.7670.7780.8260.824Table 2: MRR obtained different approaches evaluation corpora.computation whole Wikipedia graph query corpus, processtime consuming6 . Note, however, used Python implementationoptimized and, thus, results provided reference.contextualize results reported Table 1, indicate TAC 2010corpus using evaluation practically equivalent (apart 8 queriesremoved due lack context information, indicated section 4.1.1) Non-NILqueries TAC 2010 dataset. Due this, results reported column TAC 2010Table 1 roughly compared (less 1% error) TAC 2010 Non-NILaccuracy reported papers state art. instance, best performingapproach TAC 2010 (Lehmann et al., 2010) reported accuracy Non-NIL queries80.6%. Note, however, cautious comparisons, resultsreporting would equivalent obtained end-to-end system usingideal candidate search stage (we always append correct candidate) withoutcandidate selection process (we report results candidate ranking stage).Analyzing results reported Table 1, first conclusion may drawnoverall accuracy achieved using Google ranking better obtainedevaluated approaches. However, observe results obtained6. According Bianchini, Gori, Scarselli (2005), computation depends linearly numberedges Wikipedia graph.753fiFernandez Garca, Arias Fisteus & Sanchez FernandezAlgorithmsRelAF0.75RelMFRelABRelMBPMIAFDCG@KPMIMFPMIABPMIMBsimCOS0.50simRindegreeoutdegreeNBPRPPRRWPRWF0.2512345678910KFigure 4: DCG@K values different algorithms considered evaluatedOverall corpus generated aggregating queries.individual corpus, also note using Google always best approach.particular, accuracy N B TAC 2010 corpus slightly better achievedGoogle.interpret findings, take account previous work area(notably Chang et al., 2010) already pointed using Google producesrelatively good results entity linking task (accuracy near 78% TAC 2009 experimental setup). sense, overall performance obtained Google completelyunexpected. degradation performance TAC 2010 case partially explained754fiEvaluation Link-Based Approaches Candidate Ranking Link-to-Wikipedia100%90%80%Position (K)Percentage queries70%10960%87650%5440%3230%120%10%RWFRWPPPRPRNBoutdegreeindegreesimRsimCOSPMIMBPMIABPMIMFPMIAFRelMBRelABRelMFRelAF0%AlgorithmsFigure 5: Percentage queries correct candidate ranked position K (withK 1 10) different algorithms compared.755fiFernandez Garca, Arias Fisteus & Sanchez Fernandezfact corpus specifically built entity linking task using carefultargeted process7 . Due this, queries TAC 2010 corpus expectedchallenging. instance, common case8 within corpus groups queriessharing anchor linked, different correct answers dependingparticular query. case, queries share anchor, also share Googleranking and, thus, top ranked candidate but, correct answer changesqueries, using always Google top ranked candidate answer introduces errors.Note also using Google taking advantage context information,expected valuable decide best link anchor, especiallyqueries challenging.second conclusion naive popularity metrics like indegree (or F L,whose performance similar indegree) produce reasonably accurate results.aspect consistent previous work state art (Ji & Grishman, 2011)authors indicate naive candidate ranking approaches based web popularityachieve accuracies around 71% TAC 2010 corpus.Another aspect highlighted that, consistently across evaluation corpora,indegree metrics produces better accuracy outdegree, indicatesnumber backlinks offers better representation popularity Wikipedia articlenumber outgoing links. One aspect may explain, least partially,difference performance fact number outgoing links may high dueseveral reasons. Wikipedia article long (which indicates receivedextensive attention Wikipedia contributors is, sense, popular) expectlinks shorter articles. However, casesWikipedia article contain many outgoing links. case, instance, articlesrepresent hub links, List articles.test hypothesis outdegree metrics introduces bias favor hubs likeList articles, compared number queries candidate rankedtop indegree outdegree list (its title starts List ) different corpora.results shown Table 3, x, proportion queries candidateranked top list, whereas proportion queries candidateranked top list correct answer. is:Queries top ranked candidate listTotal number queries corpus(38)Queries top ranked candidate list correctQueries top ranked candidate list(39)x=y=seen Table 3, outdegree metrics ranks list pages frequentlytop indegree metrics. also seen that, cases,candidate ranked top list, correct answer. particularity explainssignificant part difference overall results indegree outdegree.7. indicated TAC KBP 2010 task definition document, available at:http://www.it.uc3m.es/berto/link-to-wikipedia/survey/KBP2010 TaskDefinition.pdf (April, 2014)8. identified total 144 queries (approximately 14%) following pattern.756fiEvaluation Link-Based Approaches Candidate Ranking Link-to-WikipediaApproachNameParamxindegreexoutdegreeCucerzanNews Wiki0.004 0.0041.01.00.06 0.0881.01.0Wiki.Random0.0220.8180.1380.956Wikinews0.0060.6670.0780.974TAC20100.0141.00.0491.0Overall0.0120.9030.0780.979Table 3: Comparison indegree outdegree regarding tendency rankWikipedia list top.difference performance using backlinks forward links alsonoticed similarity metrics, approaches relying backlink information, RelM , P , P ) produce better results corresponding metrics work(RelBBBBing forward links (RelFA , RelFM , P IFA , P IFM ).According results Table 1, also pointed that, among linkbased approaches evaluated, taking advantage context information is, general,beneficial. support conclusion compare results F L N B. NoteN B uses prior P (ci ) (see equations (22) (23)), basically normalizedversion F L. However, N B combines prior probabilities P (fj /ci ),capture context information. seen Tables 1 2, result combination N B produces better results F L. Note also none alternativesuse popularity information included among top-5 link-based evaluated). However, using contextapproaches higher accuracy (N B, RWF , simR , RWP , RelBinformation sufficient condition ensure good performance, reflectedresults PMI variants.Another conclusion reached that, cases relatedness PMImetrics, averaging pairwise similarities candidate articles F (dc ), P , RelA P ) produces, consistently across corpora, better(as done RelBBFF, P , RelM P ).accuracy relying maximum (as done RelBBFFpossible explanation result relying maximum similaritytake account one elements F (dc ) (the one maximizes similarity)represent semantics document dc , whereas, averaging, elementsF (dc ) contribute final similarity value. reasonable think setforward links dc provides accurate representation semantics contextdocument single link document.objective testing intuition, implemented two new variants RelB, name RelM (P ) P (P ). order obtain RelM (P )(c , )P IBcBBBscores compute simRB (ci , fj ) fj F (dc ) equation (7). However, insteadselecting maximum value, done equation (7), select certain percentageP top values average them. instance, |F (dc )| = 10 P = 50%,select top 5 simRB (ci , fj ) values average them. Note that, approach,. obtainP = 100% scores would equivalent obtained RelB(P )(c , ) scores proceed similar way, using P (c , f ) valuesP IBcB j(P )(see equation (11)) instead simRB (ci , fj ) ones. evaluated RelB757fiFernandez Garca, Arias Fisteus & Sanchez Fernandez0.7RelABAccuracy0.6RelMB0.5AlgorithmsPMIMB ( P)RelMB ( P)0.4PMIAB0.3PMIMB10%30%50%70%90%Percentage(P ) P (P ) approaches different valuesFigure 6: Accuracy values RelBBpercentage P evaluated Overall corpus generated aggregatingqueries.(P ) variants overall aggregated corpus different values percentage P .P IBFigure 6 reports accuracy obtained new variants. also included, P , RelAreferences horizontal lines representing overall accuracy RelBBBP IB . seen, increasing context information improves results.Also related relatedness PMI metrics fact results obtainedPMI variants quite poor compared equivalent relatedness variants.(0.715) P (0.301).example, see difference overall accuracy RelBB758fiEvaluation Link-Based Approaches Candidate Ranking Link-to-Wikipediainspection results P revealed that, using absolute values insteadlogarithmic values (as relatedness), PMI sensitive outliers. orderverify quantify observation, decided compare results PMI twoalternatives:implemented logarithmically smoothed version averaging PMI variantsadapting equations (8) (9) follows:logP IFA (ci , dc ) =logP IB(ci , dc ) =1|F (dc )|1|F (dc )|Xlog[PF (ci , fj )](40)Xlog[PB (ci , fj )](41)fj F (dc )fj F (dc )used symmetric conditional probability (SCP), introduced da SilvaLopes (1999). SCP two Wikipedia documents wi , wj computed as:SB (wi , wj ) =|B(wi ) B(wj )|2|B(wi )||B(wj )|(42)also adapted use forward links as:SF (wi , wj ) =|F (wi ) F (wj )|2|F (wi )||F (wj )|(43)Using equations (42) (43) following two metrics implemented:SCPFA (ci , dc ) =SCPBA (ci , dc ) =1|F (dc )|1|F (dc )|X[SF (ci , fj )]X[SB (ci , fj )](44)fj F (dc )(45)fj F (dc )run approaches corpora, report results Table 4 (accuracies)Table 5 (MRR). seen comparing results Table 4Table 1, significant increase performance achieved usingP IFA P IBlogarithmically smoothed version P I. also seen accuracies reportedsimilarSCPFA SCPBA better P IFA P IB, respectively.results relatedness variants RelFA RelB4.2.2 Combining Individual Approacheswant also explore possibility combining results different link-basedapproaches test whether better results obtained not. approachfollow combine alternatives described section 3 based supervised machinelearning techniques. particular, use learning rank (Joachims, 2002) method.759fiFernandez Garca, Arias Fisteus & Sanchez FernandezCucerzanApproachlogP IFAlogP IBSCPFASCPBAWiki.NewsWikiRandom0.3920.5520.5000.7280.3570.5500.4540.6340.4230.6690.4410.693TACWikinews0.3700.5900.4040.65820100.3960.6740.2860.550Overall0.3920.6320.3780.626ConfidenceInterval(Overall)(0.372, 0.411)(0.612, 0.650)(0.359, 0.397)(0.607, 0.645)Table 4: Accuracy obtained logarithmically smoothed P variants SCP based metrics evaluation corpora.ApproachlogP IFAlogP IBSCPFSCPBACucerzanNews Wiki0.604 0.5740.735 0.7140.681 0.6480.835 0.788Wiki.Random0.6230.8000.6370.815Wikinews0.5800.7520.6100.797TAC20100.6070.8050.5450.741Overall0.6010.7780.6000.781Table 5: MRR obtained logarithmically smoothed P variants SCP -basedmetrics evaluation corpora.Though several learning rank algorithms available state art (Liu, 2009),decided rely ListN et method described Cao et al. (2007). decisionbacked results reported Chen Ji (2011), several alternativesevaluated compared context entity linking problem. particular,took advantage open source implementation ListN et provided UniversityMassachusetts RankLib package (Van B. Dang, 2014).Basically, use scores returned individual approaches section 3 featurestaken account ListN et algorithm. values features normalizedrange [0, 1] avoid bias might favor them.tested three different combinations approaches. first variant (thatname ListN etAll ) combines link-based approaches evaluation (that is,algorithms included Table 1 except Google naive references F LRandom). second variant (ListN etT op ) combines top-5 best performing linkbased algorithms evaluation (according Overall accuracy Table 1, is, N B,). Finally, third case (ListN etRWF , simR , RWP , RelBop+Google ) combines top5 best performing link-based algorithms Google baseline. cases,used configuration parameters ListN et suggested RankLibimplementation (1500 epochs learning rate 105 ).order report accuracy, MRR DCG@K ListN et variants, useresults obtained averaging 10 repetitions 10-fold cross validation particularcorpus analyzed. Table 6 reports accuracy different corpora combinations considered, Table 7 reports MRR results760fiEvaluation Link-Based Approaches Candidate Ranking Link-to-WikipediaApproachListN etAllListN etT opListN etT op+GoogleCucerzanNews Wiki0.780 0.7160.824 0.7860.854 0.864Wiki.Random0.7420.7690.850Wikinews0.7380.8030.877TAC20100.6780.7930.816Overall0.7050.7970.846Table 6: Accuracy obtained combining approaches section 3 ListN etevaluation corpora.ApproachListN etAllListN etT opListN etT op+GoogleCucerzanNews Wiki0.867 0.8340.888 0.8790.916 0.930Wiki.Random0.8470.8650.916Wikinews0.8480.8850.929TAC20100.8120.8820.894Overall0.8280.8820.913Table 7: MRR obtained combining approaches section 3 ListN etevaluation corpora.combinations. Figure 7 compares DCG@K achieved ListN et variants Overallcase top-5 link-based evaluated approaches.compare accuracy values reported Table 6 Table 1.overall case, best result obtained ListN etT op+Google . ListN etT op combinationshows lower performance Google reference, outperforms N B (the bestindividual algorithms comparison). Regarding ListN etAll variant, accuracylower obtained Google N B. Similar conclusions also reachedFigure 7 DCG@K metrics overall case. conclusions suggestparticular combinations features positive impact results.However, cautious results, because, indicated Vanwinckelen (2012), repeated cross validation assumed provide perfectly preciseestimates models predictive accuracy. fact, Vanwinckelen (2012) recommend reporting confidence intervals making significance claims repeated cross validation. report that, though popular among researchers, practice contributemisleading interpretations.4.2.3 Effect Changes Search Stageindicated section 4.1.1, order isolate results candidate ranking algorithms evaluated potential bad performance particular candidate searchimplementation, would need rely ideal candidate search stage, sensealways returns correct answer among candidate set. Obviously,exist ideal candidate searcher. Thus, practice, try mimic behavior,relied state art search engine (Google) appended correct answercandidate set case found search engine.761fiFernandez Garca, Arias Fisteus & Sanchez Fernandez0.90AlgorithmsRelAB0.85simRDCG@KNBRWPRWFListNetAll0.80ListNetTopListNetTop+Google0.750.7012345678910KFigure 7: DCG@K values top-5 link-based evaluated approaches ListN et variants evaluated Overall corpus generated aggregatingqueries.762fiEvaluation Link-Based Approaches Candidate Ranking Link-to-WikipediaHowever, also interested evaluating impact results achieveddifferent algorithms aforementioned conditions change restrictivesetup. order so, proceeded follows:used information retrieval library Apache Lucene (Apache Software Foundation, 2014) build index titles DBpedia 3.8 pages. titleprocessed StandardAnalyzer Lucene.1012 queries TAC 2010 corpus carried followingprocess:anchor query used search Lucene index candidates, C(dc , a). result set limited top-10 entries, like previous experiments. However, contrary previous experiments,Lucene return correct answer within result set, appendit.documents TAC 2010 corpus contain context links,automatically generated using similar approach one describedsection 4.1.1: named entities obtained context documents usingStanford NER resolved links querying Lucene textnamed entity assigning link destination top result searchengine (as usual, filtering links articles included withincandidate set).Using aforementioned procedure built new version TAC 2010 corpusannotated Lucene. Thus, two variants TAC 2010:TAC 2010 Google, Google used candidate searcher correctcandidate appended Google results set case found.version used experiments previous sections.TAC 2010 Lucene, version built following procedure describedsection.run evaluated approaches, well references Random F L,TAC 2010 Lucene corpus. accuracies achieved different algorithms95% confidence intervals shown Figure 8. ease comparison, depictedfigure accuracies TAC 2010 Google corpus. also included(with name Search) accuracy achieved candidate ranking providedsearch engine (either Google Lucene) directly used.first aspect noted results reported Figure 8 that, surprisingly,accuracies obtained different approaches using Lucene search are, general,lower. Note Lucene case including correct candidatecandidates set. Thus, many queries (363 cases, almost 36% total queries)impossible candidate rankers rank correct candidate top.Another issue highlighted that, look top-5 best performing link-based, greatly reducedapproaches Table 1: N B, RWF , simR , RWP , RelB763fiFernandez Garca, Arias Fisteus & Sanchez Fernandez0.8Accuracy0.6CaseGoogle0.4Lucene0.2RWFRWPPPRPRNBindegreeoutdegreesimRsimCOSPMIMBPMIABPMIMFPMIAFRelMBRelABRelMFRelAFSearchMFLRandom0.0AlgorithmsFigure 8: Accuracy obtained different approaches TAC 2010 Google TAC2010 Lucene corpora.performance TAC 2010 Lucene corpus. fact, though N B top performingcorpus, statistically significant difference popularity approaches likeindegree PageRank (P R). possible explanation result TAC 2010corpus context information automatically generated search enginesupervised. Thus, expect noisy. noise affects N B, RWF , simR ,, rely context information take decisions, impactRWP , RelBindegree P R, rely context information. Note that, though noisecontext information affects cases Google Lucene used search764fiEvaluation Link-Based Approaches Candidate Ranking Link-to-Wikipediaengines, better performance Google (note results Search) makes much worseLucene case.5. Related Workfoundations link-to-Wikipedia task found two different research communities. First, area related traditional computational linguistics tasks likecross-document co-reference resolution (Bagga & Baldwin, 1998), word sense disambiguation (Navigli, 2009). main difference respect traditional tasksWikipedia used source knowledge instead lexicons WordNet (Miller,1995) typically used former work (see instance Li, Szpakowicz, & Matwin, 1995).Second, link-to-Wikipedia task also related link prediction task link mining (Getoor & Diehl, 2005), though case goal mainly decide whether twoobjects (for instance, two actors social network, actor event) linkednot, instead finding best link destination Wikipedia particular anchortext document.Traditionally, works Bunescu Pasca (2006) Cucerzan (2007)considered seminal area. Since publication papers problemlinking anchors text document Wikipedia articles addressed severalworks, like referenced section 3.Two initiatives also especially relevant sense: Knowledge Base Population (KBP) track Text Analysis Conference (TAC), Link-the-Wiki trackInitiative Evaluation XML retrieval (INEX). initiatives share goal:offer common environment (corpora, performance metrics, etc) allow fair comparative evaluation different techniques and, thus, foster area research. However,indicated introductory section, approach link-to-Wikipedia task slightdifferences. case KBP, final aim automatically populate KnowledgeBase (KB) built Wikipedia information named entities. Thus, linkto-Wikipedia variant (named entity linking) focused entities covers casegood Wikipedia target exists link, case indicates need addnew entry KB. case Link-the-Wiki INEX track, focus setkeeping links date rich dynamic hypermedia document collection (suchwiki). Therefore, link-to-Wikipedia variant (wikification) covers common termsnamed entities anchors linked, pay special attention casegood Wikipedia target exists, case link needs created.cases, overview papers published organizers events (Huanget al., 2008, 2009, 2010; Ji et al., 2010, 2011; Ji & Grishman, 2011) offer good sourcereferences area. However, comparisons provided works refersystems taking part TAC/KBP INEX, external work. Furthermore,indicated introductory section, link-to-Wikipedia systems combine, general,variety techniques features different types (based text, links, etc.) addresstask. results reported overviews refer usually full systems,difficult analyze compare performance individual techniques partsystems. goal work analysis comparison link-basedtechniques.765fiFernandez Garca, Arias Fisteus & Sanchez Fernandezsurveys related task link-to-Wikipedia and, thus, relevant purposes paper Navigli Lapata (2010), Chen Ji (2011), Hacheyet al. (2013).Chen Ji (2011) evaluate several supervised candidate rankers named entitylinking, compare reference unsupervised approaches: naive algorithmthree different similarity metrics based textual features. main goal comparisonassess machine learning mechanism (maximum entropy, SVM, SV rankListNet) top performing. Thus, results reported Chen Ji (2011)paper complementary, because, indicated section 4.2.2, differentapproaches analyzed used features supervised systems. Obviously,requires know supervised techniques work better (Chen & Ji, 2011), alsoknow link-based techniques better, goal paper.Hachey et al. (2013) re-implement compare three different named entity linkingsystems state art. However, main goal work different ours,aim Hachey et al. (2013) analyze impact candidate searchingcandidate ranking stages final performance entity linking system.Navigli Lapata (2010) compare several metrics based graph connectivity, including also considered paper, like PageRank indegree. However,work different scope ours: centered different task (word sensedisambiguation), uses different data source (WordNet).knowledge authors, previous overview comparison different linkbased approaches candidate ranking link-to-Wikipedia systems, proposedpaper, available time writing.6. Conclusions Future Linespaper presented overview link-based approaches candidate rankinglink-to-Wikipedia systems. Apart overview, comparative analysisdifferent approaches also carried out. structured analysis three parts:first part devoted compare performance individual approachesaccording three metrics (accuracy, DCG@K MRR) five different corpora(Cucerzan news, Cucerzan Wikipedia, random Wikipedia articles, random Wikinewsarticles TAC 2010). results part analysis indicate that, thoughnaive approaches based popularity candidates perform reasonablywell, taking advantage context information is, general, beneficial linkbased approaches. also found using information backlinksobtain better results using forward links techniques.second part analysis combined different approaches usingListNet. main conclusion part that, according results obtained,combining algorithms produce positive effects performance.Finally, third part analysis devoted evaluate impactcandidate search stage candidate ranking results, impact foundsignificant.766fiEvaluation Link-Based Approaches Candidate Ranking Link-to-WikipediaRegarding potential future lines development work described paper,first aspect consider evaluate impact quality context linksperformance algorithms. also want analyze effect ignoring linksmight introducing noise ranking process, like Lists. opposite case,interested measuring impact including links pages namespaces,like Categories, considered paper. sense, taking Categoriesaccount open door use semantic relatedness measures basedinformation, like described Ponzetto Strube (2007).According results paper, using ListNet combine algorithms producepositive effects performance cases. However, exhaustive analysis differentcombinations carried out. Thus, another potential line development couldexploring combinations algorithms, either taking advantage proposalsmechanisms feature selection learning rank (Geng, Liu, Qin, & Li, 2007)empirically.analyzed different algorithms perspective performancelink-to-Wikipedia task. computational complexity aspects addressed.exhaustive analysis different algorithms along line left future work.suggested section 4.1.3, link-to-Wikipedia systems integrated contentproduction workflows, interact human supervisors. Assessingimpact human factor final performance systems also constitutearea future research.Finally, though paper centered attention candidate rankingstage, link-to-Wikipedia systems usually include processing stages: identifyinganchors linked, searching candidate links anchors, deciding whetherlink suggested (detect NIL answers). end-to-end evaluation includingadditional processing stages also interesting line continue work reportedpaper.Acknowledgementsmemoriam Concepcion Garca Alonso (1943-2012) passengers passedaway Angrois railway accident (24/Jul/2013).ReferencesAdibi, J., Cohen, P. R., & Morrison, C. T. (2004). Measuring confidence intervals linkdiscovery: bootstrap approach. Proceedings ACM Special Interest GroupKnowledge Discovery Data Mining (ACM-SIGKDD-04.Apache Software Foundation (2014). Apache Lucene - Welcome Apache Lucene. Availableat: http://lucene.apache.org/.Bagga, A., & Baldwin, B. (1998). Entity-based cross-document coreferencing usingVector Space Model. Proceedings 17th international conference Computational linguistics - Volume 1, COLING 98, pp. 7985, Stroudsburg, PA, USA.Association Computational Linguistics.767fiFernandez Garca, Arias Fisteus & Sanchez FernandezBianchini, M., Gori, M., & Scarselli, F. (2005). Inside PageRank. ACM Trans. InternetTechnol., 5 (1), 92128.Bizer, C., Lehmann, J., Kobilarov, G., Auer, S., Becker, C., Cyganiak, R., & Hellmann, S.(2009). DBpedia - crystallization point Web Data. Web Semant., 7 (3),154165.Brin, S., & Page, L. (1998). anatomy large-scale hypertextual Web search engine.Comput. Netw. ISDN Syst., 30 (1-7), 107117.Budanitsky, A., & Hirst, G. (2006). Evaluating WordNet-based Measures Lexical Semantic Relatedness. Comput. Linguist., 32 (1), 1347.Bunescu, R. C., & Pasca, M. (2006). Using Encyclopedic Knowledge Named entityDisambiguation. Proceedings 11st Conference European ChapterAssociation Computational Linguistics, EACL.Cao, Y., Lin, C., & Zheng, G. (2011). MSRA TAC 2011: Entity Linking. ProceedingsKnowledge Base Population (KBP) track 4th Text Analysis Conference(TAC). National Institute Standards Technololgy (NIST).Cao, Z., Qin, T., Liu, T.-Y., Tsai, M.-F., & Li, H. (2007). Learning rank: pairwiseapproach listwise approach. ICML 07: Proceedings 24th internationalconference Machine learning, pp. 129136, New York, NY, USA. ACM.Chang, A., Spitkovsky, V., Yeh, E., Aguirre, E., & Manning, C. (2010). Stanford-UBC EntityLinking TAC-KBP. Proceedings Knowledge Base Population (KBP) track3rd Text Analysis Conference (TAC).Chen, Z., & Ji, H. (2011). Collaborative ranking: case study entity linking. Proceedings Conference Empirical Methods Natural Language Processing, EMNLP11, pp. 771781, Stroudsburg, PA, USA. Association Computational Linguistics.Cilibrasi, R. L., & Vitanyi, P. M. B. (2007). Google Similarity Distance. IEEE Trans.Knowl. Data Eng., 19 (3), 370383.Cucerzan, S. (2007). Large-Scale Named Entity Disambiguation Based Wikipedia Data.Proceedings EMNLP-CoNLL 2007, pp. 708716.Cucerzan, S. (2012). MSR System Entity Linking TAC 2012. ProceedingsKnowledge Base Population (KBP) track 5th Text Analysis Conference(TAC).da Silva, J. F., & Lopes, G. P. (1999). local maxima method fair dispersion normalization extracting multi-word units corpora. Sixth Meeting MathematicsLanguage.Dredze, M., McNamee, P., Rao, D., Gerber, A., & Finin, T. (2010). Entity disambiguationknowledge base population. Proceedings 23rd International ConferenceComputational Linguistics, COLING 10, pp. 277285, Stroudsburg, PA, USA.Association Computational Linguistics.Erbs, N., Zesch, T., & Gurevych, I. (2011). Link Discovery: Comprehensive Analysis.Proceedings 2011 IEEE Fifth International Conference Semantic Computing,ICSC 11, pp. 8386, Washington, DC, USA. IEEE Computer Society.768fiEvaluation Link-Based Approaches Candidate Ranking Link-to-WikipediaFader, A., Soderland, S., & Etzioni, O. (2009). Scaling Wikipedia-based Named EntityDisambiguation Arbitrary Web Text. Proceedings WikiAI 09 - IJCAIWorkshop: User Contributed Knowledge Artificial Intelligence: Evolving Synergy, Pasadena, CA, USA.Fahrni, A., Nastase, V., & Strube, M. (2011). HITS Cross-lingual Entity Linking SystemTAC 2011: One Model Languages. Proceedings Knowledge BasePopulation (KBP) track 4th Text Analysis Conference (TAC). National InstituteStandards Technololgy (NIST).Fernandez, N., Fisteus, J., Sanchez, L., & Martin, E. (2010). WebTLab: Cooccurencebased Approach KBP 2010 Entity-Linking Task. Proceedings KnowledgeBase Population (KBP) track 3rd Text Analysis Conference (TAC). NationalInstitute Standards Technololgy (NIST).Fernandez, N., Blazquez, J. M., Fisteus, J. A., Sanchez, L., Sintek, M., Bernardi, A., Fuentes,M., Marrara, A., & Ben-Asher, Z. (2006). NEWS: Bringing Semantic Web Technologies News Agencies. Semantic Web - ISWC 2006, Vol. 4273 LectureNotes Computer Science, pp. 778791. Springer Berlin Heidelberg.Finkel, J. R., Grenager, T., & Manning, C. (2005). Incorporating Non-local InformationInformation Extraction Systems Gibbs Sampling. Proceedings 43ndAnnual Meeting Association Computational Linguistics (ACL 2005), pp.363370.Geng, X., Liu, T.-Y., Qin, T., & Li, H. (2007). Feature selection ranking. Proceedings30th annual international ACM SIGIR conference Research developmentinformation retrieval, SIGIR 07, pp. 407414, New York, NY, USA. ACM.Gentile, A., Zhang, Z., Xia, L., & Iria, J. (2009). Graph-based Semantic RelatednessNamed Entity Disambiguation. Proceeding 1st International ConferenceSoftware, Services Semantic Technologies (S3T).Getoor, L., & Diehl, C. P. (2005). Link mining: survey. SIGKDD Explor. Newsl., 7 (2),312.Gracia, J., & Mena, E. (2008). Web-Based Measure Semantic Relatedness. Proceedings9th international conference Web Information Systems Engineering, WISE08, pp. 136150.Guo, Y., Tang, G., Che, W., Liu, T., & Li, S. (2011). HIT Approaches Entity LinkingTAC 2011. Proceedings Knowledge Base Population (KBP) track 4thText Analysis Conference (TAC). National Institute Standards Technololgy(NIST).Hachey, B., Radford, W., & Curran, J. R. (2011). Graph-based named entity linkingWikipedia. Proceedings 12th international conference Web informationsystem engineering, WISE11, pp. 213226, Berlin, Heidelberg. Springer-Verlag.Hachey, B., Radford, W., Nothman, J., Honnibal, M., & Curran, J. R. (2013). EvaluatingEntity Linking Wikipedia. Artificial Intelligence, 194 (0), 130 150.Han, X., & Sun, L. (2011). generative entity-mention model linking entitiesknowledge base. Proceedings 49th Annual Meeting Association769fiFernandez Garca, Arias Fisteus & Sanchez FernandezComputational Linguistics: Human Language Technologies - Volume 1, HLT 11, pp.945954, Stroudsburg, PA, USA. Association Computational Linguistics.Han, X., Sun, L., & Zhao, J. (2011). Collective entity linking web text: graph-basedmethod. Proceedings 34th international ACM SIGIR conference Researchdevelopment Information Retrieval, SIGIR 11, pp. 765774, New York, NY,USA. ACM.Han, X., & Zhao, J. (2009). Named entity disambiguation leveraging Wikipedia semanticknowledge. Proceedings 18th ACM conference Information knowledgemanagement, CIKM 09, pp. 215224, New York, NY, USA. ACM.Haveliwala, T. H. (2003). Topic-Sensitive PageRank: Context-Sensitive Ranking Algorithm Web Search. IEEE Trans. Knowl. Data Eng., 15 (4), 784796.Huang, D. W., Xu, Y., Trotman, A., & Geva, S. (2008). Overview INEX 2007 LinkWiki Track. Fuhr, N., Kamps, J., Lalmas, M., & Trotman, A. (Eds.), FocusedAccess XML Documents, pp. 373387. Springer-Verlag, Berlin, Heidelberg.Huang, D. W. C., Geva, S., & Trotman, A. (2009). Overview INEX 2008 LinkWiki Track. Geva, S., Kamps, J., & Trotman, A. (Eds.), Advances FocusedRetrieval, Vol. 5631 Lecture Notes Computer Science, pp. 314325. SpringerBerlin Heidelberg.Huang, W., Geva, S., & Trotman, A. (2010). Overview INEX 2009 Link WikiTrack. Geva, S., Kamps, J., & Trotman, A. (Eds.), Focused Retrieval Evaluation, Vol. 6203 Lecture Notes Computer Science, pp. 312323. Springer BerlinHeidelberg.INEX (2014). INEX 2014 main page. Available at:https://inex.mmci.uni-saarland.de/.Ji, H., & Grishman, R. (2011). Knowledge base population: Successful approacheschallenges. Proceedings 49th Annual Meeting Association Computational Linguistics (ACL), pp. 11481158.Ji, H., Grishman, R., & Dang, H. T. (2011). Overview TAC2011 Knowledge BasePopulation Track. Proceedings Knowledge Base Population (KBP) track4th Text Analysis Conference (TAC).Ji, H., Grishman, R., Dang, H. T., Griffitt, K., & Ellis, J. (2010). Overview TAC2010Knowledge Base Population Track. Proceedings Knowledge Base Population(KBP) track 3rd Text Analysis Conference (TAC).Jimenez, M., Fernandez, N., Fisteus, J., & Sanchez, L. (2013). WikiIdRank++: extensionsimprovements WikiIdRank system entity linking. International JournalArtificial Intelligence Tools, 22 (3).Joachims, T. (2002). Optimizing search engines using clickthrough data. Proceedingseighth ACM SIGKDD international conference Knowledge discovery datamining, KDD 02, pp. 133142, New York, NY, USA. ACM.Kulkarni, S., Singh, A., Ramakrishnan, G., & Chakrabarti, S. (2009). Collective annotationWikipedia entities web text. Proceedings 15th ACM SIGKDD inter770fiEvaluation Link-Based Approaches Candidate Ranking Link-to-Wikipedianational conference Knowledge discovery data mining, KDD 09, pp. 457466,New York, NY, USA. ACM.Lehmann, J., Monahan, S., Nezda, L., Jung, A., & Shi, Y. (2010). LCC ApproachesKnowledge Base Population TAC 2010. Proceedings Knowledge BasePopulation (KBP) track 3rd Text Analysis Conference (TAC).Li, X., Szpakowicz, S., & Matwin, S. (1995). WordNet-based algorithm word sensedisambiguation. Proceedings 14th international joint conference Artificialintelligence - Volume 2, IJCAI95, pp. 13681374, San Francisco, CA, USA. MorganKaufmann Publishers Inc.Lin, W.-P., Snover, M., & Ji, H. (2011). Unsupervised language-independent name translation mining Wikipedia infoboxes. Proceedings First WorkshopUnsupervised Learning NLP, EMNLP 11, pp. 4352, Stroudsburg, PA, USA. Association Computational Linguistics.Liu, T.-Y. (2009). Learning Rank Information Retrieval. Found. Trends Inf. Retr.,3 (3), 225331.Manning, C. D., Raghavan, P., & Schtze, H. (2008). Introduction Information Retrieval.Cambridge University Press, New York, NY, USA.Mihalcea, R., & Csomai, A. (2007). Wikify!: linking documents encyclopedic knowledge.Proceedings sixteenth ACM conference Conference informationknowledge management, CIKM 07, pp. 233242, New York, NY, USA. ACM.Miller, G. A. (1995). WordNet: lexical database English. Commun. ACM, 38 (11),3941.Milne, D., & Witten, I. H. (2008a). effective, low-cost measure semantic relatedness obtained Wikipedia links. Proceedings first AAAI WorkshopWikipedia Artificial Intelligence (WIKIAI08).Milne, D., & Witten, I. H. (2008b). Learning link Wikipedia. Proceedings17th ACM conference Information knowledge management, CIKM 08, pp.509518, New York, NY, USA. ACM.MSNBC (2014). MSNBC: news, video progressive community. Available at:http://www.msnbc.msn.com.National Institute Standards Technology (2014a). Text Analysis Conference (TAC).Available at: http://www.nist.gov/tac/.National Institute Standards Technology (2014b). Text Analysis Conference (TAC)KBP 2014 Tracks. Available at: http://www.nist.gov/tac/2014/KBP/.Navigli, R. (2009). Word sense disambiguation: survey. ACM Comput. Surv., 41 (2),10:110:69.Navigli, R., & Lapata, M. (2010). Experimental Study Graph ConnectivityUnsupervised Word Sense Disambiguation. IEEE Trans. Pattern Anal. Mach. Intell.,32 (4), 678692.771fiFernandez Garca, Arias Fisteus & Sanchez FernandezNguyen, H., & Cao, T. (2010). Exploring Wikipedia Text Features Named EntityDisambiguation. Nguyen, N., Le, M., & Swiatek, J. (Eds.), Intelligent InformationDatabase Systems, Vol. 5991 Lecture Notes Computer Science, pp. 1120.Springer Berlin / Heidelberg.Nothman, J., Murphy, T., & Curran, J. R. (2009). Analysing Wikipedia gold-standardcorpora NER training. Proceedings 12th Conference EuropeanChapter Association Computational Linguistics, EACL 09, pp. 612620,Stroudsburg, PA, USA. Association Computational Linguistics.Page, L., Brin, S., Motwani, R., & Winograd, T. (1999). PageRank Citation Ranking:Bringing Order Web. Technical report 1999-66, Stanford InfoLab.Pilz, A. (2010). Entity Disambiguation using Link based Relations extractedWikipedia. First Workshop Automated Knowledge Base Construction (AKBC2010), Grenoble, France.Ploch, D., Hennig, L., de Luca, E. W., & Albayrak, S. (2011). DAI ApproachesTAC-KBP 2011 Entity Linking Task. Proceedings Knowledge Base Population (KBP) track 4th Text Analysis Conference (TAC). National InstituteStandards Technololgy (NIST).Ponzetto, S. P., & Strube, M. (2007). Knowledge derived Wikipedia computingsemantic relatedness. J. Artif. Int. Res., 30 (1), 181212.Radford, W., Hachey, B., Nothma, J., Honnibal, M., & Curran, J. (2010). CMCRCTAC 2010: Document-level Entity Linking graph-based re-ranking. Proceedings 3rd Text Analysis Conference (TAC), National Institute StandardsTechnology, NIST, Maryland, USA.Ratinov, L., Roth, D., Downey, D., & Anderson, M. (2011). Local global algorithmsdisambiguation Wikipedia. Proceedings 49th Annual MeetingAssociation Computational Linguistics: Human Language Technologies - Volume1, HLT 11, pp. 13751384, Stroudsburg, PA, USA. Association ComputationalLinguistics.Sil, A. (2013). Exploring Re-ranking Approaches Joint Named-entityrecognitionLinking. Proceedings Sixth Workshop Ph.D. Students InformationKnowledge Management, PIKM 13, pp. 1118.Spitzer, F. (1976). Principles Random Walk (2nd Edition). Springer.Van B. Dang (2014). RankLib (software package). Available at:http://people.cs.umass.edu/vdang/ranklib.html.Vanwinckelen, Gitte; Blockeel, H. (2012). estimating model accuracy repeatedcross-validation. Proceedings 21st Belgian-Dutch Conference MachineLearning, pp. 3944.Voorhees, E. (1999). TREC-8 Question Answering Track Report. Proceedings 8thText Retrieval Conference, pp. 7782.Wikinews (2014a). Wikinews Random Page Generator. Available at:http://en.wikinews.org/wiki/Special:Random.772fiEvaluation Link-Based Approaches Candidate Ranking Link-to-WikipediaWikinews (2014b). Wikinews, free news source. Available at:http://en.wikinews.org/.Wikipedia (2014a). Wikipedia Random Page Generator. Available at:http://en.wikipedia.org/wiki/Special:Random.Wikipedia (2014b). Wikipedia:Namespace - Wikipedia, free encyclopedia. Available at:http://en.wikipedia.org/wiki/Wikipedia:Namespace.Yeh, E., Ramage, D., Manning, C. D., Aguirre, E., & Soroa, A. (2009). WikiWalk: randomwalks Wikipedia semantic relatedness. Proceedings 2009 WorkshopGraph-based Methods Natural Language Processing, TextGraphs-4, pp. 4149,Stroudsburg, PA, USA. Association Computational Linguistics.773fiJournal Artificial Intelligence Research 49 (2014) 269321Submitted 09/13; published 02/14Efficient HEX-Program Evaluation Based Unfounded SetsEITER @ KR . TUWIEN . AC .FINK @ KR . TUWIEN . AC .TKREN @ KR . TUWIEN . AC .Thomas EiterMichael FinkThomas KrennwallnerChristoph RedlREDL @ KR . TUWIEN . AC .Institut fur InformationssystemeTechnische Universitat WienFavoritenstrae 9-11, A-1040 Vienna, AustriaPETERSCHUELLER @ SABANCIUNIV. EDUPeter SchullerFaculty Engineering Natural SciencesSabanci UniversityOrhanli, Tuzla, 34956 Istanbul, TurkeyAbstractHEX-programs extend logic programs answer set semantics external computations external atoms. reasoning ground Horn programs nonmonotonic external atoms polynomial complexity already second level polynomial hierarchy,minimality checking answer set candidates needs special attention. end, presentapproach based unfounded sets generalization related techniques ASP programs.unfounded set detection expressed propositional SAT problem, provide twodifferent encodings optimizations them. integrate approach previouslydeveloped evaluation framework HEX-programs, enriched additional learning techniques aim avoiding reconstruction related unfounded sets. Furthermore,provide syntactic criterion allows one skip minimality check many cases.experimental evaluation shows new approach significantly decreases runtime.1. IntroductionAnswer Set Programming (ASP) declarative problem solving approach. Due expressiveextensions efficient systems like SMODELS (Simons, Niemela, & Soininen, 2002), DLV (Leone,Pfeifer, Faber, Eiter, Gottlob, Perri, & Scarcello, 2006) CLASP (Gebser, Kaufmann, & Schaub,2012), gaining popularity many applications (Brewka, Eiter, & Truszczynski, 2011).However, current trends computing, context awareness distributed systems, raisedneed access external sources program. instance, external sources Web rangelight-weight data access (e.g., XML, RDF, data bases) knowledge-intensive formalisms(e.g., OWL ontologies).cater need, Eiter, Ianni, Schindlauer, Tompits (2005) defined HEX-programsextension ASP so-called external atoms, user couple externalinformation source logic program. Roughly, atoms pass information, given predicate extensions, program external source returns output values (abstract)function computes. example, rule nb(X, ) &neighbor [0 map 0 , X](Y ) may informally import point X map stored file map (in particular data format),point neighborhood X predicate nb. convenient external accessc2014AI Access Foundation. rights reserved.fiE ITER , F INK , K RENNWALLNER , R EDL , & CH ULLERexploited many applications, including querying data ontologies (Eiter et al., 2008b; Hoehndorf et al., 2007; Marano et al., 2010), e-government (Zirtiloglu & Yolum, 2008), fuzzy answer setprogramming (Nieuwenborgh, Cock, & Vermeir, 2007a), multi-context reasoning (Brewka & Eiter,2007; Eiter et al., 2012b), (Nieuwenborgh et al., 2007b; Basol et al., 2010). formalism highlyexpressive recursive data exchange rules external sources possible.semantics HEX-programs model-based given answer sets following approach Faber, Leone, Pfeifer (2011), extends answer set semantics logic programs (Gelfond & Lifschitz, 1991) logic programs aggregates; Faber et al. approach(known FLP semantics) preserves property answer sets have, spiritclosed world assumption, smallest positive information content, formally capturedminimality condition models.current approach evaluation HEX-programs (Eiter et al., 2006a, 2011) rewritegiven HEX-program answer set program (i) eliminating external atoms favor auxiliaryatoms using called replacement atoms, (ii) introducing auxiliary rules answersets HEX-program correspond subset answers sets resulting programauxiliary atoms faithfully represent values external atoms; compatibilitycondition answer set tested postcheck.computing answer sets (disjunctive) logic program P like , different methodsproposed. immediate one implement definition answer set test whethergiven interpretation minimal model called reduct program P wrt. interpretation; end, suitable candidate answer set might guessed generated heuristics.approach essentially adopted solvers G N (Janhunen et al., 2006) CMODELS(Lierler, 2005), use test logic program, respectively SAT encoding. differentapproach presented Leone et al. (1997) based notion unfounded set (Van Gelder,Ross, & Schlipf, 1991), extended normal (non-disjunctive) disjunctive logicprograms. Intuitively, set U atoms unfounded wrt. model program P , switchingatoms U false lead violated rules; answer sets P modelsunfounded-free, i.e., models disjoint respective unfounded sets. checking(un)foundedness given candidate answer set, Koch et al. (2003) presented SAT encoding.Drescher et al. (2008) later exploited findings Leone et al. extend techniqueconflict-driven clause learning used CLASP solver disjunctive logic programs.quoted works, however, access external sources issue, thuscannot deployed HEX-programs. fact, addition compatibility check answer setreplacement program , current HEX evaluation must second step test minimalityinterpretation induced HEX-program wrt. program reduct. method,refer explicit FLP check, turns less efficient practice, often dominatestotal runtime; thus efficient method desirable.Motivated seminal approach Leone et al., consider paper useunfounded sets alternative explicit FLP check HEX-programs, referunfounded set check. end, extend notion unfounded sets disjunctive logicprograms HEX-programs, following lines Faber (2005), unfounded sets logicprograms aggregates defined, consider use combination clause learningtechniques. main contributions summarized follows:present basic encoding unfounded set existence set nogoods, i.e., constraintssatisfied, show solutions 1-1 correspondence270fiE FFICIENT HEX-P ROGRAM E VALUATION BASED U NFOUNDED ETSunfounded sets. latter thus computed running SAT solver, followed postprocessing step checks values replacement atoms compatibleexternal call results. Benchmarks show strategy already efficientexplicit FLP check.present advanced encoding unfounded set existence reusableinterpretation. Compared first encoding, conceptually involved(slightly) higher initialization cost, advantage reused unfounded set checks needs separate initialization check. benchmarks showadvanced encoding superior first one many practical problems.Next, consider optimizations hinge dependencies external ordinaryatoms determined careful analysis. optimizations integratedencodings adding nogoods restrict search space relevant parts.consider exploit information gained unfounded set check candidate answer set answer set candidate generation, i.e., evaluation program . Adopting Conflict Driven Clause Learning approach (Drescher et al., 2008), steprecently enhanced external behavior learning (Eiter et al., 2012a), nogoods describing external source behavior learned search guide model generationtowards proper guesses. show learn candidate generation step additionalnogoods unfounded sets avoid reconstruction related unfoundedsets, yielding gain.present syntactic decision criterion used decide whether program possibly unfounded sets. result check negative, computationallyexpensive search unfounded sets skipped entirely. criterion based atomdependency and, loosely speaking, says cyclic dependencies ground atomsexternal atoms. property efficiently checked given ground HEXprogram using standard methods. fact applies range applications, particularinput-stratified programs, external sources accessed workflow produce input next stage computation. However, advanced applications HEX-programscycles external atoms, e.g., natural encodings problems multi-contextsystems (Brewka & Eiter, 2007) abstract argumentation systems (Dung, 1995),FLP check simply skipped.elaboration, consider program decomposition based dependencygraph induced program (note exploiting syntactic modularization unfounded sets traced back Leone et al., 1997; Koch et al., 2003). showunfounded set wrt. candidate answer set exactly components Cdecomposition unfounded set wrt. A; computing decompositionrealized efficiently incur large overhead, apply decision criterionskipping FLP check efficiently finer-grained level, search unfounded setsguided relevant program parts.experimental evaluation advanced reasoning applications shows unfounded setschecking combined learning methods Eiter et al. (2012a) improves HEX-programevaluation considerably, sometimes drastically. specifically, benchmark applications271fiE ITER , F INK , K RENNWALLNER , R EDL , & CH ULLERinclude reasoning tasks Multi-Context Systems (Brewka & Eiter, 2007; Eiter et al., 2012b),abstract argumentation (Dung, 1995), terminological default reasoning description logicknowledge bases (Baader & Hollunder, 1995), conformant planning (Goldman & Boddy,1996; Smith & Weld, 1998). experiments carried DLVHEX version2.3.0, prototype solver HEX-programs, extended support techniquesdeveloped paper. decomposition approach yield considerable gain,appears e.g. HEX-encoding Dung-style argumentation semantics (Dung, 1995)DL-programs (Eiter et al., 2008a). hand, terminological defaultreasoning benchmark, syntactic criterion lets us conclude FLP check obsolete.conclusion, new approach enables significant speedup thus enlarges scopeHEX applicability.1.1 Organizationrest paper organized follows. next section provides preliminaries HEXprograms evaluation via answer sets transformed ASP program without externalatoms. Section 3, define unfounded sets present basic uniform encodingunfounded set search using nogoods. Section 4 considers refinements optimizationsencodings, well external behavior learning prevent reconstruction unfounded sets.Section 5, give syntactic decision criterion avoid FLP check program decomposition method exploiting it. Experimental results prototype implementation reportedSection 6. Section 7, consider related work extensions approach. Section 8,conclude point issues research.2. Preliminariessection, start basic definitions, introduce HEX-programs.accordance Gebser et al. (2012) Eiter et al. (2012a), (signed) literal positivenegative formula Ta resp. Fa, ground atom form p(c1 , . . . , c` ), predicate pconstants c1 , . . . , c` , abbreviated p(c). literal = Ta = Fa, let denote opposite, i.e.,Ta = Fa Fa = Ta. assignment (finite) set atoms consistent set signedliterals Ta Fa, Ta expresses true Fa false; complete,also called interpretation, assignment A0 exists. denote = {a | Ta A}AF = {a | Fa A} set atoms true resp. false A, ext(q, A) = {c |Tq(c) A} extension predicate q A. Furthermore, A|q set literalsatoms predicate q A. ForSa list q = q1 , . . . , qk predicates, write p q iff qi = p1 k, let A|q = j A|qj .nogood set {L1 , . . . , Ln } signed literals Li , 1 n. interpretationsolution nogood (resp. set nogoods), iff 6 (resp. 6 ).Example 1 interpretation = {Ta, Fb, Tc} solution nogood {Ta, Tb, Tc}{Ta, Fb, Tc}.2.1 HEX-ProgramsNext, recall syntax semantics HEX-programs.272fiE FFICIENT HEX-P ROGRAM E VALUATION BASED U NFOUNDED ETS2.1.1 HEX -P ROGRAM YNTAXintroduced Eiter et al. (2005), HEX-programs generalization (disjunctive) extendedlogic programs answer set semantics (Gelfond & Lifschitz, 1991). HEX-programs extendASP programs external atoms, enable bidirectional interaction programexternal sources computation. External atoms list input parameters (constants predicate names) list output parameters. Informally, evaluate external atom, reasonerpasses constants extensions predicates input tuple external source associated external atom. external source computes output tuples matchedoutput list. Syntactically, ground external atom form&g[p](c),(1)&g external predicate, p = p1 , . . . , pk input list consisting predicate namesobject constants, c = c1 , . . . , cl output list consisting constant terms. Predicatesinput list sometimes called input predicates.default literal formula b b, b ground ordinary atom form p(c1 , . . . , c` )constants ci , 1 `, external atom. every set ordinary external atoms,let = {not b | b S}.Ground HEX-programs defined similar ground ASP programs.Definition 1 (Ground HEX-programs) ground HEX-program consists rulesa1 ak b1 , . . . , bm , bm+1 , . . . , bn ,(2)ai ordinary ground atom, bj either ordinary ground atom groundexternal atom, k + n > 0.1rule r, head H(r) = {a1 , . . . , ak } body B(r) = B + (r) B (r),B + (r) = {b1 , . . . , bm } positive body, B (r) = {bm+1 , . . . , bn } negative body.B(r) = , r fact, omit . program , let A() set ordinaryatoms EA() set external atoms occurring . default literal b, let tb = Tab = atom a, tb = Fa b = a. Furthermore, f b = Fa b = f b = Tab = a.call rule r constraint, B(r) = .Example 2 rule r = ab c, H(r) = {a, b}, B + (r) = {c} B (r) = {d}.tc = Tc, f c = Fc, = Fd f = Td.also consider non-ground programs (i.e., variables allowed place object constants) examples. particular, external atoms &g[X](Y) may contain variablesinput list X output list Y. programs, suitable safety conditions allow usinggrounding procedure transforms program variable-free program answer sets (Eiter, Ianni, Schindlauer, & Tompits, 2006). However, limit formal investigationground programs.1. simplicity, formally introduce strong negation view, customary, classical literals newatoms together constraint disallows simultaneously true.273fiE ITER , F INK , K RENNWALLNER , R EDL , & CH ULLERExample 3 programdomain(a); domain(b)sel (X) domain(X), nsel (X)nsel (X) domain(X), sel (X)encodes problem partitioning two domain elements b two sets sel nsel .2.1.2 HEX -P ROGRAM EMANTICSordinary ground atom true relative assignment A, denoted |= a, Tafalse otherwise. default-negated ground atom true relative assignment A, denoted|= a, Fa false otherwise.semantics ground external atom form (1) wrt. interpretation givenvalue 1+k+l-ary Boolean oracle function f&g defined possible values A, pc, &g[p](c) true relative A, denoted |= &g[p](c), f&g (A, p, c) = 1.Example 4 (Set Partitioning) Consider programsel (a) domain(a), &diff [domain, nsel ](a)nsel (a) domain(a), &diff [domain, sel ](a)domain(a)predicates p q, &diff [p, q](X) computes set elements Xextension p extension q. Informally, program implements choicesel (a) nsel (a).Satisfaction ordinary rules ASP programs (Gelfond & Lifschitz, 1991) extendedprograms obvious way: rule r satisfied assignment A, denoted |= r,iff |= h h H(r), 6|= b b B + (r), |= b b B (r).program satisfied assignment iff |= r r . interpretation modelprogram , denoted |= , iff |= r r .notion extension ext(, A) external predicates &g input lists p naturallydefined ext(&g[p], A) = {c | f&g (A, p, c) = 1}.HEX -rulesDefinition 2 (FLP-Reduct (Faber et al., 2011)) interpretation program ,FLP-reduct wrt. set f = {r | |= b, b B(r)} rules whosebody satisfied A.assignment A1 smaller equal another assignment A2 wrt. program , denotedA1 A2 , iff {Ta A1 | A()} {Ta A2 | A()}.Definition 3 (Answer Set) answer set -minimal model f .Example 5 Consider program :p &id [q]()qpf&id (A, p) = 1 iff Tp true. answer set A1 = ; indeed-minimal model f A1 = . Note A2 = {Tp, Tq} answer set ,minimal model f A2 = .274fiE FFICIENT HEX-P ROGRAM E VALUATION BASED U NFOUNDED ETS2.2 Evaluation HEX-Programspossible way determine answer sets HEX-program use transformationASP program without external atoms whose answer sets encompass answer sets .describe transformation. external atom = &g[p](c) rule r replacedordinary ground replacement atom = e&g[p] (c) (resulting rule r), additionalrule e&g[p] (c) ne &g[p] (c) added program. answer sets resulting guessingprogram determined ASP solver projected non-replacement atoms. However,resulting assignments might spurious answer sets , values &g[p] e&g[p] (c)relative interpretation may coincide. answer set thus merely candidatemust checked external sources. discrepancy found, model candidatecompatible set . precisely,Definition 4 (Compatible Set) compatible set program assignment(i) answer set (Gelfond & Lifschitz, 1991) guessing program ,(ii) f&g (A, p, c) = 1 iff Te&g[p] (c) external atoms &g[p](c) , i.e., guessedvalues coincide values oracle functions.subset compatible sets represents answer sets , answer setgiven restriction unique compatible set non-replacement atoms.formally, answer set program corresponds compatible set(, A) = {Tea , Fne | external atom , |= e}{Fea , Tne | external atom , 6|= e} .filter compatible sets yield answer sets, compatible setchecked models FLP reduct. specific, procedure called explicit FLPcheck constructs reduct f checks whether model A0 smaller A;A0 found, rejects A, otherwise outputs answer set.explicit FLP check rewrites HEX-program ASP program without external atomsamounts search answer sets following program, truth valuesreplacement atoms coincide according oracle function values:Check (, A) = f { | A(), Ta 6 A} {a a0 | Ta A}{ smaller } {smaller | A(), Ta A} .consists reduct f rules restrict search proper subinterpretations A,smaller new atom. Moreover, actually need search modelscompatible sets, rules form a0 (where a0 new atom Ta A) make sureatoms arbitrarily true without justifying rule .Proposition 1 Let interpretation extracted compatible set program .program Check (, A) answer set A0 f&g (A0 , p, c) = 1 iff Te&g[p] (c) A0external atoms &g[p](c) , answer set .guessing rules, rewrite rules f except guesses replacementatoms constraints follows:CheckOptimized (, A) = fA { | A(), Ta 6 A} {a a0 | Ta A}{ smaller } {smaller | A(), Ta A}.275fiE ITER , F INK , K RENNWALLNER , R EDL , & CH ULLERadd external replacementatoms + guessing rulesStep S1External AtomEvaluationMain Search (CDNL)Plugin1Model Candidatescheck unverifiedexternal atom guesses...Compatible SetsStep S2FLP Check(Unfounded Set Check)AnswerSetsPluginkFigure 1: Overview framework evaluating HEX-programs.fA denotes FLP reduct wrt. interpretation rule form (2) exceptguessing rules replacement atoms rewrittena1 , . . . , ak , b1 , . . . , bm , bm+1 , . . . , bn .Proposition 2 Let interpretation extracted compatible set program .program CheckOptimized (, A) answer set A0 f&g (A0 , p, c) = 1Te&g[p] (c) A0 external atoms &g[p](c) , answer set .program efficient evaluation. comparison Section 6 uses optimizedversion explicit check, still demonstrates significant performance gain novelapproach.Example 6 (contd) Reconsider program = { p &id [q](); q p } above.corresponding guessing program = {p e&id[q] (); q p; e&id[q] ()ne &id[q] () } yieldscompatible sets A1 = A2 = {Tp, Tq, Te&id[p] }. A1 = also -minimalmodel f A1 = , A2 = {Tp, Tq} -minimal model f A2 = . Indeed,programCheck (, A2 ) = {p p0 ; q q 0 ; e&id[q] () e0&id[q] () } { smaller }{smaller p} {smaller q; smaller e&id[q] ()}answer set A0 =nFp, Tp0 , Fq, Tq 0 , Fe&id[q] (), Tne &id[q] (), Te0&id[q] (), Tsmallerf&id (A0 , q, ) = 0 Fe&id[q] () A0 .276fiE FFICIENT HEX-P ROGRAM E VALUATION BASED U NFOUNDED ETScompatiblesetBasicEncodingUniformEncodingAssumptionsAAsearch UFScandidatesFLP ChecksverifycandidateMain Search(CDNL)ExternalAtomEvaluationUFSunfounded freeFigure 2: FLP Check based Unfounded Setscomplete prodedure computing answer sets HEX-programs described Eiteret al. (2012a) shown block diagram Figure 1; first version introducing approachDLVHEX version 2.1.0. Step S1 enumerates compatible sets; reuse part evaluationprocess prior work modify it. Step S2 checks whether compatible set indeedHEX answer set. improvement efficiency S2 focus work. S1 transformsinput program introducing replacement atoms guesses replacement atoms.main search enumerates model candidates, i.e., answer sets . (Depending heuristics,search evaluate external atoms guiding search.) Model candidates verifiedsemantics external atoms. check fails, main search continues enumerate modelcandidates; check succeeds, model candidate compatible set. S2 checks whethercompatible set answer set . Previous work realized step using explicit FLP check.work propose two alternatives carry FLP check based unfounded sets.Figure 2 depicts block diagram FLP checks proposed work, called basicuniform encoding. encodings SAT theories. basic encoding builds programcompatible set A. uniform encoding based (hence reusecompatible sets), however requires us set solver assumptions based A. encoding(and assumptions) used search unfounded set (UFS) candidates (by SAT solver).UFS candidate verified values external atoms (these guessed UFSencoding). UFS candidates fail external atom check, UFS candidates,unfounded-free compatible set hence answer set . Otherwise FLP checkfound unfounded set wrt. main search continues looking new model candidate.next describe encodings UFS-checking.277fiE ITER , F INK , K RENNWALLNER , R EDL , & CH ULLER3. Unfounded Set Detectiondescribed Section 2.2, minimality check, also called explicit FLP check, computationally costly involves much overhead: models Check (, A) must enumerated,calls external sources test compatibility must made. Even worse, needsearch smaller model smaller compatible set, Check (, A) usually (toexperience) even models original program. Moreover, appears manycurrent application scenarios smaller model reduct f , i.e., assignmentsextracted compatible sets pass FLP check. two possible reliefs: developingcheaper minimality check avoid minimality check possible. section targetsformer idea, latter one addressed Section 5.end, present novel FLP check algorithm based unfounded sets (UFS). Insteadexplicitly searching smaller models reduct, check whether candidate answer setunfounded-free. end, use unfounded sets HEX-programs akin Faber (2005)programs arbitrary aggregates.Definition 5 (Unfounded Set) Given program assignment A, let X set ordinary ground atoms appearing . Then, X unfounded set wrt. if, ruleratoms X head, least one following conditions holds,..X = (A \ {Ta | X}) {Fa | X}:(i) literal B(r) false wrt. A,.(ii) literal B(r) false wrt. .X,(iii) atom H(r) \ X true wrt. A.Intuitively, unfounded set set atoms circularly support other;assigning false, violation rule introduced. answer sets,minimality enforces subset atoms true answer set form unfounded set; fact, answer sets characterized terms unfounded sets, using followingnotion.Definition 6 (Unfounded-free Interpretations) interpretation program unfoundedfree, iff X = , every unfounded set X wrt. A.following result generalization respective result ordinary (disjunctive) logicprograms (Leone et al., 1997) logic programs aggregates (Faber, 2005).Theorem 3 (Characterization Answer Sets) model HEX-program answer setiff unfounded-free.Example 7 Consider program A1 Example 6. Trivially, A1 unfounded-free,thus A1 answer set . hand, set X. = {p, q} unfounded set w.r.t. A2 ,since X intersects head p &id [q]() .X 6|= &id [q](). Therefore A2unfounded-free answer set .278fiE FFICIENT HEX-P ROGRAM E VALUATION BASED U NFOUNDED ETS3.1 Basic Encoding Unfounded Set Searchrealize search unfounded sets using nogoods, i.e., given assignmentconstruct set nogoods, solutions set correspond (potential) unfounded sets;use SAT solver search unfounded sets.specifically, encoding unfounded set detection uses set= N, O, ,contains necessary constraints set optional optimizationnogoods N,,nogoods prune irrelevant parts search space; latter related one Drescheret al. (2008) respects external atoms. idea set ordinary atoms solutionrepresents (potential) unfounded set U wrt. A, .while replacement atoms encodetruth values corresponding external atoms .U .rule r, let Bo+ (r) B + (r) consist ordinary atoms, let (r) B(r) consistexternal replacement atoms. Then,built atoms A( ) = A() {hr , lr | r },hr , lr new atoms every rule r . necessary part= {{Fa | Ta A}}N,r Rr,Aconsists nogood {Fa | Ta A}, eliminates unfounded sets intersecttrue atoms A, nogoods Rr,A = Hr,A Cr,A every rHr,A = {{Thr } {Fh | h H(r)}} {{Fhr , Th} | h H(r)}, called head criterion,encodeshr true rule r iff atom H(r) unfounded set;{{Thr }{Fa | B + (r), |= a} {ta | B (r)}eCr,A ={Th|hH(r),|=h}}|= B(r),{}otherwise,called conditional part Cr,A , encodes Condition (i), (ii) (iii) Definition 5 musthold hr true.specifically, unfounded set U rule r H(r) U 6= (hr true) musthappen |= B(r) (Condition(i) fails), Bo+ (r) |= unfounded set.(r) true .U (Condition (ii) fails), h H(r) |= h,Adefined Section 4.unfounded set (Condition (iii) fails). Concrete instancesExample 8 Consider = {r1 : p &id [p]()} compatible set = {Tp, Te&id[p] }.A2nogood set N,{{Thr1 , Fp}, {Fhr1 , Tp}, {Thr1 , Te&id[p] (), Tp}}.Towards computing unfounded sets, observe every unfounded set extended solutionnogood setA( ). Conversely, solutions include specific extensionsunfounded sets, given unfounded set U assigning true atoms U , hrH(r) intersects U , replacement atoms e&g[p] (c) &g[p](c) true..U , assigning false atoms A(A). formally,Definition 7 (Induced Assignment Unfounded Set wrt.) Let U unfounded setprogram wrt. assignment A. assignment induced U wrt., denoted (U, , , A),00(U,, , A) = (U, , A) {Fa | A( ), Ta 6 (U, , A)} ,279fiE ITER , F INK , K RENNWALLNER , R EDL , & CH ULLERI0 (U, , A) = {Ta | U } {Thr | r , H(r) U 6= }.{Te&g[p] (c) | &g[p](c) EA(), .U |= &g[p](c)} .call set N nogoods conservative, holds every unfounded set U wrt.(U,, , A) solution N . show solutions include assignments,Ainduced unfounded sets wrt. A, assuming conservative.Proposition 4 Let U unfounded set program wrt. assignment U 6= .(U,, , A) solution .Note converse hold, i.e., every solution corresponds induced assignment; intuitively reflect semantics external sources. Regardlessimmediately obtain Proposition 4 useful test unfounded-freeness.Corollary 5solution, U = every unfounded set U .Using following result, find unfounded sets wrt. among solutionsusing postcheck external atoms.Theorem 6 Let solution.(a) Te&g[p] (c) 6|= &g[p](c) implies .U |= &g[p](c);.(b) Fe&g[p] (c) |= &g[p](c) implies .U 6|= &g[p](c)U = {a | A(), Ta S}. U unfounded set wrt. A.Informally, proposition states non-replacement atoms true alsoappear form unfounded set, provided truth replacement atoms e&g[p] (c) co.incides truth corresponding &g[p](c) .U (as Definition 7). However,check required truth values e&g[p] (c) &g[p](c) differ.gives rise important optimization implementation: external atoms, whose (known) truthvalue &g[p](c) matches truth value e&g[p] (c) S, need postchecked.follows immediately Definition 7 postcheck eliminate unfounded sets,formalized following proposition.Proposition 7 Let U unfounded set program wrt. assignment U 6= .(U,, , A) fulfills Conditions (a) (b) Theorem 6.Example 9 Reconsider program = {r1 : p &id [p]()} Example 8 compatible setA2A2 = {Tp, Te&id[p] }. nogood set N,= {{Thr1 , Fp}, {Fhr1 , Tp}, {Thr1 , Te&id[p] (), Tp}}solutions {Thr1 , Tp, Fe&id[p] ()}, correspond unfounded set U = {p}. Here,.Fe&id[p] () represents A2 .U 6|= &id [p]().Note due premises Conditions (a) (b) Theorem 6, postcheck fasterTe&g[p] (c) whenever |= &g[p](c) holds many external atoms .exploited construction follows: absolutely necessary set truthvalue e&g[p] (c) differently, carry value &g[p](c) A. Specifically,successful e&g[p] (c) occur.280fiE FFICIENT HEX-P ROGRAM E VALUATION BASED U NFOUNDED ETS3.2 Uniform Encoding Unfounded Set Searchencodingpresented previous subsection disadvantage dependscurrent assignment A. Therefore needs generated separately every unfounded setcheck assignment changed (which likely). causes significant overhead,present advanced encoding reused assignment. introduceadditional variables represent truth values atoms current assignment. Priorunfounded set check, current assignment injected setting values variablesfixed values, done using assumptions supported modern SAT solversCLASP. Changing assumptions much easier changing encoding, leadsadditional speedup cases, especially programs need many unfounded set checks.advanced encoding uses set nogoods. before, idea set ordinaryatoms solution represents (potential) unfounded set U wrt. assignment A,.replacement atoms encode truth values corresponding external atoms.U . encoding conceptually complex; initialization computationally(slightly) costly, hence advantages new encoding become visible instancesmany compatible sets (thus many unfounded set checks), might counterproductivesmall instances.nogood set built atoms fresh atoms occurring :hr lr , every rule r , aA every ordinary atom A() (i.e. ordinary atoms.replacement atom auxiliaries), aA.U, aAU , aAU every ordinary atom A()..auxiliary atoms aA , aA.U, aAU , aAU used make encoding usable assignmentA. unfounded set check respect certain assignment, temporarilyadd assumptions solver force certain truth values atoms aA A()depending currentassignment A. Intuitively, aA represents truth value..aA.U .U (where U current unfounded set), aAU represents truecontained U , aAU represents false contained U .end, set assumptions consistent set signed literals. solutionnogood resp. set nogoods satisfies A, A. is, assumptions fix truth valueatoms. Modern ASP SAT solvers support assumptions natively, easilyundone without complete reset reasoner recreating whole problem instance.essential feature efficiently implementing improved encoding.encoding= N, O, ,N, = {{Fa | A()}} aA() Da r (Hr Cr ) necessary part{Fa | A()} encodes search nonempty unfounded set;{FaAU , TaA , Ta}, {TaAU , FaA }, {TaAU , Fa}Da ={FaAU , FaA }, {FaAU , Ta}, {TaAU , TaA , Fa}...{TaA.U, FaA }, {TaA.U, Ta}, {FaA.U, TaA , Fa}encodes aAU true iff aA true, aAU true iff aA false true,.aA.Utrue iff aA true false;Hr = {{Thr } {Fh | h H(r)}} {{Fhr , Th} | h H(r)}encodes hr true rule r iff atom H(r) unfounded set;281fiE ITER , F INK , K RENNWALLNER , R EDL , & CH ULLER{{Thr }{Ta | B + (r)} {Fa | B (r)}Cr =+ (r)} {ta | B (r)}{Fa|BeAU{Th|hH(r)}}AU(i)(ii)(iii)encodes hr true, one (i), (ii) (iii) Definition 5 must hold.specifically, unfounded set U rule r H(r) U 6= (hr true)must happen |= B(r) (Condition (i) fails),. Bo+ (r) |=unfounded set (r) true .U (Condition (ii) fails),h H(r) |= h unfounded set (Condition (iii) fails).Example 10 = {r1 : p &id [p]() } Example 6, constructed nogood set= {{Fp}, {FpAU , TpA , Tp}, {TpAU , FpA }, {TpAU , Fp},., FpA },{FpAU , Fp}, {FpAU , Tp}, {TpAU , TpA , Fp}, {TpA.U..{TpA.U, Tp}, {FpA.U, TpA , Fp},{Thr1 , Fp}, {Fhr1 , Tp}, {Thr1 , Te&id[p] ()A , Te&id[p] (), TpAU }} .Towards computing unfounded sets, observe every unfounded set extended solutionset nogoods A( ). Conversely, solutions include specific extensionsunfounded sets, characterized induced assignments; is, assigning trueatoms U , hr H(r) intersects U , replacement atoms e&g[p] (c).&g[p](c) true .U , appropriate truth values auxiliary atoms accordingintuitive meaning, assigning false atoms A( ). formally, leadsus following assignment:Definition 8 (Induced Assignment Unfounded Set wrt. ) Let U unfounded setprogram wrt. assignment A. assignment induced U wrt. , denoted (U, , , A),(U, , , A) = I0 (U, , A) {Fa | A( ), Ta 6 I0 (U, , A)} ,I0 (U, , A) = {Ta | U } {Thr | r , H(r) U 6= }.{Te&g[p] (c) | &g[p](c) EA(), .U |= &g[p](c)}{TaA | A(), Ta A} {TaA | EA(), |= a}{TaAU | A(), Ta A, U }.{TaA.U| A(), Ta A, 6 U }{TaAU | A(), Fa U } .adopt assignment assumption setAA = {TaA | A(), Ta A} {FaA | A(), Fa A}{TaA | EA(), |= a} {FaA | EA(), 6|= a} ,assignments induced unfounded sets wrt. solutions wrt. AA (butconversely, intuitively latter reflect semantics external sources).before, call set nogoods N conservative, (U, , , A) solution Nevery unfounded set U wrt. A. property, interpretations solutionswhole nogood set comply assumptions A.282fiE FFICIENT HEX-P ROGRAM E VALUATION BASED U NFOUNDED ETSProposition 8 Let U unfounded set program wrt. assignment U 6= .O, conservative, (U, , , A) solution satisfies AA .Corollary 9 solution satisfies AA , U = every unfounded setU (assuming O, conservative).next property allows us find unfounded sets wrt. among solutionssatisfy AA using postcheck external atoms.Theorem 10 Let solution (with conservative O, ) satisfies AA.(a) Te&g[p] (c) 6|= &g[p](c) implies .U |= &g[p](c);.(b) Fe&g[p] (c) |= &g[p](c) implies .U 6|= &g[p](c),U = {a A() | Ta S}. U unfounded set wrt. A., proposition states non-replacement atoms true appearform unfounded set, provided replacement atom e&g[p] (c) truth.value &g[p](c) .U (as Definition 8). Again, check required truthvalue e&g[p] (c) different one &g[p](c) A.Similarly encoding , follows immediately Definition 8 postcheckeliminate unfounded sets, formalized following proposition.Proposition 11 Let U unfounded set program wrt. assignment U 6=. (U, , , A) fulfills Conditions (a) (b) Theorem 10.Example 11 Reconsider program = {r1 : p &id [p]()} Example 6 compatibleset A2 = {Tp, Te&id[p] }. nogood set= {{Fp}, {FpAU , TpA , Tp}, {TpAU , FpA }, {TpAU , Fp},.{FpAU , Fp}, {FpAU , Tp}, {TpAU , TpA , Fp}, {TpA.U, FpA },..{TpA.U, Tp}, {FpA.U, TpA , Fp},{Thr1 , Fp}, {Fhr1 , Tp}, {Thr1 , Te&id[p] ()A , Te&id[p] (), TpAU }}assumptions AA2 = {TpA } solutions {Thr1 , Tp, TpA , Fe&id[p] , TpAU , TpAU ,.FpA.U}, correspond unfounded set U = {p}. Here, Fe&id[p] () represents.A2 .U 6|= &id [p]().see Section 6 encoding superiormany practically relevantprograms. effect becomes especially visible need many unfounded set checks, intuitively case many answer sets exist; reusability encoding beneficial,small programs answer sets, incurred overhead lead savings.4. Optimization Learningsection first discuss refinements optimizations nogood encodings UFSsearch. particular, present nogoods prune irrelevant parts search space;integrated encodingssuitable adjustments. that, proposestrategy learning nogoods detected unfounded sets, avoiding unfounded setgenerated later again.283fiE ITER , F INK , K RENNWALLNER , R EDL , & CH ULLER4.1 Optimizationpresent three optimizations turned effective improving UFS search,second third exclude other, i.e., used simultaneously.4.1.1 R ESTRICTING UFS EARCH ATOMS C OMPATIBLE ETFirst, atoms program relevant unfounded set search: atoms falseignored.Proposition 12 Suppose U unfounded set wrt. interpretation 6|=U . U \ {a} unfounded set wrt. A.nogoods optimization simple. encoding, add conservativeencodingnogood {Ta} A() 6|= optimization part O,conservative nogood {FaA , Ta} A() optimization part O, .4.1.2 AVOIDING G UESSES R EPLACEMENT ATOMSsituations, truth value replacement atom b solutionresp.assumptions AA irrelevant. is, STb = (S \ {Tb, Fb}) {Tb} SFb = (S \{Tb, Fb}) {Fb} solutionsresp. satisfy AA , representunfounded set. set truth value b (arbitrary) fixed value instead inspectingalternatives. next proposition states sufficient criterion irrelevance.Proposition 13 Let b replacement atom, let solutionresp. satisfyingAA . every rule r b B + (r) B (r) |= B(r), either(a) Bo+ (r) |= a, holds Ta S,(b) H(r) |= a, holds Fa S,STb SFb solutionsresp. satisfy AA .property utilized adding conservative nogoods. Recall A(A) A( )contain atoms lr every r . intuitively serve encode solutionresp.assumptions AA whether truth values replacement atoms B(r) relevantset arbitrarily. following nogoods label relevant rules r, forcing lr false iffconditions Proposition 13 holds. encoding, add O, rule r:+LA,r ={{Tlr , Ta} | Bo (r), |= a} {{Tlr , Fa} | H(r), |= a}{{Flr } {Fa | Bo+ (r), |= a} {Ta | H(r), |= a}} .encoding , add O, rule r:L,r ={{Tlr , Ta, TaA } | Bo+ (r)} {{Tlr , Fa, TaA } | H(r)}{{Flr } {FaAU | Bo+ (r)} {TaAU | H(r)}} .constraints exclusively enforce either Tlr Flr . Hence, truth value lr deterministically depends atoms, i.e., nogoods cause additional guessing.Proposition 13 set truth value replacement atom b arbitrarily, lr falser b B + (r) b B (r). However, must ensured changing truth284fiE FFICIENT HEX-P ROGRAM E VALUATION BASED U NFOUNDED ETSvalue replacement atoms harm satisfaction conditions Theorem 6 (resp.Theorem 10).mentioned Theorem 6, beneficial set truth value e&g[p] (c) one&g[p](c) A, reduce number external atoms must checked.Importantly, also relaxes antecedence conditions Theorem 6 (resp. Theorem 10),guarantees harmed. following nogoods enforce coherent interpretationreplacement atoms.encodingadd O, rule r:F,r= {Flr | b B + (r) B (r)} {Fb} | b (r), |= b{Flr | b B + (r) B (r)} {Tb} | b (r), 6|= b ,encoding add O, rule r:F,r = {Flr | b B + (r) B (r)} {TbA , Fb} | b (r){Flr | b B + (r) B (r)} {FbA , Tb} | b (r) .summary, encodingoptimization part O,= r LA,r F,rencoding optimization part O, = r L,r F,r .give example optimization using encoding .Example 12 Consider program = {r1 : p &id [p](); r2 : q &id [q]()}, compatible set = {Tp, Tq, Te&id[p] (), Te&id[q] ()}. necessary part encodingsolutions S1 {Thr1 , Tp, Fe&id[p] (), Fhr2 , Fq, Fe&id[q] ()} S2 {Thr1 , Tp, Fe&id[p] (),Fhr2 , Fq, Te&id[q] ()} (which represent unfounded set U = {p}). Here, optimizaAtion part r2 , LAr2 Fr2 = {{Tlr2 , Fq}, {Flr2 , Tq}, {Flr2 , Te&id[q] ()}}, eliminates solutions S2. beneficial solutions S1 postcheck easier (e&id[q] () S1 &id [q]()truth value A).Note optimization used, rules r atom lr fact neededthus unconstrained. avoid exponential increase number UFS candidates,atoms set fixed value.4.1.3 E XCHANGING N OGOODS B ETWEEN UFS EARCHthird optimization allows exchange learned knowledge external atomsUFS check main search compatible sets. purpose, first define nogoodscorrectly describe input-output relationship external atoms.Definition 9 nogood form N = {Tt1 , . . . , Ttn , Ff1 , . . . , Ffm , e&g[p] (c)},F, valid input-output-relationship, every assignment N \{e&g[p] (c)}holds |= &g[p](c) = F, 6|= &g[p](c) = T.Here, signed literals atoms ti , 1 n, resp. fj , 1 j m, reflect relevant trueresp. false atoms interpretation A, built predicates occur input list p. Techniques learning nogoods described Eiter et al. (2012a) exploit propertiesexternal sources (such monotonicity functionality) restrict size N .Let N nogood valid input-output-relationship learned main search,i.e., compatible sets , let F = = F.285fiE ITER , F INK , K RENNWALLNER , R EDL , & CH ULLERDefinition 10 (Nogood Transformation ) valid input-output relationship N = {Tt1 ,. . . , Ttn , Ff1 , . . . , Ffm , e&g[p] (c)} assignment A, nogood transformation definedFti 1 n,(N, A) = { {Ft1 , . . . , Ftn } {e&g[p] (c)}{Tfi | 1 m, |= fi } }otherwise.next result states (N, A) considered, valid input-output relationships Nassignments A, without losing unfounded sets.Proposition 14 Let N valid input-output relationship, let U unfounded set wrt.contains conservative nogoods, (U, , , A) solution (N, A)A. O,(i.e., also nogoods (N, A) conservative).Hence, valid input-output relationships external atoms learned searchcompatible sets reused (applying transformation) UFS check. Moreover,evaluation external atoms postcheck candidate unfounded sets (i.e., solutions), valid input-output relationships might learned. turn used(further) unfounded set checks (in transformed form) also search compatible sets.Example 13 (Set Partitioning) program Example 4, consider compatible set= {Tdomain(a), Tsel (a), Te&diff [nsel] (a)}. Suppose main search learned inputoutput relationship N = {Tdomain(a), Fnsel (a), Fe&diff [nsel] (a)}. transformed nogood(N,A)={{Fdomain(a), Fe&diff [nsel] (a)}}; intuitively encodes domain(a).unfounded set U , e&diff [nsel] (a) true .U . holds e&diff [nsel] (a)true change truth value domain(a) becomes false.learning technique adopted encoding follows.Definition 11 (Nogood Transformation ) valid input-output relationship N , nogoodtransformation defined..(N ) = {{e&g[p] (c)} {Tt1A , Ft1 , . . . , TtnA , Ftn , Ff1 A.U, . . . , Ffm A.U}} .Compared (N, A), main difference (N ) reusable every assignment, similardefinition unfounded set detection problem .next result states (N ) considered, valid input-output relationships Nassignments A, without losing unfounded sets.Proposition 15 Let N valid input-output relationship, let U unfounded set wrt.A. O, contains conservative nogoods, (U, , , A) solution (N )(i.e., also nogoods (N ) conservative).Hence, also encoding valid input-output relationships external atomslearned search compatible sets reused vice versa.286fiE FFICIENT HEX-P ROGRAM E VALUATION BASED U NFOUNDED ETSExample 14 (contd) Reconsider program Example 4 compatible set ={Tdomain(a), Tsel (a), Te&diff [domain,nsel] (a)}. Suppose main search learned inputoutput relationship N = {Tdomain(a), Fnsel (a), Fe&diff [domain,nsel] (a)}. transformed nogood..(N )={{Tdomain(a)A , Fdomain(a), Fnsel (a)A.U, Fe&diff [domain,nsel] (a)A.U}} ;intuitively encodes domain(a)true assignmentunfounded set U ,..nsel (a) false .U , e&diff [domain,nsel] (a) true .U . holdse&diff [domain,nsel] (a) true change truth value domain(a) gets false.nogood exchange also benefits advanced encoding. previous encoding,needed build SAT instance scratch every unfounded set check. Thus, nogoodslearned main search compatible sets need transformed added UFS detection problem every check (otherwise lost). new encoding , donelearned nogoods kept multiple unfounded set checks. also allows usmake use advanced forgetting heuristics SAT solvers effective.Finally, important note optimizations presented Section 4.1.2 4.1.3used simultaneously (differently optimizations Section 4.1.1 4.1.2 resp. 4.1.14.1.3), result contradictions due (transformed) learned nogoods. thus disabledoptimization avoiding guesses replacement atoms (Section 4.1.2) experiments.4.2 Learning Nogoods Unfounded Setsconsidered merely detecting unfounded sets. strategy learn detectedunfounded sets main search compatible sets missing. next develop strategycall unfounded set learning (UFL).Example 15 Consider program = { p &id [p](); x1 x2 xk }. knowExample 7, U = {p} UFS subprogram 0 = { p &id [p]() } wrt. = {Tp, Te&id ()}.true moreover every A0 A; i.e., p must never true.program Example 15 many compatible sets, half (all p true) failUFS check reason. thus develop strategy generating additional nogoodsguide search compatible sets way unfounded sets reconsidered.present two strategies, focus first one experiments shownfirst one superior instances.4.2.1 UFS-BASED L EARNINGunfounded set U wrt. define set L1 (U, , A) learned nogoods follows.Suppose r1 , . . . , rj rules r H(r) U 6= U Bo+ (r) = , i.e.,set external rules wrt. U (rules directly depend positively U ).L1 (U, , A) = {{0 , 1 , . . . , j } | 0 {Ta | U }, Hi 1 j)} ,Hi = {Th | h H(ri ) \ U, |= h} {Fb | b Bo+ (ri ), 6|= b}. Formally showadding set nogoods correct, i.e., prune answer sets:287fiE ITER , F INK , K RENNWALLNER , R EDL , & CH ULLERProposition 16 U unfounded set wrt. A, every answer set solutionnogoods L1 (U, , A).Example 16 Consider program Example 15 suppose found unfoundedset U = {p} wrt. interpretation = {Tp, Tx1 } {Fxi | 1 < k}. learned nogoodL1 (U, A, ) = {Tp} immediately guides search part search tree p false,i.e., roughly half guesses avoided.4.2.2 R EDUCT-BASED L EARNINGdifferent learning strategy based models f ratherunfounded set U itself,.hinging observation every unfounded set U , .U model f ; henceU 6= refutes minimal model f . noted Faber (2005) aggregates.exploitconstruct nogoods nonempty U wrt. model follows..interpretation .U model f , programs 0 f.A . Hence,assignment A0 falsifies least rules falsifies, A0 (A .U )T , A0answer set . yields following nogood set L2 (U, , A). Suppose r1 , . . . , rnrules r FLP-reduct wrt. (i.e., 6|= B(ri )..L2 (U, , A) = {{Ta | (A .U )T } {0 , 1 , . . . , n }| 0 {Ta | U }, Hi 1 n} ,Hi = {ta | B(r),6|= a}, 1 n. is, nogood consists true-part.smallermodel.Ureduct f , unfounded atom 0 (i.e. true..U ), false body literal (1 n) rule unsatisfied body wrt. A.Example 17 Let = {p &id [p](); q &id [q]()}, &id [a]() evaluates true ifftrue. Suppose = {Tp, Tq}.U = {Tp, Tq} unfounded set wrt. A..construction rule .U = {}, 0 {Tp, Tq} n = 0 (because rule bodiessatisfied wrt. A). learned nogoods L2 (U, , A) = {{Tp}, {Tq}}.Example 17, learned nogoods immediately guide search interpretation{Fp, Fq}, one becomes answer set. Formally, show:Proposition 17 U unfounded set wrt. |= , answer setsolution nogoods L2 (U, , A).However, L2 (U, , A) appeared clearly inferior L1 (U, , A) Section 4.2.1. Informally, nogoods overfit detected unfounded set generalize well ones.5. Deciding Necessity Minimality CheckAlthough minimality check based unfounded sets efficient explicit minimality check, computational costs still high. Moreover, evaluation computingcompatible set A, ASP solver already made unfounded set check, safelyassume founded perspective ASP solver. Hence, remaining unfoundedsets discovered ASP solver must involve external sources, behaviorfully captured ASP solver.288fiE FFICIENT HEX-P ROGRAM E VALUATION BASED U NFOUNDED ETSsection pursue ideas give decision criterion deciding whether UFS check necessary. eventually define class programs needs additionalUFS check. Intuitively, show every unfounded set already detectedconstruction contains input atoms external atoms involved cycles. programinput atom, UFS check superfluous. Afterwards, show apply criterion, holds practically relevant cases, program components; often yields additionalspeedup. However, also cases UFS check skipped; e.g., recursiveURL retrieval web resource (which requires cyclic use external atom).5.1 Basic Decision Criterionstart definition atom dependency.Definition 12 (Atom Dependency) ground program , ground atoms p(c) q(d),say(i) p(c) depends q(d), denoted p(c) q(d), rule r p(c) H(r)q(d) B(r);(ii) p(c) depends externally q(d), denoted p(c) e q(d), rule r external atom&g[q1 , . . . , qn ](e) B + (r)B (r) exist p(c) H(r) q {q1 , . . . , qn }.following, consider dependency graphs GR= (V, E) ground program , whosevertices V ground atoms whose edges E given binary relation R groundatoms (E = R). call p(c) q(d) also ordinary edge p(c) e q(d) e-edge.establish lemma allows us restrict attention core unfounded set,i.e., essential part; disregard atoms cut GR, defined follows.Definition 13 (Cut) Let U unfounded set wrt. A. set atoms C U cut GR,(i) b e/ GR, C b U (C incoming e-edge U ),R(ii) b 6 GRb 6 G , C b U \ C (there ordinary edgesC U \ C).first prove cuts removed unfounded sets resulting set stillunfounded set.Lemma 18 (Unfounded Set Reduction Lemma) Let U unfounded set wrt. completeassignment A, let C cut GR. Then, = U \ C unfounded set wrt. A.Example 18 Consider following program:= {r &id [r]();p &id [r]();p q;q p} .p q, q p, r e r p e r. unfounded set U = {p, q, r}wrt. = {Tp, Tq, Tr}. Observe C = {p, q} cut GR, therefore U \ C = {r}unfounded set wrt. A.289fiE ITER , F INK , K RENNWALLNER , R EDL , & CH ULLERNext prove intuitively, unfounded set U , either input externalatom unfounded itself, U already detected evaluated.Lemma 19 (EA-Input Unfoundedness) Let U unfounded set wrt. assignment A.GRedge x e x, U , U unfounded set wrt. A.Example 19 Reconsider program Example 18. unfounded set U 0 = {p, q}wrt. A0 = {Tp, Tq, Fr} already detected= { e&id[r] () ne &id[r] () ;r e&id[r] ();p e&id[r] ();p q;q p}evaluated ASP solver edges p e q q e p exist. contrast,unfounded set U 00 = {p, q, r} wrt. A00 = {Tp, Tq, Tr} detected ASP solverp, r U 00 p e r.Thus, unfounded sets wrt. recognized evaluationcyclic dependencies input atoms external atom. Programs acyclic dependenciesneed additional UFS checks.Recall cycle wrt. binary relation R sequence C = c0 , c1 , . . . , cn , cn+1 elements,n 0, (ci , ci+1 ) R 0 n c0 = cn+1 . set contains cycle wrt. R,cycle C = c0 , c1 , . . . , cn , cn+1 wrt. R ci 0 n + 1.Informally, next proposition states unfounded set wrt. containscycle input atoms external atom corresponds unfounded setwrt. A, i.e., unfoundedness already detected evaluated.Let = e , inverse (i.e. = {(x, y) | (y, x) }).cycle c0 , c1 , . . . , cn , cn+1 called e-cycle, contains e-edge, i.e., ci e ci+10 n.Theorem 20 (Relevance e-cycles) Let U 6= unfounded set wrt. interpretationcontain e-cycle . nonempty unfounded set wrt. A.Corollary 21 program e-cycle unfounded set wrt. interpretation A, unfounded-free .corollary used increase performance evaluation algorithm follows:cycle containing e-edges, explicit unfounded set check necessary unfounded set check evaluation sufficient. Note testdone efficiently (in fact linear time, similar deciding stratifiability ordinary logicprogram). Moreover, practice one abstract using analogous relationslevel predicate symbols instead atoms. Clearly, e-cycle predicate dependency graph, also e-cycle atom dependency graph. Hence, predicatedependency graph safely used decide whether unfounded set check skipped.Example 20 example programs far need UFS check, program = {out(X)&diff [set 1 , set 2 ](X)}F , diff computes set difference unary predicates set 1 set 2F set facts, needs UFS check e-cycle . Also program= {str (Z) dom(Z), str (X), str (Y ), &concat[X, ](Z)} (where &concat takes twoconstants computes string concatenation) needs UFS check; cycleexternal atom, e-cycle .290fiE FFICIENT HEX-P ROGRAM E VALUATION BASED U NFOUNDED ETSUnfortunately, converse Theorem 20 hold, is, may fail unfoundedfree wrt. unfounded set wrt. contains e-cycle; thus, condition Corollary 21necessary unfounded-freeness wrt. A. However, following generalizationTheorem 20 allows us conclude unfounded-free wrt. A, every unfounded set Uwrt. must contain atom provides input external atom cycle .Definition 14 (Cyclic Input Atoms) program , atom cyclic input atom,edge b e path b exists.Let CA() denote set cyclic input atoms program .Theorem 22 (Unfoundedness Cyclic Input Atom) Let U 6= unfounded set wrt.U CA() = . Then, nonempty unfounded set wrt. A.consequence Theorem 22, add nogood {Fa | CA()}.using predicate symbols instead atoms reduces overhead dependency graph.Example 21 Reconsider Example 18. U = {p, q} unfounded set wrt. ={Tp, Tq, Fr}; U disjoint CA() = {r}, detected evaluation .5.2 Program Decompositionusefulness decision criterion increased decomposing program components, criterion applied componentwise. allows us restrict UFScheck components e-cycles, e-cycle-free components ignored.Let C partitioning ordinary atoms A() subset-maximal strongly connectedcomponents e . define partition C C subprogram C associatedC C = {r | H(r) C 6= }.next show program unfounded set U wrt. A, U C unfounded setwrt. subprogram strongly connected component C.Theorem 23 Let U 6= unfounded set wrt. A. Then, C C holds U Cnonempty unfounded set C wrt. A.Note constraints (i.e., rules empty head) harm proposition. constraintr kind B(r) rewritten p B(r), p new atom p, C = {p} stronglyconnected component C = {r}, contain e-cycle. Thus, rewrittenconstraints according subprograms C ignored anyways.proposition states search unfounded sets done independently subprograms C C C. unfounded set wrt. assignment, alsounfounded set least one program component wrt. assignment. know Corollary 21programs without e-cycles contain unfounded sets already detectedsolved. apply Theorem 23 subprograms C , safely ignore e-cycle-freeprogram components.Example 22 Reconsider program Example 18. C contains components C1 ={p, q} C2 = {r} C1 = {p &id [r ](); p q; q p} C2 = {r&id [r ]()}. Theorem 23, unfounded set wrt. assignment gives rise291fiE ITER , F INK , K RENNWALLNER , R EDL , & CH ULLERunfounded set either C1 C2 . E.g., consider U = {p, q, r} = {Tp, Tq, Tr};U {r} = {r} unfounded set C2 wrt. A. C1 e-cycles, concludeCorollary 21 unfounded sets C1 already detected (resp., C1 ) evaluated.Hence, C2 needs additional UFS check. Indeed, unfounded setdetected evaluated {r}, unfounded wrt. interpretation {Tr}C2 .Finally, show splitting, i.e., component-wise check foundedness, leadspurious unfounded sets.Proposition 24 U unfounded set C wrt. U C, U unfoundedset wrt. A.results generalized subprograms larger strongly connected components; however, leave detailed study future work.6. Implementation Evaluationimplementing technique, integrated CLASP prototype system DLVHEX; useCLASP ASP solver computing compatible sets SAT solver solving nogoodset UFS check.experiments, also use external behavior learning (EBL) developed Eiteret al. (2012a). basic idea learn additional nogoods evaluations external atoms,capture (parts of) behavior external sources. Thus, nogoods eliminate modelcandidates violate known semantics external atoms.Regarding concrete setting, large number combinations EBL techniquespresented paper. Indeed, may either activate deactivate external behavior learninguse either explicit UFS-based minimality check. latter case, useunfounded set learning (UFL), decision criterion skipping unfounded set checkexploited ignored, program decomposition might used not. Moreover, chooseencodings . total, 34 different settings.However, restrict discussion interesting configurations. general,activate developed features stepwise tables efficiency increases leftright. start traditional algorithm based explicit minimality check withoutlearning techniques Eiter et al. (2012a) paper (i.e., conflict-driven learninginside CLASP used). next step add external behavior learning, UFL possible explicit check. switch explicit minimality check UFS-basedcheck without learning without exploiting decision criterion program decomposition.Nevertheless, naive kind UFS-based minimality checking often efficientexplicit minimality check EBL. next step, add decision criterion programdecomposition. following, monolithic (mol) means decision criterionprogram decomposition off, modular (mod) on. Next add EBL UFLUFS-based minimality check, finally switch encoding (including EBL,UFL modular decomposition). However, might skip steps specific benchmarks argue uninteresting respective cases. Detailed instance informationresults combinations parameters available.22. http://www.kr.tuwien.ac.at/research/projects/hexhex/ufs292fiE FFICIENT HEX-P ROGRAM E VALUATION BASED U NFOUNDED ETSBriefly, results show clear improvement, synthetic application instances,UFS check EBL. Moreover, closer analysis shows UFS check decreasescases runtime also number enumerated candidates (UFS resp. modelcandidates FLP reduct) number external atom evaluations.evaluated implementation Linux server two 12-core AMD 6176 SE CPUs128GB RAM running DLVHEX version 2.3.0. evaluated techniques configured usingcommandline arguments. best knowledge, DLVHEX implementationHEX semantics. test run CPU usage limited two CPU cores, running Condorload distribution system ensures robust runtimes (i.e., multiple runs instancenegligible deviations). timeout uniformly set 300 seconds instance;parameter value, average runtime instances printed timeouts, whose numbershown parentheses, fully taken account.6.1 Detailed Benchmark Description Experimental Resultsgive detailed description benchmarks used experiments, presentresults experimental evaluation.6.1.1 ET PARTITIONINGbenchmark extends program Example 4 additional constraintsel (X), sel (Y ), sel (Z), X 6= Y, X 6= Z, 6= Zvaries size domain. results shown Table 1. see big advantageUFS check explicit check, computing answer sets finding first one.closer investigation shows improvement mainly due optimizations Section 4,make UFS check investigate significantly fewer candidates explicit FLP check.Furthermore UFS check requires fewer external computations.explicit UFS-based minimality check benefit EBL computeanswer sets, results show UFS-based check benefits more. contrast, UFL (notshown table) lead speedup unfounded sets found program.decision criterion program decomposition improve runtime slightly small instances. However, large instances decision criterion cannot avoid UFS checkcomponents program cyclic structure. Thus single UFS check wholeprogram replaced multiple UFS checks individual program components, involvesoverhead becomes visible computing answer sets.compute one answer set, EBL turns counter-productive. learning involved additional overhead, cannot profit much learnedknowledge abort first answer set, hence costs exceed benefit.Using encoding instead increases efficiency case,large number answer sets also large number answer set candidates. Thus, reusableencoding beneficial, even compute one answer set.Since evaluation program unfounded sets encountered, obviousadditional unfounded set checks partial interpretations increase overhead benefit;hence discuss respective results.293fidomainE ITER , F INK , K RENNWALLNER , R EDL , & CH ULLERexplicit5 (1)6 (1)7 (1)8 (1)9 (1)10 (1)15 (1)20 (1)25 (1)300.00 (1)300.00 (1)300.00 (1)300.00 (1)300.00 (1)300.00 (1)300.00 (1)300.00 (1)300.00 (1)+EBLanswer setsUFSUFSmolmod+EBLexplicit300.00 (1)0.33 (0)0.32 (0) 0.09 (0)300.00 (1)0.77 (0)0.81 (0) 0.12 (0)300.00 (1)1.73 (0)1.78 (0) 0.20 (0)300.00 (1)4.35 (0)4.17 (0) 0.31 (0)300.00 (1) 10.42 (0) 10.21 (0) 0.47 (0)300.00 (1) 26.31 (0) 25.13 (0) 0.53 (0)300.00 (1) 300.00 (1) 300.00 (1) 2.83 (0)300.00 (1) 300.00 (1) 300.00 (1) 12.98 (0)300.00 (1) 300.00 (1) 300.00 (1) 45.18 (0)0.07 (0)0.10 (0)0.13 (0)0.16 (0)0.23 (0)0.29 (0)0.79 (0)1.95 (0)4.11 (0)54.02 (0)300.00 (1)300.00 (1)300.00 (1)300.00 (1)300.00 (1)300.00 (1)300.00 (1)300.00 (1)first answer set+EBL UFS UFS +EBLmolmod53.80 (0)300.00 (1)300.00 (1)300.00 (1)300.00 (1)300.00 (1)300.00 (1)300.00 (1)300.00 (1)0.05 (0)0.04 (0)0.06 (0)0.07 (0)0.08 (0)0.09 (0)0.19 (0)0.38 (0)0.70 (0)0.05 (0)0.05 (0)0.06 (0)0.06 (0)0.07 (0)0.09 (0)0.15 (0)0.29 (0)0.47 (0)0.05 (0)0.06 (0)0.06 (0)0.07 (0)0.08 (0)0.11 (0)0.27 (0)0.57 (0)1.09 (0)0.05 (0)0.06 (0)0.07 (0)0.07 (0)0.09 (0)0.12 (0)0.26 (0)0.57 (0)1.08 (0)Table 1: Set Partitioning Benchmark ResultsNote results comparable Eiter et al. (2012a), previous workfocused computation subset-minimal compatible sets perform minimalitycheck wrt. reduct, i.e., semantics different.6.1.2 N ONMONOTONIC ULTI -C ONTEXT YSTEMSNonmonotonic Multi-Context-Systems (MCSs) (Brewka & Eiter, 2007) generic formalismaligning knowledge bases called contexts, emerged approach GhidiniGiunchiglia (2001). contexts interlinked via bridge rules enable belief exchangeacross contexts; MCS semantics requires local belief sets compliant bridgerules. compliance impossible achieve; is, MCS inconsistent. understandreasons latter, Eiter et al. (2012b) defined inconsistency explanations (IEs) MCS,computed HEX-program encoding. encoding based Saturation,general technique solving p2 problems disjunctive answer set programming (cf.,Leone et al., 2006). Intuitively, quantified Boolean formula (QBF) form XY(X, Y)evaluated using technique follows. Disjunctions used guess whether variable vtrue false. spoil atom made true whenever evaluates true given truth assignmentsX Y. Finally whenever spoil true, literals set true; creates uniqueassignment respective atoms. Given guess X, unique spoil extension answerset guesses truth assignments make spoil atom true saturate guessbecome unique extensionthis holds due minimality condition answer setsreduct (see Definition 3).use HEX-encoding computing IEs benchmark, saturation rich cycles external atoms disjunctive rule heads. External atoms benchmark evaluatesemantics contexts MCS (i.e., local belief sets models).use random instances different MCS topologies, i.e., connection graphs contexts, created MCS benchmark generator.3 Note topologies structure boundcertain system sizes (number contexts), difficulty instances varies amongtopologies; thus larger instances may shorter runtimes. instances 10 contexts,consisting randomly generated consistent normal answer set program.3. Described http://www.kr.tuwien.ac.at/research/systems/dmcs/experiments.html, online available https://dmcs.svn.sourceforge.net/svnroot/dmcs/dmcs/trunk294fiE FFICIENT HEX-P ROGRAM E VALUATION BASED U NFOUNDED ETS#ctx3 (6)4 (10)5 (8)6 (6)7 (12)8 (5)9 (8)10 (11)explicit+EBLUFSmolUFSmod+EBL+UFL4.78 (0)51.90 (1)149.53 (3)159.41 (3)231.23 (9)244.39 (4)300.00 (8)300.00 (11)3.97 (0)45.91 (1)137.95 (3)154.69 (3)227.45 (9)204.92 (3)278.44 (7)268.78 (9)2.96 (0)48.71 (1)150.80 (3)157.62 (3)234.74 (9)246.42 (4)300.00 (8)300.00 (11)2.97 (0)48.59 (1)150.64 (3)157.72 (3)234.63 (9)246.34 (4)300.00 (8)300.00 (11)1.65 (0)23.48 (0)94.45 (1)151.89 (3)216.75 (8)190.60 (3)264.65 (6)247.16 (8)0.08 (0)0.10 (0)0.10 (0)0.12 (0)0.17 (0)0.17 (0)0.22 (0)0.25 (0)0.08 (0)0.11 (0)0.12 (0)0.15 (0)0.20 (0)0.21 (0)0.24 (0)0.31 (0)Table 2: Consistent MCSs Benchmark Results#ctxexplicit+EBL3.29 (0)41.57 (1)154.55 (5)130.90 (7)166.14 (5)261.96 (5)286.74 (13)300.00 (12)2.70 (0)17.94 (0)148.11 (5)102.57 (6)118.04 (5)143.75 (2)206.10 (9)300.00 (12)#ctxexplicit+EBL3 (9)4 (14)5 (11)6 (18)7 (13)8 (6)9 (14)10 (12)0.09 (0)0.13 (0)0.16 (0)0.18 (0)0.19 (0)0.23 (0)0.32 (0)0.44 (0)0.09 (0)0.14 (0)0.17 (0)0.19 (0)0.17 (0)0.20 (0)0.27 (0)0.33 (0)3 (9)4 (14)5 (11)6 (18)7 (13)8 (6)9 (14)10 (12)answer setsUFSUFSmolmod+EBL+UFL2.34 (0)37.03 (1)153.94 (5)128.12 (7)157.06 (5)263.00 (5)287.32 (12)300.00 (12)1.09 (0)6.05 (0)108.87 (2)87.75 (4)107.50 (4)118.36 (2)189.48 (8)290.18 (11)0.14 (0)2.71 (0)3.65 (0)10.61 (0)84.08 (2)55.86 (1)124.34 (5)290.69 (11)0.14 (0)0.61 (0)1.28 (0)1.55 (0)29.47 (0)51.13 (1)130.56 (6)277.05 (11)first answer setUFSUFSmolmod+EBL+UFL0.08 (0)0.12 (0)0.14 (0)0.15 (0)0.15 (0)0.17 (0)0.22 (0)0.29 (0)0.08 (0)0.11 (0)0.14 (0)0.15 (0)0.15 (0)0.17 (0)0.23 (0)0.29 (0)0.09 (0)0.13 (0)0.16 (0)0.18 (0)0.17 (0)0.19 (0)0.28 (0)0.34 (0)2.44 (0)37.04 (1)154.17 (5)128.26 (7)157.67 (5)262.95 (5)287.10 (12)300.00 (12)0.08 (0)0.11 (0)0.14 (0)0.16 (0)0.17 (0)0.21 (0)0.28 (0)0.39 (0)0.08 (0)0.12 (0)0.14 (0)0.16 (0)0.17 (0)0.20 (0)0.28 (0)0.39 (0)Table 3: Inconsistent MCSs Benchmark Resultsnumber candidates smaller models FLP reduct equals number unfoundedset candidates unfounded set corresponds smaller model. However, stopenumeration soon smaller model respectively unfounded set found, explicitUFS check may consider depending specific program solver heuristics different numbersinterpretations. explains UFS check sometimes slightly slower explicitcheck. However, delay different UFS candidates always smaller, sometimesmakes faster even visits candidates.results consistent inconsistent MCSs shown Table 2 3, respectively,number instances system size given parentheses. Intuitively, consistentinconsistent MCSs dual, candidate explicit resp. UFS check fails (i.e., stopsearly), vs. (or many) candidates check succeeds (stops late). However, mixedresults permit us draw solid conclusions computational relationship evaluation295fiE ITER , F INK , K RENNWALLNER , R EDL , & CH ULLERmethods. Nonetheless, see UFS check based often much fasterexplicit check (up three orders magnitude).consistent MCSs IEs hence answer sets, need distinguishcomputing one answer sets. effects external behavior learning (Eiter et al.,2012a) unfounded set learning clearly evident MCS benchmarks, computing first answer sets. UFS check profits EBL explicit check,adding advantage. activating UFL (which possible explicit check)gain another significant speedup.discuss effects syntactic decision criterion program decomposition. Duesaturation, encoding contains cycles nearly cycles HEX-program containleast one external atom. Therefore, decision criterion reduce set atoms,UFS check needs performed, atoms defined EDB.yield significant efficiency improvements. However, benchmark results MCS instancesconfirm syntactic check cheap hurt performance. 186 instances,total runtime decision criterion program decomposition 11,695 seconds compared11,702 seconds without, number instance timeouts same.use encoding instead , observe another significant speedup computingIEs inconsistent MCSs. usually exist many answer sets (often thousands),thus reusable encoding beneficial. contrast, compute first answer setMCS consistent (no answer set exists), check involved encodingslightly slower; reusability pay abort first answer set.summary, observe encoding leads significant performance gainencoding , decision criterion decomposition help. next benchmarkobserve opposite effects.6.1.3 BSTRACT RGUMENTATIONbenchmark compute ideal set extensions (Dung, Mancarella, & Toni, 2007) randomlygenerated instances abstract argumentation frameworks (AFs) (Dung, 1995) different sizes.problem checking whether given set arguments ideal set AF co-NPcomplete (Dunne, 2009). benchmark use HEX encoding mirrors complexity:guesses set checks ideality using Saturation technique involving external atom(see Appendix A.1).Table 4 shows results different numbers arguments, entry average30 benchmark instances. compare following configurations computingfirst answer set.first column explicit minimality check without learning techniques. secondcolumn shows learning (EBL) leads almost runtime results. explainedstructure encoding, allow effectively reusing learned nogoods.third column, perform UFS-based minimality check using encoding ,without applying decision criterion decomposition. observe alreadysignificant improvements compared explicit minimality check, illustrating effectivenessnew approach. Similar MCS benchmark, number reduct model candidatesequal number UFS candidates cases, UFS check enumeratescandidates faster; explains observed speedup.296fi#argsE FFICIENT HEX-P ROGRAM E VALUATION BASED U NFOUNDED ETS#args1 (30)2 (30)3 (30)4 (30)5 (30)6 (30)7 (30)8 (30)9 (30)10 (30)11 (30)12 (30)13 (30)14 (30)15 (30)16 (30)17 (30)18 (30)19 (30)20 (30)1 (30)2 (30)3 (30)4 (30)5 (30)6 (30)7 (30)8 (30)9 (30)10 (30)11 (30)12 (30)13 (30)14 (30)15 (30)16 (30)17 (30)18 (30)19 (30)20 (30)explicit+EBL0.06 (0)0.08 (0)0.11 (0)0.19 (0)0.32 (0)0.71 (0)1.58 (0)4.75 (0)14.02 (0)41.10 (0)129.35 (1)250.16 (12)294.91 (27)290.01 (29)290.01 (29)300.00 (30)300.00 (30)300.00 (30)300.00 (30)300.00 (30)0.06 (0)0.07 (0)0.10 (0)0.19 (0)0.32 (0)0.72 (0)1.66 (0)5.04 (0)14.97 (0)44.38 (0)139.80 (2)258.82 (17)296.67 (27)290.01 (29)290.01 (29)300.00 (30)300.00 (30)300.00 (30)300.00 (30)300.00 (30)answer setsUFSUFSmolmod0.05 (0)0.06 (0)0.08 (0)0.14 (0)0.26 (0)0.55 (0)1.16 (0)3.06 (0)8.65 (0)24.53 (0)51.39 (0)119.44 (0)274.65 (19)290.00 (29)290.00 (29)300.00 (30)300.00 (30)300.00 (30)280.39 (28)278.20 (27)explicit+EBL0.05 (0)0.07 (0)0.09 (0)0.14 (0)0.22 (0)0.46 (0)0.76 (0)2.34 (0)7.35 (0)19.47 (0)63.39 (1)119.65 (4)197.04 (14)227.27 (22)260.02 (26)230.04 (23)250.03 (25)270.02 (27)230.06 (23)220.07 (22)0.05 (0)0.07 (0)0.09 (0)0.14 (0)0.22 (0)0.47 (0)0.79 (0)2.44 (0)7.82 (0)21.05 (0)67.39 (1)126.18 (4)201.27 (15)227.72 (22)260.02 (26)230.04 (23)250.03 (25)270.02 (27)230.06 (23)220.07 (22)0.05 (0)0.06 (0)0.08 (0)0.12 (0)0.18 (0)0.33 (0)0.52 (0)1.09 (0)1.86 (0)4.73 (0)9.34 (0)12.49 (0)24.26 (0)51.38 (3)79.93 (3)80.10 (4)81.90 (5)127.43 (8)173.16 (13)167.72 (12)first answer setUFSUFSmolmod0.05 (0)0.06 (0)0.08 (0)0.12 (0)0.21 (0)0.42 (0)0.68 (0)1.98 (0)5.76 (0)15.37 (0)26.30 (0)60.88 (0)149.25 (3)218.00 (17)260.01 (26)230.02 (23)250.01 (25)270.01 (27)211.12 (21)200.29 (20)0.05 (0)0.06 (0)0.08 (0)0.10 (0)0.15 (0)0.27 (0)0.37 (0)0.89 (0)1.36 (0)3.54 (0)4.61 (0)6.11 (0)16.34 (0)41.28 (2)40.92 (2)40.63 (3)35.24 (2)74.89 (5)66.58 (4)81.81 (5)+EBL+UFL0.05 (0)0.06 (0)0.08 (0)0.12 (0)0.18 (0)0.33 (0)0.51 (0)1.08 (0)1.84 (0)4.58 (0)9.34 (0)12.38 (0)24.33 (0)51.65 (3)78.00 (3)77.91 (4)77.04 (5)126.57 (8)148.13 (10)167.02 (12)0.05 (0)0.07 (0)0.09 (0)0.13 (0)0.19 (0)0.36 (0)0.56 (0)1.15 (0)1.95 (0)4.79 (0)9.48 (0)12.39 (0)24.44 (0)51.98 (3)78.19 (3)77.95 (4)76.85 (5)125.91 (8)147.62 (10)166.07 (12)+EBL+UFL0.05 (0)0.06 (0)0.07 (0)0.10 (0)0.15 (0)0.27 (0)0.37 (0)0.90 (0)1.28 (0)3.53 (0)4.66 (0)6.11 (0)16.49 (0)41.68 (2)41.38 (2)40.69 (3)35.60 (2)75.47 (5)67.03 (4)82.33 (5)0.05 (0)0.06 (0)0.08 (0)0.12 (0)0.17 (0)0.29 (0)0.40 (0)0.94 (0)1.34 (0)3.68 (0)4.69 (0)6.13 (0)16.50 (0)41.76 (2)41.62 (2)40.84 (3)35.57 (2)75.10 (5)67.04 (4)82.45 (5)Table 4: Argumentation Benchmark Resultsenable decision criterion program decomposition, observespeedup. cycles argumentation instances usually involve small partsoverall program; thus UFS search significantly simplified excluding large program parts. observed program decomposition without decision criterioncounter-productive (not shown table), single UFS search whole programreplaced many UFS searches program components (without decision criterion,check excluded). incurs overhead.297fiE ITER , F INK , K RENNWALLNER , R EDL , & CH ULLERfifth column enable EBL UFL, leads small speedup cases.However, already mentioned above, effective reuse learned nogoods possible.Switching encoding leads small speedup cases, also counterproductive others. programs benchmark usuallycompatible sets, unfounded set checks need performed. Hence lowerinitialization overhead encoding influence runtime dramatically.hand, higher complexity encoding increases runtime small instances.6.1.4 EFAULT R EASONING ESCRIPTION L OGICSprominent instance HEX-programs DL-programs, combine description logic ontologies rules; result using special external atom available DL-pluginDLVHEX . Via DL-programs, obtain encoding terminological default reasoning description logic ontologies approach Baader Hollunder (1995) HEX-programs,defaults require cyclic dependencies external atoms. However, dependenciesinvolve default negated atoms, cycles according Definition 12, respectspositive dependencies. Hence, decision criterion comes conclusion UFS checkrequired.used variants benchmarks presented Eiter et al. (2012a), query winesontology classify red white wines, wine assumed white unlessontology explicitly entails opposite. scenario, decision criterion eliminatesunfounded set checks. However, one compatible set per instance, wouldone unfounded set check anyway, hence speedup due decision criterion significant. effect decision criterion increased slightly modifying scenariomultiple compatible sets. done, instance, nondeterministicdefault classifications, e.g., wine Italian, either French Spanish default.experiments shown small number compatible sets, performance enhancementdue decision criterion marginal, increases larger numbers compatible sets.instance, 243 compatible sets (and thus 243 unfounded set checks) could observe speedup13.59 12.19 seconds.6.1.5 C ONFORMANT P LANNINGclassical AI planning, planning domain contains description actions preconditionseffects world. Finding plan means find sequence actions reaches giveninitial state state fulfilling given goal condition. Conformant planning (Goldman & Boddy, 1996;Smith & Weld, 1998) problem initial state partially specified and/ordomain nondeterministic, executing plan reach goal regardlessaction outcomes actual initial state.experimented simple conformant planning domain: two robots limitedsensor range patrol area, object unknown initial location. goal findsequence movements two robots detect object cases. experiments used encoding realizes conformant planning using Saturation (see above)contains external atom computing whether patrol robots detect object (cf. Appendix A.2).general, deciding existence short (polynomial length bounded) conformant plan p3 298fimap size34 (10)44 (10)54 (10)64 (10)74 (10)84 (10)94 (10)104 (10)114 (10)124 (10)134 (10)144 (10)154 (10)164 (10)plan length34 (10)44 (10)54 (10)64 (10)74 (10)84 (10)94 (10)104 (10)114 (10)124 (10)134 (10)144 (10)154 (10)164 (10)answer setsexplicitUFSmolUFSmod+EBL+UFL-EBL-UFL+EBL+UFL111223344556677.10 (0)10.66 (0)10.69 (0)206.45 (2)258.82 (5)300.00 (10)300.00 (10)300.00 (10)300.00 (10)300.00 (10)300.00 (10)300.00 (10)300.00 (10)300.00 (10)0.12 (0)0.16 (0)0.15 (0)1.98 (0)2.85 (0)36.80 (0)43.20 (0)300.00 (10)299.76 (9)300.00 (10)300.00 (10)300.00 (10)300.00 (10)300.00 (10)0.11 (0)0.15 (0)0.15 (0)1.38 (0)1.79 (0)16.41 (0)19.53 (0)274.53 (5)239.61 (5)300.00 (10)300.00 (10)300.00 (10)300.00 (10)300.00 (10)0.11 (0)0.15 (0)0.14 (0)1.67 (0)2.44 (0)40.94 (0)78.11 (0)300.00 (10)300.00 (10)300.00 (10)300.00 (10)300.00 (10)300.00 (10)300.00 (10)0.12 (0)0.15 (0)0.14 (0)1.69 (0)2.43 (0)40.99 (0)77.10 (0)300.00 (10)300.00 (10)300.00 (10)300.00 (10)300.00 (10)300.00 (10)300.00 (10)0.12 (0)0.15 (0)0.13 (0)1.09 (0)1.50 (0)10.42 (0)13.91 (0)203.70 (2)174.86 (2)300.00 (10)300.00 (10)300.00 (10)300.00 (10)300.00 (10)0.14 (0)0.18 (0)0.15 (0)1.35 (0)1.84 (0)13.88 (0)19.62 (0)252.31 (5)209.41 (3)300.00 (10)300.00 (10)300.00 (10)300.00 (10)300.00 (10)first answer setplan lengthmap sizeE FFICIENT HEX-P ROGRAM E VALUATION BASED U NFOUNDED ETSexplicitUFSmolUFSmod+EBL+UFL-EBL-UFL+EBL+UFL111223344556670.89 (0)1.36 (0)2.23 (0)7.21 (0)17.39 (0)139.26 (1)150.50 (3)255.89 (7)300.00 (10)287.76 (9)300.00 (10)300.00 (10)300.00 (10)300.00 (10)0.05 (0)0.06 (0)0.06 (0)0.22 (0)0.34 (0)6.07 (0)3.24 (0)92.19 (2)97.11 (2)198.75 (5)287.07 (9)300.00 (10)300.00 (10)300.00 (10)0.05 (0)0.05 (0)0.07 (0)0.15 (0)0.22 (0)2.73 (0)1.47 (0)47.58 (0)39.99 (0)143.52 (4)211.97 (5)244.33 (7)300.00 (10)300.00 (10)0.05 (0)0.05 (0)0.06 (0)0.14 (0)0.21 (0)2.73 (0)1.69 (0)82.84 (2)84.08 (1)184.81 (5)277.79 (9)300.00 (10)300.00 (10)300.00 (10)0.05 (0)0.06 (0)0.06 (0)0.14 (0)0.20 (0)2.69 (0)1.70 (0)82.52 (2)83.85 (1)184.78 (5)277.71 (9)300.00 (10)300.00 (10)300.00 (10)0.06 (0)0.06 (0)0.07 (0)0.12 (0)0.17 (0)1.45 (0)0.89 (0)24.23 (0)19.53 (0)131.46 (4)165.64 (4)213.89 (5)285.36 (9)300.00 (10)0.06 (0)0.06 (0)0.07 (0)0.13 (0)0.18 (0)1.78 (0)1.16 (0)31.36 (0)25.85 (0)136.64 (4)185.84 (4)232.85 (6)296.10 (9)300.00 (10)Table 5: Conformant Planning Benchmark Resultscomplete, see Turner (2002), action executability decidable polynomial time, problemp2 ; example domain enjoys property.results displayed Table 5, shows averages 10 instances per size.instances consist n4 grids n {3, . . . , 16}, plan length required finding solutionincreases larger instance sizes. (This number robots increasetwo robots must still cover whole area.) Instances generated randomly placingrobots opposite quarters map.expected observe explicit FLP check performs worst, followed monolithicUFS check encoding, modular UFS encoding; UFS encoding (withoutexternal behavior unfounded set learning) performs best. External behavior learning (EBL)unfounded set learning (UFL) improve performance, contrary increases runtimes significantly modular UFS check slightly check. EBL changetimes significantly explicit check, therefore omit results explicit +EBL.looking profiling information domain found reasons: (a) externalatoms depend large part interpretation (locations robots) EBL cannot cut away299fiE ITER , F INK , K RENNWALLNER , R EDL , & CH ULLERsignificant portions search space; (b) evaluating external atom takes negligible amounttime, beneficial effects EBL outweighed computational overhead. UFLobserved benchmark instances contain unfounded sets (pruning less halfanswer set candidates) thus UFL cannot improve performance given overhead incurs.conclude scenarios, using EBL UFL reduce efficiency.check UFS check encoding constructed once, overhead EBLUFL observed encoding longer big impact. Nevertheless withoutlearning slightly outperforms UFL EBL. analysis number UFS checksnumber external atom evaluations (not shown table) revealed UFL EBL decreases(i) number unfounded set checks needed (ii) number external atoms evaluated (inone 94 instance, 5132 3341). Thus external computations would costly,positive effects UFL EBL would outweigh computational overhead wouldbeneficial activate UFL EBL domain.Interestingly, small map sizes see encoding, 34 instances actuallyseem harder solve larger 44 54 instances. instancesrequire plan length 1 find solution; larger instances constrained smallerinstances robots less freedom move around still detecting objects.Hence, 54 maps solver finds solutions faster 44 maps.conclusion benchmark depending computational task externalatoms, UFL EBL beneficial harmful efficiency reasoning.6.2 Summaryexperiments shown learning technique EBL developed Eiter et al. (2012a)techniques introduced paper lead significant performance improvements cases,exceptions specific benchmarks. effects external behavior learning (EBL)clearly evident explicit minimality check unfounded set-based check,even prominent latter. Independently whether EBL used not, unfounded setchecking pushes efficiency HEX-program evaluation compared explicit minimality checking. Moreover, allows learning additional nogoods, also advantageousbenchmarks. Regarding two problem encodings, benchmarks show UFS checkusually faster encoding encoding, however former UFS checkinvolves initialization overhead, might counterproductive small programs.decision criterion may lead additional speedup introduce notable overhead, thus always activated. Finally, program decomposition often leads additionalperformance gain, used combination decision criterion otherwise single UFS check replaced multiple UFS checks, involves overhead.7. Discussiondiscuss related work outline possible starting points extensions.7.1 Related WorkConstraint answer set solving (Gebser, Ostrowski, & Schaub, 2009) seen special caseHEX-programs. extends ASP dedicated constraint atoms rule bodies (comparisons300fiE FFICIENT HEX-P ROGRAM E VALUATION BASED U NFOUNDED ETSnumeric constraint variables) allow bidirectional exchange informationlogic program constraint solver. constraint solver concrete instanceexternal source, HEX-programs support arbitrary external sources. idea external behaviorlearning (EBL), introduced Eiter et al. (2012a) related work DrescherWalsh (2012) since approaches generate nogoods on-the-fly.Besides grounding, one main differences ASP SAT solving foundedness,i.e., truth atom answer set justified non-circular derivation rulesfacts. account circularity, notion unfounded set introduced van Gelder etal. (1991) defining well-founded semantics logic programs negation, constructingleast fixpoint monotone operator partial assignments; total fixpoints operatorcorrespond stable models logic program. actually allows give characterizationstable models terms unfounded sets. fact, unfounded set checking turnedfruitful model-based approach ASP solving, equally successful syntactic counterpartknown loop formulas (Lin & Zhao, 2004; Lee & Lifschitz, 2003; Lee, 2005). Different kindsunfounded set checks different complexities developed various program classes.computation answer sets model generate test approach, pursuedmany ASP solvers, requires form minimality check unfounded set check carriedalready ordinary logic programs (i.e., absence external atoms). However, normalprogram test tractable frequently realized using source pointers (Simons et al., 2002).Intuitively, reasoner stores atom pointer rule possibly supports atom.list source pointers updated propagation. point supportingrule atom, conclude atom must false.context ASP, notion unfounded set explicitly formulated extended disjunctive logic programs Leone et al. (1997), proved stable modelsdisjunctive logic program models unfounded-free. results basisarchitecture DLV solver, generates answer set candidates checkedunfounded-freeness. test, like answer set checking disjunctive answer set programs,co-NP-complete (Faber, 2005), reduced Koch et al. (2003) unsatisfiability testingSAT instance. approach later extended conflict-driven learning unfoundedset checking Drescher et al. (2008), two instances CLASP solver, ASP instanceSAT instance, used generate check answer set candidates, respectively. parallelwork, technique recently refined exploiting assumptions encodingunfounded set search need adopted current assignment (Gebser, Kaufmann, & Schaub, 2013). related uniform encoding unfounded set search,still restricted disjunctive ASP without external sources. HEX-programs, unfounded setsearch needs respect semantics external atoms thus general problem. Alviano, Calimeri, Faber, Leone, Perri (2011) consider normal logic programs monotoneantimonotone aggregate atoms, defined unfounded sets programs. Based this,extended well-founded semantics Van Gelder et al. (1991), whichalthough closelyrelatedis weaker general FLP semantics (Faber et al., 2011).considered unfounded set checking presence external sources FLPanswer sets, results Drescher et al. (2008) immediately carry over. Indeed,already ground Horn programs, presence nonmonotonic external atoms decidablepolynomial time makes unfoundedness checking intractable (more precisely, co-NP-complete),deciding existence FLP answer set p2 -complete problem ground case.301fiE ITER , F INK , K RENNWALLNER , R EDL , & CH ULLERcomputationally harder external atoms, complexity may increase relative oracleexternal function (see Faber, 2005). However, results paper still applycases.Drescher et al. (2008) employed also splitting technique, goes back work Leoneet al. (1997); related program decomposition, works ASP programs without external sources only. Note notion splitting different well-known splitting setsLifschitz Turner (1994), consider positive dependencies ordinary atoms.consider e-cycles, specific HEX-programs, interest Drescher et al. (2008)head-cycles, may arise disjunctive rule heads. fact, approach may regarded extension one Drescher et al., since evaluation follows principlesperforming UFS checks case head-cycles.evaluation FLP semantics, unfounded set check explicit FLP check instrumental. mention semantics HEX-programs may involve stepintractable general (as follows Leone et al., 2006, already ground Horn programsnonmonotonic external atoms decidable polynomial time). instance, Shen (2011)Shen Wang (2011) present well-justified semantics unfounded set checking essentially replaced fixpoint iteration which, intuitively, tests model candidate reproducesexcludes circular justifications. However, complexity answer set computationdecrease approach general, particular deciding well-justified answer set existence ground Horn programs nonmonotonic external atoms decidable polynomialtime p2 -complete, thus hard deciding existence answer sets Definition 3.7.2 Extensionsdesigned unfounded set check postcondition test; like explicit FLP check,carried complete assignment generated answer set candidate.However, certain cases might obvious partial interpretation (in truth valuesopen) extended answer set, existence unfounded set guaranteedextension complete assignment. One backtrack earlier, intuitively leadssaving certain classes instances.Exploring idea, generalized framework control component decides, based heuristics, unfounded set check carried out; standard setting,whenever assignment model generation complete (i.e., complete assignmentgiven).UFS check partial assignments, sound respect extension completeassignment, possible ASP solver finished unit propagation maximal subsetprogram interpretation already complete it, guessed values externalatom replacements correct. thus used criterion, easy test, greedyheuristics issue UFS checks prototype system.However, contrast initial expectation, found benchmarks UFScheck wrt. partial assignments productive. closer look reveals essentially nogood learning unfounded sets (UFL) effectively avoids reconstructionunfounded set anyway. therefore rarely happens UFS checking wrt. partial interpretationidentifies unfounded set earlier UFS checking wrt. complete interpretations. Therefore,believe UFS checking wrt. partial interpretation rarely identifies unfounded set earlierUFS checking wrt. complete assignments. UFS checking HEX-programs involves evalu302fi#argsE FFICIENT HEX-P ROGRAM E VALUATION BASED U NFOUNDED ETS5 (1)6 (1)7 (1)8 (1)9 (1)10 (1)15 (1)20 (1)25 (1)+EBL+UFLanswer setspartial (periodic) partial (max)+EBL+UFL+EBL+UFL0.07 (0)0.10 (0)0.13 (0)0.18 (0)0.24 (0)0.29 (0)0.80 (0)1.96 (0)4.15 (0)0.09 (0)0.13 (0)0.15 (0)0.20 (0)0.26 (0)0.33 (0)0.96 (0)2.46 (0)5.52 (0)0.11 (0)0.15 (0)0.19 (0)0.26 (0)0.35 (0)0.47 (0)1.61 (0)4.92 (0)11.25 (0)+EBL+UFLfirst answer setpartial (periodic)+EBL+UFLpartial (max)+EBL+UFL0.05 (0)0.06 (0)0.07 (0)0.08 (0)0.09 (0)0.11 (0)0.24 (0)0.51 (0)0.97 (0)0.06 (0)0.07 (0)0.08 (0)0.10 (0)0.12 (0)0.14 (0)0.38 (0)0.97 (0)1.98 (0)0.07 (0)0.09 (0)0.11 (0)0.14 (0)0.17 (0)0.21 (0)0.73 (0)2.30 (0)4.50 (0)#ctxTable 6: Set Partitioning UFS Checking Partial Assignments3 (6)4 (10)5 (8)6 (6)7 (12)8 (5)9 (8)10 (11)+EBL+UFLpartial (periodically)+EBL+UFLpartial (max)+EBL+UFL0.08 (0)0.11 (0)0.12 (0)0.15 (0)0.20 (0)0.21 (0)0.24 (0)0.31 (0)0.09 (0)0.11 (0)0.12 (0)0.15 (0)0.20 (0)0.21 (0)0.24 (0)0.31 (0)0.10 (0)0.12 (0)0.13 (0)0.16 (0)0.21 (0)0.22 (0)0.27 (0)0.32 (0)#ctxTable 7: Consistent MCSs Benchmark Results UFS Checking Partial Assignments3 (9)4 (14)5 (11)6 (18)7 (13)8 (6)9 (14)10 (12)+EBL+UFL0.14 (0)0.61 (0)1.28 (0)1.55 (0)29.47 (0)51.13 (1)130.56 (6)277.05 (11)answer setspartial (periodic) partial (max)+EBL+UFL+EBL+UFL0.13 (0)0.64 (0)1.36 (0)1.67 (0)31.54 (0)51.22 (1)130.99 (6)277.20 (11)0.16 (0)0.88 (0)1.81 (0)2.49 (0)44.90 (1)51.66 (1)133.84 (6)278.21 (11)+EBL+UFLfirst answer setpartial (periodic)+EBL+UFLpartial (max)+EBL+UFL0.09 (0)0.13 (0)0.16 (0)0.18 (0)0.17 (0)0.19 (0)0.28 (0)0.34 (0)0.09 (0)0.13 (0)0.16 (0)0.18 (0)0.17 (0)0.20 (0)0.27 (0)0.35 (0)0.10 (0)0.14 (0)0.17 (0)0.18 (0)0.18 (0)0.21 (0)0.28 (0)0.36 (0)Table 8: Inconsistent MCSs Benchmark Results UFS Checking Partial Assignmentsation external sources compatibility testing, easily leads costs higherpotential savings. detailed analysis requires studies; since results seempromising, leave possible future work.Table 610 show benchmark results UFS checking wrt. partial assignments enabledcomputing first answer set only.first column shows runtime UFS checking wrt. complete interpretations only, usingencoding , EBL UFL (equivalent last column tables Section 6). secondcolumn shows results UFS checking wrt. partial assignments, using heuristicsperforms UFS check periodically (periodic). third column shows runtimes UFScheck always performed, propagation technique derive truth values (max).303fi#argsE ITER , F INK , K RENNWALLNER , R EDL , & CH ULLER1 (30)2 (30)3 (30)4 (30)5 (30)6 (30)7 (30)8 (30)9 (30)10 (30)11 (30)12 (30)13 (30)14 (30)15 (30)16 (30)17 (30)18 (30)19 (30)20 (30)+EBL+UFL0.05 (0)0.07 (0)0.09 (0)0.13 (0)0.19 (0)0.36 (0)0.56 (0)1.15 (0)1.95 (0)4.79 (0)9.48 (0)12.39 (0)24.44 (0)51.98 (3)78.19 (3)77.95 (4)76.85 (5)125.91 (8)147.62 (10)166.07 (12)answer setspartial (periodic) partial (max)+EBL+UFL+EBL+UFL0.05 (0)0.06 (0)0.09 (0)0.14 (0)0.20 (0)0.36 (0)0.56 (0)1.15 (0)1.94 (0)4.80 (0)9.49 (0)12.42 (0)24.45 (0)52.03 (3)78.14 (3)77.99 (4)76.86 (5)126.17 (8)147.51 (10)165.96 (12)0.05 (0)0.07 (0)0.10 (0)0.16 (0)0.22 (0)0.39 (0)0.59 (0)1.19 (0)2.01 (0)4.96 (0)9.71 (0)12.79 (0)25.32 (0)52.57 (3)79.81 (3)79.52 (4)77.82 (5)128.83 (8)149.62 (10)168.53 (12)+EBL+UFLfirst answer setpartial (periodic)+EBL+UFLpartial (max)+EBL+UFL0.05 (0)0.06 (0)0.08 (0)0.12 (0)0.17 (0)0.29 (0)0.40 (0)0.94 (0)1.34 (0)3.68 (0)4.69 (0)6.13 (0)16.50 (0)41.76 (2)41.62 (2)40.84 (3)35.57 (2)75.10 (5)67.04 (4)82.45 (5)0.05 (0)0.07 (0)0.08 (0)0.12 (0)0.16 (0)0.29 (0)0.40 (0)0.94 (0)1.35 (0)3.67 (0)4.71 (0)6.11 (0)16.46 (0)41.80 (3)41.53 (2)40.79 (3)35.53 (2)75.32 (5)66.88 (4)82.27 (5)0.05 (0)0.07 (0)0.09 (0)0.14 (0)0.18 (0)0.31 (0)0.42 (0)0.96 (0)1.39 (0)3.75 (0)4.74 (0)6.23 (0)16.80 (0)41.98 (3)42.02 (2)41.04 (3)35.58 (2)75.37 (5)67.59 (4)82.90 (5)Table 9: Argumentation UFS Checking Partial Assignmentsobserved UFS checking wrt. partial assignments lead speedupcase. Quite contrary, instances significantly higher runtimes frequent unfounded set checks. best visible set partitioning benchmark (Table 6),computing explanations inconsistent MCSs 5, 6 7 contexts (Table 9), computing answer sets conformant planning benchmark (Table 10). set partitioningbenchmark effects especially significant, expected every compatible setunfounded-free. Thus, additional UFS checks always counterproductive. consistentmulti-context systems, reasoning fast anyway, thus frequency UFS checking significant impact (Table 7). argumentation benchmark also observe slight slowdownfrequent UFS checking, although less dramatic benchmarkspropagation methods applicable frequently thus fewer UFS checks performedeven setting max (Table 9).hand, ASP solving (where extra costs incur), UFS checks partialinterpretations may still beneficial, reported Gebser et al. (2013). conclusion, UFSchecks partial assignments HEX-programs require tailored heuristics takestructure program, also domain-specific knowledge account, remainsfuture work.8. ConclusionHEX -programs expressive extension non-monotonic logic programs access externalinformation via external atoms; supported plugin architecture fruitfully deployedrange applications. External atoms however make efficient evaluation HEX-programschallenging task, particular compute answer sets HEX-program ,models subset-minimal models FLP-reduct f (which keeps rules whose304fi#ctxE FFICIENT HEX-P ROGRAM E VALUATION BASED U NFOUNDED ETS34 (10)44 (10)54 (10)64 (10)74 (10)84 (10)94 (10)104 (10)114 (10)124 (10)134 (10)144 (10)154 (10)164 (10)11122334455667answer setspartial (periodic) partial (max)+EBL+UFL+EBL+UFL+EBL+UFLfirst answer setpartial (periodic) partial (max)+EBL+UFL+EBL+UFL+EBL+UFL0.14 (0)0.18 (0)0.15 (0)1.35 (0)1.84 (0)13.88 (0)19.62 (0)252.31 (5)209.41 (3)300.00 (10)300.00 (10)300.00 (10)300.00 (10)300.00 (10)0.06 (0)0.06 (0)0.07 (0)0.13 (0)0.18 (0)1.78 (0)1.16 (0)31.36 (0)25.85 (0)136.64 (4)185.84 (4)232.85 (6)296.10 (9)300.00 (10)0.14 (0)0.17 (0)0.15 (0)1.35 (0)1.83 (0)14.23 (0)19.96 (0)257.18 (5)214.72 (3)300.00 (10)300.00 (10)300.00 (10)300.00 (10)300.00 (10)0.16 (0)0.20 (0)0.18 (0)1.48 (0)2.03 (0)17.27 (0)23.75 (0)289.20 (7)244.84 (5)300.00 (10)300.00 (10)300.00 (10)300.00 (10)300.00 (10)0.06 (0)0.06 (0)0.07 (0)0.13 (0)0.18 (0)1.86 (0)1.18 (0)33.40 (0)27.15 (0)137.22 (4)188.73 (4)235.06 (7)297.42 (9)300.00 (10)0.08 (0)0.08 (0)0.09 (0)0.15 (0)0.21 (0)2.36 (0)1.42 (0)49.36 (0)37.64 (0)142.74 (4)209.44 (4)243.73 (7)300.00 (10)300.00 (10)Table 10: Conformant Planning UFS Checking Partial Assignmentsbodies satisfied). improve expensive test (which customary implementationsfar), presented alternative test based unfounded sets obtain adaptingnotion unfounded set aggregates Faber (2005) external atoms. Also Alviano et al. (2011)use related notion unfounded sets programs aggregates, restrict discussionmonotonic antimonotonic aggregates. realized unfounded set (UFS) checkingtransformation SAT solving, satisfying assignments constructed CNF generatecandidate unfounded sets, turn subject (rather simple) postcheck takes externalatom evaluation account.particular, provided two SAT encodings UFS checking: conceptually simpleencoding, needs initialization every UFS check, advanced encoding ,reused UFS checks. boost performance, shown learnunfounded sets deriving nogoods, i.e., constraints (possibly involving also external atoms)guide future search model generation help avoid unfounded sets regenerated.elaboration, refined basic approach suitable program splitting,UFS check carried independently program components, cutting complexity.Furthermore, presented syntactic criterion allows us decide efficiently whetherUFS check safely skipped component whole program, exploiting answerset candidates model search special unfounded sets involve cyclic inputexternal atoms; HEX-programs simple applications, usually case.experimental evaluation new approach, considered different combinationstechniques comprised problems various domains including multi-context systems,abstract argumentation, default reasoning ontologies, conformant planning, HEXprograms serve easy-cut declarative problem solving, shown efficienttraditional minimal model check; lead exponential gains yields often drastic performance improvements, slower (except cases marginal amount).Furthermore, reusable encoding turned beneficial programs require manyunfounded set checks, includes programs many answer sets.305fiE ITER , F INK , K RENNWALLNER , R EDL , & CH ULLER8.1 Future workissue improvement approach paper heuristics UFS checking partial assignments. natural heuristics considered counterproductive,others might lead additional speedup cases. However, may require incorporatedomain-specific knowledge external atoms; currently done learning algorithms heuristics. line, one might consider developing heuristicsdynamically choosing UFS search encodings presented, study heuristicsguiding unfounded set search, i.e., variable selection SAT solver. Currently,implementation applies heuristics unfounded set search model generation process. However, experimental comparison explicit minimality check termsconsidered candidate sets suggests room improvement employing suitablechoices. Developing appropriate heuristics validating effectiveness candidate set enumeration remains explored. Finally, obvious issue criteria allow skipUFS check simplify efficiently tested.AcknowledgmentsPreliminary results work presented 13th European Conference LogicsArtificial Intelligence (JELIA 2012), September 26-28, 2012, Toulouse, France (Eiter, Fink, Krennwallner, Redl, & Schuller, 2012c), 5th Workshop Answer Set ProgrammingComputing Paradigms (ASPOCP 2012), September 4, 2012, Budapest, Hungary (Eiter, Fink, Krennwallner, Redl, & Schuller, 2012b). grateful anonymous reviewers helpfulconstructive comments. work supported Austrian Science Fund (FWF) viaprojects P20840, P20841, P24090, Vienna Science Technology Fund (WWTF)project ICT08-020. Peter Schuller supported TUBITAK Fellowship 2216.Appendix A. Benchmark Encodingsappendix, give details benchmark encodings (those described references). note encodings developed tunedgood performance serve merely experimental comparison various FLP check realizations. Benchmark encodings HEX-plugins publicly available https://github.com/hexhex/benchmarks.A.1 Abstract ArgumentationAbstract Argumentation benchmark results Section 6.1 obtained using followingencoding, derived encodings admissible preferred set extensions argumentation framework (A, att) described Egly, Gaggl, Woltran (2010).Input instances benchmark defined set arguments encoded facts arg(a)set att attacks arguments, encoded facts att(a, b)(a, b) A. encoding consists following rules x, y, z A; similarencodings explained detail Egly et al. (2010) (but without use external atoms).define defeat attacks.defeat(x, y) att(x, y).306fiE FFICIENT HEX-P ROGRAM E VALUATION BASED U NFOUNDED ETSguess set using predicates inS outS .inS (x) outS (x), arg(x).outS (x) inS (x), arg(x).require arguments conflict-free defended S.inS (x), inS (y), defeat(x, y).defeated (x) inS (y), defeat(y, x).notDefended (x) defeat(y, x), defeated (y).inS (x), notDefended (x).saturation define linear order arguments, including infimum supremum.lt(x, y) arg(x), arg(y).(x < y)nsucc(x, z) lt(x, y), lt(y, z).succ(x, y) lt(x, y), nsucc(x, y).ninf (x) lt(y, x).nsup(x) lt(x, y).inf (x) ninf (x), arg(x).sup(x) nsup(x), arg(x).perform guess set using disjunction.inT (x) outT (x) arg(x).check argument whether spoil answer set .sInT upto (y) inf (y), inS (y), inT (y).sInT upto (y) inf (y), outS (y).sInT upto (y) succ(z, y), inS (y), inT (y), sInT upto (z).sInT upto (y) succ(z, y), outS (y), sInT upto (z).sInT sup(y), sInT upto (y).spoil sInT .also spoil answer set preferred extension, determined external atomsemantic function f&argSemExt f&argSemExt (A, pref , arg, att, inT , unused , spoil ) =1 iff Fspoil extension predicate inT preferred set extension argumentationframework specified extension predicates arg att. Internally, external atom usesanother ASP program compute semantics. check performed using ASP encodingpreferred extensions Egly et al. (2010).tIsNotPref &argSemExt[pref , arg, att, inT , unused , spoil ]().spoil tIsNotPref .Note parameters pref unused support general functionalities f&argSemExtrelevant benchmark. create unique answer set whenever spoil truerequire spoiled answer sets returned.inT (x) spoil , arg(x).sInT spoil .outT (x) spoil , arg(x).tIsNotPref spoil .spoil .Given instance encoded above, answer set program exists iff existsideal set extension given argumentation framework.307fiE ITER , F INK , K RENNWALLNER , R EDL , & CH ULLERA.2 Conformant PlanningConformant Planning benchmark results Section 6.1 obtained using following encoding.Input instances benchmark defined set R robots, sets X valid xcoordinates environment, maximum plan length l; instance contains robotr R initial position (x, y) facts robo X (r, x, 0) robo (r, y, 0). encoding consistsfollowing rules where, unless stated otherwise, 0 < l, r R, x X, .robot generate four possible moves environment.move(r, x, + 1, t) move(r, x, + 1, t) robo X (r, x, t), robo (r, y, t).(y + 1 )move(r, x + 1, y, t) move(r, x + 1, y, t) robo X (r, x, t), robo (r, y, t).(x + 1 X)move(r, x, 1, t) move(r, x, 1, t) robo X (r, x, t), robo (r, y, t).(y 1 )move(r, x 1, y, t) move(r, x 1, y, t) robo X (r, x, t), robo (r, y, t).(x 1 X)disallow moving multiple locations standing still (the latter strictly necessaryobtained experimental results way).move(r, x1 , y1 , t), move(r, x1 , y2 , t).(x1 , x2 X, x1 < x2 , y1 , y2 )move(r, x, y1 , t), move(r, x, y2 , t).(y1 , y2 Y, y1 < y2 )move (r, t) move(r, x, y, t).move (r, t).effect moving deterministic change location.robo X (r, x, + 1) move(r, x, y, t).robo (r, y, + 1) move(r, x, y, t).saturation guess position object.obj X (x) obj X (x) .obj X (y) obj (y) .spoil answer set object multiple locations.spoil obj X (x1 ), obj X (x2 ).(x1 , x2 X, x1 < x2 )spoil obj (y1 ), obj (y2 ).(y1 , y2 Y, y1 < y2 )spoil answer set object location.objectHasNoXUpTo(1) obj X (1).objectHasNoXUpTo(x) objectHasNoXUpTo(x 1), obj X (x).spoil objectHasNoXUpTo(xmax ).objectHasNoYUpTo(1) obj (1).objectHasNoYUpTo(y) objectHasNoYUpTo(y 1), obj (y).spoil objectHasNoYUpTo(ymax ).(x 1 X)(xmax = max(X))(y 1 )(ymax = max(Y ))spoil answer set object sensed, determined external atomsemantic function f&sense f&sense (A, robo X , robo , obj X , obj , range, spoil ) = 1 iff308fiE FFICIENT HEX-P ROGRAM E VALUATION BASED U NFOUNDED ETSTspoil predicates robo X , robo , obj X , obj represent state robotdistance less range object, i.e., robot detect object. Theqimplementationexternal atom realized C++ consists verifying range2x + 2ybookkeeping code extract x A.spoil &sense[robo X , robo , obj X , obj , range, spoil ]().create unique answer set whenever spoil true require spoiled answer setsreturned.obj X (x) spoil .obj X (x) spoil .objectHasNoXUpTo(x) spoil .objectHasNoYUpTo(y) spoil .obj (x) spoil .obj (x) spoil .spoil .Given instance encoded above, answer set program exists iff existssequence movements ensures detect object matter located. Furthermoremovements required detect object, i.e., conformant plan, encoded answer setextension move predicate.Appendix B. ProofsProof Proposition 1. () Let A0 answer set Check (, A) f&g (A0 , p, c) = 1iff Te&g[p] (c) A0 external atoms &g[p](c) .Since compatible set , f&g (A, p, c) = 1 iff Te&g[p] (c) external atoms&g[p](c) . Thus, f f replacement atoms place external atoms,additional guessing rules replacement atoms. Since A0 model Check (, A)also model f . Let A00 = {Ta A0 | A()} {Fa A0 | A()}. Sincef&g (A0 , p, c) = 1 iff Te&g[p] (c) A0 external atoms &g[p](c) assumption, A00model f .Since A0 answer set Check (, A), Check (, A) A()Ta 6 (and thus Ta 6 A), {Ta A00 | A()} A. Finally, due { smaller }{smaller | A(), Ta A} Check (, A), least one A()s.t. Ta (and thus also Ta A), Fa A0 (and thus also Fa A00 ). Therefore{Ta A00 | A()} ( model , thus answer set .() answer set , model A00 f smallerpositive part, i.e., {Ta A00 } ( {Ta A}. LetA0 = (, A00 ) {Ta0 | Ta A, Fa A00 } {Fa0 | Ta A, Ta A00 } {Tsmaller }.show A0 answer set Check (, A) f&g (A0 , p, c) = 1 iff Te&g[p] (c) A0external atoms &g[p](c) .Since extracted compatible set , f freplacement atoms place external atoms, additional guessing rules replacementatoms. Since A00 model f , truth values replacement atoms A0 coincide309fiE ITER , F INK , K RENNWALLNER , R EDL , & CH ULLERoracle functions definition (, A00 ), set exactly one ea neexternal atom true (and thus satisfy guessing rules replacement atoms), A0model f . Since {Ta A00 } ( {Ta A} thus also {Ta A0 | A()} ( {Ta| A()}, corresponding constraint Check (, A) violated. Moreover,Ta either Ta A0 Ta0 A0 , thus corresponding rule a0Check (, A) satisfied. Finally, since Tsmaller A0 , rules {smaller |A(), Ta A} satisfied constraint smaller fire. Thus A0 modelCheck (, A).0show A0 also subset-minimal model f Check (, A)A . Observe0f Check (, A)A = f {a a0 | Ta A}{smaller | A(), Ta A}.0However, atom A(f Check (, A)A ) Ta A0 changed false, interpretation model anymore corresponding rule a0 violated, onea0 true A0 definition; thus interpretation smaller positive part A00model f Check (, A)A . Hence A0 answer set Check (, A).Finally, f&g (A0 , p, c) = 1 iff Te&g[p] (c) A0 external atoms &g[p](c) definition (, A00 ).2Proof Proposition 2. result follows Proposition 1 fact programsCheck (, A) CheckOptimized (, A) answer sets. Indeed, constructionprograms models; consequently, every answer set A0 Check (, A) (which0model Check (, A)) model f CheckOptimized (, A)A . A0 minimal model0f Check (, A)A , due guessing rules a0 , Ta A, ea ne ,external atoms Check (, A), either {Ta, Fa0 } A0 {Fa, Ta0 } A0 (butboth) either {Tea , Fne } A0 {Fea , Tne } A0 (but both); furthermore, dueconstraints every A() Ta/ A, Fa A0 a.guessing rules constraints also CheckOptimized (, A), every model A000CheckOptimized (, A)A A00 CheckOptimized(,A) A0 atoms a, a0 , ea , nemust thus value A0 ; consequently, also smaller must value0A0 . follows A0 minimal model f CheckOptimized (, A)A , i.e., A0 answer setCheckOptimized (, A). argument every answer set CheckOptimized (, A)answer set Check (, A) analogous.2Proof Theorem 3. argument proves Corollary 3 Faber (2005) used mutatismutandi prove statement, external atoms place aggregates.2Proof Proposition 4. proceed contraposition show (U,, , A)solution , U cannot unfounded set U 6= .First observe nogoods Hr,A demand Thr true rule r solutionhead atom h H(r) rule U . truth values hrh H(r) defined (U,, , A) exactly criterion, nogood Hr,Aviolatedinvolved contradiction. Furthermore, nogood {Fa | Ta A} N,(U,, , A) U = ; hence, (U, , , A) solution310fiE FFICIENT HEX-P ROGRAM E VALUATION BASED U NFOUNDED ETSconservative, rule r nogood CU 6= , O,r,A mustviolated. is, know following: Thr (U,,,A)(andthereforeH(r)U 6= ),+Fa (U, , , A) Bo (r), ta (U, , , A) (r), Th(U,, , A) h H(r) |= h. Moreover, Cr,A 6= . showimplies none conditions (i)(iii) Definition 5 holds r wrt. U A,means U unfounded set.Condition (i) hold r |= B(r) (otherwise Cr,A = ).Condition (ii)hold r. Suppose contrary holds. must.b B(r) s.t. .U 6|= b. Cr,A 6= , know |= b. make casedistinction type b:b positive defaultliteral A(), Fb (U,, , A) therefore b 6 U ..Consequently .U |= b. Contradiction..b negative default literal A() , |= b implies .U |= b. Contradiction.b positive default-negated replacement atom,tb (U,, , A)..implies, definition (U, , , A), .U |= b. Contradiction.Condition (iii) hold r Th (U,, , A) thus, definition(U,,,A),hUhH(r)|=h.Thus6|= H(r) \ U .2Proof Theorem 6. Suppose U unfounded set. r s.t. H(r)U 6=none conditions (i)(iii) Definition 5 satisfied. show cannotsolutionsatisfies conditions (a) (b), proves result.Condition (i) hold, nogood form{{Thr } {Fa | Bo+ (r), |= a} {ta | (r)} {Th | h H(r), |= h}}.show contains signed literals nogood, i.e., nogood violatedassignment S.Since H(r) U 6= , Thr (otherwise nogood HrA violated). Uunfounded set, Condition (ii) .in Definition 5 hold. Consider Bo+ (r) s.t. |= a.6 U , otherwise .U 6|= contradiction assumptionCondition (ii) unsatisfied. Fa (because complete would imply Uotherwise)..consider &g[p](c) EA(r). .U |= &g[p](c) (as (ii) violated).6|= &g[p](c), Condition (i) would satisfied, hence |= &g[p](c). Te&g[p] (c).S, otherwise .U 6|= &g[p](c)precondition (b) proposition. Next consider.&g[p](c) (r). .U 6|= &g[p](c) (as (ii) violated). |= &g[p](c),Condition (i) would satisfied, hence 6|= &g[p](c). Fe&g[p] (c) S, otherwise..U |= &g[p](c) precondition (a) proposition. Therefore, ta(r).Finally, Condition (iii) Definition 5 hold, h U therefore also Thh H(r) |= a.concludes proof cannot solutionsatisfying (a) (b), Uunfounded set.2Proof Proposition 7. Let = (U,&g[y](x), , A). external atom.Te&g[y] (x) S, definition (U,,,A).U |= &g[y](x)311fiE ITER , F INK , K RENNWALLNER , R EDL , & CH ULLER(satisfying (a)). external atom &g[y](x) Fe&g[y] (x) S, definition.(U,2, , A) .U 6|= &g[y](x) (satisfying (b)).Proof Proposition 8. proceed contraposition show (U, , , A)solution assumptions AA , U cannot unfounded set U 6= .First observe nogoods Hr demand Thr true rule rhead atom h H(r) rule U . Moreover, nogoods DaA() force..aA.U true Ta/ U , equivalent Ta .U ; aAUtrue Ta U ; aAU true Fa U ..truth values hr r , aA.UaAU aAU A()(U, , , A) defined exactly conditions, contradiction must involve Crr . Furthermore, nogood {Fa | A()} violated (U, , , A)A() U = , thus U 6= ; hence, (U, , , A) solutionU 6= , since O, conservative, rule r nogood Cr must violated.is, know following:(I) Thr (U, , , A) (and therefore H(r) U 6= ),(II) TaA (U, , , A) B + (r) FaA (U, , , A) B (r),(III) FaAU (U, , , A) Bo+ (r), ta (U, , , A) (r),(IV) ThAU (U, , , A) h H(r).show implies none conditions Definition 5 holds r wrt. UA, means U unfounded set (hr true (U, , , A), impliesH(r) U 6= x).Condition (i) hold r (II), assumptions AA implies |=B(r). Condition (ii) does. hold r. Suppose contrary holds. mustb B(r) s.t. .U 6|= b. Since Condition (i) already known violated,assume |= b. make case distinction type b:.b positive default literal A() , b U (otherwise .U |= b).definition (U, , , A) TbAU (U, , , A), contradicts(III)..b negative default literal A() , |= b implies .U |= b. Contradiction.b positive default-negated replacement atom,tb (U, , , A)..implies, definition (U, , , A), .U |= b. Contradiction.Condition (iii) hold r ThAU (U, , , A) thus, definition(U, , , A), h U h H(r) |= h. Thus 6|= H(r) \ U . 2Proof Theorem 10. Suppose U unfounded set. r existsH(r) U 6= none conditions (i)(iii) Definition 5 satisfied. show S,assuming AA satisfied (a) (b) hold, cannot solution .Due rule r, (more specifically, N, ) contains nogood N formN = { {Thr }{TaA | B + (r)} {FaA | B (r)}{FaAU | Bo+ (r)} {ta | (r)}{ThAU | h H(r)} }.312fiE FFICIENT HEX-P ROGRAM E VALUATION BASED U NFOUNDED ETSshow contains signed literals N , i.e., N violated S. H(r) U 6= ,Thr (otherwise nogood Hr violated). Furthermore, U unfounded set,Condition (i) Definition 5 hold U wrt. A, hence |= B(r). assumptionsAA thus enforce TaA B + (r) FaA B (r).Consider next arbitrary Bo+ (r). Condition (ii) Definition 5 hold Uwrt. A, |= 6 U ; latter implies definition U Fa S.nogood {TaAU , Fa} conclude FaAU S.nextshow every (r), holds ta S. Indeed, let &g[p](c) EA(r)...U |= &g[p](c) (as Condition (ii) violated). Furthermore, |= &g[p](c), 6|=&g[p](c) would imply Condition (i) satisfied. Thus Condition (b)hypothesis,.follows Te&g[p] (c) S. Similarly, let &g[p](c) (r). .U 6|= &g[p](c) (asCondition (ii) violated) 6|= &g[p](c) |= &g[p](c) would satisfy Condition (i). ThusCondition (a) hypothesis, follows Fe&g[p] (c) S. Thus ta(r).Finally, Condition (iii) Definition 5 hold U wrt. A, h Utherefore also Th h H(r) |= a. is, h H(r), either FhATh S. nogoods {FhAU , FhA }, {FhAU , Th} Dh , casesThAU S.Hence, N holds, i.e., N violated S, thus solution . completesproof result.2Proof Proposition 11. Let = (U, , , A). external atom&g[y](x).Te&g[y] (x) S, definition (U, , , A) .U |= &g[y](x)(satisfying (a)). external atom &g[y](x) Fe&g[y] (x) S, definition.2(U,, , A) .U 6|= &g[y](x) (satisfying (b)).Proof Proposition 12. show U \ {a} unfounded set wrt. A, consider rH(r) (U \ {a}) 6= . show one conditions (i)(iii) Definition 5holds r. hypothesis, U unfounded set wrt. A, H(r) (U \ {a}) 6= impliesH(r)U 6= . Condition (i) holds U , also holds wrt. U \{a} condition depends.r A. AlsoCondition (ii) holds U , also holds wrt. U \ {a} .U.equivalent .(U \ {a}) since 6|= a. Finally, Condition (iii) holds U ,atom b H(r) \ U exists |= b. 6|= a, follows 6= b hence condition (iii)holds U \ {a}. proves result.2Proof Proposition 13. Suppose changing truth value b turns solutioncounterexample Sb(resp. ). is, Sb must violate nogood N resp.(N ) containing b, i.e., either Tb N Fb N .+encoding, nogood N corresponds rule b B (r) b B (r)+|= B(r), N contains also signed literals (1) Fa Bo |= (2) TaH(r) |= a. hypothesis, either (a) Ta Bo+ (r)|= a, (b) Fa H(r) |= a. nogood cannot violated,(a) contradicts one (1) (b) contradicts one (2).encoding , nogood N corresponds rule r b B + (r) b B (r).nogood contains also signed literals (1) TaA B + (r) FaA B (r), (2)FaAU Bo+ , (3) ThAU h H(r). (1) since solution313fiE ITER , F INK , K RENNWALLNER , R EDL , & CH ULLERAA , |= B(r). hypothesis, either (a) Ta Bo+ (r)|= a, (b) Fa H(r) |= a. nogood N cannotviolated, (a) contradicts part (2) definition AA aAU , (b) contradicts part (3)definition AA hAU .2Proof Proposition 14.(N, A) = proposition trivially holds. Otherwise(N, A) = {C} know Tti 1 n. Suppose C violated(U,, , A). Fti (U, , , A) therefore ti 6 U 1 n,Tfi (U, , , A) 1 |= fi , e&g[p] (c) (U,, , A)....U |= ti 1 n .U 6|= fi 1 . m.nogood N valid input-output-relationship, implies &g[p](c) .U . definition(U,, , A), e&g[p] (c) (U, , , A), contradicts assumption(N, A) violated.2Proof Proposition 15. know (N ) = {C}. Suppose (U, , , A) violates C.TtiA (U, , , A) therefore Tti Fti (U, , , A) 1 n;.Ffi A.U(U, , , A) therefore either Ffi fi U , 1 m;e&g[p] (c) I(U, , A).then, definition (U, , , A), Ttiti 6 U 1 n, hence...U |= ti 1 n. Moreover, .U 6|= fi 1m..nogood N valid input-output-relationship, implies &g[p](c) .U .hand, definition (U, , , A), e&g[p] (c) (U, , , A); contradictsassumption nogood C violated.2Proof Proposition 16. Suppose answer set A0 exists solutionL1 (U, , A), i.e., violates nogood N = {0 , 1 , . . . , n } L1 (U, , A). showcase U unfounded set wrt. A0 U A0 6= ; means A0not-unfounded-free, contradicts A0 answer set .Let r rule H(r) U 6= . show one conditions (i)(iii)Definition 5 holds.Bo+ (r) U 6= , Condition (ii) holds. Hence assume following Bo+ (r)U = , means r external rule wrt. U . N1 n either (1) = Th h H(r) h 6 U |= h, (2) = Fbb Bo+ (r) 6|= b. Since A0 violates N assumption, A0 . Case (1)Condition (iii) satisfied, Case (2) Condition (i) satisfied.Moreover, definition L1 U exists Ta A0 , i.e., A0 intersects U .proves result.2Proof Proposition 17. Towards contradiction,suppose answer set A0.solution L2 (U, , A). Let N = {Ta | .U } {0 , 1 , . . . , n } L2 (U, , A)violated nogood. A0 1 n, know A0 falsifies (at least) bodies0rules falsified A; consequently,f f . |=hypothesis..; hence, also .U |= f A0 .U unfounded set follows.U|=f..Moreover, Ta A0 all. .U , therefore A0T (A .U )T . 0 A0 ,0conclude A0T ) (A .U )T , i.e., A0 subset-minimal model . Consequently,A0 answer set , contradiction.2314fiE FFICIENT HEX-P ROGRAM E VALUATION BASED U NFOUNDED ETSProof Lemma 18. = , result holds trivially. Otherwise, let rH(r) 6= . show one conditions (i)(iii) Definition 5 holds. ObserveH(r) U 6= U . Since U unfounded set wrt. A, either(i) 6|= b b B(r);.(ii) .U 6|= b b B(r);(iii) |= h h H(r) \ U .Case (i), the. condition also holds wrt. . case (ii), let H(r) , b B(r).U 6|= b. make case distinction: either b ordinary literal externalone..b ordinary default-negatedatomc,.U 6|= b implies Tc c 6 U ,.therefore also .Y 6|= b. assume b ordinary atom. b 6 U 6|= bCase (i) applies, assume b U . H(r) b B(r), b thereforeeither a, b C a, b (becauseordinary edges C )..assumption , therefore b , hence .Y 6|= b.b external literal, q U e q q 6 . Otherwise, wouldimply q C C would incoming e-edge, contradicts assumption Ccut .of GRq , therefore truth value b. Hence,. q U e q, also..U .Y same. Hence .Y 6|= b.Case (iii), also |= h h H(r) \ U therefore H(r) \H(r) \ U .2Proof Lemma 19. U = , result holds trivially. Otherwise, suppose rH(r) U . Observe r cannot external atom guessing rule U containsordinary atoms. show one conditions Definition 5 holds r wrt. A.r external atom guessing rule, corresponding rule r containingexternal atoms place replacement atoms. U unfounded set H(r) =H(r), either:(i) 6|= b b B(r);.(ii) .U 6|= b b B(r);(iii) |= h h H(r) \ UCase (i), let b B(r) 6|= b b corresponding literal B(b) (whichb ordinary corresponding replacement literal b external). also 6|= bcompatible.Case (ii), make case distinction:. either b ordinary external.b ordinary, b B(r) .U 6|= b holds equivalentordinary atoms.b external atom default-negated external atom, atom p(c) U inputit, i.e., p predicate input parameter b; otherwisee p(c), contradicting.assumption Uinternal e-edges. .U implies 6|= b truth.value b .U same. Therefore apply Case (i).315fiE ITER , F INK , K RENNWALLNER , R EDL , & CH ULLERCase (iii), also |= h h H(r) \ U H(r) = H(r) contains ordinaryatoms equivalent ordinary atoms.2Proof Theorem 20. define reachable set R(a) atomR(a) = {b | (a, b) { } },i.e., set atoms b U reachable using edges e-edges.first assume U contains least one e-edge, i.e., x, U x e y.show u U outgoing e-edge (i.e., u e v v U ),R(u) incoming e-edges U (i.e., v R(u) b U , b 6e v holds).Suppose contrary outgoing e-edges, reachable set R(a) incominge-edge U . construct e-cycle , contradicts assumption. Startarbitrary node c0 U outgoing e-edge, let p0 (possibly empty) path(under ) c0 node d0 R(c0 ) d0 incoming e-edge, i.e.,c1 c1 e d0 ; note c1 6 R(c0 ).4 assumption, also node d1 R(c1 )incoming e-edge (from node c2 6 R(c1 )). Let p1 path c1 d1 , etc. iterationconstruct concatenation paths p0 , (d0 , c1 ), p1 , (d1 , c2 ), p2 , . . . , pi , (di , ci+1 ), . . .,pi ci di paths within reachable sets, (di , ci+1 ) e-edgesreachable sets. However, U finite nodes path must equal, i.e.,subsequence constructed sequence represents e-cycle (in reverse order).proves u node outgoing e-edge R(u) incoming e-edges.next show R(u) cut GR. Condition (i) immediately satisfied definition u.Condition (ii) shown follows. Let u0 R(u) v 0 U \ R(u). show u0 6 v 0v 0 6 u0 . Suppose, towards contradiction, u0 v 0 . u0 R(u), pathu u0 . u0 v 0 , would also path u v 0v 0 would R(u), contradiction. Analogously, v 0 u0 would also implypath u v 0 path u u0 , contradiction.Therefore, R(u) U cut GR, Lemma 18, follows U \R(u) unfoundedset. Observe U \ R(u) contains one e-edge less U u outgoing e-edgeU \ R(u) 6= ; indeed, assumption w U exists u e w, clearlyw 6 R(u). iterating argument, number e-edges unfounded set reducedzero nonempty core. Eventually Lemma 19 applies, proving remaining setunfounded set .2Proof Corollary 21. Towards contradiction, suppose unfounded set U wrt. exists.U contains e-cycle e-cycle . Theorem 20unfounded set wrt. A, contradicts assumption unfounded set wrt. A.2Proof Theorem 22. U contains cyclic input atoms, cycles containinge-edges atom dependency graph broken, i.e., U contain e-cycle. Theorem 20 exists nonempty unfounded set wrt. A.24. Whenever x e x, U , path x , otherwise woulde-cycle .316fiE FFICIENT HEX-P ROGRAM E VALUATION BASED U NFOUNDED ETSProof Theorem 23. Let U nonempty unfounded set wrt. A. C decomposition A() strongly connected components, component dependency graphhC, {(C1 , C2 ) | C1 , C2 C, a1 C1 , a2 C2 : (a1 , a2 ) e }iacyclic. Following hierarchical component dependency graph nodes without predecessor components downwards, find first component nonempty intersectionU , i.e., exists component C C C U 6= C 0 U = transitivepredecessor components C 0 C.show U C unfounded set C wrt. A. Let r C ruleH(r) (U C) 6= . show one conditions (i)-(iii) Definition 5 holdsr wrt. U C.U unfounded set wrt. know one conditions (i)(iii) holdsr wrt. U . case Condition (i), trivially holds also wrt. U C condition depends assignment A, unfounded set U ; caseCondition (iii), clearly holds H(r) \ U 6= included H(r) \ (U C)..case Condition (ii), .U 6|= b (ordinary external) bodyliteral.b . B(r). show next truth value literals B(r) .U.(U C), proves Condition (ii) holds also wrt. U C.b =. ordinary atom a, Ta 6 U consequently 6 U C,hence A. .(U C) 6|= b. b ordinary atom, either Fb A, implies immediately.(U C) 6|= b, b U . latter case b either predecessor componentC 0 C C (since h b h H(r)). since U C 0 =predecessor.components C, know b C therefore b (U C), implies .(U C) 6|= b.b positive default-negated external atom, input atoms b eitherpredecessor component C 0 C C (since h e h H(r)). show .withsimilar argumenttruth value input atom .U...(UC):.U |=a, Ta 6 U , hence 6 (U C)..therefore.(U C) |= a. .U 6|= a, either Fa A, immediately implies..(U C) 6|= a, U . latter case must C U. C 0 =predecessor components C 0 C. Therefore (U C) and. consequently. .(U C) 6|= a.input atoms truth value .U .(U C),holds also positive default-negated external atom b itself.2Proof Proposition 24. U = , result holds trivially. definition C ,H(r) C = r \ C . hypothesis U C. H(r) U =r \ C U unfounded set wrt. A.2ReferencesAlviano, M., Calimeri, F., Faber, W., Leone, N., & Perri, S. (2011). Unfounded Sets WellFounded Semantics Answer Set Programs Aggregates. Journal Artificial Intelligence Research, 42, 487527.Baader, F., & Hollunder, B. (1995). Embedding Defaults Terminological Knowledge Representation Formalisms. Journal Automated Reasoning, 14(1), 149180.317fiE ITER , F INK , K RENNWALLNER , R EDL , & CH ULLERBasol, S., Erdem, O., Fink, M., & Ianni, G. (2010). HEX Programs Action Atoms.Hermenegildo, M., & Schaub, T. (Eds.), Technical Communications 26th InternationalConference Logic Programming (ICLP10), Vol. 7 Leibniz International ProceedingsInformatics (LIPIcs), pp. 2433, Dagstuhl, Germany. Schloss DagstuhlLeibniz-Zentrumfuer Informatik.Brewka, G., & Eiter, T. (2007). Equilibria Heterogeneous Nonmonotonic Multi-Context Systems. Holte, R. C., & Howe, A. (Eds.), 22nd AAAI Conference Artificial Intelligence(AAAI07), pp. 385390. AAAI Press.Brewka, G., Eiter, T., & Truszczynski, M. (2011). Answer set programming glance. Communications ACM, 54(12), 92103.Drescher, C., Gebser, M., Grote, T., Kaufmann, B., Konig, A., Ostrowski, M., & Schaub, T. (2008).Conflict-driven disjunctive answer set solving. Brewka, G., & Lang, J. (Eds.), 11th International Conference Principles Knowledge Representation Reasoning (KR 2008),Sydney, Australia, September 16-19, 2008, pp. 422432. AAAI Press.Drescher, C., & Walsh, T. (2012). Answer set solving lazy nogood generation. Dovier,A., & Costa, V. S. (Eds.), Technical Communications 28th International ConferenceLogic Programming (ICLP 2012), Vol. 17 Leibniz International Proceedings Informatics(LIPIcs), pp. 188200. Schloss DagstuhlLeibniz-Zentrum fuer Informatik.Dung, P. M. (1995). acceptability arguments fundamental role nonmonotonicreasoning, logic programming n-person games. Artificial Intelligence, 77(2), 321357.Dung, P., Mancarella, P., & Toni, F. (2007). Computing ideal sceptical argumentation. ArtificialIntelligence, 171, 642674.Dunne, P. E. (2009). computational complexity ideal semantics. Artificial Intelligence,173(18), 15591591.Egly, U., Gaggl, S. A., & Woltran, S. (2010). Answer-set programming encodings argumentationframeworks. Argument Computation, 1(2), 147177.Eiter, T., Fink, M., Ianni, G., Krennwallner, T., & Schuller, P. (2011). Pushing Efficient EvaluationHEX Programs Modular Decomposition. Delgrande, J., & Faber, W. (Eds.), 11th International Conference Logic Programming Nonmonotonic Reasoning (LPNMR11),Vol. 6645 LNAI, pp. 93106. Springer.Eiter, T., Fink, M., Krennwallner, T., & Redl, C. (2012a). Conflict-driven ASP Solving ExternalSources. Theory Practice Logic Programming, 12(4-5), 659679.Eiter, T., Fink, M., Krennwallner, T., Redl, C., & Schuller, P. (2012b). Eliminating Unfounded SetChecking HEX-Programs. Fink, M., & Lierler, Y. (Eds.), 5th Workshop AnswerSet Programming Computing Paradigms (ASPOCP 2012), September 4, 2012,Budapest, Hungary, pp. 8397.Eiter, T., Fink, M., Krennwallner, T., Redl, C., & Schuller, P. (2012c). Exploiting Unfounded SetsHEX-Program Evaluation. del Cerro, L. F., Herzig, A., & Mengin, J. (Eds.), 13thEuropean Conference Logics Artificial Intelligence (JELIA 2012), September 26-28,2012, Toulouse, France, Vol. 7519 LNCS, pp. 160175. Springer.318fiE FFICIENT HEX-P ROGRAM E VALUATION BASED U NFOUNDED ETSEiter, T., Fink, M., Schuller, P., & Weinzierl, A. (2012b). Finding explanations inconsistencynonmonotonic multi-context systems. Tech. rep. INFSYS RR-1843-12-09, INFSYS RR1843-03-08, Inst. fur Informationssysteme, TU Wien. Preliminary version Proc. 12th International Conference Knowledge Representation Reasoning (KR 2010), pp. 329339,AAAI Press, 2010.Eiter, T., Ianni, G., Krennwallner, T., & Schindlauer, R. (2008a). Exploiting conjunctive queriesdescription logic programs. Annals Mathematics Artificial Intelligence, 53(14),115152.Eiter, T., Ianni, G., Lukasiewicz, T., Schindlauer, R., & Tompits, H. (2008b). Combining answer setprogramming description logics semantic web. Artificial Intelligence, 172(1213), 14951539.Eiter, T., Ianni, G., Schindlauer, R., & Tompits, H. (2005). Uniform Integration Higher-OrderReasoning External Evaluations Answer-Set Programming. Kaelbling, L. P., &Saffiotti, A. (Eds.), 19th International Joint Conference Artificial Intelligence (IJCAI05),pp. 9096. Professional Book Center.Eiter, T., Ianni, G., Schindlauer, R., & Tompits, H. (2006a). dlvhex: Prover Semantic-WebReasoning Answer-Set Semantics. Proceedings ICLP06 WorkshopApplications Logic Programming Semantic Web Semantic Web Services (ALPSWS2006), pp. 3339. CEUR WS.Eiter, T., Ianni, G., Schindlauer, R., & Tompits, H. (2006). Effective Integration Declarative RulesExternal Evaluations Semantic-Web Reasoning. Sure, Y., & Domingue, J. (Eds.),3rd European Conference Semantic Web (ESWC06), Vol. 4011 LNCS, pp. 273287.Springer.Faber, W. (2005). Unfounded sets disjunctive logic programs arbitrary aggregates.Baral, C., Greco, G., Leone, N., & Terracina, G. (Eds.), 8th International Conference LogicProgramming Nonmonotonic Reasoning (LPNMR05), Vol. 3662, pp. 4052. Springer.Faber, W., Leone, N., & Pfeifer, G. (2011). Semantics complexity recursive aggregatesanswer set programming. Artificial Intelligence, 175(1), 278298.Gebser, M., Ostrowski, M., & Schaub, T. (2009). Constraint answer set solving. Hill, P., & Warren, D. (Eds.), Proceedings Twenty-fifth International Conference Logic Programming (ICLP09), Vol. 5649 Lecture Notes Computer Science, pp. 235249. SpringerVerlag.Gebser, M., Kaufmann, B., & Schaub, T. (2012). Conflict-driven answer set solving: theorypractice. Artificial Intelligence, 187188, 5289.Gebser, M., Kaufmann, B., & Schaub, T. (2013). Advanced conflict-driven disjunctive answerset solving. Proceedings Twenty-Third International Joint Conference ArtificialIntelligence, IJCAI13, pp. 912918. AAAI Press.Gelfond, M., & Lifschitz, V. (1991). Classical Negation Logic Programs DisjunctiveDatabases. New Generation Computing, 9(34), 365386.Ghidini, C., & Giunchiglia, F. (2001).Local models semantics, contextual reasoning=locality+compatibility. Artificial Intelligence, 127(2), 221259.319fiE ITER , F INK , K RENNWALLNER , R EDL , & CH ULLERGoldman, R., & Boddy, M. (1996). Expressive Planning Explicit Knowledge. Drabble, B.(Ed.), 3rd International Conference Artificial Intelligence Planning Systems (AIPS96),pp. 110117. AAAI Press.Hoehndorf, R., Loebe, F., Kelso, J., & Herre, H. (2007). Representing default knowledge biomedical ontologies: application integration anatomy phenotype ontologies. BMCBioinformatics, 8, 377.Janhunen, T., Niemela, I., Seipel, D., Simons, P., & You, J.-H. (2006). Unfolding partialitydisjunctions stable model semantics. ACM Trans. Comput. Log., 7(1), 137.Koch, C., Leone, N., & Pfeifer, G. (2003). Enhancing disjunctive logic programming systemsSAT checkers. Artificial Intelligence, 151(12), 177212.Lee, J. (2005). model-theoretic counterpart loop formulas. Kaelbling, L. P., & Saffiotti,A. (Eds.), 19th International Joint Conference Artificial Intelligence (IJCAI05), pp. 503508. Professional Book Center.Lee, J., & Lifschitz, V. (2003). Loop Formulas Disjunctive Logic Programs. Palamidessi, C.(Ed.), 19th International Conference Logic Programming (ICLP03), Vol. 2916 LNCS,pp. 451465. Springer.Leone, N., Pfeifer, G., Faber, W., Eiter, T., Gottlob, G., Perri, S., & Scarcello, F. (2006). DLVSystem Knowledge Representation Reasoning. ACM Transactions ComputationalLogic, 7(3), 499562.Leone, N., Rullo, P., & Scarcello, F. (1997). Disjunctive Stable Models: Unfounded Sets, FixpointSemantics, Computation. Information Computation, 135(2), 69112.Lierler, Y. (2005). cmodels - SAT-Based Disjunctive Answer Set Solver. Baral, C., Greco, G.,Leone, N., & Terracina, G. (Eds.), 8th International Conference Logic ProgrammingNonmonotonic Reasoning (LPNMR 2005), Vol. 3662 Lecture Notes Computer Science,pp. 447451. Springer.Lifschitz, V., & Turner, H. (1994). Splitting logic program. Hentenryck, P. V. (Ed.), 11thInternational Conference Logic Programming (ICLP94), pp. 2337. MIT Press.Lin, F., & Zhao, Y. (2004). ASSAT: computing answer sets logic program SAT solvers.Artificial Intelligence, 157(12), 115137.Marano, M., Obermeier, P., & Polleres, A. (2010). Processing RIF OWL2RL within DLVHEX.Hitzler, P., & Lukasiewicz, T. (Eds.), 4th International Conference Web ReasoningRule Systems (RR10), Vol. 6333 LNCS, pp. 244250. Springer.Nieuwenborgh, D. V., Cock, M. D., & Vermeir, D. (2007a). Computing fuzzy answer sets usingdlvhex. Dahl, V., & Niemela, I. (Eds.), 23rd International Conference Logic Programming (ICLP07), Vol. 4670 LNCS, pp. 449450. Springer.Nieuwenborgh, D. V., Eiter, T., & Vermeir, D. (2007b). Conditional planning external functions. Baral, C., Brewka, G., & Schlipf, J. S. (Eds.), 9th International Conference LogicProgramming Nonmonotonic Reasoning (LPNMR07), Vol. 4483 LNCS, pp. 214227.Springer.Shen, Y.-D. (2011). Well-supported semantics description logic programs. Walsh, T. (Ed.),22nd International Joint Conference Artificial Intelligence (IJCAI11), pp. 10811086.AAAI Press.320fiE FFICIENT HEX-P ROGRAM E VALUATION BASED U NFOUNDED ETSShen, Y.-D., & Wang, K. (2011). Extending logic programs description logic expressionssemantic web. Aroyo, L., Welty, C., Alani, H., Taylor, J., Bernstein, A., Kagal, L., Noy,N. F., & Blomqvist, E. (Eds.), 10th International Semantic Web Conference (ISWC11), Vol.7031 LNCS, pp. 633648. Springer.Simons, P., Niemela, I., & Soininen, T. (2002). Extending implementing stable modelsemantics. Artificial Intelligence, 138(1-2), 181234.Smith, D. E., & Weld, D. S. (1998). Conformant Graphplan. Mostow, J., Rich, C., & Buchanan,B. (Eds.), 15th National Conference Artificial Intelligence (AAAI98), pp. 889896. AAAIPress / MIT Press.Turner, H. (2002). Polynomial-length planning spans polynomial hierarchy. Flesca, S., Greco,S., Leone, N., & Ianni, G. (Eds.), European Conference Logics Artificial Intelligence(JELIA02), Vol. 2424 LNCS, pp. 111124. Springer.Van Gelder, A., Ross, K. A., & Schlipf, J. S. (1991). Well-Founded Semantics GeneralLogic Programs. Journal ACM, 38(3), 619649.Zakraoui, J., & Zagler, W. L. (2011). logical approach web user interface adaptation.Holzinger, A., & Simonic, K.-M. (Eds.), 7th Conference Workgroup Human-ComputerInteraction Usability Engineering Austrian Computer Society (USAB11), Vol.7058 LNCS, pp. 645656. Springer.Zirtiloglu, H., & Yolum, P. (2008). Ranking semantic information e-government: complaintsmanagement. 1st International Workshop Ontology-supported Business Intelligence(OBI08), No. 5 OBI08, p. 7. ACM.321fiJournal Artificial Intelligence Research 49 (2014) 79-109Submitted 07/13; published 01/14Closure Consistency Logic-Associated ArgumentationPhan Minh DungPhan Minh Thangdung.phanminh@gmail.comthangfm@gmail.comComputer Science Information Management ProgramAsian Institute TechnologyGPO Box 4, Klong Luang, Pathumthani 12120, ThailandAbstractProperties like logical closure consistency important properties logicalreasoning system. Caminada Amgoud showed every logic-based argumentsystem satisfies relevant properties. conditions like closure contraposition transposition monotonic part underlying logic, ASPIC-like systemssatisfy properties. contrast, logical closure consistency propertieswell-understood well-known widely applied systems like logic programmingassumption based argumentation. Though conditions like closure contrapositiontransposition seem intuitive ASPIC-like systems, rule many sensible ASPIC-likesystems satisfy properties closure consistency.present new condition referred self-contradiction axiom guaranteesconsistency property ASPIC-like assumption-based systems impliedproperties closure contraposition transposition. develop logicassociated abstract argumentation framework, associating abstract argumentationabstract logics represent conclusions arguments. show logic-associatedabstract argumentation frameworks capture ASPIC-like systems (without preferences)assumption-based argumentation. present two simple natural properties compactness cohesion logic-associated abstract argumentation frameworks showcapture logical closure consistency properties. demonstrateassumption-based argumentation ASPIC-like systems, cohesion follows naturallyself-contradiction axiom. give translation ASPIC-like systems (without preferences) equivalent assumption-based systems keeps self-contradictionaxiom invariant.1. IntroductionProperties like logical closure consistency important properties logical reasoning system. Caminada Amgoud (2007) showed every logic-based argumentsystem satisfies relevant properties. conditions like closure contraposition transposition monotonic part underlying logic,1 propertiesfulfilled ASPIC systems. Prakken (2010) later Modgil Prakken (2013)developed idea ASPIC+, rich complex logic-based argumentationsystem.following example illustrates many sensible ASPIC assumptionbased systems satisfy properties closure consistency neither closedcontraposition transposition.1. precise definition closure contraposition transposition given section 4.c2014AI Access Foundation. rights reserved.fiDung & ThangExample 1 Consider ASPIC-like system = (RS, RD)1. RD = RD0 RD1 set defeasible rules(a) RD0 consists two defeasible rulesd1 : p fd2 : b frepresenting defaults birds fly, penguins dont(b) RD1 consists single defeasible ruleth bhrepresenting default Thais normally black hair2. RS = RS0 RS1 set strict rules(a) RS0 consists three strict rulesppbp Oj(d2 )Oj(d2 ) means rule d2 applicable,(b) RS1 consists single strict rulethdifficult see satisfies properties closure consistency.Even though neither closed contraposition transposition,reason rule systems like consideration long captureintuition concerned applications. fact, systems like often offer natural representation concerned applications closed contrapositiontransposition. illuminate point, imagine another ASPIC-like system containingstrict defeasible rules closed contraposition.2Suppose interested colour hair concerned Thai individual.Consider argument : th bh. Let B1 : p f B2 : p b f . LetCN consequence operator defined strict rules3 . f CN ({f, bh}),follows closure contraposition property CN, bh CN ({f, f }). Therefore argument B conclusion bh contains B1 , B2 subarguments. Bhence attacks A. B attacked (by undercut) argument C : p Oj(d2 ) B2attack C, accepted grounded extension. set {A}admissible. words, draw conclusion hair colour Thais,system needs resolve completely unrelated controversy flying capabilitiespenguins birds.2. example, adding absurdity rules representing proposition inconsistency impliesevery thing, form a, l atom appearing RS RD l literalset atoms. difficult see closed contraposition (see appendix section 1).3. precise definition given definition 1.80fiClosure Consistency Logic-Associated Argumentationgeneral, condition closure contraposition creates attackdefeasible argument inconsistency ASPIC systems. words, systems happen contain knowledge several causally independent domains likeflying penguins hair colour Thais, closure contraposition interlinkmaking necessary resolve possible inconsistencies parts systems able answer query, independent whether inconsistenciescausally related query not.4contrast, argument systems like AS, attack {A}admissible. Controversy flying capabilities penguins effectacceptance A.Though closure transposition avoids problem conflict propagation,adopted many well-known practical systems indiscriminate applicationcould lead counter-intuitive result many cases. example, consider simplifiedversion example birds fly penguins dont aspic+ whose set strict rulesclosure transposition following strict rules:app, b fp fpbp appapp ordinary premise app = app.Therefore rule app p included set strict rules.Suppose knowledge base consists ordinary premise app statingdefault birds fly applicable.Without information, two arguments are: app Bp.Accepting ordinary premise app simply says informationdefault birds fly applied. say anything penguin. closuretransposition implies definitely penguin around (a rather slippery waymake conclusion).context logic programming, rule app p also rather unnatural appviewed assumption explicit negation operator whose intuitive readingexplicit negation assertion based hard evidence,another assumption (Gelfond & Lifschitz, 1990).contrast ASPIC systems, much research done study logicalclosure consistency semantics well-known widely applied systemslike logic programming assumption based argumentation (Gelfond & Lifschitz, 1988;Lifschitz, 1999; Bondarenko, Dung, Kowalski, & Toni, 1997). Properties like closuretransposition contraposition embraced logic programming assumption basedargumentation. Prakken (2012) observed assumption-based argumentation yieldsunintuitive argument unwanted conclusion inference rules satisfy transposition property. hence natural askwhether conditions implied conditions closure contraposition transposition still guaranteeing important properties logical closureconsistency,4. Pollock (1995) Wu (2012) also pointed classical propositional proof systems propagateconflicts throughout knowledge bases unrelated parts.81fiDung & Thangwhether logical closure consistency properties could stated studiedgeneral framework generalizing assumption-based ASPIC-like systems possiblyalso logic-based argument systems ?present paper new condition referred self-contradiction axiom5guarantees consistency complete extension semantics impliedconditions closure contraposition transposition time, alsoincludes systems could avoid problem conflict-propagation. example 1AS, satisfy self-contradiction axiom.turns consistency closure properties logic-based argument systems could studied within general logic-associated abstract argumentation framework,obtained associating abstract argumentation abstract logics represent conclusions arguments. demonstrate logic-associated abstract argumentation frameworks capture ASPIC-like systems (without preferences) assumption-based argumentation. present two simple natural properties compactness cohesionlogic-associated abstract argumentation frameworks show capture logicalclosure consistency complete extension semantics. demonstrateassumption-based argumentation ASPIC-like systems cohesion follows naturallyself-contradiction axiom.give translation ASPIC-like systems (without preferences) equivalent assumption-based systems keeps self-contradiction property invariant.paper structured follows. section 2 recall abstract argumentationTarski abstract logics. introduce section 3 framework abstract argumentation associated abstract logics sentences abstract logics representargument conclusions. present section two simple natural conditions compactness cohesion show ensure satisfaction properties logicalclosure consistency complete extensions. sections 4, 5 show compactnesscohesions could captured naturally ASPIC-like systems assumption-based argumentation. introduce section 4 fundamental axiom self-contradiction showconnections properties closure contraposition transposition. provide section 6 transformation ASPIC-like systems equivalentassumption-based framework. section 7, discuss recent systems basedTarskis abstract logics. conclude.62. Preliminariesabstract argumentation framework (Dung, 1995) defined simply pair (AR, att)set arguments AR att AR AR (A, B) att represents attackargument argument B. set argument attacks argumentargument attacks A. attacks another set attacks argument. conflict-free attack itself. conflicting attacks itself.argument acceptable wrt set arguments attacks attack A.admissible conflict-free counter-attacks attack it. semantics5. intuitive reading self-contradiction X causes contradiction X contradictsitself.6. preliminary extended abstract paper published Dung Thang (2011).82fiClosure Consistency Logic-Associated Argumentationabstract argumentation determined acceptability arguments variousassociated notions extensions. complete extension admissible set containing everyargument acceptable wrt it. Complete extensions could also viewed conflict-free fixedpoints characteristic function F : 2AR 2AR defined F (S) = set acceptablearguments wrt S. Preferred extensions maximal conflict-free fixed points Fleast fixed point F called grounded extension. could many preferredextensions, exists unique grounded extension. stable extension conflict-freeset arguments attacks every argument belonging it.Amgoud Besnard (2009) proposed use Tarskis abstract logic argumentation characterized simply consequence operator.Given language L well-formed formulas, Tarski abstract logic (Amgoud & Besnard,2009) defined consequence operator CN: 2L 2L following axiomssatisfied:1. (Expansion)X CN (X)2. (Idempotence)3. (Finiteness)CN (CN (X)) = CN (X)CN (X) = {CN (Y ) | X finite }4. (Absurdity)CN ({x}) = L x L5. (Coherence)CN () 6= Lintroduce consequence operator set strict inference rules.strict rule7 form1 , . . . , n1 , . . . , n , L.Definition 1 Let RS set strict rules. Define consequence operator CNRS :2L 2L follows: set X L, CNRS (X) smallest set1. X CNRS (X),2. rule 1 , . . . n RS, {1 , . . . n } CNRS (X) CNRS (X).3. Associating Abstract Argumentation Abstract LogicsIntuitively, argument proof conclusion. many cases, proofs constructed following proof theory formal logics. logics could nonmonotonic. notions closure consistency defined according monotonicparts underlying logics.Many logics underlying argumentation systems like assumption-based argumentationASPIC-systems always impose absurdity axiom. motivates slightgeneralization Tarski abstract logics following definition.7. often also referred inference rules assumption-based argumentation.83fiDung & ThangDefinition 2 Given language L, abstract logic defined pair (CN, CON RA)CN: 2L 2L represents consequence operator CON RA 2L collectioncontradictory sets following axioms hold:1. CN satisfies expansion, idempotence finiteness axioms.2. (Weak Absurdity) CON RA superset also belongs CON RA.83. (Weak Coherence) CN () 6 CON RA.Given abstract logic (CN, CON RA), X closed iff X = CN (X). set XCON RA said contradictory.set X L said inconsistent iff closure CN (X) contradictory.9 X saidconsistent iff inconsistent. X minimal inconsistent iff X inconsistentproper subset X consistent.10Definition 3 say abstract logic satisfiesstrong absurdity axiom CON RA 6= X CON RA, CN (X) = L.follows immediately abstract logic Tarski abstract logic satisfiesstrong absurdity axiom x L {x} inconsistent.11Example 2 Let RS0 = { wr; go; b hw; hw} set strict rules,12L language consisting literals whose atoms occur rules RS0 . DefineAL0 = (CN0 , CON RA) follows:X CON RA iff X contains pair literals {l, l}.CN0 consequence operator defined RS0 .illustration, CN0 () = {wr, go}, CN0 ({m}) = {wr, go, m, hw} CN0 ({m, b}) ={wr, go, m, hw, b, hw}. Hence set {m, b} inconsistent contradictory.difficult see AL0 abstract logic. CN0 ({hw, hw}) ={hw, hw}, follows AL0 satisfy strong absurdity axiom.8. Note CON RA could empty like case definite logic programs L consistspositive literals. Nonetheless, CON RA 6= L CON RA.9. words, set sentences X inconsistent contradiction could derived thoughcontradiction may present directly X (i.e. inconsistent set may contradictory).10. proper subset X subset X 6= X.11. Tarskian one, abstract logic needs satisfy absurdity coherence. {x}inconsistent, CN ({x}) contradictory. Since strong absurdity satisfied, CN (CN ({x})) = L.idempotence, CN (CN ({x})) = CN ({x}). Hence CN ({x}) = L. coherence holds.weak coherence axiom abstract logic, CN () 6 CON RA. Due strong absurdity,CON RA 6= . Due weak absurdity, fact CON RA 6= , follows LCON RA. Hence CN () 6= L.12. rules taken example Caminada Amgoud (2007) wr = John wearssomething looks like wedding ring, = John married, hw = John wife, go =John often goes late, b = John bachelor.84fiClosure Consistency Logic-Associated ArgumentationInspired Amgoud Besnards idea (2009), use abstract logics representconclusions arguments difference them, specify detail structureindividual arguments.Definition 4 logic-associated argumentation framework language Lquadruple (AF, , AL, Cnl)1. AF = (AR, att) abstract argumentation framework,2. AL = (CN, CON RA) abstract logic L,3. Cnl : AR L assigns argument A, conclusion Cnl(A) L,4. partial order13 AR B means subargument Barguments C AR, C attacks C attacks B.Remark 1set arguments, Cnl(S) denotes set conclusionsarguments S.set subarguments denoted Sub(A). set arguments S,Sub(S) contains subarguments arguments S.next give example logic-associated argumentation framework.Example 3 Let LAF0 = (AF0 , 0 , AL0 , Cnl) AL0 defined example 2AF0 = (AR0 , att0 )1. arguments AR0 constructed rules set strict rules RS0example 2, set defeasible rules RD = {wr m; go b}. 6arguments14 :A1 : wr, A3 : wr m, A5 : wr hw.A2 : go, A4 : go b,A6 : go b hw.Attack relation: A5 attacks A6 vice versa. attacks. Letatt0 = {(A5 , A6 ), (A6 , A5 )}.2. subargument relation 0 reflexive transitive closure A1 A3 A5A2 A4 A6 .Definition 5 Let LAF = (AF, , AL, Cnl), AL = (CN, CON RA), logic-associatedargumentation framework.1. LAF said satisfy closure-property complete extension E AF,Cnl(E) closed wrt AL.13. partial order reflexive, asymmetric transitive relation.14. precise definition see definition 12.85fiDung & Thang2. LAF said satisfy consistency-property complete extension EAF, Cnl(E) consistent wrt AL.Example 4 (Continuation example 3)grounded extension AF0 GE = {A1 , A2 , A3 , A4 }. two preferredextensions E1 = {A1 , A2 , A3 , A4 , A5 } E2 = {A1 , A2 , A3 , A4 , A6 }.Cnl(GE) = {wr, go, m, b} CN0 (Cnl(GE)) = Cnl(GE) {hw, hw}. Henceset conclusions arguments grounded extension neither closed consistent wrt abstract logic AL0 . Hence LAF0 satisfies neither closure-propertyconsistency-property.also easy see sets conclusions arguments two preferredextensions neither closed consistent either.Example 5 (Continuation example 4)Let RS1 = RS0 {hw m, hw b}. consequence operator wrt RS1denoted CN1 . Let AL1 = (CN1 , CON RA) AF1 = (AR1 , att1 )AR1 = AR0 {A7 , A8 } A7 : A5 b A8 : A6 m,15att1 = {(A7 , A4 ), (A7 , A6 ), (A7 , A8 ), (A8 , A3 ), (A8 , A5 ), (A8 , A7 )},1 reflexive transitive closure 0 {A5 A7 , A6 A8 }.grounded extension AF1 GE = {A1 , A2 }. Two preferred extensions AF1E1 = {A1 , A2 , A3 , A5 , A7 } E2 = {A1 , A2 , A4 , A6 , A8 }.difficult see sets Cnl(GE ) = {wr, go}, Cnl(E1 ) = {wr, go, m, hw, b},Cnl(E2 ) = {wr, go, b, hw, m} closed consistent.Let LAF1 = (AF1 , 1 , AL1 , Cnl). closure consistency properties satisfiedLAF1 .end section, assume arbitrary fixed logicassociated framework LAF = (AF, , AL, Cnl).turns closure consistency properties based intuitiveidea base argument.Definition 6 Let argument BA finite set subarguments A. BAsaid base following conditions satisfied:1. Cnl(A) CN (Cnl(BA))2. argument C, C attacks iff C attacks BA.easy see argument A, {A} base A.example 3, though Cnl(A5 ) CN0 (Cnl(A3 )), {A3 } base A5 since A6attacks A5 A6 attack A3 .Note empty set base arguments A1 A2 .contrast, example 5, {A3 } base A5 A7 {A4 } base A6 A8 .15. i.e. A7 wr hw b, A8 go b hw m.86fiClosure Consistency Logic-Associated ArgumentationDefinition 71. argument said generated set argumentsbase BA BA Sub(S).2. set arguments generated denoted GN(S).follows immediatelyLemma 1 Let set arguments. following assertions hold:1. argument A, generated {A}.2. Sub(S) GN (S).3. Cnl(GN (S)) CN (Cnl(Sub(S))).4. CN (Cnl(GN (S))) = CN (Cnl(Sub(S))).5. argument C, C attacks GN (S) iff C attacks S.Proof See appendix section 3.Theorem 1 Let E complete extension. GN (E) = EProof See appendix section 3.Theorem 1 motivates following definitions 8, 9.Definition 8 say logic-associated argumentation framework LAF compactset arguments S, Cnl(GN (S)) closed.argumentation framework example 3 compact since = {A3 }, GN (S) ={A1 , A2 , A3 } Cnl(GN (S)) = {wr, go, m} closed since CN ({wr, go, m}) = {wr, go, m, hw}.contrast, argumentation framework example 5 compact. example,GN (S) = {A1 , A2 , A3 , A5 , A7 } (wrt LAF1 ) Cnl(GN (S)) = {wr, go, m, hw, b}closed consistent.Theorem 2 compact logic-associated argumentation framework satisfies closureproperty.Proof. Let E complete extension. compactness, follows Cnl(GN (E))closed. theorem 1, Cnl(E) closed.lemma 1, follows LAF compact iff Cnl(GN (S)) = CN (Cnl(Sub(S))) iffCN (Cnl(Sub(S))) Cnl(GN (S)). provedLemma 2 LAF compact iff set arguments, CN (Cnl(Sub(S))) Cnl(GN (S))Notation 1 Abusing notations simplicity, often refer set argumentsinconsistent (resp. consistent) Cnl(Sub(S)) inconsistent (resp. consistent).87fiDung & ThangIntuitively, inconsistency among set arguments indicates possible conflict amonggenerated arguments. insight motivates following definitions.Definition 9 logic-associated argumentation framework LAF said cohesiveinconsistent set argument S, GN (S) conflicting.illustration, consider logic-associated argumentation framework example 3.Let = {A3 , A4 }. clear inconsistent. difficult seebase argument {A5 , A6 } contains argument itself. Therefore GN (S) ={A1 , A2 , A3 , A4 }. GN (S) thus conflict-free. framework LAF0 hence cohesive.Note argumentation framework LAF1 example 5 compact cohesive.Theorem 3 Let LAF cohesive logic-associated argumentation framework. LAFsatisfies consistency-property.Proof Let E complete extension. Suppose Cnl(E) inconsistent. cohesionLAF, follows GN (E) conflicting. theorem 1, E conflicting. Contradiction.Hence Cnl(E) consistent.follows immediately theorems 2 3:Corollary 1 Let LAF compact cohesive logic-associated argumentation framework. LAF satisfies closure- consistency-properties.next sections, show ASPIC-like systems (without preferences) assumptionbased argumentation instances logic-associated argumentation frameworks.also introduce axiom self-contradiction guarantee cohesion (and consistency)systems.4. Argumentation Strict Defeasible Rulesassume language L literals literal atom explicit negationatom a. set literals said contradictory contains pair a, a.important note identify a. X L, denote X = {l | lX}.defeasible rule form1 , . . . , n1 , . . . , n , L.Definition 10 rule-based argumentation system pair = (RS, RD) set RSstrict rules set RD defeasible rules CNRS () contradictory.following definition 11 identifies abstract logic underlying rule-based argumentation system = (RS, RD).88fiClosure Consistency Logic-Associated ArgumentationDefinition 11 Let = (RS, RD) rule-based argumentation system. DefineALAS = (CNAS , CON RAAS )CON RAAS collection contradictory sets CNAS = CNRS .follows immediatelyLemma 3 ALAS abstract logic.recall arguments attack relations rule-based argumentation systemsintroduced Caminada Amgoud (2007), Prakken (2010), Pollock (1987), ModgilPrakken (2013).Definition 121. Rules form / , arguments conclusion .2. Let r strict/defeasible rule form 1 , . . . , n / , n 0. suppose A1 , . . . , , n 0, arguments conclusions 1 , . . . , n respectively.A1 , . . . , / argument conclusion last rule r.3. Every argument constructed applying finitely many times two steps.next introduce key notations.Notation 21. strict argument argument containing defeasible rule. Nonstrict arguments called defeasible arguments.2. basic defeasible argument argument whose last rule defeasible one,i.e. form A1 , . . . , .basic defeasible argument B, last rule B denoted Lr(B).3. B subargument argument form A1 , . . . , / , denotedB A, B = B subargument Ai .Remark 2 conclusion argument denoted Cnl(A).Remark 3 Arguments form A1 , . . . , / also often viewed prooftrees root labelled children root roots subtreesA1 , . . . , . Note n = 0, proof tree consists root.Illustrations argumentation systems based strict defeasible rules givenexamples 3, 5.following notion attack adopted articles Caminada Amgoud (2007),Prakken (2010), Pollock (1987), Modgil Prakken (2013).Definition 13 argument attacks argument B (on B) B basic defeasiblesubargument B one following conditions satisfied:89fiDung & Thang1. (Undercutting) Cnl(A) = Oj(Lr(B )) defeasible rule r, Oj(r) atomdenoting rule r applicable.2. (Rebutting) Cnl(A) = Cnl(B ).Remark 4 simplicity, identify rule-based argumentation system logicassociated argumentation framework (AFAS , , ALAS , Cnl) AFAS argumentation framework obtained according definitions 12,13.Theorem 4 Rule-based argumentation systems compact.Proof See appendix section 4.following lemma reveals simple important relation argumentsbasic defeasible subarguments.Lemma 4 Let argument BD set basic defeasible subarguments A.Cnl(A) CNAS (Cnl(BD)).Proof See appendix section 4.introduce fundamental condition underlying cohesion rule-based argumentation.Definition 14 abstract logic ALAS said satisfyself-contradiction axiom minimal inconsistent set X L : X CNAS (X).16example illustrates intuition self-contradiction axiom usingfamous birds fly penguins dont-example.Example 6 Let = (RS, RD) RD consists two defeasible rules:d1 : p fd2 : b fRS consists three strict rulesr0 : pr1 : p br2 : p Oj(d2 )Oj(d2 ) atom stating rule d2 applicable.obvious set strict rules RS closed transposition. alsostraightforward see CNAS ({f, f }) = {f, f } =6 L. Hence underlying abstractlogic ALAS satisfies neither strong absurdity axiom closure transpositionproperty.1716. intuitive reading self-contradiction X causes contradiction X contradictsitself.17. See section 4.1 precise definitions closure transposition contraposition relationships strong absurdity self-contradiction90fiClosure Consistency Logic-Associated Argumentationdifficult see ALAS satisfies self-contradiction axiom.18difficult see satisfies properties closure consistency.following theorem shows self-contradiction sufficient cohesion.Theorem 5 Suppose ALAS satisfies self-contradiction axiom. cohesive.Proof See appendix section 4.follows immediately corollary 1Corollary 2 Suppose ALAS satisfies self-contradiction axiom. satisfiesclosure- consistency-properties.next relate theorem 5 corollary 2 results Caminada Amgoud(2007), Prakken (2010), Modgil Prakken (2013).4.1 Sufficient Conditions Self-Contradiction Abstract Logics ALASsimplicity, possibilities misunderstanding, often write respectivelyCN , CON RA AL CNAS , CON RAAS ALAS section.first recall definitions closure contraposition transpositionarticles Caminada Amgoud (2007), Prakken (2010), Modgil Prakken (2013).Definition 151. AL saidclosed contraposition set X L, X CN (X)CN (X \ {} {}).2. set strict rules RS saidclosed transposition rule 1 , . . . , n RS, rulesform 1 , . . . , i1 , , i+1 , n also belong RS.relations closure contraposition axioms self-contradictionstrong absurdity illuminated following lemma.Lemma 51. AL closed contraposition, AL satisfies strong absurdityaxiom.2. AL satisfies strong absurdity axiom AL satisfies self-contradiction axiom.18. Let minimal inconsistent set. show CNAS (S). contradictory minimalityimplies = {a, a} L. self-contradiction axioms holds obviously. Supposecontradictory. Hence pair {a, a} CNAS (S) atom a. difficultsee CNAS (S) = CNAS () S. Therefore CNAS (S) \ CNAS () = {p, b, Oj(d2 )}. follows{a, a} CNAS () 6= {a, a} 6= . minimality S, consists exactly one element.Therefore : CNAS (S).91fiDung & ThangProof See appendix section 4.relations closure transposition self-contradiction axiomilluminated following lemma.Lemma 6 Let = (RS, RD) set strict rules RS closed transposition. ALAS satisfies self-contradiction axiom.Proof See appendix section 4.following example shows reverses assertions lemmas 5, 6 holdgeneral.Example 7 Let L = {a, a, b, b}. Let CONTRA set contradictory setsL.1. X L, define CN (X) = X. obvious abstract logic AL =(CN, CON RA) satisfies self-contradiction axiom strong absurdityaxiom.2. Consider set strict rules RS consisting normal rule b togetherabsurdity rules form x, x x {a, b}, L. Let CNconsequence operator wrt RS.obvious AL = (CN, CON RA) satisfies strong absurdity axiom (andhence also self-contradiction axiom). b CN ({a}), 6 CN ({b}) ={b}, follows AL closed contraposition.clear set strict rules closed transposition.3. Consider set strict rules RS consisting two strict rules b ba. clear rule set closed transposition correspondingconsequence operator satisfy strong absurdity axiom.following picture illustrates relationships key properties rule-basedargumentation.Figure 1:92fiClosure Consistency Logic-Associated Argumentation5. Assumption-Based ArgumentationGiven logical language L, assumption-based argumentation (ABA) framework (Bondarenko et al., 1997) triple F = (R, A, ) R set inference rules form(total) one-one1 , . . . n (for n 0), L set assumptions,mapping L, x referred contrary x followingproperties satisfied:assumptions appear heads rules R,contraries assumptions assumptions,L contains explicit negation operator CNR () contradictory wrt, i.e. L, {, } 6 CNR ().following edition birds fly penguins dont example provides illustration.Example 8 F = (R, A,) R consists rulesab1 , p fab2 , b fppbp ab2= {not ab1 , ab2 } ab1 = ab1 , ab2 = ab2identify structure abstract logics underlying ABA frameworks below.5.1 Assumption-based Abstract Logicsset X L said contradictory iffX contradictory wrt, i.e. exists assumption {, } X,X contradictory wrt ,19 i.e. exists L {, } X.Definition 16 Let F = (R, A,) ABA framework. DefineALF = (CNF , CON RAF )1. CNF = CNR .2. CON RAF set contradictory sets.follows immediatelyLemma 7 ALF abstract logic.19. L contains explicit negation operator .93fiDung & ThangRemark 5 simplicity, possibilities misunderstanding, often writesection CN (S) CON RA CNF (S) CON RAF respectively.adapt self-contradiction axiom assumption-based argumentation below.Definition 17 Let F ABA framework. say abstract logic ALF satisfiesab-self-contradiction axiom20 inconsistent set assumptions X,X CNF (X).5.2 Closure Consistency Assumption-Based Argumentationfirst recall definitions arguments attack relation associated ABA framework.Definition 181. assumption argument whose support conclusion{}, respectively.2. Let 1 , . . . n rule. suppose A1 , . . . , argumentsconclusions 1 , . . . , n respectively. A1 , . . . , argument whoseconclusion whose support union supports A1 , . . . ,3. Every argument constructed applying finitely many times two steps.Remark 6 Arguments often viewed proof trees. Arguments form A1 , . . . ,proof trees root labelled children root rootssubtrees A1 , . . . , . Note n = 0, proof tree consists root.assumption proof tree consists root labelledNotation 31. support argument denoted supp(A).support set arguments union supports individualargument denoted supp(S).2. conclusion argument denoted Cnl(A).Definition 19supp(B).1. argument attacks argument B Cnl(A) =2. say B subargument argument form A1 , . . . , Ak , denotedB A, B = B subargument Ai .Remark 7 simplicity, identify assumption-based framework F logicassociated argumentation framework (AFF , , ALF , Cnl) AFF argumentationframework generated F (according definitions 18, 19).difficult seeTheorem 6 ABA frameworks compact.20. ab stands assumption-based.94fiClosure Consistency Logic-Associated ArgumentationProof See appendix section 5.Theorem 7 Let F ABA framework. ALF satisfies ab-self-contradiction axiom,F cohesive.Proof See appendix section 5.follows immediately theorems 6,7, corollary 1Corollary 3 Let F ABA framework. ALF satisfies ab-self-contradiction axiom,F satisfies closure- consistency-properties.5.3 Logic ProgrammingLogic programming could classified three different classes definite programs,normal programs extended programs increasing complexity. Bondarenko, Dung,Kowalski Toni(1997) showed logic programs instances assumption-basedargumentation. discuss underlying abstract logics classes selfcontradiction axiom.5.3.1 Definite Logic Programsdefinite logic program simply assumption-based argumentation framework F =(R, A, ) based language L1. L consists ground atoms set assumptions empty.2. Rules R form a1 , . . . , h h, a1 , . . . , atoms L.contradiction L, CON RAF = . ab-self-contradiction axiomhold trivially. Since attack arguments, extension setarguments. closure consistency properties hold obviously.5.3.2 Normal Logic Programsnormal logic program assumption-based argumentation framework F = (R, A,based language L)1. L consists atoms form a, b, . . . together negation-as-failure literalsform atom.2. Assumptions negation-as-failure literals whose contraries a.3. Rules R form l1 , . . . , ln h h atom l1 , . . . , ln literalsL.95fiDung & ThangCON RAF consists subsets L contain pair a, atom a.ab-self-contradiction axiom holds obviously.21 closure consistency properties hence hold extensions normal programs.5.3.3 Extended Logic Programsextended logic program (Gelfond & Lifschitz, 1990; Lifschitz, 1999) assumptionbased argumentation framework F = (R, A, ) based language L1. L consists atoms form a, b, . . . explicit negations a, b, . . . togethernegation-as-failure literals form l l classical literal (i.e.atom explicit negation atom).2. Assumptions negation-as-failure literals l whose contraries l.3. R consists rules form l1 , . . . , ln h h classical literall1 , . . . , ln literals LCON RAF consists subsets L contain pair a, atompair l, l classical literal l.theorems 6,7 corollary 3, follows immediatelyCorollary 4 Let F extended logic program. CNF () contradictory wrtALF satisfies ab-self-contradiction axiom F compact cohesive hencesatisfies closure consistency properties.6. Translating Rule-Based Argumentation Assumption-BasedArgumentationshowed previous two sections self-contradiction axioms sufficientnatural conditions ensuring closure consistency properties assumptionbased rule-based argumentation.section, argue self-contradiction axiom rule-based systemssubsumed assumption-based self-contradiction axiom giving translationrule-based systems equivalent assumption-based ones. generally, translation suggests rule-based argument systems (without preferences) subsumedassumption-based argumentation.Let = (RS, RD) arbitrary fixed rule-based argumentation systemr RD, rule RS RD whose head coincides Oj(r)whose body contains occurrence Oj(r). translate assumption-basedsystem following definition.Definition 20 (AS) = (R, A,) defined follows:21. give short proof here. Let X inconsistent set assumptions. Hence assumptions.t. {, } CNF (X). Since assumptions appear heads rules, X.96fiClosure Consistency Logic-Associated Argumentation1. = {Oj(r) | r RD } {not l | l head rule RD}Oj(r) viewed assumption indicating rule r applicable lnegation-as-failure assumption stating evidence-to-the-contraryl.2.R = RS {T r(r) | r RD }r(r) formOj(r), h, 1 , . . . , n hr form 1 , . . . , n h3.Oj(r) = Oj(r) l = lRemark 8 Since rule RS RD whose head form Oj(r), assumption coincides head rule R. Therefore CNT (AS) ()contradictory wrt . difficult see CNT (AS) () = CNAS (). CNT (AS) ()hence contradictory wrt . Therefore CNT (AS) () contradictory.(AS) hence assumption-based argumentation system.(AS) distinct systems, attentive reader may ask senseequivalent?giving formal elaboration question, let us look example.Example 9 Consider simple rule-based system consisting one strict rule onedefeasible rule :r0 : br1 : b ftwo arguments here:A1 : b A2 : A1 farguments attack other. Hence complete extension Econtains arguments A1 , A2 .corresponding assumption-based system (AS) consists two rules:bOj(r1 ), f, b ffour arguments assumption-based system:B1 : bB2 : C 0 , C 1 , B1 fC0 : Oj(r1 )C1 : fattacks four arguments. complete extension E(AS) consists four arguments. fact information contained E fully captured set = {B1 , B2 } since C0 , C1 subarguments B2 , hence attack97fiDung & Thangalso attack B2 . could view set equivalent representativeE . could viewed representing core E .equivalence E E captured correspondence argumentsA1 , A2 arguments B1 , B2 respectively.Note arguments C0 , C1 extension E (AS) explicitly represent implicitmeta-level information contained extension E AS, namely, defeasible rule r1 applicable argument conclusion f .Let AF0 = (AR0 , att0 ), AF1 = (AR1 , att1 ) argumentation frameworks corresponding AS, (AS) respectively.Definition 21 Let set arguments AF1 . core S, denoted Core(S),definedCore(S) = \i.e Core(S) contains arguments assumptions.illustration, example 9, Core(E ) = {B1 , B2 }.Lemma 81. Let set arguments AF1 argument AF1 .holds: acceptable wrt iff acceptable wrt Core(S).2. Let set arguments AF1 . admissible iff Core(S) admissible.Proof See appendix section 6.following lemma states complete sets identified uniquely cores.Lemma 9 Let E, E complete extensions AF1 . holds:E = E iff Core(E) = Core(E )Proof See appendix section 6.present bijection complete extensions AF0 complete extensionsAF1 defining natural one-one mapping AR0 AR1 :Definition 22 DefineC : AR0 AR1following properties satisfied:1. form A1 , . . . , h, n 0, C(A) formC(A1 ), . . . , C(An ) h 2222. Note form h, C(A) = A.98fiClosure Consistency Logic-Associated Argumentation2. basic defeasible argument form A1 , . . . , h C(A)formOj(r), h, C(A1 ), . . . , C(An ) h 23r last rule A.set arguments AR0 , let C(S) = {C(A) | }. followsLemma 10 Let A, B AR0 AR0 . following observations hold:1. Cnl(A) = Cnl(C(A)).2. C one-one mapping AR0 onto AR1 \3. (A, B) att0 iff (C(A), C(B)) att1 .4. admissible AF0 C(S) admissible AF1 .5. acceptable wrt iff C(A) acceptable wrt C(S)Proof See appendix section 6.Let L languageL0 = L \ {Oj(r), Oj(r) | r defeasible rule AS}equivalence (AS) established following theorem.Theorem 8 complete extension E AF0 complete extension E AF1vice versa following properties hold:1. C(E) = Core(E )2. literal l L0 ,l Cnl(E) iff l Cnl(E )Proof See appendix section 6.following theorem shows self-contradiction axiom rule-based argumentation subsumed ab-self-contradiction axiom assumption-based argumentation.Let ALi = (CNi , CON RAi ), = 0,1, abstract logics associated AS, (AS)respectively.Theorem 9 AL0 satisfies self-contradiction axiom AL1 satisfies ab-selfcontradiction axiom.Proof See appendix section 6.23. Note defeasible rule r form h, C(A) form Oj(r), h, h.99fiDung & Thang7. DiscussionAmgoud Besnard (2009) introduced use Tarskis abstract logic studyconsistency property logic-based argumentation. following, discusscompactness cohesion could fulfilled systems.remarked earlier, Tarski abstract logic represented abstract logicCON RA 6= X CON RA, CN (X) = L x LCN ({x}) CON RA.Tarski abstract logic said adjunctive x, L, CN ({x}) 6=CN ({x, y}) 6= CN ({y}) exists z CN ({z}) = CN ({x, y}).knowledge base defined set L x , x consistent.argument pair = (X, ) X finite consistent supportdenoted supp(A), CN (X) conclusion denoted Cnl(A).support set arguments union supports individual arguments.AR denotes set arguments .X called minimal conflict set X inconsistent proper subset Xconsistent.24rest discussion, assume minimal conflict sets contain twoelements.Let att AR AR attack relation.1. att said context-sensitive iff a, b AR, supp(a)supp(b) inconsistenteither (a, b) att (b, a) att.2. att said conflict-dependent iff a, b AR, (a, b) att supp(a)supp(b) inconsistent.3. att said symmetric iff a, b AR, (a, b) att (b, a) att.argument B said subargument argument A, denoted B B =B = ({}, ) supp(A).Lemma 11 minimal conflict sets binary attack relation att contextsensitive, conflict-dependent symmetric LAF = (AF, , AL, Cnl) compactcohesive logic-associated argumentation framework.Proof See appendix section 7.follows immediately theorem 1:Corollary 5 minimal conflict sets binary attack relation att contextsensitive, conflict-dependent symmetric LAF satisfies properties closureconsistency.24. difficult see minimal conflict set finite CN (X) = L, L = CN ({x})x L, follows x CN (X). finiteness axiom, finite subset Xx CN (Y ). Hence CN (Y ) = L. minimality X, follows X = . X hencefinite.100fiClosure Consistency Logic-Associated ArgumentationCorollary 5 rather limited due restrictions imposed attack relations.structure arguments rather poor abstract logics revealstructure consequence relation. approach marrying abstract argumentation abstract logics resulting logic-associated abstract argumentation addressesproblem specifying subargument structure relation attack relation.Caminada Amgoud (2007) also studied unrestricted rebuts two arguments contrary conclusions considered attack other. Defeasible argumentation attacks based unrestricted rebuts violates consistency closureproperties except grounded semantics. Unrestricted rebuts gain much attention research assumption-based argumentation logic programming.suggests relevant structural features underlying unrestricted attacksstill understood. sensible idea could study kind attacks withinproposed framework logic-associated abstract argumentation could shed lightsinstances defeasible assumption-based argumentation.Non-interference, another key rationality postulate structured argumentationproposed Caminada, Carnielli, Dunne (2012) studied extensively Caminada et al. (2012), Wu (2012). Non-interference conceptually different consistency closure properties later properties could viewed correctnessargument systems former structural modularity. focuscorrectness argument systems, study structural modularity outsidescope paper. Nonetheless, non-interference seems related propertylocalizing conflicts arguments systems say argument system localizedargument attacking every argument. difficult see aspic systemsclosed contraposition localized rebutting attack it.contrast, self-contradiction axiom allows us develop localized aspic systems. wouldinteresting see two concepts localized conflicts non-interferenceinterrelated.Toni (2008) generalized assumption-based argumentation represent reasoningstrict defeasible rules satisfying rational properties logical closureconsistency. showed section 6, standard assumption-based argumentationcaptures rule-based argumentation system simple elegant transformation. Hencenecessary generalize assumption-based argumentation capture defeasible reasoning strict defeasible rules. Nevertheless, proposal Toni (2008) interesting.Nielsen Parson (2007) also proposed generalization abstract argumentationallowing sets attacking arguments. Prakken (2010) Modgil Prakken (2013)also studied preferences arguments. would interesting see whetherproperties compactness cohesion satisfied frameworks.believe compactness cohesion self-contradiction properties couldserve guideline principles design logic-based argumentation systems ensuresatisfaction properties logical closure consistency. pointed CaminadaAmgoud (2007), several argument systems (Garcia & Simari, 2004; Governatori,Maher, Antoniou, & Billington, 2004) satisfying consistency property. wouldinteresting see results paper could applied them.101fiDung & ThangAppendix A. Section 1Let CN consequence operator wrt . clear CN () = {p, b, Oj(d2 ), th}.Let c CN (X) c L X L. Let x X. show x CN (Y )= X \ {x} {c}. c CN (), absurdity rules, follows immediatelyx CN (Y ). Suppose c 6 CN (). Hence c CN (X) iff c X X contains pairliterals a, a. c X x 6= c, c . Hence {c, c} . absurdityrules, L = CN (Y ). c X x = c x . Hence x CN (Y ). X containspair literals a, x 6 {a, a}, L = CN (Y ). x {a, a} x .Appendix B. Section 3Lemma 1 Let set arguments. following assertions hold:1. argument A, generated {A}.2. Sub(S) GN (S).3. Cnl(GN (S)) CN (Cnl(Sub(S))).4. CN (Cnl(GN (S))) = CN (Cnl(Sub(S))).5. argument C, C attacks GN (S) iff C attacks S.Proof first assertion obvious definitions 6 7. Since Sub(S),{A} Sub(S), follows immediately first assertion argument Sub(S)generated S. third assertion follow immediately definitions 6 7.fourth assertion follows second third ones.GN (S), clear C attacks S, C attacks GN (S). Suppose C attacksGN (S). Let GN (S) s.t. C attacks A. Let BA base BA Sub(S).C hence attacks BA. Therefore C attacks Sub(S). Thus C attacks S.Theorem 1 Let E complete extension. GN (E) = EProof Since attack GN (E) attack E (lemma 1, last assertion),attack GN (E) counterattacked E E complete extension. ThereforeGN (E) E. second assertion lemma 1, follows E GN (E). Hence GN (E) =E.Appendix C. Section 4Remark 9 strict argument X L strict argument set rules RS {| X}.Remark 10 strict argument X, set premises A, denoted P rem(A),set literals X labelling leaves (viewed proof tree).Theorem 4 Rule-based argumentation systems compact.102fiClosure Consistency Logic-Associated ArgumentationProof Let rule-based system let set arguments wrtCNAS (Cnl(Sub(S))). lemma 2, need show Cnl(GN (S)).Let X minimal subset Cnl(Sub(S)) CNAS (X). Hencestrict argument A0 X conclusion . let SX minimal set argumentsSub(S) s.t. Cnl(SX ) = X. Let argument obtained replacing leafA0 (viewed proof tree) labelled literal X argument conclusionSX . obvious conclusion . show SX baseA. Suppose B argument attacking A. Since A0 strict argument X, B mustattack basic defeasible subargument argument SX . Hence B attacks SX . ThusGN (S). Hence Cnl(GN (S)). proved rule-based argumentation system compact.Lemma 4 Let argument BD set basic defeasible subargumentsA. Cnl(A) CNAS (Cnl(BD)).Proof induction size A.Basic Step form / .Suppose form CNAS (). BD = , lemma holds.Suppose form BD = {A}. lemma holds.Inductive Step. Suppose form A1 , . . . , /Suppose form A1 , . . . , BD. lemma holds obviously.Suppose form A1 , . . . , . Hence BD union setsBD1 , . . . , BDn basic defeasible subarguments A1 , . . . , respectively. induction hypothesis, Cnl(Ai ) CNAS (Cnl(BDi )), 0 n. Hence Cnl(A) CNAS (Cnl(BD)).Theorem 5 Suppose ALAS satisfies self-contradiction axiom. cohesive.Proof Let inconsistent set arguments. Hence Cnl(Sub(S)) inconsistent. DefineBD set basic defeasible arguments Sub(S). clear BD 6= .lemma 4, follows Cnl(Sub(S) CNAS (Cnl(BD)). Hence CNAS (Cnl(Sub(S))) =CNAS (Cnl(BD)). Cnl(BD) therefore inconsistent. Since ALAS satisfies self-contradictionaxiom, Cnl(BD) CNAS (Cnl(BD)). Let B BDCnl(B) = . CNAS (Cnl(Sub(S))) = CNAS (Cnl(BD)), follows CNAS (Cnl(Sub(S))).compactness Sub(S) GN (S), follows argumentGN (S) Cnl(A) = . Hence attacks B. Since B BD Sub(S)GN (S), GN (S) conflicting.Lemma 51. AL closed contraposition, AL satisfies strong absurdity axiom.2. AL satisfies strong absurdity axiom AL satisfies self-contradictionaxiom.Proof103fiDung & Thang1. Suppose AL closed contraposition. Let X CON RA. Henceatom s.t. {a, a} X. CN ({a, }) literal ,closure contraposition property, follows CN ({a, a}). HenceCN (X) literal . proved L = CN (X) X CON RA.definition 10, follows AL satisfies strong absurdity axiom.2. Suppose AL satisfies strong absurdity axiom. Let X L X minimalinconsistent. Therefore CN (X) CON RA. idempotence axiomstrong absurdity axiom, CN (X) = L. holds obviously: X CN (X).Lemma 6 Let = (RS, RD) set strict rules RS closed transposition. ALAS satisfies self-contradiction axiom.Proof first prove following assertion.Assertion: Let strict argument X conclusion =6 P rem(A) X.P rem(A), argument B premises P rem(A) {}conclusion .Proof prove induction height (as proof tree).25height 0, theorem obvious.Suppose form A1 , . . . , Cnl(Ai ) = . Let P rem(A).Without loss generality, let P rem(An ). closure transposition, rule1 , . . . , n1 , n also belongs RS. Let B argument A1 , . . . , An1 ,n .induction hypothesis, proof tree r whose premises P rem(An ){n } whose conclusion .Let r tree obtained r replacing occurrence premise nargument B. clear P rem(T r ) P rem(A) {} Cnl(T r ) = .Let X L s.t. X minimal inconsistent. Hence two arguments A0 , A1premises X conclusions , respectively. minimality X,holds: X = P rem(A0 ) P rem(A1 ). Let X. Without loss generality, supposeP rem(A0 ). assertion, follows exists argument Bconclusion P rem(B) P rem(A0 ) {}. Let argument obtainedreplacing leaf labelled B tree A1 . clear P rem(A) Xconclusion .Appendix D. Section 5Theorem 6 ABA frameworks compact.Proof Let set arguments. Let SU = Sub(S) CSU = Cnl(SU ).need prove CN (CSU ) Cnl(GN (S)) (lemma 2). Let CN (CSU ). easysee argument (viewed proof tree) conclusion whose leaves25. height proof tree length (the number links) longest path root leafnode.104fiClosure Consistency Logic-Associated Argumentationlabelled sentences CSU . Expand proof tree leaf labelled CSUproof tree representing argument SU conclusion . new proof treecorresponds argument B conclusion . proof trees SU usedexpand obviously form base B. hence clear B generated S.Theorem 7 Let F ABA framework. ALF satisfies ab-self-contradiction axiom,F cohesive.Proof Let inconsistent set arguments. Hence supp(S) inconsistent. SinceCNF satisfies assumption-based self-contradiction axiom, supp(S)CNF (supp(S)). lemma 2, argument GN (S)Cnl(A) = . obvious attacks argument whose premises contain .Since GN (S), GN (S) hence conflicting.Appendix E. Section 6Lemma 81. Let set arguments AF1 argument AF1 . holds:acceptable wrt iff acceptable wrt Core(S).2. Let set arguments AF1 . admissible iff Core(S) admissible.Proof1. Since Core(S) S, acceptable wrt Core(S), obviously acceptable wrt S.Suppose acceptable wrt S. Let B attack A. Hence s.t.attacks B. Therefore assumption. Hence Core(S). B henceattacked Core(S), i.e. acceptable Core(S).2. Follows immediately previous assertion.Lemma 9. Let E, E complete extensions AF1 . holds:E = E iff Core(E) = Core(E )Proof need show Core(E) = Core(E ) implies E = E . reversedirection obvious. Let Core(E) = Core(E ) = S. Let E \ S. henceassumption acceptable wrt E. lemma 8, acceptable wrt S. Thus acceptablewrt E (lemma 8). Hence E . Similarly, could show assumption E \belongs E. thus proved E = E .Lemma 10 Let A, B AR0 AR0 . following observations hold:1. Cnl(A) = Cnl(C(A)).2. C one-one mapping AR0 onto AR1 \105fiDung & Thang3. (A, B) att0 iff (C(A), C(B)) att1 .4. admissible AF0 C(S) admissible AF1 .5. acceptable wrt iff C(A) acceptable wrt C(S)Proof1. first assertion obvious.2. obvious argument AR0 C(A) A.Viewing argument AR0 proof tree, height tree definedlength (i.e. number links) longest path root leaf. Let AR0,kset trees height k AR0 . prove induction C one-oneAR0,k .obvious C one-one AR0,0 . Suppose C one-one AR0,k . Let A, Btwo different arguments AR0,k+1 . last rules A,B differentobvious C(A), C(B) different. Suppose last rules A,B identical.A, B respectively forms A1 , . . . , / h, B1 , . . . , Bn / h.Without loss generality, assume A1 6= B1 . Hence inductionhypothesis, C(A1 ) 6= C(B1 ). Therefore C(A) 6= C(B).also straightforward prove induction B AR1 \ A,AR0 C(A) = B.3. (a) Suppose (A, B) att0 . Let B basic defeasible subargument Battacks B (on B ). two cases:i. Cnl(A) = Oj(Lr(B )) (undercut attack). Cnl(A) = Cnl(C(A)),follows Cnl(C(A)) = Oj(Lr(B)) Oj(Lr(B)) supp(C(B)). C(A)hence attacks C(B) wrt att1 .ii. Cnl(A) = h h = Cnl(B ). Hence Cnl(C(A)) = h hsupp(C(B)). C(A) hence attacks C(B) wrt att1 .(b) Suppose (C(A), C(B)) att1 . two cases:i. Cnl(C(A)) = Oj(r) defeasible rule r Oj(r) supp(C(B)).Cnl(A) = Cnl(C(A)), follows Cnl(A) = Oj(r) r defeasiblerule B. Hence basic defeasible subargument B BLr(B ) = r. Hence attacks B B AF0 .ii. Cnl(C(A)) = h h supp(B). Hence basic defeasiblerule r B hd(r) = h. Therefore subargument B BLr(B ) = r. Hence attacks B B (by rebutting) AF0 .4. assertion 3, clear conflict-free iff C(S) conflict-free.Suppose defends attacks. Let attack C(S) AF1 . Thereforeassumption. second assertion, B = C 1 (A). assertion3, follows B attacks S. Therefore attacks B. Hence C(S) attacks A.106fiClosure Consistency Logic-Associated ArgumentationSuppose C(S) defends attacks. Let attack AF0 . Let B = C(A).assertion 3, follows B attacks C(S). Therefore C(S) attacks B. Hence attacksA.5. Follows immediately assertion 3.Theorem 8 complete extensions E AF0 complete extension EAF1 vice versa following properties hold:1. C(E) = Core(E )2. literal l L0 , l Cnl(E) iff l Cnl(E )Proof Let E complete extension AF0 . assertion 4 lemma 10, follows= C(E) admissible. Let set assumptions acceptable wrt S. showE = complete. Let B AF1 acceptable wrt E . Suppose Bassumption. Let = C 1 (B). lemma 10, assertion 5, acceptable wrt E. HenceE. Therefore B S. B assumption, B . proved Ecomplete Core(E ) = C(E). uniqueness E follows directly lemma 9.Let l L0 l Cnl(E ). Since l 6 A, clear l Cnl(Core(E )). Hencel Cnl(C(E)). first assertion lemma 10, follows l Cnl(E).Theorem 9 AL0 satisfies self-contradiction axiom AL1 satisfies ab-selfcontradiction axiom.Proof Suppose AL0 satisfies self-contradiction axiom. Let X inconsistentset assumptions (AS). want show exists XCN1 (X). Suppose contrary. follows immediately atom{a, a} CN1 (X). two cases.Case 1: {a, a} =6 . Since 6 A, assumption. classical negationapply negation-as-failure literal, follows = Oj(d) RD.Oj(d) = CN1 (X), contradiction hypothesis 6 XCN1 (X). case hence occur.Case 2: {a, a} = . Therefore {a, a} X = . Let S1 set argumentsAR1 \ whose support subset X. {a, a} CN1 (X) \ X, follows S1 6= .difficult see Cnl(S1 ) = CN1 (X) \ X. Let S0 set argumentsAR0 S0 = C 1 (S1 ). Cnl(S0 ) = Cnl(S1 ), follows Cnl(S0 )closed (wrt CN0 ). also easy see Sub(S0 ) = S0 . Let BS set basicdefeasible arguments S0 . lemma 4, clear CN0 (Cnl(BS)) = Cnl(S0 ). Since{a, a} CN1 (X) \ X = Cnl(S0 ) = CN0 (Cnl(BS)), Cnl(BS) hence also inconsistentwrt AS. AL0 satisfies self-contradiction axiom, literal h Cnl(BS)h CN0 (Cnl(BS)). Let = h. h Cnl(BS), followssupp(C(BS)) supp(S1 ) = X. h CN0 (Cnl(BS)) = Cnl(S1 ) = CN1 (X) \ X,follows CN1 (X). Contradiction.proved AL1 satisfies assumption-based self-contradiction axiom.107fiDung & ThangAppendix F. Section 7Lemma 11 minimal conflict sets binary attack relation att contextsensitive, conflict-dependent symmetric LAF = (AF, , AL, Cnl) compactcohesive logic-associated argumentation framework.Proof show LAF logic-associated argumentation framework, need showA, B, C AR, C attacks B B C attacks A. B = A, nothing prove. Suppose B = ({}, ) supp(A). conflict-dependency,follows supp(C) {} inconsistent. Hence supp(C) supp(A) inconsistent.context-sensitivity symmetry attack relation, follows C attacks A.Let set arguments CN (Cnl(Sub(S))). Hence exists finiteX supp(S) CN (X). Let = (X, ). Let X = {({}, ) | X}.clear X Sub(S). show X base A. Suppose B attacks A. Henceconflict-dependency att, exists minimal conflict set {, } supp(A),supp(B). Hence B attacks argument ({}, ) X . Hence GN (S).proved CN (Cnl(Sub(S))) Cnl(GN (S). Hence lemma 2, AF compact.Let inconsistent set arguments. Hence supp(S) inconsistent. existsbinary minimal conflict set {, } supp(S). Hence arguments = ({}, ), B = ({}, )attack other. A, B GN (S), GN (S) conflicting.ReferencesAmgoud, L., & Besnard, P. (2009). Bridging gap abstract argumentationsystems logic. SUM, pp. 1227.Bondarenko, A., Dung, P., Kowalski, R., & Toni, F. (1997). abstract, argumentationtheoretic approach default reasoning. Artif. Intell., 93, 63101.Caminada, M., & Amgoud, L. (2007). evaluation argumentation formalisms.Artificial Intelligence, 171, 286310.Caminada, M., Carnielli, W., & Dunne, P. (2012). Semi-stable semantics. Journal LogicComputation, 22 (5), 12071254.Dung, P. M. (1995). acceptability arguments fundamental role nonmonotonic reasoning, logic programming n-person gamescceptability argumentsfundamental role nonmono- tonic reasoning, logic programming n-persongames. Artif. Intell., 77 (2), 321358.Dung, P. M., & Thang, P. M. (2011). Closure consistency rationalities logic-based argumentation. Balduccini, M., & Son, T. C. (Eds.), Logic Programming, KnowledgeRepresentation, Nonmonotonic Reasoning, Vol. 6565, pp. 3343. Springer.Garcia, A., & Simari, G. (2004). Defeasible logic programming: argumentative approach.TPLP, 4 (1-2), 95138.Gelfond, M., & Lifschitz, V. (1988). stable model semantics logic programming.ICLP/SLP, pp. 579597. MIT Press.108fiClosure Consistency Logic-Associated ArgumentationGelfond, M., & Lifschitz, V. (1990). Logic programs classical negation. ICLP, pp.579597. MIT Press.Governatori, G., Maher, M., Antoniou, G., & Billington, D. (2004). Argumentation semantics defeasible logic. J. Log. Comput., 14 (5), 675702.Lifschitz, V. (1999). Answer set planning (abstract). LPNMR, pp. 373374. MIT Press.Modgil, S., & Prakken, H. (2013). general account argumentation preferences.Artificial Intelligence, 195, 361397.Nielsen, S., & Parson, S. (2007). generation dungs abstract framework argumentation: Arguing sets attacking arguments. LNCS, No. 4766, pp. 5473.Springer Verlag.Pollock, J. (1995). Cognitive carpentry: blueprint build person.. MIT Press,Cambridge MA.Pollock, J. (1987). Defeasible reasoning. Cognitive Science, 11 (4), 481518.Prakken, H. (2010). abstract framework argumentation structured arguments.J. Arguments Computation, 1 (2), 93124.Prakken, H. (2012). reflection two current trends formal argumentation. Artikis, A., Craven, R., Cicekli, N. K., Sadighi, B., & Stathis, K. (Eds.), Logic Programs,Norms Action, Vol. 7360 Lecture Notes Computer Science, pp. 249272.Springer Verlag.Toni, F. (2008). Assumption-based argumentation closed consistent defeasible reasoning. JSAI, 390402.Wu, Y. (2012). Arguments Conclusions. Ph.D. thesis, University Luxemburg.109fiJournal Artificial Intelligence Research 49 (2014) 171-206Submitted 07/13; published 02/14Representing Reasoning RulesGeneral Games Imperfect InformationStephan Schielstephans@ru.isSchool Computer Science, Reykjavk University,Menntavegur 1, 101 Reykjavk ICELANDMichael Thielschermit@cse.unsw.edu.auSchool Computer Science Engineering,University New South Wales,Sydney, NSW 2052 AUSTRALIAAbstractgeneral game player system play previously unknown gamesgiven rules. purpose, Game Description Language (GDL)developed high-level knowledge representation formalism communicate game rulesplayers. paper, address fundamental limitation state-of-the-art methodssystems General Game Playing, namely, confined deterministic gamescomplete information game state. develop simple yet expressive extensionstandard GDL allows formalising rules arbitrary finite, n-player gamesrandomness incomplete state knowledge. second part paper,address intricate reasoning challenge general game-playing systems comesnew description language. develop full embedding extended GDLSituation Calculus augmented Scherl Levesques knowledge fluent . formallyprove provides sound complete reasoning method players knowledgegame states well knowledge players.1. IntroductionGeneral Game Playing (GGP) concerned development systems understand rules previously unknown games learn play games well withouthuman intervention. annual AAAI GGP Competition, established2005 foster research area, led number successful approaches systems (Kuhlmann, Dresner, & Stone, 2006; Clune, 2007; Schiel & Thielscher, 2007; Kaiser,2008; Finnsson & Bjornsson, 2008; Kissmann & Edelkamp, 2011; Mehat & Cazenave, 2011;Kirci, Sturtevant, & Schaeer, 2011). General game-playing programs quintessentialexample systems end users customise specific tasks. makesGGP interesting challenging problem AI, involving many fundamental issuesreasoning, learning, planning decision making (Pell, 1993). Consequently, GeneralGame Playing broader significance variety AI disciplines beyond conventionalcomputer game playing (Genesereth, Love, & Pell, 2005).c2014AI Access Foundation. rights reserved.fiSchiffel & Thielscher1.1 Representing Rules General Gamesfirst AAAI Competition saw introduction general Game Description Language (GDL) foundation general game-playing systems (Genesereth et al., 2005).machine-processable languages specification games existed before, notably Gala (for: Game Language). latter never used purposefront-end system computing optimal strategies game trees (Koller& Pfeer, 1997). Presumably tight coupling programming language (Prolog)operationalrather declarativesemantics prevented Gala adoptedothers system-independent game specification language.GDL allows description game finitely many players finitelymany legal moves state, moves deterministic fully observable,complete game rules known player. Simultaneous moves possible,provides restricted form imperfect information. However, players alwaysimmediately informed others moves hence always perfect informationgame state every round.GDL organisers AAAI GGP Competition sought high-level gamespecification language admits purely declarative reading. Thus, enables generalgame-playing systems reason rules previously unknown game, example, order extract game-specific knowledge automatically design evaluationfunctions. proved successful problems studied extensivelyrecent past (Kuhlmann et al., 2006; Kaiser, 2007; Clune, 2007; Schiel & Thielscher,2007; Edelkamp & Kissmann, 2008; Schiel & Thielscher, 2009; Ruan, van der Hoek, &Wooldridge, 2009; Schiel, 2010; Thielscher & Voigt, 2010). GDL purely declarativelanguage tradition AI Planning languages fact seen multi-agentextension thereof since existing planning languages always describe problem perspective single agenteven case adversarial planning (Jensen & Veloso, 2000).presence agents actions goals crucial since reasoningintentions basis Opponent Modelling, central aspect GGPgoes beyond AI Planning (Genesereth et al., 2005). GDL inherits existing planning languages compactness specifications, contrasts encodingtechniques, instance use propositionalised graphs (La Mura, 2000).Despite steady progress, current state art General Game Playing limiteddeterministic games complete information game state, owing restricted expressiveness original GDL. covers variety classic games Chess,Go, Chinese Checkers etc. excludes games elements chance like Backgammon;games information asymmetry Bridge Poker; games involve private communication among cooperating players like Bughouse Chess, negotiationslike Diplomacy. Moreover, envisaged applications General Game Playing systems,automated trading agents (Thielscher & Zhang, 2010), usually characterisedimperfect information.paper, lay foundations truly general game-playing systems developing analysing extension existing description language GDL-II (for Game172fiRepresenting Reasoning General GamesDescription Language Imperfect/Incomplete Information).1 GDL-II allowdescription extensive-form game finitely many players finitely manylegal moves state moves nondeterministic playersimperfect asymmetric information. Although GDL-II based assumption game rules fully known player, incomplete-informationgamesin game-theoretic sense (Rasmusen, 2007), is, players knowexactly goal type opponents arecan modelled extendedlanguage via standard Harsanyi (1967) transformation adding unobserved movenature beginning.1.2 Reasoning Rules General GamesGame descriptions GDL-II include precise specification informationplayers get throughout game. rules game imply anythingplayers use information, is, conclusions draw it,combine already know, whether memorise it. separatequestions concern reasoning game-playing agents perform basisrules game. clear separation two issues means that, example, perfectrecall (Rasmusen, 2007) property individual players depends reasoningmechanism implemented them, rather property game itself.basic GDL, players always informed others moves, reasoningrules game rather straightforward: simple, Prolog-like inference enginesuces compute ones everyone elses legal moves maintain completestate description throughout match (Genesereth et al., 2005). contrast, playingarbitrary games incomplete state knowledge poses intricate reasoning challengegeneral game-playing systems: Imperfect information information asymmetry requireplayer draw conclusions percepts entail currentposition, everybody elses possible moves, wellplayers may know.Action formalisms like classic Situation Calculus (McCarthy, 1963) developed precisely purpose. readily available, deploy GeneralGame Playing presupposes proper translation GDL-II existing, suitably expressive action language. Therefore, second part paper address problemreasoning GDL-II presenting full embedding extended general gamedescription language suitably extended variant Situation Calculus.1.3 Overview Resultsspecific contributions paper foundations General Game Playingsummarised follows:1. show addition two keywords GDL suces obtaindesired generality game description language: first, called sees, used1. unfortunate clash terminology, agent know full state environmentsaid incomplete information AI, whereas Game Theory, players know fullstate turn, game said imperfect information.173fiSchiffel & Thielschercontrol information player gets. second, called random, denotesspecial player chooses moves randomly.2. develop new execution model GDL-II demonstrate howdespiteconceptual simplicity representation languagethe operational semantics givesrise intricate epistemic model, provides players sucient informationenable reason knowledge knowledgeopponents, predict knowledge evolve, reasonplayers know players knowledge.3. develop new communication protocol GDL-II address practical issuesarise General Game Playing imperfect information.4. investigate expressive power high-level knowledge representation language relating mathematical concept extensive-form games (Rasmusen,2007).5. extend Situation Calculus includes Scherl Levesques knowledge fluent (Scherl & Levesque, 2003) multi-agent knowledge, simultaneous moves,new concept derived action predicates.6. present mapping GDL-II fully embedded extended SituationCalculus, formally prove provides correct axiomatic accountsemantics GDL-II, enables players draw conclusionsplayers knowledge past, present, future game states.paper proceeds follows. next section, introduce GDL-II extension GDL randomness imperfect information, use various examplesdemonstrate range phenomena games described new language.also develop modified execution model GDL-II. Section 3, showlanguage suciently expressive give rise intricate multi-agent epistemic model,relate language extensive-form games. Section 4, presentformal embedding language Situation Calculus prove correctnesstranslation. discuss related work Section 5 conclude Section 6.2. Describing General Imperfect-Information Games RandomnessGeneral Game Playing requires formal language describing rules arbitrary games.complete game description needs providenames players,initial position,legal moves aect position,terminating winning criteria.174fiRepresenting Reasoning General Gamesrole(R)init(F)true(F)legal(R,M)does(R,M)next(F)terminalgoal(R,V)sees(R,P)randomR playerF holds initial positionF holds current positionR move current positionplayer R moveF holds next positioncurrent position terminalR scores V points current positionR perceives P next positionrandom playerTable 1: GDL-II keywords. Standard GDL comprises top eight. keywordsaccompanied auxiliary, pre-defined predicate distinct(X,Y), meaningsyntactic inequality two arguments (Love et al., 2006).description language GDL developed purpose (Genesereth et al.,2005; Love, Hinrichs, Haley, Schkufza, & Genesereth, 2006). emphasis high-level,declarative game rules easy understand maintain. time, GDLprecise semantics fully machine-processable. Moreover, background knowledgerequireda set rules player needs know order able playpreviously unknown game.GDL based standard syntax semantics Logic Programming.special keywords used dierent elements game description mentioned above.original game description language GDL uses first eight keywords shown Table 1.version GDL suitable describing finite, synchronous, deterministicn-player game (Genesereth et al., 2005).2 execution model entails complete stateinformation: initial position fully specified players immediately informedothers moves, (joint) moves deterministic.Although GDL developed complete-information games only, surprisingly simpleextension syntax suces generalise arbitrary (discrete finite) gamesinformation asymmetry random moves.1. new keyword random introduced special role.assumed player always makes purely random choice among legalmoves position. allows game designer describe elements chance,rolling dice shuing cards.2. second new keyword sees(R,P) introduced specifying conditionsplayer R receives information (i.e., perceives) P.ensure greatest flexibility, arbitrary terms may serve percepts P.allow game designer players observe specific state features actions,games may also feature rules according players informed logical2. Synchronous means players move simultaneously. setting, turn-taking games modelledallowing players one legal move, without eect, turn.175fiSchiffel & Thielschercombinations conditions receive partial information state featuremove another player.language extension accompanied modified execution model,players longer informed others moves default; rather,get see game rules entail percepts.refer Table 1 list keywords new language GDL-II.2.1 ExamplesPrior giving precise definition syntax semantics illustrate expressivenessextended Game Description Language several examples; first thirdrecur later paper.2.1.1 Example 1 (Krieg-Tictactoe)rules Figure 1 describe standard Tic-Tac-Toe twist playerscannot see opponents moves, like chess variant Kriegspiel (Pritchard, 1994),hence name.3two roles initial position given lines 12 lines 47, respectively.moves specified rules head legal (lines 914): player whose turnattempt mark cell already tried earliergame. player noop , move without eect.position update specified rules head next (lines 1829):submitted move mark (M, N ) player R valid (where valid meanstargeted cell still blank; cf. line 16) every feature current position continueshold, change overall state tried (R, M, N ) becomes true.4Otherwise cell coordinates (M, N ) marked none cellschange. Moreover, control goes opponent.clauses head sees (lines 3133) say player whose turn alwaysinformed this. suces player perceive yourmove ,follows must opponents turn.!2.1.2 Example 2 (Coloured Trails)class games popular research test-bed decision-making negotiationcompetitive setting (Grosz, Kraus, Talman, Stossel, & Havlin, 2004). specific gamecomes one fixed protocols defining possible interactions among players.3. word notation: paper largely concerned semantics behind GDLgame descriptions, interpreted logic programs. reason use standardProlog syntax GDL, variables indicated uppercase letters. contrastcustomary KIF-notation GDL introduced Genesereth et al. (2005). KIF-syntax alsoallows disjunctions clause bodies, easily transformed normal logic programclauses (Lloyd, 1987). Throughout paper, use clause (game) rule interchangeably.4. important note dierence legal valid moves Krieg-Tictactoe: attemptmark cell considered legal, moves accepted valid actually possiblecurrent position. Feature tried (R, M, N ) used prevent player resubmitting previouslyrejected move.176fiRepresenting Reasoning General Games12role(xplayer).role(oplayer).34567init(control(xplayer)).init(cell(1,1,b)).init(cell(1,2,b)).init(cell(2,1,b)).init(cell(2,2,b)).init(cell(3,1,b)).init(cell(3,2,b)).init(cell(1,3,b)).init(cell(2,3,b)).init(cell(3,3,b)).891011121314legal(xplayer,mark(M,N)) :- true(control(xplayer)), true(cell(M,N,Z)),distinct(Z,x), true(tried(xplayer,M,N)).legal(oplayer,mark(M,N)) :- true(control(oplayer)), true(cell(M,N,Z)),distinct(Z,o), true(tried(oplayer,M,N)).legal(xplayer,noop):- true(control(oplayer)).legal(oplayer,noop):- true(control(xplayer)).1516validmove :- does(R,mark(M,N)), true(cell(M,N,b)).171819next(F):- validmove, true(F).next(tried(R,M,N)) :- validmove, does(R,mark(M,N)).20212223242526272829next(cell(M,N,x))next(cell(M,N,o))next(cell(M,N,Z)):- validmove, does(xplayer,mark(M,N)).:- validmove, does(oplayer,mark(M,N)).:- validmove, true(cell(M,N,Z)),does(R,mark(I,J)), distinct(M,I).next(cell(M,N,Z)):- validmove, true(cell(M,N,Z)),does(R,mark(I,J)), distinct(N,J).next(control(oplayer)) :- validmove, true(control(xplayer)).next(control(xplayer)) :- validmove, true(control(oplayer)).next(tried(R,M,N)):- validmove, true(tried(R,M,N)).30313233sees(R,yourmove) :- validmove, true(control(R)).sees(xplayer,yourmove) :validmove, true(control(oplayer)).sees(oplayer,yourmove) :validmove, true(control(xplayer)).Figure 1: GDL-II description Krieg-Tictactoe. game positions encodedusing three features control (R), cell(M, N, Z), tried (R, M, N ),R {xplayer , oplayer }; M, N {1, 2, 3}; Z {x, o, b}, b meaningblank. sake simplicity, omitted (straightforward) specification terminating conditions goal values.example, simple negotiation may consist player R oering player exchangetwo chips, C D. formalised GDL-II clauses:legal(R,propose(S,tradeChips(C,D))) :true(hasChip(R,C)), true(hasChip(S,D)), distinct(R,S).sees(S,offer(R,C,D)) :- does(R,propose(S,tradeChips(C,D))).rules communication private: addressee gets see oer. !177fiSchiffel & Thielscher2.1.3 Example 3 (Monty Hall)second running example, rules Figure 2 describe simple famous gamecar prize hidden behind one three doors candidate given twochances pick door. host modelled new pre-defined role random.5Lines 17 introduce players names state features hold initially.possible moves specified lines 917: First, random player decides placecar and, simultaneously, candidate chooses door. Next, host (i.e., random)opens door one car behind one candidatechosen. Finally, candidate either stick earlier choice (noop ) switchdoor still closed.candidates percept throughout game, viz. door gets opened,defined rule head sees (line 19). remaining clauses specify position update (lines 2131), fact game ends candidates final decision(line 33), payo candidate depending whether got door rightend (lines 3536).!2.1.4 Example 4 (Poker)Together two new keywords used describe kinds card games,typically characterised randomness (shuing) information asymmetry (individual hands). single card dealt face player, say, axiomatised thus:legal(random,deal(P,C)) :- role(P), in_deck(C),distinct(P,random).next(in_hand(P,C)):- does(random,deal(P,C)).sees(P,your_card(C)) :- does(random,deal(P,C)).Here, player dealt card see it. Multiple cards handedsingle move takes card separate argument playersget see argument positions correspond cards. contrast, card dealtface-up, Texas Holdem, would axiomatised follows.legal(random,deal_river(C)) :- in_deck(C).next(river(C)):- does(random,deal_river(C)).sees(P,river(C)) :- does(random,deal_river(C)), role(P).Here, players informed river card.!example game descriptions illustrate two new features GDL-II: specialrole random used model nature, always moves randomly. keyword seescontrols information players game state. Although playersfull knowledge game rules including initial state, imperfect asymmetricknowledge later states natural consequence players individual limitedpercepts.5. Although random pre-defined constant, needs declared role (line 2) goal(line 37). way GDL-II supports upward compatibility original GDL.178fiRepresenting Reasoning General Games12role(candidate).role(random).34567init(closed(1)).init(closed(2)).init(closed(3)).init(step(1)).89101112legal(random,hide_car(D)) :- true(step(1)), true(closed(D)).legal(random,open_door(D)) :- true(step(2)), true(closed(D)),true(car(D)), true(chosen(D)).legal(random,noop):- true(step(3)).1314151617legal(candidate,choose(D))legal(candidate,noop)legal(candidate,noop)legal(candidate,switch)::::-true(step(1)), true(closed(D)).true(step(2)).true(step(3)).true(step(3)).1819sees(candidate,D) :- does(random,open_door(D)).20212223242526next(car(D))next(car(D))next(closed(D))next(chosen(D))next(chosen(D))next(chosen(D))::::::-27does(random,hide_car(D)).true(car(D)).true(closed(D)), does(random,open_door(D)).does(candidate,choose(D)).true(chosen(D)), does(candidate,switch).does(candidate,switch),true(closed(D)), true(chosen(D)).28293031next(step(2)) :- true(step(1)).next(step(3)) :- true(step(2)).next(step(4)) :- true(step(3)).3233terminal :- true(step(4)).34353637goal(candidate,100) :- true(chosen(D)), true(car(D)).goal(candidate, 0) :- true(chosen(D)), true(car(D)).goal(random,0).Figure 2: GDL-II description Monty Hall game (Rosenhouse, 2009).2.2 Formal SyntaxGDL-II based standard syntax logic programs, including negation.Definition 1Consider signature function symbols (including constants) variables.term either variable, function symbol terms arguments.atom predicate symbol terms arguments.literal atom negation.179fiSchiffel & Thielscherclause form h :- b1 , . . . , bn ., h (the head) atomb1 , . . . , bn (the body) literals (n 0), meaning b1 , . . . , bn togetherimply h.GDL-II imposes following restrictions use pre-defined keywords Table 1.Definition 2dependency graph set G clauses directed, labeled graph whose nodes+q Gpredicate symbols occur G positive edge pcontains clause p(s) :- . . . , q(t ), . . . ., negative edge p q G contains clausep(s) :- . . . , q(t ), . . . . say p depends q G path p qdependency graph G.GDL-II game description finite set clausesrole appears facts (i.e., clauses empty body) body clauses;init appears head clauses depend true,legal, does, next, terminal, goal;true appears body clauses;appears body clauses, none legal, terminal, goaldepends does;next sees appear head clauses;distinct appears body clauses. 62.3 Valid Game Descriptionsorder admit unambiguous interpretation game, GDL-II descriptions must obeygeneral syntactic restrictions, inherited predecessor GDL.Definition 3constitute valid GDL-II description, set clauses G must satisfy following.1. G stratified, is, cycles involving negative edge dependencygraph G (Apt, Blair, & Walker, 1987; Gelder, 1989).2. G allowed, is, variable clause occurs least one positive atombody (Lloyd & Topor, 1986).3. p q occur cycle dependency graph G contains clausep(s) :- q1 (t1 ), . . . , q(v1 , . . . , vk ), . . . , qn (tn ).every vi {v1 , . . . , vk },vi ground,6. formal meaning predicate given tacitly assuming unary clause distinct(s, t).,every pair s, syntactically dierent, ground (i.e., variable-free) terms.180fiRepresenting Reasoning General Gamesvi element s,vi element tj (1 j n) qj appear cyclep.last condition imposes restriction combination function symbols recursion ensure finiteness decidability relevant derivations (Love et al., 2006).reader invited verify example game descriptions Figure 1 2 satisfyrequirements valid GDL-II description. syntactic restrictions ensure setgame rules eectively unambiguously interpreted state transition systemformal game model, describe next.2.4 Semanticsunique game model obtained valid GDL-II game description using conceptstable model logic program negation (Gelfond & Lifschitz, 1988).Definition 4set clauses G set ground atoms M, let GM set negation-freeimplications h b1 . . . bk obtained taking ground instances clauses Gdeleting clauses negative body literal bi bi M,deleting negative body literals remaining clauses.stable model G least model GM .useful property stable models provide unique model whenever underlyingset clauses stratified (Gelfond & Lifschitz, 1988), requirement valid GDL-IIspecifications according Definition 3. Moreover, syntactic restrictions GDL-IIensure model finite logic programs considera property inheritedoriginal GDL (Love et al., 2006). Hence, following game model GDL-IIassume finite set players, finite states, finitely many legal moves state.shall denote SM [G] unique stable model stratified set clauses G.Specifically, then, derivable instances keyword role(R) given gamedescription define players. initial state composed derivable instancesinit(F). order determine legal moves given state, stateencoded first, using keyword true. Let, end, = {f1 , . . . , fn } state (i.e.,finite set ground terms, a.k.a. fluents), game description G augmentedn factsdeftrue = { true(f1 )....true(fn ).}instances legal(R,M) derivable G true define legalmoves player R position . way, clauses terminalgoal(R,V) define termination goal values relative encoding givenposition.Example 2 (continued)rules Figure 1 entail Krieg-Tictactoe features two roles xplayer oplayer .181fiSchiffel & Thielscherinitial position 0 = {control (xplayer ), cell (1, 1, b), . . . , cell (3, 3, b)}. 0 trueadded rules infer legal(xplayer , mark (M, N )) combinationcoordinates M, N {1, 2, 3}, oplayer one move noop .!Determining position update percepts players requires encodingcurrent position move player. Suppose joint moveplayers r1 , . . . , rk take moves m1 , . . . , mk , letdef= { does(r1 , m1 )....does(rk , mk ). }Taken together, instances next(F) derivable G true composeupdated position. Similarly, derivable instances keyword sees(R,P) describeplayer perceives joint move played position .Example 4 (continued)According rules Figure 2, initial position Monty Hall game given0 = {closed (1), closed (2), closed (3), step(1)}. three legal movesplayer state, viz. hide car (D) random choose (D) candidate ,{1, 2, 3}. Consider, say, 1 = {random ( hide car (1), candidate ( choose(3)},0 trueadded game rules, clauses keyword next determine1updated state 1 = {car (1), chosen (3), closed (1), closed (2), closed (3), step(2)}. According clause keyword sees candidate perceives nothing stagehence cannot know car hidden behind door 1.!summarised following definition.Definition 5Let G valid GDL-II description. game semantics G state transitionsystem (R, 0 , T, l, u, I, g) givenroles R = {r : role(r) SM[G]};initial position 0 = {f : init(f ) SM[G]};terminal positions = { : terminal SM[G true ]};legal moves l = {(r, m, ) : legal(r, m) SM[G true ]};state update function u(, ) = {f : next(f ) SM[G true ]}, jointmoves states ;information relation = {(r, , , p) : sees(r, p) SM[G true ]};goal relation g = {(r, v, ) : goal(r, v) SM[G true ]}.182fiRepresenting Reasoning General Games2.5 New Execution Modeladditional elements GDL-II modified semantics require new executionmodel games incomplete state information randomness: Starting initialposition, state player chooses legal move. special random roleassumed choose randomly uniform probability among legal moves.7 Givenjoint move game state changes u(, ). contrast execution modelGDL (Genesereth et al., 2005; Love et al., 2006; Schiel & Thielscher, 2010), playersinformed joint move; rather role r R \ {random} gets seep satisfies I(r, , , p). game ends soon terminal state reached,goal relation determines result players. modified execution modelspelled Figure 3. straightforwardly implemented Game Master,runs game collecting moves, allows maintain actual game statethus compute percepts also determine end match resultinggoal values players.1. Send r R \ {random} GDL-II description informindividual roles r (e.g., xplayer oplayer ). Set := 0 .2. appropriate time, collect move mr player r R\{random}and, case random R, choose uniform probability element randomset {m : (random, m, ) l}. Set := {r1 ( mr1 , . . . , rk ( mrk }.3. Send r R \ {random} set percepts {p : (r, , , p) I}. Set :=u(, ).4. Repeat 2. 3. . Determine result v r R (r, v, ) g.Figure 3: Game play GDL-II given game (R, 0 , T, l, u, I, g).2.6 New Communication Protocolchanges execution model GDL GDL-II require modificationscommunication protocol Game Master program general game players.First all, Game Master inform players individual perceptsinstead joint move previous step. practical purposes, Game Masteralso confirm back individual move well current step game.information useful players become aware communication problems (suchdropped messages timeouts) able recover problems leastcases. order make transition GDL GDL-II easier, keepcommunication protocol defined Love et al. (2006) apply necessarychanges.7. Note necessarily mean resulting states equal probability. example,tossing unfair coin shows head probability 13 may axiomatised GDL-II threelegal moves random, two eect (the coin showing tails). stress basicGDL-II could easily extended syntactic means specifying non-uniform transition probabilities.183fiSchiffel & Thielschercommunication Game Master players happens HTTPmessages, players take role HTTP servers serve movesGame Master. body HTTP messages commands encoded usingKnowledge Interchange Format (KIF) (Genesereth, 1991). use messages START,PLAY STOP follows.(START <MATCHID> <ROLE> <DESCRIPTION> <STARTCLOCK> <PLAYCLOCK>)first message sent player. contains unique identifiermatch (<MATCHID>) informs player role game (<ROLE>),game rules (<DESCRIPTION>) well time constraints start-up phase(<STARTCLOCK>) submitting moves (<PLAYCLOCK>). Players supposedreply message string READY within <STARTCLOCK> seconds.message identical start message original GDL communicationprotocol.(PLAY <MATCHID> <TURN> <LASTMOVE> <PERCEPTS>)message sent player step match. informs playernumber moves far game (<TURN>), last move (<LASTMOVE>),percepts (<PERCEPTS>) according information relation .<TURN> 0 first play message increased one every subsequent stepgame. first play message, previous move, <LASTMOVE>NIL.Players supposed reply within <PLAYCLOCK> seconds next move.submit legal move time, Game Master make randomselection behalf. case <LASTMOVE> argument next message,informs player move, vital knowledge able continue.(STOP <MATCHID> <TURN> <LASTMOVE> <PERCEPTS>)message sent player last step match, is,terminal state reached. structure play message above.Players reply message string DONE.Note parameter <LASTMOVE> play stop messages necessarywant guarantee players always know move case dropped messagestimeouts. worth stressing information cannot provided gamerule like sees(R,lastmove(M)) :- does(R,M). clause redundant lightexecution model GDL-II Figure 3, implies players always choose,hence know, moves anyway.3. Expressive Power GDL-IIPercepts GDL-II arbitrary terms triggered arbitrary conditionscurrent state joint move. provides greater flexibility standard definitionsensing action planning domain description languages, agent learnstruth values one fluents (Golden & Weld, 1996; Petrick & Bacchus,184fiRepresenting Reasoning General Games2004). Observations GDL-II need related ones move, especiallyappropriate multi-agent setting, often players see something side-eectsomeone elses actions. point case rules 32 33 Figure 1. followsspirit behind general eect axioms GDL, is, rules next, also mayindependent specific move. simple example rules 2931 Figure 2.GDL-II descriptions solely concerned providing players objectivedescription rules game. puts contrast also standard axiomatisationsaction formalisms (Lakemeyer & Levesque, 1998; Thielscher, 2000; Scherl & Levesque,2003; Forth & Shanahan, 2004), observations described termsaect knowledge agent. game description language simpler regardagnostic players use percept draw inferences, combinealready know, whether remember it.conceptual simplicity describing observations GDL-II notwithstanding,language extension gives rise intricate epistemic model player can,principle, know position players knowledge. example,GDL-II rules Krieg-Tictactoe shown Figure 1 imply one cell carry xplayermark first round oplayer unable determine one. Moreover,provided perfect recall (Rasmusen, 2007) capable drawing rightconclusions, players know others knowledge lack knowledge,respectively. following, analyse formally semantics GDL-IIdescription execution model Figure 3 entail knowledge playerperfect reasoning capabilities point game play.3.1 Legal Play Sequencesbegin defining set possible ways game develop.Definition 6Consider game (R, 0 , T, l, u, I, g). legal play sequence12n0 1 . . . n1 nn 0 {1, . . . , n},joint move, i.e., mapping players r individual move, (r);(r, (r), i1 ) l r R (that is, players make legal moves);= u(i , i1 ) (position update).Furthermore, {0 , . . . , n1 } = , is, last state may terminal.following definition characterises precisely player perfect reasoningcapabilities principle know specific stage course game.Definition 7n12nn two legal playLet = 0 1 . . . n1 n = 0 1 1 2 . . . n1sequences game roles R, initial state 0 , information relation . playerr R \ {random} cannot distinguish if, if, following holds{1, . . . , n}.185fiSchiffel & Thielscher, p ) I}1. {p : (r, , i1 , p) I} = {p : (r, , i12. (r) = (r).Example 2 (continued)Let 1 initial state Krieg-Tictactoe, cells empty, considertwo legal play sequences:= 0{xplayer $mark (1,3),oplayer $noop}= 0{xplayer $mark (2,2),oplayer $noop}1{xplayer $noop,oplayer $mark (2,2)}{xplayer $noop,oplayer $mark (2,2)}12(1)2(2)Role xplayer distinguish already first round dierentmoves. contrast, oplayer finds two sequences indistinguishable step sincetook move, noop , got percept {yourmove} rule 30 Figure 1.Ultimately, however, oplayer also able distinguish (1) (2) because, accordinggame rules, second move perceives { } {yourmove} (whereattempted mark non-blank cell).!(In-)distinguishable play sequences used also ensure game descriptionsobey desirable properties following two, straightforward consequenceDefinition 7.1. game description roles R legality relation l entails playersalways know legal moves r R \ {random} two legalplay sequences , leading states n , n{m : (r, m, n ) l} = {m : (r, , n ) l}, indistinguishable r.2. game description roles R, terminal states , goal relation g entailsplayers know end game resultr R \ {random} two legal play sequences , leading states n , nn T, n{n , n } T, {v : (r, v, n ) g} = {v : (r, v , n ) g}, indistinguishable r.fair game always satisfy properties, proving newgame may dicult practice since general requires checking possible legalplay sequences. easy way around this, namely, adding sees-rulesalways inform players explicitly legal moves, termination, goal values.hand, games may especially designed test ability playerslogically infer legal moves highly incomplete knowledge.186fiRepresenting Reasoning General GamesExample 4 (continued)candidate axiomatisation Monty Hall game (cf. Figure 2) alwaysderive legal moves game ends. easily seen factdetermine value step fluent times. hand, candidatenever receives enough information able know result. example, cannotdistinguish two legal play sequences:= 0{candidate$choose door (1),random $hide car (1)}{candidate$choose door (1),random $hide car (2)}= 01{candidate $noop,random $open door (3)}{candidate $noop,random $open door (3)}122matter action candidate chooses end, result dierentgoal value .!Knowledge object level, considered thus far, lifted higherlevels determine players know others knowledge.possible GDL-II description game provides complete rules players,able derive information roles get see(hypothetical) legal play sequence. Formalising requires constructing suitableepistemic structure based possible play sequences. Consider, end, everyfunction K maps every pair (r, i) onto set legal play sequences player rstate cannot distinguish . Meta-level knowledge obtained follows.Definition 8game develops according , far player r knows, functions Kpossible indistinguishable r.Put words, meta-level knowledge characterised set possible sets legal playsequences. follows player knows holds K-sets considers possible.If, say, Krieg-Tictactoe match unfolds according example sequence(cf. (2)) xplayer knows oplayer knows cell (2, 2) marked.process iterated inductively determine arbitrary levels meta-knowledge,shows common knowledge game rules necessarily mean commonknowledge players. example, possible obtain situation 3-playergame player knows property f player B knows knowsf , player C considers possible knows nothing f : letmake move learns f game B (but C ) alwaysinformed moves.conclude analysis (in-)distinguishable play sequences proving GDL-IIprovides true extension GDL since game agents derive completestate every round easily specified GDL-II.Proposition 1 Consider game roles R random Rclause keyword seessees(R1,moves(R,M)) :- role(R1), does(R,M).two legal play sequences , length n 0indistinguishable r R.187fiSchiffel & ThielscherProof :induction n. n = 0 one legal play sequence, viz.initial game state 0 , establishes claim. induction step, supposetwo legal play sequences , leading states n+1 = n+1indistinguishable role r R. Definition 7 follows , shortenedone step indistinguishable player. induction hypothesis,possible identical step n. Hence, two legal play sequencesformn+1n1= 0 . . . n n+11n= 0 . . . nn+1n+1Definition 5 follows state update deterministic, hence n+1 = n+1impliesn+1 = n+1 . latter conjunction clause sees impliespercepts roles dier state n joint move n+1 taken instead n+1 .contradicts assumption indistinguishable role r,establishes claim.!3.2 GDL-II vs. Extensive Formvirtue state-transition semantics concept indistinguishable play sequences, every terminating GDL-II game understood so-called extensive-formgame. following, assume reader familiar basic notionmathematical game tree imperfect information (Rasmusen, 2007; Leyton-Brown &Shoham, 2008), based general concept information sets modelpartial observability information asymmetry. sees(R,P) predicate GDL-IIused equally generally. main reason percepts confined specificobservables (e.g., state features opponents moves) arbitrary symbols usedidentifiers desired information partition.3.2.1 GDL-II Extensive-Form Gamesgiven GDL-II game, corresponding extensive-form game obtained twosteps.1. Using arbitrary fixed order roles, joint moves GDL-II serialisedway player aware simultaneous moves players (Rasmusen, 2007).2. information sets player r identified set legal play sequencesplayer cannot distinguish.example, Figure 4 depicts extensive-form game thus obtained MontyHall game description Figure 2.important realise percepts GDL-II may sometimes provide informationcontained state nonetheless needs taken accountpartitioning nodes information sets. following example illustrates abilitysolve game may depend information.188fiRepresenting Reasoning General Games!1 1 1hide car(3)33 3hide car(2)!!!choose(1)choose(3)..choose(3)choose(1).choose(2)choose(2)!!!!!!open(3)open(2) open(3)open(2)open(3)open(3)open(1)open(1)11112 !2 !!! 2!! 2!!..................switchswitchnoopnoop!!!!hide car(1)100000101100Figure 4: Monty Hall game Figure 2 mapped onto extensive form (with nodesbranches omitted). numbers right indicate player ownsnodes height (0 = random, 1 = candidate ). Dotted lines connectnodes information set candidate.3.2.2 Example 5 (Spy & Spy)GDL-II Figure 5 describes game one spy sees three colouredwires used arm bomb. signal name colour second spy,tries disarm bomb. win second player cuts right wire loseotherwise. Hence, first spy every incentive help second spy,seems one obvious rational move, namely, signal colour wire.crux, however, game rules, colour signalled logicallyindependent colour wire used arm bomb. illustratedgame tree Figure 6: second player distinguish possible statesround 2, is, {armed (red ), step(3)} , {armed (blue), step(3)} ,{armed (green), step(3)}, would belong information set, mattercolour signalled. would leave players better choicemoving randomly.!3.2.3 Extensive-Form Games GDL-IIdescribe faithfully GDL-II (that is, move-by-move) game given extensive form,two issues need addressed.1. given information sets need encoded appropriate sees-rulesindividual players. achieved indexing sets always lettingowner see index nothing else.2. Non-uniform probabilities moves nature need mapped onto uniform probability distributions randoms moves. achieved introducing189fiSchiffel & Thielscher123role(spy1).role(spy2).role(random).4567colour(red).colour(blue).colour(green).89init(step(1)).10111213legal(random,arm_bomb(C)) :- colour(C), true(step(1)).legal(spy1,signal(C)):- colour(C), true(step(2)).legal(spy2,cut_wire(C)):- colour(C), true(step(3)).14151617legal(random,noop) :- true(step(1))legal(spy1,noop):- true(step(2))legal(spy2,noop):- true(step(3))181920sees(spy1,C) :- does(random,arm_bomb(C)).sees(spy2,C) :- does(spy1,signal(C)).21222324252627next(armed(C))next(armed(C))next(explosion)next(step(2))next(step(3))next(step(4))::::::-does(random,arm_bomb(C)).true(armed(C)).does(spy2,cut_wire(C)), true(armed(C)).true(step(1)).true(step(2)).true(step(3)).2829terminal :- true(step(4)).303132333435goal(spy1,100) :- true(explosion).goal(spy2,100) :- true(explosion).goal(spy1, 0) :true(explosion).goal(spy2, 0) :true(explosion).goal(random,0).Figure 5: GDL-II description cooperative Spy & Spy game.proportional number moves dierent names lead successor state.finite extensive-form game described GDL-II using single fluentindicate node game specifying arc tree statetransition. Using methods Schulte Delgrande (2004), shownresulting GDL-II description correct finite n-player game extensive formperfect recall. size description resulting transformation obviouslyorder original game tree since moves parallelised states encodedindividual objects rather factored atomic features. Hence, unlikeMonty Hall rules Figure 2, say, direct construction exploit concisenessdescriptions made possible high-level knowledge representation language.190fiRepresenting Reasoning General Games!1 1 1arm bomb(green)33 3arm bomb(blue)!!!signal(green)signal(red)..signal(red)signal(green).signal(blue)signal(blue)!!!!!!arm bomb(red)armed(red)step(3)armed(red)step(3)armed(red)step(3)armed(blue)step(3)armed(blue)step(3)armed(blue)step(3)Figure 6: game Figure 5 mapped onto extensive form (with nodes branchesomitted). Dotted lines connect nodes spy2 cannot distinguish. nodesdepth 3 identical states collapsed onto single node,would information set player.4. Logic Reasoning GDL-II GamesBuilding basic general game player, e.g. one knows move legally,relatively simple task restriction perfect-information games. generalcase, however, even basic game play much intricate problem. Recall, example,description Krieg-Tictactoe game Figure 1. rules lines 3133 specifyplayers percepts, indicating player control next informedfact. suces since players able always derive whetherturn. must capable inferringperceive yourmove , must opponents turn. Another example(strategically useful) inference would conclude cell must carry opponentsmarker tried mark perceive yourmove again, implyingattempt must unsuccessful.Drawing conclusions sort domain action theories, Situation Calculus oldest technique formalising automating reasoning actions (McCarthy, 1963). second part paper, lay foundations buildinggeneral game-playing systems capable reasoning imperfect information. Using existing techniques like Situation Calculus purpose requires full embeddinggame description language GDL-II formalisms.following, develop mapping based Situation Calculus variantuses special fluent represent knowledge agents (Scherl & Levesque, 2003).slightly modify extend formalism purposes. Generally speaking, Situation Calculus predicate logic pre-defined languageelements:constant s0 , denotes initial situation, along constructor Do(A, S)denote situation resulting action situation S;predicate Holds(F, S), denotes fluent F (i.e., atomic state feature)true situation S;191fiSchiffel & Thielscherpredicate Poss(A, S), denotes action possible situation S.4.1 Compound Actionsgames two players, positions updated consequence playersmoving simultaneously. adequate formalisation Situation Calculus thereforeneed identify concept action vector m1 , . . . , mk containing one moveplayer. given GDL-II description, domain moves implicitly determined(second) arguments keywords legal does; e.g. mark (M, N )noop Krieg-Tictactoe. Assuming arbitrary fixed order players, say(xplayer , oplayer ), define simple axiom identifies individual move player raction vector:(3)Act(ri , M1 , . . . , Mi , . . . , Mk ) = Mi .instance, Act(xplayer , mark (1, 3), noop ) = mark (1, 3).4.2 Derived Action PredicatesGiven GDL-II game description G, identify primitive fluents terms occurscope either keywords init(F), true(F), next(F); Figure 1control (R), cell (M, N, Z), tried (R, M, N ). derived fluents take domainspecific predicates depend true G. Derived fluents (Davis,1990) require successor state axioms truth-values fullydetermined game rules values primitive fluents fixed (successor)situation. keywords terminal goal(R,V) treated derived fluents too.addition, mapping GDL-II Situation Calculus requires introductionnew concept derived action predicate. domain-specific predicatesdepend true G. example validmove descriptionKrieg-Tictactoe (cf. line 16 Figure 1). Similar derived fluents, truth-valuederived action predicate fully determined game rules fixedvalues primitive fluents situation (compound) action takensituation.4.3 Mappingshow GDL-II description G mappedin modular wayintoSituation Calculus theory. First, atoms occur G rewritten follows.replaced f (X,S) derived action predicates1. derived fluents f (X)p(X,A, S), indicating dependence situation action A,p(X)8respectively.2. init(F ) replaced Holds(F, s0 ).3. true(F ) replaced Holds(F, S).4. next(F ) replaced Holds(F, Do(A, S)).8. mapping also applies derived fluents legal(R, ) , goal(R, V ) , terminal.192fiRepresenting Reasoning General Games5. does(R, ) replaced Act(R, A) = .example, clause line 16 Figure 1 becomesvalidmove(A, S) Act(R, A) = mark (M, N ) Holds(cell(M, N, b), S) .GDL-II game descriptions based negation-as-failure principle, is, everyproposition cannot derived game rules supposed false. reflectSituation Calculus theory, use completion (Clark, 1978) clausesreplace clauses G p headfollowing way: every predicate p(X),!= body .()X(4)p(X)p(t ):-body G,variables occurcontext use () abbreviationeither body X .4.3.1 Initial Situationtransformation defined yields following axiomatisation initial situation:!Holds(F, s0 )()F = body .init(t):-body G4.3.2 PreconditionsBased completion legal according (4), i.e.,!()R = r = body ,Legal(R, M, S)legal(r,m):-body Gdefine precondition axiom compound actions situations thus:Poss(A, S) R. Legal(R, Act(R, A), S) .(5)4.3.3 Effectsresult transformation above, obtain general successor state axiom (Reiter,1991) follows:!()F = body .(6)Holds(F, Do(A, S))next(t):-body G4.3.4 KnowledgeScherl Levesque (2003) use special fluent K(S , S)to read as: situationaccessible situation Sin order axiomatise knowledge states (of agent)Situation Calculus. use straightforward generalisation multi-agent case,K(R, , S) expresses player R considers possible situation S. allowsus formalise subjective knowledge similar Scherl Levesque thus:Knows(R, , S) = . K(R, , S) [S ] .def193(7)fiSchiffel & ThielscherHere, reified formula situation argument fluents suppressed;[S ] means situation arguments reinstated . example,Knows(xplayer , X, Y. cell (X, Y, b), s0 )stands . K(xplayer , , s0 )X, Y. Holds(cell (X, Y, b), ). express knowledgeplayer another players knowledge, macro definition (7) easily extendedform nested expressions,Knows(xplayer , Knows(oplayer , control (oplayer )), Do(mark (1, 1), noop , s0 )) .also possible define common knowledge group players propertyshared situations belonging reflexive transitive closure combinedaccessibility relations.GDL-II players complete knowledge initial situation. termsSituation Calculus,(8)K(R, S, s0 ) = s0 .eects actions percepts knowledge states players definedsuccessor state axiom special fluent K, adapt Scherl Levesquesdefinition follows:K(R, , Do(A, S)) , . = Do(A , ) K(R, , S)Poss(A , )Act(R, A) = Act(R, )P. Sees(R, P, A, S) Sees(R, P, , ) .(9)Put words, player considers possible situation joint move if,if, obtained situation conceivable S;executable ; player move A; players sensingresult , identical sensing result actual A, (so cannotdistinguish two).noted axioms (8) (9) postulate perfect recall commonknowledge game rules among players: actual situation Do(. . . , S0 )situations consistent players previous information accessible.Moreover, accessible situations form Do(. . . , S0 ) too, impliesevery situation belonging reflexive transitive closure combined playersaccessibility relations governed precondition eect rules describedaxioms (5)(6).4.4 Completion Semantics Stable Modelsaxiomatisation applies Clarks completion given set GDL-II game rules.general, however, first-order semantics completion (stratified) logic programweak fully characterise (unique) stable model presence redundantrules like validmove :- validmove. stable model remainssuperfluous clauses added, Clarks completion weakened them. example,mentioned rule (assuming clauses) stable model empty194fiRepresenting Reasoning General Gamesset, first-order semantics completion admits two modelsonevalidmode holds one false.issue resolved second-order axiom (Ferraris, Lee, & Lifschitz, 2011).Denoted SM [F ], axiom provides stable model operator arbitrary first-orderformulas F . operator SM [F ] defined following way:Definition 9= (U1 , . . . , Un ) list distinctLet P = (P1 , . . . , Pn ) list predicates U= P denote conjunctionpredicate variables length P . Furthermore, let U(X)Pi (X)= 1, . . . , n . UP denoteformulas X.U< P standsconjunction formulas X.Ui (X)Pi (X) = 1, . . . , n , U(U P ) (U = P ) .expression SM[F ; P ] stands second-order sentence.(U< P ) F (U) ,F U) defined recursively:F (UPi (t ) = Ui (t ) list terms;F = F atomic formula F contain members P ;(F G) = F G ;(F G) = F G ;(F G) = (F G ) (F G) ;(F ) = (F ) ;(F G) = (F G) (G F ) ;) = X.F;(X.F) = X.F.(X.FExpression SM[F ] shorthand SM[F ; P ] P list predicates F .models SM [F ] stable models F . Specifically, F completionstratified logic program, SM [F ] unique Herbrand model correspondsunique stable model logic program.last step translation therefore add axiom SM [F ] , Fconjunction rules transformed game description.noted Situation Calculus typically uses second-order inductionaxiom limit set situations smallest set containing s0 closedoperator. However, dierent SM [F ], induction axiom sucientenforce unique model presence redundant rules.195fiSchiffel & Thielscher4.5 Soundness Completenesstheory obtained transformation developed previous section indeedSituation Calculus theory, show now.Proposition 2 Let G valid GDL-II game description axiomatisationobtained transformation defined above. syntactically correctSituation Calculus theory.Proof :Situation Calculus theory, must include precondition axiomaction a(X) formS) (X,S) .Poss(a(X),S) must refer situation S. general preconThe formula (X,dition axiom (5), variable instantiated every compound action obtainaxiom form above. right-hand side (5) free variablescontains reference situation besides S.Furthermore, must contain successor state axioms primitive fluent f (X)following form:Do(A, S)) (X,A, S) .Holds(f (X),A, S) must refer situation S. generalAgain, formula (X,successor state axiom (6) variable F instantiated every primitive fluentobtain axiom form above. right-hand side (6) refers bodiesrules head next(F ). According syntactic restrictions GDL-II bodiesmay depend init next therefore indeed never refer situationbesides S.!show transformation previous section sound complete, is, GDL-II game description resulting Situation Calculus theoryequivalent terms knowledge inferred them. this, firstrecall Definition 6 notion legal play sequence:12n0 1 . . . n1 n .Intuitively, sequence interpreted situationDo(An , . . . , Do(A2 , Do(A1 , s0 )) . . .)Situation Calculus, joint move = {(r1 , m1 ), . . . , (rk , mk )} correspondscompound action Ai = m1 , . . . , mk . following theorem states givenstate joint move, GDL-II game rules Situation Calculus theory entailpropositions.Theorem 3 Let G valid GDL-II game description Situation Calculustheory obtained G translation defined above. Furthermore, let1n= 0 . . . n legal play sequence game corresponding situation= Do(An , . . . , Do(A1 , s0 ) . . .); joint move legal n ; compoundaction corresponding .GDL-II description, let translation Situationevery predicate p(X)A, S), examples given below.Calculus denoted p (X,196fiRepresenting Reasoning General Gamestruet (F, A, S) = Holds(F, S),A, S) = p(X,S) derived fluents,pt (X,A, S) = p(X,A, S) derived action predicates.pt (X,GDL-II description, p(X)SM [G ntrue ]every predicate p(X)|= p (X, A, S).Proof :theorem follows construction Situation Calculus theorySection 4.3 result Ferraris et al. (2011) according unique stable modelstratified logic program equivalent Herbrand model SM [F ] Fconjunction completion program.!main proposition states indistinguishable legal play sequences playercorrespond situations player considers mutually possible, vice versa.implies players use Situation Calculus theory reason knowledgepast, present, future positions well knowledge players.Proposition 4 Let G valid GDL-II description semantics (R, 0 , T, l, u, I, g)Situation Calculus theory obtained G translation definedabove. Let two legal play sequences1n= 0 . . . n ,n= 0 1 . . .ngame corresponding situations = Do(An , . . . , Do(A1 , s0 ) . . .) =Do(An , . . . , Do(A1 , s0 ) . . .). role r R cannot distinguish |= K(r, , S).Proof :prove proposition induction length n sequence .base case n = 0 one legal play sequencethe initial state 0corresponding initial situation s0 . Accordingly, (8), |= K(r, S, s0 ) = s0 ,proves base case.induction step, consider two legal play sequencesn+1+ = n+1n+1+= n+1corresponding situations Do(An+1 , S) Do(An+1 , ), respectively.indistinguishable r if, if,show + , +|= K(r, Do(An+1 , ), Do(An+1 , S)) .successor state axiom special fluent K (cf. axiom (9)), knowK(r, Do(An+1 , ), Do(An+1 , S)) if, if, following hold.(a) K(r, , S);(b) Poss(An+1 , );(c) Act(r, An+1 ) = Act(r, An+1 );197fiSchiffel & Thielscher(d) P. Sees(r, P, An+1 , S) Sees(r, P, An+1 , ).show one holds.induction hypotheses, (a) holds.definition legal play sequence (Definition 6) follows playersmove n+1 legal state n , is, players r,legal(r, n+1 (r)) SM [G ntrue ] .Theorem 3 conclude holds exactly |= Legal(r, n+1 (r), )players r. n+1 (r) = Act(r, An+1 ), equivalent right hand sideprecondition axiom (5) hence equivalent Poss(An+1 , ). Thus (b) follows.According Definition 7, provided indistinguishable role r, +indistinguishable r if, if,+{p : (r, n+1 , n , p) I} = {p : (r, n+1 , n , p ) I}n+1 (r) =n+1 (r)(10)(11)definition Act(r, A) (cf. (3)), Act(r, An+1 ) = n+1 (r) Act(r, An+1 ) =n+1 (r) . Thus, equation (11) holds (c).Definition 5, = {(r, , , p) : sees(r, p) SM [G true ]}. Thus,(r, n+1 , n , p) if, if, sees(r, p) SM [G ntruen+1 ] . Theorem 3,equivalent |= Sees(r, p, An+1 , S) . reasoning holds right handside (10). Thus, (10) holds case (d) holds.proves (a) (d) consequences induction hypothesis. Hence,,K(r, Do(An+1 , ), Do(An+1 , S)) holds if, if, r cannot distinguish + +concludes induction step proof.!4.6 Practical Considerationscompleteness result requires second-order axiom SM [F ] translated gamedescription. practice, avoided confine finitely manysituations. syntactic restrictions GDL-II imply every ground atom dependsfinitely many ground atoms; consequence restricted recursionaccording Definition 3. mapping extends GDL rules situation arguments,also finitely many ground instances considered Theorem 3legal play sequences fixed hence situations depth-restricted. casesuces consider finite subset R(P, F ) grounding program P decidewhether ground atom F entailed P (Bonatti, 2001). Thus, consider finiteground program replace second-order axiom propositional loop formulas (Lin &Zhao, 2004) reconcile semantics GDL-II Situation Calculus theory.solution applies whenever confine finitely many ground situationsreasoning problem hand.99. also remark issue actually little relevance practice General Game Playing;e.g. none numerous games played past AAAI Competitions featured logically redundantclauses players recognise.198fiRepresenting Reasoning General GamesAlthough points mind decidability reasoning issue, tractabilitystill is. possible construct game rules computing legal moves aloneexpensive kind planning ahead reasonable amount time. practicallyviable approach use sound incomplete proof methods (Haufe & Thielscher,2012; Thielscher, 2013).5. Related Worknew language GDL-II first extension existing GDL nondeterministicgames imperfect information. idea behind General Game Playing goesback early work Pitrat (1968) and, later, Pell (1993). define formal languagesdescribe whole classes games, languages even less general basicGDL perfect-information games. Earlier work also includes definition Galadescribing general games imperfect information (Koller & Pfeer, 1997).main dierence GDL-II Gala tightly coupled programming language(Prolog) therefore operationalrather declarativesemantics.mentioned also GDL-II draws concepts used ActionPlanning Languages (Lobo, Mendez, & Taylor, 2001) represent eects actionspresence incomplete knowledge. GDL-II seen generalising line workmulti-agent competitive settings.keyword sees introduced Game Description Language allowsus describe players percepts side-eects moves. dierent traditional modelling reasoning actions observations direct eects sensingactions (Scherl & Levesque, 2003; Thielscher, 2000; Lobo et al., 2001) especiallyappropriate multi-player games agents may see something without acted,e.g., observe players moves cards dealt.translation GDL-II Situation Calculus first full embeddingGDL-II action formalism; recent mapping (Thielscher, 2011) Action Description Language C+ (Giunchiglia, Lee, Lifschitz, McCain, & Turner, 2004) restrictedbasic GDL hence covers neither imperfect information games knowledgesensing. expect translation provide basis mappings GDL-IIexisting action languages, example, one developed Lobo et al. (2001).opens road full range applicable methods systems exist reasoningactions AI planning.Situation Calculus previously shown viable formalism representing reasoning games Schulte Delgrande (2004), also use SituationCalculus variant knowledge (Scherl & Levesque, 2003) axiomatise extensive-formgames. one hand, approach general dealinfinite games, assume perfect recall restricted uniform probabilitiesnatures moves. hand, restrictions make GDL-II compactaxiomatisation language focuses rules games rather reasonthem. addition, GDL-II state update semantics, general preferredusual regression semantics Situation Calculus performance reasons.limitation Schulte Delgrandes axiomatisation restriction knowledgefluent K(S , S) single agent (namely, player whose move situation S,199fiSchiffel & Thielscherassuming players move simultaneously). allow reasoningknowledge player situations, one agentconclude another agent would know. remedied recent definitionmulti-agent epistemic variant Situation Calculus axiomatising games (Belle &Lakemeyer, 2010). Despite notable dierences GDL-II variant SituationCalculus, e.g. restriction non-simultaneous moves augmentation domaintheory epistemic theory subjective knowledge, believe translationsimilar one presented paper constructed full GDL-IIembedded suitably adapted version Belle Lakemeyers approach.formalisms beside Situation Calculus reasoning knowledgeactions multi-agent environments, example, epistemic logic developed Belardinelli Lomuscio (2009). translation GDL-II formalism seems possiblemight interesting model checkers logic available (Lomuscio, Qu,& Raimondi, 2009).Several General Game Playing systems exist able play games encodedGDL-II (Schofield, Cerexhe, & Thielscher, 2012; Edelkamp, Federholzner, & Kissmann,2012). Although systems reason game well, focus liessolving specific reasoning tasks (such computing legal moves possible continuationsgame) time constraints.6. ConclusionOne reasons General Game Playing yet found many applicationsoutside game-playing area could, current state art restricteddeterministic games complete state information. Aiming overcoming limitation,defined conceptually simple yet powerful extension Game DescriptionLanguage representing rules general games information asymmetryrandom moves. shown GDL-II, notationally simple is, gives riseintricate epistemic model thus suces provide players information needreason knowledge well players frontgame play.argued language extension suces describe finite n-playergame extensive form perfect recall. shows purpose GeneralGame Playing language GDL-II considered complete; additional elementsserve obtain succinct descriptions (e.g., allowing explicit specificationsnon-uniform probabilities moves random) needed conceptGeneral Game Playing extended beyond current setting, e.g. open-worldgames Scrabble (Sheppard, 2002) systems play real, physical games (Barbu,Narayanaswamy, & Siskind, 2010).second part paper, presented embedding extended gamedescription language suitable variant Situation Calculus features multiagent knowledge, simultaneous actions, action-independent sensing. GDL-IIgame description defines observations players make throughout gameuse information, Situation Calculus axiomatisation tells players200fiRepresenting Reasoning General Gamesreason percepts entail current position,possible moves, players may know.central aspect work distinction objective informationone hand aects epistemic state agent hand. dierence manifests two key predicates paper: GDL-II keyword sees(R,P)describes objective information Knows(R, , S) Situation Calculus axiomatises subjective knowledge. distinction also present two semantics givenpaper: state transition systems model rules game environment Situation Calculus axiomatisations model information processing players. drawsconnection work general distinction often made AIfunctionality agents properties task environments (Russell & Norvig, 2010).Seen perspective, GDL-II extends GDL enables us describe largerclass game environments rule-based language. Meanwhile, Situation Calculus axiomatisation viewed model game-playing agents whose functionality includesperfect recall reasoning abilities. interesting direction future work developalternative Situation Calculus axiomatisations reasoning GDL-II games usestudy types agents, e.g. memoryless purely reactive, wellaspects bounded rationality game-playing programs (Russell & Wefald, 1991).Beyond General Game Playing therefore envision applications GDL-II AIareas game models arise, automated trading agents (Thielscher & Zhang,2010), Multiagent Planning (Larbi, Konieczny, & Marquis, 2007), Multiagent Systemsgeneral. general description language games kind potentially usefulwherever need compact high-level yet machine-processable specificationsproblem domains applications form games. Also potential usingavailable General Game Playing infrastructure systems developing testingnew games modelling, simulating, reasoning dynamic environments like,example, economic systems. However, additions language, arithmetic,might necessary allow concise descriptions domains. addition,GDL-II General Game Playing infrastructure used tools teachingAI development agent programs dynamic environments several universitycourses.10Acknowledgmentsthank Joohyung Lee anonymous reviewers earlier version paper thoughtful constructive comments. research supportedAustralian Research Councils (ARC) Discovery Projects funding scheme (projectnumber DP 120102023) Icelandic Centre Research (RANNIS, grant number 210019). second author recipient ARC Future Fellowship (projectnumber FT 0991348). also aliated University Western Sydney.10. material available www.general-game-playing.de/teaching/teaching.html201fiSchiffel & ThielscherReferencesApt, K., Blair, H., & Walker, A. (1987). Towards theory declarative knowledge.Minker, J. (Ed.), Foundations Deductive Databases Logic Programming, chap. 2,pp. 89148. Morgan Kaufmann.Barbu, A., Narayanaswamy, S., & Siskind, J. (2010). Learning physically-instantiated gameplay visual observation. Proceedings IEEE International ConferenceRobotics Automation (ICRA), pp. 18791886, Anchorage. IEEE Press.Belardinelli, F., & Lomuscio, A. (2009). Quantified epistemic logics reasoningknowledge multi-agent systems. Artificial Intelligence, 173 (910), 9821013.Belle, V., & Lakemeyer, G. (2010). Reasoning imperfect information gamesepistemic situation calculus. Fox, M., & Poole, D. (Eds.), Proceedings AAAIConference Artificial Intelligence, pp. 255260, Atlanta. AAAI Press.Bonatti, P. (2001). Reasoning open logic programs. Eiter, T., Faber, W., &Trusczynski, M. (Eds.), Proceedings International Conference Logic Programming Nonmonotonic Reasoning (LPNMR), Vol. 2173 LNCS, pp. 147159,Vienna. Springer.Clark, K. (1978). Negation failure. Gallaire, H., & Minker, J. (Eds.), Logic DataBases, pp. 293322. Plenum Press.Clune, J. (2007). Heuristic evaluation functions general game playing. ProceedingsAAAI Conference Artificial Intelligence, pp. 11341139, Vancouver. AAAIPress.Davis, E. (1990). Representations Commonsense Knowledge. Morgan Kaufmann.Edelkamp, S., Federholzner, T., & Kissmann, P. (2012). Searching partial belief statesgeneral games incomplete information. Glimm, B., & Kruger, A. (Eds.),Proceedings German Annual Conference Artificial Intelligence (KI), Vol.7526 LNCS, pp. 2536, Saarbrucken, Germany. Springer.Edelkamp, S., & Kissmann, P. (2008). Symbolic classification general two-player games.Dengel, A., Berns, K., Breuel, T., Bomarius, F., & Roth-Berghofer, T. (Eds.),Proceedings German Annual Conference Artificial Intelligence (KI), Vol.5243 LNCS, pp. 185192, Kaiserslautern. Springer.Ferraris, P., Lee, J., & Lifschitz, V. (2011). Stable models circumscription. ArtificialIntelligence, 175 (1), 236263.Finnsson, H., & Bjornsson, Y. (2008). Simulation-based approach general game playing. Proceedings AAAI Conference Artificial Intelligence, pp. 259264,Chicago. AAAI Press.Forth, J., & Shanahan, M. (2004). Indirect conditional sensing event calculus.de Mantras, R. L., & Saitta, L. (Eds.), Proceedings European ConferenceArtificial Intelligence (ECAI), pp. 900904, Valencia, Spain. IOS Press.Gelder, A. V. (1989). alternating fixpoint logic programs negation. Proceedings 8th Symposium Principles Database Systems, pp. 110. ACMSIGACT-SIGMOD.202fiRepresenting Reasoning General GamesGelfond, M., & Lifschitz, V. (1988). stable model semantics logic programming.Kowalski, R., & Bowen, K. (Eds.), Proceedings International Joint ConferenceSymposium Logic Programming (IJCSLP), pp. 10701080, Seattle. MIT Press.Genesereth, M. (1991). Knowledge interchange format. Allen, J. F., Fikes, R., & Sandewall, E. (Eds.), Proceedings International Conference Principles Knowledge Representation Reasoning (KR), pp. 599600, Cambridge. Morgan Kaufmann.Genesereth, M., Love, N., & Pell, B. (2005). General game playing: Overview AAAIcompetition. AI Magazine, 26 (2), 6272.Giunchiglia, E., Lee, J., Lifschitz, V., McCain, N., & Turner, H. (2004). Nonmonotoniccausal theories. Artificial Intelligence, 153 (12), 49104.Golden, K., & Weld, D. (1996). Representing sensing actions: middle ground revisited.Aiello, L. C., Doyle, J., & Shapiro, S. (Eds.), Proceedings InternationalConference Principles Knowledge Representation Reasoning (KR), pp. 174185, Cambridge, MA. Morgan Kaufmann.Grosz, B., Kraus, S., Talman, S., Stossel, B., & Havlin, M. (2004). influence socialdependencies decision-making: Initial investigations new game. Proceedings International Conference Autonomous Agents Multiagent Systems(AAMAS), pp. 782789, New York.Harsanyi, J. (1967). Games incomplete information played Bayesian players,IIII: Part I. basic model. Management Science, 14 (3), 159182.Haufe, S., & Thielscher, M. (2012). Automated verification epistemic properties general game playing. Brewka, G., Eiter, T., & McIlraith, S. (Eds.), ProceedingsInternational Conference Principles Knowledge Representation Reasoning(KR), pp. 339349, Rome. AAAI Press.Jensen, R., & Veloso, M. (2000). OBDD-based universal planning synchronized agentsnon-deterministic domains. Journal Artificial Intelligence Research, 13, 189226.Kaiser, D. (2007). Automatic feature extraction autonomous general game playingagents. Durfee, E., Yokoo, M., Huhns, M., & Shehory, O. (Eds.), ProceedingsInternational Conference Autonomous Agents Multiagent Systems (AAMAS),Honolulu.Kaiser, D. (2008). design implementation successful general game playingagent. Wilson, D., & Sutclie, G. (Eds.), Proceedings International FloridaArtificial Intelligence Research Society Conference (FLAIRS), pp. 110115, Key West.AAAI Press.Kirci, M., Sturtevant, N., & Schaeer, J. (2011). GGP feature learning algorithm. KIKunstliche Intelligenz, 25, 3542. Springer.Kissmann, P., & Edelkamp, S. (2011). Gamer, general game playing agent. KIKunstlicheIntelligenz, 25, 4952. Springer.Koller, D., & Pfeer, A. (1997). Representations solutions game-theoretic problems.Artificial Intelligence, 94 (1), 167215.203fiSchiffel & ThielscherKuhlmann, G., Dresner, K., & Stone, P. (2006). Automatic heuristic constructioncomplete general game player. Proceedings AAAI Conference ArtificialIntelligence, pp. 14571462, Boston. AAAI Press.La Mura, P. (2000). Game networks. Proceedings Conference UncertaintyArtificial Intelligence (UAI), pp. 335342, Stanford. Morgan Kaufmann.Lakemeyer, G., & Levesque, H. (1998). AOL : logic acting, sensing, knowing,knowing. Cohn, A. G., Schubert, L. K., & Shapiro, S. C. (Eds.), ProceedingsInternational Conference Principles Knowledge Representation Reasoning(KR), pp. 316327, Trento. AAAI Press.Larbi, R. B., Konieczny, S., & Marquis, P. (2007). Extending classical planningmulti-agent case: game-theoretic approach. Mellouli, K. (Ed.), ProceedingsEuropean Conference Symbolic Quantitative Approaches ReasoningUncertainty (ECSQARU), Vol. 4724 LNCS, pp. 6375, Hammamet. Springer.Leyton-Brown, K., & Shoham, Y. (2008). Essentials Game Theory. Synthesis LecturesArtificial Intelligence Machine Learning. Morgan & Claypool.Lin, F., & Zhao, Y. (2004). ASSAT: Computing answer sets logic program SATsolvers. Artificial Intelligence, 157, 115137.Lloyd, J. (1987). Foundations Logic Programming (second, extended edition). SeriesSymbolic Computation. Springer.Lloyd, J., & Topor, R. (1986). basis deductive database systems II. Journal LogicProgramming, 3 (1), 5567.Lobo, J., Mendez, G., & Taylor, S. R. (2001). Knowledge action description language. Theory Practice Logic Programming, 1 (2), 129184.Lomuscio, A., Qu, H., & Raimondi, F. (2009). MCMAS: model checker verification multi-agent systems. Proceedings International Conference Computer Aided Verification (CAV), Vol. 5643 LNCS, pp. 682688, Grenoble, France.Springer.Love, N., Hinrichs, T., Haley, D., Schkufza, E., & Genesereth, M. (2006). General GamePlaying: Game Description Language Specification. Tech. rep. LG200601, StanfordLogic Group, Computer Science Department, Stanford University, 353 Serra Mall,Stanford, CA 94305. Available at: games.stanford.edu.McCarthy, J. (1963). Situations Actions Causal Laws. Stanford Artificial Intelligence Project, Memo 2, Stanford University, CA.Mehat, J., & Cazenave, T. (2011). parallel general game player. KIKunstliche Intelligenz, 25, 4347. Springer.Pell, B. (1993). Strategy Generation Evaluation Meta-Game Playing. Ph.D. thesis,Trinity College, University Cambridge.Petrick, R., & Bacchus, F. (2004). Extending knowledge-based approach planningincomplete information sensing. Dubois, D., Welty, C., & Williams, M.A. (Eds.), Proceedings International Conference Principles KnowledgeRepresentation Reasoning (KR), pp. 613622, Whistler. AAAI Press.204fiRepresenting Reasoning General GamesPitrat, J. (1968). Realization general game playing program. Morrell, A. (Ed.),Proceedings IFIP Congress, pp. 15701574, Edinburgh.Pritchard, D. (1994). Encycolpedia Chess Variants. Godalming.Rasmusen, E. (2007). Games Information: Introduction Game Theory (4thedition). Blackwell Publishing.Reiter, R. (1991). frame problem situation calculus: simple solution (sometimes) completeness result goal regression. Lifschitz, V. (Ed.), ArtificialIntelligence Mathematical Theory Computation, pp. 359380. Academic Press.Rosenhouse, J. (2009). Monty Hall Problem. Oxford University Press.Ruan, J., van der Hoek, W., & Wooldridge, M. (2009). Verification games gamedescription language. Journal Logic Computation, 19 (6), 11271156.Russell, S., & Norvig, P. (2010). Artificial Intelligence: Modern Approach (3rd edition).Prentice Hall.Russell, S., & Wefald, E. (1991). Right Thing: Studies Limited Rationality. MITPress.Scherl, R., & Levesque, H. (2003). Knowledge, action, frame problem. ArtificialIntelligence, 144 (1), 139.Schiel, S. (2010). Symmetry detection general game playing. ProceedingsAAAI Conference Artificial Intelligence, pp. 980985, Atlanta. AAAI Press.Schiel, S., & Thielscher, M. (2007). Fluxplayer: successful general game player. Proceedings AAAI Conference Artificial Intelligence, pp. 11911196, Vancouver.AAAI Press.Schiel, S., & Thielscher, M. (2009). Automated theorem proving general game playing.Proceedings International Joint Conference Artificial Intelligence (IJCAI),pp. 911916, Pasadena.Schiel, S., & Thielscher, M. (2010). multiagent semantics Game DescriptionLanguage. Filipe, J., Fred, A., & Sharp, B. (Eds.), Agents Artificial Intelligence,Vol. 67 Communications Computer Information Science, pp. 4455. Springer.Schofield, M., Cerexhe, T., & Thielscher, M. (2012). HyperPlay: solution generalgame playing imperfect information. Proceedings AAAI ConferenceArtificial Intelligence, pp. 16061612, Toronto. AAAI Press.Schulte, O., & Delgrande, J. (2004). Representing von Neumann-Morgenstern gamessituation calculus. Annals Mathematics Artificial Intelligence, 42 (13),73101.Sheppard, B. (2002). World-championship-caliber Scrabble. Artificial Intelligence, 134 (12), 241275.Thielscher, M. (2000). Representing knowledge robot. Cohn, A., Giunchiglia,F., & Selman, B. (Eds.), Proceedings International Conference PrinciplesKnowledge Representation Reasoning (KR), pp. 109120, Breckenridge. MorganKaufmann.205fiSchiffel & ThielscherThielscher, M. (2011). Translating general game descriptions action language.Balduccinin, M., & Son, T. (Eds.), Logic Programming, Knowledge Representation,Nonmonotonic Reasoning: Essays Honor Michael Gelfond, Vol. 6565LNAI, pp. 300314. Springer.Thielscher, M. (2013). Filtering logic programs application general gameplaying. Proceedings AAAI Conference Artificial Intelligence, Bellevue.AAAI Press.Thielscher, M., & Voigt, S. (2010). temporal proof system general game playing.Fox, M., & Poole, D. (Eds.), Proceedings AAAI Conference ArtificialIntelligence, pp. 10001005, Atlanta. AAAI Press.Thielscher, M., & Zhang, D. (2010). general game descriptions market specification language general trading agents. David, E., Gerding, E., Sarne, D., &Shehory, O. (Eds.), Agent-Mediated Electronic Commerce: Designing Trading Strategies Mechanisms Electronic Markets, Vol. 59 LNBIP, pp. 259274. Springer.206fiJournal Artificial Intelligence Research 49 (2014) 403-449Submitted 10/13; published 03/14Mechanisms Fair Allocation Problems:No-Punishment Payment Rules Verifiable SettingsGianluigi Grecoggreco@mat.unical.itDipartimento di Matematica e InformaticaUniversita della CalabriaI-87036 Rende, ItalyFrancesco Scarcelloscarcello@dimes.unical.itDIMESUniversita della CalabriaI-87036 Rende, ItalyAbstractMechanism design considered context fair allocations indivisible goodsmonetary compensation, focusing problems agents declarations allocated goods verified payments performed. setting consideredverification might subject errors, payments awarded presumption innocence, incorrect declared values necessarily mean manipulationattempts agents. Within setting, mechanism designed showntruthful, efficient, budget-balanced. Moreover, agents utilities fairly determinedShapley value suitable coalitional games, enjoy highly desirable propertiesequal treatment equals, envy-freeness, stronger one called individual-optimality.particular, latter property guarantees that, every agent, her/his utilitymaximum possible one alternative optimal allocation.computational complexity proposed mechanism also studied. turns#P-complete that, deal applications many agents involved,two polynomial-time randomized variants also proposed: one still truthfulefficient, approximately budget-balanced high probability, anotherone truthful expectation, still budget-balanced efficient.1. IntroductionWhenever outcome social choice process depends information collectednumber self-interested agents, strategic issues may come play. Indeed, agentsmay find convenient misreport types, i.e., relevant informationprivate knowledge, (global) best possible solution missed.cases, mechanism design techniques used solution approaches, augmentcombinatorial algorithms appropriate monetary payments, aimed motivatingagents truthfully report private types (see, e.g., Nisan, Roughgarden, Tardos, &Vazirani, 2007; Shoham & Leyton-Brown, 2009).class social choice utilitarian problems, agent types encode (monetary) valuations set solutions goal compute solution maximizing socialwelfare, i.e., sum agents true evaluations. prominent role mechanism designproblems class played Vickrey-Clarke-Grove (VCG) paradigm (Vick-c2014AI Access Foundation. rights reserved.fiGreco & Scarcelloery, 1961; Clarke, 1971; Groves, 1973), general method designing truthfulmechanisms, i.e., mechanisms truth-telling dominant strategy agent.particular, VCG mechanisms efficient. is, guarantee solution maximizing social welfare actually computed. However, budget-balanced, i.e.,algebraic sum monetary transfers always zero mechanisms classrun deficit. fact, well-known drawback VCG mechanisms (see, e.g.,Archer & Tardos, 2007), essentially best one hope do, given classicalimpossibility theorems (Green & Laffont, 1977; Hurwicz, 1975) stating truthfulmechanism designed always efficient budget-balanced.many practical applications, however, payments agents performedfinal outcome known, kind verification reported types mightpossible. additional power considered classical mechanism-design settingand, fact, whenever verification allowed, impossibility results might longerhold. Mechanisms verification introduced Nisan Ronen (2001),considered verification task scheduling problem: agents declaringamount time need solve task, goal tasks solved,minimizing completion time last-solved one (hence, make-span).context, payments computed actual task release times observed,have, instance, ability punish agent whose declared abilityverified different actual performance process.Compared standard mechanisms (see, e.g., Nisan et al., 2007), verificationreceived considerably less attention literature (see, e.g., Nisan & Ronen, 2001;Auletta, De Prisco, Penna, & Persiano, 2009; Penna & Ventre, 2012a; Krysta & Ventre,2010; Ferrante, Parlato, Sorrentino, & Ventre, 2009; Penna & Ventre, 2012b; Auletta,De Prisco, Penna, Persiano, & Ventre, 2006; Auletta, Penna, Persiano, & Ventre, 2011).particular, works consider verification ability partial, sense agentsreporting restricted true types plus certain specific kinds deviations (e.g., valueslower true ones) verification focused detecting lies only.extension model recently proposed Caragiannis, Elkind,Szegedy, Yu (2012), assume a-priori restrictions agents reported types,within setting agent cheating her/his type caught probability may depend her/his true type, reported type, both. fact, despitedifferent facets verification power, mechanisms verification proposedliterature share idea providing incentives truthfully report private typesexploiting intimidation punishing agents caught lying. Moreover,budget limits considered approaches (see, e.g., Nisan & Ronen,2001), mechanism verification designed budget-balanced,focus truthfulness efficiency.paper, consider instead budget-balanced mechanism based modelverification restriction possible declarations (hence, arbitrarydeviations possible), nevertheless punishment used verificationprocess. design constraint guided real-world applications clearlyemerges punishing approach would hardly acceptable agents, unless clearproof deliberate malevolent behavior exhibited. Moreover, even casepunishment proportional amount discrepancy declared404fiMechanisms Fair Allocation Problemsverified values attributed malevolent behavior. resulting setting sharesspirit work Feige Tennenholtz (2011), observed possiblediscrepancies agents declarations third-party verified values oftendue different reasons, particular fact agents, malevolent,might still unable accurately collect and/or report information valuations.detail, Feige Tennenholtz (2011) considered scheduling problem singlemachine agent reports length her/his job scheduler needs finishmany jobs possible given deadline. Differently earlier literature, assumedagents uncertain job lengths, instance, limitedcomputational resources. Moving observation mechanisms verificationoften designed way performs well agents accurate informationprivate features, might perform arbitrarily bad agents uncertaininformation, Feige Tennenholtz proposed use forgiving mechanisms,punishments used enforce truthfulness. mechanisms appliedtwo models uncertainty: One probabilistic nature, another (calledqualitative private input) quantitative model explaining extentagents trust estimate, preference agent various lotteriesmight even inconsistent probability distribution.paper follow work Feige Tennenholtz (2011) particularqualitative model uncertainty. Moreover, addition subjective perspectiveproblem, uncertainty inherent private inputs, also take accountdual (objective) perspective, discrepancies declared verified valuesmight due errors occur verification process. Indeed, verificationpractically implemented sensing parameters become observablemechanism performed, sensing clearly affected errors (it unrealistic assumecarried arbitrary precision).fact, matter perspective (objective vs subjective) problemdiscussed analyzed, intrinsic limit mechanisms verification clearlyemerged: Whenever agent misreports her/his type detected verifier,punishing agent might effective mathematical studies, inappropriatereal life situations uncertainty inherent. Accordingly, therefore assumelimited use verification power given hand made. particular,goal paper design mechanisms based punishments (whilenonetheless resulting truthful, efficient, budget-balanced) tolerantmeasurement errors uncertain inputs, sense small errors determinesmall deviations outcome would obtained errors all.1.1 Mechanisms Fair Division Monetary Compensationconsider mechanisms verification context fair allocation problems (see,e.g., Moulin, 2003; Young, 1994; Thomson, 2011). assume given setindivisible goods allocated set agents. agent equipped private preference relation, encoded real-valued function (basically, monetaryvaluation) possible goodsformal definitions Section 2. agentallocated one good, case her/his evaluation additive them. More-405fiGreco & Scarcelloover, goods indivisible, i.e., good allocated one agent most. However,monetary transfers allowed, terms payments charged agents monetarycompensations provided them. goal find efficient allocation, is, allocation maximizing total value allocated goods, designing rules guaranteeingcertain desirable properties achieved, truthfulness individual rationality, i.e., agent ever worse she/he would without participatingmechanism. Moreover, want obtain outcomes politically acceptable.is, agents perceive designed mechanism fair one (see, e.g., Brandt, Conitzer,& Endriss, 2012), independently rules leading honest. instance,desirable agent envies allocation agent, selectedoutcome Pareto efficient, i.e., must different allocation preferredagents strictly preferred least one them.model and, particular, properties fair allocations indivisible objectsmonetary transfers studied, e.g., Svensson (1983), Bevia (1998), Maskin(1987), Tadenuma Thomson (1993), Meertens, Potters, Reijnierse (2002), Tadenuma Thomson (1991), Alkan, Demange, Gale (1991), Willson (2003), Su (1999),Yang (2001), Quinzii (1984), Sakai (2007). Moreover, procedures compute fair allocations proposed Aragones (1995), Klijn (2000), Haake, Raith, Su (2002),Brams Kilgour (2001), Potthoff (2002), Abdulkadiroglu, Sonmez, Unver (2004).None approaches listed above, however, guarantee elicitation honestpreferences agents. fact, question designing truthful fair mechanismsrecently considered well (Andersson & Svensson, 2008; Andersson, 2009; Svensson, 2009; Yengin, 2012; Ohseto, 2004; Porter, Shoham, & Tennenholtz, 2004; Shioura,Sun, & Yang, 2006). approaches, budget limits sometimes enforcedmechanisms defined cannot run deficit, budget-balance never guaranteed.Indeed, comes surprise, given truthful mechanism simultaneously fair (e.g., envy-free Pareto-efficient) budget-balanced (see, e.g., Tadenuma& Thomson, 1995; Alcalde & Barbera, 1994; Andersson, Svensson, & Ehlers, 2010).circumvent impossibility, approaches studied focus weakernotions truthfulness. instance, Andersson et al. (2010) Pathak (2013) considernotion degree manipulability used compare ease manipulation allocation mechanisms, whereas notion weak strategy-proofness consideredLindner (2010), i.e., cheating agents always risking actual loss, neverguaranteed cheat successfully.paper, depart settings studied earlier approaches,interested applications form verification available mechanismtime deciding monetary compensations among agents. particular, assumevaluations well allocation scenarios determined objective propertiesgoods agents observed measured verifier, allocationperformed payments computed. Note information allocatedgoods verified hence used mechanism. framework, classicalimpossibility results longer hold. Indeed, propose mechanisms allocation problemsenjoy number highly desirable properties, particular truthful, efficient,budget-balanced, individually rational, fair, even though agents verified incorrectdeclarations punished. Observe kind a-posteriori knowledge406fiMechanisms Fair Allocation Problemspayment time quite common many applications. also pointcases thorough verification could also performed advance, order get bestperformances independently agents declarations. However, practice doneeither money time restrictions, convenient allocate goodsbasis agents declarations (especially mechanism makes honest enough).Anyway, results used even full information known mechanism,provide fair division enjoying number desirable properties listed below.Appendix reports number examples possible applications proposedframework, including real-world case Italian research-assessment program,first motivated work.completeness, leave section recalling work, wellmentioned related literature, deals setting monetary transfers allowed.fact, fair division indivisible goods without money transfers also attracted attentionliterature. instance, topic studied Bouveret Lang (2008)points view compact representation (for expressing preference relations)computational complexity (of reasoning efficiency fairness conceptsresulting framework), Lipton, Markakis, Mossel, Saberi (2004) pointview defining approximation schemes envy-freeness. Finally, relevant pointthat, paper papers discussed above, allocations assumed computedcentralized way. However, might relevant cases adopt decentralizedapproaches, based successive negotiations goods (and money) groupsagents. reader interested distributed negotiation frameworks referred workSandholm (1998), Dunne, Wooldridge, Laurence (2005), Dunne (2005), Endriss,Maudet, Sadri, Toni (2006), references therein.1.2 Contributionspaper, study allocation problems strategic setting agents misreportprivate types, study mechanisms verification algorithmiccomputational complexity viewpoint.1.2.1 Algorithmic Issuesshow given setting none classical impossibility theorems discussedholds. particular, exhibit payment rule p turns optimal allocationalgorithm, i.e., algorithm computing optimal allocation given reported types,mechanism verification that:mechanism truthful. shown pointing number propertiesallocation problems interest own.mechanism efficient, budget-balanced, individually rational, envy-free, Paretoefficient.payment rule indifferent w.r.t. values (possibly misreports) declared goodsoccur allocation selected (and hence verified).407fiGreco & Scarcelloagent, her/his utility (when truthtelling) maximum one possibleallocations. particular, utility indifferent w.r.t. specific choice allocatedgoods optimal allocations. Note strong fairness property, immediately entails envy-freeness Pareto-efficiency.Verification used force truthfulness punishing agents whose reported values found different verified ones, mechanism forgiving sense recently discussed Feige Tennenholtz (2011). Moreover,mechanism shown tolerant discrepancies emerging declared typesverified/true ones. is, properties hold equilibrium agentsreport true types, also preserved approximatively case discrepancies,guarantee within constant factor distance declaredtypes verified/true ones. Note generally possible mechanismsbased punishment approaches where, enforce truthfulness, punishment mightdisproportional harm done misreporting (cf. Feige & Tennenholtz, 2011).Agents utilities distributed according Shapley value two suitably-associatedcoalitional gamessee, e.g., (Nisan et al., 2007), comprehensive introductionsharing problems coalitional games. fact, Shapley value prototypicalsolution concept fair division monetary compensations,1 desirable properties (games associated with) allocation problems extensively studiedliterature (e.g., Moulin, 1992; Maniquet, 2003; Mishra & Rangarajan, 2007).Note Shapely value studied mechanism-design contexts too,emphasis given pricing problem service provider (Moulin & Shenker,2001; Moulin, 1999; Jain & Vazirani, 2001): cost providing service functionsets customers, goal determining customers (andprice) receive it. model gives rise cross-monotonic cost-sharinggame, Shapley-value based sharing mechanisms defined truthfulbudget-balanced, achieve lowest worst-case loss efficiency utilityprofiles (Moulin & Shenker, 2001). respect, pricing rule p abstractlyviewed witness that, whenever (partial) verification possible, Shapley-valued basedmechanisms may also implemented loss efficiency all.1.2.2 Complexity IssuesComputing optimal allocation basis reported types easy task,carried via adaptations classical matching algorithms. However, one mightsuspect computing payments computationally-efficient, basedcomputation Shapley value. indeed challenging task involves iteratingpossible subsets agents. analyze issues, provide followingcontributions:show computing Shapley value allocation problems inherently intractable, fact, #P-complete. Note #P-hardness results problems involving1. Depending application, solutions concepts different Shapley value might appropriate. instance, bankruptcy problems, nucleolus considered appropriatesolution concept fair distribution (Aumann & Maschler, 1985).408fiMechanisms Fair Allocation ProblemsShapley value computation proven literature, instance, weightedvoting games (Deng & Papadimitriou, 1994), minimum spanning-tree games (Nagamochi, Zeng, Kabutoya, & Ibaraki, 1997), games associated normative systems (Agotnes, van der Hoek, Tennenholtz, & Wooldridge, 2009). Moreover, #Phardness results established Banzhaf power index, solutionconcept closely related Shapley value (see, e.g., Bachrach & Rosenschein, 2009,2008; Bachrach, Zuckerman, Wooldridge, & Rosenschein, 2013).Therefore, order deal also scenarios involving large number agents, twomodified rules, p p , presented, allow us employ fully polynomialtime randomized approximation scheme Shapley value computation. resulting polynomial-time mechanisms retain properties p . particular,mechanism based p universally truthful, efficient, high-probabilityapproximately budget-balanced. Instead, mechanism based p truthful expectation, always efficient budget-balanced.1.2.3 Organizationrest paper organized follows. Section 2 illustrates formal frameworkbasic concepts design mechanisms verification, whose desirable propertiesillustrated Section 3. payment rule p defined Section 4, connectionscoalitional games pointed Section 5. Rules p p defined Section 6,computational issues dealt with. comparison related works reportedSection 7, concluding remarks discussed Section 8. Finally, Appendixillustrates real-world case study application examples notions presentedpaper.2. Formal Frameworksection, define formal framework studying allocation problems basedmechanism design tools. particular, focus mechanisms equipped verificationability meets no-punishment perspective.2.1 Allocation Scenariosfocus allocation problems goods set G allocated setagents = {1, ..., n} way overall value allocated goods maximumfeasible allocations, is, social welfare maximized. precisely,allocation function : 2G mapping agent non-empty setgoods (i) G (i) (j) = , j 6= i. Moreover, given vectorupper-bound constraints = (1 , ..., n ) specifies maximum number goodsassigned agent A. tuple = hA, G, called allocationscenario. mapping : 2G feasible allocation scenarioallocation goods G agents that, agent A, |(i)| holds.Observe required goods G allocated agents.Note applications maximum number goods assignedagent represents ability (e.g., maximum number tasks she/he409fiGreco & Scarcelloexecute), hence next represent function = fu (i ), objectiveproperty agent (e.g., her/his speed) fu public-knowledge computable function.Note setting general earlier approaches literatureupper bounds fixed independent agents features.Moreover, paper assume value good g agent determinedobjective property g good, well property agent.Formally, assume good valuations encoded valuation vector w = (w1 , ..., wn )where, A, valuation function assigns good g G real valuewi (g) = fv (g , ), public-knowledge computable function fv .2idea verifier, best described next section, able measure,allocation goods agents performed, objective property gevery allocated good g objective property every agent. Therefore,using (public) function fv , possible compute values goodsassigned agent. believe assumption valuationsfunctions objective properties goods agents holds many applicationsallocation problems, particular social welfare maximized(since typically measurable value). provide examples Appendix A,including real-world application evaluation research activities Italy,originally motivated present work.Let us fix allocation scenario = hA,PG, valuation vector w = (w1 , ..., wn ).Let allocation. Definewi () =g(i) wi (g), A, denotePval(, w) overall value iA wi (). say optimal (for S) w.r.t. wfeasible allocation feasible allocation 0 val( 0 , w) >val(, w). value optimal allocation w.r.t. w denoted opt(S, w).allocation algorithm function mapping allocation scenariovector w feasible allocation A(S, w) S. algorithm optimal A(S, w)optimal allocation w.r.t. w, given pair (S, w).2.2 Strategic Issues Verificationconsider classical setting mechanism design optimal allocationscomputed context neither agent-depending upper bounds valuationvector w known allocation algorithm. Therefore, even optimal algorithmhand, enough information find optimal allocation, general.fact, assume usual agent privately knows certain features,called type, determining maximum number goods allocatedher/him, well function wi encoding her/his preferences allocations. Notethat, setting, type agent naturally consists her/his characterizing propertyplus property g , good g (s)he interested in. Section 3.2, also considerhappens agent may subjective, possibly incorrect, perceptionproperties (including her/his characterizing property ).2. Note that, sake simplicity, use two functions fu fv agents. However, nothingchanges paper consider slightly general version different agents maydifferent public functions.410fiMechanisms Fair Allocation ProblemsFigure 1: Running example Section 2.assume type agent taken set available types,denote cartesian product 1 n possible agents types. Then,consider direct revelation mechanisms agents asked report types letmechanism compute allocation. so, agents self-interested, strategicissues come play.agent A, hereinafter assume ti always denotes true typeagent i, i.e., type owned private knowledge, di her/his declaredtype. Then, = (t1 , ..., tn ) = (d1 , ..., dn ) vectors true declared types,respectively. general, happen coincide t, agents findconvenient misreport types.(true declared) type vector = (1 , ..., n ) , denote hereinafter= hA, G, allocation scenario , is, scenario vector= (1 , ..., n ) that, A, upper bound determinedtype . Similarly, denote w = (w1 , ..., wn ) valuation vector wivaluation function determined type , A.Example 2.1. Let us consider two agents, a1 a2 , type vector = (t1 , t2 ),allocation scenario St = hA, G, illustrated Figure 1(I) means intuitivegraphical notation, = {a1 , a2 }, G = {g1 , ..., g8 }, = (3, 3). Moreover, considervaluation vector w wt = (wa1 , wa2 ) that, edge connectinga1 (resp., a2 ) gj Figure 1(I), wa1 (gj ) (resp., wa2 (gj )) value associatedit. Otherwise, i.e., edge connecting a1 (resp., a2 ) gj , wa1 (gj )(resp., wa2 (gj )) negative number, say 1. Given setting, easily seenoptimal allocation St w.r.t. wt allocation (a1 ) = {g1 , g2 , g4 }(a2 ) = {g5 , g7 , g8 }see Figure 1(II). Note wa1 ( ) = 25 wa2 ( ) = 26.Consider allocation Figure 1(III). Note another optimal allocation. However, wa1 ( ) = 26 > wa1 ( ) wa2 ( ) = 25 < wa2 ( ).411fiGreco & ScarcelloFigure 2: Strategic manipulation.Example 2.2. Consider setting Example 2.1, type vector privateknowledge agents. Moreover, assume vector declared typesSd = St (the allocation scenario correct one) vector wd oneillustrated Figure 2(I), negative edges omitted. Basically, agent a2 truthfullyreports her/his type, agent a1 reports type values goods g2g3 underestimated. Therefore, wd 6= wt holds. optimal allocationSd w.r.t. wd shown Figure 2(II). emerges that, declarations agenta1 , convenient include g2 g3 . fact, coincides optimalallocation depicted Figure 1(III). Hence, misreporting type, agent a1guarantee overall value goods assigned her/him 26. Instead,truthfully reporting type, a1 might risk allocation selected,overall value goods assigned her/him 25.Finally, consider slight variant problem instance actual value goodg7 6 (instead 8) a2 . Then, egoistic behavior agent a1 also leadsallocation longer optimal. Indeed, due low declared values g2 g3 ,good g7 selected allocated a2 unique (wrong) optimal allocation, whosetotal value 49 (instead 51).paper, focus allocation problems kind verification reported types possible, objective properties agents goods observedmeasured (we say verified, hereinafter) third-party verifier allocationperformed. RecallSin general subset goods actually assigned agent. Denote set iA (i) G allocated goods img(). Thus, model,good g img(), objective property g verified, nothing saidnon-allocated hence non-observed goods. Moreover, agent participating mechanism, property determines upper-bound constraintpreferences good allocations verifiable, too. Thus, using verifier,correct allocation scenario restriction img() valuation functionsdetermined, formalized next.Definition 2.3. Let vector true types. Then, verifier v (for t) functionmapping allocation pair Sv() , wv() that:(1) Sv() actual allocation scenario St (in particular, true upper bound fu (i )computed verifier agent i);(2) wv() = (wv1 , ..., wvn ) vector that, agent A, wvi : img() Rfunction assigning good g img() actual value fv (g , ) agent412fiMechanisms Fair Allocation Problemsi. Observe that, definition framework, wvi coincides restrictionimg() valuation function wti : G R determined (true) type ti .2worthwhile noting verifier general unable discover whetheragent misreported her/his type, goods allocated undergomeasurement process. pinpoint actually case practical applications,measurements non-allocated goods may technically unfeasible simplyexpensive (in money time). refer reader Appendix A.1 (in particular, subsections A.1.1A.1.3) exemplification notions real-world case studyItalian research evaluation (VQR).Example 2.4. Consider setting Example 2.2, recall agent a1 findsconvenient underestimate true values g2 g3 . However, since g2 g3selected , see Figure 2(II), way discover a1actually misreported her/his type.cases, constraints allocation scenario depend specificapplication agents types, item (1) immaterial. generally,however, proposed setting allows us model classes problems types playrole even definitions upper-bound constraints.completeness, remark results paper easily shown holdeven allocation problems every agent must get minimum number goodsgreater one (defined specific application). However, sake presentationprefer keep standard setting non-empty set goods assignedagent, long her/his upper bound constraint met.2.3 Payment Rules Mechanisms Verificationorder encourage agents truthfully report private types, design mechanismsmonetary transfers performed, verification process.sake presentation, let us assume St = hA, G, allocation scenario(recall denotes vector true types), vector declared typesassociated allocation scenario Sd = hA, G, i, v verifier (for t).payment rule p defined vector functions (p1 , ..., pn ), pi (, wd , v)amount money given agent i, basis given allocation ,vector declared valuations wd , verifier v. Observe that, notation,negative value pi (, wd , v) means amount money charged i. Let wtvector (w1 , ..., wn ). Then, (quasi-linear) utility p, sometimes called individualwelfare, defined value ui,p (, wd , v) = wi () + pi (, wd , v). verifier valways understood, ui,p (, wd , v) pi (, wd , v) simply denoted ui,p (, wd )pi (, wd ), respectively. Moreover, whenever payment rule also understoodcontext, utility simply denoted ui (, wd ).payments computed verification process, define amountmoney pi (, wd ) paid agent i, exploit verifier v. Accordingly, desirablegoods allocated, hence verified, play role definitionpayments. latter property formalized below.413fiGreco & Scarcelloverifiability: Let d0 d00 two type vectors, let wd0 = (w10 , ..., wn0 ) wd00 =(w100 , ..., wn00 ) associated valuations. Moreover, let mappingfeasible allocation scenarios Sd0 Sd00 . Then, A, pi (, wd0 ) =pi (, wd00 ) whenever wi0 (g) = wi00 (g) holds every allocated good g img(). Therefore,d0 d00 undistinguishable far computation payments concerned,even differ unallocated goods. is, payment rule dependsgoods subject verifier evaluation.mechanism verification pair (A, p), allocation algorithmp payment rule exploit verifier v. mechanism (A, p) viewedconsisting following two-phases: First, agents report declaration vector d,feasible allocation = A(wd ) Sd computed. Second, v() made available,payments given rule p calculated respect allocationvaluations wd , exploiting knowledge v(). goal design payment rule pguaranteeing declared types lead allocation maximizing social welfare,i.e., optimal allocation St w.r.t. wt . might problematic as,setting, even fact feasible allocation St guaranteed,allocation scenario depends types agents might St 6= Sd .order accomplish goal, use optimal allocation algorithm A,need p encourages agents truthfully report private types. Formally,type vector = (1 , ..., n ) type , A, let (i , )type vector (1 , ..., i1 , , i+1 , ..., n ) . Then, shall consider following concepttruthful mechanism.Definition 2.5. Let (A, p) mechanism verification, let agent A.say dominant strategy agent w.r.t. (A, p) if, type vector ,ui (A(w(i ,i ) ), w(i ,i ) ) ui (A(w ), w ) holds. mechanism (A, p) truthful if,A, ti dominant strategy.2Example 2.6. Consider setting discussed Example 2.2, trivial paymentrule p payment actually performed. Consider optimal allocation(for St w.r.t. wt ) depicted Figure 1(II), note ua1 ( , wt ) = 25. Instead,allocation depicted Figure 2(II), ua1 ( , wt ) = 26, uniqueoptimal allocation Sd = St w.r.t. wd , = (da1 , ta1 ).Therefore, mechanism (A, p ), optimal allocation algorithmA(wt ) = , truthful. generally, optimal allocation algorithm A,example witnessing (A, p ) truthful easily defined suitably adaptingabove. Hence, non-trivial payment rules necessary encourage agents truthfullyreport types.comparison approach verification existing ones reported Section 7.3. Properties (Truthful) Mechanismssection, discuss desiderata mechanisms lead fair allocationstolerant uncertain inputs. Note design mechanisms abledeal two issues interest even settings strategic, i.e., even414fiMechanisms Fair Allocation Problemsgranted agents truthfully report types. Exemplificationsproposed notions reported Appendix A.1.4, completes description casestudy regarding Italian research evaluation (VQR). examples describedAppendix A.2 Appendix A.3.3.1 Fairness Issues Desirable PropertiesLet (A, p) truthful mechanism verification. paper, focus number(ex-post) properties mechanism, checked equilibrium agentstruthfully report private types.(allocative) efficiency: A(wt ) optimal allocation St w.r.t. wt . is, socialwelfare maximized.individual rationality: ui (A(w(ti ,i ) ), w(ti ,i ) ) 0, agenttype vector agents \ {i}. Hence, voluntary participation agenttake part allocation problem encouraged (independently whetheragents actually report true types not).P(strong) budget-balance: iA pi (A(wt ), wt ) = 0. words, transfermoney scenario.envy-freeness: pair agents i, j A, feasible allocation St(i) A(wt )(j) 6= , ui (A(wt ), wt ) ui (, wt ).Pareto-efficiency: feasible allocation St that: (1) ui (, wt )ui (A(wt ), wt ), agent A, (2) agent j uj (, wt ) >uj (A(wt ), wt ). is, A(wt ) Pareto-dominated allocation.equal treatment equals: pair agents i, j = j wi = wj ,wt = (w1 , ..., wn ), must case ui (A(wt ), wt ) = uj (A(wt ), wt ).individual optimality: ui (A(wt ), wt ) ui (, wt ), feasible allocation St .Note properties make sense even settings strategic,goal compute fair allocation. Indeed, setting strategic,agents report true types, even without monetary incentive. However, withoutpayments, fairness cannot achieved general: think, instance, scenariotwo agents, a1 a2 , one good g value agents.case, matter optimal allocation considered (where g assigned either a1a2 ), one two agents would envy other. makes clear payment rulesplay role encourage agents reports true types, alsocrucial induce agents perceive given allocation fair one. fact,properties, last, classically considered context fair allocationproblems, also absence strategic issues.Here, additionally considered individual optimality, readily seenimply envy-freeness Pareto-efficiency. also entails unique possible415fiGreco & Scarcellovector utilities agents. particular, means agents utilities sensiblepossible alternative allocations, hence independent specific set allocatedgoods selected optimal algorithm A.Example 3.1. Consider trivial payment rule p discussed Example 2.6. Consideroptimal allocation depicted Figure 1(II), compare allocationFigure 1(III). Recall another optimal allocation (for St w.r.t. wt ). Moreover,p , ua1 ( , wt ) = 25 ua1 ( , wt ) = 26 hold. Therefore, optimization perspective choice immaterial, a1 might good argumentscomplain selected place . fact, p individually optimal.Individual optimality definitely desirable requirement, still miss something. Indeed, notice property trivially satisfied fully uniform paymentrule, guarantees agent gets utility, matter her/his valuationgoods. course, desirable general. Rather, meritocracy somehowaddressed, true fair rule reflect actual contribution agentoverall value allocation.Let allocation St , necessarily optimal one w.r.t. wt , definemarginal contribution non-empty set C agents w.r.t. wt value:marg,wt (C) = opt(hA, img(), i, wt ) opt(hA \ C, img(), i, wt ).(1)words, marginal contribution marg,wt (C) agents C assesses lossoverall value would register agents C part problem.Example 3.2. Consider setting Example 2.1 optimal allocation Figure 1(II). Note marg ,wt ({a1 }) = marg ,wt ({a2 }) = 51 26 = 25. Therefore, twoagents (viewed singletons) marginal contribution, defining paymentrule leads utilities equally sharing overall value 51 natural option.Consider different setting, true types induce allocation scenarioSt vector wt , valuation good g8 agent a2 ,110 instead 10. case, would still remain optimal allocation, overallvalue 151. Moreover, marginal contribution a1 affected modification,marginal contribution a2 would become 151 26 = 125. witnesses a2contributes a1 , payment rule leading equally sharing overall valuelonger perceived fair one.intuition conveyed example formalized via followingrequirement.Pmarginality: non-empty set C agents,iC ui (A(wt ), wt )margA(wt ),wt (C). Hence, group agents gets least marginal contributiongiven allocation.3.2 Sensing Errorsconclude presentation (strategic) setting fair allocation problems illustrating subtle issues arising process verification. starting point416fiMechanisms Fair Allocation Problemsdiscussion observation verifiers practically implemented sensingparameters (in setting parameters , agent i, g , allocatedgood g) become observable allocation performed that, real-worldapplications, sensing subject errors; instance, limited precisionmeasurement instruments. Therefore, unrealistic assume verifieralways able exactly discover (i.e., arbitrary precision) actual upper boundsscenario St valuation vector wt , might problematic decide whetherobserved discrepancy verified values declared ones due strategicbehavior sensing errors. fact, sensing troubles arise even settingsrelevant information available public knowledge acquired via sensingenvironment, i.e., even getting rid strategic consideration.discussed Introduction, issue pointed recent workFeige Tennenholtz (2011), though slightly different perspective. There, observed mechanisms verification often designed way performs wellagents accurate information private inputs, might perform arbitrarilybad agents uncertain private features. Uncertainty mightresult hardware measurement errors, due limited computational resourcesemployed agents identifying declared valuations. instance, setting,type agent consists her/his characterizing property plus property g ,good g (s)he interested in. According perspective Feige Tennenholtz(2011), agent might estimate type. instance, agent mightenough computational resources precisely determine properties ggoods g, type actually represent subjective perception them.light observations, clearly emerges punishing agents mighteffective mathematical studies, inappropriate real life situationsuncertainty inherent due measurements errors uncertain inputs. Therefore, addition requirements discussed far, another desirable property mechanismuse punishment (or forgiving, sense Feige & Tennenholtz, 2011).punishment: type vector , feasible allocation ,agent A, case pi (, w ) = pi (, w(ti ,i ) ). is, discrepanciesgiven type (possibly declared) true/verified oneimpact payment agent i. words, may think paymentsalways computed presumption innocence, incorrect declared valuesmean manipulation attempts agents.Moreover, admit sensing errors (or uncertain inputs) might occur,relevant quantitatively assess impact, too. Ideally, would like dealmechanisms tolerate errors, sense small errors determinesmall deviations outcome would obtained errors all. Notegenerally possible mechanisms based punishment approaches where,enforce truthfulness, punishment might disproportional harm donemisreporting (cf. Feige & Tennenholtz, 2011). next formalize final desideratum.type vector , set C agents, set G0 G goods,let us define hC, G0 , restriction scenario hA, G, agents C417fiGreco & Scarcellogoods G0 considered.3 Moreover, given two type vectors , denote[, ] set type vectors form (X1 , ..., Xn ), Xi {i , },A. Then, distance dist w (, ) valuation vector w(or dist(, ), w understood context) defined looking worstpossible impact type vectors [, ] may optimal solutions computedpossible restrictions given setting:dist w (, ) =maxCA, G0 G, 0 , 00 [,]|opt(hC, G0 , 0 i, w0 ) opt(hC, G0 , 00 i, w00 )|.Now, recall truthful mechanism always convenient agents reporttrue types. Assume however agents declare type vector differenttrue type vector t.4 consequence, get revealed setting St valuation vectorwt = (w1 , ..., wn ), available verifier v discloses information scenario Stvector wt = (w1 , ..., wn ) (restricted allocated goods). standard mechanismsdesign settings (and particular punishment approaches), guaranteeproperty could given case, mechanisms designed analyzedreports truthful. Instead, would like mechanisms tolerant sensingerrors, formalized below.error tolerance: constant c 0 that, type vectoragent A, |ui (A(wt ), wt ) ui (A(wt ), wt )| c dist(t, t).Intuitively, error tolerant mechanism, consequences errors goodallocation outcomes produce linear distorting effect agents utilities (and, turnvarious properties mechanism). particular, property statedwithout assumption sensing errors come play. Indeed, notiondist(t, t) formalizes errors global perspective. instance, requireerrors affect uniformly valuations agents, might well caseerrors biased towards specific agent.4. Mechanisms Verification Allocation Problemssection, introduce mechanism verification allocation problems startanalysis, preliminary proving properties hold optimal allocations.4.1 General Properties Allocation ProblemsLet given type vector, consider allocation scenario = hA, G, i,= (1 , ..., n ), together valuations given w = (w1 , ..., wn ). start3. Note little abuse notation: vector hC, G0 , fact restriction C. However,keep notation simple, write , confusion may arise. Similarly, valuation vectorw transparently considered valuation vector subset agents C Aweget rid unused components associated agents \ C.4. property discussed perspective uncertain inputs. adaptation caseverification errors (or case types errors occur) easy task, mainlymatter different interpretation concepts.418fiMechanisms Fair Allocation ProblemsFigure 3: One-good version allocation problem Example 4.1, two allocationsassociated update graph, defined proof Theorem 4.4.graphical representation, crossing lines represent edges bipartite cliquesconnecting two groups virtual agents goods interested in.observing optimization problem used allocate goods agents equivalently reformulated way precisely one good allocated agent.Intuitively, may replace agent fresh agents valuations i.remark equivalence used combinatorial optimization purposes,i.e., without affecting game theoretic issue.Let us formalize intuition. First, denote S1 one-good versionhA1 , G, 1i scenario , where:A1 set agents iA clones(i) agent A, clones(i)set fresh agents;1 vector components 1.Moreover, denote w1 vector agents A1 where, agent c A1 ,component wc1 associated c wc1 = wi , agentc clones(i) holds. Thus, allocation problem S1 consideringvector w1 , clone c clones(i) gets exactly one good, valuationsagent w .Example 4.1. Consider scenario St = hA, {g1 , ..., g8 }, i, = {a1 , a2 },vector wt = (wa1 , wa2 ) discussed Example 2.1. one-good version scenarioSt1 = hA1 , {g1 , ..., g8 }, 1i shown Figure 3(I). Note set agents scenarioA1 = {(a1 )1 , (a1 )2 , (a1 )3 , (a2 )1 , (a2 )2 , (a2 )3 }, clones(ai ) = {(ai )1 , (ai )2 , (ai )3 },1{1, 2}. Indeed, recall = (3, 3). Finally, vector wt1 w(a=1 )h1wa1 (resp., w(a2 )h = wa2 ), h {1, 2, 3}.419fiGreco & ScarcelloNow, consider scenario hC, G0 , i, i.e., restriction hA, G, agentsC goods G0 considered, let C1 allocationone-good version001GhC, G , . Consider function C : C 2 C (i) = cclones(i) C1 (c),A. Note |C (i)| , A. Therefore, C feasible allocationhC, G0 , i, denoted -good(C1 ). Moreover, construction, val(C , w ) = val(C1 , w1 ).Conversely, feasible allocation C hC, G0 , associated non-empty setone-good(C ) allocations C1 hC, G0 , i1 C = -good(C1 ), alsocalled one-good forms C . following immediate definition one-goodversion forms.Fact 4.2. Let given type vector, let S1 one-good version , letC1 allocation S1 . Then, C1 optimal allocation S1 w.r.t. w1 if,if, -good(C1 ) optimal allocation w.r.t. w .Example 4.3. Consider setting Example 4.1, allocation(a1 ) = {g1 , g2 , g3 } (a2 ) = {g5 , g7 , g8 }. Note optimal allocationw.r.t. valuation vector wt (reported Figure 1(I)), val(, wt ) = 50opt(St , wt ) = 51 (see, e.g., optimal allocation Figure 1(II)). Now, noticeallocation depicted Figure 3(II) indeed associated one-good form allocation,actually optimal allocation St1 w.r.t. wt1 , Fact 4.2.position stating property holds optimal allocation .property fact interest own, i.e., independently applicationstudy fair allocation problems. words, tells us that, whenever interestedallocating goods subset agents, may safely consider goods img(),rather whole set G. case, basic technical ingredient showingnumber key properties because, intuitively, allows us get rid alternative (optimal)allocations, possibly based non-allocated goods G \ img().Theorem 4.4. Let given type vector, let optimal allocationhA, G, w.r.t. w , let C set agents. Then, every optimal allocationhC, img(), w.r.t. w optimal allocation hC, G, w.r.t. w .Proof. Let C set agents, assume C optimal allocationhC, img(), w.r.t. w . shall show C optimal allocation unrestrictedproblem hC, G, w.r.t. w , too.end, consider optimal allocation C problem hC, G,goods G available agents C. next prove val(C , w ) = val(C , w ).clearly follows optimality C img(C ) img() holds. Therefore,strictly better C , C must allocate good G \ img(). Assume thuscontradiction val(C , w ) < val(C , w ), hence img(C ) 6 img(), entailsimg() G. Consider two allocations C1 one-good(C ) 1C one-good(C ),observe first that: val(C1 , w1 ) = val(C , w ) < val(C , w ) = val(1C , w1 ).Let L set agents whose good-assignment accordingallocations, i.e., L = {c C 1 | 1C (c) = C1 (c)}. Then, define (C1 , 1C ) = (C 1 \ L {s, t}, E)directed graph, called update graph C1 w.r.t. 1C , whose nodes agentsC 1 change goods two allocations plus two distinguished nodes t,whose edges E defined follows:420fiMechanisms Fair Allocation Problemsedge agent c agent c0 1C (c0 ) = C1 (c) 6= ;edge agent c0 agent c 1C (c0 ) = C1 (c) 6= ;edge agent c agent c0 1C (c0 ) = C1 (c) 6= ;edges E.example construction, consider Figure 3(IV) showing update graph allocation shown Figure 3(II) w.r.t. allocation shown Figure 3(III).agent gets one good C1 1C , node (C1 , 1C ) exactlyone incoming edge one outgoing edge. Moreover, construction, incomingedge, outgoing edge. Thus, update graph consists number pathsnumber cycles, disjoint other.Let {1 , ..., h } set possible paths cycles (C1 , 1C ),path cycle = 1 , ..., , let agents(i ) set {1 , ..., } \ {s, t}.addition, let us fix following notation: function : X 2G givendomain X, let [X 0 ] denote restriction (sub-)domain X 0 X. Moreover,: X2 2G2 two domains X1 X2 ,given two functions 1 : X1 2G1 2 Urespectively,= , let 1 2 : X1 X2 2G1 G2 functionU X1 X2 U(1 2 )[X1 ] = 1 (1 2 )[X2 ] = 2 .construction update graph, note 1C expressed termsdisjoint paths/cycles 1 , ..., h following expression:C1 [C 1 \h[agents(i )]h]1C [agents(i )].i=1i=1Observe that, val(C1 , w1 ) < val(1C , w1 ), must exists set agentsagents(k ), associated disjoint path/cycle k , 1 k h, valuegoods allocated agents according 1C greater correspondingvalue theUsame agents obtained C1 . Then, consider function k = C1 [C 1 \agents(k )] 1C [agents(k )], note first k allocation hC, G, i1 .particular, note that, agent c C 1 , |k (c)| = 1 holds,U constraintactually holds C1 1C , definition operator . Moreover,choice k , also val(k , w1 ) > val(C1 , w1 ).Note k either cycle path form s, 2 , . . . , m1 ,1C (2 ) img(), img(k ) img() would hold. Indeed, definition edgesupdate graph, first node path (that is, 2 case k path) may1C (2 ) \ img() 6= . However, observed above, impossibleval(k , w1 ) > val(C1 , w1 ) would contradict optimality C1 , hence optimalityC , Fact 4.2. Therefore, conclude k path form s, 2 , . . . , m1 ,k (2 ) = 1C (2 ) = {g 0 } G \ img(). is, allocation k (over agentsC 1 ) img(k ) = {g 0 } img(C1 ) \ C1 (m1 ). particular, observeC1 (m1 ) img() \ img(k ) holds, definition edges update graphsince edge m1 t.Let us come back optimal allocation hA, G, w.r.t. w , let 1(optimal) allocation one-good(). Let C 1 set agents 2421fiGreco & ScarcelloInput:Assumption:Notation:1.2.3.4.5.6.7.8.type vector , feasible allocation ;verifier v (for t) available, v() = (v1 , ..., vn );= hA, G, i, w = (w1 , ..., wn ), wv() = (wv1 , ..., wvn );Let C denote set possible subsets A;C C,b Compute optimal allocation C,i hC, img(), (vi ,i ) w.r.t. w(vi ,i ) ;agent A,| set C C PC,1(=val(C,i , w(vi ,i ) ));| | Let C,i (, ) := wvi (C,i ) + jC\{i} wj (C,i );P(=val(C\{i},i , w(vi ,i ) ));| b Let 2C,i (, ) := jC\{i} wj (C\{i},i );P(1C,i (, ) 2C,i (, ));| Let (, w ) := CC (|A||C|)!(|C|1)!|A|!9. bDefine pi (, w ) := (, w ) wvi ();Figure 4: Payment rule p .goods cA 1 (c) allocated agents according 1 equalset0000000cA k (c)\{g }G , G img()\img(k ) |G | 1. Note setproperty fact exists: start {2 } add agents agents(k )c found 1 (c) img()U 1 \1img(k ).Consider = k [A] [A \ A] note well-defined,construction set guarantees good allocated according k [A]allocated 1 agents A1 \ A, vice-versa. Moreover, feasible allocationhA, G, i1 . Indeed, agent c A1 , |(c)| = 1 holds, constraint actuallyholds k 1 . Eventually, since 1 optimal allocation hA, G, i1 w.r.t. w1 ,val( 1 , w1 ) val(, w1 ) holds. Thus, construction , get val( 1 [A], w1 )val([A], w1 ) = val(k [A], w1 ). UFinally, let C0 = k [C 1 \ A] 1 [A] note C0 feasible allocationhC, G, i1 , arguments used show feasible allocation.Moreover, observe val(C0 , w1 ) val(k , w1 ) > val(C1 , w1 ) img(C0 ) img().latter, recall 2 agent C 1 k (2 )\img() 6= .Again, entails C1 optimal w.r.t. w1 hence, Fact 4.2, C alsooptimal hC, img(), w.r.t. w . Contradiction.result immediately entails following two corollaries.Corollary 4.5. optimal allocation hA, G, w.r.t. w setC agents, opt(hC, img(), i, w ) = opt(hC, G, i, w ).Corollary 4.6. Let optimal allocation hA, G, w.r.t. w , let 0feasible allocation hA, G, i, hence val(, w ) val( 0 , w ). Then, setC agents, opt(hC, img(), i, w ) opt(hC, img( 0 ), i, w ).422fiMechanisms Fair Allocation Problems4.2 Design Truthful MechanismConsider payment rule p defined Figure 4: given type vector ,feasible allocation selects goods img() G agentsA. Moreover, use verifier v (for vector true types t) that, given , ablecompute actual scenario Sv() valuation vector wv() = (wv1 , ..., wvn )allocated goods img(). Note that, sake presentation, sectionconvenient look output verifier list equivalent types v() = (v1 , ..., vn )vi , agent i, upper bound constraint goods valuationimg() computed verifier v. Then, usual, (vi , ) denotestype vector obtained replacing type verified type vi . particular,w(vi ,i ) denotes valuation vector (defined img()) function wvi usedplace valuation function declared .first three steps, payment rule associates optimal allocation C,ihC, img(), (vi ,i ) w.r.t. w(vi ,i ) set C C agents agent A,C powerset A, i.e., set possible subsets agents. Then,agent A, rule computes value (, w ) step 8, means formuladepends valuations associated allocations C,i C\{i},i , C C.particular, defines two terms (1C,i (, ) 2C,i (, )), evaluate allocationsC,i C\{i},i , respectively, w.r.t. valuation vector w(vi ,i ) . Actually, term2C,i (, ), valuation immaterial C\{i},i allocation C \ {i}. Finally,payment pi (, w) defined step 9 difference (, w ) wvi ().Note payment rule depends values goods img(),verifiable, according definition provided Section 2.3. Moreover note that,far paying agent concerned, rule depends values given wviallocated goods, i.e., values returned verifier, rather wi . Thus,declaration immaterial far computation payment concerned,next fact easily follows.Fact 4.7 (no punishment). type vector , feasible allocation, agent A, case pi (, w ) = pi (, w(ti ,i ) ).Moreover, note idea underlying definition p that, verificationperformed, utility function precisely coincide bonus (, w ), hencesharing spirit5 approach Nisan Ronen (2001).Lemma 4.8. type vector feasible allocation ,case ui (, w ) = (, w ).exploiting characterization, show first crucial result payment rule p , i.e., mechanism (A, p ) truthful, provided arbitraryoptimal allocation algorithm.get high-level intuition proof observe (, w ) depends twogroups terms, 2C,i (, ) basically independent given agent i. Thus,5. say spirit, peculiar form (, w ) formally fit framework consideredNisan Ronen (2001).423fiGreco & Scarcellogoal agent maximize terms form 1C,i (, ) defined step 6valuations optimal allocations computed (in step 3) considering verified type,focusing goods img() (so verified values coincide true ones),considering subsets whole set agents. salient machinery providedCorollary 4.5, according always convenient agent reporttrue type. Indeed, optimal allocation computed via based true typeagent i, Corollary 4.5 guarantees 1C,i (, ) get maximum possiblevalue possible allocations scenarios obtained considering subsets agents,i.e., independently allocation actually selected. done withoutstrategically interacting agents. Therefore, designing payment ruleway depends values returned verifier, endverifiable rule using punishment, also obtain truthful mechanism based it.Theorem 4.9 (truthfulness). Let optimal allocation algorithm. Then, mechanism verification (A, p ) truthful.Proof. show that, agent reported type vector d,following holds: ui (A(w(ti ,di ) ), w(ti ,di ) ) ui (A(wd ), wd ); hence, Lemma 4.8,(A(w(ti ,di ) ), w(ti ,di ) ) (A(wd ), wd ).Consider construction reported Figure 4 two cases = =(ti , di ), let = A(wd ) 0 = A(w(ti ,di ) ) corresponding optimal allocations(for scenarios Sd S(ti ,di ) , respectively) received input payment rule0 )Figure 4. set C C agents, agent A, let C,i (resp., C,iallocation computed step 3. Note step well defined,optimal allocation always exists. Indeed, note exist feasible allocationsscenario , e.g., allocation : C 2img() (j) = {g} goodg (j). is, allocation trivially satisfies every upper-bound constraint, sinceassigns one good agent.show following two properties hold, C C A:(A) 1C,i ( 0 , (ti , di )) 1C,i (, d),(B) 2C,i ( 0 , (ti , di )) = 2C,i (, d).order prove (A), observe step 6, 1C,i ( 0 , (ti , di )) = val(C,i , w(vi ,di ) ) =0val(C,i , w(ti ,di ) ), last equality holds C,iimg( 0 ), true0optimal allocationvaluation disclosed verifier. Then, observe C,i00hC, img( ), (vi ,di ) = hC, img( ), (ti ,di ) w.r.t. w(vi ,di ) and, hence, w.r.t. w(ti ,di ) ,0 = A(w(ti ,di ) ) optimal allocation S(ti ,di ) = hA, G, (ti ,di ) w.r.t. w(ti ,di ) .Thus, Corollary 4.5, get following expression:01C,i ( 0 , (ti , di )) = val(C,i, w(ti ,di ) ) = opt(hC, G, (ti ,di ) i, w(ti ,di ) ).(2)Similarly, 1C,i (, d) = val(C,i , w(vi ,di ) ) = val(C,i , w(ti ,di ) ) holds. Thus,use Equation 2, order get 1C,i ( 0 , (ti , di )) = opt(hC, G, (ti ,di ) i, w(ti ,di ) )val(C,i , w(ti ,di ) ). shows (A) holds.424fiMechanisms Fair Allocation Problems0Let us focus (B). step 7, 2C,i ( 0 , (ti , di )) = val(C\{i},i, w(vi ,di ) )20whereas C,i (, d) = val(C\{i},i , w(vi ,di ) ). Recall C\{i},i (resp., C\{i},i ) optimal allocation hC \{i}, img(), (vi ,di ) (resp., hC \{i}, img( 0 ), (vi ,di ) i) w.r.t. w(vi ,di ) .Then, fact evaluation immaterial here, C\{i},i (resp.,0C\{i},i) optimal allocation hC \ {i}, img(), (resp., hC \ {i}, img( 0 ), (ti ,di ) i)w.r.t. wd (resp., w(ti ,di ) ). Then, recall (resp., 0 ) optimal allocationSd (resp., S(ti ,di ) ) w.r.t. wd (resp., w(ti ,di ) ). Thus, Corollary 4.5, 2C,i ( 0 , (ti , di )) =opt(hC \ {i}, G, (ti ,di ) i, w(ti ,di ) ). Moreover, get:2C,i (, d) = opt(hC \ {i}, G, i, wd ).(3)Eventually, 2C,i ( 0 , (ti , di )) = opt(hC \ {i}, G, (ti ,di ) i, w(ti ,di ) ) = opt(hC \{i}, G, i, wd ) holds, valuation immaterial, get (B) Equation 3.4.3 Properties Truthful StrategiesLet us analyze relevant properties hold whenever agents choose dominant strategy truthfully reporting private types. first property usefulcharacterization agents utilities.Theorem 4.10. optimal allocation St = hA, G, w.r.t. wt ,agent A, holds that:ui (, wt ) =X (|A| |C|)!(|C| 1)!opt(hC, G, i, wt ) opt(hC \ {i}, G, i, wt ) .|A|!CCProof. Lemma 4.8, know ui (, wt ) = (, wt ). Then, set C Cagents, agent A, consider expressions 1C,i (, t) 2C,i (, t) definedstep 6 step 7, respectively, mechanism Figure 4. Note that,properties verifier v stated Definition 2.3 fact payment rule consider goods allocated via , 1C,i (, t) = val(C,i , w(vi ,ti ) ) = val(C,i , wt )2C,i (, t) = val(C,i , w(vi ,ti ) ) = val(C\{i},i , wt ) hold, C,i C\{i},i optimalallocations hC, img(), w.r.t. wt hC \ {i}, img(), w.r.t. wt , respectively.Thus, 1C,i (, t) = opt(hC, img(), i, wt ) 2C,i (, t) = opt(hC \ {i}, img(), i, wt ).follows that:ui (, wt ) =X (|A| |C|)!(|C| 1)!(opt(hC, img(), i, wt ) opt(hC \ {i}, img(), i, wt )) .|A|!CC(4)Recall Corollary 4.5 that, optimal allocation hA, G, w.r.t. wtset C C agents, opt(hC, img(), i, wt ) = opt(hC, G, i, wt ). Therefore,1C,i (, t) = opt(hC, G, i, wt ) 2C,i (, t) = opt(hC \ {i}, G, i, wt ). usingequalities, result follows Equation 4.agents utilities completely independent particular optimal allocation ,every agent gets precisely utility every optimal allocation.425fiGreco & ScarcelloCorollary 4.11. Let 0 two optimal allocations St w.r.t. wt . Then, ui (, wt ) =ui ( 0 , wt ) holds, A.Example 4.12. Consider scenario = hA, G, i, = {a1 , a2 } G ={g1 , ..., g8 }, valuation vector wt = (wa1 , wa2 ) discussed Example 2.1, allocation illustrated Figure 1(I)). Then, have:ua1 ( , wt ) =12 (opt(h{a1 , a2 }, G, i, wt ) opt(h{a2 }, G, i, wt ))+12 (opt(h{a1 }, G, i, wt ) opt(h{}, G, i, wt ))+12 (opt(h{a2 }, G, i, wt ) opt(h{a2 }, G, i, wt ) =111512 (51 26) + 2 (26 0) + 2 (26 26) = 2 .instance, note opt(h{a1 }, G, i, wt )) = 26, allocate g1 , g4 , g5a1 , (s)he agent scenario.Similarly, get ua2 ( , wt ) = 512 . is, two agents share precisely halftotal value, based payment scheme. fact, looking allocationFigure 1(II), one might navely suppose a2 contributed a1 overallvalue associated . However, due specific allocation considered,actual values goods two agents. Indeed, fairness utilityvalues resulting payment rule suddenly appears considering existencealternative allocation Figure 1(II), symmetric w.r.t.seems a1 contributed a2 overall value: matter fact, twoagents completely interchangeable optimal allocations, correctly reflectedpayment scheme (without need actually looking ). particular,Corollary 4.11, agents indifferent w.r.t. specific optimal allocation selected,hence case equally divide available value themselves.basic properties mechanism pointed next.Theorem 4.13 (basic properties). Let optimal allocation algorithm. Then,mechanism (A, p ) efficient guarantees equal treatment equals. Moreover,valuations non-negative, (A, p ) individually rational.Proof. clear (A, p ) satisfies efficiency equal treatment equals.Let agent recall Lemma 4.8 that, type vectorallocation , ui (, w ) = (, w ) holds. Consider payment rulep defined Figure 4, observe (, w ) defined weighted summation,coalitions C C, terms form 1C,i (, ) 2C,i (, ). particular,weights positive claim 1C,i (, ) 2C,i (, ) 0 holds. Indeed,check that, definition, 1C,i (, ) = opt(hC, img(), i, w ) 2C,i (, ) = opt(hC \{i}, img(), i, w ). So, hypothesis valuations non-negative,opt(hC, img(), i, w ) opt(hC \ {i}, img(), i, w ) 0 holds, Cagent A. Thus, ui (, w ) 0, hence fact (A, p ) individually rational triviallyfollows (even independently allocation , whether agent truthtelling).Moreover, mechanism also tolerant sensing errors (or uncertain inputs),sense Section 3.2.426fiMechanisms Fair Allocation ProblemsTheorem 4.14 (error tolerance). Let optimal allocation algorithm. Then,mechanism (A, p ) type vector agent A, |ui (A(wt ), wt )ui (A(wt ), wt )| 3 dist(t, t).Proof. Consider construction reported Figure 4 two cases = = t,let = A(wt ) = A(wt ) corresponding allocations received inputpayment rule (optimal w.r.t. wt wt , respectively). Moreover, set C Cagents agent A, let C,i C,i corresponding allocations computedstep 3. Then, get:1C,i (, t) = opt(hC, G, i, wt ), Equation 2 proof Theorem 4.9;1C,i (, t) = opt(hC, img(), (ti ,ti )i, w(ti ,ti ) ), step 3 Figure 4 facttrue valuation agent disclosed verifier C,i img().2C,i (, t) = opt(hC \ {i}, G, i, wt ), Equation 3 proof Theorem 4.9;2C,i (, t) = opt(hC \ {i}, G, i, wt ), Equation 3;Note |1C,i (, t) opt(hC, img(), i, wt )| dist(t, t). Moreover, sinceoptimal allocation w.r.t. wt , Corollary 4.5, opt(hC, img(), i, wt ) = opt(hC, G, i, wt )and, hence, |1C,i (, t) opt(hC, G, i, wt )| dist(t, t) holds. Then, observe|opt(hC, G, i, wt ) 1C,i (, t)| dist(t, t). Therefore, conclude |1C,i (, t)1C,i (, t)| 2 dist(t, t).Similarly, |2C,i (, t) 2C,i (, t)| dist(t, t) holds. Hence, putting together,derive |(1C,i (, t) 2C,i (, t)) (1C,i (, t) 1C,i (, t))| 3 dist(t, t).light expression step 7 Figure 4,|i (, wt ) (, wt )|X (|A| |C|)!(|C| 1)!3 dist(t, t).|A|!CCPconclude proof, observe CC (|A||C|)!(|C|1)!= 1 holds, |i (, wt )|A|!(, wt )| 3 dist(t, t).Therefore, Lemma 4.8, get |ui (A(wt ), wt )ui (A(wt ), wt )| = |i (, wt ) (, wt )| 3 dist(t, t).fact, next show (A, p ), optimal allocation algorithm, satisfiesremaining properties discussed Section 3.1. end, first discussinterpretation p context coalitional games.5. Coalitional Game Theory Viewpointcoalitional game modeled pair G = hN, i, N = {1, ..., n} finiteset agents, function associating coalition R N real-value(R) R, ({}) = 0, meant encode worth agents C obtaincollaborating other. function supermodular (resp., submodular )(R ) + (R ) (R) + (T ) (resp., (R ) + (R ) (R) + (T )) holds,pair coalitions R, N .427fiGreco & Scarcellofundamental problem coalitional games single desirable outcomes, usually called solution concepts, terms appropriate notionsworth distribuPntions, i.e., vectors payoffs x = (x1 , ..., xn ) R xi = (N ).question studied economics game theory aim providing argumentscounterarguments proposals reasonable mathematical renderingsintuitive concepts fairness stability. background coalitionalgames, reader referred to, e.g., work Osborne Rubinstein (1994).Here, consider Shapley value G = hN, i, well-known solutionconcept that:X (|N | |R|)!(|R| 1)!(G) =((R) (R \ {i})), N.|N |!RNIndeed, shall show mechanism defined Section 4 nice interpretationterms Shapley value suitable-defined coalitional games. correspondenceexploited prove properties mechanism, equilibriumagents truthfully report types.5.1 Shapley Value Allocation Gamesconsider two coalitional games defined top allocation problem.margbestDefinition 5.1. Given valuation vector w, define Gw= hA, margw Gw=hA, bestw coalitional games such, set C agents,margw (C) = opt(hA, G, i, wt ) opt(hA \ C, G, i, wt ); and,bestw (C) = opt(hC, G, i, wt ).2Recall Section 3.1 defined concept marginal contributionmarg,w (C) coalition C respect given allocation (because sensibleset goods allocated ). definition, slight abuse notation,defined similar concept margw (C), depend goods allocation.turns two concepts actually coincide optimal allocations.Theorem 5.2. Let optimal allocation St w.r.t. wt , let Carbitrary set agents. Then, marg,w (C) = margw (C).Proof. Let optimal allocation St = hA, G, w.r.t. wt , hence optimalhA, img(), w.r.t. wt . is, opt(St , wt ) = opt(hA, img(), i, wt ). Moreover, set C agents, Corollary 4.5, opt(hA \ C, img(), i, wt ) =opt(hA\C, G, i, wt ) holds. Therefore, margw (C) = opt(St , wt )opt(hA\C, G, i, wt ) =opt(hA, img(), i, wt ) opt(hA \ C, img(), i, wt ), result follows valueequivalent definition marg,w (C) Equation 1 (on page 416).Note also bestw (C) best contribution C, computed assuming agentsbestalreadyC agents allocation problem. particular, game Gwconsidered Moulin (1992), precisely setting fair division allocationbestsubmodular.problems. There, shown cost function associated Gw428fiMechanisms Fair Allocation ProblemsProposition 5.3. function bestw submodular.margSince opt(hC, G, i, wt ) = bestw (C), turns Gwcalledbestliterature dual game Gw , following result known hold. Nevertheless,give direct proof, completeness.Corollary 5.4. function margw supermodular.Proof. Let St = hA, G, given scenario. result follows noticingmargw (C) = opt(hA, G, i, wt ) opt(hA \ C, G, i, wt ) = opt(hA, G, i, wt ) bestw (A \C), set agents C A. Therefore, bestw (C) = opt(hA, G, i, wt )margw (A\C).Thus, bestw (R ) + bestw (R ) bestw (R) + bestw (T ) holds R, A,margw (A \ (R )) + margw (A \ (R )) margw (A \ R) + margw (A \ )holds well, R, A. Eventually, letting R0 = \ R 0 = \ , getmargw (R0 0 ) + margw (R0 0 )) margw (R0 ) + margw (T 0 ), R0 , 0 A.is, margw supermodular.second relevant property payment rule Section 4 coincidesbestShapley value game Gwassociated w. result follows comparing utility function Theorem 4.10 expression Shapley value coalitionalbestgame Gw. Moreover, show result established dual gamemargGt , Shapley values two games identicalfor similar correspondencesShapley values different games, see also works Maniquet (2003) KalaiSamet (1983).Theorem 5.5. optimal allocation St w.r.t. wt , agent A,margbest).) = (Gwholds ui (, wt ) = (, wt ) = (GwProof. comparing utility function Theorem 4.10 expressionbestassociating coalition C agentsShapley value coalitional game Gwworth opt(hC, G, i, wt ), immediately get that, optimal allocation Stbest).w.r.t. wt , agent A, holds ui (, wt ) = (, wt ) = (Gwmargbestorder conclude proof, show agent A, (Gw ) = (Gw)holds. end, first note Shapley values written follows:Pmarg(Gw) = CA,iC (|A||C|)!(|C|1)!TC0 ,|A|!best(Gw)=PCA,iC(|A||C|)!(|C|1)!TC ,|A|!TC0 = margw (C)margw (C\{i}) TC = opt(hC, G, i, wt )opt(hC\{i}, G, i, wt ).Then, claim that:(1) set C agents C, set C = (A \ C) {i} TC0 = TC,set C = (A \ C){i} 0 = .(2) set C agents C,CC429fiGreco & Scarcello(1) Let C C, observe TC0 = margw (C) margw (C \ {i}) =(opt(St , wt ) opt(hA \ C, G, i, wt )) (opt(St , wt ) opt(hA \ (C \ {i}), G, i, wt )) =opt(hA \ (C \ {i}), G, i, wt ) opt(hA \ C, G, i, wt ) = opt(h(A \ C) {i}), G, i, wt )opt(hA \ C, G, i, wt ). Thus, let C = (A \ C) {i}, note TC0 = TC.G, i, wt )observe = opt(hC,(2) Let C C,Copt(hC \ {i}, G, i, wt ) = (opt(St , wt ) opt(hC \ {i}, G, i, wt )) (opt(St , wt )G, i, wt )) = marg ((A \ C){i}) marg (A \ C).Thus, let C = (A \ C){i}opt(hC,ww0note TC = TC.margbest(1) (2) hold, given two expressions (Gw) (Gw), concludetwo values coincide.5.2 Marginality, Budget-Balancedness, Individual Optimalityestablished precise correspondence mechanismShapley value associated allocation games, show desirable properties p . fact, exploit following well-known properties (see, e.g., Osborne &Rubinstein, 1994; Young, 1985) Shapley value game G = hN, i:(I)P(G) = (N );(II) Psupermodular (resp., submodular ),iR (G) (R)), coalition R N .PiR (G)(R) (resp.,(III) G 0 = hN, 0 game 0 (R) (R), R N , (G 0 ) (G),agent N .particular, Property(II) entails Shapley value supermodular gamePmarg) margw (R). means Shapley valueGw iR (Gwgame belongs another important solution concept coalitional games called core (Osborne & Rubinstein, 1994), highly desirable stability, every coalitionmarggets least worth deserves according function margw .agents Gwcontext, easily entail utility every group (coalition) agentsC (i.e., sum utilities agents C), less actual marginal contribution best possible allocations. Note considering collective utilityparticularly useful whenever reason terms fairness groups agents, rathersingletons. first pinpoint bestw (C) margw (C) provide upper boundlower bound, respectively, utility C.margTheorem 5.6. LetPan optimal allocation St w.r.t. wt . Then, set Cagents, bestw (C) iC ui (, wt ) margw (C).margbest), agent) = (GwProof. Theorem 5.5, know ui (, wt ) = (Gwoptimal allocation . Then, simply recall function margw (resp.,margbestbestw ) associated game Gw(resp., Gw) supermodular (resp.,P submodular)Corollary5.4(resp.,Proposition5.3).Hence,resultfollowsiC ui (, wt ) =PPmargbest(G)property(II).(G)=iC wiC w430fiMechanisms Fair Allocation Problemscombining result Theorem 5.2, immediately get following.Corollary 5.7 (marginality).P Let optimal allocation algorithm. Then, mechanism (A, p ) iC ui (A(wt ), wt ) margA(wt ),w (C), set C A.Hence, payment rule p optimal allocation algorithms, get mechanismsaccurately take care marginality property defined Section 3.1. next resultpertains budget-balance property mechanisms. Again, correspondenceShapley value crucial establish result.Theorem5.8. Let optimal allocation St w.r.t. wt .Pp(,w) = 0.iAThen, holdsbest), agent optiProof. Theorem 5.5, know ui (, wt ) = (Gwbestbestmal allocation ,(G)ShapleyvalueGw . property (I)Pof ShapleyPP w bestbest)=value, know iA (Gw ) = bestw (A). Thus, iA ui (, wt ) = iA (Gwopt(hA, G, i, wt ). definition utility letting wt = (w1 , ..., wn ), folPPPlows opt(hA, G, i, wt ) =iA pi (, w). Hence,iA wi ()iA pi (, wt ) =opt(hA, G, i, wt ) val(, wt ) = 0, indeed optimal allocation w.r.t. wt .Corollary 5.9 (budget-balancedness). Let optimal allocation algorithm. Then,mechanism (A, p ) budget-balanced.Finally, complete picture analysis proving strong fairness propertyproposed payment rule p : words, best outcome every agent alwaysdetermined (global) optimal allocation. Moreover, Corollary 4.11, agentindifferent specific optimal allocation considered. is, chosenoptimal allocation leads best results agents.Lemma 5.10. Let 0 two feasible allocations St optimal w.r.t. wt ,hence val(, wt ) val( 0 , wt ). Then, ui (, wt ) ui ( 0 , wt ), A. Moreover, 0 optimal, exists agent ui (, wt ) > ui ( 0 , wt ).Proof. allocation , consider coalitional game G = hA, v v (C) =opt(hC, img(), i, wt ), C A. looking expression Shapley valueG , easy check ui (, wt ) = (G ) (just use reasoning proofTheorem 4.10). Assume 0 allocation val(, wt ) val( 0 , wt ),0consider value v (C) = opt(hC, img( 0 ), i, wt ), C A. Corollary 4.6,0v (C) v (C), C A. Then, derive ui (, wt ) = (G )0(G ) = ui ( 0 , w) every A, property (III).assume 0 optimal, thus val(, wt ) > val( 0 , wt ). Therefore,0grand-coalition A, v (A) > v (A). property (I) Shapley0value, (and all) total value v (A) distributed agents. follows0exists agent ui (, wt ) = (G ) > (G ) = ui ( 0 , wt ).focusing optimal allocation algorithms, lemma immediately entailsfollowing two fairness properties.431fiGreco & ScarcelloTheorem 5.11 (individual optimality). Let optimal allocation algorithm.Then, agent feasible allocation St , ui (A(wt ), wt ) ui (, wt ).Corollary 5.12 (Pareto-efficiency envy-freeness). Let optimal allocationalgorithm. Then, mechanism (A, p ) Pareto efficient envy-free.Note individual optimality guarantees much classical Pareto efficiencyenvy-freeness, entails mechanism leads unique evaluation,independently chosen optimal allocation. particular, Pareto set singleton.6. Complexity Issuessection, shall reconsider mechanism verification computationalperspective. Note first computing optimal allocation basis reportedtypes easy task, carried via adaptations classical matching algorithms. Indeed, light Fact 4.2, computing optimal allocation arbitraryscenario (with agents goods G) reduces computing optimal allocationscenario agent (in A1 ) gets one good. equivalent finding matchingmaximum weight complete bipartite graph set disjoint nodes A1G, edge weights encoded via function w1 . combinatorial problemknown feasible polynomial time (e.g., Schrijver, 2003).6.1 Hardness ResultDespite fact optimal allocations computed polynomial time, mechanism computationally-efficient, since payments unlikely computablepolynomial time. Indeed, next show computation problem completecomplexity class #P (see Papadimitriou, 1993).Let us recall counting Turing machine standard nondeterministic Turingmachine auxiliary output device prints binary notation numberaccepting computations induced input. (worst-case) time complexity f (n)longest accepting computation induced set inputs size n takes f (n) steps.Then, #P class functions computed counting Turing machinespolynomial time complexity. prototypical #P-complete problem count numbertruth variable assignments satisfy Boolean formula. course, NP#P,polynomial-time algorithm solving #P-complete problem would imply P = NP.Theorem 6.1. Computing Shapley value coalitional games associated allocationproblems (as Definition 5.1) #P-complete.Proof. problem belongs #P, computing Shapley value known feasible #P class coalitional games polynomial-time value/cost functions (c.f.Deng & Papadimitriou, 1994). show #P-hard, exhibit reductionfollowing problem: Let G = (A B, E) bipartite graph |A| = |B| = n, E B,|E| = n. Recall matching set E 0 E edges pairdistinct edges (a, b) (a0 , b0 ) E 0 , 6= a0 b 6= b0 hold. matching E 0 perfect|E 0 | = n. problem counting number perfect matchings bipartitegraphs #P-complete (Valiant, 1979a).432fiMechanisms Fair Allocation ProblemsGiven graph G = (A B, E) constant k 1 (which shall fix below),build polynomial-time tuple S(G) = hA, G, vector wt that:(1) = {} (a,b)E {(a, b)1 , ..., (a, b)k }, i.e., agents one-to-one associated kdistinct clones edge (a, b) E, plus distinguished agent . Note |A| > n,considered bipartite graphs n holds.(2) G = {g } B, i.e., goods correspond nodes, plus distinguished good g .(3) = 1 (a,b)i = 2, (a, b) {1, ..., k}, componentsassociated agents (a, b)i , respectively.(4) agent c A, associated component wc vector wt definedfollows. (a, b)i A, w(a,b)i (a) = 2, w(a,b)i (b) = 2, w(a,b)i (g ) = 1, w(a,b)i (x) = 0,x (A B) \ {a, b}. Moreover, w (g ) = 1, w (x0 ) = 0, x0 (A B).Let us fix notations. set E 0 E edges, let match(E 0 ) denotesize largest set E 00 E 0 edges matching. set C \ {}agents, let A(C) = {a | (a, b)i C} B(C) = {b | (a, b)i C}. Finally, sayC \ {} tight contain two agents form (a, b)i (a, b)j ,6= j, i.e., associated edge G.Observe that, set C \ {} agents,opt(hC {}, G, i, wt ) opt(hC, G, i, wt ) =10C tight, |C| = A(C) = B(C)otherwise(5)Indeed, C0 optimal allocation hC {}, G, w.r.t. wt , alwaysval(C0 , t) = 2 |A(C)| + 2 |B(C)| + 1. Instead, C optimal allocation hC, G,w.r.t. wt ,2 |A(C)| + 2 |B(C)|C tight, |C| = A(C) = B(C)val(C ) =2 |A(C)| + 2 |B(C)| + 1 otherwisebestexploiting Equation 5, express Shapley value game GS(G),tagent convenient way. Let Xh denote number sets C \ {} agentstight |C| = |A(C)| = |B(C)| = h, let X0 = 1. Then,|A|1best(Gw)=X (|A| h 1)!(h)!Xh .|A|!(6)h=0particular, let us focus coefficient Xh . Denote Yh number matchingsG whose cardinality h. construction S(G) immediate checkmatching cardinality h G, precisely k h sets agents C \ {}tight |C| = |A(C)| = |B(C)| = h. Thus, rewrite expression:|A|1best(Gw)=X(Zh Yh ) k h , Zh =h=0433(|A|h1)!(h)!.|A|!(7)fiGreco & Scarcellobestexpression one above, given value (Gw), knowncertain circumstances reconstruct polynomial time value single termform Zh Yh (see Fact 6 work Valiant (1979b)): need integer constant> 2 that, h {0, ..., |A| 1}, Zh Yh A, k A2 . case,noticed that, h {0, ..., |A|1}, Zh Yh 1 holds, Yh |A|!/((h)!(|A| h)!).best), compute polynomialThus, k = 9, that, given value (Gwtime terms. particular, compute polynomial time term associatedh = |A| = |B| = n, recall |A| > n. term form Zn Yn , Ynnumber perfect matchings G. Thus, putting together since Zncomputed polynomial time (as size numbers n |A| logarithmicw.r.t. size G), number perfect matchings bipartite graphs countedpolynomial time too, concludes proof.Lemma 4.8 Theorem 5.5, following immediate.Corollary 6.2. Computing payments given rule p #P-complete.6.2 Fully Polynomial-Time Randomized Approximation Schemeapproach circumvent intractability Shapley value based approximation:game G = hN, i, vector -approximation Shapley value |i (G)|(G) holds, N .Recently, sampling method conceived Bachrach, Markakis, Resnick, Procaccia,Rosenschein, Saberi (2010) special class simple coalitional gamesextended deal arbitrary games supermodular monotone 6 (Liben-Nowell,Sharp, Wexler, & Woods, 2012), assumption value (R) computedoracle unitary cost, R N . result that, > 0> 0, possible compute time poly(N, 1/, log(1/)) vector approximation Shapley value probability failure . methodproperties called fully polynomial-time randomized approximation scheme.Next, propose payment rule p founded sampling strategy describedwork Liben-Nowell et al. (2012). payment rule, reported Figure 5, samplessubsets storing C (together subsets functionally determinedsamples), computes value (, w ) Figure 4, C playingrole power-set C. process repeated (log(1/)) times, componentwise median vector payments computed. resulting payment eventuallydefined step 9.new rule p gives rise randomized mechanism course still verifiableuses punishment. Moreover, mechanism truthful even realizationset C, sampled step 1, known beforehand.7 Formally, mechanism turnsuniversally truthful, i.e., probability distribution deterministic truthfulmechanisms (see, e.g., Dobzinski & Dughmi, 2009).6. Monotonicity G = hN, means (R) (T ), R N .7. evidences truthfulness desideratum, need implement paymentrule computing Shapley value coalitional game associated allocation problem (asDefinition 5.1), fact concept defined possible subsets showncomputationally hard Theorem 6.1.434fiMechanisms Fair Allocation ProblemsInput:type vector , feasible allocation , integer > 0;Assumption: verifier v (for t) available, v() = (v1 , ..., vn );Notation:= hA, G, i, w = (w1 , ..., wn ), wv() = (wv1 , ..., wvn );1.2.3.4.5.6.7.8.9.Generate set C subsets A,let C := C {(A \ C) {i} | C C, C} {A};C C,| Compute optimal allocation C,i hC, img(), (vi ,i ) w.r.t. w(vi ,i ) ;b Compute optimal allocation C\{i},i hC \ {i}, img(), (vi ,i ) w.r.t. w(vi ,i ) ;agent A,b Compute (, w ) Figure 4 (steps 48), C := C;Repeat (log(1/)) times steps 1, 2, 5,w ) component-wise median vector vectors (, w );Let (,Define pi (, w ) := (, w ) wvi ();Figure 5: Payment rule p .Theorem 6.3. Let optimal allocation algorithm. Then, mechanism (A, p )universally truthful.Proof. result follows inspecting proof Theorem 4.9 rule p Section 4.Indeed, immediately checked proof depend specificsubset coalitions C, thus smoothly applies set coalitions C usedFigure 5, instead possible subsets A. Note particular that, proofTheorem 4.9, properties (A) (B) precisely guaranteeing truthfulness,properties hold given coalition C. Therefore, still hold subsetcoalitions randomly chosen mechanism.Similarly, inspecting proofs Section 4, universally truthful mechanism,following properties seen hold every realization random coin tosses.Theorem 6.4 (basic properties). Let optimal allocation algorithm. Then,mechanism (A, p ) efficient guarantees equal treatment equals. Moreover,valuations non-negative, (A, p ) individually rational.deeper analysis payment rule p , next point relationshiputility values approximations Shapley value, equilibrium agentsreport true types.Lemma 6.5. Let = {1, ..., |A|}, let = (|A|2 /2 ). optimal allocationSt w.r.t. wt , vector (u1,p (, wt ), ..., u|A|,p (, wt )) -approximationmargbestShapley value Gw(and Gw) probability 1 , coincides expectation.Proof. exploiting line reasoning proofs Section 4 p ,see (, wt ) (at step 6 algorithm Figure 5) rewritten follows:(, wt ) =X (|A| |C|)!(|C| 1)!(bestw (C) bestw (C \ {i})) .|A|!CC435fiGreco & ScarcelloThen, observe construction C step 1, set C C agentA, set (A \ C) {i} C, too. Thus, apply line reasoningproof Theorem 5.5, order conclude that:(, wt ) =X (|A| |C|)!(|C| 1)!(margw (C) margw (C \ {i})) .|A|!CCmarg= hA, margw supermodular Corollary 5.4. MoreNow, recall game Gwmargover, Gw clearly monotone. Thus, Liben-Nowell et al. (2012), expressionmarg, approximates valuecoincides expectation Shapley value Gwconstant probability. Steps 7 8 serve amplify probability (c.f. Liben-Nowellet al., 2012), get fully polynomial-time randomized approximation scheme.result follows step 9 implements usual bonus compensation approach,ui,p (, wt ) coincides expression, (cf. Lemma 4.8).Note approach Liben-NowellP et al. (2012), final normalization stepcarried would guaranteeiA u1,p (, wt ) = margw (A) = bestw (A).Unfortunately, way truthfulness might lost, hence include normalization procedure payment rule. consequence, mechanism pguarantee (for instance) budget-balancedness Pareto-efficiency. However,Lemma 6.5, since expected utility profile coincides Shapley value, p enjoysexpectation properties p including two ones. particular,still approximate counterparts Theorem 5.6 Theorem 5.8.Theorem 6.6. Let optimal allocation St w.r.t. wt . Let = (|A|2 /2 ). Then,probability 1 ,P(1 + ) bestw (C) iC ui,p (, wt ) (1 ) margw (C), C A;val(, wt )PiA pi (, wt )val(, wt ).Proof. Here, observeLemma 6.5 TheoremP5.5, setPthat, light PC A, (1) iC ui,p (, wt ) iC ui,p (, wt ) (1+) iC ui,p (, wt ).result follows substituting bounds Theorem 5.6 Theorem 5.8,respectively, simple algebraic manipulations.Finally, propose randomized mechanism able guarantee economic efficiency budget-balancedness. price paid however truthfulnessholds expectation only. mechanism based payment rule call p .Theorem 6.7. Let optimal allocation algorithm. Then, (randomized)mechanism verification (A, p ) truthful expectation, (at truthfulequilibrium) efficient budget-balanced. Moreover, valuations non-negative,(A, p ) individually rational.Proof. payment rule p follows steps Figure 5, minor modificationsstep 8 step 9: First, step 8, whenever compute median value (, w )agent i, also compute corresponding value (, wv() ) (evaluated revealed436fiMechanisms Fair Allocation Problemstypes rather reported ones). Then, define normalization factor R =Popt(hA, img(), v() i, wv() )/( iA (, wv() )), that, step 9, pi (, w ) eventuallyreturned wvi () (, w ) R.Concerning truthfulness, note expected value R 1. Indeed,Lemma 6.5, expected value (, wv() ) (, wv() ); hence, sumvalues coincides opt(hA, img(), v() i, wv() ) efficiency Shapley value(as proof Theorem 5.8). Thus, expected utility agent paymentrule p coincides (actual, i.e., expectation) utility rule p .Hence, truthfulness expectation follows Theorem 6.3. Now, check that,truthful equilibrium, maximum social welfare achieved (equilibrium efficiency)PPiA pi (, wt ) = opt(hA, img(), i, wv() ) iA (, wt ) R = 0. is,mechanism budget-balanced, too. Finally, mechanism p seen individuallyrational, exploiting line reasoning one used mechanism basedp , since corresponding proof Section 4 affected sampling strategy.Again, Lemma 6.5, remaining properties hold expectation.7. Related approaches Mechanisms Verificationnext review main approaches literature mechanisms verification,point differences w.r.t. proposal.First observe that, differently general setting types agentsdetermine vector upper bounds allocation problem, earlier approaches assumed agent types impact underlying combinatorial problem, type vector precisely coincides valuation vector. Instead,deal explicitly allocation constraints goods valuations. instance,scheduling problem formalized setting, private type agent/machinespeed, valuation function fully determined speed sizejob processed. Then, verifier asked measure speedagents/machinessee also Appendix A. fact, immediate encode valuationstypes well, price however hiding true complexity (or simplicity)setting. instance, example, type agent vectorvaluations, would miss information agent ultimately characterizedone (observable) parameter only.substantial differences earlier approaches proposal comedefinition utility agent. works Auletta et al. (2009), PennaVentre (2012a, 2012b), Krysta Ventre (2010), Auletta et al. (2006) Ferranteet al. (2009), individual welfare agent i, given outcome vectorreported types, assumed following form:0caught lyingui,p (, d) = ti ()pi (, d) otherwisepi (, ) payment depend vector true types.papers, information assumed available payment timewhether reported type di agent differs actual true type ti .437fiGreco & Scarcellorole played verifier, fact pi (, d) exploit possibility partiallyrevealing ti . Moreover, payment scheme adopted punishes agents caughtlying. Hence, verification process provides smaller amount informationverification process approach, rules used discourage strategic behaviorsstronger based punishing agents. Also, works assumeagents misreporting restricted certain kinds lies (e.g., values lowercorresponding true ones), form one-sided verification suffices.Recently, model (partial) verification extended Caragianniset al. (2012) setting agent cheating her/his type identifiedprobability may depend her/his true type, reported type, both. fact,Caragiannis et al. also showed cases verification helpone-sided. payment scheme exactly one discussedand, hence, verification exploit (possibly partial) knowledge actualtrue type punishment approach still used. main novelty, additionprobabilistic verification, constraint type agent reportcheating.Finally, different kind verification model goes back seminal paper NisanRonen (2001), actually closer no-punishment perspective,agent principle paid mechanism even caught lying. Givenn agents, Nisan Ronen consider vector e = (e1 , ..., en ) observed agent types,completely known verification process. Moreover, individual utilityagent form ui,p (, d) = ei () pi (, d), vector eframework plays role verifiers output approach. first differencework Nisan Ronen approach that, model, agentsmisreporting restricted certain kinds lies. hand, considerrestriction form valuation functions, since verification model assumesvaluations determined objective observable properties goods agents(encoded functions form g , defined Section 2). consequence,payment time, valuation agent known every good img(). Instead,setting Nisan Ronen, valuation agent goods img() \ (i)remains unknown even verification performed. results presentedpaper, turns difference two framework crucial overcomeclassical impossibility results, meet desirable properties (without usingpunishing power).8. Conclusionpaper, proposed analyzed mechanisms fair allocation problemssetting agents declarations regard objective properties goods agents, thus(partially) verified payments made. particular, consideredmodel verification able disclose true values allocated goods, contrastprevious approaches literature partial probabilistic verificationconsidered. However, use verification power fact quite limited,payment rules designed punishment meted agents whosedeclarations match output verification process. requirement crucial438fiMechanisms Fair Allocation Problemspractical applications framework, Italian research evaluation described(Greco & Scarcello, 2013) (and summarized Appendix), discrepancydeclared verified values may due sensing errors subjective issuescannot interpreted agents lies punished.challenge show that, framework, truthfulness, efficiency, budgetbalancedness, fairness (as well desirable properties discussed Section 2)achieved simultaneously, unlike classical setting. worthwhile noting that,one guaranteed agents truthfully report true types (no strategic behaviors)or, equivalently, types given public knowledge, problem quite easy.instance, one use payments way agent gets her/his utilityShapley value according either coalitional game defined Section 5. Moreover,fairness issue, properties obtained even using simpleuniform payment rule. However, whenever agents may behave strategically, reportingtrue type longer dominant strategy, approaches used. fact, truthfulnessmight enforced equipping mechanism suitable punishment rules. However,already argued would appropriate context, typicallyresulting mechanism would error tolerant.looking proposed framework abstract perspective, one may noticebased two fundamental ingredients: base combinatorial problem determinesfeasible optimal allocations, game-theoretic notion describes considered fair, respect agents contributions expectations. Namely, applicationdomain allocation problems addressed paper, weighted matching basiccombinatorial problem Shapley value natural game-theoretic solutionconcept. perspective, natural research direction study different instancesabstract framework mechanisms verification, combinatorialproblems (colorings, coverings, etc.) different solution concepts (Nucleolus, Banzhafindex, etc.) may appropriate best describe problem hands.Another interesting avenue research would study modificationframework agents preferences directly expressed terms real-valuedfunctions, rather formalized terms orderings/ranks available goods.particularly interesting given that, strategic setting defined, agentsdeclarations contribute definition goods selected,determine values.Acknowledgmentsthank anonymous referees Associate Editor useful comments.Appendix A. Application ScenariosFair allocation monetary compensation intensively studied literature,often settings parameters interest public knowledge (or, simply,getting rid strategic issues). One example application discussed literatureparking space benefit allocation workplace, employee gets parkingspace share fixed benefits package. House allocation problems another439fiGreco & Scarcelloclassical example, agents collectively set houses, look systematicway exclusively assigning house agent, possibly monetary compensations.third example room assignment-rent division, group agents rent house,getting room paying share rent.following, illustrate applications fair allocation problems fitgeneral framework discussed Section 2. applications shall discuss, partrelevant information private knowledge agents, verification adoptedmeasure observable properties payment phase. Nonetheless, stressthat, even relevant information available public knowledge couldmeasured advance, applications would still remain interest, showneed defining allocation policies guarantee fair and/or error tolerant solutions.A.1 Italian Research Assessment Program (VQR) 20042010start overview possible application scenarios focusing real-world casestudy first motivated investigation allocation problems. applicationbest described companion paper (Greco & Scarcello, 2013), applies resultspresented specific case Italian research assessment program.A.1.1 Setting2012, National Agency Evaluation Universities Research Institutes(ANVUR) promoted VQR assessment program devoted evaluate qualitywhole Italian research production. first application, program focusesperiod 2004-2010, evaluation repeated regular basis (the next onecover years 20112014).first phase program, every structure R (a university research institute)selects submits ANVUR set P products, constraints (i)product univocally associated author (even product co-authored)(ii) three products associated author affiliated R.8abstract terms, R computes phase allocation , img() = P ,scenario R set agents/researchers affiliated R, P setgoods/products co-authored, r R, r = 3associated constraint number goods/products allocated r. wayallocation performed described below.second phase, ANVUR evaluates products P equippingquality score, expressed number.9 Hence, phase defines official valuationthat, product p (r), w(p) quality score assigned ANVUR p.overall score R sum values products P ,used proportionally transfer R funds allocated Ministry support researchactivities next years, data new evaluation subsequent periodavailable.8. simplify here. Actually, number publications may less three, authors.9. set possible scores defined VQR guidelines. ends, detail immaterialscores viewed (arbitrary) real numbers.440fiMechanisms Fair Allocation ProblemsA.1.2 Need Fair DivisionVQR program actually assigns score structure R, alsosubstructures (e.g., departments, R university). course, expectedimpact funds redistribution inside every research structure, thereforecrucial problem define fair rule funds redistribution, is, rule capableassign funds clearly reflecting true contribution researcher/substructureperformances structure whole. Moreover, recruitment policiesuniversities going evaluated well, looking (VQR) performancesresearchers hired recently. However, redistribution rule specifiedprogram, researchers believe evaluationP (the contribution of)r R coincide overall value wr () =p(r) w(p) productsallocated r submission phase. course fair general,product p P co-authored two researchers R, (and, turn,structures) might claim contribution even product formally allocatedone them.10 Therefore, sophisticated approaches definedproper evaluation individuals substructures.A.1.3 Strategic Issues Verification VQR ProgramRecall goal structure R submit ANVUR (in first phase program) products likely get highest possible scores (in second phase).end, publicly available evaluation criteria allow one perform ranking products, ideally equipping quality scoreassigned ANVUR subsequent phase. time economicreasons, first evaluation phase based self-evaluations performedauthors products, clearly assumed best experts researchsubjects. Moreover, structures, decide precise allocation products, hencedeal conflicts related co-authored products, researchers performed choicesdecentralized way; structures set optimization framework computeoptimal allocation, based agents declarations. case, abstractingspecific method adopted end feasible allocation submitted VQR,strategic issues emerged phase. particular, researchers r Rguided allocation products (e.g., cheating quality) supposedpersonal interest maximizing value wr (). Clearly enough, way optimal productselections hardly achieved structure.Note VQR case perfectly fits framework allocation problems: research products indivisible goods allocated researchers/agents, initiallydeclare goods valuations. Moreover, social welfare total ANVUR scoreresearch structure, distributed budget-balanced way researchers,hence substructures, fair way. Note upper bound constraintresearcher (3 products, exceptions) depend type case,10. problem occur products co-authored researchers belonging different structures.Indeed, product submitted several structures (assigned different co-authorthem). Thus, given research structure R, co-authors interest affiliatedR.441fiGreco & Scarcelloparameter fixed ANVUR. Therefore, private information agentslimited good valuations. Moreover, observe specific valuation functions occurring VQR fit verification model proposed paper. particular, everyresearch product objective value, measured verifierallocated hence submitted product (while nothing said productsallocated researcher). Thus, ANVUR precisely acts verifier model.A.1.4 Mechanisms VQR Programbasic approach assigning researcher r R value wr () precisely(trivial no-payment) rule p Example 2.6. There, observed mechanismsbased rule truthful general. Moreover, Example 3.1 also emergedrule fair (in particular) combined optimal allocation algorithm(in order guarantee efficiency). Therefore, rule highly undesirable, differentkinds mechanisms defined VQR setting.fact, would like end mechanism able able collectcorrect self-evaluations (truthfulness) obtain maximum possible performance(efficiency) research structures. two goals, however, accomplishedtogether fairness. Indeed, would like guarantee every researcher groupresearchers get least marginal contributions, resulting mechanismalso individually optimal. latter property important application, sinceguarantees that, researcher, her/his score maximum one possiblealternative allocations, including allocations using products submittedstructure hence verified. Moreover, also relevant propertiesguaranteed via mechanisms enjoying verifiability property, payment ruleuses certified valuations (it would unacceptable use product valuesverified ANVUR).Finally, worthwhile noting ANVUR guidelines defines range possible product values determined, e.g., publishing venues citation indices, pointingpeer-reviews also used override basic classification (e.g., papers published good journal without many citations, explicit authorsrequest). Clearly enough, entails discrepancies authors declarationsANVUR evaluations might well emerge even absence malicious behavior. Hence,no-punishment (and error-tolerant) approach seems unavoidable concretepolitically acceptable application mechanism.A.2 (Cooperative) Scheduling Task AllocationAssume h jobs set J = {1 , ..., h } executed within deadline d,n agents/machines, m1 , ..., mn , n h, available execute paralleljobs. machine mi , {1..., n}, let J denote set jobs miprinciple execute. sets determined, instance, physical, technological,accessibility constraints known scheduler, precise speedmachines guarantee process known scheduler, declaredagents. assumed machine mi always work speed independentlyworkload actually assigned (for considered jobs hand). sake442fiMechanisms Fair Allocation Problemssimplicity, assume also job consists workload wl ,executed job, fixed profit pr earned. Moreover, profit pr add earnedscheduler jobs correctly executed, (part it) distributedagents. Every machine participating process execute least one job (i.e.,assuming many jobs executed machine machinescomparable speeds convenient use them). Furthermore, every machinededicated process aims executing many jobs J possible,cannot earn profit external jobs (not J ).Therefore, allocation problem goods/jobs set {1 , ..., h }allocated/scheduled agents/machines set {m1 , ..., mn }. Here,private type agent mi speed si (devoted process), {1, ..., n}.Moreover, vector upper bounds number goods allocatedagents defined (si ) = b dswl c, {1, ..., n}. Note, particular,jobs completed within deadline, upper bound constraintsallocation scenario functions types/speeds agents/machines. Finally,define valuation vector w = (w1 , ..., wh ) that, {1, ..., n}, wi (x ) = pr ,x ; wi (x ) = 1, x 6 . Note case valuations independenttypes agents (of course, assuming single job executedwithin deadline d).Given task carried different agents, sensibleallocations perceived fair ones (see, e.g., Porter et al., 2004). end,mechanism monetary compensations described paper adopted. fact,note strategic issues come play, egoistic behavior agents may leadallocations optimal possibly miss extra-reward pr add . Observescheduler may act verifier model, end process. Indeed,allocation computed jobs executed based it, immediatelyverify truthfulness agents declarations looking amount time usedmachine execute jobs assigned it.Furthermore, practice, speed values given finite precision, wellphysical verification subject measurement errors. reason, even mechanismtolerant errors, based punishments.example, consider following task allocation problem,viewed variation previous one: Assume company select agentse1 , ..., en perform given set tasks {t1 , ..., tm } within certain deadline, assumecompany know precisely whether agents necessaryskills (experience, strength, speed, competence, etc.). instance, may happencompany starting new line production new tasks, tasksexecuted means crowdsourcing, agents selected internet call.Therefore, case agents types declarations comprise skillsnumber tasks able execute within required deadline. Valuation functionsencode profit earned agent executing given task (where value 0means agent able execute task). Note upperbound constraints allocation scenario valuations functions depend agentstypes. Again, mechanism monetary compensations used, order providefair distribution company reward tasks, encourage agents truthfully443fiGreco & Scarcellodeclare skills. Note framework verification proposed paperused assumption agents skills necessary proposed set tasksobserved evaluated verifier, (at least) end process,agents performed work (possibly failures).A.3 Protocols Wireless Communication Networksconclude overview possible applications considering cost problem where,moreover, private information, hence strategic behavior. remarkproposal described paper used even mechanism designnecessary, one still needs policy fair division enjoys properties describedSection 3.1 (e.g., envy freeness, individual optimality, on). fact, fairnessissues currently attracting much attention design scheduling protocolswireless communication networks, underlying problem bandwidth allocation;instance, design protocols high-speed wide area wireless networks,role monetary compensation played adjustments priorities users (see,e.g., Jalali, Padovani, & Pankaj, 2000). Moreover, number network applicationsemerging direct forms monetary compensation considered.example, let us consider ad-hoc networks, self-organizing wireless infrastructures mobile nodes cooperatively act via multi-hop routing transmit data evensource destination nodes transmission ranges. Cooperationachieved associating credit balance node, nodes use credits paysending traffic, earn credits forwarding traffic nodes compensate bandwidth power consumptionsee, instance, work Gobel, Krzesinski,Mandjes (2009) references therein. Consider setting nodes s1 , ..., snwilling transmit data ad-hoc network. given configurationnetwork, nodes r1 , ..., rm used forward data. particular, wheneversi rj , {1, ..., n} j {1, ..., m}, within transmission ranges,denote ci,j credit paid si transfer data via rj large enough value ci,jused state transmission possible. resulting cost problemmodeled via allocation scenario = 1, valuation vectorwi (rj ) = ci,j , {1, ..., n} j {1, ..., m}. Thus, maximizing socialwelfare amounts minimizing overall credits paid source nodes.easily seen that, even private information everything public,fairness issues emerge context, too. Indeed, different sources may want userouting node transfer data. instance, simple setting = 2n = 2 r1 preferred routing node s1 s2 (i.e., c1,1 < c1,2c2,1 < c2,2 ), node forced transfer data via r2 might perceivegiven allocation unfair. suggests credits paid source nodesadjusted via payment rules that, proposal, based Shapley valuecoalitional games described Section 5.setting similar one discussed emerges wireless cooperative file sharingsystems, mobile subscribers cluster together downloading (portions of) filesinterest long-range cellular links, exchanging short-range radio communications wireless local area network. systems cooperative environments,444fiMechanisms Fair Allocation Problemswhose benefits appreciated terms increased throughput reducedenergy consumption, also terms economic advantages users contentproviders. order effective, however, fair allocation protocols designed,whose goal encourage cooperation (see, e.g., Militano, Iera, & Scarcello, 2013).ReferencesAbdulkadiroglu, A., Sonmez, T., & Unver, M. U. (2004). Room assignment-rent division:market approach. Social Choice Welfare, 22, 515538.Agotnes, T., van der Hoek, W., Tennenholtz, M., & Wooldridge, M. (2009). Powernormative systems. Proc. AAMAS09, pp. 145152.Alcalde, J., & Barbera, S. (1994). Top dominance possibility strategyproof stableallocations matching problems. Economic Theory, 4, 417435.Alkan, A., Demange, G., & Gale, D. (1991). Fair allocation indivisible goods criteriajustice. Econometrica, 59 (4), 102339.Andersson, T. (2009). general strategy-proof fair allocation mechanism revisited. Economics Bulletin, 29 (3), 17171722.Andersson, T., & Svensson, L.-G. (2008). Non-manipulable assignment individualspositions revisited. Mathematical Social Sciences, 56 (3), 350354.Andersson, T., Svensson, L.-G., & Ehlers, L. (2010). Budget-balance, fairness minimalmanipulability. Working papers 2010:16, Lund University, Department Economics.Aragones, E. (1995). derivation money rawlsian solution. Social ChoiceWelfare, 12, 267276.Archer, A., & Tardos, E. (2007). Frugal path mechanisms. ACM Transactions Algorithms, 3, 122.Auletta, V., De Prisco, R., Penna, P., & Persiano, G. (2009). power verificationone-parameter agents. Journal Computer System Sciences, 75, 190211.Auletta, V., De Prisco, R., Penna, P., Persiano, G., & Ventre, C. (2006). New constructionsmechanisms verification. Proc. ICALP06, pp. 596607.Auletta, V., Penna, P., Persiano, G., & Ventre, C. (2011). Alternatives truthfulnesshard recognize. Autonomous Agents Multi-Agent Systems, 22 (1), 200216.Aumann, R. J., & Maschler, M. (1985). Game-theoretic analysis bankruptcy problemtalmud. Journal Economic Theory, 36 (2), 195213.Bachrach, Y., Markakis, E., Resnick, E., Procaccia, A. D., Rosenschein, J. S., & Saberi, A.(2010). Approximating power indices: theoretical empirical analysis. AutonomousAgents Multi-Agent Systems, 20, 105122.Bachrach, Y., & Rosenschein, J. S. (2008). Coalitional skill games. Proc. AAMAS08,pp. 10231030.Bachrach, Y., & Rosenschein, J. (2009). Power threshold network flow games. Autonomous Agents Multi-Agent Systems, 18 (1), 106132.445fiGreco & ScarcelloBachrach, Y., Zuckerman, M., Wooldridge, M., & Rosenschein, J. (2013). Proof systemstransformation games. Annals Mathematics Artificial Intelligence, 67 (1),130.Bevia, C. (1998). Fair allocation general model indivisible goods. ReviewEconomic Design, 3, 195213.Bouveret, S., & Lang, J. (2008). Efficiency envy-freeness fair division indivisible goods: Logical representation complexity. Journal Artificial IntelligenceResearch, 32, 525564.Brams, S. J., & Kilgour, D. M. (2001). Competitive fair division. Journal PoliticalEconomy, 109 (2), 418443.Brandt, F., Conitzer, V., & Endriss, U. (2012). Multiagent Systems, chap. ComputationalSocial Choices. MIT Press.Caragiannis, I., Elkind, E., Szegedy, M., & Yu, L. (2012). Mechanism design: partialprobabilistic verification. Proc. EC12, pp. 266283.Clarke, E. (1971). Multipart pricing public goods. Public Choice, 8, 1933.Deng, X., & Papadimitriou, C. H. (1994). complexity cooperative solution concepts. Mathematics Operations Research, 19, 257266.Dobzinski, S., & Dughmi, S. (2009). power randomization algorithmic mechanism design. Proc. FOCS09, pp. 505514.Dunne, P. E. (2005). Extremal behaviour multiagent contract negotiation. JournalArtificial Intelligence Research, 23, 4178.Dunne, P. E., Wooldridge, M., & Laurence, M. (2005). complexity contract negotiation. Artificial Intelligence, 164 (1-2), 2346.Endriss, U., Maudet, N., Sadri, F., & Toni, F. (2006). Negotiating socially optimal allocations resources. Journal Artificial Intelligence Research, 25, 315348.Feige, U., & Tennenholtz, M. (2011). Mechanism design uncertain inputs: (to errhuman, forgive divine). Proc. STOC11, pp. 549558.Ferrante, A., Parlato, G., Sorrentino, F., & Ventre, C. (2009). Fast payment schemestruthful mechanisms verification. Theoretical Computer Science, 410, 886899.Gobel, J., Krzesinski, A., & Mandjes, M. (2009). Incentive-based control ad hoc networks:performance study. Computer Networks, 53 (14), 24272443.Greco, G., & Scarcello, F. (2013). Fair division rules funds distribution: caseitalian research assessment program (vqr 2004-2010). Intelligenza Artificiale, 7 (1),4556.Green, J., & Laffont, J. (1977). Characterization satisfactory mechanisms revelation preferences public goods. Econometrica, 45 (2), 427438.Groves, T. (1973). Incentives teams. Econometrica, 41, 617631.Haake, C.-J., Raith, M. G., & Su, F. E. (2002). Bidding envy-freeness: proceduralapproach n-player fair-division problems. Social Choice Welfare, 19 (4), 723749.446fiMechanisms Fair Allocation ProblemsHurwicz, L. (1975). existence allocation systems whose manipulative nash equilibria pareto optimal. Unpublished paper, presented third World CongressEconomic Sosciety, Toronto.Jain, K., & Vazirani, V. (2001). Applications approximation algorithms cooperativegames. Proc. STOC01, pp. 364372.Jalali, A., Padovani, R., & Pankaj, R. (2000). Data throughput cdma-hdr high efficiencyhigh data rate personal communication wireless system. Proc. IEEE VTC00,Vol. 3, pp. 18541858.Kalai, E., & Samet, D. (1983). weighted Shapley values. Discussion papers 602, Northwestern University, Center Mathematical Studies Economics ManagementScience.Klijn, F. (2000). algorithm envy-free allocations economy indivisibleobjects money. Social Choice Welfare, 17 (2), 201215.Krysta, P., & Ventre, C. (2010). Combinatorial auctions verification tractable.Proc. ESA10, pp. 3950.Liben-Nowell, D., Sharp, A., Wexler, T., & Woods, K. (2012). Computing Shapley valuesupermodular coalitional games. Proc. COCOON12, pp. 568579.Lindner, C. (2010). market-affected sealed-bid auction protocol. Proc. SETN10,pp. 193202.Lipton, R. J., Markakis, E., Mossel, E., & Saberi, A. (2004). approximately fair allocations indivisible goods. Proc. EC04, pp. 125131.Maniquet, F. (2003). characterization Shapley value queueing problems. JournalEconomic Theory, 109 (1), 90103.Maskin, E. (1987). Fair Allocation Indivisible Goods, pp. 341349. MacMillan.Meertens, M., Potters, J., & Reijnierse, H. (2002). Envy-free pareto efficient allocationseconomies indivisible goods money. Mathematical Social Sciences, 44 (3),223233.Militano, L., Iera, A., & Scarcello, F. (2013). fair cooperative content-sharing service.Computer Networks, 57 (9), 19551973.Mishra, D., & Rangarajan, B. (2007). Cost sharing job scheduling problem. SocialChoice Welfare, 29 (3), 369382.Moulin, H. (1992). application Shapley value fair division money. Econometrica, 60 (6), 133149.Moulin, H. (1999). Incremental cost sharing: Characterization coalition strategyproofness. Social Choice Welfare, 16 (2), 279320.Moulin, H. (2003). Fair Division Collective Welfare. MIT Press.Moulin, H., & Shenker, S. (2001). Strategyproof sharing submodular costs: budget balanceversus effciency. Economic Theory, 18 (3), 511533.Nagamochi, H., Zeng, D.-Z., Kabutoya, N., & Ibaraki, T. (1997). Complexity minimum base game matroids. Mathematics Operations Research, 22, 146164.447fiGreco & ScarcelloNisan, N., & Ronen, A. (2001). Algorithmic mechanism design. Games EconomicBehavior, 35, 166196.Nisan, N., Roughgarden, T., Tardos, E., & Vazirani, V. V. (2007). Algorithmic GameTheory. Cambridge University Press, Cambridge, UK.Ohseto, S. (2004). Implementing egalitarian-equivalent allocation indivisible goodsrestricted domains. Economic Theory, 23, 659670 (2004).Osborne, M. J., & Rubinstein, A. (1994). Course Game Theory. MIT Press,Cambridge, MA, USA.Papadimitriou, C. H. (1993). Computational Complexity. Addison-Wesley.Pathak, A.P., S. T. (2013). Comparing mechanisms vulnerability manipulation.American Economic Review, 103 (27), 80106.Penna, P., & Ventre, C. (2012a). Collusion-resistant mechanisms verification yieldingoptimal solutions. ACM Transaction Computation Theory, 4 (2), 117.Penna, P., & Ventre, C. (2012b). Optimal collusion-resistant mechanisms verification. Games Economic Behavior, press, electronically available doi10.1016/j.geb.2012.09.002.Porter, R., Shoham, Y., & Tennenholtz, M. (2004). Fair imposition. Journal EconomicTheory, 118 (2), 209228.Potthoff, R. F. (2002). Use linear programming find envy-free solution closestbramskilgour gap solution housemates problem. Group DecisionNegotiation, 11, 405414.Quinzii, M. (1984). Core competitive equilibria indivisibilities. InternationalJournal Game Theory, 13, 4160.Sakai, T. (2007). Fairness implementability allocation indivisible objectsmonetary compensations. Journal Mathematical Economics, 43 (5), 549563.Sandholm, T. (1998). Contract types satisficing task allocation: theoretical results.AAAI Spring Symposium: Satisficing Models.Schrijver, A. (2003). Combinatorial Optimization: Polyhedra Efficiency. SpringerVerlag.Shioura, A., Sun, N., & Yang, Z. (2006). Efficient strategy proof fair allocation algorithms.Journal Operations Research Society Japan, 49 (2), 144150.Shoham, Y., & Leyton-Brown, K. (2009). Multiagent Systems. Cambridge University Press.Su, F. (1999). Rental harmony: Sperners lemma fair division. American MathematicalMonthly, 106, 930942.Svensson, L.-G. (1983). Large indivisibles: analysis respect price equilibriumfairness. Econometrica, 51 (4), pp. 939954.Svensson, L.-G. (2009). Coalitional strategy-proofness fairness. Economic Theory, 40,227245.448fiMechanisms Fair Allocation ProblemsTadenuma, K., & Thomson, W. (1991). No-envy consistency economies indivisible goods. Econometrica, 59 (6), 175567.Tadenuma, K., & Thomson, W. (1993). fair allocation indivisible goodmonetary compensations possible. Mathematical Social Sciences, 25 (2), 117132.Tadenuma, K., & Thomson, W. (1995). Games fair division. Games EconomicBehavior, 9 (2), 191204.Thomson, W. (2011). Fair allocation rules. Kenneth J. Arrow, A. S., & Suzumura, K.(Eds.), Handbook Social Choice Welfare, Vol. 2, pp. 393506. Elsevier.Valiant, L. G. (1979a). complexity computing permanent. Theoretical ComputerScience, 8 (2), 189201.Valiant, L. G. (1979b). complexity enumeration reliability problems. SIAMJournal Computing, 8 (3), 410421.Vickery, W. (1961). Counterspeculation, auctions competitive sealed tenders. JournalFinance, 837.Willson, S. J. (2003). Money-egalitarian-equivalent gain-maximin allocations indivisible items monetary compensation. Social Choice Welfare, 20, 247259.Yang, Z. (2001). intersection theorem unbounded set application fairallocation problem. Journal Optimization Theory Applications, 110, 429443.Yengin, D. (2012). Egalitarian-equivalent groves mechanisms allocation heterogenous objects. Social Choice Welfare, 38 (1), 137160.Young, H. P. (1985). Monotonic solutions cooperative games. International JournalGame Theory, 14, 6572.Young, H. P. (1994). Equity Theory Practice. Princeton University Press.449fiJournal Artificial Intelligence Research 49 (2014) 241-267Submitted 08/13; published 02/14Empirical Evaluation Ranking MeasuresRespect Robustness NoiseDaniel Berrarberrar.d.aa@m.titech.ac.jpInterdisciplinary Graduate School Science EngineeringTokyo Institute Technology4259 Nagatsuta, Midori-ku, Yokohama 226-8502, JapanAbstractRanking measures play important role model evaluation selection. Usingsynthetic real-world data sets, investigate different types levelsnoise affect area ROC curve (AUC), area ROC convex hull,scored AUC, Kolmogorov-Smirnov statistic, H-measure. experiments,AUC was, overall, robust among measures, thereby reinvigoratingreliable metric despite well-known deficiencies. paper also introduces novelranking measure, remarkably robust noise yet conceptually simple.1. IntroductionVarious metrics exist evaluate performance predictive model, oftenclear one actually choose concrete problem hand (Hand, 2006;Prati, Batista, & Monard, 2011; Hernandez-Orallo, Flach, & Ferri, 2012; Bradley, 2013;Parker, 2013). also known different metrics quantify different aspects model(Caruana & Niculescu-Mizil, 2004; Ferri, Hernandez-Orallo, & Modroiu, 2009). practice,fair objective comparison predictive models therefore trivial, particularlydata affected noise. Here, consider problem binary classificationranking problems, pervasive numerous applications (Prati et al., 2011),ranging web-based recommender systems search engines biomedical classifiers.goal study investigate robust various ranking measuresdifferent types different levels noise. Particularly, interested robustnesswidely used AUC whether recently proposed alternatives, H-measure(Hand, 2009), indeed preferable. addition, present novel performance measure,called truncated average Kolmogorov-Smirnov statistic (taKS). measure deriveddistance true positive rate (TPR) false positive rate (FPR) curves,similarly classic Kolmogorov-Smirnov statistic (KS).Surprisingly experimental studies focused comparison performance measures predictive models. course, different measures may quantify different aspectsmodel, may make little sense compare across different classes.make sense compare metrics within class, example, ranking measuresrobustness noise. knowledge, comprehensive study datecarried Ferri et al. (2009) investigated relations various performancemeasures observed measures essentially measure quite different aspects;observation also made Caruana Niculescu-Mizil (2004). recent comparative studyc2014AI Access Foundation. rights reserved.fiBerrarParker (2013) focused ranking measures; study recommends H-measureadvises AUC. theoretical approach comparison performancemeasures found work Flach (2003). Hernandez-Orallo et al. (2012) providecomprehensive view different measures related other.summary, main insights following. First, among conventional measures, AUC arguably robust across wide range noise levels types.result confirms fact, AUC reliable measure, althoughcriticized incoherent potentially misleading (Hilden, 1991; Lobo, Jimenez-Valverde,& Real, 2008; Hand, 2009; Hand & Anagnostopoulos, 2013; Parker, 2013). Therefore,experiments lend empirical support AUC robust measure modelevaluation selection. Second, overall, magnitude differences robustnesscommonly used measures dramatic relatively low noise levels.Third, proposed new measure, taKS, also remarkably robust noise,conceptually simple neat geometrical interpretation.paper organized follows. First, briefly review ranking measuresincluded comparative study. Then, give rationale new measure,beginning introductory example describing formal details. Section 4,report results comparative study involving synthetic real-world datasets. Section 5 concludes paper discussion.2. Brief Review Investigated Ranking MeasuresLet data set contain k instances (or cases) xi , = 1..k. case, exactly one classassociated, i.e., (y, xi ), {0, 1}, 1 denotes positive class 0 denotesnegative class. Commonly, predictive models generate numeric score xi ,quantifies degree class membership case class, example,class posterior probability. data set contains positive negative examples,predictive model either used ranker classifier. scoresexpressed ordinal scale, model use scores rank casesleast likely positive. setting threshold ranking score, s(x),C{s(x) t} = 1, turn ranker (crisp) classifier.2.1 Area ROC Curve (AUC)Arguably commonly used ranking measure AUC. used modelselection various applications, ranging data mining competitions biomedical tests(Berrar & Flach, 2012). AUC area ROC curve, depicts tradeoffs false positive rate (or 1 minus specificity, depicted x-axis)true positive rate (or sensitivity, depicted y-axis). trade-offs correspondpossible binary classifications dichotomization continuous outputsmodel would allow. AUC equivalent Wilcoxon rank-sum statistic (Bamber,1975; Hanley & McNeil, 1983) interpreted conditional probability: givenrandomly selected positive negative case, AUC probability classifierassigns higher score positive case (i.e., ranks negative case).Let P denote probability randomly selected actual positive case, x+ ,higher ranking score, s+ , randomly selected negative case, x , i.e., s+ > . Here,242fiAn Empirical Evaluation Ranking Measures Respect Robustness Noisehigher ranking score means x+ ranked x , f (s+ ) g(s )distribution functions scores (Hilden, 1991). Following Hildens notation, AUCwrittenZZZAUC = Pr{s+ > |x+ x } =f (s+ )ds+ g(s )ds =F (s ) dG(s ).(1)s+ >sAUC calculated different ways empirical ROC curve; practical guide, see tutorial Fawcett (2004). ROC analysis integral partevaluation machine learning algorithms (Bradley, 1997). Whereas ROC curves widely(and rightly so) considered useful, theoretical practical shortcomings AUCpointed (Hilden, 1991; Adams & Hand, 1999; Bengio, Mariethoz, & Keller,2005; Webb & Ting, 2005; Lobo et al., 2008; Hand, 2009; Hanczar, Hua, Sima, Weinstein,Bittner, & Dougherty, 2010; Hand & Anagnostopoulos, 2013; Parker, 2013). particularproblem AUC incoherent, sense assumes differentcost distributions different classifiers (Hand, 2009). One first criticisms,insightful example showing area comparisons misleading, foundwork Hilden (1991). Hand (2009), too, considers AUC fundamentally incoherent. Recently, however, Hand Anagnostopoulos (2013) showed AUC coherentmeasure, certain assumptions may hold real applications.2.2 Scored Area ROC Curve (sAUC)AUC measures well positive negative cases ranked relativeother, consider actual ranking scores. means marginscores irrelevant. Intuitively, however, seems reasonable take scoressomehow account. Various alternatives AUC suggestedthat; example scored AUC (sAUC) (Wu & Flach, 2005; Wu, Flach, & Ferri, 2007).Let n+ denote total number positive cases n denote total numbernegative cases. Let {s1+ , ...sn+ } denote predicted ranking scores positive cases{s1 , ...sn } denote scores negative cases, s1+ ... sn+s1 ... sn . si+ sj assumed normalized [0, 1],= 1, ...n+ j = 1, ...n . Let I() indicator function I(true) = 1I(f alse) = 0. sAUC definedn+ n1 XXsAUC =(si+ sj )I(si+ > sj ).n+ n(2)i=1 j=1indicator function I(si+ > sj ) assesses ranking ability, factor (si+sj ) evaluates score differences. Without factor, Equation 2 equivalentAUC. exist variants soft-AUC (Calders & Jaroszewicz, 2007)probabilistic AUC (pAUC) (Ferri, Flach, Hernandez-Orallo, & Senad, 2005); however,according Vanderlooy Hullermeier (2008), none proposed alternativesAUC effective model evaluation. therefore consider variantscomparative analysis.243fiBerrar2.3 Area ROC Convex Hull (AUCH)ROC convex hull defined convex hull encloses operating pointsROC curve (Provost & Fawcett, 2001; Flach, 2010). Note, curve called convexstraight line interpolating two points curve never curve.1ROC convex hull results interpolation following k points,ordered based increasing values abscissa: origin (xi , yi ) = (0, 0),minimum set points spanning concavities, point (1,1). areaROC convex hull, AUCH, always least large AUC. AUCHcalculated shown Equation 3.AUCH =k1Xyi (xi+1 xi ) + 0.5(yi+1 yi )(xi+1 xi ).(3)i=12.4 H-measureorder address incoherence AUC, Hand (2009) proposed H-measure. Letdenote classification threshold, let TPR(t) FPR(t) denote correspondingtrue positive false positive rate, respectively. overall misclassification lossc+ + (1TPR(t))+c (FPR(t)), c+ cost associated misclassificationpositive case c cost associated misclassification negative case,+ prior probabilities positive negative cases, respectively.RHmeasure = 1+RQ(T (c), c)u(c)dc,R1cu(c)dc + (1 c)u(c)dc(4)0c = c+ /(c+ + c ); (c) = arg mint {c+ (1 TPR(t)) + (1 c) FPR(t)}; Q(t, c) =R1{c+ (1 TPR(t)) + (1 c) FPR(t)}(c+ + c ); u(c) = c(1 c)/ c(1 c)dc.0H-measure measure overall misclassification loss functionclass-specific misclassification costs prior probabilities positive negativecases (Hand, 2009). contrast, AUC measures ranking performance entirespace classification thresholds independent costs class priors. Flach et al.(2011) showed that, two small variations, H-measure linear transformationarea cost curve, proposed Drummond Holte (2006).2.5 Kolmogorov-Smirnov Statistic (KS)Kolmogorov-Smirnov goodness-of-fit test single sample test ordinal dataassesses whether distribution n scores follows specific theoretical empiricaldistribution (Sheskin, 2007). test statistic, KS, defined maximum valueabsolute difference two cumulative distributions. assess ranking1. mathematical terms, curve considered concave, whereas standard machine learningterminology uses convex.244fiAn Empirical Evaluation Ranking Measures Respect Robustness NoiseFigure 1: (a) Classification result toy data set 4 cases, (a) optimal model 3possible thresholds, (b) another model 3 possible thresholds; (c) yet another model,5 possible thresholds (Real: real class label, 1 = positive class; Score: predicted scorepositive class).ability classifier, distributions given true positive rates falsepositive rates classification thresholds. KS statistics simple geometricalinterpretation maximum distance TPR FPR curves,KS = max{|TPRi FPRi |},(5)TPRi FPRi denote true positive rate false positive rate iththreshold, respectively (see Figure 2 example).3. Truncated Average Kolmogorov-Smirnov Statistic (taKS)section, propose new ranking measure, called truncated average KolmogorovSmirnov statistic (taKS).3.1 Introductory ExampleLet us consider prediction results arbitrary test set comprising k cases,belong either positive negative class. optimal model assign score1 positive score 0 negative case. Consider another modelassigns scores s1 , s2 ...sk k test cases, s1 s2 ... sk , alsohappen lead perfect ranking. Figure 1 illustrates idea using toy data setk = 4 cases. models example indeed ranking performance,consequently, ranking measures like AUC distinguish them.nothing wrong matters relative ordering cases, irrespectiveactual ranking scores. Note, optimal model always allows exactly threepossible thresholds: (1) one threshold separating positive negative cases (t2Figure 1a); (2) one top threshold (i.e., TPR = 0 FPR = 0; t1 Figure 1a); (3)one bottom threshold (i.e., TPR = 1 FPR = 1; t3 Figure 1a).Assume three models enter data mining competition. Let usassume we, judges, see final predictions shown Figure 1.information models calibration scores,except higher scores reflect relative confidence case belongs positiveclass. assumptions shall allowed now.245fiBerrarprobably agree model (a) winner, one runnerup, (b) (c)? answer question, could consider ranking scores, example,calculating sum squared errors (SSE) related measure Brier score.approach would tell us model (c) SSE = 0.18 preferable model (b)SSE = 0.50. However, approach makes tacit assumption models, (b)(c), produce comparable scores range, maybe posterior probabilities [0, 1].course often reasonable assumption, necessarilycase. addition, assumption actually allowed.allowed assumptions calibration? Let us speculatedesign model (b) could produced probabilities larger 0.7 smaller0.4. Based minimum message length theory, may indeed make sense preventmodel making overly confident predictions, example, limiting estimatesspecific range (Korb, Hope, & Hughes, 2001).2 particular assumption,may look performance model (b) new light. fact, differencescores (a) (b) reduces merely different scaling. Could model (b)careful model? Granted, assumption scores comparable (e.g.,[0, 1]) plausible. point take actual scores account,make assumptions models calibrations. Furthermore,scores model (c) higher level granularity model (b), mightsay model (c) refined coarser model (b). refinementnecessarily indicate better model?Let us look another difference models: number possiblethresholds. number depends refinement scores, actualvalues. idea combine number ranking performance.3.2 Formal DetailsVisually, represent class discrimination plotting true positivefalse positive rates function threshold diagram. interpolatingpoints, obtain corresponding TPR FPR curves (henceforth referredTPR-FPR plot, also known Kolmogorov-Smirnov chart).Figure 2 illustrates TPR-FPR curves toy data set. test casethreshold classified positive case. instance, threshold t6 leads 4 truepositive 1 false positive classifications 4 positive cases 1 negative caselocated threshold; corresponding rates TPR = 54 FPR = 15 (Figure 2b).Class discrimination could quantified terms area curves (ABC).Definition 1. Area curvesarea curves (ABC) area TPR curve FPR curve,result interpolating true positive false positive rates based n2. reason overly confident predictions turn incorrect lead dramaticinformation-theoretic penalty; example, penalty incorrect prediction confidence 1. Korb et al. (2001), example, allowed range [min, max] = [0.5(n + 1)1 , (n + 0.5)(n + 1)1 ],n number test cases.246fiAn Empirical Evaluation Ranking Measures Respect Robustness NoiseFigure 2: (a) example binary classification task involving ten test cases. (b)ranking scores allow 11 classification thresholds, corresponding one TPR oneFPR point. Interpolation points gives TPR FPR curves. distancecurves maximal t6 .possible thresholds,ZnABC = |ZnTPR(x)dx1FPR(x)dx|.(6)1Note, absolute value necessary accept model could also performworse random guessing, means FPR curve could TPRcurve, thereby leading negative value ABC. remainder paper,work signed ABC, though. Applying trapezoidal rule, obtainABC =n1Xi=1n1X1TPRi (xi+1 xi ) + (TPRi+1 TPRi )(xi+1 xi )21FPRi (xi+1 xi ) + (FPRi+1 FPRi )(xi+1 xi )2i=1n1X11=(xi+1 xi ) TPRi + (TPRi+1 TPRi ) FPRi (FPRi+1 FPRi )22=i=1n1X12(xi+1 xi ) [(TPRi FPRi ) + (TPRi+1 FPRi+1 )],i=1247fiBerrarTPRi FPRi denote true positive rate false positive rate iththreshold, respectively. require thresholds abscissa equidistant[0, 1], first threshold linearly mapped 0 last threshold, n, mapped1. Denoting j = + 1,1 (this condition relaxed later). (xi+1 xi ) = n1obtainABC =n1n1i=1j=21 X1 X(TPRi FPRi ) +(TPRj FPRj ).2n 22n 2Note, true positive false positive rates always zero first threshold,TPR1 = FPR1 = 0, obtainn1ABC =1 X(TPRi FPRi )n1(7)i=2Consider optimal model assigns score 1 cases class 1 score0 cases class 0. Here, n = 3, ABC = 12 (1 0) = 12 . possibleanother, suboptimal model larger ABC. example, assume ranking score= 2 ranked positive case identical score = 1 ranked positive case.Figure 3c shows example suboptimal model ABC > 0.5. Thus, modelevaluation selection, ABC used directly.1However, use ABC derive performance measure. Consider factor n1Equation 7. replacing 1 denominator 2, obtain averagedistances points spanning TPR FPR curves, excluding start-pointend-point. consider new measure, value optimal modelalways 1, model score higher. immediately obviousthresholds abscissa scaled [0, 1], FPR TPR ordinaterange 0 1. area within boundaries cannot larger 1. Thus,distance pair (TPRi ,FPRi ) cannot larger 1, therefore averagedistances cannot larger 1.Definition 2. Truncated average Kolmogorov-Smirnov statistic (taKS)Let model produce ranking scores sa R, = 1..k k test cases belonging eitherpositive negative class, sa1 sa sa+1 sa , sb : 6= b sa 6= sb . Let n > 2denote number possible thresholds ti , ti1 < ti < ti+1 , scores allow. LetTPRi FPRi denote true positive false positive rates, respectively, resultparticular threshold ti . taKS defined average distancestrue positive rates false positive rates, excluding points (0,0)(1,1),n11 XtaKS =(TPRi FPRi ).n2i=2248(8)fiAn Empirical Evaluation Ranking Measures Respect Robustness NoiseNote, relax condition thresholds x-axisequidistant [0, 1]. matters taKS distances pointsspanning TPR FPR curves; scaling x-axis irrelevant. pseudocodederiving taKS given Appendix (algorithm 1).3.3 Illustration taKSFigure 3 shows TPR-FPR plots resulting taKS nine different predictionresults. scores models Figure 3a-b different, relative ordercases same, models ranking performance. Here, taKS 1.0optimal model (Figure 3a), 0.556 model allowing 11 thresholds (Figure 3b),0.600 model allowing 10 thresholds. examples also illustrate usingABC misleading: would erronously prefer model Figure 3c ABC= 0.533 optimal model ABC = 0.500.scores (b) (c) different case #1. Model (b) predicted 0.95whereas model (c) predicted 0.80. Provided models equally calibrated, onecould argue (b) better (has smaller SSE), taKS therefore misleading.3reasoning plausible, opposite could also happened. Supposemodel (c) produces 0.95 cases #1 #2. value taKS remains(i.e., 0.60), points us better model. Either scenario equally likelypriori, correct incorrect decisions balance, average, example.means half time, taKS points us better model. Note, AUCindifferent examples, making difference (b) (c) either scenario.used AUC, could guess one better, (b) (c); thus, wouldcorrect half time, too. Consequently, compared AUC (orranking measure, matter), taKS provide advantage exampleprovide disadvantage, either.Figure 3d-f shows three models make ranking errors. modelsranking performance, score different taKS. model Figure 3e scoreslarger taKS model Figure 3f. model Figure 3e assigned score(0.80) cases #1 #2; model Figure 3f assigned score (0.60)cases #4 #5. models allow number thresholds (i.e., 10),taKS identifies model Figure 3e preferable one larger ABC.Figure 3g-i show three particular models. model Figure 3g perfect antimodel predicts like mirror image optimal model. Consequently, resultingtaKS 1. Another particular model shown Figure 3h. model assignsscore cases; thus, allows two possible thresholds, TPR FPRcurves fall onto line. ABC defined, taKS defined,either. Figure 3i shows results random prediction, leading taKS ABCzero. Note, AUC defined Figure 3h; AUC 0.5AUC Figure 3i.3. Thanks anonymous reviewer pointing out!249fiBerrarFigure 3: TPR (red) FPR (black) curves taKS nine classification results (cf.inset table). (a) Best possible predictions 3 possible thresholds; (b) perfect ranking11 possible thresholds; (c) perfect ranking 10 possible thresholds; (d) predictionranking errors 11 possible thresholds; (e) prediction ranking errors 10possible thresholds; (f) prediction ranking errors 10 possible thresholds; (g) worstpossible prediction 3 possible thresholds; (h) cases ranking score,neither ABC taKS defined; (i) random prediction 5 possible thresholds.250fiAn Empirical Evaluation Ranking Measures Respect Robustness Noise3.4 Notes taKSname implies, taKS closely related Kolmogorov-Smirnov (KS) statistic,i.e., maximum distance TPR FPR curves (cf. Equation 5). contrast,taKS average distance curves, excluding start- endpoint(0,0) (1,1), respectively. introductory example (Figure 2), KS = 35 (forthreshold t6 ) taKS = 13 .optimal model, scores 1 positive cases 0 negative cases,taKS = 1. Also, model assigns score s+ positivescore negative cases taKS = 1. Thus, taKS distinguishoptimal model another model that, say, assigns 0.7 positive cases 0.4negative cases. worst-possible model (i.e., one assigns 1 casesclass 0 0 cases class 1), taKS = 1. expected value taKS randommodel 0. model assigns score cases, taKS definednumber possible thresholds n = 2, would lead division zeroEquation 8. Graphically, TPR FPR curves straight lines (0,0)(1,1). Note, conventional ranking measures AUC definedcase.Like AUC, taKS aggregate measure performance final classificationresult. advantage ROC plots visualize performanceone classifier diagram, contrast TPR-FPR plots usedpaper. limitation taKS following. two models equally calibrated,scenarios taKS larger model larger SSE, thereby leadingus potentially inferior model (for examle, cf. Figure 3b-c). average, however,scenarios balance scenarios opposite case.4. Robustness Analysisconsidered synthetic real-world data sets study robustness rankingmeasures various types levels noise. adopted approach similiar onedescribed Ferri et al. (2009). main idea same: consider two models, C1C2 , C1 truly better model. Then, progressively added noise.question whether performance measures still identify C1 better model.measure Xi considered robust another measure Xj Xi less affectedincreasing levels noise. Below, describe different types noiseinvestigated experiments. experiments described pseudocode Appendixcarried R2.10.1 (R Development Core Team, 2009).4.1 Synthetic Data Setsconsidered predictions two classifiers, C1 C2 , hypothetical test setcomprising 100 cases, described Ferri et al. (2009). number test casesarguably little influence experiments, provided small.generated vector 100 real numbers randomly sampling uniform distribution[0, 1], represent ranking scores positive class. membership scoresinterpreted class posterior probabilities. positive class label assigned251fiBerrarnumbers 0.5, negative class label assigned remaining numbers.Next, randomly selected 10 scores replaced real number,randomly sampled [0, 1]. resulting numbers represented predictions C1 .threshold 0.5, expected accuracy C1 95% expect halfnew scores (i.e., 5 10) wrong.predictions C2 C1 , except selected 10predictions random replaced real number, randomly sampled[0, 1]. Thus, without noise, C2 expected perform worse C1 , expectedaccuracy 90%. difference two classifiers, however, expectedbecome blurred increasing levels noise.considered three types noise: misclassification noise, probability noise, classproportion noise (described below). level noise, generated model, C1C2 , n = 10000 times, time evaluating performance based different rankingmeasures. measure, counted many times erroneously indicatedC2 better C1 . Let X() denote value performance measure Xclassifier. error rate measure X given1X(C2 ) > X(C1 )n1X0.5 X(C2 ) = X(C1 )(X) =(X), (X) =ni=10X(C2 ) < X(C1 )(9)plotting (X) measures function noise level, compareresilience noise. example, measure Xi robust measure Xj ,error rate Xi consistently lower; hence, curve Xicurve Xj .4.1.1 Misclassification NoiseFirst, considered noise affects class labels. experiment evaluatessensitive measures respect mislabelings. investigated noise levels ranging0% (i.e., class label altered) 100% (i.e., class label altereddetermined flip coin). noise level 0%, expect error scores0 C1 clearly better C2 . contrast, class labels random,expect difference models, error score around 0.5.class label noise 0% 70% (Figure 4), error ratesH-measure Kolmogorov-Smirnov statistic slightlymeasures. AUCH slightly robust AUC taKS less robustH-measure Kolmogorov-Smirnov statistic. sAUC least robustexperiment. Overall, however, see dramatic differences measures.expected, measures around 0.5 noise level 100%. error ratesAUC taKS virtually identical experiment.252fiAn Empirical Evaluation Ranking Measures Respect Robustness NoiseFigure 4: Synthetic data, experiment #1. Robustness misclassification noise.4.1.2 Probability Noisenoise affects class membership scores. experiment evaluates sensitivemeasures posterior class probabilities well estimated. noiserandomly sampled uniform distribution [x, x], x ranged 0 (i.e.,noise) 0.5 (i.e., 100% noise) stepsize 0.005. noise added rankingscores.noise affects class posterior probabilities (Figure 5), sAUC performsworst. Kolmogorov-Smirnov statistic next least robust, followed Hmeasure. AUC taKS robust experiment; error ratesalmost identical. AUCH slightly less robust two measures.4.1.3 Class Proportion Noisenoise affects class proportions. experiment evaluates sensitive measures changes class distribution drifts. changed class frequenciesprogressively deleting x% cases positive class. noise x% ranged 5%95%.noise affects class frequencies (Figure 6), measures except sAUC perform similarly. AUC, AUCH, H-measure, KS, taKS, error rates remarkably low noise levels around 80%. Thus, contrast sAUC, measurescope quite well even classes heavily imbalanced.253fiBerrarFigure 5: Synthetic data, experiment #2. Robustness probability noise.4.2 Real-World Data Setsexperiments synthetic data sets, investigated wide range noise levels,including arguably unrealistically high real-world data sets. Therefore,limited next experiments noise level neither small causenoticeable effect large unrealistic. assumed noise level 10% wouldmeet requirement.experiments synthetic data sets, observed class proportionnoise little effect performance measures, except unrealistically high noiselevels. Therefore, excluded type noise following experiments. Instead,considered new type noise could study before: attribute noise, affectsattributes either training set entire data set.used naive Bayes learning construct base classifier. concrete learningalgorithm assumed little influence experimental results. denotedpredicted scores classifier C1 . randomly selected 10% scoresreplaced score random number, uniformly sampled [0, 1].result C2 . Without noise, C1 clearly better corrupted competitor, C2 .used ten benchmark data sets UCI repository (Bache & Lichman, 2013).Experiment #1: Misclassification Noise Affecting Entire Data Setfirst experiment, investigated resilience noise affecting class labelsentire data set. data set, selected 10% class labels randomly254fiAn Empirical Evaluation Ranking Measures Respect Robustness NoiseFigure 6: Synthetic data, experiment #3. Robustness class proportion noise.assigned either positive negative label. Then, compared performance C1C2 10-fold cross-validation. repeated experiment 1000 times recordedmany times C2 declared better model respective ranking measure (seeAppendix A, algorithm 2).Experiment #2: Misclassification Noise Affecting Training Setsecond experiment, investigated resilience noise affecting class labelstraining set. training set, selected 10% class labels randomlyassigned either positive negative label. Then, compared performance C1C2 10-fold cross-validation. repeated experiment 1000 times recordedmany times C2 declared better model respective ranking measure (seeAppendix A, algorithm 3).Experiment #3: Attribute Noise Affecting Entire Data Setthird experiment, investigated resilience noise affecting attribute values entire data set. data set attribute, selected 10%values randomly permuted them. Then, compared performance C1 C210-fold cross-validation. repeated experiment 1000 times recorded manytimes C2 declared better model respective ranking measure (see AppendixA, algorithm 4).255fiBerrarExperiment #4: Attribute Noise Affecting Training Setfourth experiment, investigated resilience noise affecting attribute values training set only. training set attribute, selected 10%values randomly permuted them. Then, compared performance C1 C210-fold cross-validation. repeated experiment 1000 times recorded manytimes C2 declared better model respective ranking measure (see AppendixA, algorithm 5).Table 1 shows error rates ranking measures real-world data sets.make several interesting observations. First, data sets, error ratesperformance measures relatively small drastically different other.exception sAUC, whose error rates indeed remarkably high (between 64.8%78.3%) data sets Liver Transfusion four experiments. LiverTransfusion data sets 6 4 attributes, respectively, comparativelydifficult classify data sets.4 data sets Liver Transfusion,error rates highest four experiments, whereas error rates virtuallyneglibile data set Credit. speculate data sets intrinsicallyeasy classify, injected noise negligible effect ranking measures.data set easy classify, expect classifier produces scores close0 1, fewer scores around 0.5. Now, created C2 randomly selectingscores C1 re-assigning random number [0, 1] scores. meansexpect larger number extreme scores (which likelycorrect, classification tasks relatively easy) mapped less extreme scores.Consequently, quite easy identify C1 better model, regardless whichevermeasure used. contrast, data set intrinscically difficult classify,even tiny amounts added noise may wreak havoc. seems case sAUCparticular. Note, sAUC implicitly rewards classifiers boldness: sAUCclassifier scores close 0 1 larger sAUC classifierless extreme scores, although latter may make fewer ranking errors; VanderlooyHullermeier (2008, p.252) give illustrative example.Second, error rates are, overall, higher noise affects entire data setserror rates noise affects training sets. unexpectedlatter case, portion original data remains intact.Third, overall, observe positive correlation measures, differences error rates remarkable data sets. example, experiment #2,error rate H-measure (10.9%) three times error rate AUC(3.3%) data set Spect; hand, error rate AUC (1.4%) seventimes H-measure (0.2%) data set House. Interestingly, H-measurehas, average, slightly higher error rates AUC taKS noise affectsclass labels. somewhat unexpected H-measure performed relativelywell corresponding experiments synthetic data sets (Figure 4). However,differences average error rates relatively small might perhaps explained4. checked analyzing (uncorrupted) data sets 100 times repeated 10-fold cross-validation.naive Bayes classifier achieved lowest AUC Liver Transfusion.256fiAn Empirical Evaluation Ranking Measures Respect Robustness NoiseExperiment #1Experiment #2Experiment #3Experiment #4SonarSpectHeartLiverIonosphereHouseCylinderCreditTransfusionPimaSonarSpectHeartLiverIonosphereHouseCylinderCreditTransfusionPimaSonarSpectHeartLiverIonosphereHouseCylinderCreditTransfusionPimaSonarSpectHeartLiverIonosphereHouseCylinderCreditTransfusionPimaH-measure10.3013.901.5018.100.400.200.400.005.500.405.3010.900.3016.500.000.200.000.003.400.108.008.800.5018.400.100.000.300.003.900.105.5012.100.5014.900.100.000.000.002.500.10AUC8.808.901.8016.700.701.501.000.003.400.004.803.300.2013.200.001.400.100.000.900.006.303.500.9015.600.300.000.200.002.100.004.504.000.9013.400.000.000.000.001.500.10AUCH11.709.601.7017.500.801.201.200.004.600.106.704.500.3014.000.001.300.100.001.300.008.103.400.7016.800.300.000.300.003.000.005.805.200.7013.700.000.000.100.002.000.10sAUC10.702.800.1070.200.000.007.900.1078.300.106.300.700.0066.500.000.002.900.0069.800.106.001.400.1064.800.000.002.500.1074.600.005.401.200.0065.900.000.005.100.0070.800.20KS12.0511.201.6019.300.500.100.800.007.301.007.156.950.7017.100.100.200.100.002.900.309.406.901.0021.000.100.000.700.003.800.205.857.100.8017.200.200.000.300.002.800.10taKS7.008.801.8016.800.501.000.800.003.200.003.402.800.2013.200.001.100.000.000.700.004.302.900.9015.600.300.000.000.001.700.003.203.400.9013.500.000.000.000.001.500.10Table 1: Error rates [%] ranking measures. Experiment #1: 10% class labelsdata set randomly assigned; Experiment #2: 10% class labelstraining set randomly assigned; Experiment #3: 10% values attributerandomly permuted data set; Experiment #4: 10% valuesattribute randomly permuted training set. data set analyzed 1000times 10-fold cross-validation. Lowest error rates shown boldface.257fiBerrarstatistical fluctuations. alternative explanation experiments syntheticdata, ranking scores [0, 1] equally likely. experiments real-worlddata sets, however, case. data sets relatively easy classify.Therefore, expect see scores concentrated towards 1 0 fewer scoresaround 0.5, might negative effect H-measure; however,speculation.5. Discussion ConclusionsRanking measures play important role model evaluation selection. Usingsynthetic real-world data sets, compared robustness various ranking measuresdifferent types levels noise. AUC recently criticized incoherentmeasure (Hand, 2009; Hand & Anagnostopoulos, 2013; Parker, 2013); nonetheless,arguably robust among conventional measures experiments.important finding, lends empirical credibility AUC complementsrecently published vindications (Flach, Hernandez-Orallo, & Ferri, 2011; Hernandez-Oralloet al., 2012; Bradley, 2013). AUC also robust sAUC, confirmsobservations Vanderlooy Hullermeier (2008) sAUC efficientalternative AUC.experiments synthetic data sets, KS H-measure performed bestmisclassification noise. probability noise, however, performed worseAUC AUCH. metrics except sAUC performed less similarlyclass proportion noise. Overall, differences metrics respectresilience noise rather small relatively low noise levels synthetic data. Also,investigated real-world data sets, magnitude difference arguablydramatic. sAUC used caution, though, performedpoorly experiments synthetic data (notably class proportion noise, Figure 6)experiments difficult real-world data sets (Liver, Transfusion).observations confirm earlier results, showed sAUC robustnoise (Ferri et al., 2009).experiments allow conclusion H-measure preferableAUC respect robustness. Also, believe H-measure arguablyintricate measures, geometrical interpretation straightforward AUC. course mean H-measure usefulAUC always trusted. Hilden (1991) describes interesting exampleAUC fact misleading. Also, note Parker (2013) comes conclusiondifferent ours: recommends H-measure, empirical theoreticalgrounds. However, Parker evaluated measure based (dis-)agreementmeasures, based robustness noise.also proposed novel ranking measure, called taKS. key characteristicmeasure simplicity. taKS easily derived, simple geometrical interpretation average distance two curves: true positive false positiverate curve, plotted function classification threshold. study, taKSremarkably robust noise. However, caution arguments AUC(Hilden, 1991; Hand, 2009; Hand & Anagnostopoulos, 2013) dismissed light258fiAn Empirical Evaluation Ranking Measures Respect Robustness Noiseheartedly. Particularly, Parker (2013) recently extended Hands analysis, showingrelated metrics (the area Cohens curve average precision) similarly incoherent. According Parkers theorem 1, problem measures resultintegration possible classification thresholds. taKS measured via normalizedsummation, could similarly incoherent. experimental results promising,research needed elucidate usefulness taKS. Many open questions remain,example, precise relation taKS measures, example,partial AUC (McClish, 1989)? taKS (in-)coherent? particularly,role data set idiosyncrasies selection ranking measure? also remember results empirical studies viewed isolationbackdrop previous research. AUC remarkably robust experiments,successfully used numerous studies; addition, recently vindicatedtheoretically (Hernandez-Orallo et al., 2012). Taken together, therefore concludeAUC might still good choice practical applications.Finally, note investigated metrics share important caveat: scalars,cannot paint full picture classifiers performance. condensing performancesingle number, bound lose important information behaviormodel range operating conditions, generally better described twodimensional plots ROC curves. One always wary reading muchsingle number. single number misleading. hand, scalarsobvious advantage allow us tabulate results various classifiers easily.desirable compare large number models, generally casedata mining competitions, example.Acknowledgmentsthank three anonymous reviewers much detailed constructivecomments greatly helped improve manuscript.259fiBerrarAppendix A. PseudocodesAlgorithm 1 Pseudocode taKS.Require: matrix X k rows (one test case) 2 columns (first column: real classlabel; second column: predicted score positive class, s+ ). X ordered based decreasingvalues s+ ; least two scores must different. # scores identical taKSdefined.1: TPR, FPR < 0 > # lists, containing one element: 02: tp, fp 03: np number positive cases X; nn number negative cases X4: 15: (i number rows X)6: threshold7: ii8: scorei s+ ith case9:(scoreii+1 == scorei ) (ii +1 number cases X)10:threshold threshold + 111:ii ii + 112:end13: tp number positive cases threshold14: fp number negative cases threshold15: push tp/np onto TPR; push fp/nn onto FPR16: threshold + 117: end18: taKS mean(TPR\{first, last} FPR\{first, last})19: return taKS260fiAn Empirical Evaluation Ranking Measures Respect Robustness NoiseAlgorithm 2 Real-world data set, experiment #1. Corrupt 10% class labelsdata setRequire: data set1: = 1 10002: Randomly select 10% cases randomly assign class label.3:k = 1 104:Sample k-th training k-th test set corrupted D.5:Build naive Bayes classifier k-th training set.6:Apply classifier k-th test set obtain output C1k .7:Derive Xk (C1k ).8:Randomly select 10% prediction scores C1k .9:Replace selected score random number [0, 1] obtain C2k .10:Derive Xk (C2k ).11:end12:X(C1 ) average Xk (C1k ).13:X(C2 ) average Xk (C2k ).14:X(C2 ) > X(C1 )15:(X) (X) + 116:else17:X(C2 ) == X(C1 )18:(X) (X) + 0.519:else20:(X) (X) + 021:end22:end23: end24: return (X)261fiBerrarAlgorithm 3 Real-world data set, experiment #2. Corrupt 10% class labels pertraining setRequire: data set1: = 1 10002:k = 1 103:Sample k-th training k-th test set D.4:Randomly select 10% training cases.5:Randomly assign class label selected cases.6:Build naive Bayes classifier k-th corrupted training set.7:Apply classifier k-th test set obtain output C1k .8:Derive Xk (C1k ).9:Randomly select 10% prediction scores C1k .10:Replace selected score random number [0, 1] obtain C2k .11:Derive Xk (C2k ).12:end13:X(C1 ) average Xk (C1k ).14:X(C2 ) average Xk (C2k ).15:X(C2 ) > X(C1 )16:(X) (X) + 117:else18:X(C2 ) == X(C1 )19:(X) (X) + 0.520:else21:(X) (X) + 022:end23:end24: end25: return (X)262fiAn Empirical Evaluation Ranking Measures Respect Robustness NoiseAlgorithm 4 Real-world data set, experiment #3. Corrupt 10% attribute valuesdata setRequire: data set1: = 1 10002: Randomly select 10% values attribute D.3: Randomly permute selected values per attribute.4:k = 1 105:Sample k-th training k-th test set corrupted D.6:Build naive Bayes classifier k-th corrupted training set.7:Apply classifier k-th test set obtain output C1k .8:Derive Xk (C1k ).9:Randomly select 10% prediction scores C1k .10:Replace selected score random number [0, 1] obtain C2k .11:Derive Xk (C2k ).12:end13:X(C1 ) average Xk (C1k ).14:X(C2 ) average Xk (C2k ).15:X(C2 ) > X(C1 )16:(X) (X) + 117:else18:X(C2 ) == X(C1 )19:(X) (X) + 0.520:else21:(X) (X) + 022:end23:end24: end25: return (X)263fiBerrarAlgorithm 5 Real-world data set, experiment #4. Corrupt 10% attribute valuesper training setRequire: data set1: = 1 10002:k = 1 103:Sample k-th training k-th test set D.4:training set only: select 10% values attribute.5:Randomly permute selected values per attribute.6:Build naive Bayes classifier k-th corrupted training set.7:Apply classifier k-th test set obtain output C1k .8:Derive Xk (C1k ).9:Randomly select 10% prediction scores C1k .10:Replace selected score random number [0, 1] obtain C2k .11:Derive Xk (C2k ).12:end13:X(C1 ) average Xk (C1k ).14:X(C2 ) average Xk (C2k ).15:X(C2 ) > X(C1 )16:(X) (X) + 117:else18:X(C2 ) == X(C1 )19:(X) (X) + 0.520:else21:(X) (X) + 022:end23:end24: end25: return (X)264fiAn Empirical Evaluation Ranking Measures Respect Robustness NoiseReferencesAdams, N., & Hand, D. (1999). Comparing classifiers misallocation costsuncertain. Pattern Recognition, 32 (7), 11391147.Bache, K., & Lichman, M. (2013).UCI machine learning repository.[http://archive.ics.uci.edu/ml]. Irvine, CA: University California, SchoolInformation Computer Science.Bamber, D. (1975). area ordinal dominance graph areareceiver operating characteristic curve. Journal Mathematical Psychology, 12, 387415.Bengio, S., Mariethoz, J., & Keller, M. (2005). expected performance curve. ProceedingsICML 2005 workshop ROC Analysis Machine Learning, 916.Berrar, D., & Flach, P. (2012). Caveats pitfalls ROC analysis clinical microarrayresearch (and avoid them). Briefings Bioinformatics, 13 (1), 8397.Bradley, A. (1997). use area ROC curve evaluation machinelearning algorithms. Pattern Recognition, 30 (3), 11451159.Bradley, A. (2013). ROC curve equivalence using Kolmogorov-Smirnov test. PatternRecognition Letters, 34 (5), 470475.Calders, T., & Jaroszewicz, S. (2007). Efficient AUC optimization classification. Kok,J., Koronacki, J., de Mantaras, R., Matwin, S., Mladenic, D., & Skowron, A. (Eds.),Proceedings 11th European Conference Principles Practice KnowledgeDiscovery Databases, pp. 4253. Springer.Caruana, R., & Niculescu-Mizil, A. (2004). Data mining metric space: empiricalanalysis supervised learning performance criteria. Proceedings 10th ACMSIGKDD International Conference Knowledge Discovery Data Mining, pp.6978. ACM Press.Drummond, C., & Holte, R. (2006). Cost curves: improved method visualizingclassifier performance. Machine Learning, 65, 95130.Fawcett, T. (2004). ROC graphs: Notes practical considerations researchers. KluwerAcademic Publishers, 138.Ferri, C., Flach, P., Hernandez-Orallo, J., & Senad, A. (2005). Modifying ROC curvesincorporate predicted probabilities. Proceedings 2nd Workshop ROCAnalysis Machine Learning. Bonn, Germany.Ferri, C., Hernandez-Orallo, J., & Modroiu, R. (2009). experimental comparisonperformance measures classification. Pattern Recognition Letters, 30, 2738.Flach, P. (2003). geometry ROC space: understanding machine learning metricsROC isometrics. Proceedings 20th International ConferenceMachine Learning, pp. 194201. AAAI Press.Flach, P. (2010). ROC analysis. Sammut, C., & Webb, G. (Eds.), EncyclopediaMachine Learning, pp. 869874. Springer.265fiBerrarFlach, P., Hernandez-Orallo, J., & Ferri, C. (2011). coherent interpretation AUCmeasure aggregated classification performance. Proceedings 28thInternational Conference Machine Learning, pp. 6978.Hanczar, B., Hua, J., Sima, C., Weinstein, J., Bittner, M., & Dougherty, E. (2010). Smallsample precision ROC-related estimates. Bioinformatics, 26, 822830.Hand, D. (2006). Classifier technology illusion progress. Statistical Science,21 (1), 114.Hand, D. (2009). Measuring classifier performance: coherent alternative areaROC curve. Machine Learning, 77, 103123.Hand, D., & Anagnostopoulos, C. (2013). area receiver operating characteristic curve appropriate measure classifier performance?. PatternRecognition Letters, 34 (5), 492495.Hanley, J., & McNeil, B. (1983). method comparing areas receiver operatingcharacteristic curves derived cases. Radiology, 148 (3), 839843.Hernandez-Orallo, J., Flach, P., & Ferri, C. (2012). unified view performance metrics:Translating threshold choice expected classification loss. Journal MachineLearning Research, 13, 28132869.Hilden, J. (1991). area ROC curve competitors. Medical DecisionMaking, 11 (2), 95101.Korb, K., Hope, L., & Hughes, M. (2001). evaluation predictive learners:theoretical empirical results. DeRaedt, L., & Flach, P. (Eds.), Lecture NotesArtificial Intelligence, pp. 276287. Springer.Lobo, J., Jimenez-Valverde, A., & Real, R. (2008). AUC: misleading measureperformance predictive distribution models. Global Ecology Biogeography, 17,145151.McClish, D. (1989). Analyzing portion ROC curve. Medical Decision Making, 9 (3),190195.Parker, C. (2013). measuring performance binary classifiers. KnowledgeInformation Systems, 35, 131152.Prati, R., Batista, G., & Monard, M. (2011). survey graphical methods classification predictive performance evaluation. IEEE Transactions Knowledge DataEngineering, 23 (11), 16011618.Provost, F., & Fawcett, T. (2001). Robust classification imprecise environments. MachineLearning, 42 (3), 203231.R Development Core Team (2009). R: Language Environment Statistical Computing. R Foundation Statistical Computing, Vienna, Austria. ISBN 3-900051-07-0.Sheskin, D. (2007). Handbook Parametric Nonparametric Statistical Procedures. 4thEdition, Chapman Hall, London/New York.Vanderlooy, S., & Hullermeier, E. (2008). critical analysis variants AUC. MachineLearning, 72, 247262.266fiAn Empirical Evaluation Ranking Measures Respect Robustness NoiseWebb, G., & Ting, K. (2005). application ROC analysis predict classificationperformance varying class distributions. Machine Learning, 58 (1), 2532.Wu, S., & Flach, P. (2005). scored AUC metric classifier evaluation selection.Proceedings Second Workshop ROC Analysis Machine Learning.Wu, S., Flach, P., & Ferri, C. (2007). improved model selection heuristic AUC.Kok, J., Koronacki, J., de Mantaras, R., Matwin, S., Mladenic, D., & Skowron, A.(Eds.), Proceedings 18th European Conference Machine Learning (ECML2007), pp. 478489. Springer.267fiJournal Artificial Intelligence Research 49 (2014) 111-142Submitted 10/13; published 02/14Towards Minimizing Disappointment Repeated GamesJacob W. CrandallJCRANDALL @ MASDAR . AC . AEMasdar Institute Science TechnologyAbu Dhabi, United Arab EmiratesAbstractconsider problem learning repeated games arbitrary associates. Specifically, study ability expert algorithms quickly learn effective strategies repeatedgames, towards ultimate goal learning near-optimal behavior arbitrary associatewithin handful interactions. contribution three-fold. First, advocate newmetric, called disappointment, evaluating expert algorithms repeated games. Unlike minimizing traditional notions regret, minimizing disappointment repeated games equivalentmaximizing payoffs. Unfortunately, eliminating disappointment impossible guarantee general. However, possible expert algorithm quickly achieve low disappointmentmany known classes algorithms many games. Second, show popular existing expertalgorithms often fail achieve low disappointment variety associates, particularlyearly rounds game. Finally, describe new meta-algorithm applied existingexpert algorithms substantially reduce disappointment many two-player repeated gamesassociates follow various static, reinforcement learning, expert algorithms.1. IntroductionMany real-world environments require machines interact repeatedly independent, selfinterested entities, including people machines. finitely repeated interactionsendure unknown periods time ranging minutes, hours, days, months, even years.successful interactions, machines must employ algorithms quickly learn goodstrategies arbitrary (likely adaptive) associates.Many algorithms repeated games developed last several decades, including reinforcement learning algorithms (e.g., Watkins & Dayan, 1992; Littman, 1994, 2001; Bowling& Veloso, 2002; Greenwald & Hall, 2003; Crandall & Goodrich, 2011), opponent modeling algorithms (e.g., Fudenberg & Levine, 1998; Ganzfried & Sandholm, 2011), algorithms computingdesirable equilibria (e.g., Littman & Stone, 2005; Cote & Littman, 2008; Johanson, Bard, Lanctot,Gibson, & Bowling, 2012), expert algorithms (e.g., Auer, Cesa-Bianchi, & Fischer, 2002; deFarias & Megiddo, 2004; Auer, Cesa-Bianchi, Freund, & Schapire, 1995). sometimes successful, algorithms typically one following shortcomings precludeuse. First, many algorithms learn slowly. achieve successful behaviorthousands interactions, even simple games (e.g., Crandall & Goodrich, 2011). Second,existing algorithms often myopic. fail learn profitable strategies long-term interactions. Third, many algorithms successful limited set associates.long-term goal identify algorithms learn near-optimal behavior arbitrary associate within handful interactions. paper, focus potentialexpert algorithms achieve goal two-player normal-form games. round, expertalgorithm selects expert predefined set experts dictate agents behaviorc2014AI Access Foundation. rights reserved.fiC RANDALLround. algorithmic structure several potential strengths. First, offers simple flexible design process. One create experts perform well specific scenarios agentlikely encounter (such paired particular associate) without worrying oneexpert must perform well scenarios. expert algorithm responsible finding bestexpert specific scenario run time. Second, experts complicated necessary.Though focus normal-form games paper, experts compute complex equilibriaexecute sophisticated algorithms also derived stochastic dynamics games. twoadvantages give rise third potential advantage: expert algorithms potential learneffective strategies quickly, particularly experts employ precomputed strategies.expert algorithm evaluated based ability learn select successful experts. Severalmetrics defined used literature measure success expert algorithmprocess, perhaps popular regret (Foster & Vohra, 1999; Greenwald &Jafari, 2003; Bowling, 2004; Gordon, Greenwald, & Marks, 2008). Loosely, expert algorithms(external) regret difference payoffs agent would received alwaysfollowed best expert associates observed actions payoffs actually received.context repeated games, regret desirable notion since provides simple generalizablebenchmark success. Unfortunately, minimizing regret always correspond maximizingpayoffs. paper, advocate alternative metric, called disappointment, equivalentmaximizing payoffs still providing simple generalizable benchmark success.many algorithms guaranteed achieve regret (e.g., Bowling, 2004;Foster & Vohra, 1999; Gordon et al., 2008), show impossible algorithmguaranteed disappointment unknown associate. However, possiblealgorithm quickly achieve maintain low disappointment classes algorithmsmany repeated games. first evaluate effectiveness several existing expert algorithmsachieve low disappointment paired various (1) non-adapting, (2) reinforcement learning,(3) expert algorithms two-player games. Finally, describe new meta-algorithmenhancing expert algorithms. show substantially reduces disappointmentalgorithms associates short- long-term interactions.Section 2, discuss evaluation expert algorithms. doing, define disappointment establish several theoretical results, derive research agenda. Section 3,define method generating effective set experts repeated normal-form games.evaluate ability existing expert algorithms select effective experts across ten different repeated games Section 4. propose meta-algorithm enhancing expert algorithmsSection 5, evaluate effectiveness Section 6. conclude reflect Section 7.2. Evaluating Expert Algorithmssection, review existing evaluation metrics repeated games, define discuss disappointment, compare existing metrics. Finally, formally state research agenda.2.1 Notation Terminologyconsider two-player repeated normal-form games, consist set joint actions =A1 A2 , Ai player (or agent) action set, payoff function : R2 .round t, agent independently selects actionati Ai . resulting joint action= (a1 , a2 ) produces payoff pair m1 (a ), m2 (a ) , mi (at ) payoff agent i.112fiT OWARDS INIMIZING ISAPPOINTMENTR EPEATED G AMESsimplicity, assume that, A, mi (a) [0, 1], maxaA mi (a) = 1, minaA mi (a) = 0.Play repeats unknown number rounds. refer two agents i.use terms policy strategy refer agents select actions. Agentpolicy probability distribution action set Ai . probability distribution specifiesprobability agent selects action. strategy rule defines agents policiesstate world. context experts used paper, world states typically definedprevious joint action played agents game. use notation ui (i , )denote agent expected payoff round plays policy associate plays .use notation (i , ) denote agent average expected per-round payoff timeperpetually plays strategy associate perpetually plays strategy .make several assumptions. First, initially assume game played perfect information: players know others payoff matrix. later relax assumption accountoccasions players incorrectly assess associates payoffs. Second, focusgeneral-sum repeated games, specifically address constant-sum games. However, manyconcepts discussed herein also apply constant-sum games.round t, expert algorithm employed agent selects expert ti setexperts . expert dictates policy executed agent round t. simplicityanalysis, literature often considers experts always play single action policy.make assumption paper. Experts also sophisticated automata learningalgorithms.2.2 MetricsCurrently, universally accepted metric evaluating well expert algorithms selectexperts repeated games. Existing metrics typically define desirable performance benchmarkalgorithm achieve compare payoffs obtained algorithms benchmark.reliable indicators success, metrics payoff comparable.Definition 2.1 (Payoff comparable): Let B two distinct algorithms, let o,M,To,M,TBdenote average per-round payoff obtained B, respectively, associaterepeated game length payoff matrix . evaluation metric payoff comparable if,scenario defined o, , , rates higher B o,M,T> o,M,T.Bwords, evaluation metric payoff comparable success defined metricimplies success respect maximizing agents average per-round payoff.seek evaluation metric (1) defines generalizable (and desirable) performance benchmark (2) payoff comparable. discuss several metrics respect two attributes.2.2.1 R EGRETRegret become popular performance metric evaluating effectiveness learning rulesrepeated games. notion re-discovered independently several times variousnames (Foster & Vohra, 1999). Several forms regret formulated, including externalregret internal (or swap) regret. simplicity argument, focus external regret.113fiC RANDALLFormally, agent total external regret roundRTi = maxXuti (, ati )Xmi (at ),(1)t=1t=1uti (, ati ) agent expected payoff round if, round {1, , t}, agentfollowed expert agent played observed action ai . Agent averageexternal regret roundRTi =RTi.(2)RTi 0 means expert algorithm done least well would donealways followed best expert given associate would still played observed actions.Agent said regret limT RTi 0. agents use no-regret learningrules, play converges correlated equilibria (Greenwald & Jafari, 2003; Gordon et al., 2008).performance benchmark (the estimated payoffs best expert) used calculate regretsimple generalizable scenario. However, regret payoff comparable. assumptionagent behavior affect agent future actions clearly violated agentexecutes learning algorithm even simple automata. limiting assumption means regretminimization imply payoff maximization. fact, demonstrate Section 2.3, lowregret sometimes strongly correlates low payoffs.Several alterations regret made attempt alleviate shortcomings. example, Chang (2007) proposed modified form regret considers multi-period strategies.modification provides effective evaluations simple automata tit-for-tat (atexpense increased computation complexity), still address general deficiencyregret minimization imply payoff maximization ones associate learns. Alternatively, Bowling (2004) embraced regret minimum criterion despite limitations, advocatedmore: algorithm also converge achieve negative regret self play. Thoughaddition makes metric stronger, make metric payoff comparable.2.2.2 E XPERIENCED R EGRETalternative metric devised de Farias Megiddo (2003, 2004), refer experienced regret (e-regret), compares agents average payoff rounds actual averagepayoff obtained successful expert rounds followed. Let xTi () averagepayoff obtained agent round followed expert round , given by1PTI(, ti )mi (at ),(3)xTi () = t=1PTt)I(,t=1I(, ti ) indicator function returns 1 = ti 0 otherwise. Then, e-regret1Xmi (at ).EiT = max xTi ()t=11. exception, never played time , xTi () = 0.114(4)fiT OWARDS INIMIZING ISAPPOINTMENTR EPEATED G AMESregret (Eq. 1), minuend Eq. (4) independent subtrahend.general case, xTi () different depending sequence experts (and, hence, actions)agent plays. such, max xTi () guaranteed stable metric successagents performance compared. Lower e-regret guaranteed correspond higherpayoffs (and often not; see Section 2.3). Thus, e-regret payoff comparable general.exception, de Farias Megiddo (2004) showed minimizing e-regret limitdirectly translate maximizing payoffs flexible opponents, associatesagents average payoff rounds + converges (as )limit independent history play prior round t. flexible opponents,followed sufficiently large number rounds (approaching infinity) selected, xti ()vary substantially depending sequence experts chosen (and, hence, minuendEq. (4) independent subtrahend). circumstances, minimizing e-regret equatesmaximizing payoffs. Using reasoning, de Farias Megiddo also established well-definedperformance guarantees (in limit) expert algorithm EEE flexible opponents.performance bounds provided de Farias Megiddo (2004) appealingspecial case, adopt e-regret evaluation metric repeated games two reasons.First, though set flexible opponents includes useful classes algorithms, includemany algorithms agent likely encounter, many expert algorithms (including EEEitself) learning algorithms. Second, performance bounds EEE flexibleopponents true limit. Since interactions infinite, interestedmetric provide accurate measure success time interval.summary, regret e-regret desirable since provide generalizable performancebenchmarks expert algorithms. Unfortunately, evaluation metrics payoff comparable arbitrary associates. Hence, adopt alternative (though related) metricevaluating effectively expert algorithms select experts repeated games.2.2.3 ISAPPOINTMENTExternal regret e-regret imply simple notion success: expert algorithm performleast well would performed always followed best expert. Disappointmenttargets notion, minus assumption agent actions impact agent future() policy agent would played round agentactions. Formally, letalways followed expert round t. Agent total disappointment2 roundDiT = max())uti (,Xuti (,())Xmi (at ),(5)t=1t=1agent expected payoff round if, round {1, , t},(). Agent averageagent followed expert agent acted accordingdisappointment roundDiT =DiT.(6)2. paper accepted publication, became aware recent work defining policy regret (Arora, Dekel,& Tewari, 2012; Cesa-Bianchi, Dekel, & Shamir, 2013). Disappointment captures notion policy regret,except disappointment allows experts implement complex (even adaptive) algorithms ratheractions action sequences. generalization somewhat trivial, term policy regret seem fitgiven experts. Rather continue overload term regret, refer metric disappointment.115fiC RANDALLcC0.60, 0.601.00, 0.000.00, 1.000.20, 0.20c0.84, 0.84 0.33, 1.00b 1.00, 0.33 0.00, 0.00(a) Prisoners Dilemma(b) ChickenTable 1: Payoff matrices PD Chicken. cell, row players payoffs listedfirst, followed column players.Agent said disappointment limT DiT 0.make several observations Eq. (5). First, minuend subtrahend independent.Unlike Eqs. (1) (4), computation agents best expert measured Eq. (5) independent agent played. minuend simply constant specifying well agent woulddone always followed best expert, hence stable benchmark success.agents disappointment benchmark minus accumulated payoffs. Hence, disappointmentpayoff comparable: algorithms receive higher payoffs given associate achieve lowerdisappointment algorithms receive lower payoffs associate (and vice versa).Second, agent influenced agent actions, ati good approximation(). cases, disappointment external regret essentially equivalent.desirable since minimizing regret equivalent maximizing payoffs cases.Third, like external regret, disappointment negative. Negative disappointment indicatesexpert algorithm performed better would performed always followedbest expert. However, sometimes possible, achieving negative disappointmentextremely difficult unknown associates. Thus, immediate goal, focus findingexpert algorithms achieve (or come close achieving) disappointment.Finally, strength regret e-regret computed run timerepeated game unknown associate. Thus, regret used part algorithmaddition evaluation metric. Indeed, regret used algorithmic tool variousno-regret algorithms. downside, since minimizing regret necessarily correspondmaximizing payoffs, use regret algorithmic tool lead low payoffsscenarios. hand, minuend Eq. (5) cannot computed run timeunknown associate. Thus, disappointment limited metric evaluate algorithmsrepeated games; clear could used algorithmic tool.2.3 Examples: Regret vs. Disappointmentillustrate differences disappointment regret several examples. First, considerexpert algorithm playing repeated prisoners dilemma (PD; Table 1a) tit-for-tat (TFT;Axelrod, 1984). expert algorithm disposal two experts: AC, expert always recommends cooperate, AD, expert always recommends defect. Figure 1 shows averagepayoff, average regret, average disappointment 20 rounds algorithm always cooperates always defects. Since always following AC would produce higher payoff alwaysfollowing AD (0.6 opposed 0.24), AC best expert. such, always cooperating zerodisappointment always defecting high disappointment. hand, always cooperating high regret, always defecting zero regret. Thus, scenario, minimizingregret correspond maximizing payoffs, minimizing disappointment does.116fiT OWARDS INIMIZING ISAPPOINTMENTR EPEATED G AMESTFT Prisoners Dilemma0.7Average payoffAverage regretAverage disappointment0.60.50.40.30.20.10Always CooperateAlways DefectFigure 1: Comparison average payoff, regret, disappointment PD (T = 20).Similar results observed learning algorithms play repeatedPD. example, Figures 2a 2c plot average payoffs six different learning algorithms(Exp3, UCB1, EEE, S, BR1, BR2) algorithms corresponding average regretaverage disappointment, respectively, paired four different associates3 . Figure 2a showsalgorithms achieved lower regret tended higher performance BR1,WoLF-PHC, Exp3, S. S, algorithms higher regret received substantially higher payoffs. hand, Figure 2c shows decreasing disappointmentfour algorithms resulted directly higher payoffs PD.Regret even less indicative performance Chicken (Table 1b) associates.game, lower regret tends lead higher payoffs WoLF-PHC, Exp3,BR1, (Figure 2b). PD, lower regret correlates lower payoffs Chicken,lower disappointment always translates directly higher payoffs (Figure 2d).Figures 2e2h demonstrate deficiencies e-regret evaluation metric PDChicken associates. 1000 rounds, lower e-regret BR1PD Chicken correspond higher payoffs (Figures 2e 2f). Discrepancieseven pronounced 50,000 rounds. PD, algorithms low e-regret S,wildly different average payoffs (Figure 2g). Similar, though identical, trends occurChicken (Figure 2h).2.4 Research Agendaabsence single, universally accepted, evaluation metric repeated games, sets performance criteria proposed (e.g., Powers & Shoham, 2005a; Crandall & Goodrich, 2011).Researchers advocating agendas argued successful algorithms simultaneously satisfy criteria identified set. example, Powers Shoham (2005a) arguedsuccessful algorithms simultaneously satisfy three performance criteria:Targeted Optimality: member target set associates, algorithm achieveswithin expected value best response associates actual play.3. See Appendix implementation details. experts used Exp3, UCB, EEE, described Section 3.regrets disappointments BR1 BR2 computed respect experts.117fi0.600.900.550.850.50Average PayoffAverage PayoffC RANDALL0.450.400.350.30BR1WoLFPHCExp30.250.200.1500.050.10.150.20.250.30.800.750.700.65BR1WoLFPHCExp30.600.550.3500.05Average Regret(a) PD: R1000vs. 10000.900.50BR1WoLFPHCExp30.85Average PayoffAverage Payoff0.550.15(b) Chicken: R1000vs. 1000BR1WoLFPHCExp30.600.1Average Regret0.450.400.350.300.800.750.700.650.250.600.200.1500.550.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4 0.450Average Disappointment0.850.50Average PayoffAverage Payoff0.900.550.450.400.350.30BR1WoLFPHCExp30.1500.050.10.150.350.750.700.650.550.200.050.10.150.2eregret(f) Chicken: Ei1000 vs. 10000.90BR1WoLFPHCExp30.80Average PayoffAverage Payoff0.30.60BR1WoLFPHCExp30.500.250.80(e) PD: Ei1000 vs. 10000.550.2BR1WoLFPHCExp3eregret0.600.15(d) Chicken: Di1000 vs. 10000.600.200.1Average Disappointment(c) PD: Di1000 vs. 10000.250.050.450.400.350.300.700.600.500.250.400.200.1500.050.10.150.3000.2eregret0.050.10.150.2eregret(g) PD: Ei50000 vs. 50000(h) Chicken: Ei50000 vs. 50000Figure 2: Average regret (ab), disappointment (cd), e-regret (eh) plotted averagepayoffs (1000) various pairings PD Chicken. point average 50 trials.E-regret cannot computed BR1 BR2, results excluded (eh).118fiT OWARDS INIMIZING ISAPPOINTMENTR EPEATED G AMESCompatibility: self-play, algorithm achieves least within payoffNash equilibrium Pareto dominated another Nash equilibrium.Safety: associate, algorithm always receives least within securityvalue game.set experts satisfies certain properties, expert algorithm guaranteeddisappointment also satisfy desirable performance criteria. Let Safety, Comp,TargetOptbehaviorrules/algorithmswouldsatisfySafety,Compatibility,TargetedOptimality properties, respectively, always followed. Then, expert algorithmdisappointment satisfy Safety, Compatibility, Targeted Optimality properties,respectively, experts set available experts .Proposition 2.1 Let expert algorithm, let Safety, Comp, TargetOpt, let A(i )algorithm uses select experts . guaranteed disappointment,A(i ) satisfy Safety, Compatibility, Targeted Optimality performance criteria.Proof. proof follows directly Eq. (5). associates possible games,know guaranteed disappointment, A(i )s average payoffleast high limit security value minus , since least well limit. Thus, satisfies Safety criteria. Similarly,would done always followed Safetyself play, A(i ) perform least well limit Comp, least wellTargetOptassociates targeted set associates. Hence, also meetCompatibility Targeted Optimality performance criteria.argue difficult find Safety, Comp, TargetOpt. example, Safetyexpert always plays agents maximin strategy. CompexpertTargetOptfollows Littmans Stones Godfather strategy (Littman & Stone, 2005).couldnumber algorithms derive best response memory bounded opponents,algorithm described Chakraborty Stone (2010).Similar arguments show expert algorithm guaranteed disappointmentalso meet performance criteria, performance criteria advocated CrandallGoodrich (2011). Additionally, suppose consists three experts: Expert 1 acts optimallyassociates behavior class X, Expert 2 acts optimally associates behaviorclass Y, Expert 3 acts optimally associates behavior class Z. Then,expert algorithm guaranteed disappointment, A(i ) learn act optimallyplaying associates behavior classes X, Y, Z.short, find (1) expert algorithm guaranteed disappointment(2) good set experts, agent performs well repeated games.Given results, tempting research agenda find algorithm always achievesdisappointment. Unfortunately, unless agent omniscient, goal impossible.Proposition 2.2 unknown associate, expert algorithm guarantee averagedisappointment less 1 vimm , vimm = maxi mini ui (i , ) maximin(i.e., security) value.119fiC RANDALLProof. adapt example de Farias Megiddo (2003). Let particular stringactions length 100. Consider agent playing repeated PD associate (agent i)following strategy. rounds 100, always cooperate. > 100, always cooperateagent actions matched rounds 100; otherwise, always play attack policyattack = arg minmaxi ui (i , ) (defect). Suppose agent expert playsstring first 100 rounds, defects rounds thereafter. large , bestexpert (against associate) would get average payoff near 1. But, without omniscience,expert algorithm cannot know follow expert first 100 rounds, thereforeunlikely follow 100. Thus, maximum payoff guaranteevimm = 0.2. Thus, DiT 1 vimm .less ambitious, still extremely challenging, research agenda find algorithmquickly achieves low disappointment associating member target set associatesacross many repeated games. common target set algorithms memory-boundedalgorithms (e.g., de Farias & Megiddo, 2004; Chakraborty & Stone, 2010; Arora et al., 2012; CesaBianchi et al., 2013), since theoretical guarantees easier establish algorithms.However, find appealing target set associates broad enough covermany state-of-the-art algorithms published literature, would presumably setlikely associates agent would face. example, algorithms literature include static(memory-bounded) algorithms automata, reinforcement learning algorithms, expert algorithms. Thus, paper, focus finding expert algorithms achieve low disappointmentassociates three classes algorithms.theoretical treatment aim extremely challenging beyond scopepaper. Rather, starting point, empirically evaluate disappointment algorithmsvarious static, reinforcement learning, expert algorithms literature. doing,seek algorithm quickly achieves low disappointment algorithm consider.Let set opponent algorithms considered. Then, max disappointment algorithmrespect rounds(, ),DA(, ) = max DA(7)(, ) average disappointment algorithm associate .DAThough tempting focus asymptotic performance (as ), interactions repeattens hundreds times many realistic scenarios. such, seek identify expertalgorithms quickly achieve low disappointment static associates, reinforcement learningalgorithms, expert algorithms. Thus, primarily focus disappointment achievedalgorithms first 1000 rounds, though also consider longer-term performance.Section 4 evaluate several existing algorithms respect disappointment.so, describe method computing good set experts repeated general-sum games.3. Computing Set Experts Arbitrary Repeated Gamessuccess agent employing expert algorithm depends expert algorithms ability select effective experts (and, thus, minimize disappointment) effectivenessset experts . Given importance , give considerable attention computing120fiT OWARDS INIMIZING ISAPPOINTMENTR EPEATED G AMESc0.33, 0.33 0.67, 1.00b 1.00, 0.67 0.00, 0.00c1.00, 1.00 0.00, 0.75b 0.75, 0.00 0.50, 0.50c0.84, 0.33 0.84, 0.00b 0.00, 1.00 1.00, 0.67c0.00, 0.00 0.00, 1.00b 1.00, 0.00 0.00, 0.00(a) Leader(b) Stag hunt(c) Security Game(d) Offset Gamec1.00, 1.00 0.00, 0.00b 0.00, 0.00 0.50, 0.50c0.00, 0.00 0.67, 1.00b 1.00, 0.67 0.33, 0.33c0.00, 1.00 1.00, 0.67b 0.33, 0.00 0.67, 0.33(e) Common Interest(f) Battle Sexes(g) Tricky Gamebc0, 00, 11, 0e1, 00, 00, 1f0, 11, 00, 0(h) Shapleys GameTable 2: Payoff matrices eight different games.good set experts repeated normal-form games. potential associate gameagent might encounter, set experts include least one expert perform well.Littman Stone (2001) grouped algorithms repeated games two classes: leadersfollowers. Leaders typically effective associating follower algorithms,standard reinforcement learning opponent modeling algorithms. Follower algorithmstypically effective leader strategies static algorithms. Thus, orderhigh-performing expert scenario agent might encounter, good set experts mustcontain leader follower experts.3.1 Leader ExpertsBased premise associate play best response, leader strategies designedplay strategies cause associates play portion desirable solution (sometimes calledtargeted pair) (Littman & Stone, 2001). solution sequence joint actionsagents repeatedly play. solution produces expected payoff profile v(s) = (vi (s), vi (s)).example, solution = <(c, C), (d, C)> PD corresponds situationcolumn player always cooperates row player alternates cooperating defecting.produces expected payoff profile v(s) = (0.8, 0.3) payoffs given Table 1a.Since often unclear solution agent target, define set potential targetsolutions . contains solutions satisfy following three criteria. First, consistssolutions agents expected payoff vi exceeds maximin value vimm . Second,line Occams razor, consists solutions sequences one two joint actions. Solutions longer sequences likely complex many potential associates identify,especially interactions last tens rounds, exclude them. Third, solutionsmust enforceable. must possible make playing solution associates best response.Formally, agent plays strategy , agent best responsebri (ti ) = arg max (i , ).(8)Recall (i , ) average per-round payoff strategies played.cardinality (||) varies game game. example, PD, || = 6,|| = 9 Shapleys Game (Table 2h). Furthermore, set 50 randomly-generated 5-actiongames, found || vary 18 187.121fiC RANDALLNo.1234Target solution (s)<(c, C)><(d, C), (c, D)><(c, C), (d, D)><(d, D)>v1 (s)0.600.500.400.20Strategyg2t > 0, play iattack . Otherwise, playportion current joint actionsequence s.Table 3: Leader experts generated player 1 PD.Though enforceable, solutions made associates best response associate conditions strategy many previous joint actions. curse dimensionality,algorithms designed learn quickly condition strategy previous joint actions. Thus, form separate leader expert () target solutionsbri () requires associate remember single joint action. leader expertsincentivize associates play portion target solution punishing deviationsusing similar mechanism used previously defined leader strategies (e.g., Littman &Stone, 2005; Crandall & Goodrich, 2005). associate conformedbenefited deviating it, leader expert plays portion s. However, associatebenefited deviating s, leader expert plays attack policy iattack .defines muchFormally, leader expert keeps track guilt parameter gi1associate benefited deviating s. Initially, gi = 0. Subsequently,t+1gi0max0, gi+ mi(at )ai = bi gi = 0vi + otherwise(9)bti agent current action defined target solution small nonnegative= 0 = 0.0 otherwise. g > 0, agent recentlyvalue. use = 0.1 gibenefited (or least hurt) deviating s. discourage behavior, leader= 0, leader expert plays portion s.expert plays attack policy iattack . giTable 3 lists four leader experts generated PD. Note expert createdtarget solutions <(c, C), (d, C)> <(c, C), (c, D)> , since solutionsenforceable associate learns best response conditioned last joint action.3.2 Follower ExpertsFollowers learn play best response estimated strategy associate. considerthree types follower experts, estimates associates strategy different way.first experts models associate using fictitious play assessment conditionedlast joint action played. Let ti (a, ai ) number times agent played aigiven previous joint action round t. Then, estimated probability agent playsai given previous joint action(a, ai ) = Pti (a, ai ).bi Ai (a, bi )(10)expert computes automaton best responds agents future discounted reward. refer expert .(we use discount factor = 0.95) given122fiT OWARDS INIMIZING ISAPPOINTMENTNo.12Target solution (s)(none)(none)v1 (s)1 (br1 (2t ), 2t )v1mm = 0.20345678<(c, C), (d, C)><(c, C)><(d, C), (c, D)><(c, C), (d, D)><(c, C), (c, D)><(d, D)>0.800.600.500.400.300.20R EPEATED G AMESStrategybr1 (2t )1mmat1 s, play portion nextjoint action s. Otherwise, randomly selectjoint action play portionjoint action.Table 4: Follower experts generated player 1 PD.second follower expert, called mm, assumes associate trying exploit it. Thus,best response play maximin strategy (or policy), givenimm = arg max min ui (i , ).(11)Finally, associate could also using leader strategy, computed Section 3.1. Thus, include set experts follower expert . expertsalways play part s. joint action solution played previous round,experts randomly select joint action solution sequence play agents corresponding action.Table 4 lists eight follower experts generated PD method.3.3 Set Expertsset experts used expert algorithms remainder paper consistsfollower leader experts described. scenarios encountered, least oneexperts capable performing effectively. associate employs follower algorithm,expert algorithm select number leader experts could induce desirable behavior associate. Similarly, associate employs leader algorithm, GodfatherBully (Littman & Stone, 2001), expert algorithm select corresponding follower expert.Additionally, diversity experts good expert algorithm ableobtain high payoffs expert algorithms, including select similar setexperts. case, expert algorithms must negotiate follower leader roles.illustration performance experts three different associates severalrepeated games provided Appendix B. example, set experts contains leastone high-performing expert. However, results also illustrate identifying best expertrun time extremely difficult. Sometimes best performing expert must followedconsistently many rounds produces high payoffs.4. Results Existing Expert AlgorithmsExisting expert algorithms typically evaluated terms regret. section, evaluate several algorithms repeated normal-form games terms disappointment. Specifically, analyze average disappointment four existing expert algorithms twelve123fiC RANDALLdifferent algorithms across ten repeated games. Recall goal find expert algorithmquickly achieves maintains low disappointment static algorithms, reinforcementlearning algorithms, expert algorithms.four expert algorithms Exp3, UCB1, EEE, S. Exp3 UCB1 well-known expert algorithms well-defined regret bounds multi-armed adversarial multi-armed banditproblems, respectively. algorithms shown perform effectively repeated games (Bouzy & Metivier, 2010). EEE -greedy expert algorithm designed repeatedgames played learning associates. , shown e-regret (deFarias & Megiddo, 2003, 2004). aspiration-based algorithm shown perform well expert algorithm (Bouzy, Metivier, & Pellier, 2011), though originallydesigned such. interest space, omit detailed overviews algorithms. Instead,refer reader Appendix A, provides references descriptions analysisalgorithms, also specifies parameter values used generate results paper.compare average disappointment four expert algorithms pairedtwelve representative algorithms: four static algorithms (A0, Random, Godfather, Bully), fourreinforcement learning algorithms (BR1, BR2, Q-learning, WoLF-PHC), other. Implementation details twelve algorithms also supplied Appendix A. Comparisonsmade across ten games shown Tables 1 2. well-studied games literature, representing different challenge. successful games, algorithmmust able learn make accept profitable compromises many different situations.average disappointment across games pairing shown Figure 3. figureshows that, first 1000 rounds, typically lower average disappointmentassociate three expert algorithms. Additionally, despite popularity theoreticalproperties, Exp3 performs worst four expert algorithms associate.Results vary somewhat associate. four expert algorithms eventually obtain lowdisappointment static algorithm, Figures 3a3d show reaches averagedisappointment less 0.05 within 1000 episodes four static associates.expert algorithms unable so, large part due relatively large number experts. Ss mechanism selecting experts allows find best expert fasteralgorithms. exception, effective Random, especially long run,sometimes never learn play best expert. example, learn play bestresponse Random PD, three algorithms eventually do.reinforcement learning algorithms adapt time, achieving low average disappointment associates difficult static algorithms. statementconfirmed performance four expert algorithms BR1, BR2, WoLF-PHC,Q-learning (Figures 3e3h). associates, none four expert algorithms achieveslow disappointment first 1000 rounds. average disappointment quickly increasesfirst 50-200 rounds, slowly decreases plateaus thereafter.four expert algorithms also high disappointment (Figures 3i3l).self play, manages achieve average disappointment 0.05, none threealgorithms first 1000 rounds expert algorithm. fact, Exp3,average disappointment expert algorithm increases throughout first 1000 rounds.short, none four expert algorithms quickly achieves low disappointment staticalgorithms, reinforcement learning algorithms, expert algorithms. Thus, next section,describe new meta-algorithm designed enhance performance existing expert algorithms.124fiT OWARDS INIMIZING ISAPPOINTMENT0.20.150.10.052004006008000.250.20.150.10.050010000.35EEEUCB1Exp30.32004000.10.056008000.20.150.1EEEUCB1Exp30.050010002004000.1EEEUCB1Exp30.05600800EEEUCB1Exp32004000.20.10.052004006008000.20.150.10.052004000.10.05600(j) UCB180010008001000(i) Exp30.350.30.250.20.150.1EEEUCB1Exp30.0500600200400600(k) EEE8001000Average Disappointment0.15Average Disappointment0.21000EEEUCB1Exp30.250010000.350.258000.3(h) Q-learningEEEUCB1Exp30.36000.35EEEUCB1Exp30.354000.10.05(f) BR20.15(g) WoLF-PHC2000.20.2500100010000.15001000Average Disappointment0.20.15Average DisappointmentAverage Disappointment8000.3Average Disappointment6000.350.258000.3(e) BR10.36000.250.35004000.350.25(d) Godfather400200(c) Bully0.32000.10.05Average Disappointment0.20.15Average DisappointmentAverage Disappointment0.254000.20.150010000.35EEEUCB1Exp30.32000.25(b) Random0.3500800EEEUCB1Exp30.3(a) A000600Average Disappointment0.2500R EPEATED G AMES0.35EEEUCB1Exp30.3Average DisappointmentAverage Disappointment0.35EEEUCB1Exp30.30.250.20.150.10.05002004006008001000(l)Figure 3: average disappointment time four expert algorithms twelve associates. Results average 50 trials ten selected games.125fiC RANDALLSection 6, demonstrate meta-algorithm improves Exp3, UCB1, EEE,consistently achieve much lower disappointment associates.5. Enhancing Existing Expert Algorithmsfailure expert algorithms consistently achieve low disappointment adaptingagents appears tied algorithms exploration strategies. Early game, expertalgorithms tend spend many rounds following ineffective experts seek determineexperience experts effective. result, receive low average payoffs earlyrounds game. Furthermore, frequent changes behavior caused cycling manyexperts incoherent outsider. Thus, associates unlikely determine coordinatebehavior strike mutually beneficial compromises. adaptive associates whose internalmodels conditioned somewhat associates behavior, process often leads lowpayoffs (and, hence, high disappointment) short long term. section,describe rather simple meta-algorithm designed overcome deficiency.5.1 New Meta-Algorithmpurpose meta-algorithm help expert algorithm explore effectiveness setexperts effectively. computing highest expected payoff (or potential)expert, supplying expert algorithm subset experts whose potentialmeets performance threshold. Experts lower potential followed expertshigher potentials demonstrated inability meet potentials.performance threshold round determined using aspiration learning (Karandikar,Mookherjee, R., & Vega-Redondo, 1998; Stimpson, Goodrich, & Walters, 2001; Chasparis, Shamma,& Arapostathis, 2010). aspiration learning, agent maintains aspiration ti . algorithm,1i initialized potential (see Section 5.3) expert highest potential. Formally,let zit () denote potential expert round t. Then,1i = max zi1 ().(12)(Appendix A), round new expert selected, ti updated follows:ti =+ (1 )rit ,(13)rit average payoff received agent last rounds, number consecutiverounds expert followed, [0, 1] learning rate (we use = 0.99).performance threshold round agents minimum aspiration level kitime interval k [, t], 1 t. expert whose potential meets exceedsperformance threshold considered selection round t; experts not.4 Formally,round t, experts selected set(t) = { : zit () min ki }.k[,t](14)(t) defined Eq. (14) empty, default expert added (t). set expertsdefined Section 3, add expert plays best response fictitious-play assessmentconditioned previous joint action. is, (t) = {i } cases.4. before, disappointment always computed using full set experts .126fiT OWARDS INIMIZING ISAPPOINTMENTR EPEATED G AMESAlgorithm 1 meta-algorithm (for agent i) enhance expert algorithms.Input:(the expert algorithm), (the set experts), (the payoff matrix)Initialize:t=1Compute zit ()Initialize ti = maxi zit ()repeatCompute (t) = { : zit () min [,t] }, 0 <Execute (and update) A(i (t)) rounds, specified A. Observer rit+ .t= t+Update ti =+ (1 )ritCompute zi ()Gamecomplete meta-algorithm stated Algorithm 1. make two observations. First,meta-algorithm embodies optimism-in-uncertainty principle (Brafman & Tennenholtz, 2003).aspiration level initially set high, expert presumed able meet highestpotential. experts fail meet highest potentials (which causes aspiration levelfall; Eq. 13) algorithm consider selecting experts lower potential. Second,aspiration updates similar nature previous work aspiration learning (Karandikar et al.,1998; Stimpson et al., 2001; Chasparis et al., 2010), aspiration level used differentlymeta-algorithm. Rather use ti determine whether action expert repeatednext round, use ti prune set selectable experts.5.2 Properties Reduced Set (t)Selecting experts (t) rather leaves open possibility (t) mightcontain best expert. However, certain parameter settings, meta-algorithm eitherobtain average payoffs less best expert limit, best expert contained(t) > . Let vi () denote highest possible average per-round payoff agentcould ever obtain always follow expert , let denote best expert gameassociate question, let ti average payoff obtained agent time t.following proposition.Proposition 5.1 = 1 , zit () vi (), one following must hold:Condition 1: limt ti zit ( )Condition 2: , (t)Condition 1 equates expert algorithm disappointment, Condition 2 sayseventually enter (and perpetually remain in) (t). proof propositionstraightforward. Since aspiration level ti fading average payoff agent, musttime fall zit ( ) average payoff ti perpetually zit ( ). case,accordance Eq. (14), would (t) thereafter.typical aspiration learning (Karandikar et al., 1998), use = (i.e., performancethreshold ti ) generating results shown next section. means implemen127fiC RANDALLtation technically satisfy conditions Proposition 5.1. However, observedthat, practice, algorithm achieves similar results = 1 = t.5.3 Computing Potentialstrategies learning processes target value, value equilibriumsolution current expected value learning process. always conformingpre-condition Proposition 5.1, target values often sufficient determiningpotential experts practice. demonstrate define potential experts using setexperts, defined Section 3.Let leaddenote set leader experts . assumption rational(follower) associate, highest expected payoff (or potential) reasonably expectleader expert leadobtain expected per-round payoff agent receiveopponent plays best response strategy. Formally, leadt,zit () = (, bri ()).(15)Let followdenote set follower experts excluding maximin bestiresponse experts (mm, respectively). associate appears playing portiontarget solution corresponding expert follow, potential agents expectedpayoff target solution corresponding expert played. Let sti denote observedstrategy employed agent round t. Then,(bri (sti ), sti ) bri (sti )zi ()(16)0otherwisedetermine strategies associate could playing, agent models agent actionsgiven previous joint action a. Since agent could change sti time, partialestimate sti may available. agent remembers last round k agent changedaction given previous joint action A. actions taken round k onward define sti .Formally, agent estimated strategy givenjai j [k, t) : aj =sti (a)(17)otherwiseagent estimate sti consistent leader strategy corresponding follow,agent assumes playing leader strategy computing zi ().mm z ( ) =potentials maximin best-response experts zit (mm) = vi(bri (i ), ), respectively.5.4 SafetySafety, guarantee expected average payoffs substantially maximinvalue vimm , perhaps oldest objective repeated games (Fudenberg & Levine, 1998).expert algorithm guaranteed regret guaranteed safetysafe. However, expert algorithms well-defined regret bounds, addmechanism meta-algorithm ensures safety. call mechanism safety overridesince overrides Eq. (14) certain conditions.128fiT OWARDS INIMIZING ISAPPOINTMENTR EPEATED G AMESsafety override adopted security mechanism described Crandall Goodrich(2011). sum agents payoffs ever less constant CiPTwhat wouldachieved always received maximin value (i.e., =1 mi (a ) + Ci <vimm ), (t) = {mm}. guarantees agents expected average payoffmmless vi , regardless game associate. proof safety providedmechanism given Crandall Goodrich (2011). used Ci = 100 implementation.5.5 Best ResponsePrevious work shown value properly balancing optimistic, best response, secureattitudes repeated games (Crandall & Goodrich, 2011). Eqs. (1214) induce optimistic attitude, safety override secure attitude. Finally, add best-response override.algorithm sets (t) = {i } following two conditions met:1. (t); see Eq. (14) conjunction safety override.2. historical average per-round payoff playing high expert.Formally, let xti () weighted average per-round payoff5 received agentround followed expert round t. Then, (t), xti (i ) xti ().override use algorithms like S, learn effectively many algorithms, sometimes learn best response static agents (such Random).6. Results Enhanced Expert Algorithmsenhanced four expert algorithms evaluated Section 4 meta-algorithm. callenhanced versions algorithms Exp3++, UCB++, EEE++, S++, respectively.algorithms identical original algorithms except select experts (t) rather. first evaluate whether expert algorithms consistently achieve low disappointmenttwelve associates before. also compare payoffs algorithmstop-performing algorithms literature perfect imperfect information settings.6.1 Static, Reinforcement Learning, Expert Algorithmsaverage disappointment enhanced original algorithms twelve associatesacross ten games shown Figure 4. enhanced algorithm substantially less averagedisappointment original algorithm. enhanced algorithms quickly reach low levelsdisappointment (Figure 4a). 1000 rounds, average disappointment enhancedalgorithms 0.05 (Figure 4b), substantially less original algorithms. Similar improvements present terms max disappointment (Figure 5).meta-algorithm consistently produces substantial decreases disappointmentassociates ten games (not shown). Figure 6 shows average disappointment EEE++Exp3++ associate across games. static associates (Figures 6a6d),EEE++ Exp3++ achieve low average disappointment well 1000 rounds.meta-algorithm produces even greater decreases average disappointment reinforcement learning algorithms (Figures 6e6f) expert algorithms (Figures 6i6l). algorithms5. Initially, x1i () = 1. xti () updated round followed: xti () = xt1() + (1 )mi (at ),= max(1/ti (), 2(1 )) ti () number times agent played round t.129fi0.2EEEUCB1Exp3EEE++S++UCB1++Exp3++0.150.10.050050100150200250300350Average Disappointment (T = 1000)Average DisappointmentC RANDALL0.150.10.050(a) Average disappointment timeOriginal++0.2Exp3UCB1EEE(b) Average disappointment (T=1000)Figure 4: Average disappointment across selected games associates.0.3EEEUCB1Exp3EEE++S++UCB1++Exp3++0.250.20.150.10.050050100150200250300350Max Disappointment (T = 1000)Max Disappointment0.350.350.250.20.150.10.050(a) Max disappointment timeOriginal++0.3Exp3UCB1EEE(b) Max disappointment (T=1000)Figure 5: Max disappointment (Eq. 7).enhanced meta-algorithm also achieve higher payoffs self play original algorithms (Figure 7).One interesting exception previously stated trend EEE performs betterBully first 100 rounds EEE++ (Figure 6c). Bully, best-performingexperts (see Figure 11 Appendix B) tend high potential games, expertshigh potential often achieve high payoffs well. Hence, takes many roundsagents aspiration level falls far enough best expert (t). causes EEE++higher disappointment early rounds. best expert appears (t), averagedisappointment quickly decreases.Finally, Figure 8 shows average payoffs obtained algorithms associates50,000 rounds. Even 50,000 rounds, enhanced expert algorithms outperformoriginal algorithms. UCB1 best performance four original algorithms50,000, enhanced algorithms substantially higher payoffs. Thus, enhancements improve algorithms near term, also long term.130fiT OWARDS INIMIZING ISAPPOINTMENT0.20.150.10.052004006008000.250.20.150.10.050010000.35EEEEEE++Exp3Exp3++0.32004000.10.056008000.20.150.10.050010002004000.10.056008000.10.052004000.20.10.052004006008000.20.150.10.052004000.150.10.05600(j) UCB180010000.258001000(i) Exp30.35EEEEEE++Exp3Exp3++0.20.150.10.0500600Average Disappointment0.2Average Disappointment0.251000EEEEEE++Exp3Exp3++0.250010000.350.38000.3(h) Q-learningEEEEEE++Exp3Exp3++0.36000.35EEEEEE++Exp3Exp3++0.354000.2(f) BR20.15(g) WoLF-PHC200EEEEEE++Exp3Exp3++0.2500100010000.15001000Average Disappointment0.20.15Average DisappointmentAverage Disappointment8000.3Average Disappointment6000.350.258000.25(e) BR1EEEEEE++Exp3Exp3++0.36000.30.35004000.35EEEEEE++Exp3Exp3++0.25(d) Godfather400200(c) Bully0.32000.10.05Average Disappointment0.20.15Average DisappointmentAverage Disappointment0.254000.20.150010000.35EEEEEE++Exp3Exp3++0.32000.25(b) Random0.3500800EEEEEE++Exp3Exp3++0.3(a) A000600Average Disappointment0.2500R EPEATED G AMES0.35EEEEEE++Exp3Exp3++0.3Average DisappointmentAverage Disappointment0.35200400600(k) EEE8001000EEEEEE++Exp3Exp3++0.30.250.20.150.10.05002004006008001000(l)Figure 6: Average disappointment time associate across selected games.Results average 50 trials ten selected games.131fiC RANDALLAverage Payoff (T = 1000)0.9Original++0.80.70.60.50.40.3Exp3UCB1EEEFigure 7: Average payoffs self play 1000 rounds across selected games.Average Payoff0.8EEEUCB1Exp3EEE++S++UCB1++Exp3++0.750.70.650.6010,00020,00030,00040,00050,000Figure 8: Average payoffs time across selected games associates.6.2 Meta-Algorithm Worksmeta-algorithm two different components: (1) method distinguishing expertslikely successful (2) best response safety overrides.combined impact overrides max disappointment enhanced algorithms shownFigure 9. overrides typically lower algorithms max disappointment smallmargin, small number cases (e.g., static agents) overrides responsiblesubstantial improvements. many scenarios, overrides invoked.Thus, meta-algorithm improves original algorithms primarily via mechanism distinguishing successful experts unsuccessful experts. original expert algorithms tendspend many rounds following ineffective experts seek determine experienceexperts effective. resulting frequent changes behavior caused cyclingmany experts incoherent associates, making difficult agents coordinate behaviorstrike mutually beneficial compromises. hand, enhanced algorithms selectfewer experts early rounds game, produces predictable behavior associateseasily model adapt to. This, turn, allows quickly find mutually beneficialcompromises, lead higher payoffs short long term.132fiOriginal+ (no overrides)++0.20.150.10.050Exp3UCB1EEE(a) static algorithms0.3Original+ (no overrides)++0.250.20.150.10.050Exp3UCB1EEE(b) RL algorithmsR EPEATED G AMESMax Disappointment (T = 1000)0.30.25Max Disappointment (T = 1000)Max Disappointment (T = 1000)OWARDS INIMIZING ISAPPOINTMENT0.3Original+ (no overrides)++0.250.20.150.10.050Exp3UCB1EEE(c) expert algorithmsFigure 9: Max disappointment 1000 1000 rounds class associates.6.3 Comparison Top-Performing Algorithmsshown meta-algorithm helps expert algorithms quickly achieve maintain lowdisappointment variety static, reinforcement learning, expert algorithms acrossmany repeated games. illustrate value contribution, compare average payoffs enhanced algorithms top-performing algorithms repeated games.compare algorithms state-of-the-art learning algorithms, ran several round-robintournaments involving eight algorithms: S++, EEE++, six algorithms literature: MQubed, Manipulator-Bully, Manipulator-Godfather, BR1, Godfather, Bully (see Appendix A).algorithms chosen due elite attributes. example, Bully Godfatherleader algorithms well-understood equilibrium characteristics (Littman & Stone, 2001, 2005).algorithms precompute desirable behaviors, good standards performance earlyrounds repeated games. M-Qubed reinforcement learning algorithm demonstratedsuperior asymptotic performance several empirical studies (Crandall & Goodrich, 2011; Bouzy& Metivier, 2010). makes good standard comparison long-term (or asymptotic)performance. Manipulator combines Godfather Bully BR1 maximin strategy immprovide theoretical guarantees respect targeted optimality, safety, compatibility (Powers& Shoham, 2005a).point, assumed perfect information, wherein player perfect knowledgeplayers payoffs. relax assumption consider scenariosplayers normally distributed errors assessments players payoffs. Thus,conducted three separate round-robin tournaments: one perfect information (No Noise),two different sizes errors payoff assessment ( = 0.15 = 0.30, respectively).tournament, algorithm paired seven algorithms50 random 3-action repeated games. game consisted 50,000 rounds. comparealgorithms average per-round payoff eight pairings short term(over first 100 1000 rounds) asymptotically (over last 1000 rounds). randomgames tend produce less variation average payoffs selected games6 , use randomgames guard overfitting selected games.results tournaments summarized Figure 10.6. One comparison 16 algorithms showed 0.07 difference average payoffs best- worstperforming algorithms (Crandall & Goodrich, 2011)133fiC RANDALLAverage Payoff0.850.8S++EEE++MQubedBR1BullyGodfatherManipulatorBullyManipulatorGF0.750.70.650.60.55NoiseNoise: = 0.15 Noise: = 0.30(a) Averaged first 100 roundsAverage Payoff0.850.8S++EEE++MQubedBR1BullyGodfatherManipulatorBullyManipulatorGF0.750.70.650.60.55NoiseNoise: = 0.15 Noise: = 0.30(b) Averaged first 1000 roundsAverage Payoff0.850.8S++EEE++MQubedBR1BullyGodfatherManipulatorBullyManipulatorGF0.750.70.650.60.55NoiseNoise: = 0.15 Noise: = 0.30(c) Averaged rounds 49,001 50,000Figure 10: Average payoffs perfect (No Noise) imperfect (Noise: = 0.15 = 0.30,respectively) information round-robin tournaments involving 50 random 3-action games.134fiT OWARDS INIMIZING ISAPPOINTMENTR EPEATED G AMES6.3.1 P ERFECT NFORMATIONUnsurprisingly, Godfather Manipulator-GF (which identical first 100 rounds)highest average payoffs first 100 rounds (Figures 10a). However, average payoffsS++ EEE++ perfect information far behind. T-tests show differenceaverage performance S++ Godfather statistically significant 100 rounds(p = 0.194), though difference EEE++ Godfather (p = 0.004). payoffsalgorithms substantially lower. 1000 rounds, S++ EEE++ outperformedsix algorithms perfect information (Figure 10b). 1000 rounds, difference S++ EEE++ statistically significant, though differences S++six algorithms (p < 0.010). Thus, short-term performances S++EEE++ favorable compared algorithms perfect information.long-term performance S++ EEE++ matches M-Qubed perfect information games (Figure 10c). Given M-Qubeds top asymptotic performance previous studies(Crandall & Goodrich, 2011; Bouzy & Metivier, 2010), results speak effectivenessenhanced algorithms.6.3.2 MPERFECT NFORMATIONGodfather Bully compute equilibrium strategies based knowledge payoffsassociates. using precomputed strategies, algorithms quickly achieve high payoffs. MQubed BR1, hand, seek learn effective behaviors experience. MQubed eventually quite effective, learning processes often takes many rounds. S++, EEE++,Manipulator-Godfather, Manipulator-Bully both. combine computation equilibria game begins learning experience. result, tendperform effectively short-term long-term perfect information.However, since computing (and agreeing upon) equilibrium sometimes requires perfect information, algorithms potentially limited given perfect knowledge associatespayoffs uncommon. However, uncommon agents estimates payoffsothers, though sometimes estimates error. model scenarios imperfectinformation tournaments. results tournaments also shown Figure 10.figure shows early later rounds game, Godfather, Bully, ManipulatorGodfather, Manipulator-Bully negatively impacted errors assessmentsassociates payoffs. average payoffs fall substantially (and statistically significantly)medium errors assessment ( = 0.15) large errors assessment ( = 0.30).hand, S++ EEE++ slightly affected moderate high errorsassessments. Thus, continue perform par M-Qubed asymptotically (Figure 10c),maintaining highest performance early rounds game.Manipulator algorithms, S++, EEE++ utilize precomputed strategies learnexperiences, S++ EEE++ substantially affected imperfect information,Manipulator algorithms are. two primary differences Manipulatoralgorithms enhanced expert algorithms cause difference. First, Manipulator algorithms compute single equilibrium strategy, enhanced expert algorithms computemany equilibria strategies (the various experts). Second, Manipulator algorithms execute expertsserially. algorithms first execute respective leader strategy. respective leader strategy fails produce desired payoffs, switch following BR1, on. hand,135fiC RANDALLS++ EEE++ continue evaluate multiple experts (essentially parallel). results,algorithms much robust errors assessments associates payoffs.7. Conclusions Discussionpaper, introduced new metric, called disappointment, evaluating expert algorithmsrepeated games. Disappointment similar regret, except disappointment builtassumption agents actions influence associates future behavior. result,minimizing disappointment always equivalent maximizing accumulated payoffs repeatedgame, whereas case regret. showed impossible createalgorithm guaranteed disappointment scenarios without omniscience,possible create algorithms quickly achieve (and maintain) low disappointment manyalgorithms many repeated games.accomplish goal, presented new meta-algorithm used enhance existingexpert algorithms. algorithm reduces set selectable experts combining aspirationlearning equilibrium computation. showed resulting algorithms quickly achievemaintain low disappointment associating various static algorithms, reinforcementlearning algorithms, expert algorithms. also showed expert algorithms, givengood set experts, outperform top-performing algorithms literature.7.1 Reflections Learning Using Expertsmeta-algorithm presented enhancing expert algorithms alters order expertsselected. computing highest expected payoff (or potential) expert,supplying expert algorithm subset experts whose potential meets performance threshold, determined aspiration learning. Experts lower potentialselected experts higher potential demonstrated inability meet potentials.application optimism-in-uncertainty principle (Brafman & Tennenholtz, 2003) allowsexpert algorithms learn effective strategies quickly ensuring expert algorithmaccess best expert long term.Several previously proposed algorithms (e.g., Powers & Shoham, 2005a, 2005b; Knobbout &Vreeswijk, 2011) select experts serial fashion, beginning expert highest potential. results imperfect information advocate integrated approachexperts evaluated parallel. allows agents better negotiate leader followerroles, turn leads better chances profitable cooperation compromise.7.2 Extensions Stochastic Gamesexpert algorithms discussed analyzed also applied two-player repeatedstochastic games least two different ways. First, Pepper (Crandall, 2012) used extendalgorithm designed repeated normal-form games repeated stochastic games. Pepper usesseparate instance learning algorithm designed normal-form games stage gamestochastic game. Future work determine quickly enhanced expert algorithmslearn stochastic games extended Pepper.Second, experts complex necessary. Several algorithms computing equilibrium strategies stochastic games recently developed (e.g., Cote & Littman, 2008;136fiT OWARDS INIMIZING ISAPPOINTMENTR EPEATED G AMESJohanson et al., 2012). equilibrium strategies could define set experts usedenhanced expert algorithms stochastic games. Future work involves identifying effectiveset experts stochastic games.Acknowledgmentswould like thank three anonymous reviewers provided detailed constructive feedback.suggestions, questions, comments greatly improved paper.Appendix A. Specification AlgorithmsTable 5 states parameters settings used algorithm used paper. algorithmcarefully analyzed ensure behaved defined. Parameters algorithmsselected balancing two objectives. First, desired algorithms performintended algorithms authors. Second, sought optimize algorithms short-termperformance (i.e., first 1000 rounds) compromising long-term performance.Since implementation expert algorithm provided literature (thoughmaintain general principles algorithm), provide details algorithm.Though originally designed expert algorithm, shown effectivelearning select among learning experts repeated games (Bouzy et al., 2011). learnsaspiration level, searches expert obtains payoffs meets aspiration.sets initial aspiration 1i one, highest payoff. randomly selects expert, follows joint action played twice. determined comparinglatest joint action Hc , set joint actions played far. ti updated follows:t|Hc |ti (i )|Hc |+ (1 (i )|Hc | )rit ,(18)(0, 1) learning rate rit average payoff obtained agent since lastexpert selected. updating ti , selects new expert:((t|Hc |)prob. f (ti , rit )(19)random(i ) otherwiseHere, random(i ) denotes random selection , f (ti , rit ) agents inertia givenf (ti , rit ) = min(1, rit /ti|Hc |).(20)Eq. (20) specifies agent selects expert played previous episode rit|H |meets exceeds ti . not, randomly selects new expert probability rit /ti c . Hcreset include last joint action played, process repeats.Appendix B. Performance Individual Expertsillustrate effectiveness experts defined Section 3, plot running average payoffexperts three different associates Chicken, PD, Offset, Tricky (Tables 12). results shown Figure 11. make several observations. First, scenario,137fiC RANDALLAlgorithmA0RandomBullyGodfatherDescription Parametersagent always selects first action.Randomly selects action uniform distribution action set Ai .leader strategy (Section 3.1) solution = arg maxs vi (s).mm).leader strategy (Section 3.1) solution = arg maxs (vi (s) vimm )(vi (s) vi(a) Static algorithmsAlgorithmBR1Description Parametersmodel-based reinforcement learning algorithm encodes state previous joint action.algorithm estimates associates behavior using fictitious-play assessment conditionedcurrent state (Eq. 10), computes best response using value iteration (discount factor1= 0.95). uses -greedy exploration, = 10+t/10.BR2Identical BR1 except encodes state previous two joint actions.WoLF-PHC14See Bowling Veloso (2002). Figure 2, = 100+t/10000, = 0.05, l = 20000+t,11121w = 20000+t . Otherwise, = 10+t/100 , = 10+t/100 , l = 100+t/100 , w = 100+t/100Q-learningmodel-free reinforcement learning algorithm proposed Watkins (1992). implementationencodes state previous joint action uses -greedy exploration. Q-values initialized111highest possible value 1. = 10+t/10, = 0.95, = 10+t/100(b) Reinforcement learning algorithmsAlgorithmExp3Description Parametersexpert algorithm (Auer et al., 1995) well-defined regret bounds multi-armed banditproblem. shown effective repeated games (Bouzy & Metivier, 2010; Crandall &Goodrich, 2011; Chang & Kaelbling, 2005). implementation evaluatesp expert= |Ai ||Ai | rounds selecting new expert. = /|i |, = |i |ln(|i |)/(e 1)T0 ,T0 expected number rounds game.UCB1expert algorithm (Auer et al., 2002) well-defined regret bounds adversarial multiarmed bandit problem. proved effective repeated games (Bouzy & Metivier, 2010).implementation evaluates expert = |Ai ||Ai | rounds selecting new expert.EEE-greedy expert algorithm designed repeated games played adaptive associates1(de Farias & Megiddo, 2004). = |Ai ||Ai |, = 10+t/10aspiration-based algorithm original proposed Karandikar et al. (1998), also analyzedStimpson et al. (2001). See text Appendix A. = 0.99(c) Expert algorithmsAlgorithmM-QubedDescription ParametersRL algorithm highest asymptotic performance several studies (Crandall & Goodrich,2011; Bouzy & Metivier, 2010). Parameters set work Crandall Goodrich (2011).ManipulatorBullyla Powers Shoham (2005a), algorithm serially follows three experts. first 150rounds, follows Bully. Thereafter, payoffs become lower expected, switches BR1.300 rounds, payoffs ever drop vimm , plays mmthereafter.ManipulatorGodfatherla Powers Shoham (2005a), algorithm serially follows three experts. first 150rounds, follows Godfather. Thereafter, payoffs become lower expected, switchesBR1. 300 rounds, payoffs ever drop vimm , plays mmthereafter.(d) algorithms: standards comparisonTable 5: Algorithmic parameters used paper.138fiT OWARDS INIMIZING ISAPPOINTMENTChicken: Experts Bully0.60.50.40.30.20.12004006008000.90.80.70.60.50.40.30.20.10010001Running Average PayoffRunning Average PayoffRunning Average Payoff0.7200400PD: Experts Bully0.70.60.50.40.30.20.16008000.70.60.50.40.30.20.12004004008000.60.50.40.30.20.16008000.70.60.50.40.30.20.12004000.70.60.50.40.30.20.1200(g)4006008000.90.80.70.60.50.40.30.20.1001000200400Tricky: Experts BR10.50.40.30.20.16008001000Tricky: Experts0.90.80.70.60.50.40.30.20.10010001Running Average PayoffRunning Average Payoff0.6800(i)10.7600(h)0.81000Offset: Experts0.9800(f)0.8Tricky: Experts Bully6001110000.90010008000.8001000Running Average Payoff0.76000.9Offset: Experts BR10.8(j)200(e)0.90.1Running Average PayoffRunning Average Payoff60014000.2PD: Experts0.8Offset: Experts Bully2000.3(c)0.900100014000.41(d)2000.5Running Average PayoffRunning Average PayoffRunning Average Payoff0.84000.6PD: Experts BR10.92000.70010001Running Average Payoff8000.8(b)1006000.9(a)00Chicken: Experts10.800R EPEATED G AMESChicken: Experts BR110.90020040060080010000.90.80.70.60.50.40.30.20.100200400(k)6008001000(l)Figure 11: Running average payoffs expert BR1, S, Bully four differentgames. Results average 50 trials.139fiC RANDALLleast one expert performs well opponent. example, Chicken,ideal algorithm able eventually achieve average payoff near 1 BR1many rounds. Several experts achieve performance level (Figures 11b 11c).Bully, best possible average payoff 0.33, several experts achieve (Figure 11a).Furthermore, PD, expert eventually obtains average payoff mutualcooperation (0.6) associate (Figures 11d11f).Second, Figure 11 illustrates different payoffs possible different associates.example, Chicken Tricky, best expert Bully substantially lowerpayoffs (despite playing optimally) best experts BR1 S. note disappointment normalizes performance cases average disappointment zeroindicates effective play relative set experts.Third, reaching highest possible payoff sometimes requires lot patience. example,Chicken (Figure 11c), best expert 100 rounds best expert 1000rounds. repeatedly following expert many rounds associate learnaccept equilibrium offered expert. illustrates difficult expert algorithmsmaintain low disappointment time.ReferencesArora, R., Dekel, O., & Tewari, A. (2012). Online bandit learning adaptive adversary:regret policy regret. Proceedings 29th International Conference MachineLearning, pp. 15031510.Auer, P., Cesa-Bianchi, N., & Fischer, P. (2002). Finite-time analysis multi-armed banditproblem. Machine Learning, 47, 235256.Auer, P., Cesa-Bianchi, N., Freund, Y., & Schapire, R. E. (1995). Gambling rigged casino:adversarial multi-armed bandit problem. Proceedings 36th SymposiumFoundations Computer Science, pp. 322331.Axelrod, R. (1984). Evolution Cooperation. Basic Books.Bouzy, B., & Metivier, M. (2010). Multi-agent learning experiments repeated matrix games.Proceedings 27th International Conference Machine Learning, pp. 119126.Bouzy, B., Metivier, M., & Pellier, D. (2011). Hedging algorithms repeated matrix games.ECML Workshop Machine Learning Data Mining Around Games, Athens,Greece.Bowling, M. (2004). Convergence no-regret multiagent learning. Advances NeuralInformation Processing Systems 17, pp. 209216.Bowling, M., & Veloso, M. (2002). Multiagent learning using variable learning rate. ArtificialIntelligence, 136(2), 215250.Brafman, R. I., & Tennenholtz, M. (2003). R-max general polynomial time algorithm nearoptimal reinforcement learning. Journal Machine Learning Research, 3, 213231.Cesa-Bianchi, N., Dekel, O., & Shamir, O. (2013). Online learning switching costsadaptive adversaries. Advances Neural Information Processing Systems 26, pp. 11601168.140fiT OWARDS INIMIZING ISAPPOINTMENTR EPEATED G AMESChakraborty, D., & Stone, P. (2010). Convergence, targeted optimality, safety multiagentlearning. Proceedings 27th International Conference Machine Learning, pp.191198.Chang, Y., & Kaelbling, L. P. (2005). Hedge learning: Regret-minimization learning experts.Proceedings 22nd International Conference Machine Learning, pp. 121128.Chang, Y.-H. (2007). regrets no-regret. Artificial Intelligence, 171(7), 434439.Chasparis, G., Shamma, J., & Arapostathis, A. (2010). Aspiration learning coordination games.Proceedings 49th IEEE Conference Decision Control, pp. 57565761.Cote, E. M. D., & Littman, M. L. (2008). polynomial-time Nash equilibrium algorithmrepeated stochastic games. Proceedings 24th Conference Uncertainty ArtificialIntelligence, pp. 419426.Crandall, J. W. (2012). add Pepper: extending learning algorithms repeated matrix gamesrepeated markov games. Proceedings 11th International Conference AutonomousAgents Multiagent Systems, pp. 399406.Crandall, J. W., & Goodrich, M. A. (2011). Learning compete, coordinate, cooperaterepeated games using reinforcement learning. Machine Learning, 82(3), 281314.Crandall, J. W., & Goodrich, M. A. (2005). Learning teach follow repeated games.AAAI workshop Multiagent Learning, Pittsburgh, PA.de Farias, D., & Megiddo, N. (2003). combine expert (or novice) advice actionsimpact environment. Advances Neural Information Processing Systems 16.de Farias, D., & Megiddo, N. (2004). Explorationexploitation tradeoffs expert algorithmsreactive environments. Advances Neural Information Processing Systems 17, pp. 409416.Foster, D. P., & Vohra, R. (1999). Regret on-line decision problem. Games EconomicBehavior, 29, 735.Fudenberg, D., & Levine, D. K. (1998). Theory Learning Games. MIT Press.Ganzfried, S., & Sandholm, T. (2011). Game theory-based opponent modeling large imperfectinformation games. Proceedings 10th International Conference AutonomousAgents Multiagent Systems, pp. 533540.Gordon, G. J., Greenwald, A., & Marks, C. (2008). No-regret learning convex games. Proceedings 25th International Conference Machine Learning, pp. 360367.Greenwald, A., & Jafari, A. (2003). general class no-regret learning algorithms gametheoretic equilibria. Proceedings 16th Annual Conference Computational Learning Theory, pp. 212.Greenwald, A., & Hall, K. (2003). Correlated Q-learning. Proceedings 20th InternationalConference Machine Learning, pp. 242249.Johanson, M., Bard, N., Lanctot, M., Gibson, R., & Bowling, M. (2012). Efficient Nash equilibriumapproximation Monte Carlo counterfactual regret minimization. Proceedings11th International Conference Autonomous Agents Multiagent Systems, pp. 837846.141fiC RANDALLKarandikar, R., Mookherjee, D., R., D., & Vega-Redondo, F. (1998). Evolving aspirationscooperation. Journal Economic Theory, 80, 292331.Knobbout, M., & Vreeswijk, G. A. (2011). Sequential targeted optimality new criterionteaching following repeated games. Proceedings 10th International Conference Autonomous Agents Multiagent Systems, pp. 517524.Littman, M. L. (1994). Markov games framework multi-agent reinforcement learning.Proceedings 11th International Conference Machine Learning, pp. 157163.Littman, M. L. (2001). Friend-or-foe: Q-learning general-sum games. Proceedings 18thInternational Conference Machine Learning, pp. 322328.Littman, M. L., & Stone, P. (2001). Leading best-response strategies repeated games. IJCAIworkshop Economic Agents, Models, Mechanisms, Seattle, WA.Littman, M. L., & Stone, P. (2005). polynomial-time Nash equilibrium algorithm repeatedgames. Decision Support Systems, 39, 5566.Powers, R., & Shoham, Y. (2005a). Learning opponents bounded memory. Proceedings 19th International Joint Conference Artificial Intelligence, pp. 817822.Powers, R., & Shoham, Y. (2005b). New criteria new algorithm learning multi-agentsystems. Advances Neural Information Processing Systems 17, pp. 10891096.Stimpson, J. R., Goodrich, M. A., & Walters, L. C. (2001). Satisficing learning cooperationprisoners dilemma. Proceedings 17th National Conference ArtificialIntelligence, pp. 535544.Watkins, C. J., & Dayan, P. (1992). Q-learning. Machine Learning, 8, 279292.142fiJournal Artificial Intelligence Research 49 (2014) 49-78Submitted 07/13; published 01/14Robustness Stability Constraint ProgrammingDynamism UncertaintyLaura ClimentLCLIMENT @ DSIC . UPV. ESInstituto de Automatica e Informatica IndustrialUniversidad Politecnica de Valencia, Spain.Richard J. WallaceR . WALLACE @4 C . UCC . IEINSIGHT Center Data AnalyticsDepartment Computer Science. University College Cork, Ireland.Miguel A. SalidoMSALIDO @ DSIC . UPV. ESInstituto de Automatica e Informatica IndustrialUniversidad Politecnica de Valencia, Spain.Federico BarberFBARBER @ DSIC . UPV. ESInstituto de Automatica e Informatica IndustrialUniversidad Politecnica de Valencia, Spain.AbstractMany real life problems solved constraint programming, come uncertaindynamic environments. dynamism, original problem may change time,thus solution found original problem may become invalid. reason, dealingproblems become important issue fields constraint programming.cases, extant knowledge uncertain dynamic environment. cases,information fragmentary unknown. paper, extend concept robustnessstability Constraint Satisfaction Problems (CSPs) ordered domains, limitedassumptions need made possible changes. present search algorithm searchesrobust stable solutions CSPs nature. well-known meetingcriteria simultaneously desirable objective constraint solving uncertain dynamicenvironments. also present compelling evidence search algorithm outperformsgeneral-purpose algorithms dynamic CSPs using random instances benchmarks derivedreal life problems.1. IntroductionConstraint programming powerful tool solving many artificial intelligence problemsmodeled CSPs. Much effort spent increasing efficiency algorithmssolving CSPs, reflected literature. However, techniques assume setvariables, domains constraints involved CSP known fixed problemmodeled. strong limitation deal real life situations problemsmay come uncertain dynamic environments. Due dynamism environment,original problem corresponding modeled CSP may evolve. addition, sincec2014AI Access Foundation. rights reserved.fiC LIMENT, WALLACE , ALIDO & BARBERreal world uncertain nature, information dynamism environment mayincomplete, erroneous even may exist. situations, solution holds originalmodel become invalid changes original problem.approaches deal situation classified as: (i) reactive approaches, whosemain objective obtain new solution similar possible previous solution (the solutionfound changes occurred) efficient way, (ii) proactive approaches, useknowledge possible future changes order avoid minimize effects (for surveysee Verfaillie & Jussien, 2005). Thus, proactive approaches applied changes occur,reactive approaches applied changes invalidate original solution.Reactive approaches re-solve CSP solution loss, consumes computationaltime. clear inconvenience, especially deal short-term changes, solution loss frequent. addition, many applications, online planning scheduling,time required calculate new solution may long actions taken redresssituation. addition, loss solution several negative effects modeled situation. example, task assignment production system several machines, could causeshutdown production system, breakage machines, loss material/objectproduction, etc. transport timetabling problem, solution loss, due disruptionpoint, may produce delay propagates entire schedule. negative effectsprobably entail economic loss well.Proactive approaches try avoid drawbacks stated and, therefore, highly valued dealing problems uncertain dynamic environments. Given advantagesproactive approaches potentially offer, paper restrict approach. Heretofore two main types proactive approaches considered, distinguishedbasis characteristics solutions obtain, called robust flexible(see Section 2). important survey constraint solving uncertain dynamic environments(Verfaillie & Jussien, 2005), authors mention possibility developing proactive strategiescombine solution features robustness flexibility. state: productionsolutions time robust flexible, every chance resist changeseasily adapted resist, obviously desirable objective. paper,present algorithm meets objective combining solution robustness stability.solution feature stability special case flexibility.Many proactive approaches proposed literature assume existence knowledgeuncertain dynamic environment (see Section 3). cases difficult characterizerobustness solutions detailed information possible future changes available. consider situations added difficulty stemming factlimited assumptions changes made. discussion focuses CSPs ordereddiscrete domains model problems order elements domainsignificant. cases, common type change problems may undergo restrictivemodifications bounds solution space. assumptions motivationsintroduced Climent et al. (2013). Moreover, examples real life problems exhibittype dynamism described, specifically, temporal reasoning-based problems, spatial geometric reasoning problems, design problems. temporal problems, delays inherentfeature, implies restrictive modifications bounds involved disruptions.instance, Fu, Lau, Varakantham, Xiao (2012) stated unexpected external eventsmanpower availability, weather changes, etc. lead delays advances completion activities50fiROBUSTNESS TABILITY C ONSTRAINT P ROGRAMMING DYNAMISM U NCERTAINTYscheduling problems. spatial geometric reasoning problems, constraints readjusted due measurement errors. latter also occur design problems, datacompletely certain.paper, present algorithm searches solutions CSPs ordered domains,robust also stable often repaired using value similarmagnitude undergo value loss. paper organized follows. next section recallsgeneral definitions. Section 3 gives brief account earlier proactive procedures. Section 4presents new conception robustness stability exists order elementsdomain. Sections 5 6 describe main objective finding solutions meet stabilityrobustness criteria simultaneously. Then, Section 7 search algorithm meetsobjectives explained. Section 8 presents case study scheduling problems. Section 9 describesexperiments various types CSPs, showing effectiveness present approachfinding solutions stable robust. Section 10 gives conclusions.2. Technical Backgroundsection give basic definitions used rest paper, following standardnotations definitions literature.Definition 2.1 Constraint Satisfaction Problem (CSP) represented triple P = hX , D, CiX finite set variables X = {x1 , x2 , ..., xn }, set domains = {D1 , D2 , ..., Dn }variable xi X set values variable take, Cfinite set constraints C = {C1 , C2 , ..., Cm } restrict values variables simultaneously take. denote DC set unary constraints associated D.Definition 2.2 tuple assignment values subset variables Xt X .tuple feasible call s. means assignment domain valuesvariables violate constraint. complete assignment (it involvesvariables CSP), solution CSP. Xs subset variables involveds. X \Xs set unassigned variables s. value assigned variable xdenoted s(x). addition, denote Ds (x) D(x) subset domain valuesvariable x consistent s.number possible tuples constraintQ Ci C composed elementsCartesian product domains var(Ci ): xj var(Ci ) Dj , var(Ci ) X setvariables involved Ci (scope Ci ).Definition 2.3 tightness constraint ratio number forbidden tuplesnumber possible tuples. Tightness defined within interval [0,1].Inferential processes CSPs narrow search space possible partial solutions. workuse one known used consistency procedure: arc-consistency.Definition 2.4 CSP arc-consistent (Mackworth, 1977a) iff pair constrained variablesxi xj , value Di exists least one value b Dj partialassignment (xi = a, xj = b) satisfies constraints related xi xj . value51fiC LIMENT, WALLACE , ALIDO & BARBERdomain variable arc-consistent eliminated partsolution. domain variable arc-consistent iff values arc-consistent. Thus,problem arc-consistent iff arcs arc-consistent:Cij C, D(xi ), b D(xj ): b satisfy Cij .following, several properties associated solutions problems comedynamic environments defined.Definition 2.5 robust solution CSP within set solutions one highestlikelihood remaining solution given set changes CSP.Definition 2.6 flexible solution anything (a partial solution, complete solution, conditionalsolution, set solutions, etc.) that, case change, easily modified produce solutionnew problem (Verfaillie & Jussien, 2005).specific concept flexibility concept stability.Definition 2.7 solution s1 stable another solution s2 if, eventchange invalidates them, closer alternative s1 s2 exists (modified workpresented Hebrard, 2006).main difference Definition 2.7 Definition 2.6 former introducesconcept closer solution. measurement closeness made calculating distancessolutions. concrete information distance equations explained followingsections. would like remark Definition 2.5 consider alterations originalsolution resistance changes problem. hand, Definition 2.6Definition 2.7 consider changes original solution new solution producedchange problem.3. Related Work: Proactive ApproachesSeveral approaches proposed past handling type problem,classified based kind solutions obtain. Thus, techniques search robustsolutions others search flexible solutions (for survey see Verfaillie & Jussien, 2005).section describe techniques search robust solutions limitations.discuss technique searches certain type stable solutions: super-solutions.3.1 Searching Robust SolutionsMany earlier approaches search robust solutions use additional information uncertain dynamic environment problem occurs, often involves probabilistic representations. one example type, information gathered form penaltiesvalues invalidated changes problem (Wallace & Freuder, 1998). Nevertheless, Probabilistic CSP model (PCSP) (Fargier & Lang, 1993), exists informationassociated constraint, expressing probability existence. techniques focusdynamism variables CSP. instance, Mixed CSP model (MCSP) (Fargier,52fiROBUSTNESS TABILITY C ONSTRAINT P ROGRAMMING DYNAMISM U NCERTAINTYLang, & Schiex, 1996) subsequent Uncertain CSP model (UCSP) (Yorke-Smith & Gervet,2009) consider dynamism certain uncontrollable variables take different valuesuncertain domains. related model, uses Simple Temporal Networks, adds datatime uncertainties preferences, represent starting ending times events (STPPUs) (Rossi, Venable, & Yorke-Smith, 2006). Stochastic CSP model (SCSP) (Walsh, 2002)also considers probability distributions associated uncontrollable variables. BranchingCSP model (BCSP) considers possible addition variables (with certain associated gain)current problem (Fowler & Brown, 2000).models, form algorithm dependent detailed knowledgedynamic environment. purpose, list possible changes required explicitrepresentation uncertainty, often form associated probability distribution. result,approaches cannot used necessary information unknown. many real problems,however, knowledge possible changes either limited non-existent. Hence,important need techniques find robust solutions kind environment.instance, Climent et al. (2013) cope CSPs model problems orderdomain elements significant. Specifically, CSPs modeled Weighted ConstraintSatisfaction Problems (WCSPs) (Larrosa & Schiex, 2004) penalizing valid tuples basedcoverings. Instead requiring extra detailed dynamism information, authors make limitedassumptions concerning changes might occur, related nature CSPsordered domains. Specifically, dynamism assumed take form restrictions boundssolution space. paper, make assumptions dynamism.previous WCSP modeling approach computes robustness based feasible neighbours composecovering surrounds analyzed value respect constraint boundary. Thus,cases neighbour feasible respect one bound another bound,neighbour feasible solution space. reason, approach obtains robustnessapproximations problems high relation constraints.hand, algorithm described paper computes feasible assignments respect entiresolution space, avoids weakness WCSP modeling approach explained above.comparison approaches found Section 9.3.2 Searching Super-SolutionsTechniques search stable solutions certain type, denoted super-solutions,presented Hebrard (2006). goal able repair invalid solution changesoccur, minimal changes specified advance. Since another approachrequire detailed additional information changes problem, interestcompare search algorithm introduced paper.Definition 3.1 solution (a, b)-super-solution loss values variablesrepaired assigning values variables changing values bvariables (Hebrard, 2006).CSPs, major focus finding (1, 0)-super-solutions. highcomputational cost computing b > 0 > 1. one reasons analyzeparticular super-solution case paper. reason given Verfaillie Jussien(2005), authors state desirable objective limit much possible changes53fiC LIMENT, WALLACE , ALIDO & BARBERproduced solution, motives search (a, 0)-super-solutions. general, unusual find (1, 0)-super-solutions variables repaired. reason, Hebrard(2006) also developed branch bound-based algorithm finding solutions close(1, 0)-super-solutions, i.e., number repairable variables maximized (also called maximizing (1, 0)-repairability).4. Extending Robustness Stability CSPs Ordered Domainssection extend original definition solution robustness (Definition 2.5) solutionstability (Definition 2.7) consider CSPs ordered domains, limited assumptionsmade changes problem derived inherent structure. Givenframework therefore existence significant order values domains,reasonable assume original bounds solution space restricted relaxed,even cover possible changes. bounds solution space delimiteddomains constraints CSP. Note possibility solution loss existschanges original bounds solution space restrictive. reason,solution located farther away bounds likely remain solution. Givenassumptions, specialize Definition 2.5 framework follows.Definition 4.1 robust solution CSP ordered domains without detailed dynamismdata solution maximizes distance dynamic bounds solution space.Furthermore, definition stable solutions CSPs ordered domains madeprecise possible define specific notion closeness two solutionsdue existent order domain values. Hebrard (2006) measures level dissimilaritytwo solutions countingPn number variables take different values solutions, i.e.,Hamming distance ( i=1 (s1i 6= s2i )). Later, Hebrard, OSullivan, Walsh (2007) consideranother similarity measure: Manhattan distance.P measure uses sum absolute difference values (of variable) solutions ( ni=1 |s1i s2i |). Note unlike Hammingdistance, Manhattan distance requires order elements order calculate absolutedifference values. following definition, apply Manhattan distance notionstable solutions CSPs ordered domains.Definition 4.2 Given order relationship values set solutions, solution s1stable another solution s2 iff, event change invalidates them, existsalternative solution s1 lower Manhattan distance Manhattan distancealternative solution s2.Furthermore, present extension Definition 3.1 CSPs ordered domains fixingmaximum Manhattan distance original solution repaired solution,called c.Definition 4.3 solution (a, b, c)-super-solution loss values variables most,repaired assigning values whose Manhattan distance respect originalvalues lower equal c, involves changing values b variables most.definition also holds (1, 0, c)-super-solutions (1, 0, c)-repairability,main focus stability analysis paper.54fiROBUSTNESS TABILITY C ONSTRAINT P ROGRAMMING DYNAMISM U NCERTAINTY5. Searching Robust Stable Solutions: General Main Objectiveorder find robust stable solutions CSPs ordered domains assumptions,combine robustness stability criteria presented Section 4. mentioned, calculatingdistances required search robust solutions framework. However, measuredistance dynamic bounds solution space always obvious easy derive,since bounds delimited domains constraints CSP, latter mayextensionally expressed. However, deductions minimum distances boundsmade based feasibility neighbours solution. idea first motivatedsimple example formalized.Example 5.1 Figure 1 shows two solution spaces (one convex non-convex) whosedynamic bounds marked contiguous lines. robust solutions according Definition4.1 highlighted. Note two contiguous feasible neighbours sidesassignment (discontinuous lines).(a) Convex Solution Space(b) Non-convex Solution SpaceFigure 1: Robust solutions different solution spaces.example, conclude ensure solution locatedleast distance bound certain direction n-dimensional space tuplesdistances lower equal direction feasible. Therefore, numberfeasible contiguous surrounding neighbours solution measure robustnesssolution face restrictive changes affect original bounds solution space (seeDefinition 4.1). addition fulfilling main objective finding solutions whose valueshigh number feasible neighbours close assignment, criterion used obtainsolutions high stability. value assigned variable least onefeasible neighbour values, variable repairable. is, assigned valuelost, easily repaired assigning neighbour value (since value consistentrest values assignment). Regarding stability notion Definition 4.2, notedifference lost value repairable value low, since immediateneighbours. fact, value difference one, minimum possible.55fiC LIMENT, WALLACE , ALIDO & BARBERset feasible contiguous neighbour values value v differences greaterk respect v increasing, decreasing, directions respect orderrelationship denoted Nk (x, v, s, ). Value v feasible value variable x feasiblepartial/complete assignment s. Here, say values feasible, meanalso feasible respect s. (Recall use Ds (x) D(x) subset domain valuesconsistent feasible partial assignment s.) list operators composedset paired elements, operator pairs. operator pair denoted {{>, +}, {<, }}.operator pairs fix order directions analyze. Thus, set {>, +} refers values greaterv (increasing direction) set {<, } refers values lower v (decreasing direction).operator pair, operator position j referenced ij . instance, listoperators = {{>, +}, {<, }}, operator pair 1 references {>, +} operator 12references operator +. Given notation, define Nk (x, v, s, ) as:Nk (x, v, s, )= {w Ds (x) : , w i1 v |v w| k(1)z j [1 . . . (|v w| 1)], (v z2 j) Ds (x)}first condition Equation 1 ensures value w greater lower v accordingoperator i1 {>, <} distance values less equal k.second condition ensures values closer v w also feasible values s.least one not, value w cannot belong Nk (x, v, s, ). mentioned previously,set feasible neighbours value contiguous. Otherwise, infeasiblespace value another feasible value. instance, Figure 1(b) value 5belong Nk (y, 2, {x = 2}, ) k value 4 feasible valuetherefore outside bounds solution space.general case CSPs ordered domains assume boundsdynamic, desirable objective find contiguous surrounding feasible neighbourssides. reason = {{>, +}, {<, }}. list operator pairs, last conditionEquation 1 checks values directions closer v w, also feasiblevalues s. instance, Figure 1(b), Nk (y, 2, {x = 2}, {{>, +}, {<, }}) = {1, 3} kvalue. Note neighbours sides value 2 respect axis. Section8, show specific case desirable apply one operator pair duenature problem.apply Equation 1 domains ordered Z, monotonic order-preservingfunction applied. instance, consider = {f reezing, cold, mild, warm, hot,boiling}, monotonic function assigns greater values values higher temperatures coulddefined. example, f (f reezing) = 1, f (cold) = 2, f (mild) = 3, f (warm) = 4, f (hot) =5 f (boiling) = 6.6. Objective FunctionSection 5 stated main desirable objective selected value many contiguous feasible neighbours certain direction, determine minimum distancevalue bound direction. approximating distance several values assigned(partial complete assignment), compute number neighbours value. Therefore,56fiROBUSTNESS TABILITY C ONSTRAINT P ROGRAMMING DYNAMISM U NCERTAINTYdefine objective function search algorithm sum size Nk (x, v, s, )(denoted |Nk (x, v, s, )|) variable x X . incomplete assignment, calculatemaximum |Nk (x, v, s, )| v Ds (x) unassigned variable x X \Xs (upperbound). Note maximum size set neighbour values variable | | k,| | number pair operators. Thus, maximum size set neighbour values2k composed two operator pairs k composed one operator pair. Notealso necessary check values Ds (x) if, least one them, sizeset maximum possible. following equation, formalize objective functionused search algorithm.f (s, k, ) = {Xmax{|Nk (x, v, s, )|, v Ds (x)} +X|Nk (y, s(y), s, )|}(2)yXsxX \XsExample 5.1, robust solutions Figures 1(a) 1(b) (highlighted solutions) f (s, k, {{>, +}, {<, }}) = 4, k 1, since every value assigned solutiontwo contiguous neighbours sides.Next, give formal rationale using total number neighbours solution (sumfeasible surrounding neighbours value solution) measure robustness.k = 1, convex solution space, value either zero, one two feasible neighbours. discount case zero neighbours assignment zero feasibleneighbours, must part singleton domain, part solutions.need consider values one two feasible neighbours.case, solution greater sum one whose assignments feasible neighbour pairs. easily seen consider difference solution whosevalues one feasible neighbour solution; difference equalnumber feasible neighbour pairs associated latters assignments.Proposition 1. assume two feasible neighbours confers greater robustnessone probabilities single changes independent, solutiongreater feasible neighbour-sum another also robust, vice versa.non-convex case, unfortunately possible one assignment zero feasibleneighbours, assignments variable one two. case, cannotassume Proposition 1. However, number variables problem increases, becomesincreasingly unlikely variable assignment zero feasible neighboursassociated largest neighbour-sum remaining variables.Regarding measure stability, solution maximizes (1, 0, k)-repairability (seeDefinition 4.3) also maximizes number variables repaired neighbour valuedistance less equal k (without modifying variable). However, obtain robustsolutions maximize sum neighbour values value solution. Note evenmaximization criteria identical, mentioned, number variablesproblem increases, becomes increasingly unlikely non-repairable variable associatedlargest neighbour-sum remaining variables. work usetechnique finding robust stable solutions CSPs ordered domains. Nevertheless,basic units measure criteria different.57fiC LIMENT, WALLACE , ALIDO & BARBER7. Search Algorithmsection present algorithm finding robust stable solutions according mainobjective described Section 6. purpose, incorporated optimization criterionBranch & Bound algorithm (Algorithm 1) maximizes objective function f (s, k, )(see Equation 2). mentioned, function sums |Nk | assigned variable maximumpossible |Nk | unassigned variable. Note computation upper bound finaltotal number feasible contiguous neighbours solution.Algorithm 1 (B&B-Nk ) anytime algorithm uses inference process prunesbranches whose objective function value lower equal current maximum functionvalue obtained, referred lb (lower bound). process stops branchesexplored pruned, providing solution maximum f (s, k, ). hand,limit search time therefore quality best solution found fixing time cutoff.course, time Algorithm 1 spends searching, robust stable solutionprovided be. addition, compute maximum possible objective function value,maximum number neighbours variable multiplied number variablesCSP, denoted ub (upper bound). Thus, objective function value new solution foundequal ub, algorithm stops, since solution optimal.Algorithm 1: B&B-Nk : Branch & Bound anytime algorithmData: P = hX , D, Ci, , k, scale, m, time cutoff (optional)Result: s, Nk , lb; // Partial assignmentXs ; // Set variables assignedNk ; // Set contiguous surrounding neighbourslb 1; // Maximum f (s, k, ) solutionsub | | k |X |;1;GAC3-Nk (P, s, Xs , Nk , , k, lb);repeatrestarting-scratch new solution found1;C scale mi ; //number fails cutoff+ 1;time cutoff MGAC3-Nk (P, s, Xs , Nk , , k, lb, 0, C, ub);implemented Branch & Bound algorithm using Geometric restart strategy (Walsh,1999) order reduce repetition fails search due early wrong assignments(thrashing). Thus, time number failures (referenced nbF ) reaches number-offails cutoff value condition (C) checked Algorithm 3, algorithm restarts searchscratch, except constraint weights stored dom/wdeg heuristic variable selection(Boussemart et al., 2004). value number fails cutoff increased geometrically Algorithm 1 according scale factor (referred scale) multiplicative factor (referredm). implemented two different options carry solution found. first,called restarting-completion, first solution found, algorithm continues search58fiROBUSTNESS TABILITY C ONSTRAINT P ROGRAMMING DYNAMISM U NCERTAINTYcompletion (this done assigning huge number representing number fails cutoff).second option, called restarting-scratch, solution found, algorithm restartssearch scratch also restarts number fails cutoff computation (the constraint weighsremain same). instances large domain sizes, restarting option effectiveavoids spending large amount time specific branch. latter happensAlgorithm 1 checks many domain values variables located low levels search tree, objective function partial assignment better current maximum (lb).case, exists time cutoff, Algorithm 1 could analyze branches treemay contain solutions better quality.inference process carried Algorithm 2 (GAC3-Nk ), extensionwell-known AC3 (Mackworth, 1977b) performs Generalized Arc Consistency (GAC) (Mohr& Henderson, 1986; Bessiere, 2006). specific notation included, var(c),scope c C. original seekSupport function GAC3 searches supportdomain value. modified function slightly providing set valuesanalysed parameter function. Thus, values deletedexist consistent support respect partial assignment, seekSupport returnsfalse. function first called values domain variables (for checkingpartial assignment GAC3) later Nk assigned variables (for checkingNk (x, s(x), s, ) GAC3 respect s). order ensure contiguity values Nk ,Algorithm 2 checks consistency subsets Ni Nk , equal one initially,increased one unit least one values Ni inconsistent reaches valuek. complexity updating Ni reduced | | domains ordered. Notecase greater lower values candidates set, updatingcost 2 i. composing set contiguous neighbour values GAC3 respect s,Algorithm 2 analyzes objective function f (s, k, ) greater lb. not,GAC3, returns false.Algorithm 3 (MGAC3-Nk ) performs Maintaining GAC3 procedure assigning variable x X new value v D(x), value selected GAC3-Nk respect s.implemented two value selection heuristics: lexicographical order selection valuemaximizes |Nk (x, v, s, )|, starting intermediate values. real life problemslexicographical selection order effective finding feasible solutions quickly.example scheduling problems, whose domain values represent time units; hence importanceselecting low values order exceed maximum fixed makespan. However,important select low values, heuristic starts intermediate values may offer betterresults selecting values maximize objective function current nodesearch tree. Furthermore, since search starts intermediate values, likelihood selectingvalues located far domain bounds higher.Algorithm 3 also responsible updating set assigned variables Xs , partial assignment maximum objective function value lb (for solution found). Furthermore,stores domains set neighbours variables making assignment. Notevariable x assigned, D(x) contains single value value assigned x. Algorithm 2 (GAC3-Nk ) returns false, Algorithm 3 (MGAC3-Nk ) carries backtrackingprocess also restores domains set neighbours variables.reduce computational time deal CSPs convex domains, implemented Bounds Arc Consistency discrete CSPs (Lhomme, 1993). main feature59fiC LIMENT, WALLACE , ALIDO & BARBERAlgorithm 2: GAC3-Nk : Global Arc Consistency algorithmData: P, s, Xs , Nk , , k, lb, nbFResult: D, Nk , nbFQ {(x, c), c C, x var(c)} // var(c) scope cQ 6=(x, c) takeElement(Q);seekD seekSupport(x, D(x), c); // Found support D(x) c?D(x) =nbF nbF + 1; // number failuresreturn falseseekDQ Q {(y, c ), c C c 6= c x, var(c ) x 6= y}x Xs1;repeatupdate Ni (x, s(x), s, ) applying Equation 1;seekN seekSupport(x, Ni (x, s(x), s, ), c);+ 1;seekN = false > k;Nk (x, s(x), s, ) Ni (x, s(x), s, )return f (s, k, ) > lb // See Equation 2consistency technique arc consistency restricted respect boundsconvex domain. Thus, including search algorithm affects seekSupport function, instead seeking support set values, checks minimummaximum bounds. Note implementation necessary search robust stable solutions; however allows significant reduction search time. apply boundsconsistency tentative values assignment set neighbours, sincerequire complete consistency check. Otherwise could exist infeasible gaps, wouldbreak contiguity requirement ensures minimum distances bounds.8. Case Study: Searching Robust Stable Schedulestypes real life problems whose structure provide us specific informationdynamism. section analyze well known type problem literature:scheduling problems. problems converted satisfiability problems fixingmaximum makespan, modeled CSPs. CSP modeling usually consistsassociating start end time task particular variable (in paper usestart time). domain associated variable represents possible time units, meanspossible fix maximum desired makespan. Finally, duration tasksorder (if exists) fixed means CSP constraints.section, first explain robustness scheduling measurement units,describe objective function CSPs model scheduling problems give exampleapplication.60fiROBUSTNESS TABILITY C ONSTRAINT P ROGRAMMING DYNAMISM U NCERTAINTYAlgorithm 3: MGAC3-Nk : Maintaining Global Arc ConsistencyData: P, s, Xs , Nk , , k, lb, nbF, C, ubResult: s, Nk , lbselect x X \Xs ; // dom/wdeg heuristicXs Xs x;save Nk ;D(x) 6= nbF < Cselect min(v) D(x); // Heuristic 1: lexicographical value orderselect v D(x), max{|Nk (x, v, s, )|} starting intermediate values; // Heuristic 2{x = v}D(x) v;GAC3-Nk (P, s, Xs , Nk , k, lb, nbF )Xs = X// New solution foundlb f (s, k, );lb = ubreturn true // Best possible sum achievedC ; // restarting-completionreturn false // restarting-scratchMGAC3-Nk (P, s, Xs , Nk , k, lb, nbF, C, uB)return truerestore D\D(x) Nk ;s\{x = v};Xs Xs \x;return false8.1 Robustness Measurement Schedulingsection, introduce several criteria measuring scheduling robustness.purpose, use terms buffers slack refer spare time related tasks.two main factors enhance capability schedule absorb unexpected delaysactivities: number buffers duration. Ideally, according robustness criterion,buffer time long possible longer is, longer delaysable absorb. reason another straight-forward robustness measurement proposedLeon et al. (1994) slack average schedule. combination durationbuffers distribution across schedule provides accurate robustness measuredenoted Rslack. slight variant measure introduced Surico et al. (2008) consistsmaximizing slack average (shorted avg) minimizing standard deviation (shortedstd) schedule s. regulating importance standard deviation term, authorsuse parameter called , take value interval [0.2,0.25], according authorsconsiderations.Rslack= avg(slack) std(slack)61(3)fiC LIMENT, WALLACE , ALIDO & BARBERAnother means measuring robustness system, defined Kitano (2007) relatedresistance perturbations certain probability occurrence. approachextended Escamilla et al. (2012) scheduling problems probabilities task delays, Z discrete set unexpectedunknown. robustness measure denoted RF,Zdelays duration tasks, F measures whether schedule still feasible disruption1, z Z probability(F (z) = 1 satisfiable, otherwise F (z) = 0) p(z) = |z|instance z Z (i.e., delays considered probability occurrence).RF,Z=Xp(z) F (z)(4)zZ8.2 Objective Function SchedulingCSP models scheduling problems, fact domain values represent time units implications respect measures robustness stability. problems, valuesolution lost, lower values cannot used replacing unfeasible value represent time units already taken place. Thus, incident, time pointavailable, neither values lower t. Therefore, lower feasible neighboursimprove robustness stability solution CSP models scheduling problem(since cannot absorb delays used repairable values). Given characteristics,main desirable objective search neighbours greater value assigned. this,fix set operators = {{>, +}} scheduling problems. illustrated below.Example 8.1 consider toy scheduling problem two tasks: T0 T1 . duration two time units must executed order listed. maximum makespanallowed six time units. Figure 2 see associated CSP model solution space.variables X0 X1 represent start times tasks T0 T1 , respectively. domainvariables (represented discontinuous lines) [0 . . . 4], preserves maximummakespan six time units (the maximum start time task maximum makespan minusduration aforesaid task). one constraint controlling execution order tasks(T0 must start T1 ), C0 : X1 X0 + 2. solution space represented darkgray area, six solutions (black dots).specific information given dynamic environment, schedulerobust? stated Section 8.1, greater number time buffers greater duration, robust schedule is. determine solution modeledCSP meets requirements? answer obtained determining feasible contiguousneighbours greater values, located distances less equal k solution. However,depending value k, either prioritize selection schedules large numbershort time buffers prioritize selection schedules lower number long timebuffers. number greater feasible neighbours associated value variable correspondstotal amount slack located task represented variable. Thus, slackable absorb delay previous task long itself, without modifying taskspresent schedule (robustness feature). Furthermore, slack following task sufficientabsorb delay, start following task delayed (after repairing broken assignedvalue) long enough buffer associated later task (stability feature).62fiROBUSTNESS TABILITY C ONSTRAINT P ROGRAMMING DYNAMISM U NCERTAINTY34X1012C001234X0Figure 2: CSP model associated Example 8.1 solution space.example, two-dimensional CSP representing scheduling problemtwo tasks, three schedules robust according criteria stated above.maximize sum distances greater values located distance one (k = 1)value assignment, obtain solution shown Figure 3(a), whose sum f (s0 , k =1, {>, +}) = 1 + 1. first number Nk (x0 , v0 , s, {>, +}) second Nk (x1 , v1 , s, {>, +}),v0 v1 values assigned variables x0 x1 respectively. Note sumsneighbours greater solution values located distance onef (s1 , k = 1, {>, +}) = 1 + 0 f (s2 , k = 1, {>, +}) = 0 + 1, respectively. following (a)figures, greater neighbours indicated elipse, arrow pointing solution (thecircled dot). associated (b) figures, schedules equivalent solutions marked (a)shown. Note greater neighbours indicated (a) figures correspond slack(b) figures. instance, Figure 3(b) task associated slack duration one,corresponds existence one greater neighbour value assignment Figure 3(a).hand, maximize sum greater neighbors values k > 1, threesolutions represented Figures 3(a), 4(a) 5(a) classified best solutions accordingobjective function. computation sum neighbours located distance lowerequal k, k > 1 is: f (s0 , k > 1, {>, +}) = 1 + 1 (Figure 3(a)), f (s1 , k > 1, {>, +}) = 2 + 0(Figure 4(a)) f (s2 , k > 1, {>, +}) = 0 + 2 (Figure 5(a)). Note schedules Figures4(b) 5(b) one time buffer, duration two time units, unlike schedulerepresented Figure 3(b) two time buffers one unit each. Thus, fixing k = 1prioritize seek high number time buffers. However, greater k values, prioritizeduration, even case distribution may optimal.consider stability solutions, small modifications solutions alwayspreferred. case, possible task starts scheduled time, reassigningstart time closer greater neighbour, composing another schedule similaroriginal one. Therefore, search feasible greater neighbours (which introduces bufferstasks schedule) improving both, robustness stability obtained schedules.search schedules buffers k time units also achieved modelreformulation techniques. achieved adding two variables original variable (thevariables represent start time tasks). One variable represents slack followingtask variable represents sum slack original starting time.63fiC LIMENT, WALLACE , ALIDO & BARBER012X043SlackT02X10(a) Solution space.12T134Slack56(b) Schedule marked solution.Figure 3: Robust schedule s0 = (x0 = 0, x1 = 3) Example 8.1 greater neighboursk 1.012X043SlackT02X10(a) Solution space.123T1456(b) Schedule marked solution.Figure 4: Robust schedule s1 = (x0 = 0, x1 = 4) Example 8.1 greater neighboursk > 1.012X043T02X10(a) Solution space.1SlackT123456(b) Schedule marked solution.Figure 5: Robust schedule s2 = (x0 = 0, x1 = 2) Example 8.1 greater neighboursk > 1.64fiROBUSTNESS TABILITY C ONSTRAINT P ROGRAMMING DYNAMISM U NCERTAINTYinstance, let pi starting time task xi . Thus, would add constraint pi = pi + si ,si represents slack associated task xi . addition, depending maximum desiredduration buffers, another constraint may added, si k. case, delayk timePunits. addition, objective function express goal maximizing totalslack (max ni=1 si ) must defined.Furthermore, proactive specific approaches scheduling problems involveCSP found Herroelen Leus (2005) survey. main advantage approachpresented paper proactive alternatives scheduling problems approachapplied slack-values require consistency check. requirement necessaryscheduling problems intermediate non-valid slack values possible. Examples typeproblem scheduling problems limited machine availability (see, instance Schmidt,2000). cases, machines unavailable certain time intervals; reason, tasksrequire resources cannot executed time units. happensscheduling operators, workers breaks day. Moreover,also exist reactive approaches, re-schedule activities disruption invalidatesoriginal schedule found. example, solving dynamic Resource-Constrained Project SchedulingProblems (RCPSP) (Elkhyari, Gueret, & Jussien, 2004).9. Experimental Resultssection, present results experiments designed evaluate performance Algorithm 1. Solutions obtained restarting-completion procedure referred neighboursolutions graphs tables throughout section. Solutions obtained restarting-scratchreferred neighbour solutions(R). Experiments done random problemsbenchmarks presented literature. random instances generator (RBGenerator 2.0),benchmarks parser XCSP instances found Christophe Lecoutres webpage 1 .addition assessing search Algorithm 1, also evaluated two proactive methodsrequire specific additional information dynamism. One WCSPmodeling technique (Climent et al., 2013), based dynamism assumptionspresent work. solutions obtained technique referred WCSP-modsolutions. evaluated approach scheduling problemsconsider adaptation scheduling problems presented Section 8.2 (neighbouring values lower magnitude considered). proactive approachmaximizes (1, 0)-repairability (see Section 3.2). implement technique, modified Algorithm 1 (B&B-Nk ) exchanging MGAC3-Nk GAC3-Nk algorithms MAC+GAC+ (Hebrard, 2006), respectively. solutions obtained technique referred(1, 0)-super-solutions. addition, solutions ordinary CSP solver analyzed (referred simple solutions), order detect whether cases solutionssimilar robustness and/or stability.addition, added geometric restart (restarting-completion) bounds consistency techniques explained Section 7 ordinary CSP solver super-solutions solver orderprovide computational advantages. approach models CSPs WCSP,1. http://www.cril.univ-artois.fr/ lecoutre/index.html65fiC LIMENT, WALLACE , ALIDO & BARBERused solver one used Climent et al. (2013): ToulBar22 . necessaryuse different solver evaluation technique approach requires WCSPsolver. approaches evaluated, values selected lexicographical ordertime cutoff fixed 100 seconds. Experiments run Intel Core i5-650 Processor (3.20Ghz). addition, geometric restart, scale factor fixed 10 multiplicativefactor 1.5.evaluation based two main features solutions obtained proactive approaches:stability robustness. tables section, best robustness/stability results obtainedmarked bold. accordance assumptions laid previous sections, userobustness stability measures described Section 4. Here, note ordinary CSPsolver super-solutions solver consider dynamism assumptions WCSPmodeling technique approach presented paper. say, considerpossible future restrictive modifications bounds solution space CSPs ordereddomains. Regarding stability, technique maximizes (1, 0)-repairability searchesstable solutions according Definition 3.1. However, mentioned above, paper analyzeprecise concept stability CSPs ordered domains, (1, 0, c)-repairability (seeDefinition 4.3).9.1 Robustness Analysis General CSPssection analyze robustness stability solutions obtained wide rangetightness values. purpose, random CSPs generated RBGenerator 2.0,non-convex constraints represented extensionally. non-convexity domains, bounds consistency technique cannot used. CSPs generated 25 variablesdomain size 30 200 binary constraints. Domain values integer values interval[0, 29]. tightness values analyzed 0.1, 0.2, 0.3. (Note: 0.34 critical valuetightness CSP typology.) tightness generated 10 random instancessolved Algorithm 1 k = 1. analysis deal general case CSPsordered domains (see Section 5.1) fixed set operators search algorithm= {{>, +}, {<, }} value selection heuristic 2 (see Section 7), maximizes|Nk (x, v, s, )| starting intermediate values.mentioned previously, usually feasible compute complete set solutionsCSP. reason, order measure robustness solutions obtained fourapproaches, sampled closest surrounding neighbours (k = 1). Thus, closest surrounding neighbour solution CSP, means analyzed solution could becomeinfeasible change magnitude one greater original bound/s invalidateneighbour. hand, neighbour solution CSP, means restrictive modification would invalidate analyzed solution. Therefore, satisfiability checkingrandom sample neighbours solutions provides estimation likelihoodsolutions remain valid, say, estimation robustness.sampling feasibility neighbourhood solutions, made certain numberrandom modifications magnitude k values assigned variables solutions.number values assigned variables solutions modified, denotednbV arM od [1 . . . 10]. value nbV arM od, sampled 500 neighbours2. http://carlit.toulouse.inra.fr/cgi-bin/awki.cgi/ToolBarIntro66fiROBUSTNESS TABILITY C ONSTRAINT P ROGRAMMING DYNAMISM U NCERTAINTYsolution analyzed checked feasibility. average number feasible neighbourstype solution shown Table 9.1. observed Algorithm 1 either restartingoption dramatically outperformed ordinary CSP solver technique maximizes(1, 0)-repairability. also outperformed WCSP modeling approach tightness 0.2 0.3.weakness latter approach obtains robustness approximations problemshigh relation constraints, computes feasible neighboursconstraint boundary. Thus, higher tightness, higher likelihood existenceneighbour tuples feasible one constraint/domain another one.conflicting situations less frequent unconstrained instances. reason, tightness0.1 performance modeling approach better. However, obtains better robustnessresults Algorithm 1 highly unrestricted instances high nbV arM od values. regardAlgorithm 1, restarting-completion option provides better results restarting-scratch(differentiated R) unconstrained instances, preform similarly highertightness values. Figure 6(b) selected nbV arM od = 2 emphasize trends robustnessstability function varying tightness.tightness0.10.2nbV arM od2ApproachAverage Number feasible neighbours samplesimplesuperWCSP-mneighneigh(R)7.28.8152.4206.8191.640.60.660.27574.460024.527.424.480012.810.87.910005.83.82.920.215.736.233.90.34000.12.52600000.581024600000.10000000.40.42.82.5000.10.1000000Table 1: Robustness Analysis Based tightness (< 2, 25, 30, 200, tightness >).stability measurement, (1, 0, 1)-repairability used (see Definition 4.3), measures number variables replaced value located distance onevalue assigned without modifying rest values solution. Stability results shownFigure 6(a). mentioned, solution value lost, objective find closest repairablevalues. reason, algorithm consider feasible values k units greatersmaller value assigned, since could result future solutions Manhattandistance new solution original one would exaggeratedly great (see Section4). hand, technique maximizes (1, 0)-repairability considers valuerepairable value. fact represents disadvantage searching repairable valuesordered domains. observed Figure 6(a), see poor performancesuper-solutions (1, 0, 1)-repairability.would like note CSPs highly restricted, stability robustnesssolutions obtained evaluated methods similar. due factcases CSPs solutions consequently distances solutionsbounds low. instances, number solutions lowsolutions scattered within tuple-space, likelihood solution locatedbounds solution space high. reason, likelihood variable67fiC LIMENT, WALLACE , ALIDO & BARBER25neighbours solutionneighbours (R) solutionsimple solution(1,0)-super-solutionWCSP-mod solution(1, 0, 1)-repairability201510500.10.2Tightness0.3Average sampling number neighbour solutions(a) Stability analysisneighbours solutionneighbours (R) solutionsimple solution(1,0)-super-solutionWCSP-mod solution2001501005000.10.2Tightness0.3(b) Robustness analysis nbV arM od = 2Figure 6: Combined robustness-stability based tightness (< 2, 25, 30, 200, tightness >).curves shifted improving clarity graph.68fiROBUSTNESS TABILITY C ONSTRAINT P ROGRAMMING DYNAMISM U NCERTAINTYfeasible repairable value near-by low. even case none solutionsassignment feasible neighbours located distance k. case, solutionsequally robust stable k value.9.2 Scheduling Benchmarks Evaluationsection, evaluate approaches scheduling benchmarks literature orderdetermine robustness schedules obtained wide range k values. analyzed fivesets 10 job-shop CSP instances, studied Sadeh Fox (1996). instance composed10 jobs five tasks five resources. job random linear sequenceresources visit, exception bottleneck resources, visited fixednumber operations (in order increase resource contention).analysis deals scheduling problems (see Section 8) fixed setoperators search Algorithm 1 = {{>, +}} value selection done heuristic1, values selected lexicographical order. Regarding proactive techniqueevaluated, author (1, 0)-repairability approach (Hebrard, 2006) made extensionconcept breakage (the loss assigned value) scheduling problems. breakagekind problem considered delay duration task. Therefore, valuesgreater value assigned time units considered repairable values. reason,evaluation scheduling problems, incorporated condition (1, 0)-repairabilityapproach. proper comparison approach approaches, used valuesk parameters. following, order avoid term repetition, assume = k.Note ordinary CSP solver use parameter, obtains schedulevalue k.measuring robustness schedules obtained, used robustness measures introduced Section 8.1. first robustness assessment made measuring total slack whoseduration exceed k, denoted tS(k). addition, accurate measure(k) (see Equation 3), measures average total slack, minus standardalso used, Rslackdeviation multiplied parameter. parameter fixed 0.25, insideinterval authors consider appropriate parameter. Another robustness measure usedbased resistance schedule faced perturbations, denoted RF,Z(see Equation 4), Z set incidents consist delays durations maxd tasks.used 2 different values maxd : 1 k. case, independently simulated 500delays maxd units equal probability entire schedule checked scheduleremained valid. stability measurement, again, (1, 0, 1)-repairability used (see Definition4.3), equivalent measurement number buffers schedule, denotednbB. Note desired objective cases repairs necessary, start timetask delayed short time possible.following figures tables show evaluation two Sadeh problem sets.problem sets obtained similar results. show results e0ddr1 e0ddr2 benchmarks order compare robustness stability schedules obtained different numbersbottlenecks problem (other parameters fixed). Sadeh stated e0ddr1 benchmarkcontained one bottleneck hand, e0ddr2 benchmark contained two bottlenecks.Tables 9.2 9.2 show means robustness stability measures scheduling problems. addition, measurements shown, including number schedules obtained nbS,69fiC LIMENT, WALLACE , ALIDO & BARBERtotal number restarts done search algorithm nbR, total number nodes explored nbNtotal number failures nbF . Figure 7 shows stability robustness measurements(k) e0ddr1. horizontal axis(vertical axis): mean number buffers mean Rslackfigures represents value ratio parameters k.kApproachnbSnbRnbNnbFnbBtS(k)Rslack(k)RF,Z(1)RF,Z(k)1simplesuperneighneigh(R)19.112.715.53.13.13.128.82087770.410171.12820.4853043.72465.9628.116.121.427.831.316.121.427.831.30.2080.3080.4360.5090.3280.4340.5620.6280.3380.430.5550.6183simplesuperneighneigh(R)17.315.915.53.13.13.127.72088138.25880.52406.5852619.22485.1670.516.118.920.922.344.352.459.462.10.5550.7020.8320.8860.3280.3840.4240.4480.3110.360.4090.4135simplesuperneighneigh(R)17.11912.93.13.13.123.82088373.23947.72082.3852654.21674.7517.816.119.119.520.267.882.986.387.30.8321.1011.1591.1820.3280.3880.3960.4060.2880.3430.3640.357simplesuperneighneigh(R)16.519.911.53.13.13.121.22088319.13205.91871.8853219.51032.6489.516.118.118.918.788.1101.8107.8108.61.0571.2981.41.4130.3280.3680.3840.3760.2710.3030.3310.3149simplesuperneighneigh(R)15.720.811.43.13.13.119.72088715.72793.61711.4852620.7974.2462.816.117.618.618.2105.7117.6126.51261.2421.4521.6021.5880.3280.3580.3780.3680.2570.2770.3030.29311simplesuperneighneigh(R)16197.93.13.13.116.92088019.92518.51593.9851775.8844.4435.516.118.218.118.4120.5133.6140.2138.81.3891.6291.721.6930.3280.370.3680.3740.2440.2560.280.277Table 2: Evaluation e0ddr1 benchmark.expected, schedules obtained approaches e0ddr1 benchmarkrobust stable e0ddr2 benchmark (see Tables 9.2 9.2) robustnessanalysis, see algorithm k = 11 (for restarting options) increased robustness(k) 0.5 units problems one bottleneck. Therefore,measure RF,Zexpected, fewer bottlenecks scheduling problem has, robust schedule obtainedalgorithm. Detailed results robustness measures found columns tS(k),(1) Rs (k) tables. instance, largest k value analyzed (k =Rslack(k), RF,ZF,Z11), total sum buffer times duration k schedule obtained Algorithm1 restarting-completion 140.2 time units e0ddr1 benchmark 109.67 time unitse0ddr2 benchmark (more 30 time units difference). Regarding stability analysis,algorithm k = 1 restarting-scratch (differentiated R) found schedules four meannumber buffers (nbB) problems one bottleneck problems two70fiROBUSTNESS TABILITY C ONSTRAINT P ROGRAMMING DYNAMISM U NCERTAINTYkApproachnbSnbRnbNnbFnbBtS(k)Rslack(k)RF,Z(1)RF,Z(k)1simplesuperneighneigh(R)0.96.510.112.443.9425.42278024.3311264.222555.6798.891975.671865.22709.3314.1119.8924.3327.4414.1119.8924.3327.440.170.280.370.430.280.40.490.550.280.410.490.553simplesuperneighneigh(R)0.94.916.411.943.93.922.22278602.677141.782282.6798.891198.671711.33503.8914.1117.3320.2220.1137.5647.225655.220.440.610.770.760.280.350.40.40.250.320.370.375simplesuperneighneigh(R)0.94.417.38.643.93.918.92279102.785755.222036.1198.89743.671657.33452.7814.1117.1118.1117.8955.1170.8976.6773.890.630.890.990.950.280.340.360.360.220.290.310.37simplesuperneighneigh(R)0.93.815.27.743.93.917.52279721.6749031827.4498.89914.221272.56428.7814.1115.7816.8917.2268.2282.2288.7888.670.750.971.091.090.280.320.340.350.20.250.260.269simplesuperneighneigh(R)0.93.115.76.443.93.916.222799714344.441657.5698.89959.561161.78449.2214.1115.5616.7816.7878.6792.89101.11100.440.841.061.21.190.280.310.340.340.180.210.240.2311simplesuperneighneigh(R)0.92.314.75.643.93.914.422710698.224251.781588.8998.891090.441223.5639014.1115.2216.2216.1187.4498.89109.67107.670.911.081.251.220.280.30.320.320.160.190.210.2Table 3: Evaluation e0ddr2 benchmark.71fiC LIMENT, WALLACE , ALIDO & BARBER32neighbours solutionneighbours solution (R)simple solution(1,0)-super-solution30Mean number buffers282624222018161357911k(a) Stability analysis1.8neighbours solutionneighbours solution (R)simple solution(1,0)-super-solution1.6Mean RslackS(k)1.41.210.80.60.40.21357911k(b) Robustness analysisFigure 7: Combined robustness-stability k parameter: mean measures e0ddr1 benchmark.72fiROBUSTNESS TABILITY C ONSTRAINT P ROGRAMMING DYNAMISM U NCERTAINTYbottlenecks best case. Therefore, expected, fewer bottlenecks scheduling problemhas, stable schedule obtained algorithm.tables figure, see Algorithm 1 either restarting option outperformed ordinary CSP solver technique maximizes (1, 0)-repairability.Furthermore, analysis k parameter shows parameters lowest values, number buffers schedules found algorithm markedly greatertwo techniques (see Figure 7(a)). contrast, improvement robustness algorithmrespect ordinary solver little marked greater k values. comparison(1, 0)-repairability technique shows tendency e0ddr2 benchmark (see nbB Table9.2).Regarding robustness measures plotted figure shown(1) measure numberTables 9.2 9.2, see correlation RF,Z(1)buffers. relation expected, since random incidents generated measuring RF,Zdelays one unit time. Therefore, buffers (whatever duration) greaterlikelihood schedule absorb delays one time unit. addition, tS(k), Rslack(k)RF,Z (k) measures correlated. Recall tS(k) total slack whose duration(k) average minus standard deviation multiplied parameter.exceed k RslackTherefore, unless distribution slack poor, two values must proportional.(k), greater proportionality respectNote lower parameter Rslacktwo robustness measures. RF,Z (k) measure calculated generating random delaysduration k schedule. reason, robustness measure strongly relatedtwo aforementioned. example relation aforementioned measurementunits observed Table 9.2 k = 11, schedules obtained restarting-scratch(1) values, schedulesoption (differentiated R) greater numbers buffers RF,Z(k) values.obtained restarting-completion option greater tS(k), Rslack(k) RF,Zmeans latter greater total slack whose duration exceed k, distributionlimited.Tables 9.2 9.2 also observe measurements correlated robustnessstability, important information still extracted them. k > 1, restartingcompletion algorithm finds greater mean number solutions (nbS). k = 1restarting-scratch (differentiated R) find solutions. greater k is, easierfind new solutions whose objective function better maximum one (if instancehighly restricted). reason, mean number solutions found greater highk values. restarting options, mean number solutions considerably higherapproach maximizes (1, 0)-repairability. effect stronger greater valuesk condition repairable value latter technique becomes restrictive.Moreover, technique considers feasible values domains repairable values; result,feasibility checking slower techniques assume k neighbours (as techniquedoes). expected, mean number restarts (nbR) much greater restarting-scratchoption techniques restart finding first solution. consequence,mean number nodes explored (nbN ) mean number failures (nbF ) lower.schedules obtained Algorithm 1 lowest k value highest number buffers.hand, robustness measures greater greater k values. Dependingdynamic nature problem, would desirable prioritize higher numberbuffers short duration lower number buffers long duration (if two features cannot73fiC LIMENT, WALLACE , ALIDO & BARBERmaximized). Thus, known possible future delays durationleast time units, make sense compute k values lower obtainedtime buffers could absorb delay. hand, known possible future delayscannot duration greater d, make sense compute k values greatertime units may decrease number buffers. Hence, informationpossible future changes have, better robustness results obtain. However, eveninformation unknown, obtain schedule certain level robustnessstability setting k intermediate value Algorithm 1.34neighbours solutionneighbours solution (R)simple solution(1,0)-super-solution32Mean number buffers3028262422201816102030405060Time(s)708090100708090100(a) k = 134neighbours solutionneighbours solution (R)simple solution(1,0)-super-solution32Mean number buffers3028262422201816102030405060Time(s)(b) k = 7Figure 8: Mean number buffers time intervals e0ddr1 benchmark.evaluation consists analyzing best results obtained techniquefixed cutoff time. However, also wanted analyze change degree robustnessstability schedules found time. evaluation, used e0ddr1 benchmarkdetermined mean 50 instances interval time discretization 1074fiROBUSTNESS TABILITY C ONSTRAINT P ROGRAMMING DYNAMISM U NCERTAINTYseconds. Figures 8(a) 8(b) show mean number buffers found approach k = 1k = 7. measures shown since similar trends found cases. wouldlike highlight 20 seconds simple solution technique find better schedulessearches one schedule instance (which done less equal 20seconds). remarkable aspect k = 1 Algorithm 1 restarting optionsobtains greater number buffer times approach maximizes (1, 0)-repairability,k = 1 time intervals (see Figure 8(a)).hand, Figure 8(b), represents k = 7, shows unstable results. Sincedifficult find buffers seven time units, may happen algorithm sacrificesshorter buffers order find one buffer seven time units. Thus, even overall tendencymeasure increase time, entirely uniform. hand,upward shape trend approach searches super-solutions due factconsiders values repairable possible alternative start time taskfollows task sharing resource, equivalent slack associatedtask schedule. reason, schedules better technique may contain lowernumber buffers. feature marked greater values k, since repairable valuesleast k unit times greater assigned values, therefore unlikelyfind repairable values close assigned ones.concluded general approach maximizes (1, 0)-repairability findssolutions lower robustness stability (considering closest repairable values)approach aforementioned reason. Another disadvantage assumes delaysduration d. Thus, values greater value considered repairable values.However, consider k neighbours therefore, slacks duration lower k alsovalued objective function contrast (1, 0)-repairability objective function.basis evaluation, conclude difference performancetwo restarting options (restarting-completion restarting-scratch) significant. Sometimes, time needed restart scratch solution makes option less effectiverestarting-completion. cases, restarting-completion option loses time branchesbetter solutions, restarting-scratch explores branches. instance,random experiments, restarting-completion provided slightly better results generally (see Table 9.1 Figure 6(b)), scheduling problems, restarting-scratch obtained schedulesbit robust stable lower k values (see k [1, 5] Figure 7). greater kvalues, restarting options gave similar results.10. Conclusionspaper extend concept robustness stability CSPs discrete ordereddomains limited assumptions made changes problems. particular, uncertainty statistics probabilities incidences occuroriginal problem. context, reasonable assume original bounds solutionspace may undergo restrictive modifications, introduced Climent et al. (2013). Therefore, main objective searching robust solutions find solutions maximizeEuclidean distances dynamic bounds solution space. hand, mainobjective searching stable solutions terms repairable variables find solutions whoserepairable values close possible broken assignments.75fiC LIMENT, WALLACE , ALIDO & BARBERpaper, present new search algorithm combines criteria robustnessstability framework. algorithm developed paper searches solutionmaximizes sum contiguous feasible surrounding neighbours distances k lessvalues solution. obtained solutions high probability remaining validpossible future restrictive changes constraints domains original problem(robustness criterion), also high number variables easily repairedvalue distance lower equal k undergo value loss (stability criterion).evaluated new algorithm experiments well-known scheduling benchmarkswell random CSPs. shown versions new algorithm outperformthree approaches evaluated: ordinary CSP solvers, technique maximizes(1, 0)-repairability, approach models CSPs WCSPs many conditionsreal differences robustness solutions might obtained. latter occursproblem constrained valid solutions. respecttwo restarting options developed algorithm, found performancesignificantly different, although certain situations advantage one other.slightly constrained CSPs, algorithm obtains solutions greatest number closerneighbour solutions, greatest (1, 0, 1)-repairability highest values specific measuresscheduling robustness. Furthermore, shown increasing k large problems,also increase robustness, although may happen (1, 0, 1)-repairability decreases.instance, scheduling problems schedules obtained lower k values tend maximizenumber buffers even size small. However, computation higher k values tendsgive priority duration buffers consequence, number buffers obtainedlower. Therefore, depending dynamic nature problem, would desirableprioritize higher number short buffers lower number long buffers (ifpossible maximize features).extension robustness stability definition CSPs discrete ordereddomains development search algorithm finding robust stable solutionscontext, useful practical many real life situations problems undergo restrictivechanges added difficulty information possible future changes limitednon-existent. Even difficult conditions, search algorithm able provide stablerobust solutions. Finding solutions located far away dynamic bounds importantface restrictive modifications bounds solution space. Moreover, casesvalue lost, important replace nearby value order solutionsimilar possible original one. closeness feature handled algorithmapproach searches super-solutions.Acknowledgmentswork partially supported research project TIN2010-20976-C02-01 FPUprogram fellowship (Min. de Ciencia e Innovacion, Spain). wish thank Dr. ChristopheLecoutre Dr. Diarmuid Grimes assistance.76fiROBUSTNESS TABILITY C ONSTRAINT P ROGRAMMING DYNAMISM U NCERTAINTYReferencesBessiere, C. (2006). Constraint propagation. Foundations Artificial Intelligence, 2, 2983.Boussemart, F., Hemery, F., Lecoutre, C., & Sais, L. (2004). Boosting systematic search weighting constraints. Proceedings 16th European Conference Artificial Intelligence(ECAI-04), Vol. 16, p. 146.Climent, L., Wallace, R. J., Salido, M. A., & Barber, F. (2013). Modeling robustness CSPsweighted CSPs. Proceedings 10th International Conference Integration Artificial Intelligence Operations Research techniques Constraint Programming (CPAIOR13), pp. 4460.Elkhyari, A., Gueret, C., & Jussien, N. (2004). Constraint programming dynamic schedulingproblems. Hiroshi Kise, editor, ISS04 International Scheduling Symposium, pp. 8489.Escamilla, J., Rodriguez-Molins, M., Salido, M., Sierra, M., Menca, C., & Barber, F. (2012). Robust solutions job-shop scheduling problems operators. 24th IEEE InternationalConference Tools Artificial Intelligence (ICTAI-12), pp. 209306.Fargier, H., & Lang, J. (1993). Uncertainty Constraint Satisfaction Problems: probabilistic approach. Proceedings Symbolic Quantitative Approaches Reasoning Uncertainty (EC-SQARU-93), pp. 97104.Fargier, H., Lang, J., & Schiex, T. (1996). Mixed Constraint Satisfaction: framework decisionproblems incomplete knowledge. Proceedings 13th National ConferenceArtificial Intelligence (AAAI-96), pp. 175180.Fowler, D., & Brown, K. (2000). Branching Constraint Satisfaction Problems solutions robustlikely changes. Proceedings International Conference PrinciplesPractice Constraint Programming (CP-2000), pp. 500504.Fu, N., Lau, H., Varakantham, P., & Xiao, F. (2012). Robust local search solving RCPSP/maxdurational uncertainty. Journal Artificial Intelligence Research, 43, 4386.Hebrard, E. (2006). Robust Solutions Constraint Satisfaction Optimisation Uncertainty. Ph.D. thesis, University New South Wales.Hebrard, E., OSullivan, B., & Walsh, T. (2007). Distance constraints Constraint Satisfaction.Proceedings 20th International Joint Conference Artificial Intelligence (IJCAI-07),pp. 106111.Herroelen, W., & Leus, R. (2005). Project scheduling uncertainty: Survey research potentials. European Journal Operational Research, 165(2), 289306.Kitano, H. (2007). Towards theory biological robustness. Molecular Systems Biology, 3(1).Larrosa, J., & Schiex, T. (2004). Solving weighted CSP maintaining arc consistency. ArtificialIntelligence, 159, 126.Leon, V., Wu, S., & Robert, H. (1994). Robustness measures robust scheduling job shops.IIE transactions, 26(5), 3243.Lhomme, O. (1993). Consistency techniques numeric CSPs. Proceedings 13th International Joint Conference Artificial Intelligence (IJCAI-93), Vol. 13, pp. 232232.77fiC LIMENT, WALLACE , ALIDO & BARBERMackworth, A. (1977a). Consistency network relations. Artificial Intelligence, 8, 99118.Mackworth, A. (1977b). reading sketch maps. Proceedings 5th International JointConference Artificial Intelligence (IJCAI-77), pp. 598606.Mohr, R., & Henderson, T. C. (1986). Arc path consistency revisited. Artificial intelligence,28(2), 225233.Rossi, F., Venable, K., & Yorke-Smith, N. (2006). Uncertainty soft temporal constraint problems:general framework controllability algorithms fuzzy case. Journal ArtificialIntelligence Research, 27(1), 617674.Sadeh, N., & Fox, M. (1996). Variable value ordering heuristics job shop schedulingConstraint Satisfaction Problem. Artificial Intelligence, 86(1), 141.Schmidt, G. (2000). Scheduling limited machine availability. European Journal OperationalResearch, 121(1), 115.Surico, M., Kaymak, U., Naso, D., & Dekker, R. (2008). Hybrid meta-heuristics robustscheduling. ERIM Report Series Reference No. ERS-2006-018-LIS, Available SSRN:http://ssrn.com/abstract=902747.Verfaillie, G., & Jussien, N. (2005). Constraint solving uncertain dynamic environments:survey. Constraints, 10(3), 253281.Wallace, R., & Freuder, E. (1998). Stable solutions Dynamic Constraint Satisfaction Problems.Proceedings 4th International Conference Principles Practice Constraint Programming (CP-98), pp. 447461.Walsh, T. (1999). Search small world. Proceedings International Joint ConferenceArtificial Intelligence, Vol. 16, pp. 11721177.Walsh, T. (2002). Stochastic Constraint Programming. Proceedings 15th European Conference Artificial Intelligence (ECAI-02), pp. 111115.Yorke-Smith, N., & Gervet, C. (2009). Certainty closure: Reliable constraint reasoning incomplete erroneous data. Journal ACM Transactions Computational Logic (TOCL),10(1), 3.78fi