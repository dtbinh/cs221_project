Journal Articial Intelligence Research 12 (2000) 105-147

Submitted 10/99; published 3/00

Robust Agent Teams via Socially-Attentive Monitoring

Gal A. Kaminka
Milind Tambe

galk@isi.edu
tambe@isi.edu

Information Sciences Institute Computer Science Department
University Southern California
4676 Admiralty Way
Los Angeles, CA 90292, USA

Abstract
Agents dynamic multi-agent environments must monitor peers execute individual group plans. key open question much monitoring agents'
states required eective: Monitoring Selectivity Problem. investigate
question context detecting failures teams cooperating agents, via SociallyAttentive Monitoring, focuses monitoring failures social relationships
agents. empirically analytically explore family socially-attentive
teamwork monitoring algorithms two dynamic, complex, multi-agent domains,
varying conditions task distribution uncertainty. show centralized scheme
using complex algorithm trades correctness completeness requires monitoring
teammates. contrast, simple distributed teamwork monitoring algorithm results
correct complete detection teamwork failures, despite relying limited, uncertain
knowledge, monitoring key agents team. addition, report design
socially-attentive monitoring system demonstrate generality monitoring several coordination relationships, diagnosing detected failures, on-line o-line
applications.

1. Introduction
Agents complex, dynamic, multi-agent environments must able detect, diagnose,
recover failures run-time (Toyama & Hager, 1997).

instance, robot's

grip may slippery, opponents' behavior may intentionally dicult predict, communications may fail, etc. Examples environments include virtual environments
training (Johnson & Rickel, 1997; Calder, Smith, Courtemanche, Mar, & Ceranowicz, 1993),
high-delity distributed simulations (Tambe, Johnson, Jones, Koss, Laird, Rosenbloom, &
Schwamb, 1995; Kitano, Tambe, Stone, Veloso, Coradeschi, Osawa, Matsubara, Noda, &
Asada, 1997), multi-agent robotics (Parker, 1993; Balch, 1998). rst key step
process execution-monitoring (Doyle, Atkinson, & Doshi, 1986; Ambros-Ingerson &
Steel, 1988; Cohen, Amant, & Hart, 1992; Reece & Tate, 1994; Atkins, Durfee, & Shin,
1997; Veloso, Pollack, & Cox, 1998).
Monitoring execution multi-agent settings requires agent monitor peers,
since correct execution depends also state peers (Cohen & Levesque,
1991; Jennings, 1993; Parker, 1993; Jennings, 1995; Grosz & Kraus, 1996; Tambe, 1997).
Monitoring peers particular importance teams, since team-members rely
work closely together related tasks:

c 2000 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiKaminka Tambe

Monitoring allows team-members coordinate actions plans team-

mates, help teammates cooperate without interference. example, drivers
cars convoy cannot drive without monitoring cars convoy,
disband convoy, help drivers cars break down.
Monitoring allows team-members use peers dynamic information sources,

learning new information. instance, driver convoy sees cars
front suddenly turn left, infer existence obstacle
milestone despite directly seeing herself.
Previous work investigated dierent ways monitoring context teams cooperating agents. example, theoretical work SharedPlans (Grosz & Kraus, 1999)

passive monitoring, agent notied proposition
changes (e.g., via communications), active monitoring, agent actively seeks
distinguished

nd proposition changes (e.g., via observations inference unobservable
attributes). Practical implementations investigated use passive monitoring via
communications (Jennings, 1995), active monitoring via plan-recognition (Huber & Durfee, 1995), active implicit monitoring via environment (Fenster, Kraus, & Rosenschein,
1995), dierent combinations methods (Parker, 1993; Jennings, 1993; Tambe,
1997; Lesh, Rich, & Sidner, 1999).

approach clearly superior another:

Passive

monitoring generally perceived less costly active monitoring, also less
reliable (Grosz & Kraus, 1999; Huber & Durfee, 1995; Kaminka & Tambe, 1998).
Regardless monitoring method, bandwidth computational limitations prohibit
monitoring agent monitoring agents full extent, time (Jennings,
1995; Durfee, 1995; Grosz & Kraus, 1996). Thus key open question much monitoring agents required eective (in teams) (Jennings, 1993; Grosz & Kraus,
1996, 1999). call challenging problem

Monitoring Selectivity Problem,

i.e.,

problem selectivity observing others inferring state (based observations) monitoring.

Although raised past, framework

minimal constraints answers provided (Jennings, 1993; Grosz & Kraus, 1996).
instance, theory SharedPlans requires agents verify intentions
conict teammates (Grosz & Kraus, 1996). However, methods
verication take place left investigation (Grosz & Kraus, 1996, p.
308). Section 8 provides details related work.
paper begins address monitoring selectivity problem teams, investigating monitoring requirements eective failure detection.

focus investigation

detecting failures social relationships ideally hold agents monitored team. call monitoring social relationships

socially-attentive monitoring,

dierentiate types monitoring, monitoring failures
progress agents towards goals. Here, term social relationship used denote
relation attributes multiple agents' states. Socially-attentive monitoring convoy
example involves verifying agents common destination heading,
beliefs driving convoy mutual, etc. instance, agents observed
head dierent directions, clearly common heading. dierent
monitoring whether chosen (common) heading leads towards (agreed upon)
destination.

106

fiRobust Agent Teams via Socially-Attentive Monitoring

Monitoring relationships team (socially-attentive monitoring) critical task
monitoring team-members.

Failures maintain team's relationships often lead

catastrophic failures part team, lack cooperative behavior lack
coordination. failures often result individual agent failures, failures
agent's sensors actuators. Thus socially-attentive monitoring covers large class
failures, promotes robust individual operation.
explore socially-attentive monitoring algorithms detecting teamwork failures various conditions uncertainty.

analytically show despite presence

uncertainty actual state monitored agents, centralized

active

monitoring

scheme guarantee failure detection either sound incomplete, complete
unsound. However, requires reasoning multiple hypotheses actual
state monitored agents, monitoring agents team.

show active

distributed teamwork monitoring results sound complete detection capabilities,
despite using much simpler algorithm. distributed algorithm: (a) uses single,
possibly incorrect hypothesis actual state monitored agents, (b) involves monitoring key agents team, necessarily team-members. Using transformation
analytical constructs, show analogous results centralized failure-detection
mutual-exclusion coordination relationships.
also conduct empirical investigation socially-attentive monitoring teams.
present implemented general socially-attentive monitoring framework
expected ideal social relationships maintained agents compared
actual social relationships. Discrepancies detected possible failures diagnosed. apply framework two dierent complex, dynamic, multi-agent domains,
service monitoring various social relationships, on-line o-line.
domains involve multiple interacting agents collaborative adversarial settings,
uncertainties perception action.

one domain, provide empirical results

active monitoring conrm analytical results. another domain show
o-line socially-attentive monitoring provide quantitative teamwork quality feedback
designer. also provide initial diagnosis procedures detected failures.
focus explorations practical algorithms guarantees performance real-world applications. algorithms present seek complement use
passive communications-based monitoring (which unreliable many domains) explore
use unintrusive key-hole plan-recognition alternative. However, rule
use communicationswe simply seek provide techniques work even
communications fail.

analytical guarantees failure-detection soundness

completeness hold whether monitoring done communications plan-recognition.
paper organized follows: Section 2 presents motivating examples background. Section 3 presents socially-attentive monitoring framework. Section 4 explores
monitoring selectivity centralized teamwork monitoring.

Section 5 explores monitoring

selectivity distributed teamwork monitoring. Section 6 demonstrates generality
framework applying o-line conguration. Section 7 presents investigations additional relationship models. Section 8 presents related work, Section 9 concludes.
two appendices contain proofs theorems presented (Appendix A), pseudo-code
socially-attentive monitoring algorithms (Appendix B).

107

fiKaminka Tambe

2. Motivation Background
monitoring selectivity problem paper addresseshow much monitoring required
failure-detection teamsrose growing frustration signicant software
maintenance eorts two application domains.

ModSAF domain, high-

delity battleeld virtual environment (Calder et al., 1993), involved
development synthetic helicopter pilots (Tambe et al., 1995).

RoboCup soccer

simulation domain (Kitano et al., 1997) involved developing synthetic soccer players (Marsella, Adibi, Al-Onaizan, Kaminka, Muslea, Tallis, & Tambe, 1999).
environments domains dynamic complex, many uncertainties:
behavior agents (some adversarial, cooperative), unreliable communications sensors, actions may execute intended, etc.

Agents

environments therefore presented countless opportunities failure despite
designers' best eorts.
examples may serve illustrate. following two examples actual failures
occurred ModSAF domain.

use two illustrate explore

socially-attentive monitoring throughout paper:

Example 1.

Here, team three helicopter pilot agents specied way-

point (a given position), one team-members,

attackers )

towards enemy, teammates (

scout,

forward

land wait signal.

agents monitored way-point. However, due unexpected sensor failure, one
attackers failed sense way-point.

attacker correctly landed,

failing attacker continued forward scout (see Figure 1 screen shot
illustrating failure).

Example 2.

dierent run, three agents reached way-point detected it,

scout gone forward identied enemy. sent message waiting
attackers join attack enemy. One attackers receive message,
remained behind indenitely scout attacker continued
mission alone.
collected dozens similar reports ModSAF RoboCup domain.
general, failures dicult anticipate design time, due huge number
possible states. agents therefore easily nd novel states
foreseen developer, monitoring conditions communications place
proved insucient: none failure cases reported agents involved detect, let
alone correct, erroneous behavior. agent believed agents acting
coordination it, since communication received agents indicate
otherwise. However, agents violating collaboration relationships them,
agents came disagree plan executeda collaboration relationship
failure occurred.

Preliminary empirical results show upwards 30% failures

reported involved relationship violations (relationship failures).
Human observers, however, typically quick notice failures,
clear social misbehavior agents cases. able infer failure
occurred despite knowing exactly happened. instance, seeing attacker
continuing ahead despite teammates' switching dierent plan (which human

108

fiRobust Agent Teams via Socially-Attentive Monitoring

Enemy

Scout (ahead) failing attacker (trailing)

Landing attacker

Figure 1: plan-view display (the ModSAF domain) illustrating failure Example 1.
thick wavy lines contour lines.

observers inferred fact one teammates, attacker, landed)
sucient observer detect something gone amisswithout knowing
dierent plan was.
analysis showed agents monitoring suciently. However, naive solution continuous communications agents clearly impractical since: (i) agents operating hostile environment; (ii) communications
overheads would prohibitive; (iii) fact, communications equipment broke cases. therefore sought practical ways achieve
quick detection failure, based limited ambiguous knowledge available
monitoring agent.

3. Socially-Attentive Monitoring
begin overview general structure socially-attentive monitoring system, shown Figure 2. consists of: (1) social relationship knowledge-base containing
models relationships hold among monitored agents, enabling generation

expected ideal behavior

terms relationships (Section 3.1); (2) agent

team modeling component, responsible collecting representing knowledge
monitored agents'

actual behavior

(Section 3.2); (3) relationship failure-detection compo-

nent monitors violations relationships among monitored agents contrasting
expected actual behavior (Section 3.3); (4) relationship diagnosis component
veries failures, provides explanation (Section 3.4). resulting

109

fiKaminka Tambe

explanation (diagnosis) used recovery, e.g., negotiations system (Kraus,
Sycara, & Evenchik, 1998), general (re)planner (Ambros-Ingerson & Steel, 1988).

Expected
Attribute
Values

agents monitor,
agent attributes

Social Relationships Knowledge-Base
Expected Behavior
Relationship
Diagnosis

Relationship
Failure
Detections

Detected
Failure

Observations,
Communications

Actual
Behavior

Actual Values

Monitored Agent

Agent/Team Modeling Component

Diagnosis

Socially-Attentive Monitoring System

Monitored Agent

Figure 2: general structure socially-attentive monitoring system.

3.1 Knowledge-Base Relationship Models
take relationship among agents relation state attributes. relationship
model thus species dierent attributes agent's state related
agents multi-agent system. attributes include beliefs held
agents, goals, plans, actions, etc. example, many teamwork relationship models
require team-members mutual belief joint goal (Cohen & Levesque, 1991;
Jennings, 1995).

spatial formation relationship (Parker, 1993; Balch, 1998) species

relative distances, velocities maintained group agents (in
domain, helicopter pilots).

Coordination relationships may specify temporal relationships

hold among actions two agents, e.g., business contractors (Malone &
Crowston, 1991).

relationships

social

explicitly specify multiple

agents act believe maintain relationships
them.
relationship knowledge-base contains models relationships supposed
hold system, species agents participating relationships.
knowledge-base guides agent-modeling component selecting agents monitored,
attributes state need represented (for detection diagnosis).
used failure detection component generate expectations contrasted
actual relationships maintained agents. provides diagnosis component
detailed information agents' states' attributes related, drive diagnosis
process.

implementation socially-attentive monitoring teams uses four types

relationships:


formations, role-similarity, mutual exclusion, teamwork.

teamwork

monitoring



use



STEAM

(Tambe,

1997)

general

domain-

independent model teamwork, based Cohen Levesque's Joint Intentions
Framework (Levesque, Cohen, & Nunes, 1990; Cohen & Levesque, 1991) Grosz, Sidner,
Kraus's SharedPlans (Grosz & Sidner, 1990; Grosz & Kraus, 1996, 1999).

110

However,

fiRobust Agent Teams via Socially-Attentive Monitoring

teamwork models may used instead STEAM. Although STEAM used
pilot soccer agents generate collaborative behavior, reused independently
service monitoring, i.e., monitored agents assumed team, STEAM
used monitoring teamwork. STEAM teamwork models (e.g.,

Cohen &

Levesque, 1991; Jennings, 1995; Rich & Sidner, 1997) require mutual belief team members joint goals plans. characteristic used monitor teamwork
system. relationship models used secondary monitoring role.
discussed greater length Section 7.

3.2 Knowledge Monitored Agents Team
agent modeling component responsible acquiring maintaining knowledge

actual relations exist
ideal expected relations.

monitored agents. knowledge used construct
agents' states' attributes, compared

section, describe plan-recognition capabilities agent-modeling component
implementation experiments, i.e., extent knowledge could maintained
monitored agents' plans necessary. Later sections show fact limited, possibly
inaccurate, knowledge sucient eective failure detection. Thus implementations may
use optimized agent-modeling algorithms rather full capabilities. Section 3.4
discuss additional agent-modeling capabilities, necessary diagnosis.

3.2.1 Representation

monitoring teamwork relationships, found representing agents terms
selected hierarchical reactive plans enables quick monitoring state, also
facilitates inference monitored agents' beliefs, goals, unobservable actions,
since capture agents' decision processes.
representation, reactive plans (Firby, 1987; Newell, 1990) form single decomposition hierarchy (a tree) represents alternative controlling processes agent.
reactive plan hierarchy (hereafter referred simply plan) selection
conditions (also referred preconditions) applicable, termination conditions used terminate suspend plans. given moment, agent
executing single path (root leaf ) hierarchy.

path composed

plans dierent levels.
Figure 3 presents small portion hierarchy, created ModSAF domain.
case Example 1, prior way-point,

agents

executing path be-

execute-mission highest-level plan, fly-flight-plan, fly-route,
traveling low-level. Upon reaching way-point, supposed switch
fly-flight-plan descendents wait-at-point. attackers would
select just-wait child wait-at-point, scout would select scout-forward
ginning

descendents. course, failing attacker detect way-point

fly-flight-plan selection conditions wait-at-point
failing attacker continued execute fly-flight-plan

termination conditions
satised
descendents.

111

fiKaminka Tambe

Execute-Mission
Fly Flight Plan (F)
Fly Route

Wait Point (W)

Join Scout (J)

Ordered Halt (H)

Low Level

Wait

Scout Forward
Traveling

Nap Earth

Contour

Figure 3: Portion Hierarchical Reactive Plan Library ModSAF Domain (Team plans
boxed. explained Section 3.3).

3.2.2 Acquisition

practical perspective, agents may cooperatively report monitoring
agent state using communications, requires communication channels
suciently fast, reliable secure.

unfortunately possible many realistic

domains, examples demonstrate (Section 2).
Alternatively, monitor may use plan-recognition infer agents' unobservable state
observable behavior. approach unintrusive robust face communication failures. course, monitor may still benet focused communications
agents, would critically dependent them.
enable plan-recognition using reactive plans (our chosen representation),
employed reactive plan-recognition algorithm called RESL (REal-time Situated Leastcommitments). key capability required allow explicit maintenance hierarchical
plan hypotheses matching agent's observed behavior, pruning hypotheses
deemed incorrect useless monitoring purposes.

RESL works expanding

entire plan-library hierarchy modeled agent, tagging paths matching
observed behavior agent modeled (see Appendix B pseudo-code
algorithm). Heuristics external knowledge may used eliminate paths (hypotheses)
deemed inappropriateindeed heuristics explored shortly. RESL's
basic approach similar previous work reactive plan recognition (Rao, 1994)
team-tracking (Tambe, 1996), used successfully ModSAF domain,
share many RESL's properties.

However, RESL adds belief-inference capabilities

used diagnosis process, discussed (Section 3.4).
Figure 4 gives simplied presentation plan hierarchies variation Example
1, agents correctly detected way-point, i.e., failure occurred (note
plans intermediate levels abstracted gure). scout
(Figure 4a) two attackers (Figures 4b, 4c) switched
(denoted

fly-flight-plan plan

F) wait-at-point plan (denoted W). outside observer using RESL

infers explanations agent's behavior observing agents. scout continues

112

fiRobust Agent Teams via Socially-Attentive Monitoring

low-level, one possible ight-methods
wait-at-point (W) plans. Thus

ahead, speed altitude matching


fly-flight-plan (F)



tagged possible hypotheses scout's executing plan hierarchy.

Similarly,

just-wait
ordered-halt (H)

attackers land, RESL recognizes executing
plan used service either

W



plan.

plana plan

helicopters ordered headquarters land immediately.

H



W

Thus

tagged explanations attackers' states (at second level

hierarchies). agents, RESL identies plan
plan.

However,

execute-mission

top-level

illustration, actual executing paths agents marked lled

arrows.

individual modeling

hypotheses match observed behavior marked

using dashed arrows. outside observer, course, way knowing
possible hypotheses correct.

Execute Mission

Wait-at-Point (W)

Execute Mission

Execute Mission

Fly-Flight-Plan (F)

Wait-at-Point (W)

Ordered-Halt (H)

Wait-at-Point (W)

Low-Level

Just-Wait

Just-Wait

Just-Wait

Low-Level

(b)

(a)

Ordered-Halt (H)

Just-Wait

(c)

Figure 4: Scout (a) Attackers' (b, c) actual recognized

abbreviated

reactive plan

hierarchies.

individual modeling hypotheses acquired individual agent (using planrecognition implementation, potentially also communications), monitoring
agent must combine create team-modeling hypotheses state team
whole. monitoring agent selects single individual modeling hypothesis
individual agent combines single team-modeling hypothesis. Several
team-modeling hypotheses possible given multiple hypotheses individual agents.
instance, Figure 4, team-hypotheses

execution-mission

top-

level plan, eight dierent team-hypotheses dierentiated
second-level plan:

(W,W,W), (W,W,H), (W,H,W), (W,H,H), (F,W,W), (F,W,H), (F,H,W), (F,H,H).

observer member team, knows executing itself, would still
multiple-hypotheses teammates' states. instance, attacker Figure 4b
monitoring teammates, hypotheses second level would (W,W,W), (W,W,H),

(F,W,W), (F,W,H).

avoid explicitly representing combinatorial number hypotheses, RESL explicitly
maintains candidate hypotheses agent individually, combinations
individual models team hypotheses. Instead, combinations implicitly represented. Thus number hypotheses explicitly maintained grows linearly number
agents.

113

fiKaminka Tambe

3.3 Relationship Violation Detection
failure-detection component detects violations social relationships
hold among agents.

done comparing ideal expected relationships

actual maintenance agents. teamwork specically, relationship model requires
team-members always agree

team plan jointly executed team, similarly

Joint Responsibility (Jennings, 1995), SharedPlans (Grosz & Kraus, 1996).
requirement fails actuality (i.e., agents executing dierent team plans)
teamwork failure occurred.
basic teamwork failure detection algorithm follows.
plan-hierarchies processed top-down manner.

monitored agents'

detection component uses

teamwork model tag specic plans team plans, explicitly representing joint activity
team (these plans boxed Figures 3, 5 4).

team-plans equal depths

hierarchies used create team-modeling hypotheses. hypothesis,
plans dierent agents compared detect disagreements. dierence found
indication failure.

dierences found, comparison reaches individual

plans (non-team, therefore non-boxed gures) failure detected. Individual plans,
may chosen agent individually service team plans boxed
gures, handled using relationships discussed Section 7
instance, suppose failing attacker Example 1 monitoring attacker. Figure 5 shows view hierarchical plan left. path
right represents state attacker (who landed). state inferred example observations made monitoring attacker (here,
assuming plan-recognition process resulted one correct hypothesis
agent. discuss realistic settings below). Figure 5, dierence would
detected marked arrow two plans second level top.

fly-flight-plan team-plan (on
wait-at-point team-plan (on right).

failing attacker executing

left),

attacker executing

disagreement

team-plan executed failure teamwork.

Execute Mission

Execute Mission

Fly-Flight-Plan

Wait-at-Point

Fly-Route
Traveling
Low-Level

Just-Wait

Figure 5: Comparing two hierarchical plans. top-most dierence level 2.

114

fiRobust Agent Teams via Socially-Attentive Monitoring

Detecting disagreements dicult multiple team-modeling hypotheses, since
may imply contradictory results respect failure detection: hypotheses may imply failure occurred team, others may not. Unfortunately,
expected realistic applications. instance, Figure 4 (Section 3.2) shows several hypotheses possible based observations. However, one hypotheses,
(W,W,W), implies failure occurredall agents agreement team-plan

executingwhile another hypothesis, (F,W,H), implies failures occurred.

limit reasoning small number team hypotheses, restricting
failure-detection capabilities, use disambiguation heuristic ranks team-modeling
hypotheses level

coherence

represent. heuristic provided initial

solution. Later sections examine additional heuristics.

Denition 1.



coherence

level multi-agent modeling hypothesis dened

ratio number agents modeled number plans contained hypothesis.
denition results partial ordering hypotheses set, least coherent
hypothesis (one assigns agent dierent plan team-mates),
coherent hypothesis (that assigns plan team members).

instance,

hypothesis (F,W,H) would lowest level coherence, 1, since implies complete

breakdown teamworkevery agent executing dierent plan. hypothesis (W,W,W)
would coherence level 3, highest level coherence group three agents,
since assigned plan. Ranked would hypothesis
(W,W,H), single teamwork failure (disagreement W H) coherence level
3/2.
detection component selects single maximally-coherent team-modeling hypothesis
(ties broken randomly).

intuition using coherence failures agree occur

despite agents' attempts teamwork. Thus expect agreements disagreements team.

coherence level team-hypothesis inversely related

number teamwork failures implied hypothesis. Selecting maximally-coherent hypothesis therefore corresponds minimum-number-of-failures heuristic commonly used
diagnosis (Hamscher, Console, & de Kleer, 1992).
case depicted Figure 4, complete detection process may conceptu-

1

alized follows .

Suppose one attackers, whose hierarchy described

Figure 4b, monitoring team.

First, collects plan hypotheses top

hierarchy agent (including ). case, {execute-mission},

{execute-mission}, {execute-mission}. one team-modeling hypothesis built
these: (execute-mission,

execute-mission, execute-mission).

Since hypoth-

esis shows disagreement occurs level, process continues second level.
Here, hypotheses rst agent left {F,W}, monitoring second agent
(since knows state) one possibility {W}, third agent {W,H}.

saw above, maximally team-coherent hypothesis (W,W,W) selected. Since
indicate failure, process continues third level.

agents

executing individual plans, comparison process stops. Algorithm 2 Appendix
B provides greater details process.
1. implementations may make use optimized algorithms heuristics integrated
agent-modeling algorithm.

115

fiKaminka Tambe

sub-teams introduced, dierence team-plans may explained
agents question part dierent sub-teams.

Sub-team members still

agree joint sub-team plans, may dier one
sub-team next. now, let us assume teams consideration

teams, dened Denition 2.

simple

make denition service later analytical results

appear condition. return issue sub-teams Section 7.1.

Denition 2.

say team

simple,

plan-hierarchy involves dierent

team plans executed dierent sub-teams.
Intuitively, idea simple team, members team jointly execute
team plans hierarchy. denition somewhat similar denition


ground team

(Kinny, Ljungberg, Rao, Sonenberg, Tidhar, & Werner, 1992),

allow sub-team members team joint plan dierent
members.

3.4 Relationship Diagnosis
diagnosis component constructs explanation detected failure, identifying
failure state facilitating recovery.

diagnosis given terms set agent

belief dierences (inconsistencies) explains failure maintain relationship.
starting point process detected failure (e.g., dierence team-plans).
diagnosis process compares beliefs agents involved produce set
inconsistent beliefs explain failure.
Two problems exist practical applications procedure.

First, monitoring

agent likely access beliefs held monitored agents, since
feasible practice communicate agents' beliefs other. Second,
agent real-world domain may many beliefs, many vary among
agents, though irrelevant diagnosis. Thus relevant knowledge
may simply accessible, may hidden mountains irrelevant facts.
gain knowledge beliefs monitored agents without relying communications,
diagnosis process uses process belief ascription. agent-modeling component (using RESL implementation) maintains knowledge selection termination
conditions recognized plans (hypotheses). recognized plan hypothesis, modeling component infers termination conditions plan believed false
monitored agent (since terminated plan). also found useful
use additional heuristic, infer selection conditions (preconditions)
plan

begun execution

true. idea plan selected

execution, preconditions likely hold, least short period time.
heuristic involves explicit assumption part system new plan
recognized soon begins execution.

Designers domains need verify

assumption holds.
agent i, inferred termination selection conditions make set beliefs
Bi agent. instance, suppose agent hypothesized switched

executing

fly-flight-plan



wait-at-point.

RESL infers agent believes

way-point detected (a selection condition

116

wait-at-point).

addition,

fiRobust Agent Teams via Socially-Attentive Monitoring

RESL infers agent believes enemy seen, order

wait-at-point).

received base halt mission (negated termination conditions

determine facts relevant failure, diagnosis component uses
teamwork model. teamwork model dictates beliefs agents hold must
mutually believed agents team.

dierence detected

beliefs certain failure, team members agree issues agreement
mandatory participation team.

teamwork model thus species

beliefs contained Bi sets mutual, therefore consistent:

[

Bi 6`?



inconsistency detected, diagnosis procedure looks contradictions (disagreements) would cause dierence team-plan selection. dierence beliefs serves
diagnosis, allowing monitoring agent initiate process recovery, e.g.,
negotiating conicting beliefs (Kraus et al., 1998).
example, shown Section 3.3, two attackers Example 1 (Section 2) dier
choice team-plan: One attacker continuing execution

fly-flight-plan

plan, helicopters formation. attacker detected waypoint, terminated

fly-flight-plan

wait-at-point,

switched

landing immedi-

ately (Figure 5). failing attacker monitors team-mate, detects dierence
team-plans (Section 3.3), detected dierence passed diagnosis. failing
attacker makes following inferences:
1.

Fly-flight-plan three termination conditions:

(a) seeing enemy, (b) detecting

way-point, (c) receiving order halt. failing attacker (left hierarchy
Figure 5) knows belief none conditions hold, thus
B1

2.

Wait-at-point

=

f:W ayP oint; :E nemy; :H altOrderg

one selection condition:

way-point detected.



termination condition scout sent message join it, identied
enemy's position. diagnosis component case therefore infers
attacker (right hierarchy Figure 5)
B2

=

fW ayP oint; :S coutM essageReceivedg

Then,
B1 [ B2





=

f:W ayP oint; W ayP oint; :E nemy; :S coutM essageReceived; :H altOrderg

inconsistent.



inconsistency

(disagreement





attackers)



f:W ayP oint; W ayP ointg, i.e., contradictory beliefs W aypoint. Thus failing

attacker knows team-mate seen way-point. choose quietly adapt
belief, thereby terminating

fly-flight-plan

117

selecting

wait-at-point,



fiKaminka Tambe

may choose recovery actions, negotiating attacker whether
way-point reached.
found diagnosis procedures useful many failures detected
socially-attentive monitoring (see Section 4 evaluation discussion).
since paper focuses monitoring selectivity problem

However,

detection, leave

investigation diagnosis procedures future work.

4. Monitoring Selectivity Centralized Teamwork Monitoring
Using socially-attentive framework Section 3 systematically examine failure
permutations Examples 1 2 (Section 2) centralized teamwork monitoring
conguration, single team-member monitoring team.

vary agents

failing (attacker, attacker scout, etc.) role monitoring agent (attacker
scout). report empirical results detecting diagnosing failures cases.
Using empirical results guide, explore centralized teamwork monitoring analytically. show even monitoring uncertainty, centralized teamwork monitoring
provide either sound complete detection results (but both).
starting point exploration, monitoring agent uses single maximallycoherent team-modeling hypothesis discussed Section 3.3. begin Example 2.
normal order execution

W,

execution
enemy's position.

wait-at-point (W),

followed

join-scout (J).



two attackers land wait scout visually identify

Upon identication, scout sends message join it,

triggers selection

J

plan, termination

W

plan. executing

J,

scout hovers low altitude, waiting attackers join it. failures
part attackers (they cannot receive message) part scout (it
cannot send it). failures arise, instance, radio broken team-members
range. agent fails, continues execute

W

instead switching

J.

Table 1 summarizes permutations Example 2. permutation number appear
rst column.

next three columns show actual plans selected three

agents A1, A2 A3 permutation.

second-to-last column shows whether

relationship failure occurred case, i.e., whether disagreement exists
agents. Finally, last column details physical conditions case.
possible failure permutations: case 1, none agents failed.
attacker failed.

cases 2 3 one

case 4 scout failed send message attackers failed

receive it. case 5 scout identify enemy's position (so message sent,
three agents continue execute
since attacker switch

J

W

plan). permutations possible,

plan without scout.

instance, case 2 Table 1 corresponds Example 2. scout (A3) detected
enemy, switched plan

J,

sent message attackers join it. One attacker

(A2) received message, switched plan

J, began ying towards scout.

However,

remaining attacker (A1) failed receive message, maintains position,
continuing execute

W failing switch J. Since agents longer agreement

team plan jointly executed, teamwork failure occurred. Condition
monitors used original failure case monitor scout's message. However
failures communications resulted monitoring conditions rendered useless.

118

fiRobust Agent Teams via Socially-Attentive Monitoring

Case

#

Actual Executing Plans

Relationship Failure

Physical

?

Attacker A1

Attacker A2

Scout A3

Occurred

Failure

1

J

J

J

-

-

2

W

J

J

+

A1 fails receive

3

J

W

J

+

A2 fails receive

4

W

W

J

+

A3's message lost

5

W

W

W

-

Enemy identied

Table 1: possible failure permutations broken radio-link scenario (Example 2).

One key issue raised case 5 Table 1. Here, due scout's inability identify
enemy's position (perhaps due failure scout's part, perhaps enemy
simply there), three helicopter pilots remain agreement enemy
identied. Here, even though clearly pilots failing make progress towards
task goals (the scout continues search enemy indenitely), relationship failure
taking place, since agents maintaining teamwork relationship failing
make progress. clearly demonstrates failures necessarily relationship
failures.
Table 2 presents results scout monitoring teammates Example 2, using
maximally team-coherent hypothesis basis detection. rst column shows
case number, reference Table 1. next three columns show scout's (A3's)
hypothesis plan agent executing according maximal coherence
heuristic. next two columns show whether failure detected, whether
diagnosed correctly. last column shows detection class (discussed below).

Case

#

A3's Hypothesized Executing Plans

Relationship Failure

Diagnosis

Detection

Detected?

Success?

Class

J

-

n/a

True Negative

J

+

+

True Positive

W

J

+

+

True Positive

H

J

+

-

True Positive

W

W

-

n/a

True Negative

Attacker A1

Attacker A2

Scout A3

1

J

J

2

W

J

3

J

4

H

5

W

Table 2: Scout's (A3) monitoring results permutations Example 2.
example, case 2 Table 2 shows results scout monitoring original
failure Example 2 (Section 2). Using RESL, selecting maximally-coherent hypothesis, scout hypothesizes non-moving attacker executing
moving attacker executing
selected plan

J

J (case 2, column 3).

W (case

2, column 2),

scout course knows

(case 2, column 4). violation teamwork relationship thus

detected (case 2, column 5), since A1's

W

agreement rest team's

J.

Furthermore, diagnosis successful identifying cause failure, i.e.,
fact enemy's position identied scout, knowledge
passed failing attacker (case 2, column 6).

119

fiKaminka Tambe

last column Table 2 shows detection class failure. detection class
case one of: true positive, true negative, false positive, false negative.
correspond following possible monitoring outcomes: true positive outcome
relationship failure actually occurred, detected. true negative
failure occurred, system correctly reports none detected.
false positive failure occurred, system nevertheless incorrectly
detects one, false negative failure occurred, system fails
detect it. Table 2 shows permutations Example 2 teamwork monitoring
techniques encounter problematic false positive false negative cases.
closer look results hints key contribution paper addressing
monitoring selectivity problem: Eective failure detection take place despite use
uncertain, limited, knowledge monitored agents. case 4 Table 2, monitoring agent able detect failure

involved.

despite wrong state agents

scout believes two attackers executing

W. H

plan, actually executing,

H (ordered-halt)

selected command received

headquarters halt execution hover place.

scout's perspective, hov-

ering attacker therefore inferred executing

H



W.

Thus two equally-ranked

maximally-coherent hypotheses exist: two attackers either executing
executing

H.

W



random selection made, case resulted wrong hypothe-

sis selected. Nevertheless, violation teamwork relationships detected,
neither

H



W

agrees scout's

J.

However, last column case 4 shows (in Table 2), diagnosis procedures
sensitive selection team-modeling hypothesis. hypothesis used case
correctly reect true state agents, despite scout's success
detect failure case, diagnosis procedures fail provide correct diagnosis (the
diagnosis successful two failure cases). phenomenon repeats
empirical results provide below:

diagnosis failed whenever hypothesis chosen

incorrect, although sucient detection.

intend explore ways improve

accuracy hypotheses future work, therefore address issue
paper anymore. failure detection capabilities signicant improvement
themselves, since agents know certainty failure occurred, even
diagnosis incorrect.
Many social physical failures successfully captured using team-coherence
heuristic monitoring selectivity. fact, permutations Example 2, matter
one agents monitor, failures maintain relationship (i.e., physical
failures except one team remains agreement) detected reliably,
although sometimes diagnosis failed.

result especially surprising considering

single agent monitoring. Previous monitoring methods (condition monitors
communications) unable detect failures, despite used three
agents .
Tables 3 4 present empirical results, basis Example 1.

Table 3

presents failure permutations Example 1 format Table 1. normal or-

fly-flight-plan
wait-at-point (W) plan,

der execution plans follows: agents jointly execute
(F) plan detect way-point. switch

two attackers land scout continues ahead identify enemy.

120

fiRobust Agent Teams via Socially-Attentive Monitoring

failures part agents detect way-point, thus switch


W

plan.

Case

#

Actual Executing Plans

Relationship Failure

Physical

?

Attacker A1

Attacker A2

Scout A3

Occurred

Failure

1

W

W

W

-

-

2

F

W

W

+

A1 vision fails

3

W

F

W

+

A2 vision fails

4

F

F

W

+

A1, A2 vision fails

5

W

W

F

+

A3 vision fails

6

F

W

F

+

A1, A3 vision fails

7

W

F

F

+

A2, A3 vision fails

8

F

F

F

-

A1,2,3 vision fails

Table 3: failure permutations undetected way-point scenario (Example 1).

Case

#

A1's Hypothesized Executing Plans

Relationship Failure

Detection

Attacker A1

Attacker A2

Scout A3

Detected?

Class

W

W

W

-

True Negative

2

F

W

F

+

True Positive

3

W

F

W

+

-

True Positive

False Negative
False Negative

1

4
5

F
W

F
W

F
W

6

F

W

F

+

True Positive

7

W

F

F

+

True Positive

8

F

F

F

-

True Negative

Table 4: Attacker's (A1) monitoring results permutations Example 1.

Table 4 present monitoring results permutations Example 1.



attacker A1 monitoring team using maximally team-coherent hypothesis
detecting failures. results show A1 successful detecting teamwork failures
two (cases 4-5, highlighted bold face).
two false outcomes false negatives. cases, monitoring
attacker A1 picked incorrect hypothesis scout, since scout's actions lead
ambiguous interpretations. scout forward (to scout enemy) detected
way-point (plan

W), also (then would ying formationplan F).

use maximal team-coherence heuristic causes A1 prefer hypothesis
scout agreement attackers fact not. example, case 4, two
attackers failed detect way-point executing

F. Observing scout,
F W. However, believing

monitoring attacker A1 sure whether scout executing
scout executing

F results maximally-coherent

team-modeling hypothesis (all

agents agreement), believing scout executing

121

W

results less

fiKaminka Tambe

coherent hypothesis. Thus A1 selects wrong hypothesis, case fails detect
teamwork failure.
maximal team-coherence heuristic detect failures despite using incorrect hypotheses. Unfortunately, hypotheses also lead false-negatives seen
Table 4. However, none experiments resulted false-positive result, i.e., result
system detected failure reality none occurred. Thus heuristic
provided sound results cases. able formally prove property holds
general maximal team-coherence heuristic used.
First, address matter notation. Let agent monitor agent B ,
executing plan P .

denote (A; B =P ) set agent-modeling hypotheses

A's agent-modeling component constructs based B 's observable behavior
execution P . words, (A; B =P ) A's set plans match B 's observable
behavior.

Note monitors itself, direct access state

(A; A=P )

=fP g. Using modeling notation, make following denitions

ground assumptions underlying knowledge used monitoring:

Denition 3.

agent-modeling

Given monitoring agent A, monitored agent B , say A's
agent B

complete

plan P may executed B, P 2

(A; B=P ).

set (A; B=P ) typically include matching hypotheses besides correct
hypothesis P, guaranteed include P. Following denition

individual

agent-

modeling completeness, dene group-wide team-modeling completeness:

Denition 4.
A's

Let agent monitoring team agents B1 ; ; Bn . say

team-modeling

team

complete

A's agent-modeling B1 ; ; Bn

complete.
Denition 4 critical guarantee capabilities explore analytically
section next. generally holds use RESL ModSAF RoboCup
domains, make explicit service applications techniques
domains.
Armed denitions, formalize failure detection capabilities suggested empirical evidence Theorem 1.

Theorem 1. Let monitoring agent

monitor simple team . A's team-modeling
complete, uses maximally team-coherent hypothesis detection,
teamwork failure detection results sound.

Proof.

show failure occurred, none detected, thus

failure detected fact failure. Let a1 ; : : : ; agent members .
agent ai executing plan Pi (1 n). Thus collectively, group executing

(P1 ; : : : ; Pn ). failure occurred, agents executing plan

P0 ,

i.e., 8i; Pi = P0 . Since A's team-modeling complete, correct hypothesis (P0 ; : : : ; P0 )
going set team-modeling hypotheses H .

Since maximally team-

coherent hypothesis, either selected, dierent hypothesis

coherence level



selected. hypothesis coherence level correct

one implies failure detected. Thus detection procedure sound.

122

fiRobust Agent Teams via Socially-Attentive Monitoring

Despite uncertainty knowledge used, sound failure-detection guaranteed using
maximal team-coherence heuristic.

one answer monitoring selectivity

problem. However, seen Table 4, failures may pass undetected using
heuristic (i.e., may result false-negatives).
may therefore unfortunately

complete guaranteed

incomplete.

Detection using maximal team-coherence

may prefer monitoring system

detect teamwork failures.

incoherence

therefore experimented maximal team-

heuristic, inverse

maximal team-coherence heuristic. heuristic prefers hypotheses suggest
failures, rather less.



Table 5 gives monitoring attacker A1's view team,

incoherent

similar Table 4, using maximally team-

hypothesis. shows indeed

using maximally team-incoherent hypothesis lead false-negative detections
cases 4 5 (in contrast cases Table 4).
Case

Relationship Failure

Detection

Attacker A1

Scout A3

Detected?

+

Class

1

W

Attacker A2

False Positive

2

F

H

W

+

True Positive

3

W

F

F

+

True Positive

F

F

W

+

True Positive

#

A1's Hypothesized Executing Plans

4
5

H

F

W

H

F

+

True Positive

6

F

H

W

+

True Positive

7

W

8

F

F

F

F

+

W

+

True Positive

False Positive

Table 5: Attacker's (A1) monitoring results permutations Example 1, using team-

incoherence.

Guided results, formally show team-incoherence heuristic leads
detection procedure

complete.

Theorem 2. Let monitoring agent monitor simple team . A's team-modeling
complete, uses maximally team-incoherent hypothesis detection,
teamwork failure detection results complete.
Proof. Analogous Theorem 1, proof provided appendix A.
However, successes oset false positive outcomes cases 1 8 Table 5.
cases, failures occurred, monitoring system falsely reported detected
failures. practice, may lead costly processing many false alarms.
Ideally, detection capabilities sound



complete. Unfortunately,

show coherence-based disambiguation scheme exists results sound
complete detection. show Theorem 3 provide sound complete detection,
disambiguation method inconsistent: Given set possible matching
hypotheses, sometimes rank one hypothesis top, sometimes another.

Theorem 3. Let

H complete team-modeling hypotheses set, modeling simple team.
exists disambiguation scheme (1) uses coherence alone basis

123

fiKaminka Tambe

disambiguation H , (2) deterministic selection, (3) results sound
complete failure detection.
Proof.

Let disambiguation scheme leads complete sound detection

uses knowledge coherence hypotheses selecting disambiguated hypothesis. Suppose contradiction deterministic, thus consistent, selection
hypothesis H , i.e., given H , set candidate hypotheses, applies
deterministic procedure choose one hypothesis based coherence.

Since

use knowledge outside coherence candidate hypotheses, given
set candidates, always choose hypothesis.

Let

monitoring agent using . Let B monitored agent, whose actions identical
executing team plans P1 ; P2 .
P2 , (Am ; B =P1 )

=

Thus, cannot determine whether B executing P1

(Am ; B =P2 )

=

fP1 ; P2 g. B executing P1 , 's

H

=

f(P1 ; P1 );

hypotheses set

(P1 ; P2 )g

Since leads complete sound detection, choose (P1 ; P1 ). Now,
B executing P1 P2 , respectively, matching hypothesis set H dened

above. must select (P1 ; P2 ). Since set candidate hypothesis H
used case, information supplied, must non-deterministic
selection disambiguated hypothesis, contradicting assumption.
empirical analytical results show use single disambiguated hypothesis leads improved, imperfect, failure-detection results, compared monitoring
conditions communications previously used. empirical results Tables 2, 4,
5 establish benets teamwork monitoring technique: physical failures
detected. However, analytical results (Theorems 1, 2, 3) show results less
perfect. algorithms either sound complete, both. complete monitoring, would require additional procedures dierentiate true positives
false ones, e.g., focused communication. procedures often expensive.
reduce need costly verication letting go insistence single
hypothesis, focusing instead maintaining two hypotheses: maximally-coherent hypothesis maximally-incoherent hypothesis.

Table 6 shows portion full set

team-hypotheses available attacker A1 monitoring team. total number
hypotheses presented table 24, many 4 co-existing single case,
thus maintaining full set hypotheses would expensive. However, two inverse
heuristicsteam-coherence incoherencerepresent two extremes space
hypotheses.

agree failure exists, failure actually occurred, since

team-coherent hypothesis guarantees soundness (Theorem 1). agree failure
exists, failure took place, since team-incoherent hypothesis guarantees completeness (Theorem 2). disagree (i.e., team-coherent hypothesis imply
failure, team-incoherent hypothesis does), monitoring system cannot sure
either way, must revert back verication.
revised detection algorithm oers signicant computational savings compared
single team-incoherent hypothesis approach. complete unsound, signicantly

124

fiRobust Agent Teams via Socially-Attentive Monitoring

Case

#
1

2

3
4
5

6

7
8

A1's Hypothesized Executing Plans

Relationship Failure

Detection

Scout A3

Detected?

Class

H

F

+

False Positive

H

W

+

False Positive

W

W

F

+

False Positive

W

W

W

-

True Negative

F

H

F

+

True Positive

F

H

W

+

True Positive

F

W

F

+

True Positive

F

W

W

+

True Positive

W

F

F

+

True Positive

W

F

W

+

True Positive

F

F

W

+

True Positive

F

F

F

-

False Negative

W

H

F

+

True Positive

W

H

W

+

True Positive

W

W

F

+

True Positive

W

W

W

-

False Negative

F

H

W

+

True Positive

Attacker A1

Attacker A2

W
W

F

H

F

+

True Positive

F

W

W

+

True Positive

F

W

F

+

True Positive

W

F

F

+

True Positive

W

F

W

+

True Positive

F

F

W

+

False Positive

F

F

F

-

True Negative

Table 6: portion attacker's (A1) monitoring hypotheses implied results
ranking used select single hypothesis case.

reduces need verication, since least team-coherent hypothesis implies
failures, verication necessary. requires representing two hypotheses,
thus still computationally cheaper maintaining exponential number hypotheses.
example, using maximally team-incoherent hypothesis permutations Example
1 results need verify eight cases seen (5). However, combine
hypothesis maximally team-coherent hypothesis (e.g., Table 4),
need verify four (50% ) cases. cases 2, 3, 6, 7 agreement
two hypotheses failure occurred, thus verication required.
monitoring agent therefore address monitoring selectivity problem balancing
resource usage guaranteed performance monitoring algorithm used.
Either simpler single-hypothesis algorithms would utilize one hypothesis
case, detection capabilities guaranteed sound complete, both.
complex algorithm, two hypotheses would reasoned case,

125

fiKaminka Tambe

algorithm would complete require verication fewer cases compared
simple-hypothesis complete algorithm.

5. Monitoring Selectivity Distributed Teamwork Monitoring
section focuses monitoring selectivity exploiting key opportunity execution monitoring multi-agent environmentsit monitored agents
distributed, monitoring agents distributed well. begin
simple scheme selecting single maximally team-coherent hypothesis. Since centralized
teamwork monitoring successful addressing permutations Example 2, focus
permutations Example 1 (Table 3), centralized teamwork monitoring
attacker resulted false-negative detections (cases 4-5 Table 4).
distributed teamwork monitoring scheme, single attacker monitor
teammates, scout (and attacker) also engage monitoring. Table
7 presents monitoring results failure permutations, scout
monitoring agent.

nd scout successfully detects two failure cases

attacker failed detect, compensating attackers' monitoring mistakes. Furthermore, since scout used maximal-coherence heuristic, detection sound
verication required. reason scout's success attackers' actions
case, although ambiguous, support hypothesis matched
scout's plan. words, regardless plan attackers executing
two cases, dierent plan executed scout.
Case

Relationship Failure

Detection

Detected?

Class

W

-

True Negative

F

+

True Positive

F

W

+

True Positive

F

W

+

True Positive

H

H

F

+

True Positive

F

H

F

+

True Positive

7

H

F

F

+

True Positive

8

F

F

F

-

True Negative

#

A3's Hypothesized Executing Plans
Attacker A1

Attacker A2

Scout A3

1

W

W

2

F

W

3

W

4

F

5
6

Table 7: Scout's (A3) monitoring results permutations Example 1, using teamcoherence.

Thus agents engaged monitoring permutations Example 1, detection would
sound complete. actual failure cases (and those) would least one
team-member detects failure. attempt formally dene general conditions
phenomenon holds.

Denition 5.

say two team-plans P1 ; P2 ,

observably-dierent roles

R1 ; R2

given agent B fullls roles R1 ; R2 two plans, resp., monitoring agent
(dierent B ) (A; B =P1 ) \ (A; B =P2 )

observably-dierent roles P1 P2 , call B

126

=

key agent.

;.

say B

fiRobust Agent Teams via Socially-Attentive Monitoring

Intuitively, B key agent observably dierent roles two plans
monitoring agent dierentiate B 's behavior executing P1 executing
P2 . instance, attackers observably dierent roles

W

(in land).

F

(in y)

However, observably dierent roles

require land. scout observably dierent roles


H

W H,
W (ying)

(landing).

key-agent basis conditions self-monitoring team
detect failure agent using team-coherence. rst prove lemma
conditions single given agent detect failure. use lemma
prove conditions least one agent given team detect failure.

Lemma 1. Suppose simple team

self-monitoring (all members team monitor
other) using maximally team-coherent heuristic (and assumption
agent, team-modeling complete). Let A1 ; A2 monitoring agents members
executing P1 ; P2 , respectively. A1 would detect failure maintaining teamwork
relationships agent A2 , A2 key-agent P1 ; P2 .

Proof.

See appendix A.

A1 knows executing P1 .

A2 executing P2 , key-agent P1 P2 ,

A1 guaranteed notice dierence exists A2 , since A2
acting observably dierent would executing P1 . Note, however,
A2 may may detect dierence, since A2 's perspective, A1 's behavior may

may explained P2 . A2 detect dierence A1 's roles P1 P2
also observably-dierent. However, since A1 detected failure, alert
teammates, diagnose failure, choose corrective action.
want guarantee teamwork failure always detected least
one agent, must make sure possible combination plans,
least one key-agent whose roles observably dierent.

lemma shows

agents monitoring agent notice failure one occurs. aim, dene
observably-partitioned set plans employed team.

Denition 6.

set P team-plans said

observably-partitioned

two plans

Pi ; Pj 2 P exists key-agent Aij . set Aij agents called

set P .

key agents

instance, set team-plans helicopter pilots team using
examples (Fly-Flight-Plan (F),

Wait-at-Point (W), Ordered-Halt (H), Join-Scout
(J)) observably-partitioned. attackers land W H, F J. scout
lands J H, ies W F. Table 8 shows agents observably dierent
roles two plans set. instance, nding cell intersection

H

row

W

column, nd scout observably dierent roles two

plans. Indeed, scout lands command received halt execution (H), ies
scout enemy's position executing

W.

Here, since agents observably-

dierent roles least two plans, key agents set {
teamattackers scout.

127

W , F , H, J }

includes members

fiKaminka Tambe

Fly-Flight-Plan (F)

Wait-at-Point (W)

Ordered-Halt (H)

-

Attackers

Attackers

Scout

Attackers

-

Scout

Scout Attackers

F
W
H
J

Join-Scout (J)

Attackers

Scout

-

Attackers

Scout

Scout Attackers

Attackers

-

Table 8: Observable partitioning helicopter pilot team ModSAF.

Theorem 4. simple team (1) employs observably-partitioned set team-plans O,

team-members monitor members key agents set O, (2) using complete teammodeling (3) maximally team-coherent hypotheses, teamwork failure detection
results sound complete.
Proof.

theorem 1 know detection would sound. show complete,

prove least one agent detect dierence others whenever
team-members executing plan (i.e., failure occurring). Suppose
team currently divided team-plans must executed, i.e., agents
ai ; aj team executing team plans Pi ; Pj , respectively, Pi 6= Pj .

Thus failure occurred. Let K key agents set . Since team observablypartitioned, Pi ; Pj exists least one key agent a1 2 K . three cases:

case (i).

a1 executing Pi . case agent executing Pj would detect dierence

a1 would therefore detect failure (lemma 1).

case (ii).

a1 executing Pj . case agent executing Pi would detect dierence

a1 would therefore detect failure (lemma 1).

case (iii).

a1 executing plan Q. roles must observably dierent Q

Pi , Q Pj (or both), thus agent executing Pj and/or Pi would detect
failure. case a1 's roles observably dierent Q Pi



Q

Pj impossible, since monitoring agent
(Am ; a1 =Pi ) \ (Am ; a1 =P j ) fQg 6= ;

Contradicting a1 key agent Pi ; Pj .
Since three cases, least one agent would detect failure one occurred.
Therefore, failure detection complete. Since also sound seen, detection
sound complete.
theorem shows distributed teamwork monitoring result

sound complete
key

failure-detection, using simple algorithm. team-member monitors

agents 2 , using maximally team-coherent

hypothesis. detects failure, certainly

one occurred. agent detects failure, indeed failure occurred.
simple distributed algorithm, attention-focusing features guaranteed
soundness completeness contrasts complex centralized algorithm
discussed previous section (Section 4). algorithm's eectiveness relies
2. monitoring team-member know key agents are, knows exist,
monitor team-members. increases monitoring, sound complete failure detection
still guaranteed.

128

fiRobust Agent Teams via Socially-Attentive Monitoring

condition observably-partitioned set plans, distribution monitoring.
corollary Theorems 3 4 key agents available distributed
case, failure detection either sound complete, both. even key agents
available, centralized teamwork monitoring still complete sound.
Fortunately, observable-partitioning dicult property design: Teams
often composed agents role plan, general,
roles observable dierences them. instance, helicopter pilot team
ModSAF domain typically executes set plans property, Table 8
demonstrates.
team, however, observably-partitioned, may case two agents
executing dierent plan, agent able detect using teamcoherence heuristic. minimal case occurs two agents, A1 A2
executing plans P1 P2 , respectively, P1 P2 observably dierent,

(A2 ; A1 =P1 ) \ (A1 ; A2 =P 2)

=

fP1 ; P2 g

result A1 A2 believing agreement them.
check situation made part plan design process, marking

points

risky

execution detection either sound complete (Theorem 3),

verication (e.g., communications) prescribed pro-actively. Or, check could
inserted protocol run-time analysisthe agent would simulate other's
hypotheses matching actions, detect risky points dynamically.

6. Using Socially-Attentive Monitoring O-Line Conguration
demonstrate generality socially-attentive monitoring framework,
section examines re-use teamwork monitoring domains diagnosis recovery
every failure infeasible execution. Examples domains include team
sports, military human team training (Volpe, Cannon-Bowers, & Salas, 1996),
multi-agent domains.

dynamic nature domain, hard real-time deadlines,

complexity agents involved (e.g., human team members) make diagnosis recovery
dicult.

Even failure diagnosed, often late eective recovery.



environments, monitoring agent often concerned trends performance.
information important long-term design evaluation analysis, need
necessarily calculated on-line. results analysis meant feedback
agents' designer (coach supervisor, humans).
end, developing o-line socially-attentive monitoring system called
Teamore (TEAmwork MOnitoring REview). Teamore currently uses execution traces

monitored agents perform monitoring, rather using plan recognition. Thus
need worry uncertainty plan-recognition, real-time performance. Instead, knows certainty agent's plans execution. Teamore
accumulates several quantitative measures related teamwork, including Average-Timeto-Agreement measure (ATA, short), measure level agreement team.
build failure detection algorithm, aggregate failures quantitatively.
focus ATA measure.

129

fiKaminka Tambe

Teamore denes

switch

time interval beginning point team-

member (at least one) selects new team plan execution team, ending
point team agreement team-plan executed.



perfect teamwork, team-members select new team-plan jointly, always remain
agreement.

realistic scenario, agents take longer switch,

initially teamwork failure occur. rst team-member select new plan
disagreement teammates, either rejoins executing
original plan, join selecting new plan. switch begins detected
failure ends failures detected.
Figure 6 shows illustration switch. three agents begin initial state
agreement joint execution Plan 1 (lled line). Agent 1 rst agent switch
Plan 2 (dotted line), followed Agent 3, nally Agent 2.

switch

interval begins instance Agents 1 selected Plan 2, time three agents
regained agreement (but time Plan 2).

Switch
Legend:
Plan 1

Agent 3

Plan 2
Agent 2
Agent 1
Time
Figure 6: illustration switch. three agents switch plan 1 plan 2.
Teamore keeps track lengths time failures detected

resolved. ATA measure average switch length (in time ticks) per complete
team run (e.g., mission ModSAF, game RoboCup). perfect team would
switches length zero, therefore ATA 0. worst team would one
beginning task execution end it, would agree
team plan executed. instance, RoboCup game lasts 6000 ticks.
worst possible team would one switch game, length 6000. Thus
ATA scale RoboCup goes 0 (perfect) 6000 (worst).
used ATA measure analyze series games two RoboCup simulationleague teams, ISIS'97 ISIS'98 (Marsella et al., 1999) xed opponent, Andhill'97
(Andou, 1998).

games, varied use communications teams

evaluate design decisions use communications. approximately half games,
players allowed use communications service teamwork. half,
communications agents disabled. ISIS'97 played approximately 15 games
settings, ISIS'98 played 30 games communication settings.
Table 9 shows mean ATA values games, two sub-teams (each
three members) ISIS'97 ISIS'98 (ATA values calculated separately subteam). rst column shows sub-team results refer row. second

130

fiRobust Agent Teams via Socially-Attentive Monitoring

columns shows mean ATA sub-team, communications used.
third column shows mean ATA communications used. next column shows
size ATA reductionthe drop mean ATA values communications
introduced.

last column shows probability null hypothesis two-tailed

t-test dierence ATA means. probability dierence due
chance, thus smaller numbers indicate greater signicance.

ISIS

Mean ATA

Mean ATA

ATA

t-test prob.

sub-team

comm.

Comm.

Reduction

null-hypothesis

32.80

5.79

27.01

7.13e-13

'97 Goalies
'97 Defenders

57.5

6.81

50.69

.45e-10

'98 Goalies

13.28

3.65

9.63

9.26e-16

'98 Defenders

12.99

3.98

9.01

7.13e-5

Table 9: Average-Time-to-Agreement (ATA) games Andhill'97.

Clearly, signicant dierence emerges communicating noncommunicating versions sub-team.

ATA values indicate sharing infor-

mation way communications signicantly decreases time takes team-members
come agreement selected plan. result agrees intuitions
role communications, sense, may surprising.
However, ATA reduction magnitudes indicate ISIS'98 may much less sensitive loss communications ISIS'97. dierences ATA values ISIS'97
approximately triple, nearly four times, great ISIS'98.

explanation

phenomenon ISIS'98 composed players improved capabilities monitoring environment (such better knowledge environment).

ISIS'98

therefore dependent communications teams, ISIS'97, composed
players lesser environment monitoring capabilities. ISIS'98 players better able
select correct plan without relying teammates.

Thus, would able

maintain level performance communications used. contrast,
ISIS'97 players rely passing information (monitoring other)
communications, took much longer establish agreement communications available.
validate hypothesis suggested ATA measurements looking overall
team-performance games, measured score dierence end game.
Table 10 shows mean score dierence series games Andhill'97.
rst column lists communications settings (with without).
third columns show

mean

second

score-dierence games ISIS'97 ISIS'98.



bottom row summarizes results t-tests run set games, determine
signicance level dierence mean score-dierences. score-dierence
results corroborate ATA results. dierence mean score-dierence indeed
statistically signicant ISIS'97 games, signicant ISIS'98 games. supports
explanation situationally aware ISIS'98 indeed better able handle
loss communications ISIS'97.

131

fiKaminka Tambe

ISIS'97

ISIS'98

Communication Used

-3.38

-1.53

Communication Used

-4.36

-2.13

t-test p/null hypothesis

p=0.032

p=0.13

Table 10: ISIS'97 ISIS'98 mean score dierence Andhill'97, changing communications settings

general lesson emerging experiments trade-o exists addressing monitoring selectivity problem. knowledge maintained teammates
(here, via communications) traded, extent, knowledge maintained
environment.

designer therefore range alternative capabilities

choose agents. Dierent domains may better facilitate implicit coordination monitoring environment, others require agents rely communications explicit
knowledge team-members handle coordination.
ATA results support additional conclusions, especially combined general
performance measure score-dierence.

illustrate, consider plots

actual data games. Figure 7 plots ATA values four variants,
Goalies sub-team.

graph plots approximately 60 data-points.

see Figure

7 communications used, ISIS'97's ATA values still generally better
ISIS'98's ATA without communications. Thus, despite importance, individual situational
awareness able fully compensate lack communications.

Average Time Agreement (ATA)

90
80
70
60
50

40
30
20
10
0
ISIS98/Comm.

ISIS97/Comm.

ISIS98/No-Comm. ISIS97/No-Comm.

Goalies Sub-Team
(a) ATA Values Goalies subteam

Figure 7: ATA values Goalies sub-teams games Andhill'97.

132

fiRobust Agent Teams via Socially-Attentive Monitoring

Teamore demonstrates reuse teamwork monitoring techniques developed

earlier sections o-line conguration. designer ISIS'97 set agents
use communications, since signicant improvement score-dierence.
contrast, without communications, ISIS'98 players able maintain
collaboration. Thus communications takes precious resources, relatively safely
eliminated ISIS'98 agents' design, development eorts directed
components agents.

7. Beyond Teamwork
presented general socially-attentive monitoring framework detect failures
maintaining agreement joint team plans.

However, eective operation teams often

relies additional relationships, briey address section.

7.1 Richer Agreement Model: Agreeing Disagree
teamwork model requires joint execution team plans. service agreed-upon
joint plans, agents may sometimes agree execute dierent sub-plans individually, split
sub-teams execute dierent sub-team plans. Two examples may serve illustrate.

Example 3.

ModSAF domain, helicopters engage enemy repeatedly following

masking ), popping (unmask-

following three steps: hiding behind hill trees (

ing ),

shooting missiles enemy, back hiding. variations

plan, required make sure two helicopters shooting time.
course, due limits communications, helicopters fail unmask time.

Example 4.

RoboCup domain, 11 players ISIS'97 ISIS'98 (Marsella

et al., 1999) divided four sub-teams: mid-elders, attackers, defenders, goalies
(the goalie two close defenders). division sub-teams modeled agents

play team plan (see Figure 8). Mid-elders
must select midfield plan, goalies must select defend-goal plan, etc. Again, ideally
attacker would never select plan attack, defender would select
plan defend, etc. However, due communication failures, players may sometimes
selecting one four team plans service

accidently abandon intended sub-team, execute team-plan another sub-team.
[WinGame]
[Play]

[Attack]
[Simple
Advance]
.....
Scoregoal

[Flank
Attack]
...
Pass

[Interrupt]
...

[Defend]
......

[Midfield]
...........

[DefendGoal]

[Careful
defense]
Intercept

kickout

[Simplegoal
defense]
.....
Reposition

Figure 8: Portion plan-hierarchy used ISIS RoboCup agents.

examples, certain dierences agents agreed upon
sign correct execution, failure. Indeed, lack dierence selected plans

133

fiKaminka Tambe

would indicate failure cases. use term

mutual-exclusion coordination

refer relationships. Example 3, ideally two pilots executing
plan time.



shooting

Example 4, two members dierent sub-teams (e.g.,

attacker defender) executing plan service

play (e.g., defend).



examples demonstrate, clear need monitoring mutual-exclusion coordination.
results previous sections re-used service socially-attentive monitoring
mutual-exclusion relationships. require transformation implementation
theory. hierarchies compared usual manner, except failures signied
equalities, rather dierences. instance, attacker staying team's
half eld, teammates may come suspect mistakenly defected
attackers' sub-team believes defender.
analytical results inverted well. maximal team-coherence heuristic
lead completeness, since prefers hypotheses contain equalities among agents,
failures mutual-exclusion coordination. maximal team-incoherence heuristic lead sound detection, prefers hypotheses imply equalities
occurred. properties proven formally.

Theorem 5. Let monitoring agent

monitor mutual-exclusion relationships group
agents G. A's modeling G complete, uses maximally team-incoherent
hypothesis detection, failure detection results sound.

Proof.

Provided appendix A.

Theorem 6. Let monitoring agent

monitor mutual-exclusion relationships group
agents G. A's modeling G complete, uses maximally team-coherent
hypothesis detection, failure detection results complete.
Proof.



Provided appendix A.

Thus mutual-exclusion relationships, teamwork relationships, guaranteed failuredetection results may still provided despite use limited, uncertain knowledge
monitored agents. centralized teamwork monitoring algorithms easily transformed monitoring mutual-exclusion relationships. Unfortunately, results
distributed case (Theorem 4) cannot easily transformed, since rely
property observable-partitioning, associated dierences, equalities.
leave issue future work.

7.2 Monitoring Using Role-Similarity Relationships
section applies socially-attentive monitoring role-similarity relationships, monitoring individual performance within teams. particular, service team-plans agents
may select individual sub-plans, necessitate agreement team-members,
constrained agents' roles.

fly-flight-plan

instance, service executing team-plan

(Figure 3) pilots individually select individual plans set

velocity heading within constraints formation ight method specied
mission.
Role similarity relationships specify ways given individual plans similar,
extent.

Two agents role executing dissimilar plans

134

fiRobust Agent Teams via Socially-Attentive Monitoring

considered violation role-similarity relationships. enables sociallyattentive monitoring system detect failure role-execution. monitor individual plans
agent executing, compares selection agents

role,

similarly method used teamwork. plans considered similar
role-similarity relationship model, failure detected.

Otherwise, failure may

occurred, diagnosis component called verify provide explanation.
Let us illustrate failure ModSAF domain system able
detect using role-similarity relationship:

Example 5.

team three helicopters take base head

mission. However, one pilot agents failed correctly process mission statement.
therefore kept helicopter hovering base, teammates left execute
mission themselves.
failures detected using role-similarity relationship monitoring. agreed-upon
team-plan selected agents, problem teamwork relationship
detected. team-plan involved agent selecting individual methods ight,
determine altitude velocity.

agents diered.

failing helicopter

remained hovering, teammates moved forward. Using role similarity relationship,
failing helicopter compared selected plan teammate (who shared
role subordinate formation), realized plans dissimilar enough
announce possible failure.
Unfortunately, actual similarity metrics seem domain- task-specic,
thus easy re-use across domains. Furthermore, detected failures necessarily real failures, detected failures weight.

currently

investigating ways address challenging issues.

8. Related Work
investigation socially-attentive monitoring, relationship knowledge
maintained agents' states monitoring eectiveness builds research dierent subelds multi-agent systems. address sub-elds section, explain
investigation related existing literature.

8.1 Related Work Teamwork
Previous work teamwork recognized monitoring agents critical teams.
Past investigations raised monitoring selectivity problem, addressed
depth. Building upon investigations, paper begins provide in-depth
answers problem.
theory SharedPlans (Grosz & Kraus, 1996, 1999) touches teamwork monitoring selectivity problem several ways, provides initial answers. First,
theory requires agents know teammates capable carrying tasks
team.

authors note agents must communicate enough plans

convince teammates ability carry actions (Grosz & Kraus, 1996,
p. 314). Second, theory requires agents mutual-belief shared recipe,

135

fiKaminka Tambe

state requires agents reason innite recursion agent's beliefs.

Un-

fortunately, attainment mutual belief undecidable theory (Halpern & Moses, 1990)
hence must approximated practice (Jennings, 1995; Rich & Sidner, 1997).
approximations may still impose strong monitoring requirements. Third, theory introduces
intention-that construct service coordination helpful behavior, implying monitoring others' progress assess need behavior (Grosz & Kraus, 1996,
Axiom A5-A7).

Fourth, SharedPlans requires intentions agent must con-

ict (Grosz & Kraus, 1996, Axiom A1), since intentions (in particular,
intentions-that) may involve attitudes agents, monitoring others
detect avoid conicts implied. authors point theoretically
conicts detected, infeasible practice (Grosz & Kraus, 1996, p. 307).
suggest conict detection prevention investigated problem-specic manner
within minimal constraints (i.e., monitoring capabilities, mutual-belief, progress, lack
conicts) provided SharedPlans framework (p. 308 314).
Joint-Intentions (Levesque et al., 1990; Cohen & Levesque, 1991) requires agent
privately comes believe joint-goal either achieved, unachievable, irrelevant,
must commit entire team mutually believe case. theory
SharedPlans, Joint-Intentions' use mutual belief approximated practice,
imposes strong monitoring requirements. Thus, monitoring selectivity problem
raised practical implementations Joint-Intentions.
Jennings hypothesized two central constructs cooperative multi-agent coordination

commitments

made agents,

conventions, rules used monitor

commitments (Jennings, 1993). conventions used decide information needs
monitored agents, monitored. instance, convention may
require agent report teammates changes privately detects respect
attainability team goal.

Jennings raises monitoring selectivity problem

provides example specic conventions high- low-bandwidth situations
knowledge communicated agents bandwidth available.
However, Jennings explore in-depth question conventions selected, trade-os guarantees associated selection particular
conventions. instance, guarantees eects using low-bandwidth
convention example.
theoretical investigations described raise monitoring selectivity problem (implicitly explicitly). work builds upon address problem depth,
context socially-attentive monitoring teams. paper reports soundness
and/or completeness properties teamwork relationship failure-detection analytically guaranteed, despite uncertainty knowledge acquired monitored agents.
analytical guarantees applicable plan-recognition communications,
corroborated empirical results.
Building theoretical work, practical teamwork systems include (Jennings, 1995; Rich
& Sidner, 1997) (Tambe, 1997).

Jennings' investigation Joint-Responsibility

teamwork model GRATE* (Jennings, 1995) builds Joint-Intentions, similarly
implementation, requires agents agree team-plans execute.
However, GRATE* used industrial settings foolproof communications
assumed (Jennings, 1995, p.

211), thus passive monitoring (via communica-

136

fiRobust Agent Teams via Socially-Attentive Monitoring

tions) used. Although Jennings provides evaluation GRATE*'s performance
respect communication delays, guarantees provided respect failure detection. GRATE* maintains knowledge agents acquaintances models,
used keep track team-members' capabilities (in service forming
teams). However, question much knowledge used models
left unaddressed.
Rich Sidner investigate COLLAGEN collaborative user-interface system,
communications reliable (Rich & Sidner, 1997). However, human-usability
perspective, limiting amount communications still desirable.

address is-

sue, recent empirical work Lesh, Sidner Rich (1999) utilizes plan recognition
COLLAGEN; focus work using collaborative settings make
plan-recognition tractable.

instance, ambiguities plan-recognition may resolved

asking user clarication. Work COLLAGEN investigate much
knowledge maintained eective collaborative dialogue user. contrast,
able provide guarantees failure-detection results algorithms. Also,
analysizing dialogue plans

risky points

may allow systems COLLAGEN

decide whether use communications clarication regardless plan-recognition ambiguity.
STEAM (Tambe, 1997) maintains limited information ability team-members
carry roles. STEAM also allows team-members reason explicitly
cost communication deciding whether communicate not. work signicantly
extends capabilities via plan-recognition, provides analytically-guaranteed faultdetection results. Furthermore, teamwork failure-detection capabilities useful
trigger STEAM's re-planning capabilities.

8.2 Related Work Coordination
Huber (1995) investigated use probabilistic plan-recognition service active teamwork monitoring, motivated unreliability costs passive communications-based
monitoring military applications. Washington explores observation-based coordination using Markov Models (Washington, 1998), focusing making computations tractable.
contrast Huber Washington, work focuses monitoring selectivity problem.
showed strengths limitations centralized distributed approaches guaranteed failure-detection results using coherence-based disambiguation plan-recognition
hypotheses.
Durfee (1995) discusses various methods reducing amount knowledge agents
need consider coordinating others. methods discussed involve pruning parts
nested models, using communications, using hierarchies abstractions, etc.
focus work methods modeling limited, focus
work question much modeling required guaranteed performancethe
monitoring selectivity problem. provide analytical guarantees trade-os involved
using limited knowledge agents failure-detection purposes.
Sugawara Lesser (1998) report use comparative reasoning/analysis techniques service learning specializing coordination rules system distributed agents coordinate diagnosing faulty network. investigation focused

137

fiKaminka Tambe

optimizing coordination rules minimize ineciency redundancy agent's coordinating messages. Upon detecting sub-optimal coordination (via fault model), agents
exchange information local views system problem solving activity,
construct global view. compare local view global view nd
critical values/attributes missing local view therefore gave rise
sub-optimal performance problem. values attributes used constructing
situation-specic rules optimize coordination particular situations.

example,

network diagnosis agents may learn rule guides choose coordination strategy one agent performs diagnosis shares result rest
diagnosis agents. work socially-attentive monitoring similarly uses comparison
agents views drive monitoring process. However, use comparison
product relationship monitoring.

Sugawara Lesser's work

viewed letting agents incrementally optimize monitoring requirements,
results analytically explore level monitoring required eective failure-detection,
dierent congurations. teamwork monitoring technique addresses uncertainty
acquired information, construct global view attributes systemas
would extremely expensive. Instead, technique focuses triggering failure detection via contrasting plans, incrementally expanding search dierences
diagnosis process.
Robotics literature also raised monitoring selectivity problem.

Parker (1993)

investigated monitoring selectivity problem dierent perspective, formationmaintenance task. empirically examined eects combining socially-attentive information (which referred local) knowledge team's goals, concludes
fault-tolerant strategy one agents monitor well
progress towards goals.

Kuniyoshi et al.

(Kuniyoshi, Rougeaux, Ishii, Kita, Sakane,

& Kakikura, 1994) present framework cooperation observations, robots
visually attend others prerequisite coordination. framework presents several
standard attentional templates, i.e., monitors whom. dene team attentional
structure one agents monitor other.

work focuses mon-

itoring selectivity problem within socially-attentive monitoring teamwork relationships,
provides analytical well empirical results. treat attentional templates
product relationships hold system. results show monitoring
teams may necessarily require monitoring team-members.

8.3 Related Work
Horling et al.

(Horling, Lesser, Vincent, Bazzan, & Xuan, 1999) present distributed

diagnosis system multi-agent intelligent home environment.The system uses faultmodels identify failures ineciencies components, guide recovery. Schroeder
Wagner (1997) proposed distributed diagnosis technique cooperating agents
receive requests tests diagnoses, send responses agents.



construct global diagnosis based local ones produce receivewith
assumption conicts occur.

Frohlich Nejdl (1996) investigates scheme

multiple diagnosis agents cooperate via blackboard architecture diagnosing
physical system. agents may use dierent diagnosis models systems, centralized

138

fiRobust Agent Teams via Socially-Attentive Monitoring

conict-resolution agent employed handle conicts diagnoses found. three
approaches address monitoring selectivity problem.
social measures related ATA. Goldberg Mataric (1997) in-

interference amount time robots
social entropy (Bailey, 1990) measure be-

vestigate multi-robot foraging task measure
spend avoiding other. Balch (1998) uses

havioral diversity

multi-agent tasks soccer, foraging, formation-maintenance.

investigations focus characterizing heterogeneity multi-agent systems relation
performance. contrast, focus work providing useful feedback
designer.

Possible correlation task performance ATA values remains

investigated.

9. Conclusions Future Work
work presented paper motivated practical concerns. begun
investigation monitoring selectivity problem result observation failures
continue occur despite agents' use monitoring conditions communications.
Analysis failures revealed agents suciently informed other's
state. need monitor one's teammates recognized repeatedly past
(Jennings, 1993; Grosz & Kraus, 1996; Tambe, 1997), monitoring selectivity problem
question much monitoring requiredremained largely unaddressed (Jennings,
1993; Grosz & Kraus, 1996).
provide key answers monitoring selectivity problem.

Within context

socially-attentive monitoring teams, demonstrate teamwork relationship failures
detected eectively even uncertain, limited, knowledge team-members' states.
show analytically centralized active teamwork monitoring provides failure-detection
either complete unsound, sound incomplete. However, centralized teamwork monitoring requires multiple hypotheses monitoring team-members.



contrast, distributed active teamwork monitoring results complete sound failuredetection, despite using simpler algorithm monitoring key agents team.
Using implemented general framework socially-attentive monitoring, empirically validate results ModSAF domain. also provide initial results monitoring mutual-exclusion role-similarity relationships, initial diagnosis procedures.
demonstrate generality framework applying RoboCup
domain, show useful quantitative analysis generated o-line.
ModSAF RoboCup dynamic, complex, multi-agent domains involve many uncertainties perception action.
attempted demonstrate results techniques applied
domains.

explicitly pointed necessary conditions theorems hold,

observable-partitioning team-modeling completeness. presented diagnosis
algorithm sensitive accuracy knowledge used, may require assuming
plans recognized soon selected. conditions veried
designer target application domain. Reactive plans (our chosen representation)
commonly used many dynamic multi-agent domains. focus monitoring agreements
joint plans stems centrality similar notions agreement agent human
teamwork literature (Jennings, 1995; Grosz & Kraus, 1996; Volpe et al., 1996; Tambe, 1997).

139

fiKaminka Tambe

made several references additional areas would like conduct
investigations.

One important topic plan investigate depth strong

requirements distributed teamwork monitoring algorithm terms observability.
order provide soundness completeness guarantees, distributed algorithm relies
ability team-members monitor key agents. investigating ways
relax requirement still providing guaranteed results. addition, diagnosis
procedures extended formalized, would like investigate ways
alleviate sensitivity procedures choice team-modeling hypothesis.

Acknowledgments
article partially based AAAI-98 paper (Kaminka & Tambe, 1998),
Agents-99 paper (Kaminka & Tambe, 1999) authors. research supported part NSF Grant ISI-9711665, part AFOSR contract #F49620-97-10501. thank Je Rickel, George Bekey, Victor Lesser, Dan O'Leary, David Pynadath
many useful comments. anonymous reviewers thanks helping us crystallize ideas contributions revisions paper.

Appendix A. Proofs
Theorem. (# 2, page 123). Let monitoring agent monitor simple team . A's
team-modeling complete, uses maximally team-coherent hypothesis detection, teamwork failure detection results sound.
Proof.

show failure occurs detected, thus failures

detected. Let a1 ; : : : ; agent members . agent ai executing
plan Pi (1 n).

Thus collectively, group executing (P1 ; : : : ; Pn ).

failure

occurred, two agents ak ; aj ; 1 j; k n aj executing plan
Pj ak executing plan Pk Pj 6= Pk .

Since A's team-modeling complete,

correct hypothesis (P1 ; : : : ; Pj ; : : : ; Pk ; : : : Pn ) set team-modeling hypotheses.
Since choose maximally team-incoherent hypothesis, either choose correct
hypothesis, incoherent hypothesis implying failure occurred,
select hypothesis greater incoherence hypothesis (or equivalent level).
case, failure would detected, detection procedure complete.

Lemma. (#

1, page 127). Suppose simple team self-monitoring (all members
team monitor other) using maximally team-coherent heuristic (and
assumption agent, team-modeling complete). monitoring agent A1
member executing P1 would detect failure maintaining teamwork relationships
agent A2 (also member ) executing dierent plan P2 , A2 observably
dierent role P1 P2 .

Proof.

A1 knows executing P1 .

Since members monitor

themselves, A1 monitoring A2 , observably dierent role P1 P2 . Since A2
executing P2 , following observably dierent role, P1 2
= (A1 ; A2 =P2 ). Therefore
perspective A1 , cannot case assigns P1
hypothesis, therefore

team-modeling

agent-modeling

hypothesis A1 A1 executing

140

fiRobust Agent Teams via Socially-Attentive Monitoring

P1 , A2 executing plan P1 . words, A1 's perspective

team-coherent hypothesis, dierence would detected A1 A2 .

Theorem. (# 5, page 134). Let monitoring agent monitor mutual-exclusion relation-

ships group agents G. A's modeling G complete, uses maximally
team-incoherent hypothesis detection, failure detection results sound.
Proof.

show failure occurred, none detected, thus

failure detected fact failure.
G.

Let a1 ; : : : ; agent members

agent ai executing plan Pi (1 n). Thus collectively, group

executing (P1 ; : : : ; Pn ). failure occurred, agent executing dierent
plan (i 6= j ) Pi 6= Pj ). Since A's group-modeling complete, correct hypothesis
going set group-modeling hypotheses H . Since maximally incoherent
hypothesis, either selected, dierent hypothesis

level

selected.

coherence

hypothesis coherence level correct one

implies failure detected. Thus detection procedure sound.

Theorem. (# 6, page 134). Let monitoring agent monitor mutual-exclusion relation-

ships group agents G. A's modeling G complete, uses maximally
team-coherent hypothesis detection, failure detection results complete.
Proof.

show failure occurs detected, thus procedure

complete. Let a1 ; : : : ; agent members G. agent ai executing
plan Pi (1 n).

Thus collectively, group executing (P1 ; : : : ; Pn ).

failure

occurred, two agents ak ; aj ; 1 j; k n aj executing plan
Pj ak executing plan Pk Pj

=

Pk .

Since A's group-modeling complete,

correct hypothesis (P1 ; : : : ; Pj ; : : : ; Pk ; : : : Pn ) set group-modeling hypotheses.
Since choose maximally team-coherent hypothesis, either choose correct
hypothesis, coherent hypothesis implying failure occurred,
select hypothesis greater coherence hypothesis (or equivalent level).
case, failure would detected. Therefore, detection procedure complete.

Appendix B. Socially-Attentive Monitoring Algorithms
bring algorithms (in pseudo-code) RESL plan-recognition algorithm,
comparison test supporting detection simple non-simple teams,
monitoring algorithms centralized distributed cases.

B.1 RESL
RESL works rst expanding complete operator hierarchy agents modeled, tagging plans non-matching. plans' preconditions termination conditions
agged non-matching well. plans' actions set used expectations
behavior. initializing plan-recognition hierarchy monitored agent, observations agent continuously matched actions expected plans.
Plans whose expectations match observations tagged matching, ags
propagated along hierarchy, down, complete paths hierarchy

141

fiKaminka Tambe

agged matching not. paths specify possible matching interpretations
observations. addition, precondition termination conditions agged true
not, signifying inferred appropriate belief modeled agents.

process

described Algorithm 1.

Algorithm 1 RESL's main loop, matching

observation making inferences given

plan-recognition hierarchy (a single agent).
1.

Get observations agent

2.

plan set expected observations:
(a) Compare observations expectations
(b) succeed, ag plan matching successfully, otherwise ag plan failing match

3.

plan agged matching successfully
(a) Flag parents matching successfully // propagate matching

4.

plan whose children (all them) agged failing match
(a) Flag failing match // propagate non-matching

B.2 Detection Failure, Centralized Distributed Teamwork Monitoring
Algorithm 2 shows comparison hierarchical plans carried out. limit
simple-teams. algorithm accepts input two sets hierarchical plan hypotheses, two associated agents (for clarity, algorithms assume two agents.
generalization n agents straightforward). algorithm also accepts policy ag,

Policy.



OPTIMISTIC

policy causes algorithm use maximal team-coherence

provide sound, incomplete detection.

PESSIMISTIC policy causes algorithm use

maximal team-incoherence provide complete, unsound detection.

hierarchy_1 hierarchy_2. two agents
agent_2. algorithm makes use predicate Sub-team,
true two agents (Agent1, Agent2) belong dierent sub-teams given
level hierarchy (Depth).
set hierarchical plans marked

marked

agent_1



aid Algorithm 2, dene centralized distributed failure detection algorithms.

centralized teamwork monitoring algorithm (Algorithm 3)

utilizes Algorithm 2 twice, checking failures

PESSIMISTIC



OPTIMISTIC

policies. results policies agree, certain. results agree,
(i.e.,

PESSIMISTIC

policy causes failure detected,

OPTIMISTIC

policy

causes failure detected), monitoring agent cannot certain failure
taken place, therefore needs verify failure.

Algorithm 3 therefore returns

FAILURE, NO_FAILURE, POSSIBLE_FAILURE.
distributed monitoring algorithm given pseudo-code form,
nothing call Algorithm 2

142

OPTIMISTIC

policy parameter. power

fiRobust Agent Teams via Socially-Attentive Monitoring

Algorithm 2 Hierarchical comparison two agents, allowing sub-teams.
1.

Set Depth 0 //

2.

plans depth Depth team-plans
(a)

look top-most dierence rst

Policy == OPTIMISTIC
i. Let Plan_1, Plan_2 maximally team-coherent plans level Depth
hierarchy_1 hierarchy_2, respectively.
ii. else Let Plan_1, Plan_2 maximally team-incoherent plans level Depth
hierarchy_1 hierarchy_2, respectively.

(b)

Plan_1 equal Plan_2
i. return FAILURE
ii. else bottom hierarchies reached, return NO_FAILURE, otherwise increase Depth go 2.

3.

one plan team-plan, return FAILURE, else return NO_FAILURE.

Algorithm 3 Centralized Teamwork Monitoring, applying optimistic pessimistic
views.
1.

2.

Let Optimistic_Result = Detect(agent_1, agent_2, hierarchies_1,
hierarchies_2, OPTIMISTIC)
/* algorithm 2 */
Let Pessimistic_Result = Detect(agent_1, agent_2, hierarchies_1,
hierarchies_2, PESSIMISTIC)
/* algorithm 2 */

3.

Optimistic_Result == Pessimistic_Result

4.

return Optimistic_Result /*

5.

else return POSSIBLE_FAILURE

either

143

FAILURE,



NO_FAILURE */

fiKaminka Tambe

derived fact members team using monitor key agents
team.

References
Ambros-Ingerson, J. A., & Steel, S. (1988). Intergrating planning, execution monitoring.


Proceedings Seventh National Conference Articial Intelligence (AAAI-88)

Minneapolis/St. Paul, MN. AAAI Press.
Andou, T. (1998). Renement soccer agents' positions using reinforcement learning.
Kitano, H. (Ed.),

RoboCup-97: Robot soccer world cup 1, Vol. LNAI 1395, pp. 373388.

Springer-verlag.
Atkins, E. M., Durfee, E. H., & Shin, K. G. (1997). Detecting reacting unplanned-

Proceedings Fourteenth National Conference Articial
Intelligence (AAAI-97), pp. 571576 Providence, RI. AAAI Press.
world states.

Bailey, K. D. (1990).
Balch, T. (1998).

Social Entropy Theory.

State University New York Press.

Behavioral Diversity Learning Robot Teams.

Ph.D. thesis, Georgia

Institute Technology.
Calder, R. B., Smith, J. E., Courtemanche, A. J., Mar, J. M. F., & Ceranowicz, A. Z. (1993).

Modsaf behavior simulation control. Proceedings Third Conference
Computer Generated Forces Behavioral Reresentation Orlando, Florida. Institute
Simulation Training, University Central Florida.

Cohen, P. R., Amant, R. S., & Hart, D. M. (1992).

Early warnings plan failure, false

positives, envelopes: Experiments model.

Tech. rep. CMPSCI Technical

Report 92-20, University Massachusetts.
Cohen, P. R., & Levesque, H. J. (1991). Teamwork.

Nous, 35.

Doyle, R. J., Atkinson, D. J., & Doshi, R. S. (1986). Generating perception requests
expectations verify execution plans.



Conference Articial Intelligence (AAAI-86).
Durfee, E. H. (1995).

Blissful ignorance:

Proceedings Fifth National

Knowing enough coordinate well.



Proceedings First International Conference Multiagent Systems (ICMAS-95),
pp. 406413.

Fenster, M., Kraus, S., & Rosenschein, J. S. (1995).

Coordination without communica-

Proceedings First
International Conference Multiagent Systems (ICMAS-95), pp. 102108 California,
tion: Experimental validation focal point techniques.
USA.

Firby, R. J. (1987). investigation reactive planning complex domains.

ceedings Sixth National Conference Articial Intelligence (AAAI-87).
144

Pro-

fiRobust Agent Teams via Socially-Attentive Monitoring

Frohlich, P., & Nejdl, W. (1996). Resolving conicts distributed diagnosis. Wahlster,
W. (Ed.),

12th Europeach Conference Articial Intelligence (ECAI-96).

John

Wiley & Sons, Inc.
Goldberg, D., & Mataric, M. J. (1997).

Interference tool designing evaluat-

Proceedings Fourteenth National Conference
Articial Intelligence (AAAI-97), pp. 637642 Providence, RI. AAAI Press.
ing multi-robot controllers.

Grosz, B. J., & Kraus, S. (1999). evolution sharedplans. Wooldridge, M., & Rao,
A. (Eds.),

Foundations Theories Rational Agency, pp. 227262.

Grosz, B. J., & Kraus, S. (1996). Collaborative plans complex group actions.

Intelligence, 86, 269358.

Articial

Grosz, B. J., & Sidner, C. L. (1990). Plans discourse. Cohen, P. R., Morgan, J., &
Pollack, M. (Eds.),

Intentions Communication, pp. 417445. MIT Press, Cambridge,

MA.
Halpern, J. Y., & Moses, Y. (1990). Knowledge common knowledge distributed
environment.

distributed computing, 37 (3), 549587.

Hamscher, W., Console, L., & de Kleer, J. (Eds.). (1992).

nosis.

Readings Model-Based Diag-

Morgan Kaufmann Publishers, San Mateo, CA.

Horling, B., Lesser, V. R., Vincent, R., Bazzan, A., & Xuan, P. (1999).

Diagnosis

integral part multi-agent adaptability. Tech. rep. CMPSCI Technical Report 199903, University Massachusetts/Amherst.
Huber, M. J., & Durfee, E. H. (1995).

acting together: Without communication.



Working Notes AAAI Spring Symposium Representing Mental States
Mechanisms, pp. 6071 Stanford, CA.

Jennings, N. R. (1993). Commitments conventions: foundations coordination
multi-agent systems.

Knowledge Engineering Review, 8 (3), 223250.

Jennings, N. R. (1995). Controlling cooperative problem solving industrial multi-agent
systems using joint intentions.

Articial Intelligence, 75 (2), 195240.

Johnson, W. L., & Rickel, J. (1997). STEVE: animated pedagogical agent procedural
training virtual environments.

SIGART Bulletin, 8 (1-4), 1621.

Kaminka, G. A., & Tambe, M. (1998). What's wrong us? Improving robustness

Proceedings Fifteenth National Conference Articial
Intelligence (AAAI-98), pp. 97104 Madison, WI. AAAI Press.
social diagnosis.

Kaminka, G. A., & Tambe, M. (1999).

I'm OK, You're OK, We're OK: Experiments

distributed centralized social monitoring diagnosis.



Proceedings

Third International Conference Autonomous Agents (Agents-99) Seattle, WA. ACM
Press.

145

fiKaminka Tambe

Kinny, D., Ljungberg, M., Rao, A., Sonenberg, E., Tidhar, G., & Werner, E. (1992). Planned
team activity.

Castelfranchi, C., & Werner, E. (Eds.),

Articial Social Systems,

Lecture notes AI 830, pp. 227256. Springer Verlag, New York.

Kitano, H., Tambe, M., Stone, P., Veloso, M., Coradeschi, S., Osawa, E., Matsubara, H.,

Proceedings International Joint Conference Articial Intelligence (IJCAI-97)

Noda, I., & Asada, M. (1997). RoboCup synthetic agent challenge '97.
Nagoya, Japan.

Kraus, S., Sycara, K., & Evenchik, A. (1998). Reacing agreements negotiations:
logical model implementation.

articial intelligence, 104 (1-2), 169.

Kuniyoshi, Y., Rougeaux, S., Ishii, M., Kita, N., Sakane, S., & Kakikura, M. (1994). Cooperation observation framework basic task patterns.

International Conference Robotics Automation,

IEEE

pp. 767773 San-Diego, CA.

IEEE Computer Society Press.
Lesh, N., Rich, C., & Sidner, C. L. (1999). Using plan recognition human-computer col-

Proceedings Seventh International Conference User Modelling
(UM-99) Ban, Canada.
laboration.

Levesque, H. J., Cohen, P. R., & Nunes, J. H. T. (1990). acting together.

Eigth National Conference Articial Intelligence (AAAI-90)

Proceedings

Menlo-Park,

CA. AAAI Press.
Malone, T. W., & Crowston, K. (1991).
tion.

Toward interdisciplinary theory coordina-

Tech. rep. CCS TR#120 SS WP# 3294-91-MSA, Massachusetts Institute

Technology.
Marsella, S. C., Adibi, J., Al-Onaizan, Y., Kaminka, G. A., Muslea, I., Tallis, M., & Tambe,
M. (1999).

teammate:

Experiences acquired design robocup

Proceedings Third International Conference Autonomous Agents
(Agents-99) Seattle, WA. ACM Press.

teams..

Newell, A. (1990).

Unied Theories Cognition.

Harvard University Press, Cambridge,

Massachusetts.

Proceedings
IEEE Robotics Automation Conference, pp. 582587 Atlanta, GA.

Parker, L. E. (1993). Designing control laws cooperative agent teams.

Rao, A. S. (1994). Means-end plan recognition towards theory reactive recognition.

Proceedings International Conference Knowledge Representation Reasoning (KR-94), pp. 497508.

Reece, G. A., & Tate, A. (1994). Synthesizing protection monitors causal structure.


Proceedings Articial Intelligence Planning Systems (AIPS-94) Chicago, IL.

Rich, C., & Sidner, C. L. (1997).

COLLAGEN: agents collaborate people.

Johnson, W. L. (Ed.), Proceedings First International Conference Autonomous Agents (Agents-97), pp. 284291 Marina del Rey, CA. ACM Press.

146

fiRobust Agent Teams via Socially-Attentive Monitoring

Proceedings
First International Conference Autonomous Agents (Agents-97), pp. 268275

Schroeder, M., & Wagner, G. (1997). Distributed diagnosis vivid agents.
Marina del Rey, CA. ACM Press.

Sugawara, T., & Lesser, V. R. (1998). Learning improve coordinated actions cooperative
distributed problem-solving environments.

Machine Learning, 33 (2/3), 129153.

Tambe, M. (1996). Tracking dynamic team activity.

ence Articial Intelligence (AAAI).

Tambe, M. (1997). Towards exible teamwork.

7, 83124.

Proceedings National Confer-

Journal Articial Intelligence Research,

Tambe, M., Johnson, W. L., Jones, R., Koss, F., Laird, J. E., Rosenbloom, P. S., & Schwamb,
K. (1995).

16 (1).

Intelligent agents interactive simulation environments.

AI Magazine,

Proceedings
Fourteenth National Conference Articial Intelligence (AAAI-97), pp. 39 Provi-

Toyama, K., & Hager, G. D. (1997). rst don't succeed....
dence, RI.

Veloso, M., Pollack, M. E., & Cox, M. T. (1998). Rationale-based monitoring planning
dynamic environments.

(AIPS-98) Pittsburgh, PA.

Proceedings Articial Intelligence Planning Systems

Volpe, C. E., Cannon-Bowers, J. A., & Salas, E. (1996). impact cross-training
team functioning: empirical investigation.

human factors, 38 (1), 87100.

Markov tracking agent coordination. Proceedings
Second International Conference Autonomous Agents (Agents-98), pp. 7077 Min-

Washington, R. (1998).

neapolis/St. Paul, MN. ACM Press.

147

fiJournal Artificial Intelligence Research 12 (2000) 317337

Submitted 6/99; published 5/00

Axiomatizing Causal Reasoning
Joseph Y. Halpern

halpern@cs.cornell.edu

Cornell University, Computer Science Department
Ithaca, NY 14853
http://www.cs.cornell.edu/home/halpern

Abstract
Causal models defined terms collection equations, defined Pearl,
axiomatized here. Axiomatizations provided three successively general classes
causal models: (1) class recursive theories (those without feedback), (2) class
theories solutions equations unique, (3) arbitrary theories (where
equations may solutions and, do, necessarily unique).
shown reason causality general third class, must extend
language used Galles Pearl (1997, 1998). addition, complexity
decision procedures characterized languages classes models considered.

1. Introduction
important role causal reasoningin prediction, explanation, counterfactual
reasoninghas argued eloquently number recent papers books (Chajewska
& Halpern, 1997; Heckerman & Shachter, 1995; Henrion & Druzdzel, 1990; Druzdzel &
Simon, 1993; Pearl, 1995; Pearl & Verma, 1991; Spirtes, Glymour, & Scheines, 1993).
reason causality, certainly useful find axioms characterize
reasoning. way go axiomatizing causal reasoning depends two critical
factors:
model causality,
language use reason it.
paper, consider one approach modeling causality, using structural equations.
use structural equations model causality standard social sciences,
seems go back work Sewall Wright 1920s (see (Goldberger, 1972)
discussion); particular framework use due Pearl (1995). Galles Pearl
(1997) introduce axioms causal reasoning framework; also provide
complete axiomatic characterization reasoning causality framework,
strong assumption fixed, given causal ordering equations (Galles
& Pearl, 1998). Roughly speaking, means way ordering variables
appear equations explicit axioms say Xj influence Xi
Xi Xj causal ordering.
paper, extend results Galles Pearl providing complete axiomatic
characterization three increasingly general classes causal models (defined structural
equations):
c
2000
AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiHalpern

1. class recursive theories (those without feedbackthis generalizes situation
considered Galles Pearl (1998), since every fixed causal ordering variables
gives rise recursive theory),
2. class theories solutions equations unique,
3. arbitrary theories (where equations may solutions and, do,
necessarily unique).
process, clarify problems Galles-Pearl completeness proof arise
lack propositional connectives (particularly disjunction) language
consider and, generally, highlight role language reasoning causality.
also characterize complexity decision problem languages classes
models.
rest paper organized follows. Section 2, give syntax semantics
languages considering review definition modifiable causal models.
Section 3, present complete axiomatizations. Section 4 consider complexity
decision procedure. conclude Section 5.

2. Syntax Semantics
axiomatization given respect particular language class models,
need make precise. language models use based
considered Galles Pearl (1997, 1998). make comparisons easier, use
notation much possible. start semantic model, since motivates
choices syntax, give syntax, finally define semantics formulas.
2.1 Causal Models
basic picture interested values random variables,
causal effect others. effect modeled set structural equations.
practice, seems useful split random variables two sets, exogenous
variables, whose values determined factors outside model, endogenous
variables. endogenous variables whose values described structural
equations.
formally, signature tuple (U, V, R}, U finite set exogenous
variables, V finite set endogenous variables, R associates every variable
U V nonempty set R(Y ) possible values (the range possible values ).
Unless explicitly noted otherwise, assume R(Y ) finite set U V
|R(Y )| 2. assumption U V finite relatively innocuous; shall see,
assumption R(Y ) finite impact axioms. assumption
|R(Y )| 2 allows us ignore trivial situation |R(Y )| = 1. |R(Y )| = 1,
remove variable signature without loss expressiveness.
causal model signature tuple = (S, F ) F associates
variable X V function denoted FX FX : (U U R(U )) (Y V{X}R(Y ))
R(X). FX tells us value X given values variables U V.
think functions FX defining set (modifiable) structural equations, relating
318

fiAxiomatizing Causal Structures

values variables. FX function, unique value X
set variables. Notice functions endogenous variables.
exogenous variables taken given; effect endogenous variables
(and effect endogenous variables other) modeling
structural equations.
~
Given causal model = (S, F ) signature S, (possibly empty) vector X
~ U, respectively,
variables V, vectors ~x ~u values variables X
~ R| ~ ).1
u) signature SX~ = (, VX,
define new causal model denoted TX~
~ x (~
VX
~ set ~x
Intuitively, causal model results variables X
~
~
u) = (SX~ , F X~x,~u }), FYX~x,~u obtained
variables U set ~u. Formally, TX~
~ x (~
~ ~x values variables U
FY setting values variables X
u) called submodel Pearl (1999). describe
~u. causal model TX~
~ x (~
possible counterfactual situation; is, even though, normal circumstances, setting
~ values ~
exogenous variables ~u may result variables X
x0 6= ~x,
submodel describes happens set ~
x due external action,
cause modeled explicitly. example, determine manufacturer
fault accident involved poorly maintained car, may want consider
would happened car well maintained. random variable
signature describes well maintained car is, means examining
submodel random variable set 1 (the car well maintained).
ability examine counterfactual situations makes causal structures useful tool
reasoning causality.
Notice that, general, may unique vector values simultaneously
satisfies equations TX~
u); indeed, may solution all. One special
~ x (~
case guaranteed unique solution total ordering
variables V X , FX independent value ;
i.e., FX (. . . , y, . . .) = FX (. . . , 0 , . . .) y, 0 R(Y ). case, causal model
said recursive acyclic. Intuitively, theory recursive, feedback.
X , value X may affect value , value effect
value X.
clear recursive theory, always unique solution
~ ~
equations TX~
u), X,
x, ~
u. (We simply solve variables
~ x (~
order given .) hand, following example shows, hard
construct nonrecursive theories always unique solution equations
arise.
Example 2.1: Let = (, {X, }, R}), R(X) = R(Y ) = {1, 0, 1}, let =
(S, F ), FX characterized equation X = FY characterized
equation = X (that is, FX (y) = FY (x) = x). Clearly recursive;
value X depends value value depends X. Nevertheless,
easy see unique solution X = 0, = 0, TXx unique solution
= x, TY unique solution X = y.
~ subset V consisting variables X.
~
1. implicitly identifying vector X
~


restriction

R


variables

V

X.
throughout paper. R|VX
~

319

fiHalpern

paper, consider three successively general classes causal models
given signature = (U, V, R).
1. Trec(S): class recursive causal models signature S,
~ V, ~x, ~u,
2. Tuniq(S): class causal models X
u) unique solution,
equations TX~
~ x (~
3. (S): class causal models S.
often omit signature clear context irrelevant, reader
bear mind important role.
interested causal models possess unique solutions?
real causal systems possess unique solutions? issue whether
nonrecursive system given causal interpretation discussed length
Strotz Wold (1960). argue reasonable ways interpreting causal
interpretations answer yes. interpretations, may well
one solution equations. Perhaps best way view equations
think variables V mutually interdependent; changing one may
cause change others. (Think demand supply economics populations
rabbits wolves.) solutions equations represent equilibrium situations.
one equilibrium, one solution equations.
course, equilibria, solutions equations.
related way thinking equations represent atemporal versions
temporal causal equations. is, suppose replace every variable U V
family variables Y0 , Y1 , Y2, . . ., where, intuitively, Yt represents value time t.
equation fX F replaced family equations fXt , fXt depends
exogenous variables Ut0 t0 endogenous variables Yt0 t0 < t. gives
us recursive system. values Xt setting variables subscript 0
represents evolution X setting variables. Xt eventually stabilizes,
might expect equilibrium value value X solution
original set equations. Xt stabilizes, would solution original
set equations.
2.2 Syntax
focus two languages. languages parameterized signature S.
first language, L+ (S), borrows ideas dynamic logic (Harel, 1979). Again, often write
L+ rather L+ (S) (and similarly languages defined below) simplify
notation. basic causal formula one form [Y1 y1 , . . . , Yk yk ],
Boolean combination formulas form X(~u) = x, Y1 , . . . , Yk , X variables V,
Y1 , . . . , Yk distinct, x R(X), ~u vector values variables U.
~ ~
typically abbreviate formula [Y
]. special case k = 0 (which
~
allowed) abbreviated [true]. [Y ~
]X(~u) = x interpreted possible
solutions structural equations obtained setting Yi yi , = 1, . . ., k,
exogenous variables ~u, random variable X value x. shall see, formula
true causal model solutions equations TY~ ~y (~u), random
320

fiAxiomatizing Causal Structures

variable X value x. Note formula trivially true solutions
structural equations. causal formula Boolean combination basic causal
formulas.
~ ~y i(X(~u) = x)
dynamic logic, also define formula hY
~ ~y](X(~u) = x). hY
~ ~
~ ~
abbreviation [Y
i(X(~u) = x) dual [Y
](X(~u) =
x); true if, solution structural equations obtained setting Yi
yi , = 1, . . ., k, exogenous variables ~u, random variable X value x. Taking
true(~u) abbreviation X(~u) = x X(~u) 6= x variable X x R(X),
~ ~
taking false(~u) abbreviation true(~u), hY
itrue(~u) true
solution equations obtained setting Yi yi , = 1, . . . , k,
~ ~
variables U ~u (since [Y
]false(~u) says every solution equations
obtained setting Yi yi U ~
u, formula false(~u) true, thus holds exactly
equations solution).
Let Luniq(S) sublanguage L+ (S) consists Boolean combinations
~ ~y]X(~u) = x. Thus, difference Luniq L+
formulas form [Y
~ ~
], L+ , arbitrary Boolean
Luniq, X(~u) = x allowed [Y
combinations formulas form X(~u) = x allowed. shall see, reasoning
causality Tuniq, language Luniq adequate, since equivalent expressive
power L+ . However, longer case reasoning causality .
~ ~y ]X(~u) = x X ~ (~u) = x.
Following Galles Pearls notation, often write [Y
~

~ clear context irrelevant, abbreviate X~y (~u) = x. (This

actually notation used Galles Pearl.) Let LGP (S) sublanguage Luniq(S)
consisting conjunctions formulas form X~y (~u) = x. particular,
contain disjunctions negations formulas. Although Galles Pearl (1998)
explicit language using, seems LGP .2
2.3 Semantics
formula L+ (S) true false causal model (S). usual, write |=
causal formula true causal model . basic causal formula,
~ ~y](X(~u) = x) solutions ~ (~u) (i.e., vectors values
|= [Y
~

~

~ simultaneously satisfy equations F ~y , Z V Y~ ),
variables V
Z
variable X value x. define truth value arbitrary causal formulas,
Boolean combinations basic causal formulas, obvious way:
|= 1 2 |= 1 |= 2
|= 6|= .
usual, say formula valid respect class 0 causal models
|= 0 .
make precise earlier claim Tuniq (and hence Trec), language
Luniq expressive full language L+ .

Lemma 2.2: following formulas valid Tuniq:
2. confirmed Judea Pearl [private communication, 1997].

321

fiHalpern

~ ~y]( ) [Y
~ ~
~ ~
(a) Tuniq |= [Y
] [Y
],
~ ~y]( ) [Y
~ ~
~ ~
(b) Tuniq |= [Y
] [Y
],
~ ~y] [Y
~ ~
(c) Tuniq |= [Y
].
Hence, Tuniq, every formula L+ equivalent formula Luniq.
Proof: Straightforward; left reader.
~ ~
Note follows equivalences Tuniq, [Y
] equivalent
~
hY ~yi. also worth noting Lemma 2.2(b) holds arbitrary causal models
, Tuniq. However, parts (a) (c) not, following example shows.
Example 2.3: Let = (, {X, }, R), R(X) = R(Y ) = {0, 1}; let = (S, F ),
FX characterized equation X = FY characterized equation
= X. Clearly
/ Tuniq; (0, 0) (1, 1) solutions . easy see
|= [true](X = 0 X = 1) [true](X = 0) [true](X = 1), showing part (a)
Lemma 2.2 hold , |= [true](X = 1) [true](X = 1), showing
part (c) hold either.

3. Complete Axiomatizations
briefly recall standard definitions logic. axiom system AX consists
collection axioms inference rules. axiom formula (in predetermined language L), inference rule form 1, . . . , k infer , 1, . . . , k ,
formulas L. proof AX consists sequence formulas L,
either axiom AX follows application inference rule. proof said
proof formula last formula proof . say provable AX,
write AX ` , proof AX; similarly, say consistent
AX provable AX.
axiom system AX said sound language L respect class 0
causal models every formula L provable AX valid respect 0 . AX
complete L respect 0 every formula L valid respect 0
provable AX.
want find axioms characterize classes causal models
interested, namely Trec, Tuniq, . deal Trec, helpful define
Z,
read affects Z, abbreviation formula

;

XV,~
~
x

uU U R(U ),z6=z
XV R(X),yR(y),~

0 R(Z)

(Z~xy (~u) = z 0 Z~x (~u) = z).

Thus, affects Z setting exogenous variables endogenous variables changing value changes value Z. definition
used axiom C6 below, characterizes recursiveness.
Consider following axioms:
C0. instances propositional tautologies.
C1. X~y (~u) = x X~y (~u) 6= x0 x, x0 R(X), x 6= x0
322

(equality)

fiAxiomatizing Causal Structures

C2. xR(X)X~y (~u) = x

(definiteness)

C3. (W~x(~u) = w Y~x (~u) = y) Y~xw (~u) =

(composition)

C4. Xxw~ (~u) = x

(effectiveness)

C5. (Y~xw (~u) = W~xy (~u) = w) Y~x (~u) =

(reversibility)

C6. (X0

;X

1

. . . Xk1

; X ) (X ; X )
k

k

(recursiveness)

0

one rule inference:
MP. , infer

(modus ponens)

C1 states obvious property equality: X = x every solution
equations T~x (~u), cannot X = x0 , x0 6= x.3 richer language, could
expressed (X~y (~u) = x X~y(~u) = x0 ) (x = x0 ), formula L+
(since L+ include expressions x0 = x). C2 states value
x R(X) value X solutions equations T~x(~u). C2 valid
, valid Tuniq. Note stating C2, making use fact
R(X) finite (otherwise C2 would involve infinite disjunction, would longer
formula Luniq). fact, shown allow signatures sets R(X)
infinite, include C2 random variables X R(X) finite.4
C3C5 introduced Galles Pearl (1997, 1998), names. Roughly
speaking, C3 says value W w solutions equations T~x(~u),
solutions equations T~xw (~u) solutions equations
T~x (~u). C3 valid well Tuniq. shall see, variant C3 (obtained
replacing some) also valid . C4 simply says solutions obtained
setting X x, value X x. C5 perhaps least obvious axioms;
~ ~x W
proof soundness straightforward. says setting X
~
w results value setting X ~
x results W value
~ x (and W must already value
w, must already value set X
w).
Finally, easy see C6 holds recursive models.
Z, must
X1 . . . Xk1
Xk , X0 must
precede Z causal ordering. Thus, X0
precede Xk causal ordering, Xk cannot affect X0. Thus, (Xk
X0 ) holds.
shall see, precise sense, C6 characterizes recursive models.
C6 viewed collection axioms (actually, axiom schemes), one k.
case k = 1 already gives us (Y
Z) (Z
) variables Z.

;

;

;

;
;

;

3. earlier draft paper, C1 C2 introduced, C1 called uniqueness. Galles
Pearl (1998) adopted name well. retrospect, axiom really say anything
uniqueness. axiom D10, discussed later.
used C6
4. assumption R(X) V finite also necessary abbreviation X
Luniq ; however, replace C6 axiom scheme

;

ui ) = zi (Xi+1 )~yi = zi0 ) (X0 )~yk xk (~
uk ) = zk (X0 )~yk = zk0 ),
(k1
yi xi (~
i=0 (Xi+1 )~
xi R(Xi) = 1, . . . , k. is, essentially replace C6 instances. axiom
equivalent C6 (although transparent) expressed even |V| infinite |R(X)|
infinite X V.

323

fiHalpern

is, tells us that, pair variables, one affects other. However,
restricting C6 case k = 1 suffice characterize Trec, following
example shows.
Example 3.1: Let = (, {X0, X1, X2}, R), R(X0) = R(X1) = R(X2) = {0, 1, 2},
let = (S, F ), FXi characterized equation
(

Xi =

2 Xi1 = 1
0 otherwise

addition mod 3. easy see Tuniq: variables set,
equations completely determine values variables. hand,
none variables set, easy see (0, 0, 0) solution satisfies
equations. Moreover, TX~
~ x , variable Xi 0 unless set value
0 Xi1 set 1. easily follows Xi affected Xi1 . straightforward
verification (or appeal Theorem 3.2 below) shows satisfies axioms
C6. C6 hold , since |= X0
X1 X1
X2 X2
X0. also
shows recursive. However, restricted version C6 (where k = 1)
hold . generalization example (with k random variables rather 2)
used show cannot bound k C6; need C6 hold finite
values k.

;

;

;

Let AXuniq(S) consist C0C5 MP; let AXrec (S) consist C0C4, C6, MP.
could include C5 AXrec(S); because, Galles Pearl (1998) point
out, follows C3 C6. Note signature parameter axiom
system, language set models. because, example,
set R(X) (which determined S) appears explicitly C1 C2.
Theorem 3.2: AXuniq(S) (resp., AXrec(S)) sound complete axiomatization
Luniq(S) respect Tuniq(S) (resp., Trec(S)).
Proof: See appendix.
said introduction, Galles Pearl (1998) prove similar completeness result
causal models whose variables satisfy fixed causal ordering. Given total ordering
variables V, consider following axiom:
Ord. Y~xw (~u) = Y~x (~u) W

;

Since ~x, w, ~u implicitly universally quantified Ord, axiom says (W
) holds W . follows W
, W . fact
total order, easy see Ord implies C6.
Galles Pearl show C1C4 Ord sound complete axiomatization
respect class causal models satisfying Ord LGP . precisely, Galles
Pearl take AC consist axioms C1C4 Ord (but C0 MP), show,
notation, |= implies `AC , {} set formulas LGP .
important subtle point worth stressing result: C1 C2,

;

324

fiAxiomatizing Causal Structures

axioms AC , expressible LGP (since statement involves disjunction
negation).
exactly Galles Pearls result saying? interpret |= , usual,
meaning causal models satisfying S, true.5 interpret `AC
meaning provable axioms axioms AC together
rules logic, presumably means C0 MP. follows easily Theorem 3.2
result correct (see below), unlike typical soundness completeness
proofs, since proof general involve formulas Luniq
LGP . (In particular, happen whenever C1C3 used proof.)
see Galles Pearls result follows Theorem 3.2, define
formula Luniq(S) conjunction formulas (there finitely
many, since LGP (S) finitely many distinct formulas), together conjunction instances axiom Ord (again, finitely many). Note
|= holds iff Tuniq(S) |= (since formulas Ord guarantee
causal models satisfy recursive, hence Tuniq(S)). Thus, Theorem 3.2, |= iff AXuniq(S) ` . latter statement equivalent `AC ,
defined Galles Pearl. fact, Theorem 3.2 shows AXuniq(S) + Ord gives
sound complete axiomatization respect causal models satisfying Ord
language Luniq(S), allows Boolean connectives. (Of course, Theorem 3.2 shows more,
since extends Galles Pearls result Trec(S) Tuniq(S).) suggests Luniq
appropriate language reasoning causality LGP , least causal
models Tuniq. LGP cannot express number properties causal reasoning interest
(for example, ones captured axioms C1C3). use Luniq , every
formula Luniq valid Tuniq provable axioms AXuniq, proof involves
formulas Luniq.
? able find complete axiomatization language
Luniq respect . However, think finding complete axiomatization
Luniq respect great interest, Luniq simply language
appropriate reasoning causality . necessarily unique
solution equations arise causal model , useful able say
exists solution certain properties solutions certain
properties. precisely language L+ lets us do.6 show,
fact elegant sound complete axiomatization L+ respect .
Consider following axioms:
D0. instances propositional tautologies.
~ ~y](X(~u) = x X(~u) 6= x0 ) x, x0 R(X), x 6= x0
D1. [Y

(functionality)

~ ~y](xR(X)X(~u) = x)
D2. [Y

(definiteness)

~ ~xi(W (~u) = w
~ (~u) = ~y) hX
~ ~
~ (~u) = ~
D3. hX
x; W wi(Y
y)

(composition)

5. Although say explicitly, clear intend restrict casual models
satisfying Ord, fixed order . Without restriction, result true.
6. Note L+ allows us say unique solution random variable X setting
~ ~yitrue(~
~ ~
variables. example, hY
u) [Y
](X(~
u) = x) says solutions
~ set ~y U set ~
equations
u and, them, X uniquely determined x.

325

fiHalpern

~ w;
D4. [W
~ X x](X(~u) = x)

(effectiveness)

~ ~x; yi(W (~u) = w Z(~
~ u) = ~
~ ~
~ u) = ~z))
D5. (hX
z ) hX
x; W wi(Y (~u) = Z(~
~
~
~
~
hX ~xiW (~u) = w (~u) = Z(~u) = ~z)), Z = V (X {W, })
(reversibility)
D6. (X0

;X

1

. . . Xk1

; X ) (X ; X )
k

k

0

~ ~x] [X
~ ~x]( )) [X
~ ~x]
D7. ([X
~ ~x] propositional tautology
D8. [X

(recursiveness)
(distribution)
(generalization)

~ ~yitrue(~u) xR(X)[Y
~ ~
D9. hY
](X(~u) = x) = V {X}
(unique solutions V {X})
~ ~yitrue(~u) xR(X)[Y
~ ~
D10. hY
](X(~u) = x)

(unique solutions)

~ ~
~ ~y ik (~uk ), (~ui)
~ ~yi(1(~u1 ) . . . k (~uk )) (hY
i1(~u1) . . . hY
D11. hY
Boolean combination formulas form X(~ui) = x ~ui 6= ~
uj 6= j
(separability)
D1D6 analogues C1C6 L+ . D4 D6 C4 C6,
changes all. axioms quite though. example, C1
~ ~y](X(~u) = x) [Y
~ ~
actually [Y
](X(~u) = x0 ) x 6= x0 . Lemma 2.2,
equivalent D1 Tuniq; however, two formulas equivalent general. Similarly,
~ ~y ](X(~u) = x), closer D10 D2 (since disjunction
C2 xR(X)[Y
~ ~y]). Again, D10 D2 equivalent Tuniq (both
outside scope [Y
equivalent C2 case) but, general, D10 stronger D2. D2 D9,
weaker D10, hold . exact analogue C3 would use [ ] instead h
~ (~u) = ~
say (~u) = instead
. completeness, necessary vector
variables here. Using [ ] instead h also results valid formula (and would require
~ ). two variants equivalent Tuniq, different general,
vector
one given useful. (More precisely, get completeness,
version [ ] suffice completeness.) Similarly, D5, use h instead
~ u) = ~z. turn necessary soundness.
[ ], add extra clause Z(~
sense, think D1D6 capturing true content C1C6, drop
assumption structural equations unique solution. D7 D8 standard
properties modal operators. D10 need capture fact structural
equations unique solutions. D11 essentially says solutions equations
arise exogenous variables set ~u independent solutions
arise exogenous variables set ~
u0 6= ~u.
+
Let AX consist D0D5, D7D9, D11, MP (modus ponens); let AX+
uniq
+
+
+
result adding D10 AX ; let AXrec result adding D6 AXuniq.
+
Theorem 3.3: AX+ (S) (resp., AX+
uniq(S), AXrec (S)) sound complete axiomati+
zation L (S) respect (S) (resp., Tuniq(S), Trec(S)).

Proof: See appendix.

326

fiAxiomatizing Causal Structures

4. Decision Procedures
section consider complexity deciding formula satisfiable (or valid).
This, course, depends language (L+ , Luniq, LGP ) class models (Trec,
Tuniq, ) consider. also depends formulate problem.
One version problem consider fixed signature = (U, V, R), ask
hard decide formula L+ (S) (resp., Luniq(S), LGP (S)) satisfiable Trec(S)
(resp., Tuniq(S), (S)). finite (that is, V U finite R(Y ) finite
U V), turns quite easy, trivial reasons.
Theorem 4.1: fixed finite signature, problem deciding formula
L+ (S) (resp., Luniq(S), LGP (S)) satisfiable Trec(S) (resp., Tuniq(S), (S))
solved time linear || (the length viewed string symbols).
Proof: finite, finitely many causal models (S), independent
. Given , explicitly check satisfied (or all) them.
done time linear ||. Since parameter problem, huge number
possible causal models check affects constant.
even better Theorem 4.1 suggests fixed finite signature. Suppose
V consists 100 variables mentions 3 them. causal model must specify
equations 100 variables. really necessary consider happens
97 variables mentioned decide satisfiable valid? following result
shows, restrict models Tuniq, need check variables appear
S. Given signature = (U, V, R), let = ({U }, V, R), V consists
variables V appear , U fresh exogenous variable, mentioned V U,
R (X) = R(X) X V , R(U ) consists tuples U U R(U )
mentioned .
Theorem 4.2: formula L+ (S) satisfiable Trec(S) (resp., Tuniq(S)) iff
satisfiable Trec(S) (resp., Tuniq(S)).
Proof: See appendix.
analogue Theorem 4.2 hold . example, suppose =
(, {X, Y, Z}, R), R(X) = R(Y ) = R(Z) = {0, 1}, formula hX
0i(Y = 0) hX 0i(Y = 1). easy see causal model (S)
satisfying . example, = (S, F ), FX (y, z) = z, FY (x, z) = x z
FZ (x, y) = x y, represents addition mod 2, easy check |= .
hand, causal model 0 (S) 0 |= . suppose
0 |= 0 = (S, F 0). Since 0 |= hX 0i(Y = 0), must FY0 (0) = 0; since
0 |= hX 0i(Y = 1), must FY0 (0) = 1. cannot FY0 (0) = 0
FY0 (1) = 1, since FY0 function.
variant Theorem 4.2 hold give us bound
number variables need consider. Given signature = (U, V, R), define
||S|| = XV |R(X)| (where take ||S|| = either V infinite |R(X)| =
+
X V). ||S|| > ||S||2 + ||S||, let S+ = ({U }, V+, R+
), V V
327

fiHalpern


defined together one fresh endogenous variable X , R+
(X ) = XV R(X),
+


2
+

0
R (U ) = R(U ). ||S|| ||S|| + ||S||, let = ({U }, V, R ), R0 (X) = R(X)
X V R0 (U ) = R (U ).

Theorem 4.3: formula L+ (S) satisfiable (S) iff satisfiable (S+ ).
Proof: See appendix.
Note ||S|| ||S||2 + ||S||, then, since assumed (without loss generality) |R(X)| 2 variable X, must case
2 log2 (||S||) + 1 variables signature S.
Since Theorems 4.2 4.3 apply formulas L+ (S), apply fortiori
formulas Luniq(S) LGP (S). Although stated terms satisfiability,
immediate also hold validity. Thus, tell us that, without loss generality,
considering satisfiability validity, need consider finitely many variables
(essentially, ones appear , perhaps more). sense,
restrict signatures finitely many variables without loss generality. Note
results tell us restrict finite sets values variables
without loss generality.
Returning complexity decision problem, note Theorem 4.1 analogue observation propositional logic, satisfiability problem linear
time restrict fixed set primitive propositions. proof satisfiability problem propositional logic NP-complete implicitly assumes
unbounded number primitive propositions disposal.
two ways get analogous result here. first allow signature
infinite second make signature part input problem.
results cases similar, consider case signature part
input here.
Theorem 4.4: Given input pair (, S), L+ (S) (resp., Luniq(S))
finite signature, problem deciding satisfiable Trec(S) (resp., Tuniq(S), (S))
NP-complete (resp., NP-hard) ||; LGP (S), problem deciding
satisfiable Trec(S) (resp., Tuniq(S)) NP-complete (resp., NP-hard).
Proof: See appendix.
believe problem deciding formula Luniq(S) L+ (S) satisfiable
Tuniq(S) (S) NP-complete, case deciding LGP (S) satisfiable
Tuniq(S). However, able show this. satisfiability problem
formulas LGP (S)? may well constant time! Indeed, infinite
signature (that is, = (U, V, R) |V| = ), provably constant time.
point formula LGP (S) trivially satisfiable structure LGP (S)
~ ~x, equations ~
settings X
X~
x solutions, always
model structure infinitely many variables. finitely many variables,
trivial models, may still possible show trivial enough
model exists satisfies formula. emphasizes LGP (S) simply
weak language reason models (S).
328

fiAxiomatizing Causal Structures

5. Conclusion
provided complete axiomatizations decision procedures propositional languages reasoning causality. tried stress important role choice
language (and signature) axiomatizations and, generally,
reasoning process.
models languages considered somewhat limited. example,
general approach modeling causality would allow one value
X set variables. would appropriate model things
somewhat coarser level granularity, values variables
X suffice completely determine value X. believe results paper
extended straightforward way deal generalization, although
checked details. general causal reasoning, believe need richer language,
includes first-order features. hope return issue finding appropriate
richer languages causal reasoning future work.

Acknowledgments
Id like thank Judea Pearl comments previous version paper, well
generous help providing pointers literature. work supported part
NSF grant IRI-96-25901 Air Force Office Scientific Research
grant F49620-96-1-0323. preliminary version paper appears Proc. Fourteenth
Conference Uncertainty AI, pp. 202210, 1998.

Appendix A. Proofs
Theorem 3.2: AXuniq (resp., AXrec) sound complete axiomatization Luniq(S)
respect Tuniq(S) (resp., Trec(S)).
Proof: Soundness proved Galles Pearl. make paper self-contained,
reprove non-obvious casethe validity C5 Tuniq.
Let Tuniq suppose |= Y~xw (~u) = W~xy (~u) = w. want show
|= Y~x (~u) = y. Since Tuniq, unique vector ~v1 satisfies
equations T~xw (~u) unique vector ~v2 satisfies equations T~xy (~u). claim
~ , W components vectors
~v1 = ~v2 . assumption, X,
(~x, y, w, respectively). consider T~xyw (~u). claim ~v1 ~v2
solutions equations causal theory. Note variable Z
~ {W, }, equation F ~xw,~u Z T~xw (~u) equations F ~xy,~u
X
Z
Z
FZ~xyw,~u Z T~xy (~u) T~xyw (~u), respectively, except first case, w
plugged value W , second case plugged value
, third case, w plugged in. However, since w
values W , respectively, ~v1 ~v2, since vectors satisfy
equation FZ~xw FZ~xy , must also satisfy FZ~xwy . Since equations T~xyw (~u)
unique solution, ~v1 = ~v2 , desired.
329

fiHalpern

Next, claim ~v1 satisfies equations T~x (~u). Again, above, clear
~ {W, }. similar argument shows satisfies
satisfies equation Z
/X
equation T~x (~u), since ~v1 satisfies equation T~xw (~u). Finally, similar
argument shows satisfies equation W T~x (~u), since ~v2 = ~v1 satisfies
equation W T~xy (~u). Since component ~v1 y, follows Y~x (~u) = y.
much soundness. completeness, usual, suffices prove formula
Luniq consistent AXuniq (resp., AXrec), satisfied causal model
Tuniq (resp., Trec). (Heres argument: want show every valid formula
provable. Suppose shown every consistent formula satisfiable
valid. provable, consistent. assumption, means
satisfiable, contradicting assumption valid.)
give argument case AXuniq.
Suppose formula Luniq(S), = (U, V, V ), consistent AXuniq.
Consider maximal consistent set C formulas includes . (A maximal consistent set
set formulas whose conjunction consistent larger set formulas would
inconsistent.) follows easily standard propositional reasoning (i.e., using C0
MP only) maximal consistent set exists. Moreover, C1 C2, follows
random variable X V vector ~
values, exists exactly one element
x R(X) X~y = x C. construct causal model = (S, F ) Tuniq(S)
satisfies every formula C (and, particular, satisfies ).
~ consists variables V {X}. Thus,
term XY~ ~y (~u) complete (for X)
XY~ ~y (~u) complete term every random variable X determined. use
complete terms define structural equations. variable X V, define
FX (~u, ~y) = x X~y (~u) = x, X~y (~u) complete term. gives us causal model
. show model Tuniq formulas C
satisfied .
~ |.
show XY~ ~y (~u) = x C iff |= XY~ ~y (~u) = x induction |V| |Y
~ | = 0 follows immediately C4, since X
~ . |V| |Y
~| =
case |V| |Y
6 0,
assume without loss generality X Y~ , otherwise result
~ | = 1, result follows definition
follows C4. Given assumption, |V| |Y
equations FX .
~ | = k > 1. want show
general case, suppose |V| |Y
unique solution equations TY~ ~y (~u) that, solution, X value x.
see solution, define vector ~v show fact solution.
W Y~ W w assignment W Y~ ~
, set W component ~v
w. W Y~ , set W component ~v unique value w
WY~ ~y (~u) = w C. (By C1 C2 unique value w.) claim ~v
solution equations TY~ ~y (~u).
~ W . C3 C4, every
~0 =Y
see this, let W variable V Y~ . Let
0

~
~
variable Z V , Z~yw (~u) = z . Since |V| |Y 0 | = k 1, inductive
~ 0 ,
hypothesis, ~v fact unique solution T~yw (~u). every variable Z V
w ,~
~
u
~
y,~
u
equation FZ
Z T~yw (~u) equation FZ Z T~y (~u), except
,~
~
u

W set w . Thus, every equation T~y (~u) except possibly equation FW
~
y,~
u
satisfied ~v . see FW also satisfied ~v , simply repeat argument
330

fiAxiomatizing Causal Structures

~ . (Such variable must exist since |V| |Y
~ |
starting another variable W 0 V
assumed least 2.)
remains show ~v unique solution equations T~y (~u). Suppose
another solution, say ~v 0 , equations. Suppose variable W
V Y~ , W component ~v 0 w. variable Z, must z 6= z .
Since Z~y (~u) = z , assumption, follows C1 Z~y (~u) 6= z C (since C
maximal consistent set). also easy see W V Y~ , vector ~v 0
~.
also solution equations T~yw (~u). Let W variable Z V


induction hypothesis, follows W~yz (~u) = w Z~yw (~u) = z
C. C5 (reversibility), Z~y (~u) = z C. contradicts consistency C.
completes proof case Tuniq(S). Essentially proof works
Trec. need observe C6 guarantees theory construct taken
recursive. see this, given formula consistent Trec, consider maximal set
C formulas consistent Trec contains . Let TC causal model determined
C, above. set C also determines relation exogenous variables: define
Z
Z C. easily follows C6 transitive closure
partial order: X X, X = . total order variables
consistent gives ordering TC recursive.

;

+
Theorem 3.3: AX+ (resp., AX+
uniq, AXrec ) sound complete axiomatization
L+ (S) respect (S) (resp., Tuniq(S), Trec(S)).

Proof: Soundness proceeds much Theorem 3.2; leave details reader.
completeness, proceed much proof Theorem 3.2. proofs
similar spirit, sketch proof AX+ ; modifications AX+
uniq

left


reader.
AX+
rec
Again, given formula consist AX+ , consider maximal consistent set
formulas containing consistent AX+ , use construct causal model
. Note D9 suffices this, defining FX (~u, ~y), needed know
~ ~y ](X(~u) = x) Y~ = V X, D9 (together D1) assures
unique x [Y
us unique x. Again, want show formulas C
satisfied .
~ ~y ,
this, clearly suffices show every formula form hY
C iff |= . reduce considering even simpler formulas, namely,
~ u) = ~x, applying axioms. see this, first
ones form X(~
observe standard arguments modal logic (using D0, D7, D8, MP) show
~ ~y i(1 2) provably equivalent hY
~ ~
~ ~
hY
i1 hY
i2. means
assume without loss generality conjunction formulas form X(~u) x
~ ~yi( X(~u) 6= x) equivalent
negations. D2 follows hY
0
~
hY ~y i( (x0R(X){x}X(~u) = x ). Thus, assume without loss generality
negations. applying D11, assume without loss generality
setting ~u exogenous variables used conjuncts. Thus, suffices
~ ~yi(X(~
~ u) = ~x) C iff |= hY
~ ~
~ u) = ~x) X
~ = V
~.
show hY
i(X(~
~ | again. base case dealt using
this, proceed induction |V| |Y
~
~ ~
~ u) =
D4, before. assume k 1 |V| |Y | = k + 1. Suppose hY
i(X(~
~ Suppose X1 x1 X2 x2 assignments
~x) C. Let X1 , X2 X.
331

fiHalpern

~ ~x. Let X
~ 0 ~x0 X
~ 00 ~x00 result removing X1 x1
X1 X2 X
~ ~
~ ~
~ 00(~u) = ~
X2 x2, respectively, X
x. D3, hY
; X1 x1 i(X
x00 )
~ 0(~u) = ~x0 ) C. induction hypothesis,
~ ~y; X2 x2 i(X
hY
~ ~
~ u) = ~x0 ),
formulas true . soundness D5, follows |= hY
i(X(~
desired.
~ ~
~ u) = ~x0 ). Then, since D3 sound,
Conversely, suppose |= hY
i(X(~
~ 00(~u) = ~
~ ~y ; X2 x2 i(X
~ 0(~u) = ~x0 ).
~ ~y; X1 x1i(X
x00 ) |= hY
|= hY
00
~
~
induction hypothesis, hY ~
; X1 x1i(X (~u) = ~x00 )
0
0
~ (~u) = ~x ) C. apply D5 complete proof.
~ ~y ; X2 x2 i(X
hY
Theorem 4.2: formula L+ (S) satisfiable Trec(S) (resp., Tuniq(S)) iff
satisfiable Trec(S) (resp., Tuniq(S)).
Proof: Clearly, formula satisfiable Trec(S) (resp., Tuniq(S )), satisfiable
Trec(S) (resp., Tuniq(S)). easily convert causal model = (S, F ) Trec(S)
satisfying causal model 0 = (S, F 0) Trec(S) satisfying simply defining
0
FX
constant, independent arguments, X V V ; X V , define
0
x V {X}R(Y ) ~
VV R(Y );
FX (~u, ~x, ~y) = FX (~u, ~x), ~u R(U ), ~
0
~u
/ R(U ), define FX
(~u, ~x, ~y) arbitrary constant. identical transformation
works Tuniq(S).
converse, suppose satisfiable causal model = (S, F ) Trec(S).
Thus, ordering variables V X , FX independent value . means view FX function exogenous variables
U variables V X. Let Pre(X) = {Y V : X}.
convenience, allow FX take arguments values variables U Pre(X),
rather requiring arguments include values variables U V {X}.
0
define functions FX
: (U U R(U )) (Y V{X} R(Y )) R(X) X V
induction (that is, start -minimal element, whose value independent
variables, work chains). Suppose X V ~x vector
0 (~
u, ~x) = FX (~u).
values variables V {X}. X -minimal, define FX
0
general, define FX (~u, ~x) = FX (~u, ~z), ~z vector values variables
Pre(X) defined follows. Pre(X) V , value component ~z
value component ~y ; Pre(X) V, value component
~z FY0 (~u, ~x). (By induction hypothesis, FY0 (~u, ~x) already defined.)
define causal model 0 = (S , F 0). easy check 0 Trec(S ) (the ordering
variables restricted V ). Moreover, construction guarantees
~ V , solutions equations 0
u) TX~
u) same,
X
~ x (~
~ x (~
X~
0
restricted variables V . follows satisfies .
argument case Tuniq(S) similar spirit. X V , ~u
0
(~u, ~x) value X
(U U R(U )), ~x (Y V {X}R(Y )), define FX
7
unique solution equations TV{X}~x (~u). straightforward check
0 = (S , F 0) Tuniq(S ) satisfies .
0
7. definition easily seen agree earlier definition FX
Trec .

332

fiAxiomatizing Causal Structures

Theorem 4.3: formula L+ (S) satisfiable (S) iff satisfiable (S+ ).
Proof: ||S|| ||S||2 +||S|| proof immediate, suppose ||S|| > ||S||2 +
||S|| satisfied causal model = (S, F ) (S). going
proof, useful define notation. Let V = {X1, . . . , Xm}, V = {X1, . . . , Xk }
V V = {Xk+1 , . . . , Xm}. Given vector ~x R(X ) = XV R(X) Xi V ,
let ~xi denote vector excluding value Xi . Xi V , choose two values
0
xi0 xi1 R(Xi). Define 0 = (S , F 0) defining FX
(~u, ~xi , ~yi , yi) = x,
x = yi ~xi = ~yi X = yi solution equations TV {Xi }~xi (~u);
x = xi0 yi 6= xi0 either ~xi 6= ~
yi solution equations
TV{X}~xi (~u) X = yi ;
x = xi1 otherwise.
Finally, define FX (~u, ~x) = ~x.
~ V, solutions
show construction guarantees X
0
equations TX~
u) TX~
u) same, restricted variables
~ x (~
~ x (~
u), ~
R(X )
V . First suppose (~y, ~z) solution equations TX~
~ x (~
~
x ~y agree variables X,
~z VV R(Y ). must case ~
~
(~y, ~z) also solution equations TV {Xi }~yi (~u) Xi V X. Thus,
0
0
FX
(~u, ~yi , ~y) = yi . follows (~
y, ~y ) solution equations TX~
u).
~ x (~

0
0
u).
Conversely, suppose (~y, ~y ) solution equations TX~
~ x (~
0
~
. Moreover, since ~x ~
agree variables X,
definition FX guarantees ~y = ~
0
0
(~y, ~y) must also solution equations TV{X1 }~y1 (~u). Thus, FX1 (~u, ~y1, ~y) =
z values variables V V
y1 , means must vector ~
(~y, ~z) solution equations TV {X1 }~y1 (~u). easy check
(~y, ~z) must fact solution equations TV {Xi }~yi (~u) = 1, . . ., k.
u), desired. suffices
follows (~y, ~z) solution equations TX~
~ x (~
prove direction theorem.
suppose satisfied causal model = (S+ , F ) (S+ ). Since ||S|| >
||S||2 + ||S||, must injective function f : R(X ) VV R(Y ) two
distinct vectors ~y0 = (y01, . . . , y0k ), ~y1 = (y11, . . . , y1k ) range f .
Choose two distinct vectors ~x0 = (x10, . . . , xk0), ~x1 = (x11, . . . , xk1) R(X ). Define
0 = (S, F 0) (S) follows. Xi V, ~xi V {Xi } R(Y ), ~
z R(X ),
~y VV R(Y ), let
0
FX
(~xi , ~y) =




xi , ~z) f (~z) = ~
y,
FXi (~

x

0i

x
1i

~y range f , ~
6= ~y1 ,
otherwise.

Xj V V , ~x R(X ) ~yj VV{Xj } R(Y ), let
0
(~x, ~yj )
FX
j





=



0j


1j

f (FX (~x)) = (~
yj , y),
f (FX (~x)) 6= (~
yj , 0) 0 R(Xj ), ~x 6= x~0 ,
otherwise.
333

fiHalpern

~ V , solutions
Again, show construction guarantees X
0
equations TX~
u) TX~
u) same, restricted variables V . First
~ x (~
~ x (~
u), ~
, ~z R(X ). easy
suppose (~y, ~z) solution equations TX~
~ x (~
0
check (~y, f (~z)) solution equations TX~
u). Conversely, suppose
~ x (~
0
u), ~
R(X ) ~z VV R(Y ).
(~y, ~z) solution equations TX~
~ x (~
claim must ~z = f (FX (~
)). If, fact, case, easy

u). hand,
check (~y, FX (~y) solution equations TX~
~ x (~
0 X V V guarantees ~
z=~
y0 unless
~z 6= f (FX (~y)), definition FX
j

j
~y = ~x0; ~y = ~x0 , ~z = ~y1 . definition FXi Xi V guarantees
, ~z) solution iff ~z = f (FX (~
y)).
~z = ~y0 , ~y = ~x0: otherwise, ~y = ~x1 . Thus, (~
suffices prove result.
Theorem 4.4: Given input pair (, S), L+ (S) (resp., Luniq(S))
finite signature, problem deciding satisfiable respect Trec(S) (resp.,
Tuniq(S), (S)) NP-complete (resp., NP-hard) ||; LGP (S), problem
deciding satisfiable Trec(S) (resp., Tuniq(S)) NP-complete (resp., NP-hard).
Proof: NP-lower bound easy L+ (S) Luniq(S), since obvious way
encode satisfiability problem propositional logic satisfiability problem
L+ Luniq. Given propositional formula primitive propositions p1, . . . , pk , let
= (, {X1, . . . , Xk }, R), R(Xi) = {0, 1} = 1, . . . , k. Replace occurrence
primitive proposition pi formula Xi = 1. gives us formula 0
Luniq(S). easy see 0 satisfiable causal model (S) (and, fortiori
0 satisfiable causal model either Trec(S) Tuniq(S)) solution
equations defines satisfying assignment . Conversely, satisfiable, say
truth assignment v, trivially construct causal model Trec(S)
FXi = v(pi). (For simplicity, assume valuations assign values 0 1 rather
false true.)
trivial construction 0 work LGP (S), since disjunctions
negations available. lack negations cause problem. assume
without loss generality negations occur front primitive propositions,
capture pi formula Xi = 0. idea dealing disjunctions
formula p1 p2 p3 translated [X1 0; X2 1; X3 1](Y = 0),
fresh variable. Essentially, viewing p1 p2 p3 (p1 p2 p3 ) false,
write, example, X1 0 even though p1 appears positively disjunction.
make matters simpler, assume formula 3-CNF. suffices NPhardness, since satisfiability problem 3-CNF formulas also NP-hard (Garey &
Johnson, 1979). Suppose form c1 . . .cm , cl clause consisting
disjunction three primitive propositions negations. Suppose primitive
propositions appear p1, . . . , pk . Let = (, {X1, . . . , Xk , Y1 , . . ., Ym }, R),
R(Xi) = R(Yj ) = {0, 1} i, j. Suppose cj , jth clause ,
form qj1 qj2 qj3 , qji either pji pji ji . Let ctj LGP formula
[Xj1 xj1 ; Xj2 xj2 ; Xj3 xj3 ](Yj = 0),
334

fiAxiomatizing Causal Structures

xjh 0 qjh pjh xjh 1 qjh pjh h = 1, 2, 3. Let 0
[true](Y1 = 1 . . . Ym = 1) ct1 . . . ctm.
claim satisfiable propositional formula iff LGP formula 0 satisfiable
Trec(S) (resp. Tuniq(S)). First suppose 0 satisfiable, say model Tuniq(S).
(If direction holds Tuniq(S), clearly holds fortiori Trec(S).) Let ~z
unique solution equations . construction, Yj component ~z 1
j = 1, . . ., m. Let xi value Xi component ~z. Consider valuation v
v(pi) = xi . claim v() = 1. see this, suppose clause cj qj1 qj2 qj3 .
v makes qj1 , qj2 , qj3 false, must xjh = xjh h = 1, 2, 3. Since
|= [Xj1 xj1 ; Xj2 xj2 ; Xj3 = xj3 )](Yj = 0) value Xjh component ~z
xjh h = 1, 2, 3, follows ~z solution equations TXj1 xj1 ;Xj2 xj2 ;Xj3 xj3 .
contradicts fact |= [Xj1 xj1; Xj2 xj2 ; Xj3 xj3](Yj = 0) (since
Yj component ~z 1). follows v(cj ) = v(qj1 qj2 qj3 ) = 1. Since true
clauses cj , must v() = 1.
converse, suppose satisfiable, say valuation v. show 0
satisfiable Trec(S). Order variables Xj1 , Xj2 , Xj3 Yj . (There many
orderings variables satisfy constraints; one do.) Define FXi = v(pi)
(so FXi constant, independent arguments); define FYj (xj1 , xj2 , xj3 ) = 1
(xj1 , xj2 , xj3 ) = (v(pj1 ), v(pj2 ), v(pj3 )) 0 otherwise. easy check |= 0 ,
desired.
NP upper bound case Trec(S), clearly suffices deal L+ .
Suppose given (, S) L+ . want check satisfiable Trec(S).
basic idea guess causal model verify indeed satisfies .
problem though. completely describe model , need describe
functions FX . However, may many variables X many
possible inputs. describing functions may take time much longer polynomial
. Part solution problem provided Theorem 4.2, tells us
suffices check whether satisfiable Trec(S ). light this, remainder
part proof, assume without loss generality = . limits
number variables must consider O(||). even solve
problem completely. Since given bounds |R(Y )| variables S,
even describing functions FY variables appear possible
input vectors could take time much polynomial . solution give
short partial description model show suffices.
~ ~y , ~u) subformula form [Y
~ ~
Consider pairs (Y
]
2
~u appears . Let R set pairs. Note |R| < || . say
~ ~
, ~u) R,
two causal models 0 Trec(S) agree R if, pairs (Y
0
(unique) solutions equations TY~ ~y (~u) ~ (~u) same. easy see
~

0 agree R, either 0 satisfy neither do. is,
need know causal model deals relevant equationsthose
corresponding pairs R.
~ ~y , ~u) R, guess vector ~v (Y
~ ~
pair (Y
, ~u) values endogenous
variables; intuitively, unique solutions relevant equations model
satisfying . Given guesses, easy check satisfied model
335

fiHalpern

guesses indeed represent solutions relevant equations. remains show
exists causal model Trec(S) relevant equations solutions.
this, first guess ordering variables. verify,
~ ~
fixed ~u appears , whether solution vectors ~v (Y
, ~u) guessed relevant
equations compatible , sense case two
solutions (~u, ~x) (~u, ~x0 ) variable X takes different values ~x ~x0 ,
variables X take values ~x ~
x0 . easy
see solutions compatible , define functions FX X V
equations hold FX independent values X
X, V. (Note never actually write functions FX , may take
long; know exist.) summarize, long guess
solutions relevant equations causal model solutions satisfies
, ordering solutions compatible , satisfiable
Trec(S). Conversely, satisfiable Trec(S), clearly solutions
relevant equations satisfy ordering solutions
compatible . (We take solutions ordering .) shows
satisfiability problem Trec NP, desired.

References
Chajewska, U., & Halpern, J. Y. (1997). Defining explanation probabilistic systems.
Proc. Thirteenth Conference Uncertainty Artificial Intelligence (UAI 97), pp.
6271.
Druzdzel, M. J., & Simon, H. A. (1993). Causality bayesian belief networks. Uncertainty Artificial Intelligence 9, pp. 311.
Galles, D., & Pearl, J. (1997). Axioms causal relevance. Artificial Intelligence, 97 (12),
943.
Galles, D., & Pearl, J. (1998). axiomatic characterization causal counterfactuals.
Foundation Science, 3 (1), 151182.
Garey, M., & Johnson, D. S. (1979). Computers Intractability: Guide Theory
NP-completeness. W. Freeman Co., San Francisco, Calif.
Goldberger, A. S. (1972). Structural equation methods social sciences. Econometrica,
40 (6), 9791001.
Harel, D. (1979). First-Order Dynamic Logic. Lecture Notes Computer Science, Vol. 68.
Springer-Verlag, Berlin/New York.
Heckerman, D., & Shachter, R. (1995). Decision-theoretic foundations causal reasoning.
Journal Artificial Intelligence Research, 3, 405430.
Henrion, M., & Druzdzel, M. J. (1990). Qualitative propagation scenario-based approaches explanation probabilistic reasoning. Uncertainty Artificial Intelligence 6, pp. 1732.
336

fiAxiomatizing Causal Structures

Pearl, J. (1995). Causal diagrams empirical research. Biometrika, 82 (4), 669710.
Pearl, J. (1999). Causality. Cambridge University Press, New York. Forthcoming.
Pearl, J., & Verma, T. (1991). theory inferred causation. Principles Knowledge
Representation Reasoning: Proc. Second International Conference (KR 91), pp.
441452.
Spirtes, P., Glymour, C., & Scheines, R. (1993).
Springer-Verlag, New York.

Causation, Prediction, Search.

Strotz, R. H., & Wold, H. O. A. (1960). Recursive vs. nonrecursive systems: attempt
synthesis. Econometrica, 28 (2), 417427.

337

fiJournal Artificial Intelligence Research 12 (2000) 271-315

Submitted 2/00; published 5/00

Compilability Expressive Power
Propositional Planning Formalisms
Bernhard Nebel

NEBEL @ INFORMATIK . UNI - FREIBURG . DE

Institut fur Informatik, Albert-Ludwigs-Universitat, Georges-Kohler-Allee, D-79110 Freiburg, Germany

Abstract
recent approaches extending GRAPHPLAN algorithm handle expressive
planning formalisms raise question formal meaning expressive power is.
formalize intuition expressive power measure concisely planning domains
plans expressed particular formalism introducing notion compilation
schemes planning formalisms. Using notion, analyze expressiveness
large family propositional planning formalisms, ranging basic STRIPS formalism
conditional effects, partial state specifications, propositional formulae preconditions.
One results conditional effects cannot compiled away plan size grow
linearly compiled away allow polynomial growth resulting plans.
result confirms recently proposed extensions GRAPHPLAN algorithm concerning
conditional effects optimal respect compilability framework. Another result
general propositional formulae cannot compiled conditional effects plan size
preserved linearly. implies allowing general propositional formulae preconditions
effect conditions adds another level difficulty generating plan.

1. Introduction
G RAPHPLAN (Blum & Furst, 1997) SATPLAN (Kautz & Selman, 1996) among
efficient planning systems nowadays. However, generally felt planning formalism
supported systems, namely, propositional basic STRIPS (Fikes & Nilsson, 1971),
expressive enough. reason, much research effort (Anderson, Smith, & Weld, 1998; Gazen
& Knoblock, 1997; Kambhampati, Parker, & Lambrecht, 1997; Koehler, Nebel, Hoffmann, & Dimopoulos, 1997) devoted extending GRAPHPLAN order handle powerful
planning formalisms ADL (Pednault, 1989).
appears consensus much expressive power added particular language feature. example, everybody seems agree adding negative preconditions
add much expressive power basic STRIPS, whereas conditional effects considered
significant increase expressive power (Anderson et al., 1998; Gazen & Knoblock, 1997;
Kambhampati et al., 1997; Koehler et al., 1997). However, unclear measure expressive power formal way. Related problem question whether compilation
approaches extend expressiveness planning formalism optimal. example, Gazen
Knoblock (1997) propose particular method compiling operators conditional effects
basic STRIPS operators. method, however, results exponentially larger operator sets.
people (Anderson et al., 1998; Kambhampati et al., 1997; Koehler et al., 1997) agree
cannot better that, nobody proven yet space-efficient method
impossible.
c 2000 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiN EBEL

order address problem measuring relative expressive power planning formalisms, start intuition formalism least expressive another formalism planning domains corresponding plans formalism concisely expressed
formalism . This, least, seems underlying intuition expressive power
discussed planning literature.
Backstrom (1995) proposed measure expressiveness planning formalisms using
ESP-reductions. reductions are, roughly speaking, polynomial many-one reductions
planning instances change plan length. Using notion, showed
propositional variants basic STRIPS containing conditional effects arbitrary logical
formulae considered expressively equivalent. However, taking point view, ESPreductions restrictive two reasons. Firstly, plans must identical size, might
want allow moderate growth. Secondly, requiring transformation computed
polynomial time overly restrictive. ask concisely something expressed,
necessarily imply exists polynomial-time transformation. fact, one
formalism might expressive another one, mapping formalisms might
computable all. This, least, seems usual assumption made term
expressive power discussed (Baader, 1990; Cadoli, Donini, Liberatore, & Schaerf, 1996; Erol,
Hendler, & Nau, 1996; Gogic, Kautz, Papadimitriou, & Selman, 1995).
Inspired recent approaches measure expressiveness knowledge representation formalisms (Cadoli et al., 1996; Gogic et al., 1995), propose address questions
expressive planning formalism using notion compiling one planning formalism
another one. compilation scheme one planning formalism another differs polynomial many-one reduction required compilation carried polynomial
time. However, result expressible polynomial space. Furthermore, required
operators planning instance translated without considering initial state
goal. restriction might sound unnecessarily restrictive, turns existing
practical approaches compilation (Gazen & Knoblock, 1997) well theoretical approaches
(Backstrom, 1995) consider structured transformations operators transformed
independently initial state goal description. technical point view
restriction guarantees compilations non-trivial. entire instance could transformed,
compilation scheme could decide existence plan source instance generate
small solution-preserving instance target formalism, would lead unintuitive
conclusion planning formalisms expressive power.
mentioned beginning, space taken domain structure important,
also space used plans. reason, distinguish compilation schemes
whether preserve plan size exactly, linearly, polynomially.
Using notion compilability, analyze wide range propositional planning formalisms, ranging basic STRIPS planning formalism containing conditional effects, arbitrary boolean formulae, partial state specifications. one results, identify two
equivalence classes planning formalisms respect polynomial-time compilability preserving plan size exactly. means adding language feature formalism without leaving
class increase expressive power affect principal efficiency
1. assume reader basic knowledge complexity theory (Garey & Johnson, 1979; Papadimitriou,
1994), familiar notion polynomial many-one reductions complexity classes P, NP, coNP,
PSPACE. notions introduced paper needed.

272

fiC OMPILABILITY



E XPRESSIVE P OWER P LANNING F ORMALISMS

planning method. However, also provide results separate planning formalisms using
results computational complexity theory circuit complexity non-uniform complexity
classes. separation results indicate adding particular language feature adds expressive power difficulty integrating feature existing planning algorithm.
example, prove conditional effects cannot compiled away boolean formulae
cannot compiled conditional effectsprovided plans target formalism allowed
grow linearly.
answers question posed beginning. compilation approach proposed Gazen
Knoblock (1997) cannot space efficient, even allow linear growth plans
target formalism. Allowing polynomial growth plans, however, compilation
scheme space efficient. Interestingly, seems case compilation scheme
allows polynomially larger plans similar implementation conditional effects
IPP system (Koehler et al., 1997), Kambhampati colleagues' (1997) planning system,
Anderson colleagues' (1998) planning system.
rest paper structured follows. Section 2, introduce range propositional planning formalisms analyzed paper together general terminology definitions.
Based that, introduce notion compilability planning formalisms Section 3.
Section 4 present polynomial-time compilation schemes different formalisms
preserve plan size exactly, demonstrating formalisms identical expressiveness.
remaining cases, prove Section 5 cannot compilation scheme
preserving plan size linearly, even bounds computational resources
compilation process. Section 6 reconsider question identical expressiveness using compilation schemes allow polynomial growth plans. Finally, Section 7
summarize discuss results.

2. Propositional Planning Formalisms
First, define general propositional planning formalism, appears almost
expressive propositional variant ADL (Pednault, 1989). formalism allows arbitrary
boolean formulae preconditions, conditional effects partial state specifications. Subsequently,
specialize formalism imposing different syntactic restrictions.
2.1 General Propositional Planning Formalism
Let countably infinite set propositional atoms propositional variables. Finite
subsets denoted . Further, defined set consisting constants
(denoting truth) (denoting falsity) well atoms negated atoms, i.e., literals,
. language propositional logic logical connectives
fiff ,
propositional atoms denoted fi . clause disjunction literals. Further, say
formula conjunctive normal form (CNF) conjunction clauses.
disjunctive normal form (DNF) disjunction conjunctions literals.
Given set literals , fi refer positive literals , "!$#%& refer
negative literals , '(& atoms used , i.e., '($fi*),+.-//102-33 4-5
2. Note Gazen Knoblock's (1997) translation scheme also generates planning operators depend
initial state goal description. However, operators simply code initial state goal description
nothing else. reason, ignore here.

273

fiN EBEL

76

. Further, define 8 element-wise negation , i.e.,

8),+.-90:4-35;6&<=+>4-?0@-=376BA
state C truth-assignment atoms . following, also identify state
set atoms true state. state specification subset , i.e., logical
theory consisting literals only. called consistent iff contain complementary literals
. general, state specification describes many states, namely satisfy ,
denoted EF:GH$D( . case complete, i.e., -3/ either -=/D
4-IJD , precisely one model, namely K>$D( . abusing notation, refer
inconsistent state specification , illegal state specification.
Operators pairs LM)ON pre ff post P . use notation pre LB post LQ refer first
second part operator L , respectively. precondition pre element RKSKT , i.e.,
set propositional formulae. set post, set postconditions, consists
conditional effects, form

UWV Xff
UZY



called effectV conditions elements
called
elements
U
effects. singleton sets, e.g., +.-H6
+\[]6 , often omit curly brackets write
- V [.
Example 1 order illustrate various notions, use running example planning
problems connected production camera-ready manuscripts LATEX source files
somewhat simplified, course. set atoms , choose following set:

^),+`_bacffed]fgcffihQj]klffgm no4ffgp\qgffgrsklrsffgr]rsmlffgrsm o4fftklu>hvfftk hQcfftkwm
hQj]k klu>h nxQffihBjsk y>k _za nx6BA
propositional atoms following intended meaning. atoms first line represent
presence corresponding files, atoms second line signify index
citations correct dvi-file. Based that, define following operators: rBkwr\_bac , d{_zac ,
| d]xea>kwu{h]ac . first operators simple. precondition execution
rBklr - d]fgc -file exist. successful execution, r]rsm - r]m -file
produced:

rBklr{_zacM)~}`d]fgcffgrBkwr4ff{v V +Brsrsmlffgrsm ov6"vA



| d]xea>kwu{hsac

operator similar:

| d]xea>kwu{h]acM)}4`k hc`4ff{v V +Qkwu{h`fftklm ov6"vA
Finally, d{_zac operator bit complicated. precondition needs presence
_bac -file produces effect d]fgc -, k hc -, hBjsk , -files unconditionally. addition,
know citations correct rsr]m -file present index correct
274

fiC OMPILABILITY

klu>h

-file present:



E XPRESSIVE P OWER P LANNING F ORMALISMS

d{_bac)~}_zac`4ff
V
V
rsr]m
fir]rsV
klu>h

+{d]f:cfftk hQcffihBjsklffgm no`6Bff
V hBjs8k hQy>j]k _bk y>k n_zaxff nxQff
hBjsk klu>h nxQff
V
kwu{h 8hQj]k kwu{h nx 4

semantics operators given state-transition functions, i.e., mappings states
states. Given state C set postconditions post, CBff post denotes active effects C :

MCsff post()+\0 UWV &

post ffeC0 )

U 6BA

state-transition function { induced operator L defined follows:

>\
{C>)

R 3 R
C7fi"!$#%$Csff post LB..<$MCsff post LB.. C0 ) pre LB

CBff post LQ.0)

undefined

otherwise

words, precondition operator satisfied state C active effects consistent,
state C mapped state C: differs C truth values active effects
forced become true positive effects forced become false negative effects.
precondition satisfied set active effects inconsistent, result function
undefined.
planning formalism itself, work states state specifications. general,
lead semantic problems. restricting state specifications sets
literals, however, syntactic manipulations state specifications defined way
sound Lifschitz' (1986) sense.
Similarly active effects respect states, define corresponding function
respect state specifications:

$Dff post *)+\I0 UWV fifi

post ffD^0 )

U 6BA

Further, define potentially active effects follows:

$Dff post () CBff postA
e %


$Dff post ,
state specification operator L5)N pre ff post P , $Dff post )
means state specification resulting application state-transition functions
might representable theory consisting literals only. reason, consider
operator application illegal, resulting illegal state specification . could
liberal point consider operator application state specification illegal
set states resulting applying state-transition functions could definitely represented
3. Note happen state specification incomplete.

275

fiN EBEL

theory consisting literals only. Alternatively, could consider atoms mentioned
$Dff post ,M$D8ff post unsafe application operator delete literals
7 $D8ff post $Dff post . state specification, consider resulting state specification
still legal $Dff post consistent. Since seem exist standard model
execution conditional effects presence partial state specifications, adopt first
alternative one arbitrary choice. noted, however, decision influences
results present below.
$Dff post leads illegal state specification,
Similarly rule $Dff post )
require precondition satisfied states EF:GH$D( state specification
already inconsistent, result applying L results . leads definition
function , defines outcome applying operator L set operators
state specification:

R 1 R
D/($Dff post LQ.<5M$D8ff post LB. D0)

0 ) pre LB
J

$D8ff post LB.0)

$Dand
$D8ffiLQ)


$

8

ff


B
L
.



)
ff post LB.
post





otherwise

Example 2 Using propositional atoms operators Example 1, assume following
two state specifications
)+:_zacKfftklu>hK6 , )+:_bacKfftklu{h`ffgrsr]mffgrsm ov6 . try apply
operator d{_bac , notice results



ff post zm d\_bacB.) +{d]fgcfftk hcffihQj]klffgm no4ffihQj]k klu{h nx6Bff
ff post zm d\_bacB.) ff post zm d{_bacB.H<=+\hBjsk y>k _za nxQff8hQj]k y>k _ba nx6Bff



ff post zm d\_bacB.A hand, apply rBkwr\_bac
i.e., ff post zm d{_bacB.)

successfully : ffgrBkwr\_bacB()



easily verified syntactic operation state specification using function
corresponds state transitions states described specification.
Proposition 1 Let state specification, L operator, { induced state-transition
function. $D8ffiLQ0) ,

EF:GH$$DffiLB.),+{C 0gC ){C>ffeC0 )Dfi6BA
$DffiLB;0 ) , either
1.

EF:GH$D()

,

2. two states C
3.

MC ff post LB. ,
ffeC /E:G$D( MC ff post LB.)
exists state CWE:GH$D {>C> undefined.
276

fiC OMPILABILITY

E XPRESSIVE P OWER P LANNING F ORMALISMS



words, whenever $DffiLB results legal specification, specification describes
states result application state-transition function > states satisfy
original state specification . Further, $D8ffiLQ illegal, good reasons it.

planning instance tuple

)~N&ffifft5Pff






)~N$fftP domain structure consisting finite set propositional atoms
finite set operators ,


initial state specification,
goal specification.



talk size instance, symbolically 00 00 , following, mean size
(reasonable) encoding instance.
following, use notation refer set finite sequences operators.
Elements called plans. 00 300 denotes size plan, i.e., number
operators . say -step plan 00 3008 . result applying state
specification recursively defined follows:

!B
;
R R
;!t$Dff\N$P.)
;!t]$Dff\NL iff L ffgAgAgA:ffiL>KP.) ;!]$$DffiL ff\NL ffgAgAgA{ffiL{KP.


sequence operators said plan solution iff
1. X!]ffe0)
2. X!]ffe;0 ) .
Example 3 Let propositional
atoms operators introduced Example 1
consider following planning instance:
)N.N$fftPfft+:_bacKffgrBklr]ffklu>hK6Bfft+\hBjskffihQjsk y>k _za nx6>PA
words, given latex source file (_bac ) bibliography database ( rBklr ), want generate dvi
file (hBjsk ) citations file correct (hBjsk y>k _ba nx ). Furthermore, know
know index file yet
anything existence bbl-file aux-file etc.,
( kwu{h ). plan )~Nzrsklr\_bacffgm d{_zacsP solution plan result illegal
state specification resulting state specification entails hQj]k hBjsk y>k _ba nx .
Plans satisfying (1) (2) sound. order state precisely, extend
notion state transition functions operators state transition functions plans. Let {
state transition function corresponding composition primitive state-transition functions
induced operators )~NL ffgAgAgA\ffiL>P , i.e.,



B e. b> ) >eAgAgAQfi{bvff
4. could liberal requiring . done order allow fair
comparison restricted planning formalisms.

277

fiN EBEL


e. C> defined iff e. b C defined every , 9 . Using
notion, one easily proveusing induction plan lengththat plan instance
sound Lifschitz' (1986) sense, i.e., corresponds application state transition functions
initial states.


Proposition 2 Let )N&ffifft5P planning instance
. X!]ffe consistent,

)NL gff AgAgA\ffiL>P

element

E:GH$X!ffe.),+{C 0tC ){C>ffeC0 )>6BA
;!]ffe inconsistent, either
1.

EF:GH\()

,

2. exists (possibly empty) prefix
X!]ff\NL ffgAgAgA:ffiL P. either



(a) two states C


NL gff AgAgA\ffiL>$P (
3~ )

eff C WEF:GH$D(

MC

(b) exists state CWE:GH$D {bw

C>



D)

C ff post L> . ,
ff post L>2 .)
undefined.

2.2 Family Propositional Planning Formalisms
propositional variant standard STRIPS (Fikes & Nilsson, 1971), also call
follows, planning formalism requires complete state specifications, unconditional
effects, propositional atoms formulae precondition lists. Less restrictive planning
formalisms following additional features:
Incomplete state specifications ( ): state specifications may complete.
Conditional Effects ( ): Effects conditional.
Literals formulae ( ): formulae preconditions effect conditions literals.
Boolean formulae ( ): formulae preconditions effect conditions arbitrary
boolean formulae.
extensions also combined. use combinations letters refer multiple
extensions. instance, refers formalism extended literals precondition lists,

`s refers formalism allowing incomplete state specifications conditional effects,
%QB , finally, refers general planning formalism introduced Section 2.1.



Example 4 consider planning instance Example 3, becomes quickly obvious
instance expressed using . initial state specification incomplete,

operator d{_zac contains conditional effects negative literals effect conditions. However,
need general Boolean formulae express instance.
278

fiC OMPILABILITY



E XPRESSIVE P OWER P LANNING F ORMALISMS

`{

>

>>



{

`Q

`

`








Figure 1: Planning formalisms partially ordered syntactic restrictions

Figure 1 displays partial order propositional planning formalisms defined way.
sequel say specialization , written , iff identical
diagram depicting partial order.
Comparing set planning formalisms one Backstrom (1995) analyzed, one notices despite small differences presentation planning formalisms:



common propositional strips (CPS),

propositional strips negative goals (PSN),
ground Tweak (GT).
2.3 Computational Complexity Planning -Family

one would expect planning much easier planning %s , turns
case, provided one takes computational complexity perspective.
analyzing computational complexity planning different formalisms, consider,
usual, problem deciding whether exists plan given instancethe plan existence
problem (PLANEX). use prefix referring planning formalism consider
existence problem particular planning formalism.
Theorem 3



-PLANEX PSPACE-complete



%QB .

5. consider planning formalisms identical SAS formalism (Backstrom & Nebel, 1995), since
allow multi-valued state variables.

279

fiN EBEL

Proof. PSPACE-hardness -PLANEX follows result Bylander (1994, Corollary 3.2).
Membership %Qs -PLANEX PSPACE follows could, step step, guess
sequence operators, verifying step operator application leads legal follow
state specification last operator application leads state specification entails
goal specification. step, verification carried polynomial space. reason
conditions definition verified polynomially many calls
NP-oracle. Therefore, %Qs decided non-deterministic machine polynomial space,
hence member PSPACE.
follows plan existence problem formalisms expressiveness
%s including formalismsis PSPACE-complete.

3. Expressiveness Compilability Planning Formalisms
Although difference computational complexity formalisms
QB -family, might nevertheless difference concisely planning domains plans
expressed. order investigate question, introduce notion compiling planning formalisms.
3.1 Compiling Planning Formalisms
mentioned Introduction, consider planning formalism expressive another
formalism planning domains plans formulated formalism concisely expressible
. formalize intuition making use call compilation schemes,
solution preserving mappings polynomially sized results domain structures
domain structures. restrict size result compilation scheme,
require bounds computational resources compilation. fact, measuring
expressibility, irrelevant whether mapping polynomial-time computable, exponential-time
computable, even non-recursive. least, seems idea notion expressive
power discussed similar contexts (Baader, 1990; Erol et al., 1996; Gogic et al., 1995; Cadoli
et al., 1996). want use compilation schemes practice, reasonably
efficient, course. However, want prove one formalism strictly expressive
another one, prove compilation scheme regardless many
computational resources compilation scheme might use.
far, compilation schemes restrict size domain structures. However, measuring expressive power, size generated plans also play role. Backstrom's
ESP-reductions (1995), plan size must identical. Similarly, translation


proposed Gazen Knoblock (1997) seems implicit prerequisite plan
length target formalism almost same. comparing expressiveness
different planning formalisms, might, however, prepared accept growth plans
target formalism. instance, may accept additional constant number operators,
may even satisfied plan target formalism linearly polynomially larger.
leads schematic picture compilation schemes displayed Figure 2.
Although Figure 2 gives good picture compilation framework, completely
accurate. First all, compilation scheme may introduce auxiliary propositional atoms
used control execution newly introduced operators. atoms likely
initial value may appear goal specification planning instances target
280

fiC OMPILABILITY



E XPRESSIVE P OWER P LANNING F ORMALISMS




Planning

compilation





G



B

Planning



Figure 2: compilation framework

formalism. assume compilation scheme takes care adds literals
initial state goal specifications.
Additionally, translations initial state goal specifications may necessary.
want compile formalism permits literals preconditions goals one requires atoms, trivial translations necessary. Similarly, want compile formalism
permits us use partial state specification formalism requires complete state specifications, translation initial state specification necessary. However, state translation
functions limited. depend set symbols source
formalism, context-independent, i.e., translation literal state specification
depend whole specification, efficiently computable.
compilation framework theoretical tool measure expressiveness, has,
course, practical relevance. Let us assume reasonably fast planning system
planning formalism want add new feature resulting formalism .
come efficient compilation scheme , means easily integrate
new featureeither using compilation scheme modifying planning algorithm
minimally. compilation scheme exists, probably would problems integrating feature. Finally, computationally expensive compilation schemes exist, interesting
situation. case, off-line compilation costs may high. However, since compiled
domain structure used different initial goal state specifications, high off-line costs
may compensated efficiency gain resulting using planning algorithm.
turns, however, situation arise analyzing compilability %Qs formalisms. Either identify polynomial-time compilation scheme able prove
compilation scheme exists.

6. means compilation schemes planning formalisms similar knowledge compilations (Cadoli &
Donini, 1997), fixed part computational problem domain structure variable part consists
initial state goal specifications. main difference knowledge compilation framework
also take (size the) result account. words compile function problems instead decision
problems.

281

fiN EBEL



3.2 Compilation Schemes
Assume tuple functions M)N>>ffe ffe>Qff
N&ffifft5P -instances follows:

ffz>P

induce function





-instances

)



()N@>>ffe H< $ffi\ffe>s%<zs$fft9.PgA


following three conditions satisfied, call compilation scheme



iff exists plan

1. exists plan



;

2. state-translation functions z modular, i.e.,
D0) , functions (for ?)eff ) satisfy






:

~) </ ,

,



$ffD(()
$ ffDfiff H< $ ffDff ff

polynomial-time computable;
3. size results >\ffe , > polynomial size arguments.
Condition (1) states function induced compilation scheme solutionpreserving. Condition (2) states requirements on-line state-translation functions. result
functions computable element-wise, provided state specification consistent. Considering fact functions depend original set symbols
state specification, requirement seem restrictive. Since state-translation
functions on-line functions, also require result efficiently computable.
Finally, condition (3) formalizes idea compilation. compilation much
important result concisely represented, i.e., polynomial space, compilation process fast. Nevertheless, also interested efficient compilation schemes. say
polynomial-time compilation scheme >\ffe , > polynomial-time computable
functions.
addition resource requirements compilation process, distinguish different compilation schemes according effects size plans solving
property every plan
instance target formalism. compilation scheme
solving instance exists plan solving 00 @0000 300

positive integer constant , compilation scheme preserving plan size exactly (up additive
00 300 positive integer constants
, compilation
constants). 00 @00K
scheme preserving plan size linearly, 00 00-i00 300lff{00 00 polynomial - ,
compilation scheme preserving plan size polynomially. generally, say planning formalism compilable formalism (in polynomial time, preserving plan size exactly,
linearly, polynomially), exists compilation scheme appropriate properties.

write
case compilable compilation done polynomial time. super-script , , - depending whether scheme preserves plan size
exactly, linearly plan, polynomially, respectively.
easy see, notions compilability introduced reflexive transitive.
7. Although hard imagine modular state-translation function polynomial time computable,
pathological function could, e.g., output translations exponential size encoding symbols.

282

fiC OMPILABILITY

Proposition 4 relations







E XPRESSIVE P OWER P LANNING F ORMALISMS







transitive reflexive.

Furthermore, obvious moving upwards diagram displayed Figure 1,
always polynomial-time compilation scheme preserving plan size exactly. v denotes
projection -th argument function returns always empty set, generic
compilation scheme moving upwards partial order )ON ffeffeff ff P .
Proposition 5 J ,









.

4. Compilability Preserving Plan Size Exactly
Proposition 5 leads question whether exist compilation schemes
implied specialization relation. Proposition 5 Proposition 4,
find compilation schemes every pair formalisms. suffices prove compilable
, order arrive conclusion formalisms compilable
formalisms .
preview results section given Figure 3. establish two equivalence
classes members class compilable preserving plan size exactly.
two equivalence classes called - -class, symbols ,




naming respective largest elements.

{

>

>



{

Q

>







`


Figure 3: Equivalence classes planning formalisms created polynomial-time compilation
schemes preserving plan size exactly

283

fiN EBEL

4.1 Planning Formalisms without Conditional Effects Boolean Formulae
First, show formalisms analyzed Backstrom (1995), namely, , ,


polynomial-time compilable preserving plan size exactly. fact, fourth class
added set, namely, ` , lies .

words, using notion compilability, get equivalence class
Backstrom's ESP-reductions. closer look proofs Backstrom's (1995) paper reveals surprising ESP-reductions used could reformulated
compilation schemes. Since used quite different notation, nevertheless prove claim
first principles.
key idea compiling planning formalisms literals formalisms allow atoms

consider - 4- different atoms new formalism. purpose, introduce
!
!
, "? set negative
copy . Further,
J),+ -0 -=/6 , i.e., disjoint
!
literal 4- replaced - , i.e.,
#

?)
"



!

!
+.-//I0 -3=76fi<=+ -3
J0:4-53;6

0) ff
otherwise.

!

Using < new set atoms, one translate state specifications preconditions easily. postconditions make sure intended semantics taken care of, i.e.,
!
whenever - added, - must deleted vice versa.
Finally, deal problem partial state specifications. However,
problem effects unconditional preconditions contain atoms.
case, safely assume atoms unknown truth-value false without changing
outcome application operator. Let $&%*fi denote completion respect
, i.e.,

fi*),+>4-90 -3/ff-3
76fi<?XA

$&%

Using function, transform partial state specification complete specification
without changing outcome, i.e., get plans.
Theorem 6
exactly.

, ` ,

, polynomial-time compilable preserving plan size

Proof. Since ^`H Z

, follows Propositions 4 5
show

order prove claim.

Let )N&ffifft5P -instance )N$fftP . translate operator L

operator
!
L)~N'" pre LBff(" post LQ<5)"5 post LQ.PA
set operators denoted
N>>ffe ffe>Qff ffz{P follows:

>)
)
>s)
$ffi\)
zs$fft9)



!

. define compilation scheme
!

!

$N < ff
Pff
ff
ff
$&% +* ! ' "?\ff
"==A
284

W)

fiC OMPILABILITY



E XPRESSIVE P OWER P LANNING F ORMALISMS

satisfies conditions (2) (3), functions computed polyThe scheme obviously
nomial time, -instance.
. obvious
Let
!

$ff$DffiLB.(), $ffD(ff LBA
!

) .N -L ffgAgAgA:ff/L- P denote sequence operators corresponding sequence operators

)~NL ffgAgAgA:iff L>vP . Using induction plan length, easy show
!
plan iff plan ,
i.e., condition (1) compilation schemes also satisfied. means, fact compilation
Let

scheme. Further, since plan size change, compilation scheme preserves plan size
exactly. Finally, functions computed time polynomial arguments,
polynomial-time compilation scheme.
One view result matter whether, expressivity point view,
allow atoms literals matter whether complete partial state
specificationprovided propositional formulae conditional effects allowed.
4.2 Planning Formalisms Conditional Effects without Boolean Formulae
Interestingly, view spelled generalizes case conditional effects allowed. Also case matter whether atoms also literals allowed
whether partial complete state specifications. proving that, however, two
additional complications. Firstly, one must compile conditional effects partial state specifications conditional effects complete state specifications. problem
$D8ff post LB. definition function must tested. Seccondition $Dff post LQ.)
ondly, compiling formalism literals formalism allows atoms only,
condition M$Dff post LB.0) definition must taken care of. reason,
prove result two steps.
first step, show compiled . problem specifying


compilation scheme execution operator L partial state specification leads

$Dff post LB. .
illegal state $Dff post LB.)
considering running example (Ex. 1), things quite obvious. state specification contain literal negation literal mentioned effect
condition, illegal state specification results. example, state specification neither contain r]rsm &rsrsm , result executing d{_bac . general case, however,
things less straightforward effect literals produced one conditional
rule effect condition consist one literal.
Assuming without loss generality (using polynomial transformation) effects
singleton sets, check following condition. Either one conditional effects
effect literal activatedi.e., effect condition entailed partial state
conditional effects effect literal blocked, i.e., effect condition
contains literal inconsistent state specification. true, original operator
$Dff post LQ. , otherwise resulting state specification inconsistent.
satisfies $Dff post LB.)
example, consider following operator:

L )


N$fft+Q+.-ff8[]6 V +>4-H6Bfft+10ff2v6 V +>4-H6Q6>PA
285

fiN EBEL

application operator satisfies $Dff post LB.)
1.
2.

-

0

8[ true state specification,

$Dff post LB.

iff either

2 true state specification,

3. one - *[ false one 0 2 false.



cases, get M$D8ff post LB.)
$Dff post LB. result illegal state. order
test condition formalism complete states introduce four new sets atoms:

)
)

+.- 0 -3=6Bff
.+ - 0@-3/6Bff
43 ) .+ -53=0@-3/6Bff
6
) +1 7X0 8 th conditional effect L 6BA
atom - true either - 4- part original partial state specification. atom
- set true operator one conditional effects adds - - appear
effect operator. atom 5
- 3 set true operator one conditional effects deletes
- 4- appear effect operator. Finally, atoms form 7 added
action 8 th conditional effect th operator blocked effect condition. Using
new atoms, could translate operator

N$ff8+H+.-`ffi[>ff-ff8[]6 V V +.-4 ff-53*ff4-6Bff
+ 0 ff 2 ff 0ff V 2`6 +.- ff- 3 ff4-H6Bff
1
+.-`ff4-6 V +1 6Bff
+\[ ffi[]6 V 1+ 6Bff
+ 04ff9 0H6 V 1+ 6Bff
1
+ 2]V ff9 2v6 1+ ` 6Bff
1
V <5 3 6 I+.- 3 6Bff

+ ;:X 7 (0 < )Z
1
.6Q6>PA
Let = eff>8] function returns - 5
- 3 , - 4- , respectively, effect 8 th
conditional effect th operator. Assuming atoms fi set according
6
intended semantics previous operator deleted atoms 7=<W4
35< ,
>L ! )

following test operator checks whether original operator would led inconsistent result:
test

)

ffA@+>9 7ff9=8 iff>8]e6 V 0( 7
?

6BDC



Whenever 9 7 , means 8 th conditional effect th operator (which must
previously executed operator) blocked. addition effect conditional
$Dff post LB.
effect activated, i.e., 9=8 iff>8] true, would $Dff post LB.)
original formalism. reason, force illegal state. Conversely, either 7 true
8 false one 8 , = eff>8] true, would $Dff post LQ.) $D8ff post LB.
original formalism need force illegal state.
!
could force, using extra literals, operator L{ test operator
applied. would result compilation scheme preserves plan size linearly. However,
possible better that. key idea merge test operator th step
operator step E .
286

fiC OMPILABILITY



E XPRESSIVE P OWER P LANNING F ORMALISMS

polynomial-time compilable preserving plan size exactly.

)N&ffifft9P -instance ~)N$fftP . Without loss generality,
Proof. Let
assume postconditions operators L 1 following form:
V F ffgAgAgA:ffi : H
G
V F :z6Bff
post L ),+\





F
7
7I .
Lemma 7



First, introduce number new sets symbols pairwise disjoint disjoint
:

)
JI )
)


)

I3

3
6

6

+.-
.+ -KI
+.-
+.- I3
+.- 3



)
)

)


0@-=/6Bff
0z-3/6Bff
0z-3/6Bff
0z-3/6Bff
0z-3/6Bff
+1KI 7 0 8
+1 7 0 8

th conditional effect L

6Bff
th conditional effect L 6BA

, denotes set primed literals, i.e., )+.- 0i-^Z76<
given set literals
2, i.e., C]Mv=)
+>4-`*0"$4- W76 function CLl denotes successor function modulo
6
MN\DOQPSRUT . Further, functions =WV )ff: shall functions V JV <9JV3

#
V [Bfi post L ff
V / V
[
7

= V eff>8])
[ V3 / V3 ( 7 V 8[B post L>A
let postV

L

postV
let block V

L

)ff: defined follows

L *)+\/<?'(2 VV .+ -ff-`ff- V
6 0@-3/ff\ V V %- post L e6&<
+\/<?'(2 >+ 4-ff-`ff- V3
6 0 -3Wff\
" - post L>$e6Bff

)ff: defined
block V

L ()+Q+\[ffi[{ 6 V V V 7 0Q 7 VXVXF F 7{ post L ff\$*[Q75 7>6&<
+Q+>8[ffi[ 6 WV 7 0 7
7\& post L ffi[3 7>6Bff

let testV defined

Z
Z
Z
6 Z
V\[ 6BA
),+Q+>D 7 V\[ ff9= V\[ iff>8]e6 V 0] 7 V\[
6
V .
Further, let , , fresh symbols appearing <3 <=JV <3JV 3 <
define pair compiled operators L V ( )ff: ) corresponding original operator L W :
L V )ON pre L H<=+\ V 6Bff postV V L %< blockV ZL %< testV <
+> V +>*/ V]ff^ `ffi V\[b6Q67<
+> V V <9 V3 6 J+1= V iff>8]e6Q6X<
+>
+ K:;
1
V 7
.6Q6&<
Z V\[ V]0 < Z V\[ )
6
V
+>
<5( 3 <5 Z V\[ 6BA
{C

1 V

287

fiN EBEL

pair compiled operators achieves intended effects keeps track fully known
atoms using postV , checks conditional effects blocked using block V , tests whether
$Dff post LB. using
execution previous operator satisfied condition $Dff post LB.)
testV , setup bookkeeping atoms next step. Using atoms /V , enforced
executing testing merged parallelizing test step execution step 9 .
order check execution last step, need extra checking step:

L V )ON +\ V B6 ff test V <=+> V +\`ff8 V Q6 6>PA
specify compilation scheme

> )

follows:
6
6
N\
9
<
fi



9
<

<=+\`ffi ffi{g6Bff
<5 <5 3 <93 <
<
_
+\L ffiL 0tL 1?6fi<=+\L ffiL 6>Pff
6
6
+>^4ffi/IBff8 6&<9(JI 5
< ( <5JI3 <3( 3 <5 I(<9 ff
+\v6Bff
$&% \%
< $&% +.- 0 -3=fft+.-ff"-H6Jff?)
]6>ff
/A

)
>B )
$ffi\ )
$fft5)

scheme obviously satisfies conditions (2), i.e., state-translation functions modular,
polynomially sized results. Further, functions
(3), i.e., compilation functions
computed polynomial time, -instance.

. obvious
Assume




< *)X!],z.$ffD(H<9>bff\NL P.5ff1
< ff
.$ff;!t]$Dff\NL> P..5ff1
provided ;!t]$Dff\NL P.0) . case ;!t]$Dff\NL P.F0 ) , either ;!t], $ffD(&< ff\NL P.0 )
M$Dff post L .) $Dff post L . . latter case, application operator
;!t], $ffD(ff\NL P. leads inconsistent state conditional effects test ,
part postconditions operators applicable state. Additionally, true
relation zb$ffX!]$Dff\NL>.ffiL 7 . ;!],zi$ffD(H<?>.ff\NL ffiL]7 P. .
Let )~NL ffgAgAgA\ffiL P denote sequence operators corresponding sequence operators
)~NL ffgAgAgA:ffiL>v P . Using induction plan length, easily shown







iff

plan

Further, since plan solving instance



exists plan



a` LAV


plan



.

must LAV last operator, follows

iff exists plan



.

follows immediately polynomial-time compilation scheme
preserving plan size exactly, proves claim.







proved compiled preserving plan size exactly, seems worth


noting result depends semantics chosen executing conditional operators partial state specifications. example, use alternative semantics deletes literals


7 $Dff post LB.ZM$Dff post LB. provided $Dff post LB. consistent, exists probably compilation scheme preserves plan size linearly. use semantics
288

fiC OMPILABILITY



E XPRESSIVE P OWER P LANNING F ORMALISMS

resulting state specification legal application state-transformation functions leads
theory represented set literals, seems unlikely exists scheme
preserves plan size polynomially. reason pessimistic conjecture
semantics appears coNP-hard determine whether state specification resulting
applying B -operator legal.

second step showing partial state specifications literals compiled away,
show compile . key idea proof proof

!
Theorem 6. replace negative literal 4- new atom - . order detect inconsistencies
introduced conditional effects, add postcondition conditional effects form
!
+.-ff -%6 V . Further, check last operator plan introduce inconsistencies,
force application checking operator contains conditional effects.
Lemma 8




polynomial-time compilable



preserving plan size exactly.

Proof. Let
) N&ffifft9P -instance ) N$fftP . Since
postconditions operators L1 following form:

b

post LB()+\



VXb gff AgAgA\ffi




:

VXb

:







-instance,

6Bff

^7Bff 7
.
!
proof Theorem 6, shall disjoint copy , "9 set atoms
!
c LQ following set
negative literal 4- replaced atom - . let post
post
c LB()+

?^7 V '"

b

"

fi<5)"5
7

b

\(097 VXb {7 fi
7

post LBe6BA

Further, let cons set conditional effects
cons

),+Q+.-ff -H! 6 V 0@-3/6Bff
!

let atom appearing , let L

L! )~N'"

let

!

O)+
L! 0tL1?6

pre LBff
post
c LBH< cons <=+>

V 9v6>Pff

, let operator L>

L>)~N$ff cons <=+> V ` 6>PA

specify compilation scheme

>Q )
)
>s )
$ffi\ )
zs$fft5)

follows:
!
!
N$< <3+\v6Bff =
< +\L>Q6>Pff
+>^ `6Bff
+\v6Bff
"?(<5d
"58ff
"=/A

satisfies conditions (2) (3), functions computed polyThe scheme obviously
nomial time, -instance.
289

fiN EBEL

Assume



. obvious
!

$ff$DffiLB.), $ffD(ff LBff

provided $DffiLB0)

!

!



!

case $DffiLB;0 ) , either , $ffD(ff LB;0 ) +.-ff -%6
, $ffD(ff LB -=/ .
!
latter case, application operator , $ffDff LB leads inconsistent state
conditional
effects cons, part postconditions.
!
Let )N.-L ffgAgAgA:ff/L- P denote sequence operators corresponding sequence operators

)~NL ffgAgAgA:ffiL>vP . Using induction plan length, easily shown







iff

plan

Further, since plan solving instance



exists plan



!

`



L>

plan



.

must L> last operator, follows

iff exists plan

follows polynomial-time compilation scheme
proves claim.









.

preserving plan size exactly,

result is, course, dependent semantics formalisms deal
$Dff post LB. .
complete state specifications, hence always M$Dff post LB.()
Theorem 9
size exactly.

, , `

,



polynomial-time compilable preserving plan

Proof. B follows Lemma 8, Lemma 7 Proposition 4. Using Propositions 4

5 fact `B` , claim follows.







5. Limits Compilation Preserving Plan Size Linearly
interesting question is, course, whether compilation schemes preserving plan
size exactly identified far. turns out, case. prove
pairs formalisms identified compilation scheme preserving
plan size exactly, compilation scheme impossible even allow linear increase
plan size. pairs formalisms even able prove polynomial increase
plan size would help establishing compilation scheme. results are, however,
fhe assumption. preview
conditional based assumption slightly stronger eF)g
results section given Table 1. symbol means exists compilation
scheme first formalism specialization second one. cases,
specify separation give theorem number result.
5.1 Conditional Effects Cannot Compiled Away
First all, prove conditional effects cannot compiled away. deeper reason
conditional effects, one independently number things parallel,
impossible formalisms without conditional effects. consider, example,
operator d{_zac Example 1, clear `propagates' truth value rsr]m klu{h
hQj]k y>k _ba nx hBjsk klu>h nx , respectivelyprovided state specification satisfies precondition.
290

fiC OMPILABILITY



%s


Qs


%s





%]


%Q
j


%


Cor. 15

Cor. 12

Cor. 15

Cor. 15

ji

ji

4i

Theo. 11

Cor. 12

Cor. 12

ji

ji

4i

Cor. 12

Cor. 12

Cor. 19

)





ji



%









Cor. 15









Theo. 14





)

















Cor. 15



Theo. 18






)

Cor. 19

%Q






Cor. 15







)

k



E XPRESSIVE P OWER P LANNING F ORMALISMS
















Cor. 15





)

Cor. 19



)

Table 1: Separation Results

obviously possible come set exponentially many operators
thing one step. However, unclear less exponentially many operators.
fact, show impossible.
order illustrate point, let us generalize example. start set
propositional atoms &) +.- ffgAgAgA:ff-``6 disjoint copy set: ml ) +.- l 0- ,fiv6 .
Further,


fi



, Dnl shall denote corresponding set literals


Consider following





)



l

, i.e.,

)+.- l 0@- =Dfi6&<=+>4- l 0g4- /D6BA
l



domain structure:

fi<5 l ff
B
) @*N$fft+.- V - l ff"- V 4- l 0@- Wfiv6>P ff
) N$ ff8 PA
construction follows pairs fft5 consistent complete set
1l , instance )N `ffifft5P one-step plan. Conversely, pairs
fi

fft9 gff l 1 l , exist solution.
Trying define domain structure polynomially sized 00 00 property

seems impossible, even allow -step plans. However, trying prove this, turns
additional condition state-translation function needed.
say state-translation functions local iff state specifications
ff5 )







$ ff Dpff qff s$ ffDff ()A
291





fiN EBEL

locality additional condition state-translation functions could easily prove
conditional effects cannot compiled away. Instead show, however,
possible derive weaker condition definition compilation schemes
enough prove impossibility result. weaker condition quasi-locality state-translation
functions relative given set symbols , turn based notion universal
F
literals. literal called universal literal given state-translation functions iff one
following conditions satisfied:
1. -3= :

F

2. -3= :

F

3. -3= :

F

4. -3= :

F

5. -3= :

F

6. -3= :

F

p +.-6Bfft+.-H6> ,
p +.-6Bfft+>4-H6> ,
p +.-6BffeB ,
pzs +.-H6Bfft+.-H6> ,
pzs +.-H6Bfft+>4-H6> ,
pzs +.-H6BffeB .

Let r denote set universal literals. define quasi-locality state-translation functions relative set propositional atoms induced set universal literals r follows.
D0) pairs ff ff3 ) ,








W
r

$ ff Dff sffzs$ ffDfiff







words, non-local literals quasi-local state-translation functions universal literals.
Lemma 10 given compilation scheme F)N>{ffe
00ut^
exists set atoms



ffe>Qff ffz>P natural number
quasi-local .

,

R;v function result union results possible
Proof. Let
translations literal returned state-translation functions, i.e.,
gl- *) +.-H6Bfft+.-H6>< +.-H6Bfft+>"-H6>< +.-H6BffeB.<
+.-H6Bfft+.-6>
< zB +.-H6Bfft+>4-H6>
< zs +.-H6BffeBA
Set

5)
w

r) . choose infinite subset
w





w

either

1. -3xw , finitely many atoms [xw" ,glor infinite subset w exist,
2.

w



universal literal

F

fi
r

set r?`)
r<=+

F

6

Aff4g[Q.sUr )


,

.
F

r must
Note infinite subset w must exist. reason literal
occur infinitely many atoms w could find infinite subset
satisfying condition (1). single atom six possible ways generate
F
, must exist infinite subset literal occurs either v +.-H6Bfft+.-H6> ,
F
v +.-H6Bfft+>4-H6> , zv +.-H6BffeB (for ?)iff ) subset universal literal.
292

fiC OMPILABILITY



E XPRESSIVE P OWER P LANNING F ORMALISMS

pick subset satisfying first condition, choose finite subset
desired cardinality state-translation functions quasi-local respect
r .
Otherwise repeat selection process w r condition (1) satisfied.
selection process repeated finitely often otherwise atoms tl- infinite result, impossible state-translation functions
polynomial-time computable therefore finite results.
demonstrates always exists set propositional atoms statetranslation functions quasi-local. However, might able effectively determine
set.
Using result, finally able prove non-existence compilation schemes
compiling conditional effects away preserving plan size linearly.
Theorem 11



cannot compiled % preserving plan size linearly.

Proof. Assume contradiction exists compilation scheme %Q preS
serving plan size linearly, compiles domain structure defined %

domain structure

> ) )ON$ tff PA
Lemma 10 assume set atoms chosen translation

functions quasi-local set.
Let us consider initial state specifications consistent complete
contain positive negative literals:

Obviously,
following form



{T





K
/R
+>fi4ff(fiK6BA

state specifications. assumption,

%Q

instance

N ff5 .$ ffi\H<?>b ff5 $ ffi l H<9 .P
-step plan. Since |i0 0 different -step plans, number polyno
mial size , plan used different initial statesprovided sufficiently

large.
Suppose plan used pairs fft ff\t fft , result :



) $fi4ffi H<9 K
) $ ffi l %<9
) $fi4ffi H<9 K
) zs$fi`ffi l %<9>s K

Since )
, must differ least one atom, say - . Without loss generality
assume -33 4-35 . Since successful plan modular,




follows

X!] ffeh}

zs +.- l B6 fft+.- l >6

}~

293

fiN EBEL

literals zs +.-Kl;6Bfft+.-KlX6> may added operators none literals
+.- l 6Bfft+.- l 6> deleted operator without reestablishing literal another
operator deletion. contains operators unconditional effects, adds
deletes literals regardless initial state.
F
Let us assume exists literal zs +.-Kl;6Bfft+.-KlX6> added .
F
implies 3t distinguish three cases:


= K , conclude F 3t .
F
2. p +.K
- lX6BffeB , also implies F 3t .
F
3.
state z. +\[s6Bffi& [^) K- l ,+Q+\[s6BfftF +>*[s6Bffe]6 . assumed
F
translation functions quasi-local , must universal literal. universal

F
contain positive negative
, possible initial states
F
literals well literal elements . universal , present
F
reason. Further, added valid


plan , must also part .



F
words, literals
+.K- lX6Bfft+.K- lX6> added already .
conclude
;!] ffe }y +.- l 6Bfft+.- l 6>A
1.

F

let

)
)

$ +.- l 6Bffi l J+>4- l 6>H<9 ff

< +.- l 6Bfft+.- l 6>
) zs$ 4ffi l +>"- l 67<=+.- l 6>H<9>B vA
z modular, clear } therefore ;!t]t ffefi} .




achieves well +.-KlX6Bfft+.-KlX6> , follows (again modular), achieves

also .

Since N ffi ffi l Z+>4K
- l;67</+.E- l76>P plan, plan

N ffi fft P . fact plan instance implies cannot compilation
scheme, desired contradiction.
Using Propositions 4 5 well Theorem 9, result generalized follows (see
also Table 1).
Corollary 12 %Qs , %] ,
preserving plan size linearly.




cannot compiled %Q formalism specializing %

answers question whether space efficient compilation schemes

one proposed Gazen Knoblock (1997) possible. Even assuming unbounded
computational resources compilation process, space efficient compilation scheme
impossibleprovided compilation preserve plan size linearly. allow polynomially larger plans, efficient compilation schemes possible (see Section 6).
8. result demonstrates choice semantics important. interpret conditional effects
sequentially Brewka Hertzberg (1993) do, exists straightforward compilation scheme preserving
plan size exactly.

294

fiC OMPILABILITY



E XPRESSIVE P OWER P LANNING F ORMALISMS

5.2 Non-Uniform Complexity Classes
next section make use so-called non-uniform complexity classes, defined
using advice-taking machines, order prove impossibility compilation scheme.
advice-taking Turing machine Turing machine advice oracle, (not necessarily recursive) function positive integers bit strings. input , machine loads
bit string i00 "00 continues usual. Note oracle derives bit string
length input contents input. advice said polynomial
oracle string polynomially bounded instance size. Further, complexity class defined terms resource-bounded machines, e.g., P NP, J]pBnm (also called non-uniform
X) class problems decided machines resource bounds
polynomial advice.
advice oracle, class P/poly appears much powerful P. HowY es]pBnm
ever, seems unlikely P/poly contains NP. fact, one prove fJe
implies certain relationships uniform complexity classes believed unlikely. stating result, first introduce polynomial hierarchy.
Let X class decision problems. e+ denotes class decision problems
decided polynomial time deterministic Turing machine allowed use
procedurea so-called oraclefor deciding problem , whereby executing procedure
cost constant time. Similarly, fJe denotes class decision problems

polynomial time using
nondeterministic Turing-machine solves
instances



defined follows:
oracle ~p . Based notions, sets , ,












)

V )

V )

)
V









V

V

V



)
)eff
e ff

ff
fJe
ygn fJe

Thus, )gfhe

)ygnfJe . set classes defined way called polynomial
hierarchy, denoted PH. Note

F)
V

e^







V


)
V


V

)
V






V



"A

e sekD

have,
ff
ff
V . classes, unknown whether
V
V
V
V
V
inclusions classes proper. However, strongly believed case,
i.e., hierarchy truly infinite.
Based firm belief polynomial hierarchy proper, mentioned question
eE]pBnm answered. shown fJe es]pBnm would imply

whether fJe

polynomial hierarchy collapses second level (Karp & Lipton, 1982), i.e., )
yg nfhes] pB.nThis,

however, considered quite unlikely. Further, shown fJe

ygnfJe fJ es ]pBnm implies polynomial hierarchy collapses third level (Yap, 1983),
i.e.,
) , considered unlikely. use result proving

pairs formalisms unlikely one formalism compiled
one.
9. super-script used distinguish sets analogous sets Kleene hierarchy.

295

fiN EBEL

5.3 Expressive Power Partial State Specifications Boolean Formulae
cases considered far, operators partial state specifications could compiled
operators complete state specifications, i.e., partial state specifications add expressiveness. longer true, however, also allow arbitrary boolean formulae
preconditions effect conditions. case, decide coNP-complete problem
whether formula tautology deciding whether one-step plan exists. Asking, example,
Q -instance N$fft+]Nff KPe6Bffefft+\v6>P plan equivalent asking whether tautology.
Let one-step plan existence problem (1-PLANEX) PLANEX problem restricted
plans size one. evident %QB -1-PLANEX %Q -1-PLANEX
coNP-hard. Let - fixed polynomial, polynomial step plan-existence problem
(- -PLANEX) PLANEX problem restricted plans length bounded - ,
size planning instance. easy see, problem NP formalisms except
%QB %Q . reason guessing sequence operators state specifications
polynomial size, one verify step polynomial time precondition satisfied
current state specification produces next state specification. Since
polynomially many steps, overall verification takes polynomial time.
Proposition 13 -- -PLANEX solved polynomial time nondeterministic Turing machine formalisms different %s %Q .
fact % -1-PLANEX coNP-hard and, e.g., %s -p-PLANEX NP, follows
almost immediately polynomial-time compilation scheme Q ]
ygnfJe ). However, even allow unbounded
preserves plan length polynomially (if fhe)
computational resources compilation process, proof technique first used Kautz Sel
).
man (1992) used show compilation scheme cannot exist (provided )



Theorem 14

%Q

cannot compiled %] preserving plan size polynomially, unless



)



.

Proof. Let propositional formula size conjunctive normal form three literals per
clause. first step, construct % domain structure * size polynomial
following properties. Unsatisfiability arbitrary 3CNF formula size equivalent
-step plan existence % - -PLANEX instance N8`ffi1 fft+\`6>P , 1 computed
polynomial time .
Given set atoms, denoted , define set clauses set containing
clauses three literals built using atoms. size | , i.e.,
polynomial . Let ? set new atoms -E . corresponding one-to-one clauses
. Further, let
B

)@9 F F F M- . (0\+ F ff F ff F 6M
construct % domain structure 8)~N$fivfftKP formulae size follows:


&




)

)

<?<=+\v6Bff
+]N +> v6Bfft+\v6>Pe6BA


296

fiC OMPILABILITY



E XPRESSIVE P OWER P LANNING F ORMALISMS

Let function determines 3CNF formulae , atoms ? correspond
clauses formula , i.e.,

*()+.- . 0\+ F ff F ff F 63(6BA
Now, initial state particular formula size computed follows:
)h *H<1 ?M~*.H<=+>^v6BA
1
construction, follows exists one-step plan N$&`fft`ffi1"fft+\v6>P


iff





unsatisfiable.
Let us assume exists compilation scheme %Q %] preserving plan
size polynomially. Further, let us assume % domain structure 8 compiled %]
domain structure * )N$fi fft P . Using compiled domain structure, construct
following advice-taking Turing machine.
input formula size , load advice N8 ffe $&`fftffe>]$&`fft.P .
advice polynomial 8 polynomial size compilation scheme generates
polynomially larger domain structures. polynomial-time function 1
computed polynomial time, compute

)
.$ ffi % <9>b$ fft
polynomial time. Also goal specification

) $ fft+\v6><9 $ fft
computed polynomial time. Finally, decide - -PLANEX problem resulting
%] -instance N ffi fft P . Proposition 13 know done polynomial time

nondeterministic Turing machine.
deciding - -PLANEX N ffi fft P equivalent deciding -PLANEX
N84ffi1"fft+\v6>P , turn equivalent deciding unsatisfiability , follows
decide coNP-complete problem nondeterministic, polynomial advice-taking Turing machine
fhe5]pBnm . Using Yap's (1983) result,
polynomial time. follows ygnfJe
claim follows.
Using Proposition 4 Proposition 5, result generalizes follows (see also Table 1).

Corollary 15 %Qs % cannot

compiled planning formalisms preserving

.
plan size polynomially, unless )





restrict form formulae, however, may able devise compilation schemes
%Q to, e.g., % . Reconsidering proof last theorem, turns essential
use negation CNF formula precondition. restrict CNF formulae
preconditions, seems possible move partial complete state descriptions using ideas
similar ones used proof Lemma 7.
However, compilation scheme work %s . reason condition
$Dff post LB.) $Dff post LB. definition function . condition satisfied, result operator inconsistent. condition could easily employed reduce
unsatisfiability CNF formulae 1-step plan existence, enables us use technique proof theorem.
297

fiN EBEL

5.4 Circuit Complexity
next impossibility result need notions boolean circuits families circuits.
boolean circuit directed, acyclic graph )'*ff , nodes called gates.
gate 2
type K!,2K+>fiff fiff
&ff:ffi6<F+1 ff ffgAgAgA26 . gates K!,2K

+sffiff ff ffgAgAgA26 in-degree zero, gates K!,2K+>6 in-degree one,
gates K!,2K+>
fiff 6 in-degree two. gates except one least one outgoing
edge. gate outgoing edge called output gate. gates incoming edges
called input gates. depth circuit length longest path input gate
output gate. size circuit number gates circuit.
Given value assignment variables +1
output gate obvious way. example,
gate circuit shown Figure 4.

ff ffgAgAgA6 , circuit computes value
)~ ) get value 1 output











Figure 4: Example boolean circuit

Instead using circuits computing boolean functions, also use accepting

words length +\ff:>6 . word )H AgAgA4+\ff:>6 interpreted value

assignment input variables ffgAgAgA:ff4 circuit. word accepted iff output gate

value 1 word. order deal words different length, need one circuit
possible length. family circuits infinite sequence )O' ff( ffgAgAgAw ,

input variables. language accepted family circuits theI set words
8 accepts .
Usually, one considers so-called uniform families circuits, i.e., circuits generated
Turing machine Pk( -space bound. Sometimes, however, also non-uniform families
interesting. example, class languages accepted non-uniform families polynomiallysized circuits class P/poly introduced Section 5.2.
Using restrictions size depth circuits, define new complexity
classes, uniform variants subsets P. One class important
following class languages accepted uniform families circuits polynomial size
logarithmic depth, named NC . Another class proves important us defined
terms non-standard circuits, namely circuits gates unbounded fan-in. Instead
restricting in-degree gate two maximum, allow unbounded in-degree.
class languages accepted families polynomially sized circuits unbounded fan-in
constant depth called ACI .
298

fiC OMPILABILITY



E XPRESSIVE P OWER P LANNING F ORMALISMS



definition, follows almost immediately AC
NC . Moreover,
shown languages NC non-uniform variant ACI ,
implies AC ) NC (Furst, Saxe, & Sipser, 1984).
5.5 Boolean Formulae Cannot Compiled Conditional Effects
seen Section 5.3, Boolean formulae quite expressive used combination partial state specifications. However, state specifications complete?
case, seems possible simulate evaluation CNF formulae using conditional
effects. fact, possible compile polynomial-time, example, % preserving plan

size linearly, provided formulae conjunctive normal form. operator would
split two operators, one evaluates clauses formulae original operator
one combines evaluations takes appropriate actions, e.g., asserting
precondition satisfied. Sequencing pairs operators achieved introducing
extra literals.
say general case, however? trying simulate evaluation
arbitrary logical formula using conditional effects, seems case need many
operators nesting depth formula, means would need plans cannot
bounded linearly longer original plans.
use results sketched Section 5.4 separate % . order so, let us

view domain structures fixed size plans machines accept languages. words
consisting bits, let

8)ON$fi<=+\`6BfftvPA
Assume atoms fi numbered 1 . word

consisting bits could

encoded set literals

,
) +.- 0

th bit

6fi<=+>4- 0 th bit K6BA

Conversely, consistent state specification fi , let word th bit 1 iff
- /D .
say -bit word accepted one-step -step plan 8 iff
exists one-step -step plan, respectively, instance

)~N.N$fi<=\+ v6BfftKPffi <=+>^ v6Bfft\+ `6>PA
Similarly families circuits, also define families domain structures, ) ffe ffgAgAgA .


language accepted family one-step (or -step) plan set words accepted
using domain structure 8 words length . Borrowing notion uniformity well,
say family domain structures uniform generated Pk -space Turing
machine.
Papadimitriou pointed languages accepted uniform polynomially-sized
boolean expressions identical NC (Papadimitriou, 1994, p. 386). easy see, family % domain structures nothing family boolean expressions, provided use
one-step plans acceptance.
Proposition 16 class languages accepted uniform families % domain structures using
one-step plan acceptance identical NC .
299

fiN EBEL

closer look power -step plan acceptance families

domain structures is, turns less powerful NC . order show that, first
prove following lemma relates -step plans circuits gates unbounded fan-in.





Lemma 17 Let F)~N$fftP domain structure, let
, let -step plan

. exists polynomially sized boolean circuit unbounded fan-in depth >;fiT
plan N&ffifft5P iff circuit value 1 input .
Proof. general structure circuit -step



.
.
.



plan displayed Figure 5.







1

1

.....



.
.
.

.
.
.



.
.
.

1









1

.
.
.

.....



. . .





Figure 5: Circuit structure goal testing -step



plan

7

plan step (or level) 8 atom - , connection - . connections level
input gates, i.e., - ) . goal test performed
-gate checks goals
true level , case )+.- ff4- ff- 6 . Further, using -gate, checked

inconsistency generated executing plan.
plan step 8 , must computed whether precondition satisfied
result conditional effects are. Figure 6 (a) displays precondition test precondition
+.- ff- ff4- 6 . conjunction precondition literals true, V becomes true,
connected -gate Figure 5.
Without loss generality (using polynomial transformation), assume conditional
VGF . Whether effect F activated level 8 computed circuit
effects form
V 4- .
displayed Figure 6 (b), shows circuit +.- ff4- 6

Finally, activated effects combined circuit shown Figure 6 (c). atoms - ,
check whether - 4- activated, would set true. one
inputs -gate Figure 5. neither - 4- activated, value -
level 8N determined value - level 8 . Otherwise value - level 8
7
determined value -W , i.e., activation value positive effect - level 8 .
depths circuits Figure 6 (b) (c) dominate depth circuit necessary
represent one plan step leading conclusion plan step represented using circuit
depth 7. Adding depth goal testing circuit, claim follows.
lemma implies -step plan acceptance indeed less powerful % 1-step plan

acceptance, means compilation scheme % preserving plan size linearly

impossible.
300

fiC OMPILABILITY



E XPRESSIVE P OWER P LANNING F ORMALISMS









1z










...
















(

(



(a)









z

(b)



z

(



(c)

Figure 6: Circuit structure precondition testing (a), conditional effects (b), computation
effects (c) operators



Theorem 18



, members







-class.

Proof. show %1 , Theorem 9 Proposition 4 claim follows.

Assume contradiction . Let ) ffe ffgAgAgA uniform family



domain structures `)8 ffe8 ffgAgAgAw domain structures generated compilation



scheme preserves plan size linearly. Lemma 17 know domain

structure )~N$ fft P given goal generate polynomially sized, unbounded fanin circuit depth >T tests whether particular -step plan achieves goal. order
decide -step plan existence, must test |i0 0 ie different plans, polynomial size
8 compilation scheme. plan, generate one test circuit,
adding another -gate decide -step plan existence using circuit depth >W size
polynomial size 8 . Further, since state-translation functions modular, results
fixed computed using additional level gates. Since Proposition 16
languages NC accepted uniform families % domain structures using one-step plan
acceptance, assumption % implies accept language NC (possibly

non-uniform) ACI circuits, impossible result Furst colleagues (1984).
Using Propositions 4 5 again, generalize theorem follows.
Corollary 19

]





cannot compiled



B







preserving plan size linearly.

6. Compilability Preserving Plan Size Polynomially
shown previous section, compilation schemes induced Propositions 4
5 ones identified Section 4 allow compilation schemes preserving plan size exactly. pairs formalisms able rule compilation schemeseven
301

fiN EBEL

allow linear growth resulting plans. Nevertheless, might still chance
compilation schemes preserving plan size polynomially. shown %Qs %Q cannot
compiled formalisms even plan grow polynomially, may still able
find compilation schemes preserving plan size polynomially %Qs /% pair
remaining formalisms.
preview results section given Figure 7. seen, able

`{>

>

>



{

B

>










Figure 7: Equivalence classes planning formalisms created polynomial-time compilation
schemes preserving plan size polynomially. Compilation schemes constructed
section indicated dashed lines

establish compilation schemes preserving plan size polynomially pairs formalisms
proved impossibility compilation schemes.
6.1 Compiling Conditional Effects Away Partial State Specifications
first compilation scheme develop one Qs Q . before, assume
conditional effects singleton effect sets. Further, since use arbitrary boolean
formulae effect conditions Qs , assume one rule effect literal.
Using simple polynomial transformation, arbitrary sets operators brought form.
$Dff post LB. considerably,
simplifies checking condition $Dff post LB.)
one rule activate particular literal.
302

fiC OMPILABILITY



E XPRESSIVE P OWER P LANNING F ORMALISMS

order simulate parallel behavior conditional effects, break
individual operators executed sequentially. means conditional effect
operator introduce two new operators. One simulates successful application rule,
one simulates blocking situation rule. least one operators must
executed conditional effect original operator. something force
additional literals added control execution operators. leads
sequence operators length bounded number conditional effects original
operator.
want simulate parallel behavior sequence unconditional operators, effects
unconditional operators directly influence state description, effect
deferred operators corresponding set conditional effects
executed. reason, use sequence copying operators copy activated
effects state description conditional operators executed. copying
operators also used check set activated effects consistent.
Theorem 20

Qs

compiled

Q

polynomial time preserving plan size polynomially.

Proof. Assume ) N$fftP %QB source domain structure assume further, without
loss generality (using polynomial transformation), operators form

L )~N pre L fft+{ VXF ffgAgAgA\ffe : VGF :fiz6>Pff
F
F
F
73 , 7 , 7) X
) .
V
Let 3 disjoint copies , used record active effects conditional
another disjoint copy, used record active effect
effects, let
l
copied yet. Further, let
J),+.-4*0zLW?6 new set atoms corresponding one-to-one
6
operators let set symbols corresponding one-to-one conditional effects
, i.e.,
6
V F 7 & post L>@ffiL{81?6BA
),+14 7 0 7 X
Finally, let fresh atom appearing <= </ 3 </
<= signals copying
l
active effects state specification progress. set symbols compiled
domain structure

)F<9 <5
3

<5
l

<9m<

6

</+\\6BA

operator L , compilation scheme introduces number new operators.
first operator introduce one checks whether conditional effects previous
operators executed, copying progress precondition satisfied.
case, execution conditional effects operator started:

L pre
)~N pre L{$H<5


6

<=+>8{6Bff(+.- b 6&<3(7?<5(43<5

<3(
l

PA

operator enables conditional effect operators. activated effects, introduce
following operators:

Lk 7 ~
) N +.-4b4
5 7Q6Bff*+1 7>6&</+.- ffl

303

0z-?) F 7>67<=+.- 3 ff l

0:4-) F 76>PA

fiN EBEL

words, effect condition entailed, activated positive negative effect well
fact rule tried recorded.
Since one effect literal conditional effect, conditional effect
blocked negation effect condition entailed state specification.
blocked conditional effects introduce following operators:

L 7 ~
) N +.- b
5( 7 6Bff(+1` 7 6>PA

order check conditional effects tried (activating corresponding effect
activating conditional effect blocked), following operator used:

L
) N +.-4bb6fi<=+1 7

6

0 7 VGF 7\

post L

e6Bff(+\{6&<=+>"-4bb6>PA

operator enables copying activated effects state specification, achieved
following set operators atom -3/ :


L

L
L



)
3


)

)

N +\>ff- ff4- 3 ff- l B6 fft+.-ff"- l >6 Pff
N +\>ff4-"ff-53(ff- l B6 fft+>4-ff4- l >6 Pff
N +\>ff- ff- 3 ff- l 6Bff
PA

Finally, need operator checks possible effects copied. operator
also starts execution cycle enabling execution another precondition operator:

Li ~
) N +\{67<3(
l

ff8+>*\6>PA

Using definitions, specify set compiled operators:

pre

)+\L ffiL 0L 1?6&< VHF
+\L 7 0L ?ff\ 7 VXF 7\fi post L e67<
+\L 7 0L 19ff\ 7
7\& post L e6&<
+\L ffiL 3 ffiL 0 -3W6fi<
+\LAit6BA
Based that, specify compilation scheme )ON>{ffe>zffe ff zff P follows:
>> ) N$ fft P
6
>b ) (7?<5(
3<9 l <3( <5 </+>8{6Bff
>s ) (m
<3+>*\6Bff
$ffi\ ) ff
zs$fft9) =A
scheme obviously satisfies conditions (2) (3)
compilation schemes
functions computed polynomial time. Further, Q -instance -instance.
Let legal %s state specification let ) $DffiL operator
clear D0) , exists sequence
L>X . discussion,
7 L 7 followed
pre
operators consisting L , followed operators form L


operator L , followed turn operators L , followed finally operator L ,
);!t]$D5<9 ffe ffF
304

fiC OMPILABILITY



E XPRESSIVE P OWER P LANNING F ORMALISMS

Conversely, D8%0 ) , exist plan transforms

$D5<9>bffiL pre

legal state specification contains 8 4-4b .
Using
induction plan length, follows arguments exists plan
iff exists plan every plan 00 @00v00 300
<= , <
maximum number conditional effects operators . Hence
polynomial-time compilation scheme preserving plan size polynomially.
immediate consequence theorem %s %Q form equivalence class
respect compilability preserving plan size polynomially.
Corollary 21
polynomially.

%Qs



%

polynomial-time compilable preserving plan size

Further, know Corollary 15 class cannot become larger.
case compiling , however, result depends semantics chosen


executing conditional effects partial state specifications. use alternative semantics resulting state specification legal application state-transformation
functions leads theory represented set literals, seems likely exists
another scheme preserves plan size polynomially. However, use alternative semantics


deletes literals ; $Dff post LB.(I$Dff post LB. $Dff post LB consistent,
appears unlikely able identify compilation scheme preserves plan
size polynomially.
6.2 Compiling Conditional Effects Away Complete State Specifications
next compilation scheme compiles %] % . Since deal complete state


$D8ff post LB. ,
specification, take care condition M$D8ff post LB.M)
always true complete states. makes compilation scheme somewhat simpler. Since
allow general boolean formulae, scheme becomes little bit difficult.
general, however, compilation scheme specify similar one given
proof Theorem 20.
Theorem 22 %] compiled
serving plan size polynomially.

%





compiled



polynomial time pre-

Proof. proof Theorem 20, assume ) N$fftP (%]
domain structure. Further, assume operators form

V F :b6>Pff
L )~N pre L fft+ U VXF ffgAgAgA\ff U : X
F
U %] structure U 7
7M 7




) source

structure. means
assume effects unique conditional effect.
addition, assume set symbols compiled domain structure proof
Theorem 20:

)F<9 <5

3

<5

305

l

<9m<

6

</+\\6BA

fiN EBEL



pre
operator L , introduce operators L , L , L
Theorem 20.
addition, following operators needed:


Lk 7 )
L 7e : )

,L


3

,L




N +.-4bb6&< U 7>ff*+1 7Q6fi<=+.- ff - l 0@-?) F 76&<=+.- 3 ff N +.-4bb6&</+>* 7e :0t 7e : U 76Bff*+1 7>6>PA

, L

l



proof

0:4-) F 76>Pff


compiled set operators contains operators compilation scheme

identical scheme presented proof Theorem 20. means significant
difference compilation scheme presented proof Theorem 20 operator scheme
L 7e : tests rule whether contains effect condition blocks rule. Since
complete state specifications, every conditional effect either activated blocked,
7 's used record execution conditional effect tried.
Using similar arguments proof Theorem 20, follows compilation
scheme indeed scheme leads claim made theorem.


follows equivalent respect formalisms


equivalent respect . two sets could merged one equivalence class,

provided able prove that, e.g., % compiled .



6.3 Compiling Boolean Formulae Away
Section 5.5 showed impossible compile boolean formulae conditional effects
plans allowed grow linearly. However, also sketched already idea compilation
scheme preserves plan size polynomially. show compile boolean
formulae , expressively equivalent basic STRIPS, i.e., compile boolean

formulae away completely.
Theorem 23

%

polynomial-time compilable



preserving plan size polynomially.

Proof. Assume F)ON$fftP domain structure. assume without loss generality
= (i.e.,
operators L 1 form L )ON ffi P ,
one formula precondition instead set formulae).
Let two new sets atoms corresponding one-to-one sub-formulae occurring preconditions operators . new atoms denoted [\ [>
sub-formula . Atoms form [{ used record truth-value sub-formula
computed atoms form [\ used store computed truth-value.
operator L )~N ffi P , target operator set following operator:

L )ON +\[Q.ffi[ B 6Bffi <5( PA
set operators generated way denoted .
Further, atom -3/ , introduce following two operators:

L
L



3

)

)

N +.-6Bff*+\[ ffi[ 6>Pff
N +>"-H6Bff*+\[ ff8[ 6>PA

set operators generated way denoted
306



.

fiC OMPILABILITY



E XPRESSIVE P OWER P LANNING F ORMALISMS

sub-formula occurring preconditions
operators introduced:

L

L )
L 3 )
sub-formulae J)



L
L
L 3

form )


p

following

N +\[ ffi[ ffi[\ ffi[\ B6 fft+\[ ffi[\6>Pff
N +\[ ff*[\ 6Bfft+\[ ff8\[ H6>Pff
N +\[ ff *[\ 6Bfft+\[ ff8\[ H6>PA
)

3



, following operators introduced:
) N +\[ ffi\[ 6Bfft+\[ ffi\[ 6>Pff
) N +\[ ffi\[ 6Bfft+\[ ffi\[ 6>Pff
) N +\[ ffi[ ff8\[ ff81[ 6Bfft+\[ ff*\[ H6>PA

Finally, J)^ , following operators:

L
L



3

)

)

N +\[ ff 8[ 6Bfft+\[ iff [\6>Pff
N +\[ iff [ 6Bfft+\[ ff8\[ 6>PA

set operators generated sub-formulae denoted
specify compilation scheme :

>)
)
>B)
$ffi\)
s$fft9)



.

$N <9m9<5 ff8 </ </U*Pff
ff
ff
ff
/A

construction obvious functions polynomial-time computable,

induced function reduction,

state-translation functions modular,
every plan source planning instance exists plan 00 @00
00 300 ,<^\ , < maximum number sub-formulae preconditions .
that, claim follows.
might question whether compiling boolean formulae away could done
efficiently. Using result boolean expressions evaluated circuits logarithmic
depth, indeed possible. However, satisfied result
compilation scheme preserving plan size polynomially all. result together Theorem 22 settles question compilation schemes preserving plan size polynomially pairs
formalisms.
Corollary 24 formalisms

preserving plan size polynomially.





307

%]

polynomial-time compilable

fiN EBEL

6.4 Parallel Execution Models Feasibility Compilation Schemes Preserving Plan
Size Polynomially
compilation schemes preserve plan size exactly linearly seem immediate use,
polynomial growth plan appears little practical interest. Considering practical
experience planning algorithms roughly characterized property many
steps plan without getting caught combinatorial explosion fact
number significantly smaller 100, polynomial growth seem make much sense.
take GRAPHPLAN (Blum & Furst, 1997) consideration againthe planning system
motivated investigation first placeit turns system allows parallel
execution actions. Although parallel execution might seem add power planning
system considerably, affect results all. sequential plan solve planning
instance steps, parallel plan also need least actions. Nevertheless, although size
plan (measured number operations) might same, number time steps may
considerably smallerwhich might allow efficient generation plan.
look compilation scheme compiles conditional effects away, seems case
large number generated actions could executed parallelin particular actions
simulate conditional effects.
However, semantics parallel execution GRAPHPLAN quite restrictive. one action
adds deletes atom second action adds deletes one action deletes atom
second action precondition, two actions cannot executed parallel
GRAPHPLAN . restriction, seems impossible compile conditional effects away
preserving number time steps plan. However, compilation scheme preserves
number time steps linearly seems possible. Instead compilation scheme,
approaches far either used exponential translation (Gazen & Knoblock, 1997) modified
GRAPHPLAN -algorithm order handle conditional effects (Anderson et al., 1998; Koehler et al.,
1997; Kambhampati et al., 1997). modifications involve changes semantics parallel
execution well changes search procedure. implementations compared
straightforward translation Gazen Knoblock (1997) used, would also interesting
compare compilation scheme based ideas spelled Theorem 22
base line.

7. Summary Discussion
Motivated recent approaches extend GRAPHPLAN algorithm (Blum & Furst, 1997)
deal expressive planning formalisms (Anderson et al., 1998; Gazen & Knoblock, 1997;
Kambhampati et al., 1997; Koehler et al., 1997), asked term expressive power could
mean context. One reasonable intuition seems term expressive power refers
concisely domain structures corresponding plans expressed. Based
intuition inspired recent approaches area knowledge compilation (Gogic et al., 1995;
Cadoli et al., 1996; Cadoli & Donini, 1997), introduced notion compilability order
measure relative expressiveness planning formalisms. basic idea compilation
scheme transform domain structure, i.e., symbol set operators,
initial state goal specification transformedmodulo small changes necessary
technical reasons. Further, distinguish compilation schemes according whether plan
target formalism size (up additive constant), size bounded linearly
308

fiC OMPILABILITY



E XPRESSIVE P OWER P LANNING F ORMALISMS

size plan source formalism, size bounded polynomially original planning
instance original plan.
Although compilability framework appears straightforward intuitive tool
measuring expressiveness planning formalisms, possible come alternative
measures. Backstrom (1995), instance, proposed use ESP-reductions, polynomial
many-one reductions planning problems preserve plan size exactly. However, requiring
transformation polynomial-time computable seems overly restrictive.
particular, want prove one formalism expressive another one, better
proven exists compilation scheme regardless much computational resources
compilation process may need. Furthermore, appear severe technical problems
using Backstrom's (1995) framework proving negative results. hand,
positive results reported Backstrom achievable compilation framework
transformations used fact compilation schemes. Taking together, appears
case compilation framework superior intuitive technical point view.
Another approach judging expressiveness planning formalisms proposed
Erol colleagues (1994, 1996). measure expressiveness planning formalisms according set plans planning instance have. approach contrasts hierarchical task
network planning nicely STRIPS-planning, help us making distinctions
formalisms -family.
compilability framework mainly theoretical tool measure concisely domain
structures plans expressed. However, also appears good measure
difficult planning becomes new language feature added. Polynomial-time compilation
schemes preserve plan size linearly indicate easy integrate feature
compiled away. One either use compilation scheme mimic compilation scheme
extending planning algorithm. polynomial-time compilation scheme leading
polynomial growth plan possible, indication adding new feature
requires probably significant extension planning algorithm. even compilation
scheme preserving plan size polynomially ruled out, probably serious
problem integrating new feature.
Using framework, analyzed large family planning formalisms ranging basic
STRIPS formalisms conditional effects, boolean formulae, incomplete state specifications. surprising result analysis able come complete
classification. pair formalisms, either able construct polynomial-time
compilation scheme required size bound resulting plans could prove compilation schemes impossibleeven computational resources compilation process
unbounded.
particular, showed formalisms considered paper:






incomplete state specifications literals preconditions compiled basic STRIPS
preserving plan size exactly,
incomplete state specifications literals preconditions effect conditions compiled away preserving plan size exactly, already conditional effects,
compilation schemes preserving plan size linearly except implied
specialization relationship described above.
309

fiN EBEL

allow polynomial growth plans target formalism, formalisms
containing incomplete state specifications boolean formulae compilable other. Incomplete state specifications together boolean formulae, however, seem add significantly
expressiveness planning formalism, since cannot compiled away even
allowing polynomial growth plan unbounded resources compilation process.
noted, however, results hold use semantics
conditional effects partial state specifications spelled Section 2.1. semantics,
may get slightly different results concerning compilability conditional effects partial
states.
One question one may ask happens consider formalisms boolean formulae
syntactically restricted. indicated various places paper, restricted formulae,
CNF DNF formulae, sometimes easily compiled away. However, also
cases impossible. example, shown CNF formulae cannot compiled
basic STRIPS preserving plan size linearly (Nebel, 1999), confirms Backstrom's (1995)
conjecture CNF-formulae preconditions add expressive power basic STRIPS.
Another question reasonable restrictions compilation scheme are. particular,
one may want know whether non-modular state-translation functions could lead powerful
compilation schemes. First all, requiring state-translation functions modular seems
quite weak considering fact compilation scheme concerned
domain structure initial state goal specification transformed
all. Secondly, considering fact state-translation functions depend operator
set, complicated functions seem useless. technical point view, need
modularity order prove conditional effects boolean formulae cannot compiled away
preserving plan size linearly. conditional effects, modularity similar condition seems
crucial. case boolean formulae, could weaken condition point
require state-translation functions computable circuits constant depthor
something similar. case, additional freedom one gets non-modular state-translation
functions seem help functions take operators
account. Nevertheless, seems interesting theoretical problem prove powerful
state-translation functions add power compilation schemes.
Although paper mainly theoretical, inspired recent approaches extend
GRAPHPLAN algorithm handle powerful planning formalisms containing conditional
effects. So, answers give open problems field planning algorithm
design? First all, Gazen Knoblock's (1997) approach compiling conditional effects away
optimal want allow plan growth constant factor. Secondly,
approaches (Anderson et al., 1998; Kambhampati et al., 1997; Koehler et al., 1997)
modify GRAPHPLAN algorithm using strategy similar polynomial-time compilation
scheme preserving plan size polynomially. reason, approaches compared
pure compilation approach using ideas compilation scheme developed
proof Theorem 22 base line. Thirdly, allowing unrestricted boolean formulae adds
level expressivity cannot compiled away linear growth plan
size. fact, approaches one Anderson colleagues (1998) simply expand
formulae DNF accepting exponential blow-up. Again, cannot better plan
size preserved linearly. Fourthly, want add partial state specifications top
general boolean formulae, would amount increase expressivity much larger
310

fiC OMPILABILITY



E XPRESSIVE P OWER P LANNING F ORMALISMS

adding conditional effects general formulae basic STRIPS, case way
compile away even allow polynomial plan growth.
Finally, one may wonder results apply planning approaches based translating (bounded) planning problems propositional logic SATPLAN (Kautz & Selman, 1996)
BLACKBOX (Kautz & Selman, 1998). Since entire analysis relative expressiveness
planning formalisms uses assumption compile one planning formalism another
planning formalism, results tell us anything size representations switch
another formalism. particular, seems possible find encoding (bounded) planning
problems conditional operators propositional logic concise encoding
unconditional operators. advice results give concise encoding
found first translating conditional actions unconditional actions using standard encoding unconditional actions (Kautz, McAllester, & Selman, 1996) generate boolean
formulae. However, addressing problem determining conciseness representation
context appears interesting relevant topic future research.

Acknowledgments
research reported paper started partly carried author enjoyed
visitor AI department University New South Wales. Many thanks go Norman
Foo, Maurice Pagnucco, Abhaya Nayak rest AI department discussions
cappuccinos. would also like thank Birgitt Jenner Jacobo Toran clarifications
concerning circuit complexity.

Appendix A: Symbol Index
Symbol

Explanation
cardinality set
size instance
symbol used conditional effects

syntactic specialization relation

compilability relation restriction

boolean constant denoting falsity, also denoting

illegal state specification

273 boolean constant denoting truth

295 advice function
Lff\Ll
275, 275
active effects operator state state specification
AC
298 complexity class

298 boolean circuit
298 family boolean circuits

coNP
272 complexity class
coNP/poly 295 non-uniform coNP
closing set literals w.r.t.
$&%;(Ll 284

277 plan, i.e., sequence operators
295 complexity class polynomial hierarchy


295 instance problem

0L0
V 00 L]00

Page
292
277
274
279
282
273

311

fiN EBEL





>\ffe ffe>
U


F ffeff


;ff b

E\GHLl
NC
"!@#%
NP
NP/poly

L




- ffi[ff0ff24ff
L\
ff
P
P/poly
PH

277
282
282
282
277
274
273
287
273
273
274
298
273
272
295
274
276
277
274
275

272
295
295
273
>Ll
PLANEX
279
post
274
pre
274

PSPACE
272

277
295

276
Lff\Ll
;!t]Lff\Ll 277
C
274

274

278
278

%
278
278
`

278
;
278
283



283

'(
273

273

initial state description
compilation scheme ( )~N>{ffe ffe>Qff ffz>P )
transformation induced compilation scheme
components compilation scheme
goal planning task
set boolean formulae
boolean formulae
literal
sets literals
boolean formulae use atoms
set models theory
complexity class
negative literals set literals
complexity class
non-uniform NP
operator ( )~N pre ff post P )
set operators
set finite sequences operators
propositional atoms
potentially active effects operator
given state specification
complexity class
non-uniform P
polynomial hierarchy
positive literals set literals
plan existence problem
postconditions operator
preconditions operator
complexity class
planning instance ( )ON&ffifft9P )
complexity class polynomial hierarchy
maps state specification operator new state
extension Lff\Ll plans
state (or truth assignment)
state specification
STRIPS planning formalism
STRIPS literals preconditions
STRIPS boolean formulae preconditions
STRIPS incomplete state descriptions
STRIPS conditional effects
STRIPS combinations extensions
equivalence classes induced
equivalence classes induced
propositional atoms used set literals
countably infinite set propositional atoms
312

fiC OMPILABILITY







r


ffz



X

,




273
273
295
282
292
298
295
272
277
299



E XPRESSIVE P OWER P LANNING F ORMALISMS

finite subset
set literals overs
complexity class polynomial hierarchy
state-translation functions compilation scheme
universal literals
word +\ff:>6t
complexity class
planning formalisms
domain structure ( )ON$fftP )
family domain structures

References
Anderson, C. R., Smith, D. E., & Weld, D. S. (1998). Conditional effects Graphplan. Proceedings 4th International Conference Artificial Intelligence Planning Systems (AIPS98), pp. 4453. AAAI Press, Menlo Park.
Baader, F. (1990). formal definition expressive power knowledge representation languages.
Proceedings 9th European Conference Artificial Intelligence (ECAI-90) Stockholm, Sweden. Pitman.
Backstrom, C. (1995). Expressive equivalence planning formalisms. Artificial Intelligence, 76(1
2), 1734.
Backstrom, C., & Nebel, B. (1995). Complexity results SAS planning. Computational Intelligence, 11(4), 625655.
Blum, A. L., & Furst, M. L. (1997). Fast planning planning graph analysis. Artificial
Intelligence, 90(1-2), 279298.
Brewka, G., & Hertzberg, J. (1993). things worlds: formalizing actions
plans.. Journal Logic Computation, 3(5), 517532.
Bylander, T. (1994). computational complexity propositional STRIPS planning. Artificial
Intelligence, 69(12), 165204.
Cadoli, M., & Donini, F. M. (1997). survey knowledge compilation. AI Communications,
10(3,4), 137150.
Cadoli, M., Donini, F. M., Liberatore, P., & Schaerf, M. (1996). Comparing space efficiency
propositional knowledge representation formalism. Aiello, L. C., Doyle, J., & Shapiro,
S. (Eds.), Principles Knowledge Representation Reasoning: Proceedings 5th
International Conference (KR-96), pp. 364373 Cambridge, MA. Morgan Kaufmann.
Erol, K., Hendler, J. A., & Nau, D. S. (1994). HTN planning: Complexity expressivity.
Proceedings 12th National Conference American Association Artificial Intelligence (AAAI-94), pp. 11231129 Seattle, WA. MIT Press.
313

fiN EBEL

Erol, K., Hendler, J. A., & Nau, D. S. (1996). Complexity results hierarchical task-network
planning. Annals Mathematics Artificial Intelligence, 18, 6993.
Fikes, R. E., & Nilsson, N. (1971). STRIPS: new approach application theorem proving
problem solving. Artificial Intelligence, 2, 189208.
Furst, M., Saxe, J. B., & Sipser, M. (1984). Parity, circuits, polynomial-time hierarchy.
Mathematical Systems Theory, 17(1), 1327.
Garey, M. R., & Johnson, D. S. (1979). Computers IntractabilityA Guide Theory
NP-Completeness. Freeman, San Francisco, CA.
Gazen, B. C., & Knoblock, C. (1997). Combining expressiveness UCPOP efficiency
Graphplan. Steel, S., & Alami, R. (Eds.), Recent Advances AI Planning. 4th European
Conference Planning (ECP'97), Vol. 1348 Lecture Notes Artificial Intelligence, pp.
221233 Toulouse, France. Springer-Verlag.
Gogic, G., Kautz, H. A., Papadimitriou, C. H., & Selman, B. (1995). comparative linguistics
knowledge representation. Proceedings 14th International Joint Conference
Artificial Intelligence (IJCAI-95), pp. 862869 Montreal, Canada. Morgan Kaufmann.
Kambhampati, S., Parker, E., & Lambrecht, E. (1997). Understanding extending Graphplan.
Steel, S., & Alami, R. (Eds.), Recent Advances AI Planning. 4th European Conference
Planning (ECP'97), Vol. 1348 Lecture Notes Artificial Intelligence, pp. 260272
Toulouse, France. Springer-Verlag.
Karp, R. M., & Lipton, R. J. (1982).
Mathematique, 28, 191210.

Turing machines take advice.

L' Ensignement

Kautz, H. A., McAllester, D. A., & Selman, B. (1996). Encoding plans propositional logic.
Aiello, L. C., Doyle, J., & Shapiro, S. (Eds.), Principles Knowledge Representation
Reasoning: Proceedings 5th International Conference (KR-96), pp. 374385 Cambridge, MA. Morgan Kaufmann.
Kautz, H. A., & Selman, B. (1992). Forming concepts fast inference.. Proceedings
10th National Conference American Association Artificial Intelligence (AAAI-92),
pp. 786793 San Jose, CA. MIT Press.
Kautz, H. A., & Selman, B. (1996). Pushing envelope: Planning, propositional logic,
stochastic search. Proceedings 13th National Conference American Association Artificial Intelligence (AAAI-96), pp. 11941201. MIT Press.
Kautz, H. A., & Selman, B. (1998). BLACKBOX: new approach application theorem
proving problem solving. Working notes AIPS'98 Workshop Planning
Combinatorial Search Pittsburgh, PA.
Koehler, J., Nebel, B., Hoffmann, J., & Dimopoulos, Y. (1997). Extending planning graphs
ADL subset. Steel, S., & Alami, R. (Eds.), Recent Advances AI Planning. 4th European
Conference Planning (ECP'97), Vol. 1348 Lecture Notes Artificial Intelligence, pp.
273285 Toulouse, France. Springer-Verlag.
314

fiC OMPILABILITY



E XPRESSIVE P OWER P LANNING F ORMALISMS

Lifschitz, V. (1986). semantics STRIPS. Georgeff, M. P., & Lansky, A. (Eds.), Reasoning Actions Plans: Proceedings 1986 Workshop, pp. 19 Timberline, OR.
Morgan Kaufmann.
Nebel, B. (1999). expressive power disjunctive preconditions?. Biundo, S., & Fox,
M. (Eds.), Recent Advances AI Planning. 5th European Conference Planning (ECP'99)
Durham, UK. Springer-Verlag. appear.
Papadimitriou, C. H. (1994). Computational Complexity. Addison-Wesley, Reading, MA.
Pednault, E. P. (1989). ADL: Exploring middle ground STRIPS situation
calculus. Brachman, R., Levesque, H. J., & Reiter, R. (Eds.), Principles Knowledge
Representation Reasoning: Proceedings 1st International Conference (KR-89),
pp. 324331 Toronto, ON. Morgan Kaufmann.
Yap, C. K. (1983). consequences non-uniform conditions uniform classes. Theoretical
Computer Science, 26, 287300.

315

fiJournal Artificial Intelligence Research 12 (2000) 199-217

Submitted 12/1999; published 5/2000

Complexity Reasoning Cardinality Restrictions
Nominals Expressive Description Logics
Stephan Tobies

tobies@informatik.rwth-aachen.de

LuFG Theoretical Computer Science, RWTH Aachen
Ahornstr. 55, 52074 Aachen, Germany

Abstract

study complexity combination Description Logics ALCQ ALCQI
terminological formalism based cardinality restrictions concepts. combinations naturally embedded C 2 , two variable fragment predicate logic
counting quantifiers, yields decidability NExpTime. show approach leads optimal solution ALCQI , ALCQI cardinality restrictions
complexity C 2 (NExpTime-complete). contrast, show ALCQ,
problem solved ExpTime. result obtained reduction reasoning cardinality restrictions reasoning (in general weaker) terminological
formalism general axioms ALCQ extended nominals . Using reduction,
show that, extension ALCQI nominals, reasoning general axioms
NExpTime-complete problem. Finally, sharpen result show pure
concept satisfiability ALCQI nominals NExpTime-complete. Without nominals,
problem known PSpace-complete.
1. Introduction

Description Logics (DLs) used knowledge based systems represent reason taxonomical knowledge application domain semantically well-defined
manner (Woods & Schmolze, 1992). allow definition complex concepts (i.e.,
classes, unary predicates) roles (binary predicates) built atomic ones
application given set constructors. example, following concept describes
parents least two daughters:
Human u (Male Female) u (> 2 hasChild Female) u 8hasChild:Human
concept example DL ALCQ. ALCQ extends \standard" DL ALC
(Schmidt-Schau & Smolka, 1991) qualifying number restrictions, i.e., concepts restricting number individuals related via given role (here hasChild), instead
allowing existential universal restrictions like ALC. ALCQ syntactic variant
(multi-)modal logic K graded modalities (Fine, 1972). paper study
problems DLs ALCQ ALCQI . latter extends ALCQ possibility
refer inverse role relations. Additionally, paper encounter nominals,
i.e., concepts referring single elements domain. extensions ALCQ ALCQI
nominals denoted ALCQO ALCQIO. example concept ALCQIO
describes common children individuals ALICE BOB living ALICE BOB

9hasChild 1 :ALICE u 9hasChild 1:BOB u 9livesWith:(ALICE BOB):
c 2000 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiTobies

Concept Satisfiability
GCIs
Cardinality Restr.

ALCQ

-c.
-c.
ExpTime-c.
PSpace

ExpTime

ALCQO

open

-c.
ExpTime-c.
ExpTime

ALCQI

-c.
-c.
NExpTime-c.
PSpace

ExpTime

ALCQIO

NExpTime-c.
NExpTime-c.
NExpTime-c.

Figure 1: Complexity results established paper (shown bold face)
Here, parent relationship expressed inverse hasChild relationship.
terminological component (TBox) allows organisation defined concepts
roles forms knowledge base DL system. TBoxes studied DLs range weak
ones allowing acyclic introduction abbreviations complex concepts,
TBoxes capable expressing various forms general axioms, cardinality restrictions
express restrictions number elements extension concept may
have. following, give examples three types assertions.
following TBox introduces parent abbreviation human least
one child whose children human, toddler young human, busy parent
parent least two children toddlers.
Parent = Human u (> 1 hasChild) u 8hasChild:Human
Toddler = Human u VeryYoung
BusyParent = Parent u (> 2 hasChild Toddler)
next expressions general axioms stating males females disjoint (?
denotes empty concept) males females coincide humans
exactly two human parents.
Female u Male = ?
Female Male = Human u (= 2 hasChild 1 Human)
Finally, following expression cardinality restriction expressing
two earliest ancestors:
( 2 (Human u (6 0 hasChild 1 Human)))
Cardinality restriction first introduced Baader et al. (1996) terminological
formalism DL ALCQ; see, express general axioms hence
expressive terminological formalisms considered paper.
key component DL system reasoning component provides services like
subsumption consistency tests knowledge stored TBox. subsumption
test, example, could infer previous definitions Male Female
subsumed Human BusyParent subsumed Parent busy parent must
least one child. exist sound complete algorithms reasoning large
number DLs different TBox formalisms optimal respect known
worst-case complexity problems (see Donini et al., 1996, overview).
200

fiThe Complexity Cardinality Restrictions Nominals

paper establish number new complexity results DLs cardinality
restrictions nominals. Figure 1 summarises new complexity bounds established
paper. problems complete respective complexity class. paper
organised follows.
giving basic definitions Section 2, show consistency TBoxes
cardinality restrictions ALCQI NExpTime-complete problem (Section 3). Membership NExpTime shown translation satisfiability problem C 2 (Pacholski et al., 1997)1 , two variable fragment first order predicate logic augmented
counting quantifiers. matching lower bound established reduction
NExpTime-complete bounded domino problem.
Section 4, show reasoning cardinality restrictions reduced
reasoning (weaker) formalism general axioms presence nominals.
yields interesting complexity results reasoning cardinality restrictions
nominals. Using result (De Giacomo, 1995), reduction shows consistency TBoxes cardinality restrictions ALCQ ExpTime. improves
result (Baader et al., 1996), shown problem solved
NExpTime. Moreover, show DL number restrictions, inverse roles,
nominals reasoning problems become NExpTime-hard, solves open problem
(De Giacomo, 1995). combination particular interest application DLs
area reasoning database schemata (Calvanese et al., 1998a, 1998b).
2. Logic

ALCQI

Definition 2.1 Let NC set atomic concept names NR set atomic role
names. Concepts ALCQI built inductively using following rules:
2 NC concepts, and, C , C1 , C2 concepts, also

:C; C1 u C2;



(> n C );

concepts, n 2 N = R = R 1 R 2 NR .
cardinality restriction ALCQI expression form (> n C ) (6 n C )
C concept n 2 N ; ALCQI -TCBox 2 finite set cardinality restrictions.
semantics concepts defined relative interpretation = (I ; ),
consists domain valuation (I ) maps concept name subset
AI role name R subset RI . valuation inductively
extended arbitrary concepts using following rules, ]M denotes cardinality
set :
(:C )I := n C ;
(C1 u C2 )I := C1I \ C2I ;
(> n R C )I := fa 2 j ]fb 2 j (a; b) 2 RI ^ b 2 C g ng;
(> n R 1 C )I := fa 2 j ]fb 2 j (b; a) 2 RI ^ b 2 C g ng:
1. NExpTime-result valid assume unary coding numbers counting quantifiers.
standard assumption made results concerning complexity DLs.
2. subscripted \C" indicates TBox consists cardinality restrictions

201

fiTobies

x(A)
:= Ax
2 NC
x(:C )
:= : x(C )
x(C1 u C2) := x(C1 ) ^ x(C2 )
x(> n R C ) := 9ny:(Rxy ^ (C ))
x(> n R 1 C ) := 9ny:(Ryx ^ (C ))
(C )
:= x(C )[xny; ynx]
(./ n C )
:= 9./nx: x(C ) ./ 2 f>; 6g
(T )
:= Vf (./ n C ) j (./ n C ) 2 g
Figure 2: translation ALCQI C 2
interpretation satisfies cardinality restriction (> n C ) iff ](C ) n, satisfies (6 n C ) iff ](C ) n. satisfies TCBox iff satisfies cardinality restrictions
; case, called model denote fact j= . TCBox
model called consistent.
ALCQ denote fragment ALCQI contain inverse roles
R 1.

Using constructors Definition 2.1, use (8 C ) abbreviation
cardinality restriction (6 0 :C ) introduce following abbreviations concepts:
C1 C2 = :(:C1 u :C2 )
(6 n C ) = :(> (n + 1) C )
C1 ! C2 = :C1 C2
(= n C ) = (6 n C ) u (> n C )
9S:C = (> 1 C )
> = :A 2 NC
8S:C = (6 0 :C )
TBoxes consisting cardinality restrictions first studied (Baader et al.,
1996) DL ALCQ. Obviously, two concepts C; extension interpretation iff satisfies cardinality restriction (6 0 (C u :D) (:C u D)). Hence,
cardinality restrictions express terminological axioms form C = D,
satisfied interpretation iff C = DI . General axioms expressive TBox
formalisms usually studied DL context (De Giacomo & Lenzerini, 1996). One standard inference service DL systems satisfiability concept C respect TCBox
, i.e., interpretation j= C 6= ;. TBox formalism
based cardinality restrictions easily reduced TBox consistency, obviously C satisfiable respect iff [ f(> 1 C )g consistent TCBox.
reason, restrict attention TCBox consistency; standard inferences
concept subsumption reduced consistency well.
exist direct decision procedure ALCQI TCBox consistency.
Nevertheless problem decided help well-known translation
ALCQI -TCBoxes C 2 (Borgida, 1996), given Figure 2. logic C 2 fragment
predicate logic formulae may contain two variables, enriched
counting quantifiers form 9`. translation yields satisfiable sentence
C 2 translated TCBox consistent. Since translation ALCQI C 2
202

fiThe Complexity Cardinality Restrictions Nominals

performed linear time, NExpTime upper bound (Gradel et al., 1997; Pacholski
et al., 1997) satisfiability C 2 directly carries ALCQI -TCBox consistency:
Lemma 2.2 Consistency ALCQI -TCBox decided NExpTime.
Please note NExpTime-completeness result (Pacholski et al., 1997)
valid assume unary coding numbers input; implies number n may
stored logarithmic space k-ary representation consumes n units
storage. standard assumption made results concerning complexity
DLs. come back issue Section 3.3.
3. Consistency

ALCQI -TCBoxes NExpTime-complete

show NExpTime also lower bound complexity TCBox consistency,
use bounded version domino problem. Domino problems (Wang, 1963; Berger,
1966) successfully employed establish undecidability complexity results
various description modal logics (Spaan, 1993; Baader & Sattler, 1999).
3.1 Domino Systems
Definition 3.1 n 2 N , let Zn denote set f0; : : : ; n 1g n denote addition
modulo n. domino system triple = (D; H; V ), finite set (of tiles)
H; V relations expressing horizontal vertical compatibility constraints
tiles. s; 2 N , let U (s; t) torus Zs Zt, let w = w0 : : : wn 1
word length n (with n s). say tiles U (s; t) initial condition
w iff exists mapping : U (s; t) ! that, (x; ) 2 U (s; t),

(x; y) = (x 1; y) = d0, (d; d0 ) 2 H (horizontal constraint);
(x; y) = (x; 1) = d0 , (d; d0 ) 2 V (vertical constraint);
(i; 0) = wi 0 < n (initial condition).

Bounded domino systems capable expressing computational behaviour
restricted, so-called simple, Turing Machines (TM). restriction non-essential
following sense: Every language accepted time (n) space (n) one-tape TM
accepted within time space bounds simple TM, long (n); (n)
2n (Borger et al., 1997).
Theorem 3.2 ((Borger et al., 1997), Theorem 6.1.2)

Let simple TM input alphabet . exists domino system =
(D; H; V ) linear time reduction takes input x 2 word w 2
jxj = jwj
accepts x time t0 space s0, tiles U (s; t) initial condition w
s0 + 2; t0 + 2;
accept x, tile U (s; t) initial condition w
s; 2.
203

fiTobies

Corollary 3.3

domino system following NExpTime-hard problem:
Given initial condition w = w0 : : : wn 1 length n. tile torus
U (2n+1 ; 2n+1 ) initial condition w?
Proof. Let (w.l.o.g. simple) non-deterministic TM time- (and hence space-)
bound 2n deciding arbitrary NExpTime-complete language L(M ) alphabet .
Let according domino system trans reduction Theorem 3.2.
function trans linear reduction L(M ) problem above: v 2
jvj = n, holds v 2 L(M ) iff accepts v time space 2jvj iff tiles
U (2n+1 ; 2n+1 ) initial condition trans(v ).
3.2 Defining Torus Exponential Size

Similar proving undecidability reduction unbounded domino problems, defining infinite grids key problem, defining torus exponential size key
obtaining NExpTime-completeness proof reduction bounded domino problems.
able apply Corollary 3.3 TCBox consistency ALCQI , must characterise
torus Z2 Z2 TCBox polynomial size. characterise torus, use
2n concepts X0 ; : : : ; Xn 1 Y0 ; : : : ; Yn 1 , Xi (resp., Yi) codes ith bit
binary representation X-coordinate (resp., Y-coordinate) element a.
interpretation element 2 , define pos(a)
n

n

pos(a) := (xpos(a); ypos(a)) :=
(

nX1

xi

1

n
X

2 ;


=0 (



=0

yi



2





;



62 XiI
0; 62 YiI
= 01;; ifotherwise
yi =
1; otherwise :
use well-known characterisation binary addition (e.g. (Borger et al., 1997))
relate positions elements torus:
Lemma 3.4 Let x; x0 natural numbers binary representations
xi

x

=


x0 x + 1

1

n
X

=0



1

xi

2i
1

n^ k^

(mod 2 ) iff
n

k

^

(

=0 j =0
1 1

n^ k_
k

(

=0 j =0

x0

=

1

n
X

=0



x0i

2i :

xj

= 1) ! (xk = 1 $ x0k = 0)

xj

= 0) ! (xk = x0k ) ;

empty conjunction disjunction interpreted true false, respectively.
204

fiThe Complexity Cardinality Restrictions Nominals

Deast

=

Xk

u

n

n

(

=0 j =0
1 kG1

k
n

Xj

1

=0
1

k

=0
k=0
1k 1

k
n

(8 9north:>);
(8 (= 1 north 1 >));
(> 1 C(2 1;2 1) );
(8 Deast u Dnorth )
n

n

:Xk u

G G

=

n

n

=0
1

k
n

G

1;2 1)

1

G

C(2n

=

n

G

C(0;0)

= (8 9east:>);
(8 (= 1 east 1 >));
(> 1 C(0;0) );
(6 1 C(2 1;2 1) );
G

Tn

n

:Yk

Yk

) ! ((Xk ! 8east::Xk ) u (:Xk ! 8east:Xk )) u

( :Xj ) ! ((Xk ! 8east:Xk ) u (:Xk ! 8east::Xk )) u

=0 j =0
1

G

k
n

=

=0

G

Dnorth

k

((Yk ! 8east:Yk ) u (:Yk ! 8east::Yk ))

:::

Figure 3: TCBox defining torus exponential size
TCBox Tn defined Figure 3. concept C(0;0) satisfied elements
domain pos(a) = (0; 0) holds. C(2 1;2 1) similar concept, whose
instances satisfy pos(a) = (2n 1; 2n 1).
concept Dnorth similar Deast role north substituted east
variables Xi Yi swapped. concept Deast (resp. Dnorth ) enforces that,
along role east (resp. north), value xpos (resp. ypos) increases one
value ypos (resp. xpos) unchanged. analogous formula Lemma 3.4.
following lemma consequence definition pos Lemma 3.4.
Lemma 3.5 Let = (I ; ) interpretation, Deast ; Dnorth defined Figure 3,
a; b 2 .
n

implies:
(a; b) 2 eastI 2 Deast
implies:
(a; b) 2 northI 2 Dnorth

n

xpos(b) xpos(a) + 1
ypos(b) = ypos(a)
xpos(b) = xpos(a)
ypos(b) ypos(a) + 1

(mod 2n)

(mod 2n)
TCBox Tn defines torus exponential size following sense:
Lemma 3.6 Let Tn TCBox defined Figure 3. Let = (I ; ) model
Tn .
(I ; eastI ; northI ) = (U (2n ; 2n ); S1 ; S2 ) ;
205

fiTobies

U (2n; 2n ) torus Z2 Z2 S1; S2 horizontal vertical successor
relations torus.
Proof. show function pos isomorphism U (2n ; 2n ). Injectivity
pos shown induction \Manhattan distance" d(a) pos-value element
pos-value upper right corner.
element 2 define d(a)
d(a) = (2n 1 xpos(a)) + (2n 1 ypos(a)):
Note pos(a) = pos(b) implies d(a) = d(b). Since j= (6 1 C(2 1;2 1) ),
one element 2 d(a) = 0. Hence, exactly one element
pos(a) = (2n 1; 2n 1). assume elements a; b 2
pos(a) = pos(b) d(a) = d(b) > 0. either xpos(a) < 2n 1 ypos(a) < 2n 1.
W.l.o.g., assume xpos(a) < 2n 1. j= Tn, follows a; b 2 (9east:>)I . Let
a1 ; b1 elements (a; a1 ) 2 eastI (b; b1 ) 2 eastI . Since d(a1 ) = d(b1 ) < d(a)
pos(a1 ) = pos(b1), induction hypothesis yields a1 = b1 . Lemma 3.5 follows

xpos(a1 ) xpos(b1 ) xpos(a) + 1 (mod 2n )
ypos(a1 ) = ypos(b1 ) = ypos(a)
also implies = b a1 2 (= 1 east 1:>)I f(a; a1 ); (b; a1 )g eastI . Hence
pos injective.
prove pos also surjective use similar technique. time, use
induction distance lower left corner. element (x; y) 2 U (2n ; 2n),
define:
d0 (x; ) = x + y:
show induction that, (x; y) 2 U (2n ; 2n ), element 2
pos(a) = (x; y). d0 (x; y) = 0, x = = 0. Since j= (> 1 C(0;0) ),
element 2 pos(a) = (0; 0). consider (x; y) 2 U (2n ; 2n )
d0 (x; ) > 0. Without loss generality assume x > 0 (if x = 0 > 0 must hold).
Hence (x 1; y) 2 U (2n ; 2n ) d0 (x 1; y) < d0 (x; y). induction hypothesis,
follows element 2 pos(a) = (x 1; y). must
element a1 (a; a1 ) 2 eastI Lemma 3.5 implies pos(a1 ) = (x; y). Hence
pos also surjective.
Finally, pos indeed homomorphism immediate consequence Lemma 3.5.
n

n

n

n

interesting note need inverse roles guarantee pos injective. achieved adding cardinality restriction (6 (2n 2n) >)
Tn , injectivity pos follows surjectivity simple cardinality
considerations. course size cardinality restriction would polynomial
n assume binary coding numbers. Also note made explicit use
special expressive power cardinality restrictions stating that, model Tn,
extension C(2 1;2 1) must one element. cannot expressed
ALCQI -TBox consisting terminological axioms.
n

n

206

fiThe Complexity Cardinality Restrictions Nominals

3.3 Reducing Domino Problems TCBox Consistency

Lemma 3.6 proved, easy reduce bounded domino problem
TCBox consistency. use standard reduction applied DL context,
e.g., (Baader & Sattler, 1999).
Lemma 3.7 Let = (D; V; H ) domino system. Let w = w0 : : : wn 1 2 .
TCBox (n; D; w) that:
(n; D; w) consistent iff tiles U (2n; 2n ) initial condition w.
(n; D; w) computed time polynomial n.
Proof. define (n; D; w) := Tn [ TD [ Tw , Tn defined Figure 3, TD captures
vertical horizontal compatibility constraints domino system D, Tw enforces initial condition. use atomic concept Cd tile 2 D. TD consists
following cardinality restrictions:
G
:(Cd u Cd0 ));
(8 Cd ); (8
d2D d0 2Dnfdg

Cd0

))); (8

G

(d;d0 )2H

G

G

d2D

(Cd ! (8east:

G

G

(8

d2D

d2D

G

(Cd ! (8north:

(d;d0 )2V

Cd0

))):

Tw consists cardinality restrictions
(8 (C(0;0) ! Cw0 )); : : : ; (8 (C(n 1;0) ! Cw 1 );
n

where, x; y, C(x;y) concept satisfied element iff pos(a) = (x; y),
defined similarly C(0;0) C(2 1;2 1) .
definition (n; D; w) Lemma 3.6, follows model (n; D; w)
immediately induces tiling U (2n ; 2n ) vice versa. Also, fixed domino system
D, (n; D; w) obviously polynomially computable.
main result section immediate consequence Lemma 2.2, Lemma 3.7, Corollary 3.3:
n

n

Theorem 3.8

Consistency ALCQI -TCBoxes NExpTime-complete, even unary coding numbers
used input.
Recalling note proof Lemma 3.6, see argument also
applies ALCQ allow binary coding numbers.
Corollary 3.9

Consistency ALCQ-TCBoxes NExpTime-hard, binary coding used represent
numbers cardinality restrictions.
noted open problem decided NExpTime, binary
coding numbers used, since reduction C 2 yields decidability 2-NExpTime.
207

fiTobies

following section, see that, unary coding numbers, deciding consistency ALCQ-TCBoxes done ExpTime (Corollary 4.8). shows
coding numbers indeed uence complexity reasoning problem.
worth noting complexity pure concept satisfiability ALCQ depend coding; problem PSpace-complete binary unary coding
numbers (Tobies, 2000).
unary coding, needed inverse roles cardinality restrictions
reduction. consistent fact satisfiability ALCQI concepts respect
TBoxes consisting terminological axioms still ExpTime, shown
reduction ExpTime-complete logics CIN (De Giacomo, 1995) CPDL (Pratt,
1979). shows cardinality restrictions concepts additional source
complexity. One reason might ALCQI cardinality restrictions longer
tree-model property.
4. Reasoning Nominals

Nominals, i.e., atomic concepts referring single individualsof domain, studied
area DLs (Borgida & Patel-Schneider, 1994; Donini et al., 1996) modal logics
(Gargov & Goranko, 1993; Blackburn & Seligman, 1996; Areces et al., 1999). section
show how, presence nominals, consistency TCBoxes polynomially
reduced consistency TBoxes consisting general inclusion axioms, which, general,
easier problem. correspondence used obtain two novel results: (i) show
that, unary coding, consistency ALCQ-TBoxes consisting cardinality restrictions
decided ExpTime; (ii) show that, presence inverse roles
number restrictions, reasoning nominals strictly harder without nominals:
complexity determining consistency TBoxes general axioms rises ExpTime
NExpTime, complexity concept satisfiability rises PSpace NExpTime.
Definition 4.1 Let NI set individual names (also called nominals) disjoint
NC NR . Concepts ALCQIO defined ALCQI -concepts additional rule
that, every 2 NI , ALCQIO-concept.
general concept inclusion axiom ALCQIO expression C v D,
C ALCQIO-concepts. TIBox ALCQIO finite set general
inclusion axioms ALCQIO, subscript \I" stands \Inclusion".
semantics ALCQIO concepts defined similar ALCQI , additional
requirement every interpretation maps nominal 2 NI singleton set oI ;
seen name element oI . Please note unique
name assumption, i.e., assume o1 6= o2 implies oI1 6= oI2 .
interpretation satisfies axiom C v iff C DI . satisfies TIBox Tgci iff
satisfies axioms Tgci ; case called model Tgci, denote
fact j= Tgci . TIBox model called consistent.
Cardinality restrictions, TCBoxes, interpretation ALCQIO defined analogously ALCQI .
208

fiThe Complexity Cardinality Restrictions Nominals

R

ALCQO denote fragment ALCQIO contain inverse roles

1.

Consistency TCBoxes TIBoxes ALCQO ALCQIO Exp-hard decided NExpTime, unary coding numbers used.
Proof. Consistency TIBoxes (and hence TCBoxes) ExpTime-hard already (a
syntactical variant of) ALC (Halpern & Moses, 1992). Assuming unary coding numbers,
reduce problems satisfiability C 2, yields NExpTime upper
bound.
Lemma 4.2
Time

4.1 Expressing Cardinality Restrictions Using Nominals

following show how, assumption unary coding numbers, consistency
ALCQI -TCBoxes polynomially reduced consistency ALCQIO-TIBoxes.
noted that, conversely, also possible polynomially reduce consistency
ALCQIO-TIBoxes consistency ALCQI -TCBoxes: arbitrary concept C ,
cardinality restrictions f(6 1 C ); (> 1 C )g force interpretation C singleton.
Since gain insight reduction, formally prove
result.
Definition 4.3 Let = f(./1 n1 C1 ); : : : (./k nk Ck )g ALCQI -TCBox. W.l.o.g.,
assume contains cardinality restriction form (> 0 C ) trivially
satisfied interpretation. translation , denoted (T ), ALCQIO-TIBox
defined follows:

[

(T ) = f(./i ni Ci) j 1 kg;
(./i ni Ci ) defined depending whether ./i =6 ./i =>.
(

n
1
(./i ni Ci ) = ffoCji vv Coi tj 1 tj oi ng g [ foj v :o` j 1 j < ` n g











=6 ;
./i =>
./i

o1i ; : : : ; oni fresh distinct nominals use convention empty
disjunction interpreted :> deal case ni = 0.


Assuming unary coding numbers, translation TCBox obviously computable polynomial time.
Lemma 4.4 Let ALCQI -TCBox. consistent iff (T ) consistent.
Proof. Let = f(./1 n1 C1 ); : : : (./k nk Ck )g consistent TCBox. Hence,
model , j= (./i ni Ci ) 1 k. show construct model
0 (T ) fromj . 0 identical every respect except interpretation
nominals oi (which appear ).
./i =6, j= implies ]CiI ni. ni = 0, have0 introduced
new nominals, (T ) contains Ci v :>. Otherwise, define (oji )I CiI
209

fiTobies

f(oji )I 0 j 1 j nig. implies CiI 0 (o1i )I 0 [ [ (oni )I 0 hence, either case,
0 j= (6 ni Ci).
./i =>, ni > 0 must hold, j= implies ]CiI 0ni. Let x1; : : : xn ni
distinct elements fx1 ; : : : ; xn g CiI . set (oji )I = fxj g. Since
chosen distinct individuals interpret different nominals, 0 j= oji v :o`i every
1 < ` ni. Moreover, xj 2 CiI implies 0 j= oji v Ci hence 0 j= (> ni Ci).






chosen distinct nominals every cardinality restrictions, hence previous
construction well-defined and, since 0 satisfies (./i ni Ci ) every i, 0 j= (T ).
converse direction, let models (T ). fact j= (and hence
consistency ) shown follows: let (./i ni Ci) arbitrary cardinality
restriction . ./i =6 ni = 0, (6 0 Ci) = fCi v :>g and,
since j= (T ),nwe CiI = ; hence j= (6 0 Ci). ./i =6
ni > 0,
n
1

1
fCi v oi oi g (T ). j= (T ) follows ]Ci ](oi oi ) ni. ./i =>,
foji v Ci j 1 j nig[foji v :o`i j 1 j < ` nig (T ). first set
axioms get f(oji )I j 1 j nig CiI . secondSset axioms get that,
every 1 j < ` ni, (oji )I 6= (o`i )I . implies ni = ] f(oji )I j 1 j nig ]CiI .




Theorem 4.5

Assuming unary coding numbers, consistency ALCQI -TCBoxes polynomially
reduced consistency ALCQIO-TIBoxes. Similarly, consistency ALCQ-TCBoxes
polynomially reduced consistency ALCQO-TIBoxes.
Proof. first proposition follows fact (T ) polynomially computable
assume unary coding numbers Lemma 4.4. second proposition
follows fact translation introduce additional inverse roles.
contain inverse roles, neither (T ), hence result translating
ALCQ-TCBox ALCQO-TIBox.
4.2 Complexity Results

use Theorem 4.5 obtain new complexity results DLs cardinality
restrictions nominals.
4.2.1

ALCQ ALCQO

De Giacomo (1995) obtains complexity results various DLs sophisticated polynomial
reduction propositional dynamic logic. author establishes many complexity results,
one special interest purposes.
Theorem 4.6 ((De Giacomo, 1995), Section 7.3)

Satisfiability logical implication CNO knowledge bases (TBox ABox) Exp-complete.
DL CNO studied author strict extension ALCQO; TBoxes thesis
correspond call TIBoxes paper. Unary coding numbers assumed
Time

210

fiThe Complexity Cardinality Restrictions Nominals

throughout thesis. Although unique name assumption made, inherent
utilised reduction since explicitly enforced. thus possible eliminate
propositions require unique interpretation individuals reduction. Hence,
together Lemma 4.2, get following corollary.
Corollary 4.7

Consistency ALCQO-TIBoxes ExpTime-complete unary coding number assumed.
Together Theorem 4.5, solves open problem concerning lower bound
complexity ALCQ cardinality restrictions; moreover, shows NExpTime-algorithm presented (Baader et al., 1996) optimal respect worst case
complexity.
Corollary 4.8

Consistency ALCQ-TCBoxes ExpTime-complete, unary coding numbers cardinality number restrictions used.
4.2.2

ALCQIO

Conversely, using Theorem 4.5 enables us transfer NExpTime-completeness result
Theorem 3.8 ALCQIO.
Corollary 4.9

Consistency ALCQIO-TIBoxes TCBoxes NExpTime-complete.
Proof. TIBoxes, immediate corollary Theorem 4.5 Theorem 3.8.
Reasoning TCBoxes hard TIBoxes presences nominals.
results explains gap (De Giacomo, 1995). author establishes
complexity satisfiability knowledge bases consisting TIBoxes ABoxes
CNO, allows qualifying number restrictions, CIO, allows inverse
roles, reduction ExpTime-complete PDL. results given combination CINO, strict extension ALCQIO. Corollary 4.8 shows that, assuming
ExpTime 6= NExpTime, cannot polynomial reduction satisfiability
problem CINO knowledge bases ExpTime-complete PDL. Again, possible explanation leap complexity loss tree model property. CIO
CNO, consistency decided searching tree-like pseudo-models even presence
nominals, seems longer possible case knowledge bases CINO.
Unique Name Assumption noted definition nominals nonstandard Description Logics sense impose unique name assumption widely made, i.e., two individual names o1 ; o2 2 NI , oI1 6= oI2
required. Even without unique name assumption, possible enforce distinct interpretation nominals adding axioms form o1 v :o2. Moreover, imposing unique
name assumption presence inverse roles number restriction leads peculiar
effects. Consider following TIBox:
= fo v (6 k R >); > v 9R :og
211

fiTobies

unique name assumption, consistent iff NI contains k individual
names, individual name must interpreted unique element domain, every element domain must reachable oI via role R, oI may
k R-successors. believe dependency consistency TIBox
constraints explicit TIBox counter-intuitive hence
imposed unique name assumption.
Nevertheless, possible obtain tight complexity bound consistency ALCQIOTIBoxes unique name assumption without using Theorem 4.5, immediate
adaption proof Theorem 3.8.
Corollary 4.10

Consistency ALCQIO-TIBoxes unique name assumption NExpTime-complete
unary coding numbers assumed.
Proof. simple inspection reduction used prove Theorem 3.8, especially
proof Lemma 3.6 shows single nominal, marks upper right
corner torus, necessary perform reduction. individual name
create role name, following TIBox defines torus exponential size:

Tn = > v 9east:>;
> v 9north:>;
> v (= 1 east 1 >); > v (= 1 north 1 >);
> v 9create:C(0;0) ; v C(2 1;2 1) ;
C(2 1;2 1) v o;
> v Deast u Dnorth
n

n

n

n

Since reduction uses single individual name, unique name assumption
irrelevant.
Internalisation Axioms presence inverse roles nominals, possible
internalise general inclusion axioms concepts using spy-point technique used,
e.g., (Blackburn & Seligman, 1996; Areces et al., 1999). main idea technique
enforce elements model concept reachable distinct point
(the spy-point) marked individual name single step.
Definition 4.11 Let ALCQIO-TIBox. W.l.o.g., assume form
f> v C1 ; : : : ; > v Ck g. Let spy denote fresh role name fresh individual name.
define function spy inductively structure concepts setting Aspy =
2 NC , ospy = 2 NI , (:C )spy = :C spy, (C1 u C2 )spy = C1spy u C2spy ,
(> n R C )spy = (> n R (9spy :i) u C spy).
internalisation CT defined follows:
G

=iu

>vC 2T

C spy

u

G

CT

>vC 2T

8spy:C spy

Lemma 4.12 Let ALCQIO-TIBox. consistent iff CT satisfiable.
Proof. -direction let model CT 2 (CT )I . implies iI = fag.

Let 0 defined

0 = fag [ fx 2 j (a; x) 2 spyI g
212

fiThe Complexity Cardinality Restrictions Nominals

0 = jI0 .
0
0
Claim 1: every x 2 every ALCQIO-concept C , x 2 (C spy )I iff x 2 C .
proof claim induction structure C . interesting case
C = (> n R ). case C spy = (> n R (9spy :i) u spy ).
x 2 (> n R (9spy :i) u spy )I
iff ]fy 2 j (x; y) 2 RI 2 (9spy :i)I \ (Dspy)I g > n
() iff ]fy 2 0 j (x; y) 2 RI 0 2 DI 0 g > n
iff x 2 (> n R D)I 0 ;
equivalence () holds set equality 0 definition 0.
construction,0 every > v C 2 every x 2 , x 2 (C spy )I . Due Claim 1,
implies x 2 C hence 0 j= > v C .
only-if -direction, let interpretation I0 j= . pick
arbitrary
0

0


element 2 define extension setting = fag spy = f(a; x) j
x 2 . Since spy occur , still 0 j= .
0
Claim 2: every x 2 every ALCQIO-concept C contain spy,
0
0
x 2 C iff x 2 (C spy )I .
Again, claim proved induction structure concepts
interesting case C = (> n R D).
0
x 2 (> n R )I
iff ]fy 2 0 j (x; y) 2 RI 0 2 DI 0 g > n
() iff ]fy 2 0 j (x; y) 2 RI 0 ; (a; y) 2 spyI 0 ; 2 (Dspy)I 0 g > n
iff x 2 (> n R (9spy :i) u Dspy)I 0 :
Again, equivalence () holds due set equality definition 0.
Since, every > v C0 2 , 0 j= > v C , Claim 2 yields ( >vC 2T C spy)I 0 =
0
hence 2 (CT )I
consequence, obtain sharper result already pure concept satisfiability
ALCQIO NExpTime-complete problem.
F

Corollary 4.13

Concept satisfiability ALCQIO NExpTime-complete.
Proof. Lemma 4.12, get function mapping ALCQIO-TIBox CT
reduction consistency ALCQIO-TIBoxes ALCQIO-concept satisfiability.
Corollary 4.9 know former problem NExpTime-complete. Obviously, CT
computed polynomial time. Hence, lower complexity bound transfers.
213

fiTobies

Concept Satisfiability
GCIs
Cardinality Restr.

ALCQ

-c.
-c.
ExpTime-c.
PSpace

ExpTime

ALCQO

open

-c.
ExpTime-c.
ExpTime

ALCQI

-c.
-c.
NExpTime-c.

ALCQIO

-c.
-c.
NExpTime-c.

PSpace

NExpTime

ExpTime

NExpTime

Figure 4: Complexity reasoning problems
5. Conclusion

Combining results (De Giacomo, 1995) (Tobies, 2000) results
paper, obtain classification complexity concept satisfiability TBoxconsistency various DLs TBoxes consisting either cardinality restrictions
general concept inclusion axioms shown Figure 4, assume unary coding
numbers.
result ALCQIO shows current efforts extending expressive DLs
logic SHIQ (Horrocks et al., 1999) DLR(Calvanese et al., 1998c) propositional
dynamic logics CPDLg (De Giacomo & Lenzerini, 1996) nominals dicult tasks,
one wants obtain practical decision procedure, since already concept satisfiability
logics NExpTime-hard problem.
shown that, complexity C 2, ALCQI reach
expressive power (Tobies, 1999). Cardinality restrictions, although interesting knowledge
representation, inherently hard handle algorithmically. applies nominals
presence inverse roles number restrictions. explanation offer
lack tree model property, identified Vardi (1997) explanation
good algorithmic behaviour many modal logics.
first glance, results make ALCQI cardinality restrictions concepts
ALCQIO general axioms obsolete knowledge representation C 2 delivers
expressive power computational price. Yet, likely dedicated
algorithm ALCQI may better average complexity C 2 algorithm;
algorithm yet developed. highly desirable would also applicable
reasoning problems expressive DLs nominals, applications area
reasoning database schemata (Calvanese et al., 1998a, 1998b).
interesting question lies coding numbers: allow binary coding
numbers, translation approach together result (Pacholski et al., 1997)
leads 2-NExpTime algorithm. C 2, open question whether additional
exponential blow-up necessary. positive answer would settle question C 2
proof negative answer might give hints result C 2 might
improved. ALCQ cardinality restrictions, partially solved problem:
unary coding, problem ExpTime-complete whereas, binary coding,
NExpTime-hard.

214

fiThe Complexity Cardinality Restrictions Nominals

Acknowledgments

would like thank Franz Baader, Ulrike Sattler, anonymous referees valuable
comments suggestions. work supported DFG, Project No. GR 1324/3{
1.
References

Aiello, L. C., Doyle, J., & Shapiro, S. C. (Eds.)., Proceedings KR'96 (1996). Principles
Knowledge Representation Reasoning: Proceedings Fifth International
Conference (KR'96). Morgan Kaufmann Publishers, San Francisco, California.
Areces, C., Blackburn, P., & Marx, M. (1999). road-map complexity hybrid logics.
Proceedings Annual Conference European Association Computer
Science Logic (CSL-99), LNCS 1683, pp. 307{321. Springer-Verlag.
Baader, F., Buchheit, M., & Hollunder, B. (1996). Cardinality restrictions concepts.
Artificial Intelligence, 88 (1{2), 195{213.
Baader, F., & Sattler, U. (1999). Expressive number restrictions description logics.
Journal Logic Computation, 9 (3), 319{350.
Berger, R. (1966). undecidability dominoe problem. Memoirs American
Mathematical Society, 66.
Blackburn, P., & Seligman, J. (1996). Hybrid languages. Journal Logic, Language
Information, 3 (4), 251{272.
Borger, E., Gradel, E., & Gurevich, Y. (1997). Classical Decision Problem. Perspectives
Mathematical Logic. Springer-Verlag, Berlin.
Borgida, A. (1996). relative expressiveness description logics first order logics.
Artificial Intelligence, 82, 353{367.
Borgida, A., & Patel-Schneider, P. F. (1994). semantic complete algorithm
subsumption classic description logic. Journal Artificial Intelligence Research,
1, 277{308.
Calvanese, D., De Giacomo, G., Lenzerini, M., Nardi, D., & Rosati, R. (1998a). Source integration data warehousing. Proceedings Ninth International Workshop
Database Expert Systems Applications (DEXA-98), pp. 192{197. IEEE Computer
Society Press.
Calvanese, D., De Giacomo, G., & Lenzerini, M. (1998b). decidability query
containment constraints. Proceedings Seventeenth ACM SIGACT
SIGMOD SIGART Symposium Principles Database Systems (PODS-98).
Calvanese, D., De Giacomo, G., Lenzerini, M., Nardi, D., & Rosati, R. (1998c). Description
logic framework information integration. Proc. 6th Int. Conf.
Principles Knowledge Representation Reasoning (KR'98), pp. 2{13.
215

fiTobies

De Giacomo, G. (1995). Decidability Class-Based Knowledge Representation Formalisms. Ph.D. thesis, Dipartimento di Informatica e Sistemistica, Univ. di Roma
\La Sapienza".
De Giacomo, G., & Lenzerini, M. (1996). TBox ABox reasoning expressive description
logics.. Aiello et al. (Aiello et al., 1996), pp. 316{327.
Donini, F. M., Lenzerini, M., Nardi, D., & Schaerf, A. (1996). Reasoning description
logics. Brewka, G. (Ed.), Foundation Knowledge Representation, pp. 191{236.
CSLI-Publications.
Fine, K. (1972). many possible worlds. Notre Dame Journal Formal Logic, 13,
516{520.
Gargov, G., & Goranko, V. (1993). Modal logic names. J. Philosophical Logic, 22,
607{636.
Gradel, E., Otto, M., & Rosen, E. (1997). Two-variable logic counting decidable.
Proceedings, Twelth Annual IEEE Symposium Logic Computer Science, pp.
306{317 Warsaw, Poland. IEEE Computer Society Press.
Halpern, J. Y., & Moses, Y. (1992). guide completeness complexity model
logics knowledge belief. Artificial Intelligence, 54 (3), 319{379.
Horrocks, I., Sattler, U., & Tobies, S. (1999). Practical reasoning expressive description
logics. Proceedings 6th International Conference Logic Programming
Automated Reasoning (LPAR'99), pp. 161{180.
Pacholski, L., Szwast, W., & Tendera, L. (1997). Complexity two-variable logic
counting. Proceedings, Twelth Annual IEEE Symposium Logic Computer
Science, pp. 318{327 Warsaw, Poland. IEEE Computer Society Press.
Pratt, V. R. (1979). Models program logics. Proceedings Twentieth IEEE
Symposium Foundations Computer Science, pp. 115{122. IEEE.
Schmidt-Schau, M., & Smolka, G. (1991). Attributive concept descriptions complements. Artificial Intelligence, 48, 1{26.
Spaan, E. (1993). Complexity Modal Logics. Ph.D. thesis, University Amsterdam.
Tobies, S. (1999). NExpTime-complete description logic strictly contained C 2.
Flum, J., & Rodriguez-Artalejo, M. (Eds.), Proceedings Annual Conference
European Association Computer Science Logic (CSL-99), LNCS 1683, pp.
292{306. Springer-Verlag.
Tobies, S. (2000). PSPACE reasoning graded modal logics. Journal Logic Computation. appear.
216

fiThe Complexity Cardinality Restrictions Nominals

Vardi, M. Y. (1997). modal logic robustly decidable?. Descriptive Complexity
Finite Models: Proceedings DIMACS Workshop, January 14-17, 1996, No. 31
DIMACS Series Discrete Mathematics Theoretical Computer Science, pp.
149{184. American Math. Society.
Wang, H. (1963). Dominoes AEA case Decision Problem. Bell Syst. Tech.
J., 40, 1{41.
Woods, W. A., & Schmolze, J. G. (1992). Kl-One family. Computers Mathematics
Applications { Special Issue Artificial Intelligence, 23 (2{5), 133{177.

217

fiJournal Artificial Intelligence Research 12 (2000) 387-416

Submitted 12/99; published 6/00

Application Reinforcement Learning Dialogue
Strategy Selection Spoken Dialogue System Email
Marilyn A. Walker

walker@research.att.com

AT&T Shannon Laboratory
180 Park Ave., Bldg 103, Room E103
Florham Park, NJ 07932

Abstract

paper describes novel method spoken dialogue system learn
choose optimal dialogue strategy experience interacting human users.
method based combination reinforcement learning performance modeling spoken dialogue systems. reinforcement learning component applies Q-learning
(Watkins, 1989), performance modeling component applies PARADISE evaluation framework (Walker et al., 1997) learn performance function (reward) used
reinforcement learning. illustrate method spoken dialogue system named
elvis (EmaiL Voice Interactive System), supports access email phone.
conduct set experiments training optimal dialogue strategy corpus 219
dialogues human users interact elvis phone. test
strategy corpus 18 dialogues. show elvis learn optimize strategy
selection agent initiative, reading messages, summarizing email folders.

1. Introduction
past several years, become possible build spoken dialogue systems
communicate humans telephone real time. Systems exist tasks
finding good restaurant nearby, reading email, perusing classified advertisements
cars sale, making travel arrangements (Seneff, Zue, Polifroni, Pao, Hetherington, Goddeau, & Glass, 1995; Baggia, Castagneri, & Danieli, 1998; Sanderman, Sturm,
den Os, Boves, & Cremers, 1998; Walker, Fromer, & Narayanan, 1998). systems
realized examples real time, goal-oriented interactions humans
computers. Yet spite 30 years research algorithms dialogue management task-oriented dialogue systems, (Carbonell, 1971; Winograd, 1972; Simmons &
Slocum, 1975; Bruce, 1975; Power, 1974; Walker, 1978; Allen, 1979; Cohen, 1978; Pollack,
Hirschberg, & Webber, 1982; Grosz, 1983; Woods, 1984; Finin, Joshi, & Webber, 1986;
Carberry, 1989; Moore & Paris, 1989; Smith & Hipp, 1994; Kamm, 1995) inter alia,
design dialogue manager real-time, implemented systems still art
science (Sparck-Jones & Galliers, 1996). paper describes novel method,
experiments validate method, spoken dialogue system learn
experience human users optimize choice dialogue strategy.
dialogue manager spoken dialogue system processes user's utterance
chooses real time information communicate human user
communicate it. choice makes called strategy. dialogue manager
naturally formulated state machine, state dialogue defined set
c 2000 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiWalker

state variables representing observations user's conversational behavior, results
accessing various information databases, aspects dialogue history. Transitions
states driven system's dialogue strategy. typical system,
large number potential strategy choices state dialogue.
example, consider one choice faced elvis (EmaiL Voice Interactive System)
spoken dialogue system supports access user's email phone. elvis provides
verbal summaries user's email folders, many ways summarize folder
(Sparck-Jones, 1993, 1999). summary could consist simple statement
number messages different folders, e.g., 5 new messages, could provide
much detail messages particular folder, e.g., messages
Kim, one message meeting, second interviewing Antonio.
elvis must decide many properties message mention, message's
status, sender, subject message.1
Decision theoretic planning applied problem choosing among dialogue
strategies, associating utility U strategy (action) choice positing
spoken dialogue systems adhere Maximum Expected Utility Principle
(Keeney & Raiffa, 1976; Russell & Norvig, 1995),

Maximum Expected Utility Principle: optimal action one maximizes expected utility outcome states.

Thus, elvis act optimally choosing strategy state Si maximizes U (Si ).
formulation however simply leaves us problem derive utility
values U (Si ) dialogue state Si . Several reinforcement learning algorithms based
dynamic programming specify way calculate U (Si ) terms utility successor
state Sj (Bellman, 1957; Watkins, 1989; Sutton, 1991; Barto, Bradtke, & Singh, 1995),
utility final state dialogue known, would possible calculate
utilities earlier states, thus determine policy selects optimal
dialogue strategies.
Previous work suggested possible treat dialogue strategy selection
stochastic optimization problem way (Walker, 1993; Biermann & Long, 1996; Levin,
Pieraccini, & Eckert, 1997; Mellish, Knott, Oberlander, & O'Donnell, 1998). However
(Walker, 1993), argued lack performance function assigning utility
final state dialogue critical methodological limitation. seemed
three main possibilities simple reward function: user satisfaction, task completion,
measure user effort elapsed time dialogue number
user turns. appeared simple reward functions fail
capture essential aspects system's performance. example, level user
effort complete dialogue task system, domain task dependent. Moreover, high
levels effort, e.g., requirement users confirm system's understanding
utterance, necessarily lead concomitant increases task completion,
1. strategies implemented elvis summarized Figure 1. Note due practical
constraints, implemented strategy choices subset states, elvis uses fixed
strategy states. Section 2, describe detail strategy choices elvis explores
addition choices summarization, namely choices among strategies controlling dialogue
initiative reading multiple messages.

388

fiReinforcement Learning ELVIS System

lead significant decreases user satisfaction (Shriberg, Wade, & Price, 1992; Danieli &
Gerbino, 1995; Kamm, 1995; Baggia et al., 1998). Furthermore, user satisfaction alone fails
ect fact system successful unless helps user complete
task. concluded relationship measures interesting
complex method deriving appropriate performance function
necessary precursor applying stochastic optimization algorithms spoken dialogue
systems. (Walker, Litman, Kamm, & Abella, 1997a), proposed paradise method
learning performance function corpus human-computer dialogues.
work, apply paradise model learn performance function elvis,
use calculating utility final state dialogue experiments
applying reinforcement learning elvis's selection dialogue strategies. Section 2 describes implementation version elvis randomly explores alternate strategies
initiative, reading messages, summarizing email folders. Section 3 describes
experimental design first use exploratory version elvis collect
training corpus conversations 73 human users carrying set three email
tasks. Section 4 describes apply reinforcement learning corpus 219 dialogues optimize elvis's dialogue strategy decisions. test optimized policy
experiment six new users interact elvis complete set
tasks, show learned policy performs significantly better exploratory
policy used training phase.

2. ELVIS Spoken Dialogue System
started process designing elvis conducting Wizard-of-Oz experiment
recorded dialogues six people accessing email remotely talking
human playing part spoken dialogue system. purpose
experiment identify basic functionality implemented elvis.
analysis resulting dialogues suggested elvis needed support contentbased access email messages specification subject sender field, verbal
summaries email folders, reading body email message, requests help
repetition messages (Walker et al., 1997b, 1998).
Given requirements, implemented elvis using general-purpose platform
spoken dialogue systems (Kamm et al., 1997). platform consists dialogue
manager (described detail Section 2.2), speech recognizer, audio server
voice recordings text-to-speech (TTS), interface computer running
Elvis telephone network, modules specifying rules spoken language
understanding application specific functions.
speech recognizer speaker-independent Hidden Markov Model (HMM) system,
context-dependent phone models telephone speech, constrained grammars
defining vocabulary permitted point dialogue (Rabiner, Juang, &
Lee, 1996). platform supports barge-in, user interrupt system;
barge-in important application user interrupt system
reading long email message.
audio server switch voice recordings text-to-speech (TTS)
integrate voice recordings TTS. TTS technology concatenative diphone synthe389

fiWalker

sis (Sproat & Olive, 1995). Elvis uses TTS since would possible pre-record,
concatenate, words necessary realizing content email messages.
spoken language understanding (SLU) module consists set rules specifying
vocabulary allowable utterances, associated set rules translating
user's utterance domain-specific semantic representation meaning. syntactic
rules converted FSM network used directly speech recognizer
(Mohri, Pereira, & Riley, 1998). semantic rule associated syntactic
rule maps user's utterance directly application specific template consisting
application function name arguments. templates converted directly
application specific function calls specified application module. understanding
module also supports dynamic grammar generation loading recognizer
vocabulary must change interaction, e.g., support selection email messages
content fields sender subject.
application module provides application specific functions, e.g., functions accessing message attributes subject sender, functions making realizable
speech used instantiate variables spoken language generation.

2.1 ELVIS's Dialogue Manager Strategies

's dialogue manager based state machine one dialogue strategies
explored state. state dialogue manager defined set
state variables representing various items information dialogue manager uses
deciding next. state variables encode various observations user's
conversational behavior, results processing user's speech spoken
language understanding (SLU) module, results accessing information databases
relevant application, well certain aspects dialogue history. dialogue
strategy specification system say; Elvis represented
template variables must instantiated current context. states
system always executes dialogue strategy states alternate strategies
explored. strategies implemented Elvis summarized Figure 1.
complete specification dialogue strategy executed state called
policy dialogue system.
develop version Elvis supported exploring number possible policies,
implemented several different choices particular states system. goal
implement strategy choices states optimal strategy obvious priori.
purpose illustrating dialogue strategies explored, consider situation
user attempting execute following task (one tasks used
experimental data collection described Section 3):
Elvis

Task 1.1: working home morning plan go directly meeting

go work. Kim said would send message telling
meeting is. Find Meeting Time Meeting Place.

complete task, user needs find message Kim meeting
inbox listen it. many possible strategies Elvis could use help
user accomplish task. Below, first describe dialogue strategies Figure 1
390

fiReinforcement Learning ELVIS System

Strategy Type
Initiative
Summarization

Choices
Explored?
yes
yes

Reading

yes

Request-Info



Provide-Info
Help




Timeout



Rejection



Strategy Choices
System-Initiative (SI), Mixed-Initiative (MI)
SummarizeBoth (SB), SummarizeSystem (SS),
SummarizeChoicePrompt (SCP)
Read-First (RF), Read-Summary-Only (RSO),
Read-Choice-Prompt (RCP)
AskUserName, Ask-Which-Selection (AskWS),
Ask-Selection-Criteria (AskSC),
Read-Message
AskUserName-Help, SI-Top-Help, MI-Top-Help,
Read-Message-Help, AskWS-Help, AskSC-Help
AskUserName-Timeout,
Read-Timeout,
SI-Top-Timeout, MI-Top-Timeout, Read-MessageTimeout, AskWS-Timeout, AskSC-Timeout
AskUserName-Reject,
SITop-Reject, MI-Top-Reject, AskWS-Reject, AskSCReject, Read-Message-Reject

Figure 1: ELVIS's Dialogue Strategies. ELVIS explores choices Initiative, Summarization
Read Strategies uses fixed strategies elsewhere.
Elvis makes choices among, describe detail complete state machine,
dialogue strategies Figure 1 used states choice among
dialogue strategies, space policies Elvis execute. provide several
detailed examples dialogues generated Elvis's dialogue manager's state
machine.
2.1.1 Strategy Choices ELVIS

One strategy choice experiments involved exploration two different strategies
managing dialogue initiative: system-initiative mixed-initiative. implementation Elvis tested here, choice initiative made early dialogue
style initiative used throughout dialogue whenever could
choice two order avoid confusing user.
Previous research suggested system-initiative strategy Figure 2
Elvis directive user might best strategy, given current state
art speech recognition (Kamm, 1995). Figure 2, Elvis's utterances labelled
name dialogue strategy Elvis using produce utterance, e.g.,
utterance E1 labelled SI-Top, name system-initiative top level strategy.
choice system-initiative strategy also affects utterances E2 E3; utterances
Elvis continues dialogue requesting particular items information. general,
system-initiative strategy constrains user say point dialogue,
requesting particular items information one time, user constrained
providing information asked for. reason strategy
recommended given current state art speech recognition guides
391

fiWalker

E1: Hi, ELVIS here...You 5 new unread messages
inbox. Say Read, Summarize, say Help options.
U1: Read.
E2: Select Sender, Subject order arrival?
U2: Sender.
E3: Sender?
U3: Kim.
E4: messages Kim, there's 1 message \Interviewing
Antonio" 1 message \Meeting Today." first message
titled, \Interviewing Antonio." says, \I'd like interview him.
could also go along lunch. Kim."
U4: Next.
E5: message meeting today. says meeting
morning 10:00 2d516. See there, Kim.
U5: I'm done here.

SI-Top
Ask-Which-Selection
Ask-Selection-Criterion
Read-First (RF)

Read-Message

Figure 2: System-Initiative (SI) Dialogue Strategy: ELVIS explicitly prompts user
say point dialogue. ELVIS's utterances labelled
strategy names.
user saying things system likely understand, recognizer
vocabulary state constrained responses question asked.
strategy might dispreferred users however, could tedious user
constrained providing one item information time. dialogue Figure 2,
takes four user utterances access message Kim needed complete Task 1.1.
research suggested better strategy mixed-initiative strategy allows
user take initiative except user fails say anything system
trouble understanding user (Smith & Hipp, 1994; Levin, Pieraccini, Eckert,
Fabbrizio, & Narayanan, 1999; Webber & Joshi, 1982; Walker & Whittaker, 1990).
dialogue Figure 3 illustrates mixed-initiative dialogue strategy. Elvis's
utterances Figure 3 labelled name dialogue strategy Elvis using
produce utterance, e.g., utterance E1 labelled MI-Top, name mixedinitiative top level strategy. Note unlike SI-Top strategy, MI-Top strategy
volunteer information tell user say. Instead,
mixed-initiative strategy allows user take control dialogue specify exactly
wants single utterance, utterance U1 Figure 3. However,
evidence user trouble confused, user says
nothing utterance U2, mixed-initiative strategy take initiative ask
user information tell user say. utterance E3 Figure 3
Read-Timeout strategy triggered fact user's response delayed longer
pre-set timeout threshhold, system tells user actions available
point dialogue. general, mixed-initiative strategy support
ecient dialogues; dialogue Figure 2, takes two user utterances access
message Kim needed complete Task 1.1. However eciency gain may offset
increased likelihood misunderstandings user confusion.
392

fiReinforcement Learning ELVIS System

E1: Hi, ELVIS here. I've got mail.
U1: Read messages Kim.
E2: messages Kim, there's 1 message \Interviewing
Antonio" 1 message \Meeting Today." first message
titled, \Interviewing Antonio." says, \I'd like interview him. could
also go along lunch. Kim."
U2: (User says nothing within 5 seconds system takes initiative)
E3: say repeat, repeat last message, say next,
read next message folder. say, I'm done
exit folder.
U3: Next message.
E4: message meeting today. says meeting
morning 10:00 2d516. See there, Kim.
U4: I'm done here.

MI-Top
Read-First (RF)

Read-Timeout
ReadMessage

Figure 3: Mixed-Initiative (MI) Dialogue Strategy: ELVIS leaves user take
initiative, unless user seems trouble system
Summarize Strategy
Summarize-Both (SB)

Summarize-System (SS)
Summarize-Choice-Prompt
(SCP)

Example Prompt
top level inbox, Kim, there's 1 message
\Lunch." Michael, there's 1 message \Evaluation
group meeting." Noah, there's 1 message \Call
Tomorrow" 1 message \Interviewing Antonio."
Owen, there's 1 message \Agent Personality."
top level inbox, there's 1 message Kim, 2 messages
Noah, 1 message Michael, 1 message Owen.
E: Summarize subject, sender, both?
U: Subject.
E: top level inbox, there's 1 message \Lunch," 1
message \Interviewing Antonio," 1 message \Call
Tomorrow," 1 message \Evaluation Group Meeting,"
1 message \Agent Personality."

Figure 4: Alternate Summarization Strategies response request \Summarize
messages"
different type strategy choice involves Elvis's decisions present information user. mentioned many different ways summarize
set items user wants information about. Elvis explores set alternate summarization strategies illustrated Figure 4; strategies vary message attributes
included summary messages current folder. Summarize-Both
strategy (SB) uses sender subject attributes summary. employing Summarize-System strategy (SS), Elvis summarizes subject sender
based current context. instance, user top level inbox, Elvis
summarize sender, user situated folder containing messages par393

fiWalker

ticular sender, Elvis summarize subject, summary sender would provide
new information. Summarize-Choice-Prompt (SCP) strategy asks user specify
relevant attributes summarize by. See Figure 4.
Another type information presentation choice occurs request user
read subset messages, e.g., Read messages Kim, results multiple
matching messages. strategies explored Elvis summarized Figure 5. One
choice Read-First strategy (RF) involves summarizing messages
Kim, taking initiative read first one. Elvis used read strategy
dialogues Figures 2 3. alternate strategy reading multiple matching
messages Read-Summary-Only (RSO) strategy, Elvis provides information
allows users refine selection criteria. Another strategy reading multiple
messages Read-Choice-Prompt (RCP) strategy, Elvis explicitly tells user
say order refine message selection criteria. See Figure 5.
Read Strategy
Read-First (RF)
Read-Summary-Only
(RSO)
Read-Choice-Prompt
(RCP)

Example Prompt
messages Kim, there's 1 message \Interviewing Antonio" 1 message \Meeting Today." first message
titled, \Interviewing Antonio." says, \I'd like interview him.
could also go along lunch. Kim."
messages Kim, there's 1 message \Interviewing Antonio" 1 message \Meeting Today."
messages Kim, there's 1 message \Interviewing Antonio" 1 message \Meeting Today." hear messages,
say, \Interviewing Antonio" \Meeting."

Figure 5: Alternate Read Strategies response request \Read messages
Kim"
remainder Elvis's dialogue strategies, summarized Figure 1, fixed, i.e.
multiple versions strategies explored experiments presented here.
2.1.2 ELVIS's Dialogue State Machine

mentioned above, dialogue strategy choice system makes, particular
state, say say it. policy dialogue system complete
specification strategy execute system state. state defined set
state variables. Ideally, state representation corresponds dialogue model
summarizes dialogue history compactly, retains relevant information
dialogue interaction far. notion dialogue model retaining relevant
information formally known reinforcement learning state representation
satisfies Markov Property. state representation satisfying Markov Property one
probability particular state particular reward r
action prior state estimated function action
prior state, function complete dialogue history (Sutton & Barto, 1998).
precisely,
Pr(st+1 = s0; rt+1 = rjst ; ) = Pr(st+1 = s0 ; rt+1 = rjst; ; rt ; st,1 ; at,1 ; rt,1 ; : : : R1; s0 ; a0 )
394

fiReinforcement Learning ELVIS System

s0 ; r; st .
Markov Property guaranteed state representation encodes everything
system able observe everything happened dialogue far.
However, representation would complex estimate model probability
various state transitions, systems complex spoken dialogue system must
general utilize state representations compact possible.2 However state
representation impoverished, system lose much relevant information
work well.
Operations Variable
KnowUserName
InitStrat
SummStrat
ReadStrat
TaskProgress
CurrentUserGoal
NumMatches
WhichSelection
KnowSelectionCriteria
Confidence
Timeout
Help
Cancel

Abbrev
(U)
(I)
(S)
(R)
(P)
(G)
(M)
(W)
(SC)
(C)
(T)
(H)
(L)

Possible Values
0,1
0,SI,MI
0,SS,SCP,SB
0,RF,RSO,RCP
0,1,2
0,Read,Summarize
0,1,N>1
0,Sender (Snd),Subject (Sub),InOrder (InO)
0,1
0,1
0,1
0,1
0,1

Figure 6: Operations variables possible values define operations vector
controlling aspects ELVIS's behavior. abbreviations variable
names values used column headers Operations Variables
Figures 7, 8 9.
's state space representation must obviously discriminate among states
various strategy choices explored, addition, must state variables
capture distinctions number states Elvis always executes
strategy. state variables Elvis keeps track possible values given
Figure 6. KnowUserName (U) variable keeps track whether Elvis knows user's
name not. InitStrat (I), SummStrat (S) ReadStrat (R) variables keep track
whether Elvis already employed particular initiative strategy, summarize strategy
reading strategy current dialogue, so, strategy selected.
variable needed Elvis employs one strategies, strategy
used consistently throughout rest dialogue order avoid confusing user.
TaskProgress (P) variable tracks much progress user made completing
experimental task. CurrentUserGoal (G) variable corresponds system's belief
Elvis

2. respects driven implementation requirements since system development maintenance impossible without compact state representations.

395

fiWalker

U
0
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1

Operations Variables
Action Choices

R P G
W SC C H L
0 0
0 0 0
0
0 0 0 0 0 0 AskUserName
0 0
0 0 0
0
0 0 1 0 0 0 SI-Top, MI-Top
SI 0
0 0 0
0
0 0 1 0 1 0 SI-Top-Help
SI 0
0 0 0
0
0 0 0 0 0 0 SI-Top-Reject
SI 0
0 0
0
0 0 1 0 0 0 SS,SB,SCP
SI 0
0 0 R
0
0 0 1 0 0 0 AskWS
SI 0
0 0 R
0
0 0 0 0 0 0 AskWS-Reject
SI 0
0 0 R
0 Snd 0 1 0 0 0 AskSC
SI 0
0 0 R
0 Snd 0 1 1 0 0 AskSC-TimeOut
SI 0
0 0 R N>1 Snd 1 1 0 0 0 RF,RSO,RCP
SI 0 RCP 0 R
1 Snd 1 1 0 0 0 ReadMessage
SI 0 RCP 1 0
0
0 1 0 0 0 0 SI-Top
MI 0
0 0 0
0
0 0 1 0 1 0 MI-Top-Help
MI 0
0 0 0
0
0 0 0 0 0 0 MI-Top-Reject
MI 0
0 0
0
0 0 1 0 0 0 SS,SB,SCP
MI SS
0 0 R N>1 Snd 1 1 0 0 0 RF,RSO,RCP
MI SS RF 0 R
1 Snd 1 1 0 0 0 ReadMessage

Figure 7: portion ELVIS's operations state machine using full operations vector
control ELVIS's behavior
user's current goal is. WhichSelection (W) variable tracks whether
system knows type selection criteria user would like use read
messages. KnowSelectionCriteria (SC) variable tracks whether system believes
understood either sender name subject name use select messages.
NumMatches (M) variable keeps track many messages match user's selection
criteria. Confidence (C) variable threshholded variable indicating whether
speech recognizer's confidence understood user said pre-set
threshhold. Timeout (T) variable represents system's belief user didn't
say anything allotted time. Help (H) variable represents system's belief
user said Help, leads system providing context-specific help messages.
Cancel (L) variable represents system's belief user said Cancel, leads
system resetting state state last user utterance processed.
Thus 110,592 possible states used control operation system, although
states occur.3
order reader achieve better understanding range Elvis's capabilities way operations vector used, Figure 7 shows portion Elvis's state
machine generate sample system mixed-initiative dialogue interactions
Figures 8 9. figures provides state representation strategy choices made state sample dialogues. example, row two Figure
7 shows system acquires user's name (KnowUserName (U) = 1)
high confidence (Confidence (C) = 1), explore system-initiative (SI-Top)
3. example system knows user name, none variable values change
initial value.

396

fiReinforcement Learning ELVIS System

mixed-initiative (MI-Top) strategies. Figure 8 illustrates dialogue SI strategy
chosen Figure 9 illustrates dialogue MI-Top strategy chosen.
discuss detail dialogue Figure 8 generated state machine
Figure 7.
Figure 8, first row shows Elvis's strategy AskUserName executed
initial state dialogue operations variables set 0. Elvis's
utterance E1 surface realization strategy's execution. Note according
state machine Figure 7, strategy choices initial state
dialogue. user responds name SLU module returns user's
name dialogue manager high confidence (Confidence (C) = 1). dialogue
manager updates operations variables KnowUserName(U) = 1 Confidence (C)
= 1, shown row two Figure 8. Now, according state machine Figure 7,
two choices strategy, system-initiative strategy whose initial action SI-Top
mixed-initiative strategy whose initial action MI-Top. Figure 8 illustrates one
potential path SI-Top strategy chosen; Elvis's utterance E2 realization
SI-Top strategy. user responds utterance Help processed
SLU, dialogue manager receives input information SLU believes
user said Help (Help (H) = 1) high confidence (Confidence (C) = 1). dialogue
manager updates operations variables ect information SLU well
fact executed system-initiative strategy (InitStrat (I) = SI). results
operations vector shown adjacent Elvis's utterance E3. third row state
machine Figure 7 shows state, Elvis choice strategies, Elvis
simply executes SI-Top-Help strategy, realized utterance E3. user
responds saying Read (utterance U3) dialogue manager updates operations
variables results SLU module saying believes user said Read
(Goal (G) = R) high confidence (Confidence (C) = 1). state machine Figure 7
specifies state Elvis execute AskWhichSelection (AskWS) strategy,
corresponds Elvis's utterance E4 Figure 8. time, however, user
responds system's query word Sender (utterance U4), SLU module
confident understanding (Confidence (C) = 0) operations variable
updated confidence value. According state machine Figure 7, strategy
Elvis executes state AskWS-Reject strategy, specific rejection strategy
designed executed context goal acquire value WhichSelection
operations variable (see list operations variables Figure 6). realization
AskWS-Reject strategy utterance E5. user responds saying Sender
(utterance U5) time SLU module understands user's utterance high
confidence. dialogue manager updates WhichSelection (W) variable Snd
confidence variable, resulting operations vector shown adjacent utterance
E6. state machine Figure 7 specifies state Elvis execute
AskSelectionCriterion (AskSC) strategy realized utterance E6. user says
nothing (utterance U6) SLU module detects silence pre-set timeout
threshhold high confidence. dialogue manager updates operations variables
ect observation (Timeout (T) = 1, Confidence (C) = 1). state machine
Figure 7 specifies AskSC-Timeout strategy executed state;
context specific strategy re-attempts system's initial goal providing information
397

fiWalker

Operations Variables

Utterance

U
0 0

R
0 0

P
0

G
0

W
0 0

SC C
0
0 0

1

0

0

0

0

0

0

0

0

1

0

1

SI

0

0

0

0

0

0

0

1

0

1

SI

0

0

0

R

0

0

0

1

0

1

SI

0

0

0

R

0

0

0

0

0

1

SI

0

0

0

R

0

Snd

0

1

0

1

SI

0

0

0

R

0

Snd

0

1

1

1

SI

0

0

0

R

N

Snd

1

1

0

1

SI

0

RCP

0

R

1

Snd

1

1

0

1

SI

0

RCP

1

0

0

0

0

1

0

H L
0 0 E1: Hi, ELVIS here,
that?
U1: Susan.
0 0 E2: Hi Susan, Please wait.
I'll get mail (10 seconds).
Okay Susan, 5 new
unread messages inbox. Say Read, Summarize
say Help options.
U2: Help.
1 0 E3: access messages,
say read summarize.
switch active messages,
say new messages, messages. want repeat
message summary, say repeat. always say cancel
help. Say Goodbye Elvis,
hang up.
U3: Read.
0 0 E4: Select Sender, Subject
order Arrival?
U4: Sender
0 0 E5: didn't understand you.
want select messages
sender, subject order
arrival?
U5: Sender
0 0 E6: Sender?
U6: (user says nothing)
0 0 E7: senders are, Kim,
Noah, Michael, Owen.
sender want?
U7: Kim.
0 0 E8: messages Kim,
there's 1 message \Interviewing Antonio" 1 message \Meeting Today."
hear messages, say, \Interviewing Antonio" \Meeting."
U8: Meeting.
0 0 E9: message
meeting today. says meeting morning 10:00
2d516. See there, Kim.
U9: I'm done here.
0 0 E10: back
toplevel inbox. Say Read, Summarize say Help
options.

Strategy
Name
AskUserName
SI-Top

SI-Top-Help

AskWS
AskWSReject
AskSC
AskSCTimeOut
RCP

ReadMessage

SI-Top

Figure 8: System-Initiative Dialogue, completing Task 1.1 Figure 11, illustrating
ELVIS's ability provide help, use timeout confidence information
intended help user re-asking original query, realized
utterance E7. user responds name sender (utterance U7)
understood SLU high confidence (KnowSelectionCriteria (SC) = 1, Confidence =
398

fiReinforcement Learning ELVIS System

1). Elvis retrieves messages mail server matching selection criteria,
multiple matches found (NumMatches = N, per list operations variables
Figure 6). time row ten state machine Figure 7 specifies state
choice dialogue strategies, namely choice Read-First (RF), ReadSummary-Only (RSO) Read-Choice-Prompt (RCP) strategies illustrated Figure 5.
Elvis randomly chooses explore RCP strategy, realized utterance E8.
information user needs complete Task 1.1 provided utterance E9
user responds utterance U8 saying Meeting (and SLU understands high
confidence). row utterance E9 Figure 8 shows updated operations vector
ecting fact system executed RCP strategy; ReadStrat (R) variable
used enforce fact implementation Elvis, particular reading,
strategy selected, used consistently throughout dialogue avoid confusing
user. last exchange Figure 8, SLU module's confident understanding
user's utterance U9, I'm done here, results resetting G,M,W, SC variables
dialogue manager also updates variable TaskProg (P) 1 ect progress
experimental task. Figure 7 shows that, state, system one strategy;
since InitStrat variable set SI, system executes SI-Top strategy,
realized context utterance E10.
dialogue Figure 9 illustrates potential dialogue Elvis MI-Top
strategy selected rather SI-Top strategy user name acquired.
reader may also track path dialogue utilizing state machine Figure 7.
Note operations vector Elvis utilizes needed make Elvis fully operational system provides functionality equired support users. dialogues
Figures 8 9 also show Elvis provides:

Context-Specific Help strategies: illustrated strategies SI-Top-Help MITop-Help, supported Help variable.

Timeout strategies: system uses taking initiative context, trig-

gered delay user's response going time threshhold, illustrated
strategy AskSC-TimeOut, supported Timeout variable.

Rejection strategies: backoff dialogue actions become directive user
ASR returns confidence value lower confidence threshhold,
illustrated strategies AskWS-Reject MI-Top-Reject, supported
Confidence variable.

However, operations vector state representation needed control operation
system necessarily required even optimal applying reinforcement learning
(Barto et al., 1995; Sutton & Barto, 1998). Sometimes may advantageous aggregrate states purpose applying reinforcement learning, even possible
guarantee state representation obeys Markov property (Sutton & Barto,
1998). Note many states defined Figure 7 alternate strategies
explored. example, Confidence variable used system determine whether
apply backoff rejection strategy, vary rejection strategies.
incentive aggregrating states ignoring state variables irrelevant learning
399

fiWalker

Operations Variables

Utterance

U
0 0


0

R
0

P G
0 0

W
0 0

SC C
0
0


0

H L
0 0

1

0

0

0

0

0

0

0

0

0

0

1

0

E1: Hi, ELVIS here, AskUserName
that?
U1: Susan.
E2: Hi Susan, Please wait. I'll
get mail (delay 10
seconds).

1

MI 0

0

0

0

0

0

0

1

0

1

0

1

MI 0

0

0

0

0

0

0

0

0

0

0

1

MI 0

0

0



0

0

0

1

0

0

0

1

MI SS

0

0

R

N

Snd

1

1

0

0

0

1

MI SS

RF

1

R

1

Snd

1

1

0

0

0

Strategy
Name

Okay Susan, I've got mail.
U2: Help.
E3: read summarize messages using values
sender subject field.
example, say, read
message Lee
meeting, or, read messages
Kim, or, summarize
messages. access messages
current folder, also
say next, previous, first, last.
want repeat message summary, say repeat.
always say cancel
help. exit current folder
say, I'm done here. hangup,
say, Goodbye Elvis .
U3: Summarize messages.
E4: didn't understand you.
want
messages?
U4: Summarize them.
E5: top level inbox,
there's 2 messages Kim,
1 message Noah, 1 message Michael, 1 message Owen.
U5: Read messages
Kim
E6: messages Kim,
there's one message Interviewing Antonio one message Meeting Today.
first message says (user barges
in)
U6: Next message
E7: Next message.
message meeting today.
says meeting morning
10:00 2d516. See there,
Kim.

MI-Top
MI-Top-Help

MI-TopReject
SS

RF

ReadMessage

Figure 9: Mixed Initiative Dialogue completing Task 1.1 Figure 11, illustrating ELVIS's
ability provide help, use timeout confidence information
reduction state space size; means fewer dialogue samples needed
collect large enough sample state/action pairs purpose applying reinforcement
learning. perspective, goal aggregrate state space way
distinguish states different dialogue strategies explored.
400

fiReinforcement Learning ELVIS System

However, additional constraint state aggregration. Reinforcement learning4
backs rewards received final states dialogue sf earlier states si
strategy choices explored. However algorithm distinguish strategy choices
trajectory si sf distinct strategy choice. words,
two actions point lead state, without local reward, Q-values
two actions equal.
UserName (U) Init (I) TaskProg (P) UserGoal (G)
0,1
0,SI,MI 0,1,2,
0,R,S
Figure 10: Reinforcement Learning State Variables Values
Figure 10 specifies subset state variables given Figure 6 developed represent state space purpose applying reinforcement learning.
combination state variables compact, provides distinct trajectories
different strategy choices. reduced state space 18 states, supports dialogue
optimization policy space 2 312 = 1062882 different policies. policies
prima facie candidates optimal policies support human users
completing set experimental email tasks.

3. Experimental Design
Experimental dialogues training testing phase collected via experiments human users interacted Elvis complete three representative application tasks required access email messages three different email inboxes.
collected data 73 users performing three tasks (219 dialogues) training Elvis,
tested learned policy corpus six users performing
three tasks (18 dialogues).
Instructions users given set web pages, one page experimental dialogue. web page dialogue also contained brief general description
functionality system, list hints talking system, description
tasks user supposed complete, information call Elvis.
page also contained form specifying information acquired Elvis
dialogue, survey, filled task completion, designed probe user's
satisfaction Elvis. Users read instructions oces calling Elvis
oce phone.
three calls Elvis made sequence, conversation consisted
two task scenarios system user exchanged information criteria
selecting messages information within message. tasks given Figure
11, where, e.g., Task 1.1 Task 1.2 done conversation Elvis.
motivation asking caller complete multiple tasks call create subdialogue
structure experimental dialogues (Litman, 1985; Grosz & Sidner, 1986).
4. applied without local rewards.

401

fiWalker











Task 1.1: working home morning plan go directly meeting
go work. Kim said would send message telling
meeting is. Find Meeting Time Meeting Place.
Task 1.2: second task involves finding information different message. Yesterday
evening, told Lee might want call morning. Lee said would send
message telling reach him. Find Lee's Phone Number.
Task 2.1: got work, went directly meeting. Since people
late, you've decided call ELVIS check mail see meetings may
scheduled. Find day, place time scheduled meetings.
Task 2.2: second task involves finding information different message. Find
need call anyone. so, find number call.
Task 3.1: expecting message telling Discourse Discussion Group
meet. Find place time meeting.
Task 3.2: second task involves finding information different message. secretary
taken phone call left message. Find called
reach them.

Figure 11: Sample Task Scenarios





Dialogue Eciency Metrics: elapsed time, system turns, user turns
Dialogue Quality Metrics mean recognition score, timeouts, rejections, helps, cancels,

bargeins, timeout%, rejection%, help%, cancel%, bargein%
Task Success Metrics: task completion per survey
User Satisfaction: sum TTS Performance, ASR Performance, Task Ease, Interaction
Pace, User Expertise, System Response, Expected Behavior, Comparable Interface, Future
Use.

Figure 12: Metrics collected spoken dialogues.
collect number different measures dialogue via four different methods:
(1) dialogues recorded; (2) dialogue manager logs state
system enters dialogue strategy Elvis selects state; (3) dialogue
manager logs information calculating number dialogue quality dialogue eciency
metrics summarized Figure 12 described detail below; (4) end
dialogue, users fill web page forms support calculation task success
user satisfaction measures. explain use measures paradise
framework reinforcement learning.
402

fiReinforcement Learning ELVIS System

dialogue eciency metrics calculated dialogue recordings
system logs. length recording used calculate elapsed time seconds
(ET) beginning end interaction. Measures number System
Turns, number User Turns, calculated basis system logging
everything said everything heard user say.
dialogue quality measures derived recordings, system logs
hand-labeling. number system behaviors affect quality resulting dialogue
automatically logged. included number timeout prompts (timeouts)
played user didn't respond quickly expected, number recognizer
rejections (rejects) system's confidence understanding low said
something like I'm sorry didn't understand you. User behaviors system perceived
might affect dialogue quality also logged: included number times
system played one context specific help messages believed
user said Help (helps), number times system reset context
returned earlier state believed user said Cancel (cancels).
recordings used check whether users barged system utterances,
labeled per-state basis (bargeins).
Another measure dialogue quality recognizer performance whole dialogue,
calculated terms concept accuracy. recording user's utterance compared
logged recognition result calculate concept accuracy measure utterance
hand. Concept accuracy measure semantic understanding system, rather
word word understanding. example, utterance Read messages
Kim contains two concepts, read function, sender:kim selection criterion.
system understood user said Read, concept accuracy would 0.5. Mean
concept accuracy calculated whole dialogue used, conjunction
ASR rejections, compute Mean Recognition Score (MRS) dialogue.
goal generate models performance generalize across systems
tasks, also thought important introduce metrics likely generalize.
eciency metrics seemed unlikely generalize since, e.g., elapsed time
complete task depends dicult task is. research suggested
dialogue quality metrics likely generalize (Litman, Walker, & Kearns, 1999),
thought raw counts likely task specific. Thus normalized
dialogue quality metrics dividing raw counts total number utterances
dialogue. resulted timeout%, rejection%, help%, cancel%, bargein%
metrics.
web page forms basis calculating Task Success User Satisfaction
measures. Users reported perceptions whether completed task
(Comp).5 also provide objective evidence fact completed
task filling form information acquired Elvis.6
5. Yes,No responses converted 1,0.
6. supports alternative way calculating Task Success objectively using Kappa statistic
compare information users filled key task (Walker et al., 1997a). However
earlier results indicated user's perception task success better predictor
overall satisfaction, simply use perceived task success measured Comp.

403

fiWalker











ELVIS easy understand conversation? (TTS Performance)
conversation, ELVIS understand said? (ASR Performance)
conversation, easy find message wanted? (Task Ease)
pace interaction ELVIS appropriate conversation? (Interaction Pace)
conversation, know could say point dialogue? (User
Expertise)
often ELVIS sluggish slow reply conversation? (System
Response)
ELVIS work way expected conversation? (Expected Behavior)
conversation, ELVIS's voice interface compare touch-tone interface
voice mail? (Comparable Interface)
current experience using ELVIS get email, think you'd use
ELVIS regularly access mail away desk? (Future Use)

Figure 13: User Satisfaction Survey
order calculate User Satisfaction, users asked evaluate system's performance user satisfaction survey Figure 13. question responses
five point Likert scale simply required yes, yes, no, maybe responses.
survey questions probed number different aspects users' perceptions
interaction Elvis order focus user task rating system,
(Shriberg et al., 1992; Jack, Foster, & Stentiford, 1992; Love, Dutton, Foster, Jack, &
Stentiford, 1994). multiple choice survey response mapped range 1
5. values responses summed, resulting User Satisfaction
measure dialogue possible range 8 40.

4. Training Testing Optimized Dialogue Strategy
Given experimental training data, first apply paradise estimate performance
function Elvis linear combination metrics described above. apply
performance function dialogue training corpus estimate utility
final state dialogue apply Q-learning using utility. Finally test
learned policy new population users.

4.1

paradise

Performance Modeling

first step developing performance model spoken dialogue systems specification causal model performance illustrated Figure 14 (Walker et al., 1997a).
According model, system's primary objective maximize user satisfaction.
404

fiReinforcement Learning ELVIS System

MAXIMIZE USER SATISFACTION

MAXIMIZE TASK
SUCCESS

MINIMIZE COSTS

EFFICIENCY
MEASURES

Figure 14:

QUALITATIVE
MEASURES

's structure objectives spoken dialogue performance.

paradise

Task success various costs associated interaction contributors user satisfaction. Task success measured quantitatively number
ways: could represented continuous variable representing quality solution
boolean variable representing binary task completion. Dialogue costs two types:
dialogue eciency quality. Eciency costs measures system's eciency
helping user complete task, number utterances completion
dialogue. Dialogue quality costs intended capture aspects system
may strong effects user's perception system, number times
user repeat utterance order make system understand utterance.
Given model, performance metric dialogue system estimated
experimental data applying multivariate linear regression user satisfaction
dependent variable task success, dialogue quality, dialogue eciency measures
independent variables.7 stepwise linear regression training data measures
discussed above, showed Comp, MRS, BargeIn% Rejection% significant
contributors User Satisfaction, accounting 39% variance R-Squared (F
(4,192)=30.7, p <.0001).8
Performance = :27 Comp + :54 MRS , :09 BargeIn% + :15 Rejection%
tested well performance function generalize unseen test dialogues
tenfold cross-validation, randomly sampling 90% training dialogues
testing goodness fit performance model remaining 10% dialogues
7. One advantage approach performance function derived, longer necessary
collect user satisfaction reports users, opens possibility estimating reward
function fully automatic measures. latter possibility might also useful online calculation
reward function calculating local reward.
8. normalize metrics regression magnitude coecients directly
indicates contribution factor User Satisfaction (Cohen, 1995; Walker et al., 1997a).

405

fiWalker

training set. average R2 training set 37% standard error
.005, average R2 held-out 10% dialogues 38% standard
error .06. Since average R2 test set statistically indistinguishable
training set, assume performance model generalize new Elvis dialogues.

4.2 Training Optimized Policy

Given learned performance function described above, apply function
measures logged dialogue Di , thereby replacing range measures single performance value Pi , used utility (reward) final state
dialogue.9 apply reinforcement learning Pi utility final state
dialogue Di (Bellman, 1957; Sutton, 1991; Tesauro, 1992; Russell & Norvig, 1995;
Watkins, 1989). utility action state Si , U (a; Si ) (its Q-value),
calculated terms utility successor state Sj , obeying recursive equation:
U (a; Si ) = R(a; Si ) + Mija max
U (a0 ; Sj )


X

0

j

R(a; Si ) immediate reward received action Si , strategy
finite set strategies admissable state Si, Mija probability
reaching state Sj strategy selected state Si . experiments reported here,
reward associated state, R(Si ), zero. addition, since reliable priori
prediction user action particular state possible (for example user may say
Help speech recognizer may fail understand user), state transition model
Mija estimated logged state-strategy history dialogue.
utility values estimated within desired threshold using value iteration,
updates estimate U (a; Si ), based updated utility estimates neighboring
states, equation becomes:

Un+1 (a; Si ) = R(Si) +

XM
j


ij

max
Un(a0 ; Sj )

0

Un (a; Si ) utility estimate state Si n iterations (Sutton &
Barto, 1998) pp. 101. Value iteration stops difference Un (a; Si )
Un+1 (a; Si ) threshold, utility values associated states
strategy selections made.10 value iteration completed optimal policy
obtained selecting action maximal Q-value dialogue state.
Figure 15 enumerates subset states aggregrated state space used
reinforcement learning potential actions defining policy space. strategy
greatest Q-value state training indicated boldface Figure 15.
optimized policy tested fixed policy operation Elvis.
states task, System-Initiative strategy Figure 2 predicted
optimal initiative strategy, Read-First strategy Figure 5 predicted
best performance Read strategies. Figure 15 shows, learned strategy
9. dialogue treated unique final state.
10. experimenting various threshholds, used threshold 5% performance range
dialogues.

406

fiReinforcement Learning ELVIS System

State Variables
U P G
0 0 0 0
1 0 0 0
1 SI 0
1 SI 0 R
1 SI 1 0
1 SI 1
1 SI 1 R
1 SI 2 0
1 SI 2
1 SI 2 R
1 MI 0
1 MI 0 R
1 MI 1 0
1 MI 1
1 MI 1 R
1 MI 2 0
1 MI 2
1 MI 2 R

Strategy Choices
AskUserName
SI-Top, MI-Top
SS,SB,SCP
RF,RSO,RCP
SI-Top
SS,SB,SCP
RF,RSO,RCP
SI-Top
SS,SB,SCP
RF,RSO,RCP
SS,SB,SCP
RF,RSO,RCP
MI-Top
SS,SB,SCP
RF,RSO,RCP
MI-Top
SS,SB,SCP
RF,RSO,RCP

Figure 15: subset state space defines policy class explored experiments. learned policy indicated boldface.
summarization varies according state task. different summarization
strategies illustrated Figure 4. policy learned use SummarizeBoth strategy beginning dialogue (when TaskProg = 0), switch
using Summarize-System strategy later phases dialogue. strategy makes
sense terms giving user complete information messages inbox
beginning dialogue.

4.3 Testing Optimized Policy

first constructed deterministic version Elvis implemented learned policy
discussed above, one variation. variation based fact decision
whether use Summarize-Both Summarize-System summarization strategy
conditioned value TaskProg variable. However, intended utilize optimized version system situations would access TaskProg
variable, namely situations task user attempting perform
control experimenter. examined Q-values summarization strategies course dialogue, found Summarize-System strategy
greatest average Q-value, strongly preferred Summarize-Both strategy
except initial phase dialogue, Q-value Summarize-Both
407

fiWalker

slightly greater. Thus implemented learned policy (see Figure 15),
exception Summarize-System strategy used throughout dialogue.11
terms operations state machine Figure 7, implementation learned
policy means choices SI-Top MI-Top strategies replaced
SI-Top strategy, choices different read strategies different states
replaced Read-First (RF) strategy choices different summarization
strategies different states replaced Summarize-System (SS) strategy.
tested policy six new users never used Elvis before.
users conversed Elvis perform set six email tasks used
training phase, described Figure 10 above. addition, identical performance
measures collected testing dialogue training dialogue. Overall performance
measures training test dialogues given Table 1, training data split
terms System-Initiative, Mixed-Initiative overall means. table shows
versions Elvis high levels task completion, important testing
utility reinforcement learning. Statistical analysis results indicated statistically
significant increase User Satisfaction training test (F= = 4.07 p = .047).

5. Discussion Future Work

paper proposes novel method dialogue system learn choose
optimal dialogue strategy tests experiments Elvis, dialogue system
supports access email phone, strategies initiative, reading summarizing messages. reported experiments Elvis learned System-Initiative
strategy higher utility Mixed-Initiative strategy, Read-First best
read strategy, Summarize-System generally best summary strategy.
tested policy Elvis learned new set users performing set
tasks showed learned policy resulted statistically significant increase
user satisfaction test set dialogues.
Previous work also treated system's choice dialogue strategy stochastic
optimization problem (Walker, 1993; Biermann & Long, 1996; Levin & Pieraccini, 1997;
Levin et al., 1997). knowledge, Walker (1993) first proposed reinforcement
learning algorithms could applied dialogue strategy selection. simulation experiments reported Walker (1993, 1996), dialogues two agents artificial world
used test dialogue strategies optimal various conditions.
experiments varied: (1) dialogue agent's resource bounds; (2) performance function used assess agent's performance. experiments showed strategies
optimal one set assumptions performance function could
highly ecacious performance function ected fact dialogue agent
resource bounded. Walker (1993) suggested optimal dialogue strategy could
11. Obviously choice strategy test risked testing non-optimal policy. alternative
would like try future work utilize SummStrat state variable operations vector
state representation reinforcement learning simply distinguish states summarize
strategy selected (no summary produced) states least one summary
produced. analysis dialogue phase carries through, policy
learned use Summarize-Both strategy first summary dialogue afterwards
use Summarize-System strategy.

408

fiReinforcement Learning ELVIS System

Measure Train SI Train MI Overall Train Test
Comp
.87
.80
.85
.94
User Turns
21.5
17.0
20.0 25.8
System Turns
24.2
21.2
23.1 29.2
Elapsed time (sec) 339.14
296.18
311.56 368.5
Mean recognition score
.88
.72
.82
.81
TimeOuts
2.7
4.2
3.0
3.3
TimeOut%
.11
.19
.13
.11
Cancs
.34
.02
.26
.00
Canc%
.02
.00
.01
.00
Help Requests
.67
.92
0.66 1.11
Help%
.03
.05
.03
.04
BargeIns
3.6
3.6
3.7
7.8
BargeIn%
.08
.09
.18
.30
Rejects
.9
1.6
1.1
1.4
Reject%
.04
.08
.05
.05
User satisfaction
28.9
25.0
27.5 31.7
Table 1: Performance measure means per dialogue Training Testing Dialogues. SI
= System-Initiative, MI = Mixed-Initiative
learned via reinforcement learning, appropriate performance function could determined, described experiment using genetic algorithms learn optimal dialogue
strategy. subsequent work, utilized here, paradise model proposed way
learn appropriate performance function (Walker et al., 1997a). addition, related work
utilizing Elvis, varied reward function, applied reinforcement learning
algorithms, carried Fromer (Fromer, 1998).
Biermann Long (1996), proposed use similar techniques context
learning optimal dialogue strategies multi-modal dialogue tutor. goal tutor
instruct students taking first programming class tutor interacted
students highlighting parts code printing text screen telling
wrong program. Biermann Long describe planned experiment
system would vary instructional style, system's reward would
amount time system's instructions student's response. reward
function based assumption delayed response suggested greater cognitive
load student, cognitive load minimized instructional setting.
Levin colleagues also proposed treating dialogue systems Markov Decision Processes suggested system designers could determine appropriate objective
function might (Levin et al., 1997; Levin & Pieraccini, 1997). carried series
experiments simulated user interacted implemented spoken dialogue
system travel planning exchanging messages semantic meaning level.
showed system could learn strategy choices level database interaction,
409

fiWalker

e.g., system query database determined many
constraints necessary order find ights matched user's goals.
Stochastic optimization techniques also applied similar problems textbased dialogue interaction graphical user interfaces. Mellish colleagues applied
stochastic optimization problem determining content structure
system's utterances ILEX system, interactive museum tour guide (Mellish et al.,
1998). work tested user population performance (reward)
measure based heuristics good text plans formulated experts. Christensen
colleagues applied genetic algorithms design graphical user interface
automated teller machine. goal automatically learn best layout sequence
interaction screens intracting user (Christensen, Marks, & Shieber, 1994).
work, Levin colleagues, user population simulated.
Here, method optimizing dialogue strategy selection illustrated evaluating strategies managing initiative information presentation interaction
human callers. applied paradise performance model derive empirically motivated performance function, combines subjective user preferences objective
system performance measures single function. would impossible predict priori dialogue factors uence usability dialogue system,
degree. performance equation shows task success dialogue quality measures
primary contributors system performance. Furthermore, contrast assuming priori model, use dialogues real user-system interactions provide
realistic estimates Mija , state transition model used learning algorithm.
impossible predict priori transition frequencies, given imperfect nature
spoken language understanding, unpredictability user behavior.
use method introduces several open issues possible areas future
work. First, results learning algorithm dependent representation
state space. spoken dialogue systems, system designers construct state space
decide state variables system needs monitor, whereas applications reinforcement learning (e.g. backgammon), state space pre-defined.
experiments reported here, fixed state representation carried experiments
particular state representation. However future work hope able learn
aspects state history represented using similar techniques
described (Langkilde, Walker, Wright, Gorin, & Litman, 1999). example, may
beneficial system represent additional state variables representing
dialogue history, order Elvis able learn dialogue strategies ect
aspects dialogue history.
Second, advance actually running experiments, clear much experience
system need determine strategy better. experiments reported here,
able show improvement policy converged initiative
read strategies yet converged appropriate summarization strategy.
possible local rewards nonzero optimal policy could
learned less training data. future work, hope explore interaction
training set size use local reward.
Third, experimental data based fixing particular experimental parameters.
experiments based short-term interactions novice users, might
410

fiReinforcement Learning ELVIS System

expect users email system would engage many interactions
system, preferences system interaction strategies could change time
user expertise. means performance function might change time. also
used fixed set tasks representative domain, possible
aspects policies learned might sensitive experimental tasks. Another
limitation experiments carried scenario email folder
small number messages: strategies tested might optimal
email folder contains hundreds messages.
Fourth, optimal strategy potentially dependent various system parameters.
example, ReadFirst strategy takes initiative read message, might result
messages read user wasn't interested in, since user barge-in
system utterances, little overhead taking decision. system
support barge-in, results might different.
Fifth, learned policy depends reward function. example, since Elvis
fully functional system, users complete experimental task version
system using strategies explored. means used
task completion reward function, reinforcement learning would predicted
differences different strategies. hand, using
paradise performance function, utilized reward function fit data
Elvis's performance, evidence reward function may generalize
systems (Walker, Kamm, & Litman, 2000).
Sixth, experiments report limited way demonstrate
utility reinforcement learning dialogue strategy optimization. traditional
way selecting best dialogue strategies would experiments treated
dialogue strategy selection factor, standard statistical hypothesis testing would
used compare performance different strategies. scale experiment
small enough imaginable space policies could possibly
tested traditional way. However, primary goal experiments reported
simply test feasibility methods, required working
detail many issues state strategy representation discussed above.
many details worked out, methods presented applied
much complex dialogue strategy optimization problems, varying initiative
depending dialogue state (Chu-Carroll & Brown, 1997; Webber & Joshi, 1982),
exploring combinations strategies information presentation, summarization (SparckJones, 1999), error recovery (Hirschman & Pao, 1993), database query (Levin et al., 1997),
cooperative responses (Joshi, Webber, & Weischedel, 1986; Finin et al., 1986; Chu-Carroll &
Carberry, 1994), content selection generation (McKeown, 1985; Kittredge, Korelsky,
& Rambow, 1991), inter alia.
Finally, learning algorithm report off-line algorithm, i.e. Elvis
collects set dialogues decides optimal strategy result. contrast,
possible Elvis learn on-line, course dialogue, methods
developed performance function automatically calculated approximated.
primary goal experiments reported explore application
reinforcement learning spoken dialogue systems identify open issues
discussed above. current work, exploring issues several ways.
411

fiWalker

codified notion state estimator systematically vary state
representation order explore effect state representation value function
optimal policy (Singh, Kearns, Litman, & Walker, 1999). also process
using reinforcement learning conduct set experiments spoken dialogue system
accessing information activities New Jersey. experiments explore
number different reward functions also explore much broader range strategies
user initiative, reprompting user, confirming system's understanding.

6. Acknowledgements
received many useful questions comments research presented
initial results invited talk given AAAI 1997 Providence, R.I. design
implementation basic functionality Elvis done collaboration J. Fromer,
G. DiFabbrizio, D. Hindle C. Mestel. Initial experiments reinforcement learning
Elvis done collaboration J. Fromer S. Narayanan. work also
benefited discussions W. Eckert, C. Kamm, M. Kearns, E. Levin, D. Litman, D.
McAllester, R. Pieraccini, R. Sutton, S. Singh. Special thanks S. Whittaker, J.
Wiebe four reviewers detailed comments earlier versions manuscript.
v

References
Allen, J. F. (1979). Plan-Based Approach Speech Act Recognition. Tech. rep., University Toronto.
Baggia, P., Castagneri, G., & Danieli, M. (1998). Field trials italian arise train
timetable system. Interactive Voice Technology Telecommunications Applications, IVTTA, pp. 97{102.
Barto, A., Bradtke, S. J., & Singh, S. P. (1995). Learning act using real-time dynamic
programming. Artificial Intelligence Journal, 72(1-2), 81{138.
Bellman, R. E. (1957). Dynamic Programming. Princeton University Press, Princeton, N.J.
Biermann, A. W., & Long, P. M. (1996). composition messages speech-graphics
interactive systems. Proceedings 1996 International Symposium Spoken
Dialogue, pp. 97{100.
Bruce, B. (1975). Belief systems language understanding. Tech. rep. AI-21, Bolt,
Berenak Newman.
Carberry, S. (1989). Plan recognition use understanding dialogue. Kobsa,
A., & Wahlster, W. (Eds.), User Models Dialogue Systems, pp. 133{162. Springer
Verlag, Berlin.
Carbonell, J. R. (1971). Mixed-initiative man-computer dialogues. Tech. rep. 1970, Bolt
Beranek Newman, Cambridge, MA.
412

fiReinforcement Learning ELVIS System

Christensen, J., Marks, J., & Shieber, S. (1994). Placing text labels maps diagrams.
Heckbert, P. (Ed.), Graphics Gems IV. Academic Press.
Chu-Carroll, J., & Brown, M. K. (1997). Tracking initiative collaborative dialogue interactions. Proceedings 35th Annual Meeting Association Computational
Linguistics, pp. 262{270.
Chu-Carroll, J., & Carberry, S. (1994). plan-based model response generation
collaborative task-oriented dialogue. AAAI 94, pp. 799{805.
Cohen, P. R. (1995). Empirical Methods Artificial Intelligence. MIT Press, Boston.
Cohen, P. R. (1978). knowing say: Planning speech acts. Tech. rep. 118,
University Toronto; Department Computer Science.
Danieli, M., & Gerbino, E. (1995). Metrics evaluating dialogue strategies spoken
language system. Proceedings 1995 AAAI Spring Symposium Empirical
Methods Discourse Interpretation Generation, pp. 34{39.
Finin, T. W., Joshi, A. K., & Webber, B. L. (1986). Natural language interactions
artificial experts. Proceedings IEEE, 74(7), 921{938.
Fromer, J. C. (1998). Learning optimal discourse strategies spoken dialogue system.
Tech. rep., MIT AI Lab M.S. Thesis.
Grosz, B. J. (1983). Team: transportable natural language interface system. Proc. 1st
Applied ACL, Association Computational Linguistics, Santa Monica, Ca.
Grosz, B. J., & Sidner, C. L. (1986). Attention, intentions structure discourse.
Computational Linguistics, 12, 175{204.
Hirschman, L., & Pao, C. (1993). cost errors spoken language system. Proceedings Third European Conference Speech Communication Technology,
pp. 1419{1422.
Jack, M., Foster, J. C., & Stentiford, F. W. (1992). Intelligent dialogues automated telephone services. International Conference Spoken Language Processing, ICSLP,
pp. 715 { 718.
Joshi, A. K., Webber, B., & Weischedel, R. M. (1986). aspects default reasoning
interactive discourse. Tech. rep. MS-CIS-86-27, University Pennsylvania.
Kamm, C., Narayanan, S., Dutton, D., & Ritenour, R. (1997). Evaluating spoken dialog systems telecommunication services. 5th European Conference Speech
Technology Communication, EUROSPEECH 97, pp. 2203{2206.
Kamm, C. (1995). User interfaces voice applications. Roe, D., & Wilpon, J.
(Eds.), Voice Communication Humans Machines, pp. 422{442. National
Academy Press.
413

fiWalker

Keeney, R., & Raiffa, H. (1976). Decisions Multiple Objectives: Preferences Value
Tradeoffs. John Wiley Sons.
Kittredge, R., Korelsky, T., & Rambow, O. (1991). need domain communication
knowledge. Computational Intelligence, 7 (4), 305{314.
Langkilde, I., Walker, M., Wright, J., Gorin, A., & Litman, D. (1999). Automatic prediction
problematic human-computer dialogues May Help You?. Proceedings
IEEE Workshop Automatic Speech Recognition Understanding, ASRUU99.
Levin, E., & Pieraccini, R. (1997). stochastic model computer-human interaction
learning dialogue strategies. EUROSPEECH 97.
Levin, E., Pieraccini, R., & Eckert, W. (1997). Learning dialogue strategies within
Markov Decision Process framework. Proc. IEEE Workshop Automatic Speech
Recognition Understanding.
Levin, E., Pieraccini, R., Eckert, W., Fabbrizio, G. D., & Narayanan, S. (1999). Spoken
language dialogue: theory practice. Proc. IEEE Workshop Automatic
Speech Recognition Understanding, ASRUU99.
Litman, D. (1985). Plan recognition discourse analysis: integrated approach
understanding dialogues. Tech. rep. 170, University Rochester.
Litman, D. J., Walker, M. A., & Kearns, M. J. (1999). Automatic detection poor speech
recognition dialogue level. Proceedings Thirty Seventh Annual Meeting
Association Computational Linguistics, pp. 309{316.
Love, S., Dutton, R. T., Foster, J. C., Jack, M. A., & Stentiford, F. W. M. (1994). Identifying salient usability attributes automated telephone services. International
Conference Spoken Language Processing, ICSLP, pp. 1307{1310.
McKeown, K. R. (1985). Discourse strategies generating natural language text. Artificial
Intelligence, 27 (1), 1{42.
Mellish, C., Knott, A., Oberlander, J., & O'Donnell, M. (1998). Experiments using stochastic search text planning. Proceedings International Conference Natural
Language Generation, pp. 97{108.
Mohri, M., Pereira, F. C. N., & Riley, M. D. (1998). Fsm library { general purpose finitestate machine software tools..
Moore, J. D., & Paris, C. L. (1989). Planning text advisory dialogues. Proc. 27th
Annual Meeting Association Computational Linguistics.
Pollack, M., Hirschberg, J., & Webber, B. (1982). User participation reasoning process
expert systems. Proceedings First National Conference Artificial Intelligence,
pp. pp. 358{361.
Power, R. (1974). Computer Model Conversation. Ph.D. thesis, University Edinburgh.
414

fiReinforcement Learning ELVIS System

Rabiner, L. R., Juang, B. H., & Lee, C. H. (1996). overview automatic speech
recognition. Lee, C. H., Soong, F. K., & Paliwal, K. K. (Eds.), Automatic Speech
Speaker Recognition, Advanced Topics, pp. 1{30. Kluwer Academic Publishers.
Russell, S., & Norvig, P. (1995). Artificial Intelligence: Modern Approach. Prentiss Hall,
Englewood Cliffs, N.J.
Sanderman, A., Sturm, J., den Os, E., Boves, L., & Cremers, A. (1998). Evaluation
dutchtrain timetable information system developed ARISE project.
Interactive Voice Technology Telecommunications Applications, IVTTA, pp. 91{
96.
Seneff, S., Zue, V., Polifroni, J., Pao, C., Hetherington, L., Goddeau, D., & Glass, J. (1995).
preliminary development displayless PEGASUS system. ARPA Spoken
Language Technology Workshop.
Shriberg, E., Wade, E., & Price, P. (1992). Human-machine problem solving using spoken language systems (SLS): Factors affecting performance user satisfaction.
Proceedings DARPA Speech NL Workshop, pp. 49{54.
Simmons, R., & Slocum, J. (1975). Generating english discourse semantic networks.
CACM, 15 (10), 891{905.
Singh, S., Kearns, M. S., Litman, D. J., & Walker, M. A. (1999). Reinforcement learning
spoken dialogue systems. Proc. NIPS99.
Smith, R. W., & Hipp, D. R. (1994). Spoken Natural Language Dialog Systems: Practical
Approach. Oxford University Press.
Sparck-Jones, K. (1993). might summary?. Proceedings Information
Retrieval 93: Von der Modellierung zur Anwendung, pp. 9{26 Universitatsverlag Knstanz.
Sparck-Jones, K. (1999). Automatic summarizing; factors directions. Mani, I., &
Maybury, M. (Eds.), Advances Automatic Text Summarization. MIT Press.
Sparck-Jones, K., & Galliers, J. R. (1996). Evaluating Natural Language Processing Systems.
Springer.
Sproat, R., & Olive, J. (1995). approach text-to-speech synthesis. Kleijn, W. B.,
& Paliwal, K. K. (Eds.), Speech Coding Synthesis, pp. 611{633. Elsevier.
Sutton, R. S. (1991). Planning incremental dynamic programming. Proceedings Ninth
Conference Machine Learning, pp. 353{357. Morgan-Kaufmann.
Sutton, R. S., & Barto, A. G. (1998). Reinforcement Learning. MIT Press.
Tesauro, G. (1992). Practical Issues Temporal Difference Learning. Machine Learning,
8 (3{4), 257{277.
Walker, D. (1978). Understanding Spoken Language. Elsevier, North-Holland, New York.
415

fiWalker

Walker, M., Fromer, J., Fabbrizio, G. D., Mestel, C., & Hindle, D. (1998). say:
Evaluating spoken language interface email. Proceedings Conference
Computer Human Interaction (CHI 98), pp. 582{589.
Walker, M. A., Litman, D., Kamm, C. A., & Abella, A. (1997a). PARADISE: general
framework evaluating spoken dialogue agents. Proceedings 35th Annual
Meeting Association Computational Linguistics, ACL/EACL 97, pp. 271{
280.
Walker, M., Hindle, D., Fromer, J., Fabbrizio, G. D., & Mestel, C. (1997b). Evaluating
competing agent strategies voice email agent. Proceedings European
Conference Speech Communication Technology, EUROSPEECH97.
Walker, M. A. (1993). Informational Redundancy Resource Bounds Dialogue. Ph.D.
thesis, University Pennsylvania.
Walker, M. A. (1996). Effect Resource Limits Task Complexity Collaborative
Planning Dialogue. Artificial Intelligence Journal, 85 (1{2), 181{243.
Walker, M. A., Fromer, J. C., & Narayanan, S. (1998). Learning optimal dialogue strategies: case study spoken dialogue agent email. Proceedings 36th
Annual Meeting Association Computational Linguistics, COLING/ACL 98,
pp. 1345{1352.
Walker, M. A., Kamm, C. A., & Litman, D. J. (2000). Towards developing general models
usability PARADISE. Natural Language Engineering: Special Issue Best
Practice Spoken Dialogue Systems.
Walker, M. A., & Whittaker, S. (1990). Mixed initiative dialogue: investigation
discourse segmentation. Proc. 28th Annual Meeting ACL, pp. 70{79.
Watkins, C. J. (1989). Models Delayed Reinforcement Learning. Ph.D. thesis, Cambridge
University.
Webber, B., & Joshi, A. (1982). Taking initiative natural language database interaction: Justifying why. Coling 82, pp. 413{419.
Winograd, T. (1972). Understanding Natural Language. Academic Press, New York, N.Y.
Woods, W. A. (1984). Natural language communication machines: ongoing goal.
Reitman, W. (Ed.), Artificial Intelligence Applications Business, pp. 195{209.
Ablex Publishing Corp, Norwood, N.J.

416

fiJournal Artificial Intelligence Research 12 (2000) 134

Submitted 7/99; published 2/00

Planning Graph (Dynamic) CSP:
Exploiting EBL, DDB CSP Search Techniques Graphplan
Subbarao Kambhampati

RAO @ ASU . EDU

Department Computer Science Engineering
Arizona State University, Tempe AZ 85287-5406

Abstract
paper reviews connections Graphplans planning-graph dynamic
constraint satisfaction problem motivates need adapting CSP search techniques
Graphplan algorithm. describes explanation based learning, dependency directed backtracking, dynamic variable ordering, forward checking, sticky values random-restart search
strategies adapted Graphplan. Empirical results provided demonstrate
augmentations improve Graphplans performance significantly (up 1000x speedups)on several
benchmark problems. Special attention paid explanation-based learning dependency
directed backtracking techniques empirically found useful improving
performance Graphplan.

1. Introduction
Graphplan (Blum & Furst, 1997) currently one efficient algorithms solving classical planning problems. Four five competing systems recent AIPS-98 planning competition based Graphplan algorithm (McDermott, 1998). Extending efficiency
Graphplan algorithm thus seems worth-while activity. (Kambhampati, Parker, &
Lambrecht, 1997), provided reconstruction Graphplan algorithm explicate links
previous work classical planning constraint satisfaction. One specific link discussed
connection process searching Graphplans planning graph, solving dynamic constraint satisfaction problem (DCSP) (Mittal & Falkenhainer, 1990). Seen DCSP
perspective, standard backward search proposed Blum Furst (1997) lacks variety ingredients thought make efficient CSP search mechanisms (Frost & Dechter, 1994;
Bayardo & Schrag, 1997). include forward checking, dynamic variable ordering, dependency directed backtracking explanation-based learning (Tsang, 1993; Kambhampati, 1998).
(Kambhampati et al., 1997), suggested would beneficial study impact
extensions effectiveness Graphplans backward search.
paper, describe experiences adding variety CSP search techniques improve Graphplan backward searchincluding explanation-based learning (EBL) dependencydirected backtracking capabilities (DDB), Dynamic variable ordering, Forward checking, sticky
values, random-restart search strategies. these, addition EBL DDB capabilities
turned empirically useful. EBL DDB based explaining failures
leaf-nodes search tree, propagating explanations upwards search
tree (Kambhampati, 1998). DDB involves using propagation failure explanations support
intelligent backtracking, EBL involves storing interior-node failure explanations, pruning
future search nodes. Graphplan use weak form failure-driven learning calls mem-

c 2000 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiK AMBHAMPATI

oization. shall see paper, Graphplans brand learning quite limited
explicit analysis reasons failure. Instead explanation failure search node
taken constraints search node. explained (Kambhampati, 1998),
eliminates opportunities dependency directed backtracking, also adversely effects
utility stored memos.
Adding full-fledged EBL DDB capabilities effect gives Graphplan ability
intelligent backtracking, ability learn generalized memos likely
applicable situations. Technically, involves generalizing conflict-directed backjumping
(Prosser, 1993), specialized version EBL/DDB strategy applicable binary CSP problems1
work context dynamic constraint satisfaction problems (as discussed (Kambhampati, 1998)). Empirically, EBL/DDB capabilities improve Graphplans search efficiency quite
dramaticallygiving rise 1000x speedups, allowing Graphplan easily solve several
problems hither-to hard unsolvable. particular, report experiments
bench-mark problems described Kautz Selman (1996), well 4 domains,
used recent AIPS planning competition (McDermott, 1998).
discuss utility issues involved storing using memos, point Graphplan
memoization strategy seen conservative form CSP no-good learning.
conservative strategy keeps storage retrieval costs no-goods usual bane no-good
learning strategiesunder control, also loses learning opportunities. present use
sticky values way recouping losses. Empirical studies show sticky
values lead 2-4x improvement EBL.
addition EBL DDB, also investigated utility forward checking dynamic
variable ordering, isolation concert EBL DDB. empirical studies show
capabilities typically lead additional 2-4x speedup EBL/DDB,
competitive EBL/DDB.
Finally, consider utility EBL/DDB strategies context random-restart search
strategies (Gomes, Selman, & Kautz, 1998) recently shown good solving hard combinatorial problems, including planning problems. results show EBL/DDB
strategies retain advantages even context random-restart strategies. Specifically,
EBL/DDB strategies enable Graphplan use backtrack limits effectivelyallowing
achieve higher solvability rates, optimal plans significantly smaller backtrack
restart limits.
paper organized follows. next section, provide background viewing
Graphplans backward search (dynamic) constraint satisfaction problem, review
opportunities view presents. Section 3, discuss inefficiencies backtracking
learning methods used normal Graphplan motivate need EBL/DDB capabilities.
Section 4 describes EBL DDB added Graphplan. Section 5 presents empirical studies
demonstrating usefulness augmentations. Section 7 investigates utility forward
checking dynamic variable ordering strategies Graphplan. Section 8 investigates utility
EBL/DDB strategies context random-restart search. Section 9 discusses related work
Section 10 presents conclusions directions work.
1. Binary CSP problems problems initial constraints pairs variables.

2

fiP LANNING G RAPH

Action list
Level k-1

Proposition list
Level k-1

Action list
Level k

Proposition List
Level k

G1 ; ; G4 ; P1 P6
Domains: G1 : fA1 g; G2 : fA2 gG3 : fA3 gG4 : fA4 g
P1 : fA5 gP2 : fA6 ; A11 gP3 : fA7 gP4 : fA8 ; A9 g
P5 : fA10 gP6 : fA10 g
Constraints (normal):P1 = A5 ) P4 6= A9
P2 = A6 ) P4 6= A8
P2 = A11 ) P3 6= A7
Constraints (Activity): G1 = A1 ) ActivefP1 ; P2 ; P3 g
G2 = A2 ) ActivefP4 g
G3 = A3 ) ActivefP5 g
G4 = A4 ) ActivefP1 ; P6 g
Init State: ActivefG1 ; G2 ; G3 ; G4 g

P1
A6

A1

X
A7
A8

P3

11

A2

G2
G3

P4
P5

10

G1

P2

A9

X

CSP

Variables:

A5

X



A3

G4

P6
A4

(a) Planning Graph

(b) DCSP

Figure 1: planning graph DCSP corresponding

2. Review Graphplan Algorithm Connections DCSP
2.1 Review Graphplan Algorithm
Graphplan algorithm (Blum & Furst, 1997) seen disjunctive version forward
state space planners (Kambhampati et al., 1997; Kambhampati, 1997). consists two interleaved
phases forward phase, data structure called planning-graph incrementally extended,
backward phase planning-graph searched extract valid plan. planninggraph consists two alternating structures, called proposition lists action lists. Figure 1 shows
partial planning-graph structure. start initial state zeroth level proposition list.
Given k level planning graph, extension structure level k + 1 involves introducing
actions whose preconditions present k th level proposition list. addition actions
given domain model, consider set dummy persist actions, one condition
k th level proposition list. persist-C action C precondition C effect.
actions introduced, proposition list level k + 1 constructed union
effects introduced actions. Planning-graph maintains dependency links
actions level k + 1 preconditions level k proposition list effects level k + 1
proposition list. planning-graph construction also involves computation propagation
mutex constraints. propagation starts level 1, actions statically interfering
(i.e., preconditions effects inconsistent) labeled mutex. Mutexes
propagated level forward using two simple rules: two propositions level k
marked mutex actions level k support one proposition mutex actions
support second proposition. Two actions level k + 1 mutex statically interfering
one propositions (preconditions) supporting first action mutually exclusive
one propositions supporting second action.
search phase k level planning-graph involves checking see sub-graph
planning-graph corresponds valid solution problem. involves starting
propositions corresponding goals level k (if goals present,
present pair marked mutually exclusive, search abandoned right away,
planning-grap grown another level). goal propositions, select action
3

fiK AMBHAMPATI

G1 ; ; G4 ; P1 P6
G1 : fA1 g; G2 : fA2 gG3 : fA3 gG4 : fA4 g
P1 : fA5 gP2 : fA6 ; A11 gP3 : fA7 gP4 : fA8 ; A9 g
P5 : fA10 gP6 : fA10 g
Constraints (normal):P1 = A5 ) P4 6= A9
P2 = A6 ) P4 6= A8
P2 = A11 ) P3 6= A7
Constraints (Activity): G1 = A1 ) ActivefP1 ; P2 ; P3 g
G2 = A2 ) ActivefP4 g
G3 = A3 ) ActivefP5 g
G4 = A4 ) ActivefP1 ; P6 g
Init State: ActivefG1 ; G2 ; G3 ; G4 g

G1 ; ; G4 ; P1 P6
G1 : fA1 ; ?g; G2 : fA2 ; ?gG3 : fA3 ; ?gG4 : fA4 ; ?g
P1 : fA5 ; ?gP2 : fA6 ; A11 ; ?gP3 : fA7 ; ?gP4 : fA8 ; A9 ; ?g
P5 : fA10 ; ?gP6 : fA10 ; ?g
Constraints (normal):P1 = A5 ) P4 6= A9
P2 = A6 ) P4 6= A8
P2 = A11 ) P3 6= A7
Constraints (Activity): G1 = A1 ) P1 6=? ^P2 6=? ^P3 6=?
G2 = A2 ) P4 6=?
G3 = A3 ) P5 6=?
G4 = A4 ) P1 6=? ^P6 6=?
Init State: G1 6=? ^G2 6=? ^G3 6=? ^G4 6=?

Variables:

Variables:

Domains:

Domains:

(a) DCSP

(b) CSP

Figure 2: Compiling DCSP standard CSP
level k action list supports it, two actions selected supporting two
different goals mutually exclusive (if are, backtrack try change selection
actions). point, recursively call search process k , 1 level planning-graph,
preconditions actions selected level k goals k , 1 level search.
search succeeds reach level 0 (corresponding initial state).
Consider (partial) planning graph shown Figure 3 Graphplan may generated
search solution. G1 G4 top level goals want satisfy,
A1 A4 actions support goals planning graph. specific actionprecondition dependencies shown straight line connections. actions A5 A11
left-most level support conditions P1 P6 planning-graph. Notice conditions P2
P4 level k , 1 supported two actions each. x-marked connections
actions A5 ; A9 , A6 ; A8 A7 ; A11 denote action pairs mutually exclusive. (Notice
given mutually exclusive relations alone, Graphplan cannot derive mutual exclusion
relations proposition level P1 P6 .)
2.2 Connections Graphplan CSP
Graphplan algorithm described bears little resemblance previous classical planning
algorithms. (Kambhampati et al., 1997), explicate number important links
Graphplan algorithm previous work planning constraint satisfaction communities.
Specifically, show planning-graph length k thought (to first approximation)
disjunctive (unioned) version k -level search tree generated forward state-space refinement,
action lists corresponding union actions appearing k th level, proposition
lists corresponding union states appearing k th level. mutex constraints
seen providing (partial) information subsets proposition list actually
correspond legal states corresponding forward state-space search. process searching
planning graph extract valid plan seen dynamic constraint satisfaction
problem. Since last link relevant work described paper, review
below.
dynamic constraint satisfaction problem (DCSP) (Mittal & Falkenhainer, 1990) generalization constraint satisfaction problem (Tsang, 1993), specified set variables,
4

fiP LANNING G RAPH



CSP

activity flags variables, domains variables, constraints legal variablevalue combinations. DCSP, initially subset variables active, objective
find assignments active variables consistent constraints among variables. addition, DCSP specification also contains set activity constraints. activity
constraint form: variable x takes value vx , variables y; z; w::: become
active.
correspondence planning-graph DCSP clear. Specifically, propositions various levels correspond DCSP variables2 , actions supporting correspond variable domains. three types constraints: action mutex
constraints, fact (proposition) mutex constraints subgoal activation constraints.
Since actions modeled values rather variables, action mutex constraints
modeled indirectly constraints propositions. two actions a1 a2 marked mutex
planning graph, every pair propositions p11 p12 a1
one possible supporting actions p11 a2 one possible supporting actions
p12 , constraint:

: (p11 = a1 ^ p12 = a2 )
Fact mutex constraints modeled constraints prohibit simultaneous activation
two facts. Specifically, two propositions p11 p12 marked mutex planning graph,
constraint:

: (Active(p11 ) ^ Active(p12 ))

Subgoal activation constraints implicitly specified action preconditions: supporting
active proposition p action makes propositions previous level corresponding
preconditions active.
Finally, propositions corresponding goals problem active beginning. Figure 1 shows dynamic constraint satisfaction problem corresponding example
planning-graph discussed.
2.2.1 OLVING



DCSP

two ways solving DCSP problem. first, direct, approach (Mittal & Falkenhainer,
1990) involves starting initially active variables, finding satisfying assignment
them. assignment may activate new variables, newly activated variables
assigned second epoch. process continues reach epoch new
variables activated (which implies success), unable give satisfying assignment
activated variables given epoch. latter case, backtrack previous epoch
try find alternative satisfying assignment variables (backtracking further,
assignment possible). backward search process used Graphplan algorithm (Blum &
Furst, 1997) seen solving DCSP corresponding planning graph direct
fashion.
second approach solving DCSP first compile standard CSP, use
standard CSP algorithms. compilation process quite straightforward illustrated
2. Note literal appearing different levels corresponds different DCSP variables. Thus, strictly speaking, literal p proposition list level converted DCSP variable pi . keep matters simple,
example Figure 1 contains syntactically different literals different levels graph.

5

fiK AMBHAMPATI

Figure 2. main idea introduce new null value (denoted ?) domains
DCSP variables. model inactive DCSP variable CSP variable
takes value ?. constraint particular variable P active modeled P 6=?. Thus,
activity constraint form

G1 = A1 ) ActivefP1 ; P2 ; P3 g
compiled standard CSP constraint

G1 = A1 ) P1 6=? ^P2 6=? ^P3 6=?
worth noting activation constraints concerned ensuring
propositions preconditions selected action take non-? values. thus allow
possibility propositions become active (take non-? values) even though
strictly supporting preconditions selected action. Although lead inoptimal
plans, mutex constraints ensure unsound plans produced (Kautz & Selman,
1999). avoid unnecessary activation variables, need add constraints effect
unless one actions needing variable precondition selected value
variable earlier (higher) level, variable must ? value. constraints
typically going high arity (as wind mentioning large number variables
previous level), may thus harder handle search.
Finally, mutex constraint two propositions

: (Active(p11 ) ^ Active(p12 ))
compiled

: (p11 6=? ^p12 6=?) :

Since action mutex constraints already standard CSP form, compilation,
activity constraints converted standard constraints thus entire CSP
standard CSP. solved standard CSP search techniques (Tsang, 1993).3
direct method advantage closely mirrors Graphplans planning graph
structure backward search. this, possible implement approach
plan graph structure without explicitly representing constraints. Furthermore, discuss Section 6, distinct advantages adopting DCSP view implementing
EBL/DDB Graphplan. compilation CSP requires plan graph first converted
extensional CSP. however allow use standard algorithms, well supports nondirectional search (in one follow epoch-by-epoch approach assigning
variables).4 Since main aim illustrate utility CSP search techniques context
Graphplan algorithm, adopt direct solution method DCSP. study
tradeoffs offered technique compiling planning graph CSP, reader referred
(Do & Kambhampati, 2000).
3. also possible compile CSP problem propositional satisfiability problem (i.e., CSP problem
boolean variables). accomplished compiling every CSP variable P domain fv1 ; v2 ; ; vn g
n boolean variables form P-is-v1 P-is-vn . Every constraint form P
vj ^ ) compiled
P-is-vj ^ ) . essentially done BLACKBOX system (Kautz & Selman, 1999).
4. Compilation CSP strict requirement non-directional search. (Zimmerman & Kambhampati,
1999), describe technique allows backward search Graphplan non-directional, see discussion
Section 10.

=

6

fiP LANNING G RAPH



CSP

2.3 Interpreting Mutex Propagation CSP View
Viewing planning graph constraint satisfaction problem helps put mutex propagation
clearer perspective (see (Kambhampati et al., 1997)). Specifically, way Graphplan constructs planning graph, winds enforcing partial directed 1-consistency partial directed
2-consistency (Tsang, 1993). partial 1-consistency ensured graph building procedure
introduces action level l actions preconditions present proposition
list level l , 1 mutually exclusive. Partial 2-consistency ensured mutual
exclusion propagation procedure.
particular, Graphplan planning graph construction implicitly derives no-good5 constraints form:

:Active(Pmi ) (or Pmi 6=?)

simply removed (or put into) level i, mutex
case Pm
constraints form:




: Active(Pmi ) ^ Active(Pni )

Pmi 6=? ^Pni 6=?)

(

P marked mutually exclusive.
case Pm
n
procedures directed use reachability analysis enforcing consistency, partial enforce either full 1-consistency full 2-consistency.
Lack full 1-consistency verified fact appearance goal level k
necessarily mean goal actually achievable level k (i.e., solution CSP
assigns non- ? value goal level). Similarly, lack full 2-consistency verified fact appearance pair goals level k imply plan
achieving goals level.
another, somewhat less obvious, way consistency enforcement used
Graphplan partial (and conservative)it concentrates whether single goal variable
pair goal variables simultaneously non- ? values (be active) solution. may
goal non- ? value, non- ? values feasible. Similarly, may
pair goals achievable, necessarily achievable every possible pair actions
respective domains.
interpretation mutex propagation procedure Graphplan brings fore several possible
extensions worth considering Graphplan:
1. Explore utility directional consistency enforcement procedures based solely
reachability analysis. Kambhampati et. al. (1997) argue extending analysis using
relevance information, et. al. (2000) provide empirical analysis effectiveness
consistency enforcement relevance information.
2. Explore utility enforcing higher level consistency. pointed (Kambhampati
et al., 1997; Kambhampati, 1998), memoization strategies seen failure-driven
procedures incrementally enforce partial higher level consistency.
5. Normally, CSP literature, no-good seen compound assignment part feasible
6 ? ^Pni 6 ? correspond conjunction nogoods
solution. view, mutex constraints form Pm


Pni .
form Pm au ^ Pn av au av values domains Pm

=

=

=

7

=

fiK AMBHAMPATI

3. Consider relaxing focus non- ? values alone, allow derivation no-goods
form

Pmi = au ^ Pni = av

guaranteed winning idea number derived no-goods increase
quite dramatically. particular, assuming l levels planning graph,
average goals per level, average actions supporting goal, maximum
number Graphplan style pair-wise mutexes (l m2 ) 2-size no-goods
type discussed (l (m (d + 1))2 ). consider similar issue context
Graphplan memoization strategy Section 6.

3. Inefficiencies Graphplans Backward Search
motivate need EBL DDB, shall first review details Graphplans backward
search, pinpoint inefficiencies. shall base discussion example planning
graph Figure 3 (which reproduced convenience Figure 1). Assuming G1 G4
top level goals problem interested solving, start level k , select
actions support goals G1 G4 . keep matters simple, shall assume search
assigns conditions (variables) level top bottom (i.e., G1 first, G2
on). Further, choice actions (values) support condition,
consider top actions first. Since one choice conditions level,
none actions mutually exclusive other, select actions A1 ; A2 ; A3
A4 supporting conditions level k . make sure preconditions
A1 ; A2 ; A3 ; A4 satisfied level k , 1. thus subgoal conditions P1 P6 level
k , 1, recursively start action selection them. select action A5 P1 . P2 ,
two supporting actions, using convention, select A6 first. P3 , A7
choice. get selecting support P4 , choice. Suppose
select A8 first. find choice infeasible A8 mutually exclusive A6
already chosen. So, backtrack choose A9 , find mutually exclusive
previously selected action, A5 . stymied choices P4 . So,
backtrack undo choices previous conditions. Graphplan uses chronological
backtracking approach, whereby, first tries see P3 re-assigned, P2 on.
Notice first indication inefficiency failure assign P4 nothing
assignment P3 , yet, chronological backtracking try re-assign P3 vain hope
averting failure. lead large amount wasted effort case P3
indeed choices.
turns out, find P3 choices backtrack it. P2 another
choice A11 . try continue search forward value P2 , hit impasse P3
since value P3 , A7 mutex A11 . point, backtrack P3 , continue
backtracking P2 P1 , remaining choices. backtrack
P1 , need go back level k try re-assign goals level. done,
Graphplan search algorithm makes memo signifying fact failed satisfy goals
P1 P6 level, hope search ever subgoals set goals
future, scuttle right away help remembered memo. second
indication inefficiency remembering subgoals P1 P6 even though see
problem lies trying assign P1 ; P2 ; P3 P4 simultaneously, nothing
8

fiP LANNING G RAPH

Action list
Level k-1

Proposition list
Level k-1



CSP

Action list
Level k

Proposition List
Level k

A5
P1
A6

X

A1

X
A7
A8

P2
A2

P3

G3
A3

P5
10

G2

P4

A9

X

G1

G4

P6
A4

11

Figure 3: running example used illustrate EBL/DDB Graphplan
subgoals. remember fP1 ; P2 ; P3 ; P4 g memo fP1 P6 g,
remembered memo would general, would much better chance useful
future.
memo stored, backtracking continues level k chronological
fashion, trying reassign G4 ; G3 ; G2 G1 order. see third indication inefficiency caused chronological backtracking G3 really role failure encountered
assigning P3 P4 since spawns condition P5 level k , 1. Yet, backtracking
scheme Graphplan considers reassigning G3 . somewhat subtle point reassigning
G4 going avert failure either. Although G4 requires P1 one conditions taking
part failure, P1 also required G1 unless G1 gets reassigned, considering
assignments G4 going avert failure.
example, continue backtracking G2 G1 too, since alternative supports, finally memoize fG1 ; G2 ; G3 ; G4 g level. point backward search
fails, Graphplan extends planning graph another level re-initiating backward
search extended graph.

4. Improving Backward Search EBL DDB
describe Graphplans backward search augmented full fledged EBL
DDB capabilities eliminate inefficiencies pointed previous section. Informally,
EBL/DDB strategies involve explanation failures leaf nodes, regression propagation
leaf node failure explanations compute interior node failure explanations, along lines described (Kambhampati, 1998). specific extensions propose backward search

9

fiK AMBHAMPATI

essentially seen adapting conflict-directed backjumping strategy (Prosser, 1993), generalizing work dynamic constraint satisfaction problems.
algorithm shown pseudo-code form Figure 4. contains two mutually recursive
procedures find-plan assign-goals. former called level
planning-graph. calls assign-goals assign values required conditions
level. assign-goals picks condition, selects value it, recursively calls
remaining conditions. invoked empty set conditions assigned, calls
find-plan initiate search next (previous) level.
order illustrate EBL/DDB capabilities added, lets retrace previous example,
pick point assign P4 level k , 1, assigned P1 ; P2
P3 . try assign value A8 P4, violate mutex constraint A6 A8.
explanation failure search node set constraints False derived.
complete explanation failure thus stated as:

P2 = A6 ^ P4 = A8 ^ (P2 = A6 ) P4 6= A8 )
this, part P2 = A6 ) P4 6= A8 stripped explanation since mutual
exclusion relation hold long solving particular problem particular
actions. Further, take cue conflict directed backjumping algorithm (Prosser,
1993), represent remaining explanation compactly terms conflict sets. Specifically,
whenever search reaches condition c (and find assignment it), conflict
set initialized fcg. Whenever one possible assignments c inconsistent (mutually
exclusive) current assignment previous variable c0 , add c0 conflict set c.
current example, start fP4 g conflict set P4 , expand adding P2
find A8 cannot assigned P4 choice A6 support P2 . Informally,
conflict set representation seen incrementally maintained (partial) explanation
failure, indicating conflict current value P2 one possible
values P4 (Kambhampati, 1998).
consider second possible value P4 , viz., A9 , find mutually exclusive
A5 currently supporting P1 . Following practice, add P1 conflict set
P4 . point, choices P4 , backtrack P4 , passing
conflict set P4 , viz., fP1 ; P2 ; P4 g reason failure. essence, conflict set
shorthand notation following complete failure explanation (Kambhampati, 1998):6
[(

P4 = A8 ) _ (P4 = A9 )] ^ (P1 = A5 ) P4 6= A9 ) ^ (P2 = A6 ) P4 6= A8 ) ^ P1 = A5 ^ P2 = A6

worth noting point P4 revisited future different assignments
preceding variables, conflict set re-initialized fP4 g considering assignments it.
first advantage conflict set allows transparent way supporting dependency directed backtracking (Kambhampati, 1998). current example, failed assign
P4 , start backtracking. need chronological fashion however.
6. strip first (disjunctive) clause since present graph structure, next two implicative clauses
since part mutual exclusion relations change problem. conflict set representation keeps condition (variable) names last two clauses denoting, essence, current
assignments variables P1 P2 causing failure assign P4 .

10

fiP LANNING G RAPH



CSP

Find-Plan(G:goals, pg : plan graph, k : level)
k = 0, Return empty subplan P success.
memo G,
Fail, return conflict set
Call Assign-goals(G; pg; k; ;).
Assign-goals fails returns conflict set ,
Store memo
Regress actions selected level k + 1 get R
Fail return R conflict set
Assign-goals succeeds, returns k -level subplan P ,
Return P success
Assign-goals(G:goals, pg : plan graph, k : level, A: actions)
G = ;
Let U union preconditions actions
Call Find-plan(U; pg; k , 1)
Find-plan fails returns conflict set R,
Fail return R
Find-plan succeeds returns subplan P length k , 1
Succeed return k length subplan P
Else ;;(G 6= ;)
Select goal g 2 G
Let cs
fgg, Ag set actions level k pg support g
L1:
Ag = ;, Fail return cs conflict set
Ag ,
Else, pick action 2 Ag , set Ag
mutually exclusive action b 2
Let l goal b selected support
cs [ flg
Set cs
Goto L1
Else (a mutually exclusive action A)
Call Assign-goals(G , fg g; pg; k; [ fag)
call fails returns conflict set C
g 2 C
Set cs = cs [ C ;conflict set absorption
Goto L1
Else ;(g 62 C )
Fail return C conflict set
;dependency directed backjumping

Figure 4: pseudo-code description Graphplan backward search enhanced EBL/DDB capabilities. backward search level k planning-graph pg initiated call
Find-Plan(G; pg; k), G set top level goals problem.
11

fiK AMBHAMPATI

Instead, jump back recent variable (condition) taking part conflict set P4
case P2 . so, avoiding considering alternatives P3 , thus avoiding
one inefficiencies standard backward search. easy see backjumping
sound since P3 causing failure P4 thus re-assigning wont avert failure.
Continuing along, whenever search backtracks condition c, backtrack conflict
absorbed current conflict set c. example, absorb fP1 ; P2 ; P4 g conflict
set P2 , currently fP2 g (making fP1 ; P2 ; P4 g new conflict set P2 ). assign
A11 , remaining value, P2 . Next try assign P3 find value A7
mutex A11 . Thus, set conflict set P3 fP3 ; P2 g backtrack conflict
set. backtracking reaches P2 , conflict set absorbed current conflict set
P2 (as described earlier), giving rise fP1 ; P2 ; P3 ; P4 g current combined failure reason
P2 . step illustrates conflict set condition incrementally expanded collect
reasons failure various possible values condition.
point, P2 choices, backtrack P2 current conflict set,
fP1 ; P2 ; P3 ; P4 g. P1 , first absorb conflict set fP1 ; P2 ; P3 ; P4 g P1 current conflict
set, re-initiate backtracking since P1 choices.
Now, reached end current level (k , 1). backtracking P1 must
involve undoing assignments conditions k th level. however,
two steps: memoization regression.
4.1 Memoization
backtrack first assigned variable given level, store conflict set
variable memo level. store conflict set fP1 ; P2 ; P3 ; P4 g P1 memo
level. Notice memo store shorter (and thus general) one stored
normal Graphplan, include P5 P6 , anything
failure7
4.2 Regression
backtrack level k , 1 level k , need convert conflict set (the first
assigned variable in) level k , 1 refers conditions level k . conversion
process involves regressing conflict set actions selected k th level (Kambhampati,
1998). essence, regression step computes (smallest) set conditions (variables)
kth level whose supporting actions spawned (activated, DCSP terms) conditions (variables)
conflict set level k , 1. current case, conflict set fP1 ; P2 ; P3 ; P4 g.
see P2 , P3 required condition G1 level k , condition P4 required
condition G2 .
case condition P1 , G1 G4 responsible it, supporting
actions needed P1 . cases two heuristics computing regression: (1) Prefer
choices help conflict set regress smaller set conditions (2) still choice
multiple conditions level k , pick one assigned earlier. motivation first rule keep failure explanations compact (and thus general) possible,
7. current example, memo includes conditions P4 (which farthest gone
level), even always necessary. verify P3 would memo set A11
one supporters P2 .

12

fiP LANNING G RAPH



CSP

motivation second rule support deeper dependency directed backtracking.
important note heuristics aimed improving performance EBL/DDB
affect soundness completeness approach.
current example, first rules applies, since P1 already required G1 ,
also requiring P2 P3 . Even case (i.e., G1 required P1 ), still would
selected G1 G4 regression P1 , since G1 assigned earlier search.
result regressing fP1 ; P2 ; P3 ; P4 g actions k th level thus fG1 ; G2 g. start
backtracking level k conflict set. jump back G2 right away, since
recent variable named conflict set. avoids inefficiency re-considering
choices G3 G4 , done normal backward search. G2 , backtrack conflict set
absorbed, backtracking continues since choices. procedure
repeated G1 . point, end leveland memoize fG1 ; G2 g
memo level k . Since levels backtrack to, Graphplan called
extend planning-graph one level.
Notice memos based EBL analysis capture failures may require significant
amount search rediscover. example, able discover fG1 ; G2 g failing
goal set despite fact mutex relations choices goals G1
G2 .
4.3 Using Memos
end section, couple observations regarding use stored memos.
standard Graphplan, memos level stored level-specific hash table. Whenever
backward search reaches level k set conditions satisfied, consults hash table
see exact set conditions stored memo. Search terminated exact hit
occurs. Since EBL analysis allows us store compact memos, likely complete goal
set level k going exactly match stored memo. likely stored
memo subset goal set level k (which sufficient declare goal set failure).
words, memo checking routine Graphplan needs modified checks
see subset current goal set stored memo. naive way
involves enumerating subsets current goal set checking
hash table, turns costly. One needs efficient data structures, setenumeration trees (Rymon, 1992). Indeed, Koehler co-workers (Koehler, Nebel, Hoffman,
& Dimopoulos, 1997) developed data structure called UB-Trees storing memos.
UB-Tree structures seen specialized version set-enumeration trees,
efficiently check subset current goal set stored memo.
second observation regarding memos often serve failure explanation
themselves. Suppose level k , find goal set level subsumes
stored memo . use failure explanation level, regress
back previous level. process provide us valuable opportunities
back jumping levels k . also allows us learn new compact memos levels. Note
none would possible normal memos stored Graphplan,
way memo declare goal set level k failing memo exactly equal goal
set. case regression get us goals level k + 1, buy us
backjumping learning power (Kambhampati, 1998).

13

fiK AMBHAMPATI

5. Empirical Evaluation Effectiveness EBL/DDB
seen way EBL DDB capabilities added backward search maintaining updating conflict-sets. also noted EBL DDB capabilities avoid variety
inefficiencies standard Graphplan backward search. augmentations soundness completeness preserving follows corresponding properties conflict-directed
backjumping (Kambhampati, 1998). remaining (million-dollar) question whether capabilities make difference practice. present set empirical results answer
question.
implemented EBL/DDB approach described previous section top Graphplan
implementation Lisp.8 changes needed code add EBL/DDB capability relatively minor two functions needed non-trivial changes9 . also added UB-Tree subset
memo checking code described (Koehler et al., 1997). ran several comparative experiments
benchmark problems (Kautz & Selman, 1996), well four domains.
specific domains included blocks world, rocket world, logistics domain, gripper domain, ferry
domain, traveling salesperson domain, towers hanoi. domains, including
blocks world, logistics domain gripper domain used recent AI Planning
Systems competition. specifications problems well domains publicly available.
Table 1 shows statistics times taken number backtracks made normal Graphplan, Graphplan EBL/DDB capabilities.10
5.1 Run-Time Improvement
first thing note EBL/DDB techniques offer quite dramatic speedups 1.6x
blocks world way 120x logistics domain (the Att-log-a problem unsolvable
normal Graphplan 40 hours cpu time!). also note number backtracks
reduces significantly consistently EBL/DDB. Given lengh runs, time
Lisp spends garbage collection becomes important issue. thus report cumulative time
(including cpu time garbage collection time) Graphplan EBL/DDB, separate
cpu time cumulative time plain Graphplan (in cases total time spent
large enough garbage collection time significant fraction). Specifically, two
entrys column corresponding total time normal Graphplan. first entry
cpu time spent, second entry parenthesis cumulative time (cpu time garbage
collection time) spent. speedup computed respect cumulative time Graphplan
EBL/DDB cpu time plain Graphplan. 11 reported speedups thus seen
conservative estimates.
8. original lisp implementation Graphplan done Mark Peot. implementation subsequently
improved David Smith.
9. Assign-goals find-plan
10. earlier versions paper, including paper presented IJCAI (Kambhampati, 1999) reported
experiments Sun SPARC Ultra 1 running Allegro Common Lisp 4.3. Linux machine run-time statistics
seem approximately 2.7x faster Sparc machine.
11. interesting note percentage time spent garbage collection highly problem dependent.
example, case Att-log-a, 30 minutes 41 hours (or 1% cumulative time) spent
garbage collection, case Tower-6, 3.1 hours 4.8 hours (or 65% cumulative
time) spent garbage collection!

14

fiProblem

Speedup
1.7x
1.8x
24x
17x
>1215x
11x
90x
>10x
42x
>40x
50x
37x
>25x
90x
>58x

Table 1: Empirical performance EBL/DDB. Unless otherwise noted, times cpu minutes Pentium-III 500 MHZ machine
256meg RA running Linux allegro common lisp 5, compiled speed. Tt total time, Mt time used checking
memos Btks number backtracks done search. times Graphplan EBL/DDB include cpu
garbage collection time, cpu time separated total time case normal Graphplan. numbers
parentheses next problem names list number time steps number actions respectively solution. AvLn
AvFM denote average memo length average number failures detected per stored memo respectively.

CSP

AvFM
1.26
1.13
3.2
3.22
4.9
2.2
2.3
2.4
5
-



Normal Graphplan
Tt. Mt.
# Btks AvLn
5.3 0.22
5181K
11.3
4.15 0.05
2823K 11.83
19.43 11.7
8128K
23.9
14.1
7.7 10434K
23.8
>40.5hr (>41hr)
32
1.1
.39
2802K
14.9
215(272)
17.8
>8.2hr(>16hr)
7.23 1.27 19070K
20.9
>1.7hr (>4.8hr)
22.3
22(29)
11 33357K
24.5
42(144)
24 53233K
25
>5hr(>18.4hr)
89(93) 56.7 68648K
13
>12hr (>14.5hr)
-

P LANNING G RAPH

15

Huge-Fact (18/18)
BW-Large-B (18/18)
Rocket-ext-a (7/36)
Rocket-ext-b (7/36)
Att-log-a(11/79)
Gripper-6 (11/17)
Gripper-8 (15/23)
Gripper-10(19/29)
Tower-5 (31/31)
Tower-6 (63/63)
Ferry-41 (27/27)
Ferry-5 (31/31)
Ferry-6(39/39)
Tsp-10 (10/10)
Tsp-12(12/12)

Graphplan EBL/DDB
Tt
Mt
# Btks AvLn AvFM
3.08 0.28
2004K
9.52
2.52
2.27 0.11
798K 10.15
3.32
.8
.34
764K
8.5
82
.8
.43
569K
7.5
101
1.97
.89
2186K
8.21 46.18
0.1 0.03
201K
6.9
6.2
2.4
.93
4426K
9
7.64
47.9 18.2 61373K 11.05
8.3
.17 0.02
277K
6.7
2.7
2.53 0.22
4098K
7.9
2.8
.44 0.13
723K
7.9
2.54
1.13
.41
1993K
8.8
2.53
11.62
5.3 18318K
10.9
2.6
.99 0.23
2232K
6.9
12
12.4 2.65 21482K
7.9
15.2

fiK AMBHAMPATI

5.2 Reduction Memo Length
results also highlight fact speedups offered EBL/DDB problem/domain
dependent quite meager blocks world problems, quite dramatic many
domains including rocket world, logistics, ferry, gripper, TSP Hanoi domains. statistics
memos, shown Table 1 shed light reasons variation. particular interest
average length stored memos (given columns labeled AvLn). general,
expect EBL analysis reduces length stored memos, conditions part
failure explanation stored memo. However, advantage depends
likelihood small subset goals given level actually taking part failure.
likelihood turn depends amount inter-dependencies goals given
level. table, note average length reduces quite dramatically rocket world
logistics12 , reduction much less pronounced blocks world. variation
traced back larger degree inter-dependency goals given level blocks
world problems.
reduction average memo length correlated perfectly speedups offered EBL
corresponding problems. Let put perspective. fact average length
memos Rocket-ext-a problem 8.5 EBL 24 without
EBL, shows essence
,
normal Graphplan re-discovering 8-sized failure embedded 24
8 possible ways worst
case 24 sized goal set storing new memo time (incurring increased backtracking
matching costs)! thus wonder normal Graphplan performs badly compared
Graphplan EBL/DDB.
5.3 Utility Stored Memos
statistics Table 1 also show increased utility memos stored Graphplan
EBL/DDB. Since EBL/DDB store general (smaller) memos normal Graphplan,
should, theory, generate fewer memos use often. columns labeled AvFM
give ratio number failures discovered use memos number memos
generated first place. seen measure average utility stored
memos. note utility consistently higher EBL/DDB. example, Rocketext-b, see average EBL/DDB generated memo used discover failures 101
times, number 3.2 memos generated normal Graphplan.13
5.4 Relative Utility EBL vs. DDB
statistics Table 1, see even though EBL make significant improvements
run-time, significant fraction run time EBL (as well normal Graphplan) spent
memo checking. raises possibility overall savings mostly DDB part
EBL part (i.e, part involving storing checking memos) fact net drain
(Kambhampati, Katukam, & Qu, 1997). see true, ran problems EBL (i.e.,
memo-checking) disabled. DDB capability well standard Graphplan memoization
12. case Att-log-a, took memo statistics interrupting search 6 hours
13. statistics Att-log-aseem suggest memo usage bad normal Graphplan. However,
noted Att-log-a solved normal Graphplan begin with. improved usage factor may due
mostly fact search went considerably longer time, giving Graphplan opportunity use
memos.

16

fiP LANNING G RAPH

Problem
Att-log-a
Tower-6
Rocket-ext-a
Gripper-8
TSP-10
Huge-Fct

EBL+DDB
Btks
Time
2186K 1.95
4098K 2.37
764K
.83
4426K 2.43
2238K
1.1
2004K 3.21



CSP

DDB
Btks
Time
115421K 235
97395K
121
3764K
17.18
5426K
4.71
4308K
2.3
2465K
3.83

Speedup
120x
51x
21x
1.94x
2.09x
1.19x

Table 2: Utility storing using EBL memos DDB
strategies left in.14 results shown Table 2, demonstrate ability store
smaller memos (as afforded EBL) quite helpfulgiving rise 120x speedup DDB alone
Att-log-a problem, 50x speedup Tower-6 problem. course, results also show
DDB important capability itself. Indeed, Att-log-aand tower-6 could even solved
standard Graphplan, DDB, problems become solvable. summary, results
show EBL DDB net positive utility.
5.5 Utility Memoization
Another minor, well-recognized, point brought statistics Table 1
memo checking sometimes significant fraction run-time standard Graphplan.
example, case Rocket-ext-a, standard Graphplan takes 19.4 minutes 11.7 minutes,
half time, spent memo checking (in hash tables)! raises possibility
disable memoization, perhaps well version EBL/DDB.
see case, ran problems memoization disabled. results show
general disabling memo-checking leads worsened performance. came across
cases disablement reduces overall run-time, run-time still much higher
get EBL/DDB. example, case Rocket-ext-a, disable memo
checking completely, Graphplan takes 16.5 minutes, lower 19.4 minutes taken
standard Graphplan, still much higher .8 minutes taken version Graphplan
EBL/DDB capabilities added. add DDB capability, still disabling memochecking, run time becomes 2.4 minutes, still 3 times higher afforded
EBL capability.
5.6 C vs. Lisp Question
Given existing implementations Graphplan done C many optimizations,
one nagging doubt whether dramatic speedups due EBL/DDB somehow dependent
moderately optimized Lisp implementation used experiments. Thankfully,
EBL/DDB techniques described paper also (re)implemented Maria Fox
Derek Long STAN system. STAN highly optimized implementation Graphplan
fared well recent AIPS planning competition. found EBL/DDB resulted
similar dramatic speedups system (Fox, 1998; Fox & Long, 1999). example,
14. also considered removing memoization completely, results even poorer.

17

fiK AMBHAMPATI

unable solve Att-log-a plain Graphplan, could solve easily EBL/DDB
added.
Finally, worth pointing even EBL/DDB capabilities, unable solve
larger problems AT&T benchmarks, bw-large-c Att-log-b. however
indictment EBL/DDB since knowledge planners solved
problems used either local search strategies GSAT, randomized re-start strategies,
used additional domain-specific knowledge pre-processing. least,
aware existing implementations Graphplan solve problems.

6. Utility Graphplan Memos
One important issue using EBL managing costs storage matching. Indeed, discussed (Kambhampati, 1998), naive implementations EBL/DDB known lose gains
made pruning power matching storage costs. Consequently, several techniques
invented reduce costs selective learning well selective forgetting.
interesting see costs prominent issue EBL/DDB Graphplan.
think mostly two characteristics Graphplan memoization strategy:
1. Graphplans memoization strategy provides compact representation no-goods,
well selective strategy remembering no-goods. Seen DCSP, remembers
subsets activated variables satisfying assignment. Seen CSP (c.f.
Figure 2), Graphplan remembers no-goods form

P1i 6=? ^P2i 6=? Pmi 6=?
(where superscripts correspond level planning graph proposition
belongs), normal EBL implementations learn no-goods form

P1i = a1 ^ P2j = a2 Pmk =
Suppose planning graph contains n propositions divided l levels, proposition
P level j actions supporting it. CSP compilation planning graph
n variables, + 1 values (the extra one ?). normal EBL implementation
CSP learn, worst case, (d + 2)n no-goods.15 contrast, Graphplan
n
remembers l 2 l memos16 dramatic reduction. reduction result two
factors:
(a) individual memo stored Graphplan corresponds exponentially large set
normal no-goods (the memo

P1i 6=? ^P2i 6=? Pmi 6=?
shorthand notation conjunction dm no-goods corresponding possible
i)
non- ? assignments P1i Pm

15. variable v may either present no-good, present one
possibilities n variables.
16. level, nl propositions either occurs memo occur

+1

18

+ 1 possible assignmentsgiving

fiP LANNING G RAPH



CSP

(b) Memos subsume no-goods made proposition variables planning graph level.
2. matching cost reduced fact considerably fewer no-goods ever
learned, fact Graphplan stores no-goods (memos) separately level,
consults memos stored level j , backwards search level j ,
discussion throws light so-called EBL utility problem
critical Graphplan EBL done normal CSPs.
6.1 Scenarios Memoization Conservative Avoid Rediscovery
Failures
discussion also raises possibility Graphplan (even EBL/DDB) memoization
conservative may losing useful learning opportunities
required syntactic form. Specifically, Graphplan learn memo form

P1i 6=? ^P2i 6=? Pmi 6=?;
must case dm possible assignments propositional variables must
no-good. Even one no-good, Graphplan avoids learning memo, thus
potentially repeating failing searches later time (although loss made extent
learning several memos lower level).
P
Consider example following scenario: set variables P1i Pm
n
level assigned backward search. Suppose search found legal partial asi , domain P contains k values fv1 vk g.
signment variables P1i Pm

,1

trying assign variables Pm Pni , suppose repeatedly fail backtrack variable
Pmi , re-assigning eventually settling value v7. point backtracking
higher level variables (P P ) re-assigning
occurs, time backtrack Pm

1
them. point, would useful remember no-goods effect none
going work backtracking repeated.
first 6 values Pm
no-goods take form:

Pmi = vj ^ Pmi +1 6=? ^Pmi +2 6=? Pni 6=?
tried found lead failure
j ranges 1 6, values Pm

assigning later variables. Unfortunately, no-goods syntactic form memos
memoization procedure cannot remember them. search thus forced rediscover
failures.
6.2 Sticky Values Partial Antidote
One way staying standard memoization, avoiding rediscovery failing search
paths, case example above, use sticky values heuristic (Frost
& Dechter, 1994; Kambhampati, 1998). involves remembering current value variable
skipping DDB, trying value first search comes back
variable. heuristic motivated fact skip variable DDB,
means variable current assignment contributed failure caused
19

fiK AMBHAMPATI

backtrackingso makes sense restore value upon re-visit. example above,
backtracked it, tries
heuristic remember v7 current value Pm
first value re-visited. variation technique re-arrange fold
domain variable values precede current value sent back
domain, values tried previously untried values found
fail. makes assumption values led failure likely again.
becomes fv7 ; v8 vk ; v1 ; v2 v6 g.
example above, heuristic folds domain Pm
Notice heuristics make sense employ DDB, otherwise never
skip variable backtracking.
implemented sticky value heuristics top EBL/DDB Graphplan. statistics
Table 3 show results experiments extension. seen, sticky values
approach able give 4.6x additional speedup EBL/DDB depending problem.
Further, folding heuristic dominates simple version terms number backtracks,
difference quite small terms run-time.

7. Forward Checking & Dynamic Variable Ordering
DDB EBL considered look-back techniques analyze failures looking
back past variables may played part failures. different class
techniques known look-forward techniques improving search. Prominent among
latter forward checking dynamic variable ordering. Supporting forward checking involves
filtering conflicting actions domains remaining goals, soon particular
goal assigned. example Figure 1, forward checking filter A9 domain P4
soon P1 assigned A5 . Dynamic variable ordering (DVO) involves selecting assignment
goal least number remaining establishers.17 DVO combined forward checking, variables ordered according live domain sizes (where live domain
comprised values domain yet pruned forward checking). experiments18 show techniques bring reasonable, albeit non-dramatic, improvements
Graphplans performance. Table 4 shows statistics benchmark problems, dynamic variable ordering alone, forward checking dynamic variable ordering. note
backtracks reduce 3.6x case dynamic variable ordering, 5x
case dynamic variable ordering forward checking, speedups time somewhat smaller,
ranging 1.1x 4.8x. Times perhaps improved efficient implementation forward checking.19 results also seem suggest amount optimization
going make dynamic variable ordering forward checking competitive EBL/DDB
problems. one thing, several problems, including Att-log-a, Tsp-12, Ferry-6 etc.
could solved even forward checking dynamic variable ordering. Second,
even problems could solved, reduction backtracks provided EBL/DDB far
greater provided FC/DVO strategies. example, Tsp-10, FC/DVO strategies
17. also experimented variation heuristic, known Brelaz heuristic (Gomes et al., 1998),
ties among variables sized live-domains broken picking variables take part
number constraints. variation however lead appreciable improvement performance.
18. study forward checking dynamic variable ordering initiated Dan Weld.
19. current implementation physically removes pruned values variable forward checking phase,
restores values backtracks. better implementations, including use in/out flags values well
use indexed arrays (c.f. (Bacchus & van Run, 1995))

20

fi21

EBL/DDB+Sticky
Btks
Speedup
372K
2.2x(2.05x)
172K
4.6x(3.3x)
56212K 1.29x(1.09x)
18151K .99x(1.01x)
20948K 1.26x(1.02x)
1144K
2x(1.91x)

EBL/DDB+Sticky+Fold
Time
Btks
Speedup
.33
347K
2.4x (2.2x)
.177
169K
4.5x(3.36x)
40.8 54975K 1.17x(1.12x)
11.87 18151K .97x(1.01x)
10.18 20948K 1.22x(1.02x)
.67
781K
2.9x(2.8x)

Table 3: Utility using sticky values along EBL/DDB.

CSP

Time
.37
.18
36.9
11.75
9.86
.95



Rocket-ext-a(7/36)
Rocket-ext-b(7/36)
Gripper-10(39/39)
Ferry-6
TSP-12(12/12)
Att-log-a(11/79)

Plain EBL/DDB
Time
Btks
.8
764K
.8
569K
47.95 61373K
11.62 18318K
12.44 21482K
1.95
2186K

P LANNING G RAPH

Problem

fiK AMBHAMPATI

Problem
Huge-fact (18/18)
BW-Large-B (18/18)
Rocket-ext-a (7/36)
Rocket-ext-b (7/36)
Att-log-a(11/79)
Gripper-6(11/17)
Tsp-10(10/10)
Tower-6(63/63)

GP
5.3(5181K)
4.15(2823K)
19.43(8128K)
14.1(10434K)
>10hr
1.1(2802K)
89(69974K)
>10hr

GP+DVO
2.26 (1411K)
3.14(1416K)
14.9(5252K)
7.91(4382K)
>10hr
.65(1107K)
78(37654K)
>10hr

Speedup
2.3x(3.6x)
1.3x(2x)
1.3x(1.5x)
1.8x(2.4x)
1.7x(2.5x)
1.14x(1.9x)
-

GP+DVO+FC
3.59 (1024K)
4.78(949K)
14.5(1877K)
6(1490K)
>10hr.
.73 (740K)
81(14697K)
>10hr.

Speedup
1.47x(5x)
.86(3x)
1.3x(4.3x)
2.4x(7x)
1.5x(3.7x)
1.09x(4.8x)

Table 4: Impact forward checking dynamic variable ordering routines Graphplan. Times
cpu minutes measured 500 MHZ Pentium-III running Linux Franz
Allegro Common Lisp 5. numbers parentheses next times number
backtracks. speedup columns report two factorsthe first speedup time,
second speedup terms number backtracks. FC DVO tend
reduce number backtracks, reduction always seem show
time savings.

reduce number backtracks 69974K 14697K, 4.8x improvement. However, pales
comparison 2232K backtracks (or 31x improvement) given EBL/DDB (see entry
Table 1). Notice results say variable ordering strategies make dramatic
difference Graphplans backward search (or DCSP compilation planning graph);
make claims utility FC DVO CSP compilation planning graph.
7.1 Complementing EBL/DDB Forward Checking Dynamic Variable Ordering
Although forward checking dynamic variable ordering approaches found particularly effective isolation Graphplans backward search, thought would interesting
revisit context Graphplan enhanced EBL/DDB strategies. Part original reasoning underlying expectation goal (variable) ordering significant
effect Graphplan performance based fact failing goal sets stored in-toto
memos (Blum & Furst, 1997, pp. 290). reason longer holds use EBL/DDB.
more, exists difference opinion whether forward checking
DDB fruitfully co-exist. results (Prosser, 1993) suggest domain-filteringsuch
one afforded forward checking, degrades intelligent backtracking. recent work
(Frost & Dechter, 1994; Bayardo & Schrag, 1997) however seems suggest however best CSP
algorithms capabilities.
adding plain DVO capability top EBL/DDB presents difficulties, adding forward
checking require changes algorithm Figure 4. difficulty arises
failure may occurred combined effect forward checking backtracking.
example, suppose four variables v1 v4 considered assignment
order. Suppose v3 domain f1; 2; 3g, v3 cannot 1 v1 a, cannot 2 v2
b. Suppose v4s domain contains d, constraint saying v4 cant
22

fiP LANNING G RAPH

Problem
Huge-fct
BW-Large-B
Rocket-ext-a
Rocket-ext-b
Att-log-a
Tower-6
TSP-10

EBL
Time(btks)
3.08(2004K)
2.27(798K)
.8(764K)
.8(569K)
1.97(2186K)
2.53(4098K)
.99(2232K)



CSP

EBL+DVO
Time(btks)
Speedup
1.51(745K)
2x(2.68x)
1.81(514K)
1.25x(1.6x)
.4(242K)
2x(3.2x)
.29(151K)
2.75x(3.76x)
2.59(1109K) .76x(1.97x)
3.78(3396K)
.67x(1.2x)
1.27(1793K) .77x(1.24x)

EBL+FC+DVO
Time(Btks)
Speedup
2.57(404K)
1.2x(5x)
2.98(333K) .76x(2.39x)
.73(273K)
1.09x(2.8x)
.72(195K)
1.1x(2.9x)
3.98(1134K) .5x(1.92x)
2.09(636K)
1.2x(6.4x)
1.34(828K)
.73x(2.7x)

Table 5: Effect complementing EBL/DDB dynamic variable ordering forward checking
strategies. speedup columns report two factorsthe first speedup time,
second speedup terms number backtracks. FC DVO tend
reduce number backtracks, reduction always seem show
time savings.

v1 v3 3. Suppose using forward checking, assigned v1 ; v2
values b. Forward checking prunes 1 2 v3 domain, leaving value 3.
point, try assign v4 fail. use algorithm Figure 4, conflict set v4
would fv4 ; v3 ; v1 g, constraint violated v1 = ^ v3 = 3 ^ v4 = d. However
sufficient since failure v4 may occurred forward checking stripped
value 2 domain v3 . problem handled pushing v1 v2 , variables
whose assignment stripped values v3 , v3 conflict set.20 Specifically, conflict
set every variable v initialized fv g begin with, whenever v loses value
forward checking respect assignment v 0 , v 0 added conflict set v . Whenever
future variable (such v4 ) conflicts v3 , add conflict set v3 (rather v3 )
conflict set v4 . Specifically line
Set cs = cs [ f l g
procedure Figure 4 replaced line
Set cs = cs [ Conflict-set(l)
incorporated changes implementation, support support forward checking, dynamic variable ordering well EBL Graphplan. Table 5 shows performance version experimental test suite. seen numbers, number
backtracks reduced 3.7x case EBL+DVO, 5x case
EBL+FC+DVO. cpu time improvements somewhat lower. got 2.7x speedup
20. Notice possible values stripped v3 domain may impact
failure assign v4 . example, perhaps another constraint says v4 cant v3 b,
case, strictly speaking, assignment v2 cannot really blamed failure v4 . leads
non-minimal explanations, reason expect strict minimization explanations pre-requisite
effectiveness EBL/DDB; see (Kambhampati, 1998)

23

fiK AMBHAMPATI

EBL+DVO, 1.2x speedup EBL+FC+DVO, several cases, cpu times increase FC DVO. again, attribute overheads forward checking (and
lesser extent, dynamic variable ordering). importantly, comparing results
Tables 4 5, see EBL/DDB capabilities able bring significant speedups
even Graphplan implementation using FC DVO.

8. EBL/DDB & Randomized Search
Recent years seen increased use randomized search strategies planning. include
purely local search strategies (Gerevini, 1999; Selman, Levesque, & Mitchell, 1992) well
hybrid strategies introduce random restart scheme top systematic search strategy
(Gomes et al., 1998). BLACKBOX planning system (Kautz & Selman, 1999) supports variety
random restart strategies top SAT compilation planning graph, empirical
studies show strategies can, probabilistically speaking, scale much better purely
systematic search strategies.
wanted investigate (and much) EBL & DDB techniques help Graphplan
even presence newer search strategies. EBL DDB techniques little
applicability purely local search strategies, could theory help random restart systematic
search strategies. Random restart strategies motivated attempt exploit heavytail distribution (Gomes et al., 1998) solution nodes search trees many problems.
Intuitively, problems non-trivial percentage easy find solutions
well hard find solutions, makes sense restart search find
spending much effort solution. restarting way, hope (probabilistically) hit
easier-to-find solutions.
implemented random-restart strategy top Graphplan making following simple
modifications backward search:
1. keep track number times backward search backtracks one level
plan graph previous level (a level closer goal state), whenever number
exceeds given limit (called backtrack limit), search restarted (by going back last
level plan graph), assuming number restarts also exceeded given
limit. search process two restarts referred epoch.
2. supporting actions (values) proposition variable considered randomized
order. randomization ensures search restarted, look
values variable different order.21
Notice random-restart strategy still allows application EBL DDB strategies, since
given epoch, behavior search identical standard backward
search algorithm. Indeed, backtrack limit number restarts made larger
larger, whole search becomes identical standard backward search.
21. Reordering values variable doesnt make whole lot sense BLACKBOX based SAT encodings
thus boolean variables. Thus, randomization BLACKBOX done order goals
considered assignment. typically tends clash built-in goal ordering strategies (such DVO
SAT-Z (Li & Anbulagan, 1997)), get around conflict breaking ties among variables randomly.
avoid clashes, decided randomize Graphplan reordering values variable. also picked inter-level
backtracks natural parameter characterizing difficulty problem Graphplans backward search.

24

fiProblem

%sol
2%
11%
54%
13%
94%
0%
0%
3%
2%
2%
58%
90%
100%

Normal Graphplan
Length
Time Av. MFSL
19(103)
.21
.3K(3.7K)
17.6(100.5) 1.29
3.7K(41K)
25.6(136)
3
4K(78K)
18(97.5)
3
31K(361K)
22.1(119.3)
31
33K(489K)
.2K(4K)
2.6K(53K)
28(156)
4
5K(111K)
26.5(135)
.75
.4K(8K)
29(152)
4
3.7K(111K)
21.24(87.3)
2
.2K(4K)
21.3(85)
8.1
2.3K(43K)
15.3(62.5)
45
35K(403K)

Table 6: Effect EBL/DDB random-restart Graphplan. Time measured cpu minutes Allegro Common Lisp 5.0 running
Linux 500MHZ Pentium machine. numbers next problem names number steps actions shortest
plans reported problems literature. R/B/L parameters second column refer limits number
restarts, number backtracks number levels plan graph expanded. statistics averaged
multiple runs (typically 100 50). MFSL column gives average number memo-based failures per searched level
plan graph. numbers parentheses total number memo-based failures averaged runs. Plan lengths
averaged successful runs.

CSP

Graphplan EBL/DDB
Length
Time Av. MFSL
14(82)
.41
4.6K(28K)
11.3(69.5)
.72
17.8K(59K)
11.3(69.5)
.72
17.8K(59K)
11(68.5)
2.38 73K(220K)
11(68.5)
2.38 73K(220K)
18.1(101)
1.62
8K(93K)
17.3(98)
11.4 69K(717K)
20.1(109)
15.3 74K(896K)
22.85(124) 2.77
8K(145K)
19.9(110)
14
71K(848K)
7.76(35.8)
1.3
29K(109K)
7(34.1)
1.32 38K(115K)
7(34.2)
1.21 35K(105K)



%sol
99%
100%
100%
100%
100%
17%
60%
100%
55%
100%
100%
100%
100%

P LANNING G RAPH

25

Att-log-a(11/54)
Att-log-a(11/54)
Att-log-a(11/54)
Att-log-a(11/54)
Att-log-a(11/54)
Att-log-b(13/47)
Att-log-b(13/47)
Att-log-b(13/47)
Att-log-c(13/65)
Att-log-c(13/65)
Rocket-ext-a(7/34)
Rocket-ext-a(7/34)
Rocket-ext-a(7/34)

Parameters
R/B/L
5/50/20
10/100/20
10/100/30
20/200/20
20/200/30
5/50/20
10/100/20
10/100/30
5/50/30
10/100/30
10/100/30
20/200/30
40/400/30

fiK AMBHAMPATI

check intuitions effectiveness EBL/DDB randomized search indeed correct, conducted empirical investigation comparing performance random search
standard Graphplan well Graphplan EBL/DDB capabilities. Since search randomized, problem solved multiple number times (100 times cases), runtime, plan length statistics averaged runs. experiments conducted
given backtrack limit, given restart limit, well limit number levels
planning graph extended. last one needed randomized search, solution may
missed first level appears, leading prolonged extension planning graph
(inoptimal) solution found later level. limit number levels expanded,
probability finding solution increases, time, cpu time spent searching
graph also increases.
implemented random restart search, first thing noticed improvement
solvability horizon (as expected, given results (Gomes et al., 1998)). Table 6 shows
results. One important point note results table talk average plan
lengths cpu times. needed due randomization potentially run produce
different outcome (plan). Secondly, Graphplan systematic search guarantees shortest
plans (measured number steps), randomized search guarantee.
particular, randomized version might consider particular planning graph barren
solutions, based simply fact solution could found within confines given
backtrack limit number restarts.
Graphplan, without EBL/DDB, likely solve larger problems randomized
search strategies. example, logistics domain, Att-log-a problem solvable
(within 24 hours real time) EBL systematic search. randomization added,
implementation able solve Att-log-b Att-log-c quite frequently. limits
number restarts, backtracks levels increased, likelihood finding solution well
average length solution found improves. example, Graphplan EBL/DDB able
solve Att-log-b every trial 10 restarts, 100 backtracks 30 levels limits (although
plans quite inoptimal).
next, perhaps interesting, question wanted investigate whether EBL
DDB continue useful Graphplan uses randomized search. first blush,
seems importantafter even Graphplan standard search may
luck able find solutions quickly presence randomization. thought
however suggests EBL DDB may still able help Graphplan. Specifically,
help Graphplan using given backtrack limit judicious fashion. elaborate, suppose
random restart search conducted 100 backtracks 10 restarts. EBL
DDB, Graphplan able pinpoint cause failure accurately without EBL
DDB. means search backtracks, chance backtrack
(or similar) reasons reduced. turn gives search chance
catching success one number epochs allowed. addition
direct benefit able use stored memos across epochs cut search.
seen data Table 6, given set limits number restarts, number
backtracks, number levels expanded, Graphplan EBL/DDB able get higher
percentage solvability well significantly shorter length solutions (both terms levels
terms actions). get comparable results standard Graphplan, significantly
increase input parameters (restarts, backtracks levels expanded), turn led dra26

fiP LANNING G RAPH



CSP

matic increases average run time. example, Att-log-a problem, 5 restarts
50 backtracks, 20 levels limit, Graphplan able solve problem 99% time,
average plan length 14 steps 82 actions. contrast, without EBL/DDB, Graphplan
able solve problem 2% cases, average plan length 19 steps 103
actions. double restarts backtracks, EBL/DDB version goes 100% solvability
average plan length 11.33 steps 69.53 actions. standard Graphplan goes 11%
solvability plan length 17.6 steps 100 actions. increase number levels 30,
standard Graphplan solves 54% problems average plan length 25.6 steps
136 actions. takes 20 restarts 200 backtracks, well 30-level limit standard
Graphplan able cross 90% solvability. time, average run time 31 minutes,
average plan length 22 steps 119 actions. contrast 99% solvability 0.4 minutes 14 step 82 action plans provided Graphplan EBL 5 restarts
50 backtracks significant! Similar results observed problems, logistics
(Att-log-b, Att-log-c) domains (Rocket-ext-a, Rocket-ext-b).
results also show Graphplan EBL/DDB able generate reuse memos effectively across different restart epochs. Specifically, numbers columns titled Av. MFSL
give average number memo-based failures per search level.22 note cases,
average number memo-based failures significantly higher Graphplan EBL
normal Graphplan. shows EBL/DDB analysis helping Graphplan reduce wasted effort
significantly, thus reap better benefits given backtrack restart limits.

9. Related Work
original implementation Graphplan, Blum Furst experimented variation
memoization strategy called subset memoization. strategy, keep memo generation
techniques same, change way memos used, declaring failure stored memo
found subset current goal set. Since complete subset checking costly,
experimented partial subset memoization subsets length n n , 1
considered n sized goal set.
mentioned earlier, Koehler co-workers (Koehler et al., 1997) re-visited
subset memoization strategy, developed effective solution complete subset checking
involves storing memos data structure called UB-Tree, instead hash tables.
results experiments subset memoization mixed, indicating subset memoization seem improve cpu time performance significantly. reason quite
easy understand improved memo checking time UB-Tree data structure,
still generating storing old long memos. contrast, EBL/DDB extension
described supports dependency directed backtracking, reducing average length
stored memos, increases utility significantly, thus offering dramatic speedups.
verify main source power EBL/DDB-Graphplan EBL/DDB part
UB-Tree based memo checking, re-ran experiments EBL/DDB turned off,
22. Notice number search levels may different (and smaller than) number planning graph levels,
Graphplan initiates search none goals pair-wise mutex other. Att-log-a,
Att-log-b Att-log-c, happens starting level 9. Rocket-ext-a happens starting level 5. numbers
parentheses total number memo based failures. divide number average number levels
search conducted get Av. MFSL statistic.

27

fiK AMBHAMPATI

Problem
Huge-Fact
BW-Large-b
Rocket-ext-a
Rocket-ext-b
Att-log-a

Tt
3.20
2.74
19.2
7.36
> 12hrs

Mt
1
0.18
16.7
4.77
-

#Btks
2497K
1309K
6188K
7546K
-

EBL x"
1.04x
1.21x
24x
9.2x
>120x

#Gen
24243
11708
62419
61666
-

#Fail
33628
15011
269499
265579
-

AvFM
1.38
1.28
4.3
4.3
-

AvLn
11.07
11.48
24.32
24.28
-

Table 7: Performance subset memoization UB-Tree data structure (without EBL/DDB).
Tt total cpu time Mt time taken checking memos. #Btks
number backtracks. EBLx amount speedup offered EBL/DDB subset
memoization #Gen lists number memos generated (and stored), #Fail lists
number memo-based failures, AvFM average number failures identified per
generated memo AvLn average length stored memos.

subset memo checking UB-Tree data structure still enabled. results shown
Table 7. columns labeled AvFM show expected subset memoization improve
utility stored memos normal Graphplan (since uses memo scenarios
normal Graphplan can). However, also note subset memoization
dramatic impact performance Graphplan, EBL/DDB capability significantly
enhance savings offered subset memoization.
(Kambhampati, 1998), describe general principles underlying EBL/DDB techniques
sketch extended dynamic constraint satisfaction problems. development
paper seen application ideas there. Readers needing background
EBL/DDB thus encouraged review paper. related work includes previous attempts applying EBL/DDB planning algorithms, work UCPOP+EBL system
(Kambhampati et al., 1997). One interesting contrast ease EBL/DDB added
Graphplan compared UCPOP system. Part difference comes fact
search Graphplan ultimately propositional dynamic CSP, UCPOPs search
variablized problem-solving search.
mentioned Section 2, Graphplan planning graph also compiled normal CSP
representation, rather dynamic CSP representation. used dynamic CSP representation corresponds quite directly backward search used Graphplan. saw
model provides clearer picture mutex propagation memoization strategies, helps us
unearth sources strength Graphplan memoization strategyincluding fact
memos conservative form no-good learning obviate need no-good
management strategies large extent.
dynamic CSP model may also account peculiarities results
empirical studies. example, widely believed CSP literature forward checking
dynamic variable ordering either critical as, perhaps even critical than, EBL/DDB
strategies (Bacchus & van Run, 1995; Frost & Dechter, 1994). results however show
Graphplan, uses dynamic CSP model search, DVO FC largely ineffective
compared EBL/DDB standard Graphplan. extent, may due fact

28

fiP LANNING G RAPH



CSP

Graphplan already primitive form EBL built memoization strategy. fact, Blum
& Furst (1997) argue memoization minimal action set selection (an action set
considered minimal possible remove action set still support
goals actions selected), ordering goals little effect (especially
earlier levels contain solution).
Another reason ineffectiveness dynamic variable ordering heuristic may
differences CSP DCSP problems. DCSP, main aim
quickly find assignment current level variables, rather find assignment
current level likely activate fewer easier assign variables, whose assignment
turn leads fewer easier assign variables on. general heuristic picking
variable smallest (live) domain necessarily make sense DCSP, since variable
two actions supporting may actually much harder handle another many
actions supporting it, actions supporting first one eventually lead activation
many harder assign new variables. may thus worth considering ordering strategies
customized dynamic CSP modelse.g. orderings based number
(and difficulty) variables get activated given variable (or value) choice.
recently experimented value-ordering heuristic picks value assigned variable using distance estimates variables activated choice
(Kambhampati & Nigenda, 2000). planning graph provides variety ways obtaining
distance estimates. simplest idea would say distance proposition p level
p enters planning graph first time. distance estimate used
rank variables values. Variables ranked simply terms distancesthe
variables highest distance chosen first (akin fail-first principle). Value ordering
bit trickierfor given variable, need pick action whose precondition set lowest
distance. distance precondition set computed distance individual
preconditions several ways:





Maximum distances individual propositions making preconditions.
Sum distances individual propositions making preconditions.
first level set propositions making preconditions present
non-mutex.

(Kambhampati & Nigenda, 2000), evaluate goal value ordering strategies based
ideas, show lead quite impressive (upto 4 orders magnitude
tests) speedups solution-bearing planning graphs. also relate distances computed
planning graph distance transforms computed planners like HSP (Bonet, Loerincs, &
Geffner, 1999) UNPOP (McDermott, 1999). idea using planning graph basis
computing heuristic distance metrics investigated context state-space search
(Nguyen & Kambhampati, 2000). interesting finding paper even one
using state-space instead CSP-style solution extraction, EBL still useful lazy demanddriven approach discovering n-ary mutexes improve informedness heuristic.
Specifically, Long & Kambhampati describe method limited run Graphplans backward search, armed EBL/DDB used pre-processing stage explicate memos (n-ary
mutexes) used significantly improve effectiveness heuristic
state-search.
29

fiK AMBHAMPATI

general importance EBL & DDB CSP SAT problems well recognized. Indeed,
one best systematic solvers propositional satisfiability problems RELSAT (Bayardo &
Schrag, 1997), uses EBL, DDB, forward checking. randomized version RELSAT
one solvers supported BLACKBOX system (Kautz & Selman, 1999), compiles
planning graph SAT encoding, ships various solvers. BLACKBOX thus offers
way indirectly comparing Dynamic CSP static CSP models solving planning
graph. discussed Section 2.2, main differences BLACKBOX needs compile
planning graph extensional SAT representation. makes harder BLACKBOX
exploit results searches previous levels (as Graphplan stored memos),
also leads memory blowups. latter particularly problematic techniques
condensing planning graphs, bi-level representation discussed (Fox & Long, 1999;
Smith & Weld, 1999) effective compile planning graph SAT.
flip side, BLACKBOX allows non-directional search, opportunity exploit existing SAT
solvers, rather develop customized solvers planning graph. present, clear
whether either approaches dominates other. informal experiments, found
certain problems, Att-log-x, easier solve non-directional search offered
BLACKBOX, others, Gripper-x, easier solve Graphplan backward
search. results recent AIPS planning competition also inconclusive respect
(McDermott, 1998).
main rationale focusing dynamic CSP model planning graph due
closeness Graphplans backward search, Gelle (1998) argues keeping activity constraints
distinct value constraints several advantages terms modularity representation.
Graphplan, advantage becomes apparent activation constraints known
priori, posted dynamically search,. case several extensions
Graphplan algorithm handle conditional effects (Kambhampati et al., 1997; Anderson, Smith,
& Weld, 1998; Koehler et al., 1997), incomplete initial states (Weld, Anderson, & Smith, 1998).
Although EBL DDB strategies try exploit symmetry search space improve
search performance, go far enough many cases. example, Gripper domain,
real difficulty search gets lost combinatorics deciding hand used
pick ball transfer next rooma decision completely irrelevant
quality solution (or search failures, matter). EBL/DDB allow Graphplan
cut search bit, allowing transfer 10 balls one room another,
come beyond 10 balls. two possible ways scaling further. first
variablize memos, realize certain types failures would occurred irrespective
actual identity hand used. Variablization, also called generalization part
EBL methods (Kambhampati, 1998; Kambhampati et al., 1997). Another way scaling
situations would recognize symmetry inherent problem abstract
resources search. (Srivastava & Kambhampati, 1999), describe type resource
abstraction approach Graphplan.

10. Conclusion Future work
paper, traced connections Graphplan planning graph CSP, motivated need exploiting CSP techniques improve performance Graphplan backward search. adapted evaluated several CSP search techniques contest Graph-

30

fiP LANNING G RAPH



CSP

plan. included EBL, DDB, forward checking, dynamic variable ordering, sticky values,
random-restart search. empirical studies show EBL/DDB particularly useful dramatically speeding Graphplans backward search (by tp 1000x instances). speedups
improved (by 8x) addition forward checking, dynamic variable ordering sticky values top EBL/DDB. also showed EBL/DDB techniques equally
effective helping Graphplan, even random-restart search strategies used.
secondary contribution paper clear description connections
Graphplan planning graph, (dynamic) constraint satisfaction problem. connections
help us understand unique properties Graphplan memoization strategy, viewed
CSP standpoint (see Section 9).
several possible ways extending work. first would support
use learned memos across problems (or specification problem changes,
case replanning). Blum & Furst (1997) suggest promising future direction,
EBL framework described makes extension feasible. discussed (Kambhampati,
1998; Schiex & Verfaillie, 1993), supporting inter-problem usage involves contextualizing
learned no-goods. particular, since soundness memos depends initial state
problem (given operators change problem problem), inter-problem usage
memos supported tagging learned memo specific initial state literals
supported memo. Memos used corresponding level new problem
long initial state justification holds new problem. initial state justification
memos computed incrementally procedure first justifies propagated mutex
relations terms initial state, justifies individual memos terms justifications
mutexes memos derived.
success EBL/DDB approaches Graphplan part due high degree redundancy planning graph structure. example, propositions (actions) level l
planning graph superset propositions (actions) level l , 1, mutexes (memos)
level l subset mutexes (memos) level l , 1). EBL/DDB techniques help
Graphplan exploit redundancy avoiding previous failures, exploitation redundancy pushed further. Indeed, search Graphplan planning graph size l
almost re-play search planning graph size l , 1 (with additional
choices). (Zimmerman & Kambhampati, 1999), present complementary technique called
explanation-guided backward search attempts exploit deja vu property Graphplans backward search. technique involves keeping track elaborate trace search
level l (along failure information), termed pilot explanation level l, using
pilot explanation guide search level l , 1. way EBL/DDB help process
significantly reduce size pilot explanations need maintained. Preliminary
results technique shows complements EBL/DDB provides significant
savings search.
Acknowledgements
research supported part NSF young investigator award (NYI) IRI-9457634, ARPA/Rome
Laboratory planning initiative grant F30602-95-C-0247, Army AASERT grant DAAH04-96-10247, AFOSR grant F20602-98-1-0182 NSF grant IRI-9801676. thank Maria Fox Derek
Long taking time implement experiment EBL/DDB STAN system.

31

fiK AMBHAMPATI

would also like thank them, well Terry Zimmerman, Biplav Srivastava, Dan Weld, Avrim
Blum Steve Minton comments previous drafts paper. Special thanks due
Dan Weld, hosted University Washington Summer 1997, spent time discussing
connections CSP Graphplan. Finally, thank Mark Peot David Smith
clean Lisp implementation Graphplan algorithm, served basis extensions.

References
Anderson, C., Smith, D., & Weld, D. (1998). Conditional effects graphplan. Proc. AI Planning
Systems Conference.
Bacchus, F., & van Run, P. (1995). Dynamic variable ordering CSPs. Proc. Principles
Practice Constraint Programming (CP-95). Published Lecture Notes Artificial Intelligence, No. 976. Springer Verlag.
Bayardo, R., & Schrag, R. (1997). Using CSP look-back techniques solve real-world sat instances. Proc. AAAI-97.
Blum, A., & Furst, M. (1997). Fast planning planning graph analysis. Artificial Intelligence,
90(1-2).
Bonet, B., Loerincs, G., & Geffner, H. (1999). robust fast action selection mechanism
planning. Proc. AAAI-97.
Do, B., & Kambhampati, S. (2000). Solving planning graph compiling CSP. Proc. 5th
International Conference AI Planning Scheduling.
Do, B., Srivastava, B., & Kambhampati, S. (2000). Investigating effect relevance reachability constraints sat encodings planning. Proc. 5th International Conference
AI Planning Scheduling.
Fox, M. (1998). Private correspondence..
Fox, M., & Long, D. (1999). Efficient implementation plan graph. Journal Artificial Intelligence Research, 10.
Frost, D., & Dechter, R. (1994). search best constraint satisfactions earch. Proc. AAAI94.
Gelle, E. (1998). generation locally consistent solution spaces mixed dynamic constraint problems. Ph.D. thesis, Ingenieure informaticienne EPFL de nationalite Suisse, Lausanne, Switzerland.
Gerevini, A. (1999). Fast planning greedy planning graphs. Proc. AAAI-99.
Gomes, C., Selman, B., & Kautz, H. (1998). Boosting combinatorial search randomization.
Proc. AAAI-98, pp. 431437.
Kambhampati, S. (1997). Challenges bridging plan synthesis paradigms. Proc. IJCAI-97.

32

fiP LANNING G RAPH



CSP

Kambhampati, S. (1998). relations intelligent backtracking explanation-based
learning planning constraint satisfaction. Artifical Intelligence, 105(1-2).
Kambhampati, S. (1999). Improving graphplans search ebl & ddb techniques. Proc. IJCAI99.
Kambhampati, S., Katukam, S., & Qu, Y. (1997). Failure driven dynamic search control partial
order planners: explanation-based approach. Artificial Intelligence, 88(1-2), 253215.
Kambhampati, S., & Nigenda, R. (2000). Distance-based goal ordering heuristics graphplan.
Proc. 5th International Conference AI Planning Scheduling.
Kambhampati, S., Parker, E., & Lambrecht, E. (1997). Understanding extending graphplan.
Proceedings 4th European Conference Planning. URL: rakaposhi.eas.asu.edu/ewspgraphplan.ps.
Kautz, H., & Selman, B. (1996). Pushing envelope: Plannng, propositional logic stochastic
search. Proc. AAAI-96.
Kautz, H., & Selman, B. (1999). Blackbox: Unifying sat-based graph-based planning. Proc.
IJCAI-99.
Koehler, J., Nebel, B., Hoffman, J., & Dimopoulos, Y. (1997). Extending planning graphs adl
subset. Tech. rep. 88, Albert Ludwigs University.
Li, C., & Anbulagan (1997). Heuristics based unit propagation satisfiability problems.
Proc. IJCAI-97.
McDermott,
D.
(1998).
Aips-98
planning
ftp.cs.yale.edu/pub/mcdermott/aipscomp-results.html.

competition

results.

McDermott, D. (1999). Using regression graphs control search planning. Aritificial Intelligence, 109(1-2), 111160.
Mittal, S., & Falkenhainer, B. (1990). Dynamic constraint satisfaction problems. Proc. AAAI-90.
Nguyen, X., & Kambhampati, S. (2000). Extracting effective admissible state-space heuristics
planning graph. Tech. rep. ASU CSE TR 00-03, Arizona State University.
Prosser, P. (1993). Domain filtering degrade intelligent backtracking search. Proc. IJCAI-93.
Rymon, R. (1992). Set enumeration trees. Proc. KRR-92.
Schiex, T., & Verfaillie, G. (1993). Nogood recording static dynamic constraint satisfaction
problems. Proc. 5th intl. conference tools artificial intelligence.
Selman, B., Levesque, H., & Mitchell, D. (1992). GSAT: new method solving hard satisfiability
problems. Proc. AAAI-92.
Smith, D., & Weld, D. (1999). Temporal planning mutual exclusion reasoning. Proc.
IJCAI-99.
33

fiK AMBHAMPATI

Srivastava, B., & Kambhampati, S. (1999). Scaling planning teasing resource scheduling.
Proc. European Conference Planning.
Tsang, E. (1993). Foundations Constraint Satisfaction. Academic Press, San Diego, California.
Weld, D., Anderson, C., & Smith, D. (1998). Extending graphplan handle uncertainty & sensing
actions. Proc. AAAI-98.
Zimmerman, T., & Kambhampati, S. (1999). Exploiting symmetry plan-graph via
explanation-guided search. Proc. AAAI-99.

34

fiJournal Artificial Intelligence Research 12 (2000) 235-270

Submitted 12/99; published 5/00

Backbone Fragility Local Search Cost Peak
Josh Singer

joshuas@dai.ed.ac.uk

Division Informatics, University Edinburgh
80 South Bridge, Edinburgh EH1 1HN, United Kingdom

Ian P. Gent

ipg@dcs.st-and.ac.uk

School Computer Science, University St. Andrews
North Haugh, St. Andrews, Fife KY16 9SS, United Kingdom

Alan Smaill

A.Smaill@ed.ac.uk

Division Informatics, University Edinburgh
80 South Bridge, Edinburgh EH1 1HN, United Kingdom

Abstract
local search algorithm WSat one successful algorithms solving
satisfiability (SAT) problem. notably effective solving hard Random 3-SAT
instances near so-called satisfiability threshold, still shows peak search cost
near threshold large variations cost different instances. make number
significant contributions analysis WSat high-cost random instances, using
recently-introduced concept backbone SAT instance. backbone set
literals entailed instance. find number solutions predicts
cost well small-backbone instances much less relevant large-backbone
instances appear near threshold dominate overconstrained region.
show strong correlation search cost Hamming distance
nearest solution early WSats search. pattern leads us introduce measure
backbone fragility instance, indicates persistent backbone clauses
removed. propose high-cost random instances local search
large backbones also backbone-fragile. suggest decay cost
beyond satisfiability threshold due increasing backbone robustness (the opposite
backbone fragility). hypothesis makes three correct predictions. First,
backbone robustness instance negatively correlated local search cost
factors controlled for. Second, backbone-minimal instances (which 3-SAT
instances altered backbone-fragile) unusually hard WSat. Third,
clauses often unsatisfied search whose deletion
effect backbone. understanding pathologies local search methods, hope
contribute development new better techniques.

1. Introduction
problem instances require high computational cost algorithms
solve? Answering question help us understand interaction search
algorithms problem instance structure potentially suggest principled improvements, example Minimise-Kappa heuristic (Gent, MacIntyre, Prosser, & Walsh,
1996; Walsh, 1998).
paper study propositional satisfiability problem (SAT). SAT important
first perhaps archetypal NP-complete problem. Furthermore, many
c
2000
AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiSinger, Gent & Smaill

AI tasks practical interest constraint satisfaction, planning timetabling
naturally encoded SAT instances.
SAT instance C propositional formula conjunctive normal form. C bag
clauses represents conjunction. clause disjunction literals,
Boolean variables negations. variables constitute set n symbols V .
assignment mapping V {true, false}. decision question SAT asks whether
exists assignment makes C true standard logical interpretation
connectives. assignment solution instance. solution,
SAT instance said satisfiable. study, assignments clauses
unsatisfied also important. refer quasi-solutions. k-SAT SAT
problem restricted clauses containing k literals. Notably, k-SAT decision problem
NP-hard k 3 (Cook, 1971). several NP-hard decision problems, 3SAT, certain probabilistic distributions instances parameterised control parameter
exhibit sharp threshold phase transition probability solution
(Cheeseman, Kanefsky, & Taylor, 1991; Gent et al., 1996; Mitchell, Selman, & Levesque,
1992). critical value control parameter instances generated
parameter region lower critical value (the underconstrained region)
almost always solutions. generated overconstrained region
control parameter higher critical value almost always solutions.
many problem distributions, threshold associated peak search cost
wide range algorithms. Instances generated distribution control
parameter near critical value hardest cost decays move value
lower higher values. behaviour interest basic AI research. devoid
regularities, random instances represent challenge faced algorithm
absence assumptions problem domain, knowledge
exploited design algorithm transformation problem instance.
Random k-SAT parameterised distribution k-SAT instances. Random k-SAT,
n fixed control parameter m/n. Varying m/n produces sharp threshold
probability satisfiability associated cost peak range complete algorithms
(Crawford & Auton, 1996; Larrabee & Tsuji, 1992). cost peak pattern Random
k-SAT conjectured extend reasonable complete methods Cook
Mitchell, (1997) also give overview analytic experimental results
average-case hardness SAT distributions.
paper study behaviour local search Random k-SAT. term local
search encompasses class procedures series assignments examined
objective finding solution. first assignment typically selected random.
Local search proceeds moving one assignment another flipping (i.e.
inverting) truth value single variable. variable flip chosen using heuristic
may include randomness, element hill-climbing (for example number
satisfied clauses) memory. Usually, local search incomplete SAT decision
problem: guarantee solution exists, found within time
bound. Unlike complete procedures, local search cannot usually prove certain
solution exists.
relatively recent discovery (e.g. Selman, Levesque Mitchell, 1992)
average cost local search procedures scales much better best complete
236

fiBackbone Fragility Local Search Cost Peak

procedures critical value m/n Random 3-SAT. recent studies, (e.g. Parkes
Walser, 1996) confirmed detail. Therefore system completeness
may sacrificed, local search procedures important role play,
generated much interest recent years.
restrict instances distribution satisfiable
increase control parameter, peak cost local search procedures
solve instances near critical value several constraint-like problems (Clark, Frank,
Gent, MacIntyre, Tomov, & Walsh, 1996; Hogg & Williams, 1994). underconstrained
region, average cost increases m/n due decreasing number solutions per
instance (Clark et al., 1996). However, overconstrained region, cost decreases
m/n although number solutions per instance continues fall. Several researchers
noted fact surprise (Clark et al., 1996; Parkes, 1997; Yokoo, 1997) since
number solutions change special way near critical value. Why, then,
cost satisfiable instances peak near critical value, decay?
Parkes (1997) provided appealing answer first part question study
backbone satisfiable Random 3-SAT instances. satisfiable SAT instances,
backbone set literals logically entailed clauses instance1 .
Variables appear entailed literals forced take particular truth
value solutions. Parkes study demonstrated instances underconstrained region, small fraction variables, any, appear backbone.
However, control parameter increased towards critical value, subclass
instances large backbones, mentioning around 75-95% variables, rapidly
emerges. Soon control parameter increased overconstrained region
large-backbone instances account satisfiable instances. Parkes also
showed fixed value control parameter, cost local search procedure WSat strongly influenced size backbone. suggests peak
average WSat cost near critical value control parameter increased may due
emergence large-backbone instances point. Parkes noted given
size backbone, cost actually higher instances underconstrained region
falls control parameter increased. also identified fall indicative
another factor produces overall peak cost. main aim paper
identify factor responsible pattern; instances certain size
backbone costly solve others?
remainder paper organised follows. Section 2 review details
WSat algorithm Random k-SAT distribution discuss experimental
conditions used. also elucidate patterns cost intend
explain show number solutions backbone size interact. Section
3 identify remarkable pattern WSats search behaviour clearly distinguishes
high cost lower cost instances certain backbone size. WSat usually drawn
early search quasi-solutions clauses unsatisfied. high cost
instances, quasi-solutions distant nearest solution, lower cost
instances equal backbone size, less distant. Section 4 develop causal
hypothesis, postulating structural property instances induces search space
1. Here, use term backbone follows Monasson, Zecchina, Kirkpatrick, Selman Troyansky
(1999a, 1999b) whose definition backbone equivalent satisfiable instances.

237

fiSinger, Gent & Smaill

structure turn causes observed search behaviour thus cost pattern.
suggest instances certain backbone size high cost backbonefragile, i.e. removal clauses random results instance
greatly reduced backbone size. discuss property may measured show
control parameter increased, instances certain backbone size become less
backbone-fragile.
hypothesis true scientific merit makes correct predictions. hypothesis made three correct predictions provide experimental evidence.
Section 5 show degree instance backbone-fragile accounts
variance cost control parameter backbone-size fixed.
Section 6 consider generation instances backbone-fragile.
clauses removed backbone unaffected, found resulting instances became progressively backbone-fragile. Eventually, clauses
removed without affecting backbone instance said backbone minimal.
hypothesis correctly predicts clauses removed way Random
3-SAT instances, cost becomes considerably higher. Section 7 show hypothesis makes correct prediction relating search behaviour: clauses
often unsatisfied search whose removal affects backbone.
Section 8 relate study previous research give suggestions work.
Finally, Section 9 concludes.

2. Background
section discuss local search algorithm WSat, measurement computational cost representativeness local search algorithms general. also
review Random k-SAT distribution overall cost pattern WSat Random
k-SAT. Finally look backbone size number solutions interact affect
cost.
2.1 WSat Algorithm
term WSat first introduced Selman et al. (1994). refers local search
architecture also subject number subsequent empirical studies
(Hoos, 1999a; McAllester, Selman, & Kautz, 1997; Parkes & Walser, 1996; Parkes, 1997).
pseudocode outline WSat algorithm given Figure 1. important feature
WSat that, unlike earlier local search algorithms, chooses unsatisfied clause
flips variable appearing clause: Select-variable-from-clause must
return variable mentioned clause. architecture first seen random walk
algorithm due Papadimitriou (1991). WSat may use different strategies Selectvariable-from-clause. study, used SKC strategy introduced Selman,
Kautz Cohen (1994); refer combination simply WSat. Pseudocode
SKC strategy given Figure 2.
follow Hoos (1998) approach measuring computational cost SAT
instances local search algorithm WSat. Rather run-times, measure runlengths : number flips taken find solution. set noise level p 0.55,
Hoos found approximately optimal Random 3-SAT. Hoos Stutzle (1998) showed
238

fiBackbone Fragility Local Search Cost Peak

WSat(C, Max-tries, Max-flips, p)
= 1 Max-tries
:= random assignment
j = 1 Max-flips
clause := unsatisfied clause C, selected random
v := Select-variable-from-clause(clause, C, p)
:= vs value flipped
satisfying
return
end
end
end
return satisfying assignment found

Figure 1: WSat local search algorithm

Select-variable-from-clause(clause, C, p)
variable x mentioned clause
breaks[x] := number clauses C would
become unsatisfied x flipped
end
variable clause breaks[y] = 0
return variable, breaking ties randomly
else
probability 1 p
return variable z clause
minimises breaks[z], breaking ties randomly
probability p
return variable z clause
chosen randomly
end

Figure 2: SKC variable selection strategy

run lengths easiest instances exponentially distributed many local
search variants. implies random restart mechanism (the re-randomisation
Max-flips flips) significantly worthwhile.
239

fiSinger, Gent & Smaill

known date whether, without using restart, WSat almost surely (i.e.
probability approaching 1) find solution satisfiable 3-SAT instances given unlimited
flips. local search algorithm eventually find solution conditions,
said probabilistically approximately complete (PAC). Hoos (1999a) proved whether
several local search algorithms PAC Culberson Gent (1999a) proved
WSat PAC 2-SAT case. Hoos (1998) observed data suggested WSat
could PAC. set Max-tries 1 Max-flips infinite runs reported
paper. solution found every run, evidence WSat may
PAC.
Another implication exponential distribution run lengths large number
samples must taken obtain good estimate mean. Following Hoos, use
median 1000 WSat runs instance descriptive statistic representing
WSats search cost instance. appears give stable estimate cost
(as less sensitive long tail mean) moderate amount
computational effort.
One objection studying single algorithm local search class may
representative: results obtained algorithm may generalise members
class. accept objection, evidence certain conditions,
one local search algorithm actually large extent representative whole class.
example Hoos (1998) found high correlation computational costs
random instances pairs different local search algorithms, including WSat. also
suggests algorithm-independent property instances results
high cost class algorithms.
2.2 Random k-SAT
use well-studied Random k-SAT distribution (Franco & Paull, 1983; Mitchell et al.,
1992) k = 3. Random k-SAT distribution k-SAT instances, parameterised
ratio clauses variables m/n. Let V fixed set Boolean variable symbols
size n. generate instance Random k-SAT clauses n variables,
clause C independently chosen randomly selecting literals k distinct variables
V independently negating probability 12 . guarantee
variables mentioned instance contain duplicate clauses.
local search cannot solve unsatisfiable instances, filter using complete
SAT procedure. order control effects backbone size, also need
isolate portion satisfiable part distribution backbone size
certain value. obtained calculating backbone size satisfiable
instance discarding whose backbone required size. term
controlling backbone size. Satisfiable instances certain backbone sizes rare
certain values m/n. example m/n 4.49, found 1 20,000
generated instances satisfiable backbone size 10. Hence generation instances
way somewhat costly computational terms. therefore one
limits value n data could collected.
240

fiBackbone Fragility Local Search Cost Peak

primarily interested threshold region control parameter,
cost peak occurs: region near point 50% instances satisfiable.
looked region 90% 20% satisfiability.
2.3 Pattern WSat Cost Random 3-SAT
Figure 3 show peak WSat cost mentioned e.g. Parkes
(1997). peak slightly 50% point (4.29) median appears shift
higher percentiles. similar pattern noticed Hogg Williams (1994)
local search cost graph colouring.

9000

8000
95th

7000

cost

6000

5000

90th

4000

3000
75th
2000
50th
1000

0

25th

4

4.1

4.2

4.3
m/n

4.4

4.5

Figure 3: cost peak WSat m/n varied. level m/n, generated
5000 satisfiable instances. measured per-instance WSat cost these.
line plot gives different point cost distribution, e.g. 90th
percentile difficulty 500th costly instance WSat.

Parkes (1997) Yokoo (1997) suggest local search cost peak shown
WSat Figure 3 result two competing factors. m/n increased number
solutions per instance falls causes onset high cost. However, number
solutions continues fall overconstrained region cost decreases.
must therefore second factor whose effect outweighs number solutions
overconstrained region cause fall cost. main aim paper
identify factor. pattern WSat cost Random 3-SAT identified Parkes (1997)
241

fiSinger, Gent & Smaill

starting point. Parkes observed given backbone size n, average
cost falls m/n increased.
Figure 4 shows fall WSat cost n = 100 Random 3-SAT instances.
point plot median cost 1000 instances2 length bars
interquartile range instance cost. fall cost approximately exponential decay
range m/n near threshold range backbone sizes. rate decay
affected backbone size, cost large-backbone instances decaying fastest.
length error bars Figure 4 along log scale cost axis indicates
distribution per-instance cost also positively skewed even backbone size
controlled. example point m/n 4.11 backbone size 0.9n
difference 75th percentile median 4000 whereas
median 25th percentile half that. spread cost large, particularly
relative effect control parameter. think significant portion
variance cost among instances due errors estimates cost
instance.

backbone size = 0.9 n
backbone size = 0.5 n
backbone size = 0.1 n

4

cost

10

3

10

4

4.05

4.1

4.15

4.2

4.25
m/n

4.3

4.35

4.4

4.45

4.5

Figure 4: effect varying m/n cost backbone size controlled.

2. cost instance defined median run length 1000 runs point Figure 4
median medians.

242

fiBackbone Fragility Local Search Cost Peak

2.4 Number Solutions Backbone Size Controlled
studied effect number solutions WSat cost. number solutions
determined using modified complete procedure. small-backbone instances,
evidence number solutions actually increases m/n, least
overconstrained region. Figure 5 shows plot number solutions, backbone
size controlled 0.1n. point median 1000 instances bars show
interquartile range. possible increase number solutions may help explain
fall cost small-backbone instances, appears weak effect
account full.
6

10

number solutions

backbone size = 0.1 n

5

10

4

10

4

4.05

4.1

4.15

4.2

4.25
m/n

4.3

4.35

4.4

4.45

4.5

Figure 5: Number solutions n = 100, m/n varied, backbone size controlled
0.1n.

studied relationship number solutions WSat cost
backbone size controlled different values. Figure 6 shows log-log plot number
solutions cost, m/n 4.29 backbone size 0.1n. linear least squares
regression (lsr) fit superimposed. Table 1 gives summary data log-log scatter plot
different backbone sizes transition : gradient intercept lsr fits,
product-moment correlation r rank correlation.
number solutions strongly negatively related cost smaller backbone sizes transition strength relationship fairly constant
m/n varied. speculate strong relationship instances arises
243

fiSinger, Gent & Smaill

m/n
4.03

4.11

4.18

4.23

4.29

4.35

4.41

4.49

Backbone
size
0.1n
0.5n
0.9n
0.1n
0.5n
0.9n
0.1n
0.5n
0.9n
0.1n
0.5n
0.9n
0.1n
0.5n
0.9n
0.1n
0.5n
0.9n
0.1n
0.5n
0.9n
0.1n
0.5n
0.9n

Intercept
lsr fit
3.8993
4.1410
4.2070
3.8727
4.1551
4.1387
3.7867
4.0533
4.0202
3.7771
3.9890
3.9891
3.7309
3.9169
3.7836
3.6981
3.8933
3.8173
3.6083
3.8445
3.7772
3.5483
3.7577
3.6228

Gradient
lsr fit
0.1967
0.2123
0.1372
0.1989
0.2304
0.1336
0.1911
0.2180
0.1146
0.1932
0.2140
0.1270
0.1910
0.2076
0.0610
0.1896
0.2133
0.1018
0.1782
0.2094
0.1120
0.1748
0.2043
0.0842

r

Rank corr.

0.7808
0.6761
0.1307
0.7696
0.6834
0.1275
0.7664
0.6932
0.1159
0.7829
0.6729
0.1317
0.7787
0.6921
0.0612
0.8007
0.6872
0.1044
0.7784
0.7024
0.1179
0.7972
0.6954
0.0992

-0.7731
-0.6699
-0.1365
-0.7669
-0.6855
-0.1291
-0.7760
-0.6974
-0.1217
-0.7873
-0.6867
-0.1329
-0.7844
-0.6941
-0.0534
-0.7994
-0.6967
-0.0903
-0.7628
-0.7085
-0.1045
-0.7932
-0.6991
-0.0783

Table 1: Data log-log correlations number solutions cost n = 100,
m/n varied backbone size fixed different values.

244

fiBackbone Fragility Local Search Cost Peak

m/n = 4.29, backbone size = 0.1 n

4

cost

10

3

10

2

10
2
10

3

10

4

10

5

10
number solutions

6

10

7

10

8

10

Figure 6: Scatter plot number solutions cost n = 100, m/n = 4.29
backbone size fixed 0.1n.

finding backbone straightforward main difficulty encountering solution
backbone satisfied. density solutions region satisfying
backbone important. larger backbone sizes, number solutions less
relevant cost. significant change number solutions large backbone
instances observed m/n varied. number solutions cost
strongly related instances unsurprising, large backbone size implies
solutions lie compact cluster local searchs main difficulty finding
cluster (i.e. satisfying backbone). Therefore expect density solutions
within cluster important. Hoos (1998) observed correlation
number solutions local search cost becomes small overconstrained region.
explained simply fact large-backbone instances dominate
region.

3. Search Behaviour: Hamming Distance Nearest Solution
order suggest cause cost decay large-backbone instances
observed Section 2.3, made detailed study WSats search behaviour, i.e.
assignments visited search. report exploratory part research
245

fiSinger, Gent & Smaill

section. explain somewhat novel search behaviour metrics used
giving results discussion them.
3.1 Definitions Methods
Assuming local search algorithm PAC, given run unlimited length, fb ,
number flips taken find first assignment b clauses unsatisfied,
well-defined b 0. f0 equal run length.
particular run local search algorithm consists series assignments
T0 , T1 , ..., Tf0 , Ti assignment visited flips made. found
Random 3-SAT n = 100, assignment satisfying clauses quickly
found remainder search, clauses (1 - 10) unsatisfied.
shown Gent Walsh (1993) GSat, rapid hill-climbing phase,
also suggested Hoos (1998), followed long plateau-like phase number
unsatisfied clauses low constantly changing. experiments used f5
arbitrary indicator length hill-climbing phase. Unlike GSat, WSat
well-defined end point hill-climbing phase, since short bursts hill-climbing
continue occur rest search. think using fb indicator
value b 1 10 would give similar results.
Local search proceeds flipping variable values might expect Hamming distance current assignment nearest solution may also
interest. Hamming distance two assignments hd(T1 , T2 ) simply number
variables T1 T2 assign differently. studied Hamming distance
current assignment solution Tsol C hd(T, Tsol ) minimised.
abbreviate hdns(T, C) (Hamming distance nearest solution). assignment
, hdns(T, C) may calculated using complete SAT procedure modified
every solution C visited Hamming distance calculated.
3.2 Results
section, data based Random 3-SAT instances n = 100 backbone size
controlled various values 0.1n 0.9n. Recall control backbone
certain value, generate satisfiable Random 3-SAT instances usual discard
whose backbone required size. varied m/n point 90%
satisfiability (4.03) point 20% satisfiability (4.49). hdns(Tf5 , C) Hamming
distance first assignment 5 clauses unsatisfied
nearest solution. instance calculated median value f5 mean
value hdns(Tf5 , C) based 1000 runs WSat. plots Figures 7 8,
point median 1000 instances.
Figure 7 shows effect varying m/n f5 backbone size controlled.
values f5 low compared cost range small. although
cost find solution varies considerably instance instance, quasi-solutions
quickly found matter overall cost. However, notable effects
backbone size m/n f5 . might expected, larger backbone instances,
overall cost generally higher, WSat takes slightly longer find quasi-solution.
effect m/n unexpected. backbone size controlled 0.5n more, m/n
246

fiBackbone Fragility Local Search Cost Peak

increased WSat takes slightly longer find quasi-solution, although simultaneously cost
decreasing seen Figure 4.

170

backbone size = 0.9 n
backbone size = 0.7 n
backbone size = 0.5 n
backbone size = 0.3 n
backbone size = 0.1 n

160

150

140

f5

130

120

110

100

90

80

4

4.05

4.1

4.15

4.2

4.25
m/n

4.3

4.35

4.4

4.45

4.5

Figure 7: effect varying m/n f5 backbone size controlled.
Figure 8 shows effect varying m/n hdns(Tf5 , C) effects backbone
size controlled for. plot, bars give interquartile range. spread
values mean hdns(Tf5 , C) point also small relative effect varying
m/n. positive effect backbone size hdns(Tf5 , C) one might expect
since backbone size affects cost.
backbone size controlled, m/n increased satisfiability threshold,
mean hdns(Tf5 , C) decreases linearly wide range backbone values. Hence, although
quasi-solution (Tf5 ) usually quickly found, instances lower m/n quasisolution considerably Hamming-distant nearest solution. m/n increased,
backbone size controlled, effect gradually lessened.
also looked relationship search behaviour cost
m/n fixed backbone size controlled. found case variance
hdns(Tf5 , C) accounts cost variance. Figure 9 shows plot mean
hdns(Tf5 , C) cost backbone size controlled 0.5n m/n fixed 4.29.
lsr fit superimposed. plot suggests hdns(Tf5 , C) linearly related log cost.
Table 2 gives intercept gradient lsr fits r values backbone size
controlled three values m/n varied. Variance hdns(Tf5 , C) accounts
variance cost three different backbone sizes consistent
247

fiSinger, Gent & Smaill

45

backbone size = 0.9 n
backbone size = 0.5 n
backbone size = 0.1 n
40

5

hdns(Tf ,C)

35

30

25

20

15

4

4.05

4.1

4.15

4.2

4.25
m/n

4.3

4.35

4.4

4.45

4.5

Figure 8: effect varying m/n hdns(Tf5 , C) backbone size controlled.

threshold. scatter plots (not shown) linear lsr fits data similar
shape Figure 9 consistent linear relationship. r values
greatest small-backbone instances reasons unclear. Possibly, since
search shorter small-backbone instances, success follows quickly f5
hdns(Tf5 , C) better indicator likelihood finding solution.
Figure 8 showed backbone size controlled, hdns(Tf5 , C) falls linearly m/n
increased. gradient fall 14. Table 2 showed backbone size
controlled m/n fixed, hdns(Tf5 , C) linearly related log cost, gradient
fit around 0.08. Given linear relationship continues hold
constant gradient m/n varied (in fact gradient decreases slightly) assuming
increasing m/n affecting cost means, would expect linear
decrease log mean cost gradient 1.12, slightly steeper
observed decrease log median cost shown Figure 4.
results consistent idea whatever factor causes cost decay
exponentially m/n varied largely causing hdns(Tf5 , C) fall linearly.
3.3 Discussion
identified pattern search behaviour strongly related pattern
cost discussed Section 2.3. interpretation pattern follows.
248

fiBackbone Fragility Local Search Cost Peak

m/n

Backbone size

4.03

0.1n
0.5n
0.9n
0.1n
0.5n
0.9n
0.1n
0.5n
0.9n
0.1n
0.5n
0.9n
0.1n
0.5n
0.9n
0.1n
0.5n
0.9n
0.1n
0.5n
0.9n
0.1n
0.5n
0.9n

4.11

4.18

4.23

4.29

4.35

4.41

4.49

Intercept
lsr fit
1.0528
0.6928
0.7065
1.0166
0.6315
0.8158
1.0858
0.8090
0.8109
1.1290
0.8343
0.7480
1.1289
1.0032
0.8382
1.1664
0.9835
0.9835
1.2029
1.0274
1.1070
1.2458
1.1472
1.1930

Gradient
lsr fit
0.0844
0.0925
0.0895
0.0868
0.0955
0.0867
0.0839
0.0895
0.0864
0.0821
0.0887
0.0878
0.0826
0.0828
0.0856
0.0811
0.0842
0.0808
0.0795
0.0830
0.0768
0.0777
0.0787
0.0742

r
0.9445
0.8769
0.7308
0.9511
0.8852
0.7196
0.9556
0.8799
0.7195
0.9581
0.8974
0.7691
0.9550
0.8935
0.7579
0.9628
0.8996
0.7728
0.9565
0.9135
0.7816
0.9661
0.9197
0.8086

Table 2: Data correlations hdns(Tf5 , C) log10 cost n = 100 m/n
backbone size fixed different values.

249

fiSinger, Gent & Smaill

5

10

4

cost

10

3

10

2

10

16

18

20

22

24

26
hdns(Tf ,C)

28

30

32

34

36

5

Figure 9: relationship hdns(Tf5 , C) log cost backbone size controlled
0.5n m/n fixed 4.29.

instance quasi-solutions WSat visits form interconnected areas search space
local search always move solution them, without often moving
assignment many clauses unsatisfied. evidence simply WSat
runs apparently always successful visit assignments clauses
unsatisfied infrequently. Frank, Cheeseman Stutz (1997) also mentioned
analysis GSat search spaces Random 3-SAT, local minima clauses
unsatisfied usually escaped unsatisfying one clause.
believe instances higher cost quasi-solution area extends parts
search space Hamming-distant solutions, whereas instances lower cost
area less extensive. mean Hamming distance early quasi-solution
Tf5 nearest solution accurate indicator extensive quasi-solution
area is. interpretation suggests hdns(Tf5 , C) strongly correlated cost:
extensiveness quasi-solution area determines costly search. also
suggests why, instances higher cost, quasi-solutions found slightly quickly:
quasi-solution area extensive, random starting point shorter series
hill-climbing flips required find quasi-solution.
250

fiBackbone Fragility Local Search Cost Peak

mean hdns(Tf5 , C) decreases linearly m/n increased backbone size
controlled. time, cost decays exponentially. think m/n
increased, quasi-solution area becomes progressively less extensive.

4. Causal Hypothesis
pattern search behaviour Section 3 interpretation suggested
causal hypothesis account decay cost discussed Section 2.3 hence
overall peak. key hypothesis property SAT instances: backbone fragility.
property qualitatively consistent observations. importantly,
although backbone fragility implications instances search space topology,
property based logical structure SAT instance. section motivate
define backbone fragility, discuss may measured show relates
patterns reported Sections 2.3 3.
4.1 Backbone Fragility : Motivation
Suppose B small sub-bag clauses satisfiable SAT instance C,
exists set quasi-solutions QB clauses B unsatisfied.
structural property C would cause quasi-solutions QB attractive WSat?
already know backbone Random 3-SAT instance small, solutions
found little search (Parkes, 1997). solutions C B (C B denotes C
one copy member B removed) either solutions C members QB .
assume assignments attractive WSat C approximately
assignments attractive C B, members QB (which
solutions C B) attractive C backbone C B small, particularly
Cs backbone large. Furthermore TB QB , number variables
appear backbone C B upper bound hdns(TB , C), large reduction
backbone size allows high hdns(TB , C). summarise, removal certain
small sub-bag clauses causes backbone size greatly reduced, expect
quasi-solutions clauses unsatisfied attractive WSat
possibly Hamming-distant nearest solution.
interested quasi-solutions general rather QB . removing
random small set clauses average causes large reduction backbone size,
say instance backbone-fragile. effect backbone smaller
average, instance backbone-robust. large-backbone instance backbone-fragile,
extension argument expect general quasi-solutions attractive
may Hamming-distant nearest solution. Hence idea consistent
observations interpretation Section 3: backbone fragility approximately
corresponds extensive quasi-solution area is.
idea backbone fragility underlying factor causing search behaviour
pattern appealing reasons. entailed literal l C, must
sub-bag clauses C whose conjunction entails l. given backbone size, clauses
added, given entailed literal l expect extra clauses allow alternative
combinations clauses entail l. Hence adding clauses whilst controlling
backbone size, random removal clauses less effect backbone since
251

fiSinger, Gent & Smaill

fact literal entailed depends less presence particular sub-bags.
clauses added, expect instances become less backbone-fragile. Given
hypothetical relationship backbone fragility search behaviour, would
explain qualitatively search behaviour changes m/n varied.
think backbone fragility property instances logical structure,
study may also lead results complexity issues, postpone discussion
Section 8.
4.2 Measurement Backbone Robustness
define measure backbone robustness instance allow us
test predictions hypothesis. take instance C delete clauses random,
halting process backbone size reduced least half. point
record result number deleted clauses. constitutes one robustness trial.
metric backbone robustness mean result possible trials, i.e.
average number random deletions clauses must made reduce
backbone size half.
infeasible compute results possible robustness trials. Therefore,
measuring backbone robustness instance estimated computing average
random sample trials. used least 100 robustness trials case order
ensure reasonably accurate estimate, continued sample robustness trials
standard error less 0.05 sample mean (in case estimate
mean accurate within 10% 95% confidence level). n = 100,
using satisfiable instances near satisfiability threshold whose backbone size
controlled 50, usually less 250 robustness trials required estimate
converge way. Even then, backbone robustness costly compute.
different possible metrics backbone fragility/robustness, found
metric described gave clearest results purposes without unnecessarily complicated definition. metrics, reduction backbone size
random fixed fraction clauses removed, may suitable contexts.
4.3 Change Backbone Robustness Control Parameter Varied
discussed Section 4.1 expect backbone size controlled, backbone robustness
increases m/n increased. Since measure backbone robustness defined terms
size backbone, useful comparing instances equal backbone
size.
found increasing control parameter made instances backbone-robust,
expected. Figure 10 shows effect backbone robustness increasing m/n
satisfiability threshold n = 100 backbone size controlled. point
median 1000 instances.
note backbone robustness defined measure generally higher
instances larger backbones. think large-backbone
instances, backbone must reduced larger number literals fragility trial
requires clauses removed.
252

fiBackbone Fragility Local Search Cost Peak

22

20

18

backbone robustness

16

14

12

10

8

backbone size = 0.9 n
backbone size = 0.5 n
backbone size = 0.1 n

6

4

4

4.05

4.1

4.15

4.2

4.25
m/n

4.3

4.35

4.4

4.45

4.5

Figure 10: Backbone robustness satisfiability transition, backbone size
fixed 0.1n 0.5n 0.9n.

5. Correct Prediction Cost Variance
may assert fall cost observed increase control parameter
due change factor F , example Yokoo (1997) has.
assertion makes important testable prediction: variation F
control parameter fixed accounts variation cost. However may
factors whose influence cost great obscure effect F
control parameter fixed. best reveal effect F , any, effects
factors may controlled for.
Backbone robustness proposed factor F . backbone size another factor
strongly influences cost. result section effects
m/n backbone size controlled for, i.e. fixed, effects backbone
robustness seen quite clearly large-backbone instances.
5.1 Correlation Data
Figure 11 shows plot log cost measure backbone robustness
Random 3-SAT instances n = 100, m/n 4.29 backbone size controlled 0.1n,
0.5n 0.9n. linear lsr fit superimposed case. Table 3 gives intercept,
253

fiSinger, Gent & Smaill

m/n

Backbone size

4.03

0.1n
0.5n
0.9n
0.1n
0.5n
0.9n
0.1n
0.5n
0.9n
0.1n
0.5n
0.9n
0.1n
0.5n
0.9n
0.1n
0.5n
0.9n
0.1n
0.5n
0.9n
0.1n
0.5n
0.9n

4.11

4.18

4.23

4.29

4.35

4.41

4.49

Intercept
lsr fit
3.0338
3.7075
4.2846
2.9639
3.6675
4.2287
2.9365
3.6067
4.1811
2.9257
3.5142
4.1313
2.8766
3.4903
4.0934
2.8261
3.4325
3.9939
2.7925
3.3772
3.9284
2.7164
3.3506
3.8720

Gradient
lsr fit
0.0204
0.0370
0.0419
0.0134
0.0351
0.0370
0.0146
0.0302
0.0338
0.0155
0.0239
0.0312
0.0136
0.0225
0.0290
0.0109
0.0199
0.0237
0.0100
0.0172
0.0211
0.0073
0.0170
0.0198

r

r 95%

r +95%

0.1928
0.3730
0.4711
0.1490
0.3891
0.4535
0.1745
0.3840
0.5306
0.2107
0.3643
0.5253
0.1894
0.3863
0.5325
0.1671
0.3734
0.4984
0.1763
0.3452
0.5152
0.1392
0.4034
0.5549

0.2506
0.4191
0.5165
0.2088
0.4355
0.5001
0.2356
0.4272
0.5687
0.2659
0.4105
0.5645
0.2483
0.4350
0.5721
0.2250
0.4222
0.5394
0.2321
0.3954
0.5582
0.1926
0.4585
0.5949

0.1400
0.3235
0.4251
0.0873
0.3417
0.4065
0.1149
0.3389
0.4921
0.1553
0.3154
0.4818
0.1300
0.3395
0.4931
0.1105
0.3244
0.4555
0.1175
0.2919
0.4692
0.0841
0.3516
0.5125

Rank corr.
coefficient
0.1934
0.3713
0.4699
0.1402
0.3770
0.4662
0.1663
0.3738
0.5466
0.2116
0.3436
0.5457
0.2053
0.3996
0.5467
0.1724
0.3782
0.5243
0.1683
0.3582
0.5270
0.1355
0.4027
0.5604

Table 3: Data correlation backbone robustness log10 cost n = 100
m/n backbone size fixed different values.

gradient r values lsr fits backbone size controlled three values
m/n varied threshold.
r values suggest effect backbone robustness cost, particularly large
backbone sizes. smaller backbone sizes, imagine finding backbone less
issue backbone fragility, hinders this, less effect. larger
backbone sizes, think main difficulty WSat satisfying backbone; backbone
fragility important. However, given somewhat unclear shape scatter plots,
several concerns significance correlation, address
using simple statistical methods.
254

fiBackbone Fragility Local Search Cost Peak

m/n = 4.29, backbone size = 0.1 n

3

cost

10

2

10

0

5

10

15
20
25
backbone robustness

30

35

40

35

40

35

40

m/n = 4.29, backbone size = 0.5 n

4

cost

10

3

10

2

10

0

5

10

15
20
25
backbone robustness

30

m/n = 4.29, backbone size = 0.9 n
5

10

cost

4

10

3

10

2

10

0

5

10

15
20
25
backbone robustness

30

Figure 11: Scatter plot backbone robustness cost n = 100, m/n = 4.29
backbone size fixed 0.1n, 0.5n 0.9n.

255

fiSinger, Gent & Smaill

5.2 Artifact Distributions Variables?
One concern observed r could also arisen simply distributions
two variables rather relationship them. serious
concern distributions unknown.
null hypothesis, H0 value r results distributions
two variables equal observed r. randomisation method used test H0 .
See Appendix details method. data set presented, 1000 randomised
pairings data constructed. case, found observed r
fall within range sampling distribution r randomised pairings. H0
therefore rejected 99.9% confidence level.
r coefficient, given above, greatly affected outliers. Therefore rank
correlation coefficient, less affected, also calculated. rank correlation
also given Table 3. found case rank correlation coefficient
considerably different r coefficient. demonstrates observed r
greatly affected outliers.
5.3 Confidence Intervals Correlation
Given relationship two variables merely artifact
distributions outliers, accurate measurement r? bootstrap
method used obtain bounds confidence interval statistic. Again,
reader referred Appendix details method. Using method 1000
pseudo-samples obtained lower upper bounds 95% confidence interval r,
also given Table 3 r 95% r +95% respectively. data implies 95%
confidence, upper bounds amount error estimates r 2
0.02 0.05.

6. Correct Prediction Backbone-Fragile Instances
hypothesis proposes high backbone fragility instances quite accurately represents
factor (via search behaviour patterns uncovered Section 3) causes high
WSat cost instances. However, plausible high backbone fragility
by-product unmeasured latent factor causally related
cost.
help establish causal link backbone fragility cost, therefore created sets random SAT instances higher backbone fragility usual Random
3-SAT instances. degree following methodological precedent Bayardo
Schrag (1996), created random instances contained small unsatisfiable subinstances constraints overall. often found exceptionally
hard complete procedure Ntab. experiments thereby helped establish
feature instance structure cause exceptionally high cost complete
procedures.
cannot easily set backbone fragility directly, since generation parameter.
One manipulation experiment possible use instance generation procedure results instances higher backbone fragility. hypothesis predicts
256

fiBackbone Fragility Local Search Cost Peak

instances generated using procedure harder Random 3-SAT instances.
section define procedure test prediction. may procedure also manipulating latent factor. However, since procedure specifically
designed increase backbone fragility, correct prediction still lends credibility
hypothesis.
6.1 Backbone-minimal Sub-instances
Suppose SAT instance C remove clause backbone
affected removal clause. clauses repeatedly removed, eventually
instance clause removed without disturbing backbone.
case backbone-minimal sub-instance (BMS) C. formally,
following definition:
Definition SAT instance C 0 BMS C iff
C 0 sub-instance C (i.e. sub-bag clauses) C 0
backbone C.
clause c C 0 exists literal l that:
1. C 0 l
2. (C 0 {c}) l satisfiable
i.e. every strict sub-instance C 0 strictly smaller backbone backbone C 0 2
BMSs seen satisfiable analogues minimal unsatisfiable sub-instances
(MUSs) unsatisfiable instances studied amongst others Culberson Gent (1999b)
context graph colouring Gent Walsh (1996) Bayardo Schrag
(1996) satisfiability. MUS instance C sub-instance unsatisfiable,
removal one clause sub-instance renders satisfiable.
unsatisfiable instances must MUS, satisfiable SAT instances must
BMS. BMS depend non-empty backbone
backbone instance empty, BMS empty sub-instance. instance
one BMS. Different BMSs instance may share clauses. One BMS
instance cannot strict sub-instance another.
Suppose backbone satisfiable instance C set literals {l1 , l2 , . . . , lk }. Let
clause l1 l2 . . . lk . following useful fact:
Theorem C 0 BMS C iff C 0 MUS C 2
simple proof given Appendix B. Due fact, methods studying
MUSs applied study BMSs. study BMSs satisfiable
instance C finding backbone C studying MUSs C d:
corresponds BMS C since must present every MUS C d.
find BMS C determine backbone, find random MUS C using
MUS-finding method Gent Walsh (1996) remove result.
257

fiSinger, Gent & Smaill

Instances
Preserve-backbone(C, 0, C 0 )
Preserve-backbone(C, 5, C 0 )
Preserve-backbone(C, 10, C 0 )
Preserve-backbone(C, 20, C 0 )
Preserve-backbone(C, 40, C 0 )
Preserve-backbone(C, 80, C 0 )
BMS

Backbone robustness
10th percentile Median 90th percentile
8.5845 12.9700
20.6300
7.7374 12.0317
19.1700
7.1977 11.0851
17.3500
6.0690
9.3913
14.5351
4.2622
6.4899
9.9900
2.0745
2.8661
3.9851
1.0200
1.0600
1.1600

Table 4: effect Preserve-backbone backbone robustness.

6.2 Interpolating Instance one BMSs
BMS C 0 established, also study effects interpolation
C C 0 removing random C clauses appear
C 0 . equivalent removing clauses random backbone preserved.
Preserve-backbone(C, mr , C 0 ) denote C mr clauses, appear
BMS C 0 , removed random. resulting instance backbone
C.
increasing m/n controlling backbone size causes backbone robustness
increase, found deleting clauses backbone unaffected causes
backbone robustness (as measured above) decrease, one might expect.
used 500 Random 3-SAT instances n = 100 m/n = 4.29. instance
found one BMS. used Preserve-backbone interpolate mr set
various values. Table 4 shows effect increasing mr backbone robustness.
BMSs threshold instances backbone-fragile removal one clause
likely reduce backbone half more.
hypothesis predicts interpolation C C 0 proceeds, cost
local search increases backbone robustness decreases. conceivable,
although would surprising, removing clauses random instances
near threshold generally makes cost local search increase.
case, increase cost interpolation towards BMS could merely due
removal clauses per se rather removal clauses whilst preserving backbone.
control possibility also removed clauses according two procedures.
procedure Random(C, mr ) removes mr clauses C random. procedure
Reduce-backbone(C, mr ) removes mr clauses time clause removed,
size backbone reduced. clause removed chosen randomly
clauses. procedure therefore uses opposite removal criterion Preservebackbone. backbone becomes empty, clauses removed.
Figure 12 shows effect per-instance cost applying three clause removal
procedures set 500 Random 3-SAT threshold instances. plot
median per-instance cost.
258

fiBackbone Fragility Local Search Cost Peak

4

10

cost

Preservebackbone
Reducebackbone
Random

3

10

2

10

0

10

20

30

40
mr

50

60

70

80

Figure 12: effect three clause removal procedures median per-instance cost.

observe removing clauses randomly backbone strictly reduced, causes cost reduced, removal clauses cause higher
cost. Reduce-backbone procedure causes greater initial fall cost, backbone size reduced quickly Random. However, cost stabilises
Reduce-backbone backbone becomes empty thereafter clauses
removed.
Removing clauses according Preserve-backbone causes local search cost
increase amount approximately exponential number clauses removed. Table
5 gives data effect also cost data BMSs. interpolation shifts
whole distribution up, median. median cost BMSs,
backbone-fragile instances, three times 90th cost
percentile Random 3-SAT instances.
BMSs instances 254 318 clauses. results
therefore demonstrate existence instances underconstrained region
much harder typical instances near satisfiability threshold. However since
obtained sampling Random 3-SAT directly, know
often occur. far know, vanishingly rare therefore, contrast
exceptionally hard instances complete algorithms, seems unlikely affect
mean cost. Also, Gent Walsh (1996) showed exceptionally hard
259

fiSinger, Gent & Smaill

Instances
Preserve-backbone(C, 0, C 0 )
Preserve-backbone(C, 5, C 0 )
Preserve-backbone(C, 10, C 0 )
Preserve-backbone(C, 20, C 0 )
Preserve-backbone(C, 40, C 0 )
Preserve-backbone(C, 80, C 0 )
BMS

Per-instance cost
10th percentile Median 90th percentile
517
1450
5175
537
1515
5657
557
1608
6009
570
1803
7037
643
2295
10683
816
4154
24313
1556
16945
135883

Table 5: effect Preserve-backbone per-instance cost.

instances complete algorithms hard different reason threshold
instances, BMSs apparently hard reason backbonefragile.
One useful by-product section means generating harder test instances
local search variants without increasing n. However instances require O(m + n)
complete searches generate: O(n) determine satisfiability backbone O(m)
reduce BMS.

7. Correct Prediction Search Behaviour
Recall motivating discussion Section 4.1 suggested quasisolutions QB would attractive backbone C B small. say
clauses B likely set unsatisfied clauses removal
clauses B large effect backbone. part hypothesis also makes
prediction search behaviour clauses often unsatisfied WSat
whose removal reduces backbone size most. section show prediction
correct.
looked individual instances cost percentiles set 5000 Random
k-SAT instances n = 100 m/n = 4.29. Per-instance cost determined
previous sections. clause instance, calculated number backbone
literals longer entailed clause removed. simple measure
backbone contribution (bc) clause much backbone size depends
presence clauses. clauses backbone contribution high, termed backbonecritical clause. made 1000 runs WSat instance conditions
previous sections. search, time current assignment changed recorded
whether clause unsatisfied. result averaging number times clause
unsatisfied runs gives unsatisfaction frequency (uf ) clause.
Figure 13 shows plot two quantities clauses instance whose cost
median 5000 threshold instances. note figure clauses whose
presence contributes backbone often unsatisfied average
WSat search.
260

fiBackbone Fragility Local Search Cost Peak

3

10

unsatisfaction frequency

2

10

1

10

0

10

0

5

10
15
backbone contribution

20

25

Figure 13: Scatter plot unsatisfaction frequency backbone contribution
clauses cost median 5000 instances, m/n = 4.29, n = 100.

Table 6 confirms pattern. row table gives data one instance.
selected cost percentiles; individual instances varying degrees difficulty. example
row labelled 30th corresponds instance whose cost 1500th rank
easiest difficult 5000 instances, 50th percentile instance
one used produce Figure 13. third fourth columns give mean
standard deviation unsatisfaction frequency clauses instance
last two columns give statistics sub-bag clauses
backbone-critical (their backbone contribution top 10%).
Table 7 shows converse effect also present: clauses often
unsatisfied (their unsatisfaction frequency top 10%) backbone-critical
average. Although effect quite clear means, sometimes particularly
large standard deviations bc values frequently unsatisfied clauses.
because, seen Figure 13, clauses often unsatisfied even
though removing affect backbone size all.
found experiments removal clauses along small random
bags clauses average reduce backbone size considerably. large standard
deviations therefore arise true backbone contribution clauses
apparent using simple measure.
261

fiSinger, Gent & Smaill

Cost
Percentile

Backbone
size

10th
20th
30th
40th
50th
60th
70th
80th
90th

16
11
13
36
48
25
63
70
93

clauses
uf mean
11.3430
13.1079
21.0207
22.9825
29.5615
36.2940
52.4198
92.2623
108.3124

uf std. dev.
8.0704
10.9596
16.3680
21.3118
25.9275
35.6327
48.1078
87.7827
127.1968

backbonecritical clauses
uf mean uf std. dev.
20.8703
8.8730
30.1817
16.8730
41.4660
21.1142
56.6841
27.4660
72.0704
38.7779
96.1664
54.3081
119.7691
66.8187
167.3428
149.8058
306.7200
198.6933

Table 6: Unsatisfaction frequencies clauses different cost percentile instances.

Cost
Percentile
10th
20th
30th
40th
50th
60th
70th
80th
90th

Backbone
size
16
11
13
36
48
25
63
70
93

clauses
bc mean
0.5921
0.4848
0.3963
1.8089
1.0629
1.3800
3.3916
0.6946
3.0653

bc std. dev.
1.2358
1.0380
1.2405
4.2411
3.2781
3.4920
8.8630
3.4577
10.0376

often
unsatisfied clauses
bc mean bc std. dev.
2.0909
1.8529
1.7727
1.9632
1.8409
2.4490
8.3182
6.4620
6.3182
6.6043
7.7500
5.7794
14.9091
15.8126
2.5909
7.8602
16.9318
20.6436

Table 7: Backbone contributions clauses different cost percentile instances.

262

fiBackbone Fragility Local Search Cost Peak

instances different costs satisfiability threshold, clauses
likely unsatisfied search higher backbone contribution average.
Conversely, clauses largest backbone contribution likely
unsatisfied search. section therefore demonstrates well explaining
differences cost instances, backbone fragility hypothesis also explain
differences difficulty satisfying particular clauses search.

8. Related Work
Clark et al. (1996) showed number solutions correlated search cost
number local search algorithms random instances different constraint problems,
including Random 3-SAT. pattern confirmed Hoos (1998) using improved
methodology. Clark et al.s work first step towards understanding variance
cost number constraints fixed. followed approach
looking number solutions using linear regression estimate strengths
relationships factors.
Schrag Crawford (1996) made early empirical study clauses (including
literals) entailed Random 3-SAT instances. Parkes (1997), whose study
also discussed Section 1, looked detail backbone size Random 3-SAT effect
local search cost. also linked position cost peak satisfiability
threshold emergence large-backbone instances occurs point. Parkes
also identified fall WSat cost instances given backbone size.
therefore basis study. Parkes conjectured presence failed cluster
may cause high WSat cost large-backbone Random 3-SAT instances.
According hypothesis, addition single clause could remove group solutions
Hamming distant remaining solutions, reducing size backbone
dramatically. clause would large backbone contribution. Therefore
explanation general high cost threshold region certain features common
Parkes conjecture. particular agree presence clauses
large backbone contribution causes high cost. especially demonstrated
results Section 7.
Frank et al. (1997) studied detail topology GSat search space induced
different classes random SAT instances. study discussed implications search
space structure future algorithms, well effects structures algorithms
GSat. also noted local search algorithms WSat may
blind structures studied search different ways GSat.
Yokoo (1997) also addressed question cost peak local search
m/n increased. approach analyse whole search space small satisfiable random instances. study, examined SAT, Yokoo also
showed results generalised colourability problem. Yokoo used deterministic
hill-climbing algorithm. studied number assignments solution
reachable (solution-reachable assignments) via algorithms deterministic moves,
largely determines cost algorithm.
followed Yokoo looking factor competing number solutions whose
effect cost changes m/n increased. factor Yokoo proposed cause
263

fiSinger, Gent & Smaill

overall fall cost decrease number local minima assignments
local move decreased number unsatisfied clauses. decrease
number demonstrated m/n increased. decrease attributed
decreasing size basins (interconnected regions local minima number
unsatisfied clauses). Yokoo claimed (p. 363) that:
adding constraints [...] makes [instance] easier decreasing number
local minima.
However, think clear priori relationship number
local minima cost given instance Yokoo study sufficiently
convince us explanation. contrast Yokoo, studied detail
relationship backbone fragility instances WSats cost instances
confirmed testing predictions hypothesis. Also, studied instance properties related logical structure clauses rather search space topology
induced think potential generalise across algorithms
even address complexity issues, explain towards end section.
Hoos (1998) also analysed search spaces SAT instances relation local search
cost looking two new measures induced objective function defined,
including one based local minima. Although via measures, Hoos able
account Random 3-SAT cost peak, found features correlated
cost SAT encodings problems also shown (Hoos, 1999b)
measures help distinguish alternative encodings problem.
pattern uncovered fit work makes instances
require high cost solve? Gent Walsh (1996) looked probability unsatisfiable SAT instance became satisfiable fixed number clauses removed random.
unsatisfiable instances highest computational cost complete procedure found unsatisfiability-fragile unsatisfiability
sensitive random removal clauses. may therefore fragility instances unsatisfiability backbone size cause high computational cost
context complete procedures incomplete local search, would interesting
link two algorithm classes. link may form basis possible explanation reasons threshold Random 3-SAT instances may universally hard
average case, opposed merely costly class algorithms. Recent work
Monasson et al. (1999a, 1999b) suggested parameterised distributions instances
hard average case, e.g. Random 3-SAT, exhibit discontinuity
backbone size3 control parameter varied, whereas polynomial time average-case
distributions, Random 2-SAT, backbone size changes smoothly. propose
complexity distribution linked presence discontinuity.
conjecture may asymptotic limit, instances backboneor unsatisfiability-fragile persist n increased discontinuity.
line research may therefore establish testable causal mechanism pattern,
showing properties instance distributions affect algorithm performance.
would interesting compare backbone fragility different random distributions
3-SAT instances, introduced Bayardo Schrag (1996) Iwama,
3. Monasson et al.s definition backbone also extends unsatisfiable instances.

264

fiBackbone Fragility Local Search Cost Peak

Miyano Asahiro (1996) see whether differences local search cost could explained.
method generates satisfiable instances quickly solved local search
analysed Koutsoupias Papadimitriou (1992) Gent (1998). Random clauses
added formula Random 3-SAT conflict certain
solution set advance. conjecture overconstrained examples
quickly solved local search backbone-robust.
interesting possibility mentioned Hoos Stutzle (1998) suggested exponential run length distribution, local search equivalent random generate-andtest drastically reduced search space. conjecture reduced search space
corresponds quasi-solution area. Measurements hdns(TB , C) quasi-solutions
TB may therefore indicative extensiveness reduced search space, especially
since metric linearly correlated log cost. experimentation vein
may therefore reveal topology reduced search space could
turn lead better local search algorithms designed exploit knowledge.
Finally, emphasise notions backbone backbone-fragility
equally applicable non-random SAT instances. future may able confirm
results shown random SAT instances apply equally benchmark realworld SAT instances. However, one caveat entailed literals may uncommon
instances may need study fragility sets entailed formulas.

9. Conclusion
reconsidered question cost local search peaks near Random
3-SAT satisfiability threshold. overall pattern one two competing factors.
cause onset high cost control parameter increased previously
established decreasing number solutions. proposed cause
subsequent fall cost falling backbone fragility.
found striking pattern search behaviour local search algorithm WSat.
instances given backbone size, underconstrained region control parameter, WSat attracted early quasi-solutions Hamming-distant
nearest solution. distance also strongly related search cost. control
parameter increased, distance decreases. suggested backbone fragility
cause pattern.
defined measure backbone robustness. Backbone-fragile instances low
robustness. able test predictions hypothesis fall backbone
fragility cause overall decay cost control parameter increased.
found hypothesis made three correct predictions. Firstly degree
instance backbone-fragile correlated cost effects factors
controlled for. Secondly, Random 3-SAT instances altered
backbone-fragile (by removing clauses without disrupting backbone) cost
increases. Thirdly, clauses often unsatisfied search whose
deletion effect backbone.
summarise interpretation evidence. underconstrained region,
instances small backbones predominant. region, rapid hill-climbing
phase typically results assignment close nearest solution (and probably
265

fiSinger, Gent & Smaill

satisfies backbone). Since finding small backbone largely accomplished hillclimbing, typical cost WSat low region variance cost due variance
density solutions region search space backbone satisfied.
threshold region, large-backbone instances quickly appear large quantities.
large-backbone instances, main difficulty local search identify backbone
rather find solution backbone identified. identification
large backbone may accomplished rapid hill-climbing phase greater lesser
extent. think extent determined backbone fragility instance.
large-backbone instance backbone-fragile hill-climbing phase ineffective
results assignment Hamming-distant nearest solution (probably
implying much backbone identified). costly plateau search
required find solution. Hence rare large-backbone instances occur
underconstrained region, extremely costly solve high backbone
fragility.
large-backbone instance backbone robust, rapid hill-climbing phase
effective determining backbone plateau phase shorter. overall
instance less costly WSat solve. Hence large-backbone instances, since
backbone fragility increases add clauses, cost decreases. overconstrained region,
large backbone instances dominant backbone fragility becomes main factor
determining cost. Hence cost decreases region. hypothesis proposes following
explanation cost peak: Typical cost peaks threshold region
appearance many large-backbone instances still moderately backbone-fragile,
followed increasing backbone robustness instances.

Acknowledgments
research supported UK Engineering Physical Sciences Research Council
studentship 97305799 first author. first two authors members crossuniversity Apes research group (http://www.cs.strath.ac.uk/~apes/). would like
thank members Apes group, anonymous reviewers
earlier paper Andrew Tuson invaluable comments discussions.

266

fiBackbone Fragility Local Search Cost Peak

Appendix A: Randomisation Bootstrap Tests
summarise methods used context. explanation methods
given Cohen (1995).
A.1 Randomisation Estimating Correlation Coefficient due
Distributions Variables
Randomisation used estimate correlation coefficient two variables
results simply distributions rather relationship. start
two vectors data x = hx1 , x2 , . . . , xN = hy1 , y2 , . . . , yN i. correlation
coefficient merely due distributions x y, dependent
particular xi paired yi . Therefore calculate correlation coefficient resulting
merely distributions pair x data randomly.
construct K randomisations. randomisation consists vector 0 ,
simply random permutation y. randomisation, calculate correlation
coefficient x 0 note value xi paired random value
y. randomised correlation coefficients give us estimate correlation
coefficients resulting distributions variables. K large enough,
accurate estimate compared correlation coefficient
observed data.
A.2 Bootstrap Estimation Confidence Intervals Correlation Coefficients
original sample h(x1 , y1 ), (x2 , y2 ), . . . (xN , yN )i N pairs. pseudo-sample
original also consists N pairs. j th pair pseudo-sample (xbj , yjb ) = (xq , yq )
q random number 1 N . pair pseudo-sample chosen
independently i.e. pairs sampled original replacement. assume
original sample pairs data representative whole population pairs.
Given this, composing pseudo-samples like sampling whole population.
Therefore measuring correlation coefficient many pseudo-samples, study
correlation coefficient would looked like taken many sets samples
whole population. distribution correlation coefficient among many
pseudo-samples (the bootstrap sampling distribution) infer bounds confidence
interval observed correlation coefficients.
Many pseudo-samples taken, correlation coefficient calculated
pseudo-samples. gives bootstrap sampling distribution correlation coefficient. 97.5th percentile distribution upper bound 95% confidence
interval correlation coefficient, 2.5th percentile lower bound.

Appendix B: Relationship BMSs MUSs
Let C satisfiable SAT instance {l1 , l2 , . . . , lk } set literals entailed
C. Let clause l1 l2 . . . lk .
Theorem C 0 BMS C iff C 0 MUS C 2
267

fiSinger, Gent & Smaill

Proof Suppose C 0 BMS C. C 0 d, sub-instance C d, must
unsatisfiable, violates every literal backbone C 0 . removed C 0 d,
result C 0 satisfiable. clause c removed C 0 d, must
literal backbone C 0 , li say, (C 0 {c}) li satisfiable. Therefore,
since li also literal d, (C 0 {c}) satisfiable. Therefore C 0 MUS
C d.
Conversely, suppose C 0 MUS C d. Since C 0 minimally unsatisfiable,
0
C satisfiable. Since C 0 sub-instance C, backbone C 0 must subset
backbone C. Suppose literal lj backbone C
backbone C 0 . would solution C 0 lj . would also
solution C 0 d, since lj one literal d. contradicts C 0 unsatisfiable
lj i.e. C 0 C must backbone.
C 0 minimally unsatisfiable. Therefore clause c C 0 , (C 0 {c})
satisfiable. solution (C 0 {c}) must make literal lk true, must
therefore also solution (C 0 {c}) lk . Therefore lk , backbone
C 0 , backbone (C 0 {c}). Hence C 0 BMS C 2

References
Bayardo, R. J., & Schrag, R. (1996). Using CSP Look-Back Techniques Solve Exceptionally Hard SAT Instances. Proceedings Second International Conference
Principles Practice Constraint Programming, pp. 4660. Springer.
Cheeseman, P., Kanefsky, B., & Taylor, W. (1991). Really Hard Problems Are.
Proceedings IJCAI-91, pp. 331340. Morgan Kaufmann.
Clark, D., Frank, J., Gent, I. P., MacIntyre, E., Tomov, N., & Walsh, T. (1996). Local Search
Number Solutions. Proceedings Second International Conference
Principles Practice Constraint Programming, pp. 119133. Springer.
Cohen, P. (1995). Empirical Methods Artificial Intelligence. MIT Press.
Cook, S. (1971). Complexity Theorem-Proving Procedures. Proc. 3rd Ann. ACM
Symp. Theory Computing, pp. 151158.
Cook, S., & Mitchell, D. (1997). Finding Hard Instances Satisfiability Problem:
Survey. Satisfiability Problem: Theory Applications, Vol. 35 DIMACS Series
Discrete Mathematics Theoretical Computer Science, pp. 1 18. American
Mathematical Society.
Crawford, J. M., & Auton, L. D. (1996). Experimental Results Crossover Point
Random 3SAT. Artificial Intelligence, 81, 3157.
Culberson, J., & Gent, I. P. (1999a). Completeness WalkSAT 2-SAT. Tech.
rep. APES-15-1999, APES Research Group.
Available http://apes.cs.strath.ac.uk/apesreports.html.
268

fiBackbone Fragility Local Search Cost Peak

Culberson, J., & Gent, I. P. (1999b). Well reach: hard problems hard. Tech.
rep. APES-13-1999, APES Research Group.
Available http://apes.cs.strath.ac.uk/apesreports.html.
Franco, J., & Paull, M. (1983). Probabilistic analysis Davis Putnam procedure
solving satisfiability problem. Discrete Applied Math., 5, 7787.
Frank, J., Cheeseman, P., & Stutz, J. (1997). Gravity Fails: Local Search Topology.
J. Artificial Intelligence Research, 7, 249281.
Gent, I. P. (1998). Stupid Algorithm Satisfiability. Tech. rep. APES-02-1998,
APES Research Group.
Available http://apes.cs.strath.ac.uk/apesreports.html.
Gent, I. P., MacIntyre, E., Prosser, P., & Walsh, T. (1996). Constrainedness Search.
Proceedings AAAI-96, pp. 246252. AAAI Press / MIT Press.
Gent, I. P., & Walsh, T. (1993). Empirical Analysis Search GSAT. J. Artificial
Intelligence Research, 1, 4759.
Gent, I. P., & Walsh, T. (1996). satisfiability constraint gap. Artificial Intelligence,
81, 5980.
Hogg, T., & Williams, C. P. (1994). hardest constraint problems: double phase
transition. Artificial Intelligence, 69, 359377.
Hoos, H. (1998). Stochastic Local Search - Methods, Models, Applications. Ph.D. thesis,
Darmstadt University Technology.
Hoos, H. (1999a). Run-time Behaviour Stochastic Local Search Algorithms
SAT. Proceedings AAAI-99, pp. 661666. AAAI Press / MIT Press.
Hoos, H. (1999b). SAT-Encodings, Search Space Structure, Local Search Performance.
Proceedings IJCAI-99, pp. 296302. Morgan Kaufmann.
Hoos, H., & Stutzle, T. (1998). Characterising Run-time Behaviour Stochastic Local
Search. Tech. rep. AIDA-98-01, Darmstadt University Technology.
Iwama, K., Miyano, E., & Asahiro, Y. (1996). Random generation test instances controlled attributes. Cliques, Coloring, Satisfiability, Vol. 26 DIMACS Series
Discrete Mathematics Theoretical Computer Science, pp. 377394. American
Mathematical Society.
Koutsoupias, E., & Papadimitriou, C. H. (1992). greedy algorithm satisfiability.
Information Processing Letters, 43 (1), 53 55.
Larrabee, T., & Tsuji, Y. (1992). Evidence Satisfiability Threshold Random 3CNF
Formulas. Tech. rep. UCSC-CRL-92-42, Jack Baskin School Engineering, University
California, Santa Cruz.
269

fiSinger, Gent & Smaill

McAllester, D., Selman, B., & Kautz, H. (1997). Evidence Invariants Local Search.
Proceedings AAAI-97, pp. 321326. AAAI Press / MIT Press.
Mitchell, D., Selman, B., & Levesque, H. (1992). Hard Easy Distributions SAT
Problems. Proceedings AAAI-92, pp. 459465. AAAI Press / MIT Press.
Monasson, R., Zecchina, R., Kirkpatrick, S., Selman, B., & Troyansky, L. (1999a). 2+PSAT: Relation Typical-Case Complexity Nature Phase Transition.
Random Structures Algorithms, 15, 414 440.
Monasson, R., Zecchina, R., Kirkpatrick, S., Selman, B., & Troyansky, L. (1999b). Determining computational complexity characteristic phase transitions. Nature, 400,
133137.
Papadimitriou, C. H. (1991). selecting satisfying truth assignment. Proc. 32nd
IEEE Symp. Foundations Comp. Sci., pp. 163169.
Parkes, A. (1997). Clustering Phase Transition. Proceedings AAAI-97, pp.
340345. AAAI Press / MIT Press.
Parkes, A., & Walser, J. (1996). Tuning Local Search Satisfiability Testing. Proceedings AAAI-96, pp. 356362. AAAI Press / MIT Press.
Schrag, R., & Crawford, J. (1996). Implicates prime implicates Random 3-SAT.
Artificial Intelligence, 81, 199222.
Selman, B., Kautz, H., & Cohen, B. (1994). Noise Strategies Improving Local Search.
Proceedings AAAI-94, pp. 337343. AAAI Press / MIT Press.
Walsh, T. (1998). Constrainedness Knife-Edge. Proceedings AAAI-98, pp. 406
411. AAAI Press / MIT Press.
Yokoo, M. (1997). Adding Constraints Makes Problem Easier Hill-Climbing
Algorithms: Analysing Landscapes CSPs. Proceedings Third International
Conference Principles Practice Constraint Programming, pp. 356370.
Springer.

270

fi
ff
fi
! #"$ %
'&)( *,+-*...0/21035476!(

89:;< =)( .0>
66!?A@: %&=CB0>
..

DFE<GHEJILKJM<NPORQLSTE
UWVYX[Z]\_^a`]b9VacedgfhVa\_b
ijb0fkValnmpo$Va\qZHrsZHVa\qZ,Va`<ZutAvjfkw
xzy${|ZHral}vjl~ijb0fkVbVdgln^alnmvjlnrqaWb
iZHZ]\_al}`

s$#52F<2

222Tjh$T2T$#

h'LC'A-nkhA0z LjA]'C


| 5A~5AH]
ff5ffAff
ff'AffJA,ffffffff

~j
!A$Aq,9
k 9zL9H5) 9A
a55957~05$0
H|ff-<A0zffj5)!j5)0zjA$-555 5-ff
9j5A#fi

799
ff!5ff-9|5A]55-ff
!A5n 59a0L!
|5


0!<
AL}5A]5HHA]n 9!#"ffhn
5$#5%99zz99!&'
#, 590~Ak9ffA ffAL-A
A599
!|5h5n5(

)* +-,.* /10&23465 7.89,;:<* /=,>5?890&54@0A* ,CB*D 2ff,.E=* 0F0&23'4G5 7.89,C5 7@HI2ff/JEK2LM0&23465 78N,POQ*7.2%*RL!5 7SR* /=E=,.S
LT5 7U7.2V-7.2ff,>2ff0W3.E=0&XA3.Y(2[Z>5$E=0\3](E=,>3>7PEKH-+&3.EK5$0^5 LQ*F_fi5$/=/K2ff_fi3.E=5$0`5 LQ7* 0-]&5$Sba*7E=*H-/=2ff,%E=0c3>27S?,U5 LQ3.Y&2
_fi5$0(](E=3.EK5$0(* /[](E=,.3>7EKH-+&3.E=5$0(,?LT5 7d2ff* _Yea*7E=*H-/K2^X$EKa 2ff0fa* /=+(2ff,gL!5 7hEK3.,jiV-*7.2ff0W3.kla*7E=*H-/=2ff,monQY&2
,>3>7+-_fi3.+&7.2 5 L93.Y&2p]-E=,>3>7EKHq+&3.EK5$0rE=,s7.2V-7.2ff,>2ff0W3>2ff]tX 7*V-Y-E=_* /=/KD@HWD[*C0(23'4G5 7.8tE=0[4CY-E=_Yt0(5N]&2ff,17.2V(7.2ff,>2ff0W3
a*7E=*H-/K2ff,r* 0(]^*7.754C,[*7.2

]&7P*ff4C0^LT7.5$SuV-*7.2ff0W3[0&5N](2ff,@3>5d_PY(E=/=]^0&59]&2ff,mtnCY&2ff,>2

*7.7.5v4C,r3'DNV-E=_* /=/=D

_fi5 7.7.2ff,.VI5$0-]R3>5;_* +(,.* /I7.2ff/=*3.E=5$0(,.Y(EKVq,mxw0R3.Y(2y,>3.* 0-](*7]zL!5 7S+(/=*3.E=5$0s{\3.Y&2r0&23465 7.8|E=,G0&5 3G* /J/K54G2ff]
3>5RY(*a 2U](E=7.2ff_fi3>2ff]g_fiDN_/=2ff,m
Y&2ff0R*%](E=,>3>7E=H-+&3.EK5$0E=,#,>V~2ff_E-2ff];HND
}

3>5g]&23>27S?EJ0&2%3.Y(*3r5$0&2

,.+(_PY?*t0&23465 7.8I{N3.Y&2C ',.2V-*7*3.EK5$0z_fi7EK3>27EK5$0R* /=/K54@,#5$0&2

,>23r5 L 7P* 0(]&5$Sua*7PE=*H-/K2ff,{~U{~EJ,@_fi5$0(]-EK3.EK5$0(* /=/=DEJ0(]&2V~2ff0(]&2ff0W3Q5 L6* 0(5 3.Y&27

,>23#5 Lq7* 0(]&5$Sa*7E=*H-/K2ff,ff{|{ X$EKa 2ff0;a* /=+&2ff,LT5 7 *y3.Y(EK7],>23#5 L-7P* 0(]&5$Sa*7PE=*H-/K2ff, ;mnQY(EJ,M_fi7E=3>27EK5$0
E=0Wa 5$/Ka 2ff,@5$0(/KD|3.Y&2%V(72ff,>2ff0(_fi2t5 7r*H-,>2ff0(_fi2U5 L#*7.7.54@,@E=0d3.Y&2U0&23465 78q{I0&5 3C3.Y&2]&23.* E=/K2ff]A0W+(S?27E=_* /
,>V~2ff_Eq_*3.E=5$05 L3.Y(2t_fi5$0(](EK3.EK5$0-* /s](E=,>3>7E=H-+&3.EK5$0(,ffmN22%2ff*7/6:ff $OLT5 7C*?]&23.* EJ/K2ff]g](E=,._+-,.,.EK5$0sm
2ff*7/* 0(]@2ff_PY\3>27F:ff $OY(*ffa 2g*3>3>2ffS

V(3>2ff]3>5F2fiN3>2ff0-]3.Y-E=,tLT7*

24G5 7.8`3>5^0&23'4G5 7.89,3.Y(*3

S?*DF_fi5$0W3.* E=0c]-EK7.2ff_fi3>2ff]_fiD9_/K2ff,{14CY-E=_Y_fi5 7.72ff,>V~5$0(]F3>5dL!22ff](H-* _.8^7.2ff/=*3.E=5$0(,.Y(EKVq,@*

5$0(Xga*7EJ*H-/K2ff,m

Y&2ff0`_fiD9_/K2ff,t2fi&E=,>3{M3.Y&2rZ>5$E=0\3t]-E=,>3>7EKHq+&3.EK5$0FE=,[0&5A/K5$0(X 27%,>V~2ff_E-2ff]^E=03>27PS?,[5 L3.Y&2
}

V(7.59](+(_fi3[5 L

_fi5$0(](E=3.EK5$0(* /~](E=,>3>7PEKH-+&3.EK5$0-, LT5 7C_Y(EJ/=]&7.2ff0|X$EKa 2ff0gVq*7.2ff0\3.,ff{&H-+&37*3.Y&27CHWD|,.*ffD9E=0&X?Y&5v4f3.Y&2[a* /=+&2ff,5 L
3.Y&2U5 H-,>27.a*H-/K2ta*7E=*Hq/K2ff,{(

(ffff I{q*72U]&23>27SRE=0&2ff]dHND3.Y&2%a* /=+&2ff,CL!5 7r*R,.23C5 L +(0&5 Hq,>27.a 2ff]
7* 0(](5$S](EJ,>3.+&7.H-* 0-_fi2ff,{s (ff MI{q4CY-E=_YF*7.2;* ,.,.+(S 2ff]A3>5HI2E=0(]&2V~2ff0(](2ff0\35 L 2ff* _PY^5 3.Y&27[* 0(]

3>5UY-*ffa 2@,.VI2ff_EK-2ff]?](E=,.3>7EKH-+&3.E=5$0(,mx&5 7G2ff* _Yza*7E=*H-/K2 {\
E=,2ffN+(* /s3>5|,>5$S

{N* 0?2ffN+(*3.EK5$0zE=,#X$EKa 2ff0z,>V~2ff_EKL!D9E=0&X[3.Y-*3pEK3

2tL<+(0(_fi3.E=5$0g5 L3.Y&2%_fi5 7.7.2ff,.VI5$0-](E=0&X| * 0(]d5 L,.5$S

2%,>23@5 LVq*7.2ff0\3Ca*7EJ*H-/K2ff,LT7.5$S

* 5$0&XR3.Y&2[%[4CE=3.Y?d
mp@,QHI2LT5 7.2 {&V-*72ff0\3'_PY(E=/=]g72ff/=*3.EK5$0(,.Y-EKV-,G*7.2t7.2V(72ff,>2ff0\3>2ff]dX 7*V-Y(E=_* /J/KD
HND|]&7P*ff4CE=0(X2ff](X 2ff,Q4CEK3.Yg*77.54C,CL!75$SoV-*7.2ff0W3Q0&59]&2ff,3>5R_PY(E=/=]g0&59]&2ff,m
w0?5 7](27 3>5US?*8 2y3.Y(E=,p,._Y&2ffS?2C4G2ff/=/']&2fiq0(2ff]s{$2ff*7/-* 0(]zy2ff_YW3>27G72ffW+(E=7.23.Y(*3pLT5 76* 0WD

a* /=+&2ff,

5 LM ff
* /=/93.Y&22ffN+(*3.EK5$0-, *7.2
( ff U3.Y&272QE=,2fi9* _fi3./=D5$0(2Q,>23 5 LIa* /=+(2ff,L!5 7 (ff ULT5 7 4CY(EJ_Y
,.*3.E=,>-2ff]smpwL3.Y(E=,Q+-0(E=N+&2ff0&2ff,.,_fi5$0(]-EK3.EK5$0gE=,@,.*3.E=,-2ff]1{(*R](E=,.3>7EKH-+&3.E=5$0R5va 27U
( M|4CE=/J/s]&2fiq0&2
*...z %%q!=n
=C0
Gj
!fi;]
p:! %&%' &0%2%J0 =v

fiy -

*t](EJ,>3>7EKH-+(3.EK5$0t5va 276 ( Impr0&2_* 0?3.Y(2ff0?* ,>84CY(*3 _fi5$0(](E=3.EK5$0(* /&E=0(](2VI2ff0-]&2ff0(_fi2GV(7.5 V~27.3.EK2ff,
3.Y(E=,]-E=,>3>7EKHq+&3.EK5$0|S?EKX$YW3VI5$,,>2ff,.,m
y__fi5 7](E=0(X3>5cnQY&25 7.2ffS^5 LrM2ff*7P/C* 0(]ly2ff_YW3>27`:ff $OP{CEKL@3.Y&2d

[*7.2d* /=/Q]-E=,._fi7.23>2 {G3.Y&2

a*7E=*H-/K2ff,Uo*7.2z_fi5$0-](EK3.EK5$0(* /J/KDhE=0-]&2V~2ff0(]&2ff0W3[5 L3.Y&2Ra*7E=*H-/=2ff,%X$EKa 2ff03.Y&2Ra*7E=*Hq/K2ff,EKL3.Y&2
a*7E=*H-/K2ff,C ',>2Vq*7*3>2%3.Y&2[a*7E=*Hq/K2ff,* 0(]g|m nQY&2t ',.2V-*7*3.EK5$0h_fi7EK3>27EK5$0g_* 0AH~2y2fi9V(7.2ff,,>2ff]
E=0^3>27SR,[5 L3.Y&2

L!5$/J/K54CEJ0&XgS?* 0(EKV-+-/=*3.EK5$0(,@5 L3.Y&2

X 7*V-Y4@EK3.Y0&59]&2ff,t_fi5 7.7.2ff,.VI5$0-](E=0&X|3>5d3.Y&2?



* 0(]g4@EK3.Yg*7.7.5v4C,LT7.5$SoV-*7.2ff0W3.,Q3>5z_Y(E=/J]&7.2ff0s
Oy2ff/K23>2* /=/s0&59]&2ff,LT7.5$So3.Y&2[X 7P*V-Yg2fi&_fi2V(3Q3.Y&5$,>2UE=0g%{qz{&5 7r* 0(]g3.Y(2ffEK7Q* 0(_fi2ff,>3>5 7,ffm
$Od)5$0(0&2ff_fi3QHND|* 0d2ff]&X 2t2a 27.DgV-* E=75 L0&59]&2ff,3.Y-*3C,.Y(*7.2t*R_fi5$S?S

5$0d_PY(E=/=]sm

OC2ffS 5a 2t*77.54C,GLT7.5$S* /=/-3.Y(2@2ff]&X 2ff,pEm2 mK{97.2V-/J* _fi2C2ff* _Yg]-EK7.2ff_fi3>2ff]|2ff]&X 2yHWDR* 0+(0-](EK7.2ff_fi3>2ff]
2ff](X 2
wL{~E=0h3.Y&2U72ff,.+(/K3.E=0(X?X 7*V-Ys{~* /=/MV-*3.Y(,@L!75$Su*|0&59]&2UEJ0h3>5*0&59]&2UE=0hV-* ,,C3.Y&75$+&X$Yh*0&59]&2
E=0A

{&3.Y&2ff0h$',>2V-*7*3>2ff,yeL!7.5$Szm
EKX$+&72^,.Y&5v4C,* 02fi9*

_fi5$+(0W3>27.2fi&*

Vq/K2h5 L*]-E=,>3>7EKHq+&3.EK5$0j]&2fiI0&2ff]EJ03.Y(EJ,z4*ffD {y4CY(EJ_Y,>27.a 2ff,g* ,g*

V-/K2d3>5c3.Y&2A_/=* E=S3.Y-*3z ',.2V-*7*3.EK5$0jEJS

V-/=EK2ff,;_fi5$0(]-EK3.EK5$0(* /E=0-]&2V~2ff0(]&2ff0(_fi2|L!5 7|* 0\D

0&23465 7.8F,.*3.E=,>LTD9E=0&X?3.Y&2;+(0(EJW+&2ff0(2ff,.,Q_fi5$0(](E=3.EK5$0sm@nCY&2%a*7E=*H-/=2ff,CE=0h3.Y(E=,C2fi9*
5 L6|5 7

m%nQY(2zp*7.2

Vq/K2* /J/13.*8 2

E=0(](2VI2ff0-]&2ff0\3y* 0(]^*7.2;2ffW+-* /=/KDd/=EK8 2ff/=Dg3>5gHI2;|5 7?mtnQY&2;

a* /=+&2ff,

6,*3.E=,>LTDd3.Y&2

2ffN+(*3.EK5$0(, ,Y&54C01{\E=04CY(E=_PY

* ](](EK3.E=5$0* 0-]?SU+-/K3.EKV-/=EJ_*3.EK5$0U*72Q]&5$0&2QS 59](+(/K5t :<Em2 mK{NE=0R * OPm @5 3>2
3.Y(*3r * {~ B {~{(* 0(] 3 ]&5?0&5 3Q*V(V~2ff*7QE=0|3.Y&2%2ffW+(*3.E=5$0(,{&* 0(]dY&2ff0-_fi2[V-/=*ffD|0&5 7.5$/K2[E=0g](2fiq0(E=0&X
(
3.Y&2%]-E=,>3>7EKHq+&3.EK5$0?LT5 7Q (
v 3
nQY(2%0&23'4G5 7.8d* 0(]d3.Y&2%2ffN+(*3.EK5$0(,@_/K2ff*7/KDY(*a 2%3.Y&2U7.2ffW+-EK7.2ff]g,>D90\3.* _fi3.EJ_tLT5 7Sgmnx5R,Y&54e3.Y(*3
3.Y(E=,yE=,y*Ra* /=E=]h2fi&*


LT5 7G3.Y(2@

V-/K2 {~EK3rE=,@* /J,>5|0(2ff_fi2ff,.,.*7.Dd3>5g,.Y(543.Y(*3r3.Y&2z +(0-E=W+(2ff/KD|](23>27S?E=0&2a* /=+&2ff,

m6r0&2y_* 02ff* ,.E=/KD?_fi5$0&-7S3.Y(*3GL!5 7* 0WDRa* /=+&2ff,65 Lx3.Y&2UM13.Y(2yLT5$/=/K5v4CE=0&X%a* /=+(2ff,6LT5 73.Y&2

4CE=/=/~,.*3.EJ,>L!D|* /=/s3.Y&2[2ffN+(*3.EK5$0-,


(
6


(


*




B






?




?









6p (



3

nM5R,>22[3.Y(*3Q3.Y-E=,E=,3.Y&2[5$0-/KDz,>23C5 LMa* /=+&2ff,LT5 7Q3.Y&2[

3.Y(*3@,.*3.E=,>LTDz* /=/~3.Y(2t2ffW+-*3.EK5$0(,{(0&5 3>2t-7,>3

* SU+(,.3tH~2R9{#,.E=0(_fi2RE=LGEK3UE=,%E=0-,>3>2ff* ]{3.Y&2ff0
4CY(EJ_Y^E=,rE=S V~5$,.,.E=H-/K2 m[C2ff0-_fi2 ? 3 9m;&E=0(_fi2; * 0(]F?

3.Y(*3U





R* 0(]c 3 {
3
{s462 * /=,.5d,>22;3.Y(*3

q~pvPvp[>fi %v>[CvrPv@~P[C#Px~K\1>fi fivx
P'1>A1vp#MvPv @P[#qvrvP'. !~P s#>
>yQPfix#vPv'.p<NQGv#<'#PPvv<'.pGffG<'
y&Py<' <'.#pPtJI~v vCff[&->yr #P>~>rv
'# T~rr9@ T~ %!1y1v#.ff6$xC#Pv1ff


fi F 22N-`~$--&7T-;
$ $\ $ 2

U1





B
(





*
(






?







:T

*





:T

*

p?O?

X3



X4



B

U5
X2


*

X1
U4

(


(

3

O\:T

3

X5
X6

X7

EKX$+&7.2?ry7*V-Y(EJ_* /C,>3>7+-_fi3.+&7.2A* 0(]2ffN+(*3.EK5$0(,RL!5 7|3.Y&2h_fi5$+-0\3>27.2fi&*

V-/=2 m@/J/Qa*7E=*H-/K2ff,?3.*8 2

a* /=+(2ff,tE=0 $m|nQY(2g *7.2|E=0(]&2V~2ff0(]&2ff0W3{s4CEK3.Y`2ffW+(* /pV(7.5 H-*HqE=/=EK3.EK2ff,@LT5 7UA* 0-]jm
@](]-EK3.EK5$0R* 0-]zS+(/K3.EKVq/=E=_*3.EK5$0?EJ,6]&5$0(2@S 59](+(/K5;Nm nQY&2%Mx* 0(]z3.Y&2r]&5 3>3>2ff]g*7.7.5v4C,*7.2
0&5 3QLT5 7S?* /=/KDRV-*7.3Q5 L3.Y&2tX 7*VqYs{&H-+&3Q*7.2t,Y&54C0dL!5 7C_/J*7EK3'D

* %E=S Vq/=EK2ff,3.Y(*3p * {\LT7.5$S4@Y(E=_YREK3 LT5$/=/K54@,#3.Y(*3 B ( {
,.E=0-_fi2[ ( (
23+(,U0&54 _fi5$0(,.EJ]&27%4CY(23.Y&27%5 7;0&5 3 z=E ,U_fi5$0(](EK3.EK5$0-* /=/KDhEJ0(]&2V~2ff0(]&2ff0W3[5 L??X$EKa 2ff0 *
} 2 _* 0^,>22U3.Y-*3@ ;* 0(]h?%*7.2; ',>2Vq*7*3>2ff]^HWDg * {~,.E=0-_fi2UE=0F,>3>2Vl:OC*H~5va 2 {s4624CE=/=/x]&2ff/K23>2



?C* 0-]?

3 * 0-]z* /=/-3.Y&2C2ff](X 2ff,G_fi5$0-0&2ff_fi3.E=0&XU3>5U3.Y&2ffSd{N/K2ff*aNEJ0&XU0&5UV-*3.YzL!7.5$S Q3>5?m C5v462a 27{
X$EKa 2ff0l* 0WDca* /=+&2|L!5 7; * { 3.Y(2za*7E=*H-/=2ff,U * 0(] *7.2gE=0cL<* _fi3?]&2V~2ff0(]&2ff0W3m@, ,.22ff0*H~5va 2 {

* 0WD,.23Q5 La* /=+(2ff,L!5 7C3.Y&2t

#,.*3.E=,>LTD9E=0&X;3.Y&2t2ffN+(*3.EK5$0(,CSU+(,.3QH~2t,.+(_Yd3.Y(*3Q

@2ff0(_fi2 {xEKL6

G? 9m
*
{s3.Y&2ff0cEK3yS+(,>3[H~2

3.Y(*3t

?E=,[]&23>27S?EJ0&2ff]^HWD

* 9{x3.Y&2ff0EK3[SU+-,>3rHI2;3.Y(*3r {x* 0(]E=LpE=0(,>3>2ff* ]F *
?

emz)G5$0-](EK3.EK5$0(* /5$0`*a* /=+&2 LT5 7[ * {x4G2 3.YN+(,t,>22?3.Y-*3[

?{(,.Y&5v4CE=0&X 3.Y-*3Q3.Y&2D*7.2%0&5 3C_fi5$0-](EK3.EK5$0(* /J/KDRE=0(](2VI2ff0-]&2ff0\3m



nQY(2V(7.5 H-/K2ffS*V(V~2ff*7,g3>5*7EJ,>2`H~2ff_* +(,>2`2a 2ff03.Y&5$+&X$Ye,>V~2ff_EKL!D9E=0&Xa* /=+&2ff,gLT5 7h* /=/t3.Y&2lM
{,.VI2ff_E=L!D9E=0&Xg*ha* /=+(2?L!5 7R ( * /=5$0&2z/K2ff*a 2ff,^,>23.,
5 La* /J+&2ff,[LT5 7z:T ( * B O@3.Y(*3,.*3.E=,>LTDh3.Y(2?2ffW+-*3.EK5$0(,t* ,.,.5N_E=*3>2ff]c4CEK3.Y^3.Y&2ff,.2?a*7PE=*H-/K2ff,{x2a 2ff0
3.Y&5$+&X$Y5$0(/KD5$0&2A,.23R5 L[a* /=+&2ff, 4CEJ/=/,.*3.E=,>LTD3.Y&2d2ff0W3.EK7.2F,>23R5 Lr2ffN+(*3.EK5$0(,m } Y(E=_PYla* /J+&2ff,?LT5 7
+(0(EJW+&2ff/=Dh]&23>27SRE=0&2ff,ta* /=+&2ff,%L!5 7* /=/ 3.Y(2R

:T

( * B *72dV-*7.3?5 Lr3.Y&2A5a 27* /=/@,>5$/=+&3.E=5$0l]&2V~2ff0(](, 5$0l3.Y(2da* /J+&2d5 LM[v{* 0(]j3.Y(E=,
ff
E=0(]-+(_fi2ff, *`]&2V~2ff0(]&2ff0-_fi2|H~234622ff0
Md* 0(]?
4CY&2ff03.Y&2da* /=+&2g5 Lr * E=,;890&5v4C0sm

nQY&2[72ffS

5a* /s5 LV-*7.35 L3.Y&2[X 7*V-YAE=0,>3>2V:OG5 L3.Y&2tV-7.5N_fi2ff]-+&7.2rL!5 7Q](23>27S?E=0(EJ0&X

',>2V-*7P*3.EK5$0

2ff/=E=SRE=0(*3>2ff,* 0WD|V~5$,.,EKH-E=/=E=3'D;5 L#* __fi5$+(0\3.EJ0&X?LT5 7Q3.Y(E=,]&2V~2ff0(](2ff0(_fi2
nQY(2[V(7.5 H-/K2ffS

4@EK3.Yg2ff*7/1* 0(]dy2ff_PY\3>27
,@V(7.5N5 L*V(V~2ff*7,Q_fi5$0(0&2ff_fi3>2ff]A4CEK3.Y3.Y(EJ,m nQY&2D,.*ffD {

3C3.Y(E=,V~5$E=0W3G4G2%E=0Wa 5 8 2t3.Y&2[L<* _fi3Q3.Y(*3C3.Y&2t_fi5$0(,>3>7* EJ0\3.,C5 L#)*72t0&5 3Q*7.H-EK3>7P*7.DRH-+(3
*72

LT+(0-_fi3.EK5$0(* /{10(* S?2ff/KD {sL!5 7%2a 27.Dha* /=+&2ff,r5 LfiffI3.Y&2


V-*72ff0\3.,[5 L -p* 0(]-G3.Y&27.2?EJ,

fiy -

*A,>5$/=+&3.EK5$0^LT5 7 qmRnCY(E=,rE=S

V-/JEK2ff,y3.Y(*3{xLT5 7%* 0WD^,.23

* ,,>5N_EJ*3>2ff]l4CEK3.Y0&5$09'* 0-_fi2ff,>3>5 7,;5 L



5 La*7E=*H-/=2ff,{s3.Y&2?2ffN+(*3.EK5$0(,

]&50&5 3?_fi5$0(,.3>7* E=03.Y&2V~27S?EK3>3>2ff]a* /=+&2ff,5 L

mmffm

nQY&2U2fi9* S?V-/K2UY(27.2U,.Y(54C,@3.Y(*3C3.Y(2U2ffN+(*3.EK5$0(,yE=0Wa 5$/Ka9E=0&X?0&5$09'* 0-_fi2ff,>3>5 7,y5 L
,>3>7* EJ03.Y&2tV~27S?EK3>3>2ff]a* /=+&2ff,QL!5 7

_* 0^E=0(]&22ff]A_fi5$09



+(]&2ff*M2ff*7P/;:TV~27,.5$0(* /@_fi5$SRSU+(0-E=_*3.EK5$0qORY(* ,,.+&X X 2ff,>3>2ff]3.Y-*3z3.Y&2$',>2V-*7*3.EK5$0_fi7E=3>27EK5$0
_* 0dH~2%,* /Ka*X 2ff]AHWD7.2ffN+(EK7PE=0&X

0&5 3C5$0-/KDz3.Y-*3t
( v M+(0(E=N+&2ff/KD|]&23>27S?E=0(2[ (ffff q{qH-+&3

g

_* 0hH~2t5 H(3.* E=0&2ff]dHWDd* V-7.5N_fi2ff]-+&7.2%E=0d4CY(E=_PYg3.Y&2
(ffff

* /=,>5R3.Y(*3C3.Y(EJ,C+(0(EJW+&2[,>5$/J+&3.EK5$0gLT5 7C


*7.2?+&Vs](*3>2ff]E=0* __fi5 7P](* 0(_fi2R4@EK3.YF3.Y&2R_* +(,.* /p,>3>7+(_fi3.+&72
]&D90(* S?E=_* /qV(7.59_fi2ff](+&72 {W2ff* _PYg
_fi5 7.7.2ff,.VI5$0-](E=0&Xg6* 0(]F3.Y&2

5 L63.Y&2?0(23'4G5 7.8qmRw0`,+(_Y`*g_* ,+(* /

ME=,67.2V~2ff*3>2ff](/KDR7.2V-/=* _fi2ff]|HND?3.Y&2ra* /J+&2y_fi5$S?V-+&3>2ff]|L!5 7QE=36LT7.5$S3.Y&2

_+&77.2ff0\3ya* /=+&2ff,y5 LpEK3.,yV-*7.2ff0W3.,{1* __fi5 7]-E=0&X|3>5|3.Y(22ffN+(*3.EK5$0FLT5 7r3.Y(*3

{-+(0W3.E=/s*?,>3.*H-/=2t,>3.*3>2%E=,72ff* _Y&2ff]sm6nQY&2-5v45 LE=0&LT5 7S?*3.EK5$0gE=0g,+(_Yd*?V(7.59_fi2ff](+&7.2rLT5$/=/K54@,3.Y&2


](EK72ff_fi3.EK5$0A5 Lp3.Y&2*77.54C,rE=0A3.Y&2;0&23'4G5 7.8Imt)5$0(,>2ffN+&2ff0\3./=D {~0(5N]&2ff,@3.Y(*3r*7.2

0&5 3r* 0(_fi2ff,>3>7* /3>5g* 0\D

0&59]&2;5 LE=0\3>272ff,>3t_* 0`Y(*a 2R0&5dE=0I+&2ff0(_fi2;5$03.Y&2ff,>2?0(5N]&2ff,ff{9Z>+-,>3.EKLTDNE=0(Xz3.Y&2ffE=7[2ff/=E=S?E=0-*3.EK5$0hEJ0,>3>2V
:OG5 L3.Y&2tV-7.5N_fi2ff]-+&7.2rL!5 7@]&23>27S?E=0-E=0&X; ',>2V-*7P*3.EK5$0sm
w0|X 2ff0&27* /{&4CY(23.Y&275 7Q0&5 3,.+(_PYg*](DN0(* SRE=_* /IV(7.59_fi2ff](+&7.2y2a 2ff0\3.+-* /=/KD?I0(](,63.Y&2t,>5$/=+&3.E=5$0RLT5 7


( ff S?*DR]&2V~2ff0(];5$0z4CY&23.Y&2763.Y&2Q 1*7.2y+&Vs](*3>2ff]?,.E=S+(/K3.* 0(25$+(,./KD5 76,>2ffN+&2ff0W3.E=* /=/KD {N* 0(]
ff
EKL3.Y&2Dg*7.2+&Vs](*3>2ff]d,>2ffN+&2ff0W3.E=* /=/KD {q5$0d3.Y&2U5 7]&27C5 L3.Y&2ff,.2U+&Vs](*3>2ff,m&5 7yV(7.2ff,.2ff0\3@V-+&7.V~5$,>2ff,{(E=3CE=,

,.+|_EK2ff0\363.Y(*3!t+&Vs](*3.E=0&X%,_Y&2ffS

2r2fi&E=,>363.Y(*3E=,pX$+-*7* 0\3>22ff]1{NLT5 7* 0\DRa* /=+(2ff,p5 L# ff
( ff MI{
3>5l/K2ff* ]3>53.Y(2F+(0-E=W+(2A,>5$/=+&3.E=5$0s{Q,>3.*7.3.E=0(Xc4CEK3.Y* 0WDE=0(EK3.EJ* /Qa* /=+&2ff,zL!5 7| (ff ImewLt,.+(_PY
* 0+&Vs](*3>25 7]&27r2fi&E=,>3.,{1$',>2V-*7*3.EK5$0^4@E=/=/xEJS
*H~5a 2 {s* 0WDA+&Vs](*3.E=0&X
a* /=+&2ff,?5 L[?h* 0(]j
_fi5$0(](E=3.EK5$0sm

5 7P]&27@4@E=/=/sLT5 7y,.5$S
3

V-/KDg_fi5$0(](E=3.EK5$0(* /E=0(]&2V~2ff0(]&2ff0-_fi2 myw0F3.Y&2;2fi9* S?V-/K2

2EJ0(EK3.E=* /s,>3.*3>2

/K2ff* ]h3>5_fiDN_/=EJ_tH~2ffY(*ffa9EK5$+&7yE=0d4@Y(E=_YA3.Y&2

qEKVjHq* _.8j* 0(]L!5 73.Ys{,>5c3.Y&2h2fi9* S?V-/K2h](5W2ff,|0&5 3z,*3.E=,>LTD3.Y-E=,R,>3>75$0&X 27

r0(2%,.Y&5$+(/J]g0&5 3>2%3.Y(*3@3.Y&2%2fi&*

V-/=2%E=0g3.Y(EJ,Q0&5 3>2U](5W2ff,@0&5 3CE=0Wa* /JE=](*3>2[3.Y&2U7.2ff,.+(/K35 L69V-EK7.3>2ff,

:ff #"$O@3.Y(*3y ',>2V-*7P*3.EK5$0^_* 0AH~2U+-,>2ff]d3>5]&23>27S?EJ0&2%_fi5$0(](E=3.EK5$0(* /1E=0-]&2V~2ff0(]&2ff0(_fi2tE=0h/=E=0&2ff*7@0&23
4G5 7.8N,R5 Ly0(5 7S?* /=/KD](E=,>3>7PEKH-+&3>2ff]a*7E=*H-/K2ff,;2a 2ff0EKL@3.Y&2Dl_fi5$0\3.* E=0_fiDN_/=2ff,mw0l3.Y&2A,*
NV-E=7.3>2ff,[* /=,>5gX$*a 2z*g_fi5$+(0W3>27.2fi&*

V-/K2R,Y&54CEJ0&X3.Y(*3% ',.2V-*7*3.EK5$00&22ff]0&5 3%E=S?V-/KDA_fi5$0(]-EK3.EK5$0(* /

E=0(](2VI2ff0-]&2ff0(_fi2RE=00&5$09'/JE=0&2ff*7U0(23'4G5 7.8N,;5 L@_fi5$0\3.E=0N+&5$+(,U7* 0(](5$S
nQY(EJ,

V(7.5 H-/=2ffS

2dV-*V~27ff{

_* 0(0&5 3zHI2h*ffa 5$E=]&2ff]HND,E=S

a*7E=*Hq/K2ff,t3.Y(*3

_fi5$0W3.* E=0_fiDN_/=2ff,m

V-/KD](E=,._fi723.E%$ffE=0&X3.Y&2F_fi5$0\3.EJ0W+&5$+-,?a*7E=*H-/K2ff,ff{G* ,z3.Y&2

V(7.5 Hq/K2ffS72ff*V(V~2ff*7,rE=0A3.Y(2LT5 7Su5 L60(5$092fi9EJ,>3>2ff0(_fi25 7t0&5$09'+(0(EJW+&2ff0(2ff,.,Q5 LG,>5$/=+&3.EK5$0-,m[nQY(E=,@0&5 3>2
,.Y&5v4C,#3.Y(*36E=0

0&5$09'/=EJ0&2ff*7 0&23'4G5 7.89, 5 L~](E=,._fi723>2Qa*7PE=*H-/K2ff,#*[,>3>75$0&X 276_fi5$0(]-EK3.EK5$0;3.Y(* 0?+-0(E=N+&2ff0&2ff,.,

E=,7.2ffN+(EK72ff];L!5 7p$',>2V-*7*3.E=5$0?3>5tH~2a* /JE=]sm@/K3.Y(5$+&X$Y

,.+(_PY?*t,>3>7.5$0(X 27p_fi5$0(](EK3.E=5$0

]&D90(* S?E=_,;_* 0lH~2,>22ff0j* ,?0-*3.+&7* /{ 3.Y(20(22ff]3>5a 27EKLTDc3.Y(E=,
3.Y&2*3>3>7* _fi3.EKa 2ff0&2ff,,

E=0\a 5$/=aNE=0(Xr_* +-,.* /

,.3>7.5$0&X 27?_fi5$0(](E=3.EK5$0]&5W2ff,;72ff](+(_fi2

5 LC0&23465 7.89,;4CEK3.Y_fiD9_/K2ff,;* ,*F4*ffD5 LQL!5 7PS?* /=E%$ffE=0(XA_* +(,.* /,.EK3.+-*3.EK5$0(,U4CEK3.Y

LT22ff]&H-* _.8Im



'&)(*,+.-0/,132546/7(J

wC3.Y-* 0&8h23>27NVqEK7.3>2ff,r* 0(]^nQY&5$S?* ,[@E=_Y-*7](,>5$0FLT5 7tY&2ff/KV(L<+(/x_fi5$SRS

2ff0\3.,ffm;nCY(E=,@465 7.8h4G* ,%,.+&V&

V~5 7.3>2ff]HND^3.Y&2zy*3.+&7* /9_EK2ff0(_fi2ff,U* 0(]98p0(X$E=0&227E=0(XC2ff,>2ff*7_PYl)5$+(0(_E=/5 LC)* 0(* ]-*d* 0(]`HND^3.Y&2
w0(,>3.EK3.+&3>2[LT5 7CC5 HI5 3.EJ_,Q* 0(]gw0\3>2ff/J/=EKX 2ff0W3Q9DN,>3>2ffSR,m

;:

fi F 22N-`~$--&7T-;
$ $\ $ 2

< />=?/$'/,(,/2
2ff*7/{ mt:ff $OPmA@CBDFEHGFEJILKMILNIPOQRHGJS>ITSVU6ILSXWYS,0KTKZI%UVJS,\[,]0^`_a
Bcbde?fg@CK%GhiYIjEKk

WYS
f
BHS7ONfimG&* 0mlh*3>25&{s)* /=EKLT5 70(EJ*9nlh5 7.X$* 0.ot* +&L<S?* 0(0sm

2ff*7/{ m* 0-]y2ff_PY\3>27ff{Ntm(:ff $OPm w]&2ff0W3.EKL!D9E=0&X@E=0(]&2V~2ff0(]&2ff0-_EK2ff,xE=0_* +(,.* /9X 7P*V-Y(,4CEK3.YUL!22ff](H-* _.8Im
w0!8QmNC5 7aNEK3D$r* 0(]z6m 2ff0-,>2ff0h:T2ff](E=3>5 7,PO\pqS7ONBjGILS7]rILStsBI uOJIPGK>WYS,0KTKZI%UVJS7OY;^@vB?;OYccwITSVU

?fxTyz|{5K fNTye})S
f
BHS~OYfimlA5 7X$* 0got* +&L<S?* 0(01{NV-V1mz\j\ Nm

NV-E=7.3>2ff,{mW:ff #"$OPm rEK7.2ff_fi3>2ff]%_fiDN_/=EJ_X 7*V-Y(E=_* /72V(7.2ff,>2ff0W3.*3.EK5$0(,s5 L9LT22ff]&H-* _8rS?5N]&2ff/J,m1w0[MmvB62ff,0(*7]
Imvy* 0&89,:T2ff](EK3>5 7,POfip5S~OYBjGITS,]ITSsBI uOJIPGKFWYS,0KTKZI%UVJS7OY;^@CBD
ONcHw#ILSVU#R?fvTyvK%JJS,Ty
})S
f
BHS~OYfimlA5 7X$* 0got* +&L<S?* 0(01{NV-V1m\9j\ Nm

* 0(]



fiJournal Artificial Intelligence Research 12 (2000) 149198

Submitted 11/99; published 3/00

Model Inductive Bias Learning
Jonathan Baxter

J ONATHAN .BAXTER @ ANU . EDU . AU

Research School Information Sciences Engineering
Australian National University, Canberra 0200, Australia

Abstract
major problem machine learning inductive bias: choose learners hypothesis space large enough contain solution problem learnt, yet small
enough ensure reliable generalization reasonably-sized training sets. Typically bias
supplied hand skill insights experts. paper model automatically
learning bias investigated. central assumption model learner embedded
within environment related learning tasks. Within environment learner sample
multiple tasks, hence search hypothesis space contains good solutions
many problems environment. certain restrictions set hypothesis
spaces available learner, show hypothesis space performs well sufficiently
large number training tasks also perform well learning novel tasks environment. Explicit bounds also derived demonstrating learning multiple tasks within
environment related tasks potentially give much better generalization learning single
task.

1. Introduction
Often hardest problem machine learning task initial choice hypothesis space;
large enough contain solution problem hand, yet small enough ensure
good generalization small number examples (Mitchell, 1991). suitable bias
found, actual learning task often straightforward. Existing methods bias generally
require input human expert form heuristics domain knowledge (for example,
selection appropriate set features). Despite successes, methods
clearly limited accuracy reliability experts knowledge also extent
knowledge transferred learner. Thus natural search methods
automatically learning bias.
paper introduce analyze formal model bias learning builds upon
PAC model machine learning variants (Vapnik, 1982; Valiant, 1984; Blumer,
Ehrenfeucht, Haussler, & Warmuth, 1989; Haussler, 1992). models typically take
training data
following general form: learner supplied hypothesis space
drawn independently according underlying distribution

. Based information contained , learners goal select hypothesis
minimizing measure
expected loss respect (for example, case squared loss
). models learners
bias represented choice ; contain good solution problem, then,
regardless much data learner receives, cannot learn.
course, best way bias learner supply containing single optimal hypothesis. finding hypothesis precisely original learning problem,

ff
fi
fifi fi
!"
#%$ '
&("

@



#

)

*
+
#
$
,/.1032 46587 + # 9;:<=?>
) *+ -

c 2000 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.





fiBAXTER

PAC model distinction bias learning ordinary learning. put differently,
PAC model model process inductive bias, simply takes hypothesis space
given proceeds there. overcome problem, paper assume instead
faced single learning task, learner embedded within environment
related learning tasks. learner supplied family hypothesis spaces
,
) appropriate entire environment.
goal find bias (i.e. hypothesis space
simple example problem handwritten character recognition. preprocessing stage
identifies removes (small) rotations, dilations translations image character
advantageous recognizing characters. set individual character recognition
problems viewed environment learning problems (that is, set problems
form distinguish characters, distinguish B characters,
on), preprocessor represents bias appropriate problems environment.
likely many currently unknown biases also appropriate
environment. would like able learn automatically.

DC

B

many examples learning problems viewed belonging environments related problems. example, individual face recognition problem belongs
(essentially infinite) set related learning problems (all individual face recognition problems); set individual spoken word recognition problems forms another large environment,
set fingerprint recognition problems, printed Chinese Japanese character recognition problems, stock price prediction problems on. Even medical diagnostic prognostic
problems, multitude diseases predicted pathology tests, constitute
environment related learning problems.
many cases environments normally modeled such; instead treated
single, multiple category learning problems. example, recognizing group faces would
normally viewed single learning problem multiple class labels (one face
group), multiple individual learning problems. However, reliable classifier
individual face group constructed easily combined produce
classifier whole group. Furthermore, viewing faces environment related
learning problems, results presented show bias learnt good
learning novel faces, claim cannot made traditional approach.
point goes heart model: concerned adjusting learners
bias performs better fixed set learning problems. process fact
ordinary learning richer hypothesis space components labelled bias
also able varied. Instead, suppose learner faced (potentially infinite) stream
tasks, adjusting bias subset tasks improves learning performance
future, yet unseen tasks.
Bias appropriate problems environment must learnt sampling
many tasks. single task learnt bias extracted likely specific
task. rest paper, general theory bias learning developed based upon idea
learning multiple related tasks. Loosely speaking (formal results stated Section 2),
two main conclusions theory presented here:

E

Learning multiple related tasks reduces sampling burden required good generalization,
least number-of-examples-required-per-task basis.
150

fiA ODEL NDUCTIVE B IAS L EARNING

E

Bias learnt sufficiently many training tasks likely good learning novel
tasks drawn environment.

second point shows form meta-generalization possible bias learning. Ordinarily, say learner generalizes well if, seeing sufficiently many training examples,
produces hypothesis high probability perform well future examples
task. However, bias learner generalizes well if, seeing sufficiently many training tasks produces hypothesis space high probability contains good solutions novel tasks. Another
term used process Learning Learn (Thrun & Pratt, 1997).
main theorems stated agnostic setting (that is,
necessarily contain
hypothesis space solutions problems environment), also give improved
bounds realizable case. sample complexity bounds appearing results stated
terms combinatorial parameters related complexity set hypothesis spaces
available bias learner. Boolean learning problems (pattern classification) parameters
bias learning analogue Vapnik-Chervonenkis dimension (Vapnik, 1982; Blumer et al.,
1989).
application general theory, problem learning appropriate set neuralnetwork features environment related tasks formulated bias learning problem.
case continuous neural-network features able prove upper bounds number
training tasks number examples training task required ensure set features
works well training tasks will, high probability, work well novel tasks drawn

environment. upper bound number tasks scales
measure complexity possible feature sets available learner, upper

number
bound number examples task scales
examples required learn task true set features (that is, correct bias) already
known, number tasks. Thus, case see number related tasks
learnt increases, number examples required task good generalization decays
minimum possible. Boolean neural-network feature maps able show matching
lower bound number examples required per task form.





F JILKMGONPQ

P

F HG
F JIR

G

1.1 Related Work
large body previous algorithmic experimental work machine learning
statistics literature addressing problems inductive bias learning improving generalization
multiple task learning. approaches seen special cases of, least
closely aligned with, model described here, others orthogonal. Without
completely exhaustive, section present overview main contributions. See Thrun
Pratt (1997, chapter 1) comprehensive treatment.

E

Hierarchical Bayes. earliest approaches bias learning come Hierarchical Bayesian
methods statistics (Berger, 1985; Good, 1980; Gelman, Carlin, Stern, & Rubim, 1995).
contrast Bayesian methodology, present paper takes essentially empirical
process approach modeling problem bias learning. However, model using mixture
hierarchical Bayesian information-theoretic ideas presented Baxter (1997a),
similar conclusions found here. empirical study showing utility
hierarchical Bayes approach domain containing large number related tasks given
Heskes (1998).
151

fiE

BAXTER

E

Early machine learning work. Rendell, Seshu, Tcheng (1987) VBMS Variable Bias
Management System introduced mechanism selecting amongst different learning
algorithms tackling new learning problem. STABB Shift Better Bias (Utgoff, 1986) another early scheme adjusting bias, unlike VBMS, STABB
primarily focussed searching bias applicable large problem domains. use
environment related tasks paper may also interpreted environment
analogous tasks sense conclusions one task arrived analogy
(sufficiently many of) tasks. early discussion analogy context, see Russell (1989, S4.3), particular observation analogous problems
sampling burden per task reduced.
Metric-based approaches. metric used nearest-neighbour classification, vector
quantization determine nearest code-book vector, represents form inductive bias.
Using model present paper, extra assumptions tasks
environment (specifically, marginal input-space distributions identical
differ conditional probabilities assign class labels), shown
optimal metric distance measure use vector quantization onenearest-neighbour classification (Baxter, 1995a, 1997b; Baxter & Bartlett, 1998). metric
learnt sampling subset tasks environment, used
distance measure learning novel tasks drawn environment. Bounds
number tasks examples task required ensure good performance novel
tasks given Baxter Bartlett (1998), along experiment metric
successfully trained examples subset 400 Japanese characters used
fixed distance measure learning 2600 yet unseen characters.
similar approach described Thrun Mitchell (1995), Thrun (1996),
neural networks output trained match labels novel task, simultaneously
forced match gradient derivative information generated distance metric
trained previous, related tasks. Performance novel tasks improved substantially
use derivative information.

E

E

Note many adaptive metric techniques used machine learning,
focus exclusively adjusting metric fixed set problems rather learning
metric suitable learning novel, related tasks (bias learning).
Feature learning learning internal representations. adaptive metric techniques,
many approaches feature learning focus adapting features fixed task
rather learning features used novel tasks. One cases features
learnt subset tasks explicit aim using novel tasks
Intrator Edelman (1996) low-dimensional representation learnt set
multiple related image-recognition tasks used successfully learn novel tasks
kind. experiments reported Baxter (1995a, chapter 4) Baxter (1995b),
Baxter Bartlett (1998) also nature.
Bias learning Inductive Logic Programming (ILP). Predicate invention refers process ILP whereby new predicates thought useful classification task hand
added learners domain knowledge. using new predicates background domain knowledge learning novel tasks, predicate invention may viewed form
152

fiA ODEL NDUCTIVE B IAS L EARNING

inductive bias learning. Preliminary results approach chess domain reported
Khan, Muggleton, Parson (1998).

E

E

Improving performance fixed reference task. Multi-task learning (Caruana, 1997)
trains extra neural network outputs match related tasks order improve generalization
performance fixed reference task. Although approach explicitly identify
extra bias generated related tasks way used learn novel tasks,
example exploiting bias provided set related tasks improve generalization
performance. similar approaches include Suddarth Kergosien (1990), Suddarth
Holden (1991), Abu-Mostafa (1993).

E

Bias computational complexity. paper consider inductive bias samplecomplexity perspective: learnt bias decrease number examples required
novel tasks good generalization? natural alternative line enquiry runningtime computational complexity learning algorithm may improved training
related tasks. early algorithms neural networks vein contained Sharkey
Sharkey (1993), Pratt (1992).
Reinforcement Learning. Many control tasks appropriately viewed elements sets
related tasks, learning navigate different goal states, learning set
complex motor control tasks. number papers reinforcement learning literature
proposed algorithms sharing information related tasks improve average
generalization performance across tasks Singh (1992), Ring (1995), learning bias
set tasks improve performance future tasks Sutton (1992), Thrun Schwartz
(1995).

1.2 Overview Paper
Section 2 bias learning model formally defined, main sample complexity results
given showing utility learning multiple related tasks feasibility bias learning.
results show sample complexity controlled size certain covering numbers
associated set hypothesis spaces available bias learner, much way
sample complexity learning Boolean functions controlled Vapnik-Chervonenkis
dimension (Vapnik, 1982; Blumer et al., 1989). results Section 2 upper bounds
sample complexity required good generalization learning multiple tasks learning
inductive bias.
general results Section 2 specialized case feature learning neural networks Section 3, algorithm training features gradient descent also presented.
special case able show matching lower bounds sample complexity
multiple task learning. Section 4 present concluding remarks directions future
research. Many proofs quite lengthy moved appendices
interrupt flow main text.
following tables contain glossary mathematical symbols used paper.
153

fiBAXTER

Symbol



U

"

Description
Input Space
Output Space
Distribution
(learning task)
Loss function
Hypothesis Space
Hypothesis
Error hypothesis distribution
Training set
Learning Algorithm
Empirical error training set
Set learning tasks
Distribution learning tasks
Family hypothesis spaces
Loss hypothesis space environment
-sample
Empirical loss
Bias learning algorithm
Function induced
Set
Average

Set
Set
Function probability distributions
Set
Pseudo-metric
Pseudo-metric
Covering number
Capacity
Covering number
Capacity
Sequence hypotheses
Sequence distributions
Average loss
Average loss
Set feature maps
Output class composed feature maps
Hypothesis space associated
Loss function class associated
Covering number
Capacity
Pseudo-metric feature maps
Covering number

ST"

#
#
) * + #
V
#
)Y W *X #

Z

)\ *[
P]fi^_
W)*a`
\
V
#b
#
b
#b
#
2 b fifi # c 2 b
#
fifi #Rc b
#
fifi #Rc b
dQb c
bc
# c
fifi #=c b
b
b
TeA
e
e
cb
fA g
f[
e

h Jijfi e fi f [
e
k Jijfi e c
eA
cb
h Jijfi c b fi flg

c
Jijfi b
AP b

n
P
g)*
n
\
W)* `

p
psr q
pb
h Jijfi p b fi f +
pb
k Hijfi p b
pb
ft + 2 uvxw q fi qzy
h Jijfi fi f=t + 2 uv{w






U

#
fifi #=c

fifi c

154

qp

q fi qzy

q

Z

First Referenced
155
155
155
155
155
155
156
156
156
156
157
157
157
158
158
158
159
159
159
159
159
159
159
160
160
160
160
160
160
160
160
163
163
164
164
166
166
166
166
166
166
166
166

fiA ODEL NDUCTIVE B IAS L EARNING

hSymbol

Jijfi fi f + 2 uv{w8 Description
Covering number
k uv Jijfi

Capacity
}|
Neural network hypothesis space
~ 0
restricted vector
^_
Growth function

Vapnik-Chervonenkis dimension
~
restricted matrix
~ P]fi^_
restricted matrix
Growth function
f PQ
Dimension function
f
Upper dimension function
f c
Lower dimension function cof
n
= g
Optimal performance

f

#
/ #=c Metric
#
#Rc
Average
, ,
c
#
=
#
c

3
Set
/
. > 2c 5
Permutations integer pairs
\j
Permuted \
f ` fi
U

Empirical
metric functions
W)* g
n
Optimal average error

First Referenced
166
166
167
172
172
172
173
173
173
173
173
173
175
179
179
180
182
182
182
185

2. Bias Learning Model
section bias learning model formally introduced. motivate definitions, first
describe main features ordinary (single-task) supervised learning models.
2.1 Single-Task Learning
Computational learning theory models supervised learning usually include following ingredients:

E

input space

E



Ss"
E loss function U$ "s"&D ,
probability distribution

E

hypothesis space

"

output space

,

,

set hypotheses functions

#$ &"

.

example, problem learn recognize images Marys face using neural network,
would set images (typically represented subset
component
pixel intensity), would set
, distribution would peaked images
different faces correct class labels. learners hypothesis space would class
neural networks mapping input space

. loss case would discrete loss:



"

fi

fi

U zfi $ L






155



]

(1)

fiBAXTER

fi U
U fi ] L: >

"

"

Using loss function allows us present unified treatment pattern recognition (
, above), real-valued function learning (e.g. regression)
usually
.
goal learner select hypothesis
minimum expected loss:

# CT

(2)
)* + # $ B U # fi= f QfiR
#
minimizing
course, learner know cannot search
)* + # . practice, learner samples repeatedly " according distribution
generate training set
$
fi
fifi fi j
(3)
# CT . Hence, general
Based information contained learner produces hypothesis
V
learner simply map set training samples hypothesis space :
V $ DT" &

V
(stochastic learners treated assuming distribution-valued .)
#
Many algorithms seek minimize empirical loss , defined by:


W)* X # $ ^ U # fi
(4)


course, intelligent things data simply minimizing empirical
errorfor example one add regularisation terms avoid over-fitting.
However learner chooses hypothesis , uniform bound (over
)
probability large deviation

, bound learners genas function empirical loss training set
. Whether
eralization error
bound holds depends upon richness . conditions ensuring convergence

well understood; Boolean function learning (
, discrete
loss), convergence controlled VC-dimension1 :

) W * X #

)*+ #
) * + #

#
W) *X #

# C

) *+ #

) W *X #
" Bfi

fi suppose
probability distribution
ff
fi
6fifi fibe isanygenerated
^
times fi according . Let
f$ = . probabilityby atsampling
least : (over choice training set ),
# C satisfy

>
^
#
#

f


W
(5)
)* + )* X ffKO^ f K

Theorem 1. Let

Proofs result may found Vapnik (1982), Blumer et al. (1989),
reproduced here.

aJ3













1. VC dimension class Boolean functions
largest integer exists subset
restriction contains Boolean functions .

156



fiA ODEL NDUCTIVE B IAS L EARNING

)*+ #

) *+ #

) W *X #

Theorem 1 provides conditions deviation


actually small.
likely small, guarantee true error
governed choice . contains solution small error learner minimizes
error training set, high probability
small. However, bad choice
mean hope achieving small error. Thus, bias learner model2
represented choice hypothesis space .

)*+ #

2.2 Bias Learning Model
main extra assumption bias learning model introduced learner embedded environment related tasks, sample environment generate multiple
training sets belonging multiple different tasks. model ordinary (single-task)

. bias learning
learning, learning task represented distribution
model, environment learning problems represented pair
set
(i.e., set possible learning problems),
probability distributions
distribution . controls learning problems learner likely see3 . example,
learner face recognition environment, highly peaked face-recognition-type
problems, whereas learner character recognition environment peaked
character-recognition-type problems (here, introduction, view environments
sets individual classification problems, rather single, multiple class classification problems).
Recall last paragraph previous section learners bias represented
choice hypothesis space . enable learner learn bias, supply family
.
set hypothesis spaces
Putting together, formally learning learn bias learning problem consists of:



"

Z



" fi Z

Z



Z

Z

$

E

input space

E

loss function



output space

U$ "s"&D ,
E environment fi Z

distribution ,
E

hypothesis space family

"

(both separable metric spaces),

set probability distributions





U

U

C

assume loss function range
assume bounded.



D"

set functions



#%$ &"

Z



.

fi 6 , equivalently, rescaling,

2. bias also governed learner uses hypothesis space. example, circumstances
learner may choose use full power (a neural network example early-stopping). simplicity
paper abstract away features algorithm assume uses entire hypothesis space
.
3. domain -algebra subsets . suitable one purposes Borel -algebra
generated
topology weak convergence . assume separable metric spaces, also
separable metric space Prohorov metric (which metrizes topology weak convergence) (Parthasarathy,
1967), problem existence measures
. See Appendix discussion,
particularly proof part 5 Lemma 32.













157








Q



fiBAXTER

define goal bias learner find hypothesis space
following loss:

C

minimizing

)*6[ $ = )*+ # f Z
(6)
= U # fi= f fi= f Z
Z
#
way )*[ small if, high -probability, contains good solution
Z
problem drawn random according . sense )*[ measures appropriate
Z
bias embodied environment fi .
Z
general learner know , able find minimizing )*[

Z

times according yield:
c


fifi .





E Sample ^ times S" according yield:
B
fi
fi fi .
E resulting P training setshenceforth called P]fi^_ -sample generated
processare supplied learner. sequel, P]fi^_ -sample denoted
\ written matrix:
ff

fi

ff
fi
j

..
..
..
..
\ $
(7)
.
.
.
c
fi c
c fi c !. c
c
P]fi^_ -sample simply P training sets
fifia sampled P different learning tasks
c

fi fi , task selected according environmental probability distribution Z .
size training set kept primarily facilitate analysis.
'C .
Based information contained \ , learner must choose hypothesis space
\
directly. However, learner sample environment following way:

E

Sample

P

One way would learner find
defined by:

minimizing empirical loss ,

) W *a `

[

)
*
c

fi fi

c





) W * ` $ P
3 R )W * X? #

(8)

)*6[

Note
simply average best possible empirical error achievable
training set , using function . biased estimate
. unbiased estimate
would require choosing minimal average error distributions
, defined
.
ordinary learning, likely intelligent things training data
minimizing (8). Denoting set
-samples
, general bias
learner map takes
-samples input produces hypothesis spaces

output:

\

V

P]fi^_


c c
R 3 #
) *+
P]fi^_

. c 2 5
V $

s"
&
'
c
158

Ss" . c 2 5

P

SC

(9)

fiA ODEL NDUCTIVE B IAS L EARNING

V

(as stated, deterministic bias learner, however trivial extend results stochastic
learners).
Note paper concerned sample complexity properties bias
learner ; discuss issues computability .
Since searching entire hypothesis spaces within family hypothesis spaces
, extra representational question model bias learning present
represented searched . defer
ordinary learning, family
discussion Section 2.5, main sample complexity results model bias learning
introduced. specific case learning set features suitable environment
related learning problems, see Section 3.
Regardless learner chooses hypothesis space , uniform bound (over

) probability large deviation

, compute
upper bound
, bound bias learners generalization error
.
view, question generalization within bias learning model becomes: many
tasks ( ) many examples task ( ) required ensure

close high probability, uniformly
? Or, informally, many tasks
many examples task required ensure hypothesis space good solutions
training tasks contain good solutions novel tasks drawn environment?
turns kind uniform convergence bias learning controlled size
certain function classes derived hypothesis space family , much way
VC-dimension hypothesis space
controls uniform convergence case Boolean
function learning (Theorem 1). size measures auxiliary definitions needed
state main theorem introduced following subsection.

V



V

V

V



C
P

) W *a`

) W *`

^

)*6[

) W *`

C

)*[
)*[



#%$ &D" , define #=b$ "&( fi 6
#b fi= $ U # 9fiR
(10)
hypothesis space hypothesis space family , define
bff$ B #=b$# CT j
(11)
c
#
# c , define #
fifi # c b$ DT" &( fi 6
sequence P hypotheses
fifi
c

#
fifi #Rc b
fi
fifi c fi c $ P U # fi
(12)


db
#
#=c b . hypothesis space family , define
also use denote
fifi
cb $ B #
fifi # c b$#
fifi # c CT j
(13)
2.3 Covering Numbers

Definition 1. hypothesis

Define

cb $ cb


159

(14)

fiBAXTER

#$ & "
b
b
P

"&( fi 6

#b

first part definition above, hypotheses
turned functions
mapping
composition loss function.
collection
functions original hypotheses come .
often called loss-function class.
case interested average loss across tasks, hypotheses
chosen fixed hypothesis space . motivates definition

. Finally,
collection
, restriction
belong single
hypothesis space
.

c
b

C

Definition 2.

#
fi fi # c b

C

, define

hypothesis space family



Te $ (
& fi 6
e $ 3 R )* + #

, define

db
#
fifi # c

P c
b

(15)

e $B
e $ C j

(16)
cb
e controls large P]fi^_ -sample \ must ensure
size

)W *a` )*6[ close uniformly C . size defined terms
certain covering
cb numbers, neede define measure distance
elements
also elements .
n
fifi c sequence P probability distributions DT" .
Definition 3. Let
c
db b C b , define
fi
flg dQb fi yb $ . 5 db
fi
fifi c fi c ;: yb
fi
fifi c fi c
(17)
f

fi
f c c fi c
Z
e e C e , define
Similarly, distribution
fi >
f [ e
fi e $ e
;: e f Z
(18)
>
>
fg f [ pseudo-metrics cb e respectively.
easily verified
e f
Te Te
eDC e ,


Definition 4. -cover fi [ set
fifi
f [ Te fi e Ti ; . Note require Te contained
h

e f
e , measurable functions
. Let Jijfi fi [ denote size smallest
e
cover. Define capacity

k Jilfi e $
h Jilfi e fi f [
(19)
[
. h Jijfi cb fi f g defined similar
supremum probability measures
c
fg place f [ . Define capacity b by:
way, using
k Jijfi cb $ g h Jilfi cb fi fg
(20)
supremum sequences P probability measures S" .
R ff
.
4. pseudo-metric metric without condition
4

160

fiA ODEL NDUCTIVE B IAS L EARNING

2.4 Uniform Convergence Bias Learners
enough machinery state main theorem. theorem hypothesis space
family required permissible. Permissibility discussed detail Appendix D, note
weak measure-theoretic condition satisfied almost real-world hypothesis space
families. logarithms base .





"



Z

\
P]fi^_

"




Z
c

P
^

fi 3fififiP








fi




fi







fi




fi















P

k e






P fi
> > fi fi > fi
number examples ^ task satisfies
k fi cb






^!fi
Pffi > > fi"i $> # fi
C satisfy
probability least : (over P]fi^_ -sample \ ),
)*[ % )W *a` 9K

Theorem 2. Suppose
separable metric spaces let probability distribution , set distributions
. Suppose
-sample generated
sampling times according give
, sampling times
generate
,
. Let
permissible
hypothesis space family. number tasks satisfies





(21)

(22)

(23)

Proof. See Appendix A.

k Jijfi cb
P]fi^_

several important points note Theorem 2:

k J ijfi e

)* [
# Cs
)*O[

1. Provided capacities

finite, theorem shows bias
bound generalisation error

learner selects hypothesis spaces
terms
sufficiently large
-samples . bias learners find
exact value
involves finding smallest error hypothesis
training sets . upper bound
(found, example
gradient descent error function) still give upper bound
. See
Section 3.3.1 brief discussion achieved feature learning setting.

) W *a` W
)*aP `

) W *`

\



)

*
[
P

C

\

) W *a`

^


close uniformly
2. order learn bias (in sense
), number tasks number examples task
must
sufficiently large. intuitively reasonable bias learner must see
sufficiently many tasks confident nature environment, sufficiently
many examples task confident nature task.

C
Z
^

) W * `

3. learner found
small value
, use

learn novel tasks drawn according . One following theorem bounding
sample complexity required good generalisation learning (the proof
similar proof bound Theorem 2).



161

fiBAXTER


fi
fifi fi


ilfi " ijfi
^

k ' b
^ fi >
) ( fi fi >
!
(24)
# CT satisfy
probability least %: ,
)*+ # % )W *X # K ij
k
capacity Jilfi appearing equation (24) defined analogous
#b fito=the:
f #b # b $ * fashion
capacities Definition 4 (we use pseudo-metric + fi +

# yb QfiR f fi= ). important thing note Theorem 3 number
ex-

Theorem 3. Let
training set generated sampling
according distribution . Let permissible hypothesis space.
&%
%
, number training examples satisfies

amples required good generalisation learning novel tasks proportional logarithm capacity learnt hypothesis space . contrast, learner
bias learning, reason select one hypothesis space

consequently would view candidate solution hypothesis
hypothesis spaces
. Thus, sample complexity proportional
capacity ,
, general considerably larger capacity
. learning learner learnt learn environment
individual
sense needs far smaller training sets learn novel tasks.

fi Z

C

C
b b

C

:_
W) *a` ff K
)*[
0
* $ 3 R ) * + # 1fi

W *a`
)

= )*+ #

4. learnt hypothesis space
small value
, Theorem 2 tells us
probability least
, expected value
novel task
less
. course, rule really bad performance tasks
. However, probability generating bad tasks bounded. particular,
note
expected value function
, Markovs
inequality, -/. ,



e

- #

0 *
2[
3

)
6
*
[

W
)*`

e

$ e

-


9 Ki

fi
-







(with probability

%: ).

ijfi

5. Keeping accuracy confidence parameters
fixed, note number examples
required task good generalisation obeys

^ F P k ijfi cb
(25)
c
k Jilfi b increases sublinearly P , upper bound number
provided

examples required task decrease number tasks increases. shows
suitably constructed hypothesis space families possible share information
tasks. discussed Theorem 4 below.
162

fiA ODEL NDUCTIVE B IAS L EARNING

2.5 Choosing Hypothesis Space Family

) *[
P]fi^_
\



.

) W * `

)* [
C
P ^

Theorem 2 provides conditions

close, guarantee
actually small. governed choice . contains hypothesis
space small value
learner able find
minimizing error
sample (i.e., minimizing
), then, sufficiently large , Theorem 2 enthe
sures high probability
small. However, bad choice mean
hope finding small error. sense choice represents hyper-bias
learner.
Note sample complexity point view, optimal hypothesis space family choose
contains good solutions
one containing single, minimal hypothesis space
problems environment (or least set problems high -probability), more.
bias learning (because choice made hypothesis
spaces), output bias learning algorithm guaranteed good hypothesis space
environment, since hypothesis space minimal, learning problem within environment using require smallest possible number examples. However, scenario
analagous trivial scenario ordinary learning learning algorithm contains
single, optimal hypothesis problem learnt. case learning done,
bias learning done correct hypothesis space already known.
extreme, contains single hypothesis space consisting possible functions
bias learning impossible bias learner cannot produce
restricted hypothesis space output, hence cannot produce hypothesis space improved
sample complexity requirements yet unseen tasks.
Focussing two extremes highlights minimal requirements successful bias
must strictly smaller space
learning occur: hypothesis spaces
functions
, small skewed none contain good solutions
large majority problems environment.
may seem simply replaced problem selecting right bias (i.e., selecting
right hypothesis space ) equally difficult problem selecting right hyper-bias (i.e.,
right hypothesis space family ). However, many cases selecting right hyper-bias far
easier selecting right bias. example, Section 3 see feature selection
problem may viewed bias selection problem. Selecting right features extremely
difficult one knows little environment, intelligent trial-and-error typically best
one do. However, bias learning scenario, one specify set features
exist, find loosely parameterised set features (for example neural networks), learn
features sampling multiple related tasks.

)*[
)*[



W *a`
)







Z

& "





C

'&"



2.6 Learning Multiple Tasks

P

fi Z


may learner interested learning learn, wants learn fixed set
. previous section, assume learner starts
tasks environment
hypothesis space family , also receives
-sample generated
distributions
. time, however, learner simply looking hypotheses
, contained hypothesis space , average generalization
error hypotheses minimal. Denoting
writing
,

P
#
fifi #Rc

P


fi fi c

P]fi^_

#
fifi #=c

163



\

P

n
fi fi c

fiBAXTER

c






) * g $ P
) *+ #
(26)
c


P U # fi= f fi=fi



empirical loss \
c


W)*a` $ P )W *X? #
(27)

c
P ^ U # 4 fi 4

4

#
#=c , prove uniform bound
before, regardless learner chooses
fifi
g


#
# c perform
W
probability large deviation )* ` )*
fifi
well training sets \ high probability perform well future examples

error given by:

tasks.

n

fifi c P
^

"


\



P]fi^_

Theorem 4. Let
probability distributions
let
according . Let

sample generated sampling times
permissible hypothesis space family. number examples task satisfies

"

^

k
) ( fi cb






ffP >
5
^!fi
(28)
fi > #
C c satisfy
probability least : (over choice \ ),
(29)
)* g % )W *a` ffK
c
k b
(recall Definition 4 meaning Jilfi ).
Proof. Omitted (follow proof bound ^ Theorem 2).
bound ^ Theorem 4 virtually identical bound ^ Theorem 2, note
depends inversely number tasks P (assuming first part max
k cb
expression dominate one). Whether helps depends rate growth )
( fi
function P . following Lemma shows growth always small enough ensure
never worse learning multiple tasks (at least terms upper bound number
examples required per task).

,


k li fi b k H ilfi cb k li fi b
c

Lemma 5. hypothesis space family

164

(30)

fiA ODEL NDUCTIVE B IAS L EARNING


#
#
R
#
c
b
Proof. Let 6 denote set functions
fifi c
k Hijfi cb member
k Jijfi 6 .
!C (recall Definition 1).
87
b
c

6



hypothesis space


k
k

ilfi

b
H

j

fi



Lemma 29 Appendix B,
6
right hand inequality follows.
n meaFor first inequality,
let probability measure " let
c
sure !<" obtained using first copy <"
cb flg product,#and
b C ignoring
b

elements product. Let
-cover fi
. Pick

c b C fg # fi # fifi # b fi:9
fifi;9 c b . construction,
let :9
fifi;9
flg # fi # fi3fi # b fi: 9
fi;fi 9 c b f + # fi: 9
b , establishes first inequality.
k ji fi b
k Jijfi cb P k ijfi b

(31)
keeping accuracy parameters fixed, plugging (31) (28), see upper
bound number examples required task never increases number tasks,
best decreases F NPQ . Although upper bound, provides strong hint
Lemma 5

learning multiple related tasks advantageous number examples required per task
basis. Section 3 shown feature learning types behavior possible,
decrease.
advantage
2.7 Dependence



F NPQ

Ni >

Ni

Theorems 2, 3 4 bounds sample complexity scale
. behavior
improved
empirical loss always guaranteed zero (i.e., realizable
case). behavior results interested relative deviation empirical
true loss, rather absolute deviation. Formal theorems along lines stated Appendix
A.3.

3. Feature Learning
use restricted feature sets nearly ubiquitous method encoding bias many areas
machine learning statistics, including classification, regression density estimation.
section show problem choosing set features environment
related tasks recast bias learning problem. Explicit bounds

calculated general feature classes Section 3.2. bounds applied problem
learning neural network feature set Section 3.3.

k e fiai3

k cb fiai3

3.1 Feature Learning Model
Consider following quote Vapnik (1996):
classical approach estimating multidimensional functional dependencies
based following belief:
Real-life problems exists small number strong features, simple
functions (say linear combinations) approximate well unknown function.
Therefore, necessary carefully choose low-dimensional feature space
use regular statistical techniques construct approximation.
165

fiBAXTER

q$ &


q


fi






fi




q
q
q

q
p
"
q C_o
pTr q $ B r q $ C p


p
r
$
$

C

(32)
q q j
problem carefully choosing right features q equivalent bias learning
C . Hence, provided
problem find right hypothesis space
k e
k cb learner embedded within
environment related tasks, capacities fiai fiai finite, Theorem 2 tells
us feature set q learnt rather carefully chosen. represents important
simplification, choosing set features often difficult part machine learning
problem.
k e
k cb
Section 3.2 give theorem bounding fiai fiai3 general feature classes.
theorem specialized neural network classes Section 3.3.
p
Note forced function class feature maps q , although
p
necessary. Indeed variants results follow obtained allowed vary
q .

general set strong features may viewed function
+< mapping input
(typically lower) dimensional space < . Let
set feature
space
=
maps (each may viewed set features
). must
>= <
carefully chosen quote. general, simple functions features may
represented class functions mapping < .
define hypothesis
?9
9
, hypothesis space family
space

3.2 Capacity Bounds General Feature Classes

fi= &
q


s"

s"
p
U
C p
q fi=
U
fi 6 fiR & fi= U
b "
pb
b
p b r $ r q $ C p b fi q Co
pb
k Jilfi p b $
E h Jilfi p b fi f +
+
f
$ 9zCBfiR:
supremum probability measures <" , + :9fi;9 *GF
9 CBfi= f
CBfi= .
define capacity p ofb first define pseudo-metric f + 2 uvxw
pulling back H metric follows:
ft + 2 uv w q fi q $ u v 9 r q fi=;/: 9 r q QfiR f fi=
(33)



f=t
ft
easily verified + 2 uvxw pseudo-metric. Note + 2 uv w well defined suprep
b
mum integrand must measurable. guaranteed theh hypothesis space family
ft
p ib r q $ q C permissible (Lemma
32, part 4). define Jilfi fi + 2 uv{w8

pb
f


smallest -cover pseudo-metric space fi + 2 u v w -capacity (with respect )

k uv Jilfi $
h Jilfi fi f + 2 uv{w
+
supremum probability measures -" . state main theorem
A@
<

Notationally easier view feature maps mapping
, also absorb loss function definition viewing 9

A@
:9 CB

via CB
. Previously latter function would
map <
denoted 9 follows drop subscript cause confusion.
class 9 belongs still denoted .
?9
9
definitions let
. Define capacity
usual way,

section.

166

fiA ODEL NDUCTIVE B IAS L EARNING

ii
K >

Theorem 6. Let
,



hypothesis space family equation (32).

k J ilfi cb
k Jijfi e

k H
fi p b c k u v Ji > fi
k uv Hilfi

ijfiai
fiai > .


(34)
(35)

Proof. See Appendix B.
3.3 Learning Neural Network Features

f

general, set features may viewed map (typically high-dimensional) input
=
much smaller dimensional space
( JLK
). section consider approximatspace
ing feature map one-hidden-layer neural network input nodes J output nodes
QP R

N
=
(Figure 1). denote set feature maps

R
bounded subset TS ( U number weights (parameters) first two layers).
set previous section.
feature N
,
J defined











f
|
| 2
fifi | 2 $ C

| 2 $ & fi 6 3fifi
b


|N 2 9 $ VWX B 4 # 4 KYB b
[Z
(36)

4


#
b
output
#
4 output
\^] node first hidden layer, CB
fifi_B

$
node parameters th feature V sigmoid squashing function V & fi 6 .
# $ &S , 3fifi U , computes
first layer hidden node






# 9 $ V WX

Z[
4 4 K
(37)






`
`
4



hidden nodes parameters. assume V Lipschitz. weight

fifi
`
`
vector entire feature map thus
P

fifi


fifi b
fifi b
_fi B

fi_fi B
b
fi _fi B =
fi _fi B = b




`
`
`
`
Uf
U
total number feature parameters U KffK J K .
p
arguments sake, assume simple functions features (the class previous
5

section) squashed affine maps using sigmoid function V (in keeping
P
neural network flavor features). Thus, setting feature weights generates
hypothesis space:

| $



=


N | 2 K


f $
fi fi

C R fi
=
=

ed





R
=
bounded subset . set hypothesis spaces,
$ B | Q$ P C R
> k ; h?lmgnh > k h Hkporq .
5. Lipschitz exists constant g h j
Vcb

167

(38)

(39)

fiBAXTER

Multiple Output Classes
n

k

l

Feature
Map


Input

P

P

P]fi^_

Figure 1: Neural network feature learning. feature map implemented first two
hidden layers. output nodes correspond different tasks
sample . node network computes squashed linear function nodes
previous layer.

\


fifi



=
feature
hypothesis space family. restrictions output layer weights
P


weights , restriction Lipschitz squashing function needed obtain finite upper
bounds covering numbers Theorem 2.
Finding good set features environment
equivalent finding good hyP
, turn means finding good set feature map parameters .
pothesis space
Theorem 2, correct set features may learnt finding hypothesis space
small error sufficiently large
-sample . Specializing squared loss, present
framework empirical loss
(equation (8)) given

fi Z

| C

P]fi^_
\
\
c

>

=









b
b
(40)
)W *` | P
.tsu62 2w vwRvwv 2 s^x65 >y k ^ 4
{z VYb b
N | 2 4 9K f :< 4}|
Since sigmoid function V range fi 6 , also restrict outputs " range.
|

3.3.1 LGORITHMS



F INDING



G OOD ET



F EATURES

Provided squashing function V differentiable, gradient descent (with small variation
P
backpropagation compute derivatives) used find feature weights minimizing (40)
(or least local minimum (40)). extra difficulty ordinary gradient
descent appearance definition
. solution perform gradient
P
= node feature weights .
descent output parameters


details see Baxter (1995b) Baxter (1995a, chapter 4), empirical results supporting
theoretical results presented also given.

R

W * ` |
)

fifi
168

fiA ODEL NDUCTIVE B IAS L EARNING

3.3.2 AMPLE C OMPLEXITY B OUNDS

\
k J ijfi cb



N EURAL -N ETWORK F EATURE L EARNING

size ensuring resulting features good learning novel tasks
environment given Theorem 2. compute logarithm covering
numbers

.

k J ijfi e
| $aP C ff S5 hypothesis space family }| form
Theorem 7. Let 3~


=




| $ V b
N | 2 K
f $
fi fi = C = fi






| N | 2
fi fi N | 2 = neural network U weights mapping = .

P
feature weights output weights 3fi
fifi = bounded, squashing function V
U



Lipschitz, squared loss, output space " fi 6 (any bounded subset do),
exist constants fi =y (independent ilfi U J ) . ,
k Jijfi cb J KP}K U
(41)

k Jijfi e U Ri
(42)
(recall specialized squared loss here).
Proof. See Appendix B.
Noting neural network hypothesis space family
Theorem 2 gives following theorem.



permissible, plugging (41) (42)

|

|

Theorem 8. Let
hypothesis space family hypothesis space

set squashed linear maps composed neural network feature map, above. Suppose
number features J , total number feature weights W. Assume feature weights
-sample
output weights bounded, squashing function V Lipschitz. Let
generated environment
.

\

fi Z

P fi F > U K = R fi

P]fi^_

(43)



^!fi F > J K K U P K P R
| C satisfy
probability least :
)* [ }| )W * ` }| 9 K il
169

(44)

(45)

fiBAXTER

3.3.3 ISCUSSION



F K



NPQ

1. Keeping accuracy confidence parameters fixed, upper bound number
examples required task behaves like J
U
. learner simply learning
fixed tasks (rather learning learn), upper bound also applies (recall
Theorem 4).

P
^

F

P




upper bound
2. Note away feature map altogether U
becomes J , independent (apart less important term). terms
upper bound, learning tasks becomes hard learning one task. extreme,
fix output weights effectively J
number examples required
task decreases U
. Thus range behavior number examples required
decrease number
task possible: improvement
tasks increases (recall discussion end Section 2.6).

P



F NPQ

P

F NPQ

3. feature map learnt (which achieved using techniques outlined Baxter,
1995b; Baxter & Bartlett, 1998; Baxter, 1995a, chapter 4), output weights
estimated learn novel task. keeping accuracy parameters fixed, requires
J examples. Thus, number tasks learnt increases, upper bound
number examples required task decays minimum possible, J .

F

F

4. small number strong features assumption correct, J small. However,
typically little idea features are, confident neural
network capable implementing good feature set need large, implying
UJ .
J
U
decreases rapidly increasing UJ , least
terms upper bound number examples required per task, learning small feature
sets ideal application bias learning. However, upper bound number
tasks fare well scales U .

F K

NPQ

P

F


special case multi-task framework one marginal distribution input
~ task 3fifiP , varies tasks conditional
space
distribution output space " . example would multi-class problem face
l3fifiP; P number faces recognized
recognition, "

marginal distribution simply natural distribution images faces.
case, every example 4 havein addition sample 4 th tasks conditional
distribution " samples remaining P: conditional distributions " ,
view P training sets containing ^ examples one large training set multi-class
problem ^TP examples altogether. bound ^ Theorem 8 states ^TP
F P J K U , proportional total number parameters network, result would
3.3.4 C OMPARISON



RADITIONAL ULTIPLE -C LASS C LASSIFICATION

expect from6 (Haussler, 1992).
specialized traditional multiple-class, single task framework, Theorem 8 consistent bounds already known. However, already argued, problems face
recognition really single-task, multiple-class problems. appropriately viewed
6. example classified large margin naive parameter counting improved upon (Bartlett,
1998).

170

fiA ODEL NDUCTIVE B IAS L EARNING

P

P

(potentially infinite) collection distinct binary classification problems. case, goal
bias learning find single -output network classify subset faces
well. learn set features reliably used fixed preprocessing distinguishing single face faces. new thing provided Theorem 8: tells us
provided trained -output neural network sufficiently many examples sufficiently
many tasks, confident common feature map learnt tasks good
learning new, yet unseen task, provided new task drawn distribution
generated training tasks. addition, learning new task requires estimating J
output node parameters task, vastly easier problem estimating parameters
entire network, sample computational complexity perspective. Also, since
high confidence learnt features good learning novel tasks drawn
environment, features candidate study learn
nature environment. claim could made features learnt
small set tasks guarantee generalization novel tasks, likely features
would implement idiosyncrasies specific tasks, rather invariances apply across
tasks.

P

P

^

P

viewed bias (or feature) learning perspective, rather traditional -class
classification perspective, bound number examples required task takes
somewhat different meaning. tells us provided large (i.e., collecting examples
large number tasks), really need collect examples would
examples vs. J examples).
otherwise collect feature map already known ( J U
tells us burden imposed feature learning made negligibly small, least
viewed perspective sampling burden required task.

P

K NP

3.4 Learning Multiple Tasks Boolean Feature Maps



P



Ignoring accuracy confidence parameters , Theorem 8 shows number
examples required task learning tasks common neural-network feature map
J
U
bounded
, J number features U number
adjustable parameters feature map. Since
J examples required learn single task
true features known, shows upper bound number examples
required task decays (in order) minimum possible number tasks increases.
suggests learning multiple tasks advantageous, truly convincing need
)
prove lower bound form. Proving lower bounds real-valued setting (
complicated fact single example convey infinite amount information,
one typically make extra assumptions, targets
corrupted
noise process. Rather concern complications, section restrict
attention Boolean hypothesis space families (meaning hypothesis
maps

measure error discrete loss


otherwise).

F K

NPQ

F

P

C "

"

# C

U # 9fiR # } U # 9fiR
"
show sample complexity learning P tasks Boolean hypothesis space family
f= PQ (that is, give nearly matching upper
type parameter
controlled VC dimension
f PQ ). derive bounds f PQ hypothesis space
lower bounds involving

family considered previous section Lipschitz sigmoid function V replaced hard
threshold (linear threshold networks).
171

fiBAXTER

F

well bound number examples required per task good generalization across
tasks, Theorem 8 also shows features performing well U
tasks generalize well
novel tasks, U number parameters feature map. Given many feature
learning problems U likely quite large (recall Note 4 Section 3.3.3), would useful
know
U
tasks fact necessary without restrictions environmental
distributions generating tasks. Unfortunately, yet able show lower
bound.
empirical evidence suggesting practice upper bound number
tasks may weak. example, Baxter Bartlett (1998) reported experiments
set neural network features learnt subset 400 Japanese characters turned
good enough classifying 2600 unseen characters, even though features contained
several hundred thousand parameters. Similar results may found Intrator Edelman (1996)
experiments reported Thrun (1996) Thrun Pratt (1997, chapter 8).
gap experiment theory may another example looseness inherent
general bounds, may also analysis tightened. particular, bound
number tasks insensitive size class output functions (the class Section 3.1),
may looseness arisen.

ZF



p

3.4.1 U PPER L OWER B OUNDS
PACE FAMILIES



L EARNING TASKS



B OOLEAN H YPOTHESIS


fifi C ~ 0

~ 0 $ B #
fifi # $# CT j
~
~
Clearly 0 . 0 say shatters . growth function defined
^_ $ 0 L / ~ 0
size largest set shattered :
Vapnik-Chervonenkis dimension
= $ ^ $ ^_ j

First recall concepts theory Boolean function learning. Let
class
.
set binary vectors obtainable
Boolean functions
applying functions :



important result theory learning Boolean functions Sauers Lemma (Sauer, 1972),
also make use.
Lemma 9 (Sauers Lemma). Boolean function class

positive integers

^



f ,

^ fi
^_ ^ f


.

generalize concepts learning

P

172

tasks Boolean hypothesis space family.

fiA ODEL NDUCTIVE B IAS L EARNING

Definition 5. Let
input space
matrices,



^ matrices
Denote P
. bec 2 a5 Boolean hypothesis
. c 2 space
5 family.
C
C
~



, define set (binary)
.

#



#



$z#
fi fi # c CT
_~ $
..
..
..

.
.
.
#=c c
#Rc c




~ }$ ~
P]fi^_
P . fi^ . , define
P]fi^_ $ L ~

c ~ c




]
P

fi
_
^
%


Note
matrix
. say shatters
c

f PQ $ ^ $ P]fi^_ j
Define

Define

Lemma 10.

.

P
.



let

f $ =

f $ =
f fi f
f PQ fi f P fi f
#

f K f
P
Proof. first inequality trivial definitions. get second term maximum
C = f construct matrix
second
inequality, choose
c
.
2
5

f
C
whose rows length shattered . clearly
shatters .

first term maximum take sequence
fifi . 5 shattered (the hypothesis

space consisting union hypothesis spaces ), distribute elements equally
among rows (throw away leftovers). set matrices
# ff


# ff





$
#
C
..
..

..


.
.
.
#
c
#
c

















c

f
~ size .
^ NP subset
c .c 5
Lemma 11.
^
P]fi^_ f= PQ ?
173

fi





fiBAXTER

P P]fi^_ P9^_

fifi c
#

#>
^
f PQ = P f QP

P

#
fifi #Rc

Proof. Observe ,
collection Boolean
obtained first choosing functions

functions sequences
, applying
first examples,
second examples on.
definition
,
, hence result follows Lemma 9 applied
.

C

^

k cb fiai3

P]fi ^_
fi

one follows proof Theorem 4 (in particular proof Theorem 18 Appendix
A) clear .
,
may replaced
Boolean
E
case. Making replacement Theorem 18, using choices
discussion

following Theorem 26, obtain following bound probability large deviation
empirical true performance Boolean setting.

n
fifi c P
let \


P]fi^_
^


. Let B
0
* \ $=d C c $ )* g fi )W a* ` ffK ij P]fi ^_ ) : > P9^_N

(46)
Corollary 13. conditions Theorem 12, number examples ^ task


probability distributions
Theorem 12. Let

-sample generated sampling times
according
permissible Boolean hypothesis space family. %
,

satisfies

^ fi > f PQ K P
!

probability least : (over choice \ ),
)* g % )W *a` ffK



C c

(47)
satisfy
(48)

Proof. Applying Theorem 12, require

P]fi ^_ ) : > P9^_N fi

satisfied

^!fi > f PQ f ^ PQ K P fi

fiM ,
used Lemma 11. Now,
^ K K Ifi



f PQNi > , (49) satisfied
^!fiI ^ . setting IL
^!fi > f PQ K P
174

(49)

fiA ODEL NDUCTIVE B IAS L EARNING

Corollary 13 shows algorithm learning
requires

P

tasks using hypothesis space family

^ F > =f PQ K P R

c





(50)

\

P

examples task ensure high probability average true error hypotheses
selects
within average empirical error sample . give
theorem showing learning algorithm required produce hypotheses whose average
true error within best possible error (achievable using
) arbitrary sequence
distributions
, within
factor number examples equation (50) also
necessary.

sequence
probability distributions
, define






fifi c

= g c




n
fi fi c P
g c $ R )* g

c P






contains least two
Pbe3afi Boolean
hypothesis space family
fifi let V c learning algorithm taking input P]fi^_c -samples
c
.
2
5


C
\ ( producing output P hypotheses #
fi fi #=c C .
%i%MN % %MN ,
^ % > f PQ KM:i > P : 3
!



c
n

fifi probability least (over
exist distributions
\
random choice ),
g)* V c J\ . = g c ffK

Theorem 14. Let
functions.

Proof. See Appendix C

Ni3
f PQ

3.4.2 L INEAR HRESHOLD N ETWORKS

P
f PQ

factor, sample complexity
Theorems 13 14 show within constants
learning tasks using Boolean hypothesis space family controlled complexity parameter
. section derive bounds
hypothesis space families constructed
thresholded linear combinations Boolean feature maps. Specifically, assume
form given (39), (38), (37) (36), squashing function V replaced hard
threshold:

fi
V
otherwise

$ :

Rfi



fi

fi Ry

dont restrict range feature output layer weights. Note case
proof Theorem 8 carry constants Theorem 7 depend
Lipschitz bound V .



f U

Theorem 15. Let hypothesis space family form given (39), (38), (37) (36),
hard threshold sigmoid function V . Recall parameters , J input dimension,
number hidden nodes feature map number features (output nodes feature map)
175

fiBAXTER

$ U f K]K J U K (the number adjustable parameters feature
f PQ U K J K J K U Kz
P
>
Proof. Recall
. c 2 for5 eachM | P ~ C TS , | $ &( = denotes feature map parameters P .
C


, let
denote matrix
|

6
|

.
.

.
|M .. c
. . | .. c
~ set binary P ^ matrices obtainable composing thresholded linear
Note
| ~

respectively. Let U
map). Then,

functions elements
, restriction function must applied
element row (but functions may differ rows). slight abuse notation,
define

P]fi^_ $


~


| ~ $aP C









. c 2 5
C
Fix
. Sauers
Lemma, node first hidden layer feature map computes

f 5 functions P9^ input vectors . Thus,
^TPQNb . K
^TPQN f K
distinct functions input output first hidden layer
P9^ points . Fixing first hidden layer
U b
parameters, node second layer of. b the5
feature map computes ^TPQN K functions image produced output
U =

first hidden layer. Thus second hidden layer computes ^TPQN K
functions output first hidden layer P9^ points . So, total,
b .
5 ^TP = . b
5

^
P
P]fi^_ f KR U K

| ~ , number functions computable row | ~
Now, possible matrix


=
thresholded linear combination output feature map ^_N J K . Hence,
c . =
5 obtainable applying linear threshold functions
number binary sign assignments
. Thus,
rows ^_N J K
b.
5
c .
5
.b
5
P]fi^_ f ^TKP U ^TKP = P ^TKP =
J
$

q convex function, hence IfiGfi . ,
IK U GY
K

J
q J K U K J K U K JRq JIffK U q HGffK q
b
b
U
=
=}
K

K








J

fi
J IK U G]Kc
G
U K , G f K P J K shows
Substituting
c .=
5
U

^

P

K

K






P]fi^_ K J P K
(51)
U

J

176

fiA ODEL NDUCTIVE B IAS L EARNING

Hence,

^TP J K U K





K
K

(52)
. P
J
> U K P J K
P]fi^_% c definition f PQ^ . . , observe . >


U KN U K P J K J K U K shows
> . Setting ^TP J K

U K .
(52) satisfied ^ U NP}K J K > J K
f
U
Theorem 16. Let Theorem 15 following extra restrictions: fi , fi J
f
.
J
f PQ fi U P K J K



f
f
Proof. bound apply Lemma 10. present setting contains
f
U
three-layer linear-threshold networks input nodes, hidden nodes first hidden layer, J
^

U

hidden nodes second hidden layer one output node. Theorem 13 Bartlett (1993),


=
fi lf U K U J : K3fi

f
restrictions stated greater U N . Hence fi
f Ufi

U

N.

f :

J

J choose feature weight assignment feature map
J
identity J components input vector insensitive setting reminaing
components. Hence generate J
points
whose image feature map
J
shattered linear threshold output node,
.

K

f ] K

Combining Theorem 15 Corrolary 13 shows

^!fi F > U P K J K K P
examples task suffice learning P tasks using linear threshold hypothesis space family,
combining Theorem 16 Theorem 14 shows

^ > U P K J K K P
learning algorithm fail set P tasks.
4. Conclusion
problem inductive bias one broad significance machine learning. paper
introduced formal model inductive bias learning applies learner able
sample multiple related tasks. proved provided certain covering numbers computed
set hypothesis spaces available bias learner finite, hypothesis space
contains good solutions sufficiently many training tasks likely contain good solutions
novel tasks drawn environment.
specific case learning set features, showed number examples
J
U
required task -task training set obeys
, J number

P

^ F K

177

NPQ

^

fiBAXTER

features U measure complexity feature class. showed bound
essentially tight Boolean feature maps constructed linear threshold networks. addition,
proved number tasks required ensure good performance features novel
tasks U . also showed good set features may found gradient
descent.
model paper represents first step towards formal model hierarchical approaches
learning. modelling learners uncertainty concerning environment probabilistic terms,
shown learning occur simultaneously base levellearn tasks
handand meta-levellearn bias transferred novel tasks. technical
perspective, assumption tasks distributed probabilstically allows performance guarantees proved. practical perspective, many problem domains
viewed probabilistically distributed sets related tasks. example, speech recognition
may decomposed along many different axes: words, speakers, accents, etc. Face recognition
represents potentially infinite domain related tasks. Medical diagnosis prognosis problems
using pathology tests yet another example. domains benefit
tackled bias learning approach.
Natural avenues enquiry include:

E

F



Alternative constructions . Although widely applicable, specific example feature
learning via gradient descent represents one possible way generating searching
hypothesis space family . would interesting investigate alternative methods,
including decision tree approaches, approaches Inductive Logic Programming (Khan
et al., 1998), whether general learning techniques boosting applied
bias learning setting.

E





Algorithms automatically determining hypothesis space family . model
structure
fixed apriori represents hyper-bias bias learner. would
interesting see extent structure also learnt.

E

E



Algorithms automatically determining task relatedness. ordinary learning usually little doubt whether individual example belongs learning task not.
analogous question bias learning whether individual learning task belongs
given set related tasks, contrast ordinary learning, always
clear-cut answer. examples discussed here, speech
face recognition, task-relatedness question, cases medical
problems clear. Grouping large subset tasks together related tasks could
clearly detrimental impact bias-learning multi-task learning, emprical evidence support (Caruana, 1997). Thus, algorithms automatically determining
task-relatedness potentially useful avenue research. context, see Silver
Mercer (1996), Thrun OSullivan (1996). Note question task relatedness
clearly meaningful relative particular hypothesis space family (for example,
possible collections tasks related contains every possible hypothesis space).





Extended hierarchies. extension two-level approach arbitrarily deep hierarchies,
see Langford (1999). interesting question extent hierarchy
inferred data. somewhat related question automatic induction
structure graphical models.
178

fiA ODEL NDUCTIVE B IAS L EARNING

Acknowledgements
work supported various times Australian Postgraduate Award, Shell Australia Postgraduate Fellowship, U.K Engineering Physical Sciences Research Council grants
K70366 K70373, Australian Postdoctoral Fellowship. Along way, many people
contributed helpful comments suggestions improvement including Martin Anthony,
Peter Bartlett, Rich Caruana, John Langford, Stuart Russell, John Shawe-Taylor, Sebastian Thrun
several anonymous referees.

Appendix A. Uniform Convergence Results
Theorem 2 provides bound (uniform ) probability large deviation
?1
?p

. obtain general result, follow Haussler (1992) introduce
following parameterized class metrics :



8c


" _"e


. main theorem uniform bound probability large values
"1 ?1
?p

?E"
?1


. Theorem 2 follow corollary,

, rather

?E"
better bounds realizable case
(Appendix A.3).
p



Lemma 17. following three properties

3.

easily established:

E

1.
2.




n

L


p E
,

"1 E?"1 _


,



E

,

" E ?

}





" ^_p _


.




ease exposition dealing explicitly hypothesis spaces
Q!
3 j}
containing functions
, constructing loss functions Q mapping
_
_
A3 j}
Q
. However, general view



loss function
+
j}
Q function abstract set (
)
ignore particular construction

terms loss function . remainder section, unless otherwise stated,
j}
. also considerably
hypothesis spaces sets functions mapping
_



convenient transpose notation C
-samples, writing
training sets columns
instead rows:


... . .. ...

(Equation 9 prior discussion),

fiff
. Recalling definition






transposition lives
. following definition generalizes quantities


like
,
new setting.

Definition 6. Let
functions mapping

.
, let orsetssimply
map
denote















?







?











































179







j}





fiBAXTER

. Let !"# denote set functions. Given
$ % & elements

, (or equivalently element
writing
rows), define




'

(recall equation
, define(8)). Similarly, product probability measure ( *) +)
-,#.0/ (

(recall equation (26)). 21
(not necessarily form 345 ),
define
1 %, . / 1 (
, define
(recall equation (17)). class functions mapping
6 57 98;:=?< > @7
7
supremum product probability measures
>
size smallest 7 -cover (recall Definition 4).




5









































?"

















?















































j}

































j}



























following theorem main result rest uniform convergence results
paper derived.

BA C






EDF @G
JI G
( 9) H)
GQP
+R 6 @G ST VU < G W (53)


permissible class functions mapping
Theorem 18. Let


j}








. Let
generated
independent trials





according


product
probability
measure
.


,
,


K ML








N8;:#<





p ?
?

'



'























following immediate corollary also use later.

YX[Z U]\ G H^ _&` R 6bac gd fe G ih

Corollary 19. conditions Theorem 18,


!





K L










j8;:#<















p ?"
?

'



'

'



(54)

GP g


(55)

A.1 Proof Theorem 18
proof via double symmetrization argument kind given chapter 2 Pollard (1984).
also borrowed ideas proof Theorem 3 Haussler (1992).
180

fiA ODEL NDUCTIVE B IAS L EARNING

A.1.1 F IRST YMMETRIZATION





, let







..
..
..
.
.
k .







extra piece notation:
bottom half, viz:













top half

l
..
..
..
.
.
l .















following lemma first symmetrization trick. relate probability large deviation
empirical estimate loss true loss probability large deviation
two independent empirical estimates loss.



mI G





Lemma 20. Let permissible set functions


j

!
.
probability measure


K L











N8;:#<



po

GP
N8;:#< rq


cFn



,

p ?
? 1
'






YD K L










p

?






?


j}

let

)



ts G P








(56)

q
rq ts G uo G
q G zD
0w
q uo G
q uo G

Proof. Note first permissibility guarantees measurability suprema
p
" ?
? 1






(Lemma 32 part 5). triangle inequality
,

" ?

"





?
?

?

,
. Thus,







]q
K &v

Vo ts G
xw
K v





















Q"





?









?












""

?




"

?









? 1
? 1





(57)



Chebyshevs
inequality, fixed ,


K v











Q ?
?



{I G
K L













-DF @G







? 1




gives result.








?









r



G


|R




?




?"





? 1




GD P

_

. Substituting last expression right hand side (57)

181

fiBAXTER

A.1.2 ECOND YMMETRIZATION
second symmetrization trick bounds probability large deviation two empirical
estimates loss (i.e. right hand side (56)) computing probability large deviation elements randomly permuted first second sample. following
definition introduces appropriate permutation group purpose.

}
~









~ ~ ~
~

~ H} , let

F l
.. . . . ..
. l .

" permissible set functions
Lemma 21. Let
mapping
let 3W
(as statement Theorem 18). Fix
ST -cover , 1 +
'
1

rows
G
. Then,
K L ~ H} j8:#O < ]q ; ; ts G P
K v ~ H} q

ts GR (58)

'
~ H} chosen uniformly random.
q ; ; ts G (if
Proof. Fix ~ } let

G ST . Without loss
~ already done). Choose






3 . Now,
generality assume form


' ffu ff
fi ff ff
fiff





' ffu ff
ff ff
ff

' ffp q ff
ff ff
ff

' ffu q ff
ff ff
ff

' ffp q ff
ff ff
ff ts

' ffu q ff
ff ff
ff ts
q q







Definition 7. integers
, let
denote set permutations

>
>




&
sequence pairs integers



,

































, either


.
















j}




















p







"

?






























?








Q



p









>











j





"



?




?










>




















182








cp




















?










'

?


















j









?
















j





















?




8













'





















?










?














fiA ODEL NDUCTIVE B IAS L EARNING



p

Hence, triangle inequality

,

q
q ts
q ; ;
]q


q G | R construction
G |R . Thus,
(59) implies
rq ts
v ~ H} xw
v ~ H} xw


p





>
"







>



?





?
?
?
?



>




c ?
?
c ?



?


'





p ?



?


'


" ?
?









?

>
>

"





q
q ts
(59)
ts G assumption,
GD
q GRy



?




?












'







"



?












?
















gives (58).



,be function written form
{3
K Mv ~ b} ]q ts GR YD VU < G
(60)
~ H} chosen uniformly random.


Proof. ~ f} ,
q ff
ff ff
ff ts





p
ff



q ts


(61)


ff
fi


ff

ffu

, , let
simplify notation denote ff
fiff
fiff . pair ,


lff independent random variable
fi


ff


ff



fiff
probability



lff
ff
fiff probability . (61),
K Mv ~ H} q GR




l




fiffYl
K ~ H} q ff
ff ff
ff ts GR

' ffp


' ffp



fiff +
K
fiff GR

' ffu

ffu


0 bounded ranges


, HoFor zero-mean independent random variables
effdings inequality (Devroye, Gyorfi, & Lugosi, 1996)


K \
h YD VU < D3


'



#
bound probability term right hand side (58).





Lemma 22. Let
.














>







j









?


?












j





































?


>











?






j}



Q"





























"







?












?








j





















































183



'

















fiBAXTER


fiff fi
ff
ff
fiff
ff ,

fiff+ YD VU < G
ffu
fiffV
K l
fiff GR

ffp
fiff
ff

' ffp

ffu

Let

ffp
fiff .
fiff ,
ffu
fiff
fiff . Hence,

VU < G
' ffu
'
lff ffu

lff ff YD VU < G


R . Hence
giving value
minimized setting
K v ~ f} q ts GR YD VU < G


Noting range












j











?


























j





e





Dj















j

















e




































j

j



"j



?


























required.



21 22 give:
K L ~ H} j8:#O < ]q ; ; ts G P
YD > @G ST
VU <W G
) ;) )
empirical distribution
Note
simply (




(recall Definition 3). Hence,
puts point mass
ff

N8;:=< q G P
K L ~ H}

YD 6 @G ST VU <W G
Now, random choice ,
fiff independently (but identically) distributed ~
)
ever swaps
fiff
ff (so ~ swaps
fiff drawn according ff another component
drawn according distribution). Thus integrate respect choice
~ write
j8;:#< q G P
K L

YD 6 @G ST VU <W G
A.1.3 P UTTING


fixed




OGETHER


, Lemmas





"

?






?










'









G



>



















e



e





e



_



j





























"

?




?




























j



















p

?






?








Applying Lemma 20 expression gives Theorem 18.
184









j



fiA ODEL NDUCTIVE B IAS L EARNING

A.2 Proof Theorem 2

) ;)

(

Another piece notation required proof. hypothesis space



measures
, let



?






& o&

' ]'=





?








) ;)
K (
(



probability



?

another empirical
Note used ? rather ? indicate

?1
estimate
.
_
C
also generated se -sampling process, addition
sample



although supplied learner.
quence probability measures,






means
notion used
following Lemma,

n
probability generating sequence measures environment

C _
-sample according
holds.

(

(

Lemma 23.



K L (










1




! f N8:#<





K L ( 8;:# <
! 8;:#<
K L







" ?




! x
p

"1 ?"
?





?}1






G P Dg





















"1 ?p
?1





Proof. Follows directly triangle inequality





G P Dg







(62)



(63)

G P g


.

treat two inequalities Lemma 23 separately.

A.2.1 NEQUALITY (62)





following Lemma replace supremum
8 .
Lemma 24.


K ML (











inequality (62) supremum

f j8;:#<
QG P


f N8;:#/ <
K \ (


















p ?"
?









185









p ?Ep
?

'



'



Gh

(64)

fiBAXTER


(
-&




8;:#<

p





G
jI 7

n

7

?E"
?
Proof. Suppose
. Let satisfy


?

?"
?"

. definition
,

equality. Suppose first


"
?"
?E"
exists 5
. Hence property (3)






" ?"
?E"




metric,
, exists

. Pick arbitrary
?
?
?
?
?E"
satisfying inequality. definition,

,



' .
?
?


(by assumption), compatibility
ordering




p1 ?"
?
'


p


'
reals,
, say. triangle inequality ,





7

u



G



7




G G g





G g


Thus

7 g G g 7 7 satisfying inequality
G


found. Choosing
shows exists

.

instead,
, identical argument run role (
interchanged. Thus cases,
8:# <
G w

G
p1 ?p
?



p1 ?"
?

'
?








'



'

Qc" ?p
?E"
p1 ?"
?














"1 ?p
?












'





"1 ?"
?





?"







8

Qp1 ?"
?

'





'





'







completes proof Lemma.
_
nature C
sampling process,


;8 :#/ <


j8;:=/ <
, / K \

3
AY

K \ (
















p ?"
?

'





'

Gh

'

p G h ( (65)
H permissible assumed

permissibility (Lemma 32, Appendix D). Hence
satisfies conditions Corollary 19
G g g Corollary
combining Lemma 24, Equation (65) substituting G
















GQ

?
?



































19 gives following Lemma sample size required ensure (62) holds.

+X[Z U L G f^ _&` 6 @G g G P
f j8;:#<



Lemma 25.



K L (


)



























p ?"
?




'
)








)
g

G
G
4



+X[Z U L G ^ _&` 6 @G g 4 G P

A.2.2 NEQUALITY (63)














!



G P Dg


f )



?


Note ?




, i.e expectation

distributed according . bound left-hand-side (63) apply Corollary

19
, replaced , replaced , replaced

respectively,
replaced replaced . Note
permissible whenever (Lemma 32).
Thus,

)





















?



186



g

(66)

fiA ODEL NDUCTIVE B IAS L EARNING

inequality (63) satisfied.
Now, putting together Lemma 23, Lemma 25 Equation 66, proved following

general version Theorem 2.

[I G g
YX[Z U L G ^ _&` 6 @G g G P
6 @G 0 P

[
X
Z
U
L
g

G ^ _&`
G

! j8;:#<
K L
GP g

7m
get Theorem 2, observe




7
7 |R
Setting G
maximizing G
gives
. Substituting G
p

_
-sample genTheorem 26. Let permissible hypothesis space family let C
n










erated environment
.

,





?

















p1 ?"
?1
'


































!





















?
?
1






?












7 ED


{5



.


Theorem 26 gives Theorem 2.

7
G

A.3 Realizable Case

7


7


G G
G
G
G 0 G 7
G
JI G g ,

Corollary 27. conditions Theorem 26, 7
X[Z U L G G 7 ^ _&` 6 G g 7 G G 7 P
6 G 7 P


[
X
Z
U
L
g

G G 7 ^ _&`
G G 7

G
! N8;:#<
K L
7P g
G


bounds particularly useful know
, set G
G ).
(which maximizes G




7

Theorem 2 sample complexity
scales
. improved

?"



?
?Ep





instead requiring
, require ?












?




. see this, observe ?






"1 ?"
?}1







, setting
Theorem 26 treating constant
gives:





_







$





$







_





?1



















3 z b
composition two function classes note



write
r




form given (32), written



r























Recalling Definition 6,






$


?p





Appendix B. Proof Theorem 6










?p









$



























_



_

_







187





_









_







define

fiBAXTER

bt z . Thus, setting b 0


(67)
6 .
following two Lemmas enable us bound 57






Lemma 28. Let
form

. 7 7
,
6 57 7
6 57 6 57

=

)
7




Proof. Fix measure

let minimum size -cover
.

6

$
)


$
)

5
7



definition
b let
measure
defined

) set in.



is6 measurable).
~ -algebra
( measurable


7
F


57 . Let

Let

. definition again,
6
6
9 andsize -cover
. Note

minimum
57 57 Lemma





7
7




shown
-cover
. So, given
choose
proved
1 H 1 7 1 V 1 7 . Now,
1 1 1 1 1 1
1 1
7 7
line follows
first line follows triangle inequality second






F









facts:
1
1 1
1 . Thus
7 7 -cover 1 1
result follows.
(Definition 6), following Lemma.
Recalling definition {
Lemma 29.
6 57 M3 6 57



. Let
) )
Proof. Fix product probability measure
(
/
7 -covers . let % . Given %
{& , choose 93 o&

7 . Now,





/
.
,
93

'


'

(



' o&


7

-
'
result follows.
Thus 7 -cover 93



,









j}



j}









































1





L



























c












'









































C

























C



E

















:











































_































1



















j

1

:



































































!









'

























E























188

































>















fiA ODEL NDUCTIVE B IAS L EARNING

B.1 Bounding

6 @7






j

6 7 7 e 6 @7 6 / 7 e
Lemma 29,
6 @7 6 57
/ 57
6

Using similar techniques used prove Lemmas 28 29,
satisfy
6 / 57 6 7
Lemma 28,


































:















(68)







(69)


shown





(70)

Equations (67), (68), (69) (70) together imply inequality (34).

6

6
@7 hypothesis space
wish prove 57


x

family form

|
f4 . Note f corresponds
,
) '#

, defined
probability measure induces probability measure
zz -, ) )
~ -algebra
. Note also
1 bounded, positive functions

arbitrary set ,
3 3 1 +8 :#3< 1
(71)






#




#






. Let f
Let probability measure space probability measures





. Then,
two elements corresponding hypothesis spaces


-, '= '# )
, 8; :#< ) (by (71) above)


) )
, , 8:#<




8;:#< guaranteed
permissibility (Lemma 32 part 4, ApThe measurability



|


have,
pendix D).
f
(72)
> 57
> 7 = M| e
^

B.2 Bounding

























/












? 1

























j









































1

















? 1





? 1





1



















? 1

















_













_





















gives inequality (35).
189















? 1

_





























fiBAXTER

B.3 Proof Theorem 7
order prove bounds Theorem 7 apply Theorem 6 neural network
hypothesis space family equation (39). case structure




G

G @G G G
0







~
'
bounded

subset
Lipschitz squashing function ~ . feature class

set one hidden layer neural networks inputs, hidden nodes, outputs, ~
squashing function weights
fiff ff bounded subset . Lipschitz
restriction ~ bounded restrictions weights ensure Lipschitz
b



classes. Hence exists
1 , 1
1 W 1



1 1 norm
,
case. loss function squared loss.
, hence 1 probability measures

) onNow, (recall assumed
output space
),
1 -, l
1
)
YD, 1 )
(73)

)
)
1 -

marginal distribution
derived . Similarly,
)
probability measures
,


1 YD&, 1 )
(74)
Define
6 7 e 98;:#o < > 7 ) e

supremum probability measures (the Borel subsets of)
,

)
)
7
7
e






size


smallest
-cover



metric.
Similarly
set,
>
6 7 e 98;:#o < > 7 ) e
supremum probability measures . Equations (73) (74) imply
6 57 6 7D
(75)
6 @7 6 7
D&
(76)

Applying Theorem 11 Haussler (1992), find







7

6 7!
6 D&7 7 "
w











_





j}



























m/

_









_



j}






>

_



























_


















































_


























































j}









m/





j}































































































Substituting two expressions (75) (76) applying Theorem 6 yields Theorem
7.
190

fiA ODEL NDUCTIVE B IAS L EARNING

Appendix C. Proof Theorem 14
proof follows similar argument one presented Anthony Bartlett (1999)
ordinary Boolean function learning.
First need technical Lemma.

,

G
# #
K #




K # # 0 # # %$ G 'R & '( ) +/ *-. , n 1n 0
,
# denote number occurences random sequence # # # .
Proof. Let


function viewed decision rule, i.e. based observations # , tries guess














whether probability
Bayes

Dis # WD , and.
# optimal
rule isD otherwise.
# decision
estimator: # #
Hence,
K # 2$ G K # G


K # G
KD # G







half probability binomial
random variable least WD .
Sluds inequality (Slud, 1977),
K # 3$ G K


G









Lemma 30. Let random variable uniformly distributed




>
. Let
i.i.d.
-valued random variables G
>{



. function mapping
,






















1

&



























^

















"





























$





&







"



^















^





























"





&

"







n





















j

. Tates inequality (Tate, 1953) states
normal
,

K






'4









65 n

)

1





! shattered , . row 7 let
set
Let 7

)
) )
distributions

contained
9

8


)



)
fiff
fi


ff





th;: row ofD 7 , f ,
8

. Let
.
)
;
)

<< achieved sequence







Note (
, optimal error _


fiff )

fiff
,
always contains sequence shatters 7 . optimal error

<_ 6< )

3$ =

'

' ffu
Combining last two inequalities completes proof.













+


>

C





_



>

3














C








1







C















3



>
'















C





_

>



C



_













?











G





5

191







1

>

C





1







fiBAXTER








,
p _ 6< <










(77)


fiff 3$

fiff

-sample , let element
fiff array
?=
..
..
>
..
.
.
.=
equal number occurrences
fiff .
) ;) uniformly random , generate Now, select (

@ (the output learning algorithm) have:
sample using ( ,


fiff 2$

lff C B ) />

fiff 2$

lff >
B ) /> = )
fiff 2$
fiff
lff

' ffu
) probability generating configuration >
fiff -sampling
/>
process sum possible configurations. Lemma 30,
)
lff 2$
fiff
fiff ER DF 'G ) * /. H , nn JI
,
?

C _





'







































C _



























































fiff 3$
fi
ff


K




C













































j}

j}

1



B )
























C

R'&


/>




(



)

1






























?

@




_



? = R

' ffp
M/ L /n . L
n


K






















H
) * /. , n n IJ
,





(78)


, (78)

G









192

DF

G

1

=K *-K, , 0

_ <6< G





(79)


. Plugging (77) shows


K (



C _

-valued random variable , G














lff 3$
fi
ff G
O/ L /n . L
(
)

G NR &
= K *-K, , n 0






Jensens inequality. Since
implies:











C

















hence



































5















C





G


fiA ODEL NDUCTIVE B IAS L EARNING

(

(



@

(

Since inequality holds random choice , must also hold specific choice

algorithm
sequence distributions
. Hence learning

K

?



@




Setting

Assuming equality (80), get











G 7




G



e



(80)

_ <6< 7 g




_

g







@

?





e



K



G g



ensures

_ << G



_









(81)

7g



Solving (79) , substituting expressions G shows (81) satisfied
provided
& g7 0 ^ _&` g g
(82)
g
R ( R since G |R G g ), assuming
Setting
g7 somefor
YD , (82) becomes

(83)

^'_&`
R right hand side (83) approximately maximized
Subject constraint
QPSR & , point value, exceeds
CDF D&D 7 . Thus, , 7 g

R
D&D e
(84)
7
G













!









C







1












e










j

!



C

1





















C









!



C





Q



>

>





^













<6< 7 g
_
contains least two
g
obtain -dependence Theorem 14 observe assumption
)UT two distributions
functions
, hence exists
3$
. Let
)



)T

7

8
concentrated



;: 7 . Let ( 9)
b) ( -) H) product distributions

V
)
98 generated ,T @ . Note

. ( one (
learning algorithm
chooses wrong hypothesis ,

_ 6< < 7
K




















?

@













{









?





_











'






























_

















193



























_





fiBAXTER

(

(

( ( generate
/ n
_ << 7 NR & ( ) /*X. W W n 0


Now, choose uniformly random
cording , Lemma 30 shows

K (
g
least









?



@






_

























c





1





-sample

ac-





r





_





JI g |R . Combining two constraints
X[Z U finishes proof.


C _



7 7 f^ _&` g g


provided





(85)


: (84) (with





P ) (85), using


Appendix D. Measurability
order Theorems 2 18 hold full generality impose constraint called
permissibility hypothesis space family . Permissibility introduced Pollard (1984)
ordinary hypothesis classes . definition similar Dudleys image admissible
Suslin (Dudley, 1984). extending definition cover hypothesis space families.
Throughout section assume functions map (the complete separable metric
j}
. Let denote Borel -algebra topological space . Section
space)
2.2, view , set probability measures , topological space equipping
topology weak convergence. -algebra generated topology.
following two definitions taken (with minor modifications) Pollard (1984).





ff

~





j}

ff

~

-valued functions indexed set
Definition 8. set
r

j}



ff

Definition 9. set
1.

ff









_



Zff

Q







permissible indexed set

ff

ff

ff

exists function



analytic subset Polish7 space ,


~


2. function
-algebra



ff





j}

indexing



\[]Y ff .
analytic subset ff Polish space ff


ff

measurable respect product


simply continuous image Borel subset
another Polish space . analytic subsets Polish space include Borel sets.
important projections analytic sets analytic, measured complete
measure space whereas projections Borel sets necessarily Borel, hence cannot
measured Borel measure. details see Dudley (1989), section 13.2.
Lemma 31.

2|









j}

permissible








permissible.

Proof. Omitted.
define permissibility hypothesis space families.
7. topological space called Polish metrizable complete separable metric space.

194

fiA ODEL NDUCTIVE B IAS L EARNING

W







Definition 10. hypothesis space family
permissible exist sets





analytic subsets Polish spaces respectively, function


measurable respect

,

^_[`Y ff \[`Y
ba



fe hg



ff

_}E




ff

Zff





ff

dc



ff


,



j}

@



Let
analytic subset Polish space. Let
measure space

denote analytic subsets . following three facts analytic sets taken
Pollard (1984), appendix C.

fe hg


(a)

@
(b)







ff

complete

@



e




.

e ]
[ ff .
ff , projection onto

~

contains product -algebra

(c) set





@



4

@



)




.








Recall Definition 2 definition . following Lemma assume
_
n
_ complete
completed respect probability measure , also
respect environmental measure .





Lemma 32. permissible hypothesis space family ,
1. permissible.


f permissible.
3.
permissible
.

8
#
:
<
'# measurable .
4.
5. measurable
.
6. permissible.
simply set
Proof. absorbed loss function hypotheses ,
"
-fold products
. Thus (1) follows Lemma 31. (2) (3)
2. G







/

/



/





















immediate definitions. permissible , (4) proved
identical argument used Measurable Suprema section Pollard (1984), appendix
C.


j}


j}
, function
defined
(5), note Borel-measurable








Borel measurable Kechris (1995, chapter 17). Now, permissibility




,

measurable
automatically implies permissibility

/
(4).
r



j}
appropriate way. prove (6),
let indexed




j}
1
_

}

E





_E



. Fubinis theorem
define




j}
E






-measurable function. Let
defined

1_}E
indexes
appropriate way
permissible, provided
.

-measurable. analyticity becomes important. Let
shown




1_}E _E
. property (b) analytic sets,
.


contains

1
E



1
E








set
projection
onto
, property (c)
n

also analytic.

assumed complete,
measurable, property (a). Thus
measurable function permissibility
follows.

)

kj .

0

)




;[m ff ;[fiff
qp )

'#on ) ) r[fiY
G
c c )
)
p


)

G

ff



W

lj .
)





4

195

c

c

f '# f
@





ff




)



c

fiBAXTER

References
Abu-Mostafa, Y. (1993). method learning hints. Hanson, S. J., Cowan, J. D., & Giles,
C. L. (Eds.), Advances Neural Information Processing Systems 5, pp. 7380 San Mateo,
CA. Morgan Kaufmann.
Anthony, M., & Bartlett, P. L. (1999). Neural Network Learning: Theoretical Foundations. Cambridge University Press, Cambridge, UK.
Bartlett, P. L. (1993). Lower bounds VC-dimension multi-layer threshold networks.
Proccedings Sixth ACM Conference Computational Learning Theory, pp. 44150
New York. ACM Press. Summary appeared Neural Computation, 5, no. 3.
Bartlett, P. L. (1998). sample complexity pattern classification neural networks:
size weights important size network. IEEE Transactions
Information Theory, 44(2), 525536.
Baxter, J. (1995a). Learning Internal Representations. Ph.D. thesis, Department Mathematics Statistics, Flinders University South Australia. Copy available
http://wwwsyseng.anu.edu.au/ jon/papers/thesis.ps.gz.



Baxter, J. (1995b). Learning internal representations. Proceedings Eighth International
Conference Computational Learning Theory, pp. 311320. ACM Press. Copy available
http://wwwsyseng.anu.edu.au/ jon/papers/colt95.ps.gz.



Baxter, J. (1997a). Bayesian/information theoretic model learning learn via multiple task
sampling. Machine Learning, 28, 740.
Baxter, J. (1997b). canonical distortion measure vector quantization function approximation. Proceedings Fourteenth International Conference Machine Learning,
pp. 3947. Morgan Kaufmann.
Baxter, J., & Bartlett, P. L. (1998). canonical distortion measure feature space 1-NN
classification. Advances Neural Information Processing Systems 10, pp. 245251. MIT
Press.
Berger, J. O. (1985). Statistical Decision Theory Bayesian Analysis. Springer-Verlag, New
York.
Blumer, A., Ehrenfeucht, A., Haussler, D., & Warmuth, M. K. (1989). Learnability vapnikchervonenkis dimension. Journal ACM, 36, 929965.
Caruana, R. (1997). Multitask learning. Machine Learning, 28, 4170.
Devroye, L., Gyorfi, L., & Lugosi, G. (1996). Probabilistic Theory Pattern Recognition.
Springer, New York.
Dudley, R. M. (1984). Course Empirical Processes, Vol. 1097 Lecture Notes Mathematics, pp. 2142. Springer-Verlag.
Dudley, R. M. (1989). Real Analysis Probability. Wadsworth & Brooks/Cole, California.
196

fiA ODEL NDUCTIVE B IAS L EARNING

Gelman, A., Carlin, J. B., Stern, H. S., & Rubim, D. B. (Eds.). (1995). Bayesian Data Analysis.
Chapman Hall.
Good, I. J. (1980). history hierarchical Bayesian methodology. Bernardo, J. M.,
Groot, M. H. D., Lindley, D. V., & Smith, A. F. M. (Eds.), Bayesian Statistics II. University
Press, Valencia.
Haussler, D. (1992). Decision theoretic generalizations pac model neural net
learning applications. Information Computation, 100, 78150.
Heskes, T. (1998). Solving huge number similar tasks: combination multi-task learning
hierarchical Bayesian approach. Shavlik, J. (Ed.), Proceedings 15th International
Conference Machine Learning (ICML 98), pp. 233241. Morgan Kaufmann.
Intrator, N., & Edelman, S. (1996). make low-dimensional representation suitable
diverse tasks. Connection Science, 8.
Kechris, A. S. (1995). Classical Descriptive Set Theory. Springer-Verlag, New York.
Khan, K., Muggleton, S., & Parson, R. (1998). Repeat learning using predicate invention. Page,
C. D. (Ed.), Proceedings 8th International Workshop Inductive Logic Programming
(ILP-98), LNAI 1446, pp. 65174. Springer-Verlag.
Langford, J. C. (1999). Staged learning. Tech. rep., CMU, School Computer Science.
http://www.cs.cmu.edu/ jcl/research/ltol/staged latest.ps.



Mitchell, T. M. (1991). need biases learning generalisations. Dietterich, T. G., &
Shavlik, J. (Eds.), Readings Machine Learning. Morgan Kaufmann.
Parthasarathy, K. R. (1967). Probabiliity Measures Metric Spaces. Academic Press, London.
Pollard, D. (1984). Convergence Stochastic Processes. Springer-Verlag, New York.
Pratt, L. Y. (1992). Discriminability-based transfer neural networks. Hanson, S. J.,
Cowan, J. D., & Giles, C. L. (Eds.), Advances Neural Information Processing Systems 5,
pp. 204211. Morgan Kaufmann.
Rendell, L., Seshu, R., & Tcheng, D. (1987). Layered concept learning dynamically-variable
bias management. Proceedings Tenth International Joint Conference Artificial
Intelligence (IJCAI 87), pp. 308314. IJCAI , Inc.
Ring, M. B. (1995). Continual Learning Reinforcement Environments. R. Oldenbourg Verlag.
Russell, S. (1989). Use Knowledge Analogy Induction. Morgan Kaufmann.
Sauer, N. (1972). density families sets. Journal Combinatorial Theory A, 13,
145168.
Sharkey, N. E., & Sharkey, A. J. C. (1993). Adaptive generalisation transfer knowledge.
Artificial Intelligence Review, 7, 313328.
197

fiBAXTER

Silver, D. L., & Mercer, R. E. (1996). parallel transfer task knowledge using dynamic
learning rates based measure relatedness. Connection Science, 8, 277294.
Singh, S. (1992). Transfer learning composing solutions elemental sequential tasks. Machine Learning, 8, 323339.
Slud, E. (1977). Distribution inequalities binomial law. Annals Probability, 4, 404412.
Suddarth, S. C., & Holden, A. D. C. (1991). Symolic-neural systems use hints developing complex systems. International Journal Man-Machine Studies, 35, 291311.
Suddarth, S. C., & Kergosien, Y. L. (1990). Rule-injection hints means improving network performance learning time. Proceedings EURASIP Workshop Neural
Networks Portugal. EURASIP.
Sutton, R. (1992). Adapting bias gradient descent: incremental version delta-bar-delta.
Proceedings Tenth National Conference Artificial Intelligence, pp. 171176. MIT
Press.
Tate, R. F. (1953). double inequality normal distribution. Annals Mathematical
Statistics, 24, 132134.
Thrun, S. (1996). learning n-th thing easier learning first?. Advances Neural
Information Processing Systems 8, pp. 640646. MIT Press.
Thrun, S., & Mitchell, T. M. (1995). Learning one thing. Proceedings International
Joint Conference Artificial Intelligence, pp. 12171223. Morgan Kaufmann.
Thrun, S., & OSullivan, J. (1996). Discovering structure multiple learning tasks: TC algorithm. Saitta, L. (Ed.), Proceedings 13th International Conference Machine
Learning (ICML 96), pp. 489497. Morgen Kaufmann.
Thrun, S., & Pratt, L. (Eds.). (1997). Learning Learn. Kluwer Academic.
Thrun, S., & Schwartz, A. (1995). Finding structure reinforcement learning. Tesauro, G.,
Touretzky, D., & Leen, T. (Eds.), Advances Neural Information Processing Systems, Vol. 7,
pp. 385392. MIT Press.
Utgoff, P. E. (1986). Shift bias inductive concept learning. Machine Learning: Artificial
Intelligence Approach, pp. 107147. Morgan Kaufmann.
Valiant, L. G. (1984). theory learnable. Comm. ACM, 27, 11341142.
Vapnik, V. N. (1982). Estimation Dependences Based Empirical Data. Springer-Verlag, New
York.
Vapnik, V. N. (1996). Nature Statistical Learning Theory. Springer Verlag, New York.

198

fiJournal Artificial Intelligence Research 12 (2000) 339{386

Submitted 12/99; published 6/00

Reasonable Forced Goal Orderings Use
Agenda-Driven Planning Algorithm

jana koehler@ch.schindler.com

Jana Koehler
Schindler Lifts, Ltd.
R & Technology Management
6031 Ebikon, Switzerland
Jorg Hoffmann
Institute Computer Science
Albert Ludwigs University
Georges-Kohler-Allee, Geb. 52
79110 Freiburg, Germany

hoffmann@informatik.uni-freiburg.de

Abstract

paper addresses problem computing goal orderings, one
longstanding issues AI planning. makes two new contributions. First, formally
defines discusses two different goal orderings, called reasonable
forced ordering. orderings defined simple STRIPS operators well
complex ADL operators supporting negation conditional effects. complexity
orderings investigated practical relevance discussed. Secondly, two
different methods compute reasonable goal orderings developed. One
based planning graphs, investigates set actions directly. Finally,
shown ordering relations, derived given set goals
G , used compute so-called goal agenda divides G ordered set
subgoals. planner then, principle, use goal agenda plan increasing
sets subgoals. lead exponential complexity reduction, solution
complex planning problem found solving easier subproblems. Since polynomial
overhead caused goal agenda computation, potential exists dramatically speed
planning algorithms demonstrate empirical evaluation, use
method IPP planner.
1. Introduction

effectively plan interdependent subgoals focus AI planning
research long time. Starting early work ABSTRIPS (Sacerdoti, 1974)
conjunctive-goal planning problems (Chapman, 1987), quite number approaches
presented complexity problems studied. today,
planners made progress solving bigger planning instances scalability
classical planning systems still problem.
paper, focus following problem: Given set conjunctive goals,
define detect ordering relation subsets original goal set? arrive
ordering relation subsets, first focus atomic facts contained
goal set. formally define two closely related ordering relations atomic goals,
c 2000 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiKoehler & Hoffmann
call reasonable forced ordering, study complexity. turns
hard decide.
Consequently, introduce two ecient methods used approximate
reasonable goal orderings. definitions first given simple STRIPS domains,
desired theoretical properties easily proven. Afterwards, extend definitions
ADL operators (Pednault, 1989) handling conditional effects negative preconditions,
discuss invest effort trying find forced orderings.
show set ordering relations atomic goals used divide
goal set disjunct subsets, subsets ordered respect
other. resulting sequence subsets comprises so-called goal agenda,
used control agenda-driven planning algorithm.
method, called Goal Agenda Manager, implemented context IPP
planning system, show potential exponentially reducing computation times
certain planning domains.
paper organized follows: Section 2 introduces motivates reasonable
forced goal orderings. Starting simple STRIPS operators, formally defined,
complexity investigated. Section 3, present two methods, compute approximation reasonable ordering discuss orderings
practical point view. section concludes extension definitions ADL
operators conditional effects. Section 4 shows planning system benefit
ordering information computing goal agenda guides planner. define
subsets goals ordered respect discuss goal
agenda affect theoretical properties, particular completeness planning
algorithm. Section 5 contains empirical evaluation work, showing results
obtained using goal agenda IPP. Section 6 summarize approach light
related work. paper concludes outlook possible future research directions
Section 7.
2. Ordering Relations Atomic Goals

start, investigate simple STRIPS domains allowing sets atoms
describe states, preconditions, add delete lists operators.
Definition 1 (State) set ground atoms denoted P . state 2 2
P

subset ground atoms.

Note states assumed complete, i.e., always know atom p whether
p 2 p 62 holds. also assume operator schemata ground, i.e.,
talk actions.
Definition 2 (Strips Action) STRIPS action usual form
pre(o) ! ADD add(o) DEL del(o)
pre(o) preconditions o, add(o) Add list del(o) Delete
list action, set ground atoms. also assume del(o) \ add(o) = ;.
result applying STRIPS action state defined usual:
340

fiOn Reasonable Forced Goal Orderings

Result(s; o) :=



(s [ add(o)) n del(o) pre(o)
otherwise



pre(o) holds, action said applicable s. result applying
sequence one action state recursively defined
Result(s; ho1 ; : : : ;

i) := Result(Result(s; ho1 ; : : : ; 1 i); ):
Definition 3 (Planning Problem) planning problem (O; ; G ) triple
set actions, (the initial state) G (the goals) sets ground atoms.
plan P ordered sequence actions. actions plan taken certain
action set O, denote writing P .
n

n

n

Note define plan sequence actions, sequence parallel steps,
done graphplan (Blum & Furst, 1997), example. makes subsequent
theoretical investigation readable. results directly carry parallel plans.
Given two atomic goals B , various ways define ordering relation
imagined. First, one distinguish domain-specific domainindependent goal ordering relations. although domain-specific orderings
effective, need redeveloped single domain. Therefore, one particular
interested domain-independent ordering relations broader range applicability.
Secondly, following Hullem et al. (1999), one distinguish goal selection goal
achievement order. first ordering determines order planner works
various atomic goals, second one determines order, solution
plan achieves goals. paper, compute ordering latter type.
agenda-driven planning approach propose later paper, orderings
coincide anyway. goals achieved first plan planner
works first.
following scenario motivates achievement order goals possibly
defined. Given two atomic goals B , solution plan exists, let us assume
planner achieved goal A, i.e., arrived state s( : ) ,
holds, B hold yet. Now, exists plan executable s( : )
achieves B without ever deleting A, solution found. plan
found, two possible reasons exist:
1. problem unsolvable|achieving first leads planner deadlock situation. Thus, planner forced achieve B simultaneously A.
2. existing solution plans destroy temporarily order achieve B .
then, achieved first. Instead, seems reasonable achieve
B simultaneously sake shorter solution plans.
first situation, ordering \B simultaneously A" forced inherent properties planning domain. second situation, ordering \B
simultaneously A" appears reasonable order avoid non-optimal plans. Consequently, define two goal orderings, called forced reasonable ordering.
sake clarity, first give basic definitions.
A;

B

A;

341

B

fiKoehler & Hoffmann
Definition 4 (Reachable State) Let (O; ; G ) planning problem let P

set ground atoms occur problem. say state P reachable, iff
exists sequence ho1 ; : : : ; actions = Result(I ; ho1 ; : : : ; i)
holds.
n

n

Definition 5 (Generic State s( : ) ) Let (O; ; G ) planning problem. s( :
A;

B

A;

B

)

denote reachable state achieved, B false,
i.e., B 62 s( : ) sequence actions ho1 ; : : : ; s( : ) =
Result(I ; ho1 ; : : : ; i), 2 add(o ).
A;

n

B

n

A;

B

n

One imagine s( : ) state incomplete information.
states represents satisfy j= A; :B , atoms p 2 P p 6= A; B
adopt arbitrary truth values.
Definition 6 (Reduced Action Set ) Let (O; ; G ) planning problem, let
A;

B



2 G atomic goal. denote set actions delete A,
i.e., = fo 2 j 62 del(o)g.




prepared define exactly mean forced reasonable goal orderings.
Definition 7 (Forced Ordering ) Let (O; ; G ) planning problem, let A; B 2
G two atomic goals. say forced ordering B A, written
f

B A,
f

: :9 P : B 2 Result(s( : ) ; P )
Definition 7 satisfied, plan achieving B must achieve B
simultaneously A, otherwise encounter deadlock, rendering
problem unsolvable.
Definition 8 (Reasonable Ordering ) Let (O; ; G ) planning problem, let
A; B 2 G two atomic goals. say reasonable ordering B

8 s(

:

A;

B

)

A;

B

r

A, written B A,
r

8 s( : ) : :9 P OA : B 2 Result(s( : ) ; P OA )
Definition 8 gives B meaning if, goal achieved,
A;

B

A;

B

r

plan anymore achieves B without|at least temporarily|destroying A, B
goal prior A.
remark obviously B implies B A, vice versa. also make
slightly less obvious observation point: formulae Definitions 7 8 use
universal quantification states s( : ) . planning problem
state all, formulae satisfied goals B get ordered, i.e., B
B follow, respectively. case, however, much information gained
goal ordering B , sequence actions achieve B prior
simultaneously A|A cannot achieved B still false. Thus
case, ordering relations B B trivial sense reasonable
planner would invest much effort considering goals B ordered way
round anyway.
r

f

A;

B

f

r

f

r

342

fiOn Reasonable Forced Goal Orderings
Definition 9 (Trivial Ordering Relation) Let (O; ; G ) planning problem, let
A; B 2 G two atomic goals. ordering relation B
state s( : ) .
A;



f

B called
r

trivial iff

B

paper, usually consider forced reasonable goal orderings non-trivial
orderings make distinction explicit so.
Definitions 7 8 seem deliver promising candidates achievement order.
Unfortunately, hard test: turns corresponding decision
problems PSPACE hard.
Theorem 1 Let F ORDER denote following problem:

Given two atomic facts B , well action set initial state ,
B hold ?
f

Deciding F ORDER PSPACE-hard.

Proof: proof proceeds polynomially reducing

PLANSAT (Bylander, 1994)|the
decision problem whether exists solution plan given arbitrary STRIPS
planning instance|to problem deciding F ORDER.

Let , G , denote initial state, goal state, action set arbitrary
STRIPS instance. Let A, B , C new atomic facts contained instance
far. build new action set initial state F ORDER instance setting

8
<
O0 := [ :

o1
o2




G

9
! ADD fAg DEL fC g; =
! ADD DEL fAg; ;
! ADD fB g DEL ;

= fC g
= fAg
=G



0 := fC g
definitions, reaching B equivalent solving original problem.
way round, unreachability B A|forced ordering B A|is equivalent
unsolvability original problem. order prove this, consider following:
way achieving applying 1 0 . Consequently, state s( : )
fAg, cf. Definition 5. Thus starting assumption B valid, apply
following equivalences:
f



A;

B

f

B
f

,
,
,
,

8 s( : ) : :9 P O0 : B 2 Result(s( : ) ; P O0 )
cf. Definition 7
0
0
:9 P : B 2 Result(fAg; P )
fAg reachable state s( : )
:9 P : G Result(I ; P )
definition 0
solution plan exists ; G given
A;

B

A;

B

A;

343

B

fiKoehler & Hoffmann
Thus, complement PLANSAT polynomially reduced F ORDER. PSPACE
= co-PSPACE, done.
Theorem 2 Let R ORDER denote following problem:

Given two atomic facts B , well action set initial state ,
B hold ?
Deciding R ORDER PSPACE-hard.
r

Proof: proof proceeds polynomially reducing PLANSAT R ORDER.

Let , G , initial state, goal state, action set arbitrary
STRIPS planning instance. Let A, B , C , new atomic facts contained
instance far. define new action set O0 setting
8
9
1 = fC g
! ADD fA; Dg DEL fC g; =
<
O0 := [ : 2 = fA; Dg ! ADD DEL fDg;
;
=G
! ADD fB g DEL ;



G

new initial state

0 := fC g

proof Theorem 1, intention behind definitions make solvability
original problem equivalent reachability B A. reasonable orderings,
reachability concerned actions delete A, need safety
condition D.
Precisely, way achieve applying 1 0, i.e., per Definition 5
state s( : ) fA; Dg. action new operator set O0 deletes A,
following sequence equivalences.


A;

B

B
8 s( : ) :9 P OA0 : B 2 Result(s( : ); P OA0 )
:9 P OA0 : B 2 Result(fA; Dg; P OA0 )
r

,
,
, :9 P O0 : B 2 Result(fA; Dg; P O0 )
, :9 P G Result(I ; P )
, solution plan exists ; G ;
A;

B

A;

B

cf. Definition

fA; Dg reachable state s( : )
action 0 deletes
definition 0
A;

B

Thus, complement PLANSAT polynomially reduced R ORDER.
PSPACE = co-PSPACE, done.
Consequently, finding reasonable forced ordering relations atomic goals
already hard original planning problem appears unlikely planner
gain advantage that. possible way dilemma define new
ordering relations, decided polynomial time are, ideally, sucient
existence reasonable forced goal orderings. following, introduce two
orderings.
344

8

fiOn Reasonable Forced Goal Orderings
3. Computation Goal Orderings

section,
1. define goal ordering , computed using graphplan's exclusivity
information facts. prove ordering sucient
decided polynomial time (the subscript \e" stands \ecient").
2. define goal ordering , computed based heuristic method
much faster computation based graphplan, also delivers powerful
goal ordering information (the subscript \h" stands \heuristic").
3. discuss currently available benchmark planning domains contain forced orderings, i.e., fail providing problem decomposition them.
4. show orderings extended handle expressive ADL operators.
e

r

h

f

3.1 Reasonable Goal Orderings based graphplan

goal ordering always computed specific planning problem involving initial
state , goal set G fA; B g, set ground actions. order develop
ecient computational method, proceed two steps now:
1. compute knowledge generic state s( : ) .
2. define relation investigate theoretical properties. particular,
prove implies .
A;

B

e

e

r

state s( : ) represents states reachable ,
achieved, B hold. Given information s( : ) , one derive
additional knowledge it. particular, possible determine subset atoms F,
one definitely knows F \ s( : ) = ; must hold. One method determine F
obtained via computation invariants, i.e., logical formulae hold reachable
states, cf. (Fox & Long, 1998). determined invariants, one assumes
holds, B not, computes logical implications. Another possibility
simply use graphplan (Blum & Furst, 1997). Starting O, planning graph
built graph leveled time step. proposition level time
step represents set states, superset states reachable
applying actions O. atoms, marked mutually exclusive (Blum
& Furst, 1997) level never hold state satisfying A. Thus, cannot
hold s( : ) . denote set F |the False set respect returned
1
graphplan.
F
:= fp j p exclusive graph leveled offg
(1)
Note planning graph grown given O, used
determine F sets atomic goals 2 G .
A;

B

A;

A;

A;

B

B


GP

B


GP



GP

1. assume reader familiar graphplan, planning system well known
planning research community. Otherwise, (Blum & Furst, 1997) provide necessary background.

345

fiKoehler & Hoffmann

\ = ; holds states
using actions O.
Lemma 1



FGP





satisfying 2 reachable


proof follows immediately definitions \level-off" \two propositions
mutual exclusive" given (Blum & Furst, 1997).
provide simple test sucient existence reasonable ordering
B two atomic goals B .
Definition 10 (Ecient Ordering ) Let (O; ; G fA; B g) planning problem.
r

e

Let F



GP

False set A. ordering B holds
e

8 2 : B 2 add(o) ) pre(o) \ F 6= ;

GP



means, B ordered reduced action set contains actions,
either B add lists do, require precondition
contained False set. preconditions never hold state satisfying
thus, actions never applicable.
Theorem 3
B A)B
e

r

Proof: Assume B 6 A, i.e., B 2 Result(s( : ) ; P OA ) reachable state s( :
r

A;

B

A;

B

)

2 s( : ) , B 62 s( : ) , Plan P OA = ho1 ; : : : ; 2 1 n.
62 del(o ) (Definition 6),
2 Result(s( : ) ; ho1 ; : : : ; i) 0 n
and, Lemma 1,
F
\ Result(s( : ) ; ho1 ; : : : ; i) = ; 0 n
(2)
Furthermore, B 62 s( : ) , B 2 Result(s( : ) ; ho1 ; : : : ; i), must
step makes B true, i.e.,
91 k n : B 62 Result(s( : ); ho1 ; : : : ; 1i) ^ B 2 Result(s( : ); ho1 ; : : : ; i)
step, obviously B 2 add(o ) consequently, definition
B A, pre(o ) \ F 6= ;. Now, must applicable state
executed (otherwise would add anything state), preconditions
must hold, i.e., pre(o ) Result(s( : ) ; ho1 ; : : : ; 1 i). immediately leads F \
Result(s( : ) ; ho1 ; : : : ; 1 i) 6= ;, contradiction Equation (2).
Quite obviously, ordering decided polynomial time.
A;

B

A;

n

B







A;



B



A;

GP

A;



B

B

A;

A;

n

B

k

B

A;

B

k

k

e


GP

k

k

k

k

A;

B

A;


GP

k

B

k

e

Theorem 4 Let E ORDER denote following problem:

Given two atomic facts B , well initial state action set O,

B hold ?
e

Then, E ORDER decided polynomial time:
346

E ORDER

2 P.

fiOn Reasonable Forced Goal Orderings
Proof: begin with, need show computing F

takes polynomial time.
results (Blum & Furst, 1997), follows directly building planning graph
polynomial jIj, jOj, l t, l maximal length precondition, add
delete list action, number time steps built. Taking l parameter
input size, remains show planning graph levels polynomial
number time steps. Now, planning graph leveled time steps
+ 1 neither set facts number exclusion relations change.
two subsequent time steps, set facts increase|facts already occuring
graph remain there|and number exclusions decrease|non-exclusive facts
non-exclusive subsequent layers. Thus, maximal number time steps
built graph leveled dominated maximal number changes
occur two subsequent layers, dominated maximal number
facts plus maximal number exclusion relations. maximal number facts
O(jIj + jOj l), maximal number exclusions O((jIj + jOj l)2 ), square
maximal number facts.
computed F polynomial time, testing B involves looking actions
O, rejecting either
delete A, decidable time O(l),
precondition, element F , decidable time O(l (jIj + jOj l)).
Thus additional runtime test, O(jOj l (jIj + jOj l)).

GP


GP

e


GP

Let us consider following example, illustrates computation using
common representational variant blocks world actions stack, unstack,
pickup, putdown blocks:
e

pickup(?ob)

clear(?ob) on-table(?ob) arm-empty()

! ADD holding(?ob)

DEL clear(?ob) on-table(?ob) arm-empty().

putdown(?ob)
holding(?ob)

! ADD clear(?ob) arm-empty() on-table(?ob)
DEL holding(?ob).

stack(?ob,?underob)

clear(?underob) holding(?ob)

unstack(?ob,?underob)

! ADD arm-empty() clear(?ob) on(?ob,?underob)
DEL clear(?underob) holding(?ob).

on(?ob,?underob) clear(?ob) arm-empty()

! ADD holding(?ob) clear(?underob)

DEL on(?ob,?underob) clear(?ob) arm-empty().

Given simple task stacking three blocks:
initial state: on-table(a) on-table(b) on-table(c)
goal state: on(a,b) on(b,c)
347

fiKoehler & Hoffmann
reasonable ordering two atomic goals? Intuitively, blocks world
domain possesses natural goal ordering, namely planner start building
tower bottom top way round.2
Let us first investigate whether relation on(a; b) on(b; c) holds. Vividly speaking,
asks whether still possible stack block b on(b; c) achieved.
first step, run graphplan find atoms exclusive on(b; c)
planning graph, corresponds problem, leveled off. result
e

(

)

b;c

FGP

= fclear(c), on-table(b), holding(c), holding(b), on(a,c), on(c,b), on(b,a)g

One observes immediately atoms never true state satisfies

on(b; c).

Secondly, remove ground actions delete on(b; c) (in case, action
( ).
ready test on(a; b) on(b; c) holds. action, add
on(a; b) stack(a,b). preconditions holding(a) clear(b), neither
member F ( ) . test fails get on(a; b) 6 on(b; c).
next step, test whether on(b; c) on(a; b) holds. graphplan returns
following False set:

unstack(b,c) satisfies condition) obtain reduced action set

b;c

e

b;c

e

GP

e

(

)

a;b

FGP

= fclear(b), on-table(a), holding(b), holding(a), on(a,c), on(c,b), on(b,a)g

action unstack(a,b) contained ( ) deletes on(a; b).
action adds on(b; c) stack(b,c). needs preconditions clear(c)
holding(b). second precondition holding(b) contained set false facts,
i.e., holding(b) 2 F ( ) thus, conclude on(b; c) on(a; b). Altogether,
on(a; b) 6 on(b; c) on(b; c) on(a; b), correctly ects intuition b
needs stacked onto c stacked onto b.
Although appears impose strict conditions domain order derive
reasonable goal ordering, succeeds finding reasonable goal orderings available test
domains orderings exists. example, tyreworld, bulldozer problems,
shopping problem (Russel & Norvig, 1995), fridgeworld, glass domain,
tower hanoi domain, link-world, woodshop. disadvantage
computational resources requires, since building planning graphs, theoretically
polynomial, quite time- memory-consuming thing do.3
Therefore, next section presents fast heuristic computation goal orderings,
analyzes domain actions directly need build planning graphs anymore.
a;b

a;b

e

GP

e

e

e

2. Note goals specify block c go, leave planner.
3. recent implementations planning graphs, example developed STAN (Fox &
Long, 1999) IPP 4.0 (Koehler, 1999) build graphs explicitly anymore orders
magnitude faster original graphplan implementation, still computation planning
graph takes almost time needed determine e relations.

348

fiOn Reasonable Forced Goal Orderings
3.2 Reasonable Goal Orderings derived Fast Heuristic Method

One analyze available actions directly using method call Direct Analysis
(DA). determines initial value F computing intersection delete lists
actions contain add list, defined following equation.


FDA

\

:=


2O 2
;

( )

del(o)

(3)

add

atoms set false state achieved:
deleted state description independently action used add A.
short example, let us consider two actions

! ADD fAg DEL fC; Dg
! ADD fA; C g DEL fDg
atom deleted actions, thus element initially
contained F .
However, Equation (3) says added atoms F
deleted. say anything whether might possible reestablish atoms
F . One easily imagine actions exist, leave true,
time add atoms. case, reachable states atoms
F hold.
Now, goal derive ordering relation easily computed,
ideally, like relation, sucient relation. Therefore, want make
sure atoms F really false state achieved.
arrive approximation atoms remain false performing fixpoint reduction
F set, removing atoms achievable following sense.

DA


DA


DA


DA

e

r



DA



DA

Definition 11 (Achievable Atoms) atom p achievable state given
action set (written A(s; p; O))
p2s

_ 9 2 : p 2 add(o) ^ 8 p0 2 pre(o) : A(s; p0; O)

definition says atom p achievable state holds s,
exists action domain, adds p whose preconditions achievable
s. necessary condition existence plan P state
p holds.
Lemma 2 9 P : p 2 Result(s; P ) ) A(s; p; O)
Proof: atom p must either already contained state s, added

step P . second case, preconditions need established
P way. Thus p preconditions step, adds it, achievable
sense Definition 11.
349

fiKoehler & Hoffmann
two obvious diculties Definition 11: First, p 2 must tested.
complete knowledge state s, cause problems. case,
however, generic state s( : ) cannot decide whether arbitrary
atom contained not. Secondly, observe infinite regression preconditions,
must tested achievability.
first problem, turns good heuristic simply assume p 62 s,
i.e., test performed all. second problem, order avoid infinite
looping \achievable"-test, one needs terminate regression preconditions
particular level. point question far regress? quick approximation
simply decides \achievable" first recursive call.
A;

B

Definition 12 (Possibly Achievable Atoms) atom p possibly achievable given
action set (written pA(p; O))
9 2 : p 2 add(o) ^ 8 p0 2 pre(o) :

9 o0 2 : p0 2 add(o0 )

holds, i.e., action adds p preconditions add effects
actions O.

assumption justified none atoms p contained state s,
possibly achievable necessary condition achievable.
Lemma 3 Let state p 62 also 8o 2 : p 2 add(o) ) pre(o) \ = ;

holds.

A(s; p; O) ) pA(p; O)
Proof: A(s; p; O) p 62 s, know step 2 O, p 2 add(o),

8 p0 2 pre(o) A(s; p0; O). also know pre(o) \ = ;, p0 2 pre(o)
must achiever o0 2 : p0 2 add(o0 ).

condition facts p must contained state seems
rather rigid. Nevertheless, condition possibly achievable delivers good results
benchmark domains easy decide. use test

perform fixpoint reduction set F
decide whether atomic goal B ordered A.

DA

fixpoint reduction, depicted Figure 1 below, uses approximative test pA(f; )
remove facts F achieved. finds facts certain
restrictions, see below. side effect fixpoint algorithm, obtain set
actions method assumes applicable state s( : ) . order B
iff cannot possibly achieved using actions.

DA

A;

350

B

fiOn Reasonable Forced Goal Orderings
:= F
:= n fo j F \ pre(o) 6= ;g
fixpoint reached := false
:fixpoint reached
fixpoint reached := true
f 2 F
pA(f; )


F := F n ff g
:= n fo j F \ pre(o) 6= ;g
fixpoint reached := false
F



DA




endif
endfor
endwhile
return F ,

Figure 1: Quick, heuristic fixpoint reduction set F .

DA

computation checks whether atoms F , initially set F , possibly
achievable using actions, delete require atoms
F precondition. Achievable atoms removed F , gets updated
accordingly. one iteration, F change, fixpoint reached, i.e., F
decrease increase|the final sets F false facts
applicable actions returned.
Let us illustrate fixpoint computation short example consisting empty
initial state, goals fA; B g, following set actions


DA

op1:
op2:
op3: f C g
op4: f g

!
!
!
!

ADD f g
ADD fA, C g
ADD f g
ADD f B g

DEL f C, g
DEL f g

assuming achieved, obtain F = F = fDg initial
value False set, since atom op1 op2 delete adding A.
Figure 2 illustrates hypothetical planning process. Starting empty initial state
trying achieve first, get two different states s( : ) holds.
atom hold thus states, action applicable
requires precondition. excludes op4 , yielding initial action set
= fop1; op2; op3g. Now, op4 action add B . Therefore, used
action set see B still achieved, would find case.
Consequently, without performing fixpoint computation, would order B A.
seen Figure 2, would reasonable ordering: plan
hop3 ;op4i achieves B state s( : ) = Result(I ;op2) without destroying A.
fixpoint computation works us around problem follows: action op3, add precondition op4 without deleting A. checking
pA(D; ) first iteration, fixpoint procedure finds action. checks


DA

A;



A;

351

B

B

fiKoehler & Hoffmann
whether preconditions op3 achievable sense added another action. case since precondition C added op2. Thus,
removed F , becomes empty now. action op4 put back set ,
becomes identical action set . set, turn, identical
original action set action deletes A. fixpoint process terminates B
ordered achieved using action op4. correctly ects
fact exists plan state s( : ) = Result(I ; hop2i) = fC; Ag
state satisfies B without destroying A.


A;

B

0/

Deadlock

op1

op2



C,
op3
C, A,

holds state satisfying

op4
C, A, D, B

plan B

Figure 2: example illustrating need fixpoint computation.
already pointed out, intention behind fixpoint procedure following:
Starting state s( : ) , want know facts become true without
destroying A, consequently, actions become applicable. first step,
actions use facts F applicable, facts
deleted state description added. However, actions may make facts
F true, want remove facts F . manage find facts
made true without destroying A, final set F contain
facts hold state reachable s( : ) without destroying A. case,
final action set contain actions applied s( : ) ,
safely use action set determine whether another goal B still achieved
not.
However, use approximative test pA(f; O) f 2 F find
fact current F set achievable, may facts achievable without
destroying A, remain set F . could exclude actions set
safely applied s( : ). certain restrictions, however,
prove happen. order so, need impose restriction
particular state s( : ) , achieved goal A: none preconditions
actions, add facts contained F , occur state s( : ) , fixpoint
procedure remove facts F achievable without destroying A.
use property fixpoint procedure later show heuristic ordering relation
approximates reasonable orderings.
A;

B



DA


DA


DA

A;

B

A;

A;

A;

B

B


DA

A;



DA

352

B

B

fiOn Reasonable Forced Goal Orderings
Lemma 4 Let (O; ; G ) planning problem, let 2 G atomic goal. Let
s( : ) reachable state achieved. Let P OA = ho1 ; : : : ;
sequence actions destroying A. Let F set facts returned
fixpoint computation depicted Figure 1.
A;

n

B

8f 2 F


DA

: 8o 2 : f 2 add(o) ) pre(o) \ s( : ) = ;


A;

()

B

fact F holds state reached applying P OA , i.e.,
Result(s( : ) ; P OA ) \ F = ;
A;

B

Proof:

Let F denote state fact action sets, respectively, j iterations
algorithm depicted Figure 1. F decreases computation,


F F j . Let s0 ; : : : ; denote sequence states encountered
executing P OA = ho1 ; : : : ; s( : ) , i.e., s0 = s( : ) = Result(s 1 ; ho i)
0 n. assume action applicable state 1 , i.e., pre(o ) 1 .
Otherwise, cause state transition, skip P OA . Obviously,
= Result(s( : ) ; P OA ), need show \ F = ;. proof proceeds
induction length n P OA .
n = 0: P OA = hi = s0 = s( : ) . facts F deleted state
description added, \ F = ;. F = F0 F F0 ,
proposition follows immediately.
n ! n + 1: P OA = ho1 ; : : : ; ; +1 i. induction hypothesis, know
\ F = ; 0 n. need show +1 \SF = ;.
Let j step fixpoint iteration F \ =0 becomes empty, i.e., j
denotes iteration intersection states ; n F empty
first time. iteration exists, intersections \ F n
empty.
action ; 1 n + 1 applicable state 1 , i.e., pre(o ) 1 ,
thus pre(o ) \ F = ; actions P OA . Therefore, actions contained
, set contains actions whose intersection F empty.
Let us focus facts state +1 . facts achieved executing P OA
s( : ) . words, plan s( : ) facts.
seen, plan consists actions . Applying Lemma 2 facts p 2 +1
using s( : ) P OA (= P Oj ), know facts p achievable using actions
.
j

j

n

j

n

A;

B

A;



B















n

A;

n

B

n

A;


DA

B

n

n





DA

DA

n



n

j



;:::;n





j















j



j

j

n

A;

B

A;

B

n

j

A;

B

j

: A(s( : ) ; p; )
show facts f 2 +1 interested in, namely F facts
added +1 still contained F , also possibly achievable using actions
. Let f fact f 2 +1 , f 2 F . apply Lemma 3 using s( : ) , f ,

8p 2

+1

n

A;

B

j

n

n

j

j

n

j

353

A;

B

fiKoehler & Hoffmann

O. apply Lemma 3 obviously f 62 s( : ) , 8o 2 : f 2 add(o) )
pre(o) \ s( : ) = ; prerequisite (). A(s( : ) ; p; ), arrive
8f 2 +1 \ F : pA(f; O)
A;

j

A;

B

A;

n

B

j

B

j

j

j

remains proven facts f removed F
fixpoint computation. argumentation above, sucient show
facts f 2 +1 \ F get tested pA(f; ) iteration j +1 fixpoint computation.
tests succeed lead +1 \ F+1 = ;, yielding, desired, +1 \ F = ;.
Remember F+1 F . two cases, need consider:
1. j = 0: intersections \ F0 initially empty, i.e., \ F = ; 0 n.
case, facts f 2 +1 \ F tested pA(f; O0 ) iteration j + 1 = 1
fixpoint computation.
2. j > 0: case, least one intersections \ F became empty iteration
j definition j , i.e., least one fact removed F iteration.
Therefore, fixpoint reached yet, computation performs
least one iteration, namely iteration j + 1. facts F tested
iteration, particular facts f 2 +1 \ F .
observations, induction complete proposition proven.
already said, simply order B A, possibly achievable
using action set resulted fixpoint computation. ordering relation
(where h stands \heuristic") obtained way approximates reasonable goal
ordering .
Definition 13 (Heuristic Ordering ) Let (O; ; G fA; B g) planning problem.
n

j

j

n

n

j

j



n





DA


DA



j

j

n

j

h

r

Let set actions obtained performing fixpoint computation
shown Figure 1.
ordering B holds
:pA(B; O)
h

h

reached particular state s( : ) assumptions made
fixpoint computation test pA(B; ) justified, possibly achievable sucient condition non-existence plan B
temporarily destroy A.
Theorem 5 Let (O; ; G ) planning problem, let A; B 2 G two atomic goals. Let
A;

B

s( : ) reachable state achieved, B still false, i.e., B 62
s( : ) . Let F sets facts actions, respectively, derived
fixpoint computation shown Figure 1.
A;

B

A;

B

8f 2 F [ fB g : 8o 2 : f 2 add(o) ) pre(o) \ s(


DA





:pA(B; O) ) :9P OA :

:

A;

B

B 2 Result(s( : ) ; P OA )

354

A;

B

)

=;

()

fiOn Reasonable Forced Goal Orderings
Proof: Assume plan P OA = ho1 ; : : : ; destroy A,
n

achieves B , i.e., B 2 Result(s( : ) ; ho1 ; : : : ; i). restriction ()
facts F , Lemma 4 applied action sequence ho1 ; : : : ; 1 yielding
Result(s( : ) ; ho1 ; : : : ; 1 i) \ F = ;. Consequently, either
applicable Result(s( : ) ; ho1 ; : : : ; 1i),
preconditions contained Result(s( : ); ho1 ; : : : ; 1 i), yielding pre(o ) \

F = ;.
first case, simply skip effects. second case,
2 follows. Thus, plan constructed actions achieves B
s( : ) . Applying Lemma 2 leads us A(s( : ) ; B; ). B 62 s( : ) .
also know, () respect B , , 8o 2 : B 2 add(o) )
pre(o) \ s( : ) = ; holds. Therefore, apply Lemma 3 arrive pA(B; ),
contradiction.
return blocks world example show computation proceeds.
Let us first investigate whether on(a; b) on(b; c) holds. initial value F ( )
obtained delete list stack(b,c) action, one adds
goal.
A;

n

B





DA

A;

B





A;



B

A;



B







A;

B

A;

B

A;

B



A;

B

h

b;c

h

DA

= fclear(c); holding(b)g
Intuitively, immediately clear neither facts ever hold state
on(b; c) true: b c, c clear gripper cannot hold b.
turns fixpoint computation respects intuition leaves set F ( )
unchanged, yielding F = fclear(c); holding(b)g. repeat fixpoint process
detail here, reconstructed Figure 1 details necessary
understanding correct ordering relations derived. short, facts
achievers reduced action set, need preconditions
achiever available. example, holding(b) achieved either unstack
pickup action. either need b stand another block stand table.
actions achieve facts need holding(b) true thus excluded
reduced action set.
finishing fixpoint computation, planner tests pA(on(a; b); ),
contains actions except delete on(b; c) use clear(c) holding(b)
precondition. finds action stack(a,b) adds on(a; b). preconditions
action holding(a) clear(b). conditions added actions
pickup(a) unstack(a,b), respectively, contained : neither
needs c clear b gripper. Thus, test finds fact, on(a; b)
possibly achievable using actions , ordering derived, i.e., on(a; b) 6
on(b; c) follows.
Now, way round, on(b; c) on(a; b) tested. initial value F ( )
obtained single action stack(a,b)
( )
= fclear(b); holding(a)g
F
(

)

b;c

FDA

b;c
DA

h

a;b

h

DA

a;b
DA

355

fiKoehler & Hoffmann
Again, fixpoint computation cause changes, resulting F = fclear(b);
holding(a)g. process tests whether pA(on(b; c); ) holds, contains
actions except delete on(a; b) use clear(b) holding(a)
precondition. action add on(b; c) stack(b,c). action needs
preconditions facts holding(b) clear(c). process finds crucial
condition achieving first fact violated: action achieve holding(b)
clear(b) precondition, b must clear first gripper hold it.
Since clear(b) element F , none actions achieving holding(b) contained
O. Consequently, test pA(on(b; c); ) fails obtain ordering on(b; c)
on(a; b). makes sense gripper cannot grasp b stack onto c anymore,
on(a; b) achieved.
h

3.3 Forced Goal Orderings Invertible Planning Problems

far, introduced two easily computable ordering relations
approximate reasonable goal ordering . One might wonder invest
effort trying find forced goal orderings. two reasons that:
h

e

r

1. already seen Section 2, forced goal ordering also reasonable
goal ordering, i.e., method approximates latter also used crude
approximation former.
2. Many benchmark planning problems invertible certain sense. problems
contain forced orderings anyway.
section, elaborate detail second argument. results bit
general necessary point. want make use later show
Agenda-Driven planning algorithm propose complete respect certain class
planning problems. proceed formally defining class planning problems, show
problems contain forced orderings, identify sucient criterion
membership problem class. Finally, demonstrate many benchmark
planning problems fact satisfy criterion. start, introduce notion
deadlock planning problem.
Definition 14 (Deadlock) Let (O; ; G ) planning problem. reachable state
called deadlock iff sequence actions leads goal, i.e., iff
0
0
= Result(I ; P ) :9 P : G Result(s; P ).

class planning problems interested class problems

deadlock-free. Naturally, problem called deadlock-free none reachable states

deadlock sense Definition 14.
Non-trivial forced goal orderings imply existence deadlocks (remember
ordering B B called trivial iff state s( : ) all).
f

r

A;

B

Lemma 5 Let (O; ; G ) planning problem, let A; B 2 G two atomic goals.
non-trivial forced ordering B B , exists deadlock
state problem.
f

356

fiOn Reasonable Forced Goal Orderings
Proof: Recalling Definition 9 assuming non-triviality , know
least one state s( : ) made true, B still false. Definition 7,
know plan state achieves B . particular,
possible achieve goals starting s( : ) . Thus, state := s( : ) must
deadlock.
f

A;

B

A;

B

A;

B

investigate deadlocks detail discuss commonly
used benchmark problems contain them, i.e., deadlock-free. Lemma 5,
also know domains contain non-trivial forced goal orderings
either|so much point trying find them. care trivial goal
orderings. orderings force reasonable planning algorithm consider goals
correct order.
existence deadlocks depends structural properties planning problem:
must action sequences, which, executed, lead states goals
cannot reached anymore. sequences must undesired effects, cannot
inverted sequence actions O. Changing perspective, one obtains hint
sucient condition non-existence deadlocks might defined. Assume
planning problem effects action sequence domain
inverted executing certain sequence actions. invertible planning
problem, particular possible get back initial state reachable state.
Therefore, problem solvable, contain deadlocks: state,
one reach goals going back initial state first, execute arbitrary
solution thereafter. formally define notion invertible planning problems,
turn argumentation proof.
Definition 15 (Invertible Planning Problem) Let (O; ; G ) planning problem,
let denote states reachable actions O. problem called

invertible

8 : 8 PO : 9 PO :

Result(Result(s; P ); P

O) =

Theorem 6 Let (O; ; G ) invertible planning problem, solution exists.
(O; ; G ) contain deadlocks.

Proof: Let = Result(I ; P ) arbitrary reachable state. problem invert-

ible, know sequence actions P Result(s; P ) = holds.
problem solvable, solution plan P starting achieving
G Result(I ; P ). Together, obtain G Result(Result(s; P ); P ). Therefore,
concatenation P P solution plan executable consequently,
deadlock.










know invertible planning problems, solvable, contain deadlocks
consequently, contain (non-trivial) forced goal orderings. see next
that, matter fact, benchmark planning problems invertible. arrive
sucient condition invertibility notion inverse actions.
357

fiKoehler & Hoffmann
Definition 16 (Inverse Action) Given action set containing action
form pre(o) ! add(o) del(o). action 2 called inverse
form pre(o) ! add(o) del(o) satisfies following conditions
1. pre(o) pre(o) [ add(o) n del(o)
2. add(o) = del(o)
3. del(o) = add(o)

certain conditions, applying inverse action leads back state one started
from.
Lemma 6 Let state action, applicable s. del(o) pre(o)

\ add(o) = ; hold, action inverse sense Definition 16
applicable Result(s; hoi) Result(Result(s; hoi); hoi) = follows.

Proof: applicable s, pre(o) s. atoms add(o) added,

atoms del(o) removed s, altogether

Result(s; hoi) (pre(o) [ add(o)) n del(o) pre(o)

Thus, applicable Result(s; hoi).
Furthermore, Result(s; hoi) = [ add(o) n del(o)
Result(Result(s; hoi); hoi)
= Result(s [ add(o) n del(o); hoi)
= (s [ add(o) n del(o)) [ add(o) n del(o)
= (s [ add(o) n del(o)) [ del(o) n add(o)
(cf. Definition 16)
= [ add(o) n add(o)
(because del(o) pre(o) s)
=
(because \ add(o) = ;)
Lemma 6 states two prerequisites: (1) inclusion operator's delete list preconditions (2) empty intersection operator's add list state
applicable. planning problem called invertible meets prerequisites
inverse action.
Theorem 7 Given planning problem (O; ; G ) set ground actions satisfying

del(o) pre(o) pre(o) ) add(o) \ = ; actions reachable states s.
inverse action 2 action 2 O, problem invertible.

Proof: Let reachable state, let P = ho1 ; : : : sequence actions.

need show existence sequence P



n

Result(Result(s; P ); P ) =
358

( )

fiOn Reasonable Forced Goal Orderings
holds. define P := ho ; : : : ; o1 i, prove ( ) induction n.

n = 0: Here, P = P = hi, Result(Result(s; hi); hi) = obvious.
n ! n + 1: P = ho1 ; : : : ; ; +1 i. induction hypothesis know
Result(Result(s; ho1 ; : : : ; i); ho ; : : : ; o1 i) = s. make following bit readable,
let s0 denote s0 := Result(s; ho1 ; : : : ; i).
n

n

n

n

n

n

Result(Result(s; ho1 ; : : : ; +1 i); ho +1 ; : : : ; o1 i)
Result(Result(s0 ; ho +1 i); ho +1 ; : : : ; o1 i)
Result(Result(Result(s0 ; ho +1 i); ho +1 i); ho ; : : : ; o1 i)
Result(s0 ; ho ; : : : ; o1 i)

n

n

=
=
=
=

n

n

n

n

n

n

(cf. Lemma 6 s0 +1 )
(per induction)
n

Altogether, know invertible problems, solvable, contain forced
orderings. also know problems, inverse action action
O, invertible following Theorem 7. Theorem 7 requires del(o) pre(o) hold
action o, pre(o) ) add(o) \ = ; hold actions reachable states s.
see conditions, (a) inclusion delete list precondition list, (b)
empty intersection action's add list reachable states applicable,
(c) existence inverse actions, hold currently used benchmark domains.4
Concerning condition (a) actions delete facts require preconditions, one finds phenomenon domains commonly used planning
community, least known authors. something seems
hold reasonable logical problem formulation. authors even postulate
assumption algorithms work, cf. (Fox & Long, 1998).
Similarly case conditions (b) (c): One usually finds inverse actions
benchmark domains. Also, action's preconditions usually imply|by state invariants|
add effects false. example blocks world, stack unstack
actions invert other, action's add effects exclusive preconditions|
former contained union False constructed preconditions, see
Section 3.1. Similarly domains deal logistics problems, example logistics,
trains, ferry, gripper etc., one often find inverse pairs actions preconditions
always excluding add effects. Sometimes, two different ground instances
operator schema yield inverse pair. example, gripper, two ground instances
move(roomA, roomB)
at-robby(roomA)

! ADD at-robby(roomB) DEL at-robby(roomA).


4. order avoid reasoning reachable states condition (b), one could also postulate
action add effects negative preconditions, cf. (Jonsson, Haslum, & Backstrom, 2000).
is, however, commonly used typical planning benchmark problems.

359

fiKoehler & Hoffmann
move(roomB, roomA)
at-robby(roomB)

! ADD at-robby(roomA) DEL at-robby(roomB).

move(?from,?to) operator schema invert other. Similarly, towers hanoi,
single move operator schema, inverse instance found
ground instance schema, add effects always false
preconditions true.
rarely, non-invertible actions found benchmark domains.
occur, role domain often quite limited example operators cuss
ate Russel's Tyreworld.
cuss

! DEL annoyed().

ate(?x:wheel)

have(pump) not-in ated(?x) intact(?x)

! ADD ated(?x) DEL not-in ated(?x).

Obviously, much point defining something like decuss de ate
operator. formally speaking, none ground actions operators destroys
goal precondition action domain. Therefore, matter
effects cannot inverted. particular, forced goal ordering derived
wrt. actions. 5
importance inverse actions real-world domains also discussed
Nayak Williams (1997), describe planner BURTON controlling Cassini
spacecraft. contrast domains, problems example used
Barrett et al. (1994) almost never contain inverse actions. Consequently, domains
plenty forced goal orderings could discovered used planner avoid deadlock
situations. widespread, although perhaps unconscious use invertible problems
benchmarking current phenomenon related STRIPS descending planning systems.
one anonymous reviewers pointed us, quite number non-invertible planning
problems also proposed planning literature, e.g., register assignment
problem (Nilsson, 1980), robot crossing road problem (Sanborn & Hendler, 1988),
instances manufacturing problems (Regli, Gupta, & Nau, 1995), Yale Shooting
problem (McDermott & Hanks, 1987). problems, i.e., problems
invertible, one could|in spirit argument 1 beginning section|
simply use approximate forced orderings one interested finding least
those. precisely, methods might detect forced orderings|as
also reasonable|but might also find more, necessarily forced, orderings.
one interested finding forced orderings, possible way go.
example, simple blocks world modification blocks cannot unstacked anymore
stacked|which forces planner build stacks bottom up|both
still capable finding correct goal orderings.
e

h

e

h

e

h

5. cuss operator, way, one known authors deletes fact using
precondition. also one know could removed domain description
without changing anything.

360

fiOn Reasonable Forced Goal Orderings
3.4 Extension Goal Orderings ADL Actions

orderings, introduced far, easily extended deal
ground ADL actions conditional effects using negation instead delete lists.
actions following syntactic structure:
: 0 (o) = pre0 (o) ! eff+
0 (o); eff0 (o)
1 (o) = pre1 (o) ! eff+
1 (o); eff1 (o)
..
.
(o) = pre (o) ! eff+ (o); eff (o)
unconditional elements action summarized 0 (o): precondition
action denoted pre0 (o), unconditional positive negative effects
eff+0 (o) eff0 (o), respectively. conditional effect (o) consists effect
condition (antecedent) pre (o), positive negative effects eff+ (o) eff (o).
Additionally, denote (o) set unconditional conditional effects,
i.e., (o) = f0 (o); 1 (o); : : : ; (o)g.
computation immediately carries ADL actions extension
planning graphs used, handle conditional effects, e.g., IPP (Koehler, Nebel,
Hoffmann, & Dimopoulos, 1997) SGP (Anderson & Weld, 1998). One simply takes
set exclusive facts returned systems determine set F . test
Definition 10, decides whether ordering B two atomic goals
B , extended ADL follows.
n

n

n

n









n

e



GP

e

Definition 17 (Ordering ADL) Let (O; ; G fA; B g) planning problem.
e

False set A. ordering B holds

Let F



e

GP

8 2 O; (o) 2 (o) : B 2 eff+(o) ^ 62 (o) ) (pre (o) [ pre0(o)) \ F 6= ;







GP



Here, (o) denotes negative effects implied conditions (o).


(o) :=




eff0 (o) [
eff0 (o)





pre

j (o) prei (o) effj (o) 6= 0

i=0

Thus, B ordered (unconditional conditional) effects add B either
imply effect deletes A, need conditions cannot made true together
A. Note effect requires conditions pre (o) [ pre0 (o) satisfied,
impossible state holds non-empty intersection
F
.
computation requires little adaptation effort. order obtain
set F , need investigate conditional effects well. action
conditional unconditional effect, determine atoms negated
it, matter effect used achieve A. obtain atoms intersecting
appropriate sets (o).
\
(o)
D(o) :=





GP

h


DA



+
2 effi (o)

361



fiKoehler & Hoffmann
exactly facts always deleted achieving A, matter
effect use.
intersection sets D(o) actions yields desired set F . Let us
consider following small example clarify computation.
0 (o) = fU g
! fW g f:X g;
1 (o) = fV; W g ! fAg f:X g;
2 (o) = fW g
! fU g f:Y g

DA

obtain D1 (o) = f:X g [ f:Y g = f:X; :Y g, precondition 2 (o)
implied first conditional effect 1 (o). 1 (o) effect achieve A,
get D(o) = D1 (o) = f:X; :Y g.
obtain smaller set D(o), add unconditional positive effect
action.
0 (o) = fU g
! fW; Ag f:X g;
1 (o) = fV; W g ! fAg f:X g;
2 (o) = fW g
! fU g f:Y g
case, need intersect sets D0 (o) = f:X g D1 (o) = f:X; :Y g,
yielding D(o) = f:X g. ects fact that, achieving via unconditional
effect o, X gets removed state.
fixpoint computation requires adapt computation . First, repeat
steps case simple STRIPS actions consider unconditional negative
effects intersection preconditions False set:

:= n fo j 2 eff0 (o) _ F \ pre0(o) 6= ;g

DA

Then, additionally remove action conditional effects either imply
deletion impossible effect condition.

:= red(O ) = fred(o)jo 2 Og
Here, red function red(o) : 7! o0
(o0 ) = (o) n f (o) j 2 (o) _ pre (o) \ F
k

k


DA

k

6= ;g

Finally, need redefine Definition 12, expresses conditions
fact believed possibly achievable given certain set operators O.
Definition 18 (Possibly Achievable Atoms ADL) atom p possibly achievable given action set (written pA(p; O))

9 2 O; 2 (o) : p 2 eff+(o) ^
8 p0 2 (pre (o) [ pre0(o)) : 9 o0 2 O; 0 2 (o0) : p0 2 eff+0 (o0 )










holds, i.e., positive effect p conditions preconditions
made true effects reduced action set.
362

fiOn Reasonable Forced Goal Orderings
process, decides whether atomic goal B heuristically ordered another
goal (i.e., whether B holds) proceeds exactly way described
Section 3.2: False set F reduced fixpoint computation, remains
unchanged, employs updated routines computing deciding pA(f; O).
result, B ordered (B A) possibly achievable
pA(B; ) using action set results fixpoint.
h


DA

h

4. Use Goal Orderings Planning

determined ordering relations hold pairs atomic goals
given goal set, question make use planning. Several
proposals made literature, see Section 6 detailed discussion.
paper, propose novel approach extracts explicit ordering subsets
goal set|called goal agenda. planner, case IPP, run successively
planning subproblems represented agenda.
4.1 Goal Agenda

first step one take computing goal agenda perform so-called goal
2 G atomic goals must examined
order find whether ordering relation B , B A, both, none holds
them. ordering relation , arbitrary definition used.
experiments, relation always either .
determined ordering relations hold atomic goals, want
split goal set smaller sets based relations, want order
smaller sets, also based relations. precisely, goal sequence
goal sets G1 ; : : : ; G
[
G =G
analysis. goal analysis, pair A; B

e

h

n

n







=1

G



\G =;
j

6= j; 1 i; j n. also want sequence goal sets respect ordering
relations derived atomic goals. make explicit, first
introduce simple representation detected atomic orderings: goal graph G.
G := (V; E )

V := G

E := f(A; B ) 2 G G j B g
Now, desired properties, sequence goal sets possess, easily
stated:
363

fiKoehler & Hoffmann

Goals A; B lie cycle G belong set, i.e., A; B 2 G .
G contains path goal goal B , vice versa, ordered
B , i.e., 2 G B 2 G < j .




j

properties appear reasonable goal-set sequence respecting
atomic orderings. introduce simple algorithmic method produce
sequence goal sets meets requirements.
First all, transitive closure G computed. done cubic
time size goal set (Warshall, 1962). Then, node transitive
closure, ingoing edges outgoing edges counted. disconnected nodes
= = 0 moved separate set goals G-sep containing
atomic goals, participate relation. nodes A, degree
d(A) =
determined difference number ingoing edges
number outgoing edges. Nodes identical degree merged one set.
sets ordered increasing degree yield desired sequence goal sets.
problem remaining set G-sep. non-empty, clear place
put it.
Let us consider small example process. Figure 3 depicts left goal
graph, results goal set G = fA; B; C; D; E g ordering relations
B; B C B D, transitive closure right.












B

B
C

C






E

E

Figure 3: left, goal graph depicting relations atomic subgoals.
right, transitive closure graph.
Figure 4, number in- outgoing edges goal, corresponding degrees,
resulting goal-set sequence shown.
0
0

E



0
3

1

2

B2

0

2
0

-3
{A}

C

-1
{B}

2
{C,D}

G-sep
E



Figure 4: left, number in- outgoing edges node. right,
degree nodes merged sets goals degree.
node E becomes member G-sep set remains unordered.
dicult verify resulting goal sequence respects atomic goal orderings:
364

fiOn Reasonable Forced Goal Orderings

Nodes occurring cycle graph isomorphic in- outgoing edges

transitive closure graph. particular, degree get
merged set G .
Say graph, path B , vice versa. Then,
transitive closure graph, edge node
B path to, additionally edge B , i.e., > B
follows. Similarly, ingoing edge B node path
A, additionally, edge B , gives us B > . Altogether,
d(A) =
<B
<B
B = d(B ) thus, degree
smaller degree B required, gets ordered B .
Note nothing said argumentation set unordered goals, Gsep. set could, principle, inserted anywhere sequence resulting
sequence still respecting atomic orderings. possible heuristic may use goal set
first sequence, apparently problem reach goals
goals set achieved. Another heuristic could put set end
neither problem reach goal set goals. decided
deal problem sophisticated way trying derive ordering relation
G-sep goal sets G already derived. order
so, need extend definitions goal orderings sets goals.
























4.2 Extension Goal Orderings Goal Sets

Given set atomic goals, always problem exponentially many
subsets compared order derive reasonable goal ordering
goal sets. consideration possible subsets question,
result exponential overhead. partial goal agenda obtained far
offers one possible answer. suggests taking set G-sep trying order
respect goal sets emerging goal graph.
Given planning problem (O; I; G ) two subsets atomic goals fA1 ; : : : ; g G
fB1 ; : : : ; B g G , definition sets atomic goals straightforward.
sake simplicity, consider STRIPS actions here. definitions
directly extended ADL.
define ordering , extends sets, begin defining set F f 1 n g
atoms, exclusive least one atomic goal planning graph
generated (O; I; G ):
F f 1 n g := fp j p exclusive least one graph leveled g
set 1 n g obtained accordingly removing actions delete
least one , i.e., 1 n g = fo 2 j 8 2 f1; : : : ; ng : 62 del(o)g.
Definition 19 (Ordering Goal Sets) Let (O; I; G ) planning problem
n

e

k

h

;:::;A

E

e

GP



;:::;A



GP

;:::;A





;:::;A

fA1 ; : : : ; g G fB1 ; : : : ; B g G . Let Ff 1 ng False set fA1 ; : : : ; g.
ordering fB1 ; : : : ; B g fA1 ; : : : g holds
9 j 2 f1; : : : ; kg : 8 2 1 ng : B 2 add(o) ) pre(o) \ Ff 1 ng 6= ;:
E

;:::;A

n

k

k

E

n

GP

n

;:::;A

;:::;A

j

365

GP

fiKoehler & Hoffmann
similar way, extended . , sets F determined
based Equation (3). set Ff 1 n g simply union individual sets:
f 1 n g := [ F
F
(4)


H

h



DA

;:::;A

DA

;:::;A



DA

DA



fixpoint computation entered

:= n fo 2 j 9 2 f1; : : : ; ng : 2 del(o) _ Ff 1 ng \ pre(o) 6= ;g (5)
recomputation iteration fixpoint algorithm Figure 1 done
;:::;A



DA

accordingly. Apart this, algorithm remains unchanged.

Definition 20 (Ordering ) Let (O; I; G ) planning problem fA1 ; : : : ; g

fB1 ; : : : ; B g G . Let set actions obtained performing
fixpoint computation shown Figure 1, modified handle sets facts defined
Equations (4) (5). ordering fB1 ; : : : ; B g fA1 ; : : : ; g holds
9 j 2 f1; : : : ; kg : :pA(B ; O)

G

H

n

k

H

k

n

j

given goal sets undergo goal analysis, i.e., pair sets checked
ordering relation . derived relation defines edge graph
subgoal sets nodes. transitive closure determined before, degree
node computed. graph contains disconnected nodes, total ordering
subsets goals results ordering nodes based degree. ordering
defines goal agenda. case disconnected nodes, default heuristic
adding corresponding goals last goal set agenda.
E

H

4.3 Agenda-Driven Planning Algorithm

Given planning problem (O; ; G ), let us assume goal agenda G1 ; G2 ; : : : ; G
k entries returned analysis. entry contains subset G G .
basic idea agenda-driven planning algorithm first feed planner
original initial state I1 := goals G1 := G1 , execute solution plan P
, yielding new initial state I2 = Result(I1; P ). Then, new planning problem
initialized (O; I2 ; G2 ). solving problem, want goals G2 true,
also want goals G1 remain true, set G2 := G1 [ G2 . continuous
merging successive entries agenda yields sequence incrementally growing
goal sets planner, namely
[
G := G
k







j

j

=1

little detail, agenda-driven planning algorithm implemented IPP works
follows. First, IPP called problem (O; ; G1 ) returns plan P1 ,
achieves subgoal set G1 . P1 sequence parallel sets actions, returned
IPP similarly graphplan. Given plan, resulting state R(I ; P1 ) = I2
366

fiOn Reasonable Forced Goal Orderings
computed based operational semantics planning actions.6 case set
STRIPS actions, one simply adds ADD effects deletes DEL effects
state description order obtain resulting state, following Result function
Definition 2. STRIPS, Result function coincides directly R function.
case set parallel ADL actions, one needs consider possible linearizations
parallel action set deal conditional effects separately.
linearization, different resulting state obtained, satisfy
goals. obtain new initial state I2 , one takes intersection resulting states
possible linearization actions parallel set. means compute n!
linearizations parallel action set n actions time step. Since n usually
small (more 5 6 ADL actions per time step rare), practical costs
computation neglectible.
way, given solution subproblem (O; ; G ), one calculates new initial
state +1 runs planner subsequent planning problem (O; +1 ; G +1 )
planning problem (O; ; G ) solved.
plan solving original planning problem (O; ; G ) obtained taking
sequence subplans P1 ; P2 ; : : : ; P . One could argue planning increasing goal
sets lead highly non-optimal plans. IPP still uses \no-ops first" strategy
achieve goals, originally introduced graphplan system (Blum & Furst,
1997). Employing strategy, graphplan algorithm, short, first tries achieve
goals simply keeping true, possible. Since goals G1 ; G2 ; : : : ; G already
satisfied initial state +1 , starting planner tries achieve G +1 ,
strategy ensures goals destroyed re-established solution
found otherwise. no-ops first strategy merely graphplan feature,
reasonable planning strategy preserve goals already true initial state
whenever possible.
soundness agenda-driven planning algorithm obvious G = G
sequence sound subplans yielding state transition initial state
state satisfying G .
completeness approach less obvious holds planner cannot
make wrong decisions finally reaching goals. precisely, approach
complete problems contain deadlocks introduced Definition 14.








k



k

k







k

Theorem 8 Given solvable planning problem (O; I; G ), goal agenda G1 ; G2 ; : : : G

k

G G +1 G = G . Running complete planner agenda-driven manner
described yield solution problem deadlock-free.




k

Proof: Let us assume planner find solution step agenda-driven

algorithm, i.e., solution found subproblem (O; ; G ). planner assumed
complete subproblem, implies unsolvability (O; ; G ). problem
solvable, neither problem (O; ; G ) solvable, since G G holds. Therefore,
goals cannot reached . Furthermore, reachable state|it reached
executing partial solution plans P1 ; : : : ; P 1 initial state. Consequently,
must deadlock state sense Definition 14, contradiction.


















6. See (Koehler et al., 1997) exact definition R, want repeat here.

367



fiKoehler & Hoffmann
result states feasibility approach: shown, benchmark
problems currently investigated contain inverse actions, therefore invertible
(Theorem 7), also deadlock-free (Theorem 6). Thus, Theorem 8,
approach preserves completeness domains.
However general case, completeness cannot guaranteed. following example
illustrates situation assumption s( : ) 6j= p (assuming preconditions
achieving actions contained state reached, cf. derivation
ordering Section 3) wrong yields goal ordering plan
found anymore although problem solvable.
Given initial state fC; Dg goals fA; B g, planner following set
ground STRIPS actions :
A;

B

h

op1:
op2:
op3:
op4:

fC g
fDg
fE g
fF g

!
!
!
!

ADD fB g DEL fDg
ADD fE g
ADD fF g
ADD fAg

analysis return ordering B B added op1,
precondition C effect actions. Thus concludes C
reachable state holds. example, C holds reachable
states. assumption s( : ) 6j= C made test pA(B; ) wrong. Thus, B
reached A. hand, B holds, even forced ordering
B . testing B , ordering remains undetected,
method discover precondition F op4 achievable state
B holds: obtain F = fDg, excludes op2 , op3 op4
remain set usable actions. Thus, op4 considered legal achiever A, op3
considered legal achiever precondition F . could detect right ordering
regressed action chain op4, op3, op2 found that,
F set B , actions must excluded .
Consequently, goal agenda fB g; fAg fed planner, solves first
subproblem using op1, fails achieving state fB; C g since
inverse action op1 cannot re-established way.
h

A;

B

r

f

h

B
DA

5. Empirical Results

implemented methods approximate so-called Goal Agenda Manager
(GAM) IPP planning system (Koehler et al., 1997). GAM activated
set ground actions determined either uses approximate
reasonable goal ordering. calls IPP planning algorithm entry
goal agenda outputs solution plan concatenation solution plans
found entry agenda.7
r

e

h

7. source code GAM, based IPP 3.3, collection domains
draw subsequent examples downloaded http://www.informatik.uni-freiburg.de/~
koehler/ipp/gam.html. experiments performed SPARC 1/170.

368

fiOn Reasonable Forced Goal Orderings
empirical evaluation performed uses IPP domain collection, contains 48 domains 500 planning problems. domains,
able derive goal ordering information 10 domains. domains indeed pose constraints ordering planner achieve set goals.
domains, goal orderings could derived, found either single goal
achieved, example manhattan, movie, molgen, montlake domains
goals achieved order, example logistics, gripper, ferry
domains. found benchmark domain, natural goal ordering existed,
method failed detect it. matter fact, looking goal ordering seems
natural, one usually finds ordering reasonable sense Definition 8, see
example blocks world, woodshop, tyreworld domains. method finds almost
reasonable orderings, indicates approximation techniques
appropriate detecting ordering information.
e

h

following, first compare techniques terms runtime
number goal agenda entries generated. take closer look agendas
generated selected domains investigate uence performance
IPP planning system. exact definition domains downloaded
IPP webpage, give name domain name particular
planning problem well number (ground) actions domain contains,
parameter nicely characterizes size domain usually diculty
handle it.
e

h

examples, times shown compute goal agenda contain effort
parse instantiate operators, i.e., compute set actions. Times parsing
instantiation listed explicitly, are, test examples used here,
usually close zero uence performance planner significant
way.
5.1 Comparison
h

e

begin comparison summary results obtained different representational variants blocks world. bw large bw large examples originate
SATPLAN test suite (Kautz & Selman, 1996) added larger examples
bw large e bw large g. parcplan example comes (El-Kholy & Richards, 1996)
uses multiple grippers limited space table. stack n examples use
graphplan blocks world representation simply require stack n blocks other,
table initial state.
two methods return exactly ordering relations across blocks world
problems. Figure 5 confirms, computation based planning graphs
much time-consuming. hits computational border domain contains
10000 actions. computation much faster also scales larger action
sets.
e

h

369

fiKoehler & Hoffmann
problem
bw large
bw large b
bw large c
bw large
bw large e
bw large f
bw large g
parcplan
stack 20
stack 40
stack 60
stack 80

#actions #agenda entries CPU( ) CPU( )
162
1
0.69
0.07
242
5
1.45
0.11
450
7
4.85
0.22
722
11
14.18
0.35
722
11
12.95
0.35
1250
6
44.93
0.58
1800
9
97.11
0.88
1960
4
25.84
1.47
800
19
6.91
0.36
3200
39
160.00
1.74
7200
59
840.42
4.85
12800
79
11.38
e

h

Figure 5: Comparison blocks world problems. #actions shows number
actions set O, planner tries construct plan. #agenda
entries says many goal subsets detected ordered GAM.
Column 4 5 display CPU time required methods
compute agenda provided set O. dash always mean
IPP ran memory 1 Gbyte machine.
e

h

Figure 6 Figure 7 show results domains, method
able detect reasonable orderings. Figure 6 lists domains, methods
return goal agendas. tyreworld, hanoi, fridgeworld domains originate
UCPOP (Penberthy & Weld, 1992), link-repeat domain found (Veloso
& Blythe, 1994). performance results coincide shown Figure 5. Figure 7
shows picture terms runtime performance, domains different
agendas returned .
woodshop scheduling domains contain actions conditional effects,
domains use STRIPS operators. computation fails derive goal
orderings scheduling world problems (of display largest problem
sched6) wood1 problem. explanation behavior found
different treatment conditional effects methods. IPP find limited
form mutex relations conditional effects building planning graph.
goal, achieved conditional effect, often exclusive large
number facts graph. Thus, F sets small sometimes even empty
consequently, actions excluded performing reachability
analysis thus, reasonable orderings may remain undetected. Direct analysis investigates
conditional effects detail therefore able derive much larger F sets.
behavior method STRIPS domains bulldozer, glassworld,
shopping world caused phenomenon. domains, one derive much
larger F sets using planning graphs turn sets exclude actions. Since direct
analysis finds smaller empty F sets, also finds less relations. woodshop domain
e

h

e

h

h

370

fiOn Reasonable Forced Goal Orderings
#actions #agenda entries CPU( ) CPU( )
26
6
0.05
0.01
59
6
0.20
0.03
108
6
0.45
0.06
173
6
0.84
0.10
254
6
1.56
0.15
899
6
16.29
0.64
48
3
0.05
0.02
90
4
0.10
0.04
150
5
0.19
0.08
231
6
0.35
0.12
336
7
0.63
0.19
779
2
0.77
0.55
31
2
0.19
0.01
31
2
0.21
0.01

domain
tyreworld

problem
fixit1
fixit2
fixit3
fixit4
fixit5
fixit10
hanoi
hanoi3
hanoi4
hanoi5
hanoi6
hanoi7
fridgeworld fridge
link-repeat link10
link30

e

h

Figure 6: Comparison benchmark domains, return
identical agendas.
e

h

domain
bulldozer
glassworld

problem
bull
glass1
glass2
glass3
shoppingworld shop
scheduling
sched6
woodshop
wood1
wood2
wood3

#actions #agenda entries CPU( ) CPU( )
61
2/1
0.09
0.03
26
2/1
0.02
0.01
114
2/1
0.19
0.09
122
2/1
0.22
0.09
81
2/1
0.07
0.02
104
1/4
01.0
0.12
15
1/3
0.03
0.01
15
6/5
0.03
0.01
43
6/5
0.14
0.06
e

h

Figure 7: Domains return different goal agendas, give
form n1 =n2 . number slash says many entries contained
agenda computed , number following slash says many
entries contained agenda computed . #agenda entries=1 means
agenda contains single entry, namely original goal set,
ordering derived.
e

h

e

h

shows results differ within domain, depending specific
planning problem. problem wood2 varies problem wood1 sense one
goal slightly different|an object needs put different shape|and two
goals present. goal orderings derived pairs old
371

fiKoehler & Hoffmann
goals wood1, lots relations derived mixed pairs old new goals
wood2, yielding detailed goal agenda. problem wood3 contains additional objects
many goals, also successfully ordered.
subsequent experiments, decided solely use heuristic ordering
computation less costly computation cases, yielding
comparable agendas cases. three domains investigate closely,
namely blocks world, tyreworld hanoi domains, agendas derived methods
are, fact, exactly same.
e

h

e

h

5.2 uence Goal Orderings Performance IPP Interaction
RIFO

section, analyze uence goal agenda performance IPP
combine another domain analysis method, called RIFO (Nebel, Dimopoulos, &
Koehler, 1997). RIFO family heuristics enables IPP exclude irrelevant actions
initial facts planning problem. effectively combined GAM,
IPP plans subset goals original goal set, likely
also subset relevant actions needed find plan. precisely,
obtain one subproblem entry agenda, and, subproblem,
use RIFO preprocessing planning IPP. configuration, GAM reduces
search space IPP decreasing number subgoals planner achieve
moment, RIFO reduces search space dramatically selecting
actions relevant goal subset.
5.2.1 Blocks World

Figure 8 illustrates parcplan problem (El-Kholy & Richards, 1996) detail. Seven
robot arms used order 10 blocks 3 stacks 5 possible positions table.

1

11

14

24

23

13

23

12

22

32

11

21

31

1

2

3

32
12

31

22

24

14

13
21

2

3

4

5

Figure 8: parcplan problem limited space table, seven robot arms,
several stacks.
goal agenda derived IPP orders blocks horizontal layers:
1:
2:
3:
4:

on-table(21, t2) ^ on-table(11, t1)
on-table(31, t3) ^ on(22, 21) ^ on(12, 11)
on(32, 31) ^ on(13, 12) ^ on(23, 22)
on(14, 13) ^ on(24, 23)
372

fiOn Reasonable Forced Goal Orderings
optimal plan 20 actions solving problem found IPP using GAM 14 s,
spends one second computing goal agenda, almost 13 seconds build
planning graphs, 0.01 second search plan. 70 actions tried
find solution. Without goal analysis, IPP needs approx. 47 searches 52893
actions 26 seconds.
RIFO (Nebel et al., 1997) fails detecting subset relevant actions original
goal set considered, succeeds selecting relevant actions subproblems
stated agenda. reduces runtime less 8 1 spent
goal agenda, almost 6 spent removal irrelevant actions initial facts, less
1 spent building planning graphs. previously, almost time spent
planning.
Figure 9 shows IPP SATPLAN blocks world examples (Kautz & Selman,
1996), bw large.e example taken (Dimopoulos, Nebel, & Koehler, 1997), two
large examples bw large.f (containing 25 blocks requiring build 6 stacks
goal state) bw large.g 30 blocks/8 stacks.
SATPLAN
bw large.a
bw large.b
bw large.c
bw large.d
bw large.e
bw large.f
bw large.g

# actions plan length IPP +G +G+R +G+R+L
162
12 (12)
0.70 0.74
0.58
0.34
242
22 (18) 26.71 0.86
0.55
0.52
450
48
- 7.34
2.42
2.58
722
54
- 11.62
3.74
3.81
722
52
- 11.14
3.99
3.97
1250
90
16.01
1800
84
- 117.56
28.71

Figure 9: Performance extended SATPLAN blocks world test suite. second
column shows number ground actions domain, third column
shows plan length, i.e., number actions contained plan, generated
GAM parentheses plan length generated IPP without GAM given
IPP without GAM able solve corresponding problem. +G means
IPP using GAM, +G+R means IPP uses GAM RIFO, +G+R+L
means subgoals set agenda arbitrarily linearized.
runtimes cover whole planning process starting parsing operator
domain file, performing GAM RIFO analysis (if active),
searching graph plan found.
IPP 3.3 without GAM solve bw large.a bw large.b problems. Using
goal agenda, plans become slightly longer, performance increasing dramatically.
Plan length growing blocks accidentally put positions cut
goals still ahead agenda thus, additional actions need added
plan remove blocks wrong positions. speed-up possible
RIFO additionally used, reduces size planning graphs dramatically.
Finally, goals belong subset agenda linearized based

373

fiKoehler & Hoffmann
heuristic assumption analysis found reasonable goal orderings, goals
achievable order. option, problems solved almost instantly.
reader may wonder point use linearization agenda entries
extra option investigate further. two reasons that. First,
linearization negative side effects domains investigated.
example, yields much longer plans logistics domain variants.
linearizing single entry agenda logistics problem contains, packages get
transported goal position one one. course, takes much planning
steps simultaneously transporting packages coinciding destinations.
Secondly, effects linearization somewhat unpredictible, even domains
usually tends yield good results. GAM recognise interactions goals. Consider blocks world problem four blocks A, B , C D.
Say B positioned C initially, blocks table, goal
on(A; B ) on(C; D). agenda problem comprise single entry
containing goals. fact, reasonable goal ordering here. Nevertheless,
stacking onto B immedeatly bad idea, planner needs move C achieve
on(C; D). aware this, GAM might linearize single agenda entry
on(A; B ) front, makes problem harder actually is. Thus, runtime
advantages linearization sometimes yields blocks world less seen
cases \good luck".
Figure 10 shows IPP stack n problems. IPP without domain analysis
handle 12 blocks less 5 minutes, 13 blocks 15 minutes
needed. Using GAM, 40 blocks stacked less 5 minutes. Using GAM
RIFO, 5 minutes limit extended 80 blocks, stack100 solved 11.5 min
11.3 min spent analysis methods 0.2 min needed building
planning graphs extracting plan.
time

600
450

IPP

IPP+G
IPP+G+R

300
150

10

20

Figure 10:

IPP

30

40

50

60

70

80

90

100 blocks

3.3 simple, huge stacking problem.

Figure 11 shows sharing overall problem-solving time GAM, RIFO
IPP search algorithm blocks world problems. Similar results obtained
tyreworld. GAM takes 3 16 %, RIFO takes 75 96 %,
search effort reduced approx. 1 %. overall problem solving time clearly
determined RIFO, search effort becomes marginal factor determination
performance. indicates speed-up possible improving
374

fiOn Reasonable Forced Goal Orderings
performance GAM RIFO. also indicates even hardest planning problems
become easy structured decomposed right way.
problem
stack 20
stack 40
stack 60
stack 80
parcplan

# actions
800
3200
7200
12800
1960

GAM
RIFO
0.31 = 16 % 1.44 = 75 %
1.57 = 7 % 18.77 = 90 %
4.40 = 4 % 93.10 = 94 %
9.60 = 3 % 283.60 = 96 %
0.86 = 12 % 5.52 = 76 %

search algorithm
0.13 = 7 %
0.51 = 2 %
1.15 = 1 %
2.33 = 1 %
0.83 = 11 %

Figure 11: Distribution problem-solving time blocks world examples GAM,
RIFO, search algorithm, comprises time build search
planning graph. remaining fraction total problem-solving time,
shown table, spent parsing instantiating operators.

5.2.2 Tyreworld

tyreworld problem, originally formulated Stuart Russell, asks planner find
replace tire. easily solved IPP within milliseconds. problem
becomes much harder number tires increasing, cf. Figure 12.
Tires
1
2
3
4
5
6
7
8
9
10
Figure 12:

# actions
IPP
+G+R
+G+R+L
Search Space
26
0.10 (12/19) 0.15 (14/19) 0.16 (17/19)
1298/88
59
17.47 (18/30) 0.41 (24/32) 0.32 (30/34) 1290182/210
108
2.87 (32/44) 0.63 (41/46)
-/366
173
1.12 (52/60)
-/565
254
1.93 (63/73)
-/807
353
3.42 (73/85)
-/1092
464
4.81 (84/98)
-/1420
593
8.07 (95/121)
-/1791
738
11.27 (106/124)
-/ 2205
899
16.89 (118/136)
-/2662
Tyreworld. numbers parentheses show time steps, followed
number actions generated plan. last column compares
search spaces. number slash shows \number actions tried"
parameter plain IPP planning algorithm, number following
slash shows \number actions tried" IPP using GAM, RIFO,
linearization entries agenda. dash means \number
actions tried" unknown IPP failed solving corresponding
planning problem.

IPP

375

fiKoehler & Hoffmann
IPP able solve problem 1 2 tires. Using GAM RIFO, 3
tires handled. Solution length GAM slightly increasing, caused
super uous jack-up jack-down actions. short, explained follows.
wheel needs mounted hub, expressed on(?r, ?h) goal. mount
wheel, hub must jacked up. mounting, nuts done up. Then, hub
needs jacked again, order tighten nuts achieving tight(?n, ?h) goal.
Now, GAM puts goals one entry preceeding tight goals. Thus, solving
entry containing goals, hub jacked up, wheel put on, hub
immediatly jacked order replace next wheel. Afterwards, solving
tight goals, hub must jacked up|and down|one time
nuts. Solving problem manner, planner inserts one super uous jack-up,
one super uous jack-down action wheel. precisely, super uous actions
inserted one wheel, namely wheel last mounted solving
goals. mounting wheel, goals achieved, planner proceeds
next agenda entry wheel still jacked up. Then, trying achieve
tight goals, IPP recognizes shortest plan (in terms number parallel steps)
results nuts first done hub already jacked up. Thus, hub
jacked one time, achieving corresponding goal, jacked one
time, achieving tight goal.
case 3 tires, following goal subsets identified ordered:

1:
2:
3:
4:
5:
6:
7:

ated(r3), ated(r2), ated(r1)
on(r3, hub3), on(r1, hub1), on(r2, hub2)
tight(n2, hub2), tight(n3, hub3), tight(n1, hub1)
in(w3, boot), in(pump, boot), in(w1, boot), in(w2, boot)
in(jack, boot)
in(wrench, boot)
closed(boot)

hardest subproblem agenda achieve on(r ; hub ) goals entry 2,
i.e., mount ated spare wheels various hubs. Trying generate maximum parallelized plan impossible IPP 3 tires. since goals completely
independent other, linearization perfectly work. resulting
plans become slightly longer due way tight goals achieved using
-L option. noticed earlier one wheel (the one last mounted
solving goals) super uous jack-up jack-down actions need inserted
plan. Linearizing agenda entries, super uous jack-up jack-down actions must
likely inserted wheels, yielding plans two steps longer. reason
tight goal might first linearization. likely,
tight goal corresponding hub still jacked up, planner needs
insert one super uous jack-down action here. Later, must jack hub again, yielding
another super uous action. Using +G+R+L case 10 tires, 2662 actions need
tried plan 136 actions found, takes 0.08 s. GAM requires 0.55 s,
RIFO requires 14.42 s, 1.74 consumed generate planning graphs, 0.08
spent compute initial states subproblems. remaining 0.02 consumed
parsing instantiating.


376



fiOn Reasonable Forced Goal Orderings
5.2.3 Tower Hanoi

surprising result obtained tower hanoi domain. domain, stack discs
moved one peg third peg auxiliary second peg them,
never larger disc put onto smaller disc. case three discs d1, d2, d3
increasing size, goals stated on(d3,peg3), on(d2,d3), on(d1,d2). GAM returns
following agenda, correctly ects ordering largest disc needs
put goal position first.
1: on(d3,peg3)
2: on(d2,d3)
3: on(d1,d2)

goal agenda leads partition subproblems corresponds recursive
formulation problem solving algorithm, i.e., solve problem n discs,
planner first solve problem n 1 discs, etc. first entry, plan 4
actions (time steps 0 3 below) generated, achieves goal on(d3,peg3).8
plan 2 actions (time steps 4 5) achieves goals on(d3,peg3) on(d2,d3)
on(d3,peg3) holding already initial state. Finally, one-step plan (time step 6)
generated moves third disc two discs already goal
position.
time
time
time
time

step
step
step
step

0:
1:
2:
3:

move(d1,d2,peg3)
move(d2,d3,peg2)
move(d1,peg3,d2)
move(d3,peg1,peg3)

time step 4: move(d1,d2,peg1)
time step 5: move(d2,peg2,d3)
time step 6: move(d1,peg1,d2)

Surprisingly, IPP able benefit information, runtime IPP using
GAM exploding dramatically increasing numbers discs, see Figure 13.
discs #actions IPP IPP +G
UCPOP
UCPOP subproblems
2
21 0.02
0.02 0.12 (27)
0.06 (17) + 0.02 (6)
3
48 0.08
0.07 8.00 (2291) 0.18 (48) + 0.06 (13) + 0.01 (6)
4
90 0.33
0.25
5
150 1.57
3.10
6
231 9.71
88.45
7
336 69.44 2339.94
Figure 13: Runtimes IPP without goal agenda hanoi problems compared UCPOP without agenda UCPOP agenda subproblems using
ZLIFO ibf control strategy.
8. move action takes first argument disc moved, second disc moved,
third argument disc peg moved.

377

fiKoehler & Hoffmann
able provide explanation phenomenon, division
subproblems causes much larger search space planner although solution
plans result. RIFO cannot improve situation selects actions relevant.
tower hanoi domain one found IPP's performance deteriorated GAM. currently see way one tell advance whether IPP
gain advantage using GAM not. overhead caused goal analysis
small, \inadequate" split goals subgoal sets lead
search, see also Section 6.
However case, phenomenon seems specific IPP. simulated
information provided GAM UCPOP obtained quite different picture.
fifth column Figure 13 shows runtime UCPOP using ZLIFO (Pollack, Joslin,
& Paolucci, 1997) ibf control strategy number explored partial plans
parentheses. UCPOP solve problem 2 3 discs. last column
figure, show runtime number explored partial plans, result
UCPOP run subproblems result agenda. exactly
subproblems IPP solve, performance UCPOP improves
significantly. Instead taking 8 exploring 2291 partial plans, UCPOP takes
0.18+0.06+0.01=0.25 explores 48+13+6=67 plans. Unfortunately, problems
subproblems 3 discs remain beyond performance UCPOP.
performance improvement independent search strategies used UCPOP.
example, ibf control used without ZLIFO, number explored partial plans
reduced 78606 2209 case problem 3 discs. Runtime improves
65 seconds 2 seconds. Similarly, using bf control without ZLIFO
number explored partial plans reduces 1554 873.
Knoblock (1994) also reports improvement performance Prodigy planner
(Fink & Veloso, 1994) using abstraction hierarchy generated domain
alpine module, provides essence information goal agenda.9
6. Summary Comparison Related Work

Many related approaches developed provide planner ability
decompose planning problem giving kind goal ordering information. Subsequently, discuss important review work light
approaches.
method introduces preprocessing approach, derives total ordering
subsets goals performing static, heuristic analysis planning problem hand.
approach works domains described STRIPS ADL operators based
polynomial-time algorithms. purpose method provide planner
search control, i.e., opt deriving goal achievement order successively call
planner totally ordered subsets goals.
method preserves soundness planning system, completeness
case planning domain contain deadlocks. argue
9. However, find goal ordering information, alpine requires represent tower hanoi domain
involving several operators, cf. (Knoblock, 1991).

378

fiOn Reasonable Forced Goal Orderings
benchmark domains quite often possess property, also supported
authors (Williams & Nayak, 1997).
computation requires polynomial time, methods
incomplete sense detect reasonable goal orderings general
case. complexity deciding existence forced reasonable goal orderings
proven PSPACE-hard Section 2 therefore, trading completeness
eciency seems acceptable solution. complexity results relate found
Bylander (1992) proves PSPACE-completeness serial decomposability (Korf,
1987). Given set subgoals, serial decomposability means previously satisfied subgoals need violated later solution path, i.e., subgoal
achieved, remains valid goal reached. purpose method derive
constraints make orderings explicit serial decomposability set
goals found, i.e., consider complementary problem, also ected
complexity proofs.
many cases, found goal agenda manager significantly improve
performance IPP planning system, found least one domain, namely
tower hanoi, dramatic decrease performance observed although IPP
still generates optimal plan processing ordered goals agenda.
far, complexity results Backstrom Jonsson (1995) predicted planning
abstraction hierarchies exponentially less ecient, exponentially longer
plans generated.
idea analyze effects preconditions operators derive ordering
constraints based interaction operators also found variety approaches.
analyze harmful interactions operators method studying delete
effects, approaches described (Dawsson & Siklossy, 1977; Korf, 1985; Knoblock,
1994) concentrate positive interactions operators. successful matching
effects preconditions forms basis learn macro-operators, see (Dawsson & Siklossy,
1977; Korf, 1985).
alpine system (Knoblock, 1994) learns abstraction hierarchies Prodigy
planner (Fink & Veloso, 1994). approach based ordering preconditions
effects operator, i.e., effects operator must abstraction
hierarchy preconditions must placed lower level effects.
introduces ordering possible subgoals domain, orthogonal
ordering compute: alpine, subgoal ordered subgoal B
enables B , i.e., must possibly achieved first order achieve B . method
orders B cannot achieved without necessarily destroying B . result
alpine GAM set binary constraints. case alpine, constraints
computed atoms domain, GAM restricts analysis
goals only. approaches represent binary constraints graph structure. alpine
merges atomic goals together belong strongly connected component graph.
GAM merges sets goals together identical degree. compute
topological sorting sets consistent constraints. resulting goal
orderings quite similar examples Knoblock (1994) demonstrate, GAM
approximates reasonable goal orderings domains alpine fails finding abstraction
hierarchies. Two examples (Knoblock, 1991) tower hanoi domain using
h

e

379

fiKoehler & Hoffmann
one move operator blocks world. domains, alpine cannot detect
orderings investigates operator schemata, set ground actions,
therefore cannot distinguish orderings different instantiations
literal. Although alpine could modified handle ground actions, significantly
increase amount computation requires. GAM hand, handles large sets
ground actions ecient way, particular direct analysis used.10
analysis, quite similar alpine, performed framework
HTN planning, described Tsuneto et al. (1998). approach analyzes external
conditions methods, cannot achieved decomposing method further.
means, conditions established decomposition methods,
precede method using external condition. Two strategies determine
decomposition order methods defined empirically compared. lies main
difference approaches described far: Instead trying automatically
construct decomposition orderings, predefined fixed domains
problems.
Harmful interactions among operators studied Smith Peot (1993) Etzioni
(1993). threat operator precondition p occurs instantiation
effects inconsistent p (Smith & Peot, 1993). knowledge
threats used control plan-space planner. contrast state-space planner
IPP, computing explicit ordering goals prevent presence threats
partial plan order goals processed determine order
actions occur plan. notion forced reasonable goal orderings
comparable threat threat still potential resolved
adding binding ordering constraints plans. contrast this, forced
reasonable goal ordering persists bindings enforces specific ordering
subgoals.
Given planning problem, static (Etzioni, 1993) computes backchaining tree
goals form AND/OR graph, subsequently analyzes occurrence
goal interactions necessarily occur. analysis much complicated
ours, static deal uninstantiated operators axioms,
describe properties legal states. result analysis goal ordering rules,
order goals certain conditions satisfied state. main difference GAM,
generates explicit goal orderings independently specific state. need
extract conditions specific state satisfy considers generic state
s( : ) analysis, represents states satisfying A, B . GAM, static
incomplete sense cannot detect existing goal interactions. problem
GAM deciding reasonable orderings PSPACE-hard, proven
paper. problem static compute necessary effects operator
given state. Etzioni (1993) conjectures Nebel Backstrom (1994) prove,
A;

B

10. Abstraction hierarchies general goal orderings compute. cannot serve
purpose providing planner goal ordering information, also allow generate plans
different levels refinement, see also (Bacchus & Yang, 1994). Two approaches generating
abstraction hierarchies based numerical criticality values found (Sacerdoti, 1974; Bundy,
Giunchiglia, Sebastiani, & Walsh, 1996).

380

fiOn Reasonable Forced Goal Orderings
problem computationally intractable therefore, polynomial-time analysis method
must incomplete.
Last, least quite number approaches late Eighties,
focused directly subgoal orderings. fall two categories: approaches
described (Drummond & Currie, 1989; Hertzberg & Horz, 1989) focus detection
con icts caused goal interdependencies guide partial-order planner search.
investigate approaches detail extract explicit
goal orderings preprocess planning do. works described (Irani & Cheng,
1987; Cheng & Irani, 1989; Joslin & Roach, 1990) implement preprocessing approaches,
perform structural analysis planning task determine appropriate goal
ordering planning starts. Irani Cheng (1987) compute relation
pairs goals, which|roughly speaking|orders goal goal B B must
achieved achieved. formalism rather complicated theoretical
properties relation investigated. (Cheng & Irani, 1989), approach
extended sets goals ordered respect other. exact
properties formalism remain unclear. (Joslin & Roach, 1990), graph-theoretical
approach described generates graph atoms given domain description
nodes draws arc node node B operator exists takes
precondition B effect. assuming operators inverse
counterparts, identifying connected components graph proposed means
order goals. approach unlikely scale size problem spaces today's planners
consider also completely outdated terms terminology.
Finally, one wonder reasonable forced goal orderings relate others
defined literature. one attempt know ordering
relation explicitly defined properties studied, see (Hullem et al., 1999).
paper, notion necessary goal orderings introduced, must true
minimal solution plans (Kambhampati, 1995).11 approach extends operator graphs
(Smith & Peot, 1993) orders goal based three criteria called goal subsumption, goal
clobbering, precondition violation. Goal subsumption < B holds every solution plan
achieving goal B state also achieves goal state s0 preceding s, plan
achieving one goals G n fAg deletes A. Goal clobbering holds solution plan
deletes B thus, < B . Precondition violation holds solution B results
deadlock cannot reached anymore, i.e., < B . composite
criterion defined tests three criteria simultaneously.12 goal necessarily
ordered B satisfies composite criterion.
remark precondition violation seems equivalent forced orderings
introduced, goal clobbering appears similar reasonable orderings.
possible us verify conjecture authors (Hullem et al., 1999) give
exact formal definitions. nothing similar goal subsumption argue
criterion rarely satisfied natural problems: goal achieved every
11. plan minimal contains subplan also solution plan. remark minimality
mean shortest plans least number actions considered. fact, minimal
plans highly non-optimal long action truly super uous.
12. Here, authors precise mean this. argue means
two goals ordered satisfy least one criteria.

381

fiKoehler & Hoffmann
solution goal B anyway, goal removed goal set without
changing planning task.
authors report able detect necessary orderings artificial
domains , cf. (Barrett & Weld, 1994), fail typical benchmark domains
blocks world tyreworld. reason seems operator graphs
represent possible instantiations operator schemes. authors claim,
makes operator graph analysis ecient. However, heuristic ordering
introduced paper also takes almost computation time, succeeds finding
goal orderings domains.




h

7. Outlook

Three promising avenues future research following:
First, one imagine goal ordering information also used search
process, i.e., ordering original goal set, also goals emerge
search. major challenge seems balance effort computing goal
ordering information savings result search process. One
easily imagine ordering goal sets ever generated become quite costly
investment without yielding major benefit planner.
Secondly, refinement goal agenda additional subgoals another interesting future line work. first investigation using so-called intermediate goals (these
facts planner must make true achieve original goal)
explored inside GAM results reported (Koehler & Hoffmann, 1998). Earlier
work addressing task learning intermediate goals found (Ruby & Kibler,
1989), problem focus AI planning research since then.
third line work addresses interaction GAM forward-searching planning system. seen GAM preserves correctness planner,
preserves completeness least deadlock-free planning domains. also
seen, however, solution plans using GAM get longer, i.e., GAM preserve optimality planner. Recently, planning systems deliver plans
guaranteed optimality demonstrated impressive performance terms runtime
plan length, e.g., HSP, first mentioned (Bonet, Loerincs, & Geffner, 1997),
GRT (Refanidis & Vlahavas, 1999), particular ff (Hoffmann, 2000). systems
heuristic-search planners searching forward state space non-admissible,
informative heuristics.
ff planning system developed one authors awarded \Group
Distinguished Performance Planning System" also Schindler Award
best performing planning system Miconic 10 Elevator domain (ADL track)
AIPS 2000 planning competition. integration goal agenda techniques
planner one factors enabled excellent behavior ff competition:
crucial scaling blocks world problems 50 blocks, helped factor 2
schedule Miconic 10, never slowed algorithm.
Forward state-space search quite natural framework driven goal agenda:
Simply let planner solve subproblem, start next search state
last search ended. Even appealing, heuristic forward-search planners deeper
382

fiOn Reasonable Forced Goal Orderings
kind interaction GAM example graphplan-style planners. addition
smaller problems facing using goal agenda, heuristics
uenced employ techniques estimating goal distance state.
using goal agenda, different goal sets result stage planning process
therefore, goal-distance estimate different, too. Currently heuristic device
inside ff search algorithm developed, knows driven
goal agenda, access complete set goals. information
used prune unpromising branches search space discovers
currently achieved goals probably destroyed reachieved later on.
References

Allen, J. (Ed.), AIPS-98 (1998). Proceedings 4th International Conference Artificial Intelligence Planning Systems. AAAI Press, Menlo Park.
Anderson, C., & Weld, D. (1998). Conditional effects Graphplan. Allen (Allen, 1998),
pp. 44{53.
Bacchus, F., & Yang, Q. (1994). Downward refinement eciency hierarchical
problem solving. Artificial Intelligence, 71, 43{100.
Backstrom, C., & Jonsson, P. (1995). Planning abstraction hierarchies exponentially less ecient. Mellish (Mellish, 1995), pp. 1599{1604.
Barrett, A., & Weld, D. (1994). Partial-order planning: Evaluating possible eciency gains.
Artificial Intelligence, 67, 71{112.
Blum, A., & Furst, M. (1997). Fast planning planning graph analysis. Artificial
Intelligence, 90 (1{2), 279{298.
Bonet, B., Loerincs, G., & Geffner, H. (1997). robust fast action selection mechanism planning. Proceedings 14th National Conference American
Association Artificial Intelligence, pp. 714{719.
Bundy, A., Giunchiglia, F., Sebastiani, R., & Walsh, T. (1996). Computing abstraction
hierarchies numerical simulation. Weld, & Clancey (Weld & Clancey, 1996), pp.
523{529.
Bylander, T. (1992). Complexity results serial decomposability. Proceedings
10th National Conference American Association Artificial Intelligence, pp.
729{734 San Jose, CA. MIT Press.
Bylander, T. (1994). computational complexity propositional STRIPS planning.
Artificial Intelligence, 69, 165{204.
Chapman, D. (1987). Planning conjunctive goals. Artificial Intelligence, 32 (3), 333{377.
Cheng, J., & Irani, K. (1989). Ordering problem subgoals. Sridharan (Sridharan, 1989),
pp. 931{936.
383

fiKoehler & Hoffmann
Dawsson, C., & Siklossy, L. (1977). role preprocessing problem solving systems.
Proceedings 5th International Joint Conference Artificial Intelligence, pp.
465{471 Cambridge, MA.
Dimopoulos, Y., Nebel, B., & Koehler, J. (1997). Encoding planning problems nonmonotonic logic programs. Steel (Steel, 1997), pp. 169{181.
Drummond, M., & Currie, K. (1989). Goal ordering partially ordered plans. Sridharan
(Sridharan, 1989), pp. 960{965.
El-Kholy, A., & Richards, B. (1996). Temporal resource reasoning planning:
parcPLAN approch. Wahlster, W. (Ed.), Proceedings 12th European Conference Artificial Intelligence, pp. 614{618. John Wiley & Sons, Chichester, New
York.
Etzioni, O. (1993). Acquiring search-control knowledge via static analysis. Artificial Intelligence, 62, 255{301.
Fink, E., & Veloso, M. (1994). Prodigy planning algorithm. Technical report CMU-94-123,
Carnegie Mellon University.
Fox, M., & Long, D. (1998). automatic inference state invariants TIM. Journal
Artificial Intelligence Research, 9, 367{421.
Fox, M., & Long, D. (1999). Ecient implementation plan graph STAN. Journal
Artificial Intelligence Research, 10, 87{115.
Hertzberg, J., & Horz, A. (1989). Towards theory con ict detection resolution
nonlinear plans. Sridharan (Sridharan, 1989), pp. 937{942.
Hoffmann, J. (2000). heuristic domain independent planning use enforced
hill-climbing algorithm. 12th International Symposium Methods Intelligent
Systems.
Hullem, J., Munoz-Avila, H., & Weberskirch, F. (1999). Extracting goal orderings
improve partial-order Graphplan-based planning. Technical report, University
Kaiserslautern.
Irani, K., & Cheng, J. (1987). Subgoal ordering goal augmentation heuristic problem solving. McDermott, D. (Ed.), Proceedings 10th International Joint
Conference Artificial Intelligence, pp. 1018{1024 Milan, Italy. Morgan Kaufmann.
Jonsson, P., Haslum, P., & Backstrom, C. (2000). Towards ecient universal planning:
randomized approach. Artificial Intelligence, 117 (1), 1{29.
Joslin, D., & Roach, J. (1990). theoretical analysis conjunctive-goal problems. Artificial
Intelligence, 41, 97{106.
Kambhampati, S. (1995). Admissible pruning strategies based plan minimality planspace planning. Mellish (Mellish, 1995), pp. 1627{1633.
384

fiOn Reasonable Forced Goal Orderings
Kautz, H., & Selman, B. (1996). Pushing envelope: Planning, propositional logic,
stochastic search. Weld, & Clancey (Weld & Clancey, 1996), pp. 1194{1201.
Knoblock, C. (1991). Automatically Generating Abstractions Problem Solving. Ph.D.
thesis, Carnegie Mellon University.
Knoblock, C. (1994). Automatically generating abstractions planning. Artificial Intelligence, 68 (2), 243{302.
Koehler, J. (1999). Handling conditional effects negative goals IPP. Technical report 128, University Freiburg, Institute Computer Science. available
http://www.informatik.uni-freiburg.de/~ koehler/ipp.html.
Koehler, J., & Hoffmann, J. (1998). Planning goal agendas. Technical report
110, University Freiburg. available http://www.informatik.uni-freiburg.de/~
koehler/ipp.html.
Koehler, J., Nebel, B., Hoffmann, J., & Dimopoulos, Y. (1997). Extending planning graphs
ADL subset. Steel (Steel, 1997), pp. 273{285.
Korf, R. (1985). Macro-operators: weak method learning. Artificial Intelligence, 26,
35{77.
Korf, R. (1987). Planning search: quantitative approach. Artificial Intelligence, 33,
65{88.
McDermott, D., & Hanks, S. (1987). Nonmonotonic logic temporal projection. Artificial
Intelligence, 33, 379{412.
Mellish, C. (Ed.), IJCAI-95 (1995). Proceedings 14th International Joint Conference
Artificial Intelligence. Morgan Kaufmann, San Francisco, CA.
Nebel, B., & Backstrom, C. (1994). computational complexity temporal projection, planning, plan validation. Journal Artificial Intelligence, 66 (1), 125{160.
Nebel, B., Dimopoulos, Y., & Koehler, J. (1997). Ignoring irrelevant facts operators
plan generation. Steel (Steel, 1997), pp. 338{350.
Nilsson, N. (1980). Principles Artificial Intelligence. Tioga Publishing Company, Palo
Alto.
Pednault, E. (1989). ADL: Exploring middle ground STRIPS Situation
Calculus. Brachman, R., Levesque, H., & Reiter, R. (Eds.), Proceedings 1st
International Conference Principles Knowledge Representation Reasoning,
pp. 324{332 Toronto, Canada. Morgan Kaufmann.
Penberthy, J., & Weld, D. (1992). UCPOP: sound, complete, partial order planner
ADL. Nebel, B., Swartout, W., & Rich, C. (Eds.), Proceedings 3rd
International Conference Principles Knowledge Representation Reasoning,
pp. 103{113. Morgan Kaufmann, San Mateo.
385

fiKoehler & Hoffmann
Pollack, M., Joslin, D., & Paolucci, M. (1997). Selection strategies partial-order planning.
Journal Artificial Intelligence Research, 6, 223{262.
Refanidis, I., & Vlahavas, I. (1999). GRT: domain independent heuristic STRIPS
worlds based greedy regression tables. Proceedings 5th European Conference Planning, pp. 346{358.
Regli, W., Gupta, S., & Nau, D. (1995). AI planning versus manufactoring-operation
planning: case study. Mellish (Mellish, 1995), pp. 1670{1676.
Ruby, D., & Kibler, D. (1989). Learning subgoal sequences planning. Sridharan
(Sridharan, 1989), pp. 609{615.
Russel, S., & Norvig, P. (1995). Artificial Intelligence - modern Approach. Prentice Hall.
Sacerdoti, E. (1974). Planning hierarchy abstraction spaces. Artificial Intelligence,
5, 115{135.
Sanborn, J., & Hendler, J. (1988). Near-term event projection dynamic simulation
robot cross road? Proceedings 2nd Conference AI
Simulation.
Smith, D., & Peot, M. (1993). Postponing threats partial-order planning. Proceedings
11th National Conference American Association Artificial Intelligence,
pp. 500{506. AAAI Press, MIT Press.
Sridharan, N. (Ed.), IJCAI-89 (1989). Proceedings 11th International Joint Conference Artificial Intelligence, Detroit, MI. Morgan Kaufmann.
Steel, S. (Ed.), ECP-97 (1997). Proceedings 4th European Conference Planning,
Vol. 1348 LNAI. Springer.
Tsuneto, R., Hendler, J., & Nau, D. S. (1998). Analyzing external conditions improve
eciency HTN planning. Allen (Allen, 1998), pp. 913{920.
Veloso, M., & Blythe, J. (1994). Linkability: Examining causal link commitments partialorder planning. Hammond, K. (Ed.), Proceedings 2nd International Conference Artificial Intelligence Planning Systems, pp. 170{175. AAAI Press, Menlo
Park.
Warshall, J. (1962). theorem boolean matrices. Journal ACM, 9 (1), 11{12.
Weld, D., & Clancey, B. (Eds.)., AAAI-96 (1996). Proceedings 14th National Conference American Association Artificial Intelligence. AAAI Press.
Williams, B., & Nayak, R. (1997). reactive planner model-based executive.
Proceedings 15th International Joint Conference Artificial Intelligence, pp.
1178{1185. Morgan Kaufmann, San Francisco, CA.

386

fiJournal Artificial Intelligence Research 12 (2000) 219-234

Submitted 5/99; published 5/00

Randomized Algorithms Loop Cutset Problem
Ann Becker
Reuven Bar-Yehuda
Dan Geiger

anyuta@cs.technion.ac.il
reuven@cs.technion.ac.il
dang@cs.technion.ac.il

Computer Science Department
Technion, Haifa, 32000, Israel

Abstract

show find minimum weight loop cutset Bayesian network high
probability. Finding loop cutset first step method conditioning
inference. randomized algorithm finding loop cutset outputs
minimum loop
cutset O(c 6k kn) steps probability least 1 ; (1 ; 61k )c6k , c > 1
constant specified user, k minimal size minimum weight loop cutset,
n number vertices. also show empirically variant algorithm often
finds loop cutset closer minimum weight loop cutset ones found
best deterministic algorithms known.

1. Introduction
method conditioning well known inference method computation posterior probabilities general Bayesian networks (Pearl, 1986, 1988; Suermondt & Cooper,
1990; Peot & Shachter, 1991) well finding MAP values solving constraint satisfaction problems (Dechter, 1999). method two conceptual phases. First find
optimal close optimal loop cutset perform likelihood computation
instance variables loop cutset. method routinely used
geneticists via several genetic linkage programs (Ott, 1991; Lang, 1997; Becker, Geiger, &
Schaffer, 1998). variant method developed Lange Elston (1975).
Finding minimum weight loop cutset NP-complete thus heuristic methods
often applied find reasonable loop cutset (Suermondt & Cooper, 1990).
methods past guarantee performance performed badly
presented appropriate example. Becker Geiger (1994, 1996) offered algorithm
finds loop cutset logarithm state space guaranteed
constant factor optimal value. adaptation approximation algorithms
included version 4.0 FASTLINK, popular software analyzing large
pedigrees small number genetic markers (Becker et al., 1998). Similar algorithms
context undirected graphs described Bafna, Berman, Fujito (1995)
Fujito (1996).
approximation algorithms loop cutset problem quite useful, still
worthwhile invest finding minimum loop cutset rather approximation cost finding loop cutset amortized many iterations
conditioning method. fact, one may invest effort complexity exponential size
loop cutset finding minimum weight loop cutset second phase
conditioning algorithm, repeated many iterations, uses procedure

c 2000 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiBecker, Bar-Yehuda, & Geiger

complexity. considerations apply also constraint satisfaction problems well
problems method conditioning useful (Dechter, 1990, 1999).
paper describe several randomized algorithms compute loop cutset.
done Bar-Yehuda, Geiger, Naor, Roth (1994), solution based reduction
weighted feedback vertex set problem. feedback vertex set (FVS) F set
vertices undirected graph G = (V; E ) removing F G, along
edges incident F , set trees obtained. Weighted Feedback Vertex Set
(WFVS) problem find feedback
vertex set F vertex-weighted graph weight
P
function w : V ! IR+ , v2F w(v ) minimized. w(v ) 1, problem
called FVS problem. decision version associated FVS problem known
NP-Complete (Garey & Johnson, 1979, pp. 191{192).
randomized algorithm finding WFVS, called RepeatedWGuessI, outputs

k
1
k
c
6
minimum weight FVS O(c 6 kn) steps probability least 1 ; (1 ; 6k ) ,
c > 1 constant specified user, k minimal size minimum weight FVS,
n number vertices. unweighted graphs present algorithm findsk
minimum FVS graph G O(c 4kkn) steps probability least 1 ; (1 ; 41k )c4 .
comparison, several deterministic algorithms finding minimum FVS described
literature. One complexity O((2k + 1)k n2 ) (Downey & Fellows, 1995b)
others complexity O((17k4)!n) (Bodlaender, 1990; Downey & Fellows, 1995a).
final variant randomized algorithms, called WRA, best performance
utilizes information previous runs. algorithm harder analyze
investigation mostly experimental. show empirically actual run time
WRA comparable Modified Greedy Algorithm (MGA), described Becker
Geiger (1996), best available deterministic algorithm finding close optimal
loop cutsets, yet, output WRA often closer minimum weight loop cutest
output MGA.
rest paper organized follows. Section 2 outline method
conditioning, explain related loop cutset problem describe reduction
loop cutset problem WFVS Problem. Section 3 present three randomized algorithms WFVS problem analysis. Section 4 compare experimentally
WRA MGA respect output quality run time.

2. Background: Loop Cutset Problem

short overview method conditioning definitions related Bayesian networks
given below. See book Pearl (1988) details. define loop
cutset problem.
Let P (u1 ; : : :; un) probability distribution variable ui finite set
possible values called domain ui. directed graph directed cycles
called Bayesian network P 1{1 mapping fu1; : : :; ung vertices
D, ui associated vertex P written follows:

P (u1; : : :; un) =

n

i=1

P (ui j ui ; : : :; uij )
1

( )

i1 ; : : :; ij (i) source vertices incoming edges vertex D.
220

(1)

fiRandomized Algorithms Loop Cutset Problem

Suppose variables fv1; : : :; vl g among fu1; : : :; ung assigned specific
values fv1; : : :; vlg respectively. updating problem compute probability P (ui j
v1 = v1; : : :; vl = vl ) = 1; : : :; n.
trail Bayesian network subgraph whose underlying graph simple path.
vertex b called sink respect trail exist two consecutive edges ! b
b c t. trail active set vertices Z (1) every sink respect
either Z descendant Z (2) every vertex along outside Z .
Otherwise, trail said blocked (d-separated) Z .
Verma Pearl proved Bayesian network P (u1 ; : : :; un) trails
vertex fr1; : : :; rl g vertex fs1 ; : : :; sk g blocked ft1 ; : : :; tm g,
corresponding sets variables fur ; : : :; url g fus ; : : :; usk g independent
conditioned fut ; : : :; utm g (Verma & Pearl, 1988). Furthermore, Geiger Pearl proved
result cannot enhanced (Geiger & Pearl, 1990). results presented
extended Geiger, Verma, Pearl (1990).
Using close relationship blocked trails conditional independence, Kim
Pearl developed algorithm update-tree solves updating problem
Bayesian networks every two vertices connected one trail (Kim
& Pearl, 1983). Pearl solved updating problem Bayesian network follows (Pearl, 1986). First, set vertices selected two vertices
network connected one active trail [ Z , Z subset vertices. Then, update-tree applied combination value assignments
variables corresponding , and, finally, results combined. algorithm
called method conditioning complexity grows exponentially size
. set called loop cutset. Note domain size variables varies,
update-tree called number times equal product domain sizes
variables whose corresponding vertices participate loop cutset. take
logarithm domain size (number values) weight vertex, finding
loop cutset sum vertices weights minimum optimizes Pearl's updating
algorithm case domain sizes may vary.
give alternative definition loop cutset provide probabilistic
algorithm finding it. definition borrowed paper Bar-Yehuda et al.
(1994). underlying graph G directed graph undirected graph formed
ignoring directions edges D. cycle G path whose two terminal
vertices coincide. loop subgraph whose underlying graph cycle.
vertex v sink respect loop ; two edges adjacent v ; directed
v . Every loop must contain least one vertex sink respect
loop. vertex sink respect loop ; called allowed vertex
respect ;. loop cutset directed graph set vertices contains
least one allowed vertex respectPto loop D. weight set vertices X
denoted w(X ) equal v2X w(v ) w(x) = log(jxj) jxj size
domain associated vertex x. minimum weight loop cutset weighted directed
graph loop cutset F w(F ) minimum loop cutsets G.
Loop Cutset Problem defined finding minimum weight loop cutset given
weighted directed graph D.
1

1

221

1

fiBecker, Bar-Yehuda, & Geiger

approach take reduce loop cutset problem weighted feedback
vertex set problem, done Bar-Yehuda et al. (1994). define weighted
feedback vertex set problem reduction.
Let G = (V; E ) undirected graph, let w : V ! IR+ weight function
vertices G. feedback vertex set G subset vertices F V
cycle G passes least one vertex F . words, feedback vertex
set F set vertices G removing F G, along edges
incident F , obtain set trees (i.e., aPforest). weight set vertices X
denoted (as before) w(X ) equal v2X w(v ). minimum feedback vertex set
weighted graph G weight function w feedback vertex set F G
w(F ) minimum feedback vertex sets G. Weighted Feedback Vertex Set
(WFVS) Problem defined finding minimum feedback vertex set given weighted
graph G weight function w.
reduction follows. Given weighted directed graph (D; w) (e.g., Bayesian
network), define splitting weighted undirected graph Ds weight function ws
follows. Split vertex v two vertices v v Ds incoming
edges v become undirected incident edges v Ds , outgoing edges
v become undirected incident edges v Ds. addition, connect v
v Ds undirected edge. set ws (v ) = 1 ws (v ) = w(v ). set
vertices X Ds , define (X ) set obtained replacing vertex v v
X respective vertex v vertices originated. Note
X

cycle Ds , (X ) loop D, loop D, ;1(Y ) = v2Y ;1(v )
cycle Ds
8
>
v sink
< v
;1(v ) = v
v source
>
: fv ; v g otherwise
(A vertex v source respect loop two edges adjacent v originate
v ). mapping loops cycles Ds one-to-one onto.
algorithm easily stated.




























ALGORITHM LoopCutset
Input: Bayesian network
Output: loop cutset

1. Construct splitting graph Ds
weight function ws
2. Find feedback vertex set F (Ds; ws)
using Weighted Randomized Algorithm (WRA)
3. Output (F ).

immediately seen WRA (developed later sections) outputs feedback
vertex set F Ds whose weight minimum high probability, (F ) loop
cutset minimum weight probability. observation holds due
one-to-one onto correspondence loops cycles Ds
WRA never chooses vertex infinite weight.
222

fiRandomized Algorithms Loop Cutset Problem

3. Algorithms WFVS Problem

Recall feedback vertex set G subset vertices F V cycle
G passes least one vertex F . Section 3.1 address problem
finding FVS minimum number vertices Sections 3.2 3.3 address
problem finding FVS minimum weight. Throughout, allow G
parallel edges. two vertices u v parallel edges them, every FVS
G includes either u, v , both.

3.1 Basic Algorithms

section present randomized algorithm FVS problem. First introduce
additional terminology notation. Let G = (V; E ) undirected graph.
degree vertex v G, denoted d(v ), number vertices adjacent v .
self-loop edge two endpoints vertex. leaf vertex degree
less equal 1, linkpoint vertex degree 2 branchpoint vertex
degree strictly higher 2. cardinality set X denoted jX j.
graph called rich every vertex branchpoint self-loops. Given
graph G, repeatedly removing leaves, bypassing edge every linkpoint,
graph G0 obtained size minimum FVS G0 G equal
every minimum FVS G0 minimum FVS G. Since every vertex involved
self-loop belongs every FVS, transform G0 rich graph Gr adding
vertices involved self loops output algorithm.
algorithm based observation pick edge random rich
graph probability least 1=2 least one endpoint edge belongs
given FVS F . precise formulation claim given Lemma 1 whose proof
given implicitly Voss (1968, Lemma 4).

Lemma 1 Let G = (V; E ) rich graph, F feedback vertex set G X = V n F .
Let EX denote set edges E whose endpoints vertices X EF;X denote
set edges G connect vertices F vertices X . Then, jEX j jEF;X j.
Proof. graph obtained deleting feedback vertex set F graph G(V; E )
forest vertices X = V n F . Hence, jEX j < jX j. However, vertex X
branchpoint G, so,
3 jX j

X

v 2X

d(v ) = jEF;X j + 2 jEX j:

Thus, jEX j jEF;X j. 2
Lemma 1 implies picking edge random rich graph, least
likely pick edge EF;X edge EX . Consequently, selecting vertex
random randomly selected edge probability least 1=4 belong
minimum FVS. idea yields simple algorithm find FVS.

223

fiBecker, Bar-Yehuda, & Geiger

ALGORITHM SingleGuess(G,j)
Input: undirected graph G0 integer j > 0.
Output: feedback vertex set F size j , "Fail" otherwise.
= 1; : : :; j
1. Reduce Gi;1 rich graph Gi
placing self loop vertices F .
2. Gi empty graph Return F
3. Pick edge e = (u; v ) random Ei
4. Pick vertex vi random (u; v )
5. F F [ fvig
6. V V n fvi g
Return "Fail"

Due Lemma 1, SingleGuess(G; j ) terminates FVS size j ,
probability least 1=4j output minimum FVS.
Note steps 3 4 SingleGuess determine vertex v first selecting
arbitrary edge selecting arbitrary endpoint edge. equivalent way
achieving selection rule choose vertex probability proportional
degree:
p(v) = P d(vd)(u) = 2d(jvE) j
u2V
see equivalence two selection methods, define ;(v ) set edges whose
one endpoint v , note graphs without self-loops,
X
X
p(v) =
p(v je) p(e) = 12
p(e) = 2d(jvE) j
e2;(v)
e2;(v)

equivalent phrasing selection criterion easier extend weighted case
used following sections.
algorithm finding minimum FVS high probability, call RepeatedGuess, described follows: Start j = 1. Repeat SingleGuess c 4j
times c > 1 parameter defined user. one iterations FVS
size j found, output FVS, otherwise, increase j one continue.

ALGORITHM RepeatedGuess(G,c)
Input: undirected graph G

constant c > 1.
Output: feedback vertex set F .
j = 1; : : :; jV j
Repeat c 4j times
1. F SingleGuess(G; j )
2. F "Fail" Return F
End fRepeatg
End fForg
224

fiRandomized Algorithms Loop Cutset Problem

main claims algorithms given following theorem.

Theorem 2 Let G undirected graph c 1 constant. Then, SingleGuess(G; k)
outputs FVS whose expected size 4k, RepeatedGuess(G;
c) outputs,
O(c 4kkn) steps, minimum FVS probability least 1 ; (1 ; 41k )c4k , k
size minimum FVS n number vertices.
claims probability success number steps follow immediately
fact probability success SingleGuess(G; j ) least (1=4)j
that, case success, O(cP4j ) iterations performed taking O(jn) steps. result
follows fact kj=1 j 4j order O(k4k ). proof expected size
single guess presented next section.
Theorem 2 shows guess produces FVS which, average,
far minimum, enough iterations, algorithm converges
minimum high probability. weighted case, discussed next, managed
achieve two guarantees separate algorithms, unable achieve
guarantees single algorithm.

3.2 Weighted Algorithms

turn weighted FVS problem (WFVS) size k find feedback
vertex set F vertex-weighted graph (G; w), w : V ! IR+ , size less equal k
w(F ) minimized.
Note weighted FVS problem cannot replace linkpoint v
edge v weight lighter branchpoint neighbors v participate
minimum weight FVS size k.
graph called branchy endpoints, self loops, and, addition,
linkpoint connected branchpoints (Bar-Yehuda, Geiger, Naor, & Roth, 1994).
Given graph G, repeatedly removing leaves, bypassing edge every
linkpoint neighbor equal lighter weight, graph G0 obtained
weight minimum weight FVS (of size k) G0 G equal every
minimum WFVS G0 minimum WFVS G. Since every vertex self-loop
belongs every FVS, transform G0 branchy graph without self-loops adding
vertices involved self loops output algorithm.
address WFVS problem offer two slight modifications algorithm SingleGuess presented previous section. first algorithm, call SingleWGuessI, identical SingleGuess except iteration make reduction branchy graph instead reduction rich graph.
chooses vertex
P
probability proportional degree using p(v ) = d(v )= u2V d(u). Note
probability take weight vertex account. second algorithm,
call SingleWGuessII, chooses vertex probability proportional ratio
degree weight,
X
(2)
p(v ) = wd((vv)) = wd((uu)) :
u2V

225

fiBecker, Bar-Yehuda, & Geiger

ALGORITHM SingleWGuessI(G,j)
Input: undirected weighted graph G0
integer j > 0.

Output: feedback vertex set F size j ,
"Fail" otherwise.

= 1; : : :; j

1. Reduce Gi;1 branchy graph Gi (Vi; Ei)
placing self loop vertices F .
2. Gi empty graph Return F
3. Pick vertex vi 2 Vi random

P
probability pi(v ) = di(v )= u2Vi di(u)
4. F F [ fvig
5. V V n fvi g
Return "Fail"
second algorithm uses Eq. 2 computing p(v ) Line 3. two algorithms
remarkably different guarantees performance. Version guarantees choosing
vertex belongs given FVS larger 1=6, however, expected weight
FVS produced version cannot bounded constant times weight minimum
WFVS. Version II guarantees expected weight output bounded 6 times
weight minimum WFVS, however, probability converging minimum
fixed number iterations arbitrarily small. first demonstrate via
example negative claims. positive claims phrased precisely Theorem 3
proven thereafter.
Consider graph shown Figure 1 three vertices a,b c, corresponding
weights w(a) = 6, w(b) = 3 w(c) = 3m, three parallel edges b,
three parallel edges c. minimum WFVS F size 1 consists
vertex a. According Version II, probability choosing vertex (Eq. 2):

p(a) = (1 + 1=m ) + 1

arbitrarily small suciently large, probability choosing vertex
arbitrarily small. Thus, probability choosing vertex F
criterion d(v )=w(v ), done Version II, arbitrarily small. If, hand,
Version used, probability choosing a; b, c 1=2; 1=4; 1=4, respectively.
Thus, expected weight first vertex chosen 3=4 ( + + 4),
weight minimum WFVS 6. Consequently, suciently large, expected
weight WFVS found Version arbitrarily larger minimum WFVS.
algorithm repeated guesses, call RepeatedWGuessI(G; c; j )
follows: repeat SingleWGuessI(G; j ) c 6j times, j minimal number vertices
minimum weight FVS seek. FVS found size j , algorithm outputs
size minimum WFVS larger j high probability, otherwise,
outputs lightest FVS size less equal j among explored. following
theorem summarizes main claims.
226

fiRandomized Algorithms Loop Cutset Problem

w(c) = 3
c

w(a) = 6

w(b) = 3m



b

Figure 1: minimum WFVS F = fag.

Theorem 3 Let G weighted undirected graph c 1 constant.
a) algorithm RepeatedWGuessI(G; c; kk ) outputs O(c 6kkn) steps minimum
WFVS probability least 1 ; (1 ; 61k )c6 , k minimal size minimum

weight FVS G n number vertices.
b) algorithm SingleWGuessII(G,k) outputs feedback vertex set whose expected
weight six times weight minimum weight FVS.

proof part requires preliminary lemma.

Lemma 4 Let G = (V; E ) branchy graph, F feedback vertex set G X =
V n F . Let EX denote set edges E whose endpoints vertices X

EF;X denote set edges G connect vertices F vertices X . Then,
jEX j 2 jEF;X j.

Proof. Let X b set branchpoints X . replace every linkpoint X

edge neighbors, denote resulting set edges vertices X b
b b . proof Lemma 1 shows
EXb b vertices X b F EF;X
b b j:
jEXb b j jEF;X

Since every linkpoint X neighbors set X b [ F , following holds:
b b j:
jEX j 2 jEXb b j jEF;X j = jEF;X
Hence, jEX j 2 jEF;X j. 2

immediate consequence Lemma 4 probability randomly choosing
edge least one endpoint belongs FVS greater equal 1=3. Thus,
selecting vertex random randomly selected edge probability least
1=6 belong FVS. Consequently, algorithm terminates
c 6k iterations,
k
1
WFVS size k, probability least 1 ; (1 ; 6k )c6 output
minimum WFVS size k. proves part (a) Theorem 3. Note since k
known advance, use RepeatedWGuessI(G; c; j ) increasing values j
FVS found, say j=J. set found still possible
exists WFVS J vertices smaller weight one found.
happens k > J . However, among WFVSs size J , algorithm
finds one minimum weight high probability.
second part requires following lemma.
227

fiBecker, Bar-Yehuda, & Geiger

Lemma 5 Let G branchy graph F FVS G. Then,
X
X
d(v ) 6 d(v):
v2V

v 2F

Proof. Denote dY (v) number edges vertex v set vertices .
Then,

X

v2V

Due Lemma 4,
Consequently,

d(v) =

X

X

d(v ) =

v 2F
X
X
X
dX (v) + dF (v) + d(v ):
v2X
v 2X
v2F

X

v2X

v2X

d(v ) +

dX (v) = 2jEX j 4jEF;X j = 4

X

v2V

(v ) 4
X

v2X

X

v2X

dF (v) +

X

v2X

dF (v ):

(3)

dF (v)+
X

v2F

d(v) 6

X

v 2F

d(v )

claimed. 2
prove part (b) Theorem 3 analyzing SingleWGuessII(G,k). Recall
Vi set vertices graph Gi iteration i, di (v ) degree vertex v Gi,
vi vertex chosen iteration i. Furthermore, recall pi(v ) probability
choose vertex v iteration i.
P
expected weight Ei (w(v )) = v2Vi w(v ) pi (v ) chosen vertex iteration

Pk
denoted ai . Thus, due linearity expectation operator, E (w(F )) = i=1 ai,
assuming jF j = k. define normalization constant iteration follows:

=

"

#
X di (u) ;1

u2Vi

w(u)

Then, pi (v ) = dwi((vv))

ai =

X

v2Vi

X
w(v) dwi((vv)) = di(v )

v 2V

Let F minimum FVS G Fi minimum weight FVS graph Gi .
expected weight Ei(w(v )jv 2 Fi )) vertex chosen Fi iteration denoted
bi. have,
X
X
bi =
w(v ) pi(v ) = di (v)
v2Fi

v2Fi

Lemma 5, ai =bi 6 every i.

228

fiRandomized Algorithms Loop Cutset Problem

Recall definition F2 minimum FVS branchy graph G2 obtained
G1 n fv1g. get,

E (w(F )) E1(w(v)jv 2 F1 )) + E (w(F2))
right hand side expected weight output F assuming algorithm
finds minimum FVS G2 needs select one additional vertex, left
hand side unrestricted expectation. repeating argument get,

E (w(F )) b1 + E (w(F2))
Using

P

ai =

P
bi maxi ai =bi 6,

k
X
i=1

bi

obtain

E (w(F )) 6 E (w(F )):
Hence, E (w(F )) 6 w(F ) claimed. 2
proof SingleGuess(G; k) outputs FVS whose expected size
4k (Theorem 2) k size minimum FVS analogous proof

Theorem 3 following sense. assign weight 1 vertices replace
reference
Lemma P
5 reference following claim: F FVS rich graph G,
P
v2V d(v ) 4 v2F d(v ). proof claim identical proof Lemma 5
except instead using Lemma 4 use Lemma 1.

3.3 Practical Algorithm

previous sections presented several algorithms finding minimum FVS high
probability. description algorithms geared towards analysis, rather
prescription programmer. particular, number iterations used within
RepeatedWGuessI(G; c; k) changed algorithm run j < k. feature
allowed us regard call SingleWGuessI(G; j ) made RepeatedWGuessI
independent process. Furthermore, small probability long run even
size minimum FVS small.
slightly modify RepeatedWGuessI obtain algorithm, termed WRA,
suffer deficiencies. new algorithm works follows. Repeat
SingleWGuessI(G; jV j) min(Max; c 6w(F )) iterations, w(F ) weight
lightest WFVS found far Max specified constant determining maximum
number iterations SingleWGuessI.

ALGORITHM WRA(G; c; Max)
Input: undirected weighted graph G(V; E ) constants Max c > 1
Output: feedback vertex set F
F SingleWGuessI (G; jV j)


min(Max; c 6w(F )); 1;

1. F 0 SingleWGuessI(G; jV j)
2. w(F 0 ) w(F )

229

fiBecker, Bar-Yehuda, & Geiger

jV j jE j values
15 25
15 25
15 25
25 55
25 55
25 55
55 125

2{6
2{8
2{10
2{6
2{8
2{10
2{10

size MGA WRA Eq.
3{6
12
81
7
3{6
7
89
4
3{6
6
90
4
7{12
3
95
2
7{12
3
97
0
7{12
0
100 0
17{22
0
100 0
31
652 17

Figure 2: Number graphs MGA WRA yield smaller loop cutset. last
column records number graphs two algorithms produced loop
cutsets weight. line table based 100 graphs.

F F 0;
3. + 1;
End fWhileg
Return F

min(Max; c 6w(F ))

Theorem 6 Max c6k, k minimal size minimum WFVS undi-

rected weighted graph G, thenk WRA(G; c; Max) outputs minimum WFVS G probability least 1 ; (1 ; 61k )c6 .

proof immediate corollary Theorem 3.
choice Max c depend application. decision-theoretic approach
selecting values any-time algorithms discussed Breese Horvitz (1990).

4. Experimental Results

experiments compared outputs WRA vis-a-vis greedy algorithm GA
modified greedy algorithm MGA (Becker & Geiger, 1996) based randomly generated
graphs real graphs contributed Hugin group (www.hugin.com).
random graphs divided three sets. Graphs 15 vertices 25 edges
number values associated vertex randomly chosen 2
6, 2 8, 2 10. Graphs 25 vertices 55 edges number
values associated vertex randomly chosen 2 6, 2 8,
2 10. Graphs 55 vertices 125 edges number values
associated vertex randomly chosen 2 10. instance
three classes based 100 random graphs generated described Suermondt
Cooper (1990). total number random graphs used 700.
results summarized table Figure 2. WRA run Max = 300
c = 1. two algorithms, MGA WRA, output loop cutsets size
230

fiRandomized Algorithms Loop Cutset Problem

Name jV j
Water 32
Mildew 35
Barley 48
Munin1 189

jEj jF j

123
80
126
366

16
14
20
59

GA MGA WRA
40.7 42.7 29.5
48.1 40.5 39.3
72.1 76.3 57.3
159.4 167.5 122.6

Figure 3: Log size (base 2) loop cutsets found GA, MGA, WRA.
17 graphs algorithms disagree, 95% graphs WRA performed
better MGA.
actual run time WRA(G; 1; 300) 300 times slower GA (or MGA)
G. largest random graph used, took 4.5 minutes. time spend
last improvement WRA. Considerable run time saved letting Max = 5.
700 graphs, WRA(G,1,5) already obtained better loop cutset MGA.
largest improvement, Max = 300, weight 58.0 (log2 scale) weight
35.9. improvements case obtained iterations 1, 2, 36, 83, 189
respective weights 46.7, 38.8, 37.5, 37.3, 35.9 respective sizes 22, 18, 17, 18,
17 nodes. average, 300 iterations, improvement larger 100 graphs
weight 52 39 size 22 20. improvement smaller 600
graphs weight 15 12.2 size 9 6.7.
second experiment compared GA, MGA WRA four real Bayesian
networks showing WRA outperformed GA MGA single call SingleWGuessI. weight output continued decrease logarithmically
number iterations. report results Max = 1000 c = 1. Run time
3 minutes Water 15 minutes Munin1 Pentium 133 32M RAM.

5. Discussion

randomized algorithm, WRA, incorporated popular genetic software
FASTLINK 4.1 Alejandro Schaffer develops maintains software
National Institute Health. WRA replaced previous approximation algorithms finding
FVS small Max value already matched improved FASTLINK 4.0
datasets examined. datasets used comparison described Becker et
al. (1998). main characteristics datasets collected
geneticists, small number loops, large number values node
(tens hundreds depending genetic analysis). networks method
conditioning widely used geneticists.
leading inference algorithm, however, Bayesian networks clique-tree algorithm (Lauritzen & Spiegelhalter, 1988) developed several papers
(Jensen, Lauritzen, & Olsen, 1990a; Jensen, Olsen, & Andersen, 1990b). networks
presented Table 3 conditioning feasible method clique tree algorithm
used compute posterior probabilities networks. Furthermore,
shown weight largest clique bounded weight
loop cutset union largest parent set vertex Bayesian network implying
231

fiBecker, Bar-Yehuda, & Geiger

clique tree algorithm always superior time performance conditioning algorithm
(Shachter, Andersen, & Szolovits, 1994). two methods, however, combined
strike balance time space requirements done within bucket elimination
framework (Dechter, 1999).
algorithmic ideas behind randomized algorithms presented herein also
applied constructing good clique trees initial experiments confirm improvement deterministic algorithms often obtained. idea instead greedily
selecting smallest clique constructing clique tree, one would randomly select
next clique according relative weights candidate cliques. remains develop
theory behind random choices clique trees solid assessment presented.
Currently, algorithm finding clique tree size guaranteed
close optimal high probability.
Horvitz et al. (1989) show method conditioning useful approximate
inference. particular, show rank instances loop cutset according
prior probabilities assuming variables cutset marginally independent.
conditioning algorithm run according ranking answer
query given interval shrinks towards exact solution instances
loop cutset considered (Horvitz, Suermondt, & Cooper, 1989; Horvitz, 1990).
Applying idea without making independence assumptions described Darwiche
(1994). maximal clique large store one still perform approximate
inferences using conditioning algorithm.

Acknowledgment
thank Se Naor fruitful discussions. Part work done third
author sabbatical Microsoft Research. variant work presented
fifteenth conference uncertainty artificial intelligence, July 1999, Sweden.

References
Bafna, V., Berman, P., & Fujito, T. (1995). Constant ratio approximations weighted
feedback vertex set problem undirected graphs. Proceedings Sixth Annual
Symposium Algorithms Computation (ISAAC95), pp. 142{151.
Bar-Yehuda, R., Geiger, D., Naor, J., & Roth, R. (1994). Approximation algorithms
feedback vertex set problems applications constraint satisfaction Bayesian
inference. Proceedings 5th Annual ACM-Siam Symposium Discrete Algorithms, pp. 344{354.
Becker, A., & Geiger, D. (1994). Approximation algorithms loop cutset problem.
Proceedings 10th conference Uncertainty Artificial Intelligence, pp. 60{68.
Becker, A., & Geiger, D. (1996). Optimization pearl's method conditioning greedylike approximation algorithms feedback vertex set problem. Artificial Intelligence, 83, 167{188.
232

fiRandomized Algorithms Loop Cutset Problem

Becker, A., Geiger, D., & Schaffer, A. (1998). Automatic selection loop breakers
genetic linkage analysis. Human Heredity, 48, 47{60.
Bodlaender, H. (1990). disjoint cycles. International Journal Foundations Computer Science (IJFCS), 5, 59{68.
Breese, J., & Horvitz, E. (1990). Ideal reformulation belief netwroks. Proceedings
6th conference Uncertainty Artificial Intelligence, pp. 64{72.
Darwiche, A. (1994). -bounded conditioning: method approximate updating
causal networks. Research note, Rockwell Science Center.
Dechter, R. (1990). Enhancement schemes constraint processing: backjumping, learning,
cutset decomposition. Artificial Intelligence, 41, 273{312.
Dechter, R. (1999). Bucket elimination: unifying framework structure-driven inference. Artificial Intelligence, appear.
Downey, R., & Fellows, M. (1995a). Fixed-parameter tractability completeness I: Basic
results. SIAM Journal Computing, 24 (4), 873{921.
Downey, R., & Fellows, M. (1995b). Parameterized computational feasibility. P. Clote, .
J. R. (Ed.), Feasible Mathematics II, pp. 219{244. Birkhauser, Boston.
Fujito, T. (1996). note approximation vertex cover feedback vertex set
problems - unified approach. Information Processing Letters, 59, 59{63.
Garey, M., & Johnson, D. (1979). Computers Intractability: Guide Theory
NP-completeness. W. H. Freeman, San Francisco, California.
Geiger, D., & Pearl, J. (1990). logic causal models. Uncertainty Artificial
Intelligence 4, pp. 3{14 New York. North-Holland.
Geiger, D., Verma, T., & Pearl, J. (1990). Identifying independence bayesian networks.
Networks, 20, 507{534.
Horvitz, E. J. (1990). Computation action bounded resources. Ph.D dissertation,
Stanford university.
Horvitz, E. J., Suermondt, H. J., & Cooper, G. H. (1989). Bounded conditioning: Flexible
inference decisions scarce resources. Proceedings 5th conference
Uncertainty Artificial Intelligence, pp. 182{193. Morgan Kaufmann.
Jensen, F., Lauritzen, S. L., & Olsen, K. (1990a). Bayesian updating causal probabilisitic
networks local computations. Computational Statistics Quarterly, 4, 269{282.
Jensen, F., Olsen, K., & Andersen, S. (1990b). algebra bayesian belief universes
knowledge-based systems. Networks, 20, 637{659.
Kim, H., & Pearl, J. (1983). computational model combined causal diagnostic reasoning inference systems. Proceedings Eighth International Joint
Conference Artificial Intelligence (IJCAI83), pp. 190{193.
233

fiBecker, Bar-Yehuda, & Geiger

Lang, K. (1997). Mathematical statistical methods genetic analysis. Springer.
Lange, K., & Elston, R. (1975). Extensions pedigree analysis. I. likelihood calculation
simple complex pedigrees. Human Heredity, 25, 95{105.
Lauritzen, S., & Spiegelhalter, D. (1988). Local computations probabilities graphical
structures application expert systems (with discussion). Journal Royal
Statistical Society, B, 50, 157{224.
Ott, J. (1991). Analysis human genetic linkage (revised edition). Johns Hopkins
University Press.
Pearl, J. (1986). Fusion, propagation structuring belief networks. Artificial Intelligence, 29, 241{288.
Pearl, J. (1988). Probabilistic reasoning intelligent systems: Networks plausible inference. Morgan Kaufmann, San Mateo, California.
Peot, M., & Shachter, R. (1991). Fusion propagation multiple observations
belief networks. Artificial Intelligence, 48, 299{318.
Shachter, R., Andersen, S., & Szolovits, P. (1994). Global conditioning probabilistic
inference belief networks. Proceedings tenth conference Uncertainty
Artificial Intelligence, pp. 514{522. Morgan Kaufmann.
Suermondt, H., & Cooper, G. (1990). Probabilistic inference multiply connected belief
networks using loop cutsets. International Journal Approximate Reasoning, 4, 283{
306.
Verma, T., & Pearl, J. (1988). Causal networks: Semantics expressiveness. Proceedings 4th Workshop Uncertainty Artificial Intelligence, pp. 352{359.
Voss, H. (1968). properties graphs containing k independent circuits. Proceedings
Colloquium Tihany, pp. 321{334 New York. Academic Press.

234

fiJournal Artificial Intelligence Research 12 (2000) 93-103

Submitted 11/99; published 3/00

Exact Phase Transitions
Random Constraint Satisfaction Problems
kexu@nlsde.buaa.edu.cn
liwei@nlsde.buaa.edu.cn

Ke Xu
Wei Li
National Laboratory Software Development Environment,
Department Computer Science Engineering,
Beijing University Aeronautics Astronautics,
Beijing, 100083, P.R. China

Abstract
paper propose new type random CSP model, called Model RB,
revision standard Model B. proved phase transitions region
almost problems satisfiable region almost problems unsatisfiable
exist Model RB number variables approaches infinity. Moreover, critical
values phase transitions occur also known exactly. relating hardness
Model RB Model B, shown exist lot hard instances Model RB.

1. Introduction
Since seminal paper Cheeseman, Kanefsky Taylor (1991) appeared,
great amount interest study phase transitions NP-complete problems.
However, seems dicult prove existence phenomenon obtain
exact location transition points problems. example, random 3SAT, known experiments phase transition occur ratio
clauses variables approximately 4:3 (Mitchell, Selman, & Levesque, 1992). Another
experimental estimate transition point suggested Kirkpatrick Selman (1994)
4:17. used finite-size scaling methods statistical physics derive result.
contrast experimental studies, theoretical work given loose
hard bounds location transition point. Currently, best known lower
bound upper bound 3:003 (Frieze & Suen, 1996) 4:602 (Kirousis et al., 1998)
respectively. Recently, Friedgut (1999) made tremendous progress towards establishing
existence threshold random k-SAT proving width transition region
narrows number variables increases. still obtain exact location
phase transition point approach.
fact, SAT special case constraint satisfaction problem (CSP). CSP
important theoretical value artificial intelligence, also many immediate applications areas ranging vision, language comprehension scheduling diagnosis
(Dechter, 1998). general, CSP tasks computationally intractable (NP-hard) (Dechter,
1998). recent years random constraint satisfaction problems also received great attention, experimental theoretical point view (Achlioptas et al., 1999;
Cheeseman et al., 1991; Frost & Dechter, 1994; Gent et al., 1999; Hogg, 1996; Larrosa &
Meseguer, 1996; Prosser, 1996; Purdom, 1997; Smith & Dyer, 1996; Smith, 1999; Williams

c 2000 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiXu & Li
& Hogg, 1994). Williams Hogg (1994) developed technique predict
hardest problems found uctuations diculty greatest
space problem instances. also shown predictions critical value
agree well experimental data. Smith Dyer (1996) studied location
phase transition binary constraint satisfaction problems discussed accuracy
prediction based expected number solutions. results show variance
number solutions used set bounds phase transition indicate
accuracy prediction. Recently, theoretical result Achlioptas et al. (1999)
shows many models commonly used generating random CSP instances
asymptotic threshold due presence awed variables. recently, Gent et al.
(1999) shown introduce structure con ict matrix eliminate aws.
paper propose new type random CSP model, called Model RB,
revision standard Model B (Gent et al., 1999; Smith & Dyer, 1996).
proved phase transition phenomenon exist Model RB number
variables approaches infinity. precisely, exist two control parameters r, p
corresponding critical values rcr , pcr fixed value r < rcr p < pcr ,
random CSP instance generated following Model RB satisfiable probability tending
1 number variables approaches infinity, r > rcr p > pcr , unsatisfiable
probability tending 1. Moreover, critical values rcr pcr also known
exactly. relating hardness Model RB Model B, shown Model RB
actually lot hard instances.

2. Definitions Notations
constraint satisfaction problem (CSP) consists finite set U = fu1 ; ; un g n
variables set constraints. variable ui , domain Di di elements
specified; variable assigned value domain. 2 k n
constraint Ci1;i2;;ik consists subset fui1 ; ui2 ; ; uik g U relation Ri1;i2;;ik
Di1 Dik , i1; i2; ; ik distinct. Ci1;i2;;ik called k-ary constraint
bounds variables ui1 ; ; uik . Ri1;i2;;ik specifies allowed tuples values
variables ui1 ; ; uik compatible other. solution CSP
assignment value variable domain constraints
satisfied. constraint Ci1;i2;;ik satisfied tuple values assigned variables
ui1 ; ; uik relation Ri1;i2;;ik . CSP solution called satisfiable;
otherwise unsatisfiable. paper, probability random CSP instance
satisfiable denoted P r(Sat).
assume k 2 variable domains contain number values
= nff Model RB (where ff constant). generation random CSP instance
Model RB done following two steps:
Step 1. select repetition = rn ln n random constraints. random constraint
formed selecting without repetition k n variables.
Step 2. constraint uniformly select without repetition q = p dk incompatible
tuples values, i.e., constraint relation contains exactly (1 p) dk compatible tuples
values.
94

fiExact Phase Transitions Random Constraint Satisfaction Problems
parameter r determines many constraints CSP instance, p
determines restrictive constraints are.
following definitions needed section 4 derive expectation
second moment number solutions.

Definition 1 assignment pair ordered pair hti ; tj assignments variables
U , ti = (ai1 ; ai2 ; ; ) tj = (aj 1 ; aj 2 ; ; ajn ) ail ; ajl 2 Dl . assignment pair hti ; tj satisfies CSP ti tj satisfy CSP. set
consists assignment pairs denoted Apair .
Definition 2 Similarity number f : Apair 7! f0; 1; 2; g,
f
(ht

; tj i) =

n
X

( il ; ajl )

(1)

ail = ajl
ail 6= ajl

(2)



l=1

function Sam defined follows:


( il ; ajl ) =



1
0

similarity number assignment pair equal number variables
two assignments assignment pair take identical values. Definition 2
easy see 0 f (hti ; tj i) n.

3. Main Results
paper, following theorems proved.

Theorem 1 Let rcr =
inequality k 1 1 p ,

ff

ln(1 p) .

ff > k1 , 0 < p < 1 two constants k, p satisfy

lim

P r

(

) = 1

r < r

lim

P r

(

) = 0

r > r

n!1
n!1

cr

(3)

cr

(4)

ff

Theorem 2 Let pcr = 1 e r . ff > k1 , r > 0 two constants k, ff r satisfy
ff
inequality ke r 1,
lim

P r

lim

P r

n!1
n!1

(

) = 1

p < p

cr

(5)

(

) = 0

p > p

cr

(6)

4. Proof Theorem 1 Theorem 2
expected number solutions E (N ) model RB given
( ) = dn (1

E N

)rn ln n = nffn (1

p

)rn ln n

p

(7)

Markov inequality P r(Sat) E (N ) hard show limn!1 P r(Sat) = 0
r > rcr p > pcr . Hence relations (4), (6) proved. also easy see
95

fiXu & Li
E (N ) eqal 1 r = rcr p = pcr , E (N ) grows exponentially n
r < rcr p < pcr .

key point proof relations (3), (5) derive expectation second
moment E (N 2 ) give asymptotic estimate it. Let random CSP instance
generated following Model RB. P (hti ; tj i) stands probability hti ; tj satisfying .
start derive expression P (hti ; tj i). Since constraint generated
independently, need consider probability hti ; tj satisfying random constraint. Assuming similarity number hti ; tj equal , following
two cases:
(1) variable constraint assigned value ti tj .
k
1 = dk .
case, probability hti ; tj satisfying constraint

q

(2) Otherwise, probability hti ; tj satisfying constraint




probability random constraint falls first case

0
B

P

(hti ; tj i) = B
@

k

1







q

k



= n . Thus get
k
k



probability second case 1









k



n

+





k



q

k



k

q

2



(1




k
n

q

dk

dk .
=
q
q


= n . Hence
k
k


2

1rn ln n
C
C
)A

(8)

k

q

Let set assignment pairs whose similarity number equal . easy
show cardinality given

j Sj =

n







n



1)n

(d



(9)

definition E (N 2 ),

E (N 2 ) =

n
X
=0

= dn

jAS jP (ti ; tj )



0

n (d 1)n


B

SB
B
@

dk

1





q
dk
q








k
n
k






+

dk

2





q
dk
q





(1



rn ln n
k C
)C
C (10)
n
k
1

dicult analyze expression directly. First, give asymptotic
estimate P (hti ; tj i). Let = Sn . obvious 0 1. asymptotic analysis,
get





k
n
k







(
= n n
(1

1
n )( n

1

n )(1

2

n) (n

n ) (1
2

96

k 1)
1
k g (s)
n
k 1 ) = + n + ( n2 )
n

fiExact Phase Transitions Random Constraint Satisfaction Problems



k





k

1)



(11)



1



1)(sk
2

(

k k

( )=

g

q

=

k


k



k

q

=1



(12)

p

q

k







2



q

k


(dk

=



)(dk q
k k 1)
(d

1)

q

= (1

1
)2 + ( k )


(13)

p

q

Note = nff ,


P

(hti ; tj i) = (1

) (sk +

p

( )

g
n

)2 (1

) + (1

k

p



( )

g
n

) + O(


1 rn ln n
)
+
O(
)
2
kff
n
n

1

(14)

use condition ff > k1 , get
P

(hti ; tj i) = (1

p

2rn ln n



)

1+

p

1

p

rn ln n
g (s)
1
k
(s +
)
(1 + O( ))
n

(15)

n

every 0 < < 1 (where = Sn ), asymptotic estimate jAS j

jAS j

1
1
en( ln (1 s) ln(1 s)) (1 + O( ))
n
2ns(1 s)
1
1
1 n ns 1 ns
)
( ff) p
en( ln (1 s) ln(1 s)) (1 + O( )) (16)
nff
n
n
2ns(1 s)

= nffn (nff

1)n ns p

= n2ffn (1

Notice E (N ) = nffn(1

j j (h j i) =


P

;t

E

2

p)rn ln n ,



(N ) 1 +

p

1

p

g (s)
(sk +
)

rn ln n

n

(1

1 n ns 1 ns
( ff)
ff)
n
n

n
ns



1
(1 + O( )) (17)
n

n suciently large, except first term E 2 (N ), jAS jP (hti ; tj i) mainly determined following terms:


f (s) = 1 +
rewrite
Let



f (s) = e

1

p

p

h00 (s) =

rn ln n

1
( ff )ns
n



r ln(1+ 1 p p sk ) ffs n ln n

h(s) = r ln(1 +

second derivative h(s)

sk

1

p

p

sk ) ffs

rkpsk 2[(k 1)(1 p) psk ]
(1 p + psk )2
97

(18)
(19)
(20)

(21)

fiXu & Li
Applying condition k 1 1 p Theorem 1 equation easily prove
ff
h00 (s) 0 interval 0 1. Theorem 2, condition ke r 1
follows inequality k 1 1 p still holds p < pcr . also hard show
h(0) = 0, h(1) = r ln(1 p) ff < 0 r < rcr p < pcr . Hence easily
prove unique maximum point h(s) = 0 r < rcr p < pcr . Thus
terms 0 < 1 negligible r < rcr p < pcr . need consider
terms near = 0 . process divided following three cases:
Case 1: ff > 1. = 0 (s = 0), definition g(s) Equation (11)


p k g(s) rn ln n
1+
(s +
)
=1
(22)
1 p
n
Thus Equation (17) get

jAS jP (hti ; tj i) E 2 (N )(1 n1ff )n E 2(N )

(23)

= 1 (s = n1 ), also hard prove


lim 1 +
n!1
1
Hence obtain
Similary,

p

p

(sk +

g(s)
)
n

rn ln n

jAS jP (hti ; tj i) E 2 (N )n1

ff

2(1 ff)

jAS jP (hti ; tj i) E 2 (N ) n

2!

3(1 ff)

jAS jP (hti; tj i) E 2 (N ) n
Summing terms together, obtain

E (N 2 ) =

n
X
=0

3!

= e0 = 1

S=1

(24)
(25)

= 2

= 3;

(26)

ff

(27)

jAS jP (hti ; tj i) E 2 (N )en

1

E 2 (N )

Case 2: ff = 1. use method Case 1, easily shown

jAS jP (hti; tj i) E 2 (N )(1 n1 )n E 2(N ) 1e = 0
jAS jP (hti ; tj i) E 2 (N ) 1e = 1
jAS jP (hti ; tj i) E 2 (N ) e 12! = 2

jAS jP (hti ; tj i) E 2 (N ) e 13! = 3;
98

(28)

fiExact Phase Transitions Random Constraint Satisfaction Problems
Summing terms together, obtain

E (N 2 ) =

n
X
=0

jAS jP (hti ; tj i) E 2 (N ) 1e e = E 2(N )

(29)

< ff < 1. Let S0 = nfi (where fi constant satisfies 1 ff < fi < 1 k1 ).
1
hard show 0 S0 (0 nfi 1 < n k ), following limit
Case 3:

1

k

holds:

lim

n!1 1

p

p

g(s)
) n ln n = 0
n

(sk +

(30)

Thus 0 S0 , asymptotic estimate second term right Equation
(17)


p k g(s) rn ln n 0
1+
(s +
)
e = 1 n ! 1
(31)
1 p
n
0 S0 , asymptotic estimate jAS jP (hti ; tj i)

jAS jP (hti ; tj i) E 2 (N ) Sn



(1

1 n 1
) ( ff)
nff
n

(32)

n (1 1 )n ( 1 )S binomial term whose maximum point
nff
nff

around = n1 ff , S0 = nfi > n1 ff . asymptotic analysis, obtain
noted
S0
X
=0



n (1


1 n 1
) ( ff)
nff
n

Thus get

E (N 2 ) =

n
X
=0



n
X
=0

n (1


1 n 1
) ( ff) = 1
nff
n

jAS jP (hti ; tj i) E 2(N )

(33)

(34)

Combining three cases gives

Hence

E (N 2 ) E 2 (N ) r < rcr p < pcr

(35)

E 2 (N )
lim
= 1 r < rcr p < pcr
n!1 E (N 2 )

(36)

Cauchy inequality P r(Sat) EE (N(N2 )) (Bollobas, 1985), easily proved
limn!1 P r(Sat) = 1 r < rcr p < pcr . Hence Theorem 1 Theorem 2
proved.
2

99

fiXu & Li
5. Relation Model B Model RB
section explain detail Model RB revises Model B show
hardness Model RB relating Model B. previous papers (Gent et al.,
1999; Smith & Dyer, 1996) know generation random CSP instance
standard Model B (which often written hn; d; p1 ; p2 i) done following two steps:
Step 1. select repetition = p1 n(n2 1) random constraints. random constraint
formed selecting without repetition 2 n variables.
Step 2. constraint uniformly select without repetition q = p2 d2 incompatible
tuples values, i.e., constraint relation contains exactly (1 p2 ) d2 compatible tuples
values.
Since standard Model B binary CSP model, consider binary
case Model RB section. previous papers Model B used test
CSP algorithms following way. Given values n, p1 , constraint
tightness p2 varied 0 1 steps d12 . setting hn; d; p1 ; p2 fixed
number instances (e.g. 100) generated. search algorithm applied
instance. Finally numerous statistics search cost probability
satisfiable gathered. fact, two steps forming constraint selecting
incompatible tuples values Model RB exactly Model B.
significant difference Model B Model RB Model RB restricts fast
domain size number constraints increase number variables
Model B not, may lead result many instances Model B suffer
asymptotically trivially insoluble (Achlioptas et al., 1999) Model RB avoids
problem. easy see given values n, p1 , setting hn; d; p1 ; p2
Model B equivalent setting Model RB number variables
ln r = p1 (n 1) (Let nff = rn ln n = 1 p n(n 1)).
hn; d; p1 ; p2 i, ff = ln
n
2ff ln n
2 1
Theorem 2 shows ff > 12 2e r 1, exists exact phase transition
binary case Model RB. Given values n, p1 Model B, setting
hn; d; p1 ; p2 i, conditions equivalent setting Model RB satisfies Theorem 2

ln 1
ff=
> ) d2 > n
(37)
ln n 2
ln
2 ln n
ff
2 ln
2e r 1 ) 2e ln n p1 (n 1) 1 ) p1
(38)
(n 1) ln 2
proof Theorem 2 reveals conditions (37), (38) satisfied, Model
RB exhibit exact phase transition E (N ) = 1. noted Williams
Hogg (Williams & Hogg, 1994), independently Smith (1996) already developed
theory predict phase transition point Model B basis E (N ) = 1. Prosser
(1996) found theory close agreement empirical results, except
p1 small. Inequality (38) shows order make equivalent setting Model RB
satisfy conditions Theorem 2, parameter p1 Model B less
certain value, consistent Prosser's experimental finding.
ln 10
consider typical setting h20; 10; 0:5; p2 Model B. Let n = 20, ff = ln
20
1)

1
:
5856

Model
RB.


setting

Model
RB


0:7686 r = 0:5(20
2 ln 20
values equivalent setting h20; 10; 0:5; p2 Model B. Inequalities (37)
100

fiExact Phase Transitions Random Constraint Satisfaction Problems
(38) also hard show equivalent setting Model RB corresponding
setting h20; 10; 0:5; p2 satisfies conditions Theorem 2, i.e., 102 > 20 p1 =
0:5 (202 ln1)10ln 2 0:35. experiments done Prosser (1996) show instances
generated p2 = 0:38 hard solve. maximum cost point
also agrees
well
ff
0:7686
r
1
:
5856
asymptotic phase transition point Model RB p = 1 e 1 e
0:38.
settings Model B previous work, also find equivalent
settings Model RB using method. Thus hardness solving settings
Model B equal solving equivalent settings Model RB. many
previous studies (Gent et al., 1999; Smith & Dyer, 1996; Prosser, 1996) know
instances generated phase transition many settings Model B hard
solve various kinds CSP algorithms. exist lot hard instances solve
Model RB.

6. Conclusions Future Work
lot experimental theoretical studies indicate phase transition solvability
important feature many decision problems computer science. shown
problems characterized control parameter way
space problem instances divided two regions: under-constrained region
almost problems many solutions, over-constrained region almost
problems solutions, sharp transition them. Another interesting
feature associated phase transition peak hardness solving
problem instances occurs transition region. Since instances generated
transition region appear hardest solve, commonly used benchmark
algorithms many NP-complete problems. unfortunately, except Hamiltonian
cycle problem (which NP-complete), decision problems exact results
existence location phase transition P class (Parkes, 1997),
e.g. random 2-SAT. problems interesting NP-complete problems
complexity theoretic point view solved polynomial time.
Hamiltonian cycle problem, using improved backtrack algorithm sophisticated
pruning techniques, Vandegriend Culberson (1998) recently found problem
instances phase transition region hard solve.
paper proposed new type random CSP model, Model RB,
revision standard Model B, asymptotic analysis model also
presented. results quite surprising. prove existence phase
transitions model also know location transition points exactly.
shown exist lot hard instances Model RB relating hardness
standard Model B. Since still lack studies exact derivation
phase transitions NP-complete problems, paper may provide new insight
field. However, discuss scaling behaviour Model RB
related issues paper. order get better understanding Model RB,
suggest future work include determining either empirically theoretically
whether hard instances persist reasonably high frequency number
variables increases. 1
1. Two anonymous referees suggest point.

101

fiXu & Li
Acknowledgments
research supported National 973 Project China Grant No. G1999032701.
would like thank Ian P. Gent, Barbara M. Smith, Peter van Beek anonymous
referees helpful comments suggestions.

References
Achlioptas, D., Kirousis, L., Kranakis, E., Krizanc, D., Molloy, M., & Stamatiou, Y. (1999).
Random constraint satisfaction: accurate picture. Constraints. submitted.
Also Proc. Third International Conference Principles Practice Constraint
Programming (CP 97), Springer-Verlag, pp. 107{120, 1997.
Bollobas, B. (1985). Random Graphs. Academic Press, New York.
Cheeseman, P., Kanefsky, B., & Taylor, W. (1991). really hard problems are.
Proceedings IJCAI-91, pp. 331{337.
Dechter, R. (1998). Constraint satisfaction. MIT Encyclopedia Cognitive Sciences
(MITECS). Online \ ftp://ftp.ics.uci.edu/pub/CSP-repository/papers/R68.ps".
Friedgut, E. (1999). Sharp thresholds graph properties k-sat problem. Journal
American Mathematical Society, 12, 1017{1054.
Frieze, A., & Suen, S. (1996). Analysis two simlpe heuristics random instance
k-sat. Journal Algorithms, 53, 469{486.
Frost, D., & Dechter, R. (1994). search best constraint satisfaction search.
Proceedings AAAI-94, pp. 301{306.
Gent, I., MacIntyre, E., Prosser, P., Smith, B., & Walsh, T. (1999). Random constraint satisfaction: Flaws structure. Constraints. submitted. Online \
http://www.cs.strath.edu.uk/~apes/apesreports.html".
Hogg, T. (1996). Refining phase transition combinatorial search. Artificial Intelligence, 81, 127{154.
Kirkpatrick, S., & Selman, B. (1994). Critical behavior satisfiability random
boolean expressions. Science, 264, 1297{1301.
Kirousis, L., Kranakis, E., Krizanc, D., & Stamatiou, Y. (1998). Approximating unsatisfiability threshold random formulas. Random Structures Algorithms, 12,
253{269.
Larrosa, J., & Meseguer, P. (1996). Phase transition max-csp. Proceedings ECAI-96,
pp. 190{194.
Mitchell, D., Selman, B., & Levesque, H. (1992). Hard easy distributions sat problems. Proceedings AAAI-92, pp. 459{465.
102

fiExact Phase Transitions Random Constraint Satisfaction Problems
Parkes, A. (1997). Clustering phase transition. Proceedings AAAI-97, pp.
340{345.
Prosser, P. (1996). empirical study phase transitions binary constraint satisfaction
problems. Artificial Intelligence, 81, 81{109.
Purdom, P. (1997). Backtracking random constraint satisfaction. Annals Mathematics Artificial Intelligence, 20, 393{410.
Smith, B. (1999). Constructing Asymptotic Phase Transition Random Binary Constraint Satisfaction Problems. Extended Abstract.
Smith, B., & Dyer, M. (1996). Locating phase transition binary constraint satisfaction
problems. Artificial Intelligence, 81, 155{181.
Vandegriend, B., & Culberson, J. (1998). Gn;m phase transition hard
hamiltonian cycle problem. Journal Artificial Intelligence Research, 9, 219{245.
Williams, C., & Hogg, T. (1994). Exploiting deep structure constraint problems.
Artificial Intelligence, 70, 73{117.

103

fiJournal Artificial Intelligence Research 12 (2000) 35-86

Submitted 5/99; published 2/00

Reasoning Interval Point-based
Disjunctive Metric Constraints Temporal Contexts
Federico Barber

FBARBER@DSIC.UPV.ES

Dpto. de Sistemas Informticos Computacin
Universidad Politcnica de Valencia
Camino de Vera s/n, 46022 Valencia, Spain

Abstract
introduce temporal model reasoning disjunctive metric constraints intervals
time points temporal contexts. temporal model composed labeled temporal algebra
reasoning algorithms. labeled temporal algebra defines labeled disjunctive metric pointbased constraints, disjunct input disjunctive constraint univocally associated
label. Reasoning algorithms manage labeled constraints, associated label lists, sets
mutually inconsistent disjuncts. algorithms guarantee consistency obtain minimal
network. Additionally, constraints organized hierarchy alternative temporal contexts.
Therefore, reason context-dependent disjunctive metric constraints intervals
points. Moreover, model able represent non-binary constraints, logical
dependencies disjuncts constraints handled. computational cost reasoning
algorithms exponential accordance underlying problem complexity, although
improvements proposed.

1. Introduction
Two main lines research commonly recognized temporal reasoning area. first
approach deals reasoning temporal constraints time-dependent entities. goal
determine consequences (T) follow set temporal constraints, "{TemporalConstraints}|=T?", determine whether set temporal constraints consistent,
assumptions properties temporal facts. second approach deals reasoning
change, events, actions causality. Here, goal obtain consequent state set
actions events performed initial state: "[Si, {A1, A2, ..., }]|= Sj?".
approaches constitute active fields research applications several artificial intelligence areas
reasoning change, scheduling, temporal planning, knowledge-based systems, natural
language understanding, etc. areas, time plays crucial role, problems dynamic
behavior, necessary represent reason temporal dimension information.
paper, deal first approaches. goal reasoning qualitative
quantitative constraints intervals time-points temporal contexts. Moreover, special
cases non-binary constraints also managed. tasks pending issues temporal
reasoning area, well important features facilitate modeling relevant problems area
(including planning, scheduling, causal hypothetical reasoning, etc.).
Several temporal reasoning models defined literature, clear trade-off
representation expressiveness complexity reasoning algorithms. Qualitative Point
Algebra (PA) (Vilain, Kautz & Van Beek, 1986) limited subset interval-based models. Interval

2000 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiREASONING INTERVAL POINT -BASED DISJUNCTIVE ETRIC CONSTRAINTS TEMPORAL CONTEXTS

Algebra (IA) introduced Allen (1983) represents symbolic (qualitative) constraints
intervals metric information, 'interval1 starts 2 seconds interval2 ', cannot
included. Metric (quantitative) point-based models (Dechter, Meiri & Pearl, 1991) include 'time
line' (metric) constraints, represent limited subset disjunctive
constraints intervals. Thus, constraints like 'interval1 {bef, aft} interval2 ' cannot
represented (Gerevini & Schubert, 1995).
efforts made integrate qualitative quantitative temporal information
points intervals (Kautz & Ladkin, 1991; Drakengren & Jonsson, 1997; etc.). Particularly, Meiri
(1996) introduces Qualitative Algebra (QA), interval represented three nodes (one
representing interval two representing extreme points) QA
represent qualitative metric constraints points intervals. Badaloni Berati (1996) define
Interval Distance Sub Algebra (IDSA), nodes intervals. intervals related
disjunctive 4-tuple-metric constraints ending time points {(I-i, I-j ), (I+i , I-j ), (I-i , I+j ), (I+i ,
I+j )}. Staab Hahn (1998) propose model reasoning qualitative metric boundaries
intervals. However, models cannot handle constraints interval durations,
identified earlier Allen (1983). Constraints 'interval1 lasts 2 seconds interval2'
require high-order expression (Dechter et al., 1991), duration primitive
integrated interval point constraints (Allen, 1983; Barber, 1993). Particularly, Barber (1993)
proposes two orthogonal networks relate constraints durations time points. Navarrete
(1997) Wetprasit Sattar (1998) relate disjunctive constraints durations time points,
limited subset interval constraints managed. recently, Pujari Sattar (1999)
propose framework reasoning points, intervals durations (PIDN). Here, variables
represent points intervals, constraints ordered set three intervals representing (Start,
End, Duration) subdomains. However, specialized algorithms management PIDN
constraints proposed.
relation complexity reasoning algorithms, consistency problem polynomial
PA (Vilain, Kautz & Van Beek, 1986) non-disjunctive metric networks (Dechter et al., 1991).
However, Vilain, Kautz Van Beek (1986) also showed determining consistency
general-case temporal network (i.e.: disjunctive qualitative metric constraints points,
intervals durations) NP-hard. Thus, previous qualitative quantitative models,
consistency problem tractable properties constraints, relationships
variable domains constraints, using restricted subsets constraints (Dechter et al., 1991;
Dechter, 1992; van Beek & Detcher, 1995; Wetprasit & Sattar, 1998; Jeavons et al., 1998; etc.).
instance, tractable subclasses IA identified Vilain, Kautz Van Beek (1986),
Nebel Burckert (1995), Drakengren Jonsson (1997), etc. Moreover, interesting results
obtained identification tractable subclasses QA. Specifically, Jonsson et al. (1999)
identified five maximal tractable subclasses qualitative point-interval algebra. However,
knowledge maximal tractable subclass PIDN model (maximal tractable subclass
qualitative quantitative point, interval duration constraints) still identified. case,
restricted tractable subclasses able obtain expressiveness full models,
problem reasoning disjunctive constraints points intervals remains NP-complete.
hand, qualitative metric temporal models manage certain types
non-binary constraints, important modeling problems (scheduling, causal
reasoning, etc.). instance, disjunctive assertions like (interval1 {bef, meets} interval2 ) (time36

fiBARBER

point3 [10 20] time-point4 ), temporal-causal relations like (interval1 {bef, meets}
interval2 ) (time-point3 [10 20] time-point4 ) incorporated models
(Meiri, 1996). Moreover, global consistency property introduced Dechter (1992)
important property temporal networks, since allows us obtain solutions backtrack-free
search (Dechter, 1992; Freuder, 1982). particular, global consistent network would allow us
handle conjunctive queries like (interval1 {bef, meets} interval2 ) (time-point3 [10 20]
time-point4 ) hold? without propagation query, required (van Beek, 1991).
Stergiou Koubarakis (1996), Jonsson Bckstrm (1996) dealt representation
temporal constraints means disjunctions linear constraints (linear inequalities
inequations) also named Disjunctive Linear Relations (DLRs). expressions unifying
approach manage disjunctive constraints points, intervals durations,
expressions subsume formalism temporal constraint reasoning (Jonsson & Bckstrm,
1998). Moreover, DLRs able represent disjunctions non-disjunctive metric constraints (x1 y1 c1 x2 -y2 c2 .... xn -yn cn ), xi yi time points, ci real numbers n1 (Stergiou
& Koubarakis, 1998). Obviously, satisfiability problem arbitrary set disjunctions
linear constraints NP-complete. Interesting tractable subclasses DLRs conditions
tractability identified (Cohen et al., 1996; Jonsson & Bckstrm, 1996; Stergiou &
Koubarakis, 1996). two main tractable subclasses Horn linear Ord-Horn linear
constraints (Stergiou & Koubarakis, 1996; Jonsson & Bckstrm, 1998). However, subclasses
subsume temporal algebras whose management also polynomial.
management set disjunctions linear constraints mainly based general methods
linear programming, although specific methods defined tractable subclasses
(Stergiou & Koubarakis, 1998; Cohen et al., 1996; etc.). Pujari Sattar outline (1999),
linear programming approach, though expressive, take advantage underlying
structures (e.g., domain constraints) temporal constraints. addition, usual concepts temporal
reasoning, composition intersection operations constraints, minimal constraints, kconsistency (Freuder, 1982), decomposability (Montanari , 1974), globally consistency (Dechter,
1992), etc., consequences adapted reasoning disjunctive linear constraints,
trivial issue.
spite expressive power previous models, problems (including planning,
scheduling, hypothetical reasoning, etc.) also need reason alternative contexts (situations,
intentions causal projections) know holds one (Dousson et al., 1993;
Gerevini & Schubert, 1995; Garcia & Laborie, 1996; Srivastava & Kambhampati, 1999). gives
rise need reason context-dependent constraints. feature supported usual
temporal models general way, described usual expressive power constraints
(Jeavons et al., 1999). Therefore, ad-hoc methods used reasoning temporal
contexts required.
issues addressed paper. describe temporal model, integrates
qualitative metric disjunctive constraints time-points intervals. temporal model
based time-points primitive, intervals represented means end timepoints. However, representation interval constraints seems imply kind relation
among endpoint constraints (Gerevini & Schubert, 1995). proposed temporal model introduces
labeled constraints, elemental constraint (disjunct) disjunctive point-based metric
constraint associated one unique label. way, point-based constraints related among
37

fiREASONING INTERVAL POINT -BASED DISJUNCTIVE ETRIC CONSTRAINTS TEMPORAL CONTEXTS

without using hyper-arcs. Therefore, metric symbolic constraints among intervals timepoints fully integrated, represented managed means labeled metric point-based
Temporal Constraint Network (TCN). Particularly, model proposed handles constraints
proposed QA (Meiri, 1996), IDSA (Badaloni & Berati, 1996), Distance Constraint Arrays
model (Staab & Hahn, 1998). Moreover, several added functionalities also provided:
Management alternative temporal contexts. input constraint associated
given context. hierarchy alternative temporal contexts defined,
constraints points intervals dependent context. knowledge,
features improve existing temporal models, contexts managed.
Reasoning algorithms labeled constraints based closure process. processes
guarantee consistency obtain minimal disjunctive context-dependent TCN. Additionally,
special type globally labeled-consistent TCN obtained. property allows us obtain
solutions backtrack-free search (Freuder, 1982).
Management special type non-binary constraints. Reasoning algorithms able
manage disjunctions disjunctive constraints. supposes extension disjunctions
non-disjunctive metric constraints proposed Stergiou Koubarakis (1998). Moreover,
given set disjunctive constraints, model handle logical relations among
disjunctions different constraints. Thus, express set atomic disjuncts
disjunctive constraints mutually disjunctive among them. Therefore, special type
and/or TCN managed conjunctive (and) TCN. Likewise, model also handle
special non-binary constraints representing implications among temporal constraints
identified Meiri (1996).
features, proposed temporal model suitable modeling problems
requirements appear. computational cost reasoning methods non-polynomial, given
complexity underlying problem. However, several improvements also proposed.
brief revision main temporal reasoning concepts presented Section 2. Section 3,
temporal algebra labeled point-based disjunctive metric constraints described. temporal
algebra introduces concept labeled constraints temporal operations. Reasoning
algorithms guaranteeing minimal (and consistent) TCN specified Section 4. using
model, integration interval point-based constraints management non-binary
constraints respectively described Sections 5 6. Association constraints temporal
contexts management context-dependent constraints detailed Section 7. Finally, Section
8 concludes.

2. Basic Temporal Concepts
Temporal reasoning deals reasoning temporal constraints. syntax semantics
constraints defined underlying temporal algebra, basis performing
reasoning processes. temporal algebra defined according following elements:
Temporal primitive (or variable) 'x ', usually time-points (ti ) intervals (Ii ).
Interpretation domain primitives xi . interpretation domain represents time line.
38

fiBARBER

Time points instantiated (ti D), temporal intervals modelled pairs
ending time points instantiated D: Ii = (Ii -, Ii +), Ii DxD, Ii -Ii +.
Temporal constraints primitives, constraint relates n primitives: c1,2..n (x1 ,
x2 , ..., xn ). particular cases, 'empty constraint' {} named Inconsistent-Constraint
'U' Universal-Constraint. Unary-constraints restrict interpretation domain
variables. usually used symbolic algebras, infinite domain
assumed. Binary-constraints temporal constraints two variables (xi cij xj ), nary-constraints represent temporal constraints among n variables. default, binary constraints
assumed paper. also qualitative (relative relation) quantitative
(metric relation) constraints, well disjunctive (cij set disjunctive basic constraints,
|cij |1) non-disjunctive constraints.
Operations constraints. Mainly, Temporal Composition (), Temporal Intersection
(), Temporal Union (), Temporal Inclusion ().
temporal problem specified set n variables X= {xi }, interpretation domain
finite set temporal constraints variables {(xi cij xj )}. temporal problem gives rise
Temporal Constraint Network (TCN) represented directed graph nodes
represent temporal primitives (xi ) labeled-directed edges represent binary constraints
(cij). Universal Constraint U usually represented graph, direct edge
(representing cij ) xi xj implies inverse one (representing cji ) xj xi .
According underlying Temporal Algebra, mainly IA-TCNs based Interval
Algebra (Allen, 1983), PA-TCNs based Point Algebra (Vilain et al., 1986), Metric-TCNs
based Metric Point Algebra (Dechter et al., 1991; Dean & McDermott, 1987). later
case, disjunctive metric point-based constraints give rise Temporal Constraint Satisfaction
Problem (TCSP) (Dechter et al., 1991).
Reasoning temporal constraints seen Constraint Satisfaction Problem (CSP).
instantiation variables X n-tuple (v1 , v2 , v3 , ...,vn ) / vi represents assignments
values {vi } variables {x }: (x1 =v1 , x2 =v2 , ...,xn =vn). (global) solution TCN consistent
instantiation variables X domains TCN constraints satisfied. value
v consistent (or feasible) value xi exists TCN solution xi =v. set
feasible values variable xi minimal domain variable. constraint (xi cij xj )
consistent exists solution (xi cij xj ) holds. constraint cij minimal iff consists
consistent elements (or feasible values) is, satisfied
interpretation TCN constraints. TCN minimal iff constraints minimal.
TCN consistent (or satisfiable ) iff least one solution. Freuder (1982) generalizes
notion consistency as: 'a network k-consistent iff (given instantiation k-1 variables
satisfying direct constraints among variables) exists least one instantiation
kth variable k values taken together satisfy constraints among k variables'.
consequences: (i) (k-1)-length paths network consistent, (ii) pair nodes,
exists interpretation satisfies (k-1)-length path them, (iii) sub-TCN
k-nodes consistent. particular cases, 1-consistency, 2-consistency 3-consistency called
node-consistency, arc-consistency path-consistency, respectively (Mackworth, 1977; Montanari,
1974).
39

fiREASONING INTERVAL POINT -BASED DISJUNCTIVE ETRIC CONSTRAINTS TEMPORAL CONTEXTS

Path-consistency common concept constraint networks. Montanari (1974)
Mackworth (1977), path k-length nodes (x1 , x2 , ..., xk , xj ) path-consistent iff
value v1 d1 vj dj (x1=v1 c1j xj=vj ) holds, exists sequence values v2 d2 , v3d3 ,
..., vk dk (v1 cl2 v2 ), (v2 c23 v3 ),...., (vk ck,j vj ) hold. TCN path-consistent iff
paths consistent. Moreover, Montanari (1974) proves ensure path-consistency suffices
check every 2-length path. Thus, path-consistency 3-consistency equivalent concepts.
Alternatively, Meiri (1996) outlines path k-length (xi , x1 , x2 , ...,xk , xj ) path-consistent iff cij
(ci1 c12 ... ckj ). However, definition disregards domain constraints, equivalent
former definition variable domains infinite TCN also node arc-consistent,
usual case symbolic algebras. metric algebras, path-consistency usually assumes node
arc-consistency. Therefore, taking account necessary test 2-length paths
assure path-consistency, TCN path-consistent iff cij ,cik ,ckjTCN, cij (cik ckj ).
condition gives rise usual path-consistent algorithm: Transitive Closure Algorithm
(TCA) imposes local 3-consistency sub-TCN 3 nodes, 2-length paths
become consistent paths (Mackworth, 1977; Montanari , 1974). TCA algorithm obtain
equivalent path-consistent TCN exists. Otherwise, fails.
cij ,cik ,ckj TCN: cij cij (cik ckj )
network strong k-consistent iff network j-consistent jk (Freuder, 1982). nconsistent TCN consistent TCN, strong n-consistent TCN minimal TCN. Alternatively,
Dechter (1992) introduces concepts local global consistency: partial instantiation
variables (x1 =v1 , x2 =v2 , ...,xk =vk ) / 1k<n locally consistent satisfies constraints among
variables. subTCN globally consistent locally consistent instantiation
variables subTCN extended consistent instantiation TCN. globally
consistent TCN one subTCNs globally consistent. Thus, TCN strong nconsistent iff globally consistent (Dechter, 1992).
first reasoning task TCN determine whether TCN consistent. TCN
consistent, obtain minimal-TCN, TCN solutions (by assuming discrete finite
model time), one solution, partial solution (consistent instantiation subset TCN
variables, part global solution), etc.
Deductive closure, propagation, one basic reasoning algorithms. closure process
deductive process TCN, new derived constraints deduced explicitly
asserted ones means composition () intersection () operations. Thus, process
determining consistency minimality TCN related sound complete closure
process (Vilain et al., 1986). Alternatively, CSP-based methods (with several heuristic search criteria)
also used guaranteeing consistency obtaining TCN solutions. paper, mainly
interested TCN closure processes.
Determining consistency general-case TCN NP-hard, Minimal TCNs
obtained polynomial number consistency processes (Vilain et al., 1986). Particularly, Dechter,
Meiri Pearl (1991) showed determining consistency obtaining minimal disjunctive
metric TCN achieved O(n3 le), n number TCN nodes, e number
explicitly asserted (input) constraints, l maximum number intervals input
constraint. However, specific levels k-consistency guarantee consistency obtain minimal
TCN, depending TCN topology underlying temporal algebra. example, path40

fiBARBER

consistency guarantees consistency obtains minimal non-disjunctive metric TCN (Dechter et
al., 1991). path-consistency TCA Algorithm O(n3) cost (Allen, 1983; Vilain, Kautz & Van
Beek, 1986). However, assuring path-consistency become complex task disjunctive metricTCNs variable domain large continuous. stated Dechter, Meiri Pearl
(1991), number intervals |cij cjk | upper bounded |cij |x|cjk |. Thus, total number
disjuncts (subintervals) path-consistent TCN might exponential number disjuncts per
constraints initial (input) TCN. Schwalb Dechter (1997) call fragmentation
problem, appear non-disjunctive metric TCNs. Thus, TCA algorithm O(n3
R3 ) disjunctive metric-TCNs time dense (Dechter et al., 1991), range R
maximum difference lowest highest number specified input constraints.

3. Labeled Temporal Algebra
main elements point-based disjunctive metric temporal algebra (Dechter et al., 1991):
Time-point (ti ) primitive variable. continuous variable domain (like Q ) usually
assumed.
temporal constraint cij U finite set l mutually exclusive subdomains (or
subintervals) D.
cij {[d-1 d+1 ], [d-2 d+2 ], ...., [d-k d+k ], ....., [d-l d+l ]} ,

d-k d+k d-k ,d+k D,

disjunctively restricts temporal distance two time-points, ti tj :
tj - ti {[d-1 d+1 ], [d-2 d+2 ], ....., [d-l d+l ]},
meaning (d-1 tj -ti d+1 ) .... (d-l tj -ti d+l ). Similar conditions applied open
(d-k d+k ) semi-open intervals (d-k d+k ], [d-k d+k ). Universal-Constraint U {(- +)}.
Unary constraints restrict associated subdomain time-point ti {[d-1 d+1 ], [d-2 d+2], .....,
[d-l d+l ]}. special time-point T0 usually included, represents 'the beginning
world' (usually, T0 =0). Thus, unary constraint ti represented binary one
ti T0 :
ti - T0 {[d-1 d+1 ], [d-2 d+2 ], ..... ,[d-l d+l ]} ti[d-1 , d+1 ] ti [d-2 , d+2 ] , ..., ti[d-l , d+l ]
and, default: ti , (T0 {[0 )} ti ).
algebra operations, mainly , , . (Meiri, 1996), given two temporal
constraints S={[dS-i , dS+i ]} T={[dT-j , dT +j ]},
= {dk / diS djT / dk = di +dj }.
is, [dS-i , dS+i ]S, [dT-j , dT +j ]T, T{[dS-i +d T-j , dS+i +d T+j ]}. Here, resulting subdomains
may pairwise disjoint. Therefore, additional processing may required
compute disjoint subdomain set.
= {dk / dkS dkT}. is, set-intersection subdomains.
= {dk / dkS dk T}, set-union subdomains.
ST = iff dk S, dk T.
41

fiREASONING INTERVAL POINT -BASED DISJUNCTIVE ETRIC CONSTRAINTS TEMPORAL CONTEXTS

basis point-based disjunctive metric temporal algebra operations,
introduce labeled point-based disjunctive metric temporal algebra, gives rise labeledTCN.
3.1 Labeled Constraints Inconsistent Label Sets
elemental constraint (ec) one disjunct disjunctive constraint. Similar terms atomic,
basic canonical constraints. However, lets use term due special structure labeled
elemental constraints introduced on. Thus, disjunctive constraint cij
considered disjunctive set l mutually exclusive elemental constraints {ecij.k }.
ecij.k = [d-ij.k d+ij.k ] / i,j,k d-ij.k d+ij.k
cij {ec ij.1 , ec ij.2 , ..., ec ij.l } U / k,p(1,..,l), kp, (ecij.k ec ij.p )=
Definition 1 (Labeled constraints). labeled elemental constraint lecij.k elemental constraint
ecij.k associated set labels {labelij.k}, labelij.k symbol. labeled constrain lc ij
disjunctive set labeled elemental constraints {lecij.k }. is,
lc ij {lecij.1 , lecij.2 , ..., lecij.l },
lecij.k (ec ij.k {labelij.k }), {labelij.k }{label1 , label2 , ..., labels } set symbols.

label labeled-TCN considered unique symbol. following cases
occur:
i)

input (or explicitly asserted) constraint lc ij one elemental constraint, is,
one disjunct, elemental constraint label 'R0 '. labeled UniversalConstraint {U{R0}}. given TCN, set elemental constraints labeled 'R0 '
common context. Thus, label R0 represents set elemental constraints
alternatives (disjuncts). elemental constraints labeled R0
hold since alternative disjuncts.

ii)

input constraint lc ij one elemental constraint, elemental constraint
lecij.k lc ij single exclusive label associated (|{labelij.k }|=1). Thus, label
TCN represents bi-univocally elemental constraint explicitly asserted
constraint.

iii) derived elemental constraint (obtained combining (lc) intersecting ( lc) two
labeled elemental constraints) set labels associated it. set labels obtained
label sets associated combined (or intersected) labeled elemental constraints.
detailed later specification operations (lc, lc) Section 3.2.
consequence, label set associated derived elemental constraint represents
conjunctive support-set explicitly asserted elemental constraints imply derived
elemental constraint.
Let's see simple example labeled constraints, introduced Dechter, Meiri
Pearl (1991).

42

fiBARBER

{([60 70]{R0})}

t4
{([40 50]{R3}) ([20 30]{R4})}

{([10 20]{R0})}

t3

T0
t2

{([60 ){R1}) ([30 40]{R2})}

T0

{([10 20]{R0} )}

t1

Figure 1: labeled point-based disjunctive metric TCN Example 1

Example 1: "John goes work either car [30'-40'], bus (at least 60'). Fred goes work
either car [20'-30'], carpool [40'-50']. Today John left home (t1)
7:10 7:20, Fred arrived (t4) work 8:00 8:10. also know
John arrived (t2) work 10'-20' Fred left home (t3)."
example, disjunctive labeled constraints Figure 1, T0 represents
initial time (7:00) granularity minutes. label 'R0 ' associated elemental
constraints belonging constraints one disjunct. constraints one,
mutually exclusive disjuncts, disjunct labeled exclusive label Rn (n>0). Thus,
label R0 associated "John left home 7:10 7:20", "Fred arrived work
8:00 8:10", "John arrived work 10'-20' Fred left home".
common context.
label R1 associated "John goes bus", R2 "John goes car".
label R3 associated "Fred goes carpool", R4 "Fred goes car".
Definition 2 (Inconsistent-Label-Sets). Inconsistent-Label-Set (I-L-Set) set labels {labeli }
represents set overall inconsistent elemental constraints. is, cannot
simultaneously hold.
Theorem 1. label set superset I-L-Set also I-L-Set. proof obvious.
set elemental constraints inconsistent, superset also inconsistent.
Definition 3. Elemental constraints {lecij.k} input disjunctive constraint lc ij pairwise disjoint.
Thus, 2-length set labels pair {lecij.k } added set I-L-Sets. is,
input constraint lc ij {lecij.1 , lecij.2 , ..., lecij.l }, lecij.k (ecij.k {labelij.k }) |{labelij.k }|=1:
k,p(1,..,l) / kp, I-L-Sets I-L-Sets ({labelij.k }{labelij.p })
example Figure 1, {R1 R2 } {R3 R4 } I-L-Sets. I-L-Sets existing labeled
TCN detected reasoning processes later detailed Section 4.

43

fiREASONING INTERVAL POINT -BASED DISJUNCTIVE ETRIC CONSTRAINTS TEMPORAL CONTEXTS

3.2 Operations Labeled Constraints
following points define main operations labeled constraints.
3.2.1 TEMPORAL INCLUSION LC
temporal inclusion operation lc take account inclusion temporal intervals
inclusion associated label sets:
lecij.k lc lecij.p = (ecij.k {labelij.k }) lc (ecij.p {labelij.p }) =def ecij.k ecij.p {labelij.k } {labelij.p }.
3.2.2 TEMPORAL UNION LC
Operation lc performs disjunctive temporal union labeled constraints set-union
elemental constraints. However, labeled elemental constraints whose associated labels I-L-Sets
rejected.
lc ij lc lcij =def lecij.k lc ij , lc [{lecij.k } lcij] ,
lc [{lecij.k } lcij ] = (ec ij.k {labelij.k }) lc lcij =def
Inconsistent({labelij.k }) : lcij
lecij.p lcij / lecij.p lc lecij.k : lcij
: ({lcij } {lecij.k }) - ({lecij.p }, lecij.plcij lecij.k lclecij.p )

(s1 )
(s2 ).

function Inconsistent({labelij.k}) returns true set {labelij.k } I-L-Set superset
existing I-L-Set (Theorem 1). Otherwise, returns false:
Inconsistent({labelij.k }) =def
{labels }Inconsistent-Label-Sets / {labels }{labelij.k } True Else False.
operation lc simplifies resulting constraint. Equal less-restricted elemental constraints
equal bigger associated label sets removed. instance:
{([10 30] {R1 R3 R5 R9}), ([40 40] {R6 R7})} lc {([10 20] {R1 R3}), ([40 40] {R6 R7 R8})} =
{([10 20] {R1 R3}), ([40 40] {R6 R7})}.
resulting constraint, ([10 30] {R1 R3 R5 R9}) ([40 40] {R6 R7 R8}) eliminated, examples
cases s1 s2 , respectively. is, ([10 20] {R1 R3}) lc ([10 30]{R1 R3 R5 R9}) ([40 40] {R6 R7})
lc ([40 40] {R6 R7 R8}). simplifications seem counter-intuitive. However, note label
set associated derived-labeled elemental constraint represents support set (composed
input elemental constraints) derived-labeled elemental constraint obtained. Thus,
minimal associated label set represented, reason efficiency. Moreover,
labels associated label set {labelij.k }, elemental constraint (ecij.k ) equal
restricted.
3.2.3 TEMPORAL COMPOSITION LC
Operation lc performs temporal composition labeled constraints. based operation
underlying disjunctive metric point-based algebra.
44

fiBARBER

lc ij lc lc jk =def lecij.plc ij , lecjk.q lc jk lc [ (ecij.p ecjk.q {labelij.p }{labeljk.q })].
instance: {([0 10] {R1}), ([20 30] {R2})} lc {([100 200] {R3}), ([300 400] {R4})} =
{([320 430] {R4 R2}), ([300 410] {R4 R1}), ([100 210] {R3 R1}), ([120 230] {R3 R2})}.
Note elemental constraints labeled derived constraint may pairwise disjoint.
However, labeled derived elemental constraints cannot simplified. related
fragmentation problem disjunctive metric algebra (Schwalb & Dechter, 1997).
derived-labeled elemental constraint associated label set. example,
(([320 430] {R4 R2}), ([300 410] {R4 R1})) cannot simplified ([300 430] {R4 R2 R1}) since
subinterval depends different set labels (that is, different support-set elemental
constraints). label set {R4 R2 } becomes I-L-Set, ([320 430] {R4 R2}) removed.
hand, [300 410] becomes inconsistent interval implied time points,
{R4 R1 } asserted I-L-Set.
3.2.4 TEMPORAL INTERSECTION LC
Operation lc performs temporal intersection labeled constraints based operation
.
lc ij lc lcij =def lecij.k lc ij , lecij.p lcij , lc [lecij.k lc lecij.p ]
where, lecij.k lc lecij.p =def
ec ij.k ecij.p = {}
;The Inconsistent-Constraint returned.
Else [(ecij.k ecij.p ) ({labelij.k }{labelij.p })]
example:
{([0 10] {R1}), ([20 25] {R2})} lc {([0 30] {R3}), ([40 50] {R4})} = {([20 25] {R3 R2}), ([0 10] {R3 R1})}
operations lc lc, label set {labelij.r} associated derived labeled-elemental
constraint (ecij.r) obtained set-union labels associated combined (lc) intersected
( lc) labeled-elemental constraints. Therefore, {labelij.r} represents support set (composed input
elemental constraints) implies derived elemental constraint (ecij.r).
Definition 4. set I-L-Sets complete represents inconsistent sets TCN elemental
constraints. set I-L-Sets sound I-L-Set represents inconsistent set elemental
constraints.
Theorem 2. Assuming complete sound set I-L-Sets, labeled elemental constraint
consistent iff associated label set I-L-Set. proof trivial, since label
set associated labeled elemental constraint represents support-set.
Theorem 3. Assuming complete sound set I-L-Sets, inconsistent labeled elemental
constraint obtained operations lc lc.
Proof: operations lc lc use operation lc obtain results. operation lc
rejects labeled elemental constraints whose associated labels I-L-Sets. Thus, elemental
constraints derived operations lc lc consistent (Theorem 2).
45

fiREASONING INTERVAL POINT -BASED DISJUNCTIVE ETRIC CONSTRAINTS TEMPORAL CONTEXTS

3.3 Distributive Property lc lc Disjunctive Labeled Constraints
Operations distributive (i.e.: distributes ) non-disjunctive metric TCN,
property hold disjunctive metric constraints. Dechter, Meiri Pearl (1991) show
following example. Given disjunctive metric constraints:
a= {[0 1], [10 20]},
have:

b= {[25 50]},

c= {[0 30], [40 50]},

(a (b c) = {[25 31], [35 70]}

(a b) (a c) = {[25 70]}.

Thus, clearly (a (b c) (a b) (a c). However, distributive property holds
operations lc lc labeled TCN.
Theorem 4. using labeled constraints I-L-Sets, lc distributes lc.
Proof: Lets consider labeled constraints lc , lc j lc k . Thus,
(lc lc lc j ) lc (lc lc lc k )
expressed, according definition operation lc, as:
(lecp lc , lecq lc j , lc[(lecp lc lecq )]) lc (lecrlc , lecs lc k , lc[(lecr lc lecs)]) =
lecp lc , lecq lc j , lecrlc , lecs lc k (lc[(lecp lc lecq)] lc lc[(lecr lc lecs )])
which, according definition lc, expressed as:
lecp lc , lecq lc j , lecrlc , lecs lc k (lc[(lecp lc lecq ) lc (lecr lc lecs )])

(e1)

expression, lecp lecr elemental constraints same-labeled constraint lc .
However, set-union label sets associated pair elemental constraints (input
derived) labeled constraint I-L-Set (Definition 3). is, lecp lecr, {labelp }{labelr}
I-L-Set. Thus, lecp lecr, label set associated (lecp lc lecq ) lc (lecr lc lecs ) I-LSet. consequence, (lecp lc lecq ) lc (lecr lc lecs ) rejected operation lc. is,
lecp lc , lecq lc j , lecrlc , lecs lc k / lecplecr (lc[(lecp lc lecq ) lc (lecr lc lecs )]) = .
Thus, expression (e1) results:
lecp lc , lecq lc j , lecslc k (lc [(lecp lc lecq ) lc (lecp lc lecs )]).
expression, lc clearly distributes lc elemental constraints (i.e.: non-disjunctive
constraints). Therefore:
lecp lc , lecq lc j , lecslc k (lc [(lecp lc (lecq lc lecs ))]) =
lecp lc , lc [lecp lc (lecqlc j , lecs lc k , lc [lecq lc lecs ])] = lc lc (lc j lc lc k ).
is, lc distributes lc labeled constraints.

instance, following previous example:
a= {[0 1] {R1}, [10 20] {R2}},

b= {[25 50] {R0}},

c= {[0 30] {R3}, [40 50] {R4}}

{R1 R2 }, {R3 R4 } I-L-Sets. Thus, have:
(a lc (b lc c) = {[0 1] {R1}, [10 20] {R2}} lc ({[25 50] {R0}} lc {[0 30] {R3}, [40 50] {R4}}) =
{[0 1] {R1}, [10 20] {R2}}lc {[25 30] {R3 R0}, [40 50] {R4 R0}} =
46

fiBARBER

{[25 31] {R1 R3 R0}, [40 51] {R1 R4 R0}, [35 50] {R3 R2 R0}, [50 70] {R4 R2 R0}}.
Also,
(a lc b) lc (a lc c) =
({[0 1] {R1}, [10 20] {R2}} lc {[25 50] {R0}}) lc
({[0 1] {R1}, [10 20] {R2}} lc {[0 30] {R3}, [40 50] {R4}}) =
{[25 51] {R1 R0}, [35 70] {R2 R0}} lc {[0 31] {R1 R3}, [40 51] {R1 R4} [10 50] {R2 R3}, [50 70] {R2 R4}} =
lc ([25 31] {R1 R3 R0}, [40 51] {R1 R4 R0}, [25 50] {R1 R2 R3 R0},
[50 51] {R1 R2 R4 R0}, [40 51] {R1 R2 R4 R0}, [35 50] {R3 R2 R0}, [50 70] {R4 R2 R0}).
However, {R1 R2 }, {R3 R4 } I-L-Sets. Thus, ([25 50] {R1 R2 R3 R0}, [50 51] {R1 R2 R4 R0}, [40 51] {R1
R2 R4 R0}) removed operation lc. Therefore,
(a lc b) lc (a lc c) = {[25 31] {R1 R3 R0}, [40 51] {R1 R4 R0}, [35 50] {R3 R2 R0}, [50 70] {R4 R2 R0}}.
is, (a lc (b lc c) = (a lc b) lc (a lc c).

4. Reasoning Algorithms Labeled Constraints
Several algorithms reasoning disjunctive constraints applied management
labeled temporal constraints, using lc, lc, lc lc operations. instance, wellknown Transitive Closure Algorithm, general closure algorithms (Dechter, 1992; Dechter et al.,
1991; van Beek & Dechter, 1997), CSP-based approaches, etc. However, Montanari (1974) shows
composition operation distributes intersection, path-consistent TCN also
minimal TCN. Theorem 4, lc distributes lc. Thus, application pathconsistent algorithm proposed-labeled TCN obtain minimal TCN. Thus, TCA
algorithm could used closure process labeled constraints, similar way Allen
(1983) uses it. However, incremental reasoning process proposed basis incremental
path-consistent algorithm non-disjunctive metric constraints described Barber (1993).
incremental reasoning process useful temporal constraints initially known
successively deduced independent process; instance, integrated planning
scheduling system (Garrido et al., 1999). proposed reasoning algorithm similar TCA
algorithm. However, updating closure processes performed new input constraint.
Thus, new input constraint updated closured previously minimal TCN (Figure 9).
Therefore, propagation modified constraints closure process needed. Moreover,
proposed reasoning algorithms obtain complete sound set I-L-Sets.
specification reasoning processes described Section 4.1. properties
processes described later Section 4.2.
4.1 Updating Process
Given previous labeled-TCN, composed set nodes {ni }, set labeled constraints {lc ij }
among them, set I-L-Sets, updating process new c ij nodes ni nj
constraint detailed Figure 2.
47

fiREASONING INTERVAL POINT -BASED DISJUNCTIVE ETRIC CONSTRAINTS TEMPORAL CONTEXTS

Updating (ni cij nj)
;cij {ecij., ecij.2 , ..., ecij.l }, disjunctive metric constraint.
lc'ij Put-Labels (cij ), ;An exclusive label associated elemental constraint
ecij.k cij
Consistency-Test (lc ij , lc'ij ) ;Consistency test lc'ij. previously existing
constraint n nj lcij . Moreover, new I-L-Sets
detected.
(*Inconsistent Constraint*)
Return (false)
Else (*Consistent Constraint*)
lc ij lc ij lc lc'ij ,
lc ji Inverselc (lc ij ),
Closure (ni lc ij nj ), ;Closure algorithm updated constraint.
Return (true)
End-If
End-Updating
Figure 2: Updating process labeled constraints
function Put-Labels(cij ) returns labeled-constraint lcij {lecij.1 , lecij.2 , ..., lecij.l },
associating exclusive label elemental constraint cij. one disjunct cij ,
label unique elemental constraint {R0 }. Otherwise, pair labels lcij added
set I-L-Sets, since elemental constraints cij pairwise disjoint (Definition 3). using
Inverse function non-labeled constraints, Inverse lc function is:
Inverselc ({(ec ij.k {labelij.k })}) =def {(Inverse (ec ij.k ) {labelij.k })}
described updating process performed time one new input constraint cij
asserted previous TCN. Thus, initial TCN nodes, constraints, I-L-Sets
assumed (Figure 9). new input constraint (cij ), TCN incrementally updated
closured. is, cij consistent (Consistency-Test function), constraint cij added
TCN, closure process (Closure function) propagates effects TCN, new TCN
obtained. new updating process performed new TCN, successively.
4.1.1. CONSISTENCY-TEST FUNCTION
Consistency-Test function (Figure 3) based operation lc. new input constraint lc'ij
nodes ni nj consistent temporally intersects previously existing constraint
lc ij nodes. Moreover, Consistency-Test function detect new I-L-Sets:
i)

new constraint lc'ij consistent existing constraint lc ij , two elemental
constraints ecij.p lc'ij , ecij.klc ij intersect (ecij.k ecij.p =), label set
{labelij.k }{labelij.p } I-L-Set added current set I-L-Sets.

ii)

existing elemental constraint nodes ni nj (lecij.klc ij) intersect
new constraint lc'ij , {labelij.k } I-L-Set added current set
I-L-Sets.

48

fiBARBER

Consistency-Test (lc ij , lcij ) =
(lc ij lc lcij ) = {}
Return (False)
Else
lecij.k lc ij , lecij.p lc'ij / lecij.k lc lecij.p ={}
I-L-Sets I-L-Sets ({labelij.k }{labelij.p }),
lecij.k lc ij / lecij.k lc lcij = {}
I-L-Sets I-L-Sets {labelij.k },
End-If
Return (True)
End- Consistency-Test
Figure 3: Consistency-Test function
example,
Consistency-Test ({([0 10] {R1}), ([20 25] {R2}), ([100 110] {Ra})},
{([0 30] {R3}), ([40 50] {R4}), ([-50 -40] {Rb})}) = True
since
{{([0 10] {R1}), ([20 25] {R2}), ([100 110] {Ra})} lc {([0 30] {R3}), ([40 50] {R4}), ([-50 -40] {Rb})} =
{([20 25] {R3 R2}), ([0 10] {R3 R1})} {}.
function, label sets {R4 R2 }, {R4 R1 } {Ra} detected I-L-Sets
added current set I-L-Sets, since:
{[20 25] {R2}} lc {[40 50] {R4}}={},
{[0 10] {R1})} lc {[40 50] {R4})}={},
{([100 110] {Ra})} lc {([0 30] {R3}), ([40 50] {R4}), ([-50 -40] {Rb})}={}.
Note {Rb } need detected I-L-Set, since label Rb included
final constraint {([20 25] {R3 R2}), ([0 10] {R3 R1 })} added TCN.
superset I-L-Set also I-L-Set (Theorem 1). Moreover, note {R4 R2}, {R4 R1 }
need added set I-L-Sets, since label R4 included final constraint.
Therefore, following simplifications also performed time new I-L-Set added
current set I-L-Sets. simplifications modify results reasoning processes,
minimize size set I-L-Sets improve management efficiency.
i)

new I-L-Set superset existing I-L-Set added set I-L-Sets.

ii)

existing I-L-Set superset new I-L-Set, existing I-L-Set removed.

iii) new I-L-Set contains label lc'ij , appear labeled constraint
(lc ij lc lc'ij ) added TCN, added set I-L-Sets.
Lets see example updating consistency-test processes. Lets take labeled-TCN
results Example 1 following constraints updated closured:

49

fiREASONING INTERVAL POINT -BASED DISJUNCTIVE ETRIC CONSTRAINTS TEMPORAL CONTEXTS

Set Inconsistent-Label-Sets: {{R1 R 2}, {R3 R 4}}
{([60 70] {R0})}

t4
{([40 50] {R3})]
([20 30] {R4})}
{([-10 20] {R3 R0})
([10 40] {R4 R0})}

t3
t1

{([-10 20] {R3 R0})
([10 40] {R4 R0})}

T0
{([40 60] {R2 R0})
([70 ) {R1 R0})}

{([40 ) {R1 R3 R0})
([20 ) {R1 R4 R0})
([-10 30] {R2 R4 R0})
([10 50] {R2 R3 R0})}

{([10 30] {R3 R0})
([30 50] {R4 R0})]}

t2

{((- 0] {R1 R0})
([0 30] {R2 R0})}

{([60 ) {R1})
([30 40] {R2})}

T0
{([10 20] {R0})]}

t4
t1

Figure 4: resulting labeled-TCN Figure 1 updating (t3 {[10 20]} t2 )
(t1 {[60 )R1, [30 40] R2 } t2 ), (t3 {[40 50] R3 , [20 30] R4 } t4), (T0 {[10 20]R0 } t1 ), (T0 {[60 70]R0 } t4 ).
resulting labeled-TCN shown Figure 4 set I-L-Set {{R1 R2 }, {R3 R4 }}.
Now, update (t3 {[10 20]R0 } t2 ). previously existing constraint t3 t2 (Figure 4):
{([40 ){R1 R3 R0 }) ([20 ){R1 R4 R0}), ([-10 30] {R2 R4 R0}) ([10 50] {R2 R3 R0})}
Consistency-Test function performs:
{[10 20] {R0}} lc {([40 ){R1 R3 R0 }) ([20 ){R1 R4 R0}), ([-10 30] {R2 R4 R0}) ([10 50] {R2 R3 R0})} =
{[20 20] {R1 R4 R0}, [10 20] {R2 R0} []{R1 R3 R0}} {}

(e1)

Thus, (t2-t3{[10 20] {R0}}) consistent. Moreover, {R1 R3 R0 } detected I-L-Set.
elemental constraints associated {R1 R3 R0 } inconsistent set disjuncts cannot hold
simultaneously. is:
"If today John left home 7:10 7:20 (R0 ), Fred arrived work 8:00
8:10 (R0 ) John arrived work 10'-20' Fred left home (R0 ),
impossible John gone bus (R 1 ) Fred gone carpool (R 3 )."
set I-L-Sets obtained reasoning process considered special derived
constraints, express inconsistency set input elemental constraints. instance,
I-L-Set {R0 R1 R3 } represents (Figure 1):
( (T0 [10 20] T1 ) (T3 [10 20] T2 ) (T0 [60 70] T4 ) (T3 [40 50] T4 ) (T1 [60 ) T2 )).
expression non-binary constraint. type constraints could represented
disjunctive linear constraint, Jonsson Bckstrm (1996), Stergiou Koubarakis (1996)
show. However, input elemental constraints represented derived constraints able
derive inconsistent sets input elemental constraints. model, done means
label sets associated labeled elemental constraints.

50

fiBARBER

4.2 Closure Process
closure process (Figure 5) applied time new input constraint (lc'i j ) updated,
effects lc'ij propagated TCN.
Closure (ni lc ij nj)
(* First loop: Closure n n j n k *)
nk TCN / lc jk {U{R0}}:
lc ik lc ik lc (lc ij lc lc jk ), lc ki Inverse(lc ik)
(* Second loop: Closure n j ni nl *)
nl TCN / lc il {U{R0}}:
lc jl lc jl lc (Inverse(lc ij ) lc lc il ), lc lj Inverse(lc jl )
(* Third loop: Closure nl ni nj nk *)1
nl , nk TCN / lc li {U{R0}}, lc jk {U{R0}}:
lc lk lc lk lc (lc li lc lc ij lc lc jk ), lc kl Inverse(lc lk )
End-Closure
Figure 5: closure process labeled constraints

(3)
nl.1

nl.i

lc il.i

(2)

ni

nk.1
(1)

lcij

nj

nk.i
lcjk.i

nk.t

nl.s

Figure 6: Loops Closure Process
closure process three loops (Figure 6). loops process obtains:

1

i)

Derived constraints lc ik ni node nk , nk previously connected nj
(edge 1 Figure 6).

ii)

Derived constraints lc lj nj node nl , nl previously connected ni
(edge 2 Figure 6).

loop could simplified as:
(*n l n n k*): n l, n k TCN / lc li {U{R0}}, lc j k {U{R0}}:

lc lk lc lk lc (lc li lc lc ik),

(*n l nj n k*): n l, n k TCN / lc li {U{R0}}, lc j k {U{R0}}: lc lk lc lk lc (lc lj lc lcj k)
since lc ik (or lc lj ) already closured first (or second loop). Moreover, efficiency third loop
improved modified constraints first (or second loop) considered.

51

fiREASONING INTERVAL POINT -BASED DISJUNCTIVE ETRIC CONSTRAINTS TEMPORAL CONTEXTS

Set Inconsistent-Label-Sets: {{R1 R2 }, {R3 R4}, {R1 R3 R0}}
{([60 70]{R2 R0}) ([70 70]{R4 R1 R0})}

t4
{([60 60]{R4 R1 R0})
([40 60]{R4 R2 R0})
([50 60]{R3 R2 R0})}

t1 {([10 30]{R4 R2 R0})
([10 20]{R3 R2 R0})
([40 40]{R4 R1 R0})}

{([40 50]{R3 R2 R0})
([20 30]{R4 R2 R0})
([20 20]{R4 R1 R0})}

t3

T0

{([40 50]{R2 R3 R0})
([40 60]{R2 R4 R0})
([70 70]{R1 R4 R0})}

{([10 20]{R2 R0}) ([20 20] {R4 R1 R0})}

{([50 50]{R4 R1 R0})
([20 30]{R3 R2 R0})
([30 50]{R4 R2 R0})}

t2

{([0 0] {R1 R4 R0})
([20 30]{R2 R3 R0})
([0 20]{R2 R4 R0})}

{([30 40]{R2 R0})
([60 60]{R1 R4 R0})}

T0
{([10 20]{ R2 R0}) ([10 10] {R4 R1 R0})}

t4
t1

Figure 7: Labeled-Minimal TCN Example 1
iii) Derived constraints lc lk pair nodes nl nk , nl nk previously
connected ni nj respectively (edge 3 Figure 6).
Lets see previous Example 1 represented Figure 1 Figure 4, consistent
constraint (expression e1):
(t3 {[20 20] {R1 R4 R0}, [10 20] {R2 R0}} t2 )
closured. first loop closure process, have:
lc 30 lc 30 lc ({[20 20] {R1 R4 R0}, [10 20] {R2 R0}} lc lc 20 =
{[-30 -10] {R3 R0 } [-50 -30] {R4 R 0 }} lc
({[20 20] {R1 R4 R0}, [10 20] {R2 R0}} lc {[-60 40] {R2 R0} (- -70] {R1 R0}}) =
{[-30 -10] {R3 R0}} [-50 -30] {R4 R0}} lc
{[-40 -20] {R1 R2 R4 R0}, (- -50] {R1 R4 R0} [-50 20] {R2 R0} (- -50] {R1 R2 R0}}.
However, {{R1 R2 }, {R3 R4 } {R0 R1 R3 }} I-L-Sets. labeled elemental constraints whose
associated label set superset I-L-Sets derived (Theorem 3). Thus:
lc 30 {[-30 -10] {R3 R0}} [-50 -30] {R4 R0}} lc {(- -50] {R1 R4 R0} [-50 20] {R2 R0} }=
{(-30 -20] {R2 R3 R0} [-50 50] {R4 R1 R0} [-50 -30] {R4 R2 R0}}.
Similarly,
lc 31 lc 31 lc ({[20 20] {R1 R4 R0} [10 20] {R2 R0}} lc lc 21 =
{[-20 -10] {R3 R2 R0 } [-40 -40] {R4 R1 R0} [-30 -10] {R4 R2 R0}}
lc 34 lc 34 lc ({[20 20] {R1 R4 R0}, [10 20] {R2 R0}} lc lc 24 =
{[40 50] {R3 R2 R0 } [20 30] {R4 R2 R0} [20 20] {R4 R1 R0}}.
second third loops, final labeled-TCN obtained (Figure 7). final set I-LSets {{R1 R2 }, {R3 R4 } {R0 R1 R3 }}. sets represent sets mutually inconsistent inputelemental constraints exist TCN Figure 1.
52

fiBARBER

4.3 Properties Reasoning Algorithms
section, main properties proposed reasoning algorithms described.
Theorem 5. proposed updating closure processes (Sections 4.1 4.2) guarantee
consistent TCN applied previous minimal (and consistent) TCN.
Proof: updating constraint lcij asserted TCN consistent previous minimal
constraint lc ij (Consistency-Test function).

Theorem 6. proposed closure algorithm obtains path-consistent TCN, applied
previous minimal TCN.
Proof: detailed Barber (1993) non-disjunctive TCNs applied labeled
TCNs. have:
i)

derived constraint exist pair nodes path combines
asserted constraint lc ij .

ii)

closure process computes derived constraint pair nodes (nl , nk )
become connected path across closured constraint lc ij . Lets assume existing path
nodes nx1 , ny1 includes lc ij :
nx1 , nx2 , nx3 , ........, nx, (nj lc ij nj ), ny ......, ny2 , ny1
derived constraint nx1 ny1 computed. However, minimal
constraint (nx1 , ni ) (nj , ny1 ) already exist previous minimal
TCN. consequence, derived constraint (nx1 , ny1 ) computed third loop
process.

iii) previous TCN minimal, possible derived constraints exist
pair nodes (nl, nk ) already computed constraint lclk derived nodes
proposed closure process. third loop, process obtains:
lclk = lc lk lc (lc li lc lc ij lc lc jk ).
Lets suppose exists another path (nl , nk ) across updated lc ij constraint: (nl ,
np , ni , nj , nq , nk ). path computes another derived constraint (nl , nk ):
lc''lk = lc lk lc (lc lp lc lc pi lc lc ij lc lc jq lc lc qk ).
However, since previous TCN minimal, previously existing minimal constraints
lc li lc jk imply (lc lp lc lc pi ) (lc jq lc lc qk), respectively. is, lc li lc(lc lp lc lc pi )
lc jk lc(lc jq lc lc qk ) Thus, lc''lk also implicitly implied lclk (lclk lclc''lk ). Here,
assumed associative property lc, obvious definition.
iv) Derived constraints obtained closure process need closured
previous TCN minimal. is, constraint TCN would become restricted
derived constraints also closured. Let suppose lc lk modified third loop
closure process:
lclk = lc lk lc (lc li lc lc ij lc lc jk )
propagated (nl , nk , np ) subTCN (Figure 8). Thus, following
derived constraints obtained:
53

fiREASONING INTERVAL POINT -BASED DISJUNCTIVE ETRIC CONSTRAINTS TEMPORAL CONTEXTS

lclp = lc lp lc (lclk lc lc kp )

lcpq = lc pq lc (lc pl lc lclk ).

constraint lclp , have,
lclp = lc lp lc (lclk lc lc kp ) = lc lp lc ((lc lk lc (lc li lc lc ij lc lc jk )) lc lc kp ).
However, since lc distributes lc,
lclp = lc lp lc ((lc lk lc lc kp ) lc (lc li lc lc ij lc lc jk lc lc kp )).
Since previous TCN minimal, minimal constraints lc pi lc pj previously
exist, lclp lc(lc lk lc lc kp ) lc jp lc(lc jk lc lc kp ). Thus,
lclp lc lc lp lc (lc li lc lc ij lc lc jp ).
However, third loop closure process, following derived constraint
computed:
lc''lp = lc lp lc (lc li lc lc ij lc lc jp ).
Thus, lclp already represented obtained constraint lc''lp (that is, lc''lp lc lc'lp ).
similar way,
lc''pq = lc pq lc (lc pi lc lc ij lc lc jq )
also obtained proposed closure process, lc''pq lc lc'pq .
Therefore, derived constraint (any combinable path across lc ij ) pair nodes
TCN computed, closure process obtains path-consistent TCN.

np

lclp

lcpk

lclk

nl
lclj

lc ij

ni

nk
nj

lcjk

Figure 8: lc lk also propagated lc lp lc pq
Theorem 7. proposed reasoning processes obtain minimal TCN, previous TCN
minimal TCN.
Proof: Montanari (1974) shows composition distributes intersection (i.e.:
distributes ), path-consistent TCN also minimal TCN). case nondisjunctive metric TCNs (Dechter et al., 1991). case, lc distributes lc (Theorem 4)
closure process obtains path consistent TCN (Theorem 6). Therefore, proposed reasoning
processes also obtain minimal TCN.

54

fiBARBER

New input
constraint

INITIAL
TCN
nodes,
constraints, I-L-Sets

Input Constraint
( ni lcij nj )
(ni lcij nj ) consistent
Reasoning Process: Updating + Closure processes
Consistency-Test: Consistent TCN
Closure Process: Path-Consistent TCN.
Distributive Property ( lc lc): Minimal
New consistent minimal TCN
New complete sound set I-L-Sets

Figure 9: incremental reasoning process
Theorem 8. updating process, reasoning algorithms obtain complete sound new set
I-L-Sets (Definition 4), applied previous minimal TCN previous sound
complete set I-L-Sets.
Proof:
i) new set I-L-Sets complete. consistency test updated constraint lc'ij obtains
possible new I-L-Sets appear lc'ij added TCN, except I-L-Sets
related mutual exclusion disjuncts lc'ij (which determined
Put-Label function):
a) new I-L-Sets appear label lc'ij participate. Otherwise,
would detected previous updating process, since previous set
I-L-Sets assumed complete. Thus, label lcij always participate
new I-L-Set appears lcij updated.
b) new I-L-Sets (in label lcij participates) detected consistency
test lcij. Let's assume new undetected I-L-Set exists {Rk , R1 , R2 , ....., Rp }
new elemental constraint eck{Rk}lc'ij takes part. Thus, elemental
constraints associated {R1 , R2 , ....., Rp } compute derived elemental constraint ecx
nodes ni nj :
(ecx {R1, R2, ....., Rp})

/

(ecx {R1, R2, ....., Rp}) lc (eck{Rk}) =

elemental constraint ecx already represented previously existing constraint lc ij

55

fiREASONING INTERVAL POINT -BASED DISJUNCTIVE ETRIC CONSTRAINTS TEMPORAL CONTEXTS

ni nj since previous TCN minimal2 . Thus, eck ecx=, I-LSet {Rk , R1 , R2 , ....., Rp } detected consistency test lcij . conclusion, new
inconsistent sets elemental constraints lc'ij participates detected
new I-L-Sets exist. Therefore, new set I-L-Sets complete previous set
I-L-Sets complete.
ii) new set I-L-Sets sound. new I-L-Sets obtained represent inconsistent sets
elemental constraints. trivial, given consistency test function.
conclusion, proposed reasoning algorithms obtain minimal (and consistent) TCN
applied previous minimal-TCN (Figure 9). Therefore, reasoning algorithms guarantee
TCN consistency obtain minimal TCN complete sound set I-L-Sets new
input assertion.
4.4 Global Labeled-Consistency
minimal (binary) disjunctive network, every subnetwork size two globally consistent
(Dechter, 1992). Therefore, local consistent instantiation subset two variables
extended full consistent instantiation. However, assure local consistent instantiation
subset two variables overall consistent, partial instantiation propagated
whole TCN (van Beek, 1991). Thus, assembling TCN solution become costly
propagation process disjunctive TCNs, even though minimal TCN used. proposed
reasoning processes maintain complete sound set I-L-Sets (Theorem 8). Thus, deduce
locally consistent set elemental constraints overall consistent means label sets
associated labeled elemental constraints set I-L-Sets. Specifically, deduce
whether locally consistent instantiation k variables (1<k<n) overall consistent. Lets see
following example, based previous one proposed Dechter, Meiri Pearl (1991):
Example 2: "Dave goes walking work [25 50]. John goes work either car
[10 30'], bus [45 60]. Fred goes work either car [15' 20'],
carpool [35' 40'], walking [55 60]. Today, left
home 6:50 7:50 (at t1, t2 t3 time-points), arrived
work time (t4 ) 8:00."
Here, following labeled disjunctive constraints where, T0 represents initial time
(6:50) granularity minutes:
t1 - T0 {[0 60]R0 },
t4 - 1 {[25 50]R0 },

2 - T0 {[0 60]R0 },

3 - T0 {[0 60]R0 },

4 2 {[10 30]R1 , [45 60]R2 },

4 - T0 {[0 70]R0 },

4 3 {[15 20]R3 , [35 40]R4 , [55 60]R5 }.

minimal TCN Example 2 represented Figure 10. Here, binary constraints
time-point T0 represent unary constraints restrict interpretation domains variables
(t1 , t2 , t3 , t4 ). Obviously, minimal TCN globally consistent TCN. instance,

2

elemental constraint ec x already represented explicit way, means another elemental constraint ecy
(ecy Tec x, {labely }{R1, R2, ....., Rp}) due simplification process performed operation lc . cases,
ec kec x=, ec kecy =.

56

fiBARBER

instantiations {(t1 =0), (t2=0), (t3=0)} consistent existing constraints involved among (T0 ,
t1 , t2 , t3 ), partial solution cannot extended overall TCN.

{[0 45]}

t1
{[25 50]}

{[-35 35]}
{[0 55]}

T0
{[-35 40}]

t3

{[15 20] [35 40] [55 60]}

t4

{[-50 45]}
{[10 30] [45 60]}

{[0 60]}

t2

{[25 70]}

Figure 10: Minimal TCN Example 2
Lets consider TCN labeled constraints. reasons simplicity, denote
labeled constraints among (T0 , t1 , t2 , t3 ):
(T0 {[5 45]{R0 R5}, [0 45]{R0 R4}, [0 45]{R0 R3}} 1 ),
(T0 {[0 25]{R2 R0}, [5 60]{R1 R0 R4}, [25 60]{R1 R0 R5}, [0 60]{R1 R0 R3}} 2 ),
(T0 {[25 55]{R0 R2 R3}, [0 15] {R0 R5}, [0 35]{R0 R1 R4}, [5 55]{R0 R1 R3}, [5 35]{R0 R2 R4}} 3 ),
(t 1 {([-5 35]{R0 R2}, [-40 5] {R0 R1}} 2 ),
(t 1 {[-15 15]{R0 R4}, [-35 -5]{R0 R3}, [5 35]{R0 R5}} 3 ),
(t 2 {[5 30] {R1 R0 R4}, [-45 -25]{R2 R0 R3}, [25 50]{R1 R0 R5}, [-15 10]{R1 R0 R3}, [-25 -5]{R2 R0 R4}, [-5 15]{R2 R0 R5}} t3 ).

set I-L-Sets {{R1 R2 } {R3 R4 } {R3 R5 } {R4 R5}}. labeled TCN set
I-L-Sets, deduce instantiations {(t1 =0), (t2 =0), (t3 =0)} overall consistent.
instantiations locally consistent labeled constraints subTCN (T0 , t1 , t2 , t3 ):
label sets associated possible simultaneous fulfillment
(T0 {[0 0]} 1 ), (T0 {[0 0]} 2 ) (T0 {[0 0]} 3 )

I-L-Sets. is, label sets Cartesian product
{{R0 R4 } {R0 R3 }} {{R2 R0 } {R1 R0 R3 }} {{R0 R5 } {R0 R1 R4 }}

I-L-Sets. Thus, set I-L-Sets used deduce consistency set labeled elemental
constraints obtain globally consistent labeled-TCN.
Theorem 9. Lets assume labeled-TCN n nodes (and corresponding complete sound set
I-L-Sets) local set k (1k( n2 )) labeled elemental constraints TCN, one
pair nodes:
{lec1 , lec2 ,....., leck } {(ec 1 {label1 }), (ec2 {label2 }), ..., (ec k {labelk })}.

57

fiREASONING INTERVAL POINT -BASED DISJUNCTIVE ETRIC CONSTRAINTS TEMPORAL CONTEXTS

local set labeled elemental constraints {lec1 , lec2 , ... , leck }is overall consistent iff setunion associated label sets (i=1,k {labeli }) I-L-Set.
Proof: label set (i=1,k {labeli }) support-set simultaneous fulfillment {lec1 , lec2 ,
--- , leck }. Moreover, set I-L-Sets complete sound respect overall TCN (Theorem
8), label set set I-L-Set overall consistent. Therefore (Theorem 2),
(i=1,k {labeli }) {lec1 , lec2 , ... , leck } overall consistent iff i=1,k {labeli } I-L-Set.
Definition 5 (Labeled-consistency3 ): Lets assume labeled-TCN n nodes (and corresponding
complete set I-L-Sets) set k (1k(n2 )) constraints, one pair
nodes TCN:
{c ij } / 1in, 1jn, ij.
set constraints {c ij } labeled-consistent respect nodes involved
constraints, iff:
i)

constraint cij , exists elemental labeled constraint elc ij.x (ni , nj )
TCN elc ij.x satisfies cij . is: cij , elc ij.xlc ij / c ij ecij.x .

ii)

resulting set union label sets associated elemental labeled constraints
(which satisfy {c ij }) I-L-Set: U cij{label ij.x} I-L-Set. Note
condition Theorem 9.

Theorem 10. Lets assume labeled-TCN n nodes (and corresponding complete set I-LSets) set k (1k( n2 )) constraints, one pair nodes
TCN:
{c ij } / 1in, 1jn, ij.
set constraints {c ij } overall consistent iff {c ij } labeled-consistent respect
nodes involved constraints {c ij }.
Proof: proof trivial according Definition 5 Theorem 9. set
constraints {c ij } consistent iff exists local set elemental constraints TCN {elc ij.x}
makes {c ij} labeled-consistent (Definition 5). Thus, local set {elc ij.x} consistent (Theorem
9), {c ij } also consistent.
instance, determine whether pair constraints c' ij c'kl hold simultaneously
(that is, overall consistent) if:
elc ij.xlc ij / c' ij ecij.x elc kl.yckl / c'kl eckl.y {labelij.x}{labelkl.y }
I-L-Set.
Moreover, local instantiation k-1 (1<kn) variables {t1 =v1 , t2 =v2 , ..., t(k-1)=v(k-1)}
extended global solution if:
elc 10.xlc 10 / v1ec10.x,...... , elc (k-1)0.ylc (k-1)0 / v(k-1)ec10.x,
lc i0 constraint ni T0 , {label10.x}{label20.y } .... {label(k-1)0.y }is
I-L-Set.
3

need introduce concept labeled-consistency since different concept consistency concept.

58

fiBARBER

instance, Example 2 Figure 10, partial instantiation {(t1 =0), (t2 =5), (t3 =5)}
consistent. have:
([0 45]{R0 R3})lc10 / 0[0 45],

([0 60]{R1 R0 R3})lc20 / 5[0 60],

([5 55]{R0 R1 R3})lc30 / 5[5 55],

{R0 R3 }{R0 R1 R3}{R0 R1 R3 }={R0 R1 R3 } IL-Set. Thus, partial solution
extended global solution. instance, {(t1 =0), (t2 =5), (t3 =5), (t4 =25)}.
Therefore, labeled-TCN considered globally labeled-consistent TCN. is,
basis concepts introduced Dechter (1992):
Definition 6. (Local Labeled-consistency): partial instantiation variables (1k<n) {t1 =v1 , t2 =v2 ,
..., tk =vk } local labeled-consistent labeled-consistent respect (T0 , t1 , t2 , ..., tk ) nodes.
also holds k=n.
Definition 7. (Global Labeled-consistency): labeled sub-TCN (with global set I-L-Sets)
global labeled-consistent partial instantiation variables sub-TCN, local
labeled-consistent, extended overall TCN. globally labeled-consistent TCN one
sub-TCNs globally labeled-consistent.
Theorem 11. new assertion, proposed reasoning processes obtain globally labeledconsistent TCN, applied previous minimal TCN previous sound complete
set I-L-Sets.
Proof: proof trivial according previous definitions (Definition 6 Definition 7)
properties reasoning processes (Theorem 7 Theorem 8). partial instantiation
subTCN, labeled-consistent respect nodes involved partial
instantiation, overall consistent (Theorem 10).
Similar expressions made k-labeled-consistency strong k-labeled-consistency
basis concepts provided Freuder (1982). Therefore, set I-L-Sets labeled-TCN
provides useful way assure whether local instantiation variables part global
solution. Moreover, Freuder (1982) shows strong k-consistent TCN, consistent instantiations
variables subnetwork size k found backtrack-free manner variable
ordering. also consequence decomposability (Montanari, 1974; Dechter et al., 1991)
globally consistency (Dechter, 1992) properties. Obviously, feature also holds labeled
TCNs.
4.5 Analysis Temporal Complexity
Lets analyze computational cost proposed reasoning processes. processes are,
basically, incremental path-consistent algorithm (Barber, 1993). updating process
new input constraint TCN n nodes, computational cost updating closure
processes bounded 'n2 (O(lc) + O(lc))'. proposed reasoning process, path-consistent
algorithm obtains minimal disjunctive metric TCN. possible due management
labeled constraints, associated label sets, I-L-Sets. Thus, complexity reasoning processes
mainly due (instead complex closure process) management complex data structures
(labeled constraints, associated label sets, I-L-Sets). is, complexity proposed

59

fiREASONING INTERVAL POINT -BASED DISJUNCTIVE ETRIC CONSTRAINTS TEMPORAL CONTEXTS

reasoning processes mainly due complexity operations lc lc.
computational cost lc lc depends number elemental constraints labeled
constraints, size associated label sets, size I-L-Sets previous minimal labeled
TCN. Let 'n' number nodes, 'l' maximum number disjuncts (or labels) input
constraints, 'e' number updated input constraints previous TCN. maximum
number labels TCN l*e, since disjunct updated input labeled constraint
own, unequivocal label. Moreover, I-L-Set maximum one label input
labeled constraint lc ij , since: (i) elemental constraints lc ij pairwise disjoint, pair
labels lc ij added set I-L-Sets, (ii) superset existing I-L-Set also
I-L-Set. Thus, maximum number labels I-L-Set e. Furthermore, label I-LSet different input labeled constraint. e input labeled constraints,
input labeled constraint maximum l labels. Thus, maximum number I-L-Sets q-length
(1qe) (( qe ) lq ).
Therefore, number i-length (1ie) I-L-Sets i=1,e (( ei ) li ) = O(2e le). However,
superset I-L-Set already known inconsistent, supersets stored set
I-L-Sets. Thus, number I-L-Set bounded O(le). Additionally, also e*( l2 ) I-LSets 2-length, since l disjuncts updated constraint mutually exclusive among them.
Similarly, maximum number associated label sets also bounded O(le), one
maximum e labels. Thus, number elemental constraints (or labeled subintervals)
labeled constraint bound O(le), since elemental constraint labeled constraint
associated label set.
According parameters, computational cost updating process bounded
O(n2 l3e). recovery process constraints constant cost, since minimal-TCN always
maintained. computational cost proposed algorithms agreed computational cost
inherent problem management disjunctive metric constraints (Dechter, 1991). fact,
closure process could considered integrated management le alternative nondisjunctive TCNs disjunctive TCN split, shown Dechter, Meiri Pearl
(1991). noted l bounded typical problems like scheduling,
usually l 2 (Garrido et al., 1999), restricting domain size (range granularity) metric
algebras. hand, several improvements made described processes.
example, efficient management label sets direct influence efficiency
reasoning processes. Thus, label set (for instance, {R3 R5 R8 }) considered
unidimensional array bits, binary representation integer number (for instance
(23 +25 +28 )). Therefore, associated label set represented number set I-L-Sets
becomes set numbers. Matching set-union processes label sets operations lc lc
efficiently performed means operations integer numbers constant cost.
Therefore, computational cost bounded O(n2 l2e).
alternative implementations study. Two different approaches exist temporal
constraint management (Brusoni et al., 1997; Yampratoom, Allen, 1993; Barber, 1993). first
approach maintain closured TCN recomputing TCN new input constraint
making derived constraints explicit. Here, queries answered constant time, although
implies high spatial cost. second approach explicitly represent input constraints,
spatial requirements minimum. However, computation needed query time
consistency new input constraint tested. proposed reasoning methods hold
60

fiBARBER

first approach, seems appropriate problems queries TCN
usual tasks updating processes.
addition, proposed reasoning algorithms obtain sound complete set I-L-Sets
globally labeled-consistent TCN. Regrettably, assembling solution labeled TCN, although
backtrack free, also costly due exponential number I-L-Sets. However, features offer
capability representing managing special types non-binary disjunctive constraints (later
detailed Section 6).
reasoning algorithms query processes non-closured TCN, well CSP
approaches defined basis labeled temporal algebra described. Less expensive
algorithms applied labeled constraints using specified operations lc, lc, lc
lc. instance, TCA algorithm applied Allen (1983), k-consistency algorithms
like described (Cooper, 1990; Freuder, 1978). Moreover, minimal TCN labeled
constraints obtained without enforcing global consistency; example, applying naive
backtracking algorithm described Dechter, Meiri Pearl (1991), O(n3 le).

5. Interval-Based Constraints Labeled Point-Based Constraints
integration quantitative qualitative information goal several temporal
models, described Section 1. intervals represented means ending
points Ii + Ii -, integration constraints intervals points seems require kind nonbinary constraints time-points (Gerevini & Schubert, 1995; Schwalb & Dechter, 1997;
Drakengren & Jonsson, 1997). section, proposed temporal model applied order
integrate interval point-based constraints. Constraints intervals managed means
constraints ending points intervals I-L-Sets. Likewise, metric information also added
interval constraints expressive way integrating qualitative quantitative
constraints obtained.
5.1 Symbolic Interval-Based Constraints
Symbolic constraints intervals express qualitative temporal relation two intervals.
symbolic constraint disjunctive subset 13 elemental constraints, mutually
exclusive among (Allen, 1983). example, following constraint
I1 {ec 1 , ec2 } I2 ,

ec1 , ec2 {b, m, o, d, s, f, e, bi, mi, oi, di, si, fi},

really means 'I1 [ (ec1 ec2 ) (ec1 ec2 ) ] I2', since ec 1 ec 2 mutually exclusive, one
one elemental constraint hold. reasons simplicity, consider two disjuncts
symbolic constraint. However, expressions easily extended managing
2 13 disjuncts. expression expressed as:
I1 [ (ec1 ec2 ) (ec1 ec2 ) ] I2
I1 [ (ec1 ec1 ) (ec 2 ec2 ) (ec1 ec2 ) (ec1 ec2 ) ] I2
way, have:

61

(e2).

fiREASONING INTERVAL POINT -BASED DISJUNCTIVE ETRIC CONSTRAINTS TEMPORAL CONTEXTS

i)

constraints [I1 (ec1 ec1 ) I2 ] [I1 (ec2 ec2 ) 2 ] expressed disjunctive
metric constraints pairs time-points,

ii)

constraints [I1 (ec 1 ec2 ) I2 ] [I1 (ec1 ec2 ) I2 ] expressed mutual
exclusion among associated labels point-based constraints. is, set
I-L-Sets.

present simple example illustrate conclusions. instance, (I1 {before after} I2 )
expressed means constraints among time points I1 -, I1 +, I2 - I2 +, as:
[I1 {b a} I2 ] (I1 + {(0 ){Rb1}} I2 -) (I1 - {(- 0){Ra1}} I2 +).
Thus, intervals represented means ending points Ii + Ii -, interval-based
constraint gives rise disjunctive constraints different pairs time points (i.e.: non-binary
constraints). non-binary constraints represented I-L-Sets. Thus, according
expression (e2),
[I1 {b a} I2] [I1 (b b) I2 ] [I1 (a a) I2 ] [I1 (b a) I2 ] [I1 (b a) I2 ],
have:
I1 I2 I1 + {(0 ){Rb1}} I2 -,
I1 I2
I1 + {(- 0]{Rb2}} I2 -,

I1 I2 I1 - {(- 0){Ra1}} I2 +,
I1 I2 I1 - {[0 ){Ra2}} I2 +.

Therefore, [I1 {b a} 2 ] expressed as:
[I1 + {(0 ){Rb1} (- 0]{Rb2}} I2 -] [I1 - {(- 0){Ra1} [0 ){Ra2}} I2 +]
[ (I1 + {(0 ){Rb1}} I2 -) (I1 - {(- 0){Ra1}} I2 +) ]
[ (I1 + {(- 0]{Rb2}} I2 -) (I1 - {[0 ){Ra2}} I2 +) ],
equivalent (by using labels associated elemental constraint):
[I1 + {(0 ){Rb1} (- 0]{Rb2}} I2 -] [I1 - {(- 0){Ra1} [0 ){Ra2}} I2 +]
{Rb1 Ra1},{Rb2 Ra2} I-L-Sets, one one disjunctive symbolic constraint
holds.
Thus, symbolic constraints intervals represented means of: (i) set
disjunctive metric constraints time-points, (ii) set I-L-Sets. Table 1,
equivalent metric constraints interval ending time points elemental interval-based
constraint detailed. According table, following steps allow us represent disjunctive
symbolic constraints intervals means disjunctive metric constraints interval
ending points I-L-Sets:
i)

interval represented means ending points Ii +, Ii-. default, (I - {(0, ){R0}}
Ii +) holds.

ii)

symbolic constraint two intervals (Ii cij Ij) composed disjunctive set
(from 1 13) elemental symbolic constraints cij ={ecij.k }{b, m, o, d, s, f, e, bi, mi, oi, di,
si, fi}.

iii) elemental symbolic constraint ec{b, m, o, d, s, f, e, bi, mi, oi, di, si, fi} represented
62

fiBARBER

conjunctive set disjunctive point-based metric constraints (fourth column Table
1). conjunctive set point-based constraints expresses fulfillment nonfulfillment (ec ec) elemental symbolic constraint ec.
iv) disjunctive set cij ={ecij.k } elemental symbolic constraints Ii Ij represented
by:


conjunctive set disjunctive point-based metric constraints time-points
Ii +, Ii -, Ij+ I-j . conjunctive set composed constraints fourth column
Table 1 elemental constraint {ecij.k }.



set I-L-Sets expresses logical relation among elemental symbolic
constraints {ec ij.k }. is, 'one one elemental symbolic constraint {ecij.k}
hold':
iv.a) one elemental constraint {ecij.k } hold. condition
need represented since different sets point-based constraints
correspond fulfillment different elemental symbolic constraints (second
column Table 1) already mutually exclusive.
iv.b)

One elemental symbolic constraints {ecij.k } hold. Let
label sets, label set corresponds point-based constraints
related non-fulfillment elemental symbolic constraint {ec ij.k }
(third column Table 1). Thus, Cartesian product among label sets
set I-L-Sets.

instance, I1 {b di} I2 represented as:
(I1 - { (0 ){R0}} I1 +), (I2 - { (0 ) {R0}} I2 +),

I1 {b b} I2 (I1 + {(0 ){Rb1} (- 0]{Rb2}} I2 -),
I1 {m m} I2 (I1 + {[0 0] {Rm1} (0 ){Rm2} (- 0){Rm3}} I2 -),
I1 {s s} I2 (I1 - {[0 0] {Rs1} (0 ){Rs3} (- 0){Rs4}} I2 -) (I1 + {(0 ){Rs2} (- 0]{Rs5}} I2 +),
I1 {di di} I2 I2 {d d} I1 (I2 - {(- 0){Rd1} [0 ){Rd3}} I1 -) (I2 + {(0 ){Rd2} (- 0]{Rd4}} I1 +).

Moreover, one symbolic constraints {b, m, s, di} hold. Thus (according Point
iv.b method), Cartesian product associated labels related non-fulfillment
elemental symbolic constraints {b, m, s, di}. is:
{{Rb2 }{Rm2 , Rm3 }{Rs3 , Rs4 , Rs5 }{Rd3 , Rd4 }

explicitly included set I-L-Sets.
applying method, qualitative interval-based constraints fully integrated
proposed labeled point-based constraints. case, interpretation domain time-points {Ii Ii +} restricted three values ({D}={(-, 0), [0 0], (0 )}), that, l=3. Therefore,
computational cost reasoning algorithms bounded O(n2 3 2e).
illustrate proposed method, lets show typical example symbolic interval-based
constraints (Figure 11.a), given Allen (1983). example shows interval-based
constraints represented managed means disjunctive metric point-based constraints
minimal IA-TCN obtained.
63

fiREASONING INTERVAL POINT -BASED DISJUNCTIVE ETRIC CONSTRAINTS TEMPORAL CONTEXTS

Ii ecij.k Ij

Ii ecij.k Ij

Ii ecij.k Ij

Ii (ecij.k ec
ij.k) Ij

Ii Ij

Ii + {(0 ){Rb1}} Ij -

Ii + {(- 0]{Rb2}} Ij -

Ii + {(0 ){Rb1} (- 0]{Rb2}} Ij -

Ii meets Ij

Ii + {[0 0]{Rm1}} Ij -

Ii + {(0 ){Rm2} (- 0){Rm3}} Ij -

Ii + {[0 0]{Rm1} (0 ){Rm2} (- 0){Rm3}} Ij -

Ii Ij

Ii - {(- 0){Rd1}} Ij -

(Ii - {[0 ){Rd3}} Ij -)

Ii - {(- 0){Rd1} [0 ){Rd3}} Ij -

Ii + {(0 ){Rd2}} Ij +
Ii starts Ij

Ii + {[0 0]{Rf1}} Ij +
-

Ii {(- 0){Rf2}} Ij

-




Ii + {(0 ){Rd2} (- 0]{Rd4}} Ij +
Ii - {[0 0]{Rs1} (0 ){Rs3} (- 0){Rs4}} Ij Ii + {(0 ){Rs2} (- 0]{Rs5}} Ij +

(Ii + {(- 0]{Rs5}} Ij +)

(Ii + {(0 ){Rf3} (- 0){Rf4}} Ij +)

Ii + {[0 0]{Rf1} (0 ){Rf3} (- 0){Rf4}} Ij +

(Ii {[0 ){Rf5}} Ij )
-

Ii - {(- 0){Rf2} [0 ) {Rf5}} Ij -

-

(Ii + {[0 ){Ro4}} Ij -)

+
Ii overlaps Ij Ii {(- 0){Ro1}} Ij

Ii equal Ij

(Ii + {(- 0]{Rd4}} Ij +)

(Ii - {(0 ){Rs3} (- 0){Rs4}} Ij -)

Ii - {[0 0]{Rs1}} Ij Ii + {(0 ){Rs2}} Ij +

Ii finishes Ij



Ii + {(- 0){Ro1} [0 ){Ro4}} Ij -

Ii + {(0 ){Ro2}} Ij +



(Ii + {(- 0]{Ro5}} Ij +)

Ii + {(0 ){Ro2} (- 0]{Ro5}} Ij +

Ii - {(0 ){Ro3}} Ij -



(Ii - {(- 0]{Ro6}} Ij -)

Ii - {(0 ){Ro3} (- 0]{Ro6}} Ij -

Ii + {[0 0]{Re1}} Ij +

(Ii + {(0 ){Re3} (- 0){Re4}} Ij +)

Ii + {(0 ){Re3} [0 0]{Re1} (- 0){Re4}} Ij +

Ii - {[0 0]{Re2}} Ij -

(Ii - {(0 ){Re5} (- 0){Re6}} Ij -)

Ii - {(0 ){Re5} [0 0]{Re2} (- 0){Re6}} Ij -

Table 1: Interval-based constraints equivalent disjunctive metric constraints
interval ending points (Cells second fourth columns conjunctive set constraints)

Symbolic
Constraint
(IA {d di} IB)



(IB {d di} IC)



(ID {m s} IA)



(ID {o} IB)



(ID {m s} IC)



Disjunctive Metric Constraint I+ I-

Inconsistent-Label-Sets

IA - {(- 0){R1} [0 ){R3}} IBIA + {(0 ){R2} (- 0]{R4}} IB+
IB- {(- 0){R5} [0 ){R7}} IA IB+ {(0 ) {R6} (- 0]{R8}} IA +

{R4 R8 } {R3 R8 }
{R4 R7 } {R3 R7 }

IB- {(- 0){R9} [0 ){R11}} ICIB+ {(0 ) {R10} (- 0]{R12}} IC+
IC- {(- 0){R13} [0 ){R15}} IBIC+ {(0 ) {R14} (- 0]{R16}} IB+
+
ID {[0 0]{R17} (0 ){R18} (- 0){R19}} IA ID- {[0 0]{R20} (0 ){R22} (- 0){R23}} IA ID+ {(0 ){R21} (- 0]{R24}} IA +
ID+ {(- 0){R0}} IBID+ {(0 ){R0}} IB+
ID- {(0 ){R0}} IBID+ {[0 0]{R25} (0 ){R26 (- 0){R27}} ICID- {[0 0]{R28} (0 ){R30} (- 0){R31}} ICID+ {(0 ){R29} (- 0]{R32}} IC+

{R12 R16 } {R11 R16 }
{R12 R15 } {R11 R15 }
{R19 R24 } {R18 R24 } {R19 R23 }
{R18 R23 } {R19 R22 } {R18 R22 }

{R27 R32 } {R26 R32 } {R27 R31 }
{R26 R31 } {R27 R30 } {R26 R30 }

Table 2: Symbolic constraints Figure 11.a means disjunctive metric
constraints I+, I-

64

fiBARBER

Figure 11.a represents path-consistent IA-TCN, inconsistent values constraints
(Allen, 1983). Table 2, interval-based symbolic constraints example,
corresponding disjunctive metric constraints ending time -points (Ii +, Ii -)
corresponding set I-L-Sets (according Table 1). Moreover, also have:
(IA -{(0 ){R0}}IA +), (IB-{(0 ){R0}}IB+), (IC-{(0 ){R0}}IC+ ) (ID- {(0 ){R0}}ID+).

metric constraints among ending time-points intervals updated according
proposed methods Section 4, labeled minimal TCN Table 3 obtained. associated
labels elemental constraint (disjunct) constraints included reasons brevity.




{s,m}


{s,m}

{o}

{d, di}



B

{d,di}

{d, oi, f, e, fi,
si, s, , di}

{o}

{d, di}

B

{d,di}

{s,m}

{s,m}
{d, di, s, si, e}

C

a) Path-Consistent IA-TCN

C

b) Minimal IA-TCN

Figure 11: Path-Consistent equivalent Minimal IA-TCN

IA+
IA+

IA-

IB+

{(- 0)}

{(0 ),
(- 0)}
{(0 )}

IA-

{(0 )}

IB+

{(- 0), {(- 0)}
(0 )}

IB-

{(0 )}

{(0 ),
(- 0)}

IB-

{(0 )}

{[0 0],
(0 )}

{(- 0),
(0 )}
{(- 0)}

{(0 )}

{(0 )}

IC-

ID+

ID-

{(- 0)} {(- )} {(- 0)} {(- 0)} {(- 0)}
{(0 )}

{(- 0), {[0 0], {(- 0),
[0 0],
(0 )}
[0 0]}
(0 )}
{(- 0), {(- 0)} {(- 0)} {(- 0)}
(0 )}
{(0 )}

IC+ {(- )} {(- 0)} {(- 0), {(- 0)}
(0 )}
IC
{(0 )} {(- 0), {(0 )} {(- 0),
[0 0],
(0 )}
(0 )}
ID+ {(0 )} {(- 0), {(0 )} {(- 0)}
[0 0]}
ID-

IC+

{(0 )}

{(- 0),
(0 )}

{(0 )}

{(- 0)}

{(- 0)} {(- 0)} {(- 0)}
{(0 )}

{(0 ),
[0 0]}

{(0 )}

{(- 0),
[0 0]}

{(0 )}

{[0 0],
(0 )}

{(- 0),
[0 0]}
{(- 0)}

{(0 )}

Table 3: minimal metric point-based TCN IA-TCN Figure 11.a
65

fiREASONING INTERVAL POINT -BASED DISJUNCTIVE ETRIC CONSTRAINTS TEMPORAL CONTEXTS

Allen (1983) remarks symbolic constraint (IA {f fi} IC) cannot hold given existing
constraints IA, IB, IC ID. labeled point-based TCN, (IA {f fi} IC) represented
set constraints among ending points IA IC. Moreover, labels associated
labeled elemental constraint allow us determine whether set elemental constraints
different pairs time-points part global solution (Theorem 10). Thus, deduce
whether (IA {f fi} IC) hold point-based TCN.
existing constraints ending time-points IC IA, associated labelsets are:
IC+ {(- ){R25 R30 R29 R17 R22 R21 R0){R27 R28 R29 R19 R20 R21 R0},
(- 0){R27 R28 R29 R17 R22 R21 R9 R10 R15 R16 R1 R2 R7 R0 R8},
(0 ){R25 R30 R29 R19 R20 R21 R11 R12 R13 R14 R3 R4 R5 R0 R6}} IA+
IC-

{(0 ){R27 R28 R29 R17 R22 R21 R9 R10 R15 R16 R1 R2 R7 R8 R0},
[0 0] {R25 R30 R29 R17 R22 R21 R0}{R27 R28 R29 R19 R20 R21 R0},
(- 0){R25 R30 R29 R19 R20 R21 R11 R12 R13 R14 R3 R4 R5 R6 R0}} IA-

Let's ask disjunct (IA {f fi} IC):
i) constraint (IA {f} IC) implies (IC+ {[0 0]} IA+) (IC- {(- 0)} IA-). According
Theorem 10, constraints hold iff set-union label sets associated (IC+ [0 0]
IA+) (IC- (- 0) IA-) I-L-Set. two possibilities:
i.1) {R25 R30 R29 R17 R22 R21 R0 } {R25 R30 R29 R19 R20 R21 R11 R12 R13 R14 R3 R4 R5 R6 R0 } =
{R6 R5 R4 R3 R20 R19 R25 R30 R29 R17 R22 R21 R11 R12 R13 R14 R0 },
i.2)

{R27 R28 R29 R19 R20 R21 R0 } {R25 R30 R29 R19 R20 R21 R11 R12 R13 R14 R3 R4 R5 R6 R0 } =
{R14 R13 R12 R11 R30 R25 R27 R28 R29 R19 R20 R21 R3 R4 R5 R0 R6 }.

However, label sets (i.1, i.2) I-L-Sets: instance, {R19 R22 } {R27 R30 } I-LSets (Table 2) subsets i.1 i.2, respectively. Thus, (IA {f} IC) hold.
ii) constraint (IA {fi} IC) implies (IC+ {[0 0]} IA+) (IC- { (0 )} IA-). Similarly:
ii.1) {R25 R30 R29 R17 R22 R21 R0 } {R27 R28 R29 R17 R22 R21 R9 R10 R15 R16 R1 R2 R7 R8 R0 } =
{R16 R15 R10 R9 R28 R27 R25 R30 R29 R17 R22 R21 R1 R2 R7 R0 R8 }.

label set I-L-Set. instance, {R30 R27 } I-L-Set. Also,
ii.2) {R27 R28 R29 R19 R20 R21 R0 } {R27 R28 R29 R17 R22 R21 R9 R10 R15 R16 R1 R2 R7 R8 R0 } =
{R8 R7 R2 R1 R22 R17 R27 R28 R29 R19 R20 R21 R9 R10 R15 R16 R0 }.

label sets (ii.1, ii.2) also I-L-Sets. instance, {R 30 R27} {R19 R22 } I-LSets. Thus, (IA {fi} IC) hold either.
conclusion, symbolic constraint (IA {f fi} IC) cannot hold globally labeled-consistent
point-based TCN. conclusion could also obtained minimal IA-TCN (Figure 11.b).
Additionally, (IA {f fi} IC) implies (IA+ [0 0] IC+). is, constraint (IA+ [0 0]
IC+) holds, associated constraints label sets {R25 R30 R29 R17 R22 R21 R0 }
{R27 R28 R29 R19 R20 R21 R0 } also hold. one label sets implies (IC - {[0 0]} IA-).
is: (IA+ [0 0] IC+) (IC- {[0 0]} IA-). Thus, way (IA+ [0 0] IC+) hold (IA
{e} IC) holds. relations detailed Section 6.
66

fiBARBER

5.2 Metric Constraints Intervals
Metric constraints intervals also managed described temporal model.
general point view, metric information added elemental interval-based constraint
standard way (Table 4). metric constraints interval boundaries (Table 4) similar
ones proposed Staab Hahn (1998).
IA Symbolic
Elemental
Constraints

IA Metric Elemental Constraints
cij {[dm1 dM1 ], [dm2 dM2 ], ..... [dmn dMn ]}
c'ij {[dm 1 dM1 ], [dm 2 dM2 ], ..... [dm n dMn ]}
Ii

Ii Ij

Ii (before cij ) Ij

Ii meets Ij

Ii (meets c ij ) Ij

Ii Ij

Ii (cij c'ij ) Ij

Ii starts Ij

Ii (starts c ij ) Ij

Ii finishes Ij

Ii (finishes cij ) j

C

ij

Ij

Ii
Cij

Ij

Ii

C' ij

C
ij

Ij
Ii
C
ij

Ij
Ii

C
ij

Ij
Ii

Ii overlaps Ij

Ii (overlaps cij ) Ij

Cij

Ij

Ii

Ii equal Ij

Ii (cij equal c'ij ) Ij

C
ij

C'

ij

Ij

Table 4: Metric interval constraints interval boundaries
Obviously, metric constraints Table 4 managed proposed model, means
metric constraints interval ending points. Thus, symbolic constraints Interval Algebra
extended way metric domain. However, since interval represented means
ending time-points, flexible metric constraints intervals represented means
metric constraints ending time-points. way, described model also subsumes
Interval Distance Sub Algebra model proposed Badaloni Berati (1996). Moreover, ending
points intervals also related initial time-point T0 , unary metric constraints
interval durations expressed means metric constraints two ending points
interval:
dur (Ii ) = {[dm1 dM1 ], [dm2 dM2 ], ..... [dmn dMn ]}
(Ii - {[dm1 dM1 ], [dm2 dM2 ], ..... [dmn dMn ]} Ii +).

67

fiREASONING INTERVAL POINT -BASED DISJUNCTIVE ETRIC CONSTRAINTS TEMPORAL CONTEXTS

-

[ I1 ]

-

[ I1 ]

30
60

T0

I1

I1+

[

]

20
I2
[

50

]

{[140 150], [200 210]}

Figure 12: Metric constraints intervals
Thus, following constraints (Figure 12):
(I1 {b, o} I2) (I1- [[20 30], [50 60]} I2-) (I2- {[140 150], [200 210]} T0 )
represented (Table 1):
default: (I1 - { (0 ){R0}} I1+), (I2- { (0 ){R0}} I2+),
(I1 {b, o} I2)



(I1+ {(0 ){Rb1} (- 0]{Rb2}} I2-),

(I1+ {(- 0){Ro1} [0 ){Ro4}} I2-),

(I1+ {(0 ){Ro2} (- 0]{Ro5}} I2+),

(I1- {(0 ){Ro3} (- 0]{Ro6}} I2-),



(I1- [[20 30], [50 60]} left I2-)
(I2- {[140 150], [200 210]} T0 )



(I1- {[50 60]{R1} [20 30]{R2}} I2-),
(T0 {[140 150]{R3} [200 210]{R4}} I2- ),

{Rb2 Ro4 }, {Rb2 Ro5 }, {Rb2 Ro6 }, {R1 R2 } {R3 R4 } I-L-Sets.

6. Reasoning Logical Expressions Constraints
described model, disjunct input constraint univocally associated label.
Moreover, label set associated derived elemental constraint represents support-set
input elemental constraints elemental constraint derived. I-L-Sets represent
inconsistent sets input elemental constraints. reasoning labeled disjunctive constraints,
associated label lists I-L-Sets, temporal model offers capability reasoning logical
expressions elemental constraints belonging disjunctive constraints different pairs
time points. Let's assume following labeled input constraints:
(ni lc ij nj ) (ni {(lecij.1 ){Rij.1} (lecij.2 ) {Rij.2} .....(lecij.p ) {Rij.p}} nj ),
(nk lc kl nl ) (nk {(leckl.1 ) {Rkl.1} (leckl.2 ) {Rkl.2} .....(leckll.q ) {Rkl.q}} nl )
i) represent two elemental constraints 4 (elc ij.x lc ij , elckl.ylc kl ) cannot hold simultaneously
(that (elc ij.x elc kl.y )) label set {Rij.x Rkl.y } added set I-L-Sets.
ii) represent logical dependency two elemental constraints, 'If lec ij.x
leckl.y' (where lecij.xcij , leckl.yckl ), Cartesian product {Rij.x} {{Rkl.1 , Rkl.2 , ....., Rkl.q }{Rkl.y }} added set I-L-Sets.
iii) represent two elemental constraints (elc ij.xlcij , elckl.y lc kl ) hold simultaneously
(bi-directional logical dependency), Cartesian products {Rij.x} {{Rkl.1 , Rkl.2 , ....., Rkl.q }4

reasons simplicity, two elemental constraints shown. However, two disjunctions managed
similar way. Likewise, features also applied labeled derived constraints.

68

fiBARBER

{Rkl.y }} {Rkl.y } {{Rij.1 , Rij.2 , ....., Rij.p }-{Rij.x}} added set I-L-Sets.
instance, lets see Example 2 Section 4.4 (Figure 10):
represent John goes work car Fred goes work walking possible,
{R1 R5 } asserted I-L-Set.
represent John goes work car Fred goes work walking, {R1 R3 }
{R1 R4 } asserted I-L-Sets.
represent John goes work car Fred goes work walking, vice versa,
{R1 R3 }, {R1 R4 } {R5 R2 } asserted I-L-Sets.
similar way, logical relations among point-based interval-based elemental constraints
also represented. instance, logical dependence "the duration I1 [5 8] I2 I3
duration 1 [12 15] I2 I3" represented as:
(I2 {b, bi} I3 )

(I2 + {(0 ){Rb9} (- 0]{Rb10}} I3 -),
{Rb10 Rb12 } I-L-Set,

(I3 + {(0 ){Rb11} (- 0]{Rb12}} I2 -),

(I1 - {[5 8] {R1} [12 15] {R2}} I1 +),
{R1 Rb11 }, {R2 Rb9 } I-L-Sets, since Rb11 associated I2 I3 Rb9 associated
I2 I3 . Likewise, "I1 starts time 2 t1 occurs t2" represented
(see Table 1):
I1 {s, s} I2 (I1 - {[0 0] {Rs1} (0 ){Rs3} (- 0){Rs4}} I2 -) , (I1 + {(0 ){Rs2} (- 0]{Rs5}} I2 +) ,
(t1 {(- -1] {R1}, [0 0] {R2}, [1 ){R3}} t2 ),
{R3 Rs3 }, {R3 Rs4 }, {R3 Rs5 } I-L-Sets, since R3 associated 't1 occurs t2 ' Rs3 ,
Rs4 Rs5 associated 'I1 start time I2 '.
6.1 Disjunctions Point Interval-Based Constraints
Disjunctions constraints different pairs points intervals represented
proposed model means labeled constraints points set I-L-Sets. subsumes
related expressiveness subset disjunctive linear constraints proposed Stergiou
Koubarakis (1998), disjunctions constraints different pairs points
managed.
represent disjunctive set disjunctive constraints points, have5 :
(ni lc ij nj ) (nk lc kl nl ) represented as: (ni {lc ij lc ij } nj ) (nk {lc kl lc kl } nl ),
logical relation among lc ij , lc ij , lc kl lc kl. Thus, disjunctive set constraints:
{(ni lc ij nj ) (nk lc kl nl )}
{(ni {(lecij.1 ){Rij.1}, (lecij.2){Rij.2}, ...., (lecij.p ){Rij.p}} nj )
(nk {(leckl.1 ){Rkl.1}, (leckl.2 ){Rkl.2}, ...., (leckj.q ){Rkl.q}} nl )}
5

reasons simplicity, two constraints shown. However, two disjunctive constraints managed
similar way.

69

fiREASONING INTERVAL POINT -BASED DISJUNCTIVE ETRIC CONSTRAINTS TEMPORAL CONTEXTS

represented as:
i) conjunctive set constraints (ni , nj ) (nk , nl ), where, (lecx)
represented means complementary domain (lecx):
(ni {(lecij.1 ){Rij.1}, (lecij.2 ){Rij.2}, ...., (lecij.p ){Rij.p}, {(lecij.1 ){Rij.1}, (lecij.2 ){Rij.2}, ...., (lecij.p ){Rij.p}}} nj )
(nk {(leckl.1 ){Rkl.1}, (leckl.2 ){Rkl.2}, ..., (leckj.q ){Rkl.q}, {(leckl.1 ){Rkl.1}, (leckl.2 ){Rkl.2}, ..., (leckj.q ){Rkl.q}}} nl )
{(ni {(lecij.1 ){Rij.1}, (lecij.2 ){Rij.2}, ..., (lecij.p ){Rij.p}, (lecij.1 ){R'ij.1}, (lecij.2 ){R'ij.2}, ..., (lecij.p){R'ij.p}} nj )
(nk {(leckl.1){Rkl.1}, (leckl.2 ){Rkl.2}, .., (leckj.q ){Rkl.q}, (leckl.1 ){R'kl.1}, (leckl.2){R'kl.2}, ..., ( leckl.q ){R'kl.q} } nl )}
ii) set I-L-Sets represent mutually exclusive disjunction lc ij lc kl (they cannot
simultaneously hold):
ii.a) One constraints lc ij lc kl hold: Cartesian product label sets
complementary domains lc ij lc kl , {R'ij.1 , R'ij.2 , ...., R'ij.p }{R'kl.1 , R'kl.2 , ...., R'kl.q },
I-L-Sets.
ii.b) one constraints lc ij lc kl hold: Cartesian product label sets
lc ij lc kl , {Rij.1 , Rij.2 , ...., Rij.p }{Rkl.1 , Rkl.2 , ...., Rkl.q } I-L-Sets.
Thus, disjunctive conjunctive sets disjunctive constraints points represented
managed means conjunctive set disjunctive constraints set I-L-Sets.
example:
(ti {[5 5] {R1} [10 10] {R2}} tj ) (tk {[0 0] {R3} [20 20] {R4}} tl )
(ti {[5 5] {R1} [10 10] {R2} (- 5){R5} (5 10) {R6} (10 ){R7}} tj )
(tk {[0 0] {R3} [20 20] {R4} (- 0){R8} (0 20) {R9} (20 ){R10}} tl ),

(ii.a) since (ti {[5 5] {R1}, [10 10] {R2}} tj ] [tk {[0 0] {R3}, [20 20] {R4}} tl ] hold:
{R5 R6 R7 }{R8 R9 R10 } I-L-Sets,
(ii.b) since one constraint (t {[5 5]{R1} [10 10] {R2}} tj ) (tk {[0 0] {R3} [20 20]{R4}} tl )
hold:
{R1 R2 }{R3 R4 } = {R1 R3 }, {R1 R4 }, {R2 R3 }, {R2 R4 } I-L-Sets.
Ii ecij Ij

Ii ecij Ij

Ii ecij Ij

I1 I2

I1 {(0 ){Rb1}} I2

I3 I4

I3 + {(0 ){Rb3}} I4 -

+

-

Ii (ecij ecij) Ij
-

I1 {(0 ){Rb1} (- 0]{Rb2}} I2 -

I3 + {(- 0]{Rb4}} I4 -

I3 + {(0 ){Rb3} (- 0]{Rb4}} I4 -

+

I1 {(- 0]{Rb2}} I2

+

Table 5: Point-based constraints (I1 I2 ) (I3 4 )
Similarly, disjunctions interval-based constraints different pairs intervals also
represented. instance, Table 1 Table 5, {(I1 I2 ) (I3 I4)}
represented as:
(I1 + {(0 ){Rb1} (- 0]{Rb2}} I2 -), (I3 + {(0 ){Rb3} (- 0]{Rb4}} I4 -),

70

fiBARBER


a)

one constraints (I1 I2) (I3 I4 ) hold. Thus, Cartesian product
label sets associated disjunctive constraints (Ii ecij Ij ) set I-L-Sets: {Rb2 ,
Rb4 } I-L-Set,

b)

one constraints (I1 I2 ) (I3 I4 ) hold. Thus, label set
associated mutual fulfillment constraints (Ii ecij Ij ) I-L-Set: {Rb1 , Rb3 }
I-L-Set.

Thus:
{(I1 I2 ) (I3 I4 )}
(I1 + {(0 ){Rb1} (- 0]{Rb2}} I2 -), (I3 + {(0 ){Rb3} (- 0]{Rb4}} I4 -),
{Rb2 , Rb4 }, {Rb1 , Rb3 } I-L-Sets.
Ii ecij Ij

Ii ecij Ij

Ii ecij Ij

Ii (ecij ecij) Ij

(I1 I2 )

I1 - {(- 0){Rd1}} I2 -

(I1 - {[0 ){Rd3}} I2 -)

I1 - {(- 0){Rd1} [0 ){Rd3}} I2 -

I1 + {(0 ){Rd2}} I2 +
(I3 starts I4 )

I3 - {[0 0]{Rs1}} I4 I3 + {(0 ){Rs2}} I4 +



(I1 + {(- 0]{Rd4}} I2 +)

I1 + {(0 ){Rd2} (- 0]{Rd4}} I2 +

(I3 - {(0 ){Rs3} (- 0){Rs4}} I4 -) I3 - {[0 0]{Rs1} (0 ){Rs3} (- 0){Rs4}} I4

(I3 + {(- 0]{Rs5}} I4 +)

I3 + {(0 ){Rs2} (- 0]{Rs5}} I4 +

Table 6: Point-based constraints (I1 I2 ) (I3 starts I4 )
similar way (Table 6), (I1 I2 ) (I3 starts 4 )
(I1 - {(- 0){Rd1} [0 ){Rd3}} I2 -),

(I1 + {(0 ){Rd2} (- 0]{Rd4}} I2 +),

(I3 - {[0 0] {Rs1} (0 ){Rs3} (- 0){Rs4}} I4 -), (I3 + {(0 ){Rs2} (- 0]{Rs5}} I4 +),
{Rd1 Rd2 Rs1 Rs2 } Cartesian product {Rd3 Rd4 } X {Rs3 Rs4 Rs5 } I-L-Sets.
Therefore, logical relations elemental constraints represented set I-L-Sets. Thus,
labeled TCN (and set I-L-Sets) represent special type and/or TCN. types
non-binary constraints enrich expressiveness language allow modeling
complex problems (Meiri, 1996). Stergiou Koubarakis (1996) Jonsson Bckstrm (1998)
show Disjunctions Linear Constraints (DLR) also able represent non-binary
constraints. However, Pujari Sattar (1999) remark general methods linear programming
applied DLR management, specific temporal concepts (like ones
detailed Section 2) considered general methods. proposed model,
management non-binary constraints performed proposed reasoning methods
without increasing computational complexity. added functionality interest several
temporal reasoning problems, including planning, scheduling temporal constraint databases
(Barber et al., 1994; Gerevini & Schubert, 1995; Brusoni et al., 1997; Stergiou & Koubarakis, 1998;
etc.) general solutions provided specific temporal reasoning area.
addition, proposed reasoning algorithms obtain globally labeled-consistent TCN
(Theorem 11). feature allows us manage hypothetical queries, important
requirement query processes temporal constraint databases (Brusoni et al., 1997). Thus, queries
71

fiREASONING INTERVAL POINT -BASED DISJUNCTIVE ETRIC CONSTRAINTS TEMPORAL CONTEXTS

c'ij hold, c'kl? answered without TCN propagation. label set associated
derived elemental constraint represents set input elemental constraints hold
fulfillment elemental constraint. Therefore,
(xk c'kl xl)(xi c'ij xj )
holds, elc kl.y lc kl / eckl.yc'kl elc ij.xlc ij / ec ij.xc'ij labels(elc ij.x)labels(elc kl.y ) hold.
example, labeled minimal TCN Figure 7, have:
(T1 {[40 40]} T3 ) (T2 { [0 0] } T4 ),

(T3 { [20 20] } T2 ) (T3 { [20 20] } T4 ).

However, (T3 {[10 20]} T2 ) imply (T1 {[70 70]} T4 ). Similarly, questions
c'ij hold, c'kl? also easily answered applying Theorem 9 Theorem 10.

7. Alternative Temporal Contexts
reason temporal facts, simultaneously work different alternative temporal
contexts, situations, trends, plans, intentions possible worlds (Dousson et al., 1993; Garcia &
Laborie, 1996). usual branching (backward forward) model time. Here,
alternative past contexts (i.e.: different lines facts may occurred) alternative future
contexts (i.e.: different lines facts may occur). Thus, temporal context management also
required hypothetical causal reasoning. Also, different contexts permits partition
whole TCN set independent chains order decrease complexity problem size
(Gerevini & Schubert, 1995). section, deal hypothetical reasoning issues.
goal temporal management context-dependent constraints. Thus, general, hierarchy
alternative temporal contexts established, constraints associated different
temporal contexts. instance, Figure 13 represents hierarchy alternative contexts, W0
represents root context different disjunctive constraints (n1 , n2 )
context. Temporal reasoning algorithms detailed paper able manage contextdependent constraints:
Input disjunctive constraints asserted different temporal contexts. this, labels
associated input elemental constraints also used represent context
disjunctive asserted. instance (Figure 13), constraint:
(n1 {[0 50] {R1}, [200 210] {R2}} n2 )
asserted context W1 , following input context-dependent labeled constraint:
(n1 {[0 25] {R1, W1}, [260 280] {R2, W1}} n2 ).
Here, context-dependent label set associated elemental constraint represents
alternative temporal disjunct (i.e.: R1 R2 ) context elemental
constraint asserted (W1 ).
Label sets associated context-dependent derived elemental constraints represent
temporal contexts derived elemental constraints hold.
Definition 8. context-dependent disjunctive constraint disjunctive constraint
elemental constraint (i.e.: disjunct) associated alternative temporal context. universal
labeled constraint {(- ){W0 R0}}, W0 root context.
72

fiBARBER

proposed reasoning processes manage context-dependent disjunctive constraints way
similar previously defined labeled disjunctive constraints (Section 3). instance, according
constraints contexts Figure 13, following input labeled constraints nodes n1
n2 updated:
(n1 {[0 100] {R1 W0}, [200 300] {R2 W0}} n2 ),

(n1 {[0 50] {R3 W1}, [200 210] {R4 W1}} n2 ),

(n1 {[60 100] {R5 W 2} , [290 300] {R6 W2}} n2 ),

(n1 {[0 25] {R7 W3}, [260 280] {R8 W3}} n2 ),

(n1 { [0 25] {R0 W11}} n2 ),

(n1 { [30 50] {R9 W12}, [200 205] {R10 W12}} n2 ),

(n1 {[0 20] {R0 W31}, [210 215] {R0 W32}} n2 ),

(n1 {[260 280] {R0 W33}} n2 ).

restricted constraints
Context W11

n1 {[0 25]} n 2

Context W1

n 1 {[0 50], [200 210]} n 2
Context W12

n 1 {[0 100], [200 300]} n 2

Context W2

n 1{[30 50], [200 205]} n 2

n1 {[60 100], [290 300]} n 2

Root-Context W0

Context W31

n 1{[0 20]} n 2
Context W3

n 1{[0 25], [260 280]} n 2

Context W32

n1{[210 215]} n

2

Context W33

n1{[260 280]} n

2

Assertion Context k

Downward Propagation:
Propagation contextk
successor contexts

Upward Consistency:
Consistency contextk
predecessor contexts

Figure 13: hierarchy alternative contexts
updating process new constraint cij given context Wp assure
consistency c ij context Wp , well predecessor contexts (Figure 13). consistency
cij successor contexts Wp detailed Section 7.2, since several options
identified. However, necessary assure consistency among constraints belonging contexts
different hierarchies. Successor contexts given context represent different alternatives,
mutually exclusive. Thus, constraints belonging contexts different hierarchies
mutually inconsistent. However, imply constraints contexts
necessarily mutually disjoint. instance (Figure 13), constraints (n1 {[0 50] {R3 W1}, [200
210]{R4 W1}} n2 ) context W1 (n1 {[0 25] {R7 W3}, [260 280] {R8 W3}} n2 ) context W3
mutually disjoint. However, W1 , W2 W3 assumed three mutually exclusive alternatives
W0 .
73

fiREASONING INTERVAL POINT -BASED DISJUNCTIVE ETRIC CONSTRAINTS TEMPORAL CONTEXTS

closure process new constraint cij context Wp downward propagate new
constraint cij successor contexts (Figure 13). Moreover, propagation performed
predecessor contexts contextk , among contexts different hierarchies. Elemental
constraints belonging contexts different hierarchies cannot simultaneously considered,
is, combined intersected.
7.1 Context-Dependent Updating Closure Processes
update closure processes defined Section 4 adapted order manage contextdependent disjunctive constraints. Context-Update process (Figure 14) asserts constraint
cij {ec1 , ec2, ..., ecn } context contextk. way similar updated process described
Section 4, Context-Update performed time new context-dependent constraint
asserted.
Context-Update (ni cij nj contextk)
lc'ij Put-label-context (cij , contextk )
;Labelling mutual inconsistency.
Consistency-Test (get-upward (ni , nj , contextk ), lc'ij )
;Upwards Consistency test
(*Inconsistent Constraint*)
Return (false)
Else (*Consistent Constraint*)
;lc'ij asserted contextk
lc ij (lc ij - get (ni , nj , contextk )) lc (lc ij lc lc'ij ),
;successor contexts.
lc ji Inverselc (lc ij ),
Context-Closure (ni lc ij nj contextk )
;Downwards Closure algorithm contextk.
.
Return (true)
End-If
End-Context-Update
Figure 14: Context-Update process context-dependent labeled constraints
Where:
Put-label-context (cij , contextk ) associates exclusive label set elemental constraint
ecij.p cij . label set two labels {Rij.p contextk }. label set, first label
label associated temporal disjunct. way similar Put-labels function, labels
mutually exclusive (Definition 3). second label represents context cij
updated. Moreover, pair labels associated successor contexts parent context
contextk added I-L-Sets, since successor contexts given context
mutually exclusive:
contextp / contextp Succesor-Contexts(Parent-Context(Contextk )),
I-L-Sets I-L-Sets ({contextk }{contextp }).
Parent-Context(contextk ) Successor-Contexts(contextk ) return parent-context
set successor-contexts contextk , respectively. Thus, Figure 13, {{W1 , W2 },
{W1 , W3 }, {W2 , W3 }, {W11 , W12 }, {W31 , W32 }, {W31 , W33 }, {W32 , W33 }} I-L-Sets.
74

fiBARBER

get (ni , nj , contextk ) returns set labeled elemental constraints ni nj
contextk (and successor contexts). is:
get (ni , nj , contextk )::= {(ecij.p {labelij.p })lc ij / contextk {labelij.p }}.
Note get(ni , nj, contextk ) subset lc ij . Thus, (lc ij - get (ni , nj , context k )) means setdifference lc ij get (ni , nj , contextk ). is, set elemental constraints
context-dependent constraint lc ij , contextk , successor contexts.


get-upward (ni, nj , contextk ), similarly previous get function, returns existing
constraints ni nj contextk (and successor contexts). However,
constraint ni nj contextk , function returns
constraints ni nj exist predecesor context contextk:
get-upward (ni, nj , contextk ) ::=
get (ni , nj , contextk ) return (get (ni , nj , contextk ))
Else
Contextk Parent-Context (Contextk )
get (ni , nj , contextk ) Contextk =W0
get (ni , nj , contextk ) return (get (ni , nj , contextk ))
Else return({(- +)}{W0 R0}})
End-get-upward

context-dependent closure (Figure 15) process similar closure process described
Section 4 also performed updating process. closure process updated
constraint contextk downwards performed contextk successor contexts.

Context-Closure (ni lc ij nj contextk)
(* First loop: Closure n n j n k *)
nk TCN / lc jk {U{R0 W0}}:
lc'ik lc ik lc (lc ij lc lc jk ),
lc ik (lc ik - get (ni , nk , contextk )) lc lcij ,
lc ki Inverse(lc ik)
(* Second loop: Closure n j ni nl *)
nl TCN / lc il {U{R0 W0}}:
lc'jl lc jl lc (Inverse(lc ij ) lc lc il ),
lc jl (lc jl - get (nj , nl , contextk )) lc lc'jl ,
lc lj Inverse(lc jl )
(* Third loop: Closure nl ni nj nk *)
nl , nk TCN / lc lj {U{R0 W0}}, lc jk {U{R0 W0}}:
lc'lk lc lk lc (lc li lc lc ij lc lc jk )
lc lk (lc lk - get (nl , nk , contextk )) lc lc'lk ,
lc kl Inverse(lc lk)
End-Context-Closure
Figure 15: Context-Closure process context-dependent labeled constraints
75

fiREASONING INTERVAL POINT -BASED DISJUNCTIVE ETRIC CONSTRAINTS TEMPORAL CONTEXTS

resulting label set associated context-dependent derived elemental constraint represents
contexts elemental constraint holds, well hierarchy predecessor contexts
elemental constraint. instance, Figure 16 shows contextual labeling example
Figure 13. Moreover, successively performing updating closure processes
constraints example, following constraint nodes n1 n2 :
(n1 lc 12 n2 ): (n1 {[0 100] {R1 W0}, [200 300] {R2 W0}, [0 50] {R3 R1 W1 W0}, [200 210] {R4 R2 W1 W0},
(e3)
[60 100] {R5 R1 W2 W0}, [290 300] {R6 R2 W2 W0}, [0 25] {R7 R1 W3 W0}, [260 280] {R8 R2 W3 W0},
[0 25] {R0 R3 R1 W11 W1 W0}, [30 50] {R9 R3 R1 W12 W1 W0}, [200 205] {R10 R2 R4 W12 W1 W0},
[0 20] {R0 R7 R1 W31 W3 W0}, [210 215]{R0 R2 R8 W32 W3 W0}, [260 280]{R0 R2 R8 W33 W3 W0}} n2 )

{W0}

{W0 W1}

{W0 W1 W11}

{W0 W3}

{W0 W2}

{W0 W1 W12}

{W0 W 3 W 31}

{W0 W3 W32}

{W0 W 3 W33}

Figure 16: Labels contexts
closure process performed among constraints belonging contexts different hierarchies.
According Put-label-context function, pair labels related successor contexts
context I-L-Set. Thus, I-L-Sets prevent deriving elemental constraints contexts
different hierarchies. is, derived elemental constraint obtained (combining intersecting)
two elemental constraints contexts different hierarchy inconsistent associated
label set. Therefore, derived elemental constraints rejected operation lc.
instance, example Figure 13, {{W1 , W2 }, {W1 , W3 }, {W2 , W3 }, {W11 , W12 }, {W31 , W32 },
{W31 , W33 }, {W32 , W33 }} I-L-Sets. Thus, constraint asserted context W1 :
i) propagation performed using constraints contexts W11 W12 simultaneously,
since {W11 , W12 } I-L-Set.
ii) propagation performed context W2 , W3 , successors, since {W1 ,
W2 } {W1 W3 } I-L-Sets.
Let's see example Context-Update Context-Closure processes. Lets assume
context-dependent constraints Figure 13 already updated closured, previous
constraint lc 12 (expression e3) exists n1 n2 . Now, update (n1 {[20 40]} n2 ) context
W1 . call Consistency-Test function Context-Update function is:
Consistency-Test (get-upward (n1 , n2 , W1 ), {[20 40] {R0 W1}}).
Given previous constraint lc 12 n1 n2 (expression e3), function performs:
{[0 50] {R3 R1 W1 W0}, [200 210] {R4 R2 W1 W0}, [0 25] {R0 R3 R1 W11 W1 W0},
76

fiBARBER

[30 50] {R9 R3 R1 W12 W1 W0}, [200 205] {R10 R2 R4 W12 W1 W0}} lc {[20 40]{R0 W1}}=
{[20 40] {R3 R1 R0 W1 W0}, [20 25] {R0 R3 R1 W11 W1 W0}, [30 40] {R9 R3 R1 R0 W12 W1 W0}}
Thus, new constraint (n1 {[20 40]} n2 ) consistent context W1 . Therefore, constraint
n1 n2 results:
lc12 (lc 12 - get (n 1 , n 2 , W 1 )) lc (lc 12 lc {[20 40]{R0 W1}}) =
{[0 100]{R1 W0}, [200 300] {R2 W0}, [60 100]{R5 R1 W2 W0}, [290 300]{R6 R2 W2 W0},
[0 25]{R7 R1 W3 W0}, [260 280]{R8 R2 W3 W0}, [0 20]{R0 R7 R1 W31 W3 W0},
[210 215]{R0 R2 R8 W32 W3 W0}, [260 280]{R0 R2 R8 W33 W3 W0}} lc
{[20 40]{R1 R0 W1 W0}, [20 40]{R3 R1 R0 W1 W0}, [20 25]{R0 R3 R1 W11 W1 W0}, [30 40]{R9 R3 R1 R0 W12 W1 W0}}=
{[0 100]{R1 W0}, [200 300] {R2 W0}, [60 100]{R5 R1 W2 W0}, [290 300]{R6 R2 W2 W0}, [0 25]{R7 R1 W3 W0},

(e4)

[260 280]{R8 R2 W3 W0}, [0 20]{R0 R7 R1 W31 W3 W0}, [210 215]{R0 R2 R8 W32 W3 W0}, [260 280]{R0 R2 R8 W33 W3 W0},
[20 40]{R1 R0 W1 W0}, [20 25]{R0 R3 R1 W11 W1 W0}, [30 40]{R9 R3 R1 R0 W12 W1 W0}}.

Note new updated constraint asserted context W1 propagated successor
contexts (W11 W12 ). However, new constraint context W1 affect existing
constraints predecessor contexts W1 (W0) constraints belonging contexts different
hierarchies (W2 , W3 successors).
update process, closure process performed, since node related n1 n2 .
Now, lets update (n3 {[10 20]} n1 ) context W1 . have:
Consistency-Test (get-upward (n3 , n1 , W1 ), {[10 20] {R0 W1}}),
performs:
{(- +)}{W0 R0} lc {[20 40] {R0 W1}} = {[20 40] {R0 W0 W1}} ,
since previous constraint exists (n3 n1 ) context W1 . constraint (n3 {[10 20]} n1 )
consistent, asserted TCN:
lc 31 {(- +)}{W0 R0}, [20 40] {R0 W0 W1}}.
(e5)
Afterwards, constraint closured. call Context-Closure process is:
Context-Closure (n3 , {(- +)}{W0 R0}, [20 40] {R0 W0 W1}}, n1 , W1 ).
closure process, first loop performed since node related n3 . Moreover,
previous constraint lc 12 (expression e4) exists current TCN n1 n2 . Thus,
first loop performs:
lc'32 lc 32 lc ({(- +)}{W0 R0}, [20 40] {R0 W0 W1}} lc lc 12 ) =
{(- ){W0 R0}} lc ({(- +)}{W0 R0}, [20 40] {R0 W0 W1}} lc lc 12 ) =
{(- +)}{W0 R0}, [220 340] {R2 R0 W0 W1}, [40 80] {R1 R0 W1 W0},
[40 65] {R0 R3 R1 W11 W1 W0}, [50 80] {R9 R3 R1 R0 W12 W1 W0}},
that,
lc 32 (lc 32 - get (n3 , n2 , W1 )) lc lc'32 = ({(- ){W0 R0}} - {}) lc lc'32 =
{(- ){W0 R0}, [220 340] {R2 R0 W0 W1}, [40 80] {R1 R0 W1 W0},
[40 65] {R0 R3 R1 W11 W1 W0}, [50 80] {R9 R3 R1 R0 W12 W1 W0}}.
77

(e6)

fiREASONING INTERVAL POINT -BASED DISJUNCTIVE ETRIC CONSTRAINTS TEMPORAL CONTEXTS

Thus, asserted constraint (n3 , n2 ) context W1 closured context W1
successor contexts (W11 W12 ). Likewise, closure process perform
propagation simultaneously using constraints contexts W11 W 22 , context W2 ,
W3 , successors.
7.2 Complete Versus Incomplete Partition Contexts
updating process, consistency new constraint lcij given context assured
context parent contexts. Lets deal consistency issues context
successor contexts. Here, constraints given context Wi either completely
covered partially covered existing constraints successor contexts Wi . is,
successor contexts Wi either complete partition partial partition Wi .
instance, let's assert constraint (n1 {[210 210] {R0 W1}} n2 ) context W1 example
Figure 13. Consistency-test function, (where constraint lc 12 previous
expression e2):
get-upward (n 1 , n 2 , W 1 ) lc {[210 210]{R0 W1}} =
{[0 50]{R3 R1 W1 W0}, [200 210]{R4 R2 W1 W0}, [0 25]{R0 R3 R1 W11 W1 W0}, [30 50]{R9 R3 R1 W12 W1 W0},
[200 205]{R10 R2 R4 W12 W1 W0}} lc {[210 210]{R0 W1}} = {[210 210]{R0 W1 R4 R2 W0}}.

is, asserted constraint consistent existing constraints context W1 . However,
resulting elemental constraint associated context W11 W12 . means asserted
constraint (n1 {[210 210] {R0 W1}} n2 ) consistent W1 , inconsistent W11 W12 . Here,
two alternatives appear:
i) assume existing successor contexts complete partition parent context.
Therefore, new constraint cij context Wi rejected, cij inconsistent
successor contexts Wi. instance, assume W11 W12 Figure 13
complete partition W1 . Thus, (n1 {[210 210] {R0 W1}} n2 ) rejected.
ii) assume successor contexts complete partition parent context. Therefore,
successor contexts become inconsistent removed. example,
assume contexts W11 W12 complete partition context W1 ,
another possible new successor context W 1 would able match future asserted
constraint (n1 {[210 210] {R0 W1}} n2 ). case, constraint (n1 {[210 210] {R0 W1}} n2 )
assumed correct, asserted TCN. Therefore, contexts W11
W12 become inconsistent. {W11 } {W12 } added set I-L-Sets,
contexts (and successor contexts constraints) become inconsistent
removed TCN. is, elemental constraints associated label set containing
{W11 } {W12 } removed.
cases, context always consistent successor contexts. option
adopted depend problem type solve (Garrido et al., 1999). options
easily introduced described reasoning processes, since function Consistency Test
determine successor contexts (Ws ) become inconsistent new constraint (lcij )
context (Wk ):
78

fiBARBER

Ws Successor-Contexts(Wk ) / elc ij.p get-upward (ni , nj , Wk ), Ws{labelij.p }
elc ij.r(get-upward (ni , nj , Wk ) lc lcij ), Ws{labelij.r}.
hand, when: (i) successor contexts (Wk1 , Wk2 , ..., Wkp ) context Wk
complete partition it, (ii) constraints (Wk1 , Wk2 , ..., Wkp ) asserted,
constraints Wk restricted according final existing constraints (W k1 , Wk2 , ..., Wkp ).
this, context Wk constrained temporal union constraints
successor contexts.
7.3 Minimal Consistent Context-Dependent TCN
Definition 9. context-dependent TCN minimal (and consistent) constraints context
consistent (with respect constraints context, predecessor contexts,
successor contexts) minimal (with respect constraints context predecessor
contexts).
Theorem 12. updating process, context-dependent reasoning processes obtain minimal
(and consistent) context-dependent TCN previous context-dependent TCN minimal.
Proof: previous context-dependent TCN minimal, Consistency-Test function guarantees
consistency new context-dependent input constraint:
i)

context parent contexts (get-upward function Theorem 5),

ii)

successor contexts (depending two identified cases Section 7.2).

closure process new constraint given context (Wk ) propagates effects
context successor contexts. Therefore (Theorem 7), process obtains new minimal
constraints context (Wk ) successor contexts.
Moreover, obtained context-dependent TCN globally labeled-consistent. Thus,
deduce whether set elemental constraints (between different pairs time points) consistent
(Theorem 10). is, set elemental constraints holds context. instance, given
previous constraints lc 12 , lc 31 lc 32 (previous expressions e4, e5 e6), deduce that:
(n1 {[40 40]} n2 ) (n3 {[40 40]} n1 ) (n3 {[40 40]} n2 )
full consistent since:
elc 12.xlc 12 , elc 31.y lc 31 , elc 32.zlc 32 / ({label12.x} {label12.x} {label12.x}) I-L-Set.
Specifically, instantiations hold {R1 R0 W1 W0 } {R1 R0 W0 }. Thus, set
elemental constraints holds context W1 (and, obviously, predecessor contexts).
Likewise, minimal context-dependent TCN, user retrieve constraints hold
context constraints simultaneously hold set given contexts. this,
Context-Constraints function retrieves constraints hold pair nodes (ni , nj )
given context (contextk ). is, result Get-upwards(ni , nj , contextk ) except elemental
constraints belonging successor contexts contextk :

79

fiREASONING INTERVAL POINT -BASED DISJUNCTIVE ETRIC CONSTRAINTS TEMPORAL CONTEXTS

Context-Constraints (ni, nj, contextk )::= Get-upwards (ni , nj , contextk )
{lecij.p lc ij / contextqSuccesor-Contexts(contextk ), {contextq }{labelij.p }}.
instance, given context-dependent constraint lc 12 Figure 13 (expression e3),
following constraint would hold (n1 , n2 ) contexts W1 W3 :
Context-Constraints(n 1 , n 2 , W1 ) lc Context-Constraint(n 1 , n 2 , W 3 ) =
{[0 50]{R3 R1 W1 W0}, [200 210]{R4 R2 W1 W0}} lc {[0 25]{R7 R1 W3 W0}, [260 280]{R8 R2 W3 W0}}=
{[0 25]{R7 R3 R1 W3 W1 W0}}6 .

addition, obtain constraints, simultaneously hold context
successor ones. instance, context W1 successor contexts (W11 , W12),
following constraint holds:
Context-Constrains(n1 , n2 , W1) lc [Context-Constraints(n1, n 2 , W11 ) lc Context-Constraints(n 1 , n2 , W12 )]=
{[0 50]{R3 R1 W1 W0}, [200 210]{R4 R2 W1 W0}} lc
{[0 25]{R0 R3 R1 W11 W1 W0}}lc {[30 50] {R9 R3 R1 W12 W1 W0}, [200 205]{R10 R2 R4 W12 W1 W0}}=
{[200 205]{W12 R10 R4 R2 W1 W0}, [0 25]{W11 R0 R3 R1 W1 W0}, [30 50]{W12 R9 R3 R1 W1 W0}}.

hand, alternative context (Wi ) associated alternative hypothesis
(Hi ). hypothesis Hi gives rise set constraints, asserted associated
context Wi . Thus, proposed reasoning processes assure minimal constraints hierarchy
hypotheses. Moreover, hypothesis (Hi ) becomes unavailable, label set {Wi }
added set I-L-Sets. Thus, constraints context Wi (and successor contexts)
removed. is, constraints depend unavailable hypothesis Hi removed.
7.4 Computational Complexity Temporal Context Management
management temporal context increase complexity reasoning processes
detailed Section 4. fact, consider label associated disjunct (Ri ) labeled
disjunctive constraints also associated context (Wi ). Thus, computational cost
updating process also bounded O(n2 l2e), 'l' maximum number input disjuncts
pair nodes contexts.
temporal labeled algebra proposed paper (Section 3) applied pointbased disjunctive metric constraints (Dechter, Meiri & Pearl, 1991). However, labeled algebra
also applied temporal constraints. case, operations lc, lc, lc lc
specified (Section 3) basis operations , , underlying
algebra. way, management temporal contexts also applied types
constraints.
Theorem 13. computational complexity proposed reasoning process applied contextdependent non-disjunctive metric constraints polynomial (O(n2 W2)) number W managed
contexts.
6

However, note impossible situation, since W 1 W 3 mutually exclusive contexts. is, {W 3, W 1}
I-L-Set.

80

fiBARBER

Proof: Disjunctions constraints related contexts input constraints
asserted, non-disjunctive constraints managed. is, constraints pair nodes
form:
(ni {(ec ij.0 {W0 R0 }), (ec ij.1 {W1 R0 }), ...... , (ecij.k {Wk R0 })} nj ) ,

0kW / W=|{Wi }|

Thus, maximum number disjuncts constraints bounded maximum number
managed contexts W. Moreover, maximum length associated label sets maximum depth
hierarchy contexts, set I-L-Sets 2-length sets (i.e.: pairs labels
associated pair successor contexts context). Therefore, computational cost
operations lc lc bounded O(W2 ).
methods proposed Section 7.1 management temporal contexts also applied
temporal reasoning algorithms, instead reasoning methods detailed Section 4.
requires reasoning algorithms based operations composition
intersection temporal constraints. Thus,
i) elemental constraint associated context (W ) asserted7 .
Thus, label sets associated elemental constraints one contextual label {Wi }.
ii) methods management temporal contexts described Section 7.1
integrated new reasoning algorithms. algorithms use operations
lc, lc, get get-upwards. computational cost operations lc lc related
management temporal contexts polynomial (O(W2 )) number (W) managed
contexts. Therefore, computational cost reasoning algorithms increased factor
W2 temporal contexts managed.
instance, interval-based constraints managed, TCA algorithm used
obtain path-consistent context-dependent IA-TCN, O(n3 W2 ) cost. Similarly, contextdependent reasoning applied PIDN networks (Pujari & Sattar, 1999), computational cost
specific reasoning algorithms PIDN constraints increased factor W2 . proposed
temporal algebra Section 3 applied tractable classes constraints, specific reasoning
algorithms management classes constraints also applied. computational
cost reasoning algorithms (which based combination intersection
operations constraints) increased polynomial factor W2 . instance, nondisjunctive metric constraints managed, TCA algorithm used closure algorithm
Section 7.1. algorithm obtain minimal context-dependent TCN computational
cost O(n 3 W2 ).

8. Conclusions
Several problems remain pending representation reasoning problems temporal constraints.
relation this, dealt reasoning complex qualitative quantitative constraints
time-points intervals, organized hierarchy alternative temporal
7

is, labels (Ri) associated disjunctions disjunctive constraints. Thus, Definition 3 applied
Put-Label-Context function. Therefore, distributive property lc lc hold disjunctive
constraints. However, relevant since reasoning processes applied.

81

fiREASONING INTERVAL POINT -BASED DISJUNCTIVE ETRIC CONSTRAINTS TEMPORAL CONTEXTS

contexts. described new-labeled temporal algebra, whose main elements labeled
disjunctive metric constraints, label sets associated elemental constraints, sets inconsistent
elemental constraints (I-L-Sets). temporal model presented able integrate qualitative
metric constraints time-points intervals. fact, symbolic metric constraint
intervals represented means disjunctive metric constraints time points set
I-L-Sets. model also able manage (non-binary) logical relations among elemental
constraints. reasoning algorithms described model based distributive property
composition intersection labeled constraints, guarantee consistency obtain
minimal TCN disjunctive metric point-based constraints. addition, special type global
labeled-consistent TCN also obtained.
Labeled constraints organized hierarchy alternative temporal contexts,
temporal reasoning processes performed contexts. Reasoning algorithms guarantee
consistency hierarchy contexts, maintain minimal context-dependent TCN, allow us
determine constraints hold context set alternative contexts. Thus,
reason hierarchy context-dependent constraints intervals, points unary durations
(Figure 17).
described features useful functionalities modeling important problems
temporal reasoning area. However, identified previous models. Therefore,
temporal model presented represents flexible framework reasoning complex, contextdependent, metric qualitative constraints time-points, intervals unary durations.
Dur(I 1) { [ 2 0 20], [50 60]}

I1 {b} 2
1 {[10 20], [100 130]} -2

Context W 1 1
-

1 {b m} 2
Dur(I 1 ) {[20 30], [50 100]}

1 {[100 100], [200 300]} I+ 2
Dur(I 1) {[20 30], [60 100]}

Context W 1

Context W 1 2
1 {[10 20], [100 200]} - 2
I- 1 {[0 100], [200 300]} + 2
Root-Context W 0

1 {[10 15], [120 200]}
1{ } 2
Context W 2

2

1{d} 2
1 {[10 10]} -2
Context W 2 1
Dur(I 1 ) = 50
1 { } I2
Context W 2 2

Figure 17: Context-dependent constraints intervals, time points unary durations
path-consistent algorithm used closure process labeled TCNs, like typical
TCA algorithm applied Allen (1983). path-consistent algorithm would obtain minimal
context-dependent TCN disjunctive metric constraints. proposed incremental
reasoning process. Thus, minimal (and consistent) context-dependent TCN assured new
assertion. incremental reasoning allows us detect whether new input constraint
inconsistent previously existing ones. useful problem constraints

82

fiBARBER

initially known successively deduced incremental independent process (Garrido et
al., 1999).
prototype proposed reasoning algorithms implemented Common-Lisp
available author. reasoning algorithms applied integrated architecture
planning scheduling processes (Garrido et al., 1999). Here, scheduling process
guarantee consistency alternative partial plan (i.e.: temporal constraints availability
resources operations) simultaneously planner generating partial plan (Srivastava
& Kambhampati, 1999). Thus, following main features needed:
Management disjunctive metric constraints. Particularly, planning scheduling
problems number disjuncts input constraints generally bounded l2 (i.e.: nonsimultaneous use resources). However, temporal dependencies constraints (i.e.:
non-binary constraints) appear. instance, operation durations dependent
order scheduled.
Incremental reasoning. process interactively guarantee consistency new
input temporal constraint (about resources, plans, ordering, objects) new step
deduced partial plan.
Management temporal contexts, context associated alternative plan
(action state). Reasoning algorithms simultaneously work different alternative
partial plans.
globally labeled-consistent (and minimal) TCN allows us determine consistent alternative
choices obtain optimal solutions plan. Additionally, proposed model
useful framework apply problems features also appear (Dousson et al., 1993;
Garcia & Laborie, 1996; Srivastava & Kambhampati, 1999; etc.).
computational cost reasoning algorithms exponential, due inherent complexity
management disjunctive constraints. However, management temporal contexts
increase complexity reasoning processes disjunctive constraints.
improvements decrease empirical cost reasoning algorithms proposed
paper. application algorithms handle explicit TCN (without making
derived constraints explicit) empirical evaluations several test cases study.
Moreover, reasoning algorithms applied temporal algebra presented, proposed
Section 4. hand, interesting identify subclasses labeled temporal algebra
size label sets bounded, identify tractable subclasses IA proposed
model. could also interesting identify expressive power I-L-Sets (and labeled
constraints) basis method described Jeavons, Cohen Cooper (1999). Here, I-LSet represents special derived constraint, expresses inconsistency set input
elemental constraints; is, special type disjunctive linear constraint (Jonsson & Bckstrm,
1996; Stergiou & Koubarakis, 1996).
proposed-labeled algebra (labeled constraints operations them) applied
temporal models (i.e.: classes temporal constraints, operations, reasoning
algorithms). this, operations labeled algebra (lc, lc, lc lc) defined
basis respective operations (, , ) models, reasoning
algorithms use operations defined labeled constraints ( lc, lc, lc lc).
83

fiREASONING INTERVAL POINT -BASED DISJUNCTIVE ETRIC CONSTRAINTS TEMPORAL CONTEXTS

requires reasoning algorithms based composition intersection operations.
Specifically, application proposed model tractable temporal constraints -as
identified Section 1 (Jonsson et al., 1999; Drakengren & Jonsson, 1997; Vilain, Kautz Van
Beek, 1986; etc.)- allows tractable reasoning process hierarchy temporal constraint
contexts.

Acknowledgements
work partially supported Generalitat Valenciana (Research Project #GV-1112/93)
Spanish Government (Research Project #CYCIT-TAP-98-0345). author would
sincerely like thank JAIR reviewers helpful comments suggestions previous
versions paper.

References
Allen, J. (1983). Maintaining knowledge temporal intervals. Comm ACM, 26, 11, 832843.
Badaloni, S., & Berati, M. (1996). Hybrid Temporal Reasoning Planning Scheduling.
Proceedings 3 Int. Workshop Temporal Representation Reasoning (TIME96).
Barber, F. (1993). metric time-point duration-based temporal model. ACM Sigart Bulletin,
4 (3), 30-40.
Barber, F., Botti, V., Onaindia, E., & Crespo, A. (1994). Temporal reasoning Reakt:
environment real-time knowledge-based systems. AICommunications, 7 (3), 175-202.
Brusoni, V., Console, L., & Terenziani, P. (1997). Later: Managing temporal information efficiently,
IEEE Expert, 12 (4), 56-64.
Cohen, D., Jeavons, P., & Koubarakis, M. (1996). Tractable disjunctive constraints. Proceedings.
3rd Int. Conf. Principles Practice Constraint Programming (CP96). Freuder,
E.C. (Ed.). Lecture Notes Computer Science, 1118, 297-307.
Cooper, M.C. (1990). optimal k-consistency algorithm. Artificial Intelligence, 41, 89-95.
Dean, T.L., & McDermott, D.V. (1987). Temporal data base management. Artificial Intelligence, 38,
1-55.
Dechter. R., Meiri, I., & Pearl, J. (1991). Temporal constraint networks. Artificial Intelligence, 49,
61-95.
Dechter, R. (1992). local global consistency. Artificial Intelligence, 55, 87-107.
Dousson, C., Gaborit, P., & Ghallab M. (1993). Situation Recognition: Representation
Algorithms. Proceedings 13th International Joint Conference Artificial Intelligence
(IJCAI93).
Drakengren, T., & Jonsson, P. (1997). Eight maximal tractable subclasses Allen's algebra
metric time. Journal A.I. Research, 7, 25-45.
84

fiBARBER

Freuder, E. C. (1978). Synthesizing constraint expressions. Comm. ACM, 21 (11), 958-965.
Freuder, E. C. (1982). sufficient condition backtrack-free search. Journal ACM, 29 (1),
24-32.
Garcia, F., & Laborie, P. (1996). Hierarchisation Seach Space Temporal Planning. New
Directions AI Planning, 217-232, IOS Press.
Garrido, A., Marzal, E., Sebasti, L., & Barber F. (1999). model planning scheduling
integration. Proceedings 8 th. Conference Spanish Association A.I.
(CAEPIA99).
Gerevini, A., & Schubert, L. (1995). Efficient algorithms qualitative reasoning time.
Artificial Intelligence, 74, 207-248.
Jeavons, P., Cohen, D., & Cooper M. (1998). Constraints, consistency closure. Artificial
Intelligence, 101, 251-268.
Jeavons, P., Cohen, D., Gyssens, M. (1999). determine expressive power constraints.
Constraints: Int. Journal, 4, 113-131.
Jonsson, P., & Bckstrm, C. (1996). linear-programming approach temporal reasoning.
Proceedings 13 th. National Conference Artificial Intelligence (AAAI96).AAAI
Press.
Jonsson, P., & Bckstrm, C. (1998). unifying approach temporal constraint reasoning. Artificial
Intelligence, 102, 143-155.
Jonsson, P., Drakengren, T., & Bckstrm, C. (1999). Computational complexity relating time
points intervals. Artificial Intelligence, 109, 273-295.
Kautz, H., & Ladkin, P. (1991). Integrating metric qualitative temporal reasoning. Proceedings
9th. National Conference Artificial Intelligence (AAAI91).AAAI Press.
Mackworth, A. K. (1977). Consistency networks relations, Artificial Intelligence, 8, 121-118,.
Meiri, I. (1996). Combining qualitative quantitative constraints temporal reasoning. Artificial
Intelligence, 87, 343-385.
Montanari, U. (1974). Networks constraints: fundamental properties applications picture
processing. Information Science, 7, 95-132.
Navarrete, I., & Marin, R. (1997). Qualitative temporal reasoning points durations.
Proceedings 15 th. International Joint Conference Artificial Intelligence (IJCAI-97).
Nebel, B., & Burckert, H.J. (1995). Reasoning temporal relations: maximal tractable subclass
Allen's interval algebra. Journal ACM, 42 (1), 43-66.
Pujari, A., & Sattar, A. (1999). new framework reasoning Points,. Intervals
Durations. Proceedings Int. Joint Conference Artificial Intelligence (IJCAI'99).
Schwalb, E., & Dechter, R. (1997). Processing disjunctions temporal constraints networks.
Artificial Intelligence, 93, 29-61.
85

fiREASONING INTERVAL POINT -BASED DISJUNCTIVE ETRIC CONSTRAINTS TEMPORAL CONTEXTS

Staab, S., & Hahn, U. (1998). Distance constraint arrays: model reasoning intervals
qualitative quantitative distances. Proceedings 12th Biennial Conference
Canadian Society Computational Studies Intelligence Advances Artificial
Intelligence (AI-98), Lecture Notes Artificial Intelligence, 1418, 334-348.
Srivastava, B., & Kambhampati, S. (1999). Efficient planning separate resource scheduling.
Proceedings AAAI Spring Symp. search strategy uncertainty incomplete
information. AAAI Press.
Stergiou, K., & Koubarakis, M. (1996). Tractable disjunctions Linear Constraints. Proceedings
2nd Int. Conf. Principles Practice Constraints Programming (CP96).
Freuder, E.C. (Ed.). Lecture Notes Computer Science, 1118, 297-307.
Stergiou, K., & Koubarakis, M. (1998). Bactracking algorithms disjunctions temporal
constraints. Proceedings 15 th. National Conference Artificial Intelligence (AAAI98). AAAI Press.
Van Beek, P. (1991).Temporal query processing indefinite information. Artificial Intelligence
Medicine, 3 (6), 325-339.
Van Beek, P., & Detcher R. (1995). minimality global consistency row convex
networks. Journal ACM, 42 (3), 543-561.
Van Beek, P., & Dechter, R. (1997). Constraint tightness looseness versus local global
consistency. Journal ACM, 44 (4), 549-566.
Vilain, M., Kautz, H., & Van Beek P. (1986). Constraint propagation algorithm temporal
reasoning. Proceedings 5Th. National Conference Artificial Intelligence (AAAI86).AAAI Press.
Wetprasit, R., Sattar A. (1998). Temporal representation qualitative quantitative information
points durations. Proceedings 15 th. National Conference Artificial
Intelligence (AAAI98). AAAI Press.
Yampratoom, E., & Allen, J. (1993). Performance temporal reasoning systems, ACM Sigart
Bulletin, 4, (3), 26-29.

86

fi
