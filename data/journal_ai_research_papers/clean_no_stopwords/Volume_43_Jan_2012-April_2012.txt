Journal Artificial Intelligence Research 43 (2012) 523-570Submitted 01/12; published 04/12Avoiding Escaping DepressionsReal-Time Heuristic SearchCarlos Hernandezchernan@ucsc.clDepartamento de Ingeniera InformaticaUniversidad Catolica de la Santsima ConcepcionCaupolican 491, Concepcion, ChileJorge A. Baierjabaier@ing.puc.clDepartamento de Ciencia de la ComputacionPontificia Universidad Catolica de ChileVicuna Mackenna 4860, Santiago, ChileAbstractHeuristics used solving hard real-time search problems regions depressions.regions bounded areas search space heuristic function inaccurate compared actual cost reach solution. Early real-time search algorithms,like LRTA , easily become trapped regions since heuristic values statesmay need updated multiple times, results costly solutions. State-of-the-artreal-time search algorithms, like LSS-LRTA LRTA (k), improve LRTA mechanismupdate heuristic, resulting improved performance. algorithms, however,guide search towards avoiding depressed regions. paper presents depressionavoidance, simple real-time search principle guide search towards avoiding statesmarked part heuristic depression. propose two ways depression avoidance implemented: mark-and-avoid move-to-border. implementstrategies top LSS-LRTA RTAA , producing 4 new real-time heuristicsearch algorithms: aLSS-LRTA , daLSS-LRTA , aRTAA , daRTAA . objective find single solution running real-time search algorithm once, showdaLSS-LRTA daRTAA outperform predecessors sometimes one ordermagnitude. four new algorithms, daRTAA produces best solutions givenfixed deadline average time allowed per planning episode. prove algorithms good theoretical properties: finite search spaces, find solution oneexists, converge optimal number trials.1. IntroductionMany real-world applications require agents act quickly possibly unknown environment. case, example, autonomous robots vehicles moving quicklyinitially unknown terrain (Koenig, 2001). also case virtual agentsgames (e.g., Warcraft, Starcraft), time dedicated game softwareperform tasks path-finding virtual agents limited. Actually, companies impose limits order 1 millisecond perform tasks (Bulitko, Bjornsson,Sturtevant, & Lawrence, 2011). Therefore, usually time plan full trajectories advance; rather, path-finding carried real-time fashion.Real-time search (e.g., Korf, 1990; Weiss, 1999; Edelkamp & Schrodl, 2011) standardparadigm solving search problems environment fully known advancec2012AI Access Foundation. rights reserved.fiHernandez & Baieragents act quickly. Instead running computationally expensive proceduregenerate conditional plan outset, real-time algorithms interleave planningexecution. such, usually run computationally inexpensive lookahead-update-actcycle, search carried select next move (lookahead phase), learningcarried (update phase), finally action executed may involve observingenvironment (act phase). Like standard search (Hart, Nilsson, & Raphael, 1968),use heuristic function guide action selection. environment unveiled,algorithm updates internal belief structure search space, updating (i.e.learning) heuristic value states. lookahead-update-act cycle executedsolution found.Early heuristic real-time algorithms like Learning Real-Time (LRTA ) RealTime (RTA ) (Korf, 1990) amenable settings environment initiallyunknown. algorithms perform poorly presence heuristic depressions(Ishida, 1992). Intuitively, heuristic depression bounded region search spaceheuristic inaccurate respect heuristic values statesborder region. agent controlled LRTA RTA enters regionsearch space conforms heuristic depression usually become trapped.order leave heuristically depressed region, agent need visit updatemany states region, potentially several times. Furthermore, many applications,games, behavior agent depression may look irrational thusundesirable.State-of-the-art heuristic real-time search algorithms suitable applicationsinitially unknown environments capable escaping heuristic depressionsquickly LRTA RTA . performing lookahead search,learning, combination both. search involves selecting action lookingfarther away search space. learning usually involves updating heuristicseveral states single iteration. many algorithms use one combinationtechniques (e.g., Hernandez & Meseguer, 2005; Bulitko & Lee, 2006; Koenig &Likhachev, 2006b; Hernandez & Meseguer, 2007; Rayner, Davison, Bulitko, Anderson, &Lu, 2007; Bjornsson, Bulitko, & Sturtevant, 2009; Koenig & Sun, 2009). result,algorithms perform better LRTA , spending fewer moves trapped depressions.Two algorithms representative state art real-time search initiallyunknown environments LSS-LRTA (Koenig & Sun, 2009) RTAA (Koenig &Likhachev, 2006a). algorithms generalize LRTA performing searchlearning episode. algorithms shown perform wellpractice. However, despite use elaborate techniques, may still performpoorly presence heuristic depressions. may sometimes relyincreasing heuristic value states inside depressions mechanism exit them.paper study techniques allow us improve performance real-timesearch algorithms making explicitly aware heuristic depressions,guiding search order avoid and, therefore, escape depressions. Specifically,contributions paper follows.provide new empirical evidence shows RTAA outperforms LSS-LRTAgame map benchmarks first trial, means wheneversingle chance run one real-time heuristic search algorithms solve search524fiAvoiding Escaping Depressions Real-Time Heuristic Searchproblem, RTAA finds better solutions LSS-LRTA making searcheffort. Before, Koenig Likhachev (2006b) shown similar performance resultsmazes. important since LSS-LRTA , RTAA , algorithmreceived attention real-time heuristic search community.paper consider incorporating techniques LSS-LRTA RTAA .propose definition cost-sensitive heuristic depressions, generalnotion Ishidas (1992) notion heuristic depression since incorporates actioncosts. illustrate depressions better describe regions searchspace real-time search algorithms get trapped.propose simple principle actively guide search towards avoiding cost-sensitiveheuristic depressions call depression avoidance, together two strategiesimplement depression avoidance incorporated state-of-the-artreal-time heuristic search algorithms: mark-and-avoid move-to-border.propose four new real-time search algorithms; two based mark-and-avoid, aLSSLRTA , aRTAA , two based move-to-border: daLSS-LRTA , daRTAA .algorithms result implementing depression avoidance top RTAALSS-LRTA .prove algorithms desirable properties: heuristic consistencypreserved, terminate solution exists, eventually convergeoptimal solution running sufficiently large, finite number trials.carry extensive empirical evaluation algorithms deployed gamebenchmarks mazes. evaluation shows algorithms outperform existing algorithms game maps mazes. little time allowedlookahead phase, two algorithms, daLSS-LRTA daRTAA , outperformexisting ones order magnitude.contributions paper published conference papers(Hernandez & Baier, 2011d, 2011c). article includes new materialpresented before. particular:describe evaluate daLSS-LRTA , algorithm presented articlefirst time.include full proofs termination results (Theorem 6), new theoreticalresult (Theorem 7) convergence algorithms.extend previously published empirical results including maze benchmarks,previously considered, including game domainsproblems.Finally, discuss detail scenarios techniques may performparticularly good.525fiHernandez & Baierrest paper organized follows. Section 2 explain basic conceptsreal-time search. continue presenting LSS-LRTA RTAA , extend resultsavailable literature comparing game maps. continue elaboratingconcept heuristic depression. describe strategies implementingdepression avoidance algorithms result applying LSSLRTA RTAA . continue detailed theoretical experimental analysis.Then, present discussion approach evaluation. finish summary.2. Preliminariessearch problem P tuple (S, A, c, s0 , G), (S, A) digraph representssearch space. set represents states arcs represent available actions.contain elements form (x, x). addition, cost function c : 7 R+associates cost available actions. Finally, s0 start state,G set goal states. paper assume search spaces undirected; i.e.,whenever (u, v) A, (v, u). Furthermore, c(u, v) = c(v, u), (u, v) A.successors state u defined Succ(u) = {v | (u, v) A}. Two statesneighbors successors other.heuristic function h : 7 [0, ) associates state approximation h(s)cost path goal state. denote h (s) cost optimal pathreach solution s.heuristic h consistent h(g) = 0 g G h(s) c(s, s0 ) + h(s0 )states s0 Succ(s). h consistent C(s, s0 ) cost pathtwo states s0 , h(s) C(s, s0 ) + h(s0 ). Furthermore, h consistent easyprove also admissible; i.e., h(s) underestimates h (s). detailsdefinitions, refer reader book authored Pearl (1984).refer h(s) h-value assume familiarity algorithm (Hartet al., 1968): g(s) denotes cost path start state s, f (s) definedg(s) + h(s). f -value g-value refer f (s) g(s) respectively.2.1 Real-Time Searchobjective real-time search algorithm make agent travel initialstate goal state performing, moves, amount computation boundedconstant. example situation path-finding priori unknown grid-like environments.agent sufficient memory store current belief structuresearch space. addition, free-space assumption (Zelinsky, 1992; Koenig, Tovey, &Smirnov, 2003) taken: environment initially assumed obstacle-free. agentcapable limited form sensing: obstacles neighbor states detected.obstacles detected, agent updates map accordingly.Many state-of-the-art real-time heuristic search algorithms describedpseudo-code Algorithm 1. algorithm iteratively executes lookahead-update-actcycle goal reached. lookahead phase (Line 46) determines next statemove to, update phase (Line 7) updates heuristic, act phase (Line 8)moves agent next position. lookahead-update part cycle (Lines 47)referred planning episode throughout paper.526fiAvoiding Escaping Depressions Real-Time Heuristic SearchAlgorithm 1: generic real-time heuristic search algorithm12345678910Input: search problem P , heuristic function h.Side Effect: agent moved initial state goal state trajectory existsh0 hscurrent s0scurrent 6 GLookAhead ()Open = return no-solutionsnext Extract-Best-State()Update ()move agent scurrent snext path identified LookAhead. Stopaction cost along path updated.scurrent current agent positionupdate action costs (if increased)generic algorithm three local variables: scurrent stores current positionagent, c(s, s0 ) contains cost moving state successor s0 , hh(s) contains heuristic value s. three variables may change time.path-finding tasks, environment initially unknown, initial value cobstacles assumed; i.e., c(s, s0 ) < two neighbor states s, s0 . initialvalue h(s), every s, given parameter.generic algorithm receives input search problem P , starts initializinguseful variables (Lines 12). h0 records initial value h, states P ,scurrent stores initial position agent, s0 . assume cost arccannot decrease. particular, arc costs increase infinity obstacle discovered.lookahead phase (Lines 46), algorithm determines proceed next.Lookahead() procedure Line 4 implements bounded search procedure expandsstates current state scurrent . set states generated call referredlocal search space. Different choices made implement procedure. RealTime (RTA ) Learning Real-Time (LRTA )two early algorithms proposedKorf (1990) modern real-time search algorithms run searchcurrent state fixed depth (e.g., Bulitko & Lee, 2006). Another common optionrun bounded search; choice taken Local Search Space LRTA (LSSLRTA ) (Koenig & Sun, 2009), Real-Time Adaptive (RTAA ) (Koenig & Likhachev,2006b). Algorithm 2 shows pseudo-code bounded . Note k statesexpanded, k parameter algorithm usually referred lookaheadparameter. pseudo code generic real-time search algorithm assumes callLookahead() stores frontier local search space Open, and, moreover,goal state found search, state removed frontier (inbounded pseudo-code guaranteed condition Line 7).last step lookahead phase (Line 6, Algorithm 1), variable containingnext state move to, snext , assigned. Here, algorithms select statesearch frontier estimated closest goal state. lookahead used,state usually corresponds state minimum f -value Open. Thus -basedlookahead algorithms use Algorithm 3 implement Extract-Best-State() function.527fiHernandez & BaierAlgorithm 2: Bounded lookahead12345678910111213141516procedure ()g(s)g(scurrent ) 0OpenInsert scurrent Openexpansions 0s0 Open minimum f -value s0 6 G expansions < kRemove state smallest f -value OpenInsert Closeds0 Succ(s)g(s0 ) > g(s) + c(s, s0 )g(s0 ) g(s) + c(s, s0 )s0 .back =s0 Open remove s0 OpenInsert s0 Openexpansions expansions + 1Algorithm 3: Selection Best State used LSS-LRTA , RTAA ,algorithms.12procedure Extract-Best-State ()return argmins0 Open g(s0 ) + h(s0 )update phase (Line 7, Algorithm 1), heuristic states searchspace updated value better estimate true cost reach solution,staying consistent. exploring states vicinity scurrent , algorithmgains information heuristic value number states. Using information,h-value scurrent potentially states search spacecanupdated way reflect better estimation cost reach solution.Since update heuristic states updated value closer truecost, phase also referred learning phase.literature describes several ways one implement updateheuristic, e.g., mini-min (e.g., Korf, 1990), max mins (Bulitko, 2004), heuristicbounded propagation (Hernandez & Meseguer, 2005). learning rulesrelevant paper, however, implemented LSS-LRTA RTAA .described detail following subsections.Finally, learning, agent attempts move state selectedExtract-Best-State() function, snext . implementations, path selectedstate computed already Lookahead() procedure (in case Algorithm 2,path reconstructed using back pointer set Line 13). environment known advance, agent always move destination. However,environment known advance, process fail (in path-finding,occur due discovery obstacle). obstacle found, assumeagent stops moving soon detected obstacle. cases, algorithm528fiAvoiding Escaping Depressions Real-Time Heuristic Searchupdate memory regarding environment, typically involves updating costfunction. pseudo-code, reflected Line 10.3. LSS-LRTA RTAAdescribe LSS-LRTA RTAA , two state-of-the-art real-time heuristic searchalgorithms relevant paper. make two small contributions understanding two algorithms. First, experimental comparisonbenchmarks considered before. Second, prove two theoretical resultsaim understanding differences update mechanisms (Propositions 12). knowledge, none results appear literature.3.1 LSS-LRTALocal search space LRTA (LSS-LRTA ) first introduced Koenig (2004), laterpresented detail Koenig Sun (2009). instance Algorithm 1. lookahead procedure bounded search (Algorithm 2). next state move corresponds state Open lowest f -value; i.e., uses Algorithm 3 implementExtract-Best-State().LSS-LRTA updates values state local search space wayh(s) assigned maximum possible value guarantees consistencystates Open. implementing Update() procedure modified Dijkstras algorithm (Algorithm 4). Since value h raised maximum, updatemechanism LSS-LRTA makes h informed get given current knowledgesearch space, maintaining consistency.Algorithm 4: LSS-LRTA Modified Dijkstras Procedure. assume Open listqueue ordered h-value.123456789procedure ModifiedDijkstra ()state Closed h(s)Closed 6=Extract minimum h-value OpenClosed delete Closeds0 Succ(s0 )s0 Closed h(s0 ) > c(s0 , s) + h(s)h(s0 ) c(s0 , s) + h(s)s0 6 Open Insert s0 OpenAlgorithm 5: RTAA Update Procedure1234procedure Update ()f minsOpen g(s) + h(s)Closedh(s) f g(s)529fiHernandez & Baier3.2 RTAAReal-Time Adaptive (RTAA ) proposed Koenig Likhachev (2006b).instance Algorithm 1. lookahead phase identical LSS-LRTA :bounded followed selecting state lowest f -value Open next statemove to. However uses simpler learning mechanism based update ruleincremental search algorithm Adaptive (Koenig & Likhachev, 2006a). Thus,updates heuristic value states interior local search space (i.e.,stored variable Closed) using f -value best state Open. procedureshown Algorithm 5.RTAA update procedure considerably faster practice LSS-LRTA .Obtaining lowest f -value state Open done constant timeimplemented binary heaps. that, algorithm simply iteratesstates Closed. worst-case performance O(|Closed|). hand,LSS-LRTA update procedure first needs convert Open priority queue orderedh may, worst case, need extract |Open| + |Closed| elementsbinary heap. addition, expands node ever extracted priorityqueue. time complete operations, worst case Texp N + Tb N log N ,N = |Open| + |Closed|, Texp time taken per expansion, Tb constantfactor associated extraction binary heap. worst-case asymptotic complexityextraction thus O(N log N ). However, since usually deal small N maycase term Texp N dominates expression time.prove heuristic values RTAA learns may less accurateLSS-LRTA . state formally, introduce notation. Let hn ,n > 0, denote value h variable start iteration n main algorithm,or, equivalently, right update phase iteration n 1. also denoteheuristic function given input h0 . Let kn (s, s0 ) denote cost optimal paths0 traverses states Closed ending s0 .Proposition 1 Let state Closed right call returned n-thiteration LSS-LRTA . Then,hn+1 (s) = min kn (s, sb ) + hn (sb ).sb Open(1)Proof: show value h(s) computed modified Dijkstra algorithmstate corresponds minimum cost reaching node certain stateparticular graph G. modified Dijkstra procedure seen run standardDijkstra algorithm (e.g., Cormen, Leiserson, Rivest, & Stein, 2001) graph.First observe procedure differs standard Dijkstra algorithmnon-singleton set states, namely Open, initialized finite value h.standard Dijkstra algorithm, hand, source node initializedcumulative cost 0 whereas remaining nodes initialized .facts mind, straightforward see run modified Dijkstrainterpreted run standard Dijkstra algorithm node sstart directed graphG that:nodes exactly Open Closed plus distinguished node sstart .530fiAvoiding Escaping Depressions Real-Time Heuristic Searchcontains arc (u, v) cost c arc (v, u) cost c searchgraph P one v u Open.contains arc form (sstart , s) cost h(s) Open.contains arcs.running Dijkstra algorithm sstart G, obtain, node Gcost optimal path sstart s. interpret cost h(s), s,Equation 1 holds, finishes proof.RTAA prove sightly different result.Proposition 2 Right call returns n-th iteration RTAA , letstate lowest f -value Open, let state Closed. Then,hn+1 (s) min kn (s, sb ) + hn (sb ).sb Open(2)However, hn consistent path found scurrent ,hn+1 (s) = min kn (s, sb ) + hn (sb ).sb Open(3)Proof: (2), use fact heuristic consistent, remains consistentRTAA iteration (a fact proven Koenig & Likhachev, 2006a), writeinequality hn+1 (s) minsb Open kn (s, sb ) + hn+1 (sb ). note every state sbOpen holds hn (s) = hn+1 (s), since heuristic values states Openupdated. Substituting hn+1 (s) inequality, obtain required result.(3), use fact proven Hart et al. (1968) : consistent heuristicsused, g(s) contains cost cheapest path start state rightextracted Open (Line 8 Algorithm 2).run consistent heuristic, state s0 along (optimal) pathfound scurrent ,g(s0 ) = kn (scurrent , s0 ),0(4)0g(s ) = kn (scurrent , ) + kn (s , ).(5)RTAA update rule states that:hn+1 (s0 ) = f (s ) g(s0 ) = hn (s ) + g(s ) g(s0 )(6)Substituting (4) (5) (6), obtain hn+1 (s0 ) = kn (s0 , ) + hn (s ). Finally,observekn (s0 , ) + h(s ) = min kn (s0 , sb ) + hn (sb ).sb OpenIndeed, Open kn (s0 , ) + h(s ) > kn (s0 , ) + hn (s ),adding g(s0 ) sides inequality, would f (s ) > f (s ),contradicts fact state lowest f -value Open. concludehenceforth hn+1 (s0 ) = minsb Open kn (s0 , sb ) + hn (sb ). finishes proof.531fiHernandez & BaierProposition 2 implies that, using consistent heuristics, RTAA update may yieldless informed h-values LSS-LRTA . However, least stateslocal search space, final h-values equal LSS-LRTA , henceinformed given current knowledge search space.Koenig Likhachev (2006a) show fixed value lookahead parameter, quality solutions obtained LSS-LRTA better averageobtained RTAA path-finding tasks mazes. due fact LSSLRTA heuristic informed time RTAA . However, alsoshowed given fixed time deadline per planning episode, RTAA yields better solutions LSS-LRTA . essentially due fact RTAA update mechanismfaster: fixed deadline, higher lookahead parameter used RTAALSS-LRTA .extend Koenig Likhachevs experimental analysis running comparisontwo algorithms game maps. Table 1 shows average results LSS-LRTARTAA ran 12 different game maps. map, generated 500 random test cases.Observe, example, deadline 0.0364 milliseconds imposed per planningepisode choose run RTAA lookahead k = 128, whereas chooserun LSS-LRTA lookahead k = 64. parameters, RTAA obtainssolution 36% cheaper LSS-LRTA does. Figure 1 shows average solution costversus time per episode. slopes curves suggest rate RTAAimproves solutions better LSS-LRTA , time per episode given.conclusion RTAA seems superior LSS-LRTA time actually important.thus confirm wider range tasks that, time per episode matters, RTAAbetter LSS-LRTA . findings important mazes (for previousevaluations existed) problems particular structure, resultsnecessarily generalize types problems.Although conclude RTAA algorithm superior LSS-LRTAcomes finding good solution quickly, interesting note recent researchreal-time heuristic search focused mainly extending using LSS-LRTA (see e.g.,Bulitko, Bjornsson, & Lawrence, 2010; Bond, Widger, Ruml, & Sun, 2010; Hernandez &Baier, 2011d; Sturtevant & Bulitko, 2011), RTAA rarely considered. Since LSSLRTA seems algorithm active study community, paperapply techniques algorithms.4. Heuristic Depressionsreal-time search problems heuristics usually contain depressions. identificationdepressions central algorithm. Intuitively, heuristic depression boundedregion search space containing states whose heuristic value low respectheuristic values states border depression. Depressions exist naturallyheuristics used along real-time heuristic search algorithms. seen above,real-time heuristic algorithms build solutions incrementally, updating heuristic valuesassociated certain states information gathered environment.Ishida (1992) gave constructive definition heuristic depressions. constructionstarts node heuristic value equal less532fiAvoiding Escaping Depressions Real-Time Heuristic SearchRTAA*LSS-LRTA*k Avg. Cost Time/ep Exp/ep Per/ep Time Avg. Cost Time/ep Exp/ep Per/ep Time1 1,146,014 0.00041.06.1 447.9 1,146,014 0.00128.714.8 1,259.62919,410 0.00062.09.4 475.4625,693 0.002013.729.3 979.44626,623 0.00114.017.3 468.8372,456 0.003421.354.3 818.18363,109 0.00218.034.1 383.7227,526 0.005833.8102.4 653.616188,346 0.004016.070.1 269.1127,753 0.010256.1193.5 459.93295,494 0.007832.0 152.9 192.872,044 0.018798.7397.7 345.36448,268 0.015963.9 361.3 145.740,359 0.0364 184.9903.4 279.612825,682 0.0326 126.4 932.3 125.822,471 0.0750 370.1 2,338.1 258.225613,962 0.0647 236.8 2,351.8 125.612,264 0.1534 733.6 6,003.8 272.25127,704 0.1078 377.6 4,616.7 131.67,275 0.2620 1,207.5 11,548.9 312.4Table 1: Average results 12 game maps. lookahead value k, reportsolution cost per test case (Avg. Cost), four measures efficiency: runtimeper planning episode (Time/ep) milliseconds, number cell expansions perplanning episode (Exp/ep), number heap percolations per planning episode(Per/ep) runtime per test case (Time) milliseconds. resultsobtained using Linux machine Intel Xeon CPU running 2GHz 12GB RAM.Cost vs Time per Episode (Games)Average Solution Cost (log-scale)1,000,000RTAA*LSS-LRTA*500,000100,00010,00000.050.10.150.20.250.3Time per Planning Episode msecFigure 1: Average solution cost obtained LSS-LRTA RTAA versus planning timeper episode 12 game maps.533fiHernandez & Baiersurrounding states. region extended adding state border statesresulting region heuristic value lower equal statesborder. result, heuristic depression maximal connected component statesstates boundary heuristic value greater equalheuristic value state D.known algorithms like LRTA behave poorly presence heuristicdepressions (Ishida, 1992). see this, assume LRTA run lookahead depthequal 1, expands current state, leaving immediate successorssearch frontier. Assume visits state depressionsolution node lies outside depression. exit depressed region agent must followpath interior depressed region, say, s1 . . . sn , finally choosing stateborder region, say se . visiting sn , agent chooses se next move,means se minimizes estimated cost reach solution among neighborssn . problems uniform action costs, happen h(se ) lower equalheuristic value neighbors sn . fact actually meansdepression region search space longer exists, happenheuristic values states originally depressed region updated (increased).LRTA , update process may quite costly: worst case statesdepression may need updated state may need updated several times.Ishidas definition is, nonetheless, restrictive. fact, take accountcosts actions needed move interior depression exterior.closed region states may unrealistically low heuristic values even though heuristicvalues interior greater ones border. propose intuitivenotion depression costs taken account. formal definition follows.Definition 1 (Cost-sensitive heuristic depression) connected component statescost-sensitive heuristic depression heuristic h iff state everystate s0 6 neighbor state D, h(s) < k(s, s0 ) + h(s0 ), k(s, s0 ) denotescost cheapest path starts s, traverses states D, ends s0 .Cost-sensitive heuristic depressions better reflect regions agent controlledalgorithms LRTA get trapped. illustrate this, consider two 4-connectedgrid-world problems Figure 2. Gray cells conform Ishida depression. unionyellow gray cells conform cost-sensitive heuristic depression. Suppose agentsinitial position lower-right corner Ishida depression (C4 Figure 2(a),C7 Figure 2(b)). Assume ties broken priorities, givenhigher lower, are: down, left, up, right. initial state,situation (a) situation (b), agent controlled LRTA visit every statecost-sensitive heuristic depression reaching goal. Indeed, cells costsensitive depression adjacent obstacle visited exactly 3 times,cells adjacent obstacle visited 2 times, agent escapes depression,thus performance LRTA described linear function sizecost-sensitive depression.interesting note problems like ones shown Figure 2, sizeIshida depression remains width grid varies. Thus, size534fiAvoiding Escaping Depressions Real-Time Heuristic Search1BC2345316765426543154320 GBC2345678109876549876543187654320 G(a)392(b)Figure 2: 4-connected grid-like search space unitary costs. Black cells obstacles.cell G goal cell. Cells show h-value (Manhattan distance).Ties broken giving priority movement, left, up,right. initial position agent situation (a) C4, cellsvisited agent controlled LRTA are: C3, C2, C1, B1, B2, B3, B4, C4,C3, B3, C3, C2, B2, C2, C1, B1, C1, B1, B2, B3, B4, A4, A5, A6, B6, C6.solution found (b) analogous.Ishida depression correlated performance LRTA . hand,size cost-sensitive heuristic depression predictor cost solution5. Depression Avoidancemajor issue solving real-time search problems presence heuristic depressions.State-of-the-art algorithms able deal problem essentially extensivelearning and/or extensive lookahead. lookahead, chances stateoutside depression eventually selected move to. hand, learningheuristic values several states time, fewer movements might needed orderraise heuristic values states interior depression high enough makedisappear. such, LSS-LRTA , run high value lookahead parameterexits depressions quickly LRTA run search depth equal 1 tworeasons: (1) heuristic function increases states quickly (2)high value lookahead parameter sometimes possible escapedepression one step.Besides already discussed LSS-LRTA RTAA , many algorithms described literature capable extensive lookahead learning. lookaheadability LRTS (Bulitko & Lee, 2006), TBA (Bjornsson et al., 2009) parametrized.using algorithms LRTA (k) (Hernandez & Meseguer, 2005), PLRTA (Rayneret al., 2007) LRTALS (k) (Hernandez & Meseguer, 2007) one increase numberstates updated based parameter. None algorithms however aware depressions; design simply allows escape ability lookahead,learning, combination both. Later, Section 9, give detailed overviewrelated work.improve search performance algorithms avoid depressions, principle calldepression avoidance. Depression avoidance simple principle dictates search535fiHernandez & Baierguided away states identified heuristic depression.many ways one could conceive implementation principle real-timeheuristic search algorithm. present two alternative realizations principlewithin state-of-the-art RTAA LSS-LRTA algorithms. result, proposefour new real-time search algorithms, good theoretical properties.5.1 Depression Avoidance via Mark-and-Avoidsubsection presents first possible realization depression avoidance callmark-and-avoid. strategy, extend update phase mark statesprove belong heuristic depression. modify selection best state(i.e., Extract-Best-State() function) select states marked; i.e., statesyet proven part depression.aLSS-LRTA version LSS-LRTA avoids depressions via mark-and-avoid.obtained implementing Update() function using Algorithm 6 implementingExtract-Best() function Algorithm 7. two differencesupdate procedure LSS-LRTA s. first initialization updated flagLines 23. second Line 7, sets s.updated true heuristic value hchanges result update process. following section, formally provemeans inside cost-sensitive heuristic depression (Theorem 5).Algorithm 6: Modified Dijkstra Procedure used aLSS-LRTA .123456789101112procedure ModifiedDijkstra ()first runs.updated f alse/* initialization update flag */Closed h(s)Closed 6=Extract minimum h-value Openh(s) > h0 (s) s.updated = trueClosed delete Closeds0 Succ(s0 )s0 Closed h(s0 ) > c(s0 , s) + h(s)h(s0 ) c(s0 , s) + h(s)s0 6 Open Insert s0 Openselect next state snext , aLSS-LRTA chooses state lowest f -valueOpen marked depression. state exist,algorithm selects state lowest f -value Open, like LSS-LRTA would do.Depending implementation, worst-case complexity new selection mechanism may different Algorithm 3. Indeed, Open list implementedbinary heap (as case), worst-case complexity Algorithm 7 O(N log N )N size Open. heap ordered f -value.hand worst-case complexity Algorithm 3 using binary heaps O(1).experimental results observe, however, significant degradation performancedue factor.536fiAvoiding Escaping Depressions Real-Time Heuristic SearchAlgorithm 7: Selection next state used aLSS-LRTA aRTAA123456function Extract-Best-State ()Open contains s.updated = f alseargmins0 Opens0 .updated=f alse g(s0 ) + h(s0 )elseargmins0 Open g(s0 ) + h(s0 )return ;Example Figure 3 shows example illustrates difference LSS-LRTAaLSS-LRTA lookahead parameter equal two. 4 search episodes,observe aLSS-LRTA avoids depression, leading agent position 2steps closer goal LSS-LRTA .Algorithm 8: aRTAA Update Procedure1234567procedure Update ()first runs.updated f alsef f -value best state OpenClosedh(s) f g(s)h(s) > h0 (s) s.updated true/* initialization update flag */aLSS-LRTA reference, straightforward implement mark-and-avoidstrategy RTAA . update phase resulting algorithm, aRTAA , likeRTAA extended mark states depression (Algorithm 8). selectionbest state move done way aLSS-LRTA , i.e., Algorithm7. result aRTAA version RTAA aims avoiding depressions usingmark-and-avoid.5.2 Depression Avoidance via Move-to-BorderMove-to-border finely grained implementation depression avoidance. illustrate differences, consider that, lookahead, state frontierlocal search space s.updated false. Intuitively, situationagent trapped heuristic depression. case, aLSS-LRTA behaves exactlyLRTA since states search frontier marked. Nevertheless, cases,would like movement agent still guided away depression.situations states frontier local search space alreadyproven members depression, move-to-border strategy attempts movestate seems closer border depression. next state, strategy choosesstate best f -value among states whose heuristic changed least.intuition behind behavior follows: assume (s) difference actualcost reach solution state initial heuristic value state s. Then,s1 state close border depression s2 state farther awayborder deep interior D, (s2 ) (s1 ), heuristic s2537fiHernandez & BaierLSS-LRTA12341Iteration 12G31C21 5 032 7 15443556C 4G34162G341 6B 54 1 66 5 76 2 8620 4 1 6C 4 6 5 731 6 2 86G5G1605162541BB1 7 2 970 5 1 75 7 6 8C 631504151Iteration 42GB1 5 0 343 52 7 1 554 6B1Iteration 32 6 1 431 4 0 23 5 2 44B4C 4C3B2 6 1 4431 4 0 23 5 2 41Iteration 22BCaLSS-LRTAC2G347577 2 9776GFigure 3: First 4 iterations LSS-LRTA (left) aLSS-LRTA (right) lookaheadequal 2 4-connected grid world unitary action costs, initialstate D2, goal D4. Numbers cell corners denote g-value (upperleft), f -value (upper right), h-value (lower left), new h-value expandedcell update (lower right). cells closed list showfour numbers. Cells generated expanded (i.e., Open) show threenumbers, since h-values updated. Triangles (N) denote statesupdated flag set true search episode. heuristic usedManhattan distance. assume ties broken choosing first rightbottom left top adjacent cell. position agentgiven dot. grid cell shaded (gray) blocked cell agentsensed yet. grid cell black blocked cell agentalready sensed. best state chosen move agent lookahead searchpointed arrow.538fiAvoiding Escaping Depressions Real-Time Heuristic SearchaLSS-LRTA15Iteration 1234BCCEG52344 6 5 7 6 8B4 6 5 7C3 7 4 85234 6 5 7C3 7 4 834BC282748G1234224 6 5 7 624 6 543 7 45BC282748EEG152344 6 5 7 6 8B4 8 5 7C3 7 4 8G1234224 6 5 7 644 8 543 7 45BC282748EEG12344 6 5 7 6 8B4 8 5 9C3 7 4 8E2224 6 5 7 624 6 543 7 4544 6 5 7 6 8BIteration 184G1EG153EIteration 17224 6 554 6 51Iteration 161BEIteration 15daLSS-LRTAG15BC23224 6 5 7 644 8 543 7 44284948EGGFigure 4: Iterations 1 1518 aLSS-LRTA (left) daLSS-LRTA (right)lookahead equal 1 4-connected grid, analogous previous example,objective cell E2. iterations 1 14 algorithms executeway. Numbers cells correspond initial h-value (lower-left), currenth-value (lower-right), difference two amounts (upper-right).Triangles (N) denote states whose heuristic value updated.539fiHernandez & Baierimprecise s1 . execution time, h estimate actual costreach solution.daLSS-LRTA daRTAA differ, respectively, LSS-LRTA RTAAselection next state move (i.e., function Extract-Best()) implementedvia Algorithm 9. Note worst case complexity algorithm O(N log N ),N size Open binary heaps used.Algorithm 9: Selection next state daRTAA daLSS-LRTA .12345678function Extract-Best-State ()minOpen 6= min 6= 0Remove state sb smallest f -value Openh(sb ) h0 (sb ) < minsbmin h(sb ) h0 (sb )returnFigure 4 illustrates differences aLSS-LRTA daLSS-LRTA . algorithms execute way if, lookahead phase, state Open whoseheuristic value updated. However, case (i.e.,algorithm trapped depression), daLSS-LRTA move seems closerborder depression. example Figure 4, iteration 15, algorithmchooses B4 instead C3 since B4 state h-value changed least.iteration 18, daLSS-LRTA move cells less learning carriedthus exit depression quickly.new algorithms presented section closely related. Table 2 showsschematic view different components algorithm, complexityinvolved algorithms.6. Theoretical Analysissection analyze theoretical properties algorithms propose.prove algorithms also satisfy desirable properties holdancestors. start presenting theoretical results proven using existingproofs available literature; among them, show consistencyheuristic maintained algorithms run time. continue resultsneed different proofs; particular, termination convergence optimal solution.before, use hn refer value variable h start iteration n (h0 ,thus, denotes heuristic function given parameter algorithm). Similarly,cn (s, s0 ) cost arc s0 . Finally, kn (s, s0 ) denotes costoptimal path s0 traverses nodes Closed ending s0respect cost function cn .first establish h initially consistent, h non-decreasing time.important property since means heuristic becomes accuratetime.540fiAvoiding Escaping Depressions Real-Time Heuristic SearchAlgorithmLSS-LRTAaLSS-LRTAdaLSS-LRTARTAAaRTAAdaRTAAUpdate PhaseAlgorithmTime (heaps)Modified Dijkstra(Algorithm 4)Modified DijkstraMarking (Algorithm 6)Modified Dijkstra(Algorithm 4)O(M log )Updatebestf -value(Algorithm 5)Updatebestf -valueplusmarking(Algorithm 8)Updatebestf -value(Algorithm 5)O(N )O(M log )O(M log )Next State SelectionAlgorithmTime (heaps)Best state Open(Algorithm 3)BestunmarkedstateOpen(Algorithm 7)State Openchangedleast (Algorithm 9)Best state Open(Algorithm 3)(1)O(L log L)O(L log L)(1)O(N )BestunmarkedstateOpen(Algorithm 7)O(L log L)O(N )State Openchangedleast (Algorithm 9)O(L log L)Table 2: Procedures used update phase selection next statealgorithms discussed paper. Worst-case time complexityprocedure included assuming Open list implemented binary heap.corresponds |Open| + |Closed|, N equal |Closed|, L |Open|.541fiHernandez & BaierTheorem 1 hn consistent respect cost function cn , hn+1 (s) hn (s)n along execution aLSS-LRTA daLSS-LRTA .Proof: Assume contrary, i.e., state hn (s) > hn+1 (s). Statemust Closed, since states whose h-value may updated. such,Proposition 1, hn+1 (s) = kn (s, sb ) + hn (sb ), state sb Open.However, since hn (s) > hn+1 (s), conclude that:hn (s) > kn (s, sb ) + hn (sb ),contradicts fact hn consistent. thus conclude h-valuecannot decrease.Theorem 2 hn consistent respect cost function cn , hn+1 (s) hn (s)n along execution aRTAA daRTAA .Proof: Assume contrary, i.e., state hn (s) > hn+1 (s). Statemust Closed, since states whose h-value may updated.update rule set value hn+1 (s) f (s0 ) g(s) s0 Open, i.e.,hn+1 (s) = f (s0 ) g(s) = g(s0 ) + hn (s0 ) g(s).since hn (s) > hn+1 (s), that:hn (s) > g(s0 ) + hn (s0 ) g(s).Reordering terms, obtain that:hn (s) + g(s) > g(s0 ) + hn (s0 ),means f -value greater f -value s0 . known however, run consistent heuristic, expand nodes non-decreasing f -values.conclude, thus, s0 must expanded s. Since s0 Open,cannot Closed, contradicts initial assumption. thus concludeh-value cannot decrease.Theorem 3 hn consistent respect cost function cn , hn+1 consistentrespect cost function cn+1 along execution aLSS-LRTA daLSS-LRTA .Proof: Since update procedure used aLSS-LRTA , daLSS-LRTA LSS-LRTAupdate variable h exactly way, proof Koenig Sun (2009)reused here. However, provide rather simpler proof Section B.1.Theorem 4 hn consistent respect cost function cn , hn+1 consistentrespect cost function cn+1 along execution aRTAA daRTAA .542fiAvoiding Escaping Depressions Real-Time Heuristic SearchProof: Since update procedure used aRTAA , daRTAA RTAA update variableh exactly way, re-use proof Theorem 1 Koenig Likhachev(2006b) establish result. provide however complete proof Section B.2objective mark-and-avoid strategy stay away depressions.following theorems establish that, indeed, state marked aLSS-LRTAaRTAA state heuristic depression current heuristic.Theorem 5 Let state s.updated switches false true iterations n n + 1 execution aLSS-LRTA aRTAA h initiallyconsistent. cost-sensitive heuristic depression hn .Proof: first prove result case aLSS-LRTA . proof aRTAAsimilar found Section B.3.Let maximal connected component states connected that:1. states Closed call iteration n,2. state sd hn+1 (sd ) > hn (sd ).Let s0 state boundary D. first show hn (s0 ) = hn+1 (s0 ).definition s0 either Closed Open. s0 Closed then, since s0 6 D, mustcase s0 satisfy condition 2 definition D, hence hn+1 (s0 ) hn (s0 ).However, since heuristic non-decreasing (Theorems 2 1), must hn (s0 ) =hn+1 (s0 ). hand, s0 Open, heuristic value changed thusalso hn (s0 ) = hn+1 (s0 ). established, hence, hn (s0 ) = hn+1 (s0 ).ready establish result: cost-sensitive heuristic depressionhn .Let sd state D. distinguish two cases.Case 1: s0 Closed. Then, Proposition 1,hn (s0 ) = kn (s0 , sb ) + hn (sb ),(7)sb Open. hand, since heuristic value increasedsd , hn (sd ) < hn+1 (sd ) = mins0b Open kn (sd , s0b ) + h(s0b ); particular, hn (sd ) <kn (sd , sb ) + hn (sb ). Since kn (sd , sb ) optimal cost go sd sb , kn (sd , sb )kn (sd , s0 ) + kn (s0 , sb ). Substituting kn (sd , sb ) previous inequality have:hn (sd ) < kn (sd , s0 ) + kn (s0 , sb ) + hn (sb ).(8)substitute right-hand side (8) using (7), obtainhn (sd ) < kn (sd , s0 ) + hn (s0 ).Case 2: s0 Open. Proposition 1 hn+1 (sd ) kn (sd , s0 ) + hn (s0 ).Moreover, definition D, hn+1 (sd ) > hn (sd ). Combining twoinequalities, obtain:hn (sd ) < kn (sd , s0 ) + hn (s0 ).543fiHernandez & Baiercases, proved hn (sd ) < kn (sd , s0 ) + hn (s0 ), sd s0boundary D. conclude cost-sensitive heuristic depression hn , finishesproof.turn attention termination. prove solution exists,found algorithms. prove result, need two intermediatelemmas. first establishes algorithm moves best state Open,h-value state changed h-value current state.Formally,Lemma 1 Let s0 state smallest f -value Open lookahead phaseaLSS-LRTA , daLSS-LRTA , aRTAA , daRTAA , initialized consistentheuristic h. Then,hn+1 (scurrent ) h0 (scurrent ) hn (s0 ) h0 (s0 ).Proof: Indeed, Propositions 1 2:hn+1 (scurrent ) = kn (scurrent , s0 ) + hn (s0 )(9)Let optimal path found connecting scurrent s0 . Let K0 denote costpath respect cost function c0 . Given heuristic h0 consistentrespect graph cost function c0 , h0 (scurrent ) K0 + h0 (s0 )re-written as:h0 (scurrent ) K0 h0 (s0 ).(10)Adding (10) (9), obtain:hn+1 (scurrent ) h0 (s) kn (scurrent , s0 ) K0 + hn (s0 ) h0 (s0 ).(11)Now, cn increase, cost iteration n, kn (scurrent , s0 ), strictlygreater cost iteration 0, K0 . words, amount kn (scurrent , s0 )K0positive removed right-hand side (11) produce:hn+1 (scurrent ) h0 (s) hn (s0 ) h0 (s0 ),desired result.second intermediate result prove termination following lemma.Lemma 2 Let n iteration aLSS-LRTA , daLSS-LRTA , aRTAA ,daRTAA , initialized consistent heuristic h. snext set equalstate s0 least f -value Open, then:hn (s0 ) h0 (s0 ) > hn (snext ) h0 (snext ).Proof: Indeed, aRTAA aLSS-LRTA run, means snext snextmarked updated, means hn (snext ) = h0 (snext ), equivalently,hn (snext ) h0 (snext ) = 0. Moreover, best state Open, s0 , chosen hence544fiAvoiding Escaping Depressions Real-Time Heuristic Searchmust s0 .updated = true, means h(s0 ) h0 (s0 ) > 0. obtainhn (s0 ) h0 (s0 ) > hn (snext ) h0 (snext ).case daRTAA daLSS-LRTA direct condition Line 5 Algorithm 9. Hence, also true hn (s0 ) h0 (s0 ) > hn (snext ) h0 (snext ).ready prove main termination result.Theorem 6 Let P undirected finite real-time search problem solutionexists. Let h consistent heuristic P . Then, aLSS-LRTA , daLSS-LRTA ,aRTAA , daRTAA , used h, find solution P .Proof: Let us assume contrary. two cases algorithmsreturn solution: (a) return solution Line 5 (Algorithm 1), (b)agent traverses infinite path never hits solution node.(a) assume algorithms state call . reachesLine 5 (Algorithm 1), open list empty, means agent exhaustedsearch space states reachable without finding solution; contradictionfact solution node reachable fact search problemundirected.(b) assume agent follows infinite path . Observeinfinite execution, iterationsay, Rthe value variable c increaseanymore. states around states observed past.consequence, iteration R agent traverses complete path identifiedlookahead procedure (Line 8 Algorithm 1).second important observation that, iteration R, value h statesfinite cannot increase anymore. Indeed, Theorems 4 3, h remains consistenthence admissible, means h(s) bounded actual cost reachsolution s, . Moreover, since c change anymore, callupdate function change value h(s), every .ready finish proof. Consider algorithm executes past iterationR. Since path infinite state space finite, iteration Ralgorithm decides go back previously visited state. such, going assumeagent visits state t0 selects move trough states t1 t2 tr1 tr t0 . Sinceheuristic change anymore, simply denote h, regardless iterationnumber. distinguish two cases.Case 1 agent always decides move best state Open, s0 , hencedepending algorithm usedby Proposition 1 2, h(s) = k(s, s0 )+h(s0 ),implies h(s) > h(s0 ), since action costs positive. implies that:h(t0 ) > h(t1 ) > h(t2 ) > . . . > h(tn ) > h(t0 ),contradiction; cannot case h(t0 ) > h(t0 ).Case 2 least once, agent move best state Open. Without lossgenerality, assume happens once, state ti < r. Letstate smallest f -value Open lookahead carried ti .545fiHernandez & BaierLemma 1, write following inequalities.h(t0 ) h0 (t0 ) h(t1 ) h0 (t1 ),...h(ti1 ) h0 (ti1 ) h(ti ) h0 (ti ),h(ti ) h0 (ti ) h(t ) h0 (t ),h(ti+1 ) h0 (ti+1 ) h(ti+2 ) h0 (ti+2 ),...h(tr ) h0 (tr ) h(t0 ) h0 (t0 ).Let set containing inequalities. since state ti algorithmdecides move ti+1 instead , use Lemma 2 write:hn (t ) h0 (t ) > hn (ti+1 ) h0 (ti+1 ).(12)inequalities together (12) entail h(t0 ) h0 (t0 ) > h(t0 ) h0 (t0 ),contradiction.cases derive contradictions hence conclude algorithm cannot enterinfinite loop thus finds solution.turn attention convergence. literature often analyzes propertiesreal-time heuristic search run sequence trials (e.g., Shimbo &Ishida, 2003). trial characterized running algorithm start stateproblem solved. heuristic function h resulting trial n used feedalgorithms h variable trial n + 1.stating convergence theorem prove result related h increasessuccessive iterations trials. Indeed, iteration search algorithmspotentially increases h, making informed. following result impliesimprovement cannot infinitesimal.Lemma 3 Let P finite undirected search problem, let Sol set states Psolution reached. Let n iteration aLSS-LRTA , daLSSLRTA , aRTAA , daRTAA . hn (s) take finite number values,every P .Proof: Given Proposition 1, along execution algorithms LSS-LRTAfamily, simple prove induction n that:hn (s) = K + h0 (s000 ),n, K sum costs 0 arcs P cost function cn .hand, given update rule algorithms RTAA family(e.g., Line 6 Algorithm 8),hn (s) = K K 0 + h0 (s000 ),546fiAvoiding Escaping Depressions Real-Time Heuristic Searchn, K K 0 correspond sum costs arcs P costfunction cn .Since finite problems finite number arcs, quantities referred KK 0 take finite number values. implies hn (s), P ,take finite number values, concludes proof.show h converges sequence trials, solution found hoptimal.Theorem 7 Let P undirected finite real-time search problem solutionexists. Let h consistent heuristic P . initialized h, sequence trialsaLSS-LRTA , daLSS-LRTA , aRTAA , daRTAA , converges optimalsolution.Proof: First, observe since heuristic admissible, remains admissiblenumber trials run. consequence Theorems 3 4. Hence, everystate goal state reached, h(s) bounded (finiteamount) h (s).hand, Lemma 3, h-values states solution reachableincrease finite number times. sequence trials value h thusconverges; i.e., least one complete trial, h(s) changed, every P .also assume trial, value c change either, since hconverges, path states always followed thus new cost increasesmade.Let us focus run algorithms h c change.Observe means hn (s) = h0 (s) n (recall h0 heuristic giveninput algorithm). Independent algorithm used, implies algorithmalways moves best state Open. Let s1 . . . sm sequence statesassigned snext execution (sm thus goal state). Observe since cchange along execution, states s1 . . . sm actually visited agent. Dependingalgorithm used, Proposition 1 2, know:h(si ) = k(si , si+1 ) + h(si+1 ),{0, . . . , 1},(13)k(si , si+1 ) cost optimal path si si+1 . Since heuristicconsistentPh(sm ) = 0, thus family equations (13) conclude h(s0 )equal m1i=0 k(si , si+1 ), corresponds cost path traversed agent.know h also admissible, so:h(s0 ) =m1Xk(si , si+1 ) h (s0 ).i=0Since h (s0 ) cost optimal solution, conclude path found optimalcost.547fiHernandez & BaierFigure 5: Upper row: four maze maps used test approach; 512512 cells.Lower row: 4 12 game maps used. first two come DragonAge: Origins; remaining 2 StarCraft.7. Empirical Evaluationevaluated algorithms solving real-time navigation problems unknown environments. LSS-LRTA RTAA used baseline comparisons. fairness,used comparable implementations use underlying codebase. example,search algorithms use implementation binary heaps priority queuesbreak ties among cells f -values favor cells larger g-values,known good tie-breaking strategy.carried experiments two sets benchmarks: deployed game mapsmazes. used twelve maps deployed video games carry experiments.first six taken game Dragon Age, remaining six taken gameStarCraft. maps retrieved Nathan Sturtevants pathfinding repository.1addition, used four maze maps taken HOG2 repository.2 shownFigure 5. results obtained using Linux machine Intel Xeon CPU running2GHz 12 GB RAM.maps regarded undirected, eight-neighbor grids.Horizontal vertical movements cost 1, whereas diagonal movements cost 2. used octile distance(Sturtevant & Buro, 2005) heuristic.1. http://www.movingai.com/ http://hog2.googlecode.com/svn/trunk/maps/. DragonAge used maps brc202d, orz702d, orz900d, ost000a, ost000t ost100d size 481530, 939718,656 1491 969 487, 971 487, 1025 1024 cells respectively. StarCraft, used mapsArcticStation, Enigma, Inferno JungleSiege, Ramparts WheelofWar size 768 768, 768 768,768 768, 768 768, 512 512 768 768 cells respectively.2. http://hog2.googlecode.com/svn/trunk/maps/548fiAvoiding Escaping Depressions Real-Time Heuristic SearchLSS-LRTA* Variants: Cost vs Time per Episode (Games)LSS-LRTA*aLSS-LRTA*500,000daLSS-LRTA*100,00010,00000.050.10.150.20.25LSS-LRTA* Variants: Cost vs Time per Episode (Mazes)5,500,000Average Solution Cost (log-scale)Average Solution Cost (log-scale)1,000,000LSS-LRTA*aLSS-LRTA*2,000,0000.3Time per Planning Episode msecdaLSS-LRTA*500,000100,00000.050.10.150.20.25Time per Planning Episode msec(a)(b)Figure 6: Plots showing average solution cost found LSS-LRTA variants versusaverage planning time per episode, measured milliseconds. (a) shows statsgame-map benchmarks, (b) mazes benchmarks. Times shownmilliseconds. Costs shown log-scale.evaluation ran algorithms 10 different lookahead values. map,generate 500 test cases. test case choose start goal cells randomly.presentation results sometimes use concept improvement factor.say improvement factor algorithm respect B termsaverage solution cost n, means average produces solutions n timescheaper ones found B.Next describe different views experimental data shown plotstables. continue draw experimental conclusions.7.1 Analysis LSS-LRTA Variantssection analyzes performance LSS-LRTA , aLSS-LRTA daLSS-LRTA .Figure 6 shows two plots average solution costs versus average planning timeper episode three algorithms games mazes benchmarks. Planning time perplanning episode accurate measure effort carried algorithms.Thus plots illustrate solution quality varies depending effortalgorithm carries out.Regardless search effort, observe aLSS-LRTA slightly consistently outperforms LSS-LRTA solution cost. games benchmarks observe equalsearch effort, aLSS-LRTA produces average improvement factors 1.08 1.20terms solution cost. mazes, hand, improvement factors 1.041.25. games, largest improvements observed lookahead parameter(and hence search time per episode) rather small. Thus aLSS-LRTA advantageLSS-LRTA clearly observed tighter time constraints imposedplanning episodes.549fiHernandez & BaierOften times results real-time search literature presented form tables,search performance statistics reported per lookahead value. providetables appendix paper (Tables 5 6). important observationdrawn tables time per planning episode LSS-LRTA aLSS-LRTAsimilar fixed lookahead value; indeed, time per planning episode aLSSLRTA slightly larger LSS-LRTA . interesting since showsworst-case asymptotic complexity seem achieved aLSS-LRTA(cf. Table 2).experimental results show daLSS-LRTA refined mechanism escaping depressions better aLSS-LRTA . given value search effort,daLSS-LRTA consistently outperforms aLSS-LRTA significant margin solutioncost games mazes. daLSS-LRTA also outperforms aLSS-LRTA total searchtime, i.e., overall time spent searching solution found. Details foundTables 5 6. search effort algorithm small, daLSS-LRTA averagesolution quality substantially better aLSS-LRTA s; improvements actuallyclose order magnitude.daLSS-LRTA consistently outperforms LSS-LRTA significant margin totalsearch time solution quality, independent search effort employed. termssolution cost daLSS-LRTA produces average improvement factors respect LSSLRTA 1.66 order magnitude game benchmarks, producesaverage improvement factors 1.49 order magnitude mazes benchmarks. fixed lookahead (see Tables 5 6 specific numbers), time spentper planning episode daLSS-LRTA larger time spent per planning episodeLSS-LRTA daLSS-LRTA makes heap percolations LSS-LRTA . However, small values lookahead parameter, daLSS-LRTA obtains better solutionsusing less time per planning episode LSS-LRTA used much larger lookahead.example, game maps, lookahead parameter equal 32, daLSS-LRTA obtainsbetter solutions LSS-LRTA lookahead parameter equal 128, requiring,average, 2.6 times less time per planning episode. mazes, lookahead parameterequal 16, daLSS-LRTA obtains better solutions LSS-LRTA lookaheadparameter equal 64, requiring, average, 2.4 times less time per planning episode.low values lookahead parameter (i.e. limited search effort) daLSS-LRTAobtains better solutions less time per planning episode aLSS-LRTA usedmuch larger lookahead. example, game maps, lookahead parameter equal1, daLSS-LRTA obtains better solutions aLSS-LRTA lookahead parameterequal 16, requiring, average, 14.1 times less time per planning episode.hand, mazes lookahead parameter equal 1, daLSS-LRTA obtains better solutions aLSS-LRTA lookahead parameter equal 16, requiring, average,11.6 times less time per planning episode.fixed lookahead (see Tables 5 6), time taken daLSS-LRTA per planningepisode larger time taken aLSS-LRTA per planning episode. increaseexplained because, average, daLSS-LRTA open list grows largeraLSS-LRTA . due fact that, benchmarks tried, daLSS-LRTAtends expand cells less obstacles around aLSS-LRTA does. result,550fiAvoiding Escaping Depressions Real-Time Heuristic SearchRTAA* Variants: Cost vs Time per Episode (Games)RTAA*aRTAA*500,000daRTAA*100,00010,00000.020.040.060.08RTAA* Variants: Cost vs Time per Episode (Mazes)5,500,000Average Solution Cost (log-scale)Average Solution Cost (log-scale)1,000,0000.10.12Time per Planning Episode msecRTAA*aRTAA*2,000,000daRTAA*500,000100,00000.01 0.02 0.03 0.04 0.05 0.06 0.07 0.08 0.09 0.1Time per Planning Episode msec(a)(b)Figure 7: Plots showing average solution cost found RTAA variants versus average planning time per episode. (a) shows stats game-maps benchmarks,(b) mazes benchmarks. Costs shown log-scale.daLSS-LRTA expands cells learning phase makes heap percolationslookahead phase aLSS-LRTA .Results show that, among LSS-LRTA variants, daLSS-LRTA algorithmbest performance. fact daLSS-LRTA clearly superior LSS-LRTA .60,000 runs (12 maps 500 test cases 10 lookahead-values) game benchmarks,daLSS-LRTA obtains better solution quality LSS-LRTA 69.9% cases,tie 20.9% cases, LSS-LRTA obtains better-quality solution 9.2%cases.20,000 (4 maps 500 test cases 10 lookahead-values) runs mazes benchmarks, daLSS-LRTA obtains better solution quality LSS-LRTA 75.1%cases, tie 3.3% cases, LSS-LRTA obtains better-quality solution21.7% cases.7.2 Analysis RTAA Variantssection analyze relative performance RTAA , aRTAA , daRTAA .Figure 7 shows two plots average solution costs versus average effort carriedper search episode.search effort, observe significant improvements aRTAARTAA . Indeed, small values average time per search episode aRTAAimprove solution quality upon RTAA . general, however, algorithmsseem similar performance.hand, results show daRTAA mechanism escaping depressionssubstantially better aRTAA . small values lookahead parameter (and hence reduced search effort), daRTAA obtains better solutionsvariants used much larger lookahead. Indeed, limited search effort, daRTAA551fiHernandez & Baierapproximately order magnitude better two algorithms. example,game maps, lookahead parameter equal 1, daRTAA obtains better solutionsaRTAA lookahead parameter equal 16, requiring, average, 10.4 timesless time per planning episode.daRTAA substantially improves RTAA , among best real-time heuristicsearch algorithms known date. game maps, daRTAA needs lookahead parameter 16 obtain solutions better RTAA lookahead parameter 64.values, daRTAA requires 2.3 times less time per planning episodeRTAA .results show daRTAA best-performing algorithm RTAA family.60,000 runs game-map benchmarks, daRTAA obtains better solution qualityRTAA 71.2% cases, tie 20.5% cases, RTAA obtainsbetter-quality solution 8.3% cases. 20,000 runs mazes, daRTAAobtains better solution quality RTAA 78.0% cases, tie 2.7%cases, RTAA obtains better-quality solution 19.4% cases.7.3 daLSS-LRTA Versus daRTAAdaRTAA , best performing algorithm among RTAA variants, also superiordaLSS-LRTA , best-performing algorithm LSS-LRTA variants. Figure 8 showsaverage solution costs versus search effort, game maps mazes.seen figure, lookahead parameter small (i.e., search effortlittle), performance daRTAA daLSS-LRTA fairly similar. However,search allowed per planning episode, daRTAA outperforms daLSS-LRTA .example, games benchmarks, daRTAA , allowed spend 0.08 milliseconds perepisode, obtain solutions comparable daLSS-LRTA allowedspend 0.18 millisecconds per episode.Furthermore, slopes curves significantly favorable daRTAAdaLSS-LRTA . verified types benchmarks important sincespeaks inherent superiority RTAA framework time per planning episoderelevant factor.7.4 Analysis Disaggregated Dataperformance real-time algorithms usually varies depending map used. illustrate algorithms perform different maps, Figure 9 shows improvementsolution cost daLSS-LRTA LSS-LRTA 4 game 4 maze benchmarks.confirm improvements observed domains thus showing average valuesrepresentative daLSS-LRTA behavior individual benchmarks. Although aLSSLRTA daLSS-LRTA outperform LSS-LRTA average, specific casessituation hold. notably, observe one maze benchmarks daLSS-LRTA improve significantly respect LSS-LRTA largevalues lookahead parameter. discuss next section. Figure 10shows also improvement factors daRTAA RTAA . plot, differentalgorithms show similar relative performance relation LSS-LRTA variants.552fiAvoiding Escaping Depressions Real-Time Heuristic SearchCost vs Time per Episode (Games)Cost vs Time per Episode (Mazes)1e+06Average Solution Cost (log-scale)Average Solution Cost (log-scale)daRTAA*daLSS-LRTA*100,00010,00000.050.10.150.20.25daRTAA*daLSS-LRTA*1000000.300.05Time per Planning Episode msec0.10.150.20.25Time per Planning Episode msec(a)(b)Figure 8: Plots showing average solution cost found daRTAA daLSS-LRTAversus average planning time per episode. (a) shows stats game-mapsbenchmarks, (b) mazes benchmarks. Costs shown log-scale.orz702d10maze512-16orz900d8765maze512-32ArticStationCost Improvement FactorCost Improvement Factor8Enigma76543maze512-4maze512-8432120.010.030.060.090.120.15Time Deadline per Planning Episode0.010.030.060.090.120.15Time Deadline per Planning EpisodeFigure 9: Cost improvement factor daLSS-LRTA LSS-LRTA , game maps (left)maze benchmarks (right). improvement factor equal n indicatessolution found algorithm n times cheaper one foundoriginal algorithm.553fiHernandez & Baier5orz702dmaze512-168ArticStationCost Improvement FactorCost Improvement Factororz900dEnigma432maze512-32maze512-4maze512-86543210.010.030.060.090.120.15Time Deadline per Planning Episode0.010.030.060.090.120.15Time Deadline per Planning EpisodeFigure 10: Cost improvement factor daRTAA RTAA , game maps (left)maze (right) benchmarks. improvement factor equal n indicatessolution found algorithm n times cheaper one foundoriginal algorithm.7.5 Worst-Case Experimental AnalysisAlthough algorithms perform resource-bounded computation per planning episode,hard tune lookahead parameter way LRTA daLSSLRTA incur worst-case planning effort. time spentextracting best state open list depends structure search spaceexpanded lookahead phase.section set carry experimental worst-case analysis basedtheoretical worst-case bound. bound obtained worst-case effort per planningstep follows. RTAA performs k expansions per planning episode, open listcould contain 8k states. state 8 neighbors.worst case, effort spent adding states open list would 8k log 8k.hand, daRTAA would make effort insert states openlist, would incur additional cost 8k log 8k, worst-case, remove statesopen list. Therefore, worst-case scenario, given lookahead parameter equalk, daRTAA make double effort RTAA makes parameter.Based worst-case estimation, Figure 11 presents performance RTAAvariants, displacing RTAA curve lookahead factor 2. concludeworst-case scenario daRTAA still clearly outperforms RTAA . Gains vary one ordermagnitude, low values lookahead parameter, similar performancelookahead parameter high.remark, however, never observed worst-case practice. example,game benchmarks, RTAA , used lookahead parameter 2k spends,average 50% time per planning episode daRTAA used lookahead parameterk.554fiAvoiding Escaping Depressions Real-Time Heuristic Search0.11e+060.08RTAA*(Lookahead * 2)aRTAA*aRTAA*daRTAA*daRTAA*Average Cost (log-scale)Average Time per Planning EpisodeRTAA*(Lookahead * 2)0.060.040.02100000100000050100150200250300Lookahead050100150200250300Lookahead(a)(b)Figure 11: Plots showing average time per planning episode average solution costper lookahead parameter, adjusting performance RTAA using theoretical worst-case bound 2. such, RTAA , average cost reportedlookahead k actually corresponds cost obtained lookahead2k. Costs shown log-scale.8. Discussionnumber aspects work deserve discussion. focus twothem. First, discuss setting evaluated work, focusedshowing performance improvements first trial search priori unknowndomain, without considering settings. Second, discuss scenariosalgorithms may exhibit average performance improvements shownprevious section.8.1 Experimental Setting: Unknown Environments, First Trialalgorithm tailored solving quickly search problem environmentinitially unknown. setting several applications, including goal-directed navigationunknown terrain (Koenig et al., 2003; Bulitko & Lee, 2006). also widelyused evaluate real-time heuristic search algorithms (e.g., Koenig, 1998; Hernandez &Meseguer, 2005; Bulitko & Lee, 2006; Hernandez & Meseguer, 2007; Koenig & Sun, 2009).hand, present evaluation algorithm environmentsknown priori. previous paper (Hernandez & Baier, 2011d), however,showed aLSS-LRTA obtains similar improvements LSS-LRTA environment known. However, omit results known environments since RTAALSS-LRTA representative state art scenarios. Indeed, algorithms like TBA* (Bjornsson et al., 2009) outperform LSS-LRTA significantly.immediately obvious incorporate techniques algorithms like TBA*.present experimental results regarding convergence several successivesearch trials. Recall setting, agent teleported initial location555fiHernandez & Baiernew search trial carried out. real-time search algorithmsours includedareguaranteed eventually find optimal solution. algorithms particularly excelsetting. heuristic value fewer states updated, henceheuristic values states search space converges slowly correct value.such, generally trials needed converge.Convergence performance important problems solved offlinereal-time approaches may adequate computing approximation optimalsolution. case problem computing optimal policy MDPs usingReal-Time Dynamic Programming (Barto, Bradtke, & Singh, 1995). aware,however, application deterministic search searching offline using realtime search would yield better performance using suboptimal search algorithms(e.g., Richter, Thayer, & Ruml, 2010; Thayer, Dionne, & Ruml, 2011). Indeed, Wilt,Thayer, Ruml (2010) concluded real-time algorithms, though applicable,used solving shortest path problems unless need real-time action.8.2 Bad Performance ScenariosAlthough algorithms clearly outperform originators LSS-LRTA RTAAaverage, possible contrive families increasingly difficult path-finding tasksalgorithms perform worse respective predecessors.Consider example 4-connected grid-world scenario size 7n shown Figure 12.goal agent reach state labeled G, starting S. Assumefurthermore solve problem run aRTAA aLSS-LRTA , lookaheadparameter equal 1, ties broken movement prioritymovement. initial state algorithms determine initialstate (cell E3) heuristic depression thus update heuristic cell E3. CellE3 marked depression. Since cells D3 F3 heuristicvalue ties broken favor upper cells, agent moved cell D3.later iterations, algorithm prefer move cells updatedtherefore agent go back state E3 unless currently D3 (at least) C3also marked. However, agent go back D3 quickly. Indeed, visitstates right Wall 1 Wall 2 coming back E3. happens because,algorithm executes, update mark visited states, never prefergo back previously marked position unless current neighbors also marked.situation, RTAA LSS-LRTA , run lookahead parameter 1behave differently depending tie-breaking rules. Indeed, priority given(highest), down, right, left (lowest), RTAA LSS-LRTA findgoal fairly quickly visit states right walls. Indeed,since tie-breaking rules prefer move up, agent reaches cell A3 4 moves,proceeds straight goal. situations, performance aRTAAaLSS-LRTA made arbitrarily worse RTAA LSS-LRTA , nincreased.quite different situation produced tie-breaking follows priorities given(highest), right, down, left (lowest). case four algorithms visitstates right walls. Indeed, A3 reached, tie556fiAvoiding Escaping Depressions Real-Time Heuristic Search12345678n2 n1 n...B...Wall 1EFG.........Wall 2C......GFigure 12: situation relative performance LSS-LRTA aLSSLRTA changes depending value n. start state, Ggoal. Ties broken favor upper cells.h-value B3 A4. agent prefers moving A4, continuesmoving right grid zig-zag fashion.investigating executions da- algorithms maze512-4-0 benchmark(performance shown Figures 9 10), believe lack improvementparticular benchmark explained situation described. benchmark512 512 maze corridors 4-cell width. low lookahead values,number updates high enough block corridors. such, low valueslookahead parameter increase performance still reasonably good.lookahead increases, algorithm updates states one single iteration, and,result, chances good paths may become blocked.Interestingly, however, observe phenomenon mazes wider corridorsgame maps. necessary condition block corridor leads solutionagent sufficient knowledge borders corridor. mazesnarrow corridors may happen relative ease, agent needs movestravel opposite walls. grids corridors wide however, knowledgeexistence obstacles (walls) hard obtain agent, and, thus, chancesupdating blocking, corridor leads solution lower.believe possible prove algorithms always better alwaysworse specific search space topologies. think, nevertheless, analysismay hard carry out, practical significance may limited. Thereforedecided exclude scope work. hand, thinkimpressive performance exhibited algorithms many benchmarks sufficientlystrong favor using algorithms domains contain narrow corridors.9. Related WorkBesides LSS-LRTA RTAA , number real-time search algorithmsused priori unknown environments. LRTA (k) LRTALS (k) (Hernandez &Meseguer, 2005, 2007) two algorithms competitive LSS-LRTA capable557fiHernandez & Baierlearning heuristic several states time; states heuristiclearned independent expanded lookahead phase. may escapeheuristic depressions quickly LRTA , action selection mechanismaware heuristic depressions. eLSS-LRTA preliminary version aLSS-LRTApresented extended abstract (Hernandez & Baier, 2011a). outperformedaLSS-LRTA average, usually becomes focused avoiding depressions.algorithms designed order find good-quality solutions firstsearch trial. algorithms described literature designed differentobjectives mind. example, RIBS (Sturtevant, Bulitko, & Bjornsson, 2010) realtime algorithm specifically designed converge quickly optimal solution. moveagent iterative-deepening search carried out. first solutionfinds optimal. consequence, RIBS potentially requires time find one solutionLSS-LRTA does, optimal solution required RIBS likely outperformLSS-LRTA run convergence. f -LRTA* (Sturtevant & Bulitko, 2011) another recentreal-time search algorithm builds upon ideas introduced RIBS, gcost states learned successive trials. good convergence performance,needs computation per planning step LSS-LRTA .Incremental methods, like D* (Stentz, 1995), D*Lite (Koenig & Likhachev, 2002),Adaptive A* (Koenig & Likhachev, 2006a), Tree Adaptive A* (Hernandez, Sun, Koenig,& Meseguer, 2011), search methods also allow solving goal-directed navigationproblems unknown environments. first-move delay required short, incremental A* methods cannot used since require compute complete solutionstarting move. Real-time search remains applicable strategy tasklimited time allowed per planning episode.Less related work algorithms abide real-time search constraintsassume environment known advance sufficient time given priorsolving problem, allowing preprocessing. Examples LRTA (Bulitko, Lustrek,Schaeffer, Bjornsson, & Sigmundarson, 2008) kNN-LRTA (Bulitko et al., 2010), treesubgoaling (Hernandez & Baier, 2011b), real-time search via compressed path databases(Botea, 2011).Finally, concept cost-sensitive depression real-time search could linkedconcepts used describe poor performance planning algorithms. example,Hoffmann (2005, 2011) analyzed existence plateaus h+ , effective admissibledomain-independent planning heuristic, negatively affects performanceotherwise fast planning algorithms. Cushing, Benton, Kambhampati (2011) introducedconcept -traps related poor performance best-first search problemsaction costs high variance. -traps areas search space connectedactions least cost. such, h-values states -traps consideredanalysis. Although think existence cost-sensitive heuristic depressionsaffect performance , exact relation performanceheuristic depressions seem obvious.558fiAvoiding Escaping Depressions Real-Time Heuristic Search10. Summary Future Workpresented simple principle guiding real-time search algorithms awayheuristic depressions. proposed two alternative approaches implementing principle: mark-and-avoid move-to-border. first approach, states provendepression marked update phase, avoided, possible,deciding next move. second approach, algorithm selects next movestate seems closer border depression.approaches implemented efficiently. Mark-and-avoid requires littleoverhead, results almost negligible increment time per planning episode.Move-to-border, hand, requires overhead per planning episode, but,given time deadline per planning episode, able obtain best-quality solutions.Experimentally, shown goal-directed navigation tasks unknown terrain, algorithms outperform predecessors RTAA LSS-LRTA . Indeed,algorithms based move-to-borderdaLSS-LRTA daRTAA significantlyefficient LSS-LRTA RTAA , especially lookahead parameter smallvalue.four algorithms proposed good properties: undirected, finite search spaces,guaranteed find solution solution exists. Moreover, convergeoptimal solution running number search trials.Depression avoidance principle applicable real-time heuristic search algorithms. Indeed, think could easily incorporated LRTA (k), LRTALS (k),P-LRTA* (Rayner et al., 2007). algorithms specialized mechanisms updating heuristic, mechanism select next state like LSS-LRTArun lookahead parameter equal 1. think significant improvements couldachieved procedure select next movement changed daLSS-LRTA s.also believe depression avoidance could incorporated multi-agent real-time searchalgorithms (e.g., Knight, 1993; Yokoo & Kitamura, 1996; Kitamura, Teranishi, & Tatsumi,1996).11. Acknowledgmentsthank JAIR reviewers provided extensive feedback helped improvearticle significantly. also thank IJCAI-11, SoCS-11, AIIDE-11 anonymousreviewers thoughtful insights earlier versions work. gratefulCristhian Aguilera, helped running experiments. Carlos Hernandezpartly funded Fondecyt project #11080063. Jorge Baier partly fundedVRI-38-2010 grant Pontificia Universidad Catolica de Chile Fondecyt grantnumber 11110321.Appendix A. Additional Experimental DataTables 36 show average statistics LSS-LRTA , RTAA , 4 algorithms.559fiHernandez & BaierLookAheadparameter1248163264128256512Avg.Cost5,731,1354,805,3843,217,2831,905,8951,004,971513,692262,760137,40371,93941,089LookAheadparameter1248163264128256512Avg.Cost5,165,0624,038,3472,746,6381,504,379859,669455,023239,484129,76567,34638,939k1248163264128256512Avg.Cost443,773804,990419,616374,684257,126155,573108,33775,15849,06531,265RTAA# PlanningTotalEpisodesTime5,307,5712,1743,885,6842,4102,147,0602,321954,5711,912353,7071,338127,55592746,77766118,7875219,0124755,973530aRTAA# PlanningTotalEpisodesTime4,785,2572,7983,260,1342,9811,832,3752,829755,3342,034305,3721,458114,08999243,49769918,4785599,1085066,172567daRTAA# PlanningTotalEpisodesTime415,327208689,014575321,418502260,163801148,61686466,81869734,11962617,68656810,3705906,954652Time perEpisode0.00040.00060.00110.00200.00380.00730.01410.02770.05270.0888Exp.per ep.1.02.04.08.016.032.063.9126.3237.8397.4Perc.per ep.5.99.116.833.267.8145.6331.8816.52,016.64,101.6Timeper ep.0.00060.00090.00150.00270.00480.00870.01610.03030.05550.0918Exp.per ep.1.02.04.08.016.032.063.9126.3237.5399.4Perc.per ep.10.618.934.061.5113.3216.0440.6988.92,272.54,394.9Timeper ep.0.00050.00080.00160.00310.00580.01040.01830.03210.05690.0937Exp.per ep.1.02.04.08.016.032.063.8126.2239.3408.9Perc.per ep.10.527.358.5129.4261.1476.7854.81,536.72,920.95,074.1Table 3: Average results RTAA variants mazes. given lookahead parameter value,report average solution cost (Avg. Cost), average number planning episodes(# Planning Episodes), total runtime (Total Time), average runtime per search episode(Time per Episode), average number expansions per episode (Exp. per ep.), averagenumber percolations per planning episode (Perc. per ep.). times reportedmilliseconds.560fiAvoiding Escaping Depressions Real-Time Heuristic SearchLookAheadparameter1248163264128256512Avg.Cost1,146,014919,410626,623363,109188,34695,49448,26825,68213,9627,704LookAheadparameter1248163264128256512Avg.Cost958,795763,367516,545299,786151,73781,69542,88323,21712,5106,892k1248163264128256512Avg.Cost109,33788,94774,86962,40041,14529,46918,40511,9247,9215,205RTAA# PlanningTotalEpisodesTime1,058,265448747,824475422,389469184,75338467,65226924,6091939,1381463,8541261,9411261,220132aRTAA# PlanningTotalEpisodesTime885,506549621,438598348,785569154,03744555,70629021,5332108,3571573,6311341,8451291,178133daRTAA# PlanningTotalEpisodesTime102,6165379,9516662,66410248,83816528,45319916,8572298,1521963,9081582,1161491,311145Time perEpisode0.00040.00060.00110.00210.00400.00780.01590.03260.06470.1078Exp.per ep.1.02.04.08.016.032.063.9126.4236.8377.6Perc.per ep.6.19.417.334.170.1152.9361.3932.32,351.84,616.7Timeper ep.0.00060.00100.00160.00290.00520.00980.01870.03680.07000.1132Exp.per ep.1.02.04.08.016.032.063.9126.3235.8372.7Perc.per ep.11.119.936.066.1122.5235.0485.51,114.12,586.74,826.3Timeper ep.0.00050.00080.00160.00340.00700.01360.02410.04060.07020.1107Exp.per ep.1.02.04.08.016.032.063.9126.4238.3385.1Perc.per ep.11.629.668.0153.7327.4654.91,167.41,958.93,491.55,654.4Table 4: Average results RTAA variants game maps. given lookahead parameter value, report average solution cost (Avg. Cost), average numberplanning episodes (# Planning Episodes), total runtime (Total Time), averageruntime per search episode (Time per Episode), average number expansions perepisode (Exp. per ep.), average number percolations per planning episode (Perc.per ep.). times reported milliseconds.561fiHernandez & BaierLookAheadparameter1248163264128256512Avg.Cost5,731,1353,346,6751,931,2511,195,330674,872391,120218,303119,17764,86138,182LookAheadparameter1248163264128256512Avg.Cost5,165,0622,561,7691,670,5351,027,134617,302354,691205,214112,28861,03136,524LookAheadparameter1248163264128256512Avg.Cost443,773433,576527,638317,508197,066125,51185,37365,00939,77728,937LSS-LRTA# PlanningTotalEpisodesTime5,307,5716,0362,594,7384,9671,247,2054,009586,0843,187233,4002,18996,1631,61339,0021,21516,6491,0108,4209915,8051,143aLSS-LRTA# PlanningTotalEpisodesTime4,785,2576,1741,981,5094,3211,078,5123,923504,6963,069213,9592,21787,7001,60337,1061,24016,0691,0288,3001,0105,8791,185daLSS-LRTA# PlanningTotalEpisodesTime415,327357353,087603393,2221,374205,8681,412100,9841,29345,6821,02322,72588813,7729778,2011,0566,3301,310Time perEpisode0.00110.00190.00320.00540.00940.01680.03120.06070.11770.1968Exp.per ep.8.513.420.732.954.595.2175.6341.3655.01,079.2Perc.per ep.14.328.052.197.6182.9367.4799.41,939.04,704.48,961.1Timeper ep.0.00130.00220.00360.00610.01040.01830.03340.06400.12170.2016Exp.per ep.8.513.320.733.054.695.8176.9344.4659.11,082.0Perc.per ep.19.037.769.5126.6228.3441.1918.42,134.74,997.99,283.8Timeper ep.0.00090.00170.00350.00690.01280.02240.03910.07090.12880.2070Exp.per ep.6.211.721.940.070.7119.7209.7384.7698.41,115.8Perc.per ep.18.943.396.6225.8459.9816.11,477.12,936.75,972.610,136.2Table 5: Average results LSS-LRTA variants mazes. given lookahead parameter value,report average solution cost (Avg. Cost), average number planning episodes (#Planning Episodes), total runtime (Total Time), average runtime per search episode (Timeper Episode), average number expansions per episode (Exp. per ep.), average numberpercolations per planning episode (Perc. per ep.). times reported milliseconds.Results obtained Linux PC Pentium QuadCore 2.33 GHz CPU 8 GBRAM.562fiAvoiding Escaping Depressions Real-Time Heuristic SearchLookAheadparameter1248163264128256512Avg.Cost1,146,014625,693372,456227,526127,75372,04440,35922,47112,2647,275LookAheadparameter1248163264128256512Avg.Cost958,795506,745313,789184,632111,63366,91137,21520,52411,0536,460k1248163264128256512Avg.Cost109,33779,41772,02851,75333,35121,62213,5818,6936,4644,830LSS-LRTA# PlanningTotalEpisodesTime1,058,2651,260488,096979242,171818113,23665445,24246018,4453457,6872803,4442581,7742721,192312aLSS-LRTA# PlanningTotalEpisodesTime885,5061,185395,546903204,47878692,59460239,85744917,2713517,2172783,2342511,6772611,137295daLSS-LRTA# PlanningTotalEpisodesTime102,6168669,97611658,93121438,86230020,79232210,1772934,7152332,4242201,6042671,195317Time perEpisode0.00120.00200.00340.00580.01020.01870.03640.07500.15340.2620Exp.per ep.8.713.721.333.856.198.7184.9370.1733.61,207.5Perc.per ep.14.829.354.3102.4193.5397.7903.42,338.16,003.811,548.9Timeper ep.0.00130.00230.00380.00650.01130.02030.03860.07760.15560.2592Exp.per ep.8.713.721.334.156.699.5186.8374.5741.41,204.5Perc.per ep.19.840.173.7135.6246.0479.61,036.22,553.86,339.311,823.7Timeper ep.0.00080.00170.00360.00770.01550.02880.04940.09050.16670.2651Exp.per ep.6.112.123.344.180.3139.6236.9435.4791.51,237.3Perc.per ep.20.849.9118.2274.0586.21,122.41,911.23,725.47,538.112,697.3Table 6: Average results LSS-LRTA variants game maps. given lookahead parameter value, report average solution cost (Avg. Cost), average number planningepisodes (# Planning Episodes), total runtime (Total Time), average runtime per searchepisode (Time per Episode), average number expansions per episode (Exp. per ep.), average number percolations per planning episode (Perc. per ep.). times reportedmilliseconds. Results obtained Linux PC Pentium QuadCore 2.33 GHzCPU 8 GB RAM.563fiHernandez & BaierAppendix B. Additional Proofs TheoremsB.1 Proof Theorem 3establish that, pair neighbor states, s0 , hn+1 (s) cn+1 (s, s0 ) + hn+1 (s0 ).divide rest argument three cases.Case 1. s0 Closed. Then, Proposition 1,hn+1 (s0 ) = kn (s0 , s00 ) + hn (s00 ),(14)s00 Open. hand, Proposition 1,hn+1 (s) = min kn (s, sb ) + hn (sb ),sb Openthushn+1 (s) kn (s, s00 ) + hn (s00 ),(15)since s00 element Open. However, kn (s, s00 ) cost shortest paths00 , knowkn (s, s00 ) cn (s, s0 ) + kn (s0 , s00 )(16)Adding (15) (16), obtainhn+1 (s) cn (s, s0 ) + kn (s0 , s00 ) + hn (s00 )(17)Using Equation 14 substitute kn (s0 , s00 ) + hn (s00 ) Inequality 17, obtaining:hn+1 (s) cn (s, s0 ) + hn (s0 ).(18)Since cost function increase, cn (s, s0 ) cn+1 (s, s0 ), hence:hn+1 (s) cn+1 (s, s0 ) + hn (s0 ),(19)Finally, since h non-decreasing (Theorem 1), hn (s0 ) hn+1 (s0 ), allows uswritehn+1 (s) cn+1 (s, s0 ) + hn+1 (s0 ),(20)finishes proof case.Case 2. One state among s0 Closed, state Closed.Without loss generality, assume Closed. Since s0 Closed, mustOpen, expanded s0 neighbor s. Proposition 1 know:hn+1 (s) = min kn (s, sb ) + hn (sb ),sb Opensince s0 particular state Open, have:hn+1 (s) cn (s, s0 ) + hn (s0 ).Since cn cn+1 , obtain:hn+1 (s) cn+1 (s, s0 ) + hn (s0 ),564fiAvoiding Escaping Depressions Real-Time Heuristic Searchconcludes proof case.Case 3. s0 Closed. Since hn consistent:hn (s) cn (s, s0 ) + hn (s0 )(21)use h-value s0 updated (hn (s) = hn+1 (s) hn (s0 ) =hn+1 (s0 )), fact cost function increases write:hn+1 (s) cn+1 (s, s0 ) + hn+1 (s0 ),(22)finishes proof case.three cases proved desired inequality therefore conclude heuristichn+1 consistent respect cost function cn+1 .B.2 Proof Theorem 4establish that, pair neighbor states, s0 , hn+1 (s) cn+1 (s, s0 ) + hn+1 (s0 ).divide rest argument three cases.Case 1. s0 Closed.hn+1 (s) = f (s ) g(s),00hn+1 (s ) = f (s ) g(s ),(23)(24)Open. Subtracting (24) (23), obtain:hn+1 (s) hn+1 (s0 ) = g(s0 ) g(s).(25)Since hn consistent g(s) g(s0 ) correspond cost shortest pathscurrent and, respectively, s0 . Thus g(s0 ) = kn (scurrent , s0 ) g(s) = kn (scurrent , s),therefore:hn+1 (s) hn+1 (s0 ) = kn (scurrent , s0 ) kn (scurrent , s).(26)Let us consider path scurrent s0 goes optimally s, goess0 . cost path must least kn (scurrent , s0 ). words:kn (scurrent , s0 ) kn (scurrent , s) + cn (s, s0 ),directly implies:kn (scurrent , s0 ) kn (scurrent , s) cn (s, s0 ).(27)combine (27) (26) obtain:hn+1 (s) cn (s, s0 ) + hn+1 (s0 ).(28)And, finally, since cn cn+1 conclude that:hn+1 (s) cn+1 (s, s0 ) + hn+1 (s0 ),finishes proof case.565(29)fiHernandez & BaierCase 2. One state among s0 Closed, state Closed.Without loss generality, assume Closed. Since s0 Closed, mustOpen, expanded s0 neighbor s.state Open,hn+1 (s) = f (s ) g(s)(30)use fact that, consistent heuristic hn , expands nodes increasing f -values. Note state would expanded next ,s0 would expanded later on. Moreover, soon s0 wouldexpanded g-value s0 optimal cost path scurrent s0 , kn (scurrent , s0 ).Therefore, write:f (s ) kn (scurrent , s0 ) + hn (s0 ),(31)kn (scurrent , s0 ) + hn (s0 ) f -value s0 upon expansion. Adding (30) (31),obtain:hn+1 (s) kn (scurrent , s0 ) g(s) + hn (s0 )However, since Closed, g(s) cost optimal path scurrent s,thus:hn+1 (s) kn (scurrent , s0 ) kn (scurrent , s) + hn (s0 )(32)use argument previous case conclude that:kn (scurrent , s0 ) kn (scurrent , s) cn (s, s0 ).(33)Combining (31) (33) obtain:hn+1 (s) cn (s, s0 ) + hn (s0 )(34)Since s0 closed, hn+1 (s0 ) = hn (s). Furthermore, know cn cn+1 . Substituting (34), obtain:hn+1 (s) cn+1 (s, s0 ) + hn+1 (s0 ),(35)allows us conclude proof case.Case 3. s0 Closed. proof Case 3Theorem 3.three cases proved desired inequality therefore conclude heuristichn+1 consistent respect cost function cn+1 .B.3 Appendix Proof Theorem 5section describes proof Theorem 5 specific case aRTAA .Let maximal connected component states connected (1)states Closed call iteration n, (2) state sdhn+1 (sd ) > hn (sd ). prove cost-sensitive heuristic depression hn .Let s0 state boundary D; argued case aLSS-LRTA ,show hn (s0 ) = hn+1 (s0 ). Now, let sd state D. continue proof showing566fiAvoiding Escaping Depressions Real-Time Heuristic Searchhn (sd ) low respect hn (s0 ), means heuristic depressionhn . final part proof, distinguish two cases: (Case 1) s0 Closed,(Case 2) s0 Open.Case 1, given hn+1 (s0 ) = hn (s0 ), know hn (s0 ) = f g(s0 ), flowest f -value open list algorithm run, hence:f = hn (s0 ) + g(s0 )(36)hand, since definition heuristic value increased sd ,hn (sd ) < hn+1 (sd ) = f g(sd ).(37)Substituting f Eq. 37 right-hand-side Eq. 36, get:hn (sd ) < hn (s0 ) + g(s0 ) g(sd ).(38)heuristic consistent s0 sd Closed, g(s0 ) g(sd ) actuallycorrespond cost cheapest path reach, respectively, s0 sd s; i.e.,g(s0 ) = k(s, s0 ) g(sd ) = kn (s, sd ). addition, triangular inequality kn (s, sd ) +kn (sd , s0 ) kn (s, s0 ), re-written as:g(s0 ) g(sd ) kn (sd , s0 ).(39)Inequalities 38 39 imply hn (sd ) < kn (sd , s0 ) + hn (s0 ).Finally, Case 2, s0 Open, Proposition 2 fact hn+1 (sd ) > hn (sd ),also hn (sd ) < kn (sd , s0 ) + hn (s0 ).cases, proved hn (sd ) < kn (sd , s0 ) + hn (s0 ), sd s0boundary D. conclude cost-sensitive heuristic depression hn .ReferencesBarto, A. G., Bradtke, S. J., & Singh, S. P. (1995). Learning act using real-time dynamicprogramming. Artificial Intelligence, 72 (1-2), 81138.Bjornsson, Y., Bulitko, V., & Sturtevant, N. R. (2009). TBA*: Time-bounded A*. Proceedings 21st International Joint Conference Artificial Intelligence (IJCAI),pp. 431436.Bond, D. M., Widger, N. A., Ruml, W., & Sun, X. (2010). Real-time search dynamicworlds. Proceedings 3rd Symposium Combinatorial Search (SoCS), Atlanta, Georgia.Botea, A. (2011). Ultra-fast Optimal Pathfinding without Runtime Search. Proceedings7th Annual International AIIDE Conference (AIIDE), Palo Alto, California.Bulitko, V., & Lee, G. (2006). Learning real time search: unifying framework. JournalArtificial Intelligence Research, 25, 119157.Bulitko, V. (2004). Learning adaptive real-time search. Computing Research Repository,cs.AI/0407016.567fiHernandez & BaierBulitko, V., Bjornsson, Y., & Lawrence, R. (2010). Case-based subgoaling real-timeheuristic search video game pathfinding. Journal Artificial Intelligence Research,38, 268300.Bulitko, V., Bjornsson, Y., Sturtevant, N., & Lawrence, R. (2011). Real-time HeuristicSearch Game Pathfinding. Applied Research Artificial Intelligence ComputerGames. Springer.Bulitko, V., Lustrek, M., Schaeffer, J., Bjornsson, Y., & Sigmundarson, S. (2008). Dynamiccontrol real-time heuristic search. Journal Artificial Intelligence Research, 32,419452.Cormen, T. H., Leiserson, C. E., Rivest, R. L., & Stein, C. (2001). Introduction Algorithms, Second Edition. MIT Press McGraw-Hill Book Company.Cushing, W., Benton, J., & Kambhampati, S. (2011). Cost based satisficing search considered harmful. CoRR, abs/1103.3687.Edelkamp, S., & Schrodl, S. (2011). Heuristic Search: Theory Applications. MorganKaufmann.Hart, P. E., Nilsson, N., & Raphael, B. (1968). formal basis heuristic determinationminimal cost paths. IEEE Transactions Systems Science Cybernetics, 4 (2).Hernandez, C., & Meseguer, P. (2005). LRTA*(k). Proceedings 19th InternationalJoint Conference Artificial Intelligence (IJCAI), pp. 12381243.Hernandez, C., & Meseguer, P. (2007). Improving LRTA*(k). Proceedings 20thInternational Joint Conference Artificial Intelligence (IJCAI), pp. 23122317.Hernandez, C., & Baier, J. A. (2011a). Escaping heuristic depressions real-time heuristicsearch (extended abstract). Proceedings 10th International Joint ConferenceAutonomous Agents Multi Agent Systems (AAMAS), Taipei, Taiwan.Hernandez, C., & Baier, J. A. (2011b). Fast subgoaling pathfinding via real-timesearch. Proceedings 21th International Conference Automated PlanningScheduling (ICAPS), Freiburg, Germany.Hernandez, C., & Baier, J. A. (2011c). Real-time adaptive A* depression avoidance.Proceedings 7th Annual International AIIDE Conference (AIIDE), Palo Alto,California.Hernandez, C., & Baier, J. A. (2011d). Real-time heuristic search depression avoidance.Proceedings 22nd International Joint Conference Artificial Intelligence(IJCAI), Barcelona, Spain.Hernandez, C., Sun, X., Koenig, S., & Meseguer, P. (2011). Tree adaptive A*. Proceedings10th International Joint Conference Autonomous Agents Multi AgentSystems (AAMAS), Taipei, Taiwan.Hoffmann, J. (2011). ignoring delete lists works, part II: Causal graphs. Proceedings 21th International Conference Automated Planning Scheduling(ICAPS), pp. 98105.Hoffmann, J. (2005). ignoring delete lists works: Local search topology planningbenchmarks. Journal Artificial Intelligence Research, 24, 685758.568fiAvoiding Escaping Depressions Real-Time Heuristic SearchIshida, T. (1992). Moving target search intelligence. Proceedings 10th NationalConference Artificial Intelligence (AAAI), pp. 525532.Kitamura, Y., Teranishi, K.-i., & Tatsumi, S. (1996). Organizational strategies multiagent real-time search. Proceedings 2nd International Conference Multiagent Systems (ICMAS), pp. 150156, Kyoto, Japan.Knight, K. (1993). many reactive agents better deliberative ones?. Proceedings 13th International Joint Conference Artificial Intelligence (IJCAI),pp. 432437.Koenig, S. (1998). Exploring unknown environments real-time search reinforcementlearning. Proceedings 11th Conference Advances Neural InformationProcessing Systems (NIPS), pp. 10031009.Koenig, S. (2001). Agent-centered search. Artificial Intelligence Magazine, 22 (4), 109131.Koenig, S. (2004). comparison fast search methods real-time situated agents.Proceedings 3rd International Joint Conference Autonomous AgentsMulti Agent Systems (AAMAS), pp. 864871.Koenig, S., & Likhachev, M. (2002). D* lite. Proceedings 18th National ConferenceArtificial Intelligence (AAAI), pp. 476483.Koenig, S., & Likhachev, M. (2006a). new principle incremental heuristic search:Theoretical results. Proceedings 16th International Conference AutomatedPlanning Scheduling (ICAPS), pp. 402405, Lake District, UK.Koenig, S., & Likhachev, M. (2006b). Real-time adaptive A*. Proceedings 5thInternational Joint Conference Autonomous Agents Multi Agent Systems (AAMAS), pp. 281288.Koenig, S., & Sun, X. (2009). Comparing real-time incremental heuristic searchreal-time situated agents. Autonomous Agents Multi-Agent Systems, 18 (3), 313341.Koenig, S., Tovey, C. A., & Smirnov, Y. V. (2003). Performance bounds planningunknown terrain. Artificial Intelligence, 147 (1-2), 253279.Korf, R. E. (1990). Real-time heuristic search. Artificial Intelligence, 42 (2-3), 189211.Pearl, J. (1984). Heuristics: preintelligent search strategies computer problem solving.Addison-Wesley Longman Publishing Co., Inc., Boston, MA, USA.Rayner, D. C., Davison, K., Bulitko, V., Anderson, K., & Lu, J. (2007). Real-time heuristicsearch priority queue. Proceedings 20th International Joint ConferenceArtificial Intelligence (IJCAI), pp. 23722377.Richter, S., Thayer, J. T., & Ruml, W. (2010). joy forgetting: Faster anytime searchvia restarting. Proceedings 20th International Conference AutomatedPlanning Scheduling (ICAPS), pp. 137144.Shimbo, M., & Ishida, T. (2003). Controlling learning process real-time heuristicsearch. Artificial Intelligence, 146 (1), 141.569fiHernandez & BaierStentz, A. (1995). focussed D* algorithm real-time replanning. Proceedings14th International Joint Conference Artificial Intelligence (IJCAI), pp. 16521659.Sturtevant, N. R., & Bulitko, V. (2011). Learning going whencecame: h- g-cost learning real-time heuristic search. Proceedings22nd International Joint Conference Artificial Intelligence (IJCAI), pp. 365370,Barcelona, Spain.Sturtevant, N. R., Bulitko, V., & Bjornsson, Y. (2010). learning agent-centered search.Proceedings 9th International Joint Conference Autonomous AgentsMulti Agent Systems (AAMAS), pp. 333340, Toronto, Ontario.Sturtevant, N. R., & Buro, M. (2005). Partial pathfinding using map abstractionrefinement. Proceedings 20th National Conference Artificial Intelligence(AAAI), pp. 13921397.Thayer, J. T., Dionne, A. J., & Ruml, W. (2011). Learning inadmissible heuristicssearch. Proceedings 21th International Conference Automated PlanningScheduling (ICAPS), pp. 250257, Freinurg, Germany.Weiss, G. (Ed.). (1999). Multiagent Systems: Modern Approach Distributed ArtificialIntelligence. MIT Press, Cambridge, MA.Wilt, C. M., Thayer, J. T., & Ruml, W. (2010). comparison greedy search algorithms.Proceedings 3rd Symposium Combinatorial Search (SoCS).Yokoo, M., & Kitamura, Y. (1996). Multiagent real-time A* selection: Introducingcompetition cooperative search. Proceedings 2nd International ConferenceMultiagent Systems (ICMAS), pp. 409416, Kyoto, Japan.Zelinsky, A. (1992). mobile robot exploration algorithm. IEEE Transactions RoboticsAutomation, 8 (6), 707717.570fiJournal Artificial Intelligence Research 43 (2012) 661-704Submitted 09/11; published 04/12Learning Win Reading ManualsMonte-Carlo FrameworkS.R.K. Branavanbranavan@csail.mit.eduComputer Science Artificial Intelligence LaboratoryMassachusetts Institute TechnologyDavid Silverd.silver@cs.ucl.ac.ukDepartment Computer ScienceUniversity College LondonRegina Barzilayregina@csail.mit.eduComputer Science Artificial Intelligence LaboratoryMassachusetts Institute TechnologyAbstractDomain knowledge crucial effective performance autonomous control systems.Typically, human effort required encode knowledge control algorithm.paper, present approach language grounding automatically interpretstext context complex control application, game, uses domainknowledge extracted text improve control performance. text analysiscontrol strategies learned jointly using feedback signal inherent application.effectively leverage textual information, method automatically extracts textsegment relevant current game state, labels task-centric predicatestructure. labeled text used bias action selection policy game,guiding towards promising regions action space. encode model textanalysis game playing multi-layer neural network, representing linguistic decisionsvia latent variables hidden layers, game action quality via output layer.Operating within Monte-Carlo Search framework, estimate model parameters usingfeedback simulated games. apply approach complex strategy gameCivilization II using official game manual text guide. results showlinguistically-informed game-playing agent significantly outperforms language-unawarecounterpart, yielding 34% absolute improvement winning 65% gamesplaying built-in AI Civilization.1. Introductionpaper, study task grounding document content control applicationscomputer games. applications, agent attempts optimize utilityfunction (e.g., game score) learning select situation-appropriate actions. complexdomains, finding winning strategy challenging even humans. Therefore, humanplayers typically rely manuals guides describe promising tactics providegeneral advice underlying task. Surprisingly, textual information neverutilized control algorithms despite potential greatly improve performance.goal, therefore, develop methods achieve automatic fashion.c2012AI Access Foundation. rights reserved.fiBranavan, Silver, & Barzilaynatural resources available population settles aects ability produce foodgoods. Cities built near water sources irrigate increase crop yields,cities near mineral resources mine raw materials. Build city plains grasslandsquare river running possible.Figure 1: excerpt user manual game Civilization II.explore question context strategy games, challenging class large scaleadversarial planning problems.Consider instance text shown Figure 1. excerpt usermanual game Civilization II.1 text describes game locations actionbuild-city effectively applied. stochastic player accesstext would gain knowledge hard way: would repeatedly attemptaction myriad states, thereby learning characterization promising state-actionpairs based observed game outcomes. games large state spaces, long planninghorizons, high-branching factors, approach prohibitively slow ineffective.algorithm access text, however, could learn correlations wordstext game attributes e.g., word river places rivers gamethus leveraging strategies described text select better actions.improve performance control applications using domain knowledge automatically extracted text, need address following challenges:Grounding Text State-Action Space Control Application Textguides provide wealth information effective control strategies, includingsituation-specific advice well general background knowledge. benefitinformation, algorithm learn mapping textguide, states actions control application. mapping allowsalgorithm find state-specific advice matching state attributes verbaldescriptions. Furthermore, relevant sentence found, mapping biasesalgorithm select action proposed guide document. mappingmodeled word-level, ideally would also use information encodedstructure sentence predicate argument structure. instance,algorithm explicitly identify predicates state attribute descriptions,map directly structures inherent control application.Annotation-free Parameter Estimation text analysis tasks relatewell-known methods information extraction, prior work primarily focusedsupervised methods. setup, text analysis state dependent, therefore annotations need representative entire state space. Given enormous statespace continually changes game progresses, collecting annotationsimpractical. Instead, propose learn text analysis based feedback signalinherent control application, e.g., game score. feedback computedautomatically step game, thereby allowing algorithm continuouslyadapt local, observed game context.1. http://en.wikipedia.org/wiki/Civilization II662fiLearning Win Reading Manuals Monte-Carlo FrameworkEffective Integration Extracted Text Information Control Application text guides provide complete, step-by-step advice situations player may encounter. Even advice available, learnedmapping may noisy, resulting suboptimal choices. Therefore, need design method achieve effective control absence textual advice,robustly integrating automatically extracted information available.address challenge incorporating language analysis Monte-Carlo Search,state-of-the-art framework playing complex games. Traditionally frameworkoperates state action features. extending Monte-Carlo searchinclude textual features, integrate two sources information principledfashion.1.1 Summary Approachaddress challenges unified framework based Markov Decision Processes(MDP), formulation commonly used game playing algorithms. setup consistsgame stochastic environment, goal player maximize givenutility function R(s) state s. players behavior determined action-valuefunction Q(s, a) assesses goodness action state based attributesa.incorporate linguistic information MDP formulation, expand actionvalue function include linguistic features. state action features knownpoint computation, relevant words semantic roles observed.Therefore, model text relevance hidden variable. Similarly, use hidden variablesdiscriminate words describe actions describe state attributesrest sentence. incorporate hidden variables action-value function,model Q(s, a) non-linear function approximation using multi-layer neural network.Despite added complexity, parameters non-linear model effectively learned Monte-Carlo Search framework. Monte-Carlo Search, actionvalue function estimated playing multiple simulated games starting currentgame state. use observed reward simulations update parametersneural network via backpropagation. focuses learning current game state,allowing method learn language analysis game-play appropriate observedgame context.1.2 Evaluationtest method strategy game Civilization II, notoriously challenging gameimmense action space.2 source knowledge guiding model, useofficial game manual. baseline, employ similar Monte-Carlo search based playeraccess textual information. demonstrate linguisticallyinformed player significantly outperforms baseline terms number gameswon. Moreover, show modeling deeper linguistic structure sentences improves performance. full-length games, algorithm yields 34% improve2. Civilization II #3 IGNs 2007 list top video games time.(http://top100.ign.com/2007/ign top game 3.html)663fiBranavan, Silver, & Barzilayment language unaware baseline wins 65% games built-in,hand-crafted AI Civilization II. video method playing game availablehttp://groups.csail.mit.edu/rbg/code/civ/video. code data work, alongcomplete experimental setup preconfigured environment virtual machineavailable http://groups.csail.mit.edu/rbg/code/civ.1.3 RoadmapSection 2, provide intuition benefits integrating textual informationlearning algorithms control. Section 3 describes prior work language grounding, emphasizing unique challenges opportunities setup. section also positionswork large body research Monte-Carlo based players. Section 4 presentsbackground Monte-Carlo Search applied game playing. Section 5 presentmulti-layer neural network formulation action-value function combines information text control application. Next, present Monte-Carlo methodestimating parameters non-linear function. Sections 6 7 focus application algorithm game Civilization II. Section 8 compare methodrange competitive game-playing baselines, empirically analyze properties algorithm. Finally, Section 9 discuss implications research,conclude.2. Learning Game Play Textsection, provide intuitive explanation textual information help improve action selection complex game. clarity, first discuss benefits textualinformation supervised scenario, thereby decoupling questions concerning modelingrepresentation related parameter estimation. Assume every staterepresented set n features [s1 , s2 , . . . , sn ]. Given state s, goal selectbest possible action aj fixed set A. model task multiclass classification, choice aj represented feature vector [(s1 , aj ), (s2 , aj ), . . . , (sn , aj )].Here, (si , aj ), [1, n] represents feature created taking Cartesian product [s1 , s2 , . . . , sn ] aj . learn classifier effectively, need training setsufficiently covers possible combinations state features actions. However, domains complex state spaces large number possible actions, many instancesstate-action feature values unobserved training.show generalization power classifier improved using textual information. Assume training example, addition state-action pair,contains sentence may describe action taken given state attributes. Intuitively, want enrich basic classifier features capture correspondencestates actions, words describe them. Given sentence w composedword types w1 , w2 , . . . , wm , features form (si , wk ) (aj , wk )every [1, n], k [1, m] aj A. Assuming action described using similar words throughout guide, expect text-enriched classifier would ablelearn correspondence via features (aj , wk ). similar intuition holds learningcorrespondence state-attributes descriptions represented features(si , wk ). features, classifier connect state action aj based664fiLearning Win Reading Manuals Monte-Carlo Frameworkevidence provided guiding sentence occurrences contextsthroughout training data. text-free classifier may support associationaction appear similar state context training set.benefits textual information extend models trained using controlfeedback rather supervised data. training scenario, algorithm assessesgoodness given state-action combination simulating limited number game turnsaction taken observing control feedback provided underlyingapplication. algorithm built-in mechanism (see Section 4) employsobserved feedback learn feature weights, intelligently samples space searchpromising state-action pairs. algorithm access collection sentences,similar feedback-based mechanism used find sentences match given stateaction pair (Section 5.1). state- action-description features (si , wk )(aj , wk ), algorithm jointly learns identify relevant sentences map actionsstates descriptions. Note used classification basisdiscussion section, reality methods learn regression function.3. Related Worksection, first discuss prior work field grounded language acquisition.Subsequently look two areas specific application domain i.e., natural languageanalysis context games, Monte-Carlo Search applied game playing.3.1 Grounded Language Acquisitionwork fits broad area research grounded language acquisitiongoal learn linguistic analysis non-linguistic situated context (Oates, 2001;Barnard & Forsyth, 2001; Siskind, 2001; Roy & Pentland, 2002; Yu & Ballard, 2004; Chen& Mooney, 2008; Zettlemoyer & Collins, 2009; Liang, Jordan, & Klein, 2009; Branavan,Chen, Zettlemoyer, & Barzilay, 2009; Branavan, Zettlemoyer, & Barzilay, 2010; Vogel & Jurafsky, 2010; Clarke, Goldwasser, Chang, & Roth, 2010; Tellex, Kollar, Dickerson, Walter,Banerjee, Teller, & Roy, 2011; Chen & Mooney, 2011; Liang, Jordan, & Klein, 2011; Goldwasser, Reichart, Clarke, & Roth, 2011). appeal formulation lies reducingneed manual annotations, non-linguistic signals provide powerful, albeitnoisy, source supervision learning. traditional grounding setup assumednon-linguistic signals parallel content input text, motivating machinetranslation view grounding task. alternative approach models groundingcontrol framework learner actively acquires feedback non-linguistic environment uses drive language interpretation. summarize approaches,emphasizing similarity differences work.3.1.1 Learning Grounding Parallel Datamany applications, linguistic content tightly linked perceptual observations, providing rich source information learning language grounding. Examples paralleldata include images captions (Barnard & Forsyth, 2001), Robocup game events pairedtext commentary (Chen & Mooney, 2008), sequences robot motor actions de665fiBranavan, Silver, & Barzilayscribed natural language (Tellex et al., 2011). large diversity propertiesparallel data resulted development algorithms tailored specific groundingcontexts, instead application-independent grounding approach. Nevertheless, existinggrounding approaches characterized along several dimensions illuminateconnection algorithms:Representation Non-Linguistic Input first step grounding wordsperceptual data discretize non-linguistic signal (e.g., image) representation facilitates alignment. instance, Barnard Forsyth (2001) segment images regions subsequently mapped words. approachesintertwine alignment segmentation single step (Roy & Pentland, 2002),two tasks clearly interrelated. application, segmentation requiredstate-action representation nature discrete.Many approaches move beyond discretization, aiming induce rich hierarchical structures non-linguistic input (Fleischman & Roy, 2005; Chen & Mooney, 2008,2011). instance, Fleischman Roy (2005) parse action sequences usingcontext-free grammar subsequently mapped semantic frames. ChenMooney (2008) represent action sequences using first order logic. contrast,algorithm capitalizes structure readily available data state-actiontransitions. inducing richer structure state-action space may benefit mapping, difficult problem right field hierarchicalplanning (Barto & Mahadevan, 2003).Representation Linguistic Input Early grounding approaches used bagof-words approach represent input documents (Yu & Ballard, 2004; Barnard &Forsyth, 2001; Fleischman & Roy, 2005). recent methods relied richerrepresentation linguistic data, syntactic trees (Chen & Mooney, 2008)semantic templates (Tellex et al., 2011). method incorporates linguistic information multiple levels, using feature-based representation encodes wordswell syntactic information extracted dependency trees. shownresults, richer linguistic representations significantly improve model performance.Alignment Another common feature existing grounding models trainingprocedure crucially depends well words aligned non-linguistic structures.reason, models assume alignment provided part trainingdata (Fleischman & Roy, 2005; Tellex et al., 2011). grounding algorithms,alignment induced part training procedure. Examples approachesmethods Barnard Forsyth (2001), Liang et al. (2009).models jointly generate text attributes grounding context, treatingalignment unobserved variable.contrast, explicitly model alignment model due lackparallel data. Instead, aim extract relevant information text infusecontrol application.666fiLearning Win Reading Manuals Monte-Carlo Framework3.1.2 Learning Grounding Control Feedbackrecent work moved away reliance parallel corpora, using control feedback primary source supervision. assumption behind setuptextual information used drive control application, applications performancecorrelate quality language analysis. also assumed performance measurement obtained automatically. setup conducive reinforcement learningapproaches estimate model parameters feedback signal, even noisydelayed.One line prior work focused task mapping textual instructionspolicy control application, assuming text fully specifies actions executed environment. example, previous work (Branavan et al., 2009, 2010),approach applied task translating instructions computer manualexecutable GUI actions. Vogel Jurafsky (2010) demonstrate groundingframework effectively map navigational directions corresponding path map.second line prior work focused full semantic parsing converting given textformal meaning representation first order logic (Clarke et al., 2010).methods applied domains correctness output accurately evaluated based control feedback example, output databasequery executed provides clean, oracle feedback signal learning. linework also assumes text fully specifies required output.method also driven control feedback, language interpretation taskfundamentally different. assume given text document provides highlevel advice without directly describing correct actions every potential game state.Furthermore, textual advice necessarily translate single strategy fact,text may describe several strategies, contingent specific game states.reason, strategy text cannot simply interpreted directly policy. Therefore,goal bias learned policy using information extracted text. end,aim achieve complete semantic interpretation, rather use partial text analysiscompute features relevant control application.3.2 Language Analysis GamesEven though games provide rich domain situated text analysis,prior attempts leveraging opportunity (Gorniak & Roy, 2005; Eisenstein,Clarke, Goldwasser, & Roth, 2009).Eisenstein et al. (2009) aim automatically extract information collectiondocuments help identify rules game. information, represented predicate logic formulae, estimated unsupervised fashion via generative model.extracted formulae, along observed traces game play subsequently fed Inductive Logic Program, attempts reconstruct rules game.high-level, goal similar, i.e., extract information text useful externaltask, several key differences. Firstly, Eisenstein et al. (2009) analyzetext game two disjoint steps, model tasks integrated fashion.allows model learn text analysis pertinent game play, timeusing text guide game play. Secondly, method learns text analysis game667fiBranavan, Silver, & Barzilayplay feedback signal inherent game, avoiding need pre-compiled gametraces. enables method operate effectively complex games collectingsufficiently representative set game traces impractical.Gorniak Roy (2005) develop machine controlled game character respondsspoken natural language commands. Given traces game actions manually annotatedtranscribed speech, method learns structured representation textaligned action sequences. learned model used interpret spoken instructionsgrounding actions human player current game state.method learn play game, enables human control additional gamecharacter via speech. contrast Gorniak Roy (2005), aim develop algorithmsfully autonomously control actions one player game. Furthermore,method operates games user manual rather human provided, contextuallyrelevant instructions. requires model identify text contains informationuseful current game state, addition mapping text productive actions.Finally, method learns game feedback collected via active interaction withoutrelying manual annotations. allows us effectively operate complex gamescollecting traditional labeled traces would prohibitively expensive.3.3 Monte-Carlo Search Game AIMonte-Carlo Search (MCS) state-of-the-art framework successfullyapplied, prior work, playing complex games Go, Poker, Scrabble, real-timestrategy games (Gelly, Wang, Munos, & Teytaud, 2006; Tesauro & Galperin, 1996; Billings,Castillo, Schaeffer, & Szafron, 1999; Sheppard, 2002; Schafer, 2008; Sturtevant, 2008; Balla& Fern, 2009). framework operates playing simulated games estimate goodness value different candidate actions. games state action spacescomplex, number simulations needed effective play become prohibitively large.Previous application MCS addressed issue using two orthogonal techniques: (1)leverage domain knowledge either guide prune action selection, (2) estimatevalue untried actions based observed outcomes simulated games. estimate used bias action selection. MCS based algorithm games reliestechniques. describe differences applicationtechniques prior work.3.3.1 Leveraging Domain KnowledgeDomain knowledge shown critically important achieving good performance MCS complex games. prior work achieved manuallyencoding relevant domain knowledge game playing algorithm example, viamanually specified heuristics action selection (Billings et al., 1999; Gelly et al., 2006),hand crafted features (Tesauro & Galperin, 1996), value functions encoding expertknowledge (Sturtevant, 2008). contrast approaches, goal automatically extract use domain knowledge relevant natural language documents, thusbypassing need manual specification. method learns text interpretationgame action selection based outcomes simulated games MCS. allowsidentify leverage textual domain knowledge relevant observed game context.668fiLearning Win Reading Manuals Monte-Carlo FrameworkAction selectionaccordingpolicy functionStochastic statetransition accordingdistributionFigure 2: Markov Decision Process. Actions selected according policy function (s, a)given current state s. execution selected action ai (e.g., a1 ), causesMDP transition new state s0 according stochastic state transitiondistribution (s0 | s, a).3.3.2 Estimating Value Untried ActionsPrevious approaches estimating value untried actions relied two techniques.first, Upper Confidence bounds Tree (UCT) heuristic used concertMonte-Carlo Tree Search variant MCS. augments actions value explorationbonus rarely visited state-action pairs, resulting better action selection betteroverall game performance (Gelly et al., 2006; Sturtevant, 2008; Balla & Fern, 2009).second technique learn linear function approximation action values currentstate s, based game feedback (Tesauro & Galperin, 1996; Silver, Sutton, & Muller, 2008).Even though method follows latter approach, model action-value Q(s, a) vianon-linear function approximation. Given complexity application domain,non-linear approximation generalizes better linear one, shown resultssignificantly improves performance. importantly, non-linear model enablesmethod represent text analysis latent variables, allowing use textual informationestimate value untried actions.4. Monte-Carlo Searchtask leverage textual information help us win turn-based strategy gamegiven opponent. section, first describe Monte-Carlo Search frameworkwithin method operates. details linguistically informed Monte-CarloSearch algorithm given Section 5.4.1 Game RepresentationFormally, represent given turn-based stochastic game Markov Decision Process(MDP). MDP defined 4-tuple hS, A, T, Ri,State space, S, set possible states. state represents completeconfiguration game in-between player turns.Action space, A, set possible actions. turn-based strategy game,player controls multiple game units turn. Thus, action representsjoint assignment unit actions executed current player turn.669fiBranavan, Silver, & BarzilayTransition distribution, (s0 | s, a), probability executing action stateresult state s0 next game turn. distribution encodes waygame state changes due game rules, opposing players actions.reason, (s0 | s, a) stochastic shown Figure 2, executingaction given state result different outcomes s0 .Reward function, R(s) R, immediate reward received transitioningstate s. value reward correlates goodness actions executednow, higher reward indicating better actions.aspects MDP representation game i.e., S, A, () R()defined implicitly game rules. step game, game-playingagent observe current game state s, select best possible action a.agent executes action a, game state changes according state transitiondistribution. (s0 | s, a) known priori, state transitions sampleddistribution invoking game code black-box simulator i.e., playinggame. action, agent receives reward according reward function R(s).game playing setup, value reward indication chances winninggame state s. Crucially, reward signal may delayed i.e., R(s) maynon-zero value game ending states win, loss, tie.game playing agent selects actions according stochastic policy (s, a),specifies probability selecting action state s. expected total rewardexecuting action state s, following policy termed action-value functionQ (s, a). goal find optimal policy (s, a) maximizes expectedtotal reward i.e., maximizes chances winning game. optimal action-valuefunction Q (s, a) known, optimal game-playing behavior would select actionhighest Q (s, a). may computationally hard find optimal policy(s, a) Q (s, a), many well studied algorithms available estimating effectiveapproximation (Sutton & Barto, 1998).4.2 Monte-Carlo Framework Computer GamesMonte-Carlo Search algorithm, shown Figure 3, simulation-based search paradigmdynamically estimating action-values Q (s, a) given state st (see Algorithm 1pseudo code). estimate based rewards observed multiple roll-outs,simulated game starting state st .3 Specifically, roll-out,algorithm starts state st , repeatedly selects executes actions accordingsimulation policy (s, a), sampling state transitions (s0 | s, a). game completiontime , final reward R(s ) measured, action-value function updatedaccordingly.4 Monte-Carlo control (Sutton & Barto, 1998), updated action-value3. Monte-Carlo Search assumes possible play simulated games. simulations mayplayed heuristic AI player. experiments, built-in AI game usedopponent.4. general, roll-outs run game completion. simulations expensive, casedomain, roll-outs truncated fixed number steps. however depends availabilityapproximate reward signal truncation point. experiments, use built-in scoregame reward. reward noisy, available every stage game.670fiLearning Win Reading Manuals Monte-Carlo FrameworkGameCopy gamestatesimulatorApply actionbest simulationoutcome gameSinglesimulationrolloutUpdate rolloutpolicygame feedbackrolloutSimulationSimulationFigure 3: Overview Monte-Carlo Search algorithm. game state st , independent set simulated games roll-outs done find best possible gameaction . roll-out starts state st , actions selected accordingsimulation policy (s, a). policy learned roll-outsroll-outs improving policy, turn improves roll-out action selection. process repeated every actual game state, simulationpolicy relearned scratch time.function Q (s, a) used define improved simulation policy, thereby directing subsequent roll-outs towards higher scoring regions game state space. fixed numberroll-outs performed, action highest average final rewardsimulations selected played actual game state st . process repeatedstate encountered actual game, action-value functionrelearned scratch new game state.5 simulation policy usually selectsactions maximize action-value function. However, sometimes valid actionsalso randomly explored case valuable predicted current es5. conceivable sharing action-value function across roll-outs different game stateswould beneficial, empirically case experiments. One possible reasondomain, game dynamics change radically many points game e.g.,new technology becomes available. change occurs, may actually detrimental playaccording action-value function previous game step. Note however, action-valuefunction indeed shared across roll-outs single game state st , parameters updatedsuccessive roll-outs. learned model helps improve roll-out action selection, therebyimproves game play. setup relearning scratch game state shownbeneficial even stationary environments (Sutton, Koop, & Silver, 2007).671fiBranavan, Silver, & Barzilaytimate Q (s, a). accuracy Q (s, a) improves, quality action selectionimproves vice versa, cycle continual improvement (Sutton & Barto, 1998).success Monte-Carlo Search depends ability make fast, local estimateaction-value function roll-outs collected via simulated play. However gameslarge branching factors, may feasible collect sufficient roll-outs, especiallygame simulation computationally expensive. Thus crucial learnedaction-value function generalizes well small number roll-outs i.e., observedstates, actions rewards. One way achieve model action-value functionlinear combination state action attributes:Q (s, a) = w~ f~(s, a).f~(s, a) Rn real-valued feature function, w~ weight vector. Prior workshown linear value function approximations effective Monte-Carlo Searchframework (Silver et al., 2008).Note learning action-value function Q(s, a) Monte-Carlo Search relatedReinforcement Learning (RL) (Sutton & Barto, 1998). fact, approach, usestandard gradient descent updates RL estimate parameters Q(s, a). is,however, one crucial difference two techniques: general, goal RLfind Q(s, a) applicable state agent may observe existence.Monte-Carlo Search framework, aim learn Q(s, a) specialized current states. essence, Q(s, a) relearned every observed state actual game, usingstates, actions feedback simulations. relearning may seem suboptimal,two distinct advantages: first, since Q(s, a) needs model current state,representationally much simpler global action-value function. Second, duesimpler representation, learned fewer observations global actionvalue function (Sutton et al., 2007). properties important statespace extremely large, case domain.5. Adding Linguistic Knowledge Monte-Carlo Frameworkgoal work improve performance Monte-Carlo Search frameworkdescribed above, using information automatically extracted text. section,describe achieve terms model structure parameter estimation.5.1 Model Structureachieve aim leveraging textual information improve game-play, methodneeds perform three tasks: (1) identify sentences relevant current game state, (2)label sentences predicate structure, (3) predict good game actions combininggame features text features extracted via language analysis steps. first describetasks modeled separately showing integratesingle coherent model.672fiLearning Win Reading Manuals Monte-Carlo Frameworkprocedure PlayGame ()Initialize game state fixed starting states1 s0= 1 . . .Run N simulated games= 1 . . . N(ai , ri ) SimulateGame (st )endCompute average observed utility action1 Xarg maxriNai:ai =aExecute selected action gamest+1 (s0 | st , )endprocedure SimulateGame (st )u = . . .Compute Q function approximationQ (su , a) = w~ f~(su , a)Sample action action-value function -greedy fashion:uniform (a A)probabilityau (su , a) =arg max Q (su , a) otherwiseExecute selected action game:su+1 (s0 | su , au )game lostbreakendUpdate parameters w~ Q (st , a)Return action observed utility:return , R(s )Algorithm 1: general Monte-Carlo algorithm.673fiBranavan, Silver, & Barzilay5.1.1 Modeling Sentence Relevancediscussed Section 1, small fraction strategy document likely provideguidance relevant current game context. Therefore, effectively use informationgiven document d, first need identify sentence yi relevantcurrent game state action a.6 model decision log-linear distribution,defining probability yi relevant sentence as:~p(y = yi |s, a, d) e~u(yi ,s,a,d) .(1)~ , s, a, d) Rn feature function, ~u parameters need estimate.(y~function ()encodes features combine attributes sentence yiattributes game state action. features allow model learn correlationsgame attributes attributes relevant sentences.5.1.2 Modeling Predicate Structureusing text guide action selection, addition using word-level correspondences,would also like leverage information encoded structure sentence.example, verbs sentence might likely describe suggested game actions.aim access information inducing task-centric predicate structuresentences. is, label words sentence either action-description, statedescription background. Given sentence precomputed dependency parse q,model word-by-word labeling decision log-linear fashion i.e., distributionpredicate labeling z sentence given by:p(z |y, q) = p(~e |y, q)=p(ej |j, y, q),(2)j~p(ej |j, y, q) e~v(ej ,j,y,q) ,~ j , j, y, q) Rn ,ej predicate label j th word. feature function (eaddition encoding word type part-of-speech tag, also includes dependency parseinformation word. features allow predicate labeling decision conditionsyntactic structure sentence.5.1.3 Modeling Action-Value Functionrelevant sentence identified labeled predicate structure,algorithm needs use information along attributes current game stateselect best possible game action a. end, redefine action-value functionQ(s, a) weighted linear combination features game text information:Q(s0 , a0 ) = w~ f~(s, a, yi , zi ).(3)6. use approximation selecting single relevant sentence alternative combiningfeatures sentences text, weighted relevance probability p(y = yi |s, a, d).setup computationally expensive one used here.674fiLearning Win Reading Manuals Monte-Carlo FrameworkInput layer:Deterministic featurelayer:Output layerHidden layer encodingsentence relevanceHidden layer encodingpredicate labelingFigure 4: structure neural network model. rectangle represents collectionunits layer, shaded trapezoids show connections layers.fixed, real-valued feature function ~x(s, a, d) transforms game state s, actiona, strategy document input vector ~x. second layer containstwo disjoint sets hidden units ~y ~z, ~y encodes sentence relevancedecisions, ~z predicate labeling. softmax layers, oneunit active time. units third layer f~(s, a, yi , zi ) setfixed real valued feature functions s, a, active units yi zi ~y~z respectively.s0 = hs, di, a0 = ha, yi , zi i, w~ weight vector, f~(s, a, yi , zi ) Rn featurefunction state s, action a, relevant sentence yi , predicate labeling zi .structure action-value function allows explicitly learn correlationstextual information, game states actions. action maximizes Q(s, a)selected best action state s: 7= arg max Q(s, a).5.1.4 Complete Joint Modeltwo text analysis models, action-value function described form threeprimary components text-aware game playing algorithm. construct singleprincipled model components representing via different layersmulti-layer neural network shown Figure 4. Essentially, text analysis decisionsmodeled latent variables second, hidden layer network, finaloutput layer models action-value function.7. Note select action based Q(s, a), depends relevant sentence yi . sentenceselected conditioned action a. may look like cyclic dependency actionssentence relevance. However, case since Q(s, a), therefore sentence relevancep(y|s, a, d), computed every candidate action A. actual game action selectedestimate Q(s, a).675fiBranavan, Silver, & Barzilayinput layer ~x neural network encodes inputs model i.e.,current state s, candidate action a, document d. second layer consists twodisjoint sets hidden units ~y ~z, set operates stochastic 1-of-n softmaxselection layer (Bridle, 1990). activation function units layer standardsoftmax function:.Xp(yi = 1|~x) = e~ui ~xe~uk ~x ,kithyihidden unit ~y , ~ui weight vector corresponding yi , knumber units layer. Given activation function mathematicallyequivalent log-linear distribution, layers ~y ~z operate like log-linear models.Node activation softmax layer simulates sampling log-linear distribution.use layer ~y replicate log-linear model sentence relevance Equation (1),node yi representing single sentence. Similarly, unit zi layer ~z representscomplete predicate labeling sentence, Equation (2).8third feature layer f~ neural network deterministically computed givenactive units yi zi softmax layers, values input layer. unitlayer corresponds fixed feature function fk (s, a, yi , zi ) R. Finally output layerencodes action-value function Q(s, a) weighted linear combination unitsfeature layer, thereby replicating Equation (3) completing joint model.example kind correlations learned model, consider Figure 5.Here, relevant sentence already selected given game state. predicatelabeling sentence identified words irrigate settler describingaction take. game roll-outs return higher rewards irrigate actionsettler unit, model learn association action wordsdescribe it. Similarly, learn association state description wordsfeature values current game state e.g., word city binary feature nearcity. allows method leverage automatically extracted textual informationimprove game play.5.2 Parameter EstimationLearning method performed online fashion: game state st ,algorithm performs simulated game roll-out, observes outcome simulation,updates parameters ~u, ~v w~ action-value function Q(st , ). shownFigure 3, three steps repeated fixed number times actual game state.information roll-outs used select actual game action.algorithm relearns parameters action-value function every new game statest . specializes action-value function subgame starting st . Learningspecialized Q(st , ) game state common useful games complexstate spaces dynamics, learning single global function approximationparticularly difficult (Sutton et al., 2007). consequence function specializationneed online learning since cannot predict games states seen8. intention incorporate, action-value function, information relevantsentence. Therefore, practice, perform predicate labeling sentence selectedrelevance component model.676fiLearning Win Reading Manuals Monte-Carlo FrameworkSettlers unit, candidate action 1:plainsFeatures:action = irrigate action-word = "irrigate"action = irrigate state-word = "land"action = irrigate terrain = plainsaction = irrigate unit-type = settlerstate-word = "city" near-city = truecitySettlers unit, candidate action 2:settler unitRelevant text: "Use settlers irrigate land near city"Predicted action words:"irrigate", "settler"Predicted state words:"land", "near", "city"irrigateFeatures:action = build-cityaction = build-cityaction = build-cityaction = build-citystate-word = "city"build-cityaction-word = "irrigate"state-word = "land"terrain = plainsunit-type = settlernear-city = trueFigure 5: example text game attributes, resulting candidate action features.left portion game state arrows indicating game attributes.Also left sentence relevant game state along actionstate words identified predicate labeling. right two candidateactions settler unit along corresponding features. mentionedrelevant sentence, irrigate better two actions executinglead future higher game scores. feedback features shownallow model learn effective mappings actionword irrigate action irrigate, state-word city gameattribute near-city.testing, function specialization states cannot done priori, rulingtraditional training/test separation.Since model non-linear approximation underlying action-value functiongame, learn model parameters applying non-linear regression observed finalutilities simulated roll-outs. Specifically, adjust parameters stochasticgradient descent, minimize mean-squared error action-value Q(s, a)final utility R(s ) observed game state action a. resulting updatemodel parameters form:= [R(s ) Q(s, a)]22= [R(s ) Q(s, a)] Q(s, a; ),learning rate parameter. minimization performed via standard errorbackpropagation (Bryson & Ho, 1969; Rumelhart, Hinton, & Williams, 1986), resultingfollowing online parameter updates:w~ w~ + w [Q R(s )] f~(s, a, yi , zj ),~ui ~ui + u [Q R(s )] Q ~x [1 p(yi |)],~vi ~vi + v [Q R(s )] Q ~x [1 p(zi |)].677fiBranavan, Silver, & Barzilayw learning rate, Q = Q(s, a), w,~ ~ui ~vi parametersfinal layer, sentence relevance layer predicate labeling layer respectively.derivations update equations given Appendix6. Applying Modelgame test model on, Civilization II, multi-player strategy game set eitherEarth randomly generated world. player acts ruler one civilization,starts game units i.e., two Settlers, two Workers one Explorer.goal expand civilization developing new technologies, building cities newunits, win game either controlling entire world, successfully sendingspaceship another world. map game world divided grid typically4000 squares, grid location represents tile either land sea. Figure 6 showsportion world map particular instance game, along gameunits one player. experiments, consider two-player game Civilization IImap 1000 squares smallest map allowed Freeciv. map size usednovice human players looking easier game, well advanced players wantinggame shorter duration. test algorithms built-in AI playergame, difficulty level default Normal setting.96.1 Game States Actionsdefine game state Monte-Carlo search, map game world, alongattributes map tile, location attributes players citiesunits. examples attributes shown Figure 7. space possibleactions city unit defined game rules given current game state.example, cities construct buildings harbors banks, create new unitsvarious types; individual units move around grid, perform unitspecific actions irrigation Settlers, military defense Archers. Sinceplayer controls multiple cities units, players action space turn definedcombination possible actions cities units. experiments,average, player controls approximately 18 units unit 15 possible actions.resulting action space player large i.e., 1021 . effectively deallarge action space, assume given state, actions individual cityunit independent actions cities units player.10time, maximize parameter sharing using single action-value functioncities units player.9. Freeciv five difficulty settings: Novice, Easy, Normal, Hard Cheating. evidenced discussions games online forum (http://freeciv.wikia.com/index.php?title=Forum:Playing Freeciv),human players new game find even Novice setting hard.10. Since player executes game actions turn, i.e. opposing units fixed individual playersturn, opponents moves enlarge players action space.678fiLearning Win Reading Manuals Monte-Carlo FrameworkFigure 6: portion game map one instance Civilization II game. Threecities, several units single player visible map. Also visibledifferent terrain attributes map tiles, grassland, hills, mountainsdeserts.Nation attributes:-City attributes:-Amount gold treasury% world controlledNumber citiesPopulationKnown technologiesMap tile attributes:-City populationSurrounding terrain resourcesAmount food & resources producedNumber units supported cityNumber & type units presentUnit attributes:Terrain type (e.g. grassland, mountain, etc)Tile resources (e.g. wheat, coal, wildlife, etc)Tile riverConstruction tile (city, road, rail, etc)Types units (own enemy) present-Unit type (e.g., worker, explorer, archer, etc)Unit health & hit pointsUnit experienceunit city?unit fortied?Figure 7: Example attributes game state.679fiBranavan, Silver, & Barzilay6.2 Utility FunctionCritically important Monte-Carlo search algorithm, availability utilityfunction evaluate outcomes simulated game roll-outs. typical application algorithm, final game outcome terms victory loss usedutility function (Tesauro & Galperin, 1996). Unfortunately, complexity CivilizationII, length typical game, precludes possibility running simulation roll-outsgame completion. game, however, provides player real valued gamescore, noisy indicator strength civilization. Since playingtwo-player game, players score relative opponents used utilityfunction. Specifically, use ratio game score two players.116.3 Featurescomponents method operate features computed basic set textgame attributes. text attributes include words sentence alongparts-of-speech dependency parse information dependency types parentwords. basic game attributes encode game information available human playersvia games graphical user interface. examples attributes shownFigure 7.identify sentence relevant current game state candidate action,sentence relevance component computes features combined basic attributes~ two types firstgame sentence text. features ,computes Cartesian product attributes game attributescandidate sentence. second type consists binary features test overlapwords candidate sentence, text labels current game statecandidate action. Given 3.2% word tokens manual overlaplabels game, similarity features highly sparse. However, servesignposts guide learner shown results, method able operateeffectively even absence features, performs better present.Predicate labeling, unlike sentence relevance, purely language task~ computeoperates basic text attributes. features component, ,Cartesian product candidate predicate label words type, part-of-speechtag, dependency parse information. final component model, action-valueapproximation, operates attributes game state, candidate action,sentence selected relevant, predicate labeling sentence. featureslayer, f~, compute three way Cartesian product attributes candidateaction, attributes game state, predicate labeled words relevant~~ f~ compute approximately 158,500, 7,900, 306,800 featuressentence. Overall, ,respectively resulting total 473,200 features full model. Figure 8 showsexamples features.11. difference players scores also used utility function. However, practicescore ratio produced better empirical performance across algorithms baselines.680fiLearning Win Reading Manuals Monte-Carlo FrameworkSentence relevance features:1 action = build-city& tile-has-river = true& word = "build"1 action = irrigate& tile-is-next-to-city = true& word = "irrigate"0 otherwise0 otherwisePredicate labeling features:1 label = action& word = "city"& parent-word = "build"1 label = state& word = "city"& parent-label = "near"0 otherwise0 otherwiseAction-value features:1 action = build-city& tile-has-river = true& action-word = "build"& state-word = "river"1 action = irrigate& tile-terrain = plains& action-word = "irrigate"& state-word = "city"0 otherwise0 otherwiseFigure 8: examples features used model. feature, conditionstest game attributes highlighted blue, test wordsgame manual highlighted red.7. Experimental Setupsection, describe datasets, evaluation metrics, experimental frameworkused test performance method various baselines.7.1 Datasetsuse official game manual Civilization II strategy guide document.12text manual uses vocabulary 3638 word types, composed 2083 sentences,average 16.9 words long. manual contains information rulesgame, game user interface, basic strategy advice different aspectsgame. use Stanford parser (de Marneffe, MacCartney, & Manning, 2006),default settings, generate dependency parse information sentences gamemanual.7.2 Experimental Frameworkapply method Civilization II game, use games open source reimplementation Freeciv.13 instrumented FreeCiv allow method programmatically12. www.civfanatics.com/content/civ2/reference/Civ2manual.zip13. http://freeciv.wikia.com. Game version 2.2681fiBranavan, Silver, & BarzilayPrimary GameMonte-CarloPlayerGameServerModied GameGUI ClientIn-memoryFile SystemGame Simulation 1GameStrategy GuideGameServerModied GameGUI ClientGame StateGame Simulation 2GameServerModied GameGUI ClientGame Simulation 8GameServerModied GameGUI ClientFigure 9: diagram experimental framework, showing Monte-Carlo player,server primary game playing aims win, multiple gameservers simulated play. Communications multiple processes comprising framework via UNIX sockets in-memory file system.control game i.e., measure current game state, execute game actions,save/load current game state, start end games.14Across experiments, start game initial state run 100steps. step, perform 500 Monte-Carlo roll-outs. roll-out run 20simulated game steps halting simulation evaluating outcome. Notesimulated game step, algorithm needs select action game unit.Given average number units per player 18, results 180,000 decisions500 roll-outs. pairing decisions corresponding roll-outoutcome used datapoint update model parameters. use fixed learning rate0.0001 experiments. method, baselines, run 200independent games manner, evaluations averaged across 200 runs.use experimental settings across methods, model parametersinitialized zero.experimental setup consists Monte-Carlo player, primary gameaim play win, set simulation games. primary game simula14. addition instrumentation, code FreeCiv (both server client) changed increasesimulation speed several orders magnitude, remove bugs caused game crash.best knowledge, game rules functionality identical unmodified Freecivversion 2.2682fiLearning Win Reading Manuals Monte-Carlo Frameworktions simply separate instances Freeciv game. instance Freeciv gamemade one server process, runs actual game, one client process,controlled Monte-Carlo player. start roll-out, simulationsinitialized current state primary game via game save/reload functionalityFreeciv. Figure 9 shows diagram experimental framework.experiments run typical desktop PCs single Intel Core i7 CPUs (4hyper-threaded cores per CPU). algorithms implemented execute 8 simulationroll-outs parallel connecting 8 independent simulation games. computationalsetup, approximately 5 simulation roll-outs executed per second full model,single game 100 steps runs 3 hours. Since treat Freeciv game codeblack box, special care taken ensure consistency across experiments: codecompiled one specific machine, single fixed build environment (gcc 4.3.2);experiments run identical settings fixed set machines running fixedOS configuration (Linux kernel 2.6.35-25, libc 2.12.1).7.3 Evaluation Metricswish evaluate two aspects method: well improves game play leveraging textual information, accurately analyzes text learning game feedback.evaluate first aspect comparing method various baselines termspercentage games built-in AI Freeciv. AI fixed heuristicalgorithm designed using extensive knowledge game, intention challenging human players.15 such, provides good open-reference baseline. evaluatemethod measuring percentage games won, averaged 100 independent runs.However, full games sometimes last multiple days, making difficult extensive analysis model performance contributing factors. reason, primaryevaluation measures percentage games within first 100 game steps, averaged200 independent runs. evaluation underestimate model performancegame player gaining control entire game map within100 steps considered loss. Since games remain tied 100 steps, two equallymatched average players, playing other, likely win rate closezero evaluation.8. Resultsadequately characterize performance method, evaluate respectseveral different aspects. section, first describe game playing performanceanalyze impact textual information. Then, investigate quality textanalysis produced model terms sentence relevance predicate labeling.683fiBranavan, Silver, & BarzilayMethodRandomBuilt-in AIGameLatent variableFull modelRandomized text% Win0017.326.153.740.3% Loss10005.33.75.94.3Std. Err.2.73.13.53.4Table 1: Win rate method several baselines within first 100 game steps,playing built-in game AI. Games neither lost stillongoing. models win rate statistically significant baselines.results averaged across 200 independent game runs. standard errors shownpercentage wins.MethodGameLatent variableFull model% Wins24.831.565.4Standard Error4.34.64.8Table 2: Win rate method two text-unaware baselines built-in AI.results averaged across 100 independent game runs.8.1 Game PerformanceTable 1 shows performance method several baselines primary 100-stepevaluation. scenario, language-aware Monte-Carlo algorithm wins average53.7% games, substantially outperforming baselines, best non-languageaware method win rate 26.1%. dismal performance Random baselinegames Built-in AI, playing itself, indications difficultywinning games within first 100 steps. shown Table 2, evaluated full lengthgames, method win rate 65.4% compared 31.5% best text-unawarebaseline.1615. AI constrained follow rules game, access information typicallyavailable human players, information technology, cities units opponents.methods hand restricted actions information available human players.16. Note performance methods full games different listed previouspublications (Branavan, Silver, & Barzilay, 2011a, 2011b). previous numbers biasedcode flaw FreeCiv caused game sporadically crash middle game play.originally believed crash random, subsequently discovered happen often losinggames, thereby biasing win rates methods upwards. numbers presentedgame bug fixed, crashes observed experiments.684fiObserved game scoreLearning Win Reading Manuals Monte-Carlo FrameworkMonte-Carlo rolloutsFigure 10: Observed game score function Monte-Carlo roll-outs text-awarefull model, text-unaware latent-variable model. Model parametersupdated roll-out, thus performance improves roll-outs.seen, full models performance improves dramatically small numberroll-outs, demonstrating benefit derives textual information.8.1.1 Textual Advice Game Performanceverify characterize impact textual advice models performance,compare several baselines access textual information.simplest methods, Game only, models action-value function Q(s, a) linearapproximation games state action attributes. non-text-aware method wins17.3% games (see Table 1). confirm methods improved performancesimply due inherently richer non-linear approximation, also evaluate twoablative non-linear baselines. first these, Latent variable extends linear actionvalue function Game set latent variables. essence four layerneural network, similar full model, second layers units activatedbased game information. baseline wins 26.1% games (Table 1), significantlyimproving linear Game baseline, still trailing text-aware method27%. second ablative baseline, Randomized text, identical model,except given randomly generated document input. generate documentrandomly permuting locations words game manual, thereby maintainingdocuments statistical properties terms type frequencies. ensuresnumber latent variables baseline equal full model. Thus,baseline model capacity equal text-aware method accesstextual information. performance baseline, wins 40.3% games,confirms information extracted text indeed instrumental performancemethod.685fiBranavan, Silver, & BarzilayFigure 10 provides insight textual information helps improve game performanceshows observed game score Monte-Carlo roll-outs full modellatent-variable baseline. seen figure, textual information guidesmodel high-score region search space far quicker non-text awaremethod, thus resulting better overall performance. evaluate performancemethod varies amount available textual-information, conductexperiment random portions text given algorithm. shownFigure 11, methods performance varies linearly function amount text,Randomized text experiment corresponding point informationavailable text.8.1.2 Impact Seed Vocabulary Performancesentence relevance component model uses features compute similaritywords sentence, text labels game state action. assumesavailability seed vocabulary names game attributes. domain, 256unique text labels present game, 135 occur vocabulary game manual.results sparse seed vocabulary 135 words, covering 3.7% word types3.2% word tokens manual. Despite sparsity, seed vocabularypotentially large impact model performance since provides initial set wordgroundings. evaluate importance initial grounding, test methodempty seed vocabulary. setup, full model wins 49.0% games, showingseed words important, method also operate effectivelyabsence.8.1.3 Linguistic Representation Game Performancecharacterize contribution language game performance, conduct seriesevaluations vary type complexity linguistic analysis performedmethod. results evaluation shown Table 3. first these, Sentencerelevance, highlights contributions two language components model.algorithm, identical full model lacks predicate labeling component,wins 46.7% games, showing essential identify textual advice relevantcurrent game state, deeper syntactic analysis extracted text substantiallyimproves performance.evaluate importance dependency parse information language analysis,vary type features available predicate labeling component model.first ablative experiments, dependency information, removes dependencyfeatures leaving predicate labeling operate word type features. performancebaseline, win rate 39.6%, clearly shows dependency features crucialmodel performance. remaining three methods dependency label, dependencyparent POS tag dependency parent word drop dependency featurenamed after. contribution features model performance seenTable 3.686fiWin rateLearning Win Reading Manuals Monte-Carlo FrameworkRandomtextPercentage document text given modelFigure 11: performance text-aware model function amount textavailable it. construct partial documents randomly sub-sampling sentences full game manual. x-axis shows amount sentencesgiven method ratio full text. leftmost extremeperformance Randomized Text baseline, showing fitsperformance trend point useful textual information.MethodFull modelSentence relevancedependency informationdependency labeldepend. parent POS tagdepend. parent word% Win53.746.739.650.142.633.0% Loss5.92.83.03.04.04.0Std. Err.3.53.53.43.53.53.3Table 3: Win rates several ablated versions model, showing contributiondifferent aspects textual information game performance. Sentence relevanceidentical Full model, except lacks predicate labeling component.four methods bottom table ablate specific dependency features(as indicated methods name) predicate labeling componentfull model.8.1.4 Model Complexity vs Computation Time Trade-offOne inherent disadvantage non-linear models, compared simpler linear models,increase computation time required parameter estimation. Monte-CarloSearch setup, model parameters re-estimated simulated roll-out. Therefore,given fixed amount time, roll-outs done simpler faster model.nature, performance Monte-Carlo Search improves number rollouts. trade-off model complexity roll-outs important since simpler687fiBranavan, Silver, & Barzilay60%Full modelLatent variableGamerollout50%0ts20050ut0roll-ou30%10Win rate40%llro20%10%0%020406080100120140Computation time per game step (seconds)Figure 12: Win rate function computation time per game step. MonteCarlo search method, win rate computation time measured 100,200 500 roll-outs per game step, respectively.model could compensate using roll-outs, thereby outperform complexones. scenario particularly relevant games players limited amounttime turn.explore trade-off, vary number simulation roll-outs allowedmethod game step, recording win-rate average computation time pergame. Figure 12 shows results evaluation 100, 200 500 roll-outs.complex methods higher computational demands, results clearly showeven given fixed amount computation time per game step, text-awaremodel still produces best performance wide margin.8.1.5 Learned Game StrategyQualitatively, methods described learn basic rush strategy. Essentially,attempt develop basic technologies, build army, take opposing citiesquickly possible. performance difference different models essentiallydue well learn strategy.two basic reasons algorithms learn rush strategy. First, sinceattempting maximize game score, methods implicitly biased towards findingfastest way win happens rush strategy playingbuilt-in AI Civilization 2. Second, complex strategies typically requirecoordination multiple game units. Since models assume game units independent,688fiLearning Win Reading Manuals Monte-Carlo FrameworkPhalanxes twice eective defending cities warriors.Build city plains grassland river running it.rename city like, we'll refer washington.many dierent strategies dictating orderadvances researchedroad built, use settlers start improving terrain.settlers becomes active, chose build road.Use settlers engineers improve terrain square within city radiusFigure 13: Examples methods sentence relevance predicate labeling decisions.box shows two sentences (identified green check marks)predicted relevant, two not. box showspredicted predicate structure three sentences, indicating statedescription,A action description background words unmarked. Mistakesidentified crosses.cannot explicitly learn coordination putting many complex strategies beyondcapabilities algorithms.8.2 Accuracy Linguistic Analysisdescribed Section 5, text analysis method tightly coupled game playingterms modeling, terms learning game feedback. seenresults thus far, text analysis indeed help game play. sectionfocus game-driven text analysis itself, investigate well conformscommon notions linguistic correctness. comparing model predictionssentence relevance predicate labeling manual annotations.8.2.1 Sentence RelevanceFigure 13 shows examples sentence relevance decisions produced method.evaluate accuracy decisions, would ideally like use ground-truthrelevance annotation games user manual. however, impractical sincerelevance decision dependent game context, hence specific time stepgame instance. Therefore, evaluate sentence relevance accuracy using syntheticdocument. create document combining original game manual equal689fiSentence relevance accuracyBranavan, Silver, & Barzilay1.00.80.60.4Sentence relevanceMoving average0.2020406080100Game stepFigure 14: Accuracy methods sentence relevance predictions, averaged 100 independent runs.number sentences known irrelevant game. sentencescollected randomly sampling Wall Street Journal corpus (Marcus, Santorini,& Marcinkiewicz, 1993).17 evaluate sentence relevance synthetic documentmeasuring accuracy game manual sentences picked relevant.evaluation, method achieves average accuracy 71.8%. Givenmodel differentiate game manual text Wall Street Journal,number may seem disappointing. Furthermore, seen Figure 14,sentence relevance accuracy varies widely game progresses, high average94.2% initial 25 game steps. reality, pattern high initial accuracy followed lower average entirely surprising: official game manual CivilizationII written first time players. such, focuses initial portion game,providing little strategy advice relevant subsequent game play.18 reasonobserved sentence relevance trend, would also expect final layer neuralnetwork emphasize game features text features first 25 steps game.indeed case, seen Figure 15.test hypothesis, perform experiment first n stepsgame played using full model, subsequent 100 n steps played withoutusing textual information. results evaluation several values ngiven Figure 16, showing initial phase game indeed informationgame manual useful. fact, hybrid method performs wellfull model n = 50, achieving 53.3% win rate. shows method17. Note sentences WSJ corpus contain words city potentially confusealgorithm, causing select sentences relevant game play.18. reminiscent opening books games like Chess Go, aim guide playerplayable middle game, without providing much information subsequent game play.690fiLearning Win Reading Manuals Monte-Carlo Framework0.5Game features dominate1.0Text features dominateText feature importance1.5020406080100Game stepFigure 15: Difference norms text features game featuresoutput layer neural network. Beyond initial 25 steps game,method relies increasingly game features.Win rate60%40%20%0%20406080100# initial game steps text information usedFigure 16: Graph showing availability textual information initial stepsgame affects performance full model. Textual informationgiven model first n steps (the x axis), beyond pointalgorithm access text, becomes equivalent Latent Variablemodel i.e., best non-text model.able accurately identify relevant sentences information containpertinent game play, likely produce better game performance.691fiBranavan, Silver, & BarzilayMethodRandom labelingModel, first 100 stepsModel, first 25 stepsS/A/B33.3%45.1%48.0%S/A50.0%78.9%92.7%Table 4: Predicate labeling accuracy method random baseline. ColumnS/A/B shows performance three-way labeling words state, actionbackground, column S/A shows accuracy task differentiatingstate action words.game attributewordstate: grassland"city"state: grassland"build"state: hills"build"action: settlers_build_city"city"action: set_research"discovery"action: settlers_build_city"settler"action: settlers_goto_location"build"action: city_build_barracks"construct"action: research_alphabet"develop"action: set_research"discovery"Figure 17: Examples word game attribute associations learned via featureweights model.8.2.2 Predicate LabelingFigure 13 shows examples predicate structure output model. evaluateaccuracy labeling comparing gold-standard annotation gamemanual.19 Table 4 shows performance method terms accurately labelswords state, action background, also accurately differentiates stateaction words. addition showing performance improvement randombaseline, results display clear trend: evaluations, labeling accuracyhigher initial stages game. expected since model reliesheavily textual features beginning game (see Figure 15).verify usefulness methods predicate labeling, perform final setexperiments predicate labels selected uniformly random within full model.random labeling results win rate 44% performance similar sentencerelevance model uses predicate information. confirms methodable identify predicate structure which, noisy, provides information relevantgame play. Figure 17 shows examples textual information groundedgame, way associations learned words game attributes finallayer full model. example, model learns strong association19. Note ground truth labeling words either action-description, state-description, backgroundbased purely semantics sentence, independent game state. reason,manual annotation feasible, unlike case sentence relevance.692fiLearning Win Reading Manuals Monte-Carlo Frameworkgame-state attribute grassland words city build, indicating textualinformation building cities maybe useful players unit near grassland.9. Conclusionspaper presented novel approach improving performance controlapplications leveraging information automatically extracted text documents,time learning language analysis based control feedback. model biaseslearned strategy enriching policy function text features, thereby modelingmapping words manual state-specific action selection. effectively learngrounding, model identifies text relevant current game state, inducespredicate structure text. linguistic decisions modeled jointly usingnon-linear policy function trained Monte-Carlo Search framework.Empirical results show model able significantly improve game win rateleveraging textual information compared strong language-agnostic baselines.also demonstrate despite increased complexity model, knowledgeacquires enables sustain good performance even number simulationsreduced. Moreover, deeper linguistic analysis, form predicate labeling text,improves game play. show information syntactic structuretext crucial analysis, ignoring information large impactmodel performance. Finally, experiments demonstrate tightly coupling controllinguistic features, model able deliver robust performance presencenoise inherent automatic language analysis.Bibliographical NotePortions work previously presented two conference publications (Branavanet al., 2011a, 2011b). article significantly extends previous work, notablyproviding analysis model properties impact linguistic representationmodel performance, dependence model bootstrapping conditions, tradeoff models representational power empirical complexity (Section 8).paper also significantly increases volume experiments baseconclusions. addition, provide comprehensive description model, providingfull mathematical derivations supporting algorithm (Section 5.1 Appendix A).Acknowledgmentsauthors acknowledge support NSF (CAREER grant IIS-0448168, grant IIS0835652), DARPA BOLT Program (HR0011-11-2-0008), DARPA Machine ReadingProgram (FA8750-09-C-0172, PO#4910018860), Batelle (PO#300662) MicrosoftResearch New Faculty Fellowship. Thanks anonymous reviewers, Michael Collins,Tommi Jaakkola, Leslie Kaelbling, Nate Kushman, Sasha Rush, Luke Zettlemoyer,MIT NLP group suggestions comments. opinions, findings, conclusions,recommendations expressed paper authors, necessarilyreflect views funding organizations.693fiBranavan, Silver, & BarzilayAppendix A. Parameter Estimationparameter model estimated via standard error backpropagation (Bryson &Ho, 1969; Rumelhart et al., 1986). derive parameter updates, consider slightlysimplified neural network shown below. network identical model,sake clarity, single second layer ~y instead two parallel second layers~y ~z. parameter updates parallel layers ~y ~z similar, thereforeshow derivation ~y addition updates final layer.model, nodes yi network activated via softmax function;third layer, f~, computed deterministically active nodes second layervia function ~g (yi , ~x); output Q linear combination f~ weighted w:~p(yi = 1 | ~x; ~ui ) =e~ui ~xX,e~uk ~xkf~ =X~g (~x, yi ) p(yi | ~x; ~ui ),Q = w~ f~.goal minimize mean-squared error e gradient descent. achieveupdating model parameters along gradient e respect parameter. Usinggeneral term indicate models parameters, update takes form:1(Q R)2 ,2e=Q= (Q R).e =Equation (4), updates final layer parameters given by:Qwi= (Q R)w~ f~wi= (Q R) fi .wi = (Q R)694(4)fiLearning Win Reading Manuals Monte-Carlo FrameworkSince model samples one relevant sentence yi , best predicate labelingzi , resulting online updates output layer parameters w~ are:w~ w~ + w [Q R(s )] f~(s, a, yi , zj ),w learning rate, Q = Q(s, a). updates second layers parameters similar, somewhat involved. Again, Equation (4),ui,jQui,j= (Q R)w~ f~ui,jXw~~g (~x, yk ) p(yi | ~x; ~uk )= (Q R)ui,j= (Q R)k= (Q R) w~ ~g (~x, yi )p(yi | ~x; ~ui ).ui,j(5)Considering final term equation separately,p(yi | ~x; ~ui ) =ui,je~ui ~x,ui,j Z=Z =Xe~uk ~xkeu~ ~xe~ui ~x ui,j Zu~ ~xeZZ======e~ui ~x~ui ~xelogZui,jZ~ui ~xexjlog ZZui,j~ui ~xe1 ZxjZZ ui,j"#~ui ~xe1 X ~uk ~xxjeZZ ui,jk~ui ~xe1~uk ~xxj xj eZZ~ui ~xee~ui ~xxj 1.ZZ695fiBranavan, Silver, & BarzilayTherefore, Equation (5),ui,jp(yi | ~x; ~ui )ui,j~ui ~xee~ui ~x= (Q R) w~ ~g (~x, yi )xj 1ZZ= (Q R) xj w~ ~g (~x, yi ) p(yi | ~x; ~ui ) [1 p(yi | ~x; ~ui )]= (Q R) w~ ~g (~x, yi )= (Q R) xj Q [1 p(yi | ~x; ~ui )] ,Q = w~ ~g (~x, yi ) p(yi | ~x; ~ui ).resulting online updates sentence relevance predicate labeling parameters~u ~v are:~ui ~ui + u [Q R(s )] Q ~x [1 p(yi |)],~vi ~vi + v [Q R(s )] Q ~x [1 p(zi |)].696fiLearning Win Reading Manuals Monte-Carlo FrameworkAppendix B. Example Sentence Relevance PredictionsShown portion strategy guide Civilization II. Sentencesidentified relevant text-aware model highlighted green.Choosing location.building new city, carefully plan place it. Citizenswork terrain surrounding city square x-shaped pattern (seecity radius diagram showing exact dimensions). area calledcity radius (the terrain square settlers standingbecomes city square). natural resources availablepopulation settles affect ability produce food goods. Cities builtnear water sources irrigate increase crop yields, citiesnear mineral outcroppings mine raw materials. hand,cities surrounded desert always handicapped aridnessterrain, cities encircled mountains find arable croplandpremium. addition economic potential within city's radius,need consider proximity cities strategic valuelocation. Ideally, want locate cities areas offer combinationbenefits : food population growth, raw materials production,river coastal areas trade. possible, take advantagepresence special resources terrain squares (see terrain & movementdetails benefits).Strategic value.strategic value city site final consideration. city square'sunderlying terrain increase defender's strength citycomes attack. circumstances, defensive valueparticular city's terrain might important economic value;consider case continent narrows bottleneck rivalholds side. Good defensive terrain (hills, mountains, jungle)generally poor food production inhibits early growth city.need compromise growth defense, build cityplains grassland square river running possible.yields decent trade production gains 50 percent defense bonus.Regardless city built, city square easier defendunimproved terrain. city build city wallsimprovement, triples defense factors military units stationedthere. Also, units defending city square destroyed one timelose. Outside cities, units stacked together destroyedmilitary unit stack defeated (units fortressesexception; see fortresses). Placing cities seacoast givesaccess ocean. launch ship units explore worldtransport units overseas. coastal cities, sea powerinhibited.697fiBranavan, Silver, & BarzilayAppendix C. Examples Predicate Labeling PredictionsListed predicate labellings computed text-aware method examplesentences game manual. predicted labels indicated wordsletters A, S, B action-description, state-description background respectively.Incorrect labels indicated red check mark, along correct label brackets.road built, use settlers start improving terrain.settlers becomes active, chose build road.Use settlers engineers improve terrain square within city radius(A)(S)Bronze working allows build phalanx unitsB (S)order expand civilization , need build cities(S)BB (A)order protect city , phalanx must remain insideB(S)B(S)S(A)B(A)soon you've found decent site , want settlers buildB(S)B(S)B (A)(B)permanent settlement - city(A)city build city walls improvement(S)B (A)city undefended , move friendly army city captureB (S)Bbuild city terrain square except ocean.(A)B (S)(S)launch ship units explore world transport units overseas(A)B (S)B (S)Bcity disorder, disband distant military units, return home cities,(S)(A)(A)change home citiesbuild wonder discovered advance makes possible(A)698fiLearning Win Reading Manuals Monte-Carlo FrameworkAppendix D. Examples Learned Text Game Attribute MappingsShown examples word game-attribute associations learnedmodel. top ten game attributes strongest association feature weightlisted three example words attack, build grassland. fourthword, settler, seven attributes non-zero weights experiments used collectstatistics.attackbuildphalanx (unit)worker_goto (action)warriors (unit)settler_autosettle (action)colossus (wonder)worker_autosettle (action)city walls (city improvement)pheasant (terrain attribute)archers (unit)settler_irrigate (action)catapult (unit)worker_mine (action)palace (city improvement)build_city_walls (action)coinage (city production)build_catapult (action)city_build_warriors (action)swamp (terrain attribute)city_build_phalanx (action)grassland (terrain attribute)grasslandsettlersettler_build_city (action)settlers (state attribute)worker_continue_action (action)settler_build_city (action)pheasant (terrain attribute)city (state_attribute)city_build_improvement (action)grassland (terrain_attribute)city_max_production (action)plains (terrain_attribute)settlers (state attribute)road (terrain_attribute)city_max_food (action)workers (state attribute)settler_goto (action)worker_build_road (action)pyramids (city attribute)699fiBranavan, Silver, & BarzilayAppendix E. Features Used ModelFeatures used predict sentence relevancefollowing templates used compute features sentence relevance:Word W present sentence.Number words match text label current unit, attributeimmediate neighborhood unit, action consideration.units type U, (e.g., worker) word W present sentence.action type A, (e.g., irrigate) word W present sentence.Features used predict predicate structurefollowing templates used compute features predicate labeling words.label considered word (i.e., action, state background) denotedL.Label L word type W.Label L part-of-speech tag word T.Label L parent word dependency tree W.Label L dependency type dependency parent word D.Label L part-of-speech dependency parent word T.Label L word leaf node dependency tree.Label L word leaf node dependency tree.Label L word matches state attribute name.Label L word matches unit type name.Label L word matches action name.Features used model action-value functionfollowing templates used compute features action-value approximation.Unless otherwise mentioned, features look attributes player controlledmodel.Percentage world controlled.Percentage world explored.Players game score.Opponents game score.Number cities.Average size cities.Total size cities.700fiLearning Win Reading Manuals Monte-Carlo FrameworkNumber units.Number veteran units.Wealth gold.Excess food produced.Excess shield produced.Excess trade produced.Excess science produced.Excess gold produced.Excess luxury produced.Name technology currently researched.Percentage completion current research.Percentage remaining current research.Number game turns current research completed.following feature templates applied city controlled player:Current size city.Number turns city grows size.Amount food stored city.Amount shield stored city (shields used construct new buildingsunits city).Turns remaining current construction completed.Surplus food production city.Surplus shield production city.Surplus trade production city.Surplus science production city.Surplus gold production city.Surplus luxury production city.Distance closest friendly city.Average distance friendly cities.City governance type.Type building unit currently construction.Types buildings already constructed city.Type terrain surrounding city.Type resources available citys neighborhood.701fiBranavan, Silver, & Barzilayanother city neighborhood.enemy unit neighborhood.enemy city neighborhood.following feature templates applied unit controlled player:Type unit.Moves left unit current game turn.Current health unit.Hit-points unit.unit veteran.Distance closest friendly city.Average distance friendly cities.Type terrain surrounding unit.Type resources available units neighborhood.enemy unit neighborhood.enemy city neighborhood.following feature templates applied predicate-labeled word sentenceselected relevant, combined current state action attributes:Word W present sentence, action considered A.Word W predicate label P present sentence, action consideredA.Word W present sentence, current units type U, actionconsidered A.Word W predicate label P present sentence, current units type U,action considered A.Word W present sentence, current units type U.Word W predicate label P present sentence, current units typeU.Word W present sentence, attribute text label presentcurrent units neighborhood.Word W predicate label P present sentence, attribute text labelpresent current units neighborhood.702fiLearning Win Reading Manuals Monte-Carlo FrameworkReferencesBalla, R., & Fern, A. (2009). UCT tactical assault planning real-time strategy games.Proceedings IJCAI, pp. 4045.Barnard, K., & Forsyth, D. A. (2001). Learning semantics words pictures.Proceedings ICCV, pp. 408415.Barto, A. G., & Mahadevan, S. (2003). Recent advances hierarchical reinforcementlearning. Discrete Event Dynamic Systems, 13, 341379.Billings, D., Castillo, L. P., Schaeffer, J., & Szafron, D. (1999). Using probabilistic knowledgesimulation play poker. Proceedings AAAI/IAAI, pp. 697703.Branavan, S., Chen, H., Zettlemoyer, L., & Barzilay, R. (2009). Reinforcement learningmapping instructions actions. Proceedings ACL, pp. 8290.Branavan, S., Silver, D., & Barzilay, R. (2011a). Learning win reading manualsmonte-carlo framework. Proceedings ACL, pp. 268277.Branavan, S., Silver, D., & Barzilay, R. (2011b). Non-linear monte-carlo search civilizationII. Proceedings IJCAI, pp. 24042410.Branavan, S., Zettlemoyer, L., & Barzilay, R. (2010). Reading lines: Learningmap high-level instructions commands. Proceedings ACL, pp. 12681277.Bridle, J. S. (1990). Training stochastic model recognition algorithms networks leadmaximum mutual information estimation parameters. Advances NIPS, pp.211217.Bryson, A. E., & Ho, Y.-C. (1969). Applied optimal control: optimization, estimation,control. Blaisdell Publishing Company.Chen, D. L., & Mooney, R. J. (2008). Learning sportscast: test grounded languageacquisition. Proceedings ICML, pp. 128135.Chen, D. L., & Mooney, R. J. (2011). Learning interpret natural language navigationinstructions observations. Proceedings AAAI, pp. 859865.Clarke, J., Goldwasser, D., Chang, M.-W., & Roth, D. (2010). Driving semantic parsingworlds response. Proceedings CoNNL, pp. 1827.de Marneffe, M.-C., MacCartney, B., & Manning, C. D. (2006). Generating typed dependency parses phrase structure parses. Proceedings LREC, pp. 449454.Eisenstein, J., Clarke, J., Goldwasser, D., & Roth, D. (2009). Reading learn: Constructingfeatures semantic abstracts. Proceedings EMNLP, pp. 958967.Fleischman, M., & Roy, D. (2005). Intentional context situated natural language learning.Proceedings CoNLL, pp. 104111.Gelly, S., Wang, Y., Munos, R., & Teytaud, O. (2006). Modification UCT patternsMonte-Carlo Go. Tech. rep. 6062, INRIA.Goldwasser, D., Reichart, R., Clarke, J., & Roth, D. (2011). Confidence driven unsupervisedsemantic parsing. Proceedings ACL, pp. 14861495.703fiBranavan, Silver, & BarzilayGorniak, P., & Roy, D. (2005). Speaking sidekick: Understanding situated speechcomputer role playing games. Proceedings AIIDE, pp. 5762.Liang, P., Jordan, M. I., & Klein, D. (2009). Learning semantic correspondences lesssupervision. Proceedings ACL, pp. 9199.Liang, P., Jordan, M. I., & Klein, D. (2011). Learning dependency-based compositionalsemantics. Proceedings ACL, pp. 590599.Marcus, M. P., Santorini, B., & Marcinkiewicz, M. A. (1993). Building large annotatedcorpus english: penn treebank. Computational Linguistics, 19 (2), 313330.Oates, J. T. (2001). Grounding knowledge sensors: Unsupervised learning languageplanning. Ph.D. thesis, University Massachusetts Amherst.Roy, D. K., & Pentland, A. P. (2002). Learning words sights sounds: computational model. Cognitive Science 26, 113146.Rumelhart, D. E., Hinton, G. E., & Williams, R. J. (1986). Learning representationsback-propagating errors. Nature, 323, 533536.Schafer, J. (2008). UCT algorithm applied games imperfect information.Diploma Thesis. Otto-von-Guericke-Universitat Magdeburg.Sheppard, B. (2002). World-championship-caliber Scrabble. Artificial Intelligence, 134 (1-2),241275.Silver, D., Sutton, R., & Muller, M. (2008). Sample-based learning search permanent transient memories. Proceedings ICML, pp. 968975.Siskind, J. M. (2001). Grounding lexical semantics verbs visual perception usingforce dynamics event logic. Journal Artificial Intelligence Research, 15, 3190.Sturtevant, N. (2008). analysis UCT multi-player games. Proceedings ICCG,pp. 3749.Sutton, R. S., & Barto, A. G. (1998). Reinforcement Learning: Introduction. MITPress.Sutton, R. S., Koop, A., & Silver, D. (2007). role tracking stationary environments. Proceedings ICML, pp. 871878.Tellex, S., Kollar, T., Dickerson, S., Walter, M. R., Banerjee, A. G., Teller, S., & Roy, N.(2011). Understanding natural language commands robotic navigation mobilemanipulation. Proceedings AAAI, pp. 15071514.Tesauro, G., & Galperin, G. (1996). On-line policy improvement using Monte-Carlo search.Advances NIPS, pp. 10681074.Vogel, A., & Jurafsky, D. (2010). Learning follow navigational directions. ProceedingsACL, pp. 806814.Yu, C., & Ballard, D. H. (2004). integration grounding language learningobjects. Proceedings AAAI, pp. 488493.Zettlemoyer, L., & Collins, M. (2009). Learning context-dependent mappings sentenceslogical form. Proceedings ACL, pp. 976984.704fiJournal Artificial Intelligence Research 43 (2012) 173210Submitted 08/11; published 02/12Counting-Based Search:Branching Heuristics Constraint Satisfaction ProblemsGilles Pesantgilles.pesant@polymtl.caEcole polytechnique de Montreal, Montreal, CanadaClaude-Guy Quimperclaude-guy.quimper@ift.ulaval.caUniversite Laval, Quebec, CanadaAlessandro Zanarinialessandro.zanarini@dynadec.comDynadec Europe, BelgiumAbstractDesigning search heuristic constraint programming reliable across problemdomains important research topic recent years. paper concentratesone family candidates: counting-based search. heuristics seek make branchingdecisions preserve solutions determining proportion solutionsindividual constraint agree decision. Whereas generic search heuristicsconstraint programming rely local information level individual variable,search heuristics based global information constraint level.design several algorithms used count number solutions specific familiesconstraints propose search heuristics exploiting information. experimental part paper considers eight problem domains ranging well-establishedbenchmark puzzles rostering sport scheduling. initial empirical analysis identifiesheuristic maxSD robust candidate among proposals. evaluate latterstate art, including latest generic search heuristics, restarts,discrepancy-based tree traversals. Experimental results show counting-based searchgenerally outperforms generic heuristics.1. IntroductionConstraint Programming (cp) powerful technique solve combinatorial problems.applies sophisticated inference reduce search space combination variableand value-selection heuristics guide exploration search space.inference encapsulated constraint appearing model problem, users mayconsider black box. contrast, search cp programmable, mixedblessing. allows one easily tailor search problem, adding expertise domainknowledge, may also discourage average user would prefer genericfairly robust default search heuristic works well time. generic searchheuristics indeed available cp robustness remains issue.Whereas generic search heuristics constraint programming rely informationlevel individual variable (e.g. domain size degree constraintnetwork), investigate search heuristics based global information. Globalconstraints cp successful encapsulate powerful dedicated inference algorithms foremost bring underlying structure combinatorialproblems. exposed structure also exploited search. Search heuristicsc2012AI Access Foundation. rights reserved.fiPesant, Quimper, & Zanarinifollowing fail-first principle (detect failure early possible) centered constraints guided count number solutions left constraint.might example focus search constraint currently smallest numbersolutions, recognizing failure necessarily occurs constraint admittingsolution. also count number solutions featuring given variable-valueassignment individual constraint, favoring assignments appearing high proportionsolutions hope choice generally brings us closer satisfyingwhole csp.concept counting-based search heuristics already introduced, recently Zanarini Pesant (2009). specific contributions paper are: additional counting algorithms, including families constraints, thus broadeningapplicability heuristics; experiments include effect common featuressearch heuristics search tree traversal order, restarts learning; considerableempirical evidence counting-based search outperforms generic heuristics.rest paper: Section 2 provides background reviews related work; Sections 3 5 present counting algorithms several usual constraints; Section 6introduces counting-based search heuristics exploit algorithms previous sections; Section 7 reports extensive experimental study comparing proposedheuristics state-of-the-art generic heuristics many problem domains; finally Section 8concludes paper.2. Background Related Workstart usual general representation formalism cp.Definition 1 (constraint satisfaction problem (csp)). Given finite set variables X ={x1 , x2 , . . .}, finite domain possible values variables, = {D1 , . . . , D|X| },xi Di (1 |X|), finite set constraints (relations) subsets X,C = {c1 , c2 , . . .}, constraint satisfaction problem (X, D, C) asks assignmentvalue Di variable xi X satisfies (belongs to) cj C.recall definitions notation Pesant (2005) Zanarini Pesant(2009).Definition 2 (solution count). Given constraint c(x1 , . . . , xn ) respective finite domains Di 1in, let #c(x1 , . . . , xn ) denote number n-tuples correspondingrelation, called solution count.Definition 3 (solution density). Given constraint c(x1 , . . . , xn ), respective finite domainsDi 1in, variable xi scope c, value Di , call(xi , d, c) =#c(x1 , . . . , xi1 , d, xi+1 , . . . , xn )#c(x1 , . . . , xn )solution density pair (xi , d) c. measures often certain assignment partsolution c.174fiCounting-Based SearchHeuristics usually classified two main categories: static variable ordering heuristics(SVOs) dynamic variable ordering heuristics (DVOs). former order variablesprior search revise ordering search. Common SVOs lexicographic order, lexico, decreasing degree (i.e. number constraints variableinvolved), deg. DVOs generally considered effective exploit informationgathered search. often follow fail-first principle originally introducedHaralick Elliott (1980, p. 263) i.e. succeed, try first likelyfail. authors proposed widely-used heuristic dom branchesvariables smallest domain; aim heuristic minimize branch depth.similar heuristic, proposed Brelaz (1979), selects variable smallest remaining domain breaks ties choosing one highest dynamic degree ddeg 1 (that is, one constraining largest number unbound variables). BessiereRegin (1996) Smith Grant (1998) combined domain degree informationminimizing ratio dom/deg dom/ddeg.2.1 Impact-Based HeuristicsRefalo (2004) proposed Impact Based Search (IBS), heuristic chooses variablewhose instantiation triggers largest search space reduction (highest impact)approximated reduction product variable domain cardinalities.formally impact variable-value pair is:I(xi = d) = 1Paf terPbef orePaf ter Pbef ore products domain cardinalities respectivelybranching xi = (and propagating decision). impact either computedexactly given node search (the exact computation provides better informationtime consuming) approximated average reduction observedsearch (hence automatically collected on-the-go almost additional cost), is:Pk= d) = kK (xi = d)I(x|K|K index set impact observed far assignment xi = d.variable impact defined Refalo (2004)X= d)I(xi ) =1 I(xdDi0Di0 current domain variable xi . Impact initialization fundamentalobtain good performance even root search tree; therefore, Refalo proposedinitialize impacts probing variable-value pair root node (notesubsumes reduced form singleton consistency root node quitecomputationally costly). IBS selects variable largest impact (hence trying1. also referred future degree forward degree literature.175fiPesant, Quimper, & Zanarinimaximize propagation effects reduction search space) selectsvalue smallest impact (hence leaving choices future variables).interesting connection impact-based heuristics, Szymanek OSullivan(2006) proposed query model constraints approximate number filteredvalues constraint individually. information exploited design variable and/or value selection heuristic. Nonetheless, differs impact-based searchtake consideration constraint separately, counting-based heuristics(Zanarini & Pesant, 2009) information provided coarse-grained actualsolution counts.2.2 Conflict-Driven HeuristicsBoussemart, Hemery, Lecoutre, Sais (2004) proposed conflict-driven variable orderingheuristic: extended concept variable degree integrating simple effectivelearning technique takes failures account. Basically constraint associated weight increased one time constraint leads failure (i.e.domain wipe-out). variable weighted degree wdeg sum weightsconstraints involved. Formally, weighted degree variable is:Xwdeg (xi ) =weight[c] | V ars(c) 3 xi |F utV ars(c)| > 1cCF utV ars(c) denotes uninstantiated variables constraint c, weight[c]weight V ars(c) variables involved c. heuristics proposed simply choosevariable maximizes wdeg minimizes dom/wdeg. heuristics offer generalmethod deal global constraints: natural extension increase weightevery variable failed constraint may anythingfailure, dilutes conflict information. also particularly sensitiverevision orderings (i.e. ordering propagation queue) hence leading varyingperformance. Grimes Wallace (2006, 2007) proposed adaptations dom/wdegcombined restarts updating weights value deletions well. BalafoutisStergiou (2008b) proposed, among improvements original dom/wdeg,weight aging, constraint weights periodically reduced. limits inertiaconstraints got significant weight early search criticalanymore later on.Nowadays heuristics dom/wdeg IBS considered state artgeneric heuristics clear dominance one (Balafoutis & Stergiou,2008a). Finally note rely hypothesis learned earlysearch tend remain true throughout search tree: impacts change muchone search tree node other; constraints lead domain wipe-outsdifferent parts search tree.2.3 Approximated Counting-Based Heuristicsidea using approximation number solutions problem heuristicnew. Kask, Dechter, Gogate (2004) approximate total number solutionsextending partial solution csp use value selection heuristic, choosing176fiCounting-Based Searchvalue whose assignment current variable gives largest approximate solutioncount. implementation optimized binary constraints performs well comparedpopular strategies. Hsu, Kitching, Bacchus, McIlraith (2007) later Bras,Zanarini, Pesant (2009) apply Belief Propagation algorithm within ExpectationMaximization framework (EMBP) order approximate variable biases (or marginals)i.e. probability variable takes given value solution. resulting heuristics tendeffective quite time-consuming. One way differentiate workfocus fine-grained information individual constraints whereas workcoarser information whole problem.3. Counting Alldifferent Constraintsalldifferent constraint restricts set variables pairwise different (Regin,1994).Definition 4 (Alldifferent Constraint). Given set variables X = {x1 , . . . , xn }respective domains D1 , . . . , Dn , set tuples allowed alldifferent(X) are:{(d1 , d2 , . . . , dn ) | di Di , di 6= dj 6= j}define associated (0-1) square matrix = (aid ) | i=1,...,n Di | rowscolumns aid = 1 iff Di 2 . distinct values domainsvariables, say p more, add p rows filled 1s matrix A. equivalentrepresentation given bipartite value graph vertex variable valueedges corresponding 1 entries A.discussed Zanarini Pesant (2009), counting number solutionsalldifferent constraint equivalent computing permanent (or numbermaximum matchings value graph), formally definedperm(A) =nXa1,d perm(A1,d )(1)d=1A1,d denotes submatrix obtained removing row 1 column (thepermanent empty matrix equal 1). p extra rows added, result mustdivided p! shown Zanarini Pesant (2010).computing permanent well-known #P -complete (Valiant, 1979),Zanarini Pesant (2009) developed approach based sampling gave closeapproximations led effective heuristics hard instances. Howevercompetitive easy medium difficulty instances additional computationaleffort. next section describes approach based upper bounds, trading approximation accuracy significant speedup counting procedure.32. notational convenience without loss generality, identify domain values consecutivenatural numbers.3. originally introduced Zanarini Pesant (2010).177fiPesant, Quimper, & Zanarini3.1 Upper Boundsfollowing assume notational convenience matrix n rowsP columnsdenote ri sum elements ith row (i.e. ri = nd=1 aid ).first upper bound permanent conjectured Minc (1963) later provedBregman (1973):nperm(A)(ri !)1/ri .(2)i=1Recently Liang Bai (2004) proposed second upper bound (with qi = min{d ri2+1 e, 2i e}):perm(A)2nqi (ri qi + 1).(3)i=1Neither two upper bounds strictly dominates other. followingdenote U B BM (A) Bregman-Minc upper bound U B LB (A) Liang-Baiupper bound. Jurkat Ryser (1966) proposed another bound:perm(A)nmin(ri , i).i=1However considered generally weaker U B BM (A) (see Soules, 2005 comprehensive literature review).3.1.1 Algorithmdecided adapt U B BM U B LB order compute approximation solutiondensities alldifferent constraint. Assigning variable xi translates replacingith row unit vector e(d) (i.e. setting ith row matrix 0 exceptelement column d). write Axi =d denote matrix except xi fixed d.call local probe assignment xi = performed compute Axi =d i.e. temporaryassignment propagate constraint except one processed.upper bound number solutions alldifferent(x1 , . . . , xn ) constraintrelated adjacency matrix simply#alldifferent(x1 , . . . , xn ) min{U B BM (A), U B LB (A)}Note Formulas 2 3, ri equal |Di |; since |Di | ranges 0 n,factors precomputed stored: vector BM f actors[r] = (r!)1/r , r = 0, . . . , nfirst bound similarly second one (with factors depending |Di |i). Assuming |Di | returned O(1), computing formulas takes O(n) time.Solution densities approximatedmin{U B BM (Axi =d ), U B LB (Axi =d )}Pnormalizing constant dDi (xi , d, alldifferent) = 1.(xi , d, alldifferent)178fiCounting-Based Searchlocal probe xi = may trigger local propagation according levelconsistency want achieve; therefore Axi =d subject filtering performedconstraint processed. Since two bounds Formulas 2 3 depend |Di |,stronger form consistency would likely lead changes domainsbounds, presumably accurate solution densities.want compute (xi , d, alldifferent) = 1, . . . , n Ditrivial implementation would compute Axi =d variable-value pair; total timecomplexity would O(mP + mn) (where sum cardinalities variabledomains P time complexity filtering).Although unable improve worst case complexity, following propose algorithm performs definitely better practice. introduceadditional notation: write Dk0 variable domains enforcing -consistency4constraint alone Ixi =d set indices variables subjectdomain change due local probe ensuing filtering, is, k Ixi =d iff|Dk0 | 6= |Dk |. describe algorithm Bregman-Minc bound easilyadapted Liang-Bai bound.basic idea compute bound matrix reuse speedcomputation bounds Axi =d = 1, . . . , n Di . LetBM f actors[|D0 |]BM f actors[|Dkk |] k Ixi =dk =1otherwiseU B BM (Axi =d ) =nBM f actors[|Dk0 |] =k BM f actors[|Dk |]k=1k=1= U B BM (A)nnkk=1Note k k = (i.e. computing U B BM (Axi =d )) depend d;however Ixi =d depend domain filtering.Algorithm 1 shows pseudo code computing U B BM (Axi =d ) = 1, . . . , nDi . Initially, computes bound matrix (line 1); then, given i,computes upper bound modified accordingly (line 3). Afterwards,Di , -consistency enforced (line 7) iterates set modified variables(line 9-10) compute k different 1. store upper boundvariable value structure V arV alU B[i][d]. computing boundvariables-values assignment xi = needs undone (line 12). Finally,normalize upper bounds order correctly return solution densities (line 13-14). Letequal maxi,d |Ixi =d |, time complexity O(mP + mI).matrix dense expect ' n. Therefore k different 1need computed. soon matrix becomes sparse enough nsmall fraction k need computed, Algorithm 1 advantage.4. Stands form consistency179fiPesant, Quimper, & Zanarini123456789101112131415UB = U B BM (A);= 1, . . . , nvarUB = UB * BMfactors[1] / BMfactors[|Di |];total = 0;forall Diset xi = d;enforce -consistency;VarValUB[i][d] = varUB;forall k Ixi =d \ {i}VarValUB[i][d] = VarValUB[i][d] * BMfactors[|Dk0 |] / BMfactors[|Dk |];total = total + VarValUB[i][d];rollback xi = d;forall DiSD[i][d] = VarValUB[i][d]/total;return SD;Algorithm 1: Solution Densitiessampling algorithm introduced Zanarini Pesant (2009) performed wellapproximating solution count solution densities, caseupper bounds. latter fact produce weak approximations solution countoffer good trade-off performance accuracy solution densities:taking ratio two solution counts appears cancel weakness originalapproximations (see Zanarini & Pesant, 2010 details).3.2 Symmetric AlldifferentRegin (1999) proposed symmetric alldifferent constraint special casealldifferent variables values defined set.equivalent traditional alldifferent additional set constraints statingvariable assigned value j iff variable j assigned value i. constraint usefulmany real world problems set entities need paired up; particularly,sport scheduling problems teams need form set pairs define games.symmetric alldifferent achieving domain consistency provides pruning powerequivalent decomposition given alldifferent constraint setxi = j xj = constraints (Regin, 1999). filtering algorithm inspiredone alldifferent difference matching computed graph(not necessarily bipartite) called contracted value graph vertices values representing entity collapsed single vertex (i.e. vertex xi vertexmerged single vertex representing variable value). Reginproved bijection matching contracted value graphsolution symmetric alldifferent constraint. Therefore, counting numbermatchings contracted value graph corresponds counting number solutionsconstraint.180fiCounting-Based SearchFriedland (2008) Alon Friedland (2008) extended Bregman-Minc upperbound consider number matchings general undirected graphs. Therefore,exploit bound previous section order provide upper boundsolution count solution densities symmetric alldifferent constraint.upper bound number matchings graph G = (V, E) representing contractedvalue graph following:1#matchings(G)(deg(v))! 2deg(v)(4)vVdeg(v) degree vertex v #matchings(G) denotes numbermatchings graph G. Note case bipartite graph, bound equivalentBregman-Minc upper bound.algorithm counting number solutions computing solution densitieseasily derived proposed alldifferent.Example 1. Consider symmetric alldifferent defined six variables x1 , . . . , x6one domain equal {1, . . . , 6}. Figure 1 associated contracted value graphdepicted (together possible solution constraint). case, numbersolutions symmetric alldifferent computed 5 3 = 15. contractedvalue graph vertex connected vertex, forming clique size 6, thereforevertices degree equal 5. upper bound proposed Friedland equal to:1#matchings(G)(deg(v))! 2deg(v) = (5!1/10 )6 17.68vValldifferent formulation, related value graph variable vertices connectedvalues (from 1 6) thus ri equal 6. consider ruleedges causing degenerated assignments (xi = i) end value graphri equal 5. Bregman-Minc upper bound would give:perm(A)n(ri !)1/ri = (5!(1/5) )6 312.62.i=1result obviously far upper bound given Formula 4 wellexact value.4. Counting Global Cardinality Constraintspresent section extend results obtained Section 3 GlobalCardinality Constraint (gcc), generalization alldifferent constraint.Definition 5 (Global Cardinality Constraint). set solutions constraint gcc(X, l, u)X set k variables, l u respectively lower upper boundsvalue, defined as:[(gcc(X, l, u)) = {(d1 , . . . , dk ) | di Di , ld |{di |di = d}| ud DX =Dj }xj X181fiPesant, Quimper, & Zanarini132546Figure 1: Contracted Value Graph constraint symmetric alldifferent Example1. Edges bold represent possible solution.consider gcc fixed variables removed lowerupper bounds adjusted accordingly (the semantics constraint unchanged).refer new set variables X 0 = {x X | x bound}; lower bounds l0ld0 = ld |{x X | x = d}| upper bounds u0 defined similarly; assumeconstraint maintains -consistency ld0 0 u0d 0 DX .Inspired Quimper, Lopez-Ortiz, van Beek, Golynski (2004) Zanarini, Milano,Pesant (2006), define Gl lower bound graph.Definition 6. Let Gl (X 0 Dl , El ) undirected bipartite graph X 0 setunbounded variables Dl extended value set, DX graph ld0vertices d1 , d2 , . . . representing (ld0 possibly equal zero). edge (xi , dj ) ElDi .Note maximum matching Gl corresponds partial assignment variables X satisfies gcc lower bound restriction number occurrencesvalue. partial assignment may may completed full assignmentsatisfies upper bound lower bound restrictions (here takeconsideration augmenting paths Zanarini et al., 2006 instead fix variablesvalues represented matching Gl ).Example 2. Suppose gcc defined X = {x1 , . . . , x6 } domains D1 = D4 ={1, 2, 3}, D2 = {2}, D3 = D5 = {1, 2} D6 = {1, 3}; lower upper boundsvalues respectively l1 = 1, l2 = 3, l3 = 0 u1 = 2, u2 = 3, u3 = 2. Consideringx2 = 2, lower upper bounds value 2 respectively l20 = 2 u02 = 2.lower bound graph shown Figure 2a: variable x2 bounded thus appeargraph, value vertex 2 represented two vertices l20 = 2 (althoughl2 = 3); finally value vertex 3 appear lower bound equal zero.matching shown figure (bold edges) maximum. However fix assignmentsrepresented (x1 = 2, x4 = 2, x6 = 1) possible consistent solutionsince x3 x5 assigned either 1 2 hence exceeding upper boundrestriction. compute permanent two additional fake value vertices would addedgraph connected variable vertices (not shown figure).182fiCounting-Based Searchx11x1x32x3x420x41x5x53x6x630(a)(b)Figure 2: Lower Bound Graph (a) Residual Upper Bound Graph (b) Example 2Every partial assignment satisfies lower bound restriction might correspondseveral maximum matchings Gl due duplicated vertices.Q partialassignment satisfying lower bound restriction exactly dDX ld0 ! maximummatchings corresponding particular partial assignment. take considerationExample 2 shown Figure 2a, variables x1 x4 may matched respectivelypermutation vertices 2 20 , however matter permutation, setmatchings represents always assignment x2 x4 value 2.Let Ml 5 set maximum matchings Gl . define f : Ml N, functioncounts number possible ways maximum matching extended full gccsolution. shown Example 2, f possibly equal zero. Note numberremaining variablesneed assigned starting matching Ml equalP00K = |X | dDX ld .total number solutions satisfying gcc is:P|Ml | maxmMl (f (m))U B(Gl ) maxmMl (f (m))mM f (m)QQ#gcc(X, l, u) = Q l 0(5)00dDX ld !dDX ld !dDX ld !U B(Gl ) represents upper bound permanent 0 1 matrix corresponding graph Gl .Note computing f (m) hard computing permanent. fact l urespectively equal 0 1 value, result alldifferent constraintequation 5 simplifies #gcc(X, l, u) = f (m) = {} f (m) correspondspermanent.computing f (m) #P-complete problem own, focus upper bounding f (m). order that, introduce upper bound residual graph. Intuitively,similar lower bound graph considers upper bound restriction.Definition 7. Let Gu (X 0 Du , Eu ) undirected bipartite graph X 0 setunbounded variables Du extended value set, DX graph5. DX , ld0 = 0 Ml = {} |Ml | = 1183fiPesant, Quimper, & Zanariniu0d ld0 vertices d1 , d2 , . . . representing (if u0d ld0 equal zero vertexrepresenting d). edge (xi , dj ) Eu Di u0d ld0 > 0.Similarly lower bound matching, matching Gu covers K variables maymay completed full assignment satisfying complete gcc. Figure 2b showsresidual upper bound graph Example 1: value 2 disappears graph sinceu02 = l20 i.e. starting matching lower bound graph, constraintsvalue 2 already satisfied.graphs comIn order compute maxmMl (f (m)), build |X|Kbination K variables, choose one maximizes permanent.practically, given nature U B B U B LB , suffices choose K variablescontribute highest factor computation upper bounds;easily done O(n log K) iterating n variables maintaining heapK entries highest factor. write Gu Gu graphsK variables maximize respectively U B B U B LB present; note Gu mightdifferent Gu .recall although K variables chosen, graphs Gu Gucompleted fake vertices way equal number vertices twovertex partitions. AsQin lower bound graph, given upper bound scaledfactor dDX (u0d ld0 )!. Equation 5, number gcc solutionsbounded by:#gcc(X, l, u)U B(Gl ) min(U B B (Gu ), U B LB (Gu ))Q000dDX (ld !(ud ld )!)(6)Scaling also fake vertices used permanent bounds factors degradequality upper bound. Nonetheless, solution densities computed ratiotwo upper bounds therefore scaling factors often attenuated.Example 3. refer gcc described Example 2. exact number solutions19. U B B U B LB lower bound graph Figure 2a 35 (the scalingtwo fake value vertices already considered). upper bound 2 variablesneed assigned one maximizing bounds x1 x4 (or possibly x6 ):resulting permanent upper bound 6. upper bound total number gcc solutions00b 3564 c = 52 division 4 due l2 ! = 2! u3 ! = 2!.Figure 3 shows lower bound residual upper bound graph constraintx1 = 1 domain consistency achieved. Vertex x1 removed l10 = 0u01 = 1. graph Gl permanent upper bound 6. number unassignedvariables Gu 2 ones maximizing upper bounds x4 x6 , givingupper bound 6. total number gcc solutions x1 = 1 boundedb 664 c = 9; approximate solution density normalizing thus 9/52. Notenormalization, turns 0.18 whereas exact computation5/19 0.26.184fiCounting-Based Searchx3x3x42x4x520x5x61x6330(a)(b)Figure 3: Lower Bound Graph (a) Residual Upper Bound Graph (b) assuming x1 = 15. Counting Regular Knapsack Constraintsregular constraint useful express patterns must exhibited sequencesvariables.Definition 8 (Regular Language Membership Constraint). regular(X, ) constraintholds values taken sequence finite domain variables X = hx1 , x2 , . . . , xk spellword belonging regular language defined deterministic finite automaton= (Q, , , q0 , F ) Q finite set states, alphabet, : Q Qpartial transition function, q0 Q initial state, F Q set final (oraccepting) states.Linear equalities inequalities expressed knapsack constraints.Definition 9 (Knapsack Constraint). knapsack(x, c, `, u) constraint holds` cx uc = (c1 , c2 , . . . , ck ) integer row vector, x column vector finite domainvariables (x1 , x2 , . . . , xk )T xi Di , ` u integers.assume l u finite always set smallest largestvalue cx take. Strictly speaking interpreted knapsack, integer valuesinvolved (including finite domains) nonnegative algorithmsproposed section easily adapted lift restriction nonnegative coefficients domain values, expense larger graph case algorithmSection 5.1. dealing general linear constraints.filtering algorithms regular constraint knapsack constraint (whendomain consistency enforced) based computation paths layeredacyclic directed graph (Pesant, 2004; Trick, 2003). graph property pathsfirst layer last one-to-one correspondence solutions constraint. exact counting algorithm former constraint derived Zanarini185fiPesant, Quimper, & ZanariniPesant (2009) next section describe exact counting algorithm knapsackconstraints similar spirit, Section 5.2 present approximate counting algorithm attuned bounds consistency. 65.1 Domain Consistent Knapsacksstart reduced graph described Trick (2003), layered directedgraph G(V, A) special vertex v0,0 vertex vi,b V 1 k 0 b uwheneverXj [1, i], dj Djcj dj = bj=1j (i, n], dj Dj ` bkXcj dj u b,j=i+1arc (vi,b , vi+1,b0 ) wheneverDi+1 ci+1 = b0 b.define following two recursions represent number incoming outgoingpaths node.every vertex vi,b V , let #ip(i, b) denote number paths vertex v0,0vi,b :#ip(0, 0) = 1#ip(i + 1, b0 ) =X#ip(i, b),0i<n(vi,b ,vi+1,b0 )ALet #op(i, b) denote number paths vertex vi,b vertex vk,b0 ` b0 u.#op(n, b) = 1#op(i, b) =X#op(i + 1, b0 ),0i<k(vi,b ,vi+1,b0 )Atotal number paths (i.e. solution count) given#knapsack(x, c, `, u) = #op(0, 0)time linear size graph even though may exponentially manythem. solution density variable-value pair (xi , d) givenP(vi1,b ,vi,b+ci )A #ip(i 1, b) #op(i, b + ci d).(xi , d, knapsack) =#op(0, 0)6. originally introduced Pesant Quimper (2008).186fiCounting-Based Searchb86;1761;31;13;16;12;23;25;13;25;15431;101;42;22;43;12101;31;221;91;201234Figure 4: Reduced graph knapsack constraint 5 3x1 + x2 + 2x3 + x4 8 D1 ={0, 1, 2}, D2 = {0, 1, 3}, D3 = {0, 1, 2}, D4 = {1, 2}. Vertex labels representnumber incoming outgoing paths.value0123x19/2210/223/22variablex2x38/22 9/228/22 7/226/226/22x411/2211/22Table 1: Solution densities example Fig. 4.Figure 4, left right labels inside vertex give number incomingoutgoing paths vertex, respectively. Table 1 reports solution densities everyvariable-value pair.time required compute recursions #ip() #op() related numberarcs, O(ku max1ik {|Di |}). solution density computes summationsubset arcs arc graph involved one summation,overall time complexity computing every solution density O(ku max1ik {|Di |})well.5.2 Bounds Consistent KnapsacksKnapsack constraints, indeed arithmetic constraints, traditionally handledenforcing bounds consistency, much cheaper form inference. situations,187fiPesant, Quimper, & Zanarinimay afford enforce domain consistency order get solution countinginformation need guide search heuristic. still retrieve information,perhaps accurately, weaker bounds consistency?Consider variable x domain = [a, b]. value equiprobable.associate x discrete random variable X follows discrete uniform distributionprobability mass function f (v), mean = E[X], variance 2 = V ar[X].f (v) ==2 =1ba+1v b0otherwisea+b2(b + 1)2 112(7)(8)(9)find distribution variable subject knapsack constraint, one needsfind distribution linear combination uniformly distributed random variables.Lyapunovs central limit theorem allows us approximate distribution linearcombination.Theorem 1 (Lyapunovs central limit theorem). Consider independent random variables X1 , . . . , Xn . Let mean Xi , i2 variance, ri3 = E[|Xi |3 ]third central moment.P1( n r3 ) 3lim Pni=1 1 = 0,2 2n (i=1 )PnSP=i=1 Xi follows normal distribution mean =Pn random variablen2.2 =variancei=1i=1probability mass function normal distribution mean variance 2Gaussian function:(x)2(x) =e 222(10)Note Lyapunovs central limit theorem assume variables takenidentical distributions. necessary since variables different domainsdifferent distributions.Lemma 1 defines upper bound third central moment expression kXk positive coefficient X uniformly distributed random variable.Lemma 1. Let discrete random variable equal kX k positivecoefficient X discrete random variable uniformly distributed interval [a, b].third central moment r3 = E[|Y E[Y ]|3 ] greater k 3 (b a)3 .Proof. case = b trivial. prove b > 0. proof involves simplealgebraic manipulations definition expectation.188fiCounting-Based Searchr3==kbX|i E[Y ]|3 f (i)(11)|kj kE[X]|3 f (j)(12)i=kabXj=afi3b fiXfifi+b1fijfi= ksince k > 0fifi2ba+1j=aa+bb233Xk3a+bX + b=j +jba+122a+b3j=a=k3ba+1j=baba22XXj3 +j3j=0(13)(14)2(15)j=0ba22k 3 Xj 3 since b > 0baj=0189(16)fiPesant, Quimper, & ZanariniLet =ba2 .r3k3 X 3jj=0k3 111432(m + 1) (m + 1) + (m + 1)4244332k++42443k44+m +msince 1249 3 3k4confirms r39 332 k (b(17)(18)(19)(20)(21)a)3 k 3 (b a)3 .Lemma 2 defines distribution linear combination uniformly distributed random variables.PLemma 2. Let = ni=1 ci Xi random variable Xi discrete random variableuniformly chosen interval [ai , bi ] ci non-negative coefficient.P n itendsinfinity, distribution tends normal distribution mean ni=1 ci ai +b2Pn 2 (bi ai +1)2 1variance i=1 ci.12Proof. Let Yi = ci Xi random variable. want characterize distributionPnbi aii=1 Yi . Let mi =2 . variance uniform distribution interval [ai , bi ]2(m + 1 )2+1) 11i2 = (bi ai12= 3 2 12. V ar[Yi ] = c2i V ar[Xi ] = c2i i2 . Let ri3third central moment Yi . Lemma 1, ri3 c3i (bi ai )3 . Let L termmentioned condition Lyapunovs central limit theorem:PnL =lim3i=1 rinPn12 2i=1 ci31(22)2Note numerator denominator fraction non-negative.implies L non-negative. prove L 0 n tends infinity.190fiCounting-Based SearchApproximation Combination Uniformly Distributed Random Variables0.0450.040.035density0.030.0250.020.0150.010.00500510152025x3035404550Figure 5: histogram actual distribution expression 3x+4y +2z x, y, z[0, 5]. curve approximation given Gaussian curve mean= 22.5 variance 2 = 84.583.PnL3 3i=1 8ci milimn Pn2i=1 cilimn813(mi + 12 )23Pn13Pn123i=1 ci mi2i=1 ci mi1311212(23)3(24)2vu Pn 3 3 2ui=1 ci mi6lim 2 3Pn 2 2 3ni=1 ci miPn Pn36j=1 (ci cj mi mj )i=1lim 2 3 Pn Pn Pn2ni=1j=1k=1 (ci cj ck mi mj mk )(25)(26)Note last inequality, terms (ci cj mi mj )3 (ci cj ck mi mj mk )2order. However, n times terms denominator numerator.Therefore, n tends infinity, fraction tends zero proves L = 0n tends zero.PnLyapunovs central limit theorem, n tendsinfinity,expression=i=1 YiPnPnai +bitends normal distribution mean E[Y ] = i=1 ci E[Xi ] = i=1 ci 2 variancePP+1)2 1V ar[Y ] = ni=1 c2i V ar[Xi ] = ni=1 c2i (bi ai12.PConsider knapsack constraint ` ni=1 ci xi u. Let xn+1 variable domainPPnDn+1 = [`, u]. obtain xj = c1j (xn+1 j1i=j+1 ci xi ). coefficientsi=1 ci xiexpression might negative. made positive setting c0i = ciDi0 = [ max(Di ), min(Di )]. n grows infinity, distribution xj tendsnormal distribution stated Lemma 2. practice, normal distribution191fiPesant, Quimper, & Zanarinigood estimation even small values n. Figure 5.2 shows actual distributionexpression 3x + 4y + 2z x, y, z [0, 5] approximation normal distribution.Given variable xi subject knapsack constraint, Algorithm 2 returns assignmentxi = ki highest solution density. loop computes average mean jvariance j2 uniform distribution associated variablePn xj . Lines 4 5compute mean variance distribution xn+1 j=1 cj xj Lines 6PPn7 compute mean variance xi = c1i (xn+1 i1j=1 cj xjj=i+1 cj xj ).Since normal distribution symmetric unimodal, likely value kidomain Di one closest mean . algorithm finds returns valuewell density di . density di computed using normal distribution. Sincevariable xi must assigned value domain, algorithm normalizes Line 9distribution values interval [min(Di ), max(Di )].123456789j [1, n]min(Dj )+max(Dj )j;2(max(D )min(D )+1)2 1jj;j212Pnl+u2 j=1 cj j ;2 1PV (ul+1)+ nj=1 c2j j2 ;12+c;civV c2i i2;c2iki arg minkDi |k m|;(ki m)2(km)2Pmax(Di )2vdi e 2v / k=min(De;i)return hxi = ki , diAlgorithm 2: Pxi = ki highest density well density di knapsackconstraint ` ni=1 ci xi u.10Lines 1 5 take O(n) time execute. Line 8 depends data structureused solver encode domain. assume line takes O(log |Di |) timeexecute. summation Line 9 computed constant time approximatingsummation m,v (max(Di ) + 12 ) m,v (min(Di ) + 12 ) m,v normalcumulative distribution function average variance v. constant 12 addedcontinuity correction. lines constant running time. total complexityAlgorithm 2 therefore O(n + log |Di |). Note Line 1 Line 5 dependvalue i. computation therefore cached subsequent callsfunction knapsack constraint. Using technique, finding thePvariable xi{x1 , . . . , xn } assignment xi = ki maximum density takes O( ni=1 log |Di |)time.source alteration distribution values interval absentactual domain. Bounds consistency approximates domain variablesmallest covering interval. order reduce error introduced approximation,one compute actual mean actual variance domain Di Lines 2 3192fiCounting-Based SearchinsteadP using mean variance covering interval, revised overall costO( ni=1 |Di |).6. Generic Constraint-Centered Counting-based Heuristicsprevious sections provided algorithms retrieve solution counting informationmany frequently used constraints. information must exploitedguide search. solving process alternates propagating constraints filterdomains branching fixing variable value domain. crucial choicevariable value made search heuristic. considered many search heuristicsbased counting information, describe briefly next paragraph.experiment extensively one successful ones Section 7, presentdetail. following, denote C(xi ) set constraints whose scopecontains variable xi . heuristics proposed assume lexicographical orderingtie breaking. Counting information gathered search tree node propagationfixed point reached: recomputed constraints change occurreddomain variable within scope, otherwise cached information reused.cached counting information stored trailing data structures (also known reversibledata structures) retrieved upon backtracking. heuristics consideredfall four broad categories:Combined choice variable value select directly variable-value pairwithout explicit differentiation variable value ordering, based aggregation,simple functions, counting information coming different constraints.heuristics iterate variable-value pair, aggregating solution densitiesrelevant constraints selecting pair exhibiting maximum aggregated score.type aggregation used e.g. maximum, minimum, sum, average. instance:maxSD: maxcC(xi ) ((xi , d, c)) selects maximum solution densities.maxRelSD: maxcC(xi ) ((xi , d, c) (1/|Di |)) selects maximum solutiondensities subtracting average solution density given variable (i.e. 1/|Di |).smoothes inherent solution densities differences due domain cardinalities(as also following aggregation function).,d,c)maxRelRatio: maxcC(xi ) ( (x(1/|Di |) ) selects maximum ratiosolution density average solution density given variable.PaAvgSD:(xi ,d,c)|C(xi )|cC(xi )PwSCAvg:(#c(xi ,d,c))cC(x ) #ccC(xi )Pcomputes arithmetic average solution densities.computes average solution densities weightedconstraints solution count. weights tend favor branchings variablevalue pairs keep high percentage solutions constraints high solutioncount.193fiPesant, Quimper, & ZanariniChoice constraint first focus first specific constraint (e.g. basedsolution count) select variable-value pair (as before) among variablespreselected constraints scope. instance, minSCMaxSD first selects constraintlowest number solutions restricts choice variable involvedconstraint, choosing variable-value pair highest solution density.rationale behind heuristic constraint fewest solutions probablyamong hardest satisfy.Restriction variables preselect subset variables minimum domain size choose among one best variable-value pair accordingcounting information.Choice value using generic heuristic variable selectionsolution densities value selection.Heuristic maxSD heuristic maxSD (Algorithm 3) simply iterates variablevalue pairs chooses one highest density; assuming (xi , d, c)precomputed, complexity algorithm O(qm) q numberconstraints sum cardinalities variables domains. Interestingly,heuristic likely selects variable small domain, keeping fail-firstprinciple, since values average higher density compared variablemany values (consider average density value (xi , d, c) = |D1i | ). Noteconstraint considered individually.12345678max = 0;constraint c(x1 , . . . , xk )unbound variable xi {x1 , . . . , xk }value Di(xi , d, c) > max(x? , d? ) = (xi , d);max = (xi , d, c);return branching decision x? = d? ;Algorithm 3: Maximum Solution Density search heuristic (maxSD)7. Experimental Analysisperformed thorough experimental analysis order evaluate performanceproposed heuristics eight different problems.7 problems expose sub-structuresencapsulated global constraints counting algorithms known.Counting-based heuristics use random problems class problemsexpose structure; nonetheless real-life problems usually present structure thereforeperformance heuristics proposed may positive impact questprovide generic efficient heuristics structured problems. problemsexperimented different structures different constraints possibly different7. instances used available www.crt.umontreal.ca/quosseca/fichiers/20-JAIRbenchs.tar.gz.194fiCounting-Based Searcharities interconnected different ways; thus, considered good representativesvariety problems may arise real life.7.1 Quasigroup Completion Problem Holes (QWH)Also referred Latin Square problem, QWH defined n n grid whosesquares contain integer 1 n integer appears exactly perrow column (problem 3 CSPLib maintained Gent, Walsh, Hnich, & Miguel,2009). common model uses matrix integer variables alldifferentconstraint row column. constraint defined n variablestype; variable involved two constraints domain(disregarding clues). homogeneous problem. tested 40 hardinstances used Zanarini Pesant (2009) n = 30 42% holes (correspondingphase transition), generated following Gomes Shmoys (2002).7.2 Magic Square Completion Problemmagic square completion problem (problem 19 CSPLib) defined n n gridasks fill square numbers 1 n2 row, columnmain diagonal sums value. order make harder, probleminstances partially prefilled (half instances 10% variablesset half, 50% variables set). 40 instances (9 9) takenwork Pesant Quimper (2008). problem modeled matrixinteger variables, single alldifferent constraint spanning variablesknapsack constraint row, column main diagonal. problem involvesdifferent constraints although majority equality knapsack arity.7.3 NonogramsNonogram (problem 12 CSPLib) built rectangular nm grid requires fillingsquares unique feasible way according clues given rowcolumn. reward, one gets pretty monochromatic picture. individual clueindicates many sequences consecutive filled-in squares row (column),respective size order appearance. example, 2 1 5 indicatestwo consecutive filled-in squares, isolated one, finally five consecutive ones.sequence separated others least one blank square know littleactual position row (column). clues modeled regularconstraints. homogeneous problem, constraints identical type definedn variables, (binary) variable involved two constraints.puzzles typically require amount search, despite fact domain consistencymaintained clue. experimented 180 instances8 sizes ranging16 16 32 32.8. Instances taken http://www.blindchicken.com/ali/games/puzzles.html195fiPesant, Quimper, & Zanarini7.4 Multi Dimensional Knapsack ProblemMulti dimensional knapsack problem originally proposed optimization problem community. followed approach Refalo (2004) transformingoptimization problem feasibility problem fixing objective function optimal value, thereby introducing 0-1 equality knapsack constraint. constraintsupper bounded knapsack constraints variables. tested three different set instances total 25 instances: first set corresponds six instancesused Refalo, second set third set come OR-Library (Weish[1-13]Shi, 1979; PB[1,2,4] HP[1,2] Freville & Plateau, 1990). first instance setn, number variables, ranging 6 50 m, numberconstraints, 5 10; second third instance set n varies 27 602 5. problem involves one kind constraint and, differentlyprevious problem classes, constraints posted set variables.7.5 Market Split Problemmarket split problem originally introduced Cornuejols Dawande (1999)challenge LP-based branch-and-bound approaches. exists feasibilityoptimization version. feasibility problem consists 0-1 equality knapsackconstraints defined set 10(m1) variables. Even small instances (4 6)surprisingly hard solve standard means. used 10 instances tested PesantQuimper (2008) generated Wassermann (2007). Market Split Problemshares characteristics Multi Dimensional Knapsack problem: constraintstype posted set variables.7.6 Rostering Problemrostering problem inspired rostering context. objective schedulen employees span n time periods. time period, n 1 tasks needaccomplished one employee n break. tasks fully ordered 1n 1; employee schedule respect following rules: two consecutivetime periods assigned either two consecutive tasks (in matter orderi.e. (t, + 1) (t + 1, t)) task (i.e. (t, t)); employee breakmatter task; break employee cannot perform task precedestask prior break (i.e. (t, break, t1) allowed). problem modeled oneregular constraint per row one alldifferent constraint per column. generated 2sets 30 instances n = 10 5% preset assignments respectively 0%2.5% values removed.7.7 Cost-Constrained Rostering Problemcost-constrained rostering problem borrowed Pesant Quimper (2008)10 instances well. inspired rostering problem employees(m = 4) accomplish set tasks n-day schedule (n = 25). employeeperform task another employee day (alldifferent constraintday). Moreover, hourly cost making someone work, varies196fiCounting-Based Searchacross employees days. employee, total cost must equal randomlygenerated value (equality knapsack constraint employee). Finally, instance10 forbidden shifts i.e. days employee cannot performgiven task. following, refer problem also KPRostering. problempresents constraints different types largely different arities.7.8 Traveling Tournament Problem Predefined Venues (TTPPV)TTPPV introduced Melo, Urrutia, Ribeiro (2009) consists findingoptimal single round robin schedule sport event. Given set n teams,team play every team. game, team supposed playeither home away, however team play three consecutive timeshome away. particularity problem resides venue gamepredefined, i.e. team plays b already known whether game goingheld home bs home. TTPPV instance said balancednumber home games number away games differ one team;otherwise referred non-balanced random. problem modeled onealldifferent one regular constraint per row one alldifferent constraint percolumn. TTPPV originally introduced optimization problem sumtraveling distance team minimized, however Melo et al. (2009)show particularly difficult find single feasible solution employing traditionalinteger linear programming methods. Balanced instances size 18 20 (the numberteams denotes instance size) taking roughly 20 60 seconds find firstfeasible solution Integer Linear Programming; non-balanced instances could take5 minutes (or even time 2 hours computation). Furthermore six non-balancedinstances infeasible ILP approach proposed Melo et al. unable proveit. Hence, feasibility version problem already represents challenge.every problem (unless specified otherwise): domain consistency maintainedsearch9 , counting algorithm alldifferent constraint UB-FC (upper boundsforward checking consistency level enforced), search tree binary (i.e.xi = j xi 6= j), traversed depth-first. tests performed AMD Opteron2.2GHz 1GB Ilog Solver 6.6; heuristics involve sort randomization(either heuristic counting algorithms employed) run 10 timesaverage results taken account. set timeout 20 minutesproblems heuristics. present results plotting percentage solvedinstances time backtracks.7.9 Comparing Counting-Based Search Heuristicsfirst compare several proposed search heuristics based counting respectwell guide search, measured number backtracks required findsolution. important issue overall runtime addressed following sections.9. Even knapsack constraints, comparative experimental results benchmark instances,originally reported Pesant Quimper (2008), indicated maxSD performed better domainconsistency associated counting algorithm.197fiPesant, Quimper, & ZanariniFigure 6: Percentage solved instances respect number backtrackseight benchmark problems. search heuristics compared basedsolution counting.198fiCounting-Based SearchFigure 6 plots number solved instances backtracks eight benchmark problems. Nonogram, Multi-Knapsack, Market Split problems, maxSD,maxRelSD, maxRelRatio correspond heuristics domains binary.Restricting use solution densities choice value variable selected popular domain size dynamic degree heuristic (domDeg;maxSD) generallyachieves poor performance compared others. One disappointment camesurprise selecting first constraint fewest solutions left (minSCMaxSD)often behaves poorly well. Multi-Knapsack Problem aAvgSD, takesarithmetic average solution densities, performs one order magnitude betterothers. believe might explained fact constraintsshare variables (in Latin Square Nonogram problems constraints overlapone variable): therefore branching considering constraint informationpays off. maxSD maxRelSD search heuristics stand robustbenchmarks. quite similar performs significantly betterone problem domain. slightly simpler, restrictformer remaining experiments.7.10 Comparing Generic Search Heuristicsexperimental results previous section suggest relatively simple maxSDheuristic guides search least well others. comparefollowing ones (see Section 2 reference) good representatives stateart generic search heuristics:dom - selects among variables smallest remaining domain uniformlyrandom chooses value uniformly random;domWDeg - selects variable according dom/wdeg heuristicfirst value lexicographic order;IBS - Impact-based Search full initialization impacts; chooses subset5 variables best approximated impact breaks ties basednode impacts ties broken randomly; (ILOG, 2005)Figure 7 8 plot number solved instances backtracks timeeight benchmark problems. moment ignore curves heuristicsrestarts.maxSD heuristic significantly outperforms heuristics Latin Square,Magic Square, Multi Dimensional Knapsack, Cost-Constrained Rostering (KPRosteringfigure), TTPPV problems (5 8 problems), terms numberbacktracks computation time. Nonogram Problem slightly worsedomWDeg eventually outperformed IBS. sharp improvement latteraround 1000 backtracks suggests singleton consistency powerful problemtime consuming since domains binary. Indeed IBSs full initializationimpacts root node achieves singleton consistency preprocessing step.behavior even pronounced Rostering Problem (see IBS curves).problem maxSDs performance easily compared domWDeg, dominates it.199fiPesant, Quimper, & ZanariniFigure 7: Percentage solved instances respect number backtrackstime (in seconds) first four benchmark problems. search heuristicscompared maxSD, dom, IBS, domWDeg, without restarts.200fiCounting-Based SearchFigure 8: Percentage solved instances respect number backtrackstime (in seconds) last four benchmark problems. search heuristicscompared maxSD, dom, IBS, domWDeg, without restarts.201fiPesant, Quimper, & ZanariniMarket Split Problem differences performance striking: maxSDslightly better terms backtracks enough outperform domWDegterms runtime.Magic Square plot time, notable bend 50% markcurves explained fact half instances10% cells prefilled present bigger challenge. Interestingly, simplerdom heuristics performs better IBS domWDeg, latter unable solvehalf instances allotted time. contrast Nonogram Problem,full impact initialization heavy procedure due high number variable-valuepairs probe ( n4 instances 94 = 6561). also worth notingCost-Constrained Rostering Problem, maxSD solves seven ten instancesbacktrack-free heuristic solving every instance. Similarly TTPPVProblem, almost 90% instances solved backtrack-free heuristic. Moreoversix instances happen infeasible maxSD exhibits short proof trees five them,every heuristic timing them.7.11 Adding Randomized Restartsremarked combinatorial search strictly positive probabilityreach subtree requires exponentially time subtrees encounteredfar (so called heavy-tail behavior). Nonetheless, heavy tails largely avoidedadding randomized restarts top search procedure (Gomes, Selman, & Kautz,1998). technique orthogonal search heuristic employed systematicallyrestarts search every time limit (typically bound number backtracks)reached; obviously, order effective, randomized restarts must employed alongheuristic presents sort randomization learningrestart different parts search tree explored. tested heuristicsassess performance randomized restarts. maxSD IBS heuristicsrandomized: particularly, one variable-value pair chosen random equalprobability best two provided heuristic. Note that, pointedRefalo (2004), impact information carried different runs improve qualityimpact approximation. domWDeg, learned weights kept restarts.implemented slow geometric restart policy (Walsh, 1999) (that 1, r, r2 , . . . r = 2)scale parameter optimized experimentally separately problem typesearch heuristic.turn Figure 7 8 time also consider curvesheuristics restarts. Restarts generally help less informed heuristic dom,sometimes spectacularly Rostering Problem, always indicatedresults Market Split Problem. heuristics usefulness mixed:makes little difference maxSD except Market Split degrades performanceRostering improves performance significantly, solving every instanceeasily; IBS helps difficult instances half problemsthree others degrades performance; domWDeg generally positive neverspectacular. Note heavy-tail behavior runtime distribution conjectured dependproblem structure search heuristic employed (Hulubei & OSullivan,202fiCounting-Based Search2006). Market Split Problem stands one randomized restarts hurt everysearch heuristic considered.7.12 Using Limited Discrepancy SearchAnother way avoid heavy tails change order search tree traversed,undoing decisions made top search tree earlier traversal. popularway applying limited discrepancy search (LDS) visits branchesincreasing order number discrepancies, correspond branching decisionsgoing search heuristic (Harvey & Ginsberg, 1995). restarts,combined search heuristic may cause dramatic improvements casesless natural traversal comes price. Figure 9 illustrates impact LDStwo benchmark problems, using maxSD search heuristic. Either usualdepth-first search traversal used (maxSD curve) limited discrepancy search, groupingbranches exactly number discrepancies (LDS 1), skips 2 (LDS2), skips 4 (LDS 4) discrepancies. rostering problem LDS undoes badearly decisions made heuristic allows us solve every instance quickly.However Magic Square problem impact LDS number backtrackslow actually significantly slows resolution LDS must revisit internalnodes, thus repeating propagation steps: smaller skip, larger computationalpenalty.behavior could observed search heuristics problems. LDS necessarily add robustness search.7.13 Analyzing Variable Value Selection SeparatelyOne may wonder whether success counting-based search heuristics mostly dependsinformed value selection, accompanying variable selection accessory. orderinvestigate this, introduce hybrid heuristics:maxSD; random - selects variable maxSD selects value domainuniformly random;IBS; maxSD - selects variable IBS selects value domainaccording solution densities;domWDeg; maxSD - selects variable domWDeg selects valuedomain according solution densities;Figure 10 11 plot number solved instances backtracks timeeight benchmark problems. Comparing maxSD maxSD; random indicatestime value selection according solution densities crucial, Rostering Problemexception. Interestingly value selection solution density improves overallperformance IBS; domWDeg improves Latin Square Magic Squareproblems rest, often decreasing performance. However improvementsreally tip balance favor heuristics maxSD, thus indicatingvariable selection according solution densities also important success.203fiPesant, Quimper, & ZanariniFigure 9: Percentage solved instances respect number backtrackstime (in seconds) two benchmark problems. maxSD search heuristicused every curve search tree traversal order different.204fiCounting-Based SearchFigure 10: Percentage solved instances respect number backtrackstime (in seconds) first four benchmark problems. search heuristicscompared use solution densities either variable value selection.205fiPesant, Quimper, & ZanariniFigure 11: Percentage solved instances respect number backtrackstime (in seconds) last four benchmark problems. search heuristicscompared use solution densities either variable value selection.206fiCounting-Based Search8. Conclusionpaper described evaluated counting-based search solve constraint satisfactionproblems. presented algorithms necessary extract counting informationseveral main families constraints cp. proposed variety heuristics basedcounting information evaluated them. compared one outstandingrepresentative, maxSD, state art eight different problems literatureobtained encouraging results. next logical steps research includedesigning counting algorithms common constraints strengtheningempirical evaluation considering new problems comparing applicationspecific heuristics. next two paragraphs describe less obvious steps.Users often need introduce auxiliary variables different views modelslinked together channeling constraints. important provide countinginformation available level branching variables least leveldirect comparison solution densities meaningful. example case TTPPVearlier model, two sets variables received solution densities differentconstraints, perform nearly well. Channeling constraints express one-tomany relation (such one present TTPPV) dealt considering valuemultiplicity counting algorithms (Pesant & Zanarini, 2011). complex channelingconstraints represent however limitation current framework.Combinatorial optimization problems discussed paperimportant operations research. Heuristics strong emphasis feasibility (suchcounting-based heuristics) might well suited problems strong optimizationcomponent, yet may useful dealing optimization problems involvehard combinatorics. Ideally, counting algorithms blind cost reasoning.One possibility started investigating counts number solutionsinvolve particular variable-value pair also returns average cost solutionsfeaturing particular variable-value pair. Another shown promise costlinear decomposable decision variables (Pesant & Zanarini, 2011).conclude, believe counting-based search brings us closer robust automatedsearch cp also offers efficient building blocks application-specific heuristics.AcknowledgmentsFinancial support research provided part Natural Sciences Engineering Research Council Canada Fonds quebecois de la recherche sur la natureet les technologies. wish thank Tyrel Russell participated implementationexperimentation work. also thank anonymous referees constructivecomments allowed us improve paper.ReferencesAlon, N., & Friedland, S. (2008). Maximum Number Perfect Matchings GraphsGiven Degree Sequence. Electronic Journal Combinatorics, 15 (1), N13.207fiPesant, Quimper, & ZanariniBalafoutis, T., & Stergiou, K. (2008a). Experimental evaluation modern variable selectionstrategies Constraint Satisfaction Problems. Proceedings Fifteenth Knowledge Representation Automated Reasoning Workshop Experimental EvaluationAlgorithms Solving Problems Combinatorial Explosion, RCRA-08.Balafoutis, T., & Stergiou, K. (2008b). Conflict-driven variable ordering heuristics.Proceedings Thirteenth Annual ERCIM International Workshop ConstraintSolving Constraint Logic Programming, CSCLP-08.Bessiere, C., & Regin, J.-C. (1996). MAC Combined Heuristics: Two Reasons Forsake FC (and CBJ?) Hard Problems. Proceedings Second InternationalConference Principles Practice Constraint Programming, CP-96, Vol. 1118LNCS, pp. 6175. Springer Berlin / Heidelberg.Boussemart, F., Hemery, F., Lecoutre, C., & Sais, L. (2004). Boosting Systematic SearchWeighting Constraints. Proceedings Sixteenth Eureopean ConferenceArtificial Intelligence, ECAI-04, pp. 146150. IOS Press.Bras, R. L., Zanarini, A., & Pesant, G. (2009). Efficient Generic Search Heuristics withinEMBP framework. Proceedings Fifteenth International ConferencePrinciples Practice Constraint Programming, CP-04, Vol. 5732 LNCS, pp.539553. Springer.Bregman, L. M. (1973). Properties Nonnegative Matrices Permanents.Soviet Mathematics Doklady, 14 (4), 945949.Brelaz, D. (1979). New Methods Color Vertices Graph. CommunicationsACM, 22 (4), 251256.Cornuejols, G., & Dawande, M. (1999). Class Hard Small 0-1 Programs. INFORMSJournal Computing, 11, 205210.Freville, A., & Plateau, G. (1990). Branch Bound Method MulticonstraintZero One Knapsack Problem.. Investigation Operativa, 1, 251270.Friedland, S. (2008). Upper Bound Number Perfect Matchings Graphs.http://arxiv.org/abs/0803.0864.Gent, I. P., Walsh, T., Hnich, B., & Miguel, I. (2009). Problem Library Constraints.http://www.csplib.org. last consulted 2009-08.Gomes, C., Selman, B., & Kautz, H. (1998). Boosting Combinatorial SearchRandomization. Proceedings fifteenth national/tenth conference Artificialintelligence/Innovative applications artificial intelligence, AAAI-98/IAAI-98, pp.431437. AAAI Press.Gomes, C., & Shmoys, D. (2002). Completing Quasigroups Latin Squares: StructuredGraph Coloring Problem.. Proceedings Computational Symposium GraphColoring Generalizations, COLOR-02, pp. 2239.Grimes, D., & Wallace, R. J. (2006). Learning Identify Global Bottlenecks ConstraintSatisfaction Search. Learning Search: Papers AAAI-06 Workshop, Vol.Tech. Rep. WS-06-11, pp. 2431.208fiCounting-Based SearchGrimes, D., & Wallace, R. J. (2007). Sampling Strategies Variable Selection WeightedDegree Heuristics. Proceedings Thirteenth International Conference Principles Practice Constraint Programming, CP-07, Vol. 4741 LNCS, pp. 831838. Springer.Haralick, R. M., & Elliott, G. L. (1980). Increasing Tree Seach Efficiency ConstraintSatisfaction Problems. Artificial Intelligence, 14, 263313.Harvey, W. D., & Ginsberg, M. L. (1995). Limited Discrepancy Search. ProceedingsFourteenth International Joint Conference Artificial Intelligence, IJCAI-95,pp. 607615. Morgan Kaufmann.Hsu, E. I., Kitching, M., Bacchus, F., & McIlraith, S. A. (2007). Using Expectation Maximization Find Likely Assignments Solving CSPs. Proceedings TwentySecond AAAI Conference Artificial Intelligence, pp. 224230. AAAI Press.Hulubei, T., & OSullivan, B. (2006). Impact Search Heuristics Heavy-TailedBehaviour. Constraints, 11 (2-3), 159178.ILOG (2005). ILOG Solver 6.1 Users Manual. page 378.Jurkat, W., & Ryser, H. J. (1966). Matrix Factorizations Determinants Permanents.Journal Algebra, 3, 127.Kask, K., Dechter, R., & Gogate, W. (2004). Counting-Based Look-Ahead SchemesConstraint Satisfaction. Springer-Verlag (Ed.), Proceedings Tenth International Conference Principles Practice Constraint Programming, CP-04, Vol.LNCS 3258, pp. 317331.Liang, H., & Bai, F. (2004). Upper Bound Permanent (0,1)-Matrices. LinearAlgebra Applications, 377, 291295.Melo, R., Urrutia, S., & Ribeiro, C. (2009). traveling tournament problem predefined venues. Journal Scheduling, 12 (6), 607622.Minc, H. (1963). Upper Bounds Permanents (0, 1)-matrices. Bulletin AmericanMathematical Society, 69, 789791.Pesant, G. (2004). Regular Language Membership Constraint Finite Sequences Variables. Proceedings Tenth International Conference Principles PracticeConstraint Programming, CP-04, Vol. 3258 LNCS, pp. 482495. Springer.Pesant, G. (2005). Counting solutions csps: structural approach. ProceedingsNineteenth International Joint Conference Artificial Intelligence, IJCAI-05, pp.260265.Pesant, G., & Quimper, C.-G. (2008). Counting solutions knapsack constraints. Proceedings Fifth International Conference Integration AI TechniquesConstraint Programming Combinatorial Optimization Problems, CPAIOR-08,pp. 203217.Pesant, G., & Zanarini, A. (2011). Recovering indirect solution densities counting-basedbranching heuristics. Achterberg, T., & Beck, J. C. (Eds.), CPAIOR, Vol. 6697Lecture Notes Computer Science, pp. 170175. Springer.209fiPesant, Quimper, & ZanariniQuimper, C., Lopez-Ortiz, A., van Beek, P., & Golynski, A. (2004). Improved algorithmsglobal cardinality constraint. Proceedings Tenth International ConferencePrinciples Practice Constraint Programming, CP-04, Vol. LNCS 3258, pp.542556. Springer.Refalo, P. (2004). Impact-Based Search Strategies Constraint Programming. Proceedings Tenth International Conference Principles Practice ConstraintProgramming, CP-04, Vol. LNCS 3258, pp. 557571. Springer.Regin, J.-C. (1994). Filtering Algorithm Constraints Difference CSPs.Proceedings Twelfth National Conference Artificial Intelligence, AAAI-94,Vol. 1, pp. 362367. American Association Artificial Intelligence.Regin, J. (1999). Symmetric Alldiff Constraint. Proceedings Sixteenth International Joint Conference Artificial Intelligence, IJCAI-99, pp. 420425. MorganKaufmann Publishers Inc.Shi, W. (1979). Branch Bound Method Multiconstraint Zero One KnapsackProblem.. Journal Operational Research Society, 30, 369378.Smith, B. M., & Grant, S. A. (1998). Trying Harder Fail First. Thirteenth EuropeanConference Artificial Intelligence, ECAI-98, pp. 249253. John Wiley & Sons.Soules, G. W. (2005). Permanental Bounds Nonnegative Matrices via Decomposition.Linear Algebra Applications, 394, 7389.Szymanek, R., & OSullivan, B. (2006). Guiding Search using Constraint-Level Advice.Proceeding Seventeenth European Conference Artificial Intelligence, ECAI06, Vol. 141 Frontiers Artificial Intelligence Applications, pp. 158162. IOSPress.Trick, M. A. (2003). dynamic programming approach consistency propagationknapsack constraints. Annals Operations Research, 118, 7384.Valiant, L. (1979). Complexity Computing Permanent. Theoretical ComputerScience, 8 (2), 189201.Walsh, T. (1999). Search Small World. Proceedings Sixteenth InternationalJoint Conference Artificial Intelligence, IJCAI-99, pp. 11721177.Wassermann, A. (2007).feasibility version market split problem.http://did.mat.uni-bayreuth.de/ alfred/marketsplit.html. last consulted 2007-11.Zanarini, A., Milano, M., & Pesant, G. (2006). Improved algorithm soft global cardinality constraint. Proceedings Third International Conference IntegrationAI Techniques Constraint Programming Combinatorial OptimizationProblems, CPAIOR-06, Vol. LNCS 3990, pp. 288299. Springer.Zanarini, A., & Pesant, G. (2009). Solution Counting Algorithms Constraint-CenteredSearch Heuristics. Constraints, 14, 392413.Zanarini, A., & Pesant, G. (2010). robust counting-based search heuristicsalldifferent constraints. Lodi, A., Milano, M., & Toth, P. (Eds.), CPAIOR, Vol.6140 Lecture Notes Computer Science, pp. 354368. Springer.210fiJournal Artificial Intelligence Research 43 (2012) 389418Submitted 10/11; published 03/12Generalized Biwords Bitext CompressionTranslation SpottingFelipe Sanchez-MartnezRafael C. Carrascofsanchez@dlsi.ua.escarrasco@dlsi.ua.esDepartament de Llenguatges Sistemes InformaticsUniversitat dAlacant, E-03071, Alacant, SpainMiguel A. Martnez-PrietoJoaqun Adiegomigumar2@infor.uva.esjadiego@infor.uva.esDepartamento de InformaticaUniversidad de Valladolid, E-47011, Valladolid, SpainAbstractLarge bilingual parallel texts (also known bitexts) usually stored compressedform, previous work shown efficiently compressedfact two texts mutual translations exploited. example, bitextseen sequence biwords pairs parallel words high probability cooccurrence used intermediate representation compression process.However, simple biword approach described literature exploit one-toone word alignments cannot tackle reordering words. therefore introducegeneralization biwords describe multi-word expressions reorderings.also describe methods binary compression generalized biword sequences,compare performance different schemes applied extractionbiword sequence. addition, show generalization biwords allowsimplementation efficient algorithm look compressed bitext wordstext segments one texts retrieve counterpart translationstext application usually referred translation spotting minormodifications compression algorithm.1. Introductionincreasing availability large collections multilingual texts fostered development natural-language processing applications address multilingual taskscorpus-based machine translation (Arnold, Balkan, Meijer, Humphreys, & Sadler, 1994;Lopez, 2008; Koehn, 2010; Carl & Way, 2003), cross-language information retrieval (Grossman & Frieder, 2004, Ch. 4), automatic extraction bilingual lexicons (Tufis, Barbu,& Ion, 2004), translation spotting (Simard, 2003; Veronis & Langlais, 2000).applications, monolingual nature e.g., syntactic parsing (Carroll, 2003),word sense disambiguation (Ide & Veronis, 1998) also exploit multilingual textsprojecting linguistic knowledge available one language languages (Mihalcea& Simard, 2005).bilingual parallel corpus, bitext, textual collection contains pairs documents translations one another. documents pair naturec2012AI Access Foundation. rights reserved.fiSanchez-Martnez, Carrasco, Martnez-Prieto & Adiegosometimes called source text target text, respectively. However, wheneverinformation document created unknown irrelevant, documentssimply called left text right text. words Melamed (2001, p. 1), bitextsone richest sources linguistic knowledge translation textanother language viewed detailed annotation text means.Bitexts usually available compressed form order reduce storage requirements, improve access times (Ziviani, Moura, Navarro, & Baeza-Yates, 2000),increase efficiency transmissions. However, independent compression twotexts bitext clearly far efficient information contained textsredundant: theory, one texts might sufficient generate translated version reliable machine translation systems already available (Nevill-Manning & Bell,1992). improvement compression performance obtained taking advantagefact two texts bitext mutual translations may regarded indication quality word alignments (Och & Ney, 2003). indicator, boundsmutual information (Cover & Thomas, 1991) two texts bitext, requiremanually-annotated corpus evaluate automatic alignment.first article dealing compression bitexts published Nevill-ManningBell (1992). approach compressed one texts isolation,compressed general prediction partial matching (PPM; Cleary & Witten, 1984)encoder based model used automatic translation left text predictwords right text. model exploited two types relations exact wordmatches synonymy relationships provided thesaurus relative weightpredictions depended number letters word processed.approach obtained better compression ratios standard PPM coder operatingconcatenated texts.contrast, Conley Klein (2008) proposed text alignment is, pairingswords phrases one text other, basis multilingual text compression. algorithm extends ideas delta-encoding (Suel &Memon, 2003) case right text R translated, automatically aligned,version source text L: L compressed first, block R encodedreference parallel block L. method requires computation wordand phrase-level alignments, together lemmatized forms L R. translated text retrieved references, using bilingual glossary togetherlinguistic resources: lemmata dictionary words L, dictionary possiblemorphological variants word R, bilingual glossary. authors reportslight improvements compression right text R comparison classical compression algorithms bzip21 word-based Huffman (Moffat, 1989) (approximately1% 6%, respectively). However, authors take consideration sizeauxiliary files needed retrieval right text.contrast PPM, text-compression methods use words rather charactersinput tokens (Moffat, 1989; Moffat & Isal, 2005). Analogously, Martnez-Prieto, Adiego,Sanchez-Martnez, de la Fuente, Carrasco (2009), Adiego colleagues (2009,2010) propose use biwords pairs words, one different text, high1. http://www.bzip.org390fiGeneralized Biwords Bitext Compression Translation SpottingFigure 1: Processing pipeline biword-based bitext compression approach.probability co-occurrence input units compression bitexts. meansbiword-based intermediate representation bitext obtained exploitingalignments, encoding unaligned words pairs one component emptystring. Significant spatial savings achieved technique (Martnez-Prieto et al.,2009), although compression biword sequences requires larger dictionariestraditional text compression methods.biword-based compression approach works simple processing pipeline consistingtwo stages (see Figure 1). text alignment obtained without pre-existinglinguistic resources, first stage transforms bitext biword sequence.second stage compresses sequence. Decompression works reverse order:biword sequence representing bitext first generated compressed file,original texts restored sequence.variation PPM algorithm takes words rather characters inputtokens bytes rather bits minimal output units (Adiego & de la Fuente, 2006)directly applied order compress biword sequences. bitext thus compressedusing single probabilistic model texts rather independent models usedolder bitext-compression approaches (Nevill-Manning & Bell, 1992; Conley & Klein,2008). improvement general-purpose compressors obtained approachdepends language pair: instance, reduction output size almost 11%obtained SpanishPortuguese, 2.5% EnglishFrench (Martnez-Prietoet al., 2009).different biword-based scheme called 2lcab recently proposed (Adiego et al.,2009) creates two-level dictionary store biwords compresses biwordsequence End-Tagged Dense Code (ETDC; Brisaboa, Farina, Navarro, & Parama,2007). usage ETDC permits Boyer-Moore-type searching (Boyer & Moore,1977), random access compressed file. 2lcab used compression boosterstandard PPM coder, improvements compression obtained,longer possible directly search compressed files (Adiego et al., 2010).biword sequences obtained former biword-based compression methodscontain large fraction 10% 60%, depending language pairunpaired words, is, biwords one words pair empty word .unpaired words generated three different cases:391fiSanchez-Martnez, Carrasco, Martnez-Prieto & AdiegoFigure 2: Example SpanishEnglish pair sentences one-to-many word alignments.aligner unable connect word words parallel textbecause, example, infrequent idiomatic expressions free translationsfound.aligner generates one-to-many alignment word translatedmultiword expression. instance, Spanish word volver translatedEnglish go back, biword extractor select one links, buildpair words link, leave words unpaired.aligner generates crossing alignments result word reorderingtranslation. instance, Figure 2, either pair (verde, green) pair(casa, house) must ignored biword extractor, thus leaving two unpairedwords; otherwise, information provided sequence sufficientretrieve texts original order.last two sources unpaired words responsible different spatial savingsreported Martnez-Prieto et al. (2009) bitexts consisting closely-related languages(e.g., Spanish Portuguese) involving divergent language pairs (e.g., FrenchEnglish), word reorderings multiword translations frequent.paper, describe evaluate simple biword extraction approach, compare schemes used generate generalized biword sequences maintainpart structural information provided aligner. biword essentially becomesleft word connected variable number right words plus additional informationconcerning relative position right word regard preceding one.fraction unpaired words thus reduced, better compression ratios obtained.also show generalization biwords allows implementationefficient translation spotting (Simard, 2003; Veronis & Langlais, 2000) algorithmcompressed bitext; task consists identifying words (or text segments)text translation words query. Indeed, generalized biwordsequences contain information needed order retrieve connected passages.Generalized biwords also used ingredient bilingual language modelemployed statistical machine translation systems (Koehn, 2010). instance,Marino et al. (2006) use bilingual n-grams consider translation bilingual decoding process. Casacuberta Vidal (2004) also exploit bilingual n-grams applystochastic finite-state transducers task. cases, local reordering wordsaddressed considering multiword segments source target words fundamental translation units. alternative approaches (Niehues, Herrmann, Vogel, & Waibel,2011; Matusov, Zens, Vilar, Mauser, Popovic, Hasan, & Ney, 2006; Hasan, Ganitkevitch,392fiGeneralized Biwords Bitext Compression Translation SpottingNey, & Andres-Ferrer, 2008) integrate bilingual language models additional featuredecoding function drives statistical translation process. However, noneapproaches mentioned includes structural information provided aligners partbilingual language model.remainder paper organized follows. following section showsgeneralized biword sequence represent bitext. Section 3 describes two different methods applied compress biword sequence. Section 4 introduces resourcesused evaluate different generalizations biwords, whereas Section 5 discussescompression results obtained. Section 6 describes modifications onecompression techniques order allow compressed bitext searched presentsefficient search translation spotting algorithms. Finally, concluding remarkspresented Section 7.2. Extraction Biword Sequencesextracting sequence biwords representing bitext, alignmentswords left text L = l1 l2 lM words right text R = r1 r2 rN mustestablished word aligner. Word aligners usually work sentence aligneridentified pairs sentences bitext parallel, is, plausible mutualtranslation. Sentence alignment algorithms often based simple statistical modelscorrelation sentence lengths (Brown, Lai, & Mercer, 1991; Gale & Church,1993).Current word aligners use word-based statistical machine translation models (Brown,Cocke, Pietra, Pietra, Jelinek, Lafferty, Mercer, & Roossin, 1990; Brown, Pietra, Pietra,& Mercer, 1993) compute likely alignment words two parallelsentences (Koehn, 2010, Ch. 4). case, word alignments computed opensource Giza++ toolkit2 (Och & Ney, 2003) implements set methods, includingstandard word-based statistical machine translation models (Brown et al., 1993)hidden-Markov-model-based alignment model (Vogel, Ney, & Tillmann, 1996). Giza++produces alignments depicted Figure 2, source word (here, leftword) aligned many target words (here, right words), whereas target wordaligned with, most, one source word.result word alignment bigraph G = {L, R, A} edge {li , rj }word li L word rj R signifies mutual translations accordingtranslation model used aligner. complex structures processedsplitting bigraph connected components: connected component eitherunpaired (right left) word, left word aligned sequence (one more) rightwords. shown later, connected component including structural informationneeded place words original positions bitext termgeneralized biword.order build sequence B generalized biwords, biwords sorted primarilyaccording left component and, secondarily, head right component. precisely, left() right() denote left word sequence right2. http://code.google.com/p/giza-pp/393fiSanchez-Martnez, Carrasco, Martnez-Prieto & Adiegowords respectively biword , represents empty left right componentunpaired words, precedes if:left() 6= , left() 6= left() precedes left() L.Either left() = left() = , right() 6= , right() 6= , initial wordright() precedes, R, initial word right().left() = , left() 6= biword precedes precedes.Every generalized biword = (, , ) sequence B consists of:string L ,array strings R ,integer array containing one offset every string .Here, L denotes set different words L enhanced empty word , Rdenotes set subsequences R includes empty subsequence, represented(). array offsets stores structural information needed place wordoriginal position.offset non-negative integer specifies, every wordfirst one, number words R located word preceding one ,thus allowing generation stage decompression keep track gapssubsequence filled word posterior biword B. offsetfirst word w 6= () defined number words R located wfirst available gap, is, first word R belongs biwordprecede = (, , ).combination types offsets permits encoding translationsword reordering. Indeed, seen Figure 3, offset biword (casa,(house),(1)) signifies one-word gap house occupied word green offset 0 (verde,(green),(0)). offsets (vivimos,(we,live), (0,0)) indicate comes directly word house live comesimmediately we. pseudo-code procedure extracts sequencegeneralized biwords details implementation found Appendix A.Henceforth, shall call biwords shifts biwords least one non-nulloffset (biwords without shifts, otherwise). shall differentiate biwordssimple shifts, first offset non-null, biwords complex shifts,non-consecutive words R.Generalized biwords clearly expressive, bitexts therefore mappedonto shorter sequences. However, enhanced variety biwords implies compression algorithms must use larger dictionaries. global effect compressionratio must therefore explored. also worth measuring effect ignoring certain infrequent alignments order avoid biwords complex shifts. example,generalized biword sequence Figure 3 contains one biword complex shifts,(prefiero,(i,like),(0,1)) split smaller components, (,(i),394fiGeneralized Biwords Bitext Compression Translation Spotting(prefiero,(i,like),(0,1))(,(would),(0))(volver,(to,go,back),(0,0,0))(a,(to),(0))(la,(the),(0))(casa,(house),(1))(verde, (green),(0))(en,(in),(2))(que,(),())(vivimos,(we,live),(0,0))Figure 3: Generalized biword sequence word-aligned sentence shown Figure 2.(0)) (prefiero,(like),(0)), sequence includes biwords simpleshifts. simple shifts allowed, compression algorithm needs encode, most,one non-null offset per biword.experiments shall compare results obtained algorithms describednext section (Tre 2lcab) used combination four different methodsextract sequence biwords:1:N Complex: one-to-many word alignments generated Giza++ usedgenerate sequence generalized biwords.1:N Simple: biwords complex shifts generated one-to-many alignments provided Giza++ split biwords simple shifts plus unpairedwords; result sequence biwords simple shifts without shifts. Biwords complex shifts split ignoring least frequent alignmentsresulting biwords contain simple shifts.1:1 Non-monotonic: one-to-one word alignments obtained computing intersection alignments produced Giza++ left right textexchanged; result sequence biwords whose right component contains,most, one word (and biwords cannot, therefore, complex shifts).1:1 Monotonic: 1:1 non-monotonic sequence transformed sequencebiwords without shifts splitting biwords shifts unpaired words.last method, 1:1 Monotonic, use enhancement provided generalization biwords (i.e., structural information), therefore equivalent basicprocedures described earlier (Martnez-Prieto et al., 2009; Adiego et al., 2009, 2010).3. Compression Biword Sequencesclearly possible compress intermediate representation introduced previoussection via application wide range approaches. Here, describe evaluatetwo different encoding methods, namely Tre (Subsection 3.2) 2lcab (Subsection 3.3),apply word-based implementation Huffman coding (Moffat & Turpin, 1997; Turpin395fiSanchez-Martnez, Carrasco, Martnez-Prieto & Adiego& Moffat, 2000) input strings mapped onto integers compressedHuffman codewords (Huffman, 1952). methods encode offsets described(Subsection 3.1) differ encode lexical components biwordsequence.use Huffman codewords allows two methods described achieve largespatial savings, makes inefficient search compressed bitext retrievematches. Section 6 shall describe variant 2lcab compression algorithm(searchable 2lcab) allows sequence words retrieved left textaddition parallel sequences (and context) right text.3.1 Structural EncodingPreliminary tests showed biword extraction algorithm capable generatingsequences high number (usually 70%) biwords without shifts, arraynull values thus considered default offset sequence. offsets thereforeencoded two streams integer values:positions P = (p1 , p2 , . . . , pN ) biwords shifts sequence B.positions expressed relation previous biword shifts B;example, biwords shifts Figure 3 P = (1, 5, 2).offset values biwords shifts. example, offsets =(0, 1, 1, 2); first two offsets belong first biword shifts whereasfollowing ones belong second third biword shifts, respectively.streams therefore encoded using two independent sets Huffman codewords.3.2 TRE CompressorTranslation Relationship-based Encoder (Tre) assigns codewords left wordsequences right words biword use two independent methods.left text encoded using word-based Huffman coding (Moffat, 1989). contrast,right text encoded using left text context. this, Tre uses threedictionaries: one, L , left words, second one, R , sequences rightwords, third one, translation dictionary B , maps word L ontosubset entries R :B () = { R : N : (, , ) B}.every L sequences B () sorted frequency assigned integerrange [1, |B ()|], thus signifying frequent translations lowestvalues.compression stage, text every biword (, , ) mapped onto pairintegers reference left word integer value assigned sequenceright words B (), sequences integers compressed usingindependent Huffman codewords. compression efficiency improvedfrequent translations assigned low (and thus recurrent) integer values. Finally,compressed file includes header with:396fiGeneralized Biwords Bitext Compression Translation Spottingdictionaries L R , independently encoded using PPM compression. special character used separate consecutive entries dictionarieswhite-space serves delimiter word sequences.translation dictionary B , is, Huffman-compressed sequence integers(Moffat & Turpin, 1997) containing, every entry L , size B ()references entries R store every sequence B ().independent Huffman codewords used compress integer sequences references, B () values.3.3 2LCAB Compressorcontrast Tre, 2-Level Compressor Aligned Bitexts (2lcab; Adiego et al., 2009)encodes every biword single codeword based two-level dictionary. first levelconsists two dictionaries, L R , containing left words sequences rightwords, respectively, appear biword sequence B. second level dictionary Bstores different biwords B integer sequence alternating referencesentries L R . text sequence B mapped onto sequencereferences entries B .header includes L R compressed, Tre, PPM algorithm (Cleary & Witten, 1984). also contains codewords (selected accordingHuffman compression procedure) integers sequence describing dictionaryB , encoded dictionary B , second list Huffman codewords used encodebiword sequence B. implementation 2lcab employs (bit-oriented) Huffman coding, original work (Adiego et al., 2009), application described Section 6implement byte-oriented ETDC (Brisaboa et al., 2007). bit-oriented approacheffective, ETDC permits faster searches compressed bitext.4. Resources Settingsorder evaluate performance bitext compressors based generalized biwordsmade use following bitext collections:100 MB SpanishCatalan (es-ca) bitext obtained El Periodico de Catalunya,3daily newspaper published Catalan Spanish.100 MB WelshEnglish (cy-en) bitext Proceedings National Assembly Wales (Jones & Eisele, 2006).4Bitexts (100 MB each) European Parliament Proceedings Parallel Corpus(Europarl; Koehn, 2005) seven different language pairs: GermanEnglish (de-en),SpanishEnglish (es-en), SpanishFrench (es-fr), SpanishItalian (es-it), SpanishPortuguese (es-pt), FrenchEnglish (fr-en), FinnishEnglish (fi-en).3. Available on-line http://www.elperiodico.com.4. Available on-line http://xixona.dlsi.ua.es/corpora/UAGT-PNAW/.397fiSanchez-Martnez, Carrasco, Martnez-Prieto & AdiegoLang.pairen-dees-enfr-esit-espt-esfr-enes-caen-ficy-enbzip2gzipp7zipppmdiwh22.19%22.01%21.51%21.88%21.94%21.65%27.21%22.17%21.83%31.59%31.38%30.80%31.00%31.10%31.10%37.09%31.32%31.11%21.61%21.39%20.75%21.15%21.11%21.06%24.41%20.78%20.33%20.35%20.12%19.57%19.98%20.02%19.76%25.43%20.33%20.07%23.28%23.95%24.04%23.57%23.11%24.57%27.66%22.97%25.18%Table 1: Compression ratios obtained four general-purpose compressors wordbased text compressor (wh).common information retrieval applications, texts tokenized converted lowercase (Manning & Schutze, 1999, Ch. 4). tokenization placed blankspaces every punctuation mark, word thus definedsequence alphanumeric characters delimited blank spaces.Word alignments computed Giza++ toolkit, parameters setdefault values, exception fertility set 5 (the default9). fertility maximum number words word aligned,low value moderates number right sequences one single occurrence bitext.5. Results Discussionreference, Table 1 shows compression ratio defined quotientlengths output input texts (Ziv & Lempel, 1977) achieved aforementioned bitexts compressed variety general-purpose compressorsword-based compressor operating concatenation two texts LR. approaches quoted introduction could compared eithercode linguistic resources required publicly available. compressorsused reference are:bzip2 compressor,5 splits text blocks (100-900 KB), then, appliesBurrows-Wheeler Transform (BWT; Burrows & Wheeler, 1994) followed moveto-front transformation and, finally, encodes result Huffman encoder.Two dictionary-based compressors built different variants Ziv-LempelsLZ77 (Ziv & Lempel, 1977) algorithm. First, gzip,6 classical compressorcombines LZ77-based modeling Huffman coding (Huffman, 1952). Second,modern p7zip7 compressor based Lempel-Ziv-Markov chain algorithm (Sa5. http://www.bzip.org. Experiments run version 1.0.5.6. http://www.gzip.org. Experiments carried version 1.3.12-6.7. http://www.7zip.com. Experiments carried using version 4.58dfsg1.1.398fiGeneralized Biwords Bitext Compression Translation SpottingLang.pairen-dees-enfr-esit-espt-esfr-enes-caen-ficy-en1:1Monotonic20.38%19.63%19.07%19.21%18.44%20.20%17.02%21.50%20.06%1:1Non-monotonic20.06%18.85%18.60%18.86%18.06%19.30%16.95%20.82%18.69%1:NSimple20.26%18.69%18.78%19.11%18.17%19.31%16.78%21.70%18.05%1:NComplex21.22%19.33%19.51%20.00%18.79%20.06%16.86%22.24%18.22%Table 2: Compression ratios obtained Tre compressor different biwordextraction methods.lomon, 2007, Sec. 3.24), algorithm improves LZ77 large dictionary(up 4 GB) range encoding (Martin, 1979).ppmdi (Shkarin, 2002) representative Prediction Partial Matching(PPM; Cleary & Witten, 1984) family compressors. ppmdi uses high-ordercontext model method (Howard & Vitter, 1992) handle escape codes.implementation available Pizza&Chili website8 default configuration(sixth-order context model) used.word-based Huffman compressor (Moffat, 1989) maps input stringsintegers encoding values Huffman codewords (Moffat & Turpin, 1997;Turpin & Moffat, 2000). method originally designed compress text,also works well types sources. dictionary maps words integersencoding ppmdi compressor part output.seen Table 1, lowest compression ratios obtained ppmdi,except es-ca pair. fact compression ratios depend moderatelylanguages involved suggests compressors benefit (variable)cross-language information provided translations.ratios must compared performance two compressors describedsection presented Tables 2 3. Note although bitextsaligned translation directions, results obtained direction producingbest compression reported here, since effect choice compressionratio proved small (an average difference 0.2 percentage points).comparison shows Tre 2lcab outperform general-purpose compressors cases en-fi pair. best results obtainedcases one-to-one alignments used techniques. 2lcab achievesslightly better results Tre language pairs exception it-espt-es, although two cases difference performance small considered relevant. low performance en-fi consequence larger translation8. http://pizzachili.dcc.uchile.cl/utils/ppmdi.tar.gz399fiSanchez-Martnez, Carrasco, Martnez-Prieto & AdiegoLang.pairen-dees-enfr-esit-espt-esfr-enes-caen-ficy-en1:1Monotonic19.98%19.29%18.89%19.18%18.46%19.75%16.69%21.29%19.43%1:1Non-monotonic19.83%18.68%18.50%18.87%18.09%19.03%16.61%20.62%18.30%1:NSimple20.77%19.08%19.27%19.77%18.75%19.65%16.59%22.46%17.98%1:NComplex22.12%19.99%20.25%20.96%19.60%20.71%16.70%23.31%18.25%Table 3: Compression ratios obtained 2lcab compressor different biwordextraction methods.Lang.pairen-dees-enfr-esit-espt-esfr-enes-caen-ficy-enGeneralpurpose20.35%20.12%19.57%19.98%20.02%19.76%24.41%20.33%20.07%2lcab 1:1Monotonic19.98%19.29%18.89%19.18%18.46%19.75%16.69%21.29%19.43%2lcab(best)19.83%18.68%18.50%18.87%18.09%19.03%16.59%20.62%17.98%Gain(Best/Gen.)2.56%7.16%5.47%5.56%9.64%3.69%32.04%-1.43%10.41%Gain(Best/Mono.)0.75%3.16%2.06%1.62%2.00%3.65%0.60%3.15%7.46%Table 4: Summary best compression results obtained with: i) general-purposeword-based compressors; ii) 2lcab compressor structural information (1:1Monotonic); iii) best 2lcab compressor. columns right show relative improvement best 2lcab general purpose monotonic compressors,respectively.dictionaries used Tre, larger bilingual dictionary used 2lcab, comparisonlanguage pairs. Furthermore, percentage unpaired words also higherlanguage pairs seen below.Table 4 summarizes results obtained general-purpose compressors2lcab, relative gains compression performance regard generalpurpose compressors performing best, regard 2lcab compressing1:1 Monotonic biword sequence. greatest improvement, comparison results obtained general-purpose compressors, achieved language pair es-ca:instead 24.4% compression ratio obtained p7zip, 2lcab achieves compressionratio 16.6% represents substantial spatial saving (32.04% relative improvement).suggests Tre 2lcab take advantage fact texts contain400fiGeneralized Biwords Bitext Compression Translation SpottingLang.pairen-dees-enfr-esit-espt-esfr-enes-caen-ficy-en1:1Monotonic0.6000.5060.4630.4650.4210.5400.1280.6840.5301:1Non-monotonic0.4830.3950.3980.4080.3630.4250.1220.6100.3871:NSimple0.3520.9840.2900.2790.2490.3160.0770.4920.2861:NComplex0.3190.2580.2660.2470.2250.2920.0720.4670.276Table 5: Fraction biwords extracted sequence one empty component.information encoded different languages, particularly case highlyparallel bitexts (en-cy) languages high syntactic correlation (es-ca).generalization biwords generates shorter biword sequences, essentiallysequence extracted contains lower fraction unpaired words. Table 5 showsfraction biwords one component empty word (the unpairedword). number obviously considerably reduced offsets used encodestructural information implicit alignments. course, case 1:N Complexapproach, fraction coincides bigraph produced aligner.expected, effect generalization percentage biwords emptycomponent depends languages involved, reduction smaller pairsclosely-related languages (es-ca, pt-es, it-es) pairs languages stronggrammatical divergences (en-de, es-en, fr-en) since, latter case, word reorderings multiword expressions commonly appear translations.order gain insight performance Tre 2lcab compressors,interesting make separate examination contribution output sizeheaders, dictionaries codewords. respect, worth noting that:1. number entries left dictionary L depend method usedextract biword sequence.2. number entries right dictionary R identical two extractionmethods based one-to-one alignments consists words foundright text plus empty word.Tables 6 7 show fraction output corresponds encoded biwordsequence (columns B), translation dictionary biword dictionary (columns D),depending compressor used. numbers reveal general biwords used are, compact encoded sequences compared headersdictionaries. particular, translation dictionary size (analogously, biword dictionary size) differ much non-monotonic alignments used instead basicmethod. However, usage one-to-many alignments causes size dictionarygrow considerably, particularly case biword dictionary B used 2lcab.401fiSanchez-Martnez, Carrasco, Martnez-Prieto & AdiegoLang.pairen-dees-enfr-esit-espt-esfr-enes-caen-ficy-en1:1MonotonicB0.933 0.0310.942 0.0350.934 0.0410.928 0.0450.923 0.0470.951 0.0290.892 0.0390.884 0.0590.960 0.0211:1Non-monotonicB0.9300.0340.9400.0370.9320.0420.9270.0460.9220.0480.9480.0310.8930.0390.8840.0580.9580.0231:NSimpleB0.857 0.0700.894 0.0580.884 0.0650.870 0.0730.870 0.0720.903 0.0540.870 0.0450.785 0.0930.933 0.0341:NComplexB0.787 0.0780.839 0.0690.826 0.0740.805 0.0810.819 0.0780.845 0.0660.862 0.0460.724 0.0890.916 0.038Table 6: Fraction file compressed Tre encoding bitext (B) translation dictionary (D).Lang.pairen-dees-enfr-esit-espt-esfr-enes-caen-ficy-en1:1MonotonicB0.896 0.0650.911 0.0630.894 0.0770.886 0.0830.880 0.0870.920 0.0570.859 0.0710.845 0.0940.939 0.0391:1Non-monotonicB0.8930.0670.9080.0650.8920.0790.8840.0840.8800.0880.9160.0600.8600.0700.8440.0930.9350.0421:NSimpleB0.808 0.1160.844 0.1050.831 0.1150.812 0.1280.814 0.1260.856 0.0980.832 0.0800.725 0.1510.903 0.0611:NComplexB0.733 0.1300.788 0.1190.772 0.1260.745 0.1400.762 0.1330.796 0.1140.824 0.0820.666 0.1470.884 0.066Table 7: Fraction file compressed 2lcab encoding bitext (B)biword dictionary (D).402fiGeneralized Biwords Bitext Compression Translation SpottingLang.pairen-dees-enfr-esit-espt-esfr-enes-caen-ficy-enComp.Ratio19.82%18.51%18.58%18.82%17.98%19.10%16.78%21.01%18.05%1:N SimpleBiwordBreduc. weight0.5140.0330.4950.0240.4720.0280.4580.0290.4830.0300.4790.0221.0000.0450.5390.0491.0000.0341:N ComplexComp. BiwordBRatio reduc. weight19.93%0.4650.03318.56%0.4410.02418.64%0.4340.02718.91%0.4180.02918.05%0.4560.03019.17%0.4160.02216.86%1.0000.04621.09%0.5590.04818.08%0.6310.019Table 8: Compression ratios Tre infrequent biwords split smallerbiwords, remaining fraction original biword dictionary, relative size translation dictionary compressed file.Lang.pairen-dees-enfr-esit-espt-esfr-enes-caen-ficy-en1:N SimpleComp. BiwordBRatio reduc. weight19.42%0.4350.04318.16%0.4060.03618.21%0.3850.03818.47%0.3340.03517.67%0.3610.03718.71%0.3860.03316.59%1.0000.08020.50%0.4450.05617.68%0.5730.0291:N ComplexComp. BiwordBRatio reduc. weight19.51%0.3930.04318.22%0.3260.03118.27%0.3540.03718.55%0.3060.03517.73%0.3410.03618.77%0.3340.03216.70%1.0000.08220.55%0.4640.05517.71%0.5420.029Table 9: Compression ratios 2lcab infrequent biwords split smallerbiwords, remaining fraction original biword dictionary, relative size biworddictionary compressed file.This, cases, causes 2lcab perform worse Tre one-to-manyword alignments.observation one-to-many alignment leads larger dictionaries makes worthexploring effect compression ratio infrequent biwords discarded.Tables 8 9 therefore show compression ratios obtained Tre 2lcab, respectively, infrequent biwords split smaller, frequent, biwords.split proceeds iteratively removing least frequent alignment biword (whichproduces new unpaired word) biword frequencies thresholdbiwords contain unpaired words. threshold determined means ternarysearch optimizes compression ratio. tables also show fraction biwords403fiSanchez-Martnez, Carrasco, Martnez-Prieto & Adiegoremain dictionary pruning, along new fraction outputcorresponds translation biword dictionary.seen tables, discarding infrequent biwords (about two thirdsthem) usually leads improvement compression ratios, except casesimilar languages, Catalan Spanish, translation highlyparallel. effect important case 2lcab pruning leadslarge reduction size biword dictionary compensates smallincrement total number biwords needed represent bitext (between 5%10% increment depending method used generation). filtering,2lcab Tre obtain best results extracting biword sequence method1:N Simple.6. Translation Spotting Compressed Bitextsexploitation bitexts computer-aided translation tools evolved simplebilingual concordancers (Barlow, 2004; Bowker & Barlow, 2004) advanced translationsearch engines (Callison-Burch, Bannard, & Schroeder, 2005a; Bourdaillet, Huet, Langlais,& Lapalme, 2010). standard translation unit processed bilingual concordancerssentences, concordancers thus provide whole sentence resulttranslation search. contrast, translation search engines translation spottingcapabilities, i.e. retrieve parallel text segments bitexts.would seem existing translation search engines (Callison-Burch et al., 2005a;Bourdaillet et al., 2010) access bitexts compressed forms storingcorrespondences translated segments requires additional data structuresword indexes suffix arrays (Lopez, 2007; Callison-Burch, Bannard, & Schroeder,2005b); suffix arrays typically require four times size text (Manber & Myers,1993). contrast, generalized biwords require much less space, integratealignment information compressed bitext, information exploitedretrieve translation examples. section describe minor modificationsneed done 2lcab compression algorithm applied task.also describe search algorithm compressed bitexts evaluate compressionperformance new 2lcab implementation (searchable 2lcab).application 2lcab compression technique direct search compressedbitexts leads certain challenges present decompression processbecause:Huffman PPM compression hinder direct searching random accesscompressed text (Bell, Cleary, & Witten, 1990).multilevel scheme 2lcab, whenever matching string foundinstance, biword dictionary B necessary know strings codewordorder search encoded string higher level example, sequencebiwords B.differences induced 2lcab described follows, summarized Table 10.404fiGeneralized Biwords Bitext Compression Translation SpottingDataLRBBPContentlword0, lword1, . . .rword0, rword1, . . .lpos0, rpos0, lpos1, rpos1, . . .bpos0, bpos1, . . .delta0, delta1, . . .offset0, offset1, . . .2lcabPPMPPMHuffmanHuffmanHuffmanHuffmanSearchable 2lcabPPMPPMETDCETDCRRRDAC & RGTable 10: Summary compression methods applied. marked sortitems compression. RG used DAC case biwords complexshifts present.6.1 Searchable 2LCAB Compressionseveral alternative compression methods, ETDC, allow directsearches compressed text. contrast output Huffman compression,ETDC header stores words, codeword derived word position henceforth, rank words sorted according relative frequenciesdocument compressed. means always mapping,denoted code(n), provides ETDC codeword n-th frequent word,along corresponding reverse mapping.instance, b-th byte compressed bilingual dictionary B matches leftword code, rank B determines codeword must looked B.9 course,rank obtained keeping record number n words B scannedfar, standard pattern matching algorithms BM (Boyer & Moore, 1977)KMP (Knuth, Morris, & Pratt, 1977) well suited tracking. thereforeuse finite sequence bits = b1 , b2 , , b|S| retrieve rank n-th byte nencoded B . sequence bn = 1 every n n final bytecodeword built fly B read compressed file.Succinct data structures (Navarro & Makinen, 2007, Sec. 6), RG (Gonzalez,Grabowski, Makinen, & Navarro, 2005) RRR (Raman, Raman, & Rao, 2002), provideeffective way represent sequence bits recover rank associatedevery matching sequence, support number operations sequencebits time independent length (Clark, 1996):number bits rankS (i) whose value one b1 bi .position selectS (i) i-th bit whose value one;value i-th bit S, denoted accessS (i) = bi .Moreover, structural information P describing biwords shiftsalso needs randomly accessed, succinct data structure RRR provides compactalternative Huffman-based method used 2lcab compress P, sequenceposition increments. Indeed, RRR encoding especially compact information9. rank also used discard false matches originated coincidence right word Bbecause, cases, rank even number.405fiSanchez-Martnez, Carrasco, Martnez-Prieto & Adiegounbalanced instance, 80% bits show identical value, casenumber biwords shifts small. Therefore, integer sequence Pinstead stored binary sequence P = p1 , p2 , . . . , pm pi = 1 n-th byteB final byte codeword biword shifts.Finally, offsets stored compressed directly addressable variablelength codes (DAC, Brisaboa, Ladra, & Navarro, 2009) which, contrast Huffmancompression, provide direct access n-th encoded element. Information associatedn-th biword thus retrieved immediately, since DAC encodingrequire preceding sequence decompressed beginning. biwordscomplex shifts contain one offset, access cases indirectprovided auxiliary RG data structure. structure builds sequencebits Q = q1 , q2 , , q|Q| |Q| total number offsets stored O. sequenceQ qi = 1 Oi first offset array biword (, , ), qi = 0 otherwise.seen Table 10, searchable 2lcab method replaces Huffman compression ETDC sorts contents higher-level ETDC compressionneed store codewords header.6.2 Translation Spottingsearchable 2lcab described complemented search algorithm which,given single word w left text, proceeds follows:1. word w looked L whose relatively small size permits uncompressedcopy stored memory identifier n, given word positionL , used obtain ETDC codeword c = code(n).2. exact pattern-matching algorithm (Knuth et al., 1977) identifies occurrencescodeword c biword dictionary B . match found b-th byter = rankS (b) odd (indicating match L -codeword, is, biwordleft component w), then, biword codeword code(r/2) addedsearch set Z.3. multi-pattern matching algorithm Set-Horspool (Horspool, 1980; Navarro &Raffinot, 2002) locates codewords sequence biwords B match onecontained Z, matching positions added new set .4. every match , adjacent right component read B and, wheneverpm = 1 P , offsets recovered used place right wordsoriginal order. case biwords complex shifts, interval Oi Ojcontaining offsets starts = selectQ (r) ends j = selectQ (r + 1) 1,r = rankP (m).case query consists sequence words (w1 , w2 , wK ) K > 1,Set-Horspool algorithm executed word wk sequence generatingsmallest set codewords locate Zk , remaining words used filterresults biword context retrieved.Table 11 shows actual example output obtained multiple word querycompressed biword sequence obtained 1:N Complex method. Note406fiGeneralized Biwords Bitext Compression Translation SpottingLeft text:Right text:Left text:Right text:Left text:Right text:Left text:Right text:democratic citizens able exercise influence , goes without saying entitledinformation need order perform civic dutiessociety .un componente de la democracia es que los ciudadanos puedan influir, obviamente , que tengan derecho acceder la informacion necesariapara actuar como ciudadanos en sus sociedades .concerned , , protection criminal laweuropol units receive information intelligenceneed order perform tasks .se trata , por tanto , de proteccion penal de que las unidades deeuropol deben obtener la informacion los datos que necesiten parapoder realizar su trabajo .co-decision procedure must used order performlegislative work conditions guarantee genuine debate ,involving society citizens .para que ese trabajo legislativo se realice en condiciones que garanticen un verdadero debate , social ciudadano , hace falta recurrir alprocedimiento de codecision .tools , procedures , need orderperform ?cuales son las herramientas , los procedimientos que necesitamos paraejecutarlas ?Table 11: Output obtained query order perform bitext compressed1:N Complex method. query terms translations spottedboldface.third match shows non-contiguous translation, case cannot retrievedoriginal 2lcab implementation (Adiego et al., 2009).6.3 Experimental Evaluationcompression ratios obtained searchable 2lcab shown Table 12. algorithm clearly effective 2lcab described Section 3, leading compressionratios slightly worse obtained general purpose word-basedcompressors. However, worth mentioning compressed files include information concerning alignments words, information includedfiles compressed standard compressors necessary perform translationspotting.Table 12 also shows 1:1 Monotonic method case effective1:1 Non-monotonic method latter needs additional data structure(the RRR bit sequence) order access structural information. Moreover, byteorientation ETDC reduces gain obtained encoding lower number biwords.407fiSanchez-Martnez, Carrasco, Martnez-Prieto & AdiegoLang.pairen-dees-enfr-esit-espt-esfr-enes-caen-ficy-en1:1Monotonic22.66%21.86%21.30%21.69%20.87%22.37%19.22%24.14%22.30%1:1Non-monotonic23.20%21.81%21.47%21.93%21.07%22.19%19.67%24.01%21.86%1:NSimple24.10%22.26%22.33%22.93%21.78%22.83%19.70%25.91%21.39%1:NComplex26.02%23.68%23.70%24.57%23.00%24.36%19.87%27.29%21.98%Table 12: Compression ratios obtained searchable 2lcab compressor.studied time needed process query depends language pairalso number frequencies words query. average times100 different sequences 10 runs reported Figures 4 5, process timesmeasured AMD Athlon Dual Core 2 GHz 2GB RAM.Figure 4 presents times two different language pairs. first one, en-fr, displays typical behavior Europarl bitexts (Koehn, 2005), second one,en-fi, requires particularly longer times, especially large queries. divergent behavior seems originate poor quality alignments wordspair languages. often makes words participate large number different biwordsdegrades performance Set-Horspool algorithm. language pairconsistently leads worst compression ratios.Finally, Figure 5 shows processing times two language pairs (en-cy es-ca)whose bitexts obtained totally different source. processing timesconsiderably lower required Europarl corpus manual inspectionbitexts revealed highly parallel structure. implies wordsparticipate small number biwords and, surprisingly, 2lcab achieveslowest compression ratios language pairs.7. Concluding Remarksintroduced concept generalized biwords applied compressionbitexts. Generalized biwords integrate information concerning word reorderingmultiword expressions translated text. described procedure transformsbitext sequence generalized biwords used intermediaterepresentation compression process. extended binary compressionalgorithm 2lcab proposed new one, called Tre, encoding generalizedbiword sequences. also designed variant 2lcab compression technique,companion algorithm facilitates efficient searching translation spottingcompressed bitext.compression performance 2lcab Tre tested four differentschemes extract biword sequence, uses biwords different structural408fiGeneralized Biwords Bitext Compression Translation SpottingLow-frequency sequencesMedium-frequency sequences1:1 Monotonic1:1 Non-monotonic1:N Simple1:N Complex3503001:1 Monotonic1:1 Non-monotonic1:N Simple1:N Complex350300High-frequency sequences30025025025020020020015015015010010010050505000123 4 5 6Query length781:1 Monotonic1:1 Non-monotonic1:N Simple1:N Complex3500123 4 5 6Query length78123 4 5 6Query length78(a) EnglishFrench (en-fr) bitextLow-frequency sequencesMedium-frequency sequencesHigh-frequency sequences3503503503003003002502502502002002001501501501001001:1 Monotonic1:1 Non-monotonic1:N Simple1:N Complex500123 4 5 6Query length1001:1 Monotonic1:1 Non-monotonic1:N Simple1:N Complex50078123 4 5 6Query length1:1 Monotonic1:1 Non-monotonic1:N Simple1:N Complex50078123 4 5 6Query length78(b) EnglishFinnish (en-fi) bitextFigure 4: Average time (milliseconds) needed process query containing wordslow, medium high frequency, function query length. Times showntwo different language pairs four encoding methods.409fiSanchez-Martnez, Carrasco, Martnez-Prieto & AdiegoLow-frequency sequencesMedium-frequency sequences1:1 Monotonic1:1 Non-monotonic1:N Simple1:N Complex3503001:1 Monotonic1:1 Non-monotonic1:N Simple1:N Complex350300High-frequency sequences30025025025020020020015015015010010010050505000123 4 5 6Query length781:1 Monotonic1:1 Non-monotonic1:N Simple1:N Complex3500123 4 5 6Query length78123 4 5 6Query length78(a) EnglishWelsh (en-cy) bitextLow-frequency sequencesMedium-frequency sequences1:1 Monotonic1:1 Non-monotonic1:N Simple1:N Complex3503001:1 Monotonic1:1 Non-monotonic1:N Simple1:N Complex350300High-frequency sequences30025025025020020020015015015010010010050505000123 4 5 6Query length781:1 Monotonic1:1 Non-monotonic1:N Simple1:N Complex3500123 4 5 6Query length78123 4 5 6Query length78(b) SpanishCatalan (es-ca) bitextFigure 5: Average time (milliseconds) needed process query two different languagepairs (en-cy es-ca).410fiGeneralized Biwords Bitext Compression Translation Spottingcomplexities. simplest method uses biwords without shifts therefore equivalentapproaches biwords simple pairs include structural information.methods include offsets integrate structural information alignments.experiments show generalized biwords lead better compression ratiosreduction sequences encoding bitext compensates larger dictionariesneeded. largest reduction compression ratios obtained pairs divergentlanguages because, cases, biwords without shifts cannot tackle frequent wordreorderings multiword translations.Since enhanced variability generalized biwords requires larger dictionariesincrease header included compressed files, tested effect splittinginfrequent biwords smaller, frequent biwords. reduces number differentbiwords allows 2lcab compressor obtain lower compression ratios.pruning, 2lcab provides best results biwords obtained one-to-many wordalignments simple shifts allowed, is, target text splitsegments contiguous words. algorithms, Tre 2lcab, provide bettercompression ratios general purpose compressors, particularly case pairslanguages share common language family (es-ca) bitexts highly parallel(en-cy). compression ratio therefore used indirectly measure qualityword alignment degree parallelism bitext.modifications made 2lcab compressors allow compressed bitextsearched efficiently, although adaptation leads slightly worse compression ratios.However, new compressed file includes alignments words bitextadditional information needed order implement translation spotting.relatively small difference time needed process query 1:1 Monotonicmethod (the fastest one) 1:N Complex method (the one conveying information) makes latter preferable choice translation spotting identifieslarger variety translations bitext provides richer examples.future work plan study effect translation performance integration generalized, biword-based bilingual language models current state-of-the-artstatistical machine translation systems.Appendix A. Biword Extraction AlgorithmAlgorithm 1 shows procedure used obtain sequence generalized biwords Bbitext one-to-many word alignments. main loop (lines 325) iterateswords left right texts still words sides considered.Variables n point next left right words, respectively, processed.Inside main loop, setpositions right words aligned leftword lm , set positions left words aligned right wordrn first computed. word alignments one-to-many,n contains, most, oneelement.every iteration, single biword produced.empty, i.e., lm aligned,next biword consists left word lm , empty sequence right words emptysequence offsets (line 7).empty is, biword consists emptyword, sequence right words containing rn sequence offsets containing411fiSanchez-Martnez, Carrasco, Martnez-Prieto & AdiegoAlgorithm 1 GetBiwords extracts biword sequence one-to-many word alignment two texts.Input: Two word sequences L R, one-to-many bigraph G = {L, R, A}Output: sequence B 3-tuples (word, sequence words, sequence offsets)1: B (). Create empty sequence 3-tuples2: 1; n 13: (m ) (n N )4:{j : (lm , rj ) A}5:n {i : (li , rn ) A}6:=7:add (lm , (), ()) B8:mm+19:elsen =10:add (, (rn ), (0)) B11:n NextRight(m, n, G)12:else13:(); (). Create empty sequences words offsets14:kn15:jascending order16:add rj ; add j k17:k j+118:n = j19:n NextRight(m, n, A)20:end21:end22:add (lm , , ) B23:mm+124:end25: end26:27:add (lm , (), ()) B28:mm+129: end30: n N31:n {i : (li , rn ) A}32:n =33:add (, (rn ), (0)) B34:end35:nn+136: end37: return B412fiGeneralized Biwords Bitext Compression Translation SpottingAlgorithm 2 NextRightInput: Integers n, one-to-many bigraph G = (L, R, A)Output: Index next right word paired , lm posterior word L1: repeat2:nn+13:n {i : (li , rn ) A}4: (n > N ) (An = ) (min(An ) m)5: return nnull offset (line 10). Otherwise, biword consists lm , sequence containingright words aligned lm , sequence containing one offset right word.first offset relative n, whereas following ones relative previous wordsequence (see lines 1521).Index simply incremented every time biword containing left word produced.update n subtle since words positions greater n mayalready processed aligned left word preceding lm . n thereforeassigned value returned function NextRight (depicted Algorithm 2) which, givencurrent values n, looks next n rm paired eitherempty word left word preceding lm .Finally, two loops take care words remain unprocessed main loop.Appendix B. Bitext Restoration AlgorithmAlgorithm 3 provides pseudo-code restore right text bitextbiword representation obtained Algorithm 1. Restoring left text straightforward since biwords sorted left component.main loop Algorithm 3 (lines 315) iterates sequence biwords representing bitext. Variables n point next biword processed,next gap R filled word, respectively. iterates arrayoffsets = (w1 , . . . , w|| ) (lines 710) places word j sequence rightwords = (1 , . . . , || ) right place. biword processed,updated point next biword, n point next gap R filled(lines 1214).Acknowledgmentswork supported Spanish Government projects TIN2009-14009C02-01 TIN2009-14009-C02-02, Millennium Institute Cell DynamicsBiotechnology (grant ICM P05-001-F). development work reportedpaper, Miguel A. Martnez-Prieto Department Computer Science (UniversityChile) post-doctoral stay. authors thanks Nieves R. Brisaboa ideascooperation development initial version 2lcab, Gonzalo Navarroinspiration Tre compression approach, anonymous referees suggestingsignificant improvements paper Francis M. Tyers proof-reading it.413fiSanchez-Martnez, Carrasco, Martnez-Prieto & AdiegoAlgorithm 3 GetRightText retrieves right text biword representationbitext.Input: sequence biwords B = (1 , . . . , )Output: right text R = r1 r2 rN contained sequence B.1: 12: n 13:4:k =n15:offset(m )6:right(m )7:j = 1, . . . , ||8:k k + j + 19:rk j10:end11:mm+112:rn undefined13:nn+114:end15: end16: return RReferencesAdiego, J., Brisaboa, N. R., Martnez-Prieto, M. A., & Sanchez-Martnez, F. (2009).two-level structure compressing aligned bitexts. Proceedings 16th StringProcessing Information Retrieval Symposium, Vol. 5721 Lecture Notes Computer Science, pp. 114121, Saariselka, Finland. Springer.Adiego, J., & de la Fuente, P. (2006). Mapping words codewords PPM. Proceedings13th String Processing Information Retrieval Symposium, Vol. 4209Lecture Notes Computer Science, pp. 181192, Glasgow, UK. Springer.Adiego, J., Martnez-Prieto, M. A., Hoyos-Torio, J. E., & Sanchez-Martnez, F. (2010).Modelling parallel texts boosting compression. Proceedings 2010 DataCompression Conference, p. 517, Snowbird, USA.Arnold, D., Balkan, L., Meijer, S., Humphreys, R., & Sadler, L. (1994). Machine translation:introductory guide. NCC Blackwell, Oxford.Barlow, M. (2004). Parallel concordancing translation. Proceedings ASLIB Translating Computer 26, London, UK.Bell, T. C., Cleary, J. G., & Witten, I. H. (1990). Text compression. Prentice Hall.Bourdaillet, J., Huet, S., Langlais, P., & Lapalme, G. (2010). TransSearch: bilingual concordancer translation finder. Machine Translation, 23 (34), 241271.Published 2011.Bowker, L., & Barlow, M. (2004). Bilingual concordancers translation memories:comparative evaluation. Proceedings Second International Workshop414fiGeneralized Biwords Bitext Compression Translation SpottingLanguage Resources Translation Work, Research Training Coling 2004, pp.7079, Geneva, Switzerland.Boyer, R., & Moore, J. S. (1977). fast string searching algorithm. CommunicationsACM, 20 (10), 762772.Brisaboa, N., Ladra, S., & Navarro, G. (2009). Directly addressable variable-length codes.Proceedings 16th String Processing Information Retrieval Symposium,Vol. 5721 Lecture Notes Computer Science, pp. 122130, Saariselka, Finland.Springer.Brisaboa, N. R., Farina, A., Navarro, G., & Parama, J. R. (2007). Lightweight naturallanguage text compression. Information Retrieval, 10 (1), 133.Brown, P., Lai, J., & Mercer, R. (1991). Aligning sentences parallel corpora. Proceedings 29th Annual Meeting Association Computational Linguistics, pp.169176, Berkeley, CA, USA.Brown, P. F., Cocke, J., Pietra, S. A. D., Pietra, V. J. D., Jelinek, F., Lafferty, J. D.,Mercer, R. L., & Roossin, P. S. (1990). statistical approach machine translation.Computational Linguistics, 16 (2), 7685.Brown, P. F., Pietra, S. A. D., Pietra, V. J. D., & Mercer, R. L. (1993). mathematicsstatistical machine translation: Parameter estimation. Computational Linguistics,19 (2), 263311.Burrows, M., & Wheeler, D. (1994). block sorting lossless data compression algorithm.Tech. rep. 124, Digital Systems Research Center, Palo Alto, CA, USA.Callison-Burch, C., Bannard, C., & Schroeder, J. (2005a). compact data structuresearchable translation memories. Proceedings 10th European AssociationMachine Translation Conference, pp. 5965, Budapest, Hungary.Callison-Burch, C., Bannard, C., & Schroeder, J. (2005b). Scaling phrase-based statisticalmachine translation larger corpora longer phrases. Proceedings 43rdAnnual Meeting Association Computational Linguistics, pp. 255262, AnnArbor, USA.Carl, M., & Way, A. (Eds.). (2003). Recent Advances Example-Based Machine Translation, Vol. 21 Text, Speech Language Technology. Springer.Carroll, J. (2003). Oxford Handbook Computational Linguistics, chap. 12 Parsing,pp. 233248. Oxford University Press.Casacuberta, F., & Vidal, E. (2004). Machine translation inferred stochastic finite-statetransducers. Computational Linguistics, 30 (2), 205225.Clark, D. (1996). Compact PAT trees. Ph.D. thesis, University Waterloo, Warteloo, ON,Canada.Cleary, J. G., & Witten, I. H. (1984). Data compression using adaptive coding partialstring matching. IEEE Transactions Communications, 32 (4), 396402.Conley, E., & Klein, S. (2008). Using alignment multilingual text compression. International Journal Foundations Computer Science, 19 (1), 89101.415fiSanchez-Martnez, Carrasco, Martnez-Prieto & AdiegoCover, T. M., & Thomas, J. A. (1991). Elements Information Theory. Wiley.Gale, W. A., & Church, K. W. (1993). program aligning sentences bilingual corpora.Computational Linguistics, 19 (1), 75102.Gonzalez, R., Grabowski, S., Makinen, V., & Navarro, G. (2005). Practical implementationrank select queries. Proceedings 4th International WorkshopEfficient Experimental Algorithms, pp. 2738, Santorini Island, Greece.Grossman, D. A., & Frieder, O. (2004). Information Retrieval: Algorithms Heuristics(2nd edition)., Vol. 15 Information Retrieval Series. Springer.Hasan, S., Ganitkevitch, J., Ney, H., & Andres-Ferrer, J. (2008). Triplet lexicon modelsstatistical machine translation. Proceedings 2008 Conference EmpiricalMethods Natural Language Processing, pp. 372381, Honolulu, USA.Horspool, R. N. (1980). Practical fast searching strings. Software: Practice Experience, 10 (6), 501506.Howard, P., & Vitter, J. (1992). Practical implementations arithmetic coding. Storer,J. (Ed.), Image Text Compression, pp. 85112. Kluwer Academic.Huffman, D. (1952). method construction minimum-redundancy codes. Proceedings Institute Radio Engineers, 40 (9), 10981101.Ide, N., & Veronis, J. (1998). Word sense disambiguation: state art. Computational Linguistics, 24 (1), 141.Jones, D., & Eisele, A. (2006). Phrase-based statistical machine translation EnglishWelsh. Proceedings 5th SALTMIL Workshop Minority Languages5th International Conference Language Resources Evaluation, pp. 7577,Genoa, Italy.Knuth, D. E., Morris, J. H., & Pratt, V. (1977). Fast pattern matching strings. SIAMJournal Computing, 6 (2), 323350.Koehn, P. (2005). Europarl: parallel corpus statistical machine translation. Proceedings Tenth Machine Translation Summit, pp. 7986, Phuket, Thailand.Koehn, P. (2010). Statistical Machine Translation. Cambridge University Press.Lopez, A. (2007). Hierarchical phrase-based translation suffix arrays. Proceedings2007 Joint Conference Empirical Methods Natural Language ProcessingComputational Natural Language Learning, pp. 976985, Prague, Czech Republic.Lopez, A. (2008). Statistical machine translation. ACM Computing Surveys, 40 (3), 149.Manber, U., & Myers, G. (1993). Suffix arrays: new method on-line string searches.SIAM Journal Computing, 22 (5), 935948.Manning, C. D., & Schutze, H. (1999). Foundations statistical natural language processing.MIT Press.Marino, J., Banchs, R. E., Crego, J. M., de Gispert, A., Lambert, P., Fonollosa, J. A. R.,& Costa-Jussa, M. R. (2006). N-gram-based machine translation. ComputationalLinguistics, 32 (4), 527549.416fiGeneralized Biwords Bitext Compression Translation SpottingMartin, G. (1979). Range encoding: algorithm removing redundancy digitizedmessage. Proceedings Video Data Recording Conference, Southampton, UK.Martnez-Prieto, M. A., Adiego, J., Sanchez-Martnez, F., de la Fuente, P., & Carrasco,R. C. (2009). use word alignments enhance bitext compression.Proceedings 2009 Data Compression Conference, p. 459, Snowbird, USA.Matusov, E., Zens, R., Vilar, D., Mauser, A., Popovic, M., Hasan, S., & Ney, H. (2006).RWTH machine translation system. Proceedings TC-STAR WorkshopSpeech-to-Speech Translation, pp. 3136, Barcelona, Spain.Melamed, I. D. (2001). Emplirical methods exploting parallel texts. MIT Press.Mihalcea, R., & Simard, M. (2005). Parallel texts. Natural Language Engineering, 11 (3),239246.Moffat, A. (1989). Word-based text compression. Software: Practice Experience, 19 (2),185198.Moffat, A., & Isal, R. Y. K. (2005). Word-based text compression using Burrows-Wheelertransform. Information Processing Management, 41 (5), 11751192.Moffat, A., & Turpin, A. (1997). implementation minimum redundancy prefixcodes. IEEE Transactions Communications, 45 (10), 12001207.Navarro, G., & Makinen, V. (2007). Compressed full-text indexes. ACM Computing Surveys,39 (1). Article 2.Navarro, G., & Raffinot, M. (2002). Flexible Pattern Matching String: Practical on-linesearch algorithms texts biological sequences. Cambridge University Press.Nevill-Manning, C., & Bell, T. (1992). Compression parallel texts. Information Processing& Management, 28 (6), 781794.Niehues, J., Herrmann, T., Vogel, S., & Waibel, A. (2011). Wider context using bilingual language models machine translation. Proceedings 6th WorkshopStatistical Machine Translation, pp. 198206, Edinburgh, UK.Och, F. J., & Ney, H. (2003). systematic comparison various statistical alignmentmodels. Computational Linguistics, 29 (1), 1951.Raman, R., Raman, V., & Rao, S. (2002). Succinct indexable dictionaries applicationsencoding k-ary trees multisets. Proceedings 22nd Annual ACM-SIAMSymposium Discrete Algorithms, pp. 233242, San Francisco, CA, USA.Salomon, D. (2007). Data compression. complete reference (Fourth edition). Springer.Shkarin, D. (2002). PPM: One step practicality. Proceeding 2002 Data Compression Conference, pp. 202211, Snowbird, USA.Simard, M. (2003). Translation spotting translation memories. Proceedings NAACL2003 Workshop Building Using Parallel Texts: Data Driven Machine Translation Beyond, pp. 6572, Edmonton, AB, Canada.Suel, T., & Memon, N. (2003). Algorithms delta compression remote file synchronization. Sayood, K. (Ed.), Lossless Compression Handbook, pp. 269290. AcademicPress.417fiSanchez-Martnez, Carrasco, Martnez-Prieto & AdiegoTufis, D., Barbu, A.-M., & Ion, R. (2004). Extracting multilingual lexicons parallelcorpora. Computers Humanities, 38 (2), 163189.Turpin, A., & Moffat, A. (2000). Housekeeping prefix coding. IEEE TransactionsCommunications, 48 (4), 622628.Veronis, J., & Langlais, P. (2000). Parallel text processing. Alignment use translation corpora, chap. Evaluation Parallel Text Alignment Systems ARCADEProject. Kluwer Academic Publishers.Vogel, S., Ney, H., & Tillmann, C. (1996). HMM-based word alignment statistical translation. Proceedings 16th International Conference Computational Linguistics, pp. 836841, Copenhagen, Denmark.Ziv, J., & Lempel, A. (1977). universal algorithm sequential data compression. IEEETransactions Information Theory, 23 (3), 337343.Ziviani, N., Moura, E., Navarro, G., & Baeza-Yates, R. (2000). Compression: keynext-generation text retrieval systems. IEEE Computer, 33 (11), 3744.418fiJournal Artificial Intelligence Research 43 (2012) 571-620Submitted 09/11; published 04/12Reformulating Situation Calculus EventCalculus General Theory Stable ModelsAnswer Set ProgrammingJoohyung LeeRavi Pallajoolee@asu.eduRavi.Palla@asu.eduSchool Computing, Informatics,Decision Systems EngineeringArizona State UniversityTempe, AZ 85287, USAAbstractCircumscription logic programs stable model semantics two wellknown nonmonotonic formalisms. former served basis classical logic basedaction formalisms, situation calculus, event calculus temporal actionlogics; latter served basis family action languages, languageseveral descendants. Based discovery circumscription stablemodel semantics coincide class canonical formulas, reformulate situationcalculus event calculus general theory stable models. also presenttranslation turns reformulations answer set programs, efficientanswer set solvers applied compute situation calculus event calculus.1. IntroductionCircumscription (McCarthy, 1980, 1986) logic programs stable model semantics (Gelfond & Lifschitz, 1988) two well-known nonmonotonic formalisms. oneoldest nonmonotonic formalisms, circumscription found many applications commonsense reasoning model-based diagnoses (e.g., McCarthy, 1986; Shanahan, 1995; Besnard& Cordier, 1994). stable model semantics mathematical basis Answer Set Programming (ASP) (Marek & Truszczynski, 1999; Niemela, 1999; Lifschitz, 2008),widely applied thanks availability several efficient implementations, knownanswer set solvers.two nonmonotonic formalisms applied overlapping classesproblems, minimal model reasoning ensured circumscription coincide stablemodel reasoning. Moreover, formalisms different roots. circumscriptiondefined terms translation classical (second-order) logic, stable models proposedGelfond Lifschitz (1988) defined terms grounding fixpointsstyle Reiters default logic (Reiter, 1980). differences part account facttwo formalisms formed rather disparate traditions knowledge representationresearch. particular, area temporal reasoning, former served basisclassical logic based action calculi, situation calculus (McCarthy & Hayes, 1969;Reiter, 2001), event calculus (Shanahan, 1995) temporal action logics (Doherty,c2012AI Access Foundation. rights reserved.fiLee & PallaGustafsson, Karlsson, & Kvarnstrom, 1998), whereas latter served basisfamily action languages, language (Gelfond & Lifschitz, 1998) severaldescendants translated logic programs stable model semantics.However, recent generalization stable model semantics shed new lightrelationship circumscription stable models. first-order stable model semantics defined Ferraris, Lee Lifschitz (2007, 2011) characterizes stable modelsfirst-order sentence models (in sense first-order logic) sentencesatisfy stability condition, expressed second-order formula similarone used define circumscription. Since logic programs viewed specialclass first-order sentences stable model semantics, definition extendsstable model semantics Gelfond Lifschitz (1988) full first-order level withoutlimiting attention Herbrand models. Essentially characterization independently given Lin Zhou (2011), via logic knowledge justified assumption (Lin& Shoham, 1992). definitions also equivalent definition Quantified Equilibrium Logic given Pearce Valverde (2005), defined terms logicHere-and-There (Heyting, 1930).new definition stable model motivates us investigate relationshipstable model reasoning minimal model reasoning. particular, focusrelationship area temporal reasoning. show situation calculusevent calculus reformulated first-order stable model semantics,ASP. theoretically interesting, also practically useful allows usleverage efficient answer set solvers computing circumscriptive action theories.this, develop two technical results. First, show circumscriptionfirst-order stable model semantics coincide class canonical formulas.largest syntactic class identified far two semantics coincide, generalenough cover several circumscriptive action formalisms, situation calculus,event calculus, temporal action logics. result allows us reformulateaction formalisms first-order stable model semantics. minimal model reasoningsometimes leads unintuitive results, circumscriptive action formalisms carefullydesigned avoid cases, result implies minimal model reasoningaction formalisms also viewed stable model reasoning.Second, identify class almost universal formulas, turnedsyntax logic program preserving stable models. turns reformulations situation calculus event calculus first-order stable modelsemantics fall class formulas. introduce system f2lp turns formulasclass logic programs, and, conjunction result canonical formulas, usecombination f2lp answer set solvers compute situation calculusevent calculus.work makes explicit relationship classical logic logic program traditions temporal reasoning. Interestingly, development event calculusspanned traditions. original version event calculus (Kowalski & Sergot, 1986) formulated logic programs, stable model semantics (thattime invention stable model semantics). extensive developments later carried classical logic foundation via circumscription (e.g.,Shanahan, 1995, 1997, 1999; Miller & Shanahan, 1999; Mueller, 2004), relation572fiReformulating Situation Calculus Event Calculuslogic program formulation remained implicit. Based reduction circumscription completion, SAT-based event calculus systems implemented, one ShanahanWitkowski (2004) another Mueller (2004). latter system called decreasoner,1 outperforms former thanks efficient general compilationmethod propositional logic. system handles large fragment eventcalculus, still cannot handle recursive disjunctive axioms since completion cannotapplied axioms. ASP-based approach hand handlefull version event calculus assumption domain given finite.Thanks efficiency ASP solvers, experiments indicate ASP-based eventcalculus reasoner significantly faster dec reasoner (Appendix B).Similar logic programming tradition event calculus, situation calculus (McCarthy & Hayes, 1969; Reiter, 2001) implemented Prolog, basedfact Clarks completion semantics accounts definitional axioms. unlikeevent calculus, best knowledge, efficient propositional solversapplied directly compute models situation calculus theories. paper,reformulate Lins causal action theories (1995) Reiters basic action theories (2001)first-order stable model semantics ASP. basic action theories, also provideASP-based encoding method obtains Reiters successor state axioms effectaxioms generic inertia axioms adopted ASP, idea close Reitersframe default (1980).paper organized follows. next section reviews definitions circumscription first-order stable model semantics, presents definitioncanonical formula. Based this, Sections 3 4 reformulate event calculussituation calculus first-order stable model semantics. Section 5 shows translationturns almost universal formulas logic programs accepted ASPsolvers. Sections 6 7 use result turn reformulations event calculussituation calculus given Sections 3 4 input language ASP solvers.Complete proofs given Appendix C.2. Circumscription First-Order Stable Model Semanticsassume following set primitive propositional connectives quantifiers:(falsity), , , , , .understand F abbreviation F ; symbol > stands , F Gstands (F G) (G F ).2.1 Review: CircumscriptionLet p list distinct predicate constants p1 , . . . , pn , let u list distinctpredicate variables u1 , . . . , un . u p denote conjunction formulasx(ui (x) pi (x)) = 1, . . . n, x list distinct object variables whoselength arity pi . Expression u < p stands (u p) (p u).1. http://decreasoner.sourceforge.net573fiLee & Pallainstance, p q unary predicate constants (u, v) < (p, q)x(u(x) p(x)) x(v(x) q(x)) x(p(x) u(x)) x(q(x) v(x)) .Circumscription defined terms CIRC operator minimized predicates.first-order formula F , expression CIRC[F ; p] stands second-order formulaF u((u < p) F (u)),F (u) formula obtained F substituting ui pi . F sentence(i.e., formula free variables), intuitively, models CIRC[F ; p] modelsF minimal p.definition straightforwardly extended case F many-sorted firstorder formula (Lifschitz, 1994, Section 2.4), language event calculussituation calculus based on.2.2 Review: First-Order Stable Model Semanticsreview follows definition Ferraris et al. (2011). There, stable modelsdefined terms SM operator, whose definition similar CIRC operatorprevious section. first-order formula F finite list predicate constantsp = (p1 , . . . , pn ), formula SM[F ; p] definedF u((u < p) F (u)),u defined CIRC[F ; p], F (u) defined recursively follows:pi (t) = ui (t) list terms;F = F atomic formula F (including equality) containmembers p;(F G) = F G ;(F G) = F G ;(F G) = (F G ) (F G);(xF ) = xF ;(xF ) = xF .predicates p called intensional: predicates intendcharacterize F terms non-intensional predicates.2 F sentence, modelssecond-order sentence SM[F ; p] called p-stable models F :models F stable p. often simply write SM[F ] place SM[F ; p]p list predicate constants occurring F . According Lee, Lifschitz,2. Intensional predicates analogous output predicates Datalog, non-intensional predicatesanalogous input predicates Datalog (Lifschitz, 2011).574fiReformulating Situation Calculus Event CalculusPalla (2008), answer sets defined special class stable models follows. (F )denote signature consisting object, function predicate constants occurringF . F contains least one object constant, Herbrand interpretation (F )satisfies SM[F ] called answer set F . answer sets logic program definedanswer sets FOL-representation (i.e., conjunction universalclosures implications corresponding rules). example, FOL-representationprogramp(a)q(b)r(x) p(x), q(x)p(a) q(b) x(p(x) q(x) r(x))(1)SM[F ]p(a) q(b) x(p(x) q(x) r(x))uvw(((u, v, w) < (p, q, r)) u(a) v(b)x((u(x) (v(x) q(x)) w(x)) (p(x) q(x) r(x)))),equivalent first-order sentencex(p(x) x = a) x(q(x) x = b) x(r(x) (p(x) q(x)))(2)(Ferraris et al., 2007, Example 3). stable models F first-order models (2).answer set F Herbrand model {p(a), q(b), r(a)}.According Ferraris et al. (2011), definition answer set, appliedsyntax logic programs, equivalent traditional definition answer setbased grounding fixpoints (Gelfond & Lifschitz, 1988).Note definition stable model general definitionanswer set following ways: stable models restricted Herbrand models,underlying signature arbitrary, intensional predicates fixedlist predicate constants occurring formula. last fact essential viewfollowing proposition. pr (F ) denote list predicate constants occurringF ; Choice(p) denote conjunction choice formulas x(p(x) p(x))predicate constants p p, x list distinct object variables; False(p)denote conjunction xp(x) predicate constants p p. sometimes identifylist corresponding set confusion.Proposition 1 FormulaSM[F ; p] SM[F Choice(pr (F )\p) False(p\pr (F ))](3)logically valid.Notice (implicit) intensional predicates right-hand side (3)(pr (F ) p). Choice formula makes predicates (pr (F ) \ p) exemptstability checking. hand, False formula makes predicates(p \ pr (F )) stabilized (i.e., empty extents), though occur F .575fiLee & PallaFerraris et al. (2011) incorporate strong negation stable model semanticsdistinguishing intensional predicates two kinds, positive negative.negative intensional predicate form p, p positive intensional predicatesymbol strong negation. Syntactically logical connective,appear part predicate constant. interpretation underlyingsignature coherent satisfies formulax(p(x) p(x)),(4)x list distinct object variables, negative predicate p. usuallyconsider coherent interpretations only. Intuitively, p(t) represents p(t) false.different p(t) represents known p(t) true. Similarly,p(t) represents known p(t) false, p(t) representsknown p(t) known true. Note that, unlike first-order logic, p(t)different p(t). instance, formula p(a) one answer set {p(a)} p(a)answer sets.Like extension circumscription many-sorted first-order sentences, definitionstable model straightforwardly extended many-sorted first-order sentences.2.3 Equivalence Stable Model Semantics CircumscriptionCanonical FormulasNeither stable model semantics circumscription stronger other.example,CIRC[x(p(x) p(x)); p](5)equivalent xp(x),SM[x(p(x) p(x)); p](6)equivalent >, (5) stronger (6). hand,CIRC[x(p(x) q(x)); p, q](7)equivalent x(p(x) q(x)),SM[x(p(x) q(x)); p, q](8)equivalent x(p(x) q(x)), (8) stronger (7).section, show two semantics coincide class formulas calledcanonical formulas, define below. first review notions positive, negative,strictly positive occurrences.Definition 1 say occurrence predicate constant, subexpression, formula F positive number implications containing occurrenceantecedent even, negative otherwise. (Recall treat G shorthandG .) say occurrence strictly positive number implications Fcontaining occurrence antecedent 0.576fiReformulating Situation Calculus Event Calculusexample, (1), occurrences q positive, first one strictlypositive.Definition 2 say formula F canonical relative list p predicate constantsoccurrence predicate constant p antecedents oneimplication F ,every occurrence predicate constant p scope strictly positiveoccurrence F strictly positive F .Example 1 formulax(p(x) q(x))(9)shown canonical relative {p, q} since satisfy first clausedefinition (p occurs antecedents two implications p(x) shorthandp(x) ). hand, formula canonical relative {q}. formulax(p(x) p(x))(10)canonical relative {p} since satisfy second clause (the second occurrence p scope strictly positive occurrence , strictly positive(10)); formulap(a) (x p(x) x q(x))(11)canonical relative {p, q},p(a, a) x(p(x, a) p(b, x))(12)canonical relative {p, q} since satisfy second clause (the secondoccurrence p scope strictly positive occurrence , strictlypositive formula (12)).following theorem states that, canonical formula, circumscription coincidesstable model semantics.Theorem 1 canonical formula F relative p,CIRC[F ; p] SM[F ; p](13)logically valid.instance, formula (11), canonical relative {p, q}, formulas CIRC[(11); p, q]SM[(11); p, q] equivalent other. Also, sentence F clearly canonicalrelative , CIRC[F ; ] equivalent SM[F ; ], turn equivalent F .hand, equivalence may necessarily hold non-canonical formulas.instance, observed that, formula (10) canonical relative {p}, formulas (5) (6) equivalent other. formula (9) canonical577fiLee & Pallarelative {p, q}, formulas (7) (8) equivalent other. also observeformula (12) canonical relative {p, q}, CIRC[(12); p, q] equivalentSM[(12); p, q]: Herbrand interpretation {p(a, a), p(b, a)} satisfies SM[(12); p, q],satisfy CIRC[(12); p, q].Note non-canonical formulas often equivalently rewritten canonical formulas. Since equivalent transformation preserves models circumscription, Theorem 1 applied non-canonical formulas, first rewriting canonicalformulas. example, formula (9) equivalentx(p(x) q(x)),(14)canonical relative {p, q}, CIRC[(9); p, q] equivalent SM[(14); p, q].another example, formula (10) equivalentx(p(x) p(x)),(15)canonical relative {p}, CIRC[(10); p] equivalent SM[(15); p].clear treatment applied quantifier-free formula (includingpropositional formula) quantifier-free formula equivalently rewrittencanonical formula first rewriting clausal normal form turningclause form C D, C conjunction atoms disjunctionatoms.3Sections 3 4 use Theorem 1 reformulate event calculus situationcalculus first-order stable model semantics.3. Reformulating Event Calculus General Theory StableModelssection, review syntax circumscriptive event calculus described Chapter 2book Mueller (2006). Based observation syntax conformscondition canonicality, present reformulations event calculus generaltheory stable models.3.1 Review: Circumscriptive Event Calculusassume many-sorted first-order language, contains event sort, fluent sort,timepoint sort. fluent term term whose sort fluent; event termtimepoint term defined similarly.Definition 3 condition defined recursively follows:1 2 terms, comparisons 1 < 2 , 1 2 , 1 2 , 1 > 2 , 1 = 2 ,1 6= 2 conditions;3. appears unlikely knowledge encoded non-canonical formula (12)cannot easily turned equivalent canonical formula. c.f. Guide Axiomatizing DomainsFirst-Order Logic (http://cs.nyu.edu/faculty/davise/guide.html). surprisecircumscriptive action theories mentioned paper satisfy canonicality assumption.578fiReformulating Situation Calculus Event Calculusf fluent term timepoint term, HoldsAt(f, t) HoldsAt(f, t)conditions;1 2 conditions, 1 2 1 2 conditions;v variable condition, v condition.use e ei denote event terms, f fi denote fluent terms, tidenote timepoint terms, denote conditions.event calculus, circumscribe Initiates, Terminates, Releases minimizeunexpected effects events, circumscribe Happens minimize unexpected events,circumscribe Ab (abnormality predicates) minimize abnormalities. Formally, eventcalculus description circumscriptive theory definedCIRC[ ; Initiates, Terminates, Releases] CIRC[ ; Happens]CIRC[ ; Ab 1 , . . . , Ab n ] ,(16)conjunction universal closures axioms formInitiates(e, f, t)Terminates(e, f, t)Releases(e, f, t)1 (e, f1 , t) 2 (e, f2 , t)(effect constraint)[]Happens(e1 , t) []Happens(en , t) Initiates(e, f, t)[]Happens(e1 , t) []Happens(en , t) Terminates(e, f, t),1 2 either Initiates Terminates ([] meansoptional);conjunction universal closures temporal ordering formulas (comparisonstimepoint terms) axioms formHappens(e, t)(f, t) 1 (f1 , t) n (fn , t) Happens(e, t)(causal constraints)Happens(e, t) Happens(e1 , t) Happens(en , t) (disjunctive event axiom),Started Stopped j (1 j n) either InitiatedTerminated ;conjunction universal closures cancellation axioms formAbi (..., t) ;conjunction first-order sentences (outside scope CIRC) including uniquename axioms, state constraints, event occurrence constraints, set domainindependent axioms event calculus, EC (for continuous event calculus) DEC (for discrete event calculus) (Mueller, 2006, Chapter 2). also579fiLee & Pallaincludes following definitions predicates used causal constraints :defStarted (f, t) (HoldsAt(f, t) e(Happens(e, t) Initiates(e, f, t)))(CC1 )defStopped (f, t) (HoldsAt(f, t) e(Happens(e, t) Terminates(e, f, t)))defInitiated (f, t) (Started (f, t) e(Happens(e, t) Terminates(e, f, t)))defTerminated (f, t) (Stopped (f, t) e(Happens(e, t) Initiates(e, f, t)))(CC2 )(CC3 )(CC4 ).Remark 1 following facts easy check:canonical relative {Initiates, Terminates, Releases};canonical relative {Happens};canonical relative {Ab 1 , . . . , Ab n }.facts used next section reformulate event calculus generaltheory stable models.3.2 Reformulating Event Calculus General Theory Stable ModelsFollowing Ferraris, Lee, Lifschitz, Palla (2009), formula F saynegative list p predicate constants members p strictly positiveoccurrences F .4 example, formula (9) negative {p}, negative {p, q}.formula form F (shorthand F ) negative list predicates.assume already equivalently rewritten negative {Initiates,Terminates, Releases, Happens, Ab 1 , . . . , Ab n }. easily done prependingstrictly positive occurrences predicates. following theorem showsequivalent reformulations circumscriptive event calculus general theory stablemodels.Theorem 2 event calculus description (16), following theories equivalentother:5(a) CIRC[; I, T, R] CIRC[; H] CIRC[; Ab 1 , . . . , Ab n ] ;(b) SM[; I, T, R] SM[; H] SM[; Ab 1 , . . . , Ab n ] ;(c) SM[ ; I, T, R, H, Ab 1 , . . . , Ab n ] ;(d) SM[ Choice(pr ( ) \ {I, T, R, H, Ab 1 , . . . , Ab n })] .equivalence (a) (b) immediate Theorem 1. equivalence(b) (c) shown using splitting theorem Ferraris et al. (2009).assumption negative intensional predicates essential showing4. Note distinguish formula negative (on p) occurrence negative(Section 2.3).5. brevity, abbreviate names circumscribed predicates.580fiReformulating Situation Calculus Event Calculusequivalence (For details, see proof Appendix C.4.). equivalence(c) (d) follows Proposition 1 since{I, T, R, H, Ab 1 , . . . , Ab n } \ pr ( )empty set.64. Reformulating Situation Calculus General Theory StableModelssection, review reformulate two versions situation calculusLinscausal action theories (1995) Reiters basic action theories (2001).4.1 Review: Lins Causal Action Theoriesassume many-sorted first-order language contains situation sort, actionsort, fluent sort, truth value sort object sort. understand expression P (x, s),P fluent name, shorthand Holds(P (x), s). consider functionalfluents simplicity.According Lin (1995), formula (s) called simple state formula (s)mention Poss, Caused situation term possibly variable s.assume causal action theory consists finite number followingsets axioms. often identify conjunction universal closuresaxioms D. following, F , Fi fluent names, action name, V , Vi truthvalues, s, s0 situation variables, (s) simple state formula s, symbols a, a0action variables, f variable sort fluent, v variable sort truth value, x,xi , y, yi lists variables.Dcaused conjunction axioms formPoss(A(x), s) ((s) Caused (F (y), V, do(A(x), s))(direct effect axioms),(s) Caused (F1 (x1 ), V1 , s) Caused (Fn (xn ), Vn , s) Caused (F (x), V, s)(indirect effect axioms).Dposs conjunction precondition axioms formPoss(A(x), s) (s).(17)Drest conjunction following axioms:basic axioms:Caused (f, true, s) Holds(f, s),Caused (f, false, s) Holds(f, s),true 6= false v(v = true v = false).6. I, , R, H occur domain independent axioms part .581(18)fiLee & Pallaunique name assumptions fluent names:Fi (x) 6= Fj (y), (i 6= j)Fi (x) = Fi (y) x = y.(19)Similarly action names.foundational axioms discrete situation calculus:76= do(a, s),0000do(a, s) = do(a , ) (a = = ),p p(S0 ) a, p(s) p(do(a, s)) p(s) .(20)(21)(22)frame axiom:Poss(a, s) (vCaused (f, v, do(a, s))(Holds(f, do(a, s)) Holds(f, s))).Axioms domain knowledge: (s).causal action theory definedCIRC[Dcaused ; Caused ] Dposs Drest .(23)Remark 2 easy check Dcaused canonical relative Caused .fact used next section reformulate causal action theories generaltheory stable models.4.2 Reformulating Causal Action Theories General Theory StableModelsLet Dposs conjunction axioms (s) Poss(A(x), s) axiom (17) Dposs .Instead second-order axiom (22), consider following first-order formula Dsit ,introduces new intensional predicate constant Sit whose argument sort situation.8Sit(S0 ) a, s(Sit(s) Sit(do(a, s))) sSit(s).(24)following, Dresttheory obtained Drest dropping (22).Theorem 3 Given causal action theory (23), following theories equivalentdisregard auxiliary predicate Sit:(a) CIRC[Dcaused ; Caused ] Dposs Drest ;(b) SM[Dcaused ; Caused ] Dposs DrestSM[Dsit ; Sit] ;(c) SM[Dcaused ; Caused ] SM[Dposs ; Poss] DrestSM[Dsit ; Sit] ;(d) SM[Dcaused Dposs DrestDsit ; Caused , Poss, Sit] .7. simplicity omit two axioms regarding partial-order among situations.8. Suggested Vladimir Lifschitz (personal communication).582fiReformulating Situation Calculus Event Calculus4.3 Review: Reiters Basic Action Theoriescausal action theories, understand P (x, s), P fluent name, shorthandHolds(P (x), s), consider functional fluents.basic action theory (BAT) formDss Dap Duna DS0 ,(25)conjunction foundational axioms (Section 4.1);Dss conjunction successor state axioms formF (x, do(a, s)) F (x, a, s),F (x, a, s) formula uniformamong x, a, s;9whose free variablesDap conjunction action precondition axioms formPoss(A(x), s) (x, s),(x, s) formula uniform whose free variables among x, s;Duna conjunction unique name axioms fluents actions;DS0 conjunction first-order formulas uniform S0 .4.4 Reformulating Basic Action Theories General Theory StableModelsNote BAT theory first-order logic.10 view fact first-orderlogic sentence F equivalent SM[F ; ], trivial view BAT first-order theorystable model semantics list intensional predicates empty.rest section, consider alternative encoding BAT ASP,need provide explicit successor state axioms Dss . Instead, successor stateaxioms entailed effect axioms generic inertia axioms adopted ASPmaking intensional positive predicate Holds negative predicate Holds(Recall definitions positive negative predicates Section 2.2). followingassume underlying signature contains predicates.ASP-style BAT formDeffect Dprecond Dinertia Dexogenous0 Duna DS0 ,, Duna DS0 defined before;9. refer reader book Reiter (2001) definition uniform formula.10. simplicity disregard second-order axiom (22).583(26)fiLee & PallaDeffect conjunction axioms form+R(x, a, s) Holds(R(x), do(a, s))(27)R(x, a, s) Holds(R(x), do(a, s)),(28)+R(x, a, s)R(x, a, s)variables among x, s;formulas uniform whose freeDprecond conjunction axioms form(x, s) Poss(A(x), s),(29)(x, s) formula uniform whose free variables among x, s;Dinertia conjunction axiomsHolds(R(x), s) Holds(R(x), do(a, s)) Holds(R(x), do(a, s)),Holds(R(x), s) Holds(R(x), do(a, s)) Holds(R(x), do(a, s))fluent names R;Dexogenous0 conjunctionHolds(R(x), S0 ) Holds(R(x), S0 )fluent names R.Note axioms Dinertia typically used answer set programming representcommon sense law inertia (Lifschitz & Turner, 1999). Similarly, Dexogenous0 usedrepresent initial value fluent arbitrary.11show ASP-style BAT related Reiters BAT. First, since usestrong negation, convenient define following notions. Given signatureBAT, Holds signature obtained adding Holds . sayinterpretation Holds complete Holds satisfiesy(Holds(y) Holds(y)),list distinct variables. Given interpretation Holds , expression I|denotes projection .Let Dss conjunction successor state axiomsHolds(R(x), do(a, s)) +R (x, a, s) (Holds(R(x), s) R (x, a, s)),++R (x, a, s) disjunction R (x, a, s) axioms (27) Deffect , R (x, a, s)disjunction R (x, a, s) axioms (28) Deffect . Dap denote conjunction axioms Poss(A(x), s) (x, s), (x, s) disjunction (x, s)axioms (29) Dprecond .11. axioms Dinertia Dexogenous0 also closely related translation C+ nonmonotoniccausal logic (Giunchiglia, Lee, Lifschitz, McCain, & Turner, 2004).584fiReformulating Situation Calculus Event CalculusTheorem 4 Let theory (26) signature Holds , coherent interpretationHolds complete Holds. satisfiesx s(+R (x, a, s) R (x, a, s))every fluent name R, satisfiesSM[T ; Poss, Holds, Holds]iff I| satisfies BATDss Dap Duna DS0 .5. Translating Almost Universal Sentences Logic ProgramsTheorems 24 present reformulations situation calculus event calculusgeneral theory stable models, may contain nested quantifiers connectives.hand, input languages ASP solvers limited simple rule forms,analogous clausal normal form classical logic. Although first-order formularewritten clausal normal form preserving satisfiability, transformationsnecessarily preserve stable models. due fact notion equivalencestronger stable model semantics (Lifschitz, Pearce, & Valverde, 2001).Definition 4 (Ferraris et al., 2011) formula F strongly equivalent formula G if,formula H containing F subformula (and possibly containing object, functionpredicate constants occur F , G), list p distinct predicateconstants, SM[H; p] equivalent SM[H 0 ; p], H 0 obtained H replacingoccurrence F G.words, replacing subformula another strongly equivalent subformulachange stable models whole formula. strongly equivalent theoriesclassically equivalent (i.e., equivalent classical logic), converse hold.Consequently, classically equivalent transformations necessarily preserve stable models. instance, consider p p. p intensional, former stable modelslatter not.known every propositional formula rewritten logic program (Cabalar& Ferraris, 2007; Cabalar, Pearce, & Valverde, 2005; Lee & Palla, 2007), translations extended quantifier-free formulas straightforward way (Section 5.1).However, method work presence arbitrary quantifiers,target formalism (logic programs), variables implicitly universally quantified.section, present translation turns certain class sentences calledalmost universal sentences logic programs preserving stable models. turnsreformulations situation calculus event calculus Sections 34 belong class almost universal sentences, use ASP solverscomputing them.585fiLee & Palla5.1 Translating Quantifier-Free Formulas Logic ProgramsCabalar et al. (2005) define following transformation turns propositional formula stable model semantics logic program.Left side rules:>F G7{F G}(L1)F G7(L2)F G H7(L3)(F G) H K7(F G) H K7{G F H}F H KGH KF H KGH KH F G KF G7{F G}(R1)F >G7(R2)F G H7(R3)F (G H) K7F (G H) K7{G F H}F GKF H KGF H KH F G K(L4)(L5)Right side rules:(R4)(R5)applying transformation formula lefthand side, assumeformula already written negation normal form, negation appliedliterals only, using following transformation:Negation normal form conversion:>F(F G)(F G)(F G)777777>FF GF GF GAccording Cabalar et al. (2005), successive application rewriting rulesturn propositional formula disjunctive logic program. result simplyextended turn quantifier-free formula logic program.noted Cabalar et al. (2005), translation may involve exponential blowupsize, Theorem 1 paper shows indeed vocabulary-preservingpolynomial time algorithm convert general propositional theories stable modelsemantics disjunctive logic programs. Alternatively, one use another translationpaper, linear size involves auxiliary atomscomplex.586fiReformulating Situation Calculus Event Calculus5.2 Quantifier Eliminationintroduce quantifier elimination method distinguishes two kinds occurrences quantifiers: singular non-singular. non-singular occurrencequantifier easy eliminate, singular occurrence eliminated certainsyntactic condition.Definition 5 say occurrence QxG F singularQ , occurrence QxG positive F ,Q , occurrence QxG negative F .example, occurrence x q(x) singular (11), occurrence x p(x)not.Non-singular occurrences quantifiers eliminated view fact everyfirst-order sentence rewritten prenex form. prenex form conversion rules givenSection 6.3.1 Pearce Valverde (2005) preserve strong equivalence, leadsfollowing theorem.12Theorem 5 (Lee & Palla, 2007, Proposition 5) Every first-order formula stronglyequivalent formula prenex form.prenex form conversion turns non-singular occurrence quantifieroutermost preserving strong equivalence. Consequently, sentence containssingular occurrence quantifier, results used turn sentenceuniversal sentence set ASP rules. However, presencesingular occurrence quantifier, prenex form conversion turns occurrenceoutermost , allowed logic programs. consider handleoccurrences.Obviously, Herbrand universe finite, interested Herbrand stablemodels (i.e., answer sets) only, quantified formulas rewritten multiple disjunctionsconjunctions. even need consider turning formula prenex form.example, formular x(p(x) q(x))(30)occurring theory whose signature contains {1, . . . , n} object constants (andfunction constants), replace x(p(x) q(x)) multiple disjunctionsturn resulting program nested expressions usual disjunctive program(Lifschitz, Tang, & Turner, 1999), 2n rules generated. instance, n = 3,12. Pearce Valverde (2005) show sentence QNc5 , monotonic basis Quantified EquilibriumLogic, turned prenex form, result follows.587fiLee & Pallaresulting logic programr,r,r,r,r,r,r,r,p(1),p(1),p(1),p(1),q(1),q(1),q(1),q(1),p(2),p(2),q(2),q(2),p(2),p(2),q(2),q(2),p(3)q(3)p(3)q(3)p(3)q(3)p(3)q(3).Also, translation modular depends underlying domain; multipledisjunctions conjunctions need updated domain changes. importantly, method applicable theory contains function constants positivearity, Herbrand universe infinite.One may also consider introducing Skolem constants first-order logic, presumingthat, sentence F Skolem form F 0 , SM[F ; p] satisfiable iff SM[F 0 ; p]satisfiable. However, idea work.13Example 2 formulaF = (x p(x) q) x(q p(x)),SM[F ; q] equivalent first-order sentence(q x p(x)) x(q p(x)),unsatisfiable (the equivalence established using Theorems 3 11 Ferraris et al., 2011). Formula F strongly equivalent prenex formxy (p(x) q) (q p(y)) ,(31)However, introduce new object constants b replace existentially quantifiedvariablesF 0 = (p(a) q) (q p(b)),formula SM[F 0 ; q] equivalent(q p(a)) (q p(b)),satisfiable.present method eliminating singular occurrences quantifiers introducing auxiliary predicates. idea generalization practice logic programming13. Pearce Valverde (2005) show Skolemization works QNc5 , monotonic basis Quantified Equilibrium Logic, example shows, imply Skolemization worksQuantified Equilibrium Logic.588fiReformulating Situation Calculus Event Calculussimulates negated existential quantification body rule introducing auxiliary predicates. instance, order eliminate (30), introduce newpredicate constant p0 , turn (30)(r p0 s) x(p(x) q(x) p0 ),(32)corresponds logic programr, p0p0 p(x), q(x).(33)models SM[(30); p, q, r, s] stable models (33) disregardp0 . method involve grounding, translation dependdomain restricted Herbrand models. method formally justifiedfollowing proposition.Recall formula H negative p members p strictly positiveoccurrences H. Given formula F , say occurrence subformula Gp-negated F contained subformula H F negative p.Proposition 2 Let F sentence, let p finite list distinct predicate constants,let q new predicate constant occur F . Consider non-strictlypositive, p-negated occurrence yG(y, x) F , x list free variablesyG(y, x). Let F 0 formula obtained F replacing occurrence yG(y, x)q(x).SM[F ; p] x(q(x) yG(y, x))equivalentSM[F 0 xy(G(y, x) q(x)); p, q].Proposition 2 tells us SM[F ; p] SM[F 0 xy(G(y, x) q(x); p, q]models disregard new predicate constant q. Notice F 0 retainoccurrence y.Example 3 formula (30), x(p(x) q(x)) contained negative formula (relativeset intensional predicates). accordance Proposition 2, SM[(30); p, q, r, s]models SM[(32); p, q, r, s, p0 ] disregard p0 .singular, p-negated occurrence subformula yG(y, x) also eliminatedusing Proposition 2 first rewriting yG(y, x) yG(y, x). Note yG(y, x)strongly equivalent yG(y, x), general classically equivalent transformation may necessarily preserve stable models. However, Theorem DoubleNegations (Ferraris et al., 2009, also reviewed Appendix C) tells us transformation ensured preserve p-stable models replaced occurrence p-negatedgiven formula.ready present quantifier elimination method, appliesclass almost universal formulas.589fiLee & PallaDefinition 6 say formula F almost universal relative p every singularoccurrence QxG F p-negated F .example, formula (30) almost universal relative set predicatessingular occurrence x(p(x) q(x)) (30) contained x(p(x) q(x)),negative list predicates. Formula F Example 2 almost universal relative{q} singular occurrence x p(x) contained formula itself,negative {q}, singular occurrence x(q p(x)) contained x(q p(x)),also negative {q}.following procedure used eliminate (possibly nested) quantifiersalmost universal sentence.Definition 7 (Translation elim-quantifiers) Given formula F , first prependevery maximal strictly positive occurrence formula form yH(y, x),14repeat following process occurrences quantifiers remaining: Selectmaximal occurrence formula form QyG(y, x) F , Q , xlist free variables QyG(y, x).(a) occurrence QyG(y, x) F non-singular F , set F formulaobtained F replacing occurrence QyG(y, x) G(z, x), znew variable.(b) Otherwise, Q occurrence QyG(y, x) F positive, set FF 0 (G(y, x) pG (x)),pG new predicate constant F 0 formula obtained F replacing occurrence QyG(y, x) pG (x).(c) Otherwise, Q occurrence QyG(y, x) F negative, set Fformula obtained F replacing occurrence QyG(y, x)yG(y, x).assume new predicate constants introduced translation belongsignature input formula F . clear process terminates, yieldsformula quantifier-free. Since number times step (b) appliednumber quantifiers input formula, new formulas addedsize polynomial input formula, follows size resulting quantifier-freeformula polynomial size input formula.following theorem tells us almost universal sentence F turnedform xG, G quantifier-free formula. (second-order) sentences FG signature subset signature, say F -equivalentG, denoted F G, class models F restricted identical classmodels G restricted .14. maximality understood terms subformula relation. is, select strictly positiveoccurrence subformula F form yH(y, x) contained subformulaF form.590fiReformulating Situation Calculus Event CalculusTheorem 6 Let F sentence signature , let F 0 universal closureformula obtained F applying translation elim-quantifiers, let q listnew predicate constants introduced translation. F almost universal relativep, SM[F ; p] -equivalent SM[F 0 ; p, q].statement theorem becomes incorrect require F almostuniversal relative p. instance, elim-quantifiers applied x p(x), resultsq (p(x) q). However, SM[x p(x); p] {p}-equivalentSM[x(q (p(x) q)); p, q]. former equivalent saying p singleton.latter equivalent q xp(x) (q xp(x)), inconsistent.5.3 f2lp: Computing Answer Sets First-Order FormulasUsing translation elim-quantifiers defined previous section, introduce translation f2lp turns almost universal formula logic program. assumeunderlying signature contains finitely many predicate constants.Definition 8 (Translation f2lp)1. Given formula F list intensional predicates p, apply translation elim-quantifiers (Definition 7) F ;2. Add choice formulas (q(x) q(x)) non-intensional predicates q.3. Turn resulting quantifier-free formula logic program applying translation Section 3 paper Cabalar et al. (2005), also reviewedSection 5.1.explained Section 5.1, due third step, transformation may involveexponential blowup size. One obtain polynomial translation replacing Step 3alternative translation given Section 4 paper Cabalar et al.following theorem asserts correctness translation.Theorem 7 Let F sentence signature , let p list intensional predicates,let F 0 FOL representation program obtained F applying translationf2lp p intensional predicates. F almost universal relative p, SM[F ; p]-equivalentSM[F 0 False(p \ pr (F 0 ))].Example 4 Consider one domain independent axioms discrete event calculus(DEC5 axiom):HoldsAt(f, t) ReleasedAt(f, t+1)e(Happens(e, t) Terminates(e, f, t)) HoldsAt(f, t+1).Step 1 translation f2lp introduces formulaHappens(e, t) Terminates(e, f, t) q(f, t),replaces (34)HoldsAt(f, t) ReleasedAt(f, t+1) q(f, t) HoldsAt(f, t+1).591(34)fiLee & PallaStep 3 turns formulas rulesq(f, t) Happens(e, t), Terminates(e, f, t)HoldsAt(f, t+1) HoldsAt(f, t), ReleasedAt(f, t+1), q(f, t).Turning program obtained applying translation f2lp input languageslparse 15 gringo 16 requires minor rewriting, moving equality negatedatoms head body 17 adding domain predicates body variablesoccurring rule order reduce many-sorted signature non-sorted one.18System f2lp implementation translation f2lp, turns first-order formulalanguages lparse gringo. system downloaded homepagehttp://reasoning.eas.asu.edu/f2lp .First-order formulas encoded f2lp using extended rule form F G,F G first-order formulas contain . ASCII representationquantifiers connectives shown following table.SymbolASCII-&|<-false>truexyz![X,Y,Z]:xyz?[X,Y,Z]:example, formula (34) encoded input language f2lpholdsAt(F,T+1) <- holdsAt(F,T) & releasedAt(F,T+1) &?[E]:(happens(E,T) & terminates(E,F,T)).usual lparse gringo rules (which rule arrow :-) also allowedf2lp. rules simply copied output. program returned f2lppassed ASP grounders solvers accept lparse gringo languages.6. Computing Event Calculus Using ASP SolversUsing translation f2lp, turn event calculus reformulation Section 3.2answer set programs. following procedure describes process.Definition 9 (Translation ec2asp)1. Given event calculus description (16), rewritedefinitional axioms formdefx(p(x) G)(35)x(G p(x)), G obtained G prependingoccurrences intensional predicates Initiates, Terminates, Releases, Happens,Ab 1 , . . . , Ab n . Also prepend strictly positive occurrences intensionalpredicates remaining axioms . Let 0 resulting formula obtained.15.16.17.18.http://www.tcs.hut.fi/Software/smodelshttp://potassco.sourceforge.netinstance, (X=Y) | -q(X,Y) :- p(X,Y) turned :- X!=Y, {not q(X,Y)}0, p(X,Y).Alternatively done declaring variables using #domain directive lparse gringolanguages.592fiReformulating Situation Calculus Event Calculus2. Apply translation f2lp 0 intensional predicates{Initiates, Terminates, Releases, Happens, Ab 1 , . . . , Ab n } p,p set predicate constants p (35) considered Step 1.following theorem states correctness translation.Theorem 8 Let event calculus description (16) signature contains finitelymany predicate constants, let F FOL representation program obtainedapplying translation ec2asp. -equivalent SM[F ].view theorem, system f2lp used compute event calculus descriptionssimple rewriting stated translation ec2asp.19 system used placedec reasoner many existing applications event calculus, robotics,security, video games, web service composition, listedhttp://decreasoner.sourceforge.net/csr/decapps.html .computational mechanism dec reasoner similar methodbased reduction event calculus reasoning propositional satisfiability usesefficient SAT solvers computation. However, method advantages.First, significantly faster due efficient grounding mechanisms implementedASP systems. evidenced experiments reported Appendix B.Second, f2lp allows us compute full version event calculus, assumingdomain given finite. hand, reduction implemented decreasoner based completion, weaker circumscription. makessystem unable handle recursive axioms disjunctive axioms, effect constraintsdisjunctive event axioms (Section 3.1). example, dec reasoner allowfollowing effect constraints describe indirect effects agents walkingobjects holding:HoldsAt(Holding(a, o), t) Initiates(e, InRoom(a, r), t)Initiates(e, InRoom(o, r), t)HoldsAt(Holding(a, o), t) Terminates(e, InRoom(a, r), t)Terminates(e, InRoom(o, r), t).(36)Third, enhance event calculus reasoning combining ASP rulesevent calculus description. words, event calculus viewed highlevel action formalism top ASP. illustrate using example workDogandag, Ferraris, Lifschitz (2004). 9 rooms 12 doors shownFigure 1. Initially robot Robby middle room doors closed.goal robot make rooms accessible other. Figure 2 (File robby)shows encoding problem language f2lp. Atom door(x, y) denotesdoor rooms x y; open(x, y) denotes event Robby opening door19. Kim, Lee, Palla (2009) presented prototype f2lp called ecasp tailored eventcalculus computation.593fiLee & PallaFigure 1: Robbys apartment 3 3 gridrooms x y; goto(x) denotes event Robby going room x; opened(x, y)denotes door x opened; inRoom(x) denotes Robbyroom x; accessible(x, y) denotes accessible x. Note rulesdefining relation accessible part event calculus axioms (Section 3.1).example illustrates advantage allowing ASP rules event calculus descriptions.minimal number steps solve given problem 11. findplan using combination f2lp, gringo (grounder) claspD (solver disjunctiveprograms) following way. 20$ f2lp dec robby | gringo -c maxstep=11 | claspDFile dec f2lp encoding domain independent axioms Discrete EventCalculus (The file listed Appendix A).21 following one plans found:happens(open(5,8),0) happens(open(5,2),1) happens(open(5,4),2)happens(goto(4),3) happens(open(4,1),4) happens(open(4,7),5)happens(goto(5),6) happens(open(5,6),7) happens(goto(6),8)happens(open(6,9),9) happens(open(6,3),10)7. Computing Situation Calculus Using ASP SolversUsing translation f2lp, turn situation calculus reformulations Sections 4.24.4 answer set programs.7.1 Representing Causal Action Theories Answer Set Programsfollowing theorem shows turn causal action theories answer set programs.Theorem 9 Let finite causal action theory (23) signature contains finitelymany predicate constants, let F FOL representation program obtainedapplying translation f2lpDcaused Dposs DrestDsit(37)intensional predicates {Caused , Poss, Sit}. -equivalent SM[F ].20. One use clingo instead gringo claspD output f2lp nondisjunctive program.21. file also available http://reasoning.eas.asu.edu/f2lp, along f2lp encodingsdomain independent axioms versions event calculus.594fiReformulating Situation Calculus Event Calculus% File robby% objectsstep(0..maxstep).astep(0..maxstep-1) :- maxstep > 0.room(1..9).% variables#domain step(T).#domain room(R).#domain room(R1).#domain room(R2).% positiondoor(R1,R2) <- R1door(R1,R2) <- R1door(R1,R2) <- R1door(R1,R2) <- R2doors>= 1 &>= 4 &>= 7 &< 10 &R2R2R2R2>=1 & R1 < 4 & R2 < 4 & R2 = R1+1.>= 4 & R1 < 7 & R2 < 7 & R2 = R1+1.>= 7 & R1 < 10 & R2 < 10 & R2 = R1+1.= R1+3.door(R1,R2) <- door(R2,R1).% fluentsfluent(opened(R,R1)) <- door(R1,R2).fluent(inRoom(R)).% F ranges fluents#domain fluent(F).% eventsevent(open(R,R1)) <- door(R,R1).event(goto(R)).% E E1 range events#domain event(E).#domain event(E1).% effect axiomsinitiates(open(R,R1),opened(R,R1),T).initiates(open(R,R1),opened(R1,R),T).initiates(goto(R2),inRoom(R2),T)<- holdsAt(opened(R1,R2),T) & holdsAt(inRoom(R1),T).terminates(E,inRoom(R1),T)<- holdsAt(inRoom(R1),T) & initiates(E,inRoom(R2),T).% action precondition axiomsholdsAt(inRoom(R1),T) <- happens(open(R1,R2),T).595fiLee & Palla% event occurrence constrainthappens(E1,T) <- happens(E,T) & E != E1.% state constraintholdsAt(inRoom(R2),T) <- holdsAt(inRoom(R1),T) & R1 != R2.% accessibilityaccessible(R,R1,T) <- holdsAt(opened(R,R1),T).accessible(R,R2,T) <- accessible(R,R1,T) & accessible(R1,R2,T).% initial stateholdsAt(opened(R1,R2),0).holdsAt(inRoom(5),0).% goal stateaccessible(R,R1,maxstep).% happens exempt minimization order find plan.{happens(E,T)} <- < maxstep.% fluents inertialreleasedAt(F,0).Figure 2: Robby f2lpSimilar computation event calculus Section 6, Herbrand stablemodels (37) computed using f2lp answer set solvers. input f2lpsimplified limit attention Herbrand models. drop axioms (18)(21)ensured Herbrand models. Also, order ensure finite grounding, insteadDsit , include following set rules situation input f2lp.nesting(0,s0).nesting(L+1,do(A,S)) <- nesting(L,S) & action(A) & L < maxdepth.situation(S) <- nesting(L,S).final(S) <- nesting(maxdepth,S).situation used generate finitely many situation terms whose depth maxdepth,value given option invoking gringo. Using splitting theorem(Section C.1), difficult check program containing rulesoccurrence predicate nesting rules occurrence predicate situation head rules, every answer set containsatoms situation(do(am , do(am1 , do(. . . , do(a1 , s0))))) possible sequences actionsa1 , . . . , = 0, . . . , maxdepth. Though program satisfy syntactic conditions, -restricted (Gebser, Schaub, & Thiele, 2007), -restricted (Syrjanen, 2004),finite domain programs (Calimeri, Cozza, Ianni, & Leone, 2008), answer set solversusually impose order ensure finite grounding, rules still finitely grounded596fiReformulating Situation Calculus Event Calculus% File: suitcasevalue(t).value(f).lock(l1).lock(l2).#domain value(V).#domain lock(X).fluent(up(X)).fluent(open).#domain fluent(F).action(flip(X)).#domain action(A).depth(0..maxdepth).#domain depth(L).% defining situation domainnesting(0,s0).nesting(L+1,do(A,S)) <- nesting(L,S) & L < maxdepth.situation(S) <- nesting(L,S).final(S) <- nesting(maxdepth,S).% basic axiomsh(F,S) <- situation(S) & caused(F,t,S).h(F,S) <- situation(S) & caused(F,f,S).% D_causedcaused(up(X),f,do(flip(X),S)) <situation(S) & final(S) & poss(flip(X),S) & h(up(X),S).caused(up(X),t,do(flip(X),S)) <situation(S) & final(S) & poss(flip(X),S) & h(up(X),S).caused(open,t,S) <- situation(S) & h(up(l1),S) & h(up(l2),S).% D_possposs(flip(X),S) <- situation(S).% frame axiomsh(F,do(A,S)) <h(F,S) & situation(S) & final(S) & poss(A,S)& ?[V]:caused(F,V,do(A,S)).h(F,do(A,S)) <not h(F,S) & situation(S) & final(S) & poss(A,S)& ?[V]:caused(F,V,do(A,S)).% h non-intensional.{h(F,S)} <- situation(S).Figure 3: Lins Suitcase language f2lp597fiLee & Pallagringo Version 3.x, check syntactic conditions.22 difficultsee program leads finite grounding since provide explicit upperlimit nesting depth function do.addition situation , use following program executable order representset executable situations (Reiter, 2001):executable(s0).executable(do(A,S)) <- executable(S) & poss(A,S) & final(S)& situation(S) & action(A).Figure 3 shows encoding Lins suitcase example (1995) language f2lp(h used represent Holds), describes suitcase two locks springloaded mechanism open suitcase locks up. exampleillustrates ramification problem handled causal action theories. Since fixdomain situations finite, require actions effective finalsituations. done introducing atom final(S).Consider simple temporal projection problem Lin (1995). Initially first locksecond lock up. happen first lock flipped? Intuitively,expect locks suitcase open. automate reasoningusing combination f2lp, gringo claspD. First, add executablefollowing rules theory Figure 3. order check theory entails flippingfirst lock executable, suitcase open action, encodenegation facts last rule.% initial situation<- h(up(l1),s0).h(up(l2),s0).% query<- executable(do(flip(l1),s0)) & h(open,do(flip(l1),s0)).check answer temporal projection problem running command:$ f2lp suitcase | gringo -c maxdepth=1 | claspDclaspD returns answer set expected.Now, consider simple planning problem opening suitcase locksinitially down. add executable following rules theory Figure 3.last rule encodes goal.% initial situation<- h(up(l1),s0).<- h(up(l2),s0).<- h(open,s0).% goal<- ?[S]: (executable(S) & h(open,S)).maxdepth 1, combined use f2lp, gringo claspD resultsanswer sets, maxdepth 2, finds unique answer set contains22. Similarly, system dlv-complex allows us turn finite domain checking (option -nofdcheck).system used conference paper (Lee & Palla, 2010) article based on.598fiReformulating Situation Calculus Event Calculush(open, do(flip(l2), do(flip(l1), s0))) h(open, do(flip(l1), do(flip(l2), s0))),encodes plan. words, single answer set encodes multiple plansdifferent branches situation tree, allows us combine informationdifferent branches one model. instance hypothetical reasoningelegantly handled situation calculus due branching time structure. Belleghem,Denecker, Schreye (1997) note linear time structure event calculuslimited handle hypothetical reasoning allowed situation calculus.7.2 Representing Basic Action Theories Answer Set ProgramsSince BAT (not including second-order axiom (22)) viewed first-ordertheory stable model semantics list intensional predicates empty,follows f2lp used turn logic program. before, focusASP-style BAT.Theorem 10 Let ASP-style BAT (26) signature contains finitely manypredicate constants, let F FOL representation program obtained applying translation f2lp intensional predicates {Holds, Holds, Poss}.SM[T ; Holds, Holds, Poss] -equivalent SM[F ; (F ) {Poss}].Figure 4 shows encoding broken object example discussed Reiter (1991).Consider simple projection problem determining object o, nextbomb b, broken bomb explodes. add executable following rulestheory Figure 4.% initial situationh(broken(o),s0) & h(fragile(o),s0) & h(nexto(b,o),s0).h(holding(p,o),s0) & h(exploded(b),s0).% query<- executable(do(explode(b),s0)) & h(broken(o),do(explode(b),s0)).command$ f2lp broken | gringo -c maxdepth=1 | claspDreturns answer set expected.8. Related WorkIdentifying syntactic class theories different semantics coincide importantunderstanding relationship them. known that, tight logic programstight first-order formulas, stable model semantics coincides completionsemantics (Fages, 1994; Erdem & Lifschitz, 2003; Ferraris et al., 2011). fact helps usunderstand relationship two semantics, led design answerset solver cmodels-1 23 computes answer sets using completion. Likewise classcanonical formulas introduced helps us understand relationshipstable model semantics circumscription. class canonical formulas largest23. http://www.cs.utexas.edu/users/tag/cmodels599fiLee & Palla% File: broken% domains situationsperson(p).object(o).bomb(b).#domain person(R).#domain object(Y).#domain bomb(B).fluent(holding(R,Y)).fluent(broken(Y)).fluent(nexto(B,Y)).fluent(exploded(B)).fluent(fragile(Y)).action(drop(R,Y)).action(explode(B)).action(repair(R,Y)).#domain fluent(F).#domain action(A).depth(0..maxdepth).#domain depth(L).% defining situation domainnesting(0,s0).nesting(L+1,do(A,S)) <- nesting(L,S) & L < maxdepth.situation(S) <- nesting(L,S).final(S) <- nesting(maxdepth,S).% Effect Axiomsh(broken(Y),do(drop(R,Y),S)) <- situation(S) & h(fragile(Y),S) & final(S).h(broken(Y),do(explode(B),S)) <- situation(S) & h(nexto(B,Y),S) & final(S).h(exploded(B),do(explode(B),S)) <- situation(S) & final(S).-h(broken(Y),do(repair(R,Y),S)) <- situation(S) & final(S).-h(holding(R,Y),do(drop(R,Y),S)) <- situation(S) & final(S).% Action precondition axiomsposs(drop(R,Y),S) <- h(holding(R,Y),S) & situation(S).poss(explode(B),S) <- situation(S) & h(exploded(B),S).poss(repair(R,Y),S) <- situation(S) & h(broken(Y),S).% inertial axiomsh(F,do(A,S)) <- h(F,S) & -h(F,do(A,S)) & situation(S) & final(S).-h(F,do(A,S)) <- -h(F,S) & h(F,do(A,S)) & situation(S) & final(S).% D_exogeneous_0h(F,s0) | -h(F,s0).% Consider interpretations complete Holds<- h(F,S) & -h(F,S) & situation(S).Figure 4: Broken object example language f2lp600fiReformulating Situation Calculus Event Calculussyntactic class first-order formulas identified far stable models coincidemodels circumscription. words, minimal model reasoning stablemodel reasoning indistinguishable canonical formulas.Proposition 8 work Lee Lin (2006) shows embedding propositional circumscription logic programs stable model semantics. theoremcanonical formulas generalization result first-order case. JanhunenOikarinen (2004) showed another embedding propositional circumscription logicprograms, implemented system circ2dlp,24 translation appears quitedifferent one Lee Lin.Zhang, Zhang, Ying, Zhou (2011) show embedding first-order circumscriptionfirst-order stable model semantics. Theorem 3 paper reproduced follows.25Theorem 11 (Zhang et al., 2011, Thm. 3) Let F formula negation normal formlet p finite list predicate constants. Let F formula obtained Freplacing every p(t) p(t), let F c formula obtained F replacingevery p(t) p(t) Choice(p), p p list terms. CIRC[F ; p]equivalent SM[F F c ; p].comparison Theorem 1, theorem applied characterize circumscription arbitrary formulas terms stable models first rewriting formulasnegation normal form. Theorem 1 applicable canonical formulas only,require transformation, characterization bidirectional sensealso viewed characterization stable models terms circumscription.Zhang et al. (2011) also introduce translation turns arbitrary first-order formulaslogic programs, work limited finite structures only. hand,translation f2lp (Definition 8) works almost universal formulas only,limited finite structures.situation calculus event calculus widely studied action formalisms,several papers compare relate (e.g., Belleghem, Denecker, &Schreye, 1995; Provetti, 1996; Belleghem et al., 1997; Kowalski & Sadri, 1997).Prolog provides natural implementation basic action theories since definitionalaxioms represented Prolog rules according Clarks theorem (Reiter, 2001,Chapter 5). Lloyd-Topor transformation used turn formulas Prolog rulessimilar translation f2lp, difference former preserves completionsemantics latter preserves stable model semantics.Lin Wang (1999) describe language used represent syntacticallyrestricted form Lins causal situation calculus, called clausal causal theories,allow quantifiers. show translate language answer set programsstrong negation, answer sets used obtain fully instantiatedsuccessor state axioms action precondition axioms. quite differentapproach, computes propositional models full situation calculus theoriesdirectly.Kautz Selman (1992) introduce linear encodings similar propositionalized version situation calculus (McCarthy & Hayes, 1969). Lin (2003) introduces24. http://www.tcs.hut.fi/Software/circ2dlp25. bit simpler original statement redundancy dropped.601fiLee & Pallaaction description language describes procedure compile action domainlanguage complete set successor state axioms, STRIPS-likedescription extracted. soundness procedure shown respecttranslation action domain descriptions Lins causal action theories. However,procedure based completion cannot handle recursive axioms unlikeapproach.Denecker Ternovska (2007) present inductive variant situation calculusrepresented ID-logic (Denecker & Ternovska, 2008)classical logic extended inductive definitions. ID-logic first-order stable model semantics appear closelyrelated, precise relationship yet shown.9. Conclusionfirst-order stable model semantics defined similar circumscription. papertakes advantage definition identify class formulas minimal modelreasoning stable model reasoning coincide, uses idea reformulate situation calculus event calculus first-order stable model semantics. Togethertranslation turns almost universal sentence logic program, showreasoning situation calculus event calculus reduced computinganswer sets. implemented system f2lp, front-end ASP solvers allows uscompute circumscriptive action theories. mathematical tool sets system presented paper may also useful relating circumscriptive theorieslogic programs. Also, advances ASP solvers may improve computationcircumscriptive theories.Acknowledgmentsgrateful Yuliya Lierler, Vladimir Lifschitz, Erik Mueller, Heng Zhang, Yan Zhang,anonymous referees useful comments discussions. authorspartially supported National Science Foundation Grant IIS-0916116.Appendix A. File dec Language f2lpFile dec encodes domain independent axioms discrete event calculus. fileused together event calculus domain descriptions shown Section 6.% File dec#domain#domain#domain#domain#domain#domain#domainfluent(F).fluent(F1).fluent(F2).event(E).time(T).time(T1).time(T2).time(0..maxstep).602fiReformulating Situation Calculus Event Calculus% DEC 1stoppedIn(T1,F,T2) <- happens(E,T) & T1<T & T<T2 & terminates(E,F,T).% DEC 2startedIn(T1,F,T2) <- happens(E,T) & T1<T & T<T2 & initiates(E,F,T).% DEC 3holdsAt(F2,T1+T2) <- happens(E,T1) & initiates(E,F1,T1) & T2>0 &trajectory(F1,T1,F2,T2) & stoppedIn(T1,F1,T1+T2) & T1+T2<=maxstep.% DEC 4holdsAt(F2,T1+T2) <- happens(E,T1) & terminates(E,F1,T1) & 0<T2 &antiTrajectory(F1,T1,F2,T2) & startedIn(T1,F1,T1+T2) &T1+T2<=maxstep.% DEC 5holdsAt(F,T+1) <- holdsAt(F,T) & releasedAt(F,T+1) &?[E]:(happens(E,T) & terminates(E,F,T)) & T<maxstep.% DEC 6holdsAt(F,T+1) <- holdsAt(F,T) & releasedAt(F,T+1) &?[E]:(happens(E,T) & initiates(E,F,T)) & T<maxstep.% DEC 7releasedAt(F,T+1) <releasedAt(F,T) & ?[E]:(happens(E,T) &(initiates(E,F,T) | terminates(E,F,T))) & T<maxstep.% DEC 8releasedAt(F,T+1) <- releasedAt(F,T) &?[E]: (happens(E,T) & releases(E,F,T)) & T<maxstep.% DEC 9holdsAt(F,T+1) <- happens(E,T) & initiates(E,F,T) & T<maxstep.% DEC 10holdsAt(F,T+1) <- happens(E,T) & terminates(E,F,T) & T<maxstep.% DEC 11releasedAt(F,T+1) <- happens(E,T) & releases(E,F,T) & T<maxstep.% DEC 12releasedAt(F,T+1) <- happens(E,T) &(initiates(E,F,T) | terminates(E,F,T)) & T<maxstep.{holdsAt(F,T)}.{releasedAt(F,T)}.603fiLee & PallaProblem(max. step)decreasonerdecreasoner (minisat)f2lplparse + cmodelsf2lpgringo + cmodelsf2lpgringo + clasp(D)f2lpclingoBusRide(15)0.2s(0.07s + 0.13s)A:13174/R:246870.14sKitchenSink (25)39.0s(38.9s + 0.1s)A:1014/C:1210938.9s(38.9s + 0.00s)A:1014/C:121090.24s(0.18s + 0.06s)A:11970/R:619320.20sThielscherCircuit (40)6.5s(6.3s + 0.2s)A:1394/C:424546.3s(6.3s + 0.0s)A:1394/C:424540.12s(0.09s + 0.03s)A:4899/R:355450.1sWalkingTurkey (15)0.00s(0.00s + 0.00s)A:316/R:4560.00sFalling w/AntiTraj (15)141.8s(141.4s + 0.4s)A:416/C:3056141.7s(141.7s + 0.00s)A:416/C:30560.03s(0.03s + 0.00s)A:3702/R:74140.03sFalling w/Events (25)59.5s(59.5s + 0.0s)A:1092/C:1235159.4s(59.4s + 0.0s)A:1092/C:123510.28s(0.20s + 0.08s)A:13829/R:712660.22sHotAirBaloon (15)32.2s(32.2s + 0.0s)A:288/C:116332.3s(32.3s + 0.0s)A:288/C:11630.0s(0.0s + 0.0s)A:1063/R:18350.01sTelephone1(40)9.3s(9.2s + 0.1s)A:5419/C:415909.1s(9.1s + 0.0s)A:5419/C:415900.00s(0.00s + 0.00s)A:355/R:555C:00.15s(0.07s + 0.08s)A:5269/R:24687C:53080.44s(0.19s + 0.25s)A:11970/R:61932C:00.19s(0.09s + 0.1s)A:4899/R:35545C:00.00s(0.00s + 0.00s)A:316/R:456C:00.04s(0.02s + 0.02s)A:3702/R:7414C:00.46s(0.20s + 0.26s)A:1219/R:71266C:14150.0s(0.0s + 0.0s)A:492/R:1835C:6810.11s(0.08s + 0.03s)A:9455/R:13140C:00.01s(0.00s + 0.01s)A:448/R:647Commuter(15)0.04s(0.03s + 0.01s)A:902/R:7779C:077.29s(45.74s + 31.55s)A:32861/R:8734019C:06.19s(2.99s + 3.20s)A:121621/R:480187C:00.42s(0.27s + 0.15s)A:9292/R:53719C:00.00s(0.00s + 0.00s)A:370/R:518C:00.08s(0.05s + 0.03s)A:4994/R:9717C:04.95s(2.57s + 2.38s)A:1240/R:388282C:14360.01s(0.01s + 0.00s)A:494/R:2451C:6890.22s(0.13s + 0.09s)A:21414/R:27277C:00.07s(0.06s + 0.01s)A:9455/R:131400.07sA: number atoms, C: number clauses, R: number ground rulesFigure 5: Comparing dec reasoner f2lp answer set solversAppendix B. Comparing dec Reasoner ASP-based EventCalculus Reasonercompared performance dec reasoner (v 1.0) running relsat (v 2.2)minisat (v 2.2) following:f2lp (v 1.11) lparse (v 1.0.17)+cmodels (v 3.79) running minisat (v 2.0beta),f2lp (v 1.11) gringo (v 3.0.3)+cmodels (v 3.79) running minisat (v 2.0 beta),f2lp (v 1.11) gringo (v 3.0.3) +clasp (v 2.0.2) (claspD (v 1.1.2) used insteaddisjunctive programs),f2lp (v 1.11) clingo (v 3.0.3 (clasp v 1.3.5)).f2lp turns input theory languages lparse gringo, lparsegringo turn result ground ASP program. cmodels turns ground programset clauses invokes SAT solver compute answer sets, claspcomputes answer sets using techniques similar used SAT solvers. clingosystem combines gringo clasp monolithic way.first five examples Figure 5 part benchmark problems workShanahan (1997, 1999). next four Mueller (2006). (We increased timepoints604fiReformulating Situation Calculus Event CalculusProblem(max. step)ZooTest1(16)f2lpgringo + cmodels50.48s(6.66s + 43.82s)A:930483/R:2272288C:3615955ZooTest2> 2h159.51s(22)(12.36s + 147.15s)A:2241512/R:4153670C:8864228ZooTest3> 2h142.68s(23)(13.55s + 129.13s)A:2505940/R:4556928C:9914568A: number atoms, C: number clauses, R: numberdecreasoner (minisat)> 2hf2lpgringo + clasp29.01s(6.66s + 22.35s)A:153432/R:2271175210.55s(12.36s + 198.19s)A:219220/R:4152137196.63s(13.55s + 183.08s)A:230731/R:4555325ground rulesFigure 6: Zoo World dec reasoner ASPsee notable differences.) examples found f2lp homepage.experiments done Pentium machine 3.06 GHz CPU 4GB RAM running64 bit Linux. reported run times seconds obtained using Linuxtime command (user time + sys time), except dec reasoner recordedtimes reported system. fair comparisons order avoid includingtime spent dec reasoner producing output neat format, sometimestakes non-negligible time. dec reasoner, times parentheses (SAT encoding time + SAT solving time). others, times spentgrounder solver. cmodels time includes time spent converting groundprogram generated lparse/gringo set clauses, calling SAT solver.time spent f2lp translating event calculus description answer setprogram (retaining variables) negligible problems. denotes systemcannot solve example due limited expressivity. instance, BusRide includesdisjunctive event axioms, results disjunctive program cannot handledclingo. Similarly, dec reasoner cannot handle BusRide (disjunctive event axioms),Commuter (compound events) Walking Turkey (effect constraints). evidentexperiments, main reason efficiency ASP-based approach efficient grounding mechanisms implemented ASP grounders. Though dec reasonercmodels call SAT solver minisat, number atoms processed decreasoner general much smaller. dec reasoner adopts optimizedencoding method (that based predicate completion) avoids large numberground instances atoms Initiates(e, f, t), Terminates(e, f, t), Releases(e, f, t)(Mueller, 2004, Section 4.4). hand, several examples, number clausesgenerated cmodels 0, means answer sets found without callingSAT solver. examples unique answer set coincideswell-founded model, efficiently computed cmodels preprocessing stepcalling SAT solvers. 14 benchmark examples Shanahan (1997, 1999),10 belong case lparse used grounding.605fiLee & Pallaexperiments Figure 5, solving times negligible problems. also experimented computationally hard problems, solving takestime grounding. Figure 6 shows runs medium-size action domain, ZooWorld (Akman, Erdogan, Lee, Lifschitz, & Turner, 2004). tests shown tableplanning problems max. step length minimal plan. cut-off time2 hours dec reasoner terminate within time problems. fact, entire time spent SAT encoding SAT solver nevercalled. hand, ASP grounder gringo took seconds grounddomain and, unlike Figure 5, solvers took much time grounder.see, cmodels minisat performed better clasp two problems.check time taken minisat encoding generated dec reasoner,ran ZooTest1 completion. dec reasoner terminated 116578.1 seconds (32.38hours).Appendix C. ProofsC.1 Review Useful Theoremsreview theorems Ferraris et al. (2011) Ferraris et al. (2009)used prove main results. fact, provide version splitting theoremslightly general one given Ferraris et al. (2009), orderfacilitate proof efforts.Lemma 1 Formulau p ((F ) (u) F )logically valid.Theorem 12 (Ferraris et al., 2011, Thm. 2) first-order formula Fdisjoint lists p, q distinct predicate constants,SM[F ; p] SM[F Choice(q); p q]logically valid.Let F first-order formula. rule F implication occurs strictly positivelyF . predicate dependency graph F (relative p) directed graphmembers p vertices,edge p q if, rule G H F ,p strictly positive occurrence H,q positive occurrence G belong subformula Gnegative p.Theorem 13 (Ferraris et al., 2009, Splitting Thm.) Let F , G first-order sentences,let p, q finite disjoint lists distinct predicate constants.606fiReformulating Situation Calculus Event Calculus(a) strongly connected component predicate dependency graph F G relativep, q either subset p subset q,(b) F negative q,(c) G negative pSM[F G; p q] SM[F ; p] SM[G; q]logically valid.theorem slightly general one Ferraris et al. (2009)notion dependency graph yields less edges one given Ferraris et al.Insteadq positive occurrence G belong subformula Gnegative p,Ferraris et al.s definitionq positive occurrence G belong subformulaform K.instance, according Ferraris et al., dependency graph((p q) r) p(38)relative p two edges (from p r, p p), dependency graphaccording definition edges.hand, generalization essential view following theorem.Theorem 14 (Ferraris et al., 2009, Thm. Double Negations) Let H sentence, Fsubformula H, H sentence obtained H inserting front F .occurrence F p-negated H, SM[H; p] equivalent SM[H ; p].instance, SM[(38); p] equivalent SM[((p q) r) p; p]. dependencygraph ((p q) r) p relative p according definition Ferraris et al.identical dependency graph (38) relative p according definition.Next, say formula F Clark normal form (relative list p intensionalpredicates) conjunction sentences formx(G p(x)),(39)one intensional predicate p, x list distinct object variables, Gfree variables x. completion (relative p) formula FClark normal form obtained replacing conjunctive term (39)x(p(x) G).following theorem relates SM completion. say F tight ppredicate dependency graph F relative p acyclic.Theorem 15 (Ferraris et al., 2011) formula F Clark normal form tightp, formula SM[F ; p] equivalent completion F relative p.607fiLee & PallaC.2 Proof Proposition 1Using Theorem 12 Theorem 13,SM[F ; p] SM[F ; p pr (F )] SM[>; p\pr (F )]SM[F ; p pr (F )] False(p\pr (F ))SM[F Choice(pr (F )\p)] False(p\pr (F ))SM[F Choice(pr (F )\p) False(p\pr (F ))].C.3 Proof Theorem 1following, F formula, p list distinct predicate constants p1 , . . . , pn , ulist distinct predicate variables u1 , . . . , un length p.Lemma 2 (Ferraris et al., 2011, Lemma 5) Formulau p (F (u) F )logically valid.Lemma 3 every occurrence every predicate constant p strictly positive F ,(u p) (F (u) F (u))logically valid.Proof. induction. show case F G H. casesstraightforward. ConsiderF (u) = (G (u) H (u)) (G H).Since every occurrence predicate constants p F strictly positive, G containspredicate constants p, G (u) equivalent G(u),G. Also, I.H., H (u) H(u) logically valid. Therefore sufficient proveassumption u p,(G H(u)) (G H) (G H(u))logically valid. left right clear. Assume (u p), G H(u), G. getH(u), equivalent H (u) I.H. Lemma 2, conclude H.proof Theorem 1 immediate following lemma, provedinduction.Lemma 4 F canonical relative p, formula(u p) F (F (u) F (u))logically valid.608fiReformulating Situation Calculus Event CalculusProof.F atomic formula. Trivial.F = G H. Follows I.H.F = G H. Assume (u p) (G H). Since G H canonical relative p,every occurrence every predicate constant p strictly positive G H,that, Lemma 3, G (u) equivalent G(u), H (u) equivalent H(u).F = G H. Assume (u p) (G H). sufficient show(G (u) H (u)) (G(u) H(u)).(40)Since G H canonical relative p, every occurrence every predicate constantp G strictly positive G, that, Lemma 3, G (u) equivalentG(u).Case 1: G. Lemma 2, G (u). claim follows since G (u) equivalentG(u).Case 2: H. I.H. H (u) equivalent H(u). claim follows since G (u)equivalent G(u).F = xG. Follows I.H.F = xG. Since every occurrence every predicate constant p G strictlypositive G, claim follows Lemma 3.C.4 Proof Theorem 2Proof. (a) (b):(b) (c):Follows immediately Theorem 1.Note first equivalent SM[; ]. Sinceevery strongly connected component dependency graph relative{I, T, R, H} either belongs {I, T, R} {H},negative {H},negative {I, T, R},follows Theorem 13 (b) equivalentSM[ ; I, T, R, H] SM[; Ab1 , . . . , Abn ] SM[; ]Similarly, applying Theorem 13 repeatedly, show formulaequivalent (c).(c) (d):Proposition 1.609fiLee & PallaC.5 Proof Theorem 3Since Dcaused canonical relative Caused , Theorem 1, (a)(a) (b):equivalentSM[Dcaused ; Caused ] Dposs Drest(22).(41)Consequently, sufficient prove claim that, assumption Sit(s),formula (22) equivalent SM[Dsit ; Sit].First note assumption, (22) equivalently rewrittenp p(S0 ) a, s(p(s) p(do(a, s))) p = Sit .(42)hand, Sit(s), SM[Dsit ; Sit] equivalentSit(S0 ) a, s(Sit(s) Sit(do(a, s)))p p < Sit (p(S0 ) a, s(p(s) p(do(a, s))) a, s(Sit(s) Sit(do(a, s)))) ,which, assumption Sit(s), equivalentp p(S0 ) a, s(p(s) p(do(a, s))) (p < Sit)furthermore (42).(b) (c): Since (s) contain Poss, equivalence followsequivalence completion stable model semantics.(c) (d): Since Dcaused contains strictly positive occurrence PossDposs contains occurrence Caused , every strongly connected componentpredicate dependency graph Dcaused Dposs relative {Caused , Poss} either belongs{Caused } belongs {Poss}. Theorem 13, follows (b) equivalentSM[Dcaused Dposs ; Caused , Poss] DrestSM[Dsit ; Sit].Similarly, applying Theorem 13 two times, get formula equivalent(c).C.6 Proof Theorem 4TheoryDeffect Dprecond DS0 Duna Dinertia Dexogenous0 ,corresponding BATDss Dap DS0 Duna .Without loss generality, assume already equivalently rewrittenexactly one positive effect axiom exactly one negative effect axiom fluent R,exactly one action precondition axiom action A.610fiReformulating Situation Calculus Event CalculusConsiderSM[ Deffect Dprecond DS0 Duna Dinertia Dexogenous0 ; Poss, Holds, Holds].Since Duna negative intensional predicates, formula equivalentSM[Deffect Dprecond DS0 Dinertia Dexogenous0 ; P oss, Holds, Holds] Duna .(43)Since P oss occurDeffect DS0 Dinertia Dexogenous0 ,since Dprecond negative {Holds, Holds}, Theorem 13, (43) equivalentSM[Deffect DS0 Dinertia Dexogenous0 ; Holds, Holds]SM[Dprecond ; P oss] Duna ,(44)equivalentSM[Deffect DS0 Dinertia Dexogenous0 ; Holds, Holds]Dap Duna .Therefore statement theorem proven showing following:|= x s(+R (x, a, s) R (x, a, s))(45)|=(46)SM[DS0 Dexogenous0 Deffect Dinertia ; Holds, Holds](47)every fluent R,satisfiesiff I| satisfiesDS0 Dss .Dexogenous0 , follows (47) equivalentSM[DSDexogenous0 Deffect Dinertia ; Holds, Holds],0(48)DSformula obtained DS0 prepending occurrences Holds.0assumption (46),DSDexogenous0 Deffect Dinertia0{Holds}-atomic-tight w.r.t. I, 26 relationship completion SMstated Corollary 11 (Lee & Meng, 2011), |= (48) iff satisfiesDS0 , and, fluent R,26. See Section 7 work Lee Meng (2011) definition.611fiLee & PallaHolds(R(x), do(a, s)) +R (x, a, s) (Holds(R(x, s) Holds(R(x), do(a, s)))(49)Holds(R(x), do(a, s))R (x, a, s) (Holds(R(x), s) Holds(R(x), do(a, s))), (50)x, a, (lists of) object names corresponding sorts.remains show that, assumption (45), satisfies (49) (50) iff I| satisfiesHolds(R(x), do(a, s)) +R (x, a, s) (Holds(R(x), s) R (x, a, s)).(51)following use following facts.|=Holds(R(x), s) iff I| 6|= Holds(R(x), s).F ground formula contain , |= F iff I| |= F .Left Right: Assume |= (49) (50).Case 1: I| |= Holds(R(x), do(a, s)). Clearly, |= Holds(R(x), do(a, s)), that,(49), two subcases consider.Subcase 1: |= +R (x, a, s). Clearly, I| satisfies LHS RHS (51).Subcase 2: |= Holds(R(x), s). (50), follows 6|=R (x, a, s),(x,a,s).Clearly,I|satisfiesLHSRHS (51).consequently, I| 6|=RCase 2: I| 6|= Holds(R(x), do(a, s)). follows (49) 6|= +R (x, a, s),(x,a,s).Alsosince|=Holds(R(x),do(a, s)),equivalent saying I| 6|= +R(50), two subcases consider.Subcase 1: |=R (x, a, s). Clearly, I| satisfies neither LHS RHS (51).Subcase 2: |= Holds(R(x), s). equivalent saying I| 6|=Holds(R(x), s). Clearly, I| satisfies neither LHS RHS (51).Right Left: Assume I| |= (51).Case 1: |= Holds(R(x), do(a, s)). follows (51) I| satisfies RHS (51),two subcases consider.Subcase 1: I| |= +R (x, a, s). Clearly, satisfies LHS RHS (49).Also (45), follows 6|=R (x, a, s). Consequently, satisfies neitherLHS RHS (50).Subcase 2: I| |= Holds(R(x), s)R (x, a, s). Clearly, satisfies LHSRHS (49). Since 6|=(x,a,s),satisfies neither LHS RHS (50).RCase 2: |=Holds(R(x), do(a, s)). follows (51) I| 6|= +R (x, a, s),I| 6|= (Holds(R(x), s)(x,a,s)).latter,considertwosubcases.R612fiReformulating Situation Calculus Event CalculusSubcase 1: I| 6|= Holds(R(x), s). Clearly, satisfies neither LHS RHS(49), satisfies LHS RHS (50).Subcase 2: I| 6|=R (x, a, s). Clearly, satisfies neither LHS RHS (49),satisfies LHS RHS (50).C.7 Proof Proposition 2Lemma 5 Let F formula, let p list distinct predicate constants, let Gsubformula F let G0 formula classically equivalent G. Let F 0formula obtained F substituting G0 G. occurrence G subformulaF negative p occurrence G0 subformula F 0 negativep,SM[F ; p] SM[F 0 ; p]logically valid.Proof. Let F formula obtained F prepending G, let (F 0 )formula obtained F 0 prepending G0 . Theorem DoubleNegations (Theorem 14), following formulas logically valid.SM[F ; p] SM[F ; p],SM[F 0 ; p] SM[(F 0 ) ; p].Lemma 1, follows(u p (G G0 )) ((F ) (u) ((F 0 ) ) (u))logically valid, u list predicate variables corresponding p. Consequently,SM[F ; p] SM[(F 0 ) ; p]logically valid.Proof Proposition 2. formulaSM[F 0 xy(G(y, x) q(x)); p, q],(52)clearly, F 0 negative q xy(G(y, x) q(x)) negative p. Let Hsubformula F negative p contains occurrence yG(y, x). Considertwo cases.Case 1: occurrence yG(y, x) H strictly positive. Thus dependencygraph F 0 xy(G(y, x) q(x)) relative {p, q} incoming edges q.Case 2: occurrence yG(y, x) H strictly positive. Since H negative p, yG(y, x) negative p well, dependency graphF 0 xy(G(y, x) q(x)) relative {p, q} outgoing edges q.613fiLee & PallaTherefore, every strongly connected component dependency graph belongs eitherp {q}. Consequently, Theorem 13, (52) equivalentSM[F 0 ; p] SM[xy(G(y, x) q(x)); q](53)Since yG(y, x) negative q, formula xy(G(y, x) q(x)) tight {q}. Theorem 15, (53) equivalentSM[F 0 ; p] x(yG(y, x) q(x)).(54)Lemma 5, follows (54) equivalentSM[F ; p] x(yG(y, x) q(x)).Consequently, claim follows.C.8 Proof Theorem 6clear algorithm terminates yields quantifier-free formula K.prove SM[F ; p] SM[xK; p q], x list (free) variables K.Let F formula obtained initial formula F prepending doublenegations front every maximal strictly positive occurrence formulas formyG(x, y). Since F almost universal relative p, occurrence subformulaF negative p. Thus Theorem Double Negations (Theorem 14),SM[F ; p] equivalent SM[F ; p]. Note F contains strictly positive occurrenceformulas form yG(x, y).iteration, let us assume formula iterationH0 Hn ,H0 transformed F previous iterations, Hi (i > 0)formula form G(x, y) pG (x) introduced Step (b). Initially H0 Fn = 0. Let r0 p, let ri pG Hi (i > 0). induction prove(i) every positive occurrence formulas form yG(x, y) Hi strictly positive, subformula Hi negative ri ;(ii) every negative occurrence formulas form yG(x, y) Hi subformulaHi negative ri .prove Step (a) Step (c) applied turn Hk Hk0 ,SM[x0 H0 ; r0 ] SM[xn Hn ; rn ](55)SM[x00 H00 ; r0 ] SM[x0n Hn0 ; rn ],(56)equivalentHj0 = Hj j different k, xi (i 0) list free variablesHi , x0i (i 0) list free variables Hi0 .614fiReformulating Situation Calculus Event CalculusIndeed, Step (a) part prenex form conversion, preserves strong equivalence(Theorem 5). clear (55) equivalent (56).Step (c) applied turn (55) (56), since yH(x, y) subformulaHk negative rk , equivalence (55) (56) follows Lemma 5.Step (b) applied turn Hk Hk0 introduces new conjunctive term0Hn+1 , formula (55) (, r1 , . . . , rn )-equivalent0SM[x00 H00 ; r0 ] SM[x0n Hn0 ; rn ] SM[x0n+1 Hn+1; rn+1 ](57)Proposition 2 due condition (i).Let00H000 Hm(58)final quantifier-free formula, H000 transformed F . induction,follows SM[F ; p] -equivalent00SM[x000 H000 ; r0 ] SM[x00m Hm; rm ],(59)x00i (0 m) list free variables Hi00 .Since every non-strictly positive occurrence new predicate ri (i > 0) Hj00 (0j m) positive, incoming edge ri dependency graph (58) relativer0 , r1 , . . . , rm . Consequently, every strongly connected component dependencygraph belongs one ri (i 0). Moreover, clear Hi00 (i 0) negativeevery rj j 6= i. (In case H000 , recall occurrence rj j > 0strictly positive since F , H000 obtained, contains strictly positiveoccurrence formulas form yG(x, y).) Thus splitting theorem (Theorem 13),formula (59) equivalent00SM[x000 H000 x00m Hm; r0 rm ].(60)C.9 Proof Theorem 7use notations introduced proof Theorem 6. Theorem 6, SM[F ; p]-equivalent (60) and, Theorem 12, (60) equivalent00SM[x000 H000 x00m HmChoice( pred \ p); pred r1 rm ](61)(r0 p), pred set predicate constants signature . followsProposition 3 (Cabalar et al., 2005) (61) equivalent000SM[x000 H0000 x00m HmChoice( pred \ p); pred r1 rm ],(62)Hi000 obtained Hi00 applying translation (Cabalar et al., 2005,Section 3) turns quantifier-free formula set rules. easy see F 0formula000x000 H0000 x00m HmChoice( pred \ p)615fiLee & Pallapred r1 rm p pr (F 0 ), (62) writtenSM[F 0 ; p pr (F 0 )],equivalentSM[F 0 False(p \ pr (F 0 ))].Proposition 1.C.10 Proof Theorem 8AssumeCIRC[; Initiates, Terminates, Releases] CIRC[; Happens]CIRC[; Ab 1 , . . . , Ab n ] ,equivalentSM[; Initiates, Terminates, Releases] SM[; Happens]SM[; Ab 1 , . . . , Ab n ](63)Theorem 2.Let def set definitions (35) , let 0 formula obtainedapplying Step 1. Theorem 15, follows formula (35) def equivalentSM[x(G0 p(x)); p],G0 described Step 1. Consequently, (63) equivalentSM[; Initiates, Terminates,V Releases] SM[; Happens]SM[; Ab 1 , . . . , Ab n ] (35)def SM[x(G0 p(x)); p] 00 ,(64)00 conjunction axioms 0 ones obtaineddefinitional axioms (35).Applying Theorem 13 repeatedly, follows (64) equivalentVSM[ 00 (35)def x(G0 p(x));Initiates, Terminates, Releases, Happens, Ab 1 , . . . , Ab n , p] .(65)According syntax event calculus reviewed Section 3.1,every positive occurrence formula form yG(y) (65) containedsubformula negative{Initiates, Terminates, Releases, Happens, Ab 1 , . . . , Ab n , p},negative occurrences formula form yG(y) (65).Consequently, statement theorem follows Theorem 7.616fiReformulating Situation Calculus Event CalculusC.11 Proof Theorem 9Since (37) almost universal relative {Caused , Poss, Sit}, result follows Theorems 7 3.C.12 Proof Theorem 10Dexogenous0 , follows SM[T ; Holds, Holds, Poss] equivalentSM[T ; Holds, Holds, Poss], obtained prependingoccurrences Holds DS0 . definition uniform formula (Reiter, 2001),follows almost universal relative {Holds, Holds, Poss}. result followsTheorem 7.ReferencesAkman, V., Erdogan, S., Lee, J., Lifschitz, V., & Turner, H. (2004). Representing ZooWorld Traffic World language Causal Calculator. ArtificialIntelligence, 153(12), 105140.Belleghem, K. V., Denecker, M., & Schreye, D. D. (1995). Combining situation calculusevent calculus. Proceedings International Conference Logic Programming(ICLP), pp. 8397.Belleghem, K. V., Denecker, M., & Schreye, D. D. (1997). relation situationcalculus event calculus. Journal Logic Programming, 31 (1-3), 337.Besnard, P., & Cordier, M.-O. (1994). Explanatory diagnoses characterizationcircumscription. Annals Mathematics Artificial Intelligence, 11 (1-4), 7596.Cabalar, P., & Ferraris, P. (2007). Propositional theories strongly equivalent logicprograms. Theory Practice Logic Programming, 7 (6), 745759.Cabalar, P., Pearce, D., & Valverde, A. (2005). Reducing propositional theories equilibrium logic logic programs. Proceedings Portuguese Conference ArtificialIntelligence (EPIA), pp. 417.Calimeri, F., Cozza, S., Ianni, G., & Leone, N. (2008). Computable functions ASP: theoryimplementation. Proceedings International Conference Logic Programming (ICLP), pp. 407424.Denecker, M., & Ternovska, E. (2007). Inductive situation calculus. Artificial Intelligence,171 (5-6), 332360.Denecker, M., & Ternovska, E. (2008). logic nonmonotone inductive definitions. ACMTransactions Computational Logic, 9 (2).Doherty, P., Gustafsson, J., Karlsson, L., & Kvarnstrom, J. (1998). TAL: Temporal actionlogics language specification tutorial. Linkoping Electronic Articles ComputerInformation Science ISSN 1401-9841, 3 (015). http://www.ep.liu.se/ea/cis/1998/015/.617fiLee & PallaDogandag, S., Ferraris, P., & Lifschitz, V. (2004). Almost definite causal theories..Proceedings International Conference Logic Programming NonmonotonicReasoning (LPNMR), pp. 7486.Erdem, E., & Lifschitz, V. (2003). Tight logic programs. Theory Practice LogicProgramming, 3, 499518.Fages, F. (1994). Consistency Clarks completion existence stable models. JournalMethods Logic Computer Science, 1, 5160.Ferraris, P., Lee, J., & Lifschitz, V. (2007). new perspective stable models. Proceedings International Joint Conference Artificial Intelligence (IJCAI), pp. 372379.Ferraris, P., Lee, J., & Lifschitz, V. (2011). Stable models circumscription. ArtificialIntelligence, 175, 236263.Ferraris, P., Lee, J., Lifschitz, V., & Palla, R. (2009). Symmetric splitting generaltheory stable models. Proceedings International Joint Conference ArtificialIntelligence (IJCAI), pp. 797803.Gebser, M., Schaub, T., & Thiele, S. (2007). Gringo : new grounder answer setprogramming. Proceedings International Conference Logic ProgrammingNonmonotonic Reasoning (LPNMR), pp. 266271.Gelfond, M., & Lifschitz, V. (1988). stable model semantics logic programming.Kowalski, R., & Bowen, K. (Eds.), Proceedings International Logic ProgrammingConference Symposium, pp. 10701080. MIT Press.Gelfond, M., & Lifschitz, V. (1998). Action languages. Electronic Transactions ArtificialIntelligence, 3, 195210. http://www.ep.liu.se/ea/cis/1998/016/.Giunchiglia, E., Lee, J., Lifschitz, V., McCain, N., & Turner, H. (2004). Nonmonotoniccausal theories. Artificial Intelligence, 153(12), 49104.Heyting, A. (1930). Die formalen Regeln der intuitionistischen Logik. Sitzungsberichteder Preussischen Akademie von Wissenschaften. Physikalisch-mathematische Klasse,4256.Janhunen, T., & Oikarinen, E. (2004). Capturing parallel circumscription disjunctivelogic programs. Proc. 9th European Conference Logics Artificial Intelligence(JELIA-04), pp. 134146.Kautz, H., & Selman, B. (1992). Planning satisfiability. Proceedings EuropeanConference Artificial Intelligence (ECAI), pp. 359363.Kim, T.-W., Lee, J., & Palla, R. (2009). Circumscriptive event calculus answer set programming. Proceedings International Joint Conference Artificial Intelligence(IJCAI), pp. 823829.Kowalski, R., & Sergot, M. (1986). logic-based calculus events. New GenerationComputing, 4, 6795.Kowalski, R. A., & Sadri, F. (1997). Reconciling event calculus situationcalculus. Journal Logic Programming, 31 (1-3), 3958.618fiReformulating Situation Calculus Event CalculusLee, J., Lifschitz, V., & Palla, R. (2008). reductive semantics counting choiceanswer set programming. Proceedings AAAI Conference ArtificialIntelligence (AAAI), pp. 472479.Lee, J., & Lin, F. (2006). Loop formulas circumscription. Artificial Intelligence, 170 (2),160185.Lee, J., & Meng, Y. (2011). First-order stable model semantics first-order loop formulas.Journal Artificial Inteligence Research (JAIR), 42, 125180.Lee, J., & Palla, R. (2007). Yet another proof strong equivalence propositionaltheories logic programs. Working Notes Workshop CorrespondenceEquivalence Nonmonotonic Theories.Lee, J., & Palla, R. (2010). Situation calculus answer set programming. ProceedingsAAAI Conference Artificial Intelligence (AAAI), pp. 309314.Lifschitz, V. (1994). Circumscription. Gabbay, D., Hogger, C., & Robinson, J. (Eds.),Handbook Logic AI Logic Programming, Vol. 3, pp. 298352. Oxford University Press.Lifschitz, V. (2008). answer set programming?. Proceedings AAAI Conference Artificial Intelligence, pp. 15941597. MIT Press.Lifschitz, V. (2011). Datalog programs stable models. de Moor, O., Gottlob,G., Furche, T., & Sellers, A. (Eds.), Datalog Reloaded: First International Workshop,Datalog 2010, Oxford, UK, March 16-19, 2010. Revised Selected Papers. Springer.Lifschitz, V., Pearce, D., & Valverde, A. (2001). Strongly equivalent logic programs. ACMTransactions Computational Logic, 2, 526541.Lifschitz, V., Tang, L. R., & Turner, H. (1999). Nested expressions logic programs. AnnalsMathematics Artificial Intelligence, 25, 369389.Lifschitz, V., & Turner, H. (1999). Representing transition systems logic programs.Proceedings International Conference Logic Programming NonmonotonicReasoning (LPNMR), pp. 92106.Lin, F. (1995). Embracing causality specifying indirect effects actions. Proceedings International Joint Conference Artificial Intelligence (IJCAI), pp. 19851991.Lin, F. (2003). Compiling causal theories successor state axioms STRIPS-like systems. Journal Artificial Intelligence Research, 19, 279314.Lin, F., & Shoham, Y. (1992). logic knowledge justified assumptions. ArtificialIntelligence, 57, 271289.Lin, F., & Wang, K. (1999). causal theories logic programs (sometimes).Proceedings International Conference Logic Programming NonmonotonicReasoning (LPNMR), pp. 117131.Lin, F., & Zhou, Y. (2011). answer set logic programming circumscription via logicGK. Artificial Intelligence, 175, 264277.619fiLee & PallaMarek, V., & Truszczynski, M. (1999). Stable models alternative logic programmingparadigm. Logic Programming Paradigm: 25-Year Perspective, pp. 375398.Springer Verlag.McCarthy, J. (1980). Circumscriptiona form non-monotonic reasoning. Artificial Intelligence, 13, 2739,171172.McCarthy, J. (1986). Applications circumscription formalizing common sense knowledge. Artificial Intelligence, 26 (3), 89116.McCarthy, J., & Hayes, P. (1969). philosophical problems standpointartificial intelligence. Meltzer, B., & Michie, D. (Eds.), Machine Intelligence, Vol. 4,pp. 463502. Edinburgh University Press, Edinburgh.Miller, R., & Shanahan, M. (1999). event calculus classical logic - alternative axiomatisations. Electronic Transactions Artificial Intelligence, 3 (A), 77105.Mueller, E. (2006). Commonsense reasoning. Morgan Kaufmann.Mueller, E. T. (2004). Event calculus reasoning satisfiability. Journal LogicComputation, 14 (5), 703730.Niemela, I. (1999). Logic programs stable model semantics constraint programmingparadigm. Annals Mathematics Artificial Intelligence, 25, 241273.Pearce, D., & Valverde, A. (2005). first order nonmonotonic extension constructivelogic. Studia Logica, 80, 323348.Provetti, A. (1996). Hypothetical reasoning actions: situation calculus eventcalculus. Computational Intelligence, 12, 478498.Reiter, R. (1980). logic default reasoning. Artificial Intelligence, 13, 81132.Reiter, R. (1991). frame problem situation calculus: simple solution (sometimes) completeness result goal regression. Lifschitz, V. (Ed.), ArtificialIntelligence Mathematical Theory Computation: Papers Honor John McCarthy, pp. 359380. Academic Press.Reiter, R. (2001). Knowledge Action: Logical Foundations Specifying Implementing Dynamical Systems. MIT Press.Shanahan, M. (1995). circumscriptive calculus events. Artif. Intell., 77 (2), 249284.Shanahan, M. (1997). Solving Frame Problem: Mathematical InvestigationCommon Sense Law Inertia. MIT Press.Shanahan, M. (1999). event calculus explained. Artificial Intelligence Today, LNCS1600, pp. 409430. Springer.Shanahan, M., & Witkowski, M. (2004). Event calculus planning satisfiability.Journal Logic Computation, 14 (5), 731745.Syrjanen, T. (2004). Cardinality constraint programs.. Proceedings European Conference Logics Artificial Intelligence (JELIA), pp. 187199.Zhang, H., Zhang, Y., Ying, M., & Zhou, Y. (2011). Translating first-order theories logicprograms. Proceedings International Joint Conference Artificial Intelligence(IJCAI), pp. 11261131.620fiJournal Artificial Intelligence Research 43 (2012) 353388Submitted 10/11; published 03/12Computing All-Pairs Shortest PathsLeveraging Low TreewidthLeon PlankenMathijs de Weerdtl.r.planken@tudelft.nlm.m.deweerdt@tudelft.nlFaculty EEMCS, Delft University Technology,Delft, NetherlandsRoman van der Krogtroman@4c.ucc.ieCork Constraint Computation Centre,University College Cork, Cork, IrelandAbstractpresent two new efficient algorithms computing all-pairs shortest paths.algorithms operate directed graphs real (possibly negative) weights. make usedirected path consistency along vertex ordering d. algorithms run n2 wdtime, wd graph width induced vertex ordering. graphs constanttreewidth, yields n2 time, optimal. chordal graphs, algorithmsrun (nm) time. addition, presentvariant exploits graph separatorsarrive run time nwd2 + n2 sd general graphs, sd wd sizelargest minimal separator induced vertex ordering d. show empiricallyconstructed realistic benchmarks, many cases algorithms outperformFloydWarshalls well Johnsonsalgorithm,represent current stateart run time n3 nm + n2 log n , respectively. algorithmsused spatial temporal reasoning, Simple Temporal Problem,underlines relevance planning scheduling community.1. IntroductionFinding shortest paths important fundamental problem communicationtransportation networks, circuit design, bioinformatics, Internet node traffic, social networking, graph analysis generale.g. computing betweenness (Girvan & Newman, 2002)and sub-problem many combinatorial problems,represented network flow problem. particular, context planningscheduling, finding shortest paths important solve set binary linear constraintsevents, i.e. Simple Temporal Problem (STP; Dechter, Meiri, & Pearl, 1991).STP turn appears sub-problem NP-hard Temporal Constraint SatisfactionProblem (TCSP; Dechter et al., 1991) Disjunctive Temporal Problem (DTP; Stergiou& Koubarakis, 2000), powerful enough model e.g. job-shop scheduling problems. shortest path computations applications account significantpart total run time solver. Thus, hardly surprising topics received substantial interest planning scheduling community (Satish Kumar, 2005;Bresina, Jonsson, Morris, & Rajan, 2005; Rossi, Venable, & Yorke-Smith, 2006; Shah &Williams, 2008; Conrad, Shah, & Williams, 2009).c2012AI Access Foundation. rights reserved.fiPlanken, De Weerdt, & Van der KrogtInstances STP, called Simple Temporal Networks (STNs), natural representation directed graphs real edge weights. Recently, specific interestSTNs stemming hierarchical task networks (HTNs; Castillo, Fernandez-Olivares,& Gonzalez, 2006; Bui & Yorke-Smith, 2010). graphs sibling-restrictedproperty: task, represented pair vertices, connected sibling tasks,parent children. graphs number children task restrictedconstant branching factor, therefore resulting STNs also tree-like structure.canonical way solving STP instance (Dechter et al., 1991) computingall-pairs shortest paths (APSP) STN, thus achieving full path consistency.graphs n vertices edges, done n3 time FloydWarshallalgorithm (Floyd, 1962), based Warshalls (1962) formulation efficiently computingtransitive closure Boolean matrices. However, state art computing APSPsparse graphs algorithm based technique originally proposed Johnson(1977), preprocessing allow n runs Dijkstras (1959) algorithm. UsingFibonacci heap (Fredman & Tarjan, 1987), algorithm runs n2 log n + nm time.remainder paper, refer algorithm Johnson.paper present two new algorithms APSP real edge weights (in Section 3). One algorithm, dubbed ChleqAPSP, based point-to-point shortest pathalgorithm Chleq (1995); other, named Snowball, similar Planken, de Weerdt,van der Krogts (2008) algorithm enforcing partial (instead full) path consistency (P3 C). new algorithms advance state art computing APSP.graphs constant treewidth, sibling-restricted STNs based HTNscon2stant branching factor, run timealgorithms bounded n ,optimal since output n2 . addition STNs, examples graphsconstant treewidth outerplanar graphs, graphs bounded bandwidth, graphsbounded cutwidth, series-parallel graphs (Bodlaender, 1986).ChleqAPSP Snowball applied chordal graphs, run time(nm), strict improvementstate art (Chaudhuri & Zaroliagis,2000, run time nmwd2 ; wd defined below). Chordal graphs importantsubset general sparse graphs: interval graphs, trees, k-trees split graphs specialcases chordal graphs (Golumbic, 2004). Moreover, graph made chordal usingso-called triangulation algorithm. algorithm operates eliminating vertices oneone, connecting neighbours eliminated vertex thereby inducing cliquesgraph.induced width wd vertex ordering defined equal cardinalitylargest set neighbours encountered. upperbound run timeproposed algorithms general graphs, n2 wd , depends inducedwidth. Finding vertex ordering minimum induced width, however, NP-hardproblem (Arnborg, Corneil, & Proskurowski, 1987). minimum induced widthtree-likeness property graph mentioned above, i.e. treewidth, denoted w .contrast, induced width direct measure input (graph), boundn2 wd quite proper. Still, better bound Johnson wd (log n).11. prefer write x (f (n)) instead common x = (f (n)). Formally, right-handside represents set functions grow strictly slower f (n), traditional equalityfact works one direction (see also Graham, Knuth, & Patashnik, 1989, Section 9.2).354fiComputing APSP Leveraging Low Treewidthsee this, note bound Johnson never better n2 log n , regardlessvalue m.paper, also present variant Snowball exploits graph separatorsattains upper bound run time nwd2 + n2 sd . upper bound evenbetter one two new algorithms, since sd wd size largestminimal separator induced vertex ordering d. theoretical bounds runtime usually give good indication performance algorithms, see especiallylast variant always predict algorithm best settings.Section 4, therefore, experimentally establish computational efficiencyproposed algorithms wide range graphs, varying random scale-free networksparts road network New York City, STNs generated HTNs job-shopscheduling problems.Below, first give detailed introduction required concepts,induced width, chordal graphs triangulation, present new algorithmsanalysis.2. Preliminariessection, briefly introduce algorithm enforces directed path consistency (DPC) find vertex ordering required algorithm.present algorithms all-pairs shortest paths, require enforcing DPC (orstronger property) first step. treatment, assume weights edgesgraph real possibly negative.2.1 Directed Path ConsistencyDechter et al. (1991) presented DPC, included Algorithm 1, way check whetherSTP instance consistent.2 equivalent checking graphcontain negative cycle (a closed path negative total weight). algorithm takesinput weighted directed graph G = hV, Ei vertex ordering d, bijectionV natural numbers {1, . . . , n}. paper, simply represent ithvertex ordering natural number i. (possibly negative) weightarc j represented wij R. shorthand existence arcvertices, either direction, {i, j} E. Finally, denote Gk graphinduced vertices {1, . . . , k}; likewise, set vertices V 0 V , GV 0 denotes graphinduced V 0 . So, particular, GV = Gn = G.iteration k, algorithm adds edges (in line 5) pairs lower-numberedneighbours i, j k, thus triangulating graph. Moreover, lines 3 4, updatesedge j weight paths k j j k i, shorter.Consequently, < j, defining property DPC ensures wij highertotal weight path j consists vertices outside Gj (exceptj themselves). implies particular running DPC, w12 w21labelled shortest paths vertices 1 2.2. Note algorithmssuch BellmanFordcan used purpose well, usuallyperform better practice.355fiPlanken, De Weerdt, & Van der KrogtAlgorithm 1: DPC (Dechter et al., 1991)Input: Weighted directed graph G = hV, Ei; vertex ordering : V {1, . . . , n}Output: DPC version G, inconsistent G contains negative cycle10k n 1forall < j < k {i, k} , {j, k} Ewij min {wij , wik + wkj }wji min {wji , wjk + wki }E E {{i, j}}wij + wji < 0return inconsistentendendend11return G = hV, Ei123456789run time DPC depends measure wd called induced width relativeordering vertices. Dechter et al. (1991) define induced width vertexordering procedurally exactly highest number neighbours j k j < kencountered DPC algorithm. includes neighbours original graph (i.e.{j, k} E) well vertices became neighbours edges addedearlier iteration algorithm. However, definition based originalgraph vertex ordering, making use following result.Proposition 1. Suppose G = hV, Ei undirected graph : V {1, . . . , n}(where bijection) vertex ordering. Suppose given n setsedges Ek0 1 k n, defined follows:Ek0 = {j, k} V | j < k path k j G{j}{k,k+1,...,n}Then, Ek0 exactly set edges visited iteration k DPC.Proof. Note definition, set Ek0 superset original edgesvertex k lower-numbered neighbours. use fact prove equivalenceinduction.equivalence holds first iteration k = n, En0 exactly setoriginal edges vertex n lower-numbered neighbours, earlieriterations DPC may added edges {j, k} j < k. Now, assumingequivalence holds sets E`0 ` > k, show also holds Ek0 .inductive case, prove inclusion relations separately.() reach contradiction, assume exists edge {j, k} 6 Ek0 , j < k,visited DPC iteration k. Ek0 includes original edgesk lower-numbered neighbours, must new edge added earlieriteration ` > k, must exist edges {j, `} , {k, `} E`0 . induction hypothesis,j k therefore connected induced subgraph G{j,k}{`,`+1,...,n} .356fiComputing APSP Leveraging Low Treewidthmust also connected larger subgraph G{j}{k,k+1,...n} thus definitionincluded Ek0 : contradiction.() Assume, reaching contradiction, exists edge {j, k} Ek0part E iteration k DPC therefore visited algorithm. Clearly,{j, k} cannot one original edges. definition Ek0 must thereforeexist path least one intermediate vertex j k induced subgraphG{j}{k,k+1,...n} . Let ` lowest-numbered vertex j k path;` > k > j. Then, induction hypothesis, must exist edges{j, `} , {k, `} E`0 , visited DPC iteration `. more,reach contradiction, since DPC must added {j, k} E iteration ` > k.formally define induced width follows, conclude Proposition 1equivalent original procedural definition.Definition 1. Given undirected graph G = hV, Ei, vertex ordering d, n setsedges Ek0 Proposition 1, induced width wd G (relative d) followingmeasure:fi fiwd = max fiEk0 fikVfollows run time DPC property graph per se; rather,dependent graphand vertex ordering used. careful implementation,DPCs time bound nwd2 ordering known beforehand.edges added DPC called fill edges make graph chordal (sometimesalso called triangulated). Indeed, DPC differs triangulation proceduremanipulation arc weights. chordal graph, every cycle length fouredge joining two vertices adjacent cycle. Definition 1, numberedges chordal graph, denoted mc m, (nwd ). give formaldefinitions concepts.Definition 2. Given graph G = hV, Ei set v 1 , v 2 , . . . , v k V verticesform cycle G, chordcycle edge non-adjacent verticescycle, i.e. edge v , v j E 1 < j < k 1. graph G = hV, Ei called chordalcycles size larger 3 chord.Definition 3. Given graph G = hV, Ei, triangulation G, E = ,set edges G0 = hV, E chordal. edges called fill edges.minimal triangulation G exists proper subset 0 0triangulation G.2.2 Finding Vertex Orderingprinciple, DPC use vertex ordering make graph chordal directionally path-consistent. However, since vertex ordering defines induced width,directly influences run time number edges mc resulting graph. mentioned introduction, finding ordering minimum induced width wd = w ,even determining treewidth w , NP-hard problem general. Still,class constant-treewidth graphs recognised, optimally triangulated, (n)357fiPlanken, De Weerdt, & Van der Krogttime (Bodlaender, 1996). G already chordal, find perfect ordering (resulting fill edges) (m) time, using e.g. maximal cardinality search (MCS; Tarjan &Yannakakis, 1984). perfect ordering also called simplicial ordering, every vertex k together lower-numbered neighbours ordering induces clique(simplex) subgraph Gk . implies following (known) result, relating inducedwidth treewidth size largest clique G.Proposition 2. graph G chordal, size largest clique exactly w + 1.non-chordal graph G triangulated along vertex ordering d, yielding chordal graph G0 ,size largest clique G0 exactly wd + 1. treewidth G0 equals wdupper bound treewidth original graph G: w wd .general graphs, various heuristics exist often produce good results. mentionminimum degree heuristic (Rose, 1972), iteration chooses vertexlowest degree. Since ordering produced heuristic fully knownDPC starts depends fill edges added, adjacency-list-based implementationrequire another (log n) factor DPCs time bound. However, purposesarticle, affordcomfort maintaining adjacency matrix, yields boundsn2 + nwd2 time n2 space.3. All-Pairs Shortest PathsEven though, best knowledge, DPC-based APSP algorithm yetproposed, algorithms computing single-source shortest paths (SSSP) based DPCobtained known results relatively straightforward manner. Chleq (1995)proposed point-to-point shortest path algorithm trivial adaptation computesSSSP; Planken, de Weerdt, Yorke-Smith (2010) implicitly also compute SSSP partIPPC algorithm. algorithms run (mc ) time thussimply run2vertex yield APSP algorithm (nmc ) n wd time complexity.Below, first show adapt Chleqs algorithm compute APSP; then, presentnew, efficient algorithm named Snowball relates Planken et al.s (2008) P3 C.3.1 Chleqs ApproachChleqs (1995) point-to-point shortest path algorithm simply called Minpath computes shortest path two arbitrary vertices s, V directionally pathconsistent graph G. reproduced Algorithm 2 seen run (mc )time edge considered twice. shortest distance sourcevertex maintained array D; algorithm iterates downward 1upward 1 t, updating distance array shorter path found.Since sink vertex used bound second loop, clearactually contains shortest distances pairs (s, t0 ) t0 t. Therefore,easily adapt algorithm compute SSSP within (mc ) time bound setting= n returning entire array instead D[t]. call result ChleqAPSP,included Algorithm 3, calls SSSP algorithm (referred Minpaths) n timescompute all-pairs shortest paths (nmc ) nwd2 time.358fiComputing APSP Leveraging Low TreewidthAlgorithm 2: Minpath (Chleq, 1995)Input: Weighted directed DPC graph G = hV, Ei;(arbitrary) source vertex destination vertexOutput: Distance t, inconsistent G contains negative cycle12V : D[i]D[s] 0k 1forall j < k {j, k} ED[j] min {D[j], D[k] + wkj }endendk 1forall j > k {j, k} ED[j] min {D[j], D[k] + wkj }endend13return D[t]1234567891011Algorithm 3: ChleqAPSPInput: Weighted directed graph G = hV, Ei; vertex ordering : V {1, . . . , n}Output: Distance matrix D, inconsistent G contains negative cycle12G DPC(G, d)return inconsistent DPC51 nD[i][] Minpaths(G, i)end6return34359fiPlanken, De Weerdt, & Van der KrogtAlgorithm 4: SnowballInput: Weighted directed graph G = hV, Ei; vertex ordering : V {1, . . . , n}Output: Distance matrix D, inconsistent G contains negative cycle12G DPC(G, d)return inconsistent DPC12i, j V : D[i][j]V : D[i][i] 0k 1 nforall j < k {j, k} Eforall {1, . . . , k 1}D[i][k] min {D[i][k], D[i][j] + wjk }D[k][i] min {D[k][i], wkj + D[j][i]}endendend13return345678910113.2 Snowball Algorithmsection, present algorithm computes APSP (or full path-consistency),dubbed Snowball included Algorithm 4, asymptotic worst-case timebounds ChleqAPSP requires strictly less computational work.Like ChleqAPSP, algorithm first ensures input graph directionally pathconsistent. idea behind algorithm grow, executionoutermost loop, clique {1, . . . , k} computed (shortest) distances, one vertextime, starting trivial clique consisting vertex 1; DPC performedbackward sweep along d, Snowball iterates direction. adding vertex kclique, two inner loops ensure compute distances kvertices < k. works know DPC pair (i, k),must exist shortest path k form j k (and vice versa),{j, k} E j < k edge chordal graph. means algorithmneeds look vertices i, j < k, follows inductively D[i][j]D[j][i] guaranteed correct earlier iteration.name algorithm derives snowball effect: clique computeddistances grows quadratically course operation. small exampleoperation Snowball given Figure 1. Originally, graph contained shortest path4762513. Dashed edges added DPC, path 4213 alsoshortest path; particular, w42 holds correct value. snapshot takenk = 4; shaded vertices 13 already visited shortest distances D[i][j]computed i, j 3. Then, iteration k = 4, j = 2 = 3,algorithm sets correct weight D[4][3] taking sum w42 + D[2][3].Theorem3. Algorithm 4 ( Snowball) correctly computes all-pairs shortest paths (nmc )n2 wd time.360fiComputing APSP Leveraging Low Treewidth7654321Figure 1: Snapshot (k = 4) graph operation Snowball.Proof. proof induction. enforcing DPC, w12 w21 labelledshortest distances vertices 1 2. k = 2 = j = 1, algorithmsets D[1][2] D[2][1] correct values.Now, assume D[i][j] set correctly vertices i, j < k. Let : = v0v1 v`1 v` = k shortest path k, let hmax =arg maxh{0,1,...,`} {vh }. DPC, 0 < hmax < `, exists pathweight shortcut vhmax 1 vhmax +1 taken. argument repeatedconclude must exist shortest path 0 k lies completely Gk and,except last arc, Gk1 . Thus, induction hypothesis observationalgorithm considers arcs subgraph Gk1 k, D[i][k] set correctvalue. analogous argument holds D[k][i].regard algorithms time complexity, note two outermost loopstogether result mc edges chordal graph visited exactly once.inner loop always fewer n iterations, yielding run time (nmc ) time.2observation mc nwd , also state looser time bound n wd .briefly discuss consequences two special cases: graphs constanttreewidth chordal graphs. chordal graphs, recognised (m) time,substitute mc run-time complexity; further, described above,perfect ordering exists found (m) time. gives total run-timecomplexity (nm). Likewise, stated given constant ,determined (n) time whether graph treewidth w , so, vertex ordering wd = w found within time bound. Then, omittingconstant factor wd , algorithm runs n2 time. also follows algorithms pseudocode noting every vertex k constant number (at w )neighbours j < k.note similarity Snowball P3 C algorithm (Planken et al.,2008), presented below. Like Snowball, P3 C operates enforcing DPC, followedsinglebackward sweep along vertex ordering. P3 C computes, nwd2 time, shortest361fiPlanken, De Weerdt, & Van der KrogtAlgorithm 5: P 3 C (Planken et al., 2008)Input: Weighted directed graph G = hV, Ei; vertex ordering : V {1, . . . , n}Output: PPC version G, inconsistent G contains negative cycle12G DPC(G, d)return inconsistent DPC8k 1 nforall i, j < k {i, k} , {j, k} Ewik min {wik , wij + wjk }wkj min {wkj , wki + wij }endend9return G34567paths arcs present chordal graph. similarity property chordalgraphs fact prompt us present version Snowball improved time complexity.3.3 Improving Run-Time Complexity Using Separatorssection, present improvement Snowball nwd2 + n2 sd run time,sd size largest minimal separator chordal graph obtainedtriangulation along d.Definition 4. Given connected graph G = hV, Ei, separator set V 0 VGV \V 0 longer connected. separator V 0 minimal proper subset V 0separator.bound better because, seen below, always holds sd wd . improvement hinges property chordal graphs called partial path consistency (PPC).partially path-consistent graph, arc labelled length shortest pathendpoints.3 P3 C, presented Algorithm 5, depends DPC computes PPCnwd2 time, current state art. Then, use clique treePPC graph compute shortest path vertices. Figure 2 shows examplechordal graph associated clique tree. clique tree following usefulproperties (Heggernes, 2006, Section 3.2).Property 1. Every chordal graph G = hV, Ei associated clique tree = hC, Si,constructed linear time (mc ).Property 2. clique tree node c C associated subset Vc V inducesmaximal clique G. Conversely, every maximal clique G associated clique treenode c C.Property 3. coherent: vertex v V , clique tree nodes whose associatedcliques contain v induce subtree .3. Full path-consistency (FPC) achieved arc exists pairs vertices u, v V .362fiComputing APSP Leveraging Low Treewidth(a) Chordal graph(b) Clique treeFigure 2: chordal graph clique tree. shaded shape represents maximalclique graph, containing vertices corners.Property 4. two clique tree nodes ci , cj C connected edge {ci , cj } S,Vci Vcj minimal separator G. Conversely, minimal separator V 0 G,clique tree edge {ci , cj } V 0 = Vci Vcj .Property5. vertices appear least one clique associated node , so:V=V.cC cSince Proposition 2 page 358 size largest clique chordalgraph exactly wd + 1, follows Properties 2 4 sd wd .Now, idea behind SnowballSeparators first compute PPC nwd2 time usingP3 C, traverse clique tree. PPC ensures shortest paths within cliquecomputed. Then, traversing clique tree arbitrary root nodeout, grow set Vvisited vertices cliques whose nodes already traversed.clique node c C visited traversal, shortest paths verticesclique Vc vertices Vvisited must run separator Vsep c csparent. sd size largest minimal separator G,pair vertices2suffices consider sd alternative routesfor total n sd routes, yieldingstated overall time complexity nwd2 + n2 sd . formally present algorithm basedidea Algorithm 6 associated recursive procedure Processcliquetreenode(on following page).Note visit nodes parent visiting node itself, alwaysholds Vcparent Vvisited . note that, simplicity presentation, assumegraph connected. not, simply find connected components lineartime construct clique tree them.improved algorithm edge original algorithm separatorssmall treewidth not. HTN-based sibling-restricted STNs (which describedpart experimental validation Section 4.3.5), instance, many separatorssize 2. every task many ( n) subtasks every task subtasksinduces clique,wd ( n) sd = 2, implying SnowballSeparators still2optimal n time complexity instances.4proceed prove algorithm correct meets stated run-timebounds, introduce following definition.4. However, since general every task subtasks form clique, low value sd usuallyattained practice.363fiPlanken, De Weerdt, & Van der KrogtAlgorithm 6: SnowballseparatorsInput: Weighted directed graph G = hV, Ei; vertex ordering : V {1, . . . , n}Output: Distance matrix D, inconsistent G contains negative cycle12345678910G P3 C(G, d)return inconsistent P3 Ci, j V : D[i][j]V : D[i][i] 0{i, j} E : D[i][j] wij{i, j} E : D[j][i] wjibuild clique tree = hC, Si Gselect arbitrary root node croot C(D, Vvisited ) Processcliquetreenode(croot , nil, D, )returnProcedure Processcliquetreenode(c, cparent , D, Vvisited )Input: Current clique tree node c, cs parent cparent , distance matrix D, setvisited vertices VvisitedOutput: Updated matrix set Vvisited13cparent 6= nilVnew Vc \ VcparentVsep Vc VcparentVother Vvisited \ Vcforall (i, j, k) Vnew Vsep VotherD[i][k] min {D[i][k], D[i][j] + D[j][k]}D[k][i] min {D[k][i], D[k][j] + D[j][i]}endendVvisited Vvisited Vcforall children c0 c(D, Vvisited ) Processcliquetreenode(c0 , c, D, Vvisited )end14return (D, Vvisited )123456789101112364// recursive callfiComputing APSP Leveraging Low TreewidthDefinition 5. define distance matrix valid set U vertices, (D, U )valid pair, pairs vertices (i, j) U U , D[i][j] holds shortest distanceG j.split correctness proof algorithm three parts: Lemmas 4 5culminate Theorem 6. first step show Processcliquetreenode calledvalid pair (D, U ) clique node c, procedure extends validityU Vc .Lemma 4. Consider call procedure Processcliquetreenode with, arguments, cliquenode c, cs parent cparent , distance matrix D, set visited vertices Vvisited .valid Vvisited upon calling, becomes valid Vc Vvisited running lines18 Processcliquetreenode.Proof. First, note Property 2, Vc induces clique G. Therefore, edges existpair (i, k) vertices Vc , since graph PPC, wik labelledshortest distance k. Due lines 5 6 main algorithm, alsocontains shortest distances, valid Vc .Now, remains shown pair vertices (i, k) Vc Vvisitedshortest distances D[i][k] D[k][i] set correctly. show case D[i][k];case analogous.desired result follows trivially cparent = nil, since procedure calledVvisited = . Otherwise, let Vnew = Vc \ Vcparent , Vsep = Vc Vcparent Vother = Vvisited \ Vcset procedure lines 24. either k lies Vsep , correctness D[i][k]svalue already proven, need consider pairs vertices (i, k) Vnew Vother .pair (i, k), Vsep separator k Property 4,shortest path k necessarily concatenation shortest paths jj k, j Vsep . Since follows definitions Vnew , Vsep Vother(i, j) Vnew Vsep (j, k) Vsep Vother , D[i][j] D[j][k] correctlyset (by validity Vc Vvisited , respectively), loop lines 58 yieldsdesired result.next step prove recursive calls, validity fact extendedentire subtree rooted c.Lemma 5. Consider call procedure Processcliquetreenode with, arguments,clique node c, cs parent Vcparent , distance matrix D, set visited vertices Vvisited .0valid Vvisited upon calling, returned, updated pair (D0 , Vvisited) alsovalid.Proof. First, note Lemma 4, valid Vvisited update line 10.Assume clique tree depth d; proof reverse inductiondepth clique tree node. c clique tree node depth (i.e. leaf), looplines 1113 no-op, immediately obtain desired result.assume lemma holds nodes depth k let c clique treenode depth k 1. first call (if any) made child node c0 looplines 1113, lemma applied. consequence, returned updated365fiPlanken, De Weerdt, & Van der Krogtpair valid. argument repeated loop ends procedurereturns valid pair.results disposal, state prove main theoremsection.Theorem 6. Algorithm6 ( SnowballSeparators) correctly computes all-pairs shortest pathsnwd2 + n2 sd time.Proof. Note Vvisited = call Processcliquetreenode line 9 SnowballSeparators; therefore, pair (D, Vvisited ) trivially valid. Lemma 5, call thusreturns valid updated pair (D, Vvisited ). Since Processcliquetreenode recursively traSversed entire clique tree, Vvisited contains union cC Vc cliques cliquetree = hC, Si, Property 5 equals set vertices G. Therefore,contains correct shortest paths pairs vertices graph.time complexity, note initialisations lines 3 4 carried2n time, whereas lines 5 6 require (mc ) time. Property 1,clique tree built linear time (mc ). Since clique tree containsn nodes,Processcliquetreenode called (n) times. Line 1 requires wd2 time. implementlines 24 10 Processcliquetreenode, represent characteristic functionVvisited array size n; using Vvisited instead Vcparent everywhere, simplyiterate (wd ) members Vc perform required computations.Now, complexity loop lines 58 remains shown. Note|Vsep | sd definition, |Vother | < n always. using observationn vertices graph appears Vnew exactly one invocation Processcliquetreenode (afterbecomes staunch member Vvisited ), obtain total time bound2n sd loop invocations.recursive description perhaps easier grasp satisfies claimedtime bounds, found efficiency benefited practice iterative implementation.also turns good heuristic first visit child nodes connected alreadyvisited subtree large separator, postponing processing children connectedsmall separator, set visited vertices still small. way, sumterms |Vsep Vvisited | kept low. implementation, therefore used priority queueclique nodes ordered separator sizes. Future research must point whetherfeasible determine optimal traversal clique tree within given time bounds.presented new algorithms proven correctness formal complexity, move empirical evaluation performance.4. Experimentsevaluate two algorithms together efficient implementations FloydWarshallJohnson Fibonacci heap5 across six different benchmark sets.65. Johnson used corrected Fibonacci heap implementation Fiedler (2008), since widelyused pseudocode Cormen, Leiserson, Rivest, Stein (2001) contains mistakes.6. Availablehttp://dx.doi.org/10.4121/uuid:49388c35-c7fb-464f-9293-cca1406edccf366fiComputing APSP Leveraging Low TreewidthTable 1: Properties benchmark setstypeChordalFigure 3Figure 4Scale-freeFigure 5Figure 6New YorkDiamondsJob-shopHTN#casesnwdsd2501301,0002143,12575,840499,49022,788637,00979995211799952111301601701304001211,0002501,0001083,9061112,751171,3215006251,99667,3602,1763,3301136,4221112,75132110,2207481,5998886415020025123331212880854138190240233112127properties test cases summarised Table 1. table lists numbertest cases, range number vertices n, edges m, induced width wd producedminimum degree heuristic, well size largest minimal separators sdgraphs. details different sets found below, one thingstands immediately sd often equal marginally smaller wd .However, median size minimum separator less 10 instances exceptconstructed chordal graphs.algorithms implemented Java went intensive profiling phase.7experiments run using Java 1.6 (OpenJDK-1.6.0.b09) server mode, IntelXeon E5430 CPUs running 64-bit Linux. Java processes allowed maximumheap size 4 GB, used default stack size. report measured CPU times,including time spent running triangulation heuristic ChleqAPSPSnowball. reported run times averaged 10 runs unique problem instance.Moreover, generated 10 unique instances parameter setting, obtained usingdifferent random seeds. Thus, reported statistic represents average 100 runs,unless otherwise indicated. Finally, graph instance ensured contain cyclesnegative weight.4.1 Triangulationdiscussed Section 2.2, finding optimal vertex ordering (with minimum inducedwidth) NP-hard, several efficient triangulation heuristics problem exist.ran experiments six different heuristics: minimum fill minimum degreeheuristics, static variants (taking account original graph), orderingproduced running maximum cardinality search (MCS) original graph,random ordering. these, except minimum fill, time complexities within boundrun time ChleqAPSP Snowball. found minimum degree heuristicgave average induced widths less 1.5% higher found minimum fill,7. implementations available binary formhttp://dx.doi.org/10.4121/uuid:776a266e-81c6-41ee-9d23-8c89d90b6992367fiPlanken, De Weerdt, & Van der KrogtTable 2: summed induced width, triangulation, total run time Snowballexperiments general (non-chordal) graphs show minimum degree heuristicbest choice.heuristicmin-fillmin-degreeMCSstatic min-fillstatic min-degreerandomPwd321,492326,222365,662388,569388,707505,844triangulation (s)1,204,3844981,5201,3871,3172,436Snowball (s)2,0473,1663,3482,7462,7485,179total (s)1,206,4313,6644,8684,1334,0647,615drastically lower run time. exorbitant time consumption minimumfill heuristic partially explained fact used LibTW package8compute ordering, whose implementation probably improved. However,also known literature theoretical bound minimum fill heuristicworse minimum degree (Kjrulff, 1990). heuristicsslower minimum degree, also yield induced width least 12% higher, resultinglonger total triangulation time longer total run time Snowball (see summaryresults benchmarks given Table 2). Again, confirms Kjrulffs earlierwork. experimental results included therefore show results basedminimum degree heuristic.4.2 Chordal Graphsevaluate performance new algorithms chordal graphs, construct chordalgraphs fixed size 1,000 vertices treewidth ranging 79 lessnumber vertices, thus yielding nearly complete graph high end.results experiment depicted Figure 3. this, figures, errorbars represent standard deviations measured run time instancessize. graphs induced width three quarters number vertices,Snowball significantly outperforms FloydWarshall (which yields expected horizontal line),overall run time new algorithms well Johnson acrossentire range. Figure 4 shows run times chordal graphs constant treewidthincreasing number vertices. Here, two new algorithms outperform Johnsonnearly order magnitude (a factor 9.3 Snowball around n = 1300), evenregarding FloydWarshall, confirming expectations based theoretical upper bounds.4.3 General Graphsgeneral, non-chordal graphs, expect theoretical analysis nwd2 time ChleqAPSP Snowball algorithms faster Johnson nm + n2 log n8. Available http://treewidth.com/.368fiComputing APSP Leveraging Low Treewidth100000time solve (ms, log scale)F-WJohnsonChleqSnowball1000010001001001000induced width (log scale)Figure 3: Run times generated chordal graphs fixed number 1000 verticesvarying treewidth.1e+06F-WJohnsonChleqSnowballtime solve (ms, log scale)1000001000010001003001000number vertices (log scale)3000Figure 4: Run times generated chordal graphs fixed treewidth 211.369fiPlanken, De Weerdt, & Van der Krogt100000F-WJohnsonChleqSnowballtime solve (ms, log scale)10000100010010100200300400500induced width600700800900Figure 5: Run times scale-free benchmarks graphs 1,000 vertices varyinginduced width.time bound wd low, Johnson faster sparse graphs (where low)large induced width wd . main question induced width changeoveroccurs. Regarding FloydWarshall n3 bound, expect larger nalways outperformed algorithms.4.3.1 Scale-Free GraphsScale-free networks networks whose degree distribution follows power law. is,large values k, fraction P (k) vertices network k connectionsvertices tends P (k) ck , constant c parameter . words,vertices many connections many vertices connections.property found many real-world graphs, social networksInternet. instances randomly generated Albert Barabasis (2002)preferential attachment method, iteration new vertex added graph,attached number existing vertices; higher degree existingvertex, likely connected newly added vertex. seeinduced width Johnson faster, compare run times generated graphs1,000 vertices. varying number attachments new vertex 2n/2, obtain graphs induced width ranging 88 866. graphs,induced width already quite large small attachment values: example,value 11, induced width already 500.results experiment found Figure 5. seeinduced width 350 (attachment value 5), Snowball efficient. higherinduced widths, Johnson becomes efficient; wd around 800, even FloydWarshallbecomes faster Snowball. consistent observation different anglemade Figure 6, induced width 150 200, number edges370fiComputing APSP Leveraging Low Treewidthtime solve (ms, log scale)10000F-WJohnsonChleqSnowball1000100300400500600700number vertices8009001000Figure 6: Run times scale-free benchmarks graphs induced widths 150 200varying vertex count.2,176 3,330 number vertices varied 250 1,000.see small graphs 350 vertices, Johnson fastest; Snowball overtakesit, around 750 vertices ChleqAPSP also faster Johnson (this holds resultssparse graph 1,000 vertices).Around mark 750 vertices, results show decrease run timeSnowball ChleqAPSP. artifact (preferential attachment) benchmarkgenerator. Since cannot generate scale-free graphs specific induced width,modify attachment value instead. turns out, graphs size oneattachment value yields induced width within desired range; graph size750, width high end interval, whereas graph size 800 nearlow end. explains reduced run time larger graph.scale-free networks, conclude Snowball fastest four algorithms induced width large (at one third number verticesbenchmark set). However, also observe structure scale-free networksparticularly high induced width relatively sparse graphs, exactlyvertices connections. Therefore, Snowball efficientrelatively small attachment values.4.3.2 Selections New York Road Networkinteresting artificially constructed graphs graphs based real networks,shortest path calculations relevant. first series based roadnetwork New York City, obtained DIMACS challenge website.9network large (with 264,346 vertices 733,846 edges) decided compute9. http://www.dis.uniroma1.it/~challenge9/371fiPlanken, De Weerdt, & Van der KrogtFigure 7: Coordinates vertices New York City input graph, examplesextent subgraphs respectively 250, 1000, 5000 vertices.1e+07F-WJohnsonChleqSnowballtime solve (ms, log scale)1e+06100000100001000100101001000number vertices (log scale)Figure 8: Run times New York benchmarks subgraphs varying vertex count.372fiComputing APSP Leveraging Low Treewidthshortest paths (induced) subgraphs varying sizes. obtained runningsimple breadth-first search random starting location desired numbervertices visited. extent subnetworks thus obtained illustratedthree different sizes Figure 7. results algorithms subgraphsfound Figure 8. observe ranking algorithms chordalgraphs fixed treewidth diamonds: FloydWarshall slowest n3run time, Johnson, ChleqAPSP, Snowball significantly fasterpredecessor. explained considering induced width graphs. Evenlargest graphs induced width around 30, considerably smallernumber vertices.4.3.3 STNs Diamondsbenchmark set based problem instances difference logic proposed Strichman,Seshia, Bryant (2002) also appearing smt-lib (Ranise & Tinelli, 2003),constraint graph instance takes form circular chain diamonds.diamond consists two parallel paths equal length starting single vertexending another single vertex. latter vertex, two paths start again, convergethird vertex. pattern repeated diamond chain; final vertexconnected first one. sizes diamond total numberdiamonds varied benchmarks.Problems class actually instances NP-complete Disjunctive TemporalProblem (DTP): constraints take form disjunction inequalities. DTPinstance, obtain STP instance (i.e. graph) randomly selecting one inequalitydisjunction. STP probably inconsistent, constraint graphcontains negative cycle; remedy modifying weights constraint edges.idea behind procedure structure graph still conforms typenetworks one might encounter solving corresponding DTP instance,run time algorithms mostly depends structure. Moreover, reduceinfluence randomized extraction procedure, repeat 10 different seeds.benchmark set, considered problem instances sizediamonds fixed 5 number varying. interesting property setgraphs generated sparse. ran experiments 130 graphs,ranging size 111 2751 vertices, induced width 2. induced widthclearly extremely small, translates ChleqAPSP Snowball considerablyfaster Johnson FloydWarshall, evidenced Figure 9.4.3.4 STNs Job-Shop Schedulinggenerated 400 graphs job-shop set instance real jobshop problem. instances type available smt-lib (Ranise & Tinelli,2003), larger range included benchmark collection. obtaingraphs job-shop instances, used extraction procedure describedprevious section. striking observation taken Figure 10difference Johnson two new algorithms quite pronounced,though Snowball consistently fastest three small margin. fact373fiPlanken, De Weerdt, & Van der Krogt100000F-WJohnsonChleqSnowballtime solve (ms, log scale)1000010001001011001000number vertices (log scale)Figure 9: Run times diamonds benchmarks graphs varying vertex count.10000F-WJohnsonChleqSnowballtime solve (ms, log scale)1000100101100number vertices (log scale)1000Figure 10: Run times job-shop benchmarks graphs varying vertex count.374fiComputing APSP Leveraging Low Treewidthmargin small likely due structure graphs, also reflectedrelatively high induced width. Note also run times FloydWarshallbetter graphs 160 vertices, larger graphs algorithmssignificantly faster.4.3.5 STNs HTNsFinally, consider benchmark set whose instances imitate so-called sibling-restrictedSTNs originating Hierarchical Task Networks. set therefore particularly interesting planning point view. graphs, constraints may occurparent tasks children, sibling tasks (Bui & Yorke-Smith, 2010).consider extension includes landmark variables (Castillo, Fernandez-Olivares, &Gonzalez, 2002) mimic synchronisation tasks different parts network, thereby cause deviation tree-like HTN structure. generateHTNs using following parameters: (i) number tasks initial HTN tree (fixed250; note tasks start end point), (ii) branching factor, determiningnumber children task (between 4 7), (iii) depth HTN tree(between 3 7), (iv) ratio landmark time points number tasksHTN, varying 0 0.5 step size 0.05, (v) probability constraintssiblings, varying 0 0.5 step size 0.05.settings result graphs 500 625 vertices, induced widthsvarying 2 128. Though induced width seems high light claimconstant, verified wd 2 branching factor + #landmarks + 1instances. Filling maximal values 7 125 respectively, find upperbound wd 140, well actual maximum encountered.Figure 11 shows results experiments function induced widthsgraphs. see larger induced widths, Johnson ChleqAPSPcome close. large induced widths found high landmark ratios 0.5.results indicate majority STNs stemming HTNs, Snowball significantlyefficient Johnson.4.4 SnowballSeparatorsSection 3.3 presented version Snowball improved worst-case run timevanilla Snowball taking advantage separators graph. section,discuss results experiments comparing two variants. First, turnattention benchmark problems regular graphs. results summarisedFigure 12. one see, SnowballSeparators actually performs strictly worse setsterms run-time performance compared original Snowball.However, seen Table 1, largest minimal separator often equalmarginally smaller induced width. Even though mayseparators large, many may substantially smaller (as noted above,instances median separator size 10), prompts us run experimentsinstances separator sizes artificially kept small. Indeed, foundcases SnowballSeparators shows improvement vanilla Snowball comparingnumber update operations performedi.e. lines 8 9 Snowball lines 6 7375fiPlanken, De Weerdt, & Van der KrogtF-WJohnsonChleqSnowballtime solve (ms, log scale)1000100100204060induced width80100120Figure 11: Run times HTN benchmarks graphs 500 625 verticesvarying induced width. point average instances induced width withinrange [5k, 5k + 4], k. results 5 11 instances per data point.100000SnowballSnowball-Septime solve (ms, log scale)10000chordal1000scale-freenydiamonds100htn10job shop11001000number vertices (log scale)Figure 12: Run times Snowball algorithms benchmark problem sets listedTable 1.376fiComputing APSP Leveraging Low Treewidth100000number updates (x1000, log scale)SnowballSnowball-SepDPCP3C10000100010050100150200250300induced width350400450Figure 13: Number distance matrix updates chordal instances 512 vertices,largest minimal separator size 2 varying treewidth. point represents 510 instances.Processcliquetreenode, along lines 3 4 DPC lines 5 6 P3 C. Onecase presented Figure 13. describes results collection chordalgraphs 512 vertices, largest minimal separator fixed size 2,treewidth varied 16 448. figure also includes results DPC P3 C,respective subroutines Snowball SnowballSeparators. graphs,SnowballSeparators performs strictly fewer update operations Snowball instances,although difference becomes smaller induced width increases. numberupdates shows distinct improvement Snowball, run times SnowballSeparatorsalgorithms show improvement. Instead, seen Figure 14,run times Snowball strictly better SnowballSeparators instances.Snowball even seen outperform P3 C better theoretical bound;reason adjacency matrix data structure used Snowball fast,adjacency list used P3 C, though staying within theoretical bound, inflicts largerconstant factor run time.experiments, conclude graphs sizes, additionalbookkeeping required SnowballSeparators outweighs potential improvementnumber distance matrix updates.4.5 Proper Upper Bound Run Timegeneral graphs, run time proposed algorithms depends induced width wdordering produced triangulation heuristic. induced width directmeasure input (graph), given upper bound run time quite proper.arrive proper bound, section aim relate run time treewidth,denoted w , property input. However, determining treewidth,377fiPlanken, De Weerdt, & Van der Krogt10000time solve (ms, log scale)SnowballSnowball-SepDPCP3C10001001050100150200250induced width300350400450Figure 14: Run times chordal instances 512 vertices, largest minimal separatorsize 2 varying treewidth. point represents 5 10 instances.NP-hard problem, intractable task benchmark problems used. thereforecompare measured induced width wd w , upper bound treewidth, lowerbound x w .10 unaware guarantee quality relative treewidtheither minimum degree triangulation heuristic lower bound used. However,calculate ratio wd /x get upper bound ratio wd /w .measure obtain upper bound run time expressed treewidth,least benchmark problems paper.results computations found Figure 15, plot ratiosNew York, HTN, scale-free job-shop benchmarks function lowerbound x. Using least-squares approach, fitted functions wd (x) = cxk (showingstraight line log-log plot) plotted data points. functions foundfitting, get k = 4.6 New York, k = 2.3 HTN, k = 0.98 job-shop,small multiplicative constants 0.012 < c < 1.62. one see plotted datapoints scale-free instances, amenable fit therefore omitfigure.decreasing trend job-shop data indicates quality triangulation(i.e. upper bound represented induced width) gradually increases: lowerupper bound always less factor 2 apart. Indeed, plot line representingfunction wd0 (x) = 2x (yielding horizontal line figure), find describescomfortable upper bound data points benchmark set.HTN data prompts us plot function wd00 (x) = 25 x2.5 , exponent slightlyhigher one found least-squares fit, tweaked slightly10. lower bound computed LibTW package; see http://treewidth.com/. usedMMD + Least-c heuristic.378firelative induced width (vs. lower bound)Computing APSP Leveraging Low TreewidthNew YorkHTNscale-freejob shop2x2/5x2.5842110100lower bound treewidthFigure 15: upper bound induced width relative treewidth determined experimentally comparing lower bound treewidth.multiplicative coefficient bring view. function plotted represents ampleupper bound HTN benchmarks (as well job-shop ones).fit data points New York benchmark good trendpoints clear, lower bound spans interval1 4. Therefore, cannot give upper bound set benchmarksacceptable level confidence.However, scale-free data points plotted, could fitted functionyielding straight line, mostly follow clear curving trend. hypothesisbehaviour quality upper lower bound deteriorates mostly middlesizes benchmarks; smaller larger scale-free graphs easier triangulate well.11give upper bound, could plot line outer hull data points; e.g.horizontal line represented wd (x) = 8x would work. pessimistic assumptionwould choose function highest slope, find upper boundwd00 (x) = 25 x2.5 , found HTN benchmarks, also works here.discussion,may concludebenchmarks ran except NewSnowballYork, wd (x) x2.5 turn w 2.5 ; run time algorithmsChleqAPSP instances therefore bounded n2 w 2.5 .conclude section, remark alternative triangulation heuristicwould use approximation algorithm bound induced widththeoretically determined. example, Bouchitte, Kratsch, Muller, Todinca (2004)give (log w ) approximation treewidth w . Using approximationwouldgive upper bound run time Snowball n2 w log w . However, run11. mirrors earlier observations authors.379fiPlanken, De Weerdt, & Van der Krogttime obtaining approximate induced width n3 log4 nw 5 log w highconstant well, work isfor nowmainly theoretical value.5. Related Workdense, directedgraphs real weights, state-of-the-art APSP algorithms run3n / logn time (Chan, 2005; Han, 2008). represent serious improvementn3 bound FloydWarshall profit fact graphsoccur practice, number edges significantly lower n2 .profit exactly algorithms sparse graphs aim achieve. Recently,improvement published nm + n2 log n algorithm based Johnsons (1977)Fredman Tarjans(1987) work: algorithm sparse directed graphs runningnm + n2 log log n time (Pettie, 2004). theory, algorithm thus fasterJohnson (in worst cases, large graphs) (n log n).12 However, currentlyimplementation exists (as confirmedpersonal communication Pettie, June2011). upper bound n2 wd run time Snowball smallerestablished upper bound induced width small (i.e. wd (log log n)),and, course, chordal graphs graphs constant treewidth.familiar one earlier work compute shortest paths leveraging lowtreewidth. Chaudhuri Zaroliagis (2000) presentalgorithm answering (point-towd3 .point) shortest path queries wd3 n log n preprocessing time query timedirect extension results APSP would imply run time n2 wd3 generalgraphs andO nmwd2 chordal graphs. result computing APSP general graphsn2 wd (nm) chordal graphs thus strict improvement.large part state-of-the-art point-to-point shortest paths focused roadnetworks (with positive edge weights). studies strong focus heuristics, ranging goal-directed search bi-directional search using creating hierarchicalstructure, see example (Geisberger, Sanders, Schultes, & Delling, 2008; Bauer, Delling,Sanders, Schieferdecker, Schultes, & Wagner, 2008). One hierarchical heuristicssimilarities idea using chordal graphs. heuristic called contraction.idea distinguish important (core) vertices, may possible end points,vertices never used start end point. latter verticesremoved (bypassed) one-by-one, connecting neighbours directly.restrictions input graphs shortest paths computed alsoassumed, sometimes lead algorithms tighter bounds.example,unweighted chordal graphs, APSP lengths determined n2 time (Balachandhran& Rangan, 1996; Han, Sekharan, & Sridhar, 1997) pairs distance two known.See (Dragan, 2005) overview unification approaches. Consideringplanar graphs, recent work shows APSP found n2 log2 n (Klein, Mozes,&2Weimann, 2010), improvement Johnson cases n log n .context planning scheduling, number similar APSP problems needcomputed sequentially, potentially allowing efficient approach using dynamic algorithms. Even Gazit (1985) provide method addition single edgerequire n2 steps, deletion n4 /m average. Thorup (2004) Deme12. explain use notation x (f (n)) Footnote 1 page 354.380fiComputing APSP Leveraging Low Treewidthtrescu Italiano (2006)later give alternative approach amortized run timen2 (log n + log2 n+m). Especially context planning scheduling, esnsential shortest paths time points maintained. Often, sufficientshortest paths selection pairs maintained. Above, already mentionedP3 C algorithm Planken et al. (2008) single-shot case; Planken et al. (2010)describe algorithm incrementally maintains property partial path consistencychordal graphs time linear number edges.6. Conclusions Future Workpaper give three algorithms computing all-pairs shortest paths, runtime bounded (i) n2 graphs constant treewidth, matching earlier resultsalso required n2 (Chaudhuri & Zaroliagis, 2000);(ii) (nm) chordal graphs, improving earlier nmwd2 ; (iii) n2 wd generalgraphs, showing23improvement previously known tightest bound n wd . bounds, wdinduced width ordering used; experimentally determined boundedtreewidth power 2.5 benchmarks.contributions obtained applying directed path consistency combinedknown graph-theoretic techniques, vertex elimination tree decomposition,computing shortest paths. supports general idea techniques may helpsolving graphically-representable combinatorial problems, main contributionarticle narrow, focusing improving state art single,important problem computing APSP.results extensive experiments make recommendationsalgorithm best suited type problems. small instances,FloydWarshall used; probably mostly thanks simplicity, yieldingstraightforward implementation low overhead. Snowball exploit factperfect elimination ordering efficiently found chordal graphs, makesefficient algorithm class graphs. experiments differenttypes general graphs, conclude Snowball consistently outperforms Johnson (andFloydWarshall), except induced width high. experiments also showSnowball always outperforms ChleqAPSP SnowballSeparators. Althoughlatter better bound run time, surprisingly actual performance worseSnowball instances benchmark sets. holds even instancesSnowballSeparators performs significantly fewer updates. Thus, concludeadditional bookkeeping required SnowballSeparators pay off.Regarding experiments, must noted that, although utmostobtain fair comparison, constant factor measurements depends significantway exact implementation details (e.g. whether lookup-table heap used),also put forward earlier work experimentally comparing shortest path algorithms (Mondou, Crainic, & Nguyen, 1991; Cherkassky, Goldberg, & Radzik, 1996).implementation higher constant factor Snowball algorithms may causedadhering object-oriented paradigm, i.e. inheriting DPC P3 C superclasses,choosing reuse code rather inlining method calls. Nonetheless, confidentgeneral trends identified hold independently details.381fiPlanken, De Weerdt, & Van der KrogtNote strictly speaking, algorithms introduced paper compute all-pairsshortest distances. one wants actually trace shortest paths, algorithmsextended keep track midpoint whenever distance matrix updated, likeone FloydWarshall. Then, pair vertices, actual shortest pathgraph traced (n) time.current implementation SnowballSeparators, used priority queue decideheuristically clique tree node visit next, giving precedence nodes connectedlarge separator part clique tree already visited. noted before, deferanswering question whether optimal ordering found efficiently future work.remark using minimum-degree heuristic triangulation provides Snowballnatural edge, delaying processing vertices number iterationsmiddle loop small k grows large.Cherkassky Goldberg (1999) compared several innovative algorithms singlesource shortest paths gave better efficiency standard BellmanFord algorithmpractice, worst-case bound (nm) run time. futurework, investigate clever improvements also exploited Snowball.SnowballSeparators improved way influence theoretical complexity may yield better performance practice. Iterating Votherseen reverse traversal part clique tree visited before, starting cs parent.Then, instead always using separator current clique node (containing k)parent previously visited vertices Vother , keep track smallestseparator encountered backwards traversal extra asymptotic cost. Sinceshown Table 1 largest minimal separator often hardly smallerinduced width, might well pay search smaller separators. plan implementimprovement near future.Another possible improvement suggested following observation DPC.variant DPC proposed edge directionality taken account:iteration k, neighbours i, j < k considered directed pathk j, resulting addition arc j. set added arcs would oftenmuch smaller twice number edges added standard DPC algorithm,graph produced directed variant would chordal, correctnessSnowball would impacted.Furthermore, would like also experimentally compare algorithms recentalgorithms Pettie (2004) algorithms graphs constant treewidth Chaudhuri Zaroliagis (2000) future work. addition, interested efficienttriangulation heuristics, triangulation heuristics guaranteed quality, ablegive guaranteed theoretical bound general graphs. Another direction, especiallyinteresting context planning scheduling, use ideas presenteddesign faster algorithm dynamic all-pairs shortest paths: maintaining shortest pathsedge deletions (or relaxations) additions (or tightenings).AcknowledgmentsRoman van der Krogt supported Science Foundation Ireland Grant number08/RFP/CMS1711.382fiComputing APSP Leveraging Low Treewidthoffer sincere gratitude reviewers comments, helped usimprove clarity article strengthen empirical results.article based conference paper title, receivedhonourable mention best student paper International Conference AutomatedPlanning Scheduling (Planken, de Weerdt, & van der Krogt, 2011).Appendix A. Johnsons Heapexperiments paper, presented results Johnsonusing Fibonacci2heap, theoretical bound nm + n log n time attained.practice, using binary heap theoretical bound (nm log n) time turnsefficient occasions, show results section.Figure 16 shows run times Johnson binary heap Fibonacciheap benchmark sets listed Table 1. diamonds, HTN, NewYork benchmarks binary heap percent faster Fibonacci heap,slope lines doubly logarithmic scale same, concludeaverage-case run time similar asymptotic behavior. However, larger job-shopproblems, binary heap factor 2 slower Fibonacci heap, chordalgraph benchmark problems even factor 10. benchmark problems scale-free graphsfixed number vertices help explaining difference.Figure 17, run time variants Johnson found scale-free graphs1,000 vertices, number edges varying 2,000 almost 80,000.Here, see sparsest scale-free graphs 2, 000 edges, binaryheap slightly faster, edges considered, using Fibonacci heapsignificantly outperforms using binary heap. particular, run time Fibonacciheap implementation increases slowly number edges, run timebinary heap increases much significantly. explained factrunning Dijkstras algorithm subroutine Johnson, update (candidate)shortest path done amortized constant time Fibonacci heap,binary heap worst-case cost (log n) time per update. number updatesbounded run Dijkstras algorithm, yielding bound (nm) updatesJohnson. binary heap (nm log n) bound accounts significant partrun time, Fibonacci heap operations (such extracting minimumelement heap) bigger relative contribution run time.Based results benchmark sets, conclude although Johnsonbinary heap help reducing actual run time sparse graphs, Johnson Fibonacciheap overall better choice large.383fiPlanken, De Weerdt, & Van der Krogt1e+07BinaryFibonaccitime solve (ms, log scale)1e+06chordal10000010000ny1000diamondsscale-free100htnjob shop1010100number vertices (log scale)1000Figure 16: Run times Johnson binary heap Fibonacci heapbenchmark problem sets listed Table 1.1e+07BinaryFibonaccitime solve (ms, log scale)1e+061000001000010001001020004000800016000number edges (log scale)3200064000Figure 17: Run times Johnson binary heap Fibonacci heap scale-freegraphs 1,000 vertices increasing number edges.384fiComputing APSP Leveraging Low TreewidthReferencesAlbert, R., & Barabasi, A.-L. (2002). Statistical Mechanics Complex Networks. ReviewsModern Physics, 74 (1), 4797.Arnborg, S., Corneil, D. G., & Proskurowski, A. (1987). Complexity Finding Embeddingsk -Tree. SIAM Journal Algebraic Discrete Methods, 8 (2), 277284.Balachandhran, V., & Rangan, C. P. (1996). All-pairs-shortest-length strongly chordalgraphs. Discrete applied mathematics, 69 (1-2), 169182.Bauer, R., Delling, D., Sanders, P., Schieferdecker, D., Schultes, D., & Wagner, D. (2008).Combining hierarchical goal-directed speed-up techniques Dijkstras algorithm. Experimental Algorithms (WEA 2008), Vol. 5038 LNCS, pp. 303318.Springer.Bodlaender, H. L. (1986). Classes graphs bounded tree-width. Tech. rep. RUU-CS86-22, Utrecht University.Bodlaender, H. L. (1996). Linear-Time Algorithm Finding Tree-DecompositionsSmall Treewidth. SIAM Journal Computing, 25 (6), 13051317.Bouchitte, V., Kratsch, D., Muller, H., & Todinca, I. (2004). Treewidth Approximations.Discrete Applied Mathematics, 136 (2-3), 183196.Bresina, J. L., Jonsson, A. K., Morris, P. H., & Rajan, K. (2005). Activity PlanningMars Exploration Rovers. Proc. 15th Int. Conf. Automated PlanningScheduling, pp. 4049.Bui, H. H., & Yorke-Smith, N. (2010). Efficient Variable Elimination Semi-StructuredSimple Temporal Networks Continuous Domains. Knowledge Engineering Review, 25 (3), 337351.Castillo, L., Fernandez-Olivares, J., & Gonzalez, A. (2002). Temporal Constraint NetworkBased Temporal Planner. Proc. 21st Workshop UK PlanningScheduling Special Interest Group, pp. 99109, Delft, Netherlands.Castillo, L., Fernandez-Olivares, J., & Gonzalez, A. (2006). Efficiently Handling TemporalKnowledge HTN planner. Proc. 16th Int. Conf. Automated PlanningScheduling, pp. 6372.Chan, T. (2005). All-Pairs Shortest Paths Real Weights n3 / log n Time.Algorithms Datastructures, LNCS, pp. 318324. Springer.Chaudhuri, S., & Zaroliagis, C. D. (2000). Shortest Paths Digraphs Small Treewidth.Part I: Sequential Algorithms. Algorithmica, 27 (3), 212226.Cherkassky, B. V., Goldberg, A. V., & Radzik, T. (1996). Shortest paths algorithms: theoryexperimental evaluation. Mathematical programming, 73 (2), 129174.Cherkassky, B. V., & Goldberg, A. V. (1999). Negative-cycle detection algorithms. Mathematical Programming, 85, 277311.Chleq, N. (1995). Efficient Algorithms Networks Quantitative Temporal Constraints.Proc. 1st Int. Workshop Constraint Based Reasoning, pp. 4045.385fiPlanken, De Weerdt, & Van der KrogtConrad, P. R., Shah, J. A., & Williams, B. C. (2009). Flexible execution planschoice. Proc. 19th Int. Conf. Automated Planning Scheduling.Cormen, T. H., Leiserson, C. E., Rivest, R. L., & Stein, C. (2001). Introduction Algorithms, 2nd edition. MIT Press.Dechter, R., Meiri, I., & Pearl, J. (1991). Temporal Constraint Networks. Artificial Intelligence, 49 (13), 6195.Demetrescu, C., & Italiano, G. F. (2006). Fully Dynamic All-Pairs Shortest PathsReal Edge Weights. Journal Computer System Sciences, 72 (5), 813837.Dijkstra, E. W. (1959). note two problems connexion graphs.. NumerischeMathematik, 1, 269271.Dragan, F. F. (2005). Estimating pairs shortest paths restricted graph families:unified approach. Journal Algorithms, 57 (1), 121.Even, S., & Gazit, H. (1985). Updating Distances Dynamic Graphs. Methods Operations Research, 49, 371387.Fiedler, N. (2008). Analysis Java implementations Fibonacci Heap. http://tinyurl.com/fibo-heap.Floyd, R. W. (1962). Algorithm 97: Shortest path. Communications ACM, 5 (6),345.Fredman, M., & Tarjan, R. E. (1987). Fibonacci Heaps Uses Improved NetworkOptimization Algorithms. Journal ACM, 34 (3), 596615.Geisberger, R., Sanders, P., Schultes, D., & Delling, D. (2008). Contraction hierarchies:Faster simpler hierarchical routing road networks. Proc. Int. WorkshopExperimental Algorithms, pp. 319333. Springer.Girvan, M., & Newman, M. E. J. (2002). Community Structure Social BiologicalNetworks. Proc. National Academy Sciences USA, 99 (12), 78217826.Golumbic, M. (2004). Algorithmic Graph Theory Perfect Graphs. Elsevier.Graham, R. L., Knuth, D. E., & Patashnik, O. (1989). Concrete Mathematics: FoundationComputer Science (1st edition). Addison-Wesley.Han, K., Sekharan, C. N., & Sridhar, R. (1997). Unified All-Pairs Shortest Path AlgorithmsChordal Hierarchy. Discrete Applied Mathematics, 77 (1), 5971.Han, Y. (2008). Note n3 / log n -time Algorithm All-Pairs Shortest Paths.Information Processing Letters, 105 (3), 114116.Heggernes, P. (2006). Minimal triangulations graphs: survey. Discrete Mathematics,306 (3), 297317. Minimal Separation Minimal Triangulation.Johnson, D. B. (1977). Efficient Algorithms Shortest Paths Sparse Networks. JournalACM, 24 (1), 113.Kjrulff, U. (1990). Triangulation Graphs - Algorithms Giving Small Total State Space.Tech. rep., Aalborg University.386fiComputing APSP Leveraging Low TreewidthKlein, P. N., Mozes, S., & Weimann, O. (2010). ShortestPaths Directed Planar GraphsNegative Lengths: Linear-space n log2 n -time Algorithm. ACM Transactions Algorithms, 6 (2), 118.Mondou, J. F., Crainic, T. G., & Nguyen, S. (1991). Shortest path algorithms: computational study C programming language. Computers & Operations Research,18 (8), 767786.Pettie, S. (2004). New Approach All-pairs Shortest Paths Real-weighted Graphs.Theoretical Computer Science, 312 (1), 4774.Planken, L. R., de Weerdt, M. M., & van der Krogt, R. P. J. (2008). P3 C: New AlgorithmSimple Temporal Problem. Proc. 18th Int. Conf. AutomatedPlanning Scheduling, pp. 256263.Planken, L. R., de Weerdt, M. M., & van der Krogt, R. P. J. (2011). Computing allpairs shortest paths leveraging low treewidth. Proc. 21st Int. Conf.Automated Planning Scheduling, pp. 170177.Planken, L. R., de Weerdt, M. M., & Yorke-Smith, N. (2010). Incrementally Solving STNsEnforcing Partial Path Consistency. Proc. 20th Int. Conf. AutomatedPlanning Scheduling, pp. 129136.Ranise, S., & Tinelli, C. (2003). SMT-LIB Format: Initial Proposal. Proc.Pragmatics Decision Procedures Automated Reasoning.Rose, D. J. (1972). Graph-Theoretic Study Numerical Solution Sparse PositiveDefinite Systems Linear Equations. Read, R. (Ed.), Graph theory computing,pp. 183217. Academic Press.Rossi, F., Venable, K. B., & Yorke-Smith, N. (2006). Uncertainty soft temporal constraint problems: general framework controllability algorithms fuzzycase. Journal AI Research, 27, 617674.Satish Kumar, T. K. (2005). Tractability Restricted Disjunctive Temporal Problems. Proc. 15th Int. Conf. Automated Planning Scheduling, pp.110119.Shah, J. A., & Williams, B. C. (2008). Fast Dynamic Scheduling Disjunctive TemporalConstraint Networks Incremental Compilation. Proc. 18th Int. Conf.Automated Planning Scheduling, pp. 322329.Stergiou, K., & Koubarakis, M. (2000). Backtracking algorithms disjunctions temporalconstraints. Artificial Intelligence, 120 (1), 81117.Strichman, O., Seshia, S. A., & Bryant, R. E. (2002). Deciding Separation FormulasSAT. Proc. 14th Int. Conf. Computer Aided Verification, Vol. 2404LNCS, pp. 209222. Springer.Tarjan, R. E., & Yannakakis, M. (1984). Simple Linear-time Algorithms Test ChordalityGraphs, Test Acyclicity Hypergraphs, Selectively Reduce Acyclic Hypergraphs. SIAM Journal Computing, 13 (3), 566579.387fiPlanken, De Weerdt, & Van der KrogtThorup, M. (2004). Fully-dynamic All-Pairs Shortest Paths: Faster Allowing NegativeCycles. Algorithm Theory, Vol. 3111 LNCS, pp. 384396. Springer.Warshall, S. (1962). Theorem Boolean Matrices. Journal ACM, 9 (1), 1112.388fiJournal Artificial Intelligence Research 43 (2012) 257-292Submitted 09/11; published 02/12Consistency Techniques Flow-Based Projection-Safe Global CostFunctions Weighted Constraint SatisfactionJ.H.M. LeeK.L. LeungJLEE @ CSE . CUHK . EDU . HKKLLEUNG @ CSE . CUHK . EDU . HKDepartment Computer Science EngineeringChinese University Hong KongShatin, N.T., Hong KongAbstractMany combinatorial problems deal preferences violations, goal findsolutions minimum cost. Weighted constraint satisfaction framework modelingproblems, consists set cost functions measure degree violation preferences different combinations variable assignments. Typical solution methods weightedconstraint satisfaction problems (WCSPs) based branch-and-bound search, madepractical use powerful consistency techniques AC*, FDAC*, EDAC*deduce hidden cost information value pruning search. techniques, however,designed efficient binary ternary cost functions represented tableform. tackling many real-life problems, high arity (or global) cost functions required.investigate efficient representation scheme algorithms bring benefits consistencytechniques also high arity cost functions, often derived hard global constraintsclassical constraint satisfaction.literature suggests global cost functions represented flow networks,minimum cost flow algorithm used compute minimum costs networkspolynomial time. show naive adoption flow-based algorithmic method globalcost functions result stronger form -inverse consistency. showmethod modified handle cost projections extensions maintain generalized versionsAC* FDAC* cost functions two variables. Similar generalizationstronger EDAC* less straightforward. reveal oscillation problem enforcingEDAC* cost functions sharing one variable. avoid oscillation, propose weakversion EDAC* generalize weak EDGAC* non-binary cost functions. Using variousbenchmarks involving soft variants hard global constraints IFFERENT, GCC, SAME,REGULAR, empirical results demonstrate proposal gives improvementsorder magnitude compared traditional constraint optimization approach,terms time pruning.1. IntroductionConstraint satisfaction problems (CSPs) occur walks industrial applications computerscience, scheduling, bin packing, transport routing, type checking, diagram layout,name few. Constraints CSPs functions returning true false. constraintshard sense must satisfied. over-constrained optimization scenarios, hardconstraints relaxed softened. weighted constraint satisfaction framework adoptsoft constraints cost functions returning non-negative integer upper bound . Solution techniques solving weighted constraint satisfaction problems (WCSPs) made practic2012AI Access Foundation. rights reserved.fiL EE & L EUNGcal enforcing various consistency notions branch-and-bound search, NC*, AC*,FDAC* (Larrosa & Schiex, 2004, 2003) EDAC* (de Givry, Heras, Zytnicki, & Larrosa, 2005).enforcement techniques, however, designed efficient binary ternary costfunctions represented table form. hand, many real-life problemsmodelled naturally global cost functions high arities. investigate efficient representationscheme algorithms bring benefits existing consistency techniques binaryternary cost functions also high arity cost functions, often derived hard globalconstraints classical constraint satisfaction.existing WCSP solvers, high arity cost functions delayed become binaryternary search. size tables also concern. lack efficient handlinghigh arity global cost functions WCSP systems greatly restricts applicability WCSPtechniques complex real-life problems. overcome difficulty, incorporate van Hoeve, Pesant, Rousseaus (2006) flow-based algorithmic method WCSPs, amountsrepresenting global cost functions flow networks computing minimum costsnetworks using minimum cost flow algorithm. show naive incorporation global costfunctions WCSPs would result strong form -inverse consistency (Zytnicki, Gaspin,& Schiex, 2009), still relatively weak terms lower bound estimation pruning.question whether achieve stronger consistencies GAC* FDGAC*,generalized versions AC* FDAC* respectively, non-binary cost functions efficiently.Consistency algorithms (G)AC* FD(G)AC* involve three main operations: (a) computingminimum cost cost functions variable x fixed value v, (b) projectingminimum cost cost function unary cost functions x value v, (c) extendingunary costs related high arity cost functions. operations allow cost movements amongcost functions shifting costs increase global lower bound problem, implies opportunities domain value prunings. Part (a) readily handled using minimumcost flow (MCF) algorithm proposed van Hoeve et al.s method. However, parts (b) (c)modify cost functions, possibly destroy required flow-based structure costfunctions required van Hoeve et al.s method. overcome difficulty, propose givesufficient conditions flow-based projection-safety property. global cost function flowbased projection-safe, flow-based property cost function guaranteed retainedmatter many times parts (b) (c) performed. Thus, MCF algorithm appliedthroughout enforcements GAC* FDGAC* increase search efficiency.natural next step generalize also stronger consistency EDAC* (de Givry et al., 2005)EDGAC*, turns non-trivial. identify analyze inherent limitationEDAC* similar case Full AC* (de Givry et al., 2005). ED(G)AC* enforcementgo oscillation two cost functions share one variable, commonproblem involves high arity cost functions. Sanchez, de Givry, Schiex (2008) mentionoscillation problem method enforcing EDAC* special case ternary costfunctions would avoid oscillation problem. paper, give weak form EDAC*,generalized weak EDGAC* cost functions arity. importantly, weakEDAC* reduced EDAC* two cost functions share one variable. WeakEDGAC* stronger FDGAC* GAC*, weaker VAC (Cooper, de Givry, Sanchez,Schiex, Zytnicki, & Werner, 2010). also give efficient algorithm enforce weak EDGAC*.Based theoretical results, prove soft variants IFFERENT,GCC, SAME, REGULAR constraints flow-based projection-safe, give polynomial time258fiC ONSISTENCY ECHNIQUESOFT G LOBAL C OST F UNCTIONSWCSPalgorithms enforce GAC*, FDGAC* also weak EDGAC* cost functions. Experiments carried different benchmarks featuring proposed global cost functions. Empirical results coincide theoretical prediction relative strengths various consistency notions complexities enforcement algorithms. experimental results alsoconfirm stronger consistencies GAC*, FDGAC* weak EDGAC* worthwhileessential making global cost functions WCSP practical. addition, reified approach(Petit, Regin, & Bessiere, 2000) strong IC weak estimating useful lower boundspruning search space branch-and-bound search.rest paper organized follows. Section 2 gives necessary definitionsbackground, Section 3 gives related work. Generalized versions existing consistency techniques global cost functions presented compared Section 4. Enforcement algorithmsconsistencies exponential general. introduce notion flow-based projectionsafety, describe polynomial time consistency enforcement algorithms global cost functionsenjoying flow-based projection-safety property. Section 5, prove softened formcommon hard global constraints flow-based projection-safe give experimental resultsdemonstrating feasibility efficiency proposal terms runtime searchspace pruning. Section 6 summarizes contributions shed light possible directionsfuture research.2. Backgroundgive preliminaries weighted constraint satisfaction problems, global cost functionsnetwork flows.2.1 Weighted Constraint Satisfactionweighted constraint satisfaction problem (WCSP) special case valued constraint satisfaction (Schiex, Fargier, & Verfaillie, 1995) cost structure ([0, . . . , ], , ). structurecontains set integers 0 ordered standard ordering . Addition definedb = min(, + b), subtraction defined b, b = b 6== a. Formally,Definition 1 (Schiex et al., 1995) WCSP tuple (X , D, C, ), where:X set variables {x1 , x2 , . . . , xn } ordered indices;set domains D(xi ) xi X , one value assigned xi ;C set cost functions WS different scope = {xs1 , . . . , xsn } X mapstuple L(S), L(S) = D(xs1 ) . . . D(xsn ), [0, . . . , ].assignment set variables X , written {xs1 7 vs1 , . . . , xsn 7 vsn },assign variable xsi value vsi D(xsi ). context clear assumingordering variable indices, abuse notations considering assignment also tuple= (vs1 , . . . , vsn ) L(S), L(S) = D(xs1 ) D(xs2 ) . . . D(xsn ). notation [xsi ]denotes value vsi assigned xsi S, [S ] denotes tuple formed projecting ontoS.Without loss generality, assume C = {W } {Wi | xi X } C + . W constantnullary cost function. Wi unary cost function associated xi X . C + set cost259fiL EE & L EUNGfunctions WS scope containing two variables. W {Wi } defined,assume Wi (v) = 0 v D(xi ) W = 0. simplify notation, denote Ws1 ,s2 ,...,sncost function variables {xs1 , xs2 , . . . , xsn } context clear.DefinitionL 2 Given WCSPL(X , D, C, ). cost tuple L(X ) defined cost() =W xi X Wi ([xi ]) WS C + WS ([S]). tuple L(X ) feasible cost() < ,solution WCSP cost() minimum among tuples L(X ).WCSPs usually solved basic branch-and-bound search augmented consistencytechniques prune infeasible values variable domains push costs Wpreserving equivalence problems, i.e. cost tuple L(X ) unchanged.Different consistency notions defined NC*, AC*, FDAC* (Larrosa & Schiex,2004, 2003), EDAC* (de Givry et al., 2005).Definition 3 variable xi node consistent (NC*) value v D(xi ) satisfies Wi (v)W < exists value v D(xi ) Wi (v ) = 0. WCSP NC* iffvariables NC*.Procedure enforceNC*() Algorithm 1 enforces NC*, unaryProject() moves unarycosts towards W keeping solution unchanged, pruneVal() removes infeasiblevalues. variables Q, R, global propagation queues used consistencyenforcements explained later sections. initially empty specified.1234567891011121314Procedure enforceNC*()foreach xi X unaryProject (xi );pruneVal ();Procedure unaryProject(xi):= min{Wi (v) | v D(xi )};W := W ;foreach v D(xi ) Wi (v) := Wi (v) ;Procedure pruneVal()foreach xi Xflag := false;foreach v D(xi ) s.t. Wi (v) W =D(xi ) := D(xi ) \ {v};flag := true;flag// consistency enforcement.empty specifiedQ := Q {xi };:= {xi };R := R {xi };Algorithm 1: Enforce NC*260Assume initiallyfiC ONSISTENCY ECHNIQUESOFT G LOBAL C OST F UNCTIONSWCSPBased NC*, AC* FDAC* developed binary (Larrosa & Schiex, 2004,2003) ternary cost functions (Sanchez et al., 2008). Enforcing consistency notions requires two equivalence preserving transformations besides NC* enforcement, namely projectionextension (Cooper & Schiex, 2004).projection, written Project(WS ,Wi ,v,), transforms (WS , Wi ) (WS , Wi )respect value v D(xi ) cost , min{WS () | [xi ] = v L(S)},that:Wi (u) u = v,Wi (u) =Wi (u)otherwise.WS () [xi ] = v,WS () =WS ()otherwise.extension, written Extend(WS ,Wi ,v,), transforms (WS , Wi ) (WS , Wi )respect value v D(xi ) cost , Wi (v), that:Wi (u) u = v,Wi (u) =Wi (u)otherwise.WS () [xi ] = v,WS () =WS ()otherwise.2.2 Global Constraints Global Cost Functionsglobal constraint constraint special semantics. usually high arity, thuscannot propagated efficiently standard consistency algorithms. special semantics,special propagation algorithms designed achieve efficiency.global cost function soft variant hard global constraint. cost tupleindicates much tuple violates corresponding global constraint. One global constraintgive rise different global cost functions using different violation measures. global costfunction returns 0 tuple satisfies corresponding global constraint. notation SOFT GCdenotes global cost function derived global constraint GC using violation measure .instance, IFFERENT constraint two soft variants.Definition 4 (Petit, Regin, & Bessiere, 2001) cost function SOFT IFFERENTvar returnsminimum number variable assignments needed changed tuple containsdistinct values; SOFT IFFERENTdec returns number pairs variablesassigned value.2.3 Flow TheoryDefinition 5 flow network G = (V, E, w, c, d) connected directed graph (V, E),edge e E weight , capacity ce , demand de ce .(s, t)-flow f source V sink V value G defined mappingE real numbers that:PP(s,u)E f(s,u) =(u,t)E f(u,t) = ;PP(u,v)E f(u,v) =(v,u)E f(v,u) v V \ {s, t};261fiL EE & L EUNGde fe ce e E.simplicity, call (s, t)-flow flow specified.PDefinition 6 cost flow f defined cost(f ) =eE fe . minimum cost flowproblem value find flow whose value cost minimum.given, assumed maximum value among flows.solve minimum cost flow problems, various approaches developed. Twosuccessive shortest path cycle-cancelling algorithms (Lawler, 1976). algorithmsfocus computation residual network corresponding flow network.Definition 7 Given flow f network G = (V, E, w, c, d). residual network Gres =(V, E res , wres , cres , dres ) defined as:E res = {(u, v) e | f(u,v) < c(u,v) } {(v, u) e | f(u,v) > d(u,v) };,if f(u,v) < c(u,v)w(u,v)resw(u,v) =w(u,v) ,if f(v,u) > d(v,u)c(u,v) f(u,v) ,if f(u,v) < c(u,v)cres(u,v) =f(u,v) d(u,v) ,if f(v,u) > d(v,u)drese = 0, e E;successive shortest path algorithm successively increases flow values edges alongshortest paths residual network value flow reachespaths found. cycle-cancelling algorithm reduces cost given flow minimumremoving negative cycles induced residual network.consistency enforcement flow, usually deal following problem: consider(s, t)-flow f network G = (V, E, w, c, d) minimum cost, edge e E. problemdetermine whether increasing (or decreasing) fe one unit keeps flow value unchanged,compute minimal cost new resultant flow possible. Again, problemsolved using residual network Gres (Regin, 2002; van Hoeve et al., 2006): computeshortest path P v u Gres , e = (u , v ) E. P exists, value flowunchanged fe increased one unit. new minimum cost computed followingtheorem.flow increasing feTheorem 1 (Regin, 2002; van Hoeve et al., 2006) Suppose f resultantPone unit. minimum value cost(f ) cost(f ) + weres + eP weres .Theorem 1 reduces problem finding shortest path v u , madeincremental consistency enforcement. want reduce unit flow edge,apply similar methods used Theorem 1.3. Related WorkGlobal cost functions handled using constraint optimization, focuses efficientcomputation min{WS () | L(S)} enforcing GAC hard constraint formsWS () zS , zS variable storing costs (Petit et al., 2001). Van Hoeve et al. (2006)262fiC ONSISTENCY ECHNIQUESOFT G LOBAL C OST F UNCTIONSWCSPdevelop framework global cost functions representable flow networks, whose computationpolynomial size networks. Beldiceanu (2000) Beldiceanu, Carlsson Petit (2004)develop representation scheme global cost functions using graph-based approachautomaton approach. framework, computation global cost functionsreduced considering fixed set global cost functions, e.g. SOFT REGULAR functions.hand, efficiently remove search space WCSPs solving, variousconsistency notions developed. Examples NC* (Larrosa & Schiex, 2004), BAC(Zytnicki et al., 2009), AC* (Larrosa & Schiex, 2004), FDAC* (Larrosa & Schiex, 2003),EDAC* (de Givry et al., 2005). Stronger consistency notions, namely OSAC VAC (Cooperet al., 2010), also defined, enforcement requires relaxation cost valuation structureV () rational numbers, current implementations efficient binary WCSPs.ternary cost functions, AC, FDAC EDAC introduced (Sanchez et al., 2008). Cooper (2005)incorporates concept k-consistency WCSPs form complete k-consistency. However,time space complexities increase exponentially problem size increases, making complete k-consistency impractical enforce general WCSPs.4. Consistency Notions Global Cost Functionssection, discuss four consistency notions high-arity cost functions: (1) strong inverse consistency (strong IC), (2) generalized arc consistency (GAC*), (3) full directional generalized arc consistency(FDGAC*), (4) generalized EDAC*. consistency notions requireexponential time enforce general, flow-based global cost functions (van Hoeve et al., 2006)enjoy polynomial time enforcement.4.1 Strong -Inverse ConsistencyStrong -inverse consistency based -inverse consistency (IC) (Zytnicki et al., 2009).Definition 8 (Zytnicki et al., 2009) Given WCSP P = (X , D, C, ). cost function WS C-inverse consistent (IC) exists tuple L(S) WS () = 0. WCSP ICiff cost functions IC.procedure enforceIC() Algorithm 2 enforces IC. cost function WS madeIC lines 3 6, move costs WS W simple arithmetic operations.1234567Function enforceIC()flag := false;foreach WS C:= min{WS () | L(S)};W := W ;foreach L(S) WS () := WS () ;> 0 flag := true;return flag;Algorithm 2: Enforcing IC WCSPtime complexity enforceIC() Algorithm 2 depends time complexitieslines 3 5. Line 3 computes minimum cost line 5 modifies cost tuple263fiL EE & L EUNGmaintain equivalence. general, two operations exponential arity costfunction. However, first operation reduced polynomial time global cost function.One example flow-based global cost functions (van Hoeve et al., 2006).Definition 9 (van Hoeve et al., 2006) global cost function WS flow-based WS represented flow network G = (V, E, w, c, d)min{cost(f ) | f max. {s, t}-flow G} = min{WS () | L(S)},V fixed source V fixed destination.examples, cost function SOFT IFFERENTdec (S) returns number pairsvariables share value, shown flow-based (van Hoeve et al., 2006).example corresponding flow network, = {x1 , x2 , x3 , x4 }, shown Figure 1.edges capacity 1. numbers edges represent weight edges. edgenumber, edge zero weight. thick lines show flow corresponding tuple= (a, c, b, b) cost 1.x1x2b12x3c1x4Figure 1: example flow network SOFTIFFERENTdecflow-based cost functions, first operation (computing minimum cost) reduced time polynomial network size constraints. second operationreduced constant time using data structure suggested Zytnicki et al. (2009). Insteaddeducting projected value tuple WS , simply store projected value .want know actual value WS , compute WS .Enforcing IC increases W help reduce domain size. Consider WCSPFigure 2. IC, value c D(x1 ) cannot part feasible tuple. tuplesassociated assignment {x1 7 c} must cost least 4: 1 W , 2 W1 ,1 W1,2 . allow domain reduction, extra conditions added IC form strong IC.x1bcW1022x2b= 4, W = 1x1 x2 W1,2W201b00c1x1bcFigure 2: WCSP IC264x2bbbW1,2001fiC ONSISTENCY ECHNIQUESOFT G LOBAL C OST F UNCTIONSWCSPDefinition 10 Given WCSP P = (X , D, C, ). Consider non-unary cost function WS C +variable xi S. tuple L(S) -support value v D(xi ) respect WSiff [xi ] = v W Wi (v) WS () < . cost function WS strong IC iff IC,value variable -support respect WS . WCSP strong ICIC non-unary cost functions strong IC.instance, WCSP Figure 2 strong IC. value c D(x1 ) support, since W W1 (c) min{W1,2 () | [x1 ] = c L({x1 , x2 })} = = 4. Removalc D(x1 ) makes so.Strong IC collapses GAC classical CSPs WCSPs collapse CSPs. Althoughdefinition similar BAC (Zytnicki et al., 2009), strengths incomparable. BACgathers cost information cost functions boundary values, considerinformation one non-unary cost function individual values.procedure enforceSIC() Algorithm 3 enforces strong IC, based W-AC*3()Algorithm (Larrosa & Schiex, 2004). algorithm maintains propagation queue Q variables.Cost functions involving variables Q potentially strong IC. iteration, arbitrary variable xj removed Q function pop() constant time. algorithm enforcesstrong IC cost functions involving xj lines 4 6. existence -supportenforced findSupport(). domain reduction occurs (findSupport() returns true),W increases (enforceIC() returns true), variables pushed onto Q lines 6 7 respectively, indicating IC potentially broken. algorithm terminates, i.e. Q = ,variables pushed Q line 6, Q set X line 7. implies variables strongIC WCSP IC. Thus WCSP strong IC execution.1234567891011121314Procedure enforceSIC()Q := X ;Q 6=xj := pop (Q);foreach WS C + s.t. xjforeach xi \ {xj }findSupport (WS , xi ) Q := Q {xi };enforceIC () Q := X ;Function findSupport(WS , xi )flag := false;foreach v D(xi ):= min{WS () | [xi ] = v};W Wi (v) =D(xi ) := D(xi ) \ {v};flag := true;return flag;Algorithm 3: Enforcing strong IC WCSPprocedure enforceSIC() correct must terminate. complexity analyzedabstracting worst-case time complexities findSupport() enforceIC()265fiL EE & L EUNGfstrong fIC respectively. Using augment similar proof Larrosa Schiexs(2004) Theorems 12 21, complexity stated follows.Theorem 2 procedure enforceSIC() time complexity O(r 2 edfstrong +ndfIC ),r maximum arity cost functions, maximum domain size, e = |C + | n = |X |.Proof: loop line 2 iterates O(nd) times. iteration, line 6 executesO(r |N (j)|) times, N (j) set soft constraints restrictingxj . Since line 7 exePcutes O(nd) times, overall time complexity O(rdfstrong nj=1 |N (j)| + ndfIC ) =PnO(r 2 edfstrongPn + ndfIC ). O( j=1 |N (j)|) = O(re) holds since cost function countsr times j=1 |N (j)|. Thus, must terminate.Corollary 1 procedure enforceSIC() must terminate. resultant WCSP strong IC,equivalent original WCSP.general, due enforceIC() findSupport(), enforcing strong IC exponential r. discussed before, enforceIC() reduced polynomial time flow-basedglobal cost functions. Similarly, findSupport() executed efficiently incrementallyflow-based global cost functions since line 10 computed polynomial time using minimum cost flow.Another property interested confluence. consistency confluent enforcingalways transforms problem P unique problem P . AC* confluent (Larrosa& Schiex, 2004). different variable and/or cost function orderings, AC* enforcement leaddifferent equivalent WCSPs different values W . BAC confluent (Zytnicki et al.,2009). Following proofs Propositions 3.3 4.3 Zytnicki et al., shownstrong IC also confluent.Theorem 3 (Confluence) Given WCSP P = (X , D, C, ), exists unique WCSP P =(X , , C , ) strong IC equivalent P .concludes theoretical analysis strong IC. following, comparestrength strong IC classical consistency notions used constraint optimization. Following Petit et al. (2000), define reified form WCSP follows:Definition 11 (Petit et al., 2000) Given WCSP P = (X , D, C, ). reified form, reified(P ),P constraint optimization problem (COP) (X h , h , C h , obj), where:X h = X Z, Z = {zS | WS C \ {W }} cost variables.h (xi ) = D(xi ) xi X , h (zS ) = {0, . . . , W 1} zS Z.W < 1, h (zS ) = .hC h contains reified constraints CS{z, hard constraints associatedS}hhWS C \ {WL } defined WS () zS tuple L(S). C also contains CZdefined W zS Z zS < .Lobjective minimize obj, obj = W zS Z zS .266fiC ONSISTENCY ECHNIQUESOFT G LOBAL C OST F UNCTIONSWCSPFinding optimal solution reified(P ) equivalent solving P . However, enforcing GACreified(P ) cannot remove values enforcing strong IC P . strongIC P implies GAC reified(P ) vice versa.general, define strength comparison follows.Definition 12 Given problem P representable two models (P ) (P ). consistency(P ) strictly stronger another consistency (P ), written (P ) > (P ),> (P ) = (P ), iff (P ) whenever (P ) , vice versa.Zytnicki et al. (2009) also define consistency strength comparison terms unsatisfiability detection, subsumed new definition. (P ) implies (P ), enforcing(P ) detects unsatisfiability, enforcing (P ) detect unsatisfiability well.Given WCSP P = (X , D, C, ). show strong IC P stronger GACreified(P ) following theorem.Theorem 4 Strong IC P > GAC reified(P ).Proof: Figure 2 given example WCSP whose reified COP GAC may strongIC. show strong IC P implies GAC reified(P ).First, CZh GAC. |C| 1, constraint obviously GAC. |C| > 1, vSi D(zSi ),satisfy constraint, let cost variables take value 0, i.e. supportsvSi D(zSi ) exist.hBesides, CS{zGAC. definition IC, exists tuple L(S)S}hWS ( ) = 0. tuple form support vS D(zS ) respect CS{z. Besides,S}-support v D(xi ), together vS = WS ( ), forms support v D(xi ).detailed comparison strong IC WCSPs GAC reified approach,readers refer work Leung (2009).cost functions binary, strong IC cannot stronger AC*. next section,show fact proving GAC*, generalized version AC*, stronger strong IC.4.2 Generalized Arc ConsistencyDefinition 13 (Cooper & Schiex, 2004) Given WCSP P = (X , D, C, ). Consider cost functionWS C + variable xi S. tuple L(S) simple support v D(xi ) respectWS xi iff [xi ] = v WS () = 0. variable xi star generalized arc consistent(GAC*) respect WS iff xi NC*, value vi D(xi ) simple supportrespect WS . WCSP GAC* iff variables GAC* respect related non-unarycost functions.definition designed practical considerations, slightly weakerLDefinition 4.2work Cooper et al. (2010), also requires WS () = W xi Wi ([xi ])WS () = .GAC* collapses AC* binary cost functions (Larrosa & Schiex, 2004) AC ternarycost functions (Sanchez et al., 2008). GAC* stronger strong IC, WCSP GAC*also strong IC, vice versa. state without proof follows.Theorem 5 GAC* > strong IC.267fiL EE & L EUNGprocedure enforceGAC*() Algorithm 4 enforces GAC* WCSP (X , D, C, ),based W-AC*3() Algorithm (Larrosa & Schiex, 2004). propagation queue Q stores setvariables xj . xj Q, variables involved cost functions xj potentiallyGAC*. Initially, variables Q. variable xj pushed Q valuesremoved D(xj ). iteration, arbitrary variable xj removed queuefunction pop() line 4. function findSupport() line 7 enforces GAC* xirespect WS finding simple supports. infeasible values removed functionpruneVal() line 10. value removed D(xi ), simple supports relatedvariables may destroyed. Thus, xi pushed back Q procedure pruneVal().GAC*() terminates, values variable domain must simple support. WCSPGAC*.123456789101112131415161718Procedure enforceGAC*()Q := X ;GAC* ();Procedure GAC*()Q 6=xj := pop (Q);foreach WS C + s.t. xjforeach xi \ {xj }findSupport (WS , xi )// consistency enforcement.initially empty specified:= {xi };R := R {xi };AssumepruneVal ();Function findSupport(WS , xi )flag := false;foreach v D(xi ):= min{WS () | [xi ] = v};Wi (v) = 0 > 0 flag := true;Wi (v) := Wi (v) ;foreach L(S) s.t. [xi ] = WS () := WS () ;unaryProject (xi );return flag;Algorithm 4: Enforcing GAC* WCSPprocedure enforceGAC*() Algorithm 4 correct must terminate. proofsimilar Theorem 2. replacing fstrong fGAC (the worst-case time complexitiesfindSupport()) fIC O(nd) (the complexity pruneVal()), complexityAlgorithm 4 stated follows.Theorem 6 procedure enforceGAC*() time complexity O(r 2 edfGAC +n2 d2 ),n, d, e, r defined Theorem 2.268fiC ONSISTENCY ECHNIQUESOFT G LOBAL C OST F UNCTIONSWCSPCorollary 2 procedure enforceGAC*() must terminate. resultant WCSP GAC*,equivalent original WCSP.general, procedure enforceGAC*() exponential maximum arity costfunction due findSupport(). function findSupport() consists two operations: (1)finding minimum cost tuple associated {xi 7 v} line 13, (2) performingprojection lines 15 16. time complexity first operation polynomial flowbased global cost function WS . method introduced van Hoeve et al. (2006) appliedfirst operation discussed Section 4.1. However, second operation modifies WS WS ,requires changing costs exponential number tuples. Cooper Schiex (2004)use similar technique one Zytnicki et al. (2009) (similar technique describedSection 4.1) make modification constant time. However, resulting WS may flowbased, affecting time complexity subsequent procedure calls. resolve issue,introduce flow-based projection-safety. WS flow-based projection-safe, flow propertymaintained throughout enforcement.Definition 14 Given property . global cost function WS projection-safe iff WS satisfiesproperty , WS derived WS series projections extensions, WS alsosatisfies .words, projection-safe cost function WS still satisfies numbers projections extensions. facilitates use derive efficient consistency enforcementalgorithms. following, consider special form projection-safety,flow-based property.following, first define FB, show FB sufficient condition flow-basedprojection-safety.Definition 15 global cost function satisfies FB if:1. WS flow-based, corresponding network G = (V, E, w, c, d) fixed sourceV fixed destination V ;2. exists subjective function mapping maximum flow f G tuple fL(S), and;3. exists injection mapping assignment {xi7 v} aPsubset edges E EallPmaximum flow f corresponding tuple f , eE fe = 1 wheneverf [xi ] = v, eE fe = 0 whenever f [xi ] 6= vLemma 1 Given WS satisfying FB. Suppose WS obtained Project(WS ,Wi ,v,)Extend(WS ,Wi ,v,). WS also satisfies FB.Proof: prove part projection, since proof extension similar. first showWS flow-based (condition 1). Assume G = (V, E, w, c, d) corresponding flow networkWS . projection, G modified G = (V, E, w , c, d), w (e) = w(e)e E edge corresponding {xi 7 v} w (e) = w(e) otherwise. resulting G269fiL EE & L EUNGcorresponding flow network WS , since maximum flow f G minimum cost:Xfe =eEXfeeEXfeeE= min{WS () | L(S)}XfeeE= min{WS () | L(S)}.Moreover, since topology G = (V, E, w , c, d) G = (V, E, w, c, d),WS also satisfies conditions 2 3.Theorem 7 global cost function WS satisfies FB, WS flow-based projection-safe.Proof: Initially, projection extension performed, directly Definition 15, WSflow-based. Assume WS cost function formed WS series projections and/orextensions. Lemma 1, WS still satisfies FB thus flow-based. Result follows.shown Theorem 7, global cost function flow-based projection-safe, alwaysflow-based projections and/or extensions. Besides, checking conditions Definition15, determine whether global cost function flow-based projection-safe.Note computation proof performed standard integer set insteadV () practical considerations. investigation required computation restricted V ().using Theorem 7, apply results van Hoeve et al. (2006) compute valuemin{WS () | [xi ] = v L(S)} polynomial time throughout GAC* enforcement. Besides,proof gives efficient algorithm perform projection polynomial time simply modifyingweights corresponding edges.Again, use SOFT IFFERENTdec example. Van Hoeve et al. (2006) shownSOFT IFFERENTdec (S) satisfies conditions 1 2 Definition 15. Besides,network structure shown Figure 1, taking E = {(xi , v)} assignment {xi 7 v},condition 3 satisfied. Thus, SOFT IFFERENTdec flow-based projection-safe.x11x2b12x3c1x4Figure 3: flow network SOFTIFFERENT dec ()projectionConsider flow network SOFT IFFERENTdec Figure 1. Suppose performProject(SOFT IFFERENTdec (S),W1 ,a,1). network modified one Figure 3, weight edge (x1 , a) decreased 0 1. flow cost 0,cost tuple (a, c, b, b) projection.270fiC ONSISTENCY ECHNIQUESOFT G LOBAL C OST F UNCTIONSWCSPglobal cost function flow-based projection-safe, findSupport() time complexitydepending time complexity computing minimum cost flow shortest pathtwo nodes network. result stated following theorem.Theorem 8 Given time complexities computing minimum cost flow shortest pathK SP respectively. WS flow-based projection-safe, findSupport() timecomplexity O(K + SP), = max{|D(xi )| | xi S} maximum size E.Proof: Theorem 1, finding first flow O(K), minimum cost line 13 foundaugmenting existing flow, requires O(SP). Line 15 done constant time,line 16 done follows: (a) decrease weights edges corresponding xi 7 v, (b) augment current flow one new minimum cost changing flowvalues edges whose weights modified first step. first step requires O(),second step requires O( SP). edges required change flow valuesmaintain minimality flow cost. Since unaryProject() requires O(d), overall timeO(K + d(SP + SP) + d) = O(K + SP).time complexity finding shortest path graph SP varies applying differentalgorithms. general, SP = O(|V ||E|), negative weights introduced graph. However,reduced applying potential value vertices, Johnsons (1977) algorithm.example, Figure 3, increase potential value vertices 1, weightedges (b, t) (c, t) 1. increases cost paths 1, makesweights edges non-negative. Dijkstras (1959) algorithm thus applied, reducingtime complexity O(|E| + |V |log(|V |)).Although GAC* enforced polynomial time flow-based projection-safe global costfunctions, findSupport() function still requires runtime much higher binaryternary table cost functions general. optimize performance solver, delayconsistency enforcement global cost functions binary ternary table cost functionsprocessed line 5.FDAC* binary cost functions (Larrosa & Schiex, 2003) suggests stronger consistencydeduced using extension operator. discuss generalized version FDAC*non-binary cost functions next section.4.3 Full Directional Generalized Arc ConsistencyDefinition 16 Given WCSP P = (X , D, C, ). Consider cost function WS C + variablexi S. tuple full support value v D(xL ) respect WS subsetvariables U \ {xi } iff [xi ] = v WS () xj U Wj ([xj ]) = 0. variable xidirectional star generalized arc consistent (DGAC*) respect WS NC* valuev D(xi ) full support respect {xu | xu u > i}. WCSP full directional stargeneralized arc consistent (FDGAC*) GAC* variable DGAC* respectrelated non-unary cost functions.FDGAC* collapses GAC WCSPs collapse CSPs. Moreover, FDGAC* collapsesFDAC* (Larrosa & Schiex, 2003) arity cost functions two. However, FDGAC*incomparable FDAC ternary cost functions (Sanchez et al., 2008). FDAC requires fullsupports zero unary also zero binary costs next variable only,require variables full supports zero unary costs.271fiL EE & L EUNGdefinition, FDGAC* stronger GAC* also strong IC.Theorem 9 FDGAC* > GAC* > strong IC.procedure enforceFDGAC*() enforces FDGAC* WCSP, based FDAC*() Algorithm (Larrosa & Schiex, 2003). propagation queues Q R store set variables.xj Q, variables involved cost functions xj potentially GAC*; xj R,variables xi involved cost functions xj potentially DGAC*. valuesremoved domain variable xj , xj pushed onto Q R; unary costsvalues D(xj ) increased, xj pushed R. iteration, GAC* maintainedprocedure GAC*(). DGAC* enforced DGAC*(). Enforcing DGAC* follows orderinglargest index smallest index full supports values domainsvariables smaller indices destroyed DGAC*-enforcement largerindices. variable largest index R removed R function popMax().implementing R heap, popMax() requires constant time. DGAC* enforcement performed line 10 findFullSupport(). last step, NC* re-enforced pruneVal().iteration continues propagation queues empty, implies valuesvariable domain simple full support, variables NC*. resultant WCSPFDGAC*.1234567891011121314151617181920Procedure enforceFDGAC*()R := Q := X ;R 6= Q 6=GAC* ();DGAC* ();pruneVal ();Procedure DGAC*()R 6=xu := popMax (R);foreach WS C + s.t. xu= n DownTo 1 s.t. xi \ {xu }findFullSupport (WS , xi , {xj | j > i}) R := R {xi };:= {xi } ;// consistency enforcement.Function findFullSupport(WS , xi , U )foreach xj Uforeach vj D(xj )foreach L(S) s.t. [xj ] = vj WS () := WS () Wj (vj );Wj (vj ) := 0;flag := findSupport (WS , xi );foreach xj U findSupport (WS , xj );unaryProject (xi );return flag;Algorithm 5: Enforcing FDGAC* WCSP272fiC ONSISTENCY ECHNIQUESOFT G LOBAL C OST F UNCTIONSWCSPprocedure enforceFDGAC*() Algorithm 5 correct must terminate, proofsimilar Theorems 3 4 Larrosa Schiex (2003). worst-casetime complexity enforceFDGAC*() stated terms findFullSupport()(fDGAC ) findSupport() (fGAC ) follows.Theorem 10 procedure enforceFDGAC*() time complexity O(r 2 ed(nfDGAC +fGAC ) + n2 d2 ), n, d, e, r defined Theorem 2.Proof: First analyze time complexity enforcing DGAC*. Consider procedureDGAC*() line 6. while-loop iterates O(n) times. Since value removedline 10, > j, pushed back R linewhile-loop, xi processed P11. Thus, line 10 executes O(r nj=0 |N (j)|) = O(r 2 e) times, N (j) setcost functions restricting xj . Therefore, time complexity DGAC*() O(r 2 efDGAC ). SinceDGAC*() executes O(nd) times throughout global enforcement iteration. Thus timespent enforcing DGAC* O(nr 2 edfDGAC )Although GAC*() called O(nd) times, nothing values removed variabledomains. Thus count number times calling findSupport(). Since variablespushed Q value removed, findSupport() executes O(nd) timesthroughout global enforcement iteration. Similar arguments apply pruneVal() line 10inside GAC*() defined Algorithm 4. proof similar Theorem 6, time spentenforcing GAC* O(r 2 edfGAC + n2 d2 ).pruneVal line 5 executes O(nd) times, time requires time complexityO(nd). Therefore, overall time complexity O(r 2 ed(nfDGAC + fGAC ) + n2 d2 ).Corollary 3 procedure enforceFDGAC*() must terminate. resultant WCSP FDGAC*equivalent original WCSP.Again, complexity exponential maximum arity due function findSupport()findFullSupport(). following, focus discussion findFullSupport().first part (lines 15 16) performs extensions push unary costs back WS .time execute line 17, unary costs Wj , xj U , 0, enforcing GAC* xiachieves second requirement DGAC* (each v D(xi ) full support). Line 18 re-instatesGAC* variables xj U . Note success line 17 guarantees Wj (vj ) = 0value vj appearing tuple makes WS () = 0.Again, flow-based projection-safety helps reduce time complexity findFullSupport()throughout enforcement. proof Theorem 7 gives polynomial time algorithm performextension maintain efficient computation min{WS () | L(S)}. Flow-based projectionsafety guaranteed Theorem 7, requires checking conditions 1, 2, 3definition flow-based projection-safety. complexity result follows Theorems 2 8.Theorem 11 WS flow-based projection-safe global cost function, findFullSupport()time complexity O(K + rd SP), r, , d, K SP defined Theorems 28.Proof: Similarly Theorem 8, lines 13 16 performed follows: (a) xj Uvalue vj D(xj ), increase weights edges corresponding {xj 7 vj }Wj (vj ), reduce Wj (vj ) 0, (b) find flow new minimum cost new273fiL EE & L EUNGflow network. first step done O(rd), size U bounded aritycost function r. second step done O(K), also acts preprocessingfindSupport() lines 17 18. Theorem 8, lines 17 18 done O(rd SP).Thus, overall complexity O(r + K + rd SP) = O(K + rd SP).Similarly GAC*, DGAC* enforcement global cost functions delayedbinary ternary table cost functions processed.4.4 Generalizing Existential Directional Arc ConsistencyEDAC* (de Givry et al., 2005) generalized EDGAC* using full support definitionFDGAC*. However, find naively generalizing EDAC* always enforceable, duelimitation EDAC*. following, explain provide solution limitation.4.4.1 N NHERENT L IMITATIONEDAC*Definition 17 (de Givry et al., 2005) Consider binary WCSP P = (X , D, C, ). variablexi X existential arc consistent (EAC*) NC* exists value v D(xi ) zerounary cost full supports respect binary cost functions Wi,j {xi , xj }{xj }. P existential directional arc consistent (EDAC*) FDAC* variablesEAC* .Enforcing EAC* variable xi requires two main operations: (1) compute= min {Wi (a)min {Wi,j (a, b) Wj (b)}},aD(xi )Wi,j CbD(xj )determines whether enforcing full supports breaks NC* requirement, (2) > 0, enforce full supports respect cost functions Wi,j C invoking findFullSupport (xi ,Wi,j , {xj }), implying NC* longer satisfied hence W increased enforcingNC*. EDAC* enforcement oscillate constraints share one variable. situationsimilar Example 3 de Givry et al. (2005). demonstrate example Figure 4(a),1 W 2 . FDAC* EDAC*.shows WCSP two cost functions W1,21,21x2 takes value a, W1,2 (v, a) W1 (v) 1 values v D(x1 ); x2 takes value b,2 (v, b) C (v) 1 values v D(x ). Thus, enforcing full supports valueW1,211D(x2 ) respect cost functions {x1 }, NC* broken W increased.1 , resulting Figincrease W , enforce full supports: cost 1 W1 (a) extended W1,221 W resultsure 4(b). costs W1 extended W1,2 . Performing projection W1,22Figure 4(c). WCSP EAC* FDAC*. Enforcing FDAC* converts problemstate back Figure 4(a).problem caused first step, tell unary costs separatedextension increase W . Although increment predicted, unary cost W1 (a)1 W 2 . computation, information obtainedchoice moving W1,21,2unary costs moved. shown, wrong movement breaks DAC* without incrementing W ,resulting oscillation.problem occur existing solvers handle ternary cost functions.solvers allow one binary cost functions every pair variables. indeedtwo cost functions two variables, cost functions merged one,274fiC ONSISTENCY ECHNIQUES= 4, Wx1W110bbx1bx2bx1bbW200=01x2 W1,20b21b0x2bb2W1,21002x1bx2b(a) Original WCSPOFT G LOBAL C OST F UNCTIONS= 4, Wx1W100bbW200x1bb=01x2 W121b31b0x2bb2W121002(b) Extensionx1bWCSP= 4, Wx1W100bbx2bW210x1bb=01x2 W120b30b0x2bb2W121002(c) ProjectionFigure 4: Oscillation EDAC* enforcementcost tuple merged function sum costs tuple two originalfunctions. However, allow high arity global cost functions, sharing one variablewould common necessary many scenarios. straightforward generalization EDAC*non-binary cost functions would inherit oscillation problem. case ternary costfunctions, Sanchez et al. (2008) cleverly avoid oscillation problem re-defining full supportsinclude unary also binary cost functions. EDAC enforcement, unary costsdistributed extension binary cost functions. However, method designedternary cost functions. following, define weak version EDAC*, basednotion cost-providing partitions.4.4.2 C OST-P ROVIDING PARTITIONSW EAK EDGAC*Definition 18 cost-providing partition Bxi variable xi X set sets {Bxi ,WS | xi S}that:|Bxi | number constraints scope includes xi ;Bxi ,WS S;Bxi ,WSj Bxi ,WSk = two different constraints WSk , WSj C + , and;Bx ,W Bx Bxi ,WS = ( WS C + xi S) \ {xi }.Essentially, Bxi forms partition set containing variables constrained xi . xjBxi ,WS , unary costs Wj extended WS enforcing EAC* xi .avoids problem determining unary costs xj distributed existsone constraint {xi , xj }.Based cost-providing partitions, define weak EDAC*.Definition 19 Consider binary WCSP P = (X , D, C, ) cost-providing partitions {Bxi |xi X }. weak fully supported value v D(xi ) variable xi X value zero unary, exists value b D(x )cost variable xj binary cost function Wi,jj= {}, W= {xj }. variable xiWi,j (v, b) = 0 Bxi ,Wi,j(v,b)W(b)=0Bjx,Wi,ji,jweak existential arc consistent (weak EAC*) NC* exists least one weak fullysupported value domain. P weak existential directional arc consistent (weak EDAC*)FDAC* variable weak EAC*.275fiL EE & L EUNGWeak EDAC* collapses AC WCSPs collapse CSPs cost-providing partition.Moreover, weak EDAC* reduced EDAC* (de Givry et al., 2005) binary cost functionsshare one variable.generalize weak EDAC* weak EDGAC* n-ary cost functions.Definition 20 Given WCSP P = (X , D, C, ) cost-providing partitions {Bxi | xi X }.weak fully supported value v D(xi ) variable xi value zero unary cost fullsupports respect cost functions WS C + xi Bxi ,WS . variable xi weakexistential generalized arc consistent (weak EGAC*) NC* exists least one weakfully supported value domain. P weak existential directional generalized arc consistent(weak EDGAC*) FDGAC* variable weak EGAC*.Weak EDAC* weak EDGAC* achieved using cost-providing partitions. WeakEDGAC* reduced GAC WCSPs collapse CSPs.Compared consistency notions, weak EDGAC* strictly stronger FDGAC*consistency notions described. deduced directly definition.Theorem 12 cost-providing partitions, weak EDGAC* > FDGAC* > GAC* > strong ICVAC stronger weak EDGAC*, stated theorem below.Theorem 13 VAC strictly stronger weak EDGAC* cost-providing partition.Proof: WCSP VAC must weak EDGAC* cost-providing partition. Otherwise, must exist sequence projections extensions increase W , violatesTheorem 7.3 Cooper et al. (2010). another hand, Cooper et al. (2010) give exampleEDAC* VAC. Results follow.However, weak EDGAC* incomparable complete k-consistency (Cooper, 2005), k >2, cost-providing partition. EDAC* already incomparable complete kconsistency (Sanchez et al., 2008).compute cost-providing partition Bxi variable xi , could apply Algorithm 6,greedy approach partition set containing variables related xi defined line 1,hoping gathering costs gathering variables one cost function, increasingchance removing infeasible values raising W .12345ProcedureSfindCostProvidingPartition(xi)= ( WS C + xi S) \ {xi };Sort C + decreasing order |S|;foreach WS C + s.t. xiBxi ,WS = S;= \ S;Algorithm 6: Finding Bxiprocedure enforceWeakEDGAC*() Algorithm 7 enforces weak EDGAC* WCSP.cost-providing partitions first computed line 1. procedure makes use four propagation queues P, Q, R S. xi P, variable xi potentially weak EGAC* due276fiC ONSISTENCY ECHNIQUES12345678910111213141516OFT G LOBAL C OST F UNCTIONSWCSPProcedure enforceWeakEDGAC*()foreach xi X findCostProvidingPartition (xi );R := Q := := X ;6=SR 6= Q 6=P := xi S,WS C + (S \ {xi });weakEGAC* ();:= ;DGAC* ();GAC* ();pruneVal ();Procedure weakEGAC*()P 6=xi := pop(P);findExistentialSupport (xi )R := R {xi };P := P {xj | xi , xj WS , WS C + };Function findExistentialSupport(xi)flag := false;LL:= minaD(xi ) {Wi (a) xi S,WS C + min[xi ]=a {WS () xj Bx,WSWj ([xj ])}};19> 0flag := true;foreach WS C + s.t. xi findFullSupport (WS , xi , Bxi ,WS );20return flag;1718Algorithm 7: Enforcing weak EDGAC*change unary costs removal values variables. xj R, variables xi involved cost functions xj potentially DGAC*. xj Q, variablescost functions xj potentially GAC*. propagation queue helps build Pefficiently. procedure weakEGAC*() enforces weak EGAC* variable procedurefindExistentialSupport() line 12. findExistentialSupport() returns true,projection performed cost functions. weak fully supported valuesvariables may destroyed. Thus, variables constrained xi pushed back onto P revision line 14. DGAC* GAC* enforced procedures DGAC*() GAC*().change unary cost requires re-examining DGAC* weak EGAC*, done pushingvariables corresponding queues lines 13 14, lines 11 12 Algorithm 5.last step, NC* enforced pruneVal(). Again, value D(xi ) removed, GAC*,DGAC* weak EGAC* may destroyed, xi pushed corresponding queuesre-examination pruneVal() Algorithm 1. propagation queues empty, variablesGAC*, DGAC*, weak EGAC*, i.e. WCSP weak EDGAC*.algorithm correct must terminate. analyze time complexity abstractingworst-case time complexities findSupport(), findFullSupport()277fiL EE & L EUNGfindExistentialSupport() fGAC , fDGAC , fEGAC respectively. overall timecomplexity stated follows.Theorem 14 procedure enforceWeakEDGAC*() requires O((nd+)(fEGAC +r 2 efDGAC +nd) + r 2 edfGAC ), n, d, e, r defined Theorem 2.Proof: line 1 requires O(nr), analyze overall time complexity spentsub-procedure compute overall time complexity.variable pushed value removed weak EGAC* violated. formerhappens O(nd) times, latter occurs O() times (each time weak EGAC* violated, Wincreased). Since P built S, findExistentialSupport() executedO(nd + ) times throughout global enforcement. Thus, time complexity spent enforcingweak EGAC* O((nd + )fEGAC ).variable pushed R either value removed, unary costs moved GAC*weak EGAC* enforcement. Thus, DGAC*() called O(nd + ) times. time DGAC*()called, Theorem 10, requires O(r 2 efDGAC ) DGAC* enforcement. Thus, time complexity enforcing DGAC* O((nd + )r 2 efDGAC ).variable pushed Q value removed. Thus, findSupport() insideprocedure GAC*() called O(nd) times throughout global enforcement. Usingproof similar Theorem 6, overall time spent enforcing GAC* O(r 2 edfGAC + n2 d2 ).main while-loop line 3 terminates propagation queues empty. Thus, mainwhile-loop iterates O(nd + ) times. time complexity re-enforcing NC* pruneVal()line 9 O((nd + )nd).summing time complexity results, overall time complexity O((nd+)(fEGAC +r 2 efDGAC + nd) + r 2 edfGAC ).Corollary 4 procedure enforceWeakEDGAC*() must terminate. resultant WCSPweak EDGAC*, equivalent original WCSP.procedure enforceWeakEDGAC*() exponential due findSupport(),findFullSupport() findExistentialSupport(). following, focuslast procedure. first checks whether weak fully supported value exists computing ,determines whether NC* still holds perform findFullSupport() line 19. equals0, weak fully supported value exists nothing done; otherwise, value madeweak fully supported for-loop line 19. time complexity depends two operations:(1) computing value line 16, and; (2) finding full supports line 19. twooperations exponential |S| general. However, global cost functions flow-basedprojection-safe, time complexity operations reduced polynomial time.next section, put theory practice. demonstrate framework differentbenchmarks compare results current approach.5. Towards Library Efficient Global Cost Functionsprevious section, show SOFT IFFERENTdec flow-based projection-safe.following, show range common global cost functions also flow-basedprojection-safe. give experimental results various benchmarks different consistencynotions different global cost functions.278fiC ONSISTENCY ECHNIQUESOFT G LOBAL C OST F UNCTIONSWCSP5.1 List Flow-Based Projection-Safe Global Cost Functionssection, show number common global cost functions flow-based projectionsafe. include soft variants IFFERENT, GCC, SAME, REGULAR constraints.5.1.1 OFT VARIANTSIFFERENTIFFERENT() constraint restricts variables take distinct values (Lauriere, 1978).two possible soft variants, namely SOFT IFFERENTdec () IFFERENTvar ().former returns number pairs variables share value, latter returnsleast number variables must changed variables take distinct values.cost function SOFT IFFERENTdec () shown flow-based projection-safe Section 4.2.fact, also implies another cost functionSOFT IFFERENTvar () flow-based projection-safe. SOFT IFFERENT var () functionalso corresponds flow network structure similar SOFT IFFERENTdec ()different weights edges connecting (van Hoeve et al., 2006). state resultsfollows.Theorem 15 cost functions SOFTflow-based projection-safe.IFFERENT var (S) SOFT IFFERENTdec (S)5.1.2 OFT VARIANTS GCCGiven set values = xi D(xi ) functions lb ub maps non-negativeintegers. value v associated upper bound ubv lower bound lbv .GCC(S, ub, lb) constraint satisfied tuple L(S) number occurrences valuev (denoted #(, v)) ubv times least lbv times (Regin, 1996).two soft variants GCC constraints, namely SOFT GCCvar () SOFT GCCval () (van Hoeveet al., 2006).Definition 21 (van Hoeve et al., 2006) Define two functions s(, v) e(, v): s(, v) returnslbv #(, v) #(, v) lbv , 0 otherwise; e(, v) returns #(, v) ubv #(, v) ubv ,0 otherwise.PPglobalSOFT GCC var (S) returns max{ v s(, v),v e(, v)}, proP cost functions PPvided v lbv |S| v ubv ; SOFT GCCval (S) returns v (s(, v) + e(, v)).Van Hoeve et al. (2006) show SOFT GCCvar SOFT GCCdec flow-based,flow networks structures similar SOFT IFFERENT cost functions. proofsimilar Theorem 15, show following theorem.Theorem 16 cost functions SOFT GCCvar (S) SOFT GCCval (S) flow-based projectionsafe.5.1.3 OFT VARIANTSAMEGiven two sets variables S1 S2 |S1 | = |S2 | S1 S2 = . SAME(S1 ,S2 )constraint satisfied tuple L(S1 S2 ) [S1 ] permutation [S2 ] (Beldiceanu,Katriel, & Thiel, 2004). hard SAME() constraint softened global cost functionSOFT SAMEvar () (van Hoeve et al., 2006):279fiL EE & L EUNGDefinition 22 (van Hoeve et al., 2006) Given union operation multi-set union,1 2 returns symmetric difference two multi-sets 1 2 , i.e.1 2 = (1 \2 ) (2 \ 1 ).global cost function SOFT SAMEvar (S1 , S2 ) returns |( xi S1 {[xi ]})( yi S2 {[yi ]})|/2.Theorem 17 cost functionSOFT SAMEvar (S1 ,S2 ) flow-based projection-safe.Proof: Van Hoeve et al. (2006) shown SOFT SAMEvar satisfies conditions 1 2Definition 15. instance, consider S1 = {x1 , x2 , x3 } S2 = {x4 , x5 , x6 } D(x1 ) = {a},D(x2 ) = {a, b}, D(x3 ) = {b}, D(x4 ) = {a, b} ,and D(x5 ) = D(x6 ) = {a}. flow networkcorresponding SOFT SAMEvar (S1 , S2 ) shown Fig. 5. Solid edges zero weight unitcapacity. Dotted edges unit weight capacity 3. thick edges show (s, t)-flowcorresponding tuple = (a, b, b, b, a, a).x1x4x2x5bx6x3Figure 5: flow network corresponding SOFTSAMEvar (S1 ,S2 ) constraintMoreover, network structure, taking E = {(xi , v)} xi S1 v D(xi ),E = {(v, yi )} yi S2 v D(yi ), cost function satisfies condition 3. Thus,flow-based projection-safe.5.1.4 OFT VARIANTSR EGULARR EGULAR constraint defined based regular languages. regular language L(M )represented finite state automaton = (Q, , , q0 , F ). Q set states. setcharacters. symbol q0 Q denotes initial state F Q set final states.transition function defined : Q 7 Q. automaton represented graphicallyshown Figure 6, final states denoted double circles.Given D(xi ) xi S. REGULAR(S, ) constraint accepts tupleL(S) corresponding string belongs regular language L(M ) represented finite stateautomaton = (Q, , , q0 , F ) (Pesant, 2004).bq0q1bq2Figure 6: graphical representation automaton.280fiC ONSISTENCY ECHNIQUESOFT G LOBAL C OST F UNCTIONSTwo soft variants defined REGULAR constraint, namelySOFT REGULAR edit () (van Hoeve et al., 2006):WCSPSOFT REGULAR var ()Definition 23 (van Hoeve et al., 2006) Define string formed tuple L(S).cost functions SOFT REGULARvar (S) returns min{H( , ) | L(M )}, H( 1 , 2 )returns number positions two strings 1 2 differ; SOFT REGULARedit (S)returns min{E( , ) | L(M )}, E( 1 , 2 ) returns minimum number insertions,deletions substitutions transform 1 2 .Theorem 18 cost functions SOFTprojection-safe.REGULAR var (S) SOFT REGULAR edit (S) flow-basedProof: Van Hoeve et al. (2006) show conditions 1 2 satisfied. example, considerautomaton shown Figure 6 = {x1 , x2 , x3 } D(x1 ) = {a} D(x2 ) = D(x3 ) ={a, b}. flow networks corresponding SOFT REGULARvar (S) SOFT REGULARedit (S)functions shown Figure 7(a) 7(b) respectively. solid edges zero weightdotted edges unit weight. thick edges show flow corresponding tuple (a, b, a).graphs constructed follows (van Hoeve et al., 2006): vertices separatedn + 1 layers, n = |X |, layer contains |Q| nodes. source connected q0,0first layer, sink connected {qn+1,i | qi F } last layer. ith(i + 1)th layers, zero weighted edge representing v D(xi ) connects qi,h ith layerqi+1,k (i + 1)th layer (qk , v) = qh . SOFT REGULARvar (S), set unit-weightededges Esub added graph, Esub = {(qi,k , qi+1,h )u | xi X u D(xi ) v 6=u s.t. (qk , v) = qh }. SOFT REGULARedit (S), set unit-weighted edges Eedit addedgraph, Eedit = Esub {(qi,k , qi,h ) | xi X v s.t. (qk , v) = qh } {(qi,k , qi,k )u |xi X u D(xi )}.Moreover, assignment {xi 7 v} maps set edges E labelled v layer xinetworks. example, {x1 7 a} maps edges labeled layer x1 shown Fig. 7(a).Thus, SOFT REGULAR cost functions satisfy condition 3 flow-based projection-safe.SOFT REGULAR cost functions, instead general flow computation algorithms,dynamic programming approach applied compute minimum cost (van Hoeve et al.,2006; Demassey, Pesant, & Rousseau, 2006).5.2 Experimental Resultssection, series experiments different benchmarks conducted demonstrateefficiency practicality different consistencies different global cost functions. implemented strong IC, GAC*, FDGAC* weak EDGAC* enforcement algorithmsglobal cost functions ToulBar2 version 0.51 . compare performance using five benchmarks different natures. case reified COP models, instances solved using ILOGSolver 6.0.benchmarks crisp nature, softened follows. variable xi introduced, random unary cost 0 9 assigned value D(xi ). Soft variants globalconstraints implemented proposed. target benchmarks find optimal valuewithin 1 hour.1. http://carlit.toulouse.inra.fr/cgi-bin/awki.cgi/ToolBarIntro281fiL EE & L EUNGx2x1q0x3q0q0q1q2q0bbq1q1bq0q2x1x2a,b()x3a,bq0bbq1q2varq0q1q2q1bbbbq1q2SOFT REGULARq2bb(b)bSOFT REGULARq0q2b(a)q1bq2bbedit()Figure 7: flow network corresponding soft REGULAR constraintsexperiments, variables assigned lexicographical order. Value assignment startsvalue minimum unary cost. test conducted Sun Blade 2500 (2 1.6GHzUSIIIi) machine 2GB memory. average runtime number nodes five instancesmeasured value n initial upper bound. Entries marked *average runtime exceeds limit 1 hour. best results marked using symbol.5.2.1 B ENCHMARKS BASEDOFT IFFERENTIFFERENT() constraint various applications. following, focus two:all-interval series Latin Square problem.NTERVAL ERIESall-interval series problem (prob007 CSPLib) modelled WCSP two sets variables {si } {di } domains {0, . . . n 1} denote elements adjacent differencerespectively. Random unary costs ranging 0 9 placed variable. apply twosoft IFFERENT cost functions {si } {di } respectively, set hard arithmeticconstraints di = |si si+1 | = 1, . . . , n 1.experiment divided two parts. first compare results enforcing different consistencies using global cost functions derived IFFERENT() . compare resultusing different approaches modelling SOFT IFFERENTdec () functions.result first experiment shown Table 1, agrees theoretical strengthconsistency notions shown number nodes. FDGAC* GAC* always outperforms strong IC reified modelling, FDGAC* requires time GAC*. Oneexplanation phenomenon problem structure. xi xi+1 assigned, di282fiC ONSISTENCY ECHNIQUESOFT G LOBAL C OST F UNCTIONSWCSPautomatically assigned due hard constraint di = |xi xi+1 |. Thus, enforcing FDGAC*variables {di } every search node worthwhile.(a)n89101112Reified ApproachTime(s) Nodes1.3571.03.91445.052.0 15860.659.6 13286.2180.1 31015.2Strong ICTime(s) Nodes0.2296.41.0542.220.25706.631.87536.477.8 12886.4(b)n89101112Reified ApproachTime(s) Nodes1.6777.03.91480.456.8 17753.870.1 16149.6214.9 38438.6SOFT IFFERENTvarGAC*Time(s) Nodes0.1181.00.6300.210.8 2589.416.4 3273.637.6 5204.6SOFT IFFERENTStrong ICTime(s) Nodes0.2396.81.0553.221.25999.238.49113.296.4 16355.2()FDGAC*Time(s) Nodes0.186.41.2197.215.2 1612.421.0 1715.446.8 2259.0Weak EDGAC*Time(s) Nodes0.115.40.120.20.247.40.133.60.847.6decGAC*Time(s) Nodes0.2219.60.6301.811.6 2654.618.6 3551.846.8 6405.0()FDGAC*Time(s) Nodes0.193.81.2195.016.0 1604.223.0 1812.652.6 2451.6Weak EDGAC*Time(s) Nodes0.116.00.128.80.870.41.068.61.871.2Table 1: time (in seconds) number nodes solving all-interval series instancessecond experiment based following fact. SOFT IFFERENTdec (S) flowbased projection-safe. modelled flow network consistency enforcement efficiently.Another way model global cost functions apply decomposition directly. costreturned SOFT IFFERENTdec (S) equal sum costs returned set softbinary cost functions {Wi,j | > j xi , xj S}, Wi,j (a, b) returns 0 6= b 1otherwise. Thus, binary consistency notions, AC* FDAC* applied directly.compare performance solving interval series problem different modellingmethods SOFT IFFERENTdec (). results shown Table 2. levelconsistency, global cost functions remove order magnitude 10 100 times nodesbinary decomposition. However, time required binary cost functions much smallerglobal cost functions AC* FDAC*. enforcing consistency notions binarycost functions faster global cost functions, removal nodes great enoughcompensate extra time consistency enforcement global cost functions. runtimeweak EDGAC*, however, fastest among (2 times EDAC* counterpart) sinceable utilize global information prune drastically search space binarydecomposition approaches.L ATIN QUARESLatin Square problem (prob003 CSPLib) order n fill initially empty n n tableusing numbers {0, . . . , n 1} number occurs every row everycolumn. model relax problem WCSP set variables {xij } denotingvalue placed cell ith row j th column random unary costs. costsessentially restrictions/preferences value taken cell. Thus, formulationmodel different variants Latin Square problem, including Latin Square Completionproblem. One SOFT IFFERENT() cost function posted variables row283fiL EE & L EUNGn89101112AC*Time(s) Nodes0.1317.20.1596.01.49113.81.67672.24.6 15897.2Binary DecompositionFDAC*EDAC*Time(s) Nodes Time(s) Nodes0.10.1231.6161.80.10.1358.2333.01.05957.41.0 5483.21.24578.41.2 4318.63.2 10534.82.6 7414.4GAC*Time(s) Nodes0.2219.60.6301.811.6 2654.618.6 3551.846.8 6405.0Global Cost FunctionsFDGAC*Weak EDGAC*Time(s) Nodes Time(s) Nodes0.10.116.093.80.128.81.2195.00.870.416.0 1604.21.068.623.0 1812.61.871.252.6 2451.6Table 2: time (in seconds) number nodes solving all-interval series instancesdifferent modellingcolumn, denoting elements rows columns allowed violationcosts resultant cost optimal. result shown Table 3, similar Table1. Besides, runtime also agrees theoretical strength consistency notions.n45678n45678Reified ApproachTime(s)Nodes69.0 129958.0********(a) SOFT IFFERENT var()Strong ICGAC*FDGAC*Time(s)NodesTime(s) Nodes Time(s) Nodes0.10.11.83511.0188.021.80.1490.2 348790.426.0 12368.066.2****3.4244.4****43.2 1429.4******Weak EDGAC*Time(s) Nodes0.116.60.141.21.493.616.2425.2148.22066.5Reified ApproachTime(s)Nodes62.7 121319.0********(b) SOFT IFFERENT dec()Strong ICGAC*FDGAC*Time(s)NodesTime(s) Nodes Time(s) Nodes0.10.12.63859.8187.621.80.1531.4 376526.225.2 12254.066.2****3.4244.4****43.4 1429.6******Weak EDGAC*Time(s) Nodes0.116.60.141.21.493.615.8425.2147.22066.5Table 3: time (in seconds) number nodes solving Latin Square instances usingSOFT IFFERENT cost functionsSOFT IFFERENTdec () cost functions also decomposed binary disequalitycost functions. also perform experiments compare binary decomposition approachglobal cost function approach. result shown Table 4. result confirms enforcingstronger consistency global cost functions efficient terms number nodes exploredalso problem size grows large.5.2.2 B ENCHMARKS BASEDOFT GCCGCC() constraint various applications. following, focus Latin Squareproblem round robin tournament problem.284fiC ONSISTENCY ECHNIQUESn45678AC*Time(s)Nodes0.1264.03.017955.8639.2 2188035.4****Binary DecompositionFDAC*Time(s)Nodes0.171.80.43059.6167.8 346797.6****OFT G LOBAL C OST F UNCTIONSEDAC*Time(s) Nodes0.139.40.1828.228.2 45817.8****WCSPGlobal Constraint ApproachesGAC*FDGAC*Weak EDGAC*Time(s) Nodes Time(s) Nodes Time(s) Nodes0.10.10.116.6187.621.80.10.141.225.2 12254.066.21.493.6**3.4244.415.8425.2**43.4 1429.6147.22066.5****Table 4: time (in seconds) number nodes solving Latin Square instancesdifferent modelling(a)n45678Reified ApproachTime(s)Nodes3.84865.6653.7 460989.2******Strong ICTime(s)Nodes2.83859.8621.2 376526.2******(b)n45678Reified ApproachTime(s)Nodes2.22815.8165.2 122840.0******Strong ICTime(s)Nodes1.42326.6153.4 102493.6******GCCvarGAC*Time(s) Nodes0.1220.838.6 14482.8******SOFTSOFTFDGAC*Time(s) Nodes0.1220.166.24.8244.658.4 1431.2**Weak EDGAC*Time(s) Nodes0.117.00.148.21.287.016.4331.8459.64730.8FDGAC*Time(s) Nodes0.120.40.161.23.6211.040.4 1243.6**Weak EDGAC*Time(s) Nodes0.117.00.145.21.082.213.4318.4285.23700.4GCCvalGAC*Time(s)Nodes0.1131.810.04818.21407.4 357529.8****Table 5: time (in seconds) number nodes solving Latin Square instances usingsoft GCC constraintsL ATIN QUARESfirst focus Latin Square problem, described Section 5.2.1. usesoft version replace SOFT IFFERENT either SOFT GCCvar () SOFT GCCval ()cost functions measure violation differently. results shown Table 5,shows similar result Table 3. Weak EDGAC* always performs best terms timereduction search space.ROUND ROBIN OURNAMENTround robin problem problem (prob026 CSPLib) order n schedule tournament nteams n 1 weeks. week divided n/2 periods, period divided twoslots. tournament must satisfy following three constraints: (1) every team plays leastweek, (2) every team plays twice period tournament, (3) every teamplays every team. Van Hentenryck, Michel, Perron, Regin (1999) give CSP modelbased GCC constraints: triple variables (sij , tij , mij ) represents match played ithweek j th period. assignment {sij 7 a, tij 7 b, mij 7 ab} represents team playedteam b. Ternary constraints link sij , tij mij together sij takes value285fiL EE & L EUNG(a)(N, P, )(4,3,2)(5,4,2)(6,5,3)(7,5,3)Reified ApproachTime(s) Nodes1.7 1119.24.5 2016.6****Strong ICTime(s) Nodes0.6827.42.2 1242.0****(b)(N, P, )(4,3,2)(5,4,2)(6,5,3)(7,5,3)Reified ApproachTime(s) Nodes1.5 1046.83.5 1821.4****SOFTGAC*Time(s) Nodes0.4 470.21.8 836.2****SOFTStrong ICTime(s) Nodes0.4 794.60.6 171.0****GCCvarFDGAC*Time(s) Nodes0.2 142.20.6 171.6****Weak EDGAC*Time(s) Nodes0.133.40.144.6583.46508.81283.47476.6FDGAC*Time(s) Nodes0.2 141.00.6 171.0****Weak EDGAC*Time(s) Nodes0.133.00.142.8438.26499.6765.07413.6GCCvalGAC*Time(s) Nodes0.4 464.61.4 824.6****Table 6: time (in seconds) number nodes solving round robin tournamentproblems using SOFT GCC cost functionstij takes value b iff mij takes value ab ba. first second requirementsrepresented GCC constraints {sij , tij | = w} wth week {sij , tij | j = p}pth period. third requirement represented GCC constraint {mij }.problem generalized three parameters (N, P, ): scheduling tournamentN teams weeks, week divided P periods. Besides placing random unarycosts, also replace GCC constraints soft variants. try different combinationsN , P , . results shown Table 6, agrees theoretical strengthconsistency. also shows although enforcing stronger consistency expensive, helpsreduce search space more. Thus, stronger consistency helps solve larger instances.5.2.3 B ENCHMARKS BASEDOFT AMESAME() constraint used model following two problems: (1) fair scheduling,(2) people-mission scheduling.FAIR CHEDULINGproblem suggested Global Constraint Catalog2 . goal schedule n personsshifts days schedule fair, i.e. person assignednumber ith shift. example, schedule Figure 8(a) fair. person p1assigned shift two times p2 assigned shift only. Figure 8(b) showsschedule fair everyone: p1 p2 assigned shift Overnight shiftonce, PM shift twice.model soften problem set variables {xij }, denote shift assignedith person j th day random unary costs. SOFT SAMEvar ({xp1 j }, {xp2 j }) costfunctions placed pair persons p1 p2 , allowing violation fairnessschedule obtain minimum cost. fix = 4 = 5 vary n. results shownTable 7. Similarly Table 5, weak EDGAC* produces smallest number nodes. However,2. http://www.emn.fr/x-info/sdemasse/gccat/286fiC ONSISTENCY ECHNIQUESDay 1p1p2Day 2PMPMDay 3PMOvernightOFT G LOBAL C OST F UNCTIONSDay 4PMp1p2Day 1(a) Unfair ScheduleDay 2PMPMWCSPDay 3PMOvernightDay 4OvernightPM(b) Fair ScheduleFigure 8: Examples Fair Schedulingn567891011Reified ApproachTime(s)Nodes1983.9 1457812.6************Strong ICTime(s)Nodes74.220610.41884.0 1038613.2**********GAC*Time(s)Nodes16.63511.878.811031.8377.036063.01630.0 124920.8******FDGAC*Time(s) Nodes0.127.40.440.41.045.02.045.42.649.04.058.05.867.2Weak EDGAC*Time(s) Nodes0.125.434.01.040.61.245.02.249.03.256.84.661.66.4Table 7: time (in seconds) number nodes solving fair scheduling problemenforcing different consistency notions.weak EDGAC* requires time solve FDGAC*. look execution discoverFDGAC* strong first lower bound computed already close, identical,objective value optimal solution. Therefore, enforcing weak EDGAC* gives littleimprovement reducing search space.P EOPLE -M ISSION CHEDULINGproblem extends doctor-nurse rostering problem described Beldiceanu, KatrielThiel (2004). Given three groups n persons, missions must assigned team containing exactly one person group. also given set constraints restricting combination team one mission. problem schedule people teamsmissions restriction violated. model problem {xij } denoting missionassigned ith person j th group random unary costs. combination restrictionsoftened ternary cost functions. Two global cost functions SOFT SAMEvar ({xi1 }, {xi2 })SOFT SAMEvar ({xi2 }, {xi3 }) posted ensure team exactly contains one persongroup. fix = 6 vary n. results shown Table 8. Similarly Table 7, weakEDGAC* produces smallest number nodes, requires time FDGAC*.5.2.4 B ENCHMARKS BASEDOFT R EGULARREGULAR() constraint many applications. following, focus two: (1) nurserostering problem, and; (2) STRETCH() constraint modelling.N URSE ROSTERING P ROBLEMnurse rostering problem (Cheng, Lee, & Wu, 1997) schedule group n nurses fourshifts, PM shift, shift, Overnight, Day-Off, period requirements satisfied.287fiL EE & L EUNGn4567Reified ApproachTime(s)Nodes17.516992.0427.8 283950.2****Strong ICTime(s)Nodes4.05931.645.251029.8666.6 553001.2**GAC*Time(s) Nodes1.61517.411.27073.8156.6 75481.6**FDGAC*Time(s)Nodes0.2247.83.4831.255.611065.21348.0333937.6weak EDGAC*Time(s)Nodes238.80.43.4693.410957.869.21714.0 296019.2Table 8: time (in seconds) number nodes solving people-mission schedulingproblem enforcing different consistency notions.(a)n345678Reified ApproachTime(s) Nodes260.66 118562**********Strong ICTime(s) Nodes152.6 91661.4**********(b)n345Reified ApproachTime(s)Nodes286.6 122542.4****Strong ICTime(s) Nodes178.4 91933.8****SOFT REGULARvar()GAC*Time(s) Nodes2.0956.225.4 6983.4********SOFT REGULAReditGAC*Time(s) Nodes9.22850.4126.2 27267.6**FDGAC*Time(s) Nodes0.128.60.132.64.0379.063.44017.6207.6 12242.0821.2 44414.0weak EDGAC*Time(s)Nodes0.122.80.128.03.6273.637.81927.242.82167.6229.210437.0()FDGAC*Time(s) Nodes5.6841.425.42568.8535.647091.2weak EDGAC*Time(s)Nodes803.26.227.62424.0546.8 40244.0Table 9: time (in seconds) number nodes solving nurse scheduling problemenforcing different consistency notions.experiment, nurses scheduled four days (1) nurse mustthree shifts, least two PM shifts, least one Overnight, least one day-off; (2)shift must two nurses, PM shift Overnight must one nurse, and; (3) AMshifts preferred packed together, preference also posted Day-Offs.model problem set variables {xij } denote shift assigned ith nurse j thday random unary costs. Restrictions (1) (2) modeled SOFT GCCval cost functions,(3) modeled either SOFT REGULARvar SOFT REGULARedit cost functions. restrictions allowed violated. results shown Table 9. SOFT REGULARedit ()used, FDGAC* wins term runtime. However, SOFT REGULARvar () used, weak EDGAC*requires least time least number nodes solve.ODELLINGTRETCH () C ONSTRAINTAnother application REGULAR() constraint model constraints describe patterns. Oneexample STRETCH() constraint.288fiC ONSISTENCY ECHNIQUESn303540455055Reified ApproachTime(s) Nodes183.57346.2419.4 13845.2842.4 23485.02318.2 55976.0****(a) SOFT REGULARvar()Strong ICGAC*Time(s)NodesTime(s) Nodes68.25203.236.4573.0162.210297.880.6971.6335.618067.2148.41423.2900.442007.0378.23042.01142.288616.8165.8 10762.22231.4 146901.6306.0 17130.0(b)n303540455055Reified ApproachTime(s) Nodes216.26038.6561.6 12487.61128.1 20585.8******OFT G LOBAL C OST F UNCTIONSSOFT REGULARStrong ICTime(s) Nodes83.23861.6204.27626.0413.0 12789.61151.8 30480.62122.8 62225.2**editWCSPFDGAC*Time(s) Nodes30.0171.457.6239.892.2328.6240.6651.8130.2 1660.6208.0 2291.8weak EDGAC*Time(s) Nodes162.635.2233.469.0316.0108.2570.6246.4118.21316.0193.81856.8FDGAC*Time(s) Nodes34.2123.860.6164.090.8208.4239.6 371.0204.8 967.6264.2 972.8weak EDGAC*Time(s) Nodes39.6 122.470.8 162.8101.6 194.0207.8299.6185.0823.2234.6777.6()GAC*Time(s) Nodes40.6447.486.8706.0165.81080.0446.42346.2348.69189.0623.8 13496.8Table 10: time (in seconds) number nodes solving sliding problem enforcing different consistency notions.Definition 24 (Pesant, 2001) Given value v tuple L(S). v-stretch maximalsubsequence identical values v . STRETCH(S, ub, lb) constraint satisfiedlength v-stretch ubv least lbv .simplicity, omit case STRETCH() constraint circular. However,handled variable duplication (Pesant, 2004).STRETCH() constraint described automaton thus modelled usingREGULAR () constraint (Pesant, 2004). SOFT REGULAR var () SOFT REGULAR edit () costfunctions directly applied define two soft variants STRETCH() constraint, namelySOFT STRETCH var () SOFT STRETCH edit (). flow-based projection-safe inheritingproperty SOFT REGULARvar () SOFT REGULARedit () respectively.demonstrate idea, conduct experiments using following sliding problem.sliding problem order n consists set variables {x1 , . . . , xn } domains D(xi ) = {a, b}random unary costs. subsequence {xi , . . . , xn5+i }, 1 5, requiredcontain a-stretches length 2 b-stretches length 2 3. restriction enforcedSTRETCH constraints. allow violations modeling constraints using eitherSOFT REGULAR var SOFT REGULAR edit cost functions. results shown Table 10. WeakEDGAC* needs time FDGAC* instances small, weak EDGAC* payslarge instances. experiment also shows STRETCH constraint, importantconstraint modeling patterns, efficiently propagated WCSP framework.5.2.5 ISCUSSIONScontrol comparison conducted examine efficiency ToulBar2global cost functions encoded explicitly tables well. cannot done meaningfulmanner since tables prohibitively large. Consider simple cost function 10 variables,289fiL EE & L EUNGdomain size 10. table already requires storage order 1010 integerstens gigabytes.Based experiments, two conclusions made. First, experiments showreified approach strong IC weak terms search space pruning runtimereduction compared GAC*, FDGAC*, weak EDGAC*. Second, stronger consistencynotions, weak EDGAC*, FDGAC* GAC*, worthwhile although expensiveenforce. shown experiments, GAC* reduces number search nodes least3 times reified approach 1.5 times strong IC. GAC* runtimeleast 4 times less reified approach 1.5 times less strong IC. Weak EDGAC*FDGAC* reduce search space much greater extent. additional pruning usuallycompensate extra effort. Although Table 7 Table 8 shown cases weakEDGAC* results slower runtime, FDGAC* wins small margin. general, weakEDGAC* still worthwhile enforce. Table 10 confirms stronger consistencydesirable problem becomes large.6. Conclusion Remarkssection, summarize contributions shed light possible future directionsresearch.contributions five-fold. First, introduce strong IC based IC (Zytnicki et al.,2009) give algorithm enforce strong IC. Besides, prove strong IC confluent.also show enforcing strong IC WCSP stronger GAC reified approach.Second, give algorithm enforce GAC* WCSP, enforcement exponential. efficient enforcement, introduce flow-based projection-safety, preserves basic structureglobal cost functions. give sufficient conditions global cost function flow-basedprojection-safe. also show part proof projection extension doneflow property preserved. Third, generalize FDAC* (Larrosa & Schiex, 2003)FDGAC* give enforcement algorithm. Again, flow-based projection-safety helps FDGAC*enforcement. Fourth, attempt generalize EDAC* using similar methods, find nontrivial. discover give example limitation EDAC*. cost functions shareone variable, oscillation similar one demonstrated Full AC* (de Givry et al.,2005) occur. solve problem, introduce cost-providing partitions, restrictdistribution costs enforcing EDAC*. Based cost-providing partitions, define weakEDGAC*, enforced polynomial time flow-based projection-safe global costfunctions. Last least, show soft versions IFFERENT(), GCC(), SAME()REGULAR () flow-based projection-safe. also prove practicality frameworkempirical results various benchmarks involving global cost functions. empirical resultsagree theoretical strength consistencies terms search tree pruning. resultsalso show stronger consistency notions like weak EDGAC* FDGAC* worthwhileenforce, especially solving large problems.Three directions future work possible. first one investigate even strongerconsistency notions, VAC (Cooper et al., 2010), also benefit projection-safetymake enforcement practical global cost functions. Second, current sufficient conditionsflow-based projection-safety might still overly restrictive. example, global cost function SOFT SEQUENCE (Maher, Narodytska, Quimper, & Walsh, 2008) satisfy three290fiC ONSISTENCY ECHNIQUESOFT G LOBAL C OST F UNCTIONSWCSPconditions. interesting find possible definition flow-based projection-safety,allow efficient projection extension operations. Third, consider minimumcost flow computation finding minimum cost global cost function. interestingcheck approaches, mathematical programming, used achieveresults.AcknowledgmentsWork described paper generously supported grants CUHK413808 CUHK413710Research Grants Council Hong Kong SAR.ReferencesBeldiceanu, N. (2000). Global Constraints Graph Properties Structured Network Elementary Constraints Type. Proceedings CP00, pp. 5267.Beldiceanu, N., Carlsson, M., & Petit, T. (2004). Deriving Filtering Algorithms ConstraintCheckers. Proceedings CP04, pp. 107122.Beldiceanu, N., Katriel, I., & Thiel, S. (2004). Filtering Algorithms Constraints.Proceedings CPAIOR04, pp. 6579.Cheng, B., Lee, J. H. M., & Wu, J. (1997). Nurse Rostering System Using Constraint Programming Redundant Modeling. IEEE Transactions Information TechnologyBiomedicine, 1, 4454.Cooper, M., de Givry, S., Sanchez, M., Schiex, T., Zytnicki, M., & Werner, T. (2010). Soft ArcConsistency Revisited. Artificial Intelligence, 174, 449478.Cooper, M., & Schiex, T. (2004). Arc Consistency Soft Constraints. Artifical Intelligence, 154,199227.Cooper, M. C. (2005). High-Order Consistency Valued Constraint Satisfaction. Constraints,10(3), 283305.de Givry, S., Heras, F., Zytnicki, M., & Larrosa, J. (2005). Existential Arc Consistency: GettingCloser Full Arc Consistency Weighted CSPs. Proceedings IJCAI05, pp. 8489.Demassey, S., Pesant, G., & Rousseau, L.-M. (2006). Cost-Regular Based Hybrid Column Generation Approach. Constraints, 11, 315333.Dijkstra, E. W. (1959). Note Two Problems Connexion Graphs. Numerische Mathematik, 1, 269271.Johnson, D. (1977). Efficient Algorithms Shortest Paths Sparse Networks. JournalACM, 24(1), 113.Larrosa, J., & Schiex, T. (2003). Quest Best Form Local Consistency WeightedCSP. Proceedings IJCAI03, pp. 239244.Larrosa, J., & Schiex, T. (2004). Solving Weighted CSP Maintaining Arc Consistency. ArtificialIntelligence, 159(1-2), 126.Lauriere, J.-L. (1978). Language Program Stating Solving Combinatorial Problems.Artificial Intelligence, 10, 29127.291fiL EE & L EUNGLawler, E. (1976). Combinatorial Optimization: Networks Matroids. Holt, Rinehart Winston.Leung, K. L. (2009). Soft Global Constraints Constraint Optimization Weighted ConstraintSatisfaction. Masters thesis, Chinese University Hong Kong.Maher, M., Narodytska, N., Quimper, C.-G., & Walsh, T. (2008). Flow-Based PropagatorsSEQUENCE Related Global Constraints. Proceedings CP08, pp. 159174.Pesant, G. (2001). Filtering Algorithm Stretch Constraint. Proceedings CP01, pp.183195.Pesant, G. (2004). Regular Language Membership Constraint Finite Sequences Variables.Proceedings CP04, pp. 482495.Petit, T., Regin, J.-C., & Bessiere, C. (2000). Meta-constraints Violations ConstrainedProblems. Proceedings ICTAI00, pp. 358365.Petit, T., Regin, J.-C., & Bessiere, C. (2001). Specific Filtering Algorithm Over-ConstrainedProblems. Proceedings CP01, pp. 451463.Regin, J.-C. (1996). Generalized Arc Consistency Global Cardinality Constraints. Proceedings AAAI96, pp. 209215.Regin, J.-C. (2002). Cost-Based Arc Consistency Global Cardinality Constraints. Constraints,7, 387405.Sanchez, M., de Givry, S., & Schiex, T. (2008). Mendelian Error Detection Complex Pedigreesusing Weighted Constraint Satisfaction Techniques. Constraints, 13(1), 130154.Schiex, T., Fargier, H., & Verfaillie, G. (1995). Valued Constraint Satisfaction Problems: HardEasy Problems. Proceedings IJCAI95, pp. 631637.Van Hentenryck, P., Michel, L., Perron, L., & Regin, J.-C. (1999). Constraint Programming OPL.Proceedings International Conference Principles Practice DeclarativeProgramming, pp. 98116.van Hoeve, W.-J., Pesant, G., & Rousseau, L.-M. (2006). Global Warming: Flow-based SoftGlobal Constraints. J. Heuristics, 12(4-5), 347373.Zytnicki, M., Gaspin, C., & Schiex, T. (2009). Bounds Arc Consistency Weighted CSPs. JournalArtificial Intelligence Research, 35, 593621.292fiJournal Artificial Intelligence Research 43 (2012) 477522Submitted 12/11; published 03/12Proximity-Based Non-uniform AbstractionsApproximate PlanningJir BaumAnn E. NicholsonTrevor I. DixJiri@baum.com.auAnn.Nicholson@monash.eduTrevor.Dix@monash.eduFaculty Information TechnologyMonash University, Clayton, Victoria, AustraliaAbstractdeterministic world, planning agent certain consequencesplanned sequence actions. so, however, dynamic, stochastic domainsMarkov decision processes commonly used. Unfortunately suffer cursedimensionality: state space Cartesian product many small sets (dimensions),planning exponential number dimensions.new technique exploits intuitive strategy selectively ignoring various dimensions different parts state space. resulting non-uniformity strongimplications, since approximation longer Markovian, requiring use modified planner. also use spatial temporal proximity measure, respondscontinued planning well movement agent state space, dynamically adapt abstraction planning progresses.present qualitative quantitative results across range experimental domainsshowing agent exploiting novel approximation method successfully finds solutions planning problem using much less full state space. assessanalyse features domains method exploit.1. Introductiondeterministic world planning agent certain consequencesactions, plan sequence actions, knowing execution necessarilyachieve goals. assumption appropriate flexible, multi-purpose robotsintelligent software agents need able plan dynamic, stochasticdomains operate, outcome taking action uncertain.small medium-sized stochastic domains, theory Markov decision processesprovides algorithms generating optimal plan (Bellman, 1957; Howard, 1960; Puterman & Shin, 1978). plan takes account uncertainty outcome takingaction, specified distribution possible outcomes. flexibility,reward function rather simple goal, relative desirabilityotherwise situation specified.However, domain becomes larger, algorithms become intractable approximate solutions become necessary (for instance Drummond & Bresina, 1990; Dean,Kaelbling, Kirman, & Nicholson, 1995; Kim, 2001; Steinkraus, 2005). particularstate space expressed terms dimensions, Cartesian product sets,size resulting computational cost exponential number dimensions.c2012AI Access Foundation. rights reserved.fiBaum, Nicholson & Dixhand, fortunately, results fairly structured state-space effectiveapproximations often possible.solution based selectively ignoring dimensions, partsstate space, time. words, obtain approximate solutionsdynamically varying level abstraction different parts state space.two aspects approach. Firstly, varying level abstraction introducesartefacts, planning algorithm must somewhat modified eliminate these.Secondly, interestingly, appropriate abstraction must selected later modifiedplanning action progress.work extension synthesis two existing approaches approximate planning: locality-based approximation envelope methods (Dean et al., 1995)structure-based approximation uniform abstraction (Nicholson & Kaelbling, 1994; Dearden & Boutilier, 1997). work extends exploiting structurelocality, broadening scope problems contemplated. Baum Nicholson(1998) introduced main concepts full details algorithms experimentalresults presented Baums (2006) thesis. studies arbitraryabstraction, instance Bertsekas Tsitsiklis (1996). However, generallytheoretical case tended treat approximation Markovian,would resulted unacceptable performance practice. improve extending planning algorithm deal non-Markovian aspects approximation.Finally, use measure locality, introduced Baum Nicholson (1998),similar flexible influence measure Munos Moore (1999).assume agent continues improve plan actingplanning failures generally fatal. also deal control error exclusively. Sensorerror considered assumed agent accurately discern currentworld state (fully observable), accurately knows state space, goalreward function, distribution effect actions (no learning).remainder paper organised follows. Section 2 reviews background,introduces abstraction provides framework. Section 3 discusses planningstatic non-uniform abstraction, Section 4 presents method initially selectingnon-uniform abstraction based problem description. Section 5 presents methodchanging abstraction based policy planned, Sections 6 7 introduceproximity measure method varying abstraction based measure,respectively. Section 8 presents results based direct evaluation calculatedpolicy simulation. Finally, Section 9 discusses results Section 10 givesconclusions outlines possible directions future work.2. Planning Non-uniform Abstractionsnon-deterministic world planning agent cannot certain consequencesactions except probabilities, cannot plan simple sequence actions achievegoals. able plan dynamic, stochastic domains, must usesophisticated approach. Markov decision processes appropriate commonly usedrepresentation sort planning problem.478fiProximity-Based Non-uniform Abstractions Planning2.1 Illustrative Problemsaid exposition, present two example problems here. full set experimentaldomains presented Section 8.1.two illustrative problems grid navigation domain, shown Figure 1.integer x coordinates 0 9, three doors eitheropen closed damage indication either yes no. agentmove one four cardinal directions, open door next it, nothing.doors fairly difficult open, probability success 10% per time step,moving 80% chance success, effect case failure. Runningwall closed door causes damage, cannot repaired. transitionsshown Table 1. agent starts location marked s0 Figure 1 doorsclosed damage, goal reach location marked damage.x=0y=01234567s089k31x=0y=0234567s089k312d1d2k14455668d1372391d2k178k2d39(a)k2d3(b)Figure 1: layout grid navigation domain. blue arrows show optimalpath (a) suboptimal path (b) 3Keys problem. 3Doorsproblem grid layout (walls doors) keys.3Keys problem also contains keys, required open doors. agentmay one time. additional action allows agentpick key location shown figure, open action requirescorresponding key effective (there separate unlock action). 3Doors problemcontains keys doors unlocked closed therefore correspondingkeys pickup action.optimal policy obtained exact planning 3Doors problem simply takesshortest path door 2. 3Keys problem, optimal plan collectkeys 3 1, pass south door 1 east door 3, shown Figure 1(a).suboptimal plan shown Figure 1(b).479fiBaum, Nicholson & DixxStaypre-stated1d2d3post-stated1d2dmgx33y+1South272229openopen80%80%North273303openopen80%80%East444449x0129open80%80%80%80%West555550x0129openOpen22774523239980%80%80%80%80%80%80%80%10%10%10%10%10%10%d3dmgyesyes22y1yesyes5555x+1yesyes4444x1yesyesopenopenopenopenopenopenyesTable 1: Transitions 3Doors problem, showing important changed dimensionsonly. First matching transition used. percentage shown, givenpost-state occur probability, otherwise state unchanged. Transitions without percentages deterministic.480fiProximity-Based Non-uniform Abstractions Planning2.2 Exact PlanningOne approach exact planning stochasticdomainsinvolves using Markov Decisionff0Processes (MDPs). MDP tuple S, A, T, R, , state space,set available actions, transition function, R reward function s0initial state. agent begins state s0 . time step, agent selectsaction A, which, together current state, applies obtain distributionS. current state next time-step random according distributionwrite PrT (s, a, ) probability action taken state result statenext time-step. agent also given reward time step, calculatedR current state (and possibly also action selected). aim agentmaximise cumulative function rewards, typically expected discounted1sum discounting factor . fully-observable MDP, agent full knowledge.particular, agent aware , R current state selecting action.well-known fully-observable MDP, optimal solution expressedpolicy : mapping current state optimum action. planningproblem, then, calculation . side-effect calculation, standardalgorithms also calculate value function V : R, expected discounted sumrewards starting state. Table 2 summarises notation used paper.well known iterative algorithms, Bellmans (1957) value iteration, Howards(1960) policy iteration, modified policy iteration Puterman Shin (1978)computing optimal policy . However, becomes larger, calculationbecomes computationally expensive. particularly state space structuredCartesian product dimensions, = S1 S2 SD , |S| exponentialD. Since algorithms explicitly store V usually , functions S,space complexity therefore also exponential D. Since iterate arrays,time complexity also least exponential D, even considerationfast iterative algorithms converge. Typically, grows, planningquickly becomes intractable. Since practice amount computation allowedagent limited, necessitates approximations process.3Doors problem, six dimensions (two x coordinates, threedoors one damage), = {0 . . . 9} {0 . . . 9} {open, closed}{open, closed} {open, closed} {damage, damage} |S| = 12 800. action spaceset five actions, = {north, south, east, west, open}. transition functionspecifies outcomes taking action state. reward function R 0agent h7, 7i location (marked diagram) damage, 1location damage, 2 damage. Finally, s0 stateagent h0, 0i location, doors closed, damage.Exact planning listed results |S| V (s0 ) comparison.approximation, planner must consider whole state space S. |S| thereforemeasure cost planning directly terms space indirectly termstime. hand, since planning exact, optimal value function V1. illustrative problems simple goals achievement, use time discounting orderremain general mathematical convenience.481fiBaum, Nicholson & DixsymboloriginalSdmeaningabstractW P(S)state space (specific state space / worldview, resp.)dimension state spaceNnumber dimensionssSwWstate0initial statescurcurrent state (in on-line planning)sd Sdwd Sddimension state w, resp.set actions (action space)a0default actiontransition function (formal)PrT :SAS[0, 1] PrT :WAW[0, 1] transition function (in use)R:S RR:WRreward function (one-step reward)V :SRV :W Rvalue function (expected discounted sum rewards)[0, 1)discount factor reward:SA:WApolicy:optimal policyV :S Roptimal value function (exact value function ), :, : Wapproximate policy, ith approximate policyexact value function (note: may abstract)V : RV : RV : W Rapproximate value function (approx. V )Table 2: Summary notation. first column notation original MDP,second notation non-uniform abstraction applied.obtained, along optimal policy ensuring agent expect obtainvalue. figures approximations must measure.2.3 Uniform AbstractionOne method approximation take advantage dimensions ignoringirrelevant marginally relevant order obtainapproximate solution. uniform sense dimensions ignoredthroughout state space. Since approach attacks curse dimensionalityoriginates, dimensions, effective counteracting it.Dearden Boutilier use obtain exact solution (Boutilier, 1997) approximate one (Boutilier & Dearden, 1996; Dearden & Boutilier, 1997). However, abstractions fixed throughout execution, dimensions also deleted problempre-determined sequence. makes approach somewhat inflexible. Similarly,Nicholson Kaelbling (1994) propose technique approximate planning.delete dimensions problem based sensitivity analysis, refine abstraction execution time permits, still uniform. Dietterich (2000) uses kindabstraction combination hierarchical planning good effect: subtask,Navigate location t, ignore irrelevant dimensions, location items482fiProximity-Based Non-uniform Abstractions Planningpicked even ultimate destination agent. Generally, time problemdescription derived general source rather specified particularproblem, uniform abstraction help. Gardiol Kaelbling (2008) use dimensions relevant, marginally, ignoring results approximatesolution improved planning progresses.Unfortunately, however, least human-specified problems, one would generallyexpect mentioned dimensions way relevant. Irrelevant dimensionseliminated human designer natural course specifying problem.Depending domain situation marginally relevant dimensions mightincluded, often, nearly enough effective approximation.list comparisons uniform abstraction results reasonsample domains, makes little sense. almost dimensionsimportant solving problem. case methods existeffective uniform abstraction, integrated approach easily.2.4 Non-uniform Abstractionapproximation, non-uniform abstraction, replaces state space W, particular type partition S, originally introduced Baum Nicholson (1998). callW worldview, members W worldview states members specificstates.2 Non-uniform abstraction based intuitive idea ignoring dimensionsparts state space. example, door interest agentwalk it, ignored parts state spacedistant door. particular member worldview wi W, dimensioneither taken account(concrete, refined in), ignored altogether (abstract,Q completelyw singleton subset correspondingwcoarsened out). wi =d=1concrete dimensions equal Sd abstract dimensions.3 worldviewselection modification methods ensure W remains partition times.give example, 3Doors problem one possible worldview locationdamage dimensions concrete every state, door dimensions concretestates within two steps respective door.Note domain still fully-observable. question lack knowledgedimensions question, wilful conditional ignorance planningmatter computational expediency. approximation also subsumes exactplanning uniform abstraction. exact planning, dimensions set uniformlyconcrete, |W| = |S| worldview state corresponds one specific state.uniform abstraction, combination abstract concrete dimensions fixedentire worldview. treated special cases general approach.42. Previously, used word envelope concept (Baum & Nicholson, 1998), however,worldview better describes approximation used envelope.3. allow dimension partially considered, abstract level dimensions,within them. dimension x coordinate either particular value, fullyabstract, never 59, instance.4. modified calculation reduces standard algorithm uniform fully concrete worldviews,planner obtains standard results cases.483fiBaum, Nicholson & Dixhand, approximation longer Markovian. dimensionabstracted away indeterminate. notation Markov Decision Processes,represented distribution concrete states, dimensionstochastic specific (but ignored) value. distinction importanttruly stochastic outcome, quite valid plan retry actionsucceeds (for instance, opening door 3Doors problem). dimensionmerely ignored, agent obtain outcome (door closed) time movesregion dimension ignored, within worldview, previousstates appear matter. discuss Section 3.2.5 Comparison ApproachesNon-uniform abstractions began appear literature first usually side-effectstructured method, state space represented decision tree basedindividual dimensions, Boutilier, Dearden, Goldszmidt (1995, 2000). Note,however, decision tree structure imposes restriction kinds non-uniformabstraction represented: dimension root tree consideredthroughout state space, on. significant restriction resultsrepresentation much limited representation. similar restriction affectsde Alfaro Roys (2007) magnifying-lens abstraction, refinement multivalued dimensions taken bit-by-bit bits interleaved, leveldecision tree halves space along different dimension pre-determined order.note, would work well dimensions correspond more-or-less connectedspace, gridworld, would less well features like doorsgrid navigation domain. Magnifying-lens abstraction calculates upper lower boundsvalue function, rather single approximation, advantage guidingabstraction selection allows definite termination condition (which lack).hand, always considers fully-concrete states part algorithm, limitingspace savings square root state space, whereas algorithm workmixture variously abstract states necessarily including fully concreteones. Another related approach variable grids used discretisation,indirectly used discrete domains, Boutilier, Goldszmidt, Sabata (1999) do,dimensions reasonably approximated continuous (for instance money). Unlikeapproach, variable grids completely inapplicable predicates binaryenumerated dimensions. Some, Reyes, Sucar, Morales (2009), use techniquesways quite similar continuous MDPs, though quite differentways: consider refinement only, coarsening; use sampling, ratherdirectly dealing domain model; use different refinement method,refinement evaluated fact either committed rolled back.Perhaps similar approach one modules Steinkraus (2005),ignore-state-variables module. However, module appears completely manual,requiring input variables (dimensions) ignored parts statespace. also uses values dimensions current state scur , ratherdistribution, obviously restricts situations may used (for instance,3Doors problem, doors could ignored starting state). Finally, since484fiProximity-Based Non-uniform Abstractions PlanningSteinkraus (2005) analyse report relative contributions modulessolution, meta-planning problem selecting arranging modules,difficult know extent particular module useful.approaches take advantage different features different domains. instance,factored MDP approach (used, instance, Boutilier et al., 2000, Guestrin,Koller, Parr, & Venkataraman, 2003) suitable domains parts stateaction spaces grouped together within group actions actiondimensions affect corresponding states state dimensions interactiongroups weak. St-Aubin, Hoey, Boutilier (2000) iterate symbolic representationform algebraic decision diagrams produce approximate solutions, SannerBoutilier (2009) iterate symbolic representation whole class problemsdomain, using symbolic dynamic programming, first-order algebraic decision diagramslinear value approximation, pre-compute generic solution usedquickly solve specific problems class. focus state space, others approximate action space, typically grouping actions (possibly hierarchically)macro actions, Korf (1985). instance Hauskrecht, Meuleau, Kaelbling, Dean,Boutilier (1998) Botea, Enzenberger, Muller, Schaeffer (2005) take approach,Parr (1998) uses finite state automata macro actions Srivastava, Immerman, Zilberstein (2009) take using algorithm-like plans branchesloops. Goldman, Musliner, Boddy, Durfee, Wu (2007) reduce state space generating (limited-horizon, undiscounted) MDP different, non-MDP representationincluding reachable states, pruning detected clearlyimmediately poor, inferior equivalent already-generated states. Naturally, manyapproaches combined. instance, Gardiol Kaelbling (2004, 2008) combine state space abstraction envelope work Dean et al. (1995), Steinkraus(2005) uses modular planner view combining many approaches mayappropriate given problem. details approaches variantsrefer reader recent survey field Daoui, Abbad, Tkiouat (2010).2.6 Dynamic Approximate Planningtop-level algorithm shown Algorithm 1. initialisation, consistingselecting initial abstraction setting policy, value proximity a0 , 0proportionally size worldview state, respectively,5 planner entersinfinite loop stochastically alternates among five possible calculations,described following sections. elsewhere algorithm, usestochastic choice default absence directed method.agent assumed processing power available acting,continually improve policy, modify approximation updates focusplanning based current state. means agent need planwell unlikely possibilities, therefore expend planning effortlikely paths closer future, expecting reaches partsstate space, improve approximation appropriate.5. Initialising approximate policy action a0 constitutes domain-specific heuristic namely,known default action a0 reasonably safe states, nothing action.485fiBaum, Nicholson & DixAlgorithm 1 High-level algorithm Approximate Planning Dynamic Non-uniformAbstractionsselect initial abstraction /* Algorithm 3 */worldview states w(w) a0 ; V (w) 0; P(w) |w||S|policy value calculation /* Algorithm 2 */loopchoose stochasticallypolicy value calculation /* Algorithm 2 */policy-based refinement /* Algorithm 4 */proximity calculation /* Algorithm 5 */proximity-based refinement /* Algorithm 6 */proximity-based coarsening /* Algorithm 7 */input latest current state; output policyActual execution policy assumed separate thread (executive),planner concern timeliness requirementsdomain: whenever action needs taken, executive simply uses policyrecently received planner.Dean et al. (1995) call recurrent deliberation, use locality-basedapproximation. similar architecture used CIRCA system (Musliner, Durfee, &Shin, 1995; Goldman, Musliner, Krebsbach, & Boddy, 1997) guarantee hard deadlines.CIRCA terminology, planner AIS (AI subsystem), executiveRTS (real-time subsystem).alternative recurrent deliberation pre-cursor deliberation, agent firstplans, finished planning begin act, makingadjustments plan policy. Effectively, planner, current state constantequal initial state throughout planning. work pre-cursor mode usedmeasurements, involves fewer potentially confounding variables.Conceptually, approach divided two broad parts: open-ended problem selecting good abstraction relatively closed problem planning withinabstraction. Since latter part closed, deal first, nextsection, covering Algorithm 2. explore open-ended part Sections 57,covering Algorithms 37.3. Solving Non-uniformly Abstracted MDPsGiven non-uniform abstraction, simplest way use planning take onestandard MDP algorithms, modified policy iteration PutermanShin (1978), adapt non-uniform abstraction minimally. formulae translate486fiProximity-Based Non-uniform Abstractions Planningdirectly obvious fashion. becomes function worldview states instead concretestates, on, shown Algorithm 2 (using simple variant update policyw procedure). Probabilities transition one worldview state anotherapproximated using uniform distribution concrete states (or possiblydistribution, information available).Algorithm 2 policy value calculationrepeat n timesworldview states wupdate value wworldview states wupdate policy wupdate value wprocedure update value wPrT (w, (w), w) = 1/* optimisation V (w) calculated directly case */V (w) R(w)1elsePV (w) R(w) + w PrT (w, (w), w )V (w )procedure update policyP w variant simple(w) min arg maxa w PrT (w, a, w )V (w )procedure update policy w variant Locally Uniform Abstraction/* see Section 3.1 discussion Locally Uniform Abstraction */absdims {d :w . PrT (w, a, w ) > 0 w abstract d}w abstractabsdimsLUA w . w :dimension w = dimension w/ absdimsP|w w |V w . w W |w | V (w )P(w) min arg maxa w PrT (w, a, w )V (LUA(w ))Note Algorithm 2, considered ordered set a0 smallest elementminimum used arg max gives one possibility.two aspects: (a) domain-specific heuristic, instance, breaking ties favourdefault action possible, (b) avoid policy-basedPrefinement (see Section 5)based actions equal value. Secondly, efficiency, w calculatedstates w PrT (w, a, w ) > 0, since states make contributionsum. Finally, number n tuning parameter particularly critical (we usen = 10).course, replacing state space worldview W way not, general,preserve Markov property, since actual dynamics may depend aspects statespace abstracted worldview. simple variant ignore assumeMarkov property anyway, grounds is, all, approximation.Unfortunately, resulting performance unacceptably large error, includingoutright non-attainment goals.487fiBaum, Nicholson & Dixinstance, 3Doors problem, situation occur threedoors whenever abstract s0 concrete near door question.doors relatively difficult open, 10% probability success per try.hand, moving area abstract areaconcrete, assumed probability door already open 50%.calculations performed, turns preferable plan loop, repeatedly tryingillusory 50% chance success rather attempting open door10% chance success. agent never reach goal. Worse still, ways,estimate quality solution quite good, V (s0 ) 19.0,fact better even optimal solutions V (s0 ) 27.5, true qualitysolution poor, V (s0 ) = 100 000, corresponding never reaching goal (butincurring damage, either; figures discounting factor = 0.999 99).Regions take account particularly bad piece information may seem unattractive, described above, vice versa. call problem Ostrich effect,agent refusing accept unpleasant fact, like mythical ostrich burieshead sand. solution, Locally Uniform Abstraction, described next section.abstracted approximation simply treated MDP agentknow state reach (near closed door near open door), correspondunderlying process, might reach particular state deterministically (ashere). problem especially obvious example, planner plans loop.reminiscent problem noted Cassandra, Kaelbling, Kurien (1996),plan derived POMDP failed actual robot got loop particularsituation sensor completely reliable contrary model.3.1 Locally Uniform Abstractionostrich effect occurs states different abstraction considered, instanceone door abstract one door concrete closed.solution make abstraction locally uniform, therefore locally Markovianduration policy generation iterative step. making abstraction locally,temporarily uniform, iterative step policy generation algorithm never workacross edge abstract region, and, since information availablestates considered point, impetus favouredavoided basis (for instance, avoiding state door concrete closedfavour one door abstract). action chosen chosen basedinformation presence absence.modification update policy w procedure Algorithm 2:states considered one one, region around state accessedfunction returns locally uniform version. States concrete stateconsidered averaged ignore distinctions. different statesconsidered, sometimes states taken themselves, sometimes estimatedvalues V averaged adjacent states. means dimensionspartially considered states cases, meanconcrete region must extend one step beyond region dimension488fiProximity-Based Non-uniform Abstractions Planningimmediately relevant. dimension fully considered state, possibleoutcomes actions state must also concrete dimension.modified procedure proceeds follows: first dimensions abstractpossible outcome state updated w collected variable absdims.function LUA constructed takes worldview states w returns potentialworldview states w like w abstract dimensions absdims.core modification, named LUA Locally Uniform Abstraction. Sincepotential states returned LUA not, general, members W, thereforenecessarily value stored V , function V constructed calculatesweightedaverages value function V potential states. sum,Pcalculated states w w w 6= efficiency. Finally,wupdate step carried using two functions LUA V .Unfortunately, modification applied, algorithm may may converge depending worldview. Failure converge occurs concrete regionsmall cases, algorithm cycle two policies (or conceivablymore) instead converging. One must careful, therefore, worldview, avoidsituations, else detect modify worldview accordingly. policybased worldview refinement algorithm described Section 5 ensures convergencepractice.4. Initial Abstractionbeginning planning, planner must select initial abstraction. Sinceworldview never completely discarded planner, infelicity stage mayimpair entire planning process, worldview-improvement algorithmsmake amount weakness here.different ways select initial abstraction. propose one heuristicmethod selecting initial worldview based problem description,variants. Consider example door 3Doors problem associatedtwo locations, is, immediately either side. makes sense, then, considerstatus door two locations. association read problemspecification. Intuitively, structure solution likely resemble structureproblem. incorporates structure transition function initialworldview. reward function also incorporated, reflecting assumptiondimensions reward based important.use two-step method derive initial worldview, shown Algorithm 3.Firstly, reward function specified based particular dimensions. makedimensions concrete throughout worldview, leave dimensions abstract.3Doors problem, x dmg dimensions, step10 10 2 = 200 states worldview.Secondly, transition function specified decision trees, one per action. usefind nexuses dimensions, is, linking points, pointsdimensions interact. nexus corresponds one path roottree leaf. example, 3Doors problem, decision tree open actioncontains leaf whose ancestors x, y, d1 stochastic node, choices leading489fiBaum, Nicholson & DixAlgorithm 3 select initial abstraction/* set worldview completely abstract */W {S}/* reward step */reward step enableddimensions mentioned reward treerefine whole worldview dimension/* nexus step */nexus step enabledleaf nodes action treesworldview states w matching pre-staterefine w dimensions mentioned pre-stateleaf labelled respectively 4, 2, closed 10%. corresponds nexussx = 4, sy = 2 sd1 = closed (the stochastic node ignored determining nexus).total, four nexuses side door, two locations immediatelyadjacent, shown Figure 2(a), connecting relevant door dimension xcoordinates. initial worldview shown Figure 2(b), x, dmg concreteeverywhere doors abstract except concrete one location directlyside door, corresponding location nexuses Figure 2(a).steps, |W| = 212, compared |S| = 1 600 specific states.x=0123456789x=0y=0y=011123456722d1d233d1d2445566778899(a)89d3 d3(b)Figure 2: Nexus step initial abstraction, showing (a) location nexuses3Doors problem (there four nexuses ) (b) locationsdoor dimensions concrete initial worldview.490fiProximity-Based Non-uniform Abstractions Planning3Keys problem, location nexuses Figure 2(a), exceptnexuses location also involve correspondingkey dimensions. Thus, initial worldview, locations shown Figure 2(b)concrete corresponding door dimension, also, closed,corresponding key dimension. states doors open, key dimensionremains abstract. initial worldview size 3Keys |W| = 224.Due locally-uniform abstraction, concrete door dimensions takenaccount minimal degree. worldview used withoutrefinement, expected resulting policies would poor.results6 bear expectation. worldview initialization methods thereforeintended used own, rather basis refinement. Thus,real test methods well work coupled worldviewmodification methods, described below.5. Policy-Based Refinementsection presents first worldview modification methods, policy-based refinement. method modifies worldview based directly current approximatepolicy . particular, refines states based differences actions plannedadjacent, differently-abstract states. differences indicate dimension mayimportant, adjacent states abstract dimension refined (i.e.dimension made concrete states).method previously introduced Baum Nicholson (1998), showed,using small navigation domain example (the 3Doors problem paper),refinement method resulted good policy, though optimal. present quantitative results consider complex domains.5.1 Motivationmotivation method twofold. Firstly, already indicated, method detectsareas particular dimension important, affects action planned,ensures concrete adjacent states. Thus regions dimension takenaccount expand long dimension matters, stop. Secondly,method fulfils requirements choosing worldview avoid non-convergencepolicy calculation, mentioned Section 3.1 above.Dimensions important affect policy, since policy plannersoutput. less important parts state space affectpolicy. Thus, dimensions need concrete remain abstractgleaned part state space comparing optimal actionsvarious states. optimal actions equal, states abstract,differ, states concrete. However, optimal policy .approximate policy worldview, difficult. However, planner comparepolicies areas dimension concrete, found important there,expand area concrete. policy-based refinement policy calculation6. Omitted uninteresting, presented Baum (2006).491fiBaum, Nicholson & Dixalternate, refinement continue area dimension concrete coverswhole region important.Section 3.1 noted planning algorithm requires worldview chosencare. algorithm described section detects situations potentially problematic locally-uniform abstraction modifies worldview preclude them.Intuitively, incorrect behaviour occurs edge concrete region intersectsplace two fairly-similarly valued courses action, correspondingtwo different paths goal.5.2 Methodmethod uses transition function definition adjacent states, worldview states w w considered adjacent . PrT (w, a, w ) > 0. definitionsymmetrical general, since transition function not, problemmethod, seen below. algorithm shown Algorithm 4.Algorithm 4 policy-based refinementcandidatesworldview states wactionsw : P r(w, a, w ) > 0dimensions: w abstract w concretewabstractconstruct w :dimension w = dimension w 6=bw , w . (w ) 6= (wb ) wa w 6= wb w 6=/* policy throughout w */candidates candidates {(w, d)}(w, d) candidatesw W/* replace wgroup states concrete */anewwconcretewnew :dimension wnew = dimension w 6=W W {wnew }new(wnew ) (w); V (wnew ) V (w); P(wnew ) |w|w| | P(w)W W \ {w} /* discarding also stored (w), V (w) P(w) */Example 3Doors problem, instance, applying method planningincreases number worldview states initial 212 220231, dependingstochastic choices (recall |S| = 1 600 comparison). produces concrete regionsnice tight around doors, shown Figure 3, allowing algorithmconverge reasonable solution. solution fact optimal given initialstate s0 , though simply coincidence, since s0 taken accountalgorithm states somewhat suboptimal actions (the agent would reachgoal states, shortest route).492fiProximity-Based Non-uniform Abstractions Planningx=0123456789x=0y=0123456789y=01d1d21k22d1 d1 d1d2 d2 d223d1 d1 d1 d1d23d1 k1 d1 d14d1 d14d1 d1 d1 d1 d155d1 d1 d166d177k1k28d38k39d3 d3 d39k3 k3 k3(a)k2 k2 k2(b)Figure 3: Example non-uniform abstraction (a) 3Doors (b) 3Keys problemspolicy-based refinement. x, dmg dimensions concrete everydwhere; d1, d2 d3 indicate corresponding door concrete; k1,k2 k3 indicate corresponding door concrete correspondingkey also concrete door closed.worldview obtained method often quite compact. instance, ratherrefining simple 2 3 rectangular region side door 3Doors, humanmight, algorithm makes 4 locations concrete approach side door,enough obtain good solution. seen north sides doorsd1 d2, well west side door d3 (3 concrete locations, due edge).departure side doors d2 d3, even better makes refinement all:south door d2 east door d3, action move toward goal, regardlessstatus door actions equal, refinement takes place.south side door d1 seems rather less compact. concrete area factbig 6 locations 3Doors seems excessive compared compactconcrete areas elsewhere. occur nexus close regionbest action take genuinely depends status dimension nexus,difference small. somehow agent found h4, 3i policy-basedrefinement independent scur optimal path genuinely would depend whetherdoor d1 open, path slightly suboptimal case. theoryregion could arbitrarily large extent, seems relatively minor effectpractice. Here, instance, adds couple states, 1% |W|,found real problem domains (or domains used Baum,2006).493fiBaum, Nicholson & Dix5.3 LimitationsPolicy-based refinement deal cases single dimension makes difference. two dimensions needed combination, often miss them.instance, 3Keys problem key quite distant corresponding doorpolicy-based refinement therefore never find relationship two.key, appears reason pick up, door appearsmeans unlocking it.Obviously, fixed ad hoc rewarding picking keys sake.Indeed, domain formulations literature exactly that, rewarding agentpartial achievement goal. However, clean solution. effect,domain specifications cheat providing hints.Another problem policy-based refinement provide coarseningworldview, modifying ways, instance execution progressesplanner needs update plan. Indeed, policy-based refinement ignores initial states0 altogether, current state scur recurrent planning. Thus producessolution regardless part problem agent actually asked solve.waste computation solving parts agent unlikely actuallyvisit, perhaps importantly carries penalty corresponding lossquality relevant parts.following sections describe proximity-based worldview modification, neededsolve domains combinations dimensions important also makesuse s0 scur , appropriate.6. Proximity Measuregeneral, worldview mostly concrete near agent planned pathgoal, allow detailed planning, mostly abstract elsewhere, conserve computational resources. section describe measure (originally Baum & Nicholson,1998) realises concept, proximity P, decreases statefuture less probable.7 section extends brief description BaumNicholson (1998). following section present new worldview modificationmethods based directly measure.6.1 Motivationproximity P realisation intuitive concept states near agentlikely visited, opposed distant agent unlikely. naturallytakes account current state scur recurrent planning, initial state s0pre-cursor planning, unlike policy-based refinement ignores altogether. Thusplanner selecting worldviews based proximity measure produce solutions tailoredparticular scur s0 ignore parts MDP irrelevant nearirrelevant performance state. Thus saves computation would otherwise7. Baum Nicholson (1998) used word likelihood measure. prefer proximityavoid confusion meanings word likelihood. Munos Moore (1999) use wordinfluence somewhat similar measure continuous domains.494fiProximity-Based Non-uniform Abstractions Planningwasted solving parts agent unlikely actually visit, perhapsimportantly carries advantage corresponding gain qualityrelevant parts. allows agent deal problems 3Keys beyondreach policy-based refinement.Implicitly, agent plans reaches mostly-abstract partsstate space, improve approximation appropriate. planner thus continuallyimproves policy, modifies approximation updates focus planning basedcurrent state scur . means refining regions agent findslikely visit, coarsening away details regions longer likelyvisit already traversed.three aspects proximity: temporal, spatial probabilistic. Firstly,temporal aspect indicates states may encountered near future, exponentially decaying scale. second aspect spatial nearness states (in termsstate space) agent planned path. spatial aspect somewhat indirect,spatial structure domain represented implicitly transitionmatrix, proximity measure reflect it. two aspects combinedproximity give single real number 0 1 state, denoted P Pproximity, spatial aspect temporal aspect. numberinterpreted probability namely probability encountering state Pinterpreted probability distribution states, giving final, probabilisticaspect proximity.6.2 Calculationformula proximity P similar formula value function.three differences. Firstly, instead beginning reward function basedcurrent state function, cur. Secondly, transition probabilities time-reversed(that is, matrix transposed). value calculation basedreward function, occurs future (after taking actions), current statefunction based present, taking actions. Since order taking actionsfunction upon formula based reversed time, similar reversal mustb usedapplied transition probabilities. Thirdly, estimated future policybbinstead . estimate, stochastic policy defined making (s) distributionactions assigns constant probability current (s) distributesremaining probability mass among actions equally. distributed probabilitymass corresponds probability policy change sometime future,or, alternately, probability currently-selected action yet correct.formula therefore:Xb ), s)P(s )Pr(s , (s(1)P(s) cur(s) + PP proximity discounting factor (0 P < 1)1 P scur =cur(s) =0otherwise495(2)fiBaum, Nicholson & DixPconstant 1P chosen current-state function P(s) converges1, words P probability distribution. checked near future,agent probability P(s) state s, assuming follow policynear future defined probability checking time proportionalPt (that is, P interpreted stopping probability). value calculation,one instead solve set linear equationsXb ), s)P(s )Pr(s , (s(3)P(s) = cur(s) + Por, matrix notation,(I P TbT )P = cur(4)b identityTb transition matrix induced stochastic policymatrix. implementation uses matrix form, shown Algorithm 5. proximitymeasure needs little adjustment work non-uniformly abstract worldview:simply replaced w (1) (2), scur = becoming scur w.Algorithm 5 proximity calculationsolve matrix equation P linear system:(I P TbT )P = curmeasure two tuning parameters, replanning probability discountingfactor P . replanning probability controls spatial aspect: trades focuslikely path planning less likely eventualities nearby. Similarly, P controlstemporal aspect: smaller P is, short sighted greedy planningbe. Conversely, P close 1, planner spend time planning futuremight better spent planning here-and-now. set dependingreward discounting factor , mode planner. use P = 0.95,replanning probability 10%.Example Proximities 3Doors problem shown Figure 4 initial situation (agent h0, 0i, doors closed) possible situation later execution(agent h4, 2i, doors closed). Larger symbols correspond higher proximity. Oneimmediately see agents planned path goal, large symbols correspondstates agent expects visit. Conversely small proximities show locationsagents planned path goal. example, agent expect visitstates south-western room, especially already passed door1. Similarly, proximities around initial state much lower agenth4, 2i, expect need return.6.3 DiscussionOne interesting feature resulting numbers emphasise absorbing nearabsorbing states somewhat might intuitively expected. However, considering496fiProximity-Based Non-uniform Abstractions Planningx=0123456789x=0y=0y=0112233445566778899hx = 0, = 0i123456789hx = 4, = 2iFigure 4: Proximities 3Doors problem s0 possible later scur ; symbol sizelogarithmic, proximities range 237 21.4 ; P = 0.95, replanning probability 10%.absorbing states general important, good feature, especially sincenormally planner try minimise probability entering absorbing state(unless goal). feature help ensure absorbing states keptmind long chance falling them. Dean et al. (1995), instance,note algorithm undesirable absorbing states along path goaltend come candidates removal consideration (due low probabilityreaching current policy), make special accommodationremoved consideration. proximity measure emphasisingstates, special handling necessary.contrast approach, Kirman (1994) uses probabilities Es steps,Es (an estimate of) number steps agent take switchingprevious policy policy currently calculated. assumes Esestimated well, current policy policy executive, oneplanning-cycle probability appropriate measure. fact one would prefer leasttwo-planning-cycle look-ahead, agent begins within area focusnew policy, also remains throughout validity policy, probablylonger, since planners foresight extend beyond next thinking cycle.philosophically, reliance planning cycle length desirable,artefact planner rather intrinsic domain.somewhat related approach prioritised sweeping (see instance Barto, Bradtke,& Singh, 1995). Like present approach, defines measure statesway interesting. Unlike approach, applies measure determine497fiBaum, Nicholson & Dixorder formulae V calculation applied,applied preferentially interesting states less frequently uninterestingunimportant states. well-known order calculation MDP planningalgorithms varied greatly without forfeiting convergence optimal policy,prioritised sweeping takes advantage this. Often done measure changeV previous calculations, approaches use look-ahead current state,ways simple version proximity (in fact, correspondsthreshold P replanning probability set 1). proximity measure P might wellgood candidate approach: apply V calculation states chosen directlyaccording P distribution.8Munos Moore (1999) use influence measure deterministic continuousdomains, similar P. fact, main difference measuretwo parameters re-uses replanning probability(effectively zero). means cannot take account replanning, neitherdifference horizon entails, possibility policy may changeacted upon. Absorbing states, instance, would emphasisedproximities.7. Proximity-Based Dynamic Abstractionproximity measure described previous section used focus planners attention areas likely useful near future. Firstly, means worldviewmade match proximities, refining coarsening appropriate. Secondly, since proximity measure takes account current state, methodautomatically update worldview agents circumstances change recurrentmode, is, planning execution concurrent.7.1 RefinementHigh proximity indicates states agent likely visit near future.planner therefore plan states carefully. abstract, reasonrefine allow detailed planning. states high proximitytherefore considered candidates refinement.High proximity defined simple threshold, shown Algorithm 6.refinement occurs, anomaly sometimes appears. Like anomaly ledpolicy-based refinement method, arises different levels abstraction, here,adjacent abstract state causes problem, rather recentlyrefined one. state refined, values V new states initially estimatedstates previous value V . However, typically, meansoverestimated others underestimated. policy re-calculated,state overestimated value attractive.Since problem directly follows moment refinement, self-correcting.iterations, planner converges correct policy values. However,8. retaining theoretical guarantee convergence desired, care would taken sinceP zero states reachable current state. practice, course, optimalityotherwise unreachable states immaterial.498fiProximity-Based Non-uniform Abstractions PlanningAlgorithm 6 proximity-based refinementstochastically choose dimensionworldview states wP(w) > threshold w abstract/* replace wgroup states concrete */anewwconcreteneww:dimension wnew = dimension w 6=W W {wnew }new(wnew ) (w); V (wnew ) V (w); P(wnew ) |w|w| | P(w)W W \ {w} /* discarding also stored (w), V (w) P(w) */so, transient anomalies appear policy, worst case,planner may replan path, refine states re-triggeranomaly. Rather large parts state space spuriously refined way.occurs combined V calculation phase, may updateV chance converge. solution create variant phase, Vcalculation only, replaces V calculation phase values stabilise.two iterations, appears sufficient. alternative solution wouldcopy difference values adjacent, concrete statespossible, thus obtaining better estimated values newly-refined states. However, sincesimpler solution V -only calculation works satisfactorily, complex possibilityexplored.7.2 CoarseningLow proximity indicates states agent unlikely visit near future.planner therefore need plan states carefully. Usually, alreadyabstract, never refined first place. However, concretepreviously refined reason coarsen free memoryCPU time detailed planning elsewhere. states low proximitytherefore considered candidates coarsening.Proximity-based coarsening useful primarily on-line planning scenario recurrent planning. agent moves state space current statescur changes, states likely visited near future. especially useful agent finds unexpected part state space, instancedue low-probability outcomes, agent planned path leading part waygoal (perhaps partial reward). case, however, parts statespace already traversed coarsened favour refinement front agent.9One might also imagine planning progresses, planner may wish concentratedifferent parts state space coarsening might useful cull abandonedexplorations switch focus. However, observed domains9. States already traversed cannot discarded, even agent never visit again, sinceworldview partition since agent necessarily know whether need revisit (orend revisiting) states.499fiBaum, Nicholson & Dixfound pre-cursor mode, coarsening generally worsens quality policiespositive contribution.Coarsening proceeds three steps, shown Algorithm 7. first stepsimilar proximity-based refinement: time proximity-based coarsening phaseinvoked, worldview scanned states low proximity (below threshold),put list candidates. second step tricky. Coarsening needs joinseveral states one. However, representation allow arbitrary partitionsworldviews therefore allow coarsening-together arbitrary setworldview states. planner must therefore find group states among lowproximity candidates coarsened valid worldview state. groupsdetected fact differ one dimension sizedimension, therefore covering completely. Finally, groups foundreplaced single abstract state.Algorithm 7 proximity-based coarsening/* collect candidates coarsening */candidates {w : P < threshold}/* find groups candidates coarsened together *//* partition candidates according pattern abstract concrete dimensions */patterns candidates / {(wa , wb ) : . wa concrete wb concrete d}groupsp patternsdimensionsstates p concrete/* partition p dimensions except d, giving potential groups */potgroups p / {(wa , wb ) : 6= . dimension wa = dimension wb }/* add potential groups size dimension groups */groups groups {g potgroups : |g| = |Sd |}/* replace group states single, abstract state */g groupsg Wstochastically choosewa gnewwabstractconstruct wnew :dimension wnew = dimension wa 6=W W {wnew }P1 Pnew )(wnew ) (wa ); V (wnew ) |g|wg V (w); P(wwg P(w)W W \ g /* discarding also stored (w), V (w) P(w) w g */cases, may impossible coarsen section worldview despite lowproximity, due situation somewhat akin grid-lock. Probably simplest exampleone Figure 5, shows worldview five states three-dimensional binaryspecific state space, three states ignoring different dimension each,remaining two take account three. situation, group states500fiProximity-Based Non-uniform Abstractions PlanningS100001111S200111100S301100110w1w2w3w4w5Figure 5: non-uniform worldview cannot immediately coarsened. state spacethree binary dimensions (eight states). worldview two concrete states,w1 w4 , three abstract states, w2 , w3 w5 , abstract differentdimension.coarsened single dimension. coarsening possible, one states mustfirst refined, low P candidates proximity-basedrefinement. this, integration uniform abstraction method coarseningwould also straightforward selecting initial worldview refinement,unless worldview kept uniform. However, even non-uniform worldview woulddifficult. instance, dimension could simply removed possiblerather everywhere.8. Resultsrun algorithm range different domains demonstrate approach.domains divide two broad groups. first group consists grid navigationdomain only. domain intuition gathered preliminary runsdone, however, problems domain show well approach performs,cannot show generality. second group consists domains literature,demonstrating well approach generalises.8.1 Experimental Domainsintroduce domains section. first five problems grid navigationdomain, two already described Section 2.1, shown Figure 1, three additionalproblems. remaining domains based domains literature, particularused Kim (2001) Barry (2009).described Section 2.1, problems grid navigation domain shown Figure 1x dimensions size 10, three door dimensions (binary: open/closed)damage dimension (also binary). far 3Doors problem, 3Keysproblem, keys agent must pick keys open corresponding doors.three remaining problems 1Key, shuttlebot 1010. 1Key problemsimilar 3Keys, except agent capable holding one key time,instead three binary dimensions keys, one four-valued dimensionindicating key agent holds (or none). shuttlebot problem introducescyclic goal (with extra loaded dimension damage dimension tri-valued)501fiBaum, Nicholson & Dix(a) grid navigation domainkeys worldProblem3Doors01Key333Keys0shuttlebot10100keys held time11, 2 3notecyclictileddimensions67978|S|1 6006 40012 8004 800160 000(b) robot4 -k domainProblemrobot4 -10robot4 -15robot4 -20robot4 -25dimensions11162126|S|10 240491 52020 971 520838 860 800(c) factory domainProblems-factorys-factory1s-factory3(d) tireworld domainlocationsProblemtire-small58tire-mediumtire-large1919tire-large-n0initialn1n0n12n0dimensions172125goaln4n3n3n3|S|131 0722 097 15233 554 432route length3413dimensions12184040|S|4 096262 1441 099 511 627 7761 099 511 627 776Table 3: Experimental domains problems, dimensionality statespace size.1010 variant increases size problem tiling grid 10direction (by two extra dimensions, xx yy, size 10). Table 3(a) summarisesproblems domain.next two domains based Kim (2001). Firstly, robot4 -k domain,based Kims (2001) ROBOT-k domain reducing number actionsfour. robot4 -k domain problems consist cycle k rooms shown Figure 6,room light, analogous doors 3Doors problemenable agent move. four actions variant go forward, turn lightcurrent room off, nothing. original formulation allowed agentcombination toggling lights going forward, total 2k+1 actions,reduced approach intended approximate action space.goal move first room last. k + 1 dimensions state spacek2k states, listed Table 3(b).502fiProximity-Based Non-uniform Abstractions Planning4k-13021Figure 6: robot4 -k domain.drill Bpart B:shape Bdrilledpolish Bpolish Bshapeddip Bpolishedspray Bhandpaint Bpaintedglueconnectedboltdrillpart A:shapeshapeddrilledpolishpolishdippolishedspraypaintedhandpaintFigure 7: factory domain.Kims (2001) factory domain10 series variants simple manufacturing problem, represented purely predicates (that is, dimensions size 2). agent makeproduct two parts must drilled, painted finally joined together.Figure 7 shows simplified diagram, omitting interactions optionsinstance, achieve painted predicate, agent may spray, dip handpaintobject; connect two objects, may use glue bolt (and latter requiresdrilled); on. Unlike domains, partial rewards availableagent achieving certain subgoals. problems used listed Table 3(c).final domain tireworld domain 2006 ICAPS IPC competition(Littman, Weissman, & Bonet, 2006) used Barry (2009). domain, roboticcar trying drive point point B. car room carry one spare tirelocations additional spare tires them. locations, carcarrying spare, pick one up. n locations car,2n + 2 binary dimensions problem, follows: n dimensions used representlocation car. valid states states one location dimensiontrue, explicitly stated anywhere domain.11 Another n dimensionsused represent locations spare tire not. final twodimensions represent whether car carrying spare whether flat tire.10. domain previously used Hoey, St.-Aubin, Hu, Boutilier (1999) basedbuilder domain Dearden Boutilier (1997) adapted standard job-shop schedulingproblems used test partial-order planners.11. touch aspect discussion Section 9, case include domain withoutchange order facilitate comparison literature.503fiBaum, Nicholson & Dixn0n15n10n8n4n0n12n17n6n3n9n8n18n2n6n14n4n10n16n2n1n1n1n13n3n12n3n7n0tire-smalln7n11tire-mediumn5tire-largegoal ( )locations.Figure 8: tireworld domain problems, indicating initial ( )Barry (2009) uses two tireworld problems, labelled small large.small tireworld problem 5 locations 12 variables 14 actions, largeone 19 locations 40 variables 100 actions. Curiously, large problem,direct road initial goal locations, takes single actionsolve problem. makes difficult assess whether Barrys method has, fact,scaled up. addition two, created medium-sized tireworld, 8 locations18 variables, removing locations large tireworld moving initiallocation n0, goal. variants listed Table 3(d) shownFigure 8. final variant, tire-large-n0, shown, identical large tireworldexcept initial location moved n0.8.2 Direct Evaluation Policies Pre-cursor Deliberationsmaller problems 3Doors, 1Key, 3Keys, directly evaluateapproximate policies produced planner running pre-cursor deliberation.problems small enough use exact algorithm calculate actual valuefunction corresponding approximate policies. noted Section 2.6,useful involves fewer potentially confounding variables, exploit fullpotential approach.12Table 4(a) shows results policy-based refinement is,proximity-based methods (Algorithms 5, 6 7) disabled. problem, tablelists size problem |S| value optimal solution initial state12. Proximity-based coarsening (Algorithm 7) primarily aimed regions state space agentalready traversed, pre-cursor deliberation traversal. Coarsening would thereforeexpected bring limited benefit pre-cursor deliberation direct evaluation wouldmeaningful evaluate performance. therefore evaluated recurrent deliberation.504fiProximity-Based Non-uniform Abstractions Planningolutionvaluwoerldviewsizerelatiworldviewsizplaennerestisoluti tevalueactualsolutionvalueizeoptimalstatespcediscountingfactorV (s0 ), representing costs results exact planning. followedsize worldview |W| absolute number percentage |S|, plannersestimate value solution initial state V (s0 ), actual valuesolution initial state V (s0 ). first half part table discountingfactor = 0.999 99, second half = 0.95. Averages 10 runsshown planner run 1000 . 1000 chosen approximationassumed 1 000 phases sufficient planner converge. practice,convergence generally took place much earlier. detected, however,overall assumption planner continues plan forever, responding changinginputs, makes convergence somewhat irrelevant.problem|S|V (s0 )|W|(a) policy-based refinement226.40.999 99 3Doors1 600 27.50326.81Key6 400 79.473Keys12 800 61.98262.0222.60.953Doors1 600 14.631Key6 400 19.59296.8245.73Keys12 800 18.99(b) proximity-based refinement0.999 99 3Doors1 600 27.50 1 381.71Key6 400 79.47 4 166.73Keys12 800 61.98 4 262.80.953Doors1 600 14.63 1 363.21Key6 400 19.59 2 828.23Keys12 800 18.99 4 230.6(c) policy- proximity-based refinement0.999 99 3Doors1 600 27.50 1 361.71Key6 400 79.47 4 635.53Keys12 800 61.98 5 948.20.953Doors1 600 14.63 1 359.51Key6 400 19.59 4 036.13Keys12 800 18.99 3 748.8|W||S|V (s0 )V (s0 )14%5.1%2.0%14%5.6%1.9%22.5037 512.2025 015.6013.2215.2314.5627.50100 000.00100 000.0014.6320.0020.0086%65%33%85%44%33%27.5060 031.7970 018.5914.6319.9219.7027.5060 031.7970 018.5914.6319.9219.7085%72%46%85%63%29%27.5020 063.5730 043.3914.6319.6720.0027.5020 063.5730 043.3914.6319.6720.00Table 4: Results direct evaluation policies pre-cursor deliberation threedifferent refinement methods, evaluated 1 000 phases.505fiBaum, Nicholson & Dixresults part (a) table divide neatly two types: without keys (3Doorsproblem), planner succeeds ten runs, getting perfect policies given startingstate. two problems, 1Key 3Keys, planning invariably fails. twoproblems, agent must pick key far door opens, versionplanner simply cannot think ahead extent. three these, plannersomewhat optimistic, estimating better value obtains cases evenbetter optimum. instance, 3Doors problem = 0.999 99, plannersestimate value V (s0 ) 22.50, better true valueoptimum, V (s0 ) = V (s0 ) = 27.50. fractional |W| table dueaveraged ten runs. final size worldview sometimes depends extentorder dimensions states refined, order randomisedruns. instance, 3Doors problem = 0.999 99, W varioussizes ranging 220 231 states end ten runs, average226.4.results part (a) similar two values . main differencesmaller leads smaller numbers. instance, value indicating failure 100 0001,= 0.999 99 20 = 0.95. values tend multiples 11smaller value here, 1 20 rather 100 000. cases,smaller range make differences less obvious: instance, estimated value1column (V (s0 )), clear whether numbers approximations 1 11(and failure reach goal) 0 1minus small number (representing success).1represent rewards costsunits represent once-off rewards costs, multiples 1obtained perpetuity. However, expected desired behaviour. smallerrepresents disinterest distant future, reward cost perpetuitymuch important once-off reward cost.Table 4(b) shows results ten runs pre-cursor mode 1000 proximitybased refinement (no policy-based refinement coarsening) problem. seen, 3Doors problem solved optimally cases.surprising, complex problem.1Key 3Keys problems interesting. figures Table 4(b) ariseaverage 31 successful runs, values close equal optimal valuesV (s0 ), 23 unsuccessful runs values 100 000. = 0.999 99,planner found successful policy 4 10 runs 1Key problem 3 times10 3Keys problem. Similarly = 0.95 case (2 times 3 times,1respectively), since optimal path quite long compared 1, successmeans reward 19.59 (or 18.99) failure punished 20, effectdifficult discern.Table 4(c) shows results proximity-based refinement policy-based refinement combined (no coarsening). Naturally, 3Doors problem either refinementmethod alone already obtained optimal policy shows improvement. worldview size |W| differs slightly Table 4(b), policy-based refinement sometimesdirected, |W| tend slightly smaller exploratory proximitybased refinement alone, larger policy-based refinement alone.506fiProximity-Based Non-uniform Abstractions Planningtwo problems, 1Key 3Keys, show improvement compared eitherrefinement methods alone. solved 43 runs = 0.999 99values 20 063.57 30 043.39 represent averages 2 3 unsuccessful runs8 7 successful ones, compared 4 3 successful runs proximity-basedrefinement successful runs policy-based refinement only. = 0.95,1Key problem solved 8 runs, due discounting lengthpath, goal near horizon. Again, success meaning reward19.59 failure receives 20, distinction great. 3Keys problem= 0.95 find solution parameters, receives uniform20 runs, suboptimality one unit.behaviour runs generally quite straightforward. Typically,initially calculating agent cannot reach goal initial worldview,worldview size gradually increases, plateaus coarsening here, movement agent, behaviour really possible. successful runs,planner plans route goal point increase, worldview becomes sufficient, V (s0 ) quickly reaches final value. Rarely, V (s0 ) may oscillatetwice first. omit graphs here, presented Baum (2006).8.3 Evaluation Simulation Recurrent Deliberationlarger problems, performance evaluated simulation, running agentsimulated world observing reward collects. problems, directevaluation possible calculating actual value function using exactalgorithm longer tractable. Simulation recurrent delibertion also contextcoarsening evaluated. comparison, section presents results3Keys problem evaluated simulation, without coarsening.Figure 9 shows representative sample results simulation 3Keys problemrefinement methods coarsening, combination optionsshown Table 4(c) previous section, evaluated simulation rather directly.small graph shows different individual run. seen, agent behavesreasonably working recurrent planning mode simulation.left vertical axes graphs represent reward R, plotted thick red lines.run 1 Figure 9, instance, agent starts receiving reward 1step, meaning goal, damage domain. 180 onwards, receivesreward 0 per step, meaning goal, damage. right vertical axesworldview size |W|, thin blue lines. shown details throughout section,is, scaled actual worldview sizes rather full 1|S| ranges. Taking run 1Figure 9 again, see |W| grows relatively quickly 80, continuesgrow slowly eventually levels little 5 000. full state space,comparison, 12 800. run 2, agent received reward similarly, state spacegrew longer, eventually levelling somewhat 7000. runs 3 4, agentfailed reach goal continued receiving reward 1 throughout. run 3,worldview size levelled little 3000, run 4 steadily grew 5000.horizontal axes simulated world time, corresponding discrete time-stepsMDP. two time-scales simulation: wall clock time, indicating507fiBaum, Nicholson & Dix1:|W|R2:7000600007000600005000500040004000300030002000-1|W|R2000-11000050100150200100002500|W|R50100time3:150200timeR4:700060000|W|7000600005000500040004000300030002000-12000-110000501000250150200100002500time501001502000250timeFigure 9: Simulation results, 3Keys problem, policy-based proximity-based refinement,coarsening (four runs). Reward (left axes, thick red lines) worldview size|W| (right axes, thin blue lines; detail) world time (horizontal axes).passage real time, number phases planner performed. simulation configured take 1 time step per 10s wall clock time. number phasesRcontrolled simply given speed (1.5GHz Intel) CPU implementation coded flexibility rather efficiency. Ideally, agent graduallymove general direction goal planning, simplifies problem,fast agent runs far ahead abstraction planner.planner algorithm terminate, since planner assumed keep planning(and agent keep acting) indefinitely. goal-oriented domains,examples paper, one might consider achieving goal terminationcondition, (a) example domains assume agent continuegoal goal maintenance, albeit trivial, (b) apply non-goal-orienteddomains (c) even goal-oriented domains clear apply conditioncase agent fails reach goal. simulation, therefore, runs eitherterminated manually, succeeded appeared progress508fiProximity-Based Non-uniform Abstractions Planning1:|W|R0-102:900080007000600050004000300020001000050 100 150 200 250 300 350 4000-10time|W|R900080007000600050004000300020001000050 100 150 200 250 300 350 400timeFigure 10: Simulation results illustrating effect coarsening worldview size, 3Keysproblem, policy-based refinement, proximity-based refinement coarsening(two runs).likely made, run fixed number world time steps, selected basedmanually-terminated runs allowance variation.coarsening Figure 9, worldview sizes monotonic increasing.Different runs refined differently domain algorithm stochastic.beginning planning, agent receiving reward 1 per step,yet goal. worldview size increases, planner eventually finds policyleads goal runs 1 2, seen better reward 0 obtainedruns. simple relationship worldview size performance: runsworked worldview 5 000 larger generally succeeded, smallerworldviews generally not. vast majority runs (> 90%), agent reachedgoal.coarsening (Algorithm 7) activated, compared situation turnedoff, reward gathered agent declines slightly, still reaches goalvast majority runs (> 90%). Figure 10 shows two runs, one successful oneunsuccessful, 3Keys problem proximity-based coarsening well tworefinement methods, contrast Figure 9 two refinement methodsused. Note effect interleaving refinement coarsening: worldviewsize |W| (thin blue line) longer monotonic, instead alternately increaseddecreased, shows jagged line graph. Slightly fewer runs reachgoal. decline solution quality expected, however, since goal coarseningreduce size worldview.completeness, also tested agent proximity-based methods(Algorithms 6 7) active policy-based refinement (Algorithm 4) deactivated.configuration, agent collects reward generally takes steps towardgoal, without directed policy-based refinement, largely exploratoryproximity-based methods discover keys consequently cannot reach goal.509fiBaum, Nicholson & Dix8.4 Effect Discounting Factorshuttlebot problem similar 3Doors problem requires agent moveback forth two locations repeatedly. interesting preliminaryruns pre-cursor mode solved = 0.999 99 solved optimally= 0.95. considered whether = 0.999 99 case might behave bettersimulation, agent took advantage possibility planning nearestreward replanning reward obtained. all, agent could functionwell even none policies good solution itself. However, illustratedFigure 11, agents behaviour similar pre-cursor case: = 0.999 99,(a) refinement only, run 1, (b) coarsening, run 2, would pick rewardimmediately adjacent s0 , that. Again, setting planners discountingfactor 0.95, (c) coarsening, runs 3 4, provided much better performance.13Note effect balance refinement coarsening (b) (c):worldview size |W| nice steady throughout runs (though admittedly fairfraction |S| = 4 800).8.5 Initial Worldviewproblems, standard initial worldviews large planner. Evenmodified, smaller initial worldviews obtained enabling nexus step Algorithm 3disabling reward step large. Disabling reward nexus stepsresults singleton initial worldview, W = {S}, treats entire state spacesingle (very) abstract worldview state. Unfortunately, means plannerstarts little way hints direction refine and, leastinitially, information base crucial decision. upshotcollects reward. cases remains initial state s0 , others moves aroundstate space sometimes distance, times small loopreach goal subgoals.14situation factory domain problems Kim (2001), factagent collected reward simulated runs, even though quite runssubstantial actions taken. similar result occurs 10x10 problem (in gridnavigation domain). reward obtained agent problem,standard initial worldview somewhat large planner and, again, singletoninitial worldview badly. best, runs, agent took limited stepsgeneral direction goal.interesting case tireworld domain. Again, tire-large largestandard initial worldview fails obtain solution reward step initialworldview only. However, manually-chosen initial worldview refines locationsalong path start state goal planning begins, planner solvestire-large, also tire-large-n0 40% runs (in one lessone minute, although atypical).13. rewards appear two horizontal lines runs 3 4, one solid one broken, taskcyclic, agent collects reward 1 twice cycle reward 0 steps.14. details unsuccessful runs, including |W| behaviour, given Baum (2006).510fiProximity-Based Non-uniform Abstractions Planning(a) = 0.999 99, coarsening (one run)R|W|1:4500(b) = 0.999 99, coarsening (one run)R|W|2:45004000400035001350013000300025002500200020001500015000100010005000100020003000500040000200time400600800(c) = 0.95, coarsening (two runs)R|W|3:45004:|W|R4000350013000300025002500200020001500015000100010005001000200030004500400035001001000time500040000time100020003000400005000timeFigure 11: Simulation results illustrating effect discounting factor, shuttlebotproblem, policy-based proximity-based refinement.8.6 Worldview Size QualityFinally, consider effect worldview size quality robot4 domain,agent moves series rooms lights. domain excellent examplesimulated agent works well. runs robot4 -10 robot4 -15 problemsagent thought small amount time, quickly moved goal stayedthere, small worldviews, seen Figure 12 robot4 -15problem. Four representative runs shown, two two refinement methods(runs 1 2) two three methods (runs 3 4). four runs, worldviewsizes |W| reasonable consider full state space contains almost half millionstates, 1 000-state worldview represents fifth percent. Despite smallworldview size, however, planner effective. dozen phases, agentreached goal. planner works well robot4 -10 robot4 -15.comparison, Kims (2001) largest ROBOT-k problem ROBOT-16, though sinceROBOT-16 216+1 = 131 072 actions robot4 -k domain problems 4,511fiBaum, Nicholson & Dix(a) coarsening (two runs)R1:|W|2:1200|W|R100012001000118008006006004004000020020000 10 20 30 40 50 60 70 80 90 10000 10 20 30 40 50 60 70 80 90 100timetime(b) proximity-based coarsening (two runs)R|W|3:4:1200|W|R100012001000118008006006004004000020020000 10 20 30 40 50 60 70 80 90 10000 10 20 30 40 50 60 70 80 90 100timetimeFigure 12: Simulation results, robot4 -15 problem, = 0.999 99, policy-based proximity-based refinement, without proximity-based coarsening.direct comparison would valid. hand, values k (10, 15on) necessarily powers 2, since, unlike Kim, domain specificationalways considers room numbers atomic rather binary numbers, particularadvantage powers 2.results robot4 -20 problem beginning interestingrobot4 -10 robot4 -15. Figure 13(a), showing two runs coarsening(runs 1 2), agent succeeds reasonably promptly reasonable worldviewsizes. However, illustrated Figure 13(b), coarsening active planner failsreach goal runs (about 40%, example, run 3) succeeds others(about 60%, example, run 4). state space contains almost 21 million states,successful worldviews Figure 13 order 0.01% full state space size.Figure 14 shows four representative runs robot4 -25 problem, (a) two without coarsening (runs 1 2) (b) two three methods (runs 3 4). problem state space 25 225 839 million states, effect noted robot4 -20512fiProximity-Based Non-uniform Abstractions Planning(a) coarsening (two runs)R1:|W|2:8000|W|R7000170006000016000500050004000400030003000200002000100005010015020010000250050100time150200|W|R700010160005000500040004000300030002000020001000100150200800070006000500250time(b) proximity-based coarsening (two runs)R|W|4:3:800008000100002500time501001502000250timeFigure 13: Simulation results, robot4 -20 problem, = 0.999 99, policy-based proximity-based refinement, without proximity-based coarsening.much pronounced here: without coarsening, planner tends much larger worldviews15 large worldviews cause planner run slowly. noted Section 8.3above, horizontal axes world time, planning time. relation twovaries quite significantly runs two policies per time stepsmaller worldviews less one ten time steps worldviews grewlarge.far reaching goal concerned, two cases similar. Again, successfulruns maintain reasonably-sized worldview, runs 2 4. Runsworldview size grows big invariably fail (runs 1 3). differencetime, smallest successful worldview, run 4 Figure 14, used around 2 000 well-chosenworldview states, 0.000 24% full state space. worldview growsbeyond miniscule fraction state space even 19 243-state worldview15. Note run 1 plotted different scale worldview size |W| axis compared runs 2, 34. makes details behaviour easier see, makes size run 1 less obvious.513fiBaum, Nicholson & Dix(a) coarsening (two runs)R1:00|W|2:2000018000160001400012000100008000600040002000050 100 150 200 250 300 350 400|W|R80007000160005000400030000200010000time050 100 150 200 250 300 350 400time(b) proximity-based coarsening (two runs)R|W|4:3:|W|R800080007000170001600006000500050004000400030003000020002000100002505007501000010000time020 40 60 80 100 120 140 160timeFigure 14: Simulation results, robot4 -25 problem, = 0.999 99, policy-based proximity-based refinement, without proximity-based coarsening. Notedifferent scales worldview size |W| axis run (a)1.run 1 Figure 14 0.002 3% planner stall progresspossible. Even challenging environment, agent reaches goal almost halfruns.9. DiscussionSection 8 presented results across range experimental domains showing methodsuccessfully finds solutions planning problem using much less full state space,well limitations. section discuss results analysefeatures domains method exploit give difficulty.smaller problems, could directly evaluate policies produced methodpre-cursor mode, allowing us better isolate behaviour planner. Withoutproximity-based methods, worldviews quite small planner could solve514fiProximity-Based Non-uniform Abstractions Planning3Doors problem. However, even better uniform abstraction, couldlittle here. Even oracle could best remove one door key 3Keystwo doors 3Doors, giving 25% relative worldview size however, plannerused uniform distribution removed dimension, agent would fail anyway, sinceopening doors left worldview would harder hoping bestassumed-50%-open door actually closed. succeed, would alsodeduce abstracted doors considered closed, considerable feat.function sample domains. circumstances, uniform abstraction couldeffective, either pre-processing step approach integrated W selectionmethods.expected turning proximity-based refinement (Algorithms 5 6) wouldlead larger worldviews. general, one would expect larger worldviews yield bettersolutions smaller worldviews yield worse solutions, lower computational cost.means proximity-based refinement should, general, improve solution quality.results corresponded expectation. worldviews indeed largersolution quality higher.larger problems, performance could evaluated simulation, runningagent simulated world observing reward collects. problems,direct evaluation possible calculating actual value function usingexact algorithm longer tractable. Section 8.3 therefore presented results3Keys problem comparison obtained direct evaluation policiespre-cursor deliberation discussed above. seen, results correspond, crossconfirming evaluation methods.addition, simulation recurrent delibertion context coarseningcould evaluated. proximity-based coarsening activated, comparedsituation turned off, reward gathered agent declines slightly.impression worse performance somewhat misleading. due fact firstcomparison takes place one small problems, planner able solvewithout coarsening, fact without abstraction all. Thus, disadvantages(lower reward collected) much apparent advantages (lower computationalcost).larger problems, working without abstractions option, balancereversed. fact, somewhat counterintuitively, larger problemscoarsening active, successful runs smaller worldviews unsuccessfulruns. Clearly, size worldview determines success, quality.good worldview enabled efficient calculation policies progress toward goalremaining small. poor worldview simply grew larger. smaller problems, growingworldview may eventually covered state space detail, thus maskingeffect. planner would find good policy effectively without real approximation.larger problems, finding good policy without approximation feasible,similarly growing worldview simply slowed planner progressmade. situation, worldview-reducing action proximity-based coarseningbecame crucial, ensuring least worldview remained tractably smallthereby enabled planner deal problem.515fiBaum, Nicholson & Dixseen results, coarsening successful tasktime. agent paused replan part-way goal, reduces sizeworldview keep relevant changing circumstances. runs, however,worldview size grew beyond capabilities planner. cases,10x10 problem, settled higher balance. others, appears simplycontinued growing. latter case, would appear simple questiontuning parameters: find balance, appropriate worldview size.appears factor, quality worldview determiningsuccess failure runs whether find balance reach goal growbig fail.number problems solved poorly due initial abstractionselection algorithm (Algorithm 3). problems, algorithm produced either largeworldview exceeded available memory (either immediately shortly afterwards),planning possible, small worldview planning ineffective.could set produce medium-sized worldview, none four combinationsoptions produced one. problems, singleton worldview possibleis, steps initial abstraction selection disabled, resulting worldview aggregatingstates single, maximally abstract worldview state leading typically rewardcollected agent. best, would take actions general directiongoal(s). considerably worse previous work. instance, Kim (2001)obtains approximate solutions problems larger variants, othersuse domain variant, including Hoey et al. (1999) originators, DeardenBoutilier (1997).necessity using singleton initial worldview understandably greatlyhurt performance. infelicity worldview initialisation stage could impairentire planning process, since worldview never completely discarded planner.worldview-improvement algorithms could made amount weaknessinitial worldview, singleton worldview poor starting point indeed.similar observation made Dean et al. (1995) work using reduced envelopestates (that is, subset state space). high level algorithms, like here,work regardless initial envelope (worldview). practice, however, betterinitial envelope chosen intelligence, instance contain leastpossible path goal (for goal-oriented domains). find path using simpledepth first search, directly applicable worldviewsgradations abstraction, overall concept remains: reasonable initial worldviewcrucial.tireworld results confirm this. initial worldview reward stepenabled small, since domain rewards single dimension, planningineffective. planner given better initial worldview one couldplausibly calculated became quite effective, even modified tire-large-n0initial state deliberately moved goal. seems, then,basic approach general, worldview selection modification methodsless so. good worldview selection less fundamental apect approacheasily supplemented additional methods even tuning. domains like516fiProximity-Based Non-uniform Abstractions Planningtireworld, seems modified predicate solver generate plausible trajectoriescurrent state goal would well part worldview selection.interesting compare results Sanner Boutilier (2009)tireworld, describe passing extremely poorly approximatedgoing manually tweak domain planner, adding informationlocations mutually exclusive. makes planning much easier largely invalidatescomparison approaches.16 fair question, however, extentweakness planner extent artefact domain. combinationrepresentation narrative seems rather unfortunate, narrative obvious1-of-n intuition tend obscure real features (and real applicability)propositional representation hinder rather help intuition. would occurtighter fit representation narrative.Others, course, solve tireworld domain well. Some, Barry, Kaelbling,Lozano-Prez (2010), generate full policy, others take advantage initial state,planner would do. difficult know extent planners adapteddomain extent flexible. seems recent yearsbecome common planners tested domains researchersaccess development, ICAPS IPC domains, rathergreater lesser degree hand-tuned, usually unconsciously, particulars oneanother domain, undoubtedly unconsciously tuned grid navigationdomain.interesting side point provided shuttlebot problem, solved= 0.999 99 (other collecting trivial reward immediately adjacents0 ) solved optimally = 0.95. Since simulatorintrinsic discounting factor reports reward collected one seeeven though planner working discounting factor = 0.95, providedbetter solution = 0.999 99 case worked = 0.999 99 firstplace.ways better behaviour smaller planner discounting factor reasonable, agents horizon represented world discounting factor,horizon particular policy therefore planner effectively much shorter,policy supplanted new one relatively soon. Thus, may usefuloccasion set planners discounting factor lower true world discounting factor order facilitate planning. However, may lead suboptimal, short-sightedpolicies.10. Conclusionstheory Markov decision processes provides algorithms optimal planning. However,larger domains algorithms intractable approximate solutions necessary.state space expressed terms dimensions, size resulting computational cost exponential number dimensions. Fortunately, also resultsstructured state-space effective approximations possible.16. Similarly, Kolobov, Mausam, Weld (2008) report results variant tireworld rathertireworld itself, without providing explanation.517fiBaum, Nicholson & Dixapproach based selectively ignoring dimensions partsstate space order obtain approximate solutions lower computationalcost. non-uniform abstraction dynamically adjusted planning (in on-linesituations) execution progress, different dimensions may ignored different partsstate space. strong implications, since resulting approximation longerMarkovian. However, approach intuitive practical. synthesistwo existing approaches: structure-based approximation uniform abstractiondynamic locality-based approximation envelope methods. Like envelope methods,limited reliance initial worldview (or envelope): poor,tend perform poorly overall. approach subsumes uniform abstraction completelytreated special case general method.paper extends preliminary work Baum Nicholson (1998) modifyingworldview based proximity measure, enlarging reducing size,evaluating behaviour simulation. allows us test approach largerproblems, importantly demonstrates full strength approachlimits terms domain features exploit exploitadjustment all. abstraction becomes truly dynamic, reacting changesagents current state enabling planning tailored agents situationchanges. shown qualitative quantitative results presentedBaum (2006), approach effective efficient calculating approximatepolicies guide agent simulated worlds.10.1 Future WorkOne possible direction future research would find worldview initialisationmodification methods result smaller yet still useful worldviews, probably domainspecific, extend method domains, either larger different features.example, factory tireworld domains goal-oriented based predicates,worldview selection modification method based predicate-oriented solver couldfind possible paths goal ensure relevant preconditions concrete alongpath.Interestingly, 10x10 problem, proximity-based methods keepworldview size small, seem find balance larger stil moderatesize. Thus another possibility might tune proximity-based methods developself-tuning variants.number points, instance phase selection, algorithm uses stochastic choicedefault. could replaced heuristics, learning, directed methods.One could adapt method work types MDPs, undiscountedfinite-horizon ones, combine approaches approximate different aspects domains planning problem, described Section 2.5. example,mentioned section, Gardiol Kaelbling (2004, 2008) combine hierarchical statespace abstraction somewhat similar envelope work Dean et al. (1995).Many combinations would likely fruitful planning domains features relevant multiple methods. Similarly, additional refinement coarsening methods518fiProximity-Based Non-uniform Abstractions Planningcould added, instance one based after-the-fact refinement criterionroll-back Reyes et al. (2009).theoretical side, one could look situations optimalityguaranteed, Hansen Zilberstein (2001) LAO* algorithm workDean et al. (1995), observing admissible heuristic used evaluate fringe states,rather pragmatically chosen V (out), algorithm related heuristic searchacquires stopping criterion guaranteed optimality (or -optimality). Perhapssimilar condition could developed approach, rather different heuristic.two basic directions work extendedfundamental way, relaxing one MDP assumptions, perfect observability knowledgetransition probabilities. Partially Observable Markov Decision Process (POMDP)gives agent observation instead current state, observation partlyrandom partly determined preceding action current state.optimal solution known principle, quite computationally expensive, since transforms POMDP larger, continuous, many-dimensional MDP agents beliefs.such, non-uniform abstraction approach could applied two different ways: either original POMDP, fairly direct translation, transformed MDP.extension would apply technique agent learn transitionprobabilities. particular, application technique exploration17 wouldinteresting agent would somehow learn distinctions within single abstract states, distinguish refined remainabstract.Referencesde Alfaro, L., & Roy, P. (2007). Magnifying-lens abstraction Markov decision processes.Proceedings 19th International Conference Computer Aided Verification,CAV07, pp. 325338.Barry, J., Kaelbling, L. P., & Lozano-Prez, T. (2010). Hierarchical solution large Markovdecision processes. Proceedings ICAPS Workshop Planning SchedulingUncertain Domains.Barry, J. L. (2009). Fast approximate hierarchical solution MDPs. Masters thesis,Massachusetts Institute Technology.Barto, A. G., Bradtke, S. J., & Singh, S. P. (1995). Learning act using real-time dynamic programming. Artificial Intelligence, Special Volume: Computational ResearchInteraction Agency, 72 (12), 81138.Baum, J. (2006). Dynamic Non-uniform Abstractions Approximate Planning LargeStructured Stochastic Domains. Ph.D. thesis, Clayton School Information Technology, Monash University. Available www.baum.com.au/jiri/baum-phd.ps.gz17. learning problem could also transformed MDP agents beliefs experiences,would computationally prohibitive. standard approaches instead explicitly distinguish exploration, agent learns domain (but ignores goals) exploitation, achievesgoals (but ignores opportunities learn).519fiBaum, Nicholson & DixBaum, J., & Nicholson, A. E. (1998). Dynamic non-uniform abstractions approximateplanning large structured stochastic domains. Lee, H.-Y., & Motoda, H. (Eds.),Topics Artificial Intelligence, Proceedings 5th Pacific Rim International Conference Artificial Intelligence (PRICAI-98), pp. 587598.Bellman, R. E. (1957). Dynamic Programming. Princeton University Press.Bertsekas, D. P., & Tsitsiklis, J. N. (1996). Neuro-Dynamic Programming. Athena Scientific.Botea, A., Enzenberger, M., Muller, M., & Schaeffer, J. (2005). Macro-FF: Improving AIplanning automatically learned macro-operators. Journal Articial IntelligenceResearch, 24, 581621.Boutilier, C. (1997). Correlated action effects decision theoretic regression. Geiger, D.,& Shenoy, P. (Eds.), Proceedings 13th Conference Uncertainty ArtificialIntelligence (UAI-97), pp. 3037.Boutilier, C., & Dearden, R. (1996). Approximating value trees structured dynamic programming. Proceedings 13th International Conference Machine Learning,pp. 5462.Boutilier, C., Dearden, R., & Goldszmidt, M. (1995). Exploiting structure policy construction. Mellish, C. S. (Ed.), Proceedings 14th International Joint ConferenceArtificial Intelligence (IJCAI-95), Vol. 2, pp. 11041111.Boutilier, C., Dearden, R., & Goldszmidt, M. (2000). Stochastic dynamic programmingfactored representations. Artificial Intelligence, 121 (1-2), 49107.Boutilier, C., Goldszmidt, M., & Sabata, B. (1999). Continuous value function approximation sequential bidding policies. Laskey, K., & Prade, H. (Eds.), Proceedings15th Conference Uncertainty Artificial Intelligence (UAI-99), pp. 8190.Cassandra, A. R., Kaelbling, L. P., & Kurien, J. A. (1996). Acting uncertainty: Discrete Bayesian models mobile-robot navigation. Tech. rep. TR CS-96-17, ComputerScience, Brown University.Daoui, C., Abbad, M., & Tkiouat, M. (2010). Exact decomposition approaches Markovdecision processes: survey. Advances Operations Research, 2010, 120.Dean, T., Kaelbling, L. P., Kirman, J., & Nicholson, A. E. (1995). Planning timeconstraints stochastic domains. Artificial Intelligence, 76 (1-2), 3574.Dearden, R., & Boutilier, C. (1997). Abstraction approximate decision theoretic planning. Artificial Intelligence, 89 (1), 219283.Dietterich, T. G. (2000). Hierarchical reinforcement learning MAXQ value functiondecomposition. Journal Artificial Intelligence Research, 13, 227303.Drummond, M., & Bresina, J. (1990). Anytime synthetic projection: Maximizing probability goal satisfaction. Dietterich, T., & Swartout, W. (Eds.), Proceedings8th National Conference Artificial Intelligence (AAAI-90), pp. 138144.Gardiol, N. H., & Kaelbling, L. P. (2004). Envelope-based planning relational MDPs.Advances Neural Information Processing Systems 16 NIPS-03.520fiProximity-Based Non-uniform Abstractions PlanningGardiol, N. H., & Kaelbling, L. P. (2008). Adaptive envelope MDPs relational equivalence-based planning. Tech. rep. MIT-CSAIL-TR-2008-050, Computer ScienceArtificial Intelligence Laboratory, Massachusetts Institute Technology.Goldman, R. P., Musliner, D. J., Boddy, M. S., Durfee, E. H., & Wu, J. (2007). Unrollingcomplex task models MDPs. Proceedings 2007 AAAI Spring SymposiumGame Theoretic Decision Theoretic Agents.Goldman, R. P., Musliner, D. J., Krebsbach, K. D., & Boddy, M. S. (1997). Dynamicabstraction planning. Kuipers, B., & Webber, B. (Eds.), Proceedings 14thNational Conference Artificial Intelligence 9th Innovative Applications Artificial Intelligence Conference (AAAI/IAAI-97), pp. 680686.Guestrin, C., Koller, D., Parr, R., & Venkataraman, S. (2003). Efficient solution algorithmsfactored MDPs. Journal Artificial Intelligence Research, 19, 399468.Hansen, E. A., & Zilberstein, S. (2001). LAO*: heuristic search algorithm findssolutions loops. Artificial Intelligence, 129 (12), 3562.Hauskrecht, M., Meuleau, N., Kaelbling, L. P., Dean, T., & Boutilier, C. (1998). Hierarchicalsolution Markov decision processes using macro-actions. Cooper, G., & Moral,S. (Eds.), Proceedings 14th Annual Conference Uncertainty ArtificialIntelligence (UAI-98), pp. 220229.Hoey, J., St.-Aubin, R., Hu, A., & Boutilier, C. (1999). SPUDD: Stochastic planning usingdecision diagrams. Proceedings 15th Annual Conference UncertaintyArtificial Intelligence (UAI-99), pp. 279288.Howard, R. A. (1960). Dynamic Programming Markov Processes. MIT Press.Kim, K.-E. (2001). Representations Algorithms Large Stochastic Planning Problems.Ph.D. thesis, Deptartment Computer Science, Brown University.Kirman, J. (1994). Predicting Real-time Planner Performance Domain Characterization.Ph.D. thesis, Department Computer Science, Brown University.Kolobov, A., Mausam, & Weld, D. S. (2008). Regressing deterministic plans MDPfunction approximation. Workshop Reality Check Planning SchedulingUncertainty ICAPS.Korf, R. (1985). Macro-operators: weak method learning. Artificial Intelligence, 26 (1),3577.Littman, M., Weissman, D., & Bonet, B. (2006). Tireworld domain. Fifth InternationalPlanning Competition (IPC-5) hosted International Conference AutomatedPlanning Scheduling (ICAPS 2006).Munos, R., & Moore, A. (1999). Variable resolution discretization high-accuracy solutions optimal control problems. Dean, T. (Ed.), Proceedings 16th International Joint Conference Artificial Intelligence (IJCAI-99), pp. 13481355.Musliner, D. J., Durfee, E. H., & Shin, K. G. (1995). World modeling dynamicconstruction real-time plans. Artificial Intelligence, 74, 83127.521fiBaum, Nicholson & DixNicholson, A. E., & Kaelbling, L. P. (1994). Toward approximate planning largestochastic domains. Proceedings AAAI Spring Symposium Decision Theoretic Planning, pp. 190196.Parr, R. (1998). unifying framework temporal abstraction stochastic processes.Proceedings Symposium Abstraction Reformulation Approximation(SARA-98), pp. 95102.Puterman, M. L., & Shin, M. C. (1978). Modified policy iteration algorithms discountedMarkov decision processes. Management Science, 24, 11271137.Reyes, A., Sucar, L. E., & Morales, E. F. (2009). AsistO: qualitative MDP-based recommender system power plant operation. Computacion Sistemas, 13 (1), 520.Sanner, S., & Boutilier, C. (2009). Practical solution techniques first-order MDPs.Artificial Intelligence, 173 (56), 748788. Advances Automated Plan Generation.Srivastava, S., Immerman, N., & Zilberstein, S. (2009). Abstract planning unknownobject quantities properties. Proceedings Eighth Symposium Abstraction, Reformulation Approximation (SARA-09), pp. 143150.St-Aubin, R., Hoey, J., & Boutilier, C. (2000). APRICODD: Approximate policy construction using decision diagrams. Proceedings Conference Neural InformationProcessing Systems, pp. 10891095.Steinkraus, K. A. (2005). Solving Large Stochastic Planning Problems using Multiple Dynamic Abstractions. Ph.D. thesis, Department Electrical Engineering ComputerScience, Massachusetts Institute Technology.522fiJournal Artificial Intelligence Research 43 (2012) 1-42Submitted 08/11; published 01/12Learning Reasoning Action-Related PlacesRobust Mobile ManipulationFreek Stulpstulp@clmc.usc.eduComputational Learning Motor Control LabUniversity Southern California3710 S. McClintock Avenue, Los Angeles, CA 90089, USAAndreas FedrizziLorenz MosenlechnerMichael Beetzfedrizza@cs.tum.edumoesenle@cs.tum.edubeetz@cs.tum.eduIntelligent Autonomous Systems GroupTechnische Universitat MunchenBoltzmannstrae 3, D-85747 Garching bei Munchen, GermanyAbstractpropose concept Action-Related Place (ARPlace) powerful flexible representation task-related place context mobile manipulation. ARPlacerepresents robot base locations single position, rather collection positions, associated probability manipulation action succeedlocated there. ARPlaces generated using predictive model acquiredexperience-based learning, take account uncertainty robotlocation location object manipulated.executing task, rather choosing one specific goal position basedinitial knowledge task context, robot instantiates ARPlace,bases decisions ARPlace, updated new informationtask becomes available. show advantages least-commitment approach,present transformational planner reasons ARPlaces order optimizesymbolic plans. empirical evaluation demonstrates using ARPlaces leadsrobust efficient mobile manipulation face state estimation uncertaintysimulated robot.1. IntroductionRecent advances design robot hardware software enabling robots solveincreasingly complex everyday tasks. performing tasks, robot must continually decide course action, decision commitment planaction parameterization based evidence expected costs benefits associatedoutcome. (Resulaj, Kiani, Wolpert, & Shadlen, 2009). definition highlightscomplexity decision making. involves choosing appropriate action actionparameterization, costs minimized benefits maximized. robotmust therefore able predict costs benefits arise executingaction. Furthermore, due stochasticity hidden state, exact outcome actionknown advance. robot must therefore reason expected outcomes,able predict probability different outcomes given action action paramec2012AI Access Foundation. rights reserved.fiStulp, Fedrizzi, Mosenlechner, & Beetzterization. Finally, robot commits decisions based current observable evidence,represented belief state. evidence changes, rationale committingdecision may longer valid. robot therefore needs methods efficiently reconsider decisions belief state changes action execution, possibly commitanother plan necessary.Mobile manipulation good case point. Even basic mobile manipulationtasks, picking object table, require complex decision making. pickobject robot must decide stand order pick object,hand(s) use, reach it, grasp type apply, grasp, muchgrasp force apply, lift object, much force apply lift it,hold object, hold it. decision problems complex dependspecific task context, consists many task-relevant parameters. Furthermore,decisions must continually updated verified, task context, robotsknowledge context, often changes task execution.Consequently, tasks complexity require robust hardware low-levelcontrollers, also least-commitment approach making decisions, abstract planningcapabilities, probabilistic representations, principled ways updating beliefstask execution. article, demonstrate implementing core AI topicscontributes robustness flexibility mobile manipulation platform.task-relevant decision consider article base position robotnavigate order perform manipulation action. decision alone presentsseveral challenges, 1) successfully executing reaching manipulation actioncritically depends position base; 2) due imperfect state-estimation,uncertainty position robot target object. positionsknown exactly, fundamental successfully grasping object, possibledetermine single-best base position manipulation; 3) complete knowledge requireddetermine appropriate base position often available initially, rather acquiredon-line task execution.solution idea address challenges concept Action-Related Places(ARPlace), powerful flexible representation task-related place contextmobile manipulation. ARPlace represented probability mapping, specifiesexpected probability target object successfully grasped, given positionstarget object robotARPlace : { P (Success|fkrob , hf obj , obj i) }Kk=1(1)Here, estimated position target object represented multi-variate Gaussiandistribution mean f obj covariance matrix obj 1 . discrete set robot positions{fkrob }Kk=1 thought possible base positions robot considers grasping,i.e. potential positions navigate to. Typically, set positions arranged grid,exemplary ARPlace depicted Figure 1.1. feature vectors f rob f obj contain poses robot object relative tablesedge. Details given Section 3.1. Positions without uncertainty denoted f , estimatedpositions uncertainty hf , i.2fiLearning Reasoning Action-Related Places Robust Mobile ManipulationFigure 1: ARPlace: probability successful manipulation, given current estiobjrob K, objmated object position hfcurcur i. set potential robot positions {fk }k=1arranged grid along x y-axis, whereby position leadsobj, objdifferent probability successful grasping P (Success|fkrob , hfcurcur i).black isolines represent grasp success probability levels 0.2 0.8.ARPlace three important properties: 1) models base places singleposition f rob , rather set positions {fkrob }Kk=1 , different expectationsuccess manipulation action; 2) depends upon estimated target objectposition, updating f obj obj task execution thus leads different probabilitiesARPlace; 3) using probabilistic representation takes account uncertaintytarget object position leads robust grasping.1.1 Example ScenarioFigure 2, present example scenario demonstrates propertiesARPlace address challenges stated above, supports decision-makingmobile manipulation. images top row show current situation robotoutside view, images lower visualize robots internal ARPlacerepresentation. ARPlace visualized colors red, white green,represent low, medium high grasp success probabilities respectively. Grasp successprobability levels 0.2 0.8 depicted isolines, Figure 1.scenario robots task clean table. Scene 1 robot enterskitchen vision system detects cup. robot far away cup,uncertainty arising vision-based pose estimation cup high, indicatedlarge circle around cup lower left image. exact position cupknown, possible determine single-best base position graspingcup. ARPlace representation takes uncertainty account modelingbase position probability mapping.3fiStulp, Fedrizzi, Mosenlechner, & BeetzScene 1Scene 2Scene 3Scene 4Figure 2: Example scenario.Scene 1 ARPlace distribution low probabilities overall, maximumprobability grasp success 0.52. Note although initial uncertaintycups position precludes robot determining specific base positionreliably grasp cup, robot know general area navigate.navigation, robot able determine position cup accurately,depicted Scene 2. new sensor data comes in, robot refines ARPlacetherefore ARPlace Scene 2 much higher probabilities overall, maximum0.96.Scene 3 robot detected second cup. grasping cupssingle position much efficient approaching two locations, robotmerges two ARPlaces cup one ARPlace representing probabilitysuccessfully grasping cups single position2 . Scene 4 measurementshelped reduce pose estimation uncertainties cups. maximum grasp successprobability ARPlace reaches 0.97; sufficient robot commitgoal position attempt grasp cups once.scenario illustrates real-world tasks often planned startfinish, initial knowledge often complete accurate enough determineoptimal goal position. rather committing particular base position earlybased robots initial knowledge task context, robot instantiatesARPlace particular task context, bases decisions ARPlace.place concept instantiation represented explicitly course actionenables robot reconsider reevaluate decisions on-line whenever newinformation task context comes in. instance, decision graspcups one position Scene 3 would possible robot wouldcommitted plan given initial knowledge one cup detected. Evenenvironment completely observable, dynamic properties make pre-plannedoptimal position suboptimal unaccessible. least-commitment implementation,2. Section 4.4.1 explains ARPlaces merged compute ARPlace joint tasks.4fiLearning Reasoning Action-Related Places Robust Mobile Manipulationdecisions delayed must taken flexible, leads robustefficient mobile manipulation. demonstrated empirical evaluation.1.2 Contributions, System Overview Outlinesystem overview learning, computing, reasoning ARPlaces depictedFigure 3. also serves outline rest article.Figure 3: System Overview. Numbers refer sections article. Green ovals representalgorithms procedures, blue rectangles models result them.Procedures models briefly described contributions section;detail given throughout article. Yellow rectangles cluster conceptuallyrelated procedures, also delineate different sections article.main contributions article are:Representing ARPlace Section 1. propose ARPlace flexible representationplace least-commitment decision making mobile manipulation.Model Learning Section 3. generate ARPlace, robot must ablepredict outcome action given action parameterization. proposegeneric, off-line learning approach acquiring compact prediction model twosteps: 1) learn predict whether action succeed given task parameterization. supervised classification problem implement SupportVector Machines (Sonnenburg, Raetsch, Schaefer, & Schoelkopf, 2006); 2) generalizeseveral task parameterizations generalizing learned SVM classifiers,5fiStulp, Fedrizzi, Mosenlechner, & Beetzimplement Point Distribution Models (Cootes, Taylor, Cooper, & Graham, 1995). resulting success prediction model enables robot predictwhether manipulation action given object position succeed givenbase position 3 .Generating ARPlace Section 4. demonstrate ARPlaces generated online, take object position uncertainty account Monte-Carlo simulation. Furthermore, ARPlace conditioned robot position uncertainty,thus also taken account.Reasoning ARPlace Section 5. show ARPlace integrated symbolic transformational planner, automate decision-making ARPlaces.particular, consider scenario shows ARPlaces merged jointmanipulation tasks.Empirical Evaluation Section 6. demonstrate reasoning ARPlacesleads robust efficient behavior simulated mobile manipulation platform.turning contributions, first compare approach related workSection 2.2. Related Workstate-of-the-art mobile manipulation platforms use sampling-based motion plannerssolve manipulation problems (LaValle, 2006). advantages using symbolicplanning general, ARPlaces particular, are: 1. Abstraction. Representing planning abstract symbolic actions reduces complexity planningproblem. Although computational power ever increasing, still intractable solveextended tasks, preparing meal (Beetz et al., 2008), state-space search alone.2. Least-commitment. Friedman Weld (1996) show setting open conditionsabstract actions later refining choice particular concrete action lead exponential savings. Note principle also used reduce number collisionchecks building Probabilistic Roadmaps (Bohlin & Kavraki, 2000). 3. Modular replanning. symbolic planning, causal links actions explicitly represented.robot navigates table order perform grasping motion representedplan generated sampling-based motion planner. Therefore, execution, motionplanners cannot reconsider appropriate base position decision right,must rather inefficiently replan entire trajectory belief state changes. 4. Reflection. explicit symbolic representation causality also allows robot reasonreflect plans monitor execution, instance report reasons3. using experience-based learning, approach applied variety robots environments.model learned however, obviously specific environment experiencegenerated. instance, one table height considered data collection, learnedprediction model specific table height. different table heights used experiencecollection, table height included task-relevant parameter, model ablegeneralize table heights well. refer Section 3.5 full discussion.6fiLearning Reasoning Action-Related Places Robust Mobile Manipulationplan failure: could find cup. could determine position cupsufficient accuracy robustly perform grasp. obstacle blockingpath.. obvious achieve introspection motion planning methods.Also, contrast sampling based motion-planning, ARPlace generate trajectories motion itself, rather representation supports decisions,decision robot move order manipulate. goal positiongiven motion planner order find trajectory gets robotgoal position. system instance, navigation trajectory determinedWavefront planner. Also, ARPlace Reinforcement Learning policy (Sutton& Barto, 1998). policy maps states actions, whereas ARPlace maps (uncertain)states expected probabilities successfully executing certain action. ARPlacesthus models actions, executable actions right. distinctionbecome apparent Section 5, ARPlaces used transformationalplanner detect repair performance flaws symbolic plans.perspective, similar work aSyMov (Cambon, Gravot, &Alami, 2004) RL-TOPs (Ryan, 2002), use symbolic planners generatesequences motion plans/reinforcement learning policies respectively. specific contributions article enable robot learn grounded, probabilistic modelsactions support symbolic decision making, well using flexible transformationalplanners reason models. focus thus grounding improvingrepresentations enable symbolic planning, rather underlying actionsgenerate trajectories and/or actual motion.Okada, Kojima, Sagawa, Ichino, Sato, Inaba (2006) also develop representationsplace enable symbolic planning, denote good base placement graspingspot. Different spots hand-coded different tasks, manipulating faucet,cupboard, trashcan. symbolic representations place usedLISP-based motion planner perform tool manipulation behavior. ARPlace extendsconcept spot learning autonomously, grounding observed behavior,providing probabilistic representation place. Berenson, Choset, Kuffner (2008)address issue finding optimal start goal configurations manipulating objectspick-and-place operations. explicitly take placement mobile baseaccount. interested optimal start goal configurations, insteadprobabilistic representation, approach enable least-commitment planning.Diankov, Ratliff, Ferguson, Srinivasa, Kuffner (2008) use model reachableworkspace robot arm decide robot may stand grasp objectfocus search. However, uncertainties robots base position objects positionconsidered, thus cannot compensated for. recent work Berenson,Srinivasa, Kuffner (2009) addresses issues, still relies accurate modelenvironment, high computational cost. hand, ARPlacecompact representation computed negligible computational load, allowingcontinuous updating.Recently, similar methods ones presented article used determine successful grasps, rather base positions grasping. instance, Detry et al.(2009) determine probability density function represents graspability specificobjects. function learned samples successful robot grasps, biased7fiStulp, Fedrizzi, Mosenlechner, & Beetzobserved human grasps. However, approach take examples failed graspsaccount. shall see Section 4, distance failed successfulgrasp quite small, determined taking failed grasps account.classification boundaries Section 3.2 similar Workspace Goal Regions, exceptboundaries refer base positions, whereas Workspace Goal Regions refer grasppositions (Berenson, Srinivasa, Ferguson, Romea, & Kuffner, 2009). Also, generalizeboundaries Point Distribution Model, use generate probabilisticconcept successful grasp positions.Kuipers, Beeson, Modayil, Provost (2006) present bootstrapping approachenables robots develop high-level ontologies low-level sensor data including distinctive states, places, objects, actions. high level states used choosetrajectory-following control laws move one distinctive state another. approach exactly way around: given manipulation navigation skillsrobot (which far high-dimensional learn trajectory-following control laws),learn places skills (e.g. grasping) executed successfully. focusaction affordance, recognition localization. us, place means clusterlocations execute (grasping) skill successfully, whereas Kuiperset al. refers location perceptually distinct others, thereforewell-recognized. Furthermore, work yet considered physical manipulationobjects, relates place.Learning success models considered probabilistic pre-condition learning.research field far focussed learning symbolic predicates symbolicexamples (Clement, Durfee, & Barrett, 2007; Chang & Amir, 2006; Amir & Chang, 2008).approaches applied robots, representationslearned able encapsulate complex conditions arise robot dynamicsaction parameterization. robotics, focus pre-condition learning thereforerather grounding pre-conditions robot experience. realistic domain considered Zettlemoyer, Pasula, Kaelbling (2005), simulated gripper stacks objectsblocks world. Here, focus predicting possible outcomes actions completely observable, unambiguous description current state; emphasis rathertaking state estimation uncertainty account. Dexter learns sequences manipulationskills searching grasping object (Hart, Ou, Sweeney, & Grupen, 2006).Declarative knowledge length arm learned experience. Learningsuccess models also done context robotic soccer, instance learningsuccess rate passing (Buck & Riedmiller, 2000), approaching ball (Stulp & Beetz,2008). system extends approaches explicitly representing regionssuccessful instances observed, computing Generalized Success Modelregions.interesting line research shares paradigms ARPlaces,learning relation objects actions building prediction models, ObjectAction Complexes (OACs). Geib, Mourao, Petrick, Pugeault, Steedman, Kruger,Worgotter (2006) Pastor, Hoffmann, Asfour, Schaal (2009) present OACsused integrate high-level artificial intelligence planning technology continuous low-level robot control. work stresses that, cognitive agent, objectsactions inseparably intertwined therefore paired single interface.8fiLearning Reasoning Action-Related Places Robust Mobile Manipulationphysically interacting world applying machine learning techniques, OACs allowacquisition high-level action representations low-level control representations.OACs meant generalize principle affordances (Gibson, 1977).3. Learning Generalized Success Model ARPlacesection, describe implementation off-line phase depicted Figure 3,Generalized Success Model (GSM) learned. goal acquire function gP (Success|f rob , f obj )=g(f rob , f obj ) 7 {0, 1}(2)predicts chance successful manipulation action, given relative positionsrobot object, stored feature vectors f rob f obj respectively.Note off-line learning phase, known positions. Uncertaintypositions taken account on-line phase, described Section 4.Performing mobile manipulation complex task involves many hardwaresoftware modules. overview modules platform described Appendix A.overview demonstrates large number modules required implement mobilemanipulation platform. Many modules results yearsdecades research development within companies, research groups, open-sourceprojects. global behavior robot, e.g. whether grasp cup certainbase position, depends modules, interactions them.cases, analytic models certain modules available (such Capability Maparms workspace, Section 3.1). However, general way composing modelsacquire global model systems behavior task execution. Therefore,rather learn model observed experience.However, component computes ARPlaces requires exactly global modelpredict circumstances manipulation action fail succeed. attempting theoretical analysis model foreseeable events uncertainties worldbest tedious error-prone, worst infeasible, therefore use experience-basedlearning acquire global models behavior. so, model groundedobservation actual robot behavior.off-line learning phase consists three steps: 1) repeatedly execute actionsequence observe result N different target object positions; 2) learn N SupportVector Machines classifiers N specific cup positions 3) generalize N classifiersPoint Distribution Model.3.1 Data Acquisitionrobot acquires experience executing following action sequence: 1) navigatespecified base position table; 2) reach cup; 3) close gripper; 4) liftcup (Stulp, Fedrizzi, & Beetz, 2009a). action sequence, task contextdetermined following parameters 1) pose robot navigates to4 ; 2)4. Note navigation planner parameterized robot always directly facing table.limitation planner, rather constraint added make behavior9fiStulp, Fedrizzi, Mosenlechner, & Beetzpose target object table. execution, robot logs whether objectsuccessfully grasped not. efficiently acquire sufficient data, perform trainingexperiments Gazebo simulator (Gerkey, Vaughan, & Howard, 2003). robotmodeled accurately, thus simulator provides training data also validreal robot. Examples failed successful grasp depicted Figure 4.Figure 4: Two experiment runs different samples robot position. navigatereach-grasp sequence upper row succeeds, fails lower sequence.vector field controller use perform reaching movement provenrobust wide range robots workspace (Beetz et al., 2010). alsolow computational load, easy debug, quickly adapted novel objects.disadvantage occasionally gets stuck local minima, motionmust restarted. probabilistic motion planner arm suffer localminima, plan generation fails border workspace; even though vectorfield controller able grasp there. Every planner controller advantagesdisadvantages, always sources failure real world, especiallycomplex embodied agents. article aims modelling failures experiencebased learning, basing decisions models.feature space data collected depicted Figure 5. coordinatesystem relative tables edge, position cup table.enable us apply model learned data different tablesdifferent locations kitchen, contrast previous work (Stulp, Fedrizzi, &Beetz, 2009b). on, refer f obj = [xobj obj ] observable taskrelevant parameters, robot observes cannot influence directly. xobjdistance object table edge, obj angle objectorientation normal goes table edge object, depictedphysical robot predictable; makes robot safe, required operaterobot human environments (cf. Figure 20). principle, methods paper could takeorientation account.10fiLearning Reasoning Action-Related Places Robust Mobile ManipulationFigure 5. f rob = [xrob rob ] controllable action parameters, robotuse navigation system change them.Figure 5: Relative feature space used rest paper.robot gathers data 16 target object poses, depicted Figure 6. targetobject poses listed matrix Fobj . given target object position, determinerectangular area generous estimation upper boundrobot grasp object. rectangle 16 object poses. Withinrectangle uniform grid almost 200 positions, stored matrix Frob ,defined. Figure 6 depicts results data gathering positions. Here,markers represent position robot base table. three typesmarkers, represent following classes:3.1.1 Theoretically Unreachable (Light Round Markers)cup cannot grasped many positions bounding rectangle simplyarm long enough. formally, base positions, kinematicsarm inverse kinematic solution exists end-effectorposition required grasp target object. exploit analytic models armkinematics filter base positions bounding rectangle cup theoretically unreachable. analytic model use capability map, compiledrepresentation robots kinematic workspace (Zacharias, Borst, & Hirzinger, 2007).Capability maps usually used answer question: given position base,positions reach end-effector? article, use capability mapanswer inverse question: given position target object (and thereforedesired position end-effector), base positions reach end-effectorposition? Figure 7, answer question visualized specific target objectposition. depicted area theoretical kinematic upper bound base positionsrobot reach target.example base position bounding box, use capability mapdetermine target object theoretically reachable. not, corresponding baseposition labeled failure without executing navigate-reach-grasp action sequence.saves time gathering data. Another obvious theoretical bound implementedrobots distance table least big robots radius.Otherwise robot would bump table. Again, labeled base positionsfailures without executing order save time.11fiStulp, Fedrizzi, Mosenlechner, & BeetzFigure 6: Results data acquisition 16 target object poses, listed matrix Fobj .Markers correspond center robot base. Green squares redcircles represent successful failed grasps respectively. Bright circlesexecuted successful grasp deemed theoretically impossible capabilitymaps. dark green hulls classification boundaries (Section 3.2).3.1.2 Practically Unreachable (Red Filled Round Markers)capability map considers theoretical reachability position, given kinematics robots arm. take self-collisions account, constraintsimposed vector-field controller reaching, specific hardware gripper,way gripper interacts target object. Red markers Figure 6 representbase positions capability map deems possible, lead failure performing reaching motion. causes failure are: 1) bumping table dueimprecision navigation routine 2) bumping cup grasping it; 3) closinggripper without cup handle it; 4) cup slipping gripper 5)vector field controller getting caught local minimum.One aim article demonstrate practical problems, ariseinteraction many hard- software modules, properly addressed experiencebased learning. approach use analytic models available, useexperience-based learning necessary. interacting world, robot observes12fiLearning Reasoning Action-Related Places Robust Mobile ManipulationFigure 7: Inverse capability map right arm specific object position.global behavior, learns difference possible theoryworks practice.3.1.3 Reachable (Green Square Markers)base positions robot able successfully grasp cup.task execution deemed successful cup 10cm tableaction sequence completed, case robot holdingit. prefer empirical measure instance force-closure measure,latter requires accurate models object, always have. Furthermore,argued theoretical grounds (Zheng & Qian, 2005), well demonstratedempirically (Morales, Chinellato, Fagg, & del Pobil, 2004), force-closure grasps mayalways lead successful grasps practice. course, force-closure may wellused measure successful grasping; methods described articledepend upon design choice.data acquisition yields set discrete robot object positions, associatedresulting outcome manipulation action, success failure:obj NP (Success|{f rob }M}j=1 ) = bi,j , bi,j {0, 1}i=1 , {f(3)article, number sampled object positions N = 4 4 = 16 (i.e. numbergraphs Figure 6), number sampled robot positions = 11 17 = 187 (i.e.number data points per graph Figure 6).remainder section, first generalize discrete robot positionstraining Support Vector Machines (Section 3.2), generalize N cuppositions Point Distribution Models (Section 3.3)3.2 Generalization Robot Positionsstep, generalize discrete robot positions, acquire compact booleanclassifier efficiently predicts whether manipulation succeed:13fiStulp, Fedrizzi, Mosenlechner, & BeetzP (Success|f rob , {f obj }Nj=1 )=gj=1...N (f rob ) 7 {0, 1}(4)generalization implemented follows. separate classifier gi=1...N learnedN = 16 object poses, i.e. one classifier 16 data sets depictedFigure 4. acquire prediction models, compute classification boundary aroundsuccessful samples Support Vector Machines (SVM), using implementationSonnenburg et al. (2006), Gaussian kernel =0.1 cost parameter C=40.0.successful grasps rarer, weight twice much failed grasp attempts.Figure 6 depicts resulting classification boundaries different configurations taskrelevant parameters dark-green boundaries. Manipulation predicted succeedrobots base position lies within boundary given target object pose Fobj .accuracy learned classifiers listed Section 6.1.3.3 Generalization Object Positionsnext step, generalize discrete object positions:P (Success|f rob , f obj )=g(f rob , f obj ) 7 {0, 1}(5)determining low-dimensional set parameters allows us interpolateindividual classification boundaries Support Vector Machines generate. done Point Distribution Model (PDM), established methodmodelling variations medical images faces (Cootes et al., 1995; Wimmer, Stulp,Pietzsch, & Radig, 2008). result one compact model incorporates individual boundaries, able interpolate make predictions target object posesobserved training.input PDM requires n points distributed contour.landmarks distributed described Appendix B. Given landmarks classification boundaries, compute PDM. Although PDMs well-knownuse computer vision (Cootes et al., 1995; Wimmer et al., 2008), use notationRoduit, Martinoli, Jacot (2007), focus robotic applications. First, 16boundaries 20 2D points merged one 40x16 matrix H, columnsconcatenation xrob rob coordinates 20 landmarks along classification boundary. column thus represents one boundary. next step computeP, matrix eigenvectors covariance matrix H. P representsprincipal modes variation. Given H P, decompose boundary h1..16set mean boundary linear combination columns P followshk = H + P bk . Here, bk so-called deformation mode k th boundary.Point Distribution Model. get intuition PDM represents,first three deformation modes depicted Figure 8, values first, secondthird deformation modes (columns 1, 2, 3 B) varied maximalminimal value, whilst deformation modes set 0.eigenvalues covariance matrix H indicate first 2 components already contain 96% deformation energy. reasons compactness achieve14fiLearning Reasoning Action-Related Places Robust Mobile ManipulationFigure 8: first 3 deformation modes Point Distribution Model (in B).better generalization, use first 2 deformation modes, without losing much accuracy.{fjobj , gj (f rob ) = inboundary(f rob , hj )}Nj=1{fjobj , gj (f rob ) = inboundary(f rob , H + P bj )}Nj=1g(frob,fobj) = inboundary(frob, H + P b(fobj))N Support Vector Machines(6)Point Distribution Model(7)Regressionfjobjbj(8)PDM several advantages: 1) instead store N = 16 classificationboundaries hj 20 2D points capture variation classification hulls duedifferent target object positions, store N = 16 deformation modes 2 degreesfreedom each. greatly reduces dimensionality; 2) 2 degrees freedom bused interpolate principled way computed classification boundarieshj , generate boundaries object positions observed learning; 3)simple regression two degrees freedom PDM b position f objfeasible, object position related directly shape classificationboundary. regression explained next section.3.4 Relation Task-Relevant Parametersstep, acquire function b, computes appropriate deformation modes bgiven object position f obj . so, compute regression matrixdeformation modes specific object positions B, 16 object positionsFobj , depicted Figure 6. found simple second order polynomial regressionmodel suffices compute regression, yields high coefficients determinationR2 = 0.99 R2 = 0.96 first second deformation modes respectively.coefficients polynomial model stored two 3x3 upper triangular matrices W1W2 , B [ diag([T 1] W1 [Fobj 1]T ) diag([T 1] W2 [T 1]T ]Generalized Success Model consists 1) H, mean classificationboundaries computed SVM; 2) P, principal modes variation clas15fiStulp, Fedrizzi, Mosenlechner, & Beetzsification boundaries; 3) W1,2 , mapping task-relevant parameters deformationmodes.Let us summarize Generalized Success Model used predict successfulmanipulation behavior:1. Generalized Success Model takes (observed) relative position objectobjobjtable fcur= [xobjcur cur ] input (Figure 5).2. appropriate deformation values given object position computedobjobjobjbcur = b(fcur) = [ q W1 qT q W2 qT ], q = [fcur1] = [xobjcur cur 1](Section 3.4).3. boundary computed hcur = H + P bcur (Section 3.3).4. relative robot base center f rob = [xrob rob ] within boundary hcur ,model predicts robot able successfully grasp object positionobjobj= [xobjfcurcur cur ].Note steps involve simple multiplications additions small matrices,thus performed efficiently5 . reason efficiency lies factdirectly relate task-relevant parameters, position cup table,predictions global behavior robot, whether manipulation actionsucceed not. on-line efficiency made possible experience-based learning,wealth information observation global behavior compiledcompact model off-line. approach adheres proposed strategy learning taskrelevant features map actions, instead attempting reconstruct detailed modelworld plan actions (Kemp, Edsinger, & Torres-Jara, 2007).summary, observed behavior outcomes, learned mapping Equation 2 (which repeat Equation 9), maps continuous robot target objectpositions boolean prediction success action:P (Success|f rob , f obj ) = g(f rob , f obj ) 7 {0, 1}(9)mapping used predict current base position robot leadsuccessful manipulation, also determine appropriate base positions navigate to.Equation 9 assumes true values robot target object positionsknown robot. Section 4, discuss uncertainties estimatespositions taken account task execution.3.5 Generality Generalized Success Modelexplaining Generalized Success Model used generate ARPlaces online task-execution Section 4, discuss generalization propertieslimitations Generalized Success Model. so, must distinguish5. indication, model described paper four steps take 0.2ms 2.2GHzmachine Matlab implementation.16fiLearning Reasoning Action-Related Places Robust Mobile Manipulationgeneral applicability approach different robots, objects domains,specificity model factors learned. essentially holdsdata-driven approach: model principle learned data, independentrobot system generates data, learned, specificdata generated robot system, thus specific robot system itself.practical purposes, assume domain robot hardware remain fixed, learningdomain- robot-specific model grave limitation.3.5.1 Generalization Object Poseslearned model generalizes different object poses, relative object posetable f obj = [xobj obj ] part feature space Generalized SuccessModel parameterized (see step 1. calling GSM Section 3.4). Generalizedactually refers capability generalizing Success Models specific object poses.3.5.2 Grasp-Specific ARPlacesspecific object, lot data would required learn ARPlaceobject robot manipulate. practice however, foundgrasps suffice grasp everyday objects kitchen environments real robotplatform (Maldonado, Klank, & Beetz, 2010). particular, approach required2 grasps (one top one side) achieve 47 successful grasps51 attempts 14 everyday kitchen objects. Therefore, propose use grasp-specificARPlaces, rather object-specific ARPlaces. learned Generalized SuccessModels grasps, depicted Figure 9.Figure 9: two Point Distribution Models side top grasp. Examplesobjects manipulated grasps depicted.two deformation modes Point Distribution Model depicted Figure 9already contain 99% deformation energy, even side grasps.success side grasp relatively independent orientationobject, robot need reach around object. also leadssymmetric classification boundaries top grasp, seen Figure 9.summary, two Generalized Success Models must learned two differentgrasps, two grasps suffice grasp 14 everyday kitchen objects tested17fiStulp, Fedrizzi, Mosenlechner, & Beetzreal robot Maldonado et al. (2010). rest article, focusside grasp; ARPlaces top grasps presented Fedrizzi (2010).4. Computing Action-Related Placesprevious section, demonstrated Generalized Success Model learnedobserved experience variety task parameterizations. resulting functionmaps known robot object positions prediction whether action executionsucceed feel.section, describe ARPlaces manipulation computed on-linespecific task contexts. depicted Figure 3, module takes GeneralizedSuccess Model estimated robot pose target object pose input, returnsARPlace depicted Figure 1.4.1 Taking Object Position Uncertainty AccountEquation 9, prediction whether manipulation action succeeds fails basedknown robot target object positions. However, task execution, robotestimates positions, varying levels uncertainty. uncertaintiesmust taken account predicting outcome, manipulation actionpredicted succeed might well fail target object positionrobot expects be. Given Generalized Success Model Equation 9, goalsection therefore compute mappingGeneralized Success ModelP (Succ|frob,fobjARPlace (with object uncertainty)) 7 {0, 1} Monte Carlo { P (Succ|fkrob , hf obj , obj i) }Kk=1 7 [0, 1](10)takes estimates target object position, returns continuous probabilityvalue, rather discrete {0, 1} probability value Equation 9. belief state,uncertainties object positions modelled Gaussian distribution mean f objcovariance matrix obj .robot platform described Appendix A, f obj obj obtainedvision-based object localization module (Klank, Zia, & Beetz, 2009). Typical values along222diagonal 6x6 covariance matrix are: x,x= 0.05, y,y= 0.03, z,z= 0.07,222yaw,yaw = 0.8, pitch,pitch = 0.06, roll,roll = 0.06. uncertainties position specifiedmeters angular uncertainties specified radians. estimation objectposition quite accurate, vision system problems detect handle,important estimating orientation (yaw) cup. Due constraints enforcedassumption cup standing upright table, uncertainty z, pitchroll set 0. remaining 3x3 covariance matrix mapped relative featurespace, yields obj .end Section 3.4, demonstrated classification boundary hnew reobjobjconstructed, given known task relevant parameters fnew= [ xobjnew new ].objuncertainty fnew , suffice compute one classification boundary given18fiLearning Reasoning Action-Related Places Robust Mobile Manipulationprobable position cup ARPlace grasp. mightlead failure cup position expected. Therefore, useMonte-Carlo simulation generate whole set classification boundaries. donetaking 100 samples Gaussian distribution object position, given meanposition associated covariance matrix. yields matrix task-relevant parametersobj obj ]. corresponding classification boundaries computedFobjs=1...100 = [xsamples hs = H + P b(fsobj )) Equation 8. Figure 10(a), 20100 boundaries depicted.task-relevantparametersh2 generatedobj obj2 obj obj2x0.030=.f obj = [ xobj obj ] = [ 0.2 1.5 ] obj = 2x x220 0.30obj xobjobj obj(a) Sampled classification boundaries (b) Discretized relative sum (c) Final distribution, condi(hs=1..20 ).boundaries.tioning robot pose uncertainty.Figure 10: Monte-Carlo simulation classification boundaries compute ARPlace.described Appendix C, 0 definition, FGSM defined relativecups position along tables edge. uncertainty y, described2 , leads uncertainty origin Fy,yGSM . Therefore, samplingtask-relevant parameters, also sample values y, translate FGSM accordingly. Uncertainty influence shape classification boundary PDM,simply translates classification boundary along tables edge. samplingactually already done Figure 10(a), yobj yobj = 0.03. fact,2obj obj2 obj obj2 obj objxxxx0.032 00222obj2==0 0.030obj xobjobj objobj obj2obj xobj2obj obj02obj obj00.302computed sampled classification boundaries, generate discretegrid 2.52.5cm cells, represent discrete robot positions {fkrob }Kk=1 Equation 1.cell, number classification boundaries classify cell successcounted. thus computing histogram predicted successful grasps. Dividingresult overall number boundaries yields probability grasping cupsucceed position. corresponding distribution, takes uncertaintycup position account, depicted Figure 10(b).interesting note steep decline right side distribution neartable, probability successful grasp drops 0.8 0.2 5cm.intuitive, table located right side, robot bumps tablemoving sampled initial position, leading unsuccessful navigate-reach19fiStulp, Fedrizzi, Mosenlechner, & Beetzgrasp sequence. Therefore, none 16 boundaries contain area closetable, variation P right side PDM low. Variations Blarge effect boundary, seen Figure 10(b). summingsampled boundaries, leads steep decline success probability.Note ARPlace normalized probability distribution (which sums 1),rather probability mapping, element (discrete grid cell) probabilitydistribution itself. Thus sum probabilities grid cell 1, i.e. P (Succ) +P (Succ) = 1.4.2 Taking Robot Position Uncertainty Accountrobot uncertainty position target object, alsoposition. uncertainty must also taken account ARPlace. instance,although position near left steep incline Figure 10(b) predictedsuccessful, might still fail robot actually right expected.Therefore, condition probabilities Figure 10(b) robot actuallyrob ,rob )6 , acquirecertain grid cell (xrob , rob ) given position estimate (xfinal ARPlace mapping as:ARPlace prob. mapping, Figure 10(c).P (Success|hf rob , rob i, hf obj , obj i) =P (Success|f rob , hf obj , obj i)P (f rob |hf rob , rob i)(11)Prob. mapping Equation 10, Figure 10(b).Prob. distribution robot uncertainty (Gaussian).equation, hf rob , rob interpreted two ways. First all, representactual estimate robots position current time. case, P (Success| . . . )predicts probability success manipulation current position. However,also interpreted possible goal positions robot could navigate orderrob , rob i, throughout paper. so,perform navigation, i.e. hfgoalgoalrobmake assumption future position uncertainty robgoal goal position fgoalrob . believe fair assumption because;currently, i.e. robgoal =1) realistic assuming robgoal = 0; 2) robot approaches navigationrobgoal, continually updating , thus P (Success| . . . ). reachedrob .goal, robgoal equivalent4.3 Refining ARPlace On-linesummary, ARPlaces computed on-line learned Generalized Success Model,given task-relevant parameters current task context, includes uncertainties6. Since navigation planner parameterized robot always faces table (cf. Section 3.1),ignored orientation robot computing GSM. Note therefore also ignoreuncertainty parameter here, ARPlaces take account. expectimproved robustness (evaluated Section 6.2) could improved taking (the uncertainty)parameter account.20fiLearning Reasoning Action-Related Places Robust Mobile Manipulationposes robot target object. yields probability mapping mapsrobot base positions probability grasping target object succeed.Learning Generalized Success Model costly step involves extensive datacollection, thus performed off-line. learned, model compact,used efficiently compute ARPlaces on-line7 Therefore, ARPlaces updatedexecution task progresses, incorporate new knowledge taskrelevant parameters changes environment. Figure 11 depicts ARPlaceprobability mapping affected new knowledge task-relevant parameters comesin. first row demonstrates accurate knowledge target objectsposition (lower uncertainty, e.g. lower xobj xobj ) leads focussed ARPlacehigher overall probabilities, higher mode. second third row depictsimilar effects estimates target objects position orientation change.figure serves two purposes: gives reader visual intuition effects several taskrelevant parameters shape ARPlace, demonstrates robotsinternal ARPlace representation might change new (more accurate) informationtarget object pose comes in.Decreasing uncertainty cup position perpendicular table edgexobj =0.28xobj =0.38obj =0.600.190.100.01Decreasing distance cup table edge0.330.230.13Changing orientation cup table1.301.952.65Figure 11: images demonstrate varying certain task-relevant parameters affectsshape ARPlace distribution.decision whether certain probability success suffices execute manipulationaction critically depends domain task. Failing grasp full glass wine7. indication, takes average 110ms 2.2GHz machine Matlab implementationperform steps Section 4.1 4.2.21fiStulp, Fedrizzi, Mosenlechner, & Beetzgrave consequences failing grasp tennis ball. general, ARPlace providesrepresentation enables high-level planners make rational decisionsscenarios, specify decisions made, minimalsuccess probability order perform task. Section 5 present useARPlace concrete scenario.4.4 Generality ARPlacesSection 3.5, discussed generality learning Generalized Success Model,specificity model respect robot skills, modellearned off-line. section, demonstrate generality flexibilityARPlace representation, generated on-line using Generalized Success Model.also present various ways ARPlaces extended, lay groundwork Section 5, explains ARPlaces used context high-leveltransformational planner.4.4.1 Merging ARPlaces Multiple ActionsARPlaces multiple actions composed intersecting them. Assumecomputed ARPlaces two different actions (a1 a2 ). success probabilitiesARPlaces independent, compute ARPlace executing actionsparallel multiplying probabilities ARPlaces action a1 a2 .first two graphs Figure 12 instance, ARPlaces grasping cupleft right gripper depicted. piecewise multiplication probabilities,acquire merged ARPlace, depicted right graph. robot usemerged ARPlace determine probability use left right grippergrasp cups one base position (Fedrizzi, Moesenlechner, Stulp, & Beetz, 2009).Another similar application merging ARPlaces two cup positions, graspedgripper. ARPlace represents probability able graspcup one position, placing position, without moving base.compositions would impossible robot commits specific positions advance.Figure 12: Left distribution: grasp cup left gripper. Center distribution: grasp cupright gripper. Right distribution (element-wise product twodistributions): Grasp cups left/right gripper one base position.22fiLearning Reasoning Action-Related Places Robust Mobile Manipulationnavigating one position grasp two cups much efficient navigating two positions, implemented decision transformation ruleReactive Planning Language (McDermott, 1991), described detail Section 5.4.4.2 Different Supporting PlanesDefining feature space Generalized Success Model relative tables edgeallows robot compute ARPlaces general table shapes one presented far. done determining ARPlace straight edgestable, computing union individual ARPlaces. example depictedFigure 13.Figure 13: ARPlace complex table shape.4.4.3 Different Uncertainty Distributionsarticle, uncertainty position robot target objects modelledmulti-variate Gaussian distribution. approach expectsdistribution, state estimation systems represent uncertainty.Section 4.1, described specific target object positions sampleddistribution Monte Carlo simulation. general, method applies distributionsampling done. distributions need Gaussian,might well multi-modal even non-parametric. particle filter instance,particle could directly used sample compute classification boundariesFigure 10(a).4.4.4 Applicability Domainsdemonstrate generality ARPlaces briefly showing ARPlace ablerepresent task-relevant place different task domain: approaching ballrobotic soccer. task frequently fails robot bumps ballachieving desired position ball. Figure 14(a), examples successful (S)failed (F) attempt depicted. Here, robot approach balltop. goal acquire ARPlace maps robots position fieldpredicted probability successfully approach ball.23fiStulp, Fedrizzi, Mosenlechner, & Beetzprocedure learning ARPlace equivalent mobile manipulationdomain: 1) gather data log successful failed episodes (Figure 14(a)); 2) learn classification boundaries generalized success model data; 3) generate ARPlacesspecific task contexts (Figure 14(b)). example demonstrates ARPlaceapproach limited mobile manipulation, generalizes actions domains.(a) Successful failedattempts approachingball.Data taken(Stulp & Beetz,2008).(b) robots ARPlace approaching ball. Greenplateau: high probability robot succeed approaching ball orientation indicated thickblack arrow.Figure 14: ARPlace robot soccer domain.Note two bumps left right ball. intuitively clearrobot succeed approaching ball locations, surroundingones. assume depends particular morphology robot,controller used approach ball; described Stulp Beetz (2008). Onemain advantages using approach based learning assumptionsintuitions play role acquiring model. Whatever reason may be,successful approaches obvious observed data (Figure 14(a)), henceARPlace represents them.4.4.5 Using General Cost Functionsarticle, probability success considered utility relevant determiningappropriate base position. principle, ARPlace able represent kindutility cost, example given Figure 15. Here, task robotcollect one two cups table. probabilistic ARPlaces two cupsdepicted left graph. Given parameters, chance success 0.99cups, reason prefer fetching one other. However, cup B muchcloser robot, therefore would efficient collect cup B. preferenceexpressed ARPlace. First, compute distance robot24fiLearning Reasoning Action-Related Places Robust Mobile Manipulationgrid cells probabilistic ARPlace, depicted center graph. Finally,merge probability P distance one cost u, u = (1 P )5 + d/0.3.expresses takes average 5 seconds reposition robot another graspattempt case failure, average navigation speed 0.3m/s. costthus expresses expected time overall task take8depicted Figure 15, mode ARPlace cup closerrobot higher, reflecting fact prefer robot fetch cups closer.in-depth discussion utility-based ARPlaces, affect behaviorrobot, refer Fedrizzi (2010).Probability: PDistance:Cost: u = (1 P )5 + d/0.3Figure 15: Example general cost-based ARPlace (right), includingprobability success (left) distance robot (center). includingdistance part cost, mode cost-based ARPlace closercup higher distant cup.5. Transformational Planning ARPlacefar, described ARPlaces generated on-line using learned Generalized Success Model. ability predict (probability an) outcome actionmakes ARPlaces powerful tool combined high level planning system.section, demonstrate ARPlace used context symbolic transformational planner. Reasoning ARPlace enables planner generate robustefficient plans, demonstrates flexibility least-commitment ARPlacerepresentation.particular, consider task retrieving two cups table. One actionsequence solves task is: Plan A: navigate location near cup1, pick cup1left gripper, navigate location near cup2, pick cup2 right gripper,depicted Figure 16. However, cups sufficiently close (asFigure 12, right), much efficient replace plan Plan B: navigatelocation near cup1 cup2, pick cup1 left gripper, pick cup2right gripper, saves entire navigation action.8. cost chosen simplicity, illustrate generality ARPlace representation.realistic, complex cost functions used.25fiStulp, Fedrizzi, Mosenlechner, & BeetzFigure 16: Improving performance transformational planning (merged)ARPlace. Plan A: navigate two separate poses grasping object,using ARPlaces objects. Plan B: navigate one pose graspingobjects, using merged ARPlace.Deciding whether use two base locations (Plan A) one (Plan B) difficult solvecontrol program without sacrificing generality. keep solution general,want write two separate control programs options, chooseif-then-else statement. would mean provide control programschoice points every option robot has. space choices prohibitively largeeveryday tasks allow approach. Instead, use transformational plannertakes general program (Plan A) and, appropriate, applies generic transformation ruleschange program locally (to yield Plan B). transformational planner consistsfollowing components:Plan projection. projection mechanism predicting outcome plan. ARPlacecompact representation projection mechanism, able predictprobability success action, given parameters.Flaw detection. mechanism detecting behavior flaws within predicted plan outcome. Flaws errors hinder robot completing task,may also performance flaws, suboptimal efficiency. Using two navigation actions approach cups close (Plan A) flawed,much efficient navigate one position close cups.Plan transformation. mechanism fix detected flaws applying transformationrules plan code. problem consider, local transformation ruleapplied Plan yield efficient Plan B.next sections, describe mechanisms detail,explain implemented exploit ARPlace representation. Notearticle, use transformational planner exemplify ARPlace usedcontext larger planning system. information transformationalplanning framework, examples behavior flaws transformation rules,refer work Mosenlechner Beetz (2009).26fiLearning Reasoning Action-Related Places Robust Mobile Manipulation5.1 Plan Designdetect flaws apply transformation rules repair, transformational plannermust able reason intention code parts, infer goal achievednot, deduce reason possible failure was. so, control programswritten rpl (McDermott, 1991), provides functionality annotating codeparts indicate purpose make transparent transformational planner.purpose article, important rpl instructions semantic annotationcontext pick-and-place tasks achieve, perceive at-location. formaldefinition semantics instructions given Mosenlechner Beetz (2009);describe informally.(achieve ?expression) achieve statement executes successfully, logical expression passed argument asserted true. instance, successfulexecution (achieve (entity-picked-up ?cup)), object referenced variable ?cupmust robots gripper9 .(perceive ?object) manipulating objects, robot must find objectsinstantiate belief state. successful execution, statement (perceive ?cup)asserts object referenced ?cup found, reference internalrepresentation returned.(at-location ?location ?expression) Manipulation implies execution actionsspecific locations. Therefore, must assured pick-up actions executedrobot specific location. (at-location ?location ...) asserts code withincontext either executed specified location fails. Please note transformations affect location actions performed directly modify ?locationparameter at-location expressions. Therefore, at-location importantdeclarative plan expression optimizing ARPlaces. specify locations at-location,use so-called designators, symbolic descriptions entities locations, objectsactions. instance, designator location stand picking cupspecified follows: (a location (to pick-up) (the object (type cup))). symbolicdescription resolved reasoning mechanisms ARPlaces Prologactual pose generated needed. general, infinite number poses providevalid solution pose. ARPlace gives us way evaluate utility selectbest pose.declarative expressions explained combined form tree. Everyachieve statement contain several achieve, perceive at-location statementssub-plans. example plan tree sketched Figure 17. tree, goal (achieve(entity-at-location ?object ?location)) first perceives object, picks achievingentity-picked-up, executes pick-up action within at-location block, putsobject achieving entity-put-down, also contains at-location block.shall see Section 5.4, behavior flaws repaired applying transformation rulesreplace sub-trees within plan tree new code.9. Please note lisp syntax, variables prefixed ?, example ?cup, predicatesfunctions pure symbols.27fiStulp, Fedrizzi, Mosenlechner, & Beetz(entity-at-location ?o ?l)(perceive ?o)(achieve (entity-put-down ?o ?l))(achieve (entity-picked-up ?o)........ (at-location ?obj-l).(at-location ?obj-l)............Figure 17: example plan tree created executing pick-up plan5.2 Plan Projectioncentral component transformational planner plan projection, simulatesbehavior robot arises executing plan. approach, plan projection generates temporally ordered set events based plan code presentedprevious section. use Gazebo based mechanism projectionused generating training data learning ARPlaces. particular, use information collisions, perception events locations objects robot.executing plan simulation, generate extensive execution traceused reasoning engine infers behavior flaws fixed transformation rules (Mosenlechner & Beetz, 2009). execution trace contains low-level datarepresenting position objects robot, well collisions objects,visibility objects robot, information reconstruct state programthroughout execution.ARPlaces efficient way performing plan projection, predictprobability successful outcome without requiring on-line generation execution traces.reason execution trace sampling required on-line, taskalready executed frequently off-line data acquisition (cf. Section 3.1).results task executions compiled ARPlaces learningGSM, yields compact representation experience acquired. Therefore,experience must generated anew plan generation.5.3 Behavior Flaws Reasoning Plan ExecutionPlan projection simulates robot behavior executing plan. second component transformational planner reasoning engine finds pre-defined flawsprojected robot behavior. Examples flaws collisions, e.g. caused underparameterized goal locations, blocked goals, e.g. chair standing locationrobot wants navigate to. examples behavior flaws lead criticalerrors plan execution (i.e. plan fails), also consider behavior inefficientflawed (i.e. plan succeeds, unnecessarily inefficient). task considerpaper example performance flaw, performing two navigation actions one required highly inefficient. Behavior flaws specified using28fiLearning Reasoning Action-Related Places Robust Mobile ManipulationProlog-like reasoning engine implemented Common Lisp (Mosenlechner & Beetz,2009).execution trace generated plan projection transparently integratedreasoning engine, i.e. execution trace queried using Prolog predicates. information recorded execution trace valuable information order find behavior flaws.Additional information used find behavior flaws set facts model semantics declarative expressions achieve at-location concepts world,instance objects placed supporting planes (table, cup-board, ...). findbehavior flaws, Prolog specifications matched logical representationexecution trace solutions found, corresponding flaw present planfixed.instance, code match two locations perform actions mergedone ARPlace looks follows:Listing 1: Flaw definition match two different pick-up tasks.12345(( k g l ? k 1 ( c h e v e ( e n p c k e ? b j e c 1)))( k g l ? k 2 ( c h e v e ( e n p c k e ? b j e c 2))) ( h n(== ? k 1 ? k 2)) ( p z e c n l c n ? b j e c 1? b j e c 2 ? p z e l c n ) )code first matches two different pick-up tasks. predicate optimizedaction-location holds ?optimized-location ARPlace two objectspicked up. bind variable, predicate implemented calculateARPlace.Another example flaw definition failed navigation, i.e. robotstanding location supposed drive to:Listing 2: Flaw definition find locations reached robot althoughtold reach them.12345(( k g l ? k ( c h e v e ( l c Robot ? g l l c ) ) )( k u ? k Done ? )( h l ( l c Robot ? r b l c ) ( ? ) )( (== ? g l l c ? r b l c ) ) )code first matches code navigating robot location ?goalloc. infers actual location robot navigation task terminatedbinds variable ?robot-loc finally asserts two locationsequal. Prolog expression proven execution trace, foundflaw indicating unachieved goal location.5.4 Plan Transformations Transformation Rulesbehavior flaw detected, last step planner iteration applicationtransformation rule fix behavior flaw. Transformation rules applied partsplan tree cause substantial changes structure corresponding robotbehavior.29fiStulp, Fedrizzi, Mosenlechner, & Beetztransformation rule consists three parts. input schema matchedplan part transformed binds required code parts variables orderreassemble output part. transformation part performs transformationsmatched parts, output plan describes new code respectiveplan part reassembled.input schematransformationoutput planBesides integration ARPlace robot control program at-locationstatements, ARPlace also integrated reasoning engine transformationalplanner. Using two locations grasping considered performance flaw one locationwould suffice. Informally, investigate execution trace occurrence two different pick-up actions, one executed location L1 , one executedlocation L2 . request location L3 perform actions corresponding success probability. L3 computed merging ARPlace Figure 12.probability success merged ARPlace sufficiently high, apply plantransformation, replace locations L1 L2 location L3 .transformation rule optimizing ARPlaces shown Listing 3. Please notevariables bound matching flaw definition still boundused transformation rule.Listing 3: Transformation rule fixing flaw.1234567891011( e f r r u l e f x unoptimized l c n: n p u schema( ( ( k g l ? l c n k 1( atl c n ( ? l c n 1) . ? code 1))( subt k ? l c n k 1 ? k 1))( ( k g l ? l c n k 2( atl c n ( ? l c n 2) . ? code ) )( subt k ? l c n k 2 ? k 2))): outputp l n( ( atl c n ( ? p z e l c n ) . ? code 1)( atl c n ( ? p z e l c n ) . ? code 2)))input schema code consists two similar patterns, matchingat-location sub-plan pick-up goals matched flaw. planner replacesmatching code parts corresponding entries output plan. transformationrule, location passed at-location replaced optimized locationcalculated flaw definition.behavior flaw defined match two different pick-up executions.ARPlace query performed find probability successfully graspingobjects one location. probability sufficiently high (> 0.85) Prolog querysucceeds, i.e. flaw detected sufficiently good location graspingobjects found. Note sufficiently high depends much scenariocontext. robotic soccer beneficial choose fast risky moves, whereassafe human-robot interaction, certainty successful execution importantmere speed. article focusses principled ways integrating thresholdstransformational planner, relating grounded models robots behavior.30fiLearning Reasoning Action-Related Places Robust Mobile Manipulationthresholds be, determined, depends applicationdomain users.6. Empirical Evaluationsection 1) determine many samples needed learn accurate SVMclassifier; 2) compare robustness default strategy determining base positionsstrategy uses ARPlaces; 3) compare efficiency plans withoutfixing performance flaws transformational planner; 4) present preliminary resultsphysical robot platform.6.1 Classification Accuracy Training Set SizeFigure 18 depicts accuracy SVM classifier predicting base positionslead successful grasps one particular cup position, evaluated separate test set150 samples. Without using capability map filter kinematically impossiblebase positions, graph levels 300 examples10 . filtering theoreticallyimpossible base positions capability map, classifier achieves accuracywithin 173 examples (Stulp et al., 2009).Figure 18: Accuracy dependent training set size one cup position.effect dramatic entire dataset containing data 16 different cuppositions. applying capability map, number trials need executedreduces 2992 (all markers Figure 6) 666 (only red/green filled markers Figure 6).capability map reduces unsuccessful attempts, influence finalclassification accuracy, 94%.10. graph applies another dataset described Stulp, Fedrizzi, Zacharias, Tenorth, Bandouch,Beetz (2009), similar one used rest article.31fiStulp, Fedrizzi, Mosenlechner, & Beetz6.2 Results Simulated Robotcompare robustness navigation based probabilistic ARPlacesstrategy based deterministic navigation goals. evaluation, positionrobot navigates position ARPlace returns highest probabilitygrasping target object succeed. compare strategy previoushand-coded implementation Fixed, always navigates locationrelative offset target object, whilst time taking care bumptable.experiments, vary position cup (xobj , obj ), welluncertainties robot position position cup, varyingdiagonal elements covariance matrices associated position robot(xrob xrob ,yrob yrob ) cup (xobj xobj ,obj obj ). combinationvariables, robot performs navigate-reach-grasp-lift sequence. resultrecorded, data acquisition learning Generalized Success Model.simulate uncertainty, sample specific perceived robot cup positiondistribution defined means covariance matrices. result actiondetermined true simulated state world, robot bases decisionsperceived samples.results evaluation summarized three bar plots Figure 19,depict success ratios ARPlace-based Fixed strategies. rationumber successful executions, divided number examples, 100. pvalue pair bars computed 2 test them, tests whethernumber successful failed attempts sampled distributionARPlace Fixed.first graph depicts success ratios increasing uncertainty objectposition (i.e. xobj xobj = [ 0.00 0.05 0.10 0.15 0.20 ]), fixed robot position uncertainty xrob = 0.05. cases, ARPlace strategy significantly outperformsFixed strategy. Furthermore, performance ARPlace much robust towardsincreasing object position uncertainty, ARPlace takes explicitly account.trend seen increasing uncertainty robot position (i.e.xrob xrob = yrob yrob = [ 0.00 0.05 0.10 0.15 0.20 ]), fixed object position uncertaintyxobj = 0.05. However, xrob xrob > 0.1 difference ARPlaceFixed longer significant.Finally, last graph depicts success ratios increasing robot objectuncertainty. Again, ARPlace significantly outperforms Fixed ( < 0.15).robot quite uncertain objects position ( > 0.15), grasp successprobabilities drop 50% strategies.Summarizing, ARPlace robust towards state-estimation uncertaintiesprevious default strategy. effect pronounced object positions robotpositions.6.3 Transformational Planning Merged ARPlacesevaluated merging ARPlaces joint grasping, application transformation rules rpl planner, discussed Section 4.4.1. Two cups placed32fiLearning Reasoning Action-Related Places Robust Mobile ManipulationFigure 19: Success ratios ARPlace Fixed approaches changing objectand/or robot pose uncertainties.table, distance varied 20 60cm, increments5cm. evaluation shows grasping two cups separate base positions requiresaverage 48 seconds, independent relative distance cups other.applying transformation rules, default plan optimized 32 seconds, significant (t-test: p < 0.001) substantial performance gain 50% (Fedrizzi et al., 2009).45cm, two cups cannot grasped one position, plan transformationapplied.6.4 Integration ARPlace Physical Robot Systemday open house, B21 mobile manipulation platform continually performedapplication scenario, locates, grasps, lifts cup table moveskitchen oven. Figure 20 shows two images taken demonstration. robotperformed scenario 50 times approximately 6 hours, convinced usrobot hardware software robust enough deployed amongst general public.open day, ran experiment, time determined goallocation navigating table mode ARPlace computedexecuting navigation action. Since main focus experimenterror-recovery system described Beetz et al. (2010), improved robot performanceobserved cannot quantitatively attributed use ARPlace error-recoverysystem. However, major qualitative improvement certainly attribute usingARPlace cup grasped much larger area table.Without ARPlaces, cup always placed position tableenable successful grasping.7. Conclusionarticle, present system enables robots learn action-related placesobserved experience, reason places generate robust, flexible, least33fiStulp, Fedrizzi, Mosenlechner, & Beetz1. robot navigates table2. robot reaches cupFigure 20: reach grasp trajectory performed public demonstration. (Noteoperator holding camera, remote control!)commitment plans mobile manipulation. ARPlace modeled probability distribution maps locations predicted outcome action.believe system several advantages. First all, learned modelcompact, 2 (deformation) parameters, directly related task-relevantparameters. Querying model on-line therefore efficient. advantagecompiling experience compact models, rather running novel searchsituation.hand, model acquired experience-based learning,model grounded observed experience, takes account robot hardware,control programs, interactions environment. applied mobilemanipulation platform, independent manipulators, navigation base, algorithmsrun them.output model set positions associated success probabilities,instead one specific position. Rather constraining specific position prematurely, robot efficiently update ARPlace new sensor data comes in. enablesleast-commitment planning. ARPlace representation also enables optimizationsecondary criteria, execution duration, determining best position grasping two objects simultaneously. previous work, proposed subgoal refinement (Stulp& Beetz, 2008) optimizing secondary criteria respect subgoals.Finally, using ARPlaces determine appropriate base positions, difficult positionsgrasping avoided, leads robust behavior face state estimationuncertainty, demonstrated empirical evaluation.currently extending approach several directions. processincluding ARPlace general utility-based framework, probabilitysuccess one aspects task needs optimized. New utilities,34fiLearning Reasoning Action-Related Places Robust Mobile Manipulationexecution duration power consumption, easily included framework,enables robot trade efficiency robustness on-line task execution.also applying approach complex scenarios different domains.instance, learning higher-dimensional ARPlace concepts, take aspectsscenario account, i.e. different object sizes objects require differenttypes grasps. Instead mapping specific objects places, map object graspproperties deformation modes. also investigating extensions machinelearning algorithms enable methods generalize larger space. Objectsrequire different grasps, using two hands manipulate them, requiresophisticated methods acquiring reasoning place. Generalizationplace concept respect situations task contexts research challengemid-term research agenda.Acknowledgmentsgrateful Pierre Roduit providing us Matlab code described Roduitet al. (2007). also thank Ingo Kresse, Alexis Maldonado, Federico Ruiz assistancerobotic platform, robot system overview. grateful FranziskaZacharias providing capability map (Zacharias et al., 2007) robot. thankDominik Jain Franziska Meier fruitful discussions Section 4.2.work partly funded DFG project ActAR (Action Awareness Autonomous Robots) CoTeSys cluster excellence (Cognition Technical Systems, http://www.cotesys.org), part Excellence Initiative German ResearchFoundation (DFG). Freek Stulp also supported post-doctoral Research Fellowship(STU-514/1-1) DFG, well Japanese Society PromotionScience (PE08571). Freek Stulps contributions work made IntelligentAutonomous Systems Group (Technische Universitat Munchen, Munich, Germany),Computational Neuroscience Laboratories (Advanced Telecommunications Research Institute International, Kyoto, Japan), Computational Learning Motor Control Lab(University Southern California, Los Angeles, USA),Appendix A. Robot Platformaction sequence consider article is: 1) navigate specified base positionnear table; 2) reach object; 3) close gripper; 4) lift object.sequentially describe various hard- software components involved executingactions. overview components data communicateddepicted Figure 21.main hardware component B21r mobile robot Real World Interfaces(RWI), frontal 180 degrees Sick LMS 200 laser range scanner. task execution,robot acquires map (kitchen) environment using pmap map building.navigate specified base position, robot uses Adaptive Monte Carlo Localizationalgorithm localization, AMCL Wavefront Planner global path planning.three software modules (map building, localization planning), useimplementations Player project (Gerkey et al., 2003).35fiStulp, Fedrizzi, Mosenlechner, & BeetzFigure 21: Overview mobile manipulation hardware software modules.robot close table, detects tracks target object usingapproach proposed Klank et al. (2009). stereo-vision hardware consists twohigh dynamic range cameras mounted PTU-46 pan-tilt unit DirectedPerception resolution 1390x1038 pixels.manipulation, robot equipped two 6-DOF Powercube lightweight armsAmtec Robotics. control arms reach target cup, use Kinematics Dynamics Library (Orocos-KDL) (Smits, ) Vector Field approach. Withinvector field, handle cup attractor, cup itself, tableobstacles repellors. Details position shape attractorsrepellors given Beetz et al. (2010). On-line every control cycle, task space velocity end-effector computed given attractors repellors, velocitymapped joint space velocities using damped least squares inverse kinematics algorithm.reaching desired end-effector pose, 1-DOF slide gripper closes.High-level decision making, monitoring error-recovery done planning module written Reactive Planning Language (McDermott, 1991). requests ARPlacesmodule described article, reasons them, performs navigationmanipulation requests based them.Communication modules described done middleware layerconsisting Player (Gerkey et al., 2003) YARP (Metta, Fitzpatrick, & Natale, 2006).overview simplification actual system. instance, role RFID tagsBelief State omitted. complete detailed descriptionmobile manipulation platform, refer work Beetz et al. (2010, Section 1.2).36fiLearning Reasoning Action-Related Places Robust Mobile ManipulationAppendix B. Landmark Distribution Point Distribution ModelPoint Distribution Model (PDM) takes set landmarks n contours input,represented n matrix H, returns matrices H (mean contours), P(deformation modes), B (deformation mode weighting per contour), originalcontours reconstructed.application PDMs, free choose locations landmarks. Therefore, goal procedure described determine landmark locations leadscompact PDM accurately reconstructs original contours, i.e. classificationboundaries. explicitly optimizing two measures: 1) model compactness:amount energy e stored first degrees freedom PDM, 0 e 1;2) reconstruction accuracy: mean distance l landmarks originalcontours reconstructed contours. measures combined cost function(2 e)l2 , expressing want low error high energy given number degreesfreedom d.Given number landmarks number degrees freedom d, explicitlyoptimize cost function search. varying positionlandmark, one landmark time, greedily selecting position leadslowest cost. optimization first done = 1, number degrees freedomincremented optimization leads energy lies 95%. ensuresnumber degrees freedom distance l landmarks remainslow, whilst energy e high. Therefore, resulting PDM model compact yetaccurate.optimization step far computationally intensive step off-linelearning phase. currently investigating use alignment methods computervision (Huang, Paragios, & Metaxas, 2006), replace iterative optimization approach.Appendix C. Robot Coordinate Systems Relative FeatureSpacerobot uses variety coordinate systems. goal compute matrix GSM ,describes objects position relative feature space Generalized SuccessModel. GSM used reconstruct classification boundaries successfullygrasping object, described Section 3.4. present required coordinatesystems, transformed yield Generalized Success Model requiredfeature space depicted Figure 5.coordinate frames involved transformation depicted Figure 22:world frame FW , table frame FT centered middle top table,robot frame FR centered robots base center floor, camera frameFC centered cameras sensor chip, frame pan-tilt unitcamera mounted FP , relative feature space FGSM .acquire position target object relative FGSM , compute GSMfollows:GSM= (W TGSM )137W(12)fiStulp, Fedrizzi, Mosenlechner, & BeetzFigure 22: Relevant coordinate framesglobal position objectW=WWTTRcomputed follows:RTPPTTCC(13)Here, W TR location robots base frame relative world frame.robot uses AMCL particle filter estimating position. R TP pose pantilt unit relative robots base frame. transformation matrix R TP constantspecified manually measuring distances angular offsets B21robot base pan tilt unit. careful measurement, assume maximumerrors 1mm distance measurements along x-, y-, z-axis, 2yaw angle measurement. P TC pose cameras sensor relative pan tiltunit. P TC changes according current pan tilt angles, readpan tilt units driver high accuracy. C position target object relativecamera frame. estimated vision-based object localization moduledescribed Klank et al. (2009).order compute W TGSM need know global position object W ,already computed above, global position table W TT . Currently,get world coordinates tables position map, also possibleestimate position vision-based object localization module. computenormal object table edge closest robot, seenFigure 5. origin FGSM therefore W TGSM table edge objectnormal intersect.critical parts computations angular estimationsrobots localization vision system. First, estimation uncertainty rather big.Second, error localization angle significant impact estimated objectpose, follows Equation 13.pose cup frame FGSM 6D vector [x, y, z, yaw, pitch, roll]. However,since assume cup standing upright table, set z tables height,roll pitch 0 . Since origin FGSM perpendicular tables edgepasses y, also 0 definition. remaining parameters x yawcorrespond features xobj obj respectively.38fiLearning Reasoning Action-Related Places Robust Mobile ManipulationReferencesAmir, E., & Chang, A. (2008). Learning partially observable deterministic action models.Journal Artificial Intelligence Research (JAIR), 33, 349402.Beetz, M., Stulp, F., Esden-Tempski, P., Fedrizzi, A., Klank, U., Kresse, I., Maldonado,A., & Ruiz, F. (2010). Generality legibility mobile manipulation. AutonomousRobots Journal (Special Issue Mobile Manipulation), 28 (1), 2144.Beetz, M., Stulp, F., Radig, B., Bandouch, J., Blodow, N., Dolha, M., Fedrizzi, A., Jain,D., Klank, U., Kresse, I., Maldonado, A., Marton, Z., Mosenlechner, L., Ruiz, F.,Rusu, R. B., & Tenorth, M. (2008). assistive kitchen demonstration scenariocognitive technical systems. IEEE 17th International Symposium RobotHuman Interactive Communication (RO-MAN), Muenchen, Germany. Invited paper.Berenson, D., Choset, H., & Kuffner, J. (2008). optimization approach planningmobile manipulation. Proceedings IEEE International ConferenceRobotics Automation (ICRA) 2008, pp. 11871192.Berenson, D., Srinivasa, S., Ferguson, D., Romea, A. C., & Kuffner, J. (2009a). Manipulation planning workspace goal regions. Proceedings IEEE InternationalConference Robotics Automation (ICRA), pp. 13971403.Berenson, D., Srinivasa, S. S., & Kuffner, J. J. (2009b). Addressing pose uncertaintymanipulation planning using task space regions. Proceedings IEEE/RSJInternational Conference Intelligent Robots Systems (IROS, pp. 14191425.Bohlin, R., & Kavraki, L. E. (2000). Path planning using lazy prm. IEEE InternationalConference Robototics Automation, pp. 521528.Buck, S., & Riedmiller, M. (2000). Learning situation dependent success rates actionsRoboCup scenario. Pacific Rim International Conference Artificial Intelligence,p. 809.Cambon, S., Gravot, F., & Alami, R. (2004). robot task planner merges symbolicgeometric reasoning.. Proceedings 16th European Conference ArtificialIntelligence (ECAI), pp. 895899.Chang, A., & Amir, E. (2006). Goal achievement partially known, partially observable domains. International Conference Automated Planning Scheduling(ICAPS), pp. 203211.Clement, B. J., Durfee, E. H., & Barrett, A. C. (2007). Abstract reasoning planningcoordination. Journal Artificial Intelligence Research, 28, 453515.Cootes, T. F., Taylor, C. J., Cooper, D., & Graham, J. (1995). Active shape models -training application. Computer Vision Image Understanding, 61 (1), 3859.Detry, R., Baseski, E., Popovic, M., Touati, Y., Krueger, N., Kroemer, O., Peters, J., &Piater, J. (2009). Learning object-specific grasp affordance densities. ProceedingsInternational Conference Development Learning (ICDL), pp. 17.Diankov, R., Ratliff, N., Ferguson, D., Srinivasa, S., & Kuffner, J. (2008). Bispace planning:Concurrent multi-space exploration. Proc. Int. Conf. Robotics: ScienceSystems.39fiStulp, Fedrizzi, Mosenlechner, & BeetzFedrizzi, A. (2010). Action-Related Places Mobile Manipulation. Ph.D. thesis, TechnischeUniversiat Munchen.Fedrizzi, A., Moesenlechner, L., Stulp, F., & Beetz, M. (2009). Transformational planning mobile manipulation based action-related places. ProceedingsInternational Conference Advanced Robotics (ICAR)., pp. 18.Friedman, M., & Weld, D. S. (1996). Least-commitment action selection. Proceedings3rd International Conference A.I. Planning Systems, pp. 8693. AAAI Press.Geib, C., Mourao, K., Petrick, R., Pugeault, M., Steedman, M., Kruger, N., & Worgotter,F. (2006). Object action complexes interface planning robot control.Proceedings 2006 IEEE RAS International Conference Humanoid Robots,Genova.Gerkey, B., Vaughan, R. T., & Howard, A. (2003). Player/Stage Project: Toolsmulti-robot distributed sensor systems. Proceedings 11th InternationalConference Advanced Robotics (ICAR), pp. 317323.Gibson, J. J. (1977). Theory Affordances. John Wiley & Sons.Hart, S., Ou, S., Sweeney, J., & Grupen, R. (2006). framework learning declarativestructure. RSS-06 Workshop: Manipulation Human Environments.Huang, X., Paragios, N., & Metaxas, D. N. (2006). Shape registration implicit spacesusing information theory free form deformations. IEEE Trans. Pattern AnalysisMachine Intelligence (TPAMI), 28, 13031318.Kemp, C., Edsinger, A., & Torres-Jara, E. (2007). Challenges robot manipulationhuman environments. IEEE Robotics Automation Magazine, 14 (1), 2029.Klank, U., Zia, M. Z., & Beetz, M. (2009). 3D Model Selection Internet DatabaseRobotic Vision. International Conference Robotics Automation (ICRA),pp. 24062411.Kuipers, B., Beeson, P., Modayil, J., & Provost, J. (2006). Bootstrap learning foundational representations. Connection Science, 18, 145158.LaValle, S. M. (2006). Planning Algorithms, chap. Chapter 5: Sampling-Based MotionPlanning. Cambridge University Press.Maldonado, A., Klank, U., & Beetz, M. (2010). Robotic grasping unmodeled objectsusing time-of-flight range data finger torque information. 2010 IEEE/RSJInternational Conference Intelligent Robots Systems (IROS), pp. 25862591,Taipei, Taiwan.McDermott, D. (1991). Reactive Plan Language. Research Report YALEU/DCS/RR864, Yale University.Metta, G., Fitzpatrick, P., & Natale, L. (2006). YARP: Yet Another Robot Platform. International Journal Advanced Robotics Systems, special issue Software DevelopmentIntegration Robotics, 3 (1), 4348.Morales, A., Chinellato, E., Fagg, A. H., & del Pobil, A. P. (2004). Using experienceassessing grasp reliability. International Journal Humanoid Robotics, 1 (4), 671691.40fiLearning Reasoning Action-Related Places Robust Mobile ManipulationMosenlechner, L., & Beetz, M. (2009). Using physics- sensor-based simulationhigh-fidelity temporal projection realistic robot behavior. 19th InternationalConference Automated Planning Scheduling (ICAPS09).Okada, K., Kojima, M., Sagawa, Y., Ichino, T., Sato, K., & Inaba, M. (2006). Visionbased behavior verification system humanoid robot daily environment tasks.Proceedings 6th IEEE-RAS International Conference Humanoid Robots(Humanoids), pp. 712.Pastor, P., Hoffmann, H., Asfour, T., & Schaal, S. (2009). Learning generalizationmotor skills learning demonstration. Proceedings InternationalConference Robotics Automation (ICRA), pp. 12931298.Resulaj, A., Kiani, R., Wolpert, D. M., & Shadlen, M. N. (2009). Changes minddecision-making. Nature, 461 (7261), 263266.Roduit, P., Martinoli, A., & Jacot, J. (2007). quantitative method comparing trajectories mobile robots using point distribution models. Proceedings IEEE/RSJInternational Conference Intelligent Robots Systems (IROS), pp. 24412448.Ryan, M. R. K. (2002). Using abstract models behaviours automatically generate reinforcement learning hierarchies. Proceedings 19th International ConferenceMachine Learning, Sydney, Australia, pp. 522529.Smits, R. KDL: Kinematics Dynamics Library. http://www.orocos.org/kdl.Sonnenburg, S., Raetsch, G., Schaefer, C., & Schoelkopf, B. (2006). Large scale multiplekernel learning. Journal Machine Learning Research, 7, 15311565.Stulp, F., & Beetz, M. (2008). Refining execution abstract actions learned actionmodels. Journal Artificial Intelligence Research (JAIR), 32.Stulp, F., Fedrizzi, A., & Beetz, M. (2009a). Action-related place-based mobile manipulation. Proceedings International Conference Intelligent Robots Systems(IROS), pp. 31153120.Stulp, F., Fedrizzi, A., & Beetz, M. (2009b). Learning performing place-based mobilemanipulation. Proceedings 8th International Conference DevelopmentLearning (ICDL)., pp. 17.Stulp, F., Fedrizzi, A., Zacharias, F., Tenorth, M., Bandouch, J., & Beetz, M. (2009c).Combining analysis, imitation, experience-based learning acquire conceptreachability. 9th IEEE-RAS International Conference Humanoid Robots, pp.161167.Sutton, R., & Barto, A. (1998). Reinforcement Learning: Introduction. MIT Press.Wimmer, M., Stulp, F., Pietzsch, S., & Radig, B. (2008). Learning local objective functionsrobust face model fitting. IEEE Transactions Pattern Analysis MachineIntelligence (PAMI), 30 (8), 13571370.Zacharias, F., Borst, C., & Hirzinger, G. (2007). Capturing robot workspace structure: representing robot capabilities. Proceedings IEEE/RSJ International ConferenceIntelligent Robots Systems (IROS), pp. 32293236.41fiStulp, Fedrizzi, Mosenlechner, & BeetzZettlemoyer, L. S., Pasula, H. M., & Kaelbling, L. P. (2005). Learning planning rules noisystochastic worlds. Proceedings Twentieth National Conference ArtificialIntelligence (AAAI), pp. 911918.Zheng, Y., & Qian, W.-H. (2005). Coping grasping uncertainties force-closureanalysis. International Journal Robotics Research, 24 (4), 311327.42fiJournal Artificial Intelligence Research 43 (2012) 621-659Submitted 11/11; published 04/12Market-Inspired Approach Intersection ManagementUrban Road Traffic NetworksMatteo VasiraniSascha Ossowskimatteo.vasirani@urjc.essascha.ossowski@urjc.esCentre Intelligent Information TechnologyUniversity Rey Juan CarlosC/ Tulipan s/nMadrid, 28933, SpainAbstractTraffic congestion urban road networks costly problem affects majorcities developed countries. tackle problem, possible (i) act supplyside, increasing number roads lanes network, (ii) reduce demand, restricting access urban areas specific hours specific vehicles, (iii) improveefficiency existing network, means widespread use so-called IntelligentTransportation Systems (ITS). line recent advances smart transportationmanagement infrastructures, turned promising field applicationartificial intelligence techniques. particular, multiagent systems seem idealcandidates design implementation ITS. fact, drivers naturallymodelled autonomous agents interact transportation management infrastructure, thereby generating large-scale, open, agent-based system. regulatesystem maintain smooth efficient flow traffic, decentralised mechanismsmanagement transportation infrastructure needed.article propose distributed, market-inspired, mechanism management future urban road network, intelligent autonomous vehicles, operatedsoftware agents behalf human owners, interact infrastructure ordertravel safely efficiently road network. Building reservationbased intersection control model proposed Dresner Stone, consider two differentscenarios: one single intersection one network intersections.former, analyse performance novel policy based combinatorial auctionsallocation reservations. latter, analyse impact traffic assignment strategy inspired competitive markets drivers route choices. Finallypropose adaptive management mechanism integrates auction-based trafficcontrol policy competitive traffic assignment strategy.1. IntroductionRemoving human driver control loop use autonomous vehicles integrated intelligent road infrastructure considered ultimate,long-term goal set systems technologies grouped name IntelligentTransportation Systems (ITS). Autonomous vehicles already reality. instance,three DARPA Grand Challenges 1 held far. teams participatinglatest event, DARPA Urban Challenge, competed build best autonomous vehi1. http://archive.darpa.mil/grandchallenge/c!2012AI Access Foundation. rights reserved.fiVasirani & Ossowskicles, capable driving traffic, performing complex manoeuvres merging, passing,parking negotiating intersections. results shown first timeautonomous vehicles successfully interact manned unmanned vehiculartraffic urban environment. Several car-makers expect technology affordable(and less obtrusive) decade2 . Another initiative fosters vision Connected Vehicle 3 , promotes research development technologies link roadvehicles directly physical surroundings, i.e., vehicle-to-infrastructure wirelesscommunications. advantages integration span improved road safetyefficient operational use transportation network. instance, vehiclesexchange critical safety information infrastructure, recognise high-risksituations advance therefore alert drivers. Furthermore, traffic signal systemscommunicate signal phase timing information vehicles enhance usetransportation network.regard, authors recently paid attention potential tighterintegration autonomous vehicles road infrastructure future urban traffic management. reservation-based control system (Dresner & Stone, 2008), intersectionregulated software agent, called intersection manager agent, assigns reservations space time autonomous vehicle intending cross intersection.vehicle operated another software agent, called driver agent. vehicleapproaching intersection, driver requests intersection manager reservenecessary space-time slots safely cross intersection. intersection manager,provided data vehicle ID, vehicle size, arrival time, arrival speed, type turn,etc., simulates vehicles trajectory inside intersection informs driver whetherrequest conflict already confirmed reservations. conflictexist, driver stores reservation details tries meet them; otherwise may trylater time. authors show simulations situations balancedtraffic, vehicles autonomous, delays intersection drastically reducedcompared traditional traffic lights.article explore different lines research artificial intelligence agenttechnology improve effectiveness applicability Dresner Stonesapproach, assuming vehicles autonomous capable interactingregulating traffic infrastructure. extend reservation-based model intersectioncontrol two different levels.1.1 Single Intersectionsingle intersection, objective elaborate new policy allocationreservations vehicles takes account drivers different attitudes regardingtravel times. Instead granting disputed resources (intersection space time)first agent requests them, intend allocate agents valuemost, maintaining adequate level efficiency fairness system.main contribution regard definition auction-based allocation policy2. See example Alan Taub, General Motors Vice President Global R&D, 18th World CongressIntelligent Transport Systems, October 17th, 2011.3. http://www.its.dot.gov/connected vehicle/connected vehicle.htm622fiA Market-Inspired Approach Intersection Managementassigning reservations. policy models incoming requests bids intersectionsavailable space-time slots tries maximise overall value accepted bids. Duecombinatorial nature auction restrictions scenario (mainly realtime execution safety), define specific auction protocol, adapt algorithmwinner determination purposes, evaluate behaviour approach.1.2 Network Intersections.extend Dresner Stones approach network intersections, focusproblem traffic assignment, conceived distributed choice problem intersectionmanagers try affect decision making driver agents. particular, use marketsmediators distributed choice allocation problem (Gerding, McBurney, &Yao, 2010). contribution attainment objective twofold. First,build computational market drivers must acquire right passintersections urban road network, implementing intersection managerscompetitive suppliers reservations selfishly adapt prices match actualdemand. Second, combine competitive strategy traffic assignmentauction-based control policy intersection level adaptive, market-inspired,mechanism traffic management reservation-based intersections.article structured follows. Section 2 provides overview use artificialintelligence agent technology field ITS. Section 3 briefly review keyelements reservation-based intersection control model work sets from.Section 4 present policy allocation reservations single intersection,inspired combinatorial auction theory. Section 5 extend reservation-basedmodel network intersections. Finally, conclude Section 6.2. Related Workachieve goals pursued vision increasing need understand,model, govern systems individual (micro) societal (macro)level. Transportation systems may contain thousands autonomous entities needgoverned, raises significant technical problems concerning efficiencyscalability. inherent distribution traffic management control problems,high degree complexity, fact actors traffic transportation systems(driver, pedestrians, infrastructure managers, etc.) fit concept autonomous agentwell, allow modelling terms agents interact achievegoals, selfishly well cooperatively. Therefore, traffic transportation scenariosextraordinarily appealing multiagent technology (Bazzan & Klugl, 2008). section,outline key dimensions briefly review relevant literature useartificial intelligence multiagent techniques field.2.1 Traffic Control Traffic AssignmentTraffic control refers regulation access disputed road transport resource.Traffic control systems manage traffic along arterial roadways, employing traffic detectors,traffic signals, various means communicating information drivers. Freeway control623fiVasirani & Ossowskisystems manage traffic along highways, employing traffic surveillance systems, traffic controlmeasures freeway entrance ramps (ramp metering), lane management.Traffic control intersections, based traffic lights, major control measureurban road networks. type control typically applies off-line optimisation basishistorical data. TRANSYT (Robertson, 1969) well-known frequently appliedsignal control strategy, cannot adapt dynamically changing demand patterns.control techniques, SCOOT (Hunt, Robertson, Bretherton, & Winton, 1981),use real-time traffic volume rather historical data run optimisation algorithmscompute optimal signal plan.Traffic assignment refers problem distribution traffic network, considering demands several locations, capacity network. general,demand may change non-predictable way, due changing environmental conditions,exceptional events, accidents. This, turn, leads under-utilisation overall network capacity, whereby links heavily congested capacity reserves availablealternative routes. address problem, different traffic management techniques, involving information broadcast well control optimisation, employed.example, route guidance driver information systems (RGDIS) may employed improve network efficiency via direct indirect recommendation alternative routes (Papageorgiou, Diakaki, Dinopoulou, Kotsialos, & Wang, 2003). communication devicesmay consulted potential road user make rational decision regarding whethercarry (or postpone) intended trip, choice transport mode (car, bus,underground, etc.), departure time selection route choice.Traffic control assignment different focuses therefore combinedsingle management policy takes explicitly account mutual interactionssignal control policies user route choices (Meneguzzer, 1997).2.2 Isolated Coordinated Traffic Controltraffic control strategies use control devices (e.g., traffic lights, variable message signs,ramp meters) surveillance devices (e.g., loop detectors, cameras) manage physicaltraffic network. isolated control, small portion network (e.g. singleintersection) modelled, techniques control theory employed determinesignal cycles minimise vehicles total delay. instance, da Silva et al. proposedreinforcement learning system traffic lights copes dynamismenvironment incrementally building new models environmental state transitionsrewards (da Silva, Basso, Bazzan, & Engel, 2006). traffic pattern changes,additional model created new traffic signal plan learned. creation newmodels controlled continuous evaluation prediction errors generatedpartial model.coordinated control, settings several control devices adapted other,achieve smooth traffic flow network level (i.e., green waves) rathersingle intersection. allowing individual devices coordinate actionsbased information receive sensors other, coherent trafficcontrol plans often generated faster accurately compared human trafficoperator (van Katwijk, Schutter, & Hellendoorn, 2009). instance, distributed constraint624fiA Market-Inspired Approach Intersection Managementoptimisation (DCOP) techniques recently applied coordination controldevices (Junges & Bazzan, 2008). traffic signal agent assigned one severalvariables DCOP, inter-dependencies conflicts (e.g., two neighbouringintersections giving preference different directions traffic.). mediator agentcharge resolving conflicts occur, recommending values variablesassociated agents involved mediation.2.3 Time Perspectivetime perspective refers stage decision-making processapplication takes place. Operational decision-making refers short term issues,controlling traffic intersection. Tactical decision-making deals medium-termissues, anticipating congestion diverting traffic different routes influencingdemand patterns. Finally, strategic decision-making typically involves long-term decisions,e.g. planning construction new roads, highways parking hubs.Many AI-based partially automate operational part road traffic control tasks.Tactical strategic decision-making still mainly human activity (e.g., carriedcity planners). recent decision-support systems address tactical questionswell. InT RY (Hernandez, Ossowski, & Garca-Serrano, 2002), instance, multiagentsystem aimed assisting operators traffic control centre manage urban motorwaynetwork. system capable engaging dialogues operators, e.g. diagnosecauses detected traffic problems, construct coherent sets driver informationmessages, simulate expected effects control plans.2.4 Information DriversCooperative systems improve dynamic routing traffic management (Adler, Satapathy, Manikonda, Bowles, & Blue, 2005), using information services aimed giving advicedrivers efficiently assigning traffic among network. difficult problem collective route choice performed selfish agents often leads equilibrium strategiesfar social welfare optima (Roughgarden, 2003). Providing information congestion links sharing partial views vehicle choices, context-aware routing (Zutt,van Gemund, de Weerdt, & Witteveen, 2010), may improve systems efficiency.2.5 Domain KnowledgeDomain topological knowledge exploited structure architecturereasoning models ITS. instance, Choy et al. propose cooperative, hierarchical, multiagent system real-time traffic signal control (Choy, Srinivasan, & Cheu,2003). control problem divided various sub-problems, handledintelligent agent applies fuzzy neural decision-making. multiagent systemhierarchical, since decisions made lower-level agents mediated respectivehigher-level agents. InT RY system (Hernandez et al., 2002) conceives trafficdynamics terms so-called problem areas, defined based expertisetraffic engineers. problem area controlled separate traffic control (software)agent. Knowledge modelling reasoning techniques applied integrate local control625fiVasirani & Ossowskistrategies (proposed different traffic control agents) coherent global planwhole traffic network.2.6 Learning Adaptationoften rely learning techniques adapt changing unknown traffic conditions.instance, traffic light agents may use reinforcement learning minimise overallwaiting time vehicles (Steingrover, Schouten, Peelen, Nijhuis, & Bakker, 2005; Wiering,2000). control objective global, although actions local agents. statelearning task represented aggregation waiting times individual vehiclesintersection. Traffic light agents learn value function estimates expectedwaiting times vehicles given different settings traffic lights.Several authors focus self-organising self-adapting mechanisms traffic control (Gershenson, 2005; Lammer & Helbing, 2008), traffic lights self-organisedirect communication them. local interactions neighbouring traffic lights lead emergent coordination patterns green waves. way,efficient, decentralised traffic light control achieved, combination two rules, oneaims optimising flow one aims stabilising it. RY SA2system (Hernandez et al., 2002), traffic agents use mechanism called structural cooperation (Ossowski & Garca-Serrano, 1999) locally coordinate signal plan proposalswithout need rely dedicated domain (coordination) knowledge.2.7 Market-Based Coordinationcomplex system, traffic well suited application market-based coordination mechanisms different levels. mechanisms replicate functioning realmarkets (i.e., auctions, bargaining, etc.) order coordinate activities goalspursued set agents. agents regulate infrastructure builtact team, i.e., may share global objective function represents systemdesigners preferences possible solutions, occurs multi-robot domains (Dias,Zlot, Kalra, & Stentz, 2006). line perspective, Vasirani Ossowski (2009b)proposed market-based policy traffic assignment. authors put forward cooperative learning model coordinate prices several intersections. experimentalresults showed that, general, increase profit raised team intersectionsaligned reduced average travel times. limitation work number interactions environment required order price vector maximisesoverall profit learned.extend focus include selfish driver agents interactioninfrastructure agents, non-cooperative scenario arises. instance, auction-basedpolicy intersection control proposed work Schepperle Bohm (2007).work, intersection controlled intelligent agent starts auction earliesttime slot among vehicles approaching intersection lane. authorsassume agent controls intersection detect approaching vehicleanother vehicle front it. case, former allowed participateauction (i.e., bids processed), ensure vehiclesphysical impediments cross intersection allowed participate auction.626fiA Market-Inspired Approach Intersection ManagementFurthermore, since non-combinatorial auction run allocate earliest time-slot,one bidder (i.e., driver) entitled get specific time-slot, lead inefficienciesassignments.field transport economics also studies allocation resources used moveroad users place place (Small & Verhoef, 2007). However, follows staticanalytical approach requires extensive knowledge supply demand functions.information often hard obtain extract, usually findings fieldhard transfer directly ITS.2.8 Discussionwork, mainly focus operational time perspective, since aimmanage advanced traffic infrastructure regulates route choices autonomousvehicles, tactical strategic decisions left human users. order makeproposed mechanisms broadly adoptable, minimise domain knowledge necessaryset models. software agents reside traffic managementinfrastructure need aware remaining infrastructure agents, requireexpert knowledge related underlying traffic system. focus local adaptationmechanisms, rather learning techniques, enforce emergent coordination amongsoftware agents reside traffic management infrastructure. Furthermore,put forward market-based coordination framework involves infrastructuredrivers. infrastructure agents coordinate actions indirect waycompetitive market participants aim match supply demand. driveragents participate allocation road network capacity auction-basedmechanism regulates assignment right cross intersection. Finally,recognise importance providing information drivers order influencedecision making. particular, assume existence propagation mechanisms,market price information available drivers, thus potentially influencingcollective behaviour4 .3. Reservation-Based Intersection Controlapplications AI techniques multiagent technology traffic domainsdetailed previous section conceive lies infrastructure components (traffic lights, message signs, sensors, etc.), vehicles usually treatedparticles traffic flow control policy cannot individually address. Nevertheless,continuous advances software hardware technologies make tighter integrationvehicles infrastructure possible. Even today, vehicles equippedfeatures cruise control (Ioannou & Chien, 1993) autonomous steering (Krogh& Thorpe, 1986). Small-scale systems autonomous guided vehicles (AGV) already exist,example factory transport systems. trend continues, one day fully autonomousvehicles populate road networks. case, given system comprisevariable (and possibly huge) number vehicles, open infrastructure needed control4. Setting price index boards technically feasible already today: instance, NYSE indexesapproximately 8500 stocks, whose price variations spread worldwide almost immediately.627fiVasirani & OssowskiDriver agent(2)Send REQUESTIntersection managerReservation distancelter(5)> reservationdistance di ?Calculatedistance d(r)Get driveragent's ID(3)(1)yesSendREJECTION(6)(4)reservation ?yes(11)(10)SendREJECTIONUpdate diRemoveagent'sreservationmin(di,d(r))yes(9)(7)(8)Simulatetrajectoryconicts ?(13)(12)SendCONFIRMATIONUpdate diFigure 1: Reservation-based protocol FCFS policyschedule transit AGVs. fact, nowadays centralised AGV control systems knownumber vehicles, origins destinations, route planning takesplace. case urban road traffic scenario, approach certainly unfeasible.section present details reservation-based system intersectioncontrol (Dresner & Stone, 2008) relevant work5 . particular outlinepolicy executed intersection managers process reservations requests (Section 3.1)analyse impact distance reservation sent performancecontrol mechanism (Section 3.2).3.1 Protocolreservation-based control system proposed Dresner Stone assumes existencetwo different kinds software agents: intersection manager agents driver agents.intersection manager agent controls space intersection schedules crossingvehicle. driver agent entity autonomously operates vehicle (infollowing use terms intersection manager driver short, refersoftware agents control intersection vehicle respectively). protocol,using first-come-first-served policy (FCFS), summarised Figure 1. driver,5. remark work engineered basic aspects reservation-based system.consider advanced features, acceleration within intersections, safety buffers edgetiles. basic functioning reservation-based intersection assume workevery experimental scenario compare. way fair comparison different policiesallocation reservations guaranteed.628fiA Market-Inspired Approach Intersection Management(request reservation:sender:receiver:content(D-3548IM-05629:arrival time:arrival speed:lane:type turn08:03:1523km/h2LEFT))Figure 2: Example REQUEST messageapproaching intersection, contacts intersection manager sending REQUESTmessage (1). message contains vehicles ID, arrival time, arrival speed,lane occupied vehicle road segment approaches intersectionintended type turn (see Figure 2 example REQUEST message). intersectionmanager calculates distance d(r) driver sending reservation requestr (2). distance greater maximum reservation distance di lanedriver occupying (3), request rejected without processing (4). Otherwise,intersection manager proceeds evaluate whether accommodated not.First, drivers ID parsed (5), driver already prior reservation (6),reservation removed (7). Then, information contained REQUEST message,intersection manager simulates vehicle trajectory, calculating space neededvehicle time order check potential conflicts (8). (9),intersection manager updates maximum reservation distance di (10) repliesREJECTION message (11). Otherwise, maximum reservation distance di updatedinfinite (12) intersection manager replies CONFIRMATION message (13),implies drivers request accepted.FCFS policy implies two drivers send requests require spacetime slots inside intersection, driver sends request first obtainreservation. extreme cases policy clearly inefficient. Consider case setn vehicles, v1 , v2 , . . . , vn , v1 request conflicts every vehicle,v2 , . . . , vn conflicts one another. v1 sends request first,granted vehicles requests rejected. hand, sendsrequest last, n 1 vehicles requests confirmed, whilst v1wait. Nevertheless, FCFS advantage simple policy,needs minimum amount information necessary implement reservation-basedintersection control.3.2 Reservation Distanceprotocol detailed would prone deadlock situations, make usereservation distance filter. Consider two vehicles, B, moving frontB (see Figure 3). Suppose also B cannot safely overtake A. B send request629fiVasirani & OssowskiB sends requestrst getsreservationBA's requestrejected, thusmust stopintersectionGiven cannotcross, also B muststopintersectionFigure 3: Potential deadlock situation.space-time slots inside intersection, first request intersectionmanager receives accepted, second one rejected. vehicle B,behind vehicle A, obtains reservation, result vehicle ablecross hold confirmed reservation. turn prevents vehicle Bmaking use reservation. vehicle B always sends request first, deadlocksituation arises, vehicle physically blocking vehicle B, vehicle B blocking vehiclegetting disputed reservation.avoid occurrence deadlock situations, Dresner Stone proposeduse reservation distance heuristic criterion filtering reservation requestscould generate deadlock situations. Since drivers communicate timeplan arrive intersection, well speed get(quantities drivers incentive misrepresent), possibleapproximate vehicles distance intersection, given reservation requestvehicle. heuristic approximation, called reservation distance d(r), calculatedd(r) = va (ta t), va proposed arrival speed vehicle, ta proposedarrival time vehicle, current time.approximation assumes vehicle maintaining constant speed.reservation processing policy uses follows. lane i, policy variable di ,initialised infinity, represents maximum distance driver sendreservation request. reservation request r lane i, policy computesreservation distance, d(r). d(r) > di , r rejected. If, hand, d(r) di , rprocessed normal. r rejected processed normal, di min(di , d(r)).Otherwise, di . use reservation distance guarantee630fiA Market-Inspired Approach Intersection Managementmutually blocking situations never occur, prevent situations degeneratingdeadlocks.4. Single Intersectionsingle reservation-based intersection, problem intersection managersolve allocating reservations among set drivers way specific objectivemaximised. objective be, instance, minimising average delay causedpresence regulated intersection. case, simplest policy adopt allocatingreservation first agent requests it, occurs FCFS policy proposedDresner Stone original work. Another work line objective takesinspiration adversarial queuing theory definition several alternative controlpolicies aim minimising average delay (Vasirani & Ossowski, 2009a)However, policies ignore fact real world, depending contextpersonal situation, people value importance travel times delays quitedifferently. Since processing incoming requests grant associated reservationsconsidered process assigning resources agents request them, one mayinterested intersection manager aims allocate disputed resourcesagents value most. line approaches mechanism design,assume human driver willing pay desired set space-time slots,value good. Therefore, rely combinatorial auction theory (Krishna,2002) definition auction-based policy allocation resources.4.1 Auction-Based Policyformalise auction-based policy processing incoming reservation requests,necessary specify auction design space. includes definition disputedresources, rules regulate bidding clearing policy.4.1.1 Auctioned Resourcesfirst step design auction definition resources (or items)allocated. nature items determines type auction employedallocate them. scenario, auctioned good use space insideintersection given time. model intersection discrete matrix space slots.Let set intersection space slots, = {s1 , s2 , . . . , sm }. Let tnow currenttime, = {tnow + , N} set future time-steps. set itemsbidder bid set = . Due nature problem, bidderinterested bundles items set I. absence accelerationintersection, reservation request (Figure 4) implicitly defines space slotstime driver needs order pass intersection6 . Thus, items mustnecessarily allocated combinatorial auction.6. computation easily done intersection manager, knows geometry intersection. vehicles calculate trajectory, would need know geometry everyintersection pass through.631fiVasirani & Ossowskit4t4t3t3t2t2t4t4t3t3t2t2t1t1t1t1t0t0t0t0Figure 4: Bundle items defined reservation request.4.1.2 Bidding Rulesbidding rules define form valid bid accepted auctioneer (Wurman,Wellman, & Walsh, 2001). scenario, bid bundle items implicitly definedreservation request. Given parameters arrival time, arrival speed, lane typeturn, auctioneer (i.e., intersection manager) able determine space slotsneeded time. Thus, additional parameter driver must includereservation request value bid, i.e., amount money willing payrequested reservation.bidder allowed withdraw bid submit new one. may happen,instance, driver submitted bid b, estimating intersectiontime t, realises that, due changing traffic conditions, likelyintersection time + t, thus making submitted bid b useless driver.case driver guarantees safety regarding crossing intersection. Thus,rational thing case, driver would want risk involvedcar accident, resubmitting bid updated arrival time. However, new bidmust greater equal value previous one. constraint avoidssituation whereby bidder blocks one several slots itself, acquiring earlyoverpriced bids. Even though would oblige others try reserve alternativeslots, thus make desired slot less disputed, bidder cannot take advantagethis, cannot withdraw initial bid resubmit lower bids order obtainreservation lower price.632fiA Market-Inspired Approach Intersection Managementnew bidswinnersbid setSendCONFIRMATIONSolveWDPCollectincomingbidslosersCollectincomingbidsSendREJECTIONnew bidsFigure 5: Auction policy4.1.3 Auction Policyauction policy (see Figure 5) starts auctioneer waiting bids certain amount time t. new bids collected, constitute bid set.Then, auctioneer executes algorithm winner determination problem (WDP),winner set built, containing bids whose reservation requests accepted. WDP algorithm execution, auctioneer still accepts incoming bids,included bid set next round. auctioneer sendsCONFIRMATION message bidders submitted bids contained winner set,REJECTION message sent bidders submitted remaining bids.new round begins, auctioneer collects new incoming bids certain amounttime7 .4.1.4 Winner Determination AlgorithmSince auction must performed real-time, bid collection winnerdetermination phase must time-bounded, is, must occur within specific timewindow. implies optimal complete algorithms WDP (Leyton-Brown,Shoham, & Tennenholtz, 2000; Sandholm, 2002) suited kind auction.algorithm anytime properties needed (Hoos & Boutilier, 2000), longeralgorithm keeps executing, better solution finds.7. safety reasons auctioneer cannot spend much time collecting bids, deallocatepreviously granted reservations. Therefore possible low-valued bid, winner set roundk, impedes allocation disputed reservation high-valued bids, submitted round k + n.case, second bidder slow resubmit new (possibly winning) bid. Althoughtheory bid-delay relation (Figure 7) could worsened unrelated sequence auctions,practice effect negligible.633fiVasirani & OssowskiAlgorithm 1 Winner determination algorithmB allBidsWstart currentT imecurrentT ime start < 1 secstep = 1 |B|step step + 1random drawU nif ormDistribution(0, 1)random < wpb selectRandomlyF rom(B \ A)elsehighest selectHighestF rom(B \ A)secondHighest selectSecondHighestF rom(B \ A)highest.age secondHighest.ageb highestelserandom drawU nif ormDistribution(0, 1)random < npb secondHighestelseb highestendendend !AA{b} \ N (b)A.value > W.valueWAendendendAlgorithm 1 sketches winner determination problem solved. algorithmstarts initialising set B containing bids received far. winner set Winitialised empty set. initialisation concluded, algorithmexecutes main loop 1 second. Within main loop, stochastic search performednumber steps equal number bids B. Set contains candidate bidswinner set. Then, probability wp (walk probability8 ), random bid selectedset bids actually candidate winner set (B \ A), while,probability 1 wp, highest second highest bids evaluated. highest bidselected age (i.e., number steps since bid last selected addedcandidate solution) greater equal age second highest bid. Otherwise,8. probability adding random, previously allocated bid candidate winner set.634fiA Market-Inspired Approach Intersection ManagementFigure 6: Simulator single intersectionprobability np (novelty probability9 ) second highest, probability 1 nphighest bid selected. Finally bid b added candidate solutionneighbours N (b), is, set bids bundles share b least one item,removed A. Finally, value (i.e., sum bids A) greatervalue best-so-far winner set, W, best solution found far updated.4.2 Simulation Environmentsimulator use evaluation auction-based policy custom, microscopic,time-and-space-discrete simulator, simple rules acceleration deceleration.simulated area modelled grid, subdivided lanes (see Figure 6). lane3m wide, subdivided 12 squared tiles 0.25m each. vehicle modelledrectangle 816 tiles, equivalently, rectangle 2m4m, preferred speedinterval [30, 50]km/h. simulation environment generates origin-destinationpair randomly. vehicle spawned inside simulation, insertedbeginning one 4 incoming links, randomly selected, destination randomlyassigned it. destination implies type turn (left, right straight)vehicle perform intersection well lane use travel (the leftmost lane case left turn, right-most lane case right turn, lane goingstraight). preferred speed assigned using normal distribution mean 40km/hvariance 5km/h, limited interval [30, 50].9. probability adding candidate winner set second highest bid rather greedybid, i.e., highest value.635fiVasirani & OssowskiSince link used approach intersection relatively short, assumevehicle travel pre-assigned lane, without changing it. Therefore, needcar-following model simulate vehicle dynamics, lane-changing modelneeded. car-following model use Intelligent Driver Model (Treiber, Hennecke,& Helbing, 2000). model, decision driver accelerate brake dependsspeed, speed vehicle immediately ahead it. Specifically,acceleration dv/dt given vehicle depends speed v, distancefront vehicle, speed difference v (positive approaching) :"# $ # $2 %dvv= 1dtvp(1)= s0 +#v vvT +2 ag$(2)acceleration, g deceleration10 , v actual speed, vp preferredspeed, s0 minimum gap, time headway.acceleration divided acceleration towards preferred speed freeroad, braking decelerations induced front vehicle. acceleration freeroad decreases initial acceleration 0 approaching preferred speed vp .braking term based comparison preferred distance ,current gap respect front vehicle. current gap approximatelyequal , braking deceleration essentially compensates free accelerationpart, resulting acceleration nearly zero. means correspondsgap following vehicles steady traffic conditions. addition, increasesdynamically approaching slower vehicles decreases front vehicle faster.consequence, imposed deceleration increases decreasing distance frontvehicle, increasing speed, increasing speed difference front vehicle.aforementioned parameters set vp = 50km/h, = 1.5s, s0 = 2m, = 0.3m/s2 ,b = 3m/s2 . speed vehicle updated every second, position, since spacediscrete, updated tile closest new position continuous space.4.3 Experimental Resultscreate different traffic demands varying expected number vehicles () that,every O-D pair, spawned interval 60 seconds, using Poisson distribution.spawned vehicles total time 30 minutes. Table 1 shows number vehiclesgenerated different values .main goal set experiments test whether policy based combinatorial auction (CA) enforces inverse relation money spent biddersdelay. delay measures increase travel time due presenceintersection. computed difference travel time intersection10. g different parameters different values, since usually vehicle decelerates (i.e., brakes)strongly accelerates.636fiA Market-Inspired Approach Intersection Management# vehicles12951361028515438206332571630832Table 1: Traffic demands single intersectionregulated intersection manager, travel time would arise vehiclecould travel unhindered intersection. bid driver willing submitdrawn normal distribution mean 100 cents variance 25 cents, sincewillingness human drivers pay usually normally (or log-normally) distributed (Hensher & Sullivan, 2003). Thus, agents homogeneous sense amountmoney offering differs one another. population, trackdelay subset drivers, endowed 10, 50, 100, 150, 200, 1000, 1500,2000 10000 cents. endowment entirely allocated bid. also evaluateauction-based policy respect average delay entire population drivers.WDP algorithm, set walk probability wp = 0.15 novelty probability np = 0.5, values produced best results auctions similar typesize (Hoos & Boutilier, 2000). experiments, give intersection manager onesecond execute WDP algorithm return solution. give time bidders submit bids, starting another auction, intersection manager waitsanother second collect incoming bids11 . determine one second enoughwinner determination algorithm produce acceptable results, performed following experimental analysis. According results reported Hoos Boutilier, givenauction 100 bids, winner determination algorithm able find optimalsolution probability 0.6, tends 1 algorithm allowed run10 seconds. encouraging, order justify adequacystochastic algorithm particular problem, need show that, contextauction-based policy reservation-based intersection control, produces resultsreasonably close optimum, despite relatively short time (1 second experiments) algorithm return solution. Given average numbersubmitted bids single auction 3 low traffic demand ( = 1) 80high traffic demand ( = 30), performed several experiments compare solutionprovided algorithm 1 second run-time solution provided algorithm 100 seconds. solution provided second execution algorithmassumed best approximation optimal solution. resultwinner determination algorithm able find solution whose value least 95%optimal solution value probability 96.1% high traffic demand ( = 30)99.2% low traffic demand ( = 1).Figure 7 plots (in logarithmic scale) relation travel time bid valuedifferent values . error bars denote 95% confidence intervals.sensible decrease delay experienced drivers bid 100 150 cents,represent 49.8% drivers whose bid greater mean bid. Still, delayreduction tends settle drivers bid 1000 cents.11. Nevertheless, intersection manager runs separate thread receives incoming bids alsoWDP algorithm execution.637fiVasirani & Ossowski50090807060101001000Bid (cents)(a) = 1010000900450Avg delay (sec)Avg delay (sec)Avg delay (sec)100400350300250800700600500101001000Bid (cents)(b) = 201000010100100010000Bid (cents)(c) = 30Figure 7: Bid-delay relation various values normally distributed endowmentsremark auction-based policy also uses reservation distance preprocessing step, guarantees drivers bid cannot rejected indefinitely.fact, vehicle allowed approach intersection slow reachesintersection edge. point, request rejected another driver submittedhigher value bid, reservation distance updated stopped vehicles distance.Therefore, following time step, driver allowed submit bidpreferred value. result is, course, driver suffer greater delays compareddrivers willing pay more12 .auction-based allocation policy proven effective regarding main goal,is, rewarding lower delays drivers value disputed reservationsmost. However, worth analysing impact policy intersectionsaverage delay. Figure 8a plots average delay different traffic demands ( [1, 30]).Again, error bars denote 95% confidence intervals. traffic demand low, performance CA policy FCFS approximately same. However, trafficdemand increases, noticeable increase average delay intersectionmanager applies CA. somewhat expected, CA policy aims grantreservation driver values most, rather maximising numbergranted requests. Thus, bid b, whose value greater sum n bids shareitems b, likely selected winner set. so, 1 vehicleallowed transit, n vehicles slow try again. facthighlighted also average rejected requests (Figure 8b). Since non-winningbids rejected, number rejected requests CA policy four timesgreater FCFS policy.12. Although focus technical problems social political ones, one may wonder whetherfair rich drivers travel faster poor drivers using road-infrastructure publicgood. Nevertheless, could argue money raised auction-based policy richdrivers contribute much maintenance extension public road infrastructurepoor drivers.638fiA Market-Inspired Approach Intersection ManagementFCFSCA600Avg delay (sec)Avg rejected requests (%)700500400300200100051015202530FCFSCA201510551015202530(a)(b)Figure 8: Average delay (a) average rejected requests (b)4.4 Discussionprinciple optimising use available resources unique guidingprinciple traffic controller. real world, depending contextpersonal situation, drivers value importance travel times delays quite differently.Thus, makes sense elaborate control policies aware different valuationsreward drivers value disputed resources most. respect,evaluated control policy reservation-based intersections relies auctionmechanism. policy, drivers submit high-value bids usually experiencesignificant reductions individual delays (about 30% less compared driverssubmit low-value bids).However, since objective policy maximising number grantedreservations, pays social cost, form greater average travel times. factmight limit applicability CA policy high load situations. case, additionalmechanisms reduce number vehicles approach single intersection needed.also worth noting possible driver, even theoretically infiniteamount money, cannot experience zero delay approaching intersection.auction carried realistic traffic scenario quite differentsynthetic auction set-up benchmarking purposes (Hoos & Boutilier, 2000).auctions arise traffic scenario affected high level dynamism,uncertainty noise, intrinsic domain. example, high load situations,reservation distance plays important role, since filters many potentially winningbids coming greater distance13 . Figure 9 plots reservation distance decreasestime different traffic demands. high load situations, reservation distancetends small, therefore wealthy driver must reach reservation distance orderparticipate auction acquire reservation, thus increasing travel time.estimation arrival time also greatly affects performance auction. fact,13. outlined Section 3.2, reservation distance maximum distance driver allowedrequest reservation.639fiReservation distance (m)Vasirani & Ossowski3503002502001500=1= 10= 20= 30510152025Time (min)Figure 9: Reservation distancehigh load situations, estimation much noisy uncertain, likelydriver must resubmit reservation request updated arrival time.way, possible agent wins auction time then, due new estimationarrival time, must resubmit bid time + t. bidders participateauction time + obviously different participated time t,guarantee agent might win auction again.Furthermore, real-world scenario urban traffic limits auction design spaceapplicable solution methods winner determination payments calculation.fact, gave priority winner determination problem, adapting local search algorithm needs, payments calculation adopt sophisticatedmethod, i.e., winner pays price exactly bid submitted. This,first-price payment mechanism, could principle lead malicious behaviours,drivers try acquire reservations submitting bids lowerreal valuations have. single item auctions computationally easy setincentive compatible payment mechanism, second-price (Vickrey) mechanism.Unfortunately, extending mechanism combinatorial auctions (computationally) straightforward, since equivalent truth-revealing mechanism combinatorialworld, Vickrey-Clarke-Groves (VCG) payment mechanism (Clarke, 1971; Groves, 1973;Vickrey, 1961), NP-complete. Therefore, although driver agent could potentially acquirereservation submitting bid &b lower real valuation b, practicalpoint view exclusively affects revenues auctioneer gain everybidder truth-telling, primary concern. Another possible weaknessfact bidder could start bidding lower real valuation raising bid able acquire it, thus leading communication overheadbidders auctioneer. Nevertheless, bidders within reservation distance able submit bid, thus number bids intersection manager mayreceive simultaneously necessarily bounded.640fiA Market-Inspired Approach Intersection Management5. Network Intersectionssingle intersection scenario analysed performance auction-based policyallocation reservations. context, driver modelled simple agentselects preferred value bid submitted auctioneer.focus urban road network multiple intersections, interesting noticedecision space driver much broader. fact, drivers involved complexmutually dependent decisions route choice departure time selection.time, scenario opens new possibilities intersection managers affect behaviourdrivers. example, intersection manager may interested influencingcollective route choice performed drivers, using variable message signs, informationbroadcast, individual route guidance systems, evenly distribute trafficnetwork. problem called traffic assignment.Section 5.1 evaluate market-inspired methods (Gerding et al., 2010)applied traffic assignment strategies networks reservation-based intersections.idea that, market drivers acquire necessary reservations passintersections urban network, market, intersection managersoperate supply side, designed work traffic assignmentsystem. particular, model intersection managers apply competitivepricing strategy compete among supply reservationstraded. Finally, Section 5.2 combine traffic assignment strategy auctionbased control policy integrated mechanism traffic management urban roadnetworks.5.1 Competitive Traffic Assignment (CTA)Traffic assignment strategies aim influencing collective route choice drivers orderuse road network capacity efficiently. Therefore, see traffic assignmentproblem distributed choice allocation problem, since set resources (i.e.,links capacity) must allocated set agents (i.e., drivers). regard,markets mediators distributed resource allocation problems appliedseveral socio-technical systems (Gerding et al., 2010).Setting approach outlined work Vasirani Ossowski (2011),follow metaphor model intersection manager provider resources,case, reservations intersection manages. Thus, intersection managerfree establish price reservations provides. side market,driver modelled buyer resources. Provided current pricesreservations, chooses route, according personal preferences traveltimes monetary costs. intersection manager modelled competeothers supply reservations traded. Therefore, goal marketdesigners making intersection managers adapt prices towards price vectoraccounts efficient allocation resources.641fiVasirani & Ossowski5.1.1 CTA Pricing StrategyLet L set incoming links generic intersection. incoming link l L,intersection manager defines following variables:Current price pt (l): price applied intersection manager reservationssold drivers come incoming link l.Total demand dt (l | pt (l)): represents total demand reservationsincoming link l intersection manager observes time t, given currentprice pt (l). given number vehicles want cross intersectioncoming link l time t.Supply s(l): defines reservations supplied intersection managerincoming link l. constant represents number vehicles crossintersection coming link l intersection manager willing serve.Excess demand z (l | pt (l)): difference total demand timesupply, z (l | pt (l)) = dt (l | pt (l)) s(l).Given set intersection managers operating market, J ,define price vector pt vector prices applied intersection managercontrolled links:pt = [ pt1 (l1 ) pt1 (l2 ) . . . pt|J | (lh ) ](3)p1 (l1 ) price applied intersection manager 1 controlled link l1 , p1 (l2 )price applied intersection manager another link l2 intersection,p|J | (lh ) price applied |J |th intersection manager last controlled linklh .particular, say price vector pt maps supply demand excessdemand z (l | pt (l)) 0 links network. price vector, correspondsmarket equilibrium price, computed Walrasian auction (Codenotti,Pemmaraju, & Varadarajan, 2004), buyer (i.e., driver) communicatessuppliers (i.e., intersection managers) route willing choose, given currentprice vector pt . information, intersection manager computes demanddt (l | pt (l)) well excess demand z (l | pt (l)) controlled links. Then,intersection manager adjusts prices pt (l) incoming links, loweringexcess supply ( z (l | pt (l)) < 0 ) raising excess demand( z (l | pt (l)) > 0 ). new price vector pt+1 communicated driversiteratively choose new desired route, basis new price vector pt+1 .equilibrium price computed, trading transactions take place driver buysrequired reservations intersections lay route.Walrasian auction relies quite strict assumptions, make direct implementation traffic domain hard. instance, set buyers assumed fixedauction, means traffic domain new drivers may joinauction terminates. Also fact transactions take place disequilibrium prices strict assumption traffic domain. unreasonable642fiA Market-Inspired Approach Intersection ManagementAlgorithm 2 Intersection manager price updatet0l Lpt (l)s(l) 0.5 opt $(l)endtruel Ldt (l) evaluateDemandz (l) dt (l) s(l)z (l)pt (l) pt (l) + pt (l)s(l)endtt+1enddrivers wait reach equilibrium point choosing desired route startingtravel. Finally, driver probably willing transfer money intersection managerspatially close it, is, already travelling along desired route.Thus, implement pricing strategy aims reach equilibrium price -Walrasian auction - works continuous basis, drivers leavejoin market dynamically, transactions take place continuously. reachgeneral equilibrium, intersection manager applies price update strategy sketchedAlgorithm 2. time t, intersection manager independently computes excessdemand z (l | pt (l)) updates price pt (l) using formula (Codenotti et al., 2004):'(z (l | pt (l))t+1p (l) max , p (l) + p (l)(4)s(l)minimum price intersection manager charges reservationssells.s(l) supply intersection manager, is, number vehiclesintersection manager considers excess demand starts raiseprices.claim drivers travel road network links low demand shallincur costs. reason, choose = 0. define supply s(l), relyfundamental diagram traffic flow (Gerlough & Huber, 1975). Let opt densitymaximises traffic flow link l (see Figure 10). choose s(l) = 0.5 opt $(l),$(l) length link l. words, intersection manager considersexcess demand density reaches 50% optimal density. wayintersection manager aims avoid exceeding opt raising prices diverting driversdifferent routes reaching opt .643fiVasirani & OssowskiTrafc ow (veh/h)optoptDensity (veh/km)Figure 10: Fundamental diagram traffic flow5.1.2 Driver ModelUnlike single intersection scenario, case need reasonable driver modelroute choice. route choice problem modelled multi-attribute utility-functionmaximisation problem. Given traffic system regulated market mechanism,driver must take consideration different aspects route determine utilityvalue. route modelled ordered list links, = [l1 . . . lN ]. generic linklk characterised two attributes: estimated travel time E[T (lk )] pricereservations K(lk ). sake simplicity, estimation based travel timefree flow, consider real-time information traffic conditions (see Equation 5,$(lk ) length link lk , vmax (lk ) maximum allowed speed link lk ).price reservations link lk always 0, unless link lk one incoming linkintersection (lk = l), case price pt (l) (Equation 6).E[T (lk )] =K(l ) =k)$(lk )vmax (lk )pt (l)0lk = l Lotherwise(5)(6)summatory estimated travel time links gives estimated traveltime entire route :E[T ()] =N*E[T (lk )](7)k=1Similarly, summatory price reservations links gives priceentire route :K() =N*k=1644K(lk )(8)fiA Market-Inspired Approach Intersection ManagementLet C = {1 , . . . , } choice set, is, set routes available driver.set C built using k-shortest paths algorithm (Yen, 1971), k = 10. Let uT ()normalised utility route estimated travel time attribute (Equation 9),MT = max E[T (i )] mT = min E[T (i )].CCuT () =MT E[T ()]MT mT(9)Let uK () normalised utility route reservations cost attribute (Equation 10), MK = max K(i ) mK = min K(i ).CCuK () =MK K()MK mK(10)driver multi-attribute utility route defined as:U () = wT uT () + wK uK ()(11)wT weight estimated travel time attribute wK weightcost reservations attribute. Basically, wT = 1 driver utility considersattribute related estimated travel time (i.e., prefers shortest route, matterprice reservations), wK = 1 driver utility considers attributerelated cost reservations (i.e., prefers cheapest route, matter traveltime), every combination weights wT wK driver considerstrade-off estimated travel time cost reservations. experimentsdraw wT uniform distribution interval [0, 1], set wK = 1 wT .utility routes form choice set C computed, drivermust choose one alternatives. work, model driver deterministicutility maximiser always selects route highest utility value. Sinceprice incoming links intersection changing dynamically, term uK ()Eq. 11 may change journey. reason, driver continuously evaluatesutility route following and, case different route becomesattractive, may react change on-the-fly reach destination, selecting routedifferent original one.5.1.3 Simulation Environmentexperimental evaluation performed hybrid mesoscopic-microscopic simulator,traffic flow roads modelled mesoscopic level (Schwerdtfeger, 1984),traffic flow inside intersections modelled microscopic level (Nagel &Schreckenberg, 1992).mesoscopic model vehicle dynamics governed average traffic densitylink traverses rather behaviour vehicles immediate neighbourhoodmicroscopic models. road network modelled graph, nodes representintersections edges represent lanes road. edge, also called stretch,subdivided sections (of typically 500m length) constant traffic conditionassumed. vehicle time driving link lk characterised position645fiVasirani & Ossowskixti [0, $(lk )], speed vit . time step, new target speed vehiclecomputed, using formula:v&it+t = (1xtixtik)y(l)+y(lk+1 )$(lk )$(lk )(12)y(lk ) reference speed link lk y(lk+1 ) reference speed link lk+1 .reference speeds calculated taking consideration mean speed linkvehicles desired speed. mean speed link calculated speed-densityfunction given links density (lk ) returns links mean speed (Schwerdtfeger,1984).equation takes consideration fact closer vehiclenext link lk+1 , higher effect link reference speed vehicle targetspeed. new target speed v&it+t higher (lower) current speed vit , vehicleaccelerates (decelerates) vehicle-type specific maximum acceleration (deceleration).new speed denoted vit+t . Finally, vehicle position updated usingformula:1(vit + vit+t )(13)2xt+t$(lk ), vehicle placed next link route, densities link lklk+1 updated accordingly, position reset xt+t$(lk ).mesoscopic model described offer necessary level detailmodel reservation-based intersection. reason, vehicle enters intersection, dynamics switches microscopic, cellular-based, simulator (Nagel & Schreckenberg, 1992), similar simulation environment used Section 4.2. Still, cellscompose intersections area coarse grained (5 meters), simplicityassume vehicles cross intersection constant speed, additionaltuning parameters, slowdown probability acceleration/deceleration factors,necessary.xt+t= xti +5.1.4 Experimental ResultsAlthough work depend underlying road network, chose (simplified)topology entire urban road network city Madrid empirical evaluation(see Figure 11). network characterised several freeways connect citycentre surroundings ring road. large dark vertex Figure 11 -connects three links - modelled reservation-based intersection. aimrecreate typical high load situation (i.e., central, worst part morning peak),11,000 vehicles departing within time window 50 minutes (see Table 2).vehicles travel 7 destinations outside city (marked O1 O7Figure 11) form traffic evaluation.market-inspired traffic assignment strategy compared network FCFSreservation-based intersections. latter, drivers route choice takes consideration expected travel time free flow, since notion price.focus two different types metrics, one related vehicles one relatednetwork. network-related metric density variation time 7 critical646fiA Market-Inspired Approach Intersection ManagementFigure 11: Urban road networkOriginO1O2O3O4O5O6O7O1O2DestinationO3O4O5O6O7223300208199290224323364233228316231355221229261398214349214368199238253271229362204209337-336248343216386235311191358218374219Table 2: OD Matrix (# vehicles)intersections (marked c1 . . . c7 Figure 11), connect freeways going towardcity centre ring road. vehicle-related metric average travel time,grouped origin-destination (O-D) pair. given O-D pair, compute averagetravel time vehicles go D. measurement averaged 30runs. Furthermore, O-D pair compute improvement % CTA FCFSbased average travel times. Table 3 shows average travel time drivers,according origin-destination pairs, reservations allocated647fiVasirani & Ossowskicompetitive traffic assignment (CTA) granted usual FCFSpolicy. Using CTA observe net reduction average travel time 30 42 origindestination pairs. reduction generally noteworthy busiest14 routes,O6 -O2 , O6 -O3 O7 -O3 . Along less demanded O-D pairs, FCFSbest performing policy. happens preferred routetraffic density already low enough assure free flow, exist alternative routeseven lower demand, CTA keeps diverting traffic along potentially longerthus slower routes.evaluate effects trading activity drivers intersection managersworth observing density variation time critical intersections c1 c7 ,plotted Figure 12. general, density tends lower CTA comparedsystem regulated FCFS intersection managers. least demanded intersections c1 ,c2 c7 , is, intersections whose density density maximisestraffic flow (see Figure 10), substantial difference CTA FCFS.critical intersections less demanded due topology network. fact, fewerorigins located northern part (O1 , O2 O7 ).critical intersections c3 , c4 c6 , vehicle density CTA alwaysdensity results use FCFS, especially case intersections c4c6 CTA density exceeds optimal one small extentlimited period time.intersection c5 , density higher peak around 9:30, density startsexceed optimal density later begins fall optimal density earlier.calculated integral density curves, measured interval curveoptimal density (Eq. 14)+ t2+ t2CTA (t)dtFCFS (t)dt(14)t1t1CTA FCFS density functions, t1 = min( | CTA (t) > opt , | FCFS (t) >opt ) t2 = max( | CTA (t) < opt , | FCFS (t) > opt ). metric lowerreservations allocated competitive market (70.24 veh h/km versus105.07 veh h/km).result application market-inspired traffic assignment strategybalanced urban network, since price fluctuations force demand change towardsless expensive intersections. fluctuations contribute creating system dynamicequilibrium, unused intersections became cheaper congested ones becameexpensive. effect average travel time decreases, although guaranteesdrivers pay rewarded lower travel times.14. empirically noticed experiments southern part network tendscongested simulation. due fact 4 7 origins/destinations (O3 , O4 , O5 ,O6 ) located southern part.648fiA Market-Inspired Approach Intersection ManagementOriginCTAO1 FCFS%CTAO2 FCFS%CTAO3 FCFS%CTAO4 FCFS%CTAO5 FCFS%CTAO6 FCFS%CTAO7 FCFS%DestinationO4O5O1O2O3-12.090.2711.980.31-0.8%19.580.8022.891.1714.4%14.170.7216.501.0614.1%11.260.1710.150.06-11.0%15.570.3313.350.09-16.7%24.790.7726.941.318.0%26.800.8432.171.8316.7%23.170.5022.510.40-2.9%15.050.2214.310.10-5.2%10.790.149.760.03-10.6%20.390.6022.581.069.7%22.830.7130.611.7025.4%27.310.5557.013.1352.1%23.520.3323.260.40-1.1%11.620.4113.920.8216.5%16.300.6721.541.3924.3%25.300.8941.052.5938.4%31.670.8256.423.0143.9%26.701.0435.131.8024.0%19.020.6625.871.5126.5%9.180.0812.210.6224.8%7.470.208.830.3115.4%16.400.7324.681.6233.6%24.440.9734.992.1530.2%30.750.8343.571.8929.4%23.720.8331.052.0323.6%13.990.3717.640.9220.7%8.210.2710.050.4818.3%12.120.4619.021.5036.3%19.120.6931.242.0638.8%O6O721.170.2021.350.400.8%24.000.4038.091.8237.0%18.540.3223.696.3421.7%14.350.4815.740.738.8%11.110.2410.770.26-3.1%14.130.1213.830.09-2.2%20.880.2319.510.15-7.0%24.950.4231.731.3621.4%21.660.7522.740.994.8%19.470.6317.660.52-10.3%16.580.8913.730.32-20.8%11.690.1112.000.202.5%-Table 3: Average travel time minutes ( 95%CI): CTA vs. FCFS649fiVasirani & OssowskiFCFSCTAOptimum1412108642FCFSCTAOptimum20Density (veh/km)Density (veh/km)16015105008:00:0009:00:0010:00:0011:00:0008:00:00FCFSCTAOptimum4010:00:0030201050011:00:00FCFSCTAOptimum40302010008:0009:0010:0011:0008:00:00Time(c) Intersection c309:00:0010:00:0011:00:00Time(d) Intersection c440302010FCFSCTAOptimum40Density (veh/km)FCFSCTAOptimum50Density (veh/km)09:00:00Time(b) Intersection c2Density (veh/km)Density (veh/km)Time(a) Intersection c10302010008:0009:0010:0011:0008:00Time(e) Intersection c510:0011:00Time(f) Intersection c616Density (veh/km)09:00FCFSCTAOptimum1412108642008:0009:0010:0011:00Time(g) Intersection c7Figure 12: Density variation time critical intersections evaluation650fiA Market-Inspired Approach Intersection Management5.2 Integrated Mechanism Traffic Management (CA-CTA)Section 4.1, introduced auction-based policy control single intersection.experimental results showed policy quite effective allocating reservations drivers value most. Drivers bid high usually experiencegreat reduction delay (about 30%), compared drivers submit low-valuebids. However, policy showed couple drawbacks. First, fostersattainment user optimum rather global one. therefore pays social price,form greater average delay entire population drivers. Furthermore,possible even wealthy drivers, high-load situations, could get reservation,example due decreasing reservation distance.hand, one results experimental evaluation Section 5.1traffic assignment strategy make task traffic controllers easier, enforcingbetter distribution traffic demand. Therefore, seems reasonable combineauction-based policy competitive traffic assignment strategy integrated,market-inspired, mechanism traffic management.5.2.1 CA-CTA Mechanismadapt competitive traffic assignment strategy (CTA) combine auctionbased policy (CA) integrated mechanism traffic management (CA-CTA). Sinceintersection manager supplier reservations allocatedcombinatorial auction, may control reserve price auctioned reservations, i.e.,minimum price intersection manager willing sell. modelintersection managers way compete provision reservationsdrivers, raising reserve price case increasing demand lowering casedecreasing demand. reservations allocated CA policy definedSection 4.1. However, bids whose value reserve price acceptedbid set.incoming link l generic intersection, intersection manager independentlycomputes excess demand z (l | ptr (l)) updates reserve price ptr (l) usingformula:'(z (l | ptr (l))t+1pr (l) max r , pr (l) + pr (l)(15)s(l)r minimum reserve price, s(l) number vehicles intersectionmanager willing serve. Section 5.1, choose r = 0 s(l) = 0.5 opt $(l),$(l) length link l, opt density maximises traffic flowlink l (see Figure 10).5.2.2 Driver Modelempirically evaluate CA-CTA need define driver route choice model takesconsideration fact reservations allocated combinatorialauction reserve price. assume driver holds private valuationbids willing submit pass intersections chosen route, definedvariable b. Given monetary constraint, driver selects preferred route651fiVasirani & Ossowski, taking consideration estimated travel time associated route. routemodelled ordered list links, = [l1 . . . lN ], characterisedtwo attributes, namely estimated travel time reserve price.travel time estimation based, before, travel time free flow (Equation 5). reserve price link defined as:)pr (l)lk = l L(16)K(lk ) =0otherwiseprice link lk always 0, unless link lk one incoming link intersection(lk = l), case price equal reserve price ptr (l) establishedintersection manager. summatory travel time links givesestimated travel time free flow entire route :E[T ()] =N*E[T (lk )](17)k=1Given b, driver builds choice-set C set routes whose intersectionsreserve price lower desired bid b:,C = 1 , . . . , | K(lk ) b lkchoice-set built, driver selects shortest route = argmin E[T (i )].C5.2.3 Experimental Resultsrecreate typical high load situation, using network topology ODmatrix Figure 11 Table 2. interested two different types properties.one side must evaluate whether integrated management mechanism (trafficcontrol+traffic assignment) guarantees lower delays drivers submit higher bids(user optimum). purpose, calculate average (percentage) increasetravel times D, calculated according Equation 18, (i ) observed traveltime vehicle origin destination along route , mT travel timeorigin destination along shortest route vehicle couldcross intersection unhindered15 . simplicity, refer percentage increasetravel time normalised delay.D=(i ) mTmT(18)hand, would like set system fair entire populationdrivers, guaranteeing lower average delays (global optimum). Thus, compareintegrated mechanism network intersections governed intersection managersapply FCFS control policy. assume case drivers chooseshortest route origin destination, since incentives15. ratio enables us aggregate results drivers even though different origins and/ordestinations.652fiA Market-Inspired Approach Intersection Management140%Moving avg (min)Normalised delay25114.30%110%80%67.12%73.31%50%58.10%20%0-5050-100100-150150-200FCFSCA-CTACTA20151050%Bid (cents)20%40%60%80%100%Percentage completed trips(a)(b)Figure 13: Relation normalised delay bid (a) moving average traveltime (b)diverge route. aim evaluate global performance (in terms averagetravel time) integrated mechanism compared straightforward applicationFCFS policy network intersections, detect potential social cost similarreported Section 4.3. metrics use assess performanceaverage delay every O-D pair, moving average travel time. latterintended measure average travel time evolves simulation.metric initialised 0 calculated follows: driver concludes trip,travel time (i ) computed moving average travel time updated accordingEquation 19, n number drivers completed trips far.(i )(19)n+1following tables figures refer two configurations abbreviationsCA-CTA (which stands combinatorial auction-competitive traffic assignment)FCFS.Figure 13a plots relation bid value normalised delay populationdrivers16 . still possible appreciate inverse relation two quantities: drivers submit bids 150 200 cents reduce delay50% compared bid less 50 cents. Also network level, grantingreservations combinatorial auction (the CA component CA-CTA policy)ensures drivers submit higher bids experience lower delays (user optimum).assess social cost incurred CA-CTA global level, measure movingaverage travel time, is, average travel time entire populationdrivers, computed O-D pairs, evolves simulation. compare CACTA FCFS and, completeness, CTA17 . results, 95% confidence=T +16. error bars denote 95% confidence intervals.17. order evaluate CA-CTA CTA experimental conditions ran new setexperiments using CTA combination driver model detailed Section 5.2.2.653fiVasirani & OssowskiOriginCA-CTAO1 FCFS%CA-CTAO2 FCFS%CA-CTAO3 FCFS%CA-CTAO4 FCFS%CA-CTAO5 FCFS%CA-CTAO6 FCFS%CA-CTAO7 FCFS%DestinationO4O5O1O2O3-12.220.2611.980.31-2.0%-13.650.3122.891.1740.3%10.510.1416.501.0636.4%-12.160.2110.150.06-19.8%15.050.6913.350.09-12.7%20.791.2326.941.3122.8%24.591.1032.171.8323.6%25.081.5322.510.40-11.4%15.730.3214.310.10-9.9%12.510.629.760.03-28.2%18.450.9322.581.0618.3%20.821.2630.611.7032.0%26.720.4057.013.1353.1%24.180.5223.260.40-3.9%10.520.4113.920.8224.4%12.620.6321.541.3941.4%18.121.2641.052.5955.8%22.122.2856.423.0160.8%25.123.4035.131.8028.5%19.581.3825.871.5124.3%9.010.2212.210.6226.2%7.910.488.830.3110.4%15.781.3524.681.6236.1%26.862.5934.992.1523.2%27.132.0343.571.8937.7%24.171.7431.052.0322.1%13.270.4617.640.9224.8%7.320.1510.050.4827.2%10.850.2819.021.5042.9%16.810.9931.242.0646.2%O6O723.130.3421.350.40-8.3%26.540.6738.091.8230.3%18.720.6823.696.3421%13.021.0215.740.7317.3%10.010.2810.770.267.0%-13.750.1113.830.090.5%22.210.3719.510.15-13.8%26.761.0231.731.3615.7%23.121.5322.740.99-1.7%21.881.4117.660.52-23.9%14.550.6913.730.32-6.0%-11.430.2912.000.204.7%-Table 4: Average travel time minutes ( 95%CI): CA-CTA vs. FCFSinterval error bars, plotted Figure 13b. beginning, average travel timesimilar scenarios, number drivers populate network(i.e., load) increases, grows significantly faster FCFS CA-CTApolicy. terms average travel times CTA best performing policy. CA-CTAslightly inferior performance, enforce inverse relationship bid valuedelay (see Figure 13a). fact CA-CTA CTA outperforms FCFSindication that, general, traffic assignment strategy (the CTA componentpolicies) improves travel time. fact, FCFS drivers always select shortest654fiA Market-Inspired Approach Intersection Managementroute, cases best route choice. Furthermore, granting reservationsauction (the CA component CA-CTA policy) ensures bid valuedelay reduction correlated.Table 4 shows average travel time drivers, according O-D pairs,intersection managers use CA-CTA mechanism, compared FCFS policy.CA-CTA, net reduction average travel time 70%O-D pairs compared FCFS. Furthermore, 30 intersections CA-CTAoutperforms FCFS, relative improvement (%) usually substantialrelative losses remaining 12 intersections. travel time reduction particularlynoteworthy busy routes O6 -O2 , O6 -O3 O7 -O3 gains exceed 50%.O-D pairs CA-CTA performs worst (especially O5 -O7 O3 -O2 , losses20%) assignment strategy able sufficiently reduce demandintersection, thus considerably increasing travel time due social costcombinatorial auction.6. Conclusionsarticle studied distributed mechanism control managementfuture urban road network, intelligent autonomous vehicles, controlled drivers,interact infrastructure order travel links network. lastsection summarise discuss main contributions, propose future lineswork.first objective extension reservation-based intersection control system (Dresner & Stone, 2008). focused modelling policy relied theorycombinatorial auctions (Krishna, 2002) allocate reservations drivers. empirical experimentation, discovered combinatorial auction-based policy guaranteesreduced delay drivers value time most, i.e., submit higherbids. However, new policy showed paid social cost, term greater averagedelays, especially traffic demand high.second objective work go beyond single intersection setting,extending reservation-based model network intersections. Building findingsreported Vasirani Ossowski (2011), realised traffic assignment strategycould make task traffic control policy easier, better distributing traffic flownetwork. studied market-inspired traffic assignment strategy tackledproblem adaptation perspective. model, intersection managers behavedselfishly, competing others supply reservations intersections.experimental evaluation showed way available resources efficientlyallocated drivers, generating balanced network.Finally, combined competitive strategy traffic assignment auctionbased policy traffic control, order develop adaptive, market-inspired, mechanismtraffic management. demand-response pricing policy acted distributionvehicles network, adapting reserve price (i.e., minimum priceintersection manager willing sell) generating system dynamic equilibrium,unused intersections became cheaper highly demanded ones became expensive. demand particularly disputed intersections lowered reserve price655fiVasirani & Ossowskifluctuations, social cost auction-based control policy lowered (at intersection level). Therefore, homogeneous distribution vehicles network ledbetter use network resources, thus lower average travel times. way,entire population drivers rewarded lower average travel times and,time, traffic control policy enforced inverse relation bid value delay,rewarding drivers valued reservations reduced delays.future work, economic models implemented, continuous doubleauctions. Furthermore, work assumed driver decision making model exclusivelytook consideration route choice, modelled utility maximisationproblem. order capture inherent complexity urban traffic systems, importantextend enrich driver behavioural model. example, driver couldimplemented two layer decision maker, reactive, rule-based layer providesshort-term decisions car-following lane-changing, cognitive, BDI-style,layer charge making complex decisions route choice departuretime selection (Rossetti, Bampi, Liu, Vliet, & Cybis, 2000).Finally, article interactions vehicles infrastructure takeplace. Thus, collaboration possible vehicles. Nevertheless, vehicle-tovehicle communication receiving great attention scientific engineering community (Biswas, Tatchikou, & Dion, 2006). particular, vehicle-to-vehicle communicationcould used enrich action space driver, e.g. option dynamicallyjoining abandoning coalitions vehicles, based idea platoons (Varaiya, 1993).Acknowledgmentsresearch partially supported Spanish Ministry Science Innovationproject (CONSOLIDER CSD2007-0022, INGENIO 2010) OVAMAH(TIN2009-13839-C03-02, Plan E).ReferencesAdler, J. L., Satapathy, G., Manikonda, V., Bowles, B., & Blue, V. J. (2005). multiagent approach cooperative traffic management route guidance. TransportationResearch Part B - Methodological, 39, 297318.Bazzan, A. L. C., & Klugl, F. (Eds.). (2008). Multi-agent Architectures TrafficTransportation Engineering. IGI-Global.Biswas, S., Tatchikou, R., & Dion, F. (2006). Vehicle-to-vehicle wireless communication protocols enhancing highway traffic safety. IEEE Communications Magazine, 44 (1),7482.Choy, M. C., Srinivasan, D., & Cheu, R. L. (2003). Cooperative, hybrid agent architecturereal-time traffic control. IEEE Transactions Systems, Man, Cybernetics Part A, 33 (5), 597607.Clarke, E. H. (1971). Multipart pricing public goods. Public Choice, 11 (1), 1733.656fiA Market-Inspired Approach Intersection ManagementCodenotti, B., Pemmaraju, S., & Varadarajan, K. (2004). computation marketequilibria. SIGACT News, 35 (4), 2337.da Silva, B. C., Basso, E. W., Bazzan, A. L. C., & Engel, P. M. (2006). Dealingnon-stationary environments using context detection. Proceedings 23rd International Conference Machine Learning, pp. 217224. ACM.Dias, M. B., Zlot, R. M., Kalra, N., & Stentz, A. (2006). Market-based multirobot coordination: survey analysis. Proceedings IEEE, 94 (7), 12571270.Dresner, K., & Stone, P. (2008). multiagent approach autonomous intersection management. Journal Artificial Intelligence Research, 31, 591656.Gerding, E., McBurney, P., & Yao, X. (2010). Market-based control computationalsystems: Introduction special issue. Journal Autonomous Agents MultiAgent Systems, 21, 109114.Gerlough, D. L., & Huber, M. J. (1975). Traffic-flow theory. Transportation ResearchBoard.Gershenson, C. (2005). Self-organizing traffic lights. Complex Systems, 16, 2953.Groves, T. (1973). Incentives teams. Econometrica, 41 (4), 617631.Hensher, D. A., & Sullivan, C. (2003). Willingness pay road curviness road type.Transportation Research Part - Transport Environment, 8, 139155.Hernandez, J. Z., Ossowski, S., & Garca-Serrano, A. (2002). Multiagent architecturesintelligent traffic management systems. Transportation Research Part C - EmergingTechnologies, 10 (5), 473506.Hoos, H. H., & Boutilier, C. (2000). Solving combinatorial auctions using stochastic localsearch. Proceedings 17th National Conference Artificial Intelligence, pp.2229. AAAI Press.Hunt, P. B., Robertson, D. I., Bretherton, R. D., & Winton, R. I. (1981). Scoot-a traffic responsive method coordinating signals. Tech. rep., TRRL Lab. Report 1014,Transport Road Research Laboratory, Berkshire.Ioannou, P., & Chien, C. C. (1993). Autonomous intelligent cruise control. IEEE Transactions Vehicular Technology, 42 (4), 657672.Junges, R., & Bazzan, A. L. C. (2008). Evaluating performance dcop algorithmsreal world, dynamic problem. Proceedings 7th International Joint Conference Autonomous Agents Multi-Agent Systems, pp. 599606. InternationalFoundation Autonomous Agents Multiagent Systems.Krishna, V. (2002). Auction Theory. Academic Press.Krogh, B., & Thorpe, C. (1986). Integrated path planning dynamic steering controlautonomous vehicles. Proceedings IEEE International ConferenceRobotics Automation, pp. 16641669.Lammer, S., & Helbing, D. (2008). Self-control traffic lights vehicle flows urbanroad networks. Journal Statistical Mechanics: Theory Experiment, 2008 (04).657fiVasirani & OssowskiLeyton-Brown, K., Shoham, Y., & Tennenholtz, M. (2000). algorithm multi-unitcombinatorial auctions. Proceedings 17th National Conference ArtificialIntelligence, pp. 5661. AAAI Press.Meneguzzer, C. (1997). Review models combining traffic assignment signal control.Transportation Engineering, 123 (2), 148155.Nagel, K., & Schreckenberg, M. (1992). cellular automaton model freeway traffic.Journal de Physique I, 2 (12), 22212229.Ossowski, S., & Garca-Serrano, A. (1999). Social structure computational co-ordinationmechanism societies autonomous problem-solving agents. Intelligent AgentsV: Agents Theories, Architectures, Languages, Vol. 1555 Lecture Notes Computer Science, pp. 133148. Springer.Papageorgiou, M., Diakaki, C., Dinopoulou, V., Kotsialos, A., & Wang, Y. (2003). Reviewroad traffic control strategies. Proceedings IEEE, Vol. 91, pp. 20432067.IEEE.Robertson, D. I. (1969). Transyt: traffic network study tool. Tech. rep., Rep. LR 253,Road Res. Lab., London.Rossetti, R. J. F., Bampi, S., Liu, R., Vliet, D. V., & Cybis, H. B. B. (2000). agent-basedframework assessment drivers decision making. Proceedings 3rdIEEE Conference Intelligent Transportation Systems, pp. 387392.Roughgarden, T. (2003). price anarchy independent network topology.Journal Computer System Sciences, 67 (2), 341364.Sandholm, T. (2002). Algorithm optimal winner determination combinatorial auctions. Artificial Intelligence, 135 (1-2), 154.Schepperle, H., & Bohm, K. (2007). Agent-based traffic control using auctions. Cooperative Information Agents XI, Vol. 4676 Lecture Notes Computer Science, pp.119133. Springer.Schwerdtfeger, T. (1984). Dynemo: model simulation traffic flow motorwaynetworks. Proceedings 9th International Symposium TransportationTraffic Theory, pp. 6587. VNU Science Press.Small, K., & Verhoef, E. (2007). Economics Urban Transportation. Routledge.Steingrover, M., Schouten, R., Peelen, S., Nijhuis, E., & Bakker, B. (2005). Reinforcementlearning traffic light controllers adapting traffic congestion. Proceedings17th Belgium-Netherlands Conference Artificial Intelligence, pp. 216223.Treiber, M., Hennecke, A., & Helbing, D. (2000). Congested traffic states empiricalobservations microscopic simulations. Physical Review E, 62 (2), 18051824.van Katwijk, R. T., Schutter, B. D., & Hellendoorn, J. (2009). Multi-agent control trafficnetworks: Algorithm case study. Proceedings 12th International IEEEConference Intelligent Transportation Systems, pp. 316321.Varaiya, P. (1993). Smart cars smart roads: Problems control. IEEE TransactionsAutomatic Control, 38, 195207.658fiA Market-Inspired Approach Intersection ManagementVasirani, M., & Ossowski, S. (2009a). Evaluating policies reservation-based intersectioncontrol. Proceedings 14th Portuguese Conference Artificial Intelligence,pp. 3950.Vasirani, M., & Ossowski, S. (2009b). market-inspired approach reservation-based urban road traffic management. Proceedings 8th International Joint ConferenceAutonomous Agents Multiagent Systems, pp. 617624.Vasirani, M., & Ossowski, S. (2011). computational market distributed controlurban road traffic systems. IEEE Transactions Intelligent Transportation Systems,12, 313321.Vickrey, W. (1961). Counterspeculation, auctions, competitive sealed tenders. JournalFinance, 16, 837.Wiering, M. (2000). Multi-agent reinforcement learning traffic light control. Proceedings 17th European Conference Machine Learning, pp. 11511158.Wurman, P. R., Wellman, M. P., & Walsh, W. E. (2001). parametrization auctiondesign space. Games Economic Behavior, 35 (1-2), 304338.Yen, J. Y. (1971). Finding k shortest loopless paths network. Management Science,17 (11), 712716.Zutt, J., van Gemund, A., de Weerdt, M., & Witteveen, C. (2010). Dealing uncertainty operational transport planning. Intelligent Infrastructures, pp. 349375.Springer.659fiJournal Artificial Intelligence Research 43 (2012) 329-351Submitted 11/11; published 03/12Local Consistency SAT-SolversPeter JeavonsJustyna PetkePeter.Jeavons@cs.ox.ac.ukJustyna.Petke@cs.ox.ac.ukDepartment Computer Science, University OxfordWolfson Building, Parks Road, Oxford, OX1 3QD, UKAbstractLocal consistency techniques k-consistency key component specialisedsolvers constraint satisfaction problems. paper show powerusing k-consistency techniques constraint satisfaction problem precisely capturedusing particular inference rule, call negative-hyper-resolution, standarddirect encoding problem Boolean clauses. also show current clauselearning SAT-solvers discover expected polynomial time inconsistencydeduced given set clauses using negative-hyper-resolvents fixed size.combine two results show that, without explicitly designed so, currentclause-learning SAT-solvers efficiently simulate k-consistency techniques, fixed valuesk. give experimental results show feature allows clause-learningSAT-solvers efficiently solve certain families constraint problems challengingconventional constraint-programming solvers.1. IntroductionOne oldest central ideas constraint programming, going right backMontanaris original paper 1974, idea using local consistency techniques prunesearch space (Bessiere, 2006). idea arc-consistency introduced Mackworth(1977), generalised k-consistency Freuder (1978). Modern constraint solversgenerally employ specialised propagators prune domains variables achieveform generalised arc-consistency, typically attempt enforce higher levelsconsistency, path-consistency.contrast, software tools developed solve propositional satisfiability problems,known SAT-solvers, generally use logical inference techniques, unit propagationclause-learning, prune search space.One surprising empirical findings last years remarkably good performance general SAT-solvers solving constraint satisfaction problems.apply tools constraint satisfaction problem one first translate instance set clauses using form Boolean encoding (Tamura, Taga, Kitagawa,& Banbara, 2009; Walsh, 2000). encoding techniques tend obscure structure original problem, may introduce large number Boolean variablesclauses encode quite easily-stated constraints. Nevertheless, quite cases,approaches out-performed traditional constraint-solving tools (van Dongen,Lecoutre, & Roussel, 2008, 2009; Petke & Jeavons, 2009).c2012AI Access Foundation. rights reserved.fiJeavons & Petkepaper draw number recent analytical approaches try accountgood performance general SAT-solvers many forms constraint problems.Building results Atserias, Bulatov, Dalmau (2007), Atserias Dalmau(2008), Hwang Mitchell (2005), show power using k-consistencytechniques constraint problem precisely captured using single inference rulestandard Boolean encoding problem. refer inference rule negativehyper-resolution, show conclusions deduced enforcing k-consistencydeduced sequence negative-hyper-resolution inferences involving Boolean clausesoriginal instance negative-hyper-resolvents k literals. Furthermore,using approach Atserias, Fichte, Thurley (2011), PipatsrisawatDarwiche (2009), show current clause-learning SAT-solvers mimic effectdeductions polynomial expected time, even random branching strategy. Henceshow that, although explicitly designed so, running clause-learningSAT-solver straightforward encoding constraint problem efficiently simulateseffects enforcing k-consistency values k.2. Preliminariessection give background definitions used throughoutrest paper.2.1 Constraint Satisfaction Problems k-ConsistencyDefinition 1 instance Constraint Satisfaction Problem (CSP) specifiedtriple (V, D, C),V finite set variables;= {Dv | v V } set Dv set possible values variable v,called domain v;C finite set constraints. constraint C pair (Ri , Si )Si ordered list mi variables, called constraint scope;Ri relation arity mi , called constraint relation.Given CSP instance (V, D, C), partial assignment mapping fsubset W V Dv f (v) Dv v W . partial assignment satisfiesconstraints instance if, (R, (v1 , v2 , . . . , vm )) C vj Wj = 1, 2, . . . , m, (f (v1 ), f (v2 ) . . . , f (vm )) R. partial assignment satisfiesconstraints instance called partial solution1 instance. setvariables partial assignment f defined called domain f , denotedDom(f ). partial solution g extends partial solution f Dom(g) Dom(f )g(v) = f (v) v Dom(f ). partial solution domain V called solution.One way derive new information CSP instance, may help determinewhether solution, use form constraint propagation enforce1. Note partial solutions extend solutions.330fiLocal Consistency SAT-Solverslevel local consistency (Bessiere, 2006). example, possible use notionk-consistency, defined below. note several different equivalent waysdefine enforce k-consistency described literature (Bessiere, 2006; Cooper, 1989;Freuder, 1978). presentation follows Atserias et al. (2007), inspirednotion existential k-pebble games introduced Kolaitis Vardi (2000).Definition 2 (Atserias et al., 2007) CSP instance P , k-consistency closureP set H partial assignments obtained following algorithm:1. Let H collection partial solutions f P |Dom(f )| k + 1;2. every f H |Dom(f )| k every variable v P , g Hg extends f v Dom(g), remove f extensions H;3. Repeat step 2 H unchanged.Note computing k-consistency closure according definition correspondsprecisely enforcing strong (k+1)-consistency according definitions given Bessiere(2006), Cooper (1989), Freuder (1978).Throughout paper, shall assume domain possible valuesvariable CSP instance finite. straightforward show fixed k,fixed maximum domain size, k-consistency closure instance Pcomputed polynomial time (Atserias et al., 2007; Cooper, 1989).Note solution P must extend element k-consistency closureP . Hence, k-consistency closure P empty, k, P solutions.converse true general, holds certain special cases, classinstances whose structure tree-width bounded k (Atserias et al., 2007), classinstances whose constraint relations 0/1/all relations, defined Cooper, Cohen,Jeavons (1994), connected row-convex relations, defined Deville, Barette,Hentenryck (1997). special kinds instances possible determinepolynomial time whether solution exists simply computing k-consistencyclosure, appropriate choice k. Moreover, solution exists,constructed polynomial time selecting variable turn, assigning possiblevalue, re-computing k-consistency closure, retaining assignment givesnon-empty result.following result gives useful condition determining whether k-consistencyclosure CSP instance empty.Lemma 1 (Kolaitis & Vardi, 2000) k-consistency closure CSP instance Pnon-empty exists non-empty family H partial solutions Pthat:1. f H, |Dom(f )| k + 1;2. f H f extends g, g H;3. f H, |Dom(f )| k, v/ Dom(f ) variable P ,g H g extends f v Dom(g).set partial solutions H satisfying conditions described Lemma 1 sometimescalled strategy instance P (Barto & Kozik, 2009; Kolaitis & Vardi, 2000).331fiJeavons & Petke2.2 Encoding CSP Instance Propositional FormulaOne possible approach solving CSP instance encode propositional formulasuitable set Boolean variables, use program decide satisfiabilityformula. Many programs, known SAT-solvers, availableoften efficiently handle problems thousands, sometimes even millions, Booleanvariables (Zhang & Malik, 2002).Several different ways encoding CSP instance propositional formulaproposed (Prestwich, 2009; Tamura et al., 2009; Walsh, 2000).consider one common family encodings, known sparse encodings (this termintroduced Hoos, 1999). CSP instance P = (V, D, C), sparse encodingintroduces set Boolean variables form xvi v V Dv .Boolean variable xvi assigned True original variable v assignedvalue i. say partial assignment f falsifies clause C C consists entirelyliterals form xvf (v) , variables v Dom(f ). Otherwise, say partialassignment f satisfies clause C.Example 1 Let P CSP instance V = {u, v, w}, Du = Dv = {0, 1}, Dw ={0, 1, 2} C contains single ternary constraint scope (u, v, w) specifyingu v < w. sparse encoding P introduce seven Boolean variables:xu0 , xu1 , xv0 , xv1 , xw0 , xw1 , xw2 .Sparse encodings usually contain certain clauses known at-least-one at-most-oneclauses, ensure variable v assigned value, say i, value,Wj 6= i, assigned v. at-least-one clauses form iDv xvi variablev. at-most-one clauses represented set binary clauses xvi xvji, j Dv 6= j.Example 2 case CSP instance Example 1 at-least-one clauses are:xu0 xu1 , xv0 xv1 , xw0 xw1 xw2at-most-one clauses are:xu0 xu1 , xv0 xv1 , xw0 xw1 , xw0 xw2 , xw1 xw2various different sparse encodings differ way encode constraintsCSP instance. Two methods commonly used. first one encodes disallowedvariable assignments - so-called conflicts no-goods. direct encoding (Prestwich,W2009), instance, generates clause vS xvf (v) partial assignment fsatisfy constraint (R, S) C. Using direct encoding, ternary constraintExample 1 would encoded following clauses:xu0 xv0 xw0 ,xu0 xv1 xw0 ,xu0 xv1 xw1 ,xu1 xv0 xw0 ,332fiLocal Consistency SAT-Solversxu1 xv0 xw1 ,xu1 xv0 xw2 ,xu1 xv1 xw0 ,xu1 xv1 xw1 .Another way translating constraints clauses encode allowed variableassignments - so-called supports. used basis encodingbinary CSP instances, known support encoding (Gent, 2002), defined follows.pair variables v, w scope constraint, value Dv ,Wsupport encoding contain clause xvi jA xwj , Dw setvalues variable w compatible assignment v = i, accordingconstraint.Note support encoding defined binary CSP instances only. However,non-binary constraints decomposed binary ones without introducing newvariables. instance, ternary constraint Example 1 decomposed twobinary constraints specifying u v v < w. Using support encoding,binary constraints would represented following clauses:xu0 xv0 xv1 , xu1 xv1 , xv0 xu0 , xv1 xu0 xu1 ,xv0 xw1 xw2 , xv1 xw2 , xw0 , xw1 xv0 , xw2 xv0 xv1 .2.3 Inference RulesGiven set clauses often deduce clauses applying certain inferencerules. example, two clauses form C1 x C2 x, (possiblyempty) clauses C1 , C2 , variable x, deduce clause C1 C2 .form inference known propositional resolution; resultant clause calledresolvent (Robinson, 1965).next section, shall establish close connection k-consistencyalgorithm form inference called negative-hyper-resolution (Buning & Lettmann,1999), define follows:Definition 3 collection clauses form Ci xi , = 1, 2, . . . , r,clause C0 x1 x2 xr , xi Boolean variable, C0Ci (possibly empty) disjunction negative literals, deduce clauseC0 C1 Cr .call form inference negative-hyper-resolution resultant clauseC0 C1 Cr negative-hyper-resolvent.case C0 empty, negative-hyper-resolution rule equivalentnogood resolution rule described Hwang Mitchell (2005) well H5-k ruleintroduced de Kleer (1989) nogood recording scheme described SchiexVerfaillie (1993).Note inference obtained negative-hyper-resolution also obtainedsequence standard resolution steps. However, reason introducing negative-hyperresolution allows us deduce clauses need single step without needingintroduce intermediate clauses (which may contain r 1 literals333fiJeavons & Petkenegative-hyper-resolvent). restricting size clauses use wayable obtain better performance bounds SAT-solvers results below.Example 3 Assume collection clauses form Ci xi , = 1, 2, . . . , r,clause C0 x1 x2 xr , specified Definition 3, Ci = C0 .negative-hyper-resolvent set clauses C0 .clause C0 also obtained sequence standard resolution steps, follows.First resolve C0 x1 x2 xr C0 xr obtain C0 x1 x2 xr1 .resolve next clause, C0 xr1 , clauses, finallyobtain C0 . However, case intermediate clause C0 x1 x2 xr1 containsr 1 literals negative-hyper-resolvent.Example 4 Note no-good clauses direct encoding binary CSP instanceobtained single negative-hyper-resolution step appropriate supportclause support encoding together appropriate collection at-most-one clauses.Let Dw set values variable w compatible assignmentWv = i, support encoding contain clause C = xvi jA xwj .values k Dw incompatible assignment v = i, formnegative-hyper-resolvent C at-most-one clauses xwk xwj j A,obtain corresponding no-good clause, xvi xwk .negative-hyper-resolution derivation clause C set initial clausessequence clauses C1 , C2 , . . . , Cm , Cm = C Ci follows negativehyper-resolution rule collection clauses, either containedelse occurs earlier sequence. width derivation definedmaximum size clauses Ci . Cm empty clause, sayderivation negative-hyper-resolution refutation .3. k-Consistency Negative-Hyper-Resolutionpointed many authors enforcing local consistency forminference relations analogous use resolution rule clauses (Bacchus, 2007;Bessiere, 2006; Hwang & Mitchell, 2005; Rish & Dechter, 2000). precise strengthstandard resolution inference rule direct encoding CSP instance consideredwork Walsh (2000), shown unit resolution (where oneclauses resolved consists single literal), corresponds enforcing weak formlocal consistency known forward checking. Hwang Mitchell (2005) pointedstandard resolution rule restriction clause length able simulateinferences made k-consistency algorithm. Atserias Dalmau (2008) showedstandard resolution rule restricted clauses k literals, known kresolution rule, characterised terms Boolean existential (k +1)-pebble game.follows CSP instances Boolean domains form inference correspondsenforcing k-consistency. alternative proof k-resolution achieves k-consistencyinstances Boolean domains given book Hooker (2006, Thm. 3.22).extend results little, show CSP instances arbitraryfinite domains, applying negative-hyper-resolution rule direct encoding obtain334fiLocal Consistency SAT-Solversclauses k literals corresponds precisely enforcing k-consistency. similarrelationship stated work de Kleer (1989), complete proof given.Note bound, k, impose size negative-hyper-resolvents,independent domain size. words, using inference rule needconsider inferred clauses size k, even though make use clausesencoding whose size equal domain size, may arbitrarily large.Theorem 1 k-consistency closure CSP instance P empty directencoding set clauses negative-hyper-resolution refutation width k.proof broken two lemmas inspired Lemmas 2 3 workAtserias Dalmau (2008).Lemma 2 Let P CSP instance, let direct encoding set clauses.negative-hyper-resolution refutation width k less, k-consistencyclosure P non-empty.Proof. Let V set variables P , v V domain Dv , letX = {xvi | v V, Dv } corresponding set Boolean variables . Letset clauses negative-hyper-resolution derivation width k.definition negative-hyper-resolution, every non-empty clause consists entirelynegative literals.let H set partial assignments P domain size k + 1falsify clause direct encoding.Consider element f H. definition H, f falsify clause, definition direct encoding, every element H partial solutionP . Furthermore, f extends g, g also element H, g makes fewerassignments f hence cannot falsify additional clauses f .negative-hyper-resolution refutation width k,contain empty clause, H contains (at least) partial solution empty domain,hence H empty.let f element H |Dom(f )| k let v variable PDom(f ). partial assignment g extends f Dom(g) =Dom(f ) {v} either g H else exists clausefalsified g. Since g partial assignment, clause C falsified g,must consist entirely negative literals. Hence literals C must either formxwf (w) w Dom(f ), else xvg(v) . Moreover, clause must containliteral xvg(v) , else would already falsified f .Assume, contradiction, H contain assignment g extends fDom(g) = Dom(f ) {v}. case, that, Dv , containsclause Ci consisting negative literals form xwf (w) w Dom(f ), togetherliteral xvi . consider clause, C, negative-hyper-resolventWclauses Ci at-least-one clause iDv xvi . clause C consists entirelynegative literals form xwf (w) w Dom(f ), width|Dom(f )| k, hence element . However C falsified f , contradictschoice f . Hence shown f H |Dom(f )| k,335fiJeavons & Petkevariables v v 6 Dom(f ), g H g extends fv Dom(g).shown H satisfies conditions required Lemma 1, concludek-consistency closure P non-empty.2Lemma 3 Let P CSP instance, let direct encoding set clauses.k-consistency closure P non-empty, negative-hyper-resolutionrefutation width k less.Proof. Let V set variables P , v V domain Dv , letX = {xvi | v V, Dv } corresponding set Boolean variables .Lemma 1, k-consistency closure P non-empty, exists nonempty set H partial solutions P satisfies three properties describedLemma 1.consider negative-hyper-resolution derivation width k.show induction length derivation elements H falsifyclause derivation. First note elements H partial solutions,satisfy constraints P , hence falsify clause . establishesbase case. Assume, induction, clauses derivation earlierclause C falsified element H.Note that, apart at-least-one clauses, clauses consist entirelynegative literals. Hence may assume, without loss generality, C negativehyper-resolvent set clauses = {Ci xvi | Dv } at-least-one clauseWiDv xvi , fixed variable v.f H falsifies C, literals C must form xwf (w) ,w Dom(f ). Since width derivation k, C contains k literals,hence may assume |Dom(f )| k. then, choice H, mustexist extension g f H v Dom(g). g falsifyclause , contradicts inductive hypothesis. Hence f H falsifies C, and,particular, C cannot empty.follows negative-hyper-resolution derivation width k containempty clause.2Note proof Theorem 1 applies sparse encoding containsat-least-one clauses variable, clauses purely negative.call encoding negative sparse encoding. well direct encoding,negative sparse encodings exist. example, may use negative clauses involvesubset variables scope constraints (to forbid tuples possibleextensions complete scope disallowed constraint). Another examplenegative sparse encoding well-known variant direct encodingat-most-one clauses omitted.Corollary 1 k-consistency closure CSP instance P emptynegative sparse encoding P negative-hyper-resolution refutation width k.336fiLocal Consistency SAT-Solvers4. Negative-Hyper-Resolution SAT-Solverssection adapt machinery Atserias et al. (2011), PipatsrisawatDarwiche (2009) show fixed k, existence negative-hyper-resolutionrefutation width k likely discovered SAT-solver polynomial-time usingstandard clause learning restart techniques, even totally random branchingstrategy.Note previous results power clause-learning SAT-solvers generallyassumed optimal branching strategy (Beame, Kautz, & Sabharwal, 2004; Pipatsrisawat& Darwiche, 2009) - shown solvers potentially capable doing, ratherlikely achieve practice. important exception paperAtserias et al. (2011), gives analysis likely behaviour, reliesexistence standard resolution proof bounded width. show resultsAtserias et al. extended hyper-resolution proofs, shorternarrower associated standard resolution proofs.make use following terminology Atserias et al. (2011). clauseC, Boolean variable x, truth value {0, 1}, restriction C assignmentx = a, denoted C|x=a , defined constant 1, assignment satisfies clause,else clause obtained deleting C literals involving variable x.sequence assignments form (x1 = a1 , x2 = a2 , . . . , xr = ar ) write C|Sdenote result computing restriction C assignment turn. C|Sempty, say assignments falsify clause C. set clauses ,write |S denote set {C|S | C } \ {1}.current SAT-solvers operate following way (Atserias et al., 2011; Pipatsrisawat & Darwiche, 2009). maintain database clauses current stateS, partial assignment truth values Boolean variables clauses. high-level description algorithms used update clause databasestate, derived description given Atserias et al., shown Algorithm 1 (a similar framework, using slightly different terminology, given Pipatsrisawat & Darwiche,2009).consider run algorithm shown Algorithm 1, started initialdatabase , empty state S0 , either halts discovers conflict (i.e., |S ).run called complete round started , represent sequencestates S0 , . . . , Sm , algorithm maintains. Note state Si extendsstate Si1 single assignment Boolean variable, may either decisionassignment implied assignment.generally, round initial segment S0 , S1 , . . . , Sr complete round started, state Sr either |Sr contains empty clause, |Srcontain unit clause. clause C, say round S0 , S1 , . . . , Sr satisfies CC|Sr = 1, say round falsifies C C|Sr empty.S0 , S1 , . . . , Sr round started , |Sr contains empty clause,algorithm either reports unsatisfiability learns new clause: round calledconclusive. round conclusive call inconclusive 2 . Note S0 , S1 , . . . , Srinconclusive round started , |Sr contain empty clause,2. Note complete round assigns variables reports satisfiability called inconclusive.337fiJeavons & Petkecontain unit clauses. Hence, clause C , Sr falsifiesliterals C except one, must satisfy remaining literal, hence satisfy C.property clauses captured following definition.Definition 4 (Atserias et al., 2011) Let set clauses, C non-empty clause,l literal C. say absorbs C l every inconclusive round startedfalsifies C \ {l} satisfies C.absorbs C literal l C, simply say absorbs C.Note closely related notion introduced Pipatsrisawat Darwiche (2009)clauses absorbed set clauses ; referred 1-empoweringrespect . (The exact relationship 1-empowering absorption discussedAtserias et al., 2011.)explore relationship absorption negative-hyper-resolution.Example 5 Let direct encoding CSP instance P = (V, D, C), V ={u, v, w}, Du = Dv = Dw = {1, 2} C contains two binary constraints: one forbidsassignment value 1 u v simultaneously, forbids simultaneousassignment value 2 u 1 w. Let C also contain ternary constraintforbids assignment value 2 three variables simultaneously.= { xu1 xu2 , xv1 xv2 , xw1 xw2 ,xu1 xu2 , xv1 xv2 , xw1 xw2 ,xu1 xv1 , xu2 xw1 , xu2 xv2 xw2 }.clause xv1 xw1 contained , obtained negative-hyperresolution clauses xu1 xu2 , xu1 xv1 , xu2 xw1 .clause absorbed , since every inconclusive round sets xv1 = true mustset xw1 = f alse unit propagation, every inconclusive round sets xw1 = truemust set xv1 = f alse also unit propagation.Example 5 indicates clauses obtained negative hyper-resolutionset clauses sometimes absorbed . next result clarifies situationholds.Lemma 4 negative-hyper-resolvent set disjoint clauses absorbed setclauses.Proof. Let C negative-hyper-resolvent set clauses = {Ci xi | =1, 2, . . . , r} clause C 0 = C0 x1 x2 xr , Ci (possibly empty)disjunction negative literals, 0 r. C = C0 C1 Cr Definition 3.Definition 4, must show C 0 absorbs C literals. Assumeone literals C falsified. Since set clauses C 0 assumeddisjoint, remaining literal l must belong exactly one clauses set.two cases consider.1. l belongs clause C 0 , clauses one literals falsified,remaining literal xi clauses set true, unit propagation.Hence literals C 0 falsified, except l, l set true, unit propagation.338fiLocal Consistency SAT-Solvers2. l belongs one clauses Ci xi , remaining clausesone literals falsified, corresponding literals xj set true, unitpropagation. Hence literals C 0 falsified, except xi , xi set true,unit propagation. literals Ci xi falsified, except l, l settrue unit propagation.2next example shows negative-hyper-resolvent set clausesdisjoint necessarily absorbed clauses.Example 6 Recall set clauses given Example 5, direct encodingCSP instance three variables {u, v, w}, domain {1, 2}.clause xu2 xv2 contained , obtained negative-hyperresolution clauses xw1 xw2 , xu2 xv2 xw2 , xu2 xw1 .clause absorbed , since inconclusive round sets xv2 = truenecessarily ensure xu2 = f alse unit propagation.basic approach shall use establish main results showclauses obtained bounded width negative-hyper-resolution given setclauses, immediately absorbed (such one Example 6) likelybecome absorbed quite quickly additional clauses addedprocess clause learning. Hence clause-learning SAT-solver likely fairly rapidlyabsorb clauses derived original database clauses negativehyper-resolution. particular, empty clause derived negative-hyperresolution, solver fairly rapidly absorb literal complement,hence report unsatisfiability (see proof Theorem 2 details).following key properties absorption established Atserias et al. (2011).Lemma 5 (Atserias et al., 2011) Let 0 sets clauses, let C C 0non-empty clauses.1. C belongs , absorbs C;2. C C 0 absorbs C, absorbs C 0 ;3. 0 absorbs C, 0 absorbs C.allow analysis, need make assumptions learning scheme,restart policy branching strategy used SAT-solver.learning scheme rule creates adds new clause databasewhenever conflict. clause called conflict clause, literalsfalsified assignment current state. literal falsified i-th decisionassignment, later implied assignment (i + 1)-th decision assignment,said falsified level i. conflict clause contains exactly one literal falsifiedmaximum possible level, called asserting clause (Pipatsrisawat & Darwiche,2009; Zhang, Madigan, Moskewicz, & Malik, 2001).Assumption 1 learning scheme chooses asserting clause.339fiJeavons & PetkeAlgorithm 1 Framework typical clause-learning SAT-solverInput: : set clauses;: partial assignment truth values variables.1.2.3.4.5.6.7.8.9.10.11.12.13.14.15.16.17.18.19.20.21.|S 6=|SConflictcontains decision assignmentsprint UNSATISFIABLE haltelseapply learning scheme add new clauserestart policy says restartset =elseselect recent conflict-causing unreversed decision assignmentreverse decision, remove later assignmentsendendelse {l} |S literal lUnit Propagationadd implied assignment x = satisfies lelseDecisionapply branching strategy choose decision assignment x =add decision assignmentendendprint SATISFIABLE outputlearning schemes current use satisfy assumption (Pipatsrisawat & Darwiche, 2009; Zhang et al., 2001), including learning schemes called 1UIP Decision (Zhang et al., 2001).make particular assumption restart policy. However, main resultphrased terms bound expected number restarts. algorithm restartsr conflicts, bound expected number restarts simply multipliedr get bound expected number conflicts. means resultsstrongest algorithm restarts immediately conflict. case,r = 1 bound also bound expected number conflicts. Existing SATsolvers typically employ aggressive restart policy, note remarkwork Pipatsrisawat Darwiche (2009, p.666) clear trendtowards frequent restarts modern SAT solvers.branching strategy determines decision assignment chosen inconclusive round complete. current SAT solvers strategy basedheuristic measure variable activity, related occurrence variableconflict clauses (Moskewicz, Madigan, Zhao, Zhang, & Malik, 2001). However, simplifyprobabilistic analysis, make following assumption.340fiLocal Consistency SAT-SolversAssumption 2 branching strategy chooses variable uniformly random amongstunassigned variables, assigns value TRUE.noted Atserias et al. (2011), analysis give also appliedbranching strategy randomly chooses making heuristic-baseddecision randomly-based decision. precisely, allow, say, c > 1 rounds nonrandom decisions random ones, number required restarts conflictswould appear multiplied factor c.algorithm behaves according description Algorithm 1, satisfiesassumptions above, called standard randomised SAT-solver.Theorem 2 set non-empty clauses n Boolean variables negativehyper-resolution refutation width k length m, expected number restartsrequiredby standard randomised SAT-solver discover unsatisfiable lessmnk 2 nk .Proof. Let C1 , C2 , . . . , Cm negative-hyper-resolution refutation width k ,Cm first occurrence empty clause. Since clause non-empty,Cm must derived negative-hyper-resolution collection negative literalsx1 , x2 , . . . xd purely positive clause x1 x2 xd .consider standard randomised SAT-solver started database .unit clauses xi absorbed current database, then, Definition 4,inconclusive round algorithm must assign variables xi false, hence falsifyclause x1 x2 xd . Since happens even decision assignments made,SAT-solver report unsatisfiability.remains bound expected number restarts required clauseCi absorbed, 1 < m. Let Ci negative-hyper-resolvent clauses0 x , together clause C = C x x xCi1 , Ci2 , . . . , Cir , form Cijji0012r, C0 (possibly empty) disjunction negative literals. Assume alsoclause Cij absorbed j = 0, 1, . . . , r.absorbs Ci , learning restarts needed, assumeabsorb Ci . Definition 4, means exists literal linconclusive round R started falsifies Ci \ {l} satisfy Ci . NoteR must leave literal l unassigned, one assignment would satisfy Ci0 , hence force literals x usedwould falsify C0 Cijjnegative-hyper-resolution step satisfied, Cij absorbed , Ci0would falsified, contradicting fact R inconclusive.Hence, branching strategy chooses falsify literals Ci \ {l} wheneverchoice, construct inconclusive round R0 l unassigned (sincedecision assignments R0 also assigned values R, implied assignmentsR0 must also assigned values3 R, shown R leaves lunassigned). branching strategy chooses falsify remaining literal l Ci ,algorithm would construct conclusive round R00 Ci0 falsified,3. See Lemmas 5, 8 10 work Atserias et al. (2011) formal statement proofassertion.341fiJeavons & Petkedecision assignments falsify literals Ci . Hence, Assumption 1, algorithm wouldlearn asserting clause C 0 add obtain new set 0 .Since C 0 asserting clause, contains exactly one literal, l0 , falsifiedhighest level R00 . Hence, inconclusive round R started 0 falsifies Ci \ {l}falsify one literal C 0 , hence force remaining literal l0 satisfied,unit propagation. new implied assignment l0 propagates force l true,R satisfies Ci , hence 0 absorbs Ci l. not, branching strategychoose falsify remaining literal l Ci , cause new assertingclause learned added . Since new asserting clause forces new literalsatisfied falsifying Ci \ {l} process repeated fewer n timescertain 0 absorbs Ci l.consider sequence k random branching choices. first k 1falsify literal Ci \ {l}, final choice falsifies l, shownassociated round reach conflict, add asserting clause . randombranching strategy, described Assumption 2, probability happensleast probability first k 1 random choices consist fixed set variables(in order), final choice variable associated l. numberrandom choices fall fixed set follows hypergeometric distribution, overall1probability n1 (nk+1)= 1/(k nk ).(k1)obtain upper bound expected number restarts, consider worst caserequire n asserting clauses added absorb clause Ci kliterals l. Since require upper bound,treat round independentntrial success probability p = 1/(k k ), consider worst caseachieve (m 1)nk successes ensure Ci 1 < absorbed. casetotal number restarts follow negative binomial distribution, expected value(m 1)nk/p. Hence cases expected number restarts less mnk 2 nk . 2tighter bound number restarts obtained focus Decisionlearning scheme (Atserias et al., 2011; Zhang et al., 2001), next result indicates.Theorem 3 set non-empty clauses n Boolean variables negative-hyperresolution refutation width k length m, expected number restarts requiredstandard randomised SAT-solverusing Decision learning scheme discoverunsatisfiable less nk .Proof. proof similar proof Theorem 2, except Decision learning scheme additional feature literals chosen conflict clause falsifysubset current decision assignments. Hence situation consider,decision assignments falsify literals clause Ci , learning scheme learnsubset Ci , hence immediately absorb Ci , Lemma 5 (1,2). Hence maximumnumber learnt clausesrequiredreduced (m 1)nk (m 1), probabilityincreased 1/(k nk ) 1/ nk , giving tighter bound.2Note similar argument shows standard deviation number restartsless standard deviation negative binomial distribution parameters342fiLocal Consistency SAT-Solvers1/ nk , less nk . Hence, Chebyshevs inequality (one-tailed version),probability standard randomised SAT-solver using decision learning schemediscover unsatisfiable (m + m) nk restarts greater 1/2.5. k-Consistency SAT-Solverscombining Theorem 1 Theorem 3 obtain following result linking k-consistencySAT-solvers.Theorem 4 k-consistency closure CSP instance P empty, expectednumber restarts required standard randomised SAT-solver using Decision learning scheme discover direct encoding P unsatisfiable O(n2k d2k ), nnumber variables P maximum domain size.Proof. length negative-hyper-resolution refutation width k boundedPknnumber possible no-goods lengthkP,i=1 . Hence,Theorem 1 Theorem 3 obtain boundni=1Pkndk ,O(n2k d2k ). 2Hence standard randomised SAT-solver suitable learning strategy decidesatisfiability CSP instance tree-width k O(n2k d2k ) expected restarts,even set restart immediately conflict. particular, satisfiabilitytree-structured binary CSP instance (i.e., tree-width 1) decidedsolver O(n2 d2 ) expected conflicts, comparable growth rateoptimal arc-consistency algorithm binary constraints. Note result cannotobtained directly work Atserias et al. (2011), direct encodinginstance tree-width k set clauses whose tree-width may high dk.Moreover, standard randomised SAT-solver decide satisfiability CSPinstance, structure, within polynomial bounds, constraint relationssatisfy certain algebraic properties ensure bounded width (Barto & Kozik, 2009).Examples constraint types include 0/1/all relations, defined Cooper et al.(1994), connected row-convex relations, defined Deville et al. (1997),decided 2-consistency.shown Gent (2002) support encoding binary CSP instancemade arc-consistent (that is, 1-consistent) applying unit propagation alone. Hence,standard SAT-solver mimic effect enforcing arc-consistency encodingmaking decisions restarts. combining Theorem 4 observationExample 4 direct encoding obtained support encoding negativehyper-resolution, obtain following corollary concerning support encodinghigher levels consistency.Corollary 2 k 2, k-consistency closure binary CSP instance Pempty, expected number restarts required standard randomised SATsolver using Decision learning scheme discover support encoding Punsatisfiable O(n2k d2k ), n number variables P maximumdomain size.343fiJeavons & PetkeCSP literature describes many variations notion consistency.paper considered k-consistency only. note results generalisedtypes consistency singleton arc-consistency (Bessiere, 2006).extension singleton arc-consistency follows recent discovery familyCSP instances solvable enforcing singleton arc-consistency, instancesbounded width (Chen, Dalmau, & Gruien, 2011). words, instancessolved enforcing k-consistency, fixed k. Hence, Theorem 4,solved polynomial expected time standard randomised SAT-solver.6. Experimental Resultspolynomial upper bounds obtain paper asymptotic, applyvalues n, k. However, conservative, likely meteasily practice.investigate existing SAT-solver actually performs, measured runtimeMiniSAT solver (Een & Sorensson, 2003), version 2.2.0, family CSP instancesdecided fixed level consistency. comparison, also ran experiments two state-of-the-art constraint solvers: used Minion (Gent, Jefferson, &Miguel, 2006), version 0.12, G12 finite domain solver (Nethercote et al., 2007),version 1.4.match simplified assumptions analysis closely, ranset experiments core version MiniSAT order get solver usesunit propagation conflict-directed learning restarts. also modified solverfollow random branching strategy described above. solver delete learntclauses uses extreme restart policy makes restart whenever encountersconflict. uses learning scheme MiniSAT. refer modified solversimple-MiniSAT.characteristic feature instances tested relatively low tree-width,also used Toulbar2 solver (Sanchez et al., 2008). solver implements BTD(Backtracking Tree-Decomposition) technique shown efficientpractice, contrast earlier methods proposed attempt exploittree-decompositions input problem (Jegou & Terrioux, 2003). problemfinding tree-decomposition minimal width (i.e., tree-width) NP-hard, BTDtechnique uses approximations (described Jegou & Terrioux, 2003). noteToulbar2 designed solving optimization problems, namely weighted CSPs,WCSPs. WCSP instance, certain partial assignments associated cost. However,Toulbar2 solver used solve standard CSPs simply setting costs 0.results, times given elapsed times Lenovo 3000 N200 laptopIntel Core 2 Duo processor running 1.66GHz 2GB RAM. generatedinstance run five times mean times mean number restarts shown4 .Example 7 consider family instances specified two parameters, w d.((d1)w+2)w variables arranged groups size w, domain {0, ..., d1}.4. MiniSAT simple-MiniSAT run different seeds five runs instance.Instances marked * run only. runtime simple-MiniSAT instancesexceeded 6 hours. Moreover, Toulbar2 run parameter B = 1 enables BTD.344fiLocal Consistency SAT-Solversimpose constraint arity 2w pair successive groups, requiringsum values assigned first two groups strictly smallersum values assigned second. ensures instances generatedunsatisfiable. instance w = 2 = 2 shown diagrammatically definedusing specification language MiniZinc (Nethercote et al., 2007) Figure 1 (a) (b)respectively5 . similar format used Toulbar2 6 instance encodedformat shown Figure 1 (c) (note hard constraint cost 0).(a) Graphical representation.chainx1 0 1x2 0 1x3 0 1x4 0 1x5 0 1x6 0 1x7 0 1x8 0 1hard( x1 + x2 < x3 + x4 )hard( x3 + x4 < x5 + x6 )hard( x5 + x6 < x7 + x8 )array[1..4] var 0..1 : X1;array[1..4] var 0..1 : X2;constraintforall(i 1..3)(X1[i] + X2[i] < X1[i + 1] + X2[i + 1]);solve satisfy;(b) Specification MiniZinc.(c) Specification cp format.Figure 1: example CSP instance w = 2, = 2 tree-width = 3.structure instances described Example 7 simple tree-decompositionpath nodes, node corresponding constraint scope. Hence tree-widthinstances 2w 1 shown unsatisfiable enforcing (2w 1)consistency (Atserias et al., 2007). However, instances cannot solved efficientlyusing standard propagation algorithms prune individual domain values.structure direct encoding instances also tree-decompositionnode corresponding constraint scope original CSP instance. However,direct encoding introduces Boolean variables represent variable5. order run instance CP solver one must usually use translator convert originalmodel. MiniZinc distribution provides mzn2fzn translator Minion one use Tailor(available http://www.cs.st-andrews.ac.uk/andrea/tailor/).6. cp2wcsp translator description cp wcsp formats availablehttp://carlit.toulouse.inra.fr/cgi-bin/awki.cgi/SoftCSP.345fiJeavons & Petkeoriginal instance, tree-width encoded SAT instances larger approximatelyfactor d; fact 2wd 1 (see Figure 2).(a) Tree-decomposition original instance.(b) Tree-decomposition directencoding.Figure 2: Tree-decompositions CSP instance Figure 1.Table 1 shows runtimes simple-MiniSAT original MiniSAT solverfamily instances, along times two state-of-the-art CP solversWCSP solver Toulbar2. far best solver set instances Toulbar2,explicitly designed exploit low tree-width constructing tree-decomposition.class instances considering, widths tree-decompositions foundToulbar2 matched tree-widths instances tested (i.e., 2w 1).However, also note MiniSAT remarkably effective solving chainsinequalities, compared Minion G12, even though use MiniSAT requiresencoding instance large number clauses much larger tree-widthoriginal. Although simplified version MiniSAT solver takes little longercurrent highly optimised version, still performs well instancescomparison conventional CP solvers. Moreover, number restarts (and hencenumber conflicts) appears grow polynomially size instance(see Figure 3). cases actual number restarts much lower polynomialupper bound expected number restarts given Theorem 4.best theoretical upper bounds expected run-time obtainedDecision learning scheme (Theorem 4), standard version MiniSAT uses1UIP learning scheme conflict clause minimization. allow direct comparisontheoretical upper bounds, implemented Decision scheme simpleMiniSAT. 1UIP learning scheme generally found efficientpractice (Zhang et al., 2001), switched conflict clause minimization simpleMiniSAT order compare two standard learning schemes ran setexperiments. counted number restarts two modified solvers instancesform described Example 7 - see Table 2.346fiLocal Consistency SAT-Solversgroupsize(w)22222222233333444domainsize(d)234567891023456234CSPvariables(n)812162024283236401524334251244056MinionG12(sec)0.0550.0530.0570.0841.04847.295> 20 min> 20 min> 20 min0.0550.412> 20 min> 20 min> 20 min0.060> 20 min> 20 min(sec)0.0100.0110.0130.0470.959122.468> 20 min> 20 min> 20 min0.0100.0347.147> 20 min> 20 min0.01511.523> 20 minToulbar2MiniSAT(sec)0.0210.0230.0400.0910.1990.5491.2142.5234.9300.0240.1030.8605.64628.6630.0461.24620.700(sec)0.0030.0050.0150.0430.1260.3620.8952.4075.6560.0040.0661.33420.984383.5640.0124.6311,160.873simpleMiniSAT(sec)0.0020.0070.0340.1880.7892.8849.87834.352111.9120.0080.50320.054817.779> 20 min0.118260.656> 20 minsimpleMiniSATrestarts191578203 0397 79717 59936 10865 318114 8271675 03941 478210 298731 8601 617108 1131 322 784*Table 1: Average performance solvers instances Example 7.groupsize(w)domainsize(d)CSPvariables(n)no. clausesdirectencoding2222222223333344234567891023456238121620242832364015243342512440492981 1623 4158 31517 72434 22861 257103 2051983 14123 611113 406408 72086334 666simpleMiniSAT1UIP(sec)0.0020.0080.0480.2721.3995.78024.41795.278309.9800.0090.64353.0672,266.627> 6 hours0.141603.241simpleMiniSAT1UIPrestarts212031 0264 06812 02927 35656 193109 862199 3991925 95263 952375 8491 584 012*1 937155 842simpleMiniSATDecision(sec)0.0020.0100.0570.3231.5266.03520.43669.144207.3420.0120.75071.7782,036.456> 6 hours0.192938.836simpleMiniSATDecisionrestarts232671 4245 28314 10433 62164 262113 460190 0632877 30891 283391,6641 365 481*2 592253 153Table 2: Average performance simple-MiniSAT 1UIP Decision learning schemes instances Example 7.347fiJeavons & PetkeFigure 3: Log-log plot number restarts/conflicts used simple-MiniSATinstances Example 7. solid lines show growth function d2w2 nd/w,3n number CSP variables. empirically derived polynomialfunction appears fit experimental data well, much lowerupper bound expected number restarts calculated Theorem 4O(d4w2 n4w2 ).348fiLocal Consistency SAT-SolversAlthough performance simple-MiniSAT Decision learning scheme1UIP scheme significantly worse performance original simpleMiniSAT solver, twice many restarts required instance. Hence,theoretical upper bounds still easily met standard learning schemes.7. Conclusionsshown notion k-consistency precisely captured singleinference rule direct encoding CSP instance, restricted deriving clausesk literals. used show clause-learning SAT-solver purelyrandom branching strategy simulate effect enforcing k-consistency expectedpolynomial time, fixed k. sufficient ensure solvers ablesolve certain problem families much efficiently conventional CP solvers relyingGAC-propagation.principle clause-learning SAT-solvers also much more. known that,appropriate branching strategy restart policy, able p-simulate generalresolution (Beame et al., 2004; Pipatsrisawat & Darwiche, 2009), general resolutionproofs exponentially shorter negative-hyper-resolution proofs considered (Hwang & Mitchell, 2005). practice, seems current clause-learningSAT-solvers highly-tuned learning schemes, branching strategies restart policiesoften able exploit structure Boolean encoding CSP instance eveneffectively local consistency techniques. Hence considerable work remains doneunderstanding relevant features instances able exploit, orderpredict effectiveness solving different kinds CSP instances.Acknowledgmentswould like thank Albert Atserias Marc Thurley comments conferenceversion paper, well anonymous referees. provision EPSRCDoctoral Training Award Justyna Petke also gratefully acknowledged.preliminary version paper appeared Proceedings 16th InternationalConference Principles Practice Constraint Programming - CP2010.ReferencesAtserias, A., Bulatov, A. A., & Dalmau, V. (2007). power k-consistency.International Colloquium Automata, Languages Programming - ICALP07,pp. 279290.Atserias, A., & Dalmau, V. (2008). combinatorial characterization resolution width.Journal Computer System Sciences, 74 (3), 323334.Atserias, A., Fichte, J. K., & Thurley, M. (2011). Clause-learning algorithms manyrestarts bounded-width resolution. Journal Artificial Intelligence Research(JAIR), 40, 353373.Bacchus, F. (2007). GAC via unit propagation. Principles Practice ConstraintProgramming - CP07, pp. 133147.349fiJeavons & PetkeBarto, L., & Kozik, M. (2009). Constraint satisfaction problems bounded width.Symposium Foundations Computer Science - FOCS09, pp. 595603.Beame, P., Kautz, H. A., & Sabharwal, A. (2004). Towards understanding harnessingpotential clause learning. Journal Artificial Intelligence Research (JAIR),22, 319351.Bessiere, C. (2006). Constraint propagation. Rossi, F., van Beek, P., & Walsh, T. (Eds.),Handbook Constraint Programming, chap. 3. Elsevier.Buning, H., & Lettmann, T. (1999). Propositional logic: deduction algorithms. Cambridge tracts theoretical computer science. Cambridge University Press.Chen, H., Dalmau, V., & Gruien, B. (2011). Arc consistency friends. ComputingResearch Repository - CoRR, abs/1104.4993.Cooper, M. C. (1989). optimal k-consistency algorithm. Artificial Intelligence, 41 (1),8995.Cooper, M. C., Cohen, D. A., & Jeavons, P. (1994). Characterising tractable constraints.Artificial Intelligence, 65 (2), 347361.de Kleer, J. (1989). comparison ATMS CSP techniques. International JointConference Artificial Intelligence - IJCAI89, pp. 290296.Deville, Y., Barette, O., & Hentenryck, P. V. (1997). Constraint satisfaction connectedrow convex constraints. International Joint Conference Artificial Intelligence IJCAI97 (1), pp. 405411.Een, N., & Sorensson, N. (2003). extensible SAT-solver. Theory ApplicationsSatisfiability Testing - SAT03, pp. 502518.Freuder, E. C. (1978). Synthesizing constraint expressions. Communications ACM,21 (11), 958966.Gent, I. P. (2002). Arc consistency SAT. European Conference Artificial Intelligence- ECAI02, pp. 121125.Gent, I. P., Jefferson, C., & Miguel, I. (2006). Minion: fast scalable constraint solver.European Conference Artificial Intelligence - ECAI06, pp. 98102.Hooker, J. N. (2006). Integrated Methods Optimization (International Series Operations Research & Management Science). Springer-Verlag New York, Inc., Secaucus,NJ, USA.Hoos, H. H. (1999). SAT-encodings, search space structure, local search performance.International Joint Conference Artificial Intelligence - IJCAI99, pp. 296303.Hwang, J., & Mitchell, D. G. (2005). 2-way vs. d-way branching CSP. PrinciplesPractice Constraint Programming - CP05, pp. 343357.Jegou, P., & Terrioux, C. (2003). Hybrid backtracking bounded tree-decompositionconstraint networks. Artificial Intelligence, 146 (1), 4375.Kolaitis, P. G., & Vardi, M. Y. (2000). game-theoretic approach constraint satisfaction. Conference Artificial Intelligence - AAAI00 / Innovative ApplicationsArtificial Intelligence Conference - IAAI00, pp. 175181.350fiLocal Consistency SAT-SolversMackworth, A. K. (1977). Consistency networks relations. Artificial Intelligence, 8 (1),99118.Montanari, U. (1974). Networks constraints: Fundamental properties applicationspicture processing. Information Sciences, 7, 95132.Moskewicz, M. W., Madigan, C. F., Zhao, Y., Zhang, L., & Malik, S. (2001). Chaff: Engineering efficient SAT solver. Design Automation Conference - DAC01, pp.530535.Nethercote, N., Stuckey, P. J., Becket, R., Brand, S., Duck, G. J., & Tack, G. (2007).MiniZinc: Towards standard CP modelling language. Principles PracticeConstraint Programming - CP07, pp. 529543.Petke, J., & Jeavons, P. (2009). Tractable benchmarks constraint programming. Technical Report RR-09-07, Department Computer Science, University Oxford.Pipatsrisawat, K., & Darwiche, A. (2009). power clause-learning SAT solversrestarts. Principles Practice Constraint Programming - CP09, pp. 654668.Prestwich, S. D. (2009). CNF encodings. Biere, A., Heule, M., van Maaren, H., & Walsh,T. (Eds.), Handbook Satisfiability, pp. 7597. IOS Press.Rish, I., & Dechter, R. (2000). Resolution versus search: Two strategies SAT. JournalAutomated Reasoning, 24 (1/2), 225275.Robinson, J. A. (1965). machine-oriented logic based resolution principle. JournalACM, 12 (1), 2341.Sanchez, M., Bouveret, S., de Givry, S., Heras, F., Jegou, P., Larrosa, J., Ndiaye, S., Rollon,E., Schiex, T., Terrioux, C., Verfaillie, G., & Zytnicki, M. (2008). Max-CSP competition 2008: Toulbar2 solver description. Proceedings Third InternationalCSP Solver Competition.Schiex, T., & Verfaillie, G. (1993). Nogood recording static dynamic constraintsatisfaction problems. International Conference Tools Artificial Intelligence- ICTAI93, pp. 4855.Tamura, N., Taga, A., Kitagawa, S., & Banbara, M. (2009). Compiling finite linear CSPSAT. Constraints, 14 (2), 254272.van Dongen, M., Lecoutre, C., & Roussel, O. (2008). 3rd international CSP solver competition. Instances results available http://www.cril.univ-artois.fr/CPAI08/.van Dongen, M., Lecoutre, C., & Roussel, O. (2009). 4th international CSP solver competition. Instances results available http://www.cril.univ-artois.fr/CPAI09/.Walsh, T. (2000). SAT v CSP. Principles Practice Constraint Programming CP00, pp. 441456.Zhang, L., Madigan, C. F., Moskewicz, M. W., & Malik, S. (2001). Efficient conflict drivenlearning Boolean satisfiability solver. International Conference ComputerAided Design - ICCAD01, pp. 279285.Zhang, L., & Malik, S. (2002). quest efficient Boolean satisfiability solvers.Computer Aided Verification - CAV02, pp. 1736.351fiJournal Artificial Intelligence Research 43 (2012) 87-133Submitted 07/11; published 01/12Location-Based Reasoning Complex Multi-Agent BehaviorAdam SadilekHenry KautzSADILEK @ CS . ROCHESTER . EDUKAUTZ @ CS . ROCHESTER . EDUDepartment Computer Science, University RochesterRochester, NY 14627, USAAbstractRecent research shown surprisingly rich models human activity learnedGPS (positional) data. However, effort date concentrated modeling single individuals statistical properties groups people. Moreover, prior work focused solely modelingactual successful executions (and failed attempted executions) activities interest.We, contrast, take task understanding human interactions, attempted interactions,intentions noisy sensor data fully relational multi-agent setting. use real-worldgame capture flag illustrate approach well-defined domain involves manydistinct cooperative competitive joint activities. model domain using Markov logic,statistical-relational language, learn theory jointly denoises data infers occurrences high-level activities, player capturing enemy. unified model combinesconstraints imposed geometry game area, motion model players,rules dynamics game probabilistically logically sound fashion. showmay impossible directly detect multi-agent activity due sensor noise malfunction, occurrence activity still inferred considering impactfuture behaviors people involved well events could preceded it. Further,show given model successfully performed multi-agent activities, along setexamples failed attempts activities, system automatically learns augmentedmodel capable recognizing success failure, well goals peoples actionshigh accuracy. compare approach alternatives show unified model,takes account relationships among individual players, also relationshipsamong activities entire length game, although computationally costly, significantly accurate. Finally, demonstrate explicitly modeling unsuccessful attemptsboosts performance important recognition tasks.1. Introductionsociety founded interplay human relationships interactions. Since every person tightly embedded social structure, vast majority human behavior fullyunderstood context actions others. Thus, surprisingly, evidence shows want model behavior person, single best predictor oftenbehavior people social network. instance, behavioral patterns people taking taxis,rating movies, choosing cell phone provider, sharing music best explained predictedhabits related people, rather single person attributes age, race,education (Bell, Koren, & Volinsky, 2007; Pentland, 2008).contrast observations, research effort activity recognition date concentrated modeling single individuals (Bui, 2003; Liao, Fox, & Kautz, 2004, 2005), statisticalproperties aggregate groups individuals (Abowd, Atkeson, Hong, Long, Kooper, & Pinkerton,1997; Horvitz, Apacible, Sarin, & Liao, 2005), combinations (Eagle & Pentland, 2006).c2012AI Access Foundation. rights reserved.fiS ADILEK & K AUTZNotable exceptions isolated individuals approach includes work Kamar Horvitz(2009) Gupta, Srinivasan, Shi, Davis (2009), simple relationships among peoplestarting explicitly considered leveraged. instance, Eagle Pentland (2006)elegantly model location individuals multi-modal sensory data, approachoblivious explicit effects ones friends, relatives, etc. ones behavior. isolated individuals approximations often made sake tractability representational convenience.considering individuals independently sufficient constrained tasks,many interesting domains discards wealth important information results inefficient unnatural data representation. hand, decomposing domain setentities (representing instance people, objects environment, activities) linkedvarious relationships (e.g., is-a, has-a, is-involved-in) natural clear way representingdata.address shortcomings nonrelational behavior modeling, introduce captureflag domain (described below), argue statistical-relational approach learning modelsmulti-agent behavior raw GPS data. CTF dataset one hand quite complexrecorded real-world sensors, time well-defined (as per rules game),thereby allowing unambiguous evaluation results.able recognize peoples activities reason behavior necessary precondition intelligent helpful machines aware goinghuman-machine well human-human relationships. many exciting practical applications activity recognition potential fundamentally change peoples lives.example, cognitive assistants help people teams productive, provide support(groups of) disabled individuals, efficiently summarize long complex event busy personwithout leaving essential information. important applications include intelligent navigation, security (physical well digital), human-computer interaction, crowdsourcing.applications myriad others build top multi-agent activity recognition therefore require necessary stepping stone. Furthermore, consequence anthropocentrismtechnology, modeling human behavior playsperhaps surprisinglya significant role evenapplications directly involve people (e.g., unmanned space probes).Furthermore, reasoning human intentions essential element activity recognition,since recognize person (or group people) wants do, proactivelytry help (orin adversarial situationshinder them). Intent notoriously problematicquantify (e.g., Baldwin & Baird, 2001), show capture flag domain, notionnaturally captured process learning structure failed activities. know perhapswell successful action often precededand unfortunately sometimes also followedbymultiple failed attempts. Therefore, reasoning attempts typically entails high practical utility,relatively high frequency. Consider, example, task real-time analysissecurity video system. There, detecting person group people (again, relations)intend steal something much important useful recognizing theft taken(or even taking) place, certainly late entirely prevent incident,may also late harder merely stop it. believe recognition attempts peoplesactivities severely underrepresented topic artificial intelligence needs exploredsince opens new realm interesting possibilities.delve details approach Sections 5 6, briefly introduceCTF dataset (Section 2), highlight main contributions work (Section 3), review88fiL OCATION -BASED R EASONING C OMPLEX ULTI -AGENT B EHAVIORbackground material (Section 4). discuss related work, conclude, outline future workSections 7, 8 9 respectively.paper incorporates extends previous work (Sadilek & Kautz, 2010a, 2010b).2. Capture Flag DomainImagine two teamsseven players eachplaying capture flag (CTF) university campus,player carries consumer-grade global positioning system (GPS) logs location(plus noise) every second (see Figure 1). primary goal enter opponents flag area.Players captured enemy territory tagged enemy. Uponcaptured, must remain place freed (tagged teammate) game ends.games involve many competitive cooperative activities, focus (both successfulattempted) capturing freeing. Visualization games available first authorswebsite.collected four games CTF portion University Rochester campus (about23 acres) Columbus V-900 GPS loggers (one per player) 1 GB memory cardset sampling rate 1 Hz. durations games ranged approximately 4 15minutes.work primarily motivated problem annotating strategy games, althoughobvious applications results sports combat situations. are, generally, exploring relational learning inference methods recognizing multi-agent activitieslocation data. accept fact GPS data disposal inherently unreliableambiguous one individual. therefore focus methods jointly simultaneouslylocalize recognize high-level activities groups individuals.Although CTF domain doesnt capture intricacies life, contains many complex, interesting, yet well-defined (multi-agent) activities. Moreover, based extensivereal-world GPS data (total 40,000+ data points). Thus problems addressing clearly direct analogs everyday-life situations ubiquitous computing needsaddressimagine people going daily lives city instead CTF players,smart phones instead GPS loggers.One main challenges overcome successfully model CTFsevere noise present data. Accuracy GPS data varies 1 10 meters.open areas, readings typically 3 meters, discrepancy much higher locationstall buildings (which present within game area) obstructions. Comparescale error granularity activities concern with: capturingfreeing involves players within reaching distance (less 1 meter) apart. Therefore,signal noise ratio domain daunting.error systematic component well significant stochastic component. Errorsdevices poorly correlated, subtle differences players, angledevice sits players pocket, dramatically affect accuracy. Moreover, sinceconsider multi-agent scenarios, errors individual players readings add up, therebycreating large discrepancy reality recorded dataset. playersmove freely open areas, cannot reduce data error assuming players movealong road walkways, done much work GPS-based activity recognition (e.g., Liaoet al., 2004). Finally, traditional techniques denoising GPS data, Kalman filtering,89fiS ADILEK & K AUTZFigure 1: snapshot game capture flag shows game area. Playersrepresented pins letters. version CTF, two flags stationaryshown white circles near top bottom figure. horizontal road middle image territory boundary. data shown priordenoising corrections map errors. Videos games availablehttp://www.cs.rochester.edu/u/sadilek/90fiL OCATION -BASED R EASONING C OMPLEX ULTI -AGENT B EHAVIORlittle help, due low data rate (1 sample per second) relative small amount timerequired player completely change speed direction.reliably recognize events happen games presence severenoise, need consider player, also relationships amongactions extended periods time (possibly whole length game). Consider concretetask inferring individual joint activities intentions CTF players GPStraces. example, suppose GPS data shows player running toward stationary teammateB, moving away. occurred? Possibly player freed player B, GPS errorhidden fact player actually reached B. Another possibility playerintention freeing player B, scared opponent last second. Yet another possibility freeing occurred even intended, player B previouslycaptured.Understanding game thus consists inferring complex set interactions among variousplayers well players intentions. conclusions drawn occurs one pointtime affect affected inferences past future events. example given,recognizing player B moving future reinforces conclusion player freeingplayer B, failing recognize past event player B captured decreases confidenceconclusion. game CTF also illustrates understanding situation muchrecognizing attempts intentions recognizing successfully executed actions.example, course 15 minute game, handful capture freeing events occur. However,dozens cases one player unsuccessfully tries capture opponent freeteammate. description game restricted actually occurred wouldpale reflection original.Figure 2: Three snapshots game situation successful failed capturing occur.example also illustrates need approach exploits relationalfar reaching temporal structure domain. (See text explanation.)concrete example, consider real game situation illustrated Figure 2. see threesnapshots game projected map campus modification GPS data.game time shown snapshot. Players D, F, G allies currentlyhome territory near flag, whereas players L enemies. first snapshot,players L head opponents flag thenin second framethey interceptedG. point unclear happening substantial error GPS data91fiS ADILEK & K AUTZthree players appear close other, actuality could 20meters apart. However, see third snapshot (note tens seconds passed)realize player G actually captured player didnt capture L since G evidentlystill chasing L. fact player remains stationary coupled fact neither Fattempt capture suggests indeed captured. show possible inferoccurrences capturing events even complex situations like whereas limited approacheslargely fail. However, need able recognize individual events, also needdiscover new activities, identify respective goals, distinguish events basedwhether outcomes favorable negative. instance, second frame, player G triescapture L M. Although succeeded former case, failed latter.Many different kinds cooperative competitive multi-agent activities occur games.lowest-level joint activities based location movement, include approachinglocation. Note, noise GPS data often makes difficult impossibledirectly detect simple activities. next level come competitive multi-agent activitiesincluding capturing attacking; cooperative activities include freeing; activities,chasing guarding, may belong either category categories.also abstract tactical activities, making sacrifice, overall strategies,playing defensively. paper, concentrate activities first two levels.3. Contributionsmain contributions paper follows. first present novel method simultaneously denoises positional data learns model multi-agent activities occur there.subsequently evaluate model CTF dataset show achieves high accuracyrecognizing complex game events.However, creating model manually writing new rules editing existing axiomslaborious prone introduction errors unnecessarily complex theories. Thus, wouldlike automate process learning (or inducing) new axioms training data. people,much easier provide validate concrete examples directly modify model.leads us second contribution: show automatically augment preexisting model(joint) activities capable recognizing successful actions, also identifiesfailed attempts types activities. line work also demonstrates explicitlymodeling attempted interactions unified way improves overall model performance.third contribution, demonstrate difference (discussed below)newly learned definitions failed activity original definition corresponding successful activity directly corresponds goal given activity. instance, per rulescapture flag game, captured player cannot move freed. system inducesdefinition failed capture, new theory contain constraint movementalmost-captured player, thereby allowing move freely.4. Backgroundcores models described implemented Markov logic (ML), statisticalrelational language. section, provide brief overview ML, extends finite firstorder logic (FOL) probabilistic setting. detailed (and excellent) treatment FOL,92fiL OCATION -BASED R EASONING C OMPLEX ULTI -AGENT B EHAVIORML, inductive logic programming see work Shoenfield (1967), Domingos, Kok, Lowd,Poon, Richardson, Singla (2008), De Raedt Kersting (2008), respectively.order compare Markov logic based models alternative approaches, considerdynamic Bayesian network (DBN) model experiments one baselines.therefore review relevant aspects DBNs section well.4.1 Markov LogicGiven inherent uncertainty involved reasoning real-world activities observednoisy sensor readings, looked methodology would provide elegant combinationprobabilistic reasoning expressive, relatively natural, compact unfortunately strictlytrue false formulas first-order logic. exactly Markov logic provides thusallows us elegantly model complex finite relational non-i.i.d. domains. Markov logic network(MLN) consists set constants C set pairs hFi , wi FOL formulaFi weight wi R associated it. Optionally, weight scaledreal-valued function subset variables appear corresponding formula. Markovlogic networks contain functions called hybrid MLNs (Wang & Domingos, 2008).MLN viewed template Markov network (MN) follows: MN containsone node possible ground atom MLN. value node 0 correspondingatom false 1 otherwise. Two nodes connected edge corresponding atomsappear formula. Thus, MN distinct clique corresponding groundinggformula. Fi j denote j-th grounding formula Fi . MN feature value fi,jgjFi(g1 Fi j truefi,j =0 otherwiseweight wi intuitively represents relative importance satisfying (or violating,weight negative) corresponding formula Fi . formally, weight scales differencelog-probability world satisfies n groundings corresponding formula oneresults true groundings formula, else equal (cf. Equation 1). Thusproblem satisfiability relaxed MLNs. longer search satisfying truth assignmenttraditional FOL. Instead, looking truth assignment maximizes sumweights satisfied formulas.weights either specified knowledge base engineer or, approach,learned training data. is, provide learning algorithm labeled capture instances pairs raw corresponding denoised trajectories along labeled instancesgame events finds optimal set weights maximize likelihood trainingdata. Weight learning done either generative discriminative fashion. Generative training maximizes joint probability observed (evidence) well hidden (query) predicates,whereas discriminative learning directly maximizes conditional likelihood hidden predicates given observed predicates. Since prior work demonstrated Markov network modelslearned discriminatively consistently outperform generatively trained counterparts (Singla &Domingos, 2005), focus discriminative learning activity recognition domain.knowledge base weights specified, ask questions statehidden atoms given state observed atoms. Let X vector random variables(one random variable possible ground atom MN) let set possible93fiS ADILEK & K AUTZinstantiations X. Then, x represents possible world. (x )[Pr(X = x) > 0]holds, probability distribution worlds defined!X1Pr(X = x) = expwi ni x{i}(1)Zni (x{i} ) number true groundings i-th formula wi weight world x!XXZ=expwi ni x{i}(2)xEquation 1 viewed assigning score possible world dividing scoresum scores possible worlds (the constant Z) order normalize.Maximum posteriori (MAP) inference Markov logic given state observed atomsreduces finding truth assignment hidden atoms weighed sum satisfiedclauses maximal. Even though problem general #P-complete, achieve reasonablerun times applying Cutting Plane MAP Inference (CPI) (Riedel, 2008). CPI thoughtmeta solver incrementally grounds Markov logic network, step creating Markovnetwork subsequently solved applicable methodsuch MaxWalkSAT viareduction integer linear program. CPI refines current solution searching additionalgroundings could contribute objective function.point, focused first-order Markov logic. first-order ML, variableranges objects present domain (e.g., apples, players, cars). hand, finitesecond-order Markov logic, variabilize objects also predicates (relations) (Kok & Domingos, 2007). CTF model contains predicate variable type activity. example, one variable captureType whose domain {capturing, failedCapturing}analogously freeing events. grounding second-order ML, ground predicatevariables well object variables. also preliminary work generalizing MLwell-defined infinite domains, would indeed give full power FOL (Singla &Domingos, 2007).Implementations Markov logic include Alchemy1 theBeast2 . experiments usedmodified version theBeast.4.2 Dynamic Bayesian NetworksBayesian network (BN) directed probabilistic graphical model (Jordan, 1998). Nodesgraph represent random variables edges represent conditional dependencies (cf. Figure 4).BN n nodes, joint probability distribution givenPr(X1 , . . . , Xn ) =ni=11. http://alchemy.cs.washington.edu/2. http://code.google.com/p/theBeast/94Pr Xi |Pa(Xi ) ,(3)fiL OCATION -BASED R EASONING C OMPLEX ULTI -AGENT B EHAVIORPa(Xi ) denotes parents node Xi . typical setting, subset random variablesobserved (we know actual values), others hidden values needinferred.dynamic Bayesian network (DBN) BN models sequential data. DBN composedslicesin case slice represents one second time interval. order specify DBN,either write learn intra- inter-slice conditional probability distributions (CPDs).intra-slice CPDs typically constitute observation model inter-slice CPDs modeltransitions hidden states. extensive treatment DBNs, see work Murphy(2002).number parameter learning inference techniques DBNs. matchMarkov logic-based framework, experiments DBN model presented below, focussupervised learning scenario, hidden labels known training time thereforemaximum likelihood estimate calculated directly.find set parameters (discrete probability distributions) maximize log-likelihoodtraining data. achieved optimizing following objective function.? = argmax log Pr x1:t , y1:t |) ,(4)x1:t y1:t represent sequence observed hidden values, respectively,times 1 t, ? set optimal model parameters. implementation, representprobabilities likelihoods log-counterparts avoid arithmetic underflow.testing time, interested likely explanation observed data. is,want calculate likely assignment states hidden nodes (i.e., Viterbi decodingDBN) given?(5)y1:t= argmax log Pr(y1:t |x1:t ) ,y1:tPr(y1:t |x1:t ) conditional probability sequence hidden states y1:t given concretesequence observations x1:t times 1 t. calculate Viterbi decoding efficientlyusing dynamic programming (Jordan, 1998).5. Methodologysection, describe three major components approach. short, first manuallyconstruct model captures freeings CTF optimize parameters supervisedlearning framework (Section 5.1). constitutes seed theory used denoising rawlocation data recognition successful multi-agent activities. show, Section 5.2,automatically extend seed theory inducing structure learning importancefailed captures freeings well relationships successful counterparts. Finally,Section 5.3, use augmented theory recognize richer set multi-agent activitiesbothsuccessful failed attemptsand extract goals activities.Specifically, investigate following four research questions:Q1. reliably recognize complex multi-agent activities CTF dataset even presence severe noise?Q2. models attempted activities automatically learned leveraging existing modelssuccessfully performed actions?95fiS ADILEK & K AUTZQ3. modeling success failure allow us infer respective goals activities?Q4. modeling failed attempts activities improve performance recognizing activities themselves?elaborate three components system turn, subsequentlydiscuss, light experimental results lessons learned, answers researchquestions.5.1 Recognition Successful Activitiessection, present unified framework intelligent relational denoising raw GPSdata simultaneously labeling instances player captured enemy freedally. denoising labeling cast learning inference problem Markovlogic. denoising, mean modifying raw GPS trajectories players finaltrajectories satisfy constraints imposed geometry game area, motion modelplayers, well rules dynamics game. paper, refer trajectorymodification snapping since tile game area 3 3 meter cells snap rawGPS reading appropriate cell. creating cells unobstructed space, ensure finaltrajectory consistent map area.begin modeling domain via Markov logic theory, write logical formulas express structure model hand, learn optimal set weightsformulas training data supervised discriminative fashion (details experimental setup Section 6). following two subsections, show augment seedMarkov logic theory recognize richer set events extract goals players multi-agentactivities.order perform data denoising recognition successful capturing freeing,model game weighted formulas Markov logic. formulas hard,sense interested solutions satisfy them. Hard formulas capture basicphysical constraints (e.g., player one location time) inviolable rules game(e.g., captured player must stand still freed game ends).3 rest formulassoft, meaning finite weight associated one. soft constraintscorrespond traditional low-level data filter, expressing preferences smooth trajectoriesclose raw GPS readings. soft constraints capture high-level constraints concerningindividual multi-agent activities likely occur. example, soft constraint statesplayer encounters enemy enemys territory, player likely captured.exact weights soft constraints learned labeled data, described below.distinguish two types atoms models: observed (e.g., GPS(P1 , 4, 43.13 , 77.71 )hidden (e.g., freeing(P1 , P8 , 6)). observed predicates CTF domain are: GPS, enemies, adjacent, onHomeTer, onEnemyTer;4 whereas capturing, freeing, isCaptured, isFree,samePlace, snap hidden. Additionally, set hidden predicates expanded structure learning algorithm described (see Table 1 predicate semantics). training phase,3. Cheating occur CTF games, principle could accommodated making rules highlyweighted soft constraints rather hard constraints.4. noise GPS data introduces ambiguity last two observed predicates, still reliablygenerate since road marks boundary territories constitutes neutral zone.96fiL OCATION -BASED R EASONING C OMPLEX ULTI -AGENT B EHAVIORHard Rules:H1. raw GPS reading snapped exactly one cell.H2.(a) player frees player b, involved players must snapped common celltime.(b) player freed free ally.(c) player freed currently captured.(d) Immediately freeing event, freed player transitions free state.(e) player freed enemy territory.H3.(a) player captures player b, involved players must snapped common celltime.(b) player captured free enemy.(c) player captured currently free.(d) Immediately capture event, captured player transitions captured state.(e) player captured standing enemy territory.H4. players free beginning game.H5. given time, player either captured free both.H6. player transitions captured state free state via freeing event.H7. player transitions free state captured state via capture event.H8. player captured must remain location.Soft Rules:S1. Minimize distance raw GPS reading snapped-to cell.S2. Minimize projection variance, i.e., two consecutive snappings generally correlated.S3. Maximize smoothness (both terms space time) final player trajectories.S4. players b enemies, enemy territory b not, b captured already,close other, probably captures b.S5. players b allies, enemy territory, b currently captured not,close other, probably frees b.S6. Capture events generally rare, i.e., typically captures within game.S7. Freeing events also generally rare.Figure 3: Descriptions hard soft rules capture flag.learning algorithm access known truth assignment atoms. testing phase,still access state observed atoms, infer assignment hiddenatoms.Figure 3 gives English description hard soft rules low-level movementplayer interactions within capture flag. Corresponding formulas language MLshown Figures 5 6.97fiS ADILEK & K AUTZPredicatecapturing(a, b, t)enemies(a, b)adjacent(c1 , c2 )failedCapturing(a, b, t)failedFreeing(a, b, t)freeing(a, b, t)isCaptured(a, t)isFailedCaptured(a, t)TypehiddenobservedobservedhiddenhiddenhiddenhiddenhiddenisFailedFree(a, t)hiddenisFree(a, t)hiddenonEnemyTer(a, t)onHomeTer(a, t)samePlace(a, b, t)observedobservedhiddensnap(a, c, t)hiddenMeaningPlayer capturing b time t.Players b enemies.Cells c1 c2 mutually adjacent, c1 = c2 .Player unsuccessfully capturing b time t.Player unsuccessfully freeing b time t.Player freeing b time t.Player captured state time t.time t, player state followsunsuccessful attempt capturing a.state capabilities free.time t, player state followsunsuccessful attempt freeing a.state capabilities captured.Player free state time(isFree(a, t) isCaptured(a, t)).Player enemy territory time t.Player home territory time t.Players b either snapped common celltwo adjacent cells time t.Player snapped cell c time t.Table 1: Summary logical predicates models use. Predicate names containing wordfailed introduced Markov logic theory augmentation method describedSection 5.2.1.compare unified approach four alternative models. first two models (baselinebaseline states) purely deterministic separate denoising GPS datalabeling game events. implemented Perl. involvetraining phase. third alternative model dynamic Bayesian network shown Figure 4.Finally, two models cast Markov logic: two-step ML model unified MLmodel itself. unified model handles denoising labeling joint fashion, whereastwo-step approach first performs snapping given geometric constraints subsequently labelsinstances capturing freeing. latter three models evaluated using four-fold crossvalidation order test given game, first train model three games.models access following observed data: raw GPS position playertime indication whether enemy home territory, location 3 3 metercell, cell adjacency, list pairs players enemies. tested five modelsobserved data. following describes model detail.Baseline Model (B)model two separate stages. First snap reading nearest cell afterward label instances player capturing player b. labeling rule simple:98fiL OCATION -BASED R EASONING C OMPLEX ULTI -AGENT B EHAVIORloop whole discretized (via snapping) data set output capturing(a, b, t) everytime encounter pair players b snapped (in first step)either cell two mutually adjacent cells time t, enemies,home territory b not. Freeing recognition considered simple modelsince need notion persisting player states (captured free) order modelfreeing meaningful way.Baseline Model States (B+S)second model builds top previous one introducing notion players states. player captures player b time t, b enters captured state (in logic,isCaptured(b, + 1)). b remains captured state moves (is snapped different cell later time) game ends. per rules CTF, player capturedstate cannot captured again.Thus, model works like previous one except whenever labelcapturing event, checks states involved players outputs capturing(a, b, t)b captured state.Freeing recognition implemented analogous way capturing recognition. Namely,every time captured player b transition free state, check bfree teammate nearby (again, within adjacent cells). case, outputfreeing(a, b, t).Dynamic Bayesian Network Model (DBN)dynamic Bayesian network model viewed probabilistic generalizationbaseline model states. structure DBN model one player shownFigure 4. time slice, one hidden node four observed nodes,represent binary random variables. want infer likely stateplayer given time course game. state either free capturedhidden testing time. four observed random variables per time step modelplayers motion (M ), presence absence least one enemy (EN ) ally (AN ) playernearby, finally players location either home enemy territory (ET ). playermodeled separate DBN. Therefore, fourteen instantiated DBNs game,within one game, DBNs share set parameters.Note DBN model perform GPS trajectory denoising itself. make faircomparison Markov logic models, use denoising component Markovlogic theory using constraints H1 S1S3 (in Figure 3). produces denoiseddiscretization data subsequently fed DBN model. random variableswithin DBN capture notion player movement players nearby oneanother defined occupancy grid game area, like two deterministicbaseline models. Namely, player said moving time + 1snapped two different nonadjacent cells times. Similarly, two playersnearby snapped either cell two adjacent cells.Two-Step ML Model (2SML)two-step approach, two separate theories Markov logic. first theoryused perform preliminary snapping player trajectories individually us99fiS ADILEK & K AUTZETt...ENtANtETt+1ENt+1StSt+1MtMt+1ANt+1...Figure 4: Two consecutive time slices dynamic Bayesian network modeling stateindividual player P observations. Shaded nodes represent observed randomvariables, unfilled denote hidden variables. random variables binary. (ETt = 1P enemy territory time t, ENt = 1 enemy nearby timet, ANt = 1 ally nearby time t, finally Mt = 1 P movedtime 1 t. value hidden state St 1 P captured time0 P free.)ing constraints H1 S1S3 (in Figure 3). theory identical one useddiscretization step DBN model above.second theory takes preliminary denoising list observed atomsform preliminarySnap(a, c, t) (meaning player snapped cell c time t) usesremaining constraints label instances capturing freeing, considering cell adjacency manner previous three models. two-step model constitutesdecomposition unified model (see below) overall contains virtually formulas, except 2SML operates observed preliminarySnap predicate, whereas unifiedmodel contains hidden snap predicate instead. Thus omit elaborating here.Unified ML Model (UML)unified approach, express hard constraints H1H8 soft constraints S1S7 (Figure 3) Markov logic single theory jointly denoises data labels gameevents. Selected interesting formulas shown Figure 6their labels correspondlisting Figure 3. Note formulas S1S3 contain real-valued functions d1 , d2 , d3respectively. d1 returns distance agent cell c time t. Similarly, d2 returnsdissimilarity two consecutive snapping vectors5 given agent position time+ 1 location centers two cells c1 c2 . Finally, since people prefermove straight lines, function d3 quantifies lack smoothness three consecutivesegments trajectory. Since wp , ws , wt assigned negative valuestraining, formulas S1S3 effectively softly enforce corresponding geometric constraints.5. initial point snapping (projection) vector raw GPS reading terminal point centercell snap reading to.100fiL OCATION -BASED R EASONING C OMPLEX ULTI -AGENT B EHAVIORpresence functions d1 d3 renders formulas S1S3 hybrid formulas. meansinference time, instantiated logical part formula evaluates either 1 (true)0 (false), turn multiplied product corresponding function valueformula weight.see train, test, evaluate four models, performmulti-agent activity recognition task Section 6. Next, turn supervised learning methodaugmenting unified ML model order recognize successful failed attemptsmulti-agent activities.Hard formulas:a, c : snap(a, c, t)0(H1)00a, c, c , : (snap(a, c, t) c 6= c ) snap(a, c , t)a1 , a2 , : freeing(a1 , a2 , t) samePlace(a1 , a2 , t) isFree(a1 , t)(H2)enemies(a1 , a2 ) isCaptured(a2 , t) isFree(a2 , + 1)onEnemyTer(a1 , t) onEnemyTer(a2 , t)a1 , a2 , : capturing(a1 , a2 , t) samePlace(a1 , a2 , t) isFree(a1 , t)(H3)enemies(a1 , a2 ) isFree(a2 , t) isCaptured(a2 , + 1)onHomeTer(a1 , t) onEnemyTer(a2 , t)a1 , a2 , : samePlace(a1 , a2 , t) c1 , c2 : snap(a1 , c1 , t) snap(a2 , c2 , t) adjacent(c1 , c2 )a, : (t = 0) isFree(a, t)(H4)a, : isCaptured(a, t) isFree(a, t)(H5)a, : (isFree(a, t) isCaptured(a, + 1)) (=1 a1 : capturing(a1 , a, t))(H6)a, : (isCaptured(a, t) isFree(a, + 1)) (=1 a1 : freeing(a1 , a, t))(H7)a, t, c : (isCaptured(a, t) isCaptured(a, + 1) snap(a, c, t)) snap(a, c, + 1)(H8)Figure 5: hard formulas Markov logic. See corresponding rules Figure 3 Englishdescription Table 1 explanation predicates. implementation,actual rules written syntax used theBeast, Markov logic toolkit. (=1denotes unique existential quantification, designates exclusive or.)5.2 Learning Models Failed Attemptswork described above, manually designed structure Markov logic networkmodels capture flag domain allows us jointly denoise raw GPS data recognize101fiS ADILEK & K AUTZSoft formulas:a, c, : snap(a, c, t) d1 (a, c, t) wp(S1)a,c1 , c2 , : snap(a, c1 , t) snap(a, c2 , + 1) d2 (a, c1 , c2 , t) ws(S2)a,c1 , c2 , c3 , : snap(a, c1 , t) snap(a, c2 , + 1) snap(a, c3 , + 2) d3 (a, c1 , c2 , c3 , t) wta1 , a2 , : [(enemies(a1 , a2 ) onHomeTer(a1 , t)(S3)(S4)onEnemyTer(a2 , t) isFree(a2 , t)samePlace(a1 , a2 , t)) capturing(a1 , a2 , t)] wca1 , a2 , : [(enemies(a1 , a2 ) onEnemyTer(a1 , t)(S5)onEnemyTer(a2 , t) samePlace(a1 , a2 , t) isFree(a1 , t)isCaptured(a2 , t)) freeing(a1 , a2 , t)] wfa, c, : capturing(a, c, t) wcb(S6)a, c, : [freeing(a, c, t)] wf b(S7)Figure 6: Soft formulas Markov logic. See corresponding rules Figure 3 English description. soft formulawrittentraditional quantified finite first-order logicformula (e.g., a, c, : snap(a, c, t) ), followed optional function (e.g., d1 (a, c, t)),followed weight formula (e.g., wp ). syntax denotes inferencetime, instantiated logical part formula evaluates either 1 (true) 0 (false),effectively multiplied product corresponding function valueformula weight.instances actual capturing freeing. show automaticallyin supervisedlearning settingextend theory encompass correctly label successful actions,also failed attempts interactions. is, given raw GPS data representCTF games, want new model label instances player captures (or frees) playerb successful captures (successful frees) instances player almost captures (or frees)player b failed captures (failed frees). example, failed capturing mean instanceplayers interactions whereup pointit appeared capturing b, carefullyconsider events (potentially) preceded well impacts supposed capturefuture unfolding game, conclude false alarm capture actuallyoccurred. words, conditions capture right, later on, pivotalmoment foiled capturing agents attempt.activities (capturing freeing), model jointly finds optimal separation success failure. Note since cast model second-order Markov logic,learn, e.g., isolated rule separates successful freeing failed attempt freeing.Rathersince capturing freeing events (both actual failed) related thus labelingactivity as, say, successful capturing far-reaching impact past, present, future102fiL OCATION -BASED R EASONING C OMPLEX ULTI -AGENT B EHAVIORlabelingwe learn separations joint unified way. Namely, structure (logicalform) importance (weight) formula theory considered consequencesinfluence axioms theory. system thus finds optimal balance success failure capturing freeing activities respect training data.5.2.1 HEORY AUGMENTATION LGORITHMfollows, describe Markov logic theory augmentation algorithm (Algorithm 1).clarity, explain works concrete context ML models capture flagdiscussed previous sections. However, underlying assumption successful actionsmany ways similar failed counterparts, minorbut crucialdeviations causefailure occur, often hold beyond capture flag. Therefore, algorithm applicabledomains different activities, long modeled Markov logic.Algorithm 1 : Extend ML theory model successful well failed activities.Input: A: set activitiesMS : ML theory models successful instances activitiesS: set examples successful activitiesF : set examples failed activitiesOutput: MS+F : augmented ML model learned weights models successfulattempted activitiesI: intended goals activities1:2:3:4:5:6:7:M2S liftToSecondOrderML(MS , A)M0S instantiate(M2S , A)findIncompatibleFormulas(F , M0S )MS+F M0S \IMS+F learnWeights(S, F , MS+F )MS+F removeZeroWeightedFormulas(MS+F )return MS+F ,high-level, augmentation algorithm belongs family structure learning methods. Starting seed model successful actions, searches new formulasadded seed theory order jointly model successfully unsuccessfully carriedactions. declarative language biasessentially rules exploring hypothesis space candidate structuresis defined implicitly notion given activity, structureunsuccessful attempts similar successful attempts. Therefore, augmentation algoritmgoes inflation stage, formulas seed theory generalized, followedrefinement stage, superfluous incompatible formulas inflated model prunedaway. refinement step also optimizes weights within newly induced theory.discuss process detail.input theory augmentation algorithm consists initial first-order ML theory MSmodels successful capturing freeing (such unified ML model defined Section 5.1contains formulas shown Figures 5 6), set activities interest A, setexamples successful (S) well failed (F ) captures frees. MS needweights soft formulas specified. case missing, learn scratch103fiS ADILEK & K AUTZfinal steps augmentation algorithm. weights specified, final weight learningstep MS+F leverage estimate initial weight values. specifiedset predicate names, e.g., {capturing, freeing}. example sets F describes gamesegment constitutes truth assignment appropriate literals instantiated MS . Table 2shows two toy examples sets F three time steps. Since goal learn modelfailed (and successful) attempts supervised way, example game segment F containactivities labeled predicates failedCapturing() failedFreeing().MS contains hybrid formulas (such formulas S1S3 Figure 6), appropriate functiondefinitions provided part F well. definition consists implicit mappinginput arguments function values. instance, function d1 formula S1 quantifies L2distanceagent cell c time projected Mercator space: d1 (a, c, t) =p(a.gpsXt c.gpsX)2 + (a.gpsYt c.gpsY )2 .system goes following process order induce new theory MS+Faugments MS definition failed attempts activity already defined MS .First lift MS second-order Markov logic variabilizing predicates correspondactivities interest (step 1 Algorithm 1). yields lifted theory M2S . concretely, order apply technique domain, introduce new predicate variables captureType (whose domain {capturing, failedCapturing}), freeType (over {freeing, failedFreeing}),stateType (over {isCaptured, isFailedCaptured, isFree, isFailedFree}). instance, variabilizing first-order ML formula freeing(a, b, t) enemies(a, b) yields second-order ML formulafreeType(a, b, t) enemies(a, b) (note freeType variable). Instantiating backfirst-order yields two formulas: freeing(a, b, t) enemies(a, b) failedFreeing(a, b, t)enemies(a, b).far agents behavior concerned, CTF domain, isCaptured equivalent isFailedFree, isFree equivalent isFailedCaptured. soon see, theory augmentationprocess learns equivalence classes relationships states training examples expanding subsequently refining formula H5 Figure 5. could workisCaptured predicate negation represent agents states, feel explicit failure states makes discussion clearer. Furthermore, future work need addresshierarchies activities, including failures. context, representation explicit failurestates may convenient, may necessary.Next, instantiate predicate variables M2S produce new first-order ML theory M0Scontains original theory MS entirety plus new formulas correspond failed captures frees (step 2). Since events are, e.g., near-captures appear similar actual successfulcaptures, hypothesis need drastically modify original successful formulas order model failed activities well. practice, process liftinginstantiating indeed results good seed theory. could emulate lifting groundingsteps scheme copying formulas renaming predicates duplicates appropriately,cast approach principled second-order Markov logic, ties work closelyprevious research results extensible framework. Specifically, second-order Markovlogic successfully used deep transfer learning (Davis & Domingos, 2009) predicate invention (Kok & Domingos, 2007). Therefore, interesting direction future workcombine theory augmentation refinement transfer inductive learningoperatingsecond-order MLto jointly induce models failed attempts different activities differentdomains, starting single model successful activities source domain.104fiL OCATION -BASED R EASONING C OMPLEX ULTI -AGENT B EHAVIORSet S: Successful Captureenemies(P1 , P2 )enemies(P2 , P1 )onEnemyTer(P2 , 2)onEnemyTer(P2 , 3)capturing(P1 , P2 , 2)isFree(P1 , 1)isFree(P1 , 2)isFree(P1 , 3)isFree(P2 , 1)isFree(P2 , 2)isCaptured(P2 , 3)snap(P1 , C5, 1)snap(P1 , C10, 2)snap(P1 , C10, 3)snap(P2 , C9, 1)snap(P2 , C10, 2)snap(P2 , C10, 3)samePlace(P1 , P2 , 2)samePlace(P2 , P1 , 2)samePlace(P1 , P2 , 3)samePlace(P2 , P1 , 3)Set F: Failed Captureenemies(P4 , P5 )enemies(P5 , P4 )onEnemyTer(P5 , 1)onEnemyTer(P5 , 2)onEnemyTer(P5 , 3)failedCapturing(P4 , P5 , 2)isFree(P4 , 1)isFailedCaptured(P4 , 1)isFree(P4 , 2)isFailedCaptured(P4 , 2)isFree(P4 , 3)isFailedCaptured(P4 , 3)isFree(P5 , 1)isFailedCaptured(P5 , 1)isFree(P5 , 2)isFailedCaptured(P5 , 2)isFree(P5 , 3)isFailedCaptured(P5 , 3)snap(P4 , C17, 1)snap(P4 , C34, 2)snap(P4 , C0, 3)snap(P5 , C6, 1)snap(P5 , C34, 2)snap(P5 , C7, 3)samePlace(P4 , P5 , 2)samePlace(P5 , P4 , 2)Table 2: Two examples logical representation successful (S) well failed (F ) captureevents input Algorithm 1. closed-world assumption applied, thereforeatoms listed assumed false. clarity, omit listing adjacent()predicate.Typical structure learning inductive logic programming techniques start initial (perhaps empty) theory iteratively grow refine order find form fits training datawell. order avoid searching generally huge space hypotheses, declarative bias eitherspecified hand mined data. declarative bias restricts set possible refinements formulas search algorithm apply. Common restrictions include limitingformula length, adding new predicate formula shares least one variablepredicate already present formula. hand, approach, firstgenerate seed theory instantiating activity-related predicate variables. put105fiS ADILEK & K AUTZcontext structure learning, expand input model order generate large seed theory,apply bottom-up (data-driven) learning prune seed theory, whereby training dataguides search formulas remove well optimal set weights remainingformulas. conjecture failed attempt activity always violates least one constraintholds successful executions activity. experiments support conjecture.pruning done steps 3 4 Algorithm 1. function findIncompatibleFormulas(F ,M0S ) returns set hard formulas M0S incompatible set examples failedinteractions F . say formula c compatible respect set examples F Flogically entails c (F |= c). Conversely, F entail c, say c incompatible w.r.t.F . explain find incompatible formulas next section.step 4 Algorithm 1, simply remove incompatible formulas (I) theory.point, MS+F model, hard formulas guaranteed logically consistentexamples failed activities (because removed incompatible hard formulas), wellsuccessful activities (because logically consistent start with). However,soft formulas MS+F missing properly updated weights (in Markov logic, weighthard formula simply set +). Therefore, run Markov logic weight learning using theBeastpackage (step 5).Recall theBeast implements cutting plane meta solving scheme inference Markovlogic, ground ML network reduced integer linear program subsequentlysolved LpSolve ILP solver. chose approach opposed to, e.g., MaxWalkSATmay find solution merely locally optimal, since resulting run times still relativelyshort (under hour even training testing even complex model). Weightslearned discriminatively, directly model posterior conditional probability hidden predicates given observed predicates. set theBeast optimize weights softformulas via supervised on-line learning using margin infused relaxed algorithm (MIRA) weightupdates loss function computed number false positives false negativeshidden atoms. Note soft formulas truly irrelevant respecttraining examples, picked findIncompatibleFormulas() function,weights set zero (or close zero) weight learning step (line 5 Algorithm 1).zero-weighted formulas subsequently removed following step. Note weightlearning process need experience cold start, initial setting weightsinherited input theory MS .Finally, return learned theory MS+F , whose formulas optimally weighted respect training examples. Experiments Results section below, use MS+Frecognize successful failed activities. Algorithm 1 also returns incompatible hard formulas I. see used extract intended goal activities Section 5.3,first, let us discuss step 3 Algorithm 1 detail.5.2.2 C ONSISTENCY C HECK : F INDING NCOMPATIBLE F ORMULASturn method finding incompatible formulas (summarized Algorithm 2). Sincemethod leverages satisfiability testing determine consistency candidate theoriespossible worlds (examples),6 Algorithm 2 viewed instance learninginterpretationsa learning setting inductive logic programming literature (De Raedt, 2008).6. often referred covers relation inductive logic programming.106fiL OCATION -BASED R EASONING C OMPLEX ULTI -AGENT B EHAVIORAlgorithm 2 (findIncompatibleFormulas). Find formulas ML theory logically inconsistent examples execution failed activities.Input: F : set examples failed activities: unrefined ML theory successful failed activitiesOutput: smallest set formulas appear unsatisfiable worlds F1:2:3:4:5:6:7:8:9:10:11:12:13:extractObjects(F )Thard \ Tsoftinteger n 0boolean result falseresult == falsec Thardremove new n-tuple formulas ccurrent n, n-tuples testednn+1endresult testSAT(F , c , O)endreturn Thard \ cinput, take set examples failed activities F seed theory (e.g., producedstep 2 Algorithm 1). output smallest set hard formulas appearlogically inconsistent F . algorithm first extracts set objects appearF (step 1 Algorithm 2), keeping track type object. example, suppose two example worlds F shown Table 3. extractObjects(F ) returns{P1 , P2 , P7 , P8 , C3 , C5 , 1, 2}.Example 1snap(P1 , C5 , 1)snap(P2 , C5 , 1)failedCapturing(P1 , P2 , 1)Example 2snap(P7 , C3 , 2)snap(P8 , C3 , 2)failedFreeing(P2 , P5 , 2)Table 3: Two simple examples logical representation failed capture event.step 2, limit hard formulas testing compatibility. sinceprove incompatibility hard formulas. Soft constraints violated many timesdata yet may want eliminate them. Instead, want merely adjustweights, exactly approach. Therefore, Thard contains hard formulasappear . Next, lines 5 12, check entire unmodified Thard compatible(since n = 0, remove formulas). compatible, return empty setindicating hard formulas original seed theory compatible examples.detect incompatibility, need remove some, perhaps even all, hard formulasorder arrive logically consistent theory. Therefore, incrementally start removing n-tuplesformulas. is, subsequent |Thard | iterations loop, determine107fiS ADILEK & K AUTZrestore consistency removing one hard formulas Thard . can, returnset Thard \ fi , fi identified removed incompatible formula. consistency cannotrestored removing single formula, turn begin considering pairs formulas (n = 2),triples (n = 3), etc. find pruned theory c consistent examples.general, need consider n-tuples formulas, rather testing formulaisolation. due disjunctive formulas conjunction possibly incomplete truthassignment training data. Consider following theory propositional logic:f1 = bf2 = b cData: c(Following closed-world assumption, negated atom c would actually appear training data, explicitly include example clarity.) f1 f2 individually consistent data, f1 f2 inconsistent data. complicated examplesconstructed, every group k formulas inconsistent data, even thoughindividual formulas are. special case truth values atoms training examples known, formulas tested consistency individually, reduces originalexponential number iterations Algorithm 2 executes, worst case, linear complexity.interesting direction future work explore applications logical methods lowercomputational cost general case partially observed data.also note hard formulas model physical constraints inviolable rules captureflag, therefore hold universally. Appropriately, formulas eliminated Algorithm 2. example, consider formula H1 Figure 5, asserts player occupiesexactly one cell given time. formula satisfied games include successful failed activities. hand, consider formula H8 figure. containscaptured player cell captured (following captured players cannot move ruleCTF). holds successful capturing events, necessarily hold failedattempts capturing. Therefore, rule H8 expanded via second-order ML,derived formulas going consistent observations.Specifically, candidate formula Equation 6 pruned away, inconsistenttraining examples, i.e., players nearly captured continue free move about.However, remaining three variants formula H8 pruned away. Equation 7always evaluate true, since someone attempts re-capture already captured player a,indeed remain stationary. Similarly, Equation 8 also consistent example CTF gamesfailed attempt capture immediately followed successful capture,captured player remain place time onward. Finally, Equation 9 compatible well,since original formula H8 consistent observations.a, t, c : isFailedCaptured(a, t) isFailedCaptured(a, + 1) snap(a, c, t) snap(a, c, + 1)(6)a, t, c : isCaptured(a, t) isFailedCaptured(a, + 1) snap(a, c, t) snap(a, c, + 1) (7)108fiL OCATION -BASED R EASONING C OMPLEX ULTI -AGENT B EHAVIORa, t, c : isFailedCaptured(a, t) isCaptured(a, + 1) snap(a, c, t) snap(a, c, + 1) (8)a, t, c : isCaptured(a, t) isCaptured(a, + 1) snap(a, c, t) snap(a, c, + 1)(9)function testSAT() (line 11 Algorithm 2) checks whether given candidate theory ccompatible examples F following process. First, ground c using objectsO, thereby creating ground theory G. example, c = {p(x) q(x)} = {B, W },grounding would G = {p(B) q(B), p(W ) q(W )}. check G Fhiddensatisfiable using miniSAT solver, Fhidden simply set hidden atoms appearF . Intuitively, corresponds testing whether plug worlds F csatisfying hard constraints. Though satisfiability NP-complete problem, practicetestSAT() completes within tenths second even largest problems CTF domain.instance, suppose Fhidden = {p(B), q(B)}. test satisfiability formulap(B) q(B) p(W ) q(W ) p(B) q(B).case cannot satisfy since forced set p(B) true q(B) false,renders first clauseand therefore whole formulafalse.alternative approach pruning formulas via satisfiability testing, described,would treat types formulas (hard soft) inflated theory M0S strictly softformulas learning weight formula examples successful failed gameevents. However, introduces several complications negatively impact systems performance well model clarity. First, number formulas inflated theoryexponentially larger seed theory. instantiation second-order ML representation quantified limit expansion, still worst-case exponential blow-up.treating formulas soft ones, need potentially learn many weights.especially problematic activities occur rarely, may enough training dataproperly learn weights. Eliminating hard candidate formulas proving inconsistentdramatically reduces number parameters model. satisfiability testingNP-complete, weight learning Markov logic entails running inference multiple times,#P-complete problem.second reason distinguishing soft hard formulas resulting clarityelegance final learned model MS+F . Even situations enough training dataproperly learn large number weights, run overfitting problems, neitherstructure parameters model represent domain natural way. experimentsshown skip pruning stage (steps 3 4 Algorithm 1), models recognitionperformance differ pruned model significant way (p-value 0.45).However, end large number soft formulas mixture positive negativeweights learning algorithm carefully tuned balanced fit training data.however bear little relationship concepts underlying domain. makehard human expert analyze model, makes even harder modifymodel.109fiS ADILEK & K AUTZreasons, softening hard formulas is, general, infeasible. interesting directionfuture work identify small amount key inconsistent hard formulas soften,eliminating rest inconsistent hard formulas. however entails searching largespace candidate subsets softened formulas, iteration requires expensive re-learningweights.Note Algorithm 2 terminates soon finds compatible theory requires smallestnumber formula-removals. also experimented active learning componentsystem, modify Algorithms 1 2 present several possible refinementstheory user selects one looks best. proposed modificationsshown ML theory level modified sections (formulas) highlighted welldata level program shows inferred consequences modifications.candidate modification, corresponding consequences displayed collection animationsanimation shows results activity recognition would committedparticular candidate theory. Note even people background MLinteract system since visualization easy understand. Interestingly, casecaptures frees, least modified theory off-line version algorithm findsalso best one therefore need query user. One view differentialvariant Occams razor. However, different activities domains, active learningapproach may worth revisiting leave exploration future work.Finally, general structure learning techniques statistical-relational AI inductivelogic programming applicable substitute theory augmentation algorithmseveral reasons. main reason that, efficiency reasons, existing techniques literaturetypically operate restricted set formula templates. is, consider Hornclauses, formulas without existential quantifier, formulas k literalsl variables, on. set restrictions part language bias givenapproach. principle, structure learning possible without language bias, one oftencarefully define one sake tractability (see Section 7 details). approach,language bias defined implicitly discussed Section 5.2.1.5.3 Extracting Goal Success FailureRecall applying theory augmentation process (Algorithm 1) CTF seed theorysuccessful interactions (shown Figures 5 6) induces new set formulas capturestructure failed activities ties together existing formulas seed theory.logically inconsistent formulas Algorithm 2 returns ones satisfiableworlds failed activities. time, variants formulas consistentexamples successful actions occurring games. Therefore, represents differencetheory models successful activities augmented theory successfulfailed actions, derived it. Intuitively, difference successfailure viewed intended purpose given activity rational agent executes,consequently goal agent mind engages particular activity.next section, explore goals extracted CTF domain fashion.concludes discussion models methodology, turn experimentalevaluation framework presented above.110fiL OCATION -BASED R EASONING C OMPLEX ULTI -AGENT B EHAVIOR6. Experiments Resultsevaluate approach along three major directions outlined Section 5 (Methodology),focusing answering four research questions formulated ibidem. structuresection closely follows Methodology section.nutshell, first interested Markov logic models perform standardmulti-agent activity recognition tasklabeling successful activitiesand performancecompares alternative models. Second, examine augmented model capturessuccessful failed attempts activities. model MS+F induced Algorithm 1,also lets us extract intended goal activities question. Third, compare performanceMS+F task jointly recognizing four activities alternative model.Finally, investigate extent reasoning failed attempts help recognitionsuccessfully executed activities.experiments performed capture flag dataset consisting four separate games.dataset summarized Table 4, game list number raw GPS readingsnumber instances activity interest. evaluate models via four-fold crossvalidation, always training three games (if training required model) testingfourth. experimental condition below, report precision, recall, F1 scores attainedrespective model four cross-validation runs. purposefully chosensplit data cross-validation fold directly corresponds separate game CTFconceptual convenience clarity. discussed above, events occurring games oftenfar-reaching consequences. example, captured players never freed allies.Therefore, capture beginning game typically profoundly influences entire restgame. reason, splitting games randomly even manually would introduce unnecessarycomplications, segments would dependencies segments. enforcingfold exactly corresponds different game, make fold self-contained.quantify statistical significance pair-wise differences models, usegeneralized probabilistic interpretation F1 score (Goutte & Gaussier, 2005). Namely, expressF1 scores terms gamma variates derived models true positives, false positives, falsenegatives ( = 0.5, h = 1.0, cf., Goutte & Gaussier, 2005). approach makes possiblecompare results future work may apply alternative models similar, identical,datasets. future comparison may, instance, include additional games introduce randomsplits data. note standard statistical significance tests cannot applied situations. p-values reported one sided, interested models performance significantlyimproves level sophistication increases.6.1 Recognition Successful ActivitiesRecall two-step (2SML) unified (UML) Markov logic models, specifyMarkov logic formulas hand optimize weights soft formulas via supervised online learning. run modified version theBeast software package perform weight learningMAP inference. theBeast implements cutting plane meta solving scheme inferenceMarkov logic, ground ML network reduced integer linear program subsequently solved LpSolve ILP solver. chose approach opposed to, e.g., MaxWalkSATget stuck local optimum, since resulting run times still relatively short (underhour even training testing even complex model).111fiS ADILEK & K AUTZGame 1Game 2Game 3Game 4Total#GPS13,41214,4203,47210,85042,154#AC226313#FC153412465#AF22015#FF11204Table 4: CTF dataset overview: #GPS total number raw GPS readings, #AC #FCnumber actual (successful) failed captures respectively, analogously freeings(#AF #FF).weight learning time, use margin infused relaxed algorithm (MIRA) weight updates loss function computed number false positives false negativeshidden atoms, described Methodology section. discretization stepdynamic Bayesian network model (DBN) implemented Markov logic also executedfashion. DBN model trained via maximum likelihood described Section 4.2.two deterministic baselines (B B+S) require training phase.inference time, interested likely explanation data. Markov logic,maximum posteriori inference reduces finding complete truth assignment satisfieshard constraints maximizing sum weights satisfied soft formulas. testingtime, theBeast Markov logic solver finds likely truth assignment hidden atomsdescribed above, section specifically interested values capturingfreeing atoms.DBNs, likely explanation observations equivalent Viterbi decoding.DBN model assigns either free captured state player every time step. labeltransitions free captured state capturing transitions captured freefreeing. Note DBN model capable determining player freed captured,model player freeing capturing. evaluation, givebenefit doubt assume always outputs correct actor.models, inference done simultaneously entire game (on average, 10minutes worth data). Note restrict inference (small) sliding time window.experiments described show, many events domain definitely recognizedlong occur. example, GPS noise may make impossible determine whether playercaptured moment encounter enemy, player thereafter remainsplace long time, possibility capture becomes certain.Figures 7 8 summarize performance models successful capturing freeingterms precision, recall, F1 score calculated four cross-validation runs. clarity,present results two separate plots, model jointly labeling capturingfreeing activities. consider baseline model freeing recognition activitymakes little sense without notion player state (captured free).see unified approach yields best results activities. Let us focuscapturing first (Figure 7). Overall, unified model labels 11 13 captures correctlythere112fiL OCATION -BASED R EASONING C OMPLEX ULTI -AGENT B EHAVIORCapturing Recogni/on1.001.000.800.690.690.770.870.771.000.920.850.60Precision0.400.200.00Recall0.260.160.01 0.020.03 0.06BB+SF1DBN2SMLUMLFigure 7: Comparison performance five models capturing recognition jointinference capturing freeing events. See Table 5 statistical significanceanalysis pairwise differences models. (B = baseline model, B+S = baselinemodel states, 2SML = two-step Markov logic model, UML = unified Markov logicmodel)two false negatives. fact, two capture events missed modelsinvolve two enemies appear unusually far apart (about 12 meters) raw data. Evenunified approach fails instance since cost adjusting players trajectoriestherebylosing score due violation geometry-based constraintsis compensatedpotential gain labeling additional capture.Note even two-step approach recognizes 10 13 captures. comparedunified model, misses one additional instance involved players, moderatelyfar apart, snapped mutually nonadjacent cells. hand, unified modelfail situation limited prior nonrelational snapping nearby cells.However, difference performance dataset statistically significant even0.05 level (p-value 0.32).deterministic baseline models (B B+S) perform poorly. Although yieldrespectable recall, produce overwhelming amount false positives. shows evenrelatively comprehensive pattern matching work domain. Interestingly,performance DBN model leaves much desired well, especially terms precision.DBN model significantly better baselines (p-value less 5.9 105 ),also achieves significantly worse performance Markov logic models (p-value less0.0002; see Table 5).Table 5 summarizes p-values pairwise differences models actual (i.e., successful)capturing. difference Markov logic-based models (2SML UML)113fiS ADILEK & K AUTZFreeing Recogni+on1.001.001.000.800.750.570.600.400.400.200.200.150.130.220.60Precision0.40Recall0.29F10.00B+SDBN2-SMLUMLFigure 8: Comparison performance three models freeing recognition jointinference capturing freeing events. See Table 6 statistical significanceanalysis pairwise differences models. (B+S = baseline model states,2SML = two-step Markov logic model, UML = unified Markov logic model)BB+SDBN2SMLB+S0.0192-DBN3.6 1065.9 105-2SML5.1 1079.4 1060.0002-UML2.9 1071.4 1068.0 1050.3230Table 5: Summary statistical significance (one sided p-values) pairwise differences F1 scores models actual capturing. (B = baseline model, B+S = baselinemodel states, DBN = dynamic Bayesian network model, 2SML = two-step Markovlogic model, UML = unified Markov logic model)statistically significant (p-value 0.32), pairwise differences F1 scores modelssignificant 0.02 level, often even much lower p-values.Though unified model still outperforms alternatives case freeing recognitionwell, performance ideal compared capture recognition case (Figure 8).correctly identifies 3 5 freeing events games, produce falsepositives. partly due dependency freeing capturing. failure modelrecognize capture precludes recognition future freeing. Another reason extremesparseness freeing events (there five 40,000+ datapoints). Finally,114fiL OCATION -BASED R EASONING C OMPLEX ULTI -AGENT B EHAVIORB+SDBN2SMLDBN0.2739-2SML0.07330.1672-UML0.01620.04970.2743Table 6: Summary statistical significance (one sided p-values) pairwise differences F1 scores models actual freeing. (B+S = baseline model states, DBN =dynamic Bayesian network model, 2SML = two-step Markov logic model, UML = unifiedMarkov logic model)instances players barely move freed. may occur number reasonsranging already occupying strategic spot simply tired. freeing instanceschallenging automated system, even people familiar game recognize(several situations would extremely hard disambiguate didnt accessnotes data collection).two-step ML model slightly worse job unified model freeing recognition.correctly identifies 2 5 freeings reasons capturing recognitioncase. Similarly models actual captures, difference unified two-step freeingmodels statistically significant (p-value 0.27).Table 6 summarizes p-values pairwise differences models actual (i.e., successful) freeing. see difference B+S UML models statisticallysignificant (p-value 0.01), whereas differences rest model pairsstatistically significant. Since five instances successful freeing, 2SML modelperform significantly better B+S model 0.05 significance level (p-value0.07). However, UML model achieves better recognition results even DBN modelhigh confidence (p-value less 0.05). Therefore, see although 2SML model strictlydominates non-Markov logic models evaluated capturing recognition, need fullpower unified ML model strictly outperform nonrelational alternatives freeing.suggests move complex interdependent activities, relational unifiedmodeling approaches winning larger larger margins.Even though statistical significance tests suggest 2SML likely give similar resultsUML, important note 2SML, design, precludes recognition activities questioncertain situations. Namely, experiments demonstrate, players snapped cellsfar apart, two-step model even consider instances candidateslabeling, inevitably fails recognizing them. Therefore, one needs look beyond p-valuesobtained comparing fully unified models various alternatives.expected experiments capturing recognition, deterministic baseline models perform poorly freeing recognition well. produce overwhelmingamount false positives, also fail recognize freeing events.Thus, see models cast Markov logic perform significantly betterdeterministic baseline models, also better probabilistic, nonrelational, DBN model.note DBN model potential quite powerful similar DBNsapplied great success previous work activity recognition location data (Eagle &115fiS ADILEK & K AUTZPentland, 2006; Liao, Patterson, Fox, & Kautz, 2007). also many similarities twostep ML model. share denoising discretization step, operateobserved data. key difference DBN model considers players individually,whereas two-step ML model performs joint reasoning.Looking actual CTF game data, see several concrete examples hurts DBNslabeling accuracy. instance, consider situation two allies captured nearother. Performing inference individual players isolation allows DBN model infertwo players effectively free other, even though reality captured cannotso. occurs DBN model oblivious explicit states ones teammateswell opponents. Since capturing freeing interdependent, obliviousness DBNmodel state actors negatively impacts recognition performance activities.example gave illustrates one type freeing false positives. hallucinated freeingscreate opportunities often lead false positives captures, creating vicious cycle. Falsenegatives freeing (capturing) events often occur players model incorrectly believesalready freed (captured) prior time.Since Markov logic based models significantly betterwith high level confidencealternatives fully relational, experiments validate hypothesisneed exploit rich relational temporal structure domain probabilistic waytime affirmatively answer research question Q1 (Can reliably recognize complexmulti-agent activities CTF dataset even presence severe noise?). Namely, showalthough relatively powerful probabilistic models sufficient achieve high labelingaccuracy, gain significant improvements formulating recognition problem learninginference Markov logic networks.turn evaluation method learning models success failurepeoples activities.6.2 Learned Formulas IntentionsApplying theory augmentation process (Algorithm 1) CTF seed theory (shown Figures 5 6) induces new set formulas capture structure failed activities tiestogether existing formulas theory. call model MS+F . Figure 9 showsexamples new weighted formulas modeling failed freeing capturing attempts appearMS+F .First, note system correctly carries basic preconditions activity (contrastformulas S4 S40 S5 S50 Figures 6 9 respectively). allows reliablyrecognize successful failed actions instead of, e.g., merely labeling eventspoint time appear resemble capture near-capture. re-use preconditions directlyfollows language bias theory augmentation algorithm.Turning attention learned hard formulas, observe system correctly inducedequivalence classes states, also derived mutual exclusion relationships (H50 ).furthermore tied new failure states corresponding instantaneous interactions (H60H70 ).Finally, algorithm correctly discovers rule player capturedmust remain location (H8, Figure 5) key distinction successfulfailed capture (since players actually captured still move). Therefore, introduces116fiL OCATION -BASED R EASONING C OMPLEX ULTI -AGENT B EHAVIORappropriate rule failed captures (H80 , Figure 9) explicitly stating failed capturingconfine near-captured player remain stationary. analogous process yields fittingseparation failed successful freeings. Namely, model learns unsuccessfullyfreed player remains stationary. learned difference success failure playersactions directly corresponds goal activity consequently intent rational actors. difference system outputs intended goal capturing activity (andanalogously freeing).experimental results provide evidence resounding yes Q2 (Can modelsattempted activities automatically learned leveraging existing models successfully performed actions?) Q3 (Does modeling success failure allow us infer respectivegoals activities?) within CTF domain.note instead applying automated theory augmentation method, person could,principle, manually formulate Markov logic theory successful well failed activitiesobserving games. all, designed initial seed model successfulevents. However, process extremely time consuming, one tends omit encoding factsus, humans, seem self-evident need explicitly articulated machine (e.g.,single person cannot ten different places once, player either free capturedboth). also surprisingly easy introduce errors theory, difficult debug,mostly complex weight learning techniques involved. Therefore, believetheory augmentation method significant step forward enhancing models capabilitiesrequiring small amounts human effort. complexity domains models increases,advantage gain larger larger importance.6.3 Recognition Successful Failed Activitiescompare performance model MS+F alternative (baseline) methodlabels four activities following way. Similarly baseline states model successful interactions defined Section 5.1, two separate stages. First snap GPSreading nearest cell applying geometric constraints (H1 S1S3) theory, afterward label instances activities. following labeling rule applied.loop whole discretized (via snapping) data set look instances pairplayers b snapped (in first step) either cell two adjacent cellstime t, enemies, b captured already, home territory b not.b moves (is snapped different cell later time) without ally nearby, outputfailedCapturing(a,b,t), otherwise output capturing(a,b,t). labeling rule freeing defined analogously four events tied together. also tested variant DBN modelintroduced Section 5.1 two additional hidden state values node St : isFailedFreeisFailedCaptured. However, difference results obtained model statistically significant (p-value 0.38), therefore focus conceptually straightforwardbaseline model described above.Model MS+F evaluated using four-fold cross-validation (always training three gamestesting fourth). Figure 10 compares models terms precision, recall, F1score. Note four activities modeled jointly models. F1 score augmentedmodel significantly better baseline four target activities (p-value less1.3 104 ).117fiS ADILEK & K AUTZa1 , a2 , : [(enemies(a1 , a2 ) onHomeTer(a1 , t)(S40 )onEnemyTer(a2 , t) samePlace(a1 , a2 , t) isFree(a1 , t)isFree(a2 , t)) failedCapturing(a1 , a2 , t)] 11.206a1 , a2 , : [(enemies(a1 , a2 ) onEnemyTer(a1 , t)(S50 )onEnemyTer(a2 , t) samePlace(a1 , a2 , t) isFree(a1 , t)isCaptured(a2 , t)) failedFreeing(a1 , a2 , t)] 1.483a1 , a2 , : [failedCapturing(a1 , a2 , t)] (0.0001)(S60 )a1 , a2 , : [failedFreeing(a1 , a2 , t)] (0.002)(S70 )a, : isFailedCaptured(a, t) isFree(a, t)(H50 )a, : isCaptured(a, t) isFailedFree(a, t)a, : isFailedCaptured(a, t) isFree(a, t)a, : isCaptured(a, t) isFailedFree(a, t)a, : (isFree(a, t) isFailedCaptured(a, + 1)) (=1 a1 : failedCapturing(a1 , a, t))a, : (isCaptured(a, t) isFailedFree(a, + 1)) (=1 a1 : failedFreeing(a1 , a, t))(H60 )(H70 )a, t, c : (isFailedCaptured(a, t) isFailedCaptured(a, + 1) snap(a, c, t)) snap(a, c, + 1)(H80 )Figure 9: Example formulas, learned Algorithm 1, model unsuccessful capturing freeing events. crucial intent recognition formula (H80 ) highlighted bold. Formulaseliminated Algorithm 2 preceded symbol, includedinduced model MS+F . identity isCaptured(a, t) = isFree(a, t) applied throughout refining show formulas intuitive fashion. concreteness sake,values learned weights come one cross-validation run (and similarruns).see baseline model has, general, respectable recall produces largenumber false positives activities. false positives stem fact algorithmgreedy typically labels situation several players appear closecertain period time sequence many captures subsequent frees even though noneactually occurred. Model MS+F gives significantly better results takes fulladvantage structure game probabilistic fashion. similar labelingtendency case failed captures, single capture attempt often labeledseveral consecutive attempts. hurts precision score, significant deficiency,118fiL OCATION -BASED R EASONING C OMPLEX ULTI -AGENT B EHAVIOR0.15BaselineAC (13)0.23FC (65)0.970.130.04AF (5)0.400.020.06FF (4)Augmented ML Model0.460.09F10.750.03Recall0.960.921.00AC (13)0.86FC (65)0.78AF (5)0.80FF (4)0.7500.10.20.30.40.50.60.70.8Precision0.970.891.000.861.000.91Figure 10: Performance baseline augmented (MS+F ) models joint recognitionsuccessful failed capturing freeing. F1 score augmented modelsignificantly better baseline four target activities (p-value less1.3 104 ). AC = actual (successful) capturing, FC = failed capturing, AF =actual freeing, FF = failed freeing.practice, small number short game segments labeled possible near-capturesuseful well.also note even though original model (UML) contain informationfailed capturing failed freeing, performance MS+F respectable even twonewly introduced activities. provided examples game situations attemptsoccur system augmented subsequently labeled four activities. Thus, seeindeed extend preexisting models automated fashion unified modelcapable recognizing individual activities, also success failure peoplesbehavior.6.4 Effect Modeling Failed Attempts Recognition Successful Activitiesaddress research question Q4 (Does modeling failed attempts activities improve performance recognizing activities themselves?), want see much recognitionattempted activities help modeling successful actions (the latter standard activity119fiS ADILEK & K AUTZCapturingF10.92Recall0.85Precision+0.081.00F1Freeing+0.040.75Recall+0.140.60+0.20Precision1.0000.10.20.30.4Without Modeling Failure0.50.60.70.80.91Modeling FailureFigure 11: Considering unsuccessfully attempted activities strictly improves performance standard activity recognition. Blue bars show scores obtained unified Markov logicmodel considers successful activities (MS ). red bars indicate additive improvement provided augmented model considers successfulfailed activities (MS+F , output Algorithm 1). model labels target activities jointly, separate capturing freeing plot clarity. Precision value1 models. F1 scores obtained explicitly modeling failed attemptsstatistically different F1 scores obtained without modeling attempts highconfidence level (p-value 0.20). However, results still show importancereasoning peoples attempts recognizing activities; see text details.recognition problem). Toward end, compare Markov logic model MS jointly labelssuccessful capturing freeing model MS+F jointly labels successfulfailed attempts capturing freeing (see Section 5.2.1 detailed description twomodels). However, evaluate terms precision, recall, F1 score successfulinteractions, four types activities.Figure 11 summarizes results. see evaluated actual capturing, MS+Fperforms better MS , similarly freeing. However, difference F1 scoresmodel captures attempted successful activities (MS+F ) model successful activities (MS ) statistically significant (p-value 0.20). partly MSalready produces solid results, leaving little room improvement. Additionally, CTFdataset contains relatively events interest. terms labeling performance testing time,difference two models 11% (MS MS+F recognize, respectively,120fiL OCATION -BASED R EASONING C OMPLEX ULTI -AGENT B EHAVIOR14 16 18 successful activities correctly). Thus, believe trends shown Figure 11promising modeling attempted actions improve recognition performance capturing freeing, evaluation dataset larger number events needed showdifference statistically significant higher confidence level. However, meanrecognizing attempts unimportant. show above, induced augmented modelrecognize failed (as well successful) activities complex CTF domain high accuracy,argue significant contribution.Finally, comparison MS MS+F shows applying learning algorithm augments model recognition capabilities hurt model labeling performance.fact binary classification problems typically easier solve multi-class counterparts well reported machine learning literature (Allwein, Schapire, & Singer, 2001).Therefore, introducing new activities model, especially automated way, likely degrade performance. Contrary intuition, experiments show MS+F worseMS successful activity recognition (i.e., intersection) high confidence, even thoughMS+F clearly richer useful.7. Related Workworld single-agent location-based reasoning, work Bui (2003) presents evaluates system probabilistic plan recognition cast abstract hidden Markov memory model.Subsequently, work Liao et al. (2004) implements system denoising raw GPS tracessimultaneously inferring individuals mode transportation (car, bus, etc.) goal destination. cast problem learning inference dynamic Bayesian network achieveencouraging results. follow-up work, Liao et al. (2005) introduce framework locationbased activity recognition, implemented efficient learning inference relationalMarkov network.work Ashbrook Starner (2003) focuses inferring significant locations rawGPS logs via clustering. transition probabilities important places subsequentlyused number user modeling tasks, including location prediction. work EaglePentland (2006) explores harnessing data collected regular smart phones modeling humanbehavior. Specifically, infer individuals general location nearby cell towers Bluetooth devices various times day. Applying hidden Markov model (HMM), showpredicting person home, work, someplace else achieved 90% accuracy. Similarly, work Eagle Pentland (2009) extracts significant patterns signaturespeoples movement applying eigenanalysis smart phone logs.work Hu, Pan, Zheng, Liu, Yang (2008) concentrates recognition interleavingoverlapping activities. show publicly available academic datasets contain significantnumber instances activities, formulate conditional random field (CRF) modelcapable detecting high (more 80%) accuracy. However, focus solelysingle-agent household activities.Peoples conversation primary focus multi-agent modeling effort (Barbuceanu& Fox, 1995). fields multi-agent activity recognition studies human behavior, researchers either modeled conversation explicitly (e.g., Busetta, Serafini, Singh, & Zini, 2001),leveraged peoples communication implicitly via call location logs mobile phones.data successfully used infer social networks, user mobility patterns, model socially121fiS ADILEK & K AUTZsignificant locations dynamics, others (Eagle & Pentland, 2006; Eagle, Pentland,& Lazer, 2009). arguably excellent stepping stone full-fledged multi-agent activityrecognition since location is, times, practically synonymous ones activity (e.g.,store often implies shopping) (Tang, Lin, Hong, Siewiorek, & Sadeh, 2010), social networkstremendous influence behavior (Pentland, 2008).Additionally, number researchers machine vision worked problem recognizing events videos sporting events, impressive recent work learning modelsbaseball plays (Gupta et al., 2009). work area focused recognizing individualactions (e.g., catching throwing), state art beginning consider relationalactions (e.g., ball thrown player player B). computational challenges dealingvideo data make necessary limit time windows seconds. contrast,demonstrate work many events capture flag data disambiguatedconsidering arbitrarily long temporal sequences. general, however, workmachine vision rely upon similar probabilistic models, already evidencestatistical-relational techniques similar Markov logic used activity recognitionvideo (Biswas, Thrun, & Fujimura, 2007; Tran & Davis, 2008).Looking beyond activity recognition, recent work relational spacial reasoning includesattempt locateusing spacial abductioncaches weapons Iraq based informationattacks area (Shakarian, Subrahmanian, & Spaino, 2009). Additionally, work Abowdet al. (1997) presents location- context-aware system, Cyberguide, helps people explorefully experience foreign locations. researchers explore intelligent nonintrusivenavigation system takes advantage predictions traffic conditions along modelusers knowledge competence (Horvitz et al., 2005). Finally, work Kamar Horvitz(2009) explore automatic generation synergistic plans regarding sharing vehicles across multiplecommuters.interesting line work cognitive science focuses intent goal recognition probabilistic framework (Baker, Tenenbaum, & Saxe, 2006, 2007). Specifically, cast goal inferenceinverse planning problem Markov decision processes, Bayesian inversion used estimate posterior distribution possible goals. Recent extensions work begin considersimulated multi-agent domains (Baker, Goodman, & Tenenbaum, 2008; Ullman, Baker, Macindoe,Evans, Goodman, & Tenenbaum, 2010; Baker, Saxe, & Tenenbaum, 2011). Comparisoncomputational models human judgement synthetic domains shows strong correlationpeoples predicted actual behavior. However, computational challenges involveddealing underlying partially observable Markov decision processes prohibitivecomplex domains large state spaces, ours.focus work different aspect reasoning peoples goals. Ratherinferring distribution possible, priori known goals, automatically induce goalscomplex multi-agent activities themselves.researchers concentrated modeling behavior people general agents reinforcement learning problems single-agent multi-agent settings. work (2008)proposes system household activity recognition cast single-agent Markov decision processproblem subsequently solved using probabilistic model checker. Wilson colleagues address problem learning agents roles multi-agent domain derived real-time strategycomputer game (Wilson, Fern, Ray, & Tadepalli, 2008; Wilson, Fern, & Tadepalli, 2010). Experiments synthetic domain show strongly encouraging results. perform role122fiL OCATION -BASED R EASONING C OMPLEX ULTI -AGENT B EHAVIORlearning ourselves, anticipate work Wilson et al. going play important rolelearning hierarchies peoples activities. capture flag domain, one imagine automatically identifying particular player as, example, defender subsequently leveraginginformation model behavior personalized way.work Hong (2001) concentrates recognizing goal agent courseactivities deterministic, relational setting. Interesting work goal recognitionalso applied computer-aided monitoring complex multi-agent systems, relationshipsagents leveraged compensate noise sparse data (Kaminka, Tambe, Pynadath,& Tambe, 2002). contrast, work focus learning respective goals given setmulti-agent activities probabilistic setting. knowledge turn leveraged achievestronger robustness recognition tasks. Similarly approach Hong, systemneed supplied plan library either.work also touches anomaly detection since system reasons failed attemptsplayers. Anomaly detection concerns revealing segments dataway violate expectations. excellent survey subject, refer readerresults Chandola, Banerjee, Kumar (2009). realm anomaly detection within peoplesactivities, work Moore Essa (2001) addresses problem error detection recoverycard games involve two players recorded video. system models domainstochastic context-free grammar achieves excellent results.note recognizing failed attempt activity fine-grained problemanomaly detection. failed event anomalous general.7 Rather, specificdistinction success failure human activities interested in. distinction lies fact unsuccessful attempt yield certain desired state whereassuccessful action does. desired state exactly approach extracts activityquestion. knowledge, exists prior work explicit modeling recognitionattempted activities learning intended purpose activity multi-agent setting.One components contribution focuses joint learning inference across multiple tasks (capturing, freeing, respective attempted counterparts). contrasttraditional pipeline learning architecture, system decomposed series modules module performs partial computation passes result next stage.main benefits set-up reduced computational complexity often higher modularity.However, since stage myopic, may take full advantage dependencies broaderpatterns within data. Additionally, even though errors introduced module may small,accumulate beyond tolerable levels data passes pipeline.extensive body work shown joint reasoning improves model performancenumber natural language processing data mining tasks including information extraction (i.e.,text segmentation coupled entity resolution) (Poon & Domingos, 2007), co-reference resolution (Poon & Domingos, 2008), information extraction coupled co-reference resolution (Wellner, McCallum, Peng, & Hay, 2004), temporal relation identification (Yoshikawa, Riedel, Asahara,& Matsumoto, 2009; Ling & Weld, 2010), record de-duplication (Domingos, 2004; Culotta& McCallum, 2005). Similarly work, models cast Markov logic.However, prior work uses sampling techniques perform learning inference, whereas apply7. situation player CTF moves campus speed 100 mph way passes enemyplayer certainly anomalous (and probably caused GPS sensor noise), want say failedattempt capturing.123fiS ADILEK & K AUTZreduction integer linear programming. Interestingly, work Denis Baldridge (2007)jointly addresses problems anaphoricity co-reference via manual formulationinteger linear program.Joint activity modeling also shown yield better recognition accuracy, comparedpipeline baselines well baselines make strong inter-activity independence assumptions.work Wu, Lian, Hsu (2007) performs joint learning inference concurrent singleagent activities using factorial conditional random field model. Similarly, work Helaoui,Niepert, Stuckenschmidt (2010) models interleaved activities Markov logic. distinguishforeground background activities infer time window activity takesplace RFID sensory data. contrast, focus joint reasoning multi-agent activitiesattempts fully relationaland arguably significantly noisysetting.work Manfredotti, Hamilton, Zilles (2010) propose hierarchical activity recognitionsystem formulated learning inference relational dynamic Bayesian networks. modeljointly leverages observed interactions individual objects domain relationshipsobjects. Since method outperforms hidden Markov model significant margin,contributes additional experimental evidence relational decomposition domain improvesmodel quality.work Landwehr, Gutmann, Thon, Philipose, De Raedt (2007) casts single-agentactivity recognition relational transformation learning problem, building transformationbased tagging natural language processing. system induces set transformation rulesused infer activities sensory data. Since transformation rules appliedadaptively, step, system leverages observed data, also currently assignedlabels (inferred activities). However, transformation rules learned greedy fashionexperiments show model perform significantly better simple HMM.hand, representation quite general, intuitive, extensible. see,Markov logic model similar level representational convenience performing globalinstead greedyoptimization significantly complex domain.denoising component model formulated tracking problem. Prior workproposed relational dynamic Bayesian network model multi-agent tracking (Manfredotti &Messina, 2009). evaluation shows considering relationships tracked entitiessignificantly improves model performance, compared nonrelational particle filter baseline.contrast, work explores joint tracking activity recognition. However, GPS readingannotated identity corresponding agent. work Manfredotti Messinasuggests model generalized, associations GPS agentidentities inferred need observed.Markov logic theory viewed template conditional random field (Lafferty,2001), undirected graphical model captures conditional probability hidden labelsgiven observations, rather joint probability labels observations, one wouldtypically directed graphical model. relational world, directed formalisms includerelational Bayesian networks (Jaeger, 1997) dynamic counterparts (Manfredotti, 2009),probabilistic relational models (Koller, 1999; Friedman, Getoor, Koller, & Pfeffer, 1999), Bayesianlogic programs (Kersting & De Raedt, 2000), first-order conditional influence language (Natarajan, Tadepalli, Altendorf, Dietterich, Fern, & Restificar, 2005). Conditional random fieldsextensively applied activity recognition, superior labeling performance generativemodels demonstrated number single-agent multi-agent domains (Liao124fiL OCATION -BASED R EASONING C OMPLEX ULTI -AGENT B EHAVIORet al., 2005; Limketkai, Fox, & Liao, 2007; Vail, 2008; Vail & Veloso, 2008; Hu et al., 2008).Since MLNs often solved propositionalized CRFs, directed alternatives compiled Bayesian network, expected discriminative relational models generallyoutperform generative counterparts labeling tasks. However, work needs doneanswer question entirety.Since Markov logic based on, fact subsumes, finite first-order logic, immediatelygain access number techniques developed rich field traditional logic. Current Markovlogic solvers take advantage underlying logical structure perform powerful optimizations, Alchemys lifted inference belief propagation MC-SAT (Poon & Domingos,2006). Additionally, domain pruning, one uses hard constraints infer reduced domainspredicates, shown lead significant speed-ups (Papai, Singla, & Kautz, 2011).also leverage relationship Markov first-order logic inducing augmented model. Furthermore, presence dependency cycles introduces additional problemsdirected graphical (relational) models. Thus, fact that, Markov logic, knowledgeexpressed weighted first-order formulas combined factors make powerfulframework best suited multi-agent reasoning tasks considered work.Traditional hidden Markov models operate alphabet unstructured (i.e., flat) symbols. makes relational reasoning difficult, one either propositionalize domain,thereby incurring combinatorial increase number symbols model parameters, ignorerelational structure sacrifice information. Logical hidden Markov models (LHMMs)proposed address problem (Kersting, De Raedt, & Raiko, 2006). LHMMs generalization standard HMMs compactly represents probability distributions sequenceslogical atoms rather flat symbols. LHMMs proven strictly powerfulpropositional counterparts (HMMs). applying techniques logic-based reasoning,unification, leveraging logical structure component model, Kersting et al. showLHMMs often require fewer parameters achieve higher accuracy HMMs.LHMMs recently applied activity recognition. context intelligent user interfaces, work Shen (2009) designs evaluates LHMM model recognition peoplesactivities workflows carried desktop computer. researchers proposed hierarchical extension LHMMs along efficient particle filter-based inference technique,apply activity recognition problems synthetic domains (Natarajan, Bui, Tadepalli, Kersting,& Wong, 2008). lines work show LHMMs learned applied efficiently,perform better plain HMMs.However, LHMMs generative model therefore ideal pure labelingrecognition tasks, typically want make strong independence assumptionsobservations, want explicitly model dependencies input space. TildeCRFarelational extension traditional conditional random fieldshas introduced addressissue (Gutmann & Kersting, 2006). TildeCRF allows discriminative learning inference CRFsencode sequences logical atoms, opposed sequences unstructured symbols. TildeCRFspecifically focuses efficient learning models sequential data via boosting, subsumedMarkov logic, produce discriminative generative models. cast modellatter framework make general, extensible, interpretable.PRISM, probabilistic extension Prolog, shown subsume wide variety generative models, including Bayesian networks, probabilistic context-free grammars, HMMs (alonglogical extension) (Sato & Kameya, 2001, 2008). However, since focus PRISM125fiS ADILEK & K AUTZrepresentational elegance generality, rather scalability, sheer size state spacecomplexity CTF domain precludes application here.Finally, Markov logic theory augmentation process related structure learning, transfer learning, inductive logic programming. fact, Algorithm 1 implements special casestructure learning, search target theory explains training data well,declarative bias forces target theory differ source theory much necessary.Again, intuition failed attempts similar failed counterparts. numberresearchers focused structure learning specifically Markov logic networks. includesearly work top-down structure learning, clauses knowledge base greedily modified adding, flipping, deleting logical literals (Kok & Domingos, 2005). search guidedlikelihood training data current model. work Mihalkova Mooney(2007) exploit patterns ground Markov logic networks introduce bottom-up declarativebias makes algorithm less susceptible finding local optima, compared alternative greedy methods. Similarly, work Kok Domingos (2009) introduce bottom-updeclarative bias based lifted hypergraph representation relational database. biasguides search clauses fit data. Since hypergraph lifted, relational path findingtractable. Interesting work predicate invention applies relational clustering technique formulatedsecond-order Markov logic discover new predicates relational databases (Kok & Domingos, 2007). systems capable modeling relatively rich family logical formulas.approaches perform discriminative structure learning achieve excellent results, focusrestricted set types formulas (e.g., Horn clauses) (Huynh & Mooney, 2008; Biba, Ferilli, &Esposito, 2008). work Davis Domingos (2009) successfully uses second-order Markovlogic deep transfer learning. lift model source domain second-order MLidentify high-level structural patterns. subsequently serve declarative bias structurelearning target domain.nature, inductive logic programming discipline extensively studied structurelearning deterministic, well probabilistic settings (e.g., Muggleton, 2002; De Raedt, 2008;De Raedt, Frasconi, Kersting, & Muggleton, 2008). fact, theory augmentation algorithmviewed efficient Markov logic based version theory refinement, well-established ILPtechnique aims improve quality theory terms simplicity, fit newly acquireddata, efficiency factors (Wrobel, 1996).approach differs work three main points. First, declarative bias definedimplicitly seed theory successful activities. Therefore, theory augmentation algorithmlimited hard-wired set formula types consider. Rather, search spacedefined run time extracting motifs seed theory. second distinction lies computational tractability exactness results. distinguishing soft hard formulas,able search candidate formulas systematic, rather greedy manner. Consequently, final learned model requires fewer parameters, especially importantamount training data relatively small. Additionally, weight learning experience cold starts, leverage seed theory. final difference that, knowledge,first explore structure learning context interplay success failure,relationship intended goals peoples actions.126fiL OCATION -BASED R EASONING C OMPLEX ULTI -AGENT B EHAVIOR8. Conclusionspaper took task understanding game capture flag GPS dataexemplar general problem inferring human interactions intentions sensor data.presented novel methodologycast Markov logicfor effectively combining datadenoising higher-level relational reasoning complex multi-agent domain. Specifically,demonstrated given raw noisy data, automatically reliably detectrecognize successful failed interactions adversarial well cooperative settings.Additionally, shown success, failure, goal activity intimately tiedtogether model successful events allows us naturally learn modelstwo important aspects life. Specifically, demonstrated intentions rationalagents automatically discovered process resolving inconsistencies theorymodels successful instances set activities examples failed attempts activities.formulated four research questions designed experiments within CTF domainempirically answer them. Compared alternative approaches solving multi-agent activity recognition problem, augmented Markov logic model, takes accountrelationships among individual players, also relationships among activities entire lengthgame, although computationally costly, significantly accurate real-world data.Furthermore, illustrated explicitly modeling unsuccessful attempts boosts performanceimportant recognition tasks.9. Future WorkMulti-agent activity recognition especially interesting context current unprecedentedgrowth on-line social networksin terms size, popularity, impact offline lives. paper, show location information alone allows rich models peoplesinteractions, case on-line social networks, additionally access contentusers posts explicit implicit network interactions. instance, recentstudy shows that, interestingly, 30% Twitter status updates reveal authors location(Sadilek, Kautz, & Bigham, 2012). data sources available machines massivevolumes ever-increasing real-time streaming rate. note substantial fraction postsservices Facebook Twitter talk everyday activities users (Naaman, Boase,& Lai, 2010), information channel become available research communityrecently. Thus, able reason human behavior interactions automatedway, tap colossal amounts knowledge isat presentdistributed across wholepopulation.currently extending model handle explicit GPS traces, also ableinfer location people broadcast GPS coordinates. basic idea is, again,leverage structure relationships among people. vast majority us participate on-linesocial networks typically friends publish location. thus viewGPS-enabled people noisy location sensors use network interactions dynamicsestimate location rest users. present, testing approach publictweets.127fiS ADILEK & K AUTZAcknowledgmentsthank anonymous reviewers constructive feedback. thank Sebastian Riedelhelp theBeast, Radka Sadlkova Wendy Beatty helpful comments.work supported ARO grant #W911NF-08-1-0242, DARPA SBIR Contract #W31P4Q08-C-0170, gift Kodak.ReferencesAbowd, G. D., Atkeson, C. G., Hong, J., Long, S., Kooper, R., & Pinkerton, M. (1997). Cyberguide:mobile context-aware tour guide. Wirel. Netw., 3(5), 421433.Allwein, E., Schapire, R., & Singer, Y. (2001). Reducing multiclass binary: unifying approachmargin classifiers. Journal Machine Learning Research, 1, 113141.Ashbrook, D., & Starner, T. (2003). Using GPS learn significant locations predict movementacross multiple users. Personal Ubiquitous Comput., 7, 275286.Baker, C., Tenenbaum, J., & Saxe, R. (2006). Bayesian models human action understanding.Advances Neural Information Processing Systems, 18, 99.Baker, C., Goodman, N., & Tenenbaum, J. (2008). Theory-based social goal inference. Proceedings thirtieth annual conference cognitive science society, pp. 14471452.Baker, C., Saxe, R., & Tenenbaum, J. (2011). Bayesian theory mind: Modeling joint belief-desireattribution. Proceedings Thirty-Second Annual Conference Cognitive ScienceSociety.Baker, C., Tenenbaum, J., & Saxe, R. (2007). Goal inference inverse planning. Proceedings29th annual meeting cognitive science society.Baldwin, D. A., & Baird, J. A. (2001). Discerning intentions dynamic human action. TrendsCognitive Sciences, 5(4), 171 178.Barbuceanu, M., & Fox, M. (1995). COOL: language describing coordination multiagent systems. Proceedings First International Conference Multi-Agent Systems(ICMAS-95), pp. 1724.Bell, R., Koren, Y., & Volinsky, C. (2007). Modeling relationships multiple scales improveaccuracy large recommender systems. KDD, pp. 95104, New York, NY, USA. ACM.Biba, M., Ferilli, S., & Esposito, F. (2008). Discriminative structure learning Markov logicnetworks.. pp. 5976. Springer.Biswas, R., Thrun, S., & Fujimura, K. (2007). Recognizing activities multiple cues. Workshop Human Motion, pp. 255270.Bui, H. H. (2003). general model online probabilistic plan recognition. Eighteenth International Joint Conference Artificial Intelligence (IJCAI-2003).Busetta, P., Serafini, L., Singh, D., & Zini, F. (2001). Extending multi-agent cooperation overhearing. Cooperative Information Systems, pp. 4052. Springer.Chandola, V., Banerjee, A., & Kumar, V. (2009). Anomaly detection: survey. ACM Comput.Surv., 41, 15:115:58.128fiL OCATION -BASED R EASONING C OMPLEX ULTI -AGENT B EHAVIORCulotta, A., & McCallum, A. (2005). Joint deduplication multiple record types relational data.Proceedings 14th ACM international conference Information knowledgemanagement, pp. 257258. ACM.Davis, J., & Domingos, P. (2009). Deep transfer via second-order Markov logic. Proceedings26th Annual International Conference Machine Learning, pp. 217224. ACM.De Raedt, L. (2008). Logical relational learning. Springer-Verlag New York Inc.De Raedt, L., Frasconi, P., Kersting, K., & Muggleton, S. (Eds.). (2008). Probabilistic InductiveLogic Programming - Theory Applications, Vol. 4911 Lecture Notes ComputerScience. Springer.De Raedt, L., & Kersting, K. (2008). Probabilistic inductive logic programming. (De Raedt et al.,2008), pp. 127.Denis, P., & Baldridge, J. (2007). Joint determination anaphoricity coreference resolutionusing integer programming. Proceedings NAACL HLT, pp. 236243.Domingos, P. (2004). Multi-relational record linkage. Proceedings KDD-2004 WorkshopMulti-Relational Data Mining.Domingos, P., Kok, S., Lowd, D., Poon, H., Richardson, M., & Singla, P. (2008). Markov logic.(De Raedt et al., 2008), pp. 92117.Eagle, N., & Pentland, A. (2006). Reality mining: sensing complex social systems. PersonalUbiquitous Computing, 10(4), 255268.Eagle, N., & Pentland, A. (2009). Eigenbehaviors: Identifying structure routine. BehavioralEcology Sociobiology, 63(7), 10571066.Eagle, N., Pentland, A., & Lazer, D. (2009). Inferring social network structure using mobile phonedata. Proceedings National Academy Sciences.Friedman, N., Getoor, L., Koller, D., & Pfeffer, A. (1999). Learning probabilistic relational models.International Joint Conference Artificial Intelligence, Vol. 16, pp. 13001309.Goutte, C., & Gaussier, E. (2005). probabilistic interpretation precision, recall f-score,implication evaluation.. pp. 345359. Springer.Gupta, A., Srinivasan, P., Shi, J., & Davis, L. S. (2009). Understanding videos, constructing plots:Learning visually grounded storyline model annotated videos. CVPR.Gutmann, B., & Kersting, K. (2006). TildeCRF: conditional random fields logical sequences.Machine Learning: ECML 2006, pp. 174185. Springer.Helaoui, R., Niepert, M., & Stuckenschmidt, H. (2010). statistical-relational activity recognitionframework ambient assisted living systems. Ambient Intelligence Future TrendsInternational Symposium Ambient Intelligence (ISAmI 2010), pp. 247254. Springer.Hong, J. (2001). Goal recognition goal graph analysis. Journal Artificial IntelligenceResearch, 15, 130.Horvitz, E., Apacible, J., Sarin, R., & Liao, L. (2005). Prediction, expectation, surprise: Methods, designs, study deployed traffic forecasting service. Twenty-First ConferenceUncertainty Artificial Intelligence.129fiS ADILEK & K AUTZHu, D., Pan, S., Zheng, V., Liu, N., & Yang, Q. (2008). Real world activity recognition multiplegoals. UbiComp, Vol. 8, pp. 3039.Huynh, T., & Mooney, R. (2008). Discriminative structure parameter learning Markovlogic networks. Proceedings 25th international conference Machine learning,pp. 416423. ACM.Jaeger, M. (1997). Relational Bayesian networks. Proceedings 13th Conference Uncertainty Artificial Intelligence, pp. 266273.Jordan, M. (1998). Learning graphical models. Kluwer Academic Publishers.Kamar, E., & Horvitz, E. (2009). Collaboration shared plans open world: Studiesridesharing. IJCAI.Kaminka, G. A., Tambe, D. V. P. M., Pynadath, D. V., & Tambe, M. (2002). Monitoring teamsoverhearing: multi-agent plan-recognition approach. Journal Artificial IntelligenceResearch, 17, 2002.Kersting, K., & De Raedt, L. (2000). Bayesian logic programs. Proceedings Work-inProgress Track 10th International Conference Inductive Logic Programming.Kersting, K., De Raedt, L., & Raiko, T. (2006). Logical hidden Markov models. Journal ArtificialIntelligence Research, 25(1), 425456.Kok, S., & Domingos, P. (2005). Learning structure Markov logic networks. Proceedings22nd international conference Machine learning, pp. 441448. ACM.Kok, S., & Domingos, P. (2007). Statistical predicate invention. Proceedings 24th international conference Machine learning, pp. 433440. ACM.Kok, S., & Domingos, P. (2009). Learning Markov logic network structure via hypergraph lifting.Proceedings 26th Annual International Conference Machine Learning, pp. 505512.ACM.Kok, S., & Domingos, P. (2007). Statistical predicate invention. ICML 07: Proceedings24th international conference Machine learning, pp. 433440, New York, NY, USA.ACM.Koller, D. (1999). Probabilistic relational models. Inductive Logic Programming, pp. 313.Springer.Lafferty, J. (2001). Conditional random fields: Probabilistic models segmenting labelingsequence data. International Conference Machine Learning (ICML), pp. 282289.Morgan Kaufmann.Landwehr, N., Gutmann, B., Thon, I., Philipose, M., & De Raedt, L. (2007). Relationaltransformation-based tagging human activity recognition. Proceedings 6th International Workshop Multi-relational Data Mining (MRDM07), pp. 8192.Liao, L., Patterson, D., Fox, D., & Kautz, H. (2007). Learning inferring transportation routines.Artificial Intelligence, 171(5-6), 311331.Liao, L., Fox, D., & Kautz, H. (2004). Learning inferring transportation routines. Proceedings Nineteenth National Conference Artificial Intelligence.130fiL OCATION -BASED R EASONING C OMPLEX ULTI -AGENT B EHAVIORLiao, L., Fox, D., & Kautz, H. (2005). Location-based activity recognition using relational Markovnetworks. IJCAI.Limketkai, B., Fox, D., & Liao, L. (2007). CRF-filters: Discriminative particle filters sequentialstate estimation. Robotics Automation, 2007 IEEE International Conference on, pp.31423147.Ling, X., & Weld, D. (2010). Temporal information extraction. Proceedings Twenty FifthNational Conference Artificial Intelligence.Ma, Z. (2008). Modelling PRISM intelligent system. MSc. Thesis, Linacre College, University Oxford.Manfredotti, C. (2009). Modeling inference relational dynamic Bayesian networks.Advances Artificial Intelligence, pp. 287290. Springer.Manfredotti, C., & Messina, E. (2009). Relational dynamic Bayesian networks improve multitarget tracking. Advanced Concepts Intelligent Vision Systems, pp. 528539. Springer.Manfredotti, C., Hamilton, H., & Zilles, S. (2010). Learning RDBNs activity recognition.Neural Information Processing Systems.Mihalkova, L., & Mooney, R. (2007). Bottom-up learning Markov logic network structure.Proceedings 24th international conference Machine learning, pp. 625632. ACM.Moore, D., & Essa, I. (2001). Recognizing multitasked activities using stochastic context-free grammar. Proceedings AAAI Conference.Muggleton, S. (2002). Learning structure parameters stochastic logic programs. Proceedings 12th international conference Inductive logic programming, pp. 198206.Springer-Verlag.Murphy, K. P. (2002). Dynamic bayesian networks: representation, inference learning. Ph.D.thesis, University California, Berkeley.Naaman, M., Boase, J., & Lai, C.-H. (2010). really me?: message content socialawareness streams. CSCW 10: Proceedings 2010 ACM conference Computersupported cooperative work, pp. 189192, New York, NY, USA. ACM.Natarajan, S., Tadepalli, P., Altendorf, E., Dietterich, T., Fern, A., & Restificar, A. (2005). Learningfirst-order probabilistic models combining rules. Proceedings 22nd international conference Machine learning, pp. 609616. ACM.Natarajan, S., Bui, H. H., Tadepalli, P., Kersting, K., & Wong, W. (2008). Logical hierarchicalhidden Markov models modeling user activities. Proc. ILP-08.Papai, T., Singla, P., & Kautz, H. (2011). Constraint propagation efficient inference Markovlogic. Seventeenth International Conference Principles Practice ConstraintProgramming.Pentland, A. S. (2008). Honest Signals: Shape World. MIT Press.Poon, H., & Domingos, P. (2006). Sound efficient inference probabilistic deterministicdependencies. Proceedings National Conference Artificial Intelligence, Vol. 21,p. 458. Menlo Park, CA; Cambridge, MA; London; AAAI Press; MIT Press; 1999.131fiS ADILEK & K AUTZPoon, H., & Domingos, P. (2007). Joint inference information extraction. Proceedings22nd national conference Artificial intelligence-Volume 1, pp. 913918. AAAI Press.Poon, H., & Domingos, P. (2008). Joint unsupervised coreference resolution Markov logic.Proceedings Conference Empirical Methods Natural Language Processing, pp.650659. Association Computational Linguistics.Riedel, S. (2008). Improving accuracy efficiency map inference Markov logic.Proceedings Proceedings Twenty-Fourth Conference Annual Conference Uncertainty Artificial Intelligence (UAI-08), pp. 468475, Corvallis, Oregon. AUAI Press.Sadilek, A., & Kautz, H. (2010a). Modeling reasoning success, failure, intentmulti-agent activities. Mobile Context-Awareness Workshop, Twelfth ACM InternationalConference Ubiquitous Computing.Sadilek, A., & Kautz, H. (2010b). Recognizing multi-agent activities GPS data. TwentyFourth AAAI Conference Artificial Intelligence.Sadilek, A., Kautz, H., & Bigham, J. P. (2012). Finding friends followingare. Fifth ACM International Conference Web Search Data Mining (WSDM).Sato, T., & Kameya, Y. (2001). Parameter learning logic programs symbolic-statistical modeling. Journal Artificial Intelligence Research.Sato, T., & Kameya, Y. (2008). New advances logic-based probabilistic modeling PRISM.Probabilistic inductive logic programming, pp. 118155. Springer.Shakarian, P., Subrahmanian, V., & Spaino, M. L. (2009). SCARE: Case Study Baghdad.Proceedings Third International Conference Computational Cultural Dynamics.AAAI.Shen, J. (2009). Activity recognition desktop environments. Ph.D. Thesis, Oregon State University.Shoenfield, J. R. (1967). Mathematical Logic. Addison-Wesley.Singla, P., & Domingos, P. (2005). Discriminative training Markov logic networks. Proceedings National Conference Artificial Intelligence, Vol. 20, p. 868. Menlo Park, CA;Cambridge, MA; London; AAAI Press; MIT Press; 1999.Singla, P., & Domingos, P. (2007). Markov logic infinite domains. UAI-07.Tang, K., Lin, J., Hong, J., Siewiorek, D., & Sadeh, N. (2010). Rethinking location sharing: exploring implications social-driven vs. purpose-driven location sharing. Proceedings12th ACM international conference Ubiquitous computing, pp. 8594. ACM.Tran, S., & Davis, L. (2008). Visual event modeling recognition using Markov logic networks.Proceedings 10th European Conference Computer Vision.Ullman, T., Baker, C., Macindoe, O., Evans, O., Goodman, N., & Tenenbaum, J. (2010). Helphinder: Bayesian models social goal inference. Advances Neural InformationProcessing Systems (NIPS), Vol. 22.Vail, D. (2008). Conditional random fields activity recognition. Ph.D. Thesis, Carnegie MellonUniversity.132fiL OCATION -BASED R EASONING C OMPLEX ULTI -AGENT B EHAVIORVail, D., & Veloso, M. (2008). Feature selection activity recognition multi-robot domains.Proceedings AAAI, Vol. 2008.Wang, J., & Domingos, P. (2008). Hybrid Markov logic networks. Proceedings 23rdnational conference Artificial intelligence - Volume 2, pp. 11061111. AAAI Press.Wellner, B., McCallum, A., Peng, F., & Hay, M. (2004). integrated, conditional model information extraction coreference application citation matching. Proceedings20th conference Uncertainty artificial intelligence, pp. 593601. AUAI Press.Wilson, A., Fern, A., Ray, S., & Tadepalli, P. (2008). Learning transferring roles multi-agentmdps. Proceedings AAAI.Wilson, A., Fern, A., & Tadepalli, P. (2010). Bayesian role discovery multi-agent reinforcement learning. Proceedings 9th International Conference Autonomous AgentsMultiagent Systems: volume 1-Volume 1, pp. 15871588. International FoundationAutonomous Agents Multiagent Systems.Wrobel, S. (1996). First order theory refinement. Advances inductive logic programming, pp.1433. IOS Press, Amsterdam.Wu, T., Lian, C., & Hsu, J. (2007). Joint recognition multiple concurrent activities using factorialconditional random fields. Proc. 22nd Conf. Artificial Intelligence (AAAI-2007).Yoshikawa, K., Riedel, S., Asahara, M., & Matsumoto, Y. (2009). Jointly identifying temporal relations Markov logic. Proceedings Joint Conference 47th Annual MeetingACL 4th International Joint Conference Natural Language ProcessingAFNLP: Volume 1-Volume 1, pp. 405413. Association Computational Linguistics.133fiJournal Artificial Intelligence Research 43 (2012) 211-255Submitted 8/11; published 02/12Exploiting Model Equivalences Solving Interactive DynamicInfluence DiagramsYifeng ZengYFZENG @ CS . AAU . DKDept. Computer ScienceAalborg UniversityDK-9220 Aalborg, DenmarkPrashant DoshiPDOSHI @ CS . UGA . EDUDept. Computer ScienceUniversity GeorgiaAthens, GA 30602, U.S.A.Abstractfocus problem sequential decision making partially observable environmentsshared agents uncertain types similar conflicting objectives. problempreviously formalized multiple frameworks one interactive dynamicinfluence diagram (I-DID), generalizes well-known influence diagram multiagentsetting. I-DIDs graphical models may used compute policy agent givenbelief physical state others models, changes agent acts observesmultiagent setting.may expect, solving I-DIDs computationally hard. predominantly duelarge space candidate models ascribed agents exponential growth time.present two methods reducing size model space stemming exponentialgrowth. methods involve aggregating individual models equivalence classes.first method groups together behaviorally equivalent models selects models updating result predictive behaviors distinct others updated modelspace. second method compacts model space focusing portions behavioral predictions. Specifically, cluster actionally equivalent models prescribe identicalactions single time step. Exactly identifying equivalences would require us solvemodels initial set. avoid selectively solving models, thereby introducing approximation. discuss error introduced approximation, empiricallydemonstrate improved efficiency solving I-DIDs due equivalences.1. IntroductionSequential decision making (planning) key tenet agent autonomy. Decision making becomescomplicated due actions nondeterministic physical environment oftenpartially observable. complexity increases exponentially presence agentsacting observing, whose actions impact subject agent. Multiple relatedframeworks formalize general problem decision making uncertain settings sharedsophisticated agents may similar conflicting objectives. One frameworks interactive partially observable Markov decision process (I-POMDP) (Gmytrasiewicz& Doshi, 2005), generalizes POMDPs (Smallwood & Sondik, 1973; Kaelbling, Littman,& Cassandra, 1998) multiagent settings; another framework interactive dynamic influc2012AI Access Foundation. rights reserved.fiZ ENG & OSHIRiRiAitAit+1AjtAjt+1StSt+1Mj,l-1tMj,l-1t+1OitOit+1Figure 1: two time-slice I-DID agent modeling another agent j. I-DIDs allow representingmodels model node (hexagon) update time using dotted modelupdate link. Predictions agents behavior models representedusing dashed policy link.ence diagram (I-DID) (Doshi, Zeng, & Chen, 2009). cooperative settings, decentralizedPOMDP (Bernstein, Givan, Immerman, & Zilberstein, 2002) framework models multiagent decision making.I-DIDs graphical models sequential decision making uncertain multiagent settings.concisely represent problem agent act uncertain environment sharedothers may act simultaneously sophisticated ways. I-DIDs may viewed graphicalcounterparts I-POMDPs adopt enumerative representation decision-making problem. I-DIDs generalize dynamic influence diagrams (DID) (Tatman & Shachter, 1990) multiagentsettings analogously way I-POMDPs generalize POMDPs. Importantly, I-DIDsadvantage representation explicates embedded domain structure decomposingstate space variables relationships variables. representationintuitive use, translates computational benefits compared enumerativerepresentation used I-POMDPs (Doshi et al., 2009).Following paradigm graphical models, I-DIDs compactly represent decision problemmapping various variables chance, decision utility nodes, denoting dependenciesvariables using directed arcs corresponding nodes. extend DIDsintroducing special model node whose values possible models agent.models may represented using I-DIDs leading nested modeling. agentsmodels original agents beliefs models updated time using specialmodel update link connects model nodes time steps. Solution I-DIDpolicy prescribes agent time, given beliefs physical stateothers models. Consequently, I-DIDs may used compute policy agent onlinegiven initial belief agent agent acts observes setting populatedinteracting agents. show generic I-DID Fig. 1 provide details Section 3.may expect, solving I-DIDs computationally hard. particular, acutelysuffer curses dimensionality history (Pineau, Gordon, & Thrun, 2006).state space I-DIDs includes models agents addition traditional212fiE XPLOITING ODEL E QUIVALENCES OLVING NTERACTIVE DYNAMIC NFLUENCE IAGRAMSphysical states. agents act, observe update beliefs, I-DIDs must track evolutionmodels time. Theoretically, number candidate models grows exponentially time.Thus, I-DIDs suffer curse history afflicts modeling agent, alsoexhibited modeled agents. complicated nested nature statespace.Consequently, exact solutions I-DIDs infeasible simple problems waysmitigating computational intractability critically needed. complexity predominantly due candidate models, focus principled reductions model spaceavoiding significant losses optimality decision maker. first approach buildsupon idea grouping together behaviorally equivalent (BE) models (Rathnasabapathy, Doshi,& Gmytrasiewicz, 2006; Pynadath & Marsella, 2007). models whose behavioral predictions modeled agent(s) identical. solution subject agents I-DIDaffected predicted behavior agent regardless descriptionascribed model, may consider single representative class without affectingoptimality solution. Identifying models requires solving individual models. reduce exponential growth model space discriminatively updating models. Specifically,time step, select models updating result predictive behaviorsdistinct others updated model space. words, models updatewould result predictions identical existing models selected updating. models, simply transfer revised probability masses existingmodels. Thus, avoid generating possible updated models subsequently reducing them.Rather, generate minimal set models time step.Restricting updated models exact minimal set would require solving modelsconsidered initially. Exploiting notion models whose beliefs spatially close tendBE, solve models whose beliefs -close representative. theoretically analyze error introduced approach optimality solution. Importantly,experimentally evaluate approach I-DIDs formulated multiple problem domains two agents, show approximately order magnitude improvement performancecomparison previous clustering approach (Zeng, Doshi, & Chen, 2007), comparableloss optimality. One problem domains Georgia testbed autonomous controlvehicles (GaTAC) (Doshi & Sonu, 2010), facilitates scalable realistic problem domainspertaining autonomous control unmanned agents uninhabited aerial vehicles (UAV).GaTAC provides low-cost, open-source flexible environment realistically simulatingproblem domains evaluating solutions produced multiagent decision-making algorithms.compact space models model node observing behaviorallydistinct models may prescribe identical actions single time step. may group togethermodels single equivalence class. comparison BE, definition equivalenceclass different: includes models whose prescribed action particular time stepsame, call action equivalence (AE). Since typically additional modelsones prescribe identical actions time step, AE class often includes manymodels. Consequently, model space partitioned lesser number classes previouslybounded number actions agent.Unlike update classes, given action observation AE classes updatedeterministically. show may compute probability equivalence classupdated another class next time step. Although, general, grouping AE models introduces213fiZ ENG & OSHIapproximation, derive conditions AE model grouping preserves optimalitysolution. demonstrate performance approach multiple two-agent problem domainsincluding GaTAC show significant time savings comparison previous approaches.summarize, main contributions article new approaches group equivalentmodels efficiently leading improved scalability solving I-DIDs. first method reducesexponential growth model space discriminatively updating models thereby generatingbehaviorally minimal set next time step characterized absence models.second method adopts relaxed grouping models prescribe identical actionsparticular time step. Grouping AE models leads equivalence classes often include manymodels addition BE. augment methods approximationavoids solving initial models, demonstrate much improved scalability experiments.remainder article structured follows. Section 2, discuss previous workrelated article. Section 3, briefly review graphical model I-DID wellsolution based BE. Section 4, show may discriminatively update models orderfacilitate behaviorally-distinct models subsequent time steps. introduce approximation,discuss associated computational savings error. introduce approachgrouping models based actions, Section 5. approaches solving I-DIDs empiricallyevaluated along different dimensions Section 6. conclude article discussionframework solution approaches including extensions N > 2 agent interactions,limitations, Section 7. Appendices contain proofs propositions mentioned elsewhere,detailed descriptions I-DID representations problem domains used evaluation.2. Related WorkSuryadi Gmytrasiewicz (1999) early piece related work, proposed modelingagents using IDs. approach proposed ways modify IDs better reflect observedbehavior. However, unlike I-DIDs, agents model original agent distributionmodels updated based actions observations.detailed Doshi et al. (2009), I-DIDs contribute emerging promising lineresearch graphical models multiagent decision making. includes multiagent influencediagrams (MAID) (Koller & Milch, 2001), network influence diagrams (NID) (Gal & Pfeffer,2008), recently, limited memory influence diagram based players (Madsen & Jensen,2008). MAIDs adopt external perspective interaction, exploiting conditionalindependence effects actions compute Nash equilibrium strategy agentsinvolved interaction, I-DIDs offer subjective perspective interaction, computingbest-response policy opposed policy equilibrium. latter may accountagents behaviors outside equilibrium multiple equilibria may exist. Furthermore,MAID NID formalisms focus static, single-shot interaction. contrast, I-DIDs offersolutions extended time interactions, agents act update beliefs othersmodels dynamic.I-DIDs closely relate previously mentioned ID-based graphical models, anothersignificant class graphical models compactly represents joint behavior graphical game(Kearns, Littman, & Singh, 2001). models agents graph vertices interaction payofftwo agents using edge, objective finding joint distribution agentsactions possibly equilibrium. recently, graphical multiagent models (Duong, Wellman,214fiE XPLOITING ODEL E QUIVALENCES OLVING NTERACTIVE DYNAMIC NFLUENCE IAGRAMS& Singh, 2008) enhance graphical games allowing beliefs agent behaviors formeddifferent knowledge sources, conditioning agent behaviors abstracted history gamedynamic (Duong, Wellman, Singh, & Vorobeychik, 2010).mentioned previously, dominating cause complexity I-DIDs exponentialgrowth candidate models time. Using insight models (with identical capabilitiespreferences) whose beliefs spatially close likely BE, Zeng Doshi (2007) utilized k-means approach cluster models together select K models closest meansclusters model node time step. approach facilitates consideration fixednumber models time. However, approach first generates possible modelsreducing model space time step, thereby reducing memory required. Further,utilizes iterative often time-consuming k-means clustering method.concept models proposed initially used solving I-POMDPs (Rathnasabapathy et al., 2006), discussed generally Pynadath Marsella (2007). contextualize within framework I-DIDs seek extensions. somewhat related notionstate equivalence introduced Givan et al. (2003) equivalence concept exploited factorize MDPs gain computational benefit. Along direction, another typeequivalence probabilistic frameworks MDPs POMDPs, sometimes also called BE,bisimulation (Milner, 1980; Givan et al., 2003; Castro, Panangaden, & Precup, 2009). Two statesbisimilar action states leads identical immediate reward states transition probability equivalence classes states. bisimulation test withinmodel given definition, multiagent systems defined used differently: waycomparing models using solutions. Interestingly, concepts ultimatelyuseful model minimization.frameworks modeling multiagent decision-making problem exist. notableamong decentralized POMDP (Bernstein et al., 2002). framework suitablecooperative settings focuses computing joint solution agents team.Seuken Zilberstein (2008) provide comprehensive survey approaches related decentralized POMDPs; emphasize exploit clustering. Emery-Montemerlo et al. (2005) proposeiteratively merging action-observation histories agents lead small worst-case expectedloss. clustering could lossy, Oliehoek et al. (2009) losslessly cluster historiesexhibit probabilistic equivalence. histories generate identical distribution historiesagents lead joint belief state. utilize losslessly clustermodels agent, note models combined subject agents policy induce identical distributions subject agents action-observation history. recently,Witwicki Durfee (2010) use influence-based abstraction order limit agents beliefagents relevant information focusing mutually-modeled features only.agent models analogous types game theory (Harsanyi, 1967), definedattribute vectors encompass agents private information. context, Dekel etal. (2006) define strategic topology universal type spaces (Mertens & Zamir, 1985; Brandenburger & Dekel, 1993) two types close strategic behavior similarstrategic situations. Dekel et al. focus theoretical analysis topology userationalizability solution concept, focus operationalizing within computationalframework. Furthermore, solution concept best response ones beliefs.215fiZ ENG & OSHI3. Backgroundbriefly review interactive influence diagrams (I-ID) two-agent interactions followedextension dynamic settings, I-DIDs (Doshi et al., 2009). formalisms allow modelingagent use information decision making subject agent.illustrate formalisms approaches context multiagent tiger problem (Gmytrasiewicz & Doshi, 2005) two-agent generalization well-known single agenttiger problem (Kaelbling et al., 1998). problem, two agents, j, face two closed doorsone hides tiger hides pot gold. agent gets rewarded openingdoor hides gold gets penalized opening door leading tiger. agentmay open left door (action denoted OL), open right door (OR), listen (L). listening,agent may hear tiger growling either left (observation denoted GL)right (GR). Additionally, agent hears creaks emanating direction doorpossibly opened agent creak left (CL) creak right (CR) silence(S) door opened. observations assumed noisy. door openedagent, tiger appears behind two doors randomly next time step.actions agent directly affect reward agent, may potentially changelocation tiger. formulation problem differs Nair et al. (2003)presence door creaks cooperative.3.1 Interactive Dynamic Influence DiagramsInfluence diagrams (Tatman & Shachter, 1990) typically contain chance nodes representrandom variables modeling physical state, S, agents observations, Oi , amongaspects problem; decision nodes model agents actions, Ai ; utility nodesmodel agents reward function, Ri . addition nodes, I-IDs agent includenew type node called model node. hexagonal node, Mj,l1 , Fig. 2, jdenotes agent l 1 strategy level, allows nested modelingagent j. Agent js level one less i, consistent previoushierarchical modeling game theory (Aumann, 1999a; Brandenburger & Dekel, 1993) decisiontheory (Gmytrasiewicz & Doshi, 2005). Additionally, level 0 model ID flat probabilitydistribution. note probability distribution chance node, S, model nodetogether represents agent belief interactive state space. addition model node,I-IDs differ IDs chance node, Aj , represents distributionagents actions, dashed link, called policy link.model node contains values alternative computational models ascribedagent. policy link denotes distribution Aj contingent modelsmodel node. denote set models Mj,l1 , individual model j as,mj,l1 = hbj,l1 , j i, bj,l1 level l 1 belief, j agents frame encompassingdecision, observation utility nodes. model model node may I-ID ID,recursion terminates model ID flat probability distribution actions.observe model node dashed policy link connects chance node,Aj , could represented shown Fig. 3(a) leading flat ID shown Fig. 3(b). decisionnode level l 1 I-ID transformed chance node. Specifically, OPT(m1j,l1 )set optimal actions obtained solving I-ID (or ID) denoted m1j,l1 , P r(aj216fiE XPLOITING ODEL E QUIVALENCES OLVING NTERACTIVE DYNAMIC NFLUENCE IAGRAMSRiAiAjMj.l-1OiFigure 2: generic level l > 0 I-ID agent situated one agent j. shaded hexagonmodel node (Mj,l1 ) dashed arrow policy link.Mj,l-1AjRiAiMod[Mj]mj,l-11mj,l-12j1j2AjMod[Mj]OiAj1Aj2(b)(a)Figure 3: (a) Representing model node policy link using chance nodes dependenciesthem. decision nodes lower-level I-IDs IDs (m1j,l1 , m2j,l1 ; superscript numbers serve distinguish models) mapped corresponding chancenodes (A1j , A2j ) respectively, indicated dotted arrows. Dependingvalue node, od[Mj ], distribution chance nodes assigned node Ajprobability. (b) transformed flat ID model node policy linkreplaced (a).A1j ) =1|OPT(m1j,l1 )|aj OPT(m1j,l1 ), 0 otherwise. different chance nodes (A1j , A2j )one model additionally, chance node labeled od[Mj ] form parentschance node, Aj . many action nodes number models support agentbeliefs. conditional probability table (CPT) chance node, Aj , multiplexerassumes distribution action nodes (A1j , A2j ) depending value od[Mj ].words, od[Mj ] value m1j,l1 , chance node Aj assumes distributionnode A1j , Aj assumes distribution A2j od[Mj ] value m2j,l1 .distribution od[Mj ] belief js models given state.two agents, add model node chance node representing distributionagents action linked together using policy link, agent. Interactions amongothers coordination team work could considered utilizing models, predict217fiZ ENG & OSHIjoint behavior others, distinct model node possibly updating models. example,joint behavioral models could graphical analogs decentralized POMDPs. settingsinvolving agents acting independently cooperative others adversarialmay represented well, topic research study. aside, Doshi et al. (2009)show I-IDs relate NIDs (Gal & Pfeffer, 2008).RiAitTigerLocationtAjtMod[Mjt]Growl&CreakitAjt,1Ajt,2mj,01mj,02RjTigerLocationt,1AjAjt,2t,1RjTigerLocationt,2GrowljtGrowljtFigure 4: Level 1 I-ID multiagent tiger problem. Solutions two level 0 models (IDs)t,2j map chance nodes, At,1j Aj , respectively (illustrated using dotted arrows),transforming I-ID flat ID. two models differ distributionchance node, TigerLocationt .setup I-ID multiagent tiger problem described previously, Fig. 4. discussCPTs various nodes Appendix B.1. I-ID contains two models j,would many action nodes j models.RiRiAitAit+1AjtAjt+1StSt+1Mj,l-1tMj,l-1t+1OitOit+1Figure 5: generic two time-slice level l I-DID agent i. Notice dotted model update linkdenotes update models j distribution models,time.218fiE XPLOITING ODEL E QUIVALENCES OLVING NTERACTIVE DYNAMIC NFLUENCE IAGRAMSI-DIDs extend I-IDs allow sequential decision making multiple time steps. depictgeneral, two time-slice I-DID Fig. 5. addition model nodes dashed policy link,differentiates I-DID model update link shown dotted arrow Fig. 5.briefly explain semantics model update next.StAjtMj,l-1tAjt+1Mj,l-1t+1St+1Mod[Mjt+1]Mod[Mj ]Ojt+1Aitmj,l-1t,1mj,l-1t,2Aj1Ojj2Oj2mj,l-1t+1,11mj,l-1t+1,2mj,l-1t+1,3mj,l-1t+1,4j1j2j3j4Figure 6: semantics model update link. Notice growth number modelsmodel node + 1 shown bold (superscript numbers distinguish different models).Models + 1 reflect updated beliefs j solutions provide probabilitydistributions action nodes.Agents multiagent setting may act make observations, changes beliefs.Therefore, update model node time involves two steps: First, given modelstime t, identify updated set models reside model node time + 1.agents act receive observations, models updated reflect changed beliefs. Sinceset optimal actions model could include actions, agent may receiveone |j | possible observations j set js observations, updated set time stept+1 |Mtj,l1 ||Aj ||j | models. Here, |Mtj,l1 | number models time step t,|Aj | |j | largest spaces actions observations respectively, among models.t+1t+1CPT chance node od[Mj,l1] encodes indicator function, (btj,l1 , atj , ot+1j , bj,l1 ),updates1 belief btj,l1 model mtj,l1 using action atj observation ot+1jt+1t+1bj,l1 model mj,l1 ; otherwise 0. Second, compute new distributionupdated models given original distribution probability agent performing actionreceiving observation led updated model. dotted model update linkI-DID may implemented using standard dependency links chance nodes, shown Fig. 6transforming I-DID flat DID.Fig. 7, show two time-slice flat model nodes model update linkreplaced chance nodes relationships them. Chance nodes dependencylinks bold standard, usually found single agent DIDs.Continuing illustration, show two time-slice I-DID multiagent tigerproblem Fig. 8. model update link updates number js candidate models dueaction observations growl, also updates probability distribution models.model update link I-DID implemented using standard dependency links shownFig. 9. sake clarity, illustrate update single model j contained modelnode time t.219fiZ ENG & OSHIRiRiAitAit+1StSt+1OitOit+1AjtAjt+1t+1Mod[Mj ]Mod[Mjt]Ojt+1Aj1Aj1Oj1j2AjOj24j2j3Figure 7: flat obtained replacing model nodes model update link I-DIDFig. 5 chance nodes relationships (in bold) shown Fig. 6.lower-level models solved obtain distributions chance action nodes.RiRiAitAit+1AjtAjt+1TigerLocationtTigerLocationt+1Mj,l-1tMj,l-1t+1Growl&CreaktGrowl&Creakt+1Figure 8: Two time-slice level l I-DID multiagent tiger problem. Shaded model nodescontain different models j.3.2 Behavioral Equivalence Model SolutionAlthough space possible models large, models need considered agentmodel node. mentioned previously, models (Rathnasabapathy et al., 2006;Pynadath & Marsella, 2007) could pruned single representative model considered.solution subject agents I-DID affected predicted behavioragent; thus need distinguish behaviorally equivalent models. defineformally below:Definition 1 (Behavioral equivalence). Two models, mj,l1 mj,l1 , agent, j,behaviorally equivalent if, OPT(mj,l1 ) = OPT(mj,l1 ), OPT() denotes solutionmodel forms argument.Thus, models whose behavioral predictions agent identical.220fiE XPLOITING ODEL E QUIVALENCES OLVING NTERACTIVE DYNAMIC NFLUENCE IAGRAMSTigerLocationtAjtMj,l-1tAjt+1Mj,l-1t+1TigerLocationt+1Mod[Mjt+1]Mod[Mjt]mj,l-1t+1,1Growljt+1Aitmj,l-1t,1j1mj,l-1t+1,3Growlj1mj,l-1t+1,4mj,l-1t+1,5mj,l-1t+1,6mj,l-1t+1,2Ajj12j3j4Aj5Aj6Figure 9: agent j tiger problem may receive one six possible observationsgiven action prescribed model, single model model node time couldlead six distinct models time + 1.solution I-DID (and I-ID) implemented recursively levels shownFig. 10. order solve level 1 I-DID horizon , start solving level 0 models,may traditional DIDs horizon . solutions provide probability distributionsagents actions, entered corresponding action nodes found model nodelevel 1 I-DID corresponding time step (lines 3-5). Subsequently, set js modelsminimized excluding models (line 6).solution method uses standard look-ahead technique, projecting agents actionobservation sequences forward current belief state, finding possible beliefscould next time step (Russell & Norvig, 2010). agent beliefjs models well, look-ahead includes finding possible models j couldfuture. Consequently, js level 0 models represented using standard mustsolved first time step horizon obtain optimal set actions. actionscombined set possible observations j could make model, resultingupdated set candidate models (that include updated beliefs) could describe behaviorj. SE(btj , aj , oj ) abbreviation belief update (lines 8-13). Beliefs updatedset candidate models calculated using standard inference methods dependencylinks model nodes shown Fig. 6 (lines 15-18). Agent I-DID expanded acrosstime steps manner. point algorithm Fig. 10 may realized helpstandard implementations DIDs H UGIN E XPERT (Andersen & Jensen, 1989).solution policy tree prescribes optimal action(s) perform agent initially givenbelief, actions thereafter conditional observations.4. Discriminative Model UpdatesSolving I-DIDs computationally intractable due large space complexitymodels ascribed j, also due exponential growth candidate models j time.growth leads disproportionate increase interactive state space time. beginintroducing set models minimal sense describe method generating set.minimal set analogous one notions minimal mental model space described221fiZ ENG & OSHII-DID E XACT (level l 1 I-DID level 0 DID, horizon )Expansion Phase1. 0 12.l 1Minimize Mj,l13.mtj Mtj,l14.Recursively call algorithm l 1 I-DID (or DID)represents mtj horizon,5.Map decision node solved I-DID (or DID), OPT(mtj ),corresponding chance node Aj6.Mtj,l1 PruneBEModels(Mtj,l1 )7.< 1t+1Populate Mj,l18.mtj Mtj,l19.aj OPT(mtj )10.oj Oj (part mtj )11.Update js belief, bt+1SE(btj , aj , oj )jt+112.mj New I-DID (or DID) bt+1initial beliefjt+1{m}13.Mt+1jj,l1t+114.Add model node, Mj,l1, model update linkt+1Mj,l1Mj,l115.Add chance, decision, utility nodes + 1 time slicedependency links16.Establish CPTs chance node utility nodeSolution Phase17. l 118. Represent model nodes, policy links model update linksFig. 6 obtain19. Apply standard look-ahead backup method solve expanded(other solution approaches may also used)Figure 10: Algorithm exactly solving level l 1 I-DID level 0 expanded timesteps.Pynadath Marsella (2007). assume models agent differ beliefsagents frame known. later discuss Section 7 impact frameunknown well. clarity, continue focus two-agent interactions, discussextensions techniques presented Section 7 well.4.1 Behaviorally Minimal Model SetGiven set models, Mj,l1 , agent, j, model node define correspondingbehaviorally minimal set models:222fiE XPLOITING ODEL E QUIVALENCES OLVING NTERACTIVE DYNAMIC NFLUENCE IAGRAMSDefinition 2 (Behaviorally minimal set). Define minimal set models, Mj,l1 , largestsubset Mj,l1 , model, mj,l1 Mj,l1 , exists model Mj,l1mj,l1 .Here, defined Def. 1. say Mj,l1 (behaviorally) minimizes Mj,l1 .illustrate Fig. 11 using tiger problem (Kaelbling et al., 1998), set Mj,l1 minimizesMj,l1 comprises behaviorally distinct representatives models Mj,l1models. model group models may selected representativeMj,l1 , minimal set corresponding Mj,l1 unique, although cardinality remainsfixed.0.075 0.1 0.0250.050.2 0.250.05 0.050.15 0.05Pri(Mj,0t|s)Prj(TL)0.20.60.2Pri(j,0t|s)Prj(TL)Figure 11: Illustration minimal set using tiger problem. Black vertical lines denotebeliefs contained different models agent j included model node, Mj,0 . Decimalstop indicate probability distribution js models, P ri (Mtj,0 |s). orderform behaviorally minimal set, Mtj,0 , select representative modelgroup models (models differently shaded regions). Agent distributionmodels Mtj,0 obtained summing probability mass assigned individualmodels region. Note Mtj,0 unique one model withinshaded region could selected inclusion it.Agent probability distribution minimal set, Mj,l1 , conditioned physicalstate obtained summing probability mass models Mj,l1 assigningaccumulated probability representative model Mj,l1 . Formally, let mj,l1 Mj,l1 ,then:Xbi (mj,l1 |s) =bi (mj,l1 |s)(1)mj,l1 Mj,l1Mj,l1 Mj,l1 set models representative mj,l1 belongs. Thus,Mj,l1 minimizes Mj,l1 , Eq. 1 shows may obtain probability distributionMj,l1 time step, given belief distribution models model node step(see Fig. 11).behaviorally minimal set together probability distribution importantproperty: Solution I-DID remains unchanged models model nodedistribution models replaced corresponding minimal set distributionit, respectively. words, transforming set models model nodeminimal set preserves solution. Proposition 1 states formally:223fiZ ENG & OSHIProposition 1. Let X : (Mj,l1 ) (Mj,l1 ) mapping defined Eq. 1, Mj,l1space models model node Mj,l1 minimizes it. Then, applying X preservessolution I-DID.Proof Proposition 1 given Appendix A. Proposition 1 allows us show Mj,l1indeed minimal given Mj,l1 respect solution I-DID.Corollary 1. Mj,l1 conjunction X sufficient solution-preserving subset modelsfound Mj,l1 .Proof corollary follows directly Proposition 1. Notice subset continuessolution preserving additionally augment Mj,l1 models Mj,l1 .number models minimal set is, course, original settypically much less, solution I-DID often computationally much less intensivemodel set replaced behaviorally minimal counterpart.4.2 Discrimination Using Policy Graphsstraightforward way obtaining Mj,l1 exactly time step first ascertaingroups models. requires us solve I-DIDs DIDs representing models, selectrepresentative model group include Mj,l1 , prune otherssolution representative.4.2.1 PPROACHGiven set js models, Mj,l1 , time t(=0), present technique generating minimalsets subsequent time steps I-DID. first observe behaviorally distinct models timemay result updated models + 1 BE. Hence, approach select time stepmodels updating result predictive behaviors distinctothers updated model space + 1. Models result predictions updateidentical existing models + 1 selected updating. Consequently,resulting model set + 1 minimal.solving individual I-DIDs DIDs Mtj,l1 . Solutions DIDs I-DIDspolicy trees, may merged bottom obtain policy graph, demonstrateFig. 12. Seuken Zilberstein (2007) reuse subtrees smaller horizon linking usingpointers forming policy trees next horizon solution decentralized POMDPs.net effect formation policy graph similar thereby providing alternativeapproach solving individual models first obtain complete policy treesmerge post hoc. adopt latter approach individual models, DIDs,solved using available implementations produce complete policy trees. following propositiongives complexity merging policy trees obtain policy graph.Proposition 2 (Complexity tree merge). worst-case complexity procedure mergingpolicy trees form policy graph O((|j |T 1 )2 |Mj |2 ), horizon.Proof. complexity policy tree merge procedure proportional number comparisons made parts policy trees ascertain similarity. procedurefollows bottom-up approach leaf level largest number nodes, maximum224fiE XPLOITING ODEL E QUIVALENCES OLVING NTERACTIVE DYNAMIC NFLUENCE IAGRAMSLGRGLOL*time t=0L*LLGL GR*LOLLGR GLLGL GRLGR GL GR GLLOLLL*GR GLLMerge(a)GROLMerge*GLGR*GL GRGR GLLLLLL*GLGRGL GROLLLGLGLGR*LL(b)[ 0 0.135) [ 0.135 0.865) [ 0.865 0.955) [ 0.955 1]Actions (node labels):L = ListenOL = Open left door= Open right doorObservations (edge labels):GL = Growl left doorGR = Growl right doorLGROLLLGRGLLGR*OLGRGLLGLGRGL*L* GL *L(c)Figure 12: (a) Example policy trees obtained solving four models j tiger problem.Beginning bottom up, may merge four L nodes, two nodes two OLnodes respectively obtain graph (b). two policy trees two stepsrooted L (bold circle) identical, two policy trees rooted L (rightmost), may merge them, respectively, obtain policy graph (c). Nodes= 0 annotated ranges P rj (T L).number comparisons made leaf nodes. worst case occurs none leafnodes different policy trees merged. Note precludes merger upper partspolicy trees well. policy tree may contain |j |T 1 leaf nodes,horizon. Hence, O((|j |T 1 )2 |Mj |2 ) comparisons made, O(|Mj |2 ) number pairs model set. 1 case none leaf nodes merge must occurmodels behaviorally distinct, form minimal set, Mj . words, Mj = Mj .1. assume ordering observations (edge labels) thereby ordering tree, two policy trees may sufficiently compared O(|j |T 1 ) time.225fiZ ENG & OSHInode policy graph represents action performed agent edgesrepresent agents observations. common policy graphs POMDPs, associatenode time = 0, range beliefs corresponding action optimal (seeFig. 12(c)). range may obtained computing value executing policy tree rootednode = 0 graph starting physical state. results vectorvalues policy tree, typically called -vector. Intersecting -vectors projectingintersections belief simplex provides us boundaries needed belief ranges.utilize policy graph discriminate model updates. clarity, formallydefine policy graph next.Definition 3 (Policy graph). Define policy graph as:P G = hV, A, E, , Lv , LeV set vertices (nodes); set actions form node labels; E setordered pairs vertices (edges); set observations form edge labels; Lv :V assigns vertex action set actions, (node label); Le : Eassigns edge observation set observations, (edge label). Le followsproperty two edges whose first elements identical (begin vertex) assignedobservation.Notice policy graph augments regular graph meaningful node edge labels.policy graph, P G, also define transition function, Tp : V V, convenience.Tp (v, o) returns vertex, v , {v, v } E Le ({v, v }) = o.insight Tp (v, o) root node policy tree represents predictive behavior model updated using action Lv (v) observation o. iterate js modelsmodel node time expansion phase solving I-DID, utilize Tp decidingwhether update model.first combine policy trees obtained solving models node Mj,l1obtainpolicy graph, P G, shown Fig. 12. Let v vertex P G whose action label, Lv (v), represents rational action mj,l1 Mtj,l1 . ascertain simply checking whetherbelief mj,l1 falls within belief range associated node. every observationLe ({v, }), update model, mj,l1 , using action Lv (v) observation o, v = Tp (v, o)encountered previously model. illustrate below:Example 1 (Model update). Consider level 0 models j model node time t, Mtj,0 ={h0.01, j i, h0.5, j i, h0.05, j i}, multiagent tiger problem. Recall model j,h0.01, j i, 0.01 js belief (over TL) j frame. PG Fig. 12(c), leftmostnode prescribing action L optimal first third models, second node alsoprescribing L optimal second model. Beginning model, h0.01, j i, Tp (v, GL) = v1(where Lv (v1 ) = L) Tp (v, GR) = v2 (Lv (v2 ) = OL). Since first model consider,updated using L observations resulting two models Mt+1j,0 . model,h0.5, j i, v optimal node (Lv (v ) = L), Tp (v , GR) = v1 , encounteredpreviously. Hence, model updated using L GR, although updatedusing L GL.226fiE XPLOITING ODEL E QUIVALENCES OLVING NTERACTIVE DYNAMIC NFLUENCE IAGRAMSIntuitively, model, mj,l1 , node v1 = Tp (v, o) obtained previouslymodel action-observation combination, update mj,l1previously updated model (both policy tree rooted v1 ). Hence, mj,l1 needupdated using observation o. permit updates lead models,set models obtained + 1 minimal. Applying process analogously modelsfollowing time steps lead minimal sets subsequent steps nesting levels.4.2.2 PPROXIMATIONmay gain efficiency avoiding solution models model node firsttime step. One way randomly select K models j, K |M0j,l1 |.Solution models result K policy trees, could combined shown Fig. 12form policy graph. policy graph utilized discriminate model updates.Notice approach becomes exact optimal solution model M0j,l1 identicalone K models. K models selected randomly, assumptionimplausible approach likely result substantial loss optimality mediatedK.propose simple effective refinement mitigates loss. Recall models whosebeliefs spatially close likely (Rathnasabapathy et al., 2006). remaining|M0j,l1 | K models whose belief within 0 belief K modelsalso solved. additional step makes likely behaviorally distinct solutionsgenerated included forming policy graph. = 0, models model nodesolved leading exact solution, increasing reduces number solved modelsbeyond K. One measure distance belief points L1 based metric, thoughmetrics Euclidean distance may also used.4.3 Transfer Probability MassNotice consequence updating models using action-observation combinationprobability mass would assigned updated model model nodet+1 lost. Disregarding probability mass may introduce error optimality solution.perform update model potentially updated modelalready exists model node time t+1. could avoid error transfering probabilitymass would assigned updated model model.t+1t+1mentioned previously, node od[Mj,l1] model node Mj,l1, valuest+1different models ascribed agent j time + 1. CPT od[Mj,l1 ] implementst+1t+1function (btj,l1 , atj , ot+1j , bj,l1 ), 1 bj,l1 model mj,l1 updates bj,l1 modelt+1t+1mt+1j,l1 using action-observation combination, otherwise 0. Let mj,l1 = hbj,l1 , jmodel mt+1j,l1 . order transfer probability mass model updatet+1pruned, modify CPT od[Mj,l1] indicate mt+1j,l1 model resultst+1updating bj,l1 action, aj observation oj . desired effect transferingprobability would assigned updated model (Fig. 6) mt+1j,l1 modelnode time + 1.227fiZ ENG & OSHI4.4 Algorithmpresent discriminative update based algorithm solving level l 1 I-DID (as welllevel 0 DID) Fig. 13. algorithm differs exact approach (Fig. 10) expansionphase. addition two time-slice level l I-DID horizon , algorithm takes inputnumber random models solved initially, K, distance, . Following Section 4.2,begin randomly selecting K models solve (lines 2-5). remaining models,identify one K solved model whose belief spatially closest (ties broken randomly).proximity within , model solved instead, previously computed solution0assigned corresponding action node model model node, Mj,l1(lines 6-12).Subsequently, models model node associated respective solutions (policytrees), merged obtain policy graph (line 13), illustrated Fig. 12.order populate model node next time step, identify node v P Grepresents optimal action model time t. model updated using optimal actionaj (= Lv (v)) observation oj node, v = Tp (v, oj ) encounteredprevious updates (lines 16-23). Given policy graph, evaluating Tp (v, oj ) constant timet+1operation. Otherwise, mentioned Section 4.3, modify CPT node, od[Mj,l1],transfer probability mass model (line 25). Consequently, model nodes subsequenttime steps expanded I-DID likely populated minimal sets. Given expanded I-DID,solution may proceed straightforward manner shown Fig. 10.4.5 Computational Savings Prediction Error Boundprimary complexity solving I-DIDs due large number models must solvedtime steps. time step t, could |M0j,l1 |(|Aj ||j |)t many modelsagent j, |M0j,l1 | number models considered initially. nested modelingcontributes complexity since solutions model level l 1 requires solvinglower level l 2 models, recursively level 0. N +1 agent setting,number models considered level agent bound |M|, solving I-DIDlevel l requires solutions O((N |M|)l ) many models. Discriminating model updatesreduces number agent models level size behaviorally minimalset, |Mt |, incurring worst-case complexity O((||T 1 )2 |M|2 ) forming policygraph (Proposition 2). Consequently, need solve O((N |M |)l ) number modelsnon-initial time step, largest minimal sets across levels. 2comparison O((N |M|)l ), grows exponentially time. general, M,resulting substantial reduction computation. Additionally, reduction numbermodels model node also reduces size interactive state space, makes solvingI-DID efficient.0, order form policychoose solve models initial model node, Mj,l1graph, sets models subsequent time steps indeed minimal. Consequently,loss optimality solution agent level l I-DID.case select K < |M0j,l1 | models solve, infinitesimally small,eventually solve models resulting error. increasing values , larger numbers2. discuss Section 7, may group models across agents well due number modelssolved reduces.228fiE XPLOITING ODEL E QUIVALENCES OLVING NTERACTIVE DYNAMIC NFLUENCE IAGRAMSI-DID PPROX (level l 1 I-DID level 0 DID, , K, )1. l 1Selectively solve M0j,l12. Randomly select K models M0j,l13. mkj K models4.Recursively call algorithm l 1 I-DID (or DID) represents mkj ,horizon , K,5.Map decision node solved I-DID (or DID), OPT(mkj ), chance node Akj6. mkj |M0j,l1 | K models7.Find model among K whose belief, bkj , closest bkj mkj8.||bkj bkj ||19.Map decision node OPT(mkj ) chance node, Akj10.else11.Recursively call algorithm l 1 I-DID (or DID) represents mkj ,horizon, , K,12.Map decision node solved I-DID (or DID), OPT(mkj ), chance node Akj13. Combine solutions (policy trees) models bottom obtain policy graph, P GExpansion Phase14. 0 215.l 1t+1Populate Mj,l1minimally16.mtj Mtj,l117.aj OPT(mtj )18.oj j (part mtj )19.v vertex P G mtj maps20.Tp (v, oj ) encountered previouslySE(btj , aj , oj )21.Update js belief, bt+1jt+122.mj New I-DID (or DID) bt+1beliefjt+1t+123.Mj,l1 {mj }24.elset+125.Update CPT od[Mj,l1] s. t. row mtj , aj , oj 1 columnmodelt+1t+126.Add model node, Mj,l1, model update link Mj,l1Mj,l127.Add chance, decision, utility nodes + 1 time slice dependencylinks28.Establish CPTs chance node utility nodesolution phase proceeds analogously Fig. 10Figure 13: Algorithm approximately solving level l 1 I-DID level 0 expandedtime steps using discriminative model updates.models remain unsolved could erroneously associated existing solutions.worst case, models may behaviorally distinct K solved models.Therefore, policy graph subgraph one exact case, leads sets models229fiZ ENG & OSHIsubsets minimal sets. Additionally, lower-level models solved approximatelywell. seek possibly bound prediction error, impact optimality agentlevel l I-DID difficult pinpoint. formally define error discuss bounding includinglimitations bound, Appendix A.5. Grouping Models Using Action EquivalenceGrouping models may significantly reduce given space agents models modelnode without loss optimality. may compact space models model nodeobserving behaviorally distinct models may prescribe identical actions single time step.may group together models single equivalence class. comparison BE,equivalence class includes models whose prescribed action particular time stepsame, call action equivalence. define formally next.5.1 Action EquivalenceNotice Fig. 12(c) policy graph contains multiple nodes labeled actiontime steps = 0 = 1. associated models prescribing actions identicalparticular time step, differ entire behavior. call models actionally equivalent.general case, define action equivalence (AE) below:Definition 4 (Action equivalence). Two models, mj,l1 mj,l1 , agent actionally1equivalent time step P r(Atj ) = P r(Atj ) P r(atj ) = |OPT(matj OPT(mj,l1 ),j,l1 )|0 otherwise; P r(atj ) =1|OPT(mj,l1 )|atj OPT(mj,l1 ), 0 otherwise, defined previously.Since AE may include behaviorally distinct models, partitions model space fewerclasses.show example aggregation AE models Fig. 14. figure, partitiont=0,2t=0,1model set, Mtj,l1 , induced AE time step 0 {Mt=0,1j,l1 , Mj,l1 }, Mj,l1 classmodels model space whose prescribed action = 0 L, Mt=0,2j,l1 classmodels whose prescribed action = 0 OR. Note classes include modelswell. Thus, models AE class prescribe identical action time step. Furthermore= 1, partition consists 3 AE classes and, = 2, partition also consists 3 singletonclasses.t,pMt,pj,l1 AE class comprising models mj,l1 Mj,l1 , agent conditional beliefobtained summing conditional belief member models:bi (Mt,pj,l1 |s) =Xbi (mtj,l1 |s)(2)mtj,l1 Mt,pj,l15.2 Revised CPT Mod Node Markov BlanketEquation 2 changes CPT node, od[Mj,l1], due aggregation. Chang Fung(1991) note coarsening operation type affect distributions230fiE XPLOITING ODEL E QUIVALENCES OLVING NTERACTIVE DYNAMIC NFLUENCE IAGRAMSMj,l-1t=0,10.160.23LGR0.32LLGRGLOLLGR*OLGL*GRGLLGLGR0.29time t=0Ltime t=1OL* GL *GL,0.23 GL,0.32time t=2OLGLGR,0.45LLGR*LLLGR,0.23 GR,0.32LMj,l-1t=0,2GL,0.45 *,1.0LGRL*GL*(b)(a)LGR,0.23LLGR,0.32 GL,0.23 GL,0.32 GR,0.45GL,0.45 *,1.0OL*,1.0LLGL,0.69 GL,0.31GR,0.22 GR,0.78OLL*,1.0L(c)Figure 14: (a) Annotations example probabilities models associated nodes. (b, c)may group models prescribe identical actions classes indicated dashed boxes.Probabilities edges represent probability transition class model givenaction observation (ie., CPT next od node).AjtStMod[Mjt]Mod[Mjt+1]Ojt+1Figure 15: Markov blanket chance node, od[Mj,l1], shown bold.directly involve model space joint probability distribution Markov blanket node,od[Mj,l1], remains unchanged. Fig. 15, show Markov blanket od[Mj,l1]. 3joint distribution Markov blanket is:Pt+1t+1P r(st , atj , ot+1, mt+1) = p P r(st , Mt,pjj,l1j,l1 , aj , oj , mj,l1 )Pt,pt,pt+1t+1|Mt,p= p P r(st )P r(Mj,l1 |st )P r(atj |Mj,l1 )P r(mt+1j,l1j,l1 , aj , oj )P r(oj |aj )Pt,pt,pt,pt+1t+1= P r(st )P r(oj |atj ) p P r(Mj,l1 |st )P r(atj |Mj,l1 )P r(mj,l1 |Mj,l1 , atj , ot+1j )P Pt))P r(at |Mt,p )t,p= P r(st )P r(ot+1|aPr(m|sjjpjj,l1j,l1mtj,l1t,pt+1P r(mt+1j,l1 |Mj,l1 , aj , oj )(3)j,l1(from Eq. 2)] Ojt+1 thus3. assume agents frames change, may remove arc od[Mj,l1simplifying blanket.231fiZ ENG & OSHIjoint distribution prior aggregation od[Mj,l1] is:t+1t+1P r(st , atj , ot+1j , mj,l1 ) = P r(s )P r(oj |aj )t+1P r(mt+1j,l1 |mj,l1 , aj , oj )Pmtj,l1 Mtj,l1P r(mtj,l1 |st )P r(atj |mtj,l1 )(4)equate right hand sides Eqs. 3 4 obtain constraint must satisfiedCPTs chance nodes Markov blanket order joint distributionremain unchanged:Pt,pt,pt+1t+1P r(mtj,l1 |st )p P r(aj |Mj,l1 )P r(mj,l1 |Mj,l1 , aj , oj )mtj,l1 Mt,pj,l1Pt+1t+1mtj,l1 Mtj,l1 P r(mj,l1 |s )P r(aj |mj,l1 )P r(mj,l1 |mj,l1 , aj , oj )P=(5)t+1Notice Eq. 5 imposes constraint CPTs successor nodes, Atj od[Mj,l1].t+1constraint satisfied setting CPTs nodes, Aj od[Mj,l1 ], foundgrouping AE models initial model node exact optimality I-DIDpreserved. obvious way satisfy Eq. 5 would meet following intuitive constraintAE class p:t,pt+1t+1P r(atj |Mt,pj,l1 )P r(mj,l1 |Mj,l1 , aj , oj ) =Pt,pmtj,l1j,l1t+1 )P r(mtj,l1 |st )P r(atj |mtj,l1 )P r(mt+1j,l1 |mj,l1 ,aj ,ojPP r(mtj,l1 |st )t,p(6)j,l1j,l1t,pP r(atj |mtj,l1 ) fixed model, mtj,l1 , AE class Mj,l1equals P r(atj |Mt,pj,l1 ).Therefore, Eq. 6 reduces to:t,pt+1P r(mt+1j,l1 |Mj,l1 , aj , oj )=Pt,pmtj,l1j,l1Pt+1 )P r(mtj,l1 |st )P r(mt+1j,l1 |mj,l1 ,aj ,ojt,pmtj,l1j,l1P r(mtj,l1 |st )(7)Observe Eq. 7 must hold values physical state, st . right hand sidet+1equation remains unchanged value st , may set CPT od[Mj,l1]using it. Typically, trivial often possible find single CPT chance nodet+1od[Mj,l1] satisfy constraint st . Chang Fung (1991) demonstrateclose approximation would take average right hand side Eq. 7 possiblevalues st values close.t+1course, may wish aggregate models node, od[Mj,l1], well (and on).overall procedure analogous, difference Markov blanket nodeaggregated. includes predecessor chance nodes, od[Mj,l1], Atj , Ojt+1 additionsuccessors parents successors corresponding Fig. 15.illustrate application Eq. 7 example policy graph Fig. 14(a) below:Example 2 (Model update). simplicity, let left AE class, Mt=0,1j,l1 , comprise three models,t=0,2t=0,3mt=0,1j,l1 , mj,l1 mj,l1 , prescribe action L. Let belief three models232fiE XPLOITING ODEL E QUIVALENCES OLVING NTERACTIVE DYNAMIC NFLUENCE IAGRAMS0.16, 0.23 0.32 given physical state TL TR, respectively (see Fig. 14(a)). setprobability updating say, Mt=0,1j,l1 , using different action-observation combinations individualmodels time t=1, using Eq. 7. show probabilities Fig. 14(b); form CPTt=1 ]. P r(mt=0,1 |s) remains given s, constraint Eq. 7 metnode od[Mj,l1j,l1AE based partitioning t=0 exact.Next, group AE models t=1 forming 3 AE classes shown Fig. 14(c). Again, mayset probabilities updating AE class given action-observation combinations individualmodels t=2 using right hand side Eq. 7. However, meet constraintt=0,p t=0 t=1represented Eq. 7 example, P r(mt=1,1j,l1 |Mj,l1 , aj , oj ) varies given differentvalues conditionals. aside, possible meet constraint example.t=2 ], according averageConsequently, adjust CPT chance node, od[Mj,l1right hand side Eq. 7 different values conditional variables (see Fig. 14(c)). result,AE based partitioning t=1 exact.manifestation approximation agent may think j could initially openright door, followed listening open left right door again. sequenceactions j possible original policy graph shown Fig. 14(a).5.3 Algorithmprovide algorithm exploiting AE order solve level l 1 I-DID (as well level0 DID) Fig. 16. algorithm starts selectively solving lower-level I-DID models= 0, results set policy trees (line 2). build policy graph mergingpolicy trees mentioned lines 1-13 Fig 13. algorithm differs Fig. 13expansion phase. particular, begin grouping together AE models initial modelnode. changes value initial od node AE classes (lines 3-9). Subsequently,updated models AE aggregated time steps, CPTs od nodesrevised reflect constraint involving AE classes (lines 13-24). mentioned Section 5.2,AE partitioning becomes inexact cannot find CPT successor od node satisfiesEq. 7. Given expanded I-DID, use standard look-ahead backup method getsolution.5.4 Computational Savingsmentioned, complexity exactly solving level l I-DID is, part, due solvinglower-level models agent, given solutions, due exponentially growingspace models. particular, time step t, could |M0j,l1 |(|Aj ||j |)tmany models, M0j,l1 set initial models agent. K |M0j,l1 |models solved, considering AE bounds model space |Aj | distinct classes. Thus,cardinality interactive state space I-DID bounded |S||Aj | elementstime step. significant reduction size state space. so, additionallyincur computational cost merging policy trees, O((|j |T 1 )2 |M0j,l1 |2 ) (fromProposition 2). point approach applied recursively solve I-DIDs levels1, shown algorithm.233fiZ ENG & OSHII-DID PPROX AE (level l 1 I-DID level 0 DID, , K, )1. l 12. Selectively solve models M0j,l1 Fig. 13 obtain policy graph, P GExpansion Phase3. l 14. m0j M0j,l15.v vertex P G m0j maps6.aj Lv (v) encountered previously0,aj7.Initialize AE class Mj,l10,aj8.Mj,l1 {m0j }09. Mj,l1 Set AE classes10. 0 211.l 1t+1Populate Mj,l1using AE classes12.13.14.15.16.17.18.19.20.21.22.23.24.25.26.t,ajMtj,l1Mj,l1t,ajmtj Mj,l1aj OP (mtj )oj jv vertex P G mtj mapsaj Lv (Tp (v, oj )) encountered previouslyt+1,aInitialize AE class Mj,l1 jt+1Update js belief, bj SE(btj , aj , oj )mt+1New I-DID (or DID) bt+1beliefjjt+1,aj}Mj,l1 {mt+1jMt+1j,l1 Set AE classesUpdate CPT node od[Mt+1j,l1 ] meet constraint specified Eq. 7possible, otherwise take averaget+1t+1Add model node, Mj,l1, model update link Mj,l1Mj,l1Add chance, decision, utility nodes + 1 time slice dependencylinksEstablish CPTs chance node utility nodesolution phase proceeds analogously one Fig. 10.Figure 16: Algorithm possibly inexactly solving level l 1 I-DID using action equivalence.6. Empirical Resultsimplemented algorithms Figs. 10, 13 16 refer resulting techniquesExact-BE, DMU AE, respectively. addition these, utilize previous approximationtechnique k-means clustering (Zeng et al., 2007), referred MC, exact approachwithout exploiting BE, referred Exact, baselines. MC, models clustered basedspatial closeness beliefs, clusters refined iteratively stabilize.I-DIDs eventually transform flat DIDs, implemented layer popular ID234fiE XPLOITING ODEL E QUIVALENCES OLVING NTERACTIVE DYNAMIC NFLUENCE IAGRAMStool, H UGIN E XPERT V 7.0. transformed flat DIDs level 0 DIDs solved usingH UGIN obtain policy trees.benchmark problem domains, evaluate techniques two well-known toy problemsnew scalable multiagent testbed practical implications. One benchmarkstwo-agent generalization single agent tiger problem introduced previously Section 3.mentioned, formulation problem (|S|=2, |Ai |=|Aj |=3, |i |=6, |j |=2) followsone introduced Gmytrasiewicz Doshi (2005), differs formulation Nairet al. (2003), cooperative door creaks additional observations.observations informative, though perfectly, js actions. toy domain generalization Smallwood Sondiks machine maintenance problem (Smallwood & Sondik, 1973)two-agent domain. problem (|S|=3, |Ai |=|Aj |=4, |i |=|j |=2) fully describedAppendix B.2. I-DIDs problem domains shown Section 3 Appendix B.2,respectively. Decentralized POMDP solution techniques appropriate baselines cooperative problems machine maintenance absence common initial beliefamong agents, I-DIDs take perspective agent interaction instead computingjoint behavior.physical dimensions problems small, interactive state space includes models agent order magnitude larger. Furthermore, provide advantage facilitating detailed analysis solutions uncovering interesting behaviors previously demonstrated (Doshi et al., 2009). However, beyond increasing horizons, allowevaluation scalability techniques. context, also evaluate approacheswithin Georgia testbed autonomous control vehicles (GaTAC) (Doshi & Sonu, 2010),computer simulation framework evaluating autonomous control aerial robotic vehicles UAVs. Unmanned agents UAVs used fighting forest fires (Casbeer, Beard,McLain, Sai-Ming, & Mehra, 2005), law enforcement (Murphy & Cycon, 1998), wartime reconnaissance. operate environments characterized multiple parameters affectdecisions, including agents common antagonistic preferences. taskcomplicated vehicles may possess noisy sensors unreliable actuators. GaTAC provideslow-cost open-source alternative highly complex expensive simulation infrastructures.setup execute experiments evaluate following: (a) hypothesize setsmodels attributed agent, several BE. lead exact approachgroups models (Exact-BE) significantly efficient plain approach (Exact).(b) approximation techniques (DMU AE) improve previous approximationtechnique k-means clustering (MC). MC generates models time stepclustering furthermore MC may retain models. (c) Finally, DMU AE,hypothesize AE significantly efficient forms many classesactions only. However, solution quality resulting DMU AE explored.6.1 Improved Efficiency Duereport performance exact methods (Exact-BE Exact) used solvinglevel 1 2 I-DIDs formulated small problem domains. infinitely manycomputable models, obtain policy exactly solving I-DID given finite set modelsagent initially, 0 . Fig. 17, show average rewards gathered executing235fiZ ENG & OSHIpolicy trees obtained exactly solving level 1 2 I-DIDs two problem domains,function time allocated toward solutions.data point average 200 runs executing policies, true modelagent, j, randomly selected according belief distribution js models. timeconsumed function initial number models horizon I-DID,varied beginning 0 = 50 level.Multiagent tiger problemLevel = 1Level = 26.56.5665.55.5Average RewardAverage Reward754.543.554.543.533Exact-BEExact2.5Exact-BEExact2.522051015202530406080100120Time(s)140160180200220240Time(s)(a)(b)Multiagent machine maintenance problemLevel = 20.80.70.7Average RewardAverage RewardLevel = 10.80.60.50.40.30.21020304050Time(s)60700.50.40.30.2Exact-BEExact00.68090(c)0.1100Exact-BEExact150200250Time(s)300350400(d)Figure 17: Performance profiles exact solutions multiagent tiger (a, b) machinemaintenance problems (c, d). Higher average reward given time better. Exact-BEsignificantly improves plain Exact approach levels 1 2. longer timesExact program runs memory. Vertical bars represent standard deviationmean.Fig. 17, observe Exact-BE performs significantly better Exact approach.Specifically, Exact-BE obtains amount reward Exact less time, subsequently, given allocated time, able obtain larger reward Exact.able solve better quality solution less time groups together models retainssingle representative class, thereby reducing number models held modelnode. see significant improvement performances solving I-DIDs levels.uncover main reason behind improved performance Exact-BE Fig. 18.may expect, grouping models Exact-BE maintains much fewer classes models (predicting particular behavior agent) number individual models maintainedExact. occurs horizons problem domains. number models236fiE XPLOITING ODEL E QUIVALENCES OLVING NTERACTIVE DYNAMIC NFLUENCE IAGRAMSMultiagent tigerMultiagent machine maintenance5050ExactExact-BEExactExact-BE40Model ClassesModel Classes403020103020100098765432198Horizon7654321HorizonFigure 18: Exact-BE maintains far fewer classes larger horizons comparison Exact approach. Notice number classes reduces horizon decreasessolutions tend involve fewer distinct behaviors. show increase models time Exact clarity.increase horizon reduces (but time steps increase) due model updates; however, classesreduce smaller horizon less distinct behaviors solutions.increase number levels beyond two model j strategically, expectExact-BE (and Exact) result solutions whose average reward possibly improves doesntdeteriorate. However, number models increases exponentially l, expect substantially computational resources consumed making challenging solve deeperlevels.6.2 Comparative Performance Approximation Methodsdiscriminating model updates described Section 4 leadloss optimality, combined approach solving K (which call KDM U )models 0 models, solving models -closeKDM U models, form policy graph. Thus, initially examine behavior twoparameters, KDM U , regulate performance DMU-based approximationtechnique solving level 1 I-DIDs.show performance DMU multiagent tiger machine maintenanceproblems Fig. 19. also compare performance implementation MC; KM Crepresents total number models retained clustering pruning approach.performance MC shown flat lines play role approach.data point DMU average 50 runs executing policies true modelagent, j, randomly picked according belief distribution js models, solvedexactly possible. Otherwise, l > 1, solve approximately using DMU large KDM Usmall . plot 0 = 100, horizon 10. increase number modelsrandomly selected, KDM U , reduce distance, , policies improve converge towardexact. Notice DMU improves performance MC reduce , KDM U = KM C .behavior remains true multiagent machine maintenance problem well.evaluate impact AE solving level 1 I-DIDs problem domains compareMC. experiments run analogously different values KAE .parameters play roles similar use DMU. observe Fig. 20237fiZ ENG & OSHIMultiagent tigerMultiagent machine maintenance0.756.50.760.65Average RewardAverage Reward75.554.5KDMU=25KDMU=50KMC=25KMC=50Exact-BE M0=10043.530.900.700.500.300.100.090.60.550.50.45KDMU=25KDMU=50KMC=25KMC=50Exact-BE M0=1000.40.350.30.900.070.700.500.300.100.090.07(a)(b)Figure 19: Performance profiles DMU horizon =10, level 1 I-DID 0 =100.given 0 , performance approaches exact method KDM U increasesreduces. comparison MC indicates better performance achievedDMU-based solutions.Multiagent tigerMultiagent machine maintenance0.756.50.760.65Average RewardAverage Reward75.554.5KAE=25KAE=50KMC=25KMC=50Exact-BE M0=10043.530.900.700.500.300.100.090.60.550.50.45KAE=25KAE=50KMC=25KMC=50Exact-BE M0=1000.40.350.070.30.900.700.500.300.100.090.07(a)(b)Figure 20: Performance profiles AE horizon =10, level 1 I-DID 0 =100. given0 , performance approaches exact method KAE increases reduces. Comparative performance relation MC indicates AE capableachieving better quality solutions (although relatively small values ).reduces models beyond KAE solved, solution generated AE improvesMC case KAE = KM C . course, solve models initially, AE producesbetter quality solutions generated policy graph includes parts exact graph.Additionally, may expect, solution quality approaches exact becomessignificantly close exact (within one standard deviation tiger problem) < 0.1.previous experiments demonstrated DMU AE capable improving MC, clear many initial models beyond KM C solved obtainimprovements. Furthermore, performance DMU AE compared. Fig. 21,directly compare performance DMU, AE MC. particular, measure averagerewards obtained corresponding solutions level 2 I-DIDs function time consumed238fiE XPLOITING ODEL E QUIVALENCES OLVING NTERACTIVE DYNAMIC NFLUENCE IAGRAMSMultiagent tigerMultiagent machine maintenance6.50.6560.6Average RewardAverage Reward5.554.543.50.50.45AEDMUMC30.552.5AEDMUMC0.4406080100120140160180200220240Time(s)6080100120140160180200220240Time(s)Figure 21: Performance comparison approximation techniques solving level 2 I-DIDs. AEachieves significantly improved efficiency identical quality solutions twodomains.approaches. DMU AE, time taken dependent parameters (K ), treemerging horizon I-DID solved. MC, time due iterative clusteringconvergence K models picked. problem domains considered, largerhorizon increasing K reducing typically leads better average rewards. observeDMU AE significantly improve MC produce identical quality solutionsless time MC. Furthermore, DMU AE, latters performancefavorable. because, grouping AE models may result additional approximation,efficiency made possible fewer AE classes whose number exceedconstant across horizons.empirically explore reason behind comparative performance approximationtechniques. time (and space) consumed approaches predominantly duesolution models model node, focus models retained approachesdifferent horizons. Fig. 22 shows models different horizons varyingproblem domains. Note = 0, initial models solved case DMU,results behaviorally minimal set every horizon. Furthermore, mentioned previously,non-zero , merged policy graph subgraph exact ( = 0) case. show,resulting sets models subsets minimal set.horizon, AE maintains model classes number js actions, |Aj |.see, substantially less number maintained DMU. MC maintains fixednumber, KM C , models horizon I-DID.6.3 Runtime Comparisonshow run times exact approximation techniques solving level 1 2 I-DIDsscaling horizons, Table 1. Notice plain exact approach exploitmodel equivalences scales poorly beyond small horizons. contrast, simply grouping modelsreducing exponential growth models leads significantly faster executions betterscaleup. run times reported approaches solving I-DID exactly.obtaining run times approximations, adjusted corresponding parametersquality solution approach similar other. DMU AE reported239fiZ ENG & OSHIMultiagent tiger88Exact-BEDMU =0.09DMU =0.5DMU =0.976Model classesModel Classes6Exact-BEAE =0.09AE =0.5AE =0.975432543211009876543219876Horizon54321Horizon(a)(b)Multiagent machine maintenance66Exact-BEDMU =0.09DMU =0.5DMU =0.9Exact-BEAE =0.09AE =0.5AE =0.954Model classesModel classes53214321009876543219Horizon87654321Horizon(c)(d)Figure 22: Number models maintained model node different horizon level 1 I-DIDmultiagent tiger (a, b) machine maintenance (c, d) problems. DMU,reduces, model space approaches minimal set. Aggregation using AEreduces model space.substantially less execution times better scaleup comparison MC domains.However, run times DMU AE relatively similar level 1 I-DIDs. Although,saw previously, difference number models maintained two techniques,solving js level 0 DIDs quick difference lead significant impact.differences run times significant level 2 I-DIDs solving js level 1 I-DIDscomputationally intensive. may expect, AE consumes substantially less time comparisonDMU sometimes less half. approaches scale similarly terms horizon.particular, able solve level 1 2 I-DIDs horizon 10.scaleup limited predominantly due use software H UGIN solving flatDIDs, seeks keep entire transformed main memory.6.4 Scalable Testbed: GaTACmentioned, objective behind developing GaTAC provide realistic scalabletestbed algorithms multiagent decision making. GaTAC facilitates providing intuitive easy deploy architecture makes use powerful, open-source software components.Successful demonstrations algorithms GaTAC would represent tangible gainspotential practical applications toward designing autonomous vehicles UAVs. 44. GaTAC available download http://thinc.cs.uga.edu/thinclabwiki/index.php/GaTAC_:_Georgia_Testbed_for_Autonomous_Control_of_Vehicles240fiE XPLOITING ODEL E QUIVALENCES OLVING NTERACTIVE DYNAMIC NFLUENCE IAGRAMSLevelDomain4814461236104610TigerLevel 1MMTigerLevel 2MMExact5.8s**6.66s**3m 24s**5m12s**Exact-BE0.47s10.5s2h 4m0.45s1.73s9m 40s10.97s22m 6s2h 48m1.11s13.59s20m 36sDMU0.13s1.27s15m 6s0.19s0.53s2m 9s4.63s6m 54s27m 36s0.33s4.3s3m 36sAE0.42s1.64s15m 15s0.22s0.58s2m 12s3.11s3m 3s16m 54s0.58s1.48s2m 15sMC2.12s28.45s*3.23s9.88s*1m 46s**2m 21s**Table 1: Exploiting model equivalences significant impact execution times. DMUAE demonstrate improved efficiency. Algorithm involving AE scales significantlybetter larger horizons deeper strategy levels. experiments run WinXPplatform dual processor Xeon 2.0GHz 2GB memory. * indicates datapoint unavailable program ran memory.< Socket, port >Low-level controlHigh-level controlCommunicationModule(UDP)Flight SimulatorInstance #1< Socket, port >AutonomousControl ModuleHigh-level stateFlight dynamicsHost 1Host 2Flight SimulatorServerHigh-level stateFlight SimulatorInstance #2CommunicationModule< Socket, port >(UDP)Flight dynamicsHost 3manual control(a)(b)Figure 23: (a) Design GaTAC showing two networked instances flight simulator (FlightGear3D scenery TerraGear), one autonomously manually controlled.GaTAC extensible instances may added. (b) Snapshot UAV flyingwithin FlightGear. Different viewpoints including external view showncockpit view available.simplified design GaTAC architecture shown Fig. 23, manually controlledUAV interacting autonomous one. Briefly, GaTAC employs multiple instances opensource flight simulator, called FlightGear (Perry, 2004), possibly different networked platformscommunicate via external servers, autonomous control moduleinteracts simulator instances. GaTAC deployed platforms including Linux241fiZ ENG & OSHIWindows moderate hardware requirements, entire source code availableGNU Affero public license version 3.utilize relatively straightforward setting consistinganother hostile fugitive, target ground reconnaissance (Fig. 24). UAV must track fugitiveflees safe house. problem made complex assuming fugitive unaware precise location though knows location safe house,may aware fugitives location. problem complicated realistically assume nondeterministic actions observations. simulationsGaTAC include grids sizes 3 3 5 5actors each. GaTAC may programmed supportcomplex scenarios comprising team UAVs, multiplehostile UAVs reconnaissance targets attempting blend Figure 24: Example 5 5 theaterUAV I, perin civilians.forms low-altitude reconWe summarize formulation UAVs problemnaissance potentiallydomain. utilize possible relative positionshostile theater populatedfugitive states. Hence, possible states would same,fugitive, J.north, south, east, west, north-west, on. representation 3 3 theater consists 25 physical statesUAV I. assume fugitive unaware location resulting 9 physicalstates it. Extending theater 5 5 grid leads 81 physical states UAV 25fugitive. factor physical state two variables I-DID model rowcolumn positions, respectively. UAV fugitive may move one four cardinaldirections, may additionally hover current positions listen get informativeobservations. Thus actions fugitive {move north, move south, move west,move east, listen}. may synchronize actions two agents GaTAC allocatingequal time duration performance action. Typically, UAVs infrared camerasensors whose range limited. Accordingly, assume UAV fugitivesense whether respective target north (sense north), south (sense south),west east row (sense level) location (sense found).target fugitive, fugitives target safe house. assumefugitive unaware presence, transition function straightforward simply reflectspossible nondeterministic change grid location fugitive moves listens. However,transitions physical state contingent joint actions agents. Furthermore,probability distribution next states due nondeterminism actions,also influenced current relative physical state. provide opportunity UAVcatch fugitive, assume fugitive sense safe house withindistance 1 sector (horizontally vertically) it. hand, UAV observationsfugitive limited constraint. Thus, fugitive location north(including north-west north-east), receives observation sense north. simulate noisesensors, assume likelihood correct observation 0.8 others equiprobable. reward function straightforward fugitive receiving reward locationidentical safe house, small costs performing actions discourage excessive242fiE XPLOITING ODEL E QUIVALENCES OLVING NTERACTIVE DYNAMIC NFLUENCE IAGRAMSaction taking. Analogously, UAV recieves reward performing action receivingobservation sense found, incurs small costs actions lead observations.ListenListenMove_NorthSense_NorthSense_SouthSense_LevelSafeSense_ Sense_NorthSouth*Move_NorthListenMove_WestListen**Move_NorthListenListen*Sense_ Sense_NorthSouthMove_NorthListenSense_LevelMove_WestSafeMove_WestListenMove_NorthSense_ Sense_NorthSouthListenSense_LevelSafeMove_WestSense_LevelFoundMove_NorthMove_SouthMove_WestListen***Sense_ Sense_FoundNorthLevelMove_NorthListenMove_EastMove_NorthListenListenListen(b)(a)Figure 25: (a) Example policies fugitive modeled UAV. (b) UAV optimal policypursuing fugitive obtained solving level 1 I-DID exactly using BE. policystraightforward, using observations guide actions. policies 3 3grid.modeled problem formulation described using level 1 I-DID UAVlevel 0 models fugitive. show two example policies fugitive obtained solvinglevel 0 models, Fig. 25(a). considered several models fugitive differinginitial beliefs, fugitives initial belief likely safe house results leftpolicy, initial belief likely south east safe house leads policyright. show UAVs policy reconnaissance Fig. 25(b), obtained solving level 1I-DID exactly utilizing classes. Thirty models fugitive grouped 16 classesconsidered I-DID. Here, UAV initially believes fugitive likelyrow south it.simulate reconnaissance theaters Fig. 24 GaTAC. UAV fugitivesbehaviors controlled respective policies provided input autonomous controlmodule. simulation run, generated UAVs policy solving level 1 I-DID usingeither Exact-BE, DMU AE, sampled one fugitives 30 models based UAVsinitial belief. run terminates either fugitive reaches safe house, UAV spotsfugitive entering sector fugitive. case DMU AE, usedparameters, K = 13 = 0.3 3 3 problem size, K = 17, = 0.15 5 5problem. show average reward gathered UAV across 20 simulation runsthree approaches Fig. 26(a) associated clock time solving I-DIDs Fig. 26(b).considered several different beliefs UAV, positioning approximatelyfugitive safe house yielded fugitive capture rate 65% among simulation runsescape rate 25%. remaining runs result capture escape.exactly solving I-DID using Exact-BE continues provide largest reward amongapproaches, shown Fig. 26(a), fails scale longer horizon problem size.DMU AE scale, although AE performs worse DMU context reward domain.Note longer horizons result overall better quality policies problem domain, mayexpect. UAV able plan initial action better. Finally, improved rewardobtained AE relative DMUs horizon increases 6 8 3 3 grid,243fiAverage RewardZ ENG & OSHI5040ExactBEDMUAEProblem size3033 grid201003683x355 grid636868Exact-BE1m 21s4m 32s***DMU8.7s28s3h 13m10m 18s11h 14mAE7.13s19.24s23m 54s2m 12s41m 30s5x5Horizon(T)(a)(b)Figure 26: (a) Simulation performance UAV GaTAC level 1 I-DID solved usingdifferent approaches longer horizons. scaled grid size 3 35 5. Notice Exact-BE fails scale horizon problem size increaseshow reward. (b) Execution times solving level 1 I-DID usingdifferent approaches. Although AE results solutions lower quality comparedDMU, much less time. longer horizon 8, time differenceorder magnitude.slight climb AEs relative reward percentage DMUs 57% 62%horizon 6 grid size scaled 3 3 5 5 makes us believe AEs performancenecessarily deteriorate compared DMU larger problems. Overall, demonstratescalability DMU AE increasing horizon 8 larger problem domain,scaling size. Larger grid sizes longer horizons resulted DIDs could solvedH UGIN given fixed memory.SNSNSLSNSNSN(a)(b)(c)Figure 27: UAV flight trajectory dashed blue fugitives dashed red. Trajectories (a, b) eventually lead fugitive spotted (c), fugitive reachessafe house. latter due incorrect move UAV ambiguityobservations. circle represents hovering UAV fugtivelistening senses labeled observation.244fiE XPLOITING ODEL E QUIVALENCES OLVING NTERACTIVE DYNAMIC NFLUENCE IAGRAMSFinally, handpick three simulations numerous carried showcorresponding trajectories UAV fugitive Fig. 27. show two trajectoriesUAV spots fugitive trajectory fugitive successfully escapes safehouse.Figure 27 shows trajectories UAV get quite complicated fugitivestraightforward due low strategic awareness.7. DiscussionGraphical models appealing formalism modeling decision making due conveniencerepresentation increased efficiency solution. DIDs key contributionregard. I-DIDs founded normative paradigm decision theory formalized DIDsaugmented aspects Bayesian games (Harsanyi, 1967) interactive epistemology (Aumann, 1999a, 1999b) make applicable interactions. I-DIDs generalize DIDs multiagentsettings thereby extending advantages DIDs decision making multiagent settings. I-DIDsadopt subjective approach understanding strategic behavior, rooted decision-theoretic formalism takes decision-makers perspective interaction may cooperativenon-cooperative. broader impact understanding agents decision-making process facilitates planning problem-solving level absence centralized controllersassumptions agent behaviors. game-theoretic sense, setting modeled I-DIDspartially observable stochastic game, solving computing Nash equilibria otherwise,received minimal attention game theory.presented collection exact approximation algorithms scalably solving I-DIDs.algorithms improve early techniques providing effective approaches orderreduce exponential growth agents models time step. main idea clustermodels attributed agents BE. models attribute identical behaviors acrosstime steps agent. select representative models cluster without lossoptimality solution. Instead generating updated models clustering them,showed may selectively update models existing modelsnext time step. Nevertheless, ascertaining requires solving initial set models. orderapproximate this, proposed solving K randomly picked models followed-close K models. partially bounded error due approximationcases. Despite lack proper bound, empirical results reveal error becomesunwieldy large values only. many problems admit large regions models,albeit tend reduce horizon increases.order reduce number equivalence classes, investigated grouping togethermodels whose prescribed actions particular time step identical. approach appealingnumber AE classes upper bounded number distinct actions time.AE models may grouped without loss optimality, identified conditionsAE leads approximation. experiments indicate considerationssignificance grouping AE models leads reduction model space amongdifferent approaches. However, also show gap quality solutions duegrouping grouping AE models become large. difference depends domaincharacteristics necessarily worsen problem scaled horizon size.Due expressiveness modeling ensuing complexity, experimentationfocused settings involving two agents. However, number agents increases, po245fiZ ENG & OSHItential computational savings due exploiting AE assumes greater significance.space interactive states increases exponentially number agents. Therefore, grouping agent models less numbers classes would substantially reduce state spaceconsequently size I-DID. may group models separately agentcase computations ascertaining classes grow linearly number agents.hand, consider tiger problem agent action affected somebody openingdoor, without need knowing particular agent opened it. case, may grouptogether models belonging different agents, leading increased savings.preliminary experimentation context multiagent tiger problem setting involvingtwo agents (total three agents) one thought cooperativeadversarial, indicates grouping models agent leads speed 73-horizon 5-horizon I-DID. Specifically, computation time reduces 4.8sExact 0.6s Exact-BE horizon 3, 72.6s 10.5s Exact-BEhorizon 5.identifying exact computationally intensive, think improved scalabilitymay brought investigating approximate models. would allow us formlarger clusters fewer representative models. investigating multiple waysthis, significant challenge storing policy trees grow exponentially horizonscaled. One promising approach regard compare partial policy trees boundeddepth distance belief vectors leaves trees. allows us defineapproximate measure based distance updated belief vectors givenbounded-depth policy trees identical. However, preliminary investigations revealderiving depth tree becomes challenging certain types problems.general limitation utilizing spatial closeness beliefs approximately identifyingmodels error may larger frames models differ. modelbeliefs close still less likely result behavior say, reward functionsdifferent. absence approximation, approaches discriminatively updatingmodels grouping AE models continue apply frames also uncertain operatemodel solutions policy trees actions model specifications. Another impactconsidering frame uncertainty Markov blanket shown Fig. 15 changes. general hurdlescalability ID-based graphical models also limited absence state-ofthe-art techniques solving DIDs within commercial implementations H UGIN E XPERTpredominantly rely solving entire main memory. Although newer versionsH UGIN allow use limited memory IDs (Nilsson & Lauritzen, 2000), recent advancesbranch-and-bound approach solving multistage IDs (Yuan, Wu, & Hansen, 2010) would helpdrive scalability I-DID solutions.AcknowledgmentsYifeng Zeng acknowledges support Obel Family Foundation (Denmark) NSFC (#60974089 # 60975052). Prashant Doshi acknowledges support NSF CAREER grant (#IIS-0845036) grant U.S. Air Force (# FA9550-08-1-0429). authors also thank EkhlasSonu Yingke Chen help performing GaTAC-based simulations, acknowledgeanonymous reviewers helpful comments.246fiE XPLOITING ODEL E QUIVALENCES OLVING NTERACTIVE DYNAMIC NFLUENCE IAGRAMSAppendix A. ProofsProof Proposition 1. prove induction horizon. Let {M1j,l1 , . . . , Mqj,l1 }collection behaviorally equivalent sets models Mj,l1 . aim show valueactions decision nodes time step remains unchanged applicationtransformation, X. implies solution I-DID preserved. Let Qn (bi,l , ai ) giveaction value horizon n. computation I-DID could modeled using standard dynamic programming approach. Let ERi (s, mj,l1 , ai ) expected immediatePreward agentaveraged js predicted actions. Then, mq MqERi (s, mqj,l1 , ai ) = aj Ri (s, ai , aj )j,l1j,l1P r(aj |mqj,l1 ) = Ri (s, ai , aqj ), aqj optimal mqj,l1 Mqj,l1 .PBasis step: Q1 (bi,l , ai ) = s,mj,l1 bi,l (s, mj,l1 )ERi (s, mj,l1 , ai )PP= s,q bi,l (s) mq Mqbi,l (mqj,l1 |s)Ri (s, ai , aqj ) (aqj optimal behaviorally equivalentj,l1j,l1models Mqj,l1 )PP= s,q bi,l (s)Ri (s, ai , aqj ) mq Mqbi,l (mqj,l1 |s)j,l1j,l1P= s,q bi,l (s)Ri (s, ai , aqj )bi,l (mqj,l1 |s)(from Eq. 1)Pqq= s,q bi,l (s, mj,l1 )ERi (s, mj,l1 , ai ) (aqj optimal representative mqj,l1 )= Q1 (bi,l , ai )Inductive hypothesis: Let, ai ,bi,l Qn (bi,l , ai ) = Qn (bi,l , ai ), bi,l relates bi,l using Eq. 1.Therefore, U n (bi,l ) = U n (bi,l ) U n (bi,l ) expected utility bi,l horizon n.PInductive proof: Qn+1 (bi,l , ai ) = Q1 (bi,l , ai ) + oi ,s,mj,l1 ,aj P r(oi |s, ai , aj )P r(aj |mj,l1 )bi,l (s, mj,l1 )U n (bi,l ) (basis step)PP= Q1 (bi,l , ai ) + oi ,s,q P r(oi |s, ai , aqj ) bi,l (s) mq Mqbi,l (mqj,l1 |s) U n (bi,l ) (aqj optij,l1j,l1mal models Mqj,l1 )PPbi,l (mqj,l1 |s) U n (bi,l ) (using= Q1 (bi,l , ai ) + oi ,s,q P r(oi |s, ai , aqj ) bi,l (s) mq Mqj,l1j,l1inductive hypothesis)P= Q1 (bi,l , ai ) + oi ,s,q P r(oi |s, ai , aqj ) bi,l (s) bi,l (mqj,l1 |s) U n (bi,l ) (from Eq. 1)P= Q1 (bi,l , ai ) + oi ,s,q P r(oi |s, ai , aqj ) bi,l (s, mqj,l1 ) U n (bi,l )= Qn+1 (bi,l , ai )Calculating prediction error Section 4.5. Let mj,l1 model associated solvedmodel, mj,l1 , resulting worst error. Let exact policy tree obtained solvingmj,l1 optimally policy tree mj,l1 . mj,l1 solved inexactly dueapproximate solutions lower level models, let exact policy tree optimalmj,l1 . bj,l1 belief mj,l1 bj,l1 mj,l1 , error is:E= | bj,l1 bj,l1 |= | bj,l1 bj,l1 + ( bj,l1 bj,l1 )|(add zero)= |( bj,l1 bj,l1 ) + ( bj,l1 bj,l1 )||( bj,l1 bj,l1 )| + |( bj,l1 bj,l1 )| (triangle inequality)(8)first term, | bj,l1 bj,l1 |, denote , error due associatingmj,l1 mj,l1 , solved exactly. analyze error below:247fiZ ENG & OSHI= | bj,l1 bj,l1 |= | bj,l1 bj,l1 + bj,l1 bj,l1 | (add zero)| bj,l1 bj,l1 + bj,l1 bj,l1 | ( bj,l1 bj,l1 )= | (bj,l1 bj,l1 ) (bj,l1 bj,l1 )|= |( ) (bj,l1 bj,l1 )|(Holders inequality)|| || ||bj,l1 bj,l1 ||1(Rjmax Rjmin )T(9)inequality, largest difference bj,l1 bj,l1 , otherwise model,mj,l1 belief bj,l1 , would solved. Notice error regulated , increases,solve less models beyond K approximation error worsens.subsequent time steps, sets models could subsets minimal sets,updated probabilities could transferred incorrect models. worst case, error incurredbounded analogously Eq. 9. Hence, cumulative error js predicted behavior steps, similar previous k-means model clustering approach (Zenget al., 2007):(Rjmax Rjmin )T 2second term, |( bj,l1 bj,l1 )|, Eq. 8 represents error due approximatesolutions models level (for example, level l 2 models). Since js behaviordepends, part, actions (and value solution), even slight deviationj exact prediction could lead js behavior worst error. Hence, seemsdifficult derive bounds second term tighter usual, (Rjmax Rjmin )T .Consequently, total error predicting js behavior bounded lower-level modelssolved exactly. Otherwise, show Section 6.2, error large large .many problems admit large regions models thereby overconstraining ,prediction continues remain exact. However, noticed regions reduce sizehorizon increases. summary, although error due associating different models whosebeliefs -close bounded, unable usefully bound overall error prediction dueapproximate solutions lower-level models.Appendix B. Problem Domainsprovide detailed descriptions problem domains utilized evaluations, includingI-DID models, below.B.1 Multiagent Tiger Problemmentioned previously, multiagent tiger problem non-cooperative generalizationwell-known single agent tiger problem (Kaelbling et al., 1998) multiagent setting. differsmultiagent versions problem (Nair et al., 2003) assuming agentshear creaks well growls reward function promote cooperation. Creaksindicative door opened agent(s). described problemSection 3, quantify different uncertainties here. assume accuracy creaks90%, accuracy growls 85% single agent problem. tiger locationchosen randomly next time step agents opened doors current step.248fiE XPLOITING ODEL E QUIVALENCES OLVING NTERACTIVE DYNAMIC NFLUENCE IAGRAMSFig. 8 shows I-DID unrolled two time-slices multiagent tiger problem. giveCPTs different nodes below:hati , atjhOL,hOR,h, OLih, ORihL, LihL, LiTigerLocationt****TLTRTL0.50.50.50.51.00TR0.50.50.50.501.0Table 2: CPT chance node igerLocationt+1 I-DID Fig. 8.assign marginal distribution tigers location agent initial beliefchance node, igerLocationt . CPT igerLocationt+1 next time step conditionedigerLocationt , Ati , Atj transition function, shown Table 2. CPTobservation node, Growl&Creakt+1 , shown Table 3. CPTs observation nodes level0 DIDs identical observation function single agent tiger problem.hati , atjhL, LihL, LihL, OLihL, OLihL, ORihL, ORihOL,hOR,TgrLoct+1TLTRTLTRTLTRhGL, CLi0.85*0.050.15*0.050.85*0.90.15*0.90.85*0.050.15*0.051/61/6hGL, CRi0.85*0.050.15*0.050.85*0.050.15*0.050.85*0.90.15*0.91/61/6hGL, Si0.85*0.90.15*0.90.85*0.050.15*0.050.85*0.050.15*0.051/61/6hGR, CLi0.15*0.050.85*0.050.15*0.90.85*0.90.15*0.050.85*0.051/61/6hGR, CRi0.15*0.050.85*0.050.15*0.050.85*0.050.15*0.90.85*0.91/61/6hGR, Si0.15*0.90.85*0.90.15*0.050.85*0.050.15*0.050.85*0.051/61/6Table 3: CPT chance node, Growl&Creakt+1 , agent I-DID.Decision nodes, Ati At+1, contain possible actions agent L, OL, OR. Modelnode, Mj,l1, contains different models agent j DIDs I-DID level 0,otherwise I-DIDs themselves. distribution associated od[Mjt ] node (seeFig. 9) conditional distribution js models given physical state agent initialt+1belief. CPT chance node, od[Mjt+1 ], model node, Mj,l1, reflects priormodel, action observation j results model contained model node.Finally, utility node, Ri , I-DID relies agents actions, Ati Atj ,physical states, igerLocationt . utility table shown Table 4. payoffs analogoussingle agent version, assigns reward 10 correct door opened, penalty100 opened door one behind tiger, penalty 1 listening. resultassumption agents actions impact original agents payoffs directly,rather indirectly resulting states matter original agent. utility tables level0 models exactly identical reward function single agent tiger problem.249fiZ ENG & OSHIhai , ajhOR, ORihOL, OLihOR, OLihOL, ORihL, LihL, ORihOR, LihL, OLihOL, LiTL10-10010-100-1-110-1-100TR-10010-10010-1-1-100-110Table 4: Utility table node, Ri , I-DID. Utility table I-DID agent jcolumn label, hai , aj i, swapped.B.2 Multiagent Machine Maintenance Problemextend traditional single agent based machine maintenance (MM) problem (Smallwood &Sondik, 1973) two-agent cooperative version. Smallwood Sondik (1973) described MMproblem involving machine containing two internal components. Either one componentsmachine may fail spontaneously production cycle (0-fail: component fails; 1fail: 1 component fails; 2-fail: components fail). internal component failed,chance operating upon product, cause product defective.agent may choose manufacture product (M) without examining it, examine product (E),inspect machine (I), repair (R) next production cycle. examinationproduct, subject may find defective. course, components failed,probability product defective greater.RiRiAitAit+1AjAjt+1MachineFailuretMachineFailuret+1Mj,l-1tMj,l-1t+1DefectiveitDefectiveit+1Figure 28: Level l I-DID agent multiagent MM problem.level l I-DID multiagent MM problem shown Fig. 28. consider modelsagent j lower level differ probability j assigns chance node MachineFailure. Agent initial belief physical state js models provides marginal distribution achineF ailuret . I-DID, chance node, achineF ailuret+1 , incident250fiE XPLOITING ODEL E QUIVALENCES OLVING NTERACTIVE DYNAMIC NFLUENCE IAGRAMSarcs nodes achineF ailuret , Ati , Atj . Table 5, show CPT chancenode.hati , atjhM/E,M/EihM/E,M/EihM/E,M/EihM,I/RihM,I/RihM,I/RihE,I/RihE,I/RihE,I/RihI/R,*ihI/R,*ihI/R,*iMachine Failuret+10-fail1-fail2-fail0-fail1-fail2-fail0-fail1-fail2-fail0-fail1-fail2-fail0-fail0.810.00.01.00.950.951.00.950.951.00.950.951-fail0.180.90.00.00.050.00.00.050.00.00.050.02-fail0.010.11.00.00.00.050.00.00.050.00.00.05Table 5: CPT chance node, achineF ailuret+1 , level l I-DID agent i. level 0CPT analogous one original MM problem.observation chance node, Def ectivet+1, associate CPT shown Table 6.Note arcs achineF ailuret+1 nodes, Ati Atj , previous time stepincident node. observation nodes level 0 DIDs CPTs identicalobservation function original MM problem.hati , atjhM,M/EihM,I/RihE,M/EihE,M/EihE,M/EihE,I/RihI/R,*iMachine Failuret+1**0-fail1-fail2-fail**not-defective0.50.950.750.50.250.950.95defective0.50.050.250.50.750.050.05Table 6: CPT observation node, Def ectivet+1. Corresponding CPT agent js l 1 I-DIDidentical hati , atj swapped.decision node, Ai , one information arc observation node Def ectiveti indicating knows examination results making choice. utility node Ri associatedutility table Table 7. utility table level 0 agent identical oneoriginal MM problem.t+1CPT chance node, od[Mjt+1 ], model node, Mj,l1, reflects priormodel, action observation j results model contained model node, analogouslytiger problem.251fiZ ENG & OSHIhati , atjhM,MihM,EihM,IihM,RihE,MihE,EihE,IihE,RihI,MihI,EihI,IihI,RihR,MihR,EihR,IihR,Ri0-fail1.8051.5550.4025-1.09751.55551.3050.1525-1.34750.40250.1525-1.0-2.5-1.0975-1.3475-2.5-41-fail0.950.7-1.025-1.5250.70.45-1.275-1.775-1.025-1.275-3.00-3.5-1.525-1.775-3.5-42-fail0.50.25-2.25-1.750.250.0-2.5-2.0-2.25-2.5-5.00-4.5-1.75-2.0-4.5-4Table 7: Utility table agent i. Agent js utility table l 1 I-DID identicalcolumn label, hati , atj i, swapped.B.3 UAV Reconnaissance Problemshow level l I-DID multiagent UAV problem Fig 29. Models fugitive (agentj) lower level differ probability fugitive assigns position grid.UAVs (agent i) initial beliefs probability distributions assigned relative positionfugitive decomposed chance nodes, F ugRelP osX F ugRelP osY , representrelative location fugitive along row column, respectively. CPTs assumeaction (except listen) moves UAV intended direction probability 0.67,remaining probability equally divided among neighboring positions. Action listenkeeps UAV position.observation node, SenF ug, represents UAVs sensing relative positionfugitive grid. CPT assumes UAV good sensing capability (likelihood 0.8correct relative location fugitive) action listen, otherwise UAV receivesrandom observations actions.decision node, Ai , contains five actions UAV, includes moving fourcardinal directions listening. edge incident node indicates UAV ascertainsobservation relative position fugitive takes action.utility node, Ri , reward assigned UAV actions given fugitives relativeposition actions. UAV gets rewarded 50 captures fugitive; otherwise, costs -5performing action.actual CPT tables large, show here. problem domainfiles available upon request.252fiE XPLOITING ODEL E QUIVALENCES OLVING NTERACTIVE DYNAMIC NFLUENCE IAGRAMSRiRiAitAit+1AjAjt+1FugRelPosXitFugRelPosXit+1FugRelPosYitFugRelPosYit+1Mj,l-1tMj,l-1t+1SenFugitSenFugit+1Figure 29: Level l I-DID agent UAV reconnaissance problem.ReferencesAndersen, S., & Jensen, F. (1989). Hugin: shell building belief universes expert systems.International Joint Conference Artificial Intelligence (IJCAI), pp. 332337.Aumann, R. J. (1999a). Interactive epistemology i: Knowledge. International Journal GameTheory, 28(3), 263300.Aumann, R. J. (1999b). Interactive epistemology ii: Probability. International Journal GameTheory, 28, 301314.Bernstein, D. S., Givan, R., Immerman, N., & Zilberstein, S. (2002). complexity decentralized control markov decision processes. Mathematics Operations Research, 27(4),819840.Brandenburger, A., & Dekel, E. (1993). Hierarchies beliefs common knowledge. JournalEconomic Theory, 59, 189198.Casbeer, D., Beard, R., McLain, T., Sai-Ming, L., & Mehra, R. (2005). Forest fire monitoringmultiple small uavs. American Control Conference, pp. 35303535.Castro, P., Panangaden, P., & Precup, D. (2009). Equivalence relations fully partially observable markov decision processes. International Joint Conference Artificial Intelligence(IJCAI), pp. 16531658.Chang, K.-C., & Fung, R. (1991). Refinement coarsening bayesian networks. UncertaintyArtificial Intelligence, pp. 435445.Dekel, E., Fudenberg, D., & Morris, S. (2006). Topologies types. Theoretical Economics, 1,275309.Doshi, P., & Sonu, E. (2010). Gatac: scalable realistic testbed multiagent decision making). Fifth Workshop Multiagent Sequential Decision Making Uncertain Domains(MSDM), AAMAS, pp. 6266.253fiZ ENG & OSHIDoshi, P., Zeng, Y., & Chen, Q. (2009). Graphical models interactive pomdps: Representationssolutions. Journal Autonomous Agents Multi-Agent Systems (JAAMAS), 18(3),376416.Duong, Q., Wellman, M., & Singh, S. (2008). Knowledge combination graphical multiagentmodels. Uncertainty Artificial Intelligence (UAI), pp. 153160.Duong, Q., Wellman, M., Singh, S., & Vorobeychik, Y. (2010). History-dependent graphical multiagent models. International Conference Autonomous Agents Multiagent Systems(AAMAS), pp. 12151222.Emery-Montemerlo, R., Gordon, G., Schneider, J., & Thrun, S. (2005). Game theoretic controlrobot teams. International Conference Robotics Automation (ICRA), pp. 11631169.Gal, Y., & Pfeffer, A. (2008). Networks influence diagrams: formalism representing agentsbeliefs decision-making processes. Journal Artificial Intelligence Research, 33, 109147.Givan, R., Dean, T., & Greig, M. (2003). Equivalence notions model minimization markovdecision processes. Artificial Intelligence, 147(1-2), 163223.Gmytrasiewicz, P., & Doshi, P. (2005). framework sequential planning multiagent settings.Journal Artificial Intelligence Research (JAIR), 24, 4979.Harsanyi, J. C. (1967). Games incomplete information played bayesian players. Management Science, 14(3), 159182.Kaelbling, L., Littman, M., & Cassandra, A. (1998). Planning acting partially observablestochastic domains. Artificial Intelligence Journal, 101, 99134.Kearns, M., Littman, M., & Singh, S. (2001). Graphical models game theory. UncertaintyArtificial Intelligence (UAI), pp. 253260.Koller, D., & Milch, B. (2001). Multi-agent influence diagrams representing solving games.International Joint Conference Artificial Intelligence (IJCAI), pp. 10271034.Madsen, N. S., & Jensen, F. V. (2008). influence diagram framework acting influenceagents unknown goals. Fourth European Workshop Probabilistic GraphicalModels (PGM), pp. 289296.Mertens, J., & Zamir, S. (1985). Formulation bayesian analysis games incompleteinformation. International Journal Game Theory, 14, 129.Milner, R. (1980). Calculus Communicating Systems. Springer-Verlag.Murphy, D., & Cycon, J. (1998). Applications mini vtol uav law enforcement. SPIE3577:Sensors, C3I, Information, Training Technologies Law Enforcement.Nair, R., Tambe, M., Yokoo, M., Pynadath, D., & Marsella, S. (2003). Taming decentralized pomdps: Towards efficient policy computation multiagent settings. International Joint Conference Artificial Intelligence (IJCAI), pp. 705711.Nilsson, D., & Lauritzen, S. (2000). Evaluating influence diagrams using limids. UncertaintyArtificial Intelligence (UAI), pp. 436445.254fiE XPLOITING ODEL E QUIVALENCES OLVING NTERACTIVE DYNAMIC NFLUENCE IAGRAMSOliehoek, F. A., Whiteson, S., & Spaan, M. T. J. (2009). Lossless clustering histories decentralized pomdps. International Conference Autonomous Agents Multi-Agent Systems(AAMAS), pp. 577584.Perry, A. R. (2004). flightgear flight simulator. UseLinux.Pineau, J., Gordon, G., & Thrun, S. (2006). Anytime point-based approximations large pomdps.Journal Artificial Intelligence Research (JAIR), 27, 335380.Pynadath, D., & Marsella, S. (2007). Minimal mental models. Twenty-Second ConferenceArtificial Intelligence (AAAI), pp. 10381044, Vancouver, Canada.Rathnasabapathy, B., Doshi, P., & Gmytrasiewicz, P. J. (2006). Exact solutions interactive pomdpsusing behavioral equivalence. Autonomous Agents Multi-Agents Systems Conference(AAMAS), pp. 10251032.Russell, S., & Norvig, P. (2010). Artificial Intelligence: Modern Approach (Third Edition). Prentice Hall.Seuken, S., & Zilberstein, S. (2007). Memory-bounded dynamic programming dec-pomdps.International Joint Conference Artificial Intelligence (IJCAI), pp. 20092015.Seuken, S., & Zilberstein, S. (2008). Formal models algorithms decentralized decisionmaking uncertainty. Autonomous Agents Multi-Agent Systems, 17(2), 190250.Smallwood, R., & Sondik, E. (1973). optimal control partially observable markov decisionprocesses finite horizon. Operations Research (OR), 21, 10711088.Suryadi, D., & Gmytrasiewicz, P. (1999). Learning models agents using influence diagrams.International Conference User Modeling, pp. 223232.Tatman, J. A., & Shachter, R. D. (1990). Dynamic programming influence diagrams. IEEETransactions Systems, Man, Cybernetics, 20(2), 365379.Witwicki, S. J., & Durfee, E. H. (2010). Influence-based policy abstraction weakly-coupleddec-pomdps. International Conference Automated Planning Scheduling (ICAPS),pp. 185192.Yuan, C., Wu, X., & Hansen, E. (2010). Solving multistage influence diagrams using branch-andbound search. Uncertainty Artificial Intelligence (UAI), pp. 691700.Zeng, Y., Doshi, P., & Chen, Q. (2007). Approximate solutions interactive dynamic influencediagrams using model clustering. Twenty Second Conference Artificial Intelligence(AAAI), pp. 782787.255fiJournal Artificial Intelligence Research 43 (2012) 419476Submitted 08/11; published 03/12Completeness Guarantees Incomplete OntologyReasoners: Theory PracticeBernardo Cuenca GrauBoris MotikGiorgos StoilosIan Horrocksbernardo.cuenca.grau@cs.ox.ac.ukboris.motik@cs.ox.ac.ukgiorgos.stoilos@cs.ox.ac.ukian.horrocks@cs.ox.ac.ukDepartment Computer Science, University OxfordWolfson Building, Parks Road, OX1 3QD, OxfordAbstractachieve scalability query answering, developers Semantic Web applicationsoften forced use incomplete OWL 2 reasoners, fail derive answersleast one query, ontology, data set. lack completeness guarantees, however,may unacceptable applications areas health care defence,missing answers adversely aect applications functionality. Furthermore, evenapplication tolerate level incompleteness, often advantageousestimate many kind answers lost.paper, present novel logic-based framework allows one check whetherreasoner complete given query Q ontology is, whether reasonerguaranteed compute answers Q w.r.t. arbitrary data set A. Sinceontologies typical queries often fixed application design time, approach allowsapplication developers check whether reasoner known incomplete generalactually complete kinds input relevant application.also present technique that, given query Q, ontology , reasonersR1 R2 satisfy certain assumptions, used determine whether,data set A, reasoner R1 computes answers Q w.r.t. reasoner R2 .allows application developers select reasoner provides highest degreecompleteness Q compatible applications scalability requirements.results thus provide theoretical practical foundation design futureontology-based information systems maximise scalability minimising eveneliminating incompleteness query answers.1. IntroductionEcient management querying large amounts data core problem growingrange applications fields diverse biology (Sidhu, Dillon, Chang, & Sidhu, 2005),medicine (Golbreich, Zhang, & Bodenreider, 2006), geography (Goodwin, 2005), astronomy(Derriere, Richard, & Preite-Martinez, 2006), agriculture (Soergel, Lauser, Liang, Fisseha,Keizer, & Katz, 2004), defence (Lacy, Aviles, Fraser, Gerber, Mulvehill, & Gaskill,2005). order facilitate interoperability, applications often use standard datamodels query languages. particular, RDF (Hayes, 2004) provides standard modelsemistructured data, SPARQL (Prudhommeaux & Seaborne, 2008) standard querylanguage RDF, ontology languages OWL (Horrocks, Patel-Schneider, &van Harmelen, 2003) OWL 2 (Cuenca Grau, Horrocks, Motik, Parsia, Patel-Schneider,c2012AI Access Foundation. rights reserved.fiCuenca Grau, Motik, Stoilos & Horrocks& Sattler, 2008b) used describe background knowledge applicationdomain. Thus, answering SPARQL queries RDF data sets structured using OWLontology key service ontology-based information systems.important question design systems selection appropriatereasoner. Systems Pellet (Sirin, Parsia, Cuenca Grau, Kalyanpur, & Katz, 2007),HermiT (Motik, Shearer, & Horrocks, 2009b), RACER (Haarslev & Moller, 2001)based (hyper)tableau algorithms provably completethat is, guaranteed compute answers query, ontology, data set. Completeness, however,comes cost scalability, answering queries OWL 2 ontologies high computational complexity (Glimm, Horrocks, Lutz, & Sattler, 2007; Ortiz, Calvanese, & Eiter,2008; Calvanese, De Giacomo, Lembo, Lenzerini, & Rosati, 2007; Lutz, Toman, & Wolter,2009). Thus, complete systems often fail meet scalability demands applicationsmanage data sets consisting hundreds millions even billions assertions.Scalability query answering ensured restricting expressive powerontology language level makes provably complete reasoning tractable.led development three profiles OWL 2 (Motik, Cuenca Grau, Horrocks, Wu,Fokoue, & Lutz, 2009a): OWL 2 EL, OWL 2 RL, OWL 2 QL. Query answeringthree profiles implemented polynomial time w.r.t. size data (and evenlogarithmic space case OWL 2 QL). appealing theoretical propertiesspurred development specialised reasoners QuONTO (Acciarri, Calvanese,De Giacomo, Lembo, Lenzerini, Palmieri, & Rosati, 2005) target specific profilestypically reject ontologies fall outside target profile.dierent solution scalability problem adopted reasoners Oracles Semantic Data Store (Wu, Eadon, Das, Chong, Kolovski, Annamalai, & Srinivasan,2008), Sesame (Broekstra, Kampman, & van Harmelen, 2002), Jena (McBride, Brian, 2001),OWLim (Kiryakov, Ognyanov, & Manov, 2005), Minerva (Ma, Yang, Qiu, Xie, Pan, & Liu,2006), DLE-Jena (Meditskos & Bassiliades, 2008), Virtuoso (Erling & Mikhailov, 2009).reasoners accept OWL 2 ontologies inputthat is, never reject inputs.Furthermore, best knowledge, systems intended sound,means results query indeed correct answers. Finally, reasonerstypically use scalable reasoning techniques, various (deductive) database algorithms.consequence, reasoners incomplete: reasoner, least one query, ontology, data set exist reasoner return answers query.reasoners actually designed complete particular profileOWL 2 (typically OWL 2 RL due close connection datalog),often additionally handle certain kinds axiom fall outside target profile.Since incomplete reasoners handle large data sets, often provide best practical choice developers ontology-based applications. example, OWLim usedreasoning backend BBCs 2010 World Cup website, Oracles reasonerused University Texas Health Science Center improve large-scale publichealth surveillance. order verify selected reasoner meets applicationsrequirements, developers typically resort empirical testing, check reasoners answers w.r.t. application ontology queries representative data sets.Although primarily intended testing performance, benchmark suites Lehigh420fiCompleteness Guarantees Incomplete Ontology ReasonersUniversity Benchmark (LUBM) (Guo, Pan, & Heflin, 2005) University OntologyBenchmark (UOBM) (Ma et al., 2006) used completeness testing.Empirical completeness testing, however, several important limitations. First, testsgeneric, data sets used testing typically fixed and/or repetitive structure, skew test results. Second, test data exhaustive, completenesstested w.r.t. limited number data sets. Finally, query answers may verifiable: since complete reasoners fail handle large data sets, often cannot computecontrol answers needed check answers produced incomplete reasoner.consequence, empirical completeness tests provide limited assurance reasonersability meet requirements given application.paper, present radically dierent approach solving problems.observed that, given query Q ontology , even reasoner completelanguage , reasoner may able correctly answer Q w.r.t. arbitrary dataset A; case, say reasoner (Q, )-complete. Given ontology-basedapplications often use limited set queries fixed ontology (or least queriesontology evolve relatively slowly), scalable reasoner generally incomplete,(Q, )-complete relevant combinations Q , may provide solid foundationontology-based applications, allowing enjoy best worlds: regardlessdata set encountered, applications enjoy completeness guarantees normallyavailable computationally-intensive complete reasoners, timeexhibiting scalability levels normally available sacrificing completeness. developapproach testing (Q, )-completeness given reasoner, proceed follows.Section 3 develop logic-based framework allows us establish formallyprovable (Q, )-completeness guarantees. following two notions centralframework. First, order abstract away implementation details concretereasoners, introduce notion abstract reasoner idealised reasoner captures intended behaviour salient features (such soundness monotonicity)class concrete reasoners. Second, introduce notion test suitea finite setdata sets queries. Intuitively, given Q , goal construct test suitethat, reasoner correctly answers queries data sets test suite,reasoner guaranteed (Q, )-complete.Unfortunately, show Section 3.4, certain Q , impossibleconstruct finite test suite provide aforementioned completeness guarantees.Therefore, investigate assumptions Q, , reasoner testing (Q, )completeness becomes practically feasible.Section 3.5 consider case Q rewritten unionconjunctive queries Rthat is, answering Q w.r.t data set equivalentevaluating R A. expressed OWL 2 QL, rewriting R computedusing algorithm Calvanese et al. (2007); additionally, algorithm Perez-Urbina,Motik, Horrocks (2010) sometimes compute R even syntactically outsidefragment. show R converted test suite ER usedtesting (Q, )-completeness reasoner satisfies basic assumptions;roughly speaking, reasoners answers depend names individualsoccurring data set, answers must increase monotonically new data added.size test ER polynomial size longest conjunctive query R,421fiCuenca Grau, Motik, Stoilos & Horrocksfeasible compute correct answers tests using complete reasoner.number tests ER , however, exponential size R, may leadproblems practice. remedy, Section 3.6 strengthen assumptions requirereasoner drop answers merging individualsthat is, reasoner returnsgiven inputs Q, , A, (possibly noninjective) mapping reasonerreturns (a) given inputs Q, , (A)and show (Q, )-completenessreasoners checked using test suite IR obtained R linear transformation.Q rewritable union conjunctive queries eectively prevents stating recursive axioms. overcome restriction, Section 3.7 consider first-order reproducible reasonersthat is, reasoners whose behaviour Q, ,seen computing certain answers Q w.r.t. (possibly unknown) first-ordertheory FT A. Since FT datalog program, reasoners based deductivedatabases first-order reproducible. addition, require Q rewritabledatalog, extension datalog allows existential quantifiers disjunction rule heads. many cases, transformed datalog, programusing equivalence-preserving transformations; furthermore, algorithm Perez-Urbinaet al. (2010) many cases produce plain datalog rewriting. showtransform datalog, rewriting Q test suite used test(Q, )-completeness first-order reproducible reasoners.Section 4 turn attention comparing incomplete reasoners. Roughly speaking, given Q , reasoner R1 complete reasoner R2 if, data set A,reasoner R1 computes answers Q w.r.t. computed R2 .show comparing incomplete reasoners infeasible general. Therefore, introducenotion compact reasonersthat is, reasoners whose behaviour Q, ,seen first selecting subset using complete reasoner evaluateQ w.r.t. A. Thus, class compact reasoners captures reasoners reduceinput ontology set axioms match certain parameters, fittinglanguage fragments. Q rewritten union conjunctive queriesR, show test suite IR used compare compact reasoners.implemented approaches computing test suites, tested completeness several well-known reasoners (see Section 5). show test suiteseciently computed realistic ontologies. Furthermore, able guarantee(Q, )-completeness evaluated reasoners many queries ontologies. Finally,(Q, )-completeness guarantee could provided, able computecounter-examplea small data set reasoner hand incomplete.2. Preliminariessection briefly introduce Description Logics (DLs) (Baader, McGuinness, Nardi, &Patel-Schneider, 2002)a family knowledge representation formalisms underpinOWL OWL 2 ontology languages. describe description logics widerframework first-order logic since many results hold arbitrary first-order theories.introduce datalog, datalog languages, define syntaxsemantics unions conjunctive queries (UCQs). Finally, introduce notionsUCQ, datalog, datalog, rewritings, underpin many techniques.422fiCompleteness Guarantees Incomplete Ontology Reasoners2.1 Description Logics First-Order Logicresults paper hold arbitrary first-order theories, rather description logics. work, however, motivated description logics ontologies, useDL terminology throughout paper; example, often talk TBoxesABoxes instead first-order theories sets facts.definitions paper implicitly parameterised signature = P , ,consists countably infinite disjoint sets predicates P individuals (commonlycalled constants first-order logic) . predicate associated nonnegativearity; predicates zero arity commonly called propositional symbols. notionsvariables, terms, atoms, first-order formulae, sentences defined usual (Fitting,1996); consider function symbols article assume formulaefunction-free. atom false (true) interpretations written ().atom fact contain variables. use standard first-order notionssatisfiability, unsatisfiability, entailment (written |=) sets first-order sentences.assume P contains special equality inequality predicates ,respectively; atoms form (t1 , t2 ) (t1 , t2 ) commonly written t1 t2t1 t2 , respectively. make technical assumption distinct predicatesrather than, common first-order logic, t1 t2 abbreviation (t1 t2 );furthermore, assume theory uses axiomatises semanticsfollows, (5) instantiated predicate P arity n 1 n.x, y.[x x ](1)x, y.[x x](3)x1 , . . . , xi , . . . , xn , yi .[P (x1 , . . . , xi , . . . , xn ) xi yi P (x1 , . . . , yi , . . . , xn )](5)x.[x x](2)x, y, z.[x z x z](4)Note that, according assumption, set facts satisfiable. example,set atoms {a b, b} satisfiable since b b positive variable-freeatoms semantically independent other; moreover, axiom (1) requiredobtain expected contradiction.individual renaming (often renaming) partial function :maps individuals individuals. domain range written dom()rng(); unless otherwise noted, assume dom() finite. object containingindividuals (such formula, set formulae, tuple individuals), ind()set individuals occurring , () obtained simultaneously replacingindividual ind() dom() (a).use notion substitutions first-order logic; is, substitutionmapping variables terms. term, atom, formula, result applyingsubstitution written ().TBox finite set first-order sentences contains axioms (1)(5) wheneverand/or used. ABox finite set facts. Note definition allowsatoms form b b ABoxes; furthermore, since ABoxes containpositive atoms, ABox (when considered without TBox) satisfiable.423fiCuenca Grau, Motik, Stoilos & HorrocksDL NameELFLALC+(H)+(R)+(S)+(I)+(Q)+(O)RolesRRRConcepts, A, C1 C2 , R.C, A, C1 C2 , R.C, , A, C, C1 C2 , C1 C2 , R.C, R.CR.SelfTBox AxiomsC1 C2C1 C2C1 C2R1 R2RSTrans(R)RnS.C, nS.C{a}Table 1: Syntax standard description logics. Typical extensions EL, ALC, FLnamed appending calligraphic letters (H, R, S, I, Q, and/or O).description logic DL (usually infinite) recursive set TBoxes satisfyingfollowing conditions:DL renaming , (T ) DL,DL , DL.DL, say DL-TBox. Finally, FOL largest description logiccontains finite sets first-order sentences signature question.next present overview DLs commonly considered literature. Typically, predicates DL signatures required unary binary; formercommonly called atomic concepts latter commonly called atomic roles. DLstypically use specialised syntax, summarised Table 1, provides set constructorsconstructing complex concepts roles simpler ones, well dierent kindsaxioms. Using translation Table 2, concepts translated first-orderformulae one free variable, roles translated first-order formulae twofree variables, axioms translated first-order sentences. Note translation uses counting quantifiers n n , expressed using ordinaryquantifiers equality well-known transformations.rest paper, commonly write TBoxes ABoxes DL syntax; however,simplify presentation, identify written DL syntax (T ) (A).2.2 Datalog,next introduce fragment first-order logic called datalog, extensiondatalog Cal, Gottlob, Lukasiewicz, Marnette, Pieris (2010). datalog, rule(or commonly rule) r formula form (6), Bj atom dierentwhose free variables contained x,= 1 1 (x, y1 ) = ,1 and, 1 m, formula (x, yi ) conjunction atoms dierentwhose free variables contained x yi .424fiCompleteness Guarantees Incomplete Ontology ReasonersMapping DL roles first-order logic(R, x, y) = R(x, y)(R , x, y) = R(y, x)Mapping DL concepts first-order logic(, x, y) =(, x, y) =(A, x, y) = A(x)({a}, x, y) = x(C, x, y) = (C, x, y)(C D, x, y) = (C, x, y) (D, x, y)(C D, x, y) = (C, x, y) (D, x, y)(R.C, x, y) = y.[(R, x, y) (C, y, x)](R.Self, x, y) = R(x, x)(R.C, x, y) = y.[(R, x, y) (C, y, x)]( nS.C, x, y) = n y.[(S, x, y) (C, y, x)]( nS.C, x, y) = n y.[(S, x, y) (C, y, x)]Mapping TBox axioms first-order logic(C D) = x.[(C, x, y) (D, x, y)](R S) = x, y.[(R, x, y) (S, x, y)](Trans(R)) = x, y, z.[(R, x, y) (R, y, z) (R, x, z)](R ) = x, y, z.[(R, x, y) (S, y, z) (T, x, z)]Mapping ABox axioms first-order logic(C(a)) = (C, a, y)(R(a, b)) = R(a, b)(a b) = b(a b) = bTable 2: Translation DL syntax first-order logicx.[B1 . . . Bni=1yi .i (x, yi )](6)rule safe variable x also occurs Bj ; unless otherwise noted, rulesassumed safe. brevity, outer quantifier x commonly left implicit.body rset atoms body(r) = {B1 , . . . , Bn }, head r formulahead(r) =yi .i (x, yi ). datalog, program finite set safe datalog, rules.i=1Note that, since treated ordinary predicates, occur rules, providedsemantics appropriately axiomatised; furthermore, note latterachieved using datalog, rules.Let r datalog, rule. Then, r datalog rule head(r) contains existentialquantifier. Also, r datalog rule = 1. Finally, r datalog rule = 1head r single atom without existential quantifiers (Ceri, Gottlob, & Tanca, 1989).several places paper, check whether set first-order sentences entailsdatalog, rule, accomplished using following simple result.425fiCuenca Grau, Motik, Stoilos & HorrocksProposition 2.1. Let F set first-order sentences, let r datalog, ruleform (6). Then, substitution mapping free variables r distinctindividuals occurring F r, F |= rF {(B1 ), . . . , (Bn )} |=i=1yi .i ((x), yi )Proof. Let x tuple free variables r let arbitrary substitutionmapping variables x distinct individuals occurring F r. claimproposition follows following equivalences:F |= x.[B1 . . . Bnyi .i (x, yi )]i=1F {[x.B1 . . . BnF {x.[B1 . . . BnF {(B1 ) . . . (Bn )F {(B1 ), . . . , (Bn ),yi .i (x, yi )]} unsatisfiable(skolem. x)i=1yi .i ((x), yi )} unsatisfiableyi .i ((x), yi )} unsatisfiablei=1F {(B1 ), . . . , (Bn )} |=yi .i (x, yi )]} unsatisfiablei=1i=1i=1yi .i ((x), yi ).2.3 Queriesorder achieve high degree generality, define query Q finite set firstorder sentences containing distinct query predicate Q. Intuitively, query predicate Qdetermines answers Q. order simplify notation, typically assumeassociation Q query predicate implicit (e.g., may require querycontain precisely one predicate), assume query predicate occursTBox ABox.tuple constants certain answer query Q query predicate Qrespect TBox ABox arity agrees arity QQ |= Q(a). set certain answers Q w.r.t. denotedcert(Q, , A). query predicate Q propositional (i.e., query Boolean),cert(Q, , A) either empty contains tuple zero length; cases,commonly write cert(Q, , A) = f cert(Q, , A) = t, respectively.use special Boolean query checks first-order theory unsatisfiability.Thus, cert(, , A) = unsatisfiable.query Q query predicate Q union conjunctive queries (UCQ)datalog program rule contains Q head body. UCQ Qconjunctive query (CQ) contains exactly one rule.426fiCompleteness Guarantees Incomplete Ontology Reasonersunion conjunctive queries Q ground if, rule r Q, variable occurring body r also occurs head r. Roughly speaking, computingcert(Q, , A) ground Q, variables Q matched individualsA, unnamed objects whose existence guaranteed existential quantifiers.Many state art reasoners used practice support ground UCQs. NoteQ = {A(x) Q(x), R(x, y) Q(x, y)} ground UCQ; fact, Q even validfirst-order theory since predicate Q unique arity. obtain UCQ, onepad head first rulethat is, one introduce special fresh individual nullrewrite rules Q = {A(x) Q(x, null ), R(x, y) Q(x, y)}.properties first-order logic entailment, cert satisfies following propertiesquery Q, TBoxes , ABoxes .1. Monotonicity: implycert(, , A) = implies cert(, , ) = t,cert(Q, , A) cert(Q, , ).2. Invariance renamings: renaming tuple individuals a,cert(, , A) = implies cert(, (T ), (A)) = t,cert(Q, , A) implies (a) cert((Q), (T ), (A)).2.4 RewritingsIntuitively, rewriting query Q w.r.t. TBox another query capturesinformation relevant answering Q arbitrary ABox (Calvaneseet al., 2007; Artale, Calvanese, Kontchakov, & Zakharyaschev, 2009; Perez-Urbina et al.,2010). practice, UCQs (Calvanese et al., 2007) datalog (Perez-Urbina et al., 2010)widely used target languages query rewriting. sake generality,however, paper use notion datalog, rewriting.Definition 2.2. Let Q query let TBox. datalog, rewriting (or simplyrewriting) Q w.r.t. triple R = RD , R , RQRD datalog, program containing Q |= RD ,R datalog program head(r) = r R ,RQ UCQ whose query predicate Q,following properties hold ABox A:cert(, , A) = cert(, RD R , A),cert(, , A) = f, cert(Q, , A) = cert(RQ , RD R , A).Rewriting R datalog rewriting RD datalog program. Furthermore, rewriting RUCQ rewriting RD = ; R usually written R = R , RQ .427fiCuenca Grau, Motik, Stoilos & HorrocksNote Definition 2.2 requires |= RD hold, precludes rewritings consistingaxioms unsound w.r.t. . example, let Q = {A(x) Q(x)} = ;then, RD = {B(x) A(x)} satisfy definition rewriting since formulaB(x) A(x) logical consequence .wide range Q, datalog, rewriting Q w.r.t. computed usingstraightforward equivalence-preserving transformations ; optimisedeliminating axioms irrelevant answering Q. Furthermore, severalalgorithms computing UCQ datalog rewritings proposed literature.example, Calvanese et al. (2007) showed compute UCQ rewriting casesexpressed logic DL-Lite family, approach extendedOWL 2 QL profile OWL 2 (Motik et al., 2009a). Similarly, Perez-Urbina et al. (2010)proposed algorithm computing simplest possible datalog rewritingexpressed description logic ELHIO.Rewritings produced known algorithms often contain predicates occurQ; predicates sometimes called fresh. example, many rewritingalgorithms normalise TBoxes replacing complex concepts fresh atomic concepts.rewriting R = RD , R , RQ obtained way unlikely satisfy requirement|= RD . However, predicates occurring R often eliminatedvia unfolding. example, let Q = {A(x) Q(x)} = {R.S.B A}, assumerewriting algorithm producesRD = {S(x, y) B(x) C(x), R(x, y) C(y) A(x)}.satisfy Definition 2.2, predicate C unfolded RD replacedRD = {R(x, y) S(y, z) B(z) A(x)},|= RD holds. Unfolding, however, may always possible (e.g., mightcase fresh predicates occur recursive axioms), may limit applicability results presented paper.3. Completeness Guarantees Incomplete Reasonerssection, introduce formal framework allow us establish completeness guarantees incomplete reasoners. results restricted particulardescription logic, applicable TBoxes satisfy following criterion.Definition 3.1. TBox admissible description logic DL existsDL-TBox, checking TBox satisfiability answering Boolean UCQs w.r.t.arbitrary ABox decidable DL.3.1 Concrete Abstract ReasonersConcrete reasoners complex software systems dier greatly functionalitysupported interfaces, use range dierent implementation techniques.make results general independent specific implementation techniques,introduce notion abstract reasoner. abstract reasoner thought428fiCompleteness Guarantees Incomplete Ontology Reasonersidealised reasoner captures intended behaviour salient features classconcrete reasoners. concrete reasoner belonging class may use arbitrary algorithms,long observable behaviour mirrors abstract reasoner.Definition 3.2. abstract reasoner ans description logic DL computable function takes input arbitrary DL-TBox , arbitrary ABox A, eitherspecial unsatisfiability query arbitrary UCQ Q. return value ans definedfollows:ans(, , A) either f;ans(, , A) = t, ans(Q, , A) interest arbitrary;ans(, , A) = f, ans(Q, , A) finite set tuples individuals,arity tuple equal arity query predicate Q.abstract reasoner ans DL said applicable TBox DL-TBox.Intuitively, ans(, , A) asks abstract reasoner check whether unsatisfiable, ans(Q, , A) asks abstract reasoner evaluate Q w.r.t. A.unsatisfiable, tuple constants arity query predicate Qanswer Q A; therefore, result ans(Q, , A) interestans(, , A) = fthat is, ans identifies satisfiable.Example 3.3. Consider abstract reasoners rdf, rdfs, rl, classify which, giveninput UCQ Q, TBox , ABox A, compute answer Q w.r.t.described next.Abstract reasoner rdf ignores evaluates Q w.r.t. A; precisely, rdf(, , A) = frdf(Q, , A) = cert(Q, , A). Thus, rdf captures behaviour RDF reasoners.Abstract reasoner rdfs evaluates Q w.r.t. datalog program Prdfs constructed translating RDFS axiom equivalent datalog rule;precisely, rdfs(, , A) = f rdfs(Q, , A) = cert(Q, Prdfs , A). Thus, rdfs capturesbehaviour RDFS reasoners Sesame.Abstract reasoner rl evaluates Q w.r.t. datalog program Prl constructedtranslating OWL 2 RL axiom equivalent datalog rule; precisely,rl(, , A) = cert(, Prl , A) rl(Q, , A) = cert(Q, Prl , A). Thus, rl captures behaviourOWL 2 RL reasoners Jena Oracles Semantic Data Store.Abstract reasoner classify first classifies using complete OWL 2 DL reasoner; is,computes TBox containing subclass axiom B |= B,B atomic concepts occurring . abstract reasoner proceeds rl,considers instead ; precisely, classify(, , A) = rl(, , )classify(Q, , A) = rl(Q, , A). way, classify captures behaviour OWL 2RL reasoners Minerva DLE-Jena try complete materialisingcertain consequences .ideal abstract reasoner one that, arbitrary UCQ Q, TBox ,ABox A, ans(, , A) = cert(, , A), ans(Q, , A) = cert(Q, , A) wheneverans(, , A) = f. next introduce discuss several properties abstract reasoners429fiCuenca Grau, Motik, Stoilos & Horrockslikely aect close come ideal may also relevantapplicability results.following notion soundness describes abstract reasoners return answerslogically follow Q, , A.Definition 3.4. abstract reasoner ans DL sound following conditions holdUCQ Q, DL-TBox , ABox A:ans(, , A) = implies cert(, , A) = t;ans(, , A) = f implies ans(Q, , A) cert(Q, , A).following notion monotonicity describes abstract reasoners extendinginput TBox ABox never leads dropping answers. also consider weakernotion (Q, )-monotonicity, input query Q TBox fixed.Definition 3.5. abstract reasoner ans DL monotonic following conditionshold UCQ Q, DL-TBoxes , ABoxes:ans(, , A) = implies ans(, , ) = t;ans(, , A) = f ans(, , ) = f imply ans(Q, , A) ans(Q, , ).Given UCQ Q DL-TBox , ans (Q, )-monotonic following conditionshold ABoxes :ans(, , A) = implies ans(, , ) = t;ans(, , A) = f ans(, , ) = f imply ans(Q, , A) ans(Q, , ).discussed Section 2.3, logical consequences first-order theory invariantrenaming merging individuals. define analogous properties abstractreasoners, first introduce notions -stable (Q, )-stable renamingsthat is,renamings leave individuals occurring (respectively, Q ) unchanged.Definition 3.6. Let Q query, let TBox, let renaming. Then, stable (a) = individual dom() ind(T ); furthermore, (Q, )-stable(a) = individual dom() ind(Q ).following notion weak faithfulness describes abstract reasoners whose answersinvariant replacement individuals fresh individuals. Furthermore, weak(Q, )-faithfulness relaxes property case Q fixed.Definition 3.7. abstract reasoner ans DL weakly faithful following conditions hold UCQ Q, DL-TBox , ABox A, injective renaming , tuple a:ans(, , A) = ind(T A) dom() imply ans(, (T ), (A)) = t;ans(, , A) = f, ind(Q A) dom(), ans(Q, , A) implyans(, (T ), (A)) = f (a) ans((Q), (T ), (A)).430fiCompleteness Guarantees Incomplete Ontology ReasonersGiven UCQ Q DL-TBox , ans weakly (Q, )-faithful following conditionshold ABox A, injective renaming , tuple a:ans(, , A) = t, ind(T A) dom(), -stable imply ans(, , (A)) = t;ans(, , A) = f, ind(Q A) dom(), (Q, )-stable, ans(Q, , A)imply ans(, , (A)) = f (a) ans(Q, , (A)).following notion strong faithfulness describes abstract reasoners whose answersinvariant merging individuals. Furthermore, strong (Q, )-faithfulness relaxesproperty case Q fixed.Definition 3.8. abstract reasoner ans DL strongly faithful following conditions hold UCQ Q, DL-TBox , ABox A, renaming , tuple a:ans(, , A) = implies ans(, (T ), (A)) = t;ans(, , A) = f, ans(Q, , A), ans(, (T ), (A)) = f imply(a) ans((Q), (T ), (A)).Given UCQ Q DL-TBox , ans strongly (Q, )-faithful following conditions hold ABox A, renaming , tuple a:ans(, , A) = -stable imply ans(, , (A)) = t;ans(, , A) = f, (Q, )-stable, ans(Q, , A), ans(, , (A)) = f imply(a) ans(Q, , (A)).results present rest paper applicable abstractreasoners satisfy various combinations properties; minimum, require(Q, )-monotonicity weak (Q, )-faithfulness. abstract reasoners described Example 3.3 satisfy properties. Testing case concrete reasoners may,however, infeasible practice; indeed, aware technique would allow one check whether concrete reasoner satisfies required properties. believe,however, concrete reasoners commonly used practice intended sound,monotonic, least weakly faithful, strong faithfulness reasonable assumption cases. concrete reasoner fails satisfy propertiescertain inputs, likely due implementation bugs; thus, consequent failurecompleteness seen bug, detecting situations viewedpart general problem testing software systems.next present several examples abstract reasoners satisfymentioned properties.Example 3.9. Consider abstract reasoner behaves rdf whenever numberassertions input ABox smaller certain threshold, returnsempty set answers larger ABoxes. Intuitively, abstract reasoner characterisesconcrete RDF reasoner processes inputs certain size. reasoner(Q, )-monotonic arbitrary Q .431fiCuenca Grau, Motik, Stoilos & HorrocksExample 3.10. Consider abstract reasoner behaves like rdf, that, trustreasons, removes input ABox assertions whose individuals blacklisted(e.g., come untrusted source). abstract reasoner weakly (Q, )faithful arbitrary Q .Example 3.10 suggests that, abstract reasoner weakly faithful,make decisions depend specific names individuals.Example 3.11. Consider abstract reasoner rl= that, given input UCQ Q, TBox, ABox A, proceeds follows. First, rl= computes ABox obtainedevaluating datalog program Prl Example 3.3 A. Second, rl= computesquery Q= obtained Q adding body rule r Q inequality xpairs distinct variables x occurring r. Third, rl= evaluates Q=considering databasethat is, finite first-order interpretationindividual mapped (and thus dierent individuals distinct). Thus, rl= characterises concrete reasoners evaluate queries matching dierent variables dierentindividuals. Abstract reasoner rl= sound, monotonic, weakly faithful,strongly faithful. example, given query Q = {R(x, y) Q(x)}, ABox = {R(a, b)},renaming = {a c, b c}, rl= (Q, , A) = {a}, rl= (Q, , (A)) = .Example 3.11 suggests that, abstract reasoner strongly faithful,allow distinct variables queries axioms mapped individuals.next identify classes abstract reasoners use throughout paper. Notesoundness required, contributes generality results.Definition 3.12. Given UCQ Q TBox , CwQ,T (CsQ,T ) class (Q, )monotonic weakly (strongly) (Q, )-faithful abstract reasoners applicable .Finally, note abstract reasoners introduced Example 3.3 sound, monotonic, strongly (and therefore also weakly) faithful. Consequently, concrete reasonersbased reasoning techniques outlined Example 3.3 considered sound, monotonic,strongly faithful, modulo implementation bugs.3.2 Completeness Abstract Reasonersnext define central notion abstract reasoner completeness given query QTBox . Intuitively, (Q, )-complete abstract reasoner indistinguishablecomplete abstract reasoner applied Q, , arbitrary ABox A.Definition 3.13. Let DL description logic, let ans abstract reasoner DL.Then, ans (Q, )-complete UCQ Q DL-TBox following conditionshold ABox A:cert(, , A) = t, ans(, , A) = t;cert(, , A) = f ans(, , A) = f, cert(Q, , A) ans(Q, , A).Finally, ans complete (Q, )-complete UCQ Q DL-TBox .432fiCompleteness Guarantees Incomplete Ontology ReasonersExample 3.14. Consider EL-TBox consisting following axioms; translationaxioms first-order logic shown symbol.takesCo.MathCo StMathSt takesCo.MathCoCalcCo MathCoSt Profx, y.[takesCo(x, y) MathCo(y) St(x)]x.[CalcCo(x) MathCo(x)](7)(8)x.[MathSt(x) y.[takesCo(x, y) MathCo(y)]] (9)x.[St(x) Prof(x) ](10)Axiom (7) states everyone taking maths course student; axiom (8) statescalculus course also maths course; axiom (9) states maths student takesmaths course; axiom (10) states person studentprofessor. Axiom (8) RDFS axiom, axioms apart (9) OWL2 RL axioms. Consider also query (11) retrieves students taking maths course.Q = {St(x) takesCo(x, y) MathCo(y) Q(x)}(11)None abstract reasoners rdf, rdfs, rl, classify Example 3.3 completegeneral answering UCQs EL-TBoxes. Furthermore, Q previousparagraph, abstract reasoners rdf, rdfs, rl (Q, )-complete, returnempty set answers ABox = {MathSt(c)}. contrast, following sectionsshow abstract reasoner classify (Q, )-completethat is, returnscertain answers Q, , arbitrary ABox A.3.3 Test SuitesChecking (Q, )-completeness concrete reasoner applying reasoner possibleABoxes comparing reasoners answers complete reasoner clearlyinfeasible practice since infinitely many candidate input ABoxes. obtainpractical approach, need finite number tests. formalise idea usingfollowing definition.Definition 3.15. Let TBox. -test suite pair = , SQfinite set ABoxes cert(, , A) = ,SQ finite set pairs A, ABox cert(, , A) = fUCQ.abstract reasoner ans applicable passes -test suite ans satisfiesfollowing two conditions:, ans(, , A) = t,A, SQ , ans(, , A) = f, cert(Y, , A) ans(Y, , A).Let Q UCQ, let C class abstract reasoners applicable . Then,exhaustive C Q ans C passes (Q, )-complete.-test suite Q-simple Q query occurring SQ ; then, SQ commonly written set ABoxes, A, Q SQ commonly abbreviated SQ .433fiCuenca Grau, Motik, Stoilos & HorrocksIntuitively, -test suite = , SQ determines tests abstract reasonersubjected to. reasoner pass S, must correctly identify ABoxunsatisfiable, ABoxquery pair A, SQ reasoner mustcorrectly answer w.r.t. A.Given Q , goal identify -test suite exhaustive Qthatis, test suite abstract reasoner passes guaranteed (Q, )complete. Depending properties abstract reasoners, however, dierent test suitesmay may achieve goal. Therefore, notion exhaustiveness relativeclass abstract reasoners C: exhaustive class abstract reasoners C,used test arbitrary abstract reasoner C. Note dependstarget class abstract reasoners, actual abstract reasoner tested;order words, construction depends properties one assume holdtarget abstract reasoner. Furthermore, abstract reasoner contained Cpasses S, general imply (Q, )-completeness guarantee.Example 3.16. Let Q specified Example 3.14, let A1 A6following ABoxes.A1 = {takesCo(c, d), MathCo(d)}A3 = {takesCo(c, d), CalcCo(d)}A5 = {MathSt(c)}A2 = {takesCo(c, c), MathCo(c)}A4 = {takesCo(c, c), CalcCo(c)}A6 = {St(c), Prof(c)}following sections, show Q-simple -test suite = , SQ defined= {A6 } SQ = {A1 , . . . , A5 } exhaustive class CwQ,T Q; consequently,used test abstract reasoners Example 3.3.particular, note abstract reasoners rdf rdfs fail tests SQ ,abstract reasoner rl fails test A5 SQ ; furthermore, failed tests provide counterexample (Q, )-completeness. contrast, abstract reasoner classify Example3.14 passes tests S, implies abstract reasoner indeed (Q, )-complete.Finally, consider variant abstract reasoner classify that, similarly abstractreasoner described Example 3.9, returns empty set answers input ABoxcontains than, say, ten assertions. abstract reasoner (Q, )-monotonichence belong CwQ,T . abstract reasoner clearly passes S; however, sincebelong CwQ,T , passing (correctly) imply abstract reasoner(Q, )-complete.next state following property, proof trivial.Proposition 3.17. Let Q UCQ, let TBox, let C1 C2 classesabstract reasoners applicable C1 C2 .1. -test suite exhaustive C2 Q, also exhaustive C1 Q.2. -test suite exists exhaustive C1 Q, -test suite existsexhaustive C2 Q.Therefore, proving existence -test suite exhaustive Q, generalresult one applies largest possible class abstract reasoners. Furthermore,434fiCompleteness Guarantees Incomplete Ontology Reasonersfollowing section identify cases -test suite exhaustive Qfound; Proposition 3.17 suces provide nonexistence results smallestpossible class abstract reasoners.finish section pointing important practically relevant propertyQ-simple -test suites, illustrated Example 3.16.Proposition 3.18. Let = , SQ Q-simple -test suite let ans abstractreasoner applicable . ans pass S, ans (Q, )-complete.Proof. ABox SQ ans satisfy conditions Definition3.15 counterexample (Q, )-completeness ans.Thus, Q-simple -test suite exhaustive C Q provides sucient necessary test (Q, )-completeness abstract reasoners C. contrast,Q-simple, show Section 3.7 provides sucient, alsonecessary test (Q, )-completeness abstract reasoners C.3.4 Negative ResultsSections 3.5 (resp. Section 3.6) identify restrictions UCQ Q TBoxguarantee existence -test suites exhaustive CwQ,T (resp. CsQ,T ) Q.presenting positive results, first outline limits (Q, )-completeness testingthus justify restrictions use following sections.3.4.1 Monotonicity Weak Faithfulnessapproaches testing (Q, )-completeness abstract reasoners applicablereasoners (Q, )-monotonic weakly (Q, )-faithful. section, provideformal justification requirements form following two theorems.Theorem 3.19 shows exhaustive test suites exist consider classabstract reasoners satisfying properties Section 3.1 apart (Q, )monotonicity; includes soundness, strong faithfulness (which implies weak faithfulness), monotonicity w.r.t. TBox only.Theorem 3.20 shows exhaustive test suites exist consider classabstract reasoners satisfying properties defined Section 3.1 exception(Q, )-weak faithfulness; properties include soundness monotonicity.negative results Theorems 3.19 3.20 strong: hold smallestclasses abstract reasoners define based notions introduced Section 3.1 (byProposition 3.17, smaller class abstract reasoners, general negativeresult); hold regardless Q considered (modulo minor technicality:unlike Theorem 3.19, Theorem 3.20 requires satisfiable).proof Theorem 3.19 intuitively understood follows. first assume-test suite exhaustive Q class abstract reasonerstheorem applies. Then, specify abstract reasoner ans right thing (i.e.,returns correct answer) given input query Q, TBox ,435fiCuenca Grau, Motik, Stoilos & Horrocksarbitrary ABox containing many assertions largest test ABox S;otherwise, ans returns sound, incomplete answer. finally show followingthree properties ans.Abstract reasoner ans belongs relevant class abstract reasoners.Abstract reasoner ans passes S.Abstract reasoner ans incomplete least one input ABox.three properties show exhaustive Q relevant classabstract reasoners. Intuitively, means class abstract reasoners large,allowing abstract reasoners treat input erratic way.Theorem 3.19. Let Q arbitrary UCQ, let arbitrary admissible TBox.Then, -test suite exists exhaustive Q class sound stronglyfaithful abstract reasoners applicable satisfying following conditions TBoxABox A:ans(, , A) = implies ans(, , A) = t;ans(, , A) = f ans(, , A) = f imply ans(Q, , A) ans(Q, , A).Proof. Consider arbitrary -test suite = , SQ . Let n maximum numberassertions ABox S. Furthermore, let ans abstract reasoner takesinput UCQ Qin , FOL-TBox Tin , ABox . result ans(, Tin , )determined follows.1. Try find renaming dom() = ind(T ) (T ) Tin ;exists, return f.2. contains n assertions, check satisfiability (T ) usingsound complete reasoner; return (T ) unsatisfiable.3. Return f.Furthermore, result ans(Qin , Tin , ) determined follows.4. Try find renaming dom() = ind(Q ), (T ) Tin , (Q) = Qin ;exists, return .5. contains n assertions, compute cert((Q), (T ), ) using soundcomplete reasoner return result.6. Return .Since admissible, checks steps 2 5 performed finite time; furthermore, step 1 realised enumerating mappings ind(T ) ind(Tin ), step4 realised analogously; consequently, ans implemented terminatesinputs. see ans sound monotonic w.r.t. TBox, consider arbitraryinput Qin , Tin , Tin , Tin Tin .436fiCompleteness Guarantees Incomplete Ontology ReasonersAssume ans(, Tin , ) = t. Then, Qin , Tin , abstract reasonerreturns step 2 (T ) unsatisfiable; then, since (T ) Tin ,Tin unsatisfiable well, required soundness. Furthermore,since (T ) Tin Tin , Qin , Tin , abstract reasoner returns step 2well, ans(, Tin , ) = t, required monotonicity w.r.t. TBox.Assume ans(Qin , Tin , ). Then, Qin , Tin , abstract reasonerreturns step 5, therefore cert((Q), (T ), ); then, since(Q) = Qin (T ) Tin , cert(Qin , Tin , ), required soundness. Furthermore, since (T ) Tin Tin , Qin , Tin , abstract reasonerreturns step 5 well, ans(Qin , Tin , ), required monotonicity w.r.t.TBox.see ans strongly faithful, consider arbitrary renaming . renamingexists (Q) = Qin (T ) Tin , clearly renaming exists(Q) = (Qin ) (T ) (Tin ). Consequently, ans(, Tin , ) returns step 2,ans(, (Tin ), (Ain )) returns step 2 well; similarly, ans(Qin , Tin , ) returns step5, ans((Qin ), (Tin ), (Ain )) returns step 5 well; clearly, ans strongly faithful.Finally, straightforward see ans passes S.let ABox containing least n + 1 assertions cert(Q, , A) = ;clearly exists. unsatisfiable, ans(, , A) = f; furthermore,satisfiable, ans(Q, , A) = ; consequently, ans (Q, )-complete. Thus,exhaustive Q class abstract reasoners considered theorem.next prove Theorem 3.20. proof similar proof Theorem 3.19,main dierence abstract reasoner ans construct. particular, given testsuite S, take ans return correct answer query Q, TBox ,ABox contains individuals occurring S; otherwise, abstract reasonerreturns sound, incomplete answer. Again, class abstract reasonerslarge, allowing ans treat inputs erratic way.Unlike Theorem 3.19, following theorem requires satisfiable; understandwhy, consider arbitrary unsatisfiable TBox UCQ Q. Let = , SQ-test suite defined = {} (i.e., contains single empty ABox) SQ = (i.e.,SQ contains ABoxes), consider arbitrary monotonic abstract reasoner anspasses . Since ans passes S, ans(, , ) = t; then, since ans monotonic,arbitrary ABox ans(, , A) = well, turn implies ans(Q, )-complete. Failure satisfy weak faithfulness thus irrelevant unsatisfiable.Theorem 3.20. Let arbitrary admissible satisfiable TBox let Qarbitrary UCQ. Then, -test suite exists exhaustive Q classsound monotonic abstract reasoners applicable .Proof. Consider arbitrary -test suite = , SQ . Let set individualsoccurring S, Q, . Furthermore, let ans abstract reasoner takesinput UCQ Qin , FOL-TBox Tin , ABox . result ans(, Tin , )determined follows.1. Tin , return f.437fiCuenca Grau, Motik, Stoilos & Horrocks2. Let Ain,I set assertions mention individuals I.3. Check satisfiability Ain,I using sound complete reasoner; returnAin,I unsatisfiable, return f otherwise.Furthermore, given UCQ Qin , result ans(Qin , Tin , ) determined follows:4. Tin Q =Qin , return .5. Let Ain,I set assertions mention individuals I.6. Compute cert(Q, , Ain,I ) using sound complete reasoner return result.ans implemented terminates inputs shownproof Theorem 3.19. Furthermore, soundness ans follows followingtwo observations.Assume ans(, Tin , ) = t. Then, abstract reasoner returns step 3 sinceAin,I unsatisfiable; then, since Tin Ain,I ,Tin unsatisfiable well, required.Assume ans(Qin , Tin , ). Then, abstract reasoner returns step 6,therefore cert(Q, , Ain,I ); then, since Q = Qin , Tin ,Ain,I , cert(Qin , Tin , ), required.monotonicity, consider arbitrary Tin Tin Tin ;clearly, Tin Ain,I Ain,I ; then, monotonicity first-order logic,ans(, Tin , ) = implies ans(, Tin , ) = t, ans(Q, Tin , ) ans(Q, Tin , ). Finally, straightforward see ans passes S.consider arbitrary ABox ind(A) = cert(Q, , A) = ;clearly exists. unsatisfiable, since ABox constructed step 2 emptysatisfiable, ans(, , A) = f; furthermore, satisfiable, sinceABox constructed step 5 empty, ans(Q, , A) cannot contain individuals occurringI; consequently, ans (Q, )-complete. Thus, exhaustive Qclass abstract reasoners considered theorem.3.4.2 Monotonicity Weak Faithfulness SufficeNext, show (Q, )-monotonicity (Q, )-faithfulness general guaranteeexistence -test suite exhaustive Q. particular, Theorem 3.21 shows that,contains single recursive axiom, test suite exists exhaustive classsound, monotonic, strongly faithful abstract reasoners (and Proposition 3.17CsQ,T CwQ,T well, UCQ Q). Although result applicableparticular Q , straightforward adapt proof TBox recursiveaxiom relevant given query. Example 3.22, however, shows conceptrelevance rather dicult formalise: even entails recursive axiom, axiomnecessarily relevant answering query. order complicate mattersfurther, state following result fixed Q , hope proof clearlyillustrates limitations incurred recursive axioms.438fiCompleteness Guarantees Incomplete Ontology ReasonersTheorem 3.21. Q = {A(x) Q(x)} = {R.A A}, -test suite existsexhaustive Q class sound, monotonic, strongly faithful abstractreasoners applicable .Proof. Consider arbitrary -test suite = , SQ . Since -test suite,contains ABoxes unsatisfiable; clearly, ABox existsstated theorem, = . Let SQ arbitrary, finite, set pairs A,ABox UCQ, let n maximum number assertions ABoxSQ . Furthermore, consider following ABox, ai = aj 1 < j n + 1:An+1 = {R(a0 , a1 ), . . . , R(an , an+1 ), A(an+1 )}next construct abstract reasoner pEvaln following properties:(P1) A, SQ , cert(Y, , A) pEvaln (Y, , A);(P2) a0 pEvaln (Q, , An+1 );(P3) pEvaln sound, monotonic, strongly faithful.Note a0 cert(Q, , An+1 ), three properties imply exhaustiveQ class abstract reasoners considered theorem.Abstract reasoner pEvaln accepts input FOL-TBox Tin ABox .result pEvaln (, Tin , ) determined follows.1. Return f.Furthermore, given UCQ Qin , result pEvaln (Qin , Tin , ) determined follows.2. Tin Q =Qin , return .3. Asat :=4. Repeat following computation n times:Asat := Asat {(A(x)) | substitution s.t. {(R(x, y)), (A(y))} Asat }5. Return cert(Q, , Asat ).Abstract reasoner pEvaln clearly satisfies Property (P2) deriving assertion A(a0 )requires n+1 iterations loop step 4. Furthermore, pEvaln also satisfies (P1)every ABox occurring SQ contains n individuals seenrule R(x, y) A(y) A(x), pEvaln applies n times input ABox .finally show (P3). Abstract reasoner pEvaln clearly sound. Furthermore,renaming (T ) = (Q) = Q, pEvaln clearly strongly faithful.show pEvaln monotonic, consider arbitrary Tin , Tin , ,Tin Tin ; since pEvaln (, Tin , ) = f input, followingrelevant cases.pEvaln returns step 2 input Qin , Tin , , case either TinQ = Qin . Since Tin Tin , clearly pEvaln also returns step 2 input Qin , Tin ,, monotonicity holds.439fiCuenca Grau, Motik, Stoilos & HorrockspEvaln returns step 5 input Qin , Tin , . Then, pEvaln return eitherstep 2 step 5 input Qin , Tin ; former case, monotonicity holdstrivially, latter case, pEvaln (Qin , Tin , ) pEvaln (Qin , Tin , ) followsdirectly fact .following example shows presence recursive axioms preclude existence -test suite exhaustive Q.Example 3.22. Consider Q defined follows:Q = {A(x) B(x) Q(x)}= {R.A A, B R.A}Note contains axiom mentioned Theorem 3.21; however, note also|= B A,R = , {B(x) Q(x)}UCQ rewriting Q w.r.t. . Section 3.5 show existence UCQ rewriting Q w.r.t. guarantees existence Q-simple -test suite exhaustive CwQ,T(and hence also CsQ,T ) Q; example, = , { {B(a)} } one -test suite.Intuitively, |= B consequence relevant answering Q; hence,= {B A} Q = {A(x) Q(x)}, cert(Q, , A) = cert(Q , , A)arbitrary ABox A. Hence, recursive axiom irrelevant answering Q,therefore presence preclude existence -test suite exhaustiveCwQ,T Q.3.5 Testing (Q, )-Monotonic Weakly (Q, )-Faithful Abstract Reasonerssection, identify sucient condition guarantees existence Q-simple-test suite exhaustive CwQ,T Q; Proposition 3.17, result applies CsQ,Twell. Roughly speaking, always computed instantiating rulesUCQ rewriting Q w.r.t. suitable way. requirement Q UCQrewritable w.r.t. invalidates negative result Theorem 3.21 since UCQ rewritingQ = {A(x) Q(x)} w.r.t. = {R.A A} exists.result allows one compute Q-simple -test suites exhaustive Q numerouspractically relevant cases. particular, UCQ rewriting guaranteed existexpressed DLs underpinning QL profile OWL 2 (Motik et al., 2009a; Calvaneseet al., 2007); furthermore, illustrated Example 3.22, UCQ rewriting may exist evenexpressed fragments OWL 2 OWL 2 EL (Motik et al., 2009a;Baader, Brandt, & Lutz, 2005). practice, rewritings computed using systemsQuOnto (Acciarri et al., 2005) REQUIEM (Perez-Urbina et al., 2010).establish desired result two steps. First, Section 3.5.1 present generalcharacterisation Q-simple -test suites exhaustive CwQ,T Q. Then, Section3.5.2 use characterisation establish desired connection rewritingsQ-simple -test suites exhaustive Q.440fiCompleteness Guarantees Incomplete Ontology Reasoners3.5.1 Characterisation Simple Exhaustive Test Suitesnext prove Q-simple -test suite = , SQ exhaustive CwQ,T Qcontains isomorphic copy data pattern (i.e., subset ABox)produce certain answer Q w.r.t. , preserves identityindividuals occurring Q. show sucient, alsonecessary condition existence exhaustive -test suite, observe that,contain one copy data pattern, always find abstract reasonerCwQ,T passes misses certain answers obtained via missing data patterntherefore (Q, )-complete.Theorem 3.23. Let Q UCQ, let admissible TBox, let = , SQQ-simple -test suite. Then, exhaustive CwQ,T Q followingproperties satisfied ABox A.1. unsatisfiable, exist ABox injective -stablerenaming dom() = ind(T ) (A ) A.2. satisfiable, tuple cert(Q, , A) exist ABoxSQ , tuple b cert(Q, , ), injective (Q, )-stable renaming(b) = a, dom() = ind(Q ), (A ) A.Proof. () Let arbitrary Q-simple -test suite satisfies Properties 1 2;next show exhaustive CwQ,T Q. Consider arbitrary abstract reasonerans CwQ,T passes Sthat is, ans satisfies following two properties:(a) ans(, , ) = ,(b) ans(, , ) = f implies cert(Q, , ) ans(Q, , ) SQ .next show ans (Q, )-completethat is, ans satisfies two conditionsDefinition 3.13 arbitrary ABox A. arbitrary A, followingtwo possibilities, depending satisfiability A.Assume unsatisfiable. Since satisfies Property 1, exist ABoxinjective -stable renaming s.t. dom() = ind(T ) (A ) A.Condition (a) ans(, , ) = t. Since ans weakly (Q, )-faithful, injective-stable, dom() = ind(T ), ans(, , (A )) = t; finally, since ans(Q, )-monotonic (A ) A, ans(, , A) = t, required Definition 3.13.Assume satisfiable ans(, , A) = f. Furthermore, consider arbitrary tuple cert(Q, , A). Since satisfies Property 2, exist ABox SQ ,tuple b cert(Q, , ), injective (Q, )-stable renaming (b) = a,dom() = ind(Q ), (A ) A. Since (A ) A, ans(, , A) = f, ans(Q, )-monotonic, ans(, , (A )) = f; furthermore, ind(T ) dom(),injective (Q, )-stable, ans weakly (Q, )-faithful, ans(, , (A )) = f implies ans(, , ) = f. then, Condition (b) cert(Q, , ) ans(Q, , ),b ans(Q, , ). Since ans weakly (Q, )-faithful, injective (Q, )-stable,dom() = ind(Q ), (b) ans(Q, , (A )); since (b) = a,441fiCuenca Grau, Motik, Stoilos & Horrocksans(Q, , (A )); finally, since ans (Q, )-monotonic (A ) A,ans(Q, , A), required Definition 3.13.() Assume exhaustive CwQ,T Q; next show Properties 1 2satisfied arbitrary ABox A. end, consider particular abstract reasonerans prove ans CwQ,T ans passes S; abstract reasonerhelp us identify ABox, tuple, renaming required prove Properties 1 2.Let ans abstract reasoner takes input UCQ Qin , FOL-TBox Tin ,ABox . result ans(, Tin , ) determined follows.1. =Tin , return f.2. ABox , following.(a) Check satisfiability using sound, complete, terminatingreasoner.(b) unsatisfiable, injective -stable renaming existsdom() = ind(T ) (A ) , return t.3. Return f.Furthermore, result ans(Qin , Tin , ) determined follows.4. =Tin Q =Qin , return .5. := .6. tuple constants occurring arity equal arity querypredicate Q, SQ following.(a) Compute C := cert(Q, , ) using sound, complete terminating reasoner.(b) tuple b C injective (Q, )-stable renaming exist(b) = a, dom() = ind(Q ), (A ) , add Out.7. Return Out.next show ans belongs CwQ,T ; end, prove ans terminatesinputs, (Q, )-monotonic weakly (Q, )-faithful.Termination. Since admissible, checking satisfiability computationcert(Q, , ) decidable, relevant sound, complete terminating reasonersexist. Furthermore, checking whether -stable (resp. (Q, )-stable) injective renamingexists done enumerating renamings ind(T ) (resp. ind(Q ))ind(T ) (resp. ind(Q )). Therefore, ans implementedterminates input.(Q, )-Monotonicity. Consider arbitrary input Qin , Tin , , .Assume ans(, Tin , ) = t, Tin abstract reasoner terminatesstep 2(b) . then, since (A ) , Tinabstract reasoner also terminates step 2(b), ans(, Tin , ) = t,required.442fiCompleteness Guarantees Incomplete Ontology ReasonersAssume ans(, Tin , ) = f ans(, Tin , ) = f, consider arbitrarytuple ans(Qin , Tin , ). added step 7(b) SQ. then, since (A ) , Qin , Tin , abstract reasoneralso adds step 7(b), ans(Qin , Tin , ), required.Weak (Q, )-Faithfulness. Consider arbitrary input Qin , Tin , , arbitraryinjective renaming .Assume ans(, Tin , ) = t, dom() ind(T A), -stable. Thus,Tin abstract reasoner terminates step 2(b) . Letrenaming (c) = ((c)) c ind(T ). Clearly,dom( ) = ind(T ), renaming -stable injective, (A ) (Ain ).Thus, Tin (Ain ) abstract reasoner terminates step 2(b), thereforeans(, Tin , (Ain )) = t, required.Assume ans(, Tin , ) = f, dom() ind(Q A), (Q, )-stable,consider arbitrary truple ans(Qin , Tin , ). added step7(b) SQ , , b. Let renaming defined s.t. (c) = ((c))individual c ind(Q ). Clearly, dom( ) = ind(Q ),renaming (Q, )-stable injective, (A ) (Ain ), (b) = (a). Thus,Qin , Tin , (Ain ) abstract reasoner terminates step 7(b) clearly(a) ans(Qin , Tin , (Ain )), required.concludes proof ans CwQ,T . Furthermore, ans clearly passes S; then,since exhaustive CwQ,T Q, abstract reasoner ans (Q, )-complete. nextprove main claim theorem. end, consider arbitrary ABox A;following possibilities, depending satisfiability A.Assume unsatisfiable. ans(, , A) = t, abstract reasonerreturns step 2(b) ABox -stable renaming(A ) dom() = ind(T ). Thus, Property 1 holds required.Assume satisfiable, consider arbitrary tuple cert(Q, , A).ans(, , A) = f ans(Q, , A), added step 7(b)ABox SQ , tuple b cert(Q, , ), injective (Q, )-stable renaming(b) = a, dom() = ind(Q ), (A ) A. Thus, Property 2holds required.following example illustrates Theorem 3.23.Example 3.24. Let Q specified Example 3.14, let = , SQspecified Example 3.16. show Section 3.5.2, exhaustive CwQ,T Q.Consider ABox = {St(a), MathSt(b), takesCo(a, b1 )}. Clearly, satisfiable cert(Q, , A) = {b}. Theorem 3.23, certain answer obtainedevaluating Q w.r.t. ABox SQ . Indeed, note ABox A5 SQ isomorphicsubset = {MathSt(b)} via renaming = {b c}, applying QA5 produces c, isomorphic b via .443fiCuenca Grau, Motik, Stoilos & HorrocksNote also that, remove A5 S, longer -test suiteexhaustive Q. example, abstract reasoner rl Example 3.16 would passtest suite, would return required certain answers applied A5 (and,consequently, applied either).3.5.2 Computing Test Suites Exhaustive CwQ,TBased Theorem 3.23, section show -test suite exhaustive CwQ,TQ obtained instantiating UCQ rewriting R Q w.r.t. is, replacingvariables R individuals possible ways. Please note instantiationmust full, sense possible replacements must considered.class CwQ,T contain abstract reasoners rl= Example 3.11strongly faithful may incorrectly handle case distinct variables boundindividuals.Definition 3.25. Let set individuals, let r datalog rule, letsubstitution. Then, instantiation substitution r w.r.t. (x)variable x occurring r. latter holds, instantiation r w.r.t. ABoxAr := {(B) | B body(r)}.Let Q UCQ, let TBox, let R = R , RQ UCQ rewriting Q w.r.t., let maximum number distinct variables occurring rule R, letset containing individuals occurring R, Q, , well fresh individuals.R,IR,Ifull instantiation R w.r.t. pair ER,I = ER,IER,IQ, EQ Esmallest sets ABoxesAr ER,Ir R instantiation substitution r w.r.t. I,Ar ER,IQ r RQ instantiation substitution r w.r.t.cert(, R , Ar ) = f.ER,I clearly unique renaming fresh individuals I, typically leftRimplicit, one talks full instantiation ER = ER, EQ R.Example 3.26. Let Q specified Example 3.14, let R = R , RQR = {St(x) Prof(x) } RQ consists following datalog rules:takesCo(x, y) MathCo(y) Q(x)takesCo(x, y) CalcCo(y) Q(x)MathSt(x) Q(x)Then, R UCQ rewriting Q w.r.t. , one see Q-simple -test suite= , SQ Example 3.16 full instantiation R.following theorem shows full instantiation UCQ rewriting Q w.r.t.Q-simple -test suite exhaustive CwQ,T Q. According theorem,-test suite Example 3.26 exhaustive CwQ,T Q.444fiCompleteness Guarantees Incomplete Ontology ReasonersTheorem 3.27. Let Q UCQ, let admissible TBox, let R = R , RQRUCQ rewriting Q w.r.t. , let ER = ER, EQ full instantiation R. Then,ER Q-simple -test suite exhaustive CwQ,T Q.Proof. Let set individuals ER obtained from. first show ERQ-simple -test suitethat is, satisfies two properties Definition 3.15.Consider arbitrary ABox ER. Then, rule r R instantiationsubstitution r exist = Ar ; clearly cert(, {r}, A) = t; since RUCQ rewriting, unsatisfiable, required.Consider arbitrary ABox ERQ . Then, cert(, R , A) = f Definition 3.25;since R UCQ rewriting, satisfiable, required.next show ER satisfies Properties 1 2 Theorem 3.23 arbitraryABox A.(Property 1) Assume unsatisfiable. Since R UCQ rewriting,Definition 2.2 cert(, R , A) = t; then, rule r R substitutionexist Ar cert(, {r}, Ar ) = t. Let injective renamingindividual c occurring R (c) = c, individualoccurring Ar R (d) fresh individual I;exists since number variables r smaller equal number fresh individualsI. Let instantiation substitution r (x) = ((x)) variableRx occurring r; Ar ERholds since E full instantiation R w.r.t. I. Letinjective renaming coincides inverse individual occurringAr , R, ; exists since injective range contains individualoccurring Ar , R, . Clearly (Ar ) = Ar holds, (Ar ) A. Furthermore,clearly -stable. Thus, Property (1) satisfied Ar ER.(Property 2) Assume satisfiable, consider arbitrarily chosen tuplecert(Q, , A). Since R UCQ rewriting, Definition 2.2 cert(, R , A) = fcert(RQ , R , A); then, clearly cert(RQ , , A) well. Then, rule r RQsubstitution exist Ar cert({r}, , Ar ). Let injectiverenaming individual c occurring R, Q, (c) = c,individual occurring Ar R, Q, (d) freshindividual I; clearly exists since number variables r smaller equalnumber fresh individuals I. Let instantiation substitution rR(x) = ((x)) variable x occurring r; Ar ERQ holds since Efull instantiation R w.r.t. I. Let injective renaming coincidesinverse individual occurring Ar , R, Q, ; exists sinceinjective range contains individual occurring Ar , R, Q, .Furthermore, clearly tuple b cert({r}, , Ar ) exists (head(r)) = Q(b); sinceR UCQ rewriting Ar satisfiable, b cert(Q, , Ar ); furthermore,since injective, (b) = clearly holds. then, Property (2) satisfied Ar ERQ,, b.445fiCuenca Grau, Motik, Stoilos & Horrocks3.5.3 Minimising Exhaustive Test Suitespractice, clearly beneficial compute test suites small possible.goal achieved applying known techniques minimising UCQ rewritings(Calvanese et al., 2007; Perez-Urbina, Horrocks, & Motik, 2009). Theorem 3.27,smallest rewriting instantiated obtain exhaustive test suite.State art query rewriting systems employ subsumption condensation techniques order reduce size rewriting. datalog rule r subsumes datalog ruler substitution exists (r) r ; intuitively, r general r .rewriting contains rules r r , r safely removed rewriting.Furthermore, rule r contains distinct unifiable body atoms Bi Bj , condensationr rule (r) general unifier Bi Bj . rewriting containsrule r (r) subsumes r, rule safely replaced (r). followingexample illustrates techniques used obtain small test suites.Example 3.28. Let Q specified Example 3.14, let R rewritingQ w.r.t. Example 3.26. R = R , RQ RQ consists followingrules also UCQ rewriting Q w.r.t. .takesCo(x, y) takesCo(x, z) MathCo(y) Q(x)(12)takesCo(x, y) CalcCo(y) Q(x)(14)MathSt(x) Q(x)(16)takesCo(x, x) CalcCo(x) MathCo(x) Q(x)(13)St(x) MathSt(x) Q(x)(15)Theorem 3.27, full instantiation R also -test suite exhaustive CwQ,TQ. rewriting R , however, contains redundancy hence resulting test suiteunnecessarily large. particular, applying condensation query (12), subsumptionqueries (13) (14), subsumption queries (15) (16), obtainsimpler rewriting R.Finally, note test suites obtained via full instantiation contain isomorphicABoxes. Clearly, isomorphic copies ABox safely eliminated testsuite without losing exhaustiveness CwQ,T Q.3.6 Testing (Q, )-Monotonic Strongly (Q, )-Faithful Abstract ReasonersDue full instantiation, test suites obtained Definition 3.25 exponentially largerrewriting generated from. result, even rewritings moderate sizeyield test suites containing thousands ABoxes. Intuitively, full instantiation requiredobtain test suite exhaustive class CwQ,T class contains abstractreasoners rl= Example 3.11, correctly handle casedistinct variables query matched individual.section, show test suites exhaustive class CsQ,T obtainedinjective instantiation rewritingthat is, replacing variable distinctfresh individual. Test suites obtained way linear size rewriting,thus substantially smaller test suites obtained full instantiation.446fiCompleteness Guarantees Incomplete Ontology ReasonersExample 3.29. Let Q specified Example 3.14, let = , SQQ-simple -test suite Example 3.16. Furthermore, consider abstract reasoner rl=Example 3.11 weakly, strongly (Q, )-faithful. easy checkrl= returns complete answers A1 A3 , A2 A4 . Therefore, Theorem3.27, exhaustive CwQ,T Q, must include SQ ABoxes A2 A4 ,respectively obtained ABoxes A1 A3 merging individual c.Strongly (Q, )-faithful abstract reasoners, however, correctly handle inputs obtainedmerging individuals. Based observation, section show Q-simple-test suite = , SQ SQ = {A1 , A3 , A5 }, obtained injectively instantiatingrewriting R Example 3.26, exhaustive CsQ,T Q.Section 3.5, first develop characterisation Q-simple -test suitesexhaustive CsQ,T Q; result analogous Theorem 3.23.Theorem 3.30. Let Q UCQ, let admissible TBox, let = , SQQ-simple -test suite. Then, exhaustive CsQ,T Q followingproperties satisfied ABox A.1. unsatisfiable, exist ABox -stable renamingdom() = ind(T ) (A ) A.2. satisfiable, tuple cert(Q, , A) exist ABoxSQ , tuple b cert(Q, , ), (Q, )-stable renaming (b) = a,dom() = ind(Q ), (A ) A.Proof. () Let arbitrary Q-simple -test suite satisfies Properties 1 2;next show exhaustive CsQ,T Q. Consider arbitrary abstract reasonerans CsQ,T passes Sthat is, ans satisfies following two properties:(a) ans(, , ) = ,(b) ans(, , ) = f implies cert(Q, , ) ans(Q, , ) SQ .next show ans (Q, )-completethat is, ans satisfies two conditionsDefinition 3.13 arbitrary ABox A. arbitrary A, followingtwo possibilities, depending satisfiability A.Assume unsatisfiable. Since satisfies Property 1, exist ABox-stable renaming dom() = ind(T ) (A ) A.Condition (a) ans(, , ) = t. Since ans strongly (Q, )-faithful stable, ans(, , (A )) = t; finally, since ans (Q, )-monotonic (A ) A,ans(, , A) = t, required Definition 3.13.Assume satisfiable ans(, , A) = f. Furthermore, consider arbitrary tuple cert(Q, , A). Since satisfies Property 2, exist ABox SQ ,tuple b cert(Q, , ), (Q, )-stable renaming (b) = a, (A ) A,dom() = ind(Q ). Since (A ) A, ans(, , A) = f, ans (Q, )-monotonic,ans(, , (A )) = f; furthermore, (Q, )-stable ans strongly faithful, ans(, , (A )) = f implies ans(, , ) = f. then, Condition (b)cert(Q, , ) ans(Q, , ), b ans(Q, , ). ans strongly (Q, )-faithful447fiCuenca Grau, Motik, Stoilos & Horrocks(Q, )-stable, (b) ans(Q, , (A )); since (b) = a, ans(Q, , (A ));finally, since ans (Q, )-monotonic (A ) A, ans(Q, , A), requiredDefinition 3.13.() Assume exhaustive CsQ,T Q; next show Properties 1 2satisfied arbitrary ABox A. end, consider particular abstract reasonerans prove ans CsQ,T ans passes S; abstract reasonerhelp us identify ABox, tuple, renaming required prove Properties 1 2.Let ans abstract reasoner takes input UCQ Qin , FOL-TBox Tin ,ABox . result ans(, Tin , ) determined follows.1. =Tin , return f.2. ABox , following.(a) Check satisfiability using sound, complete, terminatingreasoner.(b) unsatisfiable, -stable renaming existsdom() = ind(T ) (A ) , return t.3. Return f.Furthermore, result ans(Qin , Tin , ) determined follows.4. =Tin Q =Qin , return .5. := .6. tuple constants occurring arity equal arity querypredicate Q, SQ following.(a) Compute C := cert(Q, , ) using sound, complete terminating reasoner.(b) tuple b C (Q, )-stable renaming exist (b) = a,dom() = ind(Q ), (A ) , add Out.7. Return Out.next show ans belongs CsQ,T . proofs ans terminates(Q, )-monotonic analogous proofs Theorem 3.23. show strong (Q, )faithfulness, consider arbitrary Qin , Tin , , arbitrary renaming .Assume ans(, Tin , ) = -stable. Thus, Tin abstractreasoner terminates step 2(b) . Let renaming(c) = ((c)) c ind(T ). Clearly, dom( ) = ind(T ),renaming -stable, (A ) (Ain ). Thus, Tin (Ain ) abstractreasoner terminates step 2(b), ans(, Tin , (Ain )) = t, required.Assume ans(, Tin , ) = f (Q, )-stable, consider arbitrarytuple ans(Qin , Tin , ). added step 7(b) SQ ,448fiCompleteness Guarantees Incomplete Ontology Reasoners, b. Let renaming defined (c) = ((c)) individual c ind(Q ). Clearly, dom( ) = ind(Q ), mapping(Q, )-stable, (A ) (Ain ), (b) = (a). Thus, Qin , Tin , (Ain )abstract reasoner terminates step 7(b), (a) ans(Qin , Tin , (Ain )), required.concludes proof ans CsQ,T . Furthermore, ans clearly passes S; then,since exhaustive CsQ,T Q, abstract reasoner ans (Q, )-complete. mainclaim theorem shown Theorem 3.23.next use Theorem 3.30 show Q-simple -test suite exhaustiveQ obtained injective instantiation UCQ rewriting Q w.r.t. .CsQ,TDefinition 3.31. Let Q UCQ, let TBox, let R = R , RQ UCQ rewritingQ w.r.t. , let substitution mapping variable occurring R distinctR,fresh individual. injective instantiation R w.r.t. pair IR, = IR,, IQIR,IR,smallest sets ABoxesQAr IR,r R ,Ar IR,r RQ cert(, R , Ar ) = f.QIR, clearly unique renaming fresh individuals , typically leftRimplicit, one talks injective instantiation IR = IR, IQ R.Theorem 3.32. Let Q UCQ, let admissible TBox, let R = R , RQRUCQ rewriting Q w.r.t. , let IR = IR, IQ injective instantiation R.Then, IR Q-simple -test suite exhaustive CsQ,T Q.Proof. Let substitution IR obtained from. first show IRQ-simple -test suitethat is, satisfies two properties Definition 3.15.rConsider arbitrary IR. Then, rule r R exist = ; clearlycert(, {r}, A) = t; since R UCQ rewriting, unsatisfiable, required.Consider arbitrary IRQ . Then, cert(, R , A) = f Definition 3.31; since RUCQ rewriting, satisfiable, required.next show IR satisfies Properties 1 2 Theorem 3.30 arbitraryABox A.(Property 1) Assume unsatisfiable. Since R UCQ rewriting,Definition 2.2 cert(, R , A) = t; then, rule r R substitutionexist Ar cert(, {r}, Ar ) = t. Let renamingindividual c occurring R (c) = c, variable x r((x)) = (x). Clearly, (Ar ) = Ar , (Ar ) A. Furthermore, clear-stable. Thus, Property (1) holds Ar IR.(Property 2) Assume satisfiable, consider arbitrarily chosen tuplecert(Q, , A). Since R UCQ rewriting, Definition 2.2 cert(, R , A) = fcert(RQ , R , A); then, clearly cert(RQ , , A) well. Then, rule r RQ449fiCuenca Grau, Motik, Stoilos & Horrockssubstitution exist Ar cert({r}, , Ar ). Let renamingindividual c occurring R, Q, (c) = c,variable x r ((x)) = (x). Clearly, (Ar ) = Ar , (Ar ) A. Furthermore,clear (Q, )-stable. Finally, clearly tuple b cert({r}, , Ar ) exists(head(r)) = Q(b); since R UCQ rewriting Ar satisfiable,b cert(Q, , Ar ); furthermore, (b) = clearly holds. then, Property (2) satisfiedAr IR,,b.Q3.7 Dealing Recursive Axiomsnegative result Theorem 3.21 (which applies CwQ,T CsQ,T ) dependspresence recursive axiom TBox; thus, positive results Sections 3.53.6 require input UCQ rewritable w.r.t. input TBox, eectivelyprohibits recursion TBox axioms. Instead disallowing recursive axioms, sectionovercome limitation Theorem 3.21 placing additional requirementsabstract reasoners requiring first-order reproducible. Intuitively, lattermeans reasoners behaviour seen complete reasoning unknownfirst-order theory. abstract reasoners allowed partially evaluate recursiveaxioms, invalidates approach used prove Theorem 3.21.show -test suite exhaustive Q class first-order reproducibleabstract reasoners obtained instantiating datalog, rewriting Q w.r.t. .rewritings exist wide range TBoxes queries, turn allowsresults applicable range practically interesting cases. contrast testsuites computed UCQ rewriting, however, test suites obtained datalog,rewriting may Q-simple. fact, show Section 3.7.2 that, certain Q, -test suite exhaustive Q class first-order reproducible abstractreasoners exists, test suite Q-simple. important practicallyrelevant consequence: -test suite Q-simple, first-order reproducible abstractreasoner passes guaranteed (Q, )-complete; however, abstract reasonerpass S, general cannot conclude reasoner (Q, )-complete.3.7.1 First-Order Reproducible Abstract ReasonersState art concrete reasoners Oracles reasoner, Jena, OWLim, Minerva, Virtuoso, DLE-Jena implemented RDF triple stores extended deductivedatabase features. Given input, reasoners first precompute assertionsfollow preprocessing step. practice, step commonly implemented (a technique seen as) evaluating datalog program A.preprocessing, reasoners answer arbitrary UCQ Q simply evaluatingQ precomputed set assertions.Motivated observation, next introduce new class first-order reproducibleabstract reasonersthat is, abstract reasoners whose behaviour conceived complete reasoning unknown first-order theory. Note theory requireddatalog program; example, contain existential quantifiers, usedcapture behaviour concrete reasoners Jena OWLim (Bishop, Kiryakov,450fiCompleteness Guarantees Incomplete Ontology ReasonersOgnyano, Peikov, Tashev, & Velkov, 2011) handle existential quantifiers inputintroducing fresh individuals.Definition 3.33. abstract reasoner ans description logic DL first-order reproducible if, DL-TBox , set first-order sentences FT exists that,ABox A,ans(, , A) = cert(, FT , A),ans(, , A) = f, UCQ Q, ans(Q, , A) = cert(Q, FT , A).FT contains predicates and/or individuals occurring , assumedinternal ans accessible queries, TBoxes, ABoxes, test suites, on.Given TBox , CfT class first-order reproducible abstract reasoners applicable.Example 3.34. Abstract reasoners rdf, rdfs, rl classify Example 3.3 firstorder reproducible. Indeed, theory FT empty case rdf, precisely PrdfsPrl cases rdfs rl, respectively. Finally, abstract reasoner classify, theoryFT union Prl program containing axiom x.[A(x) B(x)]atomic subsumption B entailed input TBox.Please note first-order reproducible abstract reasoner ans need actually construct FT : matters (possibly unknown) theory FT existscharacterises reasoners behaviour specified Definition 3.33.Since QFT |= QFT whenever , first-order reproducible abstractreasoner (Q, )-monotonic arbitrary Q . Furthermore, straightforwardsee first-order reproducible abstract reasoner also strongly (Q, )-faithful.Consequently, CfT CsQ,T UCQ Q TBox .next show negative result Theorem 3.21 directly applyclass CfT . particular, show abstract reasoner pEvaln used proveTheorem 3.21 first-order reproducible. Intuitively, pEvaln understoodpartial evaluation datalog programthat is, rules program appliedfacts fixed number times rather fixpoint reached.Proposition 3.35. positive integer n, abstract reasoner pEvaln definedproof Theorem 3.21 first-order reproducible.Proof. Let = {R.A A}, let Q = {A(x) Q(x)}, consider arbitrary nonnegative integer n. Furthermore, assume pEvaln CfT ; then, finite set first-ordersentences FT exists pEvaln (Q, , A) = cert(Q, FT , A) ABox A.Let k positive integer; furthermore, let rk datalog rule let AkABox defined follows, a0 , . . . , ak arbitrary distinct fixed individuals occurringQ FT :rk = R(x0 , x1 ) . . . R(xk1 , xk ) A(xk ) A(x0 )Ak = {R(a0 , a1 ), . . . , R(ak1 , ak ), A(ak )}following condition holds Proposition 2.1:FT |= rkFT Ak |= A(a0 )451(17)fiCuenca Grau, Motik, Stoilos & Horrocksdefinition pEvaln ,a0 pEvaln (Q, , Ak ) 1 k n,a0 pEvaln (Q, , Ak ) k > n.Since pEvaln (Q, , A) = cert(Q, FT , A),a0 cert(Q, FT , Ak ) 1 k n,a0 cert(Q, FT , Ak ) k > n.Since Q contains atom A(x) body,FT Ak |= A(a0 ) 1 k n,FT Ak |= A(a0 ) k > n.condition (17),FT |= rk 1 k nFT |= rk k > n.This, however, contradicts obvious observation r1 |= rk k 1.Note proof Proposition 3.35 relies fact theory FT dependsinput TBox, input query. shown next, defined first-orderreproducible abstract reasoners allowing FT depend also input query,negative result Theorem 3.21 would applied.Definition 3.36. abstract reasoner ans DL first-order q-reproducible if,UCQ Q DL-TBox , finite set first-order sentences FQ,T exists that,ABox A,ans(, , A) = cert(, FQ,T , A),ans(, , A) = f, ans(Q, , A) = cert(Q, FQ,T , A).Theorem 3.37. Q = {A(x) Q(x)} = {R.A A}, -test suite existsexhaustive Q class sound, monotonic, strongly faithful, qreproducible abstract reasoners applicable .Proof. prove claim, suces show that, nonnegative integer n,abstract reasoner pEvaln defined proof Theorem 3.21 first-order q-reproducible.Consider arbitrary nonnegative integer n, arbitrary DL-TBox , arbitraryUCQ Q . define FQ ,T that, Q = Q, FQ ,T = ; otherwise,FQ ,T consists following n rules:A(x0 ) Q(x0 )R(x0 , x1 ) A(x1 ) Q(x0 )...R(x0 , x1 ) R(x1 , x2 ) . . . R(xn1 , xn ) A(xn ) Q(x0 )452fiCompleteness Guarantees Incomplete Ontology ReasonersClearly, pEvaln (, , ) = cert(, FQ ,T , ) = f UCQ Q , DL-TBoxABox , required. Furthermore, Q either Q = QABox , pEvaln (Q , , ) = cert(Q , FQ ,T , ) = . Finally,Q = Q, , ABox , clearly pEvaln (Q , , ) =cert(Q , FQ ,T , ), required.3.7.2 Simple vs. Non-Simple Test SuitesProposition 3.18 Section 3.3 shows Q-simple -test suite exhaustiveQ class abstract reasoners provides sucient necessary test (Q, )completeness. next show analogous result hold contains recursiveaxioms, even consider first-order reproducible abstract reasoners. Theorem 3.21, prove claim fixed Q since concept relevant recursiveaxioms might dicult formalise; however, proof easily adaptedUCQs TBoxes. result essentially states -test suite exists providesnecessary sucient condition (Q, )-completeness abstract reasonerCfT ; consequently, Proposition 3.18 -test suite exhaustive CfT QQ-simple. Furthermore, Section 3.7.3 show compute -test suite exhaustiveCfT Q, following claim hold vacuously.Theorem 3.38. Let Q = {A(x) B(x) Q(x)}, let = {R.A A}, let Cclass sound, monotonic, strongly faithful, first-order reproducible abstract reasoners applicable . Then, -test suite exists satisfies following two properties:1. exhaustive C Q;2. abstract reasoner ans C, ans (Q, )-complete ans passes S.Proof. Assume -test suite = , SQ exists satisfies properties 1 2theorem. Let n maximal number assertions occurring ABox S.next define two abstract reasoners ans1 ans2 ; straightforward checksound, monotonic, strongly faithful, first-order reproducible.Given arbitrary FOL-TBox Tin , abstract reasoner ans1 uses datalog programFT1in defined follows:Tin , FT1in = .Tin , FT1in contains following n rules:r0 =r1 =r2 =B(x0 ) A(x0 ) A(x0 )B(x0 ) R(x0 , x1 ) A(x1 ) A(x0 )B(x0 ) R(x0 , x1 ) R(x1 , x2 ) A(x3 ) A(x0 )...rn = B(x0 ) R(x0 , x1 ) . . . R(xn1 , xn ) A(xn ) A(x0 )Given arbitrary FOL-TBox Tin , abstract reasoner ans2 uses datalog programdefined follows, predicate Z private FT2in (and hence aectsoundness abstract reasoner):FT2in453fiCuenca Grau, Motik, Stoilos & HorrocksTin , FT2in = .Tin , FT2in contains FT1in well following rules:rZ1 = R(x0 , x1 ) . . . R(xn , xn+1 ) A(xn+1 ) Z(x0 )rZ2 =R(x0 , x1 ) Z(x1 ) Z(x0 )rZ3 =Z(x) B(x) A(x)let arbitrary ABox containing n assertions. next showthat, assertion containing predicate Z, FT1in |=FT2in |= . () direction trivial since FT1in FT2in , consider ()direction. Furthermore, since rZ3 rule FT2in \ FT1in containZ head, claim nontrivial form A(a0 ) individual a0 occurring A. Since antecedent rZ3 satisfied a0 , B(a0 )FT2in |= Z(a0 ). then, latter implied rZ1 rZ2 , individualsa0 , a1 , . . . , ak 0 k exist R(ai , ai+1 ) 1 < k, A(ak ) A.Since contains n assertions, w.l.o.g. assume k n. then, sinceFT1in contains rule rk , FT1in |= A(a0 ) well, proves claim. consequence claim fact ABoxes contain n assertions,cert(, FT1in , A) = cert(, FT2in , A) , cert(Y, FT1in , A) = cert(Y, FT2in , A)A, SQ .Let = {B(a0 ), R(a0 , a1 ), . . . , R(an , an+1 ), A(an+1 )}. cert(Q, , A) = {a0 }cert(Q, FT1in , A) = , ans1 (Q, )-complete. Since exhaustive C Q,abstract reasoner ans1 pass S; claim previous paragraph, abstractreasoner ans2 pass either. next show ans2 (Q, )-complete,contradicts assumption satisfies property 2 thus proves claimtheorem.Consider arbitrary ABox containing assertions. Clearly, a0 cert(Q, , A)individuals a0 , a1 , . . . , ak 0 k exist B(a0 ) A, R(ai , ai+1 )1 < k, A(ak ) A. assume k n; since rk FT2in ,FT2in |= A(a0 ) thus a0 cert(Q, FT2in , A). contrast, assume k > n; sincerZ1 FT2in , FT2in |= Z(akn1 ); since rZ2 FT2in , FT2in |= Z(ai )0 k n 1; finally, since rZ3 FT2in , FT2in |= A(a0 ); then,a0 cert(Q, FT2in , A), required.corollary Theorem 3.38, next show testing abstract reasoners CfTcannot done general using Q-simple test suites.Corollary 3.39. Q = {A(x) B(x) Q(x)} = {R.A A}, Q-simple test suite exists exhaustive Q class sound, monotonic, stronglyfaithful, first-order reproducible abstract reasoners applicable .Proof. Q-simple -test suite exhaustive Q class mentionedTheorem, Proposition 3.18 abstract reasoner ans classpass (Q, )-complete, contradicts Theorem 3.38.454fiCompleteness Guarantees Incomplete Ontology ReasonersTheorem 3.38 eectively says that, abstract reasoner ans CfT pass test suite S, cannot conclude ans (Q, )-complete. Please note holdsans fails test form A, Q =Y: Q = Y, counterexample(Q, )-completeness ans. Thus, may show ans (Q, )-complete,guaranteed so. illustrated following example.Example 3.40. Let Q = {A(x) B(x) Q(x)} let = {R.A A, R.C C}. Furthermore, let = , SQ general test suite defined follows:SQ = {{ A(c) },{ A(x) B(x) Q(x) } ,{ R(c, d), A(d) }, { A(c) Q } ,{ R(c, d), C(d) }, { C(c) Q }}Let R = RD , , Q RD = {R(x, y) A(y) A(x), R(x, y) C(y) C(x)}; clearly,R rewriting Q w.r.t. . Section 3.7.3 show compute R usingvariant injective instantiation way guarantees exhaustiveness CfT Q.let ans1 CfT abstract reasoner defined FT1 = {R(x, y) A(y) A(x)}.reasoner pass since cert({C(c) Q }, FT1 , {R(c, d), C(d)}) = f. Note, however, reasoner (Q, )-complete. Thus, test suite Q-simple, passingsucient, necessary condition (Q, )-completeness. fact, notecontains TBox Theorem 3.38, theorem cannot reducecorrectly identifies reasoners CfT (Q, )-complete.practice, however, one try mitigate fundamental theoretical limitationeliminating irrelevant axioms rewriting R thus increasing likelihoodobtaining -test suite (Q, )-complete abstract reasoner pass. example,using techniques Cuenca Grau, Horrocks, Kazakov, Sattler (2008a)extract module R relevant query. example previous paragraph,would remove rule R(x, y) C(y) C(x) R, injective instantiationproduce test suite = , SQ SQ defined follows:SQ = {{ A(c) },{ A(x) B(x) Q(x) } ,{ R(c, d), A(d) }, { A(c) Q }}Abstract reasoner ans1 previous paragraph passes thus guaranteed(Q, )-complete.let ans2 abstract reasoner defined FT2 = {B(x) R(x, y) A(y) A(x)}.Clearly, abstract reasoner ans2 (Q, )-complete, ans2 pass SQ .latter, however, cannot immediately conclude (Q, )-complete: testfails involve original query Q. possible remedy, try unfoldR certain level injectively instantiate result hope obtaining -testsuite identify ans2 (Q, )-complete. particular, first unfoldingR produces following query:B(x) R(x, y) A(y) Q(x)Instantiating rewriting produces following test suite, proveans2 (Q, )-complete.SQ = {{ B(c), R(c, d), A(d) }, { A(x) B(x) Q(x) } }455fiCuenca Grau, Motik, Stoilos & HorrocksAnother round unfolding, however, produces following query:B(x) R(x, y) R(y, z) A(z) Q(x)Instantiating query produces following test suite:Q ={{ B(c), R(c, d), R(d, e), A(e) }, { A(x) B(x) Q(x) } }ans2 passQ , conclude ans2 (Q, )-complete.better understand Example 3.40, consider first-order reproducible abstract reasonerans, arbitrary UCQ Q, TBox R = RD , , RQ datalog rewritingQ w.r.t. . Datalog program RD RQ equivalent (possibly infinite) UCQ RuQobtained RD RQ via exhaustive unfolding. following possibilities.First, assume ans (Q, )-complete. Since RD RQ equivalent RuQ ,certain answer Q w.r.t. arbitrary ABox produced r RuQ .then, injective instantiation Ar r provide us counterexample(Q, )-completeness ans. Thus, prove ans (Q, )-completegenerating elements RuQ fair manner (i.e., without indefinitely delayinggeneration element RuQ ) checking whether cert(Q, , Ar ) ans(Q, , Ar );guaranteed eventually encounter r RuQ invalidates conditionthus proves ans (Q, )-complete.Second, assume ans (Q, )-complete. Using approach, determine cert(Q, , Ar ) ans(Q, , Ar ) holds r RuQ . RuQ finite (i.e.,unfolding RD RQ terminates), RuQ UCQ rewriting Q w.r.t. ,results Section 3.6 conclude ans indeed (Q, )-complete. If, however, RuQ infinite, never obtain sucient assurance (Q, )-completeans. following section show possible remedy problem.3.7.3 Testing First-Order Reproducible Abstract Reasonerssection, show compute -test suite = , SQ exhaustive CfTQ datalog, rewriting R = RD , R , RQ Q w.r.t. . Since first-orderreproducible abstract reasoners strongly faithful, need consider injectiveinstantiations R. Thus, rules R RQ instantiated Section 3.6.rule r RD , however, instantiated pair A, SQ ABox obtainedinstantiating body r Boolean UCQ obtained instantiating headr. Intuitively, tests allow us check whether (unknown) first-order theory FTcaptures behaviour abstract reasoner entails r.Definition 3.41. Let Q UCQ query predicate Q, let admissible TBox,let R = RD , R , RQ datalog, rewriting Q w.r.t. , let substitutionmapping variable occurring R distinct fresh individual. injective instanR,R,tiation R w.r.t. pair IR, = IR,smallest set ABoxes, IQIR,smallest set pairs ABox UCQQAr IR,r R ,456fiCompleteness Guarantees Incomplete Ontology ReasonersAr , Q IR,r RQ cert(, RD R , Ar ) = f,QAr , IR,r RD form (6) cert(, RD R , Ar ) = f,QUCQ = {i ((x), yi ) Q | 1 m} propositional querypredicate Q .IR, clearly unique renaming fresh individuals , typically leftRimplicit, one talks injective instantiation IR = IR, IQ R.Example 3.42. Consider query Q = {A(x) Q(x)} EL-TBox consistingfollowing axioms, whose translation first-order logic shown symbol.R.A BBCADR.CC R.Dx, y.[R(x, y) A(y) B(x)]x, y.[R(x, y) C(y) A(x)]x.[B(x) C(x)]x.[C(x) y.[R(x, y) D(y)]]x.[A(x) D(x) ]Then, R = RD , R , RQ defined next datalog rewriting Q w.r.t. .RD = { R(x, y) A(y) B(x), R(x, y) C(y) A(x), B(x) C(x) }R = { A(x) D(x) }RQ = { A(x) Q(x) }Rinjective instantiation IR = IR, IQ R shown below.IR= { { A(c), D(c) } }IR{ A(x) Q(x) } ,Q = { { A(c) },{ R(c, d), A(d) }, { B(c) Q } ,{ R(c, d), C(d) }, { A(c) Q } ,{ B(c) },{ C(c) Q }}show injective instantiation datalog, rewriting Q w.r.t.-test suite exhaustive CfT Q.Theorem 3.43. Let Q UCQ, let TBox, let R = RD , R , RQ datalog,RRrewriting Q w.r.t. , let IR = IR, IQ injective instantiation R. Then,-test suite exhaustive CfT Q.Proof. Let substitution IR obtained from. first show IR -testsuite.rConsider arbitrary IR. Then, rule r R exist = ; clearlycert(, {r}, A) = t, cert(, RD R , A) = well; since R datalog, rewriting Q w.r.t. , unsatisfiable, required.457fiCuenca Grau, Motik, Stoilos & HorrocksConsider arbitrary IRQ . Then, cert(, RD R , A) = f Definition 3.41;,since R datalogrewriting Q w.r.t. , satisfiable,required.show IR exhaustive CfT Q, consider arbitrary abstract reasonerans CfT passes IR is, ans satisfies following two properties:(a) ans(, , ) = IR,(b) ans(, , ) = f implies cert(Y, , ) ans(Y, , ) Y, IRQ.Since ans first-order reproducible, set first-order sentences FT exists that,ABox A,ans(, , A) = cert(, FT , A),ans(, , A) = f, ans(Q, , A) = cert(Q, FT , A).assumption FT Definition 3.33 fact maps variables freshindividuals, rng() ind(FT ) = .Let R1D R2D smallest sets rules satisfying following conditionsrule r RD :cert(, FT , Ar ) = implies r R1D , r obtained r replacing head,cert(, FT , Ar ) = f implies r R2D .Furthermore, let R1Q R2Q sets rules obtained RQ analogous way.Since R1D R2D obtained RD replacing head formulae , clearlyR1D R2D |= RD ; analogously, R1Q R2Q |= RQ .next show FT |= R ; latter holds FT |= r rule r R .Consider arbitrary rule r R ; note head(r) = . Then, Definition 3.41rrAr IR; (a) ans(, , ) = t; Definition 3.33 cert(, FT , ) =hence FT Ar |= ; finally, since rng() ind(FT ) = , Proposition 2.1FT |= r, required.next show FT |= R1D ; latter holds FT |= r rule r R1D .Consider arbitrary rule r R1D ; note head(r) = . Then, definition R1Dcert(, FT , Ar ) = hence FT Ar |= ; finally, since rng() ind(FT ) = ,Proposition 2.1 FT |= r, required.completely analogous way previous paragraph, possible showFT |= R1Q .next show FT |= R2D ; latter holds FT |= r ruler R2D . Consider arbitrary rule r R2D form (6); definition R2Dcert(, FT , Ar ) = f, Definition 3.33 ans(, , Ar ) = f. Then, Definition3.41 Ar , IRx), yi ) Q | 1 m}. NoteQ UCQ = {i ((|= r Definition 2.2, Proposition 2.1 Ar |=x), yi );i=1 ((definition fact Q occur , Ar |= Q ;458fiCompleteness Guarantees Incomplete Ontology Reasonersthen, cert(Y, , Ar ) = t. latter observation, ans(, , Ar ) = f, (b) implyans(Y, , Ar ) = t, Definition 3.33 cert(Y, FT , Ar ) = t. Since Q occurs(note predicate occurringFT private FT , Q cannotroccur FT ), FT |= i=1 ((x), yi ). Finally, since rng() ind(FT ) = ,Proposition 2.1 FT |= r, required.next show Q FT |= R2Q ; latter holds Q FT |= rrule r R2Q . Consider arbitrary rule r R2Q ; note head(r) atom predicateQ, definition R2Q cert(, FT , Ar ) = f, Definition 3.33ans(, , Ar ) = f. Furthermore, Definition 3.41, cert(, RD R , Ar ) = f.Let tuple arguments (head(r)). Then, Definition 3.41Ar , Q IRcert({r}, , Ar ), cert(RQ , RD R , Ar )Q ; clearly,monotonicity first-order logic. Since R rewriting Q w.r.t. , Definition 2.2 cert(Q, , Ar ). latter observation, ans(, , Ar ) = f, (b)imply ans(Q, , Ar ). Definition 3.33 cert(Q, FT , Ar ); hence,FT Ar |= Q(a). Finally, since rng() ind(FT ) = , Proposition 2.1FT |= r, required.following table summarises entailment relationships various first-ordertheories obtained thus far:FT |= RQ FT |= R2QFT |= R1DR1Q R2Q |= RQFT |= R2DR1D R2D |= RDFT |= R1QClearly, implies following entailments:FT |= RD RQ FT |= RD R RQcomplete proof theorem show ans (Q, )-complete.end, consider arbitrary ABox A; following possibilities, dependingsatisfiability A.Assume unsatisfiable. cert(, RD R , A) = Definition2.2; mentioned entailments, cert(, FT , A) = t; consequently,ans(, , A) = Definition 3.33, required.Assume satisfiable ans(, , A) = f, consider arbitrary tuplecert(Q, , A). Then, cert(, RD R , A) = f cert(RQ , RD R , A)Definition 2.2. mentioned entailments, cert(Q, FT , A);hence, ans(Q, , A) Definition 3.33, required.Note size test suite obtained Theorem 3.43 linear sizerewriting, which, believe, makes approach suitable use practice.3.7.4 Testing Ground Queriesshown Section 3.7.2, abstract reasoner ans CfT pass -test suiteQ-simple, cannot always conclude ans (Q, )-complete.practical point view, would highly beneficial identify situations passingwould show ans indeed incomplete Q . Furthermore, applications459fiCuenca Grau, Motik, Stoilos & Horrocksprototypical queries known design time, would like design completenesstests query-independentthat is, test abstract reasoner completenessw.r.t. regardless input data query. section, showachieve two goals focusing ground queries. restriction unreasonablepractice, since SPARQL query equivalently expressed ground UCQ.first define query-independent notion exhaustiveness test suite.Definition 3.44. Let TBox, let -test suite, let C class abstractreasoners applicable . Then, exhaustive C ground UCQs ans Cpasses (Q, )-complete ground UCQ Q.Then, define notion ground rewriting rewriting capturesquery answers w.r.t. , regardless input ground query ABoxand showinstantiate ground rewritings.Definition 3.45. ground rewriting TBox pair R = RD , R that,ground UCQ Q, triple RD , R , Q datalog rewriting w.r.t. Q.injective instantiation IR R defined IR = IR R = RD , R , .Note Definition 3.45 implies variable occurring head ruleR also occurs rule body. Tools REQUIEM KAON2 easilyadapted compute ground rewriting TBox practice. next showinjective instantiation ground rewriting yields -test suite provides ussucient necessary check completeness w.r.t. ground UCQs.Theorem 3.46. Let TBox, let R = RD , R ground rewriting .Then, following two claims hold.1. IR exhaustive CfT ground UCQs.2. abstract reasoner ans CfT pass IR (Q, )-completeground UCQ Q.Proof. (Property 1) Consider arbitrary abstract reasoner ans CfT passes IR . LetFT first-order theory characterises behaviour ans; proofTheorem 3.43, fact ans passes IR implies FT |= RD R . Furthermore, considerarbitrary ground UCQ Q arbitrary ABox A. ans (Q, )-completeshown proof Theorem 3.43, minor dierence cert(Q, , A)implies cert(Q, RD R , A) Definition 3.45.(Property 2) Note that, since R ground rewriting , Definition 3.41 UCQsIR ground. Thus, abstract reasoner ans CfT pass IR , clearlyshows ans (Q, )-complete ground UCQ Q.4. Comparing Incomplete Abstract Reasonerssection, investigate techniques that, given query Q TBox , allow usdetermine whether abstract reasoner ans2 complete abstract reasonerans1 is, whether ABoxes A, abstract reasoner ans2 computes answersQ abstract reasoner ans1 . idea formalised following definition.460fiCompleteness Guarantees Incomplete Ontology ReasonersDefinition 4.1. Let Q UCQ, let TBox, let ans1 ans2 abstractreasoners applicable . Then, ans1 Q,T ans2 following conditions holdABox A:1. cert(, , A) = ans1 (, , A) = imply ans2 (, , A) = t;2. cert(, , A) = f, ans1 (, , A) = f, ans2 (, , A) = f implyans1 (Q, , A) cert(Q, , A) ans2 (Q, , A) cert(Q, , A).Furthermore, ans1 <Q,T ans2 ans1 Q,T ans2 ABox exists least onefollowing two conditions holds:3. cert(, , A) = t, ans1 (, , A) = f, ans2 (, , A) = t;4. cert(, , A) = f, ans1 (, , A) = f, ans2 (, , A) = f,ans1 (Q, , A) cert(Q, , A) ans2 (Q, , A) cert(Q, , A).Example 4.2. Consider abstract reasoners rdf, rdfs, rl, classify introduced Example 3.3 query Q TBox Example 3.14. clearly following:rdf Q,T rdfs Q,T rl Q,T classifyFurthermore, two abstract reasoners, ABox exists distinguishesabstracts reasoners w.r.t. Q ; example, ABox = {takesCo(c, d), MathsCo(d)},rdfs(Q, , ) = rl(Q, , ) = {c}. result, also following:rdf <Q,T rdfs <Q,T rl <Q,T classifywould like check whether ans1 Q,T ans2 ans1 <Q,T ans2 given pairabstract reasoners subjecting reasoners finite set tests. Towards goal,Rnext define relations RQ,T <Q,T compare abstract reasoners w.r.t. givenfinite set R ABoxes. Ideally, given Q , would like compute finite RRRQ,T <Q,T coincide Q,T <Q,T abstract reasoners class Cinterest. ideas captured following definitions.Definition 4.3. Let Q UCQ, let TBox, let R finite set ABoxes, letans1 ans2 abstract reasoners applicable .Then, ans1 RQ,T ans2 Conditions 1 2 Definition 4.1 hold ABoxRR. Furthermore, ans1 <RQ,T ans2 ans1 Q,T ans2 either Condition 3 Condition4 Definition 4.1 holds ABox R.Definition 4.4. Let Q UCQ, let TBox, let C class abstract reasonersapplicable . finite set R ABoxes (Q, )-representative C followingconditions hold ans1 , ans2 C:1. ans1 RQ,T ans2 ans1 Q,T ans2 ;461fiCuenca Grau, Motik, Stoilos & Horrocks2. ans1 <RQ,T ans2 ans1 <Q,T ans2 .show next, prove R (Q, )-representative, suces showimplication Condition 1 implication Condition 2 Definition 4.4.Proposition 4.5. Let Q UCQ, let TBox, let C class abstract reasonersapplicable , let R finite set ABoxes1. ans1 RQ,T ans2 implies ans1 Q,T ans2 ,2. ans1 <Q,T ans2 implies ans1 <RQ,T ans2 .Then, R (Q, )-representative C.Proof. Note ans1 Q,T ans2 trivially implies ans1 RQ,T ans2 ; thus, Condition 1proposition clearly implies Condition 1 Definition 4.4. Furthermore, ABox Rsatisfies Condition 3 4 Definition 4.1, Condition 1 2 Definition 4.1 holds well;consequently, Conditions 1 2 proposition imply Condition 2 Definition 4.4.obvious question whether Q-simple -test suite exhaustive classC Q also (Q, )-representative C. following example showsnecessarily case.Example 4.6. Let Q specified Example 3.14, let R = {A1 , . . . , A6 }ABoxes specified Example 3.16. shown Section 3, Q-simple -test suite= , SQ = {A6 } SQ = {A1 , . . . , A5 } exhaustive CwQ,T Q.Let trivial abstract reasoner returns empty set input, consider also RDF-based abstract reasoner rdf Example 3.3, ignores TBoxevaluates query directly ABox. Clearly, trivial Q,T rdf; furthermore,trivial <Q,T rdf since = {St(c), takesCo(c, d), MathCo(d)} rdf(Q, , A) = {c}whereas trivial(Q, , A) = . abstract reasoners, however, return empty setanswers ABoxes R thus rdf RQ,T trivial. Hence, using R cannotdierentiate two abstract reasoners.4.1 Negative Resultfollowing strong result shows that, numerous TBoxes , finite set ABoxesexists dierentiate two arbitrary abstract reasoners class sound,first-order reproducible, monotonic, strongly faithful reasoners. Note resultstronger negative result Theorem 3.21, applies smaller class abstractreasoners TBoxes imply least one concept subsumption.Theorem 4.7. Let arbitrary TBox mentioning atomic role R atomicconcepts B |= B, let Q = {B(x) Q(x)}. Then, finite setABoxes exists (Q, )-representative class sound, monotonic, stronglyfaithful, first-order reproducible abstract reasoners applicable .462fiCompleteness Guarantees Incomplete Ontology ReasonersProof. Assume finite set ABoxes R exists (Q, )-representative classsound, monotonic, strongly faithful, first-order reproducible abstract reasonersapplicable . Let n maximum number assertions ABox R.arbitrary integer k 1, let ansk first-order reproducible abstract reasonerthat, given FOL-TBox Tin , uses following datalog program FTkin :FTkin=Tin | = BA(x0 ) R(x0 , x1 ) . . . R(xk1 , xk ) B(x0 ) Tin |= BClearly, ansk sound, monotonic, strongly faithful; furthermore, ansk (, , A) = fABox A. next show ansn+1 (Q, , A) ansn+2 (Q, , A) ABoxR. Consider arbitrary a0 ansn+1 (Q, , A); then, individuals a0 , a1 , . . . , an+1 existR(a1 , ) 1 n + 1. Since contains n assertionsrule FTn+1 contains n + 1 body atoms, ai = aj = jthat is,contains R-cycle. then, rule FTn+2 matched mapping x0a0 , a0 ansn+2 (Q, , A). Therefore, ansn+1 RQ,T ansn+2 .= {A(a0 ), R(a0 , a1 ), . . . , R(an , an+1 )}, however, a0 ansn+1 (Q, , A)ansn+2 (Q, , A) = ; thus, ansn+1 Q,T ansn+2 hold, contradicts assumption R exhaustive class abstract reasoners theorem.4.2 Compact Abstract ReasonersTheorem 4.7 suggests need make additional assumptions abstract reasoners wish compare using finite set ABoxes. section, showrepresentative sets ABoxes computed practice restrictabstract reasoners call (Q, )-compact. Intuitively, abstract reasonerprocesses Q, , computing certain answers Q, A, subset, subset depends Q. words, behaviour compactabstract reasoners simulated following process: select subset axiomsinput TBox processed, compute certain answers w.r.t.selected fragment TBox. class (Q, )-compact abstract reasoners thus captures properties concrete reasoners Jena Oracles Semantic Data Storediscard axioms input TBox fall outside certain fragment (e.g., existentialrestrictions right-hand implications) encode remaining axiomssuitable set rules.Definition 4.8. Let Q UCQ, let TBox. abstract reasoner ans applicable(Q, )-compact TBox exists following properties holdABox A:1. cert(, , A) = implies ans(, , A) = t;2. cert(, , A) = f implies ans(, , A) = f ans(Q, , A) = cert(Q, , A).Abstract reasoner ans compact (Q, )-compact UCQ Q TBoxans applicable. Finally, CcQ,T class (Q, )-compact strongly(Q, )-faithful abstract reasoners applicable .463fiCuenca Grau, Motik, Stoilos & HorrocksExample 4.9. abstract reasoners defined Example 3.3 (Q, )-compactquery Q EL-TBox Example 3.14. Indeed, abstract reasoner rdf subsetgiven = ; abstract reasoner rdfs = {(8)}; abstract reasonerrl = {(8), (9), (10)}; abstract reasoner classify = .abstract reasoners ansk defined proof Theorem 4.7 (Q, )compact query TBoxes Theorem 4.7 applies.Proposition 4.10. Let Q = {B(x) Q(x)} let = {A B, C R.}. Then,k 1, abstract reasoner ansk proof Theorem 4.7 (Q, )-compact.Proof. Let Q stated theorem consider arbitrary k 1. Let A1A2 ABoxes defined follows:A1 = {A(a0 )}A2 = {A(a0 ), R(a0 , a1 ), . . . , R(ak1 , ak )}Clearly, following:ansk (Q, , A1 ) =ansk (Q, , A2 ) = {a0 }One straightforwardly check, however, following holds :cert(Q, , A1 ) = cert(Q, , A2 )Thus, ansk (Q, )-compact.Thus, negative result Theorem 4.7 immediately apply classcontaining compact abstract reasoners.4.3 Comparing Compact Abstract Reasonerssection, show set ABoxes (Q, )-representative CcQ,Tobtained computing, subset , Q-simple -test suite exhaustiveCsQ,T . minor complication arises due fact contain fewer individuals. deal cases correctly, ABoxes ST allowed containindividuals occurring , ABoxes STQ allowed containindividuals occurring Q . assumption without loss generality:given (Q, )-test suite ST , one replace individuals Qfresh individuals; result replacement (Q, )-test suite exhaustive CsQ,T .Theorem 4.11. Let Q UCQ, let TBox. Furthermore, , letST = ST , STQ Q-simple -test suite exhaustive CsQ,T QABox ST contains individual ind(T ) \ ind(T ) ABox STQ containsindividual ind(T ) \ ind(Q ). Then, set R ABoxes definedR=ST STQ(Q, )-representative CcQ,T .464fiCompleteness Guarantees Incomplete Ontology ReasonersProof. Assume R satisfies conditions theorem, let ans1 ans2arbitrary abstract reasoners CcQ,T . next show ans1 ans2 satisfy twoproperties Proposition 4.5.Property 1 Proposition 4.5:ans1 RQ,T ans2 implies ans1 Q,T ans2Property 2 Proposition 4.5:ans1 <Q,T ans2 implies ans1 <RQ,T ans2Since ans1 (Q, )-compact, TBox exists satisfies conditionsDefinition 4.8. Assume ans1 RQ,T ans2 ; next show Conditions 1 2Definition 4.1 satisfied arbitrary ABox A.(Condition 1) Assume cert(, , A) = ans1 (, , A) = t. contrapositive property 2 Definition 4.8, cert(, , A) = t. Since R contains ABoxesQ-simple -test suite exhaustive CsQ,T Q, Theorem 3.30exist ABox R -stable renaming dom() = ind(T )(A ) A; since contain individuals ind(T ) \ ind(T ), renaming also-stable. definition -test suite, cert(, , ) = t; furthermore, property 1Definition 4.8 ans1 (, , ) = t. Since ans1 RQ,T ans2 ans2 (, , ) = t.Since ans2 strongly (Q, )-faithful -stable, ans2 (, , (A )) = t. Finally, since (A ) ans2 (Q, )-monotonic, ans2 (, , A) = t, required.(Condition 2) Assume cert(, , A) = f, ans1 (, , A) = f, ans2 (, , A) = f,consider arbitrary tuple ans(Q, , A) cert(Q, , A). contrapositiveproperty 1 Definition 4.8, cert(, , A) = f; then, property 2 Definition 4.8, cert(Q, , A). Since R contains ABoxes Qsimple -test suite exhaustive CsQ,T Q, Theorem 3.30 existABox R, tuple b cert(Q, , ), (Q, )-stable renamingdom() = ind(Q ), (A ) A, (b) = a; since contain individuals ind(T ) \ ind(Q ), renaming also (Q, )-stable. definition(Q, )-test suite, cert(, , ) = f; furthermore, property 2 Definition 4.8b ans1 (Q, , ). Since ans1 R ans2 b ans2 (Q, , ). Since ans2 stronglyQ,T(Q, )-faithful (Q, )-stable, ans2 (Q, , (A )). Finally, since(A ) ans2 (Q, )-monotonic, ans2 (Q, , A), required.Assume ans1 <Q,T ans2 . Definition 4.1, ans1 Q,T ans2 ABoxexists satisfying Conditions 3 4 Definition 4.1. Clearly, ans1 RQ,T ans2 ; hence,remains shown R contains ABox satisfies Conditions 3 4Definition 4.1. Since ans1 (Q, )-compact, TBox exists satisfiesconditions Definition 4.8.(Condition 3) Assume cert(, , A) = t, assume also ans1 (, , A) =ans2 (, , A) = f. proof Condition 1, identify ABox R-stable renaming ans1 (, , ) = (A ) A. Since ans2 (Q, )monotonic ans2 (, , A) = f, ans2 (, , (A )) = f; furthermore, since ans2strongly (Q, )-faithful -stable, also ans2 (, , ) = f. then,Condition 3 Definition 4.1 satisfied R.(Condition 4) Assume cert(, , A) = f ans1 (, , A) = ans2 (, , A) = f,consider arbitrary tuple [ans1 (Q, , A) cert(Q, , A)] \ ans2 (Q, , A).proof Condition 2, identify ABox R, (Q, )-stable renaming ,465fiCuenca Grau, Motik, Stoilos & Horrockstuple b cert(Q, , ) (A ) A, (b) = a, b ans1 (Q, , ). Since ans2(Q, )-monotonic ans2 (Q, , A), ans2 (Q, , (A )); furthermore, sinceans2 strongly (Q, )-faithful (Q, )-stable, also b ans2 (Q, , ).then, Condition 4 Definition 4.1 satisfied R.Theorems 3.32 4.11 immediately suggest approach computing set ABoxes(Q, )-representative CcQ,T . First, compute UCQ rewriting Q w.r.t.subset ; then, instantiate rule rewriting using injectiveinstantiation mapping; finally, compute R union ABoxes test suites.nave procedure, however, practical since requires computing exponentialnumber UCQ rewritings. next present practical approach computingset ABoxes (Q, )-representative CcQ,T . Intuitively, instead computingexponentially many rewritings, one compute single UCQ rewriting Q w.r.t.subset-closed is, contains rewriting subset .Definition 4.12. UCQ rewriting R = R , RQ Q w.r.t. subset-closedtuple R = R , RQ exists R R , RQ RQ RUCQ rewriting Q w.r.t. .following corollary immediate consequence Theorems 3.27, 3.32, 4.11.Corollary 4.13. Let Q UCQ, let TBox, let R subset-closed UCQ rewritingRQ w.r.t. , let IR = IR, IQ injective instantiation R. Then, setQ,TRABoxes R = IR.IQ (Q, )-representative CcPractical query rewriting systems REQUIEM optimised produce smallUCQ rewriting possible, output typically subset-closed. Therefore,technique requires modification UCQ rewriting algorithms implemented existing systems. illustrated following example, required modification typicallyinvolves disabling (at least partially) subsumption-based optimisations.Example 4.14. Let Q specified Example 3.14, let = , SQ-test suite Example 3.16. system REQUIEM compute Rgiven Q . Note, however, R subset-closed; example, UCQrewriting Q w.r.t. = Q, subset RQ . rewriting madesubset-closed extending RQ following rules:St(x) takesCo(x, y) MathCo(x, y) Q(x)St(x) takesCo(x, y) CalcCo(x, y) Q(x)MathSt(x) St(x) Q(x)Systems REQUIEM, however, typically discard rules applying subsumptionoptimisations described Section 3.5.3.following example shows, subset-closed UCQ rewriting Q w.r.t. can,worst case, exponentially larger minimal UCQ rewritings Q w.r.t. .Example 4.15. Let Q = {C(x) Q(x)}, let following TBox:= {B Ai | 1 n} {A1 . . . C}466fiCompleteness Guarantees Incomplete Ontology ReasonersFurthermore, let R = R , RQ R = RQ contains following rules:C(x) Q(x)B(x) Q(x)A1 (x) . . . (x) Q(x)Clearly, R UCQ rewriting Q w.r.t. ; however, number rules subset-closedUCQ rewriting Q w.r.t. exponential n.5. Evaluationimplemented techniques computing exhaustive test suites comparing incomplete concrete reasoners prototype tool called SyGENiA.1 tool uses REQUIEMcomputing UCQ datalog rewritings.2considered two evaluation scenarios. first one uses well-known LehighUniversity Benchmark (LUBM) (Guo et al., 2005), consists relatively smallTBox academic domain, 14 test queries, data generator. second oneuses small version GALEN (Rector & Rogers, 2006)a complex ontology commonlyused medical applications.evaluated following concrete reasoners: Sesame v2.3-prl,3 DLE-Jena v2.0,4OWLim v2.9.1,5 Minerva v1.5,6 Jena v2.6.37 three variants (Micro, Mini,Max).5.1 Computing Exhaustive Test SuitesGiven UCQ Q TBox , tool uses REQUIEM compute datalog rewritingR Q . R UCQ rewriting, tool computes simple test suiteeither full injective instantiation (see Sections 3.5 3.6, respectively); otherwise,tool computes non-simple test suite instantiating R described Section 3.7.3.5.1.1 Simple Test Suitescase LUBM benchmark, 14 test queries leads UCQ rewriting w.r.t. TBox.8 Therefore, computed UCQ rewriting query Qbenchmark using REQUIEM instantiated it, fully injectively, thus obtainingQ-simple -test suites exhaustive Q CwQ,T CsQ,T , respectively.times needed compute test suites size test suite shown Table3, denotes total number ABoxes corresponding test suites.1.2.3.4.5.6.7.8.http://code.google.com/p/sygenia/http://www.cs.ox.ac.uk/projects/requiem/home.htmlhttp://www.openrdf.org/http://lpis.csd.auth.gr/systems/DLE-Jena/http://www.ontotext.com/owlim/http://www.alphaworks.ibm.com/tech/semanticstkhttp://jena.sourceforge.net/Since REQUIEM currently support individuals queries, replaced individualsqueries distinguished variables.467fiCuenca Grau, Motik, Stoilos & HorrocksQ,TCwCsQ,TQ1Time 1.22Time 1.21Q2 Q3 Q4 Q5 Q6 Q7 Q8 Q9 Q10 Q11 Q12 Q13 Q140.7 0.2 6.7 0.2 2.1 0.772.4 7.4 0.07 0.2 0.2 0.0520 2 2 352 8 1207 345 3 092 5 3 919 725 1010.6 0.2 0.6 0.2 1.2 0.4 1.5 2.5 0.6 0.05 0.1 0.1 0.0841224 169 37361 1692351Table 3: Computation simple test suites LUBM. Times given seconds.Q,TCwCsQ,TTimeTimeQ1146 0492.279Q23412 0856151Q36712 08540151Q44.6791.725Table 4: Computation simple test suites GALEN. Times given seconds.shown table, simple test suites could computed times ranging 0.057 seconds, CwQ,T CsQ,T . optimisations implemented REQUIEM ensureUCQ rewritings relatively small, resulting test suites also consistrelatively small number ABoxes. Notice, however, significant dierencenumbers ABoxes test suites obtained via injective instantiation (which range 1169 average 32), obtained via full instantiation (which range1 3, 919 average 702). Furthermore, rule rewriting contains6 atoms, therefore ABox test suite also contains 6 assertions.case GALEN, used following sample queries, REQUIEMcompute UCQ rewriting:Q1Q2Q3Q4::::HaemoglobinConcentrationProcedure(x) Q(x)PlateletCountProcedure(x) Q(x)LymphocyteCountProcedure(x) Q(x)HollowStructure(x) Q(x)instantiated UCQ rewriting fully injectively. times needed compute test suites size test suite shown Table 4.shown table, simple test suites GALEN computed times ranging1.7 67 seconds average 33 seconds. Thus, computing test suitesGALEN time consuming LUBM. unsurprising since TBoxGALEN significantly complex LUBM. number ABoxestest suites ranged 25 151 case injective instantiations 7912, 000 case full instantiations; again, note significant dierencesizes two kinds test suites. cases, however, individual ABoxsmall, largest one containing 11 assertions.5.1.2 Non-Simple Test Suitesalso computed non-simple test suites cases UCQ rewriting exists.already mentioned, LUBM queries UCQ-rewritable. Therefore, manually addedfollowing query, REQUIEM computes recursive datalog rewriting.468fiCompleteness Guarantees Incomplete Ontology ReasonersTime (s)CfTLUBMQ151.422Q55.241GALENQ6 Q71.3 2.72331Q81.612Table 5: General test suites computed datalog rewritings LUBM GALEN.SystemCompleteness Guarantee Completeness w.r.t. LUBM data setJenaMax/DLE-JenaQ1 Q14Q1 Q14OWLimQ1 Q5 , Q7 , Q9 , Q11 Q14Q1 Q14Jena Mini/MicroQ1 Q5 , Q7 , Q9 , Q11 Q14Q1 Q14MinervaQ1 Q4 , Q9 , Q14Q1 Q14SesameQ1 , Q3 , Q11 , Q14Q1 Q5 , Q11 , Q14Table 6: Completeness guarantees UCQ-rewritable queries LUBMQ15 :Organization(x) Q(x)Due complex structure GALEN TBox, test queries UCQ rewritableeasily identified. evaluated following four.Q5Q6Q7Q8::::WestergrenESRProcedure(x) Q(x)ArthroscopicProcedure(x) Q(x)TrueCavity(x) Q(x)BacterialCellWall(x) Q(x)Times needed compute test suites size test suite shown Table 5.5.2 Completeness Guaranteesalready discussed, existing concrete reasoners captured strongly (Q, )-faithfulabstract reasoners. Hence, order establish completeness guarantees concretereasoners, restricted tests test suites computed using injective instantiations.5.2.1 Results Simple Test Suitesresults original queries LUBM benchmark shown Table 6.concrete reasoner, first column table shows queriesable prove completeness using techniques (i.e., queries completearbitrary data set), second column table shows queriesconcrete reasoner computes answers canonical LUBM data set one university.results clearly show completeness w.r.t. data set LUBM benchmarkguarantee completeness arbitrary data sets; example, OWLim, Minerva,Jena Mini/Micro complete queries w.r.t. LUBM data set (andsystems even complete expressive UOBM benchmark); however, certainqueries, systems found incomplete data set test suites.Jena Max DLE-Jena systems guaranteed complete14 LUBM queries regardless data setthat is, systems behave exactly likecomplete OWL reasoner LUBM queries LUBM TBox. According Jenas469fiCuenca Grau, Motik, Stoilos & Horrocksdocumentation, Jena Max supports types axioms used LUBM TBox, henceexpected complete LUBM TBox queries. Interestingly, testedLUBM data sets, Jena Max could compute answers manyqueries, used smaller LUBM data sets instead. demonstrates additionaladvantage approach: require reasoning w.r.t. large data sets, sinceABoxes test suites typically contain small number assertions. Regarding DLEJena, according technical description (Meditskos & Bassiliades, 2008), systemuses complete DL reasoner materialise certain subsumptions preprocessing stepuses Jena saturate ABox, much like abstract reasoner classifyExample 3.3. Hence, DLE-Jena least complete Jena Mini and, addition,able draw inferences Jena Mini missing (see below).OWLim complete LUBM queries involve reasoning existentialquantifiers consequent implications. well known latter supportedsystem. Jena Mini Micro exhibited exactly behaviour OWLim,despite fact Jena Mini handle larger fragment OWL OWLim. Clearly,LUBM TBox queries suciently complex reveal dierencesOWLim, Jena Mini/Micro.Minerva guaranteed complete six queries. Like DLE-Jena, usesDL reasoner materialise entailed subsumptions atomic concepts, usescustom method saturating ABox. investigating several ABoxes testsuites concluded Minerva cannot correctly handle (at-least) inverse role axioms;example, cannot find entailment { R R , R(a, b) } |= R(b, a).Finally, Sesame complete four queries. unsurprising since SesameRDFS reasoner thus complete small fragment OWL 2 DL.next discuss results tests based GALEN ontology test queriesQ1 Q4 . could run Jena Max since GALEN heavily uses existential restrictions,(according Jenas documentation) might cause problems. Minervasystem provided completeness guarantee least one query (Q4 );Minerva precomputes subsumption relationships atomic concepts dependexistential restrictions right hand side TBox axioms, systemshandle. Also, unlike LUBM, version GALEN used containinverse roles, Minerva performed much better ontology. systemsidentified incomplete test queries.5.2.2 Results Non-Simple Test SuitesResults test queries UCQ-rewritable summarised Table 7. Symbolindicates concrete reasoner found complete given query. Furthermore, whenever concrete reasoner failed test suite, tried prove reasonerincomplete discussed examples Section 3.7.2; cases successful,symbol indicates concrete reasoner identified incompletegiven query. Finally, symbol indicates concrete reasoner ran memory.case LUBM, able establish completeness guarantees w.r.t. queryQ15 OWLim, Jena Micro, DLE-Jena, Jena Max. Note systemshandle recursive TBox statements, completeness Q15 surprising. RDFS,470fiCompleteness Guarantees Incomplete Ontology ReasonersOWLimJena MaxJena MicroDLE-JenaMinervaSesameLUBMQ15Q5GALENQ6 Q7Q8Table 7: Completeness guarantees datalog-rewritable queriesCsQ,TQ1 Q2 Q3 Q4 Q5 Q6 Q7 Q8 Q9 Q10 Q11 Q12 Q13 Q14Time 1.4 1.1 0.2 1.8 0.8 1.2 9.5 7.8 - 0.9 0.05 0.5 0.6 0.04R1 24 17 130 136 219 925 777 - 219 274 185 1Table 8: Representative sets ABoxes LUBM. Times given seconds.however, cannot express recursive TBox statements involving roles, Sesamean RDFSreasonerfails compute certain answers tests.case GALEN, completeness guaranteed query Q8 OWLim, Jena Micro,DLE-Jena, Minerva, additionally query Q6 Minerva. already mentioned,answers queries GALEN depend positive occurrences existential restrictionsaxioms, systems cannot handle. could run Jena Max GALEN.5.3 Comparing Incomplete Concrete Reasonersalso implemented techniques comparing reasoners Section 4.3. end,modified REQUIEM compute subset-closed rewritings, injectivelyinstantiated obtain (Q, )-representative sets ABoxes R.5.3.1 Tests LUBMshown Table 8, representative sets ABoxes could computed secondsLUBM queries. exception Q9 , REQUIEM terminatedisabling rule subsumption optimisations. size representative sets ranged1 777 ABoxes. expected, representative sets contain ABoxesexhaustive test suites query TBox (see Table 3).combinations system query tests Section 5.2 identifiedsystem incomplete shown Table 9. table shows proportion certainanswers system returned applied LUBM data set, ABoxes R,ABoxes test suite used Section 5.2 check systems completeness.shown table, OWLim Jena Micro exhibited behaviouralmost complete. contrast, Sesame least complete queries. Furthermore,please note dierence values obtained R S; particular,Sesame compute certain answer Q5 S, whereas system ablecompute certain answers Q5 ABoxes (e.g., LUBM data set).ABoxes cannot distinguish Sesame trivial reasoner alwaysreturns empty set answers; however, set R make distinction.471fiCuenca Grau, Motik, Stoilos & HorrocksLUBMRQ510.250.8Q610.860.86LUBMRQ210.750.75Q410.680.06MinervaQ8Q10Q121110.98 0.86 0.250.81 0.84 0.92SesameQ5Q6Q7Q810.83 0.87 0.8300.003 0.04 0.040.36 0.033 0.01 0.004Q710.860.86Q1310.20.23OWLim & JMicroQ6Q8Q101110.990.980.990.960.980.97Q90.640-Q100.830.0010.028Q1200.250.017Q1300.20.23Table 9: Reasoner comparison LUBMCsQ,TTimeRQ115140Q246266Q370266Q42127Table 10: Representative sets ABoxes GALEN5.3.2 Tests GALENshown Table 10, representative sets ABoxes GALEN could computedtimes ranging 2 70 seconds, set contains small number ABoxes.system query, Table 11 shows proportion certain answers returnedsystem R test suite Section 5.2. Minerva completesystem. Jena Micro better DLE-Jena (apart query Q4 ), DLE-JenaOWLim behaved almost way (again apart query Q4 ). expected,Sesame least complete system.discrepancies OWLim, Jena Micro, DLE-Jena Minerva rathersurprising. OWLim Jena theoretically support features OWL; furthermore,DLE-Jena extension Jena (Meditskos & Bassiliades, 2008) DLE-Jenaleast complete Jena, case LUBM. order explain discrepancies,analysed test suites queries Q1 Q4 . precisely, selected ABoxesOWLim fails return certain answers Jena Micro complete,identified minimal set TBox axioms entail certain answers. analysisrevealed that, query Q4 , OWLim fails find entailment{Device(a), HollowTopology(b), hasTopology(a, b)} |= HollowStructure(a),follows following GALEN axioms:HollowTopology Topology hasState.HollowDevice SolidStructureHollowStructure SolidStructure hasTopology.(Topology hasState.Hollow)Although existential restrictions appear several axioms, observe reasoningexistential variables actually required, first third axioms imply (by simplestructural transformation) following axiom:SolidStructure hasTopology.HollowTopology HollowStructure472fiCompleteness Guarantees Incomplete Ontology ReasonersSesameOWLimDLE-JenaJMicroMinervaQ1R0.01 0.180.54 0.650.54 0.650.69 0.820.84 0.91Q2R0 0.160.52 0.630.52 0.630.68 0.810.84 0.90Q3R0 0.160.52 0.630.52 0.630.68 0.810.84 0.90Q4R0.04 0.100.52 0.480.76 0.90.76 0.6711Table 11: Reasoner comparison GALENaxiom entails required answer, systems deal axioms form;however, unlike Jena Micro, OWLim appears incapable dealing cases.Regarding DLE-Jena, according technical description (Meditskos & Bassiliades,2008), system replaced several inference rules Jena queries DL reasoner, strictly extend Jena. investigation exhaustive test suitequery Q4 revealed DLE-Jena returns many answers based existentialrestrictions right hand side TBox axioms Jena misses; however, investigation also revealed DLE-Jena misses several inferences Jenas TBox reasonercapture, probably due replacement Jenas inference rules. alsoexplains DLE-Jena performs worse Minerva GALEN.results clearly show behaviour systems greatly depends givenapplication scenario. example, DLE-Jena complete LUBM queries,perform equally well GALEN. contrast, Minerva perform wellLUBM, complete system GALEN. results thus allow applicationdevelopers conduct thorough comparison reasoning systems given application.6. Conclusionpaper proposed theoretical framework practical techniques establishing formally provable algorithmically verifiable completeness guarantees incomplete ontology reasoners. approach radically departs ad hoc evaluation basedwell-known benchmarks, provides solid foundation striking balancescalability completeness practical applications.approach also opens numerous exciting possibilities future research.example, work opens door design ontology-based information systemsoptimised class ontologies, queries, data relevant particular application. information systems could maximise scalability reasoning still ensuringcompleteness query answers, even rich ontologies sophisticated queries.Acknowledgmentsextended version paper Incomplete Semantic Web Reasoner?Giorgos Stoilos, Bernardo Cuenca Grau, Ian Horrocks published AAAI 2010paper Completeness Guarantees Incomplete Reasoners authorspublished ISWC 2010.473fiCuenca Grau, Motik, Stoilos & Horrocksresearch supported EU project SEALS (FP7-ICT-238975),EPSRC projects ExODA (EP/H051511/1) HermiT (EP/F065841/1). B. CuencaGrau supported Royal Society University Research Fellowship.ReferencesAcciarri, A., Calvanese, D., De Giacomo, G., Lembo, D., Lenzerini, M., Palmieri, M., &Rosati, R. (2005). Quonto: Querying ontologies. Proceedings 20th NationalConference Artificial Intelligence (AAAI-05)., pp. 16701671. AAAI Press /MIT Press.Artale, A., Calvanese, D., Kontchakov, R., & Zakharyaschev, M. (2009). DL-Lite familyrelations. J. Artificial Intelligence Research (JAIR), 36, 169.Baader, F., McGuinness, D., Nardi, D., & Patel-Schneider, P. (2002). Description LogicHandbook: Theory, implementation applications. Cambridge University Press.Baader, F., Brandt, S., & Lutz, C. (2005). Pushing EL envelope. Proceedings19th International Joint Conference AI (IJCAI-05), pp. 364369. MorganKaufmann Publishers.Bishop, B., Kiryakov, A., Ognyano, D., Peikov, I., Tashev, Z., & Velkov, R. (2011).OWLIM: family scalable semantic repositories. Semantic Web, 2 (1), 3342.Broekstra, J., Kampman, A., & van Harmelen, F. (2002). Sesame: generic architecturestoring querying RDF RDF Schema. Proceedings 1st InternationalSemantic Web Conference (ISWC 2002), pp. 5468.Cal, A., Gottlob, G., Lukasiewicz, T., Marnette, B., & Pieris, A. (2010). Datalog+/-:family logical knowledge representation query languages new applications.Proc. 25th Annual IEEE Symposium Logic Computer Science (LICS),pp. 228242.Calvanese, D., De Giacomo, G., Lembo, D., Lenzerini, M., & Rosati, R. (2007). Tractablereasoning ecient query answering description logics: DL-Lite family.Journal Automated Reasoning, 39 (3), 385429.Ceri, S., Gottlob, G., & Tanca, L. (1989). always wanted know datalog(and never dared ask). IEEE Trans. Knowledge Data Engineering, 1 (1), 146166.Cuenca Grau, B., Horrocks, I., Kazakov, Y., & Sattler, U. (2008a). Modular ReuseOntologies: Theory Practice. Journal Artificial Intelligence Research, 31, 273318.Cuenca Grau, B., Horrocks, I., Motik, B., Parsia, B., Patel-Schneider, P., & Sattler, U.(2008b). OWL 2: next step OWL. Journal Web Semantics (JWS), 6 (4),309322.Derriere, S., Richard, A., & Preite-Martinez, A. (2006). Ontology AstronomicalObject Types Virtual Observatory. Proc. 26th meeting IAU:Virtual Observatory Action: New Science, New Technology, Next GenerationFacilities, pp. 1718, Prague, Czech Republic.474fiCompleteness Guarantees Incomplete Ontology ReasonersErling, O., & Mikhailov, I. (2009). RDF support virtuoso DBMS. Pellegrini, T.,Auer, S., Tochtermann, K., & Schaert, S. (Eds.), Networked Knowledge - NetworkedMedia, pp. 724. Springer Berlin / Heidelberg.Fitting, M. (1996). First-Order Logic Automated Theorem Proving, 2nd Edition. TextsComputer Science. Springer.Glimm, B., Horrocks, I., Lutz, C., & Sattler, U. (2007). Conjunctive query answeringdescription logic SHIQ. Proceedings International Joint ConferenceAI (IJCAI), pp. 399404.Golbreich, C., Zhang, S., & Bodenreider, O. (2006). Foundational Model AnatomyOWL: Experience Perspectives. Journal Web Semantics, 4 (3), 181195.Goodwin, J. (2005). Experiences using OWL Ordnance Survey. Proc.OWL: Experiences Directions Workshop (OWLED 2005), Galway, Ireland.Guo, Y., Pan, Z., & Heflin, J. (2005). LUBM: Benchmark OWL Knowledge BaseSystems. Journal Web Semantics, 3 (2), 158182.Haarslev, V., & Moller, R. (2001). RACER System Description. Gore, R., Leitsch, A., &Nipkow, T. (Eds.), Proc. 1st Int. Joint Conf. Automated Reasoning (IJCAR2001), Vol. 2083 LNAI, pp. 701706, Siena, Italy. Springer.Hayes, P. (2004). RDF Semantics. World Wide Web Consortium (W3C) Recommendation.Horrocks, I., Patel-Schneider, P. F., & van Harmelen, F. (2003). SHIQ RDFOWL: making web ontology language. Journal Web Semantics, 1 (1), 726.Kiryakov, A., Ognyanov, D., & Manov, D. (2005). Owlim-a pragmatic semantic repositoryowl.. Dean, M., Guo, Y., Jun, W., Kaschek, R., Krishnaswamy, S., Pan, Z., &Sheng, Q. Z. (Eds.), WISE Workshops, pp. 182192.Lacy, L., Aviles, G., Fraser, K., Gerber, W., Mulvehill, A., & Gaskill, R. (2005). ExperiencesUsing OWL Military Applications. Proc. OWL: Experiences DirectionsWorkshop (OWLED 2005), Galway, Ireland.Lutz, C., Toman, D., & Wolter, F. (2009). Conjunctive query answering descriptionlogic EL using relational database system. Proceedings 21st InternationalJoint Conference AI (IJCAI), pp. 20702075.Ma, L., Yang, Y., Qiu, Z., Xie, G. T., Pan, Y., & Liu, S. (2006). Towards complete OWLontology benchmark. Proceedings 3rd European Semantic Web Conference(ESWC 2006), pp. 125139.McBride, Brian (2001). Jena: Implementing RDF Model Syntax Specification.International Workshop Semantic Web 2001.Meditskos, G., & Bassiliades, N. (2008). Combining DL reasoner rule engineimproving entailment-based OWL reasoning. Proceedings 7th InternationalSemantic Web Conference (ISWC 2008), pp. 277292.Motik, B., Cuenca Grau, B., Horrocks, I., Wu, Z., Fokoue, A., & Lutz, C. (2009a). OWL 2Web Ontology Language Profiles. W3C Recommendation.475fiCuenca Grau, Motik, Stoilos & HorrocksMotik, B., Shearer, R., & Horrocks, I. (2009b). Hypertableau Reasoning DescriptionLogics. J. Artificial Intelligence Research (JAIR), 173 (14), 12751309.Ortiz, M., Calvanese, D., & Eiter, T. (2008). Data complexity query answering expressive description logics via tableaux. Journal Automated Reasoning, 41 (1), 6198.Perez-Urbina, H., Horrocks, I., & Motik, B. (2009). Ecient Query Answering OWL 2.Proceedings 8th International Semantic Web Conference (ISWC 2009), Vol.5823 LNCS, pp. 489504. Springer.Perez-Urbina, H., Motik, B., & Horrocks, I. (2010). Tractable query answering rewritingdescription logic constraints. Journal Applied Logic, 8 (2), 186209.Prudhommeaux, E., & Seaborne, A. (2008). SPARQL query language RDF. WorldWide Web Consortium (W3C). W3C Recommendation.Rector, A. L., & Rogers, J. (2006). Ontological practical issues using descriptionlogic represent medical concept systems: Experience galen. Barahona,P., Bry, F., Franconi, E., Henze, N., & Sattler, U. (Eds.), Reasoning Web, SecondInternational Summer School 2006, pp. 197231.Sidhu, A., Dillon, T., Chang, E., & Sidhu, B. S. (2005). Protein Ontology Developmentusing OWL. Proc. OWL: Experiences Directions Workshop (OWLED2005), Galway, Ireland.Sirin, E., Parsia, B., Cuenca Grau, B., Kalyanpur, A., & Katz, Y. (2007). Pellet: practicalOWL-DL reasoner. Journal Web Semantics, 5 (2), 5153.Soergel, D., Lauser, B., Liang, A., Fisseha, F., Keizer, J., & Katz, S. (2004). ReengineeringThesauri New Applications: AGROVOC Example. J. Digital Information,4 (4).Wu, Z., Eadon, G., Das, S., Chong, E. I., Kolovski, V., Annamalai, M., & Srinivasan, J.(2008). Implementing inference engine rdfs/owl constructs user-definedrules oracle. Proceedings 2008 IEEE 24th International ConferenceData Engineering (ICDE 08), pp. 12391248. IEEE Computer Society.476fiJournal Artificial Intelligence Research 43 (2012) 293-328Submitted 07/11; published 03/12SAS+ Planning SatisfiabilityRuoyun HuangYixin ChenWeixiong ZhangRUOYUN . HUANG @ WUSTL . EDUCHEN @ CSE . WUSTL . EDUWEIXIONG . ZHANG @ WUSTL . EDUDepartment Computer Science EngineeringWashington University St. LouisSaint Louis, Missouri, 63130, USAAbstractPlanning satisfiability principal approach planning many eminent advantages.existing planning satisfiability techniques usually use encodings compiled STRIPS.introduce novel SAT encoding scheme (SASE) based SAS+ formalism. newscheme exploits structural information SAS+, resulting encodingcompact efficient planning. prove correctness new encoding establishingisomorphism solution plans SASE STRIPS based encodings.analyze transition variables newly introduced SASE explain accommodatesmodern SAT solving algorithms improves performance. give empirical statistical resultssupport analysis. also develop number techniques reduce encoding sizeSASE, conduct experimental studies show strength individual technique. Finally,report extensive experimental results demonstrate significant improvements SASEstate-of-the-art STRIPS based encoding schemes terms time memory efficiency.1. IntroductionPlanning satisfiability (SAT) one main paradigms planning. Methods usingtechnique usually compile planning problem sequence SAT instances, increasingtime horizons (Kautz & Selman, 1999). Planning satisfiability number distinct characteristics make efficient widely applicable. makes use extensive advancementfast SAT solvers. SAT formulae extended accommodate variety complex problems, planning uncertainty (Castellini, Giunchiglia, & Tacchella, 2003), numericalplanning (Hoffmann, Kautz, Gomes, & Selman, 2007) temporally expressive planning (Huang,Chen, & Zhang, 2009).key factor performance planning satisfiability approaches SAT encodingscheme, way planning problem compiled SAT formulae boolean variablesclauses. encoding scheme great impact efficiency SAT-based planning,developing novel superior SAT encodings active research topic. Extensive researchdone make SAT encoding compact. One example compact encodinglifted action representation (Kautz & Selman, 1996; Ernst, Millstein, & Weld, 1997).compact encoding scheme, action represented conjunction parameters. result,method mitigates issue blowing encoding size. original scheme guaranteeoptimality makespans. However, improved lifted action representation preservesoptimality proposed (Robinson, Gretton, Pham, & Sattar, 2009). new encoding proposedc2012AI Access Foundation. rights reserved.fiH UANG , C HEN , & Z HANGbased relaxed parallelism semantic (Rintanen, Heljanko, & Niemel, 2006), alsoguarantee optimality.previous enhancements based conventional STRIPS formalism planning.Recently, SAS+ formalism (Bckstrm & Nebel, 1996) attracted lot attentionrich structural information. SAS+ formalism represents planning problem using multi-valuedstate variables instead propositional facts STRIPS (Bckstrm & Nebel, 1996). SAS+formalism used derive heuristics (Helmert, 2006; Helmert, Haslum, & Hoffmann, 2008),landmarks (Richter, Helmert, & Westphal, 2008), new search models (Chen, Huang, & Zhang,2008), strong mutual exclusion constraints (Chen, Huang, Xing, & Zhang, 2009).paper, proposed first SAS+ based SAT encoding scheme (SASE) classicalplanning. Unlike previous STRIPS based SAT encoding schemes model actions facts,SASE directly models transitions SAS+ formalism. Transitions viewed highlevel abstraction actions, typically significantly fewer transitions actionsplanning task. proposed SASE scheme describes two major classes constraints: firstconstraints transitions second constraints match actions transitions.theoretically empirically studied new SAS+ based SAT encoding comparedtraditional STRIPS based SAT encoding. improve performance SASE,proposed number techniques reduce encoding size recognizing certain structures actionstransitions.studied relationship solution space SASE STRIPS basedencoding. results showed solution plans found SATPlan06, representative STRIPSbased encoding, SASE isomorphic, meaning bijective mappingtwo. Hence, showed equivalence solving STRIPS based encoding SASE.attempt understand performance gain SASE, studied new encodingscheme makes SAT solving algorithm behave favorable way. study quantifiedwidely used VSIDS heuristic (Moskewicz, Madigan, Zhao, Zhang, & Malik, 2001).transition variables introduced higher frequencies clauses, consequentlyhigher VSIDS scores. higher VSIDS scores lead branching transition variablesaction variables. Since transition variables high scores hence stronger constraintpropagation, branching transition variables leads faster SAT solving. providedempirical evidence support explanation. Moreover, introduced indicator calledtransition index, empirically showed strong correlation transitionindex SAT solving speedup.Finally, evaluated SASE standard benchmarks recent International PlanningCompetitions. results show new SASE encoding scheme efficient termstime memory usage compared STRIPS-based encodings, solves large instancesstate-of-the-art STRIPS-based SAT planners fail solve.paper organized follows. giving basic definitions Section 2, presentSAS+ based SASE encoding Section 3 prove equivalence STRIPS based encoding Section 4. study SASE works better modern SAT solvers Section 5.techniques reduce encoding size presented Section 6. present experimental results Section 7. Finally, review related works conclude Section 8.294fiSAS+ P LANNING ATISFIABILITY2. Backgroundsection, first briefly introduce STRIPS formalism review representative STRIPSbased SAT encoding. Then, define SAS+ formalism, develop new SATencoding scheme.2.1 STRIPS Formalismtraditional STRIPS planning representation defined binary-valued propositional facts.STRIPS planning problem tuple = (F, A, , G ), where:F set propositional facts;set actions. action triple = (pre(a), add(a), del(a)), pre(a)F set preconditions, add(a) F del(a) F sets add factsdelete facts, respectively;state F subset facts assumed true. fact assumed falsestate. F initial state, G F specification goal state goalstates.define three sets actions. use ADD(f ) denote set actions f oneadd effects, meaning ADD(f ) = {a | f add(a)}. Similarly, two action setsDEL(f ) = {a | f del(a)} PRE(f ) = {a | f pre(a)}.action applicable state pre(a) . use apply(, a) denote stateapplying applicable action , variable assignments changed ( \del(a)) add(a). also write apply(s, P ) denote state applying set actions Pparallel, P A, s. set actions P applicable , 1) P applicable, 2) exist two actions a1 , a2 P a1 a2 mutually exclusive(mutex) (Blum & Furst, 1997). Two actions b mutex time step onefollowing three conditions holds:Inconsistent effects: del(a) add(b) 6= del(b) add(a) 6= .Interference: del(a) pre(b) 6= del(b) pre(a) 6= .Competing needs: exist f1 pre(a) f2 pre(b), f1 f2 mutextime step 1.Two facts f1 f2 mutex time step if, actions b f1 add(a), f2add(b), b mutex previous time step. call mutex defined planning graphsP-mutex, order distinguish mutex another notion mutex next section.Definition 1 (Parallel solution plan). STRIPS planning problem = (F, A, , G ),parallel solution plan sequence P = {P1 , P2 , . . . , PN }, Pt A, = 1, 2, . . . , N ,set actions executed time step t,G apply(. . . apply(apply(I , P1 ), P2 ) . . . PN ).295fiH UANG , C HEN , & Z HANG2.2 STRIPS Based SAT Encoding (PE)SAT instance tuple (V, C), V set variables C set clauses. GivenSAT instance (V, C), assignment sets every variable v V true false, denoted (v) =(v) =. assignment makes every clause C true, solution (V, C).encoding scheme SatPlan06 (Kautz, Selman, & Hoffmann, 2006) (denoted PEfollowing), compiled planning graphs, well known extensively testedSTRIPS based encoding. facilitate encoding, SatPlan06 introduces dummy action dumff precondition add-effect. use A+ denote set actionsdummy actions added, {dumf | f F}. Unless otherwise indicated, action setADD(f ), DEL(f ), PRE(f ) include corresponding dummy actions.denote SatPlan06 encoding time step N PE(, N ), given STRIPS task= (F, A, , G ). SAT instance, PE(, N ) defined (V, C), V = {Wf,t |fF, [1, N + 1]} {Wa,t |a A+ , [1, N ]}. Wf,t = indicates f true t, otherwiseWf,t =. clause set C includes following types clauses:I. Initial state: (f, f ): Wf,1 ;II. Goal state: (f, f G ): Wf,N +1 ;III. Add effect: (f F, [1, N ]): Wf,t+1Wa,f add(a) Wa,t ;IV. Precondition: (a A+ , f pre(a), [1, N ])): Wa,t Wf,t ;V. Mutex actions: (a, b A+ , [1, N ], b mutex): W a,t W b,t ;VI. Mutex facts: (f, g F, [1, N + 1], f g mutex) : W f,t W g,t ;Clauses class II enforce initial state true first time step,goal facts need true last time step, respectively. Clauses class III specify factf true time step t, least one action A+ time step 1 fadd effect. Clauses class IV specify action true time t, preconditionstrue time t. Classes V VI specify mutex actions facts, respectively.PE one typical SAT encoding schemes STRIPS planning. actionvariables fact variables, enforces semantics one defined planning graph.Later show equivalence new SASE encoding PE.2.3 SAS+ FormalismSAS+ formalism (Bckstrm & Nebel, 1996) represents classical planning problem setmulti-valued state variables. planning task SAS+ formalism defined tuple= {X , O, sI , sG },X = {x1 , , xN } set state variables, associated finite domain Dom(xi );set actions action tuple (pre(a), eff(a)), pre(a)eff(a) sets partial state variable assignments form xi = v, v Dom(xi );state full assignment (a set assignments assigns value every state variable).assignment (x = f ) s, write s(x) = f . denote set states.296fiSAS+ P LANNING ATISFIABILITYsI initial state, sG partial assignment state variables definegoal. state goal state sG s.first define transition is. paper, build constraints recognizing transitions atomic elements state transitions. Actions, cast constraints well case, actanother layer logic flow transitions.Definition 2 (Transition). SAS+ planning task = {X , O, sI , sG }, given state variablex X , transition re-assignment x value f g, f, g Dom(x), written fxg ,xunknown value g, written g. may also simplify notation fxg f g, confusion.Transitions SAS+ planning task classified three categories.Transitions form fxg called regular. regular transition fxg applicablestate s, iff s(x) = f . Let = apply(s, fxg ) state applying transition states, (x) = g.Transitions form fxf called prevailing. prevailing transition fxf applicablestate iff s(x) = f , apply(s, fxf ) = s.xxcalled mechanical. mechanical transition gTransitions form gxapplied arbitrary state s, result apply(s, g ) state (x) = g.transition applicable state three cases. action a, denotetransition set rans(a), includes: regular transitions fxg (x = f )pre(a) (x = g) eff(a), prevailing transitions fxf (x = f ) pre(a),xmechanical transitions g(x = g) eff(a). Given transition , use A() denoteset actions rans(a). call A() supporting action set .x}, f, g Dom(x),state variable x, introduce (x) = {fxg }{fxf }{gset transitions affect x. also define union (x), x X .set transitions. also use R(x) = {fxf | f, f Dom(x)} denote setprevailing transitions related x, R union R(x) x X .Definition 3 (Transition Mutex). SAS+ planning task, two different transitions 1 2mutually exclusive iff exists state variable x X 1 , 2 (x), onefollowing holds:1. Neither 1 2 mechanical transition.2. least one 1 2 mechanical transition, 1 2 transit different values.set transitions applicable state 1) every transition applicables, 2) exist two transitions 1 , 2 1 2 mutually exclusive.applicable s, write apply(s, ) denote state applying transitionsarbitrary order.297fiH UANG , C HEN , & Z HANGDefinition 4 (Transition Plan). transition plan sequence {T1 , T2 , . . . , TN },Tt , [1, N ], set transitions executed time step t,sG apply(. . . apply(apply(sI , T1 ), T2 ) . . . TN ).SAS+ planning task, given state action a, variable assignmentspre(a) match assignments s, applicable state s. use apply(s, a) denote stateapplying s, variable assignments changed according eff(a).Definition 5 (S-Mutex). SAS+ planning task = {X , O, sI , sG }, two actions a1 , a2S-mutex iff either following holds:1. exists transition , prevailing ( 6 R), rans(a1 )rans(a2 ). Actions a1 a2 case deletes others precondition.2. exist two transitions mutually exclusiverans(a1 ) rans(a2 ).named mutex SAS+ planning S-mutex distinguish P-mutex definedSTRIPS planning. show Section 4 two types mutual exclusionsequivalent. Therefore, paper general use single term mutual exclusion (mutex)both, unless otherwise indicated.SAS+ planning task, write apply(s, P ) denote state applying setactions P , P O, s. set actions P applicable 1) P applicable s,2) two actions a1 , a2 P a1 a2 S-mutex.Definition 6 (Action Plan). SAS+ task, action plan sequence P = {P1 , . . . , PN },Pt , [1, N ], set actions executed time stepsG apply(. . . apply(apply(sI , P1 ), P2 ) . . . PN ).definition action plan SAS+ planning essentially STRIPSplanning (Definition 1). relation transition plan action plan key newencoding scheme introduced paper. always exists unique transition plan validaction plan. contrast, given transition plan, may corresponding action plan;could multiple corresponding action plans.Definition 7 (Step Optimal Plan). SAS+ planning task, step optimal plan actionplan P = {P1 , . . . , PN } minimum N .worth noting different optimization metrics classical planning research, including step optimality (Definition 7), number actions total action cost.criteria used recent IPC competitions (The 6th Intl Planning Competition, 2008; 7th IntlPlanning Competition, 2011) total action cost. step optimality widely used criterion, action cost realistic criterion many domains involving numericalresources. Nevertheless, action cost assumes plans sequential. words,consider concurrency actions, limitation many cases.298fiSAS+ P LANNING ATISFIABILITYstep optimality introduced GraphPlan (Blum & Furst, 1997), becamepopular planning graph analysis used several planning systems (Kautz & Selman,1999; Hoffmann & Nebel, 2001; & Kambhampati, 2000). Step optimality takes concurrencyactions consideration, although assumes unit duration actions.planning methods step optimality, particular SAT-based planners, potentially madeuseful optimization metrics, topic future work.3. SAS+ Based SAT Encoding (SASE)introduce new encoding SAS+ planning tasks, denoted SASE. usesearch framework SatPlan: start small number time steps N increase N onestep satisfiable solution found. given N , encode planning taskSAT instance solved SAT solver. SASE instance includes two types binaryvariables:1. Transition variables: U,t , [1, N ], may also written Ux,f,g,texplicitly fxg ;2. Action variables: Ua,t , [1, N ].constraints, SASE eight classes clauses SAS+ planning task. following,define class every time step [1, N ] unless otherwise indicated.A. Initial state: x, sI (x) = f ,B. Goal: x, sG (x) = g,WWf g (x) Ux,f,g,1 ;f g (x) Ux,f,g,N ;xC. Progression: hf[1, N 1], Ux,h,f,tD. Regression: fxg [2, N ], Ux,f,g,tWWfxg (x) Ux,f,g,t+1 ;fx f (x) Ux,f ,f,t1 ;E. Transition mutex: 1 2 1 2 transition mutex, U 1 ,t U 2 ,t ;VF. Composition actions: O, Ua,t rans(a) U,t ;WG. Action existence: \ R, U,t a,T rans(a) Ua,t ;H. Action mutex: a1 a2 , (a1 ) (a2 ) 6 R, U a1 ,t U a2 ,t ;Clauses classes C specify restrict transitions change time steps. Clausesclass E enforce one related transition true state variable timestep. Clauses classes F G together encode actions composed match transitions.Clauses class H enforce mutual exclusions actions.Note essential differences transition variables SASE fact variablesPE. terms semantics, transition variable time step n SASE equivalentconjunction two fact variables PE, time step n n + 1, respectively. Nevertheless,fact variables able enforce transition plan transition variables do.299fiH UANG , C HEN , & Z HANGtransition variables imply values multi-valued variables, also enforcevalues propagate time steps.addition, transition variables different action variables regarding roles SATsolving. SASE, action variables exist constraints transition-actionmatching, constraints time steps. Transition variables exist both. Thustransition variables appear frequently SAT instance. inclusion high-frequencyvariables help SAT solvers VSIDS rule variable branching. shall discussissue provide empirical study, Section 5.show SASE works using example. Consider planning task two multivalued variables x y, Dom(x) = {f, g, h} Dom(y) = {d, e}. threexactions a1 = {fxg , de}, a2 = {fxg , ed} a3 = {gh, ed}. initial state{x = f, = d} goal state {x = h, = d}. One solution instance plan twoactions: a1 time step 1 a3 time step 2.following list constraints transitions actions, namely specifiedclasses F G. clauses classes self-explanatory. particular, listvariables clauses time step 1, constraints repeat time step 2.transition variables time step 1 { Ux,f,g,1 , Ux,f,f,1 , Ux,g,h,1 , Ux,g,g,1 , Ux,h,h,1 , Uy,d,d,1 , Uy,e,e,1 ,Uy,e,d,1 , Uy,d,e,1 }, repeat time step 2. action variables time step 1 { Ua1,1 ,Ua2,1 , Ua3,1 }, repeat time step 2.clauses class F are: U a1,1 Ux,f,g,1 , U a1,1 Ux,d,e,1 , U a2,1 Ux,f,g,1 , U a2,1 Uy,e,d,1 ,U a3,1 Ux,g,h,1 U a3,1 Ux,e,d,1 . clauses class G U x,f,g,1 Ua1,1 Ua2,1 , U x,g,h,1Ua3,1 , U y,d,e,1 Ua1,1 , U y,e,d,1 Ua2,1 Ua3,1 .solution, terms actions, action variables Ua1,1 Ua3,2 , action variables . addition, corresponding transition plan following transition variables: {Ux,f,g,1 , Ux,g,h,2 , Uy,d,e,1 , Uy,e,d,2 }, transition variables false.mentioned above, although often multiple transition plans, transition plan maycorrespond valid action plan. particular example, several different transitionplans satisfy initial goal states, corresponding actionplan. example, suppose transition variables {Ux,f,g,1 , Ux,g,h,2 , Uy,d,d,1 , Uy,d,d,2 } true.qualifies transition plan, goals achieved. transition plan howeverlead valid action plan.4. Correctness SAS+ Based Encodingimportant prove correctness proposed encoding. achieve provingSASE SAS+ planning solution space PE used STRIPS planning.specifically, show that, given planning task given time step N , SAT instanceSASE satisfiable SAT instance PE satisfiable. Here, assumecorrectness PE encoding, SatPlan06 (Kautz et al., 2006) STRIPS planning.PE(, N ) denotes PE formula corresponds N-step planning problem. SASE(, N )gives formula case SASE encoding equivalent SAS+ problem.300fiSAS+ P LANNING ATISFIABILITY4.1 Solution Structure STRIPS Based Encodingsection, study properties solutions STRIPS based encoding. properties provide key insights establishing relationship PE SASE encodings.Lemma 1 Given STRIPS task = (F, A, , G ), time step N , PE SAT instancePE(, N ) = (V, C), suppose satisfiable solution denoted , fact f F,[1, N ] that: 1) (Wdumf ,t ) =, 2) (Wf,t ) = , 3) DEL(f ), (Wa,t ) =,construct alternative solution PE(, N ) follows:(v) =(, v = Wdumf ,t , v V(v), v 6= Wdumf ,t , v V(1)Proof proved showing satisfies every individual clause C. See Appendix details.Lemma 2 Given STRIPS task = (F, A, , G ), time step N , PE SAT instancePE(, N ) = (V, C), suppose satisfiable solution denoted , fact f F,[1, N ] that: 1) (Wf,t ) =, 2) exists action ADD(f ) (Wa,t1 ) = ,construct alternative solution PE(, N ) follows:(v) =(, v = Wf,t , v V(v), v 6= Wf,t , v V(2)Proof prove showing makes every individual clause (three types) Ctrue. See Appendix details.Lemmas 1 2 show certain conditions, dummy action variables factvariables PE free variables. set either true false SAT instanceremains satisfied. Although manipulate free variables construct alternative solution given solution , refer STRIPS plan,change action variable. leads important insight concerning solutions PE:solution plan STRIPS planning problem may correspond multiple solutions PE(, N ).Proposition 1 Given STRIPS task = (F, A, , G ), time step N , PE SAT instancePE(, N ) = (V, C), clauses define competing needs mutex fact mutex inferredclauses PE(, N ).mutexes implied PE formula, thus completeness resolution, Proposition 1 true. Proposition 1 implies encoding STRIPS task, necessary encodefact mutex competing needs action mutex, implied clauses. Therefore,considering completeness correctness PE, ignore redundant clauses.Analysis similar conclusion found literature (Sideris & Dimopoulos, 2010),although different approaches used.301fiH UANG , C HEN , & Z HANG4.2 Equivalence STRIPS SAS+ Based Encodingsclassical planning problem represented STRIPS SAS+ formalisms giverise set solutions. Given STRIPS task = (F, A, , G ) equivalent SAS+planning task = (X , O, sI , sG ), following isomorphisms (bijective mappings) exist:Qf : F X Dom(X) (a binary STRIPS fact corresponds variable assignmentSAS+);: (a STRIPS action corresponds SAS+ action);: sI (can derived f );g : G sG (can derived f ).Furthermore, since formalisms represent planning task, mappings preserverelations actions facts. example, f pre(a) f FSTRIPS formalism, f (f ) pre(a (a)) SAS+ formalism.First, show parallelism semantics enforced S-mutex SAS+ equivalentP-mutex STRIPS.Lemma 3 Given SAS+ planning task = (X , O, sI , sG ) equivalent STRIPS task =(F, A, , G ), suppose actions a, b O, equivalent actions , b (i.e.= (a ) b = (b )), b S-mutex iff b P-mutex.Proof prove showing directions given two actions one typemutex, also mutux type. Details Appendix A.Lemma 3 connects P-mutex S-mutex. Based construct relationsencodings, used proofs Theorems 1 2, respectively.Theorem 1 Given STRIPS task SAS+ task equivalent, time step boundN , PE(, N ) satisfiable, SASE(, N ) also satisfiable.Proof prove theorem construction. Suppose know solution PE, proveconstruct solution SASE accordingly. Details Appendix A.Theorem 2 Given STRIPS task SAS+ task equivalent, time step boundN , SASE(, N ) satisfiable, PE(, N ) also satisfiable.Proof proved using technique used Theorem 1. See Appendixdetails.Theorems 1 2, reach following conclusion.Theorem 3 classical planning problem solvable PE encoding solvable SASE encoding. Further, solvable problems, solution plans found twoencodings same, optimal makespan.Theorem 3 reveals planning solution found SASEfound PE. terms SAT solutions, proofs show epimorphism (a surjectivemapping) solutions PE solutions SASE. is, multiple SAT solutions302fiSAS+ P LANNING ATISFIABILITYPE map one SAT solution SASE every SAT solution SASE mapped least oneSAT solution PE. due existence free variables PE encoding. One solutionSASE corresponds group solutions PE assignments real action variablesdifferent assignments free variables.5. SAT Solving Efficiency Different EncodingsSection 4, showed PE SASE semantically equivalent solution space. section, study makes different regarding SAT solving efficiency.particular, want understand PE SASE make SAT solver behave differentlyplanning task. Modern SAT solvers, nowadays employ many sophisticatedtechniques, complicated characterized simple models. general, difficultaccurately estimate time SAT solver needs solve SAT instance. section,provide explanation SAT encodings SASE efficient SAT solverssolve SAT encodings PE, provide empirical evidence support explanation.section, first discuss SASEs problem structure Section 5.1 reasonwidely used SAT solving heuristic VSIDS (Moskewicz et al., 2001) works better SASE encodings. idea VSIDS select variables appear frequently originallearnt clauses, since lead stronger constraint propagation space pruning. ordervariables VSIDS scores, large population top-ranked transition variables introduced SASE higher VSIDS scores top-ranked action variables. result,top-ranked transition variables selected often provide stronger constraint propagation,speeding SAT solving.study significance transition variables, explain make search efficient. Section 5.2, present comparison transition variables versus action variables.Section 5.3, show often transition variables chosen decision variables,direct evidence transition variables significance.Finally, Section 5.4 empirically define significance index transition variables.index measures significance transition variables within context VSDIS heuristic,correlates speedup SAT solving. analysis section uses SatPlan06baseline.5.1 VSIDS Heuristic SAT SolvingSAT solvers use based Conflict Driven Clause Learning framework. decisionvariable refers one selected next variable branching. decision variablechosen, variables could fixed unit propagation. ordering decision variablessignificantly affects problem solving efficiency. existing complete SAT algorithms usevariants VSIDS heuristic (Moskewicz et al., 2001) variable ordering strategy.VSIDS heuristic essentially evaluates variable using Exponential Moving Average(EMA) number times (frequency) appears clauses. frequency valuekeeps changing learnt clauses. Therefore, VSIDS uses smoothing schemeperiodically scales scores variables constant order reflect importancerecent changes frequencies. variable occurs frequently usually higher value,thus also higher chance chosen decision variable. random decision madetie. Thus, variables associated recent conflict clauses higher priorities.303fiH UANG , C HEN , & Z HANGFigure 1: Illustration search spaces two encoding schemes differ other.first consider frequency original clauses only. investigate takingperiodic update consideration.Given fact frequency used main measurement, VSIDS effectivedifference variables frequencies large variables highfrequencies. variables frequency, picking decision variables purelyrandom. Further, variables high frequencies desirable since lead stronger constraintpropagation.major difference SAT instances PE SASE latter encoding,actions responsible constraint propagation across time steps. Figure 1 illustratesdifference. SASE, SAT instance conceptually reduced following search problemtwo hierarchies.top level, search transition plan defined Definition 4. amountsfinding set transitions time step (corresponding U,t set), satisfy clauses classes A-E SASE encoding.lower level, try find action plan satisfies transition plan.words, given transition plan satisfies clauses classes A-E, try find actionplan satisfying clauses classes F-H.5.2 Transition Variables versus Action VariablesLet us first formulate frequency variable measured. Given SAT instance (V, C),variable v V , define function h(v) indicate frequency v. is, h(v)number clauses v appears in. sort variables V h values descendingorder, study variables certain h value.Definition 8 (High h Value Variable Set). Given SAT instance (V, C), h {h(v) | vV }, denote V (h ) set variables v V h(v) h .define percentile top variable set quantify analysis. Instead specifich() value, use percentage h values make analysis comparable across instances.304fiSAS+ P LANNING ATISFIABILITYDefinition 9 (Percentile). Given SAT instance (V, C), percentile hp (0 p 100), hvalue variable v V , least p% variables v V h(v ) largerequal hp .Definition 10 (Top p Variable Set). Given SAT instance (V, C) percentile hp , callV (hp ) top p variable set, denoted V p .use Vo V denote action variables transition variables V , respectively.also define Vop = Vo V p , similarly Vp = V V p . Table 1 compares h values transitionvariables action variables SAT instances. table two parts. first part, listaverage standard deviation h values transition variables action variables.data collected first satisfiable SAT instance largest solvable planning taskevery domain consider. average h value, evident domainstransition variables occur frequently action variables. Furthermore, standard deviationtransition variables general larger action variables standard deviation,also even larger expected value transition variables. high frequencies transitionvariables, along large standard deviations, preferred VSIDS heuristic aidSAT solving, discussed earlier.second part lists average h values transition variables action variables,top p variable set different values p: 1%, 2%, 5% 10%. difference VopVp large. domains, transition variables dominate top variable sets, actionvariables exist top 10% variable set domains. One exception Airportdomain. However, even domain, although average h value transition variablessmaller average h value action variables, among top 1% variables, average h valuetransition variables larger average h value action variables. Since VSIDS picksvariable highest heuristic value, transition variables higher chances pickeddecision variables.5.3 Branching Frequency Transition VariablesSection 5.2, considered difference transition variables action variables,terms h values. mentioned earlier, however, VSIDS heuristic periodically updatesheuristic values variables. dynamic updating heuristic values capturedanalysis. following, present direct empirical evidence show transitionvariables indeed chosen frequently action variables branching, especially earlystages SAT solving. is, SAT solver spends time deciding appropriatetransition plan. analysis takes consideration VSIDSs dynamic updating strategy.empirically test probabilities transition variables action variables chosenbranching variables. measure every k consecutive decision variables, numbertransition variables (M ) action variables (Mo ) selected decision variables. variablesselected equally likely,E(M ) = k|V ||Vo |E(Mo ) = k,|V | + |Vo ||V | + |Vo |(3)implies:E(M )E(Mo )=k|V |k|Vo |305(4)fiH UANG , C HEN , & Z HANGInstancesNAirport-48Depot-14Driverlog-16Elevator-16Freecell-6Openstacks-2Parcprinter-20Pathways-17Pegsol-25Pipe-notankage-49Pipe-tankage-26Rovers-18Satellite-13Scanalyzer-28Sokoban-6Storage-13TPP-30Transport-17Trucks-13Woodworking-30Zenotravel-16681218151623192125121812135351811222447Vh8.67.610.56.032.3 11.122.27.442.6 58.014.15.212.0 11.85.58.523.0 15.522.9 47.158.1 116.715.5 14.631.87.8113.0 151.415.64.84.71.912.3 16.122.8 19.05.17.66.25.120.2 25.0Voh19.6 12.96.3 3.35.6 3.110.2 3.833.2 7.011.5 4.315.5 5.912.9 3.615.2 6.341.3 3.450.7 12.816.0 6.92.0 0.38.6 1.120.0 4.76.3 1.64.8 0.74.5 1.16.4 1.210.2 3.53.9 0.31%98.532.543.927.0115.617.244.333.630.077.1266.4175.135.0242.816.610.484.299.656.723.151.3h Vph Vop2% 5 % 10% 1% 2% 5 %75.5 59.2 23.4 39.6 35.9 34.728.6 23.7 20.934.6 26.5 23.418.9 18.9 18.986.0 49.0 34.717.2 16.2 15.242.8 26.7 17.8 30.0 30.0 30.026.9 15.9 14.529.8 17.2 15.557.5 36.4 25.3174.0 86.8 56.086.0 35.5 35.535.0 35.0 35.0175.8 129.7 129.714.1 12.8 11.210.49.08.157.8 34.4 24.658.1 52.0 41.638.2 20.8 16.322.1 18.9 17.251.3 36.2 28.5-10%32.430.010.09.013.1-Table 1: h values transition variables versus action variables domains. Column Noptimal makespan. Column h average Column standard deviation. Columnh Vp h Vop refer average h value transition variables action variablesV p , p equals 1, 2, 5 10. - means variable percentile range.empirically study divide SAT solving process epoches length k = 1000each, domains IPC-3 IPC-6. present results three representative domainsFigure 2, results domains Figures 9 10 Appendix B. domain,choose instance least 100,000 decisions. domains (e.g. Woodworking),even biggest instance thousands decisions. case, choose instancelargest number decisions. every epoch, plot branching frequency,Mok|V | transition variables k|Vo | action variables, respectively. According (4), twobranching frequencies two classes variables chosen equallylikely.results Openstacks Zenotravel show clear distinctions transition variablesaction variables. evidently different, branching frequencies Openstackhigher variance. results Storage domain show completely different pattern,variables distinguish branching frequencies.Figures 9 10, evident that, instances except Storage-12 Woodworking20, branching frequencies transition variables higher action variables. fact,many cases, branching frequencies transition variables 10 times higheraction variables. Transport-26 Zenotravel-15, difference orders magnitudelarger. Hence, empirical study shows SAT solvers branch much frequentlynewly introduced transition variables action variables.306fiSAS+ P LANNING ATISFIABILITY0.70.30.60.250.050.5Transition VarsAction Vars0.060.20.040.150.030.10.020.10.050.01000.40.3Transition VarsAction Vars0.2300000600000(a) Openstack-5, N = 22, UnsatTransition VarsAction Vars03000060000(b) Storage-12, N = 9, Satisfiable050000 100000 150000 200000 250000 300000(c) Zenotravel-15, N = 7, SatisfiableFigure 2: Comparison variable branching frequency (with k = 1000) transition action variablessolving certain SAT instances instances three representative domains: Openstack, StorageZenotravel.5.4 Transition Index SAT Solving Speedupbehavior transition variables, presented above, suggests correlationsignificance transition variables speedup SASE achieves. Nevertheless, studybranching frequency profiles connection showing happens SAT solving.Another interesting study reveal leads speedup direct way. quantifyanalysis, introduce transition index.mentioned earlier, h value exactly reflect VSIDS works, updatesdynamically throughout SAT solving. Nevertheless, putting together variables studyingh values, statistics population leads following definition transitionindex.Definition 11 (Transition Index). Given planning problems SAT instance (V, C), measuretop p(0 p 100) variable set, calculate transition index p follows:|Vp |/|V p ||V |/|V |Essentially, transition index measures relative density transition variables topvariable set. distribution transition variables homogeneous total orderingbased h, |Vp |/|V p | equal |V |/|V | given p. transition index larger 1indicates transition variables higher-than-normal density top p% variable set.larger transition index is, often transition variables occurring top p%variable set.Given planning problems SAT instance, correlation transition indexspeedup SASE provides. Figures 3 4 measure correlation domainsIPC-3 IPC-6. dot one figures refers individual planning instance.y-axis speedup SASE SatPlan06. x-axis transition index given p.Bootstrap aggregating (Breiman, 1996) used regression lines. measurement,calculate Spearmans rank correlation coefficient (Myers & Well, 2003), assesses wellrelationship two variables described using monotonic function.repeated data values, perfect Spearmans correlation coefficient 1 occursvariables perfect monotone function other.307fiH UANG , C HEN , & Z HANG252520SpeedSpeed20Correlation coefficient: 0.3646471510Correlation coefficient: 0.37970125201510151015105555000000001234512345Correlation coefficient: 0.37610720SpeedCorrelation coefficient: 0.36747Speed25123Transition IndexTransition IndexTransition Index(a) p = 1(b) p = 2(c) p = 54512345Transition Index(d) p = 10Figure 3: correlation SAT solving speedup transition index different p.problem instances included. see clear cluster outliers bottom-leftgraph, Airport Rovers domains.instances included Figure 3 solved SatPlan06 SASE, PrecosatSAT solver. reduce noise, consider small instances SASESatPlan06 spend less 1 second solve. total 186 instances. speedupinstance SASEs SAT solving time divided SatPlan06s SAT solving time, greater1 cases. observed trend larger transition index leads higherspeedup. result links significance top ranked (high frequency) transition variablesspeedup SAT solving.2515SpeedSpeedCorrelation coefficient: 0.595048252010Correlation coefficient: 0.5966982520151015101510555500005012345501234550Correlation coefficient: 0.59887420SpeedCorrelation coefficient: 0.594997Speed2520123Transition IndexTransition IndexTransition Index(a) p = 1(b) p = 2(c) p = 5455012345Transition Index(d) p = 10Figure 4: correlation SAT solving speedup transition index different p.Instances Airport Rovers domains included.Figure 3 cluster instances small transition indices (to bottom-leftplot Figure 3). instances distinguish much smaller transition indexes.fact, turns instances either Airport Rovers domainproperty: high number action mutual exclusions, contributingmajority clauses. hand, mutual exclusions binary constraints,contribute significantly SAT problems hardness, trivial unit propagation.mentioned earlier, transition index merely heuristic indicate significance transitionvariables. instances, enormous number action mutual exclusion constraints makestransition index small. However, make problems harder, two-literal clausestrivial SAT solving. result, ignore outlier instances correlationanalysis. Figure 4 removed instances Airport Rovers domains, resultingtotal 159 instances. analysis, correlation becomes even explicit.is, however, one caveat study including instances domains.domains thirty instances solved, domains, solve308fiSAS+ P LANNING ATISFIABILITYInstancesPipesworld-20Storage-20Openstack-10Airport-20Driverlog-15subsumedcountsize254821.72144912.4622122.4410246.4518482.82subsumedcountsize51653.6624960.2214123.46048.4918482.82Table 2: Statistics action cliques, subsumed action cliques reduced.count" gives number action cliques, size" average size action cliques.five. result, study biased toward domains instances solved.interesting future study see transition index works sophisticated experimentalsetting, eliminating certain domain specific factors (Hoffmann, Gomes, & Selman, 2006).6. Reducing Encoding Size SASEpropose several techniques reduce size SAT instances SASE. firstrepresent mutual exclusions SASE using compact clique representation.develop new techniques recognize special structures SASE reduceencoding size.6.1 Mutual Exclusion CliquesMutual exclusions SASE naturally define cliques transitions actions onetrue time step. two types cliques: 1) x X , (x)clique transitions enforced class E clauses, 2) transitionprevailing, A() clique actions enforced class H clauses.requires O(n2 ) clauses encode mutexes within clique size n pair-wise manner.reduce number clauses used, SASE use compact representation (Rintanen, 2006),uses (n log n) auxiliary variables (n log n) clauses. cliques large n,reduction number clauses significant. show works, consider simple example.Suppose clique {x, y, z} one variable true. introduceauxiliary variables b0 b1 clauses x b0 b1 , b0 b1 z b0 b1 .6.2 Reduction TechniquesAction variables form majority variables, also lead many clauses represent actionmutual exclusions even clique technique used. Thus, important reduce numberaction variables. propose three methods certain structure SAS+ planning taskobserved.6.2.1 R EDUCING UBSUMED ACTION C LIQUESobserve many action cliques share common elements, transition cliques not.following, discuss case one action clique subset another. Given two transitions1 2 , A(1 ) A(2 ), say clique A(1 ) subsumed clique A(2 ).309fiH UANG , C HEN , & Z HANGpreprocessing, transition 1 , check A(1 ) subsumed another transition 2 action clique. so, encode action clique A(1 ). special caseA(1 ) = A(2 ) two transitions 1 2 , need encode one them.Table 2 presents number cliques average sizes, reducing actioncliques, representative problems. reduction substantial problem domains,except Driverlog reduction occurred. Note average sizes cliquesincreased since smaller ones subsumed encoded.6.2.2 U NARY RANSITION R EDUCTIONGiven transition |T ()| = 1, say action () reducible. Sinceaction supporting , logically equivalent. action a, removeVa,t replace U,t , = 1, , N . effect reduction representativedomains seen Table 3.6.2.3 U NARY IFFERENCE ET R EDUCTIONBesides unary transition variables, action variable may also eliminated two transition variables. frequent pattern following: given transition , actions A(),transition sets differ one transition.Definition 12 Given transition , let = aA() rans(a). every A(),|T rans(a) \ I| = 1, call action set A() unary difference set.Consider transition 1 A(1 ) = {a1 , a2 , . . . , }. A(1 ) unary difference set,transition sets must following form:rans(a1 ) = {1 , 2 , . . . , k , 1 }rans(a2 ) = {1 , 2 , . . . , k , 2 }...rans(an ) = {1 , 2 , . . . , k , n }case, eliminate action variables a1 , , introducing followingclauses. i, = 1, , n, replace Vai ,t U1 ,t Ui ,t , = 1, , N .case, action variables eliminated represented two transition variables.reason reduction done n actions least one action clique.mutual exclusions actions maintain correctness one sharedtransitions reduced.Table 3 shows number reducible actions several representative problems. Zenotravel,action variables eliminated two reduction methods used. OpenstackStorage, one type reduction applied.310fiSAS+ P LANNING ATISFIABILITYInstancesZeno-15Pathway-15Trucks-15Openstack-10Storage-10|O|9420117431681660846R11800173360540R276208103004000%100.0083.7310.6124.1063.83Table 3: Number reducible actions representative instances. Columns R1 R2 givenumber action variables reduced, unary transition reduction unary difference set reduction,respectively. Column % percentage actions reduced methods combined.7. Experimental Analysis Resultsexperimentally analyzed performance planning using SASE comparison manystate-of-the-art planners. tested problem instances STRIPS domains IPC-3 IPC-6.PSR Philosophers included derived facts, cannot handledcorrectly planners tested. used parser Fast-Downward (Helmert, 2006,2008) generate SAS+ formalism STRIPS inputs. preprocessing encoding partsSASE implemented Python2.6. instances based grounded STRIPS.nearly cases, problem solving took much longer time pre-processing, thusreported overall running time.ran experiments PC workstation 2.3 GHz AMD Quad-Core Opteron processor. running time instance set 1800 seconds, memory limited4GB. planners, running time included parsing, preprocessing problem solving.memory consumption peak memory usage reported SAT solvers.7.1 Comparison ResultsPrecosat (build236) (Biere, 2009), winner application track SAT09 competition,used SAT solver planners tested compared. Besides Precosat,also used CryptoMinisat (Soos, Nohl, & Castelluccia, 2009), winner SAT Race 2010,underlying solver SatPlan06 SASE. nine planners considered listed follows.1. SP06 SP06-Crypto. original SatPlan06 planner (Kautz et al., 2006),underlying SAT solver changed Precosat CryptoMinisat, respectively.2. SASE SASE-Crypto. SASE encoding introduced paper,optimization methods turned on. underlying SAT solvers Precosat CryptoMinisat,respectively.3. SP06L. SatPlan06 (Kautz et al., 2006) long-distance mutual exclusion (londex) (Chenet al., 2009). compared londex since also derives transition informationSAS+ formalism. used domain transition graphs Fast-Downwards parser derivelondex information.4. SP06C. SatPlan06 clique technique (Rintanen, 2006) represent mutualexclusions. clique information obtained via Fast-Downward. Note due311fiH UANG , C HEN , & Z HANGNumber Instances Solved400450SatPlan06nplanSplitESASELM-cut400Number Instances Solved450350300250350300SatPlan06nplanSplitESASELM-cut250200200600120018005001000Running Time (seconds)150020002500300035004000Memory Usage (Megabytes)420420400400Number Instances SolvedNumber Instances SolvedFigure 5: results different planners. include default version every planner.figures show number problems solved planner, increasing limits running timememory consumption.380360340320300280SatPlan06SP06LSP06CSASESP06-CryptoSASE-Crypto6001200Running Time (seconds)380360340320SatPlan06SP06LSP06CSASESP06-CryptoSASE-Crypto300280180050010001500200025003000Memory Usage (Megabytes)35004000Figure 6: results variants SatPlan06 SASE. data presented numberproblems solved planner, increasing limits running time memory consumption.different grounding strategies SatPlan06 Fast-Downward, mutual exclusions defined SatPlan06 could covered cliques.5. nplan. nplan solver (Rintanen et al., 2006) set use -step generate plansoptimality metric planners. executable recent releasenplans homepage. build-in SAT solver changed Precosat.6. SplitE. split encoding (Robinson et al., 2009) using Precosat. obtainedsource code authors recompiled 64bit Linux workstation.7. LM-cut. sequential optimal planner, using LM-Cut heuristic (Helmert & Domshlak,2009) A* search. used implementation Fast-Downward.present results two sets planners, Figures 5 6, respectively. setsdata, show number instances solvable testing domains, respectgiven time limit memory limit.Figure 5 compares results several different solvers using original version. datasuggests SASE clear advantages. LM-cut least efficient, although comparison312fiSAS+ P LANNING ATISFIABILITY420Number Instances SolvedNumber Instances Solved420400380360SatPlan06SP06LSP06CnplanSplitESASE34032002000004000006000008000001e+06400380360SatPlan06SP06LSP06CnplanSplitESASE3403201.2e+06 1.4e+06Number Variables05e+06 1e+07 1.5e+07 2e+07 2.5e+07 3e+07 3.5e+07 4e+07 4.5e+07Number ClausesFigure 7: Number problems solved planner, increasing limits number variables number clauses.meaningful uses optimization metric different planners. running timememory consumption, SASE clearly superior planners. Among planners,nplan slightly better others smaller instances, larger instances, SatPlan06becomes competitive.Figure 6, compare results different variants SatPlan06 SASE.SP06L SP06C extend SatPlan06 additional techniques. general make little improvements original SatPlan06.SAT based planners, present Figure 7 number instances solvableincreasing limits number variables number clauses. Note curves slightlyaffected given time memory limit, thus efficient planners like SASE stops smallernumber clauses. results show SASE advantage terms number variablesnumber clauses planners.Table 4 presents number instances solved planning domain, within giventime memory limit. general, SASE solved instances planners. Dueprogramming bugs, nplan could find correct solutions optimal makespandomains Openstacks, Rovers Storage. SplitE parser could handle problems AirportPathways. Therefore, evaluate corresponding encoding benchmarks.Although LM-Cut overall solved fewer instances, domains performed betterSAT based planners. domains seemed allow less concurrencies action.particular, domains Openstacks Sokoban plans strictly sequential, meaningactions executed time step. plans instancesoften require time steps, making challenging SAT-based planners.SP06L SP06C used Fast-Downwards parser obtain domain transition graph information. Therefore, SP06C SP06L, took much time pre-process grounded STRIPSinstances twice (one Fast-Downward one original SP06). consequence, efficiencylondex clique representation may compensate pre-processing time, leading slightlyworse performance original SP06 instances. example, londex helpfulTPP, Trucks Scanalyzer. clique representation helpful Airportdomain, 10 instances solved, help much Pegsol Satellite.313fiH UANG , C HEN , & Z HANGDomainAirportDepotDriverlogElevatorFreecellOpenstacksParcprinterPathwaysPegsolPipe-notankagePipe-tankageRoversSatelliteScanalyzerSokobanStorageTPPTransportTrucksWoodworkingZenotravelTotalSP06 SP06L SP06C nplan SplitE SASE3538392004617161619171716161617171730303030303054565655505529292930293011111112012212121212224383731403737161616221026131313018141717171816181514141813185531155151515016152730292825301916192218227651088303030303030151515151516386384379369336426SP06c SASEc SASE038423917151417171630303046655529303091012181922383538132316131716171715161717555151515282929192120787303030161616384407398LM27713195202152717117772415612101612288Table 4: Number instances solved domain within 1800 seconds. SP06c , SASEcLM short SP06-Crypto, SASE-Crypto LM-Cut. Column SASE0 result SASEwithout reduction optimization.Comparing nplan, general SASE better, nplan performed better SASEdomains concurrencies. example, Sokoban Trucks oneaction nearly every time step. believe reason way nplan encodes mutualexclusions linear encoding (Rintanen et al., 2006), could used improve SASE.SplitE general slightly worse SP06. SP06 5 domains SP06superior SplitE 6 domains. Overall, SplitE competitive nplan SASE. Rovershowever domain SplitE performed better others. Although CryptoMinisat performed better Precosat SAT Race 2010, good planning problems.SASE SP06, CryptoMinisat solved fewer instances.7.2 Ablation StudyFigure 8 shows number solvable problems problems IPC-3 IPC-6, increasing limits running time, memory consumption, number variables number clauses.Precosat used planners. Running time total time including preprocessingproblem solving. Memory usage based status report Precosat. maximumCPU time (1800s) memory limit (4Gb), clique representation reduction techniques used, SASE solved 398 instances. turning either clique representationaction reduction technique, SASE solved 416 405 instances, respectively. cliqueaction reduction techniques turned on, SASE solves 426 instances.314fi440420420400380360340clique=on, reduction=onclique=on, reduction=offclique=off, reduction=onclique=off, reduction=off32030010Number Instances SolvedNumber Instances Solved4406001200Running Time (seconds)4003803603403001800500440440420420400380360340clique=on, reduction=onclique=on, reduction=offclique=off, reduction=onclique=off, reduction=off3203005000001e+061.5e+06clique=on, reduction=onclique=on, reduction=offclique=off, reduction=onclique=off, reduction=off320Number Instances SolvedNumber Instances SolvedSAS+ P LANNING ATISFIABILITY2e+0635004000380360340clique=on, reduction=onclique=on, reduction=offclique=off, reduction=onclique=off, reduction=off300Number Variables1500 2000 2500 3000Memory Usage (Megabytes)4003202.5e+06100005e+06 1e+071.5e+072e+072.5e+073e+073.5e+074e+074.5e+07Number ClausesFigure 8: results SASE clique reduction methods turned off.reduction method improved upon problem solving time, well clique representation.clique representation provided substantial improvement memory consumption, followedaction reduction. numbers clauses, clique technique gave significant reduction. Finally,techniques helped reduce number variables.8. Conclusions Future Researchpaper, developed novel SAS+ based SAT encoding scheme SASE, showedimproves efficiency STRIPS based SAT encodings terms time memory.compared state-of-the-art SAT based planners, SASE clear advantages shownexperimental analysis. proved correctness SASE encoding showingisomorphism solution plans SASE solution plans SatPlan06.analyzed search space structure SASE, explained efficient. Below,briefly discuss related work highlight several directions future research.8.1 Semantics EncodingsMany enhancements developed SAT based planning since introduced (Kautz& Selman, 1992). split action representation (Kautz & Selman, 1992; Ernst et al., 1997) usesconjunction multiple variables represent action. optimality is, however, lost. Robinsonet al. (2009) propose new way splitting without sacrificing optimality. results315fiH UANG , C HEN , & Z HANGshow method advantages SatPlan06 (Kautz et al., 2006). many publishedworks thorough analysis, improvements along line research SatPlan family encodings. particular, power mutual exclusion, context planning SAT, attractedinterests (Chen et al., 2009; Sideris & Dimopoulos, 2010). new encoding scheme called SMPproposed, preserves merits londex shows certain advantages existingencoding schemes (Sideris & Dimopoulos, 2010).planner family SatPlan variants step-optimal. step-optimality semantics,along relaxed parallel semantics, formalized -step -step, respectively (Dimopoulos, Nebel, & Koehler, 1997; Rintanen et al., 2006). -step enforces weaker mutual exclusions-step, thus may lead reduced running time due fewer calls SAT solver. trade-off,loses optimality time steps. semantics SatPlan06 SASE -step.research various kinds semantics orthogonal contribution SASE, ideaSASE migrated new semantics.Since SAT based planning also applied sequential planning, idea SASEalso extended field. first planner kind MEDIC (Ernst et al., 1997),extends idea splitted action representation. study shows sequential planning,splitting yields competitive planners. also proposed utilize advantagessequential parallel planning (Bttner & Rintanen, 2005).8.2 Additional Techniques Planning SATtremendous amount two-literal clauses (such mutual exclusion clauses caseplanning) key challenge approaches based satisfiability tests. proposed mitigate burden encoding recognizing certain structures (Brafman, 2001). traditionalSAT planning systems like SatPlan06, mutual exclusions encoded quadratic manner.Rintanen proposes log size technique (Rintanen, 2006), called clique representation, mutual exclusion constraints, later linear size one (Rintanen et al., 2006). mutual exclusionsSASE represented clique representation. log size clique representationsupposed less compact linear encoding. results, however, shownSASE general compact. mainly due compactness SAS+ formalism.certainly open question whether linear size encoding technique adoptedimprove SASE.also techniques beyond encoding boost SAT-based planning. Rintanen introducesincorporate symmetry information SAT instances (Rintanen, 2003). MaxPlan (Xing,Chen, & Zhang, 2006) planning graph analysis find upper bound optimal makespan SAT queries using decreasing time steps, meets unsatisfiable SATinstance. lemma reusing method proposed (Nabeshima, Soh, Inoue, & Iwanuma, 2006) reuselearnt clauses across multiple SAT solvings. multiple-step query strategy introduced (Ray &Ginsberg, 2008), however asks modified SAT procedures. boosting methodsproposed context STRIPS based planning. interesting incorporate techniquesSASE study improve performance.8.3 Understanding Structure General SAT InstancesSAT intrinsically hard. performance modern SAT solvers improves constantly. therefore interesting important understand SAT solvers work well certain instances,316fiSAS+ P LANNING ATISFIABILITYfurthermore, makes SAT instance easy hard. much prior research tries obtain understanding, including backdoor set (Williams, Gomes, & Selman, 2003) backbone (Monasson, Zecchina, Kirkpatrick, Selman, & Troyansky, 1999; Zhang, Rangan, & Looks,2003; Zhang, 2004). Backdoor set variables set variables, variablesassigned, variables assignments derived polynomial time. Backbone variablesvariables assignment valid solutions, exploited improve SAT solving efficiency. recent study context planning revealsclear correlations SAT solving efficiency goal asymmetry (Hoffmann et al.,2006).interesting see connections SASEs problem structuretheories above. example, improvement SASE lead smallerbackdoor set? Second, shown efficiency SASE result transition variablessignificance, strong correlation speedup SASE transitionindex. interesting investigate similar variable set predictive index automaticallyfound general SAT solving.Finally, given efficiency SASE, promising apply SAT-based planningapproaches, complex planning preferences (Giunchiglia & Maratea, 2007)temporal features (Huang et al., 2009).9. Acknowledgmentsresearch supported National Science Foundation United States grantsNeTS-1017701, DBI-0743797, IIS-0713109, Microsoft Research New Faculty Fellowship.thank Joerg Hoffmann, Jussi Rintanen several anonymous reviewers helpful comments. particularly thank Malte Helmert making SAS+ parser available. also thankcomputing resource supports engineering group Washington University St.Louis.Appendix A. ProofsLemma 1 Given STRIPS task = (F, A, , G ), time step N , PE SAT instancePE(, N ) = (V, C), suppose satisfiable solution denoted , fact f F,[1, N ] that: 1) (Wdumf ,t ) =, 2) (Wf,t ) = , 3) DEL(f ), (Wa,t ) =,construct alternative solution PE(, N ) follows:(v) =(, v = Wdumf ,t , v V(v), v 6= Wdumf ,t , v V(5)Proof show satisfies every clause C does. Since variables Wdumf ,tkeep value, need examine clauses Wdumf ,t them. Accordingdefinition PE, Wdumf ,t may exist three types clauses:1. Clauses add effects. case, clauses form Wf,t+1 (Wdumf ,tWa1 ,t Wam ,t ), equivalent W f,t+1 Wdumf ,t Wa1 ,t Wam ,t . Since(Wdumf ,t ) = , clauses still true.317fiH UANG , C HEN , & Z HANG2. Clauses preconditions. case, clauses form Wdumf ,t Wf,t ,equivalent Wdumf ,t Wf,t . Since (Wf,t ) = , clauses remain true .3. Clauses mutual exclusion actions. Without loss generality, let us denoteclause Wdumf ,t Wa,t . given f , actions clauses mutex dumf ,f delete effect. According construction, since (Wa,t ) = (Wa,t ) =,clauses true.three cases conclude clauses include Wdumf ,t satisfied . Therefore, also solution PE.Lemma 2 Given STRIPS task = (F, A, , G ), time step N , PE SAT instancePE(, N ) = (V, C), suppose satisfiable solution denoted , fact f F,[1, N ] that: 1) (Wf,t ) =, 2) exists action ADD(f ) (Wa,t1 ) = ,construct alternative solution PE(, N ) follows:(v) =(, v = Wf,t , v V(6)(v), v 6= Wf,t , v VProof show makes clause C true. Since variables Wf,t keepvalue, need look clauses Wf,t them. Accordingdefinition PE, Wf,t may exist three types clauses.1. Clauses add effects. case, f add effect multiple actions. Let us writeclauses Wf,t (Wa1 ,t1 Wa2 ,t1 Wam ,t1 ), Wf,t Wa1 ,t1 Wa2 ,t1Wam ,t1 . Since exists action ADD(f ) (Wa,t1 ) = , clausestill true .2. Clauses preconditions. case, f precondition action b. clausewritten Wb,t Wf,t , equivalent Wb,t Wf,t . Since (Wf,t ) = , clausestill true.3. Clauses fact mutex. Without loss generality, consider fact g mutex f .corresponding clause Wf,t Wg,t . Since (Wf,t ) = , clause true(Wg,t ) =.suppose (Wg,t ) = show leads contradiction. According clausesclass III, must variable Wb,t1 , g add(b) (Wb,t1 ) = .According definition mutex, two facts mutex every pair actionsadd mutex. Thus, Wa,t1 Wb,t1 mutex. Therefore, (Wa,t1 ) =(Wb,t1 ) = , leading contradiction. result, (Wg,t ) =, consequentlyclause satisfied.three cases conclude clauses include Wf,t satisfied . Therefore,also solution PE.318fiSAS+ P LANNING ATISFIABILITYLemma 3 Given SAS+ planning task = (X , O, sI , sG ) equivalent STRIPS task =(F, A, , G ), suppose actions a, b O, equivalent actions , b (i.e.= (a ) b = (b )), b S-mutex iff b P-mutex.Proof construct proof studying directions. Based Proposition 1,consider inconsistent effects interference mutex P-mutex.: b P-mutex , b S-mutex .Since b P-mutex, one either deletes precondition add-effect other. Withoutloss generality, suppose deletes f (i.e. f del(a ) pre(b )). Consequently, musttransition 1 = fxh (a) f 6= h 2 = fxg (b). two casesconsidered.1) 1 6= 2 . 1 2 mutex transitions Definition 3, since change valuef . Therefore, b S-mutex, according second condition Definition 5.2) 1 = 2 . case, b S-mutex first condition Definition 5.Based two cases, conclude b S-mutex. similar argument appliescase one action deletes others add-effect.: b S-mutex , b P-mutex .two actions b S-mutex , two cases.1) exists transition , (a) (b). Consequently, b deletesothers precondition thus P-mutex.2) exist two distinct transitions 1 (a), 2 (b) multi-valued variable x X ,{1 , 2 } (x). Let us denote two transitions vx1 v2 vx3 v4 . case,suppose vx1 v2 vx3 v4 allowed executed parallel STRIPS plan. obviouslyleads contradiction, since v1 , v2 , v3 , v4 Dom(x) values multi-valued variable,definition SAS+ formalism, one true time. Therefore,preconditions b must mutex, hence b P-mutex.Theorem 1 Given STRIPS task SAS+ task equivalent, time step boundN , PE(, N ) satisfiable, SASE(, N ) also satisfiable.Proof Since PE(, N ) satisfiable, denote one solutions . first presentconstruct assignment SASE(, N ) . Next, prove constructed assignmentsatisfies every clause SASE(, N ).Construction. two steps construction. According Lemmas 1 2,general free variables . first step, construct alternative solutionPE(, N ) changing free variables true according Lemmas 1 2. Let usdenote resulting solution . Then, construct assignment SASE(, N ) .value variable defined follows.1. every (which also A)1 , let Ua,t = Wa,t .Wg,t+1 =1. simplicity, use denote action instead using (a).319, set Ux,f,g,t =2. every transition f g , Wf,t =.fiH UANG , C HEN , & Z HANGSatisfiability. prove every individual clause SASE satisfied . eighttypes clauses.1. (Forward progression). According construction, need show that,[1, N 2],_x(Wf,t+1 Wg,t+2 )(7)hf, (Wh,t Wf,t+1 )g,fxg(Wf,t+1 ) =, (7) satisfied . (Wf,t+1 ) = , consider actionset = {dumf } DEL(f ), subset rans(fxg ). two possibilities.every action , (Wa,t+1 ) =. case, Wdumf ,t+1 Wf,t+2free variables according Lemmas 1 2, respectively. Therefore, accordingconstruction , assigns free variables true, variables Wf,t+1 , Wf,t+2Wdumf ,t+1 . addition, f f always , meaning Wf,t+2 includedright hand side (7). Therefore, (7) satisfied .exists action , (Wa,t+1 ) = . case, let usconsider arbitrary fact g add(a). (Wg,t+2 ) = , (7) satisfied .Otherwise, according Lemma 2, Wg,t+2 free variable Wg,t+2 already settrue construction . Therefore, satisfies (7).2. (Regression). According construction, need show that, [2, N 1],_(Wh,t1 Wf,t )(8)fxg , (Wf,t Wg,t+1 )xh,hf(x)Consider clauses class III (add effect) PE. clauses indicate factf F, Wf,t implies disjunction Wa,t1 actions f add(a). Thus,given f , following clauses included PE, satisfied :_Wf,tWa,t1 .(9)aADD(f )given f , consider action seth A(hf ),Wf,t_denoted Z. Since ADD(f ) Z,Wa,t1(10)aZxxtransition hf, action A(hf), since h pre(a), satisfiesWa,t1 Wh,t1 . Therefore, h pre(a),_Wa,t1 Wh,t1 .(11)xaA(hf)expanding set Z, convert (10) to:320fiSAS+ P LANNING ATISFIABILITY_Wf,t_(xh,hfWa,t1 ).(12)xaA(hf)combining (11) (12), have:_Wf,tWh,t1 ,(13)(Wh,t1 Wf,t ).(14)xh,hfimplies_Wf,txh,hf(14), see clauses regression (8) true.3. (Initial state). need show variable x X sI (x) = f :_Uf,g,1(15)g,f gAccording construction, (15) becomes:_(Wf,1 Wg,2 ),g,f gequivalent to:_Wf,1 (Wg,2 )(16)g,f g (x)Since f initial state, (Wf,1 ) = (Wf,1 ) = . Therefore first partconjunction (16) true. rest part (16) seen true following similarargument progression case.4. (Goal). goal clauses shown similar way initial state clauses.5. V(Composition actions). clausesV want prove are, action a, Ua,tU,equivalently,Ua,trans(a) ,trans(a) U,t .Suppose rans(a) = {f1 g1 , f2 g2 , . . . , fm gm }. clause need show becomes:(Wa,t Wf1 ,t ) (Wa,t Wg1 ,t ) (Wa,t Wf2 ,t ) (Wa,t Wg2 ,t ) . . .(Wa,t Wfm ,t ) (Wa,t Wgm ,t )(17)Let us call two-literal disjunctions (17) sub-clauses. Wa,t Wfi ,t subclauses (17) exactly precondition clause (class IV) PE.Wa,t Wfi ,t (17) satisfied.Next, let us consider Wa,t Wgi ,t sub-clauses. g = gi , = 1, , m.four cases Wa,t Wg,t assigned different values:321fiH UANG , C HEN , & Z HANG(Wa,t =, Wg,t =): Wa,t Wg,t satisfied., Wg,t =): Wa,t Wg,t satisfied.(Wa,t =(Wa,t =, Wg,t =): Wa,t Wg,t satisfied.(Wa,t = , Wg,t =): According Lemma 2, Wg,t free variable. Therefore, since(Wg,t ) = , Wa,t Wg,t satisfied , hence satisfied .6. (Transition mutex). Consider mutex clause two regular transitions 1 = f g2 = f g . Let f g rans(a) f g rans(b), see bS-mutex. According Lemma 3, b also P-mutex PE. Therefore,Wa,t Wb,t .Vb,t . Then, since compositionV construction, know Ua,t Uactions, Ua,t rans(a) U,t Ub,t rans(b) U,t . simple resolutionclauses yields U1 ,t U2 ,t , equals transition mutex clause U1 ,t U2 ,t .Therefore, transition mutex clause true . similar argument appliestransitions prevailing mechanical.W7. (Action existence). clauses want prove U,t rans(a) Ua,t ,transitions . construction, clauses become_Wa,t .(18)Wf,t Wg,t+1aA(f g )Let = f g . First, know definition h A(hg ) = ADD(g). Let us denoteADD(g) Z. According clauses class III PE, clauses:_Wa,t .(19)Wg,taZdivide Z multiple action sets according different fact {f, h1 , . . . , hm }, denoted Zf , Zh1 , , Zhm . fact, h {f, h1 , . . . , hm }, Zh equivalentA(hg ). Consider hi , = 1, , m. According clauses class IV, everyaction PRE(h), clause Wa,t Whi ,t ,Wa,t Whi ,t .(20)Next, perform resolutions using (19) clauses (20), hicorresponding actions. consequently have:Wg,t (Wh1 ,t Wh2 ,t Whm ,t )_Wa,t .(21)aZfFurther, note h1 , h2 , . . . , fm mutex f , resolution using mutex clausesPEresults in:(21), Wh1 ,t Wf,t , Wh2 ,t Wf,t , . . . , Whm ,t Wf,tWWg,t (Wf,t Wf,t Wf,t ) aZf Wa,tSince Zf = A(f g ), outcome (22) leads (18).322(22)fiSAS+ P LANNING ATISFIABILITY8. (Action mutex). Action mutex clauses satisfied according Lemma 3.Combining cases concludes constructed solution satisfies clausesSASE means SASE satisfiable. Since action a, (Wa,t ) = (Wa,t ) = (Ua,t ),represent solution plan.Theorem 2 Given STRIPS task SAS+ task equivalent, time step boundN , SASE(, N ) satisfiable, PE(, N ) also satisfiable.Proof Assuming satisfiable solution SASE(, N ), first construct assignment, show satisfies every clause PE(, N ).Construction. construct solution follows:1. every (which also O), let Wa,t = Ua,t ;2. every dummy action variable dumf , let Wdumf ,t = Uf f ,t ;, set Wf,t = Wg,t+1 =3. every transition f g , Ux,f,g,t =;4. fact f , Uh,f,t = every transition hf (which implies case 3assign value f ), set Wf,t .Satisfiability. Next, prove every clause PE satisfied . clauses initialgoal states obviously satisfied. consider add-effect clauses. clauseswant prove are, every fact f :Wf,t_Wa,t1(23)aADD(f )given fact f , consider facts h 6= f , hf . h,two cases:xexists fact h hfUx,h,f,t1 = . satisfiable SASEinstance, action existence clauses class F specify truth non-prevailingtransition indicates disjunction actions A(). Since Ux,h,f,t1 = , followsxSASE instance action A(hf) Ua,t1 = . Then,construction , see Wh,t1 Wf,t true. Since Wf,t Wa,t1 ,ADD(f ), true, (23) satisfied .xevery fact h hf, Ux,h,f,t1 = , then, according construction,Wf,t = . Thus, satisfies (23).two cases conclude satisfies add effect clauses. Next, showsatisfies precondition clauses, Wa,t Wf,t (i.e. Wa,t Wf,t ), actions factsf pre(a). SASE, clauses class F, Ua,t U,t , actionsx , Urans(a). Let transition f,ga,t (Uf,t1 Ug,t1 ), impliesUa,t Uf,t1 . construction, know Wa,t Wf,t1 true.Finally, mutex clauses satisfied according Lemma 3. Combining casesconcludes constructed solution satisfies clauses PE means PE satisfiable.323fiH UANG , C HEN , & Z HANGAppendix B. Branching Frequency Domains0.0060.06Transition VarsAction Vars0.03Transition VarsAction Vars0.0050.050.0250.0040.040.020.0030.030.0150.0020.020.010.0010.010.0050004000080000120000160000(a) Airport-44, N = 68, Satisfiable0.20.18Transition VarsAction Vars0050000 100000150000200000250000300000350000010000 20000 30000 40000 50000 60000 70000(b) Depot-8, N = 14, Satisfiable(c) Driverlog-16, N = 14, Unsat0.140.045Transition VarsAction Vars0.120.16Transition VarsAction Vars0.040.0350.10.140.12Transition VarsAction Vars0.10.030.080.080.060.060.040.0250.020.0150.010.040.020.0200.005050001000015000(d) Elevator-30, N = 10, Satisfiable0.07Transition VarsAction Vars0.06005000 10000 15000 20000 25000 30000 35000(e) Freecell-4, N = 12, Unsat0.2Transition VarsAction Vars0.180.1600.040.120.10.020.030.080.0150.020.060.01060008000 10000 12000 14000(g) Pathways-15, N = 18, Satisfiable30000.0050.02400025000.0250.04200020000.030.1401500Transition VarsAction Vars0.0350.0401000(f) Parcprinter-29, N = 23, Satisfiable0.050.0150002000006000001e+06(h) Pegsol-18, N = 20, Unsat020000 40000 60000 80000 100000120000140000(i) Pipe-notankage-29, N = 14, SatisfiableFigure 9: Comparison variable branching frequency (with k = 1000) transition action variablessolving certain SAT instances twelve benchmark domains encoded SASE. figure correspondsindividual run MiniSAT. x axis corresponds decision epochs SAT solving.axis denotes branching frequency (defined text) epoch k = 1000.324fiSAS+ P LANNING ATISFIABILITY0.090.18Transition VarsAction Vars0.080.070.140.060.120.050.10.040.080.030.060.020.040.010.0200.025Transition VarsAction Vars0.160.0150.010.0050010000 20000 30000 40000 50000 60000 70000(a) Pipe-tankage-21, N = 13, Unsat0.14002000 4000 6000 8000 10000 12000 14000 16000(b) Rovers-15, N = 12, Satisfiable0.25Transition VarsAction Vars0.12Transition VarsAction Vars0.0200.02Transition VarsAction VarsTransition VarsAction Vars0.0180.250000 100000 150000 200000 250000 300000(c) Satellite-12, N = 13, Unsat0.0160.10.0140.080.150.0120.060.10.0080.010.0060.040.050.0040.020.002001000002000003000000400000(d) Scanalyzer-27, N = 12, Satisfiable3000000.160.140.05Transition VarsAction Vars0.060.040.120.040.10.030.080.060.020.020.040.0100.02050000100000150000(g) Transport-26, N = 12, SatisfiableTransition VarsAction Vars0.180.060.085000 10000 15000 20000 25000 30000 35000 40000(f) TPP-26, N = 10, Unsat0.2Transition VarsAction Vars0.070.10(e) Sokoban-6, N = 33, Unsat0.080.126000000100000200000300000400000(h) Trucks-7, N = 17, Unsat0500 1000 1500 2000 2500 3000 3500 4000 4500(i) Woodworking-20, N = 4, SatFigure 10: Comparison variable branching frequency (with k = 1000) transition action variablessolving certain SAT instances nine benchmark domains encoded SASE.ReferencesBckstrm, C., & Nebel, B. (1996). Complexity results SAS+ planning. Computational Intelligence, 11, 625655.Biere, A. (2009). Pr{e,i}coSAT@SC09. SAT09 Competition.Blum, A., & Furst, M. (1997). Fast Planning Planning Graph Analysis. Artificial Intelligence, 90, 16361642.Brafman, R. I. (2001). simplifier propositional formulas many binary clauses. Proceedings International Joint Conference Artificial Intelligence.Breiman, L. (1996). Bagging predictors. Machine Learning, 24, 123140.325fiH UANG , C HEN , & Z HANGBttner, M., & Rintanen, J. (2005). Satisfiability Planning Constraints NumberActions. Proceedings International Conference Automated Planning Scheduling.Castellini, C., Giunchiglia, E., & Tacchella, A. (2003). SAT-based planning complex domains:Concurrency, constraints nondeterminism. Artificial Intelligence, 147, 85117.Chen, Y., Huang, R., Xing, Z., & Zhang, W. (2009). Long-distance mutual exclusion planning.Artificial Intelligence, 173, 197412.Chen, Y., Huang, R., & Zhang, W. (2008). Fast Planning Search Domain Transition Graphs.Proceedings AAAI Conference Artificial Intelligence.Dimopoulos, Y., Nebel, B., & Koehler, J. (1997). Encoding planning problems nonmonotoniclogic programs. Proceeding Fourth European Conference Planning, pp. 169181. Springer-Verlag.Do, B., & Kambhampati, S. (2000). Solving Planning Graph Compiling CSP.Proceedings International Conference Automated Planning Scheduling.Ernst, M., Millstein, T., & Weld, D. (1997). Automatic SAT-compilation planning problems.Proceedings International Joint Conference Artificial Intelligence.Giunchiglia, E., & Maratea, M. (2007). Planning satisfiability preferences. ProceedingsAAAI Conference Artificial Intelligence.Helmert, M. (2006). Fast Downward planning system. Journal Artificial Intelligence Research, 26, 191246.Helmert, M. (2008). Concise finite-domain representations PDDL planning tasks. ArtificialIntelligence, 173, 503535.Helmert, M., & Domshlak, C. (2009). Landmarks, Critical paths Abstractions: Whatsdifference anyway?. Proceedings International Conference Automated PlanningScheduling.Helmert, M., Haslum, P., & Hoffmann, J. (2008). Explicit-State Abstraction: New MethodGenerating Heuristic Functions. Proceedings AAAI Conference Artificial Intelligence.Hoffmann, J., Gomes, C., & Selman, B. (2006). Structure Problem Hardness : Goal AsymmetryDPLL Proofs SAT-based Planning. Proceedings International ConferenceAutomated Planning Scheduling.Hoffmann, J., Kautz, H., Gomes, C., & Selman, B. (2007). SAT encodings state-space reachability problems numeric domains. Proceedings International Joint ConferenceArtificial Intelligence.Hoffmann, J., & Nebel, B. (2001). FF planning system: Fast plan generation heuristicsearch. Journal Artificial Intelligence Research, 14, 253302.Huang, R., Chen, Y., & Zhang, W. (2009). Optimal Temporally Expressive Planner: InitialResults Application P2P Network Optimization. Proceedings International Conference Automated Planning Scheduling.Kautz, H., & Selman, B. (1992). Planning satisfiability. Proceedings European ConferenceArtificial Intelligence.326fiSAS+ P LANNING ATISFIABILITYKautz, H., & Selman, B. (1996). Pushing envelope: Planning, propositional logic, stochasticsearch. Proceedings AAAI Conference Artificial Intelligence.Kautz, H., & Selman, B. (1999). Unifying sat-based graph-based planning. ProceedingsInternational Joint Conference Artificial Intelligence.Kautz, H., Selman, B., & Hoffmann, J. (2006). SatPlan: Planning Satisfiability. 5th International Planning Competition, International Conference Automated Planning Scheduling.Monasson, R., Zecchina, R., Kirkpatrick, S., Selman, B., & Troyansky, L. (1999). Determiningcomputational complexity characteristic phase transitions. Nature, 400(8), 133137.Moskewicz, M., Madigan, C., Zhao, Y., Zhang, L., & Malik, S. (2001). Chaff: EngineeringEfficient SAT Solver. 39th Design Automation Conference.Myers, J. L., & Well, A. D. (2003). Research Design Statistical Analysis (2nd edition). Routledge.Nabeshima, H., Soh, T., Inoue, K., & Iwanuma, K. (2006). Lemma reusing SAT based planningscheduling. Proceedings International Conference Automated PlanningScheduling.Ray, K., & Ginsberg, M. L. (2008). complexity optimal planning efficient methodfinding solutions. Proceedings International Conference Automated PlanningScheduling.Richter, S., Helmert, M., & Westphal, M. (2008). Landmarks Revisited. Proceedings AAAIConference Artificial Intelligence.Rintanen, J. (2003). Symmetry Reduction SAT Representations Transition System. Proceedings International Conference Automated Planning Scheduling.Rintanen, J. (2006). Biclique-based representations binary constraints making SAT planningapplicable larger problems. Proceedings European Conference Artificial Intelligence.Rintanen, J., Heljanko, K., & Niemel, I. (2006). Planning Satisfiability: parallel plansalgorithms plan search. Artificial Intelligence, 12-13, 10311080.Robinson, N., Gretton, C., Pham, D., & Sattar, A. (2009). SAT-Based Parallel Planning UsingSplit Representation Actions. Proceedings International Conference AutomatedPlanning Scheduling.Sideris, A., & Dimopoulos, Y. (2010). Constraint propagation propositional planning. Proceedings International Conference Automated Planning Scheduling.Soos, M., Nohl, K., & Castelluccia, C. (2009). Extending sat solvers cryptographic problems.International Conference Theory Applications Satisfiability Testing.6th Intl Planning Competition (2008). http://ipc.informatik.uni-freiburg.de/homepage/..7th Intl Planning Competition (2011). http://ipc.icaps-conference.org/..Williams, R., Gomes, C., & Selman, B. (2003). Backdoors typical case complexity. Proceedings International Joint Conference Artificial Intelligence.327fiH UANG , C HEN , & Z HANGXing, Z., Chen, Y., & Zhang, W. (2006). MaxPlan: Optimal Planning Decomposed Satisfiability Backward Reduction. 5th International Planning Competition, InternationalConference Automated Planning Scheduling.Zhang, W. (2004). Configuration landscape analysis backbone guided local search: Part I:Satisfiability maximum satisfiability. Artificial Intelligence, 158, 126.Zhang, W., Rangan, A., & Looks, M. (2003). Backbone Guided Local Search Maximum Satisfiability. Proceedings International Joint Conference Artificial Intelligence.328fiJournal Artificial Intelligence Research 43 (2012) 135-171Submitted 08/11; published 02/12CQC Algorithm: Cycling Graphs SemanticallyEnrich Enhance Bilingual DictionaryTiziano FlatiRoberto Navigliflati@di.uniroma1.itnavigli@di.uniroma1.itDipartimento di Informatica, Sapienza University Rome00198, Rome, Italy.AbstractBilingual machine-readable dictionaries knowledge resources useful many automatic tasks. However, compared monolingual computational lexicons like WordNet,bilingual dictionaries typically provide lower amount structured informationlexical semantic relations, often cover entire range possible translations word interest. paper present Cycles Quasi-Cycles (CQC),novel algorithm automated disambiguation ambiguous translations lexical entries bilingual machine-readable dictionary. dictionary representedgraph, cyclic patterns sought graph assign appropriate sense tagtranslation lexical entry. Further, use algorithms output improvequality dictionary itself, suggesting accurate solutions structural problemsmisalignments, partial alignments missing entries. Finally, successfullyapply CQC task synonym extraction.1. IntroductionLexical knowledge resources, thesauri, machine-readable dictionaries, computationallexicons encyclopedias, enjoying increasing popularity lastyears. Among resources cite Rogets Thesaurus (Roget, 1911), Macquarie Thesaurus (Bernard, 1986), Longman Dictionary Contemporary English (Proctor, 1978,LDOCE), WordNet (Fellbaum, 1998) Wikipedia. knowledge resourcesutilized many applications, including Word Sense Disambiguation (Yarowsky, 1992; Nastase & Szpakowicz, 2001; Martnez, de Lacalle, & Agirre, 2008, cf. Navigli, 2009b, 2012survey), semantic interpretation text (Gabrilovich & Markovitch, 2009), Semantic Information Retrieval (Krovetz & Croft, 1992; Mandala, Tokunaga, & Tanaka, 1998; Sanderson,2000), Question Answering (Lita, Hunt, & Nyberg, 2004; Moldovan & Novischi, 2002), Information Extraction (Jacquemin, Brun, & Roux, 2002), knowledge acquisition (Navigli &Ponzetto, 2010), text summarization (Silber & McCoy, 2003; Nastase, 2008), classification(Rosso, Molina, Pla, Jimnez, & Vidal, 2004; Wang & Domeniconi, 2008; Navigli, Faralli,Soroa, de Lacalle, & Agirre, 2011) even simplification (Woodsend & Lapata, 2011).applications exploit structure provided adopted lexical resourcesnumber different ways. instance, lexical semantic relations encodedcomputational lexicons WordNet shown useful graph-basedWord Sense Disambiguation (Mihalcea, 2005; Agirre & Soroa, 2009; Navigli & Lapata, 2010;Ponzetto & Navigli, 2010) semantic similarity (Pedersen, Banerjee, & Patwardhan,2005; Agirre, Alfonseca, Hall, Kravalova, Pasca, & Soroa, 2009). Interestingly,c2012AI Access Foundation. rights reserved.fiFlati & Naviglireported higher amount structured knowledge, higher disambiguationperformance (Navigli & Lapata, 2010; Cuadros & Rigau, 2006). Unfortunately,semantics made explicit within lexical resources. Even WordNet (Fellbaum, 1998),widely-used computational lexicon English, provides explanatory informationunstructured form textual definitions, i.e., strings text explain meaningconcepts using possibly ambiguous words (e.g., motor vehicle four wheels provideddefinition common sense car ). Still worse, computational lexiconslike WordNet contain semantically explicit information is-a part-of relations,machine-readable dictionaries (MRDs) often electronic transcriptions papercounterparts. Thus, entry mostly provide implicit information formfree text, cannot immediately utilized Natural Language Processing applications.recent years various approaches disambiguation monolingual dictionarydefinitions investigated (Harabagiu, Miller, & Moldovan, 1999; Litkowski, 2004;Castillo, Real, Asterias, & Rigau, 2004; Navigli & Velardi, 2005; Navigli, 2009a), resultsshown can, indeed, boost performance difficult tasks WordSense Disambiguation (Cuadros & Rigau, 2008; Agirre & Soroa, 2009). However, littleattention paid disambiguation bilingual dictionaries, wouldcapable improving popular applications Machine Translation.article present graph-based algorithm aims disambiguating translations bilingual machine-readable dictionaries. method takes input bilingualMRD transforms graph whose nodes word senses1 (e.g., car 1n ) whoseedges (s, s0 ) mainly represent potential relations source sense wordw (e.g., car 1n ) various senses s0 translations (e.g., macchina 3n ). Next, introduce novel notion cyclic quasi-cyclic graph paths use selectappropriate sense translation w0 source word w.contributions paper threefold: first, present novel graph-based algorithm disambiguation bilingual dictionaries; second, exploit disambiguationresults way help lexicographers make considerable improvementsdictionary address issues mistakes various kinds; third, use algorithmautomatically identify synonyms aligned across languages.paper organized follows: Section 2 introduce reader mainideas behind algorithm, also help walk-through example. Section 3provide preliminary definitions needed introduce disambiguation algorithm.Section 4 present Cycles Quasi-Cycles (CQC) algorithm disambiguationbilingual dictionaries. Section 5 assess disambiguation performance dictionarytranslations. Section 6, show enhance dictionary semi-automaticallymeans CQC, provide experimental evidence Section 7. Section 8 describeapplication monolingual bilingual synonym extraction Section 9 describeexperiments. Related work presented Section 10. give conclusions Section11.1. denote wpi i-th sense word w part speech p reference sense inventory (weuse n nouns, v verbs, adjectives r adverbs), senses simply denotedintegers (like 1, 2, 3, etc.), also letters numbers (such A.1, B.4, D.3) indicating differentlevels granularity (homonymy, polysemy, etc.).136fiCycling Graphs Semantically Enrich Enhance Bilingual Dictionary2. Brief Overviewsection provide brief overview approach disambiguation bilingualdictionary entries.2.1 Goalgeneral form bilingual dictionary entry is:wpi v1 , v2 , . . . , vkwhere:wpi i-th sense word w part speech p source language (e.g.,play 2v second sense verb play);vj translation target language sense wpi (e.g., suonare v translation play 2v ). Note vj implicitly assumed partspeech p wp . Importantly, sense explicitly associated vj .objective associate target word vj one sensesconcepts expressed wp vj match. aim systematic automaticway. First all, starting bilingual dictionary (see Section 3.1), build noisygraph associated dictionary (see Section 3.2), whose nodes word sensesedges (mainly) translation relations word senses. translation relationsobtained linking source word sense (wpi above) senses target wordvj . Next, define novel notion graph patterns, called CyclesQuasi-Cycles (CQC), use support predicting suitable sensetranslation vj source word sense wpi (see Section 3.3).2.2 Walk-Through Examplepresent walk-through example give insights main goalpresent work. Consider following Italian-English dictionary entries:giocare A.1vrecitare A.2vsuonare A.1vsuonare B.4vinterpretare 4vplay, toyact, playsound, ring, playring, echoplay, actgiocaresuonare, riprodurreinterpretare, recitarefollowing English-Italian entries:play 1vplay 2vplay 3v137fiFlati & Navigliaim sense tag target terms right-hand side, i.e., would likeobtain following output:giocare A.1vrecitare A.2vsuonare A.1vsuonare B.4vinterpretare 4vplay 1v , toy 1v3act A.1v , play v1.A.1sound v , ring 2.A.2, play 2vv2.A.4A.1ring v , echo vplay 3v , act A.1vplay 1vplay 2vplay 3vgiocare A.1v1suonare A.2v , riprodurre v3A.2interpretare v , recitare vnumbers beside right-hand translation correspond suitable sensesdictionary translation (e.g., first sense play v corresponds senseplaying game). instance, order disambiguate first entry (i.e., giocare vA.1play, toy), determine best sense English verb play given Italianverb sense giocare A.1v . humans know since source sense playinggame, right sense playv first one. fact, among 3 senses verbplay v shown above, see first sense one translates backgiocare. words, first sense play v one contained pathstarting from, ending in, giocare A.1v , namely:giocare A.1play 1v giocare A.1vvsimilar paths involving senses playv . hunchexploiting cyclic paths able predict suitable sense ambiguoustranslation. provide scoring function weights paths according length(with shorter paths providing better clues, thus receiving higher weights) and,time, favours senses participate paths. also study effectedge reversal support disambiguating translations. hunchallowing reversal subsequent edges enable previously-missed meaningfulpaths, call quasi-cycles (e.g., recitare A.2play 3v interpretare 3v act A.1vvA.2recitare v ). anticipate including quasi-cycles significantly boosts overall disambiguation performance.3. Preliminariesprovide fundamental definitions used throughout restpaper.3.1 Bilingual Dictionarydefine bilingual machine-readable dictionary (BiMRD) quadruple =(L, Senses, , M), L bilingual lexicon (i.e., L includes lexical itemslanguages), Senses mapping that, given lexical item w L, returns set138fiCycling Graphs Semantically Enrich Enhance Bilingual Dictionarylanguage [lNgwidZ] n.1 lingua; linguaggio: foreign languages, lingue straniere; technical l., la lingua dellatecnica; l. poetry, il linguaggio poetico; dead languages, le lingue morte l.laboratory, laboratorio linguistico 2 bad l., linguaggio scorretto (o sboccato) 2 sign l.,lingua dei segni (usata dai sordomuti) 2 strong l., linguaggio violento (o volgare) 2use bad l., usare un linguaggio volgare, da trivio.2 favella: Animals possess l., gli animali non possiedono la favella.Figure 1: Entry example Ragazzini-Biagi dictionary.senses w D, translation function which, given word sense Senses(w),provides set (possibly ambiguous) translations s. Typically, (s) L, is,translations lexicon. However, might well translations (s)lexicon. Finally, function which, given word sense Senses(w),provides set words representing meta-information sense (e.g., M(phoneme 1n )= {linguistics}).instance, consider Ragazzini-Biagi English-Italian BiMRD (Ragazzini & Biagi,2006). dictionary provides Italian translations English word sense, viceversa. given source lemma (e.g., language n English), dictionary lists translations target language sense expressed lemma. Figure 1 showsdictionary entry language n . dictionary provides:lexicon two languages, i.e., set L lemmas dictionary entriesexist (such languagen Figure 1, also lingua n , linguaggio n , etc.);set senses given lemma, e.g., Senses(language n ) = {language 1n , language 2n }(the communication sense vs. speaking ability), Senses(lingua n ) = {lingua 1n , lingua 2n } (the muscular organ set words used communication, respectively);Senses(linguaggio n ) = {linguaggio 1n , linguaggio 2n , linguaggio 3n } (the faculty speaking, means communication machine language, respectively);translations given sense, e.g., (language 1n ) = {lingua n , linguaggio n };optionally, meta-information given sense, M(phoneme 1n ) = {linguistics}.dictionary also provides usage examples compound translations (see Figure 1),lexical variants (e.g., acknowledgement vs. acknowledgment) references entries(e.g., motorcar car ).3.2 Noisy GraphGiven BiMRD D, define noisy dictionary graph G = (V, E) directed graphwhere:1. V set senses dictionary (i.e., V =139wL Senses(w));fiFlati & Naviglilingua2noriginaleB.3nlinguaggio1nparlatoB.1nlinguaggio3nlanguage1nlinguaggio2ntongue1nlingua1nspeech1neloquio1nfavella2nparlareD.2nidioma1nFigure 2: excerpt Ragazzini-Biagi noisy graph including language 1n neighbours.2. word w L sense Senses(w), edge (s, s0 ) E s0sense translation dictionary (i.e., s0 Senses(w0 ) w0 (s)),s0 sense meta-word definition (i.e., s0 Senses(m)M(s)).According definition, given ambiguous word w0 definition s,add edge sense w0 dictionary. words, noisy graphG associated dictionary encodes potential meanings word translationsterms edge connections. Figure 2 show excerpt noisy graph associatedRagazzini-Biagi dictionary. sub-graph three kinds nodes found:source sense (rectangular box), namely language 1n .senses translations (thick ellipse-shaped nodes), e.g., three senseslinguaggio n two senses lingua n .senses (ellipse-shaped nodes), either translations meta-informationsenses (e.g., speech 1n translation sense eloquio 1n ).3.3 Graph Cycles Quasi-Cyclesrecall definition graph cycle. cycle graph G sequence edgesG form path v1 v2 vn (vi V {1, . . . , n}) first node140fiCycling Graphs Semantically Enrich Enhance Bilingual Dictionary...(a) cycle...(b)quasi-cycle1 (terminal)reversed edge(c) quasi-cycle1 (non terminal) reversed edge...(d)quasi-cycle2 reversed edges......(e) quasi-cyclek reversed edges...(f) illegal quasicycleFigure 3: Legal illegal cycles quasi-cycles.path corresponds last, i.e., v1 = vn (Cormen, Leiserson, & Rivest, 1990, p. 88).length cycle given number edges. example, cycle length 3Figure 2 given path:language 1n linguaggio 2n lingua 2n language 1n .provide definition quasi-cycle sequence edgesreversal orientation one consecutive edges creates cycle (Bohman &Thoma, 2000). instance, quasi-cycle length 4 Figure 2 given path:language 1n linguaggio 1n speech 1n eloquio 1n language 1n .seen reversal edge (eloquio1n , speech1n ) creates cycle. Sincedirection edge opposite cycle, call reversed edge. Finally,say path (quasi-)cyclic forms (quasi-)cycle. Note considerpaths going across senses word; language 1n lingua1n tongue 1n lingua2nlanguage 1n considered legal quasi-cycle.order provide graphical representation (quasi-)cycles, Figure 3 showdifferent kinds (quasi-)cycles starting given node s, namely: cycle (a), quasicycle 1 terminal (b) non-terminal (c) reversed edge (a reversed edge terminalincident s), reversed edges ((d) (e)), illegal quasi-cyclewhose reversed edges consecutive (f).4. CQC Algorithmready introduce Cycles & Quasi-Cycles (CQC) algorithm, whose pseudocode given Table 1. algorithm takes input BiMRD = (L, Senses, , M),141fiFlati & Navigli1234567891011CQC(BiMRD = (L, Senses, , M), sense w L)word w0 (s)sense s0 Senses(w0 )paths(s0 ) :=SDFS(s0 , s)all_paths := s0 Senses(w0 ) paths(s0 )sense s0 Senses(w0 )score(s0 ) := 0path p paths(s0 )l := length(p)1v := (l) N umP aths(all_paths,l)score(s0 ) := score(s0 ) + v(w0 ) = argmax score(s0 )12returns0 Senses(w0 )Table 1: Cycles & Quasi-Cycles (CQC) algorithm pseudocode.sense word w lexicon (i.e., w L Senses(w)). algorithmaims disambiguating words ambiguous translations w0 (s), i.e., assignright sense among listed Senses(w0 ).algorithm outputs mapping ambiguous word w0 (s)sense s0 w0 chosen result disambiguation procedure illustrate hereafter.First, sense s0 target translation w0 (s), algorithm performssearch noisy graph associated collects following kinds paths:i) Cycles:s0 s1 sn2 sn1 =ii) Quasi-cycles:s0 s1 ... sj ... sk ... sn2 sn1 =1 j n2, j < k n1(1)source sense, s0 candidate sense w0 (s), si sense listed(i {1, . . . , n 2}), sn1 = s, n length path. Note kindspath start end node s, algorithm searches quasi-cycleswhose reversed edges connecting sk sj consecutive. avoid redundancy require(quasi-)cycles simple, is, node repeated path except start/endnode (i.e., si 6= s, si 6= s0 , si 6= si0 i, i0 s. t. 6= i0 ).first step algorithm (see Table 1, lines 2-3), (quasi-)cyclic pathssought sense w0 . step performed depth-first search (DFS, cf.Cormen et al., 1990, pp. 477479) depth .2 DFS whose pseudocode2. note depth-first search equivalent breadth-first search (BFS) purpose collectingpaths.142fiCycling Graphs Semantically Enrich Enhance Bilingual Dictionary1234123456789101112131415DFS(sense s0 , sense s)paths :=visited :=Rec-DFS(s0 , s, s0 )return pathsRec-DFS(sense s0 , sense s, path p)s0 visited length(p) > returns0 =paths := paths {p}returnpush(visited, s0 )// cyclesedge s0 s00p0 := p s00Rec-DFS(s00 , s, p0 )// quasi-cyclesedge s0 s00p0 := p s00reversedEdgesNotConsecutive(p0 ) continueRec-DFS(s00 , s, p0 )pop(visited)Table 2: depth-first search pseudocode algorithm cycle quasi-cycle collection.shown Table 2 starts sense s0 Senses(w0 ), recursively explores graph;outgoing edges explored order collect cycles (lines 7-9 Rec-DFS, see Table 2)incoming edges considered order collect quasi-cycles (lines 11-14);extending current path p reversed edge, however, necessary check whetherlatter consecutive previously reversed edges (if any) present p skipotherwise (cf. Formula (1)). stack visited contains nodes visited far, orderavoid repetition node path (cf. lines 1, 5 15 Rec-DFS). Finally searchends maximum path length reached, previously visited node encountered(line 1 Rec-DFS); otherwise, initial sense found, (quasi-)cycle collected(lines 2-4 Rec-DFS). sense s0 w0 DFS returns full set paths(s0 )paths collected. Finally, line 4 Table 1, all_paths set store pathssenses w0 .second phase CQC algorithm (lines 5-10 Table 1) computes scoresense s0 w0 based paths collected s0 first phase. Let ppath, let l length, i.e., number edges path. contributionp score s0 given by:score(p) :=(l)N umP aths(all_paths, l)(2)where:143fiFlati & Naviglilingua2noriginaleB.3nparlatoB.1nlanguage1nlinguaggio2ntongue1nspeech1neloquio1nfavella2nparlareD.2nidioma1nFigure 4: Ragazzini-Biagi graph Figure 2 pruned result CQC algorithm.(l) monotonically non-increasing function length l; experiments,tested three different weight functions (l), namely constant, linearinversely exponential function (see Section 5).normalization factor N umP aths(all_paths, l) calculates overall numbercollected paths length l among target senses.way score sense s0 amounts to:Xscore(s0 ) :=ppaths(s0 )score(p) =X(l)l=2N umP aths(paths(s0 ), l)N umP aths(all_paths, l)(3)rationale behind scoring formula two-fold: first thanks functionfavours shorter paths, intuitively less likely noisy; second, pathlength, accounts ratio paths length s0 participates (secondfactor right-hand side formula above).scores sense s0 target translation w0 calculated,mapping established w0 highest-scoring sense (line 11). Finally,translations disambiguated, mapping returned (line 12).result systematic application algorithm sense BiMRDD, new graph G0 = (V, E 0 ) output, V sense inventory D,E 0 subset noisy edge set E edge (s, s0 ) E 0 resultdisambiguation algorithm run input s. Figure 4 shows clean, unambiguousdictionary graph executing CQC, compared initial noisy graph Figure2. pruned graph, sense links one sense translations.4.1 Exampleexample, consider following dictionary entry Ragazzini-Biagi dictionary:144fiCycling Graphs Semantically Enrich Enhance Bilingual Dictionarylanguage1nlingua1nlanguage1nlingua1nfavella2ntongue1nidioma1ntongue1nlanguage1nlingua2nlanguage1nlingua2nlanguage1nlingua2nlanguage1nlingua2nfavella2ntongue1nidioma1ntongue1nlanguage1nlingua2nlanguage1nlingua2nlinguaggio2nlinguaggio3nlinguaggio1nFigure 5: Cycles quasi-cycles collected DFS(lingua 1n , language 1n ) (top)DFS(lingua 2n , language 1n ) (bottom).language n. 1 lingua; linguaggio.order disambiguate Italian translations call CQC algorithm follows:CQC(D, language1n ). Let us first concentrate disambiguation linguan , ambiguous word two senses Ragazzini-Biagi. First, two calls made, namelyDF S(lingua1n , language1n ) DF S(lingua2n , language1n ). function call performsDFS starting respective sense target word collect relevant cyclesquasi-cycles according algorithm Table 2. set cycles quasi-cyclescollected two senses noisy graph Figure 2 shown Figure 5.second phase CQC algorithm, sense linguan ,contribution path calculated (lines 8-10 algorithm Table 1). Specifically,following scores calculated two senses lingua n (we assume weightfunction (l) = 1/el ):score(lingua 1n ) =2score(lingua 2n ) =++'13211e41N umP aths(all_paths,4)' 2 0.0181e12 N umP aths(all_paths,2)+11e3 N umP aths(all_paths,3) +1e14 N umP aths(all_paths,4)'110.135 1 + 3 0.050 3 + 2 0.0181414= 0.009= 0.194N umP aths(all_paths, l) total number paths length l collectedsenses linguan . Finally, sense highest score (i.e., lingua2n example)returned.Similarly, determine scores various senses linguaggion follows:145fiFlati & Navigliscore(linguaggio 1n ) =2score(linguaggio 2n ) =++'1221score(linguaggio 3n ) =11e41N umP aths(all_paths,4)' 2 0.0181e12 N umP aths(all_paths,2)+11e3 N umP aths(all_paths,3) +1e14 N umP aths(all_paths,4)'110.135 2 + 2 0.050 2 + 2 0.0181e21N umP aths(all_paths,2)14' 1 0.13514= 0.009.= 0.1265.12= 0.0675.result, sense 2 correctly selected.5. Evaluation: Dictionary Disambiguationfirst set experiments aim assess disambiguation quality CQCalgorithm compare existing disambiguation approaches. first describeexperimental setup Section 5.1, introducing bilingual dictionary used throughoutarticle, providing information dictionary graph, tuning test datasets,algorithms, parameters baselines used experiments. describeexperimental results Section 5.2.5.1 Experimental Setupsection discuss experimental setup dictionary disambiguation experiment.5.1.1 Dictionaryperformed dictionary disambiguation experiments Ragazzini-Biagi (Ragazzini& Biagi, 2006), popular bilingual English-Italian dictionary, contains 90,000lemmas 150,000 word senses.5.1.2 Dictionary Graphorder get idea difficulty dictionary disambiguation task determinedratio wrong edges graph. first calculated ratio correct edges,i.e., edges link source senses right translation senses. quantityestimated overall number translations dictionary (i.e., assumingtranslation appropriate sense dictionary) divided total number edges:PCorrectnessRatio(G) =|T (s)|sV(4)|E|ratio wrong edges calculated 1 CorrectnessRatio(G), obtainingestimate 66.4% incorrect edges noisy graph Ragazzini-Biagi dictionary.146fiCycling Graphs Semantically Enrich Enhance Bilingual DictionaryDataset# entriesTuning DatasetTest Dataset50500# translations# polysemousavg. polysemyperfect alignments801,069537654.743.9537739Table 3: Statistics tuning test datasets.5.1.3 Datasetdatasets tuning test consist dictionary entries, containing translationssource sense target language. translation item manually disambiguatedaccording sense inventory bilingual dictionary. example, given Italianentry brillante A.2, translated sparkling , vivacious , associated appropriate English sense English-Italian section sparkling vivacious (senses 3 1,respectively).tuning purposes, created dataset 50 entries, totaling 80 translations. alsoprepared test dataset 500 entries, randomly sampled Ragazzini-Biagi dictionary(250 English-Italian section, 250 Italian-English section). Overall,test dataset included 1,069 translations disambiguated. report statisticstwo datasets Table 3, including number polysemous translations averagepolysemy translation. note 44 translations test set (i.e., 4.1%total) none senses listed dictionary appropriate (including monosemoustranslations). successful disambiguation system, therefore, disambiguateitems. last column table shows number translations sense existstranslates back source lemma (e.g., car 1n translates macchina macchina 3ntranslates car ).5.1.4 Algorithmscompared following algorithms experimental framework3 , since (withexception CQC variants thereof) represent widespread graph-basedapproaches used many NLP tasks state-of-the-art performance:CQC: applied CQC algorithm described Section 4;Cycles, variant CQC algorithm searches cycles (i.e., quasicycles collected);DFS, applies ordinary DFS algorithm collects pathss0 (i.e., paths closed completing edge sequences connecting s0s). setting path s0 discarded, construction foundG sense s0 Senses(w0 );Random walks, performs large number random walks starting s0collecting paths lead s. approach successfully usedapproximate exhaustive search translation circuits (Mausam, Soderland, Etzioni,3. order ensure level playing field, provided in-house implementations algorithmswithin graph-based framework, except Personalized PageRank, used standardimplementation (http://jung.sourceforge.net).147fiFlati & NavigliWeld, Skinner, & Bilmes, 2009; Mausam, Soderland, Etzioni, Weld, Reiter, Skinner,Sammer, & Bilmes, 2010). note that, virtue simulation nature,method merely serves way collecting paths random. fact, given pathending node v, next edge chosen equiprobably among edges outgoingv.Markov chains, calculates probability arriving certain source sensestarting initial translation sense s0 averaged n consecutive steps, is,P(m)(m)ps0 ,s = n1 nm=1 ps0 ,s , ps0 ,s probability arriving node using exactlysteps starting node s0 . initial Markov chain initialized noisy(0)dictionary graph follows: v, v 0 V , (v, v 0 ) E, pv,v0 = 1/out(v),(0)out(v) outdegree v noisy graph, otherwise pv,v0 = 0.Personalized PageRank (PPR): popular variant PageRank algorithm(Brin & Page, 1998) original Markov chain approach node rankingmodified perturbating initial probability distribution nodes (Haveliwala,2002, 2003). PPR successfully applied Word Sense Disambiguation (Agirre& Soroa, 2009) thus represents competitive system compare with.order disambiguate target translation w0 source word w, translationsense s0 , concentrate probability mass s0 , apply PPR. selectbest translation sense one maximizes PPR value source word(or, equivalently, translation sense itself).Lesk algorithm (Lesk, 1986): apply adaptation Lesk algorithm which,given source sense word w word w0 occurring translation s,determine right sense w0 basis (normalized) maximum overlapentries sense s0 w0 s:|next (s) next (s0 )|,0s0 Senses(w0 ) max{|next (s)|, |next (s )|}argmaxdefine next (s) = synonyms(s) next(s), synonyms(s) set lexicalizations sense (i.e., synonyms sense s, e.g., acknowledgement vs acknowledgment) next(s) set nodes s0 connected edge (s, s0 ).algorithms explicitly collect paths (CQC, Cycles, DFS Randomwalks), tried three different functions weighting paths, namely:constant function (l) = 1 weights paths equally, independentlylength l;linear function (l) = 1/l assigns path score inversely proportionallength l;exponential function (l) = 1/el assigns score decreases exponentiallypath length.148fiCycling Graphs Semantically Enrich Enhance Bilingual DictionaryAlgorithmCQCCyclesDFSRandom walksMarkov chainsBest ConfigurationLengthSpecific parameters42 terminal reversed edges444400 random walks2-Table 4: Parameter tuning path-based algorithms.5.1.5 Parametersused tuning dataset fix parameters algorithm maximizedperformance. tuned maximum path length path-based algorithms(CQC, Cycles, DFS, Random walks Markov chains), trying lengths {1, . . . , 6}.Additionally, CQC, tuned minimum maximum values parametersj k used quasi-cyclic patterns (cf. Formula 1 Section 4). parametersdetermine position number reversed edges quasi-cyclic graph pattern.best results obtained n 1 k n 1, i.e. k = n 1, n 3 j < n 1,is, CQC yielded best performance 2 terminal reversed edges sought(cf. Section 3.3 Figure 3). Random walks, tuned number walks neededdisambiguate item (ranging 50 2,000). best parameters resultingtuning reported Table 4. Finally, PPR used standard parameters:performed 30 iterations set damping factor 0.85.5.1.6 Measuresassess performance algorithms, calculated precision (the number correctanswers number items disambiguated system), recall (the numbercorrect answers number items dataset), F1 (a harmonic meanRprecision recall, given P2P+R). Note precision recall consideritems test set appropriate sense available dictionary. orderaccount items, also calculated accuracy number correct answersdivided total number items test set.5.1.7 Baselinescompared performance algorithms three baselines:First Sense (FS) Baseline, associates first sense listed dictionarytranslation disambiguated (e.g., car 1n chosen car independentlydisambiguation context). rationale behind baseline derivestendency lexicographers sort senses according importance perceiveestimate (possibly sense-tagged) corpus;Random Baseline, selects random sense target translation;149fiFlati & NavigliDegree Baseline, chooses translation sense highest out-degree,i.e., highest number outgoing edges.5.2 Resultsready present results dictionary disambiguation experiment.5.2.1 Results without Backoff StrategyTable 5 report results algorithms test set. CQC, PPR Cyclesbest performing algorithms, achieving around 83%, 81% 75% accuracy respectively.CQC outperforms systems terms F1 large margin. results showmere use cyclic patterns lead state-of-the-art performance, is,instead, obtained quasi-cycles also considered. Including quasi-cycles leadsconsiderable increase recall, time maintaining high level precision.DFS even penalizing get backward support happenscycling patterns. Markov chains consistently outperform Random walks. hypothesizedue higher coverage Markov chains compared number randomwalks collected simulated approach. PPR considerably outperforms twoprobabilistic approaches (especially terms recall accuracy), lags behind CQC3 points F1 2 accuracy. result confirms previous findings literatureconcerning high performance PPR, also corroborates hunch quasi-cyclesdetermining factor detection hard-to-find semantic connections withindictionaries. Finally, Lesk achieves high precision, low recall accuracy, duelack lookahead mechanism.choice weighting function impacts performance path-based algorithms, 1/el performing best constant function 1 resulting worst results(this case DFS, though).random baseline represents lowerbound much lower results.Compared first sense baseline, CQC, PPR Cycles obtain better performance.result consistent previous findings tasks Senseval-3 Gloss Word SenseDisambiguation (Litkowski, 2004). However, time, contrast resultsall-words Word Sense Disambiguation (Navigli, 2009b), first frequentsense baseline generally outperforms disambiguation systems. Nevertheless, naturetwo tasks different, dictionary entries senses tend equallydistributed, whereas open text single predominant meaning determinedcontext. Degree Baseline, yields results expectations, far worseFS baseline. reason behind lies fact amount translationstranslation senses necessarily correlate mainstream meanings.attaining highest precision, CQC also outperforms algorithmsterms accuracy. However, accuracy lower F1: due F1 harmonicmean precision recall, calculating accuracy every item datasettaken account, even items appropriate sense tag given.order verify reliability tuning phase (see Section 5.1), studied F1performance CQC varying depth DFS (cf. Section 4). best resultsshown Table 6 obtained test set = 4, confirms150fiCycling Graphs Semantically Enrich Enhance Bilingual DictionaryAlgorithmCQC 1/elCQC 1/lCQC 1Cycles 1/elCycles 1/lCycles 1DFS 1/elDFS 1/lDFS 1Random walks 1/elRandom walks 1/lRandom walks 1Markov chainsPPRLeskFirst Sense BLRandom BLDegree BLP87.1487.0486.3387.1786.4984.5663.4063.4063.5683.9483.6779.3885.4683.2086.0572.6728.5358.39PerformanceRF183.32 85.19 83.3583.22 85.09 83.2682.54 84.39 82.6074.93 80.59 75.5874.34 79.96 75.0272.68 78.17 73.4337.85 47.40 39.8537.85 47.40 39.8537.95 47.52 39.9461.17 70.77 62.4960.98 70.55 62.3057.85 66.93 59.3165.37 74.08 66.7081.25 82.21 81.2731.90 46.55 34.5273.17 72.92 73.5329.76 29.13 28.5358.85 58.39 58.62Table 5: Disambiguation performance Ragazzini-Biagi dataset.CQC- e1l=276.94=382.85=485.19=584.50Table 6: Disambiguation performance CQC- e1l based F1.optimal parameter choice CQC (cf. Table 4). fact, F1 increases higher values, performance peak 85.19% obtained = 4. higher valuesobserved performance decay due noise introduced. optimal valueline previous experimental results impact DFS depth Word SenseDisambiguation (Navigli & Lapata, 2010).5.2.2 Results Backoff Strategymentioned above, experimented path-based approaches allowed returnresult; case paths found sense target word.second set experiments thus let algorithms use first sense baselinebackoff strategy whenever able give result target word.especially useful disambiguation system cannot make decisionlack knowledge dictionary graph. seen Table 7, scenario changes151fiFlati & NavigliAlgorithmCQC 1/elCQC 1/lCQC 1Cycles 1/elCycles 1/lCycles 1DFS 1/elDFS 1/lDFS 1Random walks 1/elRandom walks 1/lRandom walks 1Markov chainsPPRLeskFirst Sense BLRandom BLDegree BLPerformance FSPRF186.52 87.02 86.77 86.8186.42 86.93 86.67 86.7285.74 86.24 86.00 86.0685.55 86.05 85.80 85.8784.97 85.46 85.21 85.3183.32 83.80 83.56 83.7268.00 68.39 68.19 68.9468.00 68.39 68.19 68.9468.09 68.49 68.29 69.0482.06 82.54 82.30 82.5181.86 82.34 82.10 82.3278.76 79.22 79.00 79.3382.75 83.32 83.03 83.2683.12 83.77 83.44 83.1282.07 82.63 82.35 82.6072.67 73.17 72.92 73.5328.53 29.76 29.13 28.5358.39 58.85 58.39 58.62Table 7: Disambiguation performance Ragazzini-Biagi dataset using first sense(FS) backoff strategy.radically setting. adoption first sense backoff strategy results generallyhigher performance; notwithstanding CQC keeps showing best results, achievingalmost 87% F1 accuracy = 1/el .5.2.3 Directed vs. Undirected Settingalgorithm crucially takes advantage quasi-cyclic pattern therefore reliesheavily directionality edges. Thus, order verify beneficial impactquasi-cycles, also compared approach undirected setting, i.e., using noisygraph whose edges unordered pairs. setting similar de MeloWeikum (2010), aim detecting imprecise wrong interlanguage links Wikipedia.However, task edges wrong (in fact, remove less 2%cross-lingual interlanguage links), whereas dictionary graph contains much noise,estimated involve around 66% edges (see Section 5.1.2).test whether directionality really matters, compared CQC natural undirected counterpart, namely Undirected Cycles: algorithm collects (undirected)cycles linking target sense back source sense underlying undirected noisygraph. implement DFS undirected setting equivalentUndirected Cycles; neither implement undirected versions Random Walks,152fiCycling Graphs Semantically Enrich Enhance Bilingual DictionaryAlgorithmUndirected Cycles 1/elUndirected Cycles 1/lUndirected Cycles 1P76.6776.5676.12PerformanceRF167.16 66.73 71.6067.06 66.63 71.5066.67 66.25 71.08Table 8: Disambiguation performance Ragazzini-Biagi dataset using undirectedmodel.AlgorithmUndirected Cycles 1/elUndirected Cycles 1/lUndirected Cycles 1Performance FSPRF177.50 78.10 77.50 77.8077.40 78.01 77.40 77.7077.01 77.61 77.01 77.31Table 9: Disambiguation performance Ragazzini-Biagi dataset using undirectedmodel (using FS baseline).Markov Chains PPR, broadly equivalent Degree undirectedsetting (Upstill, Craswell, & Hawking, 2003). shown Table 8, Undirected Cycles yields66% F1 performance 71% accuracy (almost regardless function). Consistentlyprevious experiments, allowing algorithm resort FS Baseline backoff strategy boosts performance 77-78% (with = 1/el producing best results,see Table 9). Nonetheless, Undirected Cycles performs significantly worse CyclesCQC.reason behaviour lies strong disambiguation evidence provideddirected flow information. fact, accounting directionality leads considerableloss information, since would treating two different scenarios way: oneanother one t.example, directed setting two senses reciprocally link oneanother (s t) create cycle length 2 (s s); undirected setting, instead,two edges merged (s t) supporting cycles length 2 found.result considering fact translates back s, precious pieceinformation! Furthermore undirected cycle likely correspond noisy, illegalquasi-cycle (cf. Figure 3(f)), i.e., one could contain sequence whatsoever plainreversed edges. Consequently, undirected setting meaningful nonsensicalpaths lumped together.6. Dictionary Enhancementpresent application CQC algorithm problem enhancingquality bilingual dictionary.153fiFlati & Navigli6.1 Ranking Translation Sensesexplained Section 4, application CQC algorithm sense entry determines,together sense choice, ranking senses chosen translations. instance,appropriate senses translations language (cf. Section 4.1) chosenbasis following scores: 0.009 (lingua 1n ), 0.194 (lingua 2n ), 0.009 (linguaggio 1n ),0.1265 (linguaggio 2n ), 0.0675 (linguaggio 3n ). higher score target translation,higher confidence selecting corresponding sense. fact, high score clearhint high amount connectivity conveyed target translation back sourcesense. result, following senses chosen example: lingua 2n , linguaggio 2n .hunch confidence information prove useful disambiguatingdictionary translations, also identifying recurring problems dictionaries tend sufferfrom.instance, assume English word w translates Italian word w0 senseentry w0 bilingual dictionary translates back w. exampleshortcoming could fixed following: wood 2n bosco sense bosco translatesback wood (here wood 2n bosco refer forest sense). However, phenomenonalways need solved. might case w relevant (e.g., popular)translation w0 , w0 frequent term. instance, idioma 1n (idiom n english)translates language sense language idioma translation. correctexpect language translate uncommon word idioma.decide whether problem kind needs fixed (like bosco)(like idioma)? answer question exploit confidence scores outputCQC algorithm. fact, applying CQC algorithm pair wood 2n , bosco 1nobtain score 0.2 (indicating bosco 1n point back wood )4 , pairidioma 1n , language 1n get score 0.07 (pointing idioma 1n easy reachlanguage 1n ).6.2 Patterns Enhancing Bilingual Dictionarysection, propose methodology enhance bilingual dictionary usingsense rankings provided CQC algorithm. order solve relevant problems raisedZanichelli lexicographers basis professional experience, identifiedfollowing 6 issues, characterized specific graph pattern:Misalignment. first pattern kind sw sw0 6 sw , sw sensew source language, sw0 sense w0 target language, denotestranslation dictionary. instance, buy 1n translated compera 1n ,compera 1n translated buy 1n . high-ranking sense compera 1n impliesissue solved.Partial alignment. pattern kind sw sw0 sw00 w sw00 w sw0sw sw sw00 w senses source language, w00 w compound endsw, sw0 sense target language. instance, repellent 1n translatedinsettifugo 1n , turn translates insect repellent 1n .4. Note practice values greater 0.3 unlikely.154fiCycling Graphs Semantically Enrich Enhance Bilingual Dictionaryissuepatternmisalignmentbuy n. 1 (fam.) acquisto; compera.compera n. 1 purchase; shopping.swsw 0repellent n. 1 sostanza repellente; insettifugo.insettifugo n. 2 insect repellent.swsw 0persistente a. 1 persistent; persisting.persisting a. (not available dictionary).w00swsw 0sw00pass n. 3 tesserino (di autobus, ecc.).tesserino n. 1 tessera.tessera n. 1 card; ticket; pass.w0 , w00swsw0 , sw00w0sww00 wsww0sww0use referenceuse variantswswexampleswsw 0w0swpartial alignmentmissing lemmasenseentryw0inconsistent spellingw00swsw00riscontro n. 6 reply; acknowledgment.acknowledgement, acknowledgment n.ferma di ricevuta; riscontro.3 con-asciugacapelli n. 1 hair-dryer.hair dryer n. 1 asciugacapelli.Table 10: set graph patterns used enhancement suggestions.Missing lemma. pattern kind sw sw0 sw0 existdictionary. example, persistente 1a translated persistent , however latterlemma exist dictionary lexicon.Use reference. pattern kind sw sw0 sw00 sw sw0reference sw00 . example, pass 3n translated tesserino 1n , latter referstessera 1n , turn translated pass n . However, claritys sake, doublereferencing avoided within dictionaries.Use variant. pattern kind sw sw0 sw00 sw , w00variant w0 . example, riscontro 6n translated acknowledgment 1n . However,variant main form acknowledgement 1n . interests consistencymain form always preferred.Inconsistent spelling. pattern kind sw sw0 sw00 sww w0 differ minimal spelling conventions. example, asciugacapelli 1ntranslated hair-dryer 1n , hair dryer 1n translated asciugacapelli 1n .inconsistency hair-dryer hair dryer must solved favour latter,lemma defined within dictionary.Table 10 presents patterns form graphs together examples.Next, collected pattern occurrences Ragazzini-Biagi bilingual dictionaryranked CQC scores assigned corresponding translation source155fiFlati & Naviglisource sensestill 1.A.1burrasca 1nachievement 2n...target senseimmobile A.2storm 1nimpresa 2n...CQC score0.33000.32000.3100...phat 1aopera 5ngrande A.1society 2n0.00010.0001Table 11: Top- bottom-ranking dictionary issues identified using misalignment pattern.issuemisalignmentpartial alignmentmissing lemmause referenceuse variantinconsistent spelling% accepted80.040.021.084.583.598.0no. absolute118904843315955167112312Table 12: Enhancement suggestions accepted.entry. excerpt top- bottom-ranking issues misalignment patternreported Table 11.7. Evaluation: Dictionary Enhancementfollowing two subsections describe experimental setup give resultsdictionary enhancement experiment.7.1 Experimental Setupaim evaluation show higher confidence score higherimportance issue expert lexicographer. Given issue (e.g., misalignment),foresee two possible actions taken lexicographer: apply changedictionary entry ignore issue. order assess quality issues, prepareddataset 200 randomly-sampled instances kind dictionary issue (i.e., 200misalignments, 200 uses variants, etc.). Overall dataset included 1,200 issue instances(i.e., 200 6 issue types). dataset manually annotated expert lexicographers,decided issue whether change dictionary needed (positive response)(negative response). Random sampling guarantees dataset distributioncomparable entire set instances issue interest.156fiCycling Graphs Semantically Enrich Enhance Bilingual Dictionarysuggestions accepted / suggestions presented1.00.90.80.70.60.50.4score00.10.20.3Figure 6: Performance trend enhancement suggestions accepted score misalignment issue.7.2 Resultsreport results issue type Table 12. observed acceptance percentageranging 80.0 84.5% three issues, namely: misalignment, use reference use variant, thus indicating high level reliability degree importancecalculated issues. note however semantics cannot much helpcase missing lemmas, partial alignment inconsistent spelling. fact issuesinevitably cause graphs disconnected thus disambiguation scores equal 0.determine whether score-based ranking impacts degree reliabilityenhancement suggestions graphed percentage accepted suggestions scoremisalignment issue (Figure 6). expected, higher disambiguation score,higher percentage suggestions accepted lexicographers, 99% score> 0.27. observed similar trends issues.8. Synonym Extractionprevious sections, shown use cycles quasi-cycles extend bilingualdictionary entries sense information tackle important dictionary issues.propose third application CQC algorithm enrich bilingual dictionarysynonyms, task referred synonym extraction. task consists automaticallyidentifying appropriate synonyms given lemma. Many efforts madedevelop automated methods collect synonyms. Current approaches typically rely eitherstatistical methods based large corpora fully-fledged semantic networksWordNet (a survey literature field given Section 10). approachcloser latter direction, relies bilingual machine readable dictionary (i.e.,resource explicit semantic relations), rather full computational lexicon.exploit cross-language connections identify appropriate synonyms givenword using cycles quasi-cycles.157fiFlati & Navigliidea behind synonym extraction approach follows: startingnode(s) graph associated given word, perform cycle quasi-cyclesearch (cf. Section 4). words encountered cycles quasi-cycles likelyclosely related word sense started tend represent good synonymcandidates two languages. adopted two synonym extraction strategies:sense-level synonym extraction: aim task find synonyms givensense word w.word-level synonym extraction: given word w, collect union synonymssenses w.cases apply CQC obtain set paths P (respectively startinggiven sense w sense w). Next, rank candidate synonym accordingfollowing formula:score(w0 ) =XpP (w0 )1(5)elength(p)provides score synonym candidate w0 , P (w0 ) set (quasi-)cyclespassing sense w0 . sense-level strategy P (w0 ) contains paths startingsense source word w, whereas word-level strategy P (w0 ) contains pathsstarting sense w. contrast approaches literature, synonymextraction approach actually produces synonyms, also senses accordingdictionary sense inventory. Further, thanks formula, able ranksynonym senses less likely. example, given English sense capable1a ,system outputs following ordered list senses:Lang.enenenen...enWord senseabile 1acapace 2aable 1askilful 1aesperto A.1clever 1adeft 1a...crafty 1adestro A.1Score13.348.504.423.213.032.611.00...0.180.17word-level strategy, instead, synonyms found performing CQC searchstarting sense word w, thus collecting union pathsobtained individual visit. result output list wordslikely synonym candidates. example, given English word capable,system outputs following ordered list words:158fiCycling Graphs Semantically Enrich Enhance Bilingual DictionaryLang.enenenen...enWordabilecapacecleverableespertoskilfuldeft...sapienteexpertScore12.0010.653.452.902.412.300.54...0.180.169. Evaluation: Synonym Extractiondescribe experimental setup discuss results synonym extractionexperiment.9.1 Experimental Setup9.1.1 Datasetcompare performance CQC synonym extraction existing approaches,used Test English Foreign Language (TOEFL) dataset provided ETS viaThomas Landauer coming originally Educational Testing Service (Landauer& Dumais, 1997). dataset part well-known TOEFL test used evaluateability individual use understand English. dataset includes 80 questionitems, presenting:1. sentence target word w emphasized;2. 4 words listed possible synonyms w.examinee asked indicate one, among four presented choices,likely right synonym given word w. examinees language abilityestimated fraction correct answers. performance automated systemsassessed way.9.1.2 Algorithmsperformed experiments algorithms used Section 5.1.4 comparedresults best ones known literature. methods basedsort graph path cycle collection. order select best synonymtarget word, used approach described Section 8 methods Markov chainsPPR. latter replaced equation 5 corresponding scoring functionmethod (cf. Section 5.1.4). also compared best approaches synonymextraction literature, including:Product Rule (PR) (Turney, Littman, Bigham, & Shnayder, 2003): methodachieves highest performance combines various different modules.159fiFlati & Naviglimodule produces probability distribution based word closeness coefficient calculated possible answers system output merge rule appliedintegrate four distributions single one.Singular Value Decomposition (LSA) (Rapp, 2003), automatic Word SenseInduction method aims finding sense descriptors different sensesambiguous words. Given word, twenty similar words considered goodcandidate descriptors. pairs formed classified according two criteria:i) two words couple dissimilar possible; ii) cooccurrencevectors sum ambiguous word cooccurrence vector (scaled 2). Finally,words highest score selected.Generalized Latent Semantic Analysis (GLSA) (Matveeva, Levow, Farahat, &Royer, 2005), corpus-based method builds term-vectors representsdocument space terms vectors. means Singular Value DecompositionLatent Semantic Analysis obtain similarity matrix wordsprefixed vocabulary extract related document matrix. Next, synonymsword selected basis highest cosine-similarity candidatesynonym fixed word.Positive PMI Cosine (PPMIC) (Bullinaria & Levy, 2007) systematically exploresseveral possibilities representation word meanings space cooccurrence vectors, studying comparing different information metrics implementation details (such cooccurrence window corpus size).Context-window overlapping (CWO) (Ruiz-Casado, M., E., & Castells, 2005)approach based key idea synonymous words replacedcontexts. Given two words, similarity measured number contextsfound replacing word other, context restrictedL-window open-class words Google snippet.Document Retrieval PMI (PMI-IR) (Terra & Clarke, 2003) integrates manydifferent word similarity measures cooccurrence estimates. Using large corpusWeb data analyze corpus size influences measure performancecompare window- document-oriented approach.Rogets Thesaurus system (JS) (Jarmasz & Szpakowicz, 2003), exploits Rogetsthesaurus taxonomy WordNet measure semantic similarity. Given two wordscloseness defined minimum distance nodes associatedwords. work closest structure knowledge resourcesexploited extract synonyms.9.2 ResultsTable 13 14 report performance (precision recall, respectively)algorithms TOEFL maximum path length varying 2 6. bestresults obtained algorithms (except Markov chains) = 6, valuemakes easier find near synonyms cannot immediately obtained translations160fiCycling Graphs Semantically Enrich Enhance Bilingual DictionaryAlgorithmCQCCyclesDFSRandom walksMarkov chainsMaximum path234100.00 97.56 98.15100.00 97.50 97.8397.67 97.78 97.8297.44 95.12 97.5694.91 86.76 85.29length598.3698.0098.0497.6285.29693.1596.4396.3697.8385.29Table 13: Precision graph-based algorithms TOEFL dataset.AlgorithmCQCCyclesDFSRandom walksMarkov chains247.5047.5052.5047.5070.00Maximum path length345650.00 66.25 75.00 85.0048.75 56.25 61.25 67.5055.00 56.25 62.50 66.2548.75 50.00 51.25 56.2573.75 72.50 72.50 72.50Table 14: Recall graph-based algorithms TOEFL dataset.target word dictionary. attribute higher recall (but lower precision)Markov chains amount noise accumulated steps. Interestingly,PPR (which independent parameter , therefore shown Tables 13 14)obtained comparable performance, i.e., 94.55% precision 65% recall. Thus, CQCbest graph-based approach achieving 93% precision 85% recall. result corroboratesprevious findings (cf. Section 5).Table 15 shows results best systems literature comparesCQC.5 note systems performing better CQC exploit large amountinformation: example Rapp (2003) uses corpus 100 million wordseveryday written spoken language, Matveeva et al. (2005) draw1 million New York Times articles history label. Even relymanually-created lexicon, cope extremely high term-space dimension need adopt method reduce dimensionality (i.e., either using LatentSemantic Indexing term space reducing vocabulary size accordinggeneral strategy selecting top frequent words).easy see work stands lexicon-based ones, raising performance78.75% 85% recall. Table 15 also report performance lexiconbased approaches literature (Hirst & St-Onge, 1998; Leacock & Chodorow, 1998;Jarmasz & Szpakowicz, 2003). note system exploits concise editionRagazzini bilingual dictionary omits lots translations (i.e., edges) sensesfound complete edition dictionary. graph algorithm could5. information state art TOEFL test found following website: http://aclweb.org/aclwiki/index.php?title=TOEFL_Synonym_Questions_(State_of_the_art)161fiFlati & NavigliAlgorithmPRLSAGLSACQCPPMICCWOPMI-IRJSHSOPairClassDSHumanRandomLCAuthor(s) / MethodTurney et al. (2003)Rapp (2003)Matveeva et al. (2005)Flati Navigli (2012)Bullinaria Levy (2007)Ruiz-Casado et al. (2005)Terra Clarke (2003)Jarmasz Szpakowicz (2003)Hirst St-Onge (1998)Turney (2008)Pado Lapata (2007)Average non-English US college applicantRandom guessingLeacock Chodorow (1998)Resource typeHybridCorpus-basedCorpus-basedLexicon-basedCorpus-basedWeb-basedCorpus-basedLexicon-basedLexicon-basedCorpus-basedCorpus-basedHumanRandomLexicon-basedRecall (%)97.5092.5086.2585.0085.0082.5581.2578.7577.9176.2573.0064.5025.0021.88Table 15: Recall synonym extraction systems TOEFL dataset.readily take advantage richer structure complete edition achieve even betterperformance.Another interesting aspect ability CQC rank synonym candidates. betterunderstand phenomenon, performed second experiment. selected 100 senses(50 language). applied CQC algorithm alsolemmas. former case sense-tagged list returned; latter list containedwords. determined precision CQC retrieving top ranking Ksynonyms (precision@K) according algorithms score. performed evaluationsense- word-level, explained Section 8. Table 16 reportprecision@K calculated levels K = 1, . . . , 10. Note that, K sufficientlysmall (K 4), sense-level extraction achieves performance similar word-levelone, semantically precise. However, observe larger values Kperformance difference increases considerably.10. Related Workreview literature three main fields dealt paper,namely: gloss disambiguation (Section 10.1), dictionary enhancement (Section 10.2)synonym extraction (Section 10.3).10.1 Gloss DisambiguationSince late 1970s much work analysis disambiguation dictionary glossesdone. includes methods automatic extraction taxonomies lexical resources (Litkowski, 1978; Amsler, 1980), identification genus terms (Chodorow, Byrd,& Heidorn, 1985) and, general, extraction explicit information machine162fiCycling Graphs Semantically Enrich Enhance Bilingual DictionaryLevelSenseWordK1234567891012345678910Precision79.0075.5070.3367.0163.4160.3159.2457.0155.2853.0680.0074.5071.6772.5071.2068.8367.2965.8864.2262.90Correct/Given79 / 100151 / 200211 / 300266 / 397312 / 492354 / 587404 / 682443 / 777482 / 872512 / 96580 / 100149 / 200215 / 300290 / 400356 / 500413 / 600471 / 700527 / 800578 / 900629 /1000Table 16: Precision@K CQC algorithm sense word synonym extractiontask.readable dictionaries (see, e.g., Nakamura & Nagao, 1988; Ide & Vronis, 1993), wellconstruction ambiguous semantic networks glosses (Kozima & Furugori, 1993).relevant project direction MindNet (Vanderwende, 1996; Richardson, Dolan, &Vanderwende, 1998), lexical knowledge base obtained automated extractionlexico-semantic information two machine-readable dictionaries.recently, set heuristics proposed semantically annotate WordNetglosses, leading release eXtended WordNet (Harabagiu et al., 1999; Moldovan &Novischi, 2004). Among heuristics, cross reference heuristic closest techniquenotion (quasi-)cyclic patterns. Given pair words w w0 , heuristicbased occurrence w gloss sense s0 w0 and, vice versa, w0gloss sense w. words, cycle s0 length 2 sought. Recently,similar consideration put forward proposing probabilistic translation circuitsused evidence automatically acquire multilingual dictionary (Mausam et al.,2009).Based eXtended WordNet, gloss disambiguation task organized Senseval3 (Litkowski, 2004). notably, best performing systems, namely TALP system(Castillo et al., 2004), SSI (Navigli & Velardi, 2005), knowledge-based relyrich knowledge resources: respectively, Multilingual Central Repository (Atserias, Vil163fiFlati & Naviglilarejo, Rigau, Agirre, Carroll, Magnini, & Vossen, 2004), proprietary lexical knowledgebase (cf. Navigli & Lapata, 2010).However, literature field gloss disambiguation focused monolingual dictionaries, WordNet LDOCE. knowledge, CQC firstalgorithm aimed disambiguating entries bilingual dictionary: key ideaharvest (quasi-)cyclic paths dictionary viewed noisy graph useassociate meanings target translations. Moreover, contrast manydisambiguation methods literature (Navigli, 2009b), approach works bilingualmachine-readable dictionaries exploit lexical semantic relations,available computational lexicons like WordNet.10.2 Dictionary Enhancementissue improving quality machine-readable dictionaries computationalmethods poorly investigated far. Ide Vronis (1993, 1994), among others,working identification relevant issues transforming machinereadable dictionary computational lexicon. include overgenerality (e.g.,newspaper defined artifact, rather publication), inconsistent definitions (e.g.,two concepts defined terms other), meta-information labels sense divisions(e.g., fine-grained vs. coarse-grained distinctions). little work doneautomatic improvement monolingual dictionaries (Navigli, 2008), well bilingual resources, gloss rewriting algorithm proposed (Bond, Nichols, & Breen,2007). However, knowledge, structure bilingual dictionaries never previously exploited purpose suggesting dictionary enhancements. Moreover,rank suggestions basis semantic-driven confidence scores, thus submittinglexicographer pressing issues first.10.3 Synonym ExtractionAnother task aimed improving machine-readable dictionaries synonym extraction. Many efforts made automatically collect set synonyms wordinterest. introduced various methods aimed task Section 8.distinguish greater detail corpus-based (i.e., statistical) lexicon-based (orknowledge-based) approaches.Corpus-based approaches typically harvest statistical information word occurrences large corpora, inferring probabilistic clauses word w likely appear(i.e., cooccur) together word probability p. Thus, word similarity approximated word distance functions. One common goal build cooccurrence matrix;done directly via corpus analysis indirectly obtaining vector spacerepresentation.widespread statistical method (Turney et al., 2003; Bullinaria & Levy, 2007;Ruiz-Casado et al., 2005; Terra & Clarke, 2003) estimate word distance countingnumber times two words appear together corpus within fixed k-sizedwindow, followed convenient normalization. approach suffers well-knowndata sparseness problem; furthermore introduces additional window-size parameter kwhose value tuned.164fiCycling Graphs Semantically Enrich Enhance Bilingual Dictionarysimilar statistical approach consists building vocabulary terms V corpusC representing document means elements V contained therein.framework document represented vector, corpus term-document matrix Lwell document-term matrix L0 . matrix product LL0 represents cooccurrencematrix gives measure word closeness.computational reasons, however, often desirable shrink vocabulary size.Classical algebraic methods, Singular Value Decomposition (SVD), appliedsynonym extraction (Rapp, 2003; Matveeva et al., 2005), able producesmaller vocabulary V 0 representing concept space. methods takeaccount relative word position, cooccurrences within document, lessinformation usually considered. hand, virtue SVD, significantconcept space built documents suitably represented.Lexicon-based approaches (Jarmasz & Szpakowicz, 2003; Blondel & Senellart, 2002)alternative purely statistical ones. Graph models employed wordsrepresented nodes relations words edges nodes. setting,corpus required. Instead two words deemed synonyms linking path, any,satisfies structural criterion, based length, structure connectivity degree.application CQC synonym extraction problem follows direction. However,contrast existing work literature, exploit lexical semantic relationconcepts, WordNet, lexical pattern done WangHirst (2012). Further, view synonym extraction dictionary enrichment taskperform bilingual level.11. Conclusionspaper presented novel algorithm, called Cycles Quasi-Cycles (CQC),disambiguation bilingual machine-readable dictionaries. algorithm basedidentification (quasi-)cycles noisy dictionary graph, i.e., circular edge sequences(possibly consecutive edges reversed) relating source word sense target one.contribution paper threefold:1. show notion (quasi-)cyclic patterns enables state-of-the-art performanceattained disambiguation dictionary entries, surpassing disambiguation approaches (including popular PPR), well competitive baselinefirst sense heuristic. Crucially, introduction reversed edges allows usfind semantic connections, thus substantially increasing recall keepingprecision high.2. explore novel task dictionary enhancement introducing graph patternsvariety dictionary issues, tackle effectively means CQCalgorithm. use CQC rank issues based disambiguation scorepresent enhancement suggestions automatically. experiments show higherscore relevant suggestion. result, important idiosyncrasiesmissing redundant translations submitted expert lexicographers,review order improve bilingual dictionary.165fiFlati & Navigli3. successfully apply CQC task synonym extraction. data-intensiveapproaches achieve better performance, CQC obtains best result among lexiconbased systems. interesting side effect, algorithm produces sense-taggedsynonyms two languages interest, whereas state-of-the-art approachesfocus single language produce sense annotations synonyms.strength approach lies weakly supervised nature: CQC algorithmrelies exclusively structure input bilingual dictionary. Unlike researchdirections, resource (such labeled corpora knowledge bases) required.paths output algorithm dataset presented Section 5.1 availablehttp://lcl.uniroma1.it/cqc. scheduling release software packageallows application CQC algorithm resource standardinterface implemented.regards future work, foresee several developments CQC algorithmapplications: starting work Budanitsky Hirst (2006), plan experimentcycles quasi-cycles used semantic similarity measure, comparesuccessful existing approaches. Moreover, although paper focuseddisambiguation dictionary glosses, exactly approach applieddisambiguation collocations using dictionary choice (along lines Navigli,2005), thus providing way enriching lexical knowledge resources externalknowledge.Acknowledgmentsauthors gratefully acknowledge support ERC Starting Grant MultiJEDI No.259234. authors wish thank Jim McManus, Simon Bartels three anonymousreviewers useful comments paper, Zanichelli making RagazziniBiagi dictionary available research purposes.ReferencesAgirre, E., Alfonseca, E., Hall, K., Kravalova, J., Pasca, M., & Soroa, A. (2009). studysimilarity relatedness using distributional wordnet-based approaches.Proceedings Conference North American Chapter AssociationComputational Linguistics (HLT-NAACL 2009), pp. 1927, Boulder, Colorado, USA.Agirre, E., & Soroa, A. (2009). Personalizing PageRank Word Sense Disambiguation.Proceedings 12th conference European chapter AssociationComputational Linguistics (EACL 2009), pp. 3341, Athens, Greece.Amsler, R. A. (1980). structure Merriam-Webster pocket dictionary, Ph.D. Thesis.University Texas, Austin, TX, USA.Atserias, J., Villarejo, L., Rigau, G., Agirre, E., Carroll, J., Magnini, B., & Vossen, P.(2004). MEANING Multilingual Central Repository. Proceedings International Global WordNet Conference (GWC 2004), pp. 2330, Brno, Czech Republic.Bernard, J. (Ed.). (1986). Macquarie Thesaurus. Macquarie, Sydney, Australia.166fiCycling Graphs Semantically Enrich Enhance Bilingual DictionaryBlondel, V. D., & Senellart, P. P. (2002). Automatic extraction synonyms dictionary.Proceedings SIAM Text Mining Workshop, Arlington, VA, USA.Bohman, T., & Thoma, L. (2000). note sparse random graphs cover graphs.Electronic Journal Combinatorics, 7 (1), 19.Bond, F. C., Nichols, E., & Breen, J. W. (2007). Enhancing dictionary transfer ruleacquisition. Linguistic Research, 24 (2), 133151.Brin, S., & Page, M. (1998). Anatomy large-scale hypertextual web search engine.Proceedings 7th Conference World Wide Web (WWW), pp. 107117, Brisbane,Australia.Budanitsky, A., & Hirst, G. (2006). Evaluating WordNet-based measures semantic distance. Computational Linguistics, 32 (1), 1347.Bullinaria, J. A., & Levy, J. P. (2007). Extracting semantic representations wordco-occurrence statistics: computational study. Behavior Research Methods, 39 (3),510526.Castillo, M., Real, F., Asterias, J., & Rigau, G. (2004). TALP systems disambiguating WordNet glosses. Proceedings ACL 2004 SENSEVAL-3 Workshop, pp. 9396,Barcelona, Spain.Chodorow, M., Byrd, R., & Heidorn, G. (1985). Extracting semantic hierarchies largeon-line dictionary. Proceedings Association Computational Linguistics (ACL1985), pp. 299304, Chicago, IL, USA.Cormen, T. H., Leiserson, C. E., & Rivest, R. L. (1990). Introduction algorithms. MITPress, Cambridge, MA.Cuadros, M., & Rigau, G. (2006). Quality assessment large scale knowledge resources.Proceedings Empirical Methods Natural Language Processing (EMNLP 2006),pp. 534541, Sydney, Australia.Cuadros, M., & Rigau, G. (2008). KnowNet: Building large net knowledgeweb. Proceedings 22nd International Conference Computational Linguistics(COLING), pp. 161168, Manchester, UK.de Melo, G., & Weikum, G. (2010). Untangling cross-lingual link structure Wikipedia.Proceedings 48th Annual Meeting Association Computational Linguistics (ACL 2010), pp. 844853, Uppsala, Sweden. Association ComputationalLinguistics.Fellbaum, C. (Ed.). (1998). WordNet: Electronic Database. MIT Press, Cambridge, MA.Gabrilovich, E., & Markovitch, S. (2009). Wikipedia-based semantic interpretation natural language processing. Journal Artificial Intelligence Research (JAIR), 34, 443498.Harabagiu, S., Miller, G., & Moldovan, D. (1999). WordNet 2 - morphologically semantically enhanced resource. Proceedings Special Interest Group LexiconAssociation Computational Linguistics (SIGLEX 99), pp. 18, Maryland,USA.167fiFlati & NavigliHaveliwala, T. H. (2002). Topic-sensitive PageRank. Proceedings 11th InternationalConference World Wide Web (WWW 2002), pp. 517526.Haveliwala, T. H. (2003). Topic-sensitive pagerank: context-sensitive ranking algorithmweb search. IEEE Transactions Knowledge Data Engineering, 15 (4), 784796.Hirst, G., & St-Onge, D. (1998). Lexical chains representations context detectioncorrection malapropisms. Fellbaum, C. (Ed.), WordNet: electronic lexicaldatabase, pp. 305332. MIT Press.Ide, N., & Vronis, J. (1993). Extracting knowledge bases machine-readable dictionaries: wasted time?. Proceedings Workshop Knowledge BasesKnowledge Structures, pp. 257266, Tokyo, Japan.Ide, N., & Vronis, J. (1994). Machine readable dictionaries: learned,go?. Proceedings COLING 94 International Workshop DirectionsLexical Research, Beijing, China.Jacquemin, B., Brun, C., & Roux, C. (2002). Enriching text semantic disambiguationInformation Extraction. Proceedings Workshop Using SemanticsInformation Retrieval Filtering 3rd International Conference LanguageResources Evaluations (LREC 2002), Las Palmas, Spain.Jarmasz, M., & Szpakowicz, S. (2003). Rogets thesaurus semantic similarity. Proceedings International Conference Recent Advances Natural Language Processing (RANLP 2003), pp. 212219, Borovets, Bulgaria.Kozima, H., & Furugori, T. (1993). Similarity words computed spreading activation english dictionary. Proceedings Association ComputationalLinguistics (ACL 1993), pp. 232239, Utrecht, Netherlands.Krovetz, R., & Croft, W. B. (1992). Lexical ambiguity Information Retrieval. ACMTransactions Information Systems, 10 (2), 115141.Landauer, T. K., & Dumais, S. T. (1997). Solution Platos Problem: Latent Semantic Analysis Theory Acquisition, Induction Representation Knowledge.Psychological Review, 104 (2), 211240.Leacock, C., & Chodorow, M. (1998). Combining local context WordNet similarityword sense identification. Fellbaum, C. (Ed.), WordNet: electronic lexicaldatabase, pp. 265283. MIT Press.Lesk, M. (1986). Automatic sense disambiguation using machine readable dictionaries:tell pine cone ice cream cone. Proceedings 5th Special InterestGroup Design Communication (SIGDOC), pp. 2426, New York, NY.Lita, L. V., Hunt, W. A., & Nyberg, E. (2004). Resource analysis Question Answering. Proceedings 42th Annual Meeting Association ComputationalLinguistics (ACL 2004), Interactive poster demonstration sessions, pp. 162165,Barcelona, Spain.Litkowski, K. C. (1978). Models semantic structure dictionaries. American JournalComputational Linguistics, 81, 2574.168fiCycling Graphs Semantically Enrich Enhance Bilingual DictionaryLitkowski, K. C. (2004). SENSEVAL-3 task: Word-Sense disambiguation WordNet glosses.Proceedings ACL 2004 SENSEVAL-3 Workshop, pp. 1316, Barcelona, Spain.Mandala, R., Tokunaga, T., & Tanaka, H. (1998). use WordNet InformationRetrieval. Proceedings COLING/ACL Workshop Usage WordNet NaturalLanguage Processing Systems, pp. 3137, Montreal, Canada.Martnez, D., de Lacalle, O. L., & Agirre, E. (2008). use automatically acquiredexamples all-nouns Word Sense Disambiguation. Journal Artificial IntelligenceResearch (JAIR), 33, 79107.Matveeva, I., Levow, G., Farahat, A., & Royer, C. (2005). Generalized latent semanticanalysis term representation. Proceedings International ConferenceRecent Advances Natural Language Processing (RANLP 2005), Borovets, Bulgaria.Mausam, Soderland, S., Etzioni, O., Weld, D., Skinner, M., & Bilmes, J. (2009). Compilingmassive, multilingual dictionary via probabilistic inference. Proceedings Association Computational Linguistics International Joint Conference NaturalLanguage Processing (ACL-IJCNLP 2009), pp. 262270, Singapore.Mausam, Soderland, S., Etzioni, O., Weld, D. S., Reiter, K., Skinner, M., Sammer, M., &Bilmes, J. (2010). Panlingual lexical translation via probabilistic inference. ArtificialIntelligence, 174 (9-10), 619637.Mihalcea, R. (2005). Unsupervised large-vocabulary word sense disambiguation graphbased algorithms sequence data labeling. Proceedings Human LanguageTechnology Conference Conference Empirical Methods Natural LanguageProcessing (HLT/EMNLP), pp. 411418, Vancouver, BC.Moldovan, D., & Novischi, A. (2002). Lexical chains Question Answering. ProceedingsInternational Conference Computational Linguistics (COLING), pp. 17, Taipei,Taiwan.Moldovan, D., & Novischi, A. (2004). Word Sense Disambiguation WordNet glosses.Computer Speech & Language, 18 (3), 301317.Nakamura, J.-I., & Nagao, M. (1988). Extraction semantic information ordinaryEnglish dictionary evaluation. Proceedings 12th International Conference Computational Linguistics (COLING), pp. 459464, Budapest, Hungary.Nastase, V. (2008). Topic-driven multi-document summarization encyclopedic knowledge spreading activation. Proceedings Conference Empirical MethodsNatural Language Processing (EMNLP 2008), pp. 763772, Honolulu, Hawaii.Nastase, V., & Szpakowicz, S. (2001). Word Sense Disambiguation Rogets ThesaurusUsing WordNet. Proceedings NAACL WordNet Lexical Resourcesworkshop, pp. 1722, Pittsburgh, USA.Navigli, R. (2005). Semi-automatic extension large-scale linguistic knowledge bases.Proceedings Eighteenth International Florida Artificial Intelligence Research Society Conference (FLAIRS), pp. 548553, Clearwater Beach, Florida.Navigli, R. (2008). structural approach automatic adjudication word sensedisagreements. Journal Natural Language Engineering, 14 (4), 293310.169fiFlati & NavigliNavigli, R. (2009a). Using Cycles Quasi-Cycles disambiguate dictionary glosses.Proceedings 12th conference European chapter AssociationComputational Linguistics (EACL 2009), pp. 594602.Navigli, R. (2009b). Word Sense Disambiguation: Survey. ACM Computing Surveys,41 (2), 169.Navigli, R. (2012). Quick Tour Word Sense Disambiguation, Induction RelatedApproaches. Proceedings 38th International Conference Current TrendsTheory Practice Computer Science (SOFSEM 2012), pindlerv Mln, CzechRepublic.Navigli, R., Faralli, S., Soroa, A., de Lacalle, O. L., & Agirre, E. (2011). Two birdsone stone: learning semantic models Text Categorization Word Sense Disambiguation. Proceedings 20th ACM Conference Information KnowledgeManagement (CIKM 2011), pp. 23172320, Glasgow, United Kingdom.Navigli, R., & Lapata, M. (2010). experimental study graph connectivity unsupervised Word Sense Disambiguation. IEEE Transactions Pattern AnaylsisMachine Intelligence (TPAMI), 32 (4), 678692.Navigli, R., & Ponzetto, S. P. (2010). BabelNet: Building large multilingual semanticnetwork. Proceedings 48th Annual Meeting Association Computational Linguistics (ACL 2010), pp. 216225, Uppsala, Sweden.Navigli, R., & Velardi, P. (2005). Structural semantic interconnections: knowledge-basedapproach Word Sense Disambiguation. IEEE Transactions Pattern AnalysisMachine Intelligence (TPAMI), 27 (7), 10751088.Pado, S., & Lapata, M. (2007). Dependency-based construction semantic space models.Computational Linguistics, 33 (2), 161199.Pedersen, T., Banerjee, S., & Patwardhan, S. (2005). Maximizing semantic relatednessperform Word Sense Disambiguation. University Minnesota SupercomputingInstitute Research Report UMSI 2005/25, Minnesota.Ponzetto, S. P., & Navigli, R. (2010). Knowledge-rich Word Sense Disambiguation rivalingsupervised system. Proceedings 48th Annual Meeting AssociationComputational Linguistics (ACL 2010), pp. 15221531, Uppsala, Sweden.Proctor, P. (Ed.). (1978). Longman Dictionary Contemporary English. Longman Group,UK.Ragazzini, G., & Biagi, A. (Eds.). (2006). Il Ragazzini-Biagi, 4th Edition. Zanichelli, Italy.Rapp, R. (2003). Word sense discovery based sense descriptor dissimilarity. ProceedingsNinth Machine Translation Summit, pp. 315322, New Orleans, LO, USA.Richardson, S. D., Dolan, W. B., & Vanderwende, L. (1998). MindNet: acquiring structuring semantic information text. Proceedings International ConferenceComputational Linguistics (COLING 1998), pp. 10981102, Montreal, Quebec,Canada.Roget, P. M. (1911). Rogets International Thesaurus (1st edition). Cromwell, New York,USA.170fiCycling Graphs Semantically Enrich Enhance Bilingual DictionaryRosso, P., Molina, A., Pla, F., Jimnez, D., & Vidal, V. (2004). Information retrieval textcategorization semantic indexing. Proceedings Intelligent Text ProcessingComputational Linguistics Conference (CICLing), pp. 596600, Seoul, Korea.Ruiz-Casado, M., A., E., & Castells, P. (2005). Using context-window overlapping synonym discovery ontology extension. Proceedings International ConferenceRecent Advances Natural Language Processing (RANLP 2005), Borovets, Bulgaria.Sanderson, M. (2000). Retrieving good sense. Information Retrieval, 2 (1), 4969.Silber, H. G., & McCoy, K. F. (2003). Efficient text summarization using lexical chains.Proceedings 5th Conference Intelligent User Interfaces (IUI), pp. 252255, NewOrleans, USA.Terra, E., & Clarke, C. (2003). Frequency estimates statistical word similarity measures.Proceedings 2003 Human Language Technology North American Chapter Association Computational Linguistics Conference (HLT/NAACL 2003), pp.244251, Edmonton, Canada.Turney, P. D. (2008). uniform approach analogies, synonyms, antonyms, associations. Proceedings 22nd International Conference ComputationalLinguistics (COLING), pp. 905912, Manchester, UK.Turney, P. D., Littman, M. L., Bigham, J., & Shnayder, V. (2003). Combining independent modules solve multiple-choice synonym analogy problems. ProceedingsInternational Conference Recent Advances Natural Language Processing(RANLP 2003), pp. 101110, Borovets, Bulgaria.Upstill, T., Craswell, N., & Hawking, D. (2003). Predicting fame fortune: PageRankIndegree?. Proceedings Australasian Document Computing Symposium, pp.3140, Canberra, Australia.Vanderwende, L. (1996). analysis noun sequences using semantic information extracted on-line dictionaries, Ph.D. Thesis. Georgetown University, Washington,USA.Wang, P., & Domeniconi, C. (2008). Building semantic kernels text classification usingWikipedia. Proceedings 14th ACM SIGKDD International ConferenceKnowledge Discovery Data Mining (KDD), pp. 713721, Las Vegas, Nevada.Wang, T., & Hirst, G. (2012). Exploring patterns dictionary definitions synonymextraction. Journal Natural Language Engineering, 18.Woodsend, K., & Lapata, M. (2011). WikiSimple: Automatic simplification wikipediaarticles. Proceedings Twenty-Fifth AAAI Conference Artificial Intelligence(AAAI), pp. 927932, San Francisco, California, USA.Yarowsky, D. (1992). Word-sense disambiguation using statistical models Rogetscategories trained large corpora. Proceedings 14th International ConferenceComputational Linguistics (COLING 1992), pp. 454460, Nantes, France.171fiJournal Artificial Intelligence Research 43 (2012) 43-86Submitted 07/11; published 01/12Robust Local Search Solving RCPSP/maxDurational UncertaintyNa FuHoong Chuin LauPradeep Varakanthamna.fu.2007@phdis.smu.edu.sghclau@smu.edu.sgpradeepv@smu.edu.sgSchool Information Systems,Singapore Management University,80 Stamford Road, 178902 SingaporeFei Xiaofeixiao@gmail.comGoogle Inc.1600 Amphitheatre Parkway Mountain View,CA 94043 USAAbstractScheduling problems manufacturing, logistics project management frequently modeled using framework Resource Constrained Project SchedulingProblems minimum maximum time lags (RCPSP/max). Due importanceproblems, providing scalable solution schedules RCPSP/max problemstopic extensive research. However, existing methods solving RCPSP/max assumedurations activities known certainty, assumption holdreal world scheduling problems unexpected external events manpoweravailability, weather changes, etc. lead delays advances completion activities.Thus, paper, focus providing scalable method solving RCPSP/maxproblems durational uncertainty. end, introduce robust local searchmethod consisting three key ideas: (a) Introducing studying properties twodecision rule approximations used compute start times activities respect dynamic realizations durational uncertainty; (b) Deriving expression robustmakespan execution strategy based decision rule approximations; (c) robustlocal search mechanism efficiently compute activity execution strategies robustdurational uncertainty. Furthermore, also provide enhancements local searchexploit temporal dependencies activities. experimental results illustraterobust local search able provide robust execution strategies efficiently.1. IntroductionResearch scheduling typically considered problems deterministic durations.real-world scheduling problems, unexpected external events manpower availability,weather changes, etc. lead uncertainty durations activities.growing interest account data uncertainty (Herroelen & Leus, 2005; Beck &Wilson, 2007; Rodrguez, Vela, Puente, & Hernandez-Arauzo, 2009) providing optimized schedules. paper also focuses important issue durational uncertaintyscheduling problems. specifically, consider scheduling problemscomplex resource constraints temporal dependencies activities.c2012AI Access Foundation. rights reserved.fiFu, Lau, Varakantham, & Xiaobroadly two approaches tackling scheduling problems durationaluncertainty. One adopt hybrid proactive reactive methods, e.g., workVonder, Demeulemeester, Herroelen (2007), initial baseline schedulecomputed offline, modified (if required) execution reactively basedoccurrence external events. second approach, e.g., paper MohringStork (2000), design schedule policies provide online decision rulestime t, policy decides task(s) may start resource(s) assign.paper, adopt latter approach focus computation robust schedulepolicy.computational perspective, stochasticity adds great deal complexityunderlying deterministic scheduling problem. example, infinite-resource projectscheduling problem processing times two possible discrete values, problemcomputing expected makespan (or point cumulative distributionoptimal makespan), #P-hard (Hagstrom, 1988; Mohring,2001). also shownPscheduling problem 1|stoch pj ; dj = d|E[ wj Uj ], problem computingpolicy (i.e., execution strategy) maximizing probability job completes exactlydeadline PSPACE-hard (Dean, Goemans, & Vondrak, 2004). Daniels Carrillo(1997) consider one-machine scheduling problem probabilistic durations,objective capture likelihood schedule yields actual performance worsegiven target level. shown NP-hard even though underlyingdeterministic problem solved polynomial time.concrete problem interest paper Resource Constrained ProjectScheduling Problem minimum maximum time lags (abbrev. RCPSP/max),great importance manufacturing, logistics project management. Thoughproblems shown NP-Hard (Bartusch, Mohring, & Radermacher, 1988),local search based techniques (Demeulemeester & Herroelen, 2002) achieved greatsuccess solving problems. Taking cue recent advancementsrobust optimization, propose robust local search method solving RCPSP/maxproblem durational uncertainty risk management perspective. precisely,(a) employ concepts robust optimization compute robust makespanproven success probability (or risk failure) execution strategy; (b) uselocal search methods computing execution strategy seeks minimize robustmakespan.recent approach (Beck & Wilson, 2007) provides techniques compute robustbaseline schedule risk management perspective, durations activitiesmodeled random variables. Given value 0 < 1, interested compute schedule minimal (probabilistic) makespan probability successfulexecution least 1 realizations durational uncertainty. maincontribution derive lower bound -makespan given schedulesolving deterministic problem. considered Job-shop Scheduling Problem (JSP)represents special case RCPSP/max (which problem interestpaper).Unlike JSPs, complex resource constraints activity dependenciesRCPSP/max problems durational uncertainty. account these, computeexecution strategy (also known commonly schedule policy) called Partial Order Schedule44fiRobust Local Search Solving RCPSP/max Durational Uncertainty(POS) instead schedule. combine techniques robust optimization classicallocal search compute POS minimizes robust makespan. robust makespanvalue probability realized makespan schedule (derivedPOS) exceed greater (1 ), realizations uncertainty. Thus,compute upper bound makespan values opposed lower bound computationwork Beck Wilson (2007).specifically, make three key contributions paper. Firstly, introducetwo decision rule approximations define expressions start times activities basedrandom variables used represent durational uncertainties: (a) Segregated LinearApproximation(SLA) (b) Generalized Non-Linear Approximation (GNLA). Secondly,derive expressions upper bound robust makespan employing one sidedChebyshevs inequality decision rule approximations above. Finally, perform localsearch execution strategy using robust makespan upper bound. also provideenhancements consider feedback robustness execution strategies improveperformance local search.order demonstrate effectiveness methods, evaluate performancebenchmark problem sets RCPSP/max Job-shop Scheduling Problems (JSPs)durational uncertainty. Furthermore, make house comparison amongst variousenhancements developed paper. Finally, due absence competing algorithmssolving RCPSP/max problems provide indication performance providedrobust local search, compare existing best solver JSPs durationaluncertainty.next section, present brief background models solution conceptsreferred paper. present decision rule approximations Section 3computation robust makespan upper bound Section 4. detailed descriptionrobust local search enhancements provided Section 5 Section 6. Finally,experimental setup results provided Section 7.2. Preliminariessection, briefly describe notations along scheduling modelsrobust optimization concepts relevance paper.2.1 Definitions Notationsgiven Ben-Tal Nemirovski (2002), also classify variables stochasticoptimization problem 2 types: Adjustable Non-Adjustable variables.Definition 1. Non-Adjustable variables priori decisions must madeactual realization uncertainty.Definition 2. Adjustable variables (also known recourse variables) wait-and-seevariables adjust part uncertain data become known.example, scheduling problem RCPSP uncertain task durations,non-adjustable variables represent execution policy, e.g., POS proposedPolicella, Smith, Cesta, Oddi (2004), need constructed priori,45fiFu, Lau, Varakantham, & Xiaoadjustable variables associated actual start times tasks,set respect execution policy dynamic realizations uncertainty.random variable denoted x bold face lower case letters xrepresent vectors.2.2 RCPSP/maxdescribe deterministic RCPSP/max scheduling problem along extension handle durational uncertainty. also explain execution policy uncertainduration extension RCPSP/max.2.2.1 Deterministic RCPSP/maxRCPSP/max problem (Bartusch et al., 1988) consists N activities {a1 , a2 ..., },activity aj (j = 1, ...N ) executed certain amount time unitswithout preemption. activity aj fixed duration processing time dj ,assumed non-negative real number non-negative integer number. addition,dummy activities a0 +1 d0 = dN +1 = 0 introduced represent beginningcompletion project, respectively.start time schedule ss assignment start times activities a1 , a2 ..., , i.e.vector ss = (st(a1 ), st(a2 ), ...st(aN )) st(ai ) represents start time activity aist(a0 ) assumed 0. Let et(ai ) end time activity ai . Since durationsdeterministic preemption allowed,st(ai ) + di = et(ai ).(1)project makespan also start time final dummy activity st(aN +1 )equalsst(aN +1 ) = maxi=1,...N et(ai ).(2)Schedules subject two kinds constraints, temporal constraints resourceconstraints. Temporal constraints restrict time lags activities. minimumtime lag Tijmin start time two different activities ai aj saysst(aj ) st(ai ) Tijmin(3)Specially, Tijmin = 0 means activity aj cannot started activity ai begins.maximum time lag Tijmax start time two different activities ai aj saysst(aj ) st(ai ) Tijmax(4)Tijmax = 0 means activity aj cannot started activity ai begins.definition, time lags connect start times two related activities, knownstart-to-start time lags. start-to-end, end-to-end, end-to-start time lags easily transformed general start-to-start time lags deterministic case given Bartuschet al. (1988). schedule ss = (st(a1 ), st(a2 ), ...st(aN )) time feasible, time lagconstraints satisfied start times st(ai ) (i = 1, ...N ).resource unit reusable available another activity longer usedcurrent activity. type resource limited capacity, Ck (k = 1, 2..., K)46fiRobust Local Search Solving RCPSP/max Durational Uncertaintyunits. activity ai requires rik units resource type k k = 1, 2..., K. LetA(t) = {i {1, 2...N }|st(ai ) et(ai )} set activities processedtime instant t. schedule resource feasible time instant t, total demandresource k exceed capacity Ck , i.e.Xrik Ck .(5)iA(t)schedule ss called feasible time resource feasible. objectivedeterministic RCPSP/max scheduling problem find feasible scheduleproject makespan minimized.Figure 1: Project Instance.1timeFigure 2: Example Schedule.47fiFu, Lau, Varakantham, & XiaoExample 1. Figure 1, show simple example deterministic RCPSP problemspecial case RCPSP/max precedence constraints (rather arbitrary time lags) activities expository purposes. circle indicates activitynumber inside circle representing activity ID. two numbers topactivity represent duration number units resource requiredactivity. example, 9 activities one type resource, capacityresource limited 10. noted activities 0 10 dummy activities introduced source sink dependency graph. Arrows activitiesrepresent temporal dependencies. feasible schedule makespan 13 representedFigure 2.2.2.2 RCPSP/max Durational Uncertainty Robust Makespanpaper, consider RCPSP/max problems durational uncertainty. durationactivity specified sum mean value deviation: di = d0i + zi , d0imean di zi perturbation part expected value 0 standarddeviation . noted irrespective distribution type, alwaysrepresent di di = d0i + zi d0i mean zi perturbation partE(zi ) = 0. addition, also assume random variables, {zi }, correspondingdurational uncertainty independent other.Similar deterministic RCPSP/max, start-to-start constraints still deterministic. However, unlike deterministic case, types constraints (end-to-startetc.) cannot converted deterministic start-to-start constraints . Instead equivalent start-to-start constraint stochastic one shown following expressionsend-to-start constraint. noted even though converted constraintsstochastic, techniques still applicable (with minor modifications) typestime lag constraints. robust local search techniques depend computationmaximum sum random variables even stochastic time lag constraintsremains case. paper, purposes exposition, present techniquesassuming temporal dependencies provided start-to-start constraints.st(aj ) et(ai ) Tijmaxst(aj ) (st(ai ) + di ) Tijmaxst(aj ) st(ai ) Tijmax + dideterministic setting, start time schedules computed values makespanused evaluate performance schedule. However, durational uncertainty involved, project makespan becomes random variable schedulereplaced execution strategy. following sections, introduce PartialOrder Schedule (POS) (Policella et al., 2004), serves execution strategyscheduling project.Given level risk 0 < 1, goal problem find strategy minimum value (across strategies) robust makespan. definerobust makespan makespan value probability feasible schedule (i.e.assignment start times activities) instantiated strategy completedrobust makespan least 1 .48fiRobust Local Search Solving RCPSP/max Durational Uncertainty2.2.3 Partial Order SchedulePartial Order Schedule (POS) first proposed Policella et al. (2004). definedset activities, partially ordered schedule total activity orderconsistent partial order resource time feasible. Mathematically, POSrepresented graph node represents activity edges representprecedence constraints activities. Within POS, activity retains setfeasible start times, provide flexibility respond unexpected disruptions.POS constructed given RCPSP instance via chaining algorithm (whereone algorithm described below).1Figure 3: Example POSExample 2. Figure 3 provides POS problem instance introduced Example 1.10 units resource shown left side figure.unit represents chain. activity require multiple resource units henceshown multiple resource units. instance, activity 6 shown resource units4, 7 8. solid arrow activities represents temporal dependency providedoriginal problem. Solid arrow activities 1 2 one example.dotted arrow activities represents temporal dependency introduced sinceactivities executed resource unit. added remove resourceconflict. example dependency introduced activity 2 activity6. explanatory purposes consider one resource type example, howevergeneral case, exists multiple resource types dependency diagramevery resource type.2.2.4 Chaining AlgorithmChaining procedure dispatching activities different resource units (henceforthreferred chains) based temporal resource feasibility. chainingprocess, activity allocated one resource chains based numberresource requirement activity. chaining process, activityscheduled executed resource unit, additional edge (indicating precedence49fiFu, Lau, Varakantham, & Xiaorelationship) added last activity selected chain activityeliminate possible resource conflicts.following, describe basic chaining algorithm proposed Policella et al.(2004). algorithm, feasible schedule first obtained using simple greedy heuristic.Consequently, POS constructed chaining method follows: First, setactivities sorted according start times given feasible solution; Then,activities allocated different chains order, chain correspondsunit certain type resource. chain called available activity end timelast activity allocated chain greater start time activityfeasible schedule. activity allocated chain, precedence constraintactivity last activity chain posted. activitiesrequire one unit one types resources, allocatednumber chains number equal overall number resource units requiredactivity.Example 3. Take Figure 3 example. Given schedule Figure 2 input,activitiesfirst sorted according starting time sequence activities presentedas: (7,1,2,8,3,5,4,6,9). chaining procedure first picks activity 7 randomly allocatesfive chains fulfill resource requirement. available chains belongingdummy activity 0.Thus, five chains 1 5 created posts precedencerelationship current last activity 0 activity 7. Activity 7 becomes lastactivity chains. Activity 1 treated way. available chainsactivity 2 belonging activity 1. Activity 2 randomly assigned chain 810 edge activity 1 activity 2 indicating precedence relationshipadded. procedure continues activities dispatched chains numberequals resource requirement, finally chained POS 3 yielded. However,randomness chaining procedure, activity 6 allocated chains belongthree different activities: activity 2, activity 1 activity 7. tie togetherexecution three previously unrelated activities: (activity 2, activity 6),(activity 1, activity6) (activity 7, activity 6), would decrease flexibility execution.reduce inter-dependencies activities much possible chainingprocedure, Policella, Cesta, Oddi, Smith (2009) developed two heuristics. One directadvantage approaches synchronization points solution reduced:Activities require one resource units allocated subsetchains. achieved scanning list available chains last activitychain : (a) requires multiple resource units; (b) also previously assignedanother resource unit allocated current activity.Activities precedence constraint defined original problem allocatedset chains. implemented choosing chain lastactivity precedence constraint current activity.Example 4. Figure 4 provides POS computed using mentioned chainingalgorithm RCPSP problem described Example 1. allocating activity 6,50fiRobust Local Search Solving RCPSP/max Durational Uncertainty1Figure 4: POS computed Removed Synchronization Pointavailable chains divided two sets: {chain 10, chain 9} {chain 8, chain7,chain6}. first set contains chains last activity (i.e. activity 5) alreadyordered problem definition respect activity 6. chain (for example, chain 10)randomly chosen set last activity activity 5. Then, remainingavailable chains activity 6 redivided two sets: {chain 9} {chain 8, chain7,chain6}. first set contains chains activity 5 (i.e. last activity firstpicked chain) last activity second set remaining. Activity 6 firstallocated chains belonging first subset satisfy remaining resource requirements.case, synchronization points caused activities 1 6, activities 7 6allocated different chains disappeared.2.3 Job-shop Scheduling Problem (JSP) Durational Uncertaintyclassical JSP consists set n jobs set machines. job Ji (i = 1, ...n)consists sequence ni operations denoted Oij (j = 1, ...ni )processed given order.P convenience, enumerate operations jobs Ok ,k = 1, ...N N = nj=1 nj . operation Ok positive duration denoteddk must executed dedicated machine denoted Mk . operationstarted must executed entire duration. operations requireresource overlap execution. Thus, operations partitioned two sets:job sets resource sets. Job sets referring operations corresponding jobresource sets referring operations require resource.solution total ordering operations resource set, conflictjob ordering. path solution sequence operations followsjob ordering ordering various resource sets solution s. lengthpath equal sum durations operations path. makespansolution make(s) length longest path. minimum makespanJSP problem defined minimum value makespans solutions, i.e.mins make(s). operation Ok associated start time st(Ok ) end time51fiFu, Lau, Varakantham, & Xiaoet(Ok ). schedule assignment starting times st(Ok ) (k = 1, ...N ) operationsmachines. objective find schedule optimizes total makespan(makespan completion time last operation): maxNk=1 et(Ok ), alsominimum value longest path solutions. job shop scheduling problemspecial case RCPSP resources unary capacity activity (i.e.operation) consumes one resource.propagate notations RCPSP/max durational uncertaintyJSP durational uncertainty, i.e. processing time activity (i.e. operation)dOk modeled sum expected value d0Ok random part zOk : dOk =d0Ok + zOk . objective find robust makespan given level risk.2.4 Segregated Random Variablesprimitive random variable zk one zero mean. Examples primitive randomvariable include U (a, a) (uniform distribution constants a) N (0, )(normal distribution mean 0 variance 2 ). mentioned earlier, assumeevery uncertain distribution equal sum nominal value (mean)deviation, represented one (or possibly more) primitive random variable z. straightforward representation, one primitive random variable zk associateduncertain variable. recent work Chen, Sim, Sun, Zhang (2008), primitiverandom variable zk represented 2 segregated random variables zk+ (read z-plus) zk(z-minus):z = z + z(6)z = max {z, 0}(7)+z = max {z, 0} .(8)following Table 1, give examples respective values mean p ,variance p 2 , 2 segregated variables z + z .zU (a, a)N (0, )V ar(z)p 2 , 2p ,ma25a248(1) 224232Table 1: Values mean variance segregated variables UniformNormal Distributionunderlying assumption use segregated random variables meanvariance individual segregated variables provided random variablesemployed. aware mean variance values segregated variablesdistributions normal uniform.2.5 Decision Rules Optimization Data Uncertaintyoptimization problems data uncertainty, decision rule specifies dependenceadjustable variables uncertainty parameters non-adjustable variables. Let z52fiRobust Local Search Solving RCPSP/max Durational Uncertaintyx denote set primitive random variables non-adjustable variables respectively.example linear decision rule framework proposed Ben-Tal Nemirovski(2002), setting value adjustable decision variable S(x, z) assumedaffinely dependent subset N number primitive random variables:S(x, z) = c0 +NXck (x)zk(9)k=1ck (x) (1 k N ) coefficient derived x.Another example segregated linear decision rule framework proposed Chenet al. (2008), adjustable decision variableassumed tobe affinely dependent++set N segregated random variables z1 , z1 , . . . , zN, zN . Hence, segregatedlinear decision rule following general form:S(x, z) = c0 +PNk=1+c+z+czk kk k .(10)show below, segregated linear decision rule allows us easily obtain upperbound subset random variables (see Eqn 14), possible lineardecision rule framework proposed Ben-Tal Nemirovski (2002).Given mean variance segregated variable E(zk+ ) = E(zk ) = k ,22, express expected value varianceV ar(zk ) = mkV ar(zk+ ) = pkadjustable variable as:E[S(x, z)] = c0 +NXc+k k + ck k(11)k=1N nX+ 22V ar[S(x, z)] =ck pk + ck mk 2c+.ckk k(12)k=13. Decision Rules RCPSP/max Durational UncertaintyRCPSP/max durational uncertainty, decision rule specifies dependenceactivity start times durational uncertainty associated activities. makecomparison Equation 9, x represents POS generated; tasks starttime associated adjustable variable S(x, z), c0 represents earliest starttime task POS, ck (x) encodes task k related taskPOS.scheduling context, start time activity dependent start timespreceding activities, i.e. Adjustable variables S(x, z) dependent one another.activity either start end activity (i.e. series) endmultiple activities occurring simultaneously (i.e. parallel). Thus, adjustable variablesfunctions adjustable variables addition operator (to model serialactivities) and/or maximum operator (to model parallel activities).53fiFu, Lau, Varakantham, & XiaoGiven number adjustable variables, may express sum adjustablevariable form segregated linear decision rule follows:PM=i=1 Si (x, z)PM 0 PN nPM + +i=1 ci +k=1i=1 ci,k zk+PMi=1 ci,k zk.(13)Similarly, given set C adjustable variables, may also express upper boundmaximum variables adjustable variable form segregatedlinear decision rule:maxiC {Si (x, z)}nPnPN++maxiC {c0i } + Nmax{c}z+max{c}z.iCiCk=1k=1i,k ki,k k(14)specifically, output solving RCPSP/max involves POS representedgraph activities vertices precedence constraints activitiesedges. Given POS graph, x = (V, E), V set activities E settemporal dependencies (an edge (u, v) represents temporal dependency statesactivity v occur activity u). activity v V , decision rulecomputing start time defined recursively follows:Sv (x, z) = max {d0u + zu + Su (x, z)}.(u,v)E(15)Equation 15 recursive expression defined combination sum maximum set random variables. noted combinations sum maximum random variables cannot computed exactly hence present two operationaldecision rule approximations evaluate recursive expression Equation 15: (a) Segregated Linear Approximation(SLA); (b) General Non-Linear Approximation(GNLA).noted Sv computable long mean variance Su computabledemonstrated approximations.3.1 Segregated Linear Approximation (SLA)decision rule, duration activity defined based segregated randomvariables introduced Section 2.4. uncertain duration mean processingtime d0 , represent sum three components: mean d0 , lateness z + (i.e.0}),max{d d0 , 0}), earliness z (i.e. max{d0 d,= d0 + z + z .(16)normally distributed duration, i.e., z N {0, }, respective values meanvariance segregated variables summarized as:E[z + ] = E[z ] =2( 1) 2V ar[z + ] = V ar[z ] =.254(17)(18)fiRobust Local Search Solving RCPSP/max Durational Uncertaintydescribe computation Sv (x, z) representing durational uncertaintyactivities using segregated random variables. Upper bounds sum maximumrandom variables derived linear functions segregated variables illustratedbelow:Sum random variables : case project network involving k activities,two either precedence constraints competingresource units, solution form POS requires computation sumactivity durations. start time activity starting k-activity projectexpressed as:PSk (x, (z+ , z )) = ki=1 (d0i + zi+ zi ).(19)PThus, adjustable variable Sk mean ki=1 d0i uncertainty capturedPk+random variable, positive segregated componenti=1 ziPknegative segregated componenti=1 zi . Mean variance segregatedvariables known hence mean variance Sk easy compute.Max random variables: Consider activities executed concurrently,upper bound start time activity starting parallel k-activityproject network SLA represented linear function positive segregatedcomponents duration perturbations:P(20)Sk (x, (z+ , z )) maxi=1,...k {d0i } + ki=1 zi+ .Thus, adjustable variable Sk upper bound mean maxi=1,...k {d0i }uncertaintyP captured random variable positive segregated component given ki=1 zi+ negative segregated component. Mean variancesegregated variables known hence mean variance Sk easycompute.Since, cases (sum max) Sk expressed linearly subset random segregated variables, recursive computation straightforward. Compared lineardecision rules (Ben-Tal & Nemirovski, 2002), superiority SLA (Chen et al., 2008) liesability linearly express upper bound subset random variables dissecting uncertainty positive negative components. approximationincreases tractability scalability, comes expense losing accuracy.3.2 General Non Linear Approximation (GNLA)SLA efficient, typically provide loose upper bounds robust makespandue linear approximation computing max random variables. section,describe General Non Linear Approximation (GNLA), restrictedaffine dependencies. clarity comparison purposes, use G denote starttime instead used SLA.Given mean variance values duration uncertainty, describe approximation involved computing mean variance sum max activities55fiFu, Lau, Varakantham, & Xiaoused Equation 15. recalled irrespective distributionalways represent = d0 + z, d0 meanuncertain duration d,z perturbation part. Thus, E(z) = 0.3.2.1 Sum Random Variablescompute sum stochastic durations serial k activity project network follows:Gk (x, z) =kX(d0i + zi ).(21)i=1case, similar representation SLA. Mean variance Gk computedfollows:Since {zi }i=1,...k random variables zero mean, calculate expectedvalue as:kkXX0E[ (di + zi )] =d0i .i=1(22)i=1{zi } assumed independent other, variance value computedfollowing expression:kkXX0V ar[ (di + zi )] =V ar[zi ],i=1(23)i=1normal distribution zi N (0, ),kkXXV ar[ (d0i + zi )] =i2 .i=1(24)i=1Note expressions expected value variance case serial activitiesidentical ones used Wu, Brown, Beck (2009).3.2.2 Max Random Variablesease explanation, begin considering two activities executed parallelextend analysis multiple parallel activities. GNLA, (unlike SLA)max random variables approximated expected value variancemax approximately calculated.Expected Value Variance Max Two Variablesdecision rule represent starting time activity, begincompletion two parallel activities defined as:G2 (z) max{d01 , d02 } + max{z1 , z2 }.Note tighten bound Eqn 20 replacing z1+ + z2+ max{z1 , z2 }.56(25)fiRobust Local Search Solving RCPSP/max Durational Uncertaintyderive expressions expected value variance adjustable variable,i.e., RHS term Eqn 25. Firstly, focus expected value:E[max{d01 , d02 } + max{z1 , z2 }] = max{d01 , d02 } + E[max{z1 , z2 }].(26)general case, difficult derive exact expression E[max{z1 , z2 }] hence,provide upper bound.following Propositions 1 2, compute expected value variancegeneral case E(z) 0 (note assume E(z) = 0 primitive random variables). calculate general case required computationexpected value variance two random variables (next subsection).Proposition 1. expected value maximum two general distributions, z1z2 nonnegativepmeans less11V ar[z1 ] + V ar[z2 ] + (E[z1 ])2 + (E[z2 ])2 .2 (E[z1 ] + E[z2 ]) + 2Proof. begin considering following two equalities:max{z1 , z2 } + min{z1 , z2 } = z1 + z2max{z1 , z2 } min{z1 , z2 } = |z1 z2 |.sum two equalities.1max{z1 , z2 } = (z1 + z2 + |z1 z2 |).2(27)Thus, compute expected value maximum using following equation:1E[max{z1 , z2 }] = (E[z1 ] + E[z2 ] + E|z1 z2 |).2(28)addition, using definition variance, obtain:V ar|z1 z2 | = E(z1 z2 )2 (E|z1 z2 |)2 0.Therefore,pE|z1 z2 | p E(z1 z2 )2= pE(z12 ) + E(z22 ) 2E(z1 )E(z2 )pE(z12 ) + E(z22 )= V ar[z1 ] + V ar[z2 ] + E(z1 )2 + E(z2 )2 .Substituting final expression Eqn 29 Eqn 28 yields boundpE[max{z1 , z2 }] 12 (E[z1 ] + E[z2 ]) + 12 V ar[z1 ] + V ar[z2 ] + (E[z1 ])2 + (E[z2 ])2 .(29)(30)Hence proof.Note paper, assume E(z) = 0, thus, tighter bound obtainedEqn 30:p(31)E[max{z1 , z2 }] 21 V ar[z1 ] + V ar[z2 ].57fiFu, Lau, Varakantham, & Xiaospecial case {zi } (i = 1, ...k) normally identically distributed,i.e. zi N (0, ), know work Clark (1961) closed formrepresentation expected value maximum k = 2:E[max{z1 , z2 }] = .focus deriving expressions variance maximum two generaldistributions, i.e., V ar[max(z1 , z2 )].Proposition 2. variance maximum two general distributions, z1 z2nonnegative means less V ar(z1 ) + V ar(z2 ) + 21 (E(z1 ))2 + 12 (E(z2 ))2 .Proof. Eqn 27,V ar[max(z1 , z2 )] = 41 V ar[z1 + z2 + |z1 z2 |]= 14 (V ar[z1 + z2 ] + V ar|z1 z2 | + 2COVp (z1 + z2 , |z1 z2 |))14 (V ar[z1 + z2 ] + V ar|z1 z2 | + 2 V ar[z1 + z2 ]V ar|z1 z2 |)12 (V ar[z1 + z2 ] + V ar|z1 z2 |).(32)Firstly, consider following two equations.V ar|z1 z2 | = E(z1 z2 )2 (E|z1 z2 |)22(33)2V ar(z1 z2 ) = E(z1 z2 ) (E(z1 z2 ))Subtracting second first yieldsV ar|z1 z2 | = V ar(z1 z2 ) + (E(z1 z2 ))2 (E|z1 z2 |)2 .Now, substitute expression last term Eqn 32 obtain:V ar[max(z1 , z2 )] V ar(z1 ) + V ar(z2 ) + 12 (E(z1 ) E(z2 ))2 21 (E|z1 z2 |)2 .(34)specific distribution duration perturbation known, obtainbound V ar[max(z1 , z2 )] as:V ar[max(z1 , z2 )] V ar(z1 ) + V ar(z2 ) + 12 (E(z1 ))2 + 12 (E(z2 ))2 .(35)Hence proof.Note paper, assume E(z) = 0, thus, tighter bound obtainedEqn 35:V ar[max(z1 , z2 )] V ar(z1 ) + V ar(z2 ).(36)interesting consider special case random variables normallydistributed. first state following lemma1 .1. found statistics texts, found online http://en.wikipedia.org/wiki/Halfnormal distribution.58fiRobust Local Search Solving RCPSP/max Durational UncertaintyLemma 3.1. X normally distributed X N (0, ), = |X| half-normallydistributed,r2E(Y ) =.(37)normal distribution zi N (0, ), since z1 z2 also normally distributed,z1 z2 N (0, 1 + 2 ), conclude Lemma 3.1 |z1 z2 | follows half-normaldistributionr2E|z1 z2 | = (1 + 2 ).(38)Thus, substitute expression Eqn 34, express upper boundvariance value maximum duration perturbation two activities, zi N (0, ):V ar[max(z1 , z2 )] (121)( 2 + 22 ) 1 2 .1(39)Expected Value Variance Max Multiple VariablesExtending two k (k > 2) parallel activities, completion time upperbounded by:Gk (z) max {d0i } + max {zi }.(40)i=1,...ki=1,...kfollowing, first compute variance value RHS termuse similar procedure compute expected value. basic expression varianceRHS is:V ar[ max {d0i } + max {zi }] = V ar[ max {zi }].(41)i=1,...ki=1,...ki=1,...kobtain value V ar[ max {zi }] general probability distributions, takei=1,...kadvantage analysis provided two-parallel-activity case above. followingsteps outline overall idea:(a) Firstly, group activity set {a1 , ..., ak } couple set {C1 , ..., Cd k e },2element Cj (j = 1, ...d k2 e) contains two different activities Cj = {aj1 , aj2 } chosenactivity set. Note k odd, final element couple set containsone activity.(b) couple Cj , apply maximum operator duration perturbations involving activities. Denote cj = max{zj1 , zj2 }, zj1 zj2 duration perturbationstwo activities involved Cj , V ar(cj ) calculated based expressiontwo-parallel-activity case.(c) max {zi } = max {cj }. (Note one activity containedi=1,...kj=1,...d k2 eCd k e k odd). Then, build another couple set {C1 , ..., Cd k e },22method steps (1) (2) used compute V ar[ max {cj }] basedj=1,...d k2 eEqn 35 and/or Eqn 36 and/or Eqn 39.59fiFu, Lau, Varakantham, & Xiaonumerous ways (exponential k) generating couple set {C1 , ..., Cd k e }2k activities parallel. couple sets lead different levels tightnessderived robust makespan. compute grouping provides best robust fitnessrandom variables generic distributions open problem. Instead, focusheuristic computes best grouping normal distribution zi N (0, ).obtained solving following optimization problem:Xmaxj1 j2(42)kj=1,...b 2 cdenotes grouping technique also decision variable; {Cj } coupleset constructed activity set grouping method t; j1 j2 standarddeviations data perturbation durations activities contained Cj . intuitionemploying optimization problem obtained Equation 39. notedcomputing tighter bound variance implies considering highest possible valueproduct primitive variances. Hence, reason employing optimizationproblem Equation 42.Proposition 3. solution optimization problem Eqn 42 obtainedordering k activities non-increasing order variance values groupingtwo nearest activities according order, i.e. Cj = {aj1 , aj2 }, j = 1, ...b k2 cstandard deviations following order:11 12 21 22 , ...b k c1 b k c2 .22(43)Proof. Suppose another grouping method t0 , elements coupleset except two couples 2 ordering different, i.e., Cm ={am1 , an2 } Cn = {am2 , an1 } (m 6= n), Cm = {am1 , am2 } Cn = {an1 , an2 }. Without loss generality, assume > n Eqn 43,m1 m2 n1 n2 .(44)Since t0 supposed provide solution less ( defined Eqn 42) ,i.e.11 12 + ... + m1 n2 + ... + n1 m2 + ... + b k c1 b k c22211 12 + ... + m1 m2 + ... + n1 n2 + ... + b k c1 b k c2 .22Therefore,m1 n2 + n1 m2 m1 m2 + n1 n2 ,equivalent to: (m1 n1 )(n2 m2 ) 0.contradicts Eqn 44 (except case standard deviations equal,case mixing order affect anything). Thus, exists t0different least two couples better objective value. general case2. noted ordering change one couple, method still producessolution within couple variance computation consider order.60fiRobust Local Search Solving RCPSP/max Durational Uncertaintyt0 multiple (more two) couples different easily derivedcase (and omitted due space constraints).Hence proof.analyzing expected value E[ max {zi }], apply procedure emi=1,...kployed calculate variance, i.e., based group solution returnedoptimization problem, first calculate expected value couple then, getfinal bound following Eqn 30 and/or Eqn 31 and/or Eqn 32.present, unable show effectivness grouping heuristic (Equation 42) analytically general case. However, show intuition behindgrouping heuristic providing analytical comparison3 examplefour activities (normally distributed durations) executed parallel, i.e. zi N (0, ),assume 1 2 3 4 (no loss generality).representation makespan grouping heuristic (denoted Mheu )random grouping (denoted Mran ) are, respectively:Mheu = max{d01 , d02 , d03 , d04 } + max{max{z1 , z2 }, max{z3 , z4 }}Mran = max{d01 , d02 , d03 , d04 } + max{max{z1 , z4 }, max{z2 , z3 }}.Let us first examine mean variance values Mheu . Eqn 31,pE(max{z1 , z2 }) 12 p12 + 22E(max{z3 , z4 }) 12 32 + 42 .(45)(46)Eqn 39,V ar[max(z1 , z2 )] (1 1 )(12 + 22 ) 2 1 2V ar[max(z3 , z4 )] (1 1 )(32 + 42 ) 2 3 4 .(47)Eqn 30, Eqn 35, Eqn 46 Eqn 47, obtain bounds mean variancevalues Mheu 4 :qppP112222E(Mheu ) const + 4 ( 1 + 2 + 3 + 4 ) + 2 ( 45 1 ) 4i=1 i2 2 (1 2 + 3 4 )(48)PV ar(Mheu ) ( 98 1 ) 4i=1 i2 2 (1 2 + 3 4 ).Similarly, mean variance values Mran also calculated,qppPE(Mran ) const + 14 ( 12 + 42 + 22 + 32 ) + 12 ( 54 1 ) 4i=1 i2 2 (1 4 + 2 3 )(49)PV ar(Mran ) ( 89 1 ) 4i=1 i2 2 (1 4 + 2 3 ).Eqn 57, bounds fitness Mheu (denoted F itheu ) Mran (denotedF itran ) respectively represented function RHS Eqn 48 Eqn 49.examine difference value two bounds, F itheu F itran . Let us firstcompare first term RHS mean values Eqn 48 Eqn 49, sincepppp222( p32 + 42 )2 ( 12 + p22 + 32 )21 + 2 +4 +(50)2222222222= 2 1 3 + 2 4 + 1 4 + 2 3 2 1 3 + 22 42 + 12 22 + 32 423. calculation use robust fitness function provided Definition 57 introduced Section 4.4. Note const Eqn 48 Eqn 49 max{d01 , d02 , d03 , d04 }.61fiFu, Lau, Varakantham, & XiaoProposition 3,1 4 + 2 3 1 2 + 3 4 ,(51)12 42 + 22 32 (12 22 + 32 42 ) = (1 4 + 2 3 )2 (1 2 + 3 4 )2 0.(52)thus,Eqn 51, Eqn 52, Eqn 48 Eqn 49, bounds mean variancevalues Mheu lower Mran . Given robust fitness function Eqn 57,concludeF itheu F itran 0(53)independent . words, grouping heuristic provide tighterfitness bound random grouping.4. Robust Fitness Functionmakespan (start time dummy sink activity) RCPSP/max durational uncertainty function non-adjustable variables x random variables representing durational uncertainty z represented using S(x, z) SLA G(x, z)GNLA. Recall robust optimization problem find minimum value Ffollowing probability bound observed5 :P (S(x, z) F ) (1 )(54)one-sided Chebyshevs Inequality, obtain bound robust objective value F function expected value variance adjustable fitnessfunction, i.e.:qq(55)V ar[S(x, z)] F P (S(x, z) F ) (1 )E[S(x, z)] + 1Hence, reformulate robust optimization problem follows:min Fs.t.E[S(x, z)] +qq1V ar[S(x, z)] F(56)model, derive robust fitness function usedlocal search framework:Definition 3. Given 0 < 1 adjustable fitness function S(x, z) defined above,robust fitness function, f (x, z, ), definedrq1f (x, z, ) = E[S(x, z)] +V ar[S(x, z)](57)goal local search mechanism find local minima f . addition, localsearch typically requires fitness function computed many times henceimperative computation fitness function efficient.5. show computation SLA robust fitness function. substituting G, obtainfitness function GNLA.62fiRobust Local Search Solving RCPSP/max Durational Uncertainty4.1 Schedule Infeasibility Given POSnoted fitness function, f assumes schedule generatedPOS, x always executable. However, due durational uncertainty maximumtime lags, schedule always executable. direct way measure IP r(POS)probability infeasibility POS (i.e. probability POS lead infeasible schedule) lies computation probability infeasibility activity aiIP r(ai ), exist feasible start time temporal constraintsrespect ai satisfied. IP r(POS) calculated probabilityleast one activity infeasible. However, due temporal dependencies activitiesproviding theoretical expression overall probability infeasibility open problem. Therefore, propose simulation approach, simulate POS executionmultiple trials compute probability eciently approximately. illustration,experimented benchmark J10 instances PSPLib (Kolisch, Schwindt,& Sprecher, 1998) RCPSP/max additional durational uncertainty followsnormal distribution mean 0 variance 1. generated 1000 sample realizationsPOS obtained SLA, check infeasibility respect original temporal(including maximum time lag) constraints. Examples probability infeasibilityobtained simulation PSP1, PSP4, PSP13 0.18, 0.17 0.001. However,problems PSP3, PSP5 etc. probability infeasibility 0,maximal time lags much larger variance durational uncertainty.5. Robust Local Search Algorithmsection present decision rule approximations introduced SLA, GNLAintegrated robust fitness function local search mechanisms providesolution problems represented RCPSP/max durational uncertainty.proposed algorithm outlined follows. Steps 1, 2, 5 6 standard steps localsearch algorithm. Steps 3 4 represent departure standard local search dealuncertainty.1. Generate initial solutionusually obtained using simple greedy heuristic.2. Generate neighborhood solutionsGenerate pool neighbor solutions current solution.3. Employ one decision rule approximations (SLA GNLA)adjustable variables check feasibilitycandidate solution x solution pool, derive coefficients Ck (x)adjustable variable. Subsequently, solution check constraint violationreject feasible.4. Evaluate robust fitness function ffeasible solution x, evaluate f obtain robust objective values.solution lowest robust objective value current best robust solution.63fiFu, Lau, Varakantham, & Xiao5. Apply penalty (optional)advanced local search strategies may require penalty applied preventcaught local minima. case tabu-search example,tabu-list updated tabu move applied. case iterated local search,perturbation move applied current local minima.6. Termination criteriatermination criteria met, return solution lowest robust fitnessfunction value else repeat optimization cycle determining next move.Algorithm 1 provides robust local search algorithm guided decision rule using, , G , G , G , obtain local search algoSLA. substituting Snowminminrithm using GNLA. Given RCPSP/max durational uncertainty level risk(0 < 1), algorithm returns POS (locally) minimal robust makespan,(or G GNLA). essence, perform robust local search neighborhood setactivity lists. activity list (al) defined precedence-constraint feasible sequenceused heuristics generate earliest start time schedules solving standardRCPSP problem (Kolisch & Hartmann, 2005).Different activity lists explored local moves. context, consideractivity list sequence activities satisfy non-negative minimal time lagconstraint. Due existence maximal time lag constraint RCPSP/max, schedulingactivities earliest possible start time based order position activity listmay restrict schedule much may even return feasible schedule. Thus,schedule activity sequentially based order position activity list,assign starting time randomly picking time domain feasible starttimes.According experiments, new randomized approach returns feasiblesolutions earliest start time one. finding feasible schedule, POSgenerated applying chaining procedure proposed Policella et al. (2004). Then,(or G GNLA) value computed according POS. Intuitively, usingrandomized approach may return schedule large baseline scheduled completiontime. However, apply shortest path algorithm resulting POS generateearliest start time schedule smaller makespan.mentioned above, may difficult find feasible schedule satisfies minimalmaximal time lag constraints using activity list. fact, believe setactivity lists, many may yield feasible schedule. overcome problemfollows. define set activity lists result feasible (or infeasible) schedulesF (or I). seek design local search algorithm following characteristics:a) Starting activity list I, local search move activity list Fwithin short time. b) Starting activity list F , local search moveactivity list minimal (or G GNLA)value. c) also diversifyexploration activity lists F allowing local search move activity listF activity list I, since activity lists F region may reachableone another simple local moves. flavor strategic oscillation proposedmeta-heuristics research.64fiRobust Local Search Solving RCPSP/max Durational UncertaintyAlgorithm 1 Robust Local Search1: Generate activity list al randomly2: Find start time schedule, ss randomly according al3: al F4:P OS chaining(ss)Compute Snowaccording P OS5:6:Update Smin Snow7: else8:Record first activity cannot scheduled9: end10: 1 Max Iterational11:12:Shift activity ahead al randomly alelse13:14:Select two activities b c al randomly15:Swap b c al al16:end17:Find randomized start time schedule ss0 according al18:al0 FP OS 0 chaining(ss0 )19:20:Compute according P OS 021:al Snow22:Snow23:al al024:SminSmin25:26:end27:end28:else al29:al al030:else31:p rand(0, 1)p < 0.0132:33:al al034:Record first activity cannot scheduled35:end36:end37: end65fiFu, Lau, Varakantham, & Xiaodetailed robust local search procedure given Algorithm 1. procedure startsrandomly generating activity list al, sequence activities satisfynon-negative minimum time lag constraint (Line 1). Line 2, schedule ss producedbased ordering activities activity list al. first perform domain reductiondistance graph using Floyd-Warshall algorithm, feasible rangestart time activity based temporal constraints obtained.schedule activity sequentially based order position activity list.activity, first pick start time randomly feasible domain evaluate resourceconstraints duration activity (i.e. check current resource capacity exceedsresource amount used activity). yes, set start time activity,run shortest path algorithm reduce domains remaining activities, updatecurrent resource capacity due consumption activity. resource constraintssatisfied, try set start time randomly prescribed maximumnumbers retries. start time current activity set, proceed iterativelynext activity according activity list. Line 4, chaining() employedgenerate POS baseline schedule (section 2.2.4). ax Iteration refersmaximum number iterations robust local search. apply two different typeslocal moves. converge quickly activity list F, first local move designedschedule activity causing temporal resource conflict earlier time.randomly shift ahead first activity cannot scheduled currentactivity list (Line 12). activity list F, second local move randomlypick two activities swap current activity list, satisfying nonnegative minimal time lag constraints (Line 14-15). move accepted, resultssmaller equal value (Line 18-29). explore different activity lists, includesmall probability accept move leads infeasible schedule (Line 31-35).probability move activity list F one set 0.01. minimal.value saved Sminworst-case computational complexity analysis given follows. iterationlocal search, three major components: randomized schedule generation, POSconstruction fitness calculation. process randomized schedule generation,perform domain reduction resource checking iteration, thus complexityO(N (N 3 + H K w)) N number activities, H maximum planninghorizon, K number types resources, w prescribed maximum numberretries activity setting randomized start time. POS constructionprocess works follows: set activities first sorted according start timesgenerated deterministic schedule sorting part costs O(N logN );proceeds allocate activity total units needed type resource. Letmaxcap maximum capacity among resources. cost computing POSO(N logN + N K maxcap ). determining fitness value generatedPOS, examine edge edge check connected parallel serialrespect predecessors costs O(N + e) e number edges POS(e < N 2 ). Thus, worst-case complexity proposed robust local search algorithmO(T N (N 3 + H K w + K maxcap )) number iterations local search.66fiRobust Local Search Solving RCPSP/max Durational Uncertainty6. Enhancing Robust Local Searchsection, describe two enhancements improve basic local search methoddescribed Section 5. Firstly, describe ordering generation, pre-processingstep used identify precedence ordering activities. precedence orderingused focus local search activity lists. Secondly, describe new chainingmethod generate POS feasible schedule.6.1 Ordering GenerationOrdering Generation pre-processing step identifies precedence relationshipspairs activities. key idea certain pairs activities, always better(with respect robust makespan) ordering among activities. goalidentify pairs activities employ ordering focus local searchactivity lists chaining method used compute POS feasible schedule.deciding ordering pair activities, b, two key steps:(i) Sample set generation: Generate two sets activity lists. first set consistsactivity lists occurs b. second set generated swapping activitiesb every activity list first set; (ii) Order determination: step, firstcompute POS robust makespan activity lists two sets. comparingrobust makespan values corresponding activity lists two sets, determineordering activities. explain steps following subsections.problem n activities, Cn2 pairs activities. decideorders pairs, ordering computation needs implemented Cn2 times,computationally expensive. Based observation, first propose PairsSelection heuristic selectively choose certain number activities pairs whose orderingsignificant impact robust makespan.Pairs-Selection heuristic picks activity pair: (a) precedence relatedoriginal problem definition; (b) exists least one type resource,total demand activities exceeds resource capacity. intuition behindpicking activity pair two activities cannot executed paralleldeciding ordering relationship imperative eliminate resource conflict. One mainadvantage heuristic number pairs activities need orderedsignificantly reduced. Now, describe two steps ordering generation below:6.1.1 Sample Set Generationfirst randomly generate activity lists initial sample set denoted .element activity list represented ali sequence activities,= 1, ...m, i.e.= {ali |ali = (a1 , a2 , ...an ), {1, ...m}}.pair activities (ak , al ) resulting Pairs-Selection heuristic, definetwo sample sets represented ak al al ak . ak al activity lists, except activity list al ak , activities swapped.ak al = {aliak al |i {1, ...m}},67fiFu, Lau, Varakantham, & Xiao((a1 , a2 , ..., ak , ...al , ...an ) ali = (a1 , a2 , ..., al , ...ak , ...an ).aliak al =aliali = (a1 , a2 , ..., ak , ...al , ...an )Similarly, al ak constructed incrementally selecting activity listinitial set al ak reverse order ak al , i.e.al ak = {alial ak |i {1, ...m}},((a1 , a2 , ..., al , ...ak , ...an ) ali = (a1 , a2 , ..., ak , ...al , ...an )alial ak =.aliali = (a1 , a2 , ..., al , ...ak , ...an )Thus, activity list sample set ak al share positions activitiesexcept ak al corresponding activity list set al ak , al precedes ak .6.1.2 Order Determinationdetermine activity order selected pair activities based samplesets obtained last phase. pair (ak , al ), construct new instance postingprecedence constraint ak al al ak original instance, based newinstance, determine fitness denoted fiak al fial ak aliak alalial ak , respectively.Note aliak al alial ak share elements positions exceptorder ak al . Thus, order ak al considered reasonfitness aliak al alial ak differs. decide order ak al , define indexvariable denoted ivak al measures percentage samples oneorder ak proceeds al wins, i.e.Pivak al =min(alakf kf lak alak ,0)|ff l|.define Index Parameter activities ak al denoted IPak albenchmark index variable ivak al determining order ak al . parameter IPak al prescribed users different values (usually larger 50%)represent different levels confidence order ak al matters causing fitnessvariance, thus also represents different controllability ivak al .value index variable ivak al larger value IPak al , set orderak al since indicates higher probability b provide better robustnessb a; ivak al less 1 IPak al , set al ak ; cases, orderak al settled.6.2 Improved Chaining based Robustness Feedbacknoted Preliminaries section, activity a, may exist multiplechoices resource chains assigned. addition, different chaining heuristics lead POSes different robust makespan values. section,propose new chaining heuristic dispatches activities resource chains predictingimprovement robust makespan generated POS.68fiRobust Local Search Solving RCPSP/max Durational UncertaintyAlgorithm 2 Robustness-Feedback Resource Chaining (Activity a, Schedule S, Order G)1: C Find set available chains, C activity based2: P Collect chains C last activity chain preceding problem3: Collect chains C last activity chain ordered G4: P 6=5:k Get first available chain P6: else 6=7:k Get first available chain8: else9:k Get first available chain C10: end11: Post constraint last activity chain k (denoted last(k)) activity12: requires one resource unit13:C1 chains C last activity last(k)14:C2 C \ C115:resource units required16:choose first available chain belonging C117:chain feasible18:choose first available chain belonging C219:end20:end21: endlatest chaining method aims increase flexibility described Section 2.2.4, chains first randomly picked superior subset (i.e., chainslast activity already ordered, chains sharing last element). Since objective makespan-related time becomes concern, build work Policellaet al. (2009) pick first available chain wherever available. updated chainingmethod called Robustness-Feedback based Resource Chaining.Example 5. Figure 5 provides POS provided chaining heuristic usedExample 1. seen, compared POS 4, key difference allocationactivity 5 6. new heuristic, seen parallelismhence reduced robust makespan high probability.employing Ordering Generation algorithm conjunction chainingheuristic, also consider information ordered pairs allocating resourceunits activity. motivation activity activity b (for example,b) ordered, high probability precedence relationship resultbetter solution. Algorithm 2 provides pseudo code Robustness-FeedbackResource Chaining heuristic Ordering.7. Experimental Evaluationsection, first evaluate scalability quality execution strategiesprovided robust local search various enhancements introduced paper.69fiFu, Lau, Varakantham, & Xiao1Figure 5: POS Robustness Feedback ChainingSecondly, establish benchmark performance, compare best knowntechnique solving JSP problems durational uncertainty. notedrobust local search method developed solve RCPSP/max problems durationaluncertainty hence exploit structure present JSP problems. Furthermore,described earlier, optimization metrics approaches different.7.1 Experimental Setuptwo sets problems consider described subsectionsbelow. Additionally, also indicate algorithms compared datasets section.7.1.1 RCPSP/max Durational Uncertaintyproblems considered RCPSP/max durational uncertainty obtainedextending three benchmark sets available RCPSP/max problems, J10, J20J30 specified PSPLib (Kolisch et al., 1998). set contains 270 probleminstances duration activity ranging 1 10. maximum numberactivities J10, J20 J30 10, 20 30, respectively. activity ai , setexpected value d0i stochastic duration corresponding deterministic durationgiven benchmarks, assume duration uncertainty normally distributed,i.e. zi N (0, ). Henceforth, refer J10, J20 J30 RCPSP/max problemsdurational uncertainty. run algorithms problems four different durationvariabilities = {0.1, 0.5, 1, 2} four increasing levels risk = {0.01, 0.05, 0.1, 0.2}.70fiRobust Local Search Solving RCPSP/max Durational UncertaintyRCPSP/max problems durational uncertainty, compare robust localsearch guided using two decision rule approximations SLA GNLA. Furthermore, also compare different enhancements robust local search RCPSP/maxproblems durational uncertainty. compare five different variants robust localsearch decision rule approximation: (a) (GNLA) refers basic robust local searchguided GNLA decision rule approximation; (b) (GNLA+RC) robust local searchnew Robustness-feedback Chaining heuristic guided GNLA; (c) (GNLA+) refersbasic robust local search additional local search iterations, numberlocal search iterations determined based problem set (as described later); (d)(GNLA+OG) Order Generation heuristic top GNLA guided robust local search;finally (e) (GNLA+OG+RC) Order Generation Robustness-feedbackChaining heuristics GNLA guided robust local search.number local search iterations robust local search set 1000. reducestochasticity effects robust local search, average 10 random executionsproblem instance. code implemented C++ executed Core(TM)2Duo CPU 2.33GHz processor FedoraCore 11 (Kernel Linux 2.6.29.4-167.fc11.i586).7.1.2 JSP Durational UncertaintyJSPs, (GNLA) compared probabilistic makespan results providedBeck Wilson (2007). benchmark problems, consider instances generatedusing existing generator work Watson, Barbulescu, Whitley, Howe (2002)durations drawn uniformly interval [1,99]. Specifically, focus threesets probabilistic JSPs size {44,66,1010} (where 44 problems consists 4jobs consisting 4 activities each) set, three uncertainty levels {0.1,0.5,1}considered.7.2 Comparison SLA GNLAfirst compare average robust makespan 270 problem instances obtained robustlocal search guided decision rule approximations proposed Section 3.1Section 3.2. refer robust makespan computed using SLA using GNLAG . Figure 6 provides results three sets RCPSP/max problemsdurational uncertainty. results, show robust makespan affectedlevel risk standard deviation duration uncertainty. X-axis representsdifferent combinations risk standard deviation durational uncertainty, showntable Figure 6. runs every instance takes couple seconds hencereport CPU times here. key observations conclusions interest Figure 6follows:Irrespective , level risk increases, robust makespan decreasesSLA GNLA. Clearly, lower risk planner willing take,higher robust value generated execution strategy. methodcapable quantifying trade off, help planner decidedesired strategies.71fiFu, Lau, Varakantham, & Xiao10595G*S*857565554512345678910111213141516(a) Results J10146136G*S*12611610696867612345678910111213141516(b) Results J20170160G*S*1501401301201101001234567891011121314(c) Results J30Figure 6: Comparison Robustness SLA GNLA.721516fiRobust Local Search Solving RCPSP/max Durational UncertaintyIrrespective , degree duration variability increases, robust makespanincreases SLA GNLA, value becomes sensitivelevel risk constrained small value (e.g. = 0.01).lower values , specifically 0.01, provides lower values robustmakespan G . hand, higher values {0.05, 0.1, 0.2}, Gprovides superior performance . yet understand reason dropperformance = 0.01, observed consistently across RCPSP/maxbenchmark problems.problem instance, also observe monotonicity absolutedifference robust makespan G risk values. level risk takesvalue around 0.02, (SLA) slightly lower value G (GNLA). However,risk becomes 0.02, superiority GNLA increases higher values risk.Figure 7 illustrates randomly picked J10 instance = 1 = 2.pattern observed across problem instances J10, J20 J30.1056595608555755065S*45S*55G*40G*4535353025250.005 0.01 0.02 0.03 0.04 0.05 0.1 0.15 0.2 0.25 0.30.005 0.01 0.02 0.03 0.04 0.05 0.1 0.15 0.2 0.25 0.3(a) Results randomly selected J10 example (b) Results randomly selected J10 example=1=2Figure 7: Comparison Robust Makespan.Next, Figure 8, compare quality execution strategies obtained usingSLA GNLA. precisely, compare distributions actual makespansschedules computed using decision rule approximations. purpose, generateset 100 samples realizations durational uncertainty test 270 instancesbenchmark set different levels risk = 0.2, = 0.1 = 0.05 obtainrespective POS, compute actual makespans schedules derivedrespective POS given realization samples. difference real makespansobtained POSs generated two different decision rule approximations observedacross board examples three sets values except 0.01. randomlyselect three problem instances benchmark set present results Figure 8.Figure 8 also compares cumulative frequency distributions actual makespans.observe GNLA provided far better realized makespans SLA - absoluteterms, well distributionally. J20, except 2 cases, rest actual makespan73fiFu, Lau, Varakantham, & Xiao82100%8080%787660%7440%7220%700%6869717375777981(a) Results randomly selected J10 example = 0.2100%6080%5560%5040%4520%400%414345474951535557(b) Results randomly selected J20 example = 0.1110100%10580%10060%9540%20%900%8586 88 90 92 94 96 98 100 102 104 106 108(c) Results randomly selected J30 example = 0.05Figure 8: Comparison Actual Makespans Gap G .(Lines left pictures top indicating: Computed , Actual Simulation, Computed G , Actual G Simulation.)74fiRobust Local Search Solving RCPSP/max Durational Uncertaintyvalues obtained SLA higher ones obtained GNLA. Similar trendsobserved J10 J30.illustrate difference quality absolute two upper bounds, providefour lines (computed , actual , computed G actual G ) indicating upperbounds computed using algorithms simulation 100 samples.7.3 Comparing Robust Local Search EnhancementsSince, already shown GNLA performs better SLA, show performance enhancements GNLA section. noted enhancements SLA provided similar results conclusions GNLA based enhancementsoutperforming SLA based enhancements. Since Ordering Generation heuristic requiresadditional rounds robust makespan computation, also include benchmark called(GNLA+) (which GNLA plus extra iterations local search) make fair comparison.avoid complexity considering pairs activities, consider pairsactivities ordering would improve performance. proposed Pairs-Selectionheuristic select pairs activities. number extra iterations local search(GNLA+) benchmark number activity pairs picked Pairs-Selectionheuristic times number samples used Ordering Generation process.experimental results shows average number activity pairs 270 instances selected Pairs-Selection heuristic J10, J20 J30 5, 14, 28 respectively.work, set = 100. Thus, extra iterations (GNLA+) benchmarkJ10, J20 J30 500, 1400 2800, respectively. performance enhancements shown Figure 9(a), Figure 9(b), Figure 9(c) J10, J20 J30 respectively.charts, represented X-axis robust makespan Y-axis. So,lower values better Y-axis.Given key observations conclusions made results:Irrespective durational uncertainty, (GNLA+RC) (GNLA+OG) providebetter robust makespan values (GNLA) (GNLA+) J10 J30.indicates new Robustness Feedback Chaining heuristic OrderDetermination able provide robust partial ordered schedules J10J30. improvement seems increase number activities, i.e.difference obvious instances J30 J10. Furthermore,difference consistently observed across problems. However, improvementconsistent J20 cases (GNLA+RC) (GNLA+OG)perform (GNLA) (GNLA+). instance J20 problems, (GNLA+)provides better performance (GNLA+RC) (GNLA+OG) = 0.01= 1.5.extra iterations local search (GNLA+) improve solution qualitymuch J10. However, improves solution quality J20 J30. couldoptimal solution obtained within 1000 iterations smallerproblems.cases, (GNLA+RC+OG) provides lowest robust makespan amongenhancements. Thus, OG RC enhancements combination degrade75fiFu, Lau, Varakantham, & Xiao(a) Results J1076fiRobust Local Search Solving RCPSP/max Durational Uncertainty(b) Results J2077fiFu, Lau, Varakantham, & Xiao(c) Results J30Figure 9: Comparison Robust Local Search Enhancements.78fiRobust Local Search Solving RCPSP/max Durational UncertaintyMNPMCBGProblem Size44UL=0.1 UL=0.5 UL=11.0231.0461.1281.0661.1231.282Problem Size66UL=0.1 UL=0.5 UL=11.0211.0731.1681.0951.1901.273Problem Size1010UL=0.1 UL=0.5 UL=11.0241.1011.2151.2101.2251.263Table 2: Comparison CB solver(UL:Uncertainty Level).performance improvement obtained individually. cases, differencesignificant J10 = 0.1 = 0.01. hand,cases (GNLA+RC+OG) provide lowest robust makespan,J20 = 0.5 = 0.01.7.4 Comparing JSPs Durational Uncertaintysection, compare performance GNLA approach (referred G )best known solver Job Shop Scheduling Problems proposed Beck Wilson (2007) (referred CB). fair comparison two approaches, employMean Normalized Makespan (MNPM) metric defined Beck Wilson:N P (a, L) =1 X D(a, l)|L|Dlb (l)(58)L set problem instances, D(a, l) probabilistic makespan (i.e., robustmakespan work) instance l algorithm generated Monte Carlo simulation,Dlb (l) lower bound probabilistic makespan.denote best MNPM values aross different algorithms reported BeckWilson CB. compare MNPM values work obtainedreplacing D(a, l) Eqn 58 upper bound robust makespan POSgenerated GNLA-guided local search. runs 4 4 6 6 instances took lessminute, 10 10 instances took 15 minutes.Table 2 provides results. performance solver comparable CB solveracross problem instances. comparison illustrates local search mechanismgeneric (different types scheduling problems) also able provide performancepar near optimal approaches. performance comparable, CB providesbetter MNPM values approach due following key reasons: (a) approachexploit structure specific JSPs (jobs consisting sequence operations).hope improve approach exploit near future. (b) robust localsearch reasons upper bounds (due Chebyshev inequality), loose.8. Related WorkResource-Constrained Project Scheduling Problem minimum maximum timelags, RCPSP/max, (or known Resource-Constrained Project Scheduling ProblemGeneralized Precedence Relations, RCPSP-GSR) strongly NP-hard combinatorial optimization problem; even decision problem determining whether79fiFu, Lau, Varakantham, & XiaoRCPSP/max instance feasible solution NP-complete (Bartusch et al., 1988).survey recent developments new applications RCPSP/max givenNeumann, Schwindt, Zimmermann (2006).However, find much study considers RCPSP/max uncertainty.One paper dealing variable durations RCPSP/max done LombardiMilano (2009), activity durations range given lower upper bounds.precedence constraint posting approach (Policella, Cesta, Oddi, & Smith, 2007)adopted. Whereas work, consider RCPSP/max durational uncertaintyactivity duration modeled random variable known mean variancevalues.Research scheduling uncertainty received much attention ArtificialIntelligence Operations Research communities. complete survey recent AIpapers robust project scheduling 2004, one may refer work HerroelenLeus (2005) production scheduling (Aytug, Lawley, McKay, Mohan, & Uzsoy,2005). Broadly, one may classify techniques tackle scheduling uncertaintytwo categories: Proactive Scheduling design priori schedule schedule policytake account possible uncertainty may occur; Reactive Scheduling modifiesre-optimizes baseline schedule unexpected event occurs. interestproactive scheduling concerned robust scheduling focusesobtaining proactive schedules maintain high level performance uncertainty.main idea proactive techniques build global solution hopefullyneed revised execution time. One divide research area threecategories, according information uncertainties takenaccount generating robust stable schedules would without usinginformation (Bidot, Vidal, Laborie, & Beck, 2009): 1. generating one complete genericschedule proved execute correctly scenarios arising execution;2. generating flexible solution decisions postponed madeexecution; 3. generating conditional solution mutually exclusive decisionsdeveloped,the one chosen dependent observations execution, likemarkov decision processes. following, briefly look first two cases sincerelated work.8.1 Generating Generic Schedulefirst method making generic schedule insensitive online perturbationsproduce complete robust schedule taking account possible scenarios, i.e.schedule strong controllability (Vidal & Fargier, 1999). Rather dealing execution 100% confidence, probabilistic techniques proposed build schedulesprobabilistic guarantee threshold value optimization metricmakespan. Another example generic schedule generation fuzzy scheduling (Herroelen & Leus, 2005): instead stochastic variables probabilistic distributions, fuzzyset scheduling use fuzzy numbers modeling uncertainties based possibility theory;recent work Rodrguez et al. (2009) modeled uncertain durations fuzzy numbersimproved local search solve Job Shop Scheduling Problem. following,80fiRobust Local Search Solving RCPSP/max Durational Uncertaintyprovide details work related strong controllability probabilistictechniques.8.1.1 Strong Controllable TechniquesStrong Controllability introduced Vidal Fargier (1999) Simple TemporalNetworks Uncertainty (STNU) controllability achievable polynomialtime. existence uncontrollable events controlled exogenous factors, often referred Nature, STNU strongly controllable exists leastone universal schedule suits situation. schedule might computed off-linebeforehand. Strong controllability strictest form STNU. strongly controllablenetwork means schedule executed without regard contingent events.useful applications contingent events cannot observed exactly.8.1.2 Probabilistic TechniquesInstead generating global solution suitable realizations uncertainties, probabilistic techniques build schedule probabilistic guarantee deterministicoptimization measure respect threshold value, e.g., find schedulehighest probability project makespan exceed particular value.Daniels Carrillo (1997) defined -robust schedule one maximum probability achieving given performance level, e.g., total flow time greatergiven threshold. presented branch-and-bound heuristic techniques find robust schedule one-machine manufacturing context performs best within givenconfidence level. Job Shop Scheduling Problem, Beck Wilson (2007) consideractivity durations random variables; given level risk 0 1, interestedsolution minimal (probabilistic) makespan probability executionleast 1 .8.2 Generating Flexible ScheduleAnother way producing robust schedule taking account uncertainty introduceflexibility schedule. idea subset decisions made offlinerest postponed made online, decisions made informationbecomes precise certain (Bidot et al., 2009). following, discuss threesubcategories works deal generating flexible schedules.8.2.1 Dynamic Controllable TechniquesSTNU Dynamic Controllable (Vidal & Fargier, 1999) exists solutionalways instantiated incrementally based outcomes contingent edges past.execution strategy using dynamic controllability needed produce incrementalsolution based subsequent revelation contingent events. Morris Muscettola(2005) proposed pseudo-polynomial algorithm handle dynamic controllability STNUsbased constraint satisfaction. Techniques proposed Wah Xin (2004)optimize bounds durations contingent edges resulting STNUdynamic controllable.81fiFu, Lau, Varakantham, & Xiao8.2.2 Redundancy-based TechniquesRedundancy-based scheduling another proactive technique scheduling. ideagenerate schedule includes allocation extra resources and/or timeschedule buffers help absorb impact unexpected events withoutrescheduling execution. Davenport, Gefflot, Beck (2001) proposed techniquesgenerating robust schedules based insertion temporal slacks critical activities allocated possibly breakable resources. Lambrechts, Demeulemeester,Herroelen (2010) analytically determined expected increase activity duration dueresource breakdown. Based information, simulation-based time buffering usedprotect schedule disruptions caused resource availability.8.2.3 Partial Order Schedule (POS)Even buffering, baseline schedules may become brittle face unpredictable execution dynamics quickly get invalidated. Instead baseline schedule, another linework consider design good schedule policies. One example notionPartial Order Schedules (POS) defined Policella et al. (2004) seeks retaintemporal flexibility whenever problem constraints allow often absorb unexpected deviation predictive assumptions. considered robustness measuresfluidity flexibility. Generating POS another example flexible approaches:subset sequencing decisions made offline remaining decisions made onlineusing dispatching rule (Bidot et al., 2009). Different methods generating POScompared terms robustness resulting schedules work Rasconi, Cesta,Policella (2010). work, apply concept POS execution policy.Given RCPSP/max instance, mean variance values segregated variablesdata perturbations level risk, objective work determine POSlocally minimal robust value.8.3 Scenario-based Optimization SchedulingAnother line work deals scheduling uncertainty based usescenarios (scenario-based optimization). example, Kouvelis, Daniels, Vairaktarakis(2000) introduced concept robustness scheduling problems. considered uncertain processing times proposed methods generate robust schedule basedmaximum absolute deviation robust solution possible scenariosgiven scenario set. shortcoming kind approach scenarios assumedknown advance, scenario space usually exponentially large. Noteworthy mention two notions solution robustness quality robustness,solution robustness (or stability) refers insensitivity actual start times, whereasquality robustness refers insensitivity solution quality (i.e. makespan) differentscenarios (Herroelen & Leus, 2005). Another pioneering scenario-based optimization workMulvey, Vanderbei, Zenios (1995) handles tradeoff solutionrobustness (if solution remains close optimal scenarios) model robustness(if solution remains feasible scenarios).82fiRobust Local Search Solving RCPSP/max Durational Uncertainty8.4 Robust Optimization Schedulingrecent development Operations Research saw potential applying conceptRobust Optimization deal uncertainty. Ben-Tal Nemirovski (2002) Bertsimas Sim (2003) proposed robust optimization models assumptionsunderlying probability distribution data needed. idea often approximatedata uncertainty tractable (convex) uncertainty set, optimization performedset. results robust counterpart formulation conic (such second-ordercone) optimization problem solved polynomial time. However,works reported literature applying robust optimization scheduling,due mainly high-degree combinational nature problem. One applicationprocess scheduling problem chemical engineering, works Janak,Lin, Floudas (2007) Li Ierapetritou (2008). notable recent breakthroughrobust optimization tractable approximation models solve stochastic optimizationproblems found Chen et al. (2008). work makes use linear segregated decision rules relevant solving combinatorial scheduling problems durationaluncertainty work exploit mechanism incorporate local search.9. ConclusionGiven level risk 0 < 1 chosen planner, investigated problem findingminimum (1 )-guaranteed makespan (i.e. Robust Makespan) proposed methodsfind schedule policy (POS) uncertainty dynamically realized,execution policy result solution whose value good robust makespan.first put forward new decision rule utilized scheduling help specify start timesactivities respect execution policy dynamic realizations data uncertainty.Based decision rule, new fitness function derived evaluate robustness,finally integrated local search framework produce solutionrobust makespan. Experimental results illustrate improved performance local searchnew fitness evaluation, provider tighter bounds robust makespanbetter partial order schedules compared existing method.simplicity adopted upper bound approach assume independence among durational uncertainties. One future work treat correlationsdurational uncertainties, since task duration could correlated others reallife. example, correlations occur external event peculiar singletask, universal, weather conditions, seasonal peaks. situations,durational delays correlated direction. occurs, decisionrules proposed paper break unfortunately, since even covariancespairs duration variables given, complex analytically model extentone duration combination (resulting SUM MAX operators)durations change together. turn complicates analysis variancemakespan variable, hence robust makespan. Extending work handlecovariances interesting future direction.83fiFu, Lau, Varakantham, & XiaoAcknowledgmentspaper extends previous research Lau, Ou, Xiao (2007) Fu, Varakantham,Lau (2010). authors wish thank reviewers insightful comments.ReferencesAytug, H., Lawley, M. A., McKay, K., Mohan, S., & Uzsoy, R. (2005). Executing production schedules face uncertainties: review future directions.European Journal Operational Research, Vol. 165(1), pp. 86110.Bartusch, M., Mohring, R. H., & Radermacher, F. J. (1988). Scheduling project networksresource constraints time windows. Annals Operations Research, 16 (1-4),201240.Beck, J. C., & Wilson, N. (2007). Proactive algorithms job shop scheduling probabilistic durations. Journal Artificial Intelligence Research, 28 (1), 183232.Ben-Tal, A., & Nemirovski, A. (2002). Robust optimization - methodology applications.Mathematical Programming, 92, 453480.Bertsimas, D., & Sim, M. (2003). Robust discrete optimization network flows. Mathematical Programming, 98, 4971.Bidot, J., Vidal, T., Laborie, P., & Beck, J. C. (2009). theoretic practical frameworkscheduling stochastic environment. Journal Scheduling, 12, 315344.Chen, X., Sim, M., Sun, P., & Zhang, J. (2008). linear decision-based approximationapproach stochastic programming. Operations Research, 56 (2), 344357.Clark, C. E. (1961). Greatest Finite Set Random Variables. Operations Research,9, 145162.Daniels, R., & Carrillo, J. (1997). Beta-robust scheduling single-machine systemsuncertain processing times. IIE Transactions, 977985.Davenport, A. J., Gefflot, C., & Beck, J. C. (2001). Slack-based techniques robustschedules. Proceedings 6th European Conferences Planning (ECP).Dean, B. C., Goemans, M. X., & Vondrak, J. (2004). Approximating stochastic knapsackproblem: benefit adaptivity. FOCS, pp. 208217.Demeulemeester, E. L., & Herroelen, W. S. (2002). Project scheduling : research handbook.Kluwer Academic Publishers, Boston.Fu, N., Varakantham, P., & Lau, H. C. (2010). Towards finding robust execution strategiesrcpsp/max durational uncertainty. Proceedings International ConferenceAutomated Planning Scheduling (ICAPS), pp. 7380.84fiRobust Local Search Solving RCPSP/max Durational UncertaintyHagstrom, J. N. (1988). Computational complexity pert problems. Networks, 18, 139147.Herroelen, W., & Leus, R. (2005). Project scheduling uncertainty: Surveyresearch potentials. European Journal Operational Research, Vol. 165(2), pp.289306.Janak, S., Lin, X., & Floudas, C. (2007). new robust optimization approach schedulinguncertainty :ii. uncertainty known probability distribution. ComputersChemical Engineering, 31, 171195.Kolisch, R., & Hartmann, S. (2005). Experimental investigation heuristics resourceconstrained project scheduling: update.. European Journal Operational Research.Kolisch, R., Schwindt, C., & Sprecher, A. (1998). Benchmark Instances Project Scheduling Problems, pp. 197212. Kluwer Academic Publishers, Boston.Kouvelis, P., Daniels, R. L., & Vairaktarakis, G. (2000). Robust scheduling two-machineflow shop uncertain processing times. IIE Transactions, 32, 421432.Lambrechts, O., Demeulemeester, E., & Herroelen, W. (2010). Time slack-based techniquesrobust project scheduling subject resource uncertainty. Open access publicationskatholieke universiteit leuven urn:hdl:123456789/272147, Katholieke UniversiteitLeuven.Lau, H. C., Ou, T., & Xiao, F. (2007). Robust local search application generatingrobust schedules. Proceedings International Conference Automated PlanningScheduling (ICAPS), pp. 208215.Li, Z., & Ierapetritou, M. G. (2008). Robust optimization process schedulinguncertainty. Industrial Engineering Chemistry Research, 47 (12), 41484157.Lombardi, M., & Milano, M. (2009). precedence constraint posting approachrcpsp time lags variable durations. Proceedings 15th internationalconference Principles practice constraint programming, CP09, pp. 569583Berlin, Heidelberg. Springer-Verlag.Mohring, R. H. (2001). Scheduling uncertainty: Bounding makespan distribution.Computational Discrete Mathematics, pp. 7997.Mohring, R. H., & Stork, F. (2000). Linear preselective policies stochastic projectscheduling. Mathematical Methods Operations Research, 52 (3), 501515.Morris, P., & Muscettola, N. (2005). Temporal dynamic controllability revisited. Proceedings 20th National Conference Artificial Intelligence, pp. 11931198. AAAIPress.Mulvey, J. M., Vanderbei, R. J., & Zenios, S. J. (1995). Robust optimization large-scalesystems. Operations Research, 43.85fiFu, Lau, Varakantham, & XiaoNeumann, K., Schwindt, C., & Zimmermann, J. (2006). Resource-constrained projectscheduling time windows. International Series Operations Research Management Science, 92, 375408.Policella, N., Cesta, A., Oddi, A., & Smith, S. (2009). Solve-and-robustify. JournalScheduling, 12, 299314. 10.1007/s10951-008-0091-7.Policella, N., Cesta, A., Oddi, A., & Smith, S. F. (2007). precedence constraint postingpartial order schedules: csp approach robust scheduling. AI Communications,20, 163180.Policella, N., Smith, S. F., Cesta, A., & Oddi, A. (2004). Generating robust schedulestemporal flexibility.. Proceedings International Conference Automated Planning Scheduling (ICAPS), pp. 209218.Rasconi, R., Cesta, A., & Policella, N. (2010). Validating scheduling approachesexecutional uncertainty. Journal Intelligent Manufacturing, 21 (1), 4964.Rodrguez, I. G., Vela, C. R., Puente, J., & Hernandez-Arauzo, A. (2009). Improved localsearch job shop scheduling uncertain durations. Proceedings International Conference Automated Planning Scheduling (ICAPS).Vidal, T., & Fargier, H. (1999). Handling contingency temporal constraint networks:consistency controllabilities. Journal Experimental Theoretical ArtificialIntelligence, 11, 2345.Vonder, S., Demeulemeester, E., & Herroelen, W. (2007). classification predictivereactive project scheduling procedures. Journal Scheduling, 10 (3), 195207.Wah, B. W., & Xin, D. (2004). Optimization bounds temporal flexible planningdynamic controllability. IEEE International Conference Tools ArtificialIntelligence, 0, 4048.Watson, J.-P., Barbulescu, L., Whitley, L. D., & Howe, A. E. (2002). Contrasting structuredrandom permutation flow-shop scheduling problems: Search-space topologyalgorithm performance. INFORMS Journal Computing, 14, 98123.Wu, C. W., Brown, K. N., & Beck, J. C. (2009). Scheduling uncertain durations: Modeling beta-robust scheduling constraints.. Computers Operations Research,36, 23482356.86fi